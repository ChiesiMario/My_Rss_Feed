<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[iThome]]>
        </title>
        <link>https://www.ithome.com.tw/news/feeds</link>
        <atom:link href="https://rsshub.app/ithome/tw/feeds/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[iThome Online 是台湾第一个网路原生报，提供 IT 产业即时新闻、企业 IT 产品报导与测试、技术专题、IT 应用报导、IT 书讯，以及面向丰富的名家专栏。 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 01 Dec 2023 17:52:52 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[【re:Invent 2023】AWS 如何以生成式 AI 再创新]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/riv23_d3selipsky_keynote_00696a.png?itok=q9zG5-YD" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>AWS</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>「以生成式 AI 再创新」，在 AWS 年度用户大会 re:Invent 2023 的重头戏－由执行长独挑大梁的主题演讲上，AWS 执行长 Adam Selipsky 开宗明义，AWS 不只是因应时下热门的生成式 AI 热潮，更借由生成式 AI 迎接新一波再创新的机会。</p><p>一如往常，Selipsky 在二个半小时的演讲中，一口气发表大量新产品服务，而其中几乎全数与生成式 AI 有关，不仅涵盖生成式 AI 架构的三个层级—基础设施、工具与应用程式，还包括首度揭晓、专为企业组织所设计的商务型 AI 聊天机器人 Amazon Q，可望成为其在生成式 AI 领域的新战略利器。</p><p>Selipsky 首先宣布的是 Amazon S3 Express One Zone，它是 AWS 目前效能最强、延迟最低的 S3 物件储存方案，效能足以应付每分钟数百万次的存取，延迟时间则不到 10 微秒，主要是因应如金融分析、诈欺侦测、机器学习训练模型与即时推播广告等应用对于高速存取的需求，而存取的计费竟然比 S3 标准版便宜一半。据先期使用者 Pintrest 的经验，其写入速度快了 10 倍，而总体成本减少 4 成。</p><p>AWS 自家研发的晶片 Graviton，则预计于明年正式推出第四代产品，Selipsky 表示，Graviton4 将会是 AWS 旗下效能最强且能源效率最好的运算晶片，其效能将比前一代 Graviton3 快 30%，资料库应用效能快 40%，在大型 Java 应用程式的效能提升则更显著，可达 45% 的提升，而采用 Graviton4 的 EC2 实体 R8g 已可提供预览。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/RIV23_D3Selipsky_Keynote_01753a.png" style="width: 640px; height: 426px;" referrerpolicy="no-referrer"></p><p>在上述两项产品宣布后，发表会旋即揭开生成式 AI 重头戏。Selipsky 首先邀请 Nvidia 执行长黄仁勋上台，宣布双方扩大多项策略合作。第一项是 Nvidia 将提供针对生成式 AI 运算需求所设计的 GH200 Grace Hopper Superchip 运算卡，让 AWS 成为第一个采用的云端运算供应商。</p><p>AWS 将会以一个 EC2 执行个体的型式提供整套 GH200 NVL32 的运算力，GH200 NVL32 整套系统是以 NVlink 连结技术串接 32 片 GH200 Grace Hopper Superchip 运算卡，整套系统亦包含 NVswitch，可配置最大 20TB 共享记忆体，运算力可说是超级电脑等级，对于需要仰赖巨量运算资源的生成式 AI 模型训练有很大的助益。</p><p>上述的 EC2 执行个体亦立基于 AWS 的第三代 EFA（）连结技术与 Nitro 的虚拟化技术，因而每片 Superchip 运算卡拥有高速低延迟的 400Gbps 网路传输速度，执行个体的串接数量可多达上千个，提供在网路服务上建立巨大的 AI 运算丛集。</p><p>AWS 与 Nvidia 的扩大合作，还包括 Nvidia 将首度提供其专为生成式 AI 运算所设计的 Nvidia DGX 超级电脑等级运算云，予以第三方云端服务供应商，由 AWS 提供云端托管服务。Nvidia DGX 亦立基于 GH200 NVL32，可支援超过 1 兆参数的生成式 AI 与大型语言模型的训练。此外，双方也借由 Project Ceiba 的合作，建置一套超过 16,384 个 Nvidia GH200 超级晶片，运算速度达 65 Exaflops 等级的 AI 超级电脑，作为 Nvidia 研发全新生成式 AI 之用。</p><p>在生成式 AI 架构的基础设施层，Selipsky 宣布 AWS 自家设计的新一代 AI 训练晶片 Trainium 2 将于明年推出，效能比前一代提升 4 倍，可应付参数量千亿至兆级的基础模型训练需求。</p><p>在生成式 AI 架构的工具层，AWS 最大的利器就是 Bedrock 平台，而 Bedrock 的一大优势就是支援多种大型语言模型，从 AI21、Amazon Titan、Anthropic、Cohere、Llama2 到 stability.ai。Selipsky 说，AWS 深信没有任何一个大型语言模型可以主宰一切，因为各个模型在不同的应用面上皆有其独到之处。</p><p>Bedrock 的另一个优势，则是客制化能力。Selipsky 指出，AWS 的生成式 AI 技术的研发，打从第一天开始就是以企业需求为出发点，考量到不同型态的企业生成式 AI 应用需要运用不同的模型，再者各别企业的产业型态、业务流程与企业知识皆有不同，企业需要有客制化模型的弹性，才能将企业知识融入模型，创造各别竞争优势，同时也由于企业知识具有机敏性，必须将资讯安全与资料隐私设计在内，确保商业机密在模型训练过程中不会外泄。</p><p>在模型客制化方面，AWS 新推出三款服务，包括 Cohere、Llma2 与 Titan 三种模型的微调（Fine tuning）、Retrieval Augmented Generation (RAG) with Knowledge Bases 及 Titan 模型的持续预训练。</p><p>对于企业担忧生成式 AI 本质上存在不可控的可能性，AWS 也新推出 Guardrails for Amazon Bedrock，提供过滤有害内容的功能，确保模型输出的内容符合企业的负责任 AI（Responsible AI）政策，而针对基础模型输出的个资内容予以事先编辑，以防个资外泄的功能，也在未来规画蓝图中。</p><p>在生成式 AI 架构最上层的应用层方面，Selipsky 则是相当兴奋地宣布 AWS 首款 AI 聊天机器人 Amazon Q 的问世。面对市面上已有众多 AI 聊天机器人抢占市场先机，为何 AWS 还要推出另一款聊天机器人？Selipsky 表示，Amazon Q 是专为企业组织设计的商务型 AI 聊天机器人，与其他聊天机器人最大的不同是考量企业应用的情境、资讯安全、资料隐私与依职责控管存取权限等需求。</p><p>Selipsky 提出 Amazon Q 可望协助企业的四大面向，包括协助软体开发人员撰写程式码、协助同仁提升日常工作效率、让同仁便于获得商业智慧的协助，以及提升更好的顾客服务。在程式码方面，AWS 新推出 Amazon Q Code Transformation，透过生成式 AI 技术协助程式码改写升级与强化程式码安全，Selipsky 指出，这项新服务可让 1 千个 Java 应用程式的改写工作，在 2 天内就完成，若在过往由开发人员改写，往往需耗时数月甚至数年。此外，Amazon Q 的训练资料涵盖 17 年的 AWS 产品与服务资料，使用 AWS 的软体开发人员或架构师可用聊天问答介面，立即取得 AWS 所有的技术资讯。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/amazonq.png" style="width: 700px; height: 508px;" referrerpolicy="no-referrer"></p><p>除了协助软体开发人员，Amazon Q 也可以帮助资料库管理人员，Amazon Redshift Serverless 资料仓储服务整合了 Amazon Q，使用者可用自然语言提出资料查询需求，由 Amazon Q 自动生成 SQL 资料库查询指令，协助提升 ETL 等工作的效率。</p><p>Amazon Q 亦可望成为企业内的专家助手，可连结超过 40 种企业常用服务的资讯源，如 S3、Salesforce、Google Drive、Microsoft 365、ServiceNow、Gmail、Slack、Atlassian 与 Zendesk 等，涵盖一般办公室文书通信、业务行销、软体开发与 IT 管理等平台，同时依据询问者的存取权限来提供其被授权的内容。此外，Amazon Q 也会整合至 Amazon Quicksight、Amazon Connect 等商业智慧与客户服务平台。</p><p>AWS 资料与人工智慧资深副总裁 Swami Sivasubramanian 则指出开发生成式 AI 应用必备的四个要素，包括要有基础模型、可让模型运行的私有安全运算环境、易于使用的生成式 AI 开发工具，以及机器学习专用运算架构。他亦强调资料是生成式 AI 的重要关键，资料会决定企业生成式 AI 的差异性，而资料的储存、处理、分析、治理，本来就是企业用户使用 AWS 云端服务的重要应用之一。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/RIV23_D4Swami_00421a(1).png" style="width: 640px; height: 426px;" referrerpolicy="no-referrer"></p><p>Sivasubramanian 也发表多项生成式 AI 服务，包括 Amazon Titan 新增影像生成功能，不仅可以生成高画质的图像，使用者甚至可用自然语言下达指令，在保持影像背景下让图片中的主角镜像翻转，而 Titan Image Generator 生成的图片都会加上隐形浮水印，以利识别 AI 生成，避免沦为假讯息之用。此外，Titan 也新增转换多模态向量（Multimodal Embeddings）的能力，同时支援文字、图片、影像与音讯。而为了因应负责任 AI 的需求，Bedrock 也提供模型评估功能，让用户先以预载的资料与检测方法评估模型的适用性与风险，另外，AWS Clean Rooms ML，则可让企业不需提供训练资料也能与合作伙伴共享模型。</p><p>在资料库与资料分析服务方面，也因应生成式 AI 而全面提升向量储存与搜寻功能，新推出的 Amazon Neptune analytics 借由内建图形（Graph）演算法提升向量搜寻速度，几秒钟内可分析百亿个连结。多款资料库服务也增加向量储存与搜寻能力，Amazon OpenSearch Serverless vector engine 可以储存与搜寻向量资料，Amazon DocumentDB、Amazon DynamoDB、Amazon MemoryDB for Redis 也都可以储存与搜寻向量。此外，支援 Zero-ETL 的资料库服务也增多了，包括 Amazon Aurora PostgreSQL、Amazon DynamoDB 与 Amazon RDS for MySQL 皆可直接整合，不需额外透过 ETL，而 Amazon OpenSearch Service 亦可直接与 S3 整合。</p><p>自去年 11 月 30 日 ChatGPT 推出后，生成式 AI 顿时蔚为风潮，短短一年内就成为兵家必争之地。虽然 AWS 在这波生成式 AI 浪潮中没有抢到引领风潮的先机，但综观 Selipsky 宣布的多款生成式 AI 新服务，包括在生成式 AI 架构最底层的基础设施层，以 Nvidia 晶片与 AWS 自家晶片提供云端服务中最强大的生成式 AI 运算力；在中间层的工具层方面，以 Bedrock 为主力扩展对基础模型的支援；在最上层的应用层，祭出 Amazon Q 聊天机器人贯通企业应用场景，而且在每个环节都将资讯安全、隐私保护、负责任 AI 与合规考量进去，让企业不因上述顾虑而畏惧生成式 AI，再加上诸多强化资料整合、提升向量资料库能力等等，很明显地，AWS 将以其拥有众多云端企业用户的优势，透过持续再创新抢占仍是处女地的生成式 AI 企业商用市场。</p></div></div></div><div></div></div></div></div>]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.ithome.com.tw/news/160117</guid>
            <link>https://www.ithome.com.tw/news/160117</link>
            <author>
                <![CDATA[吴其勋]]>
            </author>
            <category>新闻</category>
        </item>
        <item>
            <title>
                <![CDATA[AWS 现在侦测到可用区域出现潜在故障时，可自动转移用户流量到其他区域]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/zonal_autoshift_-_automatically_shift_your_traffic_away_from_availab_-_aws.amazon.com_.png?itok=Q6Q1eePq" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>AWS 新推出<a href="https://aws.amazon.com/tw/blogs/aws/zonal-autoshift-automatically-shift-your-traffic-away-from-availability-zones-when-we-detect-potential-issues/">区域自动转移（Zonal Autoshift）功能</a>，这是 Amazon Route 53 应用程式恢复控制器的新功能，能够在侦测到可用区域（Availability Zone）可能出现问题的时候，自动且安全地将用户的应用程式工作负载流量，从可用区域转移出去，并在问题解决后再将流量转回原本区域。</p><p>在部署具韧性的应用程式时，AWS 用户通常会将资源部署于同一个地区的多个可用区域。而所谓的可用区域，是相距一定距离，确保具有不同的电力、连接性、网路设备甚至是洪泛区的不同实体资料中心群组。</p><p>在过去，用户需要手动管理不同可用区工作负载平衡，以确保应用程式的高可用性和韧性。用户在可用区域指标状态不良时，便能以手动或是程式化的方式触发区域转移，将流量从原本的可用区域移出，透过负载平衡器配置将所有连接导向到健康的可用区域，供用户在调查故障的原因时，仍然可以维持应用程式的可用性。</p><p>手动区域转移虽然可以用于防止例如部署失败、配置或是操作错误等，来自用户这端的应用程式错误，但官方提到，当可用区域存在潜在故障问题时，用户有时难以辨识或是侦测到故障，毕竟用户也不会追踪每一个可用区域的指标，当用户的服务需要跨区域边界呼叫相依项目，就可能造成所有可用区域的应用出现错误。</p><p>而用户现在可以透过在启用区域自动转移功能，来保护工作负载不受潜在可用区域故障的影响。AWS 会透过内部监控工具和指标，来决定网路流量转移的时机，当 AWS 侦测到特定区域可能出现电力或是网路中断等问题，系统会自动触发该基础设施的 NLB 或 ALB 流量自动转移，并在故障解决后将流量转回。</p><p class="rtecenter"><a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2023/10/22/2023-10-22_18-19-08-1.png"><img alt="" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2023/10/22/2023-10-22_18-19-08-1.png" style="width: 600px;" referrerpolicy="no-referrer"></a></p><p>这个过程有多重保障措施，确保不会降低应用程式的可用性，AWS 也有内部控制确保用户一次只会从一个可用区域转移流量。AWS 每周都会在基础设施上演练转移 30 分钟，演练结束根据应用程式运作状况，提供用户成功或是失败的结果。</p><p>用户可以定义不希望进行转移的时间段，同时还可以设定两个 Amazon CloudWatch 警报在执行期间充当断路器，一个是阻挡演练执行，另一个则是在演练执行期间监控应用程式运作状况，当其中一个警报触发，AWS 会立即停止演练，并恢复所有可用区流量。</p><p>用户在启用区域自动转移时，需要确保所有可用区域都要部署足够容量，以承受在特定可用区域故障时所产生的流量转移。不过，在所有可用区域部署额外容量会产生成本，用户需要在应用程式的可用性和成本之间权衡。目前，区域自动转移在中国和 GovCloud 之外的所有 AWS 地区中提供。</p></div></div></div><div></div></div></div></div>]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.ithome.com.tw/news/160109</guid>
            <link>https://www.ithome.com.tw/news/160109</link>
            <author>
                <![CDATA[李建兴]]>
            </author>
            <category>新闻</category>
        </item>
        <item>
            <title>
                <![CDATA[微软未来 3 年将斥资 25 亿英镑于英国打造 AI 基础设施]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1109-microsoft-ai-image-guan_fang_tu_-960.jpg?itok=bg2CCXPv" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>微软</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>微软周四（11/30）<a href="https://blogs.microsoft.com/on-the-issues/2023/11/30/uk-ai-skilling-security-datacenters-investment/" target="_blank">宣布</a>，未来 3 年将在英国斥资 25 亿英镑（32 亿美元）以扩大其新一代 AI 资料中心的基础设施，亦将投入数百万英镑来培育 100 万名当地的 AI 人才，<a href="https://www.gov.uk/government/news/boost-for-uk-ai-as-microsoft-unveils-25-billion-investment" target="_blank">英国政府则说</a>，这是英国 40 年来最大的一笔投资。</p><p>英国政府表示，英国已是欧洲领先的科技生态系统，去年的价值是德国的两倍，更是法国的 3 倍，而去年 AI 领域对英国的经济贡献为 37 亿英镑，提供了 5 万个工作职缺。</p><p>微软计划在英国增加一倍的资料中心足迹，未来 3 年将以 25 亿英镑的预算来建置 AI 资料中心基础设施，在 2026 年时把超过 2 万个最先进的 GPU 带到英国，亦将在英国训练 100 万名适用于 AI 经济的人才，以及与英国大学及政府合作来支持当地的 AI 安全与研究。</p><p>微软表示，此一基础设施的投资将有助于满足对 AI 特定运算能力的高效及可持续性的需求，且公私部门也都在等待著要利用最新的云端与 AI 创新。</p><p>除了基础设施之外，微软准备培育的 100 万名 AI 人才包括那些有意进入 AI 领域的，训练他们掌握及使用 AI 所需的技能，也会发展 AI 技术技能，支援 AI 业务转型，推动安全与负责任的 AI，以及提供第一张生成式 AI 专业证书等。</p></div></div></div><div></div></div></div></div>]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.ithome.com.tw/news/160111</guid>
            <link>https://www.ithome.com.tw/news/160111</link>
            <author>
                <![CDATA[陈晓莉]]>
            </author>
            <category>新闻</category>
        </item>
        <item>
            <title>
                <![CDATA[Google Messages 的 RCS 用户数突破 10 亿人]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1201-google-messages-rcs-960.jpg?itok=TUIvE-nD" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>Google</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>就在苹果<a href="https://www.ithome.com.tw/news/159885" target="_blank">宣布</a>将支援丰富通讯服务（Rich Communication Services，RCS）协定的两周后，<a href="https://blog.google/products/android/7-new-messages-features/" target="_blank">Google 本周指出</a>，已有超过 10 亿名使用者于 Google Messages 中启用了 RCS，为了庆祝 10 亿的里程碑，Google Messages 开始测试 7 种新的互动方式，包括照片表情符号 Photomoji、语音情绪、萤幕效果及客制化泡泡（Custom Bubbles）等。</p><p>Google Messages 原本称为 Android Messages，是 Android 生态体系的传讯程式，它同时支援传统的文字简讯（SMS）与 RCS，初期使用者必须主动启用 RCS，但今年起某些特定的 Android 装置预设便启用了 RCS。Google 被视为 RCS 协定的最大推手，不仅于 Android 生态中导入了 RCS，也开源了基于 RCS Universal Profile 规格的客户端供外界使用。</p><p>新版 Google Messages 的 7 项新功能之一是照片表情符号，它允许使用者把自己的照片直接变成表情符号来回应亲友的文字；语音情绪则是在传送语音讯息上添加表情符号；并将某些特定文字设定成萤幕效果的提示词，只要输入相关文字，例如「我爱你」或「下雪了」，对话窗就会自动跳出视觉效果；最有趣的可能是客制化泡泡了，这个原本由苹果 iMessage 用户专属的泡泡功能，现在则变成 Google Messages 的客制化服务之一。</p><p class="rtecenter"><img alt="" src="https://s4.itho.me/sites/default/files/images/1201-google-messages-RCS-600.png" style="width: 600px;" referrerpolicy="no-referrer"></p><p>在苹果的传讯程式中，倘若双方都使用苹果装置，即可透过 iMessage 传讯，那么讯息便是以蓝色泡泡显示，但若其中有一方非采用苹果装置，或未启用 iMessage，因而使用传统的简讯服务，那么讯息就会以绿色泡泡显示。而 Google Messages 的客制化泡泡则允许使用者任意变更泡泡颜色，直接打破苹果惯例。</p></div></div></div><div></div></div></div></div>]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.ithome.com.tw/news/160110</guid>
            <link>https://www.ithome.com.tw/news/160110</link>
            <author>
                <![CDATA[陈晓莉]]>
            </author>
            <category>新闻</category>
        </item>
        <item>
            <title>
                <![CDATA[【资安日报】12 月 1 日，美国宾州水利设施遭伊朗骇客攻击，CISA 呼吁管理者应修改设备预设密码、采用双因素验证，强化基本防护力]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/20231201.png?itok=CE0eYgvj" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>美国宾州阿里奎帕市水务局证实增压站遭到伊朗骇客入侵，因采用以色列厂牌工控设备而遭到锁定。骇客也宣称，他们正在对采用这类 OT 设备的水利设施发动攻击。</p><p>值得留意的是，在美国网路安全暨基础设施安全局（CISA）发布的资安公告当中，指出骇客可能是透过配置不当的情况发动攻击，而非透过漏洞入侵受害组织。</p><p>&nbsp;</p><h3><strong>【攻击与威胁】</strong></h3><p><a href="https://www.securityweek.com/cisa-warns-of-unitronics-plc-exploitation-following-water-utility-hack/"><strong style="font-size: 22px;"><span style="color: rgb(0, 0, 0);">美国宾州水利单位的工业控制系统传出遭到骇客劫持</span></strong></a></p>
                <!-- notionvc: 32d2cfaa-f0ec-42ed-a928-d7055f901d65 -->
                <p></p>
                <p>
                    <a href="https://s4.itho.me/sites/default/files/images/image-38.png">
                        <img alt="" src="https://s4.itho.me/sites/default/files/images/image-38.png" style="width: 300px; float: right;" referrerpolicy="no-referrer">
                        </a>上周末美国宾州阿里奎帕市水务局（Municipal Water Authority of Aliquippa，MWAA）遭骇，骇客控制了其中 1 个增压站，但并未影响供水。MWAA 董事会主席 Matthew Mottes 向当地媒体 KDKA-TV 透露，此起攻击是伊朗骇客组织 Cyber Av3ngers，原因很有可能是他们采用了以色列自动化控制业者 Unitronics 的系统，而成为该组织锁定的对象。
                    </p>
                    <p>Matthew Mottes 透露，遭骇的增压站位于郊区，用于监控、调节浣熊镇及波特镇的供水，事发后该系统已经停用，警方著手进行调查。对此，Cyber Av3ngers 声称，他们锁定数个以色列供水设施的 SCADA 系统，并声称所有以色列制造的设备都是攻击目标。</p>
                    <p>而在上述攻击事件发生后，美国网路安全暨基础设施安全局（CISA）针对 Unitronics 的可程式化逻辑控制器（PLC）提出警告，呼吁管理者应修改预设为 1111 的管理密码，并在远端存取 OT 系统时进行多因素验证，以及避免控制器直接曝露在网际网路。</p>
                    <p>资料来源</p>
                    <p>1.&nbsp;
                        <a href="https://www.cbsnews.com/pittsburgh/news/municipal-water-authority-of-aliquippa-hacked-iranian-backed-cyber-group/">https://www.cbsnews.com/pittsburgh/news/municipal-water-authority-of-aliquippa-hacked-iranian-backed-cyber-group/</a>
                        <br>
2.&nbsp;
                            <a href="https://www.cisa.gov/news-events/alerts/2023/11/28/exploitation-unitronics-plcs-used-water-and-wastewater-systems">https://www.cisa.gov/news-events/alerts/2023/11/28/exploitation-unitronics-plcs-used-water-and-wastewater-systems</a>
                        </p>
                        <p>
                            <a href="https://www.sentinelone.com/blog/dprk-crypto-theft-macos-rustbucket-droppers-pivot-to-deliver-kandykorn-payloads/">
                                <strong style="font-size: 22px;">
                                    <span style="color: rgb(0, 0, 0);">北韩骇客利用恶意程式载入工具 RustBucket 散布 Kandykorn</span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: 33069a65-ead6-42bb-be07-cda9d2dc287c -->
                        <p></p>
                        <p>资安业者 SentinelOne 揭露北韩骇客锁定 Mac 电脑最近一波的攻击行动，这些骇客先前曾使用恶意程式载入工具 RustBucket 散布第二阶段工具 SwiftLoader、利用后门程式 KandyKorn 对区块链工程师发动攻击，以及使用恶意程式 ObjCShellz 对投资人或求职者下手。</p>
                        <p>但研究人员进一步分析、比对发现，这些北韩骇客彼此有合作迹象，因为在最新一波行动中，攻击者交互搭配、运用上述各种恶意程式，增加活动的复杂度，例如，透过 RustBucket 散布不同版本的 SwiftLoader，但也散布 ObjCShellz，而 SwiftLoader 与 KandyKorn 采用的基础设施有关。</p>
                        <p>研究人员也根据 Elastic 资安研究团队公布的 KandyKorn 攻击行动进行追查，结果发现骇客融合上述恶意程式攻击手法，开始透过 RustBucket 于受害电脑投放 KandyKorn。</p>
                        <p>&nbsp;</p>
                        <h3>
                            <strong>【漏洞与修补】</strong>
                        </h3>
                        <p>
                            <a href="https://www.bleepingcomputer.com/news/apple/apple-fixes-two-new-ios-zero-days-in-emergency-updates/">
                                <strong style="font-size: 22px;">
                                    <span style="color: rgb(0, 0, 0);">苹果发布行动装置及 Mac 电脑更新，修补 2 个已被用于攻击行动的 WebKit 零时差漏洞</span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: fea8c17a-3d2e-4b6d-bd12-d22454d195d4 -->
                        <p></p>
                        <p>11 月 30 日苹果发布了 iOS 17.1.2、iPadOS 17.1.2、macOS Sonoma 14.1.2、电脑版 Safari 17.1.2，修补已出现攻击行动的排版引擎 WebKit 漏洞 CVE-2023-42916、CVE-2023-42917，有可能导致在处理网页内容的过程里，攻击者可泄露敏感资讯，或是执行任意程式码。</p>
                        <p>该公司指出，这些漏洞已被用于攻击 iOS 16.7.1 及之前版本的 iPhone 手机。</p>
                        <p>
                            <a href="https://www.zyxel.com/global/en/support/security-advisories/zyxel-security-advisory-for-authentication-bypass-and-command-injection-vulnerabilities-in-nas-products">
                                <strong style="font-size: 22px;">
                                    <span style="color: rgb(0, 0, 0);">兆勤公告旗下 NAS 设备重大漏洞，有可能被用于执行作业系统命令</span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: 4667a832-fa51-4eab-a971-0662c8022d3a -->
                        <p></p>
                        <p>11 月 30 日兆勤科技（Zyxel）发布资安公告，针对旗下储存设备 NAS326、NAS542 揭露 CVE-2023-35137、CVE-2023-35138、CVE-2023-37927、CVE-2023-37928、CVE-2023-4473、CVE-2023-4474，其中的 CVE-2023-35138、CVE-2023-4473、CVE-2023-4474 为重大层级。</p>
                        <p>而这些重大等级的漏洞，CVSS 风险评分皆达到 9.8。其中，CVE-2023-35138、CVE-2023-4473 为命令注入漏洞，前者发生在 show_zysync_server_contents 功能，未经授权的攻击者能发送伪造的 HTTP POST 请求，执行作业系统命令；另一个漏洞则是与网页伺服器元件有关，未经授权的攻击者能发送伪造的 URL，执行作业系统的命令。</p>
                        <p>至于 CVE-2023-4474，则是与 WSGI 伺服器元件有关，同样能让攻击者在尚未通过身分验证的情况下，透过伪造的 URL 执行作业系统命令。</p>
                        <p>
                            <a href="https://appomni.com/blog_post/claiming-zoom-rooms-service-accounts-to-gain-access-to-tenants/">
                                <strong style="font-size: 22px;">
                                    <span style="color: rgb(0, 0, 0);">视讯会议系统 Zoom 存在漏洞，有可能让攻击者挟持会议</span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: fca1ef55-d27f-4b67-8a73-832a523ea008 -->
                        <p></p>
                        <p>今年 6 月，资安业者 AppOmn 的研究人员在
                            <a href="https://blog.zoom.us/zoom-hackerone-h1-4420-event-2023/">HackerOne 举办的活动 H1-4420</a>上，找到视讯会议解决方案 Zoom Rooms 的漏洞，近期公布相关细节。研究人员指出，攻击者有机会借此控制 Zoom Rooms 的服务帐号，从而对目标组织进行未经授权存取。
                        </p>
                        <p>攻击者可在未受到邀请的情况下劫持会议、操纵联络人的名单、渗透白板，甚至从团队交谈内容取得敏感资料。值得留意的是，这些攻击行动可在使用者难以察觉的状态下进行。他们与 Zoom 进行协调后，上述漏洞得到验证及修复。</p>
                        <p>&nbsp;</p>
                        <h3>
                            <strong>【其他新闻】</strong>
                        </h3>
                        <p>
                            <a href="https://www.bleepingcomputer.com/news/security/staples-confirms-cyberattack-behind-service-outages-delivery-issues/">
                                <strong>
                                    <span style="font-size: 20px;">
                                        <span style="color: rgb(0, 0, 0);">办公用品零售商 Staples 传出营运出现异常，起因是遭遇网路攻击后关闭部分系统所致</span>
                                    </span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: 2d231570-90a8-4a18-af53-fb90e3f594f2 -->
                        <p></p>
                        <p>
                            <a href="https://www.bleepingcomputer.com/news/security/capital-health-hospitals-hit-by-cyberattack-causing-it-outages/">
                                <strong>
                                    <span style="font-size: 20px;">
                                        <span style="color: rgb(0, 0, 0);">医疗照护系统 Capital Health 遭遇网路攻击，造成旗下医院 IT 系统中断</span>
                                    </span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: e1c5f54d-ab30-4b53-bb55-997f464b29b9 -->
                        <p>
                            <a href="https://www.securityweek.com/hackers-hijack-industrial-control-system-at-us-water-utility/">
                                <strong>
                                    <span style="font-size: 20px;">
                                        <span style="color: rgb(0, 0, 0);"></span>
                                    </span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: 8894fab6-ed38-42fb-bbfd-0dccc83672d6 -->
                        <p></p>
                        <p>
                            <a href="https://www.bleepingcomputer.com/news/security/dollar-tree-hit-by-third-party-data-breach-impacting-2-million-people/">
                                <strong>
                                    <span style="font-size: 20px;">
                                        <span style="color: rgb(0, 0, 0);">连锁折扣商店 Dollar Tree 资料外泄，近 2 百万人受害，起因是外部供应商遭骇</span>
                                    </span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: aad336fd-7a46-4d92-bfd8-756d20597b03 -->
                        <p></p>
                        <p>
                            <a href="https://securityaffairs.com/154999/cyber-crime/rhysida-ransomware-king-edward-viis-hospital.html">
                                <strong>
                                    <span style="font-size: 20px;">
                                        <span style="color: rgb(0, 0, 0);">英国爱德华七世国王医院传出遭到勒索软体 Rhysida 攻击</span>
                                    </span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: 567c73cf-eae7-4479-a466-d612eacd7fdc -->
                        <p></p>
                        <p>
                            <a href="http://arcticwolf.com/resources/blog/qlik-sense-exploited-in-cactus-ransomware-campaign/">
                                <strong>
                                    <span style="font-size: 20px;">
                                        <span style="color: rgb(0, 0, 0);">资料分析系统 Qlik Sense 重大漏洞被用于攻击行动，骇客发动勒索软体 Cactus 攻击</span>
                                    </span>
                                </strong>
                            </a>
                        </p>
                        <!-- notionvc: a423d86c-6580-4f52-bbbe-e533e6677cee -->
                        <p></p>
                        <p>&nbsp;</p>
                        <h3>
                            <strong>近期资安日报</strong>
                        </h3>
                        <p>
                            <a href="https://www.ithome.com.tw/news/160086">
                                <strong>【11 月 30 日】&nbsp;针对 10 月资料外泄事故，身分验证管理业者 Okta 表示受害范围扩大，所有使用客户支援系统的用户皆受影响</strong>
                            </a>
                        </p>
                        <p>
                            <a href="https://www.ithome.com.tw/news/160069">
                                <strong>【11 月 29 日】&nbsp;上海商银惊传 1.4 万客户资料外泄，金管会公布调查结果列 4 大缺失，依银行法重罚千万，外泄管道仍有待厘清</strong>
                            </a>
                        </p>
                        <p>
                            <a href="https://www.ithome.com.tw/news/160051">
                                <strong>【11 月 28 日】&nbsp;美国医疗保健服务业者 Henry Schein 传出二度遭遇勒索软体 BlackCat 攻击，导致电子商务平台遭到瘫痪</strong>
                            </a>
                        </p>
                    </div>
                </div>
            </div>
            <div></div>
        </div>
    </div></div>]]>
</description>
<pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>
<guid isPermaLink="false">https://www.ithome.com.tw/news/160108</guid>
<link>https://www.ithome.com.tw/news/160108</link>
<author>
    <![CDATA[周峻佑]]>
</author>
<category>新闻</category>    </item>    <item>
<title>
    <![CDATA[苹果紧急修补两个已遭攻击的零时差漏洞]]>
</title>
<description>
    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0211-safari_vulner_sec-9601.jpg?itok=x0u1gPAP" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>苹果周四（11/30）紧急更新了<a href="https://support.apple.com/zh-tw/HT214033" target="_blank">Safari</a>、<a href="https://support.apple.com/zh-tw/HT214031" target="_blank">iOS、iPadOS</a>与<a href="https://support.apple.com/zh-tw/HT214032" target="_blank">macOS Sonoma</a>，只为了修补两个已遭到攻击的零时差漏洞，根据<a href="https://www.bleepingcomputer.com/news/apple/apple-fixes-two-new-ios-zero-days-in-emergency-updates/" target="_blank">《Bleeping Computer》</a>的统计，这使得苹果今年修补的零时差漏洞达到 20 个。</p><p>此次苹果修补的两个漏洞都藏匿在浏览器引擎 WebKit 中，其中的 CVE-2023-42916 为一越界读取漏洞，在处理网页内容时可能揭露机密资讯。而 CVE-2023-42917 则为记忆体毁损漏洞，处理网页内容时可能导致任意程式执行。</p><p>这两个漏洞都是由 Google 威胁分析小组（Threat Analysis Group，TAG）的安全研究人员 Clément Lecigne 所发现，而且可能已经遭到攻击。</p><p>受到波及的使用者可将软体升级到 Safari 17.1.2、iOS 17.1.2、iPadOS 17.1.2 及 macOS Sonoma 14.1.2。</p></div></div></div><div></div></div></div></div>]]>
</description>
<pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>
<guid isPermaLink="false">https://www.ithome.com.tw/news/160107</guid>
<link>https://www.ithome.com.tw/news/160107</link>
<author>
    <![CDATA[陈晓莉]]>
</author>
<category>新闻</category>    </item>    <item>
<title>
    <![CDATA[Fintech 周报第 223 期：澳洲银行公会宣布打造收款人确认系统，可让汇款方确认收款帐户的使用者名称；调查显示全球约 26% 金融机构已开始使用生成式 AI]]>
</title>
<description>
    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/scams.png?itok=x_NOI71v" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><h3 style="margin: 10px 0px; font-family: 微软正黑体, sans-serif; font-weight: bold; line-height: 1.25em; text-rendering: optimizelegibility; font-size: 24.5px; background-color: rgb(247, 247, 247);"><span style="font-size: 18px;"><span style="color: rgb(139, 69, 19);">2023/11/27~12/1 金融科技精选新闻</span></span></h3><h1 style="font-weight: bold; line-height: 1.25em; margin: 10px 0px; font-family: 微软正黑体, sans-serif; text-rendering: optimizelegibility; font-size: 38.5px; background-color: rgb(247, 247, 247);"><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;金融诈骗</span></strong></span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;</span></strong></span><span style="font-size: 18.6667px;">&nbsp;</span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;收款人确认系统&nbsp;</span></strong></span></h1><h3>澳洲银行公会将联合银行业打造收款人确认系统，可以比对收款人姓名和帐户名称是否匹配</h3><p>澳洲银行公会（ABA）近期宣布，为了打击诈骗，他们将联合银行业者投入 1 亿美元打造收款人确认系统，提供给国内所有银行使用，让汇款人在进行转帐交易时，可以查看收款人姓名和帐户名称是否匹配，确保汇款至正确的帐户。除了在转帐环节上防止诈骗，澳洲银行业者也将会在开户环节中，至少使用一个生物辨识，来确认开户者是真人，且符合其生物特征。</p><p>此外，ABA 也表示，有鉴于加密货币平台有时会成为非法诈取金钱的工具，这项系统将会限制或停止与高风险的加密货币平台间的转帐交易。这项开发计划将在 2024 年至 2025 年间开发和交付。</p><h1 style="font-weight: bold; line-height: 1.25em; margin: 10px 0px; font-family: 微软正黑体, sans-serif; text-rendering: optimizelegibility; font-size: 38.5px; background-color: rgb(247, 247, 247);"><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;金融趋势研究&nbsp;</span></strong></span><span style="font-size: 18.6667px;">&nbsp;</span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;生成式 AI&nbsp;</span></strong></span></h1><h3>英国金融软体供应商 Finastra 发布 2023 全球金融服务状况调查，约 26% 金融机构已开始使用生成式 AI</h3><p>《2023 全球金融服务状况调查》显示，银行即服务（Banking as a Service,BaaS）、嵌入式金融和 AI 在今年发展快速，全球已有 48% 金融机构提供 BaaS 服务，相较 2022 年增加约 13%，而嵌入式金融服务也有相似的增长幅度。</p><p>此外，调查也显示，全球约有 26% 金融机构已在某些场景使用生成式 AI，31% 金融机构正在研究、测试或实验生成式 AI。根据调查，最多金融机构考虑或使用生成式 AI 来搜集、处理或分析 ESG 相关数据，以进行投资和借贷决策。这份调查搜集来自美国、英国、德国、香港和新加坡等九个国家的金融机构中，956 位主管阶层的专业人士意见。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/%E8%9E%A2%E5%B9%95%E6%93%B7%E5%8F%96%E7%95%AB%E9%9D%A2%202023-11-30%20184349.png" style="width: 600px;" referrerpolicy="no-referrer"></p><blockquote><p>调查显示，金融机构票选前五个生成式 AI 使用案例依序为：搜集处理和分析 ESG 标准或决策的相关数据、自动化人工或重复度高的工作任务、提升 IT 开发效率、搜集处理和分析 KYC 和洗钱防制资料、促进任务管理和决策预测分析。</p></blockquote><h1 style="font-weight: bold; line-height: 1.25em; margin: 10px 0px; font-family: 微软正黑体, sans-serif; text-rendering: optimizelegibility; font-size: 38.5px; background-color: rgb(247, 247, 247);"><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;生成式 AI&nbsp;</span></strong></span><span style="font-size: 18.6667px;">&nbsp;</span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;顾客虚拟助理&nbsp;</span></strong></span></h1><h3>德国商业银行将整合微软 text to speech avatar 工具开发逼真的顾客虚拟助理</h3><p>微软近期才宣布 Azure AI Speech 新工具，能生成逼真的虚拟化身，便有银行宣布要导入这项工具，开发生成式 AI 虚拟助理。德国商业银行（Commerzbank）近期宣布将开发顾客虚拟助理，提供各种银行服务，除了使用 GPT 模型，也会整合 text to speech avatar 工具来制作逼真的虚拟化身。</p><p>德国商业银行将锁定银行 App 的 220 万用户数，首先会在行动装置上发展虚拟助理。目前这项计划仍在内部实验，已进行首次顾客测试。</p><h1 style="font-weight: bold; line-height: 1.25em; margin: 10px 0px; font-family: 微软正黑体, sans-serif; text-rendering: optimizelegibility; font-size: 38.5px; background-color: rgb(247, 247, 247);"><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;客户资料外泄</span></strong></span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;</span></strong></span><span style="font-size: 18.6667px;">&nbsp;</span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;上海商银&nbsp;</span></strong></span></h1><h3>上海商银 1.4 万客户资料外泄，金管会依银行法重罚 1 千万</h3><p>金管会近期在例行记者会上公布上海商银客户资料外泄情事，针对该缺失开罚 1 千万。金管会银行局长副局长童政彰表示，2022 年 9 月及今年 5 月至 7 月间，上海银陆续接获匿名民众反映其资安问题，而后续金管会查核显示，上海商银未完善建立及未确实执行内控制度，导致客户资料外泄，且未能保有相关轨迹，至今仍不清楚外泄来源。</p><p>金管会表示，上海商银的重大缺失有四大项，分别是未订定妥善个人电脑管理者权限规定，例如案发前并未明定每半年变更个人电脑管理者权限密码，且未订定可携式设备管控规范、未留存个人资料使用轨迹，和未测试出资安软体漏洞并确认其执行情形。</p><h1 style="margin: 10px 0px; font-family: 微软正黑体, sans-serif; font-weight: bold; line-height: 1.25em; text-rendering: optimizelegibility; font-size: 38.5px; background-color: rgb(247, 247, 247);"><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;金融监管</span></strong></span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;</span></strong></span><span style="font-size: 18.6667px;">&nbsp;</span><span style="font-size: 18.6667px; color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;英国 FCA&nbsp;</span></strong></span></h1><h3>英国金融行为监理总署 FCA 进一步研究大型科技公司与金融业间资料不对称问题</h3><p>去年十月，FCA 针对大型科技公司扩张或开展消金服务的潜在影响展开研究，并搜集业界意见。研究结果显示，许多回应提到大型科技公司具备相对的资料优势，因为他们可以从金融机构取得金融相关数据，但根据资料共享相关规定，金融机构无法取得大型科技公司拥有的数据。此外，部分金融机构也担心大型科技公司将获取的数据用来发展数据分析和 AI 技术，进而影响两个行业间在金融服务上的竞争性发展。</p><p>因此，FCA 近日公开征求大型科技公司与金融业间资料不对称的相关证据，以评估这项问题是否会影响金融服务市场竞争效益。</p><p style="margin: 0px 0px 1.5em; font-size: 14pt; line-height: 2em; font-family: 微软正黑体, sans-serif; background-color: rgb(247, 247, 247);">责任编辑／李昀璇</p><p style="margin: 0px 0px 1.5em; font-size: 14pt; line-height: 2em; font-family: 微软正黑体, sans-serif; background-color: rgb(247, 247, 247);"><span style="font-family: 微软正黑体, sans-serif; font-size: 18.6667px; background-color: rgb(247, 247, 247);">图片来源／澳洲银行公会、</span>Finastra</p><p style="margin: 0px 0px 1.5em; font-size: 14pt; line-height: 2em; font-family: 微软正黑体, sans-serif; background-color: rgb(247, 247, 247);">资料来源：iThome 整理，2023 年 12 月</p><p>
    <!-- notionvc: ef728762-3e2f-4b38-9cb6-d74356a67f9e -->
</p>    </div>    </div>    </div>    <div></div>    </div>    </div></div>]]>    </description>    <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/160106</guid>    <link>https://www.ithome.com.tw/news/160106</link>    <author>    <![CDATA[李昀璇]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[Amazon 预览图像生成模型、新增文字生成模型]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1201-amazon_titan_-960.jpg?itok=QZDIyu6_" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>AWS</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p><a href="https://aws.amazon.com/tw/blogs/aws/amazon-titan-image-generator-multimodal-embeddings-and-text-models-are-now-available-in-amazon-bedrock/" target="_blank">Amazon 周四在 re: Invent 大会上公布</a>AWS 生成式 AI 模型产品，包括第一个图像生成式模型 Titan Image Generator，以及文字生成模型 Amazon Titan Text Express 及 Titan Text Lite。</p><p>新公布的模型中，Titan Image Generator 为 Amazon 自行开发的 Titan 家族最新模型之一，使其得以赶上 OpenAI、Google、微软等竞争者，具备图片编辑及加入浮水印等功能。Titan Text Express 及 Titan Text Lite 则是 AI 模型平台 Bedrock 的新增文字模型。在 Bedrock 服务平台上，用户可以透过 Bedrock 控制枱直接存取使用，或是以自有资料再加以客制化训练。</p><p>Amazon Titan Image Generator 允许用户以英文自然语言输入提示视窗，以建立专业等级的图像，作为广告、电商平台，或是媒体与娱乐内容。Amazon 表示，这项服务是以高品质而多元化的资料训练而成，可生成精准、贴近真实、少扭曲，且属性多元的图片，并能理解包含多个物件的复杂提示。</p><p class="rtecenter"><img alt="" src="https://s4.itho.me/sites/default/files/images/1201-Amazon%20Titan%20Image%20Generator.png" style="text-align: center; width: 600px;" referrerpolicy="no-referrer"></p><p>Titan Image Generator 的图片编辑功能之一，是利用内建分割模型自动编辑图片。最新模型支援以图片遮罩进行修补（inpainting）及以扩展（outpainting）延伸或变更图片背景。使用者可设定图片大小、指明想要模型产生几种款式。用户也可利用其自有资料客制化模型，以生成和公司品牌指引一致的图片，或是透过微调令模型生成特定风格的图像。它也支援负责任 AI 原则，防止生成有害或恶意的图片。</p><p>此外，有鉴于这模型可被用于生成 Deepfake 影像，所有以 Titan 生成的图片都会加入看不见的浮水印，以利辨识 AI 生成的图片。不过 Amazon 并未说明技术资讯。<a href="https://www.theverge.com/2023/11/29/23980697/amazon-ai-image-model-watermark-copyright" target="_blank">《The Verge》</a>引述 AWS 主管指出，这浮水印不会破坏图片画质，也无法被裁切或压缩掉，但使用者需要连结到独立 API 以判别是否为 AI 生成。</p><p>AWS 还为 Bedrock 新增了 2 个 Titan 文字生成模型 Titan Text Express 及 Text Lite。Titan Text Express 为「价格和效能兼顾」的文字生成模型，提供最多 8000 token 输入，也可以微调。它支援的情境包含检索增加生成（retrieval-augmented generation）、开放式文本生成、脑力激荡、摘录重点、程式码及表格生成、文本改写、改述（paraphrasing）、关联思考（chain of thought）、撷取、问答及聊天等。</p><p class="rtecenter"><img alt="" src="https://s4.itho.me/sites/default/files/images/1201-Amazon%20Titan%20Text%20Express%20Demo.png" style="width: 600px;" referrerpolicy="no-referrer"></p><p>而 Text Lite 版则是为特定使用场景而设计，强调「具成本效益且可高度客制化」的 LLM。Lite 版最大输入为 4000 token，支援场景包括摘录重点及文案写作（copywriting）。</p><p>Titan Text Express 目前已正式推出英文版，并有 100 多个语言版本已以预览版上线，Titan Lite 则仅支援英文。</p><p>除了主打的图片生成模型外，AWS 昨日还推出 Titan 多模嵌入（Titan Multimodal Embedding）模型。此一模型可支援多模态提示输入，包括文字、图片或者两者同时输入。Titan 多模嵌入模型支援输入最高 128 token 及 25MB 图片，仅支援英文。</p><p>Titan 多模嵌入提供非同步批次 API，Amazon OpenSearch Service 的神经搜寻（Neural Search）很快也会加入连接器，以便加入 Titan 多模嵌入模型支援。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/160104</guid>    <link>https://www.ithome.com.tw/news/160104</link>    <author>    <![CDATA[林妍溱]]>    </author>    <category>AI</category>    </item>    <item>    <title>    <![CDATA[Evernote 将限制免费版只能储存 50 项笔记]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1201-evernote-960.jpg?itok=0slYMRIg" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>Evernote</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>云端记事本服务 Evernote 昨（30）日正式<a href="https://evernote.com/blog/evernote-free-note-limits" target="_blank">宣布新政策</a>，下周开始，免费帐号最多只能储存 50 项笔记及 1 个线上笔记本。</p><p>从 12 月 4 日起 Evernote 将实施新政策，一个 Evernote Free 帐号最多只能储存 50 项笔记及 1 本笔记本，适用于现有或新增用户。Evernote 指出，由于大部分用户笔记数量都在 50 项以下，因此用户多半不会受影响。</p><p>在 12 月 4 日以后，超过限额的免费帐号用户必须删除笔记，或是升级到付费版本才能继续新增笔记。但现有帐号下超出 50 项笔记的用户，Evernote 表示仍然可以持续读取、编辑、共享、汇出及删除现有笔记和笔记本。</p><p>Evernote 上周开始<a href="https://techcrunch.com/2023/11/29/its-official-evernote-will-restrict-free-users-to-50-notes/" target="_blank">通知</a>免费版用户升级，并强调付款订阅版提供笔记跨装置立即同步、直觉式 AI 功能如笔记清理及 AI 搜寻，以及更高的稳定性、安全性与运作效能。</p><p>Evernote 近年因营收不佳，功能更新减缓，也缩小营运。这家曾经是独角兽的线上记事本平台，去年宣布卖给了义大利行动软体开发商 Bending Spoons，<a href="https://www.ithome.com.tw/news/157696" target="_blank">7 月宣布</a>公司营运迁往欧洲，也裁减大部分美国及南美员工。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/160103</guid>    <link>https://www.ithome.com.tw/news/160103</link>    <author>    <![CDATA[林妍溱]]>    </author>    <category>Cloud </category>    </item>    <item>    <title>    <![CDATA[【企业 LLM 实战：台湾大哥大】全体动员尝试 LLM，2 大流程让客服 AI 回答更准也更丰富]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1158-feng_mian_-tai_wan_da_-960.jpg?itok=4l2p6Nu2" width="960" height="420" alt="" title="台湾大资讯长蔡祈岩认为，要长远发展台湾 AI 国力，还有更多需努力之处。如足够绿电支援 AI 运算、更多技术研发补助、更多软体研发人才等。" referrerpolicy="no-referrer"></div></div></div><p class="caption"> 台湾大资讯长蔡祈岩认为，要长远发展台湾 AI 国力，还有更多需努力之处。如足够绿电支援 AI 运算、更多技术研发补助、更多软体研发人才等。 </p></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>今年 5 月，台湾大哥大悄悄揭露了运用大型语言模型（LLM）优化自家智能客服小麦的成果。他们并非采用常见的微调 LLM 优化方法，而是以嵌入式模型（Embedding model）搭配客服知识库，来让小麦回答更准确、更有人味。后来，他们还将自己的成功经验打包成产品，要提供给有 LLM 应用需求的企业。</p><p>为何不直接建置资料集、微调 LLM，让模型成为客服大脑？台湾大资讯长蔡祈岩认为：「现阶段嵌入式模型就够用了。」为什么？</p><p><strong style="color: rgb(51, 153, 255); font-size: 28px;">聚焦客服应用，寻找 LLM 最佳用法</strong></p><p>    <!-- notionvc: 32fc04f5-a09d-45fd-9886-a4f82d48f62e -->    </p>    <p>去年底 ChatGPT 问世，各产业争相拥抱 LLM，要来强化自家服务、提高竞争力，台湾大也不例外。「这段时间，我们尝试过许多大大小小的应用」，蔡祈岩指出，台湾大不只有一个团队在摸索，而是「各部门全员动员」，来尝试各种应用案例，特别是客服场景。</p>    <p>他们尝试了多种模型，如台智云的福尔摩沙大模型、微软的 AOAI 服务，以及 Meta 开源的 Llama 2，要来优化小麦。一开始，他们采取自建资料集、微调 LLM 的方法，来打造客服大脑，要让客服引擎更聪明、给出正确答案。于是，他们收集了客服知识点、客服文字对话、公司新闻、脸书与 LinkedIn 等资料，作为微调 LLM 的语料库。</p>    <p>接著，他们开始清理资料，去除 HTML 标签和个资等资讯。也因为每种资料清洗方式不同，难以用少数程式逻辑来处理全部资料，特别是人名，因此需要人工介入。他们将原本投入的 1 至 2 名人力，增加为 4 至 6 人。</p>    <p>资料集整理完后，团队开始用来微调模型。但由于资料集中 99.8% 的资料来自新闻语料，因此模型产出的回答偏向新闻用语，而且准确度还有进步空间，比如正确回答应为 100 点数，模型却给出 200 点数的答案。</p>    <p>经过那次测试，团队发现，LLM 不适合直接用作客服大脑，还需要其他配套方法补强。于是，团队改变策略，将目标调整为提高回答正确性，改采嵌入式模型搭配客服知识点资料库，来产出答案给顾客。而 LLM 则转为幕后辅助角色，用来新添客服知识点内容，而非直接用来处理业务问题。</p>    <p>    <strong style="font-size: 28px; color: rgb(51, 153, 255);">前后台分工，分别负责准确回答和丰富知识库</strong>    </p>    <p>进一步来说，这个作法分为前台和后台两套流程，前台流程的目标是要提高客服回答准确性。因此，当顾客向小麦问问题时，提问会经过嵌入式模型，将文字转换为向量空间，来与客服知识点中的例句计算信度，找出最符合的资料。若信度大于等于 90% 的门槛值，就可将这个知识点的资讯回传给小麦，提供新参考答案给顾客。若信度不足而无回传值，小麦则套用制式答案来回复。</p>    <p>要是信度小于门槛值，就会启动知识点后台接手处理。后台流程的目的是丰富知识库内容，因此，系统会将信度小于门槛值的内容，包含顾客提问和前几名回答，组成新的提示，由 LLM 根据新提示产出答案，并将这个新答案回馈给知识点维护人员，来更新知识点内容。</p>    <p>这么做可节省客服人员维运知识点平台的时间，而且，知识点的回复内容，也会因此循环越来越完整。这正是蔡祈岩认为，目前嵌入式模型即可解决客服业务问题的原因。</p>    <p>    <!-- notionvc: e357b5ef-b681-4cf6-b797-6ad065e015e6 -->    </p>    <p>    <span style="color:#3399ff;">    <span style="font-size:28px;">    <strong>AI 2.0 进展快速，不适合砸重金发展 LLM</strong>    </span>    </span>    </p>    <p>另一方面，随著 OpenAI 掀起 AI 2.0 超级大脑的浪潮，蔡祈岩观察，AI 2.0 进展迅速，台湾大暂不投入大量成本来发展 LLM。他指出，台湾大在 AI 2.0 已找到许多可立即看到成效的低垂果实，自行发展并非优先选择。再来，LLM 是个众神必争领域，企业自行投入的成本效益几乎没有能见度。比如，OpenAI 日前提出 GPTs，允许使用者根据自身需求，客制化专属的 ChatGPT，这就掀翻了许多 AI 企业的桌子。台湾大集团凭借多样的应用场域和 IT 人才，只要紧盯技术趋势，就能灵活找出高效益、低风险的发展机会。</p>    <p>「比起耗费大成本重新训练基础模型，GPTs 或中小模型等分支说不定就能实现 8、9 成水准，效益更高。」他认为，这种机制在垂直产业，特别有发展机会。</p>    <p>    <strong style="font-size: 28px; color: rgb(51, 153, 255);">发展 AI 国力，可强化人才发展环境</strong>    </p>    <p>生成式 AI 不只是企业标配，还成为各国秀 AI 国力的亮点。台湾已有国科会的 TAIDE 计划，来打造台版 LLM，但蔡祈岩认为，要长远发展台湾 AI 国力，还有更多需努力之处。</p>    <p>比如，台湾要加速发展再生能源，来支援 AI 算力所需的绿电，政府也能提供更多企业和新创的技术研发补助计划，来鼓励研发，激发更多 AI 软体创新。</p>    <p>此外，蔡祈岩点出，高等研发人才，特别是软体人才，更是发展重点。尤其，主流国家疯抢 AI 人才，台湾政府应提出赋税优惠来留住本地高阶技术人才，加上良好的生活环境，如医疗资源、便利性和包容的文化，来吸引国际人才。「因为，台湾的国际竞争策略一向是高 CP 值，非常成功，我们不宜孤注一掷在红海，想用世界最高薪资来抢人才。」他认为，台湾反而更适合吸引全球非电脑科学学科毕业、具高潜力的 AI 生手或 IT 素人，来台培养专业技能、转职为软体人才，同时在训练过程中，培养对台湾社会和文化的认同，进而成为台湾专属的软体人才。</p>    <p>    <a href="https://www.ithome.com.tw/article/160096" target="_blank">    <span style="color: rgb(255, 255, 255);">    <span style="font-size: 18px;">    <strong>    <span style="background-color: rgb(51, 153, 255);">&nbsp;相关报导&nbsp;</span>    </strong>    </span>    </span>    <span style="font-size: 18px;">    <strong>    <img alt="" src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/1158-feng_mian_p1_open-ruo_pu_-960x420_0.jpg?itok=1ZND9vlp" style="width: 550px;" referrerpolicy="no-referrer">    </strong>    </span>    </a>    </p>    </div>    </div>    </div>    <div></div>    </div>    </div></div>]]>    </description>    <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/160095</guid>    <link>https://www.ithome.com.tw/news/160095</link>    <author>    <![CDATA[王若朴]]>    </author>    <category>AI</category>    </item>    <item>    <title>    <![CDATA[【本土 LLM 成果：台智云福尔摩沙大模型】靠 3 种平行化技术提高训练效率，加速繁中 LLM 产品化]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/tai_zhi_yun_zong_jing_li_wu_han_zhang_-2-tu_pian_lai_yuan_-tai_zhi_yun_-960.jpg?itok=Hyofz8A3" width="960" height="420" alt="" title="台智云在今年 5 月发表了福尔摩沙大模型，以可商用的开源模型 BLOOM 为基础，经连续预训练、全参数微调和人类回馈强化学习（RLHF）等三阶段优化而成。（图片来源／台智云）" referrerpolicy="no-referrer"></div></div></div><p class="caption"> 台智云在今年 5 月发表了福尔摩沙大模型，以可商用的开源模型 BLOOM 为基础，经连续预训练、全参数微调和人类回馈强化学习（RLHF）等三阶段优化而成。（图片来源／台智云） </p></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>以打造台湾杉 2 号超级电脑起家的华硕子公司台智云，在今年 5 月和 9 月先后揭露多款繁中语料优化的大型语言模型（LLM），不只有懂台湾文化的福尔摩沙系列模型（FFM），还有一系列企业级模型开发工具和无程式码平台，来供企业使用。</p><p>这是除了国科会可信任人工智慧对话引擎（TAIDE）外，另一个具本地知识和用语的 LLM 选择。</p><p><strong style="font-size: 28px; color: rgb(51, 153, 255);">以繁中资料优化 2 种开源 LLM</strong></p><p>台智云总经理吴汉章指出，5 月揭露的福尔摩沙大模型，是以可商用的开源模型 BLOOM 为基础，经连续预训练、全参数微调和人类回馈强化学习（RLHF）等三阶段优化而成。</p><p>他们用来训练模型的资料量高达 1.5TB，其中包含繁中在内的 46 种人类语言、13 种程式语言等无版权资料，共 2 千亿个 Token。他们也针对微调，建置专用的问答组，来强化模型执行特定任务的能力。</p><p>经过 3 个月开发，福尔摩沙模型共有 2 个版本，也就是 1,760 亿参数版本和 70 亿参数版本。台智云技术长陈忠诚指出，福尔摩沙模型具备多语言、写程式和推理能力，在语言部分，不只繁体中文表现优异，可准确回答不少 ChatGPT 难以答对的问题，还特别加强东南亚语系的语言能力，为未来南向发展做准备。</p><p>今年 9 月，台智云更进一步揭露新模型 FFM-Llama 2，包含 70 亿、130 亿和 700 亿参数等 3 种版本。这款模型以 Meta 开源的 Llama 2 为基础，用繁中资料优化而成。与原 Llama 2 相比，不只能用繁体中文回答问题，而非如 Llama 2 会以英文回答中文问题，还能在写程式时，在程式码中保留所需的中文。</p><p>不只如此，台智云以这些模型为核心，进一步推出企业级大语言模型服务 AFS，可细分为 AFS Cloud 和 AFS Appliance 两款产品。前者是云端托管服务，提供完整训练过的模型，来让企业以 API 呼叫使用，而后者则是地端部署方案，企业可下载大型模型到本地端环境部署，来执行 LLM 应用。在 AFS 的预训练模型库中，除了有福尔摩沙大模型和 FFM-Llama 2 模型，还有 BLOOMZ、Llama 2、Code Llama 等开源模型。</p><p><strong style="font-size: 28px; color: rgb(51, 153, 255);">平行化运算是训练 LLM 关键</strong></p><p>打造企业级 LLM 服务并不容易，台智云如何能这么快推出产品？关键是算力的准备。</p><p>训练和微调 LLM 需要大量算力，特别是千亿参数的庞大模型 BLOOM，更需要一套有效的运算方法。早在 2022 年下半年，台智云就开始研究训练 LLM 所需的平行运算技术；他们的初始目标是，在台湾杉 2 号上，实际用 3 种平行化方法来训练 BLOOM。</p><p>这 3 种平行化方法，包括将模型水平切割的工作流程平行化（Pipeline Parallelism）</p>    <!-- notionvc: ac2bb625-a352-4a19-b453-cb6f681a805b -->    <p>、将模型垂直切割的张量平行化（Tensor Parallelism）</p>    <!-- notionvc: cff8f0aa-e06f-45ab-b0e8-0e3e12e96db0 -->    <p>，以及使用前述两种平行化后，再将训练资料分割给不同 GPU 群运算的资料平行化（Data Parallelism）</p>    <!-- notionvc: afc12f4f-c3bb-40e1-a9ea-929aaa022dab -->    <p>。</p>    <p>为实作这 3 种平行化，他们首先修改模型训练程式码，来让模型训练时，可执行相对应的平行化，比如能使用不同的 GPU 资源。接著，他们解决一系列挑战，比如找到最佳切割组合、让每张 GPU 都能发挥最佳效能，以及分割时，解决 GPU 记忆体不够用的问题。</p>    <p>陈忠诚还点出，LLM 训练需要好几个月，团队不只要实现同时调度大量 GPU，比如训练福尔摩沙大模型，最高调度 840 片 GPU 来进行平行化运算，还要注意硬体故障问题，以防止训练流程中断。因此，台智云设计一套机制，能在硬体故障问题修复后，自动开始 LLM 训练流程。最终，他们成功在台湾杉 2 号上，最高调度 840 片 GPU、同时进行平行化运算来训练 BLOOM。这个成功经验，也用于 FFM-Llama 2 的训练上。</p>    <p>不只是算力，台智云还有不同方法，来解决 LLM 训练问题。比如，为确保训练资料品质，他们还自建一套自动辨识工具，来筛选训练资料，比如判断是否夹杂不预期的语言，是否含不适当内容以及低品质的资料等。</p>    <p>同时，为避免模型发生灾难性遗忘，忘记先前学习过的知识，台智云也特别分配训练资料集，比如每一批平均涵盖不同领域的资料、新旧混合等，来让模型均衡学习。这些方法综合起来，就打造出具备繁中知识、表现良好的福尔摩沙大模型和 FFM-Llama 2。</p>    <p>    <!-- notionvc: edf6bd1c-a7cf-4a8b-a10b-bfb9a3508d34 -->    </p>    <p>台智云也将训练 LLM 累积的平行化经验，发展成容易自助操作的 LLM 训练服务。吴汉章表示，他们将平行化技术打包成无程式码平台，使用者点击滑鼠，选择各种想要微调的模型需求和条件，比如用 1,200 万字在 1 小时内完成 Llama 2 模型微调的组合条件，系统会自动根据这些条件，来调度相应 GPU 支援，自动进行平行化的模型训练任务，来降低企业训练 LLM 的门槛。他也揭露台智云下一步，不只要添加更多模型到 AFS，还要往亚洲市场进一步推广算力服务。</p>    <p>    <a href="https://www.ithome.com.tw/article/160096" target="_blank">    <span style="color: rgb(255, 255, 255);">    <span style="font-size: 18px;">    <strong>    <span style="background-color: rgb(51, 153, 255);">&nbsp;相关报导&nbsp;</span>    </strong>    </span>    </span>    <span style="font-size: 18px;">    <strong>    <img alt="" src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/1158-feng_mian_p1_open-ruo_pu_-960x420_0.jpg?itok=1ZND9vlp" style="width: 550px;" referrerpolicy="no-referrer">    </strong>    </span>    </a>    </p>    </div>    </div>    </div>    <div></div>    </div>    </div></div>]]>    </description>    <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/160093</guid>    <link>https://www.ithome.com.tw/news/160093</link>    <author>    <![CDATA[王若朴]]>    </author>    <category>AI</category>    </item>    <item>    <title>    <![CDATA[【本土 LLM：国科会 TAIDE】打造台版 LLM 供企业和公部门免费使用，还要开源繁中资料集]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/feng_mian_-guo_ke_hui_-960-2.jpg?itok=UQhQGXHx" width="960" height="420" alt="" title="国科会 TAIDE 计划负责人李育杰指出，这次计划不仅提供公部门和企业签约免费使用 TAIDE 模型，还会陆续释出高品质的繁中训练资料集，来推动台湾 LLM 发展。" referrerpolicy="no-referrer"></div></div></div><p class="caption"> 国科会 TAIDE 计划负责人李育杰指出，这次计划不仅提供公部门和企业签约免费使用 TAIDE 模型，还会陆续释出高品质的繁中训练资料集，来推动台湾 LLM 发展。 </p></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>「台湾也要有自己的 ChatGPT！」这是国科会主委吴政忠在今年 2 月新春记者会上揭露的重磅消息。</p><p>现在，10 个月过去了，国科会打造的台版 ChatGPT 不只有 70 亿参数模型的初步成果，也开始进入公部门应用讨论阶段，更预计明年初释出 130 亿参数版本供企业和公部门免费使用，并展开 700 亿参数的模型训练。这套模型名为可信任 AI 对话引擎（简称 TAIDE），以繁体中文资料训练而成，主打以台湾文化为基底，具备台湾特有用语、价值观和文化知识，能回答在地使用者问题。</p><p>国科会 TAIDE 团队，如何发展台版大型语言模型（LLM）？</p><p>    <!-- notionvc: 43aa7fef-30f7-471e-9e87-186f9fba9e36 -->    </p>    <p>    <span style="color:#3399ff;">    <span style="font-size:28px;">    <strong>3 阶段打造本土化基础模型</strong>    </span>    </span>    </p>    <p>他们采成本高、步骤最完整的方法来打造 TAIDE。有别于从无到有自行开发一套模型，团队以开源 LLM 为基础，利用自行建置的繁中语料，来对 LLM 进行连续预训练（Continual pretraining）、微调和人类回馈强化学习（RLHF）等 3 阶段优化，完成品即是 TAIDE 模型。</p>    <p>第一阶段的连续预训练，是要用大量繁中资料，来让模型学习基础知识。更贴切的形容是，让模型学会文字接龙，比如「台」后有 70% 机率接「湾」、10% 机率接「北」、4% 机率接「中」、还有 10% 是其他字等，让模型「从训练资料中，了解字与字之间的条件机率分布」，李育杰说。</p>    <p>为尽可能建置足够量的训练资料集，TAIDE 团队收集了新闻、政府公开资讯和研究资讯、繁中维基百科和学术论文等 10 种资料，制作成繁中语料集，来训练模型。由于这阶段使用的资料量最多，通常是模型参数量的 20 倍，例如 70 亿参数，需要多达 140 亿个训练 Token。因此最耗费运算资源，训练时间最长，若无建构良好的高速平行运算环境，可能耗费数月之久，难以符合现实要求。</p>    <p>    <!-- notionvc: bf598dff-2588-48b3-91e3-ebd9c9db5097 -->    </p>    <p>再来是微调（Fine-tune）阶段，也就是用问答组资料，来让模型学习特定任务，比如翻译。微调作法又可细分为 2 种，一是全参数微调，较耗费运算资源，但模型学习成效较好。另一种是参数高效能微调（PEFT），也就是采用 LoRA、P-Tuning 等常见压缩技术，只对模型部分参数微调，以较省运算资源的方式，来试图达到全参数微调的效果。</p>    <p>在这个阶段，TAIDE 团队收集了 42 万笔资料，包括 ChatGPT 问答组、繁中翻译的 rm-static 资料集、新闻摘要等，采较吃力的全参数微调方式，来让模型学习特定任务。最后一阶段是 RLHF，也就是以人工标注模型回答，再以这个回馈来改善模型，如用语更符合台湾文化和知识。这期间，TAIDE 团队也找来专攻自然语言处理的师生团队协作开发。</p>    <p>李育杰指出，经这 3 阶段训练的 TAIDE，可作为基础模型，来让公家机关或企业，以少量资料微调模型即可应用，不必从头进行预训练。使用者也可搭配自家资料库，以检索强化方式（RAG），来限制模型回答范围、降低幻觉，给出更精准的答案。</p>    <p>    <strong style="font-size: 28px; color: rgb(51, 153, 255);">改以 Llama 2 为基础打造台湾自有 LLM</strong>    </p>    <p>今年 4 月 28 日，TAIDE 计划正式展开，团队首先尝试不同的开源模型，如 BLOOM、第一代 LLaMA 等。他们发现，LLaMA 中文表现最好，因此以它为基础，来进行一系列的预训练、微调和 RLHF。</p>    <p>由于 LLaMA 只开放学术研究授权，TAIDE 团队打算先优化 LLaMA 来供学术研究使用，日后再寻找其他商用授权的 LLM，来发展台湾企业可用的基础模型。今年 6 月时，他们展示了 TAIDE 第一阶段成果，也就是以繁中资料优化的 LLaMA 70 亿参数版本，已能执行自动摘要、翻译、写信、写文章等 4 大任务，且用语符合台湾文化，表现也比未优化的 LLaMA-7b、科大讯飞-7b 和 Bloom-3b-zh 等模型要好。</p>    <p>7 月下旬，Meta 释出 Llama 2，不只开放学术研究和商用授权，表现还比第一代好。于是，国科会团队改以 Llama 2 为基础，原本打算分别进行学术研究和商用的模型训练，现在可以同步发展，省下许多功夫。</p>    <p>    <!-- notionvc: cede768e-5895-4c95-af03-ac855f979e13 -->    </p>    <p>他们从 Llama 2 70 亿参数版本开始进行预训练、微调和 RLHF 工作，打造为 TAIDE 7B 模型。接著也对 130 亿参数的 Llama-2-13b-chat 模型进行 3 阶段优化，包括以 30 亿个 Token 的繁中资料进行连续预训练、以 42 万笔资料进行微调和 RLHF 工作，打造出 Taide-Llama-2-13b-Chat 模型。</p>    <p>他们以 17 种任务来测试模型能力，如问答、写作、摘要、翻译、写程式等，再以 GPT-4 比较 TAIDE 模型与其他模型的回答，并打分数。结果，Taide-LLaMA2-13B-Chat 大胜第一阶段展示的 TAIDE 模型，表现良好，但这个版本的模型尚未上架，还需更多资料进一步优化，才能正式开放使用。</p>    <p>    <span style="color:#3399ff;">    <span style="font-size:28px;">    <strong>10 月进入公部门讨论，预计明年初上架 13B 模型</strong>    </span>    </span>    </p>    <p>打造台版 LLM 很重要，但更重要的是如何落地。</p>    <p>为此，国科会 TAIDE 团队设置使用者帐号、建立使用平台，并在 10 月和 11 月，陆续举办中央和地方公部门的应用工作坊，先让公部门尝鲜 TAIDE 7B 功能、发想可行专案，来加速落地。同时，「我们也开放业界申请，企业签订 MOU 就能免费使用 TAIDE 模型，省下从头开始做的成本。」李育杰指出，这正是国科会构想 TAIDE 计划时的重要考量，政府出资建造模型，不只弥补国外 LLM 方案可能的不足，还要带来产业效益，供企业自行使用或优化服务。</p>    <p>随著国网中心在 10 月购入 72 片 H100 GPU、完成装机，接下来团队将用这个算力，来优化 130 亿参数的 TAIDE 模型，让它具备多轮对话能力，更能记住使用者先前的对话，让任务执行更有连贯性。</p>    <p>他们预计明年初释出 TAIDE 130 亿参数版本，同时展开 700 亿参数版本模型训练，预计明年 4 月完工。不过，由于 TAIDE 计划将于明年 4 月 28 日到期，「我们正在想办法长期维运，让 TAIDE 继续营运下去」，李育杰说。</p>    <p>    <strong style="color: rgb(51, 153, 255); font-size: 28px;">繁中语料不足和授权是挑战</strong>    </p>    <p>在发展 TAIDE 的过程中，还有一大挑战要解决。</p>    <p>「我们的训练资料目前还不够！」李育杰坦言，撇除无版权的网路公开资料，团队得使用新闻和出版物等资料，才够打造完整的训练资料集。也因此，TAIDE 团队正向新闻媒体、出版社等机构，一一取得授权，来制作训练模型的繁中语料。但谈授权需要时间和经费，目前尚未有明确的时程表。</p>    <p>为打造 LLM 而取得资料授权，是必须的吗？「我请教过创立 CC 授权机制的哈佛大学教授 Lawrence Lessig，他表示，将资料用于连续预训练，属于合理使用范围，不需取得授权。」李育杰说明，预训练目的是要模型学会字与字之间的机率分布，理应不会发生抄袭问题。</p>    <p>但他与团队还是想取得授权，不只为了制作 TAIDE 训练资料集，还有一个更大的愿景。</p>    <p>    <strong style="font-size: 28px; color: rgb(51, 153, 255);">开源繁中资料集来提高国际参与机会</strong>    </p>    <p>这个愿景，就是开源这些高品质的繁中训练资料集。</p>    <p>「TAIDE 计划走到现在，更让我体认到，台湾需要庞大且高品质的繁中语料库！」李育杰深知，繁中资料集稀缺，难以带动本地 LLM 技术发展，但「有系统地收整资料、发展国家性的繁体中文语料库，不只对 TAIDE 模型训练有帮助，对未来的 LLM 研发，甚至是整体 AI 发展，都会有很大的影响。」</p>    <p>而且，有了这些资料集，台湾也更有机会参与国际 AI 研究。他举例，如 OpenAI、Google、Meta 等科技巨头打造新一代 LLM 时，就能使用台湾开源的繁中语料。</p>    <p>目前，TAIDE 计划已陆续释出一些资料集，如字典、法规资料库、中央社中文新闻等，未来还会释出更多资料集。「想建置完善的资料集，并非单凭 TAIDE 计划就能完全扛下」，李育杰坦言，建置繁中资料集犹如打造公共财，需要如数位典藏的国家性计划和经费来推动。但 TAIDE 计划是个起点，透过计划抛砖引玉、让更多人知道建置资料集的重要性，是推动台湾 AI 进展的重要一步。</p>    <p>    <a href="https://www.ithome.com.tw/article/160096" target="_blank">    <span style="color: rgb(255, 255, 255);">    <span style="font-size: 18px;">    <strong>    <span style="background-color: rgb(51, 153, 255);">&nbsp;相关报导&nbsp;</span>    </strong>    </span>    </span>    <span style="font-size: 18px;">    <strong>    <img alt="" src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/1158-feng_mian_p1_open-ruo_pu_-960x420_0.jpg?itok=1ZND9vlp" style="width: 550px;" referrerpolicy="no-referrer">    </strong>    </span>    </a>    </p>    </div>    </div>    </div>    <div></div>    </div>    </div></div>]]>    </description>    <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/160092</guid>    <link>https://www.ithome.com.tw/news/160092</link>    <author>    <![CDATA[王若朴]]>    </author>    <category>AI</category>    </item>    <item>    <title>    <![CDATA[【LLM 关键基础建设：算力】因应大模型训练需求，国网中心算力明年大扩充]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/feng_mian_-guo_ke_hui_-960.jpg?itok=fu9S5jYh" width="960" height="420" alt="" title="采用 V100 GPU 的台湾杉 2 号，运算效能可达 9 PFLOPS。因应国科会 TAIDE 计划，今年 10 月扩充了 72 片 H100 GPU，预估效能可增加 4.8 PFLOPS。明年国网中心计划再扩充 16 PFLOPS，来因应 70B 参数量 LLM 模型的预训练。（图片来源／国网中心）" referrerpolicy="no-referrer"></div></div></div><p class="caption"> 采用 V100 GPU 的台湾杉 2 号，运算效能可达 9 PFLOPS。因应国科会 TAIDE 计划，今年 10 月扩充了 72 片 H100 GPU，预估效能可增加 4.8 PFLOPS。明年国网中心计划再扩充 16 PFLOPS，来因应 70B 参数量 LLM 模型的预训练。（图片来源／国网中心） </p></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>即便不是从无到有、开发一套大型语言模型（LLM），以开源 LLM 为基础，用数百亿 Token 语料进行预训练、微调和人类回馈强化学习（RLHF）所优化出的繁中基础模型，也是极耗成本。光 130 亿参数模型，就得花上几个月才能完成预训练。</p><p>算力，是影响训练成败的一大关键。台湾现有算力，足够发展自己的 LLM 吗？</p><p><span style="color:#3399ff;"><span style="font-size:28px;"><strong>盘点台湾现有超级电脑算力</strong></span></span></p><p>台湾目前的主要算力资源，集中于国家高速网路与计算中心 3 台超级电脑，包括台湾杉 1、2、3 号，总效能约 20 PFLOPS。其中，台湾杉 1 号和 3 号以 CPU 为主，专为工程运算、大型模拟等任务设计，台湾杉 2 号则采 V100 GPU，专为 AI 模型开发和推论而设计，运算效能可达 9 PFLOPS。台湾杉 2 号虽有 2,016 片 GPU，但是分开使用，半数由国网中心管理，供公部门和学研界使用，另一部分则由建置台湾杉 2 号的台智云营运，来处理业界需求。</p><p>这样的算力，能否满足繁中 LLM 发展需求？国网中心主任张朝亮指出，以 Meta 开源模型 Llama 2 为例，它有 70 亿参数（7B）、130 亿参数（13B）和 700 亿参数（70B）版本，在标准条件下，进行 7B、13B 模型预训练和全参数微调，台湾杉 2 号都能应付。</p><p>所谓的标准条件是指，搭配预训练的资料量为模型参数的 20 倍，亦即国网中心台湾杉 2 号，不论是对 7B 模型进行预训练（搭配 1,400 亿个 Token 训练资料）还是对 13B 模型预训练（搭配 2,400 亿个 Token 资料量）的需求，都可以胜任。就算资料量多一些，台湾杉 2 号也能处理，只是所需时间长了点。</p><p>「但若是 70B 参数的模型预训练，国网中心算力可能就不太够了。」张朝亮解释，这是因为，Meta 从无到有训练 Llama 2 时，需要上千甚至上万片 A100 GPU，所需时间大约为 6 个月，而台湾杉 2 号采用相对低阶的 V100 GPU，效能约为 1：3。若以台湾杉 2 号进行 70B 模型预训练，可能得花上 9 个月至 1 年。再者，台湾杉 2 号还得支援其他 AI 专案，无法全力发展单一 LLM 专案。</p><p>如何提供够用的算力，正是国网中心协助国科会打造 TAIDE 模型时，所面临的挑战。</p><p><span style="color:#3399ff;"><span style="font-size:28px;"><strong>助国科会打造台湾自有 LLM，平行运算是关键</strong></span></span></p><p>回到今年上半年，国科会 TAIDE 计划在 4 月 28 日正式展开，国网中心也随即提供台湾杉 2 号算力，来协助发展台版 LLM。当时，国科会团队采用 Meta 释出的第一代 LLaMA 模型，以自行收集的繁中资料集，来预训练和微调 LLaMA 7B 版本。</p><p>后来，7 月 19 日，Meta 释出第二代模型 Llama 2，表现不只比第一代好，还开放研究和商用授权。于是，国科会团队跟进，改以 Llama 2 为基础，用繁中资料集对 7B 和 13B 版本模型进行预训练、微调和 RLHF。目前，国科会已提供繁中优化的 7B 版本 TAIDE 模型，供企业和公部门签约使用，预计明年初提供 13B 版本模型，同时展开 70B 参数模型的优化工作。</p><p>国科会 TAIDE 模型能一步步顺利上架，一大关键是高效能运算，尤其是平行化运算。张朝亮是该领域专家，他专攻流体力学和高效能平行计算，不只在美国 NASA 从事研究工作 34 年，回台接任国网中心主任后，也亲自参与 TAIDE 模型的平行运算和性能调校工作。</p><p>他点出，平行运算并非新发明，在高效能运算领域中已发展数十年，是项成熟技术。他自己从事科学工程运算时，就时常运用，只是在 AI 运算领域，作法稍有不同。「平行运算的原理很简单」，张朝亮说明，好比一台电脑执行一项任务，需要 10 天才能完成，若同时使用 10 台电脑，一天就能完成。以此类推，一台超级电脑可想像为成千上万台电脑组成，执行复杂的运算任务时，可透过切分任务，来让多台电脑分摊、同时执行。</p><p><strong style="color: rgb(51, 153, 255); font-size: 28px;">资料平行化和张量平行化是常见做法</strong></p>    <!-- notionvc: d3bb5584-2585-430a-9492-27f95098f5c8 -->    <p>其中一种常见且简单的平行运算方法，是从资料量下手的资料平行化。意思是，假设 AI 模型参数量不大，单片 GPU 就能执行训练，一台主机因有 8 片 GPU，就可训练模型 8 次。这时，开发者可将训练资料分割，将每批不同的训练资料，分别交给各个 GPU，同时进行运算，让模型不断修正参数。</p>    <p>当模型大到无法用单一 GPU 执行训练时，就需要另一种平行化方法来因应。因为模型参数量越大，就需要越多 GPU 支援，可能是一台主机，或数十、数百台或上千台主机。在这种情形下，每台主机只负责一部分的模型训练，而训练资料的分配和传输，就变得十分复杂，也会使模型训练过程变得冗长。</p>    <p>此时，就需要 NVLink 和讯息传输介面（MPI），来提高主机内和跨主机的资料交换效率。张朝亮指出，传统科学运算时常使用 MPI，使用者得针对每一项平行化和资料传输一一写程式，但在 AI 领域，有不少现成工具可加速，比如深度学习框架 PyTorch 提供平行运算工具，将 MPI 和 GPU 平行化所需的 NVLink 等分段工作打包好，能根据需求拆解 MPI 和 NVLink 任务、自动执行，相较于科学运算，简单许多。这就是张量平行化方法。国网中心也在国科会 TAIDE 计划初期，建置了平行化工具，来让开发团队进行性能调校。</p>    <p>    <strong style="font-size: 28px; color: rgb(51, 153, 255);">分阶段提升 AI 算力，还要引进量子电脑</strong>    </p>    <p>不只是平行化运算加持，这次 TAIDE 计划，还进一步提高了台湾杉 2 号算力。今年 10 月，他们购置了 9 台主机、共 72 片 H100 GPU，是台湾杉 2 号原搭载的 V100 GPU 第三代，预估效能可达 4.8 PFLOPS。</p>    <p>国网中心也以 4.8 PFLOPS 为基准，预计明年再增加 16 PFLOPS 算力。这些算力升级，也能用来解决，原本台湾杉 2 号不好应付的 70B 模型预训练问题。至于国网中心的整体算力提升目标，则是要在 5 年内达到 200 至 300 PFLOPS。</p>    <p>这次的 LLM 训练经验，也影响了张朝亮对下一代 AI 超级电脑的建置想法。他计划分年建置，透过每年购入新机器，来避免基础设施过时。虽然这么做，难以让超级电脑难在世界排名中名列前茅。</p>    <p>他也期望，下一代 AI 超级电脑不只要具备中大型 LLM 训练的能力，还要能支援不同类型的生成式 AI 发展，比如生化模拟、蛋白质合成，甚至是多模态分析，比如整合影像与文字分析，来发展下一代 AI 生医软体等。</p>    <p>不只如此，「我们目前规画引进量子电脑。」张朝亮点出，采用量子电脑是世界趋势，他在刚落幕的 2023 超级电脑大会中，就见到非常多量子电脑公司和新创，「台湾一定要及早切入这个领域，否则会落后。」</p>    <p>而国网中心的规画方向有 2 个，一是观察量子位元数量发展，以量子位元数多的量子电脑为优先选择，二是依照世界主流作法，将量子电脑与超级电脑整合，透过超级电脑将资料转换为适合量子运算的形式，交由量子电脑计算，再将计算结果交给超级电脑，转换为人类可读的资料。</p>    <p>国网中心将另外建置超级电脑来与量子电脑沟通，目前规画中的 AI 超级电脑，也将拨出一部分来执行这个转换工作。此外，国网中心也打算引进可模拟量子电脑的工具 cuQuantum，来提高量子电脑模拟在 GPU 的运算效率。</p>    <p>    <span style="color:#3399ff;">    <span style="font-size:28px;">    <strong>鼓励企业、新创运用超算资源做大题目</strong>    </span>    </span>    </p>    <p>「AI 和算力，是接下来几年非常重要的国家发展指标。」张朝亮认为，台湾不只要发展高速运算的基础建设，还要鼓励企业和学研界挑战「大题目」。他观察，过去几年，台湾研究风气保守，「我们鼓励大家发表论文，但并没有鼓励大家提出解决大问题的机制。」他认为，ChatGPT 之所以存在，是因为有勇于挑战大题目的文化 DNA。</p>    <p>「我希望未来几年，能够改变这样的想法。」为鼓励专家挑战大题目、勇于使用大算力解决大问题，张朝亮分享个人观点，政府在编排研究补助专案时，也许可直接命题，提出如 TAIDE 这类需要超级电脑运算的大计划，来编排经费、鼓励专家投入研究。</p>    <p>不只要改变文化，张朝亮还点出，国网中心正拟定计划，要来鼓励中小企业、新创产业使用超级电脑。也就是说，在下一代 AI 超级电脑发展的几年，国网中心要推动专案，针对出众的提案，提供「非常优惠的价格，甚至免费，来让提案企业和新创使用上百 PFLOPS 效能的超级电脑」，他说。</p>    <p>    <!-- notionvc: a82b0bf6-d8d0-41d3-8e9c-24daf0a9391c -->    </p>    <p>    <a href="https://www.ithome.com.tw/article/160096" target="_blank">    <span style="color: rgb(255, 255, 255);">    <span style="font-size: 18px;">    <strong>    <span style="background-color: rgb(51, 153, 255);">&nbsp;相关报导&nbsp;</span>    </strong>    </span>    </span>    <span style="font-size: 18px;">    <strong>    <img alt="" src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/1158-feng_mian_p1_open-ruo_pu_-960x420_0.jpg?itok=1ZND9vlp" style="width: 550px;" referrerpolicy="no-referrer">    </strong>    </span>    </a>    </p>    </div>    </div>    </div>    <div></div>    </div>    </div></div>]]>    </description>    <pubDate>Thu, 30 Nov 2023 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/160091</guid>    <link>https://www.ithome.com.tw/news/160091</link>    <author>    <![CDATA[王若朴]]>    </author>    <category>AI</category>    </item>    </channel>    </rss>
