<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[iThome]]>
        </title>
        <link>https://www.ithome.com.tw/news/feeds</link>
        <atom:link href="https://rsshub.app/ithome/tw/feeds/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[iThome Online 是台湾第一个网路原生报，提供 IT 产业即时新闻、企业 IT 产品报导与测试、技术专题、IT 应用报导、IT 书讯，以及面向丰富的名家专栏。 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 22 Feb 2024 22:45:19 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[每天执行 1.6 亿任务的高盛证券资料库，如何建立可观察性]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/secdb960-tu_pian_lai_yuan_-gao_sheng_.png?itok=wbueEM7j" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>高盛是全球超大型投资集团之一， 他们有一套用来分析庞大证券交易风险和估价的关键平台 SecDB，来协助高盛集团旗下的交易员，评估什么时候买哪一些股票的风险有多大。这个平台，正是让高盛证券交易员们一年获利数十亿美元的关键系统。</p><p>SecDB 平台已经用了 30 年，每天要执行 1.6 亿个任务，目前负责维护这套系统的开发人力超过了 3 千人。这套系统还设计了自己专属的程式语言 Slang，多年来累计超过了 2 亿行 Slang 的程式码。目前全球有 1 万 3 千名使用者，不只是交易员，还有许多分析人员。这套系统一但出现问题，甚至发生短暂当机，不只会影响了高盛的证券交易的风险评估，甚至连高盛银行的业务都会有影响。这是高盛全集团的关键系统之一。</p><p><strong>SecDB 串接全球上万资料库，可支援 25 亿个连线数</strong></p><p>为了支援各种不同的使用情境，SecDB 平台也发展出了许多原生应用，串接了 1 万多个分散在全球的物件资料库，所能支援的连线数超过 25 亿个连线，每秒接收的流入资料频宽多达 164TB， 对外流出的资料频宽，更是达到每秒 8PB 的海量资料。可以说，SecDB 和伴随的相关应用，组合成了一个庞大的分析生态圈，而 SecDB 平台就是其中的关键核心。</p><p>如何强化一个发展了 30 年的庞大老旧系统，是非常困难的挑战，尤其近几年，这套系统韧性面对的局势，每一年都在改变，可能来自各式各样的新兴网路威胁，新兴金融使用情境，新兴技术的汰换和进化，这些变化再再考验了 SecDB 系统的韧性。为了更彻底掌握 SecDB 系统的运作情况，3 年前，高盛开始打造这套关键系统的可观察性能力。</p><p>原本的 SecDB 平台为了提供高速分析能力，采用了记忆体式键值（Key-value）资料库，并采取了丛集架构的设计，由一个保持最终一致性的复写丛集群组，高盛称其为 Ring AP，把资料写入到这个丛集群组中的任何一个资料库节点成员，来建立高度分散式的效能。</p><p>在这个群组中的资料库节点，例如有纽约 SecDB 资料库，伦敦 SecDB，香港 SecDB 资料库，彼此之间还会透过一支同步程式 SecSync，可以自动更新和移除彼此不一致的地方来确保，资料库的最终一致性。</p><p><strong>旧有时间序列资料分析工具，不擅长即时维运分析</strong></p><p>数十年来，SecDB 资料库团队也打造过好几种监控机制，最近主要使用的监控矩阵 SecDB Metrics，是以时间序列资料库来搜集各种事件后，进行例行检查，也能用来，来诊断各式各样的已知问题。例如资料库组态可用记忆体限制、连线限制数的问题等。而资料库管理人员也常用一款时间序列资料分析工具 PlotTool，运用各种数值分析，来了解这些时间序列资料的维运效能 。</p><p>例如高盛资料库管理人员曾用 PlotTool 来绘制出资料库所用记忆体的变化趋势，原有标准配置的记忆体配置上限是 60GB，但从分析趋势可以看到资料库的记忆体用量需求越来越大，就可以在特定时间后，将上限值拉高到 70GB。用这样的绘图工具来看记忆体用量的长期变化趋势，可，以更视觉化地观察维运作法上需要调整之处。</p><p>高盛用了多年的时间序列资料库和 PlotTool 都是好用的维运工具，虽然有用，但是还是有所不足，因为这些适合用来观察长期趋势，而不是即时性的系统监控机制。尤其，就有监测矩阵所用的时间序列资料库，适合用来储存即时的金融资料和分析这些金融资料，但是，不擅长用于即时维运系统讯号的处理。</p><p>3 年前，高盛开始另外用批次处理程式，来产生各种分析报表，若有异常或需要注意的讯号，也只能透过电子邮件通知相关人员来处理，时效性比较不足。</p><p>可是，这几年来，SecDB 平台串接的资料库越来越多，产生的电子邮件通知数量和各种维护问题越来越多，高盛发现，他们需要一个平台，可以立即注意到关键事件出现。</p><p><strong>采用开源事件监控平台 Prometheus 打造可观察性架构</strong></p><p>高盛 SecDB 平台团队和 SRE 团队讨论后，决定使用开源事件监控平台 Prometheus，用这个 Prometheus 自己的数据查询语言 PromQL 来开发监控机制，并改用 Prometheus 的通报管理功能 Alertmanager 来发送异常通报。</p><p>为了避免影响到原有的资料库，高盛打造了一只探测程式，并在 SecDB 所在的每一台主机上，会放了一个 Daemon 程序，可以和外部的探测程式沟通，将搜集这台主机上的运作状态 Log 数据，这只探测程式还会将各种事件和 Log 资料，整理成 Prometheus 格式的资料，再汇入到 SRE 团队管理的 Prometheus 主机上，最后，资料库团队可以在 Prometheus 所有 SecDB 平台的状态仪表板。</p><p>在这个 SecDB 仪表板上，可以看过过去 6 个小时内，每一分钟，每一台 SecDC 主机的数据变化，例如每一分钟使用了多少记忆体，资料库读取的利用率有多高等等。 透过这些搜集主机状态的观察手段，可以建立整个 Ring AP 丛集群组中，每一台主机、每一个资料库的监测仪表板。</p><p>高盛使用了 PromQL 规则来定义各种事件的触发条件，来判断不同事件需要驱动哪一种等级的维运高风险通报。多数不紧急的事件只需要发出后续追踪处理的通知，但是对于关键事件，则会触发一个特别的通报机制称为 PagerDuty，直接发布通报给待命工程师。</p><p><strong>尽可能避免影响原有平台，采用指标伺服器从旁搜集遥测资料</strong></p><p>高盛 SecDB 团队打造可观察性功能时，有一个大前提是，尽可能避免影响到 SecDB 平台的系统来搜集需要的 SecDB 平台 Log 资料。所以，他们后来的作法，不是在 SecDB 平台系统中增加监测机制，而是改在每一个 SecDB 所部署的主机上，用 Daemon 程序来安装一个指标伺服器（Metrics Server），用来可以提供这台主机的即时资料库遥测，一但主机发生任何状况发生，都可以立即看到。这个指标伺服器，跟主机上的 SecDB 平台资料库，共用同样的记忆体，位在同样的环境中，也就可以用来代表 SecDB 所在主机的状态。这个即时监测手段，让高盛的资料库团队能够用新的角度来思考他们的基础架构。</p><p>不过，这个指标伺服器，因为高并发运作和锁定问题，无法使用现成的 Prometheus 函式库，后来，高盛干脆自己开发了新版的指标伺服器元件。新版指标伺服器不只可以搜集主机数据，还可以搜集到资料库内部的遥测数据，包括资料库透过内部工作流程进行交易的状态资讯，这就大大提供了过去看不到的透明度。多达二、三十种资料库的运作行为，像是新增一笔纪录，删除纪录，开始交易，交易资讯取得等行为，都可以即时看到状态资讯的变化。</p><p><strong>新版指标伺服器不只可以搜集到 SecDB 所在主机的遥测数据，连资料库内部运作行为的数据也能搜集</strong></p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/SecDB-%E5%9C%96%E7%89%87%E4%BE%86%E6%BA%90-%E9%AB%98%E7%9B%9B.png" referrerpolicy="no-referrer"></p><p>因为这套 DecDB 在全球各地都有节点，如纽约 SecDB 资料库节点、伦敦节点、香港节点等，后来，高盛将这套监控架构发展成了全球多区域的架构，每个区域各有一套自己的 Prometheus，遥测资料先集中到各地 SecDB 的 Prometheus 后，再把资料汇入到 SRE 团队的 Prometheus 上来提供整合性仪表板。高盛 SRE 团队也会提供了 SecDB 的 SLO 达成情况，方便资料库团队追踪每一天的维运状态。&nbsp;</p><p>因为 SecDB 是全球运作，而且是 24 小时都不能停，而且得支援全球不同时区的需求。每个区域会有 6 个待命工程师，每周轮流接手，来和全球的待命团队（SRE）成员合作。为了各区域值班待命工程师的工作衔接，也让他们有能力处理更多示警通报的管理，高盛还打造了一个 SOS 系统，纪录每一起事件的处理情况，方便不同区域之间的工作交接。</p><p><strong>高盛打造了一个 SOS 系统，来纪录每一起事件的处理清况，方便全球不同时区团队的工作交接。</strong></p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/SOS%E7%B3%BB%E7%B5%B1-%E5%9C%96%E7%89%87%E4%BE%86%E6%BA%90-%E9%AB%98%E7%9B%9B.png" referrerpolicy="no-referrer"></p><p>2023 年，高盛完成了 SecDB 平台的可观察性架构之后，开始将这个机制延伸到其他 SecDB 平台的各种相关应用，预计在 2024 年涵盖到所有相关应用，都要纳入同一套可观察性架构下。</p><p>&nbsp;</p></div></div></div><div></div></div></div></div>]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 16:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.ithome.com.tw/news/161428</guid>
            <link>https://www.ithome.com.tw/news/161428</link>
            <author>
                <![CDATA[王宏仁]]>
            </author>
            <category>新闻</category>
        </item>
        <item>
            <title>
                <![CDATA[AI 趋势周报第 244 期：Hugging Face 开源最大合成资料集 Cosmopedia]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/screen_shot_2024-02-23_at_12.40.57_am.png?itok=K_DJTN6P" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>Hugging Face</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p><span style="color: rgb(0, 0, 255);">重点新闻 (0216～0222)</span></p><p><span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp;Hugging Face &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; 合成资料 &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; Cosmopedia &nbsp;</span></strong></span></p><p><span style="font-size: 22px;"><strong>Hugging Face 开源最大的合成资料集 Cosmopedia</strong></span></p><p>Hugging Face 最近发布资料集 Cosmopedia v0.1，是目前最大的合成资料集，内容全由 Mixtral 7b 指令模型生成，包含 3,000 多万个档案。这些内容有教科书文字、部落格文章、故事和 WikiHow 文章等类型，共 250 亿个 Token。</p><p>团队表示，他们希望以生成合成资料的方式，来涵盖 RefinedWeb 和 RedPajama 等资料集中的世界知识。Cosmopedia 资料集除了有各种类型文章，还显示基本资讯供使用者参考，如提示、合成内容、初始资料来源、标记长度、文字格式（如教科书、部落格文章）和目标受众等。同时，团队也提供较小的子资料集 Cosmopedia-100k，来供使用者轻松管理和使用。Hugging Face 表示，这次释出的资料集仅 0.1 版本，他们还有很大的进步空间，盼纳入更多主题，来推进合成资料的研究与应用。<a href="https://huggingface.co/datasets/HuggingFaceTB/cosmopedia/viewer/auto_math_text/train?p=1">（详全文）</a></p><p><img alt="" src="https://capture.dropbox.com/t5hGWSR35ATXtSpz" referrerpolicy="no-referrer"><img alt="" src="https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/V7MGV2OrCfLO5TxKPUXs4.png" referrerpolicy="no-referrer"></p><p><span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; Groq&nbsp;&nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; LPU&nbsp;&nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; LLM&nbsp;&nbsp;</span></strong></span></p><p><span style="font-size: 22px;"><strong>突破 GPU 瓶颈！Groq 用 LPU 推论引擎提供最快 LLM 服务</strong></span></p><p>2016 年成立的科技公司 Groq，这几天成为全球 AI 社群最关注的话题，因为它的执行速度飞快，更有不少人将 Groq 与 ChatGPT 作比较，发现 ChatGPT 花了 60 秒生成答案，Groq 只花 12 秒。</p><p>不过，Groq 主要开发的并非聊天机器人或模型，而是语言处理单元（LPU）推论引擎。目前主流的 AI 系统多半在 GPU 上执行，但 LPU 的设计，能克服 LLM 在 GPU 运算密度与记忆体频宽上的两大瓶颈。Intuition Machine 共同创办人<a href="https://twitter.com/IntuitMachine/status/1759941976927924682">Carlos Perez</a>说明，Groq 用编译器技术来最佳化极简而高效能的架构，避开了复杂性，有别于主流做法。他表示，Groq 架构的核心是个单纯支援平行吞吐量的裸机，如同一个专为机器学习设计的 ASIC，还能用客制化的编译器来支援不同模型。</p><p>目前，Groq 支援标准机器学习框架如 PyTorch、TensorFlow 和 ONNX 等，但仅用于推论，LPU 推论引擎并不支援机器学习训练。Groq 欢迎硬体供应商、软体供应商、云端服务供应商或 AI 加值服务开发商寻求合作，也提供 Groq API 与 Groq Compiler 来执行 LLM 应用。<a href="https://wow.groq.com/why-groq/">（详全文）</a></p><p><span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; LoRA </span></strong></span>&nbsp;<span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; 微调 &nbsp; </span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; LLM &nbsp;</span></strong></span></p><p><span style="font-size:22px;"><strong>LoRA Land 服务来了，集结 25 个微调模型效能可胜 GPT-4</strong></span></p><p>大型语言模型服务公司 Predibase 推出 LoRA Land 服务，提供 25 个微调的大型语言模型。这些模型都以 Mistral-7b 开源模型为基础，由 Predibase 对不同任务最佳化，表现不只比原始基础模型好，甚至也比 GPT-4 好。Predibase 指出，由于 Transformer 预训练模型越来越大，很难在资源有限的条件下，适用于下游任务。于是，Predibase 用参数高效能微调（PEFT）和量化低阶适应（QLoRA）的压缩技术，来减少微调参数数量与记忆体使用量，同时尽可能兼顾模型效能。</p><p>接著，他们将这些最佳实践整合至平台中，实现每个微调模型的 GPU 成本降低至 8 美元以下，而且透过 Predibase 所开发的大型语言模型开源平台 LoRAX，使用者可在单一 GPU 上执行和部署数百个经最佳化的大型语言模型，还能使用无伺服器微调终端，亦即不需专用 GPU 资源，也能执行模型。这么做的好处是，可以大幅降低成本，而且，Predibase 提供可扩展基础设施，可依据用户的需求扩展微调模型数量，用户需要用到 GPU 时，也不需要等待 GPU 冷启动，能更快测试和迭代模型。<a href="https://predibase.com/blog/lora-land-fine-tuned-open-source-llms-that-outperform-gpt-4">（详全文）</a></p><p><img alt="" src="https://images.ctfassets.net/ft0odixqevnv/YeKN68pQ2371BzaoPo2PN/db8a4963d1833e97e9ec10ca092e9daf/Predibase_Fine-Tuned_Mistral-7b_vs._GPT-4_27.4.png?w=2390&amp;h=1556&amp;q=100&amp;fm=webp&amp;bg=transparent" referrerpolicy="no-referrer"></p><p><span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; Gemma &nbsp;</span></strong></span>&nbsp;<span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; Google &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; Gemini &nbsp;</span></strong></span></p><p><span style="font-size:22px;"><strong>Google 开源 AI 模型 Gemma，可在笔电上执行</strong></span></p><p>继日前揭露大型语言模型（LLM）Gemini 1.5 版后，Google 最近又发布开源模型 Gemma 两个版本，让开发者在云端、资料中心甚至笔电上就能自建和执行 AI 模型。进一步来说，Gemma 是轻量开源模型，由 Google DeepMind 和 Google 其他团队开发。据 Google 测试，不论在推论、数学、撰写程式上，Gemma 7B 都超越 Llama 2 7B，而在多项测试上，也超越开源模型 Mistral 7B。</p><p>此外，Gemma 可整合 Kaggle、Colab notebook 等常见工具，以及 Hugging Face、MaxText、Nvidia MeMo 和 TensorRT-LLM 等。为吸引开发者使用 Gemma，Google 还提供 Kaggle notebook、Colab 免费方案，以及 300 美元的 Google Cloud 点数。同时，为让外部使用者进行负责任 AI 评估，Google 最近也发布负责任生成式 AI 工具包，包括能以简单范例建立安全分类器的工具、模型除错及负责任模型开发与部署指引。<a href="https://blog.google/technology/developers/gemma-open-models/">（详全文）</a></p><p><img alt="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Benchmark_chart_new.width-1000.format-webp.webp" referrerpolicy="no-referrer"></p><p><span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; BigQuery &nbsp;</span></strong></span>&nbsp;<span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; RAG &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; 向量搜寻 &nbsp;</span></strong></span></p><p><span style="font-size:22px;"><strong>BigQuery 推出向量搜寻功能，还支援 RAG</strong></span></p><p>BigQuery 开始提供向量搜寻功能了，使用者能在 BigQuery 中进行向量相似性搜寻，还能使用检索强化生成（RAG）。通常，向量搜寻也称为近似最邻近（ANN）搜寻，能在高维空间中快速找到与特定向量最相近的向量。BigQuery 的向量搜寻功能能让使用者对储存于 BigQuery 的高维资料集，进行快速且准确的搜寻，可支援新资料处理和 AI 应用在内的多种用法，如使用大型语言模型进行语义搜寻，或病历、交通事故、图像等相似性搜寻，还能结合 RAG 来强化生成式 AI 工作。</p><p>BigQuery 的向量搜寻功能提供了一种简单且直觉的语法，类似 BigQuery 现有的文字搜寻功能，进而简化向量搜寻与 SQL 原语组合。此外，专门处理自然语言处理工作流程的 LangChain 框架，也能与 BigQuery 向量搜寻功能搭配使用，强化自然语言处理，让 Python 开发者更轻松整合，并与其他第三方框架一起使用。<a href="https://cloud.google.com/blog/products/data-analytics/introducing-new-vector-search-capabilities-in-bigquery">（详全文）</a></p><p><span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; LOMO &nbsp;</span></strong></span>&nbsp;<span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; LLM &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; 记忆体 &nbsp;</span></strong></span></p><p><span style="font-size:22px;"><strong>复旦大学开源优化器 LOMO，大幅降低 LLM 训练的记忆体资源</strong></span></p><p>最近，上海复旦大学开源一款大型语言模型（LLM）优化器 LOMO，能降低训练 LLM 的记忆体用量，微调所有参数。进一步来说，训练 LLM 需要大量 GPU 资源，因此降低 LLMs 训练的门槛，一直是 AI 社群的努力方向。目前的主流方法是参数高效微调（PEFT），即只微调模型部分参数，来降低训练成本。</p><p>而复旦大学团队决定从另个角度解决问题，即使用有限资源来对 LLM 的全部参数微调。他们开发一套低记忆体优化器（LOMO），融合了梯度计算和参数更新，来降低记忆体使用量。</p><p>经团队测试，联合使用 LOMO 和现有的记忆体节省技术，与 DeepSpeed 标准方法相比，能将记忆体使用量降低为 10.8％。他们点出，这个做法能在单一配备 8 个 RTX 3090 的电脑上，每个显存为 24GB 的情况下，对 650 亿参数（即 65B）模型的全部参数进行微调。<a href="https://github.com/OpenLMLab/LOMO/blob/main/README.md">（详全文）</a></p><p><img alt="" src="https://github.com/OpenLMLab/LOMO/raw/main/assets/LOMO.png" referrerpolicy="no-referrer"></p><p><span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; AI &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; 监管 &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; 诈骗 &nbsp;</span></strong></span></p><p><span style="font-size: 22px;"><strong>美国 FTC 提案强化 AI 监管，加强打诈</strong></span></p><p>美国政府最近针对 AI 科技带来的负面影响采取一系列行动，比如美国联邦通讯委员会先是裁定 AI 生成的语音即人工语音，需符合自动语音电话的规范，现在则是美国联邦交易委员会（FTC）提出行政法规修订，加强打击用 AI 冒充商业和政府机构的诈骗犯罪。</p><p>FTC 先就冒充个人提出补充公告（Supplemental Notice）来征询公众意见，讨论重点包括提供创建图像、影片和文字服务的 AI 平台，在知道其所提供的商品被用于冒充并诈骗消费者时，这些公司是否应视为违法。第二种 FTC 要打击的是伪造政府、商业电子邮件和网址，比如创建介面与真实官方网站相似，但网域名称在拼写上错误的假网站。第三种则是虚假暗示自身与政府或商业关联，诈骗犯使用让人误以为他们代表政府机构或商业实体的语言或术语等行为。FTC 将拥有更多权力，来追诉和阻止这些诈骗行为。<a href="https://www.ftc.gov/news-events/news/press-releases/2024/02/ftc-proposes-new-protections-combat-ai-impersonation-individuals">（详全文）</a></p><p><span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; PDF &nbsp;</span></strong></span>&nbsp;<span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; Adobe &nbsp;</span></strong></span>&nbsp;<span style="color: rgb(255, 255, 255);"><strong><span style="background-color: rgb(51, 153, 255);">&nbsp; AI 助理 &nbsp;</span></strong></span></p><p><span style="font-size:22px;"><strong>Adobe PDF 软体加入 AI 助理</strong></span></p><p>Adobe PDF 读取与编辑软体 Reader、Acrobat 最近加入 AI 助理功能，使用者可更容易读取、理解和分享 PDF 文件或简报。Adobe 最近也对这个 AI 助理展开公测。这个 AI 助理整合了 Reader 和 Acrobat 的工作流程，可为使用者产生长篇文件的重点摘要、提供洞察并回答用户提问。AI 助理能自动整理出重点，还能草拟电子邮件、设计报告或简报的排版、语调、浓缩文件长度，更方便分享给其他人。使用者按下「复制」键即可贴到 Email 或简报中。不只如此，AI 助理还能进行智慧引述，使用者也能点入验证 AI 助理的答案来源，重点摘要也会提供连结，方便在文件中找到原始段落。<a href="https://news.adobe.com/news/news-details/2024/Adobe-Brings-Conversational-AI-to-Trillions-of-PDFs-with-the-New-AI-Assistant-in-Reader-and-Acrobat/default.aspx">（详全文）</a></p><p>图片来源／Hugging Face、Predibase、Google、上海复旦大学</p><p><span style="color:#FFFFFF;"><strong><span style="background-color:#3399ff;">&nbsp; AI 近期新闻&nbsp;</span></strong></span></p><p><strong>1. 美国法律资料公司释出法律专用大语言系列模型 KL3M</strong></p><p><strong>2. Amazon 发表历来最大语音合成 AI 模型 BASE TTS，但未开源人</strong></p><p>资料来源：iThome 整理，2024 年 2 月</p></div></div></div><div></div></div></div></div>]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 16:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.ithome.com.tw/news/161426</guid>
            <link>https://www.ithome.com.tw/news/161426</link>
            <author>
                <![CDATA[王若朴]]>
            </author>
            <category></category>
        </item>
        <item>
            <title>
                <![CDATA[英特尔揭露 Intel Foundry 晶圆代工愿景，将替微软代工晶片]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0222-intel_foundry_direct_connect-960.jpg?itok=RN2zgs4P" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>英特尔</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>英特尔（Intel）在 2021 年 3 月<a href="https://www.ithome.com.tw/news/143423" target="_blank">宣布</a>设立全新且独立的晶圆代工服务（Intel Foundry Services，IFS）事业群，并<a href="https://www.intc.com/news-events/press-releases/detail/1675/intel-launches-worlds-first-systems-foundry-designed-for" target="_blank">在本周三（2/21）举办</a>首个 Intel Foundry Direct Connect 活动，揭露 Intel Foundry 未来的发展蓝图，宣布将替微软代工晶片，也立下在 2030 年成为全球第二大晶圆代工厂的愿景。</p><p>COVID-19 疫情期间的晶片短缺，再加上<a href="https://www.trendforce.com/presscenter/news/20231206-11949.html" target="_blank">占据全球 58% 晶圆代工市场的台积电</a>身处地缘政治的风暴中，都让各国意识到自行生产晶片的重要性，自诩为全球科技大国的美国也不例外。美国政府除了要求台积电与三星等业者至美设厂之外，也极力推动境内企业加入晶圆代工，英特尔即为一例。</p><p>在 Intel Foundry Direct Connect 活动上，英特尔直接把旗下业务划分为 Intel Foundry 与 Intel Products，等于是对外宣誓 Intel Foundry 对英特尔的重要性，同时宣布扩大制程蓝图、客户及生态系统合作伙伴。</p><p>英特尔执行长 Pat Gelsinger 指出，AI 正在深深地改变这个世界，也改变了人们对技术与支撑技术之晶圆的看法，而 Intel Foundry 是全球第一个为 AI 时代设计的系统代工厂，可共同创造新的市场，并彻底改变世界利用技术改善人们生活的方式。</p><p>Intel Foundry 原本的制程蓝图为 4 年 5 个节点（five-nodes-in-four-years，5N4Y），但本周宣布将加入新的 14A 以及其它既有节点的演化，以因应客户的不同需求。此外，微软也已经选出一款要利用 Intel 18A 制程来生产的晶片设计。</p><p class="rtecenter"><a href="https://s4.itho.me/sites/default/files/files/0222-Intel%20Foundry%20Direct%20Connect-2.jpg" style="text-align: center;" target="_blank"><img alt="" src="https://s4.itho.me/sites/default/files/images/0222-Intel%20Foundry%20Direct%20Connect-2-600.jpg" style="width: 600px;" referrerpolicy="no-referrer"></a></p><p><span style="color:#696969;"><span style="font-size:14px;">图片来源/英特尔</span></span></p><p>英特尔亦宣布一项新兴业务计划（Emerging Business Initiative），与 Arm 合作以替基于 Arm 的系统单晶片提供尖端的代工服务。</p><p>根据英特尔的估计，在 Intel Foundry 既有的晶圆及先进封装的合约中，整体价值已超过 150 亿美元。</p></div></div></div><div></div></div></div></div>]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.ithome.com.tw/news/161423</guid>
            <link>https://www.ithome.com.tw/news/161423</link>
            <author>
                <![CDATA[陈晓莉]]>
            </author>
            <category>新闻</category>
        </item>
        <item>
            <title>
                <![CDATA[【资安日报】2 月 22 日，锁定越南而来的窃资软体 VietCredCare 意图挟持企业脸书帐号，该国逾三分之二省份出现受害组织]]>
            </title>
            <description>
                <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/20240222.png?itok=sS7FJhsp" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>锁定企业脸书帐号的大规模网路攻击行动，去年 7 月、8 月，资安业者 WithSecure、Zscaler 揭露<a href="https://www.ithome.com.tw/news/158628">名为 DuckTail 的窃资软体攻击行动</a>，这起事故是越南骇客特别针对数位行销及广告领域的人才下手，借由职场社群网站 LinkedIn 寻找目标。</p><p>但类似的手法，最近又有新的发现。资安业者 Group-IB 发现另一起专门针对越南企业组织而来的攻击行动，对方使用另一款窃资软体 VietCredCare，从事攻击行动迄成约有一年半，受害组织遍及当地三分之二省份。</p><p>&nbsp;</p><h3><strong>【攻击与威胁】</strong></h3><p><a href="https://www.group-ib.com/blog/vietcredcare-stealer/"><strong style="font-size: 22px;">窃资软体 VietCredCare 锁定越南企业脸书帐号，将其用于投放广告或是诈骗</strong></a></p>
                <!-- notionvc: 5f72ff07-bfaa-49e7-b3fb-4895821b98d6 -->
                <p></p>
                <p>
                    <a href="https://s4.itho.me/sites/default/files/images/VietCredCare-1-24.jpg">
                        <img alt="" src="https://s4.itho.me/sites/default/files/images/VietCredCare-1-24.jpg" style="width: 300px; float: right;" referrerpolicy="no-referrer">
                        </a>资安业者 Group-IB 揭露从 2022 年 10 月发现的窃资软体 VietCredCare，此恶意程式专门针对越南的使用者而来，攻击者的主要目标是接管受害企业的脸书帐号。
                    </p>
                    <p>根据研究人员的调查，使用此窃资软体的骇客渗透 9 个当地政府机关、12 个省的公共服务入口网站、65 所大学、4 家电子商务平台、21 家银行、12 个当地主要企业。而在越南 63 个省份当中，44 个省出现受害组织，而且有超过半数（50.9%）位于河内，其次是胡志明市、岘港，分别有 32.9%、3.3%。</p>
                    <p>研究人员指出，此窃资软体特别之处在于，它具备自动过滤脸书帐号连线阶段（Session）的 Cookie，并能识别脸书帐号是否用于管理广告，以及投放广告的额度等资讯。而对于该恶意软体的散布途径，研究人员推测是透过网路钓鱼来进行，骇客透过社群网站贴文，声称提供 Excel、Word、Acrobat Reader 等软体，一旦使用者上当，电脑就有可能被植入 VietCredCare。</p>
                    <p>
                        <a href="https://sysdig.com/blog/ssh-snake/">
                            <strong style="font-size: 22px;">恶意软体 SSH-Snake 窃取 SSH 金钥，于受害组织网路进行横向移动</strong>
                        </a>
                    </p>
                    <!-- notionvc: a3454a1c-c6de-4586-b19c-23d93d6ee223 -->
                    <p></p>
                    <p>
                        <a href="https://s4.itho.me/sites/default/files/images/image2-76.png">
                            <img alt="" src="https://s4.itho.me/sites/default/files/images/image2-76.png" style="width: 300px; float: right;" referrerpolicy="no-referrer">
                            </a>资安业者 Sysdig 指出，自今年 1 月公开提供的网路拓朴架构呈现工具 SSH-Snake，已有骇客拿来用于攻击行动。
                        </p>
                        <p>此工具为 Bash Shell 指令码，研究人员形容是「能够自我修改的蠕虫程式」，能够自动从特定档案路径和 Shell 的事件记录档案当中，挖掘受害主机上的 SSH 帐密、私钥，从而在网路环境进行横向移动。</p>
                        <p>特别的是，此指令码档案在第 1 次执行的时候，会进行自我修改，使得档案大小产生变化，其方法是将所有的注释、空格、不必要的函数删除。有别于一般的指令码，SSH-Snake 能在所有类型的装置上运作，并完全以无档案（Fileless）的方式进行，同时还能自我复制及散布。</p>
                        <p>
                            <a href="https://blog.talosintelligence.com/google-cloud-run-abuse/">
                                <strong style="font-size: 22px;">无伺服器服务 Google Cloud Run 遭到滥用，骇客拿来散布金融木马</strong>
                            </a>
                        </p>
                        <!-- notionvc: c978a7db-12d1-4ad6-b838-79fb3925190f -->
                        <p></p>
                        <p>思科威胁情报小组 Talos 指出，他们从去年 9 月发现，来自巴西的骇客滥用无伺服器服务 Google Cloud Run 来大规模散布恶意程式，这些包含了 Astaroth（又名 Guildma）、Mekotio、Ousaban 等金融木马，他们看到骇客主要目标是拉丁美洲，但也有欧洲国家的使用者受害。</p>
                        <p>这些骇客在钓鱼邮件大多使用西班牙文，但也有使用义大利文、葡萄牙文的情况。这些钓鱼邮件通常使用发票或税务文件为诱饵，有时骇客还会冒充税务机关来从事攻击。而这些钓鱼邮件的共通点就是内含 Google Cloud Run 的 URL，收信人一旦照做，就会下载 MSI 安装程式，而有可能导致电脑被植入木马程式。</p>
                        <p>研究人员指出，骇客偏好这项云端服务的原因，在于 Google 为新用户提供免费点数等丰富资源，且能快速部署网页应用程式，而该服务在大多数企业组织的资安防护系统会视为合法流量。</p>
                        <p>
                            <a href="https://www.trellix.com/blogs/research/ransomhouse-am-see/">
                                <strong style="font-size: 22px;">勒索软体 RansomHouse 透过自动化工具 MrAgent，攻击 VMware 虚拟化平台</strong>
                            </a>
                        </p>
                        <p>资安业者 Trellix 与 Northwave 联手，发现勒索软体骇客组织 RansomHouse 近期使用的新工具 MrAgent，此恶意程式专门针对虚拟化平台 VMware ESXi 而来，主要功能是识别主机的系统、关闭防火墙，然后在虚拟机器管理程式（hypervisor）部署勒索软体，从而入侵所有虚拟机器（VM），而以上过程全部都是自动化执行。</p>
                        <p>攻击者也能透过 C2 对 MrAgent 下达命令，从而窜改虚拟机器管理程式的密码、指定勒索软体加密的参数，同时能置换虚拟机器管理程式监控工具的启动画面，从而向 IT 人员显示勒索讯息。</p>
                        <p>特别的是，虽然该恶意程式主要目标是 VMware ESXi，但研究人员指出，MrAgent 同时有 Linux 和 Windows 版本，两者具备相同的核心功能，但在 Windows 版当中，部分工作是透过 PowerShell 执行。</p>
                        <p>
                            <a href="https://psi.de/#19022024">
                                <strong style="font-size: 22px;">为能源供应商提供软体解决方案的 PSI Software 证实遭遇勒索软体攻击</strong>
                            </a>
                        </p>
                        <!-- notionvc: a28cfff0-3218-4a5f-b675-3dd157d377e6 -->
                        <p></p>
                        <p>2 月 15 日能源供应商提供软体解决方案的 PSI Software 传出遭遇网路攻击，该公司为了降低资料遗失的风险，切断包含电子邮件系统在内的多个 IT 系统连线。</p>
                        <p>到了 19 日该公司更新调查结果，指出他们遭遇了勒索软体攻击，但没有透露攻击者的身分。而对于这起事故受害的情况，他们表示尚未发现客户端的 PSI 系统受害的情况，但该公司也无法透过远端连线来进行维护作业。</p>
                        <p>
                            <a href="https://udn.com/news/amp/story/7321/7773406">
                                <strong style="font-size: 22px;">民众购买温泉旅馆泡汤券疑个资外泄遭诈骗，旅馆及 IT 业者竟称没有发生资料外泄事故，此事与他们无关</strong>
                            </a>
                        </p>
                        <!-- notionvc: 3bbd0b37-0b59-4591-b70a-7cc809456f8a -->
                        <p></p>
                        <p>赵姓妇人于 2020 年 10 月、2021 年 11 月间委托同事、家人订购 37 张北投丽禧温泉酒店温泉券，事后却接到诈骗电话要她配合操作「解除分期付款」而上当，遭骗近 10 万元，愤而指控丽禧与建置订购系统的墨攻公司未依个人资料保护法进行相关防护措施，导致她的个资遭到窃取，求偿金钱损失及精神慰抚金，并要求两家公司停止使用并删除她的个资。</p>
                        <p>值得留意的是，本起诉讼当中，丽禧、墨攻提出数发部数位产业署 2023 年的函文，表示他们只有遭到网路攻击，而非个资外泄事件，强调墨攻订购系统在 2021 年 8 月、11 月遭到攻击与个资外泄无因果关系，但后来台湾高等法院认为，这项说法不足以证明个资外流与系统遭骇无关。</p>
                        <p>高院民事法庭发现，诈骗集团在赵妇最后 1 次使用订票系统后才拨打电话，对话内容完全掌握使用的银行帐户等细节。由于前述网路攻击外泄个资超过 5 千笔，却仅有她 1 人受骗，高等法院认为两者之间没有相当因果关系，但两家公司仍要赔偿精神慰抚金。</p>
                        <p>&nbsp;</p>
                        <h3>
                            <strong>【漏洞与修补】</strong>
                        </h3>
                        <p>
                            <a href="https://www.bleepingcomputer.com/news/security/screenconnect-critical-bug-now-under-attack-as-exploit-code-emerges/">
                                <strong style="font-size: 22px;">ConnectWise 针对远端桌面连线软体 ScreenConnect 身分验证绕过漏洞提出警告，已出现攻击行动</strong>
                            </a>
                        </p>
                        <!-- notionvc: e28aae25-cedb-4070-a726-a732e9a63a57 -->
                        <p></p>
                        <p>2 月 19 日资安业者 ConnectWise 发布资安公告，指出旗下的远端桌面连线系统 ScreenConnect 存在路径穿越漏洞 CVE-2024-1708 、身分验证绕过漏洞 CVE-2024-1709，CVSS 风险评分为 8.4、10 分，影响 23.9.7 以前版本的 ScreenConnect，该公司发布 23.9.8 版修补上述漏洞，并对云端服务代管版本 screenconnect.com、hostedrmm.com 进行处置。当时资安业者 Huntress 公布概念性验证攻击（PoC），并透过 Censys 威胁分析平台找到超过 8,800 台 ScreenConnect 伺服器。</p>
                        <p>值得留意的是，20 日 ConnectWise 更新公告，指出上述漏洞已被用于攻击行动，他们公布骇客所使用的 IP 位址，供 IT 人员防堵相关攻击。但可能是因为这些漏洞造成的影响极为严重，隔日该公司宣布破例取消授权限制，让未购买维护合约的用户也能安装新版软体来缓解漏洞。</p>
                        <p>资料来源</p>
                        <p>1.&nbsp;
                            <a href="https://www.connectwise.com/company/trust/security-bulletins/connectwise-screenconnect-23.9.8">https://www.connectwise.com/company/trust/security-bulletins/connectwise-screenconnect-23.9.8</a>
                            <br>
2.&nbsp;
                                <a href="https://www.huntress.com/blog/a-catastrophe-for-control-understanding-the-screenconnect-authentication-bypass">https://www.huntress.com/blog/a-catastrophe-for-control-understanding-the-screenconnect-authentication-bypass</a>
                            </p>
                            <p>&nbsp;</p>
                            <h3>
                                <strong>【资安防御措施】</strong>
                            </h3>
                            <p>
                                <a href="https://www.ithome.com.tw/news/161395">
                                    <strong style="font-size: 22px;">资安院接手 TWCERT/CC 业务，可全天候受理民间企业资安事件通报</strong>
                                </a>
                            </p>
                            <!-- notionvc: 9dd51043-456c-4b64-8b1e-74b35ca22128 -->
                            <p></p>
                            <p>自今年元旦开始，资安院正式接手 TWCERT/CC 业务，带来最显著且立即的改变，就是民间企业资安事件的通报，全天候都有值班人员负责；但资安院为了不与民争利，主要是以第二线技术支援和咨询角色，协助受骇企业检视鉴识报告，是否有找到根因、评估回应措施是否合适。</p>
                            <p>资安院副院长兼发言人吴启文表示，原先资安事故的通报，企业可随时透过电子邮件告知 TWCERT/CC，但只有上班时间才有员工处理，处理不够即时；由于资安院已有 24 小时值班的资安监控中心（SOC），接手相关业务后可处理非上班时间接获的资安事故通报，而能够大幅提升处理时效。</p>
                            <p>&nbsp;</p>
                            <h3>
                                <strong>【其他新闻】</strong>
                            </h3>
                            <p>
                                <a href="https://www.bleepingcomputer.com/news/security/north-korean-hackers-linked-to-defense-sector-supply-chain-attack/">
                                    <strong>
                                        <span style="font-size: 20px;">德国、韩国提出警告，北韩骇客针对全球国防单位从事网路间谍行动</span>
                                    </strong>
                                </a>
                            </p>
                            <p>
                                <strong>
                                    <a href="https://medium.com/s2wblog/kimsuky-disguised-as-a-korean-company-signed-with-a-valid-certificate-to-distribute-troll-stealer-cfa5d54314e2">
                                        <span style="font-size: 20px;">北韩骇客 Kimsuky 利用 Go 窃资软体 Troll 与后门程式 GoBear，针对韩国而来</span>
                                    </a>
                                </strong>
                            </p>
                            <p>
                                <a href="https://blog.talosintelligence.com/new-zardoor-backdoor/">
                                    <strong>
                                        <span style="font-size: 20px;">沙乌地阿拉伯伊斯兰组织遭锁定，被植入后门程式 Zardoor</span>
                                    </strong>
                                </a>
                            </p>
                            <p>
                                <a href="https://www.volexity.com/blog/2024/02/13/charmingcypress-innovating-persistence/">
                                    <strong>
                                        <span style="font-size: 20px;">伊朗骇客组织 Charming Kitten 锁定中东人士散布后门 Basicstar</span>
                                    </strong>
                                </a>
                            </p>
                            <p>
                                <strong>
                                    <a href="https://www.securityweek.com/chrome-122-firefox-123-patch-high-severity-vulnerabilities/">
                                        <span style="font-size: 20px;">Google、Mozilla 发布浏览器大改版 Chrome 122、Firefox 123，修补高风险漏洞</span>
                                    </a>
                                </strong>
                            </p>
                            <p>&nbsp;</p>
                            <p>&nbsp;</p>
                            <h3>
                                <strong>近期资安日报</strong>
                            </h3>
                            <p>
                                <a href="https://www.ithome.com.tw/news/161398">
                                    <strong>【2 月 21 日】中国资安业者惊传资料外泄，意外曝露中国政府对全球各国从事网路间谍行动的情况</strong>
                                </a>
                            </p>
                            <p>
                                <a href="https://www.ithome.com.tw/news/161355">
                                    <strong>【2 月 20 日】勒索软体骇客组织 LockBit 的基础设施传出遭到执法单位围剿</strong>
                                </a>
                            </p>
                            <p>
                                <a href="https://www.ithome.com.tw/news/161344">
                                    <strong>【2 月 19 日】Ivanti Connect Secure 采用极为老旧的 Linux 核心及元件而存在数千个漏洞</strong>
                                </a>
                            </p>
                        </div>
                    </div>
                </div>
                <div></div>
            </div>
        </div></div>]]>
    </description>
    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>
    <guid isPermaLink="false">https://www.ithome.com.tw/news/161422</guid>
    <link>https://www.ithome.com.tw/news/161422</link>
    <author>
        <![CDATA[周峻佑]]>
    </author>
    <category>新闻</category>
</item>
<item>
    <title>
        <![CDATA[日本中小型银行展开核心系统上云潮，和 IT 厂商打造共享核心系统云端平台，13 间银行计划 4 年内先上云]]>
    </title>
    <description>
        <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/020800-02_0.png?itok=DEtBu1CJ" width="960" height="420" alt="" title="NTT Data 计划打造一套共享银行核心系统的云端平台，分三阶段实施，预计 2028 年先适用于 13 间银行使用的共享核心系统，2030 年再将五间银行采用的核心系统迁移至云端平台，再研议扩大应用范围。（图片来源：NTT Data）" referrerpolicy="no-referrer"></div></div></div><p class="caption"> NTT Data 计划打造一套共享银行核心系统的云端平台，分三阶段实施，预计 2028 年先适用于 13 间银行使用的共享核心系统，2030 年再将五间银行采用的核心系统迁移至云端平台，再研议扩大应用范围。（图片来源：NTT Data） </p></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>近年来，日本中小型银行掀起一波核心系统上云潮。今年二月初，日本地方银行横滨银行和东日本银行的母公司康科迪亚金融集团宣布，未来将联合其他四间银行，考虑在 2030 年应用日本 IT 大厂 NTT Data 建造的共享型核心系统云端平台，实现核心系统上云。同日，日本地方银行京都银行宣布，将联合其他 12 间银行，在 2028 年应用这套平台，实现核心系统轻量化，并将营运资源集中至转型策略发展。</p><p>NTT Data 也在同天跟著宣布，将在今年四月起开发「整合银行云」，一个共享银行核心系统的云端平台。这个服务将会涵盖硬体设备、中间软体和资料中心建置，也会将银行的共享型核心系统转为开放架构，迁移至云端平台上运作。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/111800-01.png" style="width: 600px;" referrerpolicy="no-referrer"></p><blockquote><p>NTT Data 计划打造共享银行核心系统的云端平台，除了会涵盖硬体设备、中间软体和资料中心建置，也会应用自家开发的开放架构框架将核心系统转换为开放架构，汰换大型主机。（图片来源：NTT Data）</p></blockquote><p>NTT Data 表示，这项计划将会分阶段实施。首先，他们已经在 2024 年协助横滨银行在内的五间地方银行成功转型核心系统，将他们的共用核心交易处理系统转为开放架构，汰换大型主机。有了这个阶段性成功，他们将迈入第二阶段，预计在四年内打造出「整合银行云」，并应用至 13 间银行共用的核心系统，实现核心系统上云。第三阶段则是扩大应用范围，将更多共享型核心系统应用至这个云端平台。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/020800-02(1).png" style="width: 600px;" referrerpolicy="no-referrer"></p><blockquote><p>NTT Data 计划以三阶段打造「整合银行云」，并逐步将共享核心系统迁移至平台中。第一阶段是在 2024 年 1 月将共享型核心系统 MEJAR 改为开放系统架构，第二阶段是在 2028 年上线「整合银行云」，适用 13 间银行，第三阶段则是在 2030 年扩大应用范围，应用至 MEJAR 系统。（图片来源：NTT Data）</p></blockquote><p>若计划顺利实施，2030 年日本至少会有 18 间中小型银行完成核心系统上云，同时汰换大型主机，未来更将有 40 间采用的四个共享银行核心系统在同个云端平台上运作。</p><h3>日本地方银行采共享型核心系统运作已有 20 年</h3><p>在日本，中小型银行数量众多，这些银行主要经营特定区域，称为地方银行，数量高达 64 间。2000 年期间，日本地方银行开始发展共享型核心系统，关键原因有三，第一，地方银行的营运成本有限，透过共享核心系统有助减少营运成本。第二，地方银行发展区域不同，竞争关系较低，增加多家银行合作的可能性。第三，当合作的地方银行业务规模和型态相似，系统就不需要额外客制化修改，协作效率高，同时有助于发展规模经济。</p><p>在日本这一批使用共享核心系统的地方银行中，又有超过四成采用 NTT Data 开发的核心系统。早在 2004 年，13 间地方银行就组成「地方银行联合中心」，开始以共享核心系统运作。后来，有些大型地方银行因营运成本考量，也加入共享核心系统的行列。</p><p>目前，NTT Data 建置的共享型核心交易处理系统目前发展出了四个体系，分别为地方银行联合中心、MEJAR、STELLA CUBE，和 BeSTAcloud，约有 40 间银行使用。其中，地方银行联合中心是由 NTT Data 建置和营运的核心系统中心，将首先应用至整合银行云，MEJAR 则是以日本最大地方银行横滨银行为首，其核心系统中心同样由 NTT Data 建置，但是由银行端负责营运。今年，NTT Data 和横滨银行合作将核心系统 MEJAR 转为开放架构后，预计在 2030 年把 MEJAR 迁移至整合银行云。</p><h3>日立和富士通等大型主机主要供应商接连退场，日本地方银行和 IT 厂商不得不转型</h3><p>日本地方银行启动这波大型主机汰换潮，早在 2017 年就开始酝酿。当时，多家业者开始退出大型主机市场，不仅日立宣布退出大型主机制造业务，富士通也在去年宣布结束既有的大型主机制造和销售。这个市场前景让地方银行面临内外夹击，一方面传统大型主机技术老旧，导致系统无法支援现代化应用，相关营运人才也逐渐短缺，阻碍了银行内部发展现代科技，另一方面，大型主机制造商仅剩海外厂商 IBM，日北本土厂商接连退场，长久下来恐发生 IBM 独大的技术绑定问题。</p><p>这个趋势不仅让银行业开始面对转型难题，系统供应商也同样面临威胁。直到去年，NTT Data 建置的四个共享型核心系统仍是在日立和富士通的大型主机上运作，两家厂商纷纷退场，NTT Data 也不得不开始汰换大型主机。</p><h3>日本地方银行和 IT 厂商展开核心系统转换计划，双方皆以全行上云作为发展目标</h3><p>面对这个威胁，NTT Data 在 2017 年就宣布开始研究将核心系统转换为开放架构，汰换大型主机，更要以核心系统上云作为发展目标。2019 年，NTT Data 打造出一套开放架构框架，能协助原先在大型主机上开发的应用程式至开放架构中运作。这套框架也是今年初协助 MEJAR 系统转为开放架构的关键，耗时三年，横滨银行和 NTT Data 成功让五家银行共用的核心系统，从大型主机搬迁至开放系统架构中运作，完成整合银行云第一阶段任务。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/messageImage_1708501802485.jpg" style="width: 600px;" referrerpolicy="no-referrer"></p><blockquote><p>NTT Data 开发出一套开放架构框架，名为 PITON，可作为部分中间软体，协助在大型主机运作的核心系统转换至开放架构上。（图片来源：NTT Data）</p></blockquote><p>2017 年不只 IT 厂商动起来，日本地方银行也展开核心系统上云计划。以横滨银行和东日本银行为例，他们从 2010 年代后期开始，就开启系统上云的计划。他们分为三阶段上云，第一阶段是将人事和总务系统等非交易相关的系统上云。第二阶段，是将与核心系统数据连接规模较小的系统上云，例如，各种业务系统。接下来，他们将频繁与核心系统进行数据连接，且规模较大的系统上云，例如营业融资系统和数据库。横滨银行预计，2024 年底前，全行将有超过 54% 的系统上云。最后关键，则是在 2030 年考虑采用「整合银行云」，来实现全行系统上云。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/%E8%9E%A2%E5%B9%95%E6%93%B7%E5%8F%96%E7%95%AB%E9%9D%A2%202024-02-22%20132709.png" style="width: 600px;" referrerpolicy="no-referrer"></p><blockquote><p>2010 康科迪亚金融集团旗下的横滨银行和东日本银行自 2010 年代后期开始进行全行上云计划，分三阶段实施，从与核心交易处理系统无关连、小规模系统连接到频繁连接的系统分段上云。预计 2024 年全行超过 54% 系统上云。（图片来源：康科迪亚金融集团）</p></blockquote><p>「整合银行云」的概念则是从 2021 年开始酝酿，当时，18 间地方银行组成研究小组，将这个概念列入研究主题，探讨如何透过合作提升系统营运效率。2022 年，NTT Data 正式宣布整合银行云的计划，当时仅是说明这项计划，尚未正式启动开发，就已震撼了日本 IT 界与银行业。</p><p>直到今年二月初，NTT Data 和多家地方银行完成系统转换后，双方才正式宣布启动整合银行云开发计划，预计 2028 年 13 间银行共享的核心系统上云，2030 年 5 间银行共享的核心系统上云，再研议扩大应用剩余的两套核心系统，最终目标是让多达 40 间日本地方银行在同一套基础设施上运作核心系统。</p><p>
        <!-- notionvc: 87e8a1cc-f1d7-40cb-a35e-d939d70e8d97 -->
    </p>
</div>    </div>    </div>    <div></div>    </div>    </div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161421</guid>    <link>https://www.ithome.com.tw/news/161421</link>    <author>    <![CDATA[李昀璇]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[本周才公开的 ConnectWise 重大漏洞已遭骇客利用]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0222-connectwise_screenconnect_23.9.8_security_fix_on_0219-960.jpg?itok=jLj02jBv" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>远端桌面软体业者 ConnectWise<a href="https://www.connectwise.com/company/trust/security-bulletins/connectwise-screenconnect-23.9.8" target="_blank">本周一（2/19）公开揭露</a>了位于 ScreenConnect 的两个安全漏洞，但隔天就传出已遭骇客滥用，GitHub 上亦已出现概念性验证攻击程式，使得资安业者相继出面呼吁使用者应尽速修补。</p><p>ScreenConnect 是个远端桌面软体应用，ConnectWise 同时支援 ScreenConnect 的云端代管服务、自行代管及就地部署版本。本周所揭露的两个安全漏洞为 CVE-2024-1709 与 CVE-2024-1708，前者可透过一个备用路径或通道来绕过身分验证，CVSS 风险等级高达最严重的 10 分，后者则是个路径穿越（Path Traversal）漏洞，其 CVSS 风险等级为 8.4 分。这两个漏洞影响 ScreenConnect 23.9.7 与之前的版本。</p><p>在 ConnectWise 公布漏洞之际，尚未传出相关漏洞遭到利用的消息，且 ConnectWise 已先行修补了建立在自家 ScreenConnect 伺服器上的云端服务，并建议自行代管或就地部署的客户更新至 23.9.8。</p><p>不过，隔天 ConnectWise 便说已收到可疑活动的通知，同时释出网路入侵指标（IOC）供用户参考，而利用上述漏洞的概念性验证攻击程式于 21 日就出现在 GitHub 上。</p><p><a href="https://www.huntress.com/blog/a-catastrophe-for-control-understanding-the-screenconnect-authentication-bypass" target="_blank">资安业者 Huntress 也在本周公布</a>了这两个安全漏洞的技术细节，指出当他们比较了 ScreenConnect 修补前后的程式码，发现相关漏洞非常容易被攻陷，且所建立的概念性攻击程式不仅绕过了身分验证，还能自远端执行程式。</p><p><a href="https://twitter.com/Shadowserver/status/1760229390082847029" target="_blank">根据 Shadowserver 在 20 日的追踪</a>，公开网路上仍有 3,800 台 ScreenConnect 伺服器尚未修补漏洞，相较前一天只减少了 7%。</p><p class="rtecenter"><a href="https://twitter.com/Shadowserver/status/1760229390082847029" target="_blank"><img alt="" src="https://s4.itho.me/sites/default/files/images/0222-ScreenConnect-Shadowserver.png" style="width: 600px;" referrerpolicy="no-referrer"></a></p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161417</guid>    <link>https://www.ithome.com.tw/news/161417</link>    <author>    <![CDATA[陈晓莉]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[Google 可能推出 Workspace 专属的 Gemini Business、Enterprise 方案]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0222-google_gemini-960.jpg?itok=oeq2cdRh" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>Google</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>Google 本月初将聊天机器人 Bard 改名为 Gemini，并推出第一个付费方案<a href="https://www.ithome.com.tw/news/161175" target="_blank">Gemini Advanced</a>，现在又将再进一步，推出 Google Workspace 专属的 AI 助理方案 Gemini Business 及 Gemini Enterprise。此外也为 Gemini Advanced 新增执行 Python 程式码的功能。</p><p>9to5Google 记者<a href="https://twitter.com/evowizz/status/1759690336845037869" target="_blank">Dylan Roussei</a>及<a href="https://twitter.com/testingcatalog/status/1759685618034978852/" target="_blank">开发论坛</a>发现关于 Gemini 的最新宣布。Google 针对 Workspace 用户推出 Gemini Business 及 Gemini Enterprise 方案，允许用户透过 Gemini AI 助理存取最新 Gemini 1.0 Ultra，以及「企业等级」资料防护功能，用户对话也不会被用以训练底层 AI 模型。Workspace 管理员可透过控制枱管理其设定。</p><p class="rtecenter"><a href="http://twitter.com/evowizz/status/1759690336845037869" target="_blank"><img alt="" src="https://s4.itho.me/sites/default/files/images/0222-Google_Workspace_Gemini%20Business_Enterprise.png" style="width: 600px;" referrerpolicy="no-referrer"></a></p><p>二项方案将在全球 150 多个国家地区上线，一开始仅为英文版进行优化。</p><p>这是 Google 2 月初宣布 AI 助理 Bard 改名为 Gemini 及需要付费的 Gemini Advanced 后，Google 规划的企业付费 AI 服务。不过 Workspace 本来就有<a href="https://www.ithome.com.tw/news/158487" target="_blank">Duet AI</a>助理服务。9to5Google 的 Roussei 报导，最新 Google 通知中的升级 Gemini Business 网址页连到的是 Duet AI 网页。Gemini Business/Enterprise 和 DuetAI 的关系为何，以及 Business /Enterprise 推出后，DuetAI 何去何从目前仍不清楚。</p><p>另一方面，Google 也宣布 Gemini Advanced 新增功能。用户将能直接在 Gemini 用户介面上执行 Python 程式码片段。Google 表示，这程式编写新功能特别有助于程式学习和验证二种应用场景；学生可实验程式码，测试程式变更对输出有何影响，开发人员则可验证程式码执行是否符合预期，再复制到程式工作中。</p><p>根据 Google 的说明，Gemini Advanced 新功能及 Gemini Business/Enterprise 在 2 月 20 日及 21 日上线。一如 Google Bard 改名，日期极可能都有变化。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161411</guid>    <link>https://www.ithome.com.tw/news/161411</link>    <author>    <![CDATA[林妍溱]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[AI 狂潮推动 Nvidia 季营收成长 265%]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0222-nvidia-960-guan_fang_tu_pian_.png?itok=6sfaCNgv" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>Nvidia</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>绘图处理器大厂<a href="https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/" target="_blank">Nvidia 周三（2/21）公布</a>截至今年 1 月 28 日的 2024 财年第四季财报，该季 Nvidia 创下 221 亿美元的营收，比上一季增加 22%，比去年同期成长 265%，净收入（Net Income）为 122.85 亿美元，比上一季增加 33%，相较于去年同期则成长 769%，每股盈余为 5.16 美元。在该季的销售中，AI 带动了 Nvidia 的资料中心平台，该类别的营收大增 409%，出色的表现令 Nvidia 当天的盘后股价上涨了 9.07%，来到 735.95 美元的新高。</p><p>Nvidia 的资料中心平台是利用不同的 GPU 产品来打造加速运算解决方案，标榜可利用更少的伺服器来达到更好的效能，主要供大型企业与超级运算中心使用，并支援 AI 训练、AI 推论、科学运算，以及虚拟桌面基础设施等不同的应用。</p><p>在 AI 的助益下，该季资料中心业务替 Nvidia 带进 184 亿美元的营收，比前一年同期增加了 409%，该类别占 Nvidia 总营收的 83%。</p><p>Nvidia 的其它营收类别还包括游戏的 29 亿美元，比前一年同期成长 56%，专业视觉化营收为 4.6 亿美元，成长 105%，汽车领域的营收为 2.8 亿美元，下滑 4%。</p><p>OpenAI 在 2022 年 11 月发表的 ChatGPT 掀起了全球的 AI 浪潮，也让支援平行处理且讲究效能的 GPU 跟著水涨船高。Nvidia 创办人暨执行长黄仁勋表示，加速运算与生成式 AI 已来到转捩点，全球各个国家、产业或企业对相关的需求都在激增，其资料中心平台的大幅成长来自于大型云端服务供应商、GPU 专业供应商、企业软体及消费者网路公司对资料处理、训练及推论的需求。</p><p>此外，由汽车、金融服务及健康医疗产业为首的垂直产业，也已达到数十亿美元的经济规模。</p><p>原本华尔街分析师对 Nvidia 就有很高的期待，但 Nvidia 的财报结果超越了分析师期待，让盘中下滑逾 2% 的股价在盘后大涨。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161413</guid>    <link>https://www.ithome.com.tw/news/161413</link>    <author>    <![CDATA[陈晓莉]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[【参照国际标准和法规，最快 3 月底公布 AI 评测指引草案】AI 评测中心揭今年布局]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1170-aiping_ce_-960.jpg?itok=hhuetQkA" width="960" height="420" alt="" title="数位部在去年 12 月成立 AI 评测中心，要来制定台湾的 AI 产品与系统评测制度和指引。目前已针对大型语言模型制定 10 项测试类别，如安全性、弹性、可解释性等。（图片来源／数位部）" referrerpolicy="no-referrer"></div></div></div><p class="caption"> 数位部在去年 12 月成立 AI 评测中心，要来制定台湾的 AI 产品与系统评测制度和指引。目前已针对大型语言模型制定 10 项测试类别，如安全性、弹性、可解释性等。（图片来源／数位部） </p></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>「我们最快 3 月底公布 AI 评测制度和指引！」负责 AI 评测业务的核心成员、数位发展部数位产业署副署长林俊秀说道。</p><p>就在去年 12 月，数位发展部成立了 AI 产品与系统评测中心（简称 AI 评测中心），还预告要制定「AI 产品与系统评测制度」与「AI 产品与系统评测指引」，来设置台湾 AI 产品检测和验证标准。如林俊秀所言，这些制度和指引，最快会在今年第一季末出炉。</p><p>AI 评测中心的出现、AI 产品系统评测制度和指引的到来，是否意味著 AI 厂商与企业，必须通过数位部 AI 评测，才能贩售或使用 AI 系统？</p><p><span style="font-size:28px;"><strong>台湾 AI 行动计划 2.0 催生出 AI 评测中心</strong></span></p><p>这些疑问，得从 AI 评测中心的设立谈起。去年，台湾 AI 行动计划 2.0 正式展开，在 1.0 计划的基础上，进一步深化 5 大层面的 AI 发展，包括人才、技术和产业发展、国际影响、运作环境和人文社会等。</p><p>其中的「运作环境」，不只是要完善法规制度、资料治理环境，还涵盖成立 AI 产品和系统评测中心、加速发展接轨国际的 AI 规范与标准、对通用领域和特定领域设置 AI 法规等面向。</p><p>因此，去年 12 月初，数位部成立了 AI 评测中心，要推动台湾 AI 评测制度、发展可信任 AI 环境。同时，在法规部分，我们看到了行政院在去年 8 月祭出公部门使用生成式 AI 的指引参考，国科会也联手其他部会草拟 AI 基本法，预计在今年上半年公布。而在产业规范部分，金管会则率先开出第一枪，领先其他产业主管机关，在去年 12 月底发布金融业运用 AI 指引草案，来提供金融业者使用 AI 的建议。预计接下来，还会有其他主管机关跟进，如衞福部、NCC、交通部等，针对各产业提出 AI 系统的使用建议。</p><p><span style="font-size:28px;"><strong>评测瞄准厂商和企业，将配合产业主管机关来推动</strong></span></p><p>制定「AI 产品与系统评测制度」和「AI 产品与系统评测指引」是 AI 评测中心今年的首要目标。就评测制度来说，目的是要检测 AI 产品或系统，是否符合国际对 AI 系统的要求，比如安全、可靠、透明等。</p><p>至于检测对象则有 2 种，包括销售 AI 产品和系统的厂商，以及以 AI 驱动服务的企业。「不论这个服务是对内还是对外，我们都希望企业能来送测」，林俊秀补充。尤其，数位部自去年开始推动 AI 技术服务机构服务能量分类与登录机制，来建立一份有符合资格的 AI 厂商清单，而这些厂商，将是 AI 评测中心第一波鼓励送测的对象。</p><p>林俊秀强调，AI 评测不具法律强制力，数位部不会强制要求所有厂商和企业送测，但「会用推广的方式，先锁定政府单位，如国家关键基础设施、各产业主管机关等，搭配这些机关制定的 AI 指引，来向他们说明、推广检测制度。」他说。</p><p>意思是，国家关键基础设施主管机关或各产业主管机关，会制定适合该产业的 AI 指引，如金管会制定的金融业运用 AI 指引草案，AI 评测中心就会配合这些指引，来与主管机关讨论、说明，并鼓励其管理的产业业者申请送测。</p><p>比如，金融业运用 AI 指引草案，建议金融业者采用的 AI 系统 4 大生命周期，需符合公平性、可解释性和透明性等原则。而 AI 评测中心的检验项目包含这些原则，此时金融业者或厂商，就可申请送测 AI 系统，以证明系统符合指引建议。</p><p>不只针对国家关键基础设施和产业主管机关，林俊秀表示，AI 评测中心也瞄准民间集团和业者，将对这些对象主动说明评测制度，鼓励业者申请送测自家 AI 系统。</p><p>所以，厂商和企业是否必须通过 AI 评测，才能贩售或使用 AI 系统？答案是不用。从林俊秀口中可得知，这些制度和后续出炉的 AI 评测指引，都不具备强制效力。但若各产业主管机关纷纷祭出产业 AI 运用指引，来建议各产业业者如何使用 AI，势必会带起系统评测强劲的需求。</p><p><span style="font-size:28px;"><strong>今年锁定生成式 AI，已建立生成式 AI 评测题库</strong></span></p><p>AI 系统包罗万象，AI 评测将先瞄准哪些领域？</p><p>林俊秀点出，这两年生成式 AI 遍地开花，AI 评测中心今年也锁定生成式 AI，先制定合适的测试题目，作为衡量生成式 AI 的考题。尤其，他们已针对大型语言模型（LLM）制定 10 项测试类别，包括安全性、可解释性、弹性、公平性、准确性、透明性、当责性、可靠性、隐私及资安等。</p><p>其中的公平性、准确性、可靠性、隐私和资安等 5 大类别，采考题方式来评测。举例来说，可靠性是要判断模型的敏感度，也就是 AI 系统在面对未预期的状况时，也能维持良好的表现和预测能力，因此常见的考题，就是提问中出现错别字，来判断模型能否依然正确回答。数位部目前共设计了 3,000 多道题目，接下来还会继续新增。</p><p>至于安全性、可解释性、弹性、透明性、当责性等 5 项类别，数位部打算以设计文件、规格文件等作证资料，采人工审核方式进行。不过，确切的测试方式还在讨论中。</p><p>另一方面，林俊秀也透露，他们已用这些测试类别来衡量国科会打造的国产语言模型 TAIDE，包括 70 亿参数（7B）和 130 亿参数（13B）版本。不过，林俊秀补充，这 10 项类别只是生成式 AI 测试的一环，模型就算通过 10 项测试，还是得接受完整的系统检测，合格后公部门才能正式使用。「检测 TAIDE 是我们今年的重要目标！」他说。</p><p>今年 1 月，AI 评测中心还揭露，这 10 项测试中的 5 项已能自动化测试。接下来，AI 评测中心除了继续扩充 LLM 题库，还会制定生成式 AI 以外的传统机器学习系统评测标准，如适用于影像辨识模型的测试题，来逐步完善台湾 AI 系统评测制度。</p><p><span style="font-size:28px;"><strong>由 2 大组织执行评测</strong></span></p><p>有了考题之后，AI 评测制度还有赖 2 大关键组织来落实。第一个组织是 AI 测试实验室，也就是负责执行 AI 产品和系统检测的单位，另一则是用来把关这些测试实验室的 AI 验证机构。</p><p>这些测试实验室可由民间业者担任。业者必须符合国际 AI 相关规范、取得财团法人全国认证基金会认证，才能评测厂商或企业送测的 AI 系统。林俊秀指出，他们也可能仿照 AI 技术服务机构服务能量分类与登录机制，建立一份 AI 测试实验室的政府名册，来管理检测品质。</p><p>至于 AI 验证机构，则将由资安研究院和工研院组成。他们的目的是把关测试实验室，以及维持市场秩序。林俊秀解释，由于测试实验室可自行决定服务和定价范围，但 AI 评测中心会扮演市场秩序维护角色，因此 AI 验证机构会负责认定测试实验室的报告，并剔除破坏市场机制的不良测试实验室，来确保检测一致性。</p><p>不只如此，AI 验证机构还有其他任务，比如研究新兴 AI 技术、判断是否需更改评测方式和题库等。验证机构还能根据评测项目，来要求旗下 AI 评测开发实验室研发自动化工具，加速检测作业。林俊秀就点出，他们今年会开发 2 类自动化工具，一类是给 AI 测试实验室使用，以加速评测作业，另一类是给 AI 厂商或企业，让他们在送测前，先透过自动检测工具来判断自家 AI 系统是否达到检测标准。</p><p>另一方面，就接下来要公布的 AI 评测指引而言，可细分为 2 种，包括 AI 产品与系统基本规范，以及 AI 产品与系统基本检测基准。前者涵盖了适用领域、风险管理、评测项目和规范细则，后者则指每项评测的作法说明，另也根据不同适用领域或风险等级，而制定的不同评测项目。</p><p>林俊秀表示，他们在制定这些指引时，参考了各大国际 AI 标准和规范，如美国国家标准暨技术研究院（NIST）的 AI 风险管理框架、欧盟 AI 法案、ISO 相关标准等。「指引（草稿）大都拟订好了，若这些规范有所调整，我们也会与时俱进。」林俊秀表示，接下来，他们将召开 AI 制度委员会，来决定 AI 评测指引内容，并尽快公布。</p><p>届时，这份评测指引会明定更多 AI 评测的细节，如评测效期，也就是 AI 系统通过评测后的合格期限。林俊秀补充，要是送测的系统出现改版或重大更新，AI 评测中心会要求业者重新送测，以确保检验品质。</p><p><span style="color:#FFFFFF;"><span style="font-size:28px;"><strong><span style="background-color:#3399ff;">&nbsp;10 项 LLM 测试重点&nbsp;</span></strong></span></span></p><p><strong><span style="color:#B22222;">&nbsp;1. 安全性：</span>AI 系统某些功能失效时，所产生的回应与风险</strong></p><p><strong><span style="color:#B22222;">&nbsp;2. 可解释性：</span>AI 模型的输入与输出，是否存在因果关系或关系的描述</strong></p><p><strong>&nbsp;<span style="color:#B22222;">3. 弹性：</span>AI 系统能适应不同环境、需求和条件</strong></p><p><strong>&nbsp;<span style="color:#B22222;">4. 公平性：</span>AI 系统能公平对待不同群体和个体</strong></p><p><strong>&nbsp;<span style="color:#B22222;">5. 准确性：</span>衡量 AI 系统的输出与真实结果的接近程度，即拟合程度</strong></p><p><strong><span style="color:#B22222;">&nbsp;6. 透明性：</span>纠正 AI 系统运营商和消费者之间的资讯不平衡</strong></p><p><strong><span style="color:#B22222;">&nbsp;7. 当责性：</span>AI 系统开发者和使用者需对系统的行为或操作负责</strong></p><p><strong><span style="color:#B22222;">&nbsp;8. 可靠性：</span>评量系统在面对未预期的状况时，能维持良好的表现和预测能力</strong></p><p><strong><span style="color:#B22222;">&nbsp;9. 资料隐私：</span>将可能造成隐私的冲击严重程度分级，以实现风险评估与掌控</strong></p><p><strong><span style="color:#B22222;">&nbsp;10. 系统安全：</span>AI 系统面对外部攻击、未授权访问或不当使用时，能保护其资源、功能和资料的完整性和机密性</strong></p><p><span style="font-size:14px;"><span style="color:#696969;">资料来源：AI 评测中心，iThome 整理，2024 年 2 月</span></span></p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161412</guid>    <link>https://www.ithome.com.tw/news/161412</link>    <author>    <![CDATA[王若朴]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[乐高集团如何实践平台工程？彻底改组传统 AI，拥抱云端优先和 API 优先战略]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/logo-idp-960.png?itok=Ws7FDeXy" width="960" height="420" alt="" title="乐高集团打造了一个开发者入口网站，称为 Baseplate ，这是 2 千人数位团队成员，每天上班要打开的网页。" referrerpolicy="no-referrer"></div></div></div><p class="caption"> 乐高集团打造了一个开发者入口网站，称为 Baseplate ，这是 2 千人数位团队成员，每天上班要打开的网页。 </p></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>大家都玩过乐高积木，打造出这款全球知名玩具的是乐高集团，他们从 2021 年就开始大力展开数位转型，为了实现高度敏捷化的商业能力，订出了云端优先和 API 优先的转型战略。</p><p>成立于 1932 年的乐高集团，目前全球多达 2 万四千名员工。过去 2 年，他们的数位团队的规模，增加 3 倍，现在超过了 2 千人，占了员工总数的 1 成，分散在全球四个数位据点，为了推动上云战略，他们发展出了一套数位维运模式，从产品面、架构面和工程面，来推动上云战略。</p><p>为什么乐高集团的转型战略是拥抱云端优先，API 优先，甚至从 2023 年开始拥抱 AI，开始尝试用生成式 AI 打造聊天机器人应用。乐高集团开发者体验和云端部门负责人 Rasmus Hald 之前在哥本哈根一场研讨会中，揭露了他们非做不可的原因。</p><p>Rasmus Hald 指出，一切都是为了商业敏捷力（Business Agility），乐高集团想要靠数位手段，来实现商业敏捷力。目标是希望能让 IT 的关键基础设施可以做到，让企业应用或 IT，无缝地存取到所有资料、运算资源和网路资源。</p><p>乐高集团所采取的数位手段，包括了松耦合的基础架构，也要全靠 API 来运作。「在生成式 AI 崛起的时代，更要考虑 GAI 技术对 API 使用的影响。」Rasmus Hald 补充。</p><p><strong>乐高追求的</strong><strong>商业敏捷力三大特质：实验力、品质与速度、新奇感</strong></p><p>这家积木游戏巨头想要的商业敏捷力，包括了三大特质，实验能力、兼顾品质和速度、新奇。Rasmus Hald 解释，想要有能力快速得到回馈来快速实验各种创新，也要有能力兼顾速度和品质，能以一定速度持续提供品质一致的应用成果，最后一项特质是有能创造新奇感，有能力持续创新、不断提供崭新的体验，「不能用 10 年前的老方法来做事，现在每一年都要推出新的产品，和全新的产品体验。」尤其，越来越多小孩拥有手机，他指出：「如何结合实体的乐高玩具和数位世界，正是他们的新挑战 。」</p><p>例如，乐高推出了一款建设者 App，在乐高产品纸盒外有一个 QRCode，用这个 App 扫描条码后，可以在手机上看到实体乐高积木组合成品的 3D 模型，也可以跟其他人一起组合同一组乐高模型的玩具，透过 App 分享彼此的拼法。「这个 App 就是乐高集团用来实验不同乐高玩法的平台， 现在已经成了乐高体验核心的一环。」例如，后来发展出故事式的玩法，结合一个故事，来组合纸盒中的乐高玩具 ，例如捕捉不同的动物的故事，或是开不同的车子。这是乐高数位团队其中一项创新成果，将实体体验结合数位的体验。</p><p>「 我们的目标是，只有最好才是够好。」Rasmus Hald 骄傲的说，这是他对数位团队的期许。但是，想要推动数位转型，不能被传统 IT 思维绑住，「不能抱怨钱不够、资安太难，就做不到。」</p><p>许多企业的数位转型，是以 IT 部门为基础，来发展电商引擎、数位行销等不同应用，以其对应的 AP 团队，不同应用团队的底层都是 IT 部门。乐高集团原本也是如此，有一个分工明确各司其职的 IT 部门，旗下有专门的维运，专门的开发团队。但是，Rasmus Hald 指出：「这样的组织架构，最后会沦为一昧追求成本降低、风险控管。」</p><p><strong>不惜将传统 IT 部门全面改组，成为一个个小型产品团队</strong></p><p>为了推动转型，乐高集团干脆重组了整个 IT 部门，整体 IT 人力没有减少，还是同样的一群人，但是不再有一个庞大的 IT 部门，而是改为一个个的小型产品团队，并且发展一套自己的数位维运模式。乐高的改造主要分三个面向来改组传统 IT，包括了产品面、架构面和人力面。</p><p>在产品面，改为一个个不同产品的产品团队，每个产品团队得负责这个产品的开发、维运、资安等 DevSecOops 流程的工作，而在架构面，采取了松耦合的技术架构，更容易弹性组合，重复利用来减少不同团队之间的重工。而在人力面，每个产品团队都要有自己的工程师，自己的开发战力。</p><p><strong>乐高采取不一样的 IT 组织运作模式，让 IT 绑定商业成果和责任</strong></p><p>不只是重组 IT 部门，乐高集团更采取了一个特别的 IT 组织运作模式。Rasmus Hald 指出，传统 IT 是集中式的 IT，各个业务部门提出需求，给一个 IT 部门，由这个部门负责规画、开发和维运。在这种集中式 IT 的模式下，每个 AP 的责任属于各事业部门而非 IT，IT 也不一定需要业务领域的专业，对于业绩不见得能感同身受，IT 只需要对规模效益负责。</p><p>另一种 IT 组织运作模式是彻底分散式的 IT，各个业务部门有自己的 AP 团队，负责规画和开发，再统一由一个基础架构团队来负责维运。这个模式虽然让业务与开发更紧密结合，IT 能累积足够专业，并担起主要的 AP 责任，但是规模效益变成了维运团队的事，而非产品团队的工作，而且因为最后一哩由维运团队负责，AP 团队仍有借口推诿说，不一定要对成果负责。乐高集团没有采取了上述两种，而是自己发展出了另一种运作模式，Rasmus Hald 称为绑定商业能力的 IT 运作模式（Business Capability-Aligned iT）。</p><p>在这个模式下，单一 IT 部分虽然重组成了许多的产品团队，但是没有直接隶属于特定的业务团队，而更像是负责接手业务需求的产品开发团队，一个业务部门，可以将不同的业务 AP，交给不同的产品团队来负责。而每一个产品团队，采取同样的工作流程，因此，在完成一项业务产品的开发后，也可以接手另</p><p>一个业务团队的 AP 开发需求。每一个产品团队都要负责自己所开发 AP 的维运工作，而不是交给一个独立团队，但是每个产品团队共用同样的一套基础架构。「这样的模式，可以让产品团队直接与商业成果绑在一起，也能和业务部门共享责任。」Rasmus Hald 解释。</p><p><strong>用 OKR 管理 220 个产品团队，还要订定愿景和产品蓝图</strong></p><p>目前乐高集团有 220 多个产品团队，每当有一项数位服务或数位功能的需求，就会视为是一项产品来开发，有些是用于顾客的产品，也有不少是内部数位团队自己所用的产品，例如 API 管理平台、API 探索工具，都是内部自己用的数位产品。</p><p>每一个产品都会指派一位产品经理和负责的产品团队。一个产品团队大约 10 人规模，除了产品经理，开发工程师，还会有一位工程经理，以及负责技术管理的首席工程师。「设立首席工程师的职位，是 IT 职涯发展中很重要的一件事。」Rasmus Hald 表示。</p><p>对于这些产品团队，乐高采取 OKR（目标关键成果）管理模式。每个团队不只订出每一季的目标和关键产出成果，还要建立自己产品的长期愿景以及一套产品发展蓝图。</p><p><strong>产品团队有自己的预算，对自己的成本负责</strong></p><p>乐高没有采用大规模敏捷框架或是设立一个 PMO 专案办公室来统筹管理，主要透过敏捷流程每一次的冲刺来迭代开发任务，不同产品团队都采取同样的敏捷开发模式。另外，乐高则对产品团队采取 TCO（Total Cost of Ownership，整体拥有成本）策略，让每个团队都有自己的 IT 预算，并由产品团队自己对自己的成本负责。每个产品团队都有自己的使用者团体，包括使用产品的小孩和付钱买单的父母，不只顾客，使用者团队还会找来经销商和其他同事提供意见，这是他们快速尝试不同创新实验的关键之一。</p><p>为了支援这样的多产品团队开发模式，在技术面，乐高集团的原则是尽可能提高 API、云的使用来减少技术债，也要强化资料基础建设，并将各种 IT 和开发工具系统化，并采取了松耦合的容器化技术架构。</p><p><strong>乐高 AP 优先上云，但也打造自家 K8s 边缘云来支援工厂地端需求</strong></p><p>在云端优先战略上，乐高集团希望能尽可能减少技术蓝图中的长尾技术，例如减少或少用老旧技术，大型主机等。目前乐高集团还有一座传统的实体资料中心，目前只用了 20% 的空间，他们决定不再租用代管的主机，改为购买公云业者的服务，来简化实体设备维护的复杂度。&nbsp;</p><p>不只是一昧上云，乐高的优先上云策略还会聚焦「云+端」的能力，没有采取全上云的考量，Rasmus Hald 坦言，因为全世界的乐高积木都是由乐高集团旗下工厂生产和包装，可是，有些积木工厂的地点，位于资讯基础设施不够完善的国家或地区，当地的网路连线能力可能不佳，无法透过公有云来支援这些工厂的内部运作，得靠地端的机房来维运。因此，乐高集团自己用 K8s 打造了一朵边缘云环境，可以不少到这些工厂的地端机房中，来支援这一类工厂的地端执行需求，他们所用的各种应用，也大多透过 API 呼叫，因此，可以很容易从云端切换到地端边缘云上的系统来接手提供落地工厂的 AP 需求。</p><p>因为要维持这些实体主机和资料中心的成本越来越贵，所以，乐高集团的策略是，在成本太昂贵之前，尽早将工作负载搬到云上。「 除了实体工厂需要的本地端边缘运算需求之外，其他应用都会上云。」Rasmus Hald 指出。</p><p>将 AP 上云时，乐高集团还会特别留意一件事，避免像在云端管实体机房的作法，而是改采用多租户架构的云端管理方式，让不同的 AP 拥有各自的公云帐号，而且，每一个上云的 AP，也由这些 AP 各自的开发团队来自己负责维运。另外，乐高集团对于 AP 的管理，也采取高度自动化的集中式治理，并指派一个产品团队负责打造云端治理的相关工具。</p><p><strong>彻底实践「自己打造的 AP，自己执行」原则，甚至不惜重构资料库架构</strong></p><p>「想要实现自己打造自己执行（You build it ,you run it.）这一点其实不容易，容易，但这么做，才能真正松绑产品团队的能力，要让产品团队有速度，就要这样做。」他强调。为了彻底实践这一点，甚至乐高有产品团队无法管理自己的资料库，乐高也不惜改变这个产品的资料架构，就是要能让产品团队自己管。如此一来，才可以真正打破团队和产品之间的相依性。甚至，乐高每一个产品团队都有自己的 VM，自己连线到网际网路，将不同的产品完全切开，尽可能让不同产品之间没有关联。</p><p>在选择公云业者上，乐高会避免押宝单一业者，采取跨云战略，目前乐高集团采用了 AWS 和微软的 Azure，「公云业者具有超大规模的创新能力和健康技术生态圈，和不同的公云结盟，可以降低对单一供应商的风险。」乐高集团这位云端部门的负责人 Rasmus Hald 解释他们的考量。</p><p><strong>乐高集团实践 API 优先战略的四大准则</strong></p><p>对乐高这种由产品团队负责开发和维运的模式，除了上云优先战略之外，技术架构面的关键是 API 优先战略。Rasmus Hald 表示，乐高对于 API 的运用也有一套自己的准则，第一个原则是，每一只 API 都必须达到全球可用的能力，可以在全世界各地呼叫来使用，来支援乐高集团在全球的业务发展。其次，API 设计也必须是考虑对外公开使用的设计，可以接受来自外部、第三方应用的呼叫，而不是只设计给内部使用。另外，每一个 API 都必须可以探索，也就是可以让开发者找得到。</p><p>最后一项准则是，乐高会要求每一只 API 都要订定明确的规格和使用条款，例如每一只 API 都会订出 SLA 服务水准，而且全都白纸黑字写成文件，还会订定 API 版本控管方式，每当版本升级、淘汰时都会发送相关通知给利害相关人。所有 API 都会遵循一套 API 资料架构（Schema）来设计，上架前都会进行架构分析来确保 API 的品质，乐高也有自己的 API 即时品管机制（API Linting），确保 API 的呼叫和使用都符合所订定的规格。Rasmus Hald 提醒，API 的 SLA 中特别要留意，必须定义 API 的弃用情况，才能让 API 日后有需要时可以淘汰。</p><p><strong>打造开发者入口网站，成为 2 千工程师每天必看网站</strong></p><p>为了让 2 百多个产品团队的开发人员，都可以很方便取用到这些 API，乐高集团打造了一个开发者入口网站，称为 Baseplate ，这是 2 千人数位团队成员，每天上班要打开的网页。</p><p>Baseplate 首页采取了卡片式的设计，开发者可以将自己常用的功能卡片或仪表板卡片放到首页上，方便快速浏览，开发人员甚至可以自订自己的卡片。这个开发者入口网站上提供了所有产品团队的各种产品清单、所以可以用的 API、相关的技术文件或参考资料，辅助开发或维运的各种系统工具。最近有哪些新的 API 或新功能异动，都会在开发者入口上发布最新通告。</p><p>产品团队所开发的每一项产品，可能是业务团队需要的功能，或是数位团队自己的工具或服务，会上架到开发者入口网站上。像是乐高用商用 API 管理平台 Kong 打造了一款 API 管理服务，这就是其中一项他们的产品，</p><p>每个产品都有自己的产品介绍主页，列出这个产品的负责团队，有哪些相关的文件，这个产品被哪些 AP 使用，甚至是这个产品用了哪些公云服务以及公云帐号，也会提供 VM 快照，方便部署到本地端环境中。</p><p><strong>特别重视 API 探索的设计，来提高开发者体验</strong></p><p>乐高在这个开发者入口网站上，对于 API 探索的设计，也花了不少著墨。截至 2023 年底，共有 239 只 API，提供全文检索相关文件和规格，开发者也可以快速列出自己负责的 API，也能用星号来标记出常用 API，打开 API 主页，有相关的规格介绍和文件连结，开发者点一个按钮，就可以直接申请这个 API 的存取授权，相当简单。</p><p><strong>为了降低开发者的认知负担，乐高开发者入口网站特别重视 API 探索的方便性设计</strong></p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/API%E6%8E%A2%E7%B4%A2-%E5%9C%96%E7%89%87%E4%BE%86%E6%BA%90-Lego.png" referrerpolicy="no-referrer"></p><p><strong>去年开始用 OpenAI 打造开发者 AI 助手</strong></p><p>去年底，Rasmus Hald 还用 Open AI 的服务，打造了一个开发者 AI 助手名为乐高 ChatAI，可以摘要乐高开发者入口网站上的所有文件，来回答开发者的开发问题或提供建议等，也可以询问 AI 助手，如何使用特定某一支 API，而不用自己花时间阅读完整的说明文件。</p><p><img alt="" src="https://s4.itho.me/sites/default/files/images/%E6%A8%82%E9%AB%98ChatAI.png" referrerpolicy="no-referrer"></p><p>乐高集团从 2021 年开始，为了建立想要的商业敏捷力，花了 2 年大力推动数位团队的转型，拥抱云端优先、API 优先战略，这个开发者入口网站正是强化数位团队战力的成果。虽然，Rasmus Hald 没有明说，但乐高集团数位团队大改造的过程，也正是一种平台工程的实践。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161410</guid>    <link>https://www.ithome.com.tw/news/161410</link>    <author>    <![CDATA[王宏仁]]>    </author>    <category>AI</category>    </item>    <item>    <title>    <![CDATA[Google 公布开源 AI 模型 Gemma，支援多种框架、可跑在笔电上]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0222-gemma_open_models_based_on_gemini_google-960.jpg?itok=t0JytRfM" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"><div class="field-label">图片来源:&nbsp;</div><div class="field-items"><div class="field-item even"><p>Google</p></div></div></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>Google 继上周公布大型语言模型（large language model，LLM）<a href="https://www.ithome.com.tw/news/161315" target="_blank">Gemini 1.5 版</a>后，本周再公布<a href="https://blog.google/technology/developers/gemma-open-models/" target="_blank">开源 AI 模型 Gemma</a> 2 个版本，让开发及研究人员在云端、资料中心甚至笔电上自建与执行 AI 模型。</p><p>Gemma 是一轻量开源模型家族，由 Google DeepMind 及 Google 其他团队开发，它是以开发 Gemini 模型相同的研究和技术为基础打造而成。Gemma 名称源自拉丁语「gemma」，意思是「宝石」。开源的 Gemma 有二个版本，名为 Gemma 2B 及 7B，Google 并释出其他协助开发、协同及负责任使用的工具。Gemma 今日已在全球上线（<a href="http://ai.google.dev/gemma" target="_blank">ai.google.dev/gemma</a>）。</p><p>除了 Gemma 开源模型，Google 最新 AI 模型 Gemini 也在今日全面上线。</p><p>Google 强调，Gemma 和 Gemini 采用相同技术与基础架构元件，这使得 Gemma 2B 及 7B 效能超越其他同样规模的开源模型。Gemma 在数项标竿测试上，也超越更大的模型。根据<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf" target="_blank">Google 提供的数据</a>，不论在推论、数学、撰写程式上，Gemma 7B 都超越 Llama 2 7B，而在多项数据上，也超越开源模型 Mistral 7B。</p><p class="rtecenter"><img alt="" src="https://s4.itho.me/sites/default/files/images/0222-Google-Benchmark_chart-V2(1).png" style="width: 509px;" referrerpolicy="no-referrer"></p><p><span style="font-size:14px;"><span style="color:#696969;">图片来源_Google</span></span></p><p>Gemma 预训练模型及依指示微调（instruction-tuned）后的模型，可直接执行于开发人员的笔电或工作站、桌机、或者 Google Cloud 的 Vertex AI 和 Google Kubernetes Engine（GKE）上。VertexAI 上有广泛 MLOps 工具，内建多种微调选项及一键部署。Google 表示，不论是代管的 Vertex AI 工具或自行管理的 GKE，都支援客制化，包括能部署到各种 GPU、TPU、和 CPU 等基础架构平台上。</p><p>Gemma 支援多种工具和系统，允许开发人员和企业以自有资料微调 Gemma。Google 提供的推论和监督式微调参考实作工具支援多种主要框架，包括 Kera 3.0、原生 PyTorch、JAX 和 Hugging Face Transformers。</p><p>在硬体方面，Gemma 已针对多种 AI 硬体平台进行过优化，除了 Google Cloud TPU 外，Google 也和 Nvidia 合作，以便确保 Nvidia GPU 为基础的云端、本地部署资料中心、到 RTX AI PC 上具备高执行效能。</p><p>Google 强调 Gemma 是根据其安全与负责任的 AI 原则设计。为了确保 Gemma 预训练模型的安全与稳定，研发团队使用自动化方法筛选掉资料集中的个资及其他敏感资讯，也使用微调及基于人类反馈的强化式学习（reinforcement learning from human feedback，RLHF）确保模型符合负责任行为。同时为了解及降低 Gemma 模型的风险，Google 也实行严谨的评估，包括红队演练、自动化威胁测试及模型的危险活动能力评估。为让外部用户进行负责任 AI 的评估，Google 昨日也公布新的<a href="https://ai.google.dev/responsible?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=explore-responsible&amp;utm_content=&amp;hl=zh-tw" target="_blank">负责任生成式 AI 工具包</a>，包括可以简单范例建立安全分类器的工具、模型除错及 Google 分享的负责任模型开发与部署指引。</p><p class="rtecenter"><a href="http://ai.google.dev/responsible?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=explore-responsible&amp;utm_content=&amp;hl=zh-tw" target="_blank"><img alt="" src="https://s4.itho.me/sites/default/files/images/0222-Google-Responsible%20Generative%20AI%20Toolkit.png" style="width: 600px;" referrerpolicy="no-referrer"></a></p><p>为方便开发人员开始使用 Gemma，Gemma 可整合 Kaggle、Colab notebook 常见工具如 Hugging Face、MaxText、Nvidia MeMo 及 TensorRT-LLM。为吸引开发人员使用 Gemma，Google 提供 Kaggle notebook、Colab 免费方案，以及 300 美元 Google Cloud 点数。Google 甚至提供高达 50 万美元等值 Google Cloud 点数，供研究人员申请执行专案。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161409</guid>    <link>https://www.ithome.com.tw/news/161409</link>    <author>    <![CDATA[林妍溱]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[Rust 开发者担心语言越变越难，甚至有 20% 受访者希望放慢新功能开发速度]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/2255_-_2023_annual_rust_survey_results_-_rust_blog_-_blog.rust-lang.org_.jpg?itok=t0OWq_2m" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p><a href="https://blog.rust-lang.org/2024/02/19/2023-Rust-Annual-Survey-2023-results.html">Rust 调查团队释出针对 Rust 社群的 2023 年调查报告</a>，显示开发者越来越愿意在工作上使用 Rust，而主要原因是 Rust 高安全和高效能等特性。随著开发者采用 Rust 的程度提升，对 Rust 的发展忧虑也随之增加，有 43％受访者担心 Rust 变得太复杂，甚至有 20％受访者希望 Rust 开发团队放慢新功能开发脚步。</p><p>调查报告显示，受访者将 Rust 用于工作上的比例逐年上升，2023 年的受访者中有 34％在大部分的工作中使用 Rust，相较于 2022 年增加了 5 个百分点，而这些将 Rust 用于工作的受访者，其主要原因都是希望可以建立相对正确且没有错误的程式，比例高达 86％，而第二常见的原因则是看重 Rust 的高效能，比例也有 83％。</p><p class="rtecenter"><img alt="" src="https://s4.itho.me/sites/default/files/images/why-you-use-rust-at-work.png" style="width: 580px;" referrerpolicy="no-referrer"></p><p>79％的受访者表示 Rust 的确协助企业实现目标，这相较于 2022 年增加了 7 个百分点，77％的受访者还表示，企业可能会在未来继续使用 Rust。就技术层面而言，Rust 似乎在创建伺服器后端、网页和网路服务，以及云端技术方面特别受到欢迎。整体而言，用户对于 Rust 的高效能、可控性和安全性特别有信心。</p><p>Rust 发展至今仍存在许多挑战，约有 43％的受访者担心 Rust 变得过于复杂，虽然这个问题一直存在，不过显然社群更焦虑了，2023 年的数字较 2022 年高出了 5 个百分点。还有 42％的受访者担心 Rust 没有受到科技产业广泛采用，而 2023 年有 32％的受访者最担心的议题，是 Rust 开发者和维护者没有获得足够的支援，较 2022 年上升了 6 个百分点。</p><p>开发者对 Rust 发展的关心也转化成为了担忧，官方提到，他们发现完全不关心 Rust 未来发展的受访者明显减少，2022 年为 30％而 2023 年下降至 18％。不过有趣的是，其中也有 20％的受访者希望 Rust 可以放慢新功能开发速度，而这可能与有 43％受访者担心 Rust 变得过于复杂有关，也就是说，开发者可能认为 Rust 快速发展，会导致语言变得难以掌握。</p><p>2023 年 Rust 开发者最想要 Rust 开发团队实作或改进的功能，依序是 Traits、const 执行以及非同步功能。此外，开发者最常遇到困难的领域，包括了非同步、Traits 以及借用检查器（Borrow Checker）等 Rust 中较为复杂且难以理解的概念，许多 Rust 开发者在学习使用这些功能常会遭遇挑战。</p><p class="rtecenter"><img alt="" src="https://s4.itho.me/sites/default/files/images/which-features-do-you-want-stabilized.png" style="width: 580px;" referrerpolicy="no-referrer"></p><p>在 Rust 生态系方面，最多受访者用来开发 Rust 程式的作业系统是 Linux 高达 69.7％，其次是 33.5％的 macOS 和 31.9％的 Windows，2023 年使用 WSL 开发 Rust 的受访者，与 2022 年相比少了 1.2％。而受访者最爱用的 IDE，第一名仍是 VS Code 有高达 61.7％的受访者使用，第二名则是 vi/vim/neovim 有 31％，而第三名则是 2023 年才释出的 Rust 专用 IDE Rust Rover。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161407</guid>    <link>https://www.ithome.com.tw/news/161407</link>    <author>    <![CDATA[李建兴]]>    </author>    <category>新闻</category>    </item>    <item>    <title>    <![CDATA[微软推 VisualStudio.Extensibility SDK，新扩充套件安装不再需要重启 Visual Studio]]>    </title>    <description>    <![CDATA[<header><div class="img-wrapper"><div class="field field-name-field-image field-type-image field-label-hidden"><div class="field-items"><div class="field-item even"><img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/2254_-_visualstudio.extensibility_install_extensions_without_restarting_vi_-_devblogs.microsoft.com_.jpg?itok=3WtJTSx8" width="960" height="420" alt="" referrerpolicy="no-referrer"></div></div></div></div></header><div class="row-fluid"><div class="contents-wrap"><div class="content"><div class="side-extra"></div><div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>微软推出新的<a href="https://devblogs.microsoft.com/visualstudio/visualstudio-extensibility-17-9/">VisualStudio.Extensibility SDK 公开预览版</a>，可供开发者创建独立于 Visual Studio 程序运作的扩充套件，以提高其效能和可靠性。VisualStudio.Extensibility SDK 具有一些特殊功能，包括让开发者可在 Visual Studio 市集发布扩充套件，并且更容易配置扩充套件、查询专案系统，和创建视觉化工具。</p><p>开发者以新版本 VisualStudio.Extensibility SDK 建立扩充套件，会生成一个独立的 VSIX 套件，开发者可以在本机端共用 VSIX 套件，供其他开发团队成员直接安装，或是也可以将其发布到 Visual Studio 市集中，与网路上其他开发者共享。</p><p>VisualStudio.Extensibility SDK 另一大特点是开发者安装扩充套件，不再需要关闭并重新启动 Visual Studio，微软说明，新提供的热载入功能，适用于以 VisualStudio.Extensibility SDK 编写的所有程序外扩充套件。官方会在 Visual Studio 市集上，特别标记支援热载入的扩充套件，方便开发者辨识。</p><p>现在 VisualStudio.Extensibility SDK 也让配置扩充套件、查询专案系统，和创建除错器视觉化工具更直觉简单。开发者可以直接在程式码中使用强类型类别和属性配置扩充套件，如此可减少手动维护 VSIX 清单档案的需求，也能利用 IntelliSense 快速填写所需要的配置值。此外，新的 SDK 支援创建非模态（Non-Modal）可在 IDE 中自由移动的除错器视觉化工具，非模态视窗让用户可以同时存取和操作其他介面元素，提高除错效率和灵活性。</p><p>开发者可以开始将语言伺服器协定（Language Server Protocol，LSP）整合到扩充套件中，如此便可以创建一个语言服务提供工具操作语言服务。语言服务提供工具支援配置属性，可用于控制语言服务适用的文件类型。</p><p>而 VisualStudio.Extensibility 透过经强化的查询 API 加入许多新功能，包括建置、重新载入、重新命名等专案操作，以及创建、移除解决方案等解决方案操作功能，同时还可以查询、创建和移除资料夹和启动专案，这些新功能让扩充套件能够更细致地与 Visual Studio 专案系统互动。</p></div></div></div><div></div></div></div></div>]]>    </description>    <pubDate>Wed, 21 Feb 2024 16:00:00 GMT</pubDate>    <guid isPermaLink="false">https://www.ithome.com.tw/news/161396</guid>    <link>https://www.ithome.com.tw/news/161396</link>    <author>    <![CDATA[李建兴]]>    </author>    <category>新闻</category>    </item>    </channel>    </rss>
