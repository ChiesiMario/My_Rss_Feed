<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 14 Nov 2023 13:55:22 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Milvus 上新！全新 Range Search 功能，可精準控制搜索結果]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Range Search 功能誕生於社區。</p><p>某天，一位做系統推薦的用戶在社區提出了需求，希望 Milvus 能提供一個新功能，可以返回向量距離在一定範圍之內的結果。而這不是個例，開發者在做相似性查詢時，經常需要對結果做二次過濾。</p><p>為了幫助用戶解決這一問題，Milvus 推出了全新功能—— Range Search（範圍搜索）。本文將帶各位詳解這一新功能，包括 Range Search 的基本介紹、使用場景及其背後的技術細節。</p><h2>01.什麼是 Range Search？</h2><p>顧名思義，Range Search 即範圍搜索。不同於 KNN Search 返回最相似的 TOP-K 個結果，Range Search 會返回向量距離落於某一區間的 TOP-K 個結果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b4b328c7dc3151d09d501d9cc11ac3e0591.png" alt="" referrerpolicy="no-referrer"></p><p>那麼，何時選擇 Range Search 而非 Top-K 搜索？</p><p>Range Search 最典型的應用場景就是推薦系統。比如商品推薦，一個好的推薦系統，返回的應該是與用戶點擊的商品有一定相似度，但又不太相似的結果。太相似或太不相似的推薦都會導致推薦效果不盡如人意。</p><p>在有 Range Search 功能之前，做推薦系統的用戶只能先執行一次 KNN Search，再在 Milvus 系統之外對查詢結果進行二次過濾。如今，有了 Range Search 功能，他們可以直接調用 Range Search，一次性得到所需要的結果。</p><p>Range Search 新增了 2 個參數，分別是：</p><ul><li><p>radius（半徑） - 指相似性的外邊界</p></li><li><p>range_filter（範圍過濾器） - 指相似性的內邊界</p></li></ul><h2>02.Range Search 的技術實現細節</h2><p>接下來，我們深入 Range Search 功能的架構和算法，探討其優勢、侷限性以及 Range Search 與第三方算法庫集成。</p><p>Range Search 重用了現有的搜索流程，二者在上層所有數據通路幾乎完全是一樣的。以下是接收到搜索請求時所採取的步驟：</p><ul><li><p>SDK 接到一個用戶的查詢請求，在 search param 中包含了 radius 和 range_filter 信息；</p></li><li><p>proxy 在收到這個查詢請求後，生成一個 SearchTask 傳給 querynode；</p></li><li><p>querynode 在收到 SearchTask 後，通過 cgo 調用 segcore 的 Search 接口；</p></li><li><p>segcore 會解析 search_param 中帶的參數，如果有 radius，則調用 knowhere::RangeSearch；</p></li><li><p>knowhere 再根據索引類型調用到對應的第三方庫的 range_search 函數。</p></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-312561d846ee7db2cdde2205ba34b589dd6.png" alt="" referrerpolicy="no-referrer"></p><p>目前，所有的第三方庫索引都只支持單邊 Range Search，也就是隻接收一個參數 radius，而且返回的結果是全量未排序的結果。下表概述了不同索引類型的 Range Search 策略「</p><p><img src="https://oscimg.oschina.net/oscnet/up-f9423ca4e4532ca21a092bf739084b2aa65.png" alt="" referrerpolicy="no-referrer"></p><p>對於 binary 類型的索引，HAMMING 和 JACCARD 全部都支持 Range Search，SUBSTRUCTURE/SUPERSTRUCTURE 由於返回值是 true/false，不滿足 Range Search 的語義，所以不支持 Range Search。其餘 float 類型索引，對於 L2/IP/COSINE 全部支持 Range Search。</p><p>下表是所有支持 Range Search 的索引類型和 metric type：</p><p><img src="https://oscimg.oschina.net/oscnet/up-4cd875d0cf7b27184d6fe91878755240514.png" alt="" referrerpolicy="no-referrer"></p><h2>03.Range Search 使用方法</h2><p>如需使用 Range Search，只需要修改搜索請求中的搜索參數。接下來我會講一下的詳細使用指南，在指南的最後還提供了 Python 示例代碼。</p><h3>開始前</h3><p>請確保已安裝並運行 Milvus。</p><p>請確保已創建 1 個 Collection，併為該 Collection 創建索引。</p><h3>Range Search 參數</h3><ul><li><p>radius：必要參數。決定搜索請求將執行 Range Search 還是 KNN Search。</p></li><li><p>range_filter：可選參數。如果設置該參數，函數將對結果進行二次過濾。</p></li></ul><p>通過上述兩個參數，我們可以根據不同應用場景和需求微調 Range Search 的行為。以下為示例代碼：</p><pre><code class="language-plaintext">default_index = {"index_type": "HNSW","metric_type": "L2","params": {"M":48,"efConstruction":500}
}
collection.create_index("float_vector", default_index)
search_params = {"metric_type": "L2","limit": TOPK,
                 "params": {"ef":32,"range_filter":1.0,"radius":2.0}
}
res = collection.search(vectors[:nq], "float_vector", search_params, limit)
</code></pre><h2>04.參數檢查</h2><p>下表列出了所有 metric type 對應的 radius 合法值範圍：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3931e0822befd3dcc21a619d6051825e253.png" alt="" referrerpolicy="no-referrer"></p><p>由於不同 metric type 對應的 radius 合法值範圍不同，Milvus 不會檢查 radius 的合法性，而是隻檢查 radius 和 range_filter 的相對合法性：</p><ul><li><p>對於 L2/Hamming/Jaccard，range_filter &lt; radius</p></li><li><p>對於 IP/Cosine，range_filter &gt; radius</p></li></ul><h2>05.總結</h2><p>Milvus 的 Range Search 功能不僅限於推薦引擎，還可以廣泛應用在內容匹配、異常檢測和 NLP 搜索等任務中。通過利用 radius 和 range_filter 兩個參數，用戶可以精準定製查詢，滿足不同用例的需求。</p><p>Range Search 現已正式登陸 Zilliz Cloud Beta 版！如需體驗 Range Search 功能，請將 Zilliz Cloud（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fcloud%EF%BC%89" target="_blank">https://zilliz.com.cn/cloud）</a> 集羣升級至 Beta 版或下載 Milvus 2.3.x（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmilvus.io%2Fdocs%2Finstall_cluster-milvusoperator.md%EF%BC%89%E3%80%82%E5%8F%A6%E5%A4%96%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%A4%A7%E5%AE%B6%E5%9C%A8%E4%BD%BF%E7%94%A8" target="_blank">https://milvus.io/docs/install_cluster-milvusoperator.md）。另外，如果大家在使用</a> Range Search 功能中遇到任何問題或者建議，歡迎向我們反饋！</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 10:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10143103</guid>
            <link>https://my.oschina.net/u/4209276/blog/10143103</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年收入最高的 10 種編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在過去的一年時間裏（2022 年 10 月 1 日到 2023 年 10 月 1 日） ，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Fblog%2Ftop-10-highest-paid-programming-languages%2F" target="_blank">DevJobsScanner</a> 分析了來自世界各地的超過 1000 萬份開發工作機會，以瞭解市場以及最熱門、薪酬最高的編程語言。值得注意的是，本項研究只關注了來自美國的職位。在總共 1000 萬個開發工作崗位中，有 130 萬個有工資。在這 130 萬個職位中，有 23 萬個職位屬於編程語言類。在這 23 萬個職位中，約有 8.6 萬個職位來自美國。</p><h4><strong>10 - Java</strong></h4><p><img height="144" src="https://oscimg.oschina.net/oscnet/up-da0d9c70bef29cef379fa443218b09df6dd.png" width="300" referrerpolicy="no-referrer"></p><p>Java 位列第十。DevJobsScanner 指出，Java 的工作機會大多要求份非常豐富的經驗，Spring 等 Java 框架也是該行業的高薪職位。Java 開發人員的平均年薪約為 11.8 萬美元。</p><ul style="margin-left:0; margin-right:0"><li>平均工資：~$118k</li><li>薪資中位數：$117k</li><li>發現的工作數量（帶薪水）：23K 個</li></ul><p>查看具體的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-java-jobs%2F" target="_blank">&nbsp;Java 職位</a>。</p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><strong><span style="color:#000000">9-Python</span></strong></h4><p><img height="91" src="https://oscimg.oschina.net/oscnet/up-9bb3fb64562542db24cf36832f6b43d5966.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Python 是當今最流行的語言之一，也是排名第九的高薪職位。Python 是一種 non-typed 的高級語言。它擁有全方位的實用工具，從腳本和工具到使用 Django 框架編寫整個 Web 應用程序。該語言多被用於數據科學。</span></p><p><span style="color:#000000">調查結果顯示，雖然 Python 開發人員的平均工資為每年 12.5 萬美元，但有些薪資已經達到了每年 50 萬美元。</span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">平均工資：~$125K</span></li><li><span style="color:#000000">薪資中位數：$120k</span></li><li><span style="color:#000000">發現的工作數量（帶薪水）：14K 個</span></li></ul><p>&nbsp;查看具體的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-java-jobs%2F" target="_blank">&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-python-jobs%2F" target="_blank">Python 職位</a>。</p><h4><strong>8 - Swift</strong></h4><p><img height="123" src="https://oscimg.oschina.net/oscnet/up-3a30ea9fb6d3c66be2a2ad231125f7a79ba.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Swift 是，蘋果公司開發的一種現代通用語言。它有多種用途，但最常見、流行的用途是開發 iOS 和 Mac 應用程序。Swift 開發人員的平均年薪為 12.7 萬美元。</span></p><ul style="margin-left:0; margin-right:0"><li>平均工資：~$127k</li><li>薪資中位數：$125k</li><li><span style="color:#000000">發現的工作數量（帶薪水）</span>：174 個</li></ul><p>查看具體的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-swift-jobs%2F" target="_blank">Swift 職位</a>。</p><h4><strong>7 - Go</strong></h4><p><img height="120" src="https://oscimg.oschina.net/oscnet/up-963f146d826e179eefe3c93c441a54055da.png" width="300" referrerpolicy="no-referrer"></p><p>Go 語言由&nbsp;Google 團隊成員於 2007 年推出，一直廣受歡迎。它簡單、易用，能快速完成任務。Go 深受 C 語言的影響，但在內存安全、垃圾收集和結構類型方面也有重大改進。</p><ul style="margin-left:0; margin-right:0"><li>平均工資：~$130k</li><li>薪資中位數：$128k</li><li><span style="color:#000000">發現的工作數量（帶薪水）</span>：1.2K 個</li></ul><p>查看具體的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-go-jobs%2F" target="_blank">Go 職位</a>。</p><h4><strong>6 - Ruby</strong></h4><p><img height="128" src="https://oscimg.oschina.net/oscnet/up-21b412b86bcb795c62b42a25bdd199348fd.png" width="300" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Ruby 語言已經流行多年並且現在仍然很流行。調查顯示，Ruby 需求相當高，而且大部分都是高薪。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Ruby 主要流行於 Web 開發，與著名的 Ruby on Rails 框架結合使用。它也有一些其他的實用工具，從腳本和原型設計到遊戲開發（使用 DragonRuby）。DevJobsScanner 認為，鑑於&nbsp;Ruby 的多樣性，學習該語言永遠不會是一個糟糕的選擇；它也是一種高級語言，可以快速開發應用程序（類似於 Python）。</span></p><blockquote><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Ruby 開發人員的工資中位數（13.6 萬美元）超過了平均工資（13.2 萬美元）。這表明對中級和高級 Ruby 專業人員的強勁需求，説明掌握 Ruby 方面的專業知識往往能帶來高於平均水平的薪酬。</span></p></blockquote><ul style="margin-left:0; margin-right:0"><li>平均工資：~$132k</li><li>薪資中位數：$136k</li><li>找到的工作數量（帶薪水）：3.4K 個</li></ul><p>&nbsp;查看具體的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-ruby-jobs%2F" target="_blank">Ruby 職位</a>。</p><h4><strong>5 - Scala</strong></h4><p><img height="146" src="https://oscimg.oschina.net/oscnet/up-551dddb9d865060c07593f99b8a5b10d1e9.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">排在前五位的是 Scala。Scala 是一種結合了面向對象和函數式編程的高級語言。它可以編譯成 Java 字節碼，並在 Java 虛擬機（JVM）上運行。它的設計初衷是為瞭解決 Java 所面臨的一些"缺陷"和批評。它擁有一個強大的愛好者社區，以及良好的周邊庫，可以輕鬆上手。</span></p><p><span style="color:#000000">雖然 Scala 開發人員的平均年薪為 13.5 萬美元，但有些職位的年薪最高可達約 40 萬美元。</span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">平均工資：~$135k</span></li><li><span style="color:#000000">薪資中位數：$130k</span></li><li><span style="color:#000000">找到的工作數量（帶薪水）： 533 個</span></li></ul><p>查看具體的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-scala-jobs%2F" target="_blank">Scala 職位</a>。</p><h4><strong>4 - C/C++</strong></h4><p><img height="179" src="https://oscimg.oschina.net/oscnet/up-6e86e1cf5b0d7679b684b0158bb78cd21ed.png" width="200" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">C/C++ 穩居前 4 位，平均年薪約為 13.6 萬美元。 C++ 在行業中的應用非常廣泛，視頻遊戲、服務器、數據庫、空間探測器等許多領域都可以找到 C++ 的身影。區塊鏈生態系統中也大量使用 C++，比特幣或 Solidity 智能合約語言均完全由 C++ 編寫。</span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">平均工資：~$136K</span></li><li><span style="color:#000000">薪資中位數：$125k</span></li><li><span style="color:#000000">找到的工作數量（帶薪水）：3K 個</span></li></ul><p><span style="color:#000000">&nbsp;查看具體的</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-c%2B%2B-jobs%2F" target="_blank">&nbsp;C/C++ 職位</a>。</p><h4><strong>3-ABAP</strong></h4><p><img height="124" src="https://oscimg.oschina.net/oscnet/up-c183b86954e313b623cd8417d793c87f6ba.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">ABAP 是 2023 年企業資源規劃 (ERP) 生態系統中最有價值的語言之一。ABAP 是 SAP 創建的一種高級編程語言，用於在 SAP 平台上開發應用程序。自 20 世紀 80 年代以來，它一直是 SAP 應用程序的支柱，允許自定義開發和修改 SAP 應用程序。</span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">平均工資：~$137k</span></li><li><span style="color:#000000">薪資中位數：$134k</span></li><li><span style="color:#000000">找到的工作數量（帶薪水）：134 個</span></li></ul><p>查看具體的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-abap-jobs%2F" target="_blank">ABAP 職位</a>。</p><h4><strong>2 - Rust</strong></h4><p><img height="141" src="https://oscimg.oschina.net/oscnet/up-d07474ac36e203ae14401437617eca9135b.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Rust 平均薪資約為 15.6 萬美元，且該語言的薪資和受歡迎程度都在持續上升。Rust&nbsp;與 C++ 類似，但具有內存安全或安全併發等更高級的功能，使其成為高性能大型應用程序的完美選擇。該語言最近在 web3/區塊鏈領域頗受歡迎，例如 Solana 合約不是用 Solidity 製作的，而是採用的 Rust。</span></p><p><span style="color:#000000">雖然 Rust 開發人員的平均年薪為 15.6 萬美元，但有些職位的年薪達到了 50 萬美元。</span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">平均工資：~$156k</span></li><li><span style="color:#000000">薪資中位數：$150k</span></li><li><span style="color:#000000">找到的工作數量（帶薪水）：197 個</span></li></ul><p><span style="color:#000000">查看具體的&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-rust-jobs%2F" target="_blank">Rust 職位</a>。</p><h4><span style="color:#000000"><strong>1 - Solidity</strong></span></h4><p><img height="109" src="https://oscimg.oschina.net/oscnet/up-49425fe9eab67498220eef604ab1e04f8fe.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">位居 2023 年薪資排行榜首的是 Solidity，平均薪資為 18.8 萬美元。這門以太坊背後的前團隊發明的語言最近受到了廣泛關注。相關職位的求職者人數少，從而使得薪酬直線上升。Solidity 是一種高級面向對象編程語言。它用於編寫當今大多數區塊鏈中運行的智能合約背後的邏輯。</span></p><p>&nbsp;</p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">平均工資：~$188k</span></li><li><span style="color:#000000">薪資中位數：1$180k</span></li><li><span style="color:#000000">找到的工作數量（帶薪水）：136 個</span></li></ul><p><span style="color:#000000">查看具體的&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Ftop-paid-solidity-jobs%2F" target="_blank">Solidity 職位</a><span style="color:#000000">。</span></p><hr><p><strong>完整列表</strong></p><p><img height="657" src="https://oscimg.oschina.net/oscnet/up-9139be9626b0c984bca34d0c24578038302.png" width="500" referrerpolicy="no-referrer"></p><p><strong>薪資分佈圖</strong></p><p><img height="820" src="https://oscimg.oschina.net/oscnet/up-844c88902e330224b38a8a0448482adf31d.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devjobsscanner.com%2Fblog%2Ftop-10-highest-paid-programming-languages%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 08:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266426/top-10-highest-paid-programming-languages</guid>
            <link>https://www.oschina.net/news/266426/top-10-highest-paid-programming-languages</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國內最大、性能媲美 GPT 3.5，元象開源 650 億參數高性能大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#1f2328; text-align:start"><strong>XVERSE-65B</strong><span>&nbsp;</span>是由深圳元象科技自主研發的支持多語言的大語言模型（Large Language Model），參數規模為 650 億，本次開源的模型為底座模型<span>&nbsp;</span><strong>XVERSE-65B</strong>，主要特點如下：</p><ul><li><strong>模型結構</strong>：XVERSE-65B 使用主流 Decoder-only 的標準 Transformer 網絡結構，支持 16K 的上下文長度（Context Length），能滿足更長的多輪對話、知識問答與摘要等需求，模型應用場景更廣泛。</li><li><strong>訓練數據</strong>：構建了 2.6 萬億 token 的高質量、多樣化的數據對模型進行充分訓練，包含中、英、俄、西等 40 多種語言，通過精細化設置不同類型數據的採樣比例，使得中英兩種語言表現優異，也能兼顧其他語言效果。</li><li><strong>分詞</strong>：基於 BPE（Byte-Pair Encoding）算法，使用上百 GB 語料訓練了一個詞表大小為 100,534 的分詞器，能夠同時支持多語言，而無需額外擴展詞表。</li><li><strong>訓練框架</strong>：訓練中採用 FlashAttention2 加速計算，3D 並行基礎上採用虛擬流水線（virtual pipeline）技術，降低較長流水線和 16k 上下文窗口產生的過高氣泡率，在千卡集羣的峯值算力利用率達到業界前列。同時通過集羣基礎設施運營、資源調度、訓練框架和調度平台協同等持續優化，打造出高穩定、低中斷、強容錯的訓練系統，將每週有效訓練率提升至 98.6%。</li></ul><h4 style="margin-left:0px; margin-right:0px; text-align:left"><span style="color:#000000"><strong>評測結果</strong></span></h4><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><img height="454" src="https://oscimg.oschina.net/oscnet/up-2cd1eb2bb0579c1ae7d9b7cdba455e38df6.png" width="500" referrerpolicy="no-referrer">&nbsp;</span></p><h4 style="text-align:start"><strong>硬件需求</strong></h4><p style="color:#1f2328; text-align:start">下表列出了在 XVERSE-65B 上進行推理和微調所需要的硬件資源：</p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#1f2328; display:block; font-family:-apple-system,BlinkMacSystemFont,&quot;Segoe UI&quot;,&quot;Noto Sans&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; max-width:100%; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:max-content; word-spacing:0px"><thead><tr><th>&nbsp;</th><th>類型</th><th>方法</th><th>內存</th><th>GPU</th></tr></thead><tbody><tr><td style="border-style:solid; border-width:1px">XVERSE-65B</td><td style="border-style:solid; border-width:1px">訓練</td><td style="border-style:solid; border-width:1px">LoRA with ZeRO-3</td><td style="border-style:solid; border-width:1px">1500GB</td><td style="border-style:solid; border-width:1px">8*A800 80G</td></tr><tr><td style="border-style:solid; border-width:1px">XVERSE-65B</td><td style="border-style:solid; border-width:1px">推理</td><td style="border-style:solid; border-width:1px">BF16/FP16</td><td style="border-style:solid; border-width:1px">500GB</td><td style="border-style:solid; border-width:1px">2*A800 80G</td></tr></tbody></table></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 08:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/xverse-65b</guid>
            <link>https://www.oschina.net/p/xverse-65b</link>
        </item>
        <item>
            <title>
                <![CDATA[從 JDK 11 升級到 JDK 17 的最全實踐乾貨]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1><strong>1、前言</strong></h1><p>上篇文章給大家帶來了<a href="https://my.oschina.net/u/4090830/blog/10111749">JDK8 升級 JDK11 的最全實踐，</a>相信大家閲讀後已經對 JDK11 有了比較深入的瞭解。2021 年 9 月 14 日，Oracle 發佈了可以長期支持的 JDK17 版本，那麼從 JDK11 到 JDK17，到底帶來了哪些特性呢？亞毫秒級的 ZGC 效果到底怎麼樣呢？值得我們升級嗎？而且升級過程會遇到哪些問題呢？帶着這些問題，本篇文章將帶來完整的 JDK11 升級 JDK17 最全實踐。</p><h1><strong>2、為什麼升級 JDK17</strong></h1><p><strong>1）長期支持版本</strong></p><p>JDK17 是 Oracle 官方在 2021 年 9 月 14 日發佈的一個長期支持（LTS）版本，意味着它將獲得長期的更新和支持，有助於保持程序的穩定性和可靠性。</p><p><strong>2）性能提升</strong></p><p>更好的垃圾回收器。綜合評估，從 Java 8 升級到 Java 11，**G1GC 平均速度提升 16.1%，ParallelGC 為 4.5%****，**從 Java 11 升級到 Java 17，<strong>G1GC 平均速度提升 8.66%，ParallelGC 為 6.54%</strong>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.optaplanner.org%2Fblog%2F2021%2F09%2F15%2FHowMuchFasterIsJava17.html" target="_blank">基於 OptaPlanner 的用例基準測試表明）</a></p><p>最大的亮點是帶來了<strong>穩定版的 ZGC 垃圾回收器，達到亞毫秒級停頓。</strong></p><p><strong>3）新語法和特性</strong></p><p>Switch 表達式簡化、Text Blocks 文本塊、instanceof 的模式匹配升級和 NullPointerException 提示信息改進等</p><p>4）<strong>支持最新的技術和框架</strong></p><p>Spring framework6 和 Spring Boot3 都默認使用 Java 17 作為最低版本</p><h1><strong>3、升級後壓測效果</strong></h1><blockquote><p><strong>先給出結論：</strong></p><p>1、JDK17 相對於 JDK8 和 JDK11，<strong>所有垃圾回收器的性能都有很明顯的提升，特別是穩定版的 ZGC 垃圾回收器</strong></p><p>2、<strong>不論任何機器配置下，都推薦使用 ZGC</strong>，ZGC 的停頓時間達到亞毫秒級，吞吐量也比較高</p></blockquote><p><strong>我在 JDOS 平台上選擇了不同配置的機器（2C4G、4C8G、8C16G），並分別使用 JDK8、JDK11 和 JDK17 進行部署和壓測。</strong></p><p>整個壓測過程限時 60 分鐘，用 180 個虛擬用戶併發請求一個接口，每次接口請求都創建 512Kb 的數據。最終產出不同 GC 回收器的各項指標數據，來分析 GC 的性能提升效果。</p><p><strong>以下是壓測的性能情況：</strong></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-07-18-46yVgvcZ9YUGOrY9x.png" alt="" referrerpolicy="no-referrer"></p><h1><strong>4、OracleJDK 和 OpenJDK 的選擇</strong></h1><p>2021 年 9 月，Oracle 宣佈 JDK17 可以免費商用，直到下一個 LTS 版本之後繼續提供整整一年，同時 Oracle 將繼續按照自 Java 9 以來的相同版本和時間表提供 GPL 下的 Oracle OpenJDK 版本。</p><p>2023 年 9 月，OracleJDK 發佈了新的 LTS 版本 JDK21，這就意味着從<strong>2024 年 9 月開始，在生產環境使用 OracleJDK17 將需要付費。</strong></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-01-20-01PLCD1wvvcxLRLNv.png" alt="" referrerpolicy="no-referrer"></p><p>參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oracle.com%2Fhk%2Fjava%2Ftechnologies%2Fdownloads%2F%23java17" target="_blank">https://www.oracle.com/hk/java/technologies/downloads/#java17</a></p><p>OracleJDK 和 OpenJDK 這兩個之間沒有真正的技術差別，因為針對 Oracle JDK 構建過程是基於 OpenJDK 的。自從 JDK11 開始，OracleJDK 和 OpenJDK 在功能上基本相同，所以推薦使用 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjdk.java.net%2Farchive%2F" target="_blank">OpenJDK17</a> 或其他開源的 JDK 版本，這些開源版本都是基於 OpenJDK 構建並提供長期支持的,比如：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fadoptopenjdk.net%2F" target="_blank">AdoptOpenJDK</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.redhat.com%2Fproducts%2Fopenjdk%2Foverview" target="_blank">RedHatOpenJDK。</a></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-02-11-19DsSkxKErEDeigz2.png" alt="" referrerpolicy="no-referrer"></p><p>官方參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fjava%2Fpost%2Foracle-jdk-releases-for-java-11-and-later" target="_blank">https://blogs.oracle.com/java/post/oracle-jdk-releases-for-java-11-and-later</a></p><h1><strong>5、JDK11 到 JDK17 帶來了哪些新特性</strong></h1><h3><strong>5.1、JVM 改進</strong></h3><p>1、ZGC 垃圾回收器從實驗性功能更改為<strong>正式產品功能</strong>，從 JDK11 引入以來，經過持續的迭代升級，目前已經足夠穩定。<strong>需要手動開啓，開啓方式：-XX:+UseZGC</strong></p><p>2、G1 垃圾回收器仍然作為默認垃圾回收器，進行改進升級，主要包括可中止的混合收集集合、NUMA 可識別內存分配等</p><p>3、JDK14 開始刪除 CMS 垃圾回收器</p><p>4、JDK14 開始棄用 ParallelScavenge 和 SerialOld GC 的組合使用</p><p>5、JDK15 禁用偏向鎖，默認禁用：-XX:+UseBiasedLocking</p><p>6、NullPointerException 提示信息改進</p><p>JDK14 以前的出現 NullPointerException 時，只能定位到所在異常行，無法定位具體是哪個變量。改進後的 NullPointerException，可以清晰描述具體變量，提升了空指針異常的可讀性。</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-27-10-50TTuaDvegXKr9SAo.png" alt="" referrerpolicy="no-referrer"></p><h3><strong>5.2、新語法特性</strong></h3><h4><strong>5.2.1、Switch 表達式簡化</strong></h4><p>switch 表達式帶來了簡化式的編碼方式，提供了新的分支切換方式，即 -&gt; 符號，右則表達式方法體在執行完分支方法之後，自動結束 switch 分支，同時 -&gt; 右則方法塊中可以是表達式、代碼塊或者是手動拋出的異常</p><p>參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F361" target="_blank">https://openjdk.org/jeps/361</a></p><p><strong>傳統寫法</strong></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-26-17-22rnaBICUHwCBlYZf.png" alt="" referrerpolicy="no-referrer"></p><p><strong>新寫法</strong></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-27-10-18Z48ZmbyE6jT10uWqP.png" alt="" referrerpolicy="no-referrer"></p><h4><strong>5.2.2、Text Blocks 文本塊</strong></h4><p>參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F378" target="_blank">https://openjdk.org/jeps/378</a></p><p>通過編寫 """，來減少轉義字符和換行符，達到簡化代碼和提高代碼可讀性的目的</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-26-18-16tXnkRnYOGkQhTMS.png" alt="" referrerpolicy="no-referrer"></p><h4><strong>5.2.3、Record 類型</strong></h4><p>參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F395" target="_blank">https://openjdk.org/jeps/395</a></p><p>record 是 JDK 14 引入的關鍵字，用於聲明不可變的數據類。它適用於存儲純粹的值類型數據，如接口傳輸數據、座標點和只讀的日誌記錄。與 lombok 相比，record 簡化了定義純粹數據類型的過程。由於 record 類是不可變的，成員變量只能設置一次且無法更改，無需提供顯式的 setter() 方法。</p><p><strong>1、定義 Point 類，使用關鍵字 record，未定義 get/set</strong></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-25-19-50LjIj50MDXubzNv07.png" alt="" referrerpolicy="no-referrer"></p><p><strong>2、查看編譯後的字節碼文件</strong></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-26-12-05MfRyF9o9FOD120oS.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-26-12-077FA41CoAIm41MkgIY.png" alt="" referrerpolicy="no-referrer"></p><p><strong>3、使用 Point 類</strong></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-26-12-11LdZCsODuD8JpjE0.png" alt="" referrerpolicy="no-referrer"></p><h4><strong>5.2.4、instanceof 的模式匹配升級</strong></h4><ul><li>instanceof 類型判斷再也不需要強制轉換</li></ul><p>參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F394" target="_blank">https://openjdk.org/jeps/394</a></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-25-18-20mhLGcH20q20N25D0a.png" alt="" referrerpolicy="no-referrer"></p><h4><strong>5.2.5、密封的類和接口</strong></h4><p>參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F409" target="_blank">https://openjdk.org/jeps/409</a></p><p>JDK15 開始，引入了 sealed 普通類或接口類，這些類只允許被指定的類或者 interface 進行擴展和實現。</p><p>使用修飾符 sealed，您可以將一個類聲明為密封類。密封的類使用關鍵字 permits 列出可以直接擴展它的類。子類可以是最終的，非密封的或密封的</p><p>比較實用的一個特性，可以用來限制類的層次結構</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-26-19-23EeeAvjyEjufkdfY.png" alt="" referrerpolicy="no-referrer"></p><h4><strong>5.2.6、其他優化和升級</strong></h4><p>感興趣的同學，推薦閲讀 OpenJDK 官方文檔説明，從 JDK11 到 JDK17 的改動： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fprojects%2Fjdk%2F17%2Fjeps-since-jdk-11" target="_blank">https://openjdk.org/projects/jdk/17/jeps-since-jdk-11</a></p><h1><strong>6、升級步驟</strong></h1><h3><strong>6.1、JDK 選擇</strong></h3><p>OpenJDK17 下載：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjdk.java.net%2Farchive%2F" target="_blank">https://jdk.java.net/archive/</a></p><p>行雲鏡像：jdt-base-tomcat/java-jdt-centos7.4-openjdk-17.0.2-tomcat8.0.53</p><h3><strong>6.2、pom 編譯配置升級</strong></h3><p>maven 編譯所需 JDK 升級至 17</p><pre><code>&lt;properties&gt;
    &lt;maven.compiler.source&gt;17&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;17&lt;/maven.compiler.target&gt;
&lt;/properties&gt;

</code></pre><h3><strong>6.3、SpringBoot 升級</strong></h3><p>SpringBoot 版本升級到<strong>2.7.15</strong>，Spring 版本升級為<strong>5.3.29</strong></p><p><strong>為什麼不升級到 SpringBoot3？</strong></p><p>Spring Boot 3.0 最低要求 Java 17，SpringBoot3.0 帶來了很多變化，和 SpringBoot2 差異較大。 考慮到公司很多中間件都是基於 SpringBoot2 構建的，所以此處推薦升級到 SpringBoot2 的最高版本 2.7.15。</p><p><strong>POM 升級</strong></p><pre><code>&lt;parent&gt;
 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
 &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
 &lt;version&gt;2.7.15&lt;/version&gt;
&lt;/parent&gt;

</code></pre><p>也可以通過設置 dependencyManagement 的方式：</p><pre><code>&lt;properties&gt;
    &lt;!-- 框架版本配置--&gt;
    &lt;springboot-version&gt;2.7.15&lt;/springboot-version&gt;
    &lt;springframework.version&gt;5.3.29&lt;/springframework.version&gt;
&lt;/properties&gt;  

&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
            &lt;version&gt;${springboot-version}&lt;/version&gt;
            &lt;scope&gt;import&lt;/scope&gt;
            &lt;type&gt;pom&lt;/type&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-framework-bom&lt;/artifactId&gt;
            &lt;version&gt;${springframework.version}&lt;/version&gt;
            &lt;scope&gt;import&lt;/scope&gt;
            &lt;type&gt;pom&lt;/type&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;

</code></pre><p>參考：</p><p>spring 升級指南： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fwiki%2FSpring-Framework-Versions" target="_blank">https://github.com/spring-projects/spring-framework/wiki/Spring-Framework-Versions</a></p><p>springboot 版本官網： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fprojects%2Fspring-boot%23learn" target="_blank">https://spring.io/projects/spring-boot#learn</a></p><p><strong>循環依賴問題</strong></p><p>SpringBoot 升級到 2.7.15 後，如果應用中存在循環依賴的問題，啓動時會報如下錯誤：</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-22-10-48Z10IRCapBcpKAVDi.png" alt="" referrerpolicy="no-referrer"></p><p><strong>原因</strong>：官方文檔不鼓勵循環依賴引用，默認情況下是禁止的</p><p><strong>解決方案：</strong></p><p>第一種：推薦更新應用中 bean 的依賴關係來解決</p><p>第二種：配置文件中加入以下配置，<strong>為了和舊版本保持一致，此配置推薦添加</strong></p><pre><code>#放開循環依賴
spring.main.allow-circular-references=true

</code></pre><h3><strong>6.4、常用中間件升級</strong></h3><h4><strong>6.4.1、Lombok 版本升級到 1.18.20 以上</strong></h4><pre><code>&lt;dependency&gt;
 &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
 &lt;artifactId&gt;lombok&lt;/artifactId&gt;
 &lt;version&gt;1.18.20&lt;/version&gt;
&lt;/dependency&gt;

</code></pre><p>如果不升級，編譯時會報錯如下：</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-13-20-01itBREuaDZdAzrpZ.png" alt="" referrerpolicy="no-referrer"></p><h4><strong>6.4.2、swgger 問題，springfox3.0.0 和 springboot2.7 版本不兼容</strong></h4><p><strong>異常：</strong></p><pre><code>Failed to start bean 'documentationPluginsBootstrapper'; nested exception is java.lang.NullPointerException: 
Cannot invoke "org.springframework.web.servlet.mvc.condition.PatternsRequestCondition.getPatterns()" because "this.condition" is null

</code></pre><p><strong>解決方案：</strong></p><pre><code>/**
 * 增加如下配置可解決 Spring Boot 2.7.15 與 Swagger 3.0.0 不兼容問題
 **/
@Bean
public BeanPostProcessor springfoxHandlerProviderBeanPostProcessor() {
return new BeanPostProcessor() {

@Override
 public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
if (bean instanceof WebMvcRequestHandlerProvider || bean instanceof WebFluxRequestHandlerProvider) {
                customizeSpringfoxHandlerMappings(getHandlerMappings(bean));
            }
return bean;
}

private &lt;T extends RequestMappingInfoHandlerMapping&gt; void customizeSpringfoxHandlerMappings(List&lt;T&gt; mappings) {
            List&lt;T&gt; copy = mappings.stream().filter(mapping -&gt; mapping.getPatternParser() == null).collect(Collectors.toList());
            mappings.clear();
            mappings.addAll(copy);
        }

@SuppressWarnings("unchecked")
private List&lt;RequestMappingInfoHandlerMapping&gt; getHandlerMappings(Object bean) {
try {
                Field field = ReflectionUtils.findField(bean.getClass(), "handlerMappings");
                field.setAccessible(true);
return (List&lt;RequestMappingInfoHandlerMapping&gt;) field.get(bean);
            } catch (IllegalArgumentException | IllegalAccessException e) {
throw new IllegalStateException(e);
            }
        }
    };
}

</code></pre><p>參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F950787" target="_blank">https://developer.aliyun.com/article/950787</a></p><h4><strong>6.4.3、AKS 升級（針對直接從 JDK8 升級的情況）</strong></h4><p><strong>異常</strong>：Causedby: java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException</p><p><strong>原因</strong>：Java11 刪除了 Java EE modules，其中就包括 java.xml.bind (JAXB)。</p><p><strong>解決方案：</strong></p><p>手動引入如下包即可</p><pre><code>&lt;!-- API, java.xml.bind module --&gt; 
&lt;dependency&gt;
      &lt;groupId&gt;jakarta.xml.bind&lt;/groupId&gt;
      &lt;artifactId&gt;jakarta.xml.bind-api&lt;/artifactId&gt;
      &lt;version&gt;2.3.2&lt;/version&gt;
&lt;/dependency&gt; 
&lt;!-- Runtime, com.sun.xml.bind module --&gt;
&lt;dependency&gt;
       &lt;groupId&gt;org.glassfish.jaxb&lt;/groupId&gt;
       &lt;artifactId&gt;jaxb-runtime&lt;/artifactId&gt;
       &lt;version&gt;2.3.2&lt;/version&gt;
&lt;/dependency&gt;

</code></pre><h4><strong>6.4.4、Concrete 配置中心阻塞升級</strong></h4><p>使用 Concrete 時，啓動時異常：</p><pre><code> Unable to make field private static final java.lang.reflect.Method jdk.proxy2.$Proxy97.m0 accessible: 
 module jdk.proxy2 does not "opens jdk.proxy2" to unnamed module @61d47554

</code></pre><p><strong>原因：</strong></p><p>分析下 Concrete 報錯的原因，如下圖，包內 com.wangyin.concrete.spring.ConcreteConfigProcessor#postProcessAfterInitialization（212 行）的實現邏輯</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-27-14-00LgxgUIrSYEUTxjm.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-27-13-44BFAP7OjBiZqyaDb.png" alt="" referrerpolicy="no-referrer"></p><p><strong>解決方案：</strong></p><p>1、在 JVM 啓動參數中設置--add-opens jdk.proxy2 來開啓私有字段的訪問，但因為動態代理生成的包名是隨機不明確的，<strong>所以這種方案不可行</strong>。JDK 官方文檔也明確表示不支持訪問動態代理內部的隨機字段。官方説明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcr.openjdk.org%2F%7Emr%2Fjigsaw%2Fspec%2Fapi%2Fjava%2Flang%2Freflect%2FProxy.html" target="_blank">https://cr.openjdk.org/~mr/jigsaw/spec/api/java/lang/reflect/Proxy.html</a></p><p>2、代碼修改，只需把 f.setAccessible(true) 移到 Modifier.isStatic(f.getModifiers()) 的判斷下方即可。原因是方法 Modifier.isStatic(f.getModifiers()) 本來就要跳過靜態字段，這樣修改直接避免了訪問。<strong>推動 concrete 團隊修復問題或更換使用 Ducc 配置中心</strong></p><h3><strong>6.5、JVM 啓動參數配置</strong></h3><h4><strong>6.5.1、開啓 ZGC</strong></h4><p><strong>啓動參數中配置：</strong>-XX:+UseZGC</p><p>移除-XX:ConcGCThreads，行雲部署下 JVM 參數配置需要清除</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-17-15-14Lyy3vSkGQSvlvGe.png" alt="" referrerpolicy="no-referrer"></p><h4><strong>6.5.2、不同中間件所需啓動參數</strong></h4><p>升級 JDK17 後，項目啓動時可能會遇到如下兩種類型的異常：</p><p>1、cannot access class sun.util.calendar.ZoneInfo (in module java.base) because <strong>module java.base</strong> does not <strong>export sun.util.calendar</strong> to unnamed module @0x2611f533</p><p>2、Unable to make field final int java.math.BigInteger.signum accessible: <strong>module java.base</strong> does not "<strong>opens java.math</strong>" to unnamed module @525f1e4e</p><p><strong>異常原因：</strong></p><p>自從 JDK9 中引入了模塊化功能後，再到 JDK17，對於包掃描和反射的權限控制更加的嚴格。常見的庫比如（Spring）大量用到包掃描和反射，所以常出現此錯誤。</p><p><strong>解決方案：</strong></p><p>一個粗暴的解決辦法是將沒開放的 module 強制對外開放，即保持和 Java9 之前的版本一致。</p><ul><li>--add-exports 導出包，意味着其中的所有公共類型和成員都可以在編譯和運行時訪問。</li><li>--add-opens 打開包，意味着其中的所有類型和成員（不僅是公共類型）都可以在運行時訪問。</li></ul><p>主要區別在於<code>--add-opens</code>允許「深度反射」，即非公共成員的訪問，才可以調用<code>setAccessible(true)</code></p><p>參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F44056405%2Fwhats-the-difference-between-add-exports-and-add-opens-in-java-9" target="_blank">https://stackoverflow.com/questions/44056405/whats-the-difference-between-add-exports-and-add-opens-in-java-9</a></p><p><strong>SGM 需要加入：</strong></p><pre><code>--add-opens java.management/java.lang.management=ALL-UNNAMED 
--add-opens jdk.management/com.sun.management.internal=ALL-UNNAMED 
--add-opens java.management/sun.management=ALL-UNNAMED

</code></pre><p><strong>R2M 需要加入：</strong></p><pre><code>--add-opens java.base/java.time=ALL-UNNAMED

</code></pre><p><strong>Ducc 需要加入：</strong></p><pre><code>--add-opens java.base/java.util.concurrent=ALL-UNNAMED
--add-opens java.base/java.util.concurrent.locks=ALL-UNNAMED
--add-opens java.base/java.security=ALL-UNNAMED
--add-opens java.base/jdk.internal.loader=ALL-UNNAMED
--add-opens java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED 
--add-opens java.base/java.net=ALL-UNNAMED 
--add-opens java.base/sun.nio.ch=ALL-UNNAMED 

</code></pre><p><strong>AKS 需要加入：</strong></p><pre><code>--add-exports java.base/sun.security.action=ALL-UNNAMED
--add-opens java.base/java.lang=ALL-UNNAMED
--add-opens java.base/java.math=ALL-UNNAMED
--add-opens java.base/java.util=ALL-UNNAMED
--add-opens java.base/sun.util.calendar=ALL-UNNAMED

</code></pre><h3><strong>6.6、啓動後的驗證</strong></h3><p>1.推薦先升級 JDK11，再到 JDK17，一邊升級一邊進行驗證觀察</p><p>2.觀察日誌是否有異常，特別是上面説到的啓動時異常</p><p>3.觀察監控類軟件，比如 SGM、UMP 等監控是否正常</p><p>4.推薦逐步有序切量，並做好常態化壓測，防止影響核心業務</p><p>5.升級完成後，<strong>最好能做個全流程的功能測試，防止功能異常</strong></p><h1><strong>7、總結</strong></h1><blockquote><p>1、升級後，除了可以使用新的語法特性，最大的亮點是可以使用亞毫秒級停頓的 GC 性能（至少百倍的 GC 性能提升），所以 <strong>強烈建議升級到 JDK17</strong></p><p>2、整個升級過程並不複雜，主要涉及到中間件版本的升級和啓動參數的配置</p></blockquote><p>如果還停留在 JDK8，推薦先升級 JDK11，再到 JDK17，具體升級步驟先參考我的上篇文章「<a href="https://my.oschina.net/u/4090830/blog/10111749">JDK8 升級 JDK11 最全實踐乾貨來了</a>」，再參考本章中的升級步驟。</p><p>希望以上分享可以給大家帶來實際的幫助，升級過程中如果遇到問題，歡迎大家在評論區回覆。</p><blockquote><p>作者：京東科技，曲振富</p><p>來源：京東雲開發者社區，轉載請註明來源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 07:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10142895</guid>
            <link>https://my.oschina.net/u/4090830/blog/10142895</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AlmaLinux 9.3 正式發佈，CentOS 最佳替代方案之一]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>AlmaLinux 9.3 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falmalinux.org%2Fblog%2F2023-11-13-announcing-93-stable%2F" target="_blank">已正式發佈</a></u>，代號「Shamrock Pampas Cat」。目前提供的 ISO 鏡像文件支持如下 4 種架構：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmirrors.almalinux.org%2Fisos%2Fx86_64%2F9.3.html" target="_blank">Intel/AMD (x86_64)</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmirrors.almalinux.org%2Fisos%2Faarch64%2F9.3.html" target="_blank">ARM64 (aarch64)</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmirrors.almalinux.org%2Fisos%2Fppc64le%2F9.3.html" target="_blank">IBM PowerPC (ppc64le)</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmirrors.almalinux.org%2Fisos%2Fs390x%2F9.3.html" target="_blank">IBM Z (s390x)</a></li></ul><blockquote><p>AlmaLinux 是開放源碼的、社區驅動的項目，它從紅帽企業版 Linux (RHEL) 的源碼編譯而來。AlmaLinux 跟 RHEL 8 完全在二進制上兼容，它由 CloudLinux OS 的創建者打造。AlmaLinux 團隊承諾永久免費提供 AlmaLinux 操作系統，項目永久開源且不採取任何限制，不收取任何費用，支持至 2029 年。</p><p>2020 年 Red Hat 決定停止將 CentOS Linux 作為獨立發行版，改為推出滾動更新發行版 CentOS Stream，把它作為企業發行版 RHEL 的上游 beta 版本。社區立即推出了多個項目替代 CentOS，其中最為突出的是兩個項目：Rocky Enterprise Software Foundation 贊助的 Rocky Linux；另一個是 AlmaLinux OS Foundation 的 AlmaLinux。</p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-990d29cc9bd5b9f0f68183ea6d2b6c47315.png" referrerpolicy="no-referrer"></p><p>公告寫道，AlmaLinux 9.3&nbsp;旨在提高靈活性和可靠性，並增強混合環境中的安全性。該版本繼續對自動化和系統管理進行簡化。Web 控制枱增強功能簡化了管理任務。此外，用戶可以配置運行狀況，以檢查虛擬機中 Podman 容器和 vsock 設備的操作。Application Streams 更新為開發人員提供了靈活性和自定義選項，而不會影響平台的穩定性。</p><p>此版本引入了針對容器和虛擬機的新安全特性和運行狀況檢查選項。此外還提供了支持混合雲創新所需的靈活性、穩定性和可靠性。</p><p>工具鏈也進行了更新，包括使用 GCC 11.4.1 作為默認系統編譯器，以及 GCC 13，LLVM 16.0.6，Rust 1.71.1，Go 1.20.10，Keylime 7.3.0，Node.js20，Redis 7，Apache 2.4.57，Grafana 9.2.10，PCP 6.0.5，Valgrind 3.21，SystemTap 4.9，elfutils 0.189，OpenSCAP 1.3.8，SEtools 4.4.3 和 pcsc-lite-ccid 1.5.2。</p><p>安全方面，AlmaLinux OS 9.3 改進了對 FIPS-140-3 標準要求的所有 TLS 1.2 連接所需的擴展主密鑰 （EMS） 擴展 （RFC 7627） 的支持，並將 SCAP 安全指南更新到 0.1.69 版本，其中帶來了三個符合 CCN-STIC-610A22 指南和 ANSSI 配置文件 2.0 的新 SCAP 配置文件。</p><hr><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/262448/almalinux-stays-rhel-compatible">AlmaLinux 不使用「紅帽代碼」，如何保持兼容 RHEL</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 06:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266400/almalinux-9-3-stable</guid>
            <link>https://www.oschina.net/news/266400/almalinux-9-3-stable</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源模型 Zephyr-7B🪁發佈 —— 跨越三大洲的合作]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><span style="background-color:#ffffff; color:#333333">最近我們剛剛發佈了新的開源模型 Zephry-7B🪁，</span><span style="background-color:#ffffff; color:#333333">這個模型的誕生離不開全球三大洲開源社區的協作 ❤️。</span></p><p><span style="background-color:#ffffff; color:#333333">我們的 CSO Thomas 錄了一個視頻介紹了它的起源故事。</span></p><p><img height="377" src="https://oscimg.oschina.net/oscnet/up-da1e6db4fb09e0c752bd317fe94e1e1d4a3.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">✨ 就在幾個月前，巴黎的一個新團隊發佈了他們首個模型: Mistral 7B，這個模型體積小巧但性能強勁，在基準測試中的表現超過了所有同類模型。而且這是個開源模型，這意味着大家都可以在此基礎上進行開發。</span></p><p><span style="background-color:#ffffff; color:#333333">✨ 開發者 Lewis 在瑞士伯爾尼，Ed 在法國南部里昂，他們倆都是 Hugging Face H4 團隊的一員。在 Hugging Face 舉辦的一次小聚中，他們邊喝咖啡邊討論用斯坦福大學新發表的 DPO 方法對模型進行微調的可能性。於是大家決定用他們已經構建好的代碼庫來嘗試一下💪</span></p><p><br><span style="background-color:#ffffff; color:#333333">✨接下來的一天，他們在 HF hub 上找到了一些公開的數據集，主要是由清華的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0NzM3OTc2Nw%3D%3D%26mid%3D2247487177%26idx%3D1%26sn%3Dcfbeb254d91501fdeadda5103f1d2279%26scene%3D21%23wechat_redirect" target="_blank">OpenBMB</a> 團隊新近開源的兩個大型、高質量的微調數據集: UltraFeedback 和 UltraChat 📊</span></p><p><br><span style="background-color:#ffffff; color:#333333">✨ 經過幾輪訓練實驗，他們的想法得到了證實: 這個新模型非常強大，在伯克利和斯坦福的基準測試中是他們見過的最強模型。Clémentine 是 Hugging Face Open LLM Leaderboard 的領頭人，她對模型的深入分析確認了其卓越性能。於是 H4 團隊中另一位成員 Sasha Rush 教授迅速起草了一篇研究報告，將所有細節分享給整個社區 📰</span></p><p><br><span style="background-color:#ffffff; color:#333333">✨ 幾天後，這個名為 Zephyr 的模型、研究論文以及所有細節都向世界公開了。不久之後，全球各地的公司開始應用這一模型。LlamaIndex，一個知名的數據框架和社區，分享了這個模型在實際用例基準測試中超乎預期的表現。與此同時，研究者和實踐者們在 Hugging Face hub 上討論着這篇論文和相關工作。</span></p><p>&nbsp;</p><p><span style="background-color:#ffffff; color:#333333"><span style="background-color:#ffffff; color:#333333">✨</span><span style="background-color:#ffffff; color:#333333"></span>很難相信，這一切的實現僅僅用了幾周時間 🤯！這一切都得益於世界各地 (歐洲、加利福尼亞、中國) 對知識、模型、研究和數據集的開放，以及開源社區之間的相互協作 🤝</span></p><p><br><span style="background-color:#ffffff; color:#333333"><span style="background-color:#ffffff; color:#333333">✨</span><span style="background-color:#ffffff; color:#333333"></span>這樣的故事在開源社區比比皆是，也正是這些人和事讓開源社區始終保持不斷創新的原動力 🔥</span></p><p><br><span style="background-color:#ffffff; color:#333333"><span style="background-color:#ffffff; color:#333333">✨ </span>齊心協力，我們可以一起創造出驚人的成果 ❤️</span></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br> 如有侵權，請聯繫 support@oschina.cn 刪除。<br> 本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 06:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10142118</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10142118</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | 阿里雲嚴重故障；開源軟件 OBS Studio 被賣 43 元；蘋果迴應 8GB 近似於其它系統的 16GB.....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2023.11.06-2023.11.12]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 03:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093948&#38;idx=1&#38;sn=706606fa2f64f52b06fc8b4cee57747b&#38;chksm=880c4c2fbf7bc5397b5a8f8cf06c3879715d17a1760fae142652daea51d149d354fc1dcbc442&#38;token=293181062&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093948&#38;idx=1&#38;sn=706606fa2f64f52b06fc8b4cee57747b&#38;chksm=880c4c2fbf7bc5397b5a8f8cf06c3879715d17a1760fae142652daea51d149d354fc1dcbc442&#38;token=293181062&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[Google Play 收緊 Android 應用開發者規則]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fensuring-high-quality-apps-on-google-play.html" target="_blank">宣佈</a>收緊在 Google Play 商店發佈應用程序的 Android 開發者規則，引入了一些新的政策和計劃，以提高整個平台的應用程序質量。</span></p><p><span style="color:#000000">公告指出，現在將要求擁有新創建的個人 Play Console 帳戶的開發者在發佈前，至少 2 周內與至少 20 人一起測試他們的應用程序。他們認為，此舉將幫助開發人員提前發現問題獲得用戶反饋，預計該</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgoogleplay%2Fandroid-developer%2Fanswer%2F14151465" target="_blank">要求</a><span style="color:#000000">將在「未來幾天」出現在 Play 管理中心。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">與此同時，</span>Google Play 的<span style="background-color:#ffffff">審核團隊還將加強對應用程序的審核，預計整體應用程序審核時間表不會發生重大變化。</span></span><span style="color:#000000"><span style="background-color:#ffffff">但該公司</span>警告稱，隨着這些變化的推出，少數應用程序的審批時間可能會加長，<span style="background-color:#ffffff">例如為兒童設計的應用程序或請求某些設備權限的應用程序。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「</span>我們的全球審核團隊現在花更多時間評估新應用程序，以確保它們提供有價值的用戶體驗，不會通過應用程序或場外活動欺騙或欺詐用戶，並遵守我們的政策。<span style="background-color:#ffffff">」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">此前，谷歌方面曾宣佈所有開發者在 Google Play 上發佈應用程序前必須滿足一系列擴展的驗證要求，以打擊惡意軟件行為。時至今日，該公司還</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgoogleplay%2Fandroid-developer%2Fanswer%2F14177239" target="_blank"><span style="color:#2980b9">分享</span></a><span style="color:#000000">了一些內容，指導幫助擁有現有帳戶的開發者如何完成這些驗證，以符合更新後的&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgoogleplay%2Fandroid-developer%2Fanswer%2F10788890" target="_blank">Play 管理中心要求政策</a><span style="color:#000000">。</span></p><p><span style="color:#000000">開發者將可以自行選擇完成賬戶驗證的截止日期。截止日期以先到先得的方式提供，因此官方建議用戶儘早進行選擇，以確保能在合適的時間內完成驗證。如果開發者沒有在 2024 年 2 月 29 日之前選擇截止日期，平台將自動為其指定一個截止日期。</span></p><p><span style="color:#000000"><img alt="" height="237" src="https://oscimg.oschina.net/oscnet/up-bdd9ea4f2ac3077b8a399d99314c569aae1.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">另一方面，公告表示，為了繼續為用戶提供優質內容，回報開發者在質量方面的投資，該公司<span style="background-color:#ffffff">已經開始：</span></span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">向用戶提供有關應用程序是否在其設備（包括手機、大屏幕和可穿戴設備）上運行不佳的信息</span></li><li><span style="color:#000000">呈現更多高質量的本地和區域內容</span></li></ul><p><span style="color:#000000">並計劃將從 2024 年開始添加一個標識官方應用程序的徽章標識，以幫助用戶找到所需的應用程序。&nbsp;</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fensuring-high-quality-apps-on-google-play.html" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266381/google-play-tightens-up-rules-android-app-developers</guid>
            <link>https://www.oschina.net/news/266381/google-play-tightens-up-rules-android-app-developers</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[李開復旗下 AI 公司「零一萬物」開源的 Yi 大模型照搬 Llama 架構]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>「</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.01.ai%2F">零一萬物</a><span>」是創新工場董事長兼 CEO 李開復於今年創辦的 AI 大模型創業公司。上週該公司<u><a href="https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm">宣佈</a></u></span><strong>推出&nbsp;Yi-34B 和&nbsp;Yi-6B 兩個開源大模型。</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-4ab5886e43554fd3233305e7c8264217507.png" referrerpolicy="no-referrer"></p><p>在公開的報道中，該公司稱 Yi 系列大模型擁有全球大模型中最長的上下文窗口。其中 Yi-34B 在 Hugging Face 英文測試榜單中位列第一，在 C-Eval 中文能力排行榜中超越所有開源模型。</p><p>不過在&nbsp;Yi-34B 的 Hugging Face 主頁上，有人指出<strong> Yi 完全使用了 Llama 的架構</strong>——前者只是對後者的兩個張量 (Tensor) 名稱進行了修改，具體為 input_layernorm 和 post_attention_layernorm。</p><blockquote><p>Llama 全稱為 "Large Language Model Meta AI"，是 Meta 創建的大語言模型。今年 7 月，<u><a href="https://www.oschina.net/news/249944/meta-llama-2">Meta 發佈了 Llama 2</a></u>，宣佈完全開源，並可免費商用。</p><p><img src="https://static.oschina.net/uploads/space/2023/0719/103048_jW9B_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1114/111349_Novu_2720166.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B%2Fdiscussions%2F11" target="_blank">https://huggingface.co/01-ai/Yi-34B/discussions/11</a></u></em></p><p>AI 領域知名專家賈揚清昨晚也在個人朋友圈點評了此事——不過並沒有指名道姓：</p><p><img src="https://static.oschina.net/uploads/space/2023/1114/111004_dOrQ_2720166.png" referrerpolicy="no-referrer"></p><blockquote><p>賈揚清是開源深度學習框架&nbsp;<span>Caffe 創始人、TensorFlow 作者之一、也是 PyTorch 1.0 的共同創始人。</span></p><p>今年 3 月，賈揚清從阿里離職後聯合創立了一家新的 AI 公司 Lepton AI，旨在建立高效的 AI 應用平台。</p><p>Lepton AI 總部位於美國加利福尼亞州帕洛阿託，官網宣稱可通過 Lepton AI 在幾分鐘內高效、大規模地運行 AI 應用。相比大模型，賈揚清團隊更偏重 AI 能力的開發。</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 03:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266377</guid>
            <link>https://www.oschina.net/news/266377</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[指針「爆雷」導致公司損失上億資金]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1990 年 1 月 15 日，AT&amp;T 的新澤西運營中心檢測到大範圍的系統故障，網絡顯示屏上出現了大量紅色警告。</p><p>儘管試圖排除故障，但網絡故障仍持續了 9 個小時，導致呼叫連接故障率達到 50%。</p><p><strong>AT&amp;T 因此損失了 6000 多萬美元，6 萬多名美國人的電話完全無法接通</strong>。</p><p>此外，500 個航班延誤，8.5 萬人受到影響。</p><p>按理説，AT&amp;T 的長途網絡是高效率的典範，它利用先進的電子交換機和信號系統處理了全國大部分的電話。該系統通常能在幾秒鐘內完成電話路由選擇。</p><p>然而，就在這一天，從紐約的一個交換機開始，整個網絡出現了故障。這是由於最近一次更新中的一個軟件錯誤造成的，該錯誤影響了網絡中的 114 個交換機。當紐約的交換機復位併發出信號時，這個錯誤引發了多米諾骨牌效應，導致大範圍的網絡中斷。</p><p><strong>有趣的是，這個軟件並沒有經過測試。由於代碼改動較小，因此按照管理層的要求繞過了測試</strong>。</p><h3>問題所在</h3><p>追根溯源，原因在於網絡交換機實施的軟件更新中出現了編碼錯誤。</p><p>該錯誤發生在一個 C 語言程序中，涉及嵌套條件語句中一個錯位的中斷語句，導致數據覆蓋和系統重置。</p><p>偽代碼</p><pre><code>1  while (ring receive buffer not empty 
          and side buffer not empty):

2    Initialize pointer to first message in side buffer
     or ring receive buffer

3    get copy of buffer

4    switch (message):

5       case (incoming_message):

6             if (sending switch is out of service):

7                 if (ring write buffer is empty):

8                     send "in service" to status map

9                 else:

10                    break // The error was here!

                  END IF

11           process incoming message, set up pointers to
             optional parameters

12           break
       END SWITCH


13   do optional parameter work</code></pre><h3>問題分析</h3><ul><li>如果環寫入緩衝區不是空的，那麼第 7 行的 `if` 語句就會被跳過，取而代之的是第 10 行的中斷語句。</li><li>然而，為了使程序正常運行，本應執行第 11 行。</li><li>當中斷語句被執行，而不是處理傳入的信息併為可選參數設置指針時，數據（本應保留的指針）就會被覆蓋</li><li>糾錯軟件識別出數據被覆蓋，並啓動關閉開關進行重置。由於網絡中的所有交換機都使用了這種有缺陷的軟件，導致了連鎖重置反應，最終癱瘓了整個網絡系統，使問題變得更加複雜。</li></ul><p>儘管進行了嚴格的測試，網絡的設計也非常靈活，但一行代碼還是導致了半個國家的主要通信線路癱瘓。</p><h3><strong>修復</strong></h3><p>工程師們花了 9 個小時才使 AT&amp;T 的系統完全恢復正常。他們主要是通過將交換機回滾到之前的代碼工作版本來實現的。</p><p>實際上，軟件工程師花了兩週時間進行嚴格的代碼閲讀、測試和複製，才真正弄清了錯誤所在。</p><h3><strong>結論</strong></h3><p>對於 AT&amp;T 來説，不幸的是，這還不是他們 90 年代最大的系統崩潰。在這十年的後期，他們還遇到了更多的問題。</p><p>今天的公司擁有更好的流程，但即便如此，還是會有漏洞漏網。谷歌撰寫了一篇關於網站可靠性工程 20 年的精彩回顧文章，其中對 2016 年 YouTube 的首次全球故障進行了反思。</p><p>對於公司來説，故障的規模是巨大的，每次故障都會給我們帶來教訓。然而，對於大多數公司來説，故障歸根結底是人為錯誤和流程漏洞造成的。</p><p>原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fengineercodex.substack.com%2Fp%2Fhow-one-line-of-code-caused-a-60" target="_blank">https://engineercodex.substack.com/p/how-one-line-of-code-caused-a-60</a><br> 轉自：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jdon.com%2F69737.html" target="_blank">https://www.jdon.com/69737.htm</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 03:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266368/one-line-of-code-caused-a-60</guid>
            <link>https://www.oschina.net/news/266368/one-line-of-code-caused-a-60</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[遊戲黨福音！MakerFrame SIG 跨平台遊戲引擎上線]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px"><span><span style="color:#000000">近日，經 openKylin 社區技術委員會審議通過，</span><strong><span style="color:#000000">鷹歌框架引擎技術小組—MakerFrame SIG</span></strong><span style="color:#000000">正式成立。</span></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">MakerFrame SIG 由</span><strong><span style="color:#000000">社區愛好者劉帥</span></strong><span style="color:#000000">發起成立，負責為 openKylin 社區開發簡單高效的遊戲框架引擎，致力於讓專業人士和非專業人士都來開發跨平台的遊戲和應用，大力促進 openKylin 社區遊戲生態推廣。</span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">01</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 目標</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">MakerFrame（鷹歌框架引擎）作為默認組件集成至 openKylin 社區版本中，讓社區愛好者基於遊戲引擎快捷的開發各種遊戲，拓展社區遊戲生態。</span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">02</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 職責</span></strong></span></p><ul><li><span><span style="color:#000000">MakerFrame 遊戲框架的開發維護和各平台適配；</span></span></li><li><span><span style="color:#000000">負責解答使用和開發過程中的技術問題。</span></span></li></ul><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">03</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 現階段成果</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#0052ff">1、完成框架引擎的各平台適配。</span></strong></span></p><div><p style="text-align:center"><img alt="" height="746" src="https://oscimg.oschina.net/oscnet/up-df30540c26560597e288fdc15418de64b32.png" width="1366" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#000000">目前，MakerFrame 遊戲框架已在 openKylin 社區開源，項目地址如下：</span></strong></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span><span style="color:#0052ff">https://gitee.com/openkylin/maker-frame</span></span></p><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#0052ff">2、完成《俠道仙緣》遊戲的開發和各平台適配。</span></strong></span></p><div><p style="text-align:center"><img alt="" height="745" src="https://oscimg.oschina.net/oscnet/up-c7c3e0bed2a046e5195847baed2814b8100.png" width="436" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#000000">目前，MakerFrame 框架引擎和《俠道仙緣》遊戲已上架至 openKylin 軟件商店，感興趣的小夥伴趕快下載體驗吧~</span></strong></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">04</span></strong></span></em><span><strong><span style="color:#0b43d1">歡迎加入 SIG</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">歡迎所有對 openKylin 社區遊戲開發感興趣的社區愛好者加入我們！</span></span></p><ul><li><span><span style="color:#000000">郵件列表：</span></span></li><li><span><span style="color:#0052ff">markerframe@lists.openkylin.top</span></span></li><li><span><span style="color:#000000">SIG 主頁：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/MakerFrame</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266366</guid>
            <link>https://www.oschina.net/news/266366</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[信通院牽頭的服務器無感知（Serverless）國際標準在 ITU 成功立項]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">國際電信聯盟第十三研究組（簡稱 ITU-T SG13）於 2023 年 10 月 23 日-11 月 3 日在瑞士日內瓦召開全體會議，來自世界各國的百餘名代表參加會議。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">會上，由中國信息通信研究院（簡稱「中國信通院」）牽頭提出的 ITU-T Y.FaaS-reqts「Cloud computing - Functional requirements of function as a service（雲計算-函數即服務功能要求）」國際標準成功立項，並計劃於 2025 年正式發佈。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">本國際標準依託中國信通院牽頭制定的行業標準 YD/T 3764.9-2021《雲計算服務客戶信任體系能力要求，第 9 部分：函數即服務》提出。本標準計劃給出函數即服務（FaaS）的清晰定義，界定 FaaS 與服務器無感知（Serverless）計算、雲計算之間的關係，梳理 FaaS 與周邊生態的交互關係，並詳細列出 FaaS 的功能要求，同時將通過典型場景下 FaaS 的應用案例輔助驗證本標準的適用性與準確性。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">FaaS 是 Serverless 計算最典型的形態，Serverless 體現了將基礎設施資源抽象成按需使用的服務，用戶只需關注應用邏輯，而無需管理複雜的基礎設施運維工作的設計模式，被視作雲計算的下一步。中國信通院在此領域深耕多年，目前已建立國內十分完善的 Serverless 標準與評估體系，涵蓋 Serverless 計算、Serverless 工具、泛 Serverless 化服務等多個維度。未來，中國信通院將針對 Serverless 性能基準、Serverless BaaS 服務、典型 Serverless 應用場景解決方案等領域進一步開展深入研究。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266363</guid>
            <link>https://www.oschina.net/news/266363</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英偉達發佈 AI 芯片 H200]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>英偉達昨晚正式發佈了 AI 芯片 H100 GPU 的後續產品<strong> HGX H200 GPU</strong>，可大幅提高大語言模型的能力。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b02e195462bf252f5b2f437a4a1ecdeca2d.png" referrerpolicy="no-referrer"></p><p>據悉，HGX H200 GPU 基於英偉達的「Hopper」架構，相比前代產品內存帶寬增加了 1.4 倍，內存容量增加了 1.8 倍。H200 GPU 使用了 HBM3e 內存的芯片，能夠以每秒 4.8 TB 的速度提供 141GB 的內存。</p><p>英偉達表示，H200 更大、更快的內存可加快生成式人工智能和大語言模型的速度，與 H100 GPU 相比，H200 在處理 Llama2 等大語言模型時可將推理速度提高 2 倍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b6cc928aec01bd10e6b92f2644ee04f7881.png" referrerpolicy="no-referrer"></p><p>H200 還與已經支持 H100 的系統兼容。英偉達表示，客戶在添加 H200 時不需要做任何改動。亞馬遜、谷歌、微軟和甲骨文的雲計算部門將在明年率先使用到新的 GPU。</p><p>預計 H200 將於 2024 年第二季度上市，屆時將與 AMD 的 MI300X GPU 展開競爭。與 H200 相似，AMD 的新芯片相比前代產品擁有更多內存，這對運行大型語言模型的推理計算有幫助。</p><p>據美國金融機構 Raymond James 透露，H100 芯片的成本僅為 3320 美元，但英偉達對其客戶的批量價格卻高達 2.5 萬至 4 萬美元。這使得 H100 的利潤率可能高達 1000%，成為有史以來最賺錢的芯片之一。</p><p>在訓練大型語言模型時，通常需要數千個 H100 集羣協同工作，因此科技巨頭、初創公司和政府機構都在爭奪英偉達有限的芯片供應。</p><p>由於對其產品的需求看似無窮無盡，英偉達今年的銷售額大幅增長，股價上漲了 230%，市值突破了 1.2 萬億美元大關。截至週一收盤，該股收漲 0.59%，報 486.2 美元。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266361</guid>
            <link>https://www.oschina.net/news/266361</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TGFX —— 跨平台 2D 繪圖引擎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TGFX (Tencent Graphics)&nbsp;是一個輕量級 2D 圖形庫，設計用於渲染文本、幾何圖形和圖像。它提供高性能的 API，可在各種 GPU 硬件和軟件平台上運行，包括 iOS、Android、macOS、Windows、Linux、Web 等。</p><p>TGFX 最初是作為 PAG 項目的核心組件創建的，從 4.0 版開始成為 libpag 庫的默認圖形引擎。它的主要目標是在保持更小二進制文件大小的同時，為 Skia 圖形庫提供令人信服的替代方案。隨着時間的推移，它已被許多其他產品採用，如 Hippy、騰訊文檔和各種視頻編輯應用程序。</p><p style="margin-left:0px; margin-right:0px"><strong style="color:#1a1a1a">包體優化</strong></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>TGFX 最終以 400K 左右的大小覆蓋了 Skia 近 2M 包體的絕大部分功能。核心優化策略主要有兩點：</span></p><p><img height="231" src="https://static.oschina.net/uploads/space/2023/1108/105501_oKgt_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start"><strong style="color:#1a1a1a">調度優化</strong></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>TGFX 並不只是做 Skia 的簡化，還把一些在業務上調用起來非常複雜的通用性流程進行了抽</span><span>象封裝</span><span>：</span></p><p><img alt="" height="102" src="https://static.oschina.net/uploads/space/2023/1108/105526_HLW4_4252687.png" width="700" referrerpolicy="no-referrer"></p><p>在性能和架構方面，還做了這些額外的優化：</p><ul><li>默認開啓了 HardwareBuffer 的支持，來全面加速紋理的提交，包括 Android 端。</li><li>暴露了引擎內部 Path 對應的 GPU 高速緩存，避免矢量繪製充分進行三角剖分操作。</li><li>GPU 對象支持在任意線程釋放，等關聯的上下文激活時才清理，避免隨機 Crash 問題。</li><li>約束圖片解碼完會盡可能只緩存 GPU 的紋理部分，理論上全局可以降低一半的內存佔用。</li><li>將絕大部分緩存都交給了上層業務精確管理，避免隨機繪製的緩存持續佔用額外的內存。</li><li>在全平台都實現了默認字體的讀取能力，包括瀏覽器，避免下載上百兆 CJK 字體的壓力。</li><li>增加了對各種硬解視頻幀格式的直接繪製能力，可以一次性上屏無需通過 CPU 轉換格式。</li><li>放棄了 SKSL 的統一 Shader 語言設計，更加符合原生接口調用習慣，既節省了包體，也減少了 GPU Program 的編譯耗時。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tgfx</guid>
            <link>https://www.oschina.net/p/tgfx</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 面向 AI 的下一代富文本編輯器 AiEditor]]>
            </title>
            <description>
                <![CDATA[<p><img src="https://gitee.com/aieditor-team/aieditor/raw/main/docs/assets/image/screenshot.png" alt="screenshot.png" referrerpolicy="no-referrer"></p><h1><a id="user-content-aieditor" class="anchor" href="https://gitee.com/aieditor-team/aieditor#aieditor"></a>AiEditor</h1><p>關於 AiEditor</p><blockquote><p>AiEditor 是一個面向 AI 的下一代富文本編輯器，她基於 Web Component，因此支持 Layui、Vue、React、Angular 等幾乎任何前端框架。她適配了 PC Web 端和手機端，並提供了，亮色，和 暗色，兩個主題。除此之外，她還提供了靈活的配置，開發者可以方便的使用其開發任何文字編輯的應用。</p></blockquote><h2><a id="user-content-在線演示" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%9C%A8%E7%BA%BF%E6%BC%94%E7%A4%BA"></a>在線演示</h2><p><a href="https://gitee.com/link?target=http%3A%2F%2Faieditor.jpress.cn">http://aieditor.jpress.cn</a></p><h2><a id="user-content-已完善" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%B7%B2%E5%AE%8C%E5%96%84"></a>已完善</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 基礎：標題、正文、字體、字號、加粗、斜體、下劃線、刪除線、鏈接、行內代碼、上標、下標、分割線、引用、打印</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 增強：撤回、重做、格式刷、橡皮擦、待辦事項、字體顏色、背景顏色、Emoji 表情、對齊方式、行高、有（無）序列表、段落縮進、強制換行</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 附件：支持圖片、視頻、文件功能，支持選擇上傳、粘貼上傳、拖拽上傳、支持拖動調整大小...</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 代碼：行內代碼、代碼塊、代碼語言選擇</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 表格：左增右增、左減右減、上增下增、上減下減、合併單元格、解除合併</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> A I：AI 續寫、AI 優化、AI 校對、AI 翻譯、自定義 AI 菜單及其 Prompts</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 更多：亮色主題、暗色主題、手機版適配、全屏編輯、@某某某（提及）...</li></ul><h2><a id="user-content-待完善計劃中" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%BE%85%E5%AE%8C%E5%96%84%E8%AE%A1%E5%88%92%E4%B8%AD"></a>待完善（計劃中...）</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 國際化</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 團隊協作</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 自動化測試</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 插入圖片</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 圖生圖（AI 圖片優化）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 一鍵排版</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 進一步強化增貼功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 上傳視頻自動獲取縮略圖</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> WORD 導入、導出</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> PDF 導出、PDF 預覽</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 類騰訊文檔 UI 風格</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 類 Notion 拖拽功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 更多的大模型對接：文心一言、ChatGPT</li></ul><h2><a id="user-content-構建運行" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E6%9E%84%E5%BB%BA%E8%BF%90%E8%A1%8C"></a>構建&amp;運行</h2><p><strong>構建</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://gitee.com/aieditor-team/aieditor.git</span><span id="LC2" class="line"></span><span id="LC3" class="line"><span class="nb">cd </span>aieditor</span><span id="LC4" class="line"></span><span id="LC5" class="line"><span class="c"># 安裝依賴</span></span><span id="LC6" class="line">npm <span class="nb">install</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>運行</strong></p><p>修改 <code>demos/main.ts</code> 下的內容為：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">點擊輸入內容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一個面向 AI 的開源富文本編輯器。輸入，空格 + "/" 可以快速彈出 AI 菜單哦 </span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">ai</span><span class="p">:</span><span class="p">{</span></span><span id="LC6" class="line"><span class="na">model</span><span class="p">:</span><span class="p">{</span></span><span id="LC7" class="line"><span class="na">xinghuo</span><span class="p">:</span><span class="p">{</span></span><span id="LC8" class="line"><span class="na">appId</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC9" class="line"><span class="na">apiKey</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC10" class="line"><span class="na">apiSecret</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="p">}</span></span><span id="LC13" class="line"><span class="p">}</span></span><span id="LC14" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>或者直接移除 AI 的配置，如下所示（移除後，則不能使用 AI 功能）：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">點擊輸入內容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一個面向 AI 的開源富文本編輯器。輸入，空格 + "/" 可以快速彈出 AI 菜單哦 </span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>然後再命令行下執行：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm run dev</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-ai-功能配置" class="anchor" href="https://gitee.com/aieditor-team/aieditor#ai-%E5%8A%9F%E8%83%BD%E9%85%8D%E7%BD%AE"></a>AI 功能配置</h2><ul><li>1、去科大訊飛註冊賬號 <a href="https://gitee.com/link?target=https%3A%2F%2Fxinghuo.xfyun.cn">https://xinghuo.xfyun.cn</a></li><li>2、在科大訊飛服務管理中（<a href="https://gitee.com/link?target=https%3A%2F%2Fconsole.xfyun.cn%2Fservices%2Fbm2">https://console.xfyun.cn/services/bm2</a> ） 獲取 appId、apiKey、apiSecret。</li><li>3、在配置中添加科大訊飛星火大模型配置</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">點擊輸入內容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一個面向 AI 的開源富文本編輯器。</span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">ai</span><span class="p">:</span><span class="p">{</span></span><span id="LC6" class="line"><span class="na">model</span><span class="p">:</span><span class="p">{</span></span><span id="LC7" class="line"><span class="na">xinghuo</span><span class="p">:</span><span class="p">{</span></span><span id="LC8" class="line"><span class="na">appId</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC9" class="line"><span class="na">apiKey</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC10" class="line"><span class="na">apiSecret</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="p">}</span></span><span id="LC13" class="line"><span class="p">}</span></span><span id="LC14" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/aieditor-team/aieditor</guid>
            <link>https://gitee.com/aieditor-team/aieditor</link>
        </item>
        <item>
            <title>
                <![CDATA[Linux 基金會創建高性能軟件基金會 (HPSF)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linux 基金會<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-announces-intent-to-form-high-performance-software-foundation-hpsf" target="_blank">宣佈</a>，他們正在組建<strong>高性能軟件基金會</strong>(High Performance Software Foundation, HPSF)，以幫助推進高性能計算 (HPC) 核心開源項目的發展，包括 Spack, Kokkos, AMReX, VTK-m, HPCToolkit, E4S, Charliecloud, WarpX，以及其他面向 HPC 的項目。</p><p>部分國家實驗室，知名科技公司如英特爾、英偉達和其他利益相關者已經參與其中（暫未發現 AMD 參與）。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1d45e285c4d0bd80c3829c1c4df3a8b4906.png" referrerpolicy="no-referrer"></p><p>HPSF 已制定了明確的目標：</p><ul><li>成為高性能軟件生態系統中關鍵項目的中立家園；</li><li>在開源社區和組織中推廣 HPSF 項目的使用；</li><li>提供透明的治理模式，讓政府、行業和學術界的利益相關者共同管理生態系統；</li><li>提供清晰的路徑來孵化和啓動有前景的新項目；</li><li>通過提供 CI 和 turn-key 構建，確保 HPC 軟件可訪問且可靠；</li><li>通過與 CNCF 和 OpenSSF 合作，確保 HPC 軟件安全併為上雲做好準備；</li><li>贊助活動和培訓，為 HPSF 生態系統中的軟件培養一支多元化、熟練的勞動力隊伍。</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-announces-intent-to-form-high-performance-software-foundation-hpsf" target="_blank">更多內容查看官方新聞稿</a></u>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266356/lf-high-performance-software-foundation-hpsf</guid>
            <link>https://www.oschina.net/news/266356/lf-high-performance-software-foundation-hpsf</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | GPU 架構與計算入門指南]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><img src="https://oscimg.oschina.net/oscnet/86cf28df-e180-4a38-9a4b-768dae1aa92b.jpg" referrerpolicy="no-referrer"></p><p><span><span>大多數工程師對 CPU 和順序編程都十分熟悉，這是因為自從他們開始編寫 CPU 代碼以來，就與之密切接觸。然而，對於 GPU 的內部工作原理及其獨特之處，他們的瞭解則相對較少。過去十年，由於 GPU 在深度學習中得到廣泛應用而變得極為重要。因此，每位軟件工程師都有必要了解其基本工作原理。本文旨在為讀者提供這方面的背景知識。</span></span></p><p>&nbsp;</p><p><span><span>本文作者為軟件工程師 Abhinav Upadhyay，他在《大規模並行處理器編程》第四版（Hwu 等）的基礎上編寫了本文大部分內容，其中介紹了包括 GPU 體系結構和執行模型等內容。當然，文中 GPU 編程的基本概念和方法同樣適用於其他供應商的產品。</span></span></p><p>&nbsp;</p><p style="text-align:left"><span><span>（本文由 OneFlow 編譯發佈，轉載請聯繫授權。</span><span>原文：</span>https://codeconfessions.substack.com/p/gpu-computing）</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>作者 | Abhinav Upadhyay</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>OneFlow 編譯</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>翻譯｜宛子琳、楊婷</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><strong><span><span><strong><span style="color:#f6ab00">1</span></strong></span></span></strong></span></span></p><span id="OSC_h2_1"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><strong><span><span style="color:#1e2380"><strong><span style="color:#1e2380">比較 CPU 與 GPU</span></strong></span></span></strong></span></span></p><p><span style="color:#3f3f3f"><span><strong><span><span>&nbsp;</span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">首先，我們會比較 CPU 和 GPU，這能幫助我們更好地瞭解 GPU 的發展狀況，但這應該作為一個獨立的主題，因為我們難以在一節中涵蓋其所有的內容。因此，我們將着重介紹一些關鍵點。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">CPU 和 GPU 的主要區別在於它們的設計目標。CPU 的設計初衷是執行順序指令[1]。一直以來，為提高順序執行性能，CPU 設計中引入了許多功能。其重點在於減少指令執行時延，使 CPU 能夠儘可能快地執行一系列指令。這些功能包括指令流水線、亂序執行、預測執行和多級緩存等（此處僅列舉部分）。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">而 GPU 則專為大規模並行和高吞吐量而設計，但這種設計導致了中等至高程度的指令時延。這一設計方向受其在視頻遊戲、圖形處理、數值計算以及現如今的深度學習中的廣泛應用所影響，所有這些應用都需要以極高的速度執行大量線性代數和數值計算，因此人們傾注了大量精力以提升這些設備的吞吐量。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我們來思考一個具體的例子：由於指令時延較低，CPU 在執行兩個數字相加的操作時比 GPU 更快。在按順序執行多個這樣的計算時，CPU 能夠比 GPU 更快地完成。然而，當需要進行數百萬甚至數十億次這樣的計算時，由於 GPU 具有強大的大規模並行能力，它將比 CPU 更快地完成這些計算任務。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我們可以通過具體數據來進行説明。硬件在數值計算方面的性能以每秒浮點運算次數（FLOPS）來衡量。NVIDIA 的 Ampere A100 在 32 位精度下的吞吐量為 19.5 TFLOPS。相比之下，Intel 的 24 核處理器在 32 位精度下的吞吐量僅為 0.66 TFLOPS（2021 年）。同時，隨時間推移，GPU 與 CPU 在吞吐量性能上的差距逐年擴大。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">下圖對 CPU 和 GPU 的架構進行了比較。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><img height="auto" src="https://oscimg.oschina.net/oscnet/bdd6d31c-c5ec-4301-a326-11b2bdc1264b.png" width="auto" referrerpolicy="no-referrer"><span style="color:#888888"><em><span style="color:#888888">圖 1：CPU 與 GPU 的芯片設計對比。引自《CUDA C++編程指南》（NVIDIA）</span></em></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">如圖所示，CPU 在芯片領域中主要用於降低指令時延的功能，例如大型緩存、較少的算術邏輯單元（ALU）和更多的控制單元。與此相比，GPU 則利用大量的 ALU 來最大化計算能力和吞吐量，只使用極小的芯片面積用於緩存和控制單元，這些元件主要用於減少 CPU 時延。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><strong><span>時延容忍度<strong style="color:#3f3f3f"><span>和</span></strong>高吞吐量</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">或許你會好奇，GPU 如何能夠容忍高時延並同時提供高性能呢？GPU 擁有大量線程和強大的計算能力，使這一點成為可能。即使單個指令具有高延遲，GPU 也會有效地調度線程運行，以便它們在任意時間點都能利用計算能力。例如，當某些線程正在等待指令結果時，GPU 將切換到運行其他非等待線程。這可確保 GPU 上的計算單元在所有時間點都以其最大容量運行，從而提供高吞吐量。稍後當我們討論 kernel 如何在 GPU 上運行時，我們將對此有更清晰的瞭解。</span></span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><span><strong><span style="color:#f6ab00">2</span></strong></span></span></span></span></p><span id="OSC_h2_2"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><span style="color:#1e2380"><strong><span style="color:#1e2380">GPU 架構</span></strong></span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我們已經瞭解到 GPU 有利於實現高吞吐量，但它們是通過怎樣的架構來實現這一目標的呢？本節將對此展開探討。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><strong><span>GPU 的計算架構</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">GPU 由一系列流式多處理器（SM）組成，其中每個 SM 又由多個流式處理器、核心或線程組成。例如，NVIDIA H100 GPU 具有 132 個 SM，每個 SM 擁有 64 個核心，總計核心高達 8448 個。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">每個 SM 都擁有一定數量的片上內存（on-chip memory），通常稱為共享內存或臨時存儲器，這些共享內存被所有的核心所共享。同樣，SM 上的控制單元資源也被所有的核心所共享。此外，每個 SM 都配備了基於硬件的線程調度器，用於執行線程。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">除此之外，每個 SM 還配備了幾個功能單元或其他加速計算單元，例如張量核心（tensor core）或光線追蹤單元（ray tracing unit），用於滿足 GPU 所處理的工作負載的特定計算需求。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><span><img height="auto" src="https://oscimg.oschina.net/oscnet/c25e87f8-efab-4e56-b903-e657474e8026.png" width="auto" referrerpolicy="no-referrer"></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="color:#494949; text-align:center"><span style="color:#3f3f3f"><span><span><span style="color:#888888"><em><span style="color:#888888">圖 2：GPU 的計算架構</span></em></span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">接下來，讓我們深入剖析 GPU 內存並瞭解其中的細節。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span>GPU 的內存架構</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span>&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 具有多層不同類型的內存，每一層都有其特定用途。下圖顯示了 GPU 中一個 SM 的內存層次結構。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/94a4fe5d-80dd-4461-b5af-4587fd012f16.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 3：基於康奈爾大學虛擬工作坊（Virtual Workshop）的 GPU 內存架構</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">讓我們對其進行剖析：</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><ul style="margin-left:8px; margin-right:8px"><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">寄存器</span></strong><span style="color:#3f3f3f">：讓我們從寄存器開始。GPU 中的每個 SM 都擁有大量寄存器。例如，NVIDIA 的 A100 和 H100 模型中，每個 SM 擁有 65536 個寄存器。這些寄存器在覈心之間共享，並根據線程需求動態分配。在執行過程中，每個線程都被分配了私有寄存器，其他線程無法讀取或寫入這些寄存器。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">常量緩存</span></strong><span style="color:#3f3f3f">：接下來是芯片上的常量緩存。這些緩存用於緩存 SM 上執行的代碼中使用的常量數據。為利用這些緩存，程序員需要在代碼中明確將對象聲明為常量，以便 GPU 可以將其緩存並保存在常量緩存中。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">共享內存</span></strong><span style="color:#3f3f3f">：每個 SM 還擁有一塊共享內存或臨時內存，它是一種小型、快速且低時延的片上可編程 SRAM 內存，供運行在 SM 上的線程塊共享使用。共享內存的設計思路是，如果多個線程需要處理相同的數據，只需要其中一個線程從全局內存（global memory）加載，而其他線程將共享這一數據。合理使用共享內存可以減少從全局內存加載重複數據的操作，並提高內核執行性能。共享內存還可以用作線程塊（block）內的線程之間的同步機制。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">L1 緩存</span></strong><span style="color:#3f3f3f">：每個 SM 還擁有一個 L1 緩存，它可以緩存從 L2 緩存中頻繁訪問的數據。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">L2 緩存</span></strong><span style="color:#3f3f3f">：所有 SM 都共享一個 L2 緩存，它用於緩存全局內存中被頻繁訪問的數據，以降低時延。需要注意的是，L1 和 L2 緩存對於 SM 來説是公開的，也就是説，SM 並不知道它是從 L1 還是 L2 中獲取數據。SM 從全局內存中獲取數據，這類似於 CPU 中 L1/L2/L3 緩存的工作方式。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">全局內存</span></strong><span style="color:#3f3f3f">：GPU 還擁有一個片外全局內存，它是一種容量大且帶寬高的動態隨機存取存儲器（DRAM）。例如，NVIDIA H100 擁有 80 GB 高帶寬內存（HBM），帶寬達每秒 3000 GB。由於與 SM 相距較遠，全局內存的時延相當高。然而，芯片上還有幾個額外的存儲層以及大量的計算單元有助於掩飾這種時延。</span></span></span></span></p></li></ul><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">現在我們已經瞭解 GPU 硬件的關鍵組成部分，接下來我們深入一步，瞭解執行代碼時這些組件是如何發揮作用的。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">3</span></strong></span></span></span></p><span id="OSC_h2_3"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">瞭解 GPU 的執行模型</span></strong></span></span></span></p><p>&nbsp;</p><p style="color:#494949"><span style="color:#3f3f3f"><span>&nbsp;</span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">要理解 GPU 如何執行 kernel，我們首先需要了解什麼是 kernel 及其配置。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>CUDA Kernel 與線程塊簡介</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">CUDA 是 NVIDIA 提供的編程接口，用於編寫運行在其 GPU 上的程序。在 CUDA 中，你會以類似於 C/C++函數的形式來表達想要在 GPU 上運行的計算，這個函數被稱為 kernel。kernel 在並行中操作向量形式的數字，這些數字以函數參數的形式提供給它。一個簡單的例子是執行向量加法的 kernel，即接受兩個向量作為輸入，逐元素相加，並將結果寫入第三個向量。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">要在 GPU 上執行 kernel，我們需要啓用多個線程，這些線程總體上被稱為一個網格（grid），但網格還具有更多的結構。一個網格由一個或多個線程塊（有時簡稱為塊）組成，而每個線程塊又由一個或多個線程組成。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">線程塊和線程的數量取決於數據的大小和我們所需的並行度。例如，在向量相加的示例中，如果我們要對 256 維的向量進行相加運算，那麼可以配置一個包含 256 個線程的單個線程塊，這樣每個線程就可以處理向量的一個元素。如果數據更大，GPU 上也許沒有足夠的線程可用，這時我們可能需要每個線程能夠處理多個數據點。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/7e96e636-6948-48f2-adc5-bbc37c3a1f19.png" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 4：線程塊網格。引自《CUDA C++編程指南》（NVIDIA）</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">編寫一個 kernel 需要兩步。第一步是運行在 CPU 上的主機代碼，這部分代碼用於加載數據，為 GPU 分配內存，並使用配置的線程網格啓動 kernel；第二步是編寫在 GPU 上執行的設備（GPU）代碼。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">對於向量加法示例，下圖顯示了主機代碼。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/bc098e64-ceb7-4b8c-8e4b-607b56d471d4.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 5：CUDA kernel 的主機代碼，用於將兩個向量相加。</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">下圖為設備代碼，它定義了實際的 kernel 函數。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/1d2f6102-c267-4b78-ba9e-880c832009d1.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 6：包含向量相加 kernel 定義的設備代碼。</span></em></span></span></span></p><blockquote><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由於本文的重點不在於教授 CUDA，因此我們不會更深入地討論此段代碼。現在，讓我們看看在 GPU 上執行 kernel 的具體步驟。</span></span></span></blockquote><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">4</span></strong></span></span></span></p><span id="OSC_h2_4"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">在 GPU 上執行 Kernel 的步驟</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><strong style="color:#3f3f3f"><span>1. 將數據從主機複製到設備</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">在調度執行 kernel 之前，必須將其所需的全部數據從主機（即 CPU）內存複製到 GPU 的全局內存（即設備內存）。</span><span style="color:#3f3f3f">儘管如此，在最新的 GPU 硬件中，我們還可以使用統一虛擬內存直接從主機內存中讀取數據（可參閲論文《EMOGI: Efficient Memory-access for Out-of-memory Graph-traversal in GPUs》）。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>2. SM 上線程塊的調度</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">當 GPU 的內存中擁有全部所需的數據後，它會將線程塊分配給 SM。同一個塊內的所有線程將同時由同一個 SM 進行處理。為此，GPU 必須在開始執行線程之前在 SM 上為這些線程預留資源。在實際操作中，可以將多個線程塊分配給同一個 SM 以實現並行執行。</span></span></span></p><p style="color:#494949">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/a5075db0-bd48-4627-a342-c93f06482fca.png" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 7：將線程塊分配給 SM</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由於 SM 的數量有限，而大型 kernel 可能包含大量線程塊，因此並非所有線程塊都可以立即分配執行。GPU 會維護一個待分配和執行的線程塊列表，當有任何一個線程塊執行完成時，GPU 會從該列表中選擇一個線程塊執行。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>3. 單指令多線程 (SIMT) 和</span></strong><strong><span>線程束（Warp）</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">眾所周知，一個塊（block）中的所有線程都會被分配到同一個 SM 上。但在此之後，線程還會進一步劃分為大小為 32 的組（稱為 warp[2]），並一起分配到一個稱為處理塊（processing block）的核心集合上進行執行。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">SM 通過獲取並向所有線程發出相同的指令，以同時執行 warp 中的所有線程。然後這些線程將在數據的不同部分，同時執行該指令。在向量相加的示例中，一個 warp 中的所有線程可能都在執行相加指令，但它們會在向量的不同索引上進行操作。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由於多個線程同時執行相同的指令，這種 warp 的執行模型也稱為單指令多線程 （SIMT）。這類似於 CPU 中的單指令多數據（SIMD）指令。</span></span></span></p><blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">Volta 及其之後的新一代 GPU 引入了一種替代指令調度的機制，稱為獨立線程調度（Independent Thread Scheduling）。它允許線程之間完全併發，不受 warp 的限制。獨立線程調度可以更好地利用執行資源，也可以作為線程之間的同步機制。本文不會涉及獨立線程調度的相關內容，但你可以在 CUDA 編程指南中瞭解更多相關信息。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f">4. Warp 調度和時延容忍度</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">關於 warp 的運行原理，有一些值得討論的有趣之處。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">即使 SM 內的所有處理塊（核心組）都在處理 warp，但在任何給定時刻，只有其中少數塊正在積極執行指令。因為 SM 中可用的執行單元數量是有限的。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">有些指令的執行時間較長，這會導致 warp 需要等待指令結果。在這種情況下，SM 會將處於等待狀態的 warp 休眠，並執行另一個不需要等待任何結果的 warp。這使得 GPU 能夠最大限度地利用所有可用計算資源，並提高吞吐量。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">零計算開銷調度：由於每個 warp 中的每個線程都有自己的一組寄存器，因此 SM 從執行一個 warp 切換到另一個 warp 時沒有額外計算開銷。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">與 CPU 上進程之間的上下文切換方式（context-switching）不同。如果一個進程需要等待一個長時間運行的操作，CPU 在此期間會在該核心上調度執行另一個進程。然而，在 C</span><span style="color:#3f3f3f">PU 中進行上下文切換的代價昂貴，這是因為 CPU 需要將寄存器狀態保存到主內存中，並恢復另一個進程的狀態。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f">5. 將結果數據從設備複製到主機內存</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">最後，當 kernel 的所有線程都執行完畢後，最後一步就是將結果複製回主機內存。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">儘管我們涵蓋了有關典型 kernel 執行的全部內容，但還有一點值得討論：動態資源分區。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">5</span></strong></span></span></span></p><span id="OSC_h2_5"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">資源劃分和佔用概念</span></strong></span></span></span></p><p><span style="color:#3f3f3f"><span><span style="color:#494949">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">我們通過一個稱為「occupancy（佔用率）」的指標來衡量 GPU 資源的利用率，它表示分配給 SM 的 warp 數量與 SM 所能支持的最大 warp 數量之間的比值。為實現最大吞吐量，我們希望擁有 100% 的佔用率。然而，在實踐中，由於各種約束條件，這並不容易實現。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">為什麼我們無法始終達到 100% 的佔用率呢？SM 擁有一組固定的執行資源，包括寄存器、共享內存、線程塊槽和線程槽。這些資源根據需求和 GPU 的限制在線程之間進行動態劃分。例如，在 NVIDIA H100 上，每個 SM 可以處理 32 個線程塊、64 個 warp（即 2048 個線程），每個線程塊擁有 1024 個線程。如果我們啓動一個包含 1024 個線程的網格，GPU 將把 2048 個可用線程槽劃分為 2 個線程塊。</span></span></span></span></span></p><blockquote><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">動態分區 vs 固定分區：動態分區能夠更為有效地利用 GPU 的計算資源。相比之下，固定分區為每個線程塊分配了固定數量的執行資源，這種方式並不總是最有效的。在某些情況下，固定分區可能會導致線程被分配多於其實際需求的資源，造成資源浪費和吞吐量降低。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">下面我們通過一個例子説明資源分配對 SM 佔用率的影響。假設我們使用 32 個線程的線程塊，並需要總共 2048 個線程，那麼我們將需要 64 個這樣的線程塊。然而，每個 SM 一次只能處理 32 個線程塊。因此，即使一個 SM 可以運行 2048 個線程，但它一次也只能同時運行 1024 個線程，佔用率僅為 50%。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">同樣地，每個 SM 具有 65536 個寄存器。要同時執行 2048 個線程，每個線程最多有 32 個寄存器（65536/2048 =32）。如果一個 kernel 需要每個線程有 64 個寄存器，那麼每個 SM 只能運行 1024 個線程，佔用率同樣為 50%。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">佔用率不足的挑戰在於，可能無法提供足夠的時延容忍度或所需的計算吞吐量，以達到硬件的最佳性能。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">高效創建 GPU kernel 是一項複雜任務。我們必須合理分配資源，在保持高佔用率的同時儘量降低時延。例如，擁有大量寄存器可以加快代碼的運行速度，但可能會降低佔用率，因此謹慎優化代碼至關重要。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">6</span></strong></span></span></span></p><span id="OSC_h2_6"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">總結</span></strong></span></span></span></p><p><span style="color:#3f3f3f"><span><span style="color:#494949">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">我理解眾多的新術語和新概念可能令讀者望而生畏，因此文章最後對要點進行了總結，以便快速回顧。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><ul style="margin-left:8px; margin-right:8px"><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 由多個 SM 組成，每個 SM 又包含多個處理核心。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 上存在着一個片外全局內存，通常是高帶寬內存（HBM）或動態隨機存取內存（DRAM）。它與芯片上的 SM 相距較遠，因此時延較高。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 中有兩個級別的緩存：片外 L2 緩存和片上 L1 緩存。L1 和 L2 緩存的工作方式類似於 CPU 中的 L1/L2 緩存。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">每個 SM 上都有一小塊可配置的共享內存。這塊共享內存在處理核心之間共享。通常情況下，線程塊內的線程會將一段數據加載到共享內存中，並在需要時重複使用，而不是每次再從全局內存中加載。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">每個 SM 都有大量寄存器，寄存器會根據線程需求進行劃分。NVIDIA H100 每個 SM 有 65536 個寄存器。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">在 GPU 上執行 kernel 時，我們需要啓動一個線程網格。網格由一個或多個線程塊組成，而每個線程塊又由一個或多個線程組成。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">根據資源可用性，GPU 會分配一個或多個線程塊在 SM 上執行。同一個線程塊中的所有線程都會被分配到同一個 SM 上執行。這樣做的目的是為了充分利用數據的局部性（data locality），並實現線程之間的同步。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">被分配給 SM 的線程進一步分為大小為 32 的組，稱為 warp。一個 warp 內的所有線程同時執行相同的指令，但在數據的不同部分上執行（SIMT）（儘管新一代 GPU 也支持獨立的線程調度）。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 根據每個線程的需求和 SM 的限制，在線程之間進行動態資源劃分。程序員需要仔細優化代碼，以確保在執行過程中達到最高的 SM 佔用率。</span></span></span></span></span></p></li></ul><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">腳註</span></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">[1]沒錯，得益於超線程技術和多核處理器，CPU 也可以並行執行任務。但長期以來，大量工作都致力於提高順序執行的性能。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">[2]在當前一代的 NVIDIA GPU 中，warp 大小為 32。但在未來的硬件迭代中，這個大小可能會發生改變。</span></span></span></span></span></p><span id="OSC_h2_7"></span><h2 style="margin-left:8px; margin-right:8px">&nbsp;</h2><p style="text-align:left">&nbsp;</p><p style="text-align:left"><span style="color:#3f3f3f"><span><span style="background-color:#ffffff; color:#888888">其他人都在看</span></span></span></p><span id="OSC_h3_8"></span><h3>&nbsp;</h3><ul><li><p><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492657%26idx%3D1%26sn%3Da71795c583da44c805f79630f2ef635a%26chksm%3Dfe426a07c935e3112422680f4942c0b372c01db1e63e044010f03cd72689bce2563e8672136b%26scene%3D21%23wechat_redirect" target="_blank">開源語言大模型的正確姿勢</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492610%26idx%3D1%26sn%3D9b92f3efa0d85cb1bb689efab362c3e8%26chksm%3Dfe426a34c935e32200b2d9cc84916eb980ba3c8ab1eceafa9834e38049e5243ca8aa77564a68%26scene%3D21%23wechat_redirect" target="_blank">為什麼開源大模型終將勝出</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492849%26idx%3D1%26sn%3D51f53e04b4b97cd9dd38429784015c98%26chksm%3Dfe426ac7c935e3d1b5970441a68c53b6dae05792cd9a244ad8efb40ffc5ab4c60cdf3a7181b0%26scene%3D21%23wechat_redirect" target="_blank">LoRA 和 QLoRA 微調語言大模型</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492767%26idx%3D1%26sn%3Ded8acf6d7e9117b5ab3ea0de8e540460%26chksm%3Dfe426aa9c935e3bfb8b3e2ffc7cb6349f076f4f25d2fbe13b6e8e2c30ea010261c57f8d6cacb%26scene%3D21%23wechat_redirect" target="_blank">OpenAI 規模經濟與第二護城河</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492787%26idx%3D1%26sn%3Dc5d16b72e94079bb20e9772cad81e703%26chksm%3Dfe426a85c935e393a9962ab763fc1f06ebaf1bd75331cc089ff61f8655c0e8ecbb8211264544%26scene%3D21%23wechat_redirect" target="_blank">全面對比 GPT-3.5 與 LLaMA 2 微調</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492811%26idx%3D1%26sn%3D916e330a2a4152dab3192635c3e475fa%26chksm%3Dfe426afdc935e3eb2f371ff5f56247c95800ce91a950a89bea871c26ddc4c3d13371acf03978%26scene%3D21%23wechat_redirect" target="_blank">語言大模型推理性能工程：最佳實踐</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492618%26idx%3D1%26sn%3Da20f4828b9ab3e3cee3fedfd906e0eb2%26chksm%3Dfe426a3cc935e32a8312ce9efbb4f2640787508d3e811579bbffe918685cdb07a8bd8e3ffc4b%26scene%3D21%23wechat_redirect" target="_blank">LLVM 之父:我的 AI 基礎設施軟件構建理念</a></span></span></p></li></ul><span id="OSC_h3_9"></span><h3>&nbsp;</h3><p><strong><span style="color:#3f3f3f"><span><span>試用 OneFlow: <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank">github.com/Oneflow-Inc/oneflow/</a></span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank"></a></span></span></strong></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><img src="https://oscimg.oschina.net/oscnet/b316e9d8-4d68-4323-98d4-8e2e62cf5163.png" referrerpolicy="no-referrer"></span></span></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br> 如有侵權，請聯繫 support@oschina.cn 刪除。<br> 本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10140417</guid>
            <link>https://my.oschina.net/oneflow/blog/10140417</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為與美團達成合作，正式啓動鴻蒙原生應用開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>華為迎來又一個鴻蒙生態的重要合作伙伴，宣佈與美團以 HarmonyOS 為基礎進行產業創新、技術應用、商業發展等方面展開全面合作，全力支持美團啓動開發鴻蒙原生應用工作。</p><p>自 9 月 25 日華為宣佈全新 HarmonyOS NEXT 蓄勢待發、鴻蒙原生應用全面啓動以來，已有金融、旅行、社交等多個領域的企業和開發者陸續宣佈加入鴻蒙生態。此次美團成為最新加速融入鴻蒙生態的行業頭部夥伴，形成「鴻蒙千帆起」的景象。</p><p>週一，在北京舉行的「鴻蒙原生應用開發啓動儀式」上，華為終端雲服務總裁朱勇剛表示：「很高興美團成為鴻蒙生態重要的合作伙伴，鴻蒙正在致力於打造一個‘一切皆服務，萬物可分享’的新生態。鴻蒙獨有的分佈式技術，以及一次開發、多端部署，能讓美團的服務在手機、平板、車機等設備上無縫流轉，為用戶提供場景化、智慧化的「服務合時宜」新體驗。未來華為希望與美團基於端到端的鴻蒙生態，持續源源不斷地的創新，助力美團等互聯網企業獲取新流量和商機，創造更大的商業價值。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-36c3813f9e9377dea1c3a86232a7923485a.png" referrerpolicy="no-referrer"></p><p>作為紮根本地的中國科技零售企業，美團通過「零售+科技」的戰略踐行「幫大家吃得更好，生活更好」的公司使命。美團高級副總裁李樹斌表示：「美團始終以客戶為中心，不斷加大在新技術上的研發投入，這與華為鴻蒙操作系統在前沿領先領域的探索努力不謀而合。我們希望與華為共同努力，在鴻蒙系統生態裏為用戶提供更好的服務和體驗。」</p><p>作為鴻蒙生態社交領域的重要夥伴，美團與華為早有深厚的鴻蒙生態合作基礎，此前美團就已基於鴻蒙系統特點和用戶需求，有針對性地率先開發和適配了多項功能，包括上線華為手機桌面「萬能卡片」元服務、Push Kit 實況窗功能等。</p><p>未來，華為將攜手美團等更多合作伙伴，持續共同建設鴻蒙生態，依託於 HarmonyOS 原生應用在全場景多設備高效協同、原生智能、更強大的 AI 能力、更高的安全和隱私保護體驗等獨特的技術優勢，展開全方位深層次的合作，為消費者帶來更流暢、更智能、更安全的服務體驗。</p><p>數據顯示，截至今年 8 月份，鴻蒙生態設備數量超過 7 億台，已有 220 萬開發者投入到鴻蒙生態的開發，華為始終與夥伴共享鴻蒙生態新機遇，共創萬物互聯新未來。</p><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/266107">多家互聯網公司急招鴻蒙程序員</a></li><li><a href="https://www.oschina.net/news/265725">美團招兵買馬，擬開發鴻蒙系統 App</a></li><li><a href="https://www.oschina.net/news/261747">深圳信息職業技術學院開設「開源鴻蒙班」</a></li><li><a href="https://www.oschina.net/news/252658">HarmonyOS NEXT：使用全自研內核</a></li><li><a href="https://www.oschina.net/news/252385/harmonyos-4">華為正式發佈 HarmonyOS 4</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266352</guid>
            <link>https://www.oschina.net/news/266352</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 原生編譯的 Solon 回憶錄]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start">最近和<code>@雨韻詩澤</code>、<code>@讀釣</code>兩個小夥伴一起（主要是他們兩在出力），適配了<span>&nbsp;</span><strong>Solon Native</strong><span>&nbsp;</span>的第一個開源項目：<a href="https://gitee.com/dromara/neutrino-proxy">dromara/neutrino-proxy</a><span>&nbsp;</span>（里程碑案例啊！有點修行大成的味道了！）。總體來説：</p><ul><li>適配調整完後，代碼變化不太大</li><li>整個過程是很麻煩的。因為 graalvm native image 社區版不能調試，只能不斷試（發現缺什麼，就補什麼配置）</li></ul><h3>1、緣起</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2021 年的深秋</span>，有個叫<span>&nbsp;</span><code>@饅頭蟲</code><span>&nbsp;</span>的男人。跑過來講，他有個項目需求是（給一個美國大廠做的）：存放空間只有 100M，內存只有 100M，在硬件裏運行一個管理界面系統。他研究了 spring native，因為它的基礎就太大沒過；研究了 go，做複雜的界面系統不好預期沒過。所以選擇嘗試 solon。</p><p style="color:#24292e; text-align:start">於是他種下了一顆 solon native 的種子。開始澆水、施肥。前後一兩個月的時間，真的也開花了（最後好像只有 53m 大小）。這 365 萬字省去，他怎麼不哭呢？</p><p style="color:#24292e; text-align:start">這個男人總結出了三條經驗：</p><ul><li>所有的反射需要提前登記（放到特定的配置文件裏），並通過配置獲取反射導引（比如一個類有哪些字段，哪些方法）</li><li>所有的資源文件獲取需要提前登記（放到特定的配置文件裏）</li><li>所有的動態編譯、類字節碼，不能用</li></ul><p style="color:#24292e; text-align:start">説起來，<a href="https://gitee.com/noear/solon">Solon 框架</a><span>&nbsp;</span>真的是好啊（按那男人的講法：小是真的小，快是真的快）：</p><ul><li>啓動快 5 ～ 10 倍；</li><li>qps 高 2～ 3 倍；</li><li>運行時內存節省 1/3 ~ 1/2；</li><li>打包可以縮到 1/2 ~ 1/10；</li></ul><h3>2、認識 APT</h3><p style="color:#24292e; text-align:start">後面很長的時間，我沒再碰它（主要是無知，無從下手。懵！）。偶然的一天，路過 mybatis-plus 4.x 項目倉庫，看到 APT 這幾個字眼。我對 java 確實是無知，百度後才知道神器 lombok 就是基於 APT 實現的。然後，我想起了那個男人總結的三條經驗：</p><ul><li>所有的反射需要提前登記</li><li>所有的資源文件獲取需要提前登記</li><li>所有的動態編譯、類字節碼，不能用</li></ul><p style="color:#24292e; text-align:start">是不是可以藉助 APT，去提前生成類的代理代碼，去完成資源文件、反射的登記？我估計是行的。</p><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的初春</span>，花了一週時間，把類的代理用 APT 在編譯時生成了。開心是開心的。但是，怎樣獲取需要代理的類，成了一個不解的題。路很長。然後，暫時沒有然後了！</p><h3>3、認識 AOT</h3><p style="color:#24292e; text-align:start">好多年前就聽過 AOT，大概知道它是幹嘛的。但是，還是一臉懵。</p><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的春後</span>，有個叫<span>&nbsp;</span><code>@李總</code><span>&nbsp;</span>的男人。他説，我有個項目想要用 solon 的原生編譯，而且可以叫個人幫忙搞。最後出現的男人叫<span>&nbsp;</span><code>@讀釣</code>，不知道是<span>&nbsp;</span><code>@李總</code><span>&nbsp;</span>忽悠過來的，還是我把他忽悠過來的（後來，據他説是自己跑來的）。他説，我們應該 A,B,C...這麼這麼搞！</p><p style="color:#24292e; text-align:start">還有個加強版的 AOT。原來如此，原來如此：</p><ul><li>在編譯後 -&gt; 運行項目並獲取運行中的信息 -&gt; 然後完成各種預編譯和登記 -&gt; 再進行原生編譯</li><li>一氣呵成</li></ul><p style="color:#24292e; text-align:start">這個男人從春天搞到了夏天。成了！（當中略過 365 萬字...），一直搞，不知道有沒有洗過澡， 有沒有換過衣服。</p><h3>4、我們發佈第一個 Solon Native 版本</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的夏天</span>，有個新男人來。説是要用 Solon Native。我心裏其實沒底，原生這東西太難用了。必須得忍住不哭才行。後來他招乎也沒打，跑了。</p><p style="color:#24292e; text-align:start">真的是太難用了：</p><ul><li>目前沒有哪個框架是開箱即用的（Spring Native 和 Quarkus 也一樣）</li><li>框架不一定把生態內的所有包都適配好了</li><li>第三方的包，框架沒法照顧到。只能自己試着做些補充登記（沒法調試，只能嘗試或實驗）</li><li>隨便升級某個第三方包，就可能不兼容了（需要重新適配）</li></ul><h3>5、你信輪迴？</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的深秋</span>，又是一個深秋。男人<span>&nbsp;</span><code>@雨韻詩澤</code>，説想把他的<span>&nbsp;</span><a href="https://gitee.com/dromara/neutrino-proxy">dromara/neutrino-proxy</a><span>&nbsp;</span>開源項目搞成原生編譯的。我説，那得忍住不哭才行。他説，他不會哭（其實，他動得不多。哈哈）。<code>@讀釣</code>又開始忙了。</p><p style="color:#24292e; text-align:start">説起來，<code>@讀釣</code><span>&nbsp;</span>是從春天干到了秋天。終於成了：<a href="https://www.oschina.net/news/264550/solon-2-5-12-released">《Solon v2.5.12 發佈，Java 原生編譯再起》</a>。我們也是正經的支持 Java 原生編譯的生態型框架了。且是，國產的。</p><p style="color:#24292e; text-align:start"><span style="background-color:#ffffff; color:#24292e">開源，讓很多人的願望和努力匯聚一處，也記錄了共同的回憶。</span></p><p style="color:#24292e; text-align:start">人生路，且短且長，只怪情深緣淺，你信輪迴？</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 01:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266350</guid>
            <link>https://www.oschina.net/news/266350</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘋果將禁止「搖一搖」跳轉廣告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tfcaijing.com%2Farticle%2Fpage%2F474a676e737050677a746a63653436332f646c3554773d3d" target="_blank">據時代財經報道</a></u>，互聯網大廠內部人士常樂年稱，11 月以來，蘋果公司已通知國內多家頭部 App 要求它們移除陀螺儀權限，搖一搖跳轉廣告被禁止。</p><p>據報道，11 月以來，蘋果公司已通知在線視頻軟件、短視頻軟件、音頻軟件、郵箱軟件等多種類型的 App，<strong>要求它們取消搖一搖跳轉廣告的功能</strong>。常樂年所在公司的 App 也在通知的範圍內。他透露，接下來公司可能會發布新版本 App，在蘋果的 App Store 上架，新版本將沒有搖一搖跳轉廣告，具體發佈時間還不確定。</p><p>另一位廣告從業者也證實了這一消息，他的客戶也是互聯網大廠，旗下有行業頭部 App。他説，收到通知的不只是頭部 App，還有很多其他的 App，範圍很廣。</p><p>搖一搖功能調用的是陀螺儀權限，這是一種很早就有的功能，可以用來搶電視紅包、識別歌曲等，但現在被用來做廣告跳轉，而有些手機沒有陀螺儀權限開關，用戶無法自行關閉。</p><p><img src="https://static.oschina.net/uploads/space/2023/1114/084659_fhVb_2720166.png" referrerpolicy="no-referrer"></p><p>一位手機大廠的工作人員説，這種跳轉是 App 開發出來的商業模式，手機廠商很難做系統性的調整。</p><p>中國信息通信研究院此前聯合華為、小米、OPPO、阿里巴巴等企業制定了團體標準 T / TAF 078.7—2022，於 2022 年 11 月由電信終端產業協會發布實施，該標準進一步細化了 App 信息窗口通過「搖一搖」等方式觸發頁面或跳轉至第三方應用的相關參數，提出「搖一搖」動作的設備加速度應不小於 15m/s2，轉動角度不小於 35°，操作時間不少於 3s 等系列參考數值。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 00:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266344</guid>
            <link>https://www.oschina.net/news/266344</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
