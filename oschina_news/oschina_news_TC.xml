<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 12 Dec 2023 03:58:27 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[鎧俠向 Linux 基金會捐贈 Software-Enabled Flash SDK]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#121212">幾年前從東芝分離出來的存儲公司 Kioxia（</span>鎧俠<span style="background-color:#ffffff; color:#121212">）向 Linux 基金會捐贈了一個軟件開發工具包 (SDK)，用於建立 Software-Enabled Flash SDK。</span></p><p><span style="background-color:#ffffff; color:#121212">Linux 基金會發布<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fsoftware-enabled-flash-announces-software-development-kit-sdk" target="_blank">公告稱</a>，「SEF SDK 的發佈是存儲技術領域的一個重要里程碑......SEF 項目對 KIOXIA 突破性地捐贈軟件定義閃存原生 SDK 表示熱烈歡迎，這將為開發人員提供前所未有的能力，使他們能夠為閃存存儲（flash storage）應用開發定製的獨特軟件。」</span></p><p><img alt="" height="228" src="https://oscimg.oschina.net/oscnet/up-67690b065c2207474d1a67124aa3ef403da.png" width="300" referrerpolicy="no-referrer">&nbsp; &nbsp;<img alt="" height="228" src="https://oscimg.oschina.net/oscnet/up-1056c78ed4258dcb84497a6e896204821c0.jpg" width="300" referrerpolicy="no-referrer"></p><p>該 SEF SDK 包括示例代碼和文檔，以充分利用 flash media control 的潛力；包括 WAF 減少、延遲控制、對 ZNS 和 FDP 或 Block 等多種協議的支持等。</p><p>SEF 項目旨在通過加強對驅動器的管理、增強工作負載隔離、加強延遲控制以及實現對閃存管理的更多&nbsp;host-control，在現代數據中心中開闢新的用途並最大限度地發揮基於閃存的存儲潛力。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 03:10:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270608/software-enabled-flash-sdk</guid>
            <link>https://www.oschina.net/news/270608/software-enabled-flash-sdk</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[芯瞳正式加入 openKylin，為社區貢獻高質量的國產 GPU 解決方案！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，芯瞳半導體技術（山東）有限公司（以下簡稱「芯瞳」），簽署 openKylin 社區 CLA（Contributor License Agreement 貢獻者許可協議），正式加入 openKylin 開源社區。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-4c9b13fca5452f4a217f1494d816e96a799.png" width="829" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>芯瞳（Sietium）成立於 2019 年，是一家自主設計研發 GPU 芯片及 GPU 解決方案的高科技公司，以行業先進的計算和圖形渲染平台為依託，用高質量的產品和服務為雲端、終端客戶提供可持續發展的國產 GPU 解決方案；為數字時代的創新與發展提供算力支撐，構建自由算力的文明世界。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-6914c94ad47861f5f685cb96e9bc21450f1.png" width="940" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong><span>加入 openKylin 社區後，芯瞳將參與維護社區 GPU SIG 和 Wayland SIG</span></strong><span>。<strong>憑藉其自研的 GPU 顯卡和深厚的行業經驗，優化 openKylin 環境中顯卡驅動的兼容性，確保與芯瞳顯卡的完美適配</strong>。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>在 openKylin 平台上，芯瞳顯卡將展現其在圖形顯示、渲染、視頻編解碼和大規模計算等方面的優勢，以此提升 openKylin 的用戶體驗，並提供持續的 GPU 產品升級和技術支持，為用戶提供安全可靠的使用體驗。具體計劃如下：</span></p><ul><li><p style="margin-left:0; margin-right:0"><span>積極參與社區合作，緊密關注社區的發展動態，與社區成員攜手推動 openKylin 社區的生態及品牌建設，努力構建一個健康的生態環境，為開源生態的發展貢獻力量。</span></p></li><li><p style="margin-left:0; margin-right:0"><span>尋求與社區的技術合作，通過聯合調試等方式，使 openKylin 的相關產品能更好地兼容並適應芯瞳的全新系列顯卡，從而提高產品的穩定性和性能。</span></p></li><li><p style="margin-left:0; margin-right:0"><span>在應用層面，芯瞳將持續優化軟件算法，提高系統效率，充分發掘 openKylin 在芯瞳顯卡平台上的性能潛力，從而提升整體性能，為用戶提供卓越的產品體驗。</span></p></li></ul><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>通過這一系列的舉措，芯瞳將與 openKylin 社區並肩前行，共同推動 openKylin 社區生態良好發展，為用戶帶來更多的創新和驚喜。同時，芯瞳期待與社區成員進行深入的交流和分享，以推動技術的進步和產業的協同發展，共同為中國開源生態的繁榮作出貢獻。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 03:09:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270607</guid>
            <link>https://www.oschina.net/news/270607</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Facebook 開源 StyleX —— 在 JavaScript 中寫 CSS]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Meta（原 Facebook）<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstylexjs.com%2Fblog%2Fintroducing-stylex%2F" target="_blank">開源</a></u>了全新的 CSS-in-JS 庫 StyleX。</p><p><img src="https://oscimg.oschina.net/oscnet/up-30f683ba9535a9f16ce5e615736da0460cd.png" referrerpolicy="no-referrer"></p><blockquote><p><em>GitHub 地址：<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffacebook%2Fstylex" target="_blank">https://github.com/facebook/stylex</a></u></strong></em></p></blockquote><p>官方介紹道，StyleX 是一個富有表現力、具有確定性、可靠且可擴展的樣式系統。它通過使用編譯時 (compile-time) 工具融合了靜態 CSS 的性能和可擴展性。</p><p>此外，StyleX 不僅僅是一個基於編譯器的 CSS-in-JS 庫，它經過精心設計，可以滿足大型應用程序、可複用組件庫和靜態類型代碼庫的要求。Meta 旗下多款產品如 Facebook、WhatsApp、Instagram、Workplace、Threads 等都在使用 StyleX 作為其 CSS 樣式解決方案。</p><p>StyleX 主要特性</p><ul><li><p><strong>快速</strong>：StyleX 在編譯時和運行時都具備高效的性能。Babel 轉換不會對構建過程產生顯著影響。在運行時，StyleX 避免了使用 JavaScript 插入樣式的開銷，並僅在必要時高效地組合類名字符串。生成的 CSS 經過優化，確保即使是大型網站的樣式也能被瀏覽器快速解析。</p></li><li><p><strong>可擴展</strong>：StyleX 旨在適應像 Meta 這樣的超大型代碼庫。通過原子構建和文件級緩存，Babel 插件能夠處理數萬個組件在編譯時的樣式處理。由於 StyleX 設計為封裝樣式，它允許在隔離環境中開發新組件，並期望一旦在其他組件中使用時能夠可預測地呈現。</p></li><li><p><strong>可預測性</strong>：StyleX 會自動管理 CSS 選擇器的特異性，以確保生成的規則之間不會發生衝突。它為開發人員提供了一個可靠地應用樣式的系統，並確保「最後應用的樣式始終生效」。</p></li><li><p><strong>類型安全</strong>：使用 TypeScript 或 Flow 類型來約束組件接受的樣式，每個樣式屬性和變量都具有完全的類型定義。這有助於提高代碼的可讀性和可維護性，同時減少潛在的錯誤和衝突。</p></li><li><p><strong>樣式去重</strong>：StyleX 鼓勵在同一文件中編寫樣式和組件。這種方法有助於使樣式在長期內更具可讀性和可維護性。StyleX 能夠利用靜態分析和構建時工具來跨組件去重樣式，並刪除未使用的樣式。</p></li><li><p><strong>可測試性</strong>：StyleX 可以配置為輸出調試類名，而不是功能性的原子類名。這可以用於生成快照，以便在對設計進行輕微更改時不會經常變化。通過這種方式，開發人員可以更輕鬆地測試和驗證樣式的正確性，從而提高開發效率和產品質量。</p></li></ul><p><strong>示例代碼</strong></p><pre><code class="language-javascript">import stylex from '@stylexjs/stylex';

const styles = stylex.create({
  root: {
    padding: 10,
  },
  element: {
    backgroundColor: 'red',
  },
});

const styleProps = stylex.apply(styles.root, styles.element);</code></pre><p><strong>下面是一個按鈕組件的示例代碼</strong></p><pre><code class="language-javascript">import * as stylex from "@stylexjs/stylex";

const styles = stylex.create({
  base: {
    appearance: "none",
    borderWidth: 0,
    borderStyle: "none",
    backgroundColor: "blue",
    color: "white",
    borderRadius: 4,
    paddingBlock: 4,
    paddingInline: 8,
  },
});

export default function Button({
  onClick,
  children,
}: Readonly&lt;{
  onClick: () =&gt; void;
  children: React.ReactNode;
}&gt;) {
  return (
    &lt;button {...stylex.props(styles.base)} onClick={onClick}&gt;
      {children}
    &lt;/button&gt;
  );
}</code></pre></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270597/facebook-stylex-css-in-js</guid>
            <link>https://www.oschina.net/news/270597/facebook-stylex-css-in-js</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Arc 瀏覽器開始 Windows 版 Beta 測試]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 11 日，Arc 瀏覽器開始 Windows 版 Beta 測試，第一批邀請已在加入等待隊列的用戶中篩選併發送完畢。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e387f48e7934b2c6d34f92595dbaea17a39.png" referrerpolicy="no-referrer"></p><p>感興趣的用戶可以在上線的&nbsp;<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.isarconwindowsyet.com%2F" target="_blank">IsArcOnWindowsYet</a></u>&nbsp;頁面中，填寫表單加入等待隊列。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-688afd52e0b014510739c8706073d792afb.png" referrerpolicy="no-referrer"></p><p><strong>Arc 基於 Chromium 並用 Swift 語言編寫</strong>。它支持 Chrome 瀏覽器擴充功能，同時默認使用 Google 搜索。7 月份，Arc 正式發佈了 1.0。</p><blockquote><p><u><strong><em><a href="https://www.oschina.net/news/251034/arc-browser-1-0-mac-released">Arc 瀏覽器正式發佈 1.0，聲稱是 Chrome 的替代品</a></em></strong></u></p></blockquote><p>Arc 旨在成為一個 「萬維網的操作系統」，並試圖將網頁瀏覽與內置應用程序和功能整合在一起。其內置的功能包括虛擬記事本、拼貼風格的 「easel」 和 「boosts」，該功能允許用戶美化和重新設計網站界面。Arc 的選項卡垂直排列在側邊欄中，側邊欄包含除瀏覽窗口之外的所有瀏覽器功能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-34b7b76a856863e0f84e96557bd15c058e6.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270593/arc-for-windows-is-in-beta</guid>
            <link>https://www.oschina.net/news/270593/arc-for-windows-is-in-beta</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google Colab 現已支持直接使用 🤗 transformers 庫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 編輯器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Google Colab，全稱 Colaboratory，是 Google Research 團隊開發的一款產品。在 Colab 中，任何人都可以通過瀏覽器編寫和執行任意 Python 代碼。它尤其適合機器學習、數據分析和教育目的。從技術上來説，Colab 是一種託管式 Jupyter 筆記本服務。用戶無需設置，就可以直接使用，同時還能獲得 GPU 等計算資源的免費使用權限。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005864" data-ratio="0.6592592592592592" src="https://oscimg.oschina.net/oscnet/6aca6440-d2d5-4972-8624-54894772e85a.jpg" data-type="jpeg" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;" referrerpolicy="no-referrer"></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">通過與 Colab 團隊的共同努力，Colab 託管的運行時鏡像現已默認集成了 Hugging Face transformers 庫，只需簡單執行 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">import transformers</code> 即可輕鬆接入！對於使用 Colab 進行機器學習和深度學習研究的開發者來説，這是一個非常重要的更新。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你想使用最新版本的 transformers，Colab 團隊也提供了一個簡單的命令 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">!pip install transformers --upgrade</code>，以便於隨時更新至最新版本。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">除了提升用戶體驗，這一更新還開啓了一些有趣的新功能。例如，用戶現在可以直接從 Pandas 讀取 Hugging Face 數據集，這將大大簡化數據處理和模型訓練的工作流程。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005865" data-ratio="0.4203703703703704" src="https://oscimg.oschina.net/oscnet/8ecbb7d1-9659-48de-9e0f-64e60f62d9ef.jpg" data-type="jpeg" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;" referrerpolicy="no-referrer"></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">本合作和更新還開啓了一些有趣的新功能。例如，用戶現在可以直接從 Pandas 讀取 Hugging Face 數據集，這將大大簡化數據處理和模型訓練的工作流程。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可以通過 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">hf://datasets/</code> 的方式在 Pandas 中直接讀取 Hugging Face Hub 上的數據集。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">感謝 Colab 團隊的朋友們，也希望社區的成員們喜歡本次的合作和功能更新！</p></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:07:55 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10316003</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10316003</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[HashiCorp 採用 BSL 後續，Linux 基金會孵化 Vault 開源替代品]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">今年 8 月，<span style="background-color:#ffffff">專注於雲基礎設施的軟件供應商 HashiCorp&nbsp;</span>宣佈<span style="background-color:#ffffff">修改其核心產品的開源協議。</span><strong style="color:#333333">所有 HashiCorp 產品的未來版本</strong><span style="background-color:#ffffff">將從 Mozilla Public License v2.0 (MPL 2.0) 變更為&nbsp;</span><strong style="color:#333333">Business Source License (BSL, also known as BUSL) v1.1</strong><span style="background-color:#ffffff">，其中包括&nbsp;Vault、Boundary、Consul、Nomad、Packer、Terraform、Vagrant 和 Waypoint 等。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">採用 BSL 1.1 的項目，其代碼仍會公開 (source-available)，</span><strong style="color:#333333">但只允許在特定條件下進行復制、修改、重新分發、非商業使用和商業使用</strong><span style="background-color:#ffffff">&nbsp;—— 主要是添加了商業使用方面的限制。</span></span></p><p><span style="color:#000000">此後，社區在抗議無效後選擇創建了 Terraform 的分支項目 OpenTofu（原名 OpenTF），並託管在了 Linux 基金會下。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">時至今日，有消息稱 Linux 基金會正計劃幫助孵化一個私密信息管理工具 Vault 的開源替代品。DevOps 自動化公司 Scalr 的聯合創始人兼首席執行官 Sebastian Stadil 和 OpenTofu 的組織者之一<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F12%2F08%2Fhashicorp_openbao_fork%2F" target="_blank">透露</a>，Vault 開源替代品的項目名為 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.lfedge.org%2Fdisplay%2FOH%2FOpenBao%2B%2528Hashicorp%2BVault%2BFork%2Beffort%2529%2BFAQ" target="_blank">OpenBao</a>，是競爭對手在 MPL 2.0 協議下創建的一個&nbsp;Vault 分支。</span></span></p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-1f318fa9f93212c7ed6a67c0b91e135c731.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><span style="background-color:#ffffff">OpenTofu 計劃在本月晚些時候發佈候選版本，OpenBao 也將開始接受新的貢獻。Stadil 表示，「如果有兩個相同的項目，一個是開源的，一個不是，我個人認為，道德上的選擇是使用開源項目，並以某種方式提供幫助。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">不過鑑於 OpenTofu 和 OpenBao 都是新近開發的項目，項目的可行性和持久性受到了很多關注。針對這一擔憂，Stadil 表示拒絕代表其他公司發言。事實上，他還被告知不要透露任何關於其他組織支持這些項目的消息。對於那些想要了解更多詳情的人，他建議可以訪問項目的 repos。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">當被問及 HashiCorp 重新授權其軟件的理由時，Stadil 回答稱，官方的説法是 Terraform 對互聯網至關重要，而長期以來人們一直希望將其置於 Linux 基金會的監督之下。「如果 HashiCorp 將來願意加入我們的 OpenTofu，我們會很樂見其成」。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">但</span><span style="background-color:#ffffff">他無法推測 HashiCorp 的內部決策過程。Stadil 指出，Hashicorp 一直在燒錢，隨着利率的上升，這家軟件公司選擇採取措施創造更多收入也不足為奇。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">上週，HashiCorp 公佈了 2024 財年第三財季的營收報告。營收 1.461 億美元，同比增長 17%。按照美國通用會計準則（GAAP），淨虧損為 3950 萬美元，低於去年同期的 7200 萬美元。</span></span></p><p><strong><span style="color:#000000"><span style="background-color:#ffffff">相關閲讀：</span></span></strong></p><ul><li><a href="https://www.oschina.net/news/253275/hashicorp-adopts-business-source-license" target="_blank">HashiCorp 核心產品變更開源協議，未來將採用 BSL</a></li><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/255700/opentf-fork-terraform" target="_blank">HashiCorp 採用 BSL 後，社區創建 Terraform 分支 OpenTF</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 07:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270477/hashicorp-vault-openbao-fork</guid>
            <link>https://www.oschina.net/news/270477/hashicorp-vault-openbao-fork</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 開源調試工具 ixGDB]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-readme-for-ixgdb-release" class="anchor" href="https://gitee.com/deep-spark/ixgdb#readme-for-ixgdb-release"></a>README for ixGDB release</h1><h2><a id="user-content-introduction" class="anchor" href="https://gitee.com/deep-spark/ixgdb#introduction"></a>INTRODUCTION</h2><p>ixGDB is Iluvatar CUDA source-level debugger for Linux OS, based on NVIDIA <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FNVIDIA%2Fcuda-gdb">CUDA-GDB</a> 10.2.</p><p>ixGDB provides the following capabilities:</p><ul><li>Provides a seamless debugging environment that allows simultaneous debugging of both GPU and CPU code within the same application.</li><li>Supports debugging C/C++ applications and all CUDA applications, which might use CUDA driver APIs or CUDA runtime APIs.</li><li>Supports setting breakpoints.</li></ul><h2><a id="user-content-build-instructions-example-only-adjust-as-needed" class="anchor" href="https://gitee.com/deep-spark/ixgdb#build-instructions-example-only-adjust-as-needed"></a>BUILD INSTRUCTIONS (example only, adjust as needed)</h2><p>First, make sure that libtermcap and other required dependent packages are
installed (try "sudo yum install ncurses-devel"). The "configure" command will
report an error if some packages are missing.</p><p>Please note that the libexpat development headers must be present if ixGDB is to be used for cross-platform debugging.</p><p>Issue the following commands to build ixGDB:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./configure --program-prefix=cuda- \</span><span id="LC2" class="line">    --enable-cuda \</span><span id="LC3" class="line">    --enable-targets="x86_64-apple-darwin,x86_64-unknown-linux-gnu,\</span><span id="LC4" class="line">    arm-elf-linux-gnu,m68k-unknown-linux-gnu" \</span><span id="LC5" class="line">    CFLAGS='-I/usr/local/cuda/include' \</span><span id="LC6" class="line">    LDFLAGS='-lpthread'</span><span id="LC7" class="line">make</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-using-ixgdb" class="anchor" href="https://gitee.com/deep-spark/ixgdb#using-ixgdb"></a>USING ixGDB</h2><p>All standard GDB commands could be used for both CPU and GPU code debugging. In addition to that, ixGDB provides CUDA-specific command families like "info cuda ..." to query GPU states, "cuda .." to control debugger focus on GPU and "[get|set] cuda .." to alter/query CUDA debugger configuration. If you want to know more about how to use ixGDB, please go to Iluvatar CoreX support <a href="https://gitee.com/link?target=https%3A%2F%2Fsupport.iluvatar.com%2F%23%2FDocumentCentre%3Fid%3D1%26nameCenter%3D1%26productId%3D">official site</a> and use "ixgdb" as the keyword to find document "SDK Tools User Guide", which includes detailed usage of ixGDB.</p><h2><a id="user-content-communication" class="anchor" href="https://gitee.com/deep-spark/ixgdb#communication"></a>COMMUNICATION</h2><p><a href="https://gitee.com/deep-spark/ixgdb/issues">Gitee Issues</a>: bug reports, feature requests, install issues, usage issues, etc.</p><h2><a id="user-content-license" class="anchor" href="https://gitee.com/deep-spark/ixgdb#license"></a>LICENSE</h2><p>Licensee's use of the GDB third party component is subject to the terms and conditions of GNU GPL v3:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">This product includes copyrighted third-party software licensed under the terms of the GNU General Public License v3 ("GPL v3"). All third-party software packages are copyright by their respective authors.</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Consistent with these licensing requirements, the software listed below is provided under the terms of the specified open source software licenses.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">Component    License</span><span id="LC2" class="line">ixGDB        GPL v3</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/deep-spark/ixgdb</guid>
            <link>https://gitee.com/deep-spark/ixgdb</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 機器學習硬件十年：性能變遷與趨勢]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><section style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><section><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-style="max-width: 100%; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important; color: rgb(163, 163, 163) !important;" class="js_darkmode__0" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)"><section><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-style="padding: 10px; max-width: 100%; background-color: rgb(239, 239, 239); color: rgb(62, 62, 62); line-height: 25.6px; display: inline-block; width: 670px; border-width: 2px; border-style: dashed; border-color: transparent; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important;" class="js_darkmode__1" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)"><section style="margin-right: 8px;margin-left: 8px;"><img class="rich_pages wxw-img" data-backh="421" data-backw="562" data-cropselx1="0" data-cropselx2="562" data-cropsely1="0" data-cropsely2="421" data-galleryid="397826930927296512" data-gallerysupplier="1" data-imgfileid="100009383" data-ratio="0.6666666666666666" data-s="300,640" data-type="jpeg" data-w="1080" style="text-align: center;letter-spacing: 0.578px;font-size: var(--articleFontsize);width: 578px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/b41ccc75-f4d2-460d-b101-02526ac0c450.jpg" referrerpolicy="no-referrer"><br></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section><section style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><section style="outline: 0px;background-color: rgb(25, 25, 25);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-style="max-width: 100%; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important; color: rgb(163, 163, 163) !important;" class="js_darkmode__0" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;background-color: rgb(255, 255, 255);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section style="margin-right: 8px;margin-left: 8px;outline: 0px;visibility: visible;line-height: 1.75em;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-style="padding: 10px; max-width: 100%; background-color: rgb(239, 239, 239); color: rgb(62, 62, 62); line-height: 25.6px; display: inline-block; width: 670px; border-width: 2px; border-style: dashed; border-color: transparent; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important;" class="js_darkmode__1" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="padding: 10px;outline: 0px;background-color: rgb(239, 239, 239);line-height: 25.6px;display: inline-block;width: 670px;border-width: 2px;border-style: dashed;border-color: transparent;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;caret-color: rgba(0, 0, 0, 0);outline: 0px;line-height: 1.6em;"><span style="font-size: var(--articleFontsize);letter-spacing: 2px;">本文分析了機器學習硬件性能的最新趨勢，重點關注不同 GPU 和加速器的計算性能、內存、互連帶寬、性價比和能效等指標。這篇分析旨在提供關於 ML 硬件能力及其瓶頸的全面視圖。本文作者來自調研機構<span style="letter-spacing: 2px;caret-color: rgba(0, 0, 0, 0);text-wrap: wrap;background-color: rgb(239, 239, 239);">E</span><span style="letter-spacing: 2px;caret-color: rgba(0, 0, 0, 0);text-wrap: wrap;background-color: rgb(239, 239, 239);">poch，致力於研究 AI 發展軌跡與治理的關鍵問題和趨勢。</span></span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;caret-color: rgba(0, 0, 0, 0);outline: 0px;line-height: 1.6em;"><br></p><section style="margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 2px;">（本文由 OneFlow 編譯發佈，轉載請聯繫授權。原文：https://epochai.org/blog/trends-in-machine-learning-hardware#computational-price-performance</span><strong style="caret-color: rgba(0, 0, 0, 0);font-size: var(--articleFontsize);letter-spacing: 2px;"></strong></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;caret-color: rgba(0, 0, 0, 0);line-height: 1.6em;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><strong style="letter-spacing: 2px;caret-color: rgba(0, 0, 0, 0);font-size: var(--articleFontsize);"><span style="color: rgb(63, 63, 63);">作者 |&nbsp;</span></strong><strong style="font-size: var(--articleFontsize);letter-spacing: 0.034em;">Marius Hobbhahn、Lennart Heim、Gökçe Aydos</strong></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong style="letter-spacing: 2px;caret-color: rgba(0, 0, 0, 0);font-size: var(--articleFontsize);"><span style="color: rgb(63, 63, 63);">OneFlow 編譯</span></strong></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong style="letter-spacing: 2px;caret-color: rgba(0, 0, 0, 0);font-size: var(--articleFontsize);"><span style="color: rgb(63, 63, 63);">翻譯｜楊婷、宛子琳</span></strong></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong style="color: rgb(30, 35, 128);letter-spacing: 2px;background-color: rgb(255, 255, 255);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: left;outline: 0px;"><span style="outline: 0px;"><br></span></strong></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="letter-spacing: 2px;">要點概覽</span></strong></p><p><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100009385" data-ratio="0.5611111111111111" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/020ab97f-5645-4af9-bc97-767ea99b036a.png" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="letter-spacing: 2px;">圖 1</span></em></span></strong><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="letter-spacing: 2px;">：常見機器學習加速器在給定精度下的峯值計算性能。自 2016 年以來，已出現了新的數值格式。趨勢線展示了帶有八個或更多加速器的數值格式：FP32、FP16（FP = 浮點、張量-* = 張量核心處理、TF = Nvidia 張量浮點、INT = 整數）</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">我們研究了 GPU 在不同數值表示、內存容量、帶寬以及互連帶寬方面的計算性能，使用的數據集包括 2010 年到 2023 年常用於機器學習實驗的 47 個 ML 加速器（GPU 和其他 AI 芯片），以及 2006 年到 2021 年的 1948 個 GPU。主要發現如下：</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><ol start="1" class="list-paddingleft-1" style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">與傳統 32 位浮點數（FP32）相比，低精度數字格式如 16 位浮點數（FP16）和 8 位整數（INT8）等與專用張量核心單元相結合，可以為機器學習工作負載帶來顯著的性能提升。例如，儘管使用的數據量有限，但我們估計 tensor-FP16 比 FP32 的速度快約 10 倍。</span></p></li></ol><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">2. 鑑於用於 SOTA ML 模型訓練和推理的大型硬件集羣的整體性能取決於計算性能以外的因素，所以我們研究了內存容量、內存帶寬和互連，發現：</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><ul start="1" class="list-paddingleft-1" style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">內存容量每 4 年翻一番，內存帶寬每 4.1 年翻一番。它們的增長速度比計算性能慢（計算性能每 2.3 年翻一番）。這是一個常見發現，通常被稱為內存牆（memory wall）。</span></p></li></ul><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><ul start="1" class="list-paddingleft-1" style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">最新的 ML 硬件通常配備專有的芯片間互連協議（英偉達的 NVLink 或谷歌 TPU 的 ICI），與 PCI Express（PCIe）相比，這些協議在芯片之間提供了更高的通信帶寬。例如，H100 上的 NVLink 支持的帶寬是 PCIe 5.0 的 7 倍。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p></li></ul><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">3. 分析中發現的關鍵硬件性能指標及其改進速度包括：ML 和通用 GPU 的計算性能（以 FLOP/s 計）都是每 2.3 年翻一番；ML GPU 的計算性價比（以每美元 FLOP 計）每 2.1 年翻一番，通用 GPU 每 2.5 年翻一番；ML GPU 的能效（以每瓦特 FLOP/s 計）每 3.0 年翻一番，通用 GPU 每 2.7 年翻一番。</span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="582" data-backw="578" data-croporisrc="https://oscimg.oschina.net/oscnet/86eed77e-3a5e-4a4a-a15d-269b63217fe9.png" data-cropx1="0" data-cropx2="828" data-cropy1="0" data-cropy2="835.1626297577855" data-imgfileid="100009386" data-ratio="1.0072463768115942" data-s="300,640" data-type="jpeg" data-w="828" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8666a251-442b-40ee-a6ad-e7b64707cd15.jpg" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="color: rgb(136, 136, 136);"><em><span style="letter-spacing: 2px;font-size: 12px;">表 1</span></em></span></strong><span style="color: rgb(136, 136, 136);"><em><span style="letter-spacing: 2px;font-size: 12px;">：關鍵性能趨勢。所有估算僅針對機器學習硬件。方括號中的數字表示通過 1000 次 bootstrap 採樣得出的[5; 95]百分位估算。OOM 代表數量級，N 表示數據集中的觀測次數。請注意，性能數據是指稠密矩陣乘法性能。</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-right: 8px;margin-left: 8px;white-space: normal;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.6em;"><span style="letter-spacing: 2px;"><strong style="outline: 0px;"><span style="letter-spacing: 2px;outline: 0px;font-size: 24px;color: rgb(246, 171, 0);"><strong style="font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 2px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 255);outline: 0px;"><span style="outline: 0px;font-size: 24px;color: rgb(246, 171, 0);">1</span></strong></span></strong></span></p><span id="OSC_h2_1"></span><h2 style="margin-right: 8px;margin-left: 8px;white-space: normal;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.6em;"><span style="letter-spacing: 2px;font-size: 18px;color: rgb(30, 35, 128);"><strong style="outline: 0px;"><span style="letter-spacing: 2px;outline: 0px;">引言</span></strong></span></h2><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">過去十年中，機器學習的進步在很大程度上是通過擴大用於訓練的計算資源（計算）規模實現的（Sevilla 等人，2022 年），硬件性能的提升在這一進展中發揮了一定作用。隨着我們從少量芯片轉向大規模超級計算機，對 ML R&amp;D（Cottier，2023）投資的增加導致硬件基礎設施規模的相應提升。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">本文概述了在各種數字精度和專用組件（如張量核心）方面的計算性能趨勢。此外，我們還分析了其他性能因素，如內存容量、內存帶寬和互連帶寬。總的來説，我們分析了 ML 硬件規格和組件的整體情況，這些規格和組件共同決定了硬件的實際性能，尤其是在大規模 ML 模型時代。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">在這個過程中，我們比較了各種度量標準下的峯值性能，這些指標來自硬件生產商的規格表。[2]通常，由於工作負載規格等各種因素和內存容量以及帶寬等規格的限制，實際利用的計算性能只是指定峯值計算性能的一小部分。例如，根據 Leland 等人在 2016 年的研究，常見超級計算工作負載的實際利用率可能在 5% 到 20% 之間，而在機器學習訓練中，這取決於模型的規模、並行化方式等因素（Sevilla 等人，2022），這個比例可能在 20% 到 70% 之間。儘管如此，峯值性能仍可作為比較不同硬件加速器和世代的有用上限和標準基礎。</span></p><p><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><strong><span style="letter-spacing: 2px;font-size: 18px;">術語</span></strong></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><ul start="1" class="list-paddingleft-1" style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="letter-spacing: 2px;">數字表徵</span></strong><span style="letter-spacing: 2px;">：我們將數字表徵分為三個維度：</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p></li><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="letter-spacing: 2px;">位長/精度</span></strong><span style="letter-spacing: 2px;">：從 4 位到 64 位不等，通常用於描述存儲數字的位數。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p></li><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="letter-spacing: 2px;">數字格式</span></strong><span style="letter-spacing: 2px;">：指特定的位（bit）佈局，如整數或浮點數。數字格式通常包括 FP32 等位長度，但我們拆分了位佈局和位長度[3]。</span></p></li></ul><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><ul start="1" class="list-paddingleft-1" style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="letter-spacing: 2px;">計算單元</span></strong><span style="letter-spacing: 2px;">：顯示是否使用了專用矩陣乘單元。在這篇文章中，我們只區分張量和非張量。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p></li><li style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="letter-spacing: 2px;">硬件加速器</span></strong><span style="letter-spacing: 2px;">：指加速 ML 工作負載的芯片，如 GPU 或 TPU。我們在通用術語中可交替使用芯片和硬件加速器這兩個術語，而在指代專門的加速器時則使用 GPU 和 TPU。</span></p></li></ul><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-right: 8px;margin-left: 8px;white-space: normal;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.6em;"><span style="letter-spacing: 2px;"><strong style="outline: 0px;"><span style="letter-spacing: 2px;outline: 0px;font-size: 24px;color: rgb(246, 171, 0);"><strong style="font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 2px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 255);outline: 0px;"><span style="outline: 0px;font-size: 24px;color: rgb(246, 171, 0);">2</span></strong><br></span></strong></span></p><span id="OSC_h2_2"></span><h2 style="text-align: center;"><strong><span style="font-size: 18px;color: rgb(30, 35, 128);"><span style="letter-spacing: 2px;outline: 0px;">數</span>據集</span></strong></h2><p><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">我們從兩個關鍵數據集中彙編了硬件規格。第一個數據集在 2019 年 Sun 等人的研究（<span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>https://arxiv.org/abs/2202.05924</em></span>）基礎上，包含了 2006 年至 2021 年期間發佈的 1948 款 GPU，我們將其稱為通用 GPU 數據集（主要基於一些不常用於機器學習訓練的通用 GPU）。第二個數據集僅包含自 2010 年以來的 47 個 ML 硬件加速器，如 NVIDIA 的 GPU 和 Google 的 TPU，它們通常在重要的機器學習實驗中使用（根據 2022 年 Sevilla 等人的定義）。</span></p><p style="margin-bottom: 0px;white-space: normal;text-align: left;"><span style="letter-spacing: 2px;"><br>我們自己整理了後一個數據集，並將其稱為 ML 硬件數據集，簡稱 ML 數據集（基於 ML GPU）。此數據集可以在我們的數據表中公開獲取（</span><span style="letter-spacing: 2px;"><span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>https://docs.google.com/spreadsheets/d/1NoUOfzmnepzuysr9FFVfF7dp-67OcnUzJO-LxqIPwD0/edit?usp=sharing</em></span></span><span style="letter-spacing: 2px;">）。</span></p><p><br></p><p style="margin-right: 8px;margin-left: 8px;white-space: normal;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.6em;"><span style="letter-spacing: 2px;"><strong style="outline: 0px;"><span style="letter-spacing: 2px;outline: 0px;font-size: 24px;color: rgb(246, 171, 0);"><strong style="font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 2px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 255);outline: 0px;"><span style="outline: 0px;font-size: 24px;color: rgb(246, 171, 0);">3</span></strong></span></strong></span></p><span id="OSC_h2_3"></span><h2 style="margin-right: 8px;margin-left: 8px;white-space: normal;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.6em;"><span style="letter-spacing: 2px;font-size: 18px;color: rgb(30, 35, 128);"><strong style="outline: 0px;"><span style="letter-spacing: 2px;outline: 0px;">主要性能指標趨勢</span></strong></span></h2><p><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">在本節中，我們將介紹不同數字表徵、內存容量、計算性價比和能效的趨勢。我們將簡要解釋每個指標與 ML 開發和部署的相關性，展示我們的發現，並簡要討論它們的含義。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><span id="OSC_h3_4"></span><h3 style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="font-size: 17px;"><strong><span style="letter-spacing: 2px;">數字表徵</span></strong></span><span style="letter-spacing: 2px;"></span></h3><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">用於計算的數值表徵對計算性能有很大影響。具體説來，每個值的位數決定了計算密度（每秒每芯片面積的運算次數）。[4]近年來，硬件製造商已經為 ML 應用引入了專門的低精度數值格式。雖然 FP64 在高性能計算中很常見，[5]但在過去 15 年左右的時間裏，FP32 的性能一直是大多數消費級應用關注的焦點。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><span style="letter-spacing: 2px;">近年來，精度較低的數值格式變得更加普遍，因為低精度已經足夠開發和部署 ML 模型（Dettmers 等人，2022；Suyog Gupta 等人，2015 年；Courbariaux 等人，2014 年）。根據 Rodriguez（<span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>https://deeplearningsystems.ai/#ch06/#61-numerical-formats，2020</em></span>），到目前為止，FP32 仍然是機器學習訓練和推斷中採用最廣泛的數值格式，行業越來越傾向於在某些訓練和推理任務中過渡到更低精度的數值格式，如 FP16 和 Google 的 bfloat16（BF16），以及用於部分推理工作負載的整數格式 INT8。[6]其他知名新興數值格式包括 16 位標準浮點格式 FP16，整數格式 INT4，以及 NVIDIA 開發的 19 位浮點格式 TF32。[7]</span></p><p><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><strong><span style="letter-spacing: 2px;">FP32 和 FP16 的計算性能</span></strong></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: justify;"><span style="letter-spacing: 2px;">從歷史上看，近 20 年來，FP32 精度的計算性能趨勢一直相對穩定，呈現出 2.3 年翻倍一次的趨勢，與摩爾定律的速度密切相關。在過去幾年，特別是自 2016 年以來，我們已經看到了專門支持 FP16 精度的硬件的出現，這增加了絕對計算性能，同時減少了位長。</span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="904" data-backw="578" data-croporisrc="https://oscimg.oschina.net/oscnet/4cbf0723-be89-4f40-b422-9f810a8d0ef0.png" data-cropx1="0" data-cropx2="806" data-cropy1="0" data-cropy2="1260.5951557093426" data-imgfileid="100009387" data-ratio="1.5632754342431763" data-s="300,640" data-type="jpeg" data-w="806" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/48807fb3-a5fc-4cbc-8036-00251e0bcba5.jpg" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><em><strong><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">圖 2</span></strong><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">：過去二十年，FP32 和 FP16 精度下的通用和 ML GPU 峯值性能。上圖顯示，ML GPU 的中位性能高於所有通用 GPU，但增長率相似。下圖顯示，2014 年一些硬件加速器開始提供 FP16 性能細節。</span></em><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);"></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: justify;"><span style="letter-spacing: 2px;">在過去十年中，FP32 的通用硬件和 ML 硬件的計算性能顯示出幾乎相同的增長率，但在性能水平上有所不同。我們的 ML 硬件數據集中的加速器始終處於最佳可用硬件之列。我們認為，這在一定程度上是因為機器學習實踐者選擇了最強大的可用硬件，其次，這也是由於最近推出的專門針對機器學習市場的高端數據中心 GPU 的推出，例如英偉達的 V/A/H100 或谷歌的 TPU。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><span style="font-size: 17px;"><strong><span style="font-size: 17px;letter-spacing: 2px;">通過硬件支持更低精度的數值格式以提高計算性能</span></strong></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">降低數值精度所帶來的性能提升得益於現代機器學習芯片中多重架構的改進，而不僅僅是單純降低位寬所能達到的。較小的數據類型使得每平方芯片面積可以進行更多的浮點運算，並減小了內存佔用。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">然而，其他方面的進步也在很大程度上做出了貢獻：引入了專門用於矩陣乘的新指令；[8]硬件數據壓縮；消除了諸如 NVIDIA A100 中的矩陣乘硬件中多餘的數據緩衝區，這有助於降低數據和指令內存需求，從而提高了單位芯片面積上的操作數。H100 更快的內存訪問能力進一步優化了上述進展 (Choquette, 2023).。</span></p><p><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="391" data-backw="578" data-imgfileid="100009391" data-ratio="0.6763224181360201" data-s="300,640" data-type="png" data-w="794" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/378ad9dd-46a8-4589-9bcd-6763ff5ed792.png" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 2px;">圖 3</span></em></span></strong><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 2px;">：箱線圖顯示了不同精度數字格式下 ML 加速器性能相對於其 FP32 性能的比值，這展示了相對於 FP32 的性能改善。我們發現，相對於它們自身的 FP32 性能，採用新的數值表示方式 tensor-FP32/TF32、tensor-FP16 和 tensor-INT8 可以分別使平均計算性能提高約 5 倍、8 倍和 13 倍。並非所有 GPU 都專門支持低精度格式，我們從圖中剔除了那些在較低精度格式上的計算性能未能超過較高精度格式的 GPU 型號，以便篩選出缺乏專門支持的 GPU。</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">近年來，由於使用了較低的數字精度，GPU 在機器學習工作負載中的性能大幅提升。平均而言，與在同一 GPU 上使用 FP32 相比，使用 tensor-FP32（TF32）、tensor-FP16、tensor-INT8 和 tensor-INT4 等精度較低的數值格式分別可提供約 5 倍、8 倍、13 倍和 18 倍的計算性能。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">歷史數據顯示，FP32 性能峯值每 2.3 年翻一番，這些較低精度的加速效果相當於性能提升了 3 到 9 年。然而，最大的加速效果可能超過平均值。與 FP32 相比，NVIDIA 的 H100 在 TF32、FP16 和 INT8 下分別實現了約 7 倍、15 倍和 30 倍的加速效果。</span></p><p style="margin-bottom: 0px;white-space: normal;"><span style="letter-spacing: 2px;"><br>因此，對於 H100 來説，與典型的 GPU 相比，較低的精度提供了比 FP32 更大的性能增益。正如我們所看到的，雖然使用較低精度能極大地提升計算性能，但出於模型準確性方面的權衡，通常還是會使用較高精度進行訓練。[10]儘管 TF32、FP16 和 INT8 格式在 H100 上相較於 FP32 提供了加速效果，但需要注意的是，這不僅僅是因為較小的數值格式更高效，H100 很可能針對這些格式的操作進行了優化，從而促成了速度提升。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><span id="OSC_h3_5"></span><h3 style="margin-bottom: 0px;white-space: normal;"><strong><span style="letter-spacing: 2px;font-size: 17px;">內存容量和帶寬</span></strong></h3><p style="margin-bottom: 0px;white-space: normal;"><br></p><p style="margin-bottom: 0px;white-space: normal;"><span style="letter-spacing: 2px;">典型的處理器核心通過讀取數據、處理數據，並將處理後的結果寫回內存來執行計算。因此，內存充當了在處理週期之間存儲數據的媒介。硬件傾向於使用內存層次結構：從在計算單元附近存儲數百 KB 快速訪問數據的寄存器文件，到能夠容納數十 GB 較慢訪問數據的隨機存取存儲器（RAM）。[11] 數據定期從較大的慢速訪問 RAM 通過中間緩存存儲器傳輸到寄存器文件，必要時再寫回。加速器數據表大多提供加速器卡上可用的最大 RAM[12]。我們稱這些 RAM 位的數量為內存容量。數據以塊的形式傳輸到最大 RAM 中，具體取決於所使用的內存技術，這需要一些處理週期。我們將能夠每秒傳輸到最大 RAM 的最大位數（即峯值比特速率）稱為內存帶寬[13]。</span></p><p style="margin-bottom: 0px;white-space: normal;"><br></p><p style="margin-bottom: 0px;white-space: normal;"><span style="letter-spacing: 2px;">包含硬件加速器的系統通常包含一個主存儲器，用於存儲應用程序和數據。然後，這些數據被傳輸到加速器進行處理。為確保在訓練或推理期間模型權重和訓練數據在硬件加速器上隨時可用，需要更大的內存容量。如果數據無法適應加速器的內存，邏輯（logic）將需要使用 CPU 內存，甚至更高級別的內存（例如硬盤），這將顯著影響時延和帶寬。實際上，為避免這種性能損失，模型數據分發到多個硬件加速器的內存中。</span></p><p style="margin-bottom: 0px;white-space: normal;"><br></p><p style="margin-bottom: 0px;white-space: normal;"><span style="letter-spacing: 2px;">硬件處理能力的進步需要更大的內存帶寬。如果沒有足夠的數據輸入，就無法達到峯值計算性能，內存帶寬就會成為瓶頸[14]，這被稱為帶寬牆（Rogers 等人，2009）或通常所説的內存牆。</span></p><p style="margin-bottom: 0px;white-space: normal;"><br></p><p style="margin-bottom: 0px;white-space: normal;"><span style="letter-spacing: 2px;">如圖 4 所示，相對於計算性能的改善，內存容量和帶寬的增長速度較慢。具體而言，就通用 GPU 來説，內存容量每 3.04 年翻一番，而 ML 加速器則為 4 年，內存帶寬分別為每 3.64 年和 4 年翻一番。相比之下，根據之前的分析，計算性能每 2.3 年翻一番。</span></p><p><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="412" data-backw="578" data-imgfileid="100009392" data-ratio="0.7135678391959799" data-s="300,640" data-type="png" data-w="796" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/c2f89bdb-25a7-433f-8e48-e8922d6297e7.png" referrerpolicy="no-referrer"></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="393" data-backw="578" data-imgfileid="100009393" data-ratio="0.6796482412060302" data-s="300,640" data-type="png" data-w="796" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/50b955f7-0e03-4cc2-a915-d3916e601217.png" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="color: rgb(136, 136, 136);"><em><span style="letter-spacing: 2px;font-size: 12px;">圖 4：通用硬件與 ML 硬件的內存容量和帶寬的變化軌跡。我們發現所有這些趨勢都比計算性能的趨勢慢（計算性能每 2.34 年翻一番），這與通常所説的內存牆趨勢一致。</span></em></span><em><span style="letter-spacing: 2px;font-size: 12px;"></span></em></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">如人們所預期的那樣，在內存容量和帶寬方面，ML 硬件超過了中位的 GPU。然而，即使在這方面，這些指標的增長速度也一直落後於計算性能的增長速度（每 2.3 年翻一番）。這一趨勢表明，對於大規模 ML 應用而言，內存正在成為一個日益關鍵的瓶頸。當前的架構改進，比如引入更少位的數字表徵，可能會減輕這種內存限制。然而，如果不加快發展，這一內存瓶頸將在未來幾年繼續影響整體性能。[15]</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">對於一些 ML 工作負載來説，單個加速器可能提供了足夠的計算性能。然而，由於內存限制，通常需要將工作負載分佈到多個加速器上。利用多個加速器可以增加總內存容量，從而完全將大型模型和數據集放入內存。這種策略確保了更大的內存容量，可以在多個硬件加速器上容納模型的全部權重，從而減輕了從主機系統內存傳輸數據時所產生的時延。對於某些工作負載來説，增加內存帶寬可能對滿足時延和吞吐量要求至關重要。</span></p><p style="margin-bottom: 0px;white-space: normal;"><span style="letter-spacing: 2px;"><br>值得注意的是，旨在減少內存佔用的技術，比如重新計算激活值利用了計算資源來部分抵消這些限制（Rajbhandari 等, 2021）。然而，通過多個芯片並行化模型訓練需要它們之間通過互連實現高效通信。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><span id="OSC_h3_6"></span><h3 style="text-align: left;"><strong><span style="font-size: 18px;">互連帶寬</span></strong></h3><p><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">在 ML 的訓練和部署中，由於不斷增長的內存需求，除需要巨大的計算能力之外，還需要使用多個芯片來滿足這些需求。例如，PaLM 的訓練中使用了 6144 個芯片（Chowdhery 等人，2022 年），而對於 GPT-4 可能需要使用更多芯片。這一需求強調了有效互連這些芯片的需求，使它們能夠在不借助 CPU 內存或磁盤的情況下有效地交換激活值和梯度。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">互連帶寬是指通信通道能夠傳輸的峯值比特率，通常以每秒傳輸的字節數為單位測算。當 ML 硬件之間頻繁交換數據時，如果互連帶寬跟不上處理速度，這個指標就成為了限制因素。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">互連協議定義了最大互聯帶寬。在我們的數據集中，ML 硬件涉及三種常見協議：a) PCI Express（PCIe）；b) Nvidia NVLink；c) Google Inter-Core Interconnect（ICI）[16] 。PCIe 是一種普遍採用的協議，用於在 CPU 和機器學習硬件之間進行本地互聯。相比 PCIe 的基於集線器的網絡架構，Nvidia 的專有 NVLink 通過實現設備之間的直接點對點連接，克服了 PCIe 的帶寬限制。在無法使用點對點連接的情況下，PCIe 被用作備用方案。Google 的 ICI 用於連接他們的 TPU[17]。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">前面提到的互連協議主要設計用於近距離通信[18] 。當需要進行較長距離的通信時，會採用傳統的計算機網絡協議，比如以太網或者 InfiniBand。在所有傳統網絡協議中，數據都是通過 PCIe 路由到網絡硬件[19] 。即使存在 NVLink 和 ICI，PCIe 仍然作為主機 CPU 和機器學習硬件之間的標準互連協議。在接下來的內容中，我們將始終指出對應於最快協議的互連速度。</span></p><p><br></p><section style="text-align: center;margin-left: 8px;margin-right: 8px;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="395" data-backw="578" data-croporisrc="https://oscimg.oschina.net/oscnet/79f8768c-3d34-4d74-a209-40a6f5588543.png" data-cropx1="0" data-cropx2="795" data-cropy1="0" data-cropy2="543.295847750865" data-imgfileid="100009394" data-ratio="0.6830188679245283" data-s="300,640" data-type="jpeg" data-w="795" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9207e987-873b-48dc-92b4-9816e194b1c1.jpg" referrerpolicy="no-referrer"></section><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 2px;">圖 5: 不同硬件加速器中，每個芯片的聚合互連帶寬。NVLink 和 ICI 等專有協議的互連帶寬高於 PCIe。</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">我們發現，自 2011 年以來，ML（機器學習）硬件的 PCIe 帶寬僅從 32GB/s 增加到 2023 年的 128GB/s（見圖 5）。[20]然而，英偉達（NVLink）和谷歌（ICI）的專用加速器互連協議可實現更高的互連帶寬。此外，常用於大型計算集羣的高端 ML 加速器（例如 TPU 和 V/A/H100）擁有迄今為止最高的互連速度。例如，搭載 18 個 NVLink 4.0 通道的英偉達 H100 實現了 900GB/s 的帶寬，是單個 PCIe 5.0 16 通道鏈路的 7 倍。[21]</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><span style="letter-spacing: 2px;">一個計算集羣可能配備了成千上萬台不同程度耦合的硬件加速器。例如，英偉達的 DGX H100 服務器使用 NVSwitch 使每台 H100 互連，從而實現了最大互連帶寬為 900GB/s 的緊密耦合加速器網絡（參見<span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>[Choquette, 2023]，https://doi.org/10.1109/MM.2023.3256796，"Scaling Up and Out"一章</em></span>）。許多 DGX H100 服務器又可以組成所謂的 SuperPOD，其中各個獨立服務器中的加速器仍可使用 NVLink 傳輸數據，但耦合程度較低。每個 SuperPOD 使用以太網和 Infiniband 連接到另一個 SuperPOD。服務器之間的網絡拓撲也會影響計算集羣的整體性能。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">專用集羣 ML 硬件的互連帶寬遠高於消費級硬件。這凸顯了它在大規模 ML 實驗中的重要性，因為這些實驗需要在 ML 硬件節點之間進行高帶寬的數據通信。因此，類似於內存容量和帶寬，我們建議監測互連帶寬，將其作為瞭解 ML 硬件趨勢的一個相關附加指標。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><span id="OSC_h3_7"></span><h3 style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><strong><span style="letter-spacing: 2px;font-size: 18px;">計算性價比</span></strong></h3><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">性能——價格比（Price-performance ratio）通常比單純的峯值計算性能更有用，它能反映 GPU 的整體技術改進情況，即每美元成本可獲得的性能。我們採用兩種方法來估算 ML 硬件的性價比：</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">1. 在有數據的情況下，我們使用硬件的發佈價格，根據通貨膨脹進行調整，並假定兩年的攤銷時間，詳見<span style="letter-spacing: 2px;text-wrap: wrap;">（</span><span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>Cotra (2020)，https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6</em></span>）。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">2. 在僅提供租賃的 TPU 或其他硬件等硬件發佈價格不可用或不明確的情況下，我們使用 Google Cloud 的雲計算價格（截至 2023 年 7 月 3 日）。我們根據通貨膨脹調整價格，以使價格與攤銷價格相當，並假設雲服務提供商的利潤率為 40%[22]。如圖 6 所示，在計算 FP32 精度的性價比時，需考慮估算 FP32 性價比時的一些重要注意事項。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">首先，集羣硬件的定價通常會採用私下協商的方式，不公開發布，這使得難以準確定價。其次，儘管某些芯片在個體性價比上表現強勁，但由於互連帶寬或可靠性不足，可能無法在工業集羣部署中使用。再次，FP32 計算引入了對專用 ML 芯片的偏見，這些芯片使用較低精度數字格式和未在 FP32 指標中反映的張量核心。最後，由於缺乏有關功耗、冷卻和更換率等數量的公開數據（<span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>參見[Cottier, 2023]，https://epochai.org/blog/trends-in-the-dollar-training-cost-of-machine-learning-systems</em></span>），估算實際維護成本具有挑戰性。儘管作為基準有用，但 FP32 性價比趨勢必須考慮源自 ML 的特定架構因素和數據約束的限制。</span></p><p><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="389" data-backw="578" data-imgfileid="100009396" data-ratio="0.6722222222222223" data-s="300,640" data-type="png" data-w="1080" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1ea660df-a2c3-4e78-8427-edd2d54f01b0.png" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 2px;font-size: 12px;">圖 6</span></em></span></strong><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 2px;font-size: 12px;">：通用硬件和 ML 硬件的 FP32 性價比軌跡。我們發現，這些軌跡大致遵循與峯值計算性能相同的增長軌跡（2.3 年翻倍時間）。此外，我們發現 ML GPU 的絕對性價比低於其他硬件。FP32 性價比可能存在對 ML 硬件的偏見（詳見正文）。</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">我們看到 FP32 性價比的增長軌跡（2.5/2.1 年翻倍時間）大致與通用計算性能的增長軌跡（2.3 年翻倍時間）相似。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">此外，與其他 GPU 相比，我們發現 ML GPU 的性價比較低。我們推測至少有兩個原因。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">首先，如上所述，由於它們忽略了在 ML 訓練中常見的其他數值表示（如 FP16），上述注意事項系統地使 FP32 性價比對 ML 硬件產生了偏見。其次，正如前面的部分所述，大規模 ML 訓練不僅依賴於單一性能指標，還依賴於互連帶寬、內存容量和帶寬等其他指標。然而，這些指標並未反映在 FP32 性價比中。例如，一款典型的消費級 GPU 在個體的性價比上可能更好，但對於 ML 訓練來説卻不太適用。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="376" data-backw="578" data-imgfileid="100009397" data-ratio="0.6509259259259259" data-s="300,640" data-type="png" data-w="1080" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/bd56dc1f-dd39-47cf-b13e-04e13bff8816.png" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 2px;font-size: 12px;">圖 7</span></em></span></strong><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 2px;font-size: 12px;">：不同數值表示 ML 硬件的計算性價比。其中的點表示 ML 硬件的發佈日期和性能，顏色代表數值格式。虛線表示具有十個或更多加速器的數值格式（如 INT8、FP16 和 FP32）性能改進趨勢。</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">FP32 的性價比可能會誤導對 ML 硬件成本效益的認識。例如，AMD Radeon RX 7900 XTX 消費級 GPU 在 FP32 性價比方面表現最佳。然而，NVIDIA RTX 4090 在使用 ML 訓練中常見的低精度 INT4 格式時，提供了約 10 倍高的性價比。這得益於 RTX 4090 專為低精度計算而設計的張量核心，而 FP32 指標卻忽略了這一點。</span></p><p style="margin-bottom: 0px;white-space: normal;"><span style="letter-spacing: 2px;"><br>因此，僅憑 FP32 的性價比便會錯誤地認定 Radeon 優於 RTX 4090，而實際上 RTX 4090 在實際 ML 工作負載中更為經濟實惠。這突顯了僅依賴 FP32 性價比分析，不考慮 ML 特定架構和數值表示的整體評估的風險。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">性價比最好的 GPU 在很大程度上取決於所使用的數值表示。AMD Radeon RX 7900 XTX 消費級 GPU 在 FP32 計算上的性價比最高。然而，對於像 INT4 這樣的低精度數字格式，NVIDIA RTX 4090 的每美元計算性能大約是 Radeon 的 10 倍。這説明按照性價比對 GPU 進行排名對精度非常敏感，而僅依靠 FP32 無法全面反映實際 ML 工作負載中的成本效益。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><span id="OSC_h3_8"></span><h3 style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><strong><span style="letter-spacing: 2px;font-size: 18px;">能效</span></strong></h3><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">運行硬件會消耗能源，而大多數組織的目標是儘可能充分地利用他們的硬件。因此，部署能效高的硬件是一種降低硬件加速器壽命週期成本的可能途徑。此外，能效更高的硬件通常散熱更少，有助於更好地實現可擴展性。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">為近似評估 ML 硬件的能效，我們使用每瓦特的 FLOP/s，其中能量組成部分是從熱設計功耗（TDP）計算得出的。TDP 並不等同於平均能耗，因此不應該用於精確比較。然而，在 ML 訓練和雲計算中，我們認為它是一個相當不錯的近似值，因為硬件是持續運行的（<span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>參見附錄中的 TDP 部分，https://epochai.org/blog/trends-in-machine-learning-hardware#thermal-design-power-tdp</em></span>）。</span></p><p><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="376" data-backw="578" data-imgfileid="100009398" data-ratio="0.6509259259259259" data-s="300,640" data-type="png" data-w="1080" style="width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/ba66db12-918a-446c-9ee4-6cfa15257bdf.png" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 2px;font-size: 12px;">圖 8</span></em></span></strong><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 2px;font-size: 12px;">：根據 TDP 數值計算的 FP32 精度能效軌跡。我們發現，機器學習 GPU 的平均能效比通用 GPU 高，且能效的增長速度略低於峯值計算性能（2.3 年翻倍時間）的增長速度。</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: left;"><span style="letter-spacing: 2px;">我們發現，機器學習 GPU 的平均能效比歷史 GPU 更高。這是合理的，因為 ML GPU 通常在數據中心運行，能源消耗和碳足跡是重要的度量標準（<em><span style="letter-spacing: 2px;color: rgb(136, 136, 136);">參見 Jouppi 等，2023，https://arxiv.org/pdf/2304.01433.pdf，第 7.6 節</span></em>）。此外，我們發現能效的增長速率（分別為歷史 GPU 和 ML GPU 的 2.70/3.0 年翻番時間）僅略低於峯值計算性能的增長速率（2.3 年翻番時間）。這一趨勢表明能耗目前（尚）不是擴展的現實瓶頸，但有理由認為在未來可能會成為瓶頸（<span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>參見 Hobbhahn &amp; Besiroglu, 2022b，https://epochai.org/blog/predicting-gpu-performance</em></span>）。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><p style="margin-right: 8px;margin-left: 8px;white-space: normal;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.6em;"><span style="letter-spacing: 2px;"><strong style="outline: 0px;"><span style="letter-spacing: 2px;outline: 0px;font-size: 24px;color: rgb(246, 171, 0);"><strong style="font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 2px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 255);outline: 0px;"><span style="outline: 0px;font-size: 24px;color: rgb(246, 171, 0);">4</span></strong><br></span></strong></span></p><span id="OSC_h2_9"></span><h2 style="margin-right: 8px;margin-left: 8px;white-space: normal;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.6em;"><span style="letter-spacing: 2px;font-size: 18px;color: rgb(30, 35, 128);"><strong style="outline: 0px;"><span style="color: rgb(30, 35, 128);font-size: 18px;letter-spacing: 2px;outline: 0px;">結論</span></strong></span></h2><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">最近的研究表明，對於開發和部署 ML 模型，低精度已經足夠（<span style="letter-spacing: 2px;color: rgb(136, 136, 136);"><em>參見[Dettmers 等, 2022]；[Suyog Gupta 等, 2015]; [Courbariaux 等, 2014]</em></span>）。我們發現，ML 硬件遵循上述發現，並不斷集成支持更低精度數值格式的硬件單元（如 FP16、TF32、BF16、INT8 和 INT4），以增加每秒的總操作次數。此外，張量核心等專用計算單元變得越來越普遍，並進一步提高了計算性能。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">結合這兩個趨勢，在我們的推測性佔主導的估算中，從 FP32 到張量-FP16 的躍遷平均提供了約 8 倍的峯值性能增益。然而，旗艦級 ML 硬件加速器的這一比率可能更高，例如，NVIDIA H100 SXM 的 TF32 到 FP32 比率約為 7 倍，張量-FP16 到 FP32 比率約為 15 倍，張量-INT8 到 FP32 比率約為 30 倍。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">這一趨勢表明了一種「硬件-軟件協同設計」的模式，其中 ML 從業者嘗試不同的數值表示，並已獲得了一些小而有意義的性能提升，減少了內存佔用。然後，硬件被調整以適應這些新的數值表示，從而獲取進一步的增益。多次迭代這一循環可以促成性能的實質性改善。此外，硬件生產商也在積極尋求新的創新，這些創新隨後將引領其進入 ML 實驗室。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">此外，在大規模 ML 訓練中，我們強調內存容量、內存帶寬和互連帶寬等因素的重要性。鑑於目前 ML 訓練通常需要數千個芯片之間的有效交互，超越每個芯片峯值性能的因素變得至關重要。我們觀察到，這些指標的增長速度比與計算相關的指標（例如峯值計算性能、性價比和能效）要慢。在大規模分佈式 ML 訓練場景中，內存和互連帶寬成為利用峯值計算性能的瓶頸。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">專門的機器學習硬件和替代的數值表示是相對較新的趨勢，這使得精確預測變得困難。正如我們已經明確指出，密切追蹤數值格式、內存容量、內存帶寬和互連帶寬的發展對於更準確地評估未來機器學習能力至關重要。與其依賴靜態假設，基於硬件和軟件創新不斷重新評估性能潛力才是關鍵。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><em><span style="letter-spacing: 2px;">（<span style="letter-spacing: 2px;color: rgb(136, 136, 136);">我們要感謝 Dan Zhang、Gabriel Kulp、Yafah Edelman、 Ben Cottier、Tamay Besirogl 和 Jaime Sevilla 對本文提供的詳盡反饋，還要感謝 Eduardo Roldán 將這篇文章搬運到網站上。</span>）</span></em><span style="letter-spacing: 2px;"></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;"><br></span></p><span id="OSC_h2_10"></span><h2 style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><strong><span style="letter-spacing: 2px;">附錄：次要性能指標的趨勢</span></strong></h2><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">我們補充了晶體管數量、熱設計功耗（TDP）、時鐘速度、芯片尺寸和張量核心數量等次要指標的趨勢。儘管這些指標可能與理解 ML 硬件的某些趨勢相關，但我們認為它們不如我們在文章主體中分析的指標重要或有影響力[23]。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;"><span style="letter-spacing: 2px;">請注意，這些趨勢中仍有大量缺失數據，因此可能存在偏見。例如，以下大部分數據不包括 TPU。</span></p><p><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100009399" data-ratio="0.6314496314496314" data-s="300,640" data-type="png" data-w="814" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/876d3c1e-b2f8-4b16-adfe-1547abd73ec1.png" referrerpolicy="no-referrer"></p><p><span data-lark-record-data="{&quot;rootId&quot;:&quot;JG5FdGJd2oJJbVxTANac6fy5nHh&quot;,&quot;text&quot;:{&quot;initialAttributedTexts&quot;:{&quot;text&quot;:{&quot;0&quot;:&quot;請注意，這些趨勢中仍有大量缺失數據，因此可能存在偏見。例如，以下大部分數據不包括 TPU。&quot;},&quot;attribs&quot;:{&quot;0&quot;:&quot;*0+18&quot;}},&quot;apool&quot;:{&quot;numToAttrib&quot;:{&quot;0&quot;:[&quot;author&quot;,&quot;7036992984721768450&quot;]},&quot;nextNum&quot;:1}},&quot;type&quot;:&quot;text&quot;,&quot;referenceRecordMap&quot;:{},&quot;extra&quot;:{&quot;mention_page_title&quot;:{},&quot;external_mention_url&quot;:{}},&quot;isKeepQuoteContainer&quot;:false,&quot;isFromCode&quot;:false,&quot;selection&quot;:[{&quot;id&quot;:332,&quot;type&quot;:&quot;text&quot;,&quot;selection&quot;:{&quot;start&quot;:0,&quot;end&quot;:44},&quot;recordId&quot;:&quot;RsSedwz3Eou7SYxV3y3cbkgSnhc&quot;}],&quot;payloadMap&quot;:{},&quot;isCut&quot;:false}" data-lark-record-format="docx/text"></span></p><section style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.6em;"><strong style="letter-spacing: 0.578px;font-size: 16px;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">註釋<span style="font-size: 15px;letter-spacing: 1px;text-align: left;color: rgb(163, 163, 163);font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);">（請上下滑動）</span><span style="font-size: 15px;letter-spacing: 1px;text-align: left;">&nbsp;</span></span></strong></section><span id="OSC_h3_11"></span><h3 style="letter-spacing: 0.578px;text-wrap: wrap;"><section style="margin-right: 8px;margin-left: 8px;line-height: 1.75em;text-align: left;"><section data-style="max-width: 100%; box-sizing: border-box; font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; letter-spacing: 0.544px; white-space: normal; background-color: rgb(255, 255, 255); font-size: 16px; overflow-wrap: break-word !important;" class="js_darkmode__41" style="outline: 0px;background-color: rgb(255, 255, 255);letter-spacing: 0.544px;text-size-adjust: auto;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;color: rgb(163, 163, 163) !important;"><section style="margin-top: 10px;margin-right: 8px;margin-left: 8px;outline: 0px;width: 578px;"><section style="outline: 0px;display: inline-block;vertical-align: top;overflow-y: auto;height: 540px;width: 578px;"><section style="outline: 0px;overflow-x: hidden;"><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">1 NA 表示數據不可用，因為缺乏足夠的數據來估計相關增長率。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">2 這些數字通常是基於硬件特性計算得出的。例如，計算性能通常被估算為處理核心數量、時鐘速度和每個核心的每個時鐘週期的浮點運算乘積。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">3 相同位數的比特可以表示不同的數值範圍或浮點數精度。我們的硬件數據集不包括針對給定位數格式的每種可用數值格式的計算性能。例如，我們的 FP16 數據還包括 BF16，其在指數和尾數分配的比特數方面存在差異。我們不指望在相同位數的不同浮點數格式之間有太大的性能差異。最適合的數值表示（例如，從能源或運行時間效率的角度）取決於工作負載。[Rodriguez, 2020](https://deeplearningsystems.ai/#ch06/#61-numerical-formats) 第 6.1 節中還包含了一份 ML 應用的數值表示的綜合列表。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;text-align: left;"><span style="letter-spacing: 2px;">4 根據[Mao 等人 (2021)](https://doi.org/10.1109/TVLSI.2021.3128435) 中的表 VI，一個 FP64 乘法器單元的面積大約是 FP32 乘法器的五倍。類似的關係也存在於 FP32 和 FP16 乘法器之間。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">5 由於許多具有歷史重要性的超級計算機工作負載對高精度的要求，例如計算流體力學、氣象學、核蒙特卡洛模擬、蛋白質摺疊等。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;text-align: left;"><span style="letter-spacing: 2px;">6 [Rodriguez, 2020](https://deeplearningsystems.ai/#ch06/#61-numerical-formats), 第 6.1 節指出：最受歡迎和廣泛採用的數值格式是用於訓練和推理的 FP32。行業正在向用於訓練和推理的 FP16 和 BF16 靠攏，並在某些工作負載的推理中採用 INT8。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">7 TF32 並非通用數值格式，它僅在 NVIDIA 張量核心中使用，通過在矩陣乘法之前減少 13 位精度位，加速使用 FP32 的模型處理，但保持與 FP32 相同的數值範圍。TF32 與 FP32 的內存佔用相同，因為 TF32 在張量核心中使用與 FP32 相同的寄存器（參見[Sun 等，2022](https://doi.org/10.1109/TPDS.2022.3217824)，第 8 節）。換句話説，TF32 被設計為 FP32 模型的即插即用替代品，但在矩陣乘法過程中可以接受更低的精度。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">8 請勿將其與張量核心乘法所需的新指令混淆。[Choquette 等人，2021](https://doi.org/10.1109/MM.2021.3061394)，SM Core 一節指出：在 A100 中，添加了一條新的異步組合加載-全局存儲-共享存儲指令，將數據直接傳輸到 SMEM，繞過寄存器文件，提高了效率。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">9 注意查看標題為‘SM Core’的部分。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">10 例如，目前 INT8 在訓練當前系統中並未被廣泛使用。INT8 的缺點在 Rodriguez，2020，第 6.1 節中有解釋。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">11 由 ML 硬件數據表記錄的內存容量通常指的是 RAM 容量，因為 GPU 在之前常被用於視頻處理，所以也常被稱為視頻 RAM（VRAM）。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;text-align: left;"><span style="letter-spacing: 2px;">12 例如，[AMD Instinct MI200 數據表](https://www.amd.com/system/files/documents/amd-instinct-mi200-datasheet.pdf) &nbsp;明確説明瞭 128 GB HBM2e。HBM 指的是高帶寬內存，是一種 RAM 類型。[NVIDIA H100 Tensor Core GPU 數據表](https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet) 表示 H100 SXM 的內存為 80GB，根據 [NVIDIA H100 Tensor Core GPU 架構](https://nvdam.widen.net/s/95bdhpsgrs#page=36)v1.04，第 36 頁，這個數字對應於 HBM3 的內存容量。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">13 在應用中，實際帶寬通常較低。一個原因是數據傳輸時延，這也影響了實際帶寬，並取決於內存技術。到單獨內存芯片的距離以及在大容量內存中的長路徑，會導致數據在到達處理單元之前經歷大量的週期。如果處理單元預先知道需要哪些數據，就可以以最大帶寬進行數據傳輸。如果不知道，就需要對內存進行隨機訪問。通常，隨機訪問越多，實際帶寬就越低。我們的數據集中不包含時延指標。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">14 圖形處理和機器學習訓練往往會遇到這個瓶頸，因此，現代機器學習硬件嘗試通過兩種技術來優化高內存帶寬：(a) GDDR 內存或 (b) 高帶寬內存（HBM）。GDDR 內存位於與處理芯片相同的板上，而 HBM 則實現在與處理芯片相同的封裝中，從而實現更低的時延和更高的帶寬（例如，在數據中心使用的最新機器學習加速器，如 NVIDIA A100 和 H100 採用了 HBM；而它們的遊戲型 GPU 則沒有采用 HBM，以節約成本）。將許多 DRAM 堆疊在一起，並在單個芯片封裝中互連多個半導體芯片，與在印刷電路板上連接處理芯片和 DRAM 相比，需要昂貴的工具，因此 HBM 通常出現在性能最昂貴和性能最高的機器學習硬件加速器中，例如那些用於數據中心進行大規模機器學習訓練和部署的加速器。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">15 可參閲 [Megatron-LM: 使用模型並行訓練數十億參數的語言模型](https://lilianweng.github.io/posts/2021-09-25-train-large/)，[如何在多個 GPU 上訓練非常大的模型？](https://lilianweng.github.io/posts/2021-09-25-train-large/) 或者[訓練大型神經網絡的技術](https://openai.com/research/techniques-for-training-large-neural-networks) 。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">16 [Jouppi 等，《TPU v4：一種具有嵌入式硬件支持的光學可重構超級計算機用於機器學習》](https://arxiv.org/pdf/2304.01433.pdf) 的第 2 節中有詳細內容。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">17 更多關於 ICI 的信息請參見[Jouppi 等人，2023](https://doi.org/10.48550/arXiv.2304.01433)，第 2 節。值得注意的是，TPUv4 使用光開關來滿足長距離互連需求。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">18 例如，[PCIe 4.0 支持長達 30 釐米](https://www.elektronik-kompendium.de/sites/com/0904051.htm)。根據[Jouppi 等，2023](https://doi.org/10.48550/arXiv.2304.01433)，第 7.2 節，Google ICI 用於連接 1024 個 TPUv3，但最大長度並未提供。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">19 InfiniBand 和 Ethernet 支持的網絡帶寬低於 PCIe，因此它們定義了峯值帶寬。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">20 按照 PCI-SIG 協會的標準；預計到 2025 年將增加到 256GB/s。需要注意的是，帶寬變化的速度是由協會定義的，而該協會可能在採納市場的即時需求方面較為緩慢。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;text-align: left;"><span style="letter-spacing: 2px;">21 根據[NVIDIA H100 Tensor Core GPU Architecture, v1.04, p47 的説明](https://nvdam.widen.net/s/95bdhpsgrs#page=47)：在多 GPU IO 和共享內存訪問中，總帶寬達到 900GB/秒，新的 NVLink 提供的帶寬是 PCIe Gen 5 的 7 倍。... H100 包括 18 條第四代 NVLink 連接，提供 900GB/秒的總帶寬...</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">22 Google Cloud 提供一年的 37% 的使用折扣。因此，我們估計 40% 是谷歌從正常雲計算中獲利的合理下限。有關雲計算價格的更多考慮可以在 https://epochai.org/blog/trends-in-the-dollar-training-cost-of-machine-learning-systems 找到。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">23 相關性判斷結合了作者直覺和我們在先前帖子中的推理。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">24 Chiplet 是一個將多個芯片集成到一個集成電路/封裝中的例子。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">25 根據[Hennessy 等人，《計算機體系結構》，2017 年，第 24 頁](https://www.elsevier.com/books/computer-architecture/hennessy/978-0-12-811905-1) 的描述：TDP 既不是峯值功率（峯值功率通常要高 1.5 倍），也不是在特定計算過程中實際消耗的平均功率（平均功率可能更低）。</span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 2px;">26 支持這一觀點的證據來自（Gigabyte 術語表，https://www.gigabyte.com/Glossary/tdp）：在一個穩定的、企業級的服務器房間或數據中心中，TDP 大致等同於計算設備的功耗，因為服務器通常處於最大容量或接近最大容量運行。</span></p><section style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;line-height: 1.6em;"><br></section></section></section></section></section></section></h3><span id="OSC_h2_12"></span><h2 style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(63, 63, 63);text-align: left;caret-color: rgba(0, 0, 0, 0);"><p line="Lfwy" ql-global-para="true" style="letter-spacing: 0.578px;"><span style="background-color: rgb(255, 255, 255);color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 1px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgba(0, 0, 0, 0.9);"></span></p><p line="Lfwy" ql-global-para="true" style="letter-spacing: 0.578px;"><span style="background-color: rgb(255, 255, 255);color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 1px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgba(0, 0, 0, 0.9);">其他人都在看</span></p></h2><span id="OSC_h3_13"></span><h3 style="letter-spacing: 0.578px;text-wrap: wrap;color: rgb(63, 63, 63);text-align: left;caret-color: rgba(0, 0, 0, 0);"><ul class="list-paddingleft-1" style="width: 577.422px;"><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492895%26idx%3D1%26sn%3D572040d50dcc39bb7e93c1f75e121599%26chksm%3Dfe426b29c935e23f80ba9ec00f2bbbef26c4a6af6c0457bc41d1e10f2d9fb78b66b91fe5edb0%26scene%3D21%23wechat_redirect" textvalue="GPU 架構與計算入門指南" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">GPU 架構與計算入門指南</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492849%26idx%3D1%26sn%3D51f53e04b4b97cd9dd38429784015c98%26chksm%3Dfe426ac7c935e3d1b5970441a68c53b6dae05792cd9a244ad8efb40ffc5ab4c60cdf3a7181b0%26scene%3D21%23wechat_redirect" textvalue="LoRA 和 QLoRA 微調語言大模型：數百次實驗後的見解" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">LoRA 和 QLoRA 微調語言大模型</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489016%26idx%3D1%26sn%3D3fc5d8ab05d2af9a7b95a1002ea128e9%26chksm%3Dfe419bcec93612d8220be748c1eea51e334fa489b72522ef45fe39141075a74d3669ec0f4110%26scene%3D21%23wechat_redirect" textvalue="英偉達首席科學家：深度學習硬件的過去、現在和未來" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">深度學習硬件的過去、現在和未來</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492976%26idx%3D1%26sn%3Dd919a508ce238048ae44e58b9cc06b71%26chksm%3Dfe426b46c935e2500178c2d2c8845fcd3e47fdeb5ec51f55b80cbca5f7b78382cdb3e6fe6a32%26scene%3D21%23wechat_redirect" textvalue="可復現的語言大模型推理性能指標" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">可復現的語言大模型推理性能指標</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492990%26idx%3D1%26sn%3D50844c8911834baf44863a9e3754175f%26chksm%3Dfe426b48c935e25ede3f772624ba262011b1b48f8ee78ac6d3b1daa5aaf71e7583828740b5cd%26scene%3D21%23wechat_redirect" textvalue="ChatGPT 規模化服務的經驗與教訓" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">ChatGPT 規模化服務的經驗與教訓</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492951%26idx%3D1%26sn%3D873b7c63ea18d638a9570bb582cddbb5%26chksm%3Dfe426b61c935e277e17fd2d4b06fa3ec998479ae87d84312f064dbae0e65875a7cb45829807d%26scene%3D21%23wechat_redirect" textvalue="微調語言大模型選 LoRA 還是全參數？基於 LLaMA 2 深度分析" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493030%26idx%3D1%26sn%3D58a43ed078977019c997a110526d7c02%26chksm%3Dfe426b90c935e28688b6e317a991bedaaa164471a275d64e60851a09b00f7f6b718e27d7b411%26scene%3D21%23wechat_redirect" textvalue="語言大模型的分佈式訓練與高效微調指南" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">語言大模型的分佈式訓練與高效微調指南</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492957%26idx%3D1%26sn%3D6ab02e219cb41ab8390cd6fc984125c6%26chksm%3Dfe426b6bc935e27d43802825c89eae6b2d346f7b62919270f8c77c0693913395eaf36af8d4a3%26scene%3D21%23wechat_redirect" textvalue="開源語言大模型演進史：向 LLaMA 2 看齊" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">開源語言大模型演進史：向 LLaMA2 看齊</a></p></li></ul></h3><span id="OSC_h3_14"></span><h3 style="letter-spacing: 0.578px;text-wrap: wrap;color: rgb(63, 63, 63);text-align: left;caret-color: rgba(0, 0, 0, 0);"><section><span style="font-size: 14px;">試用 OneFlow: github.com/Oneflow-Inc/oneflow/</span></section></h3><p ql-global-para="true" line="GpeA" style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(63, 63, 63);text-align: left;caret-color: rgba(0, 0, 0, 0);line-height: 1.6em;"><img class="rich_pages wxw-img" data-backh="158" data-backw="562" data-galleryid="" data-imgfileid="100009381" data-ratio="0.2802690582959641" data-s="300,640" data-type="png" data-w="892" style="font-size: var(--articleFontsize);letter-spacing: 0.578px;font-family: system-ui, -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: center;outline: 0px;display: inline;width: 100%;visibility: visible !important;height: auto !important;" src="https://oscimg.oschina.net/oscnet/71c4a4ad-2729-4491-b991-856a2ff43999.png" referrerpolicy="no-referrer"></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 01:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10319840</guid>
            <link>https://my.oschina.net/oneflow/blog/10319840</link>
            <author>
                <![CDATA[OneFlow 深度學習框架]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源 MoE 模型 Mixtral 8x7B 性能超過 GPT-3.5]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>大模型創業公司 Mistral AI 終於<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-of-experts%2F" target="_blank">介紹了</a></u>前兩天「開源」的&nbsp;MoE 模型 <strong>Mixtral 8x7B</strong>。</p><blockquote><p><strong><em><u><a href="https://www.oschina.net/news/270317/mixtral-8x7b-32kseqlen">Mistral AI 用「磁鏈鏈接」開源了 87 GB 的 8x7B MoE 模型</a></u></em></strong></p></blockquote><p>官方稱，Mixtral 8x7B 是開放權重的高質量<strong>稀疏混合專家模型 (SMoE)</strong>，採用 Apache 2.0 License 開源。在大多數基準測試中，Mixtral 的成績都優於 Llama 2-70B，且推理速度提升了 6 倍。而且在大多數標準基準測試中超過 GPT-3.5。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7a689c4f538b591b9744038a052717945e6.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-84fefd9ee6c091c07c894031a1af2faf2e3.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f9aaad324856028fb1e796beb2d7685020.png" referrerpolicy="no-referrer"></p><p>因此，Mistral AI 稱 Mixtral 是最強大的開放權重模型，也是成本/性能權衡方面的最佳模型。</p><p><strong>Mixtral 主要特性</strong></p><p>• 32k 上下文<br> • 支持英語、法語、意大利語、德語和西班牙語<br> • 性能超過 Llama 2 系列和 GPT-3.5<br> • 在代碼生成方面具有強勁性能<br> • 在 MT-Bench 上獲得 8.3 分</p><p>Mixtral 作為稀疏混合專家網絡，是一個純解碼器模型，其中前饋塊從 8 組不同的參數組中選擇。在每一層，對於每個 token，路由網絡選擇兩組「專家」來處理 token 並相加地結合它們的輸出。</p><p>Mixtral 總共有 45B 個參數，但每個 token 只使用 12B 個參數。因此，它以與 12B 模型相同的速度和成本處理輸入和生成輸出。</p><p>更多細節查看：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-of-experts%2F" target="_blank">https://mistral.ai/news/mixtral-of-experts/</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 10:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270511/mixtral-of-experts</guid>
            <link>https://www.oschina.net/news/270511/mixtral-of-experts</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[榮耀申請魔方大模型商標]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">天眼查信息顯示，榮耀終端有限公司近日申請註冊「榮耀魔方大模型」商標，國際分類為網站服務，當前商標狀態為等待實質審查。</span></p><p><img height="275" src="https://oscimg.oschina.net/oscnet/up-7baf34d7d00360b976559630121d67b0da4.png" width="700" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#222222">此前，該公司曾申請兩枚「MAGIC&nbsp;大模型」商標。榮耀 CEO 趙明曾發文稱，榮耀即將推出自研端側 AI 大模型和全新雲服務。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 08:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270492</guid>
            <link>https://www.oschina.net/news/270492</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[周熱點 | Linus 收斂火爆脾氣，談內核社區「老齡化」問題；Firefox 或將被淘汰；谷歌發佈最強 AI 模型 Gemini............]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2023.12.04-2023.12.10]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 06:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094041&#38;idx=1&#38;sn=18ed1a99fdf7fbbbc52688a346795664&#38;chksm=880c4c8abf7bc59cbaf66865402e963af1309b4bb627cd89ae402f319f12ce5c56561126ea09&#38;token=1220110296&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094041&#38;idx=1&#38;sn=18ed1a99fdf7fbbbc52688a346795664&#38;chksm=880c4c8abf7bc59cbaf66865402e963af1309b4bb627cd89ae402f319f12ce5c56561126ea09&#38;token=1220110296&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[GitHub.com 跑了 1200 多台 MySQL 主機，如何無縫升級到 8.0？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GitHub 團隊近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-07-upgrading-github-com-to-mysql-8-0%2F" target="_blank">分享</a></u>了他們將 GitHub.com 的底層數據庫無縫升級到 MySQL 8.0 的經驗。</p><p>據介紹，GitHub 使用 MySQL 來存儲大量關係數據，因此在不影響網站服務級別目標 (SLO) 的情況下升級主機集羣（<strong>1200 多台 MySQL 主機</strong>）絕非易事。其團隊表示，為了升級到 MySQL 8.0，他們規劃、測試和升級本身總共花費了一年多的時間，並且需要 GitHub 內部多個團隊的協作。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-613c88c0257637ef029cdd9528c6f8a3217.png" referrerpolicy="no-referrer"></p><p><strong>GitHub 的 MySQL 基礎設施概覽：</strong></p><ul><li>由 1200 多台主機組成，包括數據中心中的<strong> Azure 虛擬機和裸機主機</strong></li><li>存儲超過 300 TB 的數據，並在 50 多個數據庫集羣中每秒處理 550 萬次查詢</li><li>每個集羣都配置為具有主副設置的高可用性</li><li>分區存儲數據——利用水平和垂直分片來擴展 MySQL 集羣，以及使用 MySQL 集羣來存儲特定產品領域的數據。此外還為大結構域 (large-domain) 提供了水平分片的 Vitess 集羣，這些區域的增長超出了單主 MySQL 集羣的規模</li><li>龐大的工具生態，包括 Percona Toolkit、gh-ost、orchestrator、freno 和用於操作主機集羣的內部自動化工具</li></ul><p>由於需要操作兩個版本的 MySQL，因此 GitHub 內部使用的工具和自動化設施需要能夠兼容處理混合版本，並瞭解 5.7 和 8.0 之間<strong>新的、不同的或已棄用的語法</strong>。</p><p>為了滿足可用性標準，GitHub 團隊採取了逐步升級策略，滿足在整個過程中進行 checkpoint 和回滾的需求。下面是他們制定的升級計劃：</p><ul><li><strong>步驟 1：升級滾動副本 (rolling replica)</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9d574db1e2fec9bf7da0d7c92091b0fb19.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步驟 2：升級備份拓撲 (replication topology)</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-305231a10282f80062ca4f1d665c36305ee.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步驟 3：將 MySQL 8.0 主機提升為主集羣</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e9f6defe7e920b0167c797000292c7e390.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步驟 4：升級面向內部的實例類型</strong></li><li><strong>步驟 5：清理，</strong>確認集羣不需要回滾併成功升級到 MySQL 8.0 後，刪除 5.7 服務器。驗證工作會至少經歷一個完整的 24 小時流量週期，以確保在高峯流量期間不會出現問題。</li></ul><p>至於為什麼要升級到 MySQL 8.0，GitHub 團隊表示主要是因為 MySQL 5.7 的生命週期即將結束。此外升級後可以獲得最新安全補丁、錯誤修復和性能增強的 MySQL 版本。他們還希望測試 8.0 中的新功能並從中受益，包括即時 DDL、隱形索引和壓縮的 bin 日誌等。</p><p>詳細的技術細節查看：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-07-upgrading-github-com-to-mysql-8-0%2F" target="_blank">https://github.blog/2023-12-07-upgrading-github-com-to-mysql-8-0/</a></u></em></p><hr><p>延伸閲讀</p><ul><li><u><a href="https://www.oschina.net/news/188164/github-recent-service-disruptions">GitHub 解釋近期頻繁宕機原因：MySQL 不堪重負</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 05:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0</guid>
            <link>https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TIOBE 12 月：C# 有望成為年度編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">TIOBE 公佈了 2023&nbsp;年 12 月的</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">編程語言排行榜</a><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">。</span></span></p><p><img height="77" src="https://oscimg.oschina.net/oscnet/up-e944f70ee629593d3b3ba2ac7d008e89e4b.png" width="700" referrerpolicy="no-referrer"></p><p>2023 年度 TIOBE 編程語言名單即將出爐，其中最有望勝出的當屬&nbsp;C#。事實上，早在 2022 年&nbsp;C# 就有望奪得該桂冠，但卻在最後時刻被&nbsp;C++ 反超。而在今年，C# 的勝率又多出了幾分；因為該語言在一年內的增長率為 +2.38%，與其最接近的競爭者 Fortran 和 F# 的增長率則僅分別上漲了 +0.64% 和 +0.48%。</p><p>此外，Top 20 中的大部分語言人氣都出現了下降。<span style="background-color:#ffffff; color:#000000">TIOBE CEO&nbsp;Paul Jansen 評論稱，</span>「答案就在所有小語言所在的長尾（long tail）部分。這些語言的受歡迎程度都在上升，而且越來越接近大語言」。例如：一年前，排名第 50 位的語言得分僅為 0.14%，但現在第 50 位語言的得分已經達到了 0.24%。</p><p><strong style="color:#333333">TIOBE 12 月 TOP 20 編程語言</strong></p><p><img height="414" src="https://oscimg.oschina.net/oscnet/up-b25283a71bbac81145079c4b2848ccc6e95.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">相較上月，除了 Ruby<span>&nbsp;</span>(18→19)、R (19→20) 以及 Rust (20→18) 之間出現了小範圍波動外，Top&nbsp;10-20 榜單沒有其他任何排名變化，這也是近期以來榜單變動最小的一次。</span></p><p><strong style="color:#333333">TOP 10 編程語言 TIOBE 指數走勢（2002-2024）</strong></p><p><img height="228" src="https://oscimg.oschina.net/oscnet/up-c048f61fdb18f5fa94fbc07b575f6acc8f9.png" width="700" referrerpolicy="no-referrer"></p><p><strong style="color:#333333">第 21-50 名編程語言排行</strong></p><p><img height="430" src="https://oscimg.oschina.net/oscnet/up-e1c00e5bc23507475a73c563cbdb213cdc9.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">第 51-100 名如下，由於它們之間的數值差異較小，僅以文本形式列出（按字母排序）：</span></p><p>&nbsp;</p><blockquote><p>4th Dimension/4D, ABC, Algol, Apex, ATLAS, AutoLISP, Bash, Boo, Carbon, CIL, CL (OS/400), Clipper, Clojure, Curl, Eiffel, Elm, Erlang, GAMS, Groovy, Icon, Inform, Io, J#, LabVIEW, Ladder Logic, LiveCode, Maple, Modula-2, MOO, MQL5, NATURAL, Nim, OCaml, OpenEdge ABL, PostScript, Pure Data, Q, Racket, Ring, RPG, Smalltalk, Snap!, Solidity, SPARK, SPSS, Tcl, VHDL, Wolfram, X10, Zig</p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">TIOBE 編程社區指數（The TIOBE Programming Community index）是一個衡量編程語言受歡迎程度的指標，該指數每月更新一次。評判的依據來自世界範圍內的工程師、課程和第三方供應商，包括流行的搜索引擎，如 Google、必應、雅虎、維基百科、亞馬遜、YouTube 和百度都被用於指數計算。值得注意的是，TIOBE 指數並不代表編程語言的好壞或編寫代碼的多少。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">該指數可以用來檢查你的編程技能是否還能跟上時代的步伐，或者在開始建立一個新的軟件系統時，基於指數對採用何種編程語言做出決策。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F" target="_blank">TIOBE 指數</a><span style="color:#000000">的定義方式，以及詳細榜單信息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">均可查看官網</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 03:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270438/tiobe-index-2023012</guid>
            <link>https://www.oschina.net/news/270438/tiobe-index-2023012</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[因 EXT4 數據損壞錯誤，Debian 12.3 推遲發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Debian 團隊發佈公告稱，由於 Linux 內核 6.1.64-1 中的<strong> ext4 文件系統出現數據損壞問題</strong>，因此原計劃昨天發佈的 Debian 12.3 將會被推遲，同時進行修復。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-6b960c796ab8ff358469f03578c81866ec1.png" referrerpolicy="no-referrer"></p><p>來源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.debian.org%2FNews%2F2023%2F2023120902" target="_blank">https://www.debian.org/News/2023/2023120902</a></u></p></blockquote><p>據介紹，此 bug 由從 Linux 6.5 回溯的一個有問題補丁導致，它引起了 EXT4 和 iomap 代碼之間的幹擾，可能導致舊內核上的數據損壞。</p><p>這個問題主要出現在最近的 Linux 6.1 LTS 點版本中，新的 Linux 6.1.66 版本已經回滾了有問題的提交。Debian 的 bug 報告稱這個問題為「非嚴重的數據丟失」，因此應該是可以恢復的。</p><p>但由於 Debian 12.3 原本計劃發佈的內核版本受到了影響，因此被推遲發佈。建議 Debian 12 用戶在 Linux 6.1.66 內核鏡像推出之前不要升級系統。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 03:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270435/debian-12-3-delayed-ext4-corrupt</guid>
            <link>https://www.oschina.net/news/270435/debian-12-3-delayed-ext4-corrupt</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[周鴻禕：有人找我做養豬大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 2023 中國企業領袖年會上，360 創始人周鴻禕對於最近的 AI 大模型熱潮發表了看法。</p><p>他表示，（感覺）大家對大模型充滿了一種無限的嚮往或者不切實際的膜拜，之前還有人找他做養豬大模型。他認為，大模型的技術路線突破才短短几年，目前還存在着很多缺點。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-391bf18f540407673913ddee0ac73938969.png" referrerpolicy="no-referrer"></p><p>來源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2Ftv%2Fshow%2F1034%3A4977511076134973%3Ffrom%3Dold_pc_videoshow" target="_blank">https://weibo.com/tv/show/1034:4977511076134973</a></u></p></blockquote><p>他希望大家對大模型有一個正確的認知，<strong>不要高估現在大模型的能力，不要低估大模型未來發展的潛力</strong>，雖然它現在已經可以跟實體產業相結合，但它還不能完全接管此類業務，應該揚長避短髮揮它的長處，因為很多短板還有待解決。</p><p>目前國內各大企業、科研機構和高校等單位已公開的 AI 大模型至少已經達到了 188 個，而首批通過《生成式人工智能服務管理暫行辦法》備案的大模型已於 8 月 31 日公佈，第二批通過備案的 AI 大模型也已於 11 月開放服務。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3a3b3aaeff5f0043de536b6f5f44b963797.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 03:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270430</guid>
            <link>https://www.oschina.net/news/270430</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[理想汽車全自研多模態認知大模型 —— Mind GPT]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>理想汽車於 12 月 10 日晚正式發佈 OTA 5.0 版本，並計劃於 12 月 19 日開啓全量用戶推送。官方介紹稱，在 OTA 5.0 中，理想同學最大的變化是引入了 Mind GPT 的能力。</p><p>Mind GPT 是理想全自研的多模態認知大模型，據稱他們從 0 到 1 構建了 Mind GPT 原始基座模型，<strong>模型結構採用了自研的 TaskFormer 神經網絡架構</strong>，基於用車、娛樂、出行等場景使用 SFT、RLHF 等技術進行了一系列的訓練，讓 Mind GPT 擁有了理解、生成、知識記憶及推理的三大能力。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7aa6319e367ca499b8541b306ec3892d181.png" referrerpolicy="no-referrer"></p><p>目前 Mind GPT 還處於內測版本階段，那麼 Mind GPT 在行業裏到底是什麼水平呢？</p><p>官方稱在目前國內極具權威性的，中文大語言模型評測榜單 C-EVAL，覆蓋了人文、社科、理工等多個方向共 52 個學科，Mind GPT 在 58 個參加測評的大模型中排行第一名；同時，還有涵蓋從基礎學科到高級專業包含 67 個主題領域的評測榜單 CMMLU，Mind GPT 也獲得第一名，拿下了雙冠軍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d89ae63875873819f3b3676b6fea16d8c81.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-af86f00982833de97dd852d6a57f17288dd.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270426</guid>
            <link>https://www.oschina.net/news/270426</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大灣區一體化算力服務平台正式發佈，算力規模超 5000P]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 10 日，在第二屆數字政府建設峯會暨數字灣區發展論壇上，深圳市前海管理局、國家（深圳·前海）新型互聯網交換中心（下稱「前海交換中心」）共同<strong>發佈粵港澳大灣區一體化算力服務平台，並正式成立前海算力服務聯盟</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-e379cb9cc7c4002e4f3fb84f03c47a13c02.png" referrerpolicy="no-referrer"></p></blockquote><p>據介紹，該平台由前海管理局提出設想和要求，在深圳市通管局、市工信局的支持下，由前海交換中心和紫金山實驗室共同開發部署。</p><p>官方透露，該平台自 10 月 31 日試運行以來，匯聚的算力規模大幅增長近 4 倍，<strong>總規模已達 5180 PFLOPS</strong>，主流芯片覆蓋率超 75%，並已為 10 餘個企業、高校、科研機構的人工智能團隊提供算力服務。</p><ul><li><p><strong>在算力調度方面</strong>，創新多維一體編排算法，實現算力高效調度和智能供給；</p></li><li><p><strong>在算力交易方面</strong>，平台不收取中介費用，促進供需雙方合作與交易；</p></li><li><p><strong>在算力應用方面</strong>，高度集成各類算法工具，實現應用一鍵部署、資源秒級開通，進一步降低門檻、提升效率；</p></li><li><p><strong>在算力安全方面</strong>，構建算網一體化安全防護體系，持續強化算力安全保障。</p></li></ul><p><img height="360" src="https://static.oschina.net/uploads/space/2023/1211/102814_wKUa_2720166.png" width="640" referrerpolicy="no-referrer"></p><p>同時， <strong>大灣區首個算力服務行業組織 —— 前海算力服務聯盟正式成立</strong>，首批成員單位包括前海科創集團、前海交換中心、紫金山實驗室、華為、深圳商湯、萬國數據、世紀互聯、深圳數據交易所、深圳科創學院、香港中文大學未來智聯網絡研究院、粵港澳大灣區大數據研究院。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270418</guid>
            <link>https://www.oschina.net/news/270418</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[郭煒：開源大俠是怎樣煉成的]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 6 月 1 日，首個由國人主導的開源數據集成工具 Apache SeaTunnel 正式宣佈從 Apache 軟件基金會孵化器畢業成為頂級項目。歷經 18 個月的孵化，這個項目終於瓜熟蒂落，社區貢獻者 200+，代碼 24.5 萬行，上千家企業使用，風光無限。令人難以想象，郭煒剛接手它時，倉庫被封、貢獻者四散的落魄樣子。</p><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>大俠出手， SeaTunnel 浴火重生</h1><p>SeaTunnel 原名 Waterdrop，於 2017 年由樂視創建，並於同年在 Github 上開源，是一個大數據集成處理平台。當時國內各種數據引擎風起雲湧，卻少有項目解決數據源之間的無縫集成和高速同步問題，因此 Waterdrop 在其中顯得頗為亮眼。可惜這種亮眼卻為它招來了橫禍——開源項目 Waterdrop 的商標被搶注了，而且對方的法務還發送律師函給開源的發起者和 Github 。</p><p>由於開源項目的名稱不屬於【商標】，而國內的商標又是【申請在先】原則，誰先申請誰先得到，因此 Waterdrop</p><p>一下子百口莫辯，落了下風， Github 在收到律師函後，把 Github 上 Waterdrop 的整個倉庫都封了，所有的代碼、PR、Issue 也全都無法訪問，而且 Waterdrop 的創始團隊還面臨訴訟糾紛。沒辦法，團隊只能在圈內四處求助，機緣巧合之下，遇到了郭煒。</p><p>郭煒，人稱「郭大俠」，平時就愛在開源圈內熱心給大家幫忙。創始團隊找到郭煒後，郭煒看到這樣的事情，又是這樣有前途的項目，不忍心袖手旁觀，他便把項目接了過來，一邊找律師解決法律糾紛，一邊利用自己的資源輾轉聯繫微軟的 Github 管理人員解釋，幫助項目解封。</p><p>2021 年，爭議終於告一段落，Waterdrop 改名 SeaTunnel，得以繼續運轉。可大俠並不放心，畢竟團隊才 3 個人，維護社區已是夠嗆，哪還有能力顧及法律合規的事情？萬一這劇情重來一遍，可就不是鬧着玩的了。郭煒開始當 SeaTunnel 的 Mentor，手把手帶起了開源項目，並致力於把項目孵化到 Apache 基金會裏面。一方面，基金會是專業的，有專人管理法務，比現在的草台班子好多了。另一方面，SeaTunnel 也可以接替退役的 Apache Sqoop，解決數據源之間數據打通的問題。</p><p>最終，在多位導師的幫助下，2021 年 12 月 9 日，SeaTunnel 正式通過 Apache 軟件基金會的投票決議，順利進入 Apache 孵化器，成為基金會中第一個誕生自中國的數據集成平台項目，目標是「連接萬源，同步如飛」。</p><p>如今，SeaTunnel 從 Apache 軟件基金會孵化器畢業成為頂級項目，也在全球擁有很多企業用戶和開發者，早已告別最初的窘迫。郭大俠也輕輕招手，奔赴了下一個難題。</p><p style="text-align:center"><img height="664" src="https://oscimg.oschina.net/oscnet/up-8c5e3b11d68a2569fa44bc1e66d5f395f95.png" width="500" referrerpolicy="no-referrer"></p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>大俠當年也是開源「小趴菜」</h1><p>SeaTunnel 團隊最初之所以求助郭煒，是因為他成功運營過多個開源社區，在圈內早已小有名氣。時間回撥到 2010 年，郭煒就開始接觸開源了。那時候他在 Hadoop 社區裏當「潛水黨」，以一個小白的身份，旁觀各路大神在裏面交流技術問題，給出」炫酷「的解決方案。「在開源社區裏，你能看到很多全新的項目，全新的技術，能不斷學到新東西，保持走在技術圈的前排，這是別的渠道無法替代的。書上的東西太陳舊了，網上的東西又特別雜，只有在開源社區，才能純粹地瞭解新技術，瞭解開源圈在關注啥。」</p><p>當然，郭煒這樣的「 e 人」不會一直坐邊角。很快他就融入了社區，經常參加線下 meetup，也 contribute 過不少文檔。但在開源社區裏，郭煒這個名字就是一個「 nobody 」。到聯想工作之後，郭煒繼續堅持開源，也把開源帶到了聯想。在聯想 COC 核心技術架構委員會，郭煒作為全球大數據平台負責人，一直在當開源佈道者，推動開源技術的應用，許多同事都是因為他的宣傳才「入坑」的。</p><p>但那時候在企業內部做開源佈道，也是困難重重。首先開源當時並沒有現下這麼火，很多人對開源知之甚少，唯一的印象就是「免費」。其次，習慣了商業軟件的企業，更傾向於沿用原來的選擇，畢竟商業軟件雖然收費，可是有人售後，有人負責。而開源軟件，雖然免費，卻有風險，遇到問題，誰來解決呢？尤其是對於全球化的大公司而言，開源在當地還可能存在法律風險，哪怕這是個「省錢」的決定，想拍板也不容易。</p><p><strong>郭煒坦言，在大企業內部做開源推廣，就是要承擔很多的責任。</strong>説白了就是，這個鍋一開始你得背一背，才能讓一些關鍵的業務用戶用起來。等他們用起來覺得不錯了，你才能壓住質疑，談下一步的推廣。當時為了推廣 Hadoop、Spark 且要符合各國的法務規範，郭煒要跟全球的同事開會，會議從早上六點排到了夜裏兩三點，一遍一遍地跟大家科普這個項目是什麼、怎麼用、出問題怎麼辦、合不合規、為什麼要用它......經過跟業務部門「過五關斬六將」的 battle，最後一個美國的部門率先接受了 Spark，之後因為口碑不錯，才慢慢推廣到了其他國家、其他部門。</p><p>「我們開源社區裏面的每一個用戶都是很珍貴、很不容易的，尤其是那些為剛出來的新開源項目做企業內部推廣的小夥伴，每一個都是勇士。他們在企業內部推廣一項新技術，不僅需要做很多工作，更是拿自己頭上的烏紗帽在為社區佈道、保駕護航。所以，我們關注開源社區，我們不能只看到 contributor、committer、PMC，更要看到我們社區裏的普通用戶、他們的艱辛和不易。」郭煒説，<strong>「其實每一個使用開源的人，都是這個社區的 contributor，他們做了很多的 contribution，只不過沒有體現在代碼上面而已。」</strong></p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>從開源 User 變 Owner，大俠不好當</h1><p>2016 年，郭煒加入易觀，擔任 CTO（首席技術官）。當時公司在做一款用戶行為分析的產品，主要依靠 Presto 進行二次修改來適配場景。有一天，郭煒正在網上閒逛，突然發現有個新項目，跟自家產品的場景有點像。於是就測試了一下，結果發現比自家產品快 10 倍！郭煒一下子就被震驚了。</p><p><strong>這個項目就是 ClickHouse，俄羅斯的 Yandex 於 2016 年開源的</strong><strong>列式存儲數據庫</strong><strong>（</strong><strong>DBMS</strong><strong>），主要用於在線分析處理查詢（</strong><strong>OLAP</strong><strong>），能夠使用 </strong><strong>SQL</strong><strong> 查詢實時生成分析數據報告。</strong></p><p>郭煒自問在數據技術圈已屬「先鋒達人」，各種研究都是隨時關注的，可即便這樣也沒聽説過這個項目，想來其他人知道它的概率就更低了。這樣的好東西，怎麼能忍住不分享呢？於是，郭煒聯繫了 ClickHouse 的全球社區負責人 Ivan，提出幫忙運營中國的社區。ClickHouse 同意了。</p><p>但是，萬事開頭難，從 0 到 1 新建一個開源社區，就更難。沒人知道你是誰，沒人願意用你。郭煒訪談了早期快手、新浪用戶，並組建了社區羣。但是這第一個羣，花了一年半的時間才湊滿。線下社區的人就更少了，第一次 ClickHouse meetup，才來了 11 個人。</p><p>由於這是屬於個人愛好的行為，ClickHouse 的各種運營活動都得自己做。日常的建羣、驗證、答疑、指導等等，都是下班和週末抽空完成的，每天晚上 11 點，就是郭煒的 ClickHouse 支持時間。最開始的時候，還要到每個羣裏手把手教大家 ClickHouse 怎麼用、怎麼裝、怎麼配？週末還要找到一些關鍵用戶，跟他們聊天、吃飯，把他們組織起來，邀請他們來參加線下的組局等等。</p><p>「<strong>做開源不是到各種大會上去講一講就完了，</strong><strong>開源</strong><strong>布</strong><strong>道師</strong><strong>高光背後其實是無數的日常瑣碎。</strong>想要運營好一個社區是很繁瑣的，比方説羣裏有人發廣告，你得把他踢出去；有人在裏邊吵架了，你要怎麼維護？有人向社區扔臭雞蛋了，你怎麼判斷是不是開源項目的問題？如果項目有問題，我們怎麼樣虛心接受？這些都是在社區維護裏面要去做的事。一點一滴長年累月的積累，才能真的把社區這件事做好。」郭煒説，「你看前 Apache 的董事會主席 Craig，這樣的頂級大佬，都 70 多歲了，還在基金會裏做 secretary 給大家建 Apache 的賬號，你就知道社區運營有多瑣碎了。在哪裏都一樣的。」</p><p>所幸，在這條路上，郭煒不是一個人在戰鬥。隨着 ClickHouse 用戶的增加，社區隊伍也愈發壯大了。微信羣達到 10 個的時候，郭煒開始招募志願者，幫忙處理羣事務。線下的 meetup，一開始一二十人，在公司找個會議室就能辦。後來發展到線下兩三百人，線上一千多人，普通場地都裝不下了，郭煒就到處找朋友借場地，再自掏腰包飛過去組織。有一次在上海的 Meetup，報名的有 300 多人，但是找不到 Meetup 的地方，當時的趣頭條大數據負責人金海就找公司幫忙提供了一個酒店，有布台，有大屏，有 4 個 session，跟開源大會一樣。還有當年在閲文集團的劉文成，是 ClickHouse 的小 C，幫忙回答各種問題。在這些貢獻者的幫助下，ClickHouse 中國社區終於辦上了正規的 meetup。</p><p style="text-align:center"><img height="898" src="https://oscimg.oschina.net/oscnet/up-3c53346abc745644c05c6c876f2b686ccc7.png" width="1860" referrerpolicy="no-referrer"></p><p>三年後的 2019 年，ClickHouse 爆火，截至目前，ClickHouse 仍是 OLAP 方面用戶最多的社區。在整個社區裏，中國用戶也是最多的。頭條、阿里等企業用戶也相繼加入。在這一年的 meetup，社區邀請了俄羅斯 Yandex 公司 ClickHouse 開源社區創始人 Alexey Milovidov，他説：<strong>「中國的 ClickHouse 用戶量能取得這樣爆發性的增長（一個季度內用戶增長了四倍），離不開 William（郭煒）在中國的推廣。」</strong><strong></strong></p><p>&nbsp;</p><span id="OSC_h1_4"></span><h1>功成不在我，失敗猶更多</h1><p>能得到 ClickHouse 創始人的認可，郭煒很開心。不過他還是覺得，ClickHouse 能達到現在的程度，與其説是因為他這個推動者，不如説是因為這個產品本身的優秀和中國開源小夥伴們的支持。「在數據和大數據領域裏，中國對開源的接受程度和開源的使用速度在全球都是最快的，比美國還要快。這得益於中國互聯網的發展速度，和大量互聯網公司的使用。也許開源商業的天花板沒有美國那麼高，但是中國捲起來的速度更快。<strong>中國往往能快速接受一個新技術，然後快速卷，快速迭代，加上中國有廣大的開發者和用戶基礎，做起開源來有得天獨厚的優勢。</strong>」</p><p>現在回頭看，這四五年裏，郭煒自己和小夥伴們，都受益良多。當初跟他一起在社區裏改代碼的小夥伴們，現在薪資都翻了四五倍了。其中一個志願者小 C 劉文成，被騰訊選中，從一個小廠跳槽到了微信裏面做 ClickHouse 的維護。「人人為我，我為人人。你在社區裏面做的貢獻，大家都是看得見的。你的技術水平被大家認可了，那你獲得的機會自然也會比別人多。<strong>我覺得這就是開源社區的魅力吧，在這裏大家都是平等的，是金子很快就會發光。</strong>這也算是對社區貢獻者的一種回報吧。只不過這種回報不是金錢上的，而是別人對你的認可和你的影響力上的。」郭煒説。</p><p>當然，也不是所有的開源項目都能像 ClickHouse 那麼幸運。大俠也會遇到挫折，運營的開源項目中失敗的更多，有好多開源項目親自運營了兩三年，star 數才十幾個。自己做開源項目，哪有那麼容易成功呢？「犯錯沒關係，犯的錯誤多了你積累的經驗也會多。你看我現在做產品能成功，背後反而是那些失敗的經驗在發揮作用。做其他事也一樣。」郭煒兩手一攤，「因為每個人的成功，都有當時特殊的時代背景和需求，所以成功的經驗，反而不重要，失敗的經驗更重要，它才能指導你怎麼避免犯錯。所以每一個成功的背後，可能都有 99 個失敗，只不過大家最後只能看到那 1 個成功的而已。」</p><p>經過無數失敗的郭煒，也鍛煉出了自己看項目的眼光。「<strong>我覺得做開源社區，最關鍵的是要看準這個產品的定位：它到底解決什麼問題，用什麼樣的技術框架？如果真的看好這個社區的發展的話，就到裏面去跟社區一起成長好了。」</strong>郭煒説，「產品有 bug 沒關係，每個社區都不是完美的，當初 ClickHouse 也有各種各樣的問題，但只要你把大的架構定好之後，剩下的細節就在這個基礎上去迭代、去完善就好了。ClickHouse 當時解決的其實就是寬表和日誌查詢問題，就這一件事。然後它把當時最新的技術——向量計算，直接放到引擎裏，速度就是比我原來的 Presto 快十倍。它就解決這個問題，且解決得最好，所以在社區也能發展得很好。」</p><p><strong>看準了產品思路、底層邏輯和創始團隊之後，剩下的事情就是堅持了。</strong>「 ClickHouse 2016 年剛剛開源的時候，我就把它引進中國了，那時候還默默無聞，直到 2019 年才爆火。前面這幾年，完全就是靠熬過去的。你要相信你的眼光，持續堅持，不能半途而廢。有時候一個開源社區最後能不能成功，就看你堅持的時間夠不夠長了。」郭煒説，「等到社區真的成長起來，影響力足夠大的時候，裏面的每一個小夥伴都會受益。」</p><p>&nbsp;</p><span id="OSC_h1_5"></span><h1>多重身份，在開源與商業間做平衡</h1><p>2022 年 4 月，Ted Liu（劉天棟）突然來通知郭煒：我們提名你做 Apache Software Foundation（ASF）Member，你寫個材料吧！就這樣，郭煒成了 Apache 基金會 Member。「收到這個榮譽的時候，特別開心，覺得這是大家對我的肯定，同時覺得自己身上的責任更重了，也更有動力去考察和維護好 Apache 的每一個項目。」</p><p>而在 2023 年，郭煒身上又多了一個身份，白鯨開源的 CEO。很少有人同時當基金會 Member 和商業公司的領導人，郭煒會不會覺得衝突呢？做決策的時候，是先考慮開源還是商業化？如果開源和商業化功能打架，大俠不就很難辦？</p><p>不過，郭煒對此很淡定，他認為，開源和商業化並不衝突，甚至是相輔相成的。<strong>一個開源項目如果想長治久安可持續</strong><strong>發展</strong><strong>，那商業化大概是不可避免的。</strong>如果沒有商業公司去承接對核心開發者和貢獻者的支持，去滿足深度用戶的需求，久而久之，純靠愛發電的核心貢獻者可能也會難以為繼。</p><p>「像白鯨開源這樣做（Apache SeaTunnel 和 DolphinScheduler）商業化的公司，不是開源的對立面，而是開源的促進者。」郭煒説，「商業能夠更好地保住開源的調性和核心貢獻者的飯碗，讓他們能夠持續地在開源上發力。同樣地，有些深度的用戶，當開源項目無法完全滿足他的需求，或者需要有人幫他在企業內部做推廣的時候，有一個商業實體來幫他一起做這件事，那這個佈道師也會輕鬆一點，而不必像我當初那樣獨自一個人舌戰羣儒，過五關斬六將。」</p><p>可是，開源項目之所以商業化困難，恰恰是因為公開了代碼。商業和開源究竟如何取捨？哪些應該開源，哪些不開源？遇到衝突的時候，又該如何抉擇？</p><p>郭煒笑笑，露了一手聰明的「切糕大法」：「首先從產品定位來講，你得把你的開源主力用戶羣和你的非開源主力用戶羣分開——如果技術水平很強，而且自己還有時間有預算去折騰，那就用開源的好了。如果時間不夠，人力預算又不足，那使用商業版更省心。所以，這兩者的使用人羣是不同的，你的開源軟件和商業軟件定位也不一樣。明白了這個，你糾結的點也就沒那麼多了。」</p><p>按照慣例，最新的功能都會被放到開源版裏面，相對穩定的、有行業屬性的功能則通常放到商業版裏，兩邊不時互通有無。郭煒要做的，就是把握好兩邊放功能的時間和節奏就行了。「至於具體哪些功能放到商業版、哪些功能放到開源版，這就是刀法怎麼切的問題了：切得少了，你這個商業版沒有價值；切多了，又會影響社區。那怎麼來把握，就是一門藝術而不是技術了，這隻可意會不可言傳哪（笑~）」</p><p>總的來説，郭煒對中國的開源商業環境非常看好。畢竟中國對開源的接受程度很高。雖然從開源社區到商業公司和商業產品這一條路大家還在摸索，但至少，郭煒接觸到的新一代決策者，已經跟過去不一樣了：他們明白開源會讓公司的技術和國際接軌、和全球最新的科技接軌。無論是傳統公司還是互聯網企業，都在逐步嘗試使用開源原生的商業軟件。</p><p>「中國開源商業的氛圍和整體的步伐，正在覺醒。」甚至中國開源走向全球，郭煒也覺得大有希望：「畢竟中國有這麼好的土壤，特別在大數據領域裏，有這麼多的數據、終端、場景、性能......卷出來的項目，它一定是全球排名前列的，最終跟海外商業場景相結合，一定能賣得很好。」</p><p>&nbsp;</p><span id="OSC_h1_6"></span><h1>開源老將，在醞釀下一個社區</h1><p>在開源圈裏，郭大俠也有自己的偶像：「Craig 給我做了一個榜樣，他都 70 多了還在堅持為開源做貢獻，我覺得我活到 70 歲時候也能繼續做開源，他就是我的榜樣。哈哈。」</p><p>活到老學到老，這也許不止是郭煒一個人的開源理想，但至少，郭煒堅持到了現在。</p><p>如今，作為開源老將，郭煒又在關注下一個熱點了——大模型，特別是開源的大模型。「我認為將來的每一款軟件，都會被大模型和相關的 AI 技術再改造一遍、重做一遍。下一步如果再去孵化項目，可能就是跟大模型相關的了。」郭煒説，「如果只是訓練大模型，那麼國內外只有寥寥幾家公司能玩得起。但是大模型生態上下游的公司如果要做好，還是有很多機會的。那麼，哪些東西能夠促進大模型的應用、降低大模型的使用門檻、讓大模型真正跑起來，尤其是大模型跟數據之間的關聯，將會是我關注的重點。」</p><p>郭大俠收拾行囊，又奔赴了下一場挑戰。</p><p>不知道接下來，他又會遇到怎樣的故事呢？</p><div style="text-align:center"><img height="750" src="https://oscimg.oschina.net/oscnet/up-5203b04a5dc96550855c4bae1487b99f11a.png" width="500" referrerpolicy="no-referrer"></div><div>
  &nbsp; 
</div><div>
  &nbsp; 
</div><div><blockquote><div><span style="color:#16a085"><strong><span style="background-color:#f6f6f6">【溯源】</span><span style="background-color:#f6f6f6">在每一場對話中，追溯關於開源的故事，認識那些極客、自由，並堅持着的開源人。</span></strong></span></div></blockquote><p style="color:#494949; margin-left:0; margin-right:0; text-align:left"><span><span>OSCHINA 推出的開源人物專訪欄目【溯源】。</span></span></p><p style="color:#494949; margin-left:0; margin-right:0; text-align:left"><span><span>溯源，意指向源頭追溯，為開源求解。問渠哪得清如許，為有源頭活水來。每一個開源參與者，都是掀起開源浪潮最鮮活的源泉。所有開源故事，共同構建着我們今天看到的開源世界。</span></span></p><p style="color:#494949; margin-left:0; margin-right:0; text-align:left"><span><span>開源剛出現的數十年裏，為開源奔走的黑客團體都在遭受來自社會主流的冷漠和排斥。即便現在的軟件行業已經大喊出 「擁抱開源」 的口號，問題也依然存在。</span></span></p><p style="color:#494949; margin-left:0; margin-right:0; text-align:left"><span><span>我們不知道開源貢獻者、開源佈道師，以及所有參與開源的人還會面臨多少阻礙，但給予我們信心的是，更多的人在投身開源事業。</span></span></p><p style="color:#494949; margin-left:0; margin-right:0; text-align:left"><span><span>所以 OSCHINA 希望面向開發者社區，尋找每一個積極參與開源、對開源有想法的人，瞭解他們以及他們的開源故事，窺探故事中的開源事業發展規律。</span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">【溯源】系列文章：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">01&nbsp;<a href="https://my.oschina.net/u/4105562/blog/4721676"><span style="background-color:#ffffff; color:#494949">適兕</span><span>&nbsp;</span>：成為開源佈道師</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">02&nbsp;<a href="https://my.oschina.net/u/4489239/blog/4875125">衞劍釩：開源圈的 「世外高手」</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">03&nbsp;<a href="https://my.oschina.net/u/4489239/blog/4945872" target="_blank">「工具人」 趙生宇：清北本碩，為開源從阿里辭職去同濟讀博</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">04&nbsp;<a href="https://my.oschina.net/u/4489239/blog/5047833" target="_blank">吳晟：開源對我來説，社交是最重要的</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">05&nbsp;<a href="https://my.oschina.net/u/4489239/blog/6215354" target="_blank">悟空劉歧：技術瑕疵不除不快，開源社區代碼説話</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">06&nbsp;<a href="https://my.oschina.net/u/3859945/blog/5504643" target="_blank">姜寧，帶程序員前往開源 「烏託邦」</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">【溯源】專欄正在徵集開源人物故事，如果你認為自己或是身邊的人對開源做出過獨特貢獻，歡迎留言評論，讓我們聽聽 TA 的故事。</p></div></div>
                                    ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10320168</guid>
            <link>https://my.oschina.net/u/6852546/blog/10320168</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Laravel Pulse —— 實時應用程序性能監控工具和儀錶板]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#1f2328">Laravel Pulse 是一款適用於 Laravel 應用程序的實時應用程序性能監控工具和儀錶板。</span>可讓你一目瞭然地瞭解應用程序的性能和使用情況。跟蹤緩慢的作業和端點等瓶頸，找到最活躍的用戶等等。</p><p><img alt="" height="349" src="https://static.oschina.net/uploads/space/2023/1205/142731_blmT_4252687.png" width="500" referrerpolicy="no-referrer"></p><p>特性：</p><ul><li><strong>應用程序使用情況。</strong>找出在整個 Laravel 應用程序中發出最多請求、使用最慢端點和派遣最多任務的用戶。</li><li><strong>服務器統計。</strong>監控服務器的 CPU、內存和磁盤使用情況。運行多個服務器？沒問題。Pulse 可以在一個地方監控所有服務器。</li><li><strong>隊列監控。</strong>在優化 queue workers 的過程中消除猜測。查看實時和歷史統計數據，瞭解有多少作業待處理、有多少作業失敗、有多少作業已成功處理。</li><li><p><strong>性能。</strong>查看應用程序性能瓶頸的高級概覽。查看影響用戶的最慢端點、查詢、作業和發出請求。</p></li><li><strong>異常趨勢。</strong>概述應用程序中發生的異常。將異常情況與應用程序的完整健康狀況概覽並排顯示，有助於您發現整個堆棧中的異常情況。</li><li><strong>Bring Your Own。</strong>為自己定製卡片，或為 Laravel 社區創建可共享的卡片。你甚至可以自定義 Pulse 面板的佈局。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 01:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/laravel-pulse</guid>
            <link>https://www.oschina.net/p/laravel-pulse</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 開源基礎密碼庫，銅鎖/Tongsuo]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-概述" class="anchor" href="https://gitee.com/babassl/Tongsuo#%E6%A6%82%E8%BF%B0"></a>概述</h1><p>銅鎖/Tongsuo 是一個提供現代密碼學算法和安全通信協議的開源基礎密碼庫，為存儲、網絡、密鑰管理、隱私計算等諸多業務場景提供底層的密碼學基礎能力，實現數據在傳輸、使用、存儲等過程中的私密性、完整性和可認證性，為數據生命週期中的隱私和安全提供保護能力。</p><p>銅鎖獲得了國家密碼管理局商用密碼檢測中心頒發的商用密碼產品認證證書，助力用戶在國密改造、密評、等保等過程中，更加嚴謹地滿足我國商用密碼技術合規的要求。可在<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fmisc%2Fst247r05s8b5dtct">此處</a>下載資質原始文件。</p><img src="https://github.com/Tongsuo-Project/Tongsuo/blob/master/validation-android.png" width="50%" height="50%" referrerpolicy="no-referrer"><h1><a id="user-content-特性" class="anchor" href="https://gitee.com/babassl/Tongsuo#%E7%89%B9%E6%80%A7"></a>特性</h1><p>銅鎖提供如下主要的功能特性：</p><ul><li>技術合規能力
<ul><li>符合 GM/T 0028《密碼模塊安全技術要求》的"軟件密碼模塊安全一級"資質</li><li>符合 GM/T 0005-2021《隨機性檢測規範》</li></ul></li><li>零知識證明（ZKP）
<ul><li>Bulletproofs range</li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fts%2Fbulletproofs">Bulletproofs R1CS</a></li></ul></li><li>密碼學算法
<ul><li>中國商用密碼算法：SM2、SM3、SM4、<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fts%2Fcopzp3">祖沖之</a>等</li><li>國際主流算法：ECDSA、RSA、AES、SHA 等</li><li>同態加密算法：<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fmisc%2Fec-elgamal">EC-ElGamal</a>、<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fmisc%2Frdibad">Paillier</a>等</li><li>後量子密碼學*：Kyber、Dilithium 等</li></ul></li><li>安全通信協議
<ul><li>支持 GB/T 38636-2020 TLCP 標準，即<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fts%2Fhedgqf">雙證書國密</a>通信協議</li><li>支持<a href="https://gitee.com/link?target=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Frfc8998">RFC 8998</a>，即 TLS 1.3 +<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fts%2Fgrur3x">國密單證書</a></li><li>支持<a href="https://gitee.com/link?target=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Frfc9000">QUIC</a> API</li><li>支持<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fts%2Fleubbg">Delegated Credentials</a>功能，基於<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.ietf.org%2Farchive%2Fid%2Fdraft-ietf-tls-subcerts-10.txt">draft-ietf-tls-subcerts-10</a></li><li>支持<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.yuque.com%2Ftsdoc%2Fts%2Fdf5pyi">TLS 證書壓縮</a></li><li>支持緊湊 TLS 協議*</li></ul></li></ul><p>注：*號表示正在支持中</p><h1><a id="user-content-典型應用" class="anchor" href="https://gitee.com/babassl/Tongsuo#%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8"></a>典型應用</h1><p>開源應用（Opensource Application）</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fangie.software%2Fen%2F">Angie</a>, Angie 是一個可以替換掉 NGINX 的新型 Web 服務器，我們建議使用銅鎖的用戶優先選擇 Angie (We highly recommend you to replace NGINX with Angie to enable Tongsuo's functionality)</li><li>Apache APISIX</li><li>Tengine</li></ul><p>商業應用 (Commercial Application)</p><ul><li>支付寶 App</li><li>OceanBase 數據庫</li><li>阿里雲</li><li>天威誠信</li></ul><h1><a id="user-content-編譯和安裝" class="anchor" href="https://gitee.com/babassl/Tongsuo#%E7%BC%96%E8%AF%91%E5%92%8C%E5%AE%89%E8%A3%85"></a>編譯和安裝</h1><p>一般來説，典型的編譯和安裝過程如下：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./config --prefix=/path/to/install/dir</span><span id="LC2" class="line">make</span><span id="LC3" class="line">make install</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>如果是 Windows，則需要：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">perl Configure enable-ntls</span><span id="LC2" class="line">nmake</span><span id="LC3" class="line">nmake install</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>以上將會安裝銅鎖的頭文件、library 文件和銅鎖二進製程序。如果需要在獨立的 build 目錄中編譯銅鎖以保證源代碼倉庫的整潔，則可以：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">cd tongsuo-build</span><span id="LC2" class="line">/path/to/Tongsuo/source/config --prefix=/path/to/dest</span><span id="LC3" class="line">make</span><span id="LC4" class="line">make install</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>目前銅鎖支持的操作系統有：各種 Linux 發行版、macOS、Android、iOS 和 Windows。在這些操作系統上，還需要事先準備好對應的環境：</p><ul><li>make</li><li>Perl 5，以及 Text::Template 模塊</li><li>C 編譯器</li><li>C 庫</li></ul><p>銅鎖對第三方庫的依賴很少，但是目前依然對 Perl 依賴較大。</p><p>如果希望執行自動化測試用例，則需：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">make test</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>在安裝的時候，可以選擇只安裝 library 文件：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">make install_runtime_libs</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>如果還需要安裝頭文件以便於基於銅鎖開發應用程序，則可以：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">make install_dev</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>也可以只安裝銅鎖二進製程序和其依賴的銅鎖 library 文件：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">make install_programs</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>銅鎖的 Configure 腳本提供了大量的用於開關各種特性的選項。一般來講，使用<code>enable-xxx</code>做為對某個特性的開啓，而使用<code>no-xxx</code>來關閉某個特性。例如，<code>enable-ntls</code>即開啓 TLCP，而<code>no-rsa</code>則是不編譯 RSA 算法。</p><h1><a id="user-content-文檔" class="anchor" href="https://gitee.com/babassl/Tongsuo#%E6%96%87%E6%A1%A3"></a>文檔</h1><p>銅鎖的相關文檔組織在 <a href="https://gitee.com/link?target=https%3A%2F%2Fyuque.com%2Ftsdoc">銅鎖文檔網站</a> 上。</p><h1><a id="user-content-交流羣" class="anchor" href="https://gitee.com/babassl/Tongsuo#%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>交流羣</h1><p>銅鎖使用釘釘羣進行用戶答疑和交流，歡迎掃碼入羣（也可直接搜索羣號：44810299）：
<img src="https://github.com/Tongsuo-Project/Tongsuo/blob/master/tongsuo-dingtalk.jpg" width="50%" height="50%" referrerpolicy="no-referrer"></p><h1><a id="user-content-報告安全缺陷" class="anchor" href="https://gitee.com/babassl/Tongsuo#%E6%8A%A5%E5%91%8A%E5%AE%89%E5%85%A8%E7%BC%BA%E9%99%B7"></a>報告安全缺陷</h1><p>銅鎖目前使用螞蟻集團的威脅蒐集系統，請訪問如下地址進行安全缺陷的報告：</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fsecurity.alipay.com%2F">https://security.alipay.com/</a></li></ul><p>注意：對於非安全相關的 Bug，請使用 GitHub 的 Issues 進行提交。</p>]]>
            </description>
            <pubDate>Sun, 10 Dec 2023 01:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/babassl/Tongsuo</guid>
            <link>https://gitee.com/babassl/Tongsuo</link>
        </item>
    </channel>
</rss>
