<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 25 Feb 2024 15:29:18 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[基於 Rust 開發的終端應用 Warp 發佈 Linux 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Warp 是一個基於 Rust 開發的現代化終端應用，內置 AI 功能，支持 CPU 加速。</p><p>此前 Warp 僅面向 Mac 平台提供，近日其開發團隊終於<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.warp.dev%2Fblog%2Fwarp-for-linux" target="_blank">發佈</a></u>了 Linux 版本，用戶可在大多數主流 Linux 發行版上安裝 Warp，包括 Ubuntu、Fedora、Arch Linux 或 Red Hat，目前提供的安裝包格式包括：</p><ul><li><strong>.deb (apt)</strong></li><li><strong>.rpm (yum/dnf/zypper)</strong></li><li><strong>.pkg.tar.zst (pacman)</strong></li><li><strong>.AppImage</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4de6b7dfa97856c11c9134895a8dd615060.png" referrerpolicy="no-referrer"></p><p><strong>Warp for Linux 特性</strong></p><ul><li><p>基於 Rust 編寫，所有圖形渲染都直接在 GPU 上完成，性能極佳</p></li><li><p>支持 zsh、bash 和 fish 等 shell</p></li><li><p>擁有現代化的編輯特性，比如鼠標支持、自動完成、語法高亮和多光標支持</p></li><li><p>Warp AI 可以幫助開發者查找忘記的命令、調試錯誤或通過自然語言轉換為命令行</p></li><li><p>Warp Drive 可以將終端變得協作化，開發者可以將重要的命令保存為可重用的工作流，並與團隊成員共享</p></li></ul><hr><p>Warp 團隊介紹了開發 Linux 版本的一些技術挑戰。由於 Linux 上的 GPU API 與 macOS 上的 Metal API 有很大區別，因此 Warp 團隊使用了開源的 Rust 庫來實現跨平台渲染，例如 wgpu、winit 和 cosmic-text。<strong>除了平台特定的抽象之外，Linux 版本的 Warp 與 Mac 版本共享了大約 98% 的代碼</strong>。</p><p>值得一提的是，為了更好地支持跨平台抽象，Warp 團隊還擴展了其內部基於 Rust 的 UI 框架，並計劃在未來開源該框架。</p><p>現在，Warp 已經支持 macOS 和 Linux 兩個主流平台。Warp 團隊正在積極開發 Windows 版本，預計將在今年晚些時候發佈。下載地址：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapp.warp.dev%2Fget_warp%3Flinux%3Dtrue%26auto_download%3Dfalse" target="_blank">https://app.warp.dev/get_warp</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-606dd90d1e674b566bbb400477a9e8f3704.png" referrerpolicy="no-referrer"></p><hr><p><strong>延伸閲讀：<u><em><a href="https://www.oschina.net/news/276588/zed-is-now-open-source" target="news">Rust 編寫的 Zed 編輯器正式開源</a></em></u></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 25 Feb 2024 11:09:37 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280197/warp-for-linux</guid>
            <link>https://www.oschina.net/news/280197/warp-for-linux</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Wubuntu：披着 Windows 11 外衣的 Ubuntu]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>眾所周知，Ubuntu 是最受歡迎的 Linux 發行版之一。而微軟擁抱 Linux 之後，Windows 成為了最好的 Linux 發行版（不是）。如果將兩者結合，會碰撞出怎樣的火花？</p><p><strong>Wubuntu，又稱 "Windows Ubuntu"</strong>，是基於 Ubuntu 開發的操作系統，其最具特色之處在於<strong>完全復刻了 Windows 的所有外觀和功能</strong>，而且運行時不需要具備 TPM、安全啓動或任何其他硬件要求。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-b78011bce450db4cf20d1bb7cc559cd4cb6.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wubuntu.org%2F" target="_blank">https://www.wubuntu.org/</a></u></em></p></blockquote><p><span>此外，Wubuntu</span>&nbsp;通過集成 Wine 提供了與 Windows 應用的兼容性，開發者稱 Wubuntu 支持運行 Windows 的 .exe 和 .msi&nbsp;程序，以及支持 Android 應用。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bc1f4a6dcc383b64786c013151ada03e885.png" referrerpolicy="no-referrer"></p><p>Wubuntu 使用的技術棧：</p><p><img src="https://oscimg.oschina.net/oscnet/up-d127229369e54b269f10365f1fad568a5d1.png" referrerpolicy="no-referrer"></p><p>Wubuntu 運行效果：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2e20ee135339d10eb33a0777b818ad6c9f1.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ffec60452f4b93085c10c897e93761e16df.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-62e9f8b8a805f7ed3d4598c1d5c957a3119.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-1725fe7868e691dfed08e9814c6661a523e.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-61332db8d1390d860514df218a3d8a55444.png" referrerpolicy="no-referrer"></p><p>這界面不能説和 Windows 11 一模一樣，只能説完全一致，微軟法務部看了真的不會律師函警告嗎？</p><p>此外，根據官網的信息，Wubuntu 提供免費版和專業版，其中專業版需要付費購買密鑰才可使用，價格為 35 美元。但官方沒有介紹兩者的功能差異。</p><p>Wubuntu 下載地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wubuntu.org%2Findex.php%2Fget%2Fwubuntu" target="_blank">https://www.wubuntu.org/index.php/get/wubuntu</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 24 Feb 2024 10:07:14 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280083/wubuntu-windows-ubuntu</guid>
            <link>https://www.oschina.net/news/280083/wubuntu-windows-ubuntu</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[為什麼 Chromebook 鍵盤採用小寫字母？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Chromebook 鍵盤上的所有按鍵都是小寫字母。自 2010 年推出第一款 Chromebook 原型機 CR-48 以來，他們就一直如此。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fdbc3ca95eb510cf632ffad2f3b12b6bf02.png" referrerpolicy="no-referrer"></p><p>谷歌最近<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fchromebooks%2Fchromebooks-lowercase-keyboard%2F" target="_blank">解釋</a></u>了他們對「全小寫鍵盤」的設計思路。當時參與早期 Chromebook 設計的 ChromeOS 團隊高級主管 Alexander Kuscher 認為可以對按鍵進行精簡，從而打造一款易於使用、對用戶友好的鍵盤。</p><p>Chromebook 團隊高級產品經理 Donny Reynolds 提出：</p><blockquote><p>我們已經習慣了鍵盤上的大寫字母，但如果你進入一個文本開始編寫文檔，並開始在傳統鍵盤上鍵入，按鍵就會與屏幕上顯示的不一致，對吧？你按下大寫'D'鍵，但出現的卻是小寫'd'。</p></blockquote><p>因此，他們決定不再為 Chromebook 鍵盤印上大寫字母——確保用戶「所見即所得」。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f381533dbaf1652c58fb82ffd2f52aa40f7.png" referrerpolicy="no-referrer"></p><p>其實當時許多手機和平板電腦已經配備了簡化的現代鍵盤——Android 手機在 2008 年首次亮相時就採用了小寫鍵盤。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e678bff4959ef28477371fd4d648545eed9.png" referrerpolicy="no-referrer"></p><p><em>早在 2008 年初代 G1 推出時，Android 就開啓了小寫鍵盤革命</em>。</p><p>因此 Donny Reynolds 表示：「當我們開始製造 Chromebook 時，我們自問‘計算機如何才能與眾不同，而且沒有幾十年來的包袱？看起來更友好是我們計算機設計的一個重要組成部分，我認為小寫鍵盤確實已經成為幾乎自己的標誌性品牌，以幫助實現這一目標。」</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 24 Feb 2024 04:45:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280052/chromebooks-lowercase-keyboard</guid>
            <link>https://www.oschina.net/news/280052/chromebooks-lowercase-keyboard</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Databend 開源週報第 132 期]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-42f77d1f307b752e9544a0efaded2715eae.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend" target="_blank">Databend</a> 是一款現代雲數倉。專為彈性和高效設計，為您的大規模分析需求保駕護航。自由且開源。即刻體驗雲服務：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapp.databend.cn" target="_blank">https://app.databend.cn</a> 。</p></blockquote><h2>What's On In Databend</h2><p>探索 Databend 本週新進展，遇到更貼近你心意的 Databend 。</p><h3>提供對 <code>CREATE [ OR REPLACE ]</code> 的全面支持</h3><p>Databend 現已提供對 <code>CREATE [ OR REPLACE ]</code> 語法糖的全面支持，以覆蓋潛在的 <code>DROP IF EXISTS ...</code> + <code>CREATE ...</code> 用例。</p><p>目前支持該語法糖的對象包括：<code>DATABASE</code>、<code>TABLE</code>、<code>VIEW</code>、<code>AGGREGATING INDEX</code>、<code>STREAM</code>、<code>CONNECTION</code>、<code>FUNCTION</code>、<code>FILE FORMAT</code>、<code>MASKING POLICY</code> 等。</p><p>如果您想了解更多信息，歡迎聯繫 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatabend.cn%2Fcontact-us%2F" target="_blank">Databend 團隊</a>，或查看下面列出的資源。</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend%2Fissues%2F14299" target="_blank">Issue #14299 | tracking: CREATE OR REPLACE</a></li></ul><h2>Code Corner</h2><p>一起來探索 Databend 和周邊生態中的代碼片段或項目。</p><h3>利用 Databend Cloud 進行查詢剖析</h3><p>Databend Cloud 提供可視化分析工具以簡化對複雜查詢的剖析和理解。</p><p>該剖析工具可以跟蹤每個步驟的性能，從 TableScan 持續時間到 HashJoin 的詳細信息，並監控數據外溢情況。幫助您輕鬆分析查詢成本和時間，進行針對性優化。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fc41fb6d19013fb622f80bea9d8bcac3ac8.png" alt="" referrerpolicy="no-referrer"></p><p>Databend 團隊也充分利用該工具評估代碼變更對查詢執行的影響。例如 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend%2Fpull%2F14561" target="_blank">PR #14561 | feat: use materialized cte for standard stream</a> 。</p><h2>Highlights</h2><p>以下是一些值得注意的事件，也許您可以找到感興趣的內容。</p><ul><li>支持 JSON 運算符 <code>#-</code> 。</li><li>在標準流中使用物化公用表表達式（Materialized CTE），以避免重複掃描。</li><li>閲讀文檔 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.databend.com%2Fguides%2Fdata-management%2F" target="_blank">Docs | Data Management</a> 瞭解如何利用 Databend 管理、恢復和保護您的數據。</li></ul><h2>What's Up Next</h2><p>我們始終對前沿技術和創新理念持開放態度，歡迎您加入社區，為 Databend 注入活力。</p><h3>支持多表插入</h3><p>Databend 計劃支持多表插入以允許使用一條語句有條件地或無條件地插入多個表。</p><p>多表插入語句可以減少執行多個條件插入所需的表掃描和 SQL 。主要適用於數據倉庫中的 ETL 過程，支持並行化和/或將非關係型數據轉換為關係型格式。</p><pre><code class="language-sql">-- Unconditional multi-table insert
INSERT [ OVERWRITE ] ALL
  intoClause [ ... ]
&lt;subquery&gt;

-- Conditional multi-table insert
INSERT [ OVERWRITE ] { FIRST | ALL }
  { WHEN &lt;condition&gt; THEN intoClause [ ... ] }
  [ ... ]
  [ ELSE intoClause ]
&lt;subquery&gt;
</code></pre><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend%2Fissues%2F14565" target="_blank">Issue #14565 | Feature: Multi-table Inserts support</a></p><p>如果你對這個主題感興趣，可以嘗試解決其中的部分問題或者參與討論和 PR review 。或者，你可以點擊 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.databend.rs%2Fi-m-feeling-lucky" target="_blank">https://link.databend.rs/i-m-feeling-lucky</a> 來挑選一個隨機問題，祝好運！</p><h2>Changelog</h2><p>前往查看 Databend 每日構建的變更日誌，以瞭解開發的最新動態。</p><p>地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend%2Freleases" target="_blank">https://github.com/datafuselabs/databend/releases</a></p><h2>Contributors</h2><p>非常感謝貢獻者們在本週的卓越工作。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c21d62bccf01220d44b5608d571b364bb7e.png" alt="" referrerpolicy="no-referrer"></p><h2>Connect With Us</h2><p>Databend 是一款開源、彈性、低成本，基於對象存儲也可以做實時分析的新式數倉。期待您的關注，一起探索雲原生數倉解決方案，打造新一代開源 Data Cloud。</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatabend.rs" target="_blank">Databend Website</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend%2Fdiscussions" target="_blank">GitHub Discussions</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FDatafuse_Labs" target="_blank">Twitter</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.databend.rs%2Fjoin-slack" target="_blank">Slack Channel</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 24 Feb 2024 04:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5489811/blog/11044054</guid>
            <link>https://my.oschina.net/u/5489811/blog/11044054</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024 年，只有搞顏色的 P 站真正關心網站性能]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年，大家覺得一個網站 JS 文件的平均大小應該是多少？1MB、5MB、10MB，還是更加大呢？</p><p>近年來，層出不窮的現代化前端技術讓人眼花繚亂，再加上終端設備的配置越來越高，許多網站似乎不用再過分擔心性能問題 —— 常常打開網站就要下載超過 10M 的&nbsp;<span>JS 文件。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25992e8199a790e84d4276053e0858e1b77.png" referrerpolicy="no-referrer"></p><p>知名開源開發者 Nikita Prokopov 對常見網站的 JS 文件大小進行了統計（未壓縮），結果有點令人出乎意料。</p><hr><h3><strong><span style="background-color:#e67e22">以靜態頁面為主的網站</span></strong></h3><ul><li><h4>Wikipedia, 0.2&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1421231d12c5140f4dc29b93285f2916686.png" referrerpolicy="no-referrer"></p><ul><li><h4>Linear, 3&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e8a9b91df6faa5480f2103efd9cd244aa66.png" referrerpolicy="no-referrer"></p><ul><li><h4>Zoom, 6&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-63b072146754bdd245d2af6dcb63dc79c3e.png" referrerpolicy="no-referrer"></p><ul><li><h4>Vercel, 6&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-158a201b80b904688e2a4f9590f8345b4df.png" referrerpolicy="no-referrer"></p><ul><li><h4>Gitlab,<span style="background-color:#f1c40f"> 13&nbsp;MB</span></h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3de67d966870abe2b064d536d3f770d66bc.png" referrerpolicy="no-referrer"></p><ul><li><h4>Medium, 3&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a132d36ae636b6435528e8d174ad233f7d2.png" referrerpolicy="no-referrer"></p><ul><li><h4>Quora, 4.5&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3a6c4a73ff80a50c4052aa7faeced43118b.png" referrerpolicy="no-referrer"></p><ul><li><h4>Pinterest, <span style="background-color:#f1c40f">10&nbsp;MB</span></h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bb825579fd8f6d787be8051e5b32e081fed.png" referrerpolicy="no-referrer"></p><hr><h3><strong><span style="background-color:#e67e22">以搜索功能為主的網站</span></strong></h3><ul><li><h4>StackOverflow, 3.5&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-860ef367515f1ea0ae55c567ed403a1a9c4.png" referrerpolicy="no-referrer"></p><ul><li><h4>NPM, 4&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e55316c24ebe2e2a885a576106ac801e0b9.png" referrerpolicy="no-referrer"></p><ul><li><h4>Airbnb, 7&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a59cfa95b748bb2888d93b3b647a63ca416.png" referrerpolicy="no-referrer"></p><ul><li><h4>Booking.com, <span style="background-color:#f1c40f">12&nbsp;MB</span></h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fee82c93858ef67b723612d9e1ae53314ed.png" referrerpolicy="no-referrer"></p><ul><li><h4>Google, 9&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d677500f815f8156922beb9938670463a68.png" referrerpolicy="no-referrer"></p><h3><span style="background-color:#e67e22">具有簡單交互的單應用網站</span></h3><ul><li><h4>Google Translate, 2.5&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-31a83dfa4eba4b19f6010f5479ce06fc03b.png" referrerpolicy="no-referrer"></p><ul><li><h4>ChatGPT, 7&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-76109ab4826fd1e649be9e2d303e44be5ff.png" referrerpolicy="no-referrer"></p><h3><span style="background-color:#e67e22">視頻/多媒體類網站</span></h3><ul><li><h4>Loom, 7&nbsp;MB</h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-35a3913d214fb0b4ee6edc2929f9cec5b77.png" referrerpolicy="no-referrer"></p><ul><li><h4>YouTube, <span style="background-color:#f1c40f">12&nbsp;MB</span></h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-11c1827cfb0fcf18a4d1ab929ce533a8d42.png" referrerpolicy="no-referrer"></p><ul><li><h4>Pornhub, <span style="background-color:#16a085">&nbsp;1.4&nbsp;MB</span></h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6531a939e4e613a4503e6bec46e4e5eb0eb.png" referrerpolicy="no-referrer"></p><p>目前看下來，維基百科網站的 JS 文件最小，僅有 0.2MB。Pornhub 次之，為 1.4MB。</p><p>但這倆在下面這個網站前面都是弟弟——</p><ul><li><h4><strong>jQuery, 0.1 MB</strong></h4></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a30ca6a8e2eb8cbc214df1411e42772b4c4.png" referrerpolicy="no-referrer"></p><hr><p>最後看看本站：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8c7490be3117d1e5730f1bb2d6ab1bb8e77.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 09:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279994/js-bloat-2024</guid>
            <link>https://www.oschina.net/news/279994/js-bloat-2024</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Oracle 致力解決 Java 虛擬線程「Pinning」問題]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>虛擬線程在 2023 年 9 月發佈的 JDK 21 中正式成為一項穩定功能。該功能在 Java 生態系統中反響極佳，但仍存在一些痛點。Oracle 日前在&nbsp;Inside Java 網站上詳細<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finside.java%2F2024%2F02%2F21%2Fquality-heads-up%2F" target="_blank">介紹</a>了虛擬線程的「Pinning」問題。</p><p>最常見的兩種情況是：(a) 虛擬線程在 synchronized method 中駐留（如執行 socket I/O）；(b) <span style="color:#333333">虛擬線程阻塞進入&nbsp;synchronized method</span>，因為對象的相關監視器被另一個線程持有。</p><p>在這兩種情況下，載體或本地線程都不會被釋放去做其他工作。因此可能會影響性能和可擴展性，並可能<span style="color:#333333">在某些情況下</span>導致飢餓和死鎖。官方最近發佈的一個<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finside.java%2F2024%2F02%2F17%2Fvirtual-threads-next-steps%2F" target="_blank">Virtual Threads Next Steps</a>&nbsp;視頻中則更詳細地解釋了其中的原因，並討論了一些潛在的解決方案。</p><p><img height="196" src="https://oscimg.oschina.net/oscnet/up-6a2e93ce6802a570c1704258c9a589e998e.png" width="500" referrerpolicy="no-referrer"></p><p>項目團隊正在努力解決這些問題。Java Project Loom 的新早期訪問版本<span style="color:#4e4242">引入了對對象監視器實現的更改</span><span style="color:#333333">，但不適用這兩種常見情況。因此 </span><span style="color:#4e4242">Loom&nbsp;</span><span style="color:#333333">團隊正在尋求用戶的幫助，以測試這些更新的對象監控器在使用虛擬線程的代碼和大量同步的庫中的可靠性和性能。可通過&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmail.openjdk.org%2Fpipermail%2Floom-dev%2F" target="_blank">Loom 郵件列表</a>&nbsp;<span style="color:#333333">報告或反饋問題。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 06:47:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279954/java-virtual-threads-pinning-issue</guid>
            <link>https://www.oschina.net/news/279954/java-virtual-threads-pinning-issue</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Koordinator v1.4 正式發佈！為用戶帶來更多的計算負載類型和更靈活的資源管理機制]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h3_1"></span><h3>背景</h3><p style="text-align:justify">Koordinator 作為一個積極發展的開源項目，自 2022 年 4 月發佈 v0.1.0 版本以來，經歷了多次迭代，持續為 Kubernetes 生態系統帶來創新和增強。項目的核心是提供混部工作負載編排、混部資源調度、混部資源隔離和混部性能調優的綜合解決方案，幫助用戶優化容器性能，並提升集羣資源使用效率。</p><p style="text-align:justify">在過去的版本迭代中，Koordinator 社區不斷壯大，已經得到了包括阿里巴巴、螞蟻科技、Intel、小米、小紅書、愛奇藝、360、有贊、趣玩、美亞柏科、PITS 等知名企業工程師的積極參與和貢獻。每一個版本都是在社區共同努力下推進的，反映了項目在實際生產環境中解決問題的能力。</p><p style="text-align:justify"><strong>今天我們很高興的向大家宣佈，Koordinator v1.4.0 版本正式發佈。</strong>在本次發佈中，Koordinator 引入了 Kubernetes 與 YARN 負載混部、NUMA 拓撲對齊策略、CPU 歸一化和冷內存上報等新特性，同時重點增強了彈性配額管理、宿主機非容器化應用的 QoS 管理、重調度防護策略等領域的功能。這些新增和改進點旨在更好地支持企業級 Kubernetes 集羣環境，特別是對於複雜和多樣化的應用場景。</p><p style="text-align:justify">v1.4.0 版本的發佈，將為用戶帶來更多的計算負載類型支持和更靈活的資源管理機制，我們期待這些改進能夠幫助用戶應對更多企業資源管理挑戰。在 v1.4.0 版本中，共有 11 位新加入的開發者參與到了 Koordinator 社區的建設，他們是&nbsp;<em>@shaloulcy，@baowj-678，@zqzten，@tan90github，@pheianox，@zxh326，@qinfustu，@ikaven1024，@peiqiaoWang，@bogo-y，@xujihui1985</em>，感謝期間各位社區同學的積極參與和貢獻，也感謝所有同學在社區的持續投入。</p><span id="OSC_h3_2"></span><h3>版本功能特性解讀</h3><span id="OSC_h4_3"></span><h4>1. 支持 K8s 與 YARN 混部</h4><p style="text-align:justify">Koordinator 已經支持了 K8s 生態內的在離線混部，然而在 K8s 生態外，仍有相當數量的大數據任務運行在傳統的 Hadoop YARN 之上。YARN 作為發展多年的大數據生態下的資源管理系統，承載了包括 MapReduce、Spark、Flink 以及 Presto 等在內的多種計算引擎。</p><p style="text-align:justify">Koordinator 社區會同來自阿里雲、小紅書、螞蟻金服的開發者們共同啓動了 Hadoop YARN 與 K8s 混部項目 Koordinator YARN Copilot，支持將 Hadoop NodeManager 運行在 kubernetes 集羣中，充分發揮不同類型負載錯峯複用的技術價值。Koordinator YARN Copilot 具備以下特點：</p><ul><li><strong>面向開源生態</strong></li></ul><p style="text-align:justify">基於 Hadoop YARN 開源版本，不涉及對 YARN 的侵入式改造；</p><ul><li><strong>統一資源優先級和 QoS 策略</strong></li></ul><p style="text-align:justify">YARN NM 使用 Koordinator 的 Batch 優先級資源，遵循 Koordinator QoS 管理策略；</p><ul><li><strong>節點級別的資源共享</strong></li></ul><p style="text-align:justify">Koordinator 提供的混部資源，既可被 K8s Pod 使用，也可被 YARN task 使用，不同類型的離線應用可運行在同一節點。</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-ac0aa93eb176110201a885bb0d474c31_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">關於 Koordinator YARN Copilot 的詳細設計，以及在小紅書生產環境的使用情況，請參考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttp%253A%2F%2Fmp.weixin.qq.com%2Fs%253Fspm%253Da2c6h.13046898.publish-article.4.5bb96ffaCJHZTt%2526__biz%253DMzUzNzYxNjAzMg%253D%253D%2526mid%253D2247559704%2526idx%253D1%2526sn%253D3aed8968e50c85f7af7d7e79387b9365%2526chksm%253Dfae7e1d7cd9068c10df63fa4cc9362ee259bcb9c5a4f7d68439d6f9779bb31492b072142582e%2526scene%253D21%2523wechat_redirect" target="_blank">往期文章：《Koordinator 助力雲原生應用性能提升：小紅書混部技術實踐》</a>以及社區官方文檔<strong>[1]</strong>。</p><span id="OSC_h4_4"></span><h4>2. 引入 NUMA 拓撲對齊策略</h4><p style="text-align:justify">運行在 Kubernetes 集羣中的工作負載日益多樣化。尤其是在機器學習等領域，對於高性能計算資源的需求持續上升。在這些領域中，不僅需要大量 CPU 資源，還經常需要 GPU 和 RDMA 等其他高速計算資源配合使用；並且，為了獲得最佳的性能，這些資源往往需要在同一個 NUMA 節點，甚至同一個 PCIE 中。</p><p style="text-align:justify">Kubernetes 的 Kubelet 提供了 Topology Manager 來管理資源分配的 NUMA 拓撲，試圖在 Kubelet 的 Admission 階段從節點層面對齊多種資源的拓撲。然而，節點組件沒有調度器的全局視角以及為 Pod 選擇節點的時機，可能導致 Pod 被調度到無法滿足拓撲對齊策略的節點上，從而導致 Pod 由於 Topology Affinity 錯誤無法啓動。</p><p style="text-align:justify">為瞭解決這一問題，Koordinator 將 NUMA 拓撲選擇和對齊的時機放在中心調度器中，從集羣級別優化資源之間的 NUMA 拓撲。在本次發佈的版本中，Koordinator 將 CPU 資源（包含 Batch 資源）的 NUMA 感知調度和 GPU 設備的 NUMA 感知調度作為 alpha 功能支持，整套 NUMA 感知調度快速演進中。</p><p style="text-align:justify">Koordinator 支持用戶通過節點的 Label 配置節點上多種資源的 NUMA 拓撲對齊策略，可配置策略如下：</p><ul><li>None 是默認策略，不執行任何拓撲對齊。</li><li>BestEffort 表示節點不嚴格按照 NUMA 拓撲對齊來分配資源。只要節點的剩餘總量滿足 Pods 的需求，調度器總是可以將這樣的節點分配給 Pods。</li><li>Restricted 表示節點嚴格按照 NUMA 拓撲對齊來分配資源，即調度器在分配多個資源時必須只選擇相同的一個或多個 NUMA 節點，否則不應使用該節點；可以使用多個 NUMA 節點。例如，如果一個 Pod 請求 33C，並且每個 NUMA 節點有 32C，那麼它可以被分配使用兩個 NUMA 節點。如果這個 Pod 還需要請求 GPU/RDMA，那麼它需要位於與 CPU 相同的 NUMA 節點上。</li><li>SingleNUMANode 與 Restricted 類似，也是嚴格按照 NUMA 拓撲對齊，但與 Restricted 不同的是，Restricted 允許使用多個 NUMA 節點，而 SingleNUMANode 只允許使用一個 NUMA 節點。</li></ul><p style="text-align:justify">舉例，我們可以為 node-0 設置策略 SingleNUMANode：</p><pre><code>apiVersion: v1
kind: Node
metadata:
  labels:
    node.koordinator.sh/numa-topology-policy: "SingleNUMANode"
  name: node-0
spec:
  ...</code></pre><p style="text-align:justify">在生產環境中，用戶可能已經開啓了 Kubelet 的拓撲對齊策略，這個策略會由 koordlet 更新到 NodeResourceTopologyCRD 對象中的 TopologyPolicies 字段。當 Kubelet 的策略和用戶在 Node 上設置的策略相沖突時，以 Kubelet 策略為準。Koordinator 調度器基本採用與 Kubelet Topology Manager 相同的 NUMA 對齊策略語義，Kubelet 策略 SingleNUMANodePodLevel 和 SingleNUMANodeContainerLevel 被映射為 SingleNUMANode。</p><p style="text-align:justify">在為節點配置好 NUMA 對齊策略的前提下，調度器可以為每個 Pod 選出許多個符合條件的 NUMA Node 分配結果。Koordinator 當前支持 NodeNUMAResource 插件配置 CPU 和內存資源的 NUMA Node 分配結果打分策略，包括 LeastAllocated 和 MostAllocated，默認為 LeastAllocated 策略，資源支持配置權重。調度器最終將選擇得分最高的 NUMA Node 分配結果。如下例，我們配置 NUMA Node 分配結果打分策略為 MostAllocated：</p><pre><code>apiVersion: kubescheduler.config.k8s.io/v1beta2
kind: KubeSchedulerConfiguration
profiles:
  - pluginConfig:
      - name: NodeNUMAResource
        args:
          apiVersion: kubescheduler.config.k8s.io/v1beta2
          kind: NodeNUMAResourceArgs
          scoringStrategy:  # Here configure Node level scoring strategy
            type: MostAllocated
            resources:
              - name: cpu
                weight: 1
              - name: memory
                weight: 1
              - name: "kubernetes.io/batch-cpu"
                weight: 1
              - name: "kubernetes.io/batch-memory"
                weight: 1
          numaScoringStrategy: # Here configure NUMA-Node level scoring strategy
            type: MostAllocated
            resources:
              - name: cpu
                weight: 1
              - name: memory
                weight: 1
              - name: "kubernetes.io/batch-cpu"
                weight: 1
              - name: "kubernetes.io/batch-memory"
                weight: 1</code></pre><span id="OSC_h4_5"></span><h4>3. ElasticQuota 再進化</h4><p style="text-align:justify">為了充分地利用集羣資源、降低管控系統成本，用戶常常將多個租戶的負載部署在一個集羣中。在集羣資源有限的情況下，不同租戶之間必然會發生資源爭搶。有的租戶的負載可能一直被滿足，而有的租戶的負載一直無法得到執行。這就產生對公平性的訴求。配額機制是非常自然地保障租戶間公平性的方式，給每個租戶一個配額，租戶可以使用配額內的資源，超過配額的任務將不被調度和執行。然而，簡單的配額管理無法滿足租戶對雲的彈性期待。用戶希望除了配額之內的資源請求可以被滿足外，配額之外的資源請求也可以按需地被滿足。</p><p style="text-align:justify">在之前的版本中，Koordinator 複用了上游 ElasticQuota 的協議，允許租戶設置 Min 表達其一定要滿足的資源訴求，允許設置 Max 限制其最大可以使用的資源和表達在集羣資源不足的情況下對集羣剩餘資源的使用權重。另外，Koordinator 觀察到，一些租戶可能通過 Min 申請了配額，但是實際的任務申請可能並沒有充分利用該配額。由此，為了更近一步地提高資源利用率，Koordinator 允許租戶間借用/歸還資源。</p><p style="text-align:justify">除了提供彈性的配額機制滿足租戶按需訴求外，Koordinator 在 ElasticQuota 上增加註解將其組織成樹的結構，方便用戶表達樹形的組織架構。</p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-0f15360828d04b31ebe10218c08a8758_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">上圖是使用了 Koordinator 彈性配額的集羣中常見的 Quota 結構樹。Root Quota 是連接配額與集羣中實際資源之間的橋樑。在之前的設計中，Root Quota 只在調度器邏輯中存在，在本次發佈中，我們將 Root Quota 也通過 CRD 的形式暴露給用戶，用戶可以通過 koordinator-root-quota 這個 ElasticQuota CRD 查看 Root Quota 信息。</p><p style="text-align:justify"><strong>3.1 引入 Multi QuotaTree</strong></p><p style="text-align:justify">大型集羣中的節點的形態是多樣的，例如雲廠商提供的 ECS VM 會有不同的架構，常見的是 amd64 和 arm64，相同架構又會有不同種類的機型，而且一般會把節點按可用區劃分。不同類型的節點放到同一個 Quota Tree 中管理時，其特有的屬性將丟失，當用戶希望精細化管理機器的特有屬性時，當前的 ElasticQuota 顯得不夠精確。為了滿足用戶靈活的資源管理或資源隔離訴求，Koordinator 支持用戶將集羣中的資源劃分為多份，每一份由一個 Quota Tree 來管理，如下圖所示：</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-e673d71606d710f3a447f0e504527d43_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">同時，為了幫助用戶簡化管理複雜性，Koordinator 在 v1.4.0 中，引入了 ElasticQuotaProfile 機制，用戶可以通過 nodeSelector 快速的將節點關聯到不同的 QuotaTree 中，如下實例所示：</p><pre><code>apiVersion: quota.koordinator.sh/v1alpha1
kind: ElasticQuotaProfile
metadata:
  labels:
    kubernetes.io/arch: amd64
  name: amd64-profile
  namespace: kube-system
spec:
  nodeSelector:
    matchLabels:
      kubernetes.io/arch: amd64 // 挑選 amd64 節點
  quotaName: amd64-root-quota   // 匹配的 root quota 名稱
---
apiVersion: quota.koordinator.sh/v1alpha1
kind: ElasticQuotaProfile
metadata:
  labels:
    kubernetes.io/arch: arm64   
  name: arm64-profile
  namespace: kube-system
spec:
  nodeSelector:
    matchLabels:
      kubernetes.io/arch: arm64  // 挑選 arm64 節點
  quotaName: arm64-root-quota    // 匹配的 root quota 名稱</code></pre><p style="text-align:justify">關聯好 QuotaTree 之後，用戶在每一個 QuotaTree 中與之前的 ElasticQuota 用法一致。當用戶提交 Pod 到對應的 Quota 時，當前仍然需要用戶完成 Pod NodeAffinity 的管理，以確保 Pod 運行在正確的節點上。未來，我們會增加一個特性幫助用戶自動管理 Quota 到 Node 的映射關係。</p><p style="text-align:justify"><strong>3.2 支持 non-preemptible</strong></p><p style="text-align:justify">Koordinator ElasticQuota 支持把 ElasticQuota 中 min 未使用的部分共享給其他 ElasticQuota 使用從而提高資源利用效率，但當資源緊張時，會通過搶佔機制把借用配額的 Pod 搶佔驅逐走拿回資源。</p><p style="text-align:justify">在實際生產環境中，有一些在線服務如果從其他 ElasticQuota 中借用了這部分額度，後續又發生了搶佔，是可能影響服務質量的。這類工作負載實質上是不能被搶佔的。</p><p style="text-align:justify">為了實現這個機制，Koordinator v1.4.0 引入了新的 API，用戶只需要在 Pod 上聲明 quota.scheduling.koordinator.sh/preemptible: false 表示這個 Pod 不可以被搶佔。</p><p style="text-align:justify">調度器調度時發現 Pod 聲明瞭不可搶佔，那麼此類 Pod 的可用配額的上限不能超過 min，所以這裏也需要注意的是，啓用該能力時，一個 ElasticQuota 的 min 需要設置的合理，並且集羣內有相應的資源保障。</p><p style="text-align:justify">這個特性不會破壞原有的行為。</p><pre><code>apiVersion: v1
kind: Pod
metadata:
  name: pod-example
  namespace: default
  labels:
    quota.scheduling.koordinator.sh/name: "quota-example"
    quota.scheduling.koordinator.sh/preemptible: false
spec:
...</code></pre><p style="text-align:justify"><strong>3.3 其它改進</strong></p><p style="text-align:justify">1. Koordinator Scheduler 過去支持跨 Namespace 使用同一個 ElasticQuota 對象，但有一些場景下，希望只被一個或者多個有限的 Namespace 可以共享同一個對象，為了支持這個場景，用戶可以在 ElasticQuota 上增加 annotation quota.scheduling.koordinator.sh/namespaces，對應的值為一個 JSON 字符串數組。</p><p style="text-align:justify">2. 性能優化：過去的實現中，當 ElasticQuota 發生變化時，ElasticQuota 插件會重建整棵 Quota 樹，在 v1.4.0 版本中做了優化。</p><p style="text-align:justify">3. 支持忽略 Overhead：當 Pod 使用一些安全容器時，一般是在 Pod 中聲明 Overhead 表示安全容器自身的資源開銷，但這部分資源成本最終是否歸於終端用戶承擔取決於資源售賣策略。當期望不用用戶承擔這部分成本時，那麼就要求 ElaticQuota 忽略 overhead。在 v1.4.0 版本中，可以開啓 featureGate ElasticQuotaIgnorePodOverhead 啓用該功能。</p><span id="OSC_h4_6"></span><h4>4. CPU 歸一化</h4><p style="text-align:justify">隨着 Kubernetes 集羣中節點硬件的多樣化，不同架構和代數的 CPU 之間性能差異顯著。因此，即使 Pod 的 CPU 請求相同，實際獲得的計算能力也可能大不相同，這可能導致資源浪費或應用性能下降。CPU 歸一化的目標是通過標準化節點上可分配 CPU 的性能，來保證每個 CPU 單元在 Kubernetes 中提供的計算能力在異構節點間保持一致。</p><p style="text-align:justify">為瞭解決該問題，Koordinator 在 v1.4.0 版本中實現了一套支持 CPU 歸一化機制，根據節點的資源放大策略，調整節點上可分配的 CPU 資源數量，使得集羣中每個可分配的 CPU 通過縮放實現算力的基本一致。整體的架構如下圖所示：</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-b0e335f164d52e400107a5294a2a7dbb_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">CPU 歸一化分為兩個步驟：</p><p style="text-align:justify">1. CPU 性能評估，計算不同 CPU 的性能基準，可以參考工業級性能評測標準 SPEC CPU<strong>[2]</strong>，這部分 Koordinator 項目未提供；</p><p style="text-align:justify">2. 配置 CPU 歸一化係數到 Koordinator，調度系統基於歸一化係數來調度資源，這部分 Koordinator 提供。</p><p style="text-align:justify">將 CPU 歸一化比例信息配置到 koord-manager 的 slo-controller-config 中，配置示例如下：</p><pre><code>apiVersion: v1
kind: ConfigMap
metadata:
  name: slo-controller-config
  namespace: koordinator-system
data:
  cpu-normalization-config: |
    {
      "enable": true,
      "ratioModel": {
         "Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz": {
           "baseRatio": 1.29,
           "hyperThreadEnabledRatio": 0.82,
           "turboEnabledRatio": 1.52,
           "hyperThreadTurboEnabledRatio": 1.0
         },
         "Intel Xeon Platinum 8369B CPU @ 2.90GHz": {
           "baseRatio": 1.69,
           "hyperThreadEnabledRatio": 1.06,
           "turboEnabledRatio": 1.91,
           "hyperThreadTurboEnabledRatio": 1.20
         }
      }
    }
  # ...</code></pre><p style="text-align:justify">對於配置了 CPU 歸一化的節點，Koordinator 通過 Webhook 攔截 Kubelet 對 Node.Status.Allocatable 的更新以實現 CPU 資源的縮放，最終在節點上呈現出歸一後的 CPU 資源可分配量。</p><span id="OSC_h4_7"></span><h4>5. 改進的重調度防護策略</h4><p style="text-align:justify">Pod 遷移是一個複雜的過程，涉及審計、資源分配、應用啓動等步驟，並且與應用升級、擴展場景以及集羣管理員的資源操作和維護操作混合在一起。因此，如果同時有大量 Pods 正在進行遷移，可能會對系統的穩定性產生影響。此外，如果同一工作負載的許多 Pods 同時被遷移，也會影響應用的穩定性。此外，如果同時遷移多個作業中的 Pods，可能會造成驚羣效應。因此，我們希望順序處理每個作業中的 Pods。</p><p style="text-align:justify">Koordinator 在之前提供的 PodMigrationJob 功能中已經提供了一些防護策略來解決上述問題。在 v1.4.0 版本中，Koordinator 將之前的防護策略增強為仲裁機制。當有大量的 PodMigrationJob 可以被執行時，由仲裁器通過排序和篩選，來決定哪些 PodMigrationJob 可以得到執行。</p><p style="text-align:justify">排序過程如下：</p><ul><li>根據遷移開始時間與當前時間的間隔進行排序，間隔越小，排名越高。</li><li>根據 PodMigrationJob 的 Pod 優先級進行排序，優先級越低，排名越高。</li><li>按照工作負載分散 Jobs，使得同一作業中的 PodMigrationJobs 靠近。</li><li>如果作業中已有 Pods 正在遷移，則該 PodMigrationJob 的排名更高。</li></ul><p style="text-align:justify">篩選過程如下：</p><ul><li>根據工作負載、節點、命名空間等對 PodMigrationJob 進行分組和篩選。</li><li>檢查每個工作負載中正在運行狀態的 PodMigrationJob 數量，達到一定閾值的將被排除。</li><li>檢查每個工作負載中不可用副本的數量是否超出了最大不可用副本數，超出的將被排除。</li><li>檢查目標 Pod 所在節點上正在遷移的 Pod 數量是否超過單個節點的最大遷移量，超出的將被排除。</li></ul><span id="OSC_h4_8"></span><h4>6. 冷內存上報</h4><p style="text-align:justify">為提升系統性能，內核一般儘可能不讓應用程序請求的頁面緩存空閒，而是儘可能將其分配給應用程序。雖然內核分配了這些內存，但是應用可能不再訪問，這些內存被稱為冷內存。</p><p style="text-align:justify">Koordinator 在 1.4 版本中引入冷內存上報功能，主要為未來冷內存回收功能打下基礎。冷內存回收主要用於應對兩個場景：</p><ul><li>對於標準的 Kubernetes 集羣，當節點內存水位過高時，突發的內存請求容器導致系統直接內存回收，操作系統的直接內存回收觸發時會影響已經運行容器的性能，如果回收不及時極端場景可能觸發整機 oom。保持節點內存資源的相對空閒，對提升運行時穩定性至關重要。</li><li>在混部場景中，高優先級應用程序請求但未使用的資源可以被低優先級應用程序回收利用。對內存而言，操作系統未回收的內存，是不能被 Koordinator 調度系統看到的。為了提高混部資源效率，回收容器未使用的內存頁面可以提高整機的資源利用效率。</li></ul><p style="text-align:justify">Koordlet 在 Collector Plugins 中添加了一個冷頁面回收器，用於讀取由 kidled（Anolis 內核）、kstaled（Google）或 DAMON（Amazon）導出的 cgroup 文件 memory.idle_stat。該文件包含頁面緩存中的冷頁面信息，並存在於 memory 的每個層次結構中。目前 koordlet 已經對接了 kidled 冷頁面收集器並提供了其他冷頁面收集器接口。</p><p style="text-align:justify">在收集冷頁面信息後，冷頁面回收器將把收集到的指標（例如節點、Pod 和容器的熱頁面使用量和冷頁面大小）存到 metriccache 中，最後該數據會被上報到 NodeMetric CRD 中。</p><p style="text-align:justify">用戶可以通過 NodeMetric 啓用冷內存回收和配置冷內存收集策略，當前提供了 usageWithHotPageCache、usageWithoutPageCache 和 usageWithPageCache 三種策略，更多的細節詳見社區設計文檔<strong>[3]</strong>。</p><span id="OSC_h4_9"></span><h4>7. 非容器化應用的 QoS 管理</h4><p style="text-align:justify">在企業容器化過程中，除了已經運行在 K8s 上的應用，可能還會存在一些非容器化的應用運行在主機上。為了更好兼容企業在容器化過程這一過渡態，Koordinator 開發了節點資源預留機制，可以在尚未容器化的應用預留資源並賦予特定的 QoS 特性。與 Kubelet 提供的資源預留配置不同，Koordinator 主要目標是解決這些非容器化應用與容器化應用運行時的 QoS 問題，整體的方案如下圖所示：</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-5edba11d4ab8bac0dcef2bc16d12d4f6_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">目前，應用程序需要按照規範將進程啓動到對應的 cgroup 中，Koordinator 未實現自動的 cgroup 搬遷工具。針對宿主機非容器化應用，支持 QoS 如下：</p><ul><li><strong>LS (Latency Sensitive)</strong><ul><li>CPU QoS(Group Identity)：應用按照規範將進程運行在 cgroup 的 cpu 子系統中，koordlet 根據 CPU QoS 的配置 resource-qos-config 為其設置 Group Identity 參數；</li><li>CPUSet Allocation：應用按照規範將進程運行在 cgroup 的 cpu 子系統中，koordlet 將為其設置 cpu share pool 中的所有 CPU 核心。</li></ul></li><li><strong>BE (Best-effort)</strong><ul><li>CPU QoS(Group Identity)：應用按照規範將進程運行在 cgroup 的 cpu 子系統中，koordlet 根據 CPU QoS 的配置為其設置 Group Identity 參數。</li></ul></li></ul><p style="text-align:justify">關於宿主機應用 QoS 管理的詳細設計，可以參考社區文檔<strong>[4]</strong>，後續我們將陸續增加其他 QoS 策略對宿主機應用的支持。</p><span id="OSC_h4_10"></span><h4>8. 其它特性</h4><p style="text-align:justify">除了上述新特性和功能增強外，Koordinator 在 v1.4.0 版本還做了一些如下的 bugfix 和優化：</p><ul><li><strong>RequiredCPUBindPolicy</strong></li></ul><p style="text-align:justify">精細化 CPU 編排支持 Required 的 CPU 綁定策略配置，表示嚴格按照指定的 CPU 綁定策略分配 CPU，否則調度失敗。</p><ul><li><strong>CICD</strong></li></ul><p style="text-align:justify">Koordinator 社區在 v1.4.0 提供了一套 e2e 測試的 Pipeline；提供了 ARM64 鏡像。</p><ul><li><strong>Batch 資源計算策略優化</strong></li></ul><p style="text-align:justify">支持了 maxUsageRequest 的計算策略，用於更保守地超賣高優資源；優化了節點上短時間大量 Pod 啓停時，Batch allocatable 被低估的問題；完善了對 hostApplication、thirdparty allocatable、dangling pod used 等特殊情況的考慮。</p><ul><li><strong>其它</strong></li></ul><p style="text-align:justify">利用 libpfm4&amp;perf group 優化 CPI 採集、SystemResourceCollector 支持自定義的過期時間配置、BE Pod 支持根據 evictByAllocatable 策略計算 CPU 滿足度、Koordlet CPUSetAllocator 修復了對於 LS 和 None Qos 的 Pod 的過濾邏輯、RDT 資源控制支持獲得 sandbox 容器的 task IDs 等。</p><p style="text-align:justify">通過 v1.4.0 Release<strong>[5]</strong>頁面，可以看到更多包含在 v1.4.0 版本的新增功能。</p><span id="OSC_h3_11"></span><h3>未來計劃</h3><p style="text-align:justify">在接下來的版本中，Koordinator 目前規劃了以下功能：</p><ul><li><strong>Core Scheduling</strong></li></ul><p style="text-align:justify">在運行時側，Koordinator 開始探索下一代 CPU QoS 能力，通過利用 Linux Core Scheduling 等內核機制，增強的物理核維度的資源隔離，降低混部的安全性風險，相關工作詳見 Issue #1728<strong>[6]</strong>。</p><ul><li><strong>設備聯合分配</strong></li></ul><p style="text-align:justify">在 AI 大模型分佈式訓練場景中，不同機器 GPU 之間通常需要通過高性能網卡相互通信，且 GPU 和高性能網卡就近分配的時候性能更好。Koordinator 正在推進支持多種異構資源的聯合分配，目前已經在協議上和調度器分配邏輯上支持聯合分配；單機側關於網卡資源的上報邏輯正在探索中。</p><p style="text-align:justify">更多信息，敬請關注 Milestone v1.5.0<strong>[7]</strong>。</p><span id="OSC_h3_12"></span><h3>結語</h3><p style="text-align:justify">最後，我們十分感謝 Koordinator 社區的所有貢獻者和用戶，是您們的積極參與和寶貴意見讓 Koordinator 不斷進步。我們期待您繼續提供反饋，並歡迎新的貢獻者加入我們的行列。</p><p style="text-align:justify"><strong>相關鏈接：</strong></p><p style="text-align:justify">[1] 社區官方文檔</p><p style="text-align:justify"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fkoordinator.sh%2Fzh-Hans%2Fdocs%2Fnext%2Fdesigns%2Fkoordinator-yarn%2F%253Fspm%253Da2c6h.13046898.publish-article.5.5bb96ffaCJHZTt" target="_blank">https://koordinator.sh/zh-Hans/docs/next/designs/koordinator-yarn/</a></em></u></p><p style="text-align:justify">[2] SPEC CPU</p><p style="text-align:justify"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fwww.spec.org%2Fcpu2017%2F%253Fspm%253Da2c6h.13046898.publish-article.6.5bb96ffaCJHZTt" target="_blank">https://www.spec.org/cpu2017/</a></em></u></p><p style="text-align:justify">[3] 設計文檔</p><p style="text-align:justify"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Fkoordinator-sh%2Fkoordinator%2Fblob%2Fmain%2Fdocs%2Fproposals%2Fkoordlet%2F20230728-support-cold-memory-compute.md%253Fspm%253Da2c6h.13046898.publish-article.7.5bb96ffaCJHZTt%2526file%253D20230728-support-cold-memory-compute.md" target="_blank">https://github.com/koordinator-sh/koordinator/blob/main/docs/proposals/koordlet/20230728-support-cold-memory-compute.md</a></em></u></p><p style="text-align:justify">[4] 社區文檔</p><p style="text-align:justify"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fkoordinator.sh%2Fzh-Hans%2Fdocs%2Fnext%2Fuser-manuals%2Fhost-application-qos%2F%253Fspm%253Da2c6h.13046898.publish-article.8.5bb96ffaCJHZTt" target="_blank">https://koordinator.sh/zh-Hans/docs/next/user-manuals/host-application-qos/</a></em></u></p><p style="text-align:justify">[5] v1.4.0 Release</p><p style="text-align:justify"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Fkoordinator-sh%2Fkoordinator%2Freleases%2Ftag%2Fv1.4.0%253Fspm%253Da2c6h.13046898.publish-article.9.5bb96ffaCJHZTt%2526file%253Dv1.4.0" target="_blank">https://github.com/koordinator-sh/koordinator/releases/tag/v1.4.0</a></em></u></p><p style="text-align:justify">[6] Issue #1728</p><p style="text-align:justify"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Fkoordinator-sh%2Fkoordinator%2Fissues%2F1728%253Fspm%253Da2c6h.13046898.publish-article.10.5bb96ffaCJHZTt" target="_blank">https://github.com/koordinator-sh/koordinator/issues/1728</a></em></u></p><p style="text-align:justify">[7] Milestone v1.5.0</p><p style="text-align:justify"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Fkoordinator-sh%2Fkoordinator%2Fmilestone%2F14%253Fspm%253Da2c6h.13046898.publish-article.11.5bb96ffaCJHZTt" target="_blank">https://github.com/koordinator-sh/koordinator/milestone/14</a></em></u></p><p style="text-align:justify"><em>作者：喬普</em></p><p style="text-align:justify"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1423263%3Futm_content%3Dg_1000390303" target="_blank">原文鏈接</a></strong></p><p style="text-align:justify"><strong>本文為阿里雲原創內容，未經允許不得轉載。</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 06:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/yunqi/blog/11044520</guid>
            <link>https://my.oschina.net/yunqi/blog/11044520</link>
            <author>
                <![CDATA[阿里云云棲號]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | 目前的人工智能技術連貓的智能水平都沒達到]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.22</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/279713/google-gemma-open-models" target="_blank">谷歌發佈輕量級開源大語言模型 Gemma</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Gemma 是一款輕量級、先進的開源模型，供開發者和研究人員用於 AI 構建。Gemma 模型家族包括 2B（20 億參數）和 7B（70 億參數）兩種尺寸，能夠在不同的設備類型上運行，包括筆記本電腦、桌面電腦、IoT 設備、移動設備和雲端。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><h3><a href="https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released" target="_blank">夜鶯監控 V7 第一個 beta 版本</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">夜鶯項目從 2024 開始開發 V7 版本，重點做體驗優化，V7 和 V6 版本兼容可以平滑升級<span style="background-color:#ffffff; color:#333333">（V6 升級到 V7 只需要替換一下二進制重啓即可，如果是容器部署，只需要更新鏡像並重啓）</span>，第一個 beta 的優化項包括：</p><ul><li>全站暗黑主題</li><li>優化邊緣機房機器失聯告警的實現邏輯，真正做到邊緣機房告警自閉環</li><li>優化內置大盤、內置告警規則的列表頁面 UI</li><li>全局回調地址頁面展示優化，增加詳盡的文檔提示信息</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="20240221141801" src="https://download.flashcat.cloud/ulric/20240221141801.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img height="554" src="https://oscimg.oschina.net/oscnet/up-14e1acb77ab8633d225b3117ebbc7dc7920.png" width="1522" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博<span>&nbsp;</span></span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FO1MdFaqZm" target="_blank">高飛</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-a2ff0599a45c140a6bf468a7d85524102fa.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博<span>&nbsp;</span></span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1856404484%2FO1JFSAEg0" target="_blank">鳳凰網科技</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-da11d19579f9cc14d57a12c12f4479f067a.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-33430582a60711cf56a923991e1fef04da9.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p>GitHub Trending</p><p><img src="https://oscimg.oschina.net/oscnet/up-291d0213846cc3efbd09b526da6bac5ae29.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 03:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279923</guid>
            <link>https://www.oschina.net/news/279923</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 迴應 7 萬億美元半導體計劃：所需投資遠超想象]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在英偉達發佈了強勁的 2024 財年第四季度財報之後的幾小時，英特爾首席執行官 Pat Gelsinger 和 OpenAI 首席執行官 Sam Altman 在加利福尼亞州聖何塞的一個會議中心展開了一場對話，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapnews.com%2Farticle%2Fintel-openai-nvidia-chips-boom-dbf20077caafc9b33870f9f6d32d3794" target="_blank">暢談</a>半導體在 AI 時代塑造社會所扮演的角色。</span></p><p><span style="color:#000000"><img alt="" height="375" src="https://oscimg.oschina.net/oscnet/up-67bd113ff9160357624584468c53d04258a.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">在活動中，Gelsinger 詢問了 Altman 有關最近報道的計劃從中東地區籌集高達 7 萬億美元的資金，以支持 OpenAI 的一項半導體計劃，並與英偉達展開競爭的傳聞。對此，Altman 則反駁稱，這種匿名人士未經證實的説法比比皆是，「我的主要工作不是到處修正這些錯誤的文章」。</span></p><p><span style="color:#000000">但 Altman 同時也承認，AI 的發展需要大量的資金。「事實是，我們認為世界將需要更多的 AI 計算（芯片）。這將需要全球範圍內大量的投入，超出我們的想象。我們現在還沒有一個具體數字。」</span></p><p><span style="color:#000000">他還強調了過去一年加快人工智能發展的重要性。他認為人工智能的進步將為人類帶來更美好的未來，不過奧特曼也承認，在前進的過程中會有不利的一面。"我們正在走向這樣一個世界：人工智能生成的內容將多於人類生成的內容。這將不僅僅是一個 good story，而是一個 net good story。"</span></p><p><span style="color:#000000">此外，Altman 重申了在 AI 領域進行監管的必要性，強調了政府在制定框架以降低潛在風險方面的關鍵作用。</span></p><p><span style="color:#000000">Gelsinger 預測，</span><span style="background-color:#ffffff; color:#000000">到 2030 年，英特爾將成為全球第二大代工企業，僅次於台積電。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279911/intel-openai-chips</guid>
            <link>https://www.oschina.net/news/279911/intel-openai-chips</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Apache ECharts 5.5.0 引入服務端渲染的新利器：1KB 的客戶端輕量運行時]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Apache ECharts 5.5.0 版本已於 2024.2.18 正式發佈。</p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fecharts%2Freleases%2Ftag%2F5.5.0" target="_blank">https://github.com/apache/echarts/releases/tag/5.5.0</a></u></em></p><p><strong>主要變化</strong></p><ul><li><p>增強了代碼的 ESM 識別，對&nbsp;Node.js&nbsp;環境開發更加友好；</p></li><li><p>為服務端渲染方案提供了一個 gzip 後僅 1KB 的輕量運行時，極大地降低了加載時間；</p></li><li><p>為數據下鑽支持了過渡動畫，開發者可以方便地實現多級數據的動畫效果；</p></li><li><p>為餅圖和極座標系圖表增加了更多配置項，可以實現更豐富的樣式；</p></li><li><p>新增阿拉伯語和荷蘭語兩種語言的翻譯</p></li><li><p>……</p></li></ul><p>以下內容轉自：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIpGQS1GspyXzNe-u9F4B-A" target="_blank">https://mp.weixin.qq.com/s/IpGQS1GspyXzNe-u9F4B-A</a></u></em></p><hr><h2>增強的 ESM 支持</h2><p>為了讓開發者在測試和 Node.js 環境使用更方便，我們在這個版本中對 ESM 的識別問題進行了優化。</p><p>以前，ECharts 只在 npm（npm 包的 lib 目錄中）導出&nbsp;<code>*.esm</code>&nbsp;文件。雖然這在 bundlers 環境表現良好，但 Node.js 環境和一些基於 Node.js 的測試框架（如 vitest 和 jest）中的表現並不理想。</p><p>有了這個新功能，我們做了幾個改變以改善這個問題：</p><ul><li><p>在&nbsp;<code>package.json</code>&nbsp;中添加了&nbsp;<code>"type": "module"</code></p></li><li><p>在&nbsp;<code>package.json</code>&nbsp;中添加了&nbsp;<code>"exports": {...}</code></p></li><li><p>在子目錄中添加了一些只包含&nbsp;<code>"type": "commonjs"</code>&nbsp;的&nbsp;<code>package.json</code>&nbsp;文件</p></li></ul><p>這些改變意味着，像&nbsp;<code>echarts/core.js</code>&nbsp;這樣的文件現在可以在像純 Node.js、vitest、jest 和 create-react-app 這樣的環境中解析為 ESM。</p><p>我們還確保了這個新功能與各種環境兼容，包括運行時（Node.js/vitest/jest（create-react-app）/ssr/…）和打包器（webpack/rollup/vite/esbuild/…）。</p><p>我們非常期待這一新功能，並相信它將極大地改善開發者的體驗。</p><h2>服務端渲染 + 客戶端輕量運行時</h2><p>Apache ECharts 功能強大，相應地，包體積也比較大。我們在之前的版本中也做了各種努力來改進這一點。開發者可以使用 TreeShaking 按需加載部分代碼，以減少加載的代碼量。從 Apache ECharts 5.3 版本起，我們支持了零依賴的服務端 SVG 字符串渲染方案，並支持圖表的初始動畫。這樣，使用服務端渲染的結果作為首屏渲染的畫面，可以大大減少首屏加載時間。</p><p>服務端渲染雖然是一種很有效減少包體積的解決方案，但如果需要在客戶端實現一些交互，那麼不得不仍舊加載 echarts.js，這可能會增加更多的加載時間。對於一些對頁面加載速度要求較高的場景，這可能不是一個理想的選擇。</p><p><strong>在 5.5.0 版本中，我們新增了客戶端輕量運行時</strong>，客戶端無需加載完整 ECharts 即可實現部分交互。這樣，我們可以在服務端渲染圖表，然後在客戶端加載輕量運行時，實現一些常見的交互。這意味着，<strong>只需要加載&nbsp;4KB 的輕量運行時（gzip 後 1KB），即可實現帶初始動畫和部分常用交互形式的圖表</strong>。這一改進將極大地提升頁面加載速度，特別是對於移動端的體驗。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5c9857523986e92155d29f453c6307014c1.png" referrerpolicy="no-referrer"></p><p>以這個帶標題的餅圖為例，如果按客戶端僅打包餅圖和標題組件的方案，gzip 後需要 135KB；如果按服務端渲染的方案，渲染結果 SVG gzip 後 1 KB、客戶端運行時 gzip 後 1KB，僅為前者體積的 1.5%。交互方面，後者也可以做到初始動畫、鼠標移動到圖表元素後的高亮，並且獲取到點擊事件，能夠滿足大部分的常見交互需求。</p><p>如需使用客戶端輕量運行時方案，服務端代碼和之前一樣，但需要保證 ECharts 版本號在 5.5.0 以上。</p><pre><code>//&nbsp;服務端代碼
const&nbsp;echarts&nbsp;=&nbsp;require('echarts');

//&nbsp;在&nbsp;SSR&nbsp;模式下第一個參數不需要再傳入&nbsp;DOM&nbsp;對象
const&nbsp;chart&nbsp;=&nbsp;echarts.init(null,&nbsp;null,&nbsp;{
&nbsp;&nbsp;renderer:&nbsp;'svg',&nbsp;//&nbsp;必須使用&nbsp;SVG&nbsp;模式
&nbsp;&nbsp;ssr:&nbsp;true,&nbsp;//&nbsp;開啓&nbsp;SSR
&nbsp;&nbsp;width:&nbsp;400,&nbsp;//&nbsp;需要指明高和寬，如果是根據客戶端容器大小動態的，該值需要從客戶端得到
&nbsp;&nbsp;height:&nbsp;300
});

//&nbsp;像正常使用一樣&nbsp;setOption
chart.setOption({
&nbsp;&nbsp;//...
});

//&nbsp;輸出字符串
const&nbsp;svgStr&nbsp;=&nbsp;chart.renderToSVGString();

//&nbsp;調用&nbsp;dispose&nbsp;以釋放內存
chart.dispose();
chart&nbsp;=&nbsp;null;

//&nbsp;通過 HTTP Response 返回 svgStr 給前端或者緩存到本地（這裏以 Express.js 為例）：
res.writeHead(200,&nbsp;{
&nbsp;&nbsp;'Content-Type':&nbsp;'application/xml'
});
res.write(svgStr);
res.end();

</code></pre><p>客戶端將得到的 SVG 字符串添加到容器中，並綁定輕量運行時：</p><pre><code>&lt;div&nbsp;id="chart-container"&nbsp;style="width:800px;height:600px"&gt;&lt;/div&gt;

&lt;script&nbsp;src="https://cdn.jsdelivr.net/npm/echarts/ssr/client/dist/index.js"&gt;&lt;/script&gt;
&lt;script&gt;
const&nbsp;ssrClient&nbsp;=&nbsp;window['echarts-ssr-client'];

let&nbsp;isSeriesShown&nbsp;=&nbsp;{
&nbsp;&nbsp;a:&nbsp;true,
&nbsp;&nbsp;b:&nbsp;true
};

function&nbsp;updateChart(svgStr)&nbsp;{
&nbsp;&nbsp;const&nbsp;container&nbsp;=&nbsp;document.getElementById('chart-container');
&nbsp;&nbsp;container.innerHTML&nbsp;=&nbsp;svgStr;

&nbsp;&nbsp;//&nbsp;使用輕量運行時賦予圖表交互能力
&nbsp;&nbsp;ssrClient.hydrate(main,&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;on:&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;click:&nbsp;(params)&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(params.ssrType&nbsp;===&nbsp;'legend')&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;點擊圖例元素，請求服務器進行二次渲染
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;isSeriesShown[params.seriesName]&nbsp;=&nbsp;!isSeriesShown[params.seriesName];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fetch('...?series='&nbsp;+&nbsp;JSON.stringify(isSeriesShown))
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.then(res&nbsp;=&gt;&nbsp;res.text())
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.then(svgStr&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updateChart(svgStr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;});
}

//&nbsp;通過&nbsp;AJAX&nbsp;請求獲取服務端渲染的&nbsp;SVG&nbsp;字符串
fetch('...')
&nbsp;&nbsp;.then(res&nbsp;=&gt;&nbsp;res.text())
&nbsp;&nbsp;.then(svgStr&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;updateChart(svgStr);
&nbsp;&nbsp;});
&lt;/script&gt;
</code></pre><p>客戶端輕量運行時必須配合 SVG 形式的服務端渲染結果使用，支持以下交互：</p><ul><li><p>圖表初始動畫（實現原理：服務端渲染的 SVG 帶有 CSS 動畫）</p></li><li><p>高亮樣式（實現原理：服務端渲染的 SVG 帶有 CSS 動畫）</p></li><li><p>動態改變數據（實現原理：輕量運行時請求服務器進行二次渲染）</p></li><li><p>點擊圖例切換系列是否顯示（實現原理：輕量運行時請求服務器進行二次渲染）</p></li></ul><p>可以發現，這能夠滿足大部分的交互場景需求。如果需要更復雜的交互，則客戶端需要加載&nbsp;<code>echarts.js</code>&nbsp;實現完整功能。</p><p>完整的介紹請參見官網使用手冊的「應用篇 - 跨平台方案 - 服務端渲染」。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279907/echarts-5-5-0</guid>
            <link>https://www.oschina.net/news/279907/echarts-5-5-0</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[和 Gmail 基本 HTML 視圖説再見]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌已開始<u><a href="https://www.oschina.net/news/259383">停止支持 Gmail </a><a href="https://www.oschina.net/news/259383">基本 HTML 視圖</a></u>。自 2024 年 2 月起，Gmail 會自動將用戶從基本 HTML 視圖轉換為標準視圖。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0cdd4e28b49bf3c37718b40baee96da1d75.png" referrerpolicy="no-referrer"></p><p><em>基本 HTML 視圖允許用戶以簡陋的方式查看電子郵件，但對所有的瀏覽器提供了最大的兼容性。</em></p><p>Gmail 更新了其<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fmail%2Fanswer%2F15049%3Fhl%3Dzh-Hans" target="_blank">支持頁面</a>，以反映 Gmail 將在截止日期後自動切換到標準視圖。不僅如此，有用戶在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D37558372" target="_blank">Hacker News</a>上發帖稱，他們收到了一封來自 Google 的郵件，表明該功能已經結束。</p><blockquote><p>"我們寫信通知您，從 2024 年 1 月初開始，桌面網頁和移動網頁的 Gmail Basic HTML 視圖將被禁用。Gmail Basic HTML 視圖是 Gmail 的舊版本，10 多年前就已被現代版本取代，不包含完整的 Gmail 功能。"</p></blockquote><p>即使在今天，當你嘗試訪問 HTML 版本時，Google 也會顯示一條信息，稱該版本是為"較慢的連接速度和傳統瀏覽器"設計的，並要求你確認是否不想使用標準版本。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cca03ff735c3d625769511865800215a87d.png" referrerpolicy="no-referrer"></p><p>HTML 版本缺少很多功能，如聊天、拼寫檢查、搜索過濾器、鍵盤快捷鍵和豐富的格式。但在連接性較差的地區或只想瀏覽電子郵件而不想使用任何額外功能的情況下，HTML 版還是很有用的。目前還不清楚 Google 是否計劃添加低連接模式。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279900/goodbye-html-gmail</guid>
            <link>https://www.oschina.net/news/279900/goodbye-html-gmail</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[記一次 Rust 內存泄漏排查之旅]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在某次持續壓測過程中，我們發現 GreptimeDB 的 Frontend 節點內存即使在請求量平穩的階段也在持續上漲，直至被 OOM kill。我們判斷 Frontend 應該是有內存泄漏了，於是開啓了排查內存泄漏之旅。</p><h2>Heap Profiling</h2><p>大型項目幾乎不可能只通過看代碼就能找到內存泄漏的地方。所以我們首先要對程序的內存用量做統計分析。幸運的是，GreptimeDB 使用的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjemalloc%2Fjemalloc%2Fwiki%2FUse-Case%253A-Heap-Profiling" target="_blank">jemalloc 自帶 heap profiling</a>，我們也<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb%2Fblob%2Fdevelop%2Fsrc%2Fcommon%2Fmem-prof%2FREADME.md" target="_blank">支持了導出 jemalloc 的 profile dump 文件</a>。於是我們在 GreptimeDB 的 Frontend 節點內存達到 300MB 和 800MB 時，分別 dump 出了其內存 profile 文件，再用 jemalloc 自帶的 <code>jeprof</code> 分析兩者內存差異（<code>--base</code> 參數），最後用火焰圖顯示出來：</p><p><img src="https://oscimg.oschina.net/oscnet/up-002154d38e6da2e50485895918972b1b8a1.png" alt="" referrerpolicy="no-referrer"></p><p>顯然圖片中間那一大長塊就是不斷增長的 500MB 內存佔用了。仔細觀察，居然有 thread 相關的 stack trace。難道是創建了太多線程？簡單用 <code>ps -T -p</code> 命令看了幾次 Frontend 節點的進程，線程數穩定在 84 個，而且都是預知的會創建的線程。所以「線程太多」這個原因可以排除。</p><p>再繼續往下看，我們發現了很多 Tokio runtime 相關的 stack trace，而 Tokio 的 task 泄漏也是常見的一種內存泄漏。這個時候我們就要祭出另一個神器：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftokio-rs%2Fconsole" target="_blank">Tokio-console</a>。</p><h2>Tokio Console</h2><p>Tokio Console 是 Tokio 官方的診斷工具，輸出結果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-1772a99dbc1b17d9b0ab49532e083a4234f.png" alt="" referrerpolicy="no-referrer"></p><p>我們看到居然有 5559 個正在運行的 task，且絕大多數都是 Idle 狀態！於是我們可以確定，內存泄漏發生在 Tokio 的 task 上。 現在問題就變成了：GreptimeDB 的代碼裏，哪裏 spawn 了那麼多的無法結束的 Tokio task？</p><p>從上圖的 "Location" 列我們可以看到 task 被 spawn 的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb%2Fblob%2Fdevelop%2Fsrc%2Fcommon%2Fruntime%2Fsrc%2Fruntime.rs%23L63" target="_blank">地方</a>：</p><pre><code class="language-rust">impl Runtime {
    /// Spawn a future and execute it in this thread pool
    ///
    /// Similar to Tokio::runtime::Runtime::spawn()
    pub fn spawn&lt;F&gt;(&amp;self, future: F) -&gt; JoinHandle&lt;F::Output&gt;
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        self.handle.spawn(future)
    }
}
</code></pre><p>接下來的任務是找到 GreptimeDB 裏所有調用這個方法的代碼。</p><h2><code>..Default::default()</code>！</h2><p>經過一番看代碼的仔細排查，我們終於定位到了 Tokio task 泄漏的地方，並在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb%2Fpull%2F1512" target="_blank">PR #1512</a> 中修復了這個泄漏。簡單地説，就是我們在某個會被經常創建的 struct 的構造方法中，spawn 了一個可以在後台持續運行的 Tokio task，卻未能及時回收它。對於資源管理來説，在構造方法中創建 task 本身並不是問題，只要在 <code>Drop</code> 中能夠順利終止這個 task 即可。而我們的內存泄漏就壞在忽視了這個約定。</p><p>這個構造方法同時在該 struct 的 <code>Default::default()</code> 方法當中被調用了，更增加了我們找到根因的難度。</p><p>Rust 有一個很方便的，可以用另一個 struct 來構造自己 struct 的方法，即 "<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fbook%2Fch05-01-defining-structs.html%23creating-instances-from-other-instances-with-struct-update-syntax" target="_blank">Struct Update Syntax</a>"。如果 struct 實現了 <code>Default</code>，我們可以簡單的在 struct 的 field 構造中使用 <code>..Default::default()</code>。如果 <code>Default::default()</code> 內部有 「side effect」（比如我們本次內存泄漏的原因——創建了一個後台運行的 Tokio task），一定要特別注意：struct 構造完成後，<code>Default</code> 創建出來的臨時 struct 就被丟棄了，一定要做好資源回收。</p><p>例如下面這個小例子：（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplay.rust-lang.org%2F%3Fversion%3Dstable%26mode%3Ddebug%26edition%3D2021%26gist%3Dc121ffd32d2ff0fa8e1241a62809bcef" target="_blank">Rust Playground</a>）</p><pre><code class="language-rust">struct A {
    i: i32,
}

impl Default for A {
    fn default() -&gt; Self {
        println!("called A::default()");
        A { i: 42 }
    }
}

#[derive(Default)]
struct B {
    a: A,
    i: i32,
}

impl B {
    fn new(a: A) -&gt; Self {
        B {
            a,
            // A::default() is called in B::default(), even though "a" is provided here.
            ..Default::default()
        }
    }
}

fn main() {
    let a = A { i: 1 };
    let b = B::new(a);
    println!("{}", b.a.i);
}
</code></pre><p>struct A 的 <code>default</code> 方法是會被調用的，打印出 <code>called A::default()</code>。</p><h2>總結</h2><ul><li>排查 Rust 程序的內存泄漏，我們可以用 jemalloc 的 heap profiling 導出 dump 文件；再生成火焰圖可直觀展現內存使用情況。</li><li>Tokio-console 可以方便地顯示出 Tokio runtime 的 task 運行情況；要特別注意不斷增長的 idle tasks。</li><li>儘量不要在常用 struct 的構造方法中留下有副作用的代碼。</li><li><code>Default</code> 只應該用於值類型 struct。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-3d33a6c61f7c37725020cbe267d0c2d0f01.jpg" alt="" referrerpolicy="no-referrer"></p><h3>關於 Greptime</h3><p>Greptime 格睿科技於 2022 年創立，目前正在完善和打造時序數據庫 GreptimeDB 和格睿雲 GreptimeCloud 這兩款產品。</p><p>GreptimeDB 是一款用 Rust 語言編寫的時序數據庫，具有分佈式、開源、雲原生、兼容性強等特點，幫助企業實時讀寫、處理和分析時序數據的同時，降低長期存儲的成本。</p><p>GreptimeCloud 基於開源的 GreptimeDB，為用戶提供全託管的 DBaaS，以及與可觀測性、物聯網等領域結合的應用產品。利用雲提供軟件和服務，可以達到快速的自助開通和交付，標準化的運維支持，和更好的資源彈性。GreptimeCloud 已正式開放內測，歡迎關注公眾號或官網瞭解最新動態！</p><p>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreptime.com%2F" target="_blank">https://greptime.com/</a></p><p>公眾號：GreptimeDB</p><p>GitHub: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb" target="_blank">https://github.com/GreptimeTeam/greptimedb</a></p><p>文檔：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.com%2F" target="_blank">https://docs.greptime.com/</a></p><p>Twitter: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FGreptime" target="_blank">https://twitter.com/Greptime</a></p><p>Slack: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreptime.com%2Fslack" target="_blank">https://greptime.com/slack</a></p><p>LinkedIn: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fgreptime%2F" target="_blank">https://www.linkedin.com/company/greptime/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6839317/blog/11044292</guid>
            <link>https://my.oschina.net/u/6839317/blog/11044292</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Stability AI 發佈 Stable Diffusion 3 早期預覽版]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>AI 創業公司 Stability AI <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fnews%2Fstable-diffusion-3" target="_blank">宣佈</a></u>其最新一代的文本圖像模型 Stable Diffusion 3 開放預覽，該版本目前僅限部分用戶參與測試，主要是為了在正式發佈前收集與性能和安全性相關的用戶反饋。感興趣的用戶可以申請加入等候名單。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3fa2fd390f1fbdd7808ee91a4ed1a0ef4fd.png" referrerpolicy="no-referrer"></p><p>Stable Diffusion 3 早期預覽版相比前代產品在圖片質量、多主題展示和文字展示方面有大幅提升。Stable Diffusion 3 模型的參數規模從 8 億，到 80 億不等，其架構組合了 diffusion transformer（擴散變換架構）和 flow matching（流匹配），技術報告將在晚些時候公佈。</p><p><img height="582" src="https://oscimg.oschina.net/oscnet/up-25784ed1b6a0b80ca5fc50b3c842456064f.png" width="3052" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-377f7b831888b11ab490f50cafe8931753d.png" referrerpolicy="no-referrer"></p><p>性能的具體提升內容包括：</p><ol><li>多主題提示處理能力： 新模型對於包含多個主題或元素的提示具有更好的理解和處理能力。這意味着用戶可以在一個提示中描述更復雜的場景，而模型能夠更準確地根據這些描述生成圖像。</li><li>圖像質量： Stable Diffusion 3 在生成的圖像質量上有顯著提高，包括更細膩的細節表現、更準確的顏色匹配以及更自然的光影處理。這些改進使得生成的圖像更加逼真，更能捕捉到用戶的創意意圖。</li><li>拼寫和文本處理能力： 這個版本在處理文本元素，尤其是在圖像中直接展現的文本（如標語、標籤等）時，有更好的拼寫能力和文本理解。這包括更準確地識別和渲染用戶提示中的文字，甚至是在複雜的視覺背景中。</li></ol><p>Stable Diffusion 3 的性能提升不僅基於其先進的擴散變換架構，還包括了以下關鍵的技術創新和改進：</p><ol><li>新型擴散變換器： Stable Diffusion 3 採用了一種新型的擴散變換技術，與 Sora 類似，這種新技術為模型提供了更強大的圖像生成能力。 Transformer 是一種深度學習模型，專門設計來逐步構建圖像的細節，從而生成高質量的視覺內容。</li><li>流匹配與其他改進： 模型還整合了流匹配技術和其他技術改進，進一步增強了生成圖像的質量和多樣性。流匹配技術有助於模型更好地理解和模擬圖像中的動態元素和結構，使得生成的圖像在視覺上更加連貫和自然。</li><li>利用 Transformer 的改進： Stable Diffusion 3 充分利用了 Transformer 技術的最新進展，這不僅使模型能夠進一步擴展其能力，還使其能夠接受多模態輸入。這意味着模型能夠處理更復雜和多樣化的數據類型，如結合文本和圖像的輸入，從而在理解和生成圖像內容方面提供更大的靈活性和精確度。</li></ol><p>加入等候名單：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fstablediffusion3" target="_blank">https://stability.ai/stablediffusion3</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:12:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279886/stable-diffusion-3-preview</guid>
            <link>https://www.oschina.net/news/279886/stable-diffusion-3-preview</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「未來產業劃定發展路線圖」出爐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>近日，工業和信息化部、科技部、交通運輸部、文化和旅遊部等部門</span><span>聯合印發</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMjM5OTUwMTc2OA%3D%3D%26mid%3D2650903280%26idx%3D1%26sn%3Db6edd0ce1c41aac431cd9f9a52eef8be%26chksm%3Dbccfb8578bb831412b6e96f801604afe81effbd68c11d7371507f00349b1b3accc4cc18e01b4%26scene%3D21%23wechat_redirect" target="_blank">《關於推動未來產業創新發展的實施意見》</a><span>，提出到 2025 年，未來產業技術創新、產業培育、安全治理等全面發展，部分領域達到國際先進水平，產業規模穩步提升；到 2027 年，未來產業綜合實力顯著提升，部分領域實現全球引領。</span></p><p>專家認為，《意見》充分把握全球科技創新和產業發展趨勢，前瞻部署了生物製造、量子信息、氫能、核能、基因和細胞技術等多個細分賽道，將全面支撐推進新型工業化，加快形成新質生產力。</p><p style="margin-left:0; margin-right:0"><strong><span>全面佈局新賽道</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>未來產業由前沿技術驅動，尚處於孕育萌發階段或產業化初期，是具有顯著戰略性、引領性、顛覆性和不確定性的前瞻性新興產業。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">當前，新一輪科技革命和產業變革加速演進，重大前沿技術、顛覆性技術持續湧現，科技創新和產業發展融合不斷加深，催生出元宇宙、人形機器人、腦機接口、量子信息等新產業發展方向。大力培育未來產業已成為引領科技進步、帶動產業升級、開闢新賽道、塑造新質生產力的戰略選擇。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">我國具備工業體系完整、產業規模龐大、應用場景豐富等綜合優勢，為未來產業發展提供了豐厚的土壤。各省（區、市）積極培育未來產業，北京、上海、江蘇、浙江等地出台了培育未來產業的政策文件。但我國未來產業發展也面臨系統謀劃不足、技術底座不牢等問題。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">針對這些問題，《意見》從技術創新、產品突破、企業培育、場景開拓、產業競爭力等方面提出到 2025 年和 2027 年的發展目標。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">賽迪研究院未來產業研究中心所長韓健介紹，到 2025 年要形成「一批+6 百」的目標體系，建設一批未來產業孵化器和先導區，突破百項前沿關鍵核心技術，形成百項標誌性產品，打造百家領軍企業，開拓百項典型應用場景，制定百項關鍵標準，培育百家專業服務機構，初步形成符合我國實際的未來產業發展模式。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">《意見》重在產業化落地。賽智產業研究院院長趙剛認為，《意見》提出以傳統產業的高端化升級和前沿技術的產業化落地為主線，力爭做到兩年「打基礎」，五年「大提升」，成為世界未來產業重要策源地。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">此外，《意見》還詳細規劃了六大方向超過 50 多個細分領域的未來產業發展，明確提出了下一代智能終端、信息服務產品、未來高端裝備三類標誌性產品發展路線。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">「設定未來產業發展目標既是我國推進新型工業化的自身現實需求，也是參與國際競爭的外部形勢要求。從自身需求看，是我國引領科技進步、帶動產業升級、培育新質生產力的戰略選擇；從外部需求看，是我國主動參與全球未來產業分工合作、深度融入全球創新網絡的必然選擇。」趙剛説。</p><p style="margin-left:0; margin-right:0"><strong><span>重點瞄準六大方向</span></strong></p><p><span>未來產業發展的核心是前沿技術創新突破。《意見》按照「技術創新—前瞻識別—成果轉化」的思路，提出面向未來製造、未來信息、未來材料、未來能源、未來空間、未來健康六大重點方向，實施國家科技重大項目和重大科技攻關，發揮國家實驗室、全國重點實驗室等創新載體作用，鼓勵龍頭企業牽頭成立創新聯合體，體系化推進關鍵核心技術攻關。</span></p><p>趙剛分析，與優勢產業、傳統產業、戰略性新興產業相比，未來產業有 3 個明顯特徵。未來產業技術創新不是漸進式微創新，而是前瞻性、顛覆性重大創新，例如未來信息產業中的通用人工智能和量子信息、未來健康產業中的基因工程、未來材料產業中的超導材料等技術創新；未來產業生產要素配置不是傳統要素線性疊加，而是現代要素相互融合和配置效率指數級提升，例如量子計算機能讓計算能力實現成千上萬倍增加；未來產業邊界不是界限清晰，而是呈現出不同產業跨界融合和智能化、綠色化等發展特徵，如智能製造、生物材料、人形機器人、腦機接口等。</p><p>對於這六大方向業內已有佈局。早在 2016 年，字節跳動公司就成立了人工智能實驗室，聚焦研究自然語言處理、機器學習、數據挖掘等方面。2023 年以來，字節跳動公司加碼人工智能應用研究，旗下產品不斷加入 AIGC（生成式人工智能）功能。比如，結合火山引擎智能創作雲的 AIGC 能力，火山引擎視頻雲在商品營銷、互動娛樂、在線教育、智能駕駛等場景引入數字人、虛擬直播間等，助力企業降本增效，提升用戶體驗。</p><p>「技術創新是經濟長期持續增長的不竭動力，發展未來產業是高質量發展的前瞻性戰略佈局。今天對未來產業 20% 的投入和佈局，將為以後帶來 80% 的收益，從而建立起我國經濟高質量發展的長效創新機制。」趙剛説。</p><p style="margin-left:0; margin-right:0"><strong><span>打造標誌性創新產品</span></strong></p><p><span>《意見》提出，打造人形機器人、腦機接口、超大規模新型智算中心、第三代互聯網等十大創新標誌性產品。</span></p><p>趙剛分析，當顛覆式技術創新呈現出技術性能成倍提升、產品化成本大幅降低、應用場景廣泛等特徵後，創新產品就形成規模經濟效應，具有巨大的市場前景。</p><p>當前，滿足這 3 個特徵的標誌性產品主要有兩類。一是通用人工智能產品。由於以 ChatGPT 為代表的通用人工智能技術取得重大進展，圍繞通用人工智能技術創新形成的智能產品，如生成式人工智能產品、AI 手機和個人計算機、人形機器人、高級別智能網聯汽車、智能裝備、智能雲服務、超大規模新型智算中心等智能產品和服務就具有較好前景。二是生物科技產品。由於細胞和基因工程等技術取得突破性進展，生物科技創新產品工程化能力加速提升，具有很好的市場前景，如基因編輯、合成生物等。其他一些前瞻性技術儘管在實驗室獲得了成功，但離大規模產品化和商業化還有很大差距，例如量子信息技術創新。</p><p>國際數據公司 IDC 預測，人工智能電腦在中國個人計算機市場中新機的裝配比例將快速攀升，2027 年有望達 85%，成為市場主流。聯想集團副總裁、中國區戰略及業務拓展副總裁阿不力克木·阿不力米提表示，人工智能電腦是自然語言交互的個人 AI 助理。在過去 40 年發展歷程中，聯想不斷推出變革用戶體驗的產品，未來還將和生態夥伴攜手實現人工智能電腦快速普及，讓 AI 惠及每一個人。</p><p>目前我國算力總規模排名全球第二位。但從結構看，通用算力佔了大半，高性能算力佔比有待提升。浪潮信息高級副總裁劉軍表示，高質量算力採用先進的計算架構，具備高算效、高能效、可持續、可獲得、可評估五大特徵。其中，高算效是實測性能與資源利用率雙重提升，是算力供需失衡、算力利用率低等矛盾的破解之道。而高能效是在最低碳排放前提下實現最大化算力輸出，確保能源利用最優解。</p><p>腦機接口作為十大標誌性產品之一，近年來在電極、算法、芯片等方面取得了重要進展。2023 年 9 月，中國信息通信研究院雲計算與大數據研究所牽頭在人工智能醫療器械創新合作平台成立腦機接口研究工作組。</p><p>中國信通院雲計算與大數據研究所副所長閔棟介紹，腦機接口可應用於醫療、娛樂、智能生活、教育等領域。其中，醫療領域是主要陣地。腦機接口與醫療結合展現出廣闊應用前景，為相關疾病診療和康復提供了全新手段。此外，腦機接口還可與虛擬現實、人機交互、人工智能等技術結合推動現有產業變革，如腦機接口應用於工業領域，可幫助人們通過意念操控機器人、無人車、工業產線等設備。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">未來產業潛在價值巨大，需要資本持續投入。趙剛建議，要推動製造業轉型升級基金、國家中小企業發展基金等加大投入，也可適時組建國家未來產業發展基金，並引導地方設立未來產業專項資金，發揮政府引導基金的引導性作用，吸引社會資本共同投資未來產業。同時，完善金融財稅支持政策。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 05:58:15 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279756</guid>
            <link>https://www.oschina.net/news/279756</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[夜鶯監控 V7 第一個 beta 版本來了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>夜鶯項目從 2024 開始開發 V7 版本，重點做體驗優化，V7 和 V6 版本兼容可以平滑升級<span style="background-color:#ffffff; color:#333333">（V6 升級到 V7 只需要替換一下二進制重啓即可，如果是容器部署，只需要更新鏡像並重啓）</span>，今天發佈第一個 beta，此 beta 版本的優化項包括：</p><ul><li>全站暗黑主題</li><li>優化邊緣機房機器失聯告警的實現邏輯，真正做到邊緣機房告警自閉環</li><li>優化內置大盤、內置告警規則的列表頁面 UI</li><li>全局回調地址頁面展示優化，增加詳盡的文檔提示信息</li></ul><p><span style="background-color:#ffffff; color:#333333">更多優化項正在開發中，V5、V6 用戶可以放心升級，V7 會是一個更好的版本。升級之前記得備份以防萬一。</span></p><h2>項目介紹</h2><p style="color:#333333; text-align:left">夜鶯監控是一款開源雲原生觀測分析工具，採用 All-in-One 的設計理念，集數據採集、可視化、監控告警、數據分析於一體，與雲原生生態緊密集成，提供開箱即用的企業級監控分析和告警能力。夜鶯於 2020 年 3 月 20 日，在 github 上發佈 v1 版本，已累計迭代 100 多個版本。</p><p style="color:#333333; text-align:left">夜鶯最初由滴滴開發和開源，並於 2022 年 5 月 11 日，捐贈予中國計算機學會開源發展委員會（CCF ODC），為 CCF ODC 成立後接受捐贈的第一個開源項目。夜鶯的核心研發團隊，也是 Open-Falcon 項目原核心研發人員，從 2014 年（Open-Falcon 是 2014 年開源）算起來，也有 10 年了，只為把監控這個事情做好。</p><h2>項目截圖</h2><p style="color:#333333; text-align:left"><img alt="20240221141801" src="https://download.flashcat.cloud/ulric/20240221141801.png" referrerpolicy="no-referrer"></p><p style="color:#333333; text-align:left"><img alt="20240221141817" src="https://download.flashcat.cloud/ulric/20240221141817.png" referrerpolicy="no-referrer"></p><h2>項目代碼</h2><ul><li>後端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank">💡 https://github.com/ccfos/nightingale</a></li><li>前端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fn9e%2Ffe" target="_blank">💡 https://github.com/n9e/fe</a></li></ul><p style="color:#333333; text-align:left">夜鶯項目已收穫 8000 多 github stars，1000 多 forks，100 多 contributors 參與其中，歡迎大家在<span>&nbsp;</span><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank"><strong>GitHub</strong></a></strong><span>&nbsp;</span>上關注夜鶯項目，及時獲取項目更新動態，有任何問題，也歡迎提交 issues，以及提交 pull requests，開源社區需要大家一起參與才能有蓬勃的生命力。</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 04:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</guid>
            <link>https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報：等到 Sora 開源了立刻推出屬於我們自己的大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.21</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/279326/linux-kernel-is-a-cna" target="_blank">2023 年度 Rust 調查報告</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">有 93% 的受訪者稱自己是 Rust 用戶，其中 49% 的人每天（或幾乎每天）都會使用 Rust，相較上一年小幅增加 2 個百分點。在沒有使用 Rust 的用戶中，31% 的人表示主要原因時使用 Rust 有難度；67% 的人表示他們還沒有機會優先學習 Rust，這也是最常見的原因。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-335afef97d65f03d34d0f08eb8831153557.png" width="500" referrerpolicy="no-referrer"></span></p><h3><a href="https://www.oschina.net/news/279389/dart-3-3-released" target="_blank">Go 1.22 正式發佈</a></h3><p>Go 1.22 中新增的優化之一是改進了虛擬化，允許靜態調度更多的接口方法調用。啓用 PGO 後，大多數程序的性能將提高 2% 至 14%。 此外，Go 運行時中的內存優化可將 CPU 性能提高 1-3%，同時還可將大多數 Go 程序的內存開銷減少約 1%。</p><p>新的 math/rand/v2 軟件包提供了更簡潔、更一致的應用程序接口，並使用了質量更高、速度更快的偽隨機生成算法。&nbsp;</p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-9fc6f45ad8365450e0980fe7fe1855a56c5.png" referrerpolicy="no-referrer"></p><p>- 微博 <u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6640496217%2FO1tM7BenZ" target="_blank">-赤犬龍之介-</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-d423a4b13075c233da7226ccd5235dc0a3e.png" referrerpolicy="no-referrer"></p><p>-&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2F8XMQgC7LlaK" target="_blank">21 世紀經濟報道</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-25f6c0a5f5becd775a0ad6bd1080893da87.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-bbc6216c930e22f859d514d8becc057daae.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p>Gitee 榜單：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5ab4f59bdf01add8c61aac9c617fa074d2c.png" referrerpolicy="no-referrer"></p><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:47:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279735</guid>
            <link>https://www.oschina.net/news/279735</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[數百位名人簽署公開信，呼籲制定反深度偽造立法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>數百名 AI 界人士簽署了一封<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">公開信</a>，呼籲嚴格監管 AI 生成的冒名頂替或深度偽造（Deepfake）內容。</p><p><img height="274" src="https://oscimg.oschina.net/oscnet/up-df56f62fff93b887bf1198aca4ccf4bcb5e.png" width="500" referrerpolicy="no-referrer"></p><p>公開信指出，"深度偽造"是指未經同意或嚴重誤導的人工智能生成的聲音、圖像或視頻，合理的人會誤以為是真實的。這不包括對圖像或聲音的輕微改動，也不包括容易識別為合成的無害娛樂或諷刺。</p><p>如今，深度偽造通常涉及性圖像、欺詐或政治虛假信息。由於人工智能發展迅速，使得深度偽造變得更加容易，因此我們需要為數字基礎設施的運行和完整性提供保障。「Deepfakes 對社會的威脅日益嚴重，政府必須在整個供應鏈中施加義務，以阻止 Deepfakes 的擴散。」</p><p>信中呼籲：</p><ul><li>將深度偽造的兒童性虐待材料（CSAM，又名兒童色情製品）完全定為刑事犯罪，無論所描繪的人物是真實的還是虛構的。</li><li>在任何情況下，如果有人制造或傳播有害的深度偽造品，都需要受到刑事處罰。</li><li>要求軟件開發商和分銷商防止其音頻和視頻產品被用於製造有害的深度偽造品，如果他們的預防措施不充分，就要承擔責任接受處罰。</li></ul><p>他們認為，如果設計得當，這些法律可以在不會造成過重負擔的同時，培育有社會責任感的企業。</p><p>這封信中較為知名的簽名者包括：</p><ul><li>Jaron Lanier</li><li>Frances Haugen</li><li>Stuart Russell</li><li>Andrew Yang</li><li>Marietje Schaake</li><li>Steven Pinker</li><li>Gary Marcus</li><li>Oren Etzioni</li><li>Genevieve smith</li><li>Yoshua Bengio</li><li>Dan Hendrycks</li><li>Tim Wu</li></ul><p>事實上，這也不是首次出現相關的呼籲。在本月早些時候正式提出之前，歐盟已就此類措施進行了多年辯論。外媒 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F21%2Fhundreds-of-ai-luminaries-sign-letter-calling-for-anti-deepfake-legislation%2F" target="_blank">TechCrunch</a> 指出，也許正是歐盟願意進行審議和落實，才激活了這些研究人員、創作者和管理人員的發言權。雖然此舉不一定能推動真正的立法，但它確實是業界專家們如何看待這一爭議問題的風向標。</p><p>更多詳情可查看此處：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">https://openletter.net/l/disrupting-deepfakes</a>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279733/disrupting-deepfakes</guid>
            <link>https://www.oschina.net/news/279733/disrupting-deepfakes</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[出門問問創始人李志飛點評谷歌開源大模型 Gemma：差點意思]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌在北京時間昨晚發佈了<u><a href="https://www.oschina.net/news/279713/google-gemma-open-models">開源大模型 Gemma</a></u>，對標 Meta 旗下 Llama 2。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><p>出門問問創始人李志飛發表文章點評，<strong>稱 Gemma 推出時間有點晚、開源力度不夠、未放下高貴的頭顱</strong>。</p><p>李志飛在文章中表示，相比於去年上半年就開源，現在可能要花數倍的努力進行模型的差異化以及推廣的投入，才有可能在眾多開源模型中脫穎而出。「面對 OpenAI 的強力競爭，只有殺敵一千、自損一千五。」</p><p>以下為李志飛全文：</p><blockquote><p>看到 Google 開源了小的語言模型 Gemma，直接狙擊 Llama 2，回顧去年 5 月對 Google 關於開源和競爭的看法，幾點思考如下：</p><p>1. 時間有點晚：相比於去年上半年就開源，現在可能要花數倍的努力進行模型的差異化以及推廣的投入，才有可能在眾多開源模型中脫穎而出。</p><p>2. 開源力度不夠：感覺這次開源還是被動防禦和略顯扭捏的應對之策，不是進攻。比如説，開個 7B 的模型實在是太小兒科了，一點殺傷力都沒有。應該直接開源一個超越市場上所有開源的至少 100B 的模型、1M 的超長上下文、完善的推理 infra 方案、外加送一定的 cloud credit。是的，再不歇斯底里 Google 真的就晚了。面對 OpenAI 的強力競爭，只有殺敵一千、自損一千五。</p><p>3. 未放下高貴的頭顱：有種感覺，Google 覺得自己還是 AI 王者，放不下高貴的頭顱，很多發佈都有點不痛不癢，還是沿着過去研發驅動的老路而不是產品和競爭驅動，比如不停發論文、取新名字（多模態相關模型過去半年就發了 Palme、RT-2、Gemini、VideoPoet、W.A.L.T 等）、發佈的模型又完整度不夠，感覺就沒有一個絕對能打的產品。Google 可能要意識到在公眾眼中，他在 AI 領域已經是廉頗老矣潰不成軍，經常起大早趕晚集（比如説這次 Sora 借鑑的 ViT、ViViT、NaVit、MAGVit 等核心組件技術都是它家寫的論文）。</p><p>4. 希望亡羊補牢未為晚也：Google 作為一個僵化的大公司，動作慢一點可以理解，但是如果再不努力是不是就是 PC 互聯網的 IBM、移動互聯網的 Microsoft？ 作為 Google 的鐵粉，還是希望他能打起精神一戰，AI 產業需要強力的競爭才能不停向前發展，也需要他在前沿研究和系統的開源才能幫助一大眾「貧窮」的 AI 創業公司。</p><p>5. 另外，除了對外開源外，Google 應該組成三個方陣面對大模型的競爭，詳見去年 3 月發文。</p><p>回顧科技競爭史，PC 互聯網時代的 IBM、移動互聯網時代的 Microsoft、AGI 時代的 Google，新時代來臨後，難道上一個時代科技霸主都難逃衰落的宿命？</p><p>當然，Microsoft 靠 Office SaaS、雲和 OpenAI 又翻盤了。</p><p>歷史的鐵律，有被改寫的可能嗎？</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:15:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279728</guid>
            <link>https://www.oschina.net/news/279728</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 員工的一天]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Chain Of Thought (CoT) 第一作者、從谷歌跳槽到 OpenAI 的 Jason Wei 分享了自己在 OpenAI 的一天：</p><blockquote><p>[9:00am] 起牀</p><p>[9:30am] 搭乘 Waymo 前往 Mission SF，途中在 Tartine 買個牛油果吐司</p><p>[9:45am] 背誦 OpenAI 章程。向優化之神致敬，學習《The Bitter Lession》（強化學習之父 Rich Sutton 著）</p><p>[10:00am] 在 Google Meet 上開會，討論如何在更多數據上訓練更大的模型</p><p>[11:00am] 敲代碼，在更多數據上訓練更大的模型。搭檔是 Hyung Won Chung</p><p>[12:00pm] 去食堂吃午飯（純素且無麩質）</p><p>[1:00pm] 真正開始在大量數據上訓練大模型</p><p>[2:00pm] 處理基礎設施問題（我是腦子被驢踢了嗎為啥要從 master 分支拉代碼？）</p><p>[3:00pm] 監控模型訓練進度，玩 Sora</p><p>[4:00pm] 給剛才訓練的大模型上提示工程</p><p>[4:30pm] 短暫休息，坐在牛油果椅子上，思考 Gemini Ultra 的性能到底有多強</p><p>[5:00pm] 頭腦風暴模型可能的算法改進</p><p>[5:05pm] 修改算法風險太高，pass。最安全的策略還是力大磚飛（增加算力和數據規模）</p><p>[6:00pm] 晚餐時間，和 Roon 一起享用蛤蜊濃湯</p><p>[7:00pm] 回家</p><p>[8:00pm] 喝點小酒，繼續寫碼。Ballmer’s peak（酒精帶來的編碼高效階段）即將到來</p><p>[9:00pm] 分析實驗結果，我對 wandb 又愛又恨</p><p>[10:00pm] 啓動實驗，讓它自己跑一晚上，第二天查看結果</p><p>[1:00am] 實驗真正開始運行</p><p>[1:15am] 上牀睡覺。在納德拉和黃仁勳的守護下入夢。心想：壓縮才是真諦。晚安</p><p><img src="https://oscimg.oschina.net/oscnet/up-3041206e9fa5084776ebedb71c760828888.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2F_jasonwei%2Fstatus%2F1760032264120041684" target="_blank">https://twitter.com/_jasonwei/status/1760032264120041684</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279722</guid>
            <link>https://www.oschina.net/news/279722</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[StarkNet 撒錢，程序員在 Web3 領了 14 萬 ​​​]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>StarkNet 啓動空投活動，GitHub 排名前 5000 開源項目的貢獻者可領取價值 $200 獎勵。</p><h2>背景</h2><ul><li>StarkNet 公鏈項目為了激勵開發者參與其平台建設，啓動了空投活動。</li><li>如果曾向 GitHub 上獲得較多 Star 的項目提交過 PR ，就有資格領取 111.1 STRK 的空投獎勵。</li><li>只需要使用 OAuth 2.0 登錄，就可以直接領取。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-44f62dafa84c34781d15d46c71c7c8c862c.jpg" referrerpolicy="no-referrer"></p><p>有程序員曬出自己在這次空投活動獲得的獎勵——近 14 萬人民幣。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-96e62f68c4891cdbfd1f43b86ddfcdcbf79.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fstrrlthedev%2Fstatus%2F1760182038504837287" target="_blank">https://twitter.com/strrlthedev/status/1760182038504837287</a></u></em></p></blockquote><h2>領取規則</h2><ol><li>截止到 2023 年 11 月 15 日，至少對全球排名前 5000 的倉庫提交過三次代碼貢獻。</li><li>其中至少有一次貢獻是在 2018 年或之後完成的。</li></ol><h2>領取步驟</h2><p>領取地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprovisions.starknet.io%2F" target="_blank">https://provisions.starknet.io/</a></u></em></p><ol><li>訪問獎勵領取頁面並連接錢包（推薦使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2Fargent-x-starknet-wallet%2Fdlcobpjiigpikoobohmabehhmhfoodbb" target="_blank">Argent X</a>）。</li><li>通過 GitHub 登錄，採用 OAuth 2.0 驗證方式。</li><li>直接領取獎勵。後續的治理投票和問卷調查可忽略不計。</li></ol><hr><p>最後，提醒各位程序員，請注意下面這種「空手套白狼」騷操作：</p><p><img src="https://oscimg.oschina.net/oscnet/up-a8822bc079294f3f98548cf7421eda43c71.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279720</guid>
            <link>https://www.oschina.net/news/279720</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
