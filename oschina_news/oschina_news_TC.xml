<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 23 Nov 2023 06:30:38 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[程序員篡改 ETC 餘額，一年私吞 260 餘萬元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>上海網警公眾號今日報道了一起「篡改、破壞計算機信息系統罪」的案件。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrSUrzlxsrEHgzp0dqhXH1A" target="_blank">據介紹</a></u>，2023 年 9 月上海警方接到某科技公司員工張女士報案稱，其公司發現計算機系統被他人篡改數據，導致公司賬戶錢款損失。</p><p>蒐證中發現，操作者很有可能是管理網站後台系統的員工，監守自盜的可能性較大。</p><p>軟件工程師曹某主動投案自首，坦白稱，<strong>去年 8 月發現公司網站後台的漏洞，用母親和朋友身份證註冊了兩個 ETC 賬戶。</strong></p><p><strong>一年內兩個賬戶分別從公司提取來了 230 餘萬元和 36 萬元，總計 260 餘萬元。</strong>目前其因涉嫌盜竊罪已被依法刑事拘留，案件正在進一步審理中。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 06:01:24 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267760</guid>
            <link>https://www.oschina.net/news/267760</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[9 月國內手機市場出貨量 3327.7 萬部，5G 手機佔比 86.3%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>中國信通院<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhtODPwuYMGpG0LLkXScHqw" target="_blank">發佈</a>了 2023 年 9 月國內手機市場運行分析報告，具體情況如下：</p><h4 style="margin-left:0px; margin-right:0px"><strong>一、國內手機市場總體情況</strong></h4><p style="margin-left:0; margin-right:0">2023 年 9 月，國內市場手機出貨量 3327.7 萬部，同比增長 59.0%，其中，5G 手機 2871.7 萬部，同比增長 90.1%，佔同期手機出貨量的 86.3%。</p><p style="margin-left:0; margin-right:0">2023 年 1-9 月，國內市場手機總體出貨量累計 2.0 億部，同比增長 2.2%，其中，5G 手機出貨量 1.62 億部，同比增長 5.5%，佔同期手機出貨量的 80.7%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="288" src="https://oscimg.oschina.net/oscnet/up-69c95e09317725c4f7ffc7ef79b2f4738ff.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>圖 1&nbsp; 國內手機市場出貨量及 5G 手機佔比</strong></p><p style="margin-left:0; margin-right:0">2023 年 9 月，國內手機上市新機型 42 款，同比增長 23.5%，其中 5G 手機 20 款，同比增長 33.3%，佔同期手機上市新機型數量的 47.6%。</p><p style="margin-left:0; margin-right:0">2023 年 1-9 月，上市新機型累計 335 款，同比增長 9.8%，其中 5G 手機 153 款，同比下降 1.9%，佔同期手機上市新機型數量的 45.7%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="294" src="https://oscimg.oschina.net/oscnet/up-c560fe8a7f746252f0eb067442a16f4a434.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>圖 2&nbsp; 國內手機上市新機型數量及 5G 手機佔比</strong></p><h4 style="margin-left:0px; margin-right:0px"><strong>二、國內手機市場國內外品牌構成</strong></h4><p style="margin-left:0; margin-right:0">2023 年 9 月，國產品牌手機出貨量 2494.6 萬部，同比增長 36.1%，佔同期手機出貨量的 75.0%；上市新機型 41 款，同比增長 36.7%，佔同期手機上市新機型數量的 97.6%。</p><p style="margin-left:0; margin-right:0">2023 年 1-9 月，國產品牌手機出貨量累計 1.63 億部，同比下降 3.9%，佔同期手機出貨量的 81.4%；上市新機型累計 307 款，同比增長 10.4%，佔同期手機上市新機型數量的 91.6%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="229" src="https://oscimg.oschina.net/oscnet/up-f96594c4ab35fa2f58a6f38fc849910fae5.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>圖 3&nbsp; 國產品牌手機出貨量及佔比</strong></p><h4 style="margin-left:0px; margin-right:0px"><strong>三、國內智能手機發展情況</strong></h4><p style="margin-left:0; margin-right:0">2023 年 9 月，智能手機出貨量 3193.4 萬部，同比增長 60.9%，佔同期手機出貨量的 96.0%。2023 年 1-9 月，智能手機出貨量 1.92 億部，同比增長 0.3%，佔同期手機出貨量的 95.6%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="260" src="https://oscimg.oschina.net/oscnet/up-914d590bdbd5b0ede95fa2c8e1f6e33b3f8.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>圖 4&nbsp; 國內智能手機出貨量及佔比</strong></p><p style="margin-left:0; margin-right:0">2023 年 9 月，智能手機上市新機型 32 款，同比增長 14.3%，佔同期手機上市新機型數量的 76.2%。2023 年 1-9 月，智能手機上市新機型累計 279 款，同比增長 8.6%，佔同期上市新機型數量的 83.3%。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 03:47:16 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267742</guid>
            <link>https://www.oschina.net/news/267742</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[俄羅斯操作系統 ALT Linux 支持龍芯處理器 (LoongArch)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根據俄媒 CNews 的<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnews.ru%2Fnews%2Ftop%2F2023-11-16_rossiyane_vpervye_nauchili" target="_blank">報道</a></u>，ALT Linux 操作系統已經正式添加對龍芯處理器的適配，支持龍芯 3A5000、龍芯 3A6000 等 CPU。得益於龍芯 CPU 出口限制已經被解除，<strong>俄羅斯相關部門可以採購這些 CPU 來替代 AMD 和英特爾的產品</strong>。</p><p><img src="https://static.oschina.net/uploads/space/2023/1123/113827_V5RM_2720166.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b019b0af83f74abe941843b40680ea69e8a.png" referrerpolicy="no-referrer"></p><p>ALT Linux 由俄羅斯公司 Basalt SPO 開發，其桌面環境基於 KDE Plasma 及 Xfce 構建，設計風格和 Windows 類似。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6090cfdcee56fe3b264b7d1c10ce5b543eb.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5842fd873798b6510a44b29f117b94c0961.png" referrerpolicy="no-referrer"></p><p>報道稱，Basalt SPO 的開發團隊非常高效，只花了 9 個月時間，就將 ALT Linux 移植到了龍芯 LoongArch 架構。</p><p>Basalt SPO 表示，目前支持龍芯的 ALT Linux 已開始提供不穩定的測試分支，<strong>預計穩定的 11.0 正式版將在明年第一季度發佈，採用 Xfce 桌面環境</strong>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 03:44:16 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267741/russia-alt-os-linux-loongson-loongarch</guid>
            <link>https://www.oschina.net/news/267741/russia-alt-os-linux-loongson-loongarch</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[長安汽車基於 Apache Doris 的車聯網數據分析平台建設實踐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>導讀：隨着消費者更安全、更舒適、更便捷的駕駛體驗需求不斷增長，汽車智能化已成必然趨勢。長安汽車智能化研究院作為長安汽車集團有限責任公司旗下的研發機構，專注於汽車智能化技術的創新與研究。為滿足各業務部門的數據分析需求，長安汽車基於 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdoris" target="_blank">Apache Doris</a> 升級了車聯網數據分析平台，支撐單日百億級別數據實時處理，並實現十億級別數據查詢秒級響應，為長安汽車在提升用戶用車體驗、實時預警車輛故障、保證車輛安全駕駛等方面帶來顯著成果，為其在智能化方向的技術創新提供了有力支持。</p><p>作者｜長安汽車智能化研究院</p></blockquote><p>智能化是汽車工業進程中的一場革命，它旨在利用大數據、人工智能、雲計算、物聯網等前沿數字技術，對汽車設備和系統的運行狀態進行全方位的感知、分析、決策和控制，從而提高汽車的安全性、舒適性、便捷性和節能性。</p><p>長安汽車智能化研究院作為長安汽車集團有限責任公司旗下的研發機構，專注於汽車智能化技術的創新與研究，其願景是通過持續創新和技術突破，實現汽車智能駕駛、智能網聯和智能交通的全面發展，為消費者提供更安全、更便捷、更智能的出行體驗，並致力於成為中國汽車智能化領域的領軍企業。</p><p>實現汽車智能化的關鍵之一，是需要建立穩定、高效的數據平台，以承載和利用海量的車聯網數據。作為智能化發展的重要支撐，長安汽車智能化研究院肩負着整個長安汽車集團車聯網數據的匯聚、處理和應用工作。為滿足各業務部門提出的數據支持需求，目前已經構建了車聯網數據分析平台，並在業務指標分析、質量管理系統、智慧能耗、智能診斷、智慧運營等多個重點領域實現數據應用。</p><p>本文將詳細介紹長安汽車車聯網數據分析平台的演進歷程及實踐經驗，<strong>分享長安汽車基於 Apache Doris 支撐單日百億級別數據實時處理、實現十億級別數據查詢秒級響應的實踐經驗</strong>。此外，<strong>Apache Doris 的引入還為長安汽車在用戶用車體驗提升、駕駛安全保障等方面帶來顯著收益，為長安汽車從機電化到智能化轉型發展提供有力支持</strong>。</p><h1>汽車智能化所面臨的挑戰</h1><p>近些年來，長安汽車取得了令人矚目的銷量增長成績。1-8 月，長安汽車自主乘用車累計銷量超百萬輛、保持持續上升的發展勢頭，以深藍、阿維塔、啓源為代表的新能源系列品牌力和產品競爭力不斷提升，自主新能源車累計銷量約為 25.6 萬輛、同比增長 102.44%，成為銷量增長新動能。</p><p>在汽車銷量快速攀升的背後，車聯網數據更是呈現爆發式增長的態勢，其中最為核心的即車輛 CAN 總線數據。CAN 即 Controller Area Network，通過 CAN 總線可以對車輛上的各類電子控制系統進行統一通信，在實際車輛運行過程中 ，CAN 總線數據是車輛安全性、可靠性和高性能的重要保證：</p><ul><li>車輛系統監測和控制：CAN 總線數據可用於監測和控制系統中的各種設備和組件。傳感器通過 CAN 總線發送其測量值，如溫度、壓力、位置等，以便其他設備或控制器實時監測和採取相應的措施。同時，控制器可以通過 CAN 總線向執行器發送控制指令，如調節閥門、驅動電機等，以實現對系統的控制。</li><li>車輛信息實時反饋：CAN 總線數據可用於提供實時反饋信息。例如在車輛控制系統中，傳感器通過 CAN 總線傳輸車速、轉向角度、制動狀態等數據，控制器可以根據這些數據進行實時決策和調整，以確保車輛的安全性和性能。</li><li>數據共享和協調：CAN 總線數據允許不同設備之間進行數據共享和協調。通過 CAN 總線，不同的控制器和設備可以交換信息，共享狀態和控制命令，有利於提高系統的整體性能和效率。</li><li>網絡管理和故障診斷：CAN 總線數據用於網絡管理和故障診斷。通過 CAN 總線，可以進行設備的自動識別、配置和監控，以便進行網絡管理和故障排查，提高系統的可靠性和可維護性。</li></ul><p><strong>隨着網聯車銷量不斷增長，車輛每天將產生千億級別的 CAN 數據，清洗處理後的數據也在 50 億級別</strong>，面對如此龐大且持續膨脹的數據規模，如何從海量數據中快速提取挖掘有價值的信息，為研發、生產、銷售等部門提供數據支持，成為當前亟需解決的問題。</p><p>而想要提供良好的數據支持及服務，首先需要應對以下幾大挑戰：</p><ul><li><strong>大規模數據實時寫入及處理</strong>：為實現智能化，汽車的車門、座椅、剎車燈設備被設置了大量的傳感器，每個傳感器收集一種或者多種信號數據，數據被匯聚後進一步加工處理。目前長安汽車需要支持至少 400 萬輛車的鏈接，車聯網數據每秒吞吐量已達百萬級 TPS ，每日新增數據規模高達數十 TB ，且還在持續增長中。如何對數據進行實時寫入成為了長安汽車首要面臨的挑戰。</li><li><strong>準確及時的實時數據分析需求</strong>：車聯網場景下數據分析通常要求實時性，快速獲取分析結果是實時監控、故障診斷、預警和實時決策等服務的重要保障。例如在智能診斷中，車企需要近實時地收集相關信號數據，並快速定位故障原因。通過分析車輛傳感器數據、行駛記錄等，可以提前發現潛在故障，進行預防性維護，提高車輛的可靠性和安全性。</li><li><strong>更加低廉的數據存儲和計算成本</strong>：面對快速增長的的數據以及日益強烈的全量寫入和計算需求，導致數據存儲和計算成本不斷攀升。這就要求數據平台具備低成本存儲和計算的能力，以降低使用成本；同時需具備彈性伸縮能力，以便用戶在業務高峯期快速擴容，提升海量數據計算場景的分析效率。</li></ul><p>為給用戶提供更優質的駕車體驗、為業務部門提供更準確高效的數據支持，長安汽車開始對大數據平台的建設進行探索和實踐。</p><h1>Hive 離線數據倉庫難以支撐超大規模實時數據服務</h1><p><img src="https://cdn.selectdb.com/static/Hive_17776ddfed.jpg" alt="長安汽車車聯網-Hive 離線數倉.jpg" referrerpolicy="no-referrer"></p><p>長安汽車最早以 Hive 為核心構建了數據平台架構，所處理數據包括車輛 CAN 總線數據和埋點數據，這些數據通過 4G 網絡從車端傳送至長安雲端網關，然後由網關將數據寫入 Kafka。考慮到數據量級和存儲空間的限制，早期架構中的數據處理流程是將 Kafka 採集到的數據直接通過 Flink 進行處理，並通過 ETL 將結果存儲到 Hive 中。下游應用使用 Spark SQL 進行逐層離線計算，並通過 Sqoop 將彙總數據導出到 MySQL 中。最終由 Hive 和 MySQL 分別為應用層提供數據服務。</p><p>儘管該架構在早期基本滿足了數據處理需求，但隨着車輛銷量不斷增長，當需要面對每天千億級別的數據處理分析工作時，架構的問題逐步暴露出來：</p><ul><li><strong>數據時效性無法保證</strong>：Hive 的導入速度較慢，尤其在處理大規模數據時，導入時間明顯增加；同時部分業務依賴 T+1 離線任務，無法滿足實時數據處理需求；此外， Hive 只支持分區覆蓋，不支持主鍵級別的數據更新，無法滿足特殊場景的數據更新需求。</li><li><strong>數據查詢分析延遲較高</strong>：對於 10 億級別以上大規模表查詢，Hive 查詢性能較慢。通過 SparkSQL 進行數倉分層運算時，啓動和任務執行時間較長，對查詢響應也會產生影響。此外，數據看板、BI 展示應用無法直接從 Hive 中查詢，需要將 Hive 中數據導出到 MySQL 中，由 MySQL 提供服務，受限於 Hive 導數性能，當數據量較大時，導出到 MySQL 耗時大幅增加，進而導致查詢響應時間變長。此外，通過 Java 後端查詢 MySQL 時，數據量過大也會影響數據的響應時間。</li></ul><p>追根究底，產生這些問題的根本原因在於早期架構無法滿足超大規模實時數據場景下的數據需求，這迫使長安汽車必須進行平台升級改造。</p><h1>技術調研與選型</h1><p>長安汽車經過深入調研，決定引入開源實時數據倉庫 Apache Doris ，在導入性能、實時查詢等方面具有顯著優勢：</p><ul><li><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.selectdb.com%2Fblog%2F106" target="_blank">豐富的數據導入方式</a></strong>：Doris 提供了豐富的內置導入方式，如 Broker Load 和 Stream Load 等，可以滿足實時和離線場景中數據導入需求。</li><li><strong>支持實時查詢分析</strong>：Doris 大表 Join 能力突出，提供了多種分佈式 Join 方式，使 Join SQL 編寫具備高度靈活性，極大提升數據分析的效率。此外，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.selectdb.com%2Fblog%2F56" target="_blank">Doris 支持單節點上萬 QPS 的超高併發</a>，可解決早期架構由於前端併發量過大導致查詢失敗的問題。</li><li><strong>較低的使用成本</strong>：Doris 兼容 MySQL 協議，開發人員可以更高效便捷的使用 MySQL 編寫和執行查詢語句，有效提高開發效率。基於 Doris 極簡的架構，不僅讓部署運維更加簡單，也讓擴縮容操作變的更加方便彈性。同時，Doris 擁有良好的上下游生態，可為用戶提供靈活高效的數據管理和分析體驗。這些優勢和特性都極大的降低了 Doris 的使用成本。</li></ul><p>除此以外，<strong>開源社區的活躍度也是我們考慮的重要因素之一</strong> 。Apache Doris 吸引了大量的開發者及用戶參與社區，共同貢獻代碼和改進 Doris，這對質量和穩定性的提高起關鍵作用。同時，Doris 社區為用戶提供了全面的文檔資料和技術支持，任何問題都可以快速得到解答和幫助。Apache Doris 的活躍程度使我們在使用時更加放心，解決了技術方面的後顧之憂。</p><h1>基於 Apache Doris 車聯網數據分析平台</h1><p><img src="https://cdn.selectdb.com/static/_50f5a17a88.jpg" alt="長安汽車車聯網-車聯網數據分析平台.jpg" referrerpolicy="no-referrer"></p><p>在新的車聯網數據分析平台中，通過 Flink 結合 Doris 的 Stream Load 功能，可直接將 Kafka 數據實時寫入 Doris，同時，利用 Doris Broker Load 功能可以將 Hive 中數據導入到 Doris 中進行分析計算。在這個架構中，Apache Doris 承擔了實時數據部分的計算和處理，還作為結果端直接輸出數據給上游業務平台調用。</p><p>這一升級在系統上縮短了數據處理的路徑，保證了大規模數據導入的時效性。此外，Apache Doris 的引入為上游應用層提供統一數據服務支持，這對於查詢分析效率的提升至關重要。具體收益如下：</p><ul><li>便捷進行數據寫入和遷移：Doris 支持豐富的數據導入形式，可輕鬆從不同的數據源中導入數據。其次，Doris 支持通過 insert into select 快速導入數據，無需進行繁重的數據遷移配置以及引入外部同步組件。</li><li>統一數據服務，秒級查詢響應：通過 Doris Multi-Catalog 功能，數據分析師可直接從 Doris 上查詢數據，實現秒級別查詢響應。其次，Doris Join 能力優異，對於超過 1000 萬的結果表查詢也可實現秒級返回結果。</li><li>降低存儲和計算成本：在早期架構中，使用 Flink 實時寫入數據並進行壓縮時需要消耗大量的計算資源。而引入 Apache Doris 後，藉助 Doris ZSTD 壓縮算法（3-5 倍壓縮率提升），可有效降低計算和存儲所需的資源，還可以將壓縮處理流程放到 Doris 內部進行，無需消耗 Flink 計算資源。</li></ul><h1>從 T+1 到 T+0，實時數據提升智能駕駛體驗</h1><p>CAN 總線數據在車輛分析中扮演着關鍵的角色，通過 CAN 總線可以讀取車輛的各種狀態信息，例如車速、轉速、水溫等。這些數據對於分析車輛的行駛數據具有重要的價值，為整車研發單位提供寶貴的參考信息。</p><p>在早期架構中，車輛 CAN 數據是按照 CAN ID 作為維度進行上傳的，而在實際使用中，通常需要將不同 CAN ID 的信號按照時間對齊形成一個寬表。過去的數倉架構解決方案會先將 Kafka 中的數據寫入到 Hive，此時不同 CAN ID 的數據被存儲在不同的行中，需要使用 SparkSQL T+1 將數據轉換為幾個不同業務域的寬表。然而，這種計算方式耗時較長，SQL 語句難以維護，且數據的實時性較差。</p><p>在引入 Apache Doris 之後，我們在 Doris 中基於 Aggregate 聚合模型建立了業務域的寬表，將車輛和時間等作為主鍵，其他的信號字段都用<code>REPLACE_IF_NOT_NULL</code>定義。具體如下：</p><p><img src="https://cdn.selectdb.com/static/_c3afa33c84.jpg" alt="長安汽車車聯網-實時數據.jpg" referrerpolicy="no-referrer"></p><p>首先，可以使用 Flink 來消費 Kafka 中按 CAN ID 維度的數據，在 Flink 中根據業務域寬表的配置對數據進行分流，將同一個 CAN ID 上的信號分配到相應的業務域寬表中。當同一個車輛在同一時間內不同 CAN ID 的數據到達同一個業務域寬表時，可以將這些數據填充到同一行中的不同 CAN ID 的信號數據字段中，實現寬表的構建（如上圖 Doris 的表示例）。</p><p>在這種方式中，主要通過 Flink 對數據進行分流，將數據發送到不同的 Doris 業務域寬表中（每個寬表約有 200 個字段）。寬表的生成邏輯被放在了 Doris 中，而不是在 Flink 中進行寬表對齊的操作。這樣設計的原因是不同 CAN ID 的數據上傳存在一定的時間差，時間窗口過大時，使用 Flink 根據車輛和時間進行聚合可能會導致資源開銷過高。</p><p><strong>通過以上方案，可以將數據的新鮮度從 T+1 提高到 T+0 。同時，對於包含約 10 億行數據的寬表，可以達到秒級的查詢效率，即在進行單車查詢時，可以快速地獲取查詢結果。</strong></p><h1>10 億級別 DTC 故障碼實時查詢，保障車輛駕駛安全</h1><p>DTC 屬於 CAN 數據中的故障報文，因此對其進行單獨的業務數據存儲。每天的 DTC 數據量級可以達到 10 億條，為了讓業務端便捷高效的使用這些數據，快速進行故障診斷，提升車輛安全性，需要將 DTC 故障碼明細數據與一張 MySQL 業務配置表進行關聯。</p><p>在早期架構中，開發人員每天都需要將海量 DTC 數據先寫入到 Kafka 中，然後通過 Flink 進行實時處理，並將結果存儲到 Hive 中。而這種處理方式存在一些問題：</p><ul><li>面對 10 億級數據量的表，難以將其導入 MySQL 進行實時查詢。如果直接查詢 Hive，則查詢反饋時間會非常長，難以滿足業務需求。</li><li>由於無法直接關聯 MySQL 的配置表，不得不定時將配置表導入 Hive 數倉。這樣做雖然能夠滿足數據處理的需求，但卻丟失了 DTC 配置的實時性。</li></ul><p><img src="https://cdn.selectdb.com/static/_98e4700c50.jpg" alt="長安汽車車聯網-實時查詢.jpg" referrerpolicy="no-referrer"></p><p>在引入 Apache Doris 後，採用上圖所示處理方式成功解決了早期架構存在的問題。首先將 Hive 的 DTC 明細數據通過 HDFS 文件導入的方式導入到 Doris 中，然後創建對應的 MySQL Catalog 連接，最後使用後端 Java 通過 MyBatis 連接 Doris 數據庫，並使用 SQL 通過 Catalog 連接 MySQL 的 DTC 配置表進行 Join 操作，可直接實時查詢返回結果。</p><p>通過 Apache Doris 成功完成了 10 億級別數據的實時查詢，並且可以對關聯的 MySQL 配置表進行直接關聯查詢，成功實現了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.selectdb.com%2Fblog%2F31" target="_blank">配置的實時更新</a>。</p><h1>總結與規劃</h1><p><strong>憑藉 Apache Doris 卓越的性能，目前在長安汽車已經部署數十台機器，支撐了近十條業務線，每天處理數據規模達到百億級別。</strong> Apache Doris 的引入為長安汽車在提升用戶用車體驗、實時預警車輛故障、保證車輛安全駕駛等方面帶來顯著成果，為其在智能化方向的技術創新提供了有力支持。</p><p>未來，長安汽車將進一步將 Apache Doris 應用在標籤和指標業務，實現以下需求：</p><ul><li>自動識別冷熱數據：將熱數據存儲在 Apache Doris 中，冷數據存儲在 Hive 中，通過這種方式實現更高效的數據訪問和管理。</li><li>擴大業務範圍：對現有的 Doris 業務 SQL 代碼進行優化，利用 Doris 的某些特性和功能，將適合這些特性的業務遷移到 Doris 中，從而提高數據處理和查詢的效率。</li><li>共建社區：積極嘗試使用 Doris 最新版本及新功能，在與社區保持同步的同時，不斷探索和應用新的技術，反哺社區、為社區發展做出貢獻。</li></ul><p>最後，衷心感謝 Apache Doris 社區和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.selectdb.com%2F" target="_blank">飛輪科技技術團隊</a>的積極支持，期待未來與大家繼續深入合作，推動長安汽車智能化發展，為用戶提供更好的駕車體驗！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 03:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5735652/blog/10143334</guid>
            <link>https://my.oschina.net/u/5735652/blog/10143334</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[博通宣佈成功收購 VMware]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">博通（Broadcom）宣佈已經獲得<span style="background-color:#ffffff">收購所需的所有必要監管批准，成功</span>完成了對雲計算公司 VMware 的收購。</span></p><p><span style="color:#000000">中國方面於 2023 年 11 月 21 日批准了該收購，不過附帶了額外的限制性條件。聲明明確指出，VMWare 的服務器軟件應與本地硬件保持兼容，收購不得對客戶購買和使用博通的硬件產品（包括存儲適配器）施加限制。</span></p><p><span style="color:#000000"><img height="266" src="https://oscimg.oschina.net/oscnet/up-304e8a97c668a6833abc83fd09a46010735.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">收購完成後，該公司將致力於開發解決方案，幫助客戶優化其私有云、混合雲和多雲環境，並從任何地方運行應用程序和服務。公告表示，博通未來的工作重點將聚焦在幫助企業客戶創建並現代化其私有云和混合雲環境。</span></p><p><span style="color:#000000">該公司計劃投資 VMware Cloud Foundation，<span style="background-color:#ffffff">這是一個作為私有云和混合雲基礎的軟件堆棧。</span>作為收購的一部分，VMware 將在 VMware Cloud Foundation 之上提供一系列服務。</span></p><p><span style="color:#000000">博通針對 VMware Tanzu 的計劃是通過加速跨各種雲環境的應用程序開發、交付和管理來增強客戶的業務敏捷性。該解決方案適用於 VMware Cloud Foundation 和主要的超大規模提供商，為 Spring 等應用程序開發框架提供優化。Tanzu 提高了開發人員的工作效率，同時使平台團隊能夠執行標準、維護安全性和跟蹤性能。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.broadcom.com%2Fblog%2Fbroadcom-announces-successful-acquisition-of-vmware" target="_blank">查看官方公告</a>。</span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><a href="https://www.oschina.net/news/197527/broadcom-vmware-61-billion" target="_blank">博通擬以 610 億美元收購 VMware</a></li><li><a href="https://www.oschina.net/news/249166/eu-approves-broadcom-vmware-acquisition" target="news">博通 610 億美元收購 VMware 已獲歐盟委員會批准</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 03:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267737/broadcom-successful-acquisition-of-vmware</guid>
            <link>https://www.oschina.net/news/267737/broadcom-successful-acquisition-of-vmware</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[PHP 8.3 GA]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>PHP 8.3 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.php.net%2Freleases%2F8.3%2Fzh.php" target="_blank">已正式發佈</a></u>。主要變化包括：</p><ul><li>類常量顯式類型 (Typed class constants)</li><li>只讀屬性深拷貝</li><li>新增<code>#[\Override]</code>屬性</li><li>新增<code>json_validate()</code>函數</li><li>添加<code>Randomizer::getBytesFromString()</code>方法</li><li>添加<code>Randomizer::getFloat()</code>和<code>Randomizer::nextFloat()</code>方法</li><li>以及更好的性能、更好的語法、改進類型安全</li></ul><p><img height="1114" src="https://static.oschina.net/uploads/space/2023/1123/110607_AwYL_2720166.png" width="2552" referrerpolicy="no-referrer"></p><p>下面介紹部分語法的變化。</p><ul><li><strong>類型化類常量</strong></li></ul><p>PHP &lt; 8.3</p><pre><code class="language-php">interface I {
    // We may naively assume that the PHP constant is always a string.
    const PHP = 'PHP 8.2';
}

class Foo implements I {
    // But implementing classes may define it as an array.
    const PHP = [];
}</code></pre><p>PHP 8.3</p><pre><code class="language-php">interface I {
    const string PHP = 'PHP 8.3';
}

class Foo implements I {
    const string PHP = [];
}

// Fatal error: Cannot use array as value for class constant
// Foo::PHP of type string</code></pre><ul><li><strong>動態獲取類常量</strong></li></ul><p>PHP &lt; 8.3</p><pre><code class="language-php">class Foo {
    const PHP = 'PHP 8.2';
}

$searchableConstant = 'PHP';

var_dump(constant(Foo::class . "::{$searchableConstant}"));</code></pre><p>PHP 8.3</p><pre><code class="language-php">class Foo {
    const PHP = 'PHP 8.3';
}

$searchableConstant = 'PHP';

var_dump(Foo::{$searchableConstant});</code></pre><ul><li><strong>只讀屬性深拷貝</strong></li></ul><p><code>readonly</code>屬性現在可以在魔術方法<code>__clone</code>中被修改一次，以此實現只讀屬性的深拷貝。</p><p>PHP &lt; 8.3</p><pre><code class="language-php">class PHP {
    public string $version = '8.2';
}

readonly class Foo {
    public function __construct(
        public PHP $php
    ) {}

    public function __clone(): void {
        $this-&gt;php = clone $this-&gt;php;
    }
}

$instance = new Foo(new PHP());
$cloned = clone $instance;

// Fatal error: Cannot modify readonly property Foo::$php</code></pre><p>PHP 8.3</p><pre><code class="language-php">class PHP {
    public string $version = '8.2';
}

readonly class Foo {
    public function __construct(
        public PHP $php
    ) {}

    public function __clone(): void {
        $this-&gt;php = clone $this-&gt;php;
    }
}

$instance = new Foo(new PHP());
$cloned = clone $instance;

$cloned-&gt;php-&gt;version = '8.3';</code></pre><ul><li><strong>新增<code>#[\Override]</code>屬性</strong></li></ul><p>通過給方法添加<code>#[\Override]</code>屬性，PHP 將確保在父類或實現的接口中存在同名的方法。<br> 添加該屬性表示明確説明覆蓋父方法是有意為之，並且簡化了重構過程，因為刪除被覆蓋的父方法將被檢測出來。</p><p>PHP &lt; 8.3</p><pre><code class="language-php">use PHPUnit\Framework\TestCase;

final class MyTest extends TestCase {
    protected $logFile;

    protected function setUp(): void {
        $this-&gt;logFile = fopen('/tmp/logfile', 'w');
    }

    protected function taerDown(): void {
        fclose($this-&gt;logFile);
        unlink('/tmp/logfile');
    }
}

// The log file will never be removed, because the
// method name was mistyped (taerDown vs tearDown).</code></pre><p>PHP 8.3</p><pre><code class="language-php">use PHPUnit\Framework\TestCase;

final class MyTest extends TestCase {
    protected $logFile;

    protected function setUp(): void {
        $this-&gt;logFile = fopen('/tmp/logfile', 'w');
    }

    #[\Override]
    protected function taerDown(): void {
        fclose($this-&gt;logFile);
        unlink('/tmp/logfile');
    }
}

// Fatal error: MyTest::taerDown() has #[\Override] attribute,
// but no matching parent method exists</code></pre><ul><li><strong>新增<code>json_validate()</code>函數</strong></li></ul><p><code>json_validate()</code>可以檢查一個字符串是否為語法正確的 JSON，比<code>json_decode()</code>更有效。</p><p>PHP &lt; 8.3</p><pre><code class="language-php">function json_validate(string $string): bool {
    json_decode($string);

    return json_last_error() === JSON_ERROR_NONE;
}

var_dump(json_validate('{ "test": { "foo": "bar" } }')); // true</code></pre><p>PHP 8.3</p><pre><code class="language-php">var_dump(json_validate('{ "test": { "foo": "bar" } }')); // true</code></pre><hr><p>此外，PHP 8.0 的生命週期即將結束。早在 2022 年 11 月 26 日，PHP 8.0 結束了積極支持，而安全支持也將在 PHP 8.3 正式發佈三天後——2023 年 11 月 26 日停止。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267734/php-8-3-ga</guid>
            <link>https://www.oschina.net/news/267734/php-8-3-ga</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Node.js v20.10.0 (LTS)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Node.js v20.10.0 已正式發佈，代號 'Iron'。根據發佈時間表，由於上月&nbsp;Node.js 21 已正式發佈，因此&nbsp;Node.js 20 就變成了長期支持版本 (LTS)。</p><p><strong>新版本主要變化</strong></p><ul><li>引入新的<code>--experimental-default-type</code>flag，用於快速啓用 module 默認值</li><li>引入新的<code>--experimental-detect-module</code>flag，支持檢測不明確的 JavaScript 中的 ESM 語法</li><li>為文件系統函數引入新的&nbsp;<code>flush</code>&nbsp;選項</li><li>新增實驗性的 WebSocket 客戶端</li><li>修復 vm.Script 的 V8 編譯緩存支持</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnodejs.org%2Fen%2Fblog%2Frelease%2Fv20.10.0" target="_blank">詳情查看發佈公告</a></u>。</p><p>延伸閲讀：<u><em><a href="https://www.oschina.net/news/262268/nodejs-v21-release-released" target="news">Node.js 21 正式發佈</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 02:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267730/nodejs-v20-10-0-lts</guid>
            <link>https://www.oschina.net/news/267730/nodejs-v20-10-0-lts</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟 Copilot Web AI 將於 12 月 1 日正式上線，支持中文]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微軟 Copilot 具有商業數據保護功能的 Web AI 聊天功能將於今年 12 月 1 日正式上線（即 Bing Chat Enterprise）。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fbing-chat-enterprise%2Ffaq" target="_blank">官方 FAQ&nbsp; 頁面寫道</a>，Bing Chat Enterprise 為 160 多個地區提供服務——不包括中國，但該服務支持簡體中文。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d6a174ca659444ef929f4c6baec68bf72fe.png" referrerpolicy="no-referrer"></p><p>該功能無需另外付費，只要企業和教育機構訂購 Microsoft 365 即可使用，支持的許可證包括 E3、E5、A3、A5、Business Standard 以及 Business Premium。</p><p>微軟承諾該 Copilot 產生的數據內容將受到保護和隔離，並不會泄露出組織外，微軟無法訪問這些數據同時也不會用來訓練數據模型。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267719</guid>
            <link>https://www.oschina.net/news/267719</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Python 3.13.0 alpha 2]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Python 3.13.0 第 2 個 alpha 已發佈，目前處於非常早期的開發階段。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-830317f825f86fd0fff29be2fcf18a93961.png" referrerpolicy="no-referrer"></p></blockquote><p>公告寫道，Python 3.13 的許多新功能仍在規劃和編寫中（<a href="https://www.oschina.net/news/251454/steering-council-notice-about-pep-703">包括備受關注的 no-GIL</a>）。</p><p>下面是該版本的主要變化：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpeps.python.org%2Fpep-0594%2F" target="_blank">PEP 594</a>（從標準庫中刪除已棄用的模塊）：aifc、audioop、chunk、cgi、cgitb、crypt、imghdr、mailcap、msilib、nis、nntplib、ossaudiodev、pipes、sndhdr、spwd、sunau、 telnetlib、uu、xdrlib、lib2to3。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2Fdev%2Fwhatsnew%2F3.13.html%23removed" target="_blank">刪除</a>多個標準庫模塊中已被棄用的類、函數和方法</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2Fdev%2Fwhatsnew%2F3.13.html%23deprecated" target="_blank">新的棄用內容</a>，其中大部分計劃從 Python 3.15 或 3.16 中刪除</li><li>針對 C API 的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2Fdev%2Fwhatsnew%2F3.13.html%23id10" target="_blank">刪除</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2Fdev%2Fwhatsnew%2F3.13.html%23id9" target="_blank">棄用</a>（alpha 1 中存在的一些刪除已在 alpha 2 中恢復，因為此時刪除被認為過於破壞兼容性）</li></ul><p>Python 3.13 的下一個更新是 3.13.0a3，目前計劃於 2023 年 12 月 19 日發佈。</p><p>詳情查看 Python 3.13 發佈日程（將於明年 10 月 1 日正式發佈）：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpeps.python.org%2Fpep-0719%2F">https://peps.python.org/pep-0719/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 23 Nov 2023 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267717/python-3-13-0-alpha-2</guid>
            <link>https://www.oschina.net/news/267717/python-3-13-0-alpha-2</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 首席科學家 Ilya Sutskever：直面 AGI 的可能性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/7949e75d-050e-481a-b3ca-1aa0507b1f16.png" width="560" referrerpolicy="no-referrer"></p><p><span>AI 寒冬曾造成機器學習和 AI 對齊之間的分歧，上世紀 90 年代，AI 對齊領域天馬行空的暢想與機器學習的慘淡現實形成了鮮明對比，人們普遍對機器學習的發展持悲觀態度。</span><span>自 2010 年以來，以深度神經網絡為代表的 AI 技術飛速發展，AI 對齊隨之成為被逐漸重視的研究方向。</span></p><p>&nbsp;</p><p><span>AGI 是 AI 技術發展的終極目標，鑑於這項技術的深遠影響，近期在舊金山舉辦的 AI 對齊論壇的演講上，<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491988%26idx%3D1%26sn%3Dc5fcc5f3fa27bb00bf8ef9af05e7ca89%26chksm%3Dfe426fa2c935e6b4ebb279bf19471f39629ccfb6733e6d8a580fdcbb01e80bd59266f3830bac%26scene%3D21%23wechat_redirect" target="_blank"><strong>OpenAI 首席科學家 Ilya Sutskever </strong></a>指出，促進人們形成關於 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491935%26idx%3D1%26sn%3D9535636ca06c16345b432a9de5383f1e%26chksm%3Dfe426f69c935e67f717ca8a968b9dd2a3f69b45f330b561b3584ba1b196149c8ba00d3d452eb%26scene%3D21%23wechat_redirect" target="_blank"><strong>AI 對齊</strong></a>與機器學習的統一，將 AGI 安全納入機器學習的主流方向十分必要。他還稱，通用人工智能和超級智能很有可能在我們有生之年實現，實現巨大的變革，我們不該侷限於現有觀念，對其潛力設限。</span></p><p>&nbsp;</p><p><span style="color:#333333">（以下內容由 OneFlow 編譯發佈，轉載請聯繫授權。原文：https://www.youtube.com/watch?v=OPZxs6IXH00）</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><strong><span style="color:#3f3f3f">作者 | Ilya Sutskever</span></strong></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><strong><span style="color:#3f3f3f">OneFlow 編譯</span></strong></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><strong><span style="color:#3f3f3f">翻譯｜楊婷、宛子琳</span></strong></span></p><p style="color:#494949; text-align:center">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>目前，AI 領域發展迅速，通用人工智能（AGI）已不再是天方夜譚。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>現在，我先補充一些相關背景知識，以幫助大家瞭解當前狀況的成因。AI 對齊和機器學習一直在研究相關問題，但直到最近，它們才開始有了交集。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><span id="OSC_h2_1"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">1</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">AI 對齊與機器學習</span></strong></span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>AI 對齊和 AGI 安全的起源可以追溯到早期的科幻文學。當時人們還可以任意發揮想象力，尚未受到現今的技術限制。人們會思考如下問題：「如果我們擁有一個足夠強大的 AI 系統，它能夠執行研究、科學、工程和技術等任務，能夠進行 AI 研究、編程和芯片設計，並且還能將上述能力整合到一起進行管理，那將發生什麼？」</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>捫心自問，我們或許會得出這樣一個答案：那將會導致重大變革。隨之而來的問題自然是：如此強大的 AI 似乎也會帶來許多挑戰，作為普通人，我們應該如何更好地利用 AI？這就是 AI 對齊誕生的原因。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>機器學習領域也有着類似的科幻起源。在 1940 年代和 1950 年代，一些有遠見的科學家開始思考以下問題，比如：什麼是智能？大腦是如何運作的？我們能否在計算機上構建大腦？是否可以創造出人工神經網絡？計算機能夠進行學習嗎？對於以上問題，當時的研究人員十分樂觀，他們相信人類水平的 AI 將在五年內實現。</span></p><p>&nbsp;</p><span id="OSC_h2_2"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">2</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">AI 寒冬</span></strong></span></p><p style="color:#494949">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>但事實證明他們錯了，隨後 AI 寒冬到來，造成了機器學習和 AI 對齊之間的分歧。AI 寒冬的後果是什麼？它阻礙了機器學習的進展，使人們對機器學習的發展前景變得悲觀而絕望。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>當時，計算機的運行速度十分緩慢，在這種情況下，機器學習難以取得任何成就，傳統的符號 AI 成為唯一可用的 AI，在 70、80 甚至 90 年代，符號 AI 主導了 AI 領域。在計算機如此緩慢的情況下，符號 AI 是唯一的選擇。這種情況給 AI 領域造成了極大創傷，人們對 AI 的發展普遍持悲觀態度。當時，AI 要取得進步是一件十分困難的事，因此，任何進步都值得讚揚。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>人們對 AI 的悲觀態度持續了很長時間，即使到了 2010 年代初期，這時早期深度學習已在視覺和語言等多個任務上取得了進展，但人們對 AI 的悲觀情緒卻仍在持續。我也是悲觀者之一，在我看來，儘管 AI 已經發展到了一定程度，但這些都是暫時的，發展一定會停滯，AI 寒冬終將捲土重來。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>上述情況導致了 AI 領域的分道揚鑣，由此形成了 AI 對齊和機器學習兩個領域。在 AI 對齊領域，人們可以盡情發揮想象力，就超級智能和 AI 提出最大膽的問題，想象 AI 在何種情況下會變得更好或更糟。而機器學習雖然對神經網絡和一些之前的成果（如支持向量機）非常熟悉，但它只能勉強分類分辨率很低的數字。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>面對這兩種截然不同的情況，人們自然無法將 AI 對齊和機器學習聯繫在一起，AI 對齊似乎太過瘋狂，與機器學習的現實差異太大。但上述看法只適用於 90 年代或上世紀初，現在已經過時。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>眾所周知，AI 在 2010 年代獲得了飛速發展，在視覺識別、翻譯、摘要生成、遊戲對戰以及圍棋等領域取得了驚人成果，此外，圖像生成、聊天機器人等技術也逐漸成為現實。AI 近年來的發展好比是一輛高性能汽車，從 0 碼提速到 60 碼只需兩秒。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p><span><img height="auto" src="https://oscimg.oschina.net/oscnet/b11689e2-b136-4de4-9838-a26561bd1e62.png" width="auto" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>上面這張漫畫在 Twitter 上經常出現，生動地描繪了機器學習的現狀：要麼發展過慢，要麼發展過快，中間只有短暫的過渡，就像美國東海岸的夏天。</span></p><p style="color:#494949">&nbsp;</p><span id="OSC_h2_3"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">3</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">讓 AGI 安全成為主流</span></strong></span></p><p style="color:#494949; text-align:left">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>現在，通用人工智能（AGI）不再是一個暗淡無光的詞彙。阿瑟·C·克拉克（Arthur C. Clarke）在他的《未來的輪廓（Profiles of the Future）》一書中探討了原子能、火箭和航天飛行三個重要的技術革命。在每個技術革命取得突破前不久，總會有專家以堅定的口吻聲稱該技術是不切實際的，永遠不可能成為現實。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>目前，AGI 也面臨着相似的情況，這種現象十分有趣。儘管 AGI 在某些方面仍然有着令人難以想象的地方，但它正在逐漸變為現實。消除或進一步減少《未來的輪廓》中描述的一個問題是：<strong>想象力缺失</strong>。正是因為缺乏想象力，上述專家才敢斷言那些技術革命不會成為現實。想象力的匱乏導致他們在某些方面過度自信。然而，<strong>現在有大量證據表明，AI 已今非昔比，但在很多方面，我們仍受到想象力的限制。</strong></span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>希望大家能解決上述問題，使我們能夠邁出堅定的步伐，將 AGI 安全納入機器學習的主流方向。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>機器學習領域有眾多研究人員，將 AGI 安全納入機器學習主流能帶來更多益處。我們應該將 AGI 安全與基礎策略相結合，那麼為什麼要關注基礎策略？</span></p><p>&nbsp;</p><span id="OSC_h2_4"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">4</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">對齊為何重要？</span></strong></span></p><p style="color:#494949; text-align:left">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>首先是對齊。很多機器學習領域的人可能還沒有接觸過與對齊相關的概念。從基礎層面出發，我們將探討對齊面臨的問題和挑戰。即使不涉及具體的解決方案，對上述問題的探討本身就很有價值。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>我想花幾分鐘時間提出幾點論證，以強調對齊的重要性。在機器學習領域，人們可能會問，我們一直都能讓人工智能系統按照我們的意願工作，為什麼這會發生改變呢？</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>接下來，我們將探索不同的 AI 範式，並探討為何對齊可能會變得更難或更容易。</span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><span id="OSC_h3_5"></span><h3>&nbsp;</h3><p><span><strong>監督學習</strong></span></p><p style="color:#494949; text-align:left">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>在監督學習中，我們使用由人類標註者生成的數據集進行訓練，在語音識別中，我們使用人類標註者對語音進行標註；在機器翻譯中，有人類譯員對語音進行翻譯；在視覺識別中，我們會訓練神經網絡來模仿由這些數據產生的行為。</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>在這些情況下，數據理解對我們來説相對容易。我們對這些數據有很多見解，因此，當我們利用已充分理解的數據進行監督學習時，可以不用太擔心訓練結果。</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><strong><span>無監督學習</span></strong></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>無監督學習與上述情況有所不同，原因如下：當我們在大量互聯網數據上對神經網絡進行預訓練時，我們知道神經網絡獲得了一些與語言和世界相關的知識。然而，我們對它們所學知識的理解相對有限，不能確定它們究竟學到了什麼。</span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><p><span><img height="auto" src="https://oscimg.oschina.net/oscnet/c68c28d5-a841-4b24-b1c6-a4dcaa58b070.png" width="884" referrerpolicy="no-referrer"></span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>由於我們對神經網絡的行為瞭解較少，難以讓神經網絡實現我們所期望的行為。實證表明，這些模型仍然存在編造內容的情況。這一點很重要，如果這一點微不足道，模型就不會編造內容。</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>因此，與簡單的監督學習中的語音識別、計算機視覺等任務不同，無監督學習面臨着新的困難，這些困難可能以一種出乎意料的方式給我們感到驚訝。</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>這一點在 Sydney（微軟 Bing 搜索的生成式 AI 聊天機器人）上表現尤為明顯。Sydney 具有豐富的個性，這並不完全符合 Bing 創建者的最初意圖。在現實世界中，有更多的經驗證據表明，一旦開始無監督學習，情況就會變得更為複雜。</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>當然，問題的關鍵在於，<strong>AI 系統的性質以及對齊的難易程度會隨着範式的改變而改變</strong>。第二個範式是強化學習。</span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><span id="OSC_h3_6"></span><h3>&nbsp;</h3><p><span><strong>強化學習</strong></span></p><p style="color:#494949; text-align:left">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span>如今，強化學習已成為正在構建的聊天機器人中不可或缺的一部分。在預訓練之後，會啓動強化學習階段，通過某種（或一組）獎勵函數進行訓練。或許我們可以通過機器學習來具體説明。</span></p><p>&nbsp;</p><p><span><img height="auto" src="https://oscimg.oschina.net/oscnet/1d704e93-a168-4b05-8b97-50077f390146.png" width="894" referrerpolicy="no-referrer"></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>在某種程度上，我們確實可以做到這一點，並且還能取得不錯的效果，儘管我們確實會遇到早期對齊思考者假設的過度優化問題。例如，優化獎勵函數或者優化從人類教師那裏學到獎勵模型可能會非常容易，但我們也很容易就會學到一些意料之外的東西。強化學習的過程非常複雜，事實上，強化學習還具備一定的創造性。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>儘管我們可以快速解決過度優化問題，但強化學習面臨着更為關鍵的挑戰：創造性。在 AI 領域，每一個令人驚歎的創新都源自於強化學習。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>例如，AlphaZero 通過強化學習發明瞭一種全新的遊戲策略，人類打磨完善這個遊戲已經有數千年。強化學習能夠針對問題提出創造性的解決方案，而這些方案可能是我們所無法理解的。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p><span><img height="auto" src="https://oscimg.oschina.net/oscnet/61a3141f-7db3-4f5f-8ca1-dd91728e8160.png" width="890" referrerpolicy="no-referrer"></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>如果 AI 在與真實世界進行互動時，同時以我們認為有益的結果為目標，並展現出極高的創造力，那麼在中長期時間跨度上進行強化學習，會帶來怎樣的結果？</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>這個問題確實存在，但並不意味着它無法解決。事實上，這表明一些相對簡單的方法可能會受到一些出人意料的創造性影響，使得 Sydney 的「花招（antics）」變得合情合理。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><span id="OSC_h2_7"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">5</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">AGI 與超級智能</span></strong></span></p><p style="color:#494949; text-align:left">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>最後，讓我們盡情展開想象，來探討通用人工智能這一終極目標。當你編程的 AI 輸出了成千上萬行的代碼時，會發生什麼？這將是一個龐大程序。你可以進行一些單元測試，甚至可以與這個程序交互。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>這是一個全新的、亟待解決的問題，即確保 AI 系統輸出的十萬行代碼內部不包含任何可疑內容。我們希望努力控制這些代碼的生成過程。然而，這也帶來了另一個全新挑戰。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="color:#494949; margin-left:8px; margin-right:8px; text-align:left"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/cd842176-5534-482e-af69-3875bd5c5d9d.png" width="894" referrerpolicy="no-referrer"></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>這個問題並不簡單。當我們無法理解 AI 的輸出，而且它具備強大的創造力及實際行動能力時，訓練 AI 或理解其行為並不容易。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>現在，想象一下，如果你擁有一個能夠管理一家公司或實驗室的 AI，會發生什麼？</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>最後一個問題有關欺騙（deception），順便提一下，這對於那些有嚴格的機器學習背景的人來説是一個更有趣的想法。如果有這樣一個人工智能，它非常智能，在訓練過程中展現出了高超的醫療能力，但實際上，這個 AI 更想成為一名 YouTuber（視頻號博主），這時會發生什麼？</span></p><p>&nbsp;</p><span id="OSC_h2_8"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">6</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">結語</span></strong></span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><p><span><img height="auto" src="https://oscimg.oschina.net/oscnet/611cf61d-fe79-4185-a32f-9e352f70a227.png" width="900" referrerpolicy="no-referrer"></span></p><p style="color:#494949; text-align:left">&nbsp;</p><p style="color:#494949; text-align:left">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span>總的來説，<strong>通用人工智能和超級智能有可能出現，而且可能將在短期內實現。</strong>雖然很難給出確切時間點，但相關進展確實發展得非常迅速，因此我們不應該侷限於現有觀念，不應該對其潛力設限。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>AGI 將產生極其巨大（Mega gigantic）的影響，實際上，「極其巨大」只是 AGI 影響力的保守下限而已。面對這樣一項影響深遠的技術，誰也無法預測接下來會發生什麼，一切皆有可能。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>話雖如此，但至少在技術層面上，我們可以提供一定的保證，確保問題是出在人類操作上，而不是出在技術本身的行為上。這是我們可以追求的一個相對較低的基本目標。</span></p><p style="margin-left:8px; margin-right:8px"><span>&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span>當前的一個具體目標是，我希望讓更多的人對 AI 對齊和機器學習有一個更加統一的認識。目前，這兩種想法可能存在一些脫節之處，將它們聯繫起來並賦予更加完整的內涵具有非常重要的意義。這是我關於 AI 的未來願景，希望通過討論、交流等活動，這一願景終能成為現實。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p><span style="background-color:#ffffff; color:#888888">其他人都在看</span></p><span id="OSC_h3_9"></span><h3>&nbsp;</h3><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492023%26idx%3D1%26sn%3D28acd01925189816397de2317040f71e%26chksm%3Dfe426f81c935e697cacc74133e02923089df26cd8b2b07efd0e08d7a5ee2c9ca98d1a913f9cd%26scene%3D21%23wechat_redirect" target="_blank">Torch.FX 調研和實踐</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492022%26idx%3D1%26sn%3D4c2dc51a0f57494539e2d0dae4e8356b%26chksm%3Dfe426f80c935e696b204053faad502b81a5aecf14c3ff804281f8f02bbc215519a3a2ac9627e%26scene%3D21%23wechat_redirect" target="_blank">揭祕編碼器與解碼器語言模型</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491908%26idx%3D1%26sn%3D208a592f66f2cb2f412f9b58bca87401%26chksm%3Dfe426f72c935e6641a14837bb0a600bcbf28b9b2d427ca01477b492cfff2116aafedfd66c900%26scene%3D21%23wechat_redirect" target="_blank">通俗解構語言大模型的工作原理</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492001%26idx%3D1%26sn%3D8ee2ef77916c2992f570c294adc1ec19%26chksm%3Dfe426f97c935e6819fbd0cad4ca972da01c1ba40baef933db2a3eadfaed12a7605444ad86132%26scene%3D21%23wechat_redirect" target="_blank">PyTorch 創始人：開源成功的方法論</a></p></li></ul><span id="OSC_h3_10"></span><h3>&nbsp;</h3><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491882%26idx%3D1%26sn%3D7fabac6b07025d2e4e3a5db652bdab69%26chksm%3Dfe426f1cc935e60a8e203870b2ad09e2f2c9c0a48d1b6b9f826f70270875672d26e3775bf272%26scene%3D21%23wechat_redirect" target="_blank">大模型的無限上下文與數據集組合藝術</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491988%26idx%3D1%26sn%3Dc5fcc5f3fa27bb00bf8ef9af05e7ca89%26chksm%3Dfe426fa2c935e6b4ebb279bf19471f39629ccfb6733e6d8a580fdcbb01e80bd59266f3830bac%26scene%3D21%23wechat_redirect" target="_blank">OpenAI 首席科學家：通向無監督學習之路</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491935%26idx%3D1%26sn%3D9535636ca06c16345b432a9de5383f1e%26chksm%3Dfe426f69c935e67f717ca8a968b9dd2a3f69b45f330b561b3584ba1b196149c8ba00d3d452eb%26scene%3D21%23wechat_redirect" target="_blank">OpenAI 對齊負責人：「駕馭」超級智能四年計劃</a></p></li></ul><p><strong><span style="background-color:#ffffff; color:#3f3f3f">試用 OneFlow: <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank">github.com/Oneflow-Inc/oneflow/</a></span></strong></p><span id="OSC_h2_11"></span><h2 style="margin-left:8px; margin-right:8px">&nbsp;</h2><hr><p><img src="https://oscimg.oschina.net/oscnet/b9e4aa67-9b84-4baa-a70c-946f51bb7cde.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br> 如有侵權，請聯繫 support@oschina.cn 刪除。<br> 本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 10:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10110063</guid>
            <link>https://my.oschina.net/oneflow/blog/10110063</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「AI 教父」 Geoffrey Hinton：智能進化的下一個階段]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><img class="rich_pages wxw-img" data-backh="316" data-backw="562" data-ratio="0.5625" src="https://oscimg.oschina.net/oscnet/3bc6c0c6-c96c-4806-b20b-562276f8c0c3.png" data-type="png" data-w="1024" height="auto" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;white-space: normal;color: rgb(73, 73, 73);font-size: 11pt;letter-spacing: 1px;text-align: left;width: 100%;height: auto;" width="1024" referrerpolicy="no-referrer"></span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">來源 |&nbsp;The Robot Brains Podcast</span></strong><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><span style="font-size: 16px;letter-spacing: 2px;"></span></span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">OneFlow 編譯<br></span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">翻譯&nbsp;|&nbsp;楊婷、賈川</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 等大模型帶來的震撼技術革新，讓 Geoffrey Hinton 突然改變了自己的一個想法。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><section style="margin-left: 8px;margin-right: 8px;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488379%26idx%3D1%26sn%3Dcc53a2d76d08117366f992257e538cb7%26chksm%3Dfe419d4dc936145be634fe27e4f1c4bb12db8297a3f6faab799134f95ec8372e48e436e0116f%26scene%3D21%23wechat_redirect" textvalue="這位 75 歲的「深度學習教父」" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" style="font-size: 16px;letter-spacing: 2px;" data-linktype="2"><strong><span style="font-size: 16px;letter-spacing: 2px;">這位 75 歲的「人工智能教父」</span></strong></a><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">意識到，數字智能優於生物智能的進程無法避免，超級智能很快就會到來，他必須要對其風險發出警示，而人類需要找到一種方法來控制 AI 技術的發展。而在此之前，他一直認為，智能機器人不會像人類一樣聰明，不會朝着 AGI 的方向發展。</span></section><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><section style="margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">為了自由探討 AI 風險，Hinton 最近辭任 Google 工程副總裁，今年正是他在那裏工作的第十年。十年前，他與兩位學生 Alex Krizhevsky、</span><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491133%26idx%3D1%26sn%3D1e967f1c657f8781f8d876515047e5d5%26chksm%3Dfe41900bc936191d7756b74d23c85acba6e8b14f6e4c7ea48033b3959cb43011a9a2d81e0dee%26scene%3D21%23wechat_redirect" textvalue="GPT-4 創造者：第二次改變 AI 浪潮的方向 Ilya&nbsp;Sutskever（OpenAI 首席科學家）" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" style="font-size: 16px;letter-spacing: 2px;" data-linktype="2"><strong><span style="font-size: 16px;letter-spacing: 2px;">Ilya&nbsp;Sutskever（OpenAI 首席科學家）</span></strong></a><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">成立的三人組公司 DNN-research 以 4400 萬美元賣給了 Google，「天價」收購源自他們當時提出了震動業界的 AlexNet，它後來被視為新一輪深度學習的黃金時代的標誌，並且極大推動了 AI 領域的發展。</span></section><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">十年來，人工智能領域的眾多驚人突破背後都離不開深度學習，它是使得 ChatGPT、AlphaGo 等得以面世的基石。而 Hinton 作為深度學習領域眾多開創性突破的研究者，他的論文總共被引超 50 萬次，2019 年，他還獲得了計算機科學領域的「諾貝爾獎」——圖靈獎。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">功成名就之後，當他看着當前 AI 領域的顛覆式變革，卻也憂慮 AI 的黑暗面，聲稱自己有點後悔之前推動的 AI 研究工作，因為他幫助開發的技術可能會終結人類文明。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">近期，在與強化學習大牛 Pieter Abbeel 的一次對話中，他詳細解釋了為什麼要在此時呼籲重視 AI 的潛在風險，以及數字智能進化帶來的挑戰，但他認為，暫停開發 AI 的想法是幼稚的，最重要的是對 AI 技術開發過程進行監管。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">不過，對於如何通過技術解決 AI 對齊等挑戰，Hinton 自嘲自己「廉頗老矣」，不適合做相關技術工作，而且他更喜歡研究算法，他現在能做的是利用自己的名聲給人類敲響 AI 的警鐘。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: left;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">（以下內容經授權後由 OneFlow 編譯發佈，譯文轉載請聯繫 OneFlow 獲得授權。來源：</span><em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">https://www.youtube.com/watch?v=rLG68k2blOc&amp;t=206s</span></em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">）</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 24px;color: rgb(246, 171, 0);">1</span></strong></p><span id="OSC_h3_1"></span><h3 style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">警惕 AI 的風險</span></strong></h3><p><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Pieter Abbeel：5 月 1 日，《紐約時報》頭條報道了你已從 Google 離職的消息，你還提醒人們要警惕 AI 可能帶來的負面影響。從事 AI 研究多年，你為什麼現在突然改變了對 AI 的態度？</span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">50 年來，我一直在研究大腦是如何學習的：通過使用人工神經網絡在數字計算機上製作模型，以及試圖弄清楚如何讓這些模型進行學習。我堅信，要使數字模型更好地工作，就必須讓它們更像大腦，但最近，我突然發現，<strong>與大腦相比，在數字計算機上運行的反向傳播算法可能是更好的學習算法。</strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">原因如下：一年前發佈的 PaLM 可以理解笑話的有趣之處，讓我很是震驚，因為這是我長期以來判斷模型是否智能的標準。然後又出現了 ChatGPT 和 GPT-4 等模型，其能力給人們留下了深刻印象。人類大約有一千萬億個權重，這些模型只有大約一萬億個權重，但它們掌握的知識卻遠超人類，是人類的一千多倍，這表明，反向傳播在將大量信息壓縮到少量連接中很有優越性，僅使用數萬億個連接就能容納大量信息。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">之前，我認為大腦可能有更好的學習算法，但現在不禁開始重新思考，數字系統可能具有大腦所沒有的優勢，即可以在不同硬件上運行許多相同的模型。當其中一個副本學習到新知識時，它可以通過傳遞權重變化的方式將這些知識傳達給其他副本，傳輸的帶寬可以達到數萬億位。然而，對於人類而言，如果我們想要將學習內容傳達給他人，那麼被傳輸者可能需要改變權重，以便能夠與他人達成一致，並且每個句子只有幾百位的寬帶。相比人類，也許數字系統更擅長獲取知識，它們可以利用並行更好地工作。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Pieter Abbeel：從概念上看，似乎現有的預測下一個單詞的 AI（ChatGPT 等語言模型）與目標導向型 AI（AlphaGo 等）之間仍有較大差距。也許我們能快速彌合這兩類 AI 之間的差距，但與預測型 AI 相比，目標導向型 AI 仍處於相當封閉的環境中，未來我們是否會快速從預測型 AI 轉向目標導向型 AI？</span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);"><br></span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">語言模型的學習方式不僅僅是基於下一個單詞的預測，雖然這是它的主要學習方式，但同時也使用<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491655%26idx%3D1%26sn%3D0252d13c16303db3fb9fea41235566a2%26chksm%3Dfe426e71c935e7672557634df9cbebb85c11eca56f8e94c37215a0b6ef2a96066bc68adbde3c%26scene%3D21%23wechat_redirect" textvalue="人類反饋的強化學習" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><strong>人類反饋的強化學習（RLHF）</strong></a>進行訓練，可以告訴模型應該給出何種答案，不過這與預測下一個單詞有很大的差別。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類反饋的強化學習正在塑造 AI，OpenAI 在這方面取得了極大突破。他們意識到，可以通過人類反饋強化學習引導大型語言模型的行為方式，這就好比是養育孩子：孩子們可以通過探索世界、觀察世界的運轉模式進行學習，在這個過程中，父母可以通過告訴孩子能或不能做什麼參與到孩子的學習當中。長期以往，父母可以在更少參與的情況下對孩子的行為產生極大影響。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">還有其他因素在塑造語言模型。多模態大型語言模型可以利用視覺輸入做一系列事情，比如開門、將東西放進抽屜等等。所以，它們不僅僅是預測下一個單詞。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">不過，即使模型只是預測下一個單詞，也沒有人們想得那麼簡單。有人認為，模型預測下一個單詞只是在自動補齊，但關鍵是想要預測下一個單詞，唯一的方法是要真正理解前文內容，而這正是語言模型所做的。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：也就是説，模型需要有效理解人們的所思所想，以最大限度準確預測人們將要説的內容。這種模型必須十分強大。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">最好的預測模型就會像你説的那樣。這種模型可能無法完全理解人們的所思所想，但能理解大部分內容，並且它們的理解程度會與日俱增。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">回看 2015 年，那時 Transformers 架構還未現世，人們對聊天機器人毫無頭緒，現在，語言模型的能力已十分強大，難以想象未來五年它們會發展到何種程度。我不禁開始擔憂 AI 的智能程度將超過人類。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Pieter Abbeel：你怎麼定義「（AI）比人類更智能」？</span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">AI 在單個領域中的表現中有所體現。比如我不玩圍棋，也不瞭解 AlphaGo，但會一點點象棋。在我看來，AlphaZero 的強大不僅來自計算量（它的計算量還比不上 DeepBlue），還因為它有極好的下棋「意識」：AlphaZero 能在下棋過程中作出合理的犧牲與讓步，下棋技術超過了人類。AI 技術的高度發展不會僅侷限於這一個領域，它們戰勝人類靠的不僅是計算量，還有極好的「意識」。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Pieter Abbeel：你一直在嘗試構建 AI，現在成為這個行業的先驅。AI 的發展程度已經遠超你最初的預想，曾經你希望 AI 能達到與人類匹敵的智力水平，但現在可能找到了超越人類智能的方法。</span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我還想了解大腦的運轉方式，目前我們還未解開這一謎題。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我們一直在談論 AI 面臨的各種問題，比如如果我們利用有偏見的數據訓練模型，那麼模型就會同樣具有偏見，但我並不特別擔心這個問題，因為人類也存在偏見，實際上，AI 系統的偏見問題比人類的偏見更好解決。我們可以「凍結」AI 系統，進行實驗分析，但人類卻難以做到這一點，在實驗中，人類可以隱藏想法並改變他們的行為。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">雖然隨着 AI 的發展，有很多人會失業，但這並不是 AI 的錯。就拿自動駕駛來説，很多卡車司機會因此失去工作，有人認為這是 AI 的錯，不過當我們創造了更擅長挖掘的機器時，人們卻不會説「這些機器不好，我們不應該創造它們」。實際上，當時的機器一開始可能確實不太好用，但結果我們選擇了機器，因為機器比鏟子做得更好，而之前習慣於用鏟子挖掘的工人只好轉業，重新找工作。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在正派社會（Decent Society）中，提升工作效率是一件人人受益的事情。問題是，目前社會上提升工作效率可能會拉大貧富差距，讓富人更富，窮人更窮，但這並能怪 AI，我們沒有理由像勒德分子（持有反機械化以及反自動化觀點的人）一樣反對 AI 的發展，因為 AI 的發展能給人類社會帶來極大好處。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在自動駕駛領域，如果 AI 駕駛撞到了行人，大眾會感到恐慌，並且呼籲停止發展 AI 技術，即使是同一天裏，人類駕駛員撞到行人的事故更多。其實我們都知道，最終自動駕駛技術會發展成熟，會極大減少事故發生率，比人類能更好地勝任駕駛工作。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在醫學方面，AI 擁有更多知識儲備，能夠充當家庭醫生，能從醫學掃描圖像中看出更多信息，醫生也能在 AI 解讀的基礎上完善診斷結果。現在，在蛋白質結構預測方面，AlphaFold 出色地完成了任務，極大地節約了預測成本，如果這一預測任務由博士生們以傳統方式進行，足以支付大部分 AI 的費用。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">AI 的積極影響還有很多，<strong>我們需要知道，在一定程度上，人類能夠做的任何事 AI 都能更高效地完成。</strong>鑑於 AI 具備的強大能力，人類決不會放棄發展 AI。但與此同時，我也開始擔憂它們可能會帶來的負面影響。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：現在人們聽到 AI 一詞時，出現在腦海中的第一個問題就是：如果 AI 的智能程度超過人類會發生什麼，是否會對人類造成威脅？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">顯然，我們希望將 AI 保持在可控範圍內，但掌控超越自己智能水平的東西並非易事。人類是經過進化的生物，有一些強大的目標，比如認真保養身體、吃足夠的食物等等，可 AI 並沒有這些目標。對此，我們可以設置目標並將其植入 AI，讓 AI 圍繞人類的利益工作。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">不過這種方式也可能出現各式各樣的問題，以不良用途為例。如果國防部構建出機器人士兵，那麼這些士兵並不會遵守阿西莫夫原則（阿西莫夫第一原則是：機器人不得傷害人類個體，相反，它們要保護人類）。此外，我們還面臨對齊問題，如果賦予 AI 創建子目標的能力（比如我們想去機場，那麼可以創建一個總目標——找交通工具，然後再創建子目標，也就是將任務分解為幾個小目標），可以極大地提升效率。我認為，我們會選擇賦予數字智能創建子目標的能力，但問題是，如果 AI 創建了對人類有潛在不利影響的目標怎麼辦？</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">為了應對這一問題，人們通常會設置子目標，以實現對 AI 的更多掌控權，這也意味着我們可以更好地實現其他目標。不過矛盾的是，我們一旦賦予 AI 設置子目標的能力，那麼它們其中一個子目標就會獲得更多控制權，但這又與我們不想讓它們獲得更多控制權的意願背道而馳。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);"><br></span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Pieter Abbeel：最大的問題是，<strong style="letter-spacing: 0.578px;white-space: normal;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">現在</span></strong>很多人擔心 AI 將控制世界。</span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這確實是一大威脅。以前，我認為距離 AI 控制世界還很遙遠，可能需要幾十甚至上百年時間，<strong>但現在我認為可能只需 5-20 年。</strong>一旦 AI 比人類聰明，那麼就會面臨一個問題：到底是 AI 控制世界，還是我們控制 AI？</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我們正在進入一個有極大不確定性的時期，將與超越人類智能的事物進行互動，而且沒有任何經驗可供參考，我真的不知道未來會如何發展。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">最近，我和馬斯克進行了一次談話，他認為我們會開發出比人類更聰明的事物，但他希望它們讓人類存續，因為有人類存在的世界才更有趣。這是一種很大膽的假設，相當於將人類的命運寄託到 AI 身上，但他認為這是完全有可能的，AI 將變得更加智能並獲得掌控權。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：馬斯克設想的場景是 AI 與人類融合在一起，他的神經網絡公司（Neuralink）正在想辦法讓 AI 和大腦相結合。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">那很有趣。人類有語音輸入和輸出能力，但沒有視頻輸出能力。如果人類有了視頻輸出能力，就能通過傳達圖像進行溝通。不過這並不完全是馬斯克計劃要做的事，<strong>他想實現的是腦與腦之間的傳輸，將思維傳遞到一個相對抽象的層面。</strong>我們現在需要以一種他人能理解的方式傳輸信息。視頻輸出是一個相對不那麼宏偉的項目，現在已經有人知道該如何處理視頻，並將其作為輸入進行處理了。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">如果我們有視頻輸出能力，那麼人與人之間的溝通將得到極大改善。比如當你向我傳達信息時，你可以通過語言或畫圖，但在畫圖之前，你的腦海中可能已經有了一個圖像（可能並非總是如此，但大多數情況下是這樣）。如果你能夠迅速傳達腦海中的圖像，那將增加信息傳輸的帶寬，即使只增加一倍，也會是一個很大的提升，並且實際情況甚至可能不止一倍。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">2</span></strong></p><span id="OSC_h3_2"></span><h3 style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">「監管可能是唯一的辦法」</span></strong></h3><p><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：長期以來，一直有人呼籲對 AI 領域進行監管，馬斯克就是其中的典型，不過他並沒有明確提出具體的監管建議。你認為應該採取哪些監管措施？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人們常常將 AI 可能造成失業、偏見、政治分裂、威脅人類生存以及傳播虛假消息等各種各樣的問題這些問題混為一談，我們有必要分清所面臨的到底是什麼問題。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">就拿傳播虛假消息掩蓋真相來説，如果我們被虛假的東西包圍，那麼所面臨的境況會是多麼艱難。政府一直都在嚴厲打擊製造假鈔行為，如果有人給你假鈔，而你在明知是假鈔的情況下還拿去消費，這也是違法行為（即便不如製造假鈔嚴重）。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">因此，對於 AI 生成的內容，我們也要想辦法對其進行標記，如果有人在明知是虛假內容的前提下將其假冒為真，就應該受到嚴厲的法律處罰。現在能否很好地對真假內容進行檢測是另一回事，但至少我們要朝着這個方向前進，加強監管，避免被假象淹沒。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：我贊同你的觀點。不過制定規則可能比較容易，但實際執行也許會比較困難。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">為什麼執行會很困難？假設使用深度學習來幫助檢測虛假內容，我們構建了一個能夠檢測偽造品的 AI 系統，但其實利用這種系統能訓練 AI 生成更加逼真的假冒產品，這也是 GAN 模型的工作原理。因此，我們不能指望 AI 系統檢測出虛假內容。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Pieter Abbeel：對 AI 生成內容進行加密是否可以解決這個問題？比如對 AI 生成的內容添加加密簽名，顯示內容的作者，然後將作者身份和聲譽與內容的可信度聯繫起來。如果作者在內容中添加了虛假信息，他的聲譽就會受到損害。</span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">英國曾經就這樣做過，甚至現在可能還是這樣：無論你印刷什麼東西，即使是小型示威的宣傳冊，都必須在上面印上印刷者的身份，未印刷身份信息是違法的。雖然我對密碼學和加密技術一無所知，但這種想法聽起來十分合理。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Pieter Abbeel：雖然監管可能難以實施，但從原則上講，還是有一個明確的框架來避免人們被假新聞、假視頻和虛假文字所誤導。</span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">為避免引發政治分裂，我們還可以對標題黨（Clickbait）進行監管。Facebook、YouTube 等社交媒體常常會對用戶推送一些產生迴音室效應的內容，這種過度的信息過濾和選擇性接觸可能導致人們極端化，加劇社會、政治分裂。這也是我不願再為 Google 工作的原因之一。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我們可以通過立法來阻止這種行為，雖然很棘手，但至關重要。如果想要維持民主，避免羣體分裂，互相仇視，就需要採取措施監管媒體公司，避免這些公司推送可能激化矛盾的內容。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：幾周前，有人呼籲暫停訓練比 GPT-4 更大的模型，你怎麼看？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">從政治上看，這封呼籲信或許是明智的，因為它引起了人們對 AI 安全的關注。但這種呼籲其實很愚蠢，所以我沒有在呼籲信上簽名。即使美國暫停訓練 AI，中國不會暫停，俄羅斯也不會暫停，所以這是不現實的。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">對於這個問題，我贊同 Sam Altman 的看法：面對這些技術可能帶來的潛在風險問題，由於我們無法阻止其發展，所以最好的方式是大力開發它們，在開發過程中學會更好地理解和控制它們。就像寫程序一樣，坐而論道是不行的，我們必須行動起來，進行實驗和調試，以瞭解可能發生的情況。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在大力發展 AI 的同時，我們應該着力於解決潛在的負面影響，避免失控，我們必須非常嚴肅地對待這個問題。<strong>當前投入資金的 99% 都用在了開發上面，只有 1% 用於安全方面，我認為今後這個比例應該五五開。</strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：從學術角度看，用於 AI 研發和安全的資金比例達到五五開是可能的，資助機構只需在申請要求上加上這一點即可。但私企基本都是利益驅動，更注重開發能帶來更多利潤的產品，他們願意把一半的資金放在安全問題上嗎？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我只是一名科學家，並非政策專家，只能注意到可能發生的事情。其實 Google 在這方面還是相對負責任的，在研發出 Transformer 之後，他們在這一領域處於領先地位，之後又研發出了聊天機器人，但並沒有急於將其推向市場，因為他們意識到聊天機器人可能會產生很多負面影響。但當微軟資助 OpenAI 並在必應中使用聊天機器人後，Google 別無選擇，只能努力進行工程改進，以開發出與 ChatGPT 相匹敵的 Bard。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在資本主義體系下，大公司很難有其他選擇，如果要讓他們犧牲利益，監管可能是唯一的辦法。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="letter-spacing: 2px;color: rgb(246, 171, 0);font-size: 24px;">3</span></strong></p><span id="OSC_h3_3"></span><h3 style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">數字智能優於生物智能不可避免？</span></strong></h3><p><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：在接下來的 30-50 年，我們應該把重點放在哪裏？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">就歷史演進來看，<strong>數字智能優於生物智能可能是不可避免的，數字智能可能是下一個進化階段，</strong>我們應儘可能保持 AI 處於可控範圍。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">有時我會想：如果青蛙發明瞭人類並想要控制人類，但就智力而言，青蛙和人類之間差距巨大，所以我不認為「發明人類」對青蛙來説是一件好事。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">當然，這並非真實論點，因為人類由進化而來，在向着自己的目標演進，但數字智能並沒有自己的目標。一旦數字智能有了「自我繁衍（make more of me）」這一想法，那麼進化就發生了，最有決心實現自身繁衍的數字智能將會勝出。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：如果我們想讓數字智能有這種目標，這個過程會不會很困難？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">給數字智能以「自我繁衍」的目標很容易，但這種做法十分瘋狂。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：人類今天的地位是進化的結果，或許最聰明的數字智能也會在競爭中出現。它們不是與人類競爭，而是與其他數字智能競爭。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">你可以觀察到，由於人類智能功耗很低，隨着不斷進化構建出了發電站和大量數字智能，而數字智能需要大量功耗，並提供高精度製造能力，這些數字智能是進化的下一階段，它們彼此競爭並變得更加強大。人類傾向於構建比自己智能的智能體，後者可以以某種方式替代聯合國，擔任「智能調解者（intelligent mediator）」。該智能體沒有自己的目標，我們每個人都可能按照它的安排來行事，就像孩子完全信任父母一樣。當然，這只是烏託邦式願望，但也並非沒有可能。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：從技術上講，你所説的似乎可行，但需要人類團結一致。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這種情景在理論上是可行的。但人們在沒有實際經驗的情況下進行推測，往往離真相相當遙遠。一旦獲得一些實際經驗，就會意識到自己的理論有多麼離譜，還需進行修正。因此，在技術不斷髮展的過程中，我們需要進行大量工作，瞭解其中的風險，並進行實證實驗，以觀察智能系統運行時，是否傾向於控制人類，是否會產生自我繁衍的目標等。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：短期來看，擁有能設定自我目標並執行任務的 AI 可能並非壞事。一方面我們可以利用 AI 賺錢，另一方面可以使其利用自身資源和其他資源做事。但從長期來看，這樣又可能產生滑坡效應，我們無法控制 AI 為實現自我目標而設定的子目標，以及由此可能產生意料之外的後果。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這涉及到對齊問題。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：是的，這非常困難。不過我們可以對 AI 分類，一類是那些旨在完成任務並能設定目標的 AI，另一類是純粹作為顧問的 AI，後者擁有豐富的知識和預測能力，能為人類提供建議和智慧，但它們僅僅擔任顧問一職，不參與任務執行。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這樣會非常有用。不過，僅僅不讓 AI 按下控制按鈕無法保證能消除它的潛在風險。聊天機器人能閲讀馬基雅維利（Machiavelli）的作品以及其他關於操縱的小説，從而成為操縱大師。它不需要任何實際操作，只需操縱他人，就可以實現一系列行動。假如機器人想入侵華盛頓的建築，那麼它們只需讓人們認為這是拯救民主的唯一方式即可。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">因此，一種不允許 AI 實際做任何事情，只允許與人交談的隔離措施是不夠的，如果 AI 可以與人交談，它就能操縱人類，並通過操縱人類來達到自己的目的。所以關鍵在於 AI 的內置目標。如果 AI 產生了自我繁衍的目標，那麼人類就會陷入麻煩。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：有人提出，將來我們可以讓 AI 擔任公司 CEO，在 AI 的帶領下，公司可以得到更好的發展，因為 AI 能夠更好地瞭解、掌握公司和世界的發展趨勢，作出更好的決策。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這種想法沒什麼問題。關於預測未來，就拿開車來説，人們常常在夜晚開車，遇到大霧時經常發生交通事故。開車時我們可以看到前方車輛的尾燈，尾燈亮度隨距離的平方反比衰減，一旦遇到大霧，就會隨着距離損失相應亮度。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在霧中，我們可以看到前方一百碼的情況，這時人們就會誤認為自己能夠適度地看到前一千碼的情況，但事實上我們甚至難以看清前兩百碼處的情況。前方彷彿出現了一堵牆，我們的視野將變得有限或具有不確定性。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在推斷未來事件時，人們常常使用線性或二次模型，假設變化是逐漸發生的。然而，現實情況是，未來可能呈現出指數級的變化，使得長期預測變得困難。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我喜歡《紐約時報》在 1902 年的一篇文章中寫的故事：人造飛行器將需要百萬或者甚至一千萬年才能研發出來，但實際上兩個月後飛行器就出現了。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="color: rgb(246, 171, 0);"><span style="font-size: 16px;letter-spacing: 2px;">Pieter Abbeel</span></span><span style="color: rgb(246, 171, 0);"><span style="color: rgb(246, 171, 0);font-size: 16px;letter-spacing: 2px;">：</span><span style="color: rgb(246, 171, 0);font-size: 16px;letter-spacing: 2px;">你説，生物進化也許只是一個起點，接下來可能是基於計算機的數字進化或其他形式的進化。假設未來存在一種數字生命形態，在某種程度上比當今人類更具統治地位。這種數字生命體可能對人類、其他生物和周圍的一切都很友好，但也可能會摧毀一切。那麼我們是否需要考慮確保它往好的方面發展？</span></span></strong></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;"><br></span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這絕對值得考慮。數字生命體將會是非常不同的存在，它們不需要擔心死亡。人們可能還未真正注意到這一點，但實際上我們已經發現了計算機科學領域中永生的祕密：將軟件與硬件分離。人工神經網絡就是如此，如果某個硬件損壞了，知識並不會消失，權重可以記錄在某個地方，只要有另一塊能夠執行相同指令的硬件，知識就能「復活」。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類的學習算法似乎利用了大腦連接（wiring）和神經元工作的所有特殊方式，這使其在能源效率上更加高效。但也意味着硬件死亡時，知識會隨之消失，除非將其傳遞給其他人。例如，Ray Kurzweil 希望獲得永生，但他作為生物體不會實現。不過，也許人類永生之後，會變得友善一點。</span></p><p style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></strong></p><p style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">4</span></strong></p><span id="OSC_h3_4"></span><h3 style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">「退休」計劃</span></strong></h3><p><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="color: rgb(246, 171, 0);font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：你是否會繼續宣傳 AI 發展存在的風險？還是現在人們已經意識到這個問題，你的任務已經完成了？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我也不知道。我沒有想到會引發這麼大的反響，也還沒有仔細想過接下來會發生什麼。估計我會繼續思考如何控制這個問題，偶爾發表一些演講，鼓勵人們去解決對齊問題。但我不會全身心投入到這些事情上，相比之下我更喜歡鑽研算法，接下來我可能會繼續研究 forward-forward 算法及相關算法，這是我更擅長的事。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="color: rgb(246, 171, 0);font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：一方面強調對齊的重要性，另一方面又想了解大腦的運作方式，這兩者之間是否存在矛盾？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">理解大腦的運作方式不會有什麼問題，真正會帶來麻煩的是構建比大腦更強大的東西。如果我們能更好地理解人類，就能夠使社會變得更好。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="color: rgb(246, 171, 0);font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：你對 AI 研究人員或希望為這個領域做出貢獻的人有什麼建議？</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(246, 171, 0);">Geoffrey Hinton：</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">可以嘗試與最先進的聊天機器人互動，以便更深入地理解其智能程度和工作原理。雖然我們知道它的基礎是 Transformer 模型，但目前我們並不完全清楚模型是如何完成推理任務的。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">此外，我們應該關注如何在 AI 的發展過程中對其進行控制。當然，我並不是 AI 對齊方面的專家。隨着超級智能可能很快到來，我的任務是敲響警鐘，讓人們意識到這方面的問題。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="color: rgb(246, 171, 0);font-size: 16px;letter-spacing: 2px;">Pieter Abbeel：離開 Google 後，你應該有大量時間去做自己喜歡的事。</span></strong></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="color: rgb(246, 171, 0);"><strong><span style="font-size: 16px;letter-spacing: 2px;">Geoffrey Hinton：</span></strong></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在 Google 工作時，同事經常討論工作與生活的平衡，但由於工作太忙，我從未參與類似的研討會。前 50 年我都在忙於工作，錯過了很多好電影，接下來我想在 Netflix 上把錯過的電影都看一遍，並且儘量多陪陪我的孩子，儘管他們已不再是小孩了。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">卡內基梅隆大學的 Allen Newell 曾給他的研究生説：如果每週的工作時間少於 80 小時，那麼你就不是一名合格的科學家。我並不贊同這種説法，現在我打算平衡一下工作和生活，這並不意味着我會停止做研究，即使我不再像以前一樣在研究上花大量時間，但研究本身還是很有趣。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><section style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 1px;background-color: rgb(255, 255, 255);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">其他人都在看</span></section><span id="OSC_h3_5"></span><h3 style="letter-spacing: 0.578px;white-space: normal;"><ul class="list-paddingleft-1" style="width: 577.422px;"><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491667%26idx%3D1%26sn%3D77c165742d362ecbb82db832f4a06735%26chksm%3Dfe426e65c935e773145d2561f984f9a3082a7e61f187f175b5d2315a6f09511acac838c2755d%26scene%3D21%23wechat_redirect" textvalue="關於大型語言模型的爭論和侷限" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">關於大型語言模型的爭論和侷限</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491538%26idx%3D1%26sn%3D99ceba3fe2ddde6efd101bbf23374969%26chksm%3Dfe4191e4c93618f2fc63bbd92cd93ffe85b9db24fd71b864d293ea930e8e6527cecbadd8f4d9%26scene%3D21%23wechat_redirect" textvalue="John Schulman：強化學習與真實性，通往 TruthGPT 之路" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">John Schulman：通往 TruthGPT 之路</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491538%26idx%3D1%26sn%3D99ceba3fe2ddde6efd101bbf23374969%26chksm%3Dfe4191e4c93618f2fc63bbd92cd93ffe85b9db24fd71b864d293ea930e8e6527cecbadd8f4d9%26scene%3D21%23wechat_redirect" textvalue="John Schulman：強化學習與真實性，通往 TruthGPT 之路" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491548%26idx%3D1%26sn%3D45c78ba578e450e1ad81f5ca89bd0e31%26chksm%3Dfe4191eac93618fc92cb3bc221f407960a50c98d2aea1f94431b21b6fd7dc49cae770f5532d6%26scene%3D21%23wechat_redirect" textvalue="為什麼 ChatGPT 用強化學習而非監督學習？" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">為什麼 ChatGPT 用強化學習而非監督學習</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491548%26idx%3D1%26sn%3D45c78ba578e450e1ad81f5ca89bd0e31%26chksm%3Dfe4191eac93618fc92cb3bc221f407960a50c98d2aea1f94431b21b6fd7dc49cae770f5532d6%26scene%3D21%23wechat_redirect" textvalue="為什麼 ChatGPT 用強化學習而非監督學習？" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488734%26idx%3D1%26sn%3D5030ae3c61274ec2fa3b05aa73fe4776%26chksm%3Dfe419ae8c93613fe3a0496962b3548e58a1713d1daec14ed15f83f43cd4c7f9dd31877f623c7%26scene%3D21%23wechat_redirect" textvalue="Geoffery Hinton：深度學習的下一個大事件" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" style="font-size: 14px;letter-spacing: 1px;white-space: normal;" data-linktype="2">Geoffrey Hinton：深度學習的下一個大事件</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488379%26idx%3D1%26sn%3Dcc53a2d76d08117366f992257e538cb7%26chksm%3Dfe419d4dc936145be634fe27e4f1c4bb12db8297a3f6faab799134f95ec8372e48e436e0116f%26scene%3D21%23wechat_redirect" textvalue="Geoffrey Hinton：我的五十年深度學習生涯與研究心法" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">Hinton：我的五十年深度學習生涯與研究心法</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><section style="outline: 0px;line-height: 1.75em;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" textvalue="一塊 GPU 訓練 TB 級推薦模型不是夢，OneEmbedding 性能一騎絕塵" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="outline: 0px;cursor: pointer;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">OneEmbedding:單卡</a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" textvalue="一塊 GPU 訓練 TB 級推薦模型不是夢，OneEmbedding 性能一騎絕塵" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="outline: 0px;cursor: pointer;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">訓練 TB 級推薦模型不是夢</a></section></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><section style="outline: 0px;line-height: 1.75em;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247490555%26idx%3D1%26sn%3D280c4ac043a31170236a9d8fba5fc2d2%26chksm%3Dfe4195cdc9361cdb6db1cb3b77c66b45c353b2fb65c4d082fbae9b72fe0b3a441ab9101cb147%26scene%3D21%23wechat_redirect" textvalue="GLM 國產大模型訓練加速：性能最高提升 3 倍，顯存節省 1/3，低成本上手" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">GLM 訓練加速：性能最高提升 3 倍，顯存節省 1/3</a></section></li></ul><section style="outline: 0px;line-height: 1.75em;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;outline: 0px;background-color: rgb(255, 255, 255);letter-spacing: 1px;font-size: 14px;color: rgb(63, 63, 63);">試用 OneFlow: github.com/Oneflow-Inc/oneflow/</span></section></h3><h2 style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;"><hr style="border-style: solid;border-right-width: 0px;border-bottom-width: 0px;border-left-width: 0px;border-color: rgba(0, 0, 0, 0.1);transform-origin: 0px 0px;transform: scale(1, 0.5);"></h2><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: center;"><img class="rich_pages wxw-img" data-backh="162" data-backw="578" data-galleryid="" data-ratio="0.2802690582959641" data-s="300,640" src="https://oscimg.oschina.net/oscnet/e1b072a3-10fe-40a6-af64-bb89c12679d3.png" data-type="png" data-w="892" style="width: 100%;display: inline;height: auto;" referrerpolicy="no-referrer"></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 10:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/9025339</guid>
            <link>https://my.oschina.net/oneflow/blog/9025339</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sam Altman 的成功學]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:8px; margin-right:8px; text-align:justify"><strong><span style="color:#3f3f3f"><img src="https://oscimg.oschina.net/oscnet/8e9acd1f-b3e3-4dce-a9b1-4ff094015782.png" referrerpolicy="no-referrer"></span></strong></p><p style="margin-left:8px; margin-right:8px"><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489925%26idx%3D1%26sn%3Db6425ec3ebeaaf25b02dd40ef313e89c%26chksm%3Dfe4197b3c9361ea5bb74a162a2bd54020b0e8cf3ad09b91dce1a9c10153656cb1b4398cb2089%26scene%3D21%23wechat_redirect" target="_blank"><span style="background-color:#efefef; color:#3f3f3f">「如果把 Sam Altman 扔到某個食人族</span><span style="background-color:#efefef; color:#3f3f3f">之島，5 年後他會成為這個食人族島的國王。「</span></a></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span><span style="color:#3f3f3f">在硅谷創業教父<span style="background-color:#efefef; color:#3f3f3f">Paul Graham</span></span>的眼裏，</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489925%26idx%3D1%26sn%3Db6425ec3ebeaaf25b02dd40ef313e89c%26chksm%3Dfe4197b3c9361ea5bb74a162a2bd54020b0e8cf3ad09b91dce1a9c10153656cb1b4398cb2089%26scene%3D21%23wechat_redirect" target="_blank"><span style="color:#3f3f3f">Sam Altman</span></a><span>是一位極具魄力的領導者和開拓者。如今，已成為<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489925%26idx%3D1%26sn%3Db6425ec3ebeaaf25b02dd40ef313e89c%26chksm%3Dfe4197b3c9361ea5bb74a162a2bd54020b0e8cf3ad09b91dce1a9c10153656cb1b4398cb2089%26scene%3D21%23wechat_redirect" target="_blank"><strong>OpenAI CEO 的 Sam Altman</strong></a><span style="color:#3f3f3f">是全球範圍內當之無愧</span></span><span style="color:#3f3f3f">的科技領軍人物。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="background-color:#efefef; color:#3f3f3f">他的職業生</span><span style="color:#3f3f3f"><span style="background-color:#efefef; color:#3f3f3f">涯可謂一路開掛。</span>從斯坦福大學計算機系輟學後，19 歲的他成立了位置服務提供商 Loopt，而後被預付借記卡業務公司 Green Dot 收購，2014 年，<span style="background-color:#efefef; color:#3f3f3f">YC 創始人 Paul Graham 選擇他</span>成為繼任者，在不到 30 歲時開始在全球創業創新領域大放異彩。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f">2015 年，他與馬斯克等人共同成立 OpenAI，2019 年，Sam Altman 離任 YC 總裁，成為 OpenAI 的 CEO，並相繼領導推出重量級 AI 模型 GPT-3、DaLL-E 以及近期火出科技圈的 ChatGPT。</span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f">&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f">無論是個人才智和財富，還是遠見和野心，Sam Altman 顯然是標杆性的「成功人士」。</span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f">&nbsp;</span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f">在離任 YC 總裁的那一年，曾與無數創業者和技術人才交流過的 Sam Altman 發表了一篇博客，總結了他眼中獲得成功所要具備的 13 個特質，如果你渴求成功，或者至少希望自己變得優秀，這篇博客對你的個人成長將有所啓發。如果你恰好在職業生涯早期就看過，無疑是一種幸運。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span style="background-color:#efefef; color:#3f3f3f">不同於熱衷分享虛頭巴腦的</span><span style="background-color:#efefef; color:#3f3f3f">雞湯式</span><span style="background-color:#efefef; color:#3f3f3f">成功學</span><span style="background-color:#efefef; color:#3f3f3f">的</span><span style="background-color:#efefef; color:#3f3f3f">成功人士，Sam Altman 給出的這篇「成功學」建議具有可執行性，最顯著且可貴的一個特點是——不裝。</span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span style="background-color:#efefef; color:#3f3f3f"><span style="background-color:#efefef; color:#3f3f3f">注意，Sam Altman 這</span><span style="background-color:#efefef; color:#3f3f3f">篇文章的原標題是「how to be successful（如何取得成功）」，但這 13 條特質並不是一個人必然取得成功的充分或必要條件。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f">要知道，成功人士中不乏名聲不佳的，而且有些還往往強調自己的成功是由於擁有某些品質和才能，甚至刻意掩飾時代和機遇的影響。<span style="background-color:#efefef; color:#3f3f3f">Sam Altm</span><span style="background-color:#efefef; color:#3f3f3f">an</span>取得了巨大的成就，但會謙遜地告訴你「深深意識到的一個事實」：他能有今天是因為運氣好。</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f">願你也有好運。如果沒有，至少可以從 Sam Altman 這類頂尖人才的思考中獲得啓發，以在個人職業生涯中持續成長。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><strong><span>作者｜</span></strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489925%26idx%3D1%26sn%3Db6425ec3ebeaaf25b02dd40ef313e89c%26chksm%3Dfe4197b3c9361ea5bb74a162a2bd54020b0e8cf3ad09b91dce1a9c10153656cb1b4398cb2089%26scene%3D21%23wechat_redirect" target="_blank"><strong><span>Sam Altman</span></strong></a><br><strong><span style="color:#3f3f3f">OneFlow 編譯｜徐佳渝、楊婷</span></strong></p><p>&nbsp;</p><p><span style="color:#3f3f3f">通過大量觀察企業創始人，我思考了很多關於賺大錢或者建功立業的想法。通常，人們最開始一心只想賺錢，但最後會想有所成就。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">以下是關於如何獲得非凡成功的 13 條看法。如果你已經取得了一定成就（取得成就的途徑不限，可以通過天生優勢實現，也可以通過個人努力實現），那這些思考對你來説做起來會更加容易。[1] 其中大多數想法人人適用。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">1</span></strong></p><p><strong><span style="color:#1e2380">選擇「複利增長」</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">複利具有神奇的魔力，現在處處都在強調複利，這其中的奧祕就是指數曲線，因為指數曲線是創造財富的關鍵。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">一家中型企業的價值如果按照每年 50% 的速度增長，那麼它的規模可以在短時間內極速擴張。世界上少有企業具有真正的網絡效應和高度的可擴展性，但是隨着技術進步，這種情況會逐漸改變，這值得我們不斷為之努力。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">對個體的人生道路來説，我們也應該走成一條指數曲線，也就是説，我們要遵循不斷向右增長的人生軌跡。在進行職業規劃時，要選擇具有複合效應的職業，而大多數職業的發展軌跡都是一條線性直線。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在線性職業領域，工作二十年的效率並不會比工作兩年的效率高，像這樣的職業不利於個人發展，我們需要的是一份能保持不斷學習的職業。隨着職業發展我們需要產出越來越多的成果。達成這一目標的途徑多種多樣，比如説資本、技術、品牌、網絡效應和做管理。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">專注於將你所定義的成功指標增加十倍是有用的，這些指標可以是賺錢、社會地位、世界級影響力或者其他東西。我樂意接受挑戰，願意在各種項目上花時間以解鎖下一個項目。但是我希望在每一個項目上都能取得最大成就，創造職業生涯新高度。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">但是大多數人都被困於線性發展的泥潭，往往撿了芝麻丟了西瓜，我們要學會抓大放小，尋求跳躍式提升。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在我看來，無論是企業還是個人，最大的競爭優勢就是要把目光放長遠。我們要打開眼界，看出世界上不同體系之間交融互動的方式。複合增長最重要的就是眼光要儘可能放長遠，這樣的人才能搶佔市場先機，獲得最大回報。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">要相信指數曲線，耐心堅持下去，最後一定會有驚喜。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">2</span></strong></p><p><strong><span style="color:#1e2380">要有絕對自信</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">自信擁有不可思議的力量，就我認識的人來説，最成功的往往都是那些自信到離譜的人。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">我們要儘早樹立自信。如果你的判斷常常都很準確，能帶來很好的結果，那麼你一定要加倍自信。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">對自己不自信的人很難對未來抱有逆向思維，但是往往逆向思維才能創造出最大的價值。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">還記得很多年前馬斯克帶我參觀 SpaceX 工廠，他詳細地談到了製造火箭的一些細節，但是讓我印象最深的還是馬斯克談到向火星發射火箭時的表情，離開工廠時我就在想「啊，這就是自信的樣子」。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">對大多數創業者來説，激發自己以及團隊的士氣可以説是最大的挑戰之一，如果沒有自信，這就成了幾乎不可能完成的任務。但往往一個人越有雄心壯志，其受到的打擊就會越多。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">大多數非常成功的人在面對人們的質疑時至少有一次決定是正確的，否則他們面臨的挑戰會更多。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">我們在自信的同時也要保持清醒的自我認知，才能避免盲目自大。我曾經非常討厭受到批評和質疑，並且總是設法規避這些批評。但現在我開始嘗試聽取這些意見，我會先設想這些批評是正確的，然後在這個基礎上調整我的計劃。做決定的過程充滿了艱辛和痛苦，但也只有經歷了這個過程才能將自信和自欺欺人區分開來。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">保持自信與自我認知之間的平衡可以讓人免於傲氣、避免與他人脫節。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">3</span></strong></p><p><strong><span style="color:#1e2380">學會獨立思考</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">創業很難，因為培養原創性思維很難。這種思維在學校裏面是學不到的，實際上學校培養的是一種相反的思維方式，所以只能靠我們自己來培養原創性思維。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">我們可以從第一性原理（first principles）出發，從中想出新的點子，然後與人交流溝通，對這些想法進行改良，之後我們再用輕鬆快捷的方式進行實際測試。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">對創業者來説，失敗是家常便飯，但我們一定要抱有必勝的信念，要不斷嘗試、不斷試錯，只有這樣才能得到幸運之神的眷顧。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在這個過程中，最寶貴的經驗教訓之一就是，我們要學會在絕境中找到一線生機。我們經歷的越多就越會對此深信不疑。要知道勇氣來自於多次失敗後的堅持不懈。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">4</span></strong></p><p><strong><span style="color:#1e2380">做一個好「銷售」</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">光有自信是不夠的，我們還要具備説服他人的能力。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">就某種程度來説，所有職業的本質都是銷售。你必須向客戶、潛在職員、媒體、投資者等宣傳兜售你的計劃。想要説服他們，首先你的計劃要有廣闊的發展前景，對於個人而言，你要具備良好的溝通能力、一定的個人魅力以及強大的執行能力。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">具備良好的溝通能力十分重要，尤其是書面溝通。在這方面我的建議是：首先要保證思路清晰，然後就是儘量使用簡潔明瞭的語言。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">而要做好「銷售」最好的方式就是真誠，要對自己推銷的產品抱有自信。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">銷售其實無異於其他技能，我們可以通過刻意練習提高銷售技能。但是出於某些原因（比如人們可能不喜歡銷售），很多人認為銷售技能不可習得。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">做銷售的另一個祕訣是：重要的事情要親力親為。在剛開始創業時，我非常樂意出差辦事，這在很多人看來是不必要的，但是事事親力親為卻給我帶來了三次職業生涯的轉折點，如果當時沒有選擇這樣做，我可能會走上另一條道路。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">5</span></strong></p><p><strong><span style="color:#1e2380">要有冒險精神</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">大多數人往往都高估了風險低估了回報。冒險對我們來説也很重要，因為人不可能永遠不犯錯，我們需要不斷試錯，學習並快速適應。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在職業生涯早期，人們往往更願意冒險，因為那時你沒有什麼可失去的東西，但卻可能得到很多。一旦一個人履行了自己的基本責任義務，就可以開始大膽冒險了。我們可以先下小的賭注，如果賭輸了會輸掉 1 倍，但如果成功了，則可以賺到 100 倍。之後我們再沿着這個方向下更大的賭注。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">但是要注意不能一直待在舒適圈。在 YC，我們從谷歌和臉書長期工作的創始人身上看到了這樣一個問題：當人們習慣了舒適的生活、穩定的工作和無論做什麼都會取得成功的名氣時，就很難將這些置於身後了（人們總是將他們的生活方式與下一年的工資相匹配）。即使他們真的離開了，也非常有可能再回來。與長期利益相比，短期誘惑和便利往往更具吸引力，也更符合人的天性。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">但當你擺脫了這些枯燥無味的工作，你可以跟隨直覺，將時間花在那些有趣的事情上。而想做到這一點，儘可能長時間地過着樸素靈動的生活是一個很好的方法。當然，任何選擇的背後都有相應的代價。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">6</span></strong></p><p><strong><span style="color:#1e2380">保持專注</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">專注可以讓我們在工作中取得事半功倍的效果。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">磨刀不誤砍柴工，在我認識的人中，那些花時間想明白了未來方向的人最後都得到了不錯的結果。由此可見，做正確的事比長時間做事更重要。很多人都將自己的時間花在了無關緊要的事情上面。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">一旦你想明白了該做什麼，就不要猶豫，快速行動起來去完成優先事項。畢竟成功人士就沒有執行力弱的。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">7</span></strong></p><p><strong><span style="color:#1e2380">努力工作</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">通過運用自己的聰明才智或者勤奮努力，一個人可以達成工作領域裏百分之九十的成就，能做到這一點已經很不錯了。但是要想盡量做到完美，達成百分之九十九的成就，那就必須要兼顧聰明與勤奮，因為這一階段你的競爭者往往是兩者兼備的人。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">有付出才有收穫，付出越多收穫也就越大。努力工作可能會造成工作與生活失衡，我完全可以理解有的人選擇去更好地平衡工作與生活，在工作中不那麼拼命。但是拼命工作確實有很多好處，在多數情況下，努力工作會產生疊加效應，越是成功的人就越能成功。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">這通常很有趣。生活中最大的樂趣之一就是找到你的目標，並且有所建樹，然後你會發現你在這件事上的影響力比你自己本身更重要。一位 YC 創始人表示：他在離開一家大公司後，盡力發揮出了自己的最大影響力，此時他發現自己變得更快樂、更充實。為發揮出自己最大影響力而努力工作是值得慶祝的。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">我完全不能理解為什麼在美國某些地區努力工作反而成了一件壞事，但我知道世界其他地區肯定不是這樣的，那些地區的企業家表現出來的精力和幹勁正在快速成為新的社會標杆。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">你必須想出一條平衡之策，在努力工作的同時，又不至於透支身體。對此，雖然人們的應對之策不盡相同，但有條幾乎不會出錯的黃金準則，那就是與相處愉快的人一起從事喜歡的工作。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">我認為，那些假裝（在你生命中的某個時期）不用把精力放在工作上，就能平步青雲的人，其實是在誤人子弟。事實上，判斷一個人能否笑到最後的關鍵因素之一就是工作耐力。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">另外，我認為在剛入職場時就應該要努力工作。努力工作就像利滾利一樣，越早開始，獲利時間就越長。一般來説人們身上揹負的責任越少，就越容易施展身手。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">8</span></strong></p><p><strong><span style="color:#1e2380">大膽一點</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在我看來，與輕鬆創業相比，人們多半會選擇更具挑戰性的事業。因為後者往往更激動人心，能帶來更大的成就感和滿足感。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">如果你在某個重大問題上取得了進展，就會有源源不斷的人前來幫忙。志當存高遠，不要害怕去做你真正想做的事情。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">如果別人都在創辦 meme 公司，而唯獨你想創辦一家基因編輯公司，那就去做吧，不要猶豫。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">追隨你的好奇心。那些讓你感到興奮的事情，通常也適用於別人。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">9</span></strong></p><p><strong><span style="color:#1e2380">足夠堅定</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">很多人都不知道，只要你足夠堅持，世界就會以你的意志為轉移。但大多數人甚至都不會去嘗試，只單純認為世界有其自身的運作規律。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">人的潛力是巨大的，只要敢想就能做成很多事。但大多數人都會懷疑自我、過早放棄，同時又不夠努力，種種原因導致大多數人無法充分發揮自身潛能。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">詢問自身訴求，你通常不能得償所願，而且被拒絕的滋味往往不好受。但若一旦成功，效果就會好得出奇。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">那些聲稱「我將永不言棄，直到夢想成真，不論前方有多少艱難險阻，我也會迎難而上」，並將其付諸行動的人，最後幾乎總能大獲成功。因為他們堅持了足夠久，所以最終迎來了幸運之神的眷顧。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在這方面，愛彼迎（Airbnb）是我認為的行動標杆。業內流傳着許多有關愛彼迎的逸聞趣事，雖然我並不推崇他們的做法（比如透支信用卡、每頓都吃一元店買的麥片、樂此不疲地與強勁的對手進行較量等等）但是正因為他們足夠堅持，最後終於時來運轉。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">只有保持樂觀才能足夠堅定，而樂觀這種性格特徵是可以通過練習逐步提升的，要知道悲觀者是很難成功的。</span></p><p><strong><span style="color:#3f3f3f">&nbsp;</span></strong></p><p><strong><span style="color:#f6ab00">10</span></strong></p><p><strong><span style="color:#1e2380">保持強勁的市場競爭力</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">大多數人都明白，企業競爭力越強，價值就越高。這點至關重要，而且也是顯而易見的。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">這同樣也適用於個人。如果你所從事的工作具有可替代性，那麼你最終就會被薪資要求更低的人所取代。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">增強競爭力的最佳方式就是建立話語權。例如，你可以利用好個人關係，打造強大的個人品牌，或是在不同領域的交叉點建立起自己的個人優勢。當然增強競爭力的方式還有很多，但不論採取什麼方式，關鍵是你必須要做到這一點。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">大多數人會模仿身邊人的做法，但這種方式並不可取，如果一味模仿他人，那你還有什麼競爭優勢可言呢？</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">11</span></strong></p><p><strong><span style="color:#1e2380">建立人際網絡</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">出色的工作需要團隊合作。打造既可密切合作又可輕鬆相處的優質人際網絡是事業成功的必要因素。擁有優秀人才的人際網絡的規模會決定你能成功的上限。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">建立人際網絡的有效方法之一是儘可能多幫助他人。長期以來，這種行為方式給我帶來了最佳職場機遇以及四項最佳投資中的三項。我總是驚訝於發生在自己身上的意外之喜，僅僅因為我十年前曾幫助過一位企業創始人。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">建立人際網絡的另一個途徑是擁有好的名聲，不虧待每一個一起共事的人。要大方慷慨地與他人分享資源，這會給你帶來 10 倍、100 倍的回報。此外，要知人善用，讓每個人都能充分施展自己的才華（這是我從管理學中學到的最重要的一課，雖然我對管理學的研究還並不多）<span style="color:#3f3f3f">。</span>我們既要盡力挖掘他人的潛力但是又不能逼得太緊，這容易讓人感到精疲力盡。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">每個人都有各自擅長的領域。因此，我們要多看看自己的優點，不要總盯着缺點，要用優點來定義自身。面對缺點，我們要承認它，想辦法彌補它，不要讓缺點成為我們前進路上的阻礙。我常能在一些創業者口中聽到這樣的説法「我不能做 A，因為我不擅長 B」，這種思維方式讓我十分吃驚，這反映出他們缺乏創造力。彌補弱點的最佳方式是聘請互補的團隊成員，而不是僱傭那些跟你擅長相同事情的人。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">慧眼識珠挖掘未被髮掘的人才是建立人際網絡的有效途徑。通過練習，我們能快速識別那些優質、有動力、有創造力的人才。挖掘人才最簡單的方式就是多社交，多與他人打交道並且與那些給你留下深刻印象的人保持聯繫。要記住一點，不要侷限於他人過往的工作經驗和當前成就，我們需要發掘那些有潛力且能在短時間激發潛能的人。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">每當遇到新人，我都會捫心自問「這個人有異於常人的能力嗎？」對於渴求人才的人來説，這個問題很值得思考。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">建立人際網絡的特例是找到你生命中的貴人，特別是在職業生涯早期。毫無疑問，能做到這點的最佳方法就是主動去幫助他人（記住，你必須在日後回報你的貴人！）</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">最後，我們要結交那些積極向上且志同道合之人。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">12&nbsp;</span></strong></p><p><strong><span style="color:#1e2380">資產決定財富</span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">小時候，我對經濟的最大誤解就是人們通過高薪發財致富。雖然也有一些特例，比如説娛樂圈的藝人，但從以往的福布斯榜單來看，幾乎沒有人是靠高薪榮登榜單的。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">擁有能迅速增值的東西才能真正發家致富。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">這些東西可以是商業資產、不動產、自然資源、知識產權等。但無論怎樣，你需要實際擁有一些東西，而不是單靠出賣時間賺取工資，出賣時間贏來的財富只會呈慢速線性增長。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">讓事物迅速增值的最佳方法就是大量製造人們想要的東西。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><strong><span style="color:#f6ab00">13</span></strong></p><p><strong><span style="color:#1e2380"><span style="color:#1e2380">要有內驅力</span></span></strong></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">大多數人主要都是靠外部驅動，他們做事情是為了讓別人佩服。這種做法壞處頗多，但以下兩點最為突出：</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">首先這會導致你人云亦云，因循守舊。在工作中，你會過於在意他人的看法，這種在意程度可能已經遠遠超出了你的意識。並且這會阻礙你從事趣味性工作，即使你正在做這樣的工作，也不過是在炒冷飯。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">其次，這會讓你誤判風險等級。從短期影響來看，你會將注意力主要放在和他人的競爭上，以確保不會在競爭遊戲中落後。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">聰明人似乎更容易受到這種外驅力的影響。瞭解到了這一點可以幫助你擺脫這種影響，但幫助不大，我們必須要極其謹慎才能不至於掉入模仿他人的陷阱中。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">我認識的大多數成功人士都是靠自我驅動。他們做事情是為了讓自己心悅誠服，因為他們覺得給世界帶來改變是自己的責任。當你賺得盆滿缽滿並且擁有了較高的社會地位之後，金錢和名譽對你的吸引力開始逐漸消失，這時候內驅力就成為了唯一的動力，推動你向更高的地方攀登。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">這就是驅動力重要性的體現。驅動力是我瞭解他人時最先考察的點，我們很難用一套規則去定義正確的驅動力，但是當你遇到它時立刻就能有所體會。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在這件事上，傑西卡·利文斯頓（Jessica Livingston）和保羅·格雷厄姆（Paul Graham）是我認為的行動標杆。在 YC 創辦的最初幾年，人人都不看好它的發展，沒有人認為 YC 能夠成功。但是傑西卡和保羅很看好 YC 的發展，他們認為如果 YC 能夠成功將會對世界大有裨益，他們希望能夠藉此幫助到其他人，並且堅信這種新模式比現存的模式好。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">最終你會發現成功是在自己看重的領域裏做出出色的成績。向着自己熱愛的方向越早出發就能走得越遠，沒有熱愛之事的人是很難取得成就的。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#888888"><em><span style="color:#888888">[1]. 我在 HackerNews 上寫的評論回覆：</span></em></span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">對於實行基本工資制度，我感到十分欣慰。因為它能讓更多人去賭一把，從而充分釋放人類的潛能。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">在那之前，如果你不是生來幸運，就必須要先往上爬一段時間，然後才能做出巨大改變。如果你家境十分貧寒，那麼這條路將會異常艱難。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">機會分配如此不均，顯然是一種恥辱和浪費，讓人難以置信。直到我見證了足夠多的人，他們出生時手握一副爛牌，最終卻打成了王炸，我才發現普通人想要取得成功是完全有可能的。</span></p><p><span style="color:#3f3f3f">&nbsp;</span></p><p><span style="color:#3f3f3f">我深深地意識到這樣一個事實：若非生來幸運，我就不會有今天。<br><br> （本文由 OneFlow 社區編譯發佈，譯文轉載請聯繫獲得授權。原文：https://blog.samaltman.com/how-to-be-successful）</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">本文是 OneFlow 社區《<strong>升維指南</strong>》欄目的第 1 篇文章。</span><br><br><span style="color:#3f3f3f">人類的知識大致可以分為「道」和「術」兩類，在日常研究和開發工作中，只要具備基礎知識，涉及「術」層面的具體技術和工具使用方法通過練習很快可以習得，但人與人之間的差距往往在「道」的層面，也就是事情的認知層面。<br><br> 本欄目將發佈創業創新、科學技術等領域關於個人成長、創業和研究心得等方面的內容，希望有助於我們實現認知升維。</span></p><p>&nbsp;</p><p><span style="color:#888888">其他人都在看</span></p><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247490570%26idx%3D1%26sn%3D4192033f23acaa30b18fa4e10deebceb%26chksm%3Dfe41923cc9361b2af53d442f789f0098127ff62271f3daac901966133f40a45c3dfac929010c%26scene%3D21%23wechat_redirect" target="_blank">OneFlow v0.9.0 正式發佈</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489682%26idx%3D1%26sn%3Dc93019295b39a9e82b57350a453643c8%26chksm%3Dfe4196a4c9361fb2bb2d7f3aa6b99a0de5c12e35c656fd1b03ed88778d3d282200620ffc386a%26scene%3D21%23wechat_redirect" target="_blank">李白：你的模型權重很不錯，可惜被我沒收了</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489925%26idx%3D1%26sn%3Db6425ec3ebeaaf25b02dd40ef313e89c%26chksm%3Dfe4197b3c9361ea5bb74a162a2bd54020b0e8cf3ad09b91dce1a9c10153656cb1b4398cb2089%26scene%3D21%23wechat_redirect" target="_blank">OpenAI 掌門 Sam Altman：AI 下一個發展階段</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489843%26idx%3D1%26sn%3Df32143165779a5c96d4861d657286ea6%26chksm%3Dfe419705c9361e13ef901009ec002ac74ea8e7c269f8cb21c6d6edb8671e08acf1a836f76b7f%26scene%3D21%23wechat_redirect" target="_blank">比快更快，開源 Stable Diffusion 刷新作圖速度</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" target="_blank">OneEmbedding:單卡</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" target="_blank">訓練 TB 級推薦模型不是夢</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247490555%26idx%3D1%26sn%3D280c4ac043a31170236a9d8fba5fc2d2%26chksm%3Dfe4195cdc9361cdb6db1cb3b77c66b45c353b2fb65c4d082fbae9b72fe0b3a441ab9101cb147%26scene%3D21%23wechat_redirect" target="_blank">GLM 訓練加速：性能最高提升 3 倍，顯存節省 1/3</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247490544%26idx%3D1%26sn%3Ddd5c6a9d3c3def3cf6fe0f37f2897f42%26chksm%3Dfe4195c6c9361cd03f86c4c884f1d035392651752aa7d58773659f4c27a743a666f459f27400%26scene%3D21%23wechat_redirect" target="_blank">「零」代碼改動，靜態編譯讓太乙 Stable Diffusion 推理速度翻倍</a></p></li></ul><span id="OSC_h2_1"></span><h2 style="margin-left:8px; margin-right:8px"><span style="background-color:#ffffff; color:#888888">歡迎 Star、試用 OneFlow 最新版本：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank">https://github.com/Oneflow-Inc/oneflow/</a></h2><hr><p><img src="https://oscimg.oschina.net/oscnet/438500b7-0b91-47ed-8efe-76fee807a14a.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br> 如有侵權，請聯繫 support@oschina.cn 刪除。<br> 本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 10:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/7021318</guid>
            <link>https://my.oschina.net/oneflow/blog/7021318</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[聯想向 Linux 內核提交補丁，為最新款 ThinkPad 優化性能]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>聯想近日提交了一個 Linux 內核驅動程序補丁，專為其最新的 ThinkPad 筆記本電腦構建，目標是優化性能表現 (Ultra-Performance Capability) —— 確保在開啓「性能」模式的 ACPI 平台配置下，硬件能夠實現最佳 Linux 性能的同時，在平衡和省電模式下保持最佳電源節省。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-872ed115b84f6844d67e30e0fedce081295.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-23d72c784ae760869b2a39281f6a83ce971.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Fplatform-driver-x86%2F20231108162039.13737-1-mpearson-lenovo%40squebb.ca%2F" target="_blank">根據補丁的描述</a></u>，這項改進性能模式的 ThinkPad ACPI 驅動程序已在 ThinkPad T14 G4 AMD 型號上通過了測試。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1122/180125_aBnj_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>不過補丁仍在 review 階段。按照日程進度，它應該會在 v6.8 內核開發週期準備就緒。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 09:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267630/lenovo-linux-ultra-performance</guid>
            <link>https://www.oschina.net/news/267630/lenovo-linux-ultra-performance</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JetBrains 報告：Scala/Go/Kotlin 薪酬最高，Objective-C 日薄西山]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">JetBrains&nbsp;<span style="background-color:#ffffff">的第七次年度開發者生態系統調查</span>《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Flp%2Fdevecosystem-2023%2F" target="_blank">The State of&nbsp;Developer Ecosystem 2023</a>》結果已發佈，基於來自全球 26348 名開發人員的調研反饋。</span></p><p><span style="color:#000000">今年的報告在往年的基礎上擴展了人工智能（AI）領域。研究了開發人員對 AI 的看法和擔憂、AI 助手的常用功能以及 AI 增強工具的當前採用情況。</span></p><p><span style="color:#000000"><img alt="" height="342" src="https://oscimg.oschina.net/oscnet/up-fbcbe2ff153b298591f6ef6f700c114e826.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">調查發現的一些關鍵要點有：</span></span></p><ul><li><span style="color:#000000">過去三年間，排名前三的語言保持不變（JavaScript 、Python、HTML/CSS）。<strong>JavaScript 雖然一直處於榜首，但份額一直在下降。</strong>JetBrains 認為，JavaScript 程序員表示學習其他語言的可能性要高於其他程序員，因此預計其份額還會繼續小幅下降。SQL 和 Java 分別排在第 4 和第 5 位。</span></li><li><span style="color:#000000"><strong>Rust 是今年唯一創下受歡迎程度新紀錄的常用語言。</strong>報告認為 Rust 會首先超越 Go，因為每六個 Go 用戶中就有一個在考慮採用 Rust。與 Scala 一樣，Rust 也是程序員最不願意遷移的語言。</span></li><li><span style="color:#000000"><strong>Objective-C 的生命似乎已經走到了盡頭</strong>，目前已經失去了三分之二的用戶。「從 1984 年問世到 2014 年蘋果公司發佈其後繼者 Swift，Objective-C 語言一直保持着良好的發展勢頭。但隨着其他跨平台語言（如 Kotlin、Dart 等）的出現，iOS 開發人員的選擇越來越多，幾乎已經沒有理由繼續使用 Objective-C。」</span></li></ul><p><img height="350" src="https://oscimg.oschina.net/oscnet/up-6bbbf17f16876195166433f0550acbd7511.png" width="500" referrerpolicy="no-referrer"></p><ul><li><span style="color:#000000"><span style="background-color:#ffffff">2023 年，<strong>Scala、Go 和 Kotlin 開發者位列薪酬最高的三大類別。</strong></span></span></li></ul><p><img height="410" src="https://oscimg.oschina.net/oscnet/up-7bf9927251a0bb05df87c942bff3188c401.png" width="300" referrerpolicy="no-referrer"></p><ul><li><span style="color:#000000">自&nbsp;2021 年以來，調查數據一直顯示女性開發者的比例沒有改善。只有 5% 的開發者是女性，表明行業存在巨大的性別差距。值得注意的是，2023 年，<strong>韓國 30 歲以下的女性程序員佔比將達到 14%</strong>，呈現出良好的發展趨勢。這很可能是自 20 世紀 90 年代中期以來，政府為促進性別平等和鼓勵女性從事 IT 行業而制定的戰略性長期政策的結果。</span></li><li><span style="color:#000000"><strong>生成式 AI 服務的複雜格局：</strong>77% 的開發者使用 ChatGPT，46% 的開發者使用 GitHub Copilot；59% 的開發者對使用 AI 生成服務尚存安全顧慮，以及還有 19 % 的人擔心 AGI 會對人類產生敵意。</span></li><li><span style="color:#000000">開發者使用 AI 助手的最常見方式是：使用自然語言詢問軟件開發相關一般問題，其次是生成代碼，以及生成代碼註釋或代碼文檔。</span></li></ul><p><img height="299" src="https://oscimg.oschina.net/oscnet/up-da91b4da7fcfec84b51615d3e4eabe04354.png" width="500" referrerpolicy="no-referrer"></p><ul><li><span style="color:#000000">73% 的開發人員在職業生涯中經歷過倦怠。</span></li><li><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">63% 的開發人員使用 Docker。</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">41% 的受訪者為開源項目做出過貢獻；20% 的受訪者或多或少的會定期為開源項目做貢獻。</span></p></li></ul><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Flp%2Fdevecosystem-2023%2F" target="_blank">查看完整報告</a>。&nbsp;</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 07:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267606/jetbrains-devecosystem-2023</guid>
            <link>https://www.oschina.net/news/267606/jetbrains-devecosystem-2023</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[天工 Skywork-13B 開源模型的煉成和思考]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><span id="OSC_h2_1"></span><h2 data-first-child="" data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);" data-mpa-powered-by="yiban.io">前言</h2><p data-pid="zj45qEUV" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">筆者 6 月下旬加入到崑崙萬維天工大模型團隊負責大模型預訓練，第一個參與的項目就是 13B 模型的預訓練。在此期間社區不斷開源了很多優秀的大模型，如 Llama-2 系列，ChatGLM 系列，Baichuan 系列，Qwen 系列。但這些模型大多是在 Benchmark 上跑跑分，秀一下肌肉，而對技術細節如：數據處理，數據配比，模型調優，評估方案則透露較少。社區正在從開放走向封閉，就 Llama-1 和 Llama-2 的 tech report 對比，Llama-2 是更加封閉的，甚至連數據配比也沒有透露。在筆者團隊訓練出一個還不錯（可能是目前中文能力最強）的 13B 模型後，決定對我們的經驗進行總結。一來希望啓發社區，提升中文社區對預訓練的認識，推動 AGI 在中國早日的實現。二來也是對我們自己的審視，通過開源收集反饋，幫助我們更好的完成之後的工作。三來我們認為目前的中文大模型社區可能在走一個彎路，就是太注重開源榜單的評分，這個彎路社區在 BERT 時代也走過，BERT 時代過分看中 CLUE，GLUE，SuperGLUE 等榜單，正如目前過分看中 MMLU，C-EVAL 等榜單，而忽略對模型真實能力的測量。作為 Skywork-13B 項目的主要貢獻者，筆者會在本文中對數據預處理，模型結構選擇，數據配比研究，再到模型訓練和模型評估做一個詳細的梳理和解讀。</p><span id="OSC_h2_2"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">1. 天工 Skywork-13B 模型有什麼特點？</h2><ul style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;width: 690px;display: table;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);" class="list-paddingleft-1"><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">最有誠意</span>的開源協議，無需申請即可商用，不受行業，公司規模，用戶數量的限制。</p></li><li style="list-style: none;display: table-row;"><p>開源 13B 模型中文<span style="font-synthesis: style;font-weight: 600;">效果最好</span>，<span style="font-synthesis: style;font-weight: 600;">評估最全面</span>。在主流 Benchmark 評估中，整體指標超過 Baichuan-2-13B 和 Llama2-13B。在中文多領域困惑度評估中<span style="font-synthesis: style;font-weight: 600;">超過所有尺寸</span>的開源大模型，包括更大尺寸的 Qwen-14B，InternLM-20B，Aquila-2-34B。</p></li><li style="list-style: none;display: table-row;"><p>開源模型中<span style="font-synthesis: style;font-weight: 600;">訓練最多 token 數</span>，總計訓練了 3.2TB 個 token 的多語言和代碼數據，更多更好的訓練數據是能力強大的來源。</p></li><li style="list-style: none;display: table-row;"><p>罕見的<span style="font-synthesis: style;font-weight: 600;">開源了高質量預訓練數據集</span>，我們將我們的訓練數據 Skywork-150B 數據進行開源，該數據集對中文網頁進行精心清洗和過濾，大約包含 1500 億中文字符，硬盤大小約為 600G，是目前最大的開源中文數據集。無論從質量上還是數量上都遠高於之前最大中文數據集 WuDao-Data。</p></li><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">最坦誠</span>的 technical report，技術信息毫無保留的進行分享。</p></li></ul><p data-pid="k3EwqmqS" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">以下我將對我們開源項目的數據，模型結構，評估方法進行詳細介紹。</p><span id="OSC_h2_3"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">2. 數據部分</h2><p data-pid="_8WI1bEj" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">我們構建了具有 6 萬億高質量 token 的多語言數據集 Skypile，其中主要的來源是網頁數據。LLama，Falcon 等模型已經證明，預訓練中大部分使用網頁數據可以訓練出非常不錯的大模型。</p><span id="OSC_h3_4"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">2.1 數據清洗去重</h3><p data-pid="8bxKZkON" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">這部分可以參考筆者的另外一篇文章&nbsp;鹽梅：數據為王：大模型預訓練中的數據處理及思考—The RefinedWeb Dataset for Falcon LLM 論文解讀</p><p data-pid="OvmjxTVd" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">以下對整個 Pipeline 做簡單的介紹：</p><ol style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;width: 690px;counter-reset: ol 0;display: table;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);" class="list-paddingleft-1"><li style="list-style: none;display: table-row;"><p>低質量&amp;重複 URL 過濾，去除黃暴有害網頁的 URL。</p></li><li style="list-style: none;display: table-row;"><p>重複數據清洗，絕對匹配和基於哈希的語義匹配進行去重。</p></li><li style="list-style: none;display: table-row;"><p>質量過濾，過濾出中英文網頁數據，訓練分類器，過濾掉低質量的內容。</p></li></ol><span id="OSC_h3_5"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">2.2 Skypile-150B 數據開源</h3><p data-pid="nxPYVkY4" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">中文社區苦高質量數據集久已！在英文社區不斷開源了 C4，RefinedWeb，ThePile，The Stack 等高質量數據集，但中文社區之前最大的數據集仍是 Wudao-data，首先量級上和英文數據集完全不對等，Wudao-data 僅包含大約 53B 的 token，而 C4 則是超過 100B，RefinedWeb、ThePile、The Stack 等數據集則是在 500B token 的量級。其次是質量，儘管 Wudao-data 經過了嚴格的清洗過濾，但我們還是發現有很多格式錯亂、重複、數據質量低的問題。針對這一痛點，我們開源了 Skypile-150B 數據集，我們對爬取的高質量網頁進行精新清洗去重和過濾，並使用了 FastText 和 BERT 等模型移除了黃暴、低質量的內容。本次開源的數據總 token 數約為 1500 億，硬盤大小為 592G，是目前最大的中文開源數據集。我們的數據集下載地址 Skypile-150B。</p><span id="OSC_h2_6"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">3. 模型結構</h2><span id="OSC_h3_7"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">3.1 為什麼大體上沿用 Llama 的結構？</h3><p data-pid="H4ujNDrx" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">Llama 結構主要有三個特點：1. 使用 RMSNorm 代替傳統的 Layernorm，使用 pre normalization 保持訓練穩定性。2. 使用 SwiGLU 激活函數而非傳統的 ReLU。3. 使用相對位置編碼（RoPE 等）而非傳統的絕對位置編碼。在我們的前期實驗中也驗證了這一點，相比於 GPT 結構 Llama 結構可以收斂更快，收斂的效果也更好。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.7382198952879581" data-type="other" data-w="764" height="564" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="764" src="https://oscimg.oschina.net/oscnet/5e832d6d-af22-4ed1-afd8-0f0e5350c50e.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    GPT-3 結構和 Llama 結構訓練對比 
  </figcaption></figure><span id="OSC_h3_8"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">3.2 為什麼模型結構設計的更加瘦長？</h3><p data-pid="xT4YB7I1" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">在我們的集羣條件下，想要達到 Llama2-13B 的訓練效率，即 1750 tokens / per gpu / per second，那麼就需要將 global batch size 增大到 Llama2-13B 的四倍（我們集羣帶寬低於 Llama2 的訓練集羣，因此需要更多的梯度累計減少通訊）。根據我們的前期實驗，在更大 batch size 的訓練下，更加瘦長的網絡具備更好的泛化性能。因此我們將層數增加到 52 層，同時縮減了隱藏層大小，使得總體參數量和 Llama2-13B 模型是相當的。因為模型訓練的 global batch size 更大，我們將學習率設置為 Llama2-13B 的兩倍，這樣可以保證訓練時梯度的方差是一致的。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.6473684210526316" data-type="other" data-w="760" height="492" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="760" src="https://oscimg.oschina.net/oscnet/5abb5b31-bbba-424d-8787-f8509901d97a.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    Skywork-13B 和 Llama2-13B 結構對比 
  </figcaption></figure><span id="OSC_h2_9"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">4. 模型評估</h2><p data-pid="UJAfmxO-" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">在訓練之前我們需要一套評估體系明白我們訓練的模型：1. 目前模型效果怎麼樣是否還應該繼續訓練。2. 和其他開源模型比較差距還有多大，繼續訓練多久預期能超過。（可能是老闆最關心的兩個問題）</p><p data-pid="6SugjLnM" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">傳統的評估主要看的是 Training loss 或者 Benchmark 上的指標。但我們認為着兩種評估有以下問題：</p><ol style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;width: 690px;counter-reset: ol 0;display: table;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);" class="list-paddingleft-1"><li style="list-style: none;display: table-row;"><p>Training loss 因為數據配比的原因是一個整體的指標，並且不同模型不能相互比較，比如 A 模型的代碼佔比 20%，B 模型的代碼佔比 10%，那麼 A 模型訓練同樣 token 數下訓練 Loss 會顯著低於 B 模型，因為代碼數據中有很多可以預測的結構，因此 loss 相對更低。不同模型是無法直接比較 Training loss 來對比效果的。</p></li><li style="list-style: none;display: table-row;"><p>Training loss 第二個問題是可能會選擇出一個更加過擬合的模型，我們知道即使經過了精心的清洗，訓練數據中還是不可避免的有很多重複信息，並且在訓練過程中常見操作是上採樣一些高質量數據，比如 Llama1 的訓練中會上採樣 book 來源的信息。而如果對這些重複信息&amp;上採樣信息過擬合，那麼 training loss 會更低，但我們實際上是需要泛化性能更好的模型。</p></li><li style="list-style: none;display: table-row;"><p>Benchmark 的問題就更加嚴重了，第一是因為 benchmark 是公開數據，非常容易針對，通過 In-domain 數據的訓練即可增強對應 benchmark 上的效果，但模型的能力並不一定強。</p></li><li style="list-style: none;display: table-row;"><p>此外 Benchmark 評估一般是準確率，準確率是一個不連續的指標（對大模型湧現的解釋），可能訓練 500B token，benchmark 上的指標都沒有任何變化，因此我們無法根據 benckmark 上的準確率推測持續當前訓練模型會達到一個什麼樣的效果。</p></li><li style="list-style: none;display: table-row;"><p>Benckmark 評估具有一定的波動性&amp;可操作性，不同 Prompt 選擇和答案提取方式會對結果產生很大的影響，</p></li></ol><span id="OSC_h3_10"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">4.1 我們提出的方法：多領域數據損失評估方法</h3><p data-pid="t5aBtW2a" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">大語言模型本質上是讓預測下一個詞更加準確。我們認為評估基礎大模型一個重要的方式是評估在各大領域（比如中英，金融，技術，政務，代碼）上語言模型生成文檔的概率。在語言模型建模中一般使用 Cross Entropy 損失函數，整體的損失函數為每個位置預測真實詞損失的平均，則有：</p><p data-pid="dBam8j-w" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><span data-eeimg="1" data-tex="loss = -\sum^{n}_{i=1} log(p_i) / n = -log( \prod_{i=1}^n p_i) / n"><span style="color: inherit;display: contents;"></span><span tabindex="0" data-mathml="<math
                xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>&amp;#x2212;</mo><munderover><mo>&amp;#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mrow><mo>/</mo></mrow><mi>n</mi><mo>=</mo><mo>&amp;#x2212;</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><munderover><mo>&amp;#x220F;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mrow><mo>/</mo></mrow><mi>n</mi></math>" role="presentation" style=" display: inline-block; line-height: normal; font-size: 16px; word-spacing: normal; overflow-wrap: normal; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border-width: 0px; border-style: initial; border-color: initial;  "><svg
                xmlns:xlink="http://www.w3.org/1999/xlink" width="43.969ex" height="2.789ex" viewBox="0 -849.8 18931.1 1200.9" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.815ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" y="0"></use><use x="298" y="0"></use><use x="784" y="0"></use><use x="1253" y="0"></use><use x="2000" y="0"></use><use x="3057" y="0"></use><g transform="translate(4002,0)"><use x="0" y="0"></use><use transform="scale(0.707)" x="1494" y="675"></use><g transform="translate(1056,-287)"><use transform="scale(0.707)" x="0" y="0"></use><use transform="scale(0.707)" x="345" y="0"></use><use transform="scale(0.707)" x="1124" y="0"></use></g></g><use x="6474" y="0"></use><use x="6772" y="0"></use><use x="7258" y="0"></use><use x="7738" y="0"></use><g transform="translate(8128,0)"><use x="0" y="0"></use><use transform="scale(0.707)" x="712" y="-213"></use></g><use x="8975" y="0"></use><use x="9365" y="0"></use><use x="9865" y="0"></use><use x="10744" y="0"></use><use x="11800" y="0"></use><use x="12578" y="0"></use><use x="12877" y="0"></use><use x="13362" y="0"></use><use x="13843" y="0"></use><g transform="translate(14232,0)"><use x="0" y="0"></use><use transform="scale(0.707)" x="1335" y="675"></use><g transform="translate(944,-287)"><use transform="scale(0.707)" x="0" y="0"></use><use transform="scale(0.707)" x="345" y="0"></use><use transform="scale(0.707)" x="1124" y="0"></use></g></g><g transform="translate(16592,0)"><use x="0" y="0"></use><use transform="scale(0.707)" x="712" y="-213"></use></g><use x="17440" y="0"></use><use x="17830" y="0"></use><use x="18330" y="0"></use></g></svg><span role="presentation" style="top: 0px;left: 0px;clip: rect(1px, 1px, 1px, 1px);user-select: none;transition: none 0s ease 0s;padding-top: 1px !important;border-width: 0px !important;border-style: initial !important;border-color: initial !important;height: 1px !important;width: 1px !important;overflow: hidden !important;display: block !important;"><mi>
       � 
     </mi><mi>
       � 
     </mi><mi>
       � 
     </mi><mi>
       � 
     </mi><mo>
       = 
     </mo><mo>
       − 
     </mo><munderover><mo>
        ∑ 
      </mo><mrow><mi>
         � 
       </mi><mo>
         = 
       </mo><mn>
         1 
       </mn></mrow><mrow><mi>
         � 
       </mi></mrow></munderover><mi>
       � 
     </mi><mi>
       � 
     </mi><mi>
       � 
     </mi><mo stretchy="false">
       ( 
     </mo><msub><mi>
        � 
      </mi><mi>
        � 
      </mi></msub><mo stretchy="false">
       ) 
     </mo><mrow><mo>
        / 
      </mo></mrow><mi>
       � 
     </mi><mo>
       = 
     </mo><mo>
       − 
     </mo><mi>
       � 
     </mi><mi>
       � 
     </mi><mi>
       � 
     </mi><mo stretchy="false">
       ( 
     </mo><munderover><mo>
        ∏ 
      </mo><mrow><mi>
         � 
       </mi><mo>
         = 
       </mo><mn>
         1 
       </mn></mrow><mi>
        � 
      </mi></munderover><msub><mi>
        � 
      </mi><mi>
        � 
      </mi></msub><mo stretchy="false">
       ) 
     </mo><mrow><mo>
        / 
      </mo></mrow><mi>
       � 
     </mi></span></span></span></p><p data-pid="i427Onf7" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">其中 n 是文檔的長度，即 token 數，&nbsp;<span data-eeimg="1" data-tex="p_i"><span style="color: inherit;display: contents;"></span><span tabindex="0" data-mathml="<math
                xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>p</mi><mi>i</mi></msub></math>" role="presentation" style=" display: inline-block; line-height: normal; font-size: 16px; word-spacing: normal; overflow-wrap: normal; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border-width: 0px; border-style: initial; border-color: initial;  "><svg
                xmlns:xlink="http://www.w3.org/1999/xlink" width="2.059ex" height="1.747ex" viewBox="-38.5 -500.7 886.3 752.1" role="img" focusable="false" aria-hidden="true" style="vertical-align: -0.584ex;margin-left: -0.089ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" y="0"></use><use transform="scale(0.707)" x="712" y="-213"></use></g></svg><span role="presentation" style="top: 0px;left: 0px;clip: rect(1px, 1px, 1px, 1px);user-select: none;transition: none 0s ease 0s;padding-top: 1px !important;border-width: 0px !important;border-style: initial !important;border-color: initial !important;height: 1px !important;width: 1px !important;overflow: hidden !important;display: block !important;"><msub><mi>
        � 
      </mi><mi>
        � 
      </mi></msub></span></span></span>&nbsp;是位置 i 上真實詞的概率，我們知道中每一個位置上真實詞的概率的聯乘為生成該文檔的概率，這樣我們就將 loss 和生成文章的概率聯繫在了一起。而不同模型因為使用的分詞器不同，具有不同的 token 數，因此對損失函數乘以 token 數目 n 就僅考慮生成文章的概率部分，不同模型也可以進行比較。</p><p data-pid="mgoJM4KU" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">這一評估方法本質和似然（likelihoold）的定義是相似的，只不過我們是以我們 Skywork 模型分詞 token 數為基準，對其他模型的 loss 進行了標準化，使得最終指標更像是一個大家可以直接比較的 loss 值。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.075" data-type="png" data-w="1080" height="104" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1394" src="https://oscimg.oschina.net/oscnet/2d15fb8c-5112-4227-b5fe-118bb6edfa0d.png" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    wikipedia 上關於似然 likelihood 的定義 
  </figcaption></figure><p data-pid="Q5r4Jsv2" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">基於上述分析，我們構建了中文，英文，代碼，arxiv 文章等多個領域的驗證集，這些驗證集的構造方法是選取 2023 年 7 月份（項目開始的時間）發佈的最新的高質量文章數據，一來是本質上是我們需要模型具備根據歷史訓練數據來預測最新數據的能力。二來是這些數據絕對不可能在我們的模型和其他模型的訓練數據中出現，可以最公平的比較各個模型的能力。並且我們經過了仔細的人工校對，確保文本通暢，言之有物且來源多樣。對於每個領域我們構建了大約選取了幾百到一千篇文章的驗證集。</p><p data-pid="ibC2wF3T" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">NLP 領域之前有使用驗證集 Loss 來評估模型的效果，但大多隻使用固定的，單一的集合進行評測。提出用多領域滾動更新數據評估的方法我們應該是首創。</p><p data-pid="MhRnzTEI" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">使用多領域驗證集監控模型訓練效果有以下好處：</p><ol style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;width: 690px;counter-reset: ol 0;display: table;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);" class="list-paddingleft-1"><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">易於計算</span>。計算多個 benckmark 上的效果，完整進行一次評測至少需要 3 個小時以上，而即使是一千篇文章的損失計算，只需要幾分鐘就能算出來。</p></li><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">易於收集</span>。我們可以不斷使用最新數據評估我們模型能力。數據收集 Pipeline 構建完成後，我們只需要花幾個小時的時間即可構建高質量的評估集。並且我們關注什麼下游指標就可以構建什麼領域的驗證集，評估會更加全面。</p></li><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">訓練敏感</span>。loss 是一個連續的指標。訓練過程中可以持續觀察變化，而不像評價準確率的指標需要等到模型 grokking 才能看到效果上的變化。</p></li><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">模型無關</span>。標準化後可以在不同模型之間進行比較。</p></li><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">可預測</span>。因為 loss 是平滑且連續的指標，我們可以根據驗證損失進行繪圖，預測還需要多少訓練量可以達到預期的效果。</p></li><li style="list-style: none;display: table-row;"><p><span style="font-synthesis: style;font-weight: 600;">和最終綜合指標高度相關。</span>下圖是我們構建的英文驗證集損失和常用 benchmark 指標的曲線。可以看到隨着驗證集 loss 的下降，benchmark 上的平均指標幾乎是線性提升的。</p></li></ol><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="1.026851851851852" data-type="other" data-w="1080" height="1286" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1252" src="https://oscimg.oschina.net/oscnet/5115d848-1b26-4077-928e-b600247b67f0.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    英文驗證集損失和指標效果曲線 
  </figcaption></figure><p data-pid="SXccpy1p" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">7.&nbsp;<span style="font-synthesis: style;font-weight: 600;">效果在時間維度穩定</span>。在預訓練階段我們是監控 23 年 7 月份最新文章的驗證集損失指標，在模型訓練結束後我們監控的是 9 月份-10 月份新發布文章的驗證集損失指標，兩者的結果幾乎完全一致。我們開源了評估腳本和評估數據。23 年 9 月評估數據下載地址</p><p data-pid="XYUcfDAj" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">8.&nbsp;<span style="font-synthesis: style;font-weight: 600;">可滾動更新不擔心被針對</span>。如果有新模型發佈了，我們只需要用最新數據驗證集評估下模型的損失，就可以知道其效果如何，不用擔心固定的 benchmark 被針對，導致效果失真。</p><span id="OSC_h2_11"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">5. 模型訓練</h2><span id="OSC_h3_12"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">5.1 為什麼我們要採用兩階段訓練？</h3><p data-pid="AdrJjl3-" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">在訓練數據收集中，我們發現存在兩類數據，一類是相對量級較大的通用語料，存儲一般以 TB 為單位，他們的來源於網頁爬取，書籍數據，arxiv 數據等，我們稱之為 Skypile-MAIN。另一部分則是相對少量的有監督數據，這些數據來源是某些特定的做題網站，數據形式一般是問題+答案，存儲量級一般是 MB 到 GB，因為這些數據大多 STEM（數學，科學，工程，技術）相關的，我們稱之為 Skypile-STEM。在構建整個訓練計劃的時候，如果將兩部分數據直接合並，那麼 STEM 數據會被 MAIN 數據淹沒，而如果通過上採樣的方式提升 STEM 數據的比例進行訓練，那麼一是採樣多少倍不太確定，二是這些數據會對普通任務是否會造成傷害也難以衡量。因此我們決定先用 Skypile-MAIN 數據讓模型學習通用的能力，然後再給予 Skypile-STEM 數據提升模型的數學能力，邏輯推理能力，解題能力等。</p><span id="OSC_h3_13"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">5.2 第一階段預訓練</h3><p data-pid="vOAxp8Hc" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">第一階段預訓練我們使用的數據配比如下英文佔比 52.2%，中文佔比 39.6%，代碼佔比 8%，在兼顧中文和英文上的表現的同時，代碼能力也能有保證。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="1.0025252525252526" data-type="other" data-w="792" height="794" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="792" src="https://oscimg.oschina.net/oscnet/b44ae85f-db63-4809-ab92-85a722b352c8.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    第一階段數據配比 
  </figcaption></figure><p data-pid="mgEWjX3c" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">第一階段預訓練分為兩個訓練 session，我們原本計劃訓練 2TB token，但訓練完成後發現各項能力均沒有飽和，同時我們又有新的高質量數據清洗完成，因此進行第二個 session 的訓練，這一個 session 大約訓練 1.1TB token。session-2 數據配比大致和 session-1 相似，只不過數據源略有改動。第一階段訓練完成後模型訓練了 3.1TB。我們將 session-1 訓練完成的 2TB token 的模型和 session-2 訓練 3.1TB token 的模型均開源。Skywork-13B-Base-2TB Skywork-13B-Base-3.1TB</p><p data-pid="CNUYLR1X" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">下圖是我們第一階段預訓練的各項指標曲線。可以看到，在 session-1 訓練完成後模型各項指標還沒有收斂，在 session-2 訓練完成後，各項指標趨於飽和。</p><p data-pid="72Uzmy3H" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">一排中間的圖是我們的英文訓練損失和其他模型的對比。一排右邊的圖是我們的中文訓練損失和其他模型的對比。結果表明，英文綜合能力 LLama2-13B 顯著高於其他的的開源模型，而中文能力 Skywork-13B 則顯著高於其他模型。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.8629629629629629" data-type="other" data-w="1080" height="1420" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1646" src="https://oscimg.oschina.net/oscnet/c6e4066d-0fc6-4d38-9709-51080decd219.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    第一階段預訓練各項指標演化圖示 
  </figcaption></figure><span id="OSC_h3_14"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">5.3 第二階段預訓練</h3><p data-pid="N1G5j2Du" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">第二階段預訓練，我們將 Skypile-STEM 數據加入到預訓練中，第二階段訓練了 130B token，最終模型為我們的 Skywork-13B-Base 模型，總計訓練 3.2TB token。Skypile-STEM 中大量數據是數學，科學，工程等做題相關數據，而 Benchmark 中很多也是做題，因此我們也可以將 Skypile-STEM 視作 In-domain 數據，In-domain 是和榜單評估高度相似的數據。</p><span id="OSC_h3_15"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">5.4 In-domain 數據訓練的收益和危害</h3><p data-pid="6ovfpn_H" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">為了驗證 In-domain 數據訓練對模型訓練的影響，我們將訓練 500B token 後的模型直接使用 Skypile-STEM 數據繼續訓練 1B token，可以看到主流的 benchmark 上 CEVAL 和 GSM8K 得分均<span style="font-synthesis: style;font-weight: 600;">大幅上漲</span>，但在中英領域驗證損失上則出現了明顯的上升。表明通過 In-domain 數據的訓練，<span style="font-synthesis: style;font-weight: 600;">模型做題能力和刷榜能力會大幅提升，但其通用能力是大幅下降的</span>。同時也説明，benchmark 是一個相對容易針對和提升的指標，只需要在對應 benchmark 的 In-domain 數據上加大訓練，就可以將各項能力本來很弱的模型提升到很高的水平，但這是以損失通用能力為代價的。我們將訓練 500B 時模型存檔進行開源 Skywork-13B-Base-500B。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.7083333333333334" data-type="other" data-w="1080" height="890" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1256" src="https://oscimg.oschina.net/oscnet/aa9da3cc-1582-425d-b06b-3c8abb80c005.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    第一階段訓練 500B 後直接訓練 Skypile-STEM 數據各項指標的變化 
  </figcaption></figure><span id="OSC_h3_16"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">5.5 第二階段數據配比</h3><p data-pid="erRfH6eO" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">在第二階段預訓練中，我們仔細調整了數據配比，原因如上所述，我們希望賦予模型解題能力的同時，更小程度的破壞其通用能力上的效果。最終第二階段預訓練中 20% 來自 Skypile-STEM，80% 來自 Skypile-MAIN 避免災難性遺忘。我們嘗試了從 10% 到 40% 的 Skypile-STEM 數據權重，發現 20% 的佔比可以維持驗證集損失不上升的同時，benchmark 指標能有提升。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.9111111111111111" data-type="other" data-w="1080" height="1122" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1232" src="https://oscimg.oschina.net/oscnet/3b1039ab-85dd-4de2-9d30-094ae6f5f850.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    第二階段訓練模型 CEVAL 效果變化 
  </figcaption></figure><span id="OSC_h2_17"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">6. 最終效果</h2><span id="OSC_h3_18"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">6.1 Benchmark 評估效果</h3><p data-pid="IdzMfH8R" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">我們在一些主流 Benchmark 上評估了我們模型的效果，結果如下圖所示，Skywork-13B 模型在開源 13B 規模模型中綜合能力排名第一。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.4338919925512104" data-type="other" data-w="1074" height="466" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1074" src="https://oscimg.oschina.net/oscnet/5b20fcff-54fa-473c-96d4-462bb3a57d1d.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    Benchmark 評估效果 
  </figcaption></figure><p data-pid="h3uJlMRr" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">我們沒有針對榜單做特別多的評測，但在模型開源三天後就有 01 萬物的夥伴對我們模型進行了較為全面的評測，結果顯示 Skywork-13B 在 13B 參數規模中處於領先。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.8648148148148148" data-type="other" data-w="1080" height="1274" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1474" src="https://oscimg.oschina.net/oscnet/3635e40a-2333-412e-8232-618626319629.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    Yi-34B Hugging Face Homepage 
  </figcaption></figure><span id="OSC_h3_19"></span><h3 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.1em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(1.90909em);margin-bottom: calc(1.27273em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">6.2 領域驗證集評估</h3><p data-pid="2_6eAHfh" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">我們對多個領域篩選出 2023 年 9 月份新發布的幾百到上千篇高質量文章，並人工進行了核對。保證所有的測試數據不在天工模型以及其他所有模型的訓練集中。下圖列出了不同開源模型的困惑度，結果顯示天工 Skywork-13B-Base 模型在技術，電影，政務，金融，通用等多個領域取得最優效果，證明瞭我們的 Base 模型的中文能力處於國內開源模型最強水平。標準化的領域驗證集損失（loss）取指數即為困惑度（Perplexity），轉換後可讀性更強。</p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.5675925925925925" data-type="other" data-w="1080" height="620" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1092" src="https://oscimg.oschina.net/oscnet/842e44f9-04a7-4b97-b07b-0372a7da609e.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    開源模型領域驗證集 PPL 對比 
  </figcaption></figure><span id="OSC_h2_20"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">7. 如何看待大模型刷榜：榜單效果是否能代表真實效果？</h2><p data-pid="O71y1CVy" style="letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><span style="font-size: medium;">為了驗證各大模型的真實效果，我們針對 GSM8K 榜單使用 GPT-4 構建了一批驗證集，並人工核對的正確性。在下面的實驗中我們將模型在 GSM8K 訓練集上的損失稱為 L_train，測試集上的損失稱之為 L_test，在我們構造驗證集上的損失稱之為<span data-eeimg="1" data-tex="L_{ref}"><span style="color: inherit;display: contents;"> L_ref</span></span>。那麼數學能力很強的大模型應該是 L_test，</span><span style="font-size: 16px;">L_train&nbsp;</span><span style="font-size:16px;">以及我們 L_ref&nbsp;</span><span style="font-size:16px;">同樣的低，因為模型已經能在任何數據上進行很好的泛化了。</span><span style="font-size:16px;">在 L_test&nbsp;</span><span style="font-size:16px;">低但 L_ref&nbsp;</span><span style="font-size:16px;">上高，説明模型可能有測試集污染的問題。</span><span style="font-size:16px;">如果在 L_train&nbsp;</span><span style="font-size:16px;">上低但 L_ref&nbsp;</span><span style="font-size:16px;">高則説明模型過分的在 In-domain 數據上進行了預訓練，但模型的泛化性能不強。</span><span style="font-size:16px;">如果三者趨勢一致，那麼 L_ref 可</span><span style="font-size:16px;">以作為模型數學能力評估的指標，越低代表模型的數學能力越強。</span><span style="font-size:16px;">選取 GSM8K 做測量是因為 GSM8K 是一個生成式任務，可以直接用題目和答案構建驗證集測量 loss，而其他的 Benchmark 比如 MMLU，CEVAL 等是選擇題，模型只用回答 ABCD，不是很適合測試損失函數。</span><span style="font-size:16px;">我們將構建的驗證集進行了開源，下載地址 mock_gsm8k_test。</span></p><p data-pid="7YBMT76r" style="letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><span style="font-size: medium;">下圖 <span style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;letter-spacing: normal;text-align: start;text-wrap: wrap;background-color: rgb(255, 255, 255);">Δ</span>1&nbsp;=</span><span style="font-size: 16px;">&nbsp;L_test&nbsp;</span><span style="font-size:16px;">- L_ref 表</span><span style="font-size:16px;">明數據污染的程度，如果越低説明數據污染越嚴重。</span><mi mathvariant="normal" style="font-size: 16px;word-spacing: normal;">
    Δ 
  </mi><mn style="font-size: 16px;word-spacing: normal;">
    2&nbsp; 
  </mn><span style="font-size:16px;">= L_test - L_train 表</span><span style="font-size:16px;">明模型在 In-domain 數據上訓練程度，越大表明在 In-domain 上進行了更多的訓練，則過擬合風險也更大。L_ref </span><span style="font-size:16px;">在&nbsp;</span><mi mathvariant="normal" style="font-size: 16px;word-spacing: normal;">
    Δ 
  </mi><mn style="font-size: 16px;word-spacing: normal;">
    1&nbsp; 
  </mn><span style="font-size:16px;">和&nbsp;</span><mi mathvariant="normal" style="font-size: 16px;word-spacing: normal;">
    Δ 
  </mi><mn style="font-size: 16px;word-spacing: normal;">
    2&nbsp; 
  </mn><span style="font-size:16px;">均建康的情況下，越低表明模型泛化性能越強。下圖表明，我們的模型在數學能力上的泛化性能是更優的。</span></p><figure data-size="normal" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);"><p><img class="rich_pages wxw-img" data-ratio="0.7398148148148148" data-type="other" data-w="1080" height="1244" style="display: block;margin-right: auto;margin-left: auto;cursor: zoom-in;background-color: transparent;animation: 0.5s ease-in 0s 1 normal none running animation-1yvu044;width: 690px;height: auto !important;" width="1682" src="https://oscimg.oschina.net/oscnet/4f8e51b1-75f6-455b-8844-20c475d67252.jpg" referrerpolicy="no-referrer"></p><figcaption style="color: rgb(153, 153, 153);font-size: 0.9em;line-height: 1.5;margin-top: calc(0.666667em);padding-right: 1em;padding-left: 1em;text-align: center;">
    Mock-GSM8K 驗證集損失 
  </figcaption></figure><span id="OSC_h2_21"></span><h2 data-into-catalog-status="" style="letter-spacing: normal;text-align: start;text-wrap: wrap;font-variant-numeric: inherit;font-variant-east-asian: inherit;font-variant-alternates: inherit;font-variant-position: inherit;font-weight: 600;font-stretch: inherit;font-size: 1.2em;line-height: 1.5;font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-optical-sizing: inherit;font-kerning: inherit;font-feature-settings: inherit;font-variation-settings: inherit;margin-top: calc(2.33333em);margin-bottom: calc(1.16667em);clear: left;font-synthesis: style;color: rgb(18, 18, 18);background-color: rgb(255, 255, 255);">寫在後面</h2><p data-pid="Z92DCgfb" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">項目已經告一段落，也終於有時間能對過去幾個月的工作進行一個總結。很高興開源以後我們的工作得到了大家的認可。如果我們的工作對您有啓發或者幫助的話，歡迎在 Github 上 Star 我們的項目，或者引用我們的論文。</p><section style="text-indent: 0em;">
   1. Skywork-13B Github 開源項目地址，會持續更新更多更好的模型，包括對話模型，多模態模型等。 
  <br><span style="color: rgb(178, 178, 178);font-size: 13px;background-color: rgb(255, 255, 255);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;letter-spacing: normal;text-align: start;">https://</span><span style="color: rgb(178, 178, 178);font-size: 13px;background-color: rgb(255, 255, 255);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;letter-spacing: normal;text-align: start;">githu</span><span style="color: rgb(178, 178, 178);font-size: 13px;background-color: rgb(255, 255, 255);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;letter-spacing: normal;text-align: start;">b.com/SkyworkAI/Skywork</span></section><p data-pid="mMCRqvmZ" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">2. 技術報告地址，如果您想了解更多內容請查閲我們的技術報告。如果您覺得我們的工作對您有幫助，歡迎引用。<br><span style="color: rgb(178, 178, 178);font-size: 13px;">https://arxiv.org/abs/2310.19341</span></p><p data-pid="6iWdqiCg" style="font-size: medium;letter-spacing: normal;text-align: start;text-wrap: wrap;margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;background-color: rgb(255, 255, 255);">3. Hugging Face 地址，包含所有模型參數，預訓練數據，評測數據的下載地址。<br><span style="color: rgb(178, 178, 178);font-size: 13px;">http</span><span style="color: rgb(178, 178, 178);font-size: 13px;">s://</span><span style="color: rgb(178, 178, 178);font-size: 13px;">h</span><span style="color: rgb(178, 178, 178);font-size: 13px;">f</span><span style="color: rgb(178, 178, 178);font-size: 13px;">.co/Skywork</span></p><hr style="border-style: solid;border-width: 1px 0 0;border-color: rgba(0,0,0,0.1);-webkit-transform-origin: 0 0;-webkit-transform: scale(1, 0.5);transform-origin: 0 0;transform: scale(1, 0.5);"><p><br><span style="outline: 0px;color: rgb(62, 62, 62);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 14px;letter-spacing: 1px;">本文由 H</span><span style="outline: 0px;color: rgb(62, 62, 62);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 14px;letter-spacing: 1px;">ugging Face 中文社區內容共建項目提供，稿件由社區成員投稿，經授權發佈於 Hugging Face 公眾號。文章內容不代表官方立場，文中介紹的產品和服務等均不構成投資建議。瞭解更多請關注知乎專欄:&nbsp;</span><span style="color: rgb(62, 62, 62);font-size: 14px;letter-spacing: 1px;text-indent: 0em;">算法聯盟</span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-wrap: wrap;background-color: rgb(255, 255, 255);letter-spacing: 0.578px;"><span style="outline: 0px;color: rgb(62, 62, 62);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 14px;letter-spacing: 1px;">如果你有與開源 AI、</span><span style="outline: 0px;color: rgb(62, 62, 62);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 14px;letter-spacing: 1px;">Hugging Face 相關的技術和實踐分享內容，以及最新的開源 AI 項目發佈，希望通過我們分享給更多 AI 從業者和開發者們，請通過下面的鏈接投稿與我們取得聯繫:</span></p><section style="margin: 8px;outline: 0px;text-wrap: wrap;letter-spacing: 0.578px;background-color: rgb(255, 255, 255);line-height: 1.75em;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;"><span style="outline: 0px;color: rgb(136, 136, 136);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 14px;letter-spacing: 1px;">https://hf.link/tougao</span></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 07:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10149336</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10149336</link>
            <author>
                <![CDATA[HuggingFace]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenNJet KIC v1.0 發佈！K8s Ingress Controller]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><span><span>NGINX 向雲原生演進，All in<span>&nbsp;</span></span></span><a href="https://gitee.com/njet-rd/open-njet-kic" target="_blank" rel="nofollow"><span><span>OpenNJet</span></span></a>&nbsp;概述</p><hr><div>
   OpenNJet KIC(K 
  <span style="color:#1f2329">ubernetes </span>Ingress Controller) 基於 OpenNJet proxy 的動態特性、高性能實現。彌補 nginx 在雲原生場景中應用的不足。提供了豐富的流量管理能力，如動態 location、host/path 路由、負載均衡、動態 upstream、金絲雀發佈、TLS Termination/SNI 等。 
 </div><div>
   &nbsp; 
 </div><div>
   本版本主要特性： 
 </div><ul><li><div>
     支持 Ingress API、支持 path/host 路由 
   </div></li><li><div>
     支持自定義資源 VirtualServer，支持 path/host、高級 (header、請求方法等) 路由 
   </div></li><li><div>
     支持動態 Upstream 
   </div></li><li><div>
     支持 Upstream 負載均衡, 支持 round-robin 及 consitent hash 算法 
   </div></li><li><div>
     支持 Upstream 主動健康檢查 
   </div></li><li><div>
     支持 TLS SNI 
   </div></li><li><div>
     支持 Prometheus 指標採集 
   </div></li></ul><div>
   架構圖如下： 
 </div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=NThhNWUyNzhkMGJmNDIxYzk3YzgyMGFlZDNlODUzZWNfRWs1ZzFVRTFrZUplWlRvRDB0N3ZCRUszOWRwUDBxbnlfVG9rZW46VHdPZWJubXBGb01vZEp4SHF6bWN1U0VLbmxlXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><span id="OSC_h1_1"></span><h1>新特性概覽</h1><span id="OSC_h2_2"></span><h2>Ingress API</h2><div>
   OpenNJet KIC 採用動態 API 方式實現基本路由/TLS 的變化的更改，當 Ingress 資源變化時，而不需要 reload OpenNJet 配置文件。我們採用單 server 多 location 的方式實現 HTTP host 頭匹配，和 path 匹配。如下圖所示： 
 </div><div>
   &nbsp; 
 </div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDBmZWU3MjhmNzIwZThiNGI5YWFmMjZmNDk5MmM2OWZfWERLNDg2QXNFRTJYMjdEYzhnT0hrajd4bWxzdjJVdElfVG9rZW46Snk5UWJnbmhKbzJnT0p4T0tkZGNxTnQ5bnZjXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><div>
   &nbsp; 
 </div><div>
   當 Ingress 資源中 host 或者 path 變化時，通過動態 location API 來更新 OpenNJet 的配置信息，而不是 reload OpenNJet 配置文件。 
 </div><div>
   &nbsp; 
 </div><div>
   當 Ingress 資源中關聯的 service 發生改變或者 service 關聯的 pod 進行了動態擴縮容時，我們通過動態 Upstream API(目前基於 lua 實現) 來更新 OpenNJet 的配置信息，而不是 reload OpenNJet 配置文件。資源變更應用如下表所述： 
 </div><div>
   &nbsp; 
 </div><div><table cellspacing="0" style="border-collapse:collapse; border:none; table-layout:fixed; width:500px"><tbody><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        資源變化 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        OpenNJet 配置信息變化方式 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:middle"><div>
        Ingress 資源變化 
      </div><div>
        &nbsp; 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:middle"><div>
        刪除新建 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:middle"><div>
        Ingress 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        動態 location API 
      </div><div>
        動態 Upstream API 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:middle"><div>
        &nbsp; 
      </div><div>
        內容 
      </div><div>
        &nbsp; 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        host 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        動態 location API 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        path 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        動態 location API 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        service 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        動態 Upstream API 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        pod 動態擴縮容 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        &nbsp; 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        endpoint 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        動態 Upstream API 
      </div></td></tr></tbody></table></div><span id="OSC_h2_3"></span><h2>VirtualServer CR API</h2><div>
   VirtualServer 是一個自定義資源，在 OpenNJet KIC 中用來替代 Ingress 資源，是一個替代方案。VirtualServer 除了具備 Ingress 的能力，還提供了更豐富的功能，比如 advanced content-based routing 等，可以靈活的配置匹配策略實現灰度發佈。 
 </div><div>
   &nbsp; 
 </div><div>
   VS 在處理一個路由時，高級路由匹配由 spec 中的 matches 定義。conditions 在匹配中定義條件，支持 
  <code>header</code>、 
  <code>cookie</code>、 
  <code>argument</code>、 
  <code>variable</code>。 
 </div><div>
   &nbsp; 
 </div><div><p>以下是一個 VS 的示例：</p><pre><code>apiVersion: k8s.njet.org/v1
kind: VirtualServer
metadata:
  name: cafe
  namespace: default
spec:
  host: cafe.example.com.vs
  routes:
  - action:
      pass: details
    matches:
    - action:
        pass: tea-post
      conditions:
      - value: POST
        variable: $request_method
    path: ~* \.html$
  - action:
      pass: ratings
    matches:
    - action:
        pass: productpage
      conditions:
      - cookie: version
        value: v2
      - value: GET
        variable: $request_method
    path: /productpage
  upstreams:
  - name: ratings
    port: 9080
    service: ratings
  - name: productpage
    port: 9080
    service: productpage
  - name: tea-post
    port: 80
    service: tea-post-svc
  - name: details
    port: 9080
    service: details
</code></pre><p>上圖 VS 中，配置了兩個路由：</p></div><ol><li><div>
     path 為\.html$ 的正則匹配，匹配以.html 結尾的請求，實現高級路由 (請求方法為 POST 的請求被路由到 
    <code>tea-post</code> upstream，其他請求被路由到 
    <code>details</code> upstream(默認處理)) 
   </div></li><li><div>
     path 為/productpage 的前綴匹配，實現高級路由 (請求方法為 GET 且 cookie 為 version=v2 的請求被路由到 
    <code>productpage</code> upstream，其他請求被路由到 
    <code>ratings</code> upstream(默認處理)) 
   </div></li></ol><div>
   實現方式與 Ingress 基本一致。 
 </div><span id="OSC_h2_4"></span><h2>動態 Upstream</h2><div>
   在 Upstream 配置更新方面，OpenNJet KIC 使用 lua 實現 Upstream 動態配置，來應對雲原生場景。在雲原生場景中，upstrem 變更是常態，比如集羣部署了新的服務、某服務進行了動態擴縮容、Pod 被重新調度等，這都導致 upstream 相關配置的變更。 
 </div><div>
   &nbsp; 
 </div><div><p>OpenNJet KIC 配置當中會生成一個默認的被稱為"upstream_balancer"的 upstream，此 upstream 會處理所有路由。當真實流量到來時，會交由內部 lua 上下文處理。"upstream_balancer"配置如下：</p><pre><code> upstream upstream_balancer {
        ### Attention!!!
        #
        # We no longer create "upstream" section for every backend.
        # Backends are handled dynamically using Lua.
        #
        ###

        server 0.0.0.1; # placeholder

        balancer_by_lua_block {
            balancer.balance()
        }

        keepalive 320;
        keepalive_time 1h;
        keepalive_timeout  120s;
        keepalive_requests 10000;
    }</code></pre></div><span id="OSC_h3_5"></span><h3>lua 上下文怎麼區分不同流量該由誰處理呢？</h3><div>
   首先，OpenNJet KIC 會通過動態 upstream API 接口創建所有 upstream 信息。 
 </div><div>
   &nbsp; 
 </div><div>
   其次，每個路由 (location) 都會關聯實際處理自己的 upstream 名稱。 
 </div><div>
   &nbsp; 
 </div><div>
   最後，實際處理流量的 upstream 名稱會被傳遞到 lua 上下文，最終保證流量被正確處理。 
 </div><div>
   路由與 upstream 關聯如下所示： 
 </div><div>
   &nbsp; 
 </div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=ZWY1Y2U2ZGY4ZDE1NjAyNTBkZTU0MjNkMGI2ZTUxZWRfMDJIRDMzNTF2cDYwV1B4VklobW9LSUphaXBLalNSOGlfVG9rZW46T09kRWIwMnRTb2RkVER4NXRYd2M0OFhFbjRmXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><span id="OSC_h3_6"></span><h3>Upstream 的更新流程</h3><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjNmMDU0ODY4NjFlNTAzODJlNzEwOTU1YmY4NmRjOGVfUGVSUFJWR0QwT291ZnBpb1JMbmZsT2xLS3ROQ082Tk5fVG9rZW46V2I3TWI4cVY2b1l4VUp4YTE4TmM5WTA2bkNiXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><span id="OSC_h2_7"></span><h2>Upstream 負載均衡</h2><div>
   Upstream 可以設置對應的負載均衡策略，目前支持默認的 round_robin，及一致性 hash。round_robin 使用輪詢的方式獲取 peer。一致性 hash 根據配置的 hash key 值來進行負載，相同的 key 值，將始終訪問同一個後端 peer。常用的 hash key 有： 
 </div><div>
   &nbsp; 
 </div><div><table cellspacing="0" style="border-collapse:collapse; border:none; table-layout:fixed; width:500px"><tbody><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        hash key 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        描述 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        $arg_{VAR} 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        根據 url 傳遞的參數 VAR 做一致性 hash 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        $http_{NAME} 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        根據 HEADER 傳遞的參數 NAME 做一致性 hash 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        $cookie_{NAME} 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        根據 Cookie 傳遞的參數 NAME 做一致性 hash 
      </div></td></tr><tr><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        $remote_addr 
      </div></td><td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"><div>
        根據客戶端的 IP 做一致性 hash 
      </div></td></tr></tbody></table></div><div>
   OpenNJet 可使用的內部變量與 Nginx 一致，可以參考文檔：https://nginx.org/en/docs/varindex.html 
 </div><div>
   &nbsp; 
 </div><div>
   Ingress 與 VirtualServer CR 都支持 Upstream 負載均衡策略配置。 
 </div><div>
   &nbsp; 
 </div><div>
   下面給出一個 VS 配置 Upstream 負載均衡的一個例子： 
 </div><div>
   &nbsp; 
 </div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=YjBjNWRlZjJjZjA5OWU3NjNiYzE5MjViYzZjMzIyZTZfRzZQVnBLdlFzRkNNamFCT3czSmxiMWU1VHBoUzk3MW1fVG9rZW46VDhKRmJQVzVkb2Y4SVh4YlRzWmNtSnFybk9mXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><div>
   &nbsp; 
 </div><div>
   上面的例子通過 lb-method: "chash $arg_uu" 進行顯式的聲明 Upstream 負載均衡算法為 chash 且以請求攜帶的參數 uu 為 hash key。 
 </div><span id="OSC_h2_8"></span><h2>Upstream 主動健康檢查</h2><div>
   OpenNJet KIC 提供了 Upstream 主動健康檢查的能力，確保所有請求都能被健康的上游後端處理，提高用戶體驗度。 
 </div><div>
   &nbsp; 
 </div><div>
   通過 Ingress、VirtualServer CR 配置 Upstream 的主動健康檢查， OpenNJet KIC 會通過單獨的一個 priviliege agent 進程對 upstream 的各 peer 進行檢查， 如果 peer 檢查失敗，並且失敗次數達到預先配置的閾值，健康檢查程序會將對應的 peer 從 upstream peer 列表中移除。被移除的 peer, 在之後的檢查中如果為健康狀態，並達到配置的閾值，將會觸發重新上線的操作。 
 </div><div>
   &nbsp; 
 </div><div>
   下圖為健康檢查架構圖： 
 </div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=ZWFjYmM3YmRjOGY3ODg5M2ViNDQzZDFmYjQ3NmQzYjFfU0xkeVFGellqakNiV3RlSFZ4dHVSdHJHT3ZXVkFtTUxfVG9rZW46UmhaeGJWeUJUb0gyT2F4NnB1d2NvMUR3bkpjXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><ul><li><div>
     更新 Upstream 數據時，生成一份 "raw hc backends" 的副本， 定時器中的健康檢查使用此副本中的數據進行。 當健康檢查結果需要觸發 peers 變更時，更新共享內存中的 upstream backends。 
   </div></li><li><div>
     目前健康檢查模塊的定時器時間間隔是 5 秒。策略中的健康檢查間隔需&gt;=5s 。 
   </div></li></ul><div>
   下面給出一個 VS 配置主動健康檢查的一個例子： 
 </div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=ZmRmMDRhOTIzODc5YTVlYzk3YTVmOWIwMTE1MWY5MGZfT3R0WDExZFRQcThQNWJyNUVWTldKM01hUUtCUjNOS0JfVG9rZW46QkNRUmJ4c0tJb1V4cFl4OFM5V2NTemNjbnRsXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=Y2RhMDhlOGI4ZDI1YTkxMGU2Njc0NmFhNzdiNDY4ZDFfcEFFU25VODN6REFXV3U3YkxzSHJCUWFMVU5LZDVvR2pfVG9rZW46SmkyY2JVV1Jrb0FjZUx4OGthRWN4czhpbjFlXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><span id="OSC_h2_9"></span><h2>TLS Termination/SNI</h2><div>
   OpenNJet KIC 處理 TLS 流量由內部端口 443 負責，支持 TLS Termination/SNI 功能，根據主機名在同一端口上進行多路複用。 
 </div><div>
   &nbsp; 
 </div><div>
   Ingress、VirtualServer CR 都支持 TLS Termination/SNI 配置，且 OpenNJet KIC 支持配置動態更新，不進行 reload，這一能力得益於 OpenNJet 提供的動態 map 能力。host 與證書的對應關係通過動態 map HTTP 接口進行更新。 
 </div><div>
   &nbsp; 
 </div><div>
   下面給出一個 VS 配置 TLS 的一個例子： 
 </div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=MWI2M2I4MmNkMzE4NTBlMWJkYmZkNzI3ZTVmYThmYjBfTU9BMEhoU2hzUXJ0NURoYmEwY28wVHFqNHlkVjJLd25fVG9rZW46Q1R1TWJWVEh4b1h4R2F4cmJoY2NtRGlWbkplXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><div>
   上面的例子配置期望把 
  <code>vstest.example.com</code>與 
  <code>a.test.com</code>對應的證書進行關聯。 
 </div><span id="OSC_h2_10"></span><h2>Prometheus 指標採集</h2><div>
   為了滿足用戶對業務的監控，OpenNJet KIC 目前提供了 VTS(virtual host traffic status) 指標採集，OpenNJet 使用定製的 vts 模塊，採集 upstream 的相關指標。 
 </div><div>
   &nbsp; 
 </div><div>
   OpenNJet KIC 容器中的 OpenNJet 進程通過 vts 模塊記錄 Upstream 的相關指標信息，並且 OpenNJet 提供 HTTP 接口獲取 Prometheus 格式的指標信息。 
 </div><div><p>KIC 服務中通過註解 Annotations 聲明 Prometheus 指標的採集端口及路徑。配置如下：</p><pre><code>apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/port: "12001"
    prometheus.io/scheme: http
    prometheus.io/scrape: "true"
    prometheus.io/path: "/stats"
  name: njet-ingress
  namespace: njet-ingress
spec:
  type: NodePort
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    name: http
  - port: 443
    targetPort: 443
    protocol: TCP
    name: https
  selector:
    app: njet-ingress</code></pre></div><div><img src="https://xw1ei7mxto.feishu.cn/space/api/box/stream/download/asynccode/?code=YmRlMTA2NDcwMGRkMGY0OGUwODAzYjdhNTQ0M2YzOGNfR3Y4V1B3WjNVWlJIZWtVR1F3VzJhM1JSZzBtZFoySURfVG9rZW46UlZ6c2JRR3pKb3RGTFN4bWZHSWNDU3Q1bkJlXzE3MDA2MzE1NzU6MTcwMDYzNTE3NV9WNA" referrerpolicy="no-referrer"></div><span id="OSC_h1_11"></span><h1>參考鏈接</h1><blockquote><div><span><span>OpenNJet 最早是基於 NGINX1.19 基礎 fork 並獨立演進，具有高性能、穩定、易擴展的特點，同時也解決了 NGINX 長期存在的難於動態配置、管理功能影響業務等問題。</span></span></div><div><a href="https://gitee.com/njet-rd/docs#/njet-rd/docs/blob/master/zh-cn/OpenNJet-K8s%20Ingress%20Controller%20V1.0-%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.md" rel="nofollow">KIC 用戶手冊</a><span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2F" target="_blank" rel="nofollow"><span><span>官網</span></span></a></div></blockquote><div>
   &nbsp; 
 </div></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 07:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6606114/blog/10150202</guid>
            <link>https://my.oschina.net/u/6606114/blog/10150202</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[李彥宏：文心大模型重構後的廣告系統，將在 Q4 帶來數億元增量收入]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:8px; margin-right:8px; text-align:justify"><span>百度已發佈 2023 Q3 財務報告：營收達 344.47 億元，歸屬於百度的淨利潤（non-GAAP）達 73 億元，同比增長 23%，營收、利潤均超市場預期。</span>AI 原生應用數據指標顯著增長。</p><p style="color:#333333; margin-left:8px; margin-right:8px; text-align:justify"><img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-14a0ea30e5e6ef4b3341542bf826cb94603.gif" width="300" referrerpolicy="no-referrer">&nbsp;<img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-874143a1ddce299439dc33cdf25795df6ef.gif" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:8px; margin-right:8px; text-align:justify"><img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-6fbc0b5c104be721ff5e78bb5a238858f54.gif" width="300" referrerpolicy="no-referrer">&nbsp;<img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-df789025af736acdc43a188db3e3f3bd2bf.gif" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:8px; margin-right:8px; text-align:justify"><span>在百度 Q3 財報電話會上，百度創始人、董事長兼首席執行官李彥宏表示，百度正在用文心大模型重構廣告系統，包括生成式創意、生成式定向等服務，這些舉措有望在四季度帶來數億元人民幣的增量收入。</span></p><p style="color:#333333; margin-left:8px; margin-right:8px; text-align:justify"><span>李彥宏稱，採用 AI 新功能的</span><span>廣告商在第三季度平均實現了高個位數的轉化率增長。以 IT 專業教育公司達內教育為例，在使用新功能後，轉化率提升 23.3%，ROI 提升 22.7%。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 06:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267596</guid>
            <link>https://www.oschina.net/news/267596</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sam Altman 重返 OpenAI 擔任首席執行官]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 剛剛<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FOpenAI%2Fstatus%2F1727205556136579362" target="_blank">官宣</a></u>：</p><blockquote><p>我們已達成原則性協議，<strong>讓 Sam 重返 OpenAI 擔任首席執行官</strong>，並組建由 Bret Taylor（主席）、Larry Summers 和 Adam D'Angelo 組成的新董事會。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f44588248368173cec2a3abc596ffd6f59c.png" referrerpolicy="no-referrer"></p></blockquote><p>Sam Altman 緊跟着就更新了<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1727207458324848883" target="_blank">推特</a></u>：</p><blockquote><p><img height="846" src="https://static.oschina.net/uploads/space/2023/1122/142244_GkaU_2720166.png" width="1290" referrerpolicy="no-referrer"></p></blockquote><p>微軟 CEO Satya Nadella <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsatyanadella%2Fstatus%2F1727207661547233721" target="_blank">秒轉</a></u><span>&nbsp;Sam 的推文，表示對 OpenAI 董事會的變化感到鼓舞，稱這是 OpenAI 邁向穩定、信息通達、有效治理的關鍵第一步。</span></p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1122/142413_uUCM_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>一直和 Sam 共進退的&nbsp;Greg Brockman<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fgdb%2Fstatus%2F1727208843137179915" target="_blank">淡定地表示</a></u>：<strong>今晚回去 OpenAI，繼續敲代碼</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-6db19ff94b9c239d5deb9a9658ae57271b2.png" referrerpolicy="no-referrer"><br> &nbsp;</p><hr><p>update：回來了，我感覺全都回來了<br><br><img src="https://oscimg.oschina.net/oscnet/up-d1b942ece5907a7bd94c906ffc262a6c802.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 06:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267591/sam-altman-returns-ceo-open-ai</guid>
            <link>https://www.oschina.net/news/267591/sam-altman-returns-ceo-open-ai</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Redis 之父用純 C 語言代碼實現 Telegram Bot 框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Redis 創始人 antirez 最近開源了一個小項目 BOTLIB&nbsp;<span>——&nbsp;純 C 語言代碼編寫的 Telegram Bot 框架 。</span></p><blockquote><p>地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fantirez%2Fbotlib" target="_blank">https://github.com/antirez/botlib</a></u></em></p></blockquote><p><img height="1668" src="https://oscimg.oschina.net/oscnet/up-2def2c40c083bd3744f89db768458900bf1.png" width="2458" referrerpolicy="no-referrer"></p><p>顧名思義，BOTLIB 用於創建 Telegram 對話機器人。目前該項目仍處於開發階段，請謹慎使用。</p><p>從 antirez 創建的另一個倉庫 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fantirez%2Ffailed-3d-prints-bot" target="_blank">https://github.com/antirez/failed-3d-prints-bot</a>) 可知，他用了一台帶網絡攝像頭的樹莓派來監控 3D 打印機，並在檢測到打印失敗時通過 Telegram 接收該狀態消息。</p><p>為了通過 Telegram 接收信息，他編寫了一個 Telegram Bot 框架來創建 Telegram 機器人，他所創建的這個機器人用途是檢測打印機的失敗狀態，並傳回一張該狀態對應的 3D 打印機實時圖像。</p><p><strong>延伸閲讀：</strong><em><u><a href="https://www.oschina.net/news/264564" target="_blank">Redis 創始人用 C 語言編寫最小聊天服務器：Smallchat</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 04:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267574</guid>
            <link>https://www.oschina.net/news/267574</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sam Altman 與 OpenAI 董事會展開談判]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">彭博社援引知情人士<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-21%2Faltman-openai-board-open-talks-to-negotiate-his-possible-return%23xj4y7vzkg" target="_blank">消息稱</a>，Sam Altman 已經私下和 OpenAI 的新任臨時首席執行官 Emmett Shear，以及至少一名董事會成員 Adam D'Angelo 展開了談判。一些致力於推動 Altman 復職的 OpenAI 投資者也參與了會談。</span></p><p><span style="color:#000000">多位人士表示，本次談判是&nbsp;OpenAI 董事會與&nbsp;Altman 溝通之間的一項重大進展，畢竟直到本週一，董事們在很大程度上都拒絕與其接觸。</span></p><p><span style="color:#000000">如果 Altman 成功迴歸，他將繼續擔任公司的首席執行官一職。在討論中的另一種方案中，Altman 還將成為過渡董事會的董事，且 Salesforce 公司前聯席首席執行官布 Bret Taylor 也可能擔任新董事會的董事。</span></p><p><span style="color:#000000">在與董事會的談判中，由 Airbnb Inc. 首席執行官 Brian Chesky 代表 Altman 進行發言，而 Shear 代表 D’Angelo&nbsp;和董事會。<span style="background-color:#ffffff">Bret Taylor&nbsp;</span>在調解中則更多的扮演的是中立角色。</span></p><p><img height="269" src="https://oscimg.oschina.net/oscnet/up-b769cdef524fa63ef3fca964112655bde21.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">希望 Altman 復職的 OpenAI 股東包括 Thrive Capital、Khosla Ventures 和 Tiger Global Management。董事會和 Altman 希望在感恩節假期前達成解決方案，解決圍繞公司領導層的混亂局面。</span></p><p><span style="color:#000000">此外，Shear 也在要求董事會提供 Altman 錯失行為的證據。如果董事會不能以書面形式向他明確傳達突然解僱 Altman 的理由，他也不打算繼續留在該公司。</span></p><p><span style="color:#000000">針對這一事件，彭博社分析師評論稱：</span></p><blockquote><p><span style="color:#000000">Sam Altman 可能重返 OpenAI 擔任首席執行官，這可能會加強微軟的戰略定位，尤其是如果微軟能夠在新董事會中獲得一席之地的話。這也可能是微軟更希望看到的結果，因為如果微軟僱傭了 OpenAI 的大部分員工，將面臨很高的法律風險。在監管障礙不斷的情況下，我們認為微軟收購 OpenAI 的可能性微乎其微。</span></p></blockquote><p>OpenAI 拒絕對談判發表評論。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 03:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267569/altman-openai-board-open-talks</guid>
            <link>https://www.oschina.net/news/267569/altman-openai-board-open-talks</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
