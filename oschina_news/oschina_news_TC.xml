<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 31 Jan 2024 06:31:16 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[業內首個代碼大模型標準正式發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年 1 月 25 日，<strong>中國信息通信研究院</strong>（以下簡稱「中國信通院」）與<strong>中國工商銀行</strong>聯合牽頭髮起的《<strong>智能化軟件工程技術和應用要求，第 1 部分：代碼大模型</strong>》（標準編號 AIIA/PG 0110-2023）標準正式發佈。</p><p>該標準規定了代碼大模型的技術能力和應用要求，適用於企業在代碼大模型的研發、評估和驗收等過程中，為代碼大模型能力的建設和改進提供參考，為代碼大模型的技術選型提供指引。</p><p>該標準分為通用能力、專用場景能力和應用成熟度三大部分，包括 16 個能力項，100 多個能力要求，主要從輸入多樣性、任務多樣性、語言完備度、結果可接收性、結果準確度等維度，對代碼大模型提出了全棧技術能力要求。</p><p><img src="https://oscimg.oschina.net/oscnet/up-bd265583840f7c2a1a2f4355c332c4d9473.png" referrerpolicy="no-referrer"></p><p>中國人工智能產業發展聯盟（AIIA）表示，智能化軟件工程領域持續湧現出以代碼大模型為首的三類大模型，<strong>代碼大模型數量最多，運維和測試大模型次之</strong>。</p><ul><li><p>代碼大模型以其強大的代碼理解、代碼生成、代碼檢查、代碼優化、研發問答等能力，助力軟件編碼效率和質量的提升；</p></li><li><p>測試大模型當前重點關注智能單測、測試腳本生成、測試數據生成等方面，未來將從系統測試和業務測試角度真正意義上提升測試能力；</p></li><li><p>運維大模型當前重點關注運維知識問答、工單處理等方面，未來將從故障識別、故障預測、運維安全等多維度推動 AIOps 全過程智能水平提升。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5ed8594e70a8f39cd8ec922525ed46bc740.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 06:25:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277058</guid>
            <link>https://www.oschina.net/news/277058</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[IntelliJ 負責人 Kirill Skrygan 成為 JetBrains 新任 CEO]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>JetBrains 公司正式對外宣佈了最新人事任命：原負責領導 IntelliJ 部門的 Kirill Skrygan&nbsp;將於 2024 年 2 月 1 日起擔任首席執行官。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-3943b858bab2621d791912e56f8421bca6a.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fblog%2F2024%2F01%2F30%2Fjetbrains-ceo-transition%2F" target="_blank">https://blog.jetbrains.com/blog/2024/01/30/jetbrains-ceo-transition/</a></u></em></p></blockquote><p>JetBrains 在公告寫道：</p><blockquote><p>在我們邁向人工智能發揮變革作用的新時代之際，公司已經建立了一個良好的底層基礎，並且可以在此基礎上繼續推動公司向前發展。</p><p>作為新階段的一部分，Kirill Skrygan 自 2010 年加入 JetBrains，並在過去幾年裏一直領導 IntelliJ 部門，他將於 2024 年 2 月 1 日擔任首席執行官一職。</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 06:09:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277057/jetbrains-ceo-transition</guid>
            <link>https://www.oschina.net/news/277057/jetbrains-ceo-transition</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Monibuca 2023 年終回顧]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>2023 年回顧</h1><ul><li>成立南京模擬不卡科技有限公司</li><li>monibuca.com 域名通過備案</li><li>開通 qq 頻道</li><li>開通微信公眾號</li><li>推出各產品的 docker 版</li><li>Jessibuca 亮相 LVS 大會</li><li>推出 API 調試工具（基於 ApiFox）</li></ul><h2>Monibuca</h2><ul><li>版本號從<code>v4.3.4</code> 到 <code>v4.7.4</code></li><li>修復大量 bug，穩定性大幅提升</li></ul><h3>重要功能</h3><ul><li>時光回溯 (v4.4.0)</li><li>內存回收 (v4.4.0)</li><li><code>WebRTC</code> 傳輸 <code>AAC</code>、<code>H265</code>(v4.4.13)</li><li>日誌多語言 (v4.5.0)</li><li>配置功能優化，可以用環境變量覆蓋配置 (v4.5.3)</li><li>鑑權機制 ( v4.5.5)</li><li>增加 <code>trace</code> 級別日誌 (v4.5.5)</li><li>讀取 <code>mp4</code> 流 (v4.5.5)</li><li>增加內部訂閲者機制 (v4.5.5)</li><li>支持<code>EnhancedRTMP</code>規範 (v4.5.6)</li><li>新增<code>idletimeout</code>配置 (v4.5.7)</li><li>增加全局配置項<code>disableall</code>(v4.5.8)</li><li>配置支持<code>yaml tag name</code>(v4.5.9)</li><li>支持 <code>RTMPS</code> (v4.6.1)</li><li><code>http/ws-h264/h265</code> 裸流支持（v4.6.2)</li><li>引擎引入<code>sync.Cond</code>替代偽自旋鎖（v4.6.2)</li><li>單元測試和基準測試（v4.6.5)</li><li>錄製支持 mp4 格式（v4.6.8)</li><li>流新增一個狀態（v4.7.0）</li><li>遠端推拉增加正則表達式（v4.7.0）</li><li>增加 av1 和 opus 支持（v4.7.2)</li></ul><h3>新增插件</h3><ul><li><code>Monitor</code>監控插件 (v4.5.0)</li><li><code>PS</code>接受 PS 流插件 (v4.5.7)</li><li><code>LL-HL</code> llhls 格式插件 (v4.6.1)</li><li><code>CascadeServer/CascadeClient</code>級聯插件 (付費)</li><li><code>Transcode</code>轉碼插件 (付費)</li><li><code>Snappro</code>快速截圖插件 (付費)</li><li><code>CDN</code>轉推 CDN 插件 (付費)</li><li><code>Crypto</code>加密插件 (付費)</li><li><code>Gb28181pro</code>高級 GB 插件 (付費)</li></ul><h2>Jessibuca</h2><h3>網絡層</h3><ul><li>WebRTC 協議流（<code>h26x</code>）對接 <code>m7s</code>、<code>srs</code>、<code>zlm</code>、<code>阿里雲</code> 等服務器</li><li>加密流（<code>M7S</code>）(<code>H26x</code>)</li><li><code>fmp4</code>協議</li><li><code>h26x</code>裸流格式</li><li><code>Hls</code>協議流（<code>h26x</code>）</li><li>TF 卡錄像流（倍速、保持連接）</li><li>SEI 幀解析</li></ul><h3>解碼層</h3><ul><li><code>H.26x</code><code>WASM</code>（<code>SIMD</code>) 多線程視頻 (1080P 及以上)</li><li><code>Mpeg-4</code> 視頻格式軟解碼</li><li><code>MP3</code>音頻</li></ul><h3>編碼層</h3><ul><li>語音通訊（<code>PCM</code>/<code>G711A</code>/<code>G711U</code>/<code>Opus</code>）</li><li>視頻錄製（<code>flv</code>、<code>mp4</code>）</li></ul><h3>UI 層</h3><ul><li>性能面板</li><li>底部 UI 按鈕自定義</li><li>loading 效果</li><li>進度條</li><li>PTZ 雲台</li><li>電子放大</li><li>水印（全屏、動態、幽靈）</li><li>AI（人臉識別、物品識別、遮擋物檢測、黑/綠/花屏檢測）</li><li>NxN 路多屏播放、拖拽排序、局部全屏</li></ul><h2>Rebebuca</h2><ul><li>1 月開發 v1 版本</li><li>11 月 v2 版本開源</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 03:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/langhuihui/blog/10993892</guid>
            <link>https://my.oschina.net/langhuihui/blog/10993892</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><p><strong># 2024.1.30&nbsp;</strong></p><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要點</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/276876/rwkv-5-world-7b-opensource" target="_blank">RWKV-5-World 7B 模型開源 —— 最環保、最節能的 AI 模型</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">2024 年 1 月 28 日，RWKV 開源基金會<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4hTFA2CMcInhGLZTqa_H4g" target="_blank">宣佈</a></u></strong>開源 RWKV-5-World 7B 模型。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">據介紹，「RWKV-5-World 7B」 是 RWKV 第五代架構 7B 參數大模型，也是 RWKV 迄今為止多語言性能最強的開源大模型。根據性能評測數據顯示，在 100% attention-free 和只訓練 1.1T tokens 的前提下，RWKV-5 7B 模型的多語言性能超過 Mistral，英文性能看齊 LlaMa2。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3d734a934d678a080b7392fed400e7c9c3a.png" referrerpolicy="no-referrer"></p><h3><u><a href="https://www.oschina.net/news/276901" target="_blank">Milk-V Vega: 全球首款 RISC-V 萬兆開源交換機正式發售</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">MilkV 於去年 8 月亮相了 「全球首款開源萬兆 RISC-V 網絡交換機 Milk-V Vega」。時隔數月，該產品現已上架官方淘寶店開售，定價 799 元。</p><p><span style="background-color:#ffffff; color:#333333">據介紹，Milk-V Vega 是 Milk-V 面向新一代網絡架構開發的一款小體積、高密度盒式開源萬兆網絡交換機，為用戶提供寬帶、語音、視頻、監控等多業務統一承載平台，多網融合覆蓋全業務；搭載國產 RISC-V 高可靠網絡交換芯片，幫助企業與用戶大幅簡化網絡架構，降低能耗成本與運維成本。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Milk-V Vega 支持完備的二層網絡協議處理功能，包括 L2 橋接，L2 組播和風暴抑制等；支持基於流、端口、協議、子網的 VLAN 功能；支持 STP，RSTP 和 QinQ 功能；支持防 DOS 攻擊，黑白名單和協議包濾除功能；支持濾鏡，鏈路聚合，OAM 報文發送和端口保護功能；支持入口及出口的 ACL 功能，還支持同步以太網，1588 功能。</p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-705210c8717e8741ceda531371652a2176d.png" referrerpolicy="no-referrer"></p><h3><u><a href="https://www.oschina.net/news/276877/meta-code-llama-70b" target="_blank">Meta 發佈全新代碼生成大模型 Code Llama 70B</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Meta 今天發佈了全新的代碼生成大模型 Code Llama 70B。據稱其 HumanEval 評分達到 67.8，達到 GPT-4 水準，是目前評分最高的開源大模型。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Code Llama 70B 是此前<span>&nbsp;</span><strong><u><a href="https://www.oschina.net/news/255350/meta-code-llama">Code Llama<span>&nbsp;</span></a></u></strong>的升級版本，包括三個模型：</p><ul style="list-style-type:disc; margin-left:0; margin-right:0"><li>CodeLlama-70B</li><li>CodeLlama-70B-Python</li><li>CodeLlama-70B-Instruct</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>開源地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodellama%2FCodeLlama-70b-hf" target="_blank">https://huggingface.co/codellama/CodeLlama-70b-hf</a></u></em></strong></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">用戶觀點</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-f545e933088dc337f246103e4b82c375daa.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">媒體觀點</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-e098404dded22f6bad87d9c419141da28f7.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日項目榜</span></span></span></span></span></span></strong></h2><p>GitHub 榜單：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a06e7992894706ed3ac49cab5b01c1cc732.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-1be56111bfc96a12468e0e12d2848382697.png" referrerpolicy="no-referrer"></p><blockquote><h4>在線閲讀完整日報內容，訪問：<strong><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC005%E6%9C%9F%EF%BC%9Anpm%20%E5%AD%98%E5%9C%A8%E5%A4%A7%E9%87%8F%E6%AD%A6%E6%9E%97%E5%A4%96%E4%BC%A0%E8%A7%86%E9%A2%91.pdf" target="_blank">開源日報第 005 期：npm 存在大量武林外傳視頻</a></u></strong></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><u><a href="https://www.oschina.net/news/276864" target="news">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 03:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277040</guid>
            <link>https://www.oschina.net/news/277040</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Python HTTP 庫 urllib3 支持直接在瀏覽器運行]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Python HTTP 庫 urllib3 最新版本 2.2.0 新增了一項重磅特性——<strong>可直接在瀏覽器運行</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-7e0846ecd450824c3e2a7cea0f00651c22c.png" referrerpolicy="no-referrer"></p></blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Furllib3.readthedocs.io%2Fen%2Fstable%2Freference%2Fcontrib%2Femscripten.html" target="_blank">根據介紹</a>，從 2.2.0 開始，urllib3 支持在 Pyodide 運行時中使用 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FFetch_API" target="_blank">JavaScript fetch API</a>，或者在 fetch API 不可用時（例如當跨源隔離未激活時）返回 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FXMLHttpRequest" target="_blank">XMLHttpRequest</a>。這意味着開發者可以使用該庫直接從瀏覽器發出 HTTP 請求。</p><p>由於 urllib3 的 Emscripten 支持與 API 兼容，這意味着依賴於 urllib3 的庫現在也可以在 Emscripten 和 Pyodide 環境中使用。</p><p>此外，urllib3 已初步支持 HTTP/2，與此同時其團隊正在籌集更多資金（大約 4 萬美元）來完成該功能。他們表示這筆資金能確保項目在 2023 年財務支持急劇下降後獲得長期可持續維護。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-eae61d14f918da17c8b18cf92c1ed05432d.png" referrerpolicy="no-referrer"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsethmlarson.dev%2Furllib3-is-fundraising-for-http2-support" target="_blank">https://sethmlarson.dev/urllib3-is-fundraising-for-http2-support</a></em></u></p></blockquote><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Furllib3%2Furllib3%2Freleases%2Ftag%2F2.2.0" target="_blank">詳情查看 Release Notes</a></u>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 03:22:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277037/urllib3-works-in-the-browser</guid>
            <link>https://www.oschina.net/news/277037/urllib3-works-in-the-browser</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[分析了 1.5 億行代碼發現：AI 編程助手降低代碼質量]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>摘要</h2><p>2023 年是 GitHub Copilot 大放異彩的一年。在短短不到兩年的時間裏，這款 AI 編程助手已從一個初步的原型迅速成為眾多開發者和企業中不可或缺的重要工具 [1]。它的迅猛發展開啓了編寫代碼的新紀元。</p><p>GitHub 已經發布了數份關於 AI 如何影響軟件開發的增長和影響的研究。他們的一項重要發現是，開發者在使用 Copilot 時，編碼速度提升了「55%」。面對大量由 LLM 生成的代碼，我們不禁要問：這些代碼在質量和可維護性上與人工編寫的代碼相比如何？它們是不是更像經驗豐富的高級開發者的精心作品，還是更接近短期合同工的零散拼湊？</p><p>為此，GitClear 收集了從 2020 年 1 月到 2023 年 12 月之間的 153 百萬行代碼變更記錄 [A1]。這是目前已知最大的用於分析代碼質量差異的高度結構化代碼變更數據集 [A2]。</p><p>我們發現了一些關於代碼可維護性的令人擔憂的趨勢。代碼變更率 —— 指在編寫後不到兩週就被修改或撤銷的代碼行所佔的比例 —— 預計在 2024 年將是 2021 年 AI 出現之前的兩倍。我們還發現，「新增代碼」和「複製/粘貼代碼」的比例相比於「更新的」、「刪除的」和「移動的」代碼在上升。從這個角度來看，AI 生成的代碼更像是一位頻繁更換工作的合同工寫的臨時代碼，容易違反他訪問的代碼庫的 DRY（Donot Repeat Yourself，不重複自己）原則。。</p><p>我們以一些針對管理者如何在這種逆流中保持代碼高質量的建議作為本文的總結。</p><h2>GitHub: 「使用 AI 編程，提升效率 55%，增加代碼量 46%，為 GDP 貢獻 1.5 萬億美元」</h2><p>這樣驚人的數據背後，GitHub 的 CEO Thomas Dohmke 不僅忙於日常的 CEO 工作，還專門抽時間撰寫了關於 AI 革命的博客文章和研究論文。他在 2023 年發佈於 GitHub 的作品，詳細敍述了 Copilot 快速普及的激動人心的故事。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0d299b229f2006a677274efc1e61252dc26.png" referrerpolicy="no-referrer"></p><p><em>來自 Dohmke 2023 年的博客文章《AI 驅動開發者生命週期的經濟影響及從 GitHub Copilot 學到的經驗》</em></p><p>Dohmke 在博客中提出，目前已有超過 20,000 家組織在使用 GitHub Copilot for Business。這緊隨其在 2023 年 2 月宣佈的消息，即在 Copilot for Business 推出時，「已有超過一百萬人」在使用個人版 Copilot。GitHub 在提高 AI 質量和公開透明地分享其成果方面取得了令人讚賞的進展。</p><p>到底有多少開發者正在使用 AI 編寫代碼？在 GitHub 2023 年 6 月與 Wakefield Research 合作的一項獨立研究中，他們指出：「在美國大型公司工作的開發者中，有 92% 使用 AI 編程工具。」他們還強調，有 70% 的開發者認為使用 AI 帶來了顯著好處。不過，O’Reilly Publishing 在 2023 年 8 月的一項調查顯示，67% 的受訪開發者表示他們還沒有使用 ChatGPT 或 Copilot。這暗示了 GitHub 在市場上仍有很大的增長潛力。</p><h2>AI 生成代碼存在的問題</h2><p>開發者之所以採用 Copilot，是因為他們相信這款工具能夠加快編碼速度。GitHub 的研究發現，使用 Copilot 的開發者的滿意度提高了 75%。這表明開發者普遍接受了這款產品。但是，這並不意味着那些負責維護代碼的人也會感到同樣滿意。資深代碼研究員 Adam Tornhill（著有《Your Code as a Crime Scene》）對此表示懷疑：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bd20f9adfaf74d1818568d65d3765166e5d.png" referrerpolicy="no-referrer"></p><p><em>開發者研究人員對 AI 輔助編程的影響持擔憂態度</em></p><p>GitHub 聲稱，使用 Copilot 編寫代碼的速度提高了 55%。但問題是，有些本不應編寫的代碼怎麼辦？正如《Clean Code: A Handbook of Agile Software Craftsmanship》的作者 Robert Martin 所説，代碼的閲讀時間是編寫時間的十倍。更快地寫出低質量代碼，意味着後續閲讀代碼的人將面臨更多困難。</p><p>這只是使用 AI 助手的開發者所面臨的眾多挑戰之一。其他挑戰包括：</p><ol><li>頻繁收到增加代碼的建議，卻很少有關於更新、移動或刪除代碼的建議。這是源於文本環境中代碼編寫時的界面限制。</li><li>評估代碼建議可能耗費大量時間，尤其是在有多個自動建議系統相互競爭的環境中，如流行的 JetBrains IDEs（參見 [11]）。</li><li>代碼建議的優化並非基於和代碼維護者相同的激勵機制。代碼建議算法旨在提出最可能被接受的建議，而代碼維護者則努力減少需要閲讀的代碼量（即，理解如何調整現有系統）。</li></ol><p>這些問題可能解釋了為什麼初級開發者比經驗豐富的開發者更傾向於接受代碼建議。根據 GitHub 的研究：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-261e68ce302259933f0288c5bd57dc43fc8.png" referrerpolicy="no-referrer"></p><p><em>GitHub 的數據顯示，相比經驗豐富的開發者，初級開發者使用 Copilot 的頻率高出大約 20%</em></p><p>經驗豐富的開發者更深刻地理解維護代碼的長期成本。如果他們更不願使用 AI 的代碼建議，那麼這是否意味着初級開發者現在正以前所未有的速度貢獻更多額外的代碼呢？</p><h2>代碼變更的分類</h2><p>為了探究代碼質量如何隨着時間變化，我們研究了在 AI 應用日益廣泛的 2023 年與之前幾年，代碼變更類型的不同。GitClear 將代碼的變更動作分為七大類別，本研究分析了其中的六種：</p><ol><li>新增代碼。指新增加的獨立代碼行，不包含對現有代碼的小幅修改（這類修改被標記為「更新」）。此外，新增代碼也不包括那些被添加、刪除後又重新加入的代碼行（這些行被標記為「更新」和「變動」）。</li><li>刪除代碼。指被移除、提交併且在隨後的至少兩週內沒有被重新加入的代碼行。</li><li>移動代碼。指被剪切並粘貼到新文件或同一文件中新的函數位置的代碼行。按照定義，「移動」的操作中，提交時代碼內容不變，除了代碼前的空格部分可能會有所改變。</li><li>更新代碼。基於已存在的代碼行，通過修改大約三個詞或更少的詞彙來提交的新代碼行。</li><li>查找/替換代碼。這種變更模式中，同一字符串在三個或更多位置被替換為統一的新內容。</li><li>複製/粘貼代碼。除了編程語言的關鍵字（例如，<code>end</code>，<code>}</code>，<code>[</code>）外，相同的代碼內容被提交到一個提交中的多個文件或函數。</li><li>無效操作代碼。微小的代碼更改，如空格或同一代碼塊內的行號變更。這類無效操作的代碼變更沒有包含在本研究中。</li></ol><p>GitClear 對代碼操作的具體實例可以在其「Diff Delta」文檔中找到。自 2020 年起，GitClear 開始按這些操作分類 git 倉庫。截至 2024 年 1 月，GitClear 已分析並分類了大約十億行代碼，這些代碼來自於四年間的各種來源，包括商業客戶（例如，NextGen Health, Verizon）和知名的開源項目（例如，Facebook 的 React 項目，谷歌的 Chrome 瀏覽器）。在這些代碼中，有 1.53 億行是有意義的非無效操作的代碼變更，被用於本次研究。</p><p>隨着代碼變更操作的不斷演進，我們也在研究所謂的「變動代碼」（Churned code）的變化趨勢。它並不算是一種標準的代碼操作，因為一行變動代碼可能涉及到多種不同的操作，如代碼的「新增」（Added）、「刪除」（Deleted）或「更新」（Updated）。一行代碼要被視作「變動的」，它必須被創建並推送到 git 倉庫中，之後在隨後的兩週內被回退或進行重大修改。可以將 Churn 理解為最初由作者編寫、提交併推送到公司 git 倉庫時，那些不完整或錯誤的更改。</p><h2>Copilot 對代碼編輯操作趨勢的影響</h2><p>為了深入瞭解 Copilot 如何影響代碼質量，我們對 GitClear 觀察到的各種代碼行操作進行了分析，這些操作按照代碼編寫的年份來分類（依據 git 提交記錄中的 authored_at 日期 [12]）。相關的詳細數據可以在附錄中找到。下面是各年份的操作百分比：</p><table><tbody><tr><th>&nbsp;</th><th>新增</th><th>刪除</th><th>更新</th><th>移動</th><th>複製/粘貼</th><th>查找/替換</th><th>代碼波動</th></tr></tbody><tbody><tr><td>2020</td><td>39.2%</td><td>19.5%</td><td>5.2%</td><td>25.0%</td><td>8.3%</td><td>2.9%</td><td>3.3%</td></tr><tr><td>2021</td><td>39.5%</td><td>19.0%</td><td>5.0%</td><td>24.8%</td><td>8.4%</td><td>3.4%</td><td>3.6%</td></tr><tr><td>2022</td><td>41.0%</td><td>20.2%</td><td>5.2%</td><td>20.5%</td><td>9.4%</td><td>3.7%</td><td>4.0%</td></tr><tr><td>2023</td><td>42.3%</td><td>21.1%</td><td>5.5%</td><td>16.9%</td><td>10.5%</td><td>3.6%</td><td>5.5%</td></tr><tr><td>2024</td><td>43.6%</td><td>22.1%</td><td>5.8%</td><td>13.4%</td><td>11.6%</td><td>3.6%</td><td>7.1%</td></tr></tbody></table><p>這些數據在圖表中的展現方式是這樣的：左軸顯示了代碼變更操作的比例（這些百分比總和為 100%）。右軸和淺藍色線條則展示了與之相應的「代碼波動」變化。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5056ad3d85208cd11c97d7cbc2e08f934a3.png" referrerpolicy="no-referrer"></p><p>對於 2024 年的預測，我們利用 OpenAI 的 gpt-4-1106-preview 模型，通過對現有數據進行二次迴歸分析得出。附錄中詳細介紹了我們如何使用 OpenAI 模型進行這一分析。鑑於 GitHub 報告的 Copilot 的迅猛發展以及 AI 智能體的普遍應用，可以預見 2024 年的趨勢將延續 2022 年開始顯現的模式，並在 2023 年得到加速。單從 2022 年到 2023 年各種操作頻率的變化來看，我們可以發現三個可能影響代碼質量的警示信號：</p><table><tbody><tr><th>操作</th><th>同比變化</th></tr></tbody><tbody><tr><td>添加</td><td>+3.1%</td></tr><tr><td>刪除</td><td>+4.8%</td></tr><tr><td>更新</td><td>+5.2%</td></tr><tr><td>移動</td><td>-17.3%</td></tr><tr><td>複製/粘貼</td><td>+11.3%</td></tr><tr><td>查找/替換</td><td>-1.3%</td></tr><tr><td>代碼變動率 (Churn)</td><td>+39.2%</td></tr></tbody></table><h2>解讀代碼操作變化的含義</h2><p>2023 年最顯著的代碼操作變化發生在「代碼變動率 (Churn)」、「移動」和「複製/粘貼」這幾個方面。我們在這一節將詳細探討這些變化背後的意義。</p><h3>代碼變動率的顯著增長</h3><p>所謂的「代碼變動率 (Churn)」是指代碼被推送到倉庫後，接着在兩週內被撤銷、移除或更新的比例。在開發者親自編寫所有代碼的情況下，這種情況相對較少見——2023 年之前，只有 3-4% 的代碼會發生這樣的變動。不過，在 2022 年就已經出現了這種趨勢的上升，當時代碼變動率躍升至 9%。值得注意的是，2022 年是人工智能編程助手 Copilot 首次以測試版形式推出，同時也是 ChatGPT 開始被廣泛使用的一年。</p><p>在 2022 至 2023 年期間，AI 輔助工具的興起與推送到代碼倉庫的「錯誤代碼」密切相關。根據引用資料 [1] 和 [8]，如果我們假設 Copilot 在 2021 年的普及率為 0%，2022 年為 5-10%，2023 年為 30%，那麼這些因素之間的相關性極高，皮爾森相關係數高達 0.98（更多關於這一計算的細節，請參見附錄中的「代碼變動率與 Copilot 的相關性」部分）。這意味着，隨着 AI 輔助工具的使用增加，代碼變動率也在相應增長。</p><p>隨着代碼變動率的普遍增加，錯誤代碼被部署到生產環境的風險也隨之增大。如果這一趨勢持續到 2024 年，那麼超過 7% 的代碼更改可能會在兩週內被撤銷，這將是 2021 年的兩倍。根據這些數據，我們預計 Google DORA 的「變更失敗率」將在今年晚些時候發佈的「2024 年 DevOps 狀態報告」中有所增加，前提是該研究包含了 2023 年使用 AI 輔助的開發者數據。</p><h3>代碼移動越少意味着重構和複用的減少</h3><p>通常在重構現有代碼系統時，我們會發現代碼的移動。重構的系統，尤其是代碼的移動，是實現代碼複用的關鍵。隨着產品的不斷擴展，開發者往往需要將現有代碼重組到新的模塊和文件中，以便於新功能的複用。對於經驗豐富的開發者來説，代碼複用的優勢非常明顯——與新編寫的代碼相比，已經在實際環境中被測試並證實穩定的代碼顯得更加可靠。而且，經過多人修改的代碼往往包含了豐富的文檔，這大大加快了新手開發者對模塊的理解速度。</p><p>結合「複製/粘貼」代碼的增加，可以清楚地看到，當前的 AI 助手似乎在一定程度上阻礙了代碼的複用。相較於進行重構和遵循 DRY（「不要重複自己」）原則，這些助手更傾向於提供一種快捷方式，讓開發者重複使用現有代碼。</p><h3>複製/粘貼的代碼會導致未來的維護困難</h3><p>複製/粘貼的代碼可能是長期維護代碼中最大的難題之一。當開發者重複使用非關鍵字的代碼行時，實際上是在暗示他們沒有時間去深入研究之前的實現方式。這種重複添加代碼的做法，將整合實現重複功能的任務留給了未來的維護者。</p><p>大多數開發者更喜歡「實現新功能」而不是「審視潛在可複用的代碼」，因此複製/粘貼的代碼往往會過期仍然被使用。尤其在經驗不足的團隊中，可能缺乏有權威的代碼維護者來移除這些重複的代碼。即便是資深開發者，也需要付出巨大的努力和決心去充分理解代碼，以便將其刪除。</p><p>如果沒有 CTO 或工程副總裁定期安排時間來減少技術債務，那麼由於高層的時間壓力，新添加的複製/粘貼代碼可能永遠不會被整合到支撐長期開發速度的組件庫中。</p><p>根據 GitClear 的操作，只有在單次提交中重複的代碼才會被計算。因此，2023 年測量到的 11% 的複製/粘貼比例，可能只是 2024 年代碼庫中悄然增加的總複製量的一小部分。</p><h2>修訂代碼年齡趨勢分析</h2><p>我們使用了一個獨立的方法來評估 2023 年相比之前代碼質量的變化：分析 GitClear 提供的「代碼溯源」數據。所謂「代碼溯源」，其實就是要看代碼從被寫出到最終被更新或刪除的時間長度。</p><table><tbody><tr><th>年份</th><th>少於 2 周</th><th>少於一個月</th><th>少於一年</th><th>1-2 年</th></tr></tbody><tbody><tr><td>2020</td><td>65.9%</td><td>8.7%</td><td>21.8%</td><td>3.6%</td></tr><tr><td>2021</td><td>66.7%</td><td>9.0%</td><td>20.5%</td><td>3.8%</td></tr><tr><td>2022</td><td>64.7%</td><td>9.9%</td><td>21.1%</td><td>4.4%</td></tr><tr><td>2023</td><td>71.3%</td><td>9.3%</td><td>16.4%</td><td>3.0%</td></tr><tr><td>2024</td><td>74.4%</td><td>9.1%</td><td>14.1%</td><td>2.4%</td></tr></tbody></table><p>根據這些數據，我們可以看到：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1d1e4582aa2a1e3988d79b7610eac2f0736.png" referrerpolicy="no-referrer"></p><h2>解讀代碼年齡的趨勢</h2><p>對「代碼溯源」的數據分析揭示了一個有趣的現象，即在 2022 年到 2023 年間，代碼的更新速度加快了。特別是，不到兩週就被替換的代碼比例增加了 10%。同時，超過一個月的代碼更新頻率在 2023 年比 2022 年下降了 24%（2023 年為 19.4%，而 2022 年為 25.5%）。</p><p>這一趨勢顯示，在 AI 助手普及之前，開發者更可能會選擇最近編寫的代碼進行改進和再利用。根據 Techreport 的一項調查[5]，早在 2020 年代初，大約 70% 的項目採用了敏捷開發方法。在敏捷方法中，每個 Sprint（通常持續 2-3 周）都會規劃和執行新的功能。這與我們的數據相符，表明大約在 2020 年左右，團隊在每個 Sprint 結束後，可能會聚在一起討論最近的工作成果，以及如何在接下來的 Sprint 中再次利用這些成果。</p><h2>後續研究的思考題</h2><p>我們能否設定激勵措施來應對 2024 年代碼建議引擎中普遍的「添加後即忘記」的問題？</p><p>儘管我們可以訓練 AI 識別代碼整合的機會，關鍵在於它何時被觸發？我們需要一個新的用戶界面來複查代碼的刪除和更新，以及潛在的新增內容。同時，那些導致團隊今天無法騰出時間來減輕技術債務的管理層壓力，可能也會妨礙他們採用一種假設性的「代碼清理」工具。但如果有代碼助手的開發者對探索如何整合代碼感興趣，GitClear 願意與他們合作，詳細聯繫方式見附錄。</p><p>另一個值得關注的問題是：額外代碼對開發進度的影響速度有多大？特別是對於複製/粘貼的代碼，庫中代碼行數與開發者修改這些代碼的速度之間幾乎肯定存在負相關關係。現在的疑問是：「累積的複製/粘貼技術債務何時變得不可忽視？」瞭解這種減速效應發生的速率可以幫助未來的工具指導管理者何時應該減少開發新功能的時間。</p><p>最後一個探索的問題是：與 2020-2022 年相比，現在發生的複製/粘貼代碼的總比例是多少？由於 GitClear 目前僅測量單個提交中的複製/粘貼代碼，因此整體的複製/粘貼量（文件中重複的所有非關鍵字、非註釋代碼行）可能是 GitClear 當前測量值的兩倍。2024 年，複製/粘貼代碼真的會佔到所有代碼操作的 20-25% 嗎？</p><p>GitClear 將在未來的研究中探討這些問題，並鼓勵該領域的其他研究人員共享他們的數據。如果您有興趣與 GitClear 合作進行進一步研究，請查閲附錄中的聯繫信息。</p><h2>結論：開發者為何保持謹慎？</h2><p>根據我們分析的兩項關鍵數據，2023 年代碼質量面臨明顯下滑，這與大語言模型 (LLMs) 特別是 AI 代碼助手的廣泛應用密切相關。</p><p>GitHub 與 Wakefield 研究所在 2023 年的一項調查顯示，開發者已經意識到代碼質量的降低。當被問及「在沒有 AI 的情況下，應以哪些指標評估你的工作？」時，他們最關注的是「協作和溝通」，其次是「代碼質量」。</p><p>但當問題轉向「在使用 AI 時，應以哪些指標評估你的工作？」時，他們的關注點發生變化，「代碼質量」成為了最關注的問題，而「生產事件數量」上升為第三大關注點：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c3c950cc95effe8fe6f9b6d78a0706b2ea6.png" referrerpolicy="no-referrer"></p><p><em>摘自 GitHub 關於 AI 影響的調查</em></p><p>儘管開發者個人可能沒有足夠的數據來解釋為什麼使用 AI 時「代碼質量」和「生產事件」成為更加緊迫的問題，我們的數據提供了一個可能的解釋：當開發者被大量快速且簡單的短期有效建議所淹沒時，他們往往會不斷增加代碼行數，卻忽視了檢查現有系統是否可以優化重用。</p><p>對於那些通過 Tab 鍵得到複製/粘貼建議的經驗不足的開發者來説，解決這一問題並非易事。工程領導們需要密切關注新數據，並思考這些數據對未來產品維護的潛在影響。開發者分析工具，如 GitClear，能夠幫助識別問題代碼的累積速度。需要考慮的關鍵問題有：</p><ol><li>代碼複用比例是否在下降？</li><li>代碼的移動和複製/粘貼量是否有所變化？</li><li>開發者發現代碼複用機會的難易程度如何？</li></ol><p>關於 GitClear 如何應對這些問題的進一步討論見 [A3]。</p><p>AI 助手和 Copilot 如何重塑開發者的角色？無疑，隨着 AI 的普及，我們進入了一個代碼行數增加速度空前的時代。2024 年更值得關注的問題是：誰將負責整理這一切留下的爛攤子？</p><h2>引用</h2><ol><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-06-27-the-economic-impact-of-the-ai-powered-developer-lifecycle-and-lessons-from-github-copilot%2F" target="_blank">探索 AI 驅動的開發者生命週期帶來的經濟效益：GitHub Copilot 的案例分析</a>[GitHub]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-02-14-github-copilot-for-business-is-now-available%2F" target="_blank">GitHub Copilot for Business：企業級智能編程助手</a>[GitHub]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2306.15033" target="_blank">軟件開發領域的重大變革：AI 驅動下的開發者生命週期經濟與生產力分析</a>[GitHub]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1_zHZSSU5GsuORb776sRVNkuKoHXS7e2smJWWkn1Kxds%2Fedit%23slide%3Did.g9a6371a948_0_732" target="_blank">深入瞭解 Diff Delta 和 Commit 組</a>[GitClear]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechreport.com%2Fstatistics%2Fhow-many-companies-use-agile%2F" target="_blank">Techreport 調查顯示：超過七成團隊採用敏捷開發模式</a>[Techreport]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gitclear.com%2Fhelp%2Ftechnical%2Fcode_provenance" target="_blank">代碼溯源：它是什麼，為何重要？</a>[GitClear]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-06-13-survey-reveals-ais-impact-on-the-developer-experience%2F" target="_blank">調查顯示 AI 如何改變開發者的工作體驗</a>[GitHub]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oreilly.com%2Fradar%2Fthe-next-generation-of-developer-productivity%2F" target="_blank">領略下一代開發者生產力的風采</a>[O’reilly]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpragprog.com%2Ftitles%2Fatcrime2%2Fyour-code-as-a-crime-scene-second-edition%2F" target="_blank">當你的代碼變成犯罪現場</a>[Pragmatic Programmers]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.goodreads.com%2Fbook%2Fshow%2F3735293-clean-code" target="_blank">敏捷軟件工藝中的代碼潔淨之道：實用手冊及其引用</a>[Robert C. Martin, 作者]</li><li>[JetBrains AI：提升你的編程工具，迎接新的自由 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fai%2F" target="_blank">https://www.jetbrains.com/ai/</a>)[JetBrains]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit-scm.com%2Fdocs%2Fgit-commit" target="_blank">Git 提交指南：深入瞭解 git-commit</a>[Git 文檔]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gitclear.com%2Fhelp%2Ftech_debt_inspector_list_directories_by_developer_velocity" target="_blank">如何使用 Tech Debt 瀏覽器優化代碼</a>[GitClear]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDon%2527t_repeat_yourself" target="_blank">「不要重複自己」原則的智慧</a>[Wikipedia]</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FAdamTornhill%2Fstatus%2F1729592297887502611" target="_blank">X：Adam Tornhill 分享的思考</a>[X/Twitter]</li></ol><blockquote><p>本文已獲授權轉載。</p><p>原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitclear-public.s3.us-west-2.amazonaws.com%2FCoding-on-Copilot-2024-Developer-Research.pdf" target="_blank">Coding on Copilot</a><br> 作者：William Harding,Matthew Kloster<br> 譯文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaoyu.io%2Ftranslations%2Fllm%2Fcoding-on-copilot-2024-developer-research" target="_blank">在 Copilot 的協助下編程白皮書——2023 年的數據顯示了代碼質量面臨的挑戰</a><br> 譯者：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaoyu.io%2F" target="_blank">寶玉</a></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 02:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277025/coding-on-copilot-2024-developer-research</guid>
            <link>https://www.oschina.net/news/277025/coding-on-copilot-2024-developer-research</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GLM-4 模型開放 API 正式上線]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">2024 年 01 月 16 日，智譜 AI 正式推出了新一代基座大模型 GLM-4，並宣佈了一系列產品升級。時至今日，GLM-4 模型的開放 API 正式上線。所有開發者均可通過智譜 AI 的開放平台接入 GLM-4 模型開放 API。</span></p><p><strong><span style="color:#000000">網址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopen.bigmodel.cn%2Fdev%2Fapi%23glm-4" target="_blank">https://open.bigmodel.cn/dev/api#glm-4</a></strong></p><p><span style="color:#000000">根據介紹，新一代基座大模型 GLM-4，支持更長上下文；更強的多模態；支持更快推理速度，更多併發，大大降低推理成本；同時 GLM-4 增強了智能體能力。</span></p><ul><li><p><span style="color:#000000"><strong>基礎能力（英文）：</strong>GLM-4 在 MMLU、GSM8K、MATH、BBH、HellaSwag、HumanEval 等數據集上，分別達到 GPT-4 94%、95%、91%、99%、90%、100% 的水平。</span></p></li><li><p><span style="color:#000000"><strong>指令跟隨能力：</strong>GLM-4 在 IFEval 的 prompt 級別上中、英分別達到 GPT-4 的 88%、85% 的水平，在 Instruction 級別上中、英分別達到 GPT-4 的 90%、89% 的水平。</span></p></li><li><p><span style="color:#000000"><strong>對齊能力：</strong>GLM-4 在中文對齊能力上整體超過 GPT-4。</span></p></li><li><p><span style="color:#000000"><strong>長文本能力：</strong>在 LongBench（128K）測試集上對多個模型進行評測，GLM-4 性能超過 Claude 2.1；在「大海撈針」（128K）實驗中，GLM-4 的測試結果為 128K 以內全綠，做到 100% 精準召回。</span></p></li><li><p><span style="color:#000000"><strong>多模態-文生圖：</strong>CogView3 在文生圖多個評測指標上，相比 DALLE3 約在 91.4% ~99.3% 的水平之間。</span></p></li></ul><p><img height="380" src="https://oscimg.oschina.net/oscnet/up-4fe971d080041b4d60fc9d6078b26f54d9f.png" width="500" referrerpolicy="no-referrer">&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 02:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277024</guid>
            <link>https://www.oschina.net/news/277024</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Opera 將推出全球首款非 WebKit 內核的 iOS 瀏覽器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>崑崙萬維旗下海外信息分發與元宇宙平台 Opera 近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsgKWxkIL0pIwCN7x7NXXYw" target="_blank">宣佈</a>，將為歐洲的 iPhone 和 iPad 用戶帶來一款基於自研引擎的全新 AI 瀏覽器「Opera One」。</p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-e479abd2879e446aeb1c15c3023eb129f64.jpg" width="500" referrerpolicy="no-referrer"></p><p>Opera 計劃於 3 月份首次亮相這款新瀏覽器，屆時 DMA（歐洲數字市場法案）將生效。由於這些變化僅在歐盟實施，Opera 強烈鼓勵蘋果將這些增強功能推廣至全球 iOS 用戶。</p><p>為了遵守 DMA，蘋果決定允許開發者提交非基於 WebKit 的瀏覽器，包括 Web 瀏覽器應用和在 iOS 應用中顯示網頁的應用內瀏覽器。Opera 表示，這些變化將使他們有機會為 iPhone 用戶提供 Safari 之外的人工智能瀏覽器。</p><p>目前，Opera 是全球最大的第三方獨立瀏覽器。此前，Opera 於 2023 年 6 月 20 日推出旗艦瀏覽器「Opera One」，全面引入 Aria 人工智能助手，用戶只需註冊 Opera 賬戶即可免費使用。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 02:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277020</guid>
            <link>https://www.oschina.net/news/277020</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME Project Handbook：面向 GNOME 貢獻者的官方指南]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GNOME 團隊上線了新網站：<strong><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhandbook.gnome.org%2Findex.html" target="_blank">GNOME Project Handbook</a></u></em></strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-f14ac879fd6ea4b29cc11ea770593bbf2a3.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.gnome.org%2Faday%2F2024%2F01%2F30%2Fannouncing-the-gnome-project-handbook%2F" target="_blank">https://blogs.gnome.org/aday/2024/01/30/announcing-the-gnome-project-handbook/</a></u></em></p></blockquote><p>官方稱這份全新、完全重寫的文檔專門為 GNOME 貢獻者創建，旨在幫助新手貢獻者參與 GNOME 桌面環境的開發。因此《GNOME Project Handbook》不會為使用 GNOME 的用戶提供技術文檔，也不包含用戶文檔，以及不為應用程序和庫提供面向公眾的主頁。它所包含的是作為 GNOME 貢獻者進行操作所需的信息。</p><blockquote><p>該站點包含參與 GNOME 項目所需的所有信息。它適用於新的和現有的 GNOME 貢獻者。</p><p>如果您是 GNOME 新手，該手冊是瞭解 GNOME 如何工作的好地方，包括每個團隊的工作、如何訪問 GNOME 開發平台以及如何與其他項目成員溝通。</p><p>如果您已經在為 GNOME 做出貢獻，那麼您可以在本手冊中找到重要的參考信息，例如開發計劃、活動詳細信息以及如何申請旅行贊助。</p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-ab1d2877fb7465713e1026dde056406759a.png" referrerpolicy="no-referrer"></p><p>團隊稱《GNOME Project Handbook》目前雖然處於早期階段，但已包含大部分核心內容。後續該文檔會替代 wiki，因此他們建議貢獻者從現在開始查閲手冊而不是 wiki。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 02:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277015/gnome-project-handbook</guid>
            <link>https://www.oschina.net/news/277015/gnome-project-handbook</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[deepin Meetup 回顧丨 deepin V23 Beta3 新特性＆如何參與社區貢獻]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>​</span>內容來源：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdeepin-meetup-2024-beijing%2F" target="_blank">deepin（深度）社區</a></p><hr><p>1 月 27 日，deepin Meetup 北京站圓滿落幕！作為 2024 年首場線下沙龍，deepin Meetup 吸引了來自北京及周邊地區 40 餘名用戶的積極參與，各位 deepiner 線下面基，昔日網友揭開神祕面紗，共同探討最新產品進展、分享使用心得、實操經驗，大家也對 deepin 未來發展提出了諸多寶貴意見，現場氛圍熱烈。</p><p>未能親臨現場的小夥伴們，不妨通過鏡頭感受一下現場的火熱氛圍吧！</p><p style="text-align:center"><img alt="" height="577" src="https://storage.deepin.org/thread/202401300902294511_807A0015.jpg" width="866" referrerpolicy="no-referrer"></p><div><div><h1><strong>主題分享</strong></h1><p>首先，deepin（深度）社區運營負責人張可帶大家回顧了 deepin 社區的發展歷史，展示了社區部分明星產品及技術成果。過去一年是 deepin（深度）社區高速發展的一年，而這些成績的背後，離不開社區所有用戶的支持，張可也為大家詳細講解了社區用戶應如何為開源項目和社區做貢獻，讓各位 deepiner 對如何參與 deepin 社區貢獻有了更深入的瞭解。</p><p style="text-align:center"><img alt="" height="645" src="https://storage.deepin.org/thread/202401300904361053_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240130135117.jpg" width="861" referrerpolicy="no-referrer"></p></div></div><div><div><p>隨後，deepin（深度）社區產品經理梅毅翔帶來了《deepin V23 Beta3 - X11 環境下新增功能》主題分享，為大家提前揭祕了 deepin V23 Beta3 的部分新增功能，如啓動器重構、UOS AI 預裝、新增低電閾值設置功能、支持了 steam 原生應用的安裝等。</p><p>值得一提的是，備受期待的<strong>deepin V23 Beta3 鏡像將在本週正式發佈</strong>，歡迎大家體驗並提供反饋。</p></div></div><p style="text-align:center"><img alt="" height="641" src="https://storage.deepin.org/thread/202401300920179867_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240130134935.jpg" width="856" referrerpolicy="no-referrer"></p><div><div><h1><strong>交流互動</strong></h1><p>在活動現場，多位用戶分享了自己與 deepin 及開源的故事，以及一些實操經驗。</p><p>過去一年，AI 應用場景也不斷擴展，用戶&nbsp;<strong>@王鑫</strong>&nbsp;分享了他作為人像攝影師轉型為 AIGC 從業者的經歷，併為大家介紹了了兩款主流 AI 繪畫工具 Midjourney、Stable Diffusion 的優、劣勢，以及它們在攝影中的實際應用。</p><p style="text-align:center"><img alt="" height="620" src="https://storage.deepin.org/thread/202401300941388408_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240130134847.jpg" width="827" referrerpolicy="no-referrer"></p><p>用戶<strong>&nbsp;@GNUman&nbsp;</strong>則為大家分享了他在自由軟件與開源方面的所思所想，並與大家探討應如何支持自由軟件運動。</p><p style="text-align:center"><img alt="" height="629" src="https://storage.deepin.org/thread/202401300942187008_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240130134851.jpg" width="838" referrerpolicy="no-referrer"></p><p>參與開源是用戶發揮自己技能和為社區做貢獻的良好途徑，而如何參與一直備受大家關注，開源愛好者&nbsp;<strong>@凱寶</strong>&nbsp;藉此機會，結合自己從小白用戶進階成為「開源大使」的經歷，為大家分享了他一路以來的認知與收穫。</p><p style="text-align:center"><img alt="" height="628" src="https://storage.deepin.org/thread/202401300943095528_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240130134832.jpg" width="837" referrerpolicy="no-referrer"></p><p>資深社區用戶&nbsp;<strong>@拉德利&nbsp;</strong>及&nbsp;<strong>@安樹收園</strong>&nbsp;也與大家分享了自己和 deepin 的故事，講述了他們在使用 deepin 過程中所遇到的趣事、挑戰和成長。</p><p style="text-align:center"><img alt="" height="464" src="https://storage.deepin.org/thread/202401300945586774_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240130154416.jpg" width="825" referrerpolicy="no-referrer"></p></div></div><p style="text-align:center"><img alt="" height="625" src="https://storage.deepin.org/thread/202401300945253653_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240130134827.jpg" width="834" referrerpolicy="no-referrer"></p><div><div><h1><strong>下一站，成都</strong></h1><p>本次 deepin Meetup · 北京站活動圓滿結束，感謝大家在北京的嚴寒中不辭遠路趕來參加活動，有的同學甚至是從外地專程趕來，也感謝所有參與分享和討論的同學們。</p><p>那麼，讓我們準備下一次的沙龍吧！我們計劃在春節後於<strong>成都</strong>舉辦，大家覺得呢？</p><p>如果你對做分享感興趣，或是有更多的建議給到我們，可以掃描下方二維碼，申報議題或提交建議。無論是標準的主題演講 ，還是 5 分鐘簡短的閃電演講，都期待你的報名～ 期待與大家下次相見！</p><p style="text-align:center"><img alt="" height="261" src="https://storage.deepin.org/thread/202401300947008284_1027%E5%8C%97%E4%BA%AC%E6%8A%A5%E5%90%8D.jpg" width="261" referrerpolicy="no-referrer"></p></div></div><p>瞭解 deepin：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Findex%2Fzh" target="_blank">deepin - 基於 Linux 的開源國產操作系統</a></p><p>瞭解 deepin Meetup：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdeepin-meetup%2F" target="_blank">deepin Meetup – 深度科技社區</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 31 Jan 2024 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277008</guid>
            <link>https://www.oschina.net/news/277008</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[爆了！Sealos 三天支持 1000 個帕魯私服]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhzh.sealos.run%2F%3Fopenapp%3Dsystem-template%253FtemplateName%253Dpalworld%2526uid%3Dkc811077" target="_blank">Sealos 的帕魯私服模板</a>從第一天發佈之後就起了 100 多個私服，第二天直接上到 500 多個，第三天直接上千，還在加速增長中。來講講我們只用一個晚上怎麼做到上線一個專屬可用區的，還有一些帕魯實踐讓我對雲有的一些新的思考。</p><p><img src="https://oscimg.oschina.net/oscnet/up-490ea01e164188b5dfed8d0ca052a6ac442.jpg" alt="" referrerpolicy="no-referrer"></p><h2>Sealos 憑啥殺出一條血路</h2><p>這次各大雲廠商都出了私服教程。</p><p>原因很簡單，別的廠商都只是虛擬機上搭建的教程，有的甚至是長長的一篇文檔，不過後來都搞一件部署了。</p><p>而 Sealos 直接做成了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsealos.run%2Fdocs%2Fguides%2Ftemplates%2F" target="_blank">應用模版</a>，<strong>點點鼠標，有手就會，對此菜市場大媽表示體驗很好，邊買菜都可以邊部署起來</strong>。論速度我們吊打一切，只需要 30 秒起服，而其他我大部分測試了都要三分鐘，原因很簡單：<strong>我們拋棄了虛擬機</strong>。</p><p><strong>玩遊戲的很多人並非開發者，或者沒那麼懂技術的，虛擬機，控制枱這些概念都不能讓他們知道，就更別勸玩家去用了</strong>。Sealos 就是一個鏈接：</p><ul><li><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhzh.sealos.run%2F%3Fopenapp%3Dsystem-template%253FtemplateName%253Dpalworld%2526uid%3Dkc811077" target="_blank">https://hzh.sealos.run/?openapp=system-template%3FtemplateName%3Dpalworld%26uid=kc811077</a></strong></li></ul><p>看，有手就能部署，腦子都不用帶。</p><p>我們的視頻教程在 B 站獲得了非常高的熱度：</p><p><img src="https://oscimg.oschina.net/oscnet/up-e1ff512810d70062569e7e07974a64a1010.jpg" alt="" referrerpolicy="no-referrer"></p><p>視頻傳送門：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1Tw41177n3" target="_blank">【幻獸帕魯】零門檻服務器搭建配置存檔教程免費體驗</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1Ab4y1P7Es" target="_blank">【幻獸帕魯】最小白的服務器搭建教程 32 人低延遲免費體驗</a></li></ul><p><strong>Sealos 還可以先體驗後付錢，付費轉化率誇張的高！</strong></p><p>相比較包年包月，Sealos 採用完全按量計費的方式，玩家睡覺時就可以關了，收一點點磁盤的費用。容器還有個好處就是內存炸了很快就可以自動重啓，幾乎不影響用戶體驗，而虛擬機重啓下不得分鐘級。</p><p>還有就是調配置，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsealos.run%2Fdocs%2Fguides%2Fapplaunchpad%2Fautoscale" target="_blank">Sealos 隨便伸縮</a>，虛擬機包年包月伸縮就很尷尬。</p><p>最後是一些細節體驗，比如導入存檔，配置管理，死亡不掉落等等。</p><p>還有一個要點，就是運營的同學要去玩遊戲，為什麼？如果我們不玩我們就無法體會死亡不掉落的重要性，無法體會孵蛋時間是個啥，無法理解用戶在什麼時間點會上頭，這直接決定需要贈送多少額度，需要提供什麼樣的配置，需要新增什麼樣的痛點特性。</p><h2>事情經過</h2><p>有兩個朋友給我發了這個遊戲的文章，瞬間我就找到了我們 「奇技淫巧獎」 獲得者的米開朗基楊同學，當天就把模版做出來了，上架到了我們的兩個集羣。隨後文章一發，瞬間集羣資源就滿了。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e8607737eb52990918b33443b1aae7332a4.jpg" alt="" referrerpolicy="no-referrer"></p><p>週四晚上我們立馬決定建設一個新的專屬可用區，這個可用區選擇在阿里雲上，原因很簡單：需要快速擴容，而且以後可能熱度下降要考慮釋放問題。<strong>所以大家就不要隨便黑公有云了，這是成本最低的打法</strong>，下文細講。</p><p>我們一半人寫代碼，一半人買服務器起集羣，把 Sealos 中玩家不需要的東西通通裁剪掉，應用市場也就只放一個模版，用 Laf 花了五分鐘寫一個遊戲配置管理的程序並上線到 Sealos 上做默認應用。剩下的時間就在不斷優化遊戲的模版，包括緩存遊戲的鏡像讓啓動速度達到極致。</p><p>晚上就火爆了，不是在加服務器就是在加服務器的路上，我們每個節點可以跑 70 個私服。<strong>第二天團建，全員揹着電腦，幾乎一半人在燒烤一半人在支撐。</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-a3be78a611bf5d875e6a6ac46c8b5a66546.jpg" alt="" referrerpolicy="no-referrer"></p><p>到目前為止單集羣已經啓動上千個。</p><h2>帕魯事件對雲的思考</h2><p>這個事只是一個影子，他映射出未來的雲應該是什麼樣子。</p><h3>第一：應用是一等公民，忘掉雲原生，忘掉容器，更要忘掉虛擬機</h3><p>你看安卓/iOS/Windows/macOS 以及各種 Linux 發行版，大部分用戶用的是具體的應用，每個應用都有不同的用戶畫像，而很少有用戶關心繫統本身，更不會去關心內核。</p><p>把用戶的最終需求直接給到用戶才是雲發展的終極目標，像帕魯，<strong>用戶需要的肯定不是容器，也不是虛擬機</strong>，那讓用戶進入到一個虛擬機的操作控制枱顯然就違揹人性了。</p><p>當然會有很多開發者直接需要的就是虛擬機，那提供一個虛擬的應用也可以，核心邏輯解耦合，儘量不要讓用戶關心他需求以外的東西。隨着應用的豐富，大眾市場對更底層的需求就會越來越少，比如有了 RDS 之後，很多人要用數據庫的人就不想去折騰虛擬機了，這裏務必理解用戶最終想要的是什麼，直接給。</p><p>所以這必然會衍生出一種更合理的架構，其實這個架構已經有答案了，單機操作系統就是答案，有很好的標準，一堆人開發應用，另外一堆人使用應用，雲為什麼不這樣？</p><p>今天的公有云很多都被框死在了控制枱，這樣應用很難有自己的發揮空間，比如帕魯的用戶去登錄公有云一通操作，VPC 快照對象存儲幾個標籤就能把他看暈乎，這不是一種極致的產品體驗。而手機上 LOL 遊戲就不會外面套個微信的聊天框，不同的應用需要有自己不同的風格。markteplace 就更不用説了，缺乏標準，一鍋大雜燴而已。</p><h3>第二：雲是連接應用的生產者與使用者</h3><p>一旦雲足夠成熟的時候就會有非常好的靈活性，可以讓大量開發者開發雲上應用，使用者來使用，而今天雲廠商大部分是廠商自己開發雲產品，雖然也有第三方上架什麼的，但是味道不對，怎麼樣算對，參考手機生態。</p><p>Docker Hub 就有點這個味道了，什麼味道？標準的形成，很好的鏈接了鏡像的製作者和使用者，但是提供的是零件，不是完整的分佈式應用。</p><p>K8s 生態提供了很好的標準，是個非常優秀的雲內核，一旦發行版盛行，此生態大成！那個時候很多人會忘掉 K8s，我可以給一個非常讓人吃驚的數字，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsealos.run" target="_blank">Sealos</a> 雲上的用戶 80% 沒接觸過容器，20% 完全不是專業的開發者，他們就只想直接起應用。</p><p>所以先進的雲需要給應用非常高的自由度，需要讓用戶用它的時候完全沉浸在應用本身的使用中，Sealos 就是這樣，打開一個應用之後你就看不到 Sealos 的任何東西了，<strong>而目前雲廠商都有個大大的 Header 和側邊欄</strong>，所以就出現了這種怪物：</p><p><img src="https://oscimg.oschina.net/oscnet/up-dff4b1c0b72679e2c0f1003dacad4c7f038.png" alt="" referrerpolicy="no-referrer"></p><p>我想寫代碼，可是嵌套一層又一層。</p><p>雲 IDE 應當是一個獨立的應用，可能是第三方提供，然後別人來使用。即便是官方自研也應當是這樣的架構。</p><h3>第三：雲是連接資源的提供者與消費者</h3><p>現在的雲廠商基本硬件資源都是自己提供，而 Sealos 的做法比較有意思，未來我們的很多 Region 算力本身也可以由第三方提供，接入到我們平台中，真正成為一個算力平台，從算力視角連接雙方。有點像直營和加盟的意思，或者京東和淘寶。若無雲操作系統，這種想法也無法落地，而我們 24 年就會提供。</p><h3>第五：Sealos 公有云服務堅定選擇雲廠商，拋棄自託管硬件方向</h3><p>自建還是選擇公有云確實要看場景，Sealos 雲服務的業務未來只考慮用公有云。不要只看到價格的貴而忽略效率成本，還有很多其它隱性成本不可不查。</p><p>帕魯這個場景毫無疑問首選公有云，快速擴容這一個需求就決定了沒法在自己的機房跑。而且熱點過去了是要縮回來了。</p><p>即便不是帕魯這個場景，Sealos 還是堅定不移用公有云，我曾經一直在搖擺自建還是上雲，我們本身就是做雲的，絕對有託管硬件自建的能力，物理機的性能也更好，單純計算算力價格也低太多。</p><p>但是，最終發現需要花好多倍成本就解決那剩下 10% 的問題，比如高可用要備份，你的備份程序和磁盤都需要額外成本，對應人力成本也來了，最要命的是響應速度，換塊盤也需要時間，需要溝通成本等等。這些公有云上一個快照就都可以解決。</p><p>還有個噁心的備案問題，幾乎只能人肉遷移備案，開白名單這些。而且機房的帶寬費用並不便宜。</p><p>買多少硬件資源也是一個很費事的問題，預留不夠上架可就慢了。</p><p>綜合下來如果你把雲的彈性用好，是可以節省大量成本的。特別有狀態和無狀態分開運行，夜間釋放，根據不同的 SLA 等級劃分可用區，舉個例子，我們可以針對開發測試場景專門做一個對接競價實例的集羣，把所有無狀態全部用競價去跑。</p><p>使用公有云還可以讓我們自己保持輕資產運營，天下武功唯快不破，迭代速度是創業公司最為追求的。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 11:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4148359/blog/10992796</guid>
            <link>https://my.oschina.net/u/4148359/blog/10992796</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeFuse 新開源模型榮登 Big Code 評測榜首！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="jahb.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1706606628857-bd1dbf7f-50d0-4b4e-a704-2f26ae5a3814.png?x-oss-process=image%2Fresize%2Cw_900%2Climit_0" width="900" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong><span>使用多任務高效微調框架 MFTCoder，以 DeepSeek-Coder-33b 模型為底座，微調獲得的 CodeFuse-DeepSeek-33b 模型在</span></strong><strong><span style="color:#1f2937">Big<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Code</span></strong><strong><span style="color:#1f2937"><span>&nbsp;</span>Models<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Leaderboard</span></strong><strong><span>代碼大模型榜單上以 43.58% WinRate 成為新晉榜首，同時模型在 NLP 任務上也取得了很好的表現。本文我們將介紹該模型的得來和使用，包括訓練數據、訓練超參設置、模型評測效果以及如何獲取該模型和基於它繼續微調。我們已經在 HuggingFace 和 ModelScope 開放了模型下載（下載地址在文末），並同步提供了 4bit 量化版本供大家直接部署到生產環境。</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1706581702847-565b14ab-7236-4bab-b74f-b8ce640e2eb9.png" width="1734" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>圖 1: Big Code Models LeaderBoard 榜單截圖（截取時間 2024-01-30）。</span></strong><strong><span style="color:#1f2937">Big<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Code</span></strong><strong><span style="color:#1f2937"><span>&nbsp;</span>Models<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Leaderboard</span></strong><strong><span>（</span></strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fbigcode%2Fbigcode-models-leaderboard" target="_blank"><strong><span>https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard</span></strong></a><strong><span>）是由 HuggingFace BigCode 團隊維護的代碼大模型榜單，是代碼大模型領域比較權威的評測榜單。</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_1"></span><h1><span>多任務微調 MFT</span></h1><p style="margin-left:0; margin-right:0"><span>我們選擇以 DeepSeek-Coder-33b 模型為底座，使用多任務微調框架 MFTCoder 對 5 個下游任務數據進行微調，得到 CodeFuse-DeepSeek-33b 模型。以下將更為詳細地進行介紹。</span></p><span id="OSC_h2_2"></span><h2><span>訓練數據</span></h2><p style="margin-left:0; margin-right:0"><span>本次訓練我們設置了 5 個下游任務，如下表 1 所示，包括代碼補全任務、文本生成代碼任務、單測生成任務、自然語言表述對齊任務和代碼練習題任務，共約 168 萬樣本數據。得益於我們開源的多任務微調框架 MFTCoder，這些下游任務能一定程度上相互促進，比直接將所有任務數據混合為一後微調錶現更優。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 1: 下游任務訓練數據統計</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:700px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span><strong><span>序號</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span><strong><span>MFT 下游任務</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>任務能力</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span><strong><span>#Samples<span>&nbsp;</span></span></strong></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>1</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>單測用例生成</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>給定函數級代碼生成單元測試用例</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>390,393</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>2</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>代碼補全</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>根據前文補全代碼（方法級）</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>192,547</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>3</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>文本生成代碼</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>基於文本描述生成功能代碼</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>66,862</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>4</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>NLP 表述對齊</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>增強 NLP 理解能力</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>951,278</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>5</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>代碼練習題 (JAVA/CPP/GO)</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>基於文本描述生成基礎功能代碼</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>82,603</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px">&nbsp;</td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>#Total</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">1,683,683</span></span></p></td></tr></tbody></table><span id="OSC_h2_3"></span><h2><span>關鍵超參設置</span></h2><p style="margin-left:0; margin-right:0"><span>本次微調使用的是我們已經開源的多任務微調框架 MFTCoder</span><strong><span>(</span></strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fmain%2Fmftcoder_accelerate" target="_blank"><strong><span>https://github.com/codefuse-ai/MFTCoder/tree/main/mftcoder_accelerate</span></strong></a><strong><span>)</span></strong><span>，MFTCoder 支持多模型適配（包括 Llama 1/2、CodeLlama、Qwen、Baichuan 2、ChatGLM 2/3、CodeGeex 2、GPT-NEOX、Mistral、DeepSeek 等）、多任務並行、多種均衡 Loss 設計、PEFT（Lora 和 QLora）高效微調，此前已被採納為 Qwen Code AI 競賽初賽推薦微調框架（</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftianchi.aliyun.com%2Fcompetition%2Fentrance%2F532169%2Finformation" target="_blank"><span>https://tianchi.aliyun.com/competition/entrance/532169/information</span></a><span>）。本次訓練使用的關鍵超參設置如下表 2 所示，更多詳細的參數説明可參考</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fmain%2Fmft_peft_hf%2332-loraqlora" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder/tree/main/mft_peft_hf#32-loraqlora</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 2： MFTCoder 微調關鍵超參設置及解釋</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:734px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>參數名稱</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>參數值</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>簡要解釋</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>data_split</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>"98,2,0"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>98% 數據用於訓練，2% 用於驗證</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>padding_mode</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>"padding"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>使用動態填充模式，即每張卡每個 batch 大小是由每次其中的最長者動態決定而不是固定大小。另一種可選數據模式是"pack"。</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:48px"><p style="margin-left:0; margin-right:0"><span>dynamic_padding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:48px"><p style="margin-left:0; margin-right:0"><span>True</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>weighted_loss_mode</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>"case3"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>使用數據均衡 Loss 函數，更多細節可見論文</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2311.02303" target="_blank"><span>https://arxiv.org/abs/2311.02303</span></a></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>peft_type</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>"qlora"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>採取 QLora 4bit 量化微調模式</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>quantization</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>"4bit"</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>lora_rank</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>192</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>決定可訓練參數比例</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>lora_alpha</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>32</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>per_device_train_batch_size</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>4</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>訓練時單卡 batch 大小</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>per_device_eval_batch_size</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>4</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>驗證時單卡 batch 大小</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>learning_rate</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>5e-5</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>初始學習率</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>min_lr</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>1e-6</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>最小學習率</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>gradient_accumulation_steps</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>1</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>梯度累積步數，如果為 2，則每累積 2 步再更新參數，資源不足是一種間接增加 global batch size 的方式</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>world_size</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>64</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>GPU 卡數，使用 64 張 A100/A100 卡</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>evalation_steps</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>500</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>每 500 步驗證一次</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>checkpointing_steps</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>500</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>每 500 步保存一次檢查點</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>num_train_epochs</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>10</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>最大訓練輪數，最大 10 輪</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>early_stopping</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>True</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>開啓 early-stopping 機制，即當連續 3 個檢查點的 eval loss 均比倒數第 4 個檢查點的 eval loss 大時終止訓練</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>early_stopping_stall_num</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>3</span></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>使用前述訓練數據和配置，經過 156.5 小時，模型在完成 5.09 Epochs 訓練後觸發 Early-Stopping 策略後終止。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_4"></span><h1><span>模型效果</span></h1><p style="margin-left:0; margin-right:0"><span>我們從代碼能力和 NLP 能力兩個方面對訓練獲得的 CodeFuse-DeepSeek-33b 進行了測試，pass@1 測試均採用 greedy 解碼模式（即</span><span style="background-color:#d8dad9">doSample=False, num_beams=1, num_return_sequences=1</span><span>）。</span></p><span id="OSC_h2_5"></span><h2><span>代碼能力</span></h2><p style="margin-left:0; margin-right:0"><span>我們選取了常用的代碼評測集對模型進行評測，首先我們使用自己的 CodeFuse-Evaluation 評測框架（</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-evaluation" target="_blank"><span>https://github.com/codefuse-ai/codefuse-evaluation</span></a><span>）對模型在 HumanEval-X（含 HumanEval）和 MBPP 測試集上的表現進行了測試並與 CodeFus 此前微調過的模型進行了比較，如下表 3 和表 4 所示。</span></p><p style="margin-left:0; margin-right:0"><strong><span>CodeFuse-DeepSeek-33b 在 HumanEval 上 pass@1 指標值為 78.65%、在 MBPP 上為 71%（zero-shot），兩項平均為 74.83%，略高於 DeepSeek-Coder-Instruct-33B</span></strong><span>。</span></p><p style="margin-left:0; margin-right:0"><strong><span>CodeFuse-DeepSeek-33b 在多語言評測集 HumanEval-X 上 pass@1 指標值平均為 67.07%，比此前我們開放的 CodeFuse-CodeLlama-34b 模型高 6.69%，在具體各種語言上高出 3.48%~12.19% 不等</span></strong><span>。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 3: CodeFuse-DeepSeek-33b 模型與其他開源底座模型及微調模型在 HumanEval 和 MBPP 上的對比</span></strong></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1704200172671-e3b1411a-19eb-4305-878d-99f7f95945e5.png" width="636" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 4: CodeFuse-DeepSeek-33b 模型與其他開源底座模型及 MFT 微調模型在 HumanEval-X 上的對比</span></strong></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1704200193212-a4061f95-d847-46d6-853b-2f0848c16050.png" width="719" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>由於不同評測框架在代碼後處理和生成終止條件（Stop Words）等方面常存在差異，除了用我們自己的 CodeFuse-Evaluation 評測框架，我們也用代碼大模型榜單 Big Code Models LeaderBoard 所用的開源評測框架 bigcode-evaluation-harness (</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbigcode-project%2Fbigcode-evaluation-harness" target="_blank"><span>https://github.com/bigcode-project/bigcode-evaluation-harness</span></a><span>) 進行了評測，並與榜單上的模型進行了比較。榜單會測試模型在 Python 代碼補全測試集 HumenEval 和多語言代碼補全測試集 MultiPL-E 共 12 種語言上的表現，並根據各語言表現進行 WinRate 排序。（結果復現代碼地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftwelveand0%2Fbigcode-evaluation-harness" target="_blank"><span>https://github.com/twelveand0/bigcode-evaluation-harness</span></a><span>）</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 5： 採用 bigcode-evaluation-harness 評測 CodeFuse-DeepSeek-33b 模型後的新榜單</span></strong><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1706582301694-43665f48-da68-422d-ad5a-86454c8f627f.png" width="1400" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>如表 5 所示，</span><strong><span>CodeFuse-DeepSeek-33b 模型的 WinRate 為 43.58%，超過原榜首 DeepSeek-Coder-33b-instruct。在 HumanEval 評測集上，CodeFuse-DeepSeek-33b 表現不如 DeepSeek-Coder-33b-instruct，但在其他 8 種語言（包括 Java 和 JS 等）上超過後者，均值（Average Score）亦超過後者 1.7%</span></strong><span>。</span></p><span id="OSC_h2_6"></span><h2><span>NLP 通用能力</span></h2><p style="margin-left:0; margin-right:0"><span>對於 NLP 通用能力測試，我們參照 OpenCompass 選擇了 18 個評測集，包括語言能力（AFQMC、CHID、Wic、WSC）、推理能力（COPA、CMNLI、OCNLI、Ax-b、Ax-g、RTE）、理解能力（CSL、C3、EPRSTMT）、學科綜合能力（MMLU、C-Eval、ARC-c）、代碼能力（HumanEval、MBPP）。對於每個模型，我們會使用生成式和 PPL 方式計算每個指標，並在每個維度上選取兩種方式中較高的值作為指標值。</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1704260089384-cb664a24-5d58-4a7d-9081-a61159a469e3.png" width="1230" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>圖 2: CodeFuse-DeepSeek-33b NLP 通用能力雷達圖</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b 模型的評測結果如圖 3 雷達圖所示，我們將其與底座模型 DeepSeek-Coder-33b 和 DeepSeek 通用模型 DeepSeek-67b-Chat 進行了對比。</span><strong><span>從圖中可以看出，相較於底座模型 DeepSeek-Coder-33b，CodeFuse-DeepSeek-33b 在所有維度上均有正向提升；相較於我們此前開源的 CodeFuse-CodeLlama-34b，CodeFuse-DeepSeek-33b 在絕大多數維度上表現更優；相較於通用模型 DeepSeek-67b-Chat，CodeFuse-DeepSeek-33b 在語言能力、代碼能力和理解能力上整體表現更優，在推理能力上表現稍差，在學科綜合能力上差距較大。考慮到模型參數規模差距和底座目標功能類型差異，我們認為 CodeFuse-DeepSeek-33b 已經表現很好。</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_7"></span><h1><span>模型 INT4 量化</span></h1><p style="margin-left:0; margin-right:0"><span>為了便於直接部署投入生產，我們同步提供了 CodeFuse-DeepSeek-33b-INT4 量化版本。對於量化後的模型，我們測試了它的代碼能力，如表 5 所示，量化後模型在代碼補全任務上只有微弱降幅。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 5：模型量化前後在 HumanEval-X 和 MBPP 上的指標對比</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:749px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Model</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>HumanEval-X</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>MBPP</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Python</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Java</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>C++</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>JS</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Go</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>78.65%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>67.68%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>65.85%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>67.07%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>56.10%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>71.0%</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b-INT4</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>78.05%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>68.29%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>62.19%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>64.63%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>55.49%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px">&nbsp;</td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>此外，我們測試了該模型實際部署後的性能。測試環境為單張 A10（24G 顯存）、部署框架為 NVIDIA 開源的 tensorRT。測試結果具體如表 6 所示：</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 6: CodeFuse-DeepSeek-33b-INT4 在單張 A10 的推理性能</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:640px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>模型版本</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>CodeFuse-DeepSeek-33b</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>推理速度指標</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>Tokens/s</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>模型並行/gpu 型號</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center">&nbsp;</p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>單卡 A10</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>量化格式</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center">&nbsp;</p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>int4 &nbsp;</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>輸入/輸出長度</span><br><span>(batch_size=1)</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>16/8</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>21.7</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:40px"><p style="margin-left:0; margin-right:0; text-align:center"><span>64/32</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:40px"><p style="margin-left:0; margin-right:0; text-align:center"><span>21.5</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:38px"><p style="margin-left:0; margin-right:0; text-align:center"><span>256/128</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:38px"><p style="margin-left:0; margin-right:0; text-align:center"><span>21.1</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:36px"><p style="margin-left:0; margin-right:0; text-align:center"><span>1024/512</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:36px"><p style="margin-left:0; margin-right:0; text-align:center"><span>20.5</span></p></td></tr></tbody></table><span id="OSC_h1_8"></span><h1>&nbsp;</h1><span id="OSC_h1_9"></span><h1><span>模型下載試用</span></h1><p style="margin-left:0; margin-right:0"><span>我們開放了量化前後 2 個模型的下載，提供了推理格式和推理示例，並説明瞭如何在此基礎上繼續微調。</span></p><span id="OSC_h2_10"></span><h2><span>下載</span></h2><p style="margin-left:0; margin-right:0"><span>我們已經將 2 個模型（CodeFuse-DeepSeek-33b 和 CodeFuse-DeepSeek-33b-INT4）發佈到 HuggingFace 和 ModelScope 社區，大家可以選擇通過以下鏈接下載：</span></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:726px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Model</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>HuggingFace</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>ModelScope</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B" target="_blank"><span>https://huggingface.co/codefuse-ai/CodeFuse-DeepSeek-33B</span></a></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B%2Fsummary" target="_blank"><span>https://modelscope.cn/models/codefuse-ai/CodeFuse-DeepSeek-33B/summary</span></a></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b-4bits</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B-4bits" target="_blank"><span>https://huggingface.co/codefuse-ai/CodeFuse-DeepSeek-33B-4bits</span></a></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B-4bits%2Fsummary" target="_blank"><span>https://modelscope.cn/models/codefuse-ai/CodeFuse-DeepSeek-33B-4bits/summary</span></a></p></td></tr></tbody></table><span id="OSC_h2_11"></span><h2><span>推理格式與代碼</span></h2><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b 使用的推理格式如下：</span></p><pre><code>&lt;s&gt;system
{THIS IS YOUR SYSTEM PROMPT}
&lt;s&gt;human
{THIS IS YOUR PROMPT of ROUND 1}
&lt;s&gt;bot
{THIS IS MODEL's RESPONSE of ROUND 1}
&lt;s&gt;human
{THIS IS YOUR PROMPT of ROUND 2}
&lt;s&gt;bot</code></pre><p style="margin-left:0; margin-right:0"><span>在這個格式中，sysem 部分是可選的，對話輪數可以是多輪的也可以是單輪的。下面是一些具體的案例展示：</span></p><pre><code>&lt;s&gt;human
請寫一個快排程序
#Python
&lt;s&gt;bot
</code></pre><pre><code>&lt;s&gt;system
你是 CodeFuse，你會被給定一個任務，你必須按照用戶的要求完成任務。
&lt;s&gt;human
請寫一個快排程序
#Python
&lt;s&gt;bot
下面是一個使用 Python 編寫的快速排序算法的示例代碼：
```python
def quick_sort(arr):
    if len(arr) &lt;= 1:
        return arr
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x &lt; pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x &gt; pivot]
    return quick_sort(left) + middle + quick_sort(right)
# 測試快速排序算法
arr = [3, 6, 8, 10, 1, 2, 1]
print(quick_sort(arr))
```
這段代碼定義了一個`quick_sort`函數，它接受一個列表作為參數，並返回排序後的列表。在函數內部，首先判斷列表的長度是否小於等於 1，如果是，則直接返回列表本身。否則，選擇列表中間的元素作為基準值，並將列表分成三個部分：小於基準值的部分、等於基準值的部分和大於基準值的部分。然後，對這三個部分分別遞歸調用`quick_sort`函數進行排序，最後將排序後的三個部分合並並返回。
通過這個示例，你可以瞭解到如何使用 Python 編寫快速排序算法，並對其進行測試。
&lt;s&gt;human
請為以上代碼生成單測用例
&lt;s&gt;bot
</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>下面是一段示例的推理代碼：</span></p><pre><code>import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig

model_dir = "codefuse-ai/CodeFuse-DeepSeek-33B"

def load_model_tokenizer(model_path):
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    tokenizer.eos_token = "&lt;｜end▁of▁sentence｜&gt;"
    tokenizer.pad_token = "&lt;｜end▁of▁sentence｜&gt;"
    tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)
    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)
    tokenizer.padding_side = "left"
    
    model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto',torch_dtype=torch.bfloat16, trust_remote_code=True)
    return model, tokenizer


HUMAN_ROLE_START_TAG = "&lt;s&gt;human\n"
BOT_ROLE_START_TAG = "&lt;s&gt;bot\n"

text_list = [f'{HUMAN_ROLE_START_TAG}Write a QuickSort program\n#Python\n{BOT_ROLE_START_TAG}']

model, tokenizer = load_model_tokenizer(model_dir)
inputs = tokenizer(text_list, return_tensors='pt', padding=True, add_special_tokens=False).to('cuda')
input_ids = inputs["input_ids"]
attention_mask = inputs["attention_mask"]
generation_config = GenerationConfig(
        eos_token_id=tokenizer.eos_token_id,
        pad_token_id=tokenizer.pad_token_id,
        temperature=0.1,
        max_new_tokens=512,
        num_return_sequences=1,
        num_beams=1,
        top_p=0.95,
        do_sample=False
)
outputs = model.generate(
        inputs= input_ids,
        attention_mask=attention_mask,
        **generation_config.to_dict()
)
gen_text = tokenizer.batch_decode(outputs[:, input_ids.shape[1]:], skip_special_tokens=True)
print(gen_text[0])</code></pre><span id="OSC_h2_12"></span><h2><span>繼續微調</span></h2><p style="margin-left:0; margin-right:0"><span>如果你想在這兩個模型基礎上繼續微調，歡迎使用我們開源的多任務高效微調框架 MFTCoder（</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fmain%2Fmftcoder_accelerate" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder/tree/main/mftcoder_accelerate</span></a><span>）。要繼續微調，你需要準備好訓練數據集（CodeFuse-ChatML 格式）、設置訓練配置文件、設置運行配置文件並啓動訓練。這裏提供一個對 Qwen-1.8 模型用 MFTCoder 進行微調的案例供參考：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fcodeqwen_competition%2Fmft_peft_hf" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder/tree/codeqwen_competition/mft_peft_hf</span></a><span>。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_13"></span><h1><span>聯繫我們</span></h1><p style="margin-left:0; margin-right:0"><span>MFTCoder 已經開源，本文中提到的模型和數據集也在陸續開源中，如果您喜歡我們的工作，歡迎試用、指正錯誤和貢獻代碼，可以的話請給我們的項目增加 Star 以支持我們。</span></p><ul><li><span>GitHub 項目主頁：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder</span></a></li><li><span>HuggingFace 主頁：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodefuse-ai" target="_blank"><span>https://huggingface.co/codefuse-ai</span></a></li><li><span>魔搭社區主頁：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Forganization%2Fcodefuse-ai" target="_blank"><span>https://modelscope.cn/organization/codefuse-ai</span></a></li></ul></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 11:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/10992906</guid>
            <link>https://my.oschina.net/u/6942768/blog/10992906</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 版權第一案：我用 AI 做的圖，版權歸我嗎？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近，一個跟 AI 相關的案子引起了全國同行的圍觀，原因是一個百家號作者在網上寫文章時，用了一張網上的 AI 圖片當配圖，結果被圖片的生產者告侵權。這不禁讓人緊張：以後 AI 產的圖片，還能隨便用嗎？會不會侵權？</p><p>事情是這樣的——</p><p style="text-align:left">2023 年 2 月，李昀鍇使用 Stable Diffusion 模型，通過在模型上輸入數十個提示詞，設置相關迭代步數、圖片高度、提示詞引導係數以及隨機數種子等，生成了數張人像圖片。隨後，李昀鍇以 「春風送來了溫柔」 為名發佈在社交平台小紅書上。2023 年 3 月 2 日，百家號一自媒體賬號發佈的名為《三月的愛情，在桃花裏》的文章使用了李昀鍇製作的圖片。</p><p style="text-align:center"><img height="768" src="https://oscimg.oschina.net/oscnet/up-f6cf6dc908fcf7b1c685805400c6c984609.png" width="512" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#999999"><em>李昀鍇用 Stable Diffusion 模型生成的圖片</em></span></p><p style="text-align:left">李昀鍇認為，對方未獲得他的許可就截掉了他在小紅書平台的署名水印進行發佈，侵犯了署名權及信息網絡傳播權，應當承擔法律責任。</p><p style="text-align:left">2023 年 5 月，李昀鍇起訴被告劉某侵害作品署名權、信息網絡傳播權糾紛一案在北京互聯網法院立案。</p><p><strong>這裏最關鍵的爭議在於，李昀鍇基於自己設定的提示詞和參數，使用 Stable Diffusion 模型製作的圖片 「春風送來了溫柔」 是否構成作品？以及構成哪一種類型的作品？</strong></p><p style="text-align:left"><strong>法院認為，原告李昀鍇使用</strong><strong>開源軟件</strong><strong> Stable Diffusion 創作的圖片由其獨立完成，體現了他的個性化表達，因此涉案圖片具備 「獨創性」 要件。涉案圖片符合作品的定義，屬於美術作品，受到著作權法的保護。最終判決李昀鍇勝訴，被告需在百家號平台公開道歉，並向原告賠償 500 元</strong>。</p><p style="text-align:left">這個案件，也成為了 AI 生成圖片相關領域著作權第一案，讓 AI 領域的從業者和使用者都提高了警惕：</p><p>原來 AI 創作的圖片也是有著作權的，那以後使用 AI 圖片還得注意授權問題了？</p><p>AI 圖片很多都是用別人的圖片「溶」出來的，相當於「二創」。這種做法放在文藝領域早被當成抄襲了，為啥它還能享有著作權呢？這是不是合理的？</p><p>我用 AI 創作的圖，總共有哪些權利和風險？權責如何劃分？</p><p>對此，我們邀請了知識產權領域的專業律師鄧超進行對談，一起聊聊究竟怎麼回事。</p><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>01 AI 作品，版權並不明晰</h1><p><span style="color:#245bdb">開源中國：首先我們捋清一下概念，版權和著作權是一回事嗎？</span></p><p>&nbsp;</p><p>鄧超：是的，著作權和版權沒有區別。根據相關法律規定，著作權是指作品的作者等相關人員，依法對其已經完成的作品所享有的發表權、署名權、複製權、保護作品完整性權等。<strong>且著作權即版權。</strong></p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：OK，那在現行法律當中，個人或單位使用 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 生產的圖片，擁有版權嗎？</span></p><p>&nbsp;</p><p>鄧超：<strong>在現行法律當中，這塊還沒有明確規定，行業意見也不統一，需要進行個案分析。</strong></p><p>前年北京互聯網法院有一個「菲林訴百度案」，當時法院認為，機器生成的內容是沒有版權的。</p><p style="text-align:center"><img height="625" src="https://oscimg.oschina.net/oscnet/up-d4964bffd09758af1e3dbb525b78e0b065e.png" width="1421" referrerpolicy="no-referrer"></p><p>但是在深圳的「騰訊新聞案」，法院則認為，機器生成的內容有版權。</p><p style="text-align:center"><img height="687" src="https://oscimg.oschina.net/oscnet/up-9672009ee8539049d0417268a64ca6f9a30.png" width="1437" referrerpolicy="no-referrer"></p><p>一南一北，對這個問題給出了不同的答案，但是這些案子都沒有上訴，所以説現在還沒有一個統一的意見。今天這個案子裏，北京互聯網法院就認為，AI 生成的圖片是有版權的。但是，北京互聯網法院它是個基層法院，判決的效力有限，不好説能不能全國推廣。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：那 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 生成的圖片所擁有的權利很模糊啊？</span></p><p>&nbsp;</p><p>鄧超：也不能説很模糊，它有一個判斷的過程。判決也強調了，<strong>利用人工智能生成的內容是否構成作品，需要視個案情況而定，不能一概而論。</strong>在這個案子裏，這張圖片的生成涉及了上百個提示詞和參數的調整，在這種情況下，法院會認可這個創作者是付出了一定的創造性勞動的。相反，假設只是跟 AI 説「畫一幅秋天的風景畫」，那這個在我看來就不能有版權了，因為沒付出什麼符合著作權法要求的創作。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：可是，這些為創作而輸出的參數和設定，多少算多，又多少算少呢？</span></p><p>&nbsp;</p><p>鄧超：是的，這裏恰恰就是判斷的難點，可能在每個案子裏，每個法官的判斷都會不一樣。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：有律師認為，</span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 作圖跟傳統的美術創作有很大的區別，原告只輸出了提示詞，並沒有動筆去畫具體的線條，也沒有百分之百地告知 Stable Diffusion 模型怎樣去畫出具體的線條和色彩，就通過人工智能生成了圖片。</span><span style="color:#245bdb"><strong>根據《著作權法》的傳統理論，人創作的作品才受版權保護，原告李昀鍇的行為並不構成創作。</strong></span><span style="color:#245bdb">你怎麼看？</span></p><p>&nbsp;</p><p>鄧超：是的，這種反對的觀點還挺普遍。做個類比，我讓一位畫家畫一幅秋天的風景畫，但我不能在畫家畫完了之後説「我是這幅畫的作者」。這是不合理的。</p><p>還有一種反對觀點，它的邏輯是：即使我説了「畫一幅秋天的風景畫」這句話，不同的人他會畫出不一樣的東西，不能因為我説了這句指令，我就擁有了畫的著作權，這是很奇怪的。像秋天的風景這種東西，本來就是一千個人一千種畫法，即使是 AI ，不同的 AI 畫出來的也不一樣。甚至相同的 AI ，你讓它再畫一遍，都不一定畫得出來。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：即使是相同的參數，它也不一定會生成同樣的圖。</span></p><p>&nbsp;</p><p>鄧超：是的，沒錯。但是這個類比，只能放在人身上，放在 AI 身上就不太一樣，因為 AI 它是一個機器，不是具體的人，是沒有權利的。如果這幅圖是我讓一個人來畫的話，那著作權肯定就屬於畫畫的那個人了。但 AI 它不是人，它沒法成為作者。<strong>現階段，生成式人工智能模型不具備自由意志，無論是國內還是國外，都不支持 AI 成為法律上的主體。</strong></p><p>這也是法院在這個判決中做出的考量。目前來講，無論是認為 AI 作品應該有版權還是不應該有版權，其實都能解釋得通，因為 AI 這東西是新興的，法律比較落後，現在還沒有達成一致説這種情況應該怎麼辦？所以，法院現在判決的時候，更多是從產業或者立法目的的角度，去解釋説：這 AI 是把它保護起來比較好，還是不保護更好？</p><p>在這個案子裏面，原告為了生成這張圖片，輸入了大量的指令，調整了上百個參數，如此正向反向的一系列約束下來，才得到這張圖。這個過程，在法院看來，是有一定的獨創性的。咱們國家法律規定的獨創性很低。比如説攝影作品，攝影師等了一天安排了特定角度拍出來的圖，大家會認為有獨創性；但咱們普通人隨便拍的圖，一般來講也是有獨創性的，即使你沒調參數，也沒啥構思。所以説，<strong>獨創性，這東西的門檻就很低，不需要達到什麼專業高度就能擁有。</strong></p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：可是拍照這事兒是我們自己動手拍的，不是別人告訴我怎麼拍的。</span><span style="color:#245bdb"><strong>而且用 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 的話，即使描述得再具體，它也只是文字創作，不是美術創作，</strong></span><span style="color:#245bdb">它對於創作結果是不能預見也無法控制的，這與人們之前使用畫筆、繪圖軟件去作圖有很大的不同。</span><span style="color:#245bdb"><strong>它是「文生圖」，不是「手作圖」。</strong></span></p><p>&nbsp;</p><p>鄧超：所以説，這裏其實是一個價值取向的問題，給不給版權保護都説得通。</p><p>有一種反對觀點認為，比如説「畫一幅秋天的風景」這個指令，可以擁有文字性的版權，但這個文字性的版權，不能延伸到它生成的圖片，不然以後所有的秋天風景畫都侵犯了我的版權了，因為我最先説了這句指令。</p><p><strong>不過，從歷史的角度來看，各種形式的創作，要獲得版權保護都是一個時間問題。</strong>比如説攝影技術剛誕生的時候，大家覺得攝影也不應該給版權，因為攝影出現之前，大家都是用油畫，可能得花幾十年學習，才能把風景畫得很像。結果攝影技術出來之後，不需要任何繪畫功底、也不用學幾十年，只需按一下快門，就能得到一幅比你學了十幾年畫畫還要接近真實的畫，所以大家都認為它不是藝術，不應該給版權。可是後來你看，隨着技術的發展，攝影慢慢地也成為一門藝術了。</p><p>從歷史的視角來看，每當有新的事物出現，它總會面臨一些爭議，比方説要不要給版權？但是我們可以想辦法把版權保護做得更好，在保障權利的同時適應新事物的出現。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>02 新情況可以參照現有法律嗎？</h1><p><span style="color:#245bdb">開源中國：現在有一種想法是將 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 創作類比成互聯網產品。比方説程序員在後台輸入代碼，通過計算機生成了一個 APP，生成了它的各種功能。但是代碼不屬於美術作品，誰來寫都一樣，能實現就行，同一個功能背後的代碼可能是一模一樣的。在 AI 創作中，提示詞就相當於創作的「代碼」，生成的圖片就類似於前台的 APP，那這個提示詞是不是也是誰來寫都一樣呢？還應該有版權嗎？</span></p><p>&nbsp;</p><p>鄧超：在智力創作這一塊，法律要求的門檻很低，畢加索的畫有版權，小學生的畫也一樣有，並不以智力貢獻的高低來衡量，只要是你寫的就能有版權。</p><p>所以，代碼也是可以享有版權的，像軟件著作權登記，它登記的就是這個代碼。如果你寫了一個代碼，別人抄襲你的代碼，那也是構成著作權侵權的。只不過代碼的著作權僅限於這個文字代碼本身。</p><p>最開始，把代碼當成文學小説來保護，也是有爭議的。畢竟文字它沒有任何實用的功能，但是代碼，它唯一的目的就是實現功能。但是版權法不保護功能，要想保護功能可以用專利。所以最開始把代碼視為文學小説就有這麼一個不自洽的地方。那麼法律後來就規定了，<strong>實現某個功能的唯一或者非常有限的代碼，它是不能受版權保護的。</strong>比如説，單獨寫一個「彈出提示框」，僅僅這麼一點東西，是沒法被版權保護的。<strong>但要是整個程序，比如像微信，作為一個整體來講，它就受到版權保護。</strong></p><p>要是拿音樂來類比的話，單個音節，像 do、rei、mi、fa、so 本身是沒法保護的，但是你把它編成一首曲子，那這首曲子就能受到版權保護。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：意思就是它得作為整體的一個作品來呈現才能算。</span></p><p>&nbsp;</p><p>鄧超：對。但是要説得呈現到啥程度，這其實並沒有一個清晰的線。比方説一首歌算，那其中一段算不算呢？這就得到具體案件裏面，進行具體分析了。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：人工智能的軟件是可以大規模複製的，只要</span><span style="color:#245bdb">算力</span><span style="color:#245bdb">足夠，短時間生成海量的圖片完全沒有問題。如果這都可以獲得著作權保護，對整個社會而言，會不會起不到鼓勵創新的效果？</span></p><p>&nbsp;</p><p>鄧超：是這樣，現在從實踐來講，很多圖片沒法判斷是不是 AI 生成的，除了那些手畫不好的之外，其實很難分辨。在這種情況下，<strong>咱們默認所有圖片都是有版權的就行了，不要在意它是不是 AI 生產的，這跟 AI 沒關係。</strong>咱們在用圖的時候，就兩個原則：你獨創的，或者是合法購買許可的，那就用；如果不是，那就別隨便用。不能在網上看到一個圖片就隨手拿過來，這無論是不是 AI 生產的，風險都很大。</p><p>如果説我用 AI 大模型生成的圖，跟別人生成的一樣，比方説一樣的提示詞下 AI 給我們都出了一樣的圖，那也沒關係，因為這是你獨立創作的，就可以避免法律風險，哪怕對方來起訴也不怕。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：就是説</span><span style="color:#245bdb"><strong>我們用同一個 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 同一套提示詞生成的兩張圖，我們各自分別都有著作權，哪怕這兩張圖一模一樣？</strong></span></p><p>&nbsp;</p><p>鄧超：是的，因為咱們講的是獨創性，只要這是你獨立完成的，那就沒有問題。比如説，兩個人同時拍天安門廣場升旗的圖片，可能倆人的角度非常像，拍出來的圖片幾乎一樣，在這種情況下，各自都有著作權，沒有任何人侵權。但如果真到了法庭那個階段，你就得拿出證據證明這圖確實是我拍的，不是我扒的。像這個案子裏，被告把原告圖片水印都截掉了，那肯定是在網絡上扒的，肯定侵權。但如果被告的時候，能把原圖或提示詞都拿出來，證明確實能生成這圖，那被告侵權就不成立了。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：但如果要重現的話，萬一輸入同樣的提示詞，</span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 生成的圖不一樣，那不就沒法自證了？</span></p><p>&nbsp;</p><p>鄧超：理論上是這樣，但另一方面來看，這些圖片侵權的案子，判賠額都很低，這個案子判賠 500，其他案子更少，一般就幾十塊錢，風險很小。如果是自創圖片的話，雖然不一定保留有創作過程，但肯定會留痕，實在不行還能找證人出庭作證，總之肯定能查清，所以對現狀不會有什麼顛覆性的影響。</p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>03 AI 創作，風險大大的有</h1><p><span style="color:#245bdb">開源中國：説到獨創性，</span><span style="color:#245bdb"><strong>目前很多的 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 圖片，都是用別人現有的圖片「溶」出來的，這樣也能算獨創性嗎？這不算抄襲嗎？</strong></span></p><p>&nbsp;</p><p>鄧超：當前剛好有一個案子：2023 年 12 月 27 日，《紐約時報》起訴微軟和 OpenAI，宣稱報社數百萬篇文章被用作 AI 的訓練數據，這些數據的投餵到底是屬於合理使用還是版權侵權，現在也沒有定論，可以密切關注一下。</p><blockquote><p>「合理使用原則」是指，雖然你的行為嚴格來説算侵權，但你的行為是一種可以接受的借用，用來促進創造性的表達。例如，學者可以在自己的作品中引用摘錄他人內容；作者可以出版改編圖書；普通人可以截取電影片段做影評。換句話説，如果對版權限制過死，文明的創造力將可能停滯。</p><p>科技公司長期利用這一原則來規避版權爭議。2013 年，谷歌因為複製數百萬冊圖書並在線上傳書裏的片段，遭到作家協會的起訴，法官基於合理使用原則，裁決谷歌這一行為合法，因為它為公眾創建了可搜索的索引，創造了公共價值。在大模型時代，合理使用原則仍可能發揮關鍵作用。支持 AI 不侵權的人認為，<strong>大模型生成內容的過程，跟人類創作相差無幾——當你嘗試畫一幅畫或拍一支視頻，你的腦海裏也會有你看過的畫或電影。人類的創作在前人的基礎上進步，大模型也是如此。</strong></p></blockquote><p><strong>現實總是領先法律一步：現實裏出現問題了，法律再進行迴應，現在剛好卡在了沒達成一致意見的時候。</strong></p><p><strong>從本質上來講，著作權法、</strong><strong>知識產權</strong><strong>法的目的都是為了促進社會的繁榮。</strong>像遠古時代，沒有什麼知識產品，宋代印刷術出現之前，大家都是用手抄本，但大家都認為這是好事，可以防止文獻失傳。印刷術出現之後，才慢慢有了著作權。立法者認為，對作品作者給予一定保護，可以激發其他人創作出更多的作品來。現實也的確是這樣，發達國家都有着非常完善的知識沉澱。所以本質來講，還是看怎麼選擇更能促進產業和整個社會的發展。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：説到促進創作，這裏我要講一下，</span><span style="color:#245bdb"><strong>在美術界，相似度達到 10% 就屬於抄襲了，但是 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 現在是在不聲明的情況下抄襲，並且不以任何代價使用，這不就跟促進創作的初衷剛好相反了？</strong></span><span style="color:#245bdb">如果一做出來就會被抄襲，那不正好打擊了人們創作的積極性，擠壓人的創作空間嗎？</span></p><p>&nbsp;</p><p>鄧超：對，是這樣。<strong>任何一個東西，政策的影響都是兩方面的，</strong>你説的是負面的一方。但從正面來講，以前創作圖片，需要美工先學十年美術，美工畫一幅圖要畫一天。但現在，任何一個沒有學過美術的人，也可以創作出一幅畫了。從這方面來講，生產力肯定是大大提高了，AI 一天生成的圖就能頂 100 個美工的創作。當然，最後肯定還需要微調，但這生產率已經翻倍了。</p><p>假設現在一個公司需要 100 張圖，如果找美工，成本是十萬塊錢；但找一個 AI 的話，可能就 1000 塊錢，加上後期人工修改可能只需一萬。從公司的角度來講，它的成本就降低了，變得更有競爭力了，但背後可能就有十個美工失業了。可是從另外一個角度來講，可能又會有十個 AI 相關的就業崗位增加。</p><p>所以 AI 這個東西，它就像蝴蝶效應一樣，一個因素改變帶來的社會變化非常複雜，有人受益，就會有人受損，所以這裏很難預測，也不是我一個人能想明白的事。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：在風險這塊，舉個例子：假設我用 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 做圖的時候，只輸了文字</span><span style="color:#245bdb">指令</span><span style="color:#245bdb">，但 AI 在訓練的時候被餵了有版權的圖片，所以</span><span style="color:#245bdb"><strong>產出給我的圖片也侵權了，那是我負責還是 AI 公司負責？</strong></span></p><p>&nbsp;</p><p>鄧超：按照咱們討論的這個案子來講，肯定是你負責，因為 <strong>AI</strong><strong> 它只是一個工具，就跟畫筆或者照相機一樣，最後出問題可能還是得人來負責。</strong>除了我們剛才説的「紐約時報訴 OpenAI 案」，因為 OpenAI 是在訓練的時候使用了紐約時報的內容，所以要 OpenAI 負責。但是現在 OpenAI 已經把產品軟件提供出來了，你用這個 AI 軟件生成的圖片，如果侵權的話，（雖然現在還沒有案例），AI 工具它大概率是沒有責任的，責任在你。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：可是我本意沒有想要侵權任何人，也不是我讓這個 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 去抄襲別人的，甚至我都不知道別人作品的存在，是 AI 公司訓練的時候餵了有版權的圖導致的生成作品侵權，這種情況我是沒法控制的，也需要我來負責嗎？</span></p><p>&nbsp;</p><p>鄧超：確實，你問的這三個問題，是 AI 時代最棘手的三個問題，現在都沒有人有答案：</p><p><strong>第一，</strong><strong>大模型</strong><strong>使用海量數據來進行訓練，這種行為到底是侵權還是合理使用？</strong></p><p><strong>第二，</strong><strong>AI</strong><strong> 生成的作品到底有沒有版權？（今天討論的這個案子裏北京互聯網法院已經初步給出了意見）</strong></p><p><strong>第三，用 </strong><strong>AI</strong><strong> 生成的作品侵權了究竟誰來承擔責任？</strong></p><p>這三個問題現在沒人能有答案，我剛才説的，只是我個人的觀點。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：那意思就是説，有好處的話，是使用者獲得，如果是風險的話，也是使用者承擔。那 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 公司它豈不是隻負責賺錢不承擔風險？</span></p><p>&nbsp;</p><p>鄧超：簡單來説是這樣，但具體的還得結合具體案情來講。</p><p>企業的風險就是我們説的第一個問題：用別人的內容來訓練 AI 模型，屬不屬於合理使用？這時候的政策是很敏感的。假設這算合理使用，企業風險很小，那一定程度上會促進 AI 產業的發展，因為企業沒啥後顧之憂了；但如果讓企業承擔很大的責任，那一些剛發展起來的小公司搞不好會因為法律訴訟破產，這樣就阻礙了行業發展。法律也好，判決也好，肯定都是要考慮產業發展的。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：但是也不能光攬好處，把風險甩給用戶去跟原作者扯皮吧？</span></p><p>&nbsp;</p><p>鄧超：對，但是有人受益，肯定就有人受損，這個不太可能雙贏，就看你價值取向更偏向誰。比如產業早期的時候，可能傾向於促進產業發展；等產業發展成熟了，公司壯大了，還一點責任都不承擔就不太好了。不同階段，產業政策不一樣，法律方面的話，至少在我看來，裁判者也好，立法者也好，都是需要平衡的。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：伴隨着人工智能、大語言模型的發展，</span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 創作這種生產方式，還可能會觸及哪些法律問題？</span></p><p>&nbsp;</p><p>鄧超：除了上面講到的三點，還有就是<strong>可能會侵犯別人的肖像權</strong>，比方説生成的人像跟別人長得一樣，可能就會侵犯肖像權，這也屬於第三點中侵權的一種形式吧。</p><p>&nbsp;</p><p><span style="color:#245bdb">開源中國：法律屆是怎麼看待 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 創作這一新的生產模式的？接下來會不會出台相關的法律法規呢？</span></p><p>&nbsp;</p><p>鄧超：按照過往的歷史經驗來看，不會這麼早出台法律。以往像互聯網之類的新事物，法律界都會先讓子彈飛一會兒，先觀察一陣，等到時機成熟了，再出台相關法律法規。另外，咱們現在的知識產權法的框架，足以解決目前跟 AI 相關的一些問題，還沒有必要單獨針對 AI 立一個法。可能等時機成熟了，會完善法律下面的一些解釋或規定吧。</p><hr><p>對此，各位怎麼看？你認為 AI 作品應該有版權嗎？我們評論區見吧~</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>本期嘉賓：</strong>鄧超 | 律師（微信號：dengchao）</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="560" src="https://oscimg.oschina.net/oscnet/up-0fa35e5b407c4ce45828bd4c6e0c8078989.png" width="400" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">具有理學學士和法學博士學位，有着深厚的法學理論基礎；在知識產權行業從業十餘年，有着豐富的實踐經驗。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">長期專注於科技和媒體領域的知識產權前沿問題的研究和實踐，代表客戶處理相關的訴訟和非訴法律事務。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">在進入律師事務所之前，曾就職於世界 500 強公司的法務部以及國內頂尖的知識產權事務所，為眾多跨國公司、國內上市公司等提供知識產權法律服務。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10992795</guid>
            <link>https://my.oschina.net/u/6852546/blog/10992795</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[重磅！AutoMQ 品牌全新升級]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年伊始，</p><p>AutoMQ 作為一家專業的消息隊列和流存儲軟件服務供應商，</p><p>正式發佈全新的 logo 和官網與大家見面！</p><p>一直以來，</p><p>我們致力於引領消息和流存儲走向雲原生時代！</p><p>希望通過這次品牌升級，</p><p>不斷創新，為大家提供更先進的產品和服務！</p><p><strong>LOGO 升級</strong></p><p><img alt="" src="https://image.automq.com/%E5%AE%98%E7%BD%91/20231214-171408.png" referrerpolicy="no-referrer"></p><p>新 logo 以"M"字母為核心設計元素，融合"A"字母，不僅象徵着 AutoMQ 的名字，更代表了我們對核心業務和理念的堅持。AutoMQ 正是以雲原生技術理念，對消息隊列和流存儲領域進行深刻創新，致力於通過自動伸縮、自動運維和自動優化的技術，為客戶兌現雲的普惠價值。</p><p>我們的品牌形象以流暢的線條和波浪效果為特徵，象徵着 AutoMQ 助力企業駕馭規模日益龐大的數據流，確保數據傳輸的高效和穩定。在視覺上，全新品牌選擇了充滿未來感的科技紫作為主題色彩，它不僅代表了我們追求技術卓越的決心，也反映了我們以產品為驅動，不斷前行的發展理念。</p><p><strong>官網升級</strong></p><p><img alt="" src="https://image.automq.com/%E5%AE%98%E7%BD%91/%E5%AE%98%E7%BD%91%E6%88%AA%E5%9B%BE.jpeg" referrerpolicy="no-referrer"></p><p>新官網鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.automq.com" target="_blank">https://www.automq.com</a></p><p>新官網堅持技術開發者友好的設計理念，以可量化的數字結論，從<strong>成本、穩定性、彈性和兼容性</strong>等方面闡述了 AutoMQ 帶來的技術優勢和客戶價值。<br> 新官網全新設計了<strong>博客、文檔中心、產品、定價詳情頁面</strong>，幫助開發者快速瞭解 AutoMQ 的產品功能和參考資料。<br> 最後，值得一提的是官網的構建過程也使用了 Webflow 低代碼設計開發平台。整個開發過程無需前端工程師介入，由設計師直接完成設計上線，並且可以做到隨時快速迭代。</p><p>歡迎關注我們，學習更多技術乾貨！同時，也誠邀各位開源愛好者持續關注我們社區，點亮小星星🌟，跟我們一起構建雲原生消息中間件！</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 07:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276906</guid>
            <link>https://www.oschina.net/news/276906</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Wok-Server —— 輕量級 Nodejs 後端框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:left">Wok-Server 是一個簡潔易用的 Nodejs 後端框架，使用 Typescript 開發，有完整的類型約束和定義，註釋詳細，文檔齊全，支持國際化。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">主要功能：配置，日誌，國際化，校驗，緩存，MVC，mysql，mongodb ，週期任務 。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><a href="https://gitee.com/tai/wok-server/blob/master/documentation/zh-cn/index.md">查看文檔</a></p><h2 style="margin-left:0; margin-right:0; text-align:left">優點</h2><ul><li>學習成本較低，函數式為主，少量面向對象，未使用代理和裝飾器等增強技術</li><li>功能簡單，使用方便，保持克制，不引入太多特性</li><li>輕量封裝，最大限度兼容已有生態，支持集成第三方 http 相關的庫來處理請求</li><li>支持國際化，自帶多種語言的支持，國際化內容支持擴展</li><li>有完整的類型約束和定義，結合 IDE 的代碼補全功能，開發效率高</li><li>註釋詳細，文檔就在代碼中，方法和參數都有詳細説明，可在 IDE 的輔助下方便查看</li></ul><h2 style="margin-left:0; margin-right:0; text-align:left">Hello world</h2><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">安裝：</p><div style="text-align:left"><div><pre><span>npm i wok-server --save</span></pre><div style="text-align:center">&nbsp;</div></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">入口文件：</p><div style="text-align:left"><div><pre><span><strong style="color:#000000">import</strong><span>{</span><span>startWebServer</span><span>}</span><strong style="color:#000000">from</strong><span>'</span><span style="color:#dd1144">wok-server</span><span>'</span></span><span><span>startWebServer</span><span>({</span></span><span><span style="color:#008080">routers</span><span>:</span><span>{</span></span><span><span>'</span><span style="color:#dd1144">/</span><span>'</span><span>:</span><strong style="color:#000000">async</strong><span>exchange</span><span>=&gt;</span><span>exchange</span><span>.</span><span>respondText</span><span>(</span><span>'</span><span style="color:#dd1144">Hello world !</span><span>'</span><span>)</span></span><span><span>}</span></span><span><span>}).</span><strong style="color:#000000">catch</strong><span>(</span><span>e</span><span>=&gt;</span><span>{</span></span><span><span>console</span><span>.</span><span>error</span><span>(</span><span>'</span><span style="color:#dd1144">Start server failed</span><span>'</span><span>,</span><span>e</span><span>)</span></span><span><span>})</span></span></pre><div style="text-align:center">&nbsp;</div></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">上面的代碼啓動了 web 服務，訪問路徑<span>&nbsp;</span><code>http://localhost:8080</code><span>&nbsp;</span>將輸出文本 「Hello world !」。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">相關的設置可以通過環境變量來修改，查看<a href="https://gitee.com/tai/wok-server/blob/master/documentation/zh-cn/index.md">完整文檔</a>瞭解細節。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 06:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/wok-server</guid>
            <link>https://www.oschina.net/p/wok-server</link>
        </item>
        <item>
            <title>
                <![CDATA[Jina AI 開源中英和英德雙語 8K 向量模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在 Jina Embeddings 英語向量模型突破百萬下載後，Jina AI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FT-2EB1LfZKhueidIGW1x0w" target="_blank">宣佈</a>又正式開源了兩款雙語向量模型：中英雙語（Chinese-English）和英德雙語（English-German）向量模型，這也是全球首次推出支持 8K 雙語文本的開源向量模型。</span></p><h4><span style="color:#000000"><strong>技術亮點</strong></span></h4><p><span style="color:#000000"><strong>8K 輸入：長文本處理更得心應手</strong></span></p><p><span style="color:#000000">在 RAG 應用裏，文本就像被切成了多個塊，通過 Embedding 模型變成向量，然後存進數據庫。當你搜索時，系統會把這些文本塊的向量和你的搜索詞比對，找到最匹配的文本。</span></p><p><span style="color:#000000">傳統模型最多隻能處理 512 Token 的文本，面對更長文本時，就力不從心，尤其是預測的時候。</span></p><p><span style="color:#000000">但 Jina Embeddings v2 能處理高達 8k 的輸入，能夠實現從實體、句子、段落到整個篇章的多粒度向量表示。實際應用的時候，可以將這些不同層次的向量結合起來，實現更為精準的匹配。此外，也支持按語義切割，獲得更佳的搜索效果。</span></p><blockquote><p><span style="color:#000000">8K token，也就是説一整版人民日報的內容可以壓縮成一個向量！</span></p></blockquote><p><span style="color:#000000"><strong>技術創新：JinaBert 架構</strong></span></p><p><span style="color:#000000">Jina Embeddings 系列模型均基於 Jina AI 自研的 JinaBert 架構，這是首次將 ALiBi 應用到編碼器上，該架構專為長文本任務優化，直接在 Attention 層處理位置信息，讓模型更準確地捕捉詞語間的關係。就算是超長文本，也能輕鬆應對。</span></p><p><span style="color:#000000">這一技術創新讓模型在處理長文本時更加強大，也為 RAG 應用帶來了更多可能性。無論是解讀法律文件、研究醫學文獻、還是文學分析，Jina Embeddings 系列模型都表現出色，任務的準確率和效率都大大提升。</span></p><p><span style="color:#000000"><strong>雙語支持：無縫跨語言交互</strong></span></p><p><span style="color:#000000">雙語模型能把中文（或德文）和英文映射到同一個向量空間。即使是不同語言，只要含義相近，它們在向量空間裏就很接近。</span></p><p><span style="color:#000000">儘管很多模型也聲稱支持多種語言，但由於英語在互聯網上的主導地位，以及訓練階段大量使用機器翻譯文本，這些模型往往對某些人羣、主題或話題存在偏見，其影響會在下游任務中進一步放大。Jina AI 則專注於優化 2 種語言的向量表徵，嚴格把關訓練數據，力求把偏見降到最低，並確保性能超越那些支持多語言的大型模型。</span></p><p><span style="color:#000000">用 Jina Embeddings，不管是在 RAG 聊天機器人裏，還是給文本分類、做摘要、分析情感，都能把不同語言的文本當作同一種語言來處理，讓多語言應用的構建變得無比絲滑。用中文搜中文資料，或者中文搜英文、英文搜中文，都能得到又準又順的結果。Jina Embeddings 助力您打造和全球用戶無障礙溝通的新時代！</span></p><p><span style="color:#000000"><strong>MTEB 排行榜：性能領先</strong></span></p><p><span style="color:#000000">Jina Embeddings v2 系列模型在 MTEB 排行榜上，在文本分類、檢索、重排、摘要等任務上均有優勢。並且輸出和 OpenAI 完全一致，是 OpenAI ada 002 模型的理想替代開源解決方案。</span></p><p><span style="color:#000000">jina-embeddings-v2 的雙語模型以 322MB 的輕巧體積（包含 1.61 億參數），輸出維度為 768，能夠在普通計算機硬件上高效運行，無需依賴 GPU，極大地提升了其實用性和便捷性。</span></p><p><span style="color:#000000">最近，在 Standford HAI 發佈的 LoCo 性能測試中，Jina Embeddings 同樣名列前茅。</span></p><p><img height="221" src="https://oscimg.oschina.net/oscnet/up-5db7acf49ccda5e5a0aba0d4098ee18b6b6.png" width="500" referrerpolicy="no-referrer"></p><p><img height="135" src="https://oscimg.oschina.net/oscnet/up-789c9393a0fb12fa9b322e8af83f1b0e6c0.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><span style="background-color:#ffffff">Jina</span> AI 方面表示，未來將持續擴展多語言 8k 向量模型家族，支持更多語言。</span></p><ul><li><span style="color:#000000">中英雙語向量模型：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fjinaai%2Fchinese-english-embeddings" target="_blank">https://huggingface.co/jinaai/chinese-english-embeddings</a></li><li><span style="color:#000000">英德雙語向量模型：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fjinaai%2Fenglish-german-embeddings" target="_blank">https://huggingface.co/jinaai/english-german-embeddings</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276902</guid>
            <link>https://www.oschina.net/news/276902</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Milk-V Vega: 全球首款 RISC-V 萬兆開源交換機正式發售]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>MilkV 於去年 8 月亮相了「全球首款開源萬兆 RISC-V 網絡交換機 Milk-V Vega」。時隔數月，該產品現已上架官方淘寶店開售，定價 799 元。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dc8f8d1b6ca91d1342e4484e8e267513a9c.jpg" referrerpolicy="no-referrer"></p><p>據介紹，Milk-V Vega 是 Milk-V 面向新一代網絡架構開發的一款小體積、高密度盒式開源萬兆網絡交換機，為用戶提供寬帶、語音、視頻、監控等多業務統一承載平台，多網融合覆蓋全業務；搭載國產 RISC-V 高可靠網絡交換芯片，幫助企業與用戶大幅簡化網絡架構，降低能耗成本與運維成本；可廣泛應用於數據中心、園區、大中型企業網絡、酒店、科研教學等場景。 &nbsp;</p><p>Milk-V Vega 支持完備的二層網絡協議處理功能，包括 L2 橋接，L2 組播和風暴抑制等；支持基於流、端口、協議、子網的 VLAN 功能；支持 STP，RSTP 和 QinQ 功能；支持防 DOS 攻擊，黑白名單和協議包濾除功能；支持濾鏡，鏈路聚合，OAM 報文發送和端口保護功能；支持入口及出口的 ACL 功能，還支持同步以太網，1588 功能。</p><p>同時 Milk-V Vega 作為全球首款 RISC-V 開源萬兆交換機，為開發者提供了以下特性：</p><ul><li>基於開源 Linux 系統，方便二次開發及 DIY</li><li>開放 openSBI，u-boot，Linux kernel 源碼，提供交叉編譯工具鏈</li><li>提供 JTAG 接口，方便底層開發</li><li>提供 RS232 及 I2C 接口，方便外接其他傳感器</li><li>支持 1U 標準機櫃，每一層機櫃可安裝 2 台 Milk-V Vega</li><li>雙萬兆光口 + 4 千兆光口 + 8 千兆電口，滿足家用 Homelab 需求</li><li>支持遠程配置，提供 WEB 和 SSH 訪問</li><li>提供命令行業務配置，實現 VLAN 配置，端口鏡像，MAC 地址學習，流量控制等功能</li><li>提供接口 SDK 和 API，靈活實現業務配置</li></ul><p><img height="1922" src="https://oscimg.oschina.net/oscnet/up-18941523fbbd18a8e49875ecd1672e1a1a8.jpg" width="1080" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-553d000aeabc9e13f63432542706d102e13.jpg" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c56ea9be1224ad7658d518aedd13b7c0dea.jpg" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-dd5e9f39bbba69c1b283082faf3484443da.jpg" referrerpolicy="no-referrer"></p><p><strong><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsFzKJKkRKq3q9DYPtpm2_Q" target="_blank">https://mp.weixin.qq.com/s/sFzKJKkRKq3q9DYPtpm2_Q</a></u></em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 06:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276901</guid>
            <link>https://www.oschina.net/news/276901</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[npm 被濫用 —— 有人上傳了 700 多個武林外傳切片視頻]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Sonatype 安全研究團隊近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.sonatype.com%2Fnpm-flooded-with-748-packages-that-store-movies" target="_blank">介紹</a></u>了一起濫用 npm 的案例——他們發現託管在 npm 的 748 個軟件包實際上是視頻文件。</p><p>據介紹，這些軟件包每個大小約為 54.5MB，包名以 「wlwz」 作為前綴，並附帶了應該是代表日期的數字。時間戳顯示，這些包至少自 2023 年 12 月 4 日起就一直存在於 npm，但 GitHub 上週已經開始刪除。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4206ec7f1e46a5d3841a266e37293bd8f7b.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bccdf9a35b4ae1bd8a8920c57f87e5ceeb7.png" referrerpolicy="no-referrer"></p><p>每個包中都有以「.ts」擴展名結尾的視頻剪輯，這表明這些視頻剪輯是從 DVD 和藍光光盤中翻錄的。</p><blockquote><p>這裏的 ts 不是 TypeScript 文件，而是 transport stream 的縮寫，全稱為 「MPEG2-TS」：</p><p>MPEG2-TS 傳輸流（MPEG-2 Transport Stream；又稱 MPEG-TS、MTS、TS）是一種標準數字封裝格式,用來傳輸和存儲視頻、音頻與頻道、節目信息，應用於數字電視廣播系統，如 DVB、ATSC、ISDB[3]:118、IPTV 等。</p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dd32d5c3ad016f5c5ba20f9ec67e9f04a3f.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-85ee088f5f36f3c27c4bb43e72b3c6271ec.png" referrerpolicy="no-referrer"></p><p>此外，某些包（例如「wlwz-2312」）在 JSON 文件中包含普通話字幕。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-37361519bbcf2b7a95d47a0a2451c0e42aa.png" referrerpolicy="no-referrer"></p><p>雖然這些視頻不會像挖礦程序、垃圾郵件包和依賴性惡意軟件那樣毒害社區，但這種把開源基礎設施當 CDN 的操作無疑是破壞了規則，也違反了供應商的服務條款，各位耗子尾汁吧。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 03:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276893/npm-flooded-with-748-packages-wlwz</guid>
            <link>https://www.oschina.net/news/276893/npm-flooded-with-748-packages-wlwz</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源小談，贈現代臥龍、鳳雛；創造三贏的方案！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3><span>前言</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 </span><span><a href="https://www.oschina.net/comment/news/276508"><span>ioGame17 文檔或將強制收費</span></a></span><span>文中引起了一些討論，這些討論更多的是理念上的分歧。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>文中內容簡要如下</span></p><blockquote><p style="margin-left:.8em; margin-right:0"><span>近期 ioGame 將要升級到 21 版本，提醒開發者保存好 ioGame17 的文檔。</span></p><p style="margin-left:.8em; margin-right:.8em">&nbsp;</p><p style="margin-left:0; margin-right:.8em"><span>開發者如果不打算升級到 ioGame21 的，請提前私下保存好 ioGame17 相關文檔。ioGame21 發佈後，在線文檔的內容則與新版本對應。而舊的文檔（ioGame17）將從自願付費模式轉為強制付費文檔。如果不打算支付這部分文檔費用，請私下保存一份自留使用，但不得以任何形式傳播及公開。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>整體內容並不多，意外的是在討論區中驚現各種現代化的臥龍、鳳雛、五星評論員、如果哥、指點江山哥、慷他人之慨...等，之流。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>由於精力有限，將不對之前的文檔、舊的版本進行維護。舊的文檔如有需要，可付費獲取；如不想付費，請私下保存一份自留使用，但不得以任何形式傳播及公開。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>之所以不提供舊文檔的閲讀及舊版本的維護，是因為 ioGame 開源作者將精力放到了最新的 ioGame 版本上，並提供了與之對應版本的在線文檔閲讀（不需要登錄，沒有辣眼的廣告，可閲讀所有文檔）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>但似乎現代化的臥龍、鳳雛、五星評論員、如果哥、指點江山哥、慷他人之慨...等，之流，想讓開源作者繼續免費提供舊文檔，並無條件的維護舊版本。（不知道讓 spring 團隊維護 1.x 版本的，會得到什麼樣的回覆）</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 開源作者在閲讀 </span><span><a href="https://www.oschina.net/comment/news/276508"><span>ioGame17 文檔或將強制收費</span></a></span><span>討論區相關的內容後，找到了能夠完美的解決這些矛盾的三贏方案。本篇內容不多，大體如下</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>理念衝突（不同）</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>可持續性發展</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>當前開源環境</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>開源策略</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>用戶流失？不，這是三贏！</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>比較優勢</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>理念不同</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><img height="398" src="https://oscimg.oschina.net/oscnet/up-336b076ff70f355b497e0040cf1b8a333cb.png" width="700" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>當今，在制度理念上可大致分為兩種，GC 主義和資本主義。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 源碼使用的是 AGPL 協議，之所以選擇該協議是因為，就目前來説其更符合 GC 主義；GC 主義的經濟制度類型為</span><span><strong><span>生產資料公有制</span></strong></span><span>，而資本主義則是</span><span><strong><span>生產資料私有制</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；同時，ioGame 是允許私有的，前提是支付閉源授權費。所以，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。</span></p><blockquote><p style="margin-left:0; margin-right:0"><span>ioGame 使用的開源策略是：兩開一免一自主。即源碼完全開放、最新文檔閲讀完全開放、使用完全免費、開發者可自主選擇按需付費。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>為什麼需要閉源授權費</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，這裏僅指閉源授權，也就是你的產品不需要對外開源（可將生產資料私有制）；除此之外，並不會提供更多的其他服務。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>之所以需要授權費，是因為我們為產品附加了價值。《資本論》中著名的公式：商品價值 = c+v+m，即商品價值 = 不變資本+可變資本+剩餘價值。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>c+v+m 可以表示社會總產值，也可以表示某個商品的價值，或某一單位時間內生產的商品的總價值。簡單的説 c 表示的是生產資料價值，v 表示的是勞動力的價值，m 表示的是剩餘價值</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>為了易懂，這裏舉個不恰當，但意思差不多的公式。商品價值 = 你為產品迭代的勞動力 + 你的日常開銷（自身教育及小孩教育的支出、維持動者本人及家屬生存所必需的生活資料、房租房貸...等）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在，關於閉源授權費這部分也説清楚了；之所以有閉源授權費，是因為我們為產品附加了價值。這裏再重複一次，使用 ioGame 是免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；同時，ioGame 是允許私有的，前提是支付閉源授權費。所以，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>資本主義理念的小算盤是，即希望免費使用你的產品，又希望你免費維護，同時又不想將自身的產品成果公開出來（只想生產資料私有制）。換句話説就是，又想馬兒跑，又不給馬吃草，因為這一行為很符合資本主義。這裏稱其為</span><span><strong><span>自以為聰明的資本家</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>自以為聰明的資本家</span></strong></span><span>的基本特徵是：你這產品不錯、你這框架不錯、你這項目不錯，應該免費；同時，這羣傢伙還擅長慷他人之慨，真讓他們參與付出時，結局是</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一頭牛</span></a></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>可持續性發展</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>經濟基礎是一切可持續性發展的前提，開源亦是如此。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>如大家所熟悉的 apache 組織、srping 等...各開源巨頭，都是有基金會或其他經濟支持的；也有一些半開源的產品會尋求一些資本的注入，其目的也是為了得到經濟支持。所以，經濟基礎是一切可持續發展的前提。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>大部分開發者認為開源軟件是完全免費的，也應當完全免費。造成這些錯覺是因為常年使用開源巨頭所提供的軟件，但又忽略了背後基金或類似基金的支持。注意，這裏説的類似基金指的是間接或直接所獲得的收入。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>資本家是恐怖的，國外的資本家們取得收益後，或多或少的會向基金會捐贈，以保持相互的良性循環。而</span><span><strong><span>自以為聰明的資本家</span></strong></span><span>們可不這麼想，因為他們並懂可持續性發展的重要性。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>這羣</span><span><strong><span>自以為聰明的資本家們</span></strong></span><span>秉持着希望免費使用你的產品，又希望你免費維護，同時又不想將自身的成果公開出來（只想生產資料私有制）。現在，我們知道使用 ioGame 是免費的了，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；當</span><span><strong><span>自以為聰明的資本家們</span></strong></span><span>知道要他們把私有資料公開時，他們就會給你上演</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一頭牛</span></a></span><span>的故事。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>到這，已經説清楚了經濟基礎是一切可持續發展的前提。同時，也區分了真正的資本家與</span><span><strong><span>自以為聰明的資本家</span></strong></span><span>。真正的資本家是恐怖的，他們懂得可持續性發展的重要性，並壯大着這些開源組織；而</span><span><strong><span>自以為聰明的資本家們</span></strong></span><span>並不懂得這些，</span><span><strong><span>滑稽</span></strong></span><span>的是他們還喜歡充當所謂的網絡俠客（並不具備事物分析能力的人，大部分的發言是臆測主觀性的）；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>開源環境</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>經濟是發展的核心，任何強大的開源組織（開源巨頭）都離不開經濟基礎。注意，這裏説的開源組織並不是指你在 github 隨意創建一個 organization 後，放入幾個項目的那種組織。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在，國內有很多人想要往這方面發力，建立國產開源組織；但目前在國內很難實現，具體原因這裏就不細説了，因為這部分沒有十數萬字也講不清楚，而且大部開發者對這部分也沒啥興趣。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>目前國產開源組織也有一些，但大部分都是幾個項目勉強湊合到一起所形成的組織。若想要建立一個可持續性發展的開源組織，就目前的環境來説是不可能的。建立一個可持續性發展的開源組織的基本條件，是需要有基金會或類似基金會的支持。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在沒有得到外部資金的支持時，任何一個開源框架想要有長遠的發展，首先需要考慮的是如何盈利。如果沒有持續資金的支持，通常很難堅持下去。你可以在 GitHub 上找到很多長時間未更新的開源項目，通常是因為最初的熱情慢慢消退，導致不再維護。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>國產項目的開源策略大部分都是採用社區版本和商業版本的方式，其本質目的也只有一個，即維持自身的可持續性發展。同時，這也是開源維護者與開源使用者的矛盾點之一，但這些是符合馬克思主義哲學三大規律的。（將來，如非洲、東南亞、西亞、中東 ...等地區的多數國家也會經歷這一階段的發展過程，但還需要數十年。）</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現階段，國內開源土壤與環境並不理想，並且還有一羣擅長慷他人之慨的網絡俠客在添堵。但並無大礙，因為這些小卡拉並不能阻礙，也阻礙不了國產開源的發展。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 的開源策略</span></h3><blockquote><p style="margin-left:0; margin-right:0"><span>ioGame 使用的開源策略是：兩開一免一自主。即源碼完全開放、最新文檔閲讀完全開放、使用完全免費、開發者可自主選擇按需付費。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>源碼：源碼完全開放，沒有社區版、商業版本之説。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>文檔：最新文檔閲讀完全開放，並採用自願付費原則（不強制付費）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；同時，ioGame 是允許私有的，前提是支付閉源授權費；所以，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。費用採用年付費制，且費用低（不會超過當年全國最低工資標準的 2 倍，並且可申請盈利後支付）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或許有開發者會問，國產開源項目大部分都是社區版本（免費）和商業版本（強制收費）的策略。但 ioGame 為什麼會採用源碼完全開放、文檔完全開放、使用完全免費的策略呢？</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>源碼完全開放的原因</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 推崇</span><span><strong><span>生產資料公有制。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>源碼完全開放可以讓更好地服務使用者，讓使用者更快、更好地完成業務並出產品；同時，這對使用者學習框架源碼也比較友好。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>通常（中、小、新）這類公司、團隊、獨立開發者，在前期是比較缺資金的。我們知道，只有讓遊戲開發者先盈利，之後想支付費用時才無壓力（閉源自身的遊戲產品）。（注意，使用 ioGame 是完全免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來）</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>最新文檔閲讀完全開放，並採用自願付費的原因</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在你閲讀 ioGame 的在線文檔時，不會有辣眼的廣告，沒有登錄限制。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 致力於提供高質量的使用文檔，在 ioGame21 中，大概有三十多萬字（不要認為文檔內容多，學習框架成本是困難的，這兩者不是對等關係；如果文檔只保留一個字，你會認為這是簡單的嗎？）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>不誇張的説，文檔的編寫比代碼還要困難。如果文檔只服務於少部分人，那就有點可惜了。只有完全開放了文檔，才能幫助更多的遊戲團隊、獨立開發者及想進入遊戲行業的開發者。因為我們知道，只有讓開發者先盈利了，他們才更願意支付費用。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>另一個文檔閲讀完全開放的原因是，ioGame 推崇</span><span><strong><span>生產資料公有制</span></strong></span><span>（不要理解為版權免費贈送）。需要注意的是，ioGame 的文檔不是開源的，以後也不會開源。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或許有開發者會問到，如果以後你的文檔不公開了，又或者説強制收費了怎麼辦。首先，我們的目標很明確，幫助開發者提升、快速地學習整體框架、加快遊戲產品的研發並上線盈利。其次，對基礎使用文檔收費並無興趣。再次，我們推崇</span><span><strong><span>生產資料公有制</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>此時開發者又會説到，xxx 一開始文檔也是公開的，等開發者開始用了，就開始收費割韭菜了，大家都被假開源騙怕了...等之類的話。這裏借用鳳凰傳奇曾毅的一句玩笑話，歌土跟我有什麼關係，我才幾個詞；同樣的，你被騙跟我有什麼關係，又不是我騙的你。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>另外，要是 ioGame 對基礎使用文檔有收費的興趣，也就不會請提前讓開發者私下保存一份自留使用了。所以與其他案例是有本質區別的。</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>首先，已經發文提前通知了。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>其次，允許開發者私下保存一份自留使用，但不得以任何形式傳播及公開（ioGame 的文檔沒有開源，以後也不會開源，著作權歸作者所有）。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>再次，在 ioGame21 發佈後，在線文檔對應的是當前最新版本；新的在線文檔依舊採用自願付費模式策略，與之前一樣，文檔是完全開放的（開發者可閲讀所有文檔，沒有任何限制）。</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>使用 ioGame 免費的原因</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 推崇</span><span><strong><span>生產資料公有制。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是完全免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；同時，ioGame 是允許私有的，前提是支付閉源授權費（</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv" target="_blank"><span>為什麼採用授權許可申請？</span></a></span><span>）；所以，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>用戶流失？不，這是三贏！</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或許會有開發者問，為什麼使用閉源授權的方式，這樣不是會流失用戶嗎？</span></p><blockquote><p style="margin-left:0; margin-right:0"><span>提示：開源 != 免費。即使是做慈善的組織，組織內工作的人也得吃飯。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>純白嫖的用戶流失是一定的，但同時也會吸引更多的新用戶，因為 ioGame 有了更長遠的規劃。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGama 是海納百川的，在文檔中我們推薦了很多同行業的遊戲服務器框架。因為我們知道，流失的用戶與 ioGame 的矛盾點是必然存在的，但 ioGame 對待流失用戶是友好的，我們會積極的把這部分流失的用戶推薦給競品框架。這樣</span><span><strong><span>既解決了矛盾，又創造了三贏的局面，真是太棒了</span></strong></span><span>！</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>對於用戶羣體，ioGame 自身有明確的規劃，而且也沒打算説服所有的開發者來使用 ioGame；所以，我們首先要做的就是排除對自身不適合或者説理念不相同的開發者，只有這樣才能抽出更多的時間來服務真實有效使用者；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，這裏的真實有效使用者指的是在項目中使用了 ioGame 的團隊、個人、公司...等，並不是特指購買了閉源授權的；因為使用 ioGame 是完全免費的，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>最後，閉源授權的目的是為了社區的長期發展建設，通過閉源授權來營收，後將營收繼續投入到社區中，將社區壯大。規劃長久的發展，可使雙方互利，ioGame 就像一台水果採摘機器，你可以使用這台機器來採摘任何水果，在你取得收穫時，希望你能為這台機器加些能量。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>完全開源不怕被參考嗎</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 完全開源，就不怕其他開發者參考嗎？</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>不怕的，在</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23le5sm" target="_blank"><span>自研框架的成本分析及面臨的問題</span></a></span><span>這一小節中，已經列舉了很多案例了，這些案例都是與成本相關的。這些問題大致如下</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>如果負責研發框架的開發人員離職後，公司如何安排？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>如果負責研發框架的開發人員，或其他開發人員離職後，將框架帶到下個公司使用，是否等於用公司的資源幫其他公司做嫁衣？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>或將現有公司的框架帶到下個公司去使用，會給新公司帶來風險嗎？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>如果員工的框架是上個公司的，你如何確定沒有法律風險？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>有完整的使用文檔嗎？如果將你當前使用的框架給到其他團隊，在沒有你的幫助下，該團隊能順利完成開發嗎？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>打算新招一個編寫業務邏輯的人員，可以做到零學習成本嗎？</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>參考者在製作自己的框架時，也只敢參考部分，而且後續的維護成本也是恐怖的（需要付出巨大的勞動力）。看似參考的策略可以節省成本，但實際上的成本更高了。實際當中，也有很多開發者在開展這一策略，即參考 ioGame 來製作自己的框架，但其生命週期都是短暫的，最終是不了了之；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h4><span>有趣的小故事</span></h4><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>這裏説個有趣的小故事。現在，有兩個開發者分別想要研發一款遊戲，遊戲類型也大致相同，這裏將開發者稱為 A、B。 A 和 B 的目標很明確，就是快速的將遊戲開發出來並上線。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>技術選型的過程中，他們知道了 ioGame；A 、B 知道 ioGame 的源碼完全開放、最新文檔閲讀完全開放、使用完全免費；只是想將遊戲產品閉源時，則需要支付閉源授權費，但可以申請盈利後支付閉源授權費。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在，A 直接開始使用 ioGame 來研發遊戲產品了；而 B 則是在想，如何規避這部分閉源授權費。於是 B 就開始閲讀、參考 ioGame 相關源碼，並開始自制框架。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>數月後，B 依然把勞動力分配在自制的框架上；而 A 則早已將遊戲開發了出來。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或許 B 早已忘記了最開始的主要目標了，這也是大多數開發者存在的行為；為了達成次要目標，而放棄或拖延主要目標。這種行為的危害是巨大的，從而導致主要目標無法完成，甚至到最後有可能自制框架都沒能完成。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>這種真實的案例每天都在上演，你會發現很多想接觸遊戲行業的開發者，即使過了數年也沒有研發出一個遊戲。因為他們忘記了最初的主要目標，如果最開始就把勞動力分配在遊戲產品上，或許早已經完成主要目標了。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>而 A 的目標與執行力更加的明確，直接使用 ioGame 來研發產品。這樣就能把所有的勞動力分配到自身遊戲產品的業務上，從而能快速的開發出遊戲。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在這個小故事中，B 最開始只是為了規避閉源授權費，導致自身付出了更多的成本。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h4><span>比較優勢</span></h4><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>上面講了一個有趣的小故事，這裏還有一些</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23aSk5x" target="_blank"><span>關於成本分析的其他案例</span></a></span><span>（點擊我）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>大衞·李嘉圖在其代表作《政治經濟學及賦稅原理》中提出了比較成本貿易理論（後人稱為「</span><span><strong><span>比較優勢</span></strong></span><span>貿易理論」）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>比較優勢可以表述為：在兩國之間，勞動生產率的差距並不是在任何產品上都是相等的。每個國家都應集中生產並出口具有比較優勢的產品，進口具有比較劣勢的產品（即「兩優相權取其重，兩劣相衡取其輕」），雙方均可節省勞動力，獲得專業化分工提高勞動生產率的好處。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在小故事及</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23aSk5x" target="_blank"><span>關於成本分析的其他案例</span></a></span><span>中，本質上也是在描述成本的比較優勢。即兩個個體、兩個團隊、兩個公司 ... 等，之間的比較。兩者之間的分配策略，基本決定了後續的誰的生存幾率更大；把有趣小故事中的 A、B 替換成兩個公司、團隊之間的博弈亦是如此。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在有趣小故事中，之所以 A 比 B 更有幾率出遊戲產品，是因為 A 把勞動力放在遊戲產品的研發上，而 B 除了需要研發產品外，還需要兼顧自研框架。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>小結</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在我們知道了，ioGame 源碼完全開放，沒有社區版、商業版本之説，讓使用者用得開心，用得放心。ioGame 新版在線文檔閲讀完全開放，與之前一樣，依舊採用自願付費原則的策略（不強制付費）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；同時，ioGame 是允許私有的，前提是支付閉源授權費；所以，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><blockquote><p style="margin-left:0; margin-right:0"><span>ioGame 使用的開源策略是：兩開一免一自主。即源碼完全開放、最新文檔閲讀完全開放、使用完全免費、開發者可自主選擇按需付費。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>當其他開發者、團隊還有糾結及時，我們的真實有效用戶早已將產品上線並運營了。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 是無私的，能容得下所有競品框架；甚至我們還在文檔中介紹了其他的競品框架。如果 ioGame 不能很好的滿足你的需要，請別擔心，這裏還有</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fwwvg7z%23EH8Oc" target="_blank"><span>更多的 java 遊戲服務器框架推薦</span></a></span><span>給你。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>為什麼不在之前的討論區迴應</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>因為討論區大部分是各種現代化的臥龍、鳳雛。滑稽的是他們還喜歡充當所謂的網絡俠客（一些不具備事物分析能力的人，大部分的發言是臆測主觀性的）；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，這裏不是指討論區內的所有人，只是部分人符合我心中現代化臥龍、鳳雛的形象。所以，個人並不會把時間浪費在現代化臥龍、鳳雛身上；因為他們的目的不是辯，而是擺弄。不信？後續在其他版塊中，你還會看見這羣傢伙在不同的討論區中，週而復始的操弄着帶有臆測主觀性的庸俗觀點來發言。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>現代化的臥龍、鳳雛，或者説自以為聰明的資本家</span></strong></span><span>的基本特徵是：你這產品不錯、你這框架不錯、你這項目不錯，應該免費；同時，這羣傢伙還擅長慷他人之慨，真讓他們參與付出時，結局是</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一頭牛</span></a></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>我們只會把時間投入到真實有效使用者的身上，加強文檔的質量，耐心回答與 ioGame 相關的 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgame-town%2FioGame%2Fissues" target="_blank"><span>issues</span></a></span><span> 。注意，這裏的真實有效使用者指的是在項目中使用了 ioGame 的團隊、個人、公司...等，並不是特指購買了閉源授權的；因為使用 ioGame 是完全免費的，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>規避與防範 ioGame</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23a7jj5" target="_blank"><span>如何規避閉源授權費用？</span></a></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>通常來講你要防範的並不是 ioGame，因為 ioGame 每年需要支付的閉源授權的費用很少，而且可以申請盈利後支付。在成本分析中已經説明，如果你選擇自研框架，自研一個月的成本夠使用 ioGame 幾十年了（而且需要自己編寫、維護文檔）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>更多的時候，取得授權是為了保護自身產品源代碼泄露時可以得到法律的保護，所以如果你不擔心這點，我想你應該知道如何做了。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 的使命</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>改變行業現狀，降低使用難度。讓遊戲開發領域的</span><span><strong><span>生產資料公有制</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 是什麼？</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 學習成本非常低，可以説是</span><span><strong><span>零學習成本</span></strong></span><span>，即使沒有遊戲編程（網絡編程）經驗，也能輕鬆上手。開發者只需掌握普通的 java 方法或 webMVC 相關知識，就能用框架開發業務，通常在 10 分鐘內就能掌握。框架不要求開發者改變編碼習慣，而是自身適應開發者的需求。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>同時，ioGame 也</span><span><strong><span>適用於網絡遊戲服務器、物聯網、內部系統及各種需要長連接的場景</span></strong></span><span>；框架採用無鎖異步化、事件驅動的架構設計；輕量級，無需依賴任何第三方中間件或數據庫就能支持集羣、分佈式。通過 ioGame 可以很容易的搭建出一個集羣無中心節點、集羣自動化、多進程的分佈式遊戲服務器。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 是一個非常適合網絡遊戲開發的框架。可以讓你輕鬆地創建高性能、低延遲、易擴展的遊戲服務器，並且節省時間和資源。如果你想要快速地開發出令人驚豔的網絡遊戲，請不要猶豫，立即選擇 ioGame 吧！框架屏蔽了很多複雜且重複性的工作，並可為項目中的功能模塊結構、開發流程等進行</span><span><strong><span>清晰的組織定義</span></strong></span><span>，減少了後續的項目維護成本。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 的使用趨勢</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>關注 ioGame 的遊戲服務器開發者持續增多，</span><span><strong><span>2022-09 ~ 至今</span></strong></span><span>各月的統計數據；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>這裏的統計信息是關於開發者關注 ioGame 框架相關的，從統計數據中可以看出，由於 ioGame 上手簡單，功能強大等優點，得到了眾多開發者的關注。如果你想知道 ioGame 有沒有人在使用，可以先到這裏看下統計數據、開發者的評價與討論。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgpxk93%23TwVa8" target="_blank">https://www.yuque.com/iohao/game/gpxk93#TwVa8</a></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>這裏展示了每月的統計數據，統計數據來源於語雀後台，這些數據都是</span><span><strong><span>真實的、客觀存在的、活的</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>因為成本的原因，某寶某多還沒有出現能提供這種服務的商家，所以這樣的統計數據也更具真實性。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>通過統計數據，我們可以看到每天會有很多開發者在訪問 ioGame 的在線文檔，並且這些統計數據不是來源於口嗨的，也不是主觀創造的。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>所以，還在猶豫要不要使用 ioGame 的開發者們，更應該討論的是「為什麼這些開發者會選擇使用 ioGame」，而不是 ioGame 有沒有人在使用的問題。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao" target="_blank"><span>點擊我，到語雀後台查看 ioGame 的數據</span></a></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 版本命名規則</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>從發佈到中央倉庫開始，ioGame 就有定義了自身的</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fwsgmba%23zagb5" target="_blank"><span>版本規則</span></a></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>ioGame17 版本命名規則 x.y.z</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>x 表示當前使用的 JDK 版本</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>y 表示 ioGame API 變更版本 （但基本上不會變動，常規下是變動 x 才會變動 API）</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>z 表示 ioGame 新特性、新功能、新模塊、bugfix 相關</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 的 x 會跟着最新的 JDK LTS 版本來走的，目的是確保 ioGame 的 API 不會發生很大的變化。為了保持新活力與接受新鮮事物， ioGame 基本會用上最新的 JDK LTS; 也就是説，下一個 x 將會是 21;</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>x 一般延後 1~2 個季度，給開發者一個緩衝。即下一個 JDK LTS 出來後，那麼 ioGame 的 x 會在 1~2 個季度後跟上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>從 ioGame21 開始，版本命名規則將使用 x.y 的格式，其他照舊</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>x 表示當前使用的 JDK LTS 版本</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>y 表示 ioGame 新特性、新功能、新模塊、bugfix 相關</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>最後</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>由於整篇內容較長，閲讀到最後難免會忘記前面的。所以，在最後這裏，來個二次小結與介紹。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 推崇</span><span><strong><span>生產資料公有制。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 使用的開源策略是：兩開一免一自主。即源碼完全開放、最新文檔閲讀完全開放、使用完全免費、開發者可自主選擇按需付費。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是完全免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；同時，ioGame 是允許私有的，前提是支付閉源授權費（</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv" target="_blank"><span>為什麼採用授權許可申請？</span></a></span><span>）；所以，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><div><hr></div><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或許會有開發者問，為什麼使用閉源授權的方式，這樣不是會流失用戶嗎？</span></p><blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>提示：開源 != 免費。即使是做慈善的組織，組織內工作的人也得吃飯。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>純白嫖的用戶流失是一定的，但同時也會吸引更多的新用戶，因為 ioGame 有了更長遠的規劃。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGama 是海納百川的，在文檔中我們推薦了很多同行業的遊戲服務器框架。因為我們知道，流失的用戶與 ioGame 的矛盾點是必然存在的，但 ioGame 對待流失用戶是友好的，我們會積極的把這部分流失的用戶推薦給競品框架。這樣</span><span><strong><span>既解決了矛盾，又創造了三贏的局面，真是太棒了</span></strong></span><span>！</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>對於用戶羣體，ioGame 自身有明確的規劃，而且也沒打算説服所有的開發者來使用 ioGame；所以，我們首先要做的就是排除對自身不適合或者説理念不相同的開發者，只有這樣才能抽出更多的時間來服務真實有效使用者；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，這裏的真實有效使用者指的是在項目中使用了 ioGame 的團隊、個人、公司...等，並不是特指購買了閉源授權的；因為使用 ioGame 是完全免費的，</span><span><strong><span>付費不是必須的，也不是強制性的</span></strong></span><span>，選擇權在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><div><hr></div><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>真正的資本家是恐怖的，國外的資本家們取得收益後，或多或少的會向基金會捐贈，以保持相互的良性循環。而</span><span><strong><span>自以為聰明的資本家</span></strong></span><span>們可不這麼想，因為他們並懂可持續性發展的重要性。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>這羣</span><span><strong><span>自以為聰明的資本家們</span></strong></span><span>秉持着希望免費使用你的產品，又希望你免費維護，同時又不想將自身的成果公開出來（只想生產資料私有制）。現在，我們知道使用 ioGame 是免費的了，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來；當</span><span><strong><span>自以為聰明的資本家們</span></strong></span><span>知道要他們把私有資料公開時，他們就會給你上演</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一頭牛</span></a></span><span>的故事。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>現代化的臥龍、鳳雛，或者説自以為聰明的資本家</span></strong></span><span>的基本特徵是：你這產品不錯、你這框架不錯、你這項目不錯，應該免費；同時，這羣傢伙還擅長慷他人之慨，真讓他們參與付出時，結局是</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一頭牛</span></a></span><span>。</span></p><p>&nbsp;</p><div><hr></div><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>最後，我們的目的是為了幫助（中、小、新）這類公司、團隊、獨立開發者，通過雙方的比較優勢來互補。我們知道，只有讓遊戲開發者先盈利，之後想支付費用時才無壓力（閉源自身的遊戲產品）。（注意，使用 ioGame 是完全免費的，前提是要認同</span><span><strong><span>生產資料公有制</span></strong></span><span>，就是把你的產品也完全的開源出來）</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 03:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276890</guid>
            <link>https://www.oschina.net/news/276890</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[簡單一招竟把 nginx 服務器性能提升 50 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/action/visit/ad?id=1576" target="_blank">【直播預告】DBA 會被雲淘汰嗎？ <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><h2>需求背景</h2><p>接到重點業務需求要分輪次展示數據，預估最高承接 9w 的 QPS，作為後端工程師下意識的就是把接口寫好，分級緩存、機器擴容、線程拉滿等等一系列連招準備，再因為數據更新頻次兩隻手都數得過來，我們採取了最穩妥的處理方式，直接生成靜態文件拿 CDN 抗量</p><p>架構流程大致如下所示：</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-01-02-11-59FwLpwnTQRa2sueb..jpg" alt="" referrerpolicy="no-referrer"></p><p>數據更新後會重新生成新一輪次的文件，刷新 CDN 的時候會觸發大量回源請求，應用服務器極端情況得 hold 住這 9w 的 QPS</p><h2>第一次壓測</h2><p>雙機房一共 40 台 4C 的機器，25KB 數據文件，5w 的 QPS 直接把 CPU 打到 90%</p><p>這明顯不符合業務需求啊，咋辦？先無腦加機器試試唄</p><p>就在這時測試同學反饋壓測的數據不對，最後一輪文件最大會有 125KB，雪上加霜</p><p>於是乎文件替換，機器數量整體翻一倍擴到 80 台，服務端 CPU 依然是瓶頸，QPS 加不上去了</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-01-02-11-59591UDaNqz2ejKgeO.png" alt="" referrerpolicy="no-referrer"></p><p>到底是哪裏在消耗 CPU 資源呢，整體架構已經簡單到不能再簡單了</p><p>這時候我們注意到為了節省網絡帶寬 nginx 開啓了 gzip 壓縮，是不是這小子搞的鬼</p><pre><code>server
{
      listen 80;
      
      gzip on;
      gzip_disable "msie6";
      gzip_vary on;
      gzip_proxied any;
      gzip_comp_level 6;
      gzip_buffers 16 8k;
      gzip_http_version 1.1;
      gzip_types text/plain application/css text/css application/xml text/javascript application/javascript application/x-javascript;

......
}


</code></pre><h2>第二次壓測</h2><p>為了驗證這個猜想，我們把 nginx 中的 gzip 壓縮率從 6 調成 2，以減少 CPU 的計算量</p><blockquote><p>gzip_comp_level 2;</p></blockquote><p>這輪壓下來 CPU 還是很快被打滿，但 QPS 勉強能達到 9w，坐實了確實是 gzip 在耗 CPU</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-01-02-11-5911xGuMeD522kE2Orh.png" alt="" referrerpolicy="no-referrer"></p><p>nginx 作為家喻戶曉的 web 服務器，以高性能高併發著稱，區區一個靜態數據文件就把應用服務器壓的這麼高，一定是哪裏不對</p><h2>第三次壓測</h2><p>明確了 gzip 在耗 CPU 之後我們潛下心來查閲了相關資料，發現了一絲進展</p><p>html/css/js 等靜態文件通常包含大量空格、標籤等重複字符，重複出現的部分使用「距離加長度」表達可以減少字符數，進而大幅降低帶寬，這就是 gzip 無損壓縮的基本原理</p><p>作為一種端到端的壓縮技術，gzip 約定文件<strong>在服務端壓縮完成</strong>，傳輸中保持不變，直到抵達客戶端。這不妥妥的理論依據嘛～</p><p>nginx 中的 gzip 壓縮分為動態壓縮和靜態壓縮兩種</p><p>•動態壓縮</p><p>服務器給客戶端返回響應時，消耗自身的資源進行實時壓縮，保證客戶端拿到 gzip 格式的文件</p><p>這個模塊是默認編譯的，詳情可以查看 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnginx.org%2Fen%2Fdocs%2Fhttp%2Fngx_http_gzip_module.html" target="_blank">https://nginx.org/en/docs/http/ngx_http_gzip_module.html</a></p><p>•靜態壓縮</p><p>直接將預先壓縮過的 .gz 文件返回給客戶端，不再實時壓縮文件，如果找不到 .gz 文件，會使用對應的原始文件</p><p>這個模塊需要單獨編譯，詳情可以查看 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnginx.org%2Fen%2Fdocs%2Fhttp%2Fngx_http_gzip_static_module.html" target="_blank">https://nginx.org/en/docs/http/ngx_http_gzip_static_module.html</a></p><p>如果開啓了 gzip_static always，而且客戶端不支持 gzip，還可以在服務端加裝 gunzip 來幫助客戶端解壓，這裏我們就不需要了</p><p>查了一下 jdos 自帶的 nginx 已經編譯了 ngx_http_gzip_static_module，省去了重新編譯的麻煩事</p><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-01-14-21-44VgvTdUt25t44PAPy.jpg" alt="" referrerpolicy="no-referrer"></p><p>接下來通過 GZIPOutputStream 在本地額外生成一個 .gz 的文件，nginx 配置上靜態壓縮再來一次</p><blockquote><p>gzip_static on;</p></blockquote><p><img src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-01-02-11-59bMIHDM9dOrJ8soD.png" alt="" referrerpolicy="no-referrer"></p><p>面對 9w 的 QPS，40 台機器只用了 7% 的 CPU 使用率完美扛下</p><p>為了探底繼續加壓，應用服務器 CPU 增長緩慢，直到網絡流出速率被拉到了 89MB/s，擔心影響宿主機其他容器停止壓力，此時 QPS 已經來到 27w</p><p>qps 5w-&gt;27w 提升 5 倍，CPU 90%-&gt;7% 降低 10 倍，整體性能翻了 50 倍不止，這回舒服了～</p><h2>寫在最後</h2><p>經過一連串的分析實踐，似乎靜態壓縮存在「壓倒性」優勢，那什麼場景適合動態壓縮，什麼場景適合靜態壓縮呢？一番探討後得出以下結論</p><blockquote><p>純靜態不會變化的文件適合靜態壓縮，提前使用 gzip 壓縮好避免 CPU 和帶寬的浪費。動態壓縮適合 API 接口返回給前端數據這種動態的場景，數據會發生變化，這時候就需要 nginx 根據返回內容動態壓縮，以節省服務器帶寬</p></blockquote><p>作為一名後端工程師，nginx 是我們的老相識了，抬頭不見低頭見。日常工作中配一配轉發規則，查一查 header 設置，基本都是把 nginx 作為反向代理使用。這次是直接訪問靜態資源，調整過程的一系列優化加深了我們對 gzip 的動態壓縮和靜態壓縮的基本認識，這在 NG 老炮兒眼裏顯得微不足道，但對於我們來説卻是一次難得的技能拓展機會</p><p>在之前的職業生涯裏，我們一直聚焦於業務架構設計與開發，對性能的優化似乎已經形成思維慣性。面對大數據量長事務請求，減少循環變批量，增大併發，增加緩存，實在不行走異步任務解決，一般瓶頸都出現在 I/O 層面，畢竟磁盤慢嘛，減少與數據庫的交互次數往往就有效果，其他大概率不是問題。這回有點兒不一樣，CPU 被打起來的原因就是出現了大量數據計算，在高併發請求前，任何一個環節都可能產生性能問題</p><p>作者：京東零售，閆創</p><p>來源：京東雲開發者社區，轉載請註明來源</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10979685</guid>
            <link>https://my.oschina.net/u/4090830/blog/10979685</link>
            <author>
                <![CDATA[京東雲開發者]]>
            </author>
        </item>
    </channel>
</rss>
