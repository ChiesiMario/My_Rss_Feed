<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 28 Nov 2023 23:45:58 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[OpenUK：扶持開源將有效遏制人才流向美國]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">英國開源非營利組織 OpenUK&nbsp;最新發布了 「</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenuk.uk%2Fstate-of-open-the-uk-in-2023-phase-three-skills-or-bust%2F" target="_blank">State of Open: The UK in 2023: Phase 3 Skills or Bust</a><span style="background-color:#ffffff">」 報告，此部分內容主要聚焦於英國開源軟件的貢獻者和維護者。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「開源軟件是數字經濟的潛水艇。無論是互聯網、雲計算、人工智能、ML 還是區塊鏈，它都是我們所有技術生態系統的基礎。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff"><img alt="" height="420" src="https://oscimg.oschina.net/oscnet/up-a2e7775cd5fe8e3981df48a726e8410b676.jpg" width="300" referrerpolicy="no-referrer"></span></span></p><p><span style="color:#000000">Skills or Bust 重點分析了英國開源社區的數據，發現英國共有 320 萬個 GitHub 帳戶（佔英國人口的 4.5%）和 31800 個開源項目貢獻者。過去 12 個月裏，開源項目的貢獻者達 8200 人；開源項目新增了 1700 名貢獻者，實現了 20.7% 的增長。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">報告作者明確指出，英國政府有機會支持開源人才，並在英國建立一個更強大的技術部門。遠程工作是開源技術的一種常態，這意味着許多國際公司是根據技能而非地理位置來招聘人才的。隨着英國各地互聯互通的改善，無論是在城市還是農村地區，這都為掌握緊缺技能的人才提供了就業機會。這隻會推動英國科技經濟的增長，並確保其未來成為"下一個硅谷"。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">報告還揭示了 OpenUK 對英國技術和開源技能需求的調查見解：</span></p><ul><li><span style="color:#000000"><strong>77% </strong>的英國公司正在尋求編程技能</span></li><li><span style="color:#000000"><strong>後端開發人員是最受歡迎的職位</strong>（招聘比例為 51%），其次是雲工程師（36%）和開發運維工程師（32%）</span></li><li><span style="color:#000000"><strong>後端開發人員仍然是未來招聘的重點</strong>（28%），另外還有云工程師（23%）和開發運維工程師（16%）</span></li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><img alt="" height="500" src="https://oscimg.oschina.net/oscnet/up-7eec672f4d5ab2c1eec10c4fc10e98ebe5c.jpg" width="500" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">以及確定了支持英國科技行業增長至關重要的三個關鍵政策領域：</span></p><ul><li><span style="color:#000000"><strong>填補英國人才庫商業技能的空白&nbsp;</strong>—— 因收購而留下的空白，目前英國缺乏將其創新商業化所需的商業技能。</span></li><li><span style="color:#000000"><strong>留住經常逃往美國的人才&nbsp;</strong>—— 通過支持這些技能在英國的發展來阻止移民，並鼓勵技術工人移民。</span></li><li><span style="color:#000000"><strong>培訓人員掌握正確的工程和開發技能&nbsp;</strong>—— 英國目前還沒有，而且團隊缺乏實踐經驗。</span></li></ul><p><span style="color:#000000">OpenUK 首席執行官 Amanda Brock 稱，這十年以來，開源軟件的重要性一直被英國政府所忽視。而為此做出貢獻的開源工作者，是全球科技行業中受人尊敬和有影響力的一部分。</span></p><p><span style="color:#000000">「他們中的許多人都是 homeworkers，掌握着緊缺的技能，在這艘'全球潛艇'上工作併成長為領導者，將灣區的薪資帶入英國。現在是時候讓潛艇浮出水面了......」</span></p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenuk.uk%2Fstateofopen" target="_blank"><span style="color:#2980b9">查看完整報告</span></a></strong></p><hr><p><strong><span style="color:#000000">相關閲讀</span></strong></p><ul><li><a href="https://www.oschina.net/news/249841/openuk-report-benefits-of-open-source" target="_blank">英國科技總增值 27% 來自開源，價值達 135.9 億英鎊</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 28 Nov 2023 08:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268523/state-of-open-the-uk-in-2023</guid>
            <link>https://www.oschina.net/news/268523/state-of-open-the-uk-in-2023</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[滴滴昨晚系統服務故障，技術團隊連夜修復]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 28 日凌晨，「滴滴崩了」相關話題登上微博熱搜，多個用戶表示滴滴 App 無法正常使用。對此滴滴緊急迴應稱「由於系統故障，今天晚間滴滴 App 服務出現異常，經技術同學緊急修復，目前正陸續恢復中。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-795f1525cfa56ab2e93c3007ac4f10118a3.png" referrerpolicy="no-referrer"></p><p>從用戶反饋看，11 月 27 日晚間 10 點多起，陸續有用戶反饋無法使用滴滴旗下相關 App，滴滴搶修超過了 9 小時。</p><p>對此，在 11 月 28 日早間，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2838754010%2FNuBQfuzij" target="_blank">滴滴發佈微博更新了恢復情況</a></u>，滴滴稱「經技術團隊連夜修復，滴滴網約車等服務已恢復，用戶可下載滴滴 App 使用打車服務。騎車等服務還在陸續修復中，所有可開鎖或未關鎖的青桔車輛均可免費騎行，希望能為緩解早高峯壓力努力多做一點點。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e973f0017d2a44b92e63ec57b2224d9ef6.png" referrerpolicy="no-referrer"></p><p>雖然滴滴表示網約車服務已恢復，但是不少用戶早間在微博反饋仍然無法打車，只能選擇其他平台出行。</p><p>從司機反饋看，此次滴滴平台在接單、定位、計費等環節上都出現了問題。有網約車司機表示，昨晚 App 崩潰時剛好在接單，「從晚上 10 點 20 分開始什麼都做不了，客服電話也進不了線。目前恢復了少部分功能，但不能正常使用，很多錯單亂單，還出現了多位司機接同一單的現象。」</p><p>有業內人士表示，出問題的應該是滴滴自己的 IDC，這種事故也會加速滴滴全部上雲的步伐。從過往情況看，滴滴崩潰多是因為機房網絡故障等原因，不過故障當天都能修好，本次故障維修時長或是滴滴歷次故障之最。</p><p>目前滴滴由滴滴雲提供服務。滴滴雲官網顯示，滴滴出行的雲計算服務基於滴滴出行的業務技術和經驗積累，採用領先的雲計算架構、高規格服務器集羣搭建、高性能資源配置機制、精細化運營模式，致力於為開發者提供簡單快捷、高效穩定、高性價比、安全可靠的 IT 基礎設施雲服務。</p><p>在今年 2 月，滴滴雲發佈公告，由於產品線調整，滴滴雲在 2023 年 3 月 31 日起將不再對外提供公有云服務。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 28 Nov 2023 04:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268480</guid>
            <link>https://www.oschina.net/news/268480</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華碩發佈龍芯 3A6000 消費級主板]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日上午的&nbsp;2023 龍芯產品發佈暨用戶大會上，華碩宣佈推出支持龍芯 3A6000 處理器的消費級主板 ——<strong>XC-LS3A6M 主板</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-61f3a35d39534e4fb1085f11406b047d65b.png" referrerpolicy="no-referrer"></p><p>華碩電腦開放平台中國區總經理俞元麟在大會現場展示了龍芯 3A6000 的測試成績，在多核定點 / 浮點成績上強於英特爾 i3-10100 處理器。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c6d03bcc64cbfa182ffe0874a92b73a9ad8.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4ba65ea3f7d7737f377147c043f38186a81.png" referrerpolicy="no-referrer"></p><p>此外，<strong>龍芯 3A6000 可以超頻到 2.63GHz，而在液氮下保守可跑到 3GHz（BIOS 限制）</strong>，後續還能繼續提升。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fffb0755e8808aa87c3bb539474c7452802.png" referrerpolicy="no-referrer"></p><hr><p>俞元麟昨晚在其 B 站賬號（@普普通通 Tony 大叔）更新的視頻介紹了龍芯 3A6000 CPU 的性能表現：：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV15u4y1A7aK%2F" target="_blank">《國產最強！龍芯中科 3A6000 台式機 CPU 性能測試》</a></em></u>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2f786c32b8e5bec71a427021176790a2fdb.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-87828dce58a34545dcb0a71096f24938a30.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 28 Nov 2023 02:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268453</guid>
            <link>https://www.oschina.net/news/268453</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國家廣播電視總局發佈三項廣播電視和網絡視聽行業標準]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 27 日，國家廣播電視總局發佈通知，通知表示已組織審查了《有線電視業務技術要求》《IPTV 業務技術要求》《互聯網電視業務技術要求》等三項標準文件，並批准為我國廣播電視和網絡視聽推薦性行業標準。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-03c93c0f85c6c7cb4cd79deda8d4acfa63f.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nrta.gov.cn%2Fart%2F2023%2F11%2F27%2Fart_113_66209.html" target="_blank">https://www.nrta.gov.cn/art/2023/11/27/art_113_66209.html</a></u></em></p></blockquote><p>《有線電視業務技術要求》《IPTV 業務技術要求》中説明，有線電視終端與 IPTV 終端端應提供<strong>「開機進入全屏直播」和「開機進入突出直播頻道的交互主頁」</strong>兩種「開機模式」選項，<strong>系統默認設置應為「開機進入全屏直播」</strong>。</p><p>選擇進入交互主頁開機模式的，開機後默認焦點應停留在直播窗口，且如果用戶在 20s 內無操作，應自動進入全屏直播；包括開機廣告等特定內容在內的冷啓動開機時間應不大於 35s，且宜具備待機快速喚醒功能；遙控器應具備快捷看直播頻道的「看電視」按鍵。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-979f3921987d751af13a1ef1f85b0df4424.png" referrerpolicy="no-referrer"></p><p>《互聯網電視業務技術要求》中説明，互聯網電視應用<strong>啓動時間宜小於 3s</strong>，<strong>應不大於 5s</strong>，應用的啓動廣告時間應包含在互聯網電視應用啓動時間內，如展現了廣告，啓動時間仍應符合該要求。</p><p>交互主頁應設置顯著、便捷的免費業務專區入口，從交互主頁默認焦點至免費業務專區入口的操作次數不宜超過 3 次；交互主頁不應設置彈窗廣告；業務的訂購或退訂等相關操作，均應在用戶界面上提供明確的提示説明和流程操作説明，且應提供確認付費或取消付費的明確操作步驟，<strong>不應設置「一鍵付費」相關操作</strong>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 28 Nov 2023 02:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268448</guid>
            <link>https://www.oschina.net/news/268448</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[山東女子學院 openKylin 高校站正式揭牌成立]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">11 月 23 日下午，</span><strong><span style="color:#000000">山東女子學院 openKylin 高校站成立揭牌儀式</span></strong><span style="color:#000000">在山東女子學院圖書館一樓報告廳順利舉行。</span></span></p><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:center"><img alt="" height="1852" src="https://oscimg.oschina.net/oscnet/up-19707e46ea14cdaeefc8d32907ba96786fe.png" width="4032" referrerpolicy="no-referrer"></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">山東女子學院副校長李纓，數據科學與計算機學院院長孫洪峯、副院長田傑、季振東、院長助理劉麗，麒麟軟件山東事業部總經理李雲龍、校企合作總監蘇勝男，openKylin 社區技術委員會委員王文竹、生態合作負責人馬發俊以及</span><strong><span style="color:#000000">200</span></strong><span style="color:#000000">多位山東女子學院數科院教師代表和學生等出席活動。</span><strong><span style="color:#000000">山東女子學院數據科學與計算機學院院長孫洪峯主持揭牌儀式，山東女子學院副校長李纓和麒麟軟件山東事業部總經理李雲龍共同為山東女子學院 openKylin 高校站揭牌。</span></strong></span></p><div><p style="text-align:center"><img alt="" height="810" src="https://oscimg.oschina.net/oscnet/up-b65aca3254c1e869b891fe4f4559367648a.png" width="1080" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#000000">山東女子學院副校長李纓</span></strong><span style="color:#000000">為儀式致辭，對山東女子學院正式成為 openKylin 高校站的一員表示祝賀，並表示 openKylin 高校站為高校大力發展信息學科、培養高水平開源創新人才提供了寶貴平台。希望在雙方的共同努力下，能建設與發展好 openKylin 高校站，為我國開源創新體系建設以及國家信息技術發展貢獻更大的力量。</span></span></p><div>
 &nbsp;
</div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#000000">openKylin 社區生態合作負責人馬發俊</span></strong><span style="color:#000000">以《中國桌面操作系統根社區建設介紹》為題，向在座師生介紹了 openKylin 社區的整體情況和開源建設成果，並着重介紹了 openKylin 社區與高校合作開展情況、社區高校站的建立和運營模式，openKylin 建立了高校專區，通過高校站與高校建立緊密合作關係，通過技術融合、教學創新、開源實踐等多維度促進高校和開源人才培養。</span></span></p><div><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#000000">openKylin 社區技術委員會委員王文竹</span></strong><span style="color:#000000">帶來《走進開源的世界》主題演講，從開源的意義、如何參與開源、以及自身開源經歷等方面進行分享，讓同學們對開源參與有了更深入的瞭解。同時，在分享的最後，還為大家介紹了多個 openKyin 社區開源大賽，鼓勵感興趣的同學積極參與，開闊眼界的同時取得快速成長。</span></span></p><div>
 &nbsp;
</div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">在活動開展過程中，山東女子學院的同學們踴躍提問，對參與 openKylin 高校站開源貢獻表現出了極大的熱情和積極性。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#000000">openKylin 高校站</span></strong><span style="color:#000000">是 openKylin 社區在高校建立的合作站點，通過推進高校開源技術的產學研融合，構建起學生 Linux 的基礎知識架構，再通過開源活動+項目實踐的方式，為學生積累實踐經驗，並對職業規劃等方面進行詳細講解，通過理論+實踐的形式，培養卓越創新能力的開源人才。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">截至目前，已有上海交通大學、天津大學、南京大學、新疆大學、山東女子學院、內蒙古大學、洛陽理工學院、深圳職業大學等</span><strong><span style="color:#000000">33</span></strong><span style="color:#000000">所 985、雙一流、普通本科和頭部職業院校加入 openKylin 社區並建立高校站，與社區開展了多種形式的合作。</span></span></p><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:left"><span><span style="color:#000000">未來，openKylin 歡迎更多高校合作伙伴加入，一起建立產學研融合的開源創新人才培養體系，為實現國內開源事業可持續發展蓄勢儲能。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 28 Nov 2023 01:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268436</guid>
            <link>https://www.oschina.net/news/268436</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[浪潮發佈基礎大模型「源 2.0」，千億參數全面開源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>浪潮信息<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrjnsUS83TT7aEN3r2i0IPQ" target="_blank">發佈</a></u>「源 2.0」基礎大模型，並宣佈全面開源</strong>。</p><p>據介紹，源 2.0 基礎大模型包括 1026 億、518 億、21 億等三種參數規模的模型，在編程、推理、邏輯等方面展示出了先進的能力。</p><p><strong>算法方面</strong>，源 2.0 提出並採用了一種新型的注意力算法結構：局部注意力過濾增強機制 (LFA：Localized Filtering-based Attention)。LFA 通過先學習相鄰詞之間的關聯性，然後再計算全局關聯性的方法，能夠更好地學習到自然語言的局部和全局的語言特徵，對於自然語言的關聯語義理解更準確、更人性，提升了模型的自然語言表達能力，進而提升了模型精度。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184848_muAm_2720166.png" referrerpolicy="no-referrer"></p><p><strong>數據方面</strong>，源 2.0 通過使用中英文書籍、百科、論文等高質量中英文資料，降低了互聯網語料內容佔比，結合高效的數據清洗流程，為大模型訓練提供了高質量的專業數據集和邏輯推理數據集。</p><p>據稱，為了更高效地獲得相對匱乏的高質量中文數學及代碼數據集，源 2.0 採用了基於大模型的數據生產及過濾方法，在保證數據的多樣性的同時也在每一個類別上提升數據質量，獲取了一批高質量的數學與代碼預訓練數據。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184918_iLAq_2720166.png" referrerpolicy="no-referrer"></p><p><strong>算力方面</strong>，源 2.0 採用了非均勻流水並行的方法，綜合運用流水線並行+優化器參數並行+數據並行的策略，讓模型在流水並行各階段的顯存佔用量分佈更均衡，避免出現顯存瓶頸導致的訓練效率降低的問題，該方法顯著降低了大模型對芯片間 P2P 帶寬的需求，為硬件差異較大訓練環境提供了一種高性能的訓練方法。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184932_0UiQ_2720166.png" referrerpolicy="no-referrer"></p><p>源 2.0 在業界公開的評測上進行了代碼生成、數學問題求解、事實問答方面的能力測試，下面是測試結果：</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184945_PzyP_2720166.png" referrerpolicy="no-referrer"></p><p><strong>源 2.0 採用全面開源策略，全系列模型參數和代碼均可免費下載使用</strong>。</p><ul><li>代碼開源鏈接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0</a></em></u></li><li>論文鏈接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0%2Fblob%2Fmain%2Fdocs%2FYuan2.0_paper.pdf" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/Yuan2.0_paper.pdf</a></em></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268384</guid>
            <link>https://www.oschina.net/news/268384</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Furion 文檔收費？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今天訪問 Furion 官網發現它的文檔居然要付費才能看：</p><p><img height="1392" src="https://static.oschina.net/uploads/space/2023/1128/173151_D1kJ_2720166.png" width="2338" referrerpolicy="no-referrer"></p><p>http://furion.baiqian.ltd/docs/saas</p><p>而且還搞了個 499 的 VIP 技術支持服務……</p><p><img height="1858" src="https://static.oschina.net/uploads/space/2023/1128/173121_ZrVP_2720166.png" width="3360" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 09:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268540</guid>
            <link>https://www.oschina.net/news/268540</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Qt 6.6.1 修復了 400 多個 bug]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Qt 6.6&nbsp;於上個月<u><a href="https://www.oschina.net/news/261263/qt-6-6-released">正式發佈</a></u>，引入了 Qt Graphs、更強大的 Wayland 支持、各種渲染增強功能等等。</p><blockquote><p>Qt 是一個跨平台的應用程序開發框架，廣泛用於創建圖形用戶界面、嵌入式系統和移動應用等。Qt 6 是 Qt 的最新版本，於 2022 年 12 月發佈，帶來了許多新特性和改進，如更強大的 QML 語言、更靈活的圖形架構和更高效的內存管理等。</p></blockquote><p>時隔一個多月，該系列發佈了首個維護性更新<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qt.io%2Fblog%2Fqt-6.6.1-released" target="_blank"> Qt 6.6.1</a></u>，修復了 400 多個 bug，沒有添加任何新特性。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-f4640361d42bd8e0d7b9d0f090d7a2f4fd5.png" referrerpolicy="no-referrer"></p></blockquote><p>按照發布計劃，Qt 6.6.2 預計將於 1 月份發佈。對於 Qt 長期支持版用戶，從上個月起，Qt 6.5 已轉向其<u><a href="https://www.oschina.net/news/262391/qt-6-5-lts-commercial-only">僅面向商業客戶提供的 LTS 階段</a></u>。</p><p>對於下一個功能版本，Qt 6.7 將於 3 月底左右發佈。 Qt 6.7 的平台和模塊凍結於幾天前開始，功能凍結將於下週進行，Qt 6.7 Beta 1 將於 12 月中旬發佈。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 06:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268504/qt-6-6-1-released</guid>
            <link>https://www.oschina.net/news/268504/qt-6-6-1-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大語言模型的前世今生]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自華為雲社區《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F416109%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">大語言模型的前世今生</a>》，作者： 碼上開花_Lancer 。</p><p><strong>大規模語言模型（Large Language Models，LLM）</strong>，也稱大規模語言模型或大型語言模型，是一種由包含數百億以上參數的深度神經網絡構建的語言模型，使用自監督學習方法通過大量無標註文本進行訓練。自 2018 年以來，Google、OpenAI、Meta、百度、華為等公司和研究機構都相繼發佈了包括 BERT，GPT 等在內多種模型，並在幾乎所有自然語言處理任務中都表現出色。2019 年大模型呈現爆發式的增長，特別是 2022 年 11 月 ChatGPT（Chat Generative Pre-trained Transformer）發佈後，更是引起了全世界的廣泛關注。用戶可以使用自然語言與系統交互，從而實現包括問答、分類、摘要、翻譯、聊天等從理解到生成的各種任務。大型語言模型展現出了強大的對世界知識掌握和對語言的理解。</p><span id="OSC_h1_1"></span><h1>一、大規模語言模型基本概念</h1><p>語言是人類與其他動物最重要的區別，而人類的多種智能也與此密切相關。邏輯思維以語言的形式表達，大量的知識也以文字的形式記錄和傳播。如今，互聯網上已經擁有數萬億以上的網頁資源，其中大部分信息都是以自然語言描述。因此，如果人工智能算法想要獲取知識，就必須懂得如何理解人類使用的不太精確、可能有歧義、混亂的語言。語言模型（Language Model，LM）目標就是建模自然語言的概率分佈。詞彙表 V 上的語言模型，由函數 P(w1w2...wm) 表示，可以形式化地構建為詞序列 w1w2...wm 的概率分佈，表示詞序列 w1w2...wm 作為一個句子出現的可能性大小。由於聯合概率 P(w1w2...wm) 的參數量十分巨大，直接計算 P(w1w2...wm) 非常困難。按照《現代漢語詞典（第七版）》包含 7 萬單詞，句子長度按照 20 個詞計算，模型參數量達到 7.9792×1096 的天文數字。中文的書面語中超過 100 個單詞的句子也並不罕見，如果要將所有可能都納入考慮，模型的複雜度還會進一步急劇增加，無法進行存儲和計算。為了減少 P(w1w2...wm) 模型的參數空間，可以利用句子序列通常情況下從左至右的生成過程進行分解，使用鏈式法則得到：</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700874836405431196.png" referrerpolicy="no-referrer"></p><p>由此，w1w2...wm 的生成過程可以看作單詞逐個生成的過程。首先生成 w1，之後根據 w1 生成 w2，再根據 w1 和 w2 生成 w3，以此類推，根據前 m− 1 個單詞生成最後一個單詞 wm。例如：對於句子「把努力變成一種習慣」的概率計算，使用上述公式可以轉化為：</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700874878791508245.png" referrerpolicy="no-referrer"></p><p>通過上述過程將聯合概率 P(w1w2...wm) 轉換為了多個條件概率的乘積。但是，僅通過上述過程模型的參數空間依然沒有下降，P(wm|w1w2...wm.1) 的參數空間依然是天文數字。為瞭解決上述問題，可以進一步假設任意單詞 wi 出現的概率只與過去 n − 1 個詞相關，即：</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700874915077390823.png" referrerpolicy="no-referrer"></p><p>滿足上述條件的模型被稱為 n 元語法或 n 元文法 (n-gram) 模型。其中 n-gram 表示由 n 個連續單詞構成的單元，也被稱為 n 元語法單元。儘管 n 元語言模型能緩解句子概率為 0 的問題，但語言是由人和時代創造的，具備無窮的可<br> 能性，再龐大的訓練語料也無法覆蓋所有的 n-gram，而訓練語料中的零頻率並不代表零概率。因此，需要使用平滑技術（Smoothing）來解決這一問題，對所有可能出現的字符串都分配一個非零的概率值，從而避免零概率問題。平滑是指為了產生更合理的概率，對最大似然估計進行調整的一類方法，也稱為數據平滑（Data Smoothing）。平滑處理的基本思想是提高低概率，降低高概率，使整體的概率分佈趨於均勻。這類方法通常稱為統計語言模型（Statistical Language models，SLM）。n 語法模型整體上來看與訓練語料規模和模型的階數有較大的關係，不同的平滑算法在不同情況下的表現有較大的差距。平滑算法雖然較好的解決了零概率問題，但是基於稀疏表示的 n 元語言模型仍然有三個較為明顯的缺點：（1）無法建模長度超過 n 的上下文；（2）依賴人工設計規則的平滑技術；（3）當 n 增大時，數據的稀疏性隨之增大，模型的參數量更是指數級增加，並且模型受到數據稀疏問題的影響，其參數難以被準確的學習。此外，n 語法中單詞的離散表示也忽略了詞之間的相似性。</p><p>因此，基於分佈式表示和神經網絡的語言模型逐漸成為了研究熱點。Bengio 等人在 2000 年提出了使用前饋神經網絡對 P(wi|wi−n+1...wi−1) 進行估計的語言模型。詞的獨熱編碼被映射為一個低維稠密的實數向量，稱為詞向量（Word Embedding）。此後，循環神經網絡、卷積神經網絡、端到端記憶網絡等神經網絡方法都成功應用於語言模型建模。相較於 n 元語言模型，神經網絡方法可以在一定程度上避免數據稀疏問題，有些模型還可以避免對歷史長度的限制，從而更好的建模長距離依賴關係。這類方法通常稱為神經語言模型（Neural Language Models，NLM）。深度神經網絡需要採用有監督方法，使用標註數據進行訓練，因此，語言模型的訓練過程也不可避免需要構造訓練語料。但是由於訓練目標可以通過無標註文本直接獲得，從而使得模型的訓練僅需要大規模無標註文本即可語言模型也成為了典型的自監督學習（Self-supervised Learning）任務。互聯網的發展，使得大規模文本非常容易獲取，因此訓練超大規模的基於神經網絡的語言模型也成為了可能。受到計算機視覺領域採用 ImageNet 對模型進行一次預訓練，使得模型可以通過海量圖像充分學習如何提取特徵，然後再根據任務目標進行模型精調的範式影響，自然語言處理領域基於預訓練語言模型的方法也逐漸成為主流。以 ELMo 為代表的動態詞向量模型開啓了語言模型預訓練的大門，此後以 GPT 和 BERT 為代表的基於 Transformer 模型的大規模預訓練語言模型的出現，使得自然語言處理全面進入了預訓練微調範式新時代。將預訓練模型應用於下游任務時，不需要了解太多的任務細節，不需要設計特定的神經網絡結構，只需要「微調」預訓練模型，即使用具體任務的標註數據在預訓練語言模型上進行監督訓練，就可以取得顯著的性能提升。這類方法通常稱為預訓練語言模型（Pre-trained Language Models，PLM）。2020 年 Open AI 發佈了包含 1750 億參數的生成式大規模預訓練語言模型 GPT-3（GenerativePre-trained Transformer 3）。開啓了大規模語言模型的時代。由於大規模語言模型的參數量巨大，如果在不同任務上都進行微調需要消耗大量的計算資源，因此預訓練微調範式不再適用於大規模語言模型。但是研究人員發現，通過語境學習（Incontext Learning，ICL）等方法，直接使用大規模語言模型就可以在很多任務的少樣本場景下取得了很好的效果。此後，研究人員們提出了面向大規模語言模型的提示詞（Prompt）學習方法、模型即服務範式（Model as a Service，MaaS）、指令微調（Instruction Tuning）等方法，在不同任務上都取得了很好的效果。與此同時，Google、Meta、百度、華為等公司和研究機構都紛紛發佈了包括 PaLM、LaMDA、T0 等為代表的不同大型語言模型。</p><p>2022 年底 ChatGPT 的出現，將大規模語言模型的能力進行了充分的展現，也引發了大規模語言模型研究的熱潮。Kaplan 等人在文獻中提出了縮放法則（Scaling Laws），指出模型的性能依賴於模型的規模，包括：參數數量、數據集大小和計算量，模型的效果會隨着三者的指數增加而線性提高。如圖 1.1 所示，模型的損失（Loss）值隨着模型規模的指數增大而線性降低。這意味着模型的能力是可以根據這三個變量估計的，提高模型參數量，擴大數據集規模都可以使得模型的性能可預測地提高。這為繼續提升大模型的規模給出了定量分析依據。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700875112804923222.png" referrerpolicy="no-referrer"></p><p>圖 1.1 大規模語言模型的縮放法則（Scaling Laws）</p><span id="OSC_h1_2"></span><h1>二、大規模語言模型發展歷程</h1><p>大規模語言模型的發展歷程雖然只有短短不到五年的時間，但是發展速度相當驚人，截止 2023 年 6 月，國內外有超過百種大模型相繼發佈。中國人民大學趙鑫教授團隊在文獻按照時間線給出 2019 年至 2023 年 5 月比較有影響力並且模型參數量超過 100 億的大規模語言模型，如圖 2.1 所示。大規模語言模型的發展可以粗略的分為如下三個階段：基礎模型、能力探索、突破發展。</p><p><strong>基礎模型階段</strong>主要集中於 2018 年至 2021 年，2017 年 Vaswani 等人提出了 Transformer[ 架構，在機器翻譯任務上取得了突破性進展。2018 年 Google 和 Open AI 分別提出了 BERT[1] 和 GPT-1 模型，開啓了預訓練語言模型時代。BERT-Base 版本參數量為 1.1 億，BERT-Large 的參數量為 3.4 億，GPT-1 的參數量 1.17 億。這在當時，相比其它深度神經網絡的參數量已經是有數量級上提升。2019 年 Open AI 又發佈了 GPT-2，其參數量達到了 15 億。此後，Google 也發佈了參數規模為 110 億的 T5 模型。2020 年 Open AI 進一步將語言模型參數量擴展到 1750 億，發佈了 GPT-3。此後，國內也相繼推出了一系列的大規模語言模型，包括清華大學<a href="https://www.oschina.net/action/visit/ad?id=1191">ERNIE</a>(THU)、百度<a href="https://www.oschina.net/action/visit/ad?id=1191">ERNIE</a>(Baidu)、華為盤古-α 等。這個階段研究主要集中語言模型本身，包括僅編碼器（Encoder Only）、編碼器-解碼器（Encoder-Decoder）、僅解碼器（Decoder Only）等各種類型的模型結構都有相應的研究。模型大小與 BERT 相類似的算法，通常採用預訓練微調範式，針對不同下游任務進行微調。但是模型參數量在 10 億以上時，由於微調的計算量很高，這類模型的影響力在當時相較 BERT 類模型有不小的差距。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819499486261627.png" referrerpolicy="no-referrer"></p><p>圖 2.1 大規模語言模型發展時間線</p><p><strong>能力探索階段</strong>集中於 2019 年至 2022 年，由於大規模語言模型很難針對特定任務進行微調，研究人員們開始探索在不針對單一任務進行微調的情況下如何能夠發揮大規模語言模型的能力。2019 年 Radford 等人，就使用 GPT-2 模型研究了大規模語言模型在零樣本情況下的任務處理能力。在此基礎上，Brown 等人在 GPT-3 模型上研究了通過語境學習（In-Context Learning）進行少樣本學習的方法。將不同任務的少量有標註的實例拼接到待分析的樣本之前輸入語言模型，用語言模型根據實例理解任務並給出正確結果。在包括 TriviaQA、WebQS、CoQA 等評測集合都展示出了非常強的能力，在有些任務中甚至超過了此前的有監督方法。上述方法不需要修改語言模型的參數，模型在處理不同任務時無需花費的大量計算資源進行模型微調。但是僅依賴基於語言模型本身，其性能在很多任務上仍然很難達到有監督學習效果，因此研究人員們提出了指令微調（Instruction Tuning）方案，將大量各類型任務，統一為生成式自然語言理解框架，並構造訓練語料進行微調。</p><p><strong>突破發展階段</strong>以 2022 年 11 月 ChatGPT 的發佈為起點。ChatGPT 通過一個簡單的對話框，利用一個大規模語言模型就可以實現問題回答、文稿撰寫、代碼生成、數學解題等過去自然語言處理系統需要大量小模型訂製開發才能分別實現的能力。它在開放領域問答、各類自然語言生成式任務以及對話上文理解上所展現出來的能力遠超大多數人的想象。2023 年 3 月 GPT-4 發佈，相較於 ChatGPT 又有了非常明顯的進步，並具備了多模態理解能力。GPT-4 在多種基準考試測試上的得分高於 88% 的應試者，包括美國律師資格考試（Uniform Bar Exam）、法學院入學考試（Law School Admission Test）、學術能力評估（Scholastic Assessment Test，SAT）等。它展現了近乎「通用人工智能（AGI）」的能力。各大公司和研究機構也相繼發佈了此類系統，包括 Google 推出的 Bard、百度的文心一言、科大訊飛的星火大模型、智譜 ChatGLM、復旦大學 MOSS 等。表 1.1 給出了截止 2023 年 6 月典型開源和未開源大規模語言模型的基本情況。可以看到從 2022 年開始大模型呈現爆發式的增長，各大公司和研究機構都在發佈各種不同類型的大模型。</p><span id="OSC_h1_3"></span><h1>三、 大規模語言模型構建流程</h1><p>根據 OpenAI 聯合創始人 Andrej Karpathy 在微軟 Build 2023 大會上所公開的信息，OpenAI 所使用的大規模語言模型構建流程如圖 2.2 所示。主要包含四個階段：預訓練、有監督微調、獎勵建模、強化學習。這四個階段都需要不同規模數據集合、不同類型的算法，產出不同類型的模型，所需要的資源也有非常大的差別。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819526965391967.png" referrerpolicy="no-referrer"></p><p>圖 2.2 OpenAI 使用的大規模語言模型構建流程</p><p><strong>預訓練</strong><strong>（</strong><strong>Pretraining</strong><strong>）階段</strong>需要利用海量的訓練數據，包括互聯網網頁、維基百科、書籍、GitHub、論文、問答網站等，構建包含數千億甚至數萬億單詞的具有多樣性的內容。利用由數千塊高性能 GPU 和高速網絡組成超級計算機，花費數十天完成深度神經網絡參數訓練，構建基礎語言模型（Base Model）。基礎大模型構建了長文本的建模能力，使得模型具有語言生成能力，根據輸入的提示詞（Prompt），模型可以生成文本補全句子。也有部分研究人員認為，語言模型建模過程中也隱含的構建了包括事實性知識（Factual Knowledge）和常識知識（Commonsense）在內的世界知識（World Knowledge）。根據他們的文獻介紹，GPT-3 完成一次訓練的總計算量是 3640PFlops，按照 NVIDIA A100 80G 和平均利用率達到 50% 計算，需要花費近一個月時間使用 1000 塊 GPU 完成。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819546103132882.png" referrerpolicy="no-referrer"></p><p>表 1.1 典型開源大規模語言模型彙總</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819565269758033.png" referrerpolicy="no-referrer"></p><p>表 1.2 典型閉源大規模語言模型彙總</p><p><strong>有監督微調</strong>（Supervised Finetuning），也稱為指令微調（Instruction Tuning），利用少量高質量數據集合，包含用戶輸入的提示詞（Prompt）和對應的理想輸出結果。用戶輸入包括問題、閒聊對話、任務指令等多種形式和任務。</p><p><strong>例如</strong>：提示詞（Prompt）：復旦大學有幾個校區？</p><p>理想輸出：復旦大學現有 4 個校區，分別是邯鄲校區、新江灣校區、楓林校區和張江校區。其中邯鄲校區是復旦大學的主校區，邯鄲校區與新江灣校區都位於楊浦區，楓林校區位於徐彙區，張江校區位於浦東新區。</p><p>利用這些有監督數據，使用與預訓練階段相同的語言模型訓練算法，在基礎語言模型基礎上再進行訓練，從而得到有監督微調模型（SFT 模型）。經過訓練的 SFT 模型具備了初步的指令理解能力和上下文理解能力，能夠完成開放領域問題、閲讀理解、翻譯、生成代碼等能力，也具備了一定的對未知任務的泛化能力。由於有監督微調階段的所需的訓練語料數量較少，SFT 模型的訓練過程並不需要消耗非常大量的計算。根據模型的大小和訓練數據量，通常需要數十塊 GPU，花費數天時間完成訓練。SFT 模型具備了初步的任務完成能力，可以開放給用戶使用，很多類 ChatGPT 的模型都屬於該類型，包括：Alpaca、Vicuna、MOSS、ChatGLM-6B 等。很多這類模型效果也非常好，甚至在一些評測中達到了 ChatGPT 的 90% 的效果。當前的一些研究表明有監督微調階段數據選擇對 SFT 模型效果有非常大的影響，因此如何構造少量並且高質量的訓練數據是本階段有監督微調階段的研究重點。</p><p>目標是構建一個文本質量對比模型，對於同一個提示詞，SFT 模型給出的多個不同輸出結果的質量進行排序。獎勵模型（RM 模型）可以通過二分類模型，對輸入的兩個結果之間的優劣進行判斷。RM 模型與基礎語言模型和 SFT 模型不同，RM 模型本身並不能單獨提供給用戶使用。獎勵模型的訓練通常和 SFT 模型一樣，使用數十塊 GPU，通過幾天時間完成訓練。由於 RM 模型的準確率對於強化學習階段的效果有着至關重要的影響，因此對於該模型的訓練通常需要大規模的訓練數據。Andrej Karpathy 在報告中指出，該部分需要百萬量級的對比數據標註，而且其中很多標註需要花費非常長的時間才能完成。圖 2.3 給出了 InstructGPT 系統中獎勵模型訓練樣本標註示例。可以看到，示例中文本表達都較為流暢，標註其質量排序需要制定非常詳細的規範，標註人員也需要非常認真的對標規範內容進行標註，需要消耗大量的人力，同時如何保持眾包標註人員之間的一致性，也是獎勵建模階段需要解決的難點問題之一。此外獎勵模型的泛化能力邊界也在本階段需要重點研究的另一個問題。如果 RM 模型的目標是針對所有提示詞系統所生成輸出都能夠高質量的進行判斷，該問題所面臨的難度在某種程度上與文本生成等價，因此如何限定 RM 模型應用的泛化邊界也是本階段難點問題。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819609846149973.png" referrerpolicy="no-referrer"></p><p>圖 2.3 InstructGPT 系統中獎勵模型訓練樣本標註示例</p><p><strong>強化學習</strong><strong>（</strong><strong>Reinforcement Learning</strong><strong>）階段</strong>根據數十萬用戶給出的提示詞，利用在前一階段訓練的 RM 模型，給出 SFT 模型對用戶提示詞補全結果的質量評估，並與語言模型建模目標綜合得到更好的效果。該階段所使用的提示詞數量與有監督微調階段類似，數量在十萬量級，並且不需要人工提前給出該提示詞所對應的理想回復。使用強化學習，在 SFT 模型基礎上調整參數，使得最終生成的文本可以獲得更高的獎勵（Reward）。該階段所需要的計算量相較預訓練階段也少很多，通常也僅需要數十塊 GPU，經過數天時間的即可完成訓練。文獻[給出了強化學習和有監督微調的對比，在模型參數量相同的情況下，強化學習可以得到相較於有監督微調好得多的效果。關於為什麼強化學習相比有監督微調可以得到更好結果的問題，截止到 2023 年 9 月也還沒有完整和得到普遍共識的解釋。此外，Andrej Karpathy 也指出強化學習也並不是沒有問題的，它會使得基礎模型的熵降低，從而減少了模型輸出的多樣性。在經過強化學習方法訓練完成後的 RL 模型，就是最終提供給用戶使用具有理解用戶指令和上下文的類 ChatGPT 系統。由於強化學習方法穩定性不高，並且超參數眾多，使得模型收斂難度大，再疊加 RM 模型的準確率問題，使得在大規模語言模型如何能夠有效應用強化學習非常困難。</p><p>大語言模型研究進展之快，讓在自然語言處理領域開展了近三十年工作的我們也難以適從。其研究之火爆程度令人咋舌，自然語言處理領域重要國際會議 EMNLP，2022 年語言模型相關論文投稿佔比只有不到 5%。然而，2023 年語言模型相關投稿則超過了 EMNLP 整體投稿的 20%。如何能夠兼顧大語言模型的基礎理論，又能夠在快速發展的各種研究中選擇最具有代表性的工作介紹給大家，是寫作中面臨的最大挑戰之一，受限於我們的認知水平和所從事的研究工作的侷限，對其中一些任務和工作的細節理解可能存在不少錯誤，也懇請專家、讀者批評指正！</p><p>&nbsp;</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>點擊關注，第一時間瞭解華為雲新鮮技術~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 05:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10278002</guid>
            <link>https://my.oschina.net/u/4526289/blog/10278002</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龍芯宣佈兼容 IE 的龍芯瀏覽器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">在今日上午舉辦的 2023 龍芯產品發佈暨用戶大會上，龍芯中科介紹了龍芯平台當前的生態發展，稱其已可運行絕大多數 X86 / Linux 應用，並爭取 1-2 年後流暢運行絕大多數 X86 / Windows 應用。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a41459afcde42a92f9ad416d6fca4d8f732.png" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start">龍芯平台已支持多個國產操作系統和基礎應用，後續將通過二進制翻譯運行 X86 應用，兼容 Windows 和安卓應用。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-86b36d9e89683e59c00caa945cf2aab9fef.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9c91a07b40ce827b5d10883b6fe1138abc2.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-55e8d68de37d96583e2acb6ba8d53dba16b.png" referrerpolicy="no-referrer"></p><p>大會上，龍芯中科宣佈了與 IE 瀏覽器兼容的<strong>「龍芯瀏覽器」</strong>。從官方公開的 PPT 可以看到，龍芯瀏覽器之所以在 2023 年還兼容 IE，是因為我國信息系統主要基於 IE 構建。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-b7fb745bc3039ea3eb00357a2cc36dd5d5d.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 04:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268477</guid>
            <link>https://www.oschina.net/news/268477</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Reddit 再次試水 IPO]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">彭博社</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-27%2Freddit-leads-class-of-2024-us-ipo-candidates-testing-the-water%3Fsref%3Dgni836kR" target="_blank"><span style="color:#2980b9">報道</span></a><span style="color:#000000">稱，Reddit「正在與潛在投資者就首次公開募股進行談判。」&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Reddit 總部位於舊金山，由&nbsp;Steve Huffman&nbsp;、Aaron Swartz 和 Alexis Ohanian 於 2005 年聯合創立。消息人士透露，該公司正在考慮最早在明年第一季度上市。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><img height="331" src="https://oscimg.oschina.net/oscnet/up-2b1b4904c5ce1731bc1a4743a3619d6d07d.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">2021 年 12 月，Reddit 祕密向美國證券交易委員會提交了一份上市註冊聲明草案，但相關計劃並未成功實現。此舉發生在 Reddit 獲得由富達（Fidelity）領投的 4.1 億美元鉅額融資、估值達到 100 億美元的幾個月之後。當時，Reddit 計劃以 7 億美元完成 F 輪融資。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">然後，在 2022 年 1 月，Reddit 甚至邀請摩根士丹利和高盛參與上市工作。當時，該公司考慮的估值高達 150 億美元。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">目前尚不清楚如果該公司真的上市，明年的估值將會達到多少。Reddit 發言人向外媒 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F11%2F27%2Freddit-might-once-again-be-flirting-with-an-ipo%2F" target="_blank">TechCrunch</a> 表示，該公司正處於靜默期，無法發表評論。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268471/reddit-might-once-again-flirting-ipo</guid>
            <link>https://www.oschina.net/news/268471/reddit-might-once-again-flirting-ipo</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龍芯 3A6000 桌面處理器正式發佈，國產之光！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日上午舉辦的&nbsp;2023 龍芯產品發佈暨用戶大會上，龍芯 3A6000 國產桌面通用處理器正式發佈。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e6662d2058f428348499738edb731d2f88.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2bf0856cd3fa1f2a6bae9ce059cc87ace7f.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-064f9db667224d22c42556b43acac5bafe7.png" referrerpolicy="no-referrer"></p><blockquote><p>此處引用一下<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWgrMt3RO7w0a1kNyydptog" target="_blank">央視新聞的報道原文</a></u></em>：<br><br><strong>龍芯 3A6000 採用我國自主設計的指令系統和架構，無需依賴任何國外授權技術，是我國自主研發、自主可控的新一代通用處理器，可運行多種類的跨平台應用，滿足各類大型複雜桌面應用場景。</strong></p><p><strong>它的推出，標誌着我國自主研發的 CPU 在自主可控程度和產品性能方面達到新高度，性能達到國際主流產品水平。</strong></p></blockquote><p>據介紹，<strong>龍芯 3A6000 </strong>擁有四個物理核 / 八個邏輯核，主頻 2.0-2.5GHz，<strong>採用第四代 64 位微架構 LA664，實現 SMT2 技術</strong>，支持雙通道 DDR4-3200 內存，片內集成安全可信模塊，支持安全啓動和國密算法（SM2、SM3、SM4）等。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f13f4b4df7a318d97e95b08500fbdf966c5.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b28daeabb9b929cefa3541d62533899f8cd.png" referrerpolicy="no-referrer"></p><p>龍芯 3A6000 突破了同時多線程 (SMT, Simultaneous Multi-Threading) 技術，支持 CPU 核心在同一時刻運行多個線程，<strong>相比上一代龍芯 3A5000 的單線程性能提升 60%，多線程性能提升 100%</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-59bdeef2ea7f1bf45930f2862938198ffc6.png" referrerpolicy="no-referrer"></p><p>根據龍芯官方實測，<strong>2.5GHz 龍芯 3A6000 性能可達英特爾 10 代酷睿 3.6GHz&nbsp;i3-10100 的水平</strong>，下一步爭取使用成熟工藝達到英特爾、AMD 先進工藝 CPU 的性能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f0c409ce43a2e7c78d093de804acbc7ce2f.png" referrerpolicy="no-referrer"></p><p>此外，<strong>龍芯後續將推 3B6000、3B7000 等桌面端產品</strong>，而在服務端已完成龍芯 3C6000 設計，筆記本端已完成 2K3000 前端設計。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-202643b33452a1f49b4f60821a77e9010eb.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e19da8aac185fc7beffd93031306d623c92.png" referrerpolicy="no-referrer"></p><hr><p>華碩電腦開放平台中國區總經理俞元麟昨晚在其 B 站賬號（@普普通通 Tony 大叔）更新的視頻介紹了龍芯 3A6000 CPU 的性能表現：：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV15u4y1A7aK%2F">《國產最強！龍芯中科 3A6000 台式機 CPU 性能測試》</a></em></u>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2f786c32b8e5bec71a427021176790a2fdb.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268459/loongson-3a6000</guid>
            <link>https://www.oschina.net/news/268459/loongson-3a6000</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mitosis —— 前端編譯時框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Mitosis 是一個編譯時框架，可以讓開發者使用 JSX 編寫組件，並將其編譯為原生 JavaScript、Angular、React、Vue 等多種框架的代碼。</p><p>Mitosis 使用了受 Solid 啓發的靜態 JSX 子集，可以將其解析為簡單的 JSON 結構，然後輕鬆構建針對不同框架和實現的序列化器。</p><p>與其他編譯時框架相比，Mitosis 類似於 Svelte 和 SolidJS，它們都是編譯時框架，非常快速。但與它們的不同之處在於，Mitosis 允許你生成多個框架的代碼，從而提供了最大的靈活性。</p><p>與 SolidJS 類似，Mitosis 使用一種將組件編譯為 JSON 的 JSX 版本。插件可以將組件編譯為不同的目標，使你可以創建雙向工具：</p><ol><li>可以轉換為 Mitosis JSON 的代碼</li><li>將 JSON 編譯或序列化為目標框架的插件</li></ol><p>Mitosis 得到了 <a href="http://builder.io/">Builder.io</a> 的支持，因為 Mitosis 還支持無代碼工具。通過將其序列化為 <a href="http://builder.io/">Builder.io</a> 的 JSON 格式，Mitosis 可以與無代碼工具無縫集成。</p></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/mitosis</guid>
            <link>https://www.oschina.net/p/mitosis</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 數據同步中間件 MyDataHarbor]]>
            </title>
            <description>
                <![CDATA[<p align="center"><br><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.mydataharbor.com" target="_blank"><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/mydataharbor.png" alt="logo" referrerpolicy="no-referrer"></a></p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fmydataharbor.com"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Factions%2Fworkflows%2Fmaven.yml" target="_blank"><img src="https://img.shields.io/github/actions/workflow/status/mydataharbor/mydataharbor/maven.yml?branch=main" alt="GitHub-CI" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Freleases" target="_blank"><img src="https://img.shields.io/github/v/release/mydataharbor/mydataharbor" alt="查看發行的版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fsearch.maven.org%2Fsearch%3Fq%3Dcom.mydataharbor" target="_blank"><img src="https://img.shields.io/maven-central/v/com.mydataharbor/mydataharbor" alt="maven 倉庫" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Freleases" target="_blank"><img src="https://img.shields.io/github/downloads/mydataharbor/mydataharbor/total" alt="下載數量" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Fblob%2Fmain%2FLICENSE" target="_blank"><img src="https://img.shields.io/github/license/mydataharbor/mydataharbor" alt="開源協議" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fmydataharbor.yuque.com%2Fbooks%2Fshare%2Fd5b1360e-d316-4be0-85de-b0958ac64267%2Fpckin3" target="_blank"><img src="https://img.shields.io/badge/plugins-%E6%B8%85%E5%8D%95-blue" alt="插件列表" referrerpolicy="no-referrer"></a></p><p>歡迎前端、插件開發人員前來貢獻代碼，感興趣的請聯繫我：<a href="mailto:1053618636@qq.com">1053618636@qq.com</a></p><h2><a id="user-content-簡介定位" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E7%AE%80%E4%BB%8B%E5%AE%9A%E4%BD%8D"></a>簡介/定位</h2><p><img class="emoji" alt=":cn:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/cn-8adc9b40bd67529ae9a9135ebbc60809.png" width="14" height="14" referrerpolicy="no-referrer"> 🚢 MyDataHarbor 是一個致力於解決異構數據源之間的分佈式、高擴展性、高性能、微事務（至少一次保證）、準實時的數據同步中間件。</p><p>它可以幫助用戶可靠、快速、穩定的對海量數據進行準實時增量同步或者定時全量同步，主要定位是為實時交易系統服務，亦可用於大數據的數據同步（ETL 領域）。</p><h2><a id="user-content-背景" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%83%8C%E6%99%AF"></a>背景</h2><p>在微服務的大背景下，實時交易系統的數據的分散存儲已經成為常態，然而有時候我們需要對這些數據進行實時或者定時全量的同步到另外一個地方。</p><p>比如，一個公司的 C 部門的系統，需要用到 A、B 部門產生的數據，這時候避免不了進行全量或者增量的數據同步。再比如，數據庫中的數據我要實時同步到 elasticsearch、redis 等等中進行搜索。</p><p>數據同步的應用場景在日常的分佈式系統開發中非常常見，而且非常重要，一旦數據同步出現問題，將會導致數據不一致，引起其他嚴重的異常。</p><p>目前小公司的做法是在業務程序系統裏修改代碼，往目標數據源中寫入數據，上點規模的公司的做法是，各個部門開發一套自己的同步小程序，沒有管理，更可能沒有監控，來一個需求開發一個、非常浪費資源，穩定性也得不到保障，而大公司則是有一套數據遷移平台（如阿里的精衞）。</p><p>MyDataHarbor 在這種場景需求下應用而生！</p><h2><a id="user-content-特性" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E7%89%B9%E6%80%A7"></a>特性</h2><h3><a id="user-content-分佈式設計" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%BE%E8%AE%A1"></a>🚩分佈式設計</h3><p>MyDataHarbor 是一個在 zookeeper 上構建的分佈式中間件，支持水平擴展，對節點進行分組，各分組下的機器形成一個子集羣，任務在子集羣隔離範圍內進行負載均衡，防止單點故障。</p><h3><a id="user-content-插件式設計" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%8F%92%E4%BB%B6%E5%BC%8F%E8%AE%BE%E8%AE%A1"></a>🚩插件式設計</h3><p>高度合理的抽象、插件化的設計使得 MyDataHarbor 擁有很高擴展性，任何數據遷移的需求都可以通過開發插件完成。</p><h3><a id="user-content-事務支持" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E4%BA%8B%E5%8A%A1%E6%94%AF%E6%8C%81"></a>🚩事務支持</h3><p>MyDataHarbor 設計之初就考慮到數據丟失問題，引入事務的支持保障數據不丟失！</p><h3><a id="user-content-插件自描述" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%8F%92%E4%BB%B6%E8%87%AA%E6%8F%8F%E8%BF%B0"></a>🚩插件自描述</h3><p>安裝插件後中間件會自動識別這個插件的能力，並且生成用戶 UI 友好的任務創建界面，不需要用戶直接編寫複雜的 json 配置。</p><h3><a id="user-content-自由組合" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%87%AA%E7%94%B1%E7%BB%84%E5%90%88"></a>🚩自由組合</h3><p>MyDataHarbor 支持從不同的插件中複用各種組件，形一個新的 pipeline 管道，並且這些都是可以通過可視化的方式進行。</p><h3><a id="user-content-任務監控" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E4%BB%BB%E5%8A%A1%E7%9B%91%E6%8E%A7"></a>🚩任務監控</h3><p>對接 java 的 jmx，每個任務都有詳細的監控，實時查看任務的運行狀態。</p><h3><a id="user-content-批量支持" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%89%B9%E9%87%8F%E6%94%AF%E6%8C%81"></a>🚩批量支持</h3><p>為可以批量進行提交的寫入源預留批量接口通道，有效提升數據遷移速度，摩托變汽車。</p><h3><a id="user-content-forkjoin" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#forkjoin"></a>🚩ForkJoin</h3><p>對於 DataSource 無法多線程併發拉取的情況下（如 jdbc 遊標取數據），內部引入 forkjoin 併發處理模型開啓多線程處理，並且靈活的事務控制，讓速度飛快的同時保證數據遷移的穩定、不丟失，汽車變高鐵。</p><h2><a id="user-content-設計" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%AE%BE%E8%AE%A1"></a>設計</h2><p>MyDataHarbor 唯一依賴的中間件是 zookeeper，共有兩個組件：mydataharbor-console、mydataharbor-server
<img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/cluster-design.png" alt="集羣設計" referrerpolicy="no-referrer"><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/node-design.png" alt="節點任務設計" referrerpolicy="no-referrer"></p><h2><a id="user-content-支持的插件" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%94%AF%E6%8C%81%E7%9A%84%E6%8F%92%E4%BB%B6"></a>支持的插件</h2><p>詳見  <a href="https://gitee.com/link?target=https%3A%2F%2Fmydataharbor.yuque.com%2Fstaff-tzwgrd%2Fuqew9p%2Fpckin3">https://mydataharbor.yuque.com/staff-tzwgrd/uqew9p/pckin3</a></p><h2><a id="user-content-快速開始" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"></a>快速開始</h2><p>MyDataHarbor 的安裝非常簡單（啓動前請先準備好 zookeeper 集羣）：</p><h3><a id="user-content-下載二進制包" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E4%B8%8B%E8%BD%BD%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85"></a>下載二進制包</h3><p>下載地址：<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Freleases">https://github.com/mydataharbor/mydataharbor/releases</a>
下載列表：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">  mydataharbor-console-xxx-bin.tar.gz</span><span id="LC2" class="line">  mydataharbor-server-xxx-bin.tar.gz</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><blockquote><p>xxx 是發行的版本號</p></blockquote><h3><a id="user-content-mydataharbor-console" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#mydataharbor-console"></a>mydataharbor-console</h3><h4><a id="user-content-解壓" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%A7%A3%E5%8E%8B"></a>解壓</h4><p><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/image-20210812143819918.png" alt="image-20210812143819918" referrerpolicy="no-referrer"></p><h4><a id="user-content-配置" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E9%85%8D%E7%BD%AE"></a>配置</h4><p>進入 config 目錄，修改 application.yml，主要修改如下配置</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="na">server</span><span class="pi">:</span></span><span id="LC2" class="line"><span class="na">port</span><span class="pi">:</span><span class="m">8080</span><span class="c1">#console 服務啓動端口</span></span><span id="LC3" class="line"><span class="na">zk</span><span class="pi">:</span><span class="s">127.0.0.1:2181</span><span class="c1">#zk 地址</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-運行" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%BF%90%E8%A1%8C"></a>運行</h4><p>Windows 系統下運行 start.bat<br>
Linux 系統下運行 start.sh &nbsp;關閉 stop.sh</p><blockquote><p>start.sh 腳本支持 jmx、debug、status 參數，如：<br>
start.sh jmx   啓動遠程 jmx 支持 <br>
start.sh debug 開啓遠程 debug 方式啓動 <br>
start.sh status 查看當前程序狀態</p></blockquote><h3><a id="user-content-mydataharbor-server" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#mydataharbor-server"></a>mydataharbor-server</h3><h4><a id="user-content-解壓-1" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%A7%A3%E5%8E%8B-1"></a>解壓</h4><p><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/image-20210812144430744.png" alt="image-20210812144430744" referrerpolicy="no-referrer"></p><h4><a id="user-content-配置-1" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E9%85%8D%E7%BD%AE-1"></a>配置</h4><p>修改 config 目錄下的 system.yml</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="na">zk</span><span class="pi">:</span><span class="pi">[</span><span class="s2">"</span><span class="s">127.0.0.1:2181"</span><span class="pi">]</span><span class="c1">#zk 地址</span></span><span id="LC2" class="line"><span class="na">port</span><span class="pi">:</span><span class="m">1299</span><span class="c1">#server 服務啓動端口</span></span><span id="LC3" class="line"><span class="na">group</span><span class="pi">:</span><span class="s">biz001</span><span class="c1">#該節點所屬組</span></span><span id="LC4" class="line"><span class="na">pluginRepository</span><span class="pi">:</span><span class="s">http://127.0.0.1:8080</span><span class="c1">#插件倉庫地址</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-運行-1" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%BF%90%E8%A1%8C-1"></a>運行</h4><p>Windows 系統下運行 start.bat<br>
Linux 系統下運行 start.sh &nbsp;關閉 stop.sh</p><blockquote><p>start.sh 腳本支持 jmx、debug、status 參數，如：<br>
start.sh jmx   啓動遠程 jmx 支持 <br>
start.sh debug 開啓遠程 debug 方式啓動 <br>
start.sh status 查看當前程序狀態</p></blockquote><h4><a id="user-content-驗證" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E9%AA%8C%E8%AF%81"></a>驗證</h4><p>訪問：mydataharbor-console &nbsp;<a href="https://gitee.com/link?target=http%3A%2F%2F127.0.0.1%3A8080">http://127.0.0.1:8080</a>
是否可以看到剛剛啓動的節點
<img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/demo.png" alt="image-20210812143819918" referrerpolicy="no-referrer"></p><h2><a id="user-content-其它" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E5%85%B6%E5%AE%83"></a>其它</h2><p>demo 運行實例：<a href="https://gitee.com/link?target=http%3A%2F%2Fdemo.mydataharbor.com">http://demo.mydataharbor.com</a></p><p>插件市場：<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.mydataharbor.com%2Fuser%2Finfo.html">https://www.mydataharbor.com/user/info.html</a></p><p>文檔 (語雀)：<a href="https://gitee.com/link?target=http%3A%2F%2Fdoc.mydataharbor.com">http://doc.mydataharbor.com</a></p><h4><a id="user-content-qq 羣加羣時需要驗證項目 star 數請 star 一下然後記下 star 數告訴管理員" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#qq%E7%BE%A4%E5%8A%A0%E7%BE%A4%E6%97%B6%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E9%A1%B9%E7%9B%AEstar%E6%95%B0%E8%AF%B7star%E4%B8%80%E4%B8%8B%E7%84%B6%E5%90%8E%E8%AE%B0%E4%B8%8Bstar%E6%95%B0%E5%91%8A%E8%AF%89%E7%AE%A1%E7%90%86%E5%91%98"></a>QQ 羣（<strong><em>加羣時需要驗證項目 star 數，請 star 一下然後記下 star 數告訴管理員</em></strong>）</h4><p><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/qq-discuz.png" alt="QQ 羣" referrerpolicy="no-referrer"></p><h2><a id="user-content-更新日誌" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"></a>更新日誌</h2><h3><a id="user-content-200 版本" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#200%E7%89%88%E6%9C%AC"></a>2.0.0 版本</h3><p>1、新增 mydataharbor.ITaskStorage 接口，允許各組件在運行期持久化記錄數據，並提供一個 zookeeper 的默認實現，每秒 1 次準實時同步，不影響性能。</p><p>2、默認將任務的監控信息通過持久化接口近乎實時的展示在管理台</p><p>3、任務修改重建功能</p><p>4、調整 rebalance 算法，新機器加入，將轉移當前管道數大於任務分配節點數的任務</p><p>5、鑑於 1.x 使用用戶可能較少，由於修復了一些拼寫錯誤，接口名稱變了，不再向 1.x 兼容，建議大家把任務移到 2.x 上，請諒解</p>]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/mydataharbor/mydataharbor</guid>
            <link>https://gitee.com/mydataharbor/mydataharbor</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 時間複雜度為 O (nlogn) 的排序算法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>歸併排序</h1><p>歸併排序遵循<strong>分治</strong>的思想：將原問題分解為幾個規模較小但類似於原問題的子問題，遞歸地求解這些子問題，然後合併這些子問題的解來建立原問題的解，歸併排序的步驟如下：</p><ul><li><p><strong>劃分</strong>：分解待排序的 n 個元素的序列成各具 n/2 個元素的兩個子序列，將長數組的排序問題轉換為短數組的排序問題，當待排序的序列長度為 1 時，遞歸劃分結束</p></li><li><p><strong>合併</strong>：合併兩個已排序的子序列得出已排序的最終結果</p></li></ul><p>歸併排序的代碼實現如下：</p><pre><code>    private void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 劃分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid);
        sort(nums, mid + 1, right);
        // 合併
        merge(nums, left, mid, right);
    }

    private void merge(int[] nums, int left, int mid, int right) {
        // 輔助數組
        int[] temp = Arrays.copyOfRange(nums, left, right + 1);

        int leftBegin = 0, leftEnd = mid - left;
        int rightBegin = leftEnd + 1, rightEnd = right - left;
        for (int i = left; i &lt;= right; i++) {
            if (leftBegin &gt; leftEnd) {
                nums[i] = temp[rightBegin++];
            } else if (rightBegin &gt; rightEnd || temp[leftBegin] &lt; temp[rightBegin]) {
                nums[i] = temp[leftBegin++];
            } else {
                nums[i] = temp[rightBegin++];
            }
        }
    }

</code></pre><p>歸併排序最吸引人的性質是它能保證將長度為 n 的數組排序所需的時間和 nlogn 成正比；它的主要缺點是所需的額外空間和 n 成正比。</p><p>算法特性：</p><ul><li><p><strong>空間複雜度</strong>：藉助輔助數組實現合併，使用 O(n) 的額外空間；遞歸深度為 logn，使用 O(logn) 大小的棧幀空間。忽略低階部分，所以空間複雜度為 O(n)</p></li><li><p><strong>非原地排序</strong></p></li><li><p><strong>穩定排序</strong></p></li><li><p><strong>非自適應排序</strong></p></li></ul><p>以上代碼是歸併排序常見的實現，下面我們來一起看看歸併排序的優化策略：</p><span id="OSC_h3_2"></span><h3>將多次創建小數組的開銷轉換為只創建一次大數組</h3><p>在上文實現中，我們在每次合併兩個有序數組時，即使是很小的數組，我們都會創建一個新的 temp[] 數組，這部分耗時是歸併排序運行時間的主要部分。更好的解決方案是將 temp[] 數組定義成 sort() 方法的局部變量，並將它作為參數傳遞給 merge() 方法，實現如下：</p><pre><code>    private void sort(int[] nums, int left, int right, int[] temp) {
        if (left &gt;= right) {
            return;
        }

        // 劃分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid, temp);
        sort(nums, mid + 1, right, temp);
        // 合併
        merge(nums, left, mid, right, temp);
    }

    private void merge(int[] nums, int left, int mid, int right, int[] temp) {
        System.arraycopy(nums, left, temp, left, right - left + 1);
        int l = left, r = mid + 1;
        for (int i = left; i &lt;= right; i++) {
            if (l &gt; mid) {
                nums[i] = temp[r++];
            } else if (r &gt; right || temp[l] &lt; temp[r]) {
                nums[i] = temp[l++];
            } else {
                nums[i] = temp[r++];
            }
        }
    }

</code></pre><span id="OSC_h3_3"></span><h3>當數組有序時，跳過 merge() 方法</h3><p>我們可以在執行合併前添加判斷條件：如果<code>nums[mid] &lt;= nums[mid + 1]</code>時我們認為數組已經是有序的了，那麼我們就跳過 merge() 方法。它不影響排序的遞歸調用，但是對任意有序的子數組算法的運行時間就變成線性的了，代碼實現如下：</p><pre><code>    private void sort(int[] nums, int left, int right, int[] temp) {
        if (left &gt;= right) {
            return;
        }

        // 劃分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid, temp);
        sort(nums, mid + 1, right, temp);
        // 合併
        if (nums[mid] &gt; nums[mid + 1]) {
            merge(nums, left, mid, right, temp);
        }
    }

    private void merge(int[] nums, int left, int mid, int right, int[] temp) {
        System.arraycopy(nums, left, temp, left, right - left + 1);
        int l = left, r = mid + 1;
        for (int i = left; i &lt;= right; i++) {
            if (l &gt; mid) {
                nums[i] = temp[r++];
            } else if (r &gt; right || temp[l] &lt; temp[r]) {
                nums[i] = temp[l++];
            } else {
                nums[i] = temp[r++];
            }
        }
    }

</code></pre><span id="OSC_h3_4"></span><h3>對小規模子數組使用插入排序</h3><p>對小規模數組進行排序會使遞歸調用過於頻繁，而使用插入排序處理小規模子數組一般可以將歸併排序的運行時間縮短 10% ~ 15%，代碼實現如下：</p><pre><code>    /**
     * M 取值在 5 ~ 15 之間大多數情況下都能令人滿意
     */
    private final int M = 9;

    private void sort(int[] nums, int left, int right) {
        if (left + M &gt;= right) {
            // 插入排序
            insertSort(nums);
            return;
        }

        // 劃分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid);
        sort(nums, mid + 1, right);
        // 合併
        merge(nums, left, mid, right);
    }

    /**
     * 插入排序
     */
    private void insertSort(int[] nums) {
        for (int i = 1; i &lt; nums.length; i++) {
            int base = nums[i];

            int j = i - 1;
            while (j &gt;= 0 &amp;&amp; nums[j] &gt; base) {
                nums[j + 1] = nums[j--];
            }
            nums[j + 1] = base;
        }
    }

    private void merge(int[] nums, int left, int mid, int right) {
        // 輔助數組
        int[] temp = Arrays.copyOfRange(nums, left, right + 1);

        int leftBegin = 0, leftEnd = mid - left;
        int rightBegin = leftEnd + 1, rightEnd = right - left;
        for (int i = left; i &lt;= right; i++) {
            if (leftBegin &gt; leftEnd) {
                nums[i] = temp[rightBegin++];
            } else if (rightBegin &gt; rightEnd || temp[leftBegin] &lt; temp[rightBegin]) {
                nums[i] = temp[leftBegin++];
            } else {
                nums[i] = temp[rightBegin++];
            }
        }
    }

</code></pre><hr><span id="OSC_h1_5"></span><h1>快速排序</h1><p>快速排序也遵循<strong>分治</strong>的思想，它與歸併排序不同的是，快速排序是<strong>原地排序</strong>，而且快速排序會先排序當前數組，再對子數組進行排序，它的算法步驟如下：</p><ul><li><p><strong>哨兵劃分</strong>：選取數組中最左端元素為基準數，將小於基準數的元素放在基準數左邊，將大於基準數的元素放在基準數右邊</p></li><li><p><strong>排序子數組</strong>：將哨兵劃分的索引作為劃分左右子數組的分界，分別對左右子數組進行哨兵劃分和排序</p></li></ul><p>快速排序的代碼實現如下：</p><pre><code>    private void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 哨兵劃分
        int partition = partition(nums, left, right);

        // 分別排序兩個子數組
        sort(nums, left, partition - 1);
        sort(nums, partition + 1, right);
    }

    /**
     * 哨兵劃分
     */
    private int partition(int[] nums, int left, int right) {
        // 以 nums[left] 作為基準數，並記錄基準數索引
        int originIndex = left;
        int base = nums[left];

        while (left &lt; right) {
            // 從右向左找小於基準數的元素
            while (left &lt; right &amp;&amp; nums[right] &gt;= base) {
                right--;
            }
            // 從左向右找大於基準數的元素
            while (left &lt; right &amp;&amp; nums[left] &lt;= base) {
                left++;
            }
            swap(nums, left, right);
        }
        // 將基準數交換到兩子數組的分界線
        swap(nums, originIndex, left);

        return left;
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><p>算法特性：</p><ul><li><p><strong>時間複雜度</strong>：平均時間複雜度為 O(nlogn)，最差時間複雜度為 O(n2)</p></li><li><p><strong>空間複雜度</strong>：最差情況下，遞歸深度為 n，所以空間複雜度為 O(n)</p></li><li><p><strong>原地排序</strong></p></li><li><p><strong>非穩定排序</strong></p></li><li><p><strong>自適應排序</strong></p></li></ul><blockquote><p>歸併排序的時間複雜度一直是 O(nlogn)，而快速排序在最壞的情況下時間複雜度為 O(n2)，為什麼歸併排序沒有快速排序應用廣泛呢？</p><p>答：因為歸併排序是非原地排序，在合併階段需要藉助非常量級的額外空間</p></blockquote><p>快速排序有很多優點，但是在哨兵劃分不平衡的情況下，算法的效率會比較低效。下面是對快速排序排序優化的一些方法：</p><span id="OSC_h3_6"></span><h3>切換到插入排序</h3><p>對於小數組，快速排序比插入排序慢，快速排序的 sort() 方法在長度為 1 的子數組中也會調用一次，所以，在排序小數組時切換到插入排序排序的效率會更高，如下：</p><pre><code>    /**
     * M 取值在 5 ~ 15 之間大多數情況下都能令人滿意
     */
    private final int M = 9;

    public void sort(int[] nums, int left, int right) {
        // 小數組採用插入排序
        if (left + M &gt;= right) {
            insertSort(nums);
            return;
        }

        int partition = partition(nums, left, right);
        sort(nums, left, partition - 1);
        sort(nums, partition + 1, right);
    }

    /**
     * 插入排序
     */
    private void insertSort(int[] nums) {
        for (int i = 1; i &lt; nums.length; i++) {
            int base = nums[i];

            int j = i - 1;
            while (j &gt;= 0 &amp;&amp; nums[j] &gt; base) {
                nums[j + 1] = nums[j--];
            }
            nums[j + 1] = base;
        }
    }

    private int partition(int[] nums, int left, int right) {
        int originIndex = left;
        int base = nums[left];

        while (left &lt; right) {
            while (left &lt; right &amp;&amp; nums[right] &gt;= base) {
                right--;
            }
            while (left &lt; right &amp;&amp; nums[left] &lt;= base) {
                left++;
            }
            swap(nums, left, right);
        }
        swap(nums, left, originIndex);

        return left;
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><span id="OSC_h3_7"></span><h3>基準數優化</h3><p>如果數組為倒序的情況下，選擇最左端元素為基準數，那麼每次哨兵劃分會導致右數組長度為 0，進而使快速排序的時間複雜度為 O(n2)，為了儘可能避免這種情況，我們可以對基準數的選擇進行優化，採用<strong>三取樣切分</strong>的方法：選取數組最左端、中間和最右端這三個值的中位數為基準數，這樣選擇的基準數大概率不是區間的極值，時間複雜度為 O(n2) 的概率大大降低，代碼實現如下：</p><pre><code>    public void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 基準數優化
        betterBase(nums, left, right);

        int partition = partition(nums, left, right);

        sort(nums, left, partition - 1);
        sort(nums, partition + 1, right);
    }

    /**
     * 基準數優化，將 left, mid, right 這幾個值中的中位數換到 left 的位置
     * 注意其中使用了異或運算進行條件判斷
     */
    private void betterBase(int[] nums, int left, int right) {
        int mid = left + right &gt;&gt; 1;

        if ((nums[mid] &lt; nums[right]) ^ (nums[mid] &lt; nums[left])) {
            swap(nums, left, mid);
        } else if ((nums[right] &lt; nums[left]) ^ (nums[right] &lt; nums[mid])) {
            swap(nums, left, right);
        }
    }

    private int partition(int[] nums, int left, int right) {
        int originIndex = left;
        int base = nums[left];

        while (left &lt; right) {
            while (left &lt; right &amp;&amp; nums[right] &gt;= base) {
                right--;
            }
            while (left &lt; right &amp;&amp; nums[left] &lt;= base) {
                left++;
            }
            swap(nums, left, right);
        }
        swap(nums, originIndex, left);

        return left;
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><span id="OSC_h3_8"></span><h3>三向切分</h3><p>在數組有大量重複元素的情況下，快速排序的遞歸性會使元素全部重複的子數組經常出現，而對這些數組進行快速排序是沒有必要的，我們可以對它進行優化。</p><p>一個簡單的想法是將數組切分為三部分，分別對應小於、等於和大於基準數的數組，每次將其中「小於」和「大於」的數組進行排序，那麼最終也能得到排序的結果，這種策略下我們不會對等於基準數的子數組進行排序，提高了排序算法的效率，它的算法流程如下：</p><p>從左到右遍歷數組，維護指針 l 使得 [left, l - 1] 中的元素都小於基準數，維護指針 r 使得 [r + 1, right] 中的元素都大於基準數，維護指針 mid 使得 [l, mid - 1] 中的元素都等於基準數，其中 [mid, r] 區間中的元素還未確定大小關係，圖示如下：</p><p><img alt="快速排序-荷蘭國旗.jpg" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-30-09-24mWidH7TKov10iOQb.jpg" referrerpolicy="no-referrer"></p><p>它的代碼實現如下：</p><pre><code>    public void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 三向切分
        int l = left, mid = left + 1, r = right;
        int base = nums[l];
        while (mid &lt;= r) {
            if (nums[mid] &lt; base) {
                swap(nums, l++, mid++);
            } else if (nums[mid] &gt; base) {
                swap(nums, mid, r--);
            } else {
                mid++;
            }
        }

        sort(nums, left, l - 1);
        sort(nums, r + 1, right);
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><blockquote><p>這也是經典的荷蘭國旗問題，因為這就好像用三種可能的主鍵值將數組排序一樣，這三種主鍵值對應着荷蘭國旗上的三種顏色</p></blockquote><hr><span id="OSC_h3_9"></span><h3>巨人的肩膀</h3><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.hello-algo.com%2F" rel="nofollow" target="_blank">《Hello 算法》：11.5 和 11.6 小節</a></p></li><li><p>《算法，第四版》：2.3 節，快速排序</p></li><li><p>《算法導論，第三版》：第 2.2、2.3、7 章</p></li></ul><blockquote><p>作者：京東物流，王奕龍</p><p>來源：京東雲開發者社區，自猿其説 Tech 轉載請註明來源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10277308</guid>
            <link>https://my.oschina.net/u/4090830/blog/10277308</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[B 站正式啓動鴻蒙原生應用開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>嗶哩嗶哩（B 站）與華為宣佈達成鴻蒙領域全面合作，並正式啓動鴻蒙原生應用開發工作。</p><p>數據顯示，今年上半年，B 站的日活用戶同比增長 17% 至超過 9500 萬，而月活用戶達 3.19 億；總日均視頻播放量同比增長 34% 至 41 億。截至今年 8 月，鴻蒙生態設備數量已超過 7 億，超過 220 萬開發者投入到鴻蒙生態開發中，且近期日新增註冊量已過萬。</p><p><img alt="" height="331" src="https://oscimg.oschina.net/oscnet/up-25a150372aecd554f4a31c934afbf6af3f8.webp" width="500" referrerpolicy="no-referrer"></p><p>目前，已宣佈啓動鴻蒙原生應用開發的 App 包括但不限於：同程旅行、開心消消樂、美團、去哪兒、釘釘、飛常準、小紅書、B 站。</p><p>嗶哩嗶哩方面表示，鴻蒙原生版本的嗶哩嗶哩將充分利用 HarmonyOS 獨特的全場景分佈式體驗、原生智能、純淨安全、大模型 AI 交互等能力，提供更多創新體驗。華為則表示，將提供端到端的鴻蒙開發和賦能套件，使得鴻蒙應用適配成本降低。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268446</guid>
            <link>https://www.oschina.net/news/268446</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google Drive 出現數據丟失問題]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>有 Google Drive 用戶稱自己存儲在雲端的文件<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F11%2F27%2Fgoogle_drive_files_disappearing%2F" target="_blank">無端丟失</a></u>，他表示登錄 Google Drive 後發現自己的文件<strong>回到了 2023 年 5 月的狀態</strong>。由於他沒有手動刪除過文件，所以回收站也沒有任何丟失文件的記錄。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1128/102059_Ynyc_2720166.png" referrerpolicy="no-referrer"></p><p>來源：<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fdrive%2Fthread%2F245055606%2Fgoogle-drive-files-suddenly-disappeared-the-drive-literally-went-back-to-condition-in-may-2023%3Fhl%3Den" target="_blank">https://support.google.com/drive/thread/245055606/google-drive-files-suddenly-disappeared-the-drive-literally-went-back-to-condition-in-may-2023?hl=en</a></em></p></blockquote><p>其他用戶也<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fdrive%2Fthread%2F245055606%3Fhl%3Den%26msgid%3D245207929" target="_blank">報告了類似的經歷</a></u>，有人聲稱丟失了六個月的業務數據。另外有一些用戶報告稱同步功能停止工作，導致雲存儲中的文件不再是最新的版本。</p><p>一些用戶通過調整緩存文件成功恢復了部分信息，<strong>但受影響用戶的建議是在工程師找到解決方案之前不要進行任何更改</strong>。</p><p>Google 支持團隊發佈的一條消息也建議在工程師調查問題期間不要對根/數據文件夾進行更改。一些用戶猜測可能與賬戶被意外刪除有關。</p><p>這一狀況通常會波及多達數月的雲文件，且無法用恢復工具還原。有部分用戶在緩存文件中找到部分數據。目前 Google 官方人員在其中一條反饋中表示該問題已在排查中，但未能給出具體修復時間，也無法確定在修復後是否能找回全部文件。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268442/google-drive-files-suddenly-disappeared</guid>
            <link>https://www.oschina.net/news/268442/google-drive-files-suddenly-disappeared</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[研易科技加入 openKylin，共推社區 ARM 生態繁榮！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">近日，深圳市研易科技有限公司（以下簡稱」研易科技「）簽署了 openKylin 社區 CLA（Contributor License Agreement 貢獻者許可協議），正式加入 openKylin 開源社區。</span></span></p><div><p style="text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-0f2a91ac2d8ef1357d5dd4e6294f78f07a8.png" width="829" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">研易科技依託資深研發銷售隊伍，集行業專用嵌入式計算機產品研發、生產、銷售及服務於一體，產品涉及嵌入式計算機板卡、嵌入式準系統、工業整機、工業平板電腦等，可廣泛應用於智慧醫療、人工智能、智慧零售、倉儲物流、智慧城市、軌道交通、燈光工程、網絡安全、智慧電網、國產化、工業自動化等行業領域。公司旗下 Coolpi 系列開源模塊產品，可提供高性能計算能力，方便廣大開發者評估項目與應用落地。</span></span></p><div><p style="text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-ec10d5d2b359fddbaf627cab3d3c3505685.png" width="940" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">加入 opeKylin 社區後，研易科技完成了 Cool Pi 與社區操作系統 1.0 版本的兼容適配。後續，雙方將持續在技術和生態上展開合作，包括硬件升級和版本適配等。研易科技也將持續對 openKylin 社區進行投入，共同推動社區 ARM 生態繁榮。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 01:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268435</guid>
            <link>https://www.oschina.net/news/268435</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[字節跳動成立新部門 Flow，發力 AI 應用層]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">36 氪報道稱，</span><span style="background-color:#ffffff; color:#222222">字節跳動近期成立了一個新 AI 部門 Flow，技術負責人為字節跳動技術副總裁洪定坤。</span></p><p><span style="background-color:#ffffff; color:#222222">一位知情人士表示，這一新部門的業務帶頭人，為字節大模型團隊的負責人朱文佳。Flow 主要聚焦在 AI 應用層。在字節圈內，Flow 近期發佈了活水招聘帖，社會招聘也已經開始一段時間。</span></p><p><span style="background-color:#ffffff; color:#222222">在帖中，其表示是字節跳動旗下 AI 創新業務團隊，「目前已經在國內和海外分別上線豆包和 Cici 兩款產品，有多個 AI 相關創新產品孵化中」。截止發稿前，字節跳動尚無迴應。</span></p><p style="color:#262626; margin-left:0; margin-right:0; text-align:justify">在 11 月初，字節各個事業部都進行了不少業務和架構調整，這些調整仍在進行中，當前 Flow 的架構和彙報線未完全確定。且多位知情人士透露，在此次調整中，字節也從飛書、抖音等各個 BU 抽調人選，到這一部門做一款新的 C 端產品。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268383</guid>
            <link>https://www.oschina.net/news/268383</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲原生週刊：Kubernetes 1.29 中的刪除、棄用和主要更改]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>開源項目推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyonahd%2Forphaned-configmaps" target="_blank">Orphaned ConfigMaps</a></h3><p>該版本庫包含一個腳本，用於識別 Kubernetes 命名空間中的孤立的配置映射。孤立的配置映射是指那些未被命名空間中的任何活動 Pod 或容器引用的配置映射。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmarvasgit%2Fkubernetes-multicooker" target="_blank">Kubernetes Multi Cooker</a></h3><p>該項目包含一個小型 Kubernetes 控制器，用於監視每個節點的 CPU 壓力；當超過某個閾值時，節點將被污染（這樣就不會在已經超載的節點上調度額外的工作負載），最後控制器將開始從該節點驅逐 Pod。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Femberstack%2Fkubernetes-reflector" target="_blank">Reflector</a></h3><p>Reflector 是一個 Kubernetes 插件，旨在監視資源（祕密和配置映射）的更改並反映相同或其他命名空間中鏡像資源的更改。</p><h2>文章推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubernetes.io%2Fblog%2F2023%2F11%2F16%2Fkubernetes-1-29-upcoming-changes%2F" target="_blank">Kubernetes 1.29 中的刪除、棄用和主要更改</a></h3><p>和其他每次發佈一樣，Kubernetes v1.29 將棄用和移除一些特性。一貫以來生成高質量發佈版本的能力是開發週期穩健和社區健康的證明。本文列舉即將發佈的 Kubernetes 1.29 中的一些棄用和移除事項。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-storage-provider-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 大存儲提供商工具</a></h3><p>這篇文章介紹了 Kubernetes 的五個存儲提供者工具：SeaweedFS、Vitess、TiKV、Rook 和 OpenEBS。這些工具幫助管理 Kubernetes 上的數據工作負載，包括卷供應、複製、備份、加密、壓縮和性能調優等功能。它們與 Kubernetes API 和概念無縫集成，並支持持久卷（PV）、持久卷聲明（PVC）和存儲類（Storage Class）。這篇文章詳細介紹了每個工具的工作機制、優勢以及在實際使用中的案例和成功故事。通過閲讀這篇文章，讀者可以瞭解 Kubernetes 上可用的存儲提供者選項，並根據自己的需求選擇最合適的工具。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.atatus.com%2Fblog%2Ftroubleshooting-kubernetes-deployment%2F" target="_blank">對各個級別的 Kubernetes 部署進行故障排除</a></h3><p>這篇文章是關於在各個層面上解決 Kubernetes 部署問題的指南。文章首先介紹了 Kubernetes 作為容器編排的事實標準，並提到了它自動化部署、擴展和管理容器化應用程序的能力。然而，即使遵循最佳實踐並具備專業知識，Kubernetes 部署有時也是一個複雜而具有挑戰性的過程。文章探討了從應用代碼到基礎設施和 Kubernetes 組件的各個層面上的部署故障排除過程，並介紹了一些常見問題和挑戰，如容器鏡像拉取錯誤、Pod 調度問題、網絡連接問題和存儲問題。文章還討論了一些診斷和解決這些問題的最佳實踐和工具。通過閲讀這篇文章，讀者將更好地瞭解如何在 Kubernetes 部署的每個層面上進行故障排除，並更好地管理其應用程序。</p><h2>雲原生動態</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F11%2F20%2Fannouncing-the-platform-engineering-maturity-model%2F" target="_blank">CNCF 平台工程成熟度模型出爐</a></h3><p>CNCF（Cloud Native Computing Foundation）的平台工程成熟度模型首次發佈。該模型提供了對平台工程成熟度的具體應用，是今年 4 月份發佈的備受歡迎的白皮書的延伸。該模型將平台工程定義為通過在構建平台和其能力的各個方面（包括人員、流程、策略和技術）進行投資，提供內部平台作為產品的實踐，從而推動業務結果。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloudnativenow.com%2Ftopics%2Fcloudnativedevelopment%2Fmicrosoft-expands-scope-of-azure-kubernetes-services%2F" target="_blank">微軟擴大 Azure Kubernetes 服務範圍</a></h3><p>Microsoft 已普遍推出 Azure Kubernetes Fleet Manager，以便更輕鬆地集中管理多個集羣，並可與一組用於優化成本的工具一起分階段進行。</p><p>與此同時，除了預覽 Azure 容器應用程序平台的擴展以增加對事件的支持之外，微軟還使用 Kubernetes AI 工具鏈運算符簡化在 Azure Kubernetes 服務 (AKS) 上部署大型語言模型 (LLM) 的過程用於訓練 AI 模型的驅動框架，同時支持開源 Qdrant、Milvus 和 Weaviate 矢量數據庫。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10293895</guid>
            <link>https://my.oschina.net/u/4197945/blog/10293895</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
    </channel>
</rss>
