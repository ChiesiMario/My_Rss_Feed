<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 14 Nov 2023 03:36:14 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[李开复旗下 AI 公司「零一万物」开源的 Yi 大模型被指抄袭]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>「</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.01.ai%2F">零一万物</a><span>」是创新工场董事长兼 CEO 李开复于今年创办的 AI 大模型创业公司。上周该公司<u><a href="https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm">宣布</a></u></span><strong>推出&nbsp;Yi-34B 和&nbsp;Yi-6B 两个开源大模型。</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-4ab5886e43554fd3233305e7c8264217507.png" referrerpolicy="no-referrer"></p><p>在公开的报道中，该公司称 Yi 系列大模型拥有全球大模型中最长的上下文窗口。其中 Yi-34B 在 Hugging Face 英文测试榜单中位列第一，在 C-Eval 中文能力排行榜中超越所有开源模型。</p><p>不过在&nbsp;Yi-34B 的 Hugging Face 主页上，有人指出<strong> Yi 完全使用了 Llama 的架构</strong>——前者只是对后者的两个张量 (Tensor) 名称进行了修改，具体为 input_layernorm 和 post_attention_layernorm。</p><p><img src="https://static.oschina.net/uploads/space/2023/1114/111349_Novu_2720166.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B%2Fdiscussions%2F11" target="_blank">https://huggingface.co/01-ai/Yi-34B/discussions/11</a></u></em></p><p>AI 领域知名专家贾扬清昨晚也在个人朋友圈点评了此事——不过并没有指名道姓：</p><p><img src="https://static.oschina.net/uploads/space/2023/1114/111004_dOrQ_2720166.png" referrerpolicy="no-referrer"></p><blockquote><p>贾扬清是开源深度学习框架&nbsp;<span>Caffe 创始人、TensorFlow 作者之一、也是 PyTorch 1.0 的共同创始人。</span></p><p>今年 3 月，贾扬清从阿里离职后联合创立了一家新的 AI 公司 Lepton AI，旨在建立高效的 AI 应用平台。</p><p>Lepton AI 总部位于美国加利福尼亚州帕洛阿托，官网宣称可通过 Lepton AI 在几分钟内高效、大规模地运行 AI 应用。相比大模型，贾扬清团队更偏重 AI 能力的开发。</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 03:32:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266377</guid>
            <link>https://www.oschina.net/news/266377</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[指针没用好，一行代码让公司损失 6000 万美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1990 年 1 月 15 日，AT&amp;T 的新泽西运营中心检测到大范围的系统故障，网络显示屏上出现了大量红色警告。</p><p>尽管试图排除故障，但网络故障仍持续了 9 个小时，导致呼叫连接故障率达到 50%。</p><p><strong>AT&amp;T 因此损失了 6000 多万美元，6 万多名美国人的电话完全无法接通</strong>。</p><p>此外，500 个航班延误，8.5 万人受到影响。</p><p>按理说，AT&amp;T 的长途网络是高效率的典范，它利用先进的电子交换机和信号系统处理了全国大部分的电话。该系统通常能在几秒钟内完成电话路由选择。</p><p>然而，就在这一天，从纽约的一个交换机开始，整个网络出现了故障。这是由于最近一次更新中的一个软件错误造成的，该错误影响了网络中的 114 个交换机。当纽约的交换机复位并发出信号时，这个错误引发了多米诺骨牌效应，导致大范围的网络中断。</p><p><strong>有趣的是，这个软件并没有经过测试。由于代码改动较小，因此按照管理层的要求绕过了测试</strong>。</p><h3>问题所在</h3><p>追根溯源，原因在于网络交换机实施的软件更新中出现了编码错误。</p><p>该错误发生在一个 C 语言程序中，涉及嵌套条件语句中一个错位的中断语句，导致数据覆盖和系统重置。</p><p>伪代码</p><pre><code>1  while (ring receive buffer not empty 
          and side buffer not empty):

2    Initialize pointer to first message in side buffer
     or ring receive buffer

3    get copy of buffer

4    switch (message):

5       case (incoming_message):

6             if (sending switch is out of service):

7                 if (ring write buffer is empty):

8                     send "in service" to status map

9                 else:

10                    break // The error was here!

                  END IF

11           process incoming message, set up pointers to
             optional parameters

12           break
       END SWITCH


13   do optional parameter work</code></pre><h3>问题分析</h3><ul><li>如果环写入缓冲区不是空的，那么第 7 行的 `if` 语句就会被跳过，取而代之的是第 10 行的中断语句。</li><li>然而，为了使程序正常运行，本应执行第 11 行。</li><li>当中断语句被执行，而不是处理传入的信息并为可选参数设置指针时，数据（本应保留的指针）就会被覆盖</li><li>纠错软件识别出数据被覆盖，并启动关闭开关进行重置。由于网络中的所有交换机都使用了这种有缺陷的软件，导致了连锁重置反应，最终瘫痪了整个网络系统，使问题变得更加复杂。</li></ul><p>尽管进行了严格的测试，网络的设计也非常灵活，但一行代码还是导致了半个国家的主要通信线路瘫痪。</p><h3><strong>修复</strong></h3><p>工程师们花了 9 个小时才使 AT&amp;T 的系统完全恢复正常。他们主要是通过将交换机回滚到之前的代码工作版本来实现的。</p><p>实际上，软件工程师花了两周时间进行严格的代码阅读、测试和复制，才真正弄清了错误所在。</p><h3><strong>结论</strong></h3><p>对于 AT&amp;T 来说，不幸的是，这还不是他们 90 年代最大的系统崩溃。在这十年的后期，他们还遇到了更多的问题。</p><p>今天的公司拥有更好的流程，但即便如此，还是会有漏洞漏网。谷歌撰写了一篇关于网站可靠性工程 20 年的精彩回顾文章，其中对 2016 年 YouTube 的首次全球故障进行了反思。</p><p>对于公司来说，故障的规模是巨大的，每次故障都会给我们带来教训。然而，对于大多数公司来说，故障归根结底是人为错误和流程漏洞造成的。</p><p>原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fengineercodex.substack.com%2Fp%2Fhow-one-line-of-code-caused-a-60" target="_blank">https://engineercodex.substack.com/p/how-one-line-of-code-caused-a-60</a><br> 转自：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jdon.com%2F69737.html" target="_blank">https://www.jdon.com/69737.htm</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 03:05:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266368/one-line-of-code-caused-a-60</guid>
            <link>https://www.oschina.net/news/266368/one-line-of-code-caused-a-60</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[游戏党福音！MakerFrame SIG 跨平台游戏引擎上线]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px"><span><span style="color:#000000">近日，经 openKylin 社区技术委员会审议通过，</span><strong><span style="color:#000000">鹰歌框架引擎技术小组—MakerFrame SIG</span></strong><span style="color:#000000">正式成立。</span></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">MakerFrame SIG 由</span><strong><span style="color:#000000">社区爱好者刘帅</span></strong><span style="color:#000000">发起成立，负责为 openKylin 社区开发简单高效的游戏框架引擎，致力于让专业人士和非专业人士都来开发跨平台的游戏和应用，大力促进 openKylin 社区游戏生态推广。</span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">01</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 目标</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">MakerFrame（鹰歌框架引擎）作为默认组件集成至 openKylin 社区版本中，让社区爱好者基于游戏引擎快捷的开发各种游戏，拓展社区游戏生态。</span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">02</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 职责</span></strong></span></p><ul><li><span><span style="color:#000000">MakerFrame 游戏框架的开发维护和各平台适配；</span></span></li><li><span><span style="color:#000000">负责解答使用和开发过程中的技术问题。</span></span></li></ul><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">03</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 现阶段成果</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#0052ff">1、完成框架引擎的各平台适配。</span></strong></span></p><div><p style="text-align:center"><img alt="" height="746" src="https://oscimg.oschina.net/oscnet/up-df30540c26560597e288fdc15418de64b32.png" width="1366" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#000000">目前，MakerFrame 游戏框架已在 openKylin 社区开源，项目地址如下：</span></strong></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span><span style="color:#0052ff">https://gitee.com/openkylin/maker-frame</span></span></p><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#0052ff">2、完成《侠道仙缘》游戏的开发和各平台适配。</span></strong></span></p><div><p style="text-align:center"><img alt="" height="745" src="https://oscimg.oschina.net/oscnet/up-c7c3e0bed2a046e5195847baed2814b8100.png" width="436" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#000000">目前，MakerFrame 框架引擎和《侠道仙缘》游戏已上架至 openKylin 软件商店，感兴趣的小伙伴赶快下载体验吧~</span></strong></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">04</span></strong></span></em><span><strong><span style="color:#0b43d1">欢迎加入 SIG</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">欢迎所有对 openKylin 社区游戏开发感兴趣的社区爱好者加入我们！</span></span></p><ul><li><span><span style="color:#000000">邮件列表：</span></span></li><li><span><span style="color:#0052ff">markerframe@lists.openkylin.top</span></span></li><li><span><span style="color:#000000">SIG 主页：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/MakerFrame</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:56:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266366</guid>
            <link>https://www.oschina.net/news/266366</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[信通院牵头的服务器无感知（Serverless）国际标准在 ITU 成功立项]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">国际电信联盟第十三研究组（简称 ITU-T SG13）于 2023 年 10 月 23 日-11 月 3 日在瑞士日内瓦召开全体会议，来自世界各国的百余名代表参加会议。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">会上，由中国信息通信研究院（简称「中国信通院」）牵头提出的 ITU-T Y.FaaS-reqts「Cloud computing - Functional requirements of function as a service（云计算-函数即服务功能要求）」国际标准成功立项，并计划于 2025 年正式发布。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">本国际标准依托中国信通院牵头制定的行业标准 YD/T 3764.9-2021《云计算服务客户信任体系能力要求，第 9 部分：函数即服务》提出。本标准计划给出函数即服务（FaaS）的清晰定义，界定 FaaS 与服务器无感知（Serverless）计算、云计算之间的关系，梳理 FaaS 与周边生态的交互关系，并详细列出 FaaS 的功能要求，同时将通过典型场景下 FaaS 的应用案例辅助验证本标准的适用性与准确性。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">FaaS 是 Serverless 计算最典型的形态，Serverless 体现了将基础设施资源抽象成按需使用的服务，用户只需关注应用逻辑，而无需管理复杂的基础设施运维工作的设计模式，被视作云计算的下一步。中国信通院在此领域深耕多年，目前已建立国内十分完善的 Serverless 标准与评估体系，涵盖 Serverless 计算、Serverless 工具、泛 Serverless 化服务等多个维度。未来，中国信通院将针对 Serverless 性能基准、Serverless BaaS 服务、典型 Serverless 应用场景解决方案等领域进一步开展深入研究。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:45:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266363</guid>
            <link>https://www.oschina.net/news/266363</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英伟达发布 AI 芯片 H200]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>英伟达昨晚正式发布了 AI 芯片 H100 GPU 的后续产品<strong> HGX H200 GPU</strong>，可大幅提高大语言模型的能力。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b02e195462bf252f5b2f437a4a1ecdeca2d.png" referrerpolicy="no-referrer"></p><p>据悉，HGX H200 GPU 基于英伟达的「Hopper」架构，相比前代产品内存带宽增加了 1.4 倍，内存容量增加了 1.8 倍。H200 GPU 使用了 HBM3e 内存的芯片，能够以每秒 4.8 TB 的速度提供 141GB 的内存。</p><p>英伟达表示，H200 更大、更快的内存可加快生成式人工智能和大语言模型的速度，与 H100 GPU 相比，H200 在处理 Llama2 等大语言模型时可将推理速度提高 2 倍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b6cc928aec01bd10e6b92f2644ee04f7881.png" referrerpolicy="no-referrer"></p><p>H200 还与已经支持 H100 的系统兼容。英伟达表示，客户在添加 H200 时不需要做任何改动。亚马逊、谷歌、微软和甲骨文的云计算部门将在明年率先使用到新的 GPU。</p><p>预计 H200 将于 2024 年第二季度上市，届时将与 AMD 的 MI300X GPU 展开竞争。与 H200 相似，AMD 的新芯片相比前代产品拥有更多内存，这对运行大型语言模型的推理计算有帮助。</p><p>据美国金融机构 Raymond James 透露，H100 芯片的成本仅为 3320 美元，但英伟达对其客户的批量价格却高达 2.5 万至 4 万美元。这使得 H100 的利润率可能高达 1000%，成为有史以来最赚钱的芯片之一。</p><p>在训练大型语言模型时，通常需要数千个 H100 集群协同工作，因此科技巨头、初创公司和政府机构都在争夺英伟达有限的芯片供应。</p><p>由于对其产品的需求看似无穷无尽，英伟达今年的销售额大幅增长，股价上涨了 230%，市值突破了 1.2 万亿美元大关。截至周一收盘，该股收涨 0.59%，报 486.2 美元。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:42:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266361</guid>
            <link>https://www.oschina.net/news/266361</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TGFX —— 跨平台 2D 绘图引擎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TGFX (Tencent Graphics)&nbsp;是一个轻量级 2D 图形库，设计用于渲染文本、几何图形和图像。它提供高性能的 API，可在各种 GPU 硬件和软件平台上运行，包括 iOS、Android、macOS、Windows、Linux、Web 等。</p><p>TGFX 最初是作为 PAG 项目的核心组件创建的，从 4.0 版开始成为 libpag 库的默认图形引擎。它的主要目标是在保持更小二进制文件大小的同时，为 Skia 图形库提供令人信服的替代方案。随着时间的推移，它已被许多其他产品采用，如 Hippy、腾讯文档和各种视频编辑应用程序。</p><p style="margin-left:0px; margin-right:0px"><strong style="color:#1a1a1a">包体优化</strong></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>TGFX 最终以 400K 左右的大小覆盖了 Skia 近 2M 包体的绝大部分功能。核心优化策略主要有两点：</span></p><p><img height="231" src="https://static.oschina.net/uploads/space/2023/1108/105501_oKgt_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start"><strong style="color:#1a1a1a">调度优化</strong></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>TGFX 并不只是做 Skia 的简化，还把一些在业务上调用起来非常复杂的通用性流程进行了抽</span><span>象封装</span><span>：</span></p><p><img alt="" height="102" src="https://static.oschina.net/uploads/space/2023/1108/105526_HLW4_4252687.png" width="700" referrerpolicy="no-referrer"></p><p>在性能和架构方面，还做了这些额外的优化：</p><ul><li>默认开启了 HardwareBuffer 的支持，来全面加速纹理的提交，包括 Android 端。</li><li>暴露了引擎内部 Path 对应的 GPU 高速缓存，避免矢量绘制充分进行三角剖分操作。</li><li>GPU 对象支持在任意线程释放，等关联的上下文激活时才清理，避免随机 Crash 问题。</li><li>约束图片解码完会尽可能只缓存 GPU 的纹理部分，理论上全局可以降低一半的内存占用。</li><li>将绝大部分缓存都交给了上层业务精确管理，避免随机绘制的缓存持续占用额外的内存。</li><li>在全平台都实现了默认字体的读取能力，包括浏览器，避免下载上百兆 CJK 字体的压力。</li><li>增加了对各种硬解视频帧格式的直接绘制能力，可以一次性上屏无需通过 CPU 转换格式。</li><li>放弃了 SKSL 的统一 Shader 语言设计，更加符合原生接口调用习惯，既节省了包体，也减少了 GPU Program 的编译耗时。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 02:37:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tgfx</guid>
            <link>https://www.oschina.net/p/tgfx</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 面向 AI 的下一代富文本编辑器 AiEditor]]>
            </title>
            <description>
                <![CDATA[<p><img src="https://gitee.com/aieditor-team/aieditor/raw/main/docs/assets/image/screenshot.png" alt="screenshot.png" referrerpolicy="no-referrer"></p><h1><a id="user-content-aieditor" class="anchor" href="https://gitee.com/aieditor-team/aieditor#aieditor"></a>AiEditor</h1><p>关于 AiEditor</p><blockquote><p>AiEditor 是一个面向 AI 的下一代富文本编辑器，她基于 Web Component，因此支持 Layui、Vue、React、Angular 等几乎任何前端框架。她适配了 PC Web 端和手机端，并提供了，亮色，和 暗色，两个主题。除此之外，她还提供了灵活的配置，开发者可以方便的使用其开发任何文字编辑的应用。</p></blockquote><h2><a id="user-content-在线演示" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%9C%A8%E7%BA%BF%E6%BC%94%E7%A4%BA"></a>在线演示</h2><p><a href="https://gitee.com/link?target=http%3A%2F%2Faieditor.jpress.cn">http://aieditor.jpress.cn</a></p><h2><a id="user-content-已完善" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%B7%B2%E5%AE%8C%E5%96%84"></a>已完善</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 基础：标题、正文、字体、字号、加粗、斜体、下划线、删除线、链接、行内代码、上标、下标、分割线、引用、打印</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 增强：撤回、重做、格式刷、橡皮擦、待办事项、字体颜色、背景颜色、Emoji 表情、对齐方式、行高、有（无）序列表、段落缩进、强制换行</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 附件：支持图片、视频、文件功能，支持选择上传、粘贴上传、拖拽上传、支持拖动调整大小...</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 代码：行内代码、代码块、代码语言选择</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 表格：左增右增、左减右减、上增下增、上减下减、合并单元格、解除合并</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> A I：AI 续写、AI 优化、AI 校对、AI 翻译、自定义 AI 菜单及其 Prompts</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 更多：亮色主题、暗色主题、手机版适配、全屏编辑、@某某某（提及）...</li></ul><h2><a id="user-content-待完善计划中" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%BE%85%E5%AE%8C%E5%96%84%E8%AE%A1%E5%88%92%E4%B8%AD"></a>待完善（计划中...）</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 国际化</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 团队协作</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 自动化测试</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 插入图片</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 图生图（AI 图片优化）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 一键排版</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 进一步强化增贴功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 上传视频自动获取缩略图</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> WORD 导入、导出</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> PDF 导出、PDF 预览</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 类腾讯文档 UI 风格</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 类 Notion 拖拽功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 更多的大模型对接：文心一言、ChatGPT</li></ul><h2><a id="user-content-构建运行" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E6%9E%84%E5%BB%BA%E8%BF%90%E8%A1%8C"></a>构建&amp;运行</h2><p><strong>构建</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://gitee.com/aieditor-team/aieditor.git</span><span id="LC2" class="line"></span><span id="LC3" class="line"><span class="nb">cd </span>aieditor</span><span id="LC4" class="line"></span><span id="LC5" class="line"><span class="c"># 安装依赖</span></span><span id="LC6" class="line">npm <span class="nb">install</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>运行</strong></p><p>修改 <code>demos/main.ts</code> 下的内容为：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">点击输入内容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一个面向 AI 的开源富文本编辑器。输入，空格 + "/" 可以快速弹出 AI 菜单哦 </span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">ai</span><span class="p">:</span><span class="p">{</span></span><span id="LC6" class="line"><span class="na">model</span><span class="p">:</span><span class="p">{</span></span><span id="LC7" class="line"><span class="na">xinghuo</span><span class="p">:</span><span class="p">{</span></span><span id="LC8" class="line"><span class="na">appId</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC9" class="line"><span class="na">apiKey</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC10" class="line"><span class="na">apiSecret</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="p">}</span></span><span id="LC13" class="line"><span class="p">}</span></span><span id="LC14" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>或者直接移除 AI 的配置，如下所示（移除后，则不能使用 AI 功能）：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">点击输入内容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一个面向 AI 的开源富文本编辑器。输入，空格 + "/" 可以快速弹出 AI 菜单哦 </span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>然后再命令行下执行：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm run dev</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-ai-功能配置" class="anchor" href="https://gitee.com/aieditor-team/aieditor#ai-%E5%8A%9F%E8%83%BD%E9%85%8D%E7%BD%AE"></a>AI 功能配置</h2><ul><li>1、去科大讯飞注册账号 <a href="https://gitee.com/link?target=https%3A%2F%2Fxinghuo.xfyun.cn">https://xinghuo.xfyun.cn</a></li><li>2、在科大讯飞服务管理中（<a href="https://gitee.com/link?target=https%3A%2F%2Fconsole.xfyun.cn%2Fservices%2Fbm2">https://console.xfyun.cn/services/bm2</a> ） 获取 appId、apiKey、apiSecret。</li><li>3、在配置中添加科大讯飞星火大模型配置</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">点击输入内容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一个面向 AI 的开源富文本编辑器。</span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">ai</span><span class="p">:</span><span class="p">{</span></span><span id="LC6" class="line"><span class="na">model</span><span class="p">:</span><span class="p">{</span></span><span id="LC7" class="line"><span class="na">xinghuo</span><span class="p">:</span><span class="p">{</span></span><span id="LC8" class="line"><span class="na">appId</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC9" class="line"><span class="na">apiKey</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC10" class="line"><span class="na">apiSecret</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="p">}</span></span><span id="LC13" class="line"><span class="p">}</span></span><span id="LC14" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 02:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/aieditor-team/aieditor</guid>
            <link>https://gitee.com/aieditor-team/aieditor</link>
        </item>
        <item>
            <title>
                <![CDATA[Linux 基金会创建高性能软件基金会 (HPSF)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linux 基金会<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-announces-intent-to-form-high-performance-software-foundation-hpsf" target="_blank">宣布</a>，他们正在组建<strong>高性能软件基金会</strong>(High Performance Software Foundation, HPSF)，以帮助推进高性能计算 (HPC) 核心开源项目的发展，包括 Spack, Kokkos, AMReX, VTK-m, HPCToolkit, E4S, Charliecloud, WarpX，以及其他面向 HPC 的项目。</p><p>部分国家实验室，知名科技公司如英特尔、英伟达和其他利益相关者已经参与其中（暂未发现 AMD 参与）。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1d45e285c4d0bd80c3829c1c4df3a8b4906.png" referrerpolicy="no-referrer"></p><p>HPSF 已制定了明确的目标：</p><ul><li>成为高性能软件生态系统中关键项目的中立家园；</li><li>在开源社区和组织中推广 HPSF 项目的使用；</li><li>提供透明的治理模式，让政府、行业和学术界的利益相关者共同管理生态系统；</li><li>提供清晰的路径来孵化和启动有前景的新项目；</li><li>通过提供 CI 和 turn-key 构建，确保 HPC 软件可访问且可靠；</li><li>通过与 CNCF 和 OpenSSF 合作，确保 HPC 软件安全并为上云做好准备；</li><li>赞助活动和培训，为 HPSF 生态系统中的软件培养一支多元化、熟练的劳动力队伍。</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-announces-intent-to-form-high-performance-software-foundation-hpsf" target="_blank">更多内容查看官方新闻稿</a></u>。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 02:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266356/lf-high-performance-software-foundation-hpsf</guid>
            <link>https://www.oschina.net/news/266356/lf-high-performance-software-foundation-hpsf</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | GPU 架构与计算入门指南]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><img src="https://oscimg.oschina.net/oscnet/86cf28df-e180-4a38-9a4b-768dae1aa92b.jpg" referrerpolicy="no-referrer"></p><p><span><span>大多数工程师对 CPU 和顺序编程都十分熟悉，这是因为自从他们开始编写 CPU 代码以来，就与之密切接触。然而，对于 GPU 的内部工作原理及其独特之处，他们的了解则相对较少。过去十年，由于 GPU 在深度学习中得到广泛应用而变得极为重要。因此，每位软件工程师都有必要了解其基本工作原理。本文旨在为读者提供这方面的背景知识。</span></span></p><p>&nbsp;</p><p><span><span>本文作者为软件工程师 Abhinav Upadhyay，他在《大规模并行处理器编程》第四版（Hwu 等）的基础上编写了本文大部分内容，其中介绍了包括 GPU 体系结构和执行模型等内容。当然，文中 GPU 编程的基本概念和方法同样适用于其他供应商的产品。</span></span></p><p>&nbsp;</p><p style="text-align:left"><span><span>（本文由 OneFlow 编译发布，转载请联系授权。</span><span>原文：</span>https://codeconfessions.substack.com/p/gpu-computing）</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>作者 | Abhinav Upadhyay</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>OneFlow 编译</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>翻译｜宛子琳、杨婷</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><strong><span><span><strong><span style="color:#f6ab00">1</span></strong></span></span></strong></span></span></p><span id="OSC_h2_1"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><strong><span><span style="color:#1e2380"><strong><span style="color:#1e2380">比较 CPU 与 GPU</span></strong></span></span></strong></span></span></p><p><span style="color:#3f3f3f"><span><strong><span><span>&nbsp;</span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">首先，我们会比较 CPU 和 GPU，这能帮助我们更好地了解 GPU 的发展状况，但这应该作为一个独立的主题，因为我们难以在一节中涵盖其所有的内容。因此，我们将着重介绍一些关键点。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">CPU 和 GPU 的主要区别在于它们的设计目标。CPU 的设计初衷是执行顺序指令[1]。一直以来，为提高顺序执行性能，CPU 设计中引入了许多功能。其重点在于减少指令执行时延，使 CPU 能够尽可能快地执行一系列指令。这些功能包括指令流水线、乱序执行、预测执行和多级缓存等（此处仅列举部分）。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">而 GPU 则专为大规模并行和高吞吐量而设计，但这种设计导致了中等至高程度的指令时延。这一设计方向受其在视频游戏、图形处理、数值计算以及现如今的深度学习中的广泛应用所影响，所有这些应用都需要以极高的速度执行大量线性代数和数值计算，因此人们倾注了大量精力以提升这些设备的吞吐量。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我们来思考一个具体的例子：由于指令时延较低，CPU 在执行两个数字相加的操作时比 GPU 更快。在按顺序执行多个这样的计算时，CPU 能够比 GPU 更快地完成。然而，当需要进行数百万甚至数十亿次这样的计算时，由于 GPU 具有强大的大规模并行能力，它将比 CPU 更快地完成这些计算任务。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我们可以通过具体数据来进行说明。硬件在数值计算方面的性能以每秒浮点运算次数（FLOPS）来衡量。NVIDIA 的 Ampere A100 在 32 位精度下的吞吐量为 19.5 TFLOPS。相比之下，Intel 的 24 核处理器在 32 位精度下的吞吐量仅为 0.66 TFLOPS（2021 年）。同时，随时间推移，GPU 与 CPU 在吞吐量性能上的差距逐年扩大。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">下图对 CPU 和 GPU 的架构进行了比较。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><img height="auto" src="https://oscimg.oschina.net/oscnet/bdd6d31c-c5ec-4301-a326-11b2bdc1264b.png" width="auto" referrerpolicy="no-referrer"><span style="color:#888888"><em><span style="color:#888888">图 1：CPU 与 GPU 的芯片设计对比。引自《CUDA C++编程指南》（NVIDIA）</span></em></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">如图所示，CPU 在芯片领域中主要用于降低指令时延的功能，例如大型缓存、较少的算术逻辑单元（ALU）和更多的控制单元。与此相比，GPU 则利用大量的 ALU 来最大化计算能力和吞吐量，只使用极小的芯片面积用于缓存和控制单元，这些元件主要用于减少 CPU 时延。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><strong><span>时延容忍度<strong style="color:#3f3f3f"><span>和</span></strong>高吞吐量</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">或许你会好奇，GPU 如何能够容忍高时延并同时提供高性能呢？GPU 拥有大量线程和强大的计算能力，使这一点成为可能。即使单个指令具有高延迟，GPU 也会有效地调度线程运行，以便它们在任意时间点都能利用计算能力。例如，当某些线程正在等待指令结果时，GPU 将切换到运行其他非等待线程。这可确保 GPU 上的计算单元在所有时间点都以其最大容量运行，从而提供高吞吐量。稍后当我们讨论 kernel 如何在 GPU 上运行时，我们将对此有更清晰的了解。</span></span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><span><strong><span style="color:#f6ab00">2</span></strong></span></span></span></span></p><span id="OSC_h2_2"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><span style="color:#1e2380"><strong><span style="color:#1e2380">GPU 架构</span></strong></span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我们已经了解到 GPU 有利于实现高吞吐量，但它们是通过怎样的架构来实现这一目标的呢？本节将对此展开探讨。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><strong><span>GPU 的计算架构</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">GPU 由一系列流式多处理器（SM）组成，其中每个 SM 又由多个流式处理器、核心或线程组成。例如，NVIDIA H100 GPU 具有 132 个 SM，每个 SM 拥有 64 个核心，总计核心高达 8448 个。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">每个 SM 都拥有一定数量的片上内存（on-chip memory），通常称为共享内存或临时存储器，这些共享内存被所有的核心所共享。同样，SM 上的控制单元资源也被所有的核心所共享。此外，每个 SM 都配备了基于硬件的线程调度器，用于执行线程。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">除此之外，每个 SM 还配备了几个功能单元或其他加速计算单元，例如张量核心（tensor core）或光线追踪单元（ray tracing unit），用于满足 GPU 所处理的工作负载的特定计算需求。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><span><img height="auto" src="https://oscimg.oschina.net/oscnet/c25e87f8-efab-4e56-b903-e657474e8026.png" width="auto" referrerpolicy="no-referrer"></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="color:#494949; text-align:center"><span style="color:#3f3f3f"><span><span><span style="color:#888888"><em><span style="color:#888888">图 2：GPU 的计算架构</span></em></span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">接下来，让我们深入剖析 GPU 内存并了解其中的细节。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span>GPU 的内存架构</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span>&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 具有多层不同类型的内存，每一层都有其特定用途。下图显示了 GPU 中一个 SM 的内存层次结构。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/94a4fe5d-80dd-4461-b5af-4587fd012f16.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">图 3：基于康奈尔大学虚拟工作坊（Virtual Workshop）的 GPU 内存架构</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">让我们对其进行剖析：</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><ul style="margin-left:8px; margin-right:8px"><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">寄存器</span></strong><span style="color:#3f3f3f">：让我们从寄存器开始。GPU 中的每个 SM 都拥有大量寄存器。例如，NVIDIA 的 A100 和 H100 模型中，每个 SM 拥有 65536 个寄存器。这些寄存器在核心之间共享，并根据线程需求动态分配。在执行过程中，每个线程都被分配了私有寄存器，其他线程无法读取或写入这些寄存器。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">常量缓存</span></strong><span style="color:#3f3f3f">：接下来是芯片上的常量缓存。这些缓存用于缓存 SM 上执行的代码中使用的常量数据。为利用这些缓存，程序员需要在代码中明确将对象声明为常量，以便 GPU 可以将其缓存并保存在常量缓存中。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">共享内存</span></strong><span style="color:#3f3f3f">：每个 SM 还拥有一块共享内存或临时内存，它是一种小型、快速且低时延的片上可编程 SRAM 内存，供运行在 SM 上的线程块共享使用。共享内存的设计思路是，如果多个线程需要处理相同的数据，只需要其中一个线程从全局内存（global memory）加载，而其他线程将共享这一数据。合理使用共享内存可以减少从全局内存加载重复数据的操作，并提高内核执行性能。共享内存还可以用作线程块（block）内的线程之间的同步机制。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">L1 缓存</span></strong><span style="color:#3f3f3f">：每个 SM 还拥有一个 L1 缓存，它可以缓存从 L2 缓存中频繁访问的数据。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">L2 缓存</span></strong><span style="color:#3f3f3f">：所有 SM 都共享一个 L2 缓存，它用于缓存全局内存中被频繁访问的数据，以降低时延。需要注意的是，L1 和 L2 缓存对于 SM 来说是公开的，也就是说，SM 并不知道它是从 L1 还是 L2 中获取数据。SM 从全局内存中获取数据，这类似于 CPU 中 L1/L2/L3 缓存的工作方式。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">全局内存</span></strong><span style="color:#3f3f3f">：GPU 还拥有一个片外全局内存，它是一种容量大且带宽高的动态随机存取存储器（DRAM）。例如，NVIDIA H100 拥有 80 GB 高带宽内存（HBM），带宽达每秒 3000 GB。由于与 SM 相距较远，全局内存的时延相当高。然而，芯片上还有几个额外的存储层以及大量的计算单元有助于掩饰这种时延。</span></span></span></span></p></li></ul><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">现在我们已经了解 GPU 硬件的关键组成部分，接下来我们深入一步，了解执行代码时这些组件是如何发挥作用的。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">3</span></strong></span></span></span></p><span id="OSC_h2_3"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">了解 GPU 的执行模型</span></strong></span></span></span></p><p>&nbsp;</p><p style="color:#494949"><span style="color:#3f3f3f"><span>&nbsp;</span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">要理解 GPU 如何执行 kernel，我们首先需要了解什么是 kernel 及其配置。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>CUDA Kernel 与线程块简介</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">CUDA 是 NVIDIA 提供的编程接口，用于编写运行在其 GPU 上的程序。在 CUDA 中，你会以类似于 C/C++函数的形式来表达想要在 GPU 上运行的计算，这个函数被称为 kernel。kernel 在并行中操作向量形式的数字，这些数字以函数参数的形式提供给它。一个简单的例子是执行向量加法的 kernel，即接受两个向量作为输入，逐元素相加，并将结果写入第三个向量。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">要在 GPU 上执行 kernel，我们需要启用多个线程，这些线程总体上被称为一个网格（grid），但网格还具有更多的结构。一个网格由一个或多个线程块（有时简称为块）组成，而每个线程块又由一个或多个线程组成。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">线程块和线程的数量取决于数据的大小和我们所需的并行度。例如，在向量相加的示例中，如果我们要对 256 维的向量进行相加运算，那么可以配置一个包含 256 个线程的单个线程块，这样每个线程就可以处理向量的一个元素。如果数据更大，GPU 上也许没有足够的线程可用，这时我们可能需要每个线程能够处理多个数据点。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/7e96e636-6948-48f2-adc5-bbc37c3a1f19.png" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">图 4：线程块网格。引自《CUDA C++编程指南》（NVIDIA）</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">编写一个 kernel 需要两步。第一步是运行在 CPU 上的主机代码，这部分代码用于加载数据，为 GPU 分配内存，并使用配置的线程网格启动 kernel；第二步是编写在 GPU 上执行的设备（GPU）代码。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">对于向量加法示例，下图显示了主机代码。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/bc098e64-ceb7-4b8c-8e4b-607b56d471d4.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">图 5：CUDA kernel 的主机代码，用于将两个向量相加。</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">下图为设备代码，它定义了实际的 kernel 函数。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/1d2f6102-c267-4b78-ba9e-880c832009d1.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">图 6：包含向量相加 kernel 定义的设备代码。</span></em></span></span></span></p><blockquote><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由于本文的重点不在于教授 CUDA，因此我们不会更深入地讨论此段代码。现在，让我们看看在 GPU 上执行 kernel 的具体步骤。</span></span></span></blockquote><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">4</span></strong></span></span></span></p><span id="OSC_h2_4"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">在 GPU 上执行 Kernel 的步骤</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><strong style="color:#3f3f3f"><span>1. 将数据从主机复制到设备</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">在调度执行 kernel 之前，必须将其所需的全部数据从主机（即 CPU）内存复制到 GPU 的全局内存（即设备内存）。</span><span style="color:#3f3f3f">尽管如此，在最新的 GPU 硬件中，我们还可以使用统一虚拟内存直接从主机内存中读取数据（可参阅论文《EMOGI: Efficient Memory-access for Out-of-memory Graph-traversal in GPUs》）。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>2. SM 上线程块的调度</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">当 GPU 的内存中拥有全部所需的数据后，它会将线程块分配给 SM。同一个块内的所有线程将同时由同一个 SM 进行处理。为此，GPU 必须在开始执行线程之前在 SM 上为这些线程预留资源。在实际操作中，可以将多个线程块分配给同一个 SM 以实现并行执行。</span></span></span></p><p style="color:#494949">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/a5075db0-bd48-4627-a342-c93f06482fca.png" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">图 7：将线程块分配给 SM</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由于 SM 的数量有限，而大型 kernel 可能包含大量线程块，因此并非所有线程块都可以立即分配执行。GPU 会维护一个待分配和执行的线程块列表，当有任何一个线程块执行完成时，GPU 会从该列表中选择一个线程块执行。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>3. 单指令多线程 (SIMT) 和</span></strong><strong><span>线程束（Warp）</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">众所周知，一个块（block）中的所有线程都会被分配到同一个 SM 上。但在此之后，线程还会进一步划分为大小为 32 的组（称为 warp[2]），并一起分配到一个称为处理块（processing block）的核心集合上进行执行。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">SM 通过获取并向所有线程发出相同的指令，以同时执行 warp 中的所有线程。然后这些线程将在数据的不同部分，同时执行该指令。在向量相加的示例中，一个 warp 中的所有线程可能都在执行相加指令，但它们会在向量的不同索引上进行操作。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由于多个线程同时执行相同的指令，这种 warp 的执行模型也称为单指令多线程 （SIMT）。这类似于 CPU 中的单指令多数据（SIMD）指令。</span></span></span></p><blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">Volta 及其之后的新一代 GPU 引入了一种替代指令调度的机制，称为独立线程调度（Independent Thread Scheduling）。它允许线程之间完全并发，不受 warp 的限制。独立线程调度可以更好地利用执行资源，也可以作为线程之间的同步机制。本文不会涉及独立线程调度的相关内容，但你可以在 CUDA 编程指南中了解更多相关信息。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f">4. Warp 调度和时延容忍度</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">关于 warp 的运行原理，有一些值得讨论的有趣之处。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">即使 SM 内的所有处理块（核心组）都在处理 warp，但在任何给定时刻，只有其中少数块正在积极执行指令。因为 SM 中可用的执行单元数量是有限的。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">有些指令的执行时间较长，这会导致 warp 需要等待指令结果。在这种情况下，SM 会将处于等待状态的 warp 休眠，并执行另一个不需要等待任何结果的 warp。这使得 GPU 能够最大限度地利用所有可用计算资源，并提高吞吐量。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">零计算开销调度：由于每个 warp 中的每个线程都有自己的一组寄存器，因此 SM 从执行一个 warp 切换到另一个 warp 时没有额外计算开销。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">与 CPU 上进程之间的上下文切换方式（context-switching）不同。如果一个进程需要等待一个长时间运行的操作，CPU 在此期间会在该核心上调度执行另一个进程。然而，在 C</span><span style="color:#3f3f3f">PU 中进行上下文切换的代价昂贵，这是因为 CPU 需要将寄存器状态保存到主内存中，并恢复另一个进程的状态。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f">5. 将结果数据从设备复制到主机内存</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">最后，当 kernel 的所有线程都执行完毕后，最后一步就是将结果复制回主机内存。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">尽管我们涵盖了有关典型 kernel 执行的全部内容，但还有一点值得讨论：动态资源分区。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">5</span></strong></span></span></span></p><span id="OSC_h2_5"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">资源划分和占用概念</span></strong></span></span></span></p><p><span style="color:#3f3f3f"><span><span style="color:#494949">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">我们通过一个称为「occupancy（占用率）」的指标来衡量 GPU 资源的利用率，它表示分配给 SM 的 warp 数量与 SM 所能支持的最大 warp 数量之间的比值。为实现最大吞吐量，我们希望拥有 100% 的占用率。然而，在实践中，由于各种约束条件，这并不容易实现。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">为什么我们无法始终达到 100% 的占用率呢？SM 拥有一组固定的执行资源，包括寄存器、共享内存、线程块槽和线程槽。这些资源根据需求和 GPU 的限制在线程之间进行动态划分。例如，在 NVIDIA H100 上，每个 SM 可以处理 32 个线程块、64 个 warp（即 2048 个线程），每个线程块拥有 1024 个线程。如果我们启动一个包含 1024 个线程的网格，GPU 将把 2048 个可用线程槽划分为 2 个线程块。</span></span></span></span></span></p><blockquote><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">动态分区 vs 固定分区：动态分区能够更为有效地利用 GPU 的计算资源。相比之下，固定分区为每个线程块分配了固定数量的执行资源，这种方式并不总是最有效的。在某些情况下，固定分区可能会导致线程被分配多于其实际需求的资源，造成资源浪费和吞吐量降低。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">下面我们通过一个例子说明资源分配对 SM 占用率的影响。假设我们使用 32 个线程的线程块，并需要总共 2048 个线程，那么我们将需要 64 个这样的线程块。然而，每个 SM 一次只能处理 32 个线程块。因此，即使一个 SM 可以运行 2048 个线程，但它一次也只能同时运行 1024 个线程，占用率仅为 50%。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">同样地，每个 SM 具有 65536 个寄存器。要同时执行 2048 个线程，每个线程最多有 32 个寄存器（65536/2048 =32）。如果一个 kernel 需要每个线程有 64 个寄存器，那么每个 SM 只能运行 1024 个线程，占用率同样为 50%。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">占用率不足的挑战在于，可能无法提供足够的时延容忍度或所需的计算吞吐量，以达到硬件的最佳性能。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">高效创建 GPU kernel 是一项复杂任务。我们必须合理分配资源，在保持高占用率的同时尽量降低时延。例如，拥有大量寄存器可以加快代码的运行速度，但可能会降低占用率，因此谨慎优化代码至关重要。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">6</span></strong></span></span></span></p><span id="OSC_h2_6"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">总结</span></strong></span></span></span></p><p><span style="color:#3f3f3f"><span><span style="color:#494949">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">我理解众多的新术语和新概念可能令读者望而生畏，因此文章最后对要点进行了总结，以便快速回顾。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><ul style="margin-left:8px; margin-right:8px"><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 由多个 SM 组成，每个 SM 又包含多个处理核心。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 上存在着一个片外全局内存，通常是高带宽内存（HBM）或动态随机存取内存（DRAM）。它与芯片上的 SM 相距较远，因此时延较高。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 中有两个级别的缓存：片外 L2 缓存和片上 L1 缓存。L1 和 L2 缓存的工作方式类似于 CPU 中的 L1/L2 缓存。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">每个 SM 上都有一小块可配置的共享内存。这块共享内存在处理核心之间共享。通常情况下，线程块内的线程会将一段数据加载到共享内存中，并在需要时重复使用，而不是每次再从全局内存中加载。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">每个 SM 都有大量寄存器，寄存器会根据线程需求进行划分。NVIDIA H100 每个 SM 有 65536 个寄存器。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">在 GPU 上执行 kernel 时，我们需要启动一个线程网格。网格由一个或多个线程块组成，而每个线程块又由一个或多个线程组成。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">根据资源可用性，GPU 会分配一个或多个线程块在 SM 上执行。同一个线程块中的所有线程都会被分配到同一个 SM 上执行。这样做的目的是为了充分利用数据的局部性（data locality），并实现线程之间的同步。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">被分配给 SM 的线程进一步分为大小为 32 的组，称为 warp。一个 warp 内的所有线程同时执行相同的指令，但在数据的不同部分上执行（SIMT）（尽管新一代 GPU 也支持独立的线程调度）。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 根据每个线程的需求和 SM 的限制，在线程之间进行动态资源划分。程序员需要仔细优化代码，以确保在执行过程中达到最高的 SM 占用率。</span></span></span></span></span></p></li></ul><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">脚注</span></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">[1]没错，得益于超线程技术和多核处理器，CPU 也可以并行执行任务。但长期以来，大量工作都致力于提高顺序执行的性能。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">[2]在当前一代的 NVIDIA GPU 中，warp 大小为 32。但在未来的硬件迭代中，这个大小可能会发生改变。</span></span></span></span></span></p><span id="OSC_h2_7"></span><h2 style="margin-left:8px; margin-right:8px">&nbsp;</h2><p style="text-align:left">&nbsp;</p><p style="text-align:left"><span style="color:#3f3f3f"><span><span style="background-color:#ffffff; color:#888888">其他人都在看</span></span></span></p><span id="OSC_h3_8"></span><h3>&nbsp;</h3><ul><li><p><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492657%26idx%3D1%26sn%3Da71795c583da44c805f79630f2ef635a%26chksm%3Dfe426a07c935e3112422680f4942c0b372c01db1e63e044010f03cd72689bce2563e8672136b%26scene%3D21%23wechat_redirect" target="_blank">开源语言大模型的正确姿势</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492610%26idx%3D1%26sn%3D9b92f3efa0d85cb1bb689efab362c3e8%26chksm%3Dfe426a34c935e32200b2d9cc84916eb980ba3c8ab1eceafa9834e38049e5243ca8aa77564a68%26scene%3D21%23wechat_redirect" target="_blank">为什么开源大模型终将胜出</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492849%26idx%3D1%26sn%3D51f53e04b4b97cd9dd38429784015c98%26chksm%3Dfe426ac7c935e3d1b5970441a68c53b6dae05792cd9a244ad8efb40ffc5ab4c60cdf3a7181b0%26scene%3D21%23wechat_redirect" target="_blank">LoRA 和 QLoRA 微调语言大模型</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492767%26idx%3D1%26sn%3Ded8acf6d7e9117b5ab3ea0de8e540460%26chksm%3Dfe426aa9c935e3bfb8b3e2ffc7cb6349f076f4f25d2fbe13b6e8e2c30ea010261c57f8d6cacb%26scene%3D21%23wechat_redirect" target="_blank">OpenAI 规模经济与第二护城河</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492787%26idx%3D1%26sn%3Dc5d16b72e94079bb20e9772cad81e703%26chksm%3Dfe426a85c935e393a9962ab763fc1f06ebaf1bd75331cc089ff61f8655c0e8ecbb8211264544%26scene%3D21%23wechat_redirect" target="_blank">全面对比 GPT-3.5 与 LLaMA 2 微调</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492811%26idx%3D1%26sn%3D916e330a2a4152dab3192635c3e475fa%26chksm%3Dfe426afdc935e3eb2f371ff5f56247c95800ce91a950a89bea871c26ddc4c3d13371acf03978%26scene%3D21%23wechat_redirect" target="_blank">语言大模型推理性能工程：最佳实践</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492618%26idx%3D1%26sn%3Da20f4828b9ab3e3cee3fedfd906e0eb2%26chksm%3Dfe426a3cc935e32a8312ce9efbb4f2640787508d3e811579bbffe918685cdb07a8bd8e3ffc4b%26scene%3D21%23wechat_redirect" target="_blank">LLVM 之父:我的 AI 基础设施软件构建理念</a></span></span></p></li></ul><span id="OSC_h3_9"></span><h3>&nbsp;</h3><p><strong><span style="color:#3f3f3f"><span><span>试用 OneFlow: <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank">github.com/Oneflow-Inc/oneflow/</a></span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank"></a></span></span></strong></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><img src="https://oscimg.oschina.net/oscnet/b316e9d8-4d68-4323-98d4-8e2e62cf5163.png" referrerpolicy="no-referrer"></span></span></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公众号 - OneFlow（OneFlowTechnology）。<br> 如有侵权，请联系 support@oschina.cn 删除。<br> 本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 02:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10140417</guid>
            <link>https://my.oschina.net/oneflow/blog/10140417</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[华为与美团达成合作，正式启动鸿蒙原生应用开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>华为迎来又一个鸿蒙生态的重要合作伙伴，宣布与美团以 HarmonyOS 为基础进行产业创新、技术应用、商业发展等方面展开全面合作，全力支持美团启动开发鸿蒙原生应用工作。</p><p>自 9 月 25 日华为宣布全新 HarmonyOS NEXT 蓄势待发、鸿蒙原生应用全面启动以来，已有金融、旅行、社交等多个领域的企业和开发者陆续宣布加入鸿蒙生态。此次美团成为最新加速融入鸿蒙生态的行业头部伙伴，形成「鸿蒙千帆起」的景象。</p><p>周一，在北京举行的「鸿蒙原生应用开发启动仪式」上，华为终端云服务总裁朱勇刚表示：「很高兴美团成为鸿蒙生态重要的合作伙伴，鸿蒙正在致力于打造一个‘一切皆服务，万物可分享’的新生态。鸿蒙独有的分布式技术，以及一次开发、多端部署，能让美团的服务在手机、平板、车机等设备上无缝流转，为用户提供场景化、智慧化的「服务合时宜」新体验。未来华为希望与美团基于端到端的鸿蒙生态，持续源源不断地的创新，助力美团等互联网企业获取新流量和商机，创造更大的商业价值。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-36c3813f9e9377dea1c3a86232a7923485a.png" referrerpolicy="no-referrer"></p><p>作为扎根本地的中国科技零售企业，美团通过「零售+科技」的战略践行「帮大家吃得更好，生活更好」的公司使命。美团高级副总裁李树斌表示：「美团始终以客户为中心，不断加大在新技术上的研发投入，这与华为鸿蒙操作系统在前沿领先领域的探索努力不谋而合。我们希望与华为共同努力，在鸿蒙系统生态里为用户提供更好的服务和体验。」</p><p>作为鸿蒙生态社交领域的重要伙伴，美团与华为早有深厚的鸿蒙生态合作基础，此前美团就已基于鸿蒙系统特点和用户需求，有针对性地率先开发和适配了多项功能，包括上线华为手机桌面「万能卡片」元服务、Push Kit 实况窗功能等。</p><p>未来，华为将携手美团等更多合作伙伴，持续共同建设鸿蒙生态，依托于 HarmonyOS 原生应用在全场景多设备高效协同、原生智能、更强大的 AI 能力、更高的安全和隐私保护体验等独特的技术优势，展开全方位深层次的合作，为消费者带来更流畅、更智能、更安全的服务体验。</p><p>数据显示，截至今年 8 月份，鸿蒙生态设备数量超过 7 亿台，已有 220 万开发者投入到鸿蒙生态的开发，华为始终与伙伴共享鸿蒙生态新机遇，共创万物互联新未来。</p><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/266107">多家互联网公司急招鸿蒙程序员</a></li><li><a href="https://www.oschina.net/news/265725">美团招兵买马，拟开发鸿蒙系统 App</a></li><li><a href="https://www.oschina.net/news/261747">深圳信息职业技术学院开设「开源鸿蒙班」</a></li><li><a href="https://www.oschina.net/news/252658">HarmonyOS NEXT：使用全自研内核</a></li><li><a href="https://www.oschina.net/news/252385/harmonyos-4">华为正式发布 HarmonyOS 4</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266352</guid>
            <link>https://www.oschina.net/news/266352</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 原生编译的 Solon 回忆录]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start">最近和<code>@雨韵诗泽</code>、<code>@读钓</code>两个小伙伴一起（主要是他们两在出力），适配了<span>&nbsp;</span><strong>Solon Native</strong><span>&nbsp;</span>的第一个开源项目：<a href="https://gitee.com/dromara/neutrino-proxy">dromara/neutrino-proxy</a><span>&nbsp;</span>（里程碑案例啊！有点修行大成的味道了！）。总体来说：</p><ul><li>适配调整完后，代码变化不太大</li><li>整个过程是很麻烦的。因为 graalvm native image 社区版不能调试，只能不断试（发现缺什么，就补什么配置）</li></ul><h3>1、缘起</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2021 年的深秋</span>，有个叫<span>&nbsp;</span><code>@馒头虫</code><span>&nbsp;</span>的男人。跑过来讲，他有个项目需求是（给一个美国大厂做的）：存放空间只有 100M，内存只有 100M，在硬件里运行一个管理界面系统。他研究了 spring native，因为它的基础就太大没过；研究了 go，做复杂的界面系统不好预期没过。所以选择尝试 solon。</p><p style="color:#24292e; text-align:start">于是他种下了一颗 solon native 的种子。开始浇水、施肥。前后一两个月的时间，真的也开花了（最后好像只有 53m 大小）。这 365 万字省去，他怎么不哭呢？</p><p style="color:#24292e; text-align:start">这个男人总结出了三条经验：</p><ul><li>所有的反射需要提前登记（放到特定的配置文件里），并通过配置获取反射导引（比如一个类有哪些字段，哪些方法）</li><li>所有的资源文件获取需要提前登记（放到特定的配置文件里）</li><li>所有的动态编译、类字节码，不能用</li></ul><p style="color:#24292e; text-align:start">说起来，<a href="https://gitee.com/noear/solon">Solon 框架</a><span>&nbsp;</span>真的是好啊（按那男人的讲法：小是真的小，快是真的快）：</p><ul><li>启动快 5 ～ 10 倍；</li><li>qps 高 2～ 3 倍；</li><li>运行时内存节省 1/3 ~ 1/2；</li><li>打包可以缩到 1/2 ~ 1/10；</li></ul><h3>2、认识 APT</h3><p style="color:#24292e; text-align:start">后面很长的时间，我没再碰它（主要是无知，无从下手。懵！）。偶然的一天，路过 mybatis-plus 4.x 项目仓库，看到 APT 这几个字眼。我对 java 确实是无知，百度后才知道神器 lombok 就是基于 APT 实现的。然后，我想起了那个男人总结的三条经验：</p><ul><li>所有的反射需要提前登记</li><li>所有的资源文件获取需要提前登记</li><li>所有的动态编译、类字节码，不能用</li></ul><p style="color:#24292e; text-align:start">是不是可以借助 APT，去提前生成类的代理代码，去完成资源文件、反射的登记？我估计是行的。</p><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的初春</span>，花了一周时间，把类的代理用 APT 在编译时生成了。开心是开心的。但是，怎样获取需要代理的类，成了一个不解的题。路很长。然后，暂时没有然后了！</p><h3>3、认识 AOT</h3><p style="color:#24292e; text-align:start">好多年前就听过 AOT，大概知道它是干嘛的。但是，还是一脸懵。</p><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的春后</span>，有个叫<span>&nbsp;</span><code>@李总</code><span>&nbsp;</span>的男人。他说，我有个项目想要用 solon 的原生编译，而且可以叫个人帮忙搞。最后出现的男人叫<span>&nbsp;</span><code>@读钓</code>，不知道是<span>&nbsp;</span><code>@李总</code><span>&nbsp;</span>忽悠过来的，还是我把他忽悠过来的（后来，据他说是自己跑来的）。他说，我们应该 A,B,C...这么这么搞！</p><p style="color:#24292e; text-align:start">还有个加强版的 AOT。原来如此，原来如此：</p><ul><li>在编译后 -&gt; 运行项目并获取运行中的信息 -&gt; 然后完成各种预编译和登记 -&gt; 再进行原生编译</li><li>一气呵成</li></ul><p style="color:#24292e; text-align:start">这个男人从春天搞到了夏天。成了！（当中略过 365 万字...），一直搞，不知道有没有洗过澡， 有没有换过衣服。</p><h3>4、我们发布第一个 Solon Native 版本</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的夏天</span>，有个新男人来。说是要用 Solon Native。我心里其实没底，原生这东西太难用了。必须得忍住不哭才行。后来他招乎也没打，跑了。</p><p style="color:#24292e; text-align:start">真的是太难用了：</p><ul><li>目前没有哪个框架是开箱即用的（Spring Native 和 Quarkus 也一样）</li><li>框架不一定把生态内的所有包都适配好了</li><li>第三方的包，框架没法照顾到。只能自己试着做些补充登记（没法调试，只能尝试或实验）</li><li>随便升级某个第三方包，就可能不兼容了（需要重新适配）</li></ul><h3>5、你信轮回？</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的深秋</span>，又是一个深秋。男人<span>&nbsp;</span><code>@雨韵诗泽</code>，说想把他的<span>&nbsp;</span><a href="https://gitee.com/dromara/neutrino-proxy">dromara/neutrino-proxy</a><span>&nbsp;</span>开源项目搞成原生编译的。我说，那得忍住不哭才行。他说，他不会哭（其实，他动得不多。哈哈）。<code>@读钓</code>又开始忙了。</p><p style="color:#24292e; text-align:start">说起来，<code>@读钓</code><span>&nbsp;</span>是从春天干到了秋天。终于成了：<a href="https://www.oschina.net/news/264550/solon-2-5-12-released">《Solon v2.5.12 发布，Java 原生编译再起》</a>。我们也是正经的支持 Java 原生编译的生态型框架了。且是，国产的。</p><p style="color:#24292e; text-align:start"><span style="background-color:#ffffff; color:#24292e">开源，让很多人的愿望和努力汇聚一处，也记录了共同的回忆。</span></p><p style="color:#24292e; text-align:start">人生路，且短且长，只怪情深缘浅，你信轮回？</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 01:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266350</guid>
            <link>https://www.oschina.net/news/266350</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果将禁止「摇一摇」跳转广告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tfcaijing.com%2Farticle%2Fpage%2F474a676e737050677a746a63653436332f646c3554773d3d" target="_blank">据时代财经报道</a></u>，互联网大厂内部人士常乐年称，11 月以来，苹果公司已通知国内多家头部 App 要求它们移除陀螺仪权限，摇一摇跳转广告被禁止。</p><p>据报道，11 月以来，苹果公司已通知在线视频软件、短视频软件、音频软件、邮箱软件等多种类型的 App，<strong>要求它们取消摇一摇跳转广告的功能</strong>。常乐年所在公司的 App 也在通知的范围内。他透露，接下来公司可能会发布新版本 App，在苹果的 App Store 上架，新版本将没有摇一摇跳转广告，具体发布时间还不确定。</p><p>另一位广告从业者也证实了这一消息，他的客户也是互联网大厂，旗下有行业头部 App。他说，收到通知的不只是头部 App，还有很多其他的 App，范围很广。</p><p>摇一摇功能调用的是陀螺仪权限，这是一种很早就有的功能，可以用来抢电视红包、识别歌曲等，但现在被用来做广告跳转，而有些手机没有陀螺仪权限开关，用户无法自行关闭。</p><p><img src="https://static.oschina.net/uploads/space/2023/1114/084659_fhVb_2720166.png" referrerpolicy="no-referrer"></p><p>一位手机大厂的工作人员说，这种跳转是 App 开发出来的商业模式，手机厂商很难做系统性的调整。</p><p>中国信息通信研究院此前联合华为、小米、OPPO、阿里巴巴等企业制定了团体标准 T / TAF 078.7—2022，于 2022 年 11 月由电信终端产业协会发布实施，该标准进一步细化了 App 信息窗口通过「摇一摇」等方式触发页面或跳转至第三方应用的相关参数，提出「摇一摇」动作的设备加速度应不小于 15m/s2，转动角度不小于 35°，操作时间不少于 3s 等系列参考数值。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 00:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266344</guid>
            <link>https://www.oschina.net/news/266344</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Kotlin 1.9.20 现已发布，KMP 进入稳定阶段]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><section style="font-size: 15px;box-sizing: border-box;font-style: normal;font-weight: 400;text-align: justify;margin-bottom: 0px;" data-mpa-powered-by="yiban.io"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="margin: 30px 0% 10px;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;background-color: rgb(237, 238, 242);align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="display: flex;width: 100%;flex-flow: column;box-sizing: border-box;" powered-by="xiumi.us"><section style="z-index: auto;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: flex;flex-flow: row;justify-content: flex-start;transform: translate3d(18px, 0px, 0px);-webkit-transform: translate3d(18px, 0px, 0px);-moz-transform: translate3d(18px, 0px, 0px);-o-transform: translate3d(18px, 0px, 0px);margin: -16px 0% 0px;box-sizing: border-box;"><section style="display: inline-block;vertical-align: top;width: 15%;flex: 0 0 auto;height: auto;align-self: flex-start;box-sizing: border-box;"><section style="text-align: center;margin: -16px 0px 0px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img class="rich_pages wxw-img" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/857c41ff-cddd-4928-8250-1a8458f95df4.png" data-w="707" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 auto;align-self: flex-start;min-width: 10%;max-width: 100%;height: auto;box-sizing: border-box;"><section style="transform: translate3d(5px, 0px, 0px);-webkit-transform: translate3d(5px, 0px, 0px);-moz-transform: translate3d(5px, 0px, 0px);-o-transform: translate3d(5px, 0px, 0px);box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;color: rgb(115, 119, 173);padding: 0px 7px;line-height: 1.2;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="box-sizing: border-box;"><strong style="box-sizing: border-box;">记得加关注， Kotlin 之路不迷路！</strong></span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;font-size: 12px;color: rgb(221, 18, 101);line-height: 1.2;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="box-sizing: border-box;">&nbsp; &nbsp; Kotlinlang.org</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section></section></section></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin 1.9.20 版本已发布，适用于所有目标的<strong style="box-sizing: border-box;"> K2 编译器</strong>现已进入<strong style="box-sizing: border-box;">测试版</strong>阶段，<strong style="box-sizing: border-box;">Kotlin Multiplatform </strong>现已进入<strong style="box-sizing: border-box;">稳定阶段</strong><sup style="box-sizing: border-box;">1</sup>。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">以下是此版本的一些亮点：</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><ul class="list-paddingleft-1" style="list-style-type: disc;box-sizing: border-box;padding-left: 40px;list-style-position: outside;"><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">适用于所有目标的 K2 现已进入测试版阶段</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">稳定的 Kotlin Multiplatform</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">用于设置多平台项目的新默认层次结构模板</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin Multiplatform 中全面支持 Gradle 配置缓存</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Native 中默认启用自定义内存分配器</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Native 中垃圾回收器的性能改进</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Wasm 中的新目标和重命名目标，支持最新的 Wasm GC</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Wasm 的标准库中支持 WASI API</p></li></ul></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">有关完整的更改列表，请参阅&nbsp;<strong style="box-sizing: border-box;">Kotlin 1.9.20 最新变化</strong><sup style="font-size: 11px;box-sizing: border-box;">2</sup>或&nbsp;<strong style="box-sizing: border-box;">GitHub 上的版本说明</strong><sup style="font-size: 11px;box-sizing: border-box;">3</sup>。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">适用于所有目标的新 Kotlin K2 编译器已进入测试版阶段</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">JetBrains 的 Kotlin 团队正在继续稳定新 K2 编译器，这将带来重大性能改进，加快新语言功能的开发，统一 Kotlin 支持的所有平台，并为多平台项目提供更好的架构。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;"></strong></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">随着 1.9.20 版本的发布，新 K2 编译器已面向所有平台进入测试版阶段：JVM、Native、JS 和 Wasm。这意味着您现在可以在任何 Kotlin 项目中试用 K2。</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin 团队通过成功编译数十个用户和内部项目，确保了新编译器的质量。大量用户也参与了稳定过程，在他们的项目中试用新 K2 编译器，并报告他们发现的任何问题。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">Kotlin 1.9.20 版本还在 kapt 编译器插件中引入了 K2 支持。</strong>&nbsp;现在，所有必要的 Kotlin 编译器插件都支持 K2。这些包括 kapt、serialization、AtomicFU、Lombok、SAM with receiver、all-open、no-arg、jvm-abi-gen、Android Lint 和 Jetpack Compose 编译器插件。支持 K2 的 Kotlin Symbol Processing (KSP) 将在 Kotlin 1.9.20 发布后一周内发布。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">如果您使用任何其他编译器插件，请查看相关文档以了解其是否与 K2 兼容。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">下一站是 Kotlin 2.0</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">Kotlin 的下一个主要版本是 2.0.0，新 K2 编译器将作为默认的稳定编译器面向所有目标提供。</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">为了尽快解决发现的任何问题，我们计划频繁发布一系列小型 Kotlin 2.0 稳定版本。这些版本将包括 Beta1、Beta2、Beta3、RC1 和 RC2。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">在 Kotlin 2.0.0-RC1 发布时，我们计划确保与其他版本 Kotlin 编译器编译的代码的二进制文件兼容性，并消除使用 K2 编译的二进制文件时的中毒现象。这样您就能够在生产环境中使用新的 K2 编译器。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">参与进来：立即塑造 Kotlin 2.0 并试用 K2 编译器</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">K2 编译器即将完成其稳定过程，并在 Kotlin 2.0 中默认启用。至关重要的是，我们呼吁尽可能多的开发者试用 K2 并报告任何潜在问题。&nbsp;</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">您的反馈将帮助我们解决任何问题，并确保 K2 即使在最复杂的场景中也能完美运行。只需使用 K2 对您的项目进行一次编译就可以为达到 Kotlin 2.0 里程碑做出显著贡献。<strong style="box-sizing: border-box;"> 立即试用 K2！</strong><sup style="box-sizing: border-box;">4</sup></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">如何安装 Kotlin 1.9.20</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">如果您已经在使用<strong style="box-sizing: border-box;">&nbsp;IntelliJ IDEA</strong><sup style="box-sizing: border-box;">5</sup>&nbsp;2023.1 或 2023.2，IDE 会自动建议将 Kotlin 更新到 1.9.20。您也可以按照<strong style="box-sizing: border-box;">这些说明</strong><sup style="box-sizing: border-box;">6</sup>手动更新。IntelliJ IDEA 2023.3 将包含 Kotlin 1.9.20 插件。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">对于 Android Studio Hedgehog (231) 和 Iguana (232)，Kotlin 1.9.20 插件将包含在即将推出的 Android Studio 更新中。如果需要命令行编译器，请从<strong style="box-sizing: border-box;">&nbsp;GitHub 版本页面</strong><sup style="box-sizing: border-box;">7</sup>下载。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">如果您遇到任何问题</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><ul class="list-paddingleft-1" style="list-style-type: disc;box-sizing: border-box;padding-left: 40px;list-style-position: outside;"><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">在&nbsp;<strong style="box-sizing: border-box;">Slack</strong><sup style="font-size: 11px;box-sizing: border-box;">8</sup>（<strong style="box-sizing: border-box;">获得邀请</strong><sup style="font-size: 11px;box-sizing: border-box;">9</sup>）上获取帮助。</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">向我们的问题跟踪器&nbsp;<strong style="box-sizing: border-box;">YouTrack</strong><sup style="box-sizing: border-box;">10</sup>&nbsp;报告问题。</p></li></ul><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">特别感谢我们的 EAP Champions 🥇👏</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">Zac Sweers、Alexander Nozik、Oleg Yukhnevich、Josh Friend、Łukasz Wasylkowski、Simon Marquis、Benoit ‘BoD’ Lubek、Yang、Rustam Musin、Russell Wolf、Jake Wharton、Rick Clephas、Artyom Shendrik、Johannes Svensson、Sterling Albury、David Lopez。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">更多文章和视频</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><ul class="list-paddingleft-1" style="list-style-type: disc;box-sizing: border-box;padding-left: 40px;list-style-position: outside;"><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">「Kotlin 1.9.20 最新变化」文档：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="color: rgb(0, 86, 150);font-size: 14px;box-sizing: border-box;">https://kotlinlang.org/docs/whatsnew1920.html</span></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin 1.9.20 最新变化 YouTube 视频：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(0, 86, 150);box-sizing: border-box;">https://youtu.be/Ol_96CHKqg8</span><br style="box-sizing: border-box;"></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">K2 编译器将在 Kotlin 2.0 中进入稳定状态：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(0, 86, 150);box-sizing: border-box;">https://blog.jetbrains.com/zh-hans/kotlin/2023/02/k2-kotlin-2-0/</span></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin Multiplatform 已经稳定并且可以投入生产环境：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="color: rgb(0, 86, 150);font-size: 14px;box-sizing: border-box;">https://blog.jetbrains.com/kotlin/2023/11/kotlin-multiplatform-stable/</span></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin EAP Champion：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(0, 86, 150);box-sizing: border-box;">https://blog.jetbrains.com/kotlin/2022/11/eap-champions/</span><br style="box-sizing: border-box;"></p></li></ul></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin-top: 10px;margin-bottom: 10px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(120, 85, 245);padding: 10px;box-shadow: rgb(204, 204, 204) 0.2em 0.2em 0.3em;box-sizing: border-box;"><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">相关链接：</strong></p><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: left;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">1. Kotlin Multiplatform 现已进入稳定阶段：</span></p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://blog.jetbrains.com/kotlin/2023/11/kotlin-multiplatform-stable/https://github.com/jetbrains/exposed</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: left;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">2. Kotlin 1.9.20 最新变化：&nbsp;</span></p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">http://kotlinlang.org/docs/whatsnew1920.html</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">3. GitHub 上的版本说明：</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://github.com/JetBrains/kotlin/releases/tag/v1.9.20</span></p><p style="margin-bottom: 0px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">4. 立即试用 K2！：</span></p><p style="margin-bottom: 0px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;color: rgb(51, 122, 183);">https://kotlinlang.org/docs/whatsnew1920.html</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">5. IntelliJ IDEA：</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://www.jetbrains.com.cn/idea/download/</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">6. 这些说明：</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://kotlinlang.org/docs/releases.html#update-to-a-new-release</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">7. GitHub 版本页面:&nbsp;</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="color: rgb(51, 122, 183);font-size: 14px;text-align: left;box-sizing: border-box;">https://github.com/JetBrains/kotlin/releases/tag/v1.9.20</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">8. Slack:&nbsp;</span></p><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">http://kotlinlang.slack.com/</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">9. 获得邀请：</span></p><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://surveys.jetbrains.com/s3/kotlin-slack-sign-up</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">10. YouTrack：</span></p><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://youtrack.jetbrains.com/issues/KT</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 10px 0px 0px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding: 0px 0px 0px 8px;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(125, 125, 125);font-size: 12px;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">本博文英文原作者：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Andrey Polyakov</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section><section style="margin: 10px 0% 0px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;background-position: 97.529% 66.6681%;background-repeat: repeat;background-size: 171.01%;background-attachment: scroll;align-self: flex-start;flex: 0 0 auto;height: auto;background-image: url(&quot;https://oscimg.oschina.net/oscnet/0eddb263-e655-40fb-bb29-ad40b1263907.png&quot;);box-sizing: border-box;"><section style="text-align: justify;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;padding: 26px;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="margin: -9px 0px 7px;box-sizing: border-box;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(248, 248, 248);box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">这就是 Kotlin 编程语言</strong></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">简洁、跨平台、且有趣！</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 0px;box-sizing: border-box;" powered-by="xiumi.us"><section class="mp_profile_iframe_wrp" style="box-sizing: border-box;"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-id="Mzg4MzkxMzg3MQ==" data-pluginname="mpprofile" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/y4ibuu6gd7d4NyzPduLLqtqddBasicL77gAgbLQD89CyYm1n7icODFhBr3xMoloOA7yicfjR8Bv0oaRP3CJuRLIO4Q/0?wx_fmt=png" data-nickname="Kotlin 开发者" data-alias="" data-signature="现代、简洁、安全的编程语言，由 JetBrains 打造。面向服务器、Android、Web 和原生平台，提供多种在平台间重用代码的方式以实现高效编程。官网：kotlinlang.org" data-from="0" data-is_biz_ban="0"></mp-common-profile></section></section><section style="text-align: center;margin: 7px 0px 0px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;width: 45%;height: auto;box-sizing: border-box;"><img class="rich_pages wxw-img" data-ratio="0.4119760479041916" data-s="300,640" src="https://oscimg.oschina.net/oscnet/3798f3e4-8493-496c-9edb-4fd1944d295e.png" data-w="835" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section></section></section></section></section><p style="display: none;margin-bottom: 0px;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - JetBrains（JetBrainsChina）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 11:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5494143/blog/10142143</guid>
            <link>https://my.oschina.net/u/5494143/blog/10142143</link>
            <author>
                <![CDATA[JetBrains 中国]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JetBrains 推出新的 C/C++ IDE：CLion Nova]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">JetBrains 宣布推出全新的&nbsp;CLion Nova 早期预览版，<span style="background-color:#ffffff">使用 ReSharper C++/Rider C++ 语言引擎而不是 CLion「传统」引擎。「我们将新的实验预览版命名为 CLion Nova，而当前的 CLion 版本则是 CLion Classic。未来，我们计划将 CLion Nova 并入 CLion Classic。我们不打算推出新产品。」</span></span></p><p><span style="color:#000000">该公司打算先收集用户反馈，然后在 2024 年的某个时刻根据具体的反馈结果将&nbsp;<span style="background-color:#ffffff">CLion Nova 合并到&nbsp;CLion Classic。在此之前，预览版本将免费提供，并且可以与 CLion (Classic) 安装并行安装。目前&nbsp;CLion Nova&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Ftoolbox-app%2F" target="_blank">只能通过 Toolbox 应用程序</a><span style="color:#000000">获得。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-d8f4e7450a6ce6527151f7d97e3629a6f59.png" width="500" referrerpolicy="no-referrer"></span></span></p><p><span style="color:#000000">CLion Nova&nbsp;重点关注 IDE 的响应能力、准确性和性能。有两个主要目标：</span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">解决 CLion 因使用「传统」引擎而导致的长期存在的<strong>性能</strong>和<strong>质量问题。</strong></span></li><li><span style="color:#000000">统一 JetBrains 所有 C++ 工具（即 CLion、Rider 和 ReSharper C++）的用户体验。</span></li></ul><p><span style="color:#000000">&nbsp;<img alt="" height="211" src="https://oscimg.oschina.net/oscnet/up-d18769c1e056c9bdb1ea86ad5ce12804963.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">CLion Nova 仍然使用两种 C++ 语言引擎：基于 clangd 的引擎和 ReSharper C++/Rider 使用的引擎，且&nbsp;CLion Nova 包含了 CLion Classic 的大部分功能。</span></p><p><span style="color:#000000">CLion Nova </span>的性能优势主要在于：</p><ul style="margin-left:0; margin-right:0"><li>更快的高亮显示速度，尤其是在代码增量更新的情况下</li><li>响应速度更快的&nbsp;UI</li><li>查找使用速度更快</li><li>重构时的冻结和挂起情况显着减少</li><li>更快的测试索引</li></ul><p>此外，CLion Nova 还增添了一些 CLion Classic 中未包含的新功能：&nbsp;</p><ul style="margin-left:0; margin-right:0"><li>新的重构，例如<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23intro_field" target="_blank">引入字段</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23namespace_alias" target="_blank">引入命名空间别名</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23using_enum" target="_blank">引入 using 枚举</a>以及<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23convert_to_scoped" target="_blank">转换为作用域枚举</a>。</li><li>新的检查、快速修复和意图，例如冗余限定符、用明确的类型声明替换<code>auto</code>以及<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FCode_Style_Assistance_in_CPP.html%23sort_includes" target="_blank"><code>#include</code>指令排序</a>。</li><li>新的代码提示，例如<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FSettings_Inlay_Hints_CPP_Other.html%23preprocessor-directive" target="_blank">预处理指令提示</a>﻿和&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FInline_Parameter_Name_Hints.html%23push-to-hint-mode" target="_blank">Push-to-Hint 模式</a>。</li></ul><p><img alt="" height="183" src="https://oscimg.oschina.net/oscnet/up-13d64d47fd11ccfff6297a4bd485597e5e7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">与 CLion Classic 不同的是，CLion Nova 不使用&nbsp;<strong style="color:#19191c">clangd&nbsp;</strong>来实现代码完成或高亮显示等核心 IDE 功能。不过，JetBrains 的 clangd 分支仍然与新引擎一起运行，以执行各种任务（ClangFormat、Clang-Tidy、MISRA 检查、数据流分析等）。&nbsp;</span></p><p>公告指出，对于&nbsp;<span style="color:#000000">CLion Classic </span>而言，使用&nbsp;<span style="color:#000000">CLion Nova </span>将拥有一些全新的体验：</p><ul style="margin-left:0; margin-right:0"><li>用户键入时 IDE 的一些反应方式会有所差异。</li><li>与代码洞察功能相关的某些 UI 元素和设置可能看起来不寻常或位于不熟悉的位置。</li><li>某些与代码相关的设置在 CLion Nova 中可能具有不同的默认值。首次启动时，CLion Nova 将从 CLion Classic 迁移一些按项目和应用程序设置，但不是全部。</li><li>在不同语言配置（即调试/发布）之间切换可能需要更多时间来让代码洞察引擎跟上。也没有选项可以切换每个文件的解析上下文。</li><li>ReSharper C++ 仅适用于 Windows，而 Rider 则支持跨平台。ReSharper C++/Rider 引擎可能无法像 Windows 环境那样无缝地支持非 Windows 环境。</li></ul><p><img alt="" height="382" src="https://oscimg.oschina.net/oscnet/up-c2c732eb8e4fd3d5f0bda9c1c6c3a7e2241.png" width="500" referrerpolicy="no-referrer"></p><p>&nbsp;<span style="color:#000000">CLion Nova 目前确实的功能包括：</span></p><ul style="margin-left:0; margin-right:0"><li><strong>工具链</strong>：存在多种选项可用于在 CLion 中设置<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fclion%2F2023.3%2Fremote-development.html" target="_blank">远程工作</a>。CLion Nova 支持本地资源的远程工作，但瘦客户端 (Gateway)&nbsp; 的远程工作尚不可用。</li><li><strong>语言</strong>：Objective-C 语言、CUDA（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FRSCPP-613" target="_blank">RSCPP-613</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-26144" target="_blank">CPP-26144</a>）和一些特定于供应商的编译器扩展尚不受支持。</li><li>目前不支持某些 intentions 和 quick-fixes，例如&nbsp;Simplify 语句 (&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35879" target="_blank">CPP-35879</a>&nbsp;)。</li><li>一些流行度不高的 refactorings 也不支持。官方计划稍后重新引入 Move<span style="background-color:#ffffff; color:#19191c"><span>&nbsp;</span>(</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35867" target="_blank">CPP-35867</a><span style="background-color:#ffffff; color:#19191c">) 和<span>&nbsp;</span></span>Inline Parameter<span style="background-color:#ffffff; color:#19191c"><span>&nbsp;</span>refactorings (</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35868" target="_blank">CPP-35868</a><span style="background-color:#ffffff; color:#19191c">)</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35868" target="_blank">。</a></li><li>JetBrains 的 AI 助手尚不适用于 CLion Nova。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 10:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266295/jetbrains-clion-nova</guid>
            <link>https://www.oschina.net/news/266295/jetbrains-clion-nova</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[正式开源！网易有道上线 「易魔声」 语音合成引擎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>刚刚，我们上线了「易魔声」开源语音合成（TTS）引擎！🎉🎉🎉</strong></p><p>「易魔声」，是一款有道自研 TTS 引擎，目前支持中英文双语，包含<strong>2000 多种不同的音色</strong>，更有特色的情感合成功能，支持合成包含<strong>快乐、兴奋、悲伤、愤怒</strong>等广泛情感的语音。</p><p style="text-align:center"><strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fpan.baidu.com%2Fs%2F1Gl7irtGrXoqFwgox3UzlgA%3Fpwd%3Dtwck" rel="nofollow" target="_blank">「易魔声」中文&nbsp; 网易有道</a></strong></p><p style="text-align:center">（我们用「易魔声」将以上这段话进行了技术合成，点击试听 ）</p><p>用户可免费在开源社区 GitHub 进行下载使用（地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FEmotiVoice" rel="nofollow" target="_blank">https://github.com/netease-youdao/EmotiVoice</a>），通过我们提供的 web 界面、及批量生成结果的脚本接口，轻松实现音色的情感合成与应用。</p><p style="text-align:center"><img alt="" src="https://mp.weixin.qq.com/s/WktfW3t1O5vn4QJWoRVLuA" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-9d1543d602359db470e97a2559595b763a6.png" referrerpolicy="no-referrer"></p><p style="text-align:center">（<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FEmotiVoice" rel="nofollow" target="_blank">GitHub 开源界面</a></strong>，点击蓝字可跳转）</p><p>在你过往的回忆里，是不是也有一些特别的声音，比如：偶像的声音激励人心、妈妈的声音让我们一秒回忆起小时候......声音，作为语言维度的一种，总是蕴含着人类充沛的情感表达。<strong>而富有情感的合成语音，是能够为应用和内容增色的 AI 功能。</strong></p><p>现在通过「易魔声」，简单通过在文本中加入情感的描述提示，开发者或者内容创作者就可以自由合成符合自己需求的带有情感的语音，比传统 TTS 更加自然逼真！👍</p><p>「易魔声」，是有道 AI 团队今年开发的一个项目。随着基于 GAN 等现代 AI 技术的语音能力越来越成熟，实现一个质量较高的 TTS 系统的门槛越来越低。但即使如此，中英双语的高质量、现代 TTS 模块还是不容易找到，要在自己的应用与内容中<strong>加入高逼真度且高度可控的语音，特别是中英双语的语音，依然比较麻烦</strong>。</p><p>这也是我们将这个项目开源的初衷，希望能帮助有需求的开发者与内容创作者，并不断扩大高质量 TTS 的应用范围。<strong>目前该项目还处于初期阶段，期待大家在</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FEmotiVoice" rel="nofollow" target="_blank"><strong>开源网站</strong></a><strong>给予我们更多反馈</strong>，我们非常希望听到大家的使用体验与建议💪，<strong>欢迎各位扫码进群交流～</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-95a884f5c1625d1bcc2e8d42937f33d0cb9.jpg" referrerpolicy="no-referrer"></p><p style="text-align:center"><strong>若二维码失效，可扫描下方二维码，添加我们工作人员的企业微信申请进群~</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c7306442e032ed93adbdf1a5fecf938d6b4.jpg" referrerpolicy="no-referrer"></p><p>借此机会，我们也邀请您了解和探索有道的更多酷炫 AI 技术👇</p><ul><li>您可以尝试我们的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.youdao.com%2Fpersonalized-voice.s" rel="nofollow" target="_blank"><strong>声音定制和声音复刻功能</strong></a>（点击蓝字即可试用）。从用户录制到试听整个过程只需 5 分钟，即可完成个性化的声音定制。</li><li>您也可以和**<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhiecho.youdao.com%2F%23%2Fweb" rel="nofollow" target="_blank">Hi Echo 虚拟人口语私教</a>**（点击蓝字即可跳转）聊一聊。通过有道的「子曰」教育大模型、语音和虚拟人技术，Echo 可以陪你轻松练习地道的英语口语。每天练习 10 分钟，口语水平快速提高哦。</li><li>您还可以微信搜索**「有道智云体验中心」小程序**。在这里，可以访问我们已经对开发者通过 API 等形式开放的文本和图像翻译、文字和各类图片识别、作文批改等各类 AI 技术。</li></ul><p><strong>关于有道智云</strong></p><p>有道智云 AI 开放平台，是网易有道旗下一站式人工智能服务提供商，为开发者、企业和政府机构等提供自然语言翻译、文字识别、OCR、语音识别等服务以及行业解决方案，致力于提供安全、可靠和高效的云服务。</p><p>联系电话：010-8255-8901；商务合作：AIcloud_Business@corp.youdao.com.</p><p>想了解更多关于有道人工智能的内容，可访问「有道智云」官网👉<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.youdao.com%2F" rel="nofollow" target="_blank"><strong>https://ai.youdao.com</strong></a>.</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 10:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/youdaotech/blog/10142807</guid>
            <link>https://my.oschina.net/youdaotech/blog/10142807</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[完蛋！我被 Out of Memory 包围了！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><ul><li><p>是极致魅惑、洒脱自由的<code>Java heap space</code>？</p></li><li><p>是知性柔情、温婉大气的<code>GC overhead limit exceeded</code>？</p></li><li><p>是纯真无邪、活泼可爱的<code>Metaspace</code>？</p></li><li><p>如果以上不是你的菜，那还有……</p></li><li><p>刁蛮任性，无迹可寻的<code>CodeCache</code>！</p></li><li><p>性感火辣、心思细腻的<code>Direct Memory</code></p></li><li><p>高贵冷艳，独爱你一人的<code>OOM Killer</code>！</p></li><li><p>总有一款，能让你钟情！BUG 选择权，现在交由你手！</p></li></ul><p><img alt="image.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-02-10-57XocqTnPFlxTzDLX.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_1"></span><h1>Java heap space</h1><p>这是最常见的一个 OOM 问题了，谁还没经历过一个 Heap OOM 呢？</p><p>当堆内存被塞满之后，一边 GC 无法及时回收，一边又在继续创建新对象，Allocator 无法分配新的内存之后，就会送一个 OOM 的错误：</p><pre><code>java.lang.OutOfMemoryError: Java heap space

</code></pre><p>分析解决起来无非是那几步：</p><ol><li><p>dump 堆内存</p></li><li><p>通过 MAT、YourKit、JProfiler 、IDEA Profiler 等一系列工具分析 dump 文件</p></li><li><p>找到占用内存最多、最大的对象，看看是哪个小可爱干的</p></li><li><p>分析代码，尝试优化代码、减少对象创建</p></li><li><p>增加 JVM 堆内存、限制请求数、线程数、增加节点数量等</p></li></ol><span id="OSC_h3_2"></span><h3>常见类库使用误区</h3><p>尤其是一些工具库，尽可能的避免每次新建对象，从而节省内存提升性能。</p><p>大多数主流的类库，入口类都保证了单例线程安全，全局维护一份即可</p><p>举一些常见的错误使用例子：</p><span id="OSC_h4_3"></span><h4>Apache HttpClient</h4><p>CloseableHttpClient ，这玩意相当于一个「浏览器进程」了，背后有连接池连接复用，一堆机制的辅助类，如果每次都 new 一个，不仅速度慢，而且浪费了大量资源。</p><p>比较正常的做法是，全局维护一个（或者根据业务场景分组，每组一个）实例，服务启动时创建，服务关闭时销毁：</p><pre><code>CloseableHttpClient httpClient = HttpClients.custom()
                .setMaxConnPerRoute(maxConnPerRoute)
                .setMaxConnTotal(maxConnTotal)
                /// ...
                                 .build();

</code></pre><span id="OSC_h4_4"></span><h4>Gson</h4><p>毕竟是 Google 的项目，入口类自然也是实现了线程安全，全局维护一份 Gson 实例即可</p><span id="OSC_h4_5"></span><h4>Jackson</h4><p>Jackson 作为 Spring MVC 默认的 JSON 处理库，功能强大、用户众多，xml/json/yaml/properties/csv 各种主流格式都支持，单例线程安全自然也是 ok 的，全局维护一份 ObjectMapper 即可。</p><span id="OSC_h1_6"></span><h1>GC overhead limit exceeded</h1><p>这个错误比较有意思，上面的 Java heap space 是内存彻底满了之后，还在持续的创建新对象，此时服务会彻底假死，无法处理新的请求。</p><p>而这个错误，只是表示 GC 开销过大，Collector 花了大量的时间回收内存，但释放的堆内存却很小，并不代表服务死了</p><p>此时程序处于一种很微妙的状态：堆内存满了（或者达到回收阈值），不停的触发 GC 回收，但大多数对象都是可达的无法回收，同时 Mutator 还在低频率的创建新对象。</p><p>出现这个错误，一般都是流量较低的场景，有太多常驻的可达对象无法回收，但是吧，GC 后空闲的内存还可以满足服务的基本使用</p><p>不过此时，已经在频繁的老年代 GC 了，老年代又大对象又多、在现有的回收算法下，GC 效率非常低并切资源占用巨大，甚至会出现把 CPU 打满的情况。</p><p>出现这个错误的时候，从监控角度看起来可能是这个样子：</p><ol><li><p>请求量可能并不大</p></li><li><p>不停 GC，并切暂停时间很长</p></li><li><p>时不时的还有新的请求，但响应时间很高</p></li><li><p>CPU 利用率很高</p></li></ol><p>毕竟还是堆内存的问题，排查思路和上面的<code>Java heap space</code>没什么区别。</p><span id="OSC_h1_7"></span><h1>Metaspace/PermGen</h1><p>Metaspace 区域里，最主要的就是 Class 的元数据了，ClassLoader 加在的数据，都会存储在这里。</p><p>MetaSpace 初始值很小，默认是没有上限的。当利用率超过 40%（默认值 MinMetaspaceFreeRatio）会进行扩容，每次扩容一点点，扩容也不会直接 FullGC。</p><p>比较推荐的做法，是不给初始值，但限制最大值：</p><pre><code>-XX:MaxMetaspaceSize=

</code></pre><p>不过还是得小心，这玩意满了后果很严重，轻则 Full GC，重则 OOM：</p><pre><code>java.lang.OutOfMemoryError: Metaspace

</code></pre><p>排查 MetaSpace 的问题，主要思路还是追踪 Class Load 数据，比较主流的做法是：</p><ol><li><p>通过 Arthas 之类的工具，查看 ClassLoader、loadClassess 的数据，分析数量较多的 ClassLoader 或者 Class</p></li><li><p>打印每个 class 的加载日志：<code>-XX:+TraceClassLoading -XX:+TraceClassUnloading</code></p></li></ol><p>下面介绍几个常见的，可能导致 MetaSpace 增长的场景：</p><span id="OSC_h3_8"></span><h3>反射使用不当</h3><p>JAVA 里的反射，性能是非常低的，以反射的对象必须得缓存起来。尤其是这个<code>Method</code>对象，如果在并发的场景下，每次都获取新的 Method，然后 invoke 的话，用不了多久 MetaSpace 就给你打爆！</p><p>简单的说，并发场景下，Method.invoke 会重复的动态创建 class，从而导致 MetaSpace 区域增长，具体分析可以参考笨神的文章《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fheapdump.cn%2Farticle%2F54786" rel="nofollow" target="_blank">从一起 GC 血案谈到反射原理</a>》。</p><p>用反射时，尽可能的用成熟的工具类，Spring 的、Apache 的都可以。它们都内置了 reflection 相关对象的缓存，功能又全性能又好，足以解决日常的使用需求。</p><span id="OSC_h3_9"></span><h3>一些 Agent 的 bug</h3><p>一些 Java Agent，静态的和运行时注入的都算。基于 Instrumentation 这套 API 做了各种增强，一会 load 一会 redefine 一会 remove 的，如果不小心出现 BUG，也很容易生成大量动态的 class，从而导致 metaspace 打满。</p><span id="OSC_h3_10"></span><h3>动态代理问题</h3><p>像 Spring 的 AOP ，也是基于动态代理实现的，不管是 CgLib 还是 JDK Proxy，不管是 ASM 还是 ByteBuddy。最终的结果都逃不开动态创建、加载 Class，有这两个操作，那 Metaspace 必定受影响。</p><p>Spring 的 Bean 默认是<code>singleton</code>的，如果配置为<code>prototype</code>，那么每次 getBean 就会创建新的代理对象，重新生成动态的 class、重新 define，MetaSpace 自然越来越大。</p><span id="OSC_h1_11"></span><h1>Code Cache</h1><p>Code Cache 区域，存储的是 JIT 编译后的热点代码缓存（注意，编译过程中使用的内存不属于 Code cache），也属于 non heap 。</p><p>如果 Code cache 满了，你可能会看到这么一条日志：</p><pre><code>Server VM warning: CodeCache is full. Compiler has been disabled.

</code></pre><p>此时 JVM 会禁用 JIT 编译，你的服务也会开始变慢。</p><p>Code Cache 的上限默认比较低，一般是 240MB/128MB，不同平台可能有所区别。</p><p>可以通过参数来调整 Code Cache 的上限：</p><pre><code>-XX:ReservedCodeCacheSize=

</code></pre><p>只要尽量避免过大的 Class、Method ，一般也不太会出现这个区域被打满的问题，默认的 240MB/128MB 也足够了</p><span id="OSC_h1_12"></span><h1>Direct Memory</h1><p>Direct Memory 区域，一般称之为直接内存，很多涉及到，磁盘 I/O ，Socket I/O 的场景，为了「Zero Copy」提升性能都会使用 Direct Memory。</p><p>就比如 Netty ，它真的是把 Direct Memory 玩出了花（有空写一篇 Netty 内存管理分析）……</p><p>使用 Direct Memory 时，相当于直接绕过 JVM 内存管理，调用 malloc() 函数，体验手动管理内存的乐趣～</p><p>不过吧，这玩意使用比较危险，一般都配合 Unsafe 操作，一个不小心地址读写的地址错误，就能得到一个 JVM 给你的惊喜：</p><pre><code>#
# A fatal error has been detected by the Java Runtime Environment:
#
#  EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x00007ffdbd5d19b4, pid=1208, tid=0x0000000000002ee0
#
# JRE version: Java(TM) SE Runtime Environment (8.0_301-b09) (build 1.8.0_301-b09)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.301-b09 mixed mode windows-amd64 compressed oops)  
# Problematic frame:
# C  [msvcr100.dll+0x119b4]
# 
# No core dump will be written. Minidumps are not enabled by default on client versions of Windows
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.java.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#

</code></pre><p><img alt="image.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-02-10-369sm6Shj7lkLZQao.png" referrerpolicy="no-referrer"></p><p>更多的解释，可以参考我这篇《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsegmentfault.com%2Fa%2F1190000020228048" rel="nofollow" target="_blank">Java 中的 Heap Buffer 与 Direct Buffer</a>》</p><p>这个 Direct Memory 区域，默认是无上限的，但为了防止被 OS Kill，还是会限制一下，给个 256MB 或者更小的值，防止内存无限增长：</p><pre><code>-XX:MaxDirectMemorySize=

</code></pre><p>如果 Direct Memory 达到 MaxDirectMemorySize 并且无法释放时，就会得到一个 OOM 错误：</p><pre><code>java.lang.OutOfMemoryError: Direct buffer memory

</code></pre><span id="OSC_h1_13"></span><h1>Linux OOM Killer</h1><p>跳出 JVM 内存管理之后，当 OS 内存耗尽时，Linux 会选择内存占用最多，优先级最低或者最不重要的进程杀死。</p><p>一般在容器里，主要的进程就是肯定是我们的 JVM ，一旦内存满，第一个杀的就是它，而且还是 kill -TERM (-9) 信号，打你一个猝不及防。</p><p>如果 JVM 内存参数配置合理，远低于容器内存限制，还是出现了 OOM Killer 的话，那么恭喜你，大概率是有什么 Native 内存泄漏。</p><p>这部分内存，JVM 它还管不了。</p><p>除了 JVM 内部的 Native 泄漏 BUG 这种小概率事件外，大概率是你引用的第三方库导致的。</p><p>这类问题排查起来非常麻烦，毕竟在 JVM 之外，只能靠一些原生的工具去分析。</p><p>而且吧，这种动不动就要 root 权限的工具，可是得领导审批申请权限的……排查成本真的很高</p><p><img alt="image.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-02-10-39aqlx39acVlRQ29Qrm.png" referrerpolicy="no-referrer"></p><p>排查 Native 内存的基本的思路是：</p><ol><li><p>pmap 查看内存地址映射，定位可疑内存块、分析内存块数据</p></li><li><p>strace 手动追踪进程系统调用，分析内存分配的系统调用链路</p></li><li><p>更换 jemalloc/tcmalloc 之类的内存分配器（或者 async-profiler 有个支持 native 分析的分支）追踪 malloc 的调用链路</p></li></ol><p>目前最常见的 Native 内存泄漏场景，是 JDK 的 Inflater/Deflater 这俩卧龙凤雏，功能是提供 GZIP 的压缩、解压，在默认 glibc 的 malloc 实现下，很容易出现「内存泄漏」。如果出现 Native 内存泄漏，可以先看看应用里有没有 GZIP 相关操作，说不定有惊喜。</p><hr><p>好了，各类风格的 OOM 都感受完了，到底哪一个更能打动你呢？</p><blockquote><p>作者：京东保险，蒋信</p><p>来源：京东云开发者社区，转载请注明来源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 10:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10141303</guid>
            <link>https://my.oschina.net/u/4090830/blog/10141303</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【直播回顾】开源创业：要怎么推广项目，去哪里找钱？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 8 日，OSCHINA 直播——【开源漫谈】第 5 期，邀请了中国第一个人站长高春辉、禅道软件公司创始人王春生、津津乐道创始人朱峰，聊了聊开源创业相关的话题，涉及开源协议、开源漏洞、项目捐赠、创业赛道等方向。</p><p>其中，关于开源协议的选择、开源项目漏洞责任归属，以及是否要将开源项目捐赠给基金会，王春生已经在《<a href="https://my.oschina.net/oscpyaqxylk/blog/10114031">关于开源软件的七大错误认知</a>》一文做了详细解答。另外《<a href="https://my.oschina.net/u/6852546/blog/10118120">开源软件有漏洞，作者需要负责吗？是的！</a>》《<a href="https://my.oschina.net/oscpyaqxylk/blog/10140275">项目捐给了开源基金会，作者手上还剩了什么？</a>》等文章也对相关问题进行了详细分析，本文不再赘述，而是主要将关注点放在如何推广开源项目，怎么选择创业赛道等等话题上。</p><p>想了解更多精彩内容，可以微信扫描下方二维码，观看完整直播：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28f36ff6e308f95d2736438e921e43f2dca.png" referrerpolicy="no-referrer"></p><span id="OSC_h3_1"></span><h3><span style="color:#3498db"><strong>01 自己的开源项目，能不能拿来创业？</strong></span></h3><p><strong>朱峰：</strong>怎么判断自己的开源项目能不能拿来创业？</p><p><strong>王春生：</strong>首先，软件一定要有价值，能够帮助用户解决问题，这是一个大前提，不管是什么方向的创业，这是基本的。</p><p>二是要考虑软件面向的用户群体。如果你的开源软件纯粹是面向开发者，那么将很难实现商业上的转化。如果是面向企业内部的，这个方向还是有大作为的。</p><p>现在也一些很好的方向，比如工业化这块，有技术的可以朝着这个方向发展，这也是属于国家「卡脖子」的技术领域，是能够赚到钱的。我一个朋友做了一个仿真相关领域的开源平台，前段时间拿到了投资。未来这些方向还有很大机会。</p><p>不是说 to c 属性不能做，但你要拿来创业，最好不要去碰 to c 属性的开源软件。因为 to c 属性的产品，已经有互联网大厂在跟进，他们的打法是个人完全没办法复制的。</p><p><strong>朱峰：</strong>老高你认为如何？当初做 ECShop（国内第一个开源的电商建站软件） 的时候，国内还没有这么健全的开源生态。是怎么想到要将 ECShop 开源的？</p><p><strong>高春辉：</strong>开源确实是能够吸引很多用户。但项目和公司能否持续，和你开源不开源关系并不大，跟商业模式本身是否健康有很大关系。当时最有意思的一个事儿，是做网站模板的，也就是做外围工作的能赚钱，但我们做软件的人并不赚钱。</p><p>国内国外对开源的认可度是不一样的。在国内，用户很大可能就想省钱，你开源了，我就用你的开源版本，宁可自己改一改，也不愿意花钱。但国外对开源软件付费认可度会更高。同样一个软件，国外有人能成立公司，能成功，在国内可能不会那么顺利。</p><p>我们当时还有一个大问题，就是我们的软件，自始至终都是自己人在做开发。开源只是开放的源代码，真正愿意来贡献代码的人非常少。</p><p><strong>朱峰：</strong>如果我没有记错的话，你做 ECShop 的时候开源生态还没有现在这么好。</p><p><strong>高春辉：</strong>那时候没有。但我觉得，就是国内有了好的开源生态，可能情况也不会好很多。软件复杂度上来以后，真的愿意花时间把软件看懂，并在上面贡献的人也很少。现在 GitHub 比较火的项目，贡献多的大多是全职开发者，个人贡献者能有几个？大家都很忙，工作 996 ，回家了只想睡觉。在国内做开源还是要审慎。</p><span id="OSC_h3_2"></span><h3><span style="color:#3498db"><strong>02 免费用户提需求，心态是怎样吗？</strong></span></h3><p><strong>朱峰：</strong>很多时候免费用户会提出一些功能改进、BUG 修复、技术支持等要求，你们在遇到这些问题的时候，心态是怎么样的？我记得当年老高搞 ECShop，也有很多用户提各种各样的需求，然后还催着赶紧搞定。作为开发者，在这个时候心里会不会有一点点不舒服？</p><p><strong>高春辉：</strong>我觉得我的心态分成两个阶段，第一个阶段是很开心，因为有人给你提需求。但后面会发现，一旦你的资源不够，他提需求还用道德绑架的口吻来跟你聊，你就会觉得不爽了。这个东西我是免费的，你凭什么逼着我去做这个功能？</p><p>现在有些开源的维护者写的文章非常灰心丧气。原因很多，一是自己花了很多精力时间去维护这个软件，二是没有报酬，三是有些大公司用了他的东西，也没有什么支持。</p><p><strong>朱峰：</strong>春生怎么看这件事情？今天整个开源生态的情况跟当年老高那会儿又不太一样，你看到免费用户的这些诉求是怎么样的？</p><p><strong>王春生：</strong>首先，有人用肯定是好事情。我经常办一些线下商务活动，很多用户都会跟我说，他们用禅道很久了，一直也没付费，其实挺不好意思的。但我说，这就很好，你们用我们的软件，就是对我们最大的支持。他可能在当时不会买，但是员工会流动，会带着禅道到新公司，产生新的机会。所以从这一点来讲，有用户来提需求，提 bug，然后甚至有可能 diss 你等等，我觉得这都是好事情，就说明软件是真的有人在用，有人在乎你。如果你发布一个产品，都没人反馈，那就是另外一个凄惨的故事了。</p><p>第二，要区分对待用户需求，同时也要有引导。对同一件事，大家的价值认知其实是不太一样的。站在提需求或者提 bug 的用户角度，我已经对你的产品付出了很多心血，花了很大的力气来跟你讨论，还帮你提建议，提改进，你们应该立即去响应，处理这些问题。</p><p>站在开发者角度，正如老高所说的，资源确实是有限的，没办法响应所有需求。我觉得还是要保持平常心，因为不可能让每人都完全赞同。</p><p>面对用户的需求和反馈，还是需要甄别。不能被用户的反馈影响你产品的发展方向，得要有自己的主线。有的需求非常合理，逻辑也非常自洽，但只是代表的是一小部分的场景，放在通用产品角度来看，就不见得合适。如果梳理出来的需求，是绝大多数用户都有可能能用到的，那么就要第一时间去响应，然尽可能快地处理。此外，对于一些通用性可能并没有那么强的功能需求，我们也可以通过插件的方式来解决。</p><span id="OSC_h3_3"></span><h3><span style="color:#3498db"><strong>03 做产品变成了二次开发的外包公司，你们怎么看？</strong></span></h3><p><strong>朱峰：</strong>谈到二次开发也是一个挺有意思的话题，很多的做产品的公司最后都变成了做二次开发的外包公司。你怎么看待这件事？</p><p><strong>王春生：</strong>我觉得要抵住诱惑，尤其是刚开始的时候。</p><p><strong>朱峰：</strong>但是这个诱惑往往很难抵得住，当你没有钱的时候，人家拍给你几十万让把这事儿给干了，你说你能不干吗？</p><p><strong>王春生：</strong>我们也遇到过，这会让我们不停怀疑自己，走的方向是不是正确的，再重新坚定，然后再重新怀疑，再重新坚定，再重新怀疑，一直处于这样的过程中。</p><p>这么些年，不断地会有客户提出定制需求，订单金额少则十几万、几十万，多的可能过百万。做还是不做，确实是一个很大的选择。我的建议是，定制开发可以做，但是不要影响产品发展的主线，不要被定制开发项目拉歪整个团队的方向。如果定制开发的项目庞大，我们一般都不接；要求驻场我们也不接。人力有限，大项目很可能把整个团队都给拖过去，挺要命的。</p><span id="OSC_h3_4"></span><h3><span style="color:#3498db"><strong>04 怎么推广自己的开源软件？</strong></span></h3><p><strong>朱峰：</strong>怎么让你的开源项目有更多的人用，有更多人能参与其中？</p><p><strong>王春生：</strong>一是 release often，就是尽可能早、尽可能快地发布。开源软件天然就有这种属性，通过快速、持续地产品交付，就能自然而然地获得用户关注。新产品总是会有早期的种子用户，会很喜欢去尝试一些新的东西。禅道早期也是这么起来的。</p><p>比如一个以 GitHub 为内容来源的公众号，为了流量，它会定期地去挖掘一些比较好的项目并对外宣传，这就相当于有人去帮你做这个事情。</p><p>除了在产品方面尽可能早地发布，还要去写文章进行宣传，当时我们也在开源中国做了很多推广，对我们有很大的帮助。同时也在其他地方比如一些新闻网站做 SEO 优化，交换链接，参与活动，赞助等等，一些常规的运营手段都得用起来。</p><p>所以说，在早期的时候，开源软件作者在埋头写产品之外，还是要花一定的心思在运营上。有人认为产品做出来之后，用户自然而然就来了，这不太现实。</p><p><strong>高春辉：</strong>做开源软件跟做网站，没有本质的区别，它就是一个产品。产品推广，无非是看它的用途和你的受众。你的受众是做电商的，那你就要找这个圈子去曝光你的新功能，特性，用户会很好奇地去使用。</p><p>当年的做电商有两个思路：是跟着淘宝混还是自己做个站？</p><p>为了流量，大家都会选择淘宝。只有大公司才有可能会建自己的电商站，但维护很重。我们当时接过摩托罗拉项目，建个站然后通过广告引流，促成销售，但最后摩托罗拉还是选择了淘宝、京东渠道。因为对他们来说，不管是淘宝还是个站，最后只要能够实现销售额就可以。</p><p>至少在那个时候，有个站在自己的控制之下，用户是有兴趣去尝试的。国内用户都喜欢把数据放在自己手里，喜欢私有化部署，如果相关功能做得好，其实是很有吸引力的。</p><p><strong>朱峰：</strong>去建立个人影响力，建立自己的个人品牌，我觉得是合适的。如果你自己是一个自带流量的 KOL，去推自己的项目往往会事半功倍。但如果你是一个闷头写代码的素人，这件事情可能就比较难。</p><p>现在流量太贵了，买流量投广告去推广开源项目，显然不现实。所以你怎么把信任你的人留存在自己的私域里，把自己就变成了一个 KOL，这个事情才重要。</p><p>刚才春生也提到，他早先用三分之一时间开发，三分之一时间写文档，三分之一时间写文章。为什么他要用三分之一时间写文章？他就是要建立自己的影响力，因为只有个人私域自带的流量才真正是你的流量，才能够为你当前的项目，甚至说以后的项目去做转化。</p><span id="OSC_h3_5"></span><h3><span style="color:#3498db"><strong>05 软件开源，培训收费，这个思路可行吗？</strong></span></h3><p><strong>朱峰：</strong>有直播间网友提问，软件开源，培训收费，这个思路可行吗？</p><p><strong>高春辉： </strong>那成本会很高的。除非你是在线培训，或者是录制好的课程，但录制好的课程一旦泄露出去，也很麻烦。</p><p><strong>王春生：</strong>你让我提建议的话，那就是不要想着通过技术支持或者培训去收费。</p><p><strong>高春辉：</strong>对，还得通过产品本身挣钱。</p><p><strong>王春生：</strong>这块儿我想多说几句。我觉得很多开源开发者对技术支持这件事情理解得不太正确。我所接触的很多些开源软件的微信群、QQ 群，全是网友自己在互相抱团取暖，官方作者基本上不出来回答问题。</p><p>作者会认为，软件是免费的，有 FAQ（Frequently Asked Questions，常见问题解答），有文档，甚至可能还录了视频，该做的我都做了，你要想解决问题，就应该自己动手。我接触过很多的开源软件作者，基本上都是这么一种心态。如果开源作者只是为了自己的兴趣而开发软件，这么做是完全没问题的。</p><p>但如果要做商业化，还是要把这些用户当做潜在客户去对待，认真地、扎扎实实地给人家提供技术支持，让他把产品用起来，让他感知到你和团队是在认真做产品，做事情。这样才有可能跟用户之间建立起信任，才有可能去做下一步商业上的转化。</p><p>你想，我们进店吃饭，店员爱理不理地说，筷子在这儿，茶水在那儿，甚至锅灶在那儿，你可以自己炒，你肯定就不开心了。虽然目前我没有付费，你怎么知道我将来就不会付费？</p><p>所以我们的策略就是，对开源版本投入大量的人力和资源，甚至会要求第一时间响应开源版本的免费用户。对开源用户做好支持了，才有源源不断的用户，才会产生收费版本的需求。</p><span id="OSC_h3_6"></span><h3><span style="color:#3498db"><strong>06 禅道挣到钱了吗？</strong></span></h3><p><strong>朱峰：</strong>做开源项目到底挣不挣钱？禅道挣钱了吗？盈利方面有没有向好的趋势？</p><p><strong>王春生：</strong>早期的话，真的是在用爱发电，苦哈哈地做开源。从 2012 年下半年开始，现金流基本上已经盈亏平衡了。</p><p>2011 年的时候，我们是十多人的一个小团队，已经有一定的支出了，确实遇到了资金不足的问题。老高二话不说就打了第一笔钱，是我的天使投资人。 到了年底，其他几位股东也陆陆续续凑了一笔钱，准备好了 2012 年的运营费用，决定开始招聘销售、技术支持等等岗位上的人才。当时做了打算，成不成就看这一把了。如果不行了，就再去打工。</p><p>在 2012 年的上半年，我们就推出了第一个收费版本，到了下半年，现金流基本上就实现了盈亏平衡。</p><p><strong>朱峰：</strong>老高当年的 ECShop 是怎么赚钱的？</p><p><strong>高春辉：</strong>软件本身不赚钱，靠卖了赚钱。那时候做 ECShop 是 2006 年左右，电商在国内还不被看好。没有钱怎么办？那时候肯定去融资。结果跟投资人聊了大概十分钟，人家就说，十年内中国电商都不会有什么大的发展。这就把我说泄气了，那就卖了吧。</p><p>那时候淘宝、京东在往上走了，但大家都不知道它能做多大。现在你回头看， ECShop 模式在国内确实会有天花板。因为国内都是走平台策略，流量给平台拉走了，单店的模式基本上不会有太多用户。反而做淘宝的生态服务商会有更大的发展空间。但它的天花板也很低，每年能赚钱但有限，想上市基本没戏。</p><span id="OSC_h3_7"></span><h3><span style="color:#3498db"><strong>07 创业去哪里找钱？</strong></span></h3><p><strong>朱峰：</strong>大家都知道这几年，创业行情不是特别好，想找一些投资人更是尤为困难。请两位老兵跟大家聊聊怎么找钱的事儿。</p><p><strong>高春辉：</strong>我当时投资禅道的钱，也是到处凑出来的。春生要再多，我也给不起了。钱当时凑得也比较难，但是对我来说，就算都给亏光了，公司关门了，我也还好。当时我觉得，春生只要能够认真做，不走错，他就能赚钱。</p><p>至于现在，我觉得就别想着去融资这个事，先踏踏实把这个东西先做出来，哪怕利用这业余时间做，把它跑起来，你的压力就小很多。</p><p>千万不要以为，你拿了钱之后压力会小，你拿了钱压力会变大。因为现在的投资几乎就都是有连带担保的。但凡是你求 vc 的，连带担保是跑不了的。 我前几天看到一个广东的创业者说，医保攒的钱都被投资人冻结了，理论上这是救命钱。也不多，可能就几万块钱，但是连医保卡的钱都不放过，你想这个钱好拿吗？</p><p><strong>朱峰：</strong>春生在疫情期间拿到了投资，这一轮融资估值还不低。那在这个过程当中，你是怎么去选择这些投资人？</p><p><strong>王春生：</strong>也是机缘巧合，朋友介绍促成的。我们的投资人是高成资本，是中国专注于企服赛道的投资机构。彼此之间都非常认同：高成资本对我们的经营方式比较认同，我们对高成资本的投资理念也非常认同。高成资本创始合伙人洪婧是对企服赛道非常了解，而且投的都是长期项目。</p><p>到今天来看，其实大家都不太看好企服赛道这个大方向了。因为受中美关系、经济环境等各方面的影响，企服赛道正处于低谷期。风险投资商更关注硬科技、人工智能这些方向，所以现在想拿钱不太容易。再一个，美元基金基本上都撤了，人民币基金投资比较谨慎。</p><p>如果你想创业的话，我觉得这时候不是一个好时机。</p><p><strong>高春辉：</strong>我个人觉得这个时候适合积蓄力量。你可以做事儿，不要去融资。</p><span id="OSC_h3_8"></span><h3><span style="color:#3498db"><strong>08 一个有 4000 多 star 的开源聊天软件，怎么往下走？</strong></span></h3><p><strong>朱峰：</strong>直播间有网友问题，他有一个开源项目，是一个聊天软件，有 4000 多，的 star，要怎么往下走，能给点儿建议吗？</p><p><strong>王春生：</strong>我觉得还是要收费。通过开源版和收费版，把软件功能区分开。 在国内，经常会有一些说法：中国企业不乐意为软件付费。我认为这个观点是错误的。我所接触的客户，再小的客户，都非常乐意为软件付费。不过有个前提，就是这个软件需要具备很高的性价比。如果人家花个几千块或者两三万的费用就能解决一个问题，哪怕企业规模不是很大，还是会乐意掏钱。现在很多企服赛道软件不太好卖。为什么？因为动不动一个人一年的授权就要好几千，这个价格，很多消费者真的接受不了。</p><p>一个聊天软件有 4000 多，的 star，首先就有了比较好的基础，可以尝试去推收费的版本。</p><p><strong>朱峰：</strong>那如果他卖付费版本了，但是收入不高，那你怎么办？</p><p><strong>高春辉：</strong>他得先去想，那些给他打 4000 多个 star 的人的想法是啥。人家都有动手能力，就不需要买付费版。你的软件越专业，用户付费的可能性才越大。你的软件简单安装就能用，愿意付费的人可能就会很少。</p><p><strong>王春生：</strong>我们也有一个聊天的软件，叫喧喧，最开始也是开源的，后来没用开源方式去做。一年下来，有零零星星的收入，没几个钱，也就能把我们开发团队的工资赚出来。我觉得这可能是跟方向有关系，因为现在国内企业微信、钉钉、飞书太强了。</p><p>但我觉得也不要灰心，还是要找准自己的定位，就是跟其他软件的不同点是什么，不要把东西做得跟别人一样。飞书有什么功能，钉钉有什么功能，我们也要有这些功能，这是不行的，一定要有自己的差异点，把自己的这个定位搞清楚，面向的是什么样的用户场景。比如转转打入军工行业，那它就做最安全的私有部署软件。</p><p>这纯粹是当参考哈，因为我们也没有完全做出来，也还在摸索方向。</p><p>第二，从经营上来讲，经营企业，确实会有很多的事情，需要你耐心去打磨。比如说定价策略。很多开源软件作者特别具有程序员特质，定价非常直爽，100 块钱或者 1000 块钱就能买终身版，或者定个 1000 块的早鸟价，后期还会再涨价。</p><p>就这种定价方式而言，太过于草率。定价是有技巧的。比如在超市，有个东西价格比较贵，但它会衬托另一个价格更低的产品很实惠，这是一种策略；还有一种就是打包策略，在麦当劳、肯德基，花了 20 块钱就买了一个汉堡，再多花两三块钱就能得到一包薯条或者一杯可乐，消费者就会觉得很实惠。</p><p>有观点认为，定价就相当于定生死。定价，就决定了产品在市场上面向的用户群体、销售模式、商业模式、漏斗转化模式。在企服赛道，有的产品卖得非常贵，一个人一年授权是几千块钱，甚至国外产品一个人一年的授权能卖到 2 万块钱。但人家可以卖，我们就卖不了，而且人家卖的体量要比我们大太多了。所以还是要找准自己的市场。</p><span id="OSC_h3_9"></span><h3><span style="color:#3498db"><strong>09 出现负面舆情，怎么公关？</strong></span></h3><p><strong>朱峰：</strong>出现负面舆情，你怎么去公关？这对于开源软件还挺重要的。</p><p><strong>王春生：</strong>早些年发布禅道的时候，确实有很多人说，市面上已经有很多开源的缺陷管理工具，bug 管理工具，为什么还要重新造轮子。那时候是要花一部分的精力来回应这些质疑和吐槽的声音。</p><p>很多朋友在劝我，说没必要去理会这些。但我说一定要正面去回应，站在我的角度给大家解释，可能产品有不尽人意的地方，但也不像你说的那么不堪。</p><p>正面回应，最重要的不是让这个人去认同你的观点，而是要给「旁观者」信心。站在旁观者角度，软件作者不正面回应的话，就会觉得产品真的有问题，肯定会去对产品失去信心，有句话叫三言成虎嘛！</p><p>禅道是我的饭碗，是我们整个团队衣食住行的来源，所以我一定会正面回应，去影响旁观的用户，这还是蛮关键的。</p><p><strong>高春辉：</strong>这让我想起来个事，严格地讲是被敲诈。 他说：「我知道你这个地方有漏洞，是你给我钱我帮你修复好，还是我把它卖给别人？」</p><p>最后我们认栽。还好就那个钱并不多，人家也不是为了指望你给他挣多少钱，我们也觉得，花钱把这个问题消灭在萌芽之中也没有错。毕竟代码可能有几万行，有时候真的没法面面俱到，也很难一下就发现。能找上门愿意跟你谈的，都算是给你帮忙。要是被别有用心的人拿在手里，那可能给你的打击会更大。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 09:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10142795</guid>
            <link>https://my.oschina.net/u/3859945/blog/10142795</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[腾讯开源 hel-micro：工具链无关的微模块方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>腾讯宣布开源&nbsp;<span style="background-color:#ffffff; color:#353535">hel-micro，号称业内首个以 sdk 的方式支持模块联邦技术的方案，它脱离了工具链的枷锁，回归到 js 语言本身，接入快速、简单、灵活，极大的降低了模块联邦技术的接入门槛，让不同工具链间的联邦模块可以互认互通，提高了模块的流通</span><span style="background-color:#ffffff; color:#353535">。</span></p><p><span style="background-color:#ffffff; color:#353535"><img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-3760e632729b56bfe4d157f4b2fb5455b40.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#353535">独创的双构建机制，让远程模块的开发体验等效于本地模块</span></p><p><span style="background-color:#ffffff; color:#353535"><img alt="" height="226" src="https://oscimg.oschina.net/oscnet/up-9ac5bb169c747eb678ef83848d529f6bf42.png" width="500" referrerpolicy="no-referrer"></span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>运行时模块聚合让线上动态更新易如反掌，也可以按需定制不同场景的版本下发规则</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><img alt="" height="268" src="https://oscimg.oschina.net/oscnet/up-8427bafa096f9e1c1dc45202b6b1b66f0e0.gif" width="500" referrerpolicy="no-referrer"></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span style="background-color:#ffffff; color:#353535">相比社区已有方案，hel-micro 优势如下：</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><img height="247" src="https://oscimg.oschina.net/oscnet/up-b8a0b5e7e04c4a14ecb8ac2fba8c20ea2f8.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span style="background-color:#ffffff; color:#353535">基于 sdk 的远程加载能力，可以搭配公共 cdn 部署远程模块（sdk 默认指向 unpkg），用户也可以轻松定制自己的模块管控平台，然后重置 sdk 的请求模块元数据接口即可。</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><img height="128" src="https://oscimg.oschina.net/oscnet/up-7c5943f713c18c5fe937d597ec0f074914c.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span style="background-color:#ffffff; color:#353535">再结合用户自己的 cd&amp;cd&nbsp;流水线，可完成模块从提交、发布、到运维的全生命周期管理的闭环</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><img height="211" src="https://oscimg.oschina.net/oscnet/up-358b8d82cf1ffc4ee0652faae21586b2efe.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>进而可以搭建出一个类似如下架构&nbsp;helpack&nbsp;的模块管控平台</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><img height="290" src="https://oscimg.oschina.net/oscnet/up-fe1dd3acf6cd1c99f7dd5cc4fa183cd1a61.png" width="500" referrerpolicy="no-referrer"></p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><strong>开源规划</strong></h4><p><img height="282" src="https://oscimg.oschina.net/oscnet/up-c12d7d3a6c5668b3a734ad321842ca7ef11.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>项目团队表示规划未来将实现更多的上层框架远程加载适配器，例如</span></p><ul><li style="text-align:start"><span>远程&nbsp;web&nbsp;component&nbsp;组件</span></li><li style="text-align:start"><span>远程&nbsp;angular 组件</span></li><li style="text-align:start"><span>远程 vue 组件</span></li><li style="text-align:start"><span>远程 react 组件（已实现为 hel-micro-react，提供钩子函数加载远程 react 组件）</span></li><li style="text-align:start"><span>远程&nbsp;svelte&nbsp;组件&nbsp;等....</span></li></ul><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>同时后续很快很提供一个基于`hel-micro`&nbsp;+&nbsp;`react`&nbsp;+&nbsp;`pnpm`&nbsp;的微前端应用示范`helra`.</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>helra 将提供以下特性：</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>1&nbsp;子应用独立部署，独立发布，由一级路由命中访问</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>2&nbsp;共享基座上下文，可在一级路由下独立注册自己的子路由</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>3&nbsp;应用本地启动自带基座，发布后基座运行时自动移除</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>4&nbsp;应用间可相互共享组件，享受动态更新优势</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>5&nbsp;所有应用均可访问更底层的远程公告库，</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>6&nbsp;开发时应用间可以相互联调对方的代码</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><img height="241" src="https://oscimg.oschina.net/oscnet/up-190569b11b02b497276869cfd91321178e1.png" width="300" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266277</guid>
            <link>https://www.oschina.net/news/266277</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[KubeSphere 社区双周报 | KubeSphere 3.4.1 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>KubeSphere 社区双周报主要整理展示新增的贡献者名单和证书、新增的讲师证书以及两周内提交过 commit 的贡献者，并对近期重要的 PR 进行解析，同时还包含了线上/线下活动和布道推广等一系列社区动态。</p><p>本次双周报涵盖时间为：2023.10.27-2023.11.09。</p><h2>贡献者名单</h2><p><img src="https://oscimg.oschina.net/oscnet/up-19dea7efe9006edc4fbe02ed14d7f6c2cf9.gif" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-561990cd09bca795835d53b08821ba25daf.png" alt="" referrerpolicy="no-referrer"></p><h2>新晋 KubeSphere Contributor</h2><p>两周内共有 8 位新晋 KubeSphere Contributor，感谢各位对 KubeSphere 社区的贡献！</p><table><thead><tr><th>GitHub ID</th><th>证书</th></tr></thead><tbody><tr><td>Ganbingkun</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-Ganbingkun.png" target="_blank">下载证书</a></td></tr><tr><td>MisterMX</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-MisterMX.png" target="_blank">下载证书</a></td></tr><tr><td>Shimada666</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-Shimada666.png" target="_blank">下载证书</a></td></tr><tr><td>donniean</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-donniean.png" target="_blank">下载证书</a></td></tr><tr><td>guerzon</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-guerzon.png" target="_blank">下载证书</a></td></tr><tr><td>liuxu623</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-liuxu623.png" target="_blank">下载证书</a></td></tr><tr><td>nyuxiao</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-nyuxiao.png" target="_blank">下载证书</a></td></tr><tr><td>samt42</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fcontributor-2023-samt42.png" target="_blank">下载证书</a></td></tr></tbody></table><h2>新晋 KubeSphere Talented Speaker</h2><p>在上周六（11.4）KubeSphere 社区联合 SOFAStack 社区及 KubeBlocks 社区共同组织了成都站 Meetup，在本次 Meetup 中共诞生了五位新的 KubeSphere Talented Speaker，他们在本次活动中贡献了精彩的演讲。</p><table><thead><tr><th>姓名</th><th>证书</th></tr></thead><tbody><tr><td>王勤龙</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fspeaker-2023-wangqinlong.png" target="_blank">下载证书</a></td></tr><tr><td>魏泓舟</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fspeaker-2023-weihongzhou.png" target="_blank">下载证书</a></td></tr><tr><td>胡子杰</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fspeaker-2023-huzijie.png" target="_blank">下载证书</a></td></tr><tr><td>刘东明</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fspeaker-2023-liudongming.png" target="_blank">下载证书</a></td></tr><tr><td>吴学强</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpek3b.qingstor.com%2Fkubesphere-community%2Fimages%2Fspeaker-2023-wuxueqiang.png" target="_blank">下载证书</a></td></tr></tbody></table><h2>近期更新</h2><h3>KubeSphere</h3><h4>1. KubeSphere 3.4.1 发布</h4><p>相关 release：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Freleases%2Ftag%2Fv3.4.1" target="_blank">https://github.com/kubesphere/kubesphere/releases/tag/v3.4.1</a></p><h3>Fluent Operator</h3><h4>1. FluentBit 升级到 2.1.10 版本</h4><p>相关 PR: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffluent%2Ffluent-operator%2Fpull%2F978" target="_blank">https://github.com/fluent/fluent-operator/pull/978</a></p><p>贡献者：wenchajun</p><h4>2. 为 Fluentd 添加存活及就绪探针</h4><p>相关 PR: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffluent%2Ffluent-operator%2Fpull%2F980" target="_blank">https://github.com/fluent/fluent-operator/pull/980</a></p><p>贡献者：cw-Guo</p><h4>3. 为 Fluentd 添加输入插件 monitor_agent</h4><p>相关 PR: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffluent%2Ffluent-operator%2Fpull%2F967" target="_blank">https://github.com/fluent/fluent-operator/pull/967</a></p><p>贡献者： joshuabaird</p><h4>4. 修改 helm chart，使其可以传递 Fluentd env 变量</h4><p>相关 PR: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffluent%2Ffluent-operator%2Fpull%2F977" target="_blank">https://github.com/fluent/fluent-operator/pull/977</a></p><p>贡献者：guerzon</p><h2>社区动态</h2><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NTU0MzEyMg%3D%3D%26mid%3D2247526692%26idx%3D1%26sn%3D910c266022887e1adfd9b9167d5c70e3%26chksm%3Dcfa57099f8d2f98f6c7a36f29a72c50f107f71e036550bef87b20adbebeef66c637b6efc7b1f%26token%3D524162139%26lang%3Dzh_CN%23rd" target="_blank">OpenFunction 1.2.0 发布：集成 KEDA http-addon 作为同步函数运行时</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NTU0MzEyMg%3D%3D%26mid%3D2247526860%26idx%3D1%26sn%3D69e7c60e8265c01cc2ab0860c6710348%26chksm%3Dcfa57071f8d2f967a26f7caf3febd620ccc6e67c8e3db1c0c40b8793cfd74dce0720a9a675d1%26token%3D524162139%26lang%3Dzh_CN%23rd" target="_blank">云原生 + AI Meetup 成都站（11.4）精彩回顾（视频回放 + PPT）</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fconferences%2Falerting-2023%2F" target="_blank">以 Kubernetes 原生方式实现多集群告警</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fblogs%2Fdeploy-kubesphere-v3.4.0-on-arm-openeuler-2%2F" target="_blank">ARM 版 openEuler 22.03 部署 KubeSphere 3.4.0 不完全指南续篇</a></li></ul><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 06:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10142489</guid>
            <link>https://my.oschina.net/u/4197945/blog/10142489</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Slowquery —— 图形化显示 MySQL 慢日志平台]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span style="background-color:#ffffff; color:#1f2328">Slowquery</span>&nbsp;是一个开源的 PHP Web 应用程序，旨在帮助数据库管理员（DBA）和开发者更好地管理和监控 MySQL 数据库的慢查询日志。它提供了一个简单易用的界面，可以方便地查看和分析慢查询日志，并提供了许多有用的功能，例如慢查询邮件报警和自动发送慢查询分析报告等。</p><p>以下是主要功能和特点：</p><ol><li>显示慢查询日志：提供了一个实时更新的界面，可以显示数据库中的慢查询日志，包括执行时间、执行次数、SQL 语句等信息。用户可以通过界面轻松地查看和分析慢查询日志，找到哪些查询是慢查询，并了解它们的执行情况。</li><li>慢查询搜索和筛选：提供了强大的搜索和筛选功能，使用户可以快速找到感兴趣的慢查询。用户可以通过执行时间、执行次数、SQL 语句等多个维度进行搜索和筛选，还可以对搜索结果进行排序和过滤，以便更好地了解慢查询的情况。</li><li>慢查询分析：提供了慢查询分析功能，可以对慢查询进行深入的分析和诊断。它可以将慢查询与数据库的表结构进行关联，显示每个表的查询次数和平均执行时间等信息，使用户更好地了解慢查询的本质和根源。</li><li>邮件报警：支持配置邮件报警功能，可以自动发送慢查询分析报告和警报信息给指定的邮箱。用户可以根据需要设置报警阈值和报警时间等参数，以便及时了解数据库的性能问题。</li></ol><hr><p style="color:#1f2328; text-align:start">参考了开源工具 Anemometer 图形展示思路，开发在页面上点击慢 SQL，就会自动反馈优化建议，同时也支持自动发送邮件报警功能。</p><p style="color:#1f2328; text-align:start">agent 客户端慢日志采集分析是结合 Percona pt-query-digest 工具来实现。</p><hr><p><img alt="image" src="https://camo.githubusercontent.com/a7f7c0d40aafb4a0ac83921b84b47902b62dbcfd151e2c1a160f7ba85c605e6a/68747470733a2f2f646261706c75732e636e2f75706c6f616466696c652f323031392f303332302f32303139303332303130313730393136352e6a7067" referrerpolicy="no-referrer"></p><p><img alt="image" src="https://camo.githubusercontent.com/bf8132e9b985c985d7cba6c81af73f89027c0b145c064d0d27231d3201f35686/68747470733a2f2f646261706c75732e636e2f75706c6f616466696c652f323031392f303332302f32303139303332303130313732343432382e6a7067" referrerpolicy="no-referrer"></p><p><img height="768" src="https://oscimg.oschina.net/oscnet/up-fdcdf886f52f4aced8b0a9733ed59f75b68.png" width="1366" referrerpolicy="no-referrer"></p><hr><p style="color:#1f2328; text-align:start"><span style="background-color:#ffffff; color:#1f2328">视频演示：</span><a href="https://www.douyin.com/video/7278552026181586216">https://www.douyin.com/video/7278552026181586216</a></p><hr><p style="color:#1f2328; text-align:start">服务端部署</p><h1 style="margin-left:0; margin-right:0; text-align:start"><a href="https://github.com/hcymysql/slowquery#%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F">拉取镜像</a></h1><div style="text-align:start"><pre><code>shell&gt; docker pull docker.io/hcymysql/slowquery:2023-09-13</code></pre></div><h1 style="margin-left:0; margin-right:0; text-align:start"><a href="https://github.com/hcymysql/slowquery#%E5%90%AF%E5%8A%A8">启动</a></h1><div style="text-align:start"><pre><code>shell&gt; docker run -itd -e "TERM=xterm-256color" --privileged --name slowquery -p 80:80 -p 3306:3306 &lt;IMAGE ID&gt; /usr/sbin/init
</code></pre></div><h1 style="margin-left:0; margin-right:0; text-align:start"><a href="https://github.com/hcymysql/slowquery#%E8%BF%9B%E5%85%A5docker%E9%87%8C%E5%90%AF%E5%8A%A8httpd%E6%9C%8D%E5%8A%A1">进入 docker 里，启动 httpd 服务</a></h1><div style="text-align:start"><pre><code>shell&gt; docker exec -it slowquery /bin/bash
shell&gt; systemctl start httpd.service </code></pre></div><hr><h1><span>​</span>录入你要监控的 MySQL 主库配置信息</h1><div style="text-align:start"><pre><code>mysql&gt; INSERT INTO slowquery.dbinfo VALUES (1,'192.168.148.101','test','admin','123456',3306);
</code></pre><div><hr><p>客户端部署</p></div></div><p style="color:#1f2328; text-align:start">进入到 slowquery/client_agent_script 目录下，把 slowquery_analysis.sh 脚本拷贝到生产 MySQL 主库上做慢日志分析推送，并修改里面的配置信息</p><p style="color:#1f2328; text-align:start">定时任务（10 分钟一次）</p><div style="text-align:start"><pre><code>*/10 * * * * /bin/bash /usr/local/bin/slowquery_analysis.sh &gt; /dev/null 2&gt;&amp;1</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://github.com/hcymysql/slowquery#%E6%89%93%E5%BC%80%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5httpyouripslowqueryslowqueryphp">打开浏览器，输入</a><a href="http://yourip/slowquery/slowquery.php">http://yourIP/slowquery/slowquery.php</a></p><hr><h1 style="text-align:start">慢查询邮件推送报警配置</h1><p style="color:#1f2328; text-align:start">进入到 slowquery/alarm_mail/目录里，修改 sendmail.php 配置信息</p><p style="color:#1f2328; text-align:start">定时任务（每隔 3 小时慢查询报警推送一次）</p><div style="text-align:start"><pre><code>0 */3 * * * cd /var/www/html/slowquery/alarm_mail;/usr/bin/php  /var/www/html/slowquery/alarm_mail/sendmail.php</code></pre></div><p><img alt="image" src="https://camo.githubusercontent.com/f473330c47bae487618e026e4a2b1a333f40225ddf7dbc49e4d2bab2b863b017/68747470733a2f2f646261706c75732e636e2f75706c6f616466696c652f323031392f303332302f32303139303332303130313832363135302e6a7067" referrerpolicy="no-referrer"></p><p><img height="643" src="https://oscimg.oschina.net/oscnet/up-5579779848fc6de5f8ba128de399d97154d.png" width="1158" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 06:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/slowquery</guid>
            <link>https://www.oschina.net/p/slowquery</link>
        </item>
    </channel>
</rss>
