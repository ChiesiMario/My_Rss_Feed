<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 10 Nov 2023 07:14:03 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[中国电信发布千亿级参数星辰语义大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#494949"><span><span style="color:#222222">在 2023 数字科技生态大会上，中国</span><span style="color:#222222">国电信发布千亿级参数规模的星辰语义大模型。同时，星辰多模态大模型、星辰系列行业大模型也一并亮相。</span></span></p><p style="color:#494949"><span><span style="color:#222222">根据介绍，星辰语义大模型是中国电信自研大模型的升级，由此前的百万参数量级升至千亿，升级后在抑制幻觉、外推窗口、交互体验、多轮理解能力上均有所提升。</span></span></p><p style="color:#494949"><span><span style="color:#222222">技术方面，星辰语义拥有超 12 亿风格数据、训练显存降低 50%、推理提速 4.5 倍；中文意象理解生成能力提升 30%；语义细粒度生成效果提升 25%。在创意提效方面，星辰语义生产时间较此前生产工具减少 92%；设计成本下降 95%。</span></span></p><p style="color:#494949"><span><span style="color:#222222">中国电信方面表示，计划于今年 12 月开源百亿参数大模型；2024 年 4 月开源千亿参数大模型，明年 3 月实现平台工具的开放。</span></span></p><p style="color:#494949"><span><span style="color:#222222">此外，中国电信还在会议现场陆续发布了一连串产品及平台，其中一站式智算服务平台「慧聚」可实现模型开发、任务管理、模型优化、服务部署、模型服务等多项功能；中国电信「天衍」量子计算云平台则具备指数级加速大模型训练速率的潜力。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 06:37:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265881</guid>
            <link>https://www.oschina.net/news/265881</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[IntelliJ IDEA 2023.3 Beta 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#494949"><span style="display:none">&nbsp;</span><span style="color:#000000">IntelliJ IDEA 2023.3 Beta 版本现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2023%2F11%2Fintellij-idea-2023-3-beta%2F" target="_blank">发布</a>，此版本包括抢先体验计划期间引入的所有重要更新。以下是即将发布的主要版本中最值得注意的改进和新增功能列表：</span></p><ul><li><span style="color:#000000">完全支持 Java 21 功能</span></li><li><span style="color:#000000">调试器中的 Run to Cursor 嵌入选项</span></li><li><span style="color:#000000">具有代码编辑操作的浮动工具栏</span></li><li><span style="color:#000000">支持 GitLab snippets</span></li><li><span style="color:#000000">All-in-one diff viewer</span></li><li><span style="color:#000000">Maven 和 Gradle 导入的改进</span></li><li><span style="color:#000000">OpenAPI 规范的可视化编辑</span></li><li><span style="color:#000000">Quarkus 和 Micronaut 的增强功能</span></li><li><span style="color:#000000">Spring 6.1 功能支持</span></li><li><span style="color:#000000">Spring for GraphQL 支持</span></li><li><span style="color:#000000">开箱即用的 Kubernetes 工具</span></li><li><span style="color:#000000">Extended Dev Containers 支持</span></li><li><span style="color:#000000">HTTP 客户端改进</span></li></ul><p style="color:#494949"><span style="color:#000000"><strong>最新的 Kotli</strong><strong>n 版本支持现已随</strong><strong> IDE 更新一起提供</strong></span></p><p style="color:#494949"><span style="color:#000000">从 v2023.3 开始，对新 Kotlin 版本的支持与 IntelliJ IDEA 和 Android Studio 更新一起提供，这意味着用户不再需要从 JetBrains Marketplace 更新 Kotlin 插件。在每个主要 IDE 版本中，都可以有即将推出的 Kotlin Beta 和稳定版本的内置支持。</span></p><p style="color:#494949"><span style="color:#000000"><strong>Java Gradle 项目中的 Kotlin 自动配置</strong></span></p><p style="color:#494949"><span style="color:#000000">如果将 Kotlin 文件添加到 Java 模块，IntelliJ IDEA 现在可以通过更改构建脚本自动将所有需要的 Kotlin 依赖项添加到模块。你可以轻松查看这些更改并撤消它们。&nbsp;</span></p><p style="color:#494949"><span style="color:#000000">目前，满足特定标准的 Gradle 项目可以进行自动配置，其中一些标准包括：</span></p><ul><li><span style="color:#000000">Gradle 版本必须与该项目可用的 Kotlin 版本兼容。&nbsp;</span></li><li><span style="color:#000000">模块不得包含「buildSrc」文件夹。</span></li><li><span style="color:#000000">Gradle sync 不得正在进行，中。&nbsp;</span></li></ul><p style="color:#494949"><span style="color:#000000">如果无法自动配置，IDE 将建议用户可以像以前一样手动配置 Kotlin。<span style="display:none">&nbsp;</span></span></p><p style="color:#494949"><span style="color:#000000"><strong>插件更新</strong></span></p><p style="color:#494949"><span style="color:#000000">在 IntelliJ IDEA 2023.3 及更高版本中，对插件分发进行了更改。Android、Ant 和 GlassFish 插件现已通过 JetBrains Marketplace 提供。这也适用于 IntelliJ IDEA 社区版的 XPathView 插件。</span></p><p><span style="color:#000000">详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2023%2F11%2Fintellij-idea-2023-3-beta%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 06:21:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265876/intellij-idea-2023-3-beta</guid>
            <link>https://www.oschina.net/news/265876/intellij-idea-2023-3-beta</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[诺基亚在开源云平台 Sylva 成功进行 5G 独立组网测试]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>诺基亚<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nokia.com%2Fabout-us%2Fnews%2Freleases%2F2023%2F11%2F09%2Fnokia-conducts-successful-tests-of-5g-standalone-core-with-orange-on-sylva-open-source-cloud-stack%2F" target="_blank">发布新闻稿称</a></u>，他们与电信运营商 Orange 共同合作，在开源云平台 Sylva 成功进行了 5G 独立组网 (5G Standalone Core, 5G SA) 测试。</p><p>文章提到诺基亚 5G SA 核心网络功能的互操作性测试在法国 Orange 的 Sylva 验证中心成功完成。</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/140712_6l0n_2720166.png" referrerpolicy="no-referrer"></p><p>据介绍，Sylva 的整体目标是提供一个可被广泛使用的开源云平台，专为电信和边缘计算场景而定制，以解决行业的技术挑战。 Sylva 于 2022 年底在 Linux 欧洲基金会旗下推出，其支持者包括诺基亚和 Orange。</p><p>测试验证是提供灵活的云原生解决方案的关键一步，该解决方案可实现 5G SA 核心网络功能的大规模部署。对于 5G 专用无线企业客户，Sylva 旨在提供一种在边缘设备部署工业 4.0、物联网和 B2B2X 用例的有效方法。</p><p>诺基亚核心网络、云和网络服务高级副总裁兼总经理 Fran Heeran 表示：「诺基亚完全云原生的核心网络产品组合旨在通过开放、灵活的部署选项来支持不断发展的电信云环境，同时大大减少集成度，以及提供先进的自动化能力。由 Orange 主办的 Sylva 验证中心成功完成了 5G SA 核心用户平面功能 (User Plane Function) 的互操作性测试，这突显了我们的承诺和我们正在取得的进步。」</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 06:19:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265875</guid>
            <link>https://www.oschina.net/news/265875</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GitHub 发布开源编程字体家族 Monaspace]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GitHub 推出了名为「Monaspace」的开源等宽编程字体家族。</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/120711_f6hb_2720166.png" referrerpolicy="no-referrer"></p><p>地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmonaspace.githubnext.com%2F" target="_blank">https://monaspace.githubnext.com/</a></u></em></p><blockquote>
 「字体家族」（typeface / font family）和 「单款字体」（font）是不同的概念，虽然通常习惯将两者都称作 「字体」，但一个字体家族通常包含多个单款字体，字型之间以字重（粗细）、风格（正斜体）等设置区分开来。
 <br><br> 简而言之，「字体家族」 是一整套的设计，其中包含若干款 「字体」，即单独的字体文件。
</blockquote><p>根据介绍，「GitHub Monaspace」作为字体家族，整体可分为<strong>「静态」和「可变」</strong>两种类型。</p><ul><li><code>Monaspace _____</code>代表<strong>静态</strong></li><li><code>Monaspace _____ Var</code>或<code>VF</code>代表<strong>可变</strong></li></ul><p>其中「可变」字体的每个系列都包含一个文件（Neon、Argon 等）。GitHub Monaspace 总共包含 5 种字体，由于它们的属性相互兼容，因此可以混搭使用。</p><p>官方介绍道，等宽字体通常彼此不兼容。因为每个字体都使用不同的字型度量，所以无法对不同的字体进行混用。不过 GitHub Monaspace 的每款字体都经过精心设计，支持无缝混搭使用和匹配。通过超越颜色和更大胆的权重的调色板，为代码赋予更多含义，为需要更多结构和层次结构的代码构建接口。</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/121225_m9Kc_2720166.png" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1110/121823_4wpr_2720166.png" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1110/123709_02AU_2720166.png" referrerpolicy="no-referrer"></p><p>下面是单独使用 Xe 字体的效果：</p><p><img height="1228" src="https://static.oschina.net/uploads/space/2023/1110/121353_QrHp_2720166.png" width="1716" referrerpolicy="no-referrer"></p><p>开发者可基于上述 5 种字体任意搭配组合使用，如下：</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/121517_ONNu_2720166.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 04:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265861</guid>
            <link>https://www.oschina.net/news/265861</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[亚马逊开发基于 Linux 的操作系统，以摆脱 Android 依赖]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Lowpass 记者 Janko Roettgers 从多方消息来源<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lowpass.cc%2Fp%2Famazon-vega-os-fire-tv-android" target="_blank">得知</a>，亚马逊一直在开发一种新的操作系统 —— 内部代号为「Vega」，以便在 Fire TV、智能显示器和其他联网设备上取代 Android 系统。</span></p><p><span style="color:#000000">一直以来，亚马逊的一些智能家居设备都使用了名为 Fire OS 的 Android 分叉版本。但也正是因为依赖 Android 开源项目来构建 Fire OS，导致该公司操作系统的开发落后于谷歌多年。</span></p><p><span style="color:#000000">而 Vega 并不是一个新的 Android 分叉，也不是基于 AOSP，「是一种基于 Linux 的风格，并采用了一种更加面向网络的应用模式。应用程序开发人员被告知使用 React Native 作为应用程序框架，这样他们就可以使用 Javascript 驱动的界面来构建本地应用程序。」</span></p><p><img height="333" src="https://static.oschina.net/uploads/space/2023/1110/120051_g6gS_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">目前，亚马逊设备操作系统部门已有"数百人"在致力于新操作系统的开发，其中就包括前 Mozilla 工程师和 Javascript 专家 Zibi Braniecki。Branieck 于 2022 年初加入亚马逊从事 Alexa 工作，然后在 2023 年初过渡到设备操作系统团队。他当时曾在 LinkedIn 上透露，自己正在「为智能家居、汽车和其他亚马逊设备产品线开发下一代操作系统」。</span></p><p><span style="color:#000000">Roettgers 指出，Vega 开发进度似乎相当快。该系统已经在 Fire TV 流媒体适配器上进行了测试，且亚马逊已向部分合作伙伴透露了在不久的将来过渡到新应用框架的计划。</span></p><p><span style="color:#000000">一位了解该公司计划的消息人士表示，亚马逊最早可能会在明年开始在部分 Fire TV 设备上搭载 Vega。SDK 也正在准备发布，以便开发人员在 Vega 上市前将他们的应用程序移植到 Vega 上。</span></p><p><span style="color:#000000">此外，消息称亚马逊的<strong>最终目标是在其所有的新设备上摆脱对 Android 的依赖</strong>。Vega 不仅可以在 Fire TV 和智能显示器上运行，还可以在车载娱乐系统和其他未来的硬件产品上运行。亚马逊发布的多份招聘信息显示，Vega 将成为其汽车业务的关键。</span></p><p><span style="color:#000000">Vega 的出现，也帮助亚马逊避免了与谷歌的进一步冲突。Roettgers 称，两家公司长期以来一直为亚马逊使用 Android 系统的问题争吵不休，谷歌曾一度向硬件制造商施压，要求他们不要生产搭载亚马逊系统的智能电视。直到后来两家公司达成协议，允许亚马逊与海信和 TCL 等电视机制造商合作」，但亚马逊放弃 Android 系统后，应该能更好地掌控自己的命运。「</span></p><p><span style="color:#000000">不过一些业内人士认为，<span style="background-color:#ffffff">竞争压力可能并不是亚马逊转向 Vega 的主要原因。亚马逊真正关心的是如何在各种廉价设备上吸引数亿眼球，然后通过广告和服务将其货币化--而内置定制操作系统可能正是实现这一目标的最佳途径。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 04:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265858/amazon-vega-linux-based-os</guid>
            <link>https://www.oschina.net/news/265858/amazon-vega-linux-based-os</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[文心一言用户规模已达 7000 万]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在前沿数字技术创新与安全论坛和人工智能赋能产业发展论坛上，百度 CTO 王海峰</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbH6zON1itJDh9bwCAeLfWw" target="_blank"><span style="color:#2980b9">披露</span></a><span style="color:#000000">，文心一言自 8 月 31 日面向全社会开放至今，用户规模现已达到 7000 万，场景 4300 个，应用 2492 个。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://static.oschina.net/uploads/space/2023/1110/115002_eScQ_4252687.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">王海峰表示，人工智能是新一轮科技革命和产业变革的重要驱动力量，深度学习作为人工智能的核心技术，具有很强的通用性，并具备标准化、自动化和模块化的工业大生产特征，而大模型的兴起，使得人工智能应用的深度和广度进一步拓展。人工智能已进入工业大生产阶段。</span></p><p><span style="color:#000000">例如，标准化方面，框架和模型联合优化，多硬件统一适配，应用模式简洁高效，大幅降低人工智能应用门槛；自动化方面，从训练、适配，到推理部署，提升人工智能研发全流程效率；模块化方面，丰富的产业级模型库，支撑人工智能在广泛场景的便捷应用。</span></p><p><span style="color:#000000">王海峰认为，人工智能具有多种典型能力，理解、生成、逻辑、记忆是其中的基础能力，这四项能力越强，越接近通用人工智能，而大语言模型具备了这四项能力，且越来越强，为通用人工智能带来了曙光。</span></p><p><span style="color:#000000">面对大模型产业化的挑战，王海峰表示，类似芯片代工厂模式，可以采用「集约化生产，平台化应用」的模式，即具有算法、算力和数据综合优势的企业将模型生产的复杂过程封装起来，通过低门槛、高效率的生产平台，为千行百业提供大模型服务。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 02:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265847</guid>
            <link>https://www.oschina.net/news/265847</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME 获 100 万欧元投资]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">GNOME 基金会<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffoundation.gnome.org%2F2023%2F11%2F09%2Fgnome-recognized-as-public-interest-infrastructure%2F" target="_blank">宣布</a></u>收到了来自「<span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund</span>」的 100 万欧元投资，并表示这笔资金将用于实现平台现代化、改进工具和可访问性，并支持符合公共利益的功能。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><img src="https://static.oschina.net/uploads/space/2023/1110/122408_NeTS_2720166.png" referrerpolicy="no-referrer"></p><p>具体包括：</p><ul><li>改进当前的可访问性状态</li><li>设计新的辅助功能堆栈并制作原型</li><li>支持单独加密 user 主目录</li><li>实现现代化的秘密存储</li><li>扩大硬件支持的范围和质量</li><li>为质量保证和开发者体验投入资源</li><li>扩展和拓宽 freedesktop API</li><li>整合和改进平台组件</li></ul><p><span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund 是</span>德国政府资助的一项计划，由 Adriana Groh 和 Fiona Krakenbürg 运营，他们在国家和国际层面拥有「多年推广开源技术的经验」。目标是支持「开源数字基础设施的开发、改进和维护」，这与 GNOME 项目的协同作用是显而易见的。</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/122533_HxD1_2720166.png" referrerpolicy="no-referrer"></p><p>他们在官方网站写道：「.....开源生态虽然非常成功，但也越来越脆弱。因为使用开源软件的人永远比为该软件做出贡献的人多。现在是投资数字共享、志愿者社区和开源来建设我们希望看到的数字世界的时候了。」</p><p><span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund 投资过的项目</span>包括 curl、Fortran、WireGuard、OpenSSH、Yocto，以及与 OpenJS 基金会合作「改进 Javascript 生态基础设施和安全性」。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 02:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265839/gnome-sovereign-tech-fund</guid>
            <link>https://www.oschina.net/news/265839/gnome-sovereign-tech-fund</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[正在被代码折磨到深夜的你，何不请 AI 帮帮你]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在生成式 AI 工具规模化应用仍被质疑和观望的时候，由其生成的内容、视觉、代码程序已经高速涌入大众视野。AI 技术一日千里，拥抱 AI 开发工具或将成为向未来工程师的进化的必经之路。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/204756_bv5c_2720166.gif" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="text-align:center"><strong>「半天时间就能梳理 20000 行代码」</strong></p><p>大星是某电商业务的后端核心研发，入行 3 年，成长很快，已经是项目 owner 独当一面。但是大星也自有烦恼，电商促销活动频繁，且因为需求方复杂，经常需要处理突发状况，还有一个「重灾区」就是频繁修复历史技术债，不断打补丁，使得系统的可维护性越来越差，重构迫在眉睫。</p><p>今年提前两个月，双十一大促进入筹备期。大星发现，如果不尽快重构系统，不仅很难继续补丁式的开发新活动，甚至稳定性也存在风险。但是重构系统又与新的开发工作存在矛盾，人力有限，极容易顾此失彼。这时，大星想到了近期在试用的百度 Comate 研发插件，在理解老代码、生成注释方面都有不错的表现，于是大星和小伙伴，迅速梳理了遗留的老代码，制定了新优惠逻辑的实现融合方案，快速融合了新旧优惠逻辑，2 名研发只用了半天时间完成了 20000 多行代码的梳理。</p><p>后来，大星多次分享了这次经历：「这不仅等于增派了研发人力，更重要的是百度 Comate 理解更准确，注释生成更规范。这次成功救场，启发我作为工程师，更应该超前使用新工具，这样才能跑得更快。」</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/204929_EoB7_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><strong>「不被语言所困，我就是研发 E 人！」</strong></p><p>去年毕业的小韩，作为优秀校招生入职大厂，工作一年有余，由于好学爱折腾，已经接了不少项目。最近，小韩接手了一个新项目，该项目的实现语言是 Go，但是小韩不太擅长，另外，由于对项目的已有代码不熟悉，让他接手项目和快速修改其中的内容有了不少阻碍。</p><p>他想到平时使用的百度 Comate，利用其代码解释和使用其它语言实现的能力，快速理解了项目已有的代码，高质量实现了快速接手任务，得到了团队内其他成员的一致好评。</p><p>「我属于程序员 E 人，平时喜欢多交流，百度 Comate 就是小伙伴推荐的，我发现，面对短板，找到方法其实就能快速弯道超车，这对研发新人很重要。」小韩直言不讳。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205015_NLab_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><strong>「用好工具，重组生产要素，提升研发生产力」</strong></p><p>作为研发团队管理者，大刚最近痛失两名 QA，新的 QA 迟迟招不到，团队的 bug 数直线上升，质量危机迫在眉睫，将近年底，眼看质量指标达成就要灰飞烟灭。多年的经验告诉大刚要沉下心来，仔细分析找到解法，在角色、人力、环节、工时、质量几个维度上设计出最优解。</p><p>通过分析，大刚逐步梳理出了解法：既然人力缺失，是否尽可能利用自动化能力来减少人工的投入，如在每次回归测试中释放 QA 的人力。再推导一步：如果对现有代码批量生成单元测试，对于缓解 QA 人力紧缺也将有非常大的帮助。</p><p>最后，大刚决定使用百度 Comate 插件来解决这些问题。大刚和团队研发成员一起，针对遗留代码和新增的代码，使用百度 Comate 的单测生成能力，快速的生成了满足业务要求的单元测试代码，通过自动化的方式实现回归验证，保证代码在变更后的运行结果符合预期情况，将测试环节左移，更早发现问题，减少后续环节的人力投入。</p><p>大刚团队的案例，是通过百度 Comate 生成了主要流程的单元测试用例，虽然在研发过程中看上去对单个功能的开发时间加长了，但是方案保证了核心流程的正确性，提高验证效率，最大化的缓解了人员紧缺的情况。</p><p>后来大刚在覆盘中，这样总结：「研发是一个系统性工程，不仅有人人协同，还有人机协同，用好工具提升人机协同能力，重组生产要素，用技术的力量提升研发生产力。」</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205101_OWD9_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205125_R8fr_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><h3 style="text-align:center"><strong>⭐ 百度 Comate SaaS 有哪些优势？</strong></h3><p style="color:#000000; text-align:left"><span>依托文心大模型和飞桨，百度 Comate 具备多项卓越能力。例如，在和用户交互的过程中，需要准确理解用户的意图，以及根据用户的意图做出合理的解答。借助文心大模型对自然语言、代码的理解和</span><span style="color:#1c1d1f">生成</span><span>的能力，百度 Comate 在人与模型交互、代码内容的理解、知识点输出方面，都达到了领先水准，能够回答更加准确、服务更多类型的研发需求。再比如，在代码续写的场景中，需要模型能够跟得上用户的思路，即代码还没写完，就给用户正确的提示，这就需要更快的响应速度，基于飞桨的推理框架，可以让模型在推理时响应速度更快，用户体验更好。</span></p><p style="color:#000000; text-align:left"><span>在具体性能表现上，百度 Comate SaaS 支持单行推荐、多行推荐、多条推荐、代码知识的问答、代码生成、注释生成、注释文档生成、代码解释、生成行间注释、函数拆分、优化和重构等一系列编码相关的能力，在编程现场实现帮你想、帮你写、帮你改代码的效果。</span></p><p style="color:#000000; text-align:left"><span>此外，经过测试，百度 Comate 在易用性、速度、安全性、使用体验上具有明显优势。功能完备，开箱即用，后续支持私域数据索引，推理结果更精准。在使用体验上，支持全中文交互，交互速度更快，体验更好；领先的安全机制保证代码数据的安全，同时成本和部署方式上也更灵活、更具高性价比。</span></p><h3 style="text-align:center"><strong>🌈 限时福利！</strong></h3><p><span style="color:#2980b9"><strong>福利一：限时免费试用</strong></span>（活动时间：即日起- 11 月 20 日）</p><ul><li><p>扫描或长按下图二维码，即装即用，<span style="color:#c0392b"><strong>限时领取免费试用 1 个月！</strong></span></p></li><li><p>邀请其他人注册，<span style="color:#c0392b"><strong>每分享 1 人注册成功，即可获得+1 个月免费试用期，总计最高获得 6 个月免费试用</strong>。</span></p></li></ul><p><span style="color:#2980b9"><strong>福利二：限时特价</strong></span>（活动时间：即日起- 11 月 20 日）</p><p style="text-align:center"><img height="557" src="https://static.oschina.net/uploads/space/2023/1110/144509_QoI6_2720166.png" width="1268" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><h4 style="text-align:center"><span style="color:#c0392b"><strong>以上福利扫码立即获得！</strong></span></h4><p>下载下面图片➡️转发小伙伴，成功推荐其他新用户，即可延长免费试用时间，最高得 6 个月免费试用～</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1110/144648_TUoU_2720166.jpg" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 12:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265796</guid>
            <link>https://www.oschina.net/news/265796</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软计划为 Windows 10 提供 AI 助手 Copilot]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fwindows-10%2Fexclusive-microsoft-plans-to-bring-its-ai-copilot-to-1-billion-windows-10-users" target="_blank">根据 Windows Central 的报道</a></u>，微软计划将 Copilot 引入 Windows 10。该公司做出这一决定的主要原因是希望为 Copilot 增加更多用户。</p><p>Windows 11 最近发布的重大更新 v23H2 包含了 AI 助手 Copilot，它直接添加到了桌面的工具栏上。但 Windows 11 的用户数目前还远不及上一代的 Windows 10，而微软致力于让每个用户都能使用 Copilot，它正计划向有 10 亿用户的 Windows 10 提供 Copilot。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7b7b3e6ab4e1286eb6e8ecd2789040a2a53.png" referrerpolicy="no-referrer"></p><p>Windows 10 的 Copilot 和 Windows 11 基本一致，Copilot 按钮放置在工具栏上，点击该按钮会显示一个可用于对话的侧边栏。</p><p>报道还指出，Windows 10 和 Windows 11 的 Copilot 体验将是相同的，包括插件的兼容性。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265760</guid>
            <link>https://www.oschina.net/news/265760</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[reverse_sql —— MySQL 数据闪回恢复工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">reverse_sql 是一个用于解析和转换 MySQL 二进制日志（binlog）的工具。它可以将二进制日志文件中记录的数据库更改操作（如插入、更新、删除）转换为反向的 SQL 语句，以便进行数据恢复。其运行模式需二进制日志设置为 ROW 格式。</p><p style="color:#1f2328; text-align:start">该工具的主要功能和特点包括：</p><p style="color:#1f2328; text-align:start">1、解析二进制日志：reverse_sql 能够解析 MySQL 的二进制日志文件，并还原出其中的 SQL 语句。</p><p style="color:#1f2328; text-align:start">2、生成可读的 SQL：生成原始 SQL 和反向 SQL。</p><p style="color:#1f2328; text-align:start">3、支持过滤和筛选：可以根据时间范围、表、DML 操作等条件来过滤出具体的误操作 SQL 语句。</p><p style="color:#1f2328; text-align:start">4、支持多线程并发解析 binlog 事件。</p><h3 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#%E4%BD%BF%E7%94%A8">使用</a></h3><div style="text-align:start"><pre><code>shell&gt; chmod 755 reverse_sql
shell&gt; ./reverse_sql --help
usage: reverse_sql [-h] [-ot ONLY_TABLES [ONLY_TABLES ...]] [-op ONLY_OPERATION] -H MYSQL_HOST
                   -P MYSQL_PORT -u MYSQL_USER -p MYSQL_PASSWD -d MYSQL_DATABASE
                   [-c MYSQL_CHARSET] --binlog-file BINLOG_FILE [--binlog-pos BINLOG_POS]
                   --start-time ST --end-time ET [--max-workers MAX_WORKERS] [--print]

Binlog 数据恢复，生成反向 SQL 语句。

options:
  -h, --help            show this help message and exit
  -ot ONLY_TABLES [ONLY_TABLES ...], --only-tables ONLY_TABLES [ONLY_TABLES ...]
                        设置要恢复的表，多张表用,逗号分隔
  -op ONLY_OPERATION, --only-operation ONLY_OPERATION
                        设置误操作时的命令（insert/update/delete）
  -H MYSQL_HOST, --mysql-host MYSQL_HOST
                        MySQL 主机名
  -P MYSQL_PORT, --mysql-port MYSQL_PORT
                        MySQL 端口号
  -u MYSQL_USER, --mysql-user MYSQL_USER
                        MySQL 用户名
  -p MYSQL_PASSWD, --mysql-passwd MYSQL_PASSWD
                        MySQL 密码
  -d MYSQL_DATABASE, --mysql-database MYSQL_DATABASE
                        MySQL 数据库名
  -c MYSQL_CHARSET, --mysql-charset MYSQL_CHARSET
                        MySQL 字符集，默认 utf8
  --binlog-file BINLOG_FILE
                        Binlog 文件
  --binlog-pos BINLOG_POS
                        Binlog 位置，默认 4
  --start-time ST       起始时间
  --end-time ET         结束时间
  --max-workers MAX_WORKERS
                        线程数，默认 4（并发越高，锁的开销就越大，适当调整并发数）
  --print               将解析后的 SQL 输出到终端
  --replace             将 update 转换为 replace 操作

Example usage:
    shell&gt; ./reverse_sql -ot table1 -op delete -H 192.168.198.239 -P 3336 -u admin -p hechunyang -d hcy \
            --binlog-file mysql-bin.000124 --start-time "2023-07-06 10:00:00" --end-time "2023-07-06 22:00:00" 
</code></pre><div>&nbsp;</div></div><p><a href="https://github.com/hcymysql/reverse_sql#%E5%BD%93%E5%87%BA%E7%8E%B0%E8%AF%AF%E6%93%8D%E4%BD%9C%E6%97%B6%E5%8F%AA%E9%9C%80%E6%8C%87%E5%AE%9A%E8%AF%AF%E6%93%8D%E4%BD%9C%E7%9A%84%E6%97%B6%E9%97%B4%E6%AE%B5%E5%85%B6%E5%AF%B9%E5%BA%94%E7%9A%84binlog%E6%96%87%E4%BB%B6%E9%80%9A%E5%B8%B8%E4%BD%A0%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87show-master-status%E5%BE%97%E5%88%B0%E5%BD%93%E5%89%8D%E7%9A%84binlog%E6%96%87%E4%BB%B6%E5%90%8D%E4%BB%A5%E5%8F%8A%E5%88%9A%E6%89%8D%E8%AF%AF%E6%93%8D%E4%BD%9C%E7%9A%84%E8%A1%A8%E5%92%8C%E5%85%B7%E4%BD%93%E7%9A%84dml%E5%91%BD%E4%BB%A4%E6%AF%94%E5%A6%82update%E6%88%96%E8%80%85delete">当出现误操作时，只需指定误操作的时间段，其对应的 binlog 文件（通常你可以通过 show master status 得到当前的 binlog 文件名）以及刚才误操作的表，和具体的 DML 命令，比如 update 或者 delete。</a></p><p style="color:#1f2328; text-align:start">工具运行时，首先会进行 MySQL 的环境检测（if binlog_format != 'ROW' and binlog_row_image != 'FULL'），如果不同时满足这两个条件，程序直接退出。</p><p style="color:#1f2328; text-align:start">工具运行后，会在当前目录下生成一个{db}_{table}_recover.sql 文件，保存着原生 SQL（原生 SQL 会加注释） 和，反向 SQL，如果想将结果输出到前台终端，可以指定--print 选项。</p><p style="color:#1f2328; text-align:start">如果你想把 update 操作转换为 replace，指定--replace 选项即可，同时会在当前目录下生成一个{db}_{table}_recover_replace.sql 文件。</p><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/251670057-b06528a6-fbff-4e00-8adf-0cba19737d66.png" target="_blank"><img alt="图片" src="https://static.oschina.net/uploads/img/202311/08114920_eBdc.png" referrerpolicy="no-referrer"></a></p><p style="color:#1f2328; text-align:start">MySQL 最小化用户权限：</p><div style="text-align:start"><pre><code>&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO `yourname`@`%`;

&gt; GRANT SELECT ON `test`.* TO `yourname`@`%`;
</code></pre></div><h3 style="text-align:start"><br><a href="https://github.com/hcymysql/reverse_sql#%E6%81%A2%E5%A4%8D">恢复</a></h3><p style="color:#1f2328; text-align:start">在{db}_{table}_recover.sql 文件中找到你刚才误操作的 DML 语句，然后在 MySQL 数据库中执行逆向工程后的 SQL 以恢复数据。</p><p style="color:#1f2328; text-align:start">如果{db}_{table}_recover.sql 文件的内容过多，也可以通过 awk 命令进行分割，以便更容易进行排查。</p><div style="text-align:start"><pre><code>shell&gt; awk '/^-- SQL 执行时间/{filename = "output" ++count ".sql"; print &gt; filename; next} {print &gt; filename}' test_t1_recover.sql
</code></pre><div>&nbsp;</div></div><p style="color:#1f2328; text-align:start">不支持 drop 和 truncate 操作，因为这两个操作属于物理性删除，需要通过历史备份进行恢复。</p><h4 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#%E6%B3%A8reverse_sql-%E6%94%AF%E6%8C%81mysql-5780-%E5%92%8C-mariadb%E9%80%82%E7%94%A8%E4%BA%8Ecentos-7%E7%B3%BB%E7%BB%9F">注：reverse_sql 支持 MySQL 5.7/8.0 和 MariaDB，适用于 CentOS 7 系统。</a></h4><hr><h3 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#docker%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8">Docker 部署使用</a></h3><p style="color:#1f2328; text-align:start">shell&gt; wget<span>&nbsp;</span><a href="https://github.com/hcymysql/reverse_sql/archive/refs/heads/reverse_sql_progress.zip">https://github.com/hcymysql/reverse_sql/archive/refs/heads/reverse_sql_progress.zip</a></p><p style="color:#1f2328; text-align:start">shell&gt; unzip reverse_sql_progress.zip</p><p style="color:#1f2328; text-align:start">shell&gt; cd reverse_sql_progress</p><p style="color:#1f2328; text-align:start">shell&gt; vim Dockerfile</p><div style="text-align:start"><pre><code>FROM centos:7

COPY reverse_sql /root/
RUN chmod 755 /root/reverse_sql
</code></pre></div><p style="color:#1f2328; text-align:start">shell&gt; docker build -t reverse_sql .</p><p style="color:#1f2328; text-align:start">shell&gt; docker run -itd --name reverse_sql reverse_sql /bin/bash</p><p style="color:#1f2328; text-align:start">shell&gt; docker exec -it reverse_sql /root/reverse_sql --help</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/reverse-sql</guid>
            <link>https://www.oschina.net/p/reverse-sql</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | Android 发热监控实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一、背景</h1><p>相信移动端高度普及的现在，大家或多或少都会存在电量焦虑，拥有过手机发热发烫的糟糕体验。而发热问题是一个长时间、多场景的指标存在，且涉及到端侧应用层、手机 ROM 厂商系统、外界环境等多方面的影响。如何有效衡量发热场景、定位发热现场、以及归因发热问题成为了端侧应用层发热监控的面前的三座大山。本文通过得物 Android 端侧现有的一些监控实践，不深入功耗计算场景无法自拔，优先聚焦于发热场景本身，希望能给大家一些参考。</p><h1>二、发热定义</h1><p>温度是最直观能反映发热问题的指标，当前 Android 侧，我们以体感温度 37° 以上作为分界线，向上每 3° 作为一个发热温度区间，区间细分上限温度 49° ，即划分出 37-40，40-43，43-46，46-49，49+ 五个等级。</p><p>以手机温度、CPU 使用率作为第一、第二要素来判断用户是否发热的同时，获取其他参数来支撑发热现场情况。</p><p><strong>具体指标如下:</strong></p><p>手机温度 CPU 使用率、GPU 使用率；</p><p>线程堆栈；</p><p>系统服务使用频次；</p><p>设备前后台、亮灭屏时长；</p><p>电量、充电情况；</p><p>热缓解发热等级；</p><p>系统机型、版本；</p><p>....</p><h1>三、指标获取</h1><h2>温度</h2><ul><li><strong>电池温度</strong></li></ul><p>系统 BatteryManger 已经提供了一系列自带的接口和粘性广播获取电池信息。</p><p>BatteryManager.EXTRA_TEMPERATURE 广播，获取的温度值是摄氏度为单位的 10 倍数值。</p><pre><code>//获取电池温度 BatteryManager.EXTRA_TEMPERATURE，华氏温度需要除以 10
fun getBatteryTempImmediately(context: Context): Float {
    return try {
        val batIntent = getBatteryStickyIntent(context) ?: return 0f
        batIntent.getIntExtra(BatteryManager.EXTRA_TEMPERATURE, 0) / 10F
    } catch (e: Exception) {
        0f
    }
}

private fun getBatteryStickyIntent(context: Context): Intent? {
    return try {
        context.registerReceiver(null, IntentFilter(Intent.ACTION_BATTERY_CHANGED))
    } catch (e: Exception) {
        null
    }
}
</code></pre><p>BatteryManager 除支持电池温度的系统广播外，也包含电量、充电状态等额外信息的读取，均定义在其源码中。</p><pre><code>以下罗列几个值得关注的:
//BATTERY_PROPERTY_CHARGE_COUNTER 剩余电池容量，单位为微安时
//BATTERY_PROPERTY_CURRENT_NOW 瞬时电池电流，单位为微安
//BATTERY_PROPERTY_CURRENT_AVERAGE 平均电池电流，单位为微安
//BATTERY_PROPERTY_CAPACITY 剩余电池容量，显示为整数百分比
//BATTERY_PROPERTY_ENERGY_COUNTER 剩余能量，单位为纳瓦时
// EXTRA_BATTERY_LOW  是否认为电量低
// EXTRA_HEALTH  电量健康常量的常数
// EXTRA_LEVEL  电量值
// EXTRA_VOLTAGE 电压
// ACTION_CHARGING   进入充电状态
// ACTION_DISCHARGING  进入放电状态
</code></pre><ul><li><strong>传感器温度</strong></li></ul><p>Android 是基于 Linux 基础上修改的开源操作系统，同样的在手机系统 sys/class/thermal/ 目录下存在以 thermal_zoneX 为代表各传感器的温度分区，以及 cooling_deviceX 为代表风扇或散热器等冷却设备。</p><p>以一加 9 为例，共存在 105 个温度传感器 or 温度分区，以及 48 个冷却设备。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b5cf3938151953ff43b21f0a681ce4c9b65.jpg" alt="" referrerpolicy="no-referrer"></p><p>每个温度分区下记录下具体的参数类型，我们重点关注的是 type 文件和&nbsp;temp 文件，分别记录了该传感器设备的名称，以及当前的传感器温度。以 thermal_zone29 为例，代表了 CPU 第一核心的，第五处理单元的温度值为 33.2 摄氏度。而对单一设备来说分区对应的名称是固定的，从而我们可以通过读取 thermal_zone 文件的方式来记录当前第一个 type 文件名称包含&nbsp;CPU&nbsp;的传感器作为&nbsp;CPU&nbsp;温度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f2279774ca9ce74031e6897a9db4a7ea9dc.jpg" alt="" referrerpolicy="no-referrer"></p><ul><li><strong>壳温</strong></li></ul><p>Android 10 Google 官方推出了热缓解框架，通过 HAL2.0 框架监听底层硬件传感器（主要为 USB 传感器、Skin 传感器）提供 USB、壳温的热信号等级变更监听， 系统 PowerManager 源码提供了对应发热等级变更的回调和发热等级的获取，共 7 个等级，提供给开发者主动或被动获取。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1110179d6d33bc1f87ed57c99e6797dc931.jpg" alt="" referrerpolicy="no-referrer"></p><pre><code>final PowerManager powerManager = (PowerManager) mContext.getSystemService(Context.POWER_SERVICE);
powerManager.addThermalStatusListener(new PowerManager.OnThermalStatusChangedListener() {
    @Override
    public void onThermalStatusChanged(int status) {
       //返回对应的热状态
    }
});
</code></pre><p>但对于发热等级来说，壳温无疑是最为能够反应手机的发热情况的。可以看到 Android 系统的 API 实际上是提供了 AIDL 接口，可以直接注册 Thermal 变更事件的监听，获取到 Temperature 对象。但由于标识了 Hide API 。常规应用层是无法获取到的，在考虑好 Android 版本兼容性前提下，通过反射代理 ThermalManagerService 方式进行读取。</p><p><img src="https://oscimg.oschina.net/oscnet/up-50f7b8b0252859eb185129ba23e59b367cb.jpg" alt="" referrerpolicy="no-referrer"></p><p>但事与愿违，国内厂商并没有完全适配官方热缓解框架，热状态回调时常不够准确，而是需要单独接入每个厂商的热缓解 SDK 去直接获取到壳温，具体 API 则以各应用厂商的内部接入文档为准。</p><h2>CPU 使用率</h2><p>CPU 使用率的采集通过读取解析 Proc stat 文件的方式进行计算。</p><p>在系统 proc/[pid]/stat&nbsp; 和&nbsp; /proc/[pid]/task/[tid]/stat &nbsp;分别记录了对应进程 ID、进程 ID 下的线程 ID 的 CPU 信息。具体的字段描述在此不进行赘述，详见：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fman7.org%2Flinux%2Fman-pages%2Fman5%2Fprocfs.5.html" target="_blank">https://man7.org/linux/man-pages/man5/procfs.5.html</a> 。</p><p><img src="https://oscimg.oschina.net/oscnet/up-49d2512961ec5d6361ee15326af3c2c5885.jpg" alt="" referrerpolicy="no-referrer"></p><p>我们重点关注 14.15 位的信息，分别代表进程/线程的用户态运行的时间和内核态运行的时间。 <img src="https://oscimg.oschina.net/oscnet/up-30cbd118f0cbd9df3ddf67043cc22b050ea.jpg" alt="" referrerpolicy="no-referrer"></p><p>通过解析当前进程的 Stat 文件，以及 Task 目录下所有线程的 Stat 文件，在两次采样周期内 (当前设置为 1s) 的 utime+stime 之和的差值/采样间隔，即可认为是进线程的 CPU 的使用率。即，进线程 CPU 使用率 = ((utime+stime)-(lastutime+laststime)) / period</p><h2>GPU 使用率</h2><p>高通芯片的设备，我们可以参考&nbsp;/sys/class/kgsl/kgsl-3d0/gpubusy&nbsp;下文件内容，参考高通官网的说明。</p><p>GPU 的使用率 = (下图) 数值 1 / 数值 2 * 100，经过验证与 SnapDragonProfiler 信息采集获取的数值基本一致。 <img src="https://oscimg.oschina.net/oscnet/up-0be7cfc4a8df3b97c0a5600c5512c4e415e.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-9496bbec4a96755eb7d59997c3ac6fd12bc.jpg" alt="" referrerpolicy="no-referrer"></p><p>联发科芯片的设备，我们可以直接通过读取&nbsp;<strong>/d/ged/hal/gpu_utilization</strong> 下的使用率数值。</p><p>同样的通过指定周期 (每秒 1 次) 的采样间隔，即可获取到每秒的当前 GPU 使用率。</p><h2>系统服务使用</h2><p>Android 系统服务包括 Warelock、Alarm、Sensor、Wifi、Net、Location、Bluetooth、Camera 等。</p><p>与市面上常规的监控手段差异不大，都是通过系统 Hook ServiceManager 的方式，监听系统服务的 Binder 通信，匹配对应的调用方法名，做对应中间层监控的回调记录处理。</p><p>熟悉 Android 开发的同学知道 Android 的 Zygote 进程是 Android 系统启动时的第一个进程。在 Zygote Fork 进程中会孵化出系统服务相关的进程 SystemServer，在其核心的 RUN 方法中，会注册启动大量的系统服务，并通过 ServiceManager 进行管理。 <img src="https://oscimg.oschina.net/oscnet/up-f43504f6a7801c8edffd8a299338158a10c.jpg" alt="" referrerpolicy="no-referrer"></p><p>故我们可以通过反射代理 ServiceManager 的方式，以 LocationManager 为例进行监听，拦截对应 LocationManager 内对应的方法，记录我们期望获取的数据。</p><pre><code>// 获取 ServiceManager 的 Class 对象
Class&lt;?&gt; serviceManagerClass = Class.forName("android.os.ServiceManager");
// 获取 getService 方法
Method getServiceMethod = serviceManagerClass.getDeclaredMethod("getService", String.class);
// 通过反射调用 getService 方法获取原始的 IBinder 对象
IBinder originalBinder = (IBinder) getServiceMethod.invoke(null, "location");
// 创建一个代理对象 Proxy
Class&lt;?&gt; iLocationManagerStubClass = Class.forName("android.location.ILocationManager$Stub");
Method asInterfaceMethod = iLocationManagerStubClass.getDeclaredMethod("asInterface", IBinder.class);
final Object originalLocationManager = asInterfaceMethod.invoke(null, originalBinder);
Object proxyLocationManager = Proxy.newProxyInstance(context.getClassLoader(),
        new Class[]{Class.forName("android.location.ILocationManager")},
        new InvocationHandler() {
            @Override
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                // 在这里进行方法的拦截和处理
                Log.d("LocationManagerProxy", "Intercepted method: " + method.getName());
                // 执行原始的方法
                return method.invoke(originalLocationManager, args);
            }
        });
// 替换原始的 IBinder 对象
getServiceMethod.invoke(null, "location", proxyLocationManager);
</code></pre><p>同理，我们获取在固定采样周期内，各系统服务对应，申请次数、计算间隔时长等进行记录。</p><p>源码&nbsp;Power_profile&nbsp;文件中定义了每个系统服务状态下的电流量定义。</p><p>我们在需要记录每个元器件在不同状态的工作时间之后，通过以下计算方式，可以得出元器件的发热贡献排行，即：</p><p>元器件，电量消耗（发热贡献） &nbsp;~~ &nbsp;电流量 * 运行时长 * 电压（一般为固定值，可忽略）</p><p><img src="https://oscimg.oschina.net/oscnet/up-95b4814576aef6a67210588b65b259c9abf.jpg" alt="" referrerpolicy="no-referrer"></p><h2>线程堆栈</h2><p>由于发热问题是一个综合性的问题，并不像 Crash 问题一样，在发生现场我们就可以知道是哪个线程触发的。如果将所有线程的堆栈都进行 Dump 记录的话，得物当前运行时的子线程数量在 200+，全部进行存储的话无疑是不合理的。问题就转变为，如何较为准确的找到发热代码的线程堆栈？</p><p>上文说到，在计算 CPU 使用率的时读取进程下所有线程的 Stat 文件，我们可以获取到子线程的 CPU 使用率，对其使用率进行倒排，筛选超过阈值（当前定义 50% ) 或，占用 Top N 的线程进行存储。由于堆栈频繁采集时机上是有性能折损的，故牺牲了部分的堆栈采样精度和准确性，在温度、CPU 使用率等指标超过阈值定义后，才开始采集，指定下发时间的堆栈信息。</p><p>我们还要明确一个概念，线程 Stat 文件的文件名即为线程标识名，Thread.id 是指线程 ID。</p><p>其两者并不等价，但 Native 方法中给我们提供了对应的方式去建立两者的映射关系。</p><p>在 Art &nbsp;Thread.cc 方法中，将 Java 中的 Thread 对象转换成 C++ 中的 Thread 对象，调用 ShortDump 打印线程的相关信息，我们通过字符串匹配到核心的 Tid= 的信息，即可获取到线程的 Tid。 <img src="https://oscimg.oschina.net/oscnet/up-6e69839410035c1793072333c26c962790c.jpg" alt="" referrerpolicy="no-referrer"></p><p>核心代码逻辑如下:</p><pre><code>//获取队列中最近一次 cpu 采样的数据
 val threadCpuUsageData = cpuProfileStoreQueue.last().threadUsageDataList
       val hotStacks = mutableListOf&lt;HotStack&gt;()
        if (threadCpuUsageData != null) {
            val dataCount = if (threadCpuUsageData.size &lt;= TOP_THREAD_COUNT) {
                threadCpuUsageData.size
            } else {
                TOP_THREAD_COUNT
            }
            val traces: MutableMap&lt;Thread, Array&lt;StackTraceElement&gt;&gt; = Thread.getAllStackTraces()
            //定义 tid 和 thread 的映射关系 map
            val tidMap: MutableMap&lt;String, Thread&gt; = mutableMapOf()
            traces.keys.forEach { thread -&gt;
                //调用 native 方法获取到 tid 信息
                val tidInfo = hotMonitorListener?.findTidInfoByThread(thread)
                tidInfo?.let {
                    findTidByTidInfo(tidInfo).let { tid -&gt;
                        if (tid.isNotEmpty()) {
                            tidMap[tid] = thread
                        }
                    }
                }
            }
            //采集 topN 的发热堆栈
            for (index in 1..dataCount) {
                val singleThreadData = threadCpuUsageData[index - 1]
                val isMainThread = singleThreadData.pid == singleThreadData.tid
                val thread = tidMap[singleThreadData.tid.toString()]
                thread?.let { findThread -&gt;
                    traces[findThread]?.let { findStackTrace -&gt;
                        //获取当前的线程堆栈
                        val sb = StringBuilder()
                        for (element in findStackTrace) {
                            sb.append(element.toString()).append("\n")
                        }
                        sb.append("\n")
                        if (findStackTrace.isNotEmpty()) {
                            //是否为主线程
                            //组装 hotStack
                            val hotStack = HotStack(
                                //进程 id
                                singleThreadData.pid,
                                singleThreadData.tid,
                                singleThreadData.name,
                                singleThreadData.cpuUseRate,
                                sb.toString(),
                                thread.state
                                isMainThread
                            )
//                        Log.d("HotMonitor", sb.toString())
                            hotStacks.add(hotStack)
                        }
                    }
                }

            }
        }
</code></pre><h1>四、监控方案</h1><p>了解核心指标数据是如何获取的前提下，其实监控方案的核心思路无非就是通过远端 APM 配置中心下发的采样阈值、采样周期、各模块数据开关等限定采样配置，子线程 Handler 定时发消息，采集各个模块的数据进行组装，在合适的时机进行数据上报即可，具体的数据拆解、分析工作则由发热平台进一步处理。</p><p><strong>模块整体架构</strong><img src="https://oscimg.oschina.net/oscnet/up-b5030680856c30aab1b0a1b2d301fbbeea8.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>上报时机</strong><img src="https://oscimg.oschina.net/oscnet/up-0cbaca499275d7a3292d7a5990c26ced860.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>核心采集流程</strong><img src="https://oscimg.oschina.net/oscnet/up-81a16007734e761fbece449580c494a4ccb.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>线上线下区分</strong></p><p>由于所有子线程的 CPU 采集、堆栈采集实际上是会对性能有折损的，200+ 的线程的读取耗时整体在 200ms 左右，采样子线程的 CPU 使用率在 10%，考虑到线上用户体验问题，并不能全量开启高频率采样。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b83fd9a6c760d788fb151f04d854e8c40eb.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-2e9a9a66b142535b29d5dc9793467e73fdf.jpg" alt="" referrerpolicy="no-referrer"></p><p>故整体方案来说: 线下场景以重点侧重发现、排查、治理全量问题，上报全量日志，以 CPU、GPU 使用率为第一衡量指标；</p><p>线上场景以重点侧重观察整体发热大盘趋势、分析潜在问题场景，上报核心日志，以电池温度为第一衡量指标。</p><p><strong>发热平台</strong></p><p>在平台侧同学的支持下，发热现场数据经过平台侧进行消费，将核心的发热堆栈经过 Android 堆栈反混淆服务进行聚合，补齐充电状态、主线程 CPU 使用率、问题类型、电池温度等基础字段，平台侧就具备发现、分析、解决的流程化监控推进的能力。</p><p>具体的堆栈信息 &amp; 发热信息平台展示如下:</p><p><img src="https://oscimg.oschina.net/oscnet/up-3251d963a881ef9e7f09fcc6d73d9b2925d.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-04b122e8d11a65f06b2ed4f71062b718945.jpg" alt="" referrerpolicy="no-referrer"></p><p>由于电池温度、CPU 使用率是针对运行时发热场景最直观的指标，且我们一期重点关注发热场景的治理，不针对元器件 Hook 等耗电场景进行持续深入分析，故当前得物侧是以电池温度、CPU 使用率为第一第二指标 &nbsp;建立核心的发热问题四象限，优先关注高温、高 CPU 的问题场景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5a65d936a2e2676307b5562a55eb4fca2e7.jpg" alt="" referrerpolicy="no-referrer"></p><p>在数据分析过程中，我们遇到了数据上的效率排查效率不够高、问题精度不够准的情况。</p><ul><li>如何定位是高温场景是发生在 App 内部，且在使用过程中明显上升的？ 通过过滤从启动开始即高温、后台切换回来即高温的场景，重点关注在 App 内部温度上升的场景。</li><li>线上的采样后仍旧单日有 6w+ 数据的上报，我们如何筛选出更为核心的数据？当前的做法是定义了温度跨度的概念，优先看在 App 内部温度跨度较大的 Case。</li><li>线程存在调用 Wait 等方法阻塞的堆栈，消耗内核态的时间分配，但实际不消耗整体 CPU 的误报数据。 补充了线程的运行状态和 Proc 文件中记录的 State，方便优先处理 RUNNABLE 线程的 CPU 高温高占用问题。</li><li>手机温度上升作为渐进式的场景，如何实现温度上升场景下的页面精确归因？增加温度采样频率的同时，汇总 CPU 使用率和实时堆栈等瞬时数据作为数据支撑，但考虑到数据体量的情况，数据上报聚合裁剪方式仍在逐步探索更为合理的方式，力求在两者之间找到一个平衡点。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-838ac3d056faa216013c5cf2b87b08cbf57.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-abcc4634539696d10682e28632c278d9415.jpg" alt="" referrerpolicy="no-referrer"></p><h1>五、收益</h1><p>Android 端侧发热监控自上线以来，背靠平台侧的支撑，陆续发现了一些问题并联合开发同学做了对应场景的治理优化工作，如：</p><p>耗时独立线程任务，接入统一线程池调度管理；</p><p>动画执行死循环监测修复；</p><p>高 IO 场景的文件读写策略优化；</p><p>高并发任务锁粒度优化；</p><p>日志库等 Json 解析频繁场景，采用效率更高的序列化方；</p><p>系统相机等系统功率过高的采集参数设备分级尝试；</p><p>基于 Webgl 的游戏场景，帧率降低和资源及时回收优化运行时内存；</p><p>....</p><p>这无疑给未来体验工作的场景技术选型、技术实现沉淀了一些有价值的经验，符合对 App 体验追求极致的高标准、高要求。</p><h1>六、未来展望</h1><p>手机发热作为渐进式的体验场景，涉及手机硬件、系统服务、软件使用、外界环境多方位因素。对于端侧的排查上来说，当前优先级聚焦于应用层的不合理使用上，对于排查工具链路增强、问题业务归因、低电量、低功耗模式下的动态策略降低、自动化诊断报告等环节仍旧有很多值得深入挖掘的点，例如：</p><p><strong>监控/工具增强</strong></p><ul><li>App 浮层分析工具 (CPU\GPU/频率/温度/功耗等信息)</li><li>借鉴 BatteryHistorian、SnapdragonProfiler、Systrace 等工具，实现自研 TeslaLab 能力增强。</li></ul><p><strong>业务归因</strong></p><ul><li>发热堆栈自动分配</li><li>调用溯源归因精细化</li></ul><p><strong>场景策略、降级</strong></p><ul><li>CPU 调频、动态帧率、分辨率降级</li><li>端内低功耗模式探索</li></ul><p><strong>自动化诊断报告</strong></p><ul><li>单用户定向自动化分析输出诊断报告</li></ul><p>‍</p><h1>七、总结</h1><p>在此也只是粗略介绍当前已经做的针对发热治理的一些初步工作，以及对未来发热功耗相关开展的思路，希望能让 App 带来更好的体验，给用户带来更对美好事物的向往的感受。</p><p>*文 / GavinX</p><p>本文属得物技术原创，更多精彩文章请看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2F" target="_blank">得物技术官网</a></p><p>未经得物技术许可严禁转载，否则依法追究法律责任！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10141675</guid>
            <link>https://my.oschina.net/u/5783135/blog/10141675</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英伟达或将推出针对中国区的最新改良版 AI 芯片]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chinastarmarket.cn%2Fdetail%2F1512299" target="_blank">据<span style="background-color:#ffffff">《科创板日报》</span>报道</a></u>，产业链人士称英伟达现已开发出针对中国区的最新改良版 AI 芯片：HGX H20、L20 PCle 和 L2 PCle。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-edecf0f4b0f979b064fa454bfd31a0ec4e3.png" referrerpolicy="no-referrer"></p><p>知情人士称，最新三款芯片是由 H100 改良而来，英伟达最快或将于本月 16 号之后公布，国内厂商最快将在这几天拿到产品。</p><p>NVIDIA H100 Tensor Core GPU&nbsp;采用全新 Hopper 架构，基于台积电 N4 工艺，集成了 800 亿个晶体管。与上一代产品相比，可为多专家 (MoE) 模型提供高 9 倍的训练速度。</p><p>它配备第四代 Tensor Core 和 Transformer 引擎（FP8 精度），还具有高度可扩展的 NVLink 互连技术（最多可连接达 256 个 H100 GPU，相较于上一代采用 HDR&nbsp;Quantum&nbsp;InfiniBand 网络，带宽高出 9 倍，带宽速度为 900GB/s）等功能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-acc6975ca53f0be377caf78b3f05ea055f8.png" referrerpolicy="no-referrer"></p><p>记者向英伟达求证该消息的真实性，但截至发稿，英伟达方面暂无回应。</p><hr><p>2023 年 10 月 17 日，CNBC 报道称，美国商务部计划在未来几周内限制向中国出售更先进的人工智能芯片。高级政府官员表示，<strong>新政策将限制 NVIDIA A800 和 H800 芯片的出口</strong>。详情：<em><u><a href="https://www.oschina.net/news/262251/us-bans-export-of-more-ai-chips-including-nvidia-h800-to-china">美国政府限制向中国出口 NVIDIA H800 GPU</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 07:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265728</guid>
            <link>https://www.oschina.net/news/265728</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美团招兵买马，拟开发鸿蒙系统 App]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美团招聘官网近日更新了多个鸿蒙相关的社招开发岗位，为鸿蒙原生应用开发招兵买马。主要开发美团鸿蒙 App、大众点评鸿蒙 App。</span></p><p><span style="color:#000000">其中的一个「鸿蒙高级工程师（C++）」职位就是面向美团鸿蒙 App 研发团队。根据介绍，具体的岗位职责为：</span></p><ol><li><span style="color:#000000">参与鸿蒙端动态化容器的架构设计，确保项目研发质量和代码的可维护性；</span></li><li><span style="color:#000000">负责鸿蒙端动态化容器的模块设计与实现，实现高性能、高质量的容器模块；</span></li><li><span style="color:#000000">对项目中的技术难点和重点进行深入研究和总结，积累可复用的经验。</span></li><li><span style="color:#000000">能够主动解决和推动项目前鸿蒙端动态化容器技术领域的阻塞点和难点；</span></li><li><span style="color:#000000">结合美团的业务需求，探索行业前沿技术，规划容器技术路线。</span></li></ol><p><span style="color:#000000">且满足「熟悉 ArkTS 和鸿蒙上的主流开发框架（例如 ArkUI）；作为主要贡献者参与过有影响力的开源产品的开发；了解 Web 开发，熟悉浏览器内核的运行机制；了解动态化容器原理，熟悉 Hybrid、React Native、Flutter 等前沿技术之一；乐于分享和沟通，活跃于 GitHub 和各大技术社区，或有自己的高质量原创博客」等条件的将优先考虑。</span></p><p><span style="color:#000000"><img alt="" height="267" src="https://oscimg.oschina.net/oscnet/up-ae63f8c42eec2e0095d1026cb5f531df31b.png" width="500" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 07:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265725</guid>
            <link>https://www.oschina.net/news/265725</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[vivo 公布蓝心大模型 BlueLM-7B 开源地址]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>vivo 已在&nbsp;Hugging Face 上正式开源蓝心大模型 BlueLM-7B。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7b7b72160940bf13dc85103adc480ff135f.png" referrerpolicy="no-referrer"></p><p>地址：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fvivo-ai" target="_blank">https://huggingface.co/vivo-ai</a></u></p><p>BlueLM-7B 开源大模型包括&nbsp;<strong>7B 基础模型和 7B 对话模型</strong>，vivo 还开源了支持&nbsp;32K&nbsp;的长文本基础模型和对话模型。</p><p>据介绍，BlueLM 采用高质量语料库进行训练，<strong>规模达到了&nbsp;2.6 万亿&nbsp;的 token 数，该语料库包含中文、英文以及少量日韩数据</strong>。其中 BlueLM-7B-Chat 在&nbsp;C-Eval&nbsp;和&nbsp;CMMLU&nbsp;上均取得领先结果。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-032d6f2119d13af32e2019c475fa5b87681.png" referrerpolicy="no-referrer"></p><p>BlueLM-7B-Base-32K 和 BlueLM-7B-Chat-32K 均支持&nbsp;32K&nbsp;长文本，在保持基础能力相当情况下，能够支持更长上下文理解。</p><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/264455" target="_blank">vivo 开源蓝心大模型-7B：70 亿参数、适合中国开发者</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 06:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265715</guid>
            <link>https://www.oschina.net/news/265715</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 服务中断近 2 小时，CEO 奥特曼道歉：流量远超预期]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京时间 11 月 8 日晚 22 点左右，OpenAI 旗下 ChatGPT 以及相关 API 出现中断故障，导致面向用户和开发者的服务近 2 小时无法正常使用。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/114753_pknp_2720166.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstatus.openai.com%2F" target="_blank">随后 OpenAl 更新事故报告称</a></u>，已确定了一个导致 API 和 ChatGPT 错误率高的问题，正在努力修复。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/114923_hRcd_2720166.png" referrerpolicy="no-referrer"></p><p>与此同时，OpenAI CEO 山姆・奥特曼<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1722315204242149788">公开致歉称</a></u>，本周发布的新功能遇到远超预期的使用量。公司原计划在周一为所有订阅者启用 GPTs 服务，但目前还无法实现。由于负载的原因，短期内可能会出现服务不稳定的情况，对此情况向用户道歉。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/1109/113902_kyvS_2720166.png" referrerpolicy="no-referrer"></p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/265330">OpenAI 开发者大会：GPT-4 Turbo、GPTs 商店、128k 上下文窗口、大降价</a></li><li><a href="https://www.oschina.net/news/265331/openai-custom-versions-chatgpt">OpenAI 推出用户自定义版 ChatGPT</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265693</guid>
            <link>https://www.oschina.net/news/265693</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果正在利用 LLM 彻底改造 Siri，将成为杀手级 AI 应用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>爆料者 Tech_Reve 发表推文<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTech_Reve%2Fstatus%2F1722418466647625999" target="_blank">表示</a></u>，苹果公司正在使用大语言模型 (LLM) 将 Siri 彻底改造成「终极虚拟助理」，并准备将其开发为「最强大的杀手级 AI 应用」。</p><p>目前苹果正在积极推进这项开发工作，首款产品预计将在 WWDC 2024 上亮相。改进后的 Siri 将成为 iPhone 16 及后续机型的标配功能。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/111614_rFyz_2720166.png" referrerpolicy="no-referrer"></p><p>Tech_Reve 还说道，苹果和三星一样<strong>，整体思路都是专注于在设备侧运行，同时配合云端实现相关 AI 服务</strong>，这是因为 AI 在本地运行响应时间更快、不需要网络连接，且更具隐私性。</p><p>上个月<u><a href="https://www.oschina.net/news/263067">彭博社的报道</a></u>也提到了苹果公司内部对如何部署生成式 AI 的争论：<strong>完全在设备上运行、基于云运行或介于两者之间</strong>。</p><p><span style="background-color:#ffffff; color:#333333">部署在设备上会运行得更快，并有助于保护隐私，但通过云部署大模型将允许更高级的操作。部署在设备端的策略也会让苹果更难更新其技术并适应快速变化的行业。考虑到这一点，该公司很可能采用组合方法：<strong>使用设备上的部署处理某些功能，使用云来处理更高级的任务</strong>。</span></p><p>彭博社还提到，今年 7 月，苹果公司构建了自己的大型语言模型，<a href="https://www.oschina.net/news/250184/apple-gpt"><strong>称为 Ajax</strong></a>，并推出了一个名为 「Apple GPT」 的内部聊天机器人来测试其功能。下一步的关键是确定该技术是否能够应对竞争对手，以及苹果如何将其实际应用到产品中。</p><p>分别负责人工智能和软件工程的高级副总裁 John Giannandrea 以及 Craig Federighi 正在带头开展这项工作，服务主管 Eddy Cue 也参与其中。目前，3 人计划每年在该项目上花费约 10 亿美元。</p><p>据介绍，John Giannandrea 主要负责全新 AI 系统的底层技术，他的团队目前正在改进 Siri，这个更智能的 Siri 最早可能会在明年准备就绪。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265689</guid>
            <link>https://www.oschina.net/news/265689</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 工程师年薪中位数高达 92.5 万美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">来自美国薪资跟踪网站 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.levels.fyi%2Fcompanies%2Fopenai%2Fsalaries%2Fsoftware-engineer" target="_blank">Levels.fyi</a> 的数据显示，OpenAI 软件工程师的年薪中位数高达 92.5 万美元，其中包括基本工资以及潜在的股票报酬和奖金。</span></p><p><span style="color:#000000">目前 OpenAI 薪酬最低的工程师底薪为 21 万美元，拥有约 2 至 4 年的行业从业经验。L5 软件工程师（拥有 10 年以上工作经验的软件工程师）的底薪为 30 万美元，另外还可以获得 62.5 万美元的股票薪酬。此外，该公司的一些高级软件工程师的薪酬甚至更高，年薪最高达到 140 万美元。</span></p><p><img height="139" src="https://oscimg.oschina.net/oscnet/up-540ee3f9087289680579b5a9f2e340b6bf7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenAI 提供的高薪不仅对公司本身，而且对整个行业都具有深远影响。根据 Levels.fyi 的数据，以科技中心和人才库著称的旧金山，为 AI 软件开发人员提供的薪酬中位数一般约为 30 万美元。「通过提供近三倍的薪酬，OpenAI 为该地区的薪酬设定了新的基准，并表明其致力于吸引和留住顶尖 AI 人才的承诺。」</span></p><p><span style="color:#000000">OpenAI 的员工薪资由「基本工资」和「Profit Participation Units(PPU)」两个部分组成。PPU 是 OpenAI 独创的分润机制，该公司以 PPU 的形式提供股票薪酬，让员工分享公司的利润。</span></p><p><img height="291" src="https://oscimg.oschina.net/oscnet/up-9f5f514ce43285fd98946d201453956b368.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">而 PPU 的价值取决于公司未来的表现或被收购时的估值。9 月份有消息称，<span style="background-color:#ffffff">OpenAI&nbsp;</span><span style="background-color:#ffffff">正在与投资者讨论股票出售事宜</span><span style="background-color:#ffffff">，其</span><span style="background-color:#ffffff">估值大概在 800 亿至 900 亿美元之间，约是今年早些时候水平的三倍。今年 4 月，OpenAI 曾从红杉资本、Andreessen Horowitz、Thrive 和 K2 Global 等支持者那里获得了略高于 3 亿美元的融资，估值为 290 亿美元。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265688/openai-software-engineer-pay</guid>
            <link>https://www.oschina.net/news/265688/openai-software-engineer-pay</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[魅族为 Flyme 征集中文名，入选者将获赠「华小魅」手机组合包]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>魅族科技今日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2683843043%2FNrJHikCZG%3Fpagetype%3Dprofilefeed" target="_blank">发布公告称</a></u>，集魅友力量，<strong>为 Flyme 征集中文 OS 名称</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-75abc601083ca8c26ecda32cafc7d8aac84.png" referrerpolicy="no-referrer"></p><p>魅族在公告写道：「再一次，华为、小米、魅族奔跑在了同一条道路上，一条由中国企业定义、引领的手机、汽车、AR 等多终端全场景生态融合发展的道路。」</p><p>在这样一个奔涌的时代，<strong>Flyme 也需要拥有像鸿蒙、澎湃一样响亮的中文名</strong>。和用户共创是魅族的传统，魅族科技将 Flyme 的中文 OS 命名权交给魅友。</p><p>该公司将选取三个意向名称，创作者可获赠「华小魅」手机组合一份（<strong>包含华为 Mate 60 Pro、小米 14 Pro、魅族 20 PRO 各一部</strong>）。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 02:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265679</guid>
            <link>https://www.oschina.net/news/265679</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[NetBSD 10.0 发布首个 RC，类 UNIX 操作系统]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>自去年发布 NetBSD 10.0 Beta 以来，已过去接近一年，现在终于进入了 RC 阶段。开发团队称将在未来几个月内发布正式版。</p><p>NetBSD 10 的开发工作于 2019 年底启动，这将是重大版本更新。<u><a href="https://www.oschina.net/news/222371/netbsd-10-0-beta">根据之前的报道</a></u>，新版本在性能提升方面将会是一个重要里程碑，尤其是 NetBSD 10 的多核操作系统性能比以前的版本要快许多。</p><p><strong>其他重要变化</strong></p><ul><li>支持 WireGuard</li><li>支持自动为 SWAP 分区进行加密</li><li>引入新的磁盘加密方法</li><li>在内核实现 CPU 加速</li><li>支持更多采用 Arm 架构的硬件，包括 Rockchip RK356X, NXP <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fi.MX" target="_blank">i.MX</a> 8M, Amlogic G12, Apple M1 和 Raspberry Pi 4</li><li>支持最新 ARM CPU 中的新安全功能</li><li>支持新的网络适配器，包括 Realtek 2.5 千兆以太网和新的 Intel 10/25/40 千兆以太网适配器</li><li>将 compat_linux 移植到 AArch64 架构</li><li>将 DTrace 移植到 MIPS</li><li>改进对多处理器的支持，提供更多的 iMac G5 支持</li><li>对 Xen 虚拟机管理程序支持进行重大修改</li><li>为用户空间引入新的程序，包括用于手动修剪磁盘空间的 blkdiscard (8)、用于控制音频音量的 aiomixer (1)、realpath (1) 和 fsck_udf (8)……</li><li>针对多核系统显著提升性能</li><li>用于启用更新组件的无数其他硬件驱动程序改进</li></ul><p>下载地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnycdn.netbsd.org%2Fpub%2FNetBSD-daily%2Fnetbsd-10%2F202311070920Z%2Fimages%2F" target="_blank">https://nycdn.netbsd.org/pub/NetBSD-daily/netbsd-10/202311070920Z/images/</a></p><p>NetBSD 是一个免费的、安全的及高度可移植的类 UNIX 操作系统，它适合于很多种平台，从 64 位的 AlphaServers 及桌面系统到手持及嵌入式系统。它在设计上非常整洁，并拥有先进的特性，这使得它在业界和学术界都有口皆碑。用户可通过完整的源代码来获得支持。很多应用程序都可容易地从 NetBSD Packages Collection 获得。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9ddeb287fa441bf078d01f543c60856a06d.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cb37485c28b1322211fac5a6819cf507b8b.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 02:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265677/netbsd-10-0-rc</guid>
            <link>https://www.oschina.net/news/265677/netbsd-10-0-rc</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 11 原生支持 7z 和 .tar 压缩文件格式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>推特用户 @PhantomOfEarth <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FPhantomOfEarth%2Fstatus%2F1722334216199766161" target="_blank">发现</a></u>，最新的 Windows 11 Canary 版本支持将文件压缩为另外两种存档格式：.<strong>7z 和 .tar</strong>。虽然 RAR 格式仍然缺失，但至少不再局限于 zip。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bac57f48d11859af0d2e31f42856329e753.png" referrerpolicy="no-referrer"></p><p>微软没有在第 25992 版的发布说明中提及这一变更。此外，它已在默认情况下启用，因此无需执行特殊命令即可让 Windows 11 将文件打包为 7z 和 TAR 格式。将系统更新至版本 25992 后，选择要存档的文件，然后从右键菜单中选择"压缩至"即可实现。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/101016_c73D_2720166.png" referrerpolicy="no-referrer"></p><p>除了可以处理更多的归档类型，Windows 11 版本 25992 还提高了处理大型 ZIP 文件时的性能。发布说明中提到了这一点：</p><blockquote><p>做了一些工作，应有助于明显改善在文件资源管理器中打开大型 .zip 文件的性能。</p></blockquote><p>Windows 11 build 25992 中的其他更改包括 SMB 升级、已知问题修复和剪切工具中的 HDR 支持改进。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265668</guid>
            <link>https://www.oschina.net/news/265668</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
