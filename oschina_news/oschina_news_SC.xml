<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 31 Oct 2023 07:52:05 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[通义千问 APP 上线，通义千问 720 亿参数模型下月开源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">在 10 月 31 日 2023 云栖大会现场，作为通义大模型基础模型的<strong>通义千问 2.0 千亿参数模型</strong>正式发布。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-605363e0734cb16cbc76823df487f560abb.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#222222">据介绍，通义千问 2.0 模型参数达到千亿级别，不管是在阅读理解还是逻辑思维、数据等方面，都有大幅度提升，能够全面达到国际先进水平。</span></p><p><span style="background-color:#ffffff; color:#222222">与此同时，通义千问 App（仅 Android 版本）也随之发布，用户开始可以下载相关 APP 进行体验。</span></p><p><img src="https://static.oschina.net/uploads/space/2023/1031/154720_kKia_2720166.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#222222">阿里云 CTO 周靖人宣布，<strong>将在 11 月开源通义千问 720 亿参数模型</strong>，继续支持全球开发者开展模型和应用创新。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-959b92e9bef8a1dd269d943b3c6d2a9171f.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#222222">阿里云是国内最早开源自研大模型的头部科技企业，已先后开源通义千问 70 亿参数模型 Qwen7B 和 140 亿参数模型 Qwen14B，模型累计下载量超过 100 万。</span></p><p>&nbsp;</p><ul><li><a href="https://www.oschina.net/news/259447" target="_blank">阿里云开源通义千问 14B 大模型</a></li><li><a href="https://www.oschina.net/news/252324" target="_blank">阿里云开源通义千问 7B 大模型：免费、可商用</a></li></ul><p><span style="background-color:#ffffff; color:#222222">据称通义千问 72B 将成为参数规模最大的中国开源大模型。目前国内外开源社区已经产生 50 多款基于通义千问开源模型训练的新模型和新应用，涵盖医疗、法律、机器人等众多领域。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 07:39:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264277</guid>
            <link>https://www.oschina.net/news/264277</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里旗下平台「夸克」被罚 50 万]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><u><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.cac.gov.cn%2F2023-10%2F30%2Fc_1700323940777319.htm" target="_blank">据中国网信网消息</a></u>，近日，针对「夸克」平台和「网易 CC」直播平台破坏网络生态问题，国家网信办指导广东省网信办依法约谈相关平台负责人，对「夸克」平台实施 50 万元罚款处罚，责令「网易 CC」暂停「舞蹈」版块信息更新 7 日，同时责令 2 家平台立即全面深入整改，严肃处理相关责任人。</p><p><img height="1606" src="https://static.oschina.net/uploads/space/2023/1031/152055_3Pp5_2720166.png" width="2450" referrerpolicy="no-referrer"></p><p>经查，「夸克」平台未遵守相关管理要求，搜索结果呈现大量淫秽色情信息，并向用户推荐色情低俗关键词，违反《网络安全法》《网络信息内容生态治理规定》《互联网信息搜索服务管理规定》等有关规定，在平台信息内容安全审核管理方面存在严重漏洞，破坏网络生态，情节特别严重。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-da0eb9315b86d1c0f8e3e8f3bb08dbcc71e.png" referrerpolicy="no-referrer"></p><p><span style="color:#000000">夸克搜索<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.com.cn%2Ftech%2F2023-10-30%2Fdoc-imzswzyh8439300.shtml" target="_blank">回应新浪科技表示</a></u>：</span></p><blockquote><p>「对此，我们高度重视、诚恳接受、坚决执行，目前已经严格按照要求全面落实整改，封禁相关违规内容。为了进一步加强合规体系建设，我们成立了专项工作小组，升级针对不良信息的识别能力和处理速度，积极开展专项整治行动，通过人工和技术的双重巡查模式，对有害信息进行严厉打击，绝不姑息。」</p></blockquote><ul><li><em>相关阅读：<a href="https://www.oschina.net/news/258071">被罚 100 万，腾讯 QQ 回应</a></em></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 07:25:26 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264273</guid>
            <link>https://www.oschina.net/news/264273</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「IDE 启动画面是如何诞生的？」 | JetBrains AI 图形发展史]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="font-size: 15px;color: rgb(33, 33, 33);line-height: 1.6;letter-spacing: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;" data-mpa-powered-by="yiban.io"><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.1836734693877551" src="https://oscimg.oschina.net/oscnet/5b3e75ef-637e-4138-802f-b70a25faddbf.gif" data-type="gif" data-w="637" style="height: auto !important;" referrerpolicy="no-referrer"></p><section style="font-size: 15px;"><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="padding-left: 1em;padding-right: 1em;display: inline-block;text-align: center;"><span style="display: inline-block;padding: 0.3em 0.5em;border-radius: 0.5em;text-shadow: rgb(204, 204, 204) 4px 3px;color: rgb(115, 119, 173);" title="" opera-tn-ra-cell="_$.pages:0.layers:0.comps:0.title1"><p><strong>引入</strong></p></span></section><section style="border-width: 1px;border-style: solid;border-color: rgb(228, 228, 228);margin-top: -1em;padding: 20px 10px 10px;background-color: rgb(255, 255, 255);text-align: center;"><section style="" powered-by="xiumi.us"><section style="text-align: justify;"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffeatures%2Fcodespaces" target="_blank" data-linktype="2"></a><span style="font-size: 14px;">上周的<a localeditorid="c26mgf2mlo83sjrzls" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247504179%26idx%3D1%26sn%3Df1a1d015021163bf11ff593327aa7801%26scene%3D21%23wechat_redirect" textvalue="「1024 特别企划」" target="_blank" data-linktype="2"><strong>「1024 特别企划」</strong></a>推送中，我们分享了一套由 JetBrains 使用 AI 生成式技术创作的壁纸屏保。其实，JetBrains 在 AI 艺术方面的探索已经持续多年。大家熟悉的 IDE 启动画面正是这部分工作的结晶。今天的文章，我们就从技术层面揭示 JetBrains 团队是如何使用 AI 技术创造出 IDE 的启动画面和其衍生桌面艺术的。</span></p><p><span style="font-size: 14px;"><br></span></p><p><span style="font-size: 14px;">如果你还想探索和下载更多设计作品，不妨去看看我们的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode2art.jetbrains.com%2F" target="_blank" data-linktype="2"><strong>Code2Art</strong></a>&nbsp;主题页面！</span></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><br></p><section style="font-size: 15px;"><section style="margin-right: 0%;margin-left: 0%;text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;padding-right: 10px;padding-left: 10px;background-color: rgb(88, 88, 88);"><section style="display: inline-block;vertical-align: middle;"><section style="display: inline-block;vertical-align: middle;color: rgb(255, 255, 255);padding-right: 2px;font-size: 18px;"><p><strong>在 JetBrains 生成图稿</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="display: inline-block;vertical-align: middle;width: 0.8em;height: 0.8em;border-top: 0.2em solid rgb(255, 255, 255);border-right: 0.2em solid rgb(255, 255, 255);transform: rotate(45deg);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">JetBrains 不断完善用作网站元素和发布图形的图稿的创建方式。我们的使命是将平面设计师从日常任务中解放出来，让他们能够专注于自己的核心能力 – <strong>创造力</strong>。JetBrains 用于生成图稿的内部工具的历史大约开始于十年前。起初，我们主要使用基于 WebGL 的工具，这些工具可以在浏览器中实时随机生成所有内容（<strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcai.jetbrains.com%2F" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">此处</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">提供了交互式归档）。下面的图像就是用这种方式创建的。<br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/9abf4da9-b96d-4b1d-8cca-d2b2fe7b5200.png" data-type="png" data-w="960" style="height: auto !important;" referrerpolicy="no-referrer"></p><br><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.625" src="https://oscimg.oschina.net/oscnet/15dcfa47-4f1e-4950-8520-099eaf167d2c.png" data-type="png" data-w="1000" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="PyCharm Professional 2019.3 splash screen" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     使用 WebGL 创建的启动画面 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">2020 年，我们发布了第一款<strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fblog%2F2020%2F09%2F29%2Fintelligent-code-art%2F" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">基于深度神经网络的工具</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">。自那时起，所有内容都在 K8s GPU 集群中使用适用于本地和远程开发的 PyCharm 和 Datalore 生成。浏览器仅用于输入输出。通过这种基于神经网络的方式，我们实现了更高程度的个性化，这让我们能够迎合设计师的需求，并且我们一直在努力改进。</span></p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: inherit;color: inherit;line-height: inherit;">以下图片使用组合模式生成网络（CPPN，上图）和 Stable Diffusion（SD，下图）制作而成。<strong>本文将介绍这两种方式的技术细节，以及我们如何结合这两种方式来创造更精彩的设计。</strong><br></span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.562962962962963" src="https://oscimg.oschina.net/oscnet/92e23890-fbdd-4e0f-aa8c-6dd34aaf01f6.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="PyCharm desktop art" referrerpolicy="no-referrer"></figure><br><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.562962962962963" src="https://oscimg.oschina.net/oscnet/2be787a6-91d8-47c7-9c9f-f7fdbfe18af3.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="RubyMine desktop art" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     使用神经网络生成的启动画面 
   </figcaption></figure><figure style="font-size: inherit;color: inherit;line-height: inherit;"><br></figure><figure style="font-size: inherit;color: inherit;line-height: inherit;"><br></figure><section style="font-size: 15px;"><section style="margin-right: 0%;margin-left: 0%;text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;padding-right: 10px;padding-left: 10px;background-color: rgb(88, 88, 88);"><section style="display: inline-block;vertical-align: middle;"><section style="display: inline-block;vertical-align: middle;color: rgb(255, 255, 255);padding-right: 2px;font-size: 18px;"><p><strong>CPPN：概述</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="display: inline-block;vertical-align: middle;width: 0.8em;height: 0.8em;border-top: 0.2em solid rgb(255, 255, 255);border-right: 0.2em solid rgb(255, 255, 255);transform: rotate(45deg);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">CPPN（Compositional pattern-producing network 的缩写）&nbsp;是最简单的生成网络之一。它们只是简单地将像素座标 (x, y) 映射到图像颜色 (r, g, b)。CPPN 通常使用特定的图像或图像集进行训练。不过，我们发现，当初始化正确执行时，随机初始化的 CPPN 会生成漂亮的抽象图案。<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.20092592592592592" src="https://oscimg.oschina.net/oscnet/669d4106-85b9-43ea-b092-9ee4701beaf9.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="CPPN 架构" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     CPPN 架构：像素座标为输入，RGB 值为输出。 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">利用早期内部版本生成器的使用数据，我们改进了算法以提高视觉质量。除此之外，我们还通过引入多个虚拟参数略微扩展了 CPPN 的经典架构。因此，现在我们的 CPPN 会将 (x, y, a, b, c, f) 映射到 (r, g, b)。这个简单的更改允许我们引入一种易于使用（但有些不可预测）的方法来更改图像，如下所示。<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.8740740740740741" src="https://oscimg.oschina.net/oscnet/ccb31379-5cbe-42a5-913c-6d1445aa4388.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="CPPN 的虚拟参数" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     通过更新虚拟参数 (a)，我们对图片进行了略微更改。 
   </figcaption></figure><p style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-family: sans-serif;font-size: 14px;"><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">这些虚拟参数不一定是常量。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">例如，我们可以将每个像素的虚拟参数 f 的值映射到此像素到图像</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">中心的距离。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">这一技巧使我们能够确保图像呈现圆形。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">或者我们可以将 f 映射到像素座标的绝对值之和，这将产生菱形图案。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">这就是数学与艺术的真正结合！</span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.8194444444444444" src="https://oscimg.oschina.net/oscnet/5b0d9403-e33c-4907-a069-119b14edd26a.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="CPPN 的虚拟参数，第二个示例" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     不同的函数 f(x,y) 会产生不同的图像图案 
   </figcaption></figure><p style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-family: sans-serif;font-size: 14px;"><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">为了确保我们随机初始化的 CPPN 始终产生漂亮的设计，我们训练了一个推荐系统来预测给定的参数集是否会生成具有一定美感的图像。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">我们根据内部测试期间收到的用户反馈来训练我们的算法。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">下图显示了随机初始化的 CPPN 创建的两个图像示例以及它们对应的「美感」分数。</span></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.825" data-s="300,640" src="https://oscimg.oschina.net/oscnet/75019655-6d4c-4c32-90aa-22bf15b1f01d.png" data-type="png" data-w="1080" style="height: auto !important;" referrerpolicy="no-referrer"></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     预测 CPPN 图像的「美感」分数 
   </figcaption><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br></figcaption><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br></figcaption></figure><section style="font-size: 15px;"><section style="margin-right: 0%;margin-left: 0%;text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;padding-right: 10px;padding-left: 10px;background-color: rgb(88, 88, 88);"><section style="display: inline-block;vertical-align: middle;"><section style="display: inline-block;vertical-align: middle;color: rgb(255, 255, 255);padding-right: 2px;font-size: 18px;"><p><strong>CPPN：动画</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="display: inline-block;vertical-align: middle;width: 0.8em;height: 0.8em;border-top: 0.2em solid rgb(255, 255, 255);border-right: 0.2em solid rgb(255, 255, 255);transform: rotate(45deg);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">当我们的 CPPN 生成的图稿被转换成视频图形时，它们真正变得栩栩如生。通过将虚拟参数 (a, b, c) 映射到任何闭合的参数曲线（在同一点开始和结束的曲线），我们可以创建任何所需长度的无缝循环动画！<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.5731481481481482" src="https://oscimg.oschina.net/oscnet/a692b7b7-aac4-4471-a169-e1dad58339f9.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="CPPN 动画视频的示例帧" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     CPPN 动画视频的示例帧 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">曲线函数的选择至关重要。在平面圆上对虚拟参数添加动画是最简单的方式。不过，它有一个缺点：当参数的符号发生变化（例如，从 0.01 变成 -0.01），而它具有较低的一阶导数值（在圆形轨迹的情况下为零）时，生成的动画通常会抖动。为了解决这个问题，我们使用<strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FLemniscate_of_Bernoulli" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">伯努利双纽线</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">来确保虚拟参数的符号永远不会改变（见下图）。这解决了动画抖动的问题，但也带来了一个新问题。对于大多数动画帧，其中一个参数仅以增量方式更新，这使动画看起来过于简单。我们通过切换到随机样条函数解决了这个问题。我们使用的轨迹越复杂，动画看起来就越丰富！<br></span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.6675925925925926" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="Examples of CPPN curve functions" src="https://oscimg.oschina.net/oscnet/a939b9c2-0634-4135-85fd-eac8b32ff401.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     CPPN 曲线函数示例 
   </figcaption><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br></figcaption><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br></figcaption></figure><section style="font-size: 15px;"><section style="margin-right: 0%;margin-left: 0%;text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;padding-right: 10px;padding-left: 10px;background-color: rgb(88, 88, 88);"><section style="display: inline-block;vertical-align: middle;"><section style="display: inline-block;vertical-align: middle;color: rgb(255, 255, 255);padding-right: 2px;font-size: 18px;"><p><strong>CPPN：色彩校正</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="display: inline-block;vertical-align: middle;width: 0.8em;height: 0.8em;border-top: 0.2em solid rgb(255, 255, 255);border-right: 0.2em solid rgb(255, 255, 255);transform: rotate(45deg);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">还有一个更重要的细节：色彩校正。我们的 CPPN（以及由此产生的图像）是随机生成的，但我们需要确保每个图像都使用我们的品牌颜色。我们尝试了几种不同的方式来实现这一目标。第一次迭代（<strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fblog%2F2020%2F09%2F29%2Fintelligent-code-art%2F" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">在 2020 版本中使用</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">）依赖于浏览器中的 SVG 重新着色（使用 feColorMatrix 和 feComponentTransfer）。这种方式速度很快，因为重新着色在浏览器中进行，我们可以更新调色板，而无需在服务器端重新呈现图像。不过，实现起来却很棘手，因为有些调色板对于 feColorMatrix 和 feComponentTransfer 来说太过复杂，而且通常不可靠。经过大量实验后，我们发现最终的颜色会因浏览器和操作系统而异。以下是我们在 2020 年初进行的实验的一个示例。左边是在 macOS 上通过使用 Safari 的设置由早期版本生成器生成的背景的屏幕截图，右边是在 Ubuntu Linux 上通过使用 Google Chrome 的设置由生成器生成的相同背景的屏幕截图。请注意细微的亮度差异。我们应用的后期处理效果越多，亮度差异就越明显。<br></span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.5165289256198347" data-type="png" data-w="726" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="An example of brightness discrepancies" src="https://oscimg.oschina.net/oscnet/edbab4b1-2a6d-4f69-b8ec-6bd40136ae39.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     亮度差异示例 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">另一个示例是 <strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FSVG%2FElement%2FfeComponentTransfer" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">MDN 的 feComponentTransfer 示例</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">。这一次，两个图像都在同一台机器上使用 Ubuntu Linux 和 Google Chrome 制作，但在左侧的屏幕截图中，硬件加速被禁用。存在明显的色彩差异，尤其是在表查找示例之间。因此，尽管速度非常快，但这种色彩校正的方式非常不一致。<br></span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.8" data-type="png" data-w="750" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="An example of color discrepancies" src="https://oscimg.oschina.net/oscnet/e696d864-b3ed-4d90-811c-009334f2319a.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     色彩差异的示例 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">我们目前的方式（从 2021 年开始使用）更直接。我们以 32 位灰度来呈现源图像，这意味着我们的 CPPN 只返回单个明亮度值，而不是 RGB。然后，我们将每个像素映射到具有预计算理想 RGB 值的查找表。这种方式速度较慢，但会产生像素级精确的结果。<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="1.1944444444444444" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="使用灰度图像进行色彩校正的示例" src="https://oscimg.oschina.net/oscnet/40ec3320-9630-4424-b88c-dbc273b14278.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     使用灰度图像进行色彩校正的示例 
   </figcaption><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br></figcaption></figure><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.8398148148148148" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="2020.1 启动画面" src="https://oscimg.oschina.net/oscnet/2c768d79-1c08-4f58-bbfb-f5448e74a775.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     使用 SVG 重新着色的 2020.1 启动画面 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">将我们目前的色彩校正方式与带有虚拟参数和样条动画的 CPPN 一起使用时，就会得到类似下面的视频！</p><section><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3172052699912110088" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_jpg%2FsGKiaGPagC784HZUFFJWbriaCHrYrLWicAC99RzLeibzv3BaO2udebTZI1n2nxRibB4BkUxmSsMd8cSbWd6WsicpV3Fw%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1920" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3172052699912110088" referrerpolicy="no-referrer"></iframe></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">CPPN 的另一个显著特性是，得益于其简单的架构，可以轻松地将其计算图转换为 GLSL 代码。在动画视频就绪之后，我们可以将其导出为 WebGL 片段着色器，然后直接在浏览器中运行。这种方式的结果的一个示例是 <strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com.cn%2Fqodana%2F" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">Qodana 的着陆页</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">。</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">点击<strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgradient-public.labs.jb.gg%2F" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">此处</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">查看我们基于 CPPN 的生成器。</span></p></li><li><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: inherit;color: inherit;line-height: inherit;">要深入了解 CPPN，请查看我们包含代码示例的<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatalore.jetbrains.com%2Freport%2Fstatic%2F2jrFAfMBVhUsYW8njXgysC%2F9OuleGiEVhxqGen1GS9cjN" textvalue="公共 Datalore Notebook" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>公共 Datalore Notebook</strong></a>。</span></p></li></ul><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><br></p><section style="font-size: 15px;"><section style="margin-right: 0%;margin-left: 0%;text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;padding-right: 10px;padding-left: 10px;background-color: rgb(88, 88, 88);"><section style="display: inline-block;vertical-align: middle;"><section style="display: inline-block;vertical-align: middle;color: rgb(255, 255, 255);padding-right: 2px;font-size: 18px;"><p><strong>驾驭 Stable Diffusion</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="display: inline-block;vertical-align: middle;width: 0.8em;height: 0.8em;border-top: 0.2em solid rgb(255, 255, 255);border-right: 0.2em solid rgb(255, 255, 255);transform: rotate(45deg);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">Stable Diffusion 提供了高水平的广泛应用和视觉保真度，这使其成为我们图稿生成器的完美支柱。为了使 Stable Diffusion 适合用作发布图形源，我们必须遵守以下标准：</p><ul style="font-size: inherit;color: inherit;line-height: inherit;padding-left: 32px;" class="list-paddingleft-1"><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">图像应遵循品牌调色板。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">不允许出现伪影或瑕疵（如坏像素）。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">应该易于使用某种特定风格（抽象平滑线条）。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">应该需要很少或不需要提示，这意味着它应该提供易于访问且直观的控制。</span></p></li></ul><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">虽然始终存在改进的空间，但我们已经满足了所有上述要求。最新的图像已<strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode2art.jetbrains.com%2F" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">公开</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">，所有技术细节如下。<br></span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.9824074074074074" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="2023.1 splash screens" src="https://oscimg.oschina.net/oscnet/852190b3-f71c-466b-8bec-07665f2b6a37.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     使用 Stable Diffusion 创建的 2023.1 启动画面 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">为了产生始终符合我们所有标准的结果，我们使用设计师提供的各种参考资料对 Stable Diffusion 进行了微调。下面是一些根据不同风格生成的图像示例。<br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.46944444444444444" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/b744869f-22b3-4f5e-9f06-1e4850cdc202.png" referrerpolicy="no-referrer"></p><br><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.4638888888888889" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="通过微调 Stable Diffusion 获得的实验风格" src="https://oscimg.oschina.net/oscnet/5cdb078f-6c1d-4c8f-86d1-129e40d6a820.png" referrerpolicy="no-referrer"></figure><br><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.3509259259259259" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="通过微调 Stable Diffusion 获得的实验风格" src="https://oscimg.oschina.net/oscnet/035c9f63-9df7-4751-8e0d-15963ef8614e.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     通过微调 Stable Diffusion 获得的实验风格 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">在深入研究微调过程的技术细节之前，我们先来看看 Stable Diffusion 的内部原理。它在本质上由三部分组成：CLIP 文本编码器（用于将文本编码成多模态嵌入向量空间的微型 Transformer 模型），将图像压缩到隐空间以及从隐空间解压缩的变分自动编码器，以及降噪 UNet。<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.6397748592870544" data-type="png" data-w="1066" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="Stable Diffusion 的架构" src="https://oscimg.oschina.net/oscnet/dfaa53b8-d074-4766-9a9d-3c7f30d75e3a.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     Stable Diffusion 的架构（图像来源： 
    <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.philschmid.de%2Fstable-diffusion-inference-endpoints" textvalue="‍philschmid.de/stable-diffusion-inference-endpoints" linktype="text" imgurl="" tab="outerlink" data-linktype="2">philschmid.de/stable-diffusion-inference-endpoints</a>） 
   </figcaption></figure><p style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-family: sans-serif;font-size: 14px;"><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">生成过程大致如下：</span><br></p><ol style="font-size: inherit;color: inherit;line-height: inherit;padding-left: 32px;" class="list-paddingleft-1"><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">我们将提示文本编码成一个嵌入向量，即一个 77×768 浮点数组。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">我们随机生成图像的隐式表示，它可以是纯高斯噪声或初始图像的带噪表示。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">我们以给定的步数，将编码的隐图像和编码的文本反复传递给降噪 UNet。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">在对隐图像降噪后，我们将其传递给解码器，从而将其解压缩为标准的 RGB 图像。</span></p></li></ol><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.5231481481481481" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="降噪过程" src="https://oscimg.oschina.net/oscnet/01beaca1-6d92-4f4d-95d0-7d44d4c42451.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     降噪过程（图像来源： 
    <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-stable-diffusion%2F" textvalue="jalammar.github.io/illustrated-stable-diffusion/" linktype="text" imgurl="" tab="outerlink" data-linktype="2">jalammar.github.io/illustrated-stable-diffusion/</a>） 
   </figcaption></figure><p style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-family: sans-serif;font-size: 14px;"><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">对我们来说至关重要的是，Stable Diffusion 的好处在于，可以用很少的数据对其进行微调，并获得很好的结果！</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">作为「副作用」，数据高效的微调方法在计算上也是高效的，这使它变得更好。</span></p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">最直接的微调方式是文本反转 (p-tuning)。我们会冻结所有权重，例如 UNet、VAE 和文本编码器（这意味着我们不会在训练期间更新它们），并且只为文本编码器的每个嵌入向量训练一个新词。因为我们每个嵌入向量只训练一个新词，只有 768 个可训练参数！<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.5638888888888889" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="文本嵌入和反转过程概述" src="https://oscimg.oschina.net/oscnet/7251b2c3-39c3-4bde-8ba9-f8f7852433b2.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     文本嵌入和反转过程概述（&nbsp;图像来源： 
    <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftextual-inversion.github.io%2F" textvalue="textual-inversion.github.io/" linktype="text" imgurl="" tab="outerlink" data-linktype="2">textual-inversion.github.io/</a>） 
   </figcaption></figure><p style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-family: sans-serif;font-size: 14px;"><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">这些自定义嵌入向量是可组合的，这意味着我们最多可以在单个提示中使用 77 个嵌入向量。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">最重要的是，它们很容易训练，在单张 RTX 4090 上需要大约 2 个小时。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">以下是训练过程的示例。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">用于生成以下两个图像的提示均为「digital art in the style of 」，其中「」是我们正在训练的新词嵌入向量。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">随着执行的训练步骤的增多，图像会发生演变，新的视觉风格会变得越来越明显。</span></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="1" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/2c191bf3-e18e-4db0-bd26-e4082f6c6ba3.png" referrerpolicy="no-referrer"></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     使用文本反转经过 500 和 3000 个训练步骤后生成的图像 
   </figcaption></figure><p style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-family: sans-serif;font-size: 14px;"><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">另一种热门且高效的微调方法是低秩自适应（Low-Rank Adaptation，简称 LoRA）。LoRA 的关键思想类似于文本反转，只是这次除了冻结权重之外，我们还通过在 UNet 内的注意力层中添加小的适配器层来引入新权重。</span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.7553606237816765" data-type="png" data-w="1026" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="一个 Transformer 层内的 LoRA 方法示意图" src="https://oscimg.oschina.net/oscnet/bcb475a0-a79b-4448-9d7a-13b165607f8b.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     一个 Transformer 层内的 LoRA 方法示意图（图像来源： 
    <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fadapterhub.ml%2Fblog%2F2022%2F09%2Fupdates-in-adapter-transformers-v3-1%2F" textvalue="adapterhub.ml/blog/2022/09/updates-in-adapter-transformers-v3-1/" linktype="text" imgurl="" tab="outerlink" data-linktype="2">adapterhub.ml/blog/2022/09/updates-in-adapter-transformers-v3-1/</a>） 
   </figcaption></figure><p style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-family: sans-serif;font-size: 14px;"><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">与文本反转相比，这种方式可以从微调数据中捕获更复杂的图案（例如，「AI 肖像」应用会使用用户的面孔训练适配器层），但它使用的资</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">源略多，最重要的是，多个 LoRA 无法组合。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">在我们的具体用例中，我们发现 LoRA 在使用 Stable Diffusion XL 时最有效。</span><span style="color: inherit;font-size: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0px;">相比之下，在早期版本的 Stable Diffusion（1.4、1.5 或 2.1）中，文本反转可以实现更广泛的应用。</span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="1.4083333333333334" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="使用 LoRA 经过 200 和 1000 个训练步骤后生成的图像" src="https://oscimg.oschina.net/oscnet/da82c791-8e96-45e2-ae64-ab8b4fbc1bfe.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     使用 LoRA 经过 200 和 1000 个训练步骤后生成的图像 
   </figcaption><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><span style="font-size: 18px;"></span><br></figcaption><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br></figcaption></figure><section style="font-size: 15px;"><section style="margin-right: 0%;margin-left: 0%;text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;padding-right: 10px;padding-left: 10px;background-color: rgb(88, 88, 88);"><section style="display: inline-block;vertical-align: middle;"><section style="display: inline-block;vertical-align: middle;color: rgb(255, 255, 255);padding-right: 2px;font-size: 18px;"><p><strong>结合 Stable Diffusion&nbsp;</strong></p><p><strong>和 CPPN 的优点</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="display: inline-block;vertical-align: middle;width: 0.8em;height: 0.8em;border-top: 0.2em solid rgb(255, 255, 255);border-right: 0.2em solid rgb(255, 255, 255);transform: rotate(45deg);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">我们使用 Stable Diffusion 的标准之一是需要确保生成的图像遵循某个特定品牌的调色板，这正是 CPPN 的用武之地！在使用 Stable Diffusion 生成图像之前，我们使用自己的梯度生成器（如上所述）利用 CPPN 生成图像，以像素级精度应用所需的颜色，然后使用 VAE 对其进行编码并使用高斯噪声进行混合。UNet 使用生成的隐图像作为其起点，从而保留原始色彩和构图。<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.4787037037037037" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="CPPN → Stable Diffusion 流水线" src="https://oscimg.oschina.net/oscnet/2d5e74a9-8daf-431f-864a-4a63891961b6.png" referrerpolicy="no-referrer"></figure><br><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.4703703703703704" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="CPPN → Stable Diffusion 流水线" src="https://oscimg.oschina.net/oscnet/93e7736b-b1bb-4784-b5d4-6d1036613054.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     CPPN → Stable Diffusion 流水线 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">在 CPPN 图像就绪后，我们也可以直接在浏览器中对其进行编辑，以实现我们所能想象的任何形状和设计！<br></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.26851851851851855" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;height: auto !important;" title="具有手动编辑 CPPN 图像的 CPPN → Stable Diffusion 流水线" src="https://oscimg.oschina.net/oscnet/3e03e2c5-1894-41c9-b628-feffef64bd97.png" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;">
     具有手动编辑 CPPN 图像的 CPPN → Stable Diffusion 流水线 
   </figcaption></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">最后，使用我们的「CPPN → Stable Diffusion」流水线生成多个图像后，我们就可以用这些图像来训练另一个 CPPN，并将它们转换为动画，如上面的 <em style="font-size: inherit;color: inherit;line-height: inherit;">CPPN：动画</em>部分所述！这里有一些示例 <strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.shadertoy.com%2Fview%2FDsBSW3" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">GLSL 代码</a>。</strong><span style="font-size: inherit;color: inherit;line-height: inherit;"></span></p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">JetBrains 对 AI 赋能图形的探索和实现是一次冒险。多年来，我们的工具不断发展和成熟，从最初使用基于 WebGL 的随机生成方式，到目前使用 CPPN 和 Stable Diffusion 生成时尚且个性化的设计。展望未来，我们期待更高水平的自定义和广泛应用，我们对这些技术将在图形生成领域释放的潜力感到兴奋。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">我们希望这篇关于我们的 AI 图稿发展历程的深入介绍对您有所启发！我们诚邀您探索我们提供的示例（包括我们的<strong style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcai.jetbrains.com%2F" target="_blank" rel="noopener" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" data-linktype="2">交互式归档</a></strong><span style="font-size: inherit;color: inherit;line-height: inherit;">）并在文章留言区或发送电子邮件至 <a href="https://www.oschina.net/action/GoToLink?url=mailto%3Acai%40jetbrains.com" style="font-size: inherit;line-height: inherit;color: rgb(30, 107, 184);" target="_blank">cai@jetbrains.com</a> 来分享您的反馈。请告诉我们您未来希望从计算艺术团队看到什么样的主题！</span></p></section><section style="font-size: 16px;"><section style="transform: perspective(0px);transform-style: flat;" powered-by="xiumi.us"><section style="margin-top: 10px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;transform: rotateY(180deg);"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding-left: 8px;align-self: flex-start;flex: 0 0 auto;"><section style="transform: perspective(0px);transform-style: flat;" powered-by="xiumi.us"><section style="transform: rotateY(180deg);"><section style="color: rgb(125, 125, 125);font-size: 13px;text-align: right;"><p>本博文英文原作者：</p><p>Vladimir Sotnikov, Olga Andreevskikh</p></section><grazie-editor-wrapper></grazie-editor-wrapper></section></section></section></section></section><section style="" powered-by="xiumi.us"><p><br></p><p><br></p><section style="font-size: 15px;"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section style="justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section style="display: flex;flex-flow: row;text-align: center;justify-content: center;margin-right: 0%;margin-left: 0%;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 43%;flex: 0 0 auto;align-self: center;height: auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="background-color: rgb(0, 0, 0);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: middle;width: 14.0003%;flex: 0 0 auto;height: auto;line-height: 0;align-self: center;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;box-shadow: rgba(255, 255, 255, 0.1) 0px 0px 5px;"><img class="rich_pages wxw-img" data-ratio="1" data-s="300,640" data-type="png" data-w="420" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/f8105502-1c42-4b88-83a3-ddc47473d4fa.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: 43%;flex: 0 0 auto;align-self: center;height: auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="background-color: rgb(0, 0, 0);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section style="justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section style="margin-top: 10px;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;padding-right: 15px;padding-left: 15px;align-self: flex-start;flex: 0 0 auto;background-color: rgb(88, 88, 88);"><section style="justify-content: flex-start;margin-top: 10px;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;min-width: 10%;flex: 0 0 auto;height: auto;align-self: flex-start;"><section style="margin-top: 3px;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: bottom;width: 33.33%;align-self: flex-end;flex: 0 0 auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 6px 0px 6px 10px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(255, 255, 255);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: bottom;width: 33.33%;align-self: flex-end;flex: 0 0 auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 6px 0px 6px 10px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(255, 255, 255);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: bottom;width: 33.33%;margin-top: 3px;align-self: flex-end;flex: 0 0 auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 6px 0px 6px 10px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(255, 255, 255);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;min-width: 10%;flex: 0 0 auto;height: auto;margin-left: 10px;align-self: flex-start;"><section style="" powered-by="xiumi.us"><section style="color: rgb(255, 255, 255);text-align: justify;"><p><strong>更多阅读推荐</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section></section></section></section></section><section style="margin-bottom: 10px;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-style: solid;border-width: 1px;border-color: rgb(88, 88, 88);align-self: flex-start;flex: 0 0 auto;padding: 27px 7px;"><section style="" powered-by="xiumi.us"><section style="text-align: center;color: rgb(0, 0, 0);"><p><strong>新发布</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section style="text-align: center;font-size: 12px;color: rgb(0, 0, 0);"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247502861%26idx%3D1%26sn%3D62792d48fecdd57819d1237e73dff1b3%26chksm%3Dc08ba153f7fc28458201afc3ced4c0f11045f731ec8fee1e94961a3708a20e50690942745bb6%26token%3D1396192698%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">JetBrains 全系列 IDE 2023.2 更新概览</a><br></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247503998%26idx%3D1%26sn%3Dc80abda34362d92eb4077c7176fbf9c7%26chksm%3Dc08bbd20f7fc34367671f223323fdcad7d4a69e299793bab51144717a9a3902159a5a51a4227%26token%3D1790117445%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">RustRover: JetBrains 出品的独立 Rust IDE</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247492468%26idx%3D1%26sn%3D872a6fc5a40d41828299c69e20f57a56%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">JetBrains Aqua: 测试自动化 IDE</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247489349%26idx%3D1%26sn%3D1dcec5e6b810512a8c23fa52db285c06%26chksm%3Dc0887a1bf7fff30d8221cd92764618ec5262ac9a549c7173340bc754f1abecc83a0dc51e2ec8%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">JetBrains Qodana:&nbsp;代码质量平台</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247491483%26idx%3D1%26sn%3D7ef92a11da98c89c18feb4d97185a872%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">Fleet 公共预览版</a></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section style="text-align: justify;"><p><br></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section style="color: rgb(0, 0, 0);text-align: center;"><p><strong>调研报告</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section style="text-align: center;font-size: 12px;"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247494786%26idx%3D2%26sn%3Ddb281bdfcbcac3be0c040f978f8da428%26chksm%3Dc08b81dcf7fc08cadd185937e84851eb06fefeb712c3fc3d0545623eba2b061fc878f9ea7f30%26token%3D1929533000%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">2022 开发人员生态系统现状</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247489234%26idx%3D1%26sn%3Db6b7aaffebc6bdf85dfd2d8bd6dbd3ea%26chksm%3Dc0887b8cf7fff29ab0ca8e0a297f5f66d6ce4e3f11ed1c28c2c2d7853f2966ec36281bee5c60%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">Python 开发者年度调查</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247487607%26idx%3D1%26sn%3Dba4827cc6fa8965420c22a649a39ce83%26chksm%3Dc0887d29f7fff43f55c492ae88e279c77d14a7323f814fcc3a7961b6e4298dfec33494ce0788%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2">代码审查工具报告</a></p><p><span style="letter-spacing: 0px;"><br></span></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section style="text-align: justify;"><p style="text-align: center;text-wrap: wrap;"><strong>IDE 使用技巧</strong><br></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section style="text-align: center;"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247494974%26idx%3D1%26sn%3D3108e1d2c43978d81371296ad91d68d6%26chksm%3Dc08b8060f7fc09768a9b31bdcd1be4418e54f80ff76914524a4cface46e0d981b827db16ac92%26token%3D441435331%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2"><span style="font-size: 12px;">10 个热门 IDE 主题推荐</span></a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247500429%26idx%3D1%26sn%3Da0d1d597f6365c3558f0196f67f923bc%26chksm%3Dc08bafd3f7fc26c51a13b598413bb17cece97c2582b93a2902671a2dc231241cf5acf61d29f1%26token%3D443990964%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank" data-linktype="2"><span style="font-size: 12px;">IDE 中的「快速功能」</span></a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwNDI5NzUyMQ%3D%3D%26mid%3D2247492832%26idx%3D1%26sn%3Db07d1ac0f9d7fa9b7e5e291991a52acd%26chksm%3Dc08b89bef7fc00a8d9ac8f79bb75c384c7b488efbd03f045b6f198ce72a02aec2e994a202f53%26token%3D1396192698%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank" style="font-size: 12px;" data-linktype="2">最被低估的快捷键</a></p></section></section></section></section></section></section></section></section></section></section></section></section></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section style="text-align: center;margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-ratio="0.5" data-s="300,640" data-type="png" data-w="1080" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/4677158d-9778-44bd-b61a-ab3c44c4d071.png" referrerpolicy="no-referrer"></section></section><section style="" powered-by="xiumi.us"><section style="font-size: 13px;color: rgb(125, 125, 125);text-align: justify;"><p><strong>⏬ 戳「阅读原文」了解更多</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section></section></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - JetBrains（JetBrainsChina）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 06:44:26 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5494143/blog/10139905</guid>
            <link>https://my.oschina.net/u/5494143/blog/10139905</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[新款 MacBook Pro「减配」：内存带宽缩水、14 寸 M3 入门款仅 2 个 USB-C 接口]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>苹果今天在「来势迅猛」发布会上公布了<u><a href="https://www.oschina.net/news/264233/apple-m3-silicon" target="_blank">全新的 M3 系列处理器</a></u>，以及全新的&nbsp;MacBook Pro&nbsp;产品。</p><p>其官方网站的机型比较页显示，新款&nbsp;MacBook Pro&nbsp;内存带宽相比老款 M1 Pro / Max 及 M2 Pro / Max&nbsp;机型有所缩水。</p><p>搭载&nbsp;M3 Pro 的新款 14/16 寸&nbsp;MacBook Pro&nbsp;，<strong>内存带宽为 150 GB/s</strong>。作为对比，<strong>老款 M1 Pro / Max 及 M2 Pro / Max&nbsp;机型为&nbsp;200 GB/s</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9591ed9a6e921154d1d929d6f0bccd82dea.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-44eb5748b2903fdaa56a59e49ece5119773.png" referrerpolicy="no-referrer"></p><p>此外，<strong>搭载 M3 标准版的入门款&nbsp;14&nbsp;寸 MacBook Pro&nbsp;内存带宽为 100 GB/s，与 M2&nbsp;款 13 寸&nbsp;MacBook Air / Pro 持平。</strong></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7ed4e6e4604d9c254e9e028a1fc14cf71e6.png" referrerpolicy="no-referrer"></p><p>苹果技术规格描述显示，在苹果 M3 款 MacBook Pro 中，顶配的 M3 Max 内存带宽&nbsp;300 GB/s。作为对比，M1 Max / M2 Max 款内存带宽 400 GB/s。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-780970d8cb141172c9298cb91d85d392fdd.png" referrerpolicy="no-referrer"></p><hr><p>接口方面，<strong>搭载 M3 的入门款 14 寸 MacBook Pro</strong>，相比搭载 M3 Pro / Max 款的机型，<strong>阉割了右侧 USB-C 雷雳 4 接口，仅具有左侧两个 USB-C 雷雳 4 接口</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ffa1d313e943d5801a493e92c03e0579406.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1a886c2f41980c6fb669cf198c700fb301d.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4f62bc21b2365deef4e269d7386c0231158.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 06:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264253</guid>
            <link>https://www.oschina.net/news/264253</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[世界首个开源贡献榜]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">BenchCouncil（国际测试委员会）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Frk8RYcJstd7KYmFYFdoPRA" target="_blank">发布</a>了世界首个开源贡献榜。并声称该榜单只以贡献分高下，评选出了 20 世纪 60 年代至今开源计算机系统领域主要成果及其贡献者。</span></p><p><span style="color:#000000">该组织邀请了多位独立科学家，从 20 世纪 60 年代至今的开源或对开源产生重要影响的成果中，遴选出了 145 项代表性成果，在确定主要贡献者的基础上产生了开源领域五十年人才榜、机构榜、国家榜。</span></p><p><span style="color:#000000">其中，共 264 人进入榜单，上榜华人共 24 位。美国以 96.67 的分数在国家榜上遥遥领先，中国则以 6.0 的分数排名第二；加州大学伯克利分校在机构榜上获得首位，其次分别是谷歌、Apache 软件基金会。</span></p><p><span style="color:#000000">具体评估标准如下：</span></p><ul><li><span style="color:#000000">为开源运动或发展奠定基础的重要里程碑</span></li><li><span style="color:#000000">原创或开创性的开源作品</span></li><li><span style="color:#000000">对软硬件发展起到重要推动作用的开源作品</span></li><li><span style="color:#000000">被业界或学术界广泛使用或引用的开源作品</span></li></ul><p><span style="color:#000000">国际测试委员会是一个非营利性国际组织，旨在对最先进的技术和业界实践进行评测和基准测试。</span></p><p><strong><span style="color:#000000">一、开源系统贡献榜（1960s-2021）</span></strong></p><p><strong><span style="color:#000000"><img alt="" height="4194" src="https://oscimg.oschina.net/oscnet/up-624e521caa41fcd35e9dff105b3b5a7d062.png" width="300" referrerpolicy="no-referrer"></span></strong></p><p><em><span style="color:#000000">（人员机构以成果发布时所属机构为主，若当时所属机构不清，则列现属机构。）</span></em></p><p><span style="color:#000000">排名前三位学者贡献如下：</span></p><ol><li><span style="color:#000000">Richard Stallman 的主要贡献：发起了 GNU 计划，创立了自由软件基金会 FSF，提出了 Copyleft 概念并设计了 GPL 版权协议，是 GNU 工具链和 GNU Emacs 文本编辑器的主要创建者之一。</span></li><li><span style="color:#000000">Bruce Perens 的主要贡献：制定并发布了开源定义 The open source definition，是开放源代码促进会 OSI 的主要创立者之一，是 Debian 操作系统的主要贡献者之一。</span></li><li><span style="color:#000000">Krste Asanovic 的主要贡献：RISC-V 指令集架构的共同创始人之一，负责开发了 RISC-V BOOM、Rocket Chip 等开源项目，RISC-V 基金会和 SiFive 的共同创始人之一。</span></li></ol><p><span style="color:#000000">国内机构中，涛思数据因时序数据库 TDengine 上榜，百度因深度学习框架 PaddlePaddle 上榜，PingCAP 因 TiDB 数据库上榜，中国科学院计算所和北京开源芯片研究院因开源 RISC-V 处理器香山系列上榜，阿里巴巴和平头哥半导体因开源 RISC-V 处理器玄铁系列上榜，中国科学院软件所因 OpenBLAS 线性代数库上榜，上海纽约大学因对深度学习框架 MXNet 的贡献上榜。</span></p><p><span style="color:#000000"><strong>开源计算机系统成果榜</strong></span></p><p><span style="color:#000000"><strong><img alt="" height="583" src="https://oscimg.oschina.net/oscnet/up-1ccc4d461840ceb4efd4ff1d0f843d735b4.png" width="300" referrerpolicy="no-referrer"></strong></span></p><p><span style="color:#000000"><strong>二、机构榜（1960s-2021）</strong></span></p><p><span style="color:#000000"><strong><img alt="" height="2394" src="https://oscimg.oschina.net/oscnet/up-1b514ad7d52aa35bb651728ca965dcb750d.png" width="300" referrerpolicy="no-referrer"></strong></span></p><p><em>（机构分布在多个国家的，「国家」一般写总部所在国家；其中 OpenRISC Community 总部未知，国家一栏空白。）</em></p><p><span style="color:#000000"><strong>三、国家榜（1960s-2021）</strong></span></p><p><span style="color:#000000"><strong><img alt="" height="682" src="https://oscimg.oschina.net/oscnet/up-2a29a9d8b1a8a9ad4dc028771254bb2f566.png" width="300" referrerpolicy="no-referrer"></strong></span></p><p><span style="color:#000000">具体成果及榜单见 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fevaluation.benchcouncil.org%2Fopencs%2F" target="_blank">BenchCouncil Top OpenCS Achievement Evaluation</a> 网站。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 06:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264250</guid>
            <link>https://www.oschina.net/news/264250</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[裁员后，SiFive 发文谈前路发展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">在确认<a href="https://www.oschina.net/news/263350/sifive-lays-off-hundreds-of-risc-v-developers">裁员</a><span style="background-color:#ffffff">五分之一（约 140 名员工）后，RISC-V 创业公司 SiFive 的</span><span style="background-color:#ffffff">创始人兼首席执行官&nbsp;</span>Patrick<span style="background-color:#ffffff">&nbsp;Little&nbsp;发布了一篇名为「</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sifive.com%2Fblog%2Fthe-road-ahead--" target="_blank">The Road Ahead</a><span style="background-color:#ffffff">」的博文，畅谈该公司的发展之路。</span></span></p><blockquote><p><span style="color:#000000">RISC-V 显然是真实存在的，它发展迅速，并将继续存在！</span></p><p><span style="color:#000000">在 SiFive，我们正在紧急重新发明 computing。自 RISC-V 诞生以来，我们一直在推动其变革，我们的产品正被全球半导体行业中最有才华的设计师集成到最具创新性的产品中。</span></p></blockquote><p><img height="222" src="https://oscimg.oschina.net/oscnet/up-19d15e0e38b13c8d504e35b2f85ed9c59d6.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><span style="background-color:#ffffff">针对其裁员在社区中引发的大量讨论和猜测，</span>Patrick 解释称，此举是根据公司的前瞻性业务目标而做的运营调整。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">SiFive 自认发展状况十分良好：资金充足、</span><span style="background-color:#ffffff">投资者积极参与并大力支持，且正在从许多世界领先的半导体公司获得收入和复利版税。该公司表示，后续将继续大力投资于先进研发，以扩大技术领先地位。</span></span></p><p>「<span style="color:#000000">聪明、快速发展的企业会定期停下来认真审视自己的优先事项，以确保其战略、工作流程、能力和人员完全一致......我们发现需要重新将我们的优先事项和资源集中在最有前途的机会上......我们对我们的开放文化和才华横溢的员工感到非常自豪。进行重组涉及艰难的决策，但从战略上讲，我相信这是我们成长并继续引领行业前进的必要条件。我们祝愿所有同事一切顺利。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="background-color:#ffffff"><span style="color:#000000">SiFive 表示其将继续提供</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sifive.com%2Frisc-v-core-ip" target="_blank">&nbsp;RISC-V 产品组合。</a>「<span style="color:#000000">我们继续增加我们的行业第一和我们的产品组合，包括我们本月早些时候发布的产品——SiFive&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sifive.com%2Fcores%2Fperformance-p870-p870a" target="_blank">Performance P870</a><span style="color:#000000">和</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sifive.com%2Fcores%2Fintelligence-x390" target="_blank">SiFive Intelligence X390</a><span style="color:#000000">。</span>」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">同时，对四大产品系列的承诺也保持不变：<span style="background-color:#ffffff">即 Essential、Intelligence、Performance 和 Automotive 解决方案。</span>Patrick 认为，<span style="background-color:#ffffff">「</span></span><span style="background-color:#ffffff; color:#212529">SiFive 的增长从未如此强劲，我们的机遇也从未如此美好，而且我从未如此自信，SiFive 将通过 RISC-V 以我们尚未开始想象的方式彻底改变计算。</span><span style="color:#000000"><span style="background-color:#ffffff">」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">但大众对此貌似并不买账，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D38066588%26ref%3Dupstract.com" target="_blank">Hacker News</a> 上有人嘲讽道：</span></span></p><blockquote><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「撇开这篇帖子对被解雇员工的麻木不仁不谈（这已经够糟糕了），它实际上并没有告诉现有/潜在客户，SiFive 的业务和产品发生了什么变化。显然是有一些变化发生了，但其并未提供任何实质性的线索。完全适得其反。不过，一切都好，因为 SiFive 将以我们尚未开始想象的方式彻底改变计算！」</span></p></blockquote><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sifive.com%2Fblog%2Fthe-road-ahead--" target="_blank">查看官方博客</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 04:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264245/sifive-the-road-ahead</guid>
            <link>https://www.oschina.net/news/264245/sifive-the-road-ahead</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米免费可商用字体 MiSans L3 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">随着小米澎湃 OS（Xiaomi HyperOS）的发布，其设计团队也对原先提供的可免费商用字体 MiSans&nbsp;进行了更新。本次更新带来了大量生僻字支持，并符合最新 L3 级别&nbsp;GB18030-2022 国标。</span></p><p><span style="color:#000000">根据介绍，GB18030-2022 强制规范三个实现级别，于 2023 年 8 月 1 日起开始执行。实现级别 1 共 27,584 个汉字；实现级别 2 包含实现级别 1，此外，实现级别 2 还支持《通用规范汉字表》中的没有包含在实现级别 1 之内的编码汉字，共计 27,780 个汉字；实现级别 3 包含实现级别 2，此外，实现级别 3 还支持新标准件规定的全部汉字及表 3 中的康熙部首，总计 87,887 个汉字，用于政务服务和公共服务的产品应满足实现级别 3 的要求。</span></p><p><span style="color:#000000">MiSans 包含级别 1+级别 2，MiSans L3 为级别 3 字库（该字库不包含级别 1 和级别 2）。目前，小米提供的多种字体中只有 MiSans L3 满足新国标要求并增加了大量生僻字支持。</span></p><p><span style="color:#000000"><img height="1081" src="https://oscimg.oschina.net/oscnet/up-9d9e4a6db81c509dd3ee1d3fcdcda093c61.png" width="500" referrerpolicy="no-referrer"></span></p><p><strong><span style="color:#000000">下载地址：</span></strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhyperos.mi.com%2Ffont%2Fdownload" target="_blank">https://hyperos.mi.com/font/download</a></p><p><span style="color:#000000">附字体许可协议：</span></p><blockquote><p><span style="color:#000000">本《MiSans 字体知识产权许可协议》 (以下简称「协议」) 是您与小米科技有限责任公司 (以下简称「小米」或「许可方」) 之间有关安装、使用 MiSans 字体 (以下简称「MiSans」或「MiSans 字体」) 的法律协议。您在使用 MiSans 的所有或任何部分前，应接受本协议中规定的所有条款和条件安装、使用 MiSans 的行为表示您同意接受本协议所有条款的约束。否则，请不要安装或使用 MiSans，并应立即销毁和删除所有 MiSans 字体包。</span></p><p><span style="color:#000000">根据本协议的条款和条件，许可方在此授予您一份不可转让的、非独占的、免版税的、可撤销的、全球性的版权许可，使您依照本协议约定使用 MiSans 字体，前提是符合下列条件：</span></p><ol><li><span style="color:#000000">您应在软件中特别注明使用了 MiSans 字体。</span></li><li><span style="color:#000000">您不得对 MiSans 字体或其任何单独组件进行改编或二次开发。</span></li><li><span style="color:#000000">您不得单独将 MiSans 字体或其组件对外租赁、再许可、给予、出借或进一步分发字体软件或其任何副本以及重新分发或售卖。此限制不适用于您使用 MiSans 字体创作的任何其他作品。如您使用 MiSans 字体创作宣传素材、logo、应用 App 等，您有权分发或出售该作品。</span></li></ol></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264234</guid>
            <link>https://www.oschina.net/news/264234</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果发布 M3 系列芯片，采用 3nm 工艺、支持「动态缓存」技术]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>苹果今天在「来势迅猛」发布会上正式官宣 M3、M3 Pro、M3 Max 芯片，是首款采用 3 纳米工艺技术的 PC 芯片。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-71f73fe69b327c0080613e563857425d4b4.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a5ffd09ef952faf193b698712952791bef6.png" referrerpolicy="no-referrer"></p><p>苹果介绍称，M3 系列芯片搭载的新一代图形处理器实现了 Apple 芯片史上最大幅的图形处理器架构飞跃。这款图形处理器不仅速度更快、能效更高，还引入一项全新技术 —— <strong>动态缓存</strong>，同时带来首次登陆 Mac 的硬件加速光线追踪和网格着色等全新渲染功能。渲染速度与 M1 系列芯片相比最快可达 2.5 倍。中央处理器搭载的高性能核心和高能效核心比 M1 中的相应核心分别快 30% 和 50%，神经网络引擎也比 M1 系列芯片上的快 60%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dc04539ba6a94757f1c3fab246b75cd579a.png" referrerpolicy="no-referrer"></p><blockquote><p>M3 配备 8 核 CPU，10 核 GPU，24GB 统一内存，速度最高比 M2 提升 20%；</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-623eac3535af9db850bfb2d64ea6ab5b3dd.png" referrerpolicy="no-referrer"></p><p>M3 Pro 配备 12 核 CPU，18 核 GPU，36GB 统一内存，速度最高比 M2 Pro 提升 10%；</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28da4c8dc357151c24fb01ea6b31a70e3e5.png" referrerpolicy="no-referrer"></p><p>M3 Max 配备 16 核 CPU，40 核 GPU，128GB 统一内存，速度最高比 M2 Max 提升 20%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25db54ce704b69c46fa5dc54117b8d2ca78.png" referrerpolicy="no-referrer"></p></blockquote><p>据介绍，M3 系列芯片中的新一代图形处理器实现了 Apple 芯片史上最大幅的图形处理器架构飞跃。不同于传统图形处理器，它具备动态缓存功能，因而可对硬件中本地内存的使用进行实时分配。在动态缓存功能的加持下，每项任务对内存的消耗精准符合所需。</p><p>此项业界首创技术对开发者透明，为打造全新图形处理器架构提供了基石。它大幅提高了图形处理器的平均利用率，进而给要求更苛刻的专业级 App 及游戏的表现带来显著提升。</p><p>在 M3 系列芯片的支持下，硬件加速光线追踪功能首度登陆 Mac。光线追踪技术能够模拟光线在场景中的表现，从而帮助 App 创造出栩栩如生、逼真的画面。通过这一功能和全新图形处理器架构的加成，专业级 App 的运行速度最高可达到 M1 系列芯片的 2.5 倍。</p><p>此外，全新图形处理器还给 Mac 带来硬件加速网格着色功能，实现图形处理能力和能效的双重提升，更可支持游戏和对图形处理要求高的 App 呈现视觉效果更复杂的场景。官方称，M3 图形处理器在功耗减半的情况下，即可达到与 M1 相当的性能，而在峰值功耗下更可实现高达 65% 的性能提升。</p><p>M3 家族中的所有芯片均搭载 Apple 芯片标志性的统一内存架构。这带来了高带宽、低延迟，以及无出其右的高能效。此外，M3 芯片支持的内存容量最高达 128GB，这使过去无法在笔记本电脑上处理的工作流成为可能，例如 AI 开发者现可运行包含数十亿个参数的规模更大的 Transformer 模型。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4b873d2a11a318754f6315c42b0e6c81f6f.png" referrerpolicy="no-referrer"></p><p>M3、M3 Pro 和 M3 Max 芯片还引入增强型神经网络引擎，用于加速强大的机器学习（ML）模型。与 M1 系列芯片相比，新的神经网络引擎带来最高达 60% 的速度提升，在进一步加速 AI / ML 工作流的同时，还可将数据保留在设备上，以保护用户隐私。</p><p>此外，M3、M3 Pro 和 M3 Max 还支持多种编解码器，例如 H.264、HEVC、ProRes 和 ProRes RAW 以及 AV1。</p><hr><p>除了 M3 系列芯片，苹果还公布了新款 MacBook Pro、iMac。</p><ul><li><strong>MacBook Pro：芯片升级，全新黑色亮相</strong></li></ul><p>作为首条搭载 M3 系列芯片的产品线，全新的 14 英寸和 16 英寸 MacBook Pro 在外形方面并没有任何变化，依然是我们熟悉的「刘海屏」，传闻中的灵动岛并没有到来。</p><p>不过颜色方面新增了「深空黑色」。深空黑色版 MacBook Pro 不仅有着颜色更深的黑色铝金属外壳，外壳还采用了更加先进的化学工艺，外壳表面的阳极氧化层能够有效减少指纹的产生。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f4507207761ea7bc0dffbdc2631b18d3bb9.png" referrerpolicy="no-referrer"></p><p>需要注意的是，<strong>深空黑色版 MacBook Pro 仅在搭载 M3 Pro 和 M3 Max 的型号中提供，如果购买 M3 芯片的机型，依然只能选到深空灰色的版本</strong>。</p><p>价格方面，14 英寸版本中 M3 芯片机型起售价格 12999 元起、M3 Pro 芯片机型起售价格 16999 元起、M3 Max 芯片机型起售价格 26999 元起；16 英寸版本中 M3 Pro 芯片机型起售价格 19999 元起，M3 Max 芯片机型起售价格 27999 元起。</p><p><img src="https://static.oschina.net/uploads/space/2023/1031/115309_of9w_2720166.png" referrerpolicy="no-referrer"></p><blockquote><p><em><strong>相关阅读：<a href="https://www.oschina.net/news/264253" target="news">新款 MacBook Pro「减配」：内存带宽缩水、14 寸 M3 入门款仅 2 个 USB-C 接口</a></strong></em></p></blockquote><ul><li><strong>iMac：采用 M3 芯片，时隔两年终更新</strong></li></ul><p>时隔两年半，24 英寸的 iMac 芯片由 M1 升级最新的 M3 芯片，其芯片运算性能相较上一代 iMac M1 提升了一倍，并且最高可选配 24 GB 统一内存。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-98a671e3f39f136b9795179314aaeb3d2b7.png" referrerpolicy="no-referrer"></p><p>本代 iMac 四个端口的版本依然配有蓝、绿、粉、银、黄、橙和紫七种颜色可选，两个端口的版本仅有蓝、绿、粉、银可选。</p><p>售价方面，iMac 两个端口 (2 个雷雳 / USB 4) 的版本起步价为 10999 元、四个端口 (2 个雷雳 / USB 4 + 2 个 USB 3) 的版本起步价为 12499，相比上代均提高了 1000 元。11 月 1 日上午 9 点接受订购。11 月 7 日发售。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 03:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264233/apple-m3-silicon</guid>
            <link>https://www.oschina.net/news/264233/apple-m3-silicon</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【直播预告】关于开源创业的 15 件小事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p>只要软件开源了，就会有人用？</p><p>开源软件有漏洞，跟作者没关系？</p><p>开源软件协议应当选择最宽松的？</p><p style="text-align:left">应该努力地将软件捐献给基金会？</p><p>开源后，会有很多人来完善项目？</p><p>开源不是为了钱？</p><p>开源软件靠服务和捐助就可以赚钱？</p><p><strong>以上七个问题，禅道创始人王春生的回答都是「 NO 」。</strong>他用自己的亲身经历告诉大家，很多我们想当然的事情，其实并非如此。</p><p>11 月 2 日 19:00，OSCHINA 直播——【开源漫谈】第 5 期，邀请了三位大咖，请他们来聊一聊开源创业遇到的一些难题。他们分别是：</p><ul><li><strong>高春辉</strong>，中国第一个人站长，卓越网、手机之家、ECSHOP 软件、《爱壁纸 HD》应用创始人，全球领先级 ip 库 http://ipip.net 创始人</li><li><strong>王春生</strong>，禅道软件公司的创始人，二十年的 IT 老兵，14 年的创业者</li><li><strong>朱峰</strong>，津津乐道播客网络创始人、主播。连续创业者，商业经验丰富；有多年社区运营经验；资深开发者</li></ul><p>这次直播，不讲大道理，就讲讲开源创业实务，话题不设限，怎么选开源协议，要不要把开源项目捐给基金会，出现了负面舆论怎么「公关」，公司没钱了去哪里找钱，怎么给员工福利，等等，都拿出来讲一讲。</p><p><strong>直播主题：</strong>关于开源创业的 15 件小事</p><p style="text-align:left"><strong>直播时间：</strong>11 月 2 日（周四） 19:00-20:00</p><p style="text-align:left"><strong>直播平台：</strong>「OSC 开源社区」 视频号</p><p><strong>主办方：</strong>开源中国</p><p><span style="background-color:#ffffff; color:#333333">微信扫码预约直播，欢迎加入 OSC 直播交流群，一起唠嗑～</span></p><p><img height="2542" src="https://oscimg.oschina.net/oscnet/up-cb4840eb78bf9005dfd68ff7cb9ce43c4eb.jpg" width="750" referrerpolicy="no-referrer"></p><p><strong>直播福利</strong></p><ul><li><p style="margin-left:0; margin-right:0">互动抽奖：在直播评论区提问，被直播嘉宾回复的用户可获 OSC T 恤 1 件，名额不限。</p></li><li><p style="margin-left:0; margin-right:0">福袋抽奖：直播中将有多轮抽奖，参与就有机会获得 OSC T 恤、笔记本、马克杯 、前沿技术书籍等。</p></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">我们直播间见吧～</p><div><hr></div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>另外，本次直播得到了诸多社区或组织的大力支持，在此特别表示感谢：</strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>渠成开源社区</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>渠成开源社区由禅道项目管理软件团队发起，社区的经营主体为青岛渠成开源计算机网络技术研究中心，是非营利性社会服务活动的社会组织。 渠成开源社区主要面向一线开源软件生产者、贡献者、组织者、赞助商和用户，以解决具体实际问题为宗旨，旨在打造以开源软件为核心纽带的开源生态系统，真正做到让每一个优秀的开源软件都能实现商业化。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.qucheng.cc" target="_blank">www.qucheng.cc</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>禅道</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>禅道是一款开源的全生命周期项目管理软件，基于敏捷和 CMMI 管理理念进行设计，集产品管理、项目管理、质量管理、文档管理、组织管理和事务管理于一体，完整地覆盖了项目管理的核心流程。 禅道自 2009 年发布至今，累计为国内数十万计的公司或团队提供了专业的项目管理工具。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zentao.net%2F" target="_blank">https://www.zentao.net/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>津津乐道博客</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>津津乐道播客成立于 2016 年 2 月，是天津猿行天下科技有限公司旗下的播客品牌。津津乐道播客主创团队由多位行业资深人士组成，本着分享体验、传播经验的原则，团队在 IT、科技、旅游、教育等领域，制作了多档播客节目，并获得市场好评。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdao.fm%2F" target="_blank">https://dao.fm/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>IPIP.net &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>IPIP 专注 IP 地理位置以及 IP 画像数据的研究、整理与发行，我们的主力产品 IP 地理位置数据库主要基于 BGP/ASN 数据以及遍布全球的网络监测点进行城市级 IP 地域数据标注，准确度远高于国内国外同类产品。 &nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ipip.net%2F" target="_blank">https://www.ipip.net/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>GreatSQL 社区 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>GreatSQL 社区成立于 2021 年，由万里数据库发起，致力于通过开放的社区合作，构建国内自主开源数据库版本及开源数据库技术，推动中国开源数据库及应用生态繁荣发展。GreatSQL 是适用于金融级应用的国内自主开源数据库，具备高性能、高可靠、高易用性、高安全等多个核心特性，可以作为 MySQL 或 Percona Server 的可选替换，用于线上生产环境，且完全免费并兼容 MySQL 或 Percona Server。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2F" target="_blank">https://greatsql.cn/ </a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>Gitee 仓库：<a href="https://gitee.com/GreatSQL">https://gitee.com/GreatSQL</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>爱可生开源社区</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>爱可生开源社区，一个有深度的 MySQL 开源社区。社区成立于 2017 年，以开源高质量的运维工具、日常分享技术干货内容、数据库技术布道为己任；目前开源的产品有：SQL 审核工具 SQLE、分布式中间件 DBLE 和数据传输组件 DTLE。在这里，你将收获：高质量的技术内容，企业级数据库工具及服务，丰富的社区活动。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.actionsky.com%2F" target="_blank">https://opensource.actionsky.com/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>PG 中文社区</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>PostgreSQL 中文社区是一个非盈利的民间组织，目前成员都以志愿者身份加入，成立的目的在于构建 PG 数据库技术生态圈子 (内核、用户培训机构、厂商、服务商、软件开发商、高校形成 「业务与利益双向驱动」 的良性发展生态圈)；帮助企业解决人才培养和企业商用数据库成本问题，社区会在各运营平台发布 PostgreSQL 最新信息和 PostgreSQL 相关技术文章，推动 PG 技术在中国的发展。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网链接：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.postgres.cn%2Findex.php%2Fv2%2Fhome" target="_blank">http://www.postgres.cn/index.php/v2/home</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>凹语言</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>凹语言是一个面向 WebAssembly 设计的静态类型编译型语言，目标是简化 WASM 应用的开发。目前已经发布 MVP 版本，并提供了在线的纯浏览器 Playground 和贪吃蛇案例实现。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>主页： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwa-lang.org" target="_blank">https://wa-lang.org</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>KCL 社区 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>KCL&nbsp;是一个开源的基于约束的记录及函数语言，作为沙盒项目托管在 CNCF 基金会。KCL 通过成熟的编程语言技术和实践来改进对大量繁杂配置比如云原生 Kubernetes 配置场景的编写，致力于构建围绕配置的更好的模块化、扩展性和稳定性，更简单的逻辑编写，以及更简单的自动化和生态工具集成。 &nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkcl-lang.io+GitHub" target="_blank">https://kcl-lang.io GitHub </a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>仓库：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkcl-lang" target="_blank">https://github.com/kcl-lang</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>AllData</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>AllData 大数据产品是可定义数据中台，以数据平台为底座，以数据中台为桥梁，以机器学习平台，GPT 平台为框架，提供全链路数字化解决方案。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>项目地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falldatacenter%2Falldata" target="_blank">https://github.com/alldatacenter/alldata </a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>社区官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falldata.readthedocs.io%2Fzh%2Fmaster%2F" target="_blank">https://alldata.readthedocs.io/zh/master/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>得物技术</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>得物技术一直以"上海最好的技术团队"为目标，现已建立上海、北京、杭州三地研发协同与管理机制，实现研发过程数据化、自动化；覆盖供应链、业务支撑、算法、前端等领域，是得物业务背后强有力的技术力量支撑。 &nbsp;&nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2F" target="_blank">https://tech.dewu.com/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>重庆软件园 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>重庆软件园位于重庆经开区，占地 110 万平方米，布局四大组团，是重庆市首批软件产业园 (综合型)、A 区入选重庆市软件和信息服务业「满天星」示范楼宇 (首批)，于 2019 年 9 月 16 日正式开园，坚持「做生态=做产业，做人才=做产业，做服务=做产业」的发展理念，建设集科技、人文、生态、智慧为一体的领军型软件园区。聚焦「3+2」产业布局，实现新一代信息技术产业集群发展。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>园区聚集软件类企业近 2000 家，软件人才近 3 万人，已登记 4000 多项软件著作权，研发投入超 50 亿，40 余项专利将获得科技奖，营收上亿企业近 20 家。立足南岸区、重庆经开区优质产业资源，聚焦软件信息服务业、智能制造、绿色环保 、汽车软件汽车电子、大健康等产业，推动软件产业高质量发展，重庆软件园将全面贯彻落实「满天星」计划，力争到 2026 年成功建成中国软件名园。 &nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>园区官网：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.chongqingpark.com%2F" target="_blank">http://www.chongqingpark.com/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>东方瑞通 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>东方瑞通成立于 1998 年，是国内较早的 IT 高级技术培训企业之一，拥有华为、红帽、微软、PMI、VMware、Oracle 等 33 余家国际厂商授权资质，以培养 it 人才为主，目前覆盖领域：虚拟化、操作系统、网络、安全、数据库、IT 管理、软件开发等细分领域，提供线上，线下交流培训课程与活动。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官网链接：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.easthome.com" target="_blank">www.easthome.com</a></span></span></span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10139755</guid>
            <link>https://my.oschina.net/u/3859945/blog/10139755</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[企业部署 Elasticsearch 因漏洞导致数据泄露，被罚款 5 万]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify">北京市网信办依据《中华人民共和国数据安全法》对属地三家企业<strong>涉嫌存在网络数据安全违法行为</strong>进行立案调查并作出行政处罚。</p><p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify">据称，三家企业违反《中华人民共和国数据安全法》第二十七条规定，<strong>未履行数据安全保护义务，<span style="color:#e67e22">部署的 ElasticSearch 数据库存在未授权访问漏洞，造成部分数据泄露</span></strong>。</p><p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"><img src="https://static.oschina.net/uploads/space/2023/1031/104106_Il49_2720166.png" referrerpolicy="no-referrer"></p><p>北京市网信办依据《中华人民共和国数据安全法》第四十五条第一款规定，对三家企业分别作出责令改正，给予警告，<strong>并处 5 万元罚款的行政处罚，对直接主管人员和其他责任人员处以 1 万元罚款处罚</strong>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264219</guid>
            <link>https://www.oschina.net/news/264219</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ollama —— 在本地启动并运行大语言模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="project_detail_above_text_link_1" data-tracepid="project_detail_above_text_link"><a style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事 <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p><span style="color:#000000">Ollama 是一款命令行工具，可在 macOS 和 Linux 上本地运行 Llama 2、Code Llama 和其他模型。目前适用于 macOS 和 Linux，并计划支持 Windows。</span></p><p><span style="color:#000000">Ollama 目前支持近二十多个语言模型系列，每个模型系列都有许多可用的"tags"。Tags&nbsp;是模型的变体，这些模型使用不同的微调方法以不同的规模进行训练，并以不同的级别进行量化，以便在本地良好运行。量化级别越高，模型越精确，但运行速度越慢，所需的内存也越大。</span></p><p><span style="background-color:#ffffff; color:#1f2328">以下是一些可以下载的开源模型示例：</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#1f2328; display:block; font-family:-apple-system,BlinkMacSystemFont,&quot;Segoe UI&quot;,&quot;Noto Sans&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; max-width:100%; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:max-content; word-spacing:0px"><thead><tr><th>Model</th><th>Parameters</th><th>Size</th><th>Download</th></tr></thead><tbody><tr><td style="border-style:solid; border-width:1px">Mistral</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">4.1GB</td><td style="border-style:solid; border-width:1px"><code>ollama run mistral</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2</code></td></tr><tr><td style="border-style:solid; border-width:1px">Code Llama</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run codellama</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2 Uncensored</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2-uncensored</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2 13B</td><td style="border-style:solid; border-width:1px">13B</td><td style="border-style:solid; border-width:1px">7.3GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2:13b</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2 70B</td><td style="border-style:solid; border-width:1px">70B</td><td style="border-style:solid; border-width:1px">39GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2:70b</code></td></tr><tr><td style="border-style:solid; border-width:1px">Orca Mini</td><td style="border-style:solid; border-width:1px">3B</td><td style="border-style:solid; border-width:1px">1.9GB</td><td style="border-style:solid; border-width:1px"><code>ollama run orca-mini</code></td></tr><tr><td style="border-style:solid; border-width:1px">Vicuna</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run vicuna</code></td></tr></tbody></table><blockquote><p><span style="color:#000000">注意：需要至少有 8 GB 的 RAM 来运行 3B 模型，16 GB 的 RAM 来运行 7B 模型，32 GB 的 RAM 来运行 13B 模型。</span></p></blockquote></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/ollama</guid>
            <link>https://www.oschina.net/p/ollama</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 工作流引擎 FlowLong]]>
            </title>
            <description>
                <![CDATA[<img src="https://foruda.gitee.com/images/1693470775312764207/27440c57_12260.png" alt="flowlong" width="100px" height="113px" referrerpolicy="no-referrer"><h1><a id="user-content-项目介绍" class="anchor" href="https://gitee.com/aizuda/flowlong#%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D"></a>项目介绍</h1><p>FlowLong🐉飞龙工作流</p><ul><li>项目说明  <code>flowlong</code> 中文名 <code>飞龙</code> 在天美好愿景！</li></ul><blockquote><p>⭕本项目采用 <code>AGPL</code> 开源协议（抄袭牟利索赔 100 万），</p></blockquote><blockquote><p>使用必须遵守国家法律法规，⛔不允许非法项目使用，后果自负❗</p></blockquote><p><a href="https://gitee.com/aizuda/flowlong/issues/I7XGP5">使用源码登记入口</a></p><p><a href="https://flowlong.gitee.io/" rel="nofollow">打开官方开发文档</a></p><p><a href="https://flowlong.gitee.io/flowlong-designer" rel="nofollow">点击设计器在线演示</a></p><p><a href="https://gitee.com/flowlong/flowlong-designer">点击设计器源码下载</a></p><p>英文字母 <code>flw</code> 为 <code>flowlong workflow</code> 飞龙工作流的缩写</p><p>🚩中国特色流程操作概念</p><table><thead><tr><th>支持功能</th><th>功能描述</th><th>完成程度</th></tr></thead><tbody><tr><td>顺序会签</td><td>指同一个审批节点设置多个人，如 A、B、C 三人，三人按顺序依次收到待办，即 A 先审批，A 提交后 B 才能审批，需全部同意之后，审批才可到下一审批节点。</td><td>✅</td></tr><tr><td>并行会签</td><td>指同一个审批节点设置多个人，如 A、B、C 三人，三人会同时收到待办任务，需全部同意之后，审批才可到下一审批节点。</td><td>✅</td></tr><tr><td>或签</td><td>一个流程审批节点里有多个处理人，任意一个人处理后就能进入下一个节点</td><td>✅</td></tr><tr><td>抄送</td><td>将审批结果通知给抄送列表对应的人</td><td>✅</td></tr><tr><td>驳回</td><td>将审批重置发送给某节点，重新审批。驳回也叫退回，也可以分退回申请人、退回上一步、任意退回等</td><td>✅</td></tr><tr><td>分配</td><td>允许用户自行决定任务转办、委派、主办，及其它</td><td>✅</td></tr><tr><td>转办</td><td>A 转给其 B 审批，B 审批后，进入下一节点</td><td>✅</td></tr><tr><td>委派</td><td>A 转给其 B 审批，B 审批后，转给 A，A 审批后进入下一节点</td><td>✅</td></tr><tr><td>跳转</td><td>可以将当前流程实例跳转到任意办理节点</td><td>✅</td></tr><tr><td>拿回</td><td>在当前办理人尚未处理文件前，允许上一节点提交人员执行拿回</td><td>✅</td></tr><tr><td>撤销</td><td>流程发起者可以对流程进行撤销处理</td><td>✅</td></tr><tr><td>加签</td><td>允许当前办理人根据需要自行增加当前办理节点的办理人员</td><td>✅</td></tr><tr><td>减签</td><td>在当前办理人操作之前减少办理人</td><td>✅</td></tr><tr><td>认领</td><td>公共任务认领</td><td>✅</td></tr><tr><td>已阅</td><td>任务是否查看状态显示</td><td>✅</td></tr><tr><td>催办</td><td>通知当前活动任务处理人办理任务</td><td>✅</td></tr><tr><td>沟通</td><td>与当前活动任务处理人沟通</td><td>✅</td></tr><tr><td>终止</td><td>在任意节点终止流程实例</td><td>✅</td></tr></tbody></table><h1><a id="user-content-贡献力量" class="anchor" href="https://gitee.com/aizuda/flowlong#%E8%B4%A1%E7%8C%AE%E5%8A%9B%E9%87%8F"></a>贡献力量</h1><ul><li><a href="https://gitee.com/aizuda/flowlong/wikis/%E8%BF%90%E8%A1%8C%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95">运行单元测试</a></li><li>PR 请参考现在代码规范注释说明</li></ul><h1><a id="user-content-使用文档" class="anchor" href="https://gitee.com/aizuda/flowlong#%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3"></a>使用文档</h1><ul><li>设计器源码 <a href="https://gitee.com/flowlong/flowlong-designer">https://gitee.com/flowlong/flowlong-designer</a></li></ul><img src="https://foruda.gitee.com/images/1683680723972384655/f957e75d_12260.png" alt="flowlong" width="500px" height="262px" referrerpolicy="no-referrer"><h1><a id="user-content-其它说明" class="anchor" href="https://gitee.com/aizuda/flowlong#%E5%85%B6%E5%AE%83%E8%AF%B4%E6%98%8E"></a>其它说明</h1><ul><li>基于 <a href="https://gitee.com/link?target=https%3A%2F%2Fbaomidou.com">MybatisPlus</a> 为 <code>ORM</code> 层实现</li><li>后端设计参考了 <a href="https://gitee.com/yuqs/snakerflow">snakerflow</a> 开源工作流实体划分</li></ul>]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/aizuda/flowlong</guid>
            <link>https://gitee.com/aizuda/flowlong</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 浅析 Redis 大 Key]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><span id="OSC_h1_1"></span><h1>一、背景</h1><p><span style="color:#393c5a">在京东到家购物车系统中，用户基于门店能够对商品进行加车操作。用户与门店商品使用 Redis 的 Hash 类型存储，如下代码块所示。不知细心的你有没有发现，如果单门店加车商品过多，或者门店过多时，此 Key 就会越来越大，从而影响线上业务。</span></p><pre><code>userPin:{
      storeId:{门店下加车的所有商品基本信息},
      storeId:{门店下加车的所有商品基本信息},
      ......
}

</code></pre><span id="OSC_h1_2"></span><h1>二、BigKey 的界定和如何产生</h1><span id="OSC_h3_3"></span><h3>2.1、BigKey 的界定</h3><p><span style="color:#393c5a">BigKey 称为大 Key，通常以 Key 对应 Value 的存储大小，或者 Key 对应 Value 的数量来进行综合判断。对于大 Key 也没有严格的定义区分，针对 String 与非 String 结构，给出如下定义：</span></p><ul><li><span style="color:#333333">String：String 类型的 Key 对应的 Value 超过 10KB</span></li><li><span style="color:#333333">非 String 结构（Hash</span><span style="color:#777777">，</span>Set<span style="color:#777777">，</span>ZSet<span style="color:#777777">，</span>List）：Value 的数量达到 10000 个，或者 Vaule 的总大小为 100KB</li><li><span style="color:#333333">集群中 Key 的总数超过 1 亿</span></li></ul><span id="OSC_h3_4"></span><h3>2.2、如何产生</h3><p><span style="color:#393c5a">1、数据结构设置不合理，例如集合中元素唯一时，应该使用 Set 替换 List；</span></p><p><span style="color:#393c5a">2、针对业务缺少预估性，没有预见 Value 动态增长；</span></p><p><span style="color:#393c5a">3、Key 没有设置过期时间，把缓存当成垃圾桶，一直再往里面扔，但是从不处理。</span></p><span id="OSC_h1_5"></span><h1>三、BigKey 的危害</h1><span id="OSC_h3_6"></span><h3>3.1、数据倾斜</h3><p><span style="color:#393c5a">redis 数据倾斜分为</span><strong><span style="color:#393c5a">数据访问倾斜</span></strong><span style="color:#393c5a">和</span><strong><span style="color:#393c5a">数据量倾斜，</span></strong><span style="color:#393c5a">会导致该 Key 所在的数据分片节点 CPU 使用率、带宽使用率升高，从而影响该分片上所有 Key 的处理。</span></p><p><strong><span style="color:#393c5a">数据访问倾斜：</span></strong><span style="color:#393c5a">某节点中 key 的 QPS 高于其他节点中的 Key</span></p><p><strong><span style="color:#393c5a">数据量倾斜：</span></strong><span style="color:#393c5a">某节点中 key 的大小高于其他节点中的 Key，如下图，实例 1 中的 Key1 存储高于其他实例。</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=MTY3YzQ1ODcwZjZkOGYzYTc0YzljYjg4ZmVkMTZlNTEsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><span id="OSC_h3_7"></span><h3>﻿3.2、网络阻塞</h3><p><span style="color:#393c5a">Redis 服务器是一个事件驱动程序，有文件事件和时间事件，文件事件和时间事件都是主线程完成。其中文件事件就是服务器对套接字操作的抽象，客户端与服务端的通信会产生相应的文件事件，服务器通过监听并处理这些事件来完成一系列网络通信操作。</span></p><p><span style="color:#393c5a">Redis 基于 Reactor 模式开发了自己的网络事件处理器，即文件事件处理器，该处理器内部使用 I/O 多路复用程序，可同时监听多个套接字，并根据套接字执行的任务来关联不同的事件处理器。文件事件处理器以单线程的方式运行，但是通过 I/O 多路复用程序来监听多个套接字，既实现了高性能网络通信模型，又保持了内部单线程设计的简单性。文件事件处理器构成如下图：</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=OWJmZjdlMWNjNDIyMmJjMWYwNDU4YjI4NTM0YmQwYmIsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><p>﻿﻿<span style="color:#393c5a">文件事件是对套接字操作的抽象，包括连接应答，写入，读取，关闭，因为一个服务器会连接多个套接字，所以文件事件可能并发出现，即使文件事件并发的出现，但是</span><strong><span style="color:#f5222d">I/O 多路复用程序会将套接字放入一个队列，通过队列有序的，同步的每次一个套接字的方式</span></strong>向文件事件分派器传送套接字，当让一个套接字产生的事件被<strong><span style="color:#f5222d">处理完毕</span></strong>后，I/O 多路复用程序才会继续向文件事件分派器传送下一个套接字，当有大 key 时，单次操作时间延长，导致网络阻塞。</p><span id="OSC_h3_8"></span><h3>3.3、慢查询</h3><p><span style="color:#393c5a">严重影响 QPS 、TP99 等指标，对大 Key 进行的慢操作会导致后续的命令被阻塞，从而导致一系列慢查询。</span></p><span id="OSC_h3_9"></span><h3>3.4、CPU 压力</h3><p><span style="color:#393c5a">当单 Key 过大时，每一次访问此 Key 都可能会造成 Redis 阻塞，其他请求只能等待了。如果应用中设置了超时等，那么上层就会抛出异常信息。最后删除的时候也会造成 redis 阻塞，到时候内存中数据量过大，就会造成 CPU 负载过高。单个分片 cpu 占用率过高，其他分片无法拥有 cpu 资源，从而被影响。此外，大 key 对持久化也有些影响。fork 操作会拷贝父进程的页表项，如果过大，会占用更多页表，主线程阻塞拷贝需要一定的时间。</span></p><span id="OSC_h1_10"></span><h1>四、如何检测 BigKey</h1><span id="OSC_h3_11"></span><h3>4.1、redis-cli --bigkeys</h3><p><span style="color:#393c5a">首先我们从运行结果出发。首先通过脚本插入一些数据到 redis 中，然后执行 redis-cli 的--bigkeys 选项</span></p><pre><code>$ redis-cli --bigkeys

# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.01 to sleep 0.01 sec
# per SCAN command (not usually needed).
-------- 第一部分 start -------
[00.00%] Biggest string found so far 'key-419' with 3 bytes
[05.14%] Biggest list   found so far 'mylist' with 100004 items
[35.77%] Biggest string found so far 'counter:__rand_int__' with 6 bytes
[73.91%] Biggest hash   found so far 'myobject' with 3 fields

-------- 第一部分 end -------

-------- summary -------

-------- 第二部分 start -------
Sampled 506 keys in the keyspace!
Total key length in bytes is 3452 (avg len 6.82)

Biggest string found 'counter:__rand_int__' has 6 bytes
Biggest   list found 'mylist' has 100004 items
Biggest   hash found 'myobject' has 3 fields
-------- 第二部分 end -------

-------- 第三部分 start -------
504 strings with 1403 bytes (99.60% of keys, avg size 2.78)
1 lists with 100004 items (00.20% of keys, avg size 100004.00)
0 sets with 0 members (00.00% of keys, avg size 0.00)
1 hashs with 3 fields (00.20% of keys, avg size 3.00)
0 zsets with 0 members (00.00% of keys, avg size 0.00)
-------- 第三部分 end -------

</code></pre><p><span style="color:#393c5a">以下我们分三步对 bigkeys 选项源码原理进行解析，简要流程如下图：</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=NjgyZWM5MDg1MDBlNDc0MzQwZDc5NDAwMjUxYWJiMGIsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><span id="OSC_h4_12"></span><h4>﻿﻿4.1.1、第一部分是如何进行找 key 的呢？</h4><p><span style="color:#393c5a">Redis 找 bigkey 的函数是 static void findBigKeys(int memkeys, unsigned memkeys_samples)，因为--memkeys 选项和--bigkeys 选项是公用同一个函数，所以使用 memkeys 时会有额外两个参数 memkeys、memkeys_sample，但这和--bigkeys 选项没关系，所以不用理会。findBigKeys 具体函数框架为：</span></p><p><span style="color:#393c5a">1.申请 6 个变量用以统计 6 种数据类型的信息（每个变量记录该数据类型的 key 的总数量、bigkey 是哪个等信息）</span></p><pre><code>typedef struct {
    char *name;//数据类型，如 string
    char *sizecmd;//查询大小命令，如 string 会调用 STRLEN
    char *sizeunit;//单位，string 类型为 bytes，而 hash 为 field
    unsigned long long biggest;//最大 key 信息域，此数据类型最大 key 的大小，如 string 类型是多少 bytes，hash 为多少 field
    unsigned long long count;//统计信息域，此数据类型的 key 的总数
    unsigned long long totalsize;//统计信息域，此数据类型的 key 的总大小，如 string 类型是全部 string 总共多少 bytes，hash 为全部 hash 总共多少 field
    sds biggest_key;//最大 key 信息域，此数据类型最大 key 的键名，之所以在数据结构末尾是考虑字节对齐
} typeinfo;

    dict *types_dict = dictCreate(&amp;typeinfoDictType);
    typeinfo_add(types_dict, "string", &amp;type_string);
    typeinfo_add(types_dict, "list", &amp;type_list);
    typeinfo_add(types_dict, "set", &amp;type_set);
    typeinfo_add(types_dict, "hash", &amp;type_hash);
    typeinfo_add(types_dict, "zset", &amp;type_zset);
    typeinfo_add(types_dict, "stream", &amp;type_stream);

</code></pre><p><span style="color:#393c5a">2.调用 scan 命令迭代地获取一批 key（注意只是 key 的名称，类型和大小 scan 命令不返回）</span></p><pre><code>/* scan 循环扫描 */
do {
    /* 计算完成的百分比情况 */
    pct = 100 * (double)sampled/total_keys;//这里记录下扫描的进度

    /* 获取一些键并指向键数组 */
    reply = sendScan(&amp;it);//这里发送 SCAN 命令，结果保存在 reply 中
    keys  = reply-&gt;element[1];//keys 来保存这次 scan 获取的所有键名，注意只是键名，每个键的数据类型是不知道的。
    ......

} while(it != 0); 

</code></pre><p><span style="color:#393c5a">3.对每个 key 获取它的数据类型（type）和 key 的大小（size）</span></p><pre><code>/* 检索类型，然后检索大小*/
getKeyTypes(types_dict, keys, types);
getKeySizes(keys, types, sizes, memkeys, memkeys_samples);

</code></pre><p><span style="color:#393c5a">4.如果 key 的大小大于已记录的最大值的 key，则更新最大 key 的信息</span></p><pre><code>/* Now update our stats */
for(i=0;i&lt;keys-&gt;elements;i++) {
    ......//前面已解析

    //如果遍历到比记录值更大的 key 时
    if(type-&gt;biggest&lt;sizes[i]) {
        /* Keep track of biggest key name for this type */
        if (type-&gt;biggest_key)
            sdsfree(type-&gt;biggest_key);
        //更新最大 key 的键名
        type-&gt;biggest_key = sdscatrepr(sdsempty(), keys-&gt;element[i]-&gt;str, keys-&gt;element[i]-&gt;len);
        if(!type-&gt;biggest_key) {
            fprintf(stderr, "Failed to allocate memory for key!\n");
            exit(1);
        }

        //每当找到一个更大的 key 时则输出该 key 信息
        printf(
            "[%05.2f%%] Biggest %-6s found so far '%s' with %llu %s\n",
            pct, type-&gt;name, type-&gt;biggest_key, sizes[i],
            !memkeys? type-&gt;sizeunit: "bytes");

        /* Keep track of the biggest size for this type */
        //更新最大 key 的大小
        type-&gt;biggest = sizes[i];
    }

    ......//前面已解析
}

</code></pre><p><span style="color:#393c5a">5.对每个 key 更新对应数据类型的统计信息</span></p><pre><code>/* 现在更新统计数据 */
for(i=0;i&lt;keys-&gt;elements;i++) {
    typeinfo *type = types[i];
    /* 跳过在 SCAN 和 TYPE 之间消失的键 */
    if(!type)
        continue;

    //对每个 key 更新每种数据类型的统计信息
    type-&gt;totalsize += sizes[i];//某数据类型（如 string）的总大小增加
    type-&gt;count++;//某数据类型的 key 数量增加
    totlen += keys-&gt;element[i]-&gt;len;//totlen 不针对某个具体数据类型，将所有 key 的键名的长度进行统计，注意只统计键名长度。
    sampled++;//已经遍历的 key 数量

    ......//后续解析

    /* 更新整体进度 */
    if(sampled % 1000000 == 0) {
        printf("[%05.2f%%] Sampled %llu keys so far\n", pct, sampled);
    }
}

</code></pre><span id="OSC_h4_13"></span><h4>4.1.2、第二部分是如何执行的？</h4><p><span style="color:#393c5a">1.输出统计信息、最大 key 信息</span></p><pre><code>   /* We're done */
    printf("\n-------- summary -------\n\n");
    if (force_cancel_loop) printf("[%05.2f%%] ", pct);
    printf("Sampled %llu keys in the keyspace!\n", sampled);
    printf("Total key length in bytes is %llu (avg len %.2f)\n\n",
       totlen, totlen ? (double)totlen/sampled : 0);

</code></pre><p><span style="color:#393c5a">2.首先输出总共扫描了多少个 key、所有 key 的总长度是多少。</span></p><pre><code>/* Output the biggest keys we found, for types we did find */
    di = dictGetIterator(types_dict);
    while ((de = dictNext(di))) {
        typeinfo *type = dictGetVal(de);
        if(type-&gt;biggest_key) {
            printf("Biggest %6s found '%s' has %llu %s\n", type-&gt;name, type-&gt;biggest_key,
               type-&gt;biggest, !memkeys? type-&gt;sizeunit: "bytes");
        }
    }
    dictReleaseIterator(di);

</code></pre><span id="OSC_h4_14"></span><h4>4.1.3、第三部分是如何执行的？</h4><p><span style="color:#393c5a">di 为字典迭代器，用以遍历 types_dict 里面的所有 dictEntry。de = dictNext(di) 则可以获取下一个 dictEntry，de 是指向 dictEntry 的指针。又因为 typeinfo 结构体保存在 dictEntry 的 v 域中，所以用 dictGetVal 获取。然后就是输出 typeinfo 结构体里面保存的最大 key 相关的数据，包括最大 key 的键名和大小。</span></p><pre><code>  di = dictGetIterator(types_dict);
    while ((de = dictNext(di))) {
        typeinfo *type = dictGetVal(de);
        printf("%llu %ss with %llu %s (%05.2f%% of keys, avg size %.2f)\n",
           type-&gt;count, type-&gt;name, type-&gt;totalsize, !memkeys? type-&gt;sizeunit: "bytes",
           sampled ? 100 * (double)type-&gt;count/sampled : 0,
           type-&gt;count ? (double)type-&gt;totalsize/type-&gt;count : 0);
    }
    dictReleaseIterator(di);

</code></pre><span id="OSC_h3_15"></span><h3>4.2、使用开源工具发现大 Key</h3><p><span style="color:#393c5a">在不影响线上服务的同时得到精确的分析报告。使用 redis-rdb-tools 工具以定制化方式找出大 Key，该工具能够对 Redis 的 RDB 文件进行定制化的分析，但由于分析 RDB 文件为离线工作，因此对线上服务不会有任何影响，这是它的最大优点但同时也是它的最大缺点：离线分析代表着分析结果的较差时效性。对于一个较大的 RDB 文件，它的分析可能会持续很久很久。</span></p><p><span style="color:#393c5a">redis-rdb-tools 的项目地址为：https://github.com/sripathikrishnan/redis-rdb-tools﻿</span></p><span id="OSC_h1_16"></span><h1>五、如何解决 Bigkey</h1><span id="OSC_h3_17"></span><h3>5.1、提前预防</h3><ul><li><span style="color:#333333">设置过期时间，尽量过期时间分散，防止同一时间过期；</span></li><li><span style="color:#333333">存储为 String 类型的 JSON，可以删除不使用的 Filed；</span></li></ul><p><span style="color:#393c5a">例如对象为</span><span style="color:#2ea121">{"userName":"京东到家","ciyt":"北京"}</span>，如果只需要用到 userName 属性，那就定义新对象，只具有 userName 属性，精简缓存中数据</p><ul><li><span style="color:#333333">存储为 String 类型的 JSON，利用@JsonProperty 注解让 FiledName 字符集缩小，代码例子如下。但是存在缓存数据识别性低的缺点；</span></li></ul><pre><code>import org.codehaus.jackson.annotate.JsonProperty;
import org.codehaus.jackson.map.ObjectMapper;
import java.io.IOException;
public class JsonTest {
    @JsonProperty("u")
    private String userName;

    public String getUserName() {
        return userName;
    }
    public void setUserName(String userName) {
        this.userName = userName;
    }
    public static void main(String[] args) throws IOException {
        JsonTest output = new JsonTest();
        output.setUserName("京东到家");
        System.out.println(new ObjectMapper().writeValueAsString(output));

        String json = "{\"u\":\"京东到家\"}";
        JsonTest r1 = new ObjectMapper().readValue(json, JsonTest.class);
        System.out.println(r1.getUserName());
    }
}

{"u":"京东到家"}
京东到家

</code></pre><ul><li><span style="color:#333333">采用压缩算法，利用时间换空间，进行序列化与反序列化。同时也存在缓存数据识别性低的缺点；</span></li><li><span style="color:#333333">在业务上进行干预，设置阈值。比如用户购物车的商品数量，或者领券的数量，不能无限的增大；</span></li></ul><span id="OSC_h3_18"></span><h3>5.2、如何优雅删除 BigKey</h3><span id="OSC_h4_19"></span><h4>5.2.1、DEL</h4><p><span style="color:#393c5a">此命令在 Redis 不同版本中删除的机制并不相同，以下分别进行分析：</span></p><p><strong><span style="color:#393c5a">redis_version &lt; 4.0 版本</span></strong><span style="color:#393c5a">：在主线程中同步删除，删除大 Key 会阻塞主线程，见如下源码基于 redis 3.0 版本。那针对非 String 结构数据，可以先通过 SCAN 命令读取部分数据，然后逐步进行删除，避免一次性删除大 key 导致 Redis 阻塞。</span></p><pre><code>// 从数据库中删除给定的键，键的值，以及键的过期时间。
// 删除成功返回 1，因为键不存在而导致删除失败时，返回 0 
int dbDelete(redisDb *db, robj *key) {
    // 删除键的过期时间
    if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr);

    // 删除键值对
    if (dictDelete(db-&gt;dict,key-&gt;ptr) == DICT_OK) {
        // 如果开启了集群模式，那么从槽中删除给定的键
        if (server.cluster_enabled) slotToKeyDel(key);
        return 1;
    } else {
        // 键不存在
        return 0;
    }
}

</code></pre><p><strong><span style="color:#393c5a">4.0 版本 &lt; redis_version &lt; 6.0 版本</span></strong><span style="color:#393c5a">：引入 lazy-free</span><strong><span style="color:#393c5a">，</span></strong><span style="color:#393c5a">手动开启 lazy-free 时，有 4 个选项可以控制，分别对应不同场景下，是否开启异步释放内存机制：</span></p><ul><li><span style="color:#333333">lazyfree-lazy-expire：key 在过期删除时尝试异步释放内存</span></li><li><span style="color:#333333">lazyfree-lazy-eviction：内存达到 maxmemory 并设置了淘汰策略时尝试异步释放内存</span></li><li><span style="color:#333333">lazyfree-lazy-server-del：执行 RENAME/MOVE 等命令或需要覆盖一个 key 时，删除旧 key 尝试异步释放内存</span></li><li><span style="color:#333333">replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存</span></li></ul><p><span style="color:#4a4a4a">开启 lazy-free 后，Redis 在释放一个 key 的内存时，首先会评估代价，如果释放内存的代价很小，那么就直接在主线程中操作了，没必要放到异步线程中执行</span></p><p><strong><span style="color:#393c5a">redis_version &gt;= 6.0 版本</span></strong><span style="color:#393c5a">：引入 lazyfree-lazy-user-del</span><span style="color:#4a4a4a">，只要开启了，del 直接可以异步删除 key，不会阻塞主线程。具体是为什么呢，现在先卖个关子，在下面进行解析。</span></p><span id="OSC_h4_20"></span><h4>5.2.2、SCAN</h4><p><span style="color:#393c5a">SCAN 命令可以帮助在不阻塞主线程的情况下逐步遍历大量的键，以及避免对数据库的阻塞。以下代码是利用 scan 来扫描集群中的 Key。</span></p><pre><code>public void scanRedis(String cursor,String endCursor) {
        ReloadableJimClientFactory factory = new ReloadableJimClientFactory();
        String jimUrl = "jim://xxx/546";
        factory.setJimUrl(jimUrl);
        Cluster client = factory.getClient();
        ScanOptions.ScanOptionsBuilder scanOptions = ScanOptions.scanOptions();
        scanOptions.count(100);
 
        Boolean end = false;
        int k = 0;
        while (!end) {
            KeyScanResult&lt; String &gt; result = client.scan(cursor, scanOptions.build());
            for (String key :result.getResult()){
                if (client.ttl(key) == -1){
                    logger.info("永久 key 为:{}" , key);
                }
            }
            k++;
            cursor = result.getCursor();
            if (endCursor.equals(cursor)){
                break;
            }
        }
    }

</code></pre><span id="OSC_h4_21"></span><h4>5.2.3、UNLINK</h4><p><span style="color:#393c5a">Redis 4.0 提供了 lazy delete (unlink 命令) ，下面基于源码（redis_version:7.2 版本）分析下实现原理</span></p><ul><li><span style="color:#333333">del 与 unlink 命令底层都调用了 delGenericCommand() 方法；</span></li></ul><pre><code>void delCommand(client *c) {
    delGenericCommand(c,server.lazyfree_lazy_user_del);
}
void unlinkCommand(client *c) {
    delGenericCommand(c,1);
}

</code></pre><ul><li><span style="color:#333333">lazyfree-lazy-user-del 支持 yes 或者 no。默认是 no；</span></li><li><span style="color:#333333">如果设置为 yes，那么 del 命令就等价于 unlink，也是异步删除，这也同时解释了之前咱们的问题，为什么设置了 lazyfree-lazy-user-del 后，del 命令就为异步删除。</span></li></ul><pre><code>void delGenericCommand(client *c, int lazy) {
    int numdel = 0, j;
    // 遍历所有输入键
    for (j = 1; j &lt; c-&gt;argc; j++) {
        // 先删除过期的键
        expireIfNeeded(c-&gt;db,c-&gt;argv[j],0);
        int deleted  = lazy ? dbAsyncDelete(c-&gt;db,c-&gt;argv[j]) :
                              dbSyncDelete(c-&gt;db,c-&gt;argv[j]);
        // 尝试删除键
        if (deleted) {
            // 删除键成功，发送通知
            signalModifiedKey(c,c-&gt;db,c-&gt;argv[j]);
            notifyKeyspaceEvent(NOTIFY_GENERIC,"del",c-&gt;argv[j],c-&gt;db-&gt;id);
            server.dirty++;
            // 成功删除才增加 deleted 计数器的值
            numdel++;
        }
    }
    // 返回被删除键的数量
    addReplyLongLong(c,numdel);
}

</code></pre><p><span style="color:#393c5a">下面分析异步删除 dbAsyncDelete() 与同步删除 dbSyncDelete()，底层同时也是调用 dbGenericDelete() 方法</span></p><pre><code>int dbSyncDelete(redisDb *db, robj *key) {
    return dbGenericDelete(db, key, 0, DB_FLAG_KEY_DELETED);
}

int dbAsyncDelete(redisDb *db, robj *key) {
    return dbGenericDelete(db, key, 1, DB_FLAG_KEY_DELETED);
}

int dbGenericDelete(redisDb *db, robj *key, int async, int flags) {
    dictEntry **plink;
    int table;
    dictEntry *de = dictTwoPhaseUnlinkFind(db-&gt;dict,key-&gt;ptr,&amp;plink,&amp;table);
    if (de) {
        robj *val = dictGetVal(de);
        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we need to incr to retain val */
        incrRefCount(val);
        /* Tells the module that the key has been unlinked from the database. */
        moduleNotifyKeyUnlink(key,val,db-&gt;id,flags);
        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */
        signalDeletedKeyAsReady(db,key,val-&gt;type);
        // 在调用用 freeObjAsync 之前，我们应该先调用 decrRefCount。否则，引用计数可能大于 1，导致 freeObjAsync 无法正常工作。
        decrRefCount(val);
        // 如果是异步删除，则会调用 freeObjAsync 异步释放 value 占用的内存。同时，将 key 对应的 value 设置为 NULL。
        if (async) {
            /* Because of dbUnshareStringValue, the val in de may change. */
            freeObjAsync(key, dictGetVal(de), db-&gt;id);
            dictSetVal(db-&gt;dict, de, NULL);
        }
        // 如果是集群模式，还会更新对应 slot 的相关信息
        if (server.cluster_enabled) slotToKeyDelEntry(de, db);

        /* Deleting an entry from the expires dict will not free the sds of the key, because it is shared with the main dictionary. */
        if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr);
        // 释放内存
        dictTwoPhaseUnlinkFree(db-&gt;dict,de,plink,table);
        return 1;
    } else {
        return 0;
    }
}

</code></pre><p><span style="color:#393c5a">如果为异步删除，调用 freeObjAsync() 方法，根据以下代码分析：</span></p><pre><code>#define LAZYFREE_THRESHOLD 64

/* Free an object, if the object is huge enough, free it in async way. */
void freeObjAsync(robj *key, robj *obj, int dbid) {
    size_t free_effort = lazyfreeGetFreeEffort(key,obj,dbid);
    if (free_effort &gt; LAZYFREE_THRESHOLD &amp;&amp; obj-&gt;refcount == 1) {
        atomicIncr(lazyfree_objects,1);
        bioCreateLazyFreeJob(lazyfreeFreeObject,1,obj);
    } else {
        decrRefCount(obj);
    }
}

size_t lazyfreeGetFreeEffort(robj *key, robj *obj, int dbid) {
    if (obj-&gt;type == OBJ_LIST &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_QUICKLIST) {
        quicklist *ql = obj-&gt;ptr;
        return ql-&gt;len;
    } else if (obj-&gt;type == OBJ_SET &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_HT) {
        dict *ht = obj-&gt;ptr;
        return dictSize(ht);
    } else if (obj-&gt;type == OBJ_ZSET &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_SKIPLIST){
        zset *zs = obj-&gt;ptr;
        return zs-&gt;zsl-&gt;length;
    } else if (obj-&gt;type == OBJ_HASH &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_HT) {
        dict *ht = obj-&gt;ptr;
        return dictSize(ht);
    } else if (obj-&gt;type == OBJ_STREAM) {
        ...
        return effort;
    } else if (obj-&gt;type == OBJ_MODULE) {
        size_t effort = moduleGetFreeEffort(key, obj, dbid);
        /* If the module's free_effort returns 0, we will use asynchronous free
         * memory by default. */
        return effort == 0 ? ULONG_MAX : effort;
    } else {
        return 1; /* Everything else is a single allocation. */
    }
}

</code></pre><p><span style="color:#393c5a">分析后咱们可以得出如下结论：</span></p><ul><li><span style="color:#333333">当 Hash/Set 底层采用哈希表存储（非 ziplist/int 编码存储）时，并且元素数量超过 64 个</span></li><li><span style="color:#333333">当 ZSet 底层采用跳表存储（非 ziplist 编码存储）时，并且元素数量超过 64 个</span></li><li><span style="color:#333333">当 List 链表节点数量超过 64 个（注意，不是元素数量，而是链表节点的数量，List 的实现是在每个节点包含了若干个元素的数据，这些元素采用 ziplist 存储）</span></li><li><span style="color:#333333">refcount == 1 就是在没有引用这个 Key 时</span></li></ul><p><span style="color:#393c5a">只有以上这些情况，在删除 key 释放内存时，才会真正放到异步线程中执行，其他情况一律还是在主线程操作。也就是说 String（不管内存占用多大）、List（少量元素）、Set（int 编码存储）、Hash/ZSet（ziplist 编码存储）这些情况下的 key 在释放内存时，依旧在主线程中操作。</span></p><span id="OSC_h3_22"></span><h3>5.3、分而治之</h3><p><span style="color:#393c5a">采用经典算法「分治法」，将大而化小。针对 String 和集合类型的 Key，可以采用如下方式：</span></p><ul><li><span style="color:#333333">String 类型的大 Key：可以尝试将对象分拆成几个 Key-Value， 使用 MGET 或者多个 GET 组成的 pipeline 获取值，分拆单次操作的压力，对于集群来说可以将操作压力平摊到多个分片上，降低对单个分片的影响。</span></li><li><span style="color:#333333">集合类型的大 Key，并且需要整存整取要在设计上严格禁止这种场景的出现，如无法拆分，有效的方法是将该大 Key 从 JIMDB 去除，单独放到其他存储介质上。</span></li><li><span style="color:#333333">集合类型的大 Key，每次只需操作部分元素：将集合类型中的元素分拆。以 Hash 类型为例，可以在客户端定义一个分拆 Key 的数量 N，每次对 HGET 和 HSET 操作的 field 计算哈希值并取模 N，确定该 field 落在哪个 Key 上。</span></li></ul><p><span style="color:#393c5a">如果线上服务强依赖 Redis，需要考虑到如何做到「无感」，并保证数据一致性。咱们基本上可以采用三步走策略，如下图所示。分别是进行双写，双读校验，最后读新 Key。在此基础上可以设置开关，做到上线后的平稳迁移。</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=ZGE3YWQ4ZDZiZDE4ZjM5MzU1YTRiMTExOWZjY2UxYmMsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><span id="OSC_h1_23"></span><h1>﻿﻿六、总结</h1><p><span style="color:#393c5a">综上所述，针对文章开头咱们购物车大 Key 问题，相信你已经有了答案。咱们可以限制门店数，限制门店中的商品数。如果不作限制，咱们也能进行拆分，将大 Key 分散存储。例如。将 Redis 中 Key 类型改为 List，key 为用户与门店唯一键，Value 为用户在此门店下的商品。</span></p><pre><code>存储结构拆分成两种：
第一种：
    userPin：storeId 的集合
第二种：
    userPin_storeId1:{门店下加车的所有商品基本信息}；
    userPin_storeId2:{门店下加车的所有商品基本信息}     

</code></pre><p><span style="color:#393c5a">以上介绍了大 key 的产生、识别、处理，以及如何使用合理策略和技术来应对。在使用 Redis 过程中，防范大于治理，在治理过程中也要做到业务无感。</span></p><span id="OSC_h1_24"></span><h1>七、参考</h1><p><span style="color:#393c5a">﻿https://github.com/redis/redis.git﻿</span></p><p><span style="color:#393c5a">﻿http://redisbook.com/﻿</span></p><p><span style="color:#393c5a">﻿https://github.com/huangz1990/redis-3.0-annotated.git﻿</span></p><p><span style="color:#393c5a">﻿https://blog.csdn.net/ldw201510803006/article/details/124790121﻿</span></p><p><span style="color:#393c5a">﻿https://blog.csdn.net/kuangd_1992/article/details/130451679﻿</span></p><p><span style="color:#393c5a">﻿http://sd.jd.com/article/4930?shareId=119428&amp;isHideShareButton=1﻿</span></p><p><span style="color:#393c5a">﻿https://www.liujiajia.me/2023/3/28/redis-bigkeys﻿</span></p><p><span style="color:#393c5a">﻿https://www.51cto.com/article/701990.html﻿</span></p><p><span style="color:#393c5a">﻿https://help.aliyun.com/document_detail/353223.html﻿</span></p><p><span style="color:#393c5a">﻿https://juejin.cn/post/7167015025154981895﻿</span></p><p><span style="color:#393c5a">﻿https://www.jianshu.com/p/9e150d72ffc9﻿</span></p><p><span style="color:#393c5a">﻿https://zhuanlan.zhihu.com/p/449648332</span></p><blockquote><p>作者：京东零售&nbsp;高凯</p><p>来源：京东云开发者社区，转载请注明来源</p></blockquote><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10139889</guid>
            <link>https://my.oschina.net/u/4090830/blog/10139889</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[基于模式挖掘的可靠性治理探索与实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><blockquote><p>本文整理自美团技术沙龙第 77 期《美团亿级流量系统的质量风险防控和稳定性治理实践》。本文介绍了基于模式挖掘的可靠性治理探索，为通过技术手段解决该领域代表性问题开启了新的思路。文章第一部分介绍可靠性治理的痛点；第二部分引入模式的概念；第三部分讨论新基建下的新尝试；第四部分分享三个典型的实践案例。</p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-df29f8b032fe5944a8d7b649041f72acc43.jpg" alt="" referrerpolicy="no-referrer"></p><h2>1 可靠性治理的痛点</h2><p>对于亿级流量的线上系统来说，可靠性是至关重要的。从字面上理解，可靠性要求故障少、可信赖。与安全性一样，它们都是信息系统的固有属性之一，也是保障产品质量的关键因素。</p><p>对照 Google 的可靠性模型来看，测试同学会投入很多精力在用例设计、测试执行、持续交付等环节上，研发同学则会更多关注监控、应急和故障分析等。但往往由于项目进度和人力因素，在设计和编码阶段对可靠性的投入和关注不足，导致后续需要付出更高的成本发现和解决潜在隐患。有鉴于此，我们希望能找到更低成本且以更有效的方式发现和治理这些隐患，从而提升系统整体的可靠性。</p><p><img src="https://p0.meituan.net/travelcube/d94c2805fc7216f7058b60b25dee9c2d521185.png" alt="" referrerpolicy="no-referrer"></p><p>在研发设计阶段，我们需要关注系统弹性，考虑潜在故障风险、适应流量变化等，其中相关治理涉及幂等性、健壮性、一致性、超时、限流、熔断等场景。与一般功能测试相比，可靠性治理需要面对不同的服务和系统，发现并治理技术问题，在模糊度上有较大的提升和挑战。就目前而言，质量问题非常明确，但潜在风险策略和解决路径比较模糊。因此，我们希望能找到办法识别并解决这些问题。</p><p><img src="https://p0.meituan.net/travelcube/9fde4b0cae296d02895a1d03351043e3159517.png" alt="" referrerpolicy="no-referrer"></p><p>模糊度的提升会带来两种最常见的现象：</p><ul><li>一种是过于具体，Case by Case 解决问题，类似算法的过拟合，过拟合的问题在于对更广泛范围内的问题缺乏有效性。以幂等性为例，想验证一个接口是否幂等可以很快完成并很快补充接口幂等相关的测试用例，但是对不同的接口、服务、系统以及不同的幂等性设计，还有哪些问题和风险，我们没有办法关注到并控制这些风险。</li><li>另一种是过于泛化，类似算法的欠拟合，欠拟合的问题在于过度虚化导致没有抓住问题的共性特征。以主从延迟为例，主从延迟会给系统带来一致性风险，需要针对性做保护，并进行相关验证，因此我们可以制定规范、梳理 Check List 和测试模板，虽然这样可以最大程度在产研各环节提醒大家关注到这类问题，但并没有找到彻底解决问题的方法。</li></ul><p><img src="https://p0.meituan.net/travelcube/fa0db198a1641d7c6fff31be835b8753341300.png" alt="" referrerpolicy="no-referrer"></p><h2>2 模式的定义</h2><p>类似这些问题如何找到更好的解决办法？我们重点看一下模式对可靠性治理的启发。模式在维基百科的定义是：揭示了这个世界上人工设计和抽象思想中的规律。</p><p>例如下图所示，计算机图形学中的经典分形图案柯赫雪花，是 1904 年瑞典数学家科赫提出。可以看到它有明显的规律，这样的分形规律在自然界无处不在。</p><p><img src="https://p0.meituan.net/travelcube/650b75a49ab89c3f5c5204c5f712e0f6435079.png" alt="" referrerpolicy="no-referrer"></p><p>技术场景的模式会更加丰富些，这类模式和可靠性治理想找到的模式非常接近。</p><p>举例缓存设计的两种常见模式：</p><ul><li>第一种是 Cache-Aside（旁路缓存），也是使用比较广泛的一种方式，它只有在缓存没有命中时，才会查询数据库并更新缓存。</li><li>另外一种是 Write-throught（只写模式），这种模式在每次数据库变更时都会同步更新缓存。</li></ul><p>对比第一种模式，第二种模式的优点是逻辑更清晰、操作简单、缓存命中率更高；缺点是不常请求的数据会被写到缓存中，导致缓存更大。</p><p><img src="https://p1.meituan.net/travelcube/fe10478804776789b284dc94e48f97e1215075.png" alt="" referrerpolicy="no-referrer"></p><p>那么，我们如何找到这些潜在模式并应用到可靠性治理呢？我们现有的业务测试数据、专业知识积累、相关问题分析和覆盘经验，都可以帮助我们找到治理这些通用技术场景的规律。在这里，很重要的一部分是真实的业务数据，我们可以从最基础的数据提取信息，找到解决共性问题的思路。</p><h2>3 大数据下的尝试</h2><p>随着 JVM 非侵入式 AOP 解决方案的成熟，现在我们已经可以采集任意环境下的任意协议流量，以及这些流量依赖的数据关系，也可以在测试环境回放这些流量，包括线上真实采集的流量。这里依赖两个关键点：一是流量采集，这里涉及很多技术方案，这里分享主要是作为一个基础设施；二是有了全链路 Mock 能力，我们才能在测试环境进行各种流量的回放和验证。</p><p><img src="https://p0.meituan.net/travelcube/3df2f4a8531888d62d0b81cc965ebdba289384.png" alt="" referrerpolicy="no-referrer"></p><p>另一个重要基础设施是环境隔离技术，经过快速发展，它已经具备了泳道级别的数据复制隔离，也支持一站式数据消息和部署环境的即拿即用。从最开始通过泳道降低人工测试相互影响，到现在一站式拉出一套环境，能支持各类专项检查独立运行，使用线下数据且不污染主干环境。</p><p><img src="https://p0.meituan.net/travelcube/2fb9dcf93574ab8e46e16237551501ad496283.png" alt="" referrerpolicy="no-referrer"></p><p>基于流量采集和环境隔离这两个能力的成熟，给自动化领域带来了很多新可能。流量采集信息包含了请求参数、返回值和调用链路等信息；环境隔离技术支持数据隔离、消息隔离、各种协议以及部署版本隔离。</p><p>在这种情况下，海量的业务流量可以直接转化成基于规则验证的接口自动化用例，也可以应用到基于业务模型的场景级用例，模式在这里更像是两者之间的「折中」，我们希望通过这种「折中」来解决可靠性治理的难题。</p><h2>4 典型实践分享</h2><p>接下来，我们重点介绍基于模式的三个可靠性治理的典型实践，主要包括幂等性治理、依赖治理和越权治理三个方向。</p><h3>4.1 幂等性治理</h3><p>维基百科中，幂等的定义是数学和计算机科学中某些运算的性质，可以被多次应用，而不会改变最初应用之外的结果。在数学中也有相关的定义，就以一元运算为例，当 f(f(x))=f(x) 时，可以认为这个运算符 f 是幂等的；在计算机科学领域，HTTP 规范中也有对幂等的定义，即多个相同请求的副作用与单个请求相同，例如 GET、PUT 和 DELETE 是幂等的。</p><p><img src="https://p1.meituan.net/travelcube/902fbbee65d75ac506adbbf9db8ebb28204176.png" alt="" referrerpolicy="no-referrer"></p><p>在大部分分布式系统中，请求超时、网络抖动等在线上环境中随时可能发生。幂等性设计是保证服务在高并发情况下高可用的关键。对于每天产生海量订单的线上业务，比如库存、交易、支付和财务等系统都需要通过幂等性避免超卖、重复支付、重复打款等问题的发生；同时幂等性也是消息队列、定时任务、分布式事务等技术类场景稳定运行的基础。</p><p>如下图举例，当一次调用部分成功的情况下，系统会触发重试，而幂等性可以保证在重试时，成功部分不再被重复执行。</p><p><img src="https://p1.meituan.net/travelcube/22c38c3a5234bf04d0059508d0278c17289045.png" alt="" referrerpolicy="no-referrer"></p><p>我们要挖掘通用模式，就需要分析幂等性所有可能的实现方案。</p><p>如下图是几种常见的幂等性实现方案：数据库层面的唯一索引；通过版本或其他状态、条件来限制操作执行的悲观锁和乐观锁；通过具体业务属性参数，构造具有唯一性的 Token 以及分布式系统中广泛使用的分布式锁等。</p><p><img src="https://p0.meituan.net/travelcube/20c2de394399fddbb90f8348429f4020332786.png" alt="" referrerpolicy="no-referrer"></p><p>尽管幂等性的实现方案有多种，但回到幂等性的本质，我们希望多次调用不会产生新的副作用，而系统中副作用的产生往往是通过「写」操作发生。</p><p>分析调用链路发现，当链路上某个节点不幂等而对资源产生副作用后，其后的多个节点都可以检测到相关变化。例如，前序节点通过数据库的写入生成了新的单号，后序节点的参数和返回值很可能会出现这个新单号。这样，我们就可以构造多次同样的请求，之后检查链路上的这些变化来验证幂等性。</p><p><img src="https://p0.meituan.net/travelcube/feded9ba45e7cc6113b8f3c123d5d707559000.png" alt="" referrerpolicy="no-referrer"></p><p>调用链路节点的类型包括了 MYBATIS、RPC、HTTP、MAFKA、CRANE 等，不同幂等性方案在不同类型的节点上有相应的表现，例如唯一索引，更多在 MYBATIS 节点上，不同类型节点的检查策略和优先级也不同。</p><p><img src="https://p0.meituan.net/travelcube/076a87994f48ccad52ebee631b292ba2547874.png" alt="" referrerpolicy="no-referrer"></p><p>如下图，列举了部分节点检查策略和降噪策略。以 MYBATIS 为例，我们会关注到写 SQL 的内容和返回结果，结合索引冲突、锁失败等节点的异常返回进行降噪。比如 THRIFT 节点，我们会关注接口的参数和返回值变化，考虑随机 ID 的生成、时间戳字段等进行相关降噪，最终针对不同幂等性方案和不同节点类型形成通用整体策略。</p><p><img src="https://p0.meituan.net/travelcube/8c2706b169067b4e53e9fa1d6b362cd0229473.png" alt="" referrerpolicy="no-referrer"></p><p>基于通用检查能力，我们可以应用在场景用例编写、流量用例生成和离线流量的自动分析上，通过分析每天线上、线下环境产生的真实流量，我们可以对增量和存量问题进行差异化治理和跟进。</p><p><img src="https://p0.meituan.net/travelcube/2bb82708ca65eccf9942c5515998e20b151408.png" alt="" referrerpolicy="no-referrer"></p><h3>4.2 依赖治理</h3><p>随着微服务的发展，我们的系统变得越来越复杂，调用链路越来越长，例如单接口的下游依赖多达上百个，任何外部依赖的抖动都会成为核心业务的威胁，很多时候系统内部或外部的一些错误被激活，没有得到正确处理，就会在服务内部不断传播，导致系统偏离正确的服务状态，造成服务失败，最终导致业务失败，引起用户可以感知的故障。</p><p><img src="https://p0.meituan.net/travelcube/7aa84a6c96587c952494f351b41bd834559746.png" alt="" referrerpolicy="no-referrer"></p><p>在业务上可以通过依赖分级和熔断策略，保障弱依赖发生故障时，核心流程依然可用。因此我们需要进行依赖治理，而依赖的治理关键在于如何自动化完成分级合理性以及熔断策略有效性的验证。</p><p>类似前面，我们会采用回放业务流量的方式，但基于依赖治理，我们的策略是修改依赖的 Mock 结构，构造依赖故障场景，进行相关验证。</p><p>我们的预期是如果命中了弱依赖，我们期望业务主流程不被阻塞，调用链路也没有阻塞，日志打印和返回信息都符合预期，没有异常表现；如果命中强依赖，验证策略则相反。</p><p><img src="https://p0.meituan.net/travelcube/ea65f83998fd281afb61f0210ffc3115679867.png" alt="" referrerpolicy="no-referrer"></p><p>具体的策略是我们依据接口和依赖关系构造指定依赖故障场景，注入异常后，分析这个异常是否被捕获。如果直接抛到了外层或者接口返回值有相关的异常信息，那当前是强依赖；如果注入依赖后，后续的调用链路被阻断，认为当前依赖是强依赖。反之，则是弱依赖。</p><p>具备这样闭环依赖分级识别以及熔断有效性的治理能力后，我们就可以周期性地对核心服务进行下游依赖等级治理和对熔断策略有效性进行自动验证。</p><p>运营内容主要包括两方面：配置检查和业务验证。</p><p><img src="https://p1.meituan.net/travelcube/21cacef713e1c515e75ad0be73c48182459214.pngv" alt="" referrerpolicy="no-referrer"></p><ul><li>对于依赖等级正确与否的检查，每周运行，发现依赖等级与熔断策略不相符的情况，推动治理。</li><li>对于业务验证，每天运行，持续产生每天增量报告，针对强依赖业务未被阻断、弱依赖业务未被处理，对应的异常等问题推动修改。</li></ul><p><img src="https://p0.meituan.net/travelcube/46852b87e0993671f0f3dd3c788ce537337387.png" alt="" referrerpolicy="no-referrer"></p><h3>4.3 越权治理</h3><p>越权访问是 Web 应用程序中一种常见的漏洞，它存在范围广、危害大，被 OWASP 应用程序安全项目列为 Web 应用十大安全隐患第二名。对于这种商户、用户规模大，交易频繁的线上业务来说，更是存在比较大的安全和合规风险。</p><p>越权就是两个同等级用户，一个可以操作另一个数据；垂直越权则涉及到不同等级用户，例如普通用户可以操作管理员才有的权限数据。</p><p><img src="https://p0.meituan.net/travelcube/bd1d73c092a90fd955b014315529d5fb435342.png" alt="" referrerpolicy="no-referrer"></p><p>典型的有越权处理接口在收到请求后经历以下三个阶段：</p><ul><li>第一步是身份认证，让系统明确当前登录的用户是谁，是后续进行鉴权的基础条件，每家公司和业务可能会有多套鉴权系统。</li><li>第二步是系统决策判断，基于当前登录用户信息，根据身份权限判断是否可以继续操作。</li><li>第三步是数据权限验证，判断当前数据是否是该用户所属，即数据归属判断。</li></ul><p>当系统未做角色判断时，容易发生垂直越权问题；当系统未做数据归属判断时，容易发生水平越权问题。</p><p><img src="https://p0.meituan.net/travelcube/445e4b25c3642b3285bc4c6610720183385165.png" alt="" referrerpolicy="no-referrer"></p><p>我们可以通过回放业务流量构造对应场景，验证接口是否有做权限控制。</p><p>第一次回放，会结合识别到当前流量鉴权方式，构造一个无权限账户进行回放，其余的依赖数据保持不变；第二次回放与第一次类似，只不过需要构造一个有权限账户信息进行回放；比对两次回放结果以及调用链路，验证这个接口是否有相关的鉴权逻辑；再结合调用链路对比以及原始流量的调用链路，比较有效地识别当前的鉴权场景，兼容一些场景通过返回值没有办法完全识别到是否有做鉴权的情况。</p><p><img src="https://p1.meituan.net/travelcube/987a046ffe53e98a2b3a372e5e9470a6616863.png" alt="" referrerpolicy="no-referrer"></p><p>在实际应用中，要考虑我们所使用的流量质量、有效性以及鉴权方式等进行筛选。目前越权检查经过优化和适配不同业务，已经可以自动化、常态化对新增流量进行检测，并将结果同步到报告中，进行日常运营，也支持问题确认、加白和工单创建等。</p><p><img src="https://p0.meituan.net/travelcube/fc1ad4d32886ca9e572b9289ec7fecaa309813.png" alt="" referrerpolicy="no-referrer"></p><p>以上三个治理能力，已经对美团优选部分核心服务默认开启，可以低成本自动化实现相关问题的常态治理及运营。目前覆盖了 500+服务、2 万+接口和 8000+下游、累计发现并治理问题有 1000+。近期已经开始陆续接入到公司内其他业务线进行应用。</p><p><img src="https://p0.meituan.net/travelcube/1ed53bd18db0f07796de4255709e5406164876.png" alt="" referrerpolicy="no-referrer"></p><p>通过以上 3 个案例，我们可以看到共性能力和解法，因此后续的规划主要是建设通用基础设施，包含线上、线下以及不同来源的流量积累、流量分析，在其上进行模式挖掘、结果跟进和运营，在这样体系基础上，不断迭代底层能力，构建更丰富的可靠性治理场景。</p><p><img src="https://p0.meituan.net/travelcube/559a1aaa265cec97745263e1d470c0ef548540.png" alt="" referrerpolicy="no-referrer"></p><h2>5 Q&amp;A</h2><p><strong>Q1：怎样预防配置异常造成的故障？</strong></p><p><strong>A</strong>：用相关事件举例，我们的一些配置平台包含一些规则，可以字符串形式或者一些类型形式存储，系统对这些配置的兼容性或表现，我们可以构造这些配置的异常场景，比如它当前是一个数值类型的配置，那我们可以构造这个配置的异常值、边界值以及空值，比如它包含分隔符的字符串，我们可以用特殊分隔符以及特殊字符，构造异常配置的获取，验证一个配置的兼容性和可靠性的规则是当读取到这样的异常配置后，我们本来能正确回放的流量，在返回值、抛出异常、日志和调用链路层面有哪些相应表现。很多线上配置变更，因为人为原因和系统默认规则没有兜住的情况下，会引入这样的异常配置健壮性验证，有比较好的保障。</p><p><strong>Q2：越权场景检查，链路对比是指走过的链路对比吗？还是每个调用点数据对比？</strong></p><p><strong>A</strong>：对于越权场景，我们可以识别到它在哪个环节进行了鉴权相关调用，不同的鉴权体系，有对应的权限相关服务和基础接口，构造有权限和没权限的场景后，它会识别没权限后的链路调用变化，比如链路节点数量以及哪个节点返回可以发现大部分问题，如果在这层没有识别到是否做鉴权，我们会关注每个节点的请求和返回，通过其他维度信息增强发现的有效性，降低噪声。</p><p><strong>Q3：怎么自动构造接口里没有权限的用户？</strong></p><p><strong>A</strong>：在原始流量里，我们可以识别到它当前的鉴权方式以及它使用了哪些鉴权服务。这样，我们可以基于这个鉴权方式和服务构造有权限或者没有权限的用户。</p><p><strong>Q4：可靠性治理系统是自研的，还是开源的，研发工作量多少人月？</strong></p><p><strong>A</strong>：可靠性系统建设的思路，目前是自研，它基于美团的基础设施和能力，展开上层解决可靠性问题的实践；研发工作量其实还好，它的点在于我们能找到哪些可以进行治理，快速迭代相关能力，并且在这一过程中不断补全新能力加进去，因此它是一个持续的过程，整体规划上，我们会考虑可靠性，从服务和代码的每一层，从机器、资源、基础组件到服务自身、上游流量和网关分层，拆分不同节点，构建不同策略，这样会有一个整体投入。</p><p><strong>Q5：流量限流和服务降级如何实现？</strong></p><p><strong>A</strong>：美团有服务限流和降级能力的基础设施 Rhino 平台，服务降级是研发根据当前依赖等级，结合具体业务分析它是否是一个可降级的依赖，再配置对应的熔断策略，当降级时，是绕过当前故障进行降级还是在故障恢复后 Fallback，这样的相关规则和策略都可以配置化，自动化验证这些策略是否生效、是否符合预期。</p><p><strong>Q6：在有了这些能力基础上，基于模式的可靠性治理用例占比多少？价值怎样评价？</strong></p><p><strong>A</strong>：我们想基于模式找到一个通用的治理策略和能力，这样的话，我们就可以将线上、线下海量流量数据都应用到这里，不需要 QA 同学投入成本，编写对应的用例，对于研发来说，我们希望直接确认和解决一些已识别到的问题，只需要花费问题确认和修复的成本。对于可识别用例占比，因为它是基于全量流量，所以随着时间的积累，历史场景以及新场景会相应覆盖到，它的用例有多少，取决于流量池以及流量质量和代表性。</p><p><strong>Q7：流量回放 Mock，使用字节码，还是沙箱模式？</strong></p><p><strong>A</strong>：这里用到美团的基础设施能力，它在采集过程中，基于字节码增强采集，回放能力也是使用到了同样的能力。</p><p><strong>|</strong> 在美团公众号菜单栏对话框回复【2022 年货】、【2021 年货】、【2020 年货】、【2019 年货】、【2018 年货】、【2017 年货】等关键词，可查看美团技术团队历年技术文章合集。</p><p><img src="https://p1.meituan.net/travelcube/b0364d579285ab22aa6235bd100d7c22178175.png" alt="" referrerpolicy="no-referrer"></p><p>| <a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%9C%AC%E6%96%87%E7%B3%BB%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E5%87%BA%E5%93%81%EF%BC%8C%E8%91%97%E4%BD%9C%E6%9D%83%E5%BD%92%E5%B1%9E%E7%BE%8E%E5%9B%A2%E3%80%82%E6%AC%A2%E8%BF%8E%E5%87%BA%E4%BA%8E%E5%88%86%E4%BA%AB%E5%92%8C%E4%BA%A4%E6%B5%81%E7%AD%89%E9%9D%9E%E5%95%86%E4%B8%9A%E7%9B%AE%E7%9A%84%E8%BD%AC%E8%BD%BD%E6%88%96%E4%BD%BF%E7%94%A8%E6%9C%AC%E6%96%87%E5%86%85%E5%AE%B9%EF%BC%8C%E6%95%AC%E8%AF%B7%E6%B3%A8%E6%98%8E%E2%80%9C%E5%86%85%E5%AE%B9%E8%BD%AC%E8%BD%BD%E8%87%AA%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E2%80%9D%E3%80%82%E6%9C%AC%E6%96%87%E6%9C%AA%E7%BB%8F%E8%AE%B8%E5%8F%AF%EF%BC%8C%E4%B8%8D%E5%BE%97%E8%BF%9B%E8%A1%8C%E5%95%86%E4%B8%9A%E6%80%A7%E8%BD%AC%E8%BD%BD%E6%88%96%E8%80%85%E4%BD%BF%E7%94%A8%E3%80%82%E4%BB%BB%E4%BD%95%E5%95%86%E7%94%A8%E8%A1%8C%E4%B8%BA%EF%BC%8C%E8%AF%B7%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E8%87%B3tech%40meituan.com%E7%94%B3%E8%AF%B7%E6%8E%88%E6%9D%83%E3%80%82" target="_blank">本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明「内容转载自美团技术团队」。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 tech@meituan.com 申请授权。</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/10117396</guid>
            <link>https://my.oschina.net/meituantech/blog/10117396</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Hugging Face 分词器新增聊天模板属性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 编辑器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);"><em style="color: black;">一个幽灵，格式不正确的幽灵，在聊天模型中游荡！</em></p></blockquote><span id="OSC_h2_1"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">太长不看版</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">现存的聊天模型使用的训练数据格式各各不同，我们需要用这些格式将对话转换为单个字符串并传给分词器。如果我们在微调或推理时使用的格式与模型训练时使用的格式不同，通常会导致严重的、无声的性能下降，因此匹配训练期间使用的格式极其重要！Hugging Face 分词器新增了 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 属性，可用于保存模型训练时使用的聊天格式。此属性包含一个 Jinja 模板，可将对话历史记录格式化为正确的字符串。请参阅，技术文档，以了解有关如何在代码中编写和应用聊天模板。</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">引言</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你熟悉 🤗 transformers 库，你可能写过如下代码:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">tokenizer&nbsp;=&nbsp;AutoTokenizer.from_pretrained(checkpoint)<br>model&nbsp;=&nbsp;AutoModel.from_pretrained(checkpoint)<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">通过从同一个 checkpoint 中加载分词器和模型，可以确保对输入字符串使用的分词方法符合模型预期。如果你从另一个模型中选择分词器，则其分词结果很可能会完全不同，此时模型的性能就会受到严重损害。这种现象叫 <strong style="color: black;">分布漂移 (distribution shift)</strong>: 模型一直从一种分布学习 (即训练分词器)，突然，数据分布变成了另一个不同的分布。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">无论你是微调模型还是直接用它进行推理，让这种分布上的变化尽可能小，并保持提供的输入尽可能与训练时的输入一致总是一个好主意。对于常规语言模型，做到这一点相对容易 - 只需从同一检查点加载分词器和模型，就可以了。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">然而，对于聊天模型来说，情况有点不同。这是因为「聊天」不仅仅是直接对单个文本字符串进行分词 - 它需要对一系列消息进行分词。每个消息都包含一个 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">角色</code> 及其 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">内容</code> ，其内容是消息的实际文本。最常见的，角色是「用户」(用于用户发送的消息) 、「助理」(用于模型生成的响应)，以及可选的「系统」(指在对话开始时给出的高级指令)。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">干讲可能有点抽象，下面我们给出一个示例聊天，把问题具象化:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">[<br>&nbsp;&nbsp;&nbsp;&nbsp;{<span style="color: #d14;line-height: 26px;">"role"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"user"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"content"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"Hi&nbsp;there!"</span>},<br>&nbsp;&nbsp;&nbsp;&nbsp;{<span style="color: #d14;line-height: 26px;">"role"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"assistant"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"content"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"Nice&nbsp;to&nbsp;meet&nbsp;you!"</span>}<br>]<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">此消息序列需要先转换为一个文本字符串，然后才能对其进行分词以输入给模型。但问题是，转换方法有很多！例如，你可以将消息列表转换为「即时消息」格式:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">User:&nbsp;Hey&nbsp;there!<br>Bot:&nbsp;Nice&nbsp;to&nbsp;meet&nbsp;you!<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">或者你可以添加特殊词元来指示角色:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">[USER]&nbsp;Hey&nbsp;there!&nbsp;[/USER]<br>[ASST]&nbsp;Nice&nbsp;to&nbsp;meet&nbsp;you!&nbsp;[/ASST]<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">抑或你可以添加词元以指示消息之间的边界，而将角色信息作为字符串插入:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">&lt;|im_start|&gt;user<br>Hey&nbsp;there!&lt;|im_end|&gt;<br>&lt;|im_start|&gt;assistant<br>Nice&nbsp;to&nbsp;meet&nbsp;you!&lt;|im_end|&gt;<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">方法多种多样，但没有哪种方法是最好的或是最正确的。因此，不同的模型会采用截然不同的格式进行训练。上面这些例子不是我编造的，它们都是真实的，并且至少被一个现存模型使用过！但是，一旦模型接受了某种格式的训练，你需要确保未来的输入使用相同的格式，否则就可能会出现损害性能的分布漂移。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">模板: 一种保存格式信息的方式</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">当前的状况是: 如果幸运的话，你需要的格式已被正确记录在模型卡中的某个位置; 如果不幸的话，它不在，那如果你想用这个模型的话，只能祝你好运了; 在极端情况下，我们甚至会将整个提示格式放在，相应模型的博文，中，以确保用户不会错过它！但即使在最好的情况下，你也必须找到模板信息并在微调或推理流水线中手动将其写进代码。我们认为这是一个特别危险的做法，因为使用错误的聊天格式是一个 <strong style="color: black;">静默错误</strong> - 一旦出了错，不会有显式的失败或 Python 异常来告诉你出了什么问题，模型的表现只会比用正确格式时差多了，但很难调试其原因！</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这正是 <strong style="color: black;">聊天模板</strong> 旨在解决的问题。聊天模板是一个 Jinja 模板字符串，你可以使用分词器保存和加载它。聊天模板包含了将聊天消息列表转换为模型所需的、格式正确的输入字符串所需要的全部信息。下面是三个聊天模板字符串，分别对应上文所述的三种消息格式:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">{% for message in messages %}<br>    {% if message['role'] == 'user' %}<br>        {{ "User : " }}<br>    {% else %}<br>        {{ "Bot : " }}<br>    {{ message['content'] + '\n' }}<br>{% endfor %}<br></code></pre><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">{% for message in messages %}<br>    {% if message['role'] == 'user' %}<br>        {{ "[USER]" + message['content'] + " [/USER]" }}<br>    {% else %}<br>        {{ "[ASST]" + message['content'] + " [/ASST]" }}<br>    {{ message['content'] + '\n' }}<br>{% endfor %}<br></code></pre><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">"{% for message in messages %}"<br>    "{{'&lt;|im_start|&gt;' + message['role'] + '\n' + message['content'] + '&lt;|im_end|&gt;' + '\n'}}"<br>"{% endfor %}"<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你不熟悉 Jinja，我强烈建议你花点时间研究下这些模板字符串及其相应的模板输出，看看你是否可以弄清楚这些模板如何将消息列表转换为格式化的消息字符串！其语法在很多方面与 Python 非常相似。</p><span id="OSC_h2_4"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">为什么要使用模板？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你不熟悉 Jinja，一开始上手可能会有点困惑，但我们在实践中发现 Python 程序员可以很快上手它。在开发此功能的过程中，我们考虑了其他方法，例如允许用户按角色指定消息的前缀和后缀。我们发现该方法会变得令人困惑且笨重，而且它非常不灵活，以至于对一些模型而言，我们得需要一些巧妙的变通才行。而另一方面，模板功能强大到足以完全支持我们所知的所有消息格式。</p><span id="OSC_h2_5"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">为什么要这样做呢？为什么大家不统一到一个标准格式呢？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">好主意！不幸的是，为时已晚，因为现有的多个重要模型已经基于迥异的聊天格式进行了训练。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">然而，我们仍然可以稍微缓解下这个问题。我们认为最接近「标准」的格式是 OpenAI 创建的 ChatML 格式。如果你正在训练新的聊天模型，并且此格式适合你，我们建议你使用它并给分词器添加特殊的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">&lt;|im_start|&gt;</code> 和 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">&lt;|im_end|&gt;</code> 词元。它的优点是角色非常灵活，因为角色只是作为字符串插入，而不是特定的角色词元。如果你想使用这个，它是上面的第三个模板，你可以简单地使用一行代码进行设置:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">tokenizer.chat_template&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">"{%&nbsp;for&nbsp;message&nbsp;in&nbsp;messages&nbsp;%}{{'&lt;|im_start|&gt;'&nbsp;+&nbsp;message['role']&nbsp;+&nbsp;'\n'&nbsp;+&nbsp;message['content']&nbsp;+&nbsp;'&lt;|im_end|&gt;'&nbsp;+&nbsp;'\n'}}{%&nbsp;endfor&nbsp;%}"</span><br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">不过，除了格式林立的现状之外，还有第二个不硬设标准格式的原因 - 我们预计模板将广泛用于多种类型模型的预处理，包括那些可能与标准聊天操作迥异的模型。硬设标准格式限制了模型开发人员使用此功能完成我们尚未想到的任务的能力，而模板则为用户和开发人员提供了最大的自由度。甚至可以在模板中加入逻辑检查和判断，这是目前任何默认模板中都没有深入使用的功能，但我们希望它能成为喜欢冒险的用户手中的利刃。我们坚信，开源生态系统应该让你能够做你想做的事，而不是命令你做什么。</p><span id="OSC_h2_6"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">模板如何工作？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">聊天模板是 <strong style="color: black;">分词器</strong> 的一部分，因为它们履行与分词器相同的角色: 存储有关如何预处理数据的信息，以确保你以与训练时相同的格式将数据提供给模型。我们的设计使得用户非常容易将模板信息添加到现有分词器并将其保存或上传到 Hub。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在有聊天模板这个功能之前，聊天格式信息都存储在 <strong style="color: black;">类级别</strong> - 这意味着，例如，所有 LLaMA checkpoint 都将使用同一个硬设在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 的 LLaMA 模型类代码中的聊天格式。为了向后兼容，目前具有自定义聊天格式方法的模型类也已被赋予了 <strong style="color: black;">默认聊天模板</strong>。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在类级别设置默认聊天模板，用于告诉 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">ConversationPipeline</code> 等类在模型没有聊天模板时如何格式化输入，这样做 <strong style="color: black;">纯粹是为了向后兼容</strong>。我们强烈建议你在任何聊天模型上显式设置聊天模板，即使默认聊天模板是合适的。这可以确保默认聊天模板中的任何未来的更改或弃用都不会破坏你的模型。尽管我们将在可预见的将来保留默认聊天模板，但我们希望随着时间的推移将所有模型转换为显式聊天模板，届时默认聊天模板可能会被完全删除。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">有关如何设置和应用聊天模板的详细信息，请参阅，技术文档。</p><span id="OSC_h2_7"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">我该如何开始使用模板？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">很简单！如果分词器设置了 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 属性，则它已准备就绪。你可以在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">ConversationPipeline</code> 中使用该模型和分词器，也可以调用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">tokenizer.apply_chat_template()</code> 来格式化聊天以进行推理或训练。请参阅我们的，开发者指南，或 如何应用聊天模板的文档，以了解更多！</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果分词器没有 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 属性，它可能仍然可以工作，但它将使用该模型类的默认聊天模板。正如我们上面提到的，这是脆弱的，并且当类模板与模型实际训练的内容不匹配时，它同样会导致静默错误。如果你想使用没有 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 的 checkpoint，我们建议检查模型卡等文档以确保使用正确的格式，然后为该格式添加正确的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 。即使默认聊天模板是正确的，我们也建议这样做 - 它可以使模型面向未来，并且还可以清楚地表明该模板是存在的且是适用的。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">即使不是你的 checkpoint，你也可以通过提交，合并请求 (pull request) &nbsp;的方式为其添加 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 。仅需将 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">tokenizer.chat_template</code> 属性设置为 Jinja 模板字符串。完成后，推送更改就可以了！</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你想在你的聊天应用中使用某 checkpoint，但找不到有关其使用的聊天格式的任何文档，你可能应该在 checkpoint 上提出问题或联系其所有者！一旦你弄清楚模型使用的格式，请提交一个 PR 以添加合适的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 。其他用户将会非常感激你的贡献！</p><span id="OSC_h2_8"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">总结: 模板理念</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我们认为模板是一个非常令人兴奋的新特性。除了解决大量无声的、影响性能的错误之外，我们认为它们还开辟了全新的方法和数据模式。但最重要的也许是，它们还代表了一种理念转变: 从核心 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 代码库中挪出一个重要功能，并将其转移到各自模型的仓库中，用户可以自由地做各种奇怪、狂野抑或奇妙的事情。我们迫不及待想看看你会发现哪些用途！</p><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">🤗 宝子们可以戳 <strong style="color: black;">阅读原文</strong> 查看文中所有的外部链接哟！</p></blockquote><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/chat-templates</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Matthew Carrigan</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">译者: Matrix Yao (姚伟峰)，英特尔深度学习工程师，工作方向为 transformer-family 模型在各模态数据上的应用及大规模模型的训练推理。</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">审校/排版: zhongdongy (阿东)</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Hugging Face（gh_504339124f0f）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10120361</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10120361</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 可以做 WebRTC 音视频质量性能优化，惊艳到我了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p><strong>摘要</strong></p><blockquote><p>随着 GPT-4 的发布，AI 的风越吹越旺。GPT-4 可以回答问题，可以写作，甚至可以基于一张草图生成 html 代码搭建一个网站。即构社区的一位开发者@倪同学就基于目前在研究的 WebRTC QOS 技术点对 GPT-3.5 跟 GPT-4 进行一场实验，ChatGPT 会取代程序员还是成为最强辅助？</p></blockquote><p><strong>以下为@倪同学的博文。</strong></p><hr><h1>ChatGPT 取代程序员还是给程序员加 Buff？</h1><p>这两周，AI 新闻一个接着一个，3 月 23 日，Google 开放了内测已久的 AI 对话服务 Bard，Google 强调，这是一款定位为用户提供创意之源的产品，可生成写作草稿或生活中的聊天机器人。早在一周前 3 月 15 日凌晨，OpenAi 距发布 GPT-3.5 后四个月发布了升级版模型 GPT-4，据发布会说，GPT-4 可支持图片输入，角色扮演，写作能力更强了。紧接着 3 月 16 日百度发布了文心一言，一共有五大功能：文学创作、商业文案创作、数理逻辑推算、中文理解、多模态生成。</p><p>随着近日各大厂商 AI 产品的接连发布，<strong>AI 取代人工</strong>这个话题持续在发酵。AI 大幅解放人的生产力或是将冲击一大批职业？</p><p>博主近期在输出 WebRTC 相关的技术博客，不如向 AI 提问看他有什么见解。</p><p>和大部分人一样，博主都还没拿到 Bard 跟文心一言的内测资格。得知 NewBing 用的是 GPT-4 的模型，下面就着<strong>WebRTC 通过哪些 QOS 技术提升音视频通话质量</strong>，向 GPT-3.5 和 Newbing（GPT-4）分别提问，看看他们的答案有何差异。</p><p>如下图，技术科普类问题都难不倒 GPT-3.5 和 GPT-4，我就该问题继续深挖让它们举实例说明：</p><p>NewBing(GPT-4)</p><p><img src="https://oscimg.oschina.net/oscnet/up-4629da845197985993c293d94127cc0c271.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-3.5 给出的结果</p><p><img src="https://oscimg.oschina.net/oscnet/up-54f9e77266206f54ed5b4f0946988bcca36.png" alt="" referrerpolicy="no-referrer"></p><p>NewBing(GPT-4) 直接给出了具体操作实例</p><p><img src="https://oscimg.oschina.net/oscnet/up-d7d0918e1048c337e7d4649564b3858f3f3.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-3.5 给出的结果（有些空泛）</p><p><img src="https://oscimg.oschina.net/oscnet/up-e9dc01bfdceb3cc698a4093d5b1d46da426.png" alt="" referrerpolicy="no-referrer"></p><h1>GPT-4 和 GPT-3.5 对比结论</h1><p>通过实验，我们比较了同一问题两个版本的回答。在普通的文本处理当中，GPT-4 和 GPT-3.5 的区别可能比较小，但是当问题足够具体和复杂时，GPT-4 就会比 GPT-3.5 更精准、更有创意，而且能够处理用户更细微的指令。</p><p>当然，本篇内容不是要讨论 GPT-3.5 跟 GPT-4 的具体差别，而是程序员如何利用 ChatGPT 提升工作效率，加上最强 Buff。以下我将以个人开发经验为音视频开发者分享《<strong>WebRTC 的 QOS 如何提升音视频质量》。</strong></p><h1><strong>WebRTC 技术概述</strong></h1><p>WebRTC 通过一系列的 QOS 技术来提升音视频通话质量: 抗丢包策略 (NACK、 FEC), 拥塞控制策略 (TWCC/REMB), SVC 或多视轨, 视频质量自适应策略， Pacer、JitterBuffer 等.</p><p>总体 QOS 架构如下图所示：</p><p><img src="https://oscimg.oschina.net/oscnet/up-ce883c8c8e5fbb12f3bd9320f13c85cb0aa.png" alt="" referrerpolicy="no-referrer"></p><p>图 1</p><h1><strong>1</strong><strong>丢包恢复策略</strong></h1><h2><strong>1.1 NACK</strong></h2><p>NACK(Negative Acknowledgment) 相较于 ACK 是通过"非到达确认"进行选择性重传的机制。基本原理是发送端对数据进行缓存，接收端通过到达包连续性检测丢包，结合 rtt 和乱序情况在合适的时机向发送端发起重传请求。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1d2480e0c83a78a74feed657cd91b53ff67.png" alt="" referrerpolicy="no-referrer"></p><p>图 2</p><p>如图所示,Receiver 在收到报文 4 之后发现报文 2、3 未到达，暂时将报文 2、3 放入丢失 nack 列表。在超过一定乱序阈值 (通过乱序直方图计算得到，假设这里是 2，那么收到包 4 可认为包 2 丢失)，或者超过一定抖动时间 (根据 rtt 计算)，向 Sender 请求重传丢失的报文 2、3。 Receiver 的请求通过 RTP FB 发送给 Sender, 具体 NACK 请求格式参考 RFC4585。Sender 在收到 NACK 请求后重新发送报文 2、3。</p><p><strong>值得注意的是</strong>，NACK 策略丢包恢复效果取决于重传请求时机。一是 rtt 的计算 (webrtc 默认 rtt 是 100ms)，一是乱序阈值计算。重传请求节奏控制不好容易造成重传风暴，加重拥塞导致拉流出现卡顿。</p><p>参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc4585.html%23page-34%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc4585.html#page-34</a></p><h2><strong>1.2</strong><strong>FEC</strong></h2><p>FEC(Forward Error Correction),前向纠错, 在数据传输和存储中普遍用于数据纠错。WebRTC 中也使用了该技术进行丢包恢复。</p><p>webrtc 实现该冗余功能，有三种方式：</p><h3><strong>1.2.1、RED</strong></h3><p>将前面的报文直接打入到新包里面，在接收端解析主包和冗余包。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dcd63ecbf52cf04e410e589f927271b375a.png" alt="" referrerpolicy="no-referrer"></p><p>图 3</p><p>如图，后面的报文直接包含前面报文，所以当其中某个报文丢失了，可以通过其相邻报文直接恢复。这种方式缺点是抗连续丢包效果差，但是实现简单。</p><p>Opus In-band FEC 正是使用这种方式进行纠错： 将重要信息以较低的比特率再次编码之后添加到后续数据包中，opsu 解码器根据收包情况决定是否利用当前包携带的冗余包进行丢包恢复。</p><p>Opus In-band FEC 详细参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Frfc6716%23section-2.1.7" target="_blank">https://datatracker.ietf.org/doc/html/rfc6716#section-2.1.7</a></p><p>RED 详细介绍参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc2198.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc2198.html</a></p><h3><strong>1.2.2、ULPFEC</strong></h3><p>在多个数据包之间使用 XOR 来生成此冗余信息，并能够在需要时在接收方恢复丢失的数据包。 ULPFEC 能够通过选择受保护的字节数并应用 XOR 的先前数据包的数量，为不同的数据包提供不同级别的保护。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dbc67f90d60129a5ac409477503478c5928.png" alt="" referrerpolicy="no-referrer"></p><p>图 4</p><p>如图，FEC packet 1 保护 L0 级报文 A、B。 FEC packet 2 及保护 L0 级的 A、B, 也保护 L1 级报文 C、D。</p><p>参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc5109.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc5109.html</a></p><h3><strong>1.2.3、FLEXFEC</strong></h3><p>较 ULPFEC，FLEXFEC 可以灵活选择 1D 行异或、列异或以及 2D 行列异或，增加网络抗丢包能力。</p><p>1-D 行异或纠错</p><p><img src="https://oscimg.oschina.net/oscnet/up-10096bc8991b4dd01f54dfc56124b023479.png" alt="" referrerpolicy="no-referrer"></p><p>图 5</p><p>1-D 列异或纠错</p><p><img src="https://oscimg.oschina.net/oscnet/up-b5c40a4c18f39836dbb9e92fc3017670964.png" alt="" referrerpolicy="no-referrer"></p><p>图 6</p><p>2-D 行列异或纠错</p><p><img src="https://oscimg.oschina.net/oscnet/up-36d1716da02b29d6139ec01f2c1ca7a4845.png" alt="" referrerpolicy="no-referrer"></p><p>图 7</p><p>FLEXFEC 虽然相比前面两个有更强的恢复能力，行列交错丢包比如图 7 中 (1、2、5、6) 丢失就会出现无法纠错的情况。</p><p>WebRTC 用到 FEC 策略整体丢包恢复能力都偏弱，业界普遍应用 Reed-Solomon FEC 进行丢包恢复，Reed-Solomon FEC(K + N : K 个数据包 N 个 FEC 包) 可以真正恢复分组内任意 &lt;=N 个丢包。</p><p>FLEXFEC 详细实现可以参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc8627.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc8627.html</a></p><h1><strong>2 带宽评估及码率控制</strong></h1><h2><strong>2.1 REMB-GCC</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-0651b1a1da43906fa2e59639953688b12dc.png" alt="" referrerpolicy="no-referrer"></p><p>图 8</p><p>图 8 是 REMB-GCC 架构图，基本思想是通过接收端评估带宽， 然后通过 RTCP REMB 将带宽反馈给发送端。 发送端结合丢包率计算一个带宽结果 As,和 RMEB 的结果 Ar, 取 min(As, Ar) 作为最终带宽结果。</p><h2><strong>2.2 SendSide BWE</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-c4f0e4a20b5e2e2bc5801517dce2e63525b.png" alt="" referrerpolicy="no-referrer"></p><p>图 9</p><p>跟<strong>REMB-GCC</strong> 相比，TFB-GCC 主要区别在于大部分带宽计算都转移到发端计算，滤波器的实现不再用 Kalman 滤波，而是变成<strong>TrendLine 滤波器</strong>。</p><p>发送端发送的包需在扩展头带： Transport-wide sequence number.</p><p>接收端定期发送 Transport-wide feedback 报文，通知发送端和接收端接收报文的相关信息，包括报文到达时间、报文到达时间、报文格式等信息。发送端收到 Transport-wide feedback 报文之后，根据报文携带的信息进行延迟滤波计算 (Trandline).</p><p>Transport-wide feedback 报文格式参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Fdraft-holmer-rmcat-transport-wide-cc-extensions-01%3Fsource%3Doschina%26article64" target="_blank">https://datatracker.ietf.org/doc/html/draft-holmer-rmcat-transport-wide-cc-extensions-01</a></p><h2><strong>2.3 速率控制</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-cf155320998fb6f015ca55496f9b6716354.png" alt="" referrerpolicy="no-referrer"></p><p>图 10</p><p><img src="https://oscimg.oschina.net/oscnet/up-6c862c3581fe6d7a57ae15e961f84f7db78.png" alt="" referrerpolicy="no-referrer"></p><p>图 11</p><p>根据过载检测器产生的信号 s，驱动如图 10 所示的有限状态机来调整码率。</p><p>GCC 算法原理详细参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fc3lab.poliba.it%2Fimages%2F6%2F65%2FGcc-analysis.pdf%3Fsource%3Doschina%26article64" target="_blank">https://c3lab.poliba.it/images/6/65/Gcc-analysis.pdf</a></p><h1><strong>3</strong><strong>SVC</strong><strong>、多视轨</strong></h1><h2><strong>3.1</strong><strong>SVC</strong></h2><p>SVC (Scalable Video Coding，可适性视频编码或可分级视频编码) 是传统 H.264/MPEG-4 AVC 编码的延伸，可提升更大的编码弹性，并具有时间可适性 (Temporal Scalability)、空间可适性 (Spatial Scalability) 及质量可适性 (SNR/Quality/Fidelity Scalability) 三大特性。</p><p>WebRTC 中 h264 不支持 svc 编码，Vp8 仅支持 Temporal Scalability, VP9 和 AV1 支持时间可适性 (Temporal Scalability)、空间可适性 (Spatial Scalability)。</p><p><img src="https://oscimg.oschina.net/oscnet/up-973028f5afa2ef31a24851f224e9e74bd0e.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-e52d6c53588cf1a352975f823e2cef803dd.png" alt="" referrerpolicy="no-referrer"></p><p>图 12</p><p>上面是时间可适应示意图。假设图例中显示的图层以 30 fps 的帧速率显示。如果我们移除所有 L2 层的图片，剩下层（L0 和 L1）仍然可以成功解码，并且产生一个 15fps 的视频。如果我们进一步删除所有的 L1 图像，那么剩下的 L0 层依然可以被解码并产生一个 7.5fps 的视频, 所以即便是出现丢包，相比不可分级编码可明显提升弱网视频流畅度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b2dfcbe88b9bfb1b8f3f1f22ad9267f43be.png" alt="" referrerpolicy="no-referrer"></p><p>图 13</p><p>如图 12，L0 基层为分辨率最小编码数据，级别越高，分辨率越高。当实际应用中需要较低分辨率时，只需丢弃高 Level 层级数据进行解码。</p><p>针对不同的带宽条件用户和以及不同设备性能的用户可以灵活调整分辨。</p><p>SVC 扩展参考： <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fip.hhi.de%2Fimagecom_G1%2Fassets%2Fpdfs%2FOverview_SVC_IEEE07.pdf%3Fsource%3Doschina%26article64" target="_blank">http://ip.hhi.de/imagecom_G1/assets/pdfs/Overview_SVC_IEEE07.pdf</a></p><p>SVC 与 H264 结合参考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.itu.int%2Frec%2FT-REC-H.264-201704-I%3Fsource%3Doschina%26article64" target="_blank">https://www.itu.int/rec/T-REC-H.264-201704-I</a></p><h2><strong>3.2 多视轨</strong></h2><p>目前主流浏览器都支持 unified-plan sdp, 我们可以在 sdp 协商的时候添加多个视轨，业务上比较常见的就是添加两条视轨 (类似于 SVC 的 Spatial Scalability)，复用相同 DTLS 传输通道。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e11f7f6b5c3c71a6cc86c76a69182dc2ddf.png" alt="" referrerpolicy="no-referrer"></p><p>图 14</p><p>图 12 典型利用 WebRTC 支持多视轨特性编码一大一小两条流的出帧示意图。</p><p>支持多视轨 (大小流) 可以让接收端在下行带宽受限的情况下动态切换到可以支持的分辨率，提升弱网体验。</p><p>多视轨 (大小流) 在对网络丢包及带宽受限情况的适应不如 SVC 灵活，但是多视轨实现简单，编码、解码性能消耗较低，在实际的业务场景中得到广泛应用。</p><p>多视轨需要支持 Unified Plan SDP 协商, 参考 WebRTC 相关说明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwebrtc.github.io%2Fwebrtc-org%2Fweb-apis%2Fchrome%2Funified-plan%2F%3Fsource%3Doschina%26article64" target="_blank">https://webrtc.github.io/webrtc-org/web-apis/chrome/unified-plan/</a></p><h1><strong>4 视频质量调整策略</strong></h1><p>在网络传输质量变差 (上行带宽不足)、CPU 占有率过高，编码器编码质量 QP 值过大等情况下，WebRTC 会通过降质量来保障视频通话。降质量策略主要分降帧率 (即清晰优先模式) 和降分辨率 (即流畅优先模式)，通过 MediaStreamTrack Content Hints 来设置。</p><p><strong>清晰优先模式</strong> WebRTC 在编码的时候更注重视频细节，在出现上述情况需要降质量时，会通过降低帧率、保持分辨率不变来保障拉流用户的主观感受。对于推流端做屏幕分享内容是 PPT 或者拉流用户大屏显示的业务场景尤为重要。</p><p><strong>流畅优先模式</strong> 推流端在需要降质量的时候优先降低分辨率、保持一定的帧率来保障拉流用户的流畅体验。</p><p>在带宽或 CPU 资源等不再受限时，WebRTC 会根据降质量偏好设置逆向提升视频质量。</p><p>使用者应该根据自己的业务场景进行适当设置，才能在极端情况下保证主观体验不至于太差。</p><h1><strong>5 Pacer</strong></h1><p>WebRTC 的 Pacer 模块主要是让需要发送的包根据评估的网络带宽尽量均匀的分布在每个发送时间窗口发出，起到平滑发包、避免网络拥塞的作用。</p><p>假设有一条 5Mbps 和 30fps 的视频流。 在理想情况下，每个帧大小约为 21kB，打包成 18 个 RTP 数据包。 按照一秒时间窗口统计的平均比特率是 5Mbps，但在更短的时间范围内，它可以被视为每 33 毫秒突发 167Mbps。 此外，视频编码器在突然移动的情况下会超过目标帧率，尤其是在处理屏幕共享时，帧比目标尺寸大 10 倍甚至 100 倍很常见。 这些数据包如果编码完成马上发出去会导致几个问题: 网络拥塞、缓冲区膨胀、甚至数据包丢失。 大多数会话都有不止一条媒体流，可能同时包含音频流、视频流、数据流。 如果你一次性将一个帧放在一条传输通道发送，这些数据包需要 100 毫秒才能发出，这可能阻止了任何音频数据包及时发送出去。 Pacer 通过有一个缓冲区来解决这个问题。 媒体包在其中排队，然后使用漏桶算法将它们调整到网络上。 缓冲区包含所有媒体轨道的独立 fifo 流，例如，音频可以优先于视频 - 可以以循环方式发送相同优先级的流，以避免任何一个流阻塞其他流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3b894e7d0824cc00b76bb2b75a11c932177.png" alt="" referrerpolicy="no-referrer"></p><p>图 15</p><h1><strong>6 JitterBuffer</strong></h1><p><img src="https://oscimg.oschina.net/oscnet/up-0a330d475cd478eb5ad7158389b8d6b3362.png" alt="" referrerpolicy="no-referrer"></p><p>图 16</p><p>WebRTC 接收端收到 RTP 包后，放到 PacketBuffer 进行缓存和排序。如上图，在收到 Mark(帧结束) 标志之后，从后往前开始组帧。组完一帧会放到该帧所在 GOP 的缓存里面，根据帧间参考顺序进行调整，当帧间参考关系建立好之后就会放到解码器进行解码。可以认为 Jitter 主要先后做包排序、帧排序、GOP 排序。之所以要进行着一系工作是因为网络本身存在一定的抖动、甚至有丢包，如果有丢包还得等丢包恢复才能完整组帧，所以导致帧到达时间跟发送时间存在一定抖动。Jitter buffer 的存在就很好的解决这个问题，能够在拉流端对待解码数据进行平滑处理，保证我们渲染出来视频是平滑、流畅的。</p><h1><strong>7 关键帧请求</strong></h1><p>视频流通常是以 1 个关键帧+ N 个增量帧的方式发送，这些增量帧依赖于先前的帧进行解码和显示。如果因为一些原因导致 sps/pps 丢失、 组包错误等，如果不采取任何补救措施，就很难继续解码视频流，视频就会卡主, 直到下个关键帧。很多时候为了编码稳定 GOP 设置很大，这个时候意味着长时间卡顿或者黑屏。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a58f2b74a6631610904cf29d65b3ff8ec98.png" alt="" referrerpolicy="no-referrer"></p><p>图 17</p><p>如图接收端因为丢包不能恢复导致 Frame 9 组帧失败，后面即使能组帧成功也无法解码，此时需要从发送端请求一个 I 帧解码刷新当前视频流。</p><p>WebRTC 通过 RTCP 报文向发送端请求发送关键帧，关键帧请求 RTCP 报文格式比较简单，在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc4585" target="_blank">RFC4585</a>（RTP/AVPF）以及<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc5104" target="_blank">RFC5104</a>（AVPF）规定了两种不同的关键帧请求报文格式：Picture Loss Indication (PLI)、Full Intra Request (FIR)。从目前的实现看 WebRTC 在收到 PLI 或者 FIR 之后，都是让编码器编码输出关键帧，然后发送给接收端。</p><p>PLI 报文格式参考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc4585.html%23page-36%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc4585.html#page-36</a></p><p>FIR 参考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc5104.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc5104.html</a></p><h1><strong>QOS 技术总结：</strong></h1><p>本文简单介绍了 WebRTC 中所使用到的 Qos 技术，这些技术从不同的角度去提升 Qos 质量。包括通过<strong>NACK、FEC</strong>技术对丢包进行恢复，解决丢包导致的音、视频卡顿。通过<strong>带宽评估和拥塞控制</strong>技术调整编码和发送码率来自动适应网络带宽的变化情况。通过 SVC、多视轨技术保障不同网络质量的拉流的用户差异的视频质量。 而<strong>Pacer、JitterBuffer</strong>分别在发送端和接收端提升音视频的平滑、流畅度。<strong>关键帧请求</strong>对极端网络抖动之后的快速视频恢复起了重要作用。WebRTC 利用这些技术协同作用，提升整体的 Qos 质量，需要了解技术细节最好的方式还是去阅读 WebRTC 源码。</p><p>WebRTC 的 Qos 技术对提升整体音视频质量效果显著、但 WebRTC 的这些技术还是存在有很多可以优化的地方。音视频厂商 ZEGO 即构自研的 WebRTC 网关对这些策略都做了一定的优化：包括自研带宽评估算法、NACK 算法、大小流等。</p><p>所以，如果你的业务需要一款稳定可靠的音视频服务，可以试试即构实时音视频 RTC 服务。</p><p><strong>点击跳转<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc-zh.zego.im%2Farticle%2F9675%3Fsource%3Doschina%26article64" target="_blank">ZEGO 即构实时音视频服务</a>了解更多 WebRTC 最佳实践内容。</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 12:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5818436/blog/8590740</guid>
            <link>https://my.oschina.net/u/5818436/blog/8590740</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国家广电总局公示《云游戏总体技术要求》等行业标准]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>国家广播电视总局科技司<u><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.nrta.gov.cn%2Fart%2F2023%2F10%2F30%2Fart_113_65962.html" target="_blank">发布公告称</a></u>，按照广播电视和网络视听行业标准制定程序要求和计划安排，国家广播电视总局组织相关单位编制《沉浸式终端通用技术要求》《云游戏总体技术要求》《自由视角视频系统技术要求》行业标准，现对已通过全国广播电影电视标准化技术委员会审查的报批稿予以公示。</p><p><img height="1820" src="https://oscimg.oschina.net/oscnet/up-ad5c1b15dcc8e8faf28a1caa2fb63e4aefb.png" width="2436" referrerpolicy="no-referrer"></p><p>根据《云游戏总体技术要求》行业标准的报批稿，<strong>该文件规定了云游戏的总体技术架构，以及云游戏平台、网络、云游戏终端和云游戏安全的技术要求</strong>，并针对未成年人用户对云游戏平台和云游戏终端提出了要求。</p><p>该标准的起草单位包括：</p><blockquote><p>国家广播电视总局广播电视科学研究院、腾讯科技（上海）有限公司、中国广播电视网络集团有限公司、咪咕互动娱乐有限公司、元境生生（北京）科技有限公司、浙江华数广电网络股份有限公司、江苏省广电有线信息网络股份有限公司、中国广电湖南网络股份有限公司、国广东方网络（北京）有限公司、青岛西发广电传媒科技有限公司、互影科技（北京）有限公司、北京决策数科技有限公司、北京和创摩尔科技有限公司。</p></blockquote><p>云游戏总体技术架构包括云游戏平台、网络、云游戏终端和云游戏安全四个部分：</p><ul><li><p>云游戏平台接收用户操作指令，完成游戏画面的渲染、音视频编解码和游戏推流等操作，将游戏内容以音视频流的形式通过网络传输到用户侧的终端进行呈现；</p></li><li><p>用户使用终端通过网络发送操作指令到云游戏平台进行下一步游戏画面的渲染、游戏推流等；</p></li><li><p>云游戏安全贯穿云游戏的各个环节，实现对用户信息、账号信息、游戏行为信息等的保护。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c3dafe5b6f038392293411fb97f761a26cb.png" referrerpolicy="no-referrer"></p><p>文件显示，云游戏平台应具备基于独立 GPU 的画面渲染能力，应符合 GY / T 353—2021 中的视频格式要求，<strong>应具备 1080P / 50fps 或 1080P / 60fps 的画面渲染能力</strong>，宜支持 2K / 60fps、4K / 50fps、4K / 60fps 等的画面渲染。</p><p>网络方面，根据游戏画面质量的不同，对网络的要求也有所不同，<strong>比如 1080p 50/60fps 要求下行带宽为 20Mbps。</strong></p><p><img alt="" src="https://img.ithome.com/newsuploadfiles/2023/10/a00f64bc-0450-4e75-bd10-557e31022a27.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3d6e9bf9cf65cd2abe5e3c9e79a1f6eb0b9.png" referrerpolicy="no-referrer"></p><p>云游戏终端方面，文件要求设备应满足以下硬件配置要求：</p><ul><li><p>CPU：不低于 4 个处理核心，最高频率不低于 1.5GHz；</p></li><li><p>内存：至少 1GB，建议 2GB 或以上；</p></li><li><p>存储：4GB 或以上，高速 eMMC 或者 UFS。</p></li></ul><p>云游戏终端的解码时延应满足帧率为 30fps 时，解码时延在 20ms 以内；帧率为 50/60fps 时，解码时延在 10ms 以内。终端设备渲染的每一帧画面和播放的声音应严格同步，音画同步时间宜不超过 + 90ms 和-185ms，其中，正值表示声音超前于图像，负值表示声音滞后于图像。<strong>额外操作时延应不大于 150ms，宜不大于 100ms</strong>。</p><p>对未满 18 周岁的未成年人用户，云游戏平台应提供以下保护功能：</p><ul><li><p>具备对用户账号进行实名管理的能力；</p></li><li><p>具备控制未成年人使用游戏时段和时长的能力；</p></li><li><p>具备对未成年人用户游戏消费管理的能力；</p></li><li><p>具备至少通过一种方式向监护者进行提醒通知的能力。</p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 10:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264148</guid>
            <link>https://www.oschina.net/news/264148</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维开源「天工」Skywork-13B 系列大模型，0 门槛商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">昆仑万维宣布开源百亿级大语言模型「天工」Skywork-13B 系列，并配套开源了 600GB、150B Tokens 的超大高质量开源中文数据集。昆仑万维「天工」Skywork-13B 系列目前包括 130 亿参数的两大模型：Skywork-13B-Base 模型、Skywork-13B-Math 模型。</span></p><p><span style="color:#000000">除模型开源外，Skywork-13B 系列大模型还将开源 600GB、150B Tokens 的高质量中文语料数据集 Skypile/Chinese-Web-Text-150B。公告称，这是目前最大的开源中文数据集之一。同时，昆仑万维「天工」Skywork-13B 系列大模型即将全面开放商用；开发者无需申请，即可商用。</span></p><p><span style="background-color:#ffffff; color:#000000">「此次 Skywork-13B 系列大模型将全面开放商用许可，用户在下载模型并同意并遵守《Skywork 模型社区许可协议》后，无需再次申请授权即可将大模型进行商业用途。希望用户能够更便捷地探索 Skywork-13B 系列大模型技术能力，探索在不同场景下的商业化应用。」</span></p><p><strong><span style="color:#000000">Skywork-13B-Base 模型</span></strong></p><blockquote><p><span style="color:#000000">Skywork-13B-Base 模型是 Skywork-13B 的基础模型，其经由 3.2 万亿个多语言高质量数据训练，在 CEVAL、CMMLU、MMLUGSM8K 等评测与基准测试上都展现了同等规模模型的最佳效果。</span></p></blockquote><p><strong><span style="color:#000000">Skywork-13B-Math 模型</span></strong>&nbsp;</p><blockquote><p><span style="color:#000000">Skywork-13B-Math 模型经过专门的数学能力强化训练，在 GSM8K 等数据集上取得了同等规模模型的最佳效果。&nbsp;</span></p></blockquote><p><strong><span style="color:#000000">Skypile/Chinese-Web-Text-150B 数据集</span></strong>&nbsp;</p><blockquote><p><span style="color:#000000">该数据集是根据昆仑天工团队方面经过精心过滤的数据处理流程从中文网页中筛选出的高质量数据。本次开源的数据集大小约为 600GB，总 token 数量约为 150B，目前开源最大的中文数据集之一。</span></p></blockquote><p>一些评测结果如下所示：</p><p><img height="232" src="https://oscimg.oschina.net/oscnet/up-1db28014754e9cdff9ea99cd4870f7d3ee1.png" width="500" referrerpolicy="no-referrer">&nbsp;</p><p><img height="267" src="https://oscimg.oschina.net/oscnet/up-091dc8c601db00caf525c2b1517e82fda18.png" width="500" referrerpolicy="no-referrer"></p><p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FQTe6pILo6jehgC7fiZBmmQ" target="_blank">查看官方公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 09:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264137</guid>
            <link>https://www.oschina.net/news/264137</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[为什么好好的一个开源项目，商业化却往往扑街？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" target="_blank">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div><p>数字化产品如何做商业化？为什么有些开源项目这么优秀，商业化却老是扑街？第四期《开源漫谈》，我们邀请了<strong>王晔倞（头哥）</strong>和<strong>厉启鹏（寈峰）</strong>，一起来聊聊，<strong>开源项目的商业化变现，到底该怎么做？</strong></p><ul><li><p><strong>王晔倞（头哥）</strong>，「头哥侃码」主理人，专注分享技术、创业与产品创新等主题内容。</p></li><li><p><strong>厉启鹏（寈峰）</strong>，现为 vanus.ai CEO，曾就职于阿里云，Apache RocketMQ PMC ，长期专注于 AI 基础设施软件及中间件。</p></li></ul><p>&nbsp;</p><p><strong>头哥：</strong>技术，和一坨代码，和一个好的产品，中间没有直接的关系，只有间接的关系。所以你会发现很多人，他开源做得很好，但商业化做得很差。反过来有的人他商业化做得很好，但社区不会做。现在的 AI 类产品、大模型产品、开源产品，其实都是数字化产品。那么第一个问题来了：</p><p><strong>数字化产品如何实现商业化？中间有什么样的途径吗？</strong></p><p>&nbsp;</p><p><strong>厉启鹏：</strong>我先分享一下开源产品吧。一般来说，我们会先把产品在 Github 上开源，吸引一些人气。这样一来可以找到最初的用户，（毕竟开源是一种很好的推广方式），二来可以通过开源快速地打磨这个产品，在开发者们的帮助下让产品快速迭代，迅速成熟。第二步就是商业化了，在国内的话，像我们做基础设施类的，一般都是以 license 的方式去售卖，或者去拿一些大项目。我们之前服务过大客户，像银行、Saas 公司等等。除此之外，还有一种方式就是提供 Saas 服务，我们会先把产品托管到公有云上去，这样用户在使用产品的时候就不需要自己去部署、自己去运维，需要的时候开箱即用即可。</p><p>不过，不同的项目，它的形态和在商业化的时候需要考虑的东西是不一样的。举个例子，我们现在 vanus 产品的用户有国内的也有国外的，但以我们的经验来说，不同点在于：在国内，提供软件服务的公司，很难避免去做私有化的交付方式。在中国现在的环境下去运营一个纯产品类的公司还是蛮难的。我自己在甲方待过，也在乙方待过，我的感受就是：在中国的软件市场里边，甲方是非常强势的，软件用户的边界感也比较差，如果买了你的产品，就会希望你给他解决所有的问题，无论是软件的问题还是周边的问题，你都要给他解决。现在连我们国内用户做招聘，都要问我们给建议，我还帮我的甲方去面试过（笑~）</p><p>不过话说回来，这种方式还是有它的好处的。首先呢你会跟客户建立一个很强的连接，因为你服务时间长所以他会很信任你，很多东西都给到你，可能你会更容易拿到单子。像中国政企的一些客户，他们的项目都是一年到三年的，这对你的企业来讲，可能毛利不是特别高，但是会让你有持续的现金流输入，对整个企业的发展都有好处。</p><p>当然，这种方式的弊端也很明显。像我现在的产品服务了几十个客户，每个客户都有一个代码分支，每个客户手里的都不一样，这对于我们产品的维护、运维的压力就蛮大的。你会发现，一个软件公司到后期会越做越大，这不是说产品或生意越做越大，而是人员越来越多了，尤其是实施侧的人员、维护的人员，越来越多。这样下来，整体的毛利就会比较低，产品本身也比较割裂，最后可能形成了好几个产品而不是一个产品了。这也算是个有趣的中国特色吧。</p><p>从市场来看，中国纯产品型的软件公司还是比较少的，更多的是项目型的公司。但海外就不一样，就我们接触的经验而言，海外的客户他的边界感非常强，续费率又高，这就很有利于你费心思去打磨自己的产品。不过这种方式也有弊端，那就是他不愿意跟你建立太多的连接。我们之前想做个用户访谈，想问问产品的使用体验，看看你还有哪些场景是我们的产品可以满足的，但就遇到了困难。他可能会觉得，这个产品我用着没事，我也付钱了，你干嘛老找我？</p><p>哈哈，总之，这个市场的差别就非常明显。我个人觉得这两种形态都是比较典型的，也各有利弊，如果要做一个创业项目的话，还要结合具体的产品、不同的团队风格，甚至是创始人的风格，来做选择。</p><p>&nbsp;</p><p><strong>头哥：</strong>刚刚启鹏说的，我真是感同身受啊。我分享一下我的经验吧，我工作比较早，2001 年开始接触 Java，2004 年开始接触 IOE 架构，上海有个电视购物叫东方购物就是我们做的。七八年前，中国是没有基础软件厂商的，更早一点，十五年前，你说要找数据库，那只能想到 Oracle，这是一方面；另一方面，以神州数码为代表的基于标准厂商上面的第三方服务公司大行其道，我们的甲方之所以这么强势，就是被这些人给哄出来的。</p><p>当年我在东方购物的时候，我们一开始买了 Oracle 原厂的服务，Oracle 的工程师来这里支持，1 天 8 小时就要给 1 万块钱，加班另算。你想想 04 年 1 天 1 万是什么水平？后面我们把原厂的服务包给神州数码，服务非常好，价格还只要一半，加班不要钱。就这样，甲方慢慢地就被捧出来了。如果你不能全包，那我就不选你。反正我只是花钱解决问题，却还要我分清问题分开花钱，那我为什么不选一个全包的呢？我自己要是运维这么强还用找你吗？</p><p>所以，现在的甲方都很喜欢把项目总包给阿里云、华为云，这些云厂商都有行业解决方案架构师，他们做的都是解决方案，下面的产品都是模糊的，能用就行。内卷就是这么出来的。不过话说回来，市场没有好坏，关键是你要去适应它，而不是从自己的技术经验出发来判定这个市场好不好，这个思维要不得。</p><p>&nbsp;</p><p><strong>厉启鹏：</strong>是的，你在不同的市场做，就是要尊重不同市场的规则。像国内就是用这种方式去驱动产业的发展的。你也很难用好坏来评判一个市场。我上个月去考察了日本的市场，发现日本市场特别难进入，当时同行有个公司，花了一年的时间，才从日本市场拿了一个 80 万的单子。因为它那里有 POC 、安全认证等等的审核，门槛比较高。但是呢，一旦你吃下这个市场，你就可以一直吃下去，因为他们很少会主动更换供应商。所以，这也是日本市场的一个特点，我们要是想做的话也一样要尊重它的规则，国内国外都一样。</p><p>&nbsp;</p><p><strong>头哥：</strong>说得很好。刚刚启鹏也提到了一个点，就是国内的集成商比较厉害，<strong>很多甲方也会把你当外包看待，压根不管你的产品标不标准，还提一堆有关无关的需求，每个项目按人头算钱，对于这种现象，你怎么看呢？</strong></p><p>&nbsp;</p><p><strong>厉启鹏：</strong>我个人感觉，在国内做项目，要是想做得比较大，那对于这个项目负责人的要求还蛮高的，负责人他可能需要考虑很多方面。我见过一种情况就是，因为一个项目孵化了一个产品，通过这个产品打下了一个行业。之前有个做监控的公司就是这样，刚开始的时候是从建行做起来，后来把产品完善之后推到了浦发等等别的银行去了。那我觉得这种类型还是蛮有价值的，因为你解决的这个问题是一些通用的问题，你把它抽象成了产品，实现了规模化。</p><p>当然，更多的是头哥你说的那种，根本不管你产品如何是不是要做商业化，他只想解决他的问题。当然，这也没有问题，毕竟人家是甲方，出了钱的嘛。对于这种情况，可能这个项目负责人就要考虑下投入的问题，或者是怎么投入这个项目。一种是直接让自己的研发上，all in 到这个项目里边，还有一种方式是去找一些合作伙伴一起把这个项目拿下。甚至很多公司可能会先临时找些外包，因为你如果只要人头，那我就只给你人头，然后我只赚人头的钱。但有的公司呢可能会说对不起这人头钱我不赚，这个项目我不做了。</p><p>我觉得还是要想清楚吧，因为你要是没想清楚的话，可能会对公司的影响比较大，它会冲击你整个研发体系，甚至会影响整个产品的正常迭代。所以去做项目的时候一定要想清楚，你要做什么样的项目，你要服务什么样的用户，你要以什么样的方式去服务他。这个用户画像一定要清楚，不然就会把你的节奏带乱。</p><p>&nbsp;</p><p><strong>头哥：还有一个问题，作为我们这种普通的技术人，如何把我们手上的技术变现呢？</strong></p><p>&nbsp;</p><p><strong>厉启鹏：</strong>加入一家大公司，我觉得可能是一个比较好的方式。因为我自己的体会就是这样的，当时我在阿里做社区，看到不少小伙伴当时还在一家小公司，但是他在我们这个社区里边比较活跃，贡献了很多代码，这给他的经验、经历做了很大的加持，后来他们就都跳槽到大公司去了。从 ROI 的角度，或者从收益的角度来看，这是一个收益很高的事情，通过在知名项目做贡献，提升自己的技术和影响力，从而提升自己的职业生涯，我觉得这是最直接的一种方式。</p><p>第二种方式我也见过好多，就是技术经验丰富之后，去做咨询，或者是指导别人写代码，出书，出课程，做培训等等，也都做得挺不错的。</p><p>最后一种就是创业了，不过如果纯技术人想要创业的话，我建议你可以先加入一家创业公司，如果你能适应的话。假如公司靠谱，那之后它发达了你也就财富自由了。加入一家创业公司工作跟在大公司做一个具体细分的工作差异肯定非常大，在创业公司，假如说要做一辆劳斯莱斯，说不定得先从一辆自行车做起，然后做一辆电动车，再做一辆奥拓，再到宝马，最后才到劳斯莱斯，他是这么一个过程。绝对不是说我给你几年时间，让你做一辆劳斯莱斯，那样公司在市场上很难活下去的。但是在这种逐渐发展的过程中，对于一个技术人的技术视野，甚至商业的视野都会打开很多。我也见过很多这种人，之前是纯做技术的，加入这家创业公司之后，可能刚开始是做技术，后来他可能要做产品经理，再后来他可能是负责整个的售前，这对他个人能力就会有非常大的提升。</p><p>当然，选择也跟年龄段有关系。比如说工作五年以前的，我觉得还是可以去大厂看一看，体验一下。但是如果工作 5 年到 10 年甚至更久的时间了，我觉得加入一家创业公司还是一个不错的选择。但是，如果你说你要作为一个合伙人甚至是创始人去创办一家商业公司，那说实话我个人不是特别推荐。因为如果你是作为合伙人的身份的话，你会发现到后面你首先关注的不是技术了，而是用户，是融资，是市场，你要花很大的精力去做这些事情，可能有些人不一定喜欢。可能你后面做着做着发现自己成了一个销售，当然不是说销售不好，但他可能之前不喜欢，但是后边需要他做这个工作。所以第二个要考虑的就是，这是不是你能力范围内的事情，有些人他快速成长，快速改变，他的适应力非常强，那就没有问题。</p><p>&nbsp;</p><p><strong>头哥：最后一个问题，作为一个优秀的开源项目，如果想尝试商业化，有哪些方式呢？</strong></p><p>&nbsp;</p><p><strong>厉启鹏：</strong>如果是大厂想通过开源实现商业化的话，现在最典型的路径就是捐到基金会去，然后再通过运营社区的方式去获客。这种方式尤其适合基础软件，如果是一个特别垂类的软件倒不一定合适了。个人更赞同的一种方式是通过开源树立一个标杆，获得某些标杆企业的开发者的认可，这时候你再去复制可能就会非常快。比方说我这个软件，如果大厂采用了，那下面的二三线厂商可能也会跟进。影响力打出去了之后，再寻求付费可能就会容易一点了。</p><p>但是在当下，2023 年，这个节点，你建立一个项目去创业，那是比较难的。第一，开源商业化的路径比较长，你得先有项目，然后通过运营社区把这个影响力做起来，再出商业版去变现，那可能意味着这家创业公司要一年两年甚至三年没有收入，或者养活不了自己。在目前的这种就业环境包括投融资环境下，你能不能活两三年，这是一个非常大的问题，很多人撑不住的。</p><p>还有就是，以我自己的感受来讲，很多用户他只用开源版本，他从来就没有想过要用你的商业版，或者你出了商业版之后他就直接走了，这种就很难转化。有些开源公司做商业化成功了，并不是因为转化了开源用户为商业化用户，而是因为这个项目影响力起来之后，影响了那些不使用开源项目的用户，从而实现了商业化。这属于间接影响，你不好量化，从顶上来看的话，你都不好去制定一个考核机制，让大家知道哪些事有价值和引导他们做事。所以我觉得，如果是 Saas 的话，会比开源更能解决你打磨产品的问题，因为上面有数据，他们用了多少你看得到。</p><p>最后，我觉得开源最大的价值就是标准化，比如 Conflict ，它是构建大数据平台的一个标准，不管用它的开源还是买它的商业版，只要构建大数据平台都会想到它。其次就是开源有助于国际化，给了中国的企业出海或者是服务海外客户的一个机会，这是本土闭源的软件公司很难做到的。我一度认为开源加上云，是一个蛮好的方式，能够助力中国的软件企业成为一个服务全球的企业。以前没有云，想服务海外客户还得建本地团队，现在托 AWS 就可以了，大大节省了成本。</p><p>当然，开源好处多多，明天也很美好，现在的挑战就是看你能不能活到明天了。（笑~）</p><p>&nbsp;</p><p>本期直播回放如下，大家快扫码查看吧~</p><p><img height="355" src="https://oscimg.oschina.net/oscnet/up-41198acd2e49349768fe28449ea945e7227.png" width="385" referrerpolicy="no-referrer"></p></div></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 09:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10139809</guid>
            <link>https://my.oschina.net/u/6852546/blog/10139809</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌承诺 20 亿美元投资 OpenAI 对手 Anthropic]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10139755" _blank"="">高春辉、王春生、朱峰：关于开源创业的 15 件小事<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">谷歌发言人日前表示，该公司已同意向 OpenAI 的强力竞争对手 Anthropic 投资最多 20 亿美元。目前已预先投资了 5 亿美元，随着时间的推移将再追加 15 亿美元。</span></p><p><span style="color:#000000">Anthropic 成立于 2021 年，是一家由前 OpenAI 团队成员创立的人工智能初创公司。其在 ChatGPT 发布两个月后，就推出了 GPT-4 的重要竞品 Claude，并在 7 月初推出了升级版的 Claude 2。在今年上半年，Anthropic 的估值已达到了约 41 亿美元。</span></p><p><img height="277" src="https://oscimg.oschina.net/oscnet/up-cdc73121940d2bf6a2632504928ecf5790a.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Anthropic 的一份<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F04%2F06%2Fanthropics-5b-4-year-plan-to-take-on-openai%2F" target="_blank">内部文件透露</a>，该公司计划筹集 50 亿美元或更多以直接与 OpenAI 较量。并预计花费 10 亿美元，在 2024 年底推出自己的新一代大语言模型「Claude-Next」。</span></p><p><span style="color:#000000">Anthropic 首席执行官兼联合创始人 Dario Amodei 曾在上个月的一次谈话中称，「我们只成立了两年半多一点……在这段时间里，我们已经筹集了 15 亿美元，这是一个很大的数字。我们的团队规模相较来说要小得多，但我们已经成功地保持了自己的地位。我们真正做到了少花钱多办事，我认为很快我们就能用更多的资源做更多的事。」</span></p><p><span style="color:#000000">而除谷歌外，Anthropic 还获得了 Salesforce 和 Zoom 的融资。亚马逊也已经向 Anthropic 投资了 12.5 亿美元；并在 9 月份承诺，后续计划共向 Anthropic 投资高达 40 亿美元。</span></p><p><strong><span style="color:#000000">相关阅读：</span></strong></p><ul><li><a href="https://www.oschina.net/news/232921/claude-ai" target="_blank">Anthropic 推出 「更理性的 Claude」，正面硬刚 ChatGPT</a></li><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/263552/frontier-model-forum-ai-safety" target="_blank">OpenAI、谷歌微软等设立 1000 万美元 AI 安全基金</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 08:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264126/google-invest-2-billion-anthropic</guid>
            <link>https://www.oschina.net/news/264126/google-invest-2-billion-anthropic</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
