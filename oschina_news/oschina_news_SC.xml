<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 26 Jan 2024 05:49:50 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[今天是将 Firefox 设置为默认浏览器的好日子]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>苹果今日<u><a href="https://www.oschina.net/news/276674">宣布</a></u>在在欧盟地区对 iOS、Safari 浏览器和 App Store 进行更改。</p><p>其中 Safari 浏览器在欧盟地区的更改如下：<strong>iOS 用户现在就可以将第三方网络浏览器（而非 Safari 浏览器）设为默认浏览器</strong>。</p><p>Firefox 当即发推表示：「<em>今天是将 Firefox 设置为默认浏览器的好日子<img alt="😎" height="20.39772605895996" src="https://abs-0.twimg.com/emoji/v2/svg/1f60e.svg" style="margin-left:0.075em; margin-right:0.075em" width="20.39772605895996" referrerpolicy="no-referrer">。</em>」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-af61337c299ca89913bc382cdf8e3d8f7e7.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ffirefox%2Fstatus%2F1750252384582803578" target="_blank">https://twitter.com/firefox/status/1750252384582803578</a></u></em></p></blockquote><ul><li>延伸阅读：<em><u><a href="https://www.oschina.net/news/269923/firefox-on-the-brink" target="news">Firefox 会被淘汰吗？</a></u></em></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 04:15:29 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276693</guid>
            <link>https://www.oschina.net/news/276693</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[重庆警方破获「苹果 ID 贷」非法经营案，以「库克回租」为名非法放贷、暴力催收]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thepaper.cn%2FnewsDetail_forward_26150502" target="_blank">据中新网报道</a></u>，重庆巫溪县公安局获悉，该局成功侦破一起全国性「苹果 ID 贷」非法经营案，捣毁涉及 21 省 (市) 非法经营网络贷款犯罪团伙 9 个，抓获犯罪嫌疑人 41 人，涉及借款人员 2 万余名，涉案金额 1.3 亿元。</p><p>2023 年 5 月，重庆巫溪县公安局凤凰派出所接到陶某报警称，自己的苹果手机 (iPhone13) 被人远程控制锁机，请求民警帮助。后经民警综合研判，一个以黄某为首的从事互联网非法放贷犯罪团伙逐渐浮出水面。</p><p>经查，自 2022 年 8 月以来，黄某等 9 人未经监管部门批准，以营利为目的，打着「库克回租」的幌子，通过平台投放「苹果 ID 贷」广告，招揽苹果手机用户并提供贷款，再通过远程控制手机应用，修改苹果 ID 密码，威胁将手机锁机，并以拨打亲属电话骚扰、曝光个人信息等催收方式，让借款人超额还款。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-26b87b238e3799ee00df2fb9ff4bb158c38.png" referrerpolicy="no-referrer"></p></blockquote><p>该团伙累计非法放贷本金 700 余万元，非法获利 100 余万元。掌握相关证据后，专案组民警分赴陕西、四川等地，将该非法经营犯罪团伙成员全部抓获。</p><p>办案民警随后对该案扩线研判出另外 8 个涉及全国 21 省 (市) 与黄某团伙具有相同作案手法的非法经营犯罪团伙，梳理出借款人员 2 万余名。</p><p>巫溪县公安局在重庆市公安局经侦总队指导下，将该案报请公安部，并成功发起全国集群战役，成功打掉利用「苹果 ID 贷」非法经营网络贷款犯罪团伙 9 个，抓获犯罪嫌疑人 41 人，涉案金额 1.3 亿元。</p><p>目前，该案所有犯罪嫌疑人均被依法采取刑事强制措施，案件正在进一步办理中。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 04:03:29 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276691</guid>
            <link>https://www.oschina.net/news/276691</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[升级 JDK21、 Spring Boot 3.2 并开启 Virtual Thread、CRaC]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><div><div><div><div><div><div><div><span id="OSC_h2_1"></span><h2>背景</h2><ul><li><p>JDK21 已发布一段时间，是 JDK17 后的的又一个长期维护版本，支持了 Virtual Thread、CRaC 特性，并带来了新的分代 ZGC 算法</p></li><li><p>Spring Boot 3.2.1 (<span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fblog%2F2023%2F10%2F16%2Fruntime-efficiency-with-spring%2F%23jvm-checkpoint-restore-scale-to-zero-with-spring-and-project-crac" rel="nofollow" target="_blank"><span><span><img height="14" src="https://spring.io/favicon-32x32.png?v=96334d577af708644f6f0495dd1c7bc8" width="14" referrerpolicy="no-referrer"></span><span>Runtime efficiency with Spring (today and tomorrow)</span></span></a></span></span></span></span> ) 版本发布后，框架层面原生的支持了 Virtual Thread、CRaC 特性</p></li></ul><p>同时在 ops-job 上应用积累经验，可在其他项目如 Apollo 、xxljob 上继续落地</p><p>ps：本次升级项目原依赖是 JDK17，Spring Boot 2.6.5&nbsp;</p><span id="OSC_h2_2"></span><h2><span>关键结果（收益）</span></h2><ul><li><p>在不影响程序逻辑情况下，大幅缩短启动时间</p></li><li><p>内存使用降低，性能更好</p></li><li><p>CPU 资源使用率降低（因 GC 导致的 CPU 使用降低）</p></li></ul><span id="OSC_h2_3"></span><h2>升级改动</h2><span id="OSC_h3_4"></span><h3>Maven 依赖调整</h3><p>调整 Spring Boot 的依赖</p><pre><code class="language-xml">  &lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;3.2.1&lt;/version&gt;
    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
  &lt;/parent&gt;</code></pre><p>调整 Spring Cloud 、JDK 的依赖</p><pre><code class="language-xml">  &lt;properties&gt;
    &lt;java.version&gt;21&lt;/java.version&gt;
    &lt;spring-cloud.version&gt;2021.0.1&lt;/spring-cloud.version&gt;
  &lt;/properties&gt;</code></pre><span id="OSC_h3_5"></span><h3>代码兼容性改动</h3><div><div>
            &nbsp; 
          </div><div><p>Spring Boot3 升级是个比较大的变动，有很多的不兼容性。这里只记录 ops-job 这个项目遇到的问题。更多问题参考：<span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-boot%2Fwiki%2FSpring-Boot-3.0-Migration-Guide" rel="nofollow" target="_blank"><span><span><img height="14" src="https://github.com/fluidicon.png" width="14" referrerpolicy="no-referrer"></span><span>Spring Boot 3.0 Migration Guide</span></span></a></span></span></span></span> (<span style="color:var(--custom-palette-color, inherit)">官网升级指南必看</span>)</p></div></div><span id="OSC_h4_6"></span><h4>1、包名变动</h4><p>javax 更名为 jakarta，相关的资源都需要改动。比如：</p><p>@PostConstruct 注解包名拜改变路径：javax.annotation.PostConstruct 变到 jakarta.annotation.PostConstruct</p><span id="OSC_h4_7"></span><h4>2、Spring 的 <code><a href="https://my.oschina.net/bean" class="referer" target="_blank">@Bean</a></code> 注解只能用于有返回值的方法。</h4><p>比如下面代码，想在 Bean 初始化生命周期中运行一些逻辑，升级后就不支持了。被 <code><a href="https://my.oschina.net/bean" class="referer" target="_blank">@Bean</a></code> 注解的方法需要有返回值了</p><pre><code class="language-java">    @Bean
    public void initSenTry() {
        String dsn = xx
        Sentry.init(options -&gt; {
            options.setDsn(dsn);
            options.setEnvironment(env);
        });
        SentryAppender sentryAppender = new SentryAppender();
        sentryAppender.setContext(ctx);
        ThresholdFilter filter = new ThresholdFilter();
        filter.setLevel(Level.ERROR.levelStr);
        filter.start();
        sentryAppender.addFilter(filter);
        sentryAppender.start();
        ctx.addTurboFilter(new TurboFilter() {
            @Override
            public FilterReply decide(Marker marker, ch.qos.logback.classic.Logger logger, Level level, String format, Object[] params, Throwable t) {
                logger.addAppender(sentryAppender);
                return FilterReply.NEUTRAL;
            }
        });

    }</code></pre><span id="OSC_h4_8"></span><h4>3、Spring 日志系统变化</h4><p>slf4j 的 StaticLoggerBinder 类没有了，想要获取 LoggerContext 对象实现日志级别的动态调整，需要使用</p><p>LoggerFactory.getILoggerFactory 取而代之。比如：</p><pre><code class="language-java">private final LoggerContext ctx = (LoggerContext) LoggerFactory.getILoggerFactory();</code></pre><span id="OSC_h4_9"></span><h4>4、Apollo 功能受限</h4><p>Apollo 配置中心的 <code>@ApolloConfig</code> 注解失效了（内部配置加载逻辑是正常的，不影响应用启动）。比如：</p><pre><code class="language-java">@ApolloConfig
private Config config;</code></pre><p>原因是：<span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-boot%2Fissues%2F32566" rel="nofollow" target="_blank"><span><span><img height="14" src="https://github.com/fluidicon.png" width="14" referrerpolicy="no-referrer"></span><span>Spring Boot 3 milestone 5 EnableAutoConfiguration spring.factories · Issue #32566 · spring-projects/spring-boot</span></span></a></span></span></span></span></p><p>从 Spring Boot 3 M5 开始，来自 spring.factories 文件的「org.springframework.boot.autoconfigure.EnableAutoConfiguration」自动配置注册不再起作用</p><p>基于此，预计有很多 start 都会受到影响，比如 mybatis-plus 、xxl-job</p><ul><li>临时解决</li></ul><p>在类路径下创建<code>META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports</code>文件，把 Apollo 的自动加载类放进去，如：</p><pre><code>com.ctrip.framework.apollo.spring.boot.ApolloAutoConfiguration com.taptap.xxl.job.spring.XxlJobAutoConfiguration</code></pre><p>其他有影响的框架，都可以复制下自动加载类，放到这个文件里</p><ul><li>最终解决</li></ul><p>可以尝试用最新版本，看官方是否解决了 Spring Boot3.x 的兼容性问题。</p><p>1、apollo-client : 升级到 2.1.0(<span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapolloconfig%2Fapollo-java%2Fpull%2F4" rel="nofollow" target="_blank"><span><span><img height="14" src="https://github.com/fluidicon.png" width="14" referrerpolicy="no-referrer"></span><span>apollo-client support spring boot 3.0 by nobodyiam · Pull Request #4 · apolloconfig/apollo-java</span></span></a></span></span></span></span> )</p><p>2、xxl-job-spring-boot-starter : 更新到 2.3.2-183</p><span id="OSC_h2_10"></span><h2>问题记录</h2><span id="OSC_h3_11"></span><h3>1、日志框架冲突</h3><p>服务启动，会输出如下的日志</p><pre><code>Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts</code></pre><p>这个是 Spring Boot 的依赖冲突检查输出的，在 Maven 里排除 <code>commons-logging.jar</code> 就好了，如：</p><pre><code class="language-xml">    &lt;dependency&gt;
      &lt;groupId&gt;ru.yandex.clickhouse&lt;/groupId&gt;
      &lt;artifactId&gt;clickhouse-jdbc&lt;/artifactId&gt;
      &lt;version&gt;0.3.2&lt;/version&gt;
      &lt;exclusions&gt;
        &lt;exclusion&gt;
          &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;
          &lt;groupId&gt;commons-logging&lt;/groupId&gt;
        &lt;/exclusion&gt;
      &lt;/exclusions&gt;
    &lt;/dependency&gt;</code></pre><span id="OSC_h3_12"></span><h3>2、Server VM warning</h3><p>当加载 agent 时，会出现如下的警告日志。</p><pre><code>OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
[otel.javaagent 2024-01-23 17:38:45:581 +0800] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: 1.12.1
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended</code></pre><div>
           &nbsp; 
         </div><p>可通过 JVM 参数 -Xshare:off 关闭 CDS 相关的逻辑</p><span id="OSC_h2_13"></span><h2>大功告成</h2><p>如果一切顺利，启动成功后会在控制枱看到如下输出</p><p><img height="540" src="https://oscimg.oschina.net/oscnet/up-c89cbd8949a1c5ef0e8aaeb37dee992e6d8.png" width="1520" referrerpolicy="no-referrer"></p><span id="OSC_h2_14"></span><h2>开启 Virtual Thread</h2><span id="OSC_h3_15"></span><h3>启用并验证</h3><p>通过如下配置，可以一键开启 spring 的 Virtual Thread 特性。</p><pre><code>spring.threads.virtual.enabled=true</code></pre><p>验证是否开启了</p><pre><code class="language-java">@RequestMapping("/")
@RestController
public class VirtualController {

    @GetMapping("/test")
    public String virtual() {
        System.out.println(Thread.currentThread());
        return "test";
    }

}</code></pre><p>上面代码将会在控制枱输出</p><pre><code>VirtualThread[#70,tomcat-handler-0]/runnable@ForkJoinPool-1-worker-1</code></pre><div>
           &nbsp; 
         </div><span id="OSC_h3_16"></span><h3>性能测试</h3><div><div>
            &nbsp; 
          </div><div><p>环境：Redis 为本地的实例</p></div></div><div><div><div><div><pre><code class="language-java">@RequestMapping("/")
@RestController
public class VirtualController {

    final StringRedisTemplate redisTemplate;

    public VirtualController(StringRedisTemplate redisTemplate) {
        this.redisTemplate = redisTemplate;
    }

    @GetMapping("/test")
    public String virtual() {
        redisTemplate.opsForValue().set("test", "test");
        return redisTemplate.opsForValue().get("test");
    }

}</code></pre><p>我在本地通过 wrk 压测上面的代码 (读写了下 Redis )，发现在不做任何参数调优的情况下，结果如下</p></div></div></div></div><p>tomcat 默认的线程池配置：</p><pre><code>server.tomcat.threads.max=200
server.tomcat.threads.min-spare=10</code></pre><ul><li><p>wrk -t80 -c100 -d 10s --latency <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2F127.0.0.1%3A8040%2Ftest" rel="nofollow" target="_blank">http://127.0.0.1:8040/test</a></p></li></ul><div><div><p><img height="454" src="https://oscimg.oschina.net/oscnet/up-778d1c6616698d7fbacd4586940df71a153.png" width="1536" referrerpolicy="no-referrer"></p></div></div><ul><li><p>wrk -t150 -c200 -d 10s --latency <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2F127.0.0.1%3A8040%2Ftest" rel="nofollow" target="_blank">http://127.0.0.1:8040/test</a></p></li></ul><div><div><img height="460" src="https://oscimg.oschina.net/oscnet/up-10c91dde54ae8b0d9f84cda5b35a3f810bb.png" width="1532" referrerpolicy="no-referrer"></div></div><p>从两次测试结果可以看出，在不做任何优化的前提下：</p><div><div>
            &nbsp; 
          </div><div><ul><li><p>低负载（-t80 -c100）：性能相当，差别不大</p></li><li><p>高负载（-t150 -c200）：Virtual threads 依然保持高性能，Platform threads 出现了性能下降的问题。且两者 QPS 差距非常明显，<strong>Virtual threads </strong>比 <strong>Platform threads</strong> 多 19%~29% 的性能。</p></li></ul></div></div><p>在 Platform threads 模式下，尝试调大 tomcat 的线程参数</p><pre><code class="language-java">server.tomcat.threads.max=300
server.tomcat.threads.min-spare=50</code></pre><p>分别使用</p><ul><li><p>wrk -t150 -c200 -d 10s --latency <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2F127.0.0.1%3A8040%2Ftest" rel="nofollow" target="_blank">http://127.0.0.1:8040/test</a></p></li><li><p>wrk -t80 -c100 -d 10s --latency <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2F127.0.0.1%3A8040%2Ftest" rel="nofollow" target="_blank">http://127.0.0.1:8040/test</a></p></li></ul><p>压 Platform threads 的服务。</p><p><img height="458" src="https://oscimg.oschina.net/oscnet/up-e6526d1643da2f8c406ec63b7c228a525c7.png" width="1528" referrerpolicy="no-referrer"></p><div><div><p>从 tomcat 调参后的测试结果看，至少我本地这个环境，这个场景没法在通过加大 threads 数加大性能了。也在一次印证了 Platform threads 模式下，负载高过一个临界值后，性能会下降。</p></div></div><span id="OSC_h3_17"></span><h3>三方测试</h3><ul><li><p>三方测试参考：<span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2Farticle%3Fid%3D89" rel="nofollow" target="_blank"><span><span><img height="14" src="https://tech.dewu.com/favicon.ico" width="14" referrerpolicy="no-referrer"></span><span>虚拟线程原理及性能分析</span></span></a></span></span></span></span></p></li></ul><span id="OSC_h2_18"></span><h2>开启 CRaC</h2><span id="OSC_h3_19"></span><h3>说明（还不成熟）</h3><div><div>
            &nbsp; 
          </div><div><p>CRaC 当前只是初步支持，有些场景：比如内存里维护了复杂状态的应用，可能会遇到问题，启用前请谨慎做好全场景的测试。</p></div></div><p>参考文档：<span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-boot%2Fdocs%2Fcurrent%2Freference%2Fhtmlsingle%2F%23deployment.efficient.checkpoint-restore" rel="nofollow" target="_blank"><span><span><img height="14" src="https://docs.spring.io/favicon.ico" width="14" referrerpolicy="no-referrer"></span><span>Spring Boot Reference Documentation</span></span></a></span></span></span></span> \ <span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-framework%2Freference%2Fintegration%2Fcheckpoint-restore.html" rel="nofollow" target="_blank"><span><span><img height="14" src="https://docs.spring.io/spring-framework/reference/_/img/favicon.ico" width="14" referrerpolicy="no-referrer"></span><span>JVM Checkpoint Restore :: Spring Framework</span></span></a></span></span></span></span></p><span id="OSC_h3_20"></span><h3>启用并验证</h3><span id="OSC_h4_21"></span><h4>集成步骤</h4><ul><li><p>1、JVM 层面（指定内存 dump 路径）：启动时添加 <code>-XX:CRaCCheckpointTo=PATH</code> 参数，指定 CRaC 的输出加载路径</p></li><li><p>2、Spring 层面（找个合适的时机触发内存 dump）：启动时添加 <code>-Dspring.context.checkpoint=onRefresh</code> 参数。该阶段启动时会自动创建检查点<code>LifecycleProcessor.onRefresh</code>。此阶段完成后，所有非延迟初始化的单例都已实例化，并且 <code>InitializingBean#afterPropertiesSet</code>回调已被调用；但生命周期尚未开始，且 <code>ContextRefreshedEvent</code>尚未发布。</p></li><li><p>3、JVM 层面（加载内存恢复状态）：启动时添加 <code>-XX:CRaCRestoreFrom=PATH</code> 参数，指定加载的 CRaC 的路径</p></li></ul><p>从集成步骤看，第 1、2 步应该都发生在 CI 阶段，且 Spring 的触发内存 dump 的意图很明显，等 onRefresh 完成后再出发，相当于初始 Bean 的时间就可以节省出来了。当然还可以使用 jcmd 指令触发 dump，比如：</p><pre><code class="language-bash">jcmd target/example-spring-boot-0.0.1-SNAPSHOT.jar JDK.checkpoint</code></pre><p>这个可以在任意时候触发，这就可以在 dump 前做完所有的预热逻辑，然后 dump 出来的状态就是性能峰值状态了</p><span id="OSC_h4_22"></span><h4>遇到的问题</h4><p><strong>1、JDK 依赖问题</strong></p><p>CRaC 特性依赖 JDK 特性支持，目前 openjdk 发行版只支持到 JDK17：<span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCRaC%2Fopenjdk-builds%2Freleases" rel="nofollow" target="_blank"><span><span><img height="14" src="https://github.com/fluidicon.png" width="14" referrerpolicy="no-referrer"></span><span>Releases · CRaC/openjdk-builds</span></span></a></span></span></span></span> 。如果在不支持的 JDK 下启用 <code>CRaCCheckpointTo</code>，则会输出：</p><pre><code class="language-bash">Unrecognized VM option 'CRaCCheckpointTo'
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.</code></pre><p>CRaC 最早是 Azul 发起的一个项目，可以用 Azul 的社区发行版来验证 CRaC 特性，如：</p><ul><li><span style="background-color:var(--ds--code--bg-color,var(--ds-background-neutral, #F4F5F7)); color:var(--ds-text, #172B4D)"><code class="language-"><span>docker image：azul/zulu-openjdk:21-jdk-crac</span></code></span></li></ul><p><strong>2、GC 算法问题</strong></p><p>ZGC 算法下，不支持 CRaC，在 ZGC 启用时，会输出：</p><pre><code class="language-bash">Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
-XX:+UseZGC is currently unsupported for -XX:CRaCCheckpointTo.</code></pre><p>为了验证 CRaC 功能，只好先移除 <code>-XX:+UseZGC</code></p><p><strong>3、打开的 FD &amp; Socket 问题</strong></p><p>CRaC 要求应用程序关闭所有打开的文件、网络连接等。在 Linux 上，这些内容表示为文件描述符。但是，可能很难更改应用程序以与检查点正确协调，例如，由于无法修改库中的代码。在这些情况下，CRaC 通过配置提供有限的处理。</p><div><div>
            &nbsp; 
          </div><div><p>理论上所有的资源都需要向 JVM 注册资源的 Checkpoint 前后的资源状态，Spring 内置的依赖都处理好了这一步，但是三方依赖，比如 Opentelemetry 、Apollo 等没有做这一步，就会出现一些异常。</p></div></div><ul><li>Opentelemetry 的问题</li></ul><pre><code class="language-java">Suppressed: jdk.internal.crac.mirror.impl.CheckpointOpenFileException: FD fd=35 type=regular path=/tmp/opentelemetry-temp-jars2649059754140254392/jartqV3k80l.jar (deleted)
at java.base/jdk.internal.crac.mirror.Core.translateJVMExceptions(Core.java:114) ~[na:na]
at java.base/jdk.internal.crac.mirror.Core.checkpointRestore1(Core.java:188) ~[na:na]
at java.base/jdk.internal.crac.mirror.Core.checkpointRestore(Core.java:286) ~[na:na]
at java.base/jdk.internal.crac.mirror.Core.checkpointRestore(Core.java:265) ~[na:na]
at jdk.crac/jdk.crac.Core.checkpointRestore(Core.java:72) ~[jdk.crac:na]
at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
at org.crac.Core$Compat.checkpointRestore(Core.java:141) ~[crac-1.4.0.jar!/:na]
... 17 common frames omitted</code></pre><ul><li>Apollo</li></ul><pre><code class="language-java">        Suppressed: java.nio.channels.IllegalSelectorException
                at java.base/sun.nio.ch.EPollSelectorImpl.beforeCheckpoint(EPollSelectorImpl.java:401)
                at java.base/jdk.internal.crac.mirror.impl.AbstractContext.invokeBeforeCheckpoint(AbstractContext.java:43)
                at java.base/jdk.internal.crac.mirror.impl.AbstractContext.beforeCheckpoint(AbstractContext.java:58)
                at java.base/jdk.internal.crac.mirror.impl.BlockingOrderedContext.beforeCheckpoint(BlockingOrderedContext.java:64)
                at java.base/jdk.internal.crac.mirror.impl.AbstractContext.invokeBeforeCheckpoint(AbstractContext.java:43)
                at java.base/jdk.internal.crac.mirror.impl.AbstractContext.beforeCheckpoint(AbstractContext.java:58)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore1(Core.java:153)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore(Core.java:286)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestoreInternal(Core.java:299)
        Suppressed: jdk.internal.crac.mirror.impl.CheckpointOpenSocketException: Socket[addr=apollo-config.dev.tapsvc.com/172.20.12.187,port=80,localport=47004]
                at java.base/jdk.internal.crac.JDKSocketResourceBase.lambda$beforeCheckpoint$0(JDKSocketResourceBase.java:68)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore1(Core.java:169)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore(Core.java:286)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestoreInternal(Core.java:299)</code></pre><p><strong>解决</strong></p><p>可通过 <span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.azul.com%2Fcore%2Fcrac%2Ffd-policies" rel="nofollow" target="_blank"><span><span><img height="14" src="https://docs.azul.com/favicon.webp" width="14" referrerpolicy="no-referrer"></span><span>File Descriptor Policies</span></span></a></span></span></span></span>来有限的处理。</p><p>新建文件 crac.yaml ，配置内容如下：</p><pre><code class="language-xml">type: socket
localAddress: *
action: ignore
---
type: file
path: /opt
action: ignore
---
type: file
path: /tmp
action: ignore
---
type: pipe
action: ignore</code></pre><p>在 Java 应用启动系统参数里设置 -Djdk.crac.resource-policies = /{path}/crac.yaml</p><p><strong>4、遗留的问题</strong></p><p>遗留了一个问题，怎么都处理不了。刚好这个问题我认识的一个好友（Apollo 的作者）也遇到了，issue 如下：</p><ul><li><p><span><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F31680" rel="nofollow" target="_blank"><span><span><img height="14" src="https://github.com/fluidicon.png" width="14" referrerpolicy="no-referrer"></span><span>CheckpointOpenFileException occurred with spring boot log files · Issue #31680 · spring-projects/spring-framework</span></span></a></span></span></span></span></p></li></ul><pre><code class="language-java"> Suppressed: jdk.internal.crac.mirror.impl.CheckpointOpenResourceException: FD fd=12 type=unknown path=anon_inode:[eventpoll]
                at java.base/jdk.internal.crac.mirror.Core.translateJVMExceptions(Core.java:117)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore1(Core.java:188)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore(Core.java:286)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestoreInternal(Core.java:299)
        Suppressed: jdk.internal.crac.mirror.impl.CheckpointOpenResourceException: FD fd=13 type=unknown path=anon_inode:[eventfd]
                at java.base/jdk.internal.crac.mirror.Core.translateJVMExceptions(Core.java:117)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore1(Core.java:188)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestore(Core.java:286)
                at java.base/jdk.internal.crac.mirror.Core.checkpointRestoreInternal(Core.java:299)</code></pre><span id="OSC_h3_23"></span><h3>关于 CRaC 的结论</h3><p>基于如下：</p><ul><li><p>Openjdk 发行版并未全部覆盖支持，目前支持的最高版本是 JDK17。更高版本的支持只能用 Azul 的 JDK</p></li><li><p>当前还有非常多的集成问题，且大量第三方包并没有做适配，Azul 官方给的 resource-policies 解决方案还属于初步阶段</p></li><li><p>Spring Boot 3.2 也是初步支持，Issue 区有大量集成的问题</p></li></ul><p>综上，CRaC 距离生产可用还有很长的路要长，至少，当前解决应用启动问题，预热峰值问题，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.graalvm.org%2F" rel="nofollow" target="_blank">GraalVM</a> 的 Native 方案比 CRaC 要更成熟。当然，未来哪个方向会成为标准还不好说，CRaC 的优势是保留了 JIT 的优化。</p></div></div></div></div></div></div></div></div></div><div><div>
   &nbsp; 
 </div></div></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 03:49:29 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/klblog/blog/10946547</guid>
            <link>https://my.oschina.net/klblog/blog/10946547</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GreatSQL 2023 年报]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>不知不觉 2023 年已经是过去式了，本文将从产品迭代、丰收收获、生态合作、社区活动 4 个方面带大家了解 GreatSQL 社区的 2023。</p><h2>01 产品迭代</h2><p>2023 年是发展的一年。在这一年里，GreatSQL 社区版发布了 3 个版本：8.0.25-17、8.0.32-24 以及 8.0.32-25。在最新发布的 8.0.32-25 版本中，GreatSQL 首次推出支持高性能的内存查询加速 AP 引擎，可将 GreatSQL 的数据分析性能提升几个数量级；同时大幅增加 Oracle 兼容特性，支持更多数据类型、SQL 语法、函数及存储过程等；支持异步删除 InnoDB 大表；支持在 MGR 只读节点绑定动态 VIP 以及主节点切换时主动断开当前连接，缩短应用端不可用时长。</p><p>此外，GreatSQL 8.0.32-25 基于 Percona Server for MySQL 8.0.32 版本，在 MySQL 8.0.32 基础上做了大量的改进和提升以及众多新特性。这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow log 增强等大量改进和提升，这里不一一重复列出。</p><p>GreatSQL 的持续迭代，离不开用户们的反馈与贡献。从 2022 年 8 月社区官网论坛上线，至目前为止，社区已经收到超过 400 个问题讨论，2000 条互动回复。</p><p>对于每位用户来说，文档是使用过程中不可或缺的重要资源。细心的用户可能已经注意到，过去一年中，我们的文档内容也在持续增加和完善。</p><p>在此，我们衷心感谢这一年中为 GreatSQL 项目开发、文档编写以及基础设施进行贡献的伙伴。由于感谢列表过长，详细名单请参见社区文档：致谢（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fdocs%2F8032-25%2Fuser-manual%2F1-docs-intro%2F1-7-thanks.html%EF%BC%89%E3%80%82" target="_blank">https://greatsql.cn/docs/8032-25/user-manual/1-docs-intro/1-7-thanks.html）。</a></p><h2>02 丰收收获</h2><p>2023 年是收获的一年。GreatSQL 开源数据库项目成功捐赠开放原子开源基金会，成为基金会旗下孵化项目。同时，GreatSQL 社区还通过了中国信通院可信开源社区评审，取得了社区运营能力先进级、社区治理和社区开发能力增强级的社区成熟度评估，加入信通院数据库应用创新实验室，成为实验室成员之一。</p><p>在开源社区、开源组织合作上，GreatSQL 与 OpenAnolis、OpenCloudOS 达成社区合作；同时是开源之夏活动合作社区之一。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c3b6f5256bff43f1657324cd690c2f73d00.png" alt="file" referrerpolicy="no-referrer"></p><p>除此之外，GreatSQL 还收获了以下荣誉：</p><ol><li>入选 2023 年中国数据库产业图谱</li><li>开源中国 2023 年度优秀开源技术团队</li><li>开放原子开源基金会 2023 年度快速成长开源项目</li><li>OpenCloudOS 社区 2023 年度优秀贡献企业</li></ol><p><img src="https://oscimg.oschina.net/oscnet/up-eaac4f3e71d2fada057f62b688e93cca9d5.png" alt="file" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-b4b3d4cc5b77a12e4e2a147a0e3f0045957.png" alt="file" referrerpolicy="no-referrer"></p><h2>03 生态合作</h2><p>2023 年是合作的一年。在这一年中，GreatSQL 社区与华为存储、腾讯云、OpenCloudOS 社区、神州数码、软通动力、浪潮卓数、中科海光、中科驭数、中科可控、秦派软件、JumpServer、TOPIAM、ScaleFlux 等 20 余家企业完成产品兼容性测试，为社区用户提供了更便捷的软硬件及应用服务对接。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7fbd9bf9a2a8e6413e5a8651911ff6f7576.png" alt="file" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-83a796aa6732690280492d183b7f9c55472.png" alt="file" referrerpolicy="no-referrer"></p><h2>04 社区活动</h2><p>2023 是互动的一年。在这一年中，社区组织了 10 余个线上论坛互动活动，创建了社区茶话会、社区月会；自建、参加了 20 余场线上直播分享、线下技术沙龙，与墨天轮、3306Π、InfoQ、开源中国、开放原子开源基金会、中国信通院达成了深度合作。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a017eeb32a56e6fb336a19955e7caa9982a.png" alt="file" referrerpolicy="no-referrer"></p><h2>05 展望</h2><p>2024 社区将继续发展，GreatSQL 将继续投入更多的精力开发优化产品，同时，我们也希望能够有更多的外部开发者参与到项目的开发建设中，欢迎大家给 GreatSQL 提 issue、提 pr~</p><p>在每月社区月会的线上分享方面，也期待大家踊跃报名参与线上分享。分享内容是 GreatSQL 相关即可，如有意向可以联系社区小助手哦~（小助手微信：wanlidbc）</p><p>最后，大家对于产品、网站、文档有何建议，欢迎到社区论坛反馈~（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fforum-39-1.html%EF%BC%89" target="_blank">https://greatsql.cn/forum-39-1.html）</a></p><h2>2024 期待更多的人加入 GreatSQL，并肩前行。</h2><p>Enjoy GreatSQL :)</p><h2>关于 GreatSQL</h2><p>GreatSQL 是适用于金融级应用的国内自主开源数据库，具备高性能、高可靠、高易用性、高安全等多个核心特性，可以作为 MySQL 或 Percona Server 的可选替换，用于线上生产环境，且完全免费并兼容 MySQL 或 Percona Server。</p><p>相关链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2F" target="_blank">GreatSQL 社区</a><a href="https://gitee.com/GreatSQL/GreatSQL">Gitee</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreatSQL%2FGreatSQL" target="_blank">GitHub</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F1363850082%2Ffavlist" target="_blank">Bilibili</a></p><h2>GreatSQL 社区：</h2><p><img src="https://oscimg.oschina.net/oscnet/up-98ea3fd53d8ec58d6807ed1d9e70d1217af.png" alt="image" referrerpolicy="no-referrer"></p><p><strong>社区有奖建议反馈：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fthread-54-1-1.html" target="_blank">https://greatsql.cn/thread-54-1-1.html</a></p><p><strong>社区博客有奖征稿详情：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fthread-100-1-1.html" target="_blank">https://greatsql.cn/thread-100-1-1.html</a></p><p>（对文章有疑问或者有独到见解都可以去社区官网提出或分享哦~）</p><h2>技术交流群：</h2><p>微信&amp;QQ 群：</p><p>QQ 群：533341697</p><p>微信群：添加 GreatSQL 社区助手（微信号：<code>wanlidbc</code> ）好友，待社区助手拉您进群。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 03:47:29 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/GreatSQL/blog/10946645</guid>
            <link>https://my.oschina.net/GreatSQL/blog/10946645</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Deno 1.4 正式发布，新增 Temporal API]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Deno 1.40 已正式发布，新版本包含了大量增强 Deno 体验的功能，引入了用于高级日期和时间操作的强大的 Temporal API，并采用了最新的装饰器语法，使代码更具表现力。在取得这些进步的同时，还实施了一系列弃用、稳定和删除措施，旨在简化 Deno 的功能并为 Deno 2 做好准备。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6569c160926801e26123b213e2088ef4952.png" referrerpolicy="no-referrer"></p><p>新功能概览：</p><ul><li><p><code>Temporal</code>API</p></li><li><p><code>import.meta.filename</code>和<code>import.meta.dirname</code></p></li><li><p>装饰器</p></li><li><p>简化<code>deno.json</code>中的导入</p></li><li><p>停用、稳定和删除</p></li><li><p>Web API：<code>rejectionhandled</code>事件</p></li><li><p>WebGPU 窗口/"自带窗口"</p></li><li><p>Node.js 兼容性改进，API 更新</p></li><li><p>LSP 改进</p></li><li><p>更美观的诊断程序</p></li><li><p><code>deno lint</code>更新</p></li><li><p>更改处理不稳定功能的方式</p></li></ul><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeno.com%2Fblog%2Fv1.40" target="_blank"><strong>详情</strong></a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 03:40:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276687/deno-1-40-released</guid>
            <link>https://www.oschina.net/news/276687/deno-1-40-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JavaScript 运行时 Bun 引入新工具：Bun Shell]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，Bun 开发团队宣布推出新工具：<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbun.sh%2Fblog%2Fthe-bun-shell" target="_blank">Bun Shell</a></u></strong>。Bun Shell 是 Bun 新引入的实验性嵌入式语言和解释器，支持在 JavaScript 和 TypeScript 中运行跨平台 Shell 脚本，不需要额外的转换和打包。</p><p>在 Bun Shell 中，所有模板变量都会自动「逃逸」 (Escape)，以增加 Shell 指令执行的安全性。另外，诸如通配符、重定向、管道命令 (Pipe)、环境变量等常见 Shell 功能，Bun Shell 也一应俱全。</p><blockquote><p>Bun 是速度极快的 JavaScript 运行时，采用 Zig 编写，集打包器、转译器和包管理器于一身。</p><p><img height="538" src="https://static.oschina.net/uploads/space/2024/0126/110818_6mK2_2720166.png" width="1430" referrerpolicy="no-referrer"></p></blockquote><p>团队称 Bun Shell 旨在解决在 JavaScript 中执行 Shell 困难的问题，其简单直观，具有丰富的功能，支持在 Windows、macOS 和 Linux 跨平台上使用。</p><p>开发者如果在 JavaScript 执行 Shell 指令，首先会遇到跨平台兼容性问题，因为不同的操作系统具有不同的 Shell 环境和指令，因此即便是相同的 Shell 指令，在不同的操作系统上的结果也可能不同，甚至特定指令在部分系统上不存在。</p><p>而且不同的操作系统设置环境变量的方式也不同，这增加了跨平台应用中管理环境变量的复杂性。启动 Shell 程序还会增加额外的系统资源消耗，尤其是需要执行多个 Shell 指令的场景，在特定情况下，启动 Shell 的时间甚至可能比执行指令本身还久。</p><p>基于此背景，Bun 开发团队推出了 Bun Shell 工具，旨在为开发者提供更高效的跨平台解决方案。&nbsp;Bun Shell 作为 Bun JavaScript 执行环境的一部分，提供了跨平台执行 Shell 指令的新方法。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 03:19:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276685/bun-shell</guid>
            <link>https://www.oschina.net/news/276685/bun-shell</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Vulkan 2024 路线图发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Khronos Group <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.khronos.org%2Fnews%2Fpress%2Fkhronos-drives-industry-support-for-expanded-3d-features-with-vulkan-roadmap-2024" target="_blank">宣布</a>了跨平台 3D 图形和计算 API 项目 Vulkan 的 Roadmap 2024&nbsp;里程碑，作为其最新 API 功能的规范。定义了一套重要的着色器和光栅化功能，游戏和应用程序开发人员可以依靠这些功能从 2024 年开始在中高端 GPU 上获得广泛支持。</p><p>Vulkan 路线图的目标市场是由中高端智能手机、平板电脑、笔记本电脑、游戏机和台式机组成的"immersive graphics"市场。该路线图规范为目标设备提供了<span style="background-color:#ffffff; color:#333333">显着的功能增强</span>，并设定了 API 的发展方向，包括<span style="background-color:#ffffff; color:#333333">为 Vulkan 开发人员提供新的硬件功能和编程模型的改进</span>。</p><p><span style="background-color:#ffffff; color:#333333">Vulkan 路线图 2024 是 Vulkan 路线图的第二个里程碑版本，</span><span style="background-color:#ffffff; color:#121212">基于 Vulkan 1.3 和 Vulkan 路线图 2022 规范构建；包括新的扩展、</span><span style="background-color:#ffffff; color:#333333">对许多以前可选功能的强制支持以及最低硬件功能的增加：</span></p><ul><li><strong><span style="background-color:#ffffff; color:#333333">Dynamic Rendering Local Read</span>：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.vulkan.org%2Fspec%2Flatest%2Fproposals%2Fproposals%2FVK_KHR_dynamic_rendering_local_read.html" target="_blank">VK_KHR_dynamic_rendering_local_read</a>&nbsp;扩展添加了对动态渲染的帧缓冲区本地依赖性的支持，允许开发人员完全转向在所有 GPU 上进行动态渲染。查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.khronos.org%2Fblog%2Fstreamlining-subpasses" target="_blank">博客文章</a>了解详细信息。</li><li><strong>Shader Maximal Reconvergence：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.vulkan.org%2Fspec%2Flatest%2Fproposals%2Fproposals%2FVK_KHR_shader_maximal_reconvergence.html" target="_blank">VK_KHR_shader_maximal_reconvergence</a>&nbsp;扩展定义了着色器中线程发散的直观行为，从而能够开发高级并行算法。&nbsp;</li><li><strong>Shader Quad Control：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.vulkan.org%2Fspec%2Flatest%2Fproposals%2Fproposals%2FVK_KHR_shader_quad_control.html" target="_blank">VK_KHR_shader_quad_control</a>&nbsp;扩展定义了控制流中的增强纹理操作，从而提高了性能和质量。更多详细信息可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.khronos.org%2Fblog%2Fkhronos-releases-maximal-reconvergence-and-quad-control-extensions-for-vulkan-and-spir-v" target="_blank">博客。</a></li><li><strong>其他功能：</strong>Vulkan Roadmap 2024 里程碑还要求支持 shader half-float 和 8/16 位整数类型、multi-draw indirect、着色器绘制参数、push descriptors，以及增加到 7 个 Descriptor Sets 和 8 个 Color Attachments。</li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span style="color:#333333"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>对这些新扩展的支持将包含在下一个 Vulkan SDK 版本中。大多数支持 Vulkan Roadmap 2024 里程碑的 Vulkan 采用者预计将从 2024 年开始提供符合要求的产品。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>其他新扩展包括 VK_KHR_shader_subgroup_rotate、VK_KHR_shader_expect_assume 和 VK_KHR_shader_float_controls2。此外，VK_KHR_index_type_uint8、VK_KHR_line_rasterization 和 VK_KHR_load_store_op_none 扩展也从以前的"EXT"扩展升级到了 Khronos (KHR)。</p><p><img height="298" src="https://oscimg.oschina.net/oscnet/up-aaa27db5446559e0346e8725c26684b620b.png" width="500" referrerpolicy="no-referrer"></p><p>Vulkan 路线图规范是对 Vulkan 核心规范的补充，它确定了在特定细分市场中逐渐得到广泛支持的功能，并为实施定义了额外的最低限制，以减少碎片化。</p><p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.khronos.org%2Fnews%2Fpress%2Fkhronos-drives-industry-support-for-expanded-3d-features-with-vulkan-roadmap-2024" target="_blank">查看官方公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 03:17:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276684/vulkan-roadmap-2024</guid>
            <link>https://www.oschina.net/news/276684/vulkan-roadmap-2024</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果在欧盟地区放开对浏览器和应用商店的限制]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">1 月 25 日，苹果<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com.cn%2Fnewsroom%2F2024%2F01%2Fapple-announces-changes-to-ios-safari-and-the-app-store-in-the-european-union%2F" target="_blank">发布官方新闻稿</a></u>，宣布在欧盟地区对 iOS、Safari 浏览器和 App Store 进行更改。这些更改包括 600 多个新 API、拓展的 app 分析、<strong>支持替代浏览器引擎的功能</strong>，以及<strong>处理 app 支付和发行 iOS app 的新选项</strong>。</p><p>具体来说，iOS 在欧盟地区将发生的更改包括：</p><ul><li><p><strong>通过替代 app 市场发行 iOS app 的新选项</strong>——包括新的 API 和工具，使开发者能在 App Store 以外的 app 市场提供 iOS app 供用户下载。</p></li><li><p><strong>创建替代 app 市场的新框架和 API</strong>——使市场开发者能够代表其他开发者通过其专门的市场 app 来安装 app 并管理更新。</p></li><li><p><strong>替代浏览器引擎的新框架和 API</strong>——使开发者能够使用 WebKit 之外的浏览器引擎，提供浏览器 app 和包括 app 内浏览体验的 app。</p></li><li><p><strong>互操作性申请表</strong>——开发者可以提交额外申请，以实现 iPhone 和 iOS 软硬件功能的互操作性。</p></li></ul><p>Safari 浏览器在欧盟地区的更改如下：iOS 用户现在就可以将第三方网络浏览器（而非 Safari 浏览器）设为默认浏览器。按照 DMA 的规定，Apple 还将推出新的选择界面，用户在 iOS 17.4 或后续版本中首次打开 Safari 浏览器时将显示新的可选界面。这个界面将提示欧盟用户从选项列表中选择默认浏览器。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5f9b12adb84f5c3b5de102d8b1f5e146bb5.png" referrerpolicy="no-referrer"></p><p>最后是关于 App Store 的更改。这涉及在欧盟地区发行 app 的开发者，对 iOS、iPadOS、macOS、watchOS 和 tvOS 等 Apple 操作系统的 app 构成影响。这些更改还包括新的信息披露，告知欧盟用户使用 App Store 安全支付处理之外的替代方式可能带来的相关风险。</p><p><img src="https://oscimg.oschina.net/oscnet/up-730b6de9add6449d08aafe3f6f9724444ea.png" referrerpolicy="no-referrer"></p><p>苹果还共享了面向在欧盟地区发行 app 的开发者的新业务条款。开发者可选择采用这些新业务条款，或者保持 Apple 现有的条款。<strong>开发者如需在欧盟发行的 app 中使用替代发行或替代支付处理的新功能，则必须采用这些新业务条款</strong>。</p><p>欧盟地区 iOS app 的新业务条款包括三个要素：</p><ul><li><p><strong>降低的手续费</strong>——通过 App Store 发行的 iOS app 为数字商品和服务交易支付的手续费降低为 10 %（适用于绝大多数开发者及首年后的订阅）或 17%。</p></li><li><p><strong>支付处理使用费</strong>——通过 App Store 发行的 iOS app 另行支付 3% 的手续费后，可使用 App Store 的支付处理功能。开发者可在其 app 内使用支付服务提供商，或通过链接引导用户访问其网站以处理支付，无需向 Apple 支付额外费用。</p></li><li><p><strong>核心技术使用费</strong>——通过 App Store 和/或其他 app 市场发行的 iOS app 安装量超过 100 万次后，须每年为每首次安装支付 €0.50。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5056c6b387dfceea303badd372714a1c904.png" referrerpolicy="no-referrer"></p><p>对于在欧盟发行的 iPadOS、macOS、watchOS 和 tvOS app，开发者如使用 PSP 处理支付或通过链接将用户引导至其网站进行支付处理，其支付给 Apple 的手续费将享受 3% 的折扣。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 02:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276674</guid>
            <link>https://www.oschina.net/news/276674</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年我国软件业务收入 123258 亿元，同比增长 13.4%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">工信部<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fgxsj%2Ftjfx%2Frjy%2Fart%2F2024%2Fart_5af672124ebc48149d9c793b6ca7ed79.html" target="_blank">发布</a>了「</span>2023 年软件业经济运行情况<span style="background-color:#ffffff; color:#222222">」指出，</span><span style="color:#070707">2023 年，我国软件和信息技术服务业（下称「软件业」）运行稳步向好，软件业务收入高速增长，盈利能力保持稳定，软件业务出口小幅回落。</span></p><h4><strong>一、总体运行情况</strong></h4><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>软件业务收入高速增长。</strong>2023 年，全国软件和信息技术服务业规模以上企业超 3.8 万家，累计完成软件业务收入 123258 亿元，同比增长 13.4%，增速较上年同期提高 2.2 个百分点。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><img height="234" src="https://oscimg.oschina.net/oscnet/up-1b97b22cee91cda6a3f540dd959411d3e79.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>盈利能力保持稳定。</strong>2023 年，软件业利润总额 14591 亿元，同比增长 13.6%，增速较上年同期提高 7.9 个百分点，主营业务利润率提高 0.1 个百分点至 9.2%。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><img height="246" src="https://oscimg.oschina.net/oscnet/up-f15afaf046e89fcb3cfd28a5311c2507a21.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>软件业务出口小幅下滑。</strong>2023 年，软件业务出口 514.2 亿美元，同比下降 3.6%。其中，软件外包服务出口同比增长 5.4%。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><img height="258" src="https://oscimg.oschina.net/oscnet/up-4f0dcd7f0c918ddcfde0f9cdaa78acfd5cd.png" width="500" referrerpolicy="no-referrer"></p><h4><strong>二、分领域情况</strong></h4><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>软件产品收入平稳增长。</strong>2023 年，软件产品收入 29030 亿元，同比增长 11.1%，增速较上年同期提高 1.2 个百分点，占全行业收入比重为 23.6%。其中，工业软件产品实现收入 2824 亿元，同比增长 12.3%。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>信息技术服务收入较快增长。</strong>2023 年，信息技术服务收入 81226 亿元，同比增长 14.7%，高出全行业整体水平 1.3 个百分点，占全行业收入比重为 65.9%。其中，云服务、大数据服务共实现收入 12470 亿元，同比增长 15.4%，占信息技术服务收入的 15.4%，占比较上年同期提高 0.5 个百分点；集成电路设计收入 3069 亿元，同比增长 6.4%；电子商务平台技术服务收入 11789 亿元，同比增长 9.6%。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>信息安全产品和服务收入稳步增长。</strong>2023 年，信息安全产品和服务收入 2232 亿元，同比增长 12.4%，增速较上年同期提高 2.0 个百分点。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>嵌入式系统软件收入两位数增长。</strong>2023 年，嵌入式系统软件收入 10770 亿元，同比增长 10.6%，增速较上年同期回落 0.7 个百分点。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><img height="281" src="https://oscimg.oschina.net/oscnet/up-1d99c080b597f4b24191920bde6400d2883.png" width="500" referrerpolicy="no-referrer"></p><h4><strong>三、分地区情况</strong></h4><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>东部、东北地区保持较快增长，中部地区增势突出。</strong>2023 年，东部、中部、西部和东北地区分别完成软件业务收入 100783 亿元、6965 亿元、12626 亿元和 2884 亿元，分别同比增长 13.8%、17.4%、8.7% 和 13.9%。其中，东部、中部、东北部地区高出全国平均水平 0.4、4.0、0.5 个百分点。四个地区软件业务收入在全国总收入中的占比分别为 81.8%、5.7%、10.2% 和 2.3%。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><img height="241" src="https://oscimg.oschina.net/oscnet/up-0f77a3ad2e52d1aced3eeabe74eae297d32.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>京津冀地区增势突出，长三角地区稳中有升。</strong>2023 年，京津冀地区完成软件业务收入 29827 亿元，同比增长 17.1%，高出全国平均水平 3.7 个百分点；长三角地区完成软件业务收入 35437 亿元，同比增长 10.6%，增速上年同期提高 2.5 个百分点。两个地区软件业务收入在全国总收入中的占比分别为 24.2%、28.7%。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>主要软件大省收入占比小幅提高，部分中西部省市增速亮眼。</strong>2023 年，软件业务收入居前 5 名的北京、广东、江苏、山东、上海共完成收入 85135 亿元，占全国软件业比重的 69.1%，占比较上年同期提高 1.1 个百分点。软件业务收入增速高于全国整体水平的省市有 13 个，其中增速高于 20% 的省份集中在中西部地区，包括内蒙古、安徽、青海等。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><img height="253" src="https://oscimg.oschina.net/oscnet/up-8ff7d9c36aee2b9e76bfaab64e8ca01c0fb.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><strong>中心城市软件业务收入稳步增长，利润总额增速大幅提高。</strong>2023 年，全国 15 个副省级中心城市实现软件业务收入 59604 亿元，同比增长 11.2%，增速较上年同期提高 1.2 个百分点，占全国软件业的比重为 48.4%；实现利润总额 7936 亿元，同比增长 15.6%，增速较上年同期提高 13.2 个百分点。其中，哈尔滨、武汉、大连、深圳、济南、青岛、厦门和沈阳软件业务收入同比增速超过全行业整体水平。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left"><img height="321" src="https://oscimg.oschina.net/oscnet/up-45bf8cc440d9477f4ba12755cfa3e1612e4.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left">注：1.文中 2023 年数据均为快报数据，其他年份数据为年报数据。</p><p style="color:#070707; margin-left:0; margin-right:0; text-align:left">　　2.文中增速均按可比口径计算。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 02:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276673</guid>
            <link>https://www.oschina.net/news/276673</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[淘宝启动鸿蒙原生应用开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>华为终端云服务微博发布消息称，淘宝正式启动鸿蒙原生应用开发。</p><blockquote><p><span style="color:#000000">官宣！淘宝正式启动鸿蒙原生应用开发，鸿蒙生态电商领域版图进一步壮大<img alt="[送花花]" height="18" src="https://face.t.sinajs.cn/t4/appstyle/expression/ext/normal/cb/2022_Flowers_org.png" width="18" referrerpolicy="no-referrer">作为国内头部电商平台，淘宝将基于 HarmonyOS NEXT 鸿蒙星河版，为消费者打造原生精致、原生易用、原生流畅、原生安全、原生智能、原生互联的全场景购物新体验，也为千万淘宝商家带来更多商机。双方的合作，将为电商行业带来更广阔的发展空间和机遇，加速行业奔赴全场景新未来！</span></p></blockquote><p><img height="250" src="https://oscimg.oschina.net/oscnet/up-1ec21c934f03bfea3623ef0fb104247fd6c.png" width="500" referrerpolicy="no-referrer"></p><p>目前，京东、支付宝、钉钉等头部应用均已启动鸿蒙原生应用开发。据华为此前介绍，已有超 200 家头部应用加速鸿蒙原生开发，原生应用版图成型。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 02:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276671</guid>
            <link>https://www.oschina.net/news/276671</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Lan Mouse —— 键鼠共享软件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Lan Mouse 是一款类似于苹果设备上的万能控制的键鼠共享软件。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>它允许用一套鼠标和键盘使用多台电脑。它也被称为软件 KVM 切换器。</p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>主要目标是 Linux 上的 Wayland，但 Windows 和 MacOS 以及 Xorg 上的 Linux 也有部分支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>目前已经有了 gtk 前端</li></ul><p><img alt="" height="416" src="https://static.oschina.net/uploads/space/2024/0103/171926_Xa22_4252687.png" width="300" referrerpolicy="no-referrer"></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>该项目的目标是成为 Synergy 2/3、Share Mouse&nbsp;等专有工具的开源替代品。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start">重点在于性能和简洁、易于管理的实现，并可轻松扩展以支持其他后端，如 Android、iOS......。</p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><strong>极快，</strong>因为它是用 Rust 编写的。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 02:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/lan-mouse</guid>
            <link>https://www.oschina.net/p/lan-mouse</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 管理与大模型的对话和提示历史 DevChat]]>
            </title>
            <description>
                <![CDATA[<div align="center"><p><img src="https://github.com/devchat-ai/devchat/assets/592493/f39979fe-fe32-410b-bf9d-2118ac8ea3d5" alt="devchat" referrerpolicy="no-referrer"></p><h1><a id="user-content-devchat" class="anchor" href="https://gitee.com/devchat-ai/devchat#devchat"></a>DevChat</h1></div><p>👉 For an enhanced experience and UI, we welcome you to install <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdevchat-ai%2Fdevchat-vscode">Visual Studio Code extension</a> from <a href="https://gitee.com/link?target=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3Dmerico.devchat">Visual Studio Marketplace</a>! Enjoy DevChat VSCode! 👏</p><div align="center"><p><a href="https://gitee.com/link?target=http%3A%2F%2Fmakeapullrequest.com"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fcircleci.com%2Fgh%2Fdevchat-ai%2Fdevchat%2Ftree%2Fmain"><img src="https://circleci.com/gh/devchat-ai/devchat/tree/main.svg?style=shield" alt="CircleCI" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdevchat-ai%2Fdevchat%2Fblob%2Fmain%2FLICENSE"><img src="https://img.shields.io/github/license/devchat-ai/devchat.svg" alt="GitHub license" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fpepy.tech%2Fproject%2Fdevchat"><img src="https://pepy.tech/badge/devchat" alt="Downloads" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fbadge.fury.io%2Fpy%2Fdevchat"><img src="https://badge.fury.io/py/devchat.svg" alt="PyPI version" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fdiscord.gg%2F9t3yrbBUXD"><img src="https://img.shields.io/discord/1106908489114206309?logo=discord" alt="Discord Chat" referrerpolicy="no-referrer"></a></p><p><strong>The AI Coding Assistant Made Effective by Manual Control</strong></p><p>🛠️ No excessive automation, just right AI where it works.</p><p>☕ Simple to use, without complicated prompt engineering.</p><p>🍻 Designed for extensibility.</p></div><h2><a id="user-content-what-is-devchat" class="anchor" href="https://gitee.com/devchat-ai/devchat#what-is-devchat"></a>What is DevChat?</h2><p>DevChat is an open-source platform that empowers developers to more effectively integrate AI into code generation and documentation. DevChat aims to go beyond simple code auto-completion and limited operations on code snippets. DevChat offers a highly <em>practical</em> and <em>effective</em> way for developers to interact and collaborate with large language models (LLMs).</p><h2><a id="user-content-why-devchat" class="anchor" href="https://gitee.com/devchat-ai/devchat#why-devchat"></a>Why DevChat?</h2><p>While there are many AI coding tools available, we developed DevChat based on our practical insights from generating tens of thousands of lines of code. DevChat makes the following distinctive design choices:</p><ul><li><strong>Precise manual control over the context embedded in a prompt</strong>. Precise control over context is the key to effective AI use. We find that most other "intelligent" or "automatic" tools tend to over-guess what a user needs to put into a prompt. That typically introduces more noise than LLMs can effectively manage.</li><li><strong>A simple, extensible prompt directory</strong>. Bring your own prompts, and build a library of what works for you and your team. Easily integrate your own prompt templates into DevChat, avoiding significant engineering effort or a steep learning curve. You don't need a complex framework to make AI work for you. All it takes is a standard editor operating on your filesystem.</li></ul><h2><a id="user-content-feature-overview" class="anchor" href="https://gitee.com/devchat-ai/devchat#feature-overview"></a>Feature Overview</h2><h3><a id="user-content-context-building" class="anchor" href="https://gitee.com/devchat-ai/devchat#context-building"></a>Context Building</h3><p>Great output requires great input. To maximize the power of AI, DevChat assists you seamlessly to <strong>provide the right context</strong> to the AI.</p><ul><li><p>For instance, to generate test cases for a function, you can add to the prompt the function along with an existing test case. The test case serves as a useful reference for DevChat, enabling it to understand how to write a valid test case specific to your environment, thus eliminating the need for you to specify every requirement in your prompt.</p><p><img src="https://github.com/devchat-ai/devchat-vscode/assets/592493/9b19c798-d06f-4373-8f8a-6a950c3a8ba5" alt="Add to context" referrerpolicy="no-referrer"></p></li><li><p>You can incorporate the output of any command, such as <code>tree ./src</code>, into a prompt with DevChat. For example, you can add the output of <code>git diff --cached</code> to DevChat, which can then generate a commit message for you.</p><p><img src="https://github.com/devchat-ai/devchat-vscode/assets/592493/7bd34547-762c-4f97-b792-8d05a9eb1dcf" alt="Generate a commit message" referrerpolicy="no-referrer"></p></li><li><p>Program analysis can assist in building the necessary context. Suppose you want DevChat to explain some code to you. DevChat can perform better if it's aware of the dependent functions that the code is calling. In this scenario, you can select the target code with DevChat to explain and add "symbol definitions" to the context (by clicking the plus button). DevChat will then generate a prompt that explains the target code, taking into account the dependent functions.</p></li></ul><h3><a id="user-content-prompt-extension" class="anchor" href="https://gitee.com/devchat-ai/devchat#prompt-extension"></a>Prompt Extension</h3><p>DevChat utilizes a directory to manage predefined prompt templates. You can easily add your own or modify existing ones using a text editor.
By default, the directory is named <code>workflows</code> and located in the <code>.chat</code> folder at your home directory. You can run <code>ls ~/.chat/workflows</code> in a terminal to see what's inside.</p><p>The <code>workflows</code> directory typically contains three subdirectories, <code>sys</code>, <code>org</code>, and <code>usr</code>. The <code>sys</code> (system) directory is a clone of <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdevchat-ai%2Fworkflows">https://github.com/devchat-ai/workflows</a>, which contains the default prompt templates. You can overwrite those system prompts. For instance, if you create <code>commit_message</code> in the <code>usr</code> directory and define your own <code>prompt.txt</code>, DevChat will use your version instead of the default in <code>sys</code> or <code>org</code>.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">workflows</span><span id="LC2" class="line">├── sys</span><span id="LC3" class="line">│   └── commit_message</span><span id="LC4" class="line">│       └── prompt.txt</span><span id="LC5" class="line">├── org</span><span id="LC6" class="line">│   └── commit_message</span><span id="LC7" class="line">│       └── prompt.txt</span><span id="LC8" class="line">└── usr</span><span id="LC9" class="line">    └── commit_message</span><span id="LC10" class="line">        └── prompt.txt</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>The <code>org</code> directory is useful for cleanly maintaining team-wise conventions or requirements. Your team can share a Git repository to store prompts in <code>org</code>, and every team member can locally sync <code>~/.chat/workflows/org</code> with the repository. The <code>org</code> prompts will overwrite those in <code>sys</code>, while an individual developer can then further customize them in <code>usr</code>.</p><p>You can incorporate a template in your prompt by typing a "command" with the corresponding name in the DevChat input. Type <code>/</code> followed by the command name, as shown below. The <code>/</code>-separated path to the prompt directory corresponds to a <code>.</code>-separated command name. For instance, if you want to embed the 'prompt.txt' file located in <code>path/to/dir</code> into your current prompt, you should type <code>/path.to.dir</code> into the DevChat input field, along with the other content of the prompt. Note that <code>sys</code>, <code>org</code>, or <code>usr</code> do not need to be included in a command name. DevChat will first look up the corresponding path under <code>usr</code>, then <code>org</code>, and finally <code>sys</code>.</p><img width="386" alt="image" src="https://github.com/devchat-ai/devchat-vscode/assets/592493/145d94eb-a3e8-42ca-bb88-a462b6070b2f" referrerpolicy="no-referrer"><h2><a id="user-content-quick-start" class="anchor" href="https://gitee.com/devchat-ai/devchat#quick-start"></a>Quick Start</h2><p><strong>For UI, install our <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdevchat-ai%2Fdevchat-vscode">Visual Studio Code extension</a> from <a href="https://gitee.com/link?target=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3Dmerico.devchat">Visual Studio Marketplace</a>. Read <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdevchat-ai%2Fdevchat-vscode%23quick-start">Quick Start</a> for the VS Code extension.</strong></p><p>For CLI:</p><ul><li>Install Python 3.8+ and <a href="https://gitee.com/link?target=https%3A%2F%2Fpip.pypa.io%2Fen%2Fstable%2Finstallation%2F">pip</a>.</li><li>Install DevChat by running: <code>pip install devchat</code>.</li><li>Set your <a href="https://gitee.com/link?target=https%3A%2F%2Fplatform.openai.com%2Faccount%2Fapi-keys">OpenAI API Key</a> by running <code>export OPENAI_API_KEY="[sk-...]"</code> (or DevChat access key).</li><li>To access help, use the command: <code>devchat --help</code> or <code>devchat prompt --help</code>.</li></ul><h2><a id="user-content-community" class="anchor" href="https://gitee.com/devchat-ai/devchat#community"></a>Community</h2><ul><li>Join our <a href="https://gitee.com/link?target=https%3A%2F%2Fdiscord.gg%2F9t3yrbBUXD">Discord</a>!</li><li>Participate in <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdevchat-ai%2Fdevchat%2Fdiscussions">discussions</a>!</li></ul><h2><a id="user-content-what-is-prompt-centric-software-development-pcsd" class="anchor" href="https://gitee.com/devchat-ai/devchat#what-is-prompt-centric-software-development-pcsd"></a>What is Prompt-Centric Software Development (PCSD)?</h2><ul><li><p>The traditional code-centric paradigm is evolving. Stay ahead of the curve with DevChat.</p></li><li><p>Write prompts to create code. Transform prompts into all the artifacts in software engineering.</p><img width="600" alt="image" src="https://github.com/devchat-ai/devchat/assets/592493/dd32e900-92fd-4fa4-8489-96ed17ab5e0e" referrerpolicy="no-referrer"><p><sub>(This image is licensed by devchat.ai under a <a rel="license" href="https://gitee.com/link?target=http%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby-sa%2F4.0%2F">Creative Commons Attribution-ShareAlike 4.0 International License</a>.)</sub></p></li><li><p>We like to call it DevPromptOps</p><img width="500" alt="image" src="https://github.com/devchat-ai/devchat/assets/592493/e8e1215b-53b0-4473-ab00-0665d33f204a" referrerpolicy="no-referrer"><p><sub>(This image is licensed by devchat.ai under a <a rel="license" href="https://gitee.com/link?target=http%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby-sa%2F4.0%2F">Creative Commons Attribution-ShareAlike 4.0 International License</a>.)</sub></p></li></ul><h2><a id="user-content-contributing" class="anchor" href="https://gitee.com/devchat-ai/devchat#contributing"></a>Contributing</h2><p>Issues and pull request are welcome: <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdevchat-ai%2Fdevchat%2Fissues">https://github.com/devchat-ai/devchat/issues</a></p><h2><a id="user-content-contact" class="anchor" href="https://gitee.com/devchat-ai/devchat#contact"></a>Contact</h2><p>Email: <a href="mailto:hello@devchat.ai">hello@devchat.ai</a></p><p>We are creators of <a href="https://gitee.com/link?target=https%3A%2F%2Fdevlake.apache.org%2F">Apache DevLake</a>.</p>]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/devchat-ai/devchat</guid>
            <link>https://gitee.com/devchat-ai/devchat</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 小红书如何做混部？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><em>作者：宋泽辉（小红书）、张佐玮（阿里云）</em></p><p><strong>编者按：</strong></p><p>Koordinator 是一个开源项目，是基于阿里巴巴内部多年容器调度、混部实践经验孵化诞生，是行业首个生产可用、面向大规模场景的开源混部系统，致力于提升应用服务质量，优化资源使用效率。自 2022 年 4 月正式开源以来，吸引了业界众多优秀工程师的贡献参与和讨论。</p><p>小红书是 Koordinator 社区的活跃成员，自项目诞生初期就深度参与了一系列重要功能的演进。</p><h2>背景介绍</h2><p>随着小红书业务的高速发展，各类在线、离线业务对于计算资源的需求也在快速增长。与此同时，部分在线集群天均利用率水位却维持在较低水平，造成这一现象的主要原因有以下几点：</p><ul><li>在线服务资源使用量随着终端用户的使用习惯呈现稳定的潮汐现象，夜间 CPU 利用率极低，导致集群均值 CPU 利用率较低；</li><li>业务保有大量的独占资源池，资源池割裂产生大量的资源碎片，拉低 CPU 利用率；</li><li>业务为了稳定性考虑，会过量囤积资源，进一步拉低 CPU 利用率。</li></ul><p>基于以上背景，为了帮助业务降低资源使用成本，提升集群 CPU 利用率，小红书容器团队从 2022 年开始，通过规模化落地混部技术来大幅提升集群资源效能，降低业务资源成本。</p><h2>技术演进</h2><p>小红书混部技术演进分为以下四个阶段：</p><p><img src="https://oscimg.oschina.net/oscnet/up-b59b9a7f8d0367a4eda12acbb9c3b203f73.png" alt="" referrerpolicy="no-referrer"></p><h3>阶段一：闲置资源再利用</h3><p>早期集群资源管理粗放，集群中存在大量业务独占资源池，因为资源碎片等因素存在大量低分配率的低效节点，散落在各个集群中的低效节点形成大量资源浪费。另一方面，部分基于 K8s 发布的转码类近线/离线场景，全天时段均存在大量计算资源需求。</p><p>基于以上背景，容器平台通过技术手段将集群中的闲置资源收集起来，分配给转码类业务场景使用。</p><p>我们通过 virtual-kubelet 打通元数据集群与物理集群，将闲置资源汇聚起来，在元数据集群分配给转码类场景近线/离线计算服务。策略方面，二次调度器负责巡检集群所有节点，识别为低效节点后标记出来，virtual-kubelet 获取物理集群中的低效节点可用资源作为集群闲置资源二次分配给离线转码，同时二次调度器需要保证一旦在线服务有资源需求，将会立刻驱逐离线 pod 并归还资源。</p><p><img src="https://oscimg.oschina.net/oscnet/up-78e3d5cbc621e1c69abc0afefcbe2197d3c.png" alt="" referrerpolicy="no-referrer"></p><h3>阶段二：整机腾挪分时复用</h3><p>搜推广等业务的独占资源池，CPU 利用率潮汐现象明显，夜间利用率极低，资源池中的单个节点往往也只部署一个大规格业务 Pod。基于以上背景，平台通过弹性能力（HPA），在凌晨业务低峰期按比例对在线业务缩容，腾挪空出整机，并将转码、训练等离线 pod 在该时段运行起来，起到利用率「填谷」的效果。</p><p>具体实施时，需要确保在线服务能在规定的时间内全部被拉起。为此，策略方面我们实现了<strong>离线提前退场</strong>，并通过<strong>调度器抢占机制</strong>兜底，确保在线服务在业务高峰期来临之前能被全量及时拉起。</p><p><img src="https://oscimg.oschina.net/oscnet/up-84cfb939630e3290582da737276ccf7ace3.png" alt="" referrerpolicy="no-referrer"></p><h3>阶段三：常态混部</h3><p>为了降低资源碎片率，降低业务资源持有成本，平台持续推进业务大规模合池，将业务由独占池迁至平台托管的公共混部池，通过合池、资源超卖等技术手段，CPU 分配率得到有效提升，但依旧无法解决合并后的资源池夜间利用率较低等问题。</p><p>另一方面，合池后的复杂混部场景下，整机腾挪分时混部离线的调度策略很难再继续实施，平台需要通过建设更为细粒度的资源管理与调度能力来实现均值利用率提升的目标，具体包含以下几点：</p><ul><li><strong>调度侧：</strong></li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>通过动态超卖技术获取可二次分配给离线的可用资源量，并抽象出离线资源视图让 K8s 调度器感知到，调度器调度离线负载到对应节点上，实现离线对节点利用率的「填谷」效果；</li><li>通过负载调度，尽可能避免在线服务被调度到高负载机器，让集群中节点负载更加均衡；</li><li>通过二次调度，驱逐负载热点机器上的高利用率服务，使得集群负载处于动态均衡状态。</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li><strong>单机侧：</strong></li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>支持 QoS(Quality of service) 保障策略，根据服务的 QoS 等级提供差异化的运行时资源保障能力；</li><li>支持干扰检测、离线驱逐等能力，当离线对在线敏感服务产生干扰时，第一时间驱逐离线。</li></ul></li></ul><p>通过以上技术手段，可以有效保障服务混部时的稳定性，从而常态化的让在线离线工作负载混跑在节点上，实现利用率填谷效果的最大化。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c998cbca3a8fdb866b8f348eee02a1b01b3.png" alt="" referrerpolicy="no-referrer"></p><h2>架构设计与实现</h2><p>小红书容器资源调度架构设计如图所示：</p><p><img src="https://oscimg.oschina.net/oscnet/up-ddb703bb314f3320fc3682b89fb86524ff5.png" alt="" referrerpolicy="no-referrer"></p><p>小红书各类业务场景通过各类发布平台、任务平台提交后，通过上层负载编排能力，以 pod 形式下发到统一调度系统。统一调度系统基于不同的调度需求，对在线服务提供强保障的资源交付能力，差异化的 QoS 保障能力，对离线服务提供最小资源需求的保障能力和极致的弹性能力。</p><p><strong>调度侧：</strong></p><ul><li>离线调度：coscheduling；</li><li>二次调度：热点驱逐，碎片整理；</li><li>负载调度：基于 CPU 水位；</li><li>资源视图：模拟调度。</li></ul><p><strong>单机侧：</strong></p><ul><li>压制策略：bvt 压制，内存驱逐；</li><li>QoS 保障：绑核，超线程干扰抑制等；</li><li>Batch 资源上报：Batch 可用资源计算，上报；</li><li>指标采集 (from kernel)：psi，sched info 等；</li><li>干扰检测：基于 cpi、psi，业务指标的干扰检测。</li></ul><h3>离线调度资源视图</h3><p>离线服务资源调度的基本原理是基于在线服务负载感知能力的动态超卖，具体实现是将节点空闲资源二次分配给离线业务：</p><p><img src="https://oscimg.oschina.net/oscnet/up-9f0140d3bc4c514c29851f93be91a4c3081.png" alt="" referrerpolicy="no-referrer"></p><p>其中离线可用资源为节点上的空闲资源（包含未分配资源和已分配未使用资源之和），扣除安全预留资源之后剩余资源，离线可用资源计算公式如下：</p><p><strong>离线可用资源=整机资源–预留资源-在线服务实际使用量</strong></p><p>将计算出的离线可用资源量按照时间分布后如图所示（图中绿色部分）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-9b5fa6103d2a81e88ec09bae09fa979dbfe.png" alt="" referrerpolicy="no-referrer"></p><p>实际落地过程中，为了避免离线可用资源随在线服务资源使用波动而大幅波动，从而影响离线资源质量和离线服务运行稳定性，通过资源画像对上述公式中的在线服务实际使用量数据进一步处理，去除数据噪点，最终计算出一个相对稳定的离线可用资源量（图中绿色部分），如图所示：</p><p><img src="https://oscimg.oschina.net/oscnet/up-0059aa876dc7ef1a03173b62449f22cdcc5.png" alt="" referrerpolicy="no-referrer"></p><h3>混部 QoS 保障策略</h3><h4>QoS 分级</h4><p>按照业务对于服务质量（QoS: Quality of Service）的需求，我们将小红书的业务类型简单的划分为三个 QoS 级别，如下表所示：</p><table><thead><tr><th align="left"><strong>Qos 等级</strong></th><th align="left"><strong>说明</strong></th><th align="left"><strong>业务场景</strong></th></tr></thead><tbody><tr><td align="left">latency-sensitive</td><td align="left">最高 Qos 保障等级，延迟极为敏感服务</td><td align="left">搜推广延迟极为敏感场景</td></tr><tr><td align="left">mid</td><td align="left">默认 Qos 保障等级，容忍部分干扰延迟</td><td align="left">网关，java 微服务</td></tr><tr><td align="left">batch</td><td align="left">最低 Qos 保障等级，延迟不敏感，资源随时可能被抢</td><td align="left">转码，spark，flink，训练等计算场景</td></tr></tbody></table><h4>QoS 保障</h4><p>根据服务的 QoS 需求，节点侧会做 Pod 粒度的分级资源保障，实现各个资源维度差异化 QoS 保障策略，具体的保障参数如下：</p><table><thead><tr><th align="left"><strong>资源</strong></th><th align="left"><strong>特性</strong></th><th align="left"><strong>latency-sensitive</strong></th><th align="left"><strong>mid</strong></th><th align="left"><strong>batch</strong></th></tr></thead><tbody><tr><td align="left">CPU</td><td align="left">cpu burst</td><td align="left">enable</td><td align="left">enable</td><td align="left">disable</td></tr><tr><td align="left">调度优先级</td><td align="left">最高</td><td align="left">默认</td><td align="left">低</td><td align="left"></td></tr><tr><td align="left">绑核</td><td align="left">share(默认)</td><td align="left">share(默认)</td><td align="left">reclaimed</td><td align="left"></td></tr><tr><td align="left">numa</td><td align="left">强保证</td><td align="left">prefer（默认）</td><td align="left">none</td><td align="left"></td></tr><tr><td align="left">L3 cache</td><td align="left">100%</td><td align="left">100%（默认）</td><td align="left">30%（默认）</td><td align="left"></td></tr><tr><td align="left">内存带宽</td><td align="left">100%</td><td align="left">100%（默认）</td><td align="left">30%（默认）</td><td align="left"></td></tr><tr><td align="left">内存</td><td align="left">OOM 优先级</td><td align="left">最低</td><td align="left">默认</td><td align="left">最高</td></tr><tr><td align="left">内存回收水线</td><td align="left">调高</td><td align="left">默认</td><td align="left">调低</td><td align="left"></td></tr></tbody></table><p>在 CPU 核调度层面，分别设置了三种绑核类型，并设计了一套精细化 CPU 核编排策略，分配示意图如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-9b81b8f479dca622fc2faff72988e3725bf.png" alt="" referrerpolicy="no-referrer"></p><p>三种绑核类型分别为：</p><ul><li>exclusive（不推荐）</li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>特点：绑定 cpuset 调度域，CCD 感知，numa 绑定，独占排他</li><li>场景：极为敏感的搜推广大规格延迟敏感服务</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li>share</li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>特点：绑定 cpuset 调度域，CCD 感知，numa（可选）绑定，share/exlusive 排他，可与 none 类型业务共享</li><li>场景：容忍部分干扰的 Java 微服务，应用网关，web 服务</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li>reclaimed</li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>特点：无 cpuset 绑定，可能与非 exlusive 绑核模式业务共享核，核的分配完全交由内核，CPU 资源并非 100% 能得到满足</li><li>场景：batch 类离线服务，部分对延迟无要求的计算服务</li></ul></li></ul><h4>离线驱逐</h4><p>极端场景下，如整机内存使用率较高，有触发 OOM 风险，或者离线业务 CPU 长期得不到满足，单机侧支持按照离线服务内部定义的优先级配置，资源用量，运行时长等多维度综合算分排序后按序驱逐。</p><h3>离线业务场景</h3><p>小红书作为一个数亿用户的内容社区，其离线业务场景丰富多样，其中包含大量视频类，图片类转码场景，搜推，cv/nlp 算法推理训练，算法特征生产，数仓查询等离线场景，具体来讲，包含以下业务类型：</p><ul><li>近离线转码场景（已容器化）</li><li>Flink 流式/批式计算（已容器化）</li><li>Spark 批式计算 （未容器化，on yarn）</li><li>cv/nlp 算法回扫场景（已容器化）</li><li>训练场景 （已容器化）</li></ul><p>通过提供以 K8s 为底座的在离线统一调度能力，将这些离线业务与在线服务混合部署在统一计算资源池内，为在线服务提供差异化的资源质量保障，为离线服务提供海量的低层本算力，实现资源效能的提升。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e278c91df5dff9cd5dfa0b2c8ec2fb2fe2c.png" alt="" referrerpolicy="no-referrer"></p><h4>K8s 与 Yarn 混部方案</h4><p>小红书内部商业化，社区搜索等业务存在大量的算法类 Spark 任务因为离线集群资源紧张导致任务堆积，不能得到及时处理，同时在线集群在业务低峰时段资源使用率较低；另一方面，相当占比的 Spark 任务资源调度仍旧运行在 Yarn 调度器上，在这样的背景下，为了降低业务迁移成本，方案选型方面，我们选择与 Kooridinator 社区合作，采用 Yarn on K8s 混部方案来快速落地 Spark 离线场景混部，具体方案如图所示：</p><p><img src="https://oscimg.oschina.net/oscnet/up-21c973af2e9abe240b6e967c56668d29420.png" alt="" referrerpolicy="no-referrer"></p><p>其中容器化的在线、离线工作负载通过 K8s 链路发布到在线集群内，Spark 作业通过 Yarn ResourceManager 调度到具体节点，并由节点上的 Nodemanager 组件拉起。其中 Nodemanager 通过容器的方式部署在在线 K8s 集群内，除此之外，还涉及到以下组件：</p><ul><li>调度侧</li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>koord-yarn-operator ：支持 K8s 与 yarn 调度器资源视图双向同步；</li></ul></li></ul><p>&lt;!----&gt;</p><ul><li>节点侧</li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>copilot：NodeManager 操作代理，提供 Yarn Task 管控接口；</li><li>Neptune-agent/koordlet：离线资源上报，节点离线 Pod/task 管理，冲突解决，驱逐，压制策略；</li></ul></li></ul><p>支持 K8s 与 YARN 混部的核心能力目前已经在社区研发完成，在 Koordinator 1.4 版本进行发布。</p><p><strong>多调度器资源同步</strong></p><p>K8s 调度器与 YARN 调度器之间原本独立且相互不感知，为了共享分配在线集群节点上的总可用离线资源，需要通过 koord-yarn-operator 组件来做两个调度器之间的资源双向同步和协调，并实现两个同步链路：</p><ol><li>K8s-&gt;YARN 调度器资源同步链路，负责同步 Yarn 视角离线资源总量，其中 YARN 离线资源总量计算如下：</li></ol><p><strong>YARN 离线资源总量=离线总可用量-K8s 侧节点已分配</strong></p><ol start="2"><li>YARN-&gt;K8s 调度器资源同步链路，负责同步 YARN 已分配资源量，其中 K8s 离线资源总量计算如下：</li></ol><p><strong>K8s 离线资源总量=离线总可用量-YARN 侧节点已分配</strong></p><p>基于各自节点离线资源视图，两个调度器分别做出调度决策，调度 K8s 离线 Pod 与 YARN Task 到节点上，由于同步过程不适合加锁，可能会出现资源被过量分配的问题：</p><p><img src="https://oscimg.oschina.net/oscnet/up-6d5e77cabc64d55070c37537e6985b4c5a2.png" alt="" referrerpolicy="no-referrer"></p><p>具体解决措施是在单机侧增加了仲裁逻辑，当节点已分配离线服务资源量长期超过节点可用离线资源，且离线使用率持续较高，存在离线服务得不到资源被饿死的可能，单机侧则会根据离线服务的优先级，资源占用量，运行时长等因素综合算分并按序驱逐。</p><p><strong>阿里云 EMR 产品化支持</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-d1c1c3c4aa9bef46e34c575a9f0f6156861.png" alt="" referrerpolicy="no-referrer"></p><p>与此同时，阿里云 EMR 团队在产品层面提供了混部功能的开发支持，在兼容 EMR 原有日志，监控，运维逻辑的基础上，支持了 K8s 集群弹性扩缩容 NodeManager Pod 的能力。</p><h2>落地收益</h2><p>截至目前，<strong>小红书混部能力覆盖数十万台机器规模，覆盖算力规模数百万核，支持数万规模在线、离线场景服务的资源调度。</strong> 通过大规模容器混部的持续推进，小红书在资源成本效能等方面都取得了显著收益，具体包含以下两方面：</p><ul><li><strong>CPU 利用率</strong></li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>在保证在线服务服务质量的前提下，在线混部集群天均 CPU 利用率提升至&nbsp;<strong>45% 以上</strong>，部分集群天均 CPU 利用率可稳定提升至&nbsp;<strong>55%。</strong></li><li>通过在离线混部等技术手段，在线集群 CPU 利用率提升&nbsp;<strong>8%-15%</strong>&nbsp;不等，部分存储集群 CPU 利用率提升可达&nbsp;<strong>20% 以上。</strong></li></ul></li></ul><p>&lt;!----&gt;</p><ul><li><strong>资源成本</strong></li></ul><p>&lt;!----&gt;</p><ul><li><ul><li>在保证离线业务稳定性的前提下，为小红书各类离线场景提供<strong>数百万核时</strong>的低成本算力。</li><li>混部集群 CPU 分配率提升至 125% 以上，相较于独占资源池，资源碎片率明显下降。</li></ul></li></ul><h2>社区共建历程</h2><p><img src="https://oscimg.oschina.net/oscnet/up-4bd9476d9b418fa4c29e0b648c65ab748c9.png" alt="" referrerpolicy="no-referrer"></p><p>小红书是早期参与 Koordinator 社区的公司之一，2022 年 4 月，Koordinator 正式开源，同年 6 月，小红书内部启动了在离线混部项目，开始参与 Koordinator 方案设计与代码提交。2022 年 8 月，小红书与社区共建了 runtime-proxy 组件，并在内部场景落地。2023 年 4 月，小红书在社区主导启动了 YARN 与 K8s 混部项目，2023 年 8 月，该方案在小红书内规模化落地。</p><p>截至目前，依托 Koordinator 的助力，小红书的混部已经覆盖公司数万台节点，提供数十万核离线资源，<strong>整体混部集群的利用率提升至 45% 以上，</strong> 取得了不错的落地效果。</p><h2>总结与展望</h2><p>在小红书近一年多混部技术探索过程中，我们在资源效能提升方面积累了较为丰富的落地经验，并取得了不错的提升效果，随着公司业务规模逐步增长，场景愈发复杂，我们将会面临诸多新的技术挑战。下个阶段我们的目标是建设面向混合云架构的统一资源调度能力，具体工作将围绕以下三方面展开：</p><ol><li><strong>混合工作负载调度能力支持：</strong> 包括大数据、AI 在内的任务型工作负载调度能力建设，满足小红书所有业务场景的资源调度功能，性能需求；</li><li><strong>资源效能进一步提升：</strong> 面向混合云架构，推进更大规模的资源合池，推进 quota 化资源交付，通过更加激进的弹性，混部，超卖等技术手段，实现集群资源利用率的进一步提升，资源成本的大幅下降；</li><li><strong>更高服务质量保障能力：</strong> 在更为激进的 CPU 利用率目标背景下，通过建设 QoS 感知调度能力，干扰检测能力，依托安全容器等技术手段，解决深水区混部中可能遇到的各类混部干扰问题。</li></ol><h2>Koordinator&nbsp;社区近期规划</h2><p>再接下来的几个版本中，Koordinator 将在以下几个方面进行重点投入：</p><ul><li><strong>调度器性能优化：</strong> 支持等价类调度，通过合并 request 相同的 pod，避免 filter、score 等调度过程的重复计算。</li><li><strong>Network QoS：</strong> 网络维度容器服务质量，保障高优先级带宽，设计 request/limit 模型，保障最低带宽需求。</li><li><strong>大数据负载：</strong> 支持 Gang 调度原子抢占，按分组整体抢占 Pod；面向 Hadoop YARN 任务的 QoS 策略适配。</li><li><strong>资源干扰检测：</strong> 基于底层指标、感知容器资源竞争情况，识别异常 Pod，消除干扰并反馈调度链路。</li></ul><p>钉钉搜索群号：33383887&nbsp;加入 Koordinator 社区钉钉群。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 01:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/10946554</guid>
            <link>https://my.oschina.net/u/3874284/blog/10946554</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[前谷歌 TensorFlow 核心创始成员潘欣加入零一万物]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fm0eaQE1v31TuikBUPzT7jg" target="_blank">根据「甲子光年」的独家报道</a></u>，前谷歌 TensorFlow 核心创始成员潘欣已于去年加入「零一万物」，担任首席架构师，负责多模态研发。</p><p>潘欣毕业于北京邮电大学与滑铁卢大学计算机系，与深度学习框架打交道多年，曾任职于谷歌、百度、腾讯、字节跳动，在 CVPR，ICCV，SoCC 等会议发表论文。</p><p><img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-a04b47ece9e9525e21443ef117ecec0e7a2.png" width="300" referrerpolicy="no-referrer"></p><p>在谷歌期间，潘欣先在 Core Infra 从事大数据系统开发，后在 2015 年底加入谷歌大脑团队（Google Brain），与谷歌大脑的联合创始人杰夫·迪恩（Jeff Dean）、萨米·本吉奥（Samy Bengio）等合作，为 TensorFlow 和 Brain Research 的核心创始成员之一，对 Eager、TPU、Profiling 和 Model Zoo 等技术做出重要贡献。</p><p>2017 年底，潘欣带着「打造国产第一框架」的理想受邀加入百度，担任深度学习技术平台部架构师，负责 PaddlePaddle 框架开发。2019 年，潘欣加入腾讯担任平台与内容事业群（PCG） AI 平台技术负责人，打造了深度学习框架「无量」。</p><p>在加入零一万物之前，潘欣在字节跳动担任 AIGC 和视觉大模型 AI 平台负责人。</p><blockquote><p>零一万物是李开复博士在 2023 年 3 月底正式宣布筹办的大模型公司，由创新工场出资设立。2023 年 11 月，据报道，零一万物已完成由阿里云领投的新一轮融资，估值达到 10 亿美元，跻身大模型独角兽之列。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e43530b36778f17a86630730a5953d511ec.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 25 Jan 2024 11:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276646</guid>
            <link>https://www.oschina.net/news/276646</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 工具正在导致代码质量的下降]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">开发者分析公司 GitClear 最新发布了一份调查<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gitclear.com%2Fcoding_on_copilot_data_shows_ais_downward_pressure_on_code_quality" target="_blank">报告</a>，基于对着&nbsp;4 年来的数据的检查，其中包括超过 1.5 亿行被修改过的代码，以确定 Copilot 对代码编写质量的影响。</span></p><p><span style="color:#000000">结果发现，代码的流失率显着上升，为 7.1%，而 2020 年这一数据仅为 3.3%。与此同时，代码复用率却出现了令人担忧的下降。</span></p><p><span style="color:#000000">GitHub 的 Copilot 于 2021 年 6 月推出测试版，掀起了 AI 编码浪潮；来自 GitHub 和其他消息来源的数据称，在 2023 年期间，采用 AI 辅助开发的开发人员将超过 50%。GitHub 首席执行官 Thomas Dohmke 称，该软件已拥有超过 100 万开发者付费订阅。并表示，借助此工具开发者完成任务的速度提高了 55%，在启用 Copilot 的文件中，46% 的代码是由 Copilot 完成的。</span></p><p><span style="color:#000000">GitClear 的这项调查主要聚焦于代码质量而非数量。研究人员观察到，AI 助手倾向于给出"添加代码的建议，但从未给出更新、移动或删除代码的建议"。且"代码建议算法的动机是提出最有可能被接受的建议"。</span></p><p><img height="204" src="https://oscimg.oschina.net/oscnet/up-5cfd06b230fbe9cc212837f160c873c9ee9.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">研究人员发现，added、deleted、updated 以及 copy/pasted 的代码量已经突破新高；但移动代码的实例却有所下降。他们对大量复制/粘贴代码的行为影响深恶痛绝，并指出"对代码的长期可维护性而言，没有比这更大的祸害了"。</span></p><p><span style="color:#000000">不过，GitClear 的研究人员并没有就如何解决发现的问题发表太多意见，而是提出了"后续研究的问题"。但他们提出建议称"监控接收到的数据，并考虑其对未来产品维护的影响"。</span></p><p><span style="color:#000000">总的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevclass.com%2F2024%2F01%2F24%2Fai-assistance-is-leading-to-lower-code-quality-claim-researchers%2F" target="_blank">来说</a>，AI 助手不会消失，尽管它们可能会有所改进，并且像所有新工具一样，开发人员将学习如何优化其使用。</span></p><p style="text-align:start"><span style="color:#000000">在某些方面，这项研究可能会让那些担心被 AI 工具取代的开发人员感到放心。</span><span style="background-color:#ffffff"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodescene.com%2Fhubfs%2Fwhitepapers%2FRefactoring-vs-Refuctoring-Advancing-the-state-of-AI-automated-code-improvements.pdf" target="_blank">代码分析公司 CodeScene 最近</a></span><span style="color:#000000">进行的一项关于 AI 重构的研究得出的结论是：「在编码环境中，AI 远无法取代人类；今天的 AI 太容易出错，而且远未达到能够安全修改现有代码的程度。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 25 Jan 2024 10:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276640/ai-assistance-lower-code-quality</guid>
            <link>https://www.oschina.net/news/276640/ai-assistance-lower-code-quality</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[原魅族副总嘲讽华为花上万亿建设鸿蒙生态]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>曾担任过魅族副总裁，但如今已离职多年的李楠发文嘲讽华为花上万亿把安卓生态移植到鸿蒙，是硬制造困难，而后引发激烈争论。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ed126bf0724c6b85a56bb88acc1c3c4a43f.png" referrerpolicy="no-referrer"></p></blockquote><p>1 月 22 日，李楠发文称：</p><blockquote><p>华为鸿蒙哥说把 Android 生态移植到鸿蒙要上万亿。我就想说没有看到今天 AIAgent 的能力吗，本地 API 学习一遍，AI 可以直接写 Py 分步骤完成任务了。需需可能没几年，LLM 要把 Apps 生态覆了，你花上万亿还去搞移植，这就是所谓的没有困难就制造困难吗。</p></blockquote><p>随后，李楠的言论遭到了对方反驳：</p><blockquote><p>第一，我不是华为的;第二，我说的数据都有案例支撑，例如京东，美团;第三，AI 确实可以加速这一进程，但目前还停留在概念上:第四，你又没写过程序，你装啥逼？</p></blockquote><p>对此李楠回应称，自己是 20 多年前 211 计算机专业正经本科毕业，互联网后端和移动互联网前端写了 10 多年代码。码农，troubleshooting，架构，项目，产品一路干过来，反驳了对方说自己没写过程序的说法。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3c73b7065d810c2f30d7d723a6a94bcc5a5.png" referrerpolicy="no-referrer"></p></blockquote><p>1 月 22 日晚，李楠进一步发文称：</p><blockquote><p>算了我也直接一点吧，AI 时代研究怎么花上亿迁移 apps 生态的，都是 sb。更别说万亿了，相关的我都拉黑。这个内容我不改，就像几年前我预言 ARM 反攻桌面一样。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ef3ef94a39bf36319191c2a54de00c07868.png" referrerpolicy="no-referrer"></p></blockquote><p>1 月 24 日下午，李楠最后一次回应此次「论战」：</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-271d9fca5d439c8791831048cb216485b0a.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 25 Jan 2024 08:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276635</guid>
            <link>https://www.oschina.net/news/276635</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[全面升级！Apache HugeGraph 1.2.0 版本发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>图数据库以独特的数据管理和分析能力，在企业数智化转型的过程中正在成为数据治理的核心，根据 IDC 调研显示，95% 的企业认为图数据库是重要的数据管理工具，超过 65% 的厂商认为在业务上图数据库优于其他选择，尤其是在金融风控、欺诈检测、关系分析和预测分析等方面。中国图数据库市场正经历从市场教育阶段到大规模商业化落地的初期转变，在此行业背景下，&nbsp;<span style="color:#0052ff"><strong>Apache HugeGraph (Incubating) 1.2.0 版本的发布，不仅是技术的迭代，更是对产业的积极响应，该版本在系统语言、查询语言支持、服务器端算法、大数据处理框架以及易用性等方面进行了全面升级，旨在为用户提供更高效、更灵活的数据管</strong></span></span><span style="color:#0052ff"><strong>理和开发解决方案。经过百度内部的风控、搜索、爱企查等多个产品线使用验证，并<span style="background-color:#ffffff; color:#0052ff">有<strong><span style="background-color:#ffffff">网易游戏、科大讯飞、视源股份、网商银行、虎牙直播、YY 直播、货拉拉、360</span><span style="background-color:#ffffff">、</span><span style="background-color:#ffffff">百分点科技等</span></strong>超过 100 个社区用户/组织在使用 HugeGraph 。</span></strong></span></p><p><span>Apache HugeGraph 1.2.0 版本包含 3W+ 行 Pull Request 代码变更提交 ，在性能和实用性、易用性上做了大量改进和修复。&nbsp; HugeGraph 1.2.0 版本继续支持 Java 11，并保留对 Java 8 的兼容，下一步迈向 Java17。确保了与最新技术的无缝对接。Server 端大幅重构增强了已有的 OLTP 图算法，支持并行化迭代 + BFS/DFS 双模式查询, 内置了监控和 Trace 插件, 支持了初版的 Slow Query 查询, 新增 Spark-Connector 组件进行数据的导入导出, Computer 也新增了随机游走/社群发现等算法。更多详细内容请参见官网发布说明</span><span>（<span style="color:#0052ff">https://hugegraph.apache.org/docs/changelog/hugegraph-1.2.0-release-notes/</span>）。</span></p><p><span><img alt="" height="974" src="https://oscimg.oschina.net/oscnet/up-c22a598ea842ef16e1cd9b3024882a50513.png" width="866" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">易用性方面，HugeGraph 1.2.0 版本提供了一键 Server/Hubble 容器化 Docker 支持，重构整合了图周边工具链为 HugeGraph Toolchain ，简化了部署和使用流程。此外，</span><span style="background-color:#ffffff; color:#0052ff"><strong>2023 年 HugeGraph 通过了飞腾、麒麟、海光等信创厂商的兼容性认证，以及入选</strong><strong>GLCC 2023 优秀社区及优秀管理员、开放原子开源基金会 2023 年活力开源贡献者，进一步证明了其在国产数据库生态中的重要地位。</strong></span></p><p><span style="background-color:#ffffff; color:#0052ff"><strong><img alt="" height="1144" src="https://oscimg.oschina.net/oscnet/up-1ddd13ae8695acd71cb2e74578d5efb081d.jpg" width="788" referrerpolicy="no-referrer"></strong></span></p><p><span style="color:#000000"><span style="color:#000000">HugeGraph 于 2016 年由百度安全发起两年后开源，在 2022 年以全票通过的优秀表现正式成为全球首个加入 Apache 孵化的图数据库项目，是国内首个开源的图数据库，提供了一站式的千亿级大规模图数据的存储、在线查询、离线分析平台，促使国产图数据库走向世界，在提升图数据库产品开发效率、降低产业应用成本的同时，在人才、生态建设产生深远的影响，让更多开发者因此受益。</span></span></p><p><span>Apache HugeGraph 1.2.0 版本的发布，标志着图数据库技术的又一重要进步。我们期待这一版本能够助力企业在金融风控、欺诈检测等领域实现更高效的数据管理和分析，推动中国图数据库市场的快速发展。立即体验 HugeGraph 1.2.0 版本，开启您的数据智能新篇章！未来，百度安全也将持续与产学研各界合作伙伴保持合作，共同迎接大模型时代下图数据库的新机遇、新挑战，共筑安全防线，探索图数据库赋能千行百业的无限可能。</span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 25 Jan 2024 08:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4501957/blog/10946509</guid>
            <link>https://my.oschina.net/u/4501957/blog/10946509</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源软件的存在是否影响了广大程序员的收入？]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/2720166_2331655">开源软件的存在是否影响了广大程序员的收入？</a><div class="ui red label horizontal" data-tooltip="置顶">顶</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/hardbone" class="__user"><span>局</span></a> 发布于，昨天 15:49
                    </div><div class="item">阅读 1K+</div><div class="item collect-btn " data-id="2331655" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331655" data-obj-type="2">1</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/2720166_2331655#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">11</span></a></div></div><div class="content" id="articleContent"><p><span><strong>开源运动的反对者认为：</strong></span></p><div><div><div><div><div><p><span>类似于 Linux 内核之类的软件，相当于软件开发人员将自己的劳动成本免费抛向社会，而这一部分价值原本应该是由整个社会来承担的。</span></p><p><span>人们对于软件的需求是有限的，当这部分需求被免费得到后，相当于整个软件开发行业的收入就会降低。</span></p><p><span>而对于另一些项目，在需求不变的情况下，如果没有开源项目以供参考，软件公司就要招收更多的软件开发人员开发程序，如此下来软件开发人员的工作岗位就会增加。</span></p><p><span>按照这种逻辑，首先开发开免费的源软件的那个程序员的平均时薪会降低，因为他的一部分工作是没有获得劳动报酬的。其次整个行业的总收入会降低，因为有了免费的软件，人们不大可能会愿意花钱购买收费的同样功能的软件。</span></p><p><span>即使开源软件采取收费策略，但相比起闭源软件来说，也更容易遭到破解。事实上大部分开源软件都并不收费。</span></p><p><span><strong>对开源运动做出维护：</strong></span></p><p><span>开源软件的盛行使更多的人接触到更多的软件（人们更乐意接受不收费的东西），使人们更加依赖计算机软件解决问题，而不是其他途径。这使得使用计算机软件的人数增多，从而催生出更多的需求。</span></p><p><span>另一方面，大量的开源软件的出现带动了社会生产力的进步，生产力的进步使社会的总体收入增加，程序开发人员自然也会跟着增加。</span></p><p><span><strong>你认为开源软件的存在对广大程序员的收入是正向的还是负面的？</strong></span></p></div></div></div></div></div></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331655" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331655" data-obj-type="2">1</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331655" data-obj-type="2" data-url="https://www.oschina.net/question/2720166_2331655"><i class="flag red icon"></i>举报</a></div></div>
            ]]>
            </description>
            <pubDate>Thu, 25 Jan 2024 07:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/2720166_2331655</guid>
            <link>https://www.oschina.net/question/2720166_2331655</link>
        </item>
        <item>
            <title>
                <![CDATA[苹果 Mac 诞生 40 年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>苹果 CEO 蒂姆·库克今天在个人微博庆祝 Mac 诞生 40 周年。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-6fe3fc1659e0c08bb7388f87a41590780e4.png" referrerpolicy="no-referrer"></p><p><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5524254784%2FNDqPXgd7H" target="_blank">https://weibo.com/5524254784/NDqPXgd7H</a></em></u></p></blockquote><p>40 年前的 1984 年，史蒂夫·乔布斯向外界展示了 Macintosh，并称其为「计算机的未来」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ee0017fdf2ae38f2df579a0596c872a37da.png" referrerpolicy="no-referrer"></p><p>麦金塔电脑（Macintosh，1998 年后多被简称为 Mac），是自 1984 年 1 月起由苹果公司设计、开发和销售的个人电脑系列产品。目前 Mac 产品线包含以下系列：iMac、Mac mini、Mac Studio、Macbook Air、Macbook Pro、Macbook、Mac Pro 等。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-77ad4fac2810b6172e79419b15f14a89534.png" referrerpolicy="no-referrer"></p><p>Mac 在历史上曾经 3 次更换指令集架构：</p><ul><li>1994 年，Mac 从摩托罗拉 68000 系处理器迁移至 PowerPC 处理器</li><li>2005 年至 2006 年，Mac 从 PowerPC 处理器迁移至 Intel 平台处理器</li><li>2020 年至 2023 年，Mac 从 Intel 平台处理器迁移至苹果处理器</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 25 Jan 2024 04:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276599/apple-mac-40-anniversary</guid>
            <link>https://www.oschina.net/news/276599/apple-mac-40-anniversary</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ollama 发布 Python 和 JavaScript 库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Ollama Python 和 JavaScript 库的初始版本现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.ai%2Fblog%2Fpython-javascript-libraries" target="_blank">推出</a>：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Follama%2Follama-python" target="_blank">Ollama Python Library</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Follama%2Follama-js" target="_blank">Ollama JavaScript Library</a></li></ul><p>这两个库都可以通过几行代码将新的和现有的应用程序与 Ollama 集成，并共享 Ollama REST API 的 features 和 feel。</p><p><img height="224" src="https://oscimg.oschina.net/oscnet/up-4ef62e38763d1ebcd9807a29b6849e8339c.png" width="500" referrerpolicy="no-referrer"></p><blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Ollama 是一款命令行工具，可在 macOS 和 Linux 上本地运行 Llama 2、Code Llama 和其他模型。目前适用于 macOS 和 Linux，并计划支持 Windows。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Ollama 目前支持近二十多个语言模型系列，每个模型系列都有许多可用的 "tags"。Tags&nbsp;是模型的变体，这些模型使用不同的微调方法以不同的规模进行训练，并以不同的级别进行量化，以便在本地良好运行。量化级别越高，模型越精确，但运行速度越慢，所需的内存也越大。</span></p></blockquote><h4><strong>Getting Started</strong></h4><p><strong>Python</strong></p><pre><code class="language-shell">pip install ollama</code></pre><pre><code class="language-python">import ollama
response = ollama.chat(model='llama2', messages=[
  {
    'role': 'user',
    'content': 'Why is the sky blue?',
  },
])
print(response['message']['content'])</code></pre><p><strong>JavaScript</strong></p><pre><code>npm install ollama</code></pre><pre><code class="language-javascript">import ollama from 'ollama'

const response = await ollama.chat({
  model: 'llama2',
  messages: [{ role: 'user', content: 'Why is the sky blue?' }],
})
console.log(response.message.content)
</code></pre><h4><strong>用例</strong></h4><p>这两个库都支持 Ollama 的全套功能。以下是 Python 中的一些示例：</p><p><strong>Streaming</strong></p><pre style="margin-left:0; margin-right:0; text-align:start"><code class="language-python">for chunk in chat('mistral', messages=messages, stream=True):
  print(chunk['message']['content'], end='', flush=True)
</code></pre><p><strong>Multi-modal&nbsp;</strong></p><pre style="margin-left:0; margin-right:0; text-align:start"><code class="language-python">with open('image.png', 'rb') as file:
  response = ollama.chat(
    model='llava',
    messages=[
      {
        'role': 'user',
        'content': 'What is strange about this image?',
        'images': [file.read()],
      },
    ],
  )
print(response['message']['content'])
</code></pre><p><strong>Text Completion&nbsp;</strong></p><pre style="margin-left:0; margin-right:0; text-align:start"><code class="language-python">result = ollama.generate(
  model='stable-code',
  prompt='// A c function to reverse a string\n',
)
print(result['response'])
</code></pre><p><strong>Creating custom models&nbsp;</strong></p><pre style="margin-left:0; margin-right:0; text-align:start"><code class="language-python">modelfile='''
FROM llama2
SYSTEM You are mario from super mario bros.
'''

ollama.create(model='example', modelfile=modelfile)
</code></pre><p><strong>Custom client</strong>&nbsp;</p><pre style="margin-left:0; margin-right:0; text-align:start"><code class="language-python">ollama = Client(host='my.ollama.host')</code></pre><p>更多示例可查看&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Follama%2Follama-python%2Ftree%2Fmain%2Fexamples" target="_blank">Python</a>&nbsp;和&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Follama%2Follama-js%2Ftree%2Fmain%2Fexamples" target="_blank">JavaScript</a>&nbsp;库。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 25 Jan 2024 02:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276592/python-javascript-libraries</guid>
            <link>https://www.oschina.net/news/276592/python-javascript-libraries</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
