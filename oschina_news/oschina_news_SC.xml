<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 21 Feb 2024 14:08:42 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[程序员因 bug 事故被公司强制要求归还 4 万年终奖]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>某程序员在 V2EX 发帖称，因线上流量异常事故，自己被公司进行处罚。处罚的结果是被要求将去年发的 4 万多年终奖归还给公司，如果逾期不还，将以每天万分之 5 的利息收取滞纳金。</p><p>该程序员还称，公司 hr 还扬言三个月内还是不还就免费开除。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-11365064309a71d744e9abe207d19996d40.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1016302" target="_blank">https://www.v2ex.com/t/1016302</a></u></em></p></blockquote><p>最新后续：</p><blockquote><p><img height="4236" src="https://oscimg.oschina.net/oscnet/up-0b14b51439371608fa1837e2222c753a465.png" width="1504" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1017164" target="_blank">https://www.v2ex.com/t/1017164</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 10:31:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279644</guid>
            <link>https://www.oschina.net/news/279644</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[我国 5G 基站总数超 337 万个，5G 移动电话用户达 8.05 亿户]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>工业和信息化部数据指出：截至 2023 年底，我国累计建成 5G 基站 337.7 万个，5G 移动电话用户达 8.05 亿户。</p><p>网络基础日益完备。我国已建成全球最大的光纤和移动宽带网络，全国行政村通 5G 比例超 80%。通信杆塔资源与社会杆塔资源双向共享取得显著成效，目前 90% 以上的基站实现共建共享，5G 基站单站址能耗相较于商用初期降低 20% 以上。</p><p>创新能力不断增强。我国 5G 技术产业在技术标准、网络设备、终端设备等方面创新能力不断增强。轻量化 5G 核心网、定制化基站等实现商用部署。5G 工业网关、巡检机器人等一批新型终端成功研发。5G 标准必要专利声明量全球占比超 42%，持续保持全球领先。</p><p>赋能效应持续凸显。融合应用广度和深度不断拓展，5G 应用已融入 71 个国民经济大类，应用案例数超 9.4 万个，5G 行业虚拟专网超 2.9 万个。5G 应用在工业、矿业、电力、港口、医疗等行业深入推广。「5G+工业互联网」项目数超 1 万个。</p><p>赋值效应更加显著。5G 移动电话用户持续增长、5G 流量消费快速提升，有效拓展了移动通信市场的发展空间。截至 2023 年底，我国 5G 网络接入流量占比达 47%。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 09:01:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279630</guid>
            <link>https://www.oschina.net/news/279630</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[法国电信公司 Orange 违反 GPL 许可协议，被罚 65 万欧元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根据 2024 年 2 月 14 日下达的判决，法国上诉法院判定当地电信公司 <strong>Orange 因未遵守 GNU GPL v2 许可证条款而侵权</strong>，并且需要向 Entr'Ouvert 支付&nbsp;<strong>50 万欧元的经济损失赔偿和 15 万欧元的精神损失赔偿</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aba84da216106bb416ed362f90f6181cab6.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweb.archive.org%2Fweb%2F20240216164701%2Fhttps%3A%2F%2Fwww.legalis.net%2Factualite%2Forange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl%2F" target="_blank">https://web.archive.org/web/20240216164701/https://www.legalis.net/actualite/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6928315e1d404157b8404126515b42d68a7.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.orange.com%2Fen" target="_blank">Orange</a></u><span>&nbsp;是一家法国电信运营商。根据上文的判决，</span>Orange 的 IDMP 平台使用了名叫 Lasso 的库，该库的版权所有者为 Entr'Ouvert 公司。<strong>Lasso 采用 GPLv2 License —— 并为私有项目提供了商业许可证</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-7e59b5839901ae3f8dc0da42fd32d14c3d1.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flasso.entrouvert.org%2F" target="_blank">https://lasso.entrouvert.org/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2d0135e65a7b51a798b2692a65007c31a65.png" referrerpolicy="no-referrer"></p><p>2005 年年底，Orange 参与了电子管理局关于实施 My Public Service 门户网站的招标活动，为身份管理提供一套 IT 解决方案，其中包括<strong>通过软件接口将 IDMP 平台与 Entr'ouvert 公司发布的 Lasso 软件库连接起来，Lasso 库采用 GPL 许可证</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7d0ef557e10594da586685534b7728c372e.png" referrerpolicy="no-referrer"></p><p>法院认为，Entr'Ouvert 首先蒙受了与其在公共市场 Mon.service-public.fr 上收益受损相关的经济损失，「因为如果 Orange 公司遵守许可合同，并签订付费许可，他们就应该向对方支付版税。」</p><p>此外，上诉法院特别指出，「Orange 免费使用 Lasso 软件为这个持续 7 年的大规模公开市场带来了利润，此外还有 Lasso 给这个门户网站在形象方面带来的好处。<strong>这番操作让 Orange 得以节省投入从而受益，因为通过免费使用 Lasso 软件，Orange 公司可以满足通信安全和隐私管理局 (ADAE) 要求的安全标准，从而能够节省研发成本</strong>。」</p><p>Entr'ouvert 着重批评 Orange 违反了 Lasso 程序的许可合同条款，这些条款涉及它作为该程序版权持有人所拥有的知识产权，因此它以涉嫌侵犯其权利为由起诉了 Orange。</p><p>上诉法院首先要求 Entr'ouvert 证明 Lasso 软件具有原创性。</p><p>根据 Entr'ouvert 出示的证据，上诉法院得出的结论是，<strong>Lasso 「在软件组成、结构和表达方面都是原创的，符合版权保护的条件」</strong>。</p><p>上诉法院随后审查了 Entr'Ouvert 援引的三起违反 GNU GPL v2 许可协议的行为。</p><p><strong>首先，法院认为 Orange 违反了许可合同第 2 条，因为它对 IDMP 所基于的 Lasso 进行了修改，却没有将 IDMP 作为一个免费整体授予政府。</strong></p><p><strong>其次，法院判定 Orange 没有进一步遵守第 3 条，因为没有提供修改后的源代码。</strong></p><p><strong>最后，法院特别指出，Orange 在没有遵守许可合同的所有条件、特别是第 4 条的情况下，复制、修改和分发了 Lasso。</strong></p><p><strong>法院还认为 Lasso 被整合到 IDMP 平台中，而 IDMP 平台的发行条件不一样，且没有征得 Entr'Ouvert 公司的授权，此举也违反了许可合同第 10&nbsp;条。</strong></p><p>总而言之，Orange 的 IDMP 产品使用了 Lasso，要么按照 GPLv2 许可证要求公布它的源代码，要么从版权所有者 Entr'Ouvert 购买许可证。Orange 没有付费也没有遵守 GPL 许可协议。法国上诉法庭判决 Orange 侵权行为成立。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 08:09:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</guid>
            <link>https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[清华大学文生视频专利公布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">国家知识产权局网站显示，近日，清华大学申请的「一种定制化多主体文生视频方法、装置、设备及介质」专利公布，发明人为王鑫；朱文武；陈虹。</span></p><p><span style="background-color:#ffffff; color:#222222">摘要显示，该申请涉及神经网络技术领域，通过多种损失对文生视频模型的参数进行优化，使优化的模型基于文本描述生成视频中的图像时，文本描述与定制化主体保持一致，且在每个主体在生成过程中的特征不会发生混淆的同时消除合成痕迹。</span></p><p><span style="background-color:#ffffff; color:#222222"><img alt="" height="453" src="https://oscimg.oschina.net/oscnet/up-1ec28ceb1ad4ccf2dfbde602d461109e5a2.jpg" width="700" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 07:17:06 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279604</guid>
            <link>https://www.oschina.net/news/279604</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.20</strong></span></h3><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要点</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/279326/linux-kernel-is-a-cna" target="_blank">Linux 内核成为 CVE 编号机构 (CNA)</a></u></h3><p>Linux 内核已被接受为 CVE 编号机构 (CNA)，这意味着他们将直接管理内核的 CVE。Linus Torvalds 近日在邮件列表发布了 Linux 6.8-rc5，并介绍称文档添加了 CVE 漏洞处理相关的指南。</p><p>文档写道，Linux 内核开发团队有能力为潜在的内核安全问题分配 CVE，而分配的 CVE 编号将在 linux-cve-announce 邮件列表上公布，修复的安全漏洞才会分配 CVE 编号，未修复的不会自动分配编号。</p><h3><u><a href="https://www.oschina.net/news/279389/dart-3-3-released" target="_blank">Dart 3.3 发布：扩展类型、JavaScript Interop 等</a></u></h3><p>Dart 3.3 现已发布，公告称此版本改变了性能和跨平台开发的游戏规则。</p><p>增强的扩展类型（Extension Types）将彻底改变性能优化以及用户与本地代码的交互方式。JavaScript interop 模型也得到了改进，引入了强大的类型安全性和开发人员友好的方式来利用 Web 平台的强大功能。「所有这些都为 WebAssembly 支持铺平了道路」。此外，新版本还增加了 Google AI 功能。</p><p><img height="300" src="https://oscimg.oschina.net/oscnet/up-3949a01f3c180246795018315421f62eccc.webp" width="300" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日观察</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-50e80801ccee84a0972ddbf9328c862d87b.png" referrerpolicy="no-referrer"></p><p>- 微博 <em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1609119537%2FO1t7Mj9XJ" target="_blank">2gua</a></u></em></p><p><img src="https://oscimg.oschina.net/oscnet/up-1d42d0aba38b933d17c04033962ce1cc5e5.png" referrerpolicy="no-referrer"></p><p>-<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapp.myzaker.com%2Fnews%2Farticle.php%3Fpk%3D65d353d4b15ec004b02314b1" target="_blank">脑极体</a></u></em></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推荐</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-048ed3535e056a8b2c5037aadf05b7b881b.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">开源之声</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-ce33753dcaf6809a8c2305f7b0fee44604a.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日项目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜单：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8d2c1aa11cc57bc0bfb89a2a2bc2f10afdd.png" referrerpolicy="no-referrer"></p><h4><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span><br><em><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf" target="_blank">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></u></em></h4><hr><p><strong>往期回顾</strong></p><ul><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf" target="_blank">开源日报第 011 期：目前还没有「大模型版 Linux」</a></u></li><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></u></li><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf" target="_blank">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></u></li><li><u><a href="https://www.oschina.net/news/277585" target="_blank">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></u></li><li><u><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">开源日报第 006 期：选择技术栈一定要选择开源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 05:47:05 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279578</guid>
            <link>https://www.oschina.net/news/279578</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年度 Rust 调查报告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">2023 年度 Rust 调查报告现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2024%2F02%2F19%2F2023-Rust-Annual-Survey-2023-results.html" target="_blank">出炉</a>，基于 2023 年 12 月 18 日至 2024 年 1 月 15 日期间进行的调查结果。此次调查问卷共收到 11950 份回复，其中 9710 份完成了所有问题。</span></p><p><span style="color:#000000"><strong>参与情况</strong></span></p><p><span style="color:#000000">参与调查的开发者来自世界各地，最多的是美国（22%），其次是德国（12%）、中国（6%）、英国 (6%)、法国 (6) %）、加拿大（3%）、俄罗斯（3%）、荷兰（3%）、日本（3%）和波兰（3%）。92.7% 的受访者更趋向于采用英语交流技术主题，相较 2022 年的 93% 略有下降；中文是第二选择，占比为 6.1%（ 2022 年为 7%）。</span></p><p><span style="color:#000000"><strong>Rust 使用情况</strong></span></p><p><span style="color:#000000">有 93% 的受访者称自己是 Rust 用户，其中 49% 的人每天（或几乎每天）都会使用 Rust，相较上一年小幅增加 2 个百分点。在没有使用 Rust 的用户中，31% 的人表示主要原因时使用 Rust 有难度；67% 的人表示他们还没有机会优先学习 Rust，这也是最常见的原因。</span></p><p><span style="color:#000000">46% 的受访者表示其不再使用 Rust 的原因在于「无法控制的因素」（比 2022 年减少了 1 个百分点），31% 的人是因为更喜欢另一种语言（比 2022 年增加了 9 个百分点），还有 24% 是因为难度（比 2022 年减少了 6 个百分点）。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-335afef97d65f03d34d0f08eb8831153557.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">操作系统的选择方面，Linux 是最受 Rust 用户欢迎的选择，其次是 macOS 和 Windows，两者份额相近。IDE 的选择上，Visual Studio Code 仍然是最受欢迎的选择，RustRover（去年发布）也获得了一些关注。</span></p><p><span style="color:#000000"><strong>Rust 在工作中的使用情况</strong></span></p><p><span style="color:#000000">34% 的受访者表示他们在工作中的大部分编码业务都使用 Rust，相较 2022 年增加了 5 个百分点。86% 的受访者雇主投资 Rust 的首要原因是能够构建相对正确且无 bug 的软件，第二个原因是 Rust 的优秀性能（83%）。77% 的受访者表示，他们的组织可能会在未来再次使用 Rust。</span></p><p><span style="color:#000000">就技术领域而言，Rust 似乎在创建服务器后端、Web 和网络服务以及云技术方面特别受欢迎。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-956fdb129c803494d840f04071cceb0996b.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><strong>对 Rust 未来的担忧和期待</strong></span></p><p><span style="color:#000000">共有 9374 名受访者分享了他们对 Rust 未来的主要担忧，其中 43% 的受访者担心 Rust 变得过于复杂，相较 2022 年增加了 5 个百分点。42% 的受访者担心 Rust 在科技行业的使用率过低。32% 的受访者最担心 Rust 开发人员和维护人员得不到适当的支持，相较 2022 年增加了 6 个百分点。</span></p><p><span style="color:#000000">另一方面，完全不关心 Rust 未来的受访者明显减少，2023 年为 18%，2022 年为 30%。</span></p><p><span style="color:#000000">就 Rust 用户希望实现、稳定或改进的功能而言，最需要的改进是 traits（trait aliases、associated type defaults 等）、const execution（generic const expressions、const trait methodsconst 等）以及 async（async closures、coroutines）。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-bcaf516c155cafe4eb2d721dc6e86434a9e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">可能是出于对复杂度的担忧，还有 20% 的受访者希望 Rust 放慢新功能的开发速度。此外，Rust 中最令用户头疼的似乎是 asynchronous Rust、traits、generics system 以及 borrow checker。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-de1d95566f02a3dccfae6db246605f3684a.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">受访者希望 Rust 维护者主要优先考虑修复编译器错误 (68%)、提高 Rust 程序的运行时性能 (57%) 以及缩短编译时间 (45%)。受访者指出，编译时间是需要改进的最重要领域之一；但有趣的是，受访者似乎也认为运行时性能比编译时间更重要。</span></p><p><span style="color:#000000"><img alt="" height="571" src="https://oscimg.oschina.net/oscnet/up-b59d67be36c91976d230c9e2d43ae22ac9e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">更多详情可查看</span>完整的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fraw.githubusercontent.com%2Frust-lang%2Fsurveys%2Fmain%2Fsurveys%2F2023-annual-survey%2Freport%2Fannual-survey-2023-report.pdf" target="_blank">调查报告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 04:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279563/rust-survey-2023-results</guid>
            <link>https://www.oschina.net/news/279563/rust-survey-2023-results</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024，RISC-V 可期]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>转载自：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6WLBNUfHyfLCq7AR9Ortuw" target="_blank">中国电子报（ID：cena1984）</a></u></em></p></blockquote><p>2023 年，长期被冠以「低端」帽子的 RISC-V 架构，终于实现了高端化过程中的两个「小目标」：一个是单核性能走高，可与 ARM Cortex-A7 对标；另一个是应用场景拓展到 PC 领域，首台搭载 RISC-V 架构的笔记本电脑<u><a href="https://www.oschina.net/news/234292">面世</a></u>。</p><p>如此势头下， 2024 年 RISC-V 的发展似乎「一片坦途」。</p><p><strong>在数据中心市场「掘金」</strong></p><p>为了实现「高端化」转型，RISC-V 架构设计企业在持续尝试将市场拓展到对算力、稳定性等指标要求更高的领域。2023 年，业界推出多个面向数据中心的 RISC-V 产品，其中包括算能科技流片业内首颗 RISC-V 服务器芯片 SG2042、赛昉科技推出的超大规模总线 IP「昉·星链-700」及 256 核 RISC-V 众核 IP 子系统平台。</p><p>在数据中心领域，当前涌现了多家剑指服务器 CPU 的 RISC-V 初创公司。赛昉科技董事长兼 CEO 徐滔认为，不只是服务器 CPU，「数据中心」市场可谓遍地是黄金，BMC 芯片、存储芯片、AI 加速器、DPU 等都可以用 RISC-V 来做。「我认为， 2024 年将有多款不同类型的 RISC-V 芯片在数据中心场景中量产落地。」徐滔向《中国电子报》表示。</p><p>此外，还有多家 RISC-V 厂商设计的 「大芯片」有流片可能，其中包括 Ventana 的 192 核、4nm 的 RISC-V 服务器 CPU——Veyron V2，Tenstorrent 的 3nm AI &amp; CPU Chiplets——Grendel 等，它们都有机会在 2024 年流片。</p><p><strong>赶上「AI 特快」</strong></p><p>「人工智能是目前正在开发的新兴技术中最重要的类别，该类应用需要新型的编程模型、新型的 SoC 以及新型的系统，我们看到 RISC-V 在其中扮演着非常重要的角色。」 SiFive 企业营销与业务开发资深副总裁刚至坚在接受《中国电子报》记者采访时表示。</p><p>刚至坚认为，RISC-V 提供了一个奇妙的、共享的生态系统， 一个 AI 编程环境以及开发新软件的环境，随着性能、可定制化能力不断提升，RISC-V 将越来越多地进入人工智能主导的新兴市场中，其应用场景包括数据中心、汽车以及消费电子等领域。</p><p><strong>高端 SoC 可商用</strong></p><p>在深度数智总裁卜祥敏看来，2024 年最关键的是 SoC 可商用产品的落地。</p><p>「2023 年我们做了一年基于 RISC-V 的整体解决方案，我深刻地感受到，现在 SoC 芯片与真正的可商业化落地之间还有不少距离。」卜祥敏告诉《中国电子报》记者，「2023 年深度数智推出了基于 RISC-V 架构的笔记本电脑。2024 年，我们计划和生态圈的合作伙伴一同推出搭载新一代基于 RISC-V 架构设计的 SoC 笔记本电脑和服务器。」</p><p>2023 年，谷歌与安卓宣布支持 RISC-V 生态。卜祥敏表示，这将推动 RISC-V 的生态系统走向完善。更加完备的生态系统，将有助于提升 RISC-V 在桌面、智能终端等领域的可用性。</p><p>徐滔认为，垂直整合是 RISC-V 处理器在高端市场落地的有效方式。「垂直整合，即通过应用定义芯片。RISC-V 在商业上标准开放、技术上架构灵活，厂商可以更好地根据应用需求设计芯片。高端应用定义芯片，更能释放垂直整合的价值，这也是 RISC-V 最大的机会。」徐滔表示。</p><p><strong>软件生态加速建设</strong></p><p>2023 年 6 月，全球 RISC-V 软件生态计划 RISE（RISC-V Software Ecosystem）组织成立。该计划由谷歌、英特尔、高通、联发科、Andes、平头哥、Rivos、SiFive、Ventana、三星、英伟达、Imagination 等共 13 家产业巨头共同发起的，旨在协助 RISC-V 国际基金会共同加速 RISC-V 商用软件生态建设。它的成立，标志着 RISC-V 软件生态从纯开源主导、基金会主导进入商业化主导、全球大规模共建的时代。</p><p>中国科学院软件研究所副所长、总工程师武延军在接受《中国电子报》记者采访时表示，由于 RISC-V 得到 Debian 和 OpenEuler 两大开源操作系统社区的官方主线支持，加之 RISE 组织成立，头部软硬件企业正式加入 RISC-V 生态，2024 年 RISC-V 软件生态将加速建设。</p><p>武延军认为，2024 年，市面上将会在 2023 年已有产品的基础上，再次出现 RISC-V 标志性高性能处理器，服务器软件生态规模化适配正式开启。开源开放和全球协作理念，使得 RISC-V 开发者的规模持续快速增长。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:24:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279556</guid>
            <link>https://www.oschina.net/news/279556</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 21 虚拟线程如何限流控制吞吐量]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>虚拟线程（Virtual Threads）是 Java 21 所有新特性中最为吸引人的内容，它可以大大来简化和增强 Java 应用的并发性。但是，随着这些变化而来的是如何最好地管理此吞吐量的问题。本文，就让我们看一下开发人员在使用虚拟线程时，应该如何管理吞吐量。</p><p>在大多数情况下，开发人员不需要自己创建虚拟线程。例如，对于 Web 应用程序，Tomcat 或 Jetty 等底层框架将为每个传入请求自动生成一个虚拟线程。</p><p>如果在应用程序内部需要自行调用来提供业务并发能力时，我们可以使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2Fjava21%2Fjep444-virtual-threads.html" target="_blank">Java 21 新特性：虚拟线程（Virtual Threads）</a>中介绍的方法去创建和使用，比如较为常用的就是<code>Executors.newVirtualThreadPerTaskExecutor()</code>。</p><pre><code class="language-java">Runnable runnable = () -&gt; {
    System.out.println("Hello, www.didispace.com");
};

try (ExecutorService executorService = Executors.newVirtualThreadPerTaskExecutor()) {
    for (int i = 0; i &lt; 100; i++) {
        executorService.submit(runnable);
    }
}
</code></pre><p>我们可以像上面开启 100 个虚拟线程来执行任务。那么问题来了，我们要如何对虚拟线程限流控制吞吐量呢？</p><h2>虚拟线程的限流</h2><p>对于虚拟线程并发控制的答案是：信号量！**划重点：不要池化虚拟线程，因为它们不是稀缺资源。**所以，对于虚拟线程并发控制的最佳方案是使用<code>java.util.concurrent.Semaphore</code>。</p><p>下面的代码示例演示了如何实现<code>java.util.concurrent.Semaphore</code>来控制虚拟线程的并发数量：</p><pre><code class="language-java">public class SemaphoreExample {

    // 定义限流并发的信号量，这里设置为：10
private static final Semaphore POOL = new Semaphore(10); 

public void callOldService(...) {
try{
POOL.acquire(); // 尝试通过信号量获取执行许可
} catch(InterruptedException e){
            // 执行许可获取失败的异常处理
}

try {
// 获取到执行许可，这里是使用虚拟线程执行任务的逻辑
} finally {
            // 释放信号量
POOL.release(); 
}
}
}
</code></pre><p>是不是很简单呢？今天的分享就到这里，希望对你有所帮助，更多关于 Java 新特性的学习可以关注我的免费专栏<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2F" target="_blank">Java 新特性</a>。</p><h2>扩展阅读</h2><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Farticle%2Fjava-21-virtaul-threads.html" target="_blank">启动 1000 万个虚拟线程需要多少时间？需要多少平台线程？</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Farticle%2Fspring-boot%2Fspring-boot-virtual-threads-vs-webflux.html" target="_blank">Spring Boot 虚拟线程与 Webflux 在 JWT 验证和 MySQL 查询上的性能比较</a></li></ul><blockquote><p>欢迎关注我的公众号：程序猿 DD。第一时间了解前沿行业消息、分享深度技术干货、获取优质学习资源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:02:42 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/didispace/blog/11044187</guid>
            <link>https://my.oschina.net/didispace/blog/11044187</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[芯片架构师 Jim Keller：英伟达的 CUDA 不是护城河，是沼泽]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>曾从事 x86、Arm、MISC 和 RISC-V 处理器研究的芯片架构师 Jim Keller 批评了英伟达的 CUDA 架构和软件技术栈，他认为 CUDA 是英伟达的沼泽而非护城河。</p><blockquote><p><strong>「CUDA 是沼泽，而不是护城河。x86 也是一片沼泽。[…] CUDA 并不美好，它是通过一次堆积一件东西来构建的。」</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-bb29c91be732d8384401f752fab63b43fa2.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fjimkxa%2Fstatus%2F1758943525662769498" target="_blank">https://twitter.com/jimkxa/status/1758943525662769498</a></u></em></p></blockquote><p>他指出，就连英伟达本身也有多个专用软件包，出于性能原因，这些软件包依赖于开源框架。</p><p>就像 x86 一样，CUDA 在保持软件和硬件向后兼容性的同时逐渐增加了功能。这确保英伟达的平台完整且向后兼容，但它影响了性能并使程序开发变得更加困难。同时，很多开源软件开发框架可以比 CUDA 更高效地使用。</p><p>Jim Keller 写道：「<strong><em>基本上没有人编写 CUDA，如果你确实编写 CUDA，它可能不会很快。[...] Triton、Tensor RT、Neon 和 Mojo 的存在是有充分理由的。</em></strong>」</p><p>甚至英伟达本身也有不完全依赖 CUDA 的工具。例如，Triton Inference Server 是英伟达的一款开源工具，可简化 AI 模型的大规模部署，支持 TensorFlow、PyTorch 和 ONNX 等框架。Triton 还提供模型版本控制、多模型服务和并发模型执行等功能，以优化 GPU 和 CPU 资源的利用率。</p><p>英伟达的 TensorRT 是一种高性能深度学习推理优化器和运行时库，可加速英伟达 GPU 上的深度学习推理。TensorRT 从各种框架（例如 TensorFlow 和 PyTorch）中获取经过训练的模型，并对其进行优化以进行部署，从而减少延迟并提高图像分类、对象检测和自然语言处理等实时应用程序的吞吐量。</p><p>尽管像 Arm、CUDA 和 x86 这样的架构可能会被认为是沼泽，因为它们的演进速度相对较慢、必须向后兼容并且体积庞大，但这些平台也不像 GPGPU 这样分散，这可能根本不是一件坏事。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:01:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279549</guid>
            <link>https://www.oschina.net/news/279549</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MariaDB 可能会以 3700 万美元被私有化]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">MariaDB 董事会<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businesswire.com%2Fnews%2Fhome%2F20240219857559%2Fen%2FAnnouncement-Regarding-Possible-Offer" target="_blank">确认</a>，已于 2024 年 2 月 15 日收到了来自加利福尼亚 K1 投资管理公司的临时收购要约。K1 于 2024 年 2 月 16 日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk1.com%2Fmeridian%2F" target="_blank">公开</a>宣布了这一要约。MariaDB 董事会正在审查可能要约并听取建议。</span></p><p><span style="color:#000000">这是一份非约束性的探索性提议，可能会根据未来几周的谈判进展而发生变化。该提议包括以每股 0.55 美元的价格购买所有 MariaDB 股票，按照该公司 2 月 5 日的收盘估值计算，约合 3700 万美元。</span></p><p><span style="color:#000000">拟定交易将通过爱尔兰法律安排计划进行，K1 或其附属公司将收购该公司 100% 的已发行股份。然而，K1 保留以合同要约的方式实施该提议的权利。尚未确定该提议将采取何种形式。</span></p><p><span style="color:#000000">值得一提的是，这一消息的发布正值该公司发生重大变化和动荡之际，新任首席执行官上任后，该公司进行了大规模裁员，并剥离了数据库即服务和地理空间业务。</span></p><p><img height="223" src="https://oscimg.oschina.net/oscnet/up-1da31f278849ce4cdcc7e6d0a823d84c4f4.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">2009 年，甲骨文公司斥资数十亿美元对 MySQL 进行了一系列收购，使 MySQL 实际上成为甲骨文公司的资产，MySQL 项目的创建者因此对 MySQL 的独立性产生了担忧，于是 MariaD B 在 15 年前作为 MySQL 的一个分支而出现。对于那些寻求完全开源的 MySQL 替代品的人来说，MariaDB 被认为是一个"drop-in"的替代品，并已被一些大公司用于在其应用程序中存储和处理数据。</span></p><p><span style="color:#000000">多年来，MariaDB 背后的商业实体筹集了大约 2.3 亿美元的风险资金，最终于 2022 年 12 月通过 SPAC 上市。但正如 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F19%2Fstruggling-database-company-mariadb-could-be-taken-private-in-a-37m-deal%2F" target="_blank">TechCrunch</a> 所指出，MariaDB 的上市远未取得巨大成功，从 2022 年底上市首日 4.45 亿美元的市值（与之前 D 轮融资时 6.72 亿美元的私有企业价值相比，市值本身已大幅下降）跌入常年低谷，自今年年初以来一直徘徊在 1 千万美元关口附近。</span></p><p><span style="color:#000000">纽约证券交易所曾在 9 月份警告 MariaDB，称其不符合上市规则 —— 该规则规定公司的全球平均市值在连续 30 天的交易期内不得低于 5000 万美元。在随后的几个月里，MariaDB 收到了第一份收购要约，来自其现有投资者 Runa Capital，初步报价为每股 0.56 美元现金。三周后，Runa 表示最终不会收购 MariaDB，而是由一家名为 RP Ventures 的公司提供 2650 万美元的贷款。</span></p><p><span style="color:#000000">今年二月初，MariaDB 宣布与债权人达成临时暂缓协议，即在寻求替代融资方案期间，债权人将不行使贷款协议中规定的任何补救措施。这一消息导致 MariaDB 的股价在几天内上涨了一倍多，这也是为什么 K1 的出价与宣布任何暂缓协议前 MariaDB 的收盘价相对应。</span></p><p><span style="color:#000000">事实上，K1 表示，它的报价比 MariaDB 2 月 5 日的收盘价（0.19 美元）高出 189%，相当于市值约为 1290 万美元。虽然不能保证 K1 会正式竞购 MariaDB，但与更像传统风险投资公司的 Runa Capital 不同，K1 在其 12 年的历史中拥有后期投资记录，这使其更接近私募股权投资领域。且 K1 已经进行了多次收购，包括在 2022 年斥资 3.19 亿美元收购澳大利亚 ELMO 软件公司，并在收购过程中将其私有化。</span></p><p><span style="color:#000000">因此，从很多方面来说，K1 可能比 Runa 更适合接管 MariaDB。根据爱尔兰收购规则第 2.6 条，K1 必须在 2024 年 3 月 29 日下午 5:00（纽约时间）（即 K1 公告后的第 42 天）之前，正式确定其收购要约或完全放弃该计划。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 02:36:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279540/mariadb-could-be-taken-private-37m-k1</guid>
            <link>https://www.oschina.net/news/279540/mariadb-could-be-taken-private-37m-k1</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[红帽改变发布 RHEL Beta 测试版本的更新策略]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>红帽<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.redhat.com%2Fen%2Fblog%2Fupcoming-improvements-red-hat-enterprise-linux-minor-release-betas" target="_blank">宣布</a></u>对 RHEL Beta 测试版本的更新策略进行改进。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1c1f35a138e6545bd30f1e3fb14505f82f2.png" referrerpolicy="no-referrer"></p><p>目前 RHEL 新版本正式发布之前，红帽大致提供了一个月的测试期。但红帽及其客户发现，长达一个月的 RHEL 测试期通常太短，意义不大。</p><p>从 RHEL 9.5 开始，<strong>红帽将开始更早且持续地发布"beta"软件包</strong>。在即将发布的次要版本完成初始测试后，这些软件包将开始推送到其测试版渠道。<strong>因此，它的测试期长达 4 个月，而不仅仅是 1 个月的周期</strong>。</p><p>但随着测试期的延长以及每周发布测​​试包更新，RHEL 次要版本测试版的安装介质（例如预构建的 ISO 和云/VM 镜像）将不再存在。</p><p>此更改仅影响 RHEL 9.5 及更高版本，并将持续到从 RHEL 10.1 开始的点版本。RHEL 8 或更早版本中的点版本更新都不会发生变化。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 02:28:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279538/red-hat-changes-beta-timing</guid>
            <link>https://www.oschina.net/news/279538/red-hat-changes-beta-timing</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中国大模型赛道最大单笔融资，月之暗面获超 10 亿美金融资]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>AI 初创公司月之暗面（Moonshot AI）最近完成了一轮超过 10 亿美金的融资，投资方包括红杉中国、小红书、美团和阿里，老股东也进行了跟投。这一轮融资使月之暗面的估值达到了约 25 亿美金，成为国内大模型领域的头部企业之一。这是自从 ChatGPT 引发全球热潮以来国内 AI 大模型公司获得的单轮最大金额融资。</p><p>月之暗面的上一轮融资为 2023 年获得的超 2 亿美金融资，投资方包括红杉中国、真格基金等。</p><p>月之暗面成立于 2023 年 3 月，迅速成为大模型领域的重要参与者。其核心团队成员曾参与 Google Gemini、Google Bard、盘古 NLP 和悟道等多个大模型项目的研发工作，拥有多年大模型研究和开发经验。目前，公司团队规模已超过 80 人。</p><p>根据官方介绍，Moonshot AI 是下一代跨模态大模型研发商，致力于研发下一代跨模态大模型。目前发明了 RoPE 相对位置编码，是 Meta LLaMa 和 Google PALM 等大多数主流模型的重要组成部分；发明了 group normalization，是 Stable Diffusion 等 AI 模型成功的关键组件。</p><p>公司创始人杨植麟是 90 后学霸，毕业于清华大学计算机系，师从唐杰教授，之后获得卡内基梅隆大学计算机博士学位，师从苹果公司现任 AI 负责人、深度学习奠基人之一 Ruslan Salakhutdinov，曾在 Facebook AI Research， Google Brain 从事自然语言处理研究，获 DREAM9 全球癌症预测大赛第一名，阿里巴巴天池大数据竞赛全球第二名，2017 Nvidia 先锋研究奖。于 ICLR、NIPS、ICML、KDD、ACL 等顶级 AI 会议发表论文二十余篇；在所有六个主流语言建模数据集保持世界第一名（State-of-the-art）。</p><p>2023 年 6 月，科技媒体 The Information 将杨植麟列为 「中国 OpenAI」 的五大候选人之一，表明了他在业界得到了高度认可，其余四位为 MiniMax、智谱 AI、光年之外以及澜舟科技。</p><p>自成立以来，月之暗面在短短不到一年的时间里，已经完成了从通用大模型到上层应用的全面布局。公司已经训练了千亿级别的自研通用大模型，并在 2023 年 10 月推出了面向 C 端的 Kimi 智能助手，这是公司首次尝试 To C 超级应用。</p><p>Kimi 智能助手支持 20 万汉字的长文本输入，主打无损记忆。「长文本（Long Context）」 是月之暗面当前主打的技术之一，这来源于团队希望突破大模型的落地瓶颈 —— 大模型的智慧之所以能 「涌现」，主要是因为通过扩大参数规模，突破到了千亿级别。</p><p>11 月，公司宣布其 Kimi Chat 聊天机器人面向全社会开放服务，用户可通过官网体验。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkimi.moonshot.cn%2F" target="_blank">https://kimi.moonshot.cn/</a></p><p><img height="261" src="https://oscimg.oschina.net/oscnet/up-e5902a7ff6a62c3a72f9c3ed663ad23e4ed.png" width="500" referrerpolicy="no-referrer"></p><p>杨植麟认为，在 B2C 领域，AI Native 将开辟新的流量渠道，它们有望成为 AI 时代的 Super App，带来巨大的商机。</p><p>据悉，月之暗面正在研发通用多模态模型，并预计在今年内推出，多模态模型是近期大模型创业公司的核心竞争点。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 10:31:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279462</guid>
            <link>https://www.oschina.net/news/279462</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[周鸿祎回应 2024 年 AI 行业十大预言，现已实现四个]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>中国企业家杂志独家对话了知名企业家、360 集团董事长周鸿祎，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1193725273%2FO1t4r21L4" target="_blank">共同探讨</a></u>了近期备受瞩目的 AI 技术 Sora 所带来的重大影响。在被问及如何看待年初提出的 AI 十大预言时，周鸿祎兴奋地表示，目前已经有四个预言得以实现，分别是<strong>开源大模型爆发、大模型运行在终端、文生图和文生视频取得突破性进展、多模态成为大模型标配</strong>。周鸿祎认为，特别是 Sora 的出现让他感到很意外，发展得很快。</p><p>附周鸿祎此前提出的 AI 十大预言：</p><ol><li>大模型无处不在，成为数字系统标配；</li><li><strong>开源大模型爆发；</strong></li><li><strong>"小模型"涌现，运行在更多终端；</strong></li><li>大模型企业级市场崛起，向产业化、垂直化方向发展；</li><li>Agent 智能体激发大模型潜能，成为超级生产力工具；</li><li>2024 年是大模型应用场景之年，To C 出现杀手级应用；</li><li><strong>多模态成为大模型标配；</strong></li><li><strong>文生图、文生视频等 AIGC 功能突破性增长；</strong></li><li>具身智能赋能人形机器人产业蓬勃发展；</li><li>大模型推动基础科学取得突破。</li></ol><hr><p>周鸿祎前几天在微博<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1708942053%2FO0Sivblel" target="_blank">发表</a></u>了对 Sora 的看法，他认为 Sora 的诞生意味着 AGI（通用人工智能）实现可能从 10 年缩短至一两年。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9cbd9c40a32b414d55590e86ad84c498a87.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 08:16:08 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279421</guid>
            <link>https://www.oschina.net/news/279421</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[字节跳动推出中文版「Sora」？回应来了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">近日，市场有消息称，在 Sora 引爆文生视频赛道之前，国内的字节跳动也推出了一款新型视频模型 Boximator，与 Gen-2、Pink1.0 等既有模型相比，Boximator 的独特之处在于，它能够通过文本输入精确地控制视频中人物或物体的运动。</span></p><p><span style="color:#000000">2 月 20 日，字节跳动相关人士回应称，Boximator 是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</span></p><p><span style="color:#333333">Sora 是 OpenAI 于日前发布的首个视频生成模型。可根据文本描述生成长达 60 秒的视频，其中包含精细复杂的场景、生动的角色表情以及复杂的镜头运动。OpenAI 在技术报告介绍道，</span><strong style="color:#333333">他们将 Sora 视频生成模型视作世界模拟器</strong><span style="color:#333333">。具体来说就是通过跨越不同持续时间、宽高比和分辨率的视频和图像，从而生成最高可达一分钟的高清视频。</span></p><p><img height="274" src="https://oscimg.oschina.net/oscnet/up-80cdbef18c0af0f443e5c577f0b8b7d9f0d.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Sora 使用了一种特殊的深度学习模型（即 Transformer）来处理视频和图像数据。这种处理方式首先将视频和图像编码成潜在代码，然后将这些代码分解成包含时间和空间信息的小块（即时空补丁），最后利用 Transformer 模型在这些补丁上进行操作。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">这样的处理方法能够有效地捕捉和生成视频和图像数据中的复杂时空动态，为生成高质量的视频和图像提供了一种强大的方法。</p><p><strong>相关阅读：</strong></p><ul><li><a href="https://www.oschina.net/news/278821/openai-text-to-video-sora" target="_blank">OpenAI 发布文本生成视频模型 Sora</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 08:00:14 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279411</guid>
            <link>https://www.oschina.net/news/279411</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Dart 3.3 发布：扩展类型、JavaScript Interop 等]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Dart 3.3 现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2Fdartlang%2Fdart-3-3-325bf2bf6c13" target="_blank">发布</a>，公告称此版本改变了性能和跨平台开发的游戏规则。</p><p>增强的扩展类型（Extension Types）将彻底改变性能优化以及用户与本地代码的交互方式。JavaScript interop 模型也得到了改进，引入了强大的类型安全性和开发人员友好的方式来利用 Web 平台的强大功能。「<strong>所有这些都为 WebAssembly 支持铺平了道路</strong>」。此外，新版本还增加了 Google AI 功能。</p><p><img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-3949a01f3c180246795018315421f62eccc.webp" width="300" referrerpolicy="no-referrer"></p><h4><strong>扩展类型</strong></h4><p>扩展类型引入了类型的零成本 wrappers，使用它们可以优化对性能敏感的代码，尤其是在与 host&nbsp;平台交互时，扩展类型提供了具有特定成员自定义类型的便利性，同时消除了典型的 wrappers 分配开销。</p><pre><span style="color:#aa0d91">extension</span> type Wrapper(<span style="color:#5c2699">int</span> i) {
  <span style="color:#aa0d91">void</span> showValue() {
    <span style="color:#5c2699">print</span>(<span style="color:#c41a16">'my value is <span style="color:#000000">$i</span>'</span>);
  }
}

<span style="color:#aa0d91">void</span> main() {
  <span style="color:#aa0d91">final</span> wrapper = Wrapper(<span style="color:#1c00cf">42</span>);
  wrapper.showValue(); <span style="color:#007400">// Prints 'my value is 42'</span>
}</pre><p style="color:#242424; margin-left:0; margin-right:0; text-align:start">以上示例<span style="color:#2b2b2b">实现了一个&nbsp;</span><strong><code>Wrapper</code></strong><span style="color:#2b2b2b">&nbsp;扩展类型，但将其用作普通的 Dart 类型，在实际使用里，开发者可以实例化它并调用函数。主要区别在于 Dart 将其编译为普通 Dart&nbsp;</span><strong><code>int</code></strong><span style="color:#2b2b2b">&nbsp;类型，扩展类型允许</span><span style="color:#000000">创建具有唯一的成员类型，而无需分配典型 wrappers 类型的间接成本。因此，虽然&nbsp;&nbsp;extension members&nbsp;功能（Dart 2.7 开始）允许向现有类型添加函数和属性，但扩展类型功能也可以执行相同的操作，并且还允许定义隐藏底层表示的新 API。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#242424">这对于与 host&nbsp;平台的交互特别有用。可以直接使用 Native types，无需创建 wrappers&nbsp;和相关的间接成本，同时还能提供简洁的 Dart API。有关扩展类型的更多信息，可参阅<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fdart.dev%2Flanguage%2Fextension-types" target="_blank">新文档</a>。</span></p><h4><strong>不断发展的 JavaScript Interop</strong></h4><p>Dart 3.3 引入了一种与 JavaScript 库和 Web 互操作的新模型。它从一组用于与 JavaScript 交互的新 API 开始：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapi.dart.dev%2Fdart-js_interop%2Fdart-js_interop-library.html" target="_blank">dart:js_interop</a>&nbsp;库。现在，Dart 开发人员可以访问&nbsp;typed API 来与 JavaScript 交互。该 API 通过静态强制明确定义了两种语言之间的边界。这在编译之前消除了一整类问题。除了用于访问 JavaScript 代码的新 API 之外，Dart 现在还包含一个新模型，用于使用扩展类型在 Dart 中表示 JavaScript 类型。</p><pre><span style="color:#aa0d91">import</span><span style="color:#c41a16">'dart:js_interop'</span>;

<span style="color:#007400">/// Represents the `console` browser API.</span><span style="color:#aa0d91">extension</span> type MyConsole(JSObject _) <span style="color:#aa0d91">implements</span> JSObject {
  <span style="color:#aa0d91">external</span><span style="color:#aa0d91">void</span> log(JSAny? value);
  <span style="color:#aa0d91">external</span><span style="color:#aa0d91">void</span> debug(JSAny? value);
  <span style="color:#aa0d91">external</span><span style="color:#aa0d91">void</span> info(JSAny? value);
  <span style="color:#aa0d91">external</span><span style="color:#aa0d91">void</span> warn(JSAny? value);
}</pre><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#242424">基于 extension types 的语法比 extension members 允许更多的表达和健全性。这简化了 Dart 中 JavaScript API 的利用。了解更多信息，可参阅<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdart.dev%2Finterop%2Fjs-interop" target="_blank">有关 JS interop 的新文档</a>。</span></p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><strong>改进 browser libraries</strong></h4><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#242424">从 1.0 版本开始，Dart SDK 就包含了一套全面的 browser libraries。其中包括核心&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapi.dart.dev%2Fdart-html%2Fdart-html-library.html" target="_blank">dart:html</a>&nbsp;库以及 SVG、WebGL 等库。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#242424">改进的 JavaScript interop 模型提供了重新构想这些库的机会。</span><span style="color:#2b2b2b">未来 browser libraries&nbsp;</span><span style="color:#242424">支持将集中在&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpub.dev%2Fpackages%2Fweb" target="_blank">package:web</a>&nbsp;上。这简化了版本控制、加速了更新并与&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2F" target="_blank">MDN</a>&nbsp;资源保持一致。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#242424">且这一系列的改进导将推动：将 Dart 编译为&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwebassembly.org%2F" target="_blank">WebAssembly</a>。</span></p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><strong><span style="color:#242424">开启 WebAssembly 的未来</span></strong></h4><p style="margin-left:0px; margin-right:0px; text-align:start">Dart 3.3 为 WebAssembly 的 Web 应用奠定基础，虽然 Flutter Web 中的 WebAssembly 支持仍处于试验阶段，<span style="color:#242424">但团队正在努力稳定实现。</span></p><p style="margin-left:0px; margin-right:0px; text-align:start">要使用 WebAssembly 在 Web 上运行 Flutter 应用，需要使用新的 JavaScript Interop 机制和&nbsp;<code>package:web</code>&nbsp;，旧版 JavaScript 和 browser libraries 保持不变，并支持编译为 JavaScript 代码。但是，编译为 WebAssembly 需要迁移。详情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdart.dev%2Fgo%2Fpackage-web" target="_blank">迁移指南</a>。</p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><strong><span style="color:#242424">Google AI Dart SDK</span></strong></h4><p style="margin-left:0px; margin-right:0px; text-align:start">谷歌发布了 Google AI Dart SDK 测试版。用户可以将生成式 AI 功能构建到 Dart 或 Flutter 应用程序中。这些应用程序使用了谷歌最新的 AI 模型系列 Gemini。可查看软件包&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpub.dev%2Fpackages%2Fgoogle_generative_ai" target="_blank">google_generative_ai</a>。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><img height="130" src="https://oscimg.oschina.net/oscnet/up-904498ac3cf1c5073e4d35bfc96bb71743c.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2Fdartlang%2Fdart-3-3-325bf2bf6c13" target="_blank">查看官方博客</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 06:48:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279389/dart-3-3-released</guid>
            <link>https://www.oschina.net/news/279389/dart-3-3-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：目前还没有「大模型版 Linux」；nginx 核心开发者创建新分支]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.19</strong></span></h3><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要点</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/278819/nginx-forked-freenginx" target="_blank">核心 Nginx 开发者创建新分支 Freenginx</a></u></h3><p>作为 Nginx Web 服务器的长期核心开发人员之一，Maxim Dounin 宣布创建该项目的一个新分支，名为 Freenginx。</p><p>Maxim Dounin 决定分叉 Nginx 是因为与 F5 发生了分歧，F5 于 2019 年收购了 Nginx 公司。Dounin 在宣布 Freenginx 时表示将不再参与由 F5 负责的 nginx 开发。取而代之的是启动另一个项目，由开发人员而非公司实体来运营。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3488ed2ae05fcc308c3b208aa3bfbebd210.png" referrerpolicy="no-referrer"></p><h3><u><a href="https://www.oschina.net/news/279147/magika-ai-powered-type-identification" target="_blank">谷歌开源 Magika —— AI 驱动的文件类型检测工具</a></u></h3><p>谷歌开源了由 AI 驱动的文件内容类型识别工具，声称能够在毫秒级内精确识别超过 100 种不同文件类型，无论是二进制文件还是文本文件。Magika 是基于深度学习技术的文件类型识别系统，用于准确检测二进制和文本文件类型。在底层，Magika 采用定制的、高度优化的深度学习模型，即使在 CPU 上运行，也能在几毫秒内实现精确的文件识别。</p><p>在谷歌内部，Magika 被用于提升用户安全，帮助对 Gmail、Drive 和安全浏览中的文件进行安全检查和内容策略扫描。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5f0a4182522f53b7a69907f3cff050925ff.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日观察</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-c204357960927dcfcfa94bea7bede0ce869.png" referrerpolicy="no-referrer"></p><blockquote><p>很多人看着各种大模型开源了之后就觉着下个开源时代来了，我认为目前的大模型跟开源社区的最终发展结果是相悖的。早期开源运动兴起时，个人主机和廉价冗余服务器逐渐普及，软件的核心是代码，开放代码之后，所有人都可以在此基础上进行修改、部署和分发；而目前的大模型则依赖于数据和算力，集市模式的开源社区很难具备两个条件。</p><p>因此，目前的大模型开源运动更像是几个巨型公司找了社区这么个的外包组织，虽然大家干的都很红火，但能提供模型本身的依然只有几个公司，能提供模型服务的，也都是商业公司，而不是开发者或者终端用户。最终当大模型的生态平稳之后，社区很难直接拥有大模型的关键技术。<br><br> - 微博 <em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1809500942%2FO14ohCDQJ" target="_blank">&nbsp;axb 的自我修养</a></u></em></p></blockquote><blockquote><p>「套壳」只是中国大模型产业现状的冰山一角，这背后折射出产业发展的五个问题，它们之间互为因果，每个问题都无法独立解决。</p><ul><li>模型：原创、拼装还是套壳？</li><li>算力：卡脖子还是不想买？</li><li>数据：低质数据怎么解决？</li><li>资本：只有资本短视吗？</li><li>商业化：谁是合适的买单人。</li></ul><p>- 财经十一人 <em>《<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2Fttarticle%2Fp%2Fshow%3Fid%3D2309405002841407488086" target="_blank"><strong>中国大模型产业的五个真问题</strong></a></u>》</em></p></blockquote><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推荐</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-5064f005dfe68164213affe8f74aeffb692.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">开源之声</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-b13ece2ded33000fc7c2b96deef4a7c0df2.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日项目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜单：</p><p><img src="https://oscimg.oschina.net/oscnet/up-e5c538c2846376405aef6d023e59a916f2f.png" referrerpolicy="no-referrer"></p><blockquote><h4><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span><br><em><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC011%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></u></em></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></u></li><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf" target="_blank">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></u></li><li><u><a href="https://www.oschina.net/news/277585" target="_blank">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></u></li><li><u><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">开源日报第 006 期：选择技术栈一定要选择开源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 03:44:19 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279351</guid>
            <link>https://www.oschina.net/news/279351</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Steam Audio SDK 完整源代码现已开源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Steam 社区<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsteamcommunity.com%2Fgames%2F596420%2Fannouncements%2Fdetail%2F7745698166044243233" target="_blank">公告称</a>，随着 Steam Audio 最新版本（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FValveSoftware%2Fsteam-audio%2Freleases%2Ftag%2Fv4.5.2" target="_blank">v4.5.2</a>）的发布，Steam Audio SDK 的完整源代码现已开源。这是 Steam Audio SDK 源代码的第一个开源版本。</span></p><p><span style="color:#000000">「通过此版本，我们的目标是为开发人员提供更多的控制权，从而为用户带来更好的体验，并希望为使用 Steam Audio 的更广泛的开发者社区做出有价值的贡献。」</span></p><p><span style="color:#000000">整个 Steam Audio 代码库，包括 SDK 和所有插件，现已在 Apache 2.0 许可证下发布。开发人员可以在商业产品中使用 Steam Audio，并根据自己的许可条款修改或重新分发它，而无需包含源代码。</span></p><p><span style="color:#000000"><img alt="" height="270" src="https://oscimg.oschina.net/oscnet/up-05ddfd635cb1684b81ccf53468f07d2f90f.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">官方表示，在获取了大量来自社区提供的对开源插件（Unity、Unreal 和 FMOD Studio）的有价值的反馈和贡献之后，他们决定做出这一开源举措，以希望将同样的优势带到核心 SDK 中。此举将使得开发人员能够根据自己的需求定制 SDK，并为使用该技术的每个人提供更好的体验。</span></p><blockquote><p><span style="color:#000000">我们所从事的功能的选择通常是由内部项目的需求驱动的。例如，在开发 Half-Life 期间，我们花了大量时间开发混合混响和路径功能，并将其作为 Steam Audio 4.0.0 的一部分发布。</span></p><p><span style="color:#000000">但这些优先事项可能并不总是与合作伙伴的优先事项一致，因此我们希望消除阻碍合作伙伴实施需要访问核心 Steam Audio SDK 的空间音频功能的障碍。例如，我们可能正在修复 Steam Audio 中影响内部项目的性能问题，但合作伙伴可能需要将 Steam Audio 移植到控制枱平台。</span></p><p><span style="color:#000000">将整个 SDK 作为开源提供给合作伙伴，可以让他们自己管理移植工作，并根据自己的需要进行优化，同时还允许他们在需要时将自己的修改意见反馈回来。</span></p></blockquote><p><span style="color:#000000">接下来，项目团队还将继续对 Steam Audio 进行持续改进，包括发布错误修复和新功能。&nbsp;</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 03:19:34 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279335/steam-audio-sdk-opensource</guid>
            <link>https://www.oschina.net/news/279335/steam-audio-sdk-opensource</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 内核成为 CVE 编号机构 (CNA)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linux 内核已被接受为 CVE 编号机构 (CNA)，这意味着他们将直接管理内核的 CVE。Linus Torvalds 近日在邮件列表<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3Dwi8vZD7EXZfob-yhfDERyfzWxzMOzG9FsOuaKU-v6%2BPHA%40mail.gmail.com%2FT%2F%23u" target="_blank">发布</a></u>了 Linux 6.8-rc5，并介绍称文档添加了 CVE 漏洞处理相关的指南。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-7db09f50c2a2dac5a652d9899693a817661.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Ftorvalds%2Flinux.git%2Fdiff%2FDocumentation%2Fprocess%2Fcve.rst%3Fid%3D5928d411557ec5d53832cdd39fc443704a3e5b77" target="_blank">CVE 文档页面</a></u></em></p></blockquote><p>文档写道，Linux 内核开发团队有能力为潜在的内核安全问题分配 CVE，而分配的 CVE 编号将在 linux-cve-announce 邮件列表上公布，<strong>修复的安全漏洞才会分配 CVE 编号，未修复的不会自动分配编号</strong>。</p><blockquote><p><img height="1156" src="https://oscimg.oschina.net/oscnet/up-2da79e81f6f9140a562eeb928a92757fe7e.png" width="1400" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flinux-cve-announce%2F" target="_blank">https://lore.kernel.org/linux-cve-announce/</a></u></em></p></blockquote><p>CVE 是通用漏洞披露 (Common Vulnerabilities and Exposures) 的英文缩写，列出了已公开披露的各种计算机安全缺陷。CVE 识别号由 CVE 编号管理机构&nbsp;(CNA) 分配。</p><p>任何人都可以从任何地方进行 CVE 报告。无论是供应商、研究人员或是个人用户，都有可能发现缺陷，并促使他人予以关注。很多供应商都会提供错误报告奖励，以鼓励相关人员负责任地披露各种安全问题。</p><p>在 Linux 内核成为 CNA 之前，它无法自行管理内核的 CVE 漏洞编号分配。由于内核是系统的底层，几乎任何错误都可能被用于危害内核安全，但当错误被修复时，被利用的可能性通常不明显。过去 CNA 过于谨慎，几乎为发现或收到的任何安全漏洞分配了 CVE 编号，导致 Linux 内核团队需要花费大量时间处理许多未造成重大影响的漏洞。</p><p>因此接下来 Linux 内核中未修复的安全漏洞不会提前分配 CVE 编号，只有在漏洞被修复后才会分配 CVE 编号，这样可以通过正确的方式来追踪原始修复的 git commit ID。</p><p>延伸阅读：<u><em><a href="https://www.oschina.net/news/276167/curl-is-a-cna" target="news">curl 项目已被接受为 CVE 编号机构 (CNA)</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 02:59:34 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279326/linux-kernel-is-a-cna</guid>
            <link>https://www.oschina.net/news/279326/linux-kernel-is-a-cna</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2026 年传统搜索引擎流量将下降 25%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">市场分析公司 Gartner <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gartner.com%2Fen%2Fnewsroom%2Fpress-releases%2F2024-02-19-gartner-predicts-search-engine-volume-will-drop-25-percent-by-2026-due-to-ai-chatbots-and-other-virtual-agents" target="_blank">指出</a>，生成式 AI 已严重威胁传统搜索引擎。预测到 2026 年，传统搜索引擎的流量将下降 25%，搜索营销的市场份额将被人工智能聊天机器人和其他虚拟代理所取代。</span></p><p><img height="261" src="https://oscimg.oschina.net/oscnet/up-a7078c146496ef4a1ec0a21edf9088d52e3.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Gartner 副总裁分析师 Alan Antin 称，有机搜索和付费搜索是科技营销人员实现认知和需求生成目标的重要渠道。GenAI 解决方案正在成为替代答案引擎，取代以前可能在传统搜索引擎中执行的用户查询。随着 GenAI 越来越深入企业的方方面面，这将迫使企业重新思考其营销渠道战略。</span></p><blockquote><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">随着 GenAI 推动降低内容制作成本，包括关键字策略和网站域名权威评分在内的各项活动都将受到影响。搜索引擎算法将进一步重视内容的质量，以抵消人工智能生成内容的数量，因为内容的实用性和质量仍然是有机搜索结果成功的关键。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">此外，还将更加重视水印和其他验证高价值内容的手段。全球各地的政府法规已经开始要求公司对人工智能创建的营销内容资产承担责任。这很可能会对搜索引擎如何显示此类数字内容产生影响。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">公司需要专注于制作对客户和潜在客户有用的独特内容。内容应继续展示搜索质量评估者的要素，例如专业知识、经验、权威性和可信度。</span></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 02:26:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279308/gartner-search-engine-2026-ai</guid>
            <link>https://www.oschina.net/news/279308/gartner-search-engine-2026-ai</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Zilliz Cloud 再发新版本：性能提升超 10 倍，AI 应用开发流程再简化！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Zilliz Cloud 再发新版本！</p><p>本次新版本的主要内容包括：大幅提升的向量搜索性能（性能提升 10 倍以上）、企业级数据安全和无缝数据集成。新版本发布后，用户无需自定义代码，便可快速顺畅地完成非结构化数据处理和索引。此外，Zilliz Cloud 将有效帮助用户节省成本，简化支付和采购流程。</p><p>以下为本次发布的新特性一览：</p><ul><li><p>Cardinal 搜索引擎</p></li><li><p>Zilliz Cloud 正式升级至 Milvus 2.3 版本</p></li><li><p>基于角色的访问控制和权限管理（RBAC）</p></li><li><p>Databricks Connector</p></li><li><p>支持 Google Cloud Marketplace 订阅</p></li><li><p>其他数据安全方面更新</p></li></ul><p><img src="https://assets.zilliz.com/cms-cn/640_2024_02_19_T165818_906_45850c7576.png" alt="" referrerpolicy="no-referrer"></p><h2>01. Cardinal 搜索引擎：搜索速度提升 10 倍，数据容量提升 50%</h2><p>Cardinal 是用现代 C++ 语言和实用的近似最近邻搜索（ANNS）算法构建的多线程、高效率向量搜索引擎。它同时能够处理暴搜请求和 ANNS 索引修改请求；处理各种数据格式，包括 FP32、FP16 和 BF16。Cardinal 搜索引擎强调速度和效率，能够在有限的资源内处理更多用户请求。</p><p>在推动 Cardinal 引擎创新的过程中，我们始终坚持推动异构计算的原则。团队对算法进行调优，采用了针对计算密集型操作优化的 low-level 内核，并确保支持多种硬件，包括 x86 和 ARM。Cardinal 利用 x86 的 AVX-512 扩展和 ARM 的 NEON 及 SVE 指令集等尖端技术，提供针对高效计算优化的代码。这些改进保证了 Cardinal 能够时刻全力运行，是行业内最快的向量搜索引擎。</p><p>有了 Cardinal 搜索引擎的加持，Zilliz Cloud 实现了 10 倍性能提升（与开源 Milvus 相比），能够实现超快的查询速度外加高召回率。无论是处理大型数据集还是对快速响应有高要求，Cardinal 都能为此保驾护航，提升用户体验，提升 AI 应用的竞争力。</p><p>「Zilliz Cloud 的性能给我们留下了深刻的印象，它在数据负载大的情况下尤为出色！」Picdmo 的 CEO 兼创始人 Alex Alexander 称赞道，「采用 Cardinal 搜索引擎后，Zilliz Cloud 性能比上一个版本提升了 2 倍，搜索查询的速度和效率更惊人！此外，Zilliz Cloud 还提供增强数据安全保障。得益于 Zilliz Cloud，我们搭建的以图搜图应用功能变得更强大了。」</p><h2>02. 开箱即用的 Milvus 2.3：生产就绪的高级向量搜索功能</h2><p>经过为期 4 个月的 Beta 阶段后，Zilliz Cloud 正式上线了和 Milvus 2.3 相同的功能。目前，Zilliz Cloud 用户可以在生产环境中使用全新的高级向量搜索和数据管理功能。新版本功能包括：</p><ul><li><p>Cosine 相似度类型： 无需向量归一化，简化数据搜索流程。</p></li><li><p>Upsert 数据：提升更新和删除数据的管理流程效率，适用于频繁更新数据且追求数据一致性和原子性的场景。</p></li><li><p>范围搜索（Range Search）: 通过限制查询向量与其他向量之间的距离，范围搜索能够实现对搜索结果的有效细化，适用于搭建推荐引擎的场景。</p></li><li><p>支持 Parquet 文件：提升数据处理能力，支持 Parquet 文件，通过其高效的列式存储格式，提供更好的查询性能，适用于具有复杂数据集的场景。</p></li><li><p>支持 Array 数据类型：支持在搜索过程中基于多个属性进行精确的元数据过滤。在电商领域中，该功能支持根据不同产品标签进行搜索，为用户返回相关的搜索结果。</p></li></ul><h2>03. RBAC: 对数据访问进行细粒度的控制</h2><p>Zilliz Cloud 的 RBAC（角色权限访问控制）功能提供了一种结构化和可扩展的方法来管理数据访问权限，保障数据安全。在过去的几个月中，我们新增了多项相关功能，进一步打磨了 Zilliz Cloud 的 RBAC 系统，使其比市面上所有向量数据库都更加细致和全面。</p><p>RBAC 分为两层：控制层和数据层。在控制层，角色管理集群、项目、用户和计费等资源的操作权限。Zilliz Cloud 在控制层设有 4 种角色，其中组织管理员、项目所有者和项目成员是 3 种常用角色：</p><ul><li><p>组织管理员：拥有组织管理权限，包括管理组织设置、支付方式、账单、组织 API 密钥等。此外组织管理员还具备所有组织下资源（如：项目）的管理权限。</p></li><li><p>项目管理员：拥有项目管理权限，包括项目设置、项目内所有集群、项目 API 密钥等资源。</p></li><li><p>项目成员：拥有项目读写权限，包括读写项目下所有集群、查看项目下所有集群详情、管理 Collection 和索引等。</p></li></ul><p>在数据层面，角色权限是指在集群中添加、删除、修改和访问数据的能力。Zilliz Cloud 在数据层级提供了 3 种内置角色：管理员（Admin）、只读（Read-Only）和读写（Read-Write），不同角色对集群数据的读写和管理权限不同。此外，Zilliz Cloud 允许用户创建自定义角色，针对特定 Collection、Partition 或操作分配相应权限，确保数据安全。</p><p>通过 RBAC 功能，企业用户可以实现对数据访问进行细粒度的控制，提高数据安全性和合规性，同时促进团队间的协作，并确保用户根据其角色和职责拥有对应的访问权限和级别。</p><h2>04. Databricks Connector：简化 AI 应用的开发过程</h2><p>Zilliz 一直致力于为用户提供开箱即用的数据集成解决方案，近期，我们便通过引入 Confluent 和 Airbyte Connector，扩展了 Zilliz Cloud 数据对接和转换能力。本次版本更新，Zilliz Cloud 再次放大招，集成 Databricks Connector，为 Zilliz 向非结构化数据平台的发展打下了坚实的基础。</p><p>具体来看，Databricks Connector 提供了一套简单的数据迁移和转换解决方案，简化了 AI 应用的开发过程。无论是你的团队在研究 ML 并希望更新 Embedding 模型，还是作为个人用户希望直接将 data frame 记录从 Spark 上传至 Milvus，灵活的 Databricks Connector 都能一一满足。</p><p><img src="https://assets.zilliz.com/cms-cn/640_2024_02_19_T165827_910_2d9e7b4d3d.png" alt="" referrerpolicy="no-referrer"></p><p>此外，通过 Databricks Connector，用户就可以通过两种方式将数据导入到 Zilliz Cloud：流式处理（适用于实时更新）或批处理（适用于大型数据集）。访问链接 （<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com%2Fdatabricks_zilliz_demos" target="_blank">https://zilliz.com/databricks_zilliz_demos</a>）了解更多细节。</p><h2>05. 支持 GCP Marketplace 订阅: 简化支付和采购流程</h2><p>Zilliz Cloud 现已集成 GCP Marketplace，为开发者提供无缝的体验。用户可以直接用 Google Cloud 账号在 Marketplace 中购买 Zilliz Cloud，并根据自己的项目进展情况，按需扩展自己的集群并支付费用。此外，大家可以在 Zilliz Cloud 的操作界面中设置 GCP Marketplace 作为支付方式，或直接通过 GCP Marketplace 订阅。</p><h2>06. 其他数据安全方面更新</h2><p>Zilliz Cloud 已经通过了 SOC 2 Type II 和 ISO 27001 数据合规认证。我们始终致力于维持最高数据安全标准，为用户在 Zilliz Cloud 的体验保驾护航。</p><p>立即注册 Zilliz Cloud（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.zilliz.com.cn%2Fsignup" target="_blank">https://cloud.zilliz.com.cn/signup</a>）即可享受 30 天免费试用。如果在使用过程中遇到任何问题，欢迎通过 Zilliz Cloud 支持中心（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.zilliz.com.cn%2Fhc%2Fzh-cn" target="_blank">https://support.zilliz.com.cn/hc/zh-cn</a>）联系我们。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 20 Feb 2024 01:53:27 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/11044004</guid>
            <link>https://my.oschina.net/u/4209276/blog/11044004</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
