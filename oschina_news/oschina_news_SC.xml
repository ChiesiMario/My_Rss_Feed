<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 02 Dec 2023 17:58:24 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[算力基础设施领域国家标准发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0">2023 年 11 月 27 日，国家标准 GB/T 43331-2023《互联网数据中心（IDC）技术和分级要求》正式发布。中国信息通信研究院（简称「中国信通院」）联合多家企事业单位编制的这一国家标准正契合当前国家算力基础设施建设和算力产业高质量发展需要。</p><p style="margin-left:0; margin-right:0"><img alt="" height="292" src="https://oscimg.oschina.net/oscnet/up-cc1753c1d4186d7e0e332aeaa3974d09ff3.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">该标准规定了互联网数据中心（IDC）在绿色、可用性、安全性、服务能力、算力算效、低碳等六大方面的技术及分级要求，适用于互联网数据中心（IDC）的规划、设计、建设、运维和评估，期望更好的为不同行业深化赋能作用。</p><p style="margin-left:0; margin-right:0">2013 年以来，中国信通院云计算与大数据研究所数据中心团队基于中国通信标准化协会编制发布了数项数据中心评级通信行业标准，对数据中心的绿色、可靠和安全性进行分级分类。经过多年实践迭代，团队联合业界众多使用方、设计方和供应方共同编制了该国家标准，以期更好地指导我国数据中心的健康发展。</p><p style="margin-left:0; margin-right:0">高能效一直是数据中心发展过程中广受关注的问题，该国家标准将在绿色技术应用和运维制度管理等方面提出促进数据中心能效水平提升的具体要求；服务能力是数据中心对外服务的综合体现，通过对服务能力的客观评价，有利于数据中心的自我改进提升，也有利于客户根据业务需求选择合适的数据中心；可用性方面，通过提高设备冗余，可以在架构方面更好地保障数据中心应对突发情况的能力；安全性有助于保障数据中心设备运行及人员的安全。通过综合评估数据中心等级情况，有利于运营者加强自我了解，更有利于行业按需选择。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 08:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269062</guid>
            <link>https://www.oschina.net/news/269062</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国产编程语言 MoonBit（月兔）需要支持中文关键字吗？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>MoonBit（月兔）是中国开发者团队创建的编程语言，由粤港澳大湾区数字经济研究院（IDEA 研究院）基础软件中心负责人张宏波领导的团队开发。</p><p>张宏波本人不仅为多种编程语言做出了贡献，包括 OCaml、ReScript（原 ReasonML/BuckleScript）和 Flow，还曾是 Rescript 语言工具链几乎所有关键组件的作者，包括高速编译器、标准库以及构建系统等。</p><blockquote><p>MoonBit 专为云计算、边缘计算设计，是一个用于云计算和边缘计算的 WebAssembly 端到端编程语言工具链，集开发、编译、测试、部署于一体 —— 涵盖了通用程序语言设计、编译器、构建系统、IDE、部署工具等。在语言设计、编译器和构建系统上实现高度的垂直整合，为用户提供更佳的开发体验和性能，致力打造未来世界级的基础软件生态。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8f1d876877f96c97b9e12b93fb1fef4c7ec.gif" referrerpolicy="no-referrer"></p></blockquote><p>昨天，张宏波在知乎发表提问：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F632589892" target="_blank">《MoonBit 国产编程语言提供中文关键字的可能性？》</a></u>，希望收集一些关于为 MoonBit 提供中文关键字支持的反馈，主要是有两方面考虑：一是支持中文关键字从社区来说会带来什么潜在的负面作用？另外就是了解下真实的中文编程用户有多少。</p><p>张宏波说道：</p><blockquote><p>对于专业人士来说，中文确实不是学习编程的主要难点，但是从讨论热烈的程度来说，好像对一部分人来说或多或少是个门槛。<strong>从技术实现来讲，可能就是一个上午就能大概支持了</strong>。</p><p>我提这个问题是想从两方面收集一些反馈：<strong>一方面是支持中文关键字从社区来说会带来什么潜在的负面作用？另一方面是了解下真实的中文编程用户有多少，你会因问 MoonBit 支持中文关键字而更多地使用或者推荐给其他人吗？</strong></p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-11a36224f77741f56eab1b317a5008a9d60.png" referrerpolicy="no-referrer"></p><p>下面是用 MoonBit 语言实现<code>fib</code>函数的示例代码：</p><pre><code>// Moonbit
func fib(num : Int) -&gt; Int {
  fn aux(n, acc1, acc2) {
    match n {
      0 =&gt; acc1
      1 =&gt; acc2
      _ =&gt; aux(n - 1, acc2, acc1 + acc2)
    }
  }

  aux(num, 0, 1)
}
</code></pre><p><strong>延伸阅读：</strong></p><ul><li><strong><em><u><a href="https://www.oschina.net/news/255951/moonbit-first-announce" target="_blank">中国开发者团队创建的编程语言：MoonBit（月兔）</a></u></em></strong></li><li><strong><em><u><a href="https://www.oschina.net/project/awesome?columnId=20" target="_blank">中国人主导编程语言列表</a></u></em></strong></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 08:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269052</guid>
            <link>https://www.oschina.net/news/269052</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AWS 全面推出适用于 Rust 和 Kotlin 的 SDK]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">自 2021 年 12 月首次公开预览两年后，AWS 宣布已全面推出适用于 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fblogs%2Fdeveloper%2Fannouncing-general-availability-of-the-aws-sdk-for-rust%2F" target="_blank">Rust</a> 和 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fblogs%2Fdeveloper%2Faws-sdk-for-kotlin-ga%2F" target="_blank">Kotlin</a> 的 SDK 并支持生产使用。&nbsp;</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">官方介绍称，</span>AWS SDK for Rust 提供了惯用的类型安全 API；以及涵盖了 Rust 语言的优势，例如性能、可靠性和生产力。该 SDK 支持 async/await、非阻塞 IO 和构建器等现代 Rust 语言特性。并提供对 300 多个 AWS 服务的访问，每个服务都有自己的 &nbsp;crate；项目团队后续计划将继续增加对新服务和功能的支持。</span></p><p><span style="color:#000000">该 SDK 使用合理的默认值开箱即用，但它也是可扩展的，允许用户根据自己独特的用例对其进行自定义。SDK 是模块化的，允许客户仅为他们使用的服务编译 crate。它的设计速度也很快。借助 Rust SDK，用户可以在 Amazon Simple Storage Service (Amazon S3)、Amazon Elastic Compute Cloud (Amazon EC2) 和 Amazon DynamoDB 之间快速传输数据。</span></p><p><img height="300" src="https://oscimg.oschina.net/oscnet/up-79f46fd536e1e97a2b7983b321eed1fb7f8.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">事实上，对 AWS 服务的非官方 Rust 支持至少从 2015 年就开始存在了，当时 Matthew Mayer 和 Anthony DiMarco 在 Rust 1.0 发布后不久启动了一个名为 Rusoto 的独立项目，目标包括学习 Rust。根据 Rust crate 存储库 crates.io 上的统计，Rusoto 已被下载超过 1100 万次。2021 年，AWS Rust SDK 的第一个 alpha 版本由当时在 AWS 工作的 iliana etaoin 推出，她也是 Rusoto 的联合维护者。</span></p><p><span style="color:#000000">另一方面，AWS SDK for Kotlin 采用了从头开始设计。AWS 方面表示，此举旨在为用户您提供惯用的 Kotlin 体验，包括特定域语言 (DSL) 构建器，以及使用例程对异步 AWS 服务调用的支持。新发布的版本使开发人员能够使用 JVM 平台或 Android API Level 24+，未来版本还将支持 Kotlin/Native 等其他平台。</span></p><p><span style="color:#000000">那么就有人问了，既然 Kotlin 可以轻松地与现有的 Java SDK 进行互操作，那么&nbsp;AWS 为什么还要为 Kotlin 制作 SDK 呢？对此，AWS 解释原因有三：</span></p><ul><li style="text-align:start"><span style="color:#000000">首先，Kotlin 比 Java 具有更多的互操作性，包括 null-safety、coroutines、extension functions 和 smart casting。AWS 希望提供一个能够充分利用该语言并且让 Kotlin 开发者感到符合语言习惯的 SDK。</span></li><li style="text-align:start"><span style="color:#000000">其次，自 2019 年以来，Android 移动开发一直以 Kotlin 为先。Android 开发人员应该能够使用支持所有 AWS 服务的现代 SDK。这也是 AWS SDK for Kotlin 支持 Android API 24+ 的首要原因。事实上，AWS Amplify for Android v2 就是在 AWS SDK for Kotlin 的基础上构建的。</span></li><li style="text-align:start"><span style="color:#000000">最后，Kotlin 并不是一种仅限 JVM 的语言。Kotlin multiplatform 允许用户编写针对 JVM、本机二进制文件（Linux、Windows、macOS 和 iOS）、JavaScript 和 WASM 的 Kotlin 代码。因此该 SDK 从一开始也就被定位开发为多平台库，项目团队计划在未来支持更多目标。</span></li></ul><p><span style="color:#000000">了解有关未来版本计划推出的功能的详细信息，可查看</span><span style="color:#333333">&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Forgs%2Fawslabs%2Fprojects%2F50%2F" target="_blank">AWS SDK for Rust 路线图</a>&nbsp;<span style="color:#333333">和&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fawslabs%2Faws-sdk-kotlin%2Fprojects%2F2" target="_blank">AWS SDK for Kotlin 路线图</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 04:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269167/aws-sdks-for-rust-and-kotlin</guid>
            <link>https://www.oschina.net/news/269167/aws-sdks-for-rust-and-kotlin</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米回应「雷军最落魄时只剩冰冷的 40 亿」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">近日，存在两张有关小米创始人雷军的图片在网络上广为流传。图片文案显示，「雷军最落魄的时候，只剩下银行卡里冰冷的 40 亿」。</span></p><p><span style="background-color:#ffffff; color:#222222"><img alt="" height="392" src="https://oscimg.oschina.net/oscnet/up-90e839ec6755aa3946e458eff583478c12a.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#222222">对此，小米公司发言人官方微博昨日发文回应称：</span></p><blockquote><p><span style="color:#333333">今日网上出现大量关于本集团创始人雷军的不实传闻，所谓「冰冷的 40 亿」 纯属子虚乌有、完全失实。请大家勿信、勿传。 人生从来不是爽文，而是脚踏实地的历程，感谢大家的理解与支持。 ​​​</span></p></blockquote><p>雷军本人也在评论区评论称：</p><blockquote><p><span style="color:#333333">人生从来不是爽文，都是脚踏实地的历程，感谢大家的理解与支持。</span>&nbsp;</p></blockquote><p><img height="308" src="https://oscimg.oschina.net/oscnet/up-bf1373ae5fb064655792a016bd1dc5ca6d7.png" width="500" referrerpolicy="no-referrer">&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269159</guid>
            <link>https://www.oschina.net/news/269159</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[gkd —— 自定义屏幕点击 APP]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>gdk 是一个<span style="background-color:#ffffff; color:#1f2328">基于<span>&nbsp;</span></span><strong style="color:#1f2328">无障碍</strong><span style="background-color:#ffffff; color:#1f2328"><span>&nbsp;</span>+<span>&nbsp;</span></span><strong style="color:#1f2328">高级选择器</strong><span style="background-color:#ffffff; color:#1f2328"><span>&nbsp;</span>+<span>&nbsp;</span></span><strong style="color:#1f2328">订阅规则</strong><span style="background-color:#ffffff; color:#1f2328"><span>&nbsp;</span>的自定义屏幕点击 APP。</span></p><p style="color:#1f2328; text-align:start">基于<span>&nbsp;</span><a href="https://github.com/gkd-kit/selector">高级选择器</a><span>&nbsp;</span>+<span>&nbsp;</span><a href="https://github.com/gkd-kit/subscription">订阅规则</a><span>&nbsp;</span>+<span>&nbsp;</span><a href="https://github.com/gkd-kit/inspect">快照审查</a>，它可以实现</p><ul><li>点击跳过任意开屏广告/点击关闭应用内部任意弹窗广告, 如关闭百度贴吧帖子广告卡片/知乎回答底部推荐广告卡片</li><li>一些快捷操作, 如微信电脑登录自动同意/微信扫描登录自动同意/微信自动领取红包</li></ul><p><img alt="" height="667" src="https://static.oschina.net/uploads/space/2023/1120/165010_l9Dm_4252687.jpg" width="300" referrerpolicy="no-referrer">&nbsp;<img alt="" height="667" src="https://static.oschina.net/uploads/space/2023/1120/165048_Krg3_4252687.jpg" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="674" src="https://static.oschina.net/uploads/space/2023/1120/165057_bqXk_4252687.gif" width="300" referrerpolicy="no-referrer"></p><p>&nbsp;<img alt="" height="500" src="https://static.oschina.net/uploads/space/2023/1120/165116_uE95_4252687.gif" width="300" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/gkd</guid>
            <link>https://www.oschina.net/p/gkd</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 在纯 WebGPU/Rust 中实现 RWKV 语言模型]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-web-rwkv" class="anchor" href="https://gitee.com/cryscan/web-rwkv#web-rwkv"></a>Web-RWKV</h1><p><a href="https://gitee.com/link?target=https%3A%2F%2Fcrates.io%2Fcrates%2Fweb-rwkv"><img src="https://img.shields.io/crates/v/web-rwkv" alt="crates.io" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fdocs.rs%2Fweb-rwkv"><img src="https://docs.rs/web-rwkv/badge.svg" alt="docs.rs" referrerpolicy="no-referrer"></a></p><p align="center"></p><p>This is an inference engine for the <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FBlinkDL%2FRWKV-LM">language model of RWKV</a> implemented in pure WebGPU.</p><h2><a id="user-content-features" class="anchor" href="https://gitee.com/cryscan/web-rwkv#features"></a>Features</h2><ul><li>No dependencies on CUDA/Python.</li><li>Support Nvidia/AMD/Intel GPUs, including integrated GPUs.</li><li>Vulkan/Dx12/OpenGL backends.</li><li>Batched inference.</li><li>Int8 and NF4 quantization.</li><li>Very fast.</li><li>LoRA merging at loading time.</li><li>Support RWKV V4, V5 and V6.</li></ul><p align="center"></p><p>Note that <code>web-rwkv</code> is only an inference engine. It only provides the following functionalities:</p><ul><li>A tokenizer.</li><li>Model loading.</li><li>State creation and updating.</li><li>A <code>run</code> function that takes in prompt tokens and returns logits (predicted next token probabilities after calling <code>softmax</code>).</li></ul><p>It <em>does not</em> provide the following:</p><ul><li>OpenAI API or APIs of any kind.
<ul><li>If you would like to deploy an API server, check <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fcgisky1980%2Fai00_rwkv_server">AI00 RWKV Server</a> which is a fully-functional OpenAI-compatible API server built upon <code>web-rwkv</code>.</li><li>You could also check the <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FPrunoideae%2Fweb-rwkv-axum"><code>web-rwkv-axum</code></a> project if you want some fancy inference pipelines, including Classifier-Free Guidance (CFG), Backus–Naur Form (BNF) guidance, and more.</li></ul></li><li>Samplers, though in the examples a basic nucleus sampler is implemented, this is <em>not</em> included in the library itself.</li><li>State caching or management system.</li><li>Python (or any other languages) binding.</li><li>Runtime. Without a runtime makes it easy to be integrated into any applications from servers, front-end apps (yes, <code>web-rwkv</code> can run in browser) to game engines.</li></ul><h2><a id="user-content-compile-and-run" class="anchor" href="https://gitee.com/cryscan/web-rwkv#compile-and-run"></a>Compile and Run</h2><ol><li><a href="https://gitee.com/link?target=https%3A%2F%2Frustup.rs%2F">Install Rust</a>.</li><li>Download the model from <a href="https://gitee.com/link?target=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-5-world">HuggingFace</a>, and convert it using <a href="https://gitee.com/cryscan/web-rwkv/blob/main/convert_safetensors.py"><code>convert_safetensors.py</code></a>. Put the <code>.st</code> model under <code>assets/models</code>.</li><li>To generate 100 tokens and measure the time cost, run
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> gen</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To chat with the model, run
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To generate 4 batches of text with various lengths simultaneously, run
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> batch</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To specify the location of your safetensors model, use
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat <span class="nt">--</span><span class="nt">--model</span> /path/to/model</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To load custom prompts for chat, use
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat <span class="nt">--</span><span class="nt">--prompt</span> /path/to/prompt</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>
See <a href="https://gitee.com/cryscan/web-rwkv/blob/main/assets/prompt.json"><code>assets/prompt.json</code></a> for details.</li><li>To specify layer quantization, use <code>--quant &lt;LAYERS&gt;</code> or <code>--quant-nf4 &lt;LAYERS&gt;</code> to quantize the first <code>&lt;LAYERS&gt;</code> layers. For example, use
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat <span class="nt">--</span><span class="nt">--quant</span> 32</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>
to quantize all 32 layers.</li><li>Use <code>--turbo</code> flag to switch to alternative <code>GEMM</code> kernel when inferring long prompts.</li></ol><h2><a id="user-content-use-in-your-project" class="anchor" href="https://gitee.com/cryscan/web-rwkv#use-in-your-project"></a>Use in Your Project</h2><p>To use in your own rust project, simply add <code>web-rwkv = "0.4"</code> as a dependency in your <code>Cargo.toml</code>.
Check examples on how to create the environment, the tokenizer and how to run the model.</p><h3><a id="user-content-explanation-of-batched-inference" class="anchor" href="https://gitee.com/cryscan/web-rwkv#explanation-of-batched-inference"></a>Explanation of Batched Inference</h3><p>Since version v0.2.4, the engine supports batched inference, i.e., inference of a batch of prompts (with different length) in parallel.
This is achieved by a modified <code>WKV</code> kernel.</p><p>When building the model, the user specifies <code>token_chunk_size</code> (default: 32, but for powerful GPUs this could be much higher), which is the maximum number of tokens the engine could process in one <code>run</code> call.</p><p>After creating the model, the user creates a <code>ModelState</code> with <code>max_batch</code> specified.
This means that there are <code>max_batch</code> slots that could consume the inputs in parallel.</p><p>Before calling <code>run()</code>, the user fills each slot with some tokens as prompt.
If a slot is empty, no inference will be run for it.</p><p>After calling <code>run()</code>, some (but may not be all) input tokens are consumed, and <code>logits</code> appears in their corresponding returned slots if the inference of that slot is finished during this run.
Since there are only <code>token_chunk_size</code> tokens are processed during each <code>run()</code> call, there may be none of <code>logits</code> appearing in the results.</p><h2><a id="user-content-convert-models" class="anchor" href="https://gitee.com/cryscan/web-rwkv#convert-models"></a>Convert Models</h2><p><em>You must download the model and put in <code>assets/models</code> before running if you are building from source.</em>
You can now download the converted models <a href="https://gitee.com/link?target=https%3A%2F%2Fhuggingface.co%2Fcgisky%2FRWKV-safetensors-fp16">here</a>.</p><p>You may download the official RWKV World series models from <a href="https://gitee.com/link?target=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-5-world">HuggingFace</a>, and convert them via the provided <a href="https://gitee.com/cryscan/web-rwkv/blob/main/convert_safetensors.py"><code>convert_safetensors.py</code></a>.</p><p>If you don't have python installed or don't want to, there is a pure rust converter that you can run</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span><span class="nb">cd</span> ./crates/web-rwkv-converter</span><span id="LC2" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--</span><span class="nt">--input</span> /path/to/model.pth</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-troubleshoot" class="anchor" href="https://gitee.com/cryscan/web-rwkv#troubleshoot"></a>Troubleshoot</h2><ul><li><p>"thread 'main' panicked at 'called <code>Result::unwrap()</code> on an <code>Err</code> value: HeaderTooLarge'"</p><p>Your model is broken, mainly because you cloned the repo but did not set up git-lfs.Please download the model manually and overwrite that one in <code>assets/models</code>.</p></li><li><p>"thread 'main' panicked at 'Error in Queue::submit: parent device is lost'"</p><p>Your GPU is not responding.
Maybe you are running a model that is just too big for your device. If the model doesn't fit into your VRam, the driver needs to constantly swap and transfer the model parameters, causing it to be 10x slower.
Try to quantize your model first.</p></li></ul><h2><a id="user-content-credits" class="anchor" href="https://gitee.com/cryscan/web-rwkv#credits"></a>Credits</h2><ul><li>Tokenizer is implemented by <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkoute%2Frwkv_tokenizer">@koute</a>.</li></ul>]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/cryscan/web-rwkv</guid>
            <link>https://gitee.com/cryscan/web-rwkv</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 七年 4 个阶段：滴滴可观测架构演进与实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一分钟精华速览</h1><p>在当前阶段，可观测性的建设并没有统一的执行路径。每家公司会根据自身的业务需求、运营模式和规模，形成一套独特的实践方案。为了应对业务规模的扩大和需求的变化，可观测团队必须持续优化和升级其架构，并始终保证可观测系统本身的高可用性。</p><p>本文详尽地描绘了滴滴从 2017 年至今，在四个不同阶段所遭遇的技术挑战，如单体应用阶段的资源瓶颈、运维成本的上升、分布式服务的通信问题等等。滴滴通过寻找并应用适宜的技术方案，逐渐战胜了这些技术难题，使其可观测架构始终能为业务提供强大的支持。 <img src="https://oscimg.oschina.net/oscnet/up-37ea3e51d7965f7f81e1f723481e1d1511f.png" alt="file" referrerpolicy="no-referrer"></p><p>作者介绍 <img src="https://oscimg.oschina.net/oscnet/up-0a5962d122ef197918b9378c33d36a225a4.png" alt="file" referrerpolicy="no-referrer"></p><p>滴滴出行可观测架构负责人——钱威</p><p>TakinTalks 稳定性社区专家团成员，滴滴出行可观测架构负责人。深耕可观测领域多年，专注于架构设计与优化。带领团队完成了滴滴第二代到第四代的架构迭代。多个可观测开源项目的 Contributor。目前聚焦在滴滴可观测的稳定性建设和滴滴场景下的可观测性的实现与落地工作。</p><p>温馨提醒：本文约 7500 字，预计花费 12 分钟阅读。</p><p>「TakinTalks 稳定性社区」公众号后台回复 「交流」 进入读者交流群；回复「1026」获取课件资料；</p><h1>背景</h1><p>大家先来看一个故事——</p><p>「20 世纪初，当时处于高速发展期的福特公司。有一天一台电机坏了，相关生产工作被迫停止。很多工人和专家都找不到问题在哪。直到请到了一个叫斯坦门茨的人，斯坦门茨检查后用粉笔在电机外壳画了一条线，说打开电机，把记号处的线圈减少 16 圈。修理工照做后，故障排除，生产随即恢复。」</p><p>我们在工作或在开发过程中，时常会遇到这样的场景——让你一头雾水，不知道从何下手的难题，但是总有那么一两个「专家」一眼就能洞察问题所在。那么，我们需要思考一下，这到底是好事还是坏事？</p><p>滴滴作为一家出行平台，业务涵盖快车、专车、顺风车、共享单车等多个领域。每天有千万的用户和司机在平台上进行交互和使用，服务之间形成了复杂的依赖关系。在如此大规模的分布式系统中，故障排查和性能优化无疑是一项复杂的任务。</p><p>每次都依赖于个别专家的经验显然是无法控制的，也无法保证结果。因此，我们更愿意通过不断地演进可观测的架构，来支持业务的快速迭代和创新。</p><h1>一、可观测架构演进解决了哪些问题？</h1><h2>1.1 滴滴可观测系统通用架构</h2><p>滴滴可观测系统通用架构主要包含几个部分，如下图所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-41df9f4c584d6ec7df86ea7af9d0dfc6121.png" alt="file" referrerpolicy="no-referrer"></p><p>我们会采集目标主机或其他的相关指标，经过传输链路后，某些指标可能会经过计算模块进行处理，然后再写回系统中。随后，这些数据会被存储起来。基于这些存储的数据，查询功能可以为上层应用提供数据展示，如仪表板、数据大盘、报警和事件等。</p><p>需要注意的是，每个模块需要完成的任务或实现的功能各不相同。例如，查询模块可能需要负责数据路由、聚合以及实现 DSL 等功能，这些功能通常在查询层进行实现。</p><p>数据存储的实现方式有很多种，如 InfluxDB、RRDtool、Prometheus、Druid、ClickHouse 等，都可以作为可观测系统的存储方案。</p><p>传输模块在系统中起到连接的作用，常见的消息队列就是用在这一模块中。当我们提到消息队列时，大家首先想到的可能是 Kafka，当然也有一些较为小众的选择，如 NSQ。</p><p>计算模块的任务则是将大量的指标转换成我们所需的形式，可能会去除一些维度进行计算。Flink、Spark 等工具在这一模块中都是常见的选择。</p><p>对于数据采集，也有许多丰富的工具可以选择，如 Telegraf、Node exporter，以及最近推出的 Grafana Agent 等。</p><h2>1.2 可观测架构演进的 4 个阶段</h2><h3>1.2.1 阶段一：2017 年以前</h3><p>当业务需求发生变化时，存储模块的性能问题通常是最先暴露出来的。在 2017 年以前，滴滴主要使用 InfluxDB 作为存储选择。我们根据业务服务的维度将 InfluxDB 实例进行了拆分，这样的设计便带来了一些问题。</p><p>首先，单机版本的性能存在瓶颈。例如，我们可能会遇到查询量较大的情况，如查询跨度长或查询数据多，这种情况下很可能会出现内存溢出（OOM）的问题。这也是社区中经常讨论的问题。 <img src="https://oscimg.oschina.net/oscnet/up-416c08cc213a26dc5a99ac0e2175637595c.png" alt="file" referrerpolicy="no-referrer"></p><p>再者，我们采用的分片方式也存在问题。我们是按照服务进行拆分的，例如，如果今天有 50 个服务，那可能需要 50 个或更少的实例。但如果服务数量在明天增加到 500 个，那么运维成本将随之显著增加。特别是在当前大家普遍采用微服务架构的情况下，这种运维成本将会非常高。</p><h3>1.2.2 阶段二：2017-2018 年</h3><p>为了解决上述问题，我们在 2017 年引入了 RRDTool。在此期间，RRDTool 取代了 InfluxDB，成为滴滴可观测的主要存储工具。</p><p>在 RRDTool 的设计中，我们采用了一致性哈希算法，在读写链路中进行多个 RRDTool 实例的分片。这种哈希算法的过程是先将所有的 Tag 打平，然后排序，最后再进行哈希，分配到各个实例中。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7ac44d840041980a63c09d3c56e62770b70.png" alt="file" referrerpolicy="no-referrer"></p><p>除此之外，我们还引入了一个名为「索引」的服务。这个服务的主要任务是满足产品需求。比如，我们可能需要提供服务列表，当用户选择了他们自己的服务后，需要知道该服务下有哪些指标，以及每个指标下有哪些 Tag。这种需求需要一个高效的索引服务来完成。</p><p>基于 RRDTool 的架构改进带来了两大成果。首先，它解决了 InfluxDB 的热点问题。我们原来是按照服务去拆分实例，现在我们将这些曲线分散到各个实例上。其次，这也减轻了 InfluxDB 的运维成本，因为我们采用了相对自动化的分片方式。</p><h3>1.2.3 阶段三：2018-2020 年</h3><p>在 2018 年以后，我们面临了新的挑战。由于 RRDTool 的设计原理是每条曲线一个文件，因此，当数据规模扩大时，对 IO 的需求也随之增大。我们的 IOPS 已经超过了 3 万，这就需要我们增加更多的设备，例如具有高 IO 性能的机器，以解决这个问题。但是，这导致成本逐渐增高，且问题愈发严重。同时，可观测性中的读写是正交的，读写优化存在冲突——写通常是所有曲线写入最新的部分，而读通常是读取多条曲线或某条曲线长时间的数据。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d81c56d2f84ab2161a197aedd244e17e750.png" alt="file" referrerpolicy="no-referrer"></p><p>（纵向为 Writes，横向为 Reads)</p><p>那么，我们如何解决这个问题呢？经过分析，我们发现 80% 的查询都集中在最近两个小时内，因此，我们设计了一个冷热分层策略。这个策略的核心就是将压缩后的数据存储在内存中。压缩主要针对两个方面，一是时间戳，二是值。由于时间戳产生的时间间隔通常比较固定，而值的变化往往较为平缓，这为我们的压缩策略提供了依据。</p><p>基于这个原理，我们内部创建了一个名为"Cacheserver"的服务，主要服务于最近两小时的数据，采用了全内存的设计。这种设计使得用户查询的延迟从 10 秒降低到了 1 秒以内，每个数据点的存储由原来的 16 字节降低到了 1.64 字节。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a65d91b989d8dd692a5abc11952dddb1621.png" alt="file" referrerpolicy="no-referrer"></p><p>整个设计可以通过上述图示来理解。首先是冷热分层，RRDTool 和 Cacheserver 共同完成了整个存储任务。以图示右半部分为例，原始的时间戳为 350、360、370、381，存储这些数据需要 256 比特。但经过压缩后，只需要 88 比特就足够了。这只是四个时间戳的情况，如果时间戳更多，那么压缩效果会更加显著。</p><h3>1.2.4 阶段四：2020-至今</h3><p>随着用户接入的组件不断增多，用户的查询需求也变得越来越复杂。在我们的使用场景中，一旦 RRDTool 进行了降采，我们就无法再查看到原始数据。</p><p>面对这种情况，我们开始思考如何设计一个能满足用户当前和未来需求的系统。我们改变了问题解决的策略，不再针对每个具体情况单独设计方案。例如，如果过去有新增的查询形态，我们会需要编码并上线一个新的函数。而现在，我们选择直接利用业界的生态。</p><p>当时，Prometheus 是非常流行的。我们将目标从引入生态转变为引入 Prometheus 的生态。选择 Prometheus 的原因是，随着 K8s 的普及，Prometheus 已经成为了监控系统的事实标准。许多业界大厂和流行的厂商都在为 Prometheus 持续贡献代码和架构。</p><p>然而，如果我们选择引入 Prometheus 的生态，就无法继续使用 RRDTool，因为它无法兼容 Prometheus 的生态。这就需要我们寻找新的存储方案。</p><p>难点 1：新的存储方案如何选择？</p><p>在面临新的存储方案选择时，我们主要考虑了 Cortex、Thanos 和 VictoriaMetrics（简称 VM）。这些方案都是为了弥补 Prometheus 本身的一些缺陷而设计的，因为 Prometheus 从诞生之初就定位为单机存储，不支持长期存储，也没有高可用性。因此，Cortex 和 Thanos 在当时成为了业界主要的解决方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-176778420cc3bcd7e50c8134538547fba02.png" alt="file" referrerpolicy="no-referrer"></p><p>（调研业界 Prometheus 相关方案）</p><p>在对比这些方案时，我们发现 Cortex 和 Thanos 都能有效解决 Prometheus 的原生缺点。从成本角度考虑，由于 Thanos 和 Cortex 都采用了对象存储，因此它们的成本相对较低。但是，这两个方案由于使用了大量的第三方服务，如果公司没有对象存储或者没有云服务，那么这些组件的维护工作可能就需要由可观测团队来完成。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1d163b32eaf5437ddae21f7a3ecc49ca221.png" alt="file" referrerpolicy="no-referrer"></p><p>(RRDTool 与 VictoriaMetrics 方案对比）</p><p>相比之下，VM 与 RRDTool 相比，它是完全兼容 Prometheus 的。此外，我们之前提到过降采策略，RRDTool 的数据在超过两小时后会进行降采，一旦降采，我们就无法查看到原始数据。而 VM 本身不进行降采，这为我们带来了更多可能性。在降低存储成本方面，VM 的表现较好，在我们的环境测试中，其存储成本只有 RRDTool 的 1/20 左右。在数据上报形态上，Prometheus 是 Pull 形式，而 RRDTool 只能支持 Push 形式，并且只支持私有协议。但 VM 既支持 Pull 也支持 Push，对流行的数据上报协议也有良好的支持。</p><p>难点 2：如何引入 Prometheus 生态？</p><p>那么，我们是否可以简单地将存储方案替换为 VM 呢？实际上，答案是否定的。在引入新的生态系统时，我们首先需要考虑现有的公司方案。引入新的生态并不意味着要完全颠覆现有的产品架构，不能简单地进行替换。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4ced98fb48857f34094958a2cf4099a710e.png" alt="file" referrerpolicy="no-referrer"></p><p>为了引入新的生态，滴滴进行了一些改造。如图所示，绿色部分是使用 Prometheus 原生方案所需完成的工作。只要被监控的对象支持"/metrics"这样的接口，Prometheus 便可以进行数据拉取。对滴滴而言，我们原来的架构是基于采集、传输、存储的 Push 模型。因此，我们在采集部分增加了一个兼容 Prometheus 的 Adapter。在原有基础上，对于那些新增并且支持 Prometheus 拉取的服务，我们也可以使用自有的采集方法进行数据拉取。</p><p>在生态引入的成果方面，我们已经支持了 Prometheus 的数据采集，并且可以支持 PromQL 的图表查看和报警这两个常见场景。此外，我们还在图表查看这个维度上增加了一些新的功能，比如增加了 TopK/BottomK 等图表维度的 Outlier 能力。这样，如果一个服务有很多个实例，我们就可以利用 TopK/BottomK 这样的功能找出异常点。</p><p>在回馈社区方面，我们向 VM 官方和 Prometheus 社区递交了一些 PR，以此为整个社区做出贡献。</p><h1>二、如何保障可观测系统自身稳定性？</h1><p>众所周知，可观测系统的目的是保障业务的稳定性。那么，我们如何保障可观测系统本身的稳定性呢？首先，我们需要探讨如何监测这个可观测的系统。是否可以在自身的系统上配置一些策略？或者建立一些仪表盘？或者采取其他一些方式？在这方面，我将分享一些我们的实验和思考。</p><h2>2.1 如何观测可观测系统？</h2><p>我们不能让可观测的系统对其本身做观测。例如，如果存储系统出现故障，而查询数据的方式是从自身的存储中查询，那么就会形成循环依赖。因此，第一个原则就是不能让可观测的系统自观测。第二个原则与第一个原则有关，即需要一套独立的数据采集和报警服务来进行观测。</p><p>在我们的实践中，主要采用了两种方法。</p><p><img src="https://oscimg.oschina.net/oscnet/up-2baf281d16b9116d4a30925231fa56d1a24.png" alt="file" referrerpolicy="no-referrer"></p><p>第一种方法用于监测流量，适用于数据采集、传输和存储。这种方法主要通过使用 Exporter、Prometheus 和 Alertmanager 来进行自我监测。例如，如果存储写入流量突然变化，就可以使用这套系统进行自我监测。</p><p>另一种方法是监测能力。以报警为例，最简单的方法是设置一条始终会触发阈值的报警，但可能不会发送实时消息或短信通知。一旦报警事件中断，可能是因为报警系统本身存在问题，或者报警系统所依赖的存储查询存在问题。在这种情况下，我们可以通过设置探测器和进行端到端的检查来解决问题。</p><h2>2.2 如何保障可观测架构始终稳定？</h2><p>我们可以从两个方面来考虑：一是通过架构优化, 二是采取常用的保障手段。</p><h3>2.2.1 架构优化</h3><p>要点 1：鸡蛋不要放在一个篮子里</p><p>对于架构优化，一个简单的原则就是不要把所有的鸡蛋放在一个篮子里。我们可以通过以下的设计实现这一点。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8c1c833a7b8db7fbd51e4b6d56286bd0b83.png" alt="file" referrerpolicy="no-referrer"></p><p>（VictoriaMetrics 存储多集群设计）</p><p>滴滴主要从事打车业务，我们的网约车和非网约车业务的观测数据各自存储在不同的存储集群上，这就是我们采用的 VM 多集群设计。例如，如果非网约车业务实例出现问题，我们希望这不会影响到网约车业务，反之亦然。因此，我们在存储方面进行了多集群的设计。</p><p><img src="https://oscimg.oschina.net/oscnet/up-cd3d73594c6c53d06c8471fcc73d75d357f.png" alt="file" referrerpolicy="no-referrer"></p><p>（传输多集群设计）</p><p>在数据传输方面，我们的设计理念也是类似的，但有一点区别在于，传输和存储会用到不同的分片策略，这是因为它们的负载特性不同。例如，某个业务的传输量非常大，但存储查询的量却非常小，这种情况下，我们会在传输端对数据进行拆分，在存储端只需要保证数据的写入即可。它们可以共享同一存储集群。</p><p>要点 2：及时扔掉坏鸡蛋</p><p>另外还有一个原则，我们称之为「及时扔掉坏鸡蛋」。在传输模块中，除了写入存储，还有其他的下游模块，如流式报警等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e7a9c8c431cd89da042a2190e0ddb20e84f.png" alt="file" referrerpolicy="no-referrer"></p><p>因此，如果某个子系统因为某些原因运行变慢，从而影响了整个传输模块，这是我们不愿看到的。我们希望在子系统运行变慢或出现问题时，能够及时将其剔除出系统，即熔断策略。在某些情况下，我们可以自动进行熔断，并尝试不断恢复这个子系统。如果它成功恢复，那我们就会重新将这个系统接入。</p><h3>2.2.2 其他常用保障手段</h3><p>熔断、降级、多维度限流：</p><p>除了熔断和降级，我们还有其他保障手段，如多维度的限流。多维度限流采取灵活策略对请求进行限制，例如，一些持续且高频的跨度长时间的查询，比如几个月甚至几年的数据查询，我们就会应用多维度的限流手段。</p><p>慢查治理：</p><p>另一个保障手段是慢查的治理，这涉及到对大量曲线的查询。比如，一次查询涉及到了上百万的曲线，此时我们需要进行慢查发现，然后进行治理。在一些重点保障的时期，我们会开启这些策略，一旦识别到异常，就采用多维度限流，根据它的特征进行限流或者直接禁用。</p><p>多活：</p><p>内部可观测的多活，我们采用的方式是做单元化。例如，如果 A 机房和 B 机房的专线中断，我们需要保障用户可以单独访问相应机房的数据。</p><p>容量评估体系：</p><p>我们还有容量评估体系。因为在可观测架构和业务流量或订单量的增长可能不成正比，所以需要一套自身的容量评估体系。每家公司的业务模型可能不同，所以这个体系需要建立起来，对于保障手段来说，这是有帮助的。</p><p>预案、演练：</p><p>我们还会制定预案并进行演练，以保证这些手段是有效的。</p><h1>三、可观测性在滴滴是怎么实现的？</h1><h2>3.1 策略选择</h2><p>可观测性这个主题在 2021 或 2022 年是一个非常热门的话题。有人可能会觉得，如果不谈论可观测性，就相当落后了。我们先来看一下各大厂对可观测性的定义。</p><p>可观测性是可帮助团队有效调试其系统的工具或技术解决方案。可观测性基于对事先未定义的属性和模式的探索。——来源 Google</p><p>可观测性是指能够通过检查系统或应用的输出、日志和性能指标来监控、测量和理解系统或应用的状态。——来源 RedHat</p><p>可观测性是指您仅根据所了解的外部输出对复杂系统内部状态或条件的理解程度。——来源 IBM</p><p>我在这里分别引用了 Google、RedHat 和 IBM 对可观测性的定义，他们有两个共识。第一个是，可观测性是能从外部理解系统内部的状态，而这些状态并不需要是已知的。第二个共识是，可观测性有许多手段，包括日志、指标、事件等。</p><p>那么，如何实现可观测性呢？各大厂都有自己的实现方式。Google 推荐使用其云平台 GCP，RedHat 推荐使用 OpenShift Observability，IBM 有其自己的产品 Instana Observability，而 Grafana 推荐使用 LGTM(Loki、Tempo、Mimir)。</p><p>综合来看，实现可观测性的方法大概有三种。第一种是购买 SaaS 厂商的服务，第二种是尽可能地采集和存储详尽的可观测数据，第三种是关联多种观测数据。</p><h2>3.2 方案对比</h2><p>对于滴滴，第一种实现方式并不适合，因此我们优先排除。</p><p>至于第二种实现方式是「尽可能详尽」，于是我们将观测数据分为两个维度，即 Dimensionality 和 Cardinality。Dimensionality 类似于标签的概念，例如时间戳、版本、顾客 ID 等。Cardinality 则以顾客 ID 为例，可能有从 1 万 01 到 1 万 9999 的数据。这种方案优点是能采集大量数据，但缺点是实现成本高、资源消耗大，且数据利用率偏低。</p><p>第三种实现方式是关联多种观测数据，常见的观测数据包括 Metric、Trace、Log。Metric 数据属于高层次抽象，能告诉你错误数，但无法提供具体错误信息。Trace 数据主要用于跨服务关联，比如一个请求经历了哪些服务。Log 数据则是开发人员偏好的信息，它提供最详细的、人类可读的数据。然而，这种关联多种观测数据的方式，其缺点是架构实现相对复杂。</p><h2>3.3 架构设计</h2><p>在滴滴，我们借鉴了上述两种方法，将数据分为低基数和高基数两类。低基数指的是指标数据，而高基数则是日志数据。我们将这两种数据分别存储在不同的数据库中，并建立它们的关联关系。 <img src="https://oscimg.oschina.net/oscnet/up-0c28337ec890c982e26ae239ad7987fc15e.png" alt="file" referrerpolicy="no-referrer"></p><p>举个例子，如果在一段时间内我们收集到两个错误日志，我们就会将这个错误数「2」上报到时序数据库。同时，我们将对其中一条错误日志进行采样，并将其存储在 Exemplar DB 中。然后，我们会通过标签将时序数据库和 Exemplar DB 进行关联。</p><h2>3.4 实践成果</h2><p>滴滴的可观测性实践成果非常显著。在建立可观测性之前，我们在排查故障时需要登录到机器上并检索日志。如果有幸找到了问题所在的机器，那就算是幸运的。但如果并非问题出在这台机器，甚至不是这个服务，我们就需要重复上述的操作。而且，即使经过这样的操作，是否能找到问题也是不确定的。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b9ba869b9b09a5cf7b46c0cc30f7de8a81a.png" alt="file" referrerpolicy="no-referrer"></p><p>然而，在建立了可观测性之后，当我们收到报警消息时，我们可以直接查看与这条报警相关联的日志原文。查阅了日志原文之后，如果认为没有大问题，可以暂时不进行处理。如果是紧急情况，我们就会启动紧急处理流程。</p><p>此外，当我们在查看图表时，如果发现某个指标突然升高，想要知道是什么原因导致的，我们可以使用下钻功能。这个功能不仅可以让我们查看日志原文，如果日志中包含 Trace 信息，还可以将这个 Trace 信息提取出来。然后可以将 Trace 信息下钻到专门的 Trace 产品进行进一步的处理。</p><p>四、总结展望，滴滴的可观测性架构的发展实际上是基于不同的需求、场景和时代背景，选择了最适宜的解决方案。</p><p>我们对接了业界一些成熟的生态系统，并将这些生态系统融入到我们的系统中，这极大地帮助我们完成了许多工作，也提升了我们的工作效率。同时，在建设可观测性平台的过程中，我们也采用了一些策略来实现观测系统自身的稳定性保障。</p><p>值得注意的是，可观测性的建设并没有一种统一的实现方式，每家公司都有其自身的特色。因此，各公司需要根据自己的特点去定制专门的解决方案，并根据实际情况不断选择和调整最合适的方案。（全文完）</p><h1>Q&amp;A</h1><p>1、滴滴是否有专门的技术团队去维护可观测架构？Prometheus 的横向扩展能力相对有限。InfluxDB 具体有哪些问题？</p><p>2、如何去度量一个架构的可观测性？有什么建议吗？</p><p>3、Metric 的时效性有必要做到秒级吗？</p><p>4、接口偶发性超时，调用链只能看到超时接口名称，看不到内部方法，无法定位根因，也难以复现，怎么办？</p><p>以上问题答案，欢迎点击<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.shulie.io%2F%3Fp%3D7518" target="_blank">「阅读全文」</a>，观看完整版解答！</p><p>声明：本文由公众号「TakinTalks 稳定性社区」联合社区专家共同原创撰写，如需转载，请后台回复「转载」获得授权。</p><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/5129714/blog/10315681</guid>
            <link>https://my.oschina.net/5129714/blog/10315681</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维发布「天工 SkyAgents」平台，零代码打造 AI 智能体]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">12 月 1 日，昆仑万维正式发布「天工 SkyAgents」平台，助力大模型走入千家万户。「天工 SkyAgents」是国内领先的 AI Agents 开发平台，基于昆仑万维「天工大模型」打造，具备从感知到决策，从决策到执行的自主学习和独立思考能力。用户可以通过自然语言构建自己的单个或多个「私人助理」。并且将不同任务模块化，通过操作系统模块的方式，实现执行包括问题预设、指定回复、知识库创建与检索、意图识别、文本提取、http 请求等任务。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">在「天工 SkyAgents」平台上，用户可以通过自然语言和简单操作，无需代码编程，即可在几分钟之内部署属于自己的 AI Agents，完成行业研究报告、单据填写、商标设计、甚至健身计划、旅行航班预定等多项私人定制需求。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">对于企业用户而言，「天工 SkyAgents」则可以按需拼装成企业 IT、智能客服、企业培训、HR、法律顾问等众多个性化的应用，并支持一键服务部署，确保其在不同业务系统中的无缝接入。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-b2d9f445592d6b227dc00b733eb3b8eff7b.jpg" width="1268" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">AI Agent 一般译为「人工智能体」或「人工智能代理」，是一种能够感知环境、进行决策和执行动作的智能实体。不同于传统的人工智能程序，基于大模型能力打造的 AI Agent 具备通过独立思考、调用工具去逐步完成给定目标的能力。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">模块交互，更易用</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">当前，多数用户既不具备代码开发经验，也不具备训练大模型提示词工程（Prompt Engineering）的能力，难以将众多日常生活的实际需求通过对话问答形式快速实现，无法将大模型能力发挥到极致。「天工 SkyAgents」正是为了解决这一痛点而研发的一款产品。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">「天工 SkyAgents」通过将 Agent-to-Agent，Human-to-Agent 的交互模式集成在高度模块化的大语言模型构件中，实现完全无代码化操作，并通过简单直观的图形界面进行任务设定和部署，为广大用户提供了一个全面、高效且易于使用的 AI 产品，能够帮助用户轻松利用大模型能力应对复杂任务，满足日常需求、驱动业务增长、激发灵感创新。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">数据导入，更灵活</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-6d36ddc7cbd9554af55070f2b41d742d529.jpg" width="1268" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">大模型能力虽强，但也有其天生的弱项。一方面，大模型通过参数训练获得的知识只能停留在某一时点，更新成本很高；另一方面，大模型的训练数据通常以通用知识为主，细分领域的数据往往缺乏。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">为了解决这一问题， 「天工 SkyAgents」具备数据检索增强（RAG）的能力， 能够支持导入更多格式和更大规模的数据和知识，相当于给大模型增加了「智能知识库外脑」。结合人工智能技术，平台能够从导入的数据中自动识别关键信息点，形成结构化的知识体系。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">从此，「天工 SkyAgents」不仅能够成为你的私人 AI 助理，还能是你的私人法律专家、私人人力顾问、私人 IT 大神……</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">技术领先，更强大</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">对话问答类大模型应用遇到需要多流程、多步骤处理的复杂业务，往往要么容易产生「幻觉」，输出错误回答，要么容易错步、漏步、跳步，直接输出结果。然而不幸的是，人们在现实生活中遇到的大多数问题，往往都是复杂流程任务。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">为了解决这一问题，「天工 SkyAgents」在原有大模型技术基础上进一步了强化自然语言处理能力，辅之以先进的目标理解与工作流自动化技术，使得「天工 SkyAgents」能更精准地识别和解析复杂的业务目标，自动生成定制化的工作流程，甚至预测并建议潜在的优化方案。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-c7e6afa126be7553e35e2f575f2b5953f3c.jpg" width="1268" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">本次「天工 SkyAgents」的发布，将有助于缺乏代码开发能力的个人与中小企业积极拥抱大模型技术，以简单的模块化操作，设计出专属于自己的大模型 AI 助手，从而推动大模型技术的行业落地与普惠化，助力大模型走入千家万户，为人工智能产业发展贡献力量。前往天工开放平台预约申请：</span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagentspro.cn%2F%23%2F" target="_blank"><span><span><span><span style="color:#3370ff">https://agentspro.cn/#/</span></span></span></span></a></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">昆仑万维集团</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">昆仑万维于 2008 年成立，2015 年深交所上市，从游戏起家到 AII In AGI 与 AIGC， 全面构建多元化的业务生态，至今十余年的发展，我们始终致力于为全球用户提供领先的互联网产品与服务。现今，昆仑万维还在不断探索 AI 领域的无限可能。目前昆仑万维逐渐构建了 AGI 与 AIGC、海外信息分发与元宇宙、投资三大业务板块，业务覆盖全球一百多个国家和地区，全球平均月活跃用户近 4 亿。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">凭借对科技发展趋势的超前预判，昆仑万维早在 2020 年便已开始布局 AIGC 领域。至今，已积累近三年的相关工程研发经验，并建立了行业领先的预训练数据深度处理能力，昆仑万维也在人工智能领域取得了重大突破，目前已形成 AI 大模型、AI 搜索、AI 游戏、AI 音乐、AI 动漫、AI 社交六大 AI 业务矩阵，是国内模型技术与工程能力最强，布局最全面，同时全身心投入开源社区建设的企业之一。</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 09:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269081</guid>
            <link>https://www.oschina.net/news/269081</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[支持 Upsert、Kafka Connector、集成 Airbyte，Milvus 助力高效数据流处理]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Milvus 已支持 Upsert、 Kafka Connector、Airbyte！</p><p>在上周的文章中《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzMDI5OTA5NQ%3D%3D%26mid%3D2247499457%26idx%3D1%26sn%3D210ed71ffaa36d4220df3907a9a0ab41%26chksm%3Dfa515f79cd26d66f573354b0dc98dba492b925b1db63fbf5e5ad8b4cafb3f3b315d2bf6c5502%26scene%3D21%23wechat_redirect" target="_blank">登陆 Azure、发布新版本……Zilliz 昨夜今晨发生了什么？</a>》，我们已经透露过 Milvus（Zilliz Cloud）为提高数据流处理效率， 先后支持了 Upsert、 Kafka Connector、Airbyte，而这些功能的作用都是简化数据处理和集成流程，为开发人员提供更高效的工具来管理复杂的数据，今天我们将向大家一一介绍。</p><h2>01.Upsert：简化数据更新流程</h2><p>Upsert 功能上线以前，在 Milvus 中的更新数据需要两个步骤：删除数据，然后再插入新数据。虽然这种方法也可行，但无法确保数据原子性，且操作过于繁琐。Milvus 2.3 版本发布了全新的 Upsert 功能。（Zilliz Cloud 海外版也已上线 Upsert 功能 Beta 版）。</p><p>可以说，Upsert 功能重新定义了数据更新和管理方式。使用 Upsert 时，Milvus 会判断数据是否已经存在。如果数据不存在则插入数据，如果已存在则更新数据。这种具有原子性的方法对 Milvus 这样单独管理插入和删除数据的系统中尤为重要。</p><p>Upsert 具体的顺序为：先插入数据，然后删除重复数据。这样可以确保了操作期间的数据仍然可见。</p><p>此外，Upsert 功能还特别考虑了修改主键的场景。在数据更新过程中无法更改主键列。这与 Milvus 根据主键哈希跨分片（shard）管理数据的原则一致。这种限制避免了跨 Shard 操作带来的复杂性和潜在的数据不一致性。</p><p>Upsert 使用方法简单，类似于插入操作。用户可以轻松将 Upsert 集成到现有的工作流程中，无需对原有流程进行大改。在 Pymilvus 等 SDK 中，Upsert 命令调用和插入命令完全一致。熟悉 Milvus 的用户使用起来没有任何难度，可以获得一致和丝滑的用户体验。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f41551a015823f1b2df852545459520d410.png" alt="" referrerpolicy="no-referrer"></p><p>执行命令时，Upsert 会提供关于操作成功与否以及受影响的数据的反馈，进一步增加了开发者的使用便利性。这种易于使用且稳定的功能能够助力数据管理。更多详情，请查看 Upsert 文档。</p><p>但是使用 Upsert 功能时还需要考虑以下两点：</p><ul><li><p>AutoID 限制：使用 Upsert 功能的前提条件是将 AutoID 设置为 false。如果 Collection Schema 中将 AutoID 设置为 true，则无法执行 Upsert 操作。我们设置了这个限制的主要考量是，Upsert 也包含数据更新操作，更新的数据需要有新的主键值。如果用户提供的主键值与 AutoID 自动生成的主键值发生冲突，那可能会导致数据被覆盖。所以，已经开启了 AutoID 的 Collection 不可使用 Upsert 功能。后续新版本中我们可能会取消这一限制。</p></li><li><p>性能开销：Upsert 可能会导致性能成本。Milvus 使用 WAL 架构，过多删除操作可能会导致性能下滑。Milvus 中的删除操作不会立即清除数据，而是为数据打上删除标记。随后在数据压缩过程中才会根据这些标记真正清除数据。因此，频繁的删除操作可能会导致数据膨胀，影响性能。我们建议不要太过于频繁地使用 Upsert 功能，以确保最佳性能。</p></li></ul><h2>02.Kafka Connector：赋能实时数据处理</h2><p>近期，Milvus 和 Zilliz Cloud 接入了 Kafka Sink Connector，向量数据可以无缝丝滑地通过 Confluent/Kafka 实时导入 Milvus 或 Zilliz Cloud 向量数据库中。本次集成能够进一步释放向量数据库潜能，助力实时生成式 AI 应用，尤其是使用 OpenAI GPT-4 这种大模型的场景。</p><p>如今，我们所获取的信息中，非结构化数据已占据 80% 以上，且这类数据还在呈爆炸式增长。Zilliz 与 Confluent 的合作标志着非结构化数据管理和分析的重大进步，我们能够更高效存储、处理实时向量数据流，将其转化为易于搜索的数据。</p><p>Kafka Connector + Milvus / Zilliz Cloud 的常见用例包括：</p><p>增强生成式 AI：为 GenAI 应用提供最新的向量数据，从而确保生成的准确性和及时性。这两点对于金融和媒体等领域尤为重要，因为都需要实时处理各种来源的流式数据。</p><p>优化电商推荐系统：电商平台需要实时根据库存和客户行为动态调整其推荐商品或内容以提升用户体验。</p><p>在 Zilliz Cloud 中使用 Kafka Connector 的步骤也十分简单：</p><ul><li><p>从 GitHub 或 Confluent Hub 下载 Kafka Sink Connector。</p></li><li><p>配置 Confluent 和 Zilliz Cloud 账号。</p></li><li><p>阅读在 GitHub 仓库中提供的指南并配置 Kafka Connector。</p></li><li><p>运行 Kafka Connector，将实时流数据导入 Zilliz Cloud。</p></li></ul><p>如需更深入了解如何设置 Kafka Connector 和相关用例，请前往 GitHub 仓库或访问此网页。</p><h2>03.集成 Airbyte：数据处理更高效</h2><p>近期，Milvus 与 Airbyte 团队合作，在 Milvus 中集成 Airbyte，增强了大语言模型（LLM）和向量数据库中的数据获取和使用流程。本次集成能增强开发者存储、索引和搜索高维向量数据的能力，大大简化生成式聊天机器人和产品推荐等应用搭建流程。</p><p>本次集成的主要亮点包括：</p><ul><li><p>数据传输更高效：Airbyte 能够无缝将数据从各种来源传输到 Milvus 或 Zilliz Cloud，即时将数据转化为 Embedding 向量，简化了数据处理流程。</p></li><li><p>搜索功能更强大：此次集成增强了向量数据库的语义搜索能力。基于 Embedding 向量，系统可以自动识别并搜索出语义相似性高的相关内容，能够为需要高效检索非结构化数据的应用赋能。</p></li><li><p>设置过程更简单：设置 Milvus 集群和配置 Airbyte 同步数据的步骤十分简单。如果需要使用 Streamlit 和 OpenAI Embedding API 构建应用也是同样的设置步骤。</p></li></ul><p>此次集成简化了数据传输和处理，释放实时 AI 应用的无限可能性。例如，在客户支持系统中，使用 Milvus 或 Zilliz Cloud 集成 Airbyte 可以创建基于语义搜索的智能技术支持工单系统，从而为用户提供即时、有用的信息，减少人工干预，提升用户体验。</p><p>Zilliz 始终致力于提升非结构化数据管理和处理能力和技术，本次推出的 Upsert、Kafka Connector、Airbyte 等工具的集成都展现了这一点。后续，我们将进一步优化数据获取和数据 Pipeline 功能，敬请期待！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 08:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10315720</guid>
            <link>https://my.oschina.net/u/4209276/blog/10315720</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AYANEO 新品复古 Mini PC：R3 3200U/R7 5700U 可选]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">游戏硬件公司 Ayaneo 于近日<span style="background-color:#ffffff">正式发布了旗下首款迷你主机：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ayaneo.com%2Fproduct%2FAYANEO-Retro-Mini-PC-AM01.html" target="_blank">Ayaneo Retro Mini PC AM01</a>，号称引领 Mini PC 2.0 时代。该公司全新的 Mini PC 系列旨在满足玩家的多样化需求，打造无缝的游戏体验。</span></p><p><span style="color:#000000">Retro Mini PC AM01 整体设计致敬了苹果公司经典的&nbsp;Macintosh。精致复古的造型设计搭配<span style="background-color:#ffffff">仅 1L 的小巧体积，轻巧且便携，Bare System 重量约为 466 克。机身正面带有一个可自主更换的磁吸装饰件，虚拟屏幕（仅用于装饰目的，不可拆卸）同样也可以使用自定义贴纸进行装饰。</span></span></p><p><span style="color:#000000">虽然&nbsp;<span style="background-color:#ffffff">Ayaneo Retro Mini PC 具有苹果风格的外观，但实际上运行的却是 Windows 11；支持安装 Windows 和 Ubuntu、Debian 等 Linux 系统，以及 Steam OS 和 Batocera 等游戏系统。它可以配置为软件路由器或个人 NAS 系统使用。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">核心配置方面，AYANEO Retro Mini PC AM01&nbsp;配备 AMD Ryzen 3 3200U 或 Ryzen 7 5700U，提供多种处理器选项以适应各种用途需要。并且具有良好的可扩展性，配备五个 USB 端口（一个 USB-C 和四个 USB-A），另外还有 HDMI、DisplayPort、耳机插孔、以太网、蓝牙和 Wi-Fi。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">散热方面采用了高性能四铜管导热结构、35W 大尺寸高压涡轮风扇、60008 mm² 铝制散热片的设计；</span></span><span style="color:#000000"><span style="background-color:#ffffff">立体环绕进排气</span></span><span style="color:#000000"><span style="background-color:#ffffff">系统，智能风扇控制。</span></span></p><p><img height="430" src="https://oscimg.oschina.net/oscnet/up-d080ffb024ee9f3cec60c28fd06a4058905.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">AM01 的<span style="background-color:#ffffff">早鸟优惠价格为 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.indiegogo.com%2Fprojects%2Fayaneo-retro-mini-pc-creator-of-mini-pc-2-0-era%23%2F" target="_blank">149 美元起</a>，最高为 459 美元。</span>现已接受预订，官方计划于 12 月开始发货。<span style="background-color:#ffffff">具体的价格矩阵如下所示：</span></span></p><p><img alt="" height="267" src="https://oscimg.oschina.net/oscnet/up-0cd8ae66a9a0393d2fb33a48f61a185f409.jpg" width="500" referrerpolicy="no-referrer"></p><p><strong>外观：</strong></p><p><img alt="" height="359" src="https://oscimg.oschina.net/oscnet/up-f8a5d7972d50038132cff8a992237d7b940.webp" width="500" referrerpolicy="no-referrer"></p><p><img height="376" src="https://oscimg.oschina.net/oscnet/up-e356e6ca490bb95486b9e1c3f8430ed747b.png" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="399" src="https://oscimg.oschina.net/oscnet/up-062ac361b585bde3beff445262346fb83b7.webp" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="472" src="https://oscimg.oschina.net/oscnet/up-79b4dd3419f6dc327dc82be45836609e8cb.webp" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="115" src="https://oscimg.oschina.net/oscnet/up-9517c76acb34e140a6044d3e7472437369f.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">详情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ayaneo.com%2Fproduct%2FAYANEO-Retro-Mini-PC-AM01.html" target="_blank">官网</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 07:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269045/ayaneo-retro-mini-pc-am01</guid>
            <link>https://www.oschina.net/news/269045/ayaneo-retro-mini-pc-am01</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Turbo Pascal 诞生 40 年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Turbo Pascal <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.marcocantu.com%2Fblog%2F2023-november-turbopascal40.html" target="_blank">迎来了 40 岁生日</a></u>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-48365f6b4678042d953b96727360a44c28a.png" referrerpolicy="no-referrer"></p><p>1983 年 11 月 20 日，Borland 公司发布了 Turbo Pascal 的第一个版本。<strong>该版本的编译器核心部分由&nbsp;<span style="background-color:#ffffff; color:#333333">Anders Hejlsberg&nbsp;</span>授权给 Borland 公司</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-55fee9e8e268162cefc3a9f34a094250bdc.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwinworldpc.com%2Fproduct%2Fturbo-pascal%2F100" target="_blank">https://winworldpc.com/product/turbo-pascal/100</a></u></em></p><p>Anders Hejlsberg 为 MS-DOS 和 CP/M 设计了 Pascal 编译器，Borland 买下该编译器并改称 <strong>Turbo Pascal</strong>，之后 Anders Hejlsberg 也加入了 Borland 公司，并且是后来所有 Turbo Pascal 版本与 Delphi 前 3 个版本的架构师。</p><p>再后来 Anders Hejlsberg 被比尔·盖茨下重本挖到了微软，先后创造了 Visual J++、.NET、C#&nbsp;和&nbsp;TypeScript。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f1f3c48731e272b9d855120589ccc1969de.png" referrerpolicy="no-referrer"></p><p>说回 Turbo Pascal，它作为一种结构化编程语言对计算机编程产生了重大影响，并成为了许多程序员的入门语言。</p><p>Turbo Pascal 的设计目标是提供一种易于学习和使用的编程语言，同时具有高效的编译器和强大的功能。它采用了 Pascal 语言的语法和结构，但在性能和功能上进行了优化和扩展。Turbo Pascal 的编译器非常快速，可以在几秒钟内将源代码编译成可执行文件。这使得程序员能够快速地进行开发和调试。</p><p>Turbo Pascal 在教育领域也非常受欢迎。许多学校和大学使用 Turbo Pascal 作为计算机科学课程的教学工具。它的简单易学的语法和清晰的结构使得初学者能够快速上手，并理解编程的基本概念。</p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/130871/26-years-of-delphi" target="news">Delphi 26 岁</a></li><li><a href="https://www.oschina.net/news/241121/delphi-11-n-cbuilder-11-ce-released" target="news">Delphi 11 和 C++Builder 11 社区版发布</a></li><li><a href="https://www.oschina.net/news/265941/rad-studio-12-athens" target="news">Delphi 12 &amp; C++ Builder 12、RAD Studio 12 发布</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269027/turbo-pascal-turns-40</guid>
            <link>https://www.oschina.net/news/269027/turbo-pascal-turns-40</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sailfish OS 开发商 Jolla 已被其前管理层收购]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>芬兰科技公司 Jolla 的前管理层收购了 Jolla Ltd. 的全部业务和员工。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjolla.com%2Fcontent%2Fuploads%2F2023%2F11%2FFormer_leadership_buys_Jolla_Business_Pressrelease_271123_.pdf" target="_blank">根据 Jolla 发布的新闻稿</a></u>，Jolla Ltd 专注于操作系统和汽车软件的全部业务和员工将被转移到一家新公司，这家新公司已被 Jolla 前管理层收购。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-a0fea2cd154728b4d75b4df0ee0fe5f1894.png" referrerpolicy="no-referrer"></p></blockquote><p>由于乌克兰战争，<strong>俄罗斯在 Jolla 集团结构中的所有权成为员工和客户面临的一个紧迫问题</strong>，最终导致该公司于 2023 年春季开始实施企业重组计划。2023 年 11 月 24 日，Pirkanmaa 地方法院就重组计划做出了决定，并责成将业务完全出售给另一家公司。目前 Jolla 的前管理层已经收购了该公司。</p><p>Jolla 是一家曾经致力于开发智能手机和平板电脑的公司，但是这些产品并没有取得成功。后来 Jolla 将重心转向了基于 Linux 的 Sailfish OS<span style="background-color:#ffffff; color:#333333">（旗鱼）</span>，并将其应用于现有设备上。<span style="background-color:#ffffff; color:#333333">Sailfish OS 是由 Jolla 在 MeeGo 基础上开发的移动操作系统。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-11949d06737c31b962048e00e7e15b11d7f.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7f799a724c401bfe3018e347c698e78405b.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><img height="1476" src="https://oscimg.oschina.net/oscnet/up-7b2f29a69cf34959186e9e7746927ce1a22.png" width="3226" referrerpolicy="no-referrer"></p><p>新公司将继续致力于开发 Sailfish OS，并向全球客户销售。他们还计划将 Sailfish OS 引入新的「人工智能时代」。Jolla 还将通过自己的子公司 Seafarix 为汽车行业提供软件。</p><p><strong>延伸阅读：<em><u><a href="https://www.oschina.net/news/266231">俄罗斯操作系统 Aurora OS 5.0 全新 UI 亮相</a></u></em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269024/jolla-acquired-by-management</guid>
            <link>https://www.oschina.net/news/269024/jolla-acquired-by-management</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 表达式引擎选型调研分析]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><p><span style="letter-spacing: 1px;display: none;line-height: 0px;">‍‍</span></p><p style="margin-bottom: 24px;line-height: 1.6em;margin-top: 0px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.22676579925650558" src="https://oscimg.oschina.net/oscnet/73c34fc7-7990-4717-b675-aba8baad56ca.gif" data-type="gif" data-w="1076" style="" referrerpolicy="no-referrer"></p><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 编辑器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">一、简介</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"></h1><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">我们项目组主要负责面向企业客户的业务系统，<strong>企业的需求往往是多样化且复杂的，对接不同企业时会有不同的定制化的业务模型和流程</strong>。我们在业务系统中<strong>使用表达式引擎，集中配置管理业务规则，并实现实时决策和计算，可以提高系统的灵活性和响应能力</strong>，从而更好地满足业务的需求。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">举个简单的例子，假设我们有一个业务场景，在返利系统中，当推广员满足一定的奖励条件时，就会给其对应的奖励金额。例如某个产品的具体奖励规则如下：</span></section><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100024223" data-ratio="0.3739612188365651" data-s="300,640" src="https://oscimg.oschina.net/oscnet/1bb246c0-169f-4742-ab48-5956e774e993.png" data-type="png" data-w="361" style="" referrerpolicy="no-referrer"></p><section style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">这个规则看起来很好实现，只要在代码里写几个 if else 分支就可以了。但是如果返利系统对接了多家供应商，且每家提供的产品的奖励规则都不同呢？再通过硬编码的方式写 if else 似乎就不太好了，每次增加修改删除规则都需要系统发版上线。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">引入规则引擎似乎就能解决这个问题，规则引擎的一个好处就是可以使业务规则和业务代码分离，从而降低维护难度，同时它还可以满足业务人员通过编写 DSL 或通过界面指定规则的诉求，这样就可以在没有开发人员参与的情况下建立规则了，这种说法听起来似乎很有道理，但在实践中却很少行得通。首先，规则引擎有一定的学习成本，即使开发人员使用也需要进行专门的学习，更何况没有任何编程背景的业务人员，其次，其实现的复杂度也高，如果业务规则复杂，规则制定者对规则引擎内部隐藏的程序流程不了解，很可能会得到意想不到的结果，最后，有些规则引擎还存在性能瓶颈。如果对规则引擎和表达式引擎都不熟悉，抽离的业务规则又需要由开发人员来制定，那么<strong>相比之下表达式引擎就要容易上手得多，其语法更接近 Java，而且有些表达式引擎还会将表达式编译成字节码，在执行速度和资源利用方面可能就更有优势。</strong>所以，对于此类业务场景，使用表达式引擎似乎更加合适一些。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">本文主要对 Java 表达式引擎进行概要性介绍和分析，并提供一定建议，为团队研发过程中对表达式引擎的技术选型提供输入。</span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 编辑器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">二、技术栈简介</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;visibility: visible;"></h1><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"></h2><section style="margin-top: 24px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;visibility: visible;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">本文将针对</span>AviatorScript 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>MVEL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>OGNL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>SpEL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>QLExpress 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>JEXL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>JUEL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">几种常见表达式引擎进行选型调研。先简单介绍一下这几种表达式引擎。</span></section><span id="OSC_h2_1"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.1 AviatorScript</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript 是一门高性能、轻量级寄宿于 JVM 之上的脚本语言。AviatorScript 可将表达式编译成字节码。它原来的定位一直只是一个表达式引擎，不支持 if/else 条件语句，也不支持 for/while 循环语句等，随着 5.0 的发布变身为一个通用脚本语言，支持了这些语言特性。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：https://www.yuque.com/boyan-avfmj/aviatorscript﻿</span></section><span id="OSC_h2_2"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.2 MVEL (MVFLEX Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">MVEL 是一种混合的动态/静态类型的、可嵌入 Java 平台的表达式语言，MVEL 被众多 Java 项目使用。MVEL 在很大程度上受到 Java 语法的启发，但也有一些本质区别，目的是使其作为一种表达式语言更加高效，例如直接支持集合、数组和字符串匹配的操作符，以及正则表达式。最早版本发布于 2007 年。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：http://mvel.documentnode.com/﻿</span></section><span id="OSC_h2_3"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.3 OGNL (Object-Graph Navigation Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">OGNL 是 Object-Graph Navigation Language（对象图导航语言）的缩写；它是一种表达式语言，用于获取和设置 Java 对象的属性，以及其他额外功能，如列表投影和选择以及 lambda 表达式。于 2005 年发布 2.1.4 版。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：https://commons.apache.org/dormant/commons-ognl/language-guide.html﻿</span></section><span id="OSC_h2_4"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.4 SpEL (Spring Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">SpEL 是一种功能强大的表达式语言，支持在运行时查询和操作对象图。该语言的语法与 Unified EL 相似，但提供了更多的功能，其中最主要的是方法调用和基本的字符串模板功能。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：https://docs.spring.io/spring-framework/docs/5.3.x/reference/html/core.html#expressions﻿</span></section><span id="OSC_h2_5"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.5 QLExpress</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由阿里的电商业务规则、表达式（布尔组合）、特殊数学公式计算（高精度）、语法分析、脚本二次定制等强需求而设计的一门动态脚本引擎解析工具，于 2012 年开源。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：https://github.com/alibaba/QLExpress﻿</span></section><span id="OSC_h2_6"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.6 JEXL (Java Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JEXL 旨在促进在 Java 编写的应用程序和框架中实现动态脚本功能。JEXL 基于对 JSTL 表达式语言的一些扩展实现了一种表达式语言，支持 shell 脚本或 ECMAScript 中的大部分构想。1.0 版发布于 2005 年。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：https://commons.apache.org/proper/commons-jexl/reference/syntax.html﻿</span></section><span id="OSC_h2_7"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.7 JUEL (Java Unified Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JUEL 是统一表达式语言 (EL) 的实现，该语言是 JSP 2.1 标准 (JSR-245) 的一部分，已在 JEE5 中引入。此外，JUEL 2.2 实现了 JSP 2.2 维护版本规范，完全符合 JEE6 标准。于 2006 年发布 2.1.0 版本，2.2.7 发布于 2014 年。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：https://juel.sourceforge.net/guide/start.html﻿</span></section><span id="OSC_h2_8"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.8 Janino</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">Janino 是一个超小、超快的 Java 编译器，也可以用作表达式引擎，它的性能非常出色，根据官网介绍，Apache Spark、Apache Flink、Groovy 等优秀的开源项目都在用 Janino。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文档：http://janino-compiler.github.io/janino/﻿</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由于 Janino 实际是一个 Java 编译器，理论上其性能应该更接近于直接执行 Java 代码，其次作为表达式引擎使用起来比较复杂。因此，下面的对比中，Janino 不参与比较，可以将其作为一个参照。</span></section><span id="OSC_h2_9"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.9 其他</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如下一些表达式引擎虽然也常见于各技术博客，但由于长期没有更新维护，因此没有纳入此次选型比较</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">Fel</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">Fel 是轻量级的高效的表达式计算引擎。Fel 源自于企业项目，设计目标是为了满足不断变化的功能需求和性能需求。项目托管于 Google Code，上次更新是 2012 年，已经十几年没有更新了，所以没有纳入此次选型。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">ik-expression</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">IK Expression 是一个开源的（OpenSource)，可扩展的（Extensible），基于 java 语言开发的一个超轻量级（Super lightweight）的公式化语言解析执行工具包。2009 年 2 月发布第一个版本，2009 年 10 月发布最后一个版本后再没有新版本发布，所以没有纳入此次选型。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">JSEL</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JSEL 是一个兼容 JavaScript 运算规则的简单的表达式解释引擎，你可以通过 Map 接口，或者 JavaBean 给出一个变量集合，能后通过表达式从这个集合中抽取变量，再通过表达式逻辑生成你需要的数据。2009 年发布第一个版本，2011 年发布最后一个版本后未再更新，所以没有纳入此次选型。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">此外规则引擎如 Drools， urule， easy-rules 不参与此次选型比较。相对比较成熟完善的脚本语言如 Groovy 也不参与选型比较。这篇文章主要针对相对轻量简单的表达式引擎进行选型。</span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 编辑器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">三、技术栈选型评估</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"></h1><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">选择表达式引擎，我们希望其社区支持情况良好、实现复杂度适中、执行速度快、安全并且简单易学。所以，接下来将<strong>从社区支持情况、引入的大小和依赖、性能、安全性、使用案例和语法几个方面对几种表达式引擎进行比较评估。</strong></span></section><span id="OSC_h2_10"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.1 社区支持情况</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">社区支持情况可以辅助评估项目的健康度，有问题是不是能及时解决，项目是不是能持续演进等等</span></strong><span style="font-size: 15px;letter-spacing: 1px;">，下面列出了 GitHub star，watch，fork，last commit 等数据，可以作为参考，由于数据随着时间推移会产生变化，以下仅针对 2023.10.29 的数据进行分析。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><img class="rich_pages wxw-img" data-imgfileid="100024219" data-ratio="0.28055555555555556" src="https://oscimg.oschina.net/oscnet/c39b5f24-498a-493f-a227-256df954a368.png" data-type="png" data-w="1080" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">﻿﻿由于 Spring 项目被广泛使用，而 SpEl 又是 Spring 的一个子项目，所以从各项数据来看 SpEl 的社区支持情况是最好的。下面先排除 SpEl 分析其他几个表达式引擎。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">QLExpress，AviatorScript 和 MVEL 在国内使用比较多，这可能是他们 star，watch，fork 数较高的原因。说明这几个项目受欢迎度，受认可度，影响力应该较高。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">从 issues，pull requests 数来分析，可以看到 MVEL，AviatorScript 和 QLExpress 高于其他脚本引擎，说明他们的用户需求和反馈较多，也可能意味着项目面临较多问题和挑战。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">MVEL，JEXL，OGNL 均有较多贡献者参与。他们的社区协作、项目可持续性方面应该都比较不错。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">综合以上分析，除 SpEl 外，QLExpress，AviatorScript 和 MVEL 的社区支持情况都相对较好。</span></strong></section><span id="OSC_h2_11"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.2 引入大小和依赖</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">代码大小和依赖可以辅助评估代码的复杂性，下面列出了各个 Github 仓库的代码大小，可以作为一个参考（实际并不完全准确反映其实现的复杂性）。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">以下是 2023.10.29 的数据</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024218" data-ratio="1.41635687732342" src="https://oscimg.oschina.net/oscnet/afac92d7-a244-4283-bc12-84e3f543152c.png" data-type="png" data-w="269" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">﻿﻿JUEL，QLExpress 代码大小最小，都在 600 多 KB；其次是 OGNL 1MB 多一点；AviatorScript，MVEL，JEXL 大小都在 2MB 左右；SpEl 由于在 spring-framework 仓库中，上表中统计的是 spring-framework 的总量，单纯看 SpEl 的模块 spring-expression 的话，大小是 1.3MB 左右。但是其还依赖了 spring-core 和 spring-jcl，再含这两个的话，大小 7.4MB 左右。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">我们再结合各个项目的依赖来分析一下。</span></section><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="ruby"><code><span class="code-snippet_outer">+- org.mvel:mvel2:jar:2.5.0.Final:compile</span></code><code><span class="code-snippet_outer">+- com.googlecode.aviator:aviator:jar:5.3.3:compile</span></code><code><span class="code-snippet_outer">+- com.alibaba:QLExpress:jar:3.3.1:compile</span></code><code><span class="code-snippet_outer">|  +- commons-beanutils:commons-beanutils:jar:1.8.2:compile</span></code><code><span class="code-snippet_outer">|  |  \- (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.2)</span></code><code><span class="code-snippet_outer">|  \- commons-lang:commons-lang:jar:2.4:compile</span></code><code><span class="code-snippet_outer">+- org.codehaus.janino:janino:jar:3.1.10:compile</span></code><code><span class="code-snippet_outer">|  \- org.codehaus.janino:commons-compiler:jar:3.1.10:compile</span></code><code><span class="code-snippet_outer">+- ognl:ognl:jar:3.4.2:compile</span></code><code><span class="code-snippet_outer">|  \- org.javassist:javassist:jar:3.29.2-GA:compile</span></code><code><span class="code-snippet_outer">+- org.apache.commons:commons-jexl3:jar:3.3:compile</span></code><code><span class="code-snippet_outer">|  \- commons-logging:commons-logging:jar:1.2:compile</span></code><code><span class="code-snippet_outer">+- org.springframework:spring-expression:jar:5.3.29:compile</span></code><code><span class="code-snippet_outer">|  \- org.springframework:spring-core:jar:5.3.29:compile</span></code><code><span class="code-snippet_outer">|     \- org.springframework:spring-jcl:jar:5.3.29:compile</span></code><code><span class="code-snippet_outer">+- de.odysseus.juel:juel-api:jar:2.2.7:compile</span></code><code><span class="code-snippet_outer">+- de.odysseus.juel:juel-impl:jar:2.2.7:compile</span></code><code><span class="code-snippet_outer">+- de.odysseus.juel:juel-spi:jar:2.2.7:compile</span></code></pre></section></pre><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">除了 SpEl 外，QLExpress，OGNL，JEXL 也都有其他依赖。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如果考虑 commons-beanutils， commons-lang， commons-logging 三个依赖，QLExpress 引入的大小在 10MB 左右。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如果考虑 javassist 依赖，OGNL 引入的大小是 4MB 多。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如果考虑 commons-logging 依赖，JEXL 引入的大小是 2.5MB 左右。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">综合来看，JUEL，AviatorScript，MVEL，JEXL 在引入大小和依赖方面要好于其他。</span></strong></section><span id="OSC_h2_12"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3 性能</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">较好的性能意味着系统能够快速地响应用户的请求，减少等待时间，提升体验。</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">性能方面主要通过 JMH 在字面量表达式、含有变量的表达式以及含有方法调用的表达式等使用场景对几个表达式引擎进行测试。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JMH（Java Microbenchmark Harness），是用于代码微基准测试的工具套件，主要是基于方法层面的基准测试，精度可以达到纳秒级。该工具是由 Oracle 内部实现 JIT 的大牛们编写的，他们应该比任何人都了解 JIT 以及 JVM 对于基准测试的影响。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由于不同表达式引擎语法或特性稍有差别，下面测试中对于差异项会进行说明。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">性能测试代码地址：</span><span style="letter-spacing: 1px;font-size: 15px;">GitHub</span><span style="font-size: 15px;">-https://github.com/howiefh/expression-engine-benchmark</span></section><span id="OSC_h3_13"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.1 字面量表达式</span></strong></h3><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024215" data-ratio="0.43444730077120824" src="https://oscimg.oschina.net/oscnet/57f87300-b4c2-48fe-bb02-d1bd3b156186.svg" data-type="svg" data-w="1556" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: left;"><span style="font-size: 15px;letter-spacing: 1px;text-align: justify;background-color: rgb(2, 30, 170);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;text-align: justify;">：1000 + 100.0 * 99 - (600 - 3 * 15) / (((68 - 9) - 3) * 2 - 100) + 10000 % 7 * 71</span></section><section style="line-height: 1.6em;margin-top: 16px;margin-bottom: 16px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(61, 170, 214);">&nbsp;&nbsp; </span><span style="font-size: 15px;letter-spacing: 1px;">：6.7 - 100 &gt; 39.6 ? 5 == 5 ? 4 + 5 : 6 - 1 : !(100 % 3 - 39.0 &lt; 27) ? 8 * 2 - 199 : 100 % 3</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">说明：</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由于 QlExpress 执行第 2 个表达式时报错，需要增加圆括号，实际执行的是 6.7 - 100 &gt; 39.6 ? (5 == 5 ? 4 + 5 : 6 - 1) : (!(100 % 3 - 39.0 &lt; 27) ? 8 * 2 - 199 : 100 % 3)</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">结果分析:</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">可以明显看到 JEXL，JUEL，QlExpress 这三个表达式引擎性能明显不如其他引擎。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">SpEl 在执行第 1 个算数操作时表现出色，但是在执行第 2 个嵌套三元操作时明显不如 AviatorScript，MVEL，OGNL 引擎。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">此轮测试中 AviatorScript，OGNL，MVEL 表现出色。AviatorScript，OGNL 执行两个表达式表现都比较出色，其中 AviatorScript 略好于 OGNL。MVEL 在执行第 1 个算数操作时表现最出色，但是在执行第 2 个嵌套三元操作时慢于 AviatorScript，OGNL 引擎。</span></section><span id="OSC_h3_14"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.2 含有变量的表达式</span></strong></h3><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024217" data-ratio="0.8046272493573264" src="https://oscimg.oschina.net/oscnet/cf08fbe6-72a8-45dc-bf9e-1303f1f07414.svg" data-type="svg" data-w="1556" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;"><span style="letter-spacing: 1px;background-color: rgb(2, 30, 170);">&nbsp; &nbsp;</span>：pi * d + b - (1000 - d * b / pi) / (pi + 99 - i * d) - i * pi * d / b</span><br></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(61, 170, 214);background-color: rgb(61, 170, 214);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：piDecimal * dDecimal + bDecimal - (1000 - dDecimal * bDecimal / piDecimal) / (piDecimal + 99 - iDecimal * dDecimal) - iDecimal * piDecimal * dDecimal / bDecimal</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(0, 128, 255);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：i * pi + (d * b - 199) / (1 - d * pi) - (2 + 100 - i / pi) % 99 == i * pi + (d * b - 199) / (1 - d * pi) - (2 + 100 - i / pi) % 99</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(0, 209, 0);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：(clientVersion == '1.9.0' || clientVersion == '1.9.1' || clientVersion == '1.9.2') &amp;&amp; deviceType == 'Xiaomi' &amp;&amp; weight &gt;= 4 &amp;&amp; osVersion == 'Android 9.0' &amp;&amp; osType == 'Android' &amp;&amp; clientIp != null &amp;&amp; requestTime &lt;= now&amp;&amp; customer.grade &gt; 1 &amp;&amp; customer.age &gt; 18</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">说明：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="font-size: 15px;"><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由于不同的表达式引擎在执行第 2 个表达式时底层实现除法时有所差别，MVEL，AviatorScript，JEXL 执行 decimal.divide(otherDecimal, java.math.MathContext.DECIMAL128)，其他实际执行的是 decimal.divide(otherDecimal, scale, roundingMode)，只是参数略有不同，分析时分组进行。</span></p></li><li style="font-size: 15px;"><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由于 QlExpress 执行第 3 个表达式时报错，不支持非整型 mod 操作，需要增加类型转换，实际执行的是 i * pi + (d * b - 199) / (1 - d * pi) - (int)(2 + 100 - i / pi) % 99 == i * pi + (d * b - 199) / (1 - d * pi) - (int)(2 + 100 - i / pi) % 99</span></p></li><li><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由于 A</span><span style="font-size: 15px;letter-spacing: 1px;">viatorScript 执行第 4 个表达式时报错，null 的字面量是 nil，实际执行的是 (clientVersion == '1.9.0' || clientVersion == '1.9.1' || clientVersion == '1.9.2') &amp;&amp; deviceType == 'Xiaomi' &amp;&amp; weight &gt;= 4 &amp;&amp; osVersion == 'Android 9.0' &amp;&amp; osType == 'Android' &amp;&amp; clientIp != nil &amp;&amp; requestTime &lt;= now&amp;&amp; customer.grade &gt; 1 &amp;&amp; customer.age &gt; 18</span></p></li></ul><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">结果分析：</span></strong></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 1 个基本类型包装类的算术计算 SpEl 最优。其次是 AviatorScript，MVEL，OGNL。而 JEXL，JUEL，QlExpress 则不如其他引擎。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 2 个 BigDecimal 类型的算术计算。由于底层实现不同，分为两组。第 1 组 MVEL、AviatorScript 和 JEXL，AviatorScript 优于 MVEL 优于 JEXL。第 2 组 JUEL，QlExpress，OGNL 和 SpEl，性能由优到差依次是 OGNL，SpEl，JUEL，QlExpress。并且第 1 组由于精度更高，性能明显都差于第 2 组。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 3 个含有基本类型包装类算数计算的布尔表达式。SpEl 最优，AviatorScript 次之，接下来依次是 OGNL, MVEL，JUEL，JEXL，QlExpress。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 4 个含有字符串比较的布尔表达式。AviatorScript，MVEL，JEXL，OGNL 性能优于 JUEL，QlExpress，SpEl。</span></p><span id="OSC_h3_15"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.3 含有方法调用的表达式</span></strong></h3><p style="margin-top: 24px;margin-bottom: 24px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024216" data-ratio="0.6195372750642674" src="https://oscimg.oschina.net/oscnet/f7706f84-f707-493c-8470-1d59715d2194.svg" data-type="svg" data-w="1556" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(2, 30, 170);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：new java.util.Date()</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(61, 170, 214);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：s.substring(b.d)</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(0, 128, 255);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：s.substring(b.d).substring(a, b.c.e)</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">说明：</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="font-size: 15px;"><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由于 JUEL 执行 new java.util.Date() 时报错，不支持 new 实例，本轮实际执行的是自定义函数 fn:date()</span></p></li><li><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由于 A</span><span style="font-size: 15px;letter-spacing: 1px;">viatorScript 执行 s.substring 时报错，需使用其提供的内部函数，本轮实际执行的是其内部函数 string.substring</span></p></li></ul><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">结果分析：</span></strong></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">此轮测试中 SpEl 的表现最优，甚至比 Janino 还要快。MVEL，AviatorScript 次之，在执行构造方法时 MVEL 要好于 AviatorScript。JEXL 表现也比较出色。QlExpress，JUEL，OGNL 这三个表达式引擎则不如其他引擎。</span></p><span id="OSC_h3_16"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.4 总结</span></strong></h3><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">综合以上测试结果，AviatorScript，SpEl，MVEL，OGNL 性能表现相对较好。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript 性能相对较好，表现均衡，但其语法相较其他引擎跟 Java 的差异略大。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">SpEl 除了在个别场景下性能较差，大部分场景表现非常出色，尤其是在字面量和含有变量的算数计算及方法调用场景下。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">MVEL 性能表现相对均衡，含有变量的算术计算略差于 AviatorScript，其在字面量算术计算，方法调用场景下表现都非常出色。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">OGNL 性能表现也相对均衡，但方法调用场景下表现不佳。</span></p><span id="OSC_h2_17"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.4 安全</span></strong></span></h2><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">引入表达式引擎，应该重视系统的安全性和可靠性，比如要防止在不可信环境中被注入恶意脚本，越权执行某些系统命令或使应用停止服务等。</span></strong><span style="font-size: 15px;letter-spacing: 1px;">安全性方面主要通过漏洞披露、安全指南和配置比较几种表达式引擎。</span></p><span id="OSC_h3_18"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.4.1 漏洞</span></strong></h3><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">首先在 https://cve.mitre.org/cve/search_cve_list.html 通过关键字搜索的方式粗略了解一下不同表达式引擎被公开的漏洞。这种方式可能不是非常的准确，由于不同表达式引擎的使用场景、使用方式、关注度的不同可能导致被公开的漏洞存在差异。比如我们所熟悉的 OGNL、SpEl 的关键字出现在漏洞中的频率明显高于其他表达式引擎。OGNL 在 MyBatis 和 Struts 中被使用，SpEl 则在 Spring 中被广泛使用，这两个表达式引擎会被大部分项目间接使用，直接将用户输入作为表达式的一部分执行，很容易导致出现漏洞。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">我们<strong>可以从这些公布的漏洞中了解不同表达式引擎可能存在的安全隐患及其修复情况，在使用过程中尽可能避免出现类似问题。</strong></span></p><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">此外，不推荐将表达式执行直接开放到不可信的环境，如果确实需要，应该详细了解选择的表达式引擎，是否提供了必要的设置选项可以避免某些安全隐患。</span></strong></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100024222" data-ratio="0.5028901734104047" data-s="300,640" src="https://oscimg.oschina.net/oscnet/3f83fb13-b9be-47be-bbef-ecbcbf8b045c.png" data-type="png" data-w="519" style="" referrerpolicy="no-referrer"></p><p><strong><span style="font-size: 15px;letter-spacing: 1px;">3.4.2 安全设置</span></strong><br></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript，QLExpress，JEXL 均从不同程度提供了一些安全选项设置。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">设置白名单</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="php"><code><span class="code-snippet_outer">// 在 new 语句和静态方法调用中允许使用的类白名单，默认 null 表示无限制</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.ALLOWED_CLASS_SET, Sets.newHashSet(List.class));</span></code><code><span class="code-snippet_outer">// 在 new 语句和静态方法调用中允许使用的类白名单，包含子类，默认 null 表示无限制</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.ASSIGNABLE_ALLOWED_CLASS_SET, Sets.newHashSet(List.class));</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">防止死循环</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">// 循环最大次数，默认 0 表示无限制</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.MAX_LOOP_COUNT, 10000);</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">特性开关</span></p></li></ul><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="php"><code><span class="code-snippet_outer">// 关闭某些特性</span></code><code><span class="code-snippet_outer">AviatorEvaluator.getInstance().disableFeature(Feature.Module);</span></code><code><span class="code-snippet_outer">AviatorEvaluator.getInstance().disableFeature(Feature.NewInstance);</span></code><code><span class="code-snippet_outer">// 只开启需要的特性</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.FEATURE_SET, Feature.asSet(Feature.If));</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">QLExpress</span></strong></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">开启沙箱模式</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">QLExpressRunStrategy.setSandBoxMode(true);</span></code></pre></section></pre><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">在沙箱模式中，不可以：</span></p><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">import Java 类</span></section><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">显式引用 Java 类，比如 String a = 'mmm'</span></section><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">取 Java 类中的字段：a = new Integer(11); a.value</span></section><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">调用 Java 类中的方法：Math.abs(12)</span></section><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">可以：</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">使用 QLExpress 的自定义操作符/宏/函数，以此实现与应用的受控交互</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">使用. 操作符获取 Map 的 key 对应的 value，比如 a 在应用传入的表达式中是一个 Map，那么可以通过 a.b 获取</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">所有不涉及应用 Java 类的操作</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">设置白名单</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="swift"><code><span class="code-snippet_outer">// 设置编译期白名单</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.setCompileWhiteCheckerList(Arrays.asList(</span></code><code><span class="code-snippet_outer">    // 精确设置</span></code><code><span class="code-snippet_outer">    CheckerFactory.must(Date.class),</span></code><code><span class="code-snippet_outer">    // 子类设置</span></code><code><span class="code-snippet_outer">    CheckerFactory.assignable(List.class)</span></code><code><span class="code-snippet_outer">));</span></code><code><span class="code-snippet_outer">// 设置运行时白名单// 必须将该选项设置为 true</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.setForbidInvokeSecurityRiskMethods(true);</span></code><code><span class="code-snippet_outer">// 有白名单设置时, 则黑名单失效</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.addSecureMethod(RiskBean.class, "secureMethod");</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">设置黑名单</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="swift"><code><span class="code-snippet_outer">// 必须将该选项设置为 true</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.setForbidInvokeSecurityRiskMethods(true);</span></code><code><span class="code-snippet_outer">// 这里不区分静态方法与成员方法, 写法一致</span></code><code><span class="code-snippet_outer">// 不支持重载, riskMethod 的所有重载方法都会被禁止</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.addSecurityRiskMethod(RiskBean.class, "riskMethod");</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">QLExpess 目前默认添加的黑名单有：</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.System.exit</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.Runtime.exec</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.ProcessBuilder.start</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.Method.invoke</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.Class.forName</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.ClassLoader.loadClass</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.ClassLoader.findClass</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">防止死循环</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">//可通过 timeoutMillis 参数设置脚本的运行超时时间:1000ms</span></code><code><span class="code-snippet_outer">Object r = runner.execute(express, context, null, true, false, 1000);</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">JEXL</span></strong></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">使用沙箱</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">// 使用中应该通过 JexlSandbox 的重载构造方法进行配置</span></code><code><span class="code-snippet_outer">new JexlBuilder().sandbox(new JexlSandbox()).create();</span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">设置白名单权限</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="css"><code><span class="code-snippet_outer">new JexlBuilder().permissions(JexlPermissions.RESTRICTED.compose("com.jd.*")).create();</span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">特性开关</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">// 关闭循环、new 实例，import 等特性</span></code><code><span class="code-snippet_outer">new JexlBuilder().features(new JexlFeatures().loops(false).newInstance(false).importPragma(false)).create();</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><span id="OSC_h2_19"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.5 使用案例</span></strong></h2><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">从业界使用情况可以了解不同表达式引擎的可行性、生态和整合性，以及最佳实践，进而借鉴。从下表可以看到 AviatorScript，MVEL，QLExpress 在国内业务线均有使用案例，有些企业也有文章输出，我们可以借鉴使用。</span></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100024221" data-ratio="0.8702064896755162" data-s="300,640" src="https://oscimg.oschina.net/oscnet/7351a73e-f1e0-4db3-a3d3-b3fe2ca7815b.png" data-type="png" data-w="339" style="" referrerpolicy="no-referrer"></p><p><strong style="color: rgb(2, 30, 170);font-size: 16px;letter-spacing: 0.034em;"><span style="font-size: 15px;letter-spacing: 1px;">3.6 语法</span></strong><br></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">易于理解和使用的语法可以提高开发效率，并降低学习成本。接下来从类型、操作符、控制语句、集合、方法定义几方面比较一下不同表达式引擎的语法设计。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">类型方面，AviatorScript 设计了特有的类型，使用时需要注意其类型转换的优先级 long-&gt;bigint-&gt;decimal-&gt;double。AviatorScript、MVEL、OGNL、JEXL 都支持 BigInteger、BigDecimal 字面量，这意味着进行精确计算时可以使用字面量，将更方便，如 10.24B 就表示一个 BigDecimal 字面量（AviatorScript 中 BigDecimal 字面量后缀是 M）。此外 AviatorScript、QLExpress 还支持高精度计算的设置项。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">操作符方面，QLExpress 支持替换、自定义操作符及添加操作符别名，这可能有助于简化复杂表达式或使表达式更加直观，不过添加预置函数应该可以达到差不多的效果。AviatorScript 也支持自定义部分操作符，不过支持数量相当有限。AviatorScript、SpEl、JEXL 支持正则匹配操作符。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">控制语句方面，除 OGNL、SpEl、JUEL 不支持控制语句外，其他都支持，不过需要注意 AviatorScript 的 else if 语法有些特殊写作 elsif，foreach 语句跟 Java 也有所不同。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">集合方面，除 JUEL 外其他都提供了快捷定义的方式，只不过语法不同。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">函数定义方面，SpEl、JUEL 均不支持，OGNL 支持伪 lambda 定义，其他都支持定义函数。QLExpress 不支持定义 lambda。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">综合来看，和 Java 语法都或多或少存在一些差异。<strong>AviatorScript 设计了自己特有的一些语法，使用的话需要熟悉一下。QLExpress 支持自定义操作符，可以使表达式看起来更直观。MVEL、JEXL 的语法可能更接近 Java，让人更容易接受一些。OGNL、SpEl、JUEL 的语法更简单一些，不支持控制语句和函数定义，当然也可以通过预置一些函数变通解决一些较复杂的问题。</strong></span></p><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 编辑器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">四、选型建议</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"></h1><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">社区方面，SpEl 无疑是最活跃的。AviatorScript，QLExpress，MVEL 在国内很受欢迎，QLExpress 有阿里背书。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">代码大小和依赖方面，AviatorScript，MVEL 依赖少，并且代码大小也偏小。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">性能方面，如果你使用表达式引擎执行字面量算术计算或方法调用偏多可以选用 SpEl，MVEL。如果希望整体性能表现较好可以选用 AviatorScript。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">安全方面，如果想自定义安全选项，可以考虑 AviatorScript，QLExpress 和 JEXL。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">使用案例方面，AviatorScript，MVEL，QLExpress 在国内都有实际使用案例可循。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">语法方面，可能存在一些主观因素，仅供参考，个人觉得 MVEL、JEXL 的语法设计使用起来会更容易一些。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">通过对以上几个方面的评估和分析，希望可以帮助团队基于自身情况及偏好选择最适合自己项目的 Java 表达式引擎。</span></p><span id="OSC_h1_20"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">参考资料</span></h1><span id="OSC_h1_21"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[1]</span><span style="outline: 0px;">&nbsp;QLExpress：</span></span><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">https://github.com/alibaba/QLExpress﻿</span></h1><span id="OSC_h1_22"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">[2] AviatorScript：https://github.com/killme2008/aviatorscript﻿</span></h1><span id="OSC_h1_23"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">[3] MVEL：https://github.com/mvel/mvel﻿</span></h1><span id="OSC_h1_24"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">[4] OGNL：https://github.com/orphan-oss/ognl﻿</span></h1><span id="OSC_h1_25"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="outline: 0px;">[5]&nbsp;SpEl</span>：</span><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">https://github.com/spring-projects/spring-framework</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">﻿</span></h1><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">[6]&nbsp;</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">Janino：</span><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/janino-compiler/janino</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[7]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">JUEL：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/beckchr/juel</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[8]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">JEXL：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/apache/commons-jexl</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[9]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">Fel：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/dbcxy/fast-el</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[10]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">ik-expression：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://code.google.com/archive/p/ik-expression/</span></span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">﻿</span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">[11]&nbsp;</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">JS</span><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">EL：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://code.google.com/archive/p/lite/wikis/JSEL.wiki</span></span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">﻿</span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">[1]&nbsp;</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">JMH：https://www.cnblogs.com/wupeixuan/p/13091381.html</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span style="display: none;line-height: 0px;">‍</span></p><section style="margin-bottom: 8px;margin-top: 32px;text-align: center;"><span style="color: rgb(136, 136, 136);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 255);">-end-</span></section><section class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzU1OTgxMTg2Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/9K73WSRq6BWyKqhKFzMgibicMuLCqmmqWpOmQ2tovCBswRKVxdO6zaiarVIPc83MibTauxLibnACJWk48ibUyAXBF7dw/0?wx_fmt=png" data-nickname="京东云开发者" data-alias="JDT_Developers" data-signature="京东云开发者（Developer of JD Technology）是京东科技集团旗下为 AI、云计算、IoT 等相关领域开发者提供技术分享交流的平台。平台将发布京东产品技术信息、行业技术内容、技术活动等资讯。拥抱技术，与开发者携手预见未来！" data-from="0" data-is_biz_ban="0"></mp-common-profile></section><p><span style="letter-spacing: 1px;display: none;line-height: 0px;">‍</span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - 京东云开发者（JDT_Developers）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10315584</guid>
            <link>https://my.oschina.net/u/4090830/blog/10315584</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JumpServer 开源堡垒机 V2 社区版即将停止维护]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">尊敬的 JumpServer 开源堡垒机用户：您好！</p><p style="color:#000000; text-align:start">如《关于 JumpServer 开源堡垒机 V2 版本产品生命周期的相关说明》所示，<span style="color:#3e3e3e">JumpServer 开源堡垒机 V2 版本（社区版）将于</span><strong><span style="color:#28937c">2023 年 12 月 31 日</span></strong>停止维护支持。</p><p style="color:#000000; text-align:start">在过去两年多的时间里，JumpServer 开源堡垒机 V2 版本获得了众多用户的支持和喜爱。出于产品自身迭代和用户需求升级的要求，<strong>2023 年 2 月 27 日，JumpServer 开源堡垒机正式发布 v3.0 版本，目前已更新至 v3.9.2 版本。</strong>JumpServer 开源项目组<strong><span style="color:#28937c">建议社区版和企业版用户更新至 JumpServe v3.x 版本</span></strong>，以使用更多的新增功能并获取更好的软件使用体验。</p><p style="color:#000000; text-align:start">JumpServer V2 版本（企业版）维护支持截止日期为<strong><span style="color:#28937c">2025 年 12 月 31 日</span></strong>。</p><p style="color:#000000; text-align:start">aJumpServer 开源堡垒机 V2 版本产品生命周期具体如下，广大用户可以根据时间表合理安排系统升级及迁移工作。</p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3c2a04eded6684a1a8f9948a1e26454f4ef.jpg" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><span>▲ JumpServer 开源堡垒机 V2 版本产品生命周期</span></p><p style="color:#000000; text-align:start">感谢您长期以来对 JumpServer 开源项目的支持与厚爱。如果您在升级过程中遇到问题，可以联系 JumpServer 开源项目组获取升级建议和指导。</p><p style="color:#000000; text-align:right"><span><span style="color:#000000">JumpServer 开源项目组</span></span></p><p style="color:#000000; text-align:right"><span><span style="color:#000000">2023 年 12 月 1 日</span></span></p><p style="color:#000000; text-align:start"><span><strong><span style="color:#000000">关于 JumpServer 开源堡垒机</span></strong></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">JumpServer（jumpserver.org）是广受欢迎的开源堡垒机，遵循 GPL v3 开源许可协议，是符合 4A（包含认证 Authentication 、授权 Authorization、 账号 Accounting 和审计 Auditing）规范的运维安全审计系统。它通过企业版或者软硬件一体机的方式，向企业级用户交付开源增值的运维安全审计解决方案。</span></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">JumpServer 开源堡垒机在分布式架构设计、多云环境支持、大规模资产纳管、容器化部署、使用体验等方面极具领先性，能够很好地满足企业用户在混合 IT 环境中运维安全审计需求。</span></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">目前，JumpServer 开源项目在代码托管平台 Github 上的 Star 数量已经超过 22,400 个。在中国的企业用户群中，JumpServer 堡垒机拥有广泛的安装基础，社区版软件的累计安装部署次数超过 250,000 次，用户遍及金融、制造、物流、媒体、互联网等各行各业。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/10315623</guid>
            <link>https://my.oschina.net/u/4736111/blog/10315623</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里云开源通义千问 720 亿参数模型 Qwen-72B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今天，阿里云举办通义千问发布会，开源通义千问 720 亿参数模型 Qwen-72B。</p><p>地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fqwen%2FQwen-72B%2Fsummary" target="_blank">https://modelscope.cn/models/qwen/Qwen-72B/</a></u></em></p><p>据介绍，Qwen-72B 在 10 个权威基准测评创下开源模型最优成绩，<strong>成为业界最强开源大模型</strong>，性能超越开源标杆 Llama 2-70B 和大部分商用闭源模型。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dbe96cabe4027456789b8a9e0043edf0f57.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-dbb7cbd494ee0a9564f0102e1d5aa832bb9.png" referrerpolicy="no-referrer"></p><p>通义千问-72B (Qwen-72B) 主要特性：</p><ol><li><strong>大规模高质量训练语料</strong>：使用超过 3 万亿 tokens 的数据进行预训练，包含高质量中、英、多语言、代码、数学等数据，涵盖通用及专业领域的训练语料。通过大量对比实验对预训练语料分布进行了优化。</li><li><strong>强大的性能</strong>：Qwen-72B 在多个中英文下游评测任务上（涵盖常识推理、代码、数学、翻译等），效果显著超越现有的开源模型。具体评测结果请详见下文。</li><li><strong>覆盖更全面的词表</strong>：相比目前以中英词表为主的开源模型，</li></ol><p>通义千问还开源了 18 亿参数模型 Qwen-1.8B 和音频大模型 Qwen-Audio。至此，通义千问共开源 18 亿、70 亿、140 亿、720 亿参数的 4 款大语言模型，以及视觉理解、音频理解两款多模态大模型，实现「全尺寸、全模态」开源。</p><p><img height="727" src="https://static.oschina.net/uploads/space/2023/1201/134056_Rt7C_2720166.png" width="1280" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1201/134308_ZNwt_2720166.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlFeZToVywbkDUvKhsrKY7A" target="_blank">https://mp.weixin.qq.com/s/lFeZToVywbkDUvKhsrKY7A</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 05:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269015</guid>
            <link>https://www.oschina.net/news/269015</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Rust std fs 比 Python 慢！真的吗！？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>作者：Xuanwo</p><p>Databend Labs 成员，数据库研发工程师</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxuanwo" target="_blank">https://github.com/xuanwo</a></p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-380bdbcb15f94b1c42039337e7daa46badb.png" alt="" referrerpolicy="no-referrer"></p><p>我即将分享一个冗长的故事，从 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal" target="_blank">OpenDAL</a> 的 <code>op.read()</code>开始，以一个意想不到的转折结束。这个过程对我来说非常有启发性，我希望你也能感受到。我会尽力重现这个经历，并附上我一路学到的教训。让我们开始吧！</p><blockquote><p>所有的代码片段和脚本都可以在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow" target="_blank">Xuanwo/when-i-find-rust-is-slow</a> 中找到。</p></blockquote><h2>OpenDAL Python 绑定比 Python 慢？</h2><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal" target="_blank">OpenDAL</a> 是一个数据访问层，允许用户以统一的方式从各种存储服务中轻松高效地获取数据。我们通过 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FPyO3%2Fpyo3" target="_blank">pyo3</a> 为 OpenDAL 提供了 python 绑定。</p><p>有一天，@beldathas 在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscord.com%2Fchannels%2F1081052318650339399%2F1174840499576770560" target="_blank">discord</a> 向我报告了一个案例，即 OpenDAL 的 python 绑定比 python 慢：</p><pre><code>import&nbsp;pathlib
import&nbsp;timeit

import&nbsp;opendal

root&nbsp;=&nbsp;pathlib.Path(__file__).parent
op&nbsp;=&nbsp;opendal.Operator("fs",&nbsp;root=str(root))
filename&nbsp;=&nbsp;"lorem_ipsum_150mb.txt"

def&nbsp;read_file_with_opendal()&nbsp;-&gt;&nbsp;bytes:
&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;op.open(filename,&nbsp;"rb")&nbsp;as&nbsp;fp:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fp.read()
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;result

def&nbsp;read_file_with_normal()&nbsp;-&gt;&nbsp;bytes:
&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;open(root&nbsp;/&nbsp;filename,&nbsp;"rb")&nbsp;as&nbsp;fp:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fp.read()
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;result

if&nbsp;__name__&nbsp;==&nbsp;"__main__":
&nbsp;&nbsp;&nbsp;&nbsp;print("normal:&nbsp;",&nbsp;timeit.timeit(read_file_with_normal,&nbsp;number=100))
&nbsp;&nbsp;&nbsp;&nbsp;print("opendal:&nbsp;",&nbsp;timeit.timeit(read_file_with_opendal,&nbsp;number=100))
</code></pre><p>结果显示</p><pre><code>(venv)&nbsp;$&nbsp;python&nbsp;benchmark.py
normal:&nbsp;&nbsp;4.470868484000675
opendal:&nbsp;&nbsp;8.993250704006641
&nbsp;&nbsp;&nbsp;&nbsp;
</code></pre><p>Emmm，我对这些结果有点尴尬。以下是一些快速的假设：</p><ul><li><p>Python 是否有内部缓存可以重复使用相同的内存？</p></li><li><p>Python 是否拥有加速文件读取的一些技巧？</p></li><li><p>PyO3 是否引入了额外的开销？</p></li></ul><p>我将代码重构如下：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fpython-fs-read%2Ftest.py" target="_blank">python-fs-read</a></p><pre><code>with&nbsp;open("/tmp/file",&nbsp;"rb")&nbsp;as&nbsp;fp:
&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fp.read()
assert&nbsp;len(result)&nbsp;==&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024
</code></pre><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fpython-opendal-read%2Ftest.py" target="_blank">python-opendal-read</a></p><pre><code>import&nbsp;opendal

op&nbsp;=&nbsp;opendal.Operator("fs",&nbsp;root=str("/tmp"))

result&nbsp;=&nbsp;op.read("file")
assert&nbsp;len(result)&nbsp;==&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024
</code></pre><p>结果显示，Python 比 OpenDAL 快得多：</p><pre><code>Benchmark&nbsp;1:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.9&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.7&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.6&nbsp;ms,&nbsp;System:&nbsp;10.1&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;14.9&nbsp;ms&nbsp;…&nbsp;&nbsp;21.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;180&nbsp;runs
&nbsp;&nbsp;
Benchmark&nbsp;2:&nbsp;python-opendal-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;32.9&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;1.3&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;6.1&nbsp;ms,&nbsp;System:&nbsp;26.6&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;31.4&nbsp;ms&nbsp;…&nbsp;&nbsp;42.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;85&nbsp;runs
&nbsp;&nbsp;
Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;2.07&nbsp;±&nbsp;0.12&nbsp;times&nbsp;faster&nbsp;than&nbsp;python-opendal-read/test.py
</code></pre><p>OpenDAL 的 Python 绑定似乎比 Python 本身运行得更慢，这并不是个好消息。让我们来探究其背后的原因。</p><h2>OpenDAL Fs 服务比 Python 慢？</h2><p>这个谜题涉及到许多元素，如 rust、opendal、python、pyo3 等。让我们集中精力尝试找出根本原因。</p><p>我在 rust 中通过 opendal fs 服务实现了相同的逻辑：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Frust-opendal-fs-read%2Fsrc%2Fmain.rs" target="_blank">rust-opendal-fs-read</a></p><pre><code>use&nbsp;std::io::Read;
use&nbsp;opendal::services::Fs;
use&nbsp;opendal::Operator;

fn&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;cfg&nbsp;=&nbsp;Fs::default();
&nbsp;&nbsp;&nbsp;&nbsp;cfg.root("/tmp");
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;op&nbsp;=&nbsp;Operator::new(cfg).unwrap().finish().blocking();

&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;bs&nbsp;=&nbsp;vec![0;&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024];

&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;f&nbsp;=&nbsp;op.reader("file").unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;ts&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;loop&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;buf&nbsp;=&nbsp;&amp;mut&nbsp;bs[ts..];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;f.read(buf).unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;n&nbsp;as&nbsp;usize;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;0&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ts&nbsp;+=&nbsp;n;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;assert_eq!(ts,&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024);
}
</code></pre><p>然而，结果显示即使 opendal 是用 rust 实现的，它的速度仍然比 python 慢：</p><pre><code>Benchmark&nbsp;1:&nbsp;rust-opendal-fs-read/target/release/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.8&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;2.0&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.4&nbsp;ms,&nbsp;System:&nbsp;23.4&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;21.8&nbsp;ms&nbsp;…&nbsp;&nbsp;34.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;121&nbsp;runs
&nbsp;
Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.6&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.5&nbsp;ms,&nbsp;System:&nbsp;10.0&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;14.4&nbsp;ms&nbsp;…&nbsp;&nbsp;20.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;166&nbsp;runs
&nbsp;
Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.52&nbsp;±&nbsp;0.15&nbsp;times&nbsp;faster&nbsp;than&nbsp;rust-opendal-fs-read/target/release/test
</code></pre><p>虽然&nbsp; rust-opendal-fs-read&nbsp;的表现略优于 python-opendal-read，这暗示了在绑定和 pyo3 中有改进的空间，但这些并非核心问题。我们需要进一步深入探究。</p><p>啊，opendal fs 服务比 python 慢。</p><h2>Rust std fs 比 Python 慢？</h2><p>OpenDAL 通过 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstd%2Ffs%2Findex.html" target="_blank">std::fs</a> 实现文件系统服务。OpenDAL 本身会产生额外的开销吗？</p><p>我使用 <code>std::fs</code> 在 Rust 中实现了相同逻辑：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Frust-std-fs-read%2Fsrc%2Fmain.rs" target="_blank">rust-std-fs-read</a></p><pre><code>use&nbsp;std::io::Read;
use&nbsp;std::fs::OpenOptions;

fn&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;bs&nbsp;=&nbsp;vec![0;&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024];
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;f&nbsp;=&nbsp;OpenOptions::new().read(true).open("/tmp/file").unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;ts&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;loop&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;buf&nbsp;=&nbsp;&amp;mut&nbsp;bs[ts..];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;f.read(buf).unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;n&nbsp;as&nbsp;usize;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;0&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ts&nbsp;+=&nbsp;n;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;assert_eq!(ts,&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024);
}
</code></pre><p>但是：</p><pre><code>Benchmark&nbsp;1:&nbsp;rust-std-fs-read/target/release/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.1&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;2.5&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.3&nbsp;ms,&nbsp;System:&nbsp;22.8&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;21.0&nbsp;ms&nbsp;…&nbsp;&nbsp;37.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;124&nbsp;runs
&nbsp;
Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.2&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;1.1&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.4&nbsp;ms,&nbsp;System:&nbsp;9.7&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;14.3&nbsp;ms&nbsp;…&nbsp;&nbsp;21.4&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;178&nbsp;runs

Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.52&nbsp;±&nbsp;0.20&nbsp;times&nbsp;faster&nbsp;than&nbsp;rust-std-fs-read/target/release/test
</code></pre><p>哇，Rust 的 std fs 比 Python 还慢？这怎么可能呢？无意冒犯，但是这怎么可能呢？</p><h2>Rust std fs 比 Python 还慢？真的吗！？</h2><p>我无法相信这个结果：Rust std fs 的速度竟然比 Python 还要慢。</p><p>我尝试学会了如何使用 <code>strace</code>&nbsp;进行系统调用分析。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstrace.io%2F" target="_blank"><code>strace</code></a>是一个 Linux 系统调用追踪器，它让我们能够监控系统调用并理解其过程。</p><p>strace 将包含程序发出的所有系统调用。我们应该关注与<code>/tmp/file</code>&nbsp;相关的方面。每一行 strace 输出都以系统调用名称开始，后跟输入参数和输出。</p><p>比如：</p><pre><code>openat(AT_FDCWD,&nbsp;"/tmp/file",&nbsp;O_RDONLY|O_CLOEXEC)&nbsp;=&nbsp;3
</code></pre><p>这意味着我们使用参数 <code>AT_FDCWD</code>，<code>"/tmp/file"</code> 和 <code>O_RDONLY|O_CLOEXEC</code>调用 <code>openat</code>系统调用。这将返回输出 <code>3</code> ，这是在后续的系统调用中引用的文件描述符。</p><p>好了，我们已经掌握了 <code>strace</code>。让我们开始使用它吧！</p><p><code>rust-std-fs-read</code> 的 strace:</p><pre><code>&gt;&nbsp;strace&nbsp;./rust-std-fs-read/target/release/test
...
mmap(NULL,&nbsp;67112960,&nbsp;PROT_READ|PROT_WRITE,&nbsp;MAP_PRIVATE|MAP_ANONYMOUS,&nbsp;-1,&nbsp;0)&nbsp;=&nbsp;0x7f290dd40000
openat(AT_FDCWD,&nbsp;"/tmp/file",&nbsp;O_RDONLY|O_CLOEXEC)&nbsp;=&nbsp;3
read(3,&nbsp;"\tP\201A\225\366&gt;\260\270R\365\313\220{E\372\274\6\35\"\353\204\220s\2|7C\205\265\6\263"...,&nbsp;67108864)&nbsp;=&nbsp;67108864
read(3,&nbsp;"",&nbsp;0)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
munmap(0x7f290dd40000,&nbsp;67112960)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
...
</code></pre><p><code>python-fs-read</code> 的 strace:</p><pre><code>&gt;&nbsp;strace&nbsp;./python-fs-read/test.py
...
openat(AT_FDCWD,&nbsp;"/tmp/file",&nbsp;O_RDONLY|O_CLOEXEC)&nbsp;=&nbsp;3
newfstatat(3,&nbsp;"",&nbsp;{st_mode=S_IFREG|0644,&nbsp;st_size=67108864,&nbsp;...},&nbsp;AT_EMPTY_PATH)&nbsp;=&nbsp;0
ioctl(3,&nbsp;TCGETS,&nbsp;0x7ffe9f844ac0)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;-1&nbsp;ENOTTY&nbsp;(Inappropriate&nbsp;ioctl&nbsp;for&nbsp;device)
lseek(3,&nbsp;0,&nbsp;SEEK_CUR)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
lseek(3,&nbsp;0,&nbsp;SEEK_CUR)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
newfstatat(3,&nbsp;"",&nbsp;{st_mode=S_IFREG|0644,&nbsp;st_size=67108864,&nbsp;...},&nbsp;AT_EMPTY_PATH)&nbsp;=&nbsp;0
mmap(NULL,&nbsp;67112960,&nbsp;PROT_READ|PROT_WRITE,&nbsp;MAP_PRIVATE|MAP_ANONYMOUS,&nbsp;-1,&nbsp;0)&nbsp;=&nbsp;0x7f13277ff000
read(3,&nbsp;"\tP\201A\225\366&gt;\260\270R\365\313\220{E\372\274\6\35\"\353\204\220s\2|7C\205\265\6\263"...,&nbsp;67108865)&nbsp;=&nbsp;67108864
read(3,&nbsp;"",&nbsp;1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
rt_sigaction(SIGINT,&nbsp;{sa_handler=SIG_DFL,&nbsp;sa_mask=[],&nbsp;sa_flags=SA_RESTORER|SA_ONSTACK,&nbsp;sa_restorer=0x7f132be5c710},&nbsp;{sa_handler=0x7f132c17ac36,&nbsp;sa_mask=[],&nbsp;sa_flags=SA_RESTORER|SA_ONSTACK,&nbsp;sa_restorer=0x7f132be5c710},&nbsp;8)&nbsp;=&nbsp;0
munmap(0x7f13277ff000,&nbsp;67112960)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
...
</code></pre><p>从分析 strace 来看，很明显 <code>python-fs-read</code> 的系统调用比 <code>rust-std-fs-read</code> 多，两者都利用了<code>mmap</code>。那为什么 Python 要比 Rust 更快呢？</p><h3>👨🏻‍💻 <strong>我们这里为什么用了 <code>mmap</code>？</strong></h3><p>我最初认为<code>mmap</code>仅用于将文件映射到内存，从而通过内存访问文件。然而，<code>mmap</code>还有其他用途。它通常被用来为应用程序分配大块的内存区域。</p><p>这可以在 strace 的结果中看到：</p><pre><code>mmap(NULL,&nbsp;67112960,&nbsp;PROT_READ|PROT_WRITE,&nbsp;MAP_PRIVATE|MAP_ANONYMOUS,&nbsp;-1,&nbsp;0)&nbsp;=&nbsp;0x7f13277ff000
</code></pre><p>这个系统调用的含义是</p><ul><li><p><code>NULL</code>：第一个参数表示要映射的内存区域的起始地址。<code>NULL</code>将让操作系统为我们选择一个合适的地址。</p></li><li><p><code>67112960</code>：要映射的内存区域的大小。我们在这里分配 64MiB + 4KiB 内存，额外的页面用于存储此内存区域的元数据。</p></li><li><p><code>PROT_READ|PROT_WRITE</code>：该内存区域可读写。</p></li><li><p><code>MAP_PRIVATE|MAP_ANONYMOUS</code>:</p></li><li><p><code>MAP_PRIVATE</code>意味着对此内存区域进行更改不会对其他映射相同区域的进程可见，并且不会传递到底层文件（如果有）。</p></li><li><p><code>MAP_ANONYMOUS</code>意味着我们正在分配与文件无关联匿名内存.</p></li><li><p><code>-1</code>: 要的映射文件描述符. <code>-1</code> 表示我们没有映射文件。</p></li><li><p><code>0</code>: 文件中要从哪个偏移量开始映射. 我们并没有映射文件，所以使用 <code>0</code></p></li></ul><h3>👨🏻‍💻 <strong>但是我们代码里没有调用 <code>mmap</code> 啊？</strong></h3><p><code>mmap</code>系统调用由<code>glibc</code>分派。我们使用<code>malloc</code>向系统请求内存，作为回应， <code>glibc</code>采用了 <code>brk</code> 和 <code>mmap</code> 系统调用来根据我们的请求大小分配内存。如果请求的大小足够大，那么 <code>glibc</code> 会选择使用 <code>mmap</code>, 这有助于缓解内存碎片问题。</p><p>默认情况下，所有以目标 <code>x86_64-unknown-linux-gnu</code> 编译的 Rust 程序都使用由 <code>glibc</code> 提供的 <code>malloc</code> 实现。</p><h3>👨🏻‍💻 <strong>Python 和 Rust 是否使用相同的内存分配器？</strong></h3><p>默认情况下，Python 使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fc-api%2Fmemory.html%23default-memory-allocators" target="_blank"><code>pymalloc</code></a>，这是一个针对小型分配进行优化的内存分配器。Python 具有三个内存域，每个代表不同的分配策略，并针对各种目的进行了优化。</p><p><code>pymalloc</code> 有如下行为：</p><blockquote><p>Python has a <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fc-api%2Fmemory.html%23default-memory-allocators" target="_blank"><code>pymalloc</code></a> allocator optimized for small objects (smaller or equal to 512 bytes) with a short lifetime. It uses memory mappings called 「arenas」 with a fixed size of either 256 KiB on 32-bit platforms or 1 MiB on 64-bit platforms. It falls back to PyMem_RawMalloc() and PyMem_RawRealloc() for allocations larger than 512 bytes.</p></blockquote><h2>Rust 默认的内存分配器比 Python 慢吗？</h2><p>我怀疑<code>mmap</code>是导致这个问题的原因。如果我切换到<code>jemalloc</code>，会发生什么情况？</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Frust-std-fs-read-with-jemalloc%2Fsrc%2Fmain.rs" target="_blank">rust-std-fs-read-with-jemalloc</a></p><pre><code>use&nbsp;std::io::Read;
use&nbsp;std::fs::OpenOptions;

#[global_allocator]
static&nbsp;GLOBAL:&nbsp;jemallocator::Jemalloc&nbsp;=&nbsp;jemallocator::Jemalloc;

fn&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;bs&nbsp;=&nbsp;vec![0;&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024];
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;f&nbsp;=&nbsp;OpenOptions::new().read(true).open("/tmp/file").unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;ts&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;loop&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;buf&nbsp;=&nbsp;&amp;mut&nbsp;bs[ts..];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;f.read(buf).unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;n&nbsp;as&nbsp;usize;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;0&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ts&nbsp;+=&nbsp;n;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;assert_eq!(ts,&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024);
}
</code></pre><p><strong>Wooooooooooooooow?!</strong></p><pre><code>Benchmark&nbsp;1:&nbsp;rust-std-fs-read-with-jemalloc/target/release/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.7&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.3&nbsp;ms,&nbsp;System:&nbsp;9.4&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.0&nbsp;ms&nbsp;…&nbsp;&nbsp;12.4&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;259&nbsp;runs
&nbsp;
Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.8&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.9&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.9&nbsp;ms,&nbsp;System:&nbsp;9.8&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;15.0&nbsp;ms&nbsp;…&nbsp;&nbsp;21.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;169&nbsp;runs

Summary
&nbsp;&nbsp;rust-std-fs-read-with-jemalloc/target/release/test&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.64&nbsp;±&nbsp;0.14&nbsp;times&nbsp;faster&nbsp;than&nbsp;python-fs-read/test.py
</code></pre><p>什么？！我知道 <code>jemalloc</code>&nbsp;是一个高效的内存分配器，但它为啥会这么优秀呢？</p><h2>只有在我的电脑上，Rust 运行速度比 Python 慢！</h2><p>随着更多的朋友加入讨论，我们发现只有在我的机器上，Rust 运行速度比 Python 慢。</p><p>我的 CPU:</p><pre><code>&gt;&nbsp;lscpu
Architecture:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x86_64
&nbsp;&nbsp;CPU&nbsp;op-mode(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;32-bit,&nbsp;64-bit
&nbsp;&nbsp;Address&nbsp;sizes:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;48&nbsp;bits&nbsp;physical,&nbsp;48&nbsp;bits&nbsp;virtual
&nbsp;&nbsp;Byte&nbsp;Order:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Little&nbsp;Endian
CPU(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;32
&nbsp;&nbsp;On-line&nbsp;CPU(s)&nbsp;list:&nbsp;&nbsp;&nbsp;0-31
Vendor&nbsp;ID:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AuthenticAMD
&nbsp;&nbsp;Model&nbsp;name:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AMD&nbsp;Ryzen&nbsp;9&nbsp;5950X&nbsp;16-Core&nbsp;Processor
&nbsp;&nbsp;&nbsp;&nbsp;CPU&nbsp;family:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;25
&nbsp;&nbsp;&nbsp;&nbsp;Model:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;33
&nbsp;&nbsp;&nbsp;&nbsp;Thread(s)&nbsp;per&nbsp;core:&nbsp;&nbsp;2
&nbsp;&nbsp;&nbsp;&nbsp;Core(s)&nbsp;per&nbsp;socket:&nbsp;&nbsp;16
&nbsp;&nbsp;&nbsp;&nbsp;Socket(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1
&nbsp;&nbsp;&nbsp;&nbsp;Stepping:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;Frequency&nbsp;boost:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enabled
&nbsp;&nbsp;&nbsp;&nbsp;CPU(s)&nbsp;scaling&nbsp;MHz:&nbsp;&nbsp;53%
&nbsp;&nbsp;&nbsp;&nbsp;CPU&nbsp;max&nbsp;MHz:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5083.3979
&nbsp;&nbsp;&nbsp;&nbsp;CPU&nbsp;min&nbsp;MHz:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2200.0000
&nbsp;&nbsp;&nbsp;&nbsp;BogoMIPS:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6787.49
&nbsp;&nbsp;&nbsp;&nbsp;Flags:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fpu&nbsp;vme&nbsp;de&nbsp;pse&nbsp;tsc&nbsp;msr&nbsp;pae&nbsp;mce&nbsp;cx8&nbsp;apic&nbsp;sep&nbsp;mtrr&nbsp;pge&nbsp;mca&nbsp;cmov&nbsp;pat&nbsp;pse36&nbsp;clflush&nbsp;mmx&nbsp;fxsr&nbsp;sse&nbsp;sse2&nbsp;ht&nbsp;syscall&nbsp;nx&nbsp;mmxext&nbsp;fxsr_opt&nbsp;pdpe1gb&nbsp;rdtscp&nbsp;lm&nbsp;con
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stant_tsc&nbsp;rep_good&nbsp;nopl&nbsp;nonstop_tsc&nbsp;cpuid&nbsp;extd_apicid&nbsp;aperfmperf&nbsp;rapl&nbsp;pni&nbsp;pclmulqdq&nbsp;monitor&nbsp;ssse3&nbsp;fma&nbsp;cx16&nbsp;sse4_1&nbsp;sse4_2&nbsp;movbe&nbsp;popcnt&nbsp;aes&nbsp;xsave&nbsp;avx&nbsp;f
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16c&nbsp;rdrand&nbsp;lahf_lm&nbsp;cmp_legacy&nbsp;svm&nbsp;extapic&nbsp;cr8_legacy&nbsp;abm&nbsp;sse4a&nbsp;misalignsse&nbsp;3dnowprefetch&nbsp;osvw&nbsp;ibs&nbsp;skinit&nbsp;wdt&nbsp;tce&nbsp;topoext&nbsp;perfctr_core&nbsp;perfctr_nb&nbsp;bpex
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t&nbsp;perfctr_llc&nbsp;mwaitx&nbsp;cpb&nbsp;cat_l3&nbsp;cdp_l3&nbsp;hw_pstate&nbsp;ssbd&nbsp;mba&nbsp;ibrs&nbsp;ibpb&nbsp;stibp&nbsp;vmmcall&nbsp;fsgsbase&nbsp;bmi1&nbsp;avx2&nbsp;smep&nbsp;bmi2&nbsp;erms&nbsp;invpcid&nbsp;cqm&nbsp;rdt_a&nbsp;rdseed&nbsp;adx&nbsp;smap
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;clflushopt&nbsp;clwb&nbsp;sha_ni&nbsp;xsaveopt&nbsp;xsavec&nbsp;xgetbv1&nbsp;xsaves&nbsp;cqm_llc&nbsp;cqm_occup_llc&nbsp;cqm_mbm_total&nbsp;cqm_mbm_local&nbsp;user_shstk&nbsp;clzero&nbsp;irperf&nbsp;xsaveerptr&nbsp;rdpru&nbsp;wb
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;noinvd&nbsp;arat&nbsp;npt&nbsp;lbrv&nbsp;svm_lock&nbsp;nrip_save&nbsp;tsc_scale&nbsp;vmcb_clean&nbsp;flushbyasid&nbsp;decodeassists&nbsp;pausefilter&nbsp;pfthreshold&nbsp;avic&nbsp;v_vmsave_vmload&nbsp;vgif&nbsp;v_spec_ctrl
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;umip&nbsp;pku&nbsp;ospke&nbsp;vaes&nbsp;vpclmulqdq&nbsp;rdpid&nbsp;overflow_recov&nbsp;succor&nbsp;smca&nbsp;fsrm&nbsp;debug_swap
Virtualization&nbsp;features:
&nbsp;&nbsp;Virtualization:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AMD-V
Caches&nbsp;(sum&nbsp;of&nbsp;all):
&nbsp;&nbsp;L1d:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;512&nbsp;KiB&nbsp;(16&nbsp;instances)
&nbsp;&nbsp;L1i:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;512&nbsp;KiB&nbsp;(16&nbsp;instances)
&nbsp;&nbsp;L2:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8&nbsp;MiB&nbsp;(16&nbsp;instances)
&nbsp;&nbsp;L3:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;64&nbsp;MiB&nbsp;(2&nbsp;instances)
NUMA:
&nbsp;&nbsp;NUMA&nbsp;node(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1
&nbsp;&nbsp;NUMA&nbsp;node0&nbsp;CPU(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0-31
Vulnerabilities:
&nbsp;&nbsp;Gather&nbsp;data&nbsp;sampling:&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Itlb&nbsp;multihit:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;L1tf:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Mds:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Meltdown:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Mmio&nbsp;stale&nbsp;data:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Retbleed:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Spec&nbsp;rstack&nbsp;overflow:&nbsp;&nbsp;Vulnerable
&nbsp;&nbsp;Spec&nbsp;store&nbsp;bypass:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vulnerable
&nbsp;&nbsp;Spectre&nbsp;v1:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vulnerable:&nbsp;__user&nbsp;pointer&nbsp;sanitization&nbsp;and&nbsp;usercopy&nbsp;barriers&nbsp;only;&nbsp;no&nbsp;swapgs&nbsp;barriers
&nbsp;&nbsp;Spectre&nbsp;v2:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vulnerable,&nbsp;IBPB:&nbsp;disabled,&nbsp;STIBP:&nbsp;disabled,&nbsp;PBRSB-eIBRS:&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Srbds:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Tsx&nbsp;async&nbsp;abort:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
</code></pre><p>我的内存:</p><pre><code>&gt;&nbsp;sudo&nbsp;dmidecode&nbsp;--type&nbsp;memory
#&nbsp;dmidecode&nbsp;3.5
Getting&nbsp;SMBIOS&nbsp;data&nbsp;from&nbsp;sysfs.
SMBIOS&nbsp;3.3.0&nbsp;present.

Handle&nbsp;0x0014,&nbsp;DMI&nbsp;type&nbsp;16,&nbsp;23&nbsp;bytes
Physical&nbsp;Memory&nbsp;Array
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Location:&nbsp;System&nbsp;Board&nbsp;Or&nbsp;Motherboard
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Use:&nbsp;System&nbsp;Memory
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Error&nbsp;Correction&nbsp;Type:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;Capacity:&nbsp;64&nbsp;GB
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Error&nbsp;Information&nbsp;Handle:&nbsp;0x0013
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;Of&nbsp;Devices:&nbsp;4

Handle&nbsp;0x001C,&nbsp;DMI&nbsp;type&nbsp;17,&nbsp;92&nbsp;bytes
Memory&nbsp;Device
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Array&nbsp;Handle:&nbsp;0x0014
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Error&nbsp;Information&nbsp;Handle:&nbsp;0x001B
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total&nbsp;Width:&nbsp;64&nbsp;bits
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data&nbsp;Width:&nbsp;64&nbsp;bits
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Size:&nbsp;16&nbsp;GB
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Form&nbsp;Factor:&nbsp;DIMM
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Locator:&nbsp;DIMM&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bank&nbsp;Locator:&nbsp;P0&nbsp;CHANNEL&nbsp;A
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Type:&nbsp;DDR4
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Type&nbsp;Detail:&nbsp;Synchronous&nbsp;Unbuffered&nbsp;(Unregistered)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Speed:&nbsp;3200&nbsp;MT/s
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Manufacturer:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Serial&nbsp;Number:&nbsp;04904740
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Asset&nbsp;Tag:&nbsp;Not&nbsp;Specified
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Part&nbsp;Number:&nbsp;LMKUFG68AHFHD-32A
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rank:&nbsp;2
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Configured&nbsp;Memory&nbsp;Speed:&nbsp;3200&nbsp;MT/s
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Minimum&nbsp;Voltage:&nbsp;1.2&nbsp;V
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;Voltage:&nbsp;1.2&nbsp;V
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Configured&nbsp;Voltage:&nbsp;1.2&nbsp;V
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Technology:&nbsp;DRAM
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Operating&nbsp;Mode&nbsp;Capability:&nbsp;Volatile&nbsp;memory
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Firmware&nbsp;Version:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Module&nbsp;Manufacturer&nbsp;ID:&nbsp;Bank&nbsp;9,&nbsp;Hex&nbsp;0xC8
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Module&nbsp;Product&nbsp;ID:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Subsystem&nbsp;Controller&nbsp;Manufacturer&nbsp;ID:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Subsystem&nbsp;Controller&nbsp;Product&nbsp;ID:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Non-Volatile&nbsp;Size:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Volatile&nbsp;Size:&nbsp;16&nbsp;GB
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cache&nbsp;Size:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Logical&nbsp;Size:&nbsp;None
</code></pre><p>所以我尝试了以下事情：</p><h3>👨🏻‍💻 开启 Mitigations</h3><p>CPU 拥有许多可能将私有数据暴露给攻击者的漏洞，其中<code>Spectre</code>是最知名的之一。Linux 内核已经开发了各种缓解这些漏洞的措施，并且默认启用它们。然而，这些缓解措施可能会增加额外的系统成本。因此，Linux 内核也为希望禁用它们的用户提供了一个<code>mitigations</code>开关。</p><p>我过去禁用了所有的 mitigations：</p><pre><code>title&nbsp;Arch&nbsp;Linux
linux&nbsp;/vmlinuz-linux-zen
initrd&nbsp;/amd-ucode.img
initrd&nbsp;/initramfs-linux-zen.img
options&nbsp;root="PARTUUID=206e7750-2b89-419d-978e-db0068c79c52"&nbsp;rw&nbsp;mitigations=off
</code></pre><p>启用它并不能改变结果</p><h3>👨🏻‍💻 调整透明大页</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kernel.org%2Fdoc%2Fhtml%2Fnext%2Fadmin-guide%2Fmm%2Ftranshuge.html" target="_blank">透明大页</a>可以显著影响性能。大多数现代发行版默认启用它。</p><pre><code>&gt;&nbsp;cat&nbsp;/sys/kernel/mm/transparent_hugepage/enabled
[always]&nbsp;madvise&nbsp;never
</code></pre><p>切换到 <code>madvise</code>&nbsp;或 <code>never</code>&nbsp;会改变绝对结果，但相对比例保持一致。</p><h3>👨🏻‍💻 Tune CPU 核心亲和度</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 猜测这可能与 <code>CPU 核心间距</code> 有关。我试图使用 <a href="https://my.oschina.net/u/5489811/blog/*https://docs.rs/core_affinity/latest/core_affinity/*">core_affinity</a>将进程绑定到特定的 CPU，但结果仍然相同。</p><h3>👨🏻‍💻 <strong>使用 eBPF 精确测量 syscall 延迟</strong></h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 也为我创建了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fscripts%2Fread-latency.py" target="_blank">一个 eBPF 程序</a>，以便我衡量读取系统调用的延迟。研究结果表明，Rust 在系统调用级别上就比 Python 慢。</p><blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 写一篇文章来分享关于这个 eBPF 程序的故事！</p></blockquote><pre><code>   #&nbsp;python&nbsp;fs&nbsp;read
   Process&nbsp;57555&nbsp;read&nbsp;file&nbsp;8134049&nbsp;ns
   Process&nbsp;57555&nbsp;read&nbsp;file&nbsp;942&nbsp;ns

   #&nbsp;rust&nbsp;std&nbsp;fs&nbsp;read
   Process&nbsp;57634&nbsp;read&nbsp;file&nbsp;24636975&nbsp;ns
   Process&nbsp;57634&nbsp;read&nbsp;file&nbsp;1052&nbsp;ns
</code></pre><p>观察：在我的电脑上，Rust 运行速度比 Python 慢，而且这似乎与软件无关。</p><h2>C 比 Python 慢？</h2><p>当用户想要进行大数据分析时，心里所期望的基本是：</p><p>我感到相当困惑，无法准确指出差异。我怀疑这可能与 CPU 有关，但我不确定是哪个方面：缓存？频率？核间距？核亲和性？架构？</p><p>根据 Telegram 群组 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Frust_zh" target="_blank">Rust 众</a> 的建议，我开发了一个 C 版本：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fc-fs-read%2Ftest.c" target="_blank">c-fs-read</a></p><pre><code>#include&nbsp;&lt;stdio.h&gt;
#include&nbsp;&lt;stdlib.h&gt;

#define&nbsp;FILE_SIZE&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024&nbsp;&nbsp;//&nbsp;64&nbsp;MiB

int&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;FILE&nbsp;*file;
&nbsp;&nbsp;&nbsp;&nbsp;char&nbsp;*buffer;
&nbsp;&nbsp;&nbsp;&nbsp;size_t&nbsp;result;

&nbsp;&nbsp;&nbsp;&nbsp;file&nbsp;=&nbsp;fopen("/tmp/file",&nbsp;"rb");
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(file&nbsp;==&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fputs("Error&nbsp;opening&nbsp;file",&nbsp;stderr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;1;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;buffer&nbsp;=&nbsp;(char&nbsp;*)malloc(sizeof(char)&nbsp;*&nbsp;FILE_SIZE);
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(buffer&nbsp;==&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fputs("Memory&nbsp;error",&nbsp;stderr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fclose(file);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;2;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fread(buffer,&nbsp;1,&nbsp;FILE_SIZE,&nbsp;file);
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(result&nbsp;!=&nbsp;FILE_SIZE)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fputs("Reading&nbsp;error",&nbsp;stderr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fclose(file);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;free(buffer);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;3;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;fclose(file);
&nbsp;&nbsp;&nbsp;&nbsp;free(buffer);

&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;0;
}

</code></pre><p>但是......</p><pre><code>Benchmark&nbsp;1:&nbsp;c-fs-read/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.8&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.9&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.3&nbsp;ms,&nbsp;System:&nbsp;23.6&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;23.0&nbsp;ms&nbsp;…&nbsp;&nbsp;27.1&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;120&nbsp;runs

Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19.1&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.3&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;8.6&nbsp;ms,&nbsp;System:&nbsp;10.4&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;18.6&nbsp;ms&nbsp;…&nbsp;&nbsp;20.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;146&nbsp;runs

Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.25&nbsp;±&nbsp;0.05&nbsp;times&nbsp;faster&nbsp;than&nbsp;c-fs-read/test
</code></pre><p>C 版本也比 Python 慢！Python 有魔法吗？</p><h2><strong>在指定的偏移量下，C 语言比 Python 慢！</strong></h2><p>当用户想要进行大数据分析时，心里所期望的基本是：</p><p>在这个时候，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flilydjwg" target="_blank">@lilydjwg</a> 加入了讨论，并注意到 C 和 Python 之间的内存区域偏移存在差异。</p><blockquote><p><code>strace -e raw=read,mmap ./program</code>被用来打印系统调用的未解码参数：指针地址。</p></blockquote><pre><code>`c-fs-read` 的 strace:

    &gt;&nbsp;strace&nbsp;-e&nbsp;raw=read,mmap&nbsp;./c-fs-read/test
    ...
    mmap(0,&nbsp;0x4001000,&nbsp;0x3,&nbsp;0x22,&nbsp;0xffffffff,&nbsp;0)&nbsp;=&nbsp;0x7f96d1a18000
    read(0x3,&nbsp;0x7f96d1a18010,&nbsp;0x4000000)&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0x4000000
    close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
    python-fs-read&nbsp;的&nbsp;strace

`python-fs-read` 的 strace

    &gt;&nbsp;strace&nbsp;-e&nbsp;raw=read,mmap&nbsp;./python-fs-read/test.py
    ...
    mmap(0,&nbsp;0x4001000,&nbsp;0x3,&nbsp;0x22,&nbsp;0xffffffff,&nbsp;0)&nbsp;=&nbsp;0x7f27dcfbe000
    read(0x3,&nbsp;0x7f27dcfbe030,&nbsp;0x4000001)&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0x4000000
    read(0x3,&nbsp;0x7f27e0fbe030,&nbsp;0x1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
    close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
</code></pre><p>在 <code>c-fs-read</code> 中，<code>mmap</code>返回 <code>0x7f96d1a18000</code>，但是 read 系统调用使用 <code>0x7f96d1a18010</code>作为起始地址，偏移量是 <code>0x10</code>。在 <code>python-fs-read</code>中， <code>mmap</code> 返回 <code>0x7f27dcfbe000</code>, 并且 read 系统调用使用 <code>0x7f27dcfbe030</code> 作为起始地址, 偏移量是 <code>0x30</code>.</p><p>所以 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flilydjwg" target="_blank">@lilydjwg</a>&nbsp;尝试用相同的偏移量来调用 'read'。</p><pre><code>    :)&nbsp;./bench&nbsp;c-fs-read&nbsp;c-fs-read-with-offset&nbsp;python-fs-read
    ['hyperfine',&nbsp;'c-fs-read/test',&nbsp;'c-fs-read-with-offset/test',&nbsp;'python-fs-read/test.py']
    Benchmark&nbsp;1:&nbsp;c-fs-read/test
    &nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.7&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.2&nbsp;ms,&nbsp;System:&nbsp;23.6&nbsp;ms]
    &nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;23.0&nbsp;ms&nbsp;…&nbsp;&nbsp;25.5&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;119&nbsp;runs

    &nbsp;&nbsp;Warning:&nbsp;Statistical&nbsp;outliers&nbsp;were&nbsp;detected.&nbsp;Consider&nbsp;re-running&nbsp;this&nbsp;benchmark&nbsp;on&nbsp;a&nbsp;quiet&nbsp;system&nbsp;without&nbsp;any&nbsp;interferences&nbsp;from&nbsp;other&nbsp;programs.&nbsp;It&nbsp;might&nbsp;help&nbsp;to&nbsp;use&nbsp;the&nbsp;'--warmup'&nbsp;or&nbsp;'--prepare'&nbsp;options.

    Benchmark&nbsp;2:&nbsp;c-fs-read-with-offset/test
    &nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8.9&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.4&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.2&nbsp;ms,&nbsp;System:&nbsp;8.8&nbsp;ms]
    &nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8.3&nbsp;ms&nbsp;…&nbsp;&nbsp;10.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;283&nbsp;runs

    Benchmark&nbsp;3:&nbsp;python-fs-read/test.py
    &nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19.1&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.3&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;8.6&nbsp;ms,&nbsp;System:&nbsp;10.4&nbsp;ms]
    &nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;18.6&nbsp;ms&nbsp;…&nbsp;&nbsp;20.0&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;147&nbsp;runs

    Summary
    &nbsp;&nbsp;c-fs-read-with-offset/test&nbsp;ran
    &nbsp;&nbsp;&nbsp;&nbsp;2.15&nbsp;±&nbsp;0.11&nbsp;times&nbsp;faster&nbsp;than&nbsp;python-fs-read/test.py
    &nbsp;&nbsp;&nbsp;&nbsp;2.68&nbsp;±&nbsp;0.16&nbsp;times&nbsp;faster&nbsp;than&nbsp;c-fs-read/test
</code></pre><p>！！！</p><p>在<code>c-fs-read</code>中对<code>buffer</code>应用偏移量可以提高其速度，超过 Python！此外，我们已经验证了这个问题在 <code>AMD Ryzen 9 5900X</code> 和 <code>AMD Ryzen 7 5700X</code> 上都能复现。</p><p>新的信息让我找到了关于类似问题的其他报告，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fusers.rust-lang.org%2Ft%2Fstd-read-slow%2F85424" target="_blank">Std::fs::read slow?</a>。在这篇帖子中，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fambiso" target="_blank">@ambiso</a> 发现系统调用性能与内存区域的偏移量有关。他指出当从每页的前 <code>0x10</code> 字节写入时，这款 CPU 会变慢。</p><pre><code>    offset&nbsp;milliseconds
    &nbsp;...
    &nbsp;14&nbsp;&nbsp;&nbsp;130
    &nbsp;15&nbsp;&nbsp;&nbsp;130
    &nbsp;16&nbsp;&nbsp;&nbsp;&nbsp;46&nbsp;&nbsp;&nbsp;&lt;-----&nbsp;0x10!
    &nbsp;17&nbsp;&nbsp;&nbsp;&nbsp;48
    &nbsp;...
</code></pre><h2>在指定的偏移量下，AMD Ryzen 9 5900X 很慢！</h2><p>我们已确认这个问题与 CPU 有关。然而，我们仍然不确定其可能的原因。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a>&nbsp;已邀请内核开发者 <a href="https://my.oschina.net/u/5489811/blog/*https://github.com/ryncsn*">@ryncsn</a> 加入讨论。</p><p>他可以在 <code>AMD Ryzen 9 5900HX</code> 上使用我们的 <code>c-fs-read</code> 和 <code>c-fs-read-with-offset</code> 重现相同的结果。他还尝试使用 <code>perf</code> 对两个程序进行性能分析。</p><p><strong>没有 offset:</strong></p><pre><code>perf&nbsp;stat&nbsp;-d&nbsp;-d&nbsp;-d&nbsp;--repeat&nbsp;20&nbsp;./a.out
&nbsp;Performance&nbsp;counter&nbsp;stats&nbsp;for&nbsp;'./a.out'&nbsp;(20&nbsp;runs):

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;30.89&nbsp;msec&nbsp;task-clock&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.968&nbsp;CPUs&nbsp;utilized&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.35%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;context-switches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.000&nbsp;/sec
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu-migrations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.000&nbsp;/sec
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;598&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;page-faults&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;19.362&nbsp;K/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;0.05%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;90,321,344&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cycles&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;2.924&nbsp;GHz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.12%&nbsp;)&nbsp;&nbsp;(40.76%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;599,640&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-frontend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.66%&nbsp;frontend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;2.19%&nbsp;)&nbsp;&nbsp;(42.11%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;398,016&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-backend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.44%&nbsp;backend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;22.41%&nbsp;)&nbsp;&nbsp;(41.88%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;43,349,705&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instructions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.48&nbsp;&nbsp;insn&nbsp;per&nbsp;cycle
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.01&nbsp;&nbsp;stalled&nbsp;cycles&nbsp;per&nbsp;insn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.32%&nbsp;)&nbsp;&nbsp;(41.91%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7,526,819&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;243.701&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;5.01%&nbsp;)&nbsp;&nbsp;(41.22%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37,541&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branch-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.50%&nbsp;of&nbsp;all&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;4.62%&nbsp;)&nbsp;&nbsp;(41.12%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;127,845,213&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;4.139&nbsp;G/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.14%&nbsp;)&nbsp;&nbsp;(39.84%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,172,628&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;2.48%&nbsp;of&nbsp;all&nbsp;L1-dcache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.34%&nbsp;)&nbsp;&nbsp;(38.46%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-loads
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-load-misses
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;654,651&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;21.196&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.71%&nbsp;)&nbsp;&nbsp;(38.72%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2,828&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.43%&nbsp;of&nbsp;all&nbsp;L1-icache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;2.35%&nbsp;)&nbsp;&nbsp;(38.67%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15,615&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;505.578&nbsp;K/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.28%&nbsp;)&nbsp;&nbsp;(38.82%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12,825&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;82.13%&nbsp;of&nbsp;all&nbsp;dTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.15%&nbsp;)&nbsp;&nbsp;(38.88%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;518.043&nbsp;/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;27.06%&nbsp;)&nbsp;&nbsp;(38.82%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2,202&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;13762.50%&nbsp;of&nbsp;all&nbsp;iTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;23.62%&nbsp;)&nbsp;&nbsp;(39.38%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1,843,493&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;59.688&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.36%&nbsp;)&nbsp;&nbsp;(39.40%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetch-misses

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.031915&nbsp;+-&nbsp;0.000419&nbsp;seconds&nbsp;time&nbsp;elapsed&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.31%&nbsp;)
</code></pre><p>有 offset:</p><pre><code>perf&nbsp;stat&nbsp;-d&nbsp;-d&nbsp;-d&nbsp;--repeat&nbsp;20&nbsp;./a.out
&nbsp;Performance&nbsp;counter&nbsp;stats&nbsp;for&nbsp;'./a.out'&nbsp;(20&nbsp;runs):

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.39&nbsp;msec&nbsp;task-clock&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.937&nbsp;CPUs&nbsp;utilized&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.24%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;context-switches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;64.972&nbsp;/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;17.62%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu-migrations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.000&nbsp;/sec
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;598&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;page-faults&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;38.854&nbsp;K/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;0.06%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;41,239,117&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cycles&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;2.679&nbsp;GHz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.95%&nbsp;)&nbsp;&nbsp;(40.68%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;547,465&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-frontend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;1.33%&nbsp;frontend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.43%&nbsp;)&nbsp;&nbsp;(40.60%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;413,657&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-backend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;1.00%&nbsp;backend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;20.37%&nbsp;)&nbsp;&nbsp;(40.50%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37,009,429&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instructions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.90&nbsp;&nbsp;insn&nbsp;per&nbsp;cycle
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.01&nbsp;&nbsp;stalled&nbsp;cycles&nbsp;per&nbsp;insn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.13%&nbsp;)&nbsp;&nbsp;(40.43%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5,410,381&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;351.526&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.24%&nbsp;)&nbsp;&nbsp;(39.80%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;34,649&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branch-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.64%&nbsp;of&nbsp;all&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;4.04%&nbsp;)&nbsp;&nbsp;(39.94%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;13,965,813&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;907.393&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.37%&nbsp;)&nbsp;&nbsp;(39.44%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,623,350&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;25.94%&nbsp;of&nbsp;all&nbsp;L1-dcache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.56%&nbsp;)&nbsp;&nbsp;(39.52%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-loads
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-load-misses
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;590,613&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;38.374&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.39%&nbsp;)&nbsp;&nbsp;(39.67%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1,995&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.34%&nbsp;of&nbsp;all&nbsp;L1-icache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;4.18%&nbsp;)&nbsp;&nbsp;(39.67%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16,046&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;1.043&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.28%&nbsp;)&nbsp;&nbsp;(39.78%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14,040&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;87.50%&nbsp;of&nbsp;all&nbsp;dTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.24%&nbsp;)&nbsp;&nbsp;(39.78%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;714.697&nbsp;/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;29.56%&nbsp;)&nbsp;&nbsp;(39.77%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,657&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;33245.45%&nbsp;of&nbsp;all&nbsp;iTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;14.61%&nbsp;)&nbsp;&nbsp;(40.30%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;395,578&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;25.702&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.34%&nbsp;)&nbsp;&nbsp;(40.10%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetch-misses

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.016429&nbsp;+-&nbsp;0.000521&nbsp;seconds&nbsp;time&nbsp;elapsed&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.17%&nbsp;)
</code></pre><p>他发现<code>L1-dcache-prefetches</code>和<code>L1-dcache-loads</code>的值差异很大。</p><ul><li><p><code>L1-dcache-prefetches</code>是 CPU L1 数据缓存的预取。</p></li><li><p><code>L1-dcache-loads</code>是 CPU L1 数据缓存的加载。</p></li></ul><p>如果没有指定偏移量，CPU 将执行更多的加载和预取操作，导致系统调用时间增加。</p><p>他对热点 ASM 进行了进一步研究：</p><pre><code>Samples:&nbsp;15K&nbsp;of&nbsp;event&nbsp;'cycles:P',&nbsp;Event&nbsp;count&nbsp;(approx.):&nbsp;6078132137
&nbsp;&nbsp;Children&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Self&nbsp;&nbsp;Command&nbsp;&nbsp;&nbsp;&nbsp;Shared&nbsp;Object&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Symbol
-&nbsp;&nbsp;&nbsp;94.11%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.00%&nbsp;&nbsp;a.out&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[kernel.vmlinux]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[k]&nbsp;entry_SYSCALL_64_after_hwframe&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;-&nbsp;entry_SYSCALL_64_after_hwframe&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;94.10%&nbsp;do_syscall_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;86.66%&nbsp;__x64_sys_read&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ksys_read&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;vfs_read&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;85.94%&nbsp;shmem_file_read_iter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;77.17%&nbsp;copy_page_to_iter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;75.80%&nbsp;_copy_to_iter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;19.41%&nbsp;asm_exc_page_fault&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.71%&nbsp;__might_fault&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;4.87%&nbsp;shmem_get_folio_gfp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.76%&nbsp;folio_mark_accessed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;4.38%&nbsp;__x64_sys_munmap&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;1.02%&nbsp;0xffffffffae6f6fe8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;0.79%&nbsp;__x64_sys_execve&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;0.58%&nbsp;__x64_sys_mmap&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</code></pre><p><code>_copy_to_iter</code> 中的 ASM：</p><pre><code>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy_user_generic():
    &nbsp;&nbsp;2.19&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mov&nbsp;&nbsp;&nbsp;&nbsp;%rdx,%rcx
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mov&nbsp;&nbsp;&nbsp;&nbsp;%r12,%rsi
    &nbsp;92.45&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rep&nbsp;&nbsp;&nbsp;&nbsp;movsb&nbsp;%ds:(%rsi),%es:(%rdi)
    &nbsp;&nbsp;0.49&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nop
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nop
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nop
</code></pre><p>这里的关键区别是<code>rep movsb</code>的性能。</p><h2>AMD Ryzen 9 5900X 因为 FSRM 慢！</h2><p>在这个时候，我的一个朋友给我发送了一个关于<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugs.launchpad.net%2Fubuntu%2F%2Bsource%2Fglibc%2F%2Bbug%2F2030515" target="_blank">Terrible memcpy performance on Zen 3 when using rep movsb</a>的链接。其中也指向了<code>rep movsb</code>：</p><blockquote><p>I've found this using a memcpy benchmark at <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fska-sa%2Fkatgpucbf%2Fblob%2F69752be58fb8ab0668ada806e0fd809e782cc58b%2Fscratch%2Fmemcpy%5C%5C_loop.cpp" target="_blank">https://github.com/ska-sa/katgpucbf/blob/69752be58fb8ab0668ada806e0fd809e782cc58b/scratch/memcpy\\_loop.cpp</a> (compiled with the adjacent Makefile). To demonstrate the issue, run</p><p>./memcpy_loop -b 2113 -p 1000000 -t mmap -S 0 -D 1 0</p><p>This runs:</p><ul><li><p>•&nbsp;2113-byte memory copies</p></li><li><p>•&nbsp;1,000,000 times per timing measurement</p></li><li><p>•&nbsp;in memory allocated with mmap</p></li><li><p>•&nbsp;with the source 0 bytes from the start of the page</p></li><li><p>•&nbsp;with the destination 1 byte from the start of the page</p></li><li><p>•&nbsp;on core 0.</p></li></ul><p>It reports about 3.2 GB/s. Change the -b argument to 2111 and it reports over 100 GB/s. So the REP MOVSB case is about 30× slower!</p></blockquote><p><code>FSRM</code>，即 <code>Fast Short REP MOV</code>，是英特尔最初的创新，近期也被 AMD 采纳，用以提升 <code>rep movsb</code> 和 <code>rep movsd</code> 的速度。它旨在提高大量内存复制的效率。声明支持它的 CPU 将在 <code>glibc</code> 中默认使用 <code>FSRM</code>。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fryncsn" target="_blank">@ryncsn</a> 进一步研究并发现它与 L1 预取无关。</p><blockquote><p>It seems that <code>rep movsb</code> performance poorly when DATA IS PAGE ALIGNED, and perform better when DATA IS NOT PAGE ALIGNED, this is very funny...</p></blockquote><h2>总结</h2><p>总的来说，这个问题并非与软件有关。由于 AMD 的一个错误，Python 在性能上超过了 C/Rust。（我终于可以好好睡觉了。）</p><p>然而，我们的用户仍然需要面对这个问题。不幸的是，像<code>FSRM</code>这样的功能将会被实现在<code>ucode</code>中，我们别无选择只能等待 AMD 的回应。另一种可能的解决方案是不使用<code>FSRM</code>或者提供一个标志来禁用它。Rust 开发者可能会考虑切换到 <code>jemallocator</code>以提高性能 ，即使没有 AMD CPU Bug 存在，这也是一个好主意！</p><h2>回顾</h2><p>我花了近三天的时间来解决这个问题，它始于 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal" target="_blank">opendal:</a> 用户的投诉，并最终引导我到 CPU 的微代码。这次旅程让我对<code>strace</code>、<code>perf</code>和<code>eBPF</code>有了深入的了解。这是我第一次使用 <code>eBPF</code>进行诊断。我还探索了各种收效甚微的途径，比如研究 rust 的 <code>std::fs</code> 和 Python &amp; CPython 的读取实现细节。起初，我希望能在更高层面上解决这个问题，但发现有必要深入挖掘。</p><p>对于所有参与寻找答案的人，我表示衷心感谢：</p><ul><li><p>感谢 opendal 的 Discord 上的 @beldathas 发现了这个问题。</p></li><li><p>感谢 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs" target="_blank">@datafuselabs</a> 团队提供的建议。</p></li><li><p>感谢我们在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Frust_zh" target="_blank">Rust 众</a>&nbsp;的朋友们给出的建议和复现努力。</p></li><li><p>感谢 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 复现问题并使用 eBPF 进行调查，这帮助我们将问题定位到系统调用本身。</p></li><li><p>感谢 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flilydjwg" target="_blank">@lilydjwg</a> 找出根本原因：内存中<code>0x20</code>偏移量 -感谢 <a href="https://my.oschina.net/u/5489811/blog/*https://github.com/ryncsn*">@ryncsn</a> 他对此事进行了彻底分析。</p></li><li><p>•&nbsp;还有一位分享了关于 FSRM 有用链接的朋友。</p></li></ul><p>期待我们下次旅程！</p><h2>引用</h2><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow" target="_blank">Xuanwo/when-i-find-rust-is-slow</a>&nbsp;有所有的样例和脚本</p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fusers.rust-lang.org%2Ft%2Fstd-read-slow%2F85424" target="_blank">Std::fs::read slow?</a> 是来自 Rust 社区的汇报</p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugs.launchpad.net%2Fubuntu%2F%2Bsource%2Fglibc%2F%2Bbug%2F2030515" target="_blank">Terrible memcpy performance on Zen 3 when using rep movsb</a> 是来自 ubuntu glibc 的报告</p></li><li><p>[binding/python](rust std fs is slower than python fs:&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal%2Fissues%2F3665" target="_blank">https://github.com/apache/incubator-opendal/issues/3665</a>)</p></li></ul><h2>关于&nbsp;Databend</h2><p>Databend 是一款开源、弹性、低成本，基于对象存储也可以做实时分析的新式数仓。期待您的关注，一起探索云原生数仓解决方案，打造新一代开源 Data Cloud。</p><p>👨‍💻‍ Databend Cloud：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatabend.cn" target="_blank">https://databend.cn</a></p><p>📖 Databend 文档：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatabend.rs%2F" target="_blank">https://databend.rs/</a></p><p>💻 Wechat：Databend</p><p>✨ GitHub：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend" target="_blank">https://github.com/datafuselabs/databend</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 05:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5489811/blog/10314995</guid>
            <link>https://my.oschina.net/u/5489811/blog/10314995</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[恭喜 Devlive DataCap 新晋一位前端 Committer]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>非常感谢所有对 DataCap 项目的支持和贡献，我们迎来了新的一位来自互联网行业的美女前端工程师，感谢她对 DataCap 的支持已经代码的贡献。</p></blockquote><p><img alt="8AA600FB-3F02-4229-8353-EA4400BCE1D7.jpg" src="https://images.edurt.io/devlive.org/2023-12-1/8AA600FB-3F02-4229-8353-EA4400BCE1D7.jpg" referrerpolicy="no-referrer"></p><h3>关于 DataCap</h3><hr><p>DataCap 是数据转换、集成和可视化的集成软件。支持多种数据源，文件类型，大数据相关数据库，关系型数据库，NoSQL 数据库等。通过软件可以实现管理多种数据源，对该源下的数据进行各种操作转换，制作数据图表，监控数据源等各种功能。</p><h3>DataCap 喜迎一位 Committer 成员</h3><hr><table><tbody><tr><th>名字</th><th>职业</th><th>GitHub ID</th></tr></tbody><tbody><tr><td>张扬</td><td>前端工程师</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FStacey1018" target="_blank">Stacey1018</a></td></tr></tbody></table><h4>个人描述</h4><hr><p>一名热情富有经验的前端开发者，我曾参与过多个前端项目，从小型网站到大型应用都有涉猎。熟悉 <code>react</code>、<code>vue</code>、<code>angular</code> 等多个前端框架。熟悉打包工具如 <code>Webpack</code>，能够优化前端资源的加载和管理，从而提高网站的性能。</p><h4>对 DataCap 的认识</h4><hr><p>在做公司数据部门项目时，从 github 中搜索，发现 datacap 项目，结合公司内部业务，经过一段时间运行后发现页面组件出现层级问题和 MonacoEditor 组件渲染问题，特意在源码中修复了以上两个问题。</p><h4>代码提交之路</h4><hr><ol><li>在 datacap 上提交了相关代码 (commit 9afddb4f4edb529cc80dda76a9c52acb33e933dd (HEAD -&gt; fixbug/zy))</li></ol><h4>得到的收获</h4><hr><ol><li>借此机会学习了新技术，工具，是提升自己技能和知识的宝贵机会</li><li>很荣幸参与 datacap 开源项目，熟悉了开源项目整个开发流程</li></ol><h4>对新人的建议</h4><hr><ol><li>参与项目开发时，可以先从一些小任务，小问题入手，有助于熟悉项目代码</li><li>建议从自己熟悉的技术栈入手，这样可以更快的融入项目</li><li>建议将项目部署下来，这样才能得到真实的体验</li></ol><h4>如何参与 DataCap</h4><hr><ul><li>参考官网 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fdatacap.devlive.org%2Fdeveloper_guide%2Fenv.html" target="_blank">开发者文档</a></li><li>通过 Issues 列表参与 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdevlive-community%2Fdatacap%2Fissues" target="_blank">GitHub</a> &amp; <a href="https://gitee.com/devlive-community/datacap/issues">Gitee</a></li><li>加入我们的微信群&amp;钉钉群（在代码仓库中可以看到二维码）</li><li>微信公众号后台留言（搜索微信公公众号 <code>devlive-sf</code> 关注，标记 DataCap 项目给我们留言即可）</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268990</guid>
            <link>https://www.oschina.net/news/268990</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Android Studio Hedgehog (2023.1.1) 稳定版发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Android Studio 2023.1.1&nbsp;<span>稳定版</span><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fandroid-studio-hedgehog-is-stable.html" target="_blank">已发布</a></u><span>，代号 "</span>Hedgehog<span>"。</span></p><p>下载地址：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.android.com%2Fstudio%3Fhl%3Dzh-cn" target="_blank">https://developer.android.com/studio</a></u></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb7ce431349064dcf0ec711ab407e8f5cc7.png" referrerpolicy="no-referrer"></p><p>Android Studio Hedgehog 将底层 IntelliJ 平台升级到了 2023.1，添加了新功能，旨在提高应用程序性能和电池寿命，使升级到最新 Android 版本的应用程序更容易，并且提升使用 Jetpack Compose 的开发速度，以提高开发者的生产力。</p><p>以下是一些主要的功能和改进：</p><ol><li><p><strong>应用程序性能</strong>：Android Studio Hedgehog 提供了 App Quality Insights 工具，其中包括 Android vitals 数据。通过 Android vitals，开发者可以查看在 Google Play 商店发布的任何应用程序的崩溃报告，无需在应用程序中进行额外的仪器化。开发者可以查看 Android vitals 问题、筛选它们，并从 Play 中查看崩溃的原因，从堆栈跟踪跳转到代码，快速了解和解决崩溃。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-abcd5ef88e1fb351967ac0d35d842b2130a.png" referrerpolicy="no-referrer"><br> &nbsp;</p></li><li><p><strong>电源分析器</strong>：新的 Power Profiler 可以显示设备上的电源消耗情况。它将电源消耗信息按子系统（称为「Power Rails」）进行分段。这有助于开发者可视化电源消耗与应用程序中发生的操作之间的关联。通过了解这些信息，开发者可以通过运行 A/B 测试来比较不同算法、功能甚至应用程序的不同版本的功耗，从而可能识别和修复应用程序中的功耗问题。优化功耗较低的应用程序可以改善电池和热性能，最终提供更好的用户体验。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-3ebcd51b6c8babaede19a4faa95fb8d39d0.png" referrerpolicy="no-referrer"><br> &nbsp;</p></li><li><p><strong>编码生产力</strong>：Android Studio Hedgehog 引入了 Android SDK Upgrade Assistant，它提供了一个逐步向导流程，帮助开发者升级到目标 SDK 版本。它将文档直接引入 IDE，节省时间和精力。Hedgehog 版本还添加了额外的相关性过滤器，以删除不必要的步骤，并且在某些情况下，升级助手将准确指出需要进行更改的代码位置。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-f3c9eb53c6f9692cca6fe995cb22f8f0415.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></li><li><p><strong>新的用户界面</strong>：在 Giraffe 版本中，我们推出了一个全新的用户界面。这个重新设计的主题减少了视觉复杂性，提供了更容易访问的基本功能，使界面看起来更加现代和清晰。在 Hedgehog 版本中，我们根据用户的反馈进行了更新，添加了紧凑模式、垂直和水平分割以及 Mac OS 的项目选项卡。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-ec74c1d250255dab48c8691f8f1a467d857.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></li><li><p><strong>设备镜像</strong>：您现在可以在 Android Studio 的 Running Devices 窗口中镜像您的物理 Android 设备。通过通过 ADB 通过 USB 或 Wi-Fi 直接在 Android Studio 中镜像设备的显示屏，您可以执行常见操作，如启动和与应用程序交互、旋转屏幕、折叠和展开手机、调整音量等。这样可以方便地在 Android Studio 内部完成这些操作，而无需切换到设备上进行操作。<br><img src="https://oscimg.oschina.net/oscnet/up-e948c8fe967e8a8edccd6df3a0c819f7fed.gif" referrerpolicy="no-referrer"></p></li></ol><p>详情查看<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fandroid-studio-hedgehog-is-stable.html" target="_blank">发布公告</a></u>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 03:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268979/android-studio-hedgehog-stable</guid>
            <link>https://www.oschina.net/news/268979/android-studio-hedgehog-stable</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[袋鼠数据库工具 v3.99.2 已发布，第一个完成 GTK4 升级的大型应用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>重点特性介绍</h2><ol><li>这是两个版本（3.99.1 / 3.99.2）的合并新闻稿</li><li>连接管理页面支持分组和添加机构；</li><li>起始页支持自定义默认页面</li><li>对象浏览器全字段过滤支持</li><li>App 实现激活支持</li></ol><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">袋鼠从第一行代码到成长为 GTK3 应用中的顶流杠把子，又经过两年多夜以继日的升级开发，成为第一个完成 GTK4 升级的大型 GTK 应用，开发团队为此付出了艰苦卓绝的努力，克服了重重困难。数据库引擎从 libgda 5.0 到 libgda 6.0，然后升级到 ODBC，再升级为 DirectAccess；SQLite 支持从 SQLite 到 SQLCiphper，再到 SQLite3MC。。。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">如果您能体验到袋鼠的生产力和丝滑功能，也请您为袋鼠团队加油，谢谢。</p><h2>新特性或修复的缺陷列表</h2><ul><li>起始页支持自定义默认首页</li><li>更新模块文件属性</li><li>调整数据网格列宽度</li><li>重构执行行为支持多语句执行</li><li>数据库连接添加分组和机构支持</li><li>改进对象浏览器全字段过滤支持</li><li>更新数据网格当前单元格背景颜色</li><li>App 实现激活支持</li><li>添加多模型视图支持</li><li>工作台关闭时添加提示和确认支持</li><li>SQLite: 替换 SQLCipher 为 SQLite3MC</li><li>SQLite: 增加兼容性支持提示</li><li>SQLite: 调整表设计界面字段类型</li><li>PostgreSQL: 隐藏模板和临时数据库</li><li>更新中文语言支持 (zh-CN/zh-TW/zh-SG/zh-HK)</li><li>改进，空值 (NULL) 支持</li><li>修复: MySQL/MariaDB 导出崩溃问题</li><li>修复: 快速打开并关闭连接空间时崩溃问题</li><li>修复: 导出表结构和数据到文件时崩溃问题</li><li>修复: 源码编辑器显示样式问题</li><li>修复: SQL 格式化和缩微化丢失内容问题</li><li>修复: 连接空间视图布局加载问题</li><li>修复: App 关闭时无法保存空间布局问题</li><li>修复: 实体关系模型视图关闭时崩溃问题</li><li>修复: 使用错误的类型封装用户数据</li></ul><h2>下载与安装</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv3.99.2.231201.html" target="_blank">袋鼠数据库管理工具 3.99.1</a></p><h2>新版本功能快照</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2F" target="_blank"><img alt="连接分组" src="https://oscimg.oschina.net/oscnet/up-bae7af3d082e6a4a7194345022123e1606f.gif" referrerpolicy="no-referrer"></a><span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2F" target="_blank"><img alt="首页默认页定制" src="https://oscimg.oschina.net/oscnet/up-5e72dbe9eda442c20c3aef0fa33d34c1412.png" referrerpolicy="no-referrer"></a><span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv3.93.1.230928.html" target="_blank"><img alt="袋鼠数据库工具 v3.93.1 快照" src="https://oscimg.oschina.net/oscnet/up-e0853214711ebcdc88b4aa8ddeff6e5f7c6.png" referrerpolicy="no-referrer"></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268976/kangaroo-3-99-2-released</guid>
            <link>https://www.oschina.net/news/268976/kangaroo-3-99-2-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[哈工大人工智能专业大一学生写了 70 万行代码？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>哈尔滨工业大学近日在其公众号发表的一篇文章引起了不小争议。</p><p>该文章介绍称，哈工大计算学部人工智能专业的一名 2022 级学生在中国机器人及人工智能大赛总决赛上获得了<strong>机器人应用赛（自动驾驶仿真）一等奖</strong>。</p><p>据了解，该比赛涉及人工智能、无人驾驶 &nbsp;和虚拟仿真等学科领域，还涉及高精地图、定位、感知 &nbsp;预测、规划与控制等模块的运行机制和代码架构。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-4e9f3dd3dff3e07407fc1c6d36c7929e333.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c32e0b9e93b8ada29cac4146e775157de9d.png" referrerpolicy="no-referrer"></p></blockquote><p>但写这篇文章的人显然不了解编程，所以闹出了下图中「连续几个月写了 70 万行代码」的抽象现场。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-08391d81d81371237587ffa244dd02b6ae9.png" referrerpolicy="no-referrer"></p><p><img height="714" src="https://static.oschina.net/uploads/space/2023/1201/105216_eog8_2720166.png" width="1400" referrerpolicy="no-referrer"></p><p><img height="668" src="https://static.oschina.net/uploads/space/2023/1201/103954_yEjJ_2720166.png" width="1406" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKyBMh6QHPZ3yUxRxjFKIJQ" target="_blank">https://mp.weixin.qq.com/s/KyBMh6QHPZ3yUxRxjFKIJQ</a></u></em><br><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrAjBwbzKwmxMNrzBOAUy6w" target="_blank">https://mp.weixin.qq.com/s/rAjBwbzKwmxMNrzBOAUy6w</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 02:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268970</guid>
            <link>https://www.oschina.net/news/268970</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
