<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 16 Nov 2023 04:58:48 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[开源中国将在年末推出大模型托管平台，大量人才招募中]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">Gitee 正在招募大量人才，欢迎加入。</span></span></p><p><span style="color:#000000"><img alt="" height="1348" src="https://static.oschina.net/uploads/space/2023/1116/114828_diMZ_3820517.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">开源中国于 2023 年 6 月完成了 B+ 轮战略融资，</span><strong><span style="background-color:#ffffff">融资总额达 7.75 亿元</span></strong><span style="background-color:#ffffff">，公司创始团队重新成为实际控制人，经此股份重组企业成为完全中立平台。目前，开源中国员工共计 300 余人，其中研发团队占比 85% 以上。</span></span></p><p><span style="color:#000000"><strong><span style="background-color:#ffffff">开源中国将在年末推出大模型托管平台</span></strong><span style="background-color:#ffffff">，在 AI 时代为广大开发者和企业提供更高质量的服务。从软件应用到 AI 时代，开源中国将坚持帮助国内开发者和企业共同发展，创造健康的生态环境。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Gitee 是开源中国旗下，国内第一大企业级研发效能平台和全球第二大开源代码托管平台。经过 10 年发展，Gitee 已经拥有超过 1100 万开发者，托管超过 2500 万个代码仓库，服务 26 万家企业（含 1200 家中大型私有化部署企业）和 2000 多所高校，为他们提供优质的 DevOps 产品服务。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 16 Nov 2023 03:58:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266707/gitee-hiring</guid>
            <link>https://www.oschina.net/news/266707/gitee-hiring</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[金山办公 WPS AI 开启公测]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>金山办公<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcSKhX3tqmZgdw7EfTid_TA" target="_blank">宣布</a>旗下只能办公助手 WPS AI 开启公测，即日起面向全体用户陆续开放体验。WPS AI 是一款生成式人工智能应用，具备了大语言模型能力。它提供起草、改写、总结、润色等功能，可以提高办公创作效率。</p><p>用户可前往 <strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.wps.cn%2F" target="_blank">WPS AI 官网</a></strong>申请权益，并下载最新版 WPS PC 客户端限时体验文字/智能文档、表格/智能表格、PPT 演示组件的 AI 能力，安卓、iOS 和 Mac 端预计将于 11 月底陆续开放。</p><p><img alt="" height="376" src="https://oscimg.oschina.net/oscnet/up-9b4717aaa45d58081e02785ba28fc5dda23.png" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="354" src="https://oscimg.oschina.net/oscnet/up-fa29542a7d817329492fdc62024e16f7025.png" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="379" src="https://oscimg.oschina.net/oscnet/up-f98e75322933cd6c5d3e5239be36401148e.png" width="300" referrerpolicy="no-referrer"></p><p>更多详细功能介绍可查看 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhome.wps.cn%2Ftopic%2F10254" target="_blank">WPS AI 能力介绍（11 月最新版）</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 16 Nov 2023 03:52:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266706</guid>
            <link>https://www.oschina.net/news/266706</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软将 Bing Chat 更名为 Copilot in Bing]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在 Ignite 2023 大会上，微软宣布将今年早些时候在 Bing 上推出的 AI 聊天机器人 Bing Chat 更名为 Copilot in Bing。与此同时，Bing Chat 的高端企业版（之前称为 Bing Chat Enterprise）也已更名为 Copilot。</span></p><p><span style="color:#000000">目前该公司现在约有十几种产品共享 Copilot 品牌，微软方面表示，此次改名并不是为了造成混淆。其通信总监 Caitlin Roulston 解释称，「将 Bing Chat Enterprise 更名为 Copilot 反映了我们为消费者和商业客户打造统一的 Copilot 体验的愿景。」</span></p><p><span style="color:#000000">科技媒体 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F11%2F15%2Fbing-chat-is-now-copilot%2F" target="_blank">TechCrunch</a> 认为，虽然 Roulston 的言论有一定的道理。但也不排除是因为 Bing Chat 并没有给 Bing 带来多大的推动，所以微软希望将这项技术与推出它的搜索引擎剥离开来的原因。StatCounter 8 月份的一份报告指出，在 Bing Chat 推出六个月后，Bing 未能从 Google 手中夺取任何市场份额；不过微软方面对这一调查结果提出异议。</span></p><p><img height="279" src="https://oscimg.oschina.net/oscnet/up-3a23b972d5c87805c49dd110d3b0bb06145.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">除了改名之外，从 12 月 1 日起，使用企业账户（准确地说，是 Microsoft Entra ID）登录 Bing 的用户在 Bing 中使用 Copilot 时，将享受"商业数据保护"的好处。Roulston 称，这意味着用户的数据不会被保存、不会被用于训练人工智能模型，且微软也无法访问这些数据。</span></p><p><span style="color:#000000">「Copilot 将于 12 月 1 日更新商业条款和条件，以反映它是微软的通用产品。作为其中的一部分，它将继承微软在线服务的通用许可条款……随着时间的推移，微软将免费向更多的 Entra ID 用户提供具有商业数据保护功能的 Copilot。」</span></p><p><span style="color:#000000">除了 Copilot.Microsoft.com 和 Bing 之外，现在还可以在 Windows 中访问 Copilot，并在 Microsoft 的一系列企业订阅计划（Microsoft 365 E、E5、Business Premium 和 Business Standard）中提供，无需额外付费。Copilot 将从 12 月 1 日起包含在 Microsoft 365 F3 中。对于所有其他客户，它将以每月 5 美元的价格提供服务。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 16 Nov 2023 03:29:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266700/bing-chat-rename-copilot</guid>
            <link>https://www.oschina.net/news/266700/bing-chat-rename-copilot</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里云 11.12 故障原因曝光：访问密钥服务 (Access Key) 异常]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>针对阿里云 11.12 的重大服务故障， 该公司发给客户的一份「官方故障报告」昨天在网上被广泛流传。</span></p><blockquote><p><span>事件回顾：</span><u><a href="https://www.oschina.net/news/266144">阿里云严重故障，全线产品受影响（已恢复）</a></u></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-12e038da50562b9fb7806fac53534a272ac.png" referrerpolicy="no-referrer"></p><hr><p style="margin-left:0; margin-right:0"><strong><span>影响范围</span></strong></p><p><span style="color:#021eaa"><strong><span style="color:#021eaa">1、OSS、OTS、SLS、MNS 等产品的部分服务受到影响，大部分产品如 ECS、RDS、网络等运行不受影响。</span></strong></span></p><p><span style="color:#0052ff"><strong><span>2、云产品控制枱、管控 API 等功能受到影响。</span></strong></span></p><p style="margin-left:0; margin-right:0"><strong><span>时间</span></strong></p><p><span style="color:#0052ff"><strong><span>2023 年 11 月 12 日 17:39～19.20，</span></strong></span><span style="color:#021eaa"><strong><span>故障时间为 1 小时 41 分。</span></strong></span></p><p style="margin-left:0; margin-right:0"><strong><span style="color:rgba(0, 0, 0, 0.9)">问题概况</span></strong></p><p><span style="color:#0052ff"><strong><span>2023 年 11 月 12 日 17:39 起，阿里云云产品控制枱访问及管控 API 调用出现异常、部分云产品服务访问异常，工程师排查故障原因与访问密钥服务 (AK) 异常有关。工程师修订白名单版本后，采取分批重启 AK 服务的措施，于 18:35 开始陆续恢复，19:20 绝大部分 Region 产品控制枱和管控 API 恢复。</span></strong></span></p><p style="margin-left:0; margin-right:0"><strong><span style="color:rgba(0, 0, 0, 0.9)">处理过程</span></strong></p><p><span>17:39：阿里云云产品控制枱访问及管控 API 调用出现异常。</span></p><p><span>17:50：工程师确认故障是 AK 服务异常导致，影响云产品控制枱、管控 API 调<span>用异常，以及依赖 AK 服务的云产品服务运行异常。</span></span></p><p><span>18:01：工程师定位到根因。</span></p><p><span>18:07：开始执行恢复措施，包括修订白名单版本、重启 AK 服务。</span></p><p><span>18:35：杭州等 Region 开始恢复正常。</span></p><p><span>19:20：绝大部分 Region 的云产品控制枱和管控 API 调用恢复正常。</span></p><p style="margin-left:0; margin-right:0"><strong><span>原因</span></strong></p><p><span style="color:#021eaa"><strong><span>访问密钥服务 (AK）在读取白名单数据时出现读取异常，因处理读取异常的代码存在逻辑缺陷，生成了一份不完整白名单，导致不在此白名单中的有效请求失败，影响云产品控制枱及管控 API 服务出现异常，同时部分依赖 AK 服务的产品因不完整的白名单出现部分服务运行异常。</span></strong></span></p><p style="margin-left:0; margin-right:0"><strong><span>改进措施</span></strong></p><p><span>1、增加 AK 服务白名单生成结果的校验及告警拦截能力。</span></p><p><span>2、增加 AK 服务白名单更新的灰度验证逻辑，提前发现异常。</span></p><p><span>3、增加 AK 服务白名单的快速恢复能力。</span></p><p><span>4、加强云产品侧的联动恢复能力。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 15 Nov 2023 03:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266694</guid>
            <link>https://www.oschina.net/news/266694</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米官宣 Xiaomi Vela 全面开源，底层内核为 NuttX]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>小米澎湃 OS 刚刚在微博<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.weibo.com%2F1786860821%2FNsNK2mfse%3Fpagetype%3Dprofilefeed" target="_blank">宣布</a></u>，Xiaomi Vela 采用 Apache 2.0 License 面向全球软硬件开发者正式开源。</p><blockquote><p><img height="1352" src="https://static.oschina.net/uploads/space/2023/1116/102959_ekSh_2720166.png" width="2000" referrerpolicy="no-referrer"></p></blockquote><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fiot.mi.com%2Fvela" target="_blank">根据官网的介绍</a></u>，Xiaomi Vela 是小米基于开源实时操作系统<strong><u><a href="https://www.oschina.net/p/nuttx">NuttX</a></u></strong>打造的物联网嵌入式软件平台，Vela 在各种物联网硬件平台上提供统一的软件服务，支持丰富的组件和易用的框架，打通碎片化的物联网应用场景。‘Vela’ 一词源自拉丁语中船帆的含义，也是南方星空中最亮的星座之一。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2e4d78299513d8dd8e48dd44f9f1c80cbea.png" referrerpolicy="no-referrer"></p><p><strong>Xiaomi Vela 主要特性</strong></p><ul><li>高效性能：Vela 基于 NuttX 内核，具有高实时性、低功耗、低延迟等特点，适用于各种资源受限的嵌入式设备。</li><li>丰富组件：Vela 提供了多种常用的组件，如网络、音频、视频、图形、安全等，方便开发者快速构建应用。</li><li>易用框架：Vela 提供了一套统一的应用框架，支持 Lua、JavaScript 等脚本语言开发应用，并提供了丰富的 API 和文档。</li><li>万物互联：Vela 支持多种通信协议和标准，如 WiFi、BLE、Zigbee、MQTT 等，并提供了小米妙享技术，实现设备之间的无缝连接和协同。</li></ul><p><strong>Xiaomi Vela 系统架构如下</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-9bc7edd16b77b3d0ef73407769d0dc0b404.png" referrerpolicy="no-referrer"></p><ul><li><strong>底层 NuttX 内核</strong>：提供最基本的任务调度、跨进程间通信、文件系统等基础 OS 功能，同时也提供简洁高效的设备驱动、轻量级的 TCP/IP 协议栈和电源管理等组件。</li><li><strong>应用框架</strong>：分为上下两层，下层是为扩展系统服务而提供的通用应用框架，上层是针对不同的物联网应用而开发的定制应用框架，例如多媒体应用框架和传感应用框架，提供 Cloud SDK 可以方便开发者更快速的接入小米云服务。</li><li><strong>开发者工具</strong>：除了常见的 Logger 和 Debugger 工具，Xiaomi Vela 还提供 Emulator 工具来帮助开发者提升调试效率，使用 Emulator，开发者可以利用 PC 端丰富的调试工具和调试信息，降低嵌入式系统开发和调试的难度。</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fiot.mi.com%2Fvela%2Fdetail.html" target="_blank">点此查看更多细节</a></u>。</p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/263025" target="_blank">雷军公布小米澎湃 OS 完整系统架构，称底层全部重构</a></li><li><a href="https://www.oschina.net/news/263645" target="_blank">小米澎湃 OS 正式发布，Xiaomi Vela 将开源</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 15 Nov 2023 02:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266688/xiaomi-vela-opensource</guid>
            <link>https://www.oschina.net/news/266688/xiaomi-vela-opensource</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Socket.D —— 基于语义消息流的网络协议]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">Socket.D&nbsp;是一个基于连接的、可扩展的、消息驱动的传输协议。具有异步，自动分片，背压流控，双向通讯，多路复用，断线重连，支持签权，基于主题消息等特性。</p><ul><li>具有语言无关性的二进制通信协议（支持 tcp, ws, udp）</li><li>异步非阻塞消息驱动通信</li><li>可以进行流量控制、自动连接恢复</li><li>支持双向通信（如：单链接双向 RPC 接口调用）</li><li>更加适合分布式通信场景</li><li>支持 ssl，支持国密 ssl</li><li>消息有由元信息和数据组成，通过元信息实现可扩展性</li><li>接口简单</li></ul><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">开发时，主要交互只有 2 接口对象（更多可见：<a href="https://gitee.com/noear/socketd/blob/main/API.md">API.md</a><span>&nbsp;</span>）：</p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#40485b; display:block; font-family:-apple-system,&quot;system-ui&quot;,&quot;Segoe UI&quot;,Helvetica,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Liberation Sans&quot;,&quot;PingFang SC&quot;,&quot;Microsoft YaHei&quot;,&quot;Hiragino Sans GB&quot;,&quot;Wenquanyi Micro Hei&quot;,&quot;WenQuanYi Zen Hei&quot;,&quot;ST Heiti&quot;,SimHei,SimSun,&quot;WenQuanYi Zen Hei Sharp&quot;,sans-serif; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:left; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:835px; word-break:initial; word-spacing:0px"><thead><tr><th>接口</th><th>描述</th><th>说明</th></tr></thead><tbody><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">listener</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">监听器</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">（可双向互听）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">session</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">会话</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">（可双向互发）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">session::send</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发送</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">session::sendAndRequest</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发送并请求</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">要求一次答复</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">session::sendAndSubscribe</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发送并订阅</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">答复结束之前，不限答复次数</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">session::reply</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">答复</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">session::replyEnd</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">答复结束</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr></tbody></table><h3 style="margin-left:0; margin-right:0; text-align:left">适用场景：</h3><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">可用于 MSG、RPC、IM、MQ，等一些的场景开发，可替代 http, websocket, grpc 等一些协议。比如移动设备与服务器的连接，比如一些微服务场景等等。</p></div>
                                                                ]]>
            </description>
            <pubDate>Wed, 15 Nov 2023 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/socketd</guid>
            <link>https://www.oschina.net/p/socketd</link>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 代码解释器存在巨大安全漏洞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 近日为 ChatGPT 推出了全新的代码解释器（Code Interpreter）工具，可以帮助程序员调试、完善代码编程工作。该工具可以利用 AI 来编写 Python 代码，所编写的代码甚至可以在沙盒中运行。</p><p>不过根据 Johann Rehberger 网络安全专家、Tom's Hardware 等多家国外媒体<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tomshardware.com%2Fnews%2Fchatgpt-code-interpreter-security-hole" target="_blank">报道</a></u>，由于该代码解释器工具可以处理任何电子表格文件，并能以图表的形式分析和呈现数据，<strong>黑客可以欺骗 ChatGPT 聊天机器人，让其执行来自第三方 URL 的指令</strong>。</p><p>Tom's Hardware 媒体复现了相关漏洞，创建虚假的环境变量文件，利用 ChatGPT 的功能处理此数据，然后将其发送到外部恶意站点。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1ca35470cf685c96d916ec4c8a97265c843.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-df3cfd0173073986a718e72cfaab32eb096.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-787cc41d51a67b812ef60dda6ed6532d570.png" referrerpolicy="no-referrer"></p><p>ChatGPT 可以响应 Linux 命令，可以访问相关信息和文件，黑客通过这种方式，可以在用户没有防备的情况下，访问相关的敏感数据。</p><p>目前需要订阅 ChatGPT Plus，才能访问该代码解释工具，但这个漏洞引发了网络安全专家的担忧。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 15 Nov 2023 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266683/chatgpt-code-interpreter-security-hole</guid>
            <link>https://www.oschina.net/news/266683/chatgpt-code-interpreter-security-hole</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 基于 Kotlin 的 AndroidX 仿微信图片选择器 MXImagePicker]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-imagepicker" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#imagepicker"></a>ImagePicker</h1><h2><a id="user-content-介绍" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E4%BB%8B%E7%BB%8D"></a>介绍</h2><h2><a id="user-content-基于 kotlinandroidx 的仿微信图片选择器" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E5%9F%BA%E4%BA%8Ekotlinandroidx%E7%9A%84%E4%BB%BF%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87%E9%80%89%E6%8B%A9%E5%99%A8"></a>基于 Kotlin，AndroidX 的仿微信图片选择器
<a href="https://gitee.com/link?target=https%3A%2F%2Fjitpack.io%2F%23com.gitee.zhangmengxiong%2FMXImagePicker"><img src="https://jitpack.io/v/com.gitee.zhangmengxiong/MXImagePicker.svg" alt="" referrerpolicy="no-referrer"></a></h2><p>Gradle 引用</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="n">implementation</span><span class="s1">'com.gitee.zhangmengxiong:MXImagePicker:1.6.3'</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><img src="https://gitee.com/zhangmengxiong/MXImagePicker/raw/master/imgs/screenshot1.png" alt="Image text" referrerpolicy="no-referrer"><img src="https://gitee.com/zhangmengxiong/MXImagePicker/raw/master/imgs/screenshot2.png" alt="Image text" referrerpolicy="no-referrer"><img src="https://gitee.com/zhangmengxiong/MXImagePicker/raw/master/imgs/screenshot3.png" alt="Image text" referrerpolicy="no-referrer"></p><h2><a id="user-content-使用方法" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"></a>使用方法</h2><h4><a id="user-content-第一步项目增加 androidx 库和 glide 图片加载库图片缩放库" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E7%AC%AC%E4%B8%80%E6%AD%A5%E9%A1%B9%E7%9B%AE%E5%A2%9E%E5%8A%A0androidx%E5%BA%93%E5%92%8Cglide%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E5%BA%93%E5%9B%BE%E7%89%87%E7%BC%A9%E6%94%BE%E5%BA%93"></a>第一步：项目增加 Androidx 库和 Glide 图片加载库、图片缩放库</h4><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="n">implementation</span><span class="s2">"androidx.appcompat:appcompat:x.x.x"</span></span><span id="LC2" class="line"><span class="n">implementation</span><span class="s2">"androidx.recyclerview:recyclerview:x.x.x"</span></span><span id="LC3" class="line"><span class="n">implementation</span><span class="s2">"com.github.bumptech.glide:glide:x.x.x"</span></span><span id="LC4" class="line"><span class="n">implementation</span><span class="s2">"androidx.constraintlayout:constraintlayout:2.0.4"</span></span><span id="LC5" class="line"><span class="n">implementation</span><span class="s2">"com.github.chrisbanes:PhotoView:2.3.0"</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-第二步使用前需要修改 androidmanifestxml 配置添加相册存储权限" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%BD%BF%E7%94%A8%E5%89%8D%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9androidmanifestxml%E9%85%8D%E7%BD%AE%E6%B7%BB%E5%8A%A0%E7%9B%B8%E5%86%8C%E5%AD%98%E5%82%A8%E6%9D%83%E9%99%90"></a>第二步：使用前需要修改‘AndroidManifest.xml’配置：添加相册、存储权限</h4><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 如果 Android 版本 &lt; 33 需要以下权限：</span></span><span id="LC2" class="line"><span class="nc">Manifest</span><span class="p">.</span><span class="n">permission</span><span class="p">.</span><span class="nc">CAMERA</span></span><span id="LC3" class="line"><span class="nc">Manifest</span><span class="p">.</span><span class="n">permission</span><span class="p">.</span><span class="nc">READ_EXTERNAL_STORAGE</span></span><span id="LC4" class="line"><span class="c1">// 如果 Android 版本 &gt;= 33 需要以下权限：</span></span><span id="LC5" class="line"><span class="nc">Manifest</span><span class="p">.</span><span class="n">permission</span><span class="p">.</span><span class="nc">CAMERA</span></span><span id="LC6" class="line"><span class="nc">Manifest</span><span class="p">.</span><span class="n">permission</span><span class="p">.</span><span class="nc">READ_MEDIA_IMAGES</span></span><span id="LC7" class="line"><span class="nc">Manifest</span><span class="p">.</span><span class="n">permission</span><span class="p">.</span><span class="nc">READ_MEDIA_VIDEO</span></span><span id="LC8" class="line"></span><span id="LC9" class="line"><span class="c1">// targetSdkVersion &gt;= 29 的应用需要在 application 节点添加以下属性</span></span><span id="LC10" class="line"><span class="n">android</span><span class="p">:</span><span class="n">requestLegacyExternalStorage</span><span class="p">=</span><span class="s">"true"</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>注意：<code>没有权限进入选择页面会报错！</code></p><h4><a id="user-content-第三步启动选择页面" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E7%AC%AC%E4%B8%89%E6%AD%A5%E5%90%AF%E5%8A%A8%E9%80%89%E6%8B%A9%E9%A1%B5%E9%9D%A2"></a>第三步：启动选择页面</h4><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">val</span><span class="py">intent</span><span class="p">=</span><span class="nc">MXPickerBuilder</span><span class="p">().</span><span class="nf">setMaxSize</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">createIntent</span><span class="p">(</span><span class="k">this</span><span class="p">)</span></span><span id="LC2" class="line"><span class="nf">startActivityForResult</span><span class="p">(</span><span class="n">intent</span><span class="p">,</span><span class="mh">0x22</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-预加载说明" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E9%A2%84%E5%8A%A0%E8%BD%BD%E8%AF%B4%E6%98%8E"></a>预加载说明</h5><p>预加载可以提前搜索本机图片/视频资源，减少首次进入选择页面时空白时间</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nc">MXImagePicker</span><span class="p">.</span><span class="nf">init</span><span class="p">(</span><span class="n">application</span><span class="p">)</span></span><span id="LC2" class="line"><span class="nc">MXScanBiz</span><span class="p">.</span><span class="nf">scanAll</span><span class="p">(</span><span class="k">this</span><span class="p">,</span><span class="n">lifecycleScope</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-mxpickerbuilder 参数说明" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#mxpickerbuilder%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E"></a>MXPickerBuilder 参数说明</h5><ol><li><code>setMaxSize(size: Int)</code> 设置最大选择文件个数</li><li><code>setType(type: PickerType)</code> 设置类型
<ul><li>PickerType.Image = 图片</li><li>PickerType.Video = 视频</li><li>PickerType.ImageAndVideo = 图片 + 视频，混合选择</li></ul></li><li><code>setCameraEnable(enable: Boolean)</code> 设置是否启动拍摄功能，默认=true</li><li><code>setMaxVideoLength(length: Int)</code> 当类型=Video 时，可以选择视频最大时长限制，单位：秒，默认=-1 无限制</li><li><code>setMaxListSize(size: Int)</code> 最长列表加载长度，防止图片过多时产生 OOM -1=不限制，默认限制长度=1000 条</li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 在图片选择器 Activity 创建时会回调这个方法，一般会通过这个来改变导航栏、状态栏的 Theme,demo 中搭配`ImmersionBar`来实现沉浸式效果</span></span><span id="LC2" class="line"><span class="nc">MXImagePicker</span><span class="p">.</span><span class="nf">registerActivityCallback</span><span class="p">{</span><span class="n">activity</span><span class="p">-&gt;</span></span><span id="LC3" class="line"><span class="nc">ImmersionBar</span><span class="p">.</span><span class="nf">with</span><span class="p">(</span><span class="n">activity</span><span class="p">)</span></span><span id="LC4" class="line"><span class="p">.</span><span class="nf">autoDarkModeEnable</span><span class="p">(</span><span class="k">true</span><span class="p">)</span></span><span id="LC5" class="line"><span class="p">.</span><span class="nf">statusBarColorInt</span><span class="p">(</span><span class="n">activity</span><span class="p">.</span><span class="n">resources</span><span class="p">.</span><span class="nf">getColor</span><span class="p">(</span><span class="nc">R</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">picker_color_background</span><span class="p">))</span></span><span id="LC6" class="line"><span class="p">.</span><span class="nf">fitsSystemWindows</span><span class="p">(</span><span class="k">true</span><span class="p">)</span></span><span id="LC7" class="line"><span class="p">.</span><span class="nf">navigationBarColor</span><span class="p">(</span><span class="nc">R</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">picker_color_background</span><span class="p">)</span></span><span id="LC8" class="line"><span class="p">.</span><span class="nf">init</span><span class="p">()</span></span><span id="LC9" class="line"><span class="p">}</span></span><span id="LC10" class="line"></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-页面颜色设置" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E9%A1%B5%E9%9D%A2%E9%A2%9C%E8%89%B2%E8%AE%BE%E7%BD%AE"></a>页面颜色设置</h5><p>将下面颜色值放如主项目的资源 xml 中，可以修改页面对应的颜色显示</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c">&lt;!--  页面背景色  --&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;color</span><span class="na">name=</span><span class="s">"mx_picker_color_background"</span><span class="nt">&gt;</span>#333333<span class="nt">&lt;/color&gt;</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c">&lt;!--  字体、icon 颜色  --&gt;</span></span><span id="LC5" class="line"><span class="nt">&lt;color</span><span class="na">name=</span><span class="s">"mx_picker_color_important"</span><span class="nt">&gt;</span>#F1F1F1<span class="nt">&lt;/color&gt;</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="c">&lt;!--  选中状态颜色  --&gt;</span></span><span id="LC8" class="line"><span class="nt">&lt;color</span><span class="na">name=</span><span class="s">"mx_picker_color_select"</span><span class="nt">&gt;</span>#03CE65<span class="nt">&lt;/color&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-多语言设置" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E5%A4%9A%E8%AF%AD%E8%A8%80%E8%AE%BE%E7%BD%AE"></a>多语言设置</h5><p>将下面字符串定义放入对应的语言目录中，可以修改页面对应的文字提示</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_select"</span><span class="nt">&gt;</span>选择<span class="nt">&lt;/string&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_all"</span><span class="nt">&gt;</span>全部<span class="nt">&lt;/string&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_image_limit_tip"</span><span class="nt">&gt;</span>您最多只能选择 %s 张图片！<span class="nt">&lt;/string&gt;</span></span><span id="LC4" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_video_limit_tip"</span><span class="nt">&gt;</span>您最多只能选择 %s 个视频！<span class="nt">&lt;/string&gt;</span></span><span id="LC5" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_video_limit_length_tip"</span><span class="nt">&gt;</span>只能选择 %s 秒以内的视频<span class="nt">&lt;/string&gt;</span></span><span id="LC6" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_need_permission_storage_camera"</span><span class="nt">&gt;</span>需要写入存储、相机权限<span class="nt">&lt;/string&gt;</span></span><span id="LC7" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_need_permission_storage"</span><span class="nt">&gt;</span>需要读取存储权限<span class="nt">&lt;/string&gt;</span></span><span id="LC8" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_open_failed"</span><span class="nt">&gt;</span>打开失败！<span class="nt">&lt;/string&gt;</span></span><span id="LC9" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_preview"</span><span class="nt">&gt;</span>预览<span class="nt">&lt;/string&gt;</span></span><span id="LC10" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_not_compress"</span><span class="nt">&gt;</span>原图<span class="nt">&lt;/string&gt;</span></span><span id="LC11" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_take_pic"</span><span class="nt">&gt;</span>拍摄图片<span class="nt">&lt;/string&gt;</span></span><span id="LC12" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_take_video"</span><span class="nt">&gt;</span>拍摄视频<span class="nt">&lt;/string&gt;</span></span><span id="LC13" class="line"><span class="nt">&lt;string</span><span class="na">name=</span><span class="s">"mx_picker_string_show_list"</span><span class="nt">&gt;</span>图片查看<span class="nt">&lt;/string&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>dimens.xml 资源</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c">&lt;!--  顶部导航栏高度  --&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;dimen</span><span class="na">name=</span><span class="s">"mx_picker_bar_height"</span><span class="nt">&gt;</span>50dp<span class="nt">&lt;/dimen&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-自定义图片加载器默认使用 glide" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E5%99%A8%E9%BB%98%E8%AE%A4%E4%BD%BF%E7%94%A8glide"></a>自定义图片加载器（默认使用 Glide）</h5><p>通过继承实现接口<code>IImageLoader</code> ,并注册到服务<code>MXImagePicker</code>即可</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 数据对象</span></span><span id="LC2" class="line"><span class="kd">data class</span><span class="nc">MXItem</span><span class="p">(</span><span class="kd">val</span><span class="py">path</span><span class="p">:</span><span class="nc">String</span><span class="p">,</span><span class="kd">val</span><span class="py">time</span><span class="p">:</span><span class="nc">Long</span><span class="p">,</span><span class="kd">val</span><span class="py">type</span><span class="p">:</span><span class="nc">MXPickerType</span><span class="p">,</span><span class="kd">val</span><span class="py">duration</span><span class="p">:</span><span class="nc">Int</span><span class="p">=</span><span class="mi">0</span><span class="p">)</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c1">// 全局注册加载器，可以卸载 Application 里面，不影响启动速度</span></span><span id="LC5" class="line"><span class="nc">MXImagePicker</span><span class="p">.</span><span class="nf">registerImageLoader</span><span class="p">{</span><span class="n">activity</span><span class="p">,</span><span class="n">item</span><span class="p">,</span><span class="n">imageView</span><span class="p">-&gt;</span></span><span id="LC6" class="line"><span class="k">if</span><span class="p">(</span><span class="nc">File</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="n">path</span><span class="p">).</span><span class="nf">exists</span><span class="p">())</span><span class="p">{</span></span><span id="LC7" class="line"><span class="nc">Glide</span><span class="p">.</span><span class="nf">with</span><span class="p">(</span><span class="n">activity</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="nc">File</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="n">path</span><span class="p">))</span></span><span id="LC8" class="line"><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="nc">R</span><span class="p">.</span><span class="n">drawable</span><span class="p">.</span><span class="n">mx_icon_picker_image_place_holder</span><span class="p">).</span><span class="nf">into</span><span class="p">(</span><span class="n">imageView</span><span class="p">)</span></span><span id="LC9" class="line"><span class="p">}</span><span class="k">else</span><span class="k">if</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">startsWith</span><span class="p">(</span><span class="s">"http"</span><span class="p">))</span><span class="p">{</span></span><span id="LC10" class="line"><span class="nc">Glide</span><span class="p">.</span><span class="nf">with</span><span class="p">(</span><span class="n">activity</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="n">path</span><span class="p">)</span></span><span id="LC11" class="line"><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="nc">R</span><span class="p">.</span><span class="n">drawable</span><span class="p">.</span><span class="n">mx_icon_picker_image_place_holder</span><span class="p">).</span><span class="nf">into</span><span class="p">(</span><span class="n">imageView</span><span class="p">)</span></span><span id="LC12" class="line"><span class="p">}</span><span class="k">else</span><span class="p">{</span></span><span id="LC13" class="line"><span class="nc">Glide</span><span class="p">.</span><span class="nf">with</span><span class="p">(</span><span class="n">activity</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="n">uri</span><span class="p">)</span></span><span id="LC14" class="line"><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="nc">R</span><span class="p">.</span><span class="n">drawable</span><span class="p">.</span><span class="n">mx_icon_picker_image_place_holder</span><span class="p">).</span><span class="nf">into</span><span class="p">(</span><span class="n">imageView</span><span class="p">)</span></span><span id="LC15" class="line"><span class="p">}</span></span><span id="LC16" class="line"><span class="p">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-第四步获取返回结果" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E7%AC%AC%E5%9B%9B%E6%AD%A5%E8%8E%B7%E5%8F%96%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C"></a>第四步：获取返回结果</h4><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">override</span><span class="k">fun</span><span class="nf">onActivityResult</span><span class="p">(</span><span class="n">requestCode</span><span class="p">:</span><span class="nc">Int</span><span class="p">,</span><span class="n">resultCode</span><span class="p">:</span><span class="nc">Int</span><span class="p">,</span><span class="n">data</span><span class="p">:</span><span class="nc">Intent</span><span class="p">?)</span><span class="p">{</span></span><span id="LC2" class="line"><span class="k">super</span><span class="p">.</span><span class="nf">onActivityResult</span><span class="p">(</span><span class="n">requestCode</span><span class="p">,</span><span class="n">resultCode</span><span class="p">,</span><span class="n">data</span><span class="p">)</span></span><span id="LC3" class="line"><span class="k">if</span><span class="p">(</span><span class="n">resultCode</span><span class="p">==</span><span class="nc">RESULT_OK</span><span class="p">&amp;&amp;</span><span class="n">requestCode</span><span class="p">==</span><span class="mh">0x22</span><span class="p">)</span><span class="p">{</span></span><span id="LC4" class="line"><span class="kd">val</span><span class="py">paths</span><span class="p">=</span><span class="nc">MXPickerBuilder</span><span class="p">.</span><span class="nf">getPickerResult</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">?:</span><span class="k">return</span><span class="c1">//返回 List&lt;String&gt;类型数据</span></span><span id="LC5" class="line"><span class="nf">println</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span></span><span id="LC6" class="line"><span class="p">}</span></span><span id="LC7" class="line"><span class="p">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-调取摄像头单独拍摄照片" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E8%B0%83%E5%8F%96%E6%91%84%E5%83%8F%E5%A4%B4%E5%8D%95%E7%8B%AC%E6%8B%8D%E6%91%84%E7%85%A7%E7%89%87"></a>调取摄像头单独拍摄照片</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">val</span><span class="py">builder</span><span class="p">=</span><span class="nc">MXCaptureBuilder</span><span class="p">().</span><span class="nf">setType</span><span class="p">(</span><span class="nc">MXPickerType</span><span class="p">.</span><span class="nc">Image</span><span class="p">)</span></span><span id="LC2" class="line"></span><span id="LC3" class="line"><span class="nf">startActivityForResult</span><span class="p">(</span><span class="n">builder</span><span class="p">.</span><span class="nf">createIntent</span><span class="p">(</span><span class="k">this</span><span class="p">),</span><span class="mh">0x11</span><span class="p">)</span></span><span id="LC4" class="line"></span><span id="LC5" class="line"><span class="c1">// 在 onActivityResult 获取结果</span></span><span id="LC6" class="line"><span class="kd">val</span><span class="py">file</span><span class="p">=</span><span class="n">builder</span><span class="p">.</span><span class="nf">getCaptureFile</span><span class="p">()</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-调取摄像头单独拍摄视频" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E8%B0%83%E5%8F%96%E6%91%84%E5%83%8F%E5%A4%B4%E5%8D%95%E7%8B%AC%E6%8B%8D%E6%91%84%E8%A7%86%E9%A2%91"></a>调取摄像头单独拍摄视频</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">val</span><span class="py">builder</span><span class="p">=</span><span class="nc">MXCaptureBuilder</span><span class="p">().</span><span class="nf">setType</span><span class="p">(</span><span class="nc">MXPickerType</span><span class="p">.</span><span class="nc">Video</span><span class="p">).</span><span class="nf">setMaxVideoLength</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span></span><span id="LC2" class="line"><span class="nf">startActivityForResult</span><span class="p">(</span><span class="n">builder</span><span class="p">.</span><span class="nf">createIntent</span><span class="p">(</span><span class="k">this</span><span class="p">),</span><span class="mh">0x11</span><span class="p">)</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c1">// 在 onActivityResult 获取结果</span></span><span id="LC5" class="line"><span class="kd">val</span><span class="py">file</span><span class="p">=</span><span class="n">builder</span><span class="p">.</span><span class="nf">getCaptureFile</span><span class="p">()</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-图片查看器" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E5%9B%BE%E7%89%87%E6%9F%A5%E7%9C%8B%E5%99%A8"></a>图片查看器</h3><p><img src="https://gitee.com/zhangmengxiong/MXImagePicker/raw/master/imgs/screenshot3.png" alt="Image text" referrerpolicy="no-referrer"></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nc">MXImgShowActivity</span><span class="p">.</span><span class="k">open</span><span class="p">(</span></span><span id="LC2" class="line"><span class="k">this</span><span class="p">,</span><span class="nf">arrayListOf</span><span class="p">(</span></span><span id="LC3" class="line"><span class="s">"http://videos.jzvd.org/v/饺子主动.jpg"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="s">"http://videos.jzvd.org/v/饺子运动.jpg"</span></span><span id="LC5" class="line"><span class="p">),</span><span class="s">"图片详情"</span></span><span id="LC6" class="line"><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-单张图片压缩" class="anchor" href="https://gitee.com/zhangmengxiong/MXImagePicker#%E5%8D%95%E5%BC%A0%E5%9B%BE%E7%89%87%E5%8E%8B%E7%BC%A9"></a>单张图片压缩</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">val</span><span class="py">file</span><span class="p">=</span><span class="nc">File</span><span class="p">(</span><span class="s">".../xx.png"</span><span class="p">)</span></span><span id="LC2" class="line"><span class="kd">val</span><span class="py">scaleImg</span><span class="p">=</span><span class="nc">MXImageCompress</span><span class="p">.</span><span class="nf">from</span><span class="p">(</span><span class="n">context</span><span class="p">)</span></span><span id="LC3" class="line"><span class="p">.</span><span class="nf">setCacheDir</span><span class="p">(</span><span class="n">applicationContext</span><span class="p">.</span><span class="n">cacheDir</span><span class="p">)</span><span class="c1">// 缓存目录</span></span><span id="LC4" class="line"><span class="p">.</span><span class="nf">setSupportAlpha</span><span class="p">(</span><span class="k">true</span><span class="p">)</span><span class="c1">// 支持透明通道 (’.png‘格式) 默认=’.jpg‘格式</span></span><span id="LC5" class="line"><span class="p">.</span><span class="nf">setTargetFileSize</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span><span class="c1">// 设置压缩文件大小目标值，单位：Kb 默认=0 自然压缩</span></span><span id="LC6" class="line"><span class="p">.</span><span class="nf">setTargetPixel</span><span class="p">(</span><span class="mi">2400</span><span class="p">)</span><span class="c1">// 设置压缩文件宽或高目标值，单位：像素</span></span><span id="LC7" class="line"><span class="p">.</span><span class="nf">compress</span><span class="p">(</span><span class="n">file</span><span class="p">)</span></span><span id="LC8" class="line"></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Wed, 15 Nov 2023 02:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/zhangmengxiong/MXImagePicker</guid>
            <link>https://gitee.com/zhangmengxiong/MXImagePicker</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 百度搜索智能化算力调控分配方法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-24c7ae180da549d2d3ab12f4b6a9d4899ff.png" alt="" referrerpolicy="no-referrer"></p><p>作者 | 泰来</p><blockquote><p>导读</p><p>随着近年深度学习技术的发展，搜索算法复杂度不断上升，算力供给需求出现了爆发式的增长。伴随着 AI 技术逐步走到深水区，算法红利在逐步消失，边际效应日益显著，算力效能的提升尤为重要，同时随着宏观经济影响，大规模的算力需求供给也遭遇到了瓶颈。同时随着流量、时间或系统故障时带来的容量变化，总算力约束也在时刻改变，周期性的出现波峰、波谷，以及会因为流量突增、网络抖动等原因导致系统出现稳定性问题。</p><p>在此背景下，需要一种更加智能化、个性化的算力调控分配方法，不断提高系统的自适应性，使得在给定资源上限的情况下，最大化资源投入的性价，同时在故障时刻发生时自适应的调整算力分配，降低系统负载。</p></blockquote><blockquote><p><em>全文 4328 字，预计阅读时间 11 分钟。</em></p></blockquote><h1><strong>01 问题与挑战</strong></h1><p>互联网行业十余年的蓬勃发展及硬件性能的持续攀升，使得 Ranking 相关算法进入到了深度学习时代，模型、技术创新层出不穷。但随着技术逐步进入到深水区，在同样的算力需求下对效果的增长边际已经非常明显。</p><p>同时伴随当前宏观经济影响，大规模算力的需求供给也持续遭遇瓶颈，如何在有限的算力资源内不断创造出更大的效果价值是一项非常有挑战性的工作。</p><p><img src="https://oscimg.oschina.net/oscnet/up-630522985830d91e7f1357f55777b530f87.png" alt="图片" referrerpolicy="no-referrer"></p><p>为此我们不断探索根据流量价值及系统状态自适应的进行算力分配，使得总体投入产出比不断提升。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a64376c135fecc2ffcb80b1ecc848497a0b.png" alt="图片" referrerpolicy="no-referrer"></p><h1><strong>02 整体思路</strong></h1><p>目前搜索系统流转过程中调控手段彼此相互之间是独立的，调控的算子的输入输出没有全局视角，调控算子彼此割裂、联动和管理是比较困难的，且调控手段大多基于静态阈值配置。但我们认为系统中请求经过每层的调控算子是有状态的，理想的级联系统中每种调控算子应该是全局可见的，需要从全局的视角更好的审视业务系统，站在更高的维度去看算力调控分配这项工作。</p><p>我们在微观和宏观两方案开展了相关调控工作：</p><p><strong>1.微观</strong>：忽略系统容量状态，在当前时刻下根据流量产生的价值来动态的分配算力，使得在给定算力总约束下获得全局最优。</p><p><img src="https://oscimg.oschina.net/oscnet/up-98985f8b2a15f8558c83df58a4ebe18715d.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong>2.宏观</strong>：随着流量、时间或系统故障时带来的容量变化，总算力约束在不断改变，需要在给定的资源及响应时间限制下，计算出在当前限制条件下的最优分配方式。动态的调整系统核心阶段的计算强度，合理调控峰值算力。并基于搜索系统的实时状态反馈，自动的调节系统的安全状态。使搜索系统能够在速度、资源、效果、稳定性等多个维度上进行自适应的调控。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1e6e541b843bafcd142fbd5bd3d69ef3dba.png" alt="图片" referrerpolicy="no-referrer"></p><h2><strong>2.1 问题建模</strong></h2><p><strong>变量说明：</strong></p><p>第 i 条流量\(r_i\)。</p><p>流量 i 在阶段 j 的具体信息，例如队列长度，模型选型等，可以用表示，其中的 alpha beta gamma 都可以根据经验进行设定并用实验来验证。</p><p>\(Q_(i,j) = [α*queue_length, β*cpu_usage, γ*gpu_uasage]\)</p><p>流量在第 j 阶段的折扣因子\(Y_i\)。</p><p>第 i 条流量的价值\(O_i=Y(r_i,Q_(i,1),Q_(i,2),…,Q_(i,N) )\)</p><p><img src="https://oscimg.oschina.net/oscnet/up-7c9ce2b9226f138fc1dd8bbc65e9ea1234b.png" alt="图片" referrerpolicy="no-referrer"></p><p>目标：通过调控流量在各个阶段的信息例如队列长度、模型选型等，从而调节折扣因子，最终实现流量价值最大化，假设 M 条流量经过 N 个阶段表达如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-de28539ee4bac5fbd6df6f7e3f1317cb2fd.png" alt="图片" referrerpolicy="no-referrer"></p><p>C1 成本约束，对于任意一个阶段，都必须小于等于其成本；</p><p>C2 时间约束，对于任意一个请求流量，在 N 个阶段的耗时综合都必须小于等于规定的耗时；</p><p>C3 辅助约束，对于任意一个请求任意一个阶段都必须有大于等于 0 的值。</p><p>对于一个实时的搜索系统来说，在线进行上述的优化并不太实际也会带来比较多的困难。为了简化分析和提高系统的鲁棒性，我们将上述 N 个阶段拆封成 N 个子问题，这样方便对各个阶段进行监控和可靠的干预，提高系统的鲁棒性，例如当系统出现巨大的变化时，可以随时动态调整各个阶段的参数。简化问题求解，将 C1、C2 约束进行一定的拆分。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f6430b5dc5daf55c8c881024c8212a8e1b4.png" alt="图片" referrerpolicy="no-referrer"></p><p>具体来说，对于阶段 j，流量的价值最大化，我们可以看作是上述的一个子问题。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6946e0b198d88545b3f7e182609a5ae6124.png" alt="图片" referrerpolicy="no-referrer"></p><p>假设\(Y_j （r_i,Q_(i,j)）\) 是单调递增的，但其对\(Q_(i,j)\) 的导数是单调递减的，也就是其价值会随着配置资源的增加而越来越缓慢的增加。</p><h2><strong>2.2 示例说明</strong></h2><p><strong>示例：用相关性精排阶段的弹性候选集进行举例</strong></p><p>假设将流量 i 细化成第 i 条 Query，j 阶段则为具体筛选阶段，增加一个维度 k 表示 URL 级别的参数和特征信息。在正排候选集筛选阶段 k 信息表示为多个特征的分数信息，authority_feature【权威性特征】、click_feature【点击特征】...correlation_feature【相关性特征】。</p><p>则在正排候选集筛选阶段请求 i 的第 k 条 url 的信息可以表示为：</p><p><img src="https://oscimg.oschina.net/oscnet/up-0d31f093be129945380d88fc27f864dce80.png" alt="图片" referrerpolicy="no-referrer"></p><p>流量 i 在弹性候选集下的折扣因子，可以看作是 1 - 删掉 URL 数量在原本可出现在最终排序的 Top40 的概率，假如候选集合中完全没有删除的 URL 则无折扣损失，若是候选集合中删除了 URL，但对最终 Top40 的召回无影响，也可以看作是对总价值无折扣影响。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c740c592761c36f2c38a784c92ba5018ff8.png" alt="图片" referrerpolicy="no-referrer"></p><p>具体来说，针对第 i 条 query 的 k 条 url 的具体信息，我们采用多个维度的特征进行考量。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1d1ec5ab10bfc446a85c856a1d408835f4c.png" alt="图片" referrerpolicy="no-referrer"></p><p>其中</p><p><img src="https://oscimg.oschina.net/oscnet/up-c45ba9cae44e13b3fb3f8f399a3e20c6626.png" alt="图片" referrerpolicy="no-referrer"></p><p>如果是 0 表示丢弃，1 表示留下第 k 条 url，希腊字母表示的是采取的阈值标准，例如评分位于后 x%。如果一个 url 的所有特征贡献度排名都处于分布的末尾，则会将该 url 从候选集中剔除。</p><p><img src="https://oscimg.oschina.net/oscnet/up-50089654880969967f46124956cfddd37f6.png" alt="图片" referrerpolicy="no-referrer"></p><h1><strong>03 关键技术</strong></h1><p>过去传统的调控方式下，既不知道上游阶段做过哪些调控动作，也不知道在自己的阶段上做的调控动作，下游是如何反馈的，只能追求自己的局部最优。而我们认为在搜索这种分层的级联系统下，越往下流转看到的特征和信号越多，调控动作应该随着流转过程发生状态转变，不应该是静态的。我们创新的采用弹性级联调控框架将调控手段进行组合，追求全局的最优解，从全链路上提升算力投入产出的性价比。</p><p><img src="https://oscimg.oschina.net/oscnet/up-58fe63995a5a07653dc25586db731a312e6.png" alt="图片" referrerpolicy="no-referrer"></p><p>具体做法，我们构建的弹性级联框架包含四个部分：</p><p><strong>1、调控算子集合</strong>，将调控动作按照 Query 级别、URL 级别、Feature 级别进行划分，调控算子拥有相同基类，接口规范统一；</p><p><strong>2、计算中心</strong>，负责实时计算各种调控动作所需的各类信号、以及流量价值的判断、容量信号的获取等；</p><p><strong>3、参数集合</strong>，经过计算中心产出的特征和信号，固化超参数，使得模块内超参数全局可见，跨模块之间按照规定协议统一进行交互；</p><p><strong>4、调控决策器</strong>，主要负责根据参数集合，确定各个阶段的调控档位设置并调用算子集合里的算子进行执行，每个调控阶段包含控制流（Control Level）和反馈流（FeedbackLevel），控制流能结合当前阶段看到的特征和信号给出它下游其他阶段的调控档位，反馈流是当前阶段参考其他阶段给出的调控档位建议和当前阶段看到的特征和信号确定实际执行的调控档位。通过这种方式，每个调控阶段既能看到到其他阶段实际执行的调控状态，同时也能根据它们对当前阶段的指导建议进行综合判断，最终在全链路上获取全局最优解。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3d45fec8e8b0e24a58b2e608cce248a3628.png" alt="图片" referrerpolicy="no-referrer"></p><p>如上图左侧可以看到整个弹性级联框架的组成部分，右侧是举例正排阶段的弹性候选集的实际计算过程，将各种维度的特征通过计算中心生成价值参数，用于调控决策器进行决策，然后给出实际的正排计算集合。我们不仅建立控制反馈流级联自适应调控系统，而且还提供了一个全局视角的弹性算力分配控制中心。弹性算力系统主要通过对集群各种维度指标的获取、策略分析及周期性执行最适合当前机器负载状态的策略组合参数来实现其核心弹性算力分配决策。</p><p>根据当前搜索系统，当前智能弹性调参把系统定义和描述为下面 4 种状态：系统异常状态，负载峰值状态，弹性过渡状态，负载低谷状态，根据不同的系统状态，执行当前状态的策略集合，从而使资源使用率及业务收益效果最优。具体方案见下图：</p><p><img src="https://oscimg.oschina.net/oscnet/up-34531ef341d0092f4c8826b061a4c72cb68.png" alt="图片" referrerpolicy="no-referrer"></p><p>主要包含流程如下：</p><p><strong>信息采集</strong>：自动化的周期性采集业务日志（流量 pv，流量分类，流量质量）和机器状态（CPU/MEM 使用率）等信息。对于这些信息进行深入挖掘分析，主要从以下几个时间维度进行采集：</p><p>1、峰值时间段模块状态信号；</p><p>2、前 n 个采集周期模块状态信号；</p><p>3、前一天同时刻前 n 个采集周期模块状态信号；</p><p>4、前一周同时刻前 n 个采集周期模块状态信号。</p><p>系统状态预估:&nbsp;对各种维度信息采集，之后通过人工规则，在线策略，离线预估等手段评估系统当前状态，把目前系统划分为系统异常状态，系统负载峰值状态，系统负载低谷状态，系统负载过渡状态。下面是系统状态定义规则，及状态转移图：</p><p><strong>系统异常状态</strong>：系统发生故障，例如系统可用性 SLA，CPU 负载率，结果空值率等不符合预期。</p><p><strong>系统负载峰值状态</strong>：系统请求数，CPU 负载率等系统容量指标大于指定阈值。</p><p><strong>系统负载低谷状态</strong>：系统请求数，CPU 负载率等系统容量指标小于指定阈值。</p><p><strong>系统负载过渡状态</strong>：负载峰值和低谷之间的过渡状态。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8a94ecc0c3d4bfc093470cc02d2f1a4dff4.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong>档位判断</strong>：根据系统状态抽象成便于系统决策的系统档位，及每个档位内需要关注的系统问题。</p><p><strong>1、异常档位</strong>：如何快速服务降级，保证保证系统质量。</p><p><strong>2、峰值档位</strong>：需要关注系统的稳定性和响应时间，以确保系统在高负载下依然能够稳定运行。</p><p><strong>3、低谷档位</strong>：可以考虑优化系统资源的分配，提升资源的投入产出比。在探测到系统出现异常故障状态时。</p><p><strong>4、过渡档位</strong>：一种中间状态，它的主要作用是在系统从低负载状态过渡到高负载状态，或从高负载状态过渡到低负载状态时，提供一个缓冲阶段，以避免系统状态的突然跳变。过渡档位不进行策略的调整，而是保持系统在一个相对稳定的状态。这样做的目的是为了避免频繁的策略调整带来的系统震动，保证系统的稳定性。</p><p><strong>方案决策执行：</strong></p><p>降级档位主要应对系统异常或重大风险，其对应的策略包括关闭被动触发流量，以及降低召回集合，降低复杂模型计算等策，通过这种方式降低系统的负载，保证核心业务的正常运行。低谷档位对应的是弹性策略集，这些策略主要目的是在低谷期加强复杂策略的计算，提升搜索效果。而在峰值档位，我们主要采用削峰策略，包括减少被动触发流量，以确保系统在高负载下依然能够稳定运行。</p><p><strong>示例：视频搜索弹性扩触发：</strong></p><p>在系统资源容量低谷阶段，根据指标采集数据计算当前系统容量资源冗余情况，基于冗余资源进行扩触发比例计算，通过弹性算力决策模块下发触发信号，利用闲时资源扩大流量的触发面。</p><h1><strong>04 总结与展望</strong></h1><p>通过基于弹性级联框架的调控方式，提升了分层系统的效益比，对于每个用户请求实施精细化、差异化的调控组合，在算力效能提升上取得了不错的成绩。</p><p>算力分配是架构研究的核心问题之一，未来会在以下两个方面持续开展系统性工作：</p><p>1、结合 AI 大模型的推理能力在调控组合上可以做到更加精细化，在算力效能的提升上会带来更大的挖掘空间；</p><p>2、通过自适应的宏观调控给系统稳定性带来了柔性降级能力，后续会在这个方向上持续深耕，不断提升系统自动化的处置能力。</p><p>——END——</p><p><strong>推荐阅读</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247573568%26idx%3D1%26sn%3D393c3af07b86b342aba082cb42ae6594%26chksm%3Dc03f903cf748192a906d259791b7a49b4a34742a656379482051df9c8c0411af15290af1b2b6%26scene%3D21%23wechat_redirect" target="_blank">UBC SDK 日志级别重复率优化实践</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247573374%26idx%3D1%26sn%3D9d9d6dd9fa1476416facc30344724b0f%26chksm%3Dc03fef02f7486614370c5f861cf8139e7f37c35e856eda45b4cf1c7269ae82fbe315e1750254%26scene%3D21%23wechat_redirect" target="_blank">百度搜索深度学习模型业务及优化实践</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247573218%26idx%3D1%26sn%3De5082b7c4b4c14ed9365c18ac74bc8b2%26chksm%3Dc03fee9ef7486788a9ddac5e35cd9c4e1c7bd001b533ca57b9835af04560f09a0ae95ef058c7%26scene%3D21%23wechat_redirect" target="_blank">文生图大型实践：揭秘百度搜索 AIGC 绘画工具的背后故事！</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247572968%26idx%3D1%26sn%3D6895f4d29410e3a2fc2a9884df0a078a%26chksm%3Dc03fed94f7486482f93bbdbce036341e82f50a4822eb3d91ffbd76ca018d47fe35a9f77bdd99%26scene%3D21%23wechat_redirect" target="_blank">大模型在代码缺陷检测领域的应用实践</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247572835%26idx%3D1%26sn%3D7d08b04901206d41bf39c8b07087b391%26chksm%3Dc03fed1ff74864095e11f2f4eb75b15c4abbef06649c719201f782f1f3a653cd22e9fd7f5dac%26scene%3D21%23wechat_redirect" target="_blank">通过 Python 脚本支持 OC 代码重构实践（二）：数据项提供模块接入数据通路的代码生成</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 15 Nov 2023 02:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/10143329</guid>
            <link>https://my.oschina.net/u/4939618/blog/10143329</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[向开源作者提问「项目还活着吗」非常粗鲁且无礼]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近几个月，开源 AI 项目的创始人 Max Woolf 经历了一场关于自己的工作的 「存在危机」。</p><p>他表示自己对 AI 的负面抵制情绪日益强烈，以及 AI 行业进展神速，Max 发现自己无法跟上进度，陷入了对开源工作的质疑。在此期间，他暂停了 GitHub 上自己开源项目的开发，其中包括 ChatGPT 的 Python 接口 simpleaichat。</p><p><img src="https://static.oschina.net/uploads/space/2023/1115/190841_hkBi_2720166.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fminimaxir%2Fsimpleaichat" target="_blank">https://github.com/minimaxir/simpleaichat</a></u></em></p><p>简单来说，Max 压力太大，需要休息一段时间。按理来说，他的代码不应该有问题，因为项目本身设计就考虑到了他可能暂停开发的情况。</p><p>然而当 Max 想重操旧业时，却在自己项目的 GitHub 上收到了质疑开发是否已经停止的问题。尽管没有任何证据表明代码出问题，但项目 Stars 数高达 3k 的 simpleaichat 还是收到了 「这个项目被放弃了吗」 的问题。</p><p><img height="302" src="https://static.oschina.net/uploads/space/2023/1115/190713_TFZG_2720166.png" width="1454" referrerpolicy="no-referrer"></p><p>这让 Max 感到既震惊又气愤。他认为，这种质疑开发者的行为是在施加不必要的压力，也显得无礼。</p><p>事实上，开源项目从来没有 「必须持续开发」 的硬性规定。大多数开源许可协议都明确写明软件 「按原样」 提供，不承诺后续维护。但部分社区成员似乎默认开源项目有更新的义务，这让 Max 和其他开源开发者感到困扰。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f8029289e5c8978243bb08f62b2b0a4dcf.png" referrerpolicy="no-referrer"></p><p>他认为，开源的最大优势是可以随时分叉。如果有开发者认为某项目 「死了」, 大可以复制代码自行维护。但是有些人却以 「分叉」 来威胁原作者，这让原作者不堪重负。</p><p>AI 行业进展迅速，也加重了这一问题。受 ChatGPT 热潮影响，部分 AI 新创通过风险投资大规模运营，让人产生开源 AI 必须 「快速迭代」 的误解。</p><p>Max 表示，这种对开源项目 「活跃度」 的不合理期待，已经成为阻止他继续开源工作的主要障碍。他正在考虑通过创业来全职维护自己的项目，但前景未卜。</p><p>他认为，质疑开源项目是否 「死了」 的问题本身，不可能让开发者产生继续工作的动力。开源社区如果不能保持友善，只会让更多优秀项目消失。</p><p>原文：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fminimaxir.com%2F2023%2F11%2Fopen-source-dead-github%2F" target="_blank">https://minimaxir.com/2023/11/open-source-dead-github/</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 10:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266608/open-source-dead-github</guid>
            <link>https://www.oschina.net/news/266608/open-source-dead-github</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[零一万物对 Yi-34B 训练过程的说明]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>事件背景：</p><ul><li><a href="https://www.oschina.net/news/266377">李开复旗下 AI 公司「零一万物」开源的 Yi 大模型照搬 Llama 架构</a></li><li><a href="https://www.oschina.net/news/266525">「零一万物」 回应 Yi 开源大模型「套壳」 Llama</a></li></ul><hr><p>零一万物今天正式发文回应 Yi 开源大模型引起的争议：</p><blockquote><p>就零一万物的观察和分析，大模型社区在技术架构方面现在是一个处于接近往通用化逐步收拢的阶段，基本上国际主流大模型都是基于<strong>Transformer</strong>的架构，做 attention，activation，normalization，positional embedding 等部分的改动，LLaMA、Chinchilla、Gopher 等模型的架构和 GPT 架构大同小异，全球开源社区基于主流架构的模型变化非常之多，生态呈现欣欣向荣，国内已发布的开源模型也绝大多数采用渐成行业标准的 GPT/LLaMA 的架构。然而，大模型持续发展与寻求突破口的<strong>核心点不仅在于架构，而是在于训练得到的参数</strong>。</p><p>模型训练过程好比做一道菜，架构只是决定了做菜的原材料和大致步骤，这在大多数人的认知中也逐步形成共识。<strong>要训练出好的模型，还需要更好的「原材料」（数据）和对每一个步骤细节的把控（训练方法和具体参数）</strong>。由于大模型技术发展还在非常初期，从技术观点来说，行业共识是与主流模型保持一致的模型结构，更有利于整体的适配与未来的迭代。</p><p>零一万物在训练模型过程中，沿用了 GPT/LLaMA 的基本架构，由于 LLaMA 社区的开源贡献，让零一万物可以快速起步。零一万物<strong>从零开始训练</strong>了 Yi-34B 和 Yi-6B 模型，并根据实际的训练框架重新实现了训练代码，用自建的数据管线构建了高质量配比的训练数据集（从 3PB 原始数据精选到 3T token 高质量数据）。除此以外，在 Infra 部分进行算法、硬件、软件联合端到端优化，实现训练效率倍级提升和极强的容错能力等原创性突破。<strong>这些科学训模的系统性工作，往往比起基本模型结构能起到巨大的作用跟价值。</strong></p><p>零一万物团队在训练前的实验中，尝试了不同的数据配比科学地选取了最优的数据配比方案，投注大部分精力调整训练方法、数据配比、数据工程、细节参数、baby sitting（训练过程监测）技巧等。这一系列超越模型架构之外，研究与工程并进且具有前沿突破性的研发任务，才是真正属于模型训练内核<strong>最为关键、能够形成大模型技术护城河 know-how 积累</strong>。在模型训练同时，零一万物也针对模型结构中的若干关键节点进行了大量的实验和对比验证。举例来说，我们实验了 Group Query Attention（GQA）、Multi-Head Attention（MHA）、Vanilla Attention 并选择了 GQA，实验了 Pre-Norm 和 Post-Norm 在不同网络宽度和深度上的变化，并选择了 Pre-Norm，使用了 RoPE ABF 作为 positional embedding 等。也正是在这些实验与探索过程中，为了执行对比实验的需要，模型对部分推理参数进行了重新命名。</p><p>在零一万物初次开源过程中，我们发现用和开源社区普遍使用的 LLaMA 架构会对开发者更为友好，对于沿用 LLaMA 部分推理代码经实验更名后的疏忽，原始出发点是为了充分测试模型，并非刻意隐瞒来源。<strong>零一万物对此提出说明，并表达诚挚的歉意</strong>，我们正在各开源平台重新提交模型及代码并补充 LLaMA 协议副本的流程中，承诺尽速完成各开源社区的版本更新。</p><p>我们非常感谢社区的反馈，零一万物在开源社区刚刚起步，希望和大家携手共创社区繁荣，在近期发布 Chat Model 之后，我们将择期发布技术报告，Yi Open-source 会尽最大努力虚心学习，持续进步。</p><p><em>开源社区讨论参考：</em><br><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B%2Fdiscussions%2F11%236553145873a5a6f938658491" target="_blank">https://huggingface.co/01-ai/Yi-34B/discussions/11#6553145873a5a6f938658491</a></p></blockquote><p>创新工场 CMO 在转发上文的朋友圈中表示：「沿用行业演进渐成通用、生态拥抱的基础架构就成了「套模、山寨」？（就像手机 app 开发者都得益于 iOS、Android 的共通架构）。零一万物会持续从社区中虚心学习，持续进步。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-76f874328ebdab1a891bfc44ea094f539e4.png" referrerpolicy="no-referrer"></p><p>原文：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FaDclX74mPPtjQvco3GYmZQ" target="_blank">https://mp.weixin.qq.com/s/aDclX74mPPtjQvco3GYmZQ</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 09:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266597</guid>
            <link>https://www.oschina.net/news/266597</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeFuse 开源 ModelCache 大模型语义缓存]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:0; margin-right:0"><img alt="" src="https://img.alicdn.com/imgextra/i2/O1CN01Moy0hq1P2Cgi8LERe_!!6000000001782-2-tps-900-383.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>CodeFuse 开源火热进行中！本次开源的是 ModelCache 大模型语义缓存，可大幅降低大模型应用的推理成本，提升用户体验。</span></p><p style="margin-left:0; margin-right:0"><span>CodeFuse-ModelCache 项目地址：</span></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-ModelCache" target="_blank" rel="nofollow"><span>https://github.com/codefuse-ai/CodeFuse-ModelCache</span></a></p><span id="OSC_h2_1"></span><h2><strong><span style="color:#000000">0 背景</span></strong></h2><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#333333">在 LLM 技术浪潮席卷全球的背景下，大型模型快速增长的参数规模，对部署所需的推理资源带来了极大的挑战。为了提高大型模型的推理性能和效率，我们尝试从缓存角度解决当前大模型规模化服务部署的困境。类似传统应用，大模型的用户访问同样具有时间和空间的局部性（例如：热门话题相关内容，热门 GitHub repo）。如果有了缓存层，在遇到相似请求时，就无需调用大模型服务，直接从缓存的数据中返回已有的结果给用户，会大幅降低推理成本，提升用户体验。</span></p><span id="OSC_h2_2"></span><h2><span style="color:#333333">1 大模型缓存的意义</span></h2><p style="margin-left:0; margin-right:0"><span style="color:#333333">当前大模型服务面临一下三个挑战：</span></p><ol><li><span style="color:#333333">成本高：大模型参数量千亿级别，单实例就需要多张 A10 卡，规模化部署成本高昂。因此，当前大模型服务基本按照处理的 token 数量计费，导致用户侧使用成本也居高不下。</span></li><li><span style="color:#333333">速度慢：大型模型的推理速度也是一个关键问题。在许多实时应用中，如对话系统、业务助手，响应时间要求非常高，通常在毫秒级别。然而，大型模型的推理速度往往较慢，在秒级，导致无法实时返回结果，用户体验下降。</span></li><li><span style="color:#333333">稳定性无保障：由於单实例部署成本高昂，当前大模型服务接受到大流量请求时，通过限流的方式，防止服务不可用。</span></li></ol><span id="OSC_h2_3"></span><h2><span>2 方案调研</span></h2><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#333333">我们对开源方案 GPTCache 进行了调研，其是致力于构建用于存储 LLM 响应的语义缓存的项目，该项目提供了语义相似度匹配框架，并提供了相对完善的功能模块和接口。具有以下优点：<span>&nbsp;</span></span></p><ul><li><span style="color:#333333">项目的活跃性，它不断引入新功能，使得我们能够紧跟最新的发展动态。<span>&nbsp;</span></span></li><li><span style="color:#333333">具备开放的功能模块，可以进行调整和优化，这为业务的扩展提供了便利。</span></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#333333">GPTCache 的整体架构如图 1 所示：</span></p><p style="margin-left:0; margin-right:0; text-align:left"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/275821/1699497539548-420014c2-90f5-45dc-929f-15a2e3d32ebf.png" width="642" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center"><span style="color:#333333">图 1. GPTCache 架构</span></p><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#333333">但是，GPTCache 在落地应用上仍存在诸多不足，包括：</span></p><ol><li><span style="color:#333333">架构上将大模型调用和数据回写对用户进行了黑盒处理，使得大模型产品在流式输出、安全审核、问题排查等方面变的复杂。</span></li><li><span style="color:#333333">默认采用 faiss 和 sqlite 作为存储，不能进行分布式部署，尤其是在关系型数据库方面，SqlAlchemy 框架无法支持蚂蚁的 OceanBase。</span></li><li><span style="color:#333333">数据和资源隔离上，无法处理多模型多版本场景。</span></li><li><span style="color:#333333">不支持多轮会话，尤其是当模型有 system 指令时，无法很好兼容。更多待改进功能会在 3.3 部分会做详细介绍。</span></li></ol><span id="OSC_h2_4"></span><h2><span>3 ModelCache 建设</span></h2><p style="margin-left:0; margin-right:0"><span style="color:#333333">针对上述问题，我们基于 GPTCache 进行了二次开发，构建蚂蚁内部缓存产品 ModelCache，整体架构见图 2，接下来会详细介绍我们的工作，包括：3.1 整体架构；3.2 功能升级。在功能升级部分，会详细介绍 ModelCache 中新增的功能点。</span></p><span id="OSC_h3_5"></span><h3><span>3.1 整体架构</span></h3><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/305114/1699892547016-2e6263cc-8940-4c43-bffb-5bbd06c57998.png" width="941.818161404823" referrerpolicy="no-referrer"></p><p style="margin-left:16em; margin-right:0"><span>图 2. ModelCache 架构及上下游</span></p><span id="OSC_h4_6"></span><h4><span style="color:#000000">3.1.1 技术架构</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">在初始架构中，将大模型调用和数据回写对用户进行了黑盒处理。然而，这种架构导致问题排查繁琐，以及流式输出和数据安全审核等方面难以满足企业级要求。</span></p><p style="margin-left:0; margin-right:0"><span style="color:#333333">因此，我们对架构进行了重新调整，ModelCache 采用了轻量化的接入方式，不打扰大模型产品的功能实现。我们设计 ModelCache 为类 redis 结构，提供了开放式的数据查询、数据回写、数据管理等 API，同时解</span><span style="color:#000000">耦</span><span style="color:#333333">了大模型调用，可作为一个独立模块嵌入到大模型产品。通过 ModelCache，产品侧能够更加灵活地管理和使用大模型，提高系统的可维护性和可扩展性。</span></p><span id="OSC_h4_7"></span><h4><span style="color:#000000">3.1.2 核心模块</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">在 ModelCache 中，包含了一系列核心模块，包括 adapter、embedding、</span><span style="color:inherit">rank</span><span style="color:#333333">和 data_manager 等，具体功能如下：</span></p><ol><li><span>adapter 模块：其主要功能是处理各种任务的业务逻辑，并且能够将 embedding、</span><span style="color:inherit">rank</span><span>、data_manager 等模块串联起来。</span></li><li><span style="color:inherit">embedding 模块：该模块主要负责将文本转换为语义向量表示，它将用户的查询转换为向量形式，并用于后续的召回或存储操作。</span></li><li><span style="color:inherit">rank 模块：用于对召回的向量进行相似度排序和评估，可根据 L2 距离、余弦相似度或者评估模型，对两个向量进行相似度评分，并进行排序。</span></li><li><span style="color:inherit">data_manager 模块：该模块主要用于管理数据库，包括向量数据库和关系型数据库，它负责数据的存储、查询、更新和删除等操作。</span></li></ol><ol><li><ol><li><span style="color:inherit">向量数据库（Milvus）：</span><span style="color:#333333">Milvus 作为一个高性能、可扩展、多功能的向量数据库，适用于多种需要向量检索的应用场景。</span></li><li><span style="color:#333333">关系型数据库（OceanBase）：我们采用蚂蚁的 OceanBase 数据库，存储用户 query、LLM 相应、模型版本等信息。</span></li></ol></li></ol><span id="OSC_h4_8"></span><h4><span>3.1.3 功能对比</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">功能方面，为了解决 huggingface 网络问题并提升推理速度，增加了 embedding 本地推理能力。鉴于 SqlAlchemy 框架存在一些限制，我们对关系数据库交互模块进行了重写，以更灵活地实现数据库操作。在实践中，大型模型产品需要与多个用户和多个模型对接，因此在 ModelCache 中增加了对多租户的支持，同时也初步兼容了系统指令和多轮会话。更详细的功能对比请参见表 1。</span></p><p style="margin-left:0; margin-right:0"><span style="color:#333333"><img alt="" src="https://img.alicdn.com/imgextra/i4/O1CN01P0Zr401heMlvow7LH_!!6000000004302-0-tps-716-788.jpg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0; text-align:center"><span>表 1. ModelCache 与 GPTCache 功能点对比</span></p><span id="OSC_h3_9"></span><h3><span>3.2 功能升级</span></h3><p style="margin-left:0; margin-right:0"><span style="color:inherit">为了将 Cache 产品应用于企业级用户，并实现真正的落地效果，我们对其功能进行了大量迭代升级，核心功能如图 3 所示。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/2756586/1693799564935-9cb1f565-58a4-4f83-af78-54aaace84668.png" width="657" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center"><span>图 3. ModelCache 核心功能</span></p><span id="OSC_h4_10"></span><h4><span>3.2.1 数据管理</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">Cache 需要确保过时或不必要的数据不会在缓存中累积，缓存管理是 Cache 中关键的一环，为此，我们实现了两个重要的功能：</span></p><ul><li><span>一键清空能力：</span><span style="color:#333333">ModelCache 中提供了数据移除接口，使用户能够一键清空其缓存。这项功能确保当模型版本或者参数发生变更时，前期版本的数据不会对线上的回答造成干扰。</span></li><li><span>缓存淘汰策略：</span><span style="color:#333333">ModelCache 支持可定制化的缓存淘汰策略，使用户能够根据自身需求来定制缓存。</span></li></ul><span id="OSC_h4_11"></span><h4><span>3.2.2 数据隔离</span></h4><p style="margin-left:0; margin-right:0"><span>在实际应用中，数据隔离是一个重要的功能，为了满足不同场景的需求，ModelCache 实现了多种数据隔离功能，包括：</span></p><ul><li><span>环境隔离： 支持在不同环境中进行数据隔离，包括 DEV、预发和线上环境。这些环境可能存在模型版本和参数上的差异，因此确保了数据在不同环境中的独立性。</span></li><li><span>模型隔离： 支持模型级别的隔离，使用向量数据库表和 OB 表字段实现独立存储。通过这种方式，不同模型之间的数据可以得到有效的隔离，确保数据的安全性和完整性。</span></li></ul><span id="OSC_h4_12"></span><h4><span>3.2.3 数据回流</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">数据回流功能具有知识持久化的能力，能够确保系统重要数据得到有效地保存和持续使用，从而支持系统的长期发展。为此，Cache 中提供了数据回流功能，使得系统中的数据能够得到有效的持久化，这项功能采用异步方式进行，尽可能减少对系统性能的影响。</span></p><span id="OSC_h4_13"></span><h4><span>3.2.4 system 指令及多轮对话支持</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">在 ModelCache 中，提供了 system 指令和多轮对话支持，以满足用户的需求。具体如下：</span></p><ul><li><span style="color:#333333">system 指令支持： ModelCache 中支持 system 指令，尤其是后续用户可以自定义 system 指令的情况下，会区分不同 system 指令下对话的语义相似性，保持 Cache 的稳定性，未来，我们还计划将 system 指令与会话进行分离，以进一步提升系统的灵活性和可扩展性。</span></li><li><span style="color:#333333">多轮对话能力： ModelCache 还支持多轮对话，即能够匹配连续对话的语义相似性。</span></li></ul><span id="OSC_h4_14"></span><h4><span>3.2.5 可迁移性</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">ModelCache 具有出色的可迁移性，能够适应不同的场景，OceanBase 可以无缝迁移至 mysql 等产品，Milvus 也是一种可快速部署的数据库服务，所以无论是专有云还是公有云都能够快速应对，并提供高质量的服务。这种可迁移性意味着，ModelCache 可以为用户提供更加灵活和可扩展的部署方案，以满足不同的需求和场景。</span></p><span id="OSC_h4_15"></span><h4><span>3.2.6 Embedding 能力</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">在当前的 cache 中，用户可使用中文通用 embedding 模型（text2vec-base-chinese）。我们也支持大模型 embedding 层的嵌入能力，这使得 embedding 能够更好地适应模型本身的语义，但仅使用大模型的 embedding 层，演变成了词袋模型，无法获取各个 token 的权重。为此，我们在训练 SGPT（GPT Sentence Embeddings<span>&nbsp;</span></span><span>for Semantic<span>&nbsp;</span></span><span style="color:#333333">Search），以更好的支持 ModelCache。</span></p><span id="OSC_h2_16"></span><h2>&nbsp;</h2><span id="OSC_h2_17"></span><h2><span>4 效果统计</span></h2><span id="OSC_h4_18"></span><h4><span>4.1 效率统计</span></h4><p style="margin-left:0; margin-right:0"><span>依据蚂蚁内部大模型产品的 GOC 日志信息，统计了缓存命中时长和直接调用模型时长，因为产品端采用了流式输出，时间上会有一定的增加。经过实际系统统计，命中缓存可以将平均耗时降低 10 倍，整体有效提速率可达 14.5%。有效提速率的定义参见下面公式：</span></p><p style="margin-left:0; margin-right:0"><span><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/ba80167f7563caedd5661a48c7813188.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#333333">根据回流数据（排除流式输出的延迟），对缓存的耗时进行了评估，缓存未命中的耗时已经控制在数百毫秒量级，我们仍在持续进行查询耗时的优化。</span></p><span id="OSC_h4_19"></span><h4><span>4.2 embedding 模型的持续优化</span></h4><p style="margin-left:0; margin-right:0"><span style="color:#333333">在缓存场景中，我们发现仅仅评估语义相似性是不够的，核心目标应该是判断 query 对应的大型模型输出是否一致（query 的语义相似不等价于大型模型的回复一致）。例如下面的 query，一词之差，但生成的结果是完全不同的</span></p><ul><li><ul><li><span style="color:#333333">query: 从 1 遍历到 1000，找出所有能被 13 和 23 整除的数字，用 Python 实现</span></li><li><span style="color:#333333">query: 从 1 遍历到 1000，找出所有能被 13 和 23 整除的数字，用 Java 实现</span></li></ul></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#333333">我们调研了 SentenceTransformer 领域的诸多模型，但都无法满足缓存场景的需求。因此训练了一个面向企业级应用的 embedding 模型，并希望在此基础上进一步提升语义相似度评估的准确性，以提高缓存的准确率。</span></p><span id="OSC_h2_20"></span><h2><span>5 未来展望</span></h2><p style="margin-left:0; margin-right:0"><span style="color:#333333">未来，我们旨在提供性能更强、精度更高的解决方案，以满足 LLM Cache 场景下的需求。将不断地进行研究和优化，以确保 Cache 系统能够在实际应用中取得最佳的性能和准确性</span></p><p style="margin-left:0; margin-right:0"><span style="color:#333333">在性能方面，将通过深入优化各个环节，包括算法、数据和计算资源，以实现更快的召回时间，目标是将整体处理时间压缩到 300 毫秒以内，以提供更快捷高效的用户体验。</span></p><p style="margin-left:0; margin-right:0"><span style="color:#333333">在精度方面，将注重语义模型的建设，通过深入研究和改进语义表示技术，致力于提升模型对复杂语义的准确理解能力，从而更精准地匹配用户的 query。此外，还会对相似度评估模块进行优化，以进一步提升召回率。我们将综合考虑多种评估指标，如准确度、召回率和 F1 分数，以确保模型在各个方面都取得显著的提升。</span></p><span id="OSC_h2_21"></span><h2>&nbsp;</h2><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#333333">想了解更多 CodeFuse 详情，点击进入</span><span style="color:#000000">CodeFuse 官网：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodefuse.alipay.com%2F" target="_blank" rel="nofollow">https://codefuse.alipay.com</a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 08:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/10143074</guid>
            <link>https://my.oschina.net/u/6942768/blog/10143074</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Seata 进入 Apache 孵化器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#191919">Apache 基金会邮件列表<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fincubator.apache.org%2Fprojects%2Fseata.html" target="_blank">显示</a>，2023 年 10 月 29 日，分布式事务开源项目 Seata 正式通过 Apache 基金会的投票决议，正式成为 Apache 孵化器项目。</span></p><p><span style="background-color:#ffffff; color:#191919">Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。</span></p><p><img height="243" src="https://oscimg.oschina.net/oscnet/up-d0f430ca0d175df97cdbcae3599abb935b9.png" width="700" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">2019 年 1 月，阿里巴巴中间件团队发起了开源项目<span>&nbsp;</span><a href="https://www.oschina.net/p/fescar" target="_blank">Fescar</a>（Fast &amp; EaSy Commit And Rollback），和社区一起共建开源分布式事务解决方案。Fescar 的愿景是让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者们遇到的分布式事务方面的所有难题。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Fescar 开源后，蚂蚁金服加入 Fescar 社区参与共建，并在 Fescar 0.4.0 版本中贡献了 TCC 模式。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">为了打造更中立、更开放、生态更加丰富的分布式事务开源社区，经过社区核心成员的投票，大家决定对 Fescar&nbsp;进行品牌升级，并更名为<span>&nbsp;</span><strong>Seata</strong>，意为：<strong>Simple Extensible Autonomous Transaction Architecture</strong>，是一套一站式分布式事务解决方案。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 08:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266588/seata-apache-incubator</guid>
            <link>https://www.oschina.net/news/266588/seata-apache-incubator</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 内核中 Rust 的最新状态]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在近日举行的 Linux Plumbers Conference 上，Linux 和 Rust 开发人员 Miguel Ojeda 向 Linux 内核开发人员介绍了有关 Linux 内核中 Rust 的最新情况。简而言之，Rust Linux 正在不断走向成熟，并得到了思科、三星和 Canonical 等开发者和供应商的大力支持。</span></p><p><span style="color:#000000">目前，一些发行版已经张开双臂拥抱 Rust。例如，Ubuntu 已经提供了「构建和测试树外内核模块所需的所有必要工具链和内核要求」。</span></p><p><span style="color:#000000">三大 Linux Rust 工具链也正在形成。一个是 rustc 的 GCC codegen，该工具链无需修改源代码即可编译并启动主线 Rust 和 Linux。</span></p><p><span style="color:#000000">另一个是 GCC Front-End for Rust，它可以由现有的 rustc 前端加载，但受益于 GCC 的优化；不过该项目仍处于 alpha 阶段。还有一个是 Coccinelle for Rust；Coccinelle 是一个用于制作大规模 Linux 内核 C 源代码的工具，而 Coccinelle for Rust 正试图将这一功能引入 Rust 代码库。</span></p><p><span style="color:#000000">一些开发者还在尝试使用 Rust 编写驱动程序。至于一些使 Rust 与 Linux 完全集成所需的日常工作，均可以在&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frust-for-linux.com%2F" target="_blank">Rust for Linux</a> 这一官方网站查询更多详情。</span></p><p><img height="222" src="https://oscimg.oschina.net/oscnet/up-331334d8e76a3e1efb2f883a44a9c3d254b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">开发了两年之久的原始 rust 代码分支已经退役；代码还在，但已被冻结和归档。今后，rust-next 分支将包含新的 Rust 特性，并在 Linux 内核的下一个合并窗口中提交。而这个分支，顾名思义就是 Linux Next 的一部分。</span></p><p><span style="color:#000000">Rust-fixes 分支则包含 Linux 内核当前周期的 Rust 修复。还有一个用于集成的实验分支 Rust-dev ，是一个"look good enough"的补丁队列。</span></p><p><span style="color:#000000">理所当然的是，前进之路并非一帆风顺。Rust on Linux 的开发人员在过程中发现了一些问题：例如，当两个或多个线程等待另一个线程结束时，死锁在 Rust 中是安全的，因为它们不会导致未定义的行为，但它们在 Linux 内核中却不安全。目前开发人员正在努力解决这个问题。</span></p><p><span style="color:#000000">另一方面，开发人员还在担心如何处理 Rust 版本的问题。因为最新版本的 Rust Linux 兼容一些不稳定的功能，所以他们无法保证较新的 Rust 版本能在 Linux 中运行。Linux Rust 程序员现下正在跟踪最新版本的 Rust 编译器。</span></p><p><span style="color:#000000">与此相关的一个问题是，大众对将 Rust 支持反向移植到的 Linux 的 LTS 版本（特别是 5.15 和 6.1）中越来越感兴趣。但 Linux 通常不允许将 Rust 移植到 LTS Linux 中。因此，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zdnet.com%2Farticle%2Frust-in-linux-where-we-are-and-where-were-going-next%2F" target="_blank">ZDNet</a> 指出，如果你真的非常想要在旧版的 LTS 内核中获得功能齐全的 Rust 支持，那么你就需要以某种方式支付费用。</span></p><p><span style="color:#000000">总的来说，Rust 无疑正在成为 Linux 开发的重要语言。但在这一进程中无疑还有许多挑战需要克服，正如 Ojeda&nbsp;所述，虽然「核心团队随着新成员的加入而成长」，但前进之路上仍有很多工作要完成。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266584/rust-in-linux</guid>
            <link>https://www.oschina.net/news/266584/rust-in-linux</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Telegram 演示运行于 visionOS 的原生应用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Telegram 创始人帕维尔-杜罗夫 (Pavel Durov) 今天展示了 Telegram 即将推出的 visionOS 应用程序的简短一瞥，这是我们目前看到的首批第三方 visionOS 应用程序概念之一。</p><p>在 Telegram 上提供的视频中，Telegram 应用采用了半透明设计，与周围区域融为一体，这也是苹果为 visionOS 所采用的设计语言。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-22ca9cb9d4938d2680c3ed6406f83b992af.png" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1115/150409_gDLb_2720166.png" referrerpolicy="no-referrer"></p><p>该应用的侧边栏列出了用户正在进行的所有可用对话。播放的视频会从界面中跳出，变得更加身临其境，而 emoji 字符则会占据显示屏，并在分享时以独特的方式呈现出动画效果。用户可以使用虚拟键盘或通过 Siri 听写来发送信息。</p><p>与主页界面上的所有 visionOS 图标一样，Telegram 图标在被视觉选中时会以动画的形式弹出，动画可作为应用程序被突出显示的视觉提示。由于 Vision Pro 头显使用眼睛和手势导航，因此手指轻点即可启动应用。</p><p>苹果预计将于 2024 年初推出 Vision Pro，也就是四月份或之前。随着首发日期的临近，我们很快就会看到许多其他第三方应用程序的 VisionOS 体验。</p><p><strong>演示视频可用 Telegram 观看：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Fdurov%2F239" target="_blank">https://t.me/durov/239</a></p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/244019/visionos-apples-latest-operating-system">苹果宣布最新操作系统：visionOS</a></li><li><a href="https://www.oschina.net/news/251993">Vision Pro 新专利：可模拟生成气味</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 07:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266572/telegram-visionos-app</guid>
            <link>https://www.oschina.net/news/266572/telegram-visionos-app</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT Plus 临时暂停新用户注册，CEO 称服务器扛不住了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 首席执行官 Sam Altman 今日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1724626002595471740" target="_blank">发表推文称</a></u>，目前暂时暂停 ChatGPT Plus 新用户注册，原因是<strong>「自 DevDay 大会后，ChatGPT 使用量的激增超出了我们的承受能力，我们希望确保每个人都有良好的体验」</strong>。</p><p><img src="https://static.oschina.net/uploads/space/2023/1115/134613_H0qt_2720166.png" referrerpolicy="no-referrer"></p><blockquote><p>via&nbsp;<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1724626002595471740" target="_blank">https://twitter.com/sama/status/1724626002595471740</a></u></em></p></blockquote><p><span>上周 ChatGPT 因为流量过高导致服务不稳定，</span><u><a href="https://www.oschina.net/news/265693">而中断了 2 个小时</a></u><span>。半年前，OpenAI 刚上线 ChatGPT Plus 订阅计划时，也是这番操作：</span><em><u><a href="https://www.oschina.net/news/235524/openai-has-temporarily-stopped-selling-the-plus" target="_blank">OpenAI 暂时关闭 ChatGPT Plus 升级</a></u></em><span>。</span></p><p>根据调查机构&nbsp;Writerbuddy.ai&nbsp;公布的一份报告，排名前 50 名的 AI 工具在 10 个月中累计被访问 240 亿次，<strong>而其中 ChatGPT 达到了惊人的 146 亿次，占比超过 60%，平均每月访问 15 亿次</strong>。排名前十的还有 Hugging Face、谷歌 BARD、Novel AI、Capcut、Janitor AI 和 Civit AI 等等。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b6328a3f5e61c49394df02d7c0d63287218.png" referrerpolicy="no-referrer"></p><p>OpenAI 于 11 月 7 日举行了其首届开发者大会 DevDay，期间<u><a href="https://www.oschina.net/news/265331/openai-custom-versions-chatgpt"> CEO 重磅推出 GPTs </a></u>——允许开发者和公司定制 ChatGPT，以满足他们的特定需求和服务。</p><p><img height="802" src="https://static.oschina.net/uploads/space/2023/1115/141558_VJJd_2720166.png" width="1452" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">GPTs 是一种新方式，任何人都可以创建 ChatGPT 的定制版本，以便在日常生活、特定任务、工作或家庭中更有帮助，然后与其他人分享该创作。例如，GPTs 可以帮助你学习任何棋盘游戏的规则、帮助你指导孩子的数学或设计贴纸。</span></p><p><em>DevDay 大会回顾</em></p><ul><li><u><em><a href="https://www.oschina.net/news/265330" target="_blank">OpenAI 开发者大会：GPT-4 Turbo、GPTs 商店、128k 上下文窗口、大降价</a></em></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 05:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266554</guid>
            <link>https://www.oschina.net/news/266554</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[悬赏十几万元以用 Rust 重写 Prettier]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Facebook 法国前端工程师、React Native 和 Prettier 的联合创始人 Vjeux&nbsp;在 Twitter </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FVjeux%2Fstatus%2F1722733472522142022" target="_blank">发帖</a><span style="color:#000000">，寻求有能力的开发者来使用 Rust 重写前端代码格式化工具&nbsp;Prettier，并悬赏 1 万美元。</span></p><blockquote><p><span style="color:#000000">使用 Rust 实现更快、更美观的 printers 引起了广泛关注。但主要问题在于，它们都无法与 prettier 的长尾格式化逻辑相匹配。</span></p><p><span style="color:#000000">如果用 Rust 编写的项目能通过通过 95% 以上的 prettier JavaScript 测试，我将悬赏 1 万美元。</span></p></blockquote><p><img alt="" height="229" src="https://oscimg.oschina.net/oscnet/up-6f7c5921c3486449f168f164f0c04ed72c1.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Vercel 的首席执行官&nbsp;Guillermo Rauch&nbsp;也跟帖<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Frauchg%2Fstatus%2F1723400569392656771" target="_blank">表示</a>，进一步对该悬赏进行加码，将赏金升级到了 2 万美元。</span></p><p><span style="color:#000000">此外，Wasmer 官方也附议了&nbsp;Vjeux 的这一提议，并表示将额外提供 2500 美元的奖励。「我们喜欢这一倡议！如果项目编译到 WASIX 并（通过 CI）发布到 Wasmer，我们将为项目所有者额外奖励 2500 美元。」</span></p><p><span style="color:#000000">Prettier 是一个 「有主见」 的代码格式化工具。它通过解析你的代码并根据自己的规则 re-printing（将最大行长考虑在内），并在必要时对代码进行封装，从而实现一致的风格。简而言之，这个工具能够使输出代码保持风格一致。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 04:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266545/rewriting-prettier-rust</guid>
            <link>https://www.oschina.net/news/266545/rewriting-prettier-rust</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[11.25 源创会杭州站报名开启：从数据到大模型应用]]>
            </title>
            <description>
                <![CDATA[11.25 源创会杭州站报名开启：从数据到大模型应用]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/action/visit/ad?id=1558</guid>
            <link>https://www.oschina.net/action/visit/ad?id=1558</link>
        </item>
        <item>
            <title>
                <![CDATA[BifroMQ-v2.0.0 发布：支持标准集群模式（StandardCluster）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#3e3e3e">百度天工 AIoT 团队在 2023 年 7 月正式宣布开源高性能分布式 MQTT 物联网消息中间件，并将其全新命名为 BifroMQ。历时三个月，BifroMQ-v2.0.0 版本现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FT6CCbbEsdM9mBu_hJVRPGA" target="_blank">发布</a>。</span></p><p><span style="background-color:#ffffff; color:#3e3e3e">新版本首次支持集群模式，官方将其称为标准集群 StandardCluster（简称 StandardCluster）。</span><strong><span style="background-color:#ffffff; color:#3e3e3e">主要有以下特性：</span></strong></p><ul><li style="text-align:justify">集群模式全面支持 MQTT 协议：在集群模式下，每个节点均具备完整的 MQTT 协议功能，提供更高的可用性和扩展性。</li><li style="text-align:justify">新增 HTTP API 支持：除 MQTT 外，本版本新增对 HTTP API 的支持，更加灵活多变。</li><li style="text-align:justify">高性能不减：专注于在大规模负载环境下的高性能 MQTT 协议。</li><li style="text-align:justify">模块化架构进一步优化：适应各种业务需求的分布式集群管理。</li><li style="text-align:justify">强力可扩展性：目标支持大规模多租户的 Serverless 云服务。</li></ul><h4><strong>BifroMQ 的集群架构解析</strong></h4><p><strong>StandardCluster 的整体结构</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">BifroMQ 将逻辑上的 MQTT 功能从负载的角度分解为若干子服务，每个子服务对应一类关键负载：</p><ul><li style="text-align:justify"><span style="color:#3e3e3e">bifromq-mqtt：负责 MQTT 协议连接负载</span></li><li style="text-align:justify"><span style="color:#3e3e3e">bifromq-dist：负责订阅和消息路由分发负载</span></li><li style="text-align:justify"><span style="color:#3e3e3e">bifromq-inbox：负责持久会话中的离线消息队列负载</span></li><li style="text-align:justify"><span style="color:#3e3e3e">bifromq-retain：负责 Retain 消息存取负载</span></li></ul><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">从部署的角度出发，BifroMQ StandardCluster 是将这些独立负载的服务模块"封装"到一个节点服务进程的集群模式，从逻辑上来说，此为 Standalone 运行模式的抽象（BifroMQ Standalone 可以看作是单个节点的 BifroMQ StandardCluster）。与其他支持集群的 MQTT Broker 不同，BifroMQ 内置分布式持久化功能，因此单个 BifroMQ 节点是"有状态的"（Stateful）。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="340" src="https://oscimg.oschina.net/oscnet/up-10103acc9b9400c10279995130df8a8a450.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>消息分发能力的水平扩展</strong></p><p style="margin-left:0; margin-right:0">在 StandardCluster 集群模式下，每个节点进程内的分发负载模块（ 简称 Dist Service ）构成逻辑上的负载子集群（Dist-SubCluster）。Dist Service 将订阅信息存储在内置的持久化引擎中，并通过持久化引擎的分布式功能在节点之间同步路由信息。公告称，在 StandardCluster 模式下，通过增加节点的方式，即可以实现消息分发能力的水平扩展，特别是在 CleanSession 为 True 的情况下。</p><p style="margin-left:0; margin-right:0"><img height="361" src="https://oscimg.oschina.net/oscnet/up-e9a61c9398acd91228e41d3c1715da396bc.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>离线消息队列的持久化、扩展性及高可靠性</strong></p><p style="margin-left:0; margin-right:0">与 Dist Service 模块类似，节点进程内负责 MQTT 持久会话中离线消息队列的 Inbox Service 模块构成了另一个逻辑上的负载子集群（以下简称 Inbox-SubCluster）。Inbox Service 将离线队列消息持久化到内置的存储引擎中，可以极大程度地减少因节点故障导致的数据丢失。在存储方面，Inbox Service 利用内置存储引擎的分片功能，在实现存储规模和处理能力水平扩展的同时，通过静态配置或运行时策略动态增加分片的副本数，可以进一步提高离线消息数据的可靠性，这对某些对数据可靠性要求更高的应用场景尤为重要。</p><p style="margin-left:0; margin-right:0"><img height="427" src="https://oscimg.oschina.net/oscnet/up-e83bad09a192ee073e83448271eeacd3340.png" width="500" referrerpolicy="no-referrer"></p><p><strong>Inbox 服务的基于负载的拆分策略</strong></p><p>如前文所述，在 StandardCluster 部署下，单个节点进程内的 Inbox Service 利用了内置存储引擎的分片功能来实现存储规模和处理能力的水平扩展。然而，分片策略对实际运行效果有着决定性的影响。在 BifroMQ StandardCluster 版本中，已内置开箱即用的基于负载的拆分策略（以下简称 Load-based Splitting）。该策略通过统计最近一段时间内的负载情况来决定对 KV Range 的划分，可以视为一种"后验"拆分策略。当使用场景已经对离线消息负载的分布有提前规划和了解时，提前划分 Range 往往能在负载到来时带来更稳定的性能表现，而对于深度使用 BifroMQ 的用户，可以通过 SPI 机制实现此类"先验"拆分策略。</p><p style="margin-left:0; margin-right:0"><img height="435" src="https://oscimg.oschina.net/oscnet/up-9ebbc30509ae5d8f8471705413c1acf321a.png" width="300" referrerpolicy="no-referrer"></p><p><strong>HTTP API 模块</strong></p><p>BifroMQ StandardCluster 版本同时引入了 HTTP API 功能，每个集群节点均可通过配置开放 API 访问端口。BifroMQ HTTP API 作为无状态的全局接口，旨在支持业务层面的管理控制逻辑集成，访问任何一个节点的 API 都可以实现对整个集群的操作。</p><p><img height="321" src="https://oscimg.oschina.net/oscnet/up-616f9216ef245596cf8317b83796422bcca.png" width="500" referrerpolicy="no-referrer"></p><h4>混合负载对性能的影响</h4><p style="color:#878787; margin-left:0; margin-right:0; text-align:justify"><span style="color:#3e3e3e">在 StandardCluster 部署下，单个节点具备完整的 MQTT 协议功能，承担各种类型的负载。因此，这种模式非常适用于以下两类企业级应用场景：</span></p><ul><li style="text-align:justify"><span style="color:#3e3e3e">业务产生的负载类型相对单一</span></li><li style="text-align:justify"><span style="color:#3e3e3e">业务产生的负载类型多元化，但产生时间相对分散。对于负载形式复杂且在时间维度上有集中产生的情况，官方建议用户通过模拟负载测试来获得单个 BifroMQ StandardCluster 集群下的最佳资源配置和参数设置，或者考虑使用多个 BifroMQ StandardCluster 来承载不同类型的业务负载。</span></li></ul><h4 style="margin-left:0px; margin-right:0px; text-align:justify"><strong><span style="color:#3e3e3e">简单部署和简化运维</span></strong></h4><p><span style="color:#3e3e3e">BifroMQ 集群建立在一套内置的去中心化技术之上（base-cluster），无需依赖外部节点注册和发现服务。因此，构建 BifroMQ StandardCluster 的部署过程非常简单，只需指定任何一个集群中的节点作为种子节点，即可完成新节点的加入。此外，BifroMQ 还内置了集群分裂后的自愈能力，可以极大地简化出现网络分区（Network Partition）等故障时的运维操作。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 08:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266594/bifromq-2-0-0-released</guid>
            <link>https://www.oschina.net/news/266594/bifromq-2-0-0-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源多媒体播放器 VLC 发布 3.0.20，为 Windows 添加 AV1 硬件解码]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>开源多媒体播放器 VLC 近日了发布了最新版本 3.0.20。</p><p><img alt="" height="319" src="https://oscimg.oschina.net/oscnet/up-b17d30ec88965ab4d14a96a982f5e49804d.png" width="500" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.videolan.org%2Fnews.html%23news-2023-11-02" target="_blank">公告写道</a></u>，这是 VLC 3.0 分支的中度更新：它升级了编解码器，修复了 FLAC 的质量问题，并改进了多种格式的播放，包括改进字幕渲染。它还修复了使用逐帧操作时的冻结问题。在 macOS 上，音频布局问题也得到了解决。</p><p>更新日志如下：</p><ul><li>VLC 3.0.20 是 "Vetinari" 系列的第 21 次更新</li><li>改进了多种格式的播放，包括某些字幕的渲染</li><li>升级编解码器</li><li>修复 FLAC 渲染质量问题</li><li>修复使用某些旧版 AMD GPU 显卡驱动程序播放大量文件存在的问题</li><li>在 Windows 上添加 AV1 硬件解码</li><li>升级了大量第三方库</li><li>提升 SMB 与 Windows 11 主机的兼容性</li><li>优化本地化翻译</li><li>修复两个安全问题，详见：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.videolan.org%2Fsecurity%2Fsb-vlc3019.html" target="_blank">1</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.videolan.org%2Fsecurity%2Fsb-vlc3020.html" target="_blank">2</a></li></ul><p>下载地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.videolan.org%2Fvlc%2Freleases%2F3.0.20.html" target="_blank">https://www.videolan.org/vlc/releases/3.0.20.html</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 13 Nov 2023 03:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266538/vlc-3-0-20</guid>
            <link>https://www.oschina.net/news/266538/vlc-3-0-20</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
