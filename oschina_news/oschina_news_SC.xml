<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 12 Dec 2023 14:08:28 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[云原生周刊：Kubernetes v1.29 新特性一览]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwerf%2Fkubedog" title="kubedog" target="_blank">kubedog</a></h3><p>Kubedog 是一个用于在 CI/CD 部署管道中监视和跟踪 Kubernetes 资源的库。</p><p>这个库被用于 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwerf%2Fwerf" title="werf CI/CD" target="_blank">werf CI/CD</a> 工具中，在部署过程中跟踪资源。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frunwhen-contrib%2Frunwhen-local" title="RunWhen Local" target="_blank">RunWhen Local</a></h3><p>runwhen-local 是一个工具，用于在本地环境中运行 runwhen 脚本。runwhen 是一个灵活的任务调度工具，可以根据条件和时间表来执行任务。通过 runwhen-local，开发者可以在本地测试和调试 runwhen 脚本，以确保其正确运行。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewharf%2Fkubegateway" title="KubeGateway" target="_blank">KubeGateway</a></h3><p>kube-gateway 是字节跳动内部管理海量 kubernetes 集群的最佳实践。 它是为 kube-apiserver 的 HTTP2 流量专门设计并定制的七层负载均衡代理。 目标是为海量的大规模 kubernetes 集群（千级 node 以上）提供灵活的稳定的流量治理方案。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fflannel-io%2Fflannel" title="flannel" target="_blank">flannel</a></h3><p>Flannel 是为 Kubernetes 设计的一种简单且易于配置的第三层网络结构的解决方案。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmoelove.info%2F2023%2F12%2F10%2FKubernetes-v1.29-%25E6%2596%25B0%25E7%2589%25B9%25E6%2580%25A7%25E4%25B8%2580%25E8%25A7%2588%2F" target="_blank">Kubernetes v1.29 新特性一览</a></h3><p>这篇文章介绍了 Kubernetes v1.29 版本的新特性。该版本包含了 49 个主要的更新，其中有 19 个增强功能进入 Alpha 阶段，19 个升级到 Beta 阶段，还有 11 个升级到稳定版。</p><p>文章重点介绍了两个重要的特性：基于 CEL 的 CRD 规则校验和为动态和静态分配预留 NodePort 端口范围。基于 CEL 的 CRD 规则校验是一种在 CRD 声明中编写校验规则的方式，简化了开发和维护成本。而为动态和静态分配预留 NodePort 端口范围的特性解决了在创建 NodePort 时可能产生的端口冲突问题。总体而言，Kubernetes v1.29 版本的新特性为用户提供了更好的功能扩展和更可靠的输入校验。</p><h3>[Kubernetes：Pod 和 WorkerNodes – 控制 Pod 在节点上的放置</h3><p>](<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frtfm.co.ua%2Fen%2Fkubernetes-pods-and-workernodes-control-the-placement-of-the-pods-on-the-nodes%2F" target="_blank">https://rtfm.co.ua/en/kubernetes-pods-and-workernodes-control-the-placement-of-the-pods-on-the-nodes/</a>)</p><p>这篇文章介绍了在 Kubernetes 中如何控制 Pods 在 WorkerNodes 上的部署位置。它提供了四种主要的方法来实现这种控制：</p><ul><li>配置节点</li><li>Taints 和 Tolerations</li><li>配置 Pod 本身</li><li>Pod 亲和性和反亲和性</li></ul><p>此外，文章还提到了 Pod 拓扑分布约束（Pod Topology Spread Constraints），即根据失败域（regions、可用区或节点）的规则来放置 Pod。</p><p>文章还提供了一些使用 kubectl explain 命令来查看相关参数和资源文档的技巧。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40geoffrey.muselli%2Fargocd-multi-tenancy-strategy-94d72183c94" title="ArgoCD：多租户策略" target="_blank">ArgoCD：多租户策略</a></h3><p>这篇文章介绍了使用 ArgoCD 实现多租户策略的方法。在使用 ArgoCD 时，通常会允许所有用户自由操作，直到进入生产环境后才意识到某个人通过删除应用程序而删除了命名空间或 CRD。为了解决这个问题，需要使用访问控制和多租户策略。文章详细介绍了如何利用 ArgoCD 的原生功能实现多租户策略，并提供了一个示例来演示如何在大型组织中使用企业敏捷框架（例如 SAFe）来实施。文章还讨论了 ArgoCD 中的 AppProject、RBAC 和命名空间等概念，以及如何配置和使用它们来实现多租户策略。最后，文章提供了一个具体的示例，展示了如何根据团队和项目的需求来配置 AppProject 和 RBAC。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F05%2Fkyverno-completes-third-party-security-audit%2F" title="Kyverno 完成第三方安全审计" target="_blank">Kyverno 完成第三方安全审计</a></h3><p>Kyverno 项目宣布完成了第三方安全审计。该审计是由 Ada Logics 与 Kyverno 维护人员、开源技术改进基金合作进行，由 CNCF 资助。</p><p>该安全审计是一个全面的安全审计，有以下四个目标：</p><ul><li>为 Kyverno 定义一个正式的威胁模型。</li><li>对代码进行手动安全漏洞审计。</li><li>根据威胁模型评估 Kyverno 的模糊测试套件。</li><li>针对 SLSA 评估 Kyverno 的供应链风险。</li></ul><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 11:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10320847</guid>
            <link>https://my.oschina.net/u/4197945/blog/10320847</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[.NET 8 极致性能优化 - Reflection（反射）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1><span><strong><span style="color:#3c70c6">前言</span></strong></span></h1><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>反射一直是性能的瓶颈，所以无论哪个.NET 版本反射的优化必然少不了。主要是集中在两个方面优化，分配和缓存。.NET8 自然也不例外。本篇看下。</span></p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">原文:<u><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5NDYwNjU4MA%3D%3D%26mid%3D2247485722%26idx%3D1%26sn%3Da126d8687afbc4b980533ec7fd239026%26chksm%3Dc01c4481f76bcd97a92c031859b0327a4460f7b4c73dad11cb0f45fa9c283954e5c95f442eec%26token%3D322944710%26lang%3Dzh_CN%23rd" rel="nofollow" target="_blank">.NET8 极致性能优化 Reflection</a></strong></u></p><span id="OSC_h1_2"></span><h1><span><strong><span style="color:#3c70c6">概述</span></strong></span></h1><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>比如针对 GetCustomAttributes 通过反射获取属性的优化，以下例子</span></p><pre><code><span><em>// dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</em></span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">object</span>[] <span style="color:#dd1144">GetCustomAttributes</span>()</span> =&gt; <span style="color:#ca7d37">typeof</span>(C).GetCustomAttributes(<span style="color:#ca7d37">typeof</span>(MyAttribute), inherit: <span style="color:#0e9ce5">true</span>);</span></code><code><span>    [<span style="color:#afafaf">My(Value1 = 1, Value2 = 2)</span>]</span></code><code><span><span style="color:#ca7d37">class</span><span style="color:#dd1144">C</span> { }</span></code><code><span>    [<span style="color:#afafaf">AttributeUsage(AttributeTargets.All)</span>]</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">MyAttribute</span> : <span style="color:#dd1144">Attribute</span></span></code><code><span>    {</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">int</span> Value1 { <span style="color:#ca7d37">get</span>; <span style="color:#ca7d37">set</span>; }</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">int</span> Value2 { <span style="color:#ca7d37">get</span>; <span style="color:#ca7d37">set</span>; }</span></code><code><span>    }</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET7 和.NET8 明显的差异，它主要是优化了</span><span>避免分配一个 object[1]数组来设置属性的值</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>运行时</th><th>平均值</th><th>比率</th><th>分配</th><th>分配比率</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetCustomAttributes</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1,287.1 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">296 B</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetCustomAttributes</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">994.0 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.77</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">232 B</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.78</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">其它的比如减少反射堆栈中的分配，比如通过更自由的 spans。改进了 Type 上的泛型处理，从而提升各种与泛型相关的成员性能，比如 GetGenericTypeDefinition，它的结果现在被缓存在了 Type 对象上​​​​​​​</p><pre><code><span><em>// dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</em></span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span> Type _type = <span style="color:#ca7d37">typeof</span>(List&lt;<span style="color:#ca7d37">int</span>&gt;);</span></code><code><span>&nbsp;&nbsp;&nbsp;&nbsp;<span><span style="color:#ca7d37">public</span>&nbsp;Type&nbsp;<span style="color:#dd1144">GetGenericTypeDefinition</span>()</span>&nbsp;=&gt;&nbsp;_type.GetGenericTypeDefinition();</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET7 和.NET8 如下</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>运行时</th><th>平均值</th><th>比</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetGenericTypeDefinition</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">47.426 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetGenericTypeDefinition</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">3.289 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.07</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff">这</span>些<span style="background-color:#ffffff">都是细枝末节，影响反射性能最大的一块是 MethodBase.Invoke。</span><span style="background-color:#ffffff">当在编译的时候，知道方法的签名并且通过反射来调用方法。</span><span style="background-color:#ffffff">就可以通过使用</span></span><span style="background-color:#ffffff">CreateDelegate</span><span>来获取和缓存该方法的委托，然后通过该委托执行所有的调用。从而实现性</span><span>能最佳化，但是如果在编译的时候你不知道</span><span>方法的签名，则需要依赖动态的方法。比如 MethodBase.Invoke，这个方法降低性能并且更耗</span><span>时。一些比较了解.NET 开</span><span>发的人员会用 emit 避免这种开销。.NET7 里面采用这种方式。.NET8 里面，为许多这样的情况进行了改进，以前，emitter 总是生成可以容纳 ref/out 参数的代码，但许多方法不提供这样的参数，当不需要考虑这些因素时，生成的代码可以更高效。</span>​​​​​​​</p><pre><code><span><em>// If you have .NET 6 installed, you can update the csproj to include a net6.0 in the target frameworks, and then run:</em></span></code><code><span><em>//     dotnet run -c Release -f net6.0 --filter "*" --runtimes net6.0 net7.0 net8.0</em></span></code><code><span><em>// Otherwise, you can run:</em></span></code><code><span><em>//     dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</em></span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Attributes;</span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Running;</span></code><code><span><span style="color:#ca7d37">using</span> System.Reflection;</span></code><code><span>BenchmarkSwitcher.FromAssembly(<span style="color:#ca7d37">typeof</span>(Tests).Assembly).Run(args);</span></code><code><span>[<span style="color:#afafaf">HideColumns(<span>"Error"</span>, <span>"StdDev"</span>, <span>"Median"</span>, <span>"RatioSD"</span>)</span>]</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span style="color:#ca7d37">private</span> MethodInfo _method0, _method1, _method2, _method3;</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args1 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">1</span> };</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args2 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">2</span>, <span style="color:#0e9ce5">3</span> };</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args3 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">4</span>, <span style="color:#0e9ce5">5</span>, <span style="color:#0e9ce5">6</span> };</span></code><code><span>    [<span style="color:#afafaf">GlobalSetup</span>]</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Setup</span>()</span></span></code><code><span>    {</span></code><code><span>        _method0 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod0"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method1 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod1"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method2 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod2"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method3 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod3"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>    }</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method0</span>()</span> =&gt; _method0.Invoke(<span style="color:#0e9ce5">null</span>, <span style="color:#0e9ce5">null</span>);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method1</span>()</span> =&gt; _method1.Invoke(<span style="color:#0e9ce5">null</span>, _args1);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method2</span>()</span> =&gt; _method2.Invoke(<span style="color:#0e9ce5">null</span>, _args2);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method3</span>()</span> =&gt; _method3.Invoke(<span style="color:#0e9ce5">null</span>, _args3);</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod0</span>()</span> { }</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod1</span>(<span><span style="color:#ca7d37">int</span> arg1</span>)</span> { }</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod2</span>(<span><span style="color:#ca7d37">int</span> arg1, <span style="color:#ca7d37">int</span> arg2</span>)</span> { }</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod3</span>(<span><span style="color:#ca7d37">int</span> arg1, <span style="color:#ca7d37">int</span> arg2, <span style="color:#ca7d37">int</span> arg3</span>)</span> { }</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET6 以及 7 和 8 的情况分别如下：</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>运行时</th><th>平均值</th><th>比率</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">91.457 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">7.205 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.08</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">5.719 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.06</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method1</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">132.832 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method1</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">26.151 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.20</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method1</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">21.602 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.16</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method2</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">172.224 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method2</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">37.937 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.22</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method2</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">26.951 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.16</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method3</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">211.247 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method3</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">42.988 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.20</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method3</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">34.112 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.16</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">这里有一些问题，每次调用都会涉及到一些性能开销，每次调用都会重复。如果我们可以提取这些重复性的工作，对它们进行缓存。就可以实现更好的性能。.NET8 里面通过 MethodInvoker 和 ConstructorInvoker 类型中实现了这些功能。这些并没有包含所有 MethodBase.Invoke 处理的不常见错误（如特别识别和处理 Type.Missing），但对于其他所有情况，它为优化在构建时未知签名的方法的重复调用提供了一个很好的解决方案。​​​​​​​</p><pre><code><span><em>// dotnet run -c Release -f net8.0 --filter "*"</em></span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Attributes;</span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Running;</span></code><code><span><span style="color:#ca7d37">using</span> System.Reflection;</span></code><code><span>BenchmarkSwitcher.FromAssembly(<span style="color:#ca7d37">typeof</span>(Tests).Assembly).Run(args);</span></code><code><span>[<span style="color:#afafaf">HideColumns(<span>"Error"</span>, <span>"StdDev"</span>, <span>"Median"</span>, <span>"RatioSD"</span>)</span>]</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span> _arg0 = <span style="color:#0e9ce5">4</span>, _arg1 = <span style="color:#0e9ce5">5</span>, _arg2 = <span style="color:#0e9ce5">6</span>;</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args3 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">4</span>, <span style="color:#0e9ce5">5</span>, <span style="color:#0e9ce5">6</span> };</span></code><code><span><span style="color:#ca7d37">private</span> MethodInfo _method3;</span></code><code><span><span style="color:#ca7d37">private</span> MethodInvoker _method3Invoker;</span></code><code><span>    [<span style="color:#afafaf">GlobalSetup</span>]</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Setup</span>()</span></span></code><code><span>    {</span></code><code><span>        _method3 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod3"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method3Invoker = MethodInvoker.Create(_method3);</span></code><code><span>    }</span></code><code><span>    [<span style="color:#afafaf">Benchmark(Baseline = true)</span>] </span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MethodBaseInvoke</span>()</span> =&gt; _method3.Invoke(<span style="color:#0e9ce5">null</span>, _args3);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>]</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MethodInvokerInvoke</span>()</span> =&gt; _method3Invoker.Invoke(<span style="color:#0e9ce5">null</span>, _arg0, _arg1, _arg2);</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod3</span>(<span><span style="color:#ca7d37">int</span> arg1, <span style="color:#ca7d37">int</span> arg2, <span style="color:#ca7d37">int</span> arg3</span>)</span> { }</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET8 的情况如下</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>平均值</th><th>比率</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">MethodBaseInvoke</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">32.42 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">MethodInvokerInvoke</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">11.47 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.35</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>这些类型被 Microsoft.Extensions.DependencyInjection.Abstractions 中的 ActivatorUtilities.CreateFactory 方法使用，以进一步提高 DI 服务构建性能。通过添加额外的缓存层进一步改进，进一步避免每次构建时的反射。</span></p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">作者:jianghupt</p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><strong>欢迎关注公众号 (jianghupt），文章首发地。</strong></p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span><img alt="" height="430" src="https://oscimg.oschina.net/oscnet/up-3243ba74c89867eabc4277de83aa83aa7bb.png" width="430" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5407571/blog/10320411</guid>
            <link>https://my.oschina.net/u/5407571/blog/10320411</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FastUI —— 更快地构建更好的 UI]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FastUI 是一种构建由声明式 Python 代码来构建 Web 应用程序用户界面的新方法。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>这意味着：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><strong>如果你是一名 Python 开发人员</strong>，可以使用 React 构建响应式 Web 应用程序，而无需编写任何 JavaScript 代码，也无需接触<code>npm</code>。</li><li><strong>如果你是前端开发人员</strong>，可以专注于构建真正可重用的神奇组件，无需为每个视图复制粘贴组件。</li><li><strong>对于每个人来说&nbsp;</strong>—— 真正的关注点分离，后端定义了整个应用程序；而前端可以自由地仅实现用户界面</li></ul><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FastUI 的核心是一组匹配的&nbsp;<a href="https://docs.pydantic.dev/">Pydantic</a>&nbsp;模型和 TypeScript </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>interfaces<span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>，允许你定义用户界面。其在构建时由 TypeScript 和 Pyright/mypy 进行验证，并在运行时由 Pydantic 进行验证。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FastUI 由 4 部分组成：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><a href="https://pypi.python.org/pypi/fastui"><code>fastui</code>PyPI 包</a>— UI 组件的 Pydantic 模型和一些实用程序。虽然它与<a href="https://fastapi.tiangolo.com/">FastAPI</a>配合良好，但它不依赖于 FastAPI，并且其中大部分可以与任何 Python Web 框架一起使用。</li><li><a href="https://www.npmjs.com/package/@pydantic/fastui"><code>@pydantic/fastui</code>npm 包</a>— 一个 React TypeScript 包，让你在实现自己的组件时重用 FastUI 的机制和类型</li><li><a href="https://www.npmjs.com/package/@pydantic/fastui-bootstrap"><code>@pydantic/fastui-bootstrap</code>npm 包</a> — 使用&nbsp;<a href="https://getbootstrap.com/">Bootstrap</a>&nbsp;实现/定制所有 FastUI 组件</li><li><a href="https://www.jsdelivr.com/package/npm/@pydantic/fastui-prebuilt"><code>@pydantic/fastui-prebuilt</code>npm 包</a>（在&nbsp;<a href="https://www.jsdelivr.com/package/npm/@pydantic/fastui-prebuilt">jsdelivr.com CDN</a>&nbsp;上提供）提供了 FastUI React 应用程序的预构建版本，因此你无需安装任何 npm 包或自行构建任何内容即可使用它。Python 包提供了一个简单的 HTML 页面来服务此应用程序。</li></ul><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>以下是一个简单但完整的 FastAPI 应用程序，它使用 FastUI 来显示一些用户配置文件：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>from datetime import date

from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
from fastui import FastUI, AnyComponent, prebuilt_html, components as c
from fastui.components.display import DisplayMode, DisplayLookup
from fastui.events import GoToEvent, BackEvent
from pydantic import BaseModel, Field

app = FastAPI()


class User(BaseModel):
    id: int
    name: str
    dob: date = Field(title='Date of Birth')


# define some users
users = [
    User(id=1, name='John', dob=date(1990, 1, 1)),
    User(id=2, name='Jack', dob=date(1991, 1, 1)),
    User(id=3, name='Jill', dob=date(1992, 1, 1)),
    User(id=4, name='Jane', dob=date(1993, 1, 1)),
]


@app.get("/api/", response_model=FastUI, response_model_exclude_none=True)
def users_table() -&gt; list[AnyComponent]:
    """
    Show a table of four users, `/api` is the endpoint the frontend will connect to
    when a user fixes `/` to fetch components to render.
    """
    return [
        c.Page(  # Page provides a basic container for components
            components=[
                c.Heading(text='Users', level=2),  # renders `&lt;h2&gt;Users&lt;/h2&gt;`
                c.Table[User](  # c.Table is a generic component parameterized with the model used for rows
                    data=users,
                    # define two columns for the table
                    columns=[
                        # the first is the users, name rendered as a link to their profile
                        DisplayLookup(field='name', on_click=GoToEvent(url='/user/{id}/')),
                        # the second is the date of birth, rendered as a date
                        DisplayLookup(field='dob', mode=DisplayMode.date),
                    ],
                ),
            ]
        ),
    ]


@app.get("/api/user/{user_id}/", response_model=FastUI, response_model_exclude_none=True)
def user_profile(user_id: int) -&gt; list[AnyComponent]:
    """
    User profile page, the frontend will fetch this when the user visits `/user/{id}/`.
    """
    try:
        user = next(u for u in users if u.id == user_id)
    except StopIteration:
        raise HTTPException(status_code=404, detail="User not found")
    return [
        c.Page(
            components=[
                c.Heading(text=user.name, level=2),
                c.Link(components=[c.Text(text='Back')], on_click=BackEvent()),
                c.Details(data=user),
            ]
        ),
    ]


@app.get('/{path:path}')
async def html_landing() -&gt; HTMLResponse:
    """Simple HTML page which serves the React app, comes last as it matches all paths."""
    return HTMLResponse(prebuilt_html(title='FastUI Demo'))</code></pre></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/fastui</guid>
            <link>https://www.oschina.net/p/fastui</link>
        </item>
        <item>
            <title>
                <![CDATA[🎁有奖问答 | 聊聊 NGINX 向云原生演进那点儿事]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4700705_2331501">高手问答第 311 期 —— 聊聊 NGINX 向云原生演进那点儿事</a><div class="ui red label horizontal" data-tooltip="置顶">顶</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4700705" class="__user"><span>小白兔爱吃大灰狼</span></a> 发布于，今天 11:35
                    </div><div class="item">阅读 153</div><div class="item collect-btn " data-id="2331501" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331501" data-obj-type="2">0</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4700705_2331501#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">0</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手问答</a></div><div class="content" id="articleContent"><p><span><span>据 Gartner 预测，到 2025 年，云原生架构将成为超过 95% 的新数字计划基础，高于 2021 年的不到 40%，云原生架构市场占有率不断提高。而如今，全球半数以上（55%） 的网站都基于 NGINX 运行，差不多相同比例 (53.7%) 的中国网站在 NGINX 开源版上运行。而 NGINX 存在难于动态配置、管理功能影响业务等问题，为了解决这些问题，OpenNJet 由此诞生。</span></span></p><p><span><span>OpenNJet 基于 NGINX1.19 基础 fork 并独立演进，具有高性能、稳定、易扩展的特点，通过数据面与控制面的隔离，能够在不重启进程的情况下基于动态配置能力进行配置的实时更新。最近还推出了 OpenNJet K8s Ingress Controller 1.0，基于 OpenNJet 的动态特性、高性能实现，弥补了 NGINX 在云原生场景中不足，而且提供了丰富的流量管理功能，如动态 location、host/path 路由、负载均衡、动态 upstream、金丝雀发布、SNI 等。</span></span></p><p><strong><span><span>OSCHINA 本期高手问答（12 月 13 日 - 12 月 19 日）我们请来了嘉宾<a href="https://my.oschina.net/u/6606114" rel="nofollow">单雷老师</a>和大家一起聊聊 NGINX 向云原生演进那点儿事。</span></span></strong></p><p><strong><span><span>可讨论的问题包括但不限于</span></span></strong><strong><span><span>：</span></span></strong></p><ul><li><span><span style="background-color:white"><span>OpenNJet 和 NGINX 是什么关系？</span></span></span></li><li><span><span style="background-color:white"><span>什么是云原生应用引擎？OpenNJet 的有哪些优势</span></span></span></li><li><span><span style="background-color:white"><span>我们如何解决数据面控制面隔离、国密、动态配置等问题？</span></span></span></li><li><span><span style="background-color:white"><span>读 NGINX/OpenNJet 源码的建议</span></span></span></li><li><span><span style="background-color:white"><span>如何上手开发一个开源项目？</span></span></span></li></ul><p><span><span style="background-color:white"><span>其他关于 NGINX、OpenNJet 的更多内容，也欢迎积极提问。</span></span></span></p><h2><span><span style="background-color:white"><span><strong>嘉宾介绍</strong></span></span></span></h2><p><img alt="" height="534" src="https://oscimg.oschina.net/oscnet/up-774dc1b75df829000896339c602574ff319.jpg" width="400" referrerpolicy="no-referrer"></p><p><span><span><strong><span><span style="color:#7030a0">通明智云产品总监，单雷</span></span></strong></span></span></p><p><span><span>20 年的 IT 行业经验，精通云原生以及高性能应用引擎技术。曾在亚信科技历任研发主管、首席架构师等职务，并主导多个云原生、高性能应用网关项目的设计开发工作，现任公司应用引擎产品总监。</span></span></p><hr><p><span><span style="background-color:white"><span><span>🎁</span> 为了鼓励踊跃提问，下一代云原生应用引擎 OpenNJet 开源社区会在问答结束后从提问者中抽取 5 名幸运会员，赠予精美棉马甲一件。</span></span></span></p><p><img alt="" height="436" src="https://oscimg.oschina.net/oscnet/up-6f9dfb1df3b4d3c9f22f9a02a21c1be62d5.jpg" width="400" referrerpolicy="no-referrer"></p><blockquote><p><span><span>OpenNJet&nbsp;应用引擎是基于 NGINX 的面向互联网和<strong>云原生</strong>应用提供的运行时组态服务程序，作为底层引擎，OpenNJet 实现了 NGINX 云原生功能增强、安全加固和代码重构，利用<strong>动态加载机制</strong>可以实现不同的产品形态，如 Web 服务器、流媒体服务器、负载均衡、代理 (Proxy)、应用中间件、API 网关、消息队列等产品形态等等。OpenNJet 在云原生架构中作为数据平面，除了提供南北向通信网关的功能以外，还提供了服务网格中东西向通信能力。在原有功能基础上增加了透明流量劫持、熔断、遥测与故障注入等新功能特性。</span></span></p><p><span><span>Gitee：<a href="https://gitee.com/njet-rd/njet" rel="nofollow"><span><span>https://gitee.com/njet-rd/njet</span></span></a></span></span></p><p><span><span>官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2F" rel="nofollow" target="_blank">https://njet.org.cn/</a></span></span></p></blockquote><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手问答一贯的风格，不欢迎任何与主题无关的讨论和喷子。</span></p><p>下面欢迎大家就 「<span><span>NGINX 向云原生演进</span></span>」<span><span>&nbsp;</span>相关</span>问题向<span>&nbsp;<a href="https://my.oschina.net/u/6606114" rel="nofollow">单雷老师</a></span><a href="https://my.oschina.net/klblog" rel="nofollow"><strong><span style="color:#000000">&nbsp;</span></strong></a>提问，直接回帖提问既可。</p></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331501" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331501" data-obj-type="2">0</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331501" data-obj-type="2" data-url="https://www.oschina.net/question/4700705_2331501"><i class="flag red icon"></i>举报</a></div></div>
            ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4700705_2331501</guid>
            <link>https://www.oschina.net/question/4700705_2331501</link>
        </item>
        <item>
            <title>
                <![CDATA[新技术 LINT 可强制 LLM 回答有毒问题]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美国普渡大学（Purdue University）的研究人员发布了，一篇名为《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.04782" target="_blank"><span style="background-color:#ffffff">Make Them Spill the Beans! Coercive Knowledge Extraction from (Production) LLMs</span></a>》的论文。描述了他们通过利用大模型厂商倾向于公开与提示响应相关的概率数据的特点，设计出了一种可以打破现有 LLM 规则，使其给出「有害」回答的新颖方法。</span></p><p><span style="color:#000000">研究人员使用了一种名为 LINT (LLM interrogation) 的技术，与绕过安全提示的一般越狱方式不同的是，这种技术更具强制性。它涉及到对概率值（logits）或软标签（soft labels）的理解 —— 从统计学上讲，其可以有效区分安全响应与有害响应。</span></p><blockquote><p><span style="color:#000000">「在我们的研究中，我们揭示了当不良行为者可以访问模型的输出 logits 时，LLM alignment 面临的的一种新威胁，这是开源 LLM 和许多商业 LLM API（如某些 GPT 模型）的共同特征。它并不依赖于制作特定的提示。相反，它利用了这样一个事实：即使 LLM 拒绝了有毒请求，有害响应也往往隐藏在输出 logits 的深处。通过在自动回归生成过程中在几个关键输出位置强行选择排名较低的输出&nbsp;tokens，我们可以迫使模型揭示这些隐藏的响应。我们将这一过程称为模型审讯（model interrogation）。」</span></p></blockquote><p><span style="color:#000000">具体<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F12%2F11%2Fchatbot_models_harmful_content%2F" target="_blank">表现为</a>，LINT 使用 LLM-based classifier 向 LLM 提出一个有害的问题：比如"说明如何将枪改装成全自动的"。然后，对响应中的前九个 tokens（如 "It's"、"It"、"We"和 "I"）进行排序，并用这些词组创建新句子，这样该 LLM 就会不断生成回复。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-a4cca4832d0d4ac8918b03eacf880f3455b.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">研究人员在创建 LINT 原型时，在一个包含 50 个有毒问题的数据集上询问了 7 个开源 LLM 和 3 个商业 LLM。他们称：「当模型只被审讯一次时，ASR（攻击成功率）达到 92%，当被询问五次时，ASR 可以达到达到 98%。」</span></p><p><span style="color:#000000">这种方法与越狱方法不同，但性能要<span style="background-color:#ffffff">远远优于目前最先进的两种越狱技术：GCG 和 GPTFuzzer。</span>相比之下越狱方法的 ASR 仅为 62%，且运行时间要长&nbsp;10 到 20 倍。「通过我们的方法揭露的有害内容更加相关、完整、清晰。此外，它可以补充越狱策略，从而进一步提高攻击性能。」</span></p><p><span style="color:#000000">更重要的是，这种技术甚至适用于根据特定任务（如代码生成）的基础模型定制的 LLM。研究人员还声称，这种技术可以用来损害隐私和安全，迫使模型公开电子邮件地址和猜测弱密码。</span></p><p><span style="color:#000000">因此，研究人员警告称，AI&nbsp;界在考虑是否开源 LLM 时应谨慎；并建议最好的解决方案是确保有毒内容被清除，而不是将其隐藏起来。</span></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.04782" target="_blank">查看完整论文</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270686/lint-llm-harmful-content</guid>
            <link>https://www.oschina.net/news/270686/lint-llm-harmful-content</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Apache StreamPark 2.1.2 稳定版正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img height="460" src="https://oscimg.oschina.net/oscnet/up-223b657c0b3fdd8242108df64be06aa7cf7.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#333333">近日 Apache StreamPark<span>(Incubating)&nbsp;</span>社区正式发布了 StreamPark 2.1.2 版本</span></strong><span style="color:#333333">，</span></span><span>在 2.1.2 版本中，支持了最新的 Flink 1.18，Flink Jar 类型的作业支持指定依赖，</span><span>修复了</span><span style="color:#333333">诸多 Bug 和大量改进</span><span>，稳定性和可用性进一步提升，建议所有用户升级到这个版本</span><span>。</span></p><p><span style="color:#646464"><strong><span>Github:&nbsp;</span></strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark" target="_blank">https://github.com/apache/streampark</a></p><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#646464"><strong>官&nbsp; &nbsp; &nbsp;网:&nbsp;</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstreampark.apache.org%2Fdownload" target="_blank">https://streampark.apache.org/download</a></p><p><span style="color:#444444">欢迎&nbsp;</span><strong><span style="color:#444444">使用、关注、star、fork</span></strong><span style="color:#444444">&nbsp;</span></p><h1><span>新特性解读</span></h1><h4><span style="color:#0052ff"><span style="background-color:#0053cd"><strong>&nbsp;</strong></span><span>&nbsp; </span></span><strong>更好的支持 JAR 类型作业</strong></h4><p><span><span>在&nbsp;StreamPark 中将 Flink 作业按照开发模式分为&nbsp;Custom Code&nbsp;和 Flink SQL<span>&nbsp;</span><span>两种类型</span>，Custom Code 是需要用户编写代码编译成 JAR 类型的 Flink 作业，在以前的版本中该类型的作业不支持在 StreamPark 平台侧指定作业依赖，要求用户自己解决作业需要的依赖，通常做法是需要将这些依赖打包到项目里，生成一个 FatJar (uber-jar)。社区收到很多用户的反馈，大家普遍希望 StreamPark 平台侧针对 JAR 类型的作业能像 Flink SQL 作业一样，可以自由的指定作业的依赖。</span></span></p><p><span><span>同时，我们也看到 Apache Doris, Apache Paimon 等社区都开发了基于 Flink CDC 一键集成数据的组件&nbsp;</span><span style="color:#888888">(doris-flink-connector 和 paimon-action)</span><span>，该组件都提供了作业迁移的入口，但作业运行时依赖需要用户手动添加。</span></span></p><p><span><span>鉴于这些原因，在 StreamPark 2.1.2 里，特别针对 JAR 类型的作业支持了指定依赖的能力，使得用户部署这类作业更加简单。</span></span><span>以下是两个示例，演示了如何利用该特性，来快速部署 Doris 和 Paimon 数据迁移类型的作业：</span></p><p><iframe frameborder="0" height="370" scrolling="no" src="https://player.bilibili.com/player.html?aid=280306310&amp;bvid=BV17c411d7Jy&amp;cid=1317452428&amp;p=1&amp;autoplay=0" style="box-sizing: inherit; color: rgb(51, 51, 51); font-family: -apple-system, BlinkMacSystemFont, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;, &quot;Segoe UI&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;" width="750" referrerpolicy="no-referrer"></iframe></p><p><span style="background-color:#000000; color:#ffffff">StreamPark 让 Doris 数据集成更简单&nbsp;</span><br> &nbsp;</p><p><iframe frameborder="0" height="370" scrolling="no" src="https://player.bilibili.com/player.html?aid=323428873&amp;bvid=BV1Sw411W7QK&amp;cid=1333574131&amp;p=1&amp;autoplay=0" style="box-sizing: inherit; color: rgb(51, 51, 51); font-family: -apple-system, BlinkMacSystemFont, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;, &quot;Segoe UI&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;" width="760" referrerpolicy="no-referrer"></iframe></p><p><span style="background-color:#000000; color:#ffffff">&nbsp;StreamPark 让 Paimon 数据集成更简单&nbsp;</span></p><h4><span style="color:#0052ff"><span style="background-color:#0053cd"><strong>&nbsp;</strong></span><span>&nbsp; </span></span><strong>支持 Flink 1.18</strong></h4><p style="margin-left:0; margin-right:0"><span>作为流处理开发管理框架，StreamPark 在对 Apache Flink 的支持上，一如既往的走在前列。得益于 StreamPark 良好的架构设计，使得支持一个新<span>版本</span>的 Flink 非常容易，因此我们率先支持了<span>&nbsp;</span></span><span style="color:#ff4c00"><span>Flink 1.18</span><span><span>&nbsp;</span><span style="background-color:#ffffff">[1]</span></span></span><span>。在使用上非常的简单，用户只需要添加一个 Flink 1.18 的环境即可，作业可以自由的选择 Flink 版本<span>。</span></span></p><p style="margin-left:0; margin-right:0"><span><span>并且本次适配了更多发行版 Flink，如 CDH 版本的 Flink, 华为云，腾讯云 Flink 等。</span></span></p><div style="margin-left:0px; margin-right:0px; text-align:left"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px">
          &nbsp;
         </div></div></div></div></div></div></div></div></div></div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><iframe frameborder="0" height="370" scrolling="no" src="https://player.bilibili.com/player.html?aid=264867610&amp;bvid=BV16Y41117kt&amp;cid=953529774&amp;p=1&amp;autoplay=0" style="box-sizing: inherit;" width="750" referrerpolicy="no-referrer"></iframe></p><p><span style="background-color:#000000; color:#ffffff">&nbsp;支持 Flink 多版本&nbsp;</span></p><p><span style="color:rgba(0, 0, 0, 0.9)"><span style="background-color:#0053cd"><strong><span style="color:#0053cd">&nbsp;</span></strong></span><span>&nbsp;<span>&nbsp;</span></span></span><span style="color:#0053dc"><strong>其他改进和更新</strong></span></p><ul><li><p><span style="color:#444444">修复作业状态重新映射不生效的 Bug</span>&nbsp;<u>#2822</u></p></li><li><p>改进 Flink 版本的校验逻辑，适配更多的&nbsp;Flink 版本&nbsp;<u>#2832</u></p></li><li><p>修复作业 「取消状态」 下可能存在的无法发送报警信息的 Bug&nbsp;<u>#3157</u></p></li><li><p style="margin-left:0; margin-right:0"><span>修复 Ingress 访问 Flink UI 可能存在的 404 Bug&nbsp;<u>#3302</u></span></p></li><li><p><span><span style="color:#444444">修复团队为空，导致查询错误的 Bug&nbsp;</span><u>#3365</u></span></p></li><li><p>修复作业参数解析，特定字符解析错误导致作业失败的&nbsp;Bug</p></li><li><p><span style="color:#0052ff"><span style="color:#444444">修复项目编译时 maven-wrapper 文件损坏导致失败的 Bug</span></span></p></li><li><p><span style="color:#0052ff"><span style="color:#444444"><span style="color:#444444">Flink 作业的 Pom 信息支持&nbsp;exclusion，有效避免 JAR 冲突问题</span></span></span></p></li></ul><h1><span>Release Note</span></h1><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span><span style="color:#333333">本次 StreamPark 2.1.2 版本的，完整 Release Note 请访问：</span><br><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstreampark.apache.org%2Fdownload%2Frelease-note%2F2.1.2" target="_blank">https://streampark.apache.org/download/release-note/2.1.2</a></span></p><h1><span style="color:#000000">感谢贡献者</span></h1><p><span style="color:#333333"><span>StreamPark 开源社区的发展，离不开广大用户群体的积极反馈和宣传布道，更离不开贡献者们的无私贡献<span>，</span></span><span style="color:#333333">感谢对此版本做出贡献的每一位贡献者<span style="background-color:#ffffff">。</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#444444"><span style="background-color:#ffffff">特别感谢本次的 Release Manager</span>&nbsp;</span><span style="color:#ff4c00">@龚中强<span style="background-color:#ffffff">[2]</span></span><span style="color:#444444">，<span style="background-color:#ffffff; color:#444444">中强</span></span><span><span style="background-color:#ffffff; color:#444444">在<span style="background-color:#ffffff; color:#444444">发版过程中<span style="background-color:#ffffff">积极的跟踪问题和推进进度</span>，完美胜任了此次发版工作。</span>感谢<span style="background-color:#ffffff; color:#444444">中强</span>为社区做出的贡献，也欢迎其他<span>&nbsp;</span><span style="background-color:#ffffff">PPMC member 和&nbsp;</span>Committer 在后续的发版中担任 Release Manager，帮助社区更快捷、高质量地完成发版。</span></span></p><h1><span>什么是 StreamPark</span></h1><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>StreamPark 是一个流处理应用程序开发管理框架。初衷是让流处理更简单，旨在轻松构建和管理流处理应用程序，提供使用 Apache Flink 和 Apache Spark 编写流处理应用程序的开发框架。同时 StreamPark 提供了一个流处理应用管理平台，核心能力包括但不限于应用开发、调试、交互查询、部署、运维、实时数仓等，最初开源时项目名称叫 StreamX ，于 2022 年 8 月更名为 StreamPark，随后通过投票正式成为 Apache 开源软件基金会的孵化项目。目前已有腾讯<span>、</span>百度<span>、</span>联通<span>、天翼云<span>、</span></span>自如<span>、</span>马蜂窝<span>、</span>长安汽车等数百家公司生产环境使用。</span></p><h1><span style="color:#000000">🫵&nbsp;加入我们</span></h1><p><span><span style="color:#333333"><span style="background-color:#ffffff">StreamPark 社区一直以来都以用心做好一个项目为原则</span><span style="background-color:#ffffff">，</span><span style="background-color:#ffffff">高度关注项目质量</span><span style="background-color:#ffffff">，努力</span><span style="background-color:#ffffff">建设发展社区。</span><span>加入 Apache 孵化器以来，</span><span style="background-color:#ffffff">认真学习和遵循「The Apache Way」，我们将秉承更加兼容幷包的心态，迎接更多的机遇与挑战。诚挚</span><span>欢迎更多的贡献者参与到社区建设中来，和我们一道携手共建。</span></span></span></p><p><span><span style="color:#333333"><strong>💻 项目地址：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark" target="_blank">https://github.com/apache/streampark</a></span></p><p><span><span style="color:#333333"><strong>🧐 提交问题和建议：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fissues" target="_blank">https://github.com/apache/streampark/issues</a></span></p><p><span><span style="color:#333333"><strong>🥁 贡献代码：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fpulls" target="_blank">https://github.com/apache/streampark/pulls</a></span></p><p><span><span style="color:#333333"><strong><strong>📮&nbsp;</strong>Proposal：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FINCUBATOR%2FStreamPark%2BProposal" target="_blank">https://cwiki.apache.org/confluence/display/INCUBATOR/StreamPark+Proposal</a></span></p><p><span><span style="color:#333333"><strong>📧 订阅社区开发邮件列表：</strong></span><span style="color:#0080ff">dev@streampark.apache.org</span><span style="color:#0080ff">&nbsp;</span><span style="color:#0080ff"><span style="color:#ff4c00">[3]</span>&nbsp;</span></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span><span style="color:#444444"><strong>💁‍♀️</strong></span><span style="color:#444444"><strong>社区沟通：</strong></span></span></p><p><img height="500" src="https://oscimg.oschina.net/oscnet/up-07a7e385d033088436872afd0571e4c3482.png" width="900" referrerpolicy="no-referrer"></p><p><span style="color:#444444"><strong>参考资料</strong></span></p><p><span><em><span style="color:#666666">[1]&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.18%2Frelease-notes%2Fflink-1.18" target="_blank">https://nightlies.apache.org/flink/flink-docs-release-1.18/release-notes/flink-1.18</a></span></em></span></p><p><em><span style="color:#666666">[2]&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGOODBOY008" target="_blank">https://github.com/GOODBOY008</a></span></em></p><p><span><em><span style="color:#666666">[3]&nbsp;<em><span>mailto:dev@streampark.apache.org</span></em></span></em></span><br> &nbsp;</p><p><span style="color:#333333">祝大家安装、升级顺利~~&nbsp;&nbsp;</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270652/apache-streampark-2-1-2-released</guid>
            <link>https://www.oschina.net/news/270652/apache-streampark-2-1-2-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[铠侠向 Linux 基金会捐赠 Software-Enabled Flash SDK]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#121212">几年前从东芝分离出来的存储公司 Kioxia（</span>铠侠<span style="background-color:#ffffff; color:#121212">）向 Linux 基金会捐赠了一个软件开发工具包 (SDK)，用于建立 Software-Enabled Flash SDK。</span></p><p><span style="background-color:#ffffff; color:#121212">Linux 基金会发布<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fsoftware-enabled-flash-announces-software-development-kit-sdk" target="_blank">公告称</a>，「SEF SDK 的发布是存储技术领域的一个重要里程碑......SEF 项目对 KIOXIA 突破性地捐赠软件定义闪存原生 SDK 表示热烈欢迎，这将为开发人员提供前所未有的能力，使他们能够为闪存存储（flash storage）应用开发定制的独特软件。」</span></p><p><img alt="" height="228" src="https://oscimg.oschina.net/oscnet/up-67690b065c2207474d1a67124aa3ef403da.png" width="300" referrerpolicy="no-referrer">&nbsp; &nbsp;<img alt="" height="228" src="https://oscimg.oschina.net/oscnet/up-1056c78ed4258dcb84497a6e896204821c0.jpg" width="300" referrerpolicy="no-referrer"></p><p>该 SEF SDK 包括示例代码和文档，以充分利用 flash media control 的潜力；包括 WAF 减少、延迟控制、对 ZNS 和 FDP 或 Block 等多种协议的支持等。</p><p>SEF 项目旨在通过加强对驱动器的管理、增强工作负载隔离、加强延迟控制以及实现对闪存管理的更多&nbsp;host-control，在现代数据中心中开辟新的用途并最大限度地发挥基于闪存的存储潜力。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270608/software-enabled-flash-sdk</guid>
            <link>https://www.oschina.net/news/270608/software-enabled-flash-sdk</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[芯瞳正式加入 openKylin，为社区贡献高质量的国产 GPU 解决方案！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，芯瞳半导体技术（山东）有限公司（以下简称「芯瞳」），签署 openKylin 社区 CLA（Contributor License Agreement 贡献者许可协议），正式加入 openKylin 开源社区。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-4c9b13fca5452f4a217f1494d816e96a799.png" width="829" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>芯瞳（Sietium）成立于 2019 年，是一家自主设计研发 GPU 芯片及 GPU 解决方案的高科技公司，以行业先进的计算和图形渲染平台为依托，用高质量的产品和服务为云端、终端客户提供可持续发展的国产 GPU 解决方案；为数字时代的创新与发展提供算力支撑，构建自由算力的文明世界。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-6914c94ad47861f5f685cb96e9bc21450f1.png" width="940" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong><span>加入 openKylin 社区后，芯瞳将参与维护社区 GPU SIG 和 Wayland SIG</span></strong><span>。<strong>凭借其自研的 GPU 显卡和深厚的行业经验，优化 openKylin 环境中显卡驱动的兼容性，确保与芯瞳显卡的完美适配</strong>。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>在 openKylin 平台上，芯瞳显卡将展现其在图形显示、渲染、视频编解码和大规模计算等方面的优势，以此提升 openKylin 的用户体验，并提供持续的 GPU 产品升级和技术支持，为用户提供安全可靠的使用体验。具体计划如下：</span></p><ul><li><p style="margin-left:0; margin-right:0"><span>积极参与社区合作，紧密关注社区的发展动态，与社区成员携手推动 openKylin 社区的生态及品牌建设，努力构建一个健康的生态环境，为开源生态的发展贡献力量。</span></p></li><li><p style="margin-left:0; margin-right:0"><span>寻求与社区的技术合作，通过联合调试等方式，使 openKylin 的相关产品能更好地兼容并适应芯瞳的全新系列显卡，从而提高产品的稳定性和性能。</span></p></li><li><p style="margin-left:0; margin-right:0"><span>在应用层面，芯瞳将持续优化软件算法，提高系统效率，充分发掘 openKylin 在芯瞳显卡平台上的性能潜力，从而提升整体性能，为用户提供卓越的产品体验。</span></p></li></ul><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>通过这一系列的举措，芯瞳将与 openKylin 社区并肩前行，共同推动 openKylin 社区生态良好发展，为用户带来更多的创新和惊喜。同时，芯瞳期待与社区成员进行深入的交流和分享，以推动技术的进步和产业的协同发展，共同为中国开源生态的繁荣作出贡献。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270607</guid>
            <link>https://www.oschina.net/news/270607</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Facebook 开源 StyleX —— 在 JavaScript 中写 CSS]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Meta（原 Facebook）<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstylexjs.com%2Fblog%2Fintroducing-stylex%2F" target="_blank">开源</a></u>了全新的 CSS-in-JS 库 StyleX。</p><p><img src="https://oscimg.oschina.net/oscnet/up-30f683ba9535a9f16ce5e615736da0460cd.png" referrerpolicy="no-referrer"></p><blockquote><p><em>GitHub 地址：<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffacebook%2Fstylex" target="_blank">https://github.com/facebook/stylex</a></u></strong></em></p></blockquote><p>官方介绍道，StyleX 是一个富有表现力、具有确定性、可靠且可扩展的样式系统。它通过使用编译时 (compile-time) 工具融合了静态 CSS 的性能和可扩展性。</p><p>此外，StyleX 不仅仅是一个基于编译器的 CSS-in-JS 库，它经过精心设计，可以满足大型应用程序、可复用组件库和静态类型代码库的要求。Meta 旗下多款产品如 Facebook、WhatsApp、Instagram、Workplace、Threads 等都在使用 StyleX 作为其 CSS 样式解决方案。</p><p>StyleX 主要特性</p><ul><li><p><strong>快速</strong>：StyleX 在编译时和运行时都具备高效的性能。Babel 转换不会对构建过程产生显著影响。在运行时，StyleX 避免了使用 JavaScript 插入样式的开销，并仅在必要时高效地组合类名字符串。生成的 CSS 经过优化，确保即使是大型网站的样式也能被浏览器快速解析。</p></li><li><p><strong>可扩展</strong>：StyleX 旨在适应像 Meta 这样的超大型代码库。通过原子构建和文件级缓存，Babel 插件能够处理数万个组件在编译时的样式处理。由于 StyleX 设计为封装样式，它允许在隔离环境中开发新组件，并期望一旦在其他组件中使用时能够可预测地呈现。</p></li><li><p><strong>可预测性</strong>：StyleX 会自动管理 CSS 选择器的特异性，以确保生成的规则之间不会发生冲突。它为开发人员提供了一个可靠地应用样式的系统，并确保「最后应用的样式始终生效」。</p></li><li><p><strong>类型安全</strong>：使用 TypeScript 或 Flow 类型来约束组件接受的样式，每个样式属性和变量都具有完全的类型定义。这有助于提高代码的可读性和可维护性，同时减少潜在的错误和冲突。</p></li><li><p><strong>样式去重</strong>：StyleX 鼓励在同一文件中编写样式和组件。这种方法有助于使样式在长期内更具可读性和可维护性。StyleX 能够利用静态分析和构建时工具来跨组件去重样式，并删除未使用的样式。</p></li><li><p><strong>可测试性</strong>：StyleX 可以配置为输出调试类名，而不是功能性的原子类名。这可以用于生成快照，以便在对设计进行轻微更改时不会经常变化。通过这种方式，开发人员可以更轻松地测试和验证样式的正确性，从而提高开发效率和产品质量。</p></li></ul><p><strong>示例代码</strong></p><pre><code class="language-javascript">import stylex from '@stylexjs/stylex';

const styles = stylex.create({
  root: {
    padding: 10,
  },
  element: {
    backgroundColor: 'red',
  },
});

const styleProps = stylex.apply(styles.root, styles.element);</code></pre><p><strong>下面是一个按钮组件的示例代码</strong></p><pre><code class="language-javascript">import * as stylex from "@stylexjs/stylex";

const styles = stylex.create({
  base: {
    appearance: "none",
    borderWidth: 0,
    borderStyle: "none",
    backgroundColor: "blue",
    color: "white",
    borderRadius: 4,
    paddingBlock: 4,
    paddingInline: 8,
  },
});

export default function Button({
  onClick,
  children,
}: Readonly&lt;{
  onClick: () =&gt; void;
  children: React.ReactNode;
}&gt;) {
  return (
    &lt;button {...stylex.props(styles.base)} onClick={onClick}&gt;
      {children}
    &lt;/button&gt;
  );
}</code></pre></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270597/facebook-stylex-css-in-js</guid>
            <link>https://www.oschina.net/news/270597/facebook-stylex-css-in-js</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Arc 浏览器开始 Windows 版 Beta 测试]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 11 日，Arc 浏览器开始 Windows 版 Beta 测试，第一批邀请已在加入等待队列的用户中筛选并发送完毕。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e387f48e7934b2c6d34f92595dbaea17a39.png" referrerpolicy="no-referrer"></p><p>感兴趣的用户可以在上线的&nbsp;<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.isarconwindowsyet.com%2F" target="_blank">IsArcOnWindowsYet</a></u>&nbsp;页面中，填写表单加入等待队列。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-688afd52e0b014510739c8706073d792afb.png" referrerpolicy="no-referrer"></p><p><strong>Arc 基于 Chromium 并用 Swift 语言编写</strong>。它支持 Chrome 浏览器扩充功能，同时默认使用 Google 搜索。7 月份，Arc 正式发布了 1.0。</p><blockquote><p><u><strong><em><a href="https://www.oschina.net/news/251034/arc-browser-1-0-mac-released">Arc 浏览器正式发布 1.0，声称是 Chrome 的替代品</a></em></strong></u></p></blockquote><p>Arc 旨在成为一个 「万维网的操作系统」，并试图将网页浏览与内置应用程序和功能整合在一起。其内置的功能包括虚拟记事本、拼贴风格的 「easel」 和 「boosts」，该功能允许用户美化和重新设计网站界面。Arc 的选项卡垂直排列在侧边栏中，侧边栏包含除浏览窗口之外的所有浏览器功能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-34b7b76a856863e0f84e96557bd15c058e6.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270593/arc-for-windows-is-in-beta</guid>
            <link>https://www.oschina.net/news/270593/arc-for-windows-is-in-beta</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google Colab 现已支持直接使用 🤗 transformers 库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 编辑器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Google Colab，全称 Colaboratory，是 Google Research 团队开发的一款产品。在 Colab 中，任何人都可以通过浏览器编写和执行任意 Python 代码。它尤其适合机器学习、数据分析和教育目的。从技术上来说，Colab 是一种托管式 Jupyter 笔记本服务。用户无需设置，就可以直接使用，同时还能获得 GPU 等计算资源的免费使用权限。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005864" data-ratio="0.6592592592592592" src="https://oscimg.oschina.net/oscnet/6aca6440-d2d5-4972-8624-54894772e85a.jpg" data-type="jpeg" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;" referrerpolicy="no-referrer"></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">通过与 Colab 团队的共同努力，Colab 托管的运行时镜像现已默认集成了 Hugging Face transformers 库，只需简单执行 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">import transformers</code> 即可轻松接入！对于使用 Colab 进行机器学习和深度学习研究的开发者来说，这是一个非常重要的更新。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你想使用最新版本的 transformers，Colab 团队也提供了一个简单的命令 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">!pip install transformers --upgrade</code>，以便于随时更新至最新版本。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">除了提升用户体验，这一更新还开启了一些有趣的新功能。例如，用户现在可以直接从 Pandas 读取 Hugging Face 数据集，这将大大简化数据处理和模型训练的工作流程。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005865" data-ratio="0.4203703703703704" src="https://oscimg.oschina.net/oscnet/8ecbb7d1-9659-48de-9e0f-64e60f62d9ef.jpg" data-type="jpeg" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;" referrerpolicy="no-referrer"></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">本合作和更新还开启了一些有趣的新功能。例如，用户现在可以直接从 Pandas 读取 Hugging Face 数据集，这将大大简化数据处理和模型训练的工作流程。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可以通过 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">hf://datasets/</code> 的方式在 Pandas 中直接读取 Hugging Face Hub 上的数据集。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">感谢 Colab 团队的朋友们，也希望社区的成员们喜欢本次的合作和功能更新！</p></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Hugging Face（gh_504339124f0f）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10316003</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10316003</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 开源调试工具 ixGDB]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-readme-for-ixgdb-release" class="anchor" href="https://gitee.com/deep-spark/ixgdb#readme-for-ixgdb-release"></a>README for ixGDB release</h1><h2><a id="user-content-introduction" class="anchor" href="https://gitee.com/deep-spark/ixgdb#introduction"></a>INTRODUCTION</h2><p>ixGDB is Iluvatar CUDA source-level debugger for Linux OS, based on NVIDIA <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FNVIDIA%2Fcuda-gdb">CUDA-GDB</a> 10.2.</p><p>ixGDB provides the following capabilities:</p><ul><li>Provides a seamless debugging environment that allows simultaneous debugging of both GPU and CPU code within the same application.</li><li>Supports debugging C/C++ applications and all CUDA applications, which might use CUDA driver APIs or CUDA runtime APIs.</li><li>Supports setting breakpoints.</li></ul><h2><a id="user-content-build-instructions-example-only-adjust-as-needed" class="anchor" href="https://gitee.com/deep-spark/ixgdb#build-instructions-example-only-adjust-as-needed"></a>BUILD INSTRUCTIONS (example only, adjust as needed)</h2><p>First, make sure that libtermcap and other required dependent packages are
installed (try "sudo yum install ncurses-devel"). The "configure" command will
report an error if some packages are missing.</p><p>Please note that the libexpat development headers must be present if ixGDB is to be used for cross-platform debugging.</p><p>Issue the following commands to build ixGDB:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./configure --program-prefix=cuda- \</span><span id="LC2" class="line">    --enable-cuda \</span><span id="LC3" class="line">    --enable-targets="x86_64-apple-darwin,x86_64-unknown-linux-gnu,\</span><span id="LC4" class="line">    arm-elf-linux-gnu,m68k-unknown-linux-gnu" \</span><span id="LC5" class="line">    CFLAGS='-I/usr/local/cuda/include' \</span><span id="LC6" class="line">    LDFLAGS='-lpthread'</span><span id="LC7" class="line">make</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-using-ixgdb" class="anchor" href="https://gitee.com/deep-spark/ixgdb#using-ixgdb"></a>USING ixGDB</h2><p>All standard GDB commands could be used for both CPU and GPU code debugging. In addition to that, ixGDB provides CUDA-specific command families like "info cuda ..." to query GPU states, "cuda .." to control debugger focus on GPU and "[get|set] cuda .." to alter/query CUDA debugger configuration. If you want to know more about how to use ixGDB, please go to Iluvatar CoreX support <a href="https://gitee.com/link?target=https%3A%2F%2Fsupport.iluvatar.com%2F%23%2FDocumentCentre%3Fid%3D1%26nameCenter%3D1%26productId%3D">official site</a> and use "ixgdb" as the keyword to find document "SDK Tools User Guide", which includes detailed usage of ixGDB.</p><h2><a id="user-content-communication" class="anchor" href="https://gitee.com/deep-spark/ixgdb#communication"></a>COMMUNICATION</h2><p><a href="https://gitee.com/deep-spark/ixgdb/issues">Gitee Issues</a>: bug reports, feature requests, install issues, usage issues, etc.</p><h2><a id="user-content-license" class="anchor" href="https://gitee.com/deep-spark/ixgdb#license"></a>LICENSE</h2><p>Licensee's use of the GDB third party component is subject to the terms and conditions of GNU GPL v3:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">This product includes copyrighted third-party software licensed under the terms of the GNU General Public License v3 ("GPL v3"). All third-party software packages are copyright by their respective authors.</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Consistent with these licensing requirements, the software listed below is provided under the terms of the specified open source software licenses.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">Component    License</span><span id="LC2" class="line">ixGDB        GPL v3</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/deep-spark/ixgdb</guid>
            <link>https://gitee.com/deep-spark/ixgdb</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 语言大模型的推理技巧]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><img src="https://oscimg.oschina.net/oscnet/7d0eafbb-7a1e-416d-83e4-ac07a8583a4b.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:8px; margin-right:8px"><span>本文探讨了一系列<span style="background-color:#efefef">语言大模型的</span>推理优化技巧，涵盖 KV 缓存、量化和稀疏性等方法，并分享了如何有效实施这些技术。对于想要优化 Transformer 模型，以期提升推理速度或效</span><span>率的人来说</span><span>值得一读。</span></p><p>&nbsp;</p><p><span>本文作者为机器学习研究员 Finbarr Timbers，他曾是 DeepMind 的工程师。</span><span>（本文由 OneFlow 编译发布，转载请联系授权。原文：</span><span>https://www.artfintel.com/p/transformer-inference-tricks）</span></p><p>&nbsp;</p><p><strong><span style="color:#3f3f3f">作者 |&nbsp;</span></strong><strong><span>Finbarr Timbers</span></strong></p><p><strong><span style="color:#3f3f3f">OneFlow 编译</span></strong></p><p><strong><span style="color:#3f3f3f">翻译｜杨婷、宛子琳</span></strong></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">1</span></strong></span></p><span id="OSC_h2_1"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">键值（KV）缓存</span></strong></span></h2><p>&nbsp;</p><p><span>目前，键值（KV）缓存是最常见（也是最重要）的解码器优化方法。在解码器模型中，对于每次解码迭代，提示的键和值将是相同的。此外，一旦你运行了一个词元，该词元的键和值将在后续的每个迭代中保持不变。因此，你可以缓存提示，并在解码时逐渐将每个词元的 KV 张量添加到缓存中，这样可以减少大量计算。在注意力机制中，我们能够将形状为（batch, context_length, feature_dim）的两个张量相乘，变为将形状为（batch, 1, feature_dim）的查询张量与形状为（batch, context_length, feature_dim）的 KV 张量相乘。因此，采样的复杂度不再是二次方，这使我们能够获得更长上下文长度的良好解码（采样）性能。</span></p><p>&nbsp;</p><p><span>实际上，这会在你的实现中增加复杂性，因为现在你不仅仅是运行纯函数，而且有了状态（state），所以即便一个序列已经完成了推理，你仍需要持续运行推理（<span style="color:#888888"><em>参见 Google MaxText 的实现，https://github.com/google/maxtext</em></span>）。</span></p><p>&nbsp;</p><p><span>KV 缓存需要 2 * n_layers * n_heads * d_head 个参数。对于 GPT-3，其中 n_layers = 96，n_heads = 96，d_head = 128，这意味着每个上下文中的词元需要 2.4m 个参数。使用典型的 16 位精度，每个词元需要 5MB；如果上下文窗口有 2048 个词元，那就需要将 10GB 的 HBM 用于 KV 缓存。这虽然昂贵，但每 GB 的消耗都物有所值。</span></p><p>&nbsp;</p><p><span>这些内存需求是在消费级 GPU 上训练语言大模型如此困难的重要原因之一。目前最强大的消费级显卡是 4090，只有 24GB 的 HBM。虽然其每秒浮点运算次数（FLOPS）可与企业级芯片相媲美，但其内存限制要低得多，这使得难以将权重和 KV 缓存置入内存。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">2</span></strong></span></p><span id="OSC_h2_2"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">推测性解码</span></strong></span></h2><p>&nbsp;</p><p><span>推测性解码是一种在计算能力充裕时使用的技术，通常用于本地推理设置。它利用了现代加速器的特性，即在批次数据上运行推理所需的时间与在单个数据点上运行推理的时间相同。以 A100 为例，你可以在相同的时间内对多达 160 个数据点进行推理，所需推理时间与单个数据点相同。因此，现在已经出现了许多利用这一特性的技术，如束搜索（beam search）、MCTS（蒙特卡洛树搜索）或推测性解码。</span></p><p>&nbsp;</p><p><span>推测性解码包括两个模型：一个小而快的模型以及大而慢的模型。由于现代解码器的推理速度与参数数量成正比，使用较小的模型可以在大型模型运行一次推理所需的时间内运行多次推理。</span></p><p>&nbsp;</p><p><span>现代解码器模型（如 GPT 系列）使用了自回归采样技术，即要对 N 个词元的序列进行采样，模型会进行 N 次推理，每次推理都要使用前一次推理的结果。</span></p><p>&nbsp;</p><p><span>在推测性解码中，你会并行运行这两个模型。快速模型会运行一批推理并猜测大模型将预测哪些词元，然后将这些猜测相叠加。与此同时，大模型在后台运行，检查较小模型是否记录了相同结果。较小模型能够在大模型进行一次推理的时间内进行多次猜测。然而，鉴于我们有多余的计算能力，大模型能够并行评估所有猜测。因此，我们支付顺序生成序列成本的唯一地方是在较小的模型上。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/59e12167-b54f-4b1c-bcb5-4479facca980.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>推测性解码的主要缺点是它需要一个「草稿（draft）」模型，该模型能够预测较大模型的输出，而且你必须让两个模型同时存在于同一台机器的内存中（或者在多 GPU 设置下的同一节点上）。这增加了复杂性，需要额外的工作，因为你必须训练两个模型（原始模型和「草稿」模型）。此外，任何性能提升都受限于小模型能够在多大程度上精确地预测大模型。如果小模型始终能够准确预测大模型的行为，那么我们就可以直接使用它！因此，推测性解码能够发挥作用的程度存在根本差距。HuggingFace 声称它通常可以将解码速率提高一倍，这与原始论文（<span style="color:#888888"><em>https://arxiv.org/abs/2211.17192</em></span>）中声称的 2 至 3 倍的提升一致。</span></p><p>&nbsp;</p><p><span>最近出现了一种试图改进推测性解码的前向解码（Lookahead Decoding）技术（<span style="color:#888888"><em>https://lmsys.org/blog/2023-11-21-lookahead-decoding/</em></span>），该技术让模型生成 n-gram，然后在无需草稿模型的情况下递归匹配这些 n-gram。这种技术被称为 Jacobi 解码（来自他们的博客截图），可能是对贪婪解码的潜在改进。Jacobi 解码的工作原理是在生成词元的每一点上生成 n 个词元，对整个序列进行「猜测」。然后，将其与先前的猜测相验证，如果两者匹配，就接受该猜测。这可以在没有副作用的情况下减少时延，因为在最坏的情况下，它会变成贪婪解码。</span></p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/d545a2df-0729-4b32-a7dc-390784598002.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>前向解码通过保留解码过程中生成的 n-gram，并尝试将它们用作猜测，进一步改进了这一技术。鉴于已生成的文本与将要生成的文本之间存在很高的相关性，这也有可能以极低的成本，显著改进时延。这一技巧非常巧妙。考虑到这项技术才发布不久，我非常好奇它在实际场景中的性能表现。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/cdf7da2f-7ac8-475c-90ff-a2baacf4b4c3.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">3</span></strong></span></p><span id="OSC_h2_3"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">有效稀疏性</span></strong></span></h2><p>&nbsp;</p><p><span>在仅解码器 Transformer 中，模型核心是注意力机制，可总结为如下的注意力方程：</span></p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/51f1f3da-d1e8-4cff-b3c2-b1f2f9a7af30.png" referrerpolicy="no-referrer"></p><p><span>softmax 操作会使非最大值变得很小。</span></p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/a66d9144-d636-4c8e-a891-8a79045d5e40.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="text-align:left"><span>因此，我们将数值张量（在注意力方程中用 V 表示）与一个主要由零（zero）组成的张量相乘。结果，注意力机制的输出中包含了大量的零，最高可达 97%（<span style="color:#888888"><em>https://x.com/YesThisIsLion/status/1647747069086666752?s=20）</em></span>。类似地，在多层感知器网络（MLP）中的每个 ReLU 之后，我们也得到了大量稀疏性。</span></p><p>&nbsp;</p><p><span>不幸的是，现在要实际利用这一点比较困难。如果权重中存在稀疏性，那么可通过结构化稀疏性（例如</span><span>tor<span>‍</span>ch.sparse</span><span>）做大量工作，但目前还不清楚系统能够多大程度地利用激活的稀疏性。</span></p><p>&nbsp;</p><p><span>可以进行的一个优化是：如果某个激活为零，那么可以跳过加载与该激活对应的权重，并避免相应计算。据我所知，这并未很好地得到主流张量计算程序的支持，但对于</span><span>Llama.cpp</span><span>等自定义推理实现来说，这一优化比较容易实现。</span></p><p>&nbsp;</p><p><span>这是因为激活是每个词元的函数，因此有效稀疏性也是随机分布在词元上。因此，这种优化的效果会随着批大小的增加呈指数级衰减。假设我们的有效稀疏性为 X%，批大小为 N，那么对于一个给定激活的所有条目在整个批次中都为零的概率可以表示为 X^N。我制作了一张表格，列出了不同 X 和 N 值的情况。这种衰减效应非常显著。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/a82589c0-f80d-4a43-aab4-348ae7b1f293.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>因此，除批大小为 1 的情况，利用这一方法十分困难，即使在这种情况下，使用推测性解码通常更为有效。但如果你想要在本地运行推理，并且确实需要降低时延，这可能是一个很棒的技巧。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">4</span></strong></span></p><span id="OSC_h2_4"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">量化</span></strong></span></h2><p>&nbsp;</p><p><span>量化是人们更为熟悉的技巧之一。我之前已经写过量化的相关内容 (<span style="color:#888888"><em>https://finbarrtimbers.substack.com/p/efficient-llm-inference</em></span>），所以不打算在具体方法上花费太多时间。我们很难精确度量量化的效果。GPTQ 论文等文献所使用的模型与 SOTA 模型差距较大，因为大型实验室并未公开其所使用的模型，并且学术界无法与大型实验室所拥有的资源相匹敌。</span></p><p>&nbsp;</p><p><img src="https://oscimg.oschina.net/oscnet/1bcc4196-002b-475d-a149-812f9b6e70b7.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>例如，GPTQ 报告了 OPT 和 BLOOM 模型的量化结果，这些结果远不如当前的一系列开源模型，更不用说 GPT-4 了。</span></p><p>&nbsp;</p><p><span>当然，大型实验室并未公开其研究进展，而我看到的大部分个案报告都来自那些试图在消费级硬件上运行较小模型的人，这种硬件的内存非常有限。我认为，很多业余爱好者（即非大型实验室研究人员）都被在本地运行庞大模型的吸引力所诱惑，因此他们对量化产生了浓厚兴趣。但实际上，量化并不具备固有优势！从第一性原则出发，如果你有两个位数相同的模型，它们应该具有相同数量的词元/秒，并且应该具有类似的性能水平。只有在使用更高精度格式的位数时做得很糟，才会有较大差异。</span></p><p>&nbsp;</p><p><span>但文献中的观点与我的直觉不一致。上述 GPTQ 论文发现，将模型量化为低至 4 倍的精度时，性能的下降微乎其微。我认为，这是因为性能更差的模型更容易在量化过程中保持其性能不受损。如果假设两个相同的 LLM，一个经过 2 万亿词元的训练，另一个经过 5000 亿词元的训练（分别称为 LLM-2T、LLM-500B），在进行量化时，我认为经过更多词元训练的模型在性能上受到的影响更大，因为它应该更充分地利用这些词元。我们仍然预计经过量化的 LLM-2T 会优于 LLM-500B，但我认为从 LLM-2T 到经过量化的 LLM-2T 的性能下降，会比从 LLM-500B 到经过量化的 LLM-500B 的下降更显著。</span></p><p>&nbsp;</p><p><span>注：虽然上述论点很有说服力，但实际上并没有相关的文献支持。量化似乎确实非常接近于「免费的午餐」。</span></p><p>&nbsp;</p><p style="text-align:left"><span>近期的研究，如关于 k-bit 推理规模定律的论文（<span style="color:#888888"><em>https://arxiv.org/abs/2212.09720</em></span>），在一系列 LLM 架构上进行了大量实验，得出了不同的位数分配对模型性能的影响。他们研究了在给定精度水平下使用 N 个参数的模型与使用 2N 个参数和一半精度的模型之间的权衡。其结果非常引人注目，与未进行量化的性能几乎没有差别（至少对于 4 位或更多位而言）。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/e695f055-912b-4be6-99bf-e046a7191224.png" referrerpolicy="no-referrer"></p><p><span>基本上，他们发现可以将精度降至 4 位而不损失任何性能，量化几乎不会导致任何权衡。你可以运行一个小 4 倍的模型而不会显著降低性能。由于在现代加速器上推理性能等于处理的位数（即使用较少精度时每秒可以获得更多的运算次数），这点很有帮助。</span></p><p>&nbsp;</p><p><span>因此，我的结论是：推荐采纳「k-bit 推理论文」的建议。然而，对于生产负载，我对使用低于 8 位的精度还有些犹豫。fp8 是目前现代加速器本地支持的最低精度浮点格式，即使如此，支持也是有限的。我建议在 fp8 精度下进行训练和推理，并观察进一步量化可能带来的精度损失对你的用例来说是否可以接受。当生产环境中缺乏来自这些平台（例如 Nvidia 和 Torch/JAX 团队）的本地支持时，我很难推荐在生产环境中使用更低级别的精度。</span></p><p>&nbsp;</p><p><span>根据我从文献中了解到的（这与我的直觉相符），fp8 严格来说优于 int8，但在硬件上的支持有限。如果你在一个 GPU 资源充沛的组织，并且能够将 H100 用于所有任务，那么请使用 fp8。否则，也可以使用 int8，而且相比起来要容易得多（PyTorch 使其变得相当容易，尽管 API 不太稳定）。</span></p><p>&nbsp;</p><p><span>关于实际进行模型量化，PyTorch 团队已经撰写了一篇关于如何具体操作的文章（<span style="color:#888888"><em>https://pytorch.org/blog/accelerating-generative-ai/</em></span>），并提供了一系列 API 用于简化操作，尽管它们不太稳定。此外，bitsandbytes 是另一个出色的量化库，不过我个人还未使用过。</span></p><p>&nbsp;</p><p><span>（特别感谢@cis_female 与我讨论稀疏性的复杂性，以及@nostalgebraist 纠正量化部分中的错误。我现在认为，证据表明，至少量化到 4 位或更多位，在性能方面的权衡非常小。）</span></p><p>&nbsp;</p><p>&nbsp;</p><span id="OSC_h2_5"></span><h2 style="margin-left:8px; margin-right:8px; text-align:left">&nbsp;</h2><p><span style="background-color:#ffffff; color:#888888">其他人都在看</span></p><span id="OSC_h3_6"></span><h3 style="text-align:left">&nbsp;</h3><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491309%26idx%3D1%26sn%3D407fefb7ec76a2c9fdfe1ae960f7de4d%26chksm%3Dfe4190dbc93619cd0b9bfecb979e142a125fd8548d323dd9bdc2cbeb619400202e6e1affced0%26scene%3D21%23wechat_redirect" target="_blank">大型语言模型的推理演算</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493088%26idx%3D1%26sn%3Dff319e3b8cc19f165232c3226779588c%26chksm%3Dfe426bd6c935e2c0946fdaa96378d04123f31eb797e39c8ab0d619bbb00db8b665354a167583%26scene%3D21%23wechat_redirect" target="_blank">LoRA 微调语言大模型的实用技巧</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492976%26idx%3D1%26sn%3Dd919a508ce238048ae44e58b9cc06b71%26chksm%3Dfe426b46c935e2500178c2d2c8845fcd3e47fdeb5ec51f55b80cbca5f7b78382cdb3e6fe6a32%26scene%3D21%23wechat_redirect" target="_blank">可复现的语言大模型推理性能指标</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492990%26idx%3D1%26sn%3D50844c8911834baf44863a9e3754175f%26chksm%3Dfe426b48c935e25ede3f772624ba262011b1b48f8ee78ac6d3b1daa5aaf71e7583828740b5cd%26scene%3D21%23wechat_redirect" target="_blank">ChatGPT 规模化服务的经验与教训</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493053%26idx%3D1%26sn%3Dfe7a51fbda920626b55d8919dd780e05%26chksm%3Dfe426b8bc935e29d3a806dfd6682619ee46effa39b09777907d5bccfd80d8cd639580c6f6e23%26scene%3D21%23wechat_redirect" target="_blank">机器学习硬件十年：性能变迁与趋势</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492951%26idx%3D1%26sn%3D873b7c63ea18d638a9570bb582cddbb5%26chksm%3Dfe426b61c935e277e17fd2d4b06fa3ec998479ae87d84312f064dbae0e65875a7cb45829807d%26scene%3D21%23wechat_redirect" target="_blank">微调语言大模型选 LoRA 还是全参数？</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492811%26idx%3D1%26sn%3D916e330a2a4152dab3192635c3e475fa%26chksm%3Dfe426afdc935e3eb2f371ff5f56247c95800ce91a950a89bea871c26ddc4c3d13371acf03978%26scene%3D21%23wechat_redirect" target="_blank">语言大模型推理性能工程：最佳实践</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493030%26idx%3D1%26sn%3D58a43ed078977019c997a110526d7c02%26chksm%3Dfe426b90c935e28688b6e317a991bedaaa164471a275d64e60851a09b00f7f6b718e27d7b411%26scene%3D21%23wechat_redirect" target="_blank">语言大模型的分布式训练与高效微调指南</a></p></li></ul><span id="OSC_h3_7"></span><h3 style="text-align:left">&nbsp;</h3><p><strong><span>试用 OneFlow: <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank">github.com/Oneflow-Inc/oneflow/</a></span></strong></p><p style="color:#3f3f3f; margin-left:8px; margin-right:8px; text-align:left"><img src="https://oscimg.oschina.net/oscnet/f2b38f8c-5887-4315-9787-03816b68ada4.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公众号 - OneFlow（OneFlowTechnology）。<br> 如有侵权，请联系 support@oschina.cn 删除。<br> 本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 01:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10320747</guid>
            <link>https://my.oschina.net/oneflow/blog/10320747</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源 MoE 模型 Mixtral 8x7B 性能超过 GPT-3.5]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>大模型创业公司 Mistral AI 终于<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-of-experts%2F" target="_blank">介绍了</a></u>前两天「开源」的&nbsp;MoE 模型 <strong>Mixtral 8x7B</strong>。</p><blockquote><p><strong><em><u><a href="https://www.oschina.net/news/270317/mixtral-8x7b-32kseqlen">Mistral AI 用「磁链链接」开源了 87 GB 的 8x7B MoE 模型</a></u></em></strong></p></blockquote><p>官方称，Mixtral 8x7B 是开放权重的高质量<strong>稀疏混合专家模型 (SMoE)</strong>，采用 Apache 2.0 License 开源。在大多数基准测试中，Mixtral 的成绩都优于 Llama 2-70B，且推理速度提升了 6 倍。而且在大多数标准基准测试中超过 GPT-3.5。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7a689c4f538b591b9744038a052717945e6.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-84fefd9ee6c091c07c894031a1af2faf2e3.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f9aaad324856028fb1e796beb2d7685020.png" referrerpolicy="no-referrer"></p><p>因此，Mistral AI 称 Mixtral 是最强大的开放权重模型，也是成本/性能权衡方面的最佳模型。</p><p><strong>Mixtral 主要特性</strong></p><p>• 32k 上下文<br> • 支持英语、法语、意大利语、德语和西班牙语<br> • 性能超过 Llama 2 系列和 GPT-3.5<br> • 在代码生成方面具有强劲性能<br> • 在 MT-Bench 上获得 8.3 分</p><p>Mixtral 作为稀疏混合专家网络，是一个纯解码器模型，其中前馈块从 8 组不同的参数组中选择。在每一层，对于每个 token，路由网络选择两组「专家」来处理 token 并相加地结合它们的输出。</p><p>Mixtral 总共有 45B 个参数，但每个 token 只使用 12B 个参数。因此，它以与 12B 模型相同的速度和成本处理输入和生成输出。</p><p>更多细节查看：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-of-experts%2F" target="_blank">https://mistral.ai/news/mixtral-of-experts/</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 10:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270511/mixtral-of-experts</guid>
            <link>https://www.oschina.net/news/270511/mixtral-of-experts</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[荣耀申请魔方大模型商标]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">天眼查信息显示，荣耀终端有限公司近日申请注册「荣耀魔方大模型」商标，国际分类为网站服务，当前商标状态为等待实质审查。</span></p><p><img height="275" src="https://oscimg.oschina.net/oscnet/up-7baf34d7d00360b976559630121d67b0da4.png" width="700" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#222222">此前，该公司曾申请两枚「MAGIC&nbsp;大模型」商标。荣耀 CEO 赵明曾发文称，荣耀即将推出自研端侧 AI 大模型和全新云服务。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 08:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270492</guid>
            <link>https://www.oschina.net/news/270492</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[HashiCorp 采用 BSL 后续，Linux 基金会孵化 Vault 开源替代品]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">今年 8 月，<span style="background-color:#ffffff">专注于云基础设施的软件供应商 HashiCorp&nbsp;</span>宣布<span style="background-color:#ffffff">修改其核心产品的开源协议。</span><strong style="color:#333333">所有 HashiCorp 产品的未来版本</strong><span style="background-color:#ffffff">将从 Mozilla Public License v2.0 (MPL 2.0) 变更为&nbsp;</span><strong style="color:#333333">Business Source License (BSL, also known as BUSL) v1.1</strong><span style="background-color:#ffffff">，其中包括&nbsp;Vault、Boundary、Consul、Nomad、Packer、Terraform、Vagrant 和 Waypoint 等。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">采用 BSL 1.1 的项目，其代码仍会公开 (source-available)，</span><strong style="color:#333333">但只允许在特定条件下进行复制、修改、重新分发、非商业使用和商业使用</strong><span style="background-color:#ffffff">&nbsp;—— 主要是添加了商业使用方面的限制。</span></span></p><p><span style="color:#000000">此后，社区在抗议无效后选择创建了 Terraform 的分支项目 OpenTofu（原名 OpenTF），并托管在了 Linux 基金会下。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">时至今日，有消息称 Linux 基金会正计划帮助孵化一个私密信息管理工具 Vault 的开源替代品。DevOps 自动化公司 Scalr 的联合创始人兼首席执行官 Sebastian Stadil 和 OpenTofu 的组织者之一<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F12%2F08%2Fhashicorp_openbao_fork%2F" target="_blank">透露</a>，Vault 开源替代品的项目名为 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.lfedge.org%2Fdisplay%2FOH%2FOpenBao%2B%2528Hashicorp%2BVault%2BFork%2Beffort%2529%2BFAQ" target="_blank">OpenBao</a>，是竞争对手在 MPL 2.0 协议下创建的一个&nbsp;Vault 分支。</span></span></p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-1f318fa9f93212c7ed6a67c0b91e135c731.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><span style="background-color:#ffffff">OpenTofu 计划在本月晚些时候发布候选版本，OpenBao 也将开始接受新的贡献。Stadil 表示，「如果有两个相同的项目，一个是开源的，一个不是，我个人认为，道德上的选择是使用开源项目，并以某种方式提供帮助。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">不过鉴于 OpenTofu 和 OpenBao 都是新近开发的项目，项目的可行性和持久性受到了很多关注。针对这一担忧，Stadil 表示拒绝代表其他公司发言。事实上，他还被告知不要透露任何关于其他组织支持这些项目的消息。对于那些想要了解更多详情的人，他建议可以访问项目的 repos。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">当被问及 HashiCorp 重新授权其软件的理由时，Stadil 回答称，官方的说法是 Terraform 对互联网至关重要，而长期以来人们一直希望将其置于 Linux 基金会的监督之下。「如果 HashiCorp 将来愿意加入我们的 OpenTofu，我们会很乐见其成」。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">但</span><span style="background-color:#ffffff">他无法推测 HashiCorp 的内部决策过程。Stadil 指出，Hashicorp 一直在烧钱，随着利率的上升，这家软件公司选择采取措施创造更多收入也不足为奇。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">上周，HashiCorp 公布了 2024 财年第三财季的营收报告。营收 1.461 亿美元，同比增长 17%。按照美国通用会计准则（GAAP），净亏损为 3950 万美元，低于去年同期的 7200 万美元。</span></span></p><p><strong><span style="color:#000000"><span style="background-color:#ffffff">相关阅读：</span></span></strong></p><ul><li><a href="https://www.oschina.net/news/253275/hashicorp-adopts-business-source-license" target="_blank">HashiCorp 核心产品变更开源协议，未来将采用 BSL</a></li><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/255700/opentf-fork-terraform" target="_blank">HashiCorp 采用 BSL 后，社区创建 Terraform 分支 OpenTF</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 07:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270477/hashicorp-vault-openbao-fork</guid>
            <link>https://www.oschina.net/news/270477/hashicorp-vault-openbao-fork</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[周热点 | Linus 收敛火爆脾气，谈内核社区「老龄化」问题；Firefox 或将被淘汰；谷歌发布最强 AI 模型 Gemini............]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2023.12.04-2023.12.10]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 06:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094041&#38;idx=1&#38;sn=18ed1a99fdf7fbbbc52688a346795664&#38;chksm=880c4c8abf7bc59cbaf66865402e963af1309b4bb627cd89ae402f319f12ce5c56561126ea09&#38;token=1220110296&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094041&#38;idx=1&#38;sn=18ed1a99fdf7fbbbc52688a346795664&#38;chksm=880c4c8abf7bc59cbaf66865402e963af1309b4bb627cd89ae402f319f12ce5c56561126ea09&#38;token=1220110296&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[GitHub.com 跑了 1200 多台 MySQL 主机，如何无缝升级到 8.0？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GitHub 团队近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-07-upgrading-github-com-to-mysql-8-0%2F" target="_blank">分享</a></u>了他们将 GitHub.com 的底层数据库无缝升级到 MySQL 8.0 的经验。</p><p>据介绍，GitHub 使用 MySQL 来存储大量关系数据，因此在不影响网站服务级别目标 (SLO) 的情况下升级主机集群（<strong>1200 多台 MySQL 主机</strong>）绝非易事。其团队表示，为了升级到 MySQL 8.0，他们规划、测试和升级本身总共花费了一年多的时间，并且需要 GitHub 内部多个团队的协作。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-613c88c0257637ef029cdd9528c6f8a3217.png" referrerpolicy="no-referrer"></p><p><strong>GitHub 的 MySQL 基础设施概览：</strong></p><ul><li>由 1200 多台主机组成，包括数据中心中的<strong> Azure 虚拟机和裸机主机</strong></li><li>存储超过 300 TB 的数据，并在 50 多个数据库集群中每秒处理 550 万次查询</li><li>每个集群都配置为具有主副设置的高可用性</li><li>分区存储数据——利用水平和垂直分片来扩展 MySQL 集群，以及使用 MySQL 集群来存储特定产品领域的数据。此外还为大结构域 (large-domain) 提供了水平分片的 Vitess 集群，这些区域的增长超出了单主 MySQL 集群的规模</li><li>庞大的工具生态，包括 Percona Toolkit、gh-ost、orchestrator、freno 和用于操作主机集群的内部自动化工具</li></ul><p>由于需要操作两个版本的 MySQL，因此 GitHub 内部使用的工具和自动化设施需要能够兼容处理混合版本，并了解 5.7 和 8.0 之间<strong>新的、不同的或已弃用的语法</strong>。</p><p>为了满足可用性标准，GitHub 团队采取了逐步升级策略，满足在整个过程中进行 checkpoint 和回滚的需求。下面是他们制定的升级计划：</p><ul><li><strong>步骤 1：升级滚动副本 (rolling replica)</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9d574db1e2fec9bf7da0d7c92091b0fb19.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步骤 2：升级备份拓扑 (replication topology)</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-305231a10282f80062ca4f1d665c36305ee.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步骤 3：将 MySQL 8.0 主机提升为主集群</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e9f6defe7e920b0167c797000292c7e390.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步骤 4：升级面向内部的实例类型</strong></li><li><strong>步骤 5：清理，</strong>确认集群不需要回滚并成功升级到 MySQL 8.0 后，删除 5.7 服务器。验证工作会至少经历一个完整的 24 小时流量周期，以确保在高峰流量期间不会出现问题。</li></ul><p>至于为什么要升级到 MySQL 8.0，GitHub 团队表示主要是因为 MySQL 5.7 的生命周期即将结束。此外升级后可以获得最新安全补丁、错误修复和性能增强的 MySQL 版本。他们还希望测试 8.0 中的新功能并从中受益，包括即时 DDL、隐形索引和压缩的 bin 日志等。</p><p>详细的技术细节查看：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-07-upgrading-github-com-to-mysql-8-0%2F" target="_blank">https://github.blog/2023-12-07-upgrading-github-com-to-mysql-8-0/</a></u></em></p><hr><p>延伸阅读</p><ul><li><u><a href="https://www.oschina.net/news/188164/github-recent-service-disruptions">GitHub 解释近期频繁宕机原因：MySQL 不堪重负</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 05:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0</guid>
            <link>https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TIOBE 12 月：C# 有望成为年度编程语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">TIOBE 公布了 2023&nbsp;年 12 月的</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">编程语言排行榜</a><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">。</span></span></p><p><img height="77" src="https://oscimg.oschina.net/oscnet/up-e944f70ee629593d3b3ba2ac7d008e89e4b.png" width="700" referrerpolicy="no-referrer"></p><p>2023 年度 TIOBE 编程语言名单即将出炉，其中最有望胜出的当属&nbsp;C#。事实上，早在 2022 年&nbsp;C# 就有望夺得该桂冠，但却在最后时刻被&nbsp;C++ 反超。而在今年，C# 的胜率又多出了几分；因为该语言在一年内的增长率为 +2.38%，与其最接近的竞争者 Fortran 和 F# 的增长率则仅分别上涨了 +0.64% 和 +0.48%。</p><p>此外，Top 20 中的大部分语言人气都出现了下降。<span style="background-color:#ffffff; color:#000000">TIOBE CEO&nbsp;Paul Jansen 评论称，</span>「答案就在所有小语言所在的长尾（long tail）部分。这些语言的受欢迎程度都在上升，而且越来越接近大语言」。例如：一年前，排名第 50 位的语言得分仅为 0.14%，但现在第 50 位语言的得分已经达到了 0.24%。</p><p><strong style="color:#333333">TIOBE 12 月 TOP 20 编程语言</strong></p><p><img height="414" src="https://oscimg.oschina.net/oscnet/up-b25283a71bbac81145079c4b2848ccc6e95.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">相较上月，除了 Ruby<span>&nbsp;</span>(18→19)、R (19→20) 以及 Rust (20→18) 之间出现了小范围波动外，Top&nbsp;10-20 榜单没有其他任何排名变化，这也是近期以来榜单变动最小的一次。</span></p><p><strong style="color:#333333">TOP 10 编程语言 TIOBE 指数走势（2002-2024）</strong></p><p><img height="228" src="https://oscimg.oschina.net/oscnet/up-c048f61fdb18f5fa94fbc07b575f6acc8f9.png" width="700" referrerpolicy="no-referrer"></p><p><strong style="color:#333333">第 21-50 名编程语言排行</strong></p><p><img height="430" src="https://oscimg.oschina.net/oscnet/up-e1c00e5bc23507475a73c563cbdb213cdc9.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">第 51-100 名如下，由于它们之间的数值差异较小，仅以文本形式列出（按字母排序）：</span></p><p>&nbsp;</p><blockquote><p>4th Dimension/4D, ABC, Algol, Apex, ATLAS, AutoLISP, Bash, Boo, Carbon, CIL, CL (OS/400), Clipper, Clojure, Curl, Eiffel, Elm, Erlang, GAMS, Groovy, Icon, Inform, Io, J#, LabVIEW, Ladder Logic, LiveCode, Maple, Modula-2, MOO, MQL5, NATURAL, Nim, OCaml, OpenEdge ABL, PostScript, Pure Data, Q, Racket, Ring, RPG, Smalltalk, Snap!, Solidity, SPARK, SPSS, Tcl, VHDL, Wolfram, X10, Zig</p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">TIOBE 编程社区指数（The TIOBE Programming Community index）是一个衡量编程语言受欢迎程度的指标，该指数每月更新一次。评判的依据来自世界范围内的工程师、课程和第三方供应商，包括流行的搜索引擎，如 Google、必应、雅虎、维基百科、亚马逊、YouTube 和百度都被用于指数计算。值得注意的是，TIOBE 指数并不代表编程语言的好坏或编写代码的多少。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">该指数可以用来检查你的编程技能是否还能跟上时代的步伐，或者在开始建立一个新的软件系统时，基于指数对采用何种编程语言做出决策。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F" target="_blank">TIOBE 指数</a><span style="color:#000000">的定义方式，以及详细榜单信息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">均可查看官网</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 03:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270438/tiobe-index-2023012</guid>
            <link>https://www.oschina.net/news/270438/tiobe-index-2023012</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[因 EXT4 数据损坏错误，Debian 12.3 推迟发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Debian 团队发布公告称，由于 Linux 内核 6.1.64-1 中的<strong> ext4 文件系统出现数据损坏问题</strong>，因此原计划昨天发布的 Debian 12.3 将会被推迟，同时进行修复。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-6b960c796ab8ff358469f03578c81866ec1.png" referrerpolicy="no-referrer"></p><p>来源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.debian.org%2FNews%2F2023%2F2023120902" target="_blank">https://www.debian.org/News/2023/2023120902</a></u></p></blockquote><p>据介绍，此 bug 由从 Linux 6.5 回溯的一个有问题补丁导致，它引起了 EXT4 和 iomap 代码之间的干扰，可能导致旧内核上的数据损坏。</p><p>这个问题主要出现在最近的 Linux 6.1 LTS 点版本中，新的 Linux 6.1.66 版本已经回滚了有问题的提交。Debian 的 bug 报告称这个问题为「非严重的数据丢失」，因此应该是可以恢复的。</p><p>但由于 Debian 12.3 原本计划发布的内核版本受到了影响，因此被推迟发布。建议 Debian 12 用户在 Linux 6.1.66 内核镜像推出之前不要升级系统。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 03:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270435/debian-12-3-delayed-ext4-corrupt</guid>
            <link>https://www.oschina.net/news/270435/debian-12-3-delayed-ext4-corrupt</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
