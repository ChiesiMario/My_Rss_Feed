<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 27 Feb 2024 14:22:08 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[墨干理工套件 V1.2.5 LTS 发布了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(255, 255, 245, 0.86); margin-left:0; margin-right:0; text-align:start">墨干理工套件 V1.2.5LTS<span>本次更新主要是修复既有错误、改进用户体验。</span></p><blockquote><p style="color:var(--vp-c-text-2); margin-left:0; margin-right:0">注意：一个重大的变更是默认开启了实验选项<code>DO NOT use UTF-8 for CJK in TM format</code>，保持和 GNU TeXmacs 2.1.2 的兼容性。之前在墨干 V1.1.x 使用了 TM 格式中显示中文特性的用户，可以关闭这个选项以正确加载墨干 V1.1.x 生成的可以在纯文本编辑器中正常显示中文的文档。v1.1.x 的在 tm 文档中显示中文的特性可能会带来一些严重的兼容性问题，故而不建议用户使用可以在纯文本编辑器中正常显示中文的 TM 文档。从墨干 V1.2.6 开始，我们会实验性地支持 TMU 格式以 UTF-8 编码显示中文。TMU 格式经过多个版本迭代，最终才会对所有用户开放。</p></blockquote><p>墨干理工套件 V1.2.5 LTS 包含以下组件：</p><ul><li>墨干 V1.2.5LTS (Mogan Research v1.2.5 LTS)</li></ul><p>墨干 V1.2.5 LTS 这个版本标志着墨干作为 GNU TeXmacs 的一个发行版，基本完成了从 Qt 4 到 Qt 6 的升级，从 GNU Guile 1.8 到 S7 Scheme 的执行引擎切换，从 Autotools 到 xmake 的构建工具切换等重要的基础设施的建设。在这个坚实的基础上，从 V1.2.0 开始，我们以一月一版本的愉快的高强度研发迭代下，大大改善了墨干的可用性和易用性。</p><p>墨干 V1.2.5 LTS 是为期至少一年的长期支持版，其目的是服务教育工作者。一年的长期支持，是为了覆盖 2024 年的春季学期和秋季学期。欢迎教育工作者们使用墨干制作试卷、幻灯片、讲义以及撰写书籍。在未来的一个月内，我们会发布 V1.2.5.1，以修复 V1.2.5 中仍旧存在的错误。后续的补丁版本会按需发布，欢迎教育工作者们使用墨干并反馈错误。</p><p>墨干 V1.2.5 LTS 保留了对 Qt 5 的支持，这是为了以一种比较低的维护成本为老旧系统提供构建墨干的可行性：比如 Windows 7，macOS 10.x，龙芯生态的旧世界。</p><p>从墨干 V1.2.6 开始，我们移除了对 Qt 5 的支持，轻装上阵；另外，我们也会放慢研发迭代的节奏，每两个月发布一个版本，作为 TeXmacs 发行版中的先行者，稳步迭代进化。</p><h2>影响用户体验的详细更新<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmogan.app%2Fzh%2Fguide%2FChangeLog_v1.2.5.html%23%25E5%25BD%25B1%25E5%2593%258D%25E7%2594%25A8%25E6%2588%25B7%25E4%25BD%2593%25E9%25AA%258C%25E7%259A%2584%25E8%25AF%25A6%25E7%25BB%2586%25E6%259B%25B4%25E6%2596%25B0" target="_blank">​</a></h2><ul><li>安装包 
  <ul><li>提供 Ubuntu 20.04 的 deb 安装包</li><li>提供 Debian 12 (bookworm) 的 deb 安装包</li><li>提供 Windows 平台的便携版安装包</li></ul></li><li>幻灯片模式 
  <ul><li>修复在 macOS 平台切换幻灯片主题无法切换幻灯片背景图的问题</li></ul></li><li>快捷键 
  <ul><li>macOS：Command 和+/-的组合无论是否按下 Shift 都可以放大或者缩小</li><li>修复未知快捷键被作为文本插入到文档中的问题</li></ul></li><li>用户界面 
  <ul><li>修复在 macOS 平台双击打开含有中文字符的文件失败的问题</li></ul></li><li>排版引擎 
  <ul><li>修复在文档中删除内容出现残影的问题</li><li>修复在幻灯片设置部分内容为双栏时出错的问题</li><li>number 原语支持汉字的数字：一、二、三等</li></ul></li><li>性能优化 
  <ul><li>改进解析 TeXmacs 文档的性能</li><li>改进渲染 Pine 幻灯片主题的性能</li></ul></li><li>PDF 导入 
  <ul><li>新增<code>文件-&gt;导入-&gt;可编辑 PDF</code>用于导入可编辑 PDF，而不是直接使用<code>文件-&gt;打开</code>来打开可编辑 PDF</li></ul></li><li>版本控制 
  <ul><li>修复在 Windows 平台进入<code>版本-&gt;历史</code>之后，无法查看文档历史版本的问题</li></ul></li><li>图像插件 
  <ul><li>改进对 Postscript 图像格式的支持（需要用户手动安装 Ghostscript）</li><li>改进对 SVG 图像格式的支持（需要用户手动安装 Inkscape）</li></ul></li><li>会话插件 
  <ul><li>改进 Scheme 会话中中文变量名、中文字符串的支持</li></ul></li><li>代码插件 
  <ul><li>重新添加了 Python 的代码高亮</li></ul></li></ul><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 12:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280535/mogan-1-2-5-released</guid>
            <link>https://www.oschina.net/news/280535/mogan-1-2-5-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[aiohttp < 3.9.2 路径遍历漏洞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>漏洞描述</h2><p>aiohttp 是一个开源的用于 asyncio 和 Python 的异步 HTTP 客户端/服务器框架。</p><p>当使用 aiohttp 作为 Web 服务器并设置静态路由时，若 follow_symlinks 选项设为 True，则不会验证指定文件路径是否位于根目录内。攻击者可以通过构造恶意的请求，访问服务器任意文件。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fray-project%2Fray%EF%BC%88ray" target="_blank">https://github.com/ray-project/ray（ray</a> dashboard）等多个项目中并未正确配置该参数，也会受到漏洞影响。</p><table><tbody><tr><th>漏洞名称</th><th>aiohttp &lt; 3.9.2 路径遍历漏洞</th></tr></tbody><tbody><tr><td>漏洞类型</td><td>路径遍历</td></tr><tr><td>发现时间</td><td>2024-01-30</td></tr><tr><td>漏洞影响广度</td><td>广</td></tr><tr><td>MPS 编号</td><td>MPS-rxvm-9042</td></tr><tr><td>CVE 编号</td><td>CVE-2024-23334</td></tr><tr><td>CNVD 编号</td><td>-</td></tr></tbody></table><h2>影响范围</h2><p>aiohttp@[1.0.5, 3.9.2)</p><p>python-aiohttp@影响所有版本</p><p>aiohttp@[1.0.5, 3.9.2)</p><h2>修复方案</h2><p>将 aiohttp 升级至 3.9.2 及以上版本</p><p>如果应用程序的静态资源服务不需要符号链接功能，将 follow_symlinks 设置为 False</p><h2>参考链接</h2><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oscs1024.com%2Fhd%2FMPS-rxvm-9042" target="_blank">https://www.oscs1024.com/hd/MPS-rxvm-9042</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnvd.nist.gov%2Fvuln%2Fdetail%2FCVE-2024-23334" target="_blank">https://nvd.nist.gov/vuln/detail/CVE-2024-23334</a></p><h2>免费情报订阅&amp;代码安全检测</h2><p>OSCS 是国内首个开源软件供应链安全社区，社区联合开发者帮助全球顶级开源项目解决安全问题，并提供实时的安全漏洞情报，同时提供专业的代码安全检测工具为开发者免费使用。社区开发者可以通过配置飞书、钉钉、企业微信机器人获取一手的情报。</p><p>免费代码安全检测工具： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.murphysec.com%2F%3Fsrc%3Dosc" target="_blank">https://www.murphysec.com/?src=osc</a></p><p>免费情报订阅： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oscs1024.com%2Fcm%2F%3Fsrc%3Dosc" target="_blank">https://www.oscs1024.com/cm/?src=osc</a></p><p>具体订阅方式详见： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oscs1024.com%2Fdocs%2Fvuln-warning%2Fintro%2F%3Fsrc%3Dosc" target="_blank">https://www.oscs1024.com/docs/vuln-warning/intro/?src=osc</a></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4aeef4048430ca1baea7afb51fe0f5dc3dd.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 11:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280528</guid>
            <link>https://www.oschina.net/news/280528</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[马斯克抱怨微软 Windows 难用，V 神：加入 Linux！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>特斯拉 CEO 埃隆・马斯克在社交平台说道，上周末他购买了一台新款的 Windows 11 笔记本电脑，却发现必须创建微软账户 (MSA) 才能使用系统，这让他感到非常愤怒，认为这变相地让微软的人工智能 (AI) 访问了他的数据。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-e5e820c2d6e02c58e0b272f4e8447623295.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FVitalikButerin%2Fstatus%2F1762363524918227423" target="_blank">https://twitter.com/VitalikButerin/status/1762363524918227423</a></u></em></p></blockquote><p>对此，<span style="background-color:#ffffff; color:#333333">以太坊联合创始人 Vitalik Buterin</span>&nbsp;建议马斯克改用 Linux 桌面发行版。</p><p>X 上的一些用户称赞 V 神推广了开源软件。但也有人指出，Linux 可能不是马斯克的最佳选择，因为他使用 PC 的主要目的是玩游戏。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 09:59:34 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280524</guid>
            <link>https://www.oschina.net/news/280524</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GPL 抗辩成功——织梦 CMS「系列」版权纠纷迎来重大转折]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><blockquote><p style="text-align:justify"><span style="color:#27ae60"><strong>摘要</strong></span></p><p style="text-align:justify"><span style="color:#4e5f70">原告：上海卓卓网络科技有限公司（以下简称：卓卓公司）</span></p><p style="text-align:justify"><span style="color:#4e5f70">被告：****医院</span></p><p style="text-align:justify"><span style="color:#4e5f70">事件：****医院使用 DedeCMSV5.7-sp1 软件开发网站，卓卓公司以拥有 DedeCMS Biz V1.0 以及后续多个版本的著作权为由，认为医院侵犯了自己的著作权，要求***医院赔偿 5800 元的授权许可费和 8700 元的诉讼费用。</span></p><p style="text-align:justify"><span style="color:#4e5f70">判决：一审法院认为 DedeCMSV5.7-sp1 中包含 GPL 协议下开源的代码，整体应遵守 GPL 协议，****医院使用软件不用支付授权费用，但仍需遵守署名权的要求。</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>持续近 3 年、涉及 300 万用户的织梦 CMS 「系列」版权纠纷案在</span></span></span><span><span><span>近</span></span></span><span><span><span>日迎来第一份抗辩成功判决。上海卓卓网络科技有限公司自 2021 年起，以「织梦商业网站内容管理系统【简称：DedeCMS Biz】V1.0」著作权方的身份，在全国各地起诉多个网站中含有 DedeCMS 相关代码的公司，要求赔偿。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>2023 年 9 月 11 日，卓卓公司诉****医院侵害计算机软件著作权纠纷案件立案。2024 年 2 月 19 日，江苏省无锡市中级人民法院</span></span></span><span><span><span>作出</span></span></span><span><span><span>一审判决书，认可了 GPL 的</span></span></span><span><span><span>「</span></span></span><span><span><span>传染性</span></span></span><span><span><span>」</span></span></span><span><span><span>，涉案软件（具体版本为 DedeCMSV5.7-sp1）整体按 GPL 对外许可，但要求使用者（被告）在网页底部添加原告网址链接，不得侵犯原告的署名权。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>一审判决书在判决书送达之日起十五日，当事人没有提起上诉的，就会生效。据案件知情人士分析，卓卓公司肯定会上诉。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>开源中国</span></span></span><span><span><span>从知情人处</span></span></span><span><span><span>获取并查阅判决书。据判决书显示，卓卓公司提出，卓卓通过受让取得了 DedeCMS Biz V1.0 的软件著作权，又在 DedeCMS Biz V1.0 版本的基础上迭代出 DedeCMSV5.5、DedeCMSV5.6、DedeCMSV5.7 等版本。****医院名下网站相关网页相关源代码与卓卓公司享有著作权的涉案软件代码相同，证据包括授权协议中的卓卓公司名称、Powered By DedeCMS、织梦内容管理系统 DEDECMS 的 logo/mark 等等。但****医院并未向卓卓公司购买正版涉案软件，也从未获得过卓卓公司商业使用授权许可。因此卓卓要求****医院支付涉案软件 DedeCMS 软件的授权许可费 5800 元，以及卓卓公司为诉讼所指出的 8700 元费用，共计 14500 元。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>而****医院辩称：卓卓虽然通过受取得 DedeCMS Biz V1.0 的软件著作权，但没有证据能够证明卓卓公司是织梦内容管理系统 DedeCMS 软件的著作权人。此外，DedeCMS 是一款以 GPL 协议对外许可发布的开源软件，DedeCMS 后续版本包括涉案权利软件都是在 DedeCMSV3 版本基础上迭代升级的，因此受 GPL 约束。根据 GPL 协议禁止添加商业使用的限制条款，也不允许著作权人就软件本身收取授权许可费。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>此外，围绕案件，卓卓公司和****医院还列举了多项诉求与证据，详情可查看一审判决书（尚未生效）。</span></span></span></span></span></span></p><div><blockquote><div><span style="color:#4e5f70">此份判决书由知情人提供并脱密：https://report.oschina.net/api/files/jhim80u9qm1ofsw/79ci47r1rrt9yqm/2023_02_482_cEvUNytTpS.pdf</span></div></blockquote></div><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>法院总结此案件争议焦点有两个：</span></span></span></span></span></span></p><div><blockquote><div><span style="color:#4e5f70">综合双方的诉辩主张，并经双方确认，本院对本案的争议焦点归纳为：</span></div><div><span style="color:#4e5f70">一、涉案权利软件的著作权人是否是卓卓公司；</span></div><div><span style="color:#4e5f70">二、****医院是否有权依据 GPL 协议免费使用涉案权利软件</span></div></blockquote></div><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>针对第一点，法院认为：</span></span></span></span></span></span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span style="color:#4e5f70">涉案权利软件的著作权人是卓卓公司。</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>针对第二点，法院认为：</span></span></span></span></span></span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span>&nbsp;</span><span><span><span><span style="color:#646a73">涉案软件 DedeCMSV5.7-sp1&nbsp;是包含采用 GPLV2.0 及以后版本做为协议的 sphinxclient 的派生作品。……由此本案中卓卓公司将涉案软件进行发布代表卓卓公司已经接受 GPL 协议。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#646a73">……</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#646a73">涉案软件应当遵守 GPL 协议，卓卓公司在涉案软件的许可协议中的「商业用途需获得授权」的条款与 GPL 协议</span></span></span><span><span><span style="color:#646a73">相</span></span></span><span><span><span style="color:#646a73">抵触，卓卓公司有义务按照 GPL 协议将涉案软件整体授权给获得许可的人，****医院因 GPL 协议获得了对涉案软件使用的授权，并未侵犯卓卓公司的复制权，卓卓公司无权对此行为请求支付授权费用。</span></span></span></span></span><span>&nbsp;</span></p></blockquote><p><span>不过，法院认为****医院需在网站注明来源是卓卓公司。</span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span>&nbsp;</span><span><span><span><span style="color:#646a73">卓卓公司在许可协议中载明用户应在使用涉案软件建成网站的主页标注网站链接 www.dedecms.com，该条款并不构成对下游接收者对软件复制、分发、修改权利的限制，应当有效。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#646a73">……</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#646a73">GPL 协议作为许可协议有双务性，被许可人在行使复制、发布修改开源软件的权利时，也需要按照协议要求承担相应义务，****医院使用涉案软件 DedeCMS 建成了网站，但未在主页标注卓卓公司创作印记或官网链接，违反了该附加条款，侵害了卓卓公司的署名权，损害了卓卓公司的身份权益。故卓卓公司请求****医院赔偿损失并赔礼道歉，具有事实和法律依据，本院予以支持。</span></span></span></span></span><span>&nbsp;</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>最终，法院判定由****医院赔偿卓卓公司经济损失及合理维权开支共 800 元，并在判决生效之日起十日内在其公司网站主页发布为期三十日的赔礼道歉声明。在关于赔偿金额的表述中，法院的考量因素中还提到两点值得关注：</span></span></span></span></span></span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span style="color:#4e5f70">第三，卓卓公司主张****医院在内的用户需遵守涉案软件的许可协议，但卓卓公司在使用他人代码时却未遵守他人软件的 GPL 许可协议，其行为本身有违诚信原则，具有不正当性。卓卓公司自身对涉案软件的著作权也存在管理不周的情况，软件源代码中记录的版权信息、署名都未直接指向卓卓公司，源代码中不同位置的许可协议条款存在不一致的情形。</span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span style="color:#4e5f70">第四，卓卓公司以涉案软件为权利基础，在全国法院提起大量侵害计算机软件著作权纠纷案件，并因此获得较大收益，该种维权模式既不利于有效打击侵权源头，又大量占用解决纠纷的公共资源，不宜提倡和鼓励。</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>此外，据企查查信息显示，上海卓卓发起了多起侵害计算机软件著作权纠纷诉讼，自 2 月 28 日-3 月 30 日将陆续有案件开庭。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img height="522" src="https://static.oschina.net/uploads/space/2024/0227/170855_5DFc_4489239.png" width="600" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>开源中国将持续关注 DedeCMS 系列版权纠纷案件进展，本周内也将梳理此系列纠纷的时间线，欢迎知情者私信爆料。</span></span></span></span></span></span></p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 09:10:34 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280518/gpl-dedecms</guid>
            <link>https://www.oschina.net/news/280518/gpl-dedecms</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[白宫敦促开发者改用内存安全的编程语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">白宫国家网络主任办公室 (ONCD) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.whitehouse.gov%2Foncd%2Fbriefing-room%2F2024%2F02%2F26%2Fpress-release-technical-report%2F" target="_blank">发布</a>了一份报告，呼吁科技界主动减少网络空间的攻击面；通过改用 Rust 等内存安全编程语言，减少内存安全漏洞的数量来提高软件安全性。同时鼓励研究界解决软件可测量性问题，以便开发出更好的测量网络安全质量的诊断方法。</span></p><p><img height="390" src="https://oscimg.oschina.net/oscnet/up-7cb1183993aa2d8ce4f54a8bb5787fa09a7.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">ONCD 例举了历史上一些著名的网络攻击事件，包括：1988 年的 Morris 蠕虫病毒、2003 年的 Slammer 蠕虫病毒、2014 年的 Heartbleed 漏洞、2016 年的 Trident 漏洞、2023 年的 Blastpass 漏洞。并指出，所有这些问题的背后都有一个共同的根本原因，即内存安全漏洞。</span></p><p><span style="color:#000000">报告称：「35 年来，三十五年来，内存安全漏洞一直困扰着数字生态系统，但情况本不必如此。消除整类软件漏洞的挑战是一个紧迫而复杂的问题。展望未来，必须采取新方法来减轻这种风险。」</span></p><p><span style="color:#000000">「减少内存安全漏洞的最高杠杆方法是保护网络空间的构建模块之一：编程语言。使用内存安全编程语言可以消除大多数内存安全错误。」</span></p><p><span style="color:#000000">在此之前，</span><span style="background-color:#ffffff"><span style="color:#000000">美国国家安全局 (NSA) 曾于 2022 年 11 月发布了关于软件开发人员如何防止软件内存安全问题的</span><a href="https://www.oschina.net/news/217425/nsa-memory-safe-programming-language" target="_blank">指南。</a></span><span style="background-color:#ffffff; color:#000000">美国网络安全与基础设施安全局 (CISA)<span>&nbsp;</span></span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>也在 2023 年 12 月发布了类似<a href="https://www.oschina.net/news/269933/cisa-the-case-for-memory-safe-roadmaps">报告</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="color:#000000"><span style="background-color:#ffffff">，</span>要求过渡到内存安全编程语言，通过消除与内存相关的漏洞来减少软件产品的攻击面。</span></p><p><span style="color:#000000">ONCD 报告以美国总统拜登于 2023 年 3 月签署的</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Fwhite-house-releases-new-us-national-cybersecurity-strategy%2F" target="_blank">国家网络安全战略</a><span style="color:#000000">为基础，将网络安全的责任从个人和小型企业转移到技术公司和联邦政府等更有能力管理不断变化的威胁的大型组织身上。并在与整个联邦政府的安全设计计划和研发工作保持一致的同时更进一步，涵盖了由 CISA、NSA、FBI 和 NIST 领导的计划和研发工作。</span></p><p><span style="color:#000000">报告中有关内存安全的工作还补充了美国国会对此主题的兴趣。此外，美国参议院国土安全和政府事务委员会主席 Gary Peters (D-MI) 和美国参议员 Ron Wyden (D-OR) 也向 ONCD 强调了他们在内存安全方面的立法努力。</span></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.whitehouse.gov%2Fwp-content%2Fuploads%2F2024%2F02%2FFinal-ONCD-Technical-Report.pdf" target="_blank">查看完整报告</a>。</span></p><p><strong><span style="color:#000000">相关阅读：</span></strong></p><ul><li><a href="https://www.oschina.net/news/217425/nsa-memory-safe-programming-language" target="_blank">美国国家安全局建议从 C/C++ 切换到内存安全语言</a></li><li><a href="https://www.oschina.net/news/269933/cisa-the-case-for-memory-safe-roadmaps" target="_blank">美国 CISA 建议放弃 C/C++，消除内存安全漏洞</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 08:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280505/white-house-memory-safe-programming-languages</guid>
            <link>https://www.oschina.net/news/280505/white-house-memory-safe-programming-languages</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[南京大学将开通全国高校首家 AI 课程]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">南京大学正式发布全国高校首家面向 3700 余名新生开设的「1+X+Y」三层次的人工智能通识核心课总体方案。</span></p><p><span style="color:#000000">该方案包含 1 门必修的人工智能通识核心课，X 门人工智能素养课，Y 门各学科与人工智能深度融合的前沿拓展课。其中，1 门人工智能通识核心课面向对象为 2024 年起面向全体本科新生。</span></p><p><span style="color:#000000"><img height="256" src="https://oscimg.oschina.net/oscnet/up-c46928165fcc29d00ea987b62dd6db02a66.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">南京大学党委书记、中国科学院院士谭铁牛指出，当今世界，由人工智能引领的新一轮科技革命和产业变革方兴未艾。在移动互联网、大数据、超级计算、传感网、脑科学等新理论新技术驱动下，人工智能已经对经济发展、社会进步、全球治理等各方面产生重大而深远的影响。只有紧跟时代步伐，把握时代脉搏，才能顺势而上，应势而为，把创新主动权、发展主动权牢牢掌握在自己手中。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 08:03:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280497</guid>
            <link>https://www.oschina.net/news/280497</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[0201-0225 开放签团队工作日记]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span><span><span><span>2022 年底</span></span></span><span><span><span>团队决定</span></span></span><span><span><span>以全新的产品运营和设计思路重回电子签章行业，重新做</span></span></span><span><span><span>电子签章</span></span></span><span><span><span>产品。至于当时如何离开电子签章，又是如何回来的，具体原因等后面再敍。在这么多年的创业的过程中，我们团队经历了从迷茫无助到方向坚定（我们认为的），从一点点构建基础技术架构到基本成熟，有太多的不容易，每一个不容易都可以是个故事，具体的也在将来一一再敍，这次单说最近的一些工作感受和工作概况。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>经过努力</span></span></span><span><span><span>，23 年底（12 月 15 日）</span></span></span><span><span><span>产品</span></span></span><span><span><span>上线</span></span></span><span><span><span>后</span></span></span><span><span><span>，我们深知自己在</span></span></span><span><span><span>市场竞争中与头部企业仍存在功能层面的差距</span></span></span><span><span><span>，不敢妄想有什么好的反馈和成果。但是首</span></span></span><span><span><span>月</span></span></span><span><span><span>便</span></span></span><span><span><span>迎来了</span></span></span><span><span><span>付费用户</span></span></span><span><span><span>（企业版）和近</span></span></span><span><span><span>百</span></span></span><span><span><span>个开源用户</span></span></span><span><span><span>，</span></span></span><span><span><span>这完全出乎我和同事的意料</span></span></span><span><span><span>。刚开始我们以为这些用户至少要在 3-5 个月内才能积累到。事实证明我们错了，我们保守了，但是方向貌似对了（还需要更多的付出和积累）。在与客户沟通过程中，很快就收集到</span></span></span><span><span><span>首批客户集中提出</span></span></span><span><span><span>的众多需求，主要体现在</span></span></span><span><span><span>移动端签署、API 集成、</span></span></span><span><span><span>国产化</span></span></span><span><span><span>及优化交互体验</span></span></span><span><span><span>四大方面。也有很多我们在设计过程中没有考虑到的，没有考虑到的方面对我们来说尤其珍贵，价值巨大。</span></span></span><span><span><span>所以</span></span></span><span><span><span>我们在年前</span></span></span><span><span><span>加快工作节奏，</span></span></span><span><span><span>年后规划新年一季度目标。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>首要任务是</span></span></span><span><span><span>移动端开发，并承诺于春节后第一周交付新功能。</span></span></span><span><span><span>这段时间的工作节奏是这样的：</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>1、</span></span></span><span><span><span>临近春节</span></span></span><span><span><span>（</span></span></span><span><span><span>农历 28 日</span></span></span><span><span><span>）</span></span></span><span><span><span>我们完成了功能开</span></span></span><span><span><span>发，勉强通过冒烟测试</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>2、</span></span></span><span><span><span>年后进行系统和功能测试时，</span></span></span><span><span><span>出乎意料的事情接踵而至</span></span></span><span><span><span>，</span></span></span><span><span><span>出现了</span></span></span><span><span><span>移动端链接逻辑</span></span></span><span><span><span>跳转混乱</span></span></span><span><span><span>、文件签署内存异常、</span></span></span><span><span><span>签署</span></span></span><span><span><span>图片丢失、签署控件重复等</span></span></span><span><span><span>问题</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>3、</span></span></span><span><span><span>测试同学「大壮」在群里</span></span></span><span><span><span>发飙了，</span></span></span><span><span><span>讲述上线风险和延期上线的请求</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>4、不动声色的产品负责人老胡看到</span></span></span><span><span><span>请求</span></span></span><span><span><span>后</span></span></span><span><span><span>一直未回复（他的性格很刚强，表面不说，内心很要强）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>5、老胡</span></span></span><span><span><span>开始</span></span></span><span><span><span>着手</span></span></span><span><span><span>理清工作任务，</span></span></span><span><span><span>逐条分析 BUG，确定优先级。</span></span></span><span><span><span>···········（结果：原定计划</span></span></span><span><span><span>（2 月 25 日）</span></span></span><span><span><span>未完成上线）只好协调大家</span></span></span><span><span><span>周六日</span></span></span><span><span><span>继续</span></span></span><span><span><span>通宵奋战</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>6、</span></span></span><span><span><span>直至</span></span></span><span><span><span>2 月 26 日</span></span></span><span><span><span>凌晨五点成功修复所有问题并上线新版本</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>这个过程真是酸爽，自从决定做开放签以来，首先内心是非常欣慰的，工作状态也超好，整个团队也是热情澎湃的，甚至自然而然的解决了一些团队管理问题。</span></span></span><span><span><span>同样的产品不同的公司，都是为了服务客户</span></span></span><span><span><span>和理想在</span></span></span><span><span><span>奋斗</span></span></span><span><span><span>、在</span></span></span><span><span><span>熬夜，感谢</span></span></span><span><span><span>团</span></span></span><span><span><span>队成员的努力付出</span></span></span><span><span><span>！加油！（会想尽一切办法和努力给大家加鸡腿，让我们</span></span></span><span><span><span>的</span></span></span><span><span><span>产品更好</span></span></span><span><span><span>，</span></span></span><span><span><span>团队更顽强</span></span></span><span><span><span>，客户更放心</span></span></span><span><span><span>........）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>值得欣喜的是，按照约定我们成功完成版本更新</span></span></span><span><span><span>，</span></span></span><span><span><span>并与两家新客户签约。接下来，我们将采取敏捷迭代策略，小步快跑地满足需求</span></span></span><span><span><span>。</span></span></span><span><span><span>同时大胆创新签约场景模式，使更多企业在真实场景下实现高效合规</span></span></span><span><span><span>签署，让电子签更简单不是说说而已</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:right"><span><span><span><span><span><span><span>2024 年 02 月 27 日</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 07:32:21 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280492</guid>
            <link>https://www.oschina.net/news/280492</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Spring Boot 拒绝用 AI 为仓库自动生成注释]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">一名开发者近日在 Spring Boot 提交了一项 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-boot%2Fpull%2F39754%2F" target="_blank">PR</a>，旨在使用 AI 模型为整个 Spring Boot 代码库添加注释：</span></p><blockquote><p><span style="color:#000000">此代码变更为整个 Spring Boot 代码库添加了注释。本 PR 的内容完全由自定义微调 AI 模型创建。</span></p><p><span style="color:#000000">我们正在对我们的工具进行大规模实验，在数百万行代码上运行该工具，以识别任何 bug 或错误。在此代码库中运行时，该工具的编译成功率高达 99.9%。</span></p><p><span style="color:#000000">我们可以选择放弃这些代码，或者将其发布并作为一项贡献。我们选择了后者，并决定打开此 Pull Request。</span></p></blockquote><p><img height="280" src="https://oscimg.oschina.net/oscnet/up-c694ca89e5d80a24accaf670c4f099452bc.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">但 Spring Boot 项目负责人 Phil Webb 对此进行了婉拒。并表示，相较自动生成，团队成员更喜欢人工手动的方式；且自动生成这种无差别的方式，很可能给整个仓库增添许多不必要的麻烦。</span></p><p><span style="color:#000000">「我认为您的工具对于正在学习代码库或需要某些部分的额外帮助的人来说可能非常有用。」</span></p><p>Reddit 上的一些讨论也表达了对这一提议的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F1b0n9kx%2Fai_added_comments_for_the_entire_code_base_of%2F" target="_blank">不看好</a>：</p><blockquote><p>「哇，这太可怕了。我真希望这只是个玩笑，提出要求的人只是在嘲笑这个想法。」</p><p>「如果这不是纯粹为了吸引眼球，那么我想公关背后的开发人员可以说是真的缺乏开发技能。」</p></blockquote><p>目前，相关 PR 已被关闭。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 06:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280473/ai-comments-spring-boot</guid>
            <link>https://www.oschina.net/news/280473/ai-comments-spring-boot</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | 鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.26</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/280197/warp-for-linux" target="_blank">基于 Rust 开发的终端应用 Warp 发布 Linux 版本</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Warp 是一个基于 Rust 开发的现代化终端应用，内置 AI 功能，支持 CPU 加速。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">此前 Warp 仅面向 Mac 平台提供，近日其开发团队终于<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.warp.dev%2Fblog%2Fwarp-for-linux" target="_blank">发布</a></u>了 Linux 版本，用户可在大多数主流 Linux 发行版上安装 Warp，包括 Ubuntu、Fedora、Arch Linux 或 Red Hat。</p><h3><a href="https://www.oschina.net/news/280083/wubuntu-windows-ubuntu" target="_blank">Wubuntu：披着 Windows 11 外衣的 Ubuntu</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Wubuntu，又称 "Windows Ubuntu"</strong>，是基于 Ubuntu 开发的操作系统，其最具特色之处在于<strong>完全复刻了 Windows 的所有外观和功能</strong>，而且运行时不需要具备 TPM、安全启动或任何其他硬件要求。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span>此外，Wubuntu</span>&nbsp;通过集成 Wine 提供了与 Windows 应用的兼容性，开发者称 Wubuntu 支持运行 Windows 的 .exe 和 .msi&nbsp;程序，以及支持 Android 应用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b78011bce450db4cf20d1bb7cc559cd4cb6.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-a5cb30243de8b0b91be1d481043c473ad9e.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tmtpost.com%2F6949344.html" target="_blank">钛媒体</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-dd0b05ccdc75b8e461bccd191d8b02a887a.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>开源之声</strong></span></h2><p><img height="376" src="https://oscimg.oschina.net/oscnet/up-61ab492b02eb694af46583aa700ca993ddd.png" width="1104" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-393f28205ac4c95982b1545e5541957f5f9.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 Gitee 精选</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-f0e8ff0ed6f05f1864bb5c951acca5d3893.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 04:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280457</guid>
            <link>https://www.oschina.net/news/280457</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OSI 发布报告，研究 BSL 这样的「延迟开源发布」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff">Open Source Initiative（OSI）近期发布了一个报告《Delayed Open Source Publication:&nbsp;</span>A Survey of Historical and Current Practices<span style="background-color:#ffffff; color:#060607">》（</span>延迟开源发布：历史与当前实践调研<span style="background-color:#ffffff; color:#060607">），作者是 Seth Schoen、James Vasile 和 Karl Fogel。</span></p><p>&nbsp;</p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">Delayed Open Source Publication，简称 DOSP，延迟开源发布的意思，这份报告研究了它的历史和现状。报告核心要点：</p><p style="margin-left:0; margin-right:0"><strong>延迟开源发布（DOSP）定义</strong>：DOSP 是指软件最初在专有许可下发布，然后计划性地在某个时间点将源代码以开源许可的形式公开。</p><p style="margin-left:0; margin-right:0"><strong>历史背景</strong>：DOSP 的做法可以追溯到 GNU 项目，并且一直延续至今。公司尝试各种商业模式，以在有限时间内保持独家权利，然后过渡到 OSI（开放源代码倡议）批准的许可。</p><p style="margin-left:0; margin-right:0"><strong>策略类型</strong>：DOSP 分为三种类型：无条件计划性重新许可、事件驱动的重新许可和有条件的重新许可。</p><p style="margin-left:0; margin-right:0"><strong>商业源许可（BUSL）</strong>：BUSL 是一种新兴的 DOSP 许可方式，它要求在特定的「变更日期」后，软件的许可将变为开源许可。这种做法在数据库系统中尤为常见。（以往也叫 BSL）</p><p style="margin-left:0; margin-right:0">以下是当前知名的 16 个使用 BUSL 的项目，都是延迟几年后转型成开源协议：</p><p style="margin-left:0; margin-right:0"><img height="1588" src="https://static.oschina.net/uploads/space/2024/0227/115012_ybIG_3820517.png" width="1434" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>反竞争条款</strong>：一些 DOSP 许可中包含反竞争条款，旨在防止许可证持有者使用软件提供与许可方直接竞争的服务。</p><p style="margin-left:0; margin-right:0"><strong>后果和影响</strong>：从开源许可转变为 DOSP 许可的项目可能会受到批评，有时会导致用户转向其他项目或维护竞争性的分支。</p><p style="margin-left:0; margin-right:0"><strong>未来研究问题</strong>：报告提出了一些未来研究的问题，包括 AGPL 与 DOSP 许可的比较、DOSP 对外部贡献的影响、BUSL 额外使用授权的分类、以及在初始开源发布后重新许可的策略。</p><p style="margin-left:0; margin-right:0"><strong>结论</strong>：DOSP 自开源运动早期以来一直在使用，公司通常利用它来保持商业优势，同时尽可能保留开源的优势。报告强调，DOSP 的实验性和多样性比预期的要多，且这种趋势可能会继续。</p><p>详情可以查看<a href="https://apiv1.oschina.net/api/files/jhim80u9qm1ofsw/27nfbrttho0ynu9/delayed_open_source_publication_2FzjpHTElG.pdf?token=">报告原文</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:57:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280456/osi-delayed-open-source-publication-report</guid>
            <link>https://www.oschina.net/news/280456/osi-delayed-open-source-publication-report</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[终于，我们拿下了硅谷的那个 Linear]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-0963fd788787982101b5435a54ca146c2ab.png" alt="file" referrerpolicy="no-referrer"></p><p>就像设计领域的 Figma，文档领域的 Notion，Linear 同样在软件开发管理领域推出了革命性的工具。而且以其名字 Linear Style 命名的设计风格，也成为了一股软件设计潮流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-19feb8c039e4eb58e00760e5e8abaeba7f9.png" alt="file" referrerpolicy="no-referrer"></p><p>Linear 于 2019 年在美国 🇺🇸 旧金山创立。目前服务的对象涵盖了从新兴初创到知名上市公司的广泛范围，其中包括 Vercel、Arc、Runway，Supercell 和 OpenSea 等知名企业。其产品因能显著提升团队生产力和协作效率而成为近几年硅谷新兴公司的首选。</p><p><img src="https://oscimg.oschina.net/oscnet/up-29fa5d140ca7408dad14b59ffc2cef3023a.png" alt="file" referrerpolicy="no-referrer"></p><p><strong>Linear 使用 Bytebase 管理其数据库的全开发生命周期。收口员工查询数据库操作，通过 Bytebase API 将数据库变更集成进现有 CI/CD 工作流。</strong></p><p>Linear 的员工统一在 SQL 编辑器查询数据，通过权限管控、数据脱敏及行为审计，限制查询范围、监控行为并满足合规需求。</p><p>通过 Bytebase API 将数据库变更的审核部署集成进现有的代码提交部署工作流中，触发在 Bytebase 中建立工单，自动进行 SQL 预审核以减少人力降低错误可能性；根据变更的风险等级，通过自定义审批流确保相应的审批管理；并且，通过变更记录的查询功能，便于锁定特定的变更，以利于后续的审计。此外，单点登录 (SSO)，双因子身份验证 (2FA) 等功能进一步为账户管理带来了便利性和安全性保障。</p><p>未来 Linear 还将利用 Bytebase 的批量变更能力管理部署在不同地域的同构数据库。</p><p><img src="https://oscimg.oschina.net/oscnet/up-07cce1911ea9af359d0b945ffb3b6a4eca4.png" alt="file" referrerpolicy="no-referrer"></p><p>对开发者工具极其挑剔的 Linear 最终选择了 Bytebase。正如我们在 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMjI2MDY5OQ%3D%3D%26mid%3D2247483664%26idx%3D1%26sn%3Dbd6be60909c156c2d54687ad90ba4825%26chksm%3Dc25f3f24f528b63261d5d86fb9ddcad8f36826bdaa16fdb43da555d5457313c5036aa1665b78%26scene%3D21%23wechat_redirect" target="_blank">2021 年发布 Bytebase</a> 时设想的那样，<strong>Bytebase 会站上世界最高的舞台，成为现代软件研发工具链上的核心一环</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-551f266a1ef72674d8516e4795c1c18b9b4.png" alt="file" referrerpolicy="no-referrer"></p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:52:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/11044874</guid>
            <link>https://my.oschina.net/u/6148470/blog/11044874</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 工程师使用 Rust 为 Linux 开发内核调度程序]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Ubuntu 内核团队工程师 Andrea Righi 使用&nbsp;Rust 编写了一个 Linux 内核调度程序，并利用 eBPF 在运行时动态加载。Ubuntu 还没有承诺将其作为发行版的一部分，Righi 也在博客表示这是一个实验性内核项目，用于探索 Rust 在 Ubuntu 的应用，并谈到了未来<strong>利用 Rust 和 eBPF 进行「微内核设计」</strong>的可能性。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c0d741c436f514bc20978b2df98eb1e23a1.png" referrerpolicy="no-referrer"></p><p>Righi 在博客介绍称，用 Rust 开发的内核调度程序 sched-ext 不仅为开发者提供了便利，还能让用户也受益，比如可以根据用户的工作负载和其他特殊情况加载优化的调度程序。</p><p>博客文章最后写道：</p><blockquote><p>「我们正朝着一种微内核设计迈进，它有可能为 Linux 认证铺平道路：在上述情况下，如果用户空间调度程序崩溃，任务将无缝过渡到默认的内核调度程序，确保系统的持续可用性，而不会出现任何停机时间。</p><p>这表明，类似的方法也可用于其他子系统，从而使 Linux 内核能够提供完全冗余和崩溃安全的系统。」</p></blockquote><p>相关链接</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsched-ext%2Fscx%2Fpull%2F161" target="_blank">https://github.com/sched-ext/scx/pull/161</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2F%2Fblog%2Fcrafting-new-linux-schedulers-with-sched-ext-rust-and-ubuntu" target="_blank">https://ubuntu.com//blog/crafting-new-linux-schedulers-with-sched-ext-rust-and-ubuntu</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:25:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280450/ubuntu-rust-scheduler-micro</guid>
            <link>https://www.oschina.net/news/280450/ubuntu-rust-scheduler-micro</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linkerd 2.15 推出，调整了发布方式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linkerd 2.15 现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flinkerd.io%2F2024%2F02%2F21%2Fannouncing-linkerd-2.15%2F" target="_blank">发布</a>，该版本增加了对 Kubernetes 以外工作负载的支持。新的「网格扩展（mesh expansion）」功能首次允许 Linkerd 用户将运行在虚拟机、物理机和其他非 Kubernetes 位置上的应用程序引入到网格中，为 Kubernetes 和非 Kubernetes 工作负载提供统一的安全、可靠和可观测的连接。</p><p>2.15 版本还引入了对 SPIFFE 的支持，SPIFFE 是一种工作负载身份标准，它使 Linkerd 能够为集群外的工作负载提供加密身份验证。此外，还新增了原生的 Sidecar 容器支持，这是 Kubernetes 的一个新特性，它简化了 Sidecar 模型在 Kubernetes 中的使用，特别是对于作业工作负载而言。</p><p>以及对 Linkerd 的发布方式进行了一些重要调整。公告指出，「尽管 Linkerd 将始终是开源的，但从 2.15 版开始，我们将不再发布开源的稳定版本工件」。如果你目前正在生产环境中使用 Linkerd，可查看"<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flinkerd.io%2F2024%2F02%2F21%2Fannouncing-linkerd-2.15%2F%23a-new-model-for-stable-releases" target="_blank">A new model for stable releases</a>"部分进行了解。</p><p>与往常一样，2.15 版本还包含了大量的错误修复和改进。</p><h4><strong>网格扩展</strong></h4><p>Linkerd 2.15 引入了网格扩展功能：可以在 Kubernetes 之外的任何地方部署 Linkerd 的超轻量级 Rust 微代理，并将它们连接到运行在 Kubernetes 集群上的 Linkerd 控制平面。这使得 Linkerd 能够处理非 Kubernetes 工作负载，将所有 TCP 通信与这些工作负载之间的通信升级为安全、可靠和可观测的连接。非 Kubernetes 应用程序可以获得 Linkerd 的全部功能，包括互相 TLS、重试、超时、断路器、基于延迟的负载均衡、动态的每个请求路由、零信任授权策略等等。</p><p>网格扩展是实现 Linkerd 成为云原生组织的通用网络层目标的重要组成部分。官方认为，这一举措在很大程度上得益于 Linkerd 的核心设计，即用 Rust 编写的超轻量级微代理。Rust 语言具备"防止内存相关错误、管理并发、生成小型、高效的二进制文件"的能力，使得 Linkerd 不仅避免了 C 和 C++等语言普遍存在的内存漏洞，而且提供了最小的资源占用和最重要的是对用户的最小操作负担。</p><p>「Linkerd 的 Rust 微代理是其以简单为先的方法的关键所在，我们能够提供小型、静态的二进制文件，可以编译为各种架构和平台，这是解锁 Linkerd 新的网格扩展功能的关键所在。」</p><h4><strong>SPIFFE 支持</strong></h4><p>网格扩展的一个主要挑战是如何为非 Kubernetes 工作负载生成工作负载标识。为了解决这个问题，项目团队引入了对 SPIFFE 的支持。通过 Linkerd 2.15，用户现在可以默认加密所有与虚拟机工作负载的通信，并在特定客户端的每个 HTTP 路由和 gRPC 方法级别上添加零信任控制。</p><h4><strong>原生 sidecar 支持</strong></h4><p>Linkerd 2.15 添加了对原生 sidecar 容器的支持，这是 Kubernetes 1.28 引入的一个新的 Kubernetes 特性，并在 Kubernetes 1.29 中默认启用。使用原生 sidecar 容器部署 Linkerd 解决了在 Kubernetes 中使用 sidecar 容器时长期存在的一些烦恼，特别是在支持 Job 和容器启动过程中的 race conditions 问题。</p><p><strong>稳定版本的新模式</strong></p><p>从 Linkerd 2.15 开始对交付方式进行了一些重大更改。虽然 Linkerd 始终是开源的，但从 Linkerd 2.15 开始，稳定的 Linkerd 发布将由供应商社区负责。</p><p>这不仅包括 Linkerd 2.15.0，还包括即将推出的 Linkerd 2.15.1 这样的 point releases、即将推出的 2.16.0 这样的重大版本，以及即将推出的 Linkerd 2.14.11 这样的 backports 版本，所有这些都将由供应商社区处理。</p><blockquote><p>「我们将一如既往地在 GitHub 代码库中发布 edge releases，其中包含最新的 Linkerd 代码，包括错误修复、新功能等。这些版本一直是社区进行早期测试和审查的重要机制，我们希望在新框架下能看到更多这样的版本。当然，Linkerd 的开发工作仍将照常进行，包括功能开发、我们的安全漏洞响应政策，以及其他所有让 Linkerd 变得更出色的活动。</p><p>需要明确的是：Linkerd 始终是开源的。这一改变只涉及 release artifacts，而不是关于代码、管理、社区或其他任何方面。早在创建 Linkerd 之前，我们就已经是开源用户、贡献者和倡导者，我们对健康、包容、协作和不断发展的开源 Linkerd 的承诺一如既往。」</p></blockquote><h4><strong>下一步</strong></h4><p>项目团队计划在接下来的版本中：扩展对网格扩展的支持，以包括私有网络；使 Gateway API 和非 Gateway API 接口达到一致；支持 IPv6；致力于处理入口流量和增加对出口流量的控制；探索以其他方式提供 Linkerd，包括「ambient」和其他方法等等。</p><p>更多详情可查看官方<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flinkerd.io%2F2024%2F02%2F21%2Fannouncing-linkerd-2.15%2F" target="_blank">公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280444/linkerd-2-15-released</guid>
            <link>https://www.oschina.net/news/280444/linkerd-2-15-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GIMP 2.99.18 发布 —— 3.0 之前的最后一个开发者预览版]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>开源图像编辑器 GIMP 发布了 3.0 之前的最后一个开发者预览版本<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gimp.org%2Fnews%2F2024%2F02%2F21%2Fgimp-2-99-18-released%2F" target="_blank"> GIMP 2.99.18</a></u>。该版本旨在预览开发进展，让社区能更早发现问题和报告问题。它是一个不稳定版本，不适合用于生产环境。</p><p>GIMP 3.0 使用 GTK3 进行重构，并且支持 Wayland，同时还有许多其他的改进和功能增强。对于这个版本，广大用户已经期待了十年。GIMP 团队计划在 2024 年 5 月<a href="https://www.oschina.net/news/268067/gimp-3-0-may-2024-schedule">发布</a>备受瞩目的 GIMP 3.0。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d08a7bf4228037e192418e690efa9306020.png" referrerpolicy="no-referrer"></p><p>GIMP 2.99.18 包含了大量更新，其中包括</p><ul><li>正确校正颜色的 Space Invasion 项目</li><li>改进色彩算法</li><li>非破坏性编辑的基本实现</li><li>改进字体处理</li><li>自动扩展层</li></ul><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gimp.org%2Fnews%2F2024%2F02%2F21%2Fgimp-2-99-18-released%2F" target="_blank">详情查看发布公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280439/gimp-2-99-18-released</guid>
            <link>https://www.oschina.net/news/280439/gimp-2-99-18-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Rebebuca —— 桌面端 ffmpeg 管理器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>Rebebuca（发音：瑞贝不卡） 是一个使用 Rust 开发的桌面端 ffmpeg 管理器，在不卡系列中处于推流端的生态位（Monibuca 为服务端，Jessibuca 为播放端）。</p></li><li><p>Rebebuca 在不久的将来会支持管理 Monibuca&nbsp;进程。</p></li><li><p><strong style="color:black"><span style="color:#010101">Rebebuca&nbsp;</span>可以在 30 秒内完成创建、运行、管理你的 ffmpeg 命令</strong></p><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div class="ckeditor-html5-video" style="text-align:center"><video controls="controls" src="https://rebebuca.com/quick.mp4">&nbsp;</video></div></div><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0">&nbsp;</div><div style="margin-left:0; margin-right:0">&nbsp;</div></div></div></div></div></div></div></div></div></div></li><li><p>帮助我们更好的管理繁多复杂的 ffmpeg 参数和 ffmpeg 命令运行状态</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>功能特性</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>ffmpeg 命令全周期管理</p><ul style="list-style-type:circle; margin-left:0; margin-right:0"><li style="list-style-type:circle"><p>支持 ffmpeg 命令运行、停止、重启等操作</p></li><li style="list-style-type:circle"><p>支持 ffmpeg 命令参数可视化配置、导入终端命令</p></li><li style="list-style-type:circle"><p>支持，按项目维度管理各种 ffmpeg 命令</p></li><li style="list-style-type:circle"><p>支持，数据导出</p></li></ul></li><li><p>列表+详情交互模式</p></li><li><p>支持 ffmpeg 源切换、中英语言、深色浅色主题切换、窗口关闭方式选择</p><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0">&nbsp;</div><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0; text-align:center"><div class="ckeditor-html5-video" style="text-align:center"><video controls="controls" src="https://rebebuca.com/quick.mp4">&nbsp;</video></div></div><div style="margin-left:0; margin-right:0">&nbsp;</div></div></div></div></div></div></div></div></div></div></li><li><p>支持软件自动更新</p></li><li><p>支持 mac 和 window 平台</p></li><li><p>简单好用、能力丰富、长期维护</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>下载安装</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>Windows：https://download.m7s.live/rb/Rebebuca_0.1.0_x64_en-US.msi</p></li><li><p>Mac：https://download.m7s.live/rb/Rebebuca_0.1.0_x64.dmg</p></li><li><p>Mac(arm64) ：https://download.m7s.live/rb/Rebebuca_0.1.0_aarch64.dmg</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>官方地址</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>官方网站：https://rebebuca.com</p></li><li><p>github：https://github.com/rebebuca/rebebuca</p></li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/rebebuca</guid>
            <link>https://www.oschina.net/p/rebebuca</link>
        </item>
        <item>
            <title>
                <![CDATA[华为发布首个 5.5G 智能核心网：计划 2024 年商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 MWC24 巴塞罗那期间，华为云核心网产品线总裁高治国发布 5.5G 智能核心网解决方案。</p><p>据悉，2023 年新通话已在中国 31 省部署，可支撑 5000 万用户，同时在欧洲、拉美、中东、亚太等多个区域得到了广泛验证，计划 2024 年商用。高治国表示：「华为发布的业界首个新通话-A 通过智能能力和 DC（Data Channel）交互能力升级，正式迈入多模态通信时代。」</p><p><img height="333" src="https://oscimg.oschina.net/oscnet/up-b019072789c268abb1883dc58f6487ea5eb.png" width="500" referrerpolicy="no-referrer"></p><p>5.5G 也就是 5G-A，全称为 5G-Advanced，是 5G 的技术演进，具备更大带宽、更广连接、确定性时延等能力。作为 5G-A 的重要技术之一，三载波聚合（3CC）是 5G-A 的基础体验网，5G-A 三载波聚合可以通过三载波组网方案，结合确定性体验保障等技术，进一步提升网络质量与体验。</p><p>华为倡导的 5.5G 时代，是包含 5.5G、F5.5G、Net5.5G 等全面演进升级的端到端解决方案，会带来 10 倍的网络性能提升，可实现下行万兆、上行千兆的峰值能力。同时在时延、定位、可靠性方面也有了 10 倍的提升，还能实现毫秒级时延和低成本千亿物联。</p><p>在 2023 MWC 上海展会上， 华为董事、ICT 产品与解决方案总裁杨超斌曾宣布，华为 2024 年将会推出面向商用的 5.5G 全套网络设备。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280433</guid>
            <link>https://www.oschina.net/news/280433</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | Web 端弹幕库 Fly Barrage]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content--fly-barrage" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-fly-barrage"></a>✨ Fly Barrage</h1><p>Fully functional and powerful web-based barrage library</p><p>功能完善，强大的 web 端弹幕库</p><h2><a id="user-content--rendering-effects" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-rendering-effects"></a>🎥 Rendering effects</h2><p><img src="https://gitee.com/fei_fei27/fly-barrage/raw/master/public/imgs/0001.png" alt="渲染效果" referrerpolicy="no-referrer"></p><h2><a id="user-content--official-website" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-official-website"></a>📝 Official Website</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Ffly-barrage.netlify.app%2F">https://fly-barrage.netlify.app/</a></p><h2><a id="user-content--install" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-install"></a>📥 Install</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm <span class="nb">install </span>fly-barrage</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--usage" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-usage"></a>🌍 Usage</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c">&lt;!-- Taking Vue framework as an example, this library is not limited to specific frameworks. --&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;</span><span class="k">template</span><span class="nt">&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;div</span><span class="na">id=</span><span class="s">"container"</span><span class="nt">&gt;</span></span><span id="LC4" class="line"><span class="nt">&lt;video</span></span><span id="LC5" class="line"><span class="na">ref=</span><span class="s">"video"</span></span><span id="LC6" class="line"><span class="na">id=</span><span class="s">"video"</span></span><span id="LC7" class="line"><span class="na">controls</span></span><span id="LC8" class="line"><span class="na">autoplay</span></span><span id="LC9" class="line"><span class="na">src=</span><span class="s">"../src/assets/demo1.mp4"</span></span><span id="LC10" class="line"><span class="err">@</span><span class="na">play=</span><span class="s">"videoPlay"</span></span><span id="LC11" class="line"><span class="err">@</span><span class="na">pause=</span><span class="s">"videoPause"</span></span><span id="LC12" class="line"><span class="nt">&gt;&lt;/video&gt;</span></span><span id="LC13" class="line"><span class="nt">&lt;/div&gt;</span></span><span id="LC14" class="line"><span class="nt">&lt;/</span><span class="k">template</span><span class="nt">&gt;</span></span><span id="LC15" class="line"></span><span id="LC16" class="line"><span class="nt">&lt;</span><span class="k">script</span><span class="na">setup</span><span class="na">lang=</span><span class="s">"ts"</span><span class="nt">&gt;</span></span><span id="LC17" class="line"><span class="k">import</span><span class="nx">BarrageRenderer</span><span class="p">,</span><span class="p">{</span><span class="nx">BarrageOptions</span><span class="p">}</span><span class="k">from</span><span class="dl">'</span><span class="s1">fly-barrage</span><span class="dl">'</span><span class="p">;</span></span><span id="LC18" class="line"><span class="k">import</span><span class="p">{</span><span class="nx">onMounted</span><span class="p">,</span><span class="nx">ref</span><span class="p">}</span><span class="k">from</span><span class="dl">'</span><span class="s1">vue</span><span class="dl">'</span><span class="p">;</span></span><span id="LC19" class="line"></span><span id="LC20" class="line"><span class="kd">const</span><span class="nx">barrages</span><span class="p">:</span><span class="nx">BarrageOptions</span><span class="p">[]</span><span class="o">=</span><span class="p">[</span></span><span id="LC21" class="line"><span class="p">{</span></span><span id="LC22" class="line"><span class="dl">"</span><span class="s2">id</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">e55b45c9-7f9e-48c9-9bba-4d3b53441976</span><span class="dl">"</span><span class="p">,</span></span><span id="LC23" class="line"><span class="dl">"</span><span class="s2">barrageType</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">scroll</span><span class="dl">"</span><span class="p">,</span></span><span id="LC24" class="line"><span class="dl">"</span><span class="s2">time</span><span class="dl">"</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span></span><span id="LC25" class="line"><span class="dl">"</span><span class="s2">text</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">残灯无焰影幢幢，此夕闻君谪九江。</span><span class="dl">"</span><span class="p">,</span></span><span id="LC26" class="line"><span class="dl">"</span><span class="s2">fontSize</span><span class="dl">"</span><span class="p">:</span><span class="mi">34</span><span class="p">,</span></span><span id="LC27" class="line"><span class="dl">"</span><span class="s2">lineHeight</span><span class="dl">"</span><span class="p">:</span><span class="mf">1.2</span><span class="p">,</span></span><span id="LC28" class="line"><span class="dl">"</span><span class="s2">color</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">#FFFF00</span><span class="dl">"</span><span class="p">,</span></span><span id="LC29" class="line"><span class="p">},</span></span><span id="LC30" class="line"><span class="p">];</span></span><span id="LC31" class="line"></span><span id="LC32" class="line"><span class="kd">const</span><span class="nx">barrageRenderer</span><span class="o">=</span><span class="nx">ref</span><span class="o">&lt;</span><span class="nx">BarrageRenderer</span><span class="o">&gt;</span><span class="p">();</span></span><span id="LC33" class="line"><span class="kd">const</span><span class="nx">video</span><span class="o">=</span><span class="nx">ref</span><span class="p">();</span></span><span id="LC34" class="line"></span><span id="LC35" class="line"><span class="nx">onMounted</span><span class="p">(()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC36" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="o">=</span><span class="k">new</span><span class="nx">BarrageRenderer</span><span class="p">({</span></span><span id="LC37" class="line"><span class="na">container</span><span class="p">:</span><span class="dl">'</span><span class="s1">container</span><span class="dl">'</span><span class="p">,</span></span><span id="LC38" class="line"><span class="na">video</span><span class="p">:</span><span class="nx">video</span><span class="p">.</span><span class="nx">value</span><span class="p">,</span></span><span id="LC39" class="line"><span class="nx">barrages</span><span class="p">,</span></span><span id="LC40" class="line"><span class="p">});</span></span><span id="LC41" class="line"><span class="p">})</span></span><span id="LC42" class="line"></span><span id="LC43" class="line"><span class="kd">const</span><span class="nx">videoPlay</span><span class="o">=</span><span class="p">()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC44" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="p">?.</span><span class="nx">play</span><span class="p">();</span></span><span id="LC45" class="line"><span class="p">};</span></span><span id="LC46" class="line"></span><span id="LC47" class="line"><span class="kd">const</span><span class="nx">videoPause</span><span class="o">=</span><span class="p">()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC48" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="p">?.</span><span class="nx">pause</span><span class="p">();</span></span><span id="LC49" class="line"><span class="p">};</span></span><span id="LC50" class="line"><span class="nt">&lt;/</span><span class="k">script</span><span class="nt">&gt;</span></span><span id="LC51" class="line"></span><span id="LC52" class="line"><span class="nt">&lt;</span><span class="k">style</span><span class="nt">&gt;</span></span><span id="LC53" class="line"><span class="o">*</span><span class="p">{</span></span><span id="LC54" class="line"><span class="nl">padding</span><span class="p">:</span><span class="m">0</span><span class="p">;</span></span><span id="LC55" class="line"><span class="nl">margin</span><span class="p">:</span><span class="m">0</span><span class="p">;</span></span><span id="LC56" class="line"><span class="p">}</span></span><span id="LC57" class="line"></span><span id="LC58" class="line"><span class="nf">#container</span><span class="p">{</span></span><span id="LC59" class="line"><span class="nl">width</span><span class="p">:</span><span class="m">1000px</span><span class="p">;</span></span><span id="LC60" class="line"><span class="nl">height</span><span class="p">:</span><span class="m">700px</span><span class="p">;</span></span><span id="LC61" class="line"><span class="nl">margin</span><span class="p">:</span><span class="m">20px</span><span class="nb">auto</span><span class="m">0</span><span class="p">;</span></span><span id="LC62" class="line"><span class="p">}</span></span><span id="LC63" class="line"></span><span id="LC64" class="line"><span class="nf">#video</span><span class="p">{</span></span><span id="LC65" class="line"><span class="nl">width</span><span class="p">:</span><span class="m">100%</span><span class="p">;</span></span><span id="LC66" class="line"><span class="nl">height</span><span class="p">:</span><span class="m">100%</span><span class="p">;</span></span><span id="LC67" class="line"><span class="nl">background</span><span class="p">:</span><span class="no">black</span><span class="p">;</span></span><span id="LC68" class="line"><span class="p">}</span></span><span id="LC69" class="line"><span class="nt">&lt;/</span><span class="k">style</span><span class="nt">&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>For complete usage, please clone the project directly, install the dependencies, and then execute npm run dev to view the complete usage</p><p>Try to use a higher version of the node version, my local version is v18.19.0</p><h2><a id="user-content--license" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-license"></a>🌲 License</h2><p><a href="https://gitee.com/fei_fei27/fly-barrage/blob/master/LICENSE">MIT License</a></p>]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/fei_fei27/fly-barrage</guid>
            <link>https://gitee.com/fei_fei27/fly-barrage</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 得物自研 API 网关实践之路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>一、业务背景</h1><p style="color:#24292f; text-align:start">老网关使用 Spring Cloud Gateway （下称 SCG）技术框架搭建，SCG 基于 webflux 编程范式，webflux 是一种响应式编程理念，响应式编程对于提升系统吞吐率和性能有很大帮助; webflux 的底层构建在 netty 之上性能表现优秀；SCG 属于 spring 生态的产物，具备开箱即用的特点，以较低的使用成本助力得物早期的业务快速发展；但是随着公司业务的快速发展，流量越来越大，网关迭代的业务逻辑越来越多，以及安全审计需求的不断升级和稳定性需求的提高，SCG 在以下几个方面逐步暴露了一系列的问题。</p><span id="OSC_h2_2"></span><h2>网络安全</h2><p style="color:#24292f; text-align:start">从网络安全角度来讲，对公网暴露接口无疑是一件风险极高的事情，网关是对外网络流量的重要桥梁，早期的接口暴露采用泛化路由的模式，即通过正则形式（ /api/v1/app/order/** ）的路由规则开放接口，单个应用服务往往只配置一个泛化路由，后续上线新接口时外部可以直接访问；这带来了极大的安全风险，很多时候业务开发的接口可能仅仅是内部调用，但是一不小心就被泛化路由开放到了公网，甚至很多时候没人讲得清楚某个服务具体有多少接口属于对外，多少对内；另一方面从监控数据来看，黑产势力也在不断对我们的接口做渗透试探。</p><span id="OSC_h2_3"></span><h2>协同效率</h2><p style="color:#24292f; text-align:start">引入了接口注册机制，所有对外暴露接口逐一注册到网关，未注册接口不可访问，安全的问题得到了解决但同时带来了性能问题，SCG 采用遍历方式匹配路由规则，接口注册模式推广后路由接口注册数量迅速提升到 3W+，路由匹配性能出现严重问题；泛化路由的时代，一个服务只有一个路由配置，变动频率很低，配置工作由网关关开发人员负责，效率尚可，接口注册模式将路由工作转移到了业务开发同学的身上，这就得引入一套完整的路由审核流程，以提升协同效率；由于路由信息早期都存在配置中心，同时这么大的数据量给配置中心也带来极大的压力和稳定性风险。</p><span id="OSC_h2_4"></span><h2>性能与维护成本</h2><p style="color:#24292f; text-align:start">业务迭代的不断增多，也使得 API 网关堆积了很多的业务逻辑，这些业务逻辑分散在不同的 filter 中，为了降低开发成本，网关只有一套主线分支，不同集群部署的代码完全相同，但是不同集群的业务属性不同，所需要的 filter 逻辑是不一样的；如内网网关集群几乎没什么业务逻辑，但是 App 集群可能需要几十个 filter 的逻辑协同工作；这样的一套代码对内网网关而言，存在着大量的性能浪费；如何平衡维护成本和运行效率是个需要思考的问题。</p><span id="OSC_h2_5"></span><h2>稳定性风险</h2><p style="color:#24292f; text-align:start">API 网关作为基础服务，承载全站的流量出入，稳定性无疑是第一优先级，但其定位决定了绝不可能是一个简单的代理层，在稳定运行的同时依然需要承接大量业务需求，例如 C 端用户登录下线能力，App 强升能力，B 端场景下的鉴权能力等；很难想象较长一段时间以来，网关都保持着双周一次的发版频率；频繁的发版也带来了一些问题，实例启动初期有很多资源需要初始化，此时承接的流量处理时间较长，存在着明显的接口超时现象；早期的每次发版几乎都会导致下游服务的接口短时间内超时率大幅提高，而且往往涉及多个服务一起出现类似情况；为此甚至拉了一个网关发版公告群，提前置顶发版公告，让业务同学和 NOC 有一个心里预期；在发布升级期间尽可能让业务服务无感知这是个刚需。</p><span id="OSC_h2_6"></span><h2>定制能力</h2><p style="color:#24292f; text-align:start">流量灰度是网关最常见的功能之一，对于新版本迭代，业务服务的某个节点发布新版本后希望引入少部分流量试跑观察，但很遗憾 SCG 原生并不支持，需要对负载均衡算法进行手动改写才可以，此外基于流量特征的定向节点路由也需要手动开发，在 SCG 中整个负载均衡算法属于比较核心的模块，不对外直接暴露，存在较高的改造成本。</p><p style="color:#24292f; text-align:start">B 端业务和 C 端业务存在着很大的不同，例如对接口的响应时间的忍受度是不一样的，B 端场景下下载一个报表用户可以接受等待 10s 或者 1 分钟，但是 C 端用户现在没有这个耐心。作为代理层针对以上的场景，我们需要针对不同接口定制不同的超时时间，原生的 SCG 显然也不支持。</p><p style="color:#24292f; text-align:start">诸如此类的定制需求还有很多，我们并不寄希望于开源产品能够开箱即用满足全部需求，但至少定制性拓展性足够好。上手改造成本低。</p><span id="OSC_h1_7"></span><h1>二、技术痛点</h1><p style="color:#24292f; text-align:start">SCG 主要使用了 webflux 技术，webflux 的底层构建在 reactor-netty 之上，而 reactor-netty 构建于 netty 之上；SCG 能够和 spring cloud 的技术栈的各组件，完美适配，做到开箱即用，以较低的使用成本助力得物早期的业务快速发展；但是使用 webflux 也是需要付出一定成本，首先它会额外增加编码人员的心智负担，需要理解流的概念和常用的操作函数，诸如 map, flatmap, defer 等等；其次异步非阻塞的编码形式，充斥着大量的回调函数，会导致顺序性业务逻辑被割裂开来，增加代码阅读理理解成本；此外经过多方面评估我们发现 SCG 存在以下缺点：</p><span id="OSC_h2_8"></span><h2>内存泄露问题</h2><p style="color:#24292f">SCG 存在较多的内存泄漏问题，排查困难，且官方迟迟未能修复，长期运行会导致服务触发 OOM 并宕机；以下为 github 上 SCG 官方开源仓库的待解决的内存泄漏问题，大约有 16 个之多。</p><p style="color:#24292f; text-align:center"><img alt="80.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/80.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 内存泄漏 BUG</p><p style="color:#24292f">下图可以看到 SCG 在长期运行的过程中内存使用一直在增长，<strong>当增长到机器内存上限时当前节点将不可用，联系到网关单节点所承接的 QPS 在几千，可想而知节点宕机带来的危害有多大</strong>；一段时间以来我们需要对 SCG 网关做定期重启。</p><p style="color:#24292f; text-align:center"><img alt="078.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/078.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 生产实例内存增长趋势</p><span id="OSC_h2_9"></span><h2>响应式编程范式复杂</h2><p style="color:#24292f">基于 webflux 中的 flux 和 mono ，在对 request 和 response 信息读取修改时，编码复杂度高，代码理解困难，下图是对 body 信息进行修改时的代码逻辑。</p><p style="color:#24292f; text-align:center"><img alt="607.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/607.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">对 requestBody 进行修改的方式</p><span id="OSC_h2_10"></span><h2>多层抽象的性能损耗</h2><p style="color:#24292f; text-align:start">尽管相比于传统的阻塞式网关，SCG 的性能已经足够优秀，但相比原生的 netty 仍然比较低下，SCG 依赖于 webflux 编程范式，webflux 构建于 reactor-netty 之上，reactor-netty 构建于 netty 之上，多层抽象存在较大的性能损耗。<span>&nbsp;</span></p><p style="color:#24292f; text-align:start"><img alt="106.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/106.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 依赖层级</p><p style="color:#24292f">一般认为程序调用栈越深性能越差；下图为只有一个 filter 的情况下的调用栈，可以看到存在大量的 webflux 中的 subscribe() 和 onNext() 方法调用,这些方法的执行不关联任何业务逻辑，属于纯粹的框架运行层代码，粗略估算下没有引入任何逻辑的情况下 SCG 的调用栈深度在 90+ ，如果引入多个 filter 处理不同的业务逻辑，线程栈将进一步加深，<strong>当前网关的业务复杂度实际栈深度会达到 120 左右，也就是差不多有四分之三的非业务栈损耗，这个比例是有点夸张的。</strong></p><p style="color:#24292f; text-align:center"><img alt="205.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/205.png" referrerpolicy="no-referrer"><img alt="200.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/200.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG filter 调用栈深度</p><span id="OSC_h2_11"></span><h2>路由能力不完善</h2><p style="color:#24292f">原生的的 SCG 并不支持动态路由管理，路由的配置信息通过大量的 KV 配置来做，平均一个路由配置需要三到四条 KV 配置信息来支撑，这些配置数据一般放在诸如 Apollo 或者 ark 这样的配置中心，即使是添加了新的配置 SCG 并不能动态识别，需要引入动态刷新路由配置的能力。另一方面路由匹配算法通过遍历所有的路由信息逐一匹配的模式，当接口级别的路由数量急剧膨胀时，性能是个严重问题。</p><p style="color:#24292f; text-align:center"><img alt="017.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/017.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 路由匹配算法为 On 时间复杂度</p><span id="OSC_h2_12"></span><h2>预热时间长，冷启动 RT 尖刺大</h2><p style="color:#24292f">SCG 中 LoadBalancerClient 会调用 choose 方法来选择合适的 endpoint 作为本次 RPC 发起调用的真实地址，由于是懒加载，只有在有真实流量触发时才会加载创建相关资源；在触发底层的 NamedContextFactory#getContext 方法时存在一个全局锁导致，woker 线程在该锁上大量等待。</p><p style="color:#24292f; text-align:center"><img alt="769.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/769.png" referrerpolicy="no-referrer">NamedContextFactory#getContext 方法存在全局锁</p><p style="color:#24292f; text-align:center"><img alt="209.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/209.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 发布时超时报错增多</p><span id="OSC_h2_13"></span><h2>定制性差，数据流控制耦合</h2><p style="color:#24292f">SCG 在开发运维过程中已经出现了较多的针对源码改造的场景，如动态路由，路由匹配性能优化等；其设计理念老旧，控制流和数据流混合使用，架构不清晰，如对路由管理操作仍然耦合在 filter 中，即使引入 spring mvc 方式管理，依然绑定使用 webflux 编程范式，同时也无法做到控制流端口独立，存在一定安全风险。</p><p style="color:#24292f; text-align:center"><img alt="9007.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9007.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">filter 中对路由进行管理</p><span id="OSC_h1_14"></span><h1>三、方案调研</h1><span id="OSC_h2_15"></span><h2>理想中的网关</h2><p style="color:#24292f; text-align:start">综合业务需求和技术痛点，我们发现<strong>理想型的网关</strong>应该是这个样子的：</p><ul><li><p>支持海量接口注册，并能够在运行时支持动态添加修改路由信息，具备出色路由匹配性能</p></li><li><p>编程范式尽可能简单，降低开发人员心智负担，同时最好是开发人员较为熟悉的语言</p></li><li><p>性能足够好，至少要等同于目前 SCG 的性能，RT99 线和 ART 较低</p></li><li><p>稳定性好，无内存泄漏，能够长时间持续稳定运行，发布升级期间要尽可能下游无感</p></li><li><p>拓展能力强，支持超时定制，多网络协议支持，http，Dubbo 等，生态完善</p></li><li><p>架构设计清晰，数据流与控制流分离，集成 UI 控制面</p></li></ul><span id="OSC_h2_16"></span><h2>开源网关对比</h2><p style="color:#24292f; text-align:start">基于以上需求，我们对市面上的常见网关进行了调研，以下几个开源方案对比。</p><p style="color:#24292f; text-align:start"><img alt="6078.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6078.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">结合当前团队的技术栈，我们倾向于选择 Java 技术栈的开源产品，唯一可选的只有 zuul2 ，但是 zuul2 路由注册和稳定性方面也不能够满足我们的需求，也没有实现数控分离的架构设计。因此唯有走上自研之路。</p><span id="OSC_h1_17"></span><h1>四、自研架构</h1><p style="color:#24292f; text-align:start">通常而言代理网关分为透明代理与非透明代理，其主要区别在于对于流量是否存在侵入性，这里的侵入性主要是指对请求和响应数据的修改；显然 API Gateway 的定位决定了必然会对流量进行数据调整，常见的调整主要有，添加或者修改 head 信息，加密或者解密 query params head ,以及 requestbody 或者 responseBody，可以说 http 请求的每一个部分数据都存在修改的可能性，这要求代理层必须要完全解析数据包信息，而非简单的做一个路由器转发功能。</p><p style="color:#24292f; text-align:start">传统的服务器架构，以 reactor 架构为主。boss 线程和 worker 线程的明确分工，boss 线程负责连接建立创建；worker 线程负责已经建立的连接的读写事件监听处理，同时会将部分复杂业务的处理放到独立的线程池中，进而避免 worker 线程的执行时间过长影响对网络事件处理的及时性；由于网关是 IO 密集型服务，相对来说计算内容较少，可以不必引入这样的业务线程池；直接基于 netty 原生 reactor 架构实现。</p><span id="OSC_h2_18"></span><h2>Reactor 多线程架构</h2><p style="color:#24292f; text-align:start"><img alt="1009.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1009.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">为了只求极致性能和降低多线程编码的数据竞争，单个请求从接收到转发后端，再到接收后端服务响应，以及最终的回写给 client 端，这一系列操作被设计为完全闭合在一个 workerEventLoop 线程中处理；这需要 worker 线程中执行的 IO 类型操作全部实现异步非阻塞化，确保 worker 线程的高速运转；这样的架构和 NGINX 很类似；我们称之为 thread-per-core 模式。<img alt="1008.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1008.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_19"></span><h2>API 网关组件架构</h2><p style="color:#24292f; text-align:start"><img alt="7008.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/7008.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_20"></span><h2>数据流控制流分离</h2><p style="color:#24292f; text-align:start">数据面板专注于流量代理，不处理任何 admin 类请求，控制流监听独立的端口，接收管理指令。</p><p style="color:#24292f; text-align:start"><img alt="6009.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6009.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h1_21"></span><h1>五、核心设计</h1><span id="OSC_h2_22"></span><h2>请求上下文封装</h2><p style="color:#24292f; text-align:start">新的 API 网关底层仍然基于 Netty，其自带的 http 协议解析 handler 可以直接使用。基于 netty 框架的编程范式，需要在初始化时逐一注册用到的 Handler。<span>&nbsp;</span></p><p style="color:#24292f; text-align:start"><img alt="10035.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/10035.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">Client 到 Proxy 链路 Handler 执行顺序</p><p style="color:#24292f; text-align:start">HttpServerCodec 负责 HTTP 请求的解析；对于体积较大的 Http 请求，客户端可能会拆成多个小的数据包进行发送，因此在服务端需要适当的封装拼接，避免收到不完整的 http 请求；HttpObjectAggregator 负责整个请求的拼装组合。</p><p style="color:#24292f; text-align:start">拿到 HTTP 请求的全部信息后在业务 handler 中进行处理；如果请求体积过大直接抛弃；使用 ServerWebExchange 对象封装请求上下文信息，其中包含了 client2Proxy 的 channel, 以及负责处理该 channel 的 eventLoop 线程等信息，考虑到整个请求的处理过程中可能在不同阶段传递一些拓展信息，引入了 getAttributes 方法，用于存储需要传递的数据；此外 ServerWebExchange 接口的基本遵循了 SCG 的设计规范，保证了在迁移业务逻辑时的最小化改动；具体到实现类，可以参考如下代码：</p><pre><code>@Getter
  public class DefaultServerWebExchange implements ServerWebExchange {
    private final Channel client2ProxyChannel;
    private final Channel proxy2ClientChannel;
    private final EventLoop executor;
    private ServerHttpRequest request;
    private ServerHttpResponse response;
    private final Map&lt;String, Object&gt; attributes;
 }
</code></pre><p style="text-align:center">DefaultServerWebExchange</p><p style="color:#24292f; text-align:start">Client2ProxyHttpHandler 作为核心的入口 handler 负责将接收到的 FullHttpRequest 进行封装和构建 ServerWebExchange 对象，其核心逻辑如下。可以看到对于数据读取封装的逻辑较为简单，并没有植入常见的业务逻辑，封装完对象后随即调用 Request filter chain。</p><pre><code>@Override
protected void channelRead0(ChannelHandlerContext ctx, FullHttpRequest fullHttpRequest) {
    try {
        Channel client2ProxyChannel = ctx.channel();
        DefaultServerHttpRequest serverHttpRequest = new DefaultServerHttpRequest(fullHttpRequest, client2ProxyChannel);
        ServerWebExchange serverWebExchange = new DefaultServerWebExchange(client2ProxyChannel,(EventLoop) ctx.executor(), serverHttpRequest, null);
        // request filter chain
        this.requestFilterChain.filter(serverWebExchange);
    }catch (Throwable t){
        log.error("Exception caused before filters!\n {}",ExceptionUtils.getStackTrace(t));
        ByteBufHelper.safeRelease(fullHttpRequest);
        throw t;
    }
}
</code></pre><p style="text-align:center">Client2ProxyHttpHandler 精简后的代码</p><span id="OSC_h2_23"></span><h2>FilterChain 设计</h2><p style="color:#24292f; text-align:start">FilterChain 可以解决异步请求发送出去后，还没收到响应，但是顺序逻辑已经执行完成的尴尬；例如当我们在上文的。</p><p style="color:#24292f; text-align:start">channelRead0 方法中发起某个鉴权 RPC 调用时，出于性能考虑只能使用非阻塞的方式，按照 netty 的非阻塞编码 API 最终要引入类似如下的 callback 机制，++在业务逻辑上在没有收到 RPC 的响应之前该请求的处理应该「暂停」，等待收到响应时才能继续后续的逻辑执行++; 也就是下面代码中的下一步执行逻辑并不能执行，正确的做法是将 nextBiz() 方法包裹在 callBack() 方法内，由 callBack() 触发后续逻辑的执行；这只是发起一次 RPC 调用的情况，在实际的的日常研发过程中存在着鉴权，风控，集群限流（Redis）等多次 RPC 调用，这就导致这样的非阻塞代码编写将异常复杂。</p><pre><code>ChannelFuture writeFuture = channel.writeAndFlush(asyncRequest.httpRequest);
    writeFuture.addListener(future -&gt; {
                if(future.isSuccess()) {
                   callBack();
                }
            }
    );
    nextBiz()；
</code></pre><p style="text-align:center">非阻塞调用下的业务逻辑编排</p><p style="color:#24292f; text-align:start">对于这样的复杂场景，采用 filterChain 模式可以很好的解决；首先 RequestFilterChain().filter(serverWebExchange); 后不存在任何逻辑；发起请求时 ，当前 filter 执行结束，由于此时没有调用 chain.filter(exchange); 所以不会继续执行下一个 filter，发送请求到下游的逻辑也不会执行；当前请求的处理流程暂时中止，<strong>eventloop 线程将切换到其他请求的处理过程上；当收到 RPC 响应时，chain.filter(exchange) 被执行，之前中断的流程被重新拉起。</strong></p><pre><code>public void filter(ServerWebExchange exchange) {
    if (this.index &lt; filters.size()) {
        GatewayFilter filter = filters.get(this.index);
        DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1);
        try {
            filter.filter(exchange, chain);
        }catch (Throwable e){
            log.error("Filter chain unhandle backward exception! Request path {}, FilterClass: {}, exception: {}", exchange.getRequest().getPath(),   filter.getClass(), ExceptionUtils.getFullStackTrace(e));
            ResponseDecorator.failResponse(exchange,500, "网关内部错误！filter chain exception！");
        }
    }
}
</code></pre><p style="text-align:center">基于 filterChain 的调用模式</p><p style="color:#24292f; text-align:start">对于 filter 的执行需要定义先后顺序，这里参考了 SCG 的方案，每个 filter 返回一个 order 值。不同的地方在于 DAG 的设计不允许 order 值重复，因为在 order 重复的情况下，很难界定到底哪个 Filter 先执行，存在模糊地带，这不是我们期望看到的；DAG 中的 Filter 执行顺序为 order 值从小到大，且不允许 order 值重复。为了易于理解，<strong>这里将 Filter 拆分为了 requestFilter，和 responseFilter；分别代表请求的处理阶段，和拿到下游响应阶段，responseFilter 遵循同样的逻辑执行顺序与不可重复性。</strong></p><pre><code>public interface GatewayFilter extends Ordered {
    void filter(ServerWebExchange exchange, GatewayFilterChain chain);
}

public interface ResponseFilter extends GatewayFilter { }

public interface RequestFilter extends GatewayFilter { }
</code></pre><p style="text-align:center">filter 接口设计</p><span id="OSC_h2_24"></span><h2>路由管理与匹配</h2><p style="color:#24292f; text-align:start">以 SCG 网关注册的路由数量为基准，网关节点的需要支撑的路由规则数量是上万级别的，按照得物目前的业务量，上限不超过 5W，为了保证匹配性能，路由规则放在分布式缓存中显然是不合适的，需要保存在节点的内存中。类似于在 nginx 上配置上万条 location 规则，手动维护难度可想而知，即使在配置中心管理起来也很麻烦，所以需要引入独立路由管理模块。<img alt="1090.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1090.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">在匹配的效率上也需要进一步优化，SCG 的路由匹配策略为普通的循环迭代逐一匹配，时间效率为 On，在路由规则膨胀到万级别后，性能急剧拉胯，结合得物的接口规范，新网关采用 Hash 匹配模式，将匹配效率提升到 O1；hash 的 key 为接口的 path, 需要强调的是在同一个网关集群中，path 是唯一的，这里的 path 并不等价于业务服务的接口 path, 绝大多数时候存在一些剪裁，例如在业务服务的编写的/order/detail 接口，在网关实际注册的接口可能为/api/v1/app/order/detail；由于使用了 path 作为 key 进行 hash 匹配。常见的 restful 接口显然是不支持的，确切的讲基于 path 传参数模式的接口均不支持；出于某些历史原因，网关保留了类似 nginx 的前缀匹配的支持，但是这部分功能不对外开放。</p><pre><code>public class Route implements Ordered {
    private final String id;
    private final int skipCount;
    private final URI uri;
 }
</code></pre><p style="text-align:center">route 类设计</p><p style="color:#24292f; text-align:start">route 的 URI 字段中包含了，需要路由到的具体服务名，这里也可以称之为 host ，route 信息会暂存在 exchange 对象的 attributes 属性中, 在后续的 loadbalance 阶段 host 信息会被进一步替换为真实的 endpoint。</p><pre><code>private Route lookupRoute(ServerWebExchange exchange) {
    String path = exchange.getRequest().getPath();
    CachingRouteLocator locator = (CachingRouteLocator) routeLocator;
    Route exactRoute = pathRouteMap.getOrDefault(path, null);
    if (exactRoute != null) {
        exchange.getAttributes().put(DAGApplicationConfig.GATEWAY_ROUTE_CACHE, route);
        return exactRoute;
    }
}
</code></pre><p style="text-align:center">路由匹配逻辑</p><span id="OSC_h2_25"></span><h2>单线程闭环</h2><p style="color:#24292f; text-align:start">为了更好地利用 CPU，以及减少不必要的数据竞争，++将单个请求的处理全部闭合在一个线程当中++；这意味着这个请求的业务逻辑处理，RPC 调用，权限验证，限流 token 获取都将始终由某个固定线程处理。netty 中，网络连接被抽象为 channel，channel 与 eventloop 线程的对应关系为 N 对 1，一个 channel 仅能被一个 eventloop 线程所处理，这在处理用户请求时没有问题，但是在接收请求完毕向下游转发请求时，我们碰到了一些挑战，下游的连接往往是连接池在管理，连接池的管理是另一组 eventLoop 线程在负责，++为了保持闭环需要将连接池的线程设定为处理当前请求的线程++，并且只能是这一个线程；这样一来，默认状态下启动的 N 个线程（N 与机器核心数相同），分别需要管理一个连接池；thread-per-core 模式的性能已经在 nginx 开源组件上得到验证。<img alt="659.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/659.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_26"></span><h2>连接管理优化</h2><p style="color:#24292f; text-align:start">为了满足单线程闭环，需要将连接池的管理线程设置为当前的 eventloop 线程，最终我们通过 threadlocal 进行线程与连接池的绑定；通常情况下 netty 自带的连接池 FixedChannelPool 可以满足我们大部分场景下的需求，这样的连接池也是适用于多线程的场景；由于新网关使用 thread-per-core 模式并将请求处理的全生命周期闭合在单个线程中，所有为了线程安全的额外操作不再必要且存在性能浪费；为此需要对原生连接池做一些优化, 连接的获取和释放简化为对链表结构的简单 getFirst , addLast。</p><p style="color:#24292f; text-align:start">对于 RPC 而言，无论是 HTTP，还是 Dubbo，Redis 等最终底层都需要用到 TCP 连接，将构建在 TCP 连接上的数据解析协议与连接剥离后，我们发现这种纯粹的连接管理是可以复用的，对于连接池而言不需要知道具体连接的用途，只需要维持到特定 endpoint 的连接稳定即可，那么这里的 RPC 服务的连接仍然可以放入连接池中进行托管；最终的连接池设计架构图。<img alt="1300.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1300.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_27"></span><h2>AsyncClient 设计</h2><p style="color:#24292f; text-align:start">对于七层流量而言基本全部都是 Http 请求，同样在 RPC 请求中 http 协议也占了大多数，考虑到还会存在少量的 dubbo, Redis 等协议通信的场景。因此需要抽象出一套异步调用框架来支撑；这样的框架需要具备超时管理，回调执行，错误输出等功能，更重要的是具备协议无关性质， 为了更方便使用需要支持链式调用。</p><p style="color:#24292f; text-align:start">发起一次 RPC 调用通常可以分为以下几步：</p><ol><li>获取目标地址和使用的协议, 目标服务为集群部署时，需要使用 loadbalance 模块</li><li>封装发送的请求，这样的请求在应用层可以具体化为某个 Request 类，网络层序列化为二进制数据流</li><li>出于性能考虑选择非阻塞式发送，发送动作完成后开始计算超时</li><li>接收数据响应，由于采用非阻塞模式，这里的发送线程并不会以 block 的方式等待数据</li><li>在超时时间内完成数据处理，或者触发超时导致连接取消或者关闭<img alt="9006.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9006.jpeg" referrerpolicy="no-referrer"></li></ol><p style="color:#24292f">AsyncClient 模块内容并不复杂，AsyncClient 为抽象类不区分使用的网络协议；ConnectionPool 作为连接的管理者被 client 所引用，<strong>获取连接的 key 使用 protocol+ip+port 再适合不过</strong>；通常在某个具体的连接初始化阶段就已经确定了该 channel 所使用的协议，因此初始化时会直接绑定协议 Handler；当协议为 HTTP 请求时，HttpClientCodec 为 HTTP 请求的编解码 handler；也可以是构建在 TCP 协议上的 Dubbo, Mysql ,Redis 等协议的 handler。</p><p style="color:#24292f; text-align:start">首先对于一个请求的不同执行阶段需要引入状态定位，这里引入了 STATE 枚举：</p><pre><code>enum STATE{
        INIT,SENDING,SEND,SEND_SUCCESS,FAILED,TIMEOUT,RECEIVED
}
</code></pre><p style="color:#24292f; text-align:start">其次在执行过程中设计了 AsyncContext 作为信息存储的载体，内部包含 request 和 response 信息，作用类似于上文提到的 ServerWebExchange；channel 资源从连接池中获取，使用完成后需要自动放回。</p><pre><code>public class AsyncContext&lt;Req, Resp&gt; implements Cloneable{
    STATE state = STATE.INIT;
    final Channel usedChannel;
    final ChannelPool usedChannelPool;
    final EventExecutor executor;
    final AsyncClient&lt;Req, Resp&gt; agent;
    
    Req request;
    Resp response;
    
    ResponseCallback&lt;Resp&gt; responseCallback;
    ExceptionCallback exceptionCallback;
    
    int timeout;
    long deadline;
    long sendTimestamp;

    Promise&lt;Resp&gt; responsePromise;
}
</code></pre><p style="text-align:center">AsyncContext</p><p style="color:#24292f; text-align:start">AsyncClient 封装了基本的网络通信能力，不拘泥于某个固定的协议，可以是 Redis, http，Dubbo 等。当将数据写出去之后，该 channel 的非阻塞调用立即结束，在没有收到响应之前无法对 AsyncContext 封装的数据做进一步处理，如何在收到数据时将接收到的响应和之前的请求管理起来这是需要面对的问题，channel 对象，的 attr 方法可以用于临时绑定一些信息，以便于上下文切换时传递数据，可以在发送数据时将 AsyncContext 对象绑定到该 channel 的某个固定 key 上。当 channel 收到响应信息时，在相关的 AsyncClientHandler 里面取出 AsyncContext。</p><pre><code>public abstract class AsyncClient&lt;Req, Resp&gt; implements Client {
    private static final int defaultTimeout = 5000;
    private final boolean doTryAgain = false;
    private final ChannelPoolManager channelPoolManager = ChannelPoolManager.getChannelPoolManager();
    protected static AttributeKey&lt;AsyncRequest&gt; ASYNC_REQUEST_KEY = AttributeKey.valueOf("ASYNC_REQUEST");

    public abstract ApplicationProtocol getProtocol();
    
    public AsyncContext&lt;Req, Resp&gt; newRequest(EventExecutor executor, String endpoint, Req request) {
        final ChannelPoolKey poolKey = genPoolKey(endpoint);
        ChannelPool usedChannelPool = channelPoolManager.acquireChannelPool(executor, poolKey);
        return new AsyncContext&lt;&gt;(this,executor,usedChannelPool,request, defaultTimeout, executor.newPromise());
    }

    public void submitSend(AsyncContext&lt;Req, Resp&gt; asyncContext){
        asyncContext.state = AsyncContext.STATE.SENDING;
        asyncContext.deadline = asyncContext.timeout + System.currentTimeMillis();   
        ReferenceCountUtil.retain(asyncContext.request);
        Future&lt;Resp&gt; responseFuture = trySend(asyncContext);
        responseFuture.addListener((GenericFutureListener&lt;Future&lt;Resp&gt;&gt;) future -&gt; {
            if(future.isSuccess()){
                ReferenceCountUtil.release(asyncContext.request);
                Resp response = future.getNow();
                asyncContext.responseCallback.callback(response);
            }
        });
    }
    /**
     * 尝试从连接池中获取连接并发送请求，若失败返回错误
     */
    private Promise&lt;Resp&gt; trySend(AsyncContext&lt;Req, Resp&gt; asyncContext){
        Future&lt;Channel&gt; acquireFuture = asyncContext.usedChannelPool.acquire();
        asyncContext.responsePromise = asyncContext.executor.newPromise();
        acquireFuture.addListener(new GenericFutureListener&lt;Future&lt;Channel&gt;&gt;() {
                @Override
                public void operationComplete(Future&lt;Channel&gt; channelFuture) throws Exception {
                    sendNow(asyncContext,channelFuture);
                }
        });
        return asyncContext.responsePromise;
    }

    private void sendNow(AsyncContext&lt;Req, Resp&gt; asyncContext, Future&lt;Channel&gt; acquireFuture){
        boolean released = false;
        try {
            if (acquireFuture.isSuccess()) {
                NioSocketChannel channel = (NioSocketChannel) acquireFuture.getNow();
                released = true;
                assert channel.attr(ASYNC_REQUEST_KEY).get() == null;
                asyncContext.usedChannel = channel;
                asyncContext.state = AsyncContext.STATE.SEND;
                asyncContext.sendTimestamp = System.currentTimeMillis();
                channel.attr(ASYNC_REQUEST_KEY).set(asyncContext);
                ChannelFuture writeFuture = channel.writeAndFlush(asyncContext.request);
                channel.eventLoop().schedule(()-&gt; doTimeout(asyncContext), asyncContext.timeout, TimeUnit.MILLISECONDS);
            } else {
                asyncContext.responsePromise.setFailure(acquireFuture.cause());
            }
        } catch (Exception e){
            throw new Error("Unexpected Exception.............!");
        }finally {
            if(!released) {
                ReferenceCountUtil.safeRelease(asyncContext.request);
            }
        }
    }
}
</code></pre><p style="text-align:center">AsyncClient 核心源码</p><pre><code>public class AsyncClientHandler extends SimpleChannelInboundHandler {
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception {
        AsyncContext asyncContext = ctx.attr(AsyncClient.ASYNC_REQUEST_KEY).get();
        try {
            asyncContext.state = AsyncContext.STATE.RECEIVED;
            asyncContext.releaseChannel();
            asyncContext.responsePromise.setSuccess(msg);
        }catch (Throwable t){
            log.error("Exception raised when set Success callback. Exception \n: {}", ExceptionUtils.getFullStackTrace(t));
            ByteBufHelper.safeRelease(msg);
            throw t;
        }
    }
}
</code></pre><p style="text-align:center">AsyncClientHandler</p><p style="color:#24292f; text-align:start">通过上面几个类的封装得到了一个易用使用的 AsyncClient，下面的代码为调用权限系统的案例：</p><pre><code>final FullHttpRequest httpRequest = HttpRequestUtil.getDefaultFullHttpRequest(newAuthReq, serviceInstance, "/auth/newCheckSls");
asyncClient.newRequest(exchange.getExecutor(), endPoint,httpRequest)
        .timeout(timeout)
        .onComplete(response -&gt; {
            String checkResultJson = response.content().toString(CharsetUtil.UTF_8);
            response.release();
            NewAuthResult result = Jsons.parse(checkResultJson,NewAuthResult.class);
            TokenResult tokenResult = this.buildTokenResult(result);
            String body = exchange.getAttribute(DAGApplicationConfig.REQUEST_BODY);

            if (tokenResult.getUserInfoResp() != null) {
                UserInfoResp userInfo = tokenResult.getUserInfoResp();
                headers.set("userid", userInfo.getUserid() == null ? "" : String.valueOf(userInfo.getUserid()));
                headers.set("username", StringUtils.isEmpty(userInfo.getUsername()) ? "" : userInfo.getUsername());
                headers.set("name", StringUtils.isEmpty(userInfo.getName()) ? "" : userInfo.getName());
                chain.filter(exchange);
            } else {
                log.error("{},heads: {},response: {}", path, headers, tokenResult);
                int code = tokenResult.getCode() != null ? tokenResult.getCode().intValue() : ResultCode.UNAUTHO.code;
                ResponseDecorator.failResponse(exchange, code, tokenResult.getMsg());
            }
        })
        .onError(throwable -&gt; {
            log.error("Request service {},occur an exception {}",endPoint, throwable);
            ResponseDecorator.failResponseWithStatus(exchange,HttpResponseStatus.INTERNAL_SERVER_ERROR,"AuthFilter 验证失败");
        })
        .sendRequest();
</code></pre><p style="text-align:center">asyncClient 的使用</p><span id="OSC_h2_28"></span><h2>请求超时管理</h2><p style="color:#24292f; text-align:start">一个请求的处理时间不能无限期拉长， 超过某个阈值的情况下 App 的页面会被取消 ，长时间的加载卡顿不如快速报错带来的体验良好；显然网关需要针对接口做超时处理，尤其是在向后端服务发起请求的过程，通常我们会设置一个默认值，例如 3 秒钟，超过这个时间网关会向请求端回写 timeout 的失败信息，由于网关下游接入的服务五花八门，可能是 RT 敏感型的 C 端业务，也可能是逻辑较重 B 端服务接口，甚至是存在大量计算的监控大盘接口。这就导致不同接口对超时时间的诉求不一样，因此针对每个接口的超时时间设定应该被独立出来，而不是统一配置成一个值。</p><pre><code>asyncClient.newRequest(exchange.getExecutor(), endPoint,httpRequest)
        .timeout(timeout)
        .onComplete(response -&gt; {
            String checkResultJson = response.content().toString(CharsetUtil.UTF_8);
            //..........
        })
        .onError(throwable -&gt; {
            log.error("Request service {},occur an exception {}",endPoint, throwable);
            ResponseDecorator.failResponseWithStatus(exchange,HttpResponseStatus.INTERNAL_SERVER_ERROR,"AuthFilter 验证失败");
        })
        .sendRequest();
</code></pre><p style="color:#24292f; text-align:start">asyncClient 的链式调用设计了 timeout 方法，用于传递超时时间，我们可以通过一个全局 Map 来配置这样的信息。</p><p style="color:#24292f; text-align:start">Map&lt;String,Integer&gt; 其 key 为全路径的 path 信息，V 为设定的超时时间，单位为 ms, 至于 Map 的信息在实际配置过程中如何承载，使用 ARK 配置或者 Mysql 都很容易实现。处于并发安全和性能的极致追求，超时事件的设定和调度最好能够在与当前 channel 绑定的线程中执行，庆幸的是 EventLoop 线程自带 schedule 方法。具体来看上文的 AsyncClient 的 56 行。schedule 方法内部以堆结构的方式实现了对超时时间进行管理，整体性能尚可。</p><span id="OSC_h2_29"></span><h2>堆外内存管理优化</h2><p style="color:#24292f; text-align:start">常见的堆外内存手动管理方式无非是引用计数，不同处理逻辑可能针对 RC (引用计数) 的值做调整，到某个环节的业务逻辑处理后已经不记得当前的引用计数值是多少了，甚至是前面的 RC 增加了，后面的 RC 忘记减少了；但换个思路，在数据回写给客户端后我们肯定要把这个请求整个生命周期所申请的堆外内存全部释放掉，堆外内存在回收的时候条件只有一个，就是 RC 值为 0 ，那么在最终的 release 的时候，我们引入一个 safeRelase 的思路 , 如果当前的 RC&gt;0 就不停的 release ，直至为 0；因此只要把这样的逻辑放在 netty 的最后一个 Handler 中即可保证内存得到有效释放。</p><pre><code>public static void safeRelease(Object msg){
    if(msg instanceof ReferenceCounted){
        ReferenceCounted ref = (ReferenceCounted) msg;
        int refCount = ref.refCnt();
        for(int i=0; i&lt;refCount; i++){
            ref.release();
        }
    }
}
</code></pre><p style="text-align:center">safeRelease</p><span id="OSC_h2_30"></span><h2>响应时间尖刺优化</h2><p style="color:#24292f; text-align:start">由于 DAG 选择了复用 spring 的 loadbalance 模块，但这样一来就会和 SCG 一样存在启动初期的响应时间尖刺问题；为此我们进一步分析 RibbonLoadBalancerClient 的构建过程，发现其用到了 NamedContextFactory，该类的 contexts 变量保存了每一个 serviceName 对应的一个独立 context，这种使用模式带来大量的性能浪费。</p><pre><code>public abstract class NamedContextFactory&lt;C extends NamedContextFactory.Specification&gt;implements DisposableBean, ApplicationContextAware {
    //1. contexts 保存 key -&gt; ApplicationContext 的 map
    private Map&lt;String, AnnotationConfigApplicationContext&gt; contexts = new ConcurrentHashMap&lt;&gt;();
    //........
}
</code></pre><p style="color:#24292f; text-align:start">在实际运行中 RibbonLoadBalancerClient 会调用 choose 方法来选择合适的 endpoint 作为本次 RPC 发起调用的真实地址；choose 方法执行过程中会触发 getLoadBalancer() 方法执行，可以看到该方法的可以按照传入的 serviceId 获取专属于这个服务的 LoadBalancer，事实上这样的设计有点多此一举。大部分情况下，每个服务的负载均衡算法都一致的，完全可以复用一个 LoadBalancer 对象；该方法最终是从 spring 容器中获取 LoadBalancer。</p><pre><code>class  RibbonLoadBalancerClient{
    //..........
    private SpringClientFactory clientFactory;
    
    @Override
    public ServiceInstance choose(String serviceId) {
       return choose(serviceId, null);
    }
    
    public ServiceInstance choose(String serviceId, Object hint) {
       Server server = getServer(getLoadBalancer(serviceId), hint);
       if (server == null) {
          return null;
       }
       return new RibbonServer(serviceId, server, isSecure(server, serviceId),
             serverIntrospector(serviceId).getMetadata(server));
    }
    
    protected ILoadBalancer getLoadBalancer(String serviceId) {
       return this.clientFactory.getLoadBalancer(serviceId);
    }
    //.........
}
</code></pre><p style="text-align:center">RibbonLoadBalancerClient</p><p style="color:#24292f; text-align:start"><strong>由于是懒加载，实际流量触发下才会执行，因此第一次执行时，RibbonLoadBalancerClient 对象并不存在，需要初始化创建，创建时大量线程并发调用 SpringClientFactory#getContext 方法，锁在同一个对象上，出现大量的 RT 尖刺。这也解释了为什么 SCG 网关在发布期间会出现响应时间大幅度抖动的现象。</strong></p><pre><code>public class SpringClientFactory extends NamedContextFactory&lt;RibbonClientSpecification&gt;{
    //............    
    protected AnnotationConfigApplicationContext getContext(String name) {
       if (!this.contexts.containsKey(name)) {
          synchronized (this.contexts) {
             if (!this.contexts.containsKey(name)) {
                this.contexts.put(name, createContext(name));
             }
          }
       }
       return this.contexts.get(name);
    }
    //.........
}
</code></pre><p style="text-align:center">SpringClientFactory</p><p style="color:#24292f; text-align:start">在后期的压测过程中，发现 DAG 的线程数量远超预期，基于 thread-per-core 的架构模式下，过多的线程对性能损害比较大，尤其是当负载上升到较高水位时。上文提到<strong>默认情况下，每个服务都会创建独立 loadBalanceClient , 而在其内部又会启动独立的线程去同步当前关联的 serviceName 对应的可用 serverList</strong>,网关的特殊性导致需要接入的服务数量极为庞大，进而导致运行一段时间后 DAG 的线程数量急剧膨胀，对于同步 serverList 这样的动作而言，完全可以采用非阻塞的方式从注册中心拉取相关的 serverList , 这种模式下单线程足以满足性能要求。</p><p style="color:#24292f; text-align:start"><img alt="1078.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1078.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">serverList 的更新前后架构对比</p><p style="color:#24292f; text-align:start">通过预先初始化的方式以及全局只使用 1 个 context 的方式，可以将这里冷启动尖刺消除，改造后的测试结果符合预期。<img alt="6034.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6034.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">通过进一步修改优化 spring loadbalance serverList 同步机制，降低 90% 线程数量的使用。</p><p style="color:#24292f; text-align:start"><img alt="879.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/879.png" referrerpolicy="no-referrer"></p><p style="text-align:center">优化前线程数量（725）</p><p style="color:#24292f; text-align:start"><img alt="779.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/779.png" referrerpolicy="no-referrer"></p><p style="text-align:center">优化后线程数量（72）</p><span id="OSC_h2_31"></span><h2>集群限流改造优化</h2><p style="color:#24292f; text-align:start">首先来看 DAG 启动后 sentinel 相关线程，类似的问题，线程数量非常多，需要针对性优化。<img alt="234.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/234.png" referrerpolicy="no-referrer"></p><p style="text-align:center">Sentinel 线程数</p><p style="color:#24292f; text-align:start">sentinel 线程分析优化：</p><p style="color:#24292f; text-align:start"><img alt="120.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/120.jpeg" referrerpolicy="no-referrer"><img alt="220.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/220.png" referrerpolicy="no-referrer"></p><p style="text-align:center">最终优化后的线程数量为 4 个</p><p style="color:#24292f; text-align:start">sentinel 原生限流源码分析如下，进一步分析 SphU#entry 方法发现其底调用 FlowRuleCheck#passClusterCheck；<strong>在 passClusterCheck 方法中发现底层网络 IO 调用为阻塞式</strong>，由于该方法的执行线程为 workerEventLoop，因此需要使用上文提到的 AsyncClient 进行优化。</p><pre><code>private void doSentinelFlowControl(ServerWebExchange exchange, GatewayFilterChain chain, String resource){
    Entry urlEntry = null;
    try {
        if (!StringUtil.isEmpty(resource)) {
            //1. 检测是否限流
            urlEntry = SphU.entry(resource, ResourceTypeConstants.COMMON_WEB, EntryType.IN);
        }
       //2. 通过，走业务逻辑
        chain.filter(exchange);
    } catch (BlockException e) {
        //3. 拦截，直接返回 503
        ResponseDecorator.failResponseWithStatus(exchange, HttpResponseStatus.SERVICE_UNAVAILABLE, ResultCode.SERVICE_UNAVAILABLE.message);
    } catch (RuntimeException e2) {
        Tracer.traceEntry(e2, urlEntry);
        log.error(ExceptionUtils.getFullStackTrace(e2));
        ResponseDecorator.failResponseWithStatus(exchange, HttpResponseStatus.INTERNAL_SERVER_ERROR,HttpResponseStatus.INTERNAL_SERVER_ERROR.reasonPhrase());
    } finally {
        if (urlEntry != null) {
            urlEntry.exit();
        }
        ContextUtil.exit();
    }
}
</code></pre><p style="text-align:center">SentinelGatewayFilter（sentinel 适配 SCG 的逻辑）</p><pre><code>public class RedisTokenService implements InitializingBean {
    private final RedisAsyncClient client = new RedisAsyncClient();
    private final RedisChannelPoolKey connectionKey;
    
    public RedisTokenService(String host, int port, String password, int database, boolean ssl){
        connectionKey = new RedisChannelPoolKey(String host, int port, String password, int database, boolean ssl);
    }
    //请求 token
    public Future&lt;TokenResult&gt; asyncRequestToken(ClusterFlowRule rule){
        ....
        sendMessage(redisReqMsg,this.connectionKey)
    }
    
    private Future&lt;TokenResult&gt; sendMessage(RedisMessage requestMessage, EventExecutor executor, RedisChannelPoolKey poolKey){
        AsyncRequest&lt;RedisMessage,RedisMessage&gt; request = client.newRequest(executor, poolKey,requestMessage);
        DefaultPromise&lt;TokenResult&gt; tokenResultFuture = new DefaultPromise&lt;&gt;(request.getExecutor());

        request.timeout(timeout)
                .onComplete(response -&gt; {
                    ...
                    tokenResultFuture.setSuccess(response);
                })
                .onError(throwable -&gt; {
                    ...
                    tokenResultFuture.setFailure(throwable);
                }).sendRequest();

        return tokenResultFuture;
    }
}
</code></pre><p style="text-align:center">RedisTokenService</p><p style="color:#24292f; text-align:start">最终的限流 Filter 代码如下：</p><pre><code>public class SentinelGatewayFilter implements RequestFilter {
    @Resource
    RedisTokenService tokenService;\
    
    @Override
    public void filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //当前为 netty NioEventloop 线程
        ServerHttpRequest request = exchange.getRequest();
        String resource = request.getPath() != null ? request.getPath() : "";
  
        //判断是否有集群限流规则
        ClusterFlowRule rule = ClusterFlowManager.getClusterFlowRule(resource);
        if (rule != null) {
           //异步非阻塞请求 token
            tokenService.asyncRequestToken(rule,exchange.getExecutor())
                    .addListener(future -&gt; {
                        TokenResult tokenResult;
                        if (future.isSuccess()) {
                            tokenResult = (TokenResult) future.getNow();
                        } else {
                            tokenResult = RedisTokenService.FAIL;
                        }
                        if(tokenResult == RedisTokenService.FAIL || tokenResult == RedisTokenService.ERROR){
                            log.error("Request cluster token failed, will back to local flowRule check");
                        }
                        ClusterFlowManager.setTokenResult(rule.getRuleId(), tokenResult);
                        doSentinelFlowControl(exchange, chain, resource);
                    });
        } else {
            doSentinelFlowControl(exchange, chain, resource);
        }
    }
}
</code></pre><p style="text-align:center">改造后适配 DAG 的 SentinelGatewayFilter</p><span id="OSC_h1_32"></span><h1>六、压测性能</h1><span id="OSC_h2_33"></span><h2>DAG 高压表现</h2><p style="color:#24292f; text-align:start">wrk -t32 -c1000 -d60s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">DAG 网关的 QPS、实时 RT、错误率、CPU、内存监控图；<strong>在 CPU 占用 80% 情况下，能够支撑的 QPS 在 4.5W。</strong><img alt="657.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/657.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 网关的 QPS、RT 折线图</p><p style="color:#24292f; text-align:start"><img alt="645.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/645.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>DAG 在 CPU 占用 80% 情况下，能够支撑的 QPS 在 4.5W，ART 19ms</strong></p><span id="OSC_h2_34"></span><h2>SCG 高压表现</h2><p style="color:#24292f; text-align:start">wrk -t32 -c1000 -d60s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">SCG 网关的 QPS、实时 RT、错误率、CPU、内存监控图：<img alt="3410.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/3410.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">SCG 网关的 QPS、RT 折线图：<img alt="1670.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1670.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>SCG 在 CPU 占用 95% 情况下，能够支撑的 QPS 在 1.1W，ART 54.1ms</strong></p><span id="OSC_h2_35"></span><h2>DAG 低压表现</h2><p style="color:#24292f; text-align:start">wrk -t5 -c20 -d120s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">DAG 网关的 QPS、实时 RT、错误率、CPU、内存：<img alt="1354.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1354.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 网关的 QPS、RT 折线图：</p><p style="color:#24292f; text-align:start"><img alt="1·.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1%C2%B7.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>DAG 在 QPS 1.1W 情况下，CPU 占用 30%，ART 1.56ms</strong></p><span id="OSC_h2_36"></span><h2>数据对比</h2><p style="color:#24292f; text-align:start"><img alt="00.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/-00.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>结论</strong></p><p style="color:#24292f; text-align:start">满负载情况下，DAG 要比 SCG 的吞吐量高很多，QPS 几乎是 4 倍，RT 反而消耗更低，SCG 在 CPU 被打满后，RT 表现出现严重性能劣化。DAG 的吞吐控制和 SCG 一样情况下，CPU 和 RT 损耗下降了更多。DAG 在最大压力下，内存消耗比较高，达到了 75% 左右，不过到峰值后，就不再会有大幅变动了。对比压测结果，结论令人欣喜，<strong>SCG 作为 Java 生态当前使用最广泛的网关，其性能属于一线水准，DAG 的性能达到其 4 倍以上也是远超意料，这样的结果给与研发同学极大的鼓舞。</strong></p><span id="OSC_h1_37"></span><h1>七、投产收益</h1><span id="OSC_h2_38"></span><h2>安全性提升</h2><p style="color:#24292f; text-align:start"><strong>完善的接口级路由管理</strong></p><p style="color:#24292f; text-align:start">基于接口注册模式的全新路由上线，包含了接口注册的申请人，申请时间，接口场景备注信息等，接口管理更加严谨规范；结合路由组功能可以方便的查询当前服务的所有对外接口信息，某种程度上具备一定的 API 查询管理能力；同时为了缓解用户需要检索的接口太多的尴尬，引入了一键收藏功能，大部分时候用户只需要切换到已关注列表即可。</p><p style="color:#24292f; text-align:start"><img alt="·01.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/%C2%B701.png" referrerpolicy="no-referrer"></p><p style="text-align:center">注册接口列表</p><p style="color:#24292f; text-align:start"><img alt="=0.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/=0.png" referrerpolicy="no-referrer"></p><p style="text-align:center">接口收藏</p><p style="color:#24292f; text-align:start"><strong>防渗透能力极大增强</strong></p><p style="color:#24292f; text-align:start">早期的泛化路由，给黑产的渗透带来了极大的想象空间和安全隐患，甚至可以在外网直接访问某些业务的配置信息。<img alt="701.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/701.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">黑产接口渗透</p><p style="color:#24292f; text-align:start">接口注册模式启用后，所有未注册的接口均无法访问，防渗透能力提升一个台阶，同时自动推送异常接口访问信息。</p><p style="color:#24292f; text-align:start"><img alt="81.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/8-1.png" referrerpolicy="no-referrer"></p><p style="text-align:center">404 接口访问异常推送</p><span id="OSC_h2_39"></span><h2>稳定性增强</h2><p style="color:#24292f; text-align:start"><strong>内存泄漏问题解决</strong></p><p style="color:#24292f; text-align:start">通过一系列手段改进优化和严格的测试，新网关的内存使用更加稳健，内存增长曲线直接拉平，彻底解决了泄漏问题。</p><p style="color:#24292f; text-align:start"><img alt="2300.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/2300.png" referrerpolicy="no-referrer"></p><p style="text-align:center">老网关内存增长趋势</p><p style="color:#24292f; text-align:start"><img alt="789=.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/789=.png" referrerpolicy="no-referrer"></p><p style="text-align:center">新网关内存增长趋势</p><p style="color:#24292f; text-align:start"><strong>响应时间尖刺消除</strong></p><p style="color:#24292f; text-align:start">通过预先初始化 &amp; context 共用等手段，去除了运行时并发创建多个 context 抢占全局锁的开销，冷启动 RT 尖刺降低 99% ；关于 spring load balance 模块的更多优化细节可以参考这篇博客：Spring LoadBalance 存在问题与优化。</p><p style="color:#24292f; text-align:start"><strong>压测数据对比</strong><img alt="1=.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1-=.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>实际生产监控</strong></p><p style="color:#24292f; text-align:start">趋势图上略有差异，但是从非 200 请求的绝对值上看，这种差异可以忽略, <strong>对比发布期间和非发布期间异常请求的数量，发现基本没有区别，这代表着以往的发布期间的响应时间尖刺基本消除，做到了发布期间业务服务彻底无感知。</strong></p><p style="color:#24292f; text-align:start"><img alt="01.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-1.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 4 日发布期间各节点流量变化</p><p style="color:#24292f; text-align:start"><img alt="02.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-2.png" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 4 日异常请求状态数量监控 (发布期间)</p><p style="color:#24292f; text-align:start"><img alt="03.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-3.png" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 5 日异常请求状态数量监控（无发布）</p><span id="OSC_h2_40"></span><h2>降本增效</h2><p style="color:#24292f; text-align:start"><strong>资源占用下降 50% +</strong></p><p style="color:#24292f; text-align:start"><img alt="04.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-4.png" referrerpolicy="no-referrer"></p><p style="text-align:center">SCG 平均 CPU 占用</p><p style="color:#24292f; text-align:start"><img alt="05.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-5.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 资源占用</p><p style="color:#24292f; text-align:start"><strong>JDK17 升级收益</strong></p><p style="color:#24292f">得益于 ZGC 的优秀算法，JVM17 在 GC 暂停时间上取得了出色的成果，网关作为延迟敏感型应用对 GC 的暂停时间尤为看重，为此我们组织升级了 JDK17 版本；下面为同等流量压力情况下的配置不同 GC 的效果对比，<strong>可以看到 GC 的暂停时间从平均 70ms 降低到 1ms 内，RT99 线得到大幅度提升；吞吐量不再受流量波动而大幅度变化，性能表现更加稳定；同时网关的平均响应时间损耗降低 5%。</strong></p><p style="color:#24292f"><img alt="08.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-8.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK8-G1 暂停时间表现</p><p style="color:#24292f; text-align:start"><img alt="09.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/09-.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17-ZGC 暂停时间表现</p><p style="color:#24292f; text-align:start">吞吐量方面，G1 伴随流量的变化呈现出一定的波动趋势，均线在 99.3% 左右。ZGC 的吞吐量则比较稳定，维持在无限接近 100% 的水平。</p><p style="color:#24292f; text-align:start"><img alt="9.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9--.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK8-G1 吞吐量</p><p style="color:#24292f; text-align:start"><img alt="1.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/--1.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17-ZGC 吞吐量</p><p style="color:#24292f; text-align:start">对于实际业务接口的影响，从下图中可以看到平均响应时间有所下降，这里的 RT 差值表示接口经过网关层的损耗时间；不同接口的 RT 差值损耗是不同的，这可能和请求响应体的大小，是否经过登录验证，风控验证等业务逻辑有关。</p><p style="color:#24292f; text-align:start"><img alt="80.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/8-0.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17 与 JDK8 ART 对比</p><p style="color:#24292f; text-align:start">需要指出的是 ZGC 对于一般的 RT 敏感型应用有很大提升， 服务的 RT 99 线得到显著改善。但是如果当前应用大量使用了堆外内存的方式，则提升相对较弱，如大量使用 netty 框架的应用, 因为这些应用的大部分数据都是通过手动释放的方式进行管理。</p><span id="OSC_h1_41"></span><h1>八、思考总结</h1><span id="OSC_h2_42"></span><h2>架构演进</h2><p style="color:#24292f; text-align:start">API 网关的自研并非一蹴而就，而是经历了多次业务迭代循序渐进的过程；从早期的泛化路由引发的安全问题处理，到后面的大量路由注册，带来的匹配性能下降 ，以及最终压垮老网关最后一根稻草的内存泄漏问题；在不同阶段需要使用不同的应对策略，早期业务快速迭代，大量的需求堆积，最快的时候一个功能点的改动需要三四天内上线 ，我们很难有足够的精力去做一些深层次的改造，这个时候需求导向为优先，功能性建设完善优先，是一个快速奔跑的建设期；伴随体量的增长安全和稳定性的重视程度逐步拔高，继而推进了这些方面的大量建设；从拓展 SCG 的原有功能到改进框架源码，以及最终的自研重写，可以说新的 API 网关是一个业务推进而演化出来的产物，也只有这样 」生长「 出来的架构产品才能更好的契合业务发展的需要。</p><span id="OSC_h2_43"></span><h2>技术思考</h2><p style="color:#24292f; text-align:start">开源的 API 网关有很多，但是自研的案例并不多，我们能够参考的方案也很有限。除了几个业界知名的产品外，很多开源的项目参考的价值并不大；从自研的目标来看，我们最基本的要求是性能和稳定性要优于现有的开源产品，至少 Java 的生态是这样；这就要求架构设计和代码质量上必须比现有的开源产品更加优秀，才有可能；为此我们深度借鉴了流量代理界的常青树 Nginx，发现基于 Linux 多进程模型下的 OS，如果要发挥出最大效能，单 CPU 核心支撑单进程（线程）是效率最高的模式。可以将 OS 的进程调度开销最小化同时将高速缓存 miss 降到最低，此外还要尽可能减少或者消除数据竞争，避免锁等待和自旋带来的性能浪费；DAG 的整个技术架构可以简化的理解为引入了独立控制流的多线程版的 Nginx。</p><p style="color:#24292f; text-align:start">中间件的研发创新存在着较高的难度和复杂性，更何况是在业务不断推进中换引擎。在整个研发过程中，为了尽可能适配老的业务逻辑，对原有的业务逻辑的改动最小化，新网关对老网关的架构层接口做了全面适配；换句话说新引擎的对外暴露的核心接口与老网关保持一致，让老的业务逻辑在 0 改动或者仅改动少量几行代码后就能在新网关上直接跑，能够极大幅度降低我们的测试回归成本，因为这些代码本身的逻辑正确性，已经在生产环境得到了大量验证。这样的适配器模式同样适用于其他组件和业务开发。</p><p style="color:#24292f; text-align:start">作为底层基础组件的开发人员，要对自己写下的每一行代码都有清晰的认识，不了解的地方一定要多翻资料，多读源码，模棱两可的理解是绝对不够的；常见的开源组件虽然说大部分代码都是资深开发人员写出来的，但是有程序员的地方就有 bug ，要带着审慎眼光去看到这些组件，而不是一味地使用盲从，所谓尽信书不如无书；很多中间件的基本原理都是相通的，如常见 Raft 协议，基于 epoll 的 reactor 网络架构，存储领域的零拷贝技术，预写日志，常见的索引技术，hash 结构，B+树，LSM 树等等。一个成熟的中间件往往会涉及多个方向的技术内容。研发人员并不需要每一个组件都涉猎极深，也不现实，掌握常见的架构思路和技巧以及一些基本的技术点，做到对一两个组件做到熟稔于心。思考和理解到位了，很容易触类旁通。</p><span id="OSC_h2_44"></span><h2>稳定性把控</h2><p style="color:#24292f; text-align:start">自研基础组件是一项浩大的工程，可以预见代码量会极为庞大，如何有效管理新项目的代码质量是个棘手的问题; 原有业务逻辑的改造也需要回归测试；现实的情况是中间件团队没有专职的测试，质量保证完全依赖开发人员；这就对开发人员的代码质量提出了极高的要求，一方面我们通过与老网关适配相同的代理引擎接口，降低迁移成本和业务逻辑出现 bug 的概率；另一方面还对编码质量提出了高标准，平均每周两到三次的 CodeReview；80% 的单元测试行覆盖率要求。</p><p style="color:#24292f; text-align:start">网关作为流量入口，承接全司最高流量，对稳定性的要求极为苛刻。最理想的状态是在业务服务没有任何感知的情况下，我们将新网关逐步替换上去；为此我们对新网关上线的过程做了充分的准备，严格控制上线过程；具体来看整个上线流程分为以下几个阶段：</p><p style="color:#24292f; text-align:start"><strong>第一阶段</strong></p><p style="color:#24292f; text-align:start">我们在压测环境长时间高负载压测，持续运行时间 24 小时以上，以检测内存泄漏等稳定性问题。同时利用性能检测工具抓取热点火焰图，做针对性优化。</p><p style="color:#24292f; text-align:start"><strong>第二阶段</strong></p><p style="color:#24292f; text-align:start">发布测试环境试跑，采用并行试跑的方式，新老网关同时对外提供服务（流量比例 1 ：1，初期新网关承接流量可能只有十分之一），一旦用户反馈的问题可能跟新网关有关，或者发现异常 case，立即关停新网关的流量。待查明原因并确认修复后，重新引流。</p><p style="color:#24292f; text-align:start"><strong>第三阶段</strong></p><p style="color:#24292f; text-align:start">上线预发，小得物环境试跑，由于这些环境流量不大，依然可以并行长时间试跑，发现问题解决问题。</p><p style="color:#24292f; text-align:start"><strong>第四阶段</strong></p><p style="color:#24292f; text-align:start">生产引流，单节点从万分之一比例开始灰度，逐步引流放大，每个阶段停留 24 小时以上，观察修正后再放大，循环此过程；基於单节点承担正常比例流量后，再次抓取火焰图，基于真实流量场景下的性能热点做针对性优化。</p><span id="OSC_h2_45"></span><h2>团队成长</h2><p style="color:#24292f; text-align:start">回顾整个研发历程我们在不间断新业务承接的情况下，几个月时间内完成开发和上线，从节奏上来讲不可谓不快，研发同学的心态也经历了一些变化。从一开始的质疑，认为大家以前从没有做过的东西现在就这点人能搞的出来吗？到中期的这个组件写起来蛮有挑战也很有意思！直到后期初版压测数据出来后的惊讶。就项目结果而言，可以说收获感满满，从后续的针对研发同学的 one one 沟通反馈来看，对于整个项目感触最大的是技术上的提升很大，对高并发网络编程领域的认知提升了一个档次, 尤其是异步编程方面，技术信心增强很多；内部也组织了分享会，大家普遍很感兴趣，收获了较大的技术红利。</p><p style="color:#24292f; text-align:start">*<strong>文/簌语</strong></p><p>本文属得物技术原创，更多精彩文章请看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com" target="_blank">得物技术官网</a></p><p>未经得物技术许可严禁转载，否则依法追究法律责任！</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/11033092</guid>
            <link>https://my.oschina.net/u/5783135/blog/11033092</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软投资「欧洲版 OpenAI」 Mistral]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软公司周一宣布与法国大模型创业公司&nbsp;Mistral AI 建立新的合作伙伴关系，后者有 「欧洲版 OpenAI」 之称。</p><p>微软在一份声明中表示将投资 20 亿欧元帮助 Mistral AI 开启「新的商业机会」，并向全球市场扩张，但没有提供进一步的财务细节。</p><p>根据协议，Mistral 宣布其最先进的大模型 Mistral Large 首次通过微软的云服务 Azure 提供——成为继 OpenAI 之后第二家在微软 Azure 云计算平台上提供商业语言模型的公司。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-24b13d1f5c37e4bc325eac6c3bbdf3ab204.png" referrerpolicy="no-referrer"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmistral-large%2F" target="_blank">https://mistral.ai/news/mistral-large/</a></em></u></p><p>微软还将帮助这家初创公司获得新客户，后者将推出其 ChatGpt 风格的多语言对话助手「Le Chat」（猫）。微软总裁布拉德·史密斯（Brad Smith）周一表示，这笔交易是该公司支持欧洲技术的「重要」信号。</p><p>与此同时，有人发现 Mistral AI 修改了其网站内容，删除了所有提及对开源社区义务的内容，所以有网友推测他们未来不太可能再发布任何开源模型。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c96c457e5fd400acfcd37ead7a44f8b1528.png" referrerpolicy="no-referrer"></p><p>一位 X 用户发帖称：「我不想说谎；我很遗憾 Mistral 没有开源他们的任何模型。我以为他们是 OSS 团队的。」另一位用户转发了微软 CEO 纳德拉宣布与 Mistral AI 合作的消息，并评论称：「这可能是原因。」马斯克则<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Felonmusk%2Fstatus%2F1762217391633952953" target="_blank">评论道</a>：「是微软让他们闭源的？」</p><p><img height="2051" src="https://oscimg.oschina.net/oscnet/up-6027c2509b672051b14eb678783045ad0e9.png" width="1287" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280426</guid>
            <link>https://www.oschina.net/news/280426</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中文 JDK21 API 网站上线，为 Java 开发者提供全新体验！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">Java Development Kit (JDK) 21 是 Java 平台的最新版本，为 Java 开发者提供了许多新特性和改进。为了更好地支持中文开发者，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在码官网</a>在此自豪地宣布推出最新的中文 JDK21 API 网站。</p><p>这个<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在码</a>网站将成为中文 Java 开发者的首选资源，提供以下内容：</p><ol><li>中文 Java 教程：提供系统的 Java 编程教程，从 Java 基础到高级特性，全面介绍 Java 编程的最佳实践。</li><li>JavaFX 教程：提供 JavaFX 编程的详细教程，介绍 JavaFX 的视图和控制器、图形和动画、媒体和图像等多个方面。</li><li>Orekit 教程：提供 Orekit 库的详细教程，介绍 Orekit 的轨道运动学和控制、姿态和姿态动力学、导航和定位等多个方面。</li><li>JDK21 API 文档：提供 JDK21 中所有类和方法的详细 API 文档，包括类描述、方法签名、参数和返回值等。</li><li>JDK21 工具的中文文档：提供 JDK21 中所有工具的中文文档，包括<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjava.cunzaima.cn%2Fjdk21%2Fdoc-zh%2Fspecs%2Fman%2Fjpackage.html" target="_blank">j</a>package、jwebserver、jlink、jmap 等。</li></ol><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">我们相信，这个新的中文 JDK21 API 将会成为中文 Java 开发者的不可或缺的工具，为他们提供更加便捷和高效的 Java 开发体验。欢迎访问<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn%2F" target="_blank">https://cunzaima.cn/</a>，并在评论区留下您的反馈和建议。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">感谢您的支持和关注！</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn%2F" target="_blank"><img height="100" src="https://oscimg.oschina.net/oscnet/up-3f77e9064178316e9c9acacd55ae6b89c0f.jpg" width="100" referrerpolicy="no-referrer"></a></p><p>网站内容截图：</p><p><img height="887" src="https://oscimg.oschina.net/oscnet/up-b439f6c336100368058aa097a0cc2cc8b44.png" width="1166" referrerpolicy="no-referrer"></p><p><img height="887" src="https://oscimg.oschina.net/oscnet/up-e5afd9a524f3a61fbd854899739c3a190fb.png" width="1166" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 14:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280393</guid>
            <link>https://www.oschina.net/news/280393</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
