<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 06 Feb 2024 11:42:36 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[央行发布《金融业开源软件应用，评估规范》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">1 月 15 日，人民银行发布金融行业标准《金融业开源软件应用，评估规范》（JR/T 0291-2024）（以下简称「《规范》」），于当天实施。</span></p><p><span style="color:#000000"><img alt="" height="412" src="https://oscimg.oschina.net/oscnet/up-d702051be7eaa2a8e19b671e9fec9c74ac8.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">据悉，在金融业信息系统建设过程中，开源软件得到了广泛应用，在促进金融机构科技创新和数字化转型等方面发挥了积极作用，但也带来安全、合规等方面的风险与挑战。因此，有必要对开源软件的引入、维护、退出阶段进行规范，提出相应的评估指标。</span></p><p><span style="color:#000000">《规范》旨在针对开源软件使用过程中的风险与难点，提出一套完整的开源软件生命周期管理各阶段评估项与评估方法，降低金融机构开源软件评估过程的复杂度和时间成本，提升金融机构开源治理能力。</span></p><p><span style="color:#000000">《规范》规定了金融机构在应用开源软件时的评估要求，对开源软件的引入、维护和退出提出实现要求、评估方法和判定准则。适用于金融机构对应用的开源软件进行评估。</span></p><p><span style="color:#000000">《规范》提到，引入的开源软件按照实际应用情况，可分为开源基础软件、开源组件和开源工具 3 类。</span></p><p><span style="color:#000000"><strong>开源软件引入评估</strong></span></p><p><span style="color:#000000">开源软件引入流程分为 3 个阶段：</span></p><ul><li><span style="color:#000000">一是需求确定阶段。应明确软件功能需求与非功能需求。</span></li><li><span style="color:#000000">二是初步筛选阶段。应根据需求展开调研，依照初选评估要求，对开源软件进行评估，建立若干可进入终选评估的开源软件名单。</span></li><li><span style="color:#000000">三是终选评估阶段。应根据初选阶段建立的开源软件名单，依照终选评估要求进行评估，并确定最终引入的开源软件。</span></li></ul><p><span style="color:#000000">在初选评估要求上，评估维度包括：</span></p><p><span style="color:#000000">1、开源许可证。金融机构在选用开源软件时，应遵守该开源许可证对使用、修改等行为的规定。 2、产品认可度。产品认可度反映了开源软件在行业生产实践中的应用情况。 3、产品活跃度。产品活跃度反映了开源软件的可持续性和可进化能力，主要从开源软件的版本发布情况、开源社区情况、软件关注情况等方面进行评估。 4、行业支持情况。行业支持情况反映开源软件在业界提供专业化服务的情况。 5、功能特性。不同软件用于解决不同场景的特定问题，其功能特性也不相同，对于功能的评测应结合具体场景进行。 6、安全性。初步筛选阶段安全性重点考查已暴露的漏洞情况。 7、可靠性。重点考察开源软件自身或者结合其他开源软件的高可用性，在出现故障时是否具备自动故障切换能力和容错能力。 8、兼容性。可通过查看文档的方式评估开源软件的兼容性，例如开源软件对不同硬件的兼容性、对不同操作系统的兼容性。</span></p><p><span style="color:#000000">在终选评估要求上，评估维度则包括：</span></p><p><span style="color:#000000">1、安全性。终选阶段安全性重点考查安全机制方面的支持情况。 2、可靠性。终选阶段可靠性重点考察外部开源软件长时间无故障运行的能力，系统可在极限情况下长时间稳定运行，保证业务成功率以及执行效率。 3、性能效率。终选阶段性能效率重点考查在实际压测环境下开源软件的 TPS、QPS、平均响应时间、最大响应时间、最大并发数、服务调用成功率、时间标准差、CPU 使用率、内存占用率、带宽占用及 I/O 情况。 4、兼容性。兼容性包括硬件兼容性、操作系统平台兼容性、数据库兼容性、开源软件版本之间的兼容性，以及编程语言的兼容性、协议兼容性、同一运行环境的其他组件兼容性、开源软件与国产操作系统兼容性。 5、可维护性。可维护性即维护人员对该开源软件进行维护的难易程度，具体包括理解、改正、改动和改进该软件的难易程度。 6、可扩展性。可扩展性主要包括分布式系统下节点的水平扩展、动态扩展及代码扩展能力。 7、易用性。易用性描述了开源软件的学习成本、安装和部署的难易程度等。</span></p><p><span style="color:#000000"><strong>开源软件维护评估</strong></span></p><p><span style="color:#000000">在开源软件维护过程中，金融机构应根据开源软件的自主可控程度将开源软件进行分类管理，根据其对主营业务的影响程度分为 3 类：</span></p><ul><li><span style="color:#000000">简单使用类开源软件：可搭建环境，且功能可正常使用。</span></li><li><span style="color:#000000">深度使用类开源软件：在满足简单使用类开源软件要求基础上，掌握开源软件容灾容错机制、实现原理、核心算法等重要内容。</span></li><li><span style="color:#000000">定制开发类开源软件：在满足深度使用类开源软件要求基础上，熟悉代码实现、设计思路，通过定制开发能够较好地满足平台需求。</span></li></ul><p><span style="color:#000000">其中，简单实用类开源软件维护评估内容有：</span></p><p><span style="color:#000000"><img alt="" height="364" src="https://oscimg.oschina.net/oscnet/up-09331353c70a84785f1975e432d5f805b0a.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">深度使用类开源软件维护评估内容为：</span></p><p><span style="color:#000000"><img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-536ed6dd8f5f3d1ff3e7a20ba421c81f313.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">定制开发类开源软件维护评估内容为：</span></p><p><span style="color:#000000"><img alt="" height="369" src="https://oscimg.oschina.net/oscnet/up-30dfc33dfd5d8956fcecfbf08ff14c65dcd.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><strong>开源软件退出评估</strong></span></p><p><span style="color:#000000">对于开源软件当前版本已无法满足功能、性能需求，或发现当前版本存在重大风险隐患，或该开源软件已停止更新等情况，应进行退出评估。开源软件的退出可通过开源软件版本升级或开源软件更换来实现。</span></p><p><span style="color:#000000">开源软件退出评估内容包括：开源软件退出机制、开源软件的升级具备兼容性、开源软件在升级后开源许可证的变化，以及更换的开源软件。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 08:13:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278033</guid>
            <link>https://www.oschina.net/news/278033</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌向 Rust 基金会捐赠 100 万美元，改进 Rust 与 C++ 的互操作性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsecurity.googleblog.com%2F2024%2F02%2Fimproving-interoperability-between-rust-and-c.html" target="_blank">宣布</a></u>向 Rust 基金会捐赠 100 万美元，这笔资金将用于支持名为<strong>「Interop Initiative」</strong>的新计划——专注提升 C++ 与 Rust&nbsp;互操作性。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-8a0f4a84a2a1250ba949160c21a66e31916.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffoundation.rust-lang.org%2Fnews%2Fgoogle-contributes-1m-to-rust-foundation-to-support-c-rust-interop-initiative%2F" target="_blank">https://foundation.rust-lang.org/</a></u></em></p></blockquote><p>据介绍，谷歌的核心产品采用了数百万行 C++ 代码进行编写，由于无数的业务相关或技术因素，在合理的时间内用 Rust 重写这些代码并不实际。因此在谷歌的支持下，Rust 基金会创建了新的"Interop Initiative"计划，让全世界正在使用 C++ 的组织更顺利地做出采用 Rust 的决策和流程。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-58623854011083ebd628e8852dfca87752d.png" referrerpolicy="no-referrer"></p><p>谷歌称早已在 Android 和其他产品中广泛使用 Rust 编程语言，并表示 Rust 是他们解决内存安全问题的最强大的工具之一。而且整体来看，谷歌在 Android 中使用 Rust 的增长最为显著。</p><p>Android 安全与隐私工程副总裁 Dave Kleidermacher 表示，根据历史漏洞密度统计数据，Rust 已主动阻止数百个漏洞影响 Android 生态系统。目前这项投资旨在扩大 Rust 在平台各个组件中的采用。</p><p>除了 Android，谷歌也积极在其他应用程序和产品中采用 Rust，包括客户端和服务器硬件。</p><p>Rust 基金会董事会主席兼谷歌成员总监 Lars Bergstrom 说道：「谷歌相信 Rust 等内存安全语言所发挥的关键作用，以及解决各个领域内存安全问题的迫切需要。我们支持 Rust 基金会的&nbsp;<strong>Interop Initiative</strong>&nbsp;计划，因为与 C++ 更好的互操作性将是 Rust 被采用的关键，并让更多组织和社区从内存安全系统中受益。」</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 08:09:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278032/google-contributes-1m-to-rust-foundation</guid>
            <link>https://www.oschina.net/news/278032/google-contributes-1m-to-rust-foundation</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MetaBCI —— 脑机接口开源软件平台]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>MetaBCI 是中国首个脑机接口开源软件平台，由离线分析模块 Brainda、刺激呈现模块 Brainstim 和在线数据流模块 Brainflow 三大部分构成，提供了面向 BCI 软件层面全链条开发的解决方案。</p><ul style="list-style-type:disc; margin-left:0; margin-right:0"><li>面向离线分析需求，Brainda 统一了现有公开数据集接口，优化了脑电数据读取、处理流程，复现多种主要 BCI 数据分析及解码算法，以此提高研究者的算法开发效率；</li><li>面向刺激呈现需求，Brainstim 提供了简洁高效的范式设计模块，可快速创建脑机接口范式刺激界面；</li><li>面向在线开发需求，Brainflow 利用双线程、双进程编程方法实现了实时高速的数据读取、数据处理、结果反馈等功能，帮助开发者轻松搭建脑机接口在线实验系统。</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-8f4d4e3e7fbcc8a74be3635f43436fba05b.png" referrerpolicy="no-referrer"></p><p>相较于现有的脑机接口软件工具包，MetaBCI 基于开源语言 Python 编写，并且能够涵盖脑机接口全链条功能。MetaBCI 完全打通了脑机接口软硬件开发与设计链路，可为脑机接口在科学研究、医疗康复、娱乐生活、特种控制等领域的应用提供重要支撑，持续推动新一代脑机智能快速发展。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:59:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/metabci</guid>
            <link>https://www.oschina.net/p/metabci</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 一文详解静态图和动态图中的自动求导机制]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4a0c43362f56c1a7d9d7eaa7f9a9328a225.png" referrerpolicy="no-referrer"></p><p>作者 | FesianXu</p><blockquote><p>导读</p><p>4 年前在《AutoDiff 理解》 之第一篇「自动求导技术在深度学习中的应用」[1]中打算写一个关于 autodiff 的系列文章，因为工作和学习上比较忙碌（Lan Duo :P），就一直拖到了现在。刚好最近又在学习 OPEN MLSYS[2]，借此机会将静态图中的 autodiff 笔记也一并写完吧。如有谬误请联系指出。</p><p>（注意，在阅读本文之前，请确保已经阅读过[1]，了解为什么深度学习以自动求导作为主要的训练方式，会对理解本文有所帮助。）</p></blockquote><blockquote><p><em>全文 8965 字，预计阅读时间 23 分钟。</em></p></blockquote><span id="OSC_h1_1"></span><h1><strong>01 静态图与动态图的区别</strong></h1><p>之前在[1]中提到过，自动求导（AutoDiff）机制是当前深度学习模型训练采用的主要方法，而在静态图和动态图中对于自动求导的处理是不一样的。作为前置知识，这里简单进行介绍。</p><p>我们都知道静态图建模（如 TensorFlow，<a href="https://www.oschina.net/action/visit/ad?id=1185">paddle</a> fluid）是声明式编程，其建图过程和计算过程是分开的，而对于动态图建模而言（如 pytorch，<a href="https://www.oschina.net/action/visit/ad?id=1185">paddle</a>）是命令式编程，其计算伴随着建图一起进行。注意，这两种编程范式有着根本上的区别，相信用过 tensorflow 和 pytorch 的小伙伴能感受得到。总的来说，动态图边建图边计算的方式容易理解，而静态图先建图，后计算的方式并不是很容易理解，我们完全可以把静态图语言（比如 TensorFlow，<a href="https://www.oschina.net/action/visit/ad?id=1185">Paddle</a>）看成是独立于 python 之外的建图的一种描述语言，其任务主要是建计算图，而其计算部分完全由其 C++后端进行计算。静态图的建图和计算独立的过程和示意代码，可以用 Fig 1.1 进行</p><p><img alt="图片" src="https://oscimg.oschina.net/oscnet/up-c4bc16ff7bc7f8c10fd88d122b341233392.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 1.1 静态图建图和计算的过程示意</strong></em></p><p>注意到，动态图边建图边计算，也即是每一次的模型训练都会进行重新建图和计算，这意味着：</p><p>1、系统无法感知整个动态图模型的全局信息。有些变量可能后续不会再被引用了，可以释放内存，在动态图系统中由于无法感知到后续图的结构，因此就必须保留下来（除非工程师手动释放），导致显存占用一般会大于静态图（当然也并不一定）。</p><p>2、每次都需要重新建图，在计算效率上不如静态图，静态图是一次建图，后续永远都是在这个建图结果的基础上进行计算的。这个就类似于解释性语言（如 python）和编译性语言（如 C 和 C++）的区别。</p><p>3、由于动态图需要每次重新建图，导致其无法在嵌入式设备上进行部署（两种原因，1 是效率问题，2 是嵌入式设备通常不具有网站的建图运行时，只支持推理模式），通常需要其以某种形式（比如 ONNX）转化为静态图的参数后，通过静态图部署。常见的部署方式包括 TensorRT，<a href="https://www.oschina.net/action/visit/ad?id=1189">Paddle Lite</a>，TensorFlow Lite，TensorFlow Serving，NCNN（手机端居多）等等。</p><span id="OSC_h1_2"></span><h1><strong>02 自动求导 AutoDiff</strong></h1><span id="OSC_h2_3"></span><h2><strong>2.1 动态图</strong></h2><p>动态图是完全的边建图边计算，注意到是完全，完全，完全！重要的事情说三遍，这意味着在动态图里面的自动求导过程也是边建图边计算完成了。如 Fig 2.1 所示，在进行前向计算的过程中，除了对前向计算结果进行保存外（简称为前向计算缓存，forward cache），还会同时进行当前可计算的反向梯度的计算（简称为反向计算缓存，backward cache），并且将反向梯度的计算结果同样保存下来。在需要进行端到端的梯度计算的时候，比如调用了 pytorch 的 output.backward()，此时会分析输出节点 output 和每个叶子节点的拓扑关系，进行反向链式求导。此时其实每一步的梯度都已经求出来了，只需要拼在一起，形成一个链路即可。将早已计算得到的前向缓存和反向缓存结果代入拓扑中，得到最终每个叶子节点的梯度。如式子 (2-1) 和 (2-2) 所示。这就是动态图的前向和反向计算逻辑，在建图的同时完成前向计算和反向计算。这种机制使得模型的在线调试变得容易（对比静态图而言），我们待会将会看到静态图是多么的「反人类」（对比动态图而言）。</p><p><span class="math-tex">\(\begin{align} \dfrac{\partial H_3}{\partial X_1} &amp;= \dfrac{\partial H_3}{\partial H_2} (\dfrac{\partial H_2}{\partial X_1}+\dfrac{\partial H_2}{\partial H_1} \dfrac{\partial H_1}{\partial X_1}) \ &amp;= 5(1+1*0.2) = 6 \end{align} \tag{2-1}\)</span></p><p><span class="math-tex">\(\begin{align} \dfrac{\partial H_3}{\partial X_2} &amp;= \dfrac{\partial H_3}{\partial X_2} + \dfrac{\partial H_3}{\partial H_2} (\dfrac{\partial H_2}{\partial H_1} \dfrac{\partial H_1}{\partial X_2}) \ &amp;= -18 + 510.6 = -15 \end{align} \tag{2-2}\)</span></p><p><img alt="图片" src="https://oscimg.oschina.net/oscnet/up-0023ca7b570f61d4ebaf2280addb4e4dc37.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 2.1 动态图的前向和反向计算过程是在建图的时候一起完成的</strong></em>_</p><p>不难发现，在进行反向传播的时候整个系统需要缓存，维护多种类型的变量，包括前向计算的结果缓存，反向梯度的缓存，参数矩阵等等。这些都是模型训练过程中占据显存使用的大头。</p><span id="OSC_h2_4"></span><h2><strong>2.2&nbsp;静态图</strong></h2><p>对于静态图而言，建图是一次性完成的，计算可以在这个建好的计算图上反复进行。如 Fig 3.2 所示，静态图在建图阶段同时将前向计算图和反向计算图都一并建好了（除非指定了在推理模型，此时没有反向建图的过程），当 placeholder 输入真实的 Tensor 数据时（也就是 feed_list），在指定了输出节点的情况下（也就是 fetch_list），执行器会解析整个计算图，得到每个节点的计算顺序，并对 Tensor 进行相对应的处理。如以下代码所示，通过 tf.gradients(Y, X) 可以显式拿到梯度节点，在执行器运行过程中 sess.run()，只需要指定需要的输出节点（比如是前向输出 output 或者是梯度输出 grad）和喂入数据 feed_list，即可在计算图上计算得到结果。</p><pre><code>import tensorflow as tf

X1 = tf.placeholder(tf.float32, shape=(1,), name="X1")
X2 = tf.placeholder(tf.float32, shape=(1,), name="X2")

h1 = tf.multiply(X1, X2)
h2 = tf.add(h1, X1)
output = tf.div(h2, X2)

grad = tf.gradients(output, [X1, X2])

feed_dict = {
    "X1": 0.6, "X2": 0.2
}
sess = tf.Session()
output_v = sess.run(output, feed_dict)
grad_v = sess.run(grad, feed_dict)



</code></pre><p><img alt="图片" src="https://oscimg.oschina.net/oscnet/up-efd595949c5802c6f69794361d2b29297ea.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.2 静态图的正向建图和反向建图都在建图阶段一并完成了</strong></em></p><p>由此我们发现了静态图和动态图自动求导机制的不同点，静态图在执行计算过程中，其实并不区分前向计算和反向计算。对于执行器而言，无论是前向过程建的图，亦或是反向过程建的图都是等价的，执行器不需要区分，因此只需要一套执行器即可，将自动求导机制的实现嵌入到了建图过程中。而由于动态图的建图和计算同时进行，导致其执行器也必须区分前向和反向的过程。从静态图的实现机制上看，我们也不难发现，由于静态图提前已经对整个计算图的拓扑结构有所感知，就能对其中不合理的内存使用进行优化，并且可以对节点进行融合优化，也可以静态分析得到更合理的节点执行顺序，从而实现更大的并行度。静态图的这些性质决定了其更适合于模型部署，计算效率和内存使用效率都比动态图更高。但是静态图也有一个最大麻烦，就是模型调试麻烦。首先由于对整个图都建好了后才能执行，因此并不能动态往里面添加原生 python 的 print 操作——此时 Tensor 都还没计算出来呢，你打印出来的只是该计算节点本身而已，并没有输入任何数值信息。为了 print 其中的节点以进行模型调试，可以往里面插入 TensorFlow 的 tf.Print 操作节点，如 Fig 3.3 所示。当然，你也可以单纯在执行器运行时，通过指定 fetch_list=[h2]进行中间变量的获取。但是不管是哪种方法，都显然比动态图的调试更为麻烦。</p><p><img alt="图片" src="https://oscimg.oschina.net/oscnet/up-378415e5011770ede0f66dc0c731563b7fa.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.3 在计算图中插入 Print 节点，以进行模型调试</strong></em></p><p>静态图对于数据流控制的操作，也远比动态图麻烦。以条件判断为例子，在动态图中只需要实时计算判断条件，实时建图计算即可，一切都是那么地顺滑。但是静态图是必须得提前建图的，这意味着无法实时进行分支判断，因此所有可能的分支都需要进行建图，如 Fig 3.4 所示，实现了以下的条件判断逻辑。</p><pre><code>if (X &gt; 2) {
    return X * X3
} else {
    return X4 - X
}



</code></pre><p><img alt="图片" src="https://oscimg.oschina.net/oscnet/up-2f84a6626d0c423dfe41347b905584f1311.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.4 静态图中对于所有可能的条件判断分支，都需要提前建图</strong></em></p><span id="OSC_h1_5"></span><h1><strong>03 静态图自动求导的实现示例</strong></h1><span id="OSC_h2_6"></span><h2><strong>3.1 前向建图和反向建图</strong></h2><p>以上讲了那么多动态图和静态图的差别，看似有些跑题了，我们说好的自动求导实现呢？嗯嗯，本章在读者对静态图和动态图有了充分的认知之后，将会讨论如何实现静态图的自动求导机制。笔者已经将代码开源_（ <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFesianXu%2FToyAutoDiff" target="_blank">https://github.com/FesianXu/ToyAutoDiff</a> ）_，有兴趣的读者可以自行尝试。在这个代码库中，主要有两种数据结构类，Node 和 Op。Node 是节点类，如下所示，其主要定义了输入列表 self.inputs，这个输入列表用于储存当前节点的所有输入信息，而其本身则是作为输出存在，通过这种方式可以建立一个前向图，如 Fig 3.5 所示，通过维护 Node 类中的 inputs 列表，就足以维护前向图的拓扑关系，其是一个有向无环图（Directed Acyclic Cycle, DAG）。同时，Node 类中还具有一个 const_attr 用于描述 Tensor 与常数的一些操作，如果想要引入类型推断系统，那么还需要加入 self.shape，但是本文中并没有引入这个机制。</p><pre><code>class Node(object):
    def __init__(self):
        self.inputs = []
        self.op = None
        self.const_attr = None
        self.name = ""

    def __add__(self, other):
        if isinstance(other, Node):
            new_node = add_op(self, other)
        else:
            new_node = add_byconst_op(self, other)
        return new_node

    def __mul__(self, other):
        if isinstance(other, Node):
            new_node = mul_op(self, other)
        else:
            new_node = mul_byconst_op(self, other)
        return new_node

    def __truediv__(self, other):
        raise ValueError('No implement div')

    # Allow left-hand-side add and multiply.
    __radd__ = __add__
    __rmul__ = __mul__

    def __str__(self):
        return self.name

    __repr__ = __str__



</code></pre><p><img alt="图片" src="https://oscimg.oschina.net/oscnet/up-0a120695cc882c7543516445b214cfcc60d.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.5 通过组织 Node 里面的 inputs 列表，既可以维护一个前向图关系的描述</strong></em></p><p>通过实现一个抽象类 Op，我们把所有算子的基类需要的共有接口给定义了，第一个是计算方法（Compute），注意到该操作并不区分前向或者反向，在执行器调用这个 compute 的时候，只是对输入的实际 Tensor 进行指定计算而已，因此这个方法其实就是在图计算中实现惰性计算（Lazy Compute）的实际计算方法。第二个是反向建图方法（gradient），该方法对当前输入节点和输出节点（也即是自身）进行反向求导建图。同时注意到在__call__方法中，Op 将输出节点 new_node = Node() 进行定义，并且将其纳入自己类中 new_node.op = self。</p><pre><code>class Op(object):
    def __call__(self):
        new_node = Node()
        new_node.op = self
        return new_node

    def compute(self, node, input_vals):
        raise NotImplementedError

    def gradient(self, node, output_grad):
        raise NotImplementedError



</code></pre><p>该 Op 类是一个抽象类，需要集成它实现其他具体的算子，比如矩阵乘法算子 MatMulOp。该矩阵乘法算子的输入是两个 Op，分别是 node_A 和 node_B。其在 compute 方法中，传入的 Tensor 是基于 numpy array 的，因此直接采用 np.dot() 进行计算即可，当然也可以加入类型断言，形状断言用以判断传入的 Tensor 符合计算图的要求。在 gradient 方法中，我们知道对于矩阵乘法而言，其微分如 (3-1) 所示，将每个输入节点的对应微分写到 gradient 中，此时的<span class="math-tex">\(\partial \mathbf{Y}\)</span>就是前继节点的求导累积结果，在代码中记为 output_grad。</p><p><span class="math-tex">\(\begin{align} \mathbf{Y} &amp;= \mathbf{A} \mathbf{B} \ \partial \mathbf{A} &amp;= \partial \mathbf{Y} \cdot \mathbf{B}^{\mathrm{T}} \ \partial \mathbf{B} &amp;= \mathbf{A}^{\mathrm{T}} \cdot \partial \mathbf{Y} \end{align} \tag{3-1}\)</span></p><pre><code>class MatMulOp(Op):
    """Op to matrix multiply two nodes."""
    def __call__(self, node_A, node_B, trans_A=False, trans_B=False):
        new_node = Op.__call__(self)
        new_node.matmul_attr_trans_A = trans_A
        new_node.matmul_attr_trans_B = trans_B
        new_node.inputs = [node_A, node_B]
        new_node.name = "MatMul(%s,%s,%s,%s)" % (node_A.name, node_B.name, str(trans_A), str(trans_B))
        return new_node

    def compute(self, node, input_vals):
        assert len(input_vals) == 2
        assert type(input_vals[0]) == np.ndarray and type(input_vals[1]) == np.ndarray
        return np.dot(input_vals[0], input_vals[1])

    def gradient(self, node, output_grad):
        """
    if Y=AB, then dA=dY B^T, dB=A^T dY
        """
        return [matmul_op(output_grad, transpose_op(node.inputs[1])), matmul_op(transpose_op(node.inputs[0]), output_grad)]




</code></pre><p>通过类似的方法还可以实现其他很多算子操作，比如加减乘除等等。前向建图很容易完成，我们讨论下如何进行反向建图。在该试验代码中，实现了一个 gradients 函数，如下所示，该函数对输出节点 output_node 和指定的节点列表（node_list）中的每个节点进行求导操作。在实现这个的过程中，我们调用了一个叫做 find_topo_sort 的函数，对以这个输出节点 output_node 为起始点进行深度优先搜寻（Depth First Search），然后进行逆序就得到了反拓扑结构。还是以 Fig 3.2 的拓扑结构为例子，对其输出 H3 进行 DFS，得到的拓扑序为 X2 -&gt; X1 -&gt; H1 -&gt; H2 -&gt; H3，进行翻转后得到 H3 -&gt; H2 -&gt; H1 -&gt; X1 -&gt; X2。我们发现翻转后的序，和 Fig 3.2 的反向建图的序是一致的。因此以此为序，遍历的过程中不断地调用当前遍历节点的 op.gradient 方法，实现层次反向建图。</p><pre><code>def gradients(output_node, node_list):
    """Take gradient of output node with respect to each node in node_list.
    Parameters
    ----------
    output_node: output node that we are taking derivative of.
    node_list: list of nodes that we are taking derivative wrt.
    Returns
    -------
    A list of gradient values, one for each node in node_list respectively.
    Something wrong, should be the backward graph of the gradients
    """
    node_to_output_grads_list = {}
    node_to_output_grads_list[output_node] = [oneslike_op(output_node)]
    reverse_topo_order = reversed(find_topo_sort([output_node]))

    for ind, each in enumerate(reverse_topo_order):
        if ind == 0:
            gg = each.op.gradient(each, oneslike_op(output_node))
        else:
            gg = each.op.gradient(each, node_to_output_grads_list[each])

        if gg is None:
            continue
        for indv, eachv in enumerate(gg):
            if each.inputs[indv] in node_to_output_grads_list.keys():
                node_to_output_grads_list[each.inputs[indv]] += gg[indv]
            else:
                node_to_output_grads_list[each.inputs[indv]] = gg[indv]

        node_to_output_grad[each] = each
    grad_node_list = [node_to_output_grads_list[node] for node in node_list]
    return grad_node_list

def find_topo_sort(node_list):
    """Given a list of nodes, return a topological sort list of nodes ending in them.

    A simple algorithm is to do a post-order DFS traversal on the given nodes, 
    going backwards based on input edges. Since a node is added to the ordering
    after all its predecessors are traversed due to post-order DFS, we get a topological
    sort.
    """
    visited = set()
    topo_order = []
    for node in node_list:
        topo_sort_dfs(node, visited, topo_order)
    return topo_order

def topo_sort_dfs(node, visited, topo_order):
    """Post-order DFS"""
    if node in visited:
        return
    visited.add(node)
    for n in node.inputs:
        topo_sort_dfs(n, visited, topo_order)
    topo_order.append(node)



</code></pre><p>建图完后我们就需要进行计算了，而计算是有执行器（Executor）进行的。执行器中最主要的方法是 run，这个相当于 TensorFlow 中的 sess.run()，不同的在于，这里的执行器是在构造器中指定 fetch_list，在 run() 中指定喂入的 Tensor 数据。在 run 方法中，我们同样需要采用 DFS 对计算图进行遍历（不区分前向还是反向，再强调一遍），得到了计算序后，依次喂入 tensor 数据，调用 op.compute() 进行 tensor 计算即可。</p><pre><code>class Executor:
    """Executor computes values for a given subset of nodes in a computation graph."""
    def __init__(self, eval_node_list):
        self.eval_node_list = eval_node_list

    def run(self, feed_dict):
        node_to_val_map = dict(feed_dict)
        # Traverse graph in topological sort order and compute values for all nodes.
        topo_order = find_topo_sort(self.eval_node_list)
        for each in topo_order:
            if each.inputs:
                input_vals = []
                for each_input in each.inputs:
                    input_vals += [node_to_val_map[each_input]]
                node_to_val_map[each]  = each.op.compute(node=each, input_vals=input_vals)
        node_val_results = [node_to_val_map[node] for node in self.eval_node_list]
        return node_val_results



</code></pre><p>至此，我们就实现了一个简单的静态图 autodiff 机制得到试验，后续可以加入形状推断机制，抽象出 Layer 神经网络层，参数初始化器 Initiator，优化器 Optimizer，损失 Loss，模型层 Model，那么我们就可以构建出一个玩具版本的 TensorFlow 啦，嘿嘿嘿~~</p><p>————END————</p><p><strong>参考资料：</strong></p><p>[1].&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.csdn.net%2FLoseInVain%2Farticle%2Fdetails%2F88557173" target="_blank">https://blog.csdn.net/LoseInVain/article/details/88557173</a>, 《AutoDiff 理解》 之第一篇， 自动求导技术在深度学习中的应用</p><p>[2].&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenmlsys.github.io%2Fchapter_preface%2Findex.html" target="_blank">https://openmlsys.github.io/chapter_preface/index.html</a>, OPEN MLSYS</p><p>[3].&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFesianXu%2FToyAutoDiff" target="_blank">https://github.com/FesianXu/ToyAutoDiff</a></p><p><strong>推荐阅读：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576591%26idx%3D1%26sn%3D308b40799e498afc211537944424e429%26chksm%3Dc03f9c73f7481565df2f217d1417bf381ec406c10ac50796cd678c0ae51168a408c0e301e576%26scene%3D21%23wechat_redirect" target="_blank">千万级高性能长连接 Go 服务架构实践</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576575%26idx%3D1%26sn%3D2d4638ad0c3235d958e724cc6cf1aaf9%26chksm%3Dc03f9b83f7481295dd1eefab21d11828a366851c427abcc588a28f0555d4ec9cda0173914c91%26scene%3D21%23wechat_redirect" target="_blank">百度搜索 Push 个性化：新的突破</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576268%26idx%3D1%26sn%3Dede6034f715c60a750d08a6191985ff8%26chksm%3Dc03f9ab0f74813a6b5f236490e30555546de98117a902557c6ccf3e370b1ba6dcd6743458954%26scene%3D21%23wechat_redirect" target="_blank">数据交付变革：研发到产运自助化的转型之路</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576227%26idx%3D1%26sn%3Daf13e8a1c98b8948fd29dc5acaa4054c%26chksm%3Dc03f9adff74813c9f993092cf59b2f29578e5583a05c4ad5d2e0fd46e5d665959c4abb12db20%26scene%3D21%23wechat_redirect" target="_blank">百度搜索 exgraph 图执行引擎设计与实践</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247575843%26idx%3D1%26sn%3D52fc61ebc3de5d36c75061a6ca2f7dfe%26chksm%3Dc03f995ff74810492986bf919bbb764fee89153a04d5d6faa2a80aaa4a23a5d391403c01da6e%26scene%3D21%23wechat_redirect" target="_blank">百度搜索&amp;金融：构建高时效、高可用的分布式数据传输系统</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:53:32 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/11032933</guid>
            <link>https://my.oschina.net/u/4939618/blog/11032933</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Go 语言之父总结成功因素：吉祥物功不可没]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Go 语言之父 Rob Pike 在澳大利亚悉尼举行的 GopherCon AU 大会上，为纪念 Go 编程语言发布 14 周年 (&nbsp;2009 年 11 月 10 日) 发表了一场演讲，主题旨在回顾： "我们做对了什么以及做错了什么 (What We Got Right, What We Got Wrong)"。</span></p><p><span style="color:#000000">Pike <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommandcenter.blogspot.com%2F2024%2F01%2Fwhat-we-got-right-what-we-got-wrong.html" target="_blank">分享</a>了许多关于 Go 早期历史的内部记忆，以及在开发过程中有关一些重要因素的见解。不过他也声明称，本次发言仅代表个人观点，与&nbsp;Go 团队或谷歌没有关系。</span></p><blockquote><p><span style="color:#000000">"Go 过去是、现在仍然是一个敬业的团队和一个庞大的社区所付出的巨大努力。所以如果你同意我说的任何话，请感谢他们。如果你不同意，可以责怪我，但请不要说出来。"</span></p></blockquote><p><span style="color:#000000">Pike 补充到，编程语言的好坏在很大程度上是一个见仁见智的问题，而不是事实。在 2022 年发表的一篇讨论了 Go 流行原因的文章中，Pike 与 Ken Thompson、Russ Cox、Robert Griesemer 和 Ian Lance Taylor 曾共同<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthenewstack.io%2Fgolang-co-creator-rob-pike-what-go-got-right-and-wrong%2F" target="_blank">指出</a>，Go 是专门为并发和并行性而设计的，在处理大规模工作负载的同时利用了新的多核芯片的强大功能。但他们也将 Go 的成功归功于其持续的「以开发为中心的理念」，以及其蓬勃发展的社区及其贡献（包括新包）。</span></p><p><span style="color:#000000">在演讲中 Pike 再次提到了这个主题表示，「我们最初的目标不是创造一种新的编程语言，而是创造一种编写软件的更好方法.....如果我当时不花 45 分钟来构建二进制文件，Go 就不会出现。」</span></p><p><span style="color:#000000">简而言之，Pike 指出，Go 是一种编程语言，但也不仅仅是一种编程语言。它的目的是帮助提供一种开发高质量软件的更好方法。时至今日，这仍然是它的目标；Go 是一个让生产软件的开发更简单、更高效的项目。</span></p><p><span style="color:#000000">出人意料的是，Pike 在例举 Go 语言的成功之处时，首先提及的是吉祥物 (Go gopher )，并将之誉为 Go 成功的最早因素之一、对 Go 的发展至关重要。他认为，呆萌有趣辨识度高的吉祥物很好的团结了社区氛围，为社区参与项目奠定了基调 —— 即卓越的技术与真正的乐趣相结合。</span></p><p><span style="color:#000000">但对于以 CC 许可发布 Gopher 的设计，Pike 则坦言，这"也许不是最好的选择"，如果再重来一次他们会慎重考虑。</span></p><p><span style="color:#000000"><img alt="" height="451" src="https://oscimg.oschina.net/oscnet/up-a004fea240880685504378aa24a754146e5.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">在提到 Go 语言发展过程中所做出的一些正确决策时，Pike 提到了：确保 Go 易于解析，此举反过来又使得创建 IDE 等工具以及 Go 的官方语言服务器 gopls（也提供 IDE 功能）变得容易；以及为编译器添加了自动测试和代码审查工具。其他还包括：</span></p><ul><li><span style="color:#000000">gofmt 自动格式化工具</span></li><li><span style="color:#000000">Go 的软件包库</span></li><li><span style="color:#000000">发布了 Go 语言的正式规范</span></li><li><span style="color:#000000">在早期就发布了 Go 语言的兼容性保证，等等。</span></li></ul><p><span style="color:#000000">此外，Pike 还透露了一些他期待出现的功能，包括：允许使用任意精度的整数，他认为这将消除一整类安全隐患；以及希望看到编译器对 Go 的动态接口进行更多自动检查，并检查资源共享可能导致的进度停滞死锁。"任何能让程序在编译时更安全的东西都是好东西。"</span></p><p><span style="color:#000000">Pike 指出，Go 语言的另一个关键之处在于它的可移植性；也就是说，它可以轻松地为其他平台编译代码。这在一定程度上得益于 Ken Thompson 用 C 语言编写的编译器，尽管其他人认为编译器应该用 Go 本身编写（或使用 LLVM 中的工具）。Pike 也将该编译器描述为「an odd duck」，但无论如何，他认为这对于当时的处境来说是一个正确的选择。直到 2015 年，Russ Cox 编写了一个工具，可以将编译器从 C 半自动编译为 Go。</span></p><p><span style="color:#000000">而有关 Go 最具影响力的决定 —— 「并发」。在分享这一故事时，Pike 首先描述了 2002 年自己刚加入 Google 时的世界。在他的记忆中，彼时的谷歌似乎一直在回避进程线程的并发执行，甚至采取"几乎完全禁止"的态度，这也让他感到很苦恼。</span></p><p><span style="color:#000000">「自 20 世纪 70 年代以来，我一直在做类似并发的事情，甚至是在无意识的情况下」。事实上，除了 Pike 外，当时许多其他语言、论文甚至书籍都写过关于并发编程的内容，并表明并发编程可以做得很好。只是当时的并发还没有成为主流理念，Go 的诞生部分就是为了解决这个问题，而它最终也成为了 Go 最大的亮点之一。</span></p><p><span style="color:#000000">"</span><span><span style="color:#222222"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span><span>回顾过去，我认为可以公平地说，Go 在&nbsp;</span></span></span></span></span></span></span><span style="background-color:#ffffff"><span><span><span><span><span>让编程世界相信并发是一个强大的工具（尤其是在多核网络世界中）方面发挥了重要作用，并且它可以比 pthread 做得更好。如今，</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="color:#000000">大多数主流语言都对并发提供了良好的支持。但在当时，这让 Go 看起来像是一种新事物......Go 对并发的支持是一个主要的吸引因素，它帮助增加了早期的采用率，吸引了那些之前没有使用过并发但对其可能性很感兴趣的程序员"。</span></p><p><span style="color:#000000">Pike 认为，这是一个绝对成功的举措，Go"帮助普及了并发作为服务器软件结构的一种方式"。</span></p><p><span style="color:#000000">最后，</span><span style="color:#000000">Pike 简洁的总结了一些促使 Go 成功的因素，「最重要的是，我们得到了 Gophers 这个乐于助人、多元化社区的大力支持。」</span></p><p><span style="color:#000000"><img height="246" src="https://oscimg.oschina.net/oscnet/up-0480c7a61fc3b60e8358dbf35422313383c.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">更多详情<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommandcenter.blogspot.com%2F2024%2F01%2Fwhat-we-got-right-what-we-got-wrong.html" target="_blank">可查看博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278027/golang-rob-pike-what-go-got-right-and-wrong</guid>
            <link>https://www.oschina.net/news/278027/golang-rob-pike-what-go-got-right-and-wrong</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国产数据库管理工具 CloudDM v2.4.4 发布，支持更多数据库对象查看]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><p style="margin-left:0; margin-right:0"><span>CloudDM<span>&nbsp;</span></span><span style="color:#333333">是<span>&nbsp;</span></span><span>ClouGence</span><span style="color:#333333"><span>&nbsp;</span>公司推出的一款</span><strong><span>一站式多数据源开发管理工具</span></strong><span style="color:#333333">，使用它可以方便地访问和管理<span>&nbsp;</span></span><span>MySQL、Oracle、PostgreSQL、阿里云 RDS、Greenplum、TiDB、Redis、StarRocks、Doris、SelectDB、SQL SERVER、ClickHouse、OceanBase 、PolarDB-X 、IBM Db2 等多种不同类型的数据库。通过 CloudDM 丰富的数据源支持可以避免在多个专业工具之间切换，从而提高工作效率。</span></p><p style="margin-left:0; margin-right:0"><span>它是本地化的应用程序，没有后台进程。和<span>&nbsp;</span></span><strong><span>DataGrip</span></strong><span>、</span><strong><span>Navicat</span></strong><span><span>&nbsp;</span>一样在安装完成后，只需要双击应用程序图标，便可以方便的管理位于本地计算机或远程计算机上的数据库。已经支持<span>&nbsp;</span></span><strong><span>Windows</span></strong><span>、</span><strong><span>MacOS</span></strong><span><span>&nbsp;</span>和<span>&nbsp;</span></span><strong><span>Linux</span></strong><span><span>&nbsp;</span>主流操作系统。</span></p></div></div><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><img src="https://oscimg.oschina.net/oscnet/up-c0a92ca7654a775e970ab24569abe3fe44d.png" referrerpolicy="no-referrer"></p><div><div><h2><span>更新内容</span></h2><div><ul><li><span>[新增]</span><ul><li><span>针对 MySQL 数据源在数据库对象视图中可以看到，存储过程、触发器、视图、函数</span></li><li><span>针对 Oracle&nbsp;数据源在数据库对象视图中可以看到，存储过程、触发器、视图、函数、</span>序列、物化视图</li><li>针对 <span>PostgreSQL&nbsp;</span>数据源在数据库对象视图中可以看到，存储过程、触发器、视图、函数<span>、</span>序列、物化视图</li><li>针对 <span>Oceanbase&nbsp;</span>数据源在数据库对象视图中可以看到，存储过程、触发器、视图、函数</li><li>针对 <span>SQL SERVER</span><span>&nbsp;数据源在数据库对象视图中可以看到，存储过程、触发器、视图、函数</span><span>、</span>序列</li></ul></li><li><span style="color:#333333">[优化]</span><ul><li>优化，移除 TiDB 数据库不兼容的数据库对象，详情请参照 TiDB 官方文档 v7.5</li></ul></li><li><span style="color:#333333">[修复]</span><ul><li><p>修复，内置用户出现多条记录而导致的报错问题</p></li><li><p>修复 Oracle 数据库查看普通表时连同物化视图一起获取的问题</p></li><li><p>修复 Oracle 数据库访问部分 Schema 时，由于使用权限需求过高的语句，而出现表或视图不存在报错的问题</p></li></ul></li></ul></div></div><h2><span>下载与反馈</span></h2><ul><li><span>产品官网：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.clougence.com%2Fclouddm-personal" target="_blank"><span>https://www.clougence.com/clouddm-personal</span></a></li><li><span>问题反馈：</span><a href="https://gitee.com/clougence/clouddm-issue/issues" target="_blank"><span>https://gitee.com/clougence/clouddm-issue/issues</span></a></li><li>Release Node：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.clougence.com%2Fdmp-doc%2Freleaseinfo%2Fdesktop_2_4_2" target="_blank">https://www.clougence.com/dmp-doc/releaseinfo/desktop_2_4_2</a></li><li><span style="color:#333333">微信交流群：访问产品官网，扫描右侧二维码即可加入</span></li></ul></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:00:11 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278017/clouddm-2-4-4</guid>
            <link>https://www.oschina.net/news/278017/clouddm-2-4-4</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源 - 奋进者的盛宴 | Apache StreamPark in 2023]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ed43d3f9ec4da28ec68103abf6c2af05c00.png" referrerpolicy="no-referrer"></p><p>时间的指针已跨过 2023，对于 Apache StreamPark 社区而言，这是一个值得书写回顾的时刻。Apache StreamPark 从最初的个人项目到加入全球最大的开源软件基金会（Apache Software Foundation），一路走来我们始终相信坚持和协作的力量，相信社区的力量。开源，不是天才的甜点，而是奋进者的盛宴。此时此刻，让我们一起回顾 Apache StreamPark 社区过去一年的精彩时刻。</p><span id="OSC_h1_1"></span><h1>社区向好发展</h1><p>在过去一年，Apache StreamPark 一直在积极地建设社区，大力地培养开发者，遵循 Apache 软件基金会的「Community over Code」原则来运营社区，以开放包容、自由平等的态度对待每位参与者，在 2023 年社区有许多值得被分享的事情：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-549cf545062bc87773f5f663f719934c10a.png" referrerpolicy="no-referrer"></p><ul><li><p>全年发布了&nbsp;<strong>2.0.0 -&nbsp;2.1.2</strong>&nbsp;共&nbsp;**<code>4</code>**个 Apache 版本。</p></li><li><p>社区参加了 2023 年 8 月「Community over Code」ASIA 大会，带来**<code>3</code>**场 Apache StreamPark 相关的主题分享。</p></li><li><p>投票推选了&nbsp;<strong><code>2</code></strong>&nbsp;位&nbsp;PPMC Member&nbsp;和**<code>5</code>**位新晋 Committer，分别是：Chunjin Mu、Sizhu Wang、Li Zhou、Zhongqiang Gong、Yuepeng Pan、Cancai Cai、Chao Zhang，恭喜他们，感谢他们为 Apache StreamPark 所做的贡献。</p></li><li><p>重新制作上线了官网，整理上线了 <strong><code>8</code></strong>&nbsp; 篇生产实践的文章。</p></li><li><p>项目 Star 新增 <strong><code>800+</code></strong>，累积 <strong><code>3.5k</code></strong>&nbsp;, 项目 fork 累积 <strong><code>900+</code></strong>。</p></li><li><p>贡献者总数达到&nbsp;<strong><code>130+</code></strong>&nbsp;&nbsp;相比 2022 年新增了&nbsp;<strong><code>40+</code></strong>。</p></li><li><p>共计 <strong><code>59</code></strong> 位开发者提交了超过 <strong><code>550</code></strong> 个 commit。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bd5f43f528488dde6a0b7be9e8847ef2234.png" referrerpolicy="no-referrer"></p><p>2023 年 9 月 1 日，是 Apache StreamPark 孵化整整一周年的日子，在这个值得纪念的日子里，我们特此剪辑了一个短片，回顾 Apache StreamPark 的发展历程：</p><p><iframe frameborder="no" height="400px" scrolling="no" src="https://player.bilibili.com/player.html?aid=275553707&amp;bvid=BV1aF41167pF&amp;cid=1255969269&amp;p=1" width="720px" referrerpolicy="no-referrer"></iframe></p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>项目关键进展</h1><p>2023 年 Apache StreamPark&nbsp;在开发新功能的同时，对项目的稳定性持续打磨，在对 Apache Flink 的基础能力支持上日益成熟，以下是项目的关键进展:</p><ol><li><strong>更好的 Flink 支持</strong>：在 Flink 作业的部署模式和版本支持上都做大量改进，开发管理 Flink 作业更加的简单丝滑。重构了 Flink on K8s 作业部署和状态监控，整体稳定性达到生产可用级别，并经过用户 500+&nbsp;生产环境作业的验证。</li><li><strong>新功能持续更新</strong>：项目在功能上持续更新，新增了团队管理、LDAP 登录、变量等深受欢迎的企业级特性和能力，更贴合企业的使用。基于 Vue3 重构了项目前端，显著提升了项目的可读性、可维护性，前端的构建和启动速度提升了 5~10&nbsp;倍。</li><li><strong>产品越发成熟</strong>：这一年我们发布了三个改进 &amp; Bug 修复版本，在此过程中我们收集了大量的用户反馈，项目从前端到后台，不论是作业的开发部署，还是状态管理，使用体验...方方面面都做了大量改进，产品综合表现越发成熟稳定。</li><li><strong>支持生态项目:</strong> &nbsp;无缝地支持对接 Apache Doris、Paimon 等数据集成作业。</li><li><strong>安全性 &amp; 合规性</strong>：作为孵化中的项目，项目合规是重要的一环，我们排查解决了项目中存在漏洞的依赖，修复了项目自身的漏洞，4 次发版通过 Apache 的检查，项目合规性得到有效保证。</li></ol><span id="OSC_h1_3"></span><h1><strong>用户持续增长</strong></h1><p>在 2023 年，我们迎来了越来越多的用户，公开收集的登记使用用户新增 24 位。目前如，百度、腾讯、联通、天翼云、自如、圆通、网易智企、同程数科、长安汽车、马蜂窝，等一二线大厂都在使用，其他使用或者基于 Apache StreamPark 二次开发的公司更是不计其数。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-60000a0362483b96361b6cadac51b0d8ebb.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_4"></span><h1><strong>荣获多项殊荣</strong></h1><p>在 2023 年，Apache StreamPark 社区获得了多项荣誉。Apache StreamPark&nbsp;作为一个年轻的开源项目，能在多个评选中获得各个不同主办方对项目的认可并被授予表彰，不仅证明了项目的价值，更提高了项目的知名度，这是对我们多年来坚持不懈努力的嘉许。这些奖项不仅肯定了我们才华横溢的贡献者，更见证了开源社区的繁荣与创新。感谢各个主办方，感谢我们的导师和所有的贡献者们。让我们牢记这份珍贵的荣誉，我们将继续努力，争取更好的成绩。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e30c75b0c6a7af48c7d9547919e21a28e1a.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_5"></span><h1>持续分享输出</h1><p>2023 Apache StreamPark 社区在技术分享上持续输出，在&nbsp;2023 年 8 月「Community over Code」ASIA 大会，带来&nbsp;<strong><code>3</code></strong> 场 Apache StreamPark 相关的主题分享。此外产生了来自 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247553003%26idx%3D1%26sn%3D0b5647ba233dd7fdb3f86c6365366503%26chksm%3Dc04d717ff73af869c31ec1db46beb48c9a36ede1dbe525c4660862e55a77d584de5ffa440624%26scene%3D21%23wechat_redirect" target="_blank">自如</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247547381%26idx%3D1%26sn%3D071f941543a2b9539d14f5d51275d9bd%26chksm%3Dc04d4761f73ace77c9bd3d07284ea506173dcd7722c0d75a6827c3f9f63391adf1735840a841%26scene%3D21%23wechat_redirect" target="_blank">、</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247547381%26idx%3D1%26sn%3D071f941543a2b9539d14f5d51275d9bd%26chksm%3Dc04d4761f73ace77c9bd3d07284ea506173dcd7722c0d75a6827c3f9f63391adf1735840a841%26scene%3D21%23wechat_redirect" target="_blank">顺网科技</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247544817%26idx%3D1%26sn%3Dca8a8978254e5e38042ad729766e67e8%26chksm%3Dc04d5165f73ad873f836d114fb3b16a4877ce19182d11043ebfd759f1ef5f73c34e71b4aa2ef%26scene%3D21%23wechat_redirect" target="_blank">、</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247544817%26idx%3D1%26sn%3Dca8a8978254e5e38042ad729766e67e8%26chksm%3Dc04d5165f73ad873f836d114fb3b16a4877ce19182d11043ebfd759f1ef5f73c34e71b4aa2ef%26scene%3D21%23wechat_redirect" target="_blank">海程邦达&nbsp;等企业的</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247544817%26idx%3D1%26sn%3Dca8a8978254e5e38042ad729766e67e8%26chksm%3Dc04d5165f73ad873f836d114fb3b16a4877ce19182d11043ebfd759f1ef5f73c34e71b4aa2ef%26scene%3D21%23wechat_redirect" target="_blank">多篇</a> 生产实践文章，并且生产了数十个原创视频，在各个渠道累计播放量 <strong><code>20W+</code></strong> &nbsp;。在此非常感谢各合作社区的关照和传播，正是各个合作社区伙伴们的帮衬和关照才能使得 Apache StreamPark 项目的影响力不断上升。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-99395c3375f020ad6ffa87b072eafe03929.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><span id="OSC_h1_6"></span><h1><strong>展，望 2024</strong></h1><p>如果用一个词概括总结 Apache StreamPark 的 2023, 我想就是: 奋进，持志如心痛，我们始终以奋进的姿态推动项目发展，为用户的使用落地保驾护航。停留片刻，岁月扉页已翻到 2024，2024 Apache&nbsp;StreamPark 有哪些期待呢？<br> Apache StremaPark 最初的想法就是简化 Flink | Spark 的开发和管理，让流处理更简单，因此会继续加大，对 Flink 的支持力度，包括不限于支持 PyFlink，探索 Sql-gateway 等交互式方面的体验，继续完善底层基础建设，改进 Flink on K8S 的基础能力，加强完善&nbsp;SLA&nbsp;的方面的保障体系，和生态项目共同建设发展，更好的支持和集成 Apache Paimon/Doris 和 Flink CDC 等生态项目。 Apache&nbsp;StreamPark 从来都不是一个独立的平台，也并非绑定在某个流计算引擎之上，因此，在 2024 年社区会发起讨论，启动对 Apache Spark 的支持，包括不限于开发框架和作业管控平台，使其真正做到让流处理更简单，成为流处理开发管理和实时计算平台事实上的最佳选择。</p><span id="OSC_h1_7"></span><h1>加入我们</h1><p>Apache&nbsp;StreamPark 是一个流处理应用程序开发管理框架。旨在轻松构建和管理流处理应用程序，提供使用 Apache Flink 和 Apache Spark 编写流处理应用程序的开发框架。同时 Apache&nbsp;StreamPark 提供了一个流处理应用管理平台，核心能力包括但不限于应用开发、调试、交互查询、部署、运维、实时数仓等，最初开源时项目名称叫 StreamX ，于 2022 年 8 月更名为 StreamPark，随后通过投票正式成为 Apache 软件基金会的孵化项目。目前已有腾讯、百度、联通、天翼云、自如、马蜂窝、同程数科、长安汽车、大健云仓等众多公司在生产环境使用。</p><p>Apache StreamPark 社区一直以来都以用心做好一个项目为原则，高度关注项目质量，努力建设发展社区。加入 Apache 孵化器以来，认真学习和遵循「The Apache Way」，我们将秉承更加兼容幷包的心态，迎接更多的机遇与挑战。诚挚欢迎更多的贡献者参与到社区建设中来，和我们一道携手共建。</p><p><strong>💻 项目地址：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark" target="_blank">https://github.com/apache/streampark</a><br><strong>🧐 提交问题和建议：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fissues" target="_blank">https://github.com/apache/streampark/issues</a><br><strong>🥁 贡献代码：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fpulls" target="_blank">https://github.com/apache/streampark/pulls</a><br><strong><strong>📮&nbsp;<strong>Proposal：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FINCUBATOR%2FStreamPark%2BProposal" target="_blank">https://cwiki.apache.org/confluence/display/INCUBATOR/StreamPark+Proposal</a><br> 📧 订阅社区开发邮件列表：dev@streampark.apache.org<br> 💁‍♀️</strong></strong>社区沟通：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-463ce49840586bf1b6c38042bd20495d7ba.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 06:19:16 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/streampark/blog/11027473</guid>
            <link>https://my.oschina.net/streampark/blog/11027473</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：「小而美」 Tauri 已支持 Android 和 iOS；苹果开源 Pkl]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><p><strong># 2024.2.5</strong></p><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要点</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/277597/vuejs-10yr" target="_blank">Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Tauri v2 首个 Beta 已发布，新版本添加了<strong>对移动端（iOS 和 Android）的支持</strong>。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a84ea1fdc7a280dc620420b12cee4e8bf63.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">公告<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbeta.tauri.app%2Fblog%2Ftauri-2-0-0-beta%2F" target="_blank">写道</a></u>：「Tauri v2 是支持跨平台开发的一个重大里程碑，开发桌面和移动应用程序从未如此简单。你可以将现有的桌面程序无缝迁移到移动设备，并获得原生 API 和 Tauri CLI 的出色开发者体验。」</p><h3><u><a href="https://www.oschina.net/news/277816/apple-pkl-lang" target="_blank">苹果开源 Pkl —— 用于生成配置的编程语言</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">苹果发布了专用于创建配置文件的脚本编程语言&nbsp;Pkl（发音为 Pickle）。Pkl 团队<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpkl-lang.org%2Fblog%2Fintroducing-pkl.html" target="_blank">介绍称</a></u>，该项目旨在应对 JSON、YAML 和属性列表等静态配置格式的不足，提供一种介于静态语言和通用语言之间、「两全其美」的方案。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Pkl 的三个设计目标是语法安全、可扩展和 IDE 集成，使用声明式语法、易读易写，但也支持类、函数、条件和循环等常见的编程语言功能。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>示例代码</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">bird.pkl</p><pre style="margin-left:0; margin-right:0; text-align:left"><code class="language-json"><span style="color:#6f42c1">name</span> = <span style="color:#032f62">"Swallow"</span><span style="color:#6f42c1">job</span><span style="color:#032f62">{</span><span style="color:#6f42c1">title</span> = <span style="color:#032f62">"Sr. Nest Maker"</span><span style="color:#6f42c1">company</span> = <span style="color:#032f62">"Nests R Us"</span><span style="color:#6f42c1">yearsOfExperience</span> = <span style="color:#032f62">2</span><span style="color:#6f42c1">}</span></code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">↓</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">bird.json</p><pre style="margin-left:0; margin-right:0; text-align:left"><code class="language-json">{
  <span style="color:#6f42c1">"name"</span>: <span style="color:#032f62">"Swallow"</span>,
  <span style="color:#6f42c1">"job"</span>: {
    <span style="color:#6f42c1">"title"</span>: <span style="color:#032f62">"Sr. Nest Maker"</span>,
    <span style="color:#6f42c1">"company"</span>: <span style="color:#032f62">"Nests R Us"</span>,
    <span style="color:#6f42c1">"yearsOfExperience"</span>: <span>2</span>
  }
}</code></pre><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推荐</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-41e1b46b27f9899b2f2893d8ed2b70534e9.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">开源之声</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-e3a4add7186ca1ff7c533ae75453c1ebc93.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日项目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜单：</p><p><img src="https://oscimg.oschina.net/oscnet/up-a1f42bf84d0c31d454864b491f232d5f371.png" referrerpolicy="no-referrer"></p><hr><p><strong>往期回顾</strong></p><ul><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf" target="_blank">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></u></li><li><u><a href="https://www.oschina.net/news/277585" target="_blank">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></u></li><li><u><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">开源日报第 006 期：选择技术栈一定要选择开源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 04:49:20 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277997</guid>
            <link>https://www.oschina.net/news/277997</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Anolis OS 获 Gitee 最有价值开源项目称号]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="text-align: justify;margin-left: 8px;margin-right: 8px;margin-bottom: 8px;line-height: 1.75em;" data-mpa-powered-by="yiban.io"><ne-clipboard source="https%3A%2F%2Faliyuque.antfin.com%2Fhd01475069%2Fnzgfgg%2Fczegeetz123okfva%3FsingleDoc%23"></ne-clipboard></section><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;"><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">近日，龙蜥操作系统 Anolis OS 获得 Gitee 认可，在众多开源项目中脱颖而出，荣获 GVP（ Gitee Most Valuable Project，即最有价值开源项目）称号。</span></p><article data-identifier-application__slash__x-doc-key="ABmOor4xydxWqawZ"><article data-clipboard-cangjie="[&quot;root&quot;,{},[&quot;p&quot;,{&quot;uuid&quot;:&quot;lrezcm8lam8s8sce36&quot;,&quot;jc&quot;:&quot;center&quot;},[&quot;img&quot;,{&quot;src&quot;:&quot;https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOor4rBQ3yqawZ/img/923b311f-c690-47e0-968b-cf7192fd62ea.jpg&quot;,&quot;width&quot;:341,&quot;height&quot;:455,&quot;opacity&quot;:1,&quot;uuid&quot;:&quot;ls2t7an6bcla5vee0pa&quot;,&quot;extraData&quot;:{&quot;resourceId&quot;:&quot;923b311f-c690-47e0-968b-cf7192fd62ea&quot;,&quot;metaData&quot;:{&quot;size&quot;:2830050,&quot;originWidth&quot;:3024,&quot;originHeight&quot;:4032,&quot;format&quot;:&quot;jpg&quot;,&quot;ratio&quot;:1}},&quot;rotation&quot;:0},[&quot;span&quot;,{&quot;data-type&quot;:&quot;text&quot;},[&quot;span&quot;,{&quot;data-type&quot;:&quot;leaf&quot;},&quot;&quot;]]]]]" data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnV1aWQlMjIlM0ElMjJscmV6Y204bGFtOHM4c2NlMzYlMjIlMkMlMjJqYyUyMiUzQSUyMmNlbnRlciUyMiU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJpbmxpbmUlMjIlMkMlMjJ0eXBlJTIyJTNBJTIyaW1hZ2UlMjIlMkMlMjJkYXRhJTIyJTNBJTdCJTIyc3JjJTIyJTNBJTIyaHR0cHMlM0ElMkYlMkZhbGlkb2NzLm9zcy1jbi16aGFuZ2ppYWtvdS5hbGl5dW5jcy5jb20lMkZyZXMlMkZBQm1Pb3I0ckJRM3lxYXdaJTJGaW1nJTJGOTIzYjMxMWYtYzY5MC00N2UwLTk2OGItY2Y3MTkyZmQ2MmVhLmpwZyUyMiUyQyUyMndpZHRoJTIyJTNBMzQxJTJDJTIyaGVpZ2h0JTIyJTNBNDU1JTJDJTIyb3BhY2l0eSUyMiUzQTElMkMlMjJ1dWlkJTIyJTNBJTIybHMydDdhbjZiY2xhNXZlZTBwYSUyMiUyQyUyMmV4dHJhRGF0YSUyMiUzQSU3QiUyMnJlc291cmNlSWQlMjIlM0ElMjI5MjNiMzExZi1jNjkwLTQ3ZTAtOTY4Yi1jZjcxOTJmZDYyZWElMjIlMkMlMjJtZXRhRGF0YSUyMiUzQSU3QiUyMnNpemUlMjIlM0EyODMwMDUwJTJDJTIyb3JpZ2luV2lkdGglMjIlM0EzMDI0JTJDJTIyb3JpZ2luSGVpZ2h0JTIyJTNBNDAzMiUyQyUyMmZvcm1hdCUyMiUzQSUyMmpwZyUyMiUyQyUyMnJhdGlvJTIyJTNBMSU3RCU3RCUyQyUyMnJvdGF0aW9uJTIyJTNBMCU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJ0ZXh0JTIyJTJDJTIybGVhdmVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJsZWFmJTIyJTJDJTIydGV4dCUyMiUzQSUyMiUyMiUyQyUyMm1hcmtzJTIyJTNBJTVCJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTdE" data-identifier-application__slash__x-doc-key="ABmOor4xydxWqawZ"><article data-clipboard-cangjie="[&quot;root&quot;,{},[&quot;p&quot;,{&quot;uuid&quot;:&quot;ls2w8i6r6ruyj6gisz9&quot;,&quot;jc&quot;:&quot;justify&quot;},[&quot;img&quot;,{&quot;id&quot;:&quot;uip7mi&quot;,&quot;name&quot;:&quot;bf5edbe747ed2378318be806f1952707.jpeg&quot;,&quot;size&quot;:1934061,&quot;width&quot;:748,&quot;height&quot;:561,&quot;uuid&quot;:&quot;ls2xnew0h5jwcuopd9o&quot;,&quot;src&quot;:&quot;https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOor4xydxWqawZ/img/c54a56e0-b42d-4fea-aff1-df1f042076f8.jpeg&quot;,&quot;extraData&quot;:{&quot;resourceId&quot;:&quot;c50ad89f-46e1-40f0-98b6-79ee3aa06e8d&quot;,&quot;metaData&quot;:{&quot;size&quot;:1934061,&quot;originWidth&quot;:3648,&quot;originHeight&quot;:2736,&quot;format&quot;:&quot;jpg&quot;,&quot;ratio&quot;:0}}},[&quot;span&quot;,{&quot;data-type&quot;:&quot;text&quot;},[&quot;span&quot;,{&quot;data-type&quot;:&quot;leaf&quot;},&quot;&quot;]]]]]" data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnV1aWQlMjIlM0ElMjJsczJ3OGk2cjZydXlqNmdpc3o5JTIyJTJDJTIyamMlMjIlM0ElMjJqdXN0aWZ5JTIyJTdEJTJDJTIybm9kZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMmlubGluZSUyMiUyQyUyMnR5cGUlMjIlM0ElMjJpbWFnZSUyMiUyQyUyMmRhdGElMjIlM0ElN0IlMjJpZCUyMiUzQSUyMnVpcDdtaSUyMiUyQyUyMm5hbWUlMjIlM0ElMjJiZjVlZGJlNzQ3ZWQyMzc4MzE4YmU4MDZmMTk1MjcwNy5qcGVnJTIyJTJDJTIyc2l6ZSUyMiUzQTE5MzQwNjElMkMlMjJ3aWR0aCUyMiUzQTc0OCUyQyUyMmhlaWdodCUyMiUzQTU2MSUyQyUyMnV1aWQlMjIlM0ElMjJsczJ4bmV3MGg1andjdW9wZDlvJTIyJTJDJTIyc3JjJTIyJTNBJTIyaHR0cHMlM0ElMkYlMkZhbGlkb2NzLm9zcy1jbi16aGFuZ2ppYWtvdS5hbGl5dW5jcy5jb20lMkZyZXMlMkZBQm1Pb3I0eHlkeFdxYXdaJTJGaW1nJTJGYzU0YTU2ZTAtYjQyZC00ZmVhLWFmZjEtZGYxZjA0MjA3NmY4LmpwZWclMjIlMkMlMjJleHRyYURhdGElMjIlM0ElN0IlMjJyZXNvdXJjZUlkJTIyJTNBJTIyYzUwYWQ4OWYtNDZlMS00MGYwLTk4YjYtNzllZTNhYTA2ZThkJTIyJTJDJTIybWV0YURhdGElMjIlM0ElN0IlMjJzaXplJTIyJTNBMTkzNDA2MSUyQyUyMm9yaWdpbldpZHRoJTIyJTNBMzY0OCUyQyUyMm9yaWdpbkhlaWdodCUyMiUzQTI3MzYlMkMlMjJmb3JtYXQlMjIlM0ElMjJqcGclMjIlMkMlMjJyYXRpbyUyMiUzQTAlN0QlN0QlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIydGV4dCUyMiUyQyUyMmxlYXZlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIybGVhZiUyMiUyQyUyMnRleHQlMjIlM0ElMjIlMjIlMkMlMjJtYXJrcyUyMiUzQSU1QiU1RCU3RCU1RCU3RCU1RCU3RCU1RCU3RCU1RCU3RA==" data-identifier-application__slash__x-doc-key="ABmOor4xydxWqawZ"><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-backh="434" data-backw="578" data-imgfileid="100038991" data-ratio="0.75" src="https://oscimg.oschina.net/oscnet/f0a958d9-c9d1-4b5e-a125-a1badd9c34d6.jpg" data-type="jpeg" data-w="1080" style="width: 100%;height: auto;" referrerpolicy="no-referrer"></p></article></article><p style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 16px;"><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">（图</span><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">/&nbsp;Gitee&nbsp;最有价值开源项目奖</span><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">牌</span><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">）</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 16px;"><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">Gitee 是全球规模第二大的代码托管平台，为超过 500&nbsp;万名开发者和 10&nbsp;万家企业提供服务，该平台托管的开源项目超过 1000&nbsp;万，汇聚了众多国内知名的优秀开源项目，是国内首屈一指的代码托管平台。</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">GVP 是 Gitee 综合评定的优秀开源项目展示平台，其评选</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">既要获得开发者广泛认可、满足客观硬性指标，也要通过评委会专家的共同评定才可入选。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 16px;"><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">龙蜥社区（OpenAnolis）是立足中国面向国际的 Linux 服务器操作系统开源根社区，引领云智融合技术浪潮下国产操作系统的创新发展。</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">龙蜥操作系统 Anolis OS 搭载了 ANCK 版本的内核，性能和稳定性经过历年「双 11」历练，能为云上典型用户场景带来 40%&nbsp;的综合性能提升，故障率降低 50%，兼容 CentOS 生态，提供平滑的 CentOS 迁移方案，并提供全栈国密能力。</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">龙蜥社区围绕芯片、内核、编译器、安全、虚拟化及云原生等操作系统核心领域进行技术创新，已发布首款拥抱智算时代的<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MTMyMTUwMQ%3D%3D%26mid%3D2247516403%26idx%3D1%26sn%3D0a18dcbe8891f369111d1e6deae3804b%26chksm%3Dcf657381f812fa97e04d6f05257b62da1880ef327a4b10372b4b89cb5882b90d9ceb751a0d6b%26scene%3D21%23wechat_redirect" textvalue="国产操作系统 Anolis OS 23" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">国产操作系统 Anolis OS 23</a>、 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MTMyMTUwMQ%3D%3D%26mid%3D2247491504%26idx%3D1%26sn%3Dea85642b4e5891ef3dee243a4bbf8628%26chksm%3Dcf66ecc2f81165d4f652c5538771320030ac4ff3f511bbeb278561301bed339e7e43bf627d3b%26scene%3D21%23wechat_redirect" textvalue="LoongArch GA" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">LoongArch GA</a>、Anolis OS 7.9、 8.4 、8.6、8.8 等多个社区版本，超万名开发者参与贡献。</span></p></article><section style="margin-right: 8px;margin-bottom: 16px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.75em;text-align: center;"><span style="outline: 0px;font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;color: rgb(136, 136, 136);">—— 完 ——</span></section><section style="margin-right: 8px;margin-bottom: 16px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.75em;"><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">Alib</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">aba Cloud Lin</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">ux 诚邀广大企业用</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">户加入，首批招募 30 家伙伴单位，一起共建云</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">上软件生</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">态繁荣！</span></section><section style="margin-right: 8px;margin-bottom: 16px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.75em;"><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MTMyMTUwMQ%3D%3D%26mid%3D2247520955%26idx%3D1%26sn%3D7a02bf5e9ea85f2af75d19d0bee04120%26chksm%3Dcf6561c9f812e8df7dd7d4d5da9b4b3d6ffa8f89111a5b8c35bfe2295ee5420ff02280183356%26scene%3D21%23wechat_redirect" textvalue="你已选中了添加链接的内容" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="1"><span class="js_jump_icon h5_image_link" style="outline: 0px;vertical-align: bottom;user-select: none;width: 100%;"><img class="rich_pages wxw-img" data-backh="250" data-backw="562" data-imgfileid="100038588" data-ratio="0.4444444444444444" src="https://oscimg.oschina.net/oscnet/a899e876-a6bd-473a-b20a-3e5ee6535362.jpg" data-w="900" style="outline: 0px;border-width: 0px;border-style: initial;border-color: initial;border-radius: 18px;width: 100%;visibility: visible !important;height: auto;" referrerpolicy="no-referrer"></span></a></span></section><section style="display: none;line-height: 1.75em;"><br></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - OpenAnolis 龙蜥（OpenAnolis）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 11:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5265430/blog/11030226</guid>
            <link>https://my.oschina.net/u/5265430/blog/11030226</link>
            <author>
                <![CDATA[OpenAnolis 龙蜥社区]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[用 AI 大模型在线写春联]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/2720166_2331677">用 AI 大模型在线写春联，欢迎来玩</a><div class="ui red label horizontal" data-tooltip="置顶">顶</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/hardbone" class="__user"><span>局</span></a> 发布于，今天 16:33
                    </div><div class="item">阅读 78</div><div class="item collect-btn " data-id="2331677" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331677" data-obj-type="2">0</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/2720166_2331677#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">0</span></a></div></div><div class="content" id="articleContent"><p>体验地址：</p><h4><u><em><strong><a href="https://tool.oschina.net/ai_couplet" target="_blank" rel="nofollow">https://tool.oschina.net/ai_couplet</a></strong></em></u></h4><p>对联成品：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f31a898dac4327a0da89726e61fbecde959.png" referrerpolicy="no-referrer"></p><p>使用方法：</p><p>在输入框写提示词，点击「生成春联」即可。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0e8f04687bd6129ce3854330412d0c2ddf2.png" referrerpolicy="no-referrer"></p></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331677" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331677" data-obj-type="2">0</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331677" data-obj-type="2" data-url="https://www.oschina.net/question/2720166_2331677"><i class="flag red icon"></i>举报</a></div></div>
            ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 11:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/2720166_2331677</guid>
            <link>https://www.oschina.net/question/2720166_2331677</link>
        </item>
        <item>
            <title>
                <![CDATA[PostgreSQL 90% 的新代码仅由 50 人完成，拓数派荣占一席]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>PostgreSQL 作为世界上最受欢迎的开源数据库之一，于去年荣获&nbsp;DB-Engines 2023 年度数据库，其全球 Committer 人数却长期维持在较少的数目（约 30 人），全球 Contributor 名单也罕见中国人身影。<strong>拓数派长期以来一直以强大的技术能力，用高质量、高数量的代码贡献力参与到 PostgreSQL 社区的产品和生态建设中。</strong></p><p>EnterpriseDB 首席数据库科学家 Robert Haas 是 PostgreSQL 主要贡献者，自 2009 年开始就作为 PostgreSQL Committer 参与到 PostgreSQL 的代码 commit、review 和 merge 工作中。自 2017 年起，Robert&nbsp;已经连续 8 年持续统计 PostgreSQL 的贡献者情况，并在其于 1 月 29 日发布的《Who Contributed to PostgreSQL Development in 2023》博文中提到：</p><blockquote><p><strong>「2023 年，PostgreSQL 66% 的新代码是由其中的 18 人贡献的，而 90% 的新代码贡献是由 50 人完成的。」</strong></p></blockquote><p>这 50 位主要贡献者中，仅有 2 名中国人，<strong>拓数派技术专家 Richard Guo 便是其中之一，这已经是 Richard 荣登该榜单的第二年。</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e337e187374f776c9e8c21e63805794e579.png" referrerpolicy="no-referrer"></p><p style="text-align:center">拓数派&nbsp;Richard&nbsp;Guo&nbsp;连续两年被列为&nbsp;PostgreSQL&nbsp;主要贡献者</p><p>在 Robert 的统计中，2023 年，Richard 为 PostgreSQL 贡献了 1710 行代码，提交了 40 个 Commits，在名单中排名 25 名。2022 年的统计中，Richard 同样荣登代码主要贡献榜单，以 1071 行代码，24 个 Commits，在 40 名主要代码贡献者中排名 38 名。</p><p>由于 Robert 的统计数据仅包括 Commits 所涉及的第一作者（Principle Author），Richard 的贡献量远不止这些。<strong>经统计，Richard 在 PostgreSQL 16 版本中参与的 Commits 数为 118。</strong></p><p>除了 Richard，拓数派多位研发同事均对 PostgreSQL 多个版本做出了代码贡献，尤其是在 PostgreSQL 16 发布中，共有 33 名贡献者来自中国，<strong>而拓数派占据其中 5 席，并以接近一半的 Commits 次数在国内独占鳌头</strong>。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-161a9945b89959aba9dd3b332765f0873e3.png" referrerpolicy="no-referrer"></p><p style="text-align:center">PostgreSQL 16&nbsp;中拓数派贡献量在国内独占鳌头</p><p>不管是代码贡献质量，或是数量上，拓数派团队一如既往的引领 PostgreSQL 中国贡献力。<strong>这一成绩充分说明了拓数派团队的技术实力与拥抱开放的企业文化。</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-62da53dc8790271b70bb5370ee426da3059.png" referrerpolicy="no-referrer"></p><p style="text-align:center">拓数派获得的 PostgreSQL 社区代码贡献致谢奖章</p><p>除了 PostgreSQL 社区,拓数派团队还一直以代码贡献、讲师布道等多种形式活跃于 PostgreSQL、Clickhouse、Kubernetes、Spark 等开源社区，<strong>并利用长期积累的技术能力为云原生虚拟数仓 PieCloudDB 「添砖加瓦」</strong> ，为用户带来更灵活、更安全、更易用的使用体验和性能特性。未来，拓数派团队将继续努力，在技术之路上不断创新，引领行业前行。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 09:42:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277896</guid>
            <link>https://www.oschina.net/news/277896</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[深圳开放智算中心点亮运营]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">昨日，深圳开放智算中心点亮运营，同期深圳市智慧城市算力统筹调度平台揭牌，这意味着深圳正加快打造 10 万卡级别的超强算力集群。多家人工智能头部企业、电信运营商、行业协会在现场与运营方深智城集团签约开展智能算力合作。</span></p><p><img height="333" src="https://oscimg.oschina.net/oscnet/up-1a3542f35ffad419079830641f01c95149c.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">该「中心+平台」的算力供给调度规模将超 30000P，深圳开放智算中心基于国际主流智能算力芯片，可实现高复杂度、高计算需求的千亿级大模型训练，协助打造「河套-西丽湖-光明科学城」AI 科创算力走廊，助力深圳加快构筑大湾区算力供给高地。</span></p><p><span style="color:#000000">市智慧城市算力统筹调度平台将积极承担公共算力调度、创新服务等功能，探索通过标准化接口汇聚全市多元异构算力、以算网大脑实现算力的弹性分配，全力提供具有公信力、安全性和普惠性的算力供给服务，努力构建超高可靠、极低时延、极速带宽、极高性能、绿色低碳的算力调度体系，助力深圳人工智能产业高质量发展。</span></p><p><span style="color:#000000">据了解，「万卡」是指人工智能大模型产品的开发需要多达一万块 GPU 芯片的智算算力支持，也是指超大型智算中心的规模「门槛」是一万块 GPU 芯片。此次活动由市工信局、市政数局、市科创局、市国资委指导，福田区政府、深智城集团主办。</span></p><p><em><span style="color:#000000">来源：深圳特区报</span></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 08:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277880</guid>
            <link>https://www.oschina.net/news/277880</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeFuse-VLM 开源，支持多模态多任务预训练 / 微调]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1707121095833-b957fd4f-440e-46d0-8084-86c8bab7a005.png" width="900" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>CodeFuse-MFT-VLM 项目地址：</span></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-MFT-VLM" target="_blank" rel="nofollow"><span>https://github.com/codefuse-ai/CodeFuse-MFT-VLM</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>CodeFuse-</span><span style="color:#1f2328">VLM-14B</span><span><span>&nbsp;</span>模型地址：</span></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fss41979310%2FCodeFuse-VLM-14B%2Ffiles" target="_blank" rel="nofollow"><span>https://modelscope.cn/models/ss41979310/CodeFuse-VLM-14B/files</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_1"></span><h3><span style="color:#333333">CodeFuse-VLM 框架简介</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#333333">随着 huggingface 开源社区的不断更新，会有更多的 vision encoder 和 LLM 底座发布，这些 vision encoder 和 LLM 底座都有各自的强项，例如 code-llama 适合生成代码类任务，但是不适合生成中文类的任务，因此用户常常需要根据 vision encoder 和 LLM 的特长来搭建自己的多模态大语言模型。针对多模态大语言模型种类繁多的落地场景，我们搭建了 CodeFuse-VLM 框架，支持多种视觉模型和语言大模型，使得 MFT-VLM 可以适应不同种类的任务。</span></p><p style="margin-left:0; margin-right:0"><span>CodeFuse-VLM 支持多种视觉达模型：CLIP，CLIP-336px，Chinese Clip，Chinese Clip-336px，Qwen Clip；多种语言达模型：Vicuna-7B，Vicunam-13B，LLAMA-2-7B，Qwen-7B，Qwen-14B。用户可以根据自己的需求，通过配置文件的方式搭配 VL-MFTCoder 中不同的 Vision Encoder 和 LLM，使用同一套框架去适配的不同的模型，大大提高了开发效率。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705576530632-29cdc597-d396-4bbd-b02f-310015e7fcda.png" width="1688" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="color:#333333">我们在 2024 年 1 月开源了多模态多任务微调框架——CodeFuse-VLM。在 CodeFuse 多任务微调的基础上，CodeFuse-VLM 可以实现在多个模态，多个任务上同时并行地进行微调。通过结合多种损失函数，我们有效地解决了多任务学习中常见的任务间数据量不平衡、难易不一和收敛速度不一致等挑战。此外，CodeFuse-VLM 框架具备高效训练特征，支持高效的 PEFT 微调，能有效提升微调训练速度并降低对资源的需求。</span></p><div><div class="ckeditor-html5-video"><video controls="controls">
     &nbsp; 
   </video></div><p>&nbsp;</p></div><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_2"></span><h3><span>CodeFuse-VLM-14B 模型</span></h3><p style="margin-left:0; margin-right:0"><span>我们基于 Qwen-VL 的视觉编码器和 Qwen-14B 大语言模型，在 CodeFuse-VLM 框架下训练了 CodeFuse-VLM-14B 模型，在多个通用和代码任务上的性能超过 LLAVA-1.5 和 Qwen-VL。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_3"></span><h4><span>预训练数据</span></h4><p style="margin-left:0; margin-right:0"><span>参考了 Qwen-VL 的 Multi-Task Pretraining 数据集，我们准备使用多种数据对齐 Qwen-VL-14B 的模态。在预训练当中我们使用多任务训练的方式，每一个数据集都是一个训练任务任务。</span></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:750px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>dataset</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>type</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>number of samples</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>synthdog-en</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w<span>&nbsp;</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>synthdog-zh</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>cc3m(downsampled)</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Image Caption</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>55w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>SBU</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Image Caption</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>85w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome Region descriptions</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Ref Grouding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome objects</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Caption With Grouding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR_VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR and VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>我们使用预训练数据集训练模态对齐的 cross attention 模块，可以执行以下代码来启动模型预训练</span></p><pre><code>sh scripts/pretrain_multinode.sh</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_4"></span><h4><span>指令微调数据</span></h4><p style="margin-left:0; margin-right:0"><span>我们使用了 LLAVA-1.5 的指令微调数据，总共 65w 样本，LLAVA 的指令微调数据集包含复杂图片的推理分析，对 LLM 理解视觉特征很有帮助。</span></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/23956347/1701595326578-2fa8ac49-a3a6-413f-9a44-c9fb9416e5eb.png" width="369" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>指令微调数据构成如下，在视觉指令微调当中我们使用多任务训练的方式，每一个数据集都是一个训练任务任务。</span></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:750px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>dataset</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>type</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>number of samples</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR_VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR and VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>7w<span>&nbsp;</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>GQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Image Caption</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>8w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Ref Grouding and Caption With Grouding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>10w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>COCO</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Detailed Description and Complex Reasoning</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>37w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Text-VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Detailed Description and Complex Reasoning</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>3w</span></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>我们使用指令微调数据训练 CodeFuse-VLM-14B 中的 Qwen-14B 大语言模型，可以执行以下代码来启动模型的指令微调</span></p><pre><code>sh scripts/finetune_multinode.sh</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_5"></span><h4><span>模型性能</span></h4><p style="margin-left:0; margin-right:0"><span>我们训练的 CodeFuse-VLM-14B 模型在多个 benchmark 上的表现超过 Qwen-VL 和 LLAVA-1.5, 具体得分参考下面的图表。</span></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705311351163-de87fc69-620f-46f7-9e58-fe48e9d32ee6.png" width="514" referrerpolicy="no-referrer"></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:1000px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Benchmark</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>LLAVA-1.5</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Qwen-VL</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0px; margin-right:0px; text-align:center"><span>CodeFuse-VLM-14B</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>MM_Bench</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span style="color:#4d4d4d">67.7</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>60.6</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><strong><span>75.7</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>MM_Bench_CN</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span style="color:#4d4d4d">63.6</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>56.7</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><strong><span>69.8</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>VqaV2</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><strong><span style="color:#4d4d4d">80.0</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>78.2</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>79.3</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>GQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span style="color:#4d4d4d">63.3</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>57.5</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>59.4</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>TextVqa</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span style="color:#4d4d4d">61.3</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>63.8</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>63.9</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>VizWiz</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span style="color:#4d4d4d">53.6</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>35.25</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>45.3</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>Sketch2Code</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>-</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>90.7</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>94.4</span></strong></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>我们的 CodeFuse-VLM-14B 在 MMBenchmark 的</span><strong><span>中英文榜单</span></strong><span>分别取得第</span><strong><span>13/21</span></strong><span>名的排名，高于 Qwen-VL 第</span><strong><span>29/36</span></strong><span>名的排名</span></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmmbench.opencompass.org.cn%2Fleaderboard" target="_blank" rel="nofollow"><span>https://mmbench.opencompass.org.cn/leaderboard</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_6"></span><h3><span>产品图片</span></h3><p style="margin-left:0; margin-right:0"><span>我们通过 CodeFuse-VLM 在蚂蚁内部训练了网页图片到前端代码的多模态大模型，并把大模型集成到内部的 Visual Studio Code 插件中。如下面两站图所示，左边的图片是网页原图，右边的图片是大模型生成的前端代码渲染出的图片，多模态大模型生成的前端代码渲染出的图片对网页原图有很高的还原性，很大地提高了前端工程师开发的效率。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705907166749-474f92e8-31c1-4b38-9cba-5bd06165c311.png" width="3048" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705907389506-fac00ebc-2646-41fa-b847-7d40a6f2a1de.png" width="1560" referrerpolicy="no-referrer"></p></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 08:33:23 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/11030240</guid>
            <link>https://my.oschina.net/u/6942768/blog/11030240</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><p><strong># 2024.2.4</strong></p><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要点</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/277597/vuejs-10yr" target="_blank">10 年前的今天 —— Vue.js 正式问世</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">10 年前的今天（2014 年 2 月 3 日），Vue 在 Hacker News 上首次对外亮相：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D7169288" target="_blank">news.ycombinator.com/item?id=7169288</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">10 年后，Vue 已成为使用最广泛的前端项目之一，在世界各地拥有多元化的社区。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-581bff0bf554afab956437fa62cb1777d18.png" referrerpolicy="no-referrer"></p><h3><u><a href="https://www.oschina.net/news/277568" target="_blank">扎克伯格解释 Meta 为什么要开源其 AI 技术</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Meta 开源其 AI 技术是出于推动技术创新、提升模型质量、建立行业标准、吸引人才、增加透明度和支持其长期战略的考虑。这不仅有助于 Meta 在竞争激烈的 AI 领域保持领先地位，也有助于推动整个行业的前进。</p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推荐</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-41e1b46b27f9899b2f2893d8ed2b70534e9.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">开源之声</span></span></span></span></span></span></strong></h2><p><img height="1430" src="https://oscimg.oschina.net/oscnet/up-32c6e76e1aeb2f3d27d77abe42640a381f6.png" width="2400" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日项目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜单：</p><p><img src="https://oscimg.oschina.net/oscnet/up-c6a5d161821e5d48ee96c57b0e92da312f7.png" referrerpolicy="no-referrer"></p><blockquote><h4><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span><br><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC008%E6%9C%9F%EF%BC%9A%E6%8E%A8%E5%8A%A8%E4%B8%AD%E5%9B%BD%E5%BC%80%E6%BA%90%E8%BD%AF%E7%A1%AC%E4%BB%B6%E5%8F%91%E5%B1%95%E7%9A%84%E7%BB%8F%E9%AA%8C%E4%B8%8E%E5%BB%BA%E8%AE%AE.pdf" target="_blank">开源日报 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><u><a href="https://www.oschina.net/news/277585" target="_blank">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></u></li><li><u><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">开源日报第 006 期：选择技术栈一定要选择开源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 04:09:04 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277841</guid>
            <link>https://www.oschina.net/news/277841</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[KubeEdge v1.16.0 版本发布！10 项新增特性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自华为云社区《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F421489%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">KubeEdge v1.16.0 版本发布！集群升级部署易用性大幅提升</a>》，作者： 容器大未来。</p><p>北京时间 2024 年 1 月 23 日，KubeEdge 发布 1.16.0 版本。新版本新增多个增强功能，在集群升级、集群易用性、边缘设备管理等方面均有大幅提升。</p><p><strong>KubeEdge v1.16.0 新增特性：</strong></p><ul><li><div>
    集群升级：支持云边组件自动化升级 
  </div></li><li><div>
    支持边缘节点的镜像预下载 
  </div></li><li><div>
    支持使用 Keadm 安装 Windows 边缘节点 
  </div></li><li><div>
    增加多种容器运行时的兼容性测试 
  </div></li><li><div>
    EdgeApplication 中支持更多 Deployment 对象字段的 Override 
  </div></li><li><div>
    支持基于 Mapper-Framework 的 Mapper 升级 
  </div></li><li><div>
    DMI 数据面内置集成 Redis 与 TDEngine 数据库 
  </div></li><li><div>
    基于 Mapper-Framework 的 USB-Camera Mapper 实现 
  </div></li><li><div>
    易用性提升：基于 Keadm 的部署能力增强 
  </div></li><li>升级 K8s 依赖到 v1.27</li></ul><div><div><div><div><div><div><div><div><div><div><img alt="kubeedge.jpeg" src="https://bbs-img.huaweicloud.com/blogs/img/20240202/1706837744174647751.jpeg" referrerpolicy="no-referrer"></div></div></div><div><span id="OSC_h1_1"></span><h1>新特性概览</h1></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div><div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div></div></div></div></div><span id="OSC_h3_2"></span><h3>集群升级：支持云边组件自动化升级</h3><p>随着 KubeEdge 社区的持续发展，社区版本不断迭代；用户环境版本升级的诉求亟需解决。针对升级步骤难度大，边缘节点重复工作多的问题，v1.16.0 版本的 KubeEdge 支持了云边组件的自动化升级。用户可以通过 Keadm 工具一键化升级云端，并且可以通过创建相应的 Kubernetes API，批量升级边缘节点。</p><ul><li><strong>云端升级</strong></li></ul><p>云端升级指令使用了三级命令与边端升级进行了区分，指令提供了让用户使用更便捷的方式来对云端的 KubeEdge 组件进行升级。当前版本升级完成后会打印 ConfigMap 历史配置，如果用户手动修改过 ConfigMap，用户可以选择通过历史配置信息来还原配置文件。我们可以通过 help 参数查看指令的指导信息：</p><div><pre>keadm upgrade cloud --help
Upgrade the cloud components to the desired version, it uses helm to upgrade the installed release of cloudcore chart, which includes all the cloud components

Usage:
  keadm upgrade cloud [flags]

Flags:
      --advertise-address string    Please set the same value as when you installed it, this value is only used to generate the configuration and does not regenerate the certificate. eg: 10.10.102.78,10.10.102.79
  -d, --dry-run                     Print the generated k8s resources on the stdout, not actual execute. Always use in debug mode
      --external-helm-root string   Add external helm root path to keadm
      --force                       Forced upgrading the cloud components without waiting
  -h, --help                        help for cloud
      --kube-config string          Use this key to update kube-config path, eg: $HOME/.kube/config (default "/root/.kube/config")
      --kubeedge-version string     Use this key to set the upgrade image tag
      --print-final-values          Print the final values configuration for debuging
      --profile string              Sets profile on the command line. If '--values' is specified, this is ignored
      --reuse-values                reuse the last release's values and merge in any overrides from the command line via --set and -f.
      --set stringArray             Sets values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --values stringArray          specify values in a YAML file (can specify multiple)</pre></div><p>升级指令样例：</p><div><pre>keadm upgrade cloud --advertise-address=&lt;init 时设置的值&gt; --kubeedge-version=v1.16.0</pre></div><ul><li><strong>边端升级</strong></li></ul><p>v1.16.0 版本的 KubeEdge 支持通过 NodeUpgradeJob 的 Kubernetes API 进行边缘节点的一键化、批量升级。API 支持边缘节点的升级预检查、并发升级、失败阈值、超时处理等功能。对此，KubeEdge 支持了云边任务框架。社区开发者将无需关注任务控制、状态上报等逻辑实现，只需聚焦云边任务功能本身。</p><p>升级 API 样例：</p><div><pre>apiVersion: operations.kubeedge.io/v1alpha1
kind: NodeUpgradeJob
metadata:
  name: upgrade-example
  labels:
    description: upgrade-label
spec:
  version: "v1.16.0"
  checkItems:
    - "cpu"
    - "mem"
    - "disk"
  failureTolerate: "0.3"
  concurrency: 2
  timeoutSeconds: 180
  labelSelector:
    matchLabels:
      "node-role.kubernetes.io/edge": ""
      node-role.kubernetes.io/agent: ""</pre></div><ul><li><strong>兼容测试</strong></li></ul><p>KubeEdge 社区提供了完备的版本兼容性测试，用户在升级时仅需要保证云边版本差异不超过 2 个版本，就可以避免升级期间云边版本不一致带来的问题。</p><div>
  更多信息可参考： 
</div><p>https://github.com/kubeedge/kubeedge/pull/5330</p><p>https://github.com/kubeedge/kubeedge/pull/5229</p><div>
  https://github.com/kubeedge/kubeedge/pull/5289 
</div><span id="OSC_h3_3"></span><h3>支持边缘节点的镜像预下载</h3><p>新版本引入了镜像预下载新特性，用户可以通过 ImagePrePullJob 的 Kubernetes API 提前在边缘节点上加载镜像，该特性支持在批量边缘节点或节点组中预下载多个镜像，帮助减少加载镜像在应用部署或更新过程，尤其是大规模场景中，带来的失败率高、效率低下等问题。</p><p>镜像预下载 API 示例：</p><div><pre>apiVersion: operations.kubeedge.io/v1alpha1
kind: ImagePrePullJob
metadata:
  name: imageprepull-example
  labels:
    description:ImagePrePullLabel
spec:
  imagePrePullTemplate：
    images:
      - image1
      - image2
    nodes：
      - edgenode1
      - edgenode2
    checkItems:
      - "disk"
    failureTolerate: "0.3"
    concurrency: 2
    timeoutSeconds: 180
    retryTimes: 1</pre></div><p>更多信息可参考：</p><p>https://github.com/kubeedge/kubeedge/pull/5310</p><p>https://github.com/kubeedge/kubeedge/pull/5331</p><span id="OSC_h3_4"></span><h3>支持使用 Keadm 安装 Windows 边缘节点</h3><p>KubeEdge 1.15.0 版本实现了在 Windows 上运行边缘节点，在新版本中，我们支持使用安装工具 Keadm 直接安装 Windows 边缘节点，操作命令与 Linux 边缘节点相同，简化了边缘节点的安装步骤。</p><p>更多信息可参考：https://github.com/kubeedge/kubeedge/pull/4968</p><span id="OSC_h3_5"></span><h3>增加多种容器运行时的兼容性测试</h3><p>新版本中新增了多种容器运行时的兼容性测试，目前已集成了<strong>containerd</strong>，<strong>docker</strong>，<strong>isulad</strong><span>&nbsp;</span>和<span>&nbsp;</span><strong>cri-o<span>&nbsp;</span></strong>4 种主流容器运行时，保障 KubeEdge 版本发布质量，用户在安装容器运行时过程中也可以参考该 PR 中的适配安装脚本。</p><p>更多信息可参考：https://github.com/kubeedge/kubeedge/pull/5321</p><span id="OSC_h3_6"></span><h3>EdgeApplication 中支持更多 Deployment 对象字段的 Override</h3><p>在新版本中，我们扩展了 EdgeApplication 中的差异化配置项（overriders），主要的扩展有环境变量、命令参数和资源。当您不同区域的节点组环境需要链接不同的中间件时，就可以使用环境变量（env）或者命令参数（command, args）去重写中间件的链接信息。或者当您不同区域的节点资源不一致时，也可以使用资源配置（resources）去重写 cpu 和内存的配置。</p><p>更多信息可参考：</p><div>
  https://github.com/kubeedge/kubeedge/pull/5262 
</div><p>https://github.com/kubeedge/kubeedge/pull/5370</p><span id="OSC_h3_7"></span><h3>支持基于 Mapper-Framework 的 Mapper 升级</h3><p>1.16.0 版本中，基于 Mapper 开发框架 Mapper-Framework 构建了 Mapper 组件的升级能力。新框架生成的 Mapper 工程以依赖引用的方式导入原有 Mapper-Framework 的部分功能，在需要升级时，用户能够以升级依赖版本的方式完成，简化 Mapper 升级流程。</p><ul><li><div><strong>Mapper-Framework 代码解耦:</strong></div></li></ul><div>
  1.16.0 版本中将 Mapper-Framework 中的代码解耦为用户层和业务层。用户层功能包括设备驱动及与之强相关的部分管理面数据面能力，仍会随 Mapper-Framework 生成在用户 Mapper 工程中，用户可根据实际情况修改。业务层功能包括 Mapper 向云端注册、云端下发 Device 列表等能力，会存放在 kubeedge/mapper-framework 子库中。 
</div><ul><li><strong>Mapper 升级框架:</strong></li></ul><p>1.16.0 版本 Mapper-Framework 生成的用户 Mapper 工程通过依赖引用的方式使用 kubeedge/mapper-framework 子库中业务层功能，实现完整的设备管理功能。后续用户能够通过升级依赖版本的方式达到升级 Mapper 的目的，不再需要手动修改大范围代码。</p><p>更多信息可参考：</p><div>
  https://github.com/kubeedge/kubeedge/pull/5308 
</div><p>https://github.com/kubeedge/kubeedge/pull/5326</p><span id="OSC_h3_8"></span><h3>DMI 数据面内置集成 Redis 与 TDEngine 数据库</h3><p>1.16.0 版本中进一步增强 DMI 数据面中向用户数据库推送数据的能力，增加 Redis 与 TDengine 数据库作为内置数据库。用户能够直接在 device-instance 配置文件中定义相关字段，实现 Mapper 自动向 Redis 与 TDengine 数据库推送设备数据的功能，相关数据库字段定义为：</p><div><pre>type DBMethodRedis struct {
 // RedisClientConfig of redis database
 // +optional
 RedisClientConfig *RedisClientConfig `json:"redisClientConfig,omitempty"`
}
type RedisClientConfig struct {
 // Addr of Redis database
 // +optional
 Addr string `json:"addr,omitempty"`
 // Db of Redis database
 // +optional
 DB int `json:"db,omitempty"`
 // Poolsize of Redis database
 // +optional
 Poolsize int `json:"poo lsize,omitempty"`
 // MinIdleConns of Redis database
 // +optional
 MinIdleConns int `json:"minIdleConns,omitempty"`
}</pre><pre>type DBMethodTDEngine struct {
 // tdengineClientConfig of tdengine database
 // +optional
 TDEngineClientConfig *TDEngineClientConfig `json:"TDEngineClientConfig,omitempty"`
}
type TDEngineClientConfig struct {
 // addr of tdEngine database
 // +optional
 Addr string `json:"addr,omitempty"`
 // dbname of tdEngine database
 // +optional
 DBName string `json:"dbName,omitempty"`
}</pre></div><p>更多信息可参考：https://github.com/kubeedge/kubeedge/pull/5064</p><span id="OSC_h3_9"></span><h3>基于 Mapper-Framework 的 USB-Camera Mapper 实现</h3><p>基于 KubeEdge 的 Mapper-Framework，新版本提供了 USB-Camera 的 Mapper 样例，该 Mapper 根据 USB 协议的 Camera 开发，用户可根据该样例和 Mapper-Framework 更轻松地开发具体业务相关的 Mapper。</p><p>在样例中提供了 helm chart 包，用户可以通过修改 usbmapper-chart/values.yaml 部署 UBS-Camera Mapper，主要添加 USB-Camera 的设备文件, nodeName, USB-Camera 的副本数，其余配置修改可根据具体情况而定，通过样例目录中的 Dockerfile 制作 Mapper 镜像。</p><div><pre>global: 
  replicaCounts:
......   
    cameraUsbMapper:
      replicaCount: 2  #USB-Camera 的副本数
      namespace: default
......  
  nodeSelectorAndDevPath:
    mapper:  
       - edgeNode: "edgenode02"  #USB-Camera 连接的缘节点 nodeName
         devPath: "/dev/video0"  #USB-Camera 的设备文件 
       - edgeNode: "edgenode1"  
         devPath: "/dev/video17"
......</pre></div><p>USB-Camera Mapper 的部署命令如下：</p><div><pre>helm install usbmapper-chart ./usbmapper-chart</pre></div><div>
  更多信息可参考：https://github.com/kubeedge/mappers-go/pull/122 
</div><span id="OSC_h3_10"></span><h3>易用性提升：基于 Keadm 的部署能力增强</h3><ul><li><strong>添加云边通信协议配置参数</strong></li></ul><p>在 KubeEdge v1.16.0 中，使用 keadm join 边缘节点时，支持使用--hub-protocol 配置云边通信协议。目前 KubeEdge 支持 websocket 和 quic 两种通信协议，默认为 websocket 协议。</p><p>命令示例：</p><div><pre>keadm join --cloudcore-ipport &lt;云节点 ip&gt;:10001 --hub-protocol=quic --kubeedge-version=v1.16.0 --token=xxxxxxxx</pre></div><p><strong>说明：</strong>当--hub-protocol 设置为 quic 时，需要将--cloudcore-ipport 的端口设置为 10001，并需在 CloudCore 的 ConfigMap 中打开 quic 开关，即设置 modules.quic.enable 为 true。</p><p><strong>操作示例</strong>：使用 kubectl edit cm -n kubeedge cloudcore，将 quic 的 enable 属性设置成 true，保存修改后重启 CloudCore 的 pod。</p><div><pre>modules：
......
  quic:
    address: 0.0.0.0
    enable: true  #quic 协议开关
    maxIncomingStreams: 10000
    port: 10001
......</pre></div><p>更多信息可参考：https://github.com/kubeedge/kubeedge/pull/5156</p><ul><li><strong>keadm join 与 CNI 插件解耦</strong></li></ul><p>在新版本中，keadm join 边缘节点时，不需要再提前安装 CNI 插件，已将边缘节点的部署与 CNI 插件解耦。同时该功能已同步到 v1.12 及更高版本，欢迎用户使用新版本或升级老版本。</p><p><strong>说明</strong>：如果部署在边缘节点上的应用程序需要使用容器网络，则在部署完 EdgeCore 后仍然需要安装 CNI 插件。</p><p>更多信息可参考：</p><p>https://github.com/kubeedge/kubeedge/pull/5196</p><span id="OSC_h3_11"></span><h3>升级 K8s 依赖到 v1.27</h3><p>新版本将依赖的 Kubernetes 版本升级到 v1.27.7，您可以在云和边缘使用新版本的特性。</p><p>更多信息可参考：</p><div>
  https://github.com/kubeedge/kubeedge/pull/5121 
</div><div><div><div><div><div><div><div><div><span id="OSC_h1_12"></span><h1>版本升级注意事项</h1></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div><div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div></div></div></div></div><p>新版本我们使用 DaemonSet 来管理边端的 MQTT 服务 Eclipse Mosquitto 了，我们能够通过云端 Helm Values 配置来设置是否要开启 MQTT 服务。使用 DaemonSet 管理 MQTT 后，我们可以方便的对边端 MQTT 进行统一管理，比如我们可以通过修改 DaemonSet 的配置将边端 MQTT 替换成 EMQX。</p><p>但是如果您是从老版本升级到最新版本，则需要考虑版本兼容问题，同时使用原本由静态 Pod 管理的 MQTT 和使用新的 DaemonSet 管理的 MQTT 会产生端口冲突。兼容操作步骤参考：</p><div><strong>1、您可以在云端执行命令，将旧的边缘节点都打上自定义标签</strong></div><div><pre>kubectl label nodes --selector=node-role.kubernetes.io/edge without-mqtt-daemonset=""</pre></div><div><strong>2、您可以修改 MQTT DaemonSet 的节点亲和性</strong></div><div><pre>nodeAffinity:
  requiredDuringSchedulingIgnoredDuringExecution:
    nodeSelectorTerms:
      - matchExpressions:
          - ...
          - key: without-mqtt-daemonset
            operator: Exists</pre></div><div><strong>3、将节点 MQTT 改为由 DaemonSet 管理</strong></div><div><pre># ------ 边端 ------
# 修改/lib/systemd/system/edgecore.service，将环境变量 DEPLOY_MQTT_CONTAINER 设置成 false
# 这步可以放在更新 EdgeCore 前修改，这样就不用重启 EdgeCore 了
sed -i '/DEPLOY_MQTT_CONTAINER=/s/true/false/' /etc/systemd/system/edgecore.service

# 停止 EdgeCore
systemctl daemon-reload &amp;&amp; systemctl stop edgecore

# 删除 MQTT 容器，Containerd 可以使用 nerdctl 替换 docker
docker ps -a | grep mqtt-kubeedge | awk '{print $1}' | xargs docker rm -f

# 启动 EdgeCore
systemctl start edgecore

# ------ 云端 ------
# 删除节点标签
kubectl label nodes &lt;NODE_NAME&gt; without-mqtt-daemonset</pre></div><div>
  新版本的 keadm join 命令会隐藏 with-mqtt 参数，并且将默认值设置成 false，如果您还想使用静态 Pod 管理 MQTT，您仍然可以设置参数--with-mqtt 来使其生效。with-mqtt 参数在 v1.18 版本中将会被移除。 
</div><div><div><div><div><div><div><div><div><span id="OSC_h1_13"></span><h1>致谢</h1></div></div></div></div><div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div></div></div></div></div><p>感谢 KubeEdge 社区技术指导委员会 (TSC)、各 SIG 成员对 v1.16.0 版本开发的支持与贡献，未来 KubeEdge 将持续在新场景探索与支持、稳定性、安全性、可扩展性等方面持续发展与演进！</p><div><strong>相关链接</strong></div><p>Release Notes：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubeedge%2Fkubeedge%2Fblob%2Fmaster%2FCHANGELOG%2FCHANGELOG-1.16.md" rel="nofollow" target="_blank">https://github.com/kubeedge/kubeedge/blob/master/CHANGELOG/CHANGELOG-1.16.md</a></p><p>&nbsp;</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>点击关注，第一时间了解华为云新鲜技术~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 04:04:04 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/11030176</guid>
            <link>https://my.oschina.net/u/4526289/blog/11030176</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ReactOS 最新测试版已引入 GUI 安装程序]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>ReactOS 最近进行了一次重要的更新。去年 11 月，ReactOS 开发团队宣布其 64 位 UEFI 启动功能已经支持更广泛的设备。而此次更新主要集中在改善图形用户界面（GUI）安装程序上。</p><p>与文本模式的安装程序"USETUP"相比，GUI 界面更加直观易用，尤其对普通用户而言。对于被称为「开源的 Windows」的 ReactOS 来说，拥有一个定义良好的 GUI 显然是必不可少的。</p><p>ReactOS 在博客文章中<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Freactos.org%2Fblogs%2Fgui-setup-part2-partitioning%2F" target="_blank">写道</a></u>：「虽然文本模式的 USETUP 使用合理的工作流程（每个操作都在不同的屏幕上进行；只允许向前进行，一旦选择了一个操作就无法撤销），但 GUI 模式安装程序改变了其中一些假设。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-287edd3bc4a4238feae4013db6436bcf869.png" referrerpolicy="no-referrer"></p><p>「GUI 设置向导式的风格允许在不同的页面之间来回跳转。它的分区页面显示了一个简约的界面，类似于文本模式的界面，但更让人联想到其他 GUI 分区软件。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-01c01deb4f0860a4323ef7f1277f8ded9a5.png" referrerpolicy="no-referrer"></p><p>从公布截图来看，ReactOS 的 GUI 安装程序与经典 Windows 设置相似，例如 Windows 95。用户可以选择安装目录，但目前 GPT（GUID 分区表）尚未得到支持。</p><ul><li>延伸阅读：<em><a href="https://www.oschina.net/news/260162/reactos-gui-setup-project" target="_blank">「开源 Windows」 ReactOS 改进 GUI 设置 / 安装</a></em></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 03:47:07 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277838/reactos-gui-mode-installer-goes</guid>
            <link>https://www.oschina.net/news/277838/reactos-gui-mode-installer-goes</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周热点 | npm 存在大量武林外传视频；大神只用 Excel 就构建了一颗 CPU；Linus 怒怼谷歌内核贡献者.....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2024.01.29-2024.02.04]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 03:29:07 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094157&#38;idx=1&#38;sn=b292847617ebe4004a3e8540053cfca7&#38;chksm=880c431ebf7bca0826725b540f3eaf79a7f51f14a56ae6297cce70671c632efc8a32903fc6fd&#38;token=1893846415&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094157&#38;idx=1&#38;sn=b292847617ebe4004a3e8540053cfca7&#38;chksm=880c431ebf7bca0826725b540f3eaf79a7f51f14a56ae6297cce70671c632efc8a32903fc6fd&#38;token=1893846415&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[苹果开源 Pkl —— 用于生成配置的编程语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>苹果发布了专用于创建配置文件的脚本编程语言&nbsp;Pkl（发音为 Pickle）。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fd76c052669ab34b0879a64a839ee812dd1.png" referrerpolicy="no-referrer"></p><p><em>官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsspai.com%2Flink%3Ftarget%3Dhttps%253A%252F%252Fpkl-lang.org%252F" target="_blank">pkl-lang.org</a>&nbsp;</em></p><p>Pkl 团队<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpkl-lang.org%2Fblog%2Fintroducing-pkl.html" target="_blank">介绍称</a></u>，该项目旨在应对 JSON、YAML 和属性列表等静态配置格式的不足，提供一种介于静态语言和通用语言之间、「两全其美」的方案。</p><div><div><div><div><div><p style="margin-left:0; margin-right:0"><strong>示例代码</strong></p><p style="margin-left:0; margin-right:0">bird.pkl</p><pre><code class="language-json">name = "Swallow"

job {
  title = "Sr. Nest Maker"
  company = "Nests R Us"
  yearsOfExperience = 2
}</code></pre><p style="margin-left:0; margin-right:0">↓</p><p style="margin-left:0; margin-right:0">bird.json</p><pre><code class="language-json">{
  "name": "Swallow",
  "job": {
    "title": "Sr. Nest Maker",
    "company": "Nests R Us",
    "yearsOfExperience": 2
  }
}</code></pre><p style="margin-left:0; margin-right:0">Pkl 的三个设计目标是语法安全、可扩展和 IDE 集成，使用声明式语法、易读易写，但也支持类、函数、条件和循环等常见的编程语言功能。</p></div></div></div></div></div><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-22c3ee52b4d47fa7152e2e262ed4b875edd.png" referrerpolicy="no-referrer"></p></blockquote><p>根据文档，Pkl 可用于生成任何格式的静态配置文件，也可以作为库嵌入在 Java、Kotlin、Swift、Go 等语言的代码中运行。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d89a660e2346e9f1536d4df60f0ba725793.png" referrerpolicy="no-referrer"></p><p>部分代码示例仓库：</p><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-go-examples" target="_blank">https://github.com/apple/pkl-go-examples</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-jvm-examples" target="_blank">https://github.com/apple/pkl-jvm-examples</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-k8s-examples" target="_blank">https://github.com/apple/pkl-k8s-examples</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-swift-examples" target="_blank">https://github.com/apple/pkl-swift-examples</a></p></li></ul><p>苹果还同步推出了支持 IntelliJ、Visual Studio Code 和 Neovim 等编辑器的 Pkl 插件，但没有为自家 IDE Xcode 开发插件。</p><p><img src="https://oscimg.oschina.net/oscnet/up-eff9cd63e6a81ddfe145eb97dcacb4fed4f.gif" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 02:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277816/apple-pkl-lang</guid>
            <link>https://www.oschina.net/news/277816/apple-pkl-lang</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软为 Windows 11 引入原生 Sudo 命令支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">网曝微软正在 Windows 11 中测试类似 macOS 或 Linux 的原生 Sudo 命令支持。Windows Latest <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowslatest.com%2F2024%2F02%2F01%2Ffirst-look-windows-11-is-getting-native-macos-or-linux-like-sudo-command%2F" target="_blank">报道</a>称，Windows Update 服务器上日前出现了一个泄露的 Windows Server 预览版，包含了一些正在开发的新功能，其中就有 Windows "sudo"命令的新设置。</span></p><p><span style="color:#000000">Sudo「superuser do」命令将作为开发人员设置的一部分出现在 Windows 11 中。它可能允许用户管理需要管理权限的设置，例如卸载应用程序、更改系统设置或其他与开发人员相关的设置。用户将可在 Windows 11 的开发者设置中找到 Sudo 的开关选项。</span></p><blockquote><p><span style="color:#000000">Superuser do (或 sudo) 是一种 Linux 控制枱程序，允许低权限用户以提升的权限（通常是 root）执行命令。该命令提高了 Linux 的安全性，因为服务器可以在低权限账户下正常使用，同时还允许用户在运行特定命令时根据需要提升权限。</span></p></blockquote><p><span style="color:#000000">使用 Sudo 命令前提是需要开启开发者模式，但目前这一功能在泄露的预览版中尚未启用。</span></p><p><span style="color:#000000"><img alt="" height="292" src="https://oscimg.oschina.net/oscnet/up-bb4f7cbad244d7fcc09d756b8b7f03ebbbd.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="312" src="https://oscimg.oschina.net/oscnet/up-83a013eb2b6863974cb93e72362fe94a81f.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">用户可以通过设置使用 Sudo 运行命令的偏好来自定义 Sudo 命令的行为：</span></p><ul><li><span style="color:#000000">开启新窗口：这可能意味着当你使用 Sudo 运行命令时，它会在一个单独的新窗口（可能是终端窗口）中打开，并在该窗口中执行命令。</span></li><li><span style="color:#000000">禁用输入：尚不清楚此切换如何工作。但是从名称来看，它可能表示一种安全功能，即在 Sudo 命令运行时暂时禁用键盘或鼠标的输入，以防止在执行期间发生未经授权的操作。</span></li><li><span style="color:#000000">内联：这可能允许 Sudo 命令在当前窗口或上下文中执行，而无需打开新窗口，这对于快速任务或在集成开发环境 (IDE) 中工作时可能很有帮助。</span></li></ul><p><span style="color:#000000">此外，Sudo 设置还警告称，运行命令可能会使设备和个人数据面临安全风险，并有可能损害用户的设备，但却没有解释其中的猫腻。 只要启用该功能并开启开发者模式，你就可以使用命令提示符、PowerShell 或 Windows 上的任何终端界面访问 Sudo 命令。</span></p><p><span style="color:#000000">目前尚未明确 Sudo 命令何时会出现在生产（稳定）版本中。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 04 Feb 2024 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277814/microsoft-linux-sudo-command-windows</guid>
            <link>https://www.oschina.net/news/277814/microsoft-linux-sudo-command-windows</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gradle 8.6 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">Gradle 8.6&nbsp;现已</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Frelease-notes.html" target="_blank">发布</a><span style="background-color:#ffffff; color:#333333">。Gradle&nbsp;是一个基于&nbsp;Apache Ant&nbsp;和&nbsp;Apache Maven&nbsp;概念的项目自动化构建工具，支持依赖管理和多项目，类似&nbsp;Maven，但比之简单轻便。它使用一种基于&nbsp;Groovy&nbsp;的特定领域语言来声明项目设置，而不是传统的&nbsp;XML。</span></p><p><span style="background-color:#ffffff; color:#333333">此版本支持配置缓存的自定义加密密钥，对 build init 进行了多项改进，并更新了 build authoring API。还为 IDE integrators 提供了更多有用的错误和警告信息以及新的 API。</span></p><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>配置缓存改进</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>配置<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fconfiguration_cache.html" target="_blank">缓存</a>通过缓存配置阶段的结果并将其重用于后续构建来缩短构建时间。此功能可以显着提高构建性能。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>自定义加密密钥</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>配置缓存经过加密，可降低敏感数据意外泄露的风险。默认情况下，Gradle 会自动创建并管理密钥，并将其存储在 Gradle 用户主目录的密钥库中。这样做虽然方便，但在某些环境下可能并不合适。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>现在用户可以向 Gradle 提供用于通过<code>GRADLE_ENCRYPTION_KEY</code>环境变量加密缓存配置数据的密钥。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>更多详细信息查看 Gradle 用户手册的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fconfiguration_cache.html%23config_cache%3Asecrets%3Aconfiguring_encryption_key" target="_blank">配置缓存</a>部分。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Build init 改进</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fbuild_init_plugin.html" target="_blank">build init 插件</a>允许用户轻松创建新的 Gradle 构建，支持各种类型的项目。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Simpler source package handling</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>你不再需要回答有关源包的交互式问题。取而代之的是使用<code>org.example</code>的默认值。你可以使用<code>init</code>任务的现有选项<code>--package</code>flag 来覆盖它。此外，还可以通过在 Gradle 用户主页的<code>gradle.properties</code>中添加<code>org.gradle.buildinit.source.package</code>新属性来设置默认值。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>// ~/.gradle/gradle.properties org.gradle.buildinit.source.package=my.corp.domain </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>生成的 convention plugins 的名称现在以<code>buildlogic</code>开头，而不是软件包名称，从而使名称更简短、更整洁。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Generating without interactive questions</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>新增的 --use-defaults 选项可为未明确配置的选项应用默认值。它还能确保 init 命令在没有交互式用户输入的情况下完成。这在 shell 脚本中非常方便，可确保脚本不会意外挂起。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>例如，你可以在不回答任何问题的情况下生成 Kotlin 库：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>gradle init --use-defaults --type kotlin-library
</code></pre><p style="color:#02303a; text-align:start"><strong>Simpler assignment syntax in Kotlin DSL</strong></p><p style="color:#02303a; text-align:start">示例：</p><pre><code>application {
mainClass = "org.example.AppKt"
}</code></pre><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Build authoring 改进</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Gradle 为插件作者和构建工程师提供了丰富的 API 来开发自定义构建逻辑。如果执行构建不需要任务，则任务配置避免 API 会避免配置任务<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Ftask_configuration_avoidance.html" target="_blank">。</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Lazy name-based filtering of tasks</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start">示例：</p><pre><code>tasks.named { it.contains("pack") }.configureEach {
    // lazily configure details of all '*pack*' tasks that are part of the task graph
}</code></pre><p style="text-align:start"><strong>Allow Providers to be used with dependency capabilities</strong></p><p style="text-align:start">Gradle 支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fcomponent_capabilities.html" target="_blank">声明</a>组件的功能，以便允许 Gradle 在构建时检测和解决依赖项之间的冲突，从而更好地管理依赖项。</p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>dependencies { implementation("org.foo:bar:1.0") { capabilities { // Values in the interpolated String below are lazily evaluated, allowing them to be set after this block requireCapability(project.provider(() -&gt; "${project.group}:${project.name}-platform:${project.version}")) } } } // Later, the version of the project is set. // Without the provider above, this change would not be reflected in the capability. project.version = "1.0.0" </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><h4><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>错误和警告报告改进</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Gradle 提供了一组丰富的错误和警告消息来帮助用户理解和解决构建中的问题。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>出现依赖锁定错误时更清晰的建议操作</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>此版本通过将错误与可能的操作分开以修复控制枱输出中的问题，改进了依赖锁定中的错误消息。启用 strict mode 时，由于锁定文件格式无效或缺少锁定状态而导致的错误现在显示如下：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>FAILURE: Build failed with an exception. * What went wrong: Execution failed for task ':dependencies'. &gt; Could not resolve all dependencies for configuration ':lockedConf'. &gt; Invalid lock state for lock file specified in '&lt;project&gt;/lock.file'. Line: '&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD' * Try: &gt; Verify the lockfile content. For more information on lock file format, please refer to https://docs.gradle.org/8.6/userguide/dependency_locking.html#lock_state_location_and_format in the Gradle documentation. &gt; Run with --info or --debug option to get more log output. &gt; Run with --scan to get full insights. &gt; Get more help at https://help.gradle.org. </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>更好地报告 providers 中的循环引用的错误</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>FAILURE: Build failed with an exception. * Where: Build file '&lt;project&gt;/build.gradle' line: 7 * What went wrong: A problem occurred evaluating root project 'test'. &gt; Circular evaluation detected: property(java.lang.String, map(java.lang.String map(&lt;CIRCULAR REFERENCE&gt;) check-type())) -&gt; map(java.lang.String map(property(java.lang.String, &lt;CIRCULAR REFERENCE&gt;)) check-type()) -&gt; map(property(java.lang.String, map(java.lang.String &lt;CIRCULAR REFERENCE&gt; check-type()))) -&gt; property(java.lang.String, map(java.lang.String map(&lt;CIRCULAR REFERENCE&gt;) check-type())) </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>IDE 集成改进</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fthird_party_integration.html" target="_blank">Gradle 使用 Tooling API</a>&nbsp;集成到许多 IDE 中。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><hr><p style="text-align:start">此外，<span style="background-color:#ffffff; color:#02303a">Gradle 8.6 中还修复了 86 个&nbsp;issue。更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Frelease-notes.html" target="_blank">查看官方公告</a>。</span></p></div>
                                    ]]>
            </description>
            <guid isPermaLink="false">https://www.oschina.net/news/277856/gradle-8-6-released</guid>
            <link>https://www.oschina.net/news/277856/gradle-8-6-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
