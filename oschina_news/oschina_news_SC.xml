<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 14 Mar 2024 12:31:03 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[中国 AIGC 产业全景报告：万亿市场潜力解析、全景图谱揭秘及 50 家机构瞩目亮相！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">《中国 AIGC 产业全景报告》（2023 年 3 月版）由量子位智库出品。报告详细分析了中国 AIGC（人工智能生成内容）产业的市场规模、产业全景图谱、行业变革分析、代表案例以及值得关注的 AIGC 机构。</p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><img height="787" src="https://static.oschina.net/uploads/space/2024/0314/165804_tahR_4700705.png" width="1119" referrerpolicy="no-referrer"></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">以下是报告的核心内容概要：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>市场规模</strong>：</p><ul><li>预计到 2030 年，中国 AIGC 市场规模将达到万亿级别。</li><li>2023-2025 年为培育摸索期，2025-2027 年为应用蓬勃期，2028 年后为整体加速期。</li><li>AIGC 产业的营收模式主要包括 MaaS（Model as Service）、按产出内容量付费、软件订阅付费和模型定制开发费。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>产业全景图谱</strong>：</p><ul><li>AIGC 产业分为基础设施层、模型层和应用层。</li><li>基础设施层包括数据层、算力层、计算平台等。</li><li>模型层主要分为底层通用大模型和中间层模型。</li><li>应用层涉及直接生产可消费内容、结合底层系统生产高附加值内容、提供内容生产辅助工具和提供体系化解决方案。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>行业变革分析</strong>：</p><ul><li>AIGC 技术将深刻影响线上游戏、影视传媒、内容资讯、电子商务等多个行业。</li><li>AIGC 技术的应用将提高创作灵活度、激发内容生产多样性、降低内容创作门槛等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>代表案例</strong>：</p><ul><li>报告列举了多家中国 AIGC 产业的代表性公司及其产品，如百度的「文心一言」、科大讯飞的 SMART-TTS 系统、阿里巴巴的达摩院和阿里云、腾讯的 AlLab 等。</li><li>这些案例展示了 AIGC 技术在不同领域的应用，包括数字人生成、内容创作、虚拟主播、AI 写作等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>中国最值得关注的 50 家 AIGC 机构（AIGC50）</strong>：</p><ul><li>报告评选出了中国最值得关注的 50 家 AIGC 机构，包括百度、阿里巴巴、腾讯、华为、京东科技、小冰公司等，这些机构在 AIGC 领域具有显著的技术实力和市场影响力。</li></ul></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">报告强调了 AIGC 产业的快速发展和巨大潜力，同时也指出了产业发展中的挑战和机遇。通过对市场规模的预测、产业图谱的梳理、行业变革的分析以及代表性案例的展示，报告为读者提供了一个全面的中国 AIGC 产业现状和未来趋势的视角。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 09:07:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283068</guid>
            <link>https://www.oschina.net/news/283068</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[VLC 下载量突破 50 亿，计划推出 Vision Pro 应用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">开发 VLC 及相关技术的非营利组织 VideoLAN 的总裁 Jean-Baptiste Kempf <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lowpass.cc%2Fp%2Fvlc-five-billion-downloads-vision-pro-app" target="_blank">透露</a>，开源多媒体播放器 VLC 在桌面和移动平台上的下载量已超过了 50 亿次。</span></p><p><span style="color:#000000">VLC 于 2001 年首次发布，是有史以来最成功、最知名的开源桌面应用程序之一。2019 年初，该应用的下载量突破了 30 亿次；尽管 Netflix 等流媒体服务近年来有所增长，但大众对它的兴趣依然浓厚。就 11 月发布的最新 VLC 版本而言，仅桌面用户的下载量就已达到了 3.35 亿次。</span></p><p><img height="281" src="https://oscimg.oschina.net/oscnet/up-4d9be4beeb6dac65d1b5272e14016566b55.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">VLC 在移动设备上的使用量也在持续增加，Android 和 iOS 版本的应用程序总下载量约为 3.18 亿次。Kempf 称，「大家仍然在大量下载 VLC。」</span></p><p><span style="color:#000000">谈到项目的未来规划时，Videolan 团队并不满足于成为桌面设备上最受欢迎的多媒体播放器，并已经把目光投向了下一代平台。Kempf 表示，除了继续开发 VLC 4.0，Videolan 团队还在将 VLC 移植到苹果的 Vision Pro 头戴式耳机，未来甚至可能提供对 FAST 频道和其他广告支持的在线媒体的访问。</span></p><p><span style="color:#000000">他们已经在 Vision Pro 上运行了一个版本的 VLC。不过，该应用程序尚未发布。Kempf 称，部分原因是潜在用户群仍然很小。「我还不确定是否有任何用例」。Kempf 表示，他也愿意为 Meta 的 Quest 耳机开发一个版本，虽然该平台上已经有「许多优秀的播放器」可用。</span></p><p><span style="color:#000000">Kempf 还解释道，VLC 4.0 版本原本应在前段时间发布，但由于其复杂程度高于预期所以导致了推迟。「我们一直在重写 VLC 的整个核心」。此外，Videolan 团队还在开发 VLC 的 WebAssembly 版本。</span></p><p><span style="color:#000000">Videolan 4 的 Nightly 版本提供了一个更加以内容为中心的界面，它将默认播放器窗口替换成了 someone’s library。不过，Kempf 提醒道，其中一些改动很可能会在应用程序正式发布前被还原。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 08:40:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283057/vlc-five-billion-downloads</guid>
            <link>https://www.oschina.net/news/283057/vlc-five-billion-downloads</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[System76 计划 5 月底发布 COSMIC Desktop Alpha]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>System76 原计划在第一季度末发布 Rust 编写的 COSMIC 桌面环境的第一个 alpha 版本，但现在他们将时间推迟到了 5 月下旬，以便有时间完成新桌面应用程序的功能开发工作。</p><p>最初，System76 打算将其首个 COSMIC alpha 版本与 Pop!_OS 22.04 上的 GNOME 应用程序一起发布，但随着 COSMIC <span style="color:#121212">应用程序取得良好进展</span>，他们打算将 alpha 版本的发布时间推迟两个月，以便使其应用程序处于更好的状态。</p><p>System76 在终端编辑器、文本编辑器、文件管理器和应用程序商店方面都取得了不错的进展。虽然首个 alphas 版本已经推迟发布，但 System76 的目标仍然是在今年发布 COSMIC 桌面稳定版，同时发布的还有基于 Ubuntu 24.04 LTS 的 Pop!_OS 24.04。</p><p>COSMIC 开发人员最近完成了混合图形支持、窗口最小化和还原、新壁纸、平铺小程序和输入设备设置等方面的工作。COSMIC 今后的工作主要集中在应用程序、图标和其他用户界面方面。</p><p><img alt="" height="282" src="https://oscimg.oschina.net/oscnet/up-ac24e7f96ded9d378f335ac724fc52b08b7.webp" width="500" referrerpolicy="no-referrer"></p><p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.system76.com%2Fpost%2Fcosmic-more-alpha-more-fun" target="_blank">查看官方博客</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 07:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283047/system76-cosmic-alpha-may</guid>
            <link>https://www.oschina.net/news/283047/system76-cosmic-alpha-may</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linus Torvalds 不满 Linux 6.9 中的一些 Bcachefs 代码]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Bcachefs 文件系统自从被纳入 Linux 6.7 内核的上游版本以来，一直保持着良好的运行状态。但现如今，随着 Bcachefs 的功能更新被提交到 Linux 6.9 合并窗口，引发了 Linus Torvalds 对其中一些 proposed code 的不满。</span></p><p><span style="color:#000000">维护者 Kent Overstreet 将针对 Linux 6.9 的 Bcachefs 改动的拉取请求<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2Flfypw4vqq3rkohlh2iwhub3igjopdy26lfforfcjws2dfizk7d%4032yk5dnemi4u%2F" target="_blank">总结为</a>：</span></p><ul><li><span style="color:#000000">Subvolume children btree；是为 walking subvolumes 提供用户空间界面所必需的，计划在稍后提供</span></li><li><span style="color:#000000">对目录结构检查进行了大量改进</span></li><li><span style="color:#000000">改进了日志管道，显着提高了 high iodepth write workloads 的性能</span></li><li><span style="color:#000000">Discard path 改进：Discard path 更加高效，并且不再不必要地刷新日志</span></li><li><span style="color:#000000">Buffered write path 现在可以避免占用 inode lock</span></li><li><span style="color:#000000">调出用于 XFS 的各种库代码：time stats、mean_and_variance、darray、eytzinger、thread_with_file</span></li><li><span style="color:#000000">新的 mm helper：memalloc_flags_{save|restore}</span></li><li><span style="color:#000000">mempool now does kvmalloc mempools</span></li></ul><p><span style="color:#000000">但让 Linus Torvalds 感到不解的是，这些补丁把 Bcachefs 代码中的一些元素移到了一些 library-type 的代码中，以至于可以轻松地被其他文件系统重用。</span></p><p><span style="color:#000000">Linus Torvalds 在</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3Dwg3djFJMeN3L_zx3P-6eN978Y1JTssxy81RhAbxB%3D%3DL8Q%40mail.gmail.com%2F" target="_blank">回应</a><span style="color:#000000">相关 PR 时表示：「我看了看'make random bcachefs code be a library function'的内容，觉得毫无意义，最终决定在没有进一步解释的情况下我不会使用它（老实说，我不认为这些解释站得住脚）。」</span></p><p><span style="color:#000000">并直言 "stdio_redirect_printf() "和 darray_char 都很「恶心」。建议 Overstreet 将其保留在自己的代码中就好，不要试图提交上来。如果实在不死心的话，建议他先做好以下几点：</span></p><ul><li><span style="color:#000000">多加解释</span></li><li><span style="color:#000000">有更合理的命名，减少恶心和完全无意义的 interfaces ("DARRAY()")。</span></li></ul><p><img height="318" src="https://oscimg.oschina.net/oscnet/up-87349de7cf38ec24e77d98c8c7165c68d31.png" width="500" referrerpolicy="no-referrer"></p><blockquote><p><span style="color:#000000">而且，仅仅找到一个其他文件系统来共享这种代码并不足以证明它是一个合理的 interfaces 和合理的命名。</span></p><p><span style="color:#000000">但是，最主要的问题是疯狂的数学计算。该死的，我们很久以前就讨论过"mean and variance"这种愚蠢的垃圾。当时就错了，现在还是错的。你没有解释为什么它不能使用简单得多的 MAD（<em>median absolute deviation</em>），而不是使用 variance。这个错误的决定直接导致无意义地使用过于复杂的 128 位数学。</span></p><p><span style="color:#000000">我当时称其为疯狂的过度工程化，而就我所知，除了一些轻微的类型名称细节外，绝对没有任何变化。</span></p><p><span style="color:#000000">只要你把它改成某种只适用于 bcachefs 的东西，我就不介意。但现在，你却试图把这些垃圾作为通用库代码推向市场，让其他人也能使用，这就意味着，我会介意这种过度设计的 interfaces。</span></p><p><span style="color:#000000">在其他方面，time_stats 看上去就像是一个有名称和用途的正常 interfaces，但使用了这种可怕的基础架构后，它就变得不伦不类了。</span></p></blockquote><p><span style="color:#000000">在 Overstreet 争辩之后，Linus 进一步</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3DwhbgtooUErM9bOP2iWimndpkPLaPy1YZmbmHACU07h3Mw%40mail.gmail.com%2F" target="_blank">补充道</a><span style="color:#000000">：</span></p><blockquote><p><span style="color:#000000">加权版本的代码字面上没有任何变化。</span></p><p><span style="color:#000000">variance value 是不同的，但 MAD 和 standard deviation&nbsp;之间的区别基本上只是一个 constant factor（不同的分布会有所不同，但那又怎样？任何特定情况都会有特定的分布）。那么，为什么 constant factor&nbsp;会对指数加权产生任何影响呢？</span></p><p><span style="color:#000000">不管怎样，请随意将您的代码保存在 bcachefs 中。也许 xfs 甚至想复制该代码。我不在乎，这看起来很愚蠢，但这是文件系统的选择。但如果我们要把它打造成一个通用的内核库，它就必须是健全的。不要让人们仅仅为了随机统计元素而进行 64 位平方根和 128 位除法。</span></p></blockquote><p><span style="color:#000000">因此，就目前情况而言，Linus Torvalds 并没有接受这个针对 Linux 6.9 内核的 Bcachefs 拉取请求。至于后续如何，就要看新的 PR 会不会放弃这些补丁或以其他方式重新修改以满足&nbsp;Linus 的要求。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 07:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283043/linux-6-9-bcachefs-attempt</guid>
            <link>https://www.oschina.net/news/283043/linux-6-9-bcachefs-attempt</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[不卡科技系列全新 Logo 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img height="1395" src="https://oscimg.oschina.net/oscnet/up-d91ca53fe6e4275e089c404f966b1009a32.jpg" width="1073" referrerpolicy="no-referrer"></p><p>新 Logo 由前 vivo 官网设计师操刀，更加高端大气上档次，有圆角也有棱角，预示着产品有态度也有温度。</p><p><img height="1298" src="https://oscimg.oschina.net/oscnet/up-0d5d0bafee553d66a62a40447c60c3e6116.png" width="2534" referrerpolicy="no-referrer"></p><p>也和官网整体风格匹配，更加成熟，商务和技术风格相融合，也是产品的基本调性。打造酷炫且实用的产品体验。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283025</guid>
            <link>https://www.oschina.net/news/283025</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | 全球首位 AI 软件工程师 Devin；谷歌承认「窃取」OpenAI 模型关键信息]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.13</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><strong><a href="https://www.oschina.net/news/282901/laravel-11-released" target="_blank">Laravel 11 正式发布</a></strong></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Laravel 11 和 Laravel Reverb 现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel-news.com%2Flaravel-11" target="_blank">发布</a>。Reverb 是 Laravel 生态系统的最新成员，是第一方、可扩展的 WebSocket 服务器，旨在为用户的应用程序提供强大的实时功能。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Laravel 11 引入了：极简应用结构、默认使用 SQLite、实现 health routing、提供每秒速率限制、支持优雅的加密密钥轮换、改进队列测试、引入新的 Artisan 命令、添加 Resend 邮件传输、集成 Prompt validator、新的 Artisan commands、Model Casts 改进、The once function、改进了使用内存数据库进行测试时的性能、改进了对 MariaDB 的支持等等。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="352" src="https://oscimg.oschina.net/oscnet/up-0453b972568e047b7d57af4dd0cf5cf3c7d.png" width="500" referrerpolicy="no-referrer"></p><h3><strong><a href="https://www.oschina.net/news/282895/cognition-labs-devin" target="_blank">全球首位 AI 软件工程师 Devin：能自学新语言、开发迭代 App、自动 Debug</a></strong></h3><p>初创公司 Cognition 近日发布公告，宣布推出全球首个 AI 软件工程师 Devin，并号称会彻底改变人类构建，软件的方式。官方描述如下：Devin 是一位不知疲倦、技术娴熟的队友，随时准备与您并肩作战，或独立完成，任务供您审查。有了 Devin，工程师可以专注于更有趣的问题，工程团队可以努力实现更远大的目标。Devin 在 SWE-bench 编码基准测试中取得了突破性的成功，展示了执行复杂任务的能力，甚至超越了顶尖的人类工师。</p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-9eca7b14f877d8f53cdbf3e675e1942c4a7.png" width="500" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img height="160" src="https://oscimg.oschina.net/oscnet/up-4101ac3e993fdd0d11ceb478c4000751d2b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微信&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU4ODQwNTIxMw%3D%3D%26mid%3D2247526466%26idx%3D1%26sn%3D50c1810505d13cd76439d7099e062905%26scene%3D0" target="_blank">人工智能产业链 union</a></em></u></p><p><img height="123" src="https://oscimg.oschina.net/oscnet/up-26d3c03709ed15944aee6780c7a432211d8.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.cn%2Farticle_5182171545_134e1a99902001pzg3.html" target="_blank">界面新闻</a></em></u></p><p><img height="218" src="https://oscimg.oschina.net/oscnet/up-413b05deedd40f689af0d5326b693b401dc.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2Fusstock%2Fmggd%2F2024-03-13%2Fdetail-inanefqq3854800.d.html" target="_blank">环球市场播报</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img height="401" src="https://oscimg.oschina.net/oscnet/up-1b97b2ca5e5274365ef49658a177ccdc3d9.png" width="500" referrerpolicy="no-referrer"></p><p><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftremorlabs%2Ftremor" target="_blank">https://github.com/tremorlabs/tremor</a></em></u></p><hr><h2><span style="color:#16a085"><strong>事件点评</strong></span></h2><p><img height="527" src="https://oscimg.oschina.net/oscnet/up-8c63b78a5992700821d2183b90b07e6027b.png" width="500" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong><span style="background-color:#e67e22">每日 GitHub 精选</span></strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="659" src="https://oscimg.oschina.net/oscnet/up-07e7c0e0484d7ed9ad4c32f79130e119b77.png" width="500" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/q35lx4s6qq9ls4r/28_cognition_labs_devin_Epbxne3xzN.pdf" target="_blank">开源日报第 028 期：全球首位 AI 软件工程师 Devin；谷歌承认「窃取」OpenAI 模型关键信息</a></u></em></h4></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>往期回顾</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/hh291xp9mxksc9i/27_ai_google_50_gpt_4_KfagjDXXfZ.pdf" target="_blank">开源日报第 027 期：AI 接连翻车的 Google 要变天了；互联网大厂 50 款大模型及应用，能否全面超越 GPT-4？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/uwsizmmsnhq8zdk/26_git_hub_22_web_os_22_vue_rolldown_FpVykoR7rJ.pdf" target="_blank">开源日报第 026 期：大模型替代程序员根本就是一个伪命题；GitHub 顶流 "Web OS"</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6ho57sxydzsh9jh/25_ai_5_ax1LWz5GP5.pdf" target="_blank">开源日报第 025 期：买手机送大模型；「钓鱼式维权」 须遏制；「AI 原生」 骗局江湖</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7xd6teyhekcvamw/24_risc_v_x86_arm_5LsjoStPUn.pdf" target="_blank">开源日报第 024 期：RISC-V 能否和 x86、Arm 一起成为三大主流架构；给阎王开发地府管理系统</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">开源日报第 023 期：Google = 开源，好评；Microsoft = 闭源收入还低，差评</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">开源日报第 022 期：轻松复现 Sora 模型；事关 CUDA 兼容，英伟达禁止了；百度还差一个 「遥遥领先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">开源日报第 021 期：闭源模型就是比开源安全；起诉 OpenAI 不能更赞同</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">开源日报第 020 期：为什么王炸都来自 OpenAI；Pingora 最好不要用 YAML 当配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">开源日报第 019 期：我让 AI 用 C 语言写一个算法；微软三进制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">开源日报第 018 期：苹果十年造车梦碎；这个开源项目有点...「大胆」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">开源日报第 017 期：MariaDB 消亡史；写代码我有三不沾；V 神建议马斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有 「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 06:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283024</guid>
            <link>https://www.oschina.net/news/283024</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[首款基于 RISC-V 的安卓设备将于 2024 年大规模商业化落地]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在阿里巴巴平头哥玄铁 RISC-V 生态大会上，阿里巴巴达摩院院长张建锋在演讲中指出，RISC-V 开源指令集架构发展迅速，在主流市场年平均增长率超过 40%，在主流应用占比超过 30%，用 10 年时间完成了 Arm 30 年的历史。 </span></p><p><span style="color:#000000">会上，达摩院还宣布了多款玄铁处理器的升级：玄铁 C907 首次实现矩阵运算（Matrix）扩展，为未来 AI 加速计算提供更多选择，并将集成到其他玄铁处理器中；下一代旗舰处理器 C930 也将于年内推出。</span></p><p><span style="color:#000000">据悉，首款基于 RISC-V 的安卓设备也将于 2024 年大规模商业化落地。目前，国际及国内主流操作系统已完成与 RISC-V 的全适配，包括安卓、Linux、OpenHarmony、Debian、Fedora、Gentoo、Ubuntu、龙蜥、统信、openKylin、创维酷开系统、RTT 等操作系统。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283009</guid>
            <link>https://www.oschina.net/news/283009</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JetBrains 公布 Ktor 2024 路线图]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">JetBrains <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2024%2F03%2Fthe-ktor-roadmap-for-2024%2F" target="_blank">公布</a>了 Ktor 的 0224 年开发路线图。Ktor 是一个基于 Kotlin 的异步框架，用于创建微服务、Web 应用等。</span></p><p><span style="color:#000000">该公司在路线图中表示，他们对 Ktor 的持续计划和目标与前几年保持一致。旨在努力保持框架的轻量级、灵活和透明，以便用户可以轻松创建强大且可维护的服务和客户端。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-085d99ec88e786fe7765205a2d60852b18c.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">项目团队将致力于在每个新版本中提高所提供功能的质量和性能，同时扩展 Ktor 插件生态系统。此举将涉及引入新插件来简化现有用例（例如事务处理）并添加对新用例（例如 Observability 和 gRPC）的支持。</span></p><p><span style="color:#000000">在改进核心产品的同时，还将为用户提供更轻松的开发体验。使插件生态系统更易于使用，并消除社区贡献的障碍。以及致力于提高所提供文档的范围、质量和多样性。并利用 Kotlin Multiplatform (KMP) 的稳定性和不断发展的多平台库生态系统，让 Ktor 开发人员能够享受到 KMP 的优势，创建多平台应用程序。</span></p><p><span style="color:#000000">计划在 2024 年提供以下<strong>新功能</strong>：</span></p><ul><li><span style="color:#000000"><strong>OpenTelemetry 插件。</strong>计划为 Ktor 客户端和服务器引入 OpenTelemetry 插件，这将使用户能够生成遥测数据（指标、日志和跟踪）并公布它以供收集。</span></li><li><span style="color:#000000"><strong>基于 gRPC 的服务。</strong>团队正在努力添加 gPRC 支持。计划 2024 年将通过惯用的 Kotlin 实现将 gRPC 集成到 Ktor 客户端和服务器中。JetBrains 表示，这将使创建和使用基于 gRPC 的服务像 HTTP 和 REST 一样自然和熟悉。</span></li><li><span style="color:#000000"><strong>在 Ktor 3.0.0 中迁移到 Kotlinx-io。</strong>用 Kotlinx-io 提供的网络类型替换现有的定制网络类型，以使得多平台库的创建者更容易支持 Ktor 客户端和服务器。通过此更新，现有 IO 功能将在 Ktor 3.0.0 中弃用，并将在 Ktor 4.0.0 中删除。</span></li><li><span style="color:#000000"><strong>添加对托管事务的支持。</strong>目前 Ktor 服务需要手动管理数据库事务，适合复杂的场景。但是，在许多情况下，最好在请求开始时启动事务并在请求结束时提交事务，前提是没有错误。JetBrains 计划在 2024 年推出一个实现此行为的官方插件，简化数据库访问，同时提供从 SQL 和特定于应用程序的异常中恢复的支持。</span></li><li><span style="color:#000000"><strong>简化的依赖注入。</strong>将于 2024 年正式在 Ktor Server 中添加对 DI 的支持，并发布有关如何最好地集成现有 DI 库的指南。</span></li></ul><p><span style="color:#000000">除了向 Ktor 添加新功能外，JetBrains 还将进行一些更改。包括对文档进行改进，2024 年的重点是提高当前内容质量并扩大对新材料的支持，计划通过多次迭代来支持：</span></p><ul><li><span style="color:#000000">扩展、改进和简化 Ktor 服务器和 Ktor 客户端文档的入门部分中的教程。</span></li><li><span style="color:#000000">解决云部署和配置主题。</span></li><li><span style="color:#000000">介绍使用 Kotlin Multiplatform 进行全栈开发的综合指南。</span></li><li><span style="color:#000000">扩大文档中 API 的覆盖范围。</span></li></ul><p><span style="color:#000000">以及计划进行结构性变革。教程将无缝地相互补充，更有效地链接主题，并且服务器和客户端内容将被重新组织以确保更清晰的区别。所有这些新增内容都将利用现代化的外观和感觉，并与其他 JetBrains 框架和库的文档集成。</span></p><p><span style="color:#000000">JetBrains 还计划引入一种接受第三方 Ktor 插件的机制。包括用于创建 Ktor 插件的新的简化格式、项目生成器的新版本以及向 Ktor 团队提交拉取请求的过程。</span></p><p><span style="color:#000000">此外，JetBrains 将在 2024 年发布 Ktor CLI 工具。满足对 JetBrains Intellij IDEA Ultimate IDE 中在线项目生成器或向导的基于命令行替代方案的需求。这一举措将允许用户在终端或 shell 中创建和修改项目。</span></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2024%2F03%2Fthe-ktor-roadmap-for-2024%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283003/ktor-roadmap-for-2024</guid>
            <link>https://www.oschina.net/news/283003/ktor-roadmap-for-2024</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[DeviceScript —— 用于微型物联网设备的 TypeScript]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>DeviceScript 为基于低资源微控制器的设备带来了专业的 TypeScript 开发人员体验。DeviceScript 被编译为自定义 VM 字节码，可以在非常受限的环境中运行。</p><p><img alt="" height="313" src="https://static.oschina.net/uploads/space/2023/0530/145731_bXBv_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><strong>特性：</strong></p><ul><li><strong><a href="https://microsoft.github.io/devicescript/language">TypeScript for IoT</a></strong></li></ul><p>熟悉的语法和工具，尽在你的指尖。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/devices">Small Runtime</a></strong></li></ul><p>低功耗/闪存/内存的字节码解释器。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/developer/clients">Hardware as Services</a></strong></li></ul><p>传感器和执行器的客户端/服务器架构。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/getting-started/vscode/debugging">Debugging</a></strong></li></ul><p>在 Visual Studio Code 中，用于嵌入式硬件或模拟设备。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/developer/simulation">Simulation and Testing</a></strong></li></ul><p>使用硬件/模拟传感器开发和测试你的固件。CI 友好。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/developer/cloud/gateway">Development Gateway</a></strong></li></ul><p>具有设备管理、固件部署和消息队列的 Prototype cloud service。</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/devicescript</guid>
            <link>https://www.oschina.net/p/devicescript</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 异构数据源同步服务 DatalinkX]]>
            </title>
            <description>
                <![CDATA[<p><img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/project_name.png" alt="输入图片说明" referrerpolicy="no-referrer"></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FSplitfireUptown%2Fdatalinkx"><img src="https://img.shields.io/github/stars/SplitfireUptown/datalinkx.svg?style=flat&amp;label=GithubStars" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx"><img src="https://gitee.com/atuptown/datalinkx/badge/star.svg?theme=dark" alt="Gitee Starts" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx"><img src="https://gitee.com/atuptown/datalinkx/badge/fork.svg?theme=dark" alt="Gitee Starts" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#"><img src="https://img.shields.io/badge/Author-%E5%9C%A8%E4%B8%8Buptown-orange.svg" alt="作者" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/JDK-21-red.svg" alt="jdk 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/SpringBoot-3.2.1-green.svg" alt="SpringBoot 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/MySQL-8.0-orange.svg" alt="MySQL 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/Redis-5.0-green.svg" alt="Redis 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Redis%20Stream-red.svg" alt="Redis 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/ORM-SpringData%20JPA-blue.svg" alt="ORM 框架" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1-xxljob-green.svg" alt="分布式定时任务" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-Flink-red.svg" alt="计算引擎" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2-Docker%20&amp;%20DockerCompose-yellow.svg" alt="部署" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%89%8D%E7%AB%AF-Vue2.x-green.svg" alt="部署" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%89%8D%E7%AB%AFUI-AntDesignUI-red.svg" alt="前端" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/RPC-Retrofit2-blue.svg" alt="RPC 框架" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%90%8C%E6%AD%A5%E6%A1%86%E6%9E%B6-Chunjun(FlinkX)-green.svg" alt="同步框架" referrerpolicy="no-referrer"></a></p><h2><a id="user-content-异构数据源同步服务 datalinkx 介绍" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%BC%82%E6%9E%84%E6%95%B0%E6%8D%AE%E6%BA%90%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1datalinkx%E4%BB%8B%E7%BB%8D"></a>异构数据源同步服务 DatalinkX 介绍</h2><p><strong>核心功能</strong> ：在不同的异构数据源中进行数据同步，对同步任务进行管理和维护</p><p><strong>意义</strong>：只要公司规模较大，部门与部门之间有数据协作都应该有类似 DatalinkX 的项目，比如爬虫组的同事爬下来数据要定时同步到数仓组负责的库下。同步服务会集中管理同步任务，收拢同步日志、提高内部工作效率。</p><p><img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/image.png" alt="输入图片说明" referrerpolicy="no-referrer"></p><h2><a id="user-content-项目特性" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E7%89%B9%E6%80%A7"></a>项目特性</h2><ul><li><strong>简单易用</strong>：通过 Web 页面快速创建数据源、同步任务，操作简单，一分钟上手</li><li><strong>定时触发</strong>：对接 xxl-job 定时，设置 cron 表达式触发同步任务</li><li><strong>配置化任务对接</strong>：将数据库信息、任务详情界面化配置</li><li><strong>高性能同步</strong>：使用高性能流式 flink 计算引擎</li><li><strong>容器化部署</strong>：支持 docker 部署</li></ul><h2><a id="user-content-项目技术栈" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%8A%80%E6%9C%AF%E6%A0%88"></a>项目技术栈</h2><table><thead><tr><th>依赖</th><th>版本</th><th>描述</th></tr></thead><tbody><tr><td>Spring Boot</td><td>3.2.1</td><td>项目脚手架</td></tr><tr><td>SpringData JPA</td><td>3.2.1</td><td>持久层框架</td></tr><tr><td>MySQL</td><td>8.0</td><td>DB 数据库</td></tr><tr><td>ElasticSearch</td><td>7.x</td><td>支持流转的数据库</td></tr><tr><td>Redis</td><td>5.0 ↑</td><td>缓存数据库</td></tr><tr><td>ChunJun(原 FlinkX)</td><td>1.10_release</td><td>袋鼠云开源数据同步框架</td></tr><tr><td>Flink</td><td>1.10.3</td><td>分布式大数据计算引擎</td></tr><tr><td>Xxl-job</td><td>2.3.0</td><td>分布式调度框架</td></tr><tr><td>Retrofit2</td><td>2.9.0</td><td>RPC 通信服务</td></tr><tr><td>Jackson</td><td>2.11.4</td><td>反序列化框架</td></tr><tr><td>Maven</td><td>3.6.X</td><td>Java 包管理</td></tr><tr><td>Vue.js</td><td>2.X</td><td>前端框架</td></tr><tr><td>AntDesignUI</td><td>3.0.4</td><td>前端 UI</td></tr><tr><td>Docker</td><td></td><td>容器化部署</td></tr></tbody></table><h2><a id="user-content-启动姿势" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%90%AF%E5%8A%A8%E5%A7%BF%E5%8A%BF"></a>启动姿势</h2><h4><a id="user-content-中间件" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E4%B8%AD%E9%97%B4%E4%BB%B6"></a>中间件</h4><p>执行 <code>docker compose -p datalinkx up -d</code> 命令将各组件启动</p><h5><a id="user-content-手动搭建组件 linux" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E7%BB%84%E4%BB%B6linux"></a>手动搭建组件（linux）：</h5><p>xxl-job: <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fxuxueli%2Fxxl-job%2Farchive%2Frefs%2Ftags%2F2.3.0.zip">https://github.com/xuxueli/xxl-job/archive/refs/tags/2.3.0.zip</a>
纯 Java 项目，可 clone 代码后打包成 jar 包启动，xxl-job 依赖 mysql，需要修改对应数据库地址配置，表结构在/xxl-job-2.3.0/doc/db/tables_xxl_job.sql，导入 mysql 即可。</p><p>flink：<a href="https://gitee.com/link?target=https%3A%2F%2Farchive.apache.org%2Fdist%2Fflink%2Fflink-1.10.3%2F">https://archive.apache.org/dist/flink/flink-1.10.3/</a>
选择 flink-1.10.3-bin-scala_2.12.tgz 下载，解压进入 bin 目录执行./start-cluster.sh，首次运行默认只有一个任务 slot，访问<a href="https://gitee.com/link?target=http%3A%2F%2Flocalhost%3A8081">http://localhost:8081</a> 进去 flink 后台页面。</p><h4><a id="user-content-db 层" class="anchor" href="https://gitee.com/atuptown/datalinkx#db%E5%B1%82"></a>DB 层</h4><p>执行  /datalinkx-server/src/main/resources/db.sql</p><h4><a id="user-content-后端" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%90%8E%E7%AB%AF"></a>后端</h4><ol><li>运行<code>datalinkx-server</code>与<code>datalinkx-job</code>模块
<ol><li><strong>datalinkx-server</strong>与 front 交互，依赖 mysql、redis</li><li><strong>datalinkx-job</strong>负责提交、维护任务的生命周期，依赖 xxl-job、flink
<ol><li>服务启动后会默认使用 netty 启动<code>${xxl.job.executor.port}</code> 负责监听 xxl-job 的任务事件</li><li>任务执行详细信息通过 datalinkx-client 的 rpc 能力访问<code>${client.dataserver}</code></li><li>如果更改了 datalinkx-server 端口需要同步更改 datalinkx-job 配置项<code>${client.dataserver}</code>。</li><li><code>${flinkx.path}</code>配置 flinkx 模块的路径</li></ol></li><li>遇到依赖问题执行 <code>mvn clean -U </code></li></ol></li><li>flinkx 模块为单独的项目
<ol><li>需要手动执行<code>mvn clean install -U -Dmaven.test.skip=true -Dcheckstyle.skip=true</code>将插件打包</li><li>打包后配置好 flinkx/flinkconf 中 flink 的地址<code>jobmanager.rpc.address:</code>和端口<code>rest.port</code>即可</li></ol></li></ol><h4><a id="user-content-前端" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%89%8D%E7%AB%AF"></a>前端</h4><p><code>yarn install &amp;&amp; export NODE_OPTIONS=--openssl-legacy-provider &amp;&amp; yarn run serve</code></p><h2><a id="user-content-使用姿势" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E4%BD%BF%E7%94%A8%E5%A7%BF%E5%8A%BF"></a>使用姿势</h2><ol><li>登录系统，默认密码 admin、admin 登录，没有权限相关控制
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/login.png" alt="img.png" referrerpolicy="no-referrer"></li><li>数据源管理，配置数据流转数据源信息
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/ds_config.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任务管理，配置 from_db 与 to_db 构造 job_graph
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/job_config.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任务级联配置
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/job_cascade.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任务血缘
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/job_relation.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任务调度
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/xxl.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任务执行
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/flink.png" alt="img.png" referrerpolicy="no-referrer"></li></ol><h2><a id="user-content-datalinkx 交流群" class="anchor" href="https://gitee.com/atuptown/datalinkx#datalinkx%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>datalinkx 交流群</h2><p>私聊进群我会拉到项目交流群中
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/author.png" alt="输入图片说明" referrerpolicy="no-referrer"></p><h2><a id="user-content-项目文档" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"></a>项目文档</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fnote.youdao.com%2Fs%2Fa9ltzlc1">细致文档带你吃透 DatalinkX</a></p>]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/atuptown/datalinkx</guid>
            <link>https://gitee.com/atuptown/datalinkx</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 万字带你了解 ChatGLM]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>本文分享自华为云社区《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F420208%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">【云驻共创】华为云之升思 MindSpore 大模型专题（第二期）-第一课：ChatGLM</a>》，作者： 愚公搬代码。</span></p><span id="OSC_h1_1"></span><h1><span><span>前言</span></span></h1><span id="OSC_h2_2"></span><h2><span>1.升思 MindSpore</span></h2><p><span>升思 MindSpore 是华为公司推出的一款全场景 AI 计算框架。它提供了自动微分、分布式训练和推理、模型部署等功能，支持多种硬件平台，包括 CPU、GPU 和 Ascend AI 处理器。MindSpore 采用图和算子相结合的编程模型，能够高效地处理复杂的深度学习任务。它具有灵活的设计、高效的性能和易于使用的接口，使开发者能够更快地开发和部署 AI 应用。MindSpore 还支持自定义操作和算法，可以满足不同场景下的需求。</span></p><span id="OSC_h2_3"></span><h2><span>2.大模型</span></h2><p><span>大模型是指具有数百万到数十亿个参数的深度学习模型。这些模型通常用于处理大规模数据集，并能够在各种任务上取得出色的性能。大模型通常需要大量的计算资源进行训练，并且需要更长的时间来收敛。然而，由于其具有更多的参数，大模型可以更好地捕捉数据中的复杂关系，从而提升模型的预测性能。大模型的应用范围非常广泛，包括自然语言处理、计算机视觉、语音识别等领域。</span></p><span id="OSC_h2_4"></span><h2><span>3.ChatGLM</span></h2><p><span>ChatGLM 是一种生成式语言模型，用于聊天和对话任务。它是基于 OpenAI 的 GPT 模型框架构建的，采用了大规模的预训练数据集来学习语言模式和生成文本的能力。ChatGLM 可以理解上下文并生成连贯、自然的回复。它可以用于构建对话系统、智能客服、聊天机器人等应用，能够提供更加交互性和人性化的对话体验。ChatGLM 模型的训练和优化过程需要大量的计算资源和数据，而且模型的生成性质也需要进行适当的监督和过滤，以确保生成的回复符合预期的行为准则和标准。</span></p><span id="OSC_h1_5"></span><h1><span><span>一、GLM Model Architecture</span></span></h1><span id="OSC_h2_6"></span><h2><span>1.Evolution Tree of LLMs</span></h2><p><span>Evolution Tree of LLMs（Language Model Megasuite 的演化树）是指由 OpenAI 发布的一系列语言模型的历史和演化关系图。</span></p><p><span>OpenAI 的 LLMs 系列是一系列基于深度学习的语言模型，旨在生成人类语言的自然文本。这些模型中的每一个都是通过对大量文本进行训练而得到的，可以用于自动回答问题、生成文章、翻译文本等自然语言处理任务。</span></p><p><span>Evolution Tree of LLMs 图中展示了这些模型的发展历程。从最早的模型开始，每个后续模型都是在前一个模型的基础上进行改进和扩展。这些改进可能涉及模型的规模增加、训练数据的增加、架构的改进等。通过不断地改进和提升模型，OpenAI 致力于推动语言模型的发展，使其在各种自然语言处理任务上表现更加出色。</span></p><p><span>Evolution Tree of LLMs 图不仅展示了各个模型之间的关系，还反映了 OpenAI 在不同时间点的研究重点和技术进展。这个图可以帮助研究人员和开发者了解 LLMs 系列的发展历程，从而更好地理解和应用这些语言模型。</span></p><p><span><img src="https://static001.geekbang.org/infoq/84/84d7f15028efbda63b9a3553a51913e6.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_7"></span><h2><span>2.Autoregressive Blank Infilling</span></h2><span id="OSC_h3_8"></span><h3><span>2.1 Autoregressive、Autoencoding、Encoder-Decoder</span></h3><p><span>「Autoregressive」、"Autoencoding"和"Encoder-Decoder"是三种常见的神经网络模型结构，用于处理序列数据或生成模型。</span></p><p><span>Autoregressive（自回归）模型是一种生成模型，它将序列数据的生成建模为一个逐步预测每个元素的条件概率的过程。在每个时间步，模型根据之前生成的元素预测当前元素的概率分布。常见的 Autoregressive 模型包括语言模型，如 OpenAI GPT 模型，它可以生成与输入序列相似的新文本。</span></p><p><span>Autoencoding（自编码）模型是一类无监督学习方法，用于学习输入数据的紧凑表示。它由一个编码器和一个解码器组成。编码器将输入数据映射到低维表示，解码器将该低维表示恢复到原始数据空间。Autoencoding 模型的目标是尽可能准确地重建输入数据，同时学习到有用的特征表示。常见的 Autoencoding 模型包括 Variational Autoencoder (VAE) 和 Denoising Autoencoder。</span></p><p><span>Encoder-Decoder（编码器-解码器）模型是一种常用的序列到序列（Sequence-to-Sequence）模型，用于处理输入和输出都是序列数据的任务。它由两个部分组成：编码器和解码器。编码器将输入序列映射为固定大小的向量表示，解码器使用该向量表示生成输出序列。Encoder-Decoder 模型可以在不同长度的输入和输出序列之间进行转换，例如机器翻译和文本摘要等任务。</span></p><p><span>GLM（自回归填空）模型是一种灵活且多样化的语言模型，可以根据给定的上下文生成缺失的部分内容。根据已知的部分文本内容生成可能的填空内容。它可以用于自动文本补全、问答系统、语义理解和生成等多个自然语言处理任务中。</span></p><p><span><img src="https://static001.geekbang.org/infoq/d0/d0d722561e2136aecdbee22b8cc9e4f2.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/b6/b69d1b89caf74a34b44f39dda2ecc13c.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_9"></span><h3><span>2.1 OpenAI GPT 系列模型</span></h3><p><span>自然语言处理领域的 GPT（Generative Pre-trained Transformer）系列模型是由 OpenAI 开发的一系列强大的自然语言处理模型。下面是 GPT 系列模型的发展历程：</span></p><p><span>GPT-1: GPT 模型是于 2018 年发布的第一代模型。它使用了 Transformer 架构，预训练了一个大规模的语言模型，并使用无标签的文本数据进行模型训练。这个模型的特点是生成连贯的文本，能够完成一些基础的自然语言处理任务，如语言模型、文本分类和文本生成等。</span></p><p><span>GPT-2: 在 2019 年，OpenAI 发布了 GPT-2 模型作为 GPT 的后续版本。GPT-2 模型采用了更大的预训练模型，使用无标签的互联网文本进行训练。这个模型在生成文本方面取得了突破性的进展，可以生成高质量、连贯的文本，使得生成的文本内容更具有逼真性。由于考虑到模型被滥用可能带来的风险，OpenAI 最初限制了 GPT-2 的访问，并未发布完整的模型。</span></p><p><span>GPT-3: GPT-3 是在 2020 年发布的 GPT 系列的第三代模型。参数量达到了 1750 亿个，训练了十几万小时。GPT-3 在文本生成、文本补全、问答系统等任务上表现出色，其生成的文本能够接近人类水平的表达能力。GPT-3 还可以通过提供一些文本提示来理解并回答问题，具有较强的语言理解和推理能力。</span></p><p><span>GPT-4：在 2023 年，OpenAI 发布了 GPT-4，这是 GPT 系列的第四个模型。GPT-4 比 GPT-3 系列大得多，具有 1.8 万亿个参数，而 GPT-3 只有 1750 亿个参数。GPT4 是一种多模态模型，而 GPT3 系列是一种自然语言处理模型。自然语言模型只能听或看懂语言，而多模态模型可以处理多种媒体数据，并且将他们整合到统一的语义空间之中。GPT4 可接收的文字输入长度达到了惊人的 32000 字，而 GPT3 系列，只能输入 3000 字。</span></p><p><span><img src="https://static001.geekbang.org/infoq/22/22cd98f7991e34b325e96903d431ee3d.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_10"></span><h3><span>2.3 Autoregressive Blank Infilling</span></h3><p><span>Autoregressive Blank Infilling（ABI）是一种用于填充时间序列数据中缺失值的方法。在时间序列数据中，由于种种原因，可能会存在一些缺失值，这些缺失值会影响数据的完整性和准确性。ABI 方法通过基于自回归模型，利用其他已有的数据来预测并填补缺失值。</span></p><p><span>ABI 方法的基本思想是根据时间序列数据的自相关性，使用已有的数据点来逐个预测缺失值。具体来说，ABI 方法使用 AR 模型（自回归模型）来建模时间序列数据中的缺失值和非缺失值之间的关系。然后，根据该模型，利用其他已有的数据点来预测缺失值的数值。</span></p><p><span>ABI 方法在填充缺失值时，通常还会考虑一些其他因素，如数据的趋势、季节性和周期性等。通过综合考虑这些因素，ABI 方法能够更准确地填充缺失值，从而提高数据的完整性和可靠性。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>顺序分为 A 部分和 B 部分：</span></p><ul><li><p><span>A 部分：带掩码跨度的序列</span></p></li><li><p><span>B 部分：在 A 部分中被掩盖的原始跨度</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/9c/9cd53a85acf9c50e4dbcb787418f89ca.png" referrerpolicy="no-referrer"></span></p><p><span>如果多个跨度被遮罩，它们将在 B 部分中被打乱</span></p><p><span><img src="https://static001.geekbang.org/infoq/ec/ec1a49a4c5ef4e94bfeb66406fd923af.png" referrerpolicy="no-referrer"></span></p><p><span>B 部分中的每个跨度都以[S]作为输入，以[E]作为输出。</span></p><p><span>该模型自回归生成 B 部分——它基于前一部分预测下一个令牌。</span></p><p><span><img src="https://static001.geekbang.org/infoq/e4/e4dce02ba15e65d99610952f3fea5f95.png" referrerpolicy="no-referrer"></span></p><p><span>A 部分可以自行处理，但不能处理 B 部分</span></p><p><span><img src="https://static001.geekbang.org/infoq/85/85f78a3971bae19c0a1af660f7d7a638.png" referrerpolicy="no-referrer"></span></p><p><span>B 部分可以关注 A 及其在 B 中的经历</span></p><p><span><img src="https://static001.geekbang.org/infoq/22/223329a780e3153f4dbf92f8ddc72574.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_11"></span><h3><span>2.4 Multi-Task Pretraining</span></h3><p><span>Multi-Task Pretraining 是一种多任务预训练的方法。在传统的预训练方法中，语言模型通过在大规模文本数据上进行训练来学习语言的通用模式和表示。然而，在 Multi-Task Pretraining 中，模型同时在多个任务上进行训练，这些任务需要不同类型的语言理解能力。</span></p><p><span>Multi-Task Pretraining 的思想是通过在多个任务上训练语言模型，可以学习到更加通用和鲁棒的语言表示。这是因为不同的任务需要不同的语言技能，如句法分析、语义理解或文档级连贯性。通过让模型接触多样化的任务，它可以学习捕捉不同任务之间的共同语言模式，并利用这些模式更好地泛化到新任务上。</span></p><p><span>Multi-Task Pretraining 已被证明可以提高语言模型在下游任务上的性能。例如，预训练在多个任务上的模型在各种自然语言处理基准测试中取得了最先进的结果，如问答、文本分类和命名实体识别。</span></p><p><span>其中一种常见的 Multi-Task Pretraining 方法是基于 Transformer 的模型，如 BERT（双向编码器表示来自 Transformer 的方法）和 RoBERTa（经过优化的鲁棒 BERT 方法）。这些模型在掩码语言建模、下一个句子预测和其他辅助任务上进行预训练。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>通过改变遮盖内容的长度和数量，从而使模型能够基于 natural language understanding, conditional generation, unconditional generation 三类任务进行预训练，实现「三合一」</span></p><p><span>改变缺失跨度的数量和长度：</span></p><p><span><img src="https://static001.geekbang.org/infoq/1c/1cb25c4d2b09190bff8a46554eb25a72.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_12"></span><h3><span>2.5 Finetuning</span></h3><p><span>Finetuning 是指在预训练的基础上，将模型进一步调整和优化以适应特定任务或特定数据集的过程。在机器学习中，预训练模型通常在大规模的数据上进行训练，学习到通用的模式和特征表示。然而，这些预训练模型可能不直接适用于特定的任务或数据集。</span></p><p><span>通过 Finetuning，可以利用预训练模型的通用知识和特征表示来快速适应特定的任务或数据集。这通常涉及解冻预训练模型的一部分或全部层，并在目标任务上进行进一步的训练。通过在目标任务上微调模型参数，可以使其更好地适应任务的特定要求和数据特征。</span></p><p><span>Finetuning 的过程通常包括以下步骤：</span></p><ol><li>选择预训练模型：选择与目标任务相匹配的预训练模型，如 BERT 或 GPT 等。</li><li>初始化参数：将预训练模型加载到模型中，并冻结所有或部分层的参数。</li><li>构建任务特定层：根据目标任务的需求，构建一个或多个任务特定的层。</li><li>训练：使用目标任务的数据集，通过反向传播和梯度下降等优化算法，更新模型的参数。</li><li>调整超参数：对模型进行验证和评估，并根据结果调整超参数，如学习率、批大小等。</li><li>重复迭代：根据需要，多次迭代训练和调整模型，直到达到满意的性能。</li></ol><p><span>Finetuning 可以大大减少在特定任务上的训练时间和样本需求，同时利用预训练模型的知识提供了更好的初始参数和特征表示。它已经被广泛应用于自然语言处理、计算机视觉和其他领域中的许多任务，如文本分类、问答、命名实体识别等。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>GLM 将 NLG 和 NLU 类下游任务统一为完型填空的生成式任务，如对于分类任务，将输入 x 写成一个填空问题 c(x)，后将生成的答案 v(y) 映射至标签 y</span></p><p><span><img src="https://static001.geekbang.org/infoq/9c/9cf3b6f327ad83502cfc914715d24411.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_13"></span><h3><span>2.6 LLM Reversal Curse</span></h3><p><span>LLM（Large Language Model）是指一种非常大的语言模型，它由数十亿个参数组成，具有强大的语言理解和生成能力。大模型 LLM 可以实现诸如问答、摘要、对话生成等任务，被广泛应用于自然语言处理领域。</span></p><p><span>LLM Reversal Curse（逆转诅咒）是指在使用大模型 LLM 进行任务生成时，其生成结果出现明显的逆转或反转现象。具体而言，当模型用于生成某个任务的结果时，相比原始输入，生成的结果可能会出现与原始意图相反的内容或表达。</span></p><p><span>例如，在问答任务中，当用户提出一个问题时，大模型 LLM 应该生成一个准确且与问题相符的答案。然而，由于模型的复杂性和训练数据的特点，有时候模型会出现生成与问题相反甚至荒谬的答案的情况。</span></p><p><span>这种逆转诅咒可能是由于模型在训练过程中接触到了大量的噪声数据、错误标注的数据或具有偏见的数据，导致模型在生成过程中出现了一些意料之外的结果。</span></p><p><span>为了解决大模型 LLM 的逆转诅咒问题，需要进一步优化模型的训练数据、标注过程和生成算法，以提高模型的生成质量和准确性。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span><img src="https://static001.geekbang.org/infoq/47/470e1c92bd0f829635ac34d21389bfe2.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_14"></span><h2><span>3. 2D Positional Encoding</span></h2><p><span>2D positional encoding 是一种将 2D 网格或图像中元素的位置信息进行编码的技术。位置编码通常在自然语言处理任务中使用，例如机器翻译或语言建模，来表示句子中单词的顺序或位置。然而，它也可以应用于 2D 网格或图像。</span></p><p><span>对于 2D 网格或图像，位置编码可以用于编码每个元素的空间位置。这样，模型可以有一种对元素之间的相对位置的感知，并捕捉它们之间的空间关系。</span></p><p><span>一个常见的 2D 位置编码的方法是使用不同频率的正弦和余弦函数。其思想是创建一个根据网格或图像内位置而变化的正弦信号。然后将这个位置编码作为每个元素在网格或图像中的额外输入或特征。</span></p><p><span>位置编码可以使用以下公式定义：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>PE(x,2i) = sin(x / (10000^(2i / d_model))) PE(x,2i+1) = cos(x / (10000^(2i / d_model))) </span></span></span></span></span></span></pre><p><span>其中，PE(x, i) 表示位置 i 处元素 x 的位置编码，d_model 是模型的维度。</span></p><p><span>通过使用正弦和余弦函数的不同频率，位置编码可以捕捉位置信息中的不同模式或关系。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>模型输入的 position ids 分为两种，从而使得模型可以学习到片段生成的长度</span></p><p><span>Position 1： Part A 中 token 的绝对位置</span></p><ul><li><p><span>Part A：从 1 开始排列</span></p></li><li><p><span>Part B：每一个 span 对应 Part A 中[MASK]的位置</span></p></li></ul><p><span>Position 2：intra-span position，masked span 内部的相对位置</span></p><ul><li>Part A：0</li><li>Part B：每个 span 的 token 从 1 开始排列</li></ul><p><span><img src="https://static001.geekbang.org/infoq/30/30383d2e7f2fa1315a66adc3ee5da034.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/c7/c793beb9a4581f4044b058e18a2af481.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_15"></span><h3><span>3.1 大模型训练最大挑战:训练稳定性</span></h3><ul><li><p><span>权衡利弊：训练稳定性（高精度低效）还是训练效率（低精度高效）</span></p></li><li><p><span>目前已开源训练过程大模型的解决方案</span></p><ul><li>FB OPT-175B：训练崩溃时反复调整学习率/跳过数据（权宜之计，损失性能）</li><li>HF BLOOM 176B：embedding norm 和 BF16（损失性能，有限适配平台）</li></ul></li></ul><p><span><img src="https://static001.geekbang.org/infoq/2e/2e62e9e0874e3f25b7539be3f325e2ce.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_16"></span><h3><span>3.2 GLM-130B：稳定训练方法</span></h3><p><span>GLM-130B 是一个稳定训练方法，它是机器学习中的一种算法。GLM 代表广义线性模型，130B 表示这个算法的特定版本。</span></p><p><span>稳定训练方法是指通过一定的技巧和策略来增强模型的稳定性和鲁棒性，使其能够更好地处理噪声和异常数据。在训练过程中，稳定训练方法会对输入样本或特征进行一些改变或调整，以减少模型对于噪声的敏感性。</span></p><p><span>GLM-130B 的稳定训练方法可能包括以下几个方面：</span></p><ol><li>数据预处理：对输入数据进行去噪、归一化、特征选择等预处理操作，以减少噪声对模型训练的影响。</li><li>正则化：通过添加正则化项来限制模型的复杂度，防止过拟合，提高模型的泛化能力。</li><li>异常值处理：通过识别和处理异常值，减少它们对模型训练的影响。</li><li>随机化：引入随机化因素，如随机选择样本、随机初始化参数等，以增加模型的稳定性和抗噪能力。</li><li>交叉验证：使用交叉验证来评估模型的性能，并选择最佳的参数配置，避免对特定数据集过拟合。</li><li>集成学习：通过集成多个模型的预测结果，综合考虑它们的意见，提高整体模型的性能和稳定性。</li></ol><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>Attention score 层：Softmax in 32 避免上下溢出</span></p><p><span><img src="https://static001.geekbang.org/infoq/eb/eb9466cc9a9e1358eed2e03385231462.png" referrerpolicy="no-referrer"></span></p><p><span>调小 Embedding 层梯度，缓解前期梯度爆炸问题</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>word_embedding = word_embedding * alpha + word_embedding .detach() * (1 ‒ alpha) </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/02/0231e5136feafcb716c06bfcca29c53e.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/3a/3a35d951843f5cd1436a49bc8915d3ef.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_17"></span><h3><span>3.2 GLM-130B：大量实验确定最优架构</span></h3><p><span>有时候需要进行多次实验来确定最佳的架构设计。这些实验可能包括调整不同的参数、添加或移除不同的组件，以及测试不同的配置选项。GLM-130B 是根据这些实验的结果和分析，确定出的最佳架构。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>DeepNorm：稳定训练 1000 层 Post-LN 的方法</span></p><p><span><img src="https://static001.geekbang.org/infoq/30/302dcbc2e7fcda7ad9f07eae3f114634.png" referrerpolicy="no-referrer"></span></p><p><span>旋转位置编码 (RoPE)：适用于 GLM 的相对位置编码</span></p><p><span><img src="https://static001.geekbang.org/infoq/d1/d1bf3e06247efeb07a892962f7cad23a.png" referrerpolicy="no-referrer"></span></p><p><span>门控注意单元 (GLU)：FFN 层的替换，稳定提升模型性能</span></p><p><span><img src="https://static001.geekbang.org/infoq/5b/5b8a177e8e00a66dcdf3c8f225804f82.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/73/73f81d7a3a8b7ecbc268a63a89c879e6.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_18"></span><h3><span>3.3 Post LayerNorm</span></h3><p><span>Post LayerNorm（后层归一化）是一种神经网络层归一化的方法，用于解决深层神经网络中梯度消失和梯度爆炸问题。传统的 LayerNorm（层归一化）是在每个神经网络层的输入上进行归一化操作，而 Post LayerNorm 是在每个神经网络层的输出上进行归一化操作。</span></p><p><span>具体来说，在每个神经网络层的输入和激活函数之间，先进行 LayerNorm 的归一化操作，然后再进行激活函数的计算。这样可以使得每个神经网络层的输出都在相似的尺度上，避免了梯度消失和梯度爆炸的问题。</span></p><p><span>与之相比，传统的 LayerNorm 在每个神经网络层的输入上进行归一化操作，但在深层网络中，由于每层的输入分布不稳定，因此归一化操作的效果可能会下降。而 Post LayerNorm 能够在每个神经网络层的输出上进行归一化操作，保证了归一化的效果，提高了网络的稳定性和训练效果。</span></p><p><span>Post LayerNorm 是在 Transformer 网络中被提出的，并在各个任务上取得了显著的性能提升。它被认为是一种更加有效和稳定的归一化方法，在大规模深层网络的训练中具有重要的作用。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>重新排列层规范化和剩余连接的顺序</span></p><p><span><img src="https://static001.geekbang.org/infoq/d3/d3c43cdb9d19825a5f54d683e7b8787e.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_19"></span><h3><span>3.4 GLU</span></h3><p><span>GLU（Gated Linear Unit）是一种门控线性单元，用于增强神经网络的表示能力。通过将 GLU 应用于 MindSpore 框架中的大型模型，可以进一步提升模型的性能和效果。</span></p><p><span>GLU 的核心思想是将输入进行分割成两部分，然后通过门控机制控制两部分的信息传递。这种门控机制可以帮助模型更好地理解输入数据中的相关性，从而提高模型的表达能力和泛化能力。</span></p><p><span>在 MindSpore 框架中，GLU 可以被用于各种任务，包括自然语言处理、计算机视觉和语音识别等。通过使用 MindSpore 大模型 GLU，研究人员和开发人员可以更轻松地构建和训练复杂的模型，并获得更好的结果。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>用 GeLU 替换 ReLU 激活</span></p><p><span><img src="https://static001.geekbang.org/infoq/6d/6da4d692af614635c3118af36ff1e85f.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_20"></span><h3><span>3.5 并行策略：高效训练千亿模型</span></h3><p><span>存下 GPT-3 模型需要 2.8T 显存存放训练状态 + 中间激活函数值</span></p><p><span><img src="https://static001.geekbang.org/infoq/f5/f5b86a4417a834ee3b785f509cb03691.png" referrerpolicy="no-referrer"></span></p><p><span>挑战：远超单卡显存（40GB），采取何种并行方式高效训练？</span></p><ul><li>采用 ZeRO 优化器在数据并行组内分摊优化器状态 → ~25%</li></ul><p><span><img src="https://static001.geekbang.org/infoq/d8/d8e3bbef5f09de2a7896ec693dfbb1fd.png" referrerpolicy="no-referrer"></span></p><p><span>远超单卡显存，如何高效训练？</span></p><p><span><span>模型并行：将模型参数分布到多个 GPU 上</span></span></p><ul><li>张量并行：切分参数矩阵，每 GPU 计算一部分 → 额外通信，降低计算粒度</li><li>流水线并行：将网络分成多段并行 → 引入流水线气泡</li><li>ZeRO-3：将参数分布到数据并行组中，算之前先取回参数 → 额外通信时间</li></ul><p><span>分析：流水线的气泡占比： 𝑛⁄𝑡 $ 1 ，n / t &lt;&lt; 4m 的时候可以忽略不计</span></p><p>并行策略：张量并行随着模型规模增大缓慢扩展，但不超过单机规模（<br> &lt;=8），其余全部使用流水线并行，通过调整微批处理大小减少气泡占比</p><p><span><img src="https://static001.geekbang.org/infoq/fe/fe19784afba50f126511687410ba6880.png" referrerpolicy="no-referrer"></span></p><p><span><span>其他优化</span></span></p><ul><li>算子融合：融合多个 element-wise 算子 → 提升 ~10% 计算速度</li><li>流水线平衡：流水线首尾阶段各少放置一个层平衡占用 → 节省 ~10% 显存</li></ul><p><span><span>跨平台兼容：swDeepSpeed 训练库  与 DeepSpeed API 兼容</span></span></p><ul><li>支持申威架构，一行代码无缝替换兼容</li><li>实现并行通信策略，混合精度策略，ZeRO 优化器</li><li>同一套训练框架可在三个集群上对齐训练曲线</li></ul><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>import swDeepSpeed as deepspeed model, optimizer, _, _ = deepspeed.initialize( model=model, model_parameters=param_groups, args=args, mpu=mpu, dist_init_required=False, config_params=config_params ) </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/79/795f6c20368e1406f95a5bb8482c06d4.png" referrerpolicy="no-referrer"></span></p><p><span><span>测试集群配置：</span></span></p><ul><li>A100 集群（A100）： 96 台 DGX-A100，每台 2 张 200GB IB 网卡，硬件差异性大</li><li>海光 GPU（Hygon）：3000 台机器，每台 4 张 DCU 加速卡、4 张 50G IB 网卡</li><li>申威处理器（Sunway）：8192 个节点，每节点一块 SW26010-PRO 处理器</li></ul><p>训练 GPT-3 175B 规模的模型，按照相同的 300B 单词量估计训练时间：</p><p><span><img src="https://static001.geekbang.org/infoq/85/851274d88bafc04b1eb34d7889c30d5e.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_21"></span><h2><span>4.Rotary Positional Embedding</span></h2><span id="OSC_h3_22"></span><h3><span>4.1 Introduction of Positional Embedding</span></h3><p><span>Positional Embedding（位置编码）是一种用于处理序列数据的技术，主要应用于自然语言处理（NLP）任务中。在序列数据中，单词的顺序和位置对于语义的理解非常重要。位置编码的目的是为了将单词的位置信息融入到模型的表示中，使得模型能够更好地理解单词的顺序和上下文关系。</span></p><p><span>传统的词向量表示只考虑了单词的语义信息，而没有考虑单词的位置。位置编码通过为每个单词分配一个唯一的位置向量来解决这个问题。常用的位置编码方法包括相对位置编码、绝对位置编码、正弦位置编码等。</span></p><p><span>在相对位置编码中，每个单词的位置编码是相对于其他单词的位置差异而得到的。绝对位置编码则是将每个单词的位置映射为一个唯一的位置向量。正弦位置编码是一种常用的绝对位置编码方法，通过使用正弦和余弦函数来生成位置向量，从而捕捉到不同位置之间的相对关系。</span></p><p><span>位置编码的作用是为模型提供位置信息，帮助模型在处理序列数据时更好地理解单词的上下文和关系。它通常与注意力机制和 Transformer 等模型结构一起使用，为模型提供更丰富的上下文信息。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>自注意力机制主要关注词语之间的相互关系，在计算中，根据词语之间的语义关系来计算注意力分数，并不会考虑词语之间的位置关系。</span></p><p><span>即使打乱序列中词语的顺序，依旧会得到相同的语义表达因此需要额外增加位置信息。</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>The dog chased the pig. = The pig chased the dog. = chased pig The the dog. </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/33/3307391c156e6459b1b234929bde6337.png" referrerpolicy="no-referrer"></span></p><p><span>位置信息的表示有很多种，如</span></p><p><span><span><strong>absolute positional embeddings：</strong></span></span></p><ul><li>原理：对于第 k 个位置的向量 xk，添加位置向量 pk（仅依赖于位置编号 k），得到 xk+pk</li><li>举例/应用模型：sinusoidal positional embedding（Transformer）、learned absolute positional embedding（BERT/RoBERTa/GPT）</li></ul><p><span><span><strong>relative positional embeddings:</strong></span></span></p><ul><li>原理：对于第 m 个和第 n 个位置的向量 xm、xn，将相对位置 m-n 的信息添加到 self-attention matrix 中</li><li>举例/应用模型：T5</li></ul><p><span><span><strong>rotary positional embeddings</strong></span></span></p><ul><li>原理：使用旋转矩阵对绝对位置进行编码，并同时在自注意力公式中引入了显式的相对位置依赖。</li><li>举例/应用模型：PaLM/GPT-Neo/GPT-J/LLaMa1&amp;2/ChatGLM1&amp;2</li></ul><span id="OSC_h3_23"></span><h3><span>4.2 Sinusoidal Positional Embedding</span></h3><p><span>Sinusoidal Positional Embedding（正弦位置编码）是一种用于编码序列数据中单词位置信息的方法，最初在 Transformer 模型中被引入。它是一种绝对位置编码方法，通过正弦和余弦函数来生成位置向量，从而捕捉到不同位置之间的相对关系。</span></p><p><span>在正弦位置编码中，每个单词的位置编码由两个维度的正弦和余弦函数计算得到。具体计算公式如下：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>PE(pos,2i) = sin(pos / 10000^(2i/d_model)) PE(pos,2i+1) = cos(pos / 10000^(2i/d_model)) </span></span></span></span></span></span></pre><p><span>其中，pos 表示单词在序列中的位置，i 表示位置向量的维度索引，d_model 表示模型的维度。这样，每个单词的位置编码可以由位置索引 pos 和维度索引 i 计算得到。</span></p><p><span>正弦位置编码的特点是，不同位置之间的位置向量是正弦和余弦函数的周期函数。这使得不同位置之间的位置向量能够保持一定的相似性，从而帮助模型更好地理解位置信息并捕捉到序列中的顺序关系。</span></p><p><span>正弦位置编码通常与注意力机制和 Transformer 模型一起使用，用于为模型提供序列数据的位置信息。它的优点是简单且可解释，能够有效地表达不同位置之间的相对关系。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>通过 sine 和 cosine 函数计算每个位置的 positional embedding</span></p><ul><li><p><span>优点：1. 可以反应相对位置信息；2. 模型可以接受不同长度的输入</span></p></li><li><p><span>缺点：数值为固定值，无法参与学习</span></p></li></ul><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>PE(pos, 2i)=sin(pos/10000^2i/d_model) PE(pos, 2i+1)=cos⁡(pos/10000^2i/d_model) </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/59/5991a37b1ee92ffd917cb742725276c3.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_24"></span><h3><span>4.3 Learned Positional Embedding</span></h3><p><span>Learned Positional Embedding 是一种在自然语言处理任务中用于编码位置信息的技术。在传统的 Transformer 模型中，位置编码是通过固定的数学公式（如正弦函数或余弦函数）来计算得到的。而 Learned Positional Embedding 则是通过在模型的嵌入层中引入可学习的参数来学习位置信息的表示。</span></p><p><span>传统的位置编码方法只能对句子的位置进行大致的编码，而 Learned Positional Embedding 可以更准确地表示不同位置的信息。当模型学习到不同位置的嵌入表示时，它可以更好地区分不同位置的词语，并捕捉到位置信息对任务的影响。</span></p><p><span>Learned Positional Embedding 的一个优点是可以根据任务的需要进行调整。传统的位置编码是固定的，不会随着训练进行调整。而 Learned Positional Embedding 可以通过反向传播算法来优化参数，以更好地适应不同任务的需求。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>将表示位置的 position ids 放入 nn.Embedding，获取大小为 hidden size 的 positional embedding</span></p><ul><li><p><span>优点：可以随模型训练进行参数更新</span></p></li><li><p><span>缺点：可扩展性差，只能表征在 max_seq_length 以内的位置</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/aa/aab0c97c5cad3ea7b922666b58d78e16.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_25"></span><h3><span>4.4 Relative Positional Embedding</span></h3><p><span>相对位置嵌入（Relative Positional Embedding）是一种用于编码序列中元素之间相对位置关系的技术，常用于自然语言处理和序列建模任务中。</span></p><p><span>在传统的位置嵌入方法中，如正弦/余弦位置嵌入（Sinusoidal Positional Embedding）或学习位置嵌入（Learned Positional Embedding），每个位置的嵌入向量是固定的，不考虑其与其他位置的关系。但在很多任务中，序列中的元素之间的相对位置关系对于理解序列的语义和结构非常重要。</span></p><p><span>相对位置嵌入通过将每个元素的位置嵌入向量与其他位置的偏移向量进行组合，来编码元素之间的相对距离。这样，每个元素的位置嵌入向量会随着其与其他元素的位置关系而变化，从而更好地捕捉序列中的局部结构信息。</span></p><p><span>相对位置嵌入常用于 Transformer 模型中，在自注意力机制（Self-Attention）中使用。通过引入相对位置嵌入，Transformer 可以更好地处理序列中元素之间的相对位置关系，从而提高序列建模的性能。在相对位置嵌入中，常见的方法是使用距离编码矩阵（Distance Encoding Matrix）来计算偏移向量，然后与位置嵌入向量相加。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>在计算自注意力分数时，在 query 和 key 的 dot product，以及最终注意力权重和 value 矩阵乘时，分别额外添加一个表示位置 m 和位置 n 相对位置信息的 bias，仅依赖于 m-n</span></p><p><span>优点：</span></p><ul><li><p><span>可以直观记录词语的相对位置信息</span></p></li><li><p><span>模型可接受不同长度的输入</span></p></li></ul><p><span>缺点：</span></p><ul><li>训练和推理速度慢（尤其是长序列的时候）</li></ul><p><span><img src="https://static001.geekbang.org/infoq/76/760ef0b0234b9fa018bde315640a7b98.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/52/52d0da76f1a528e963667f604e7667ea.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_26"></span><h3><span>4.5 Rotary Positional Embedding</span></h3><p><span>相关代码如下：</span></p><p><span><img src="https://static001.geekbang.org/infoq/9b/9b38ccc9f634a10b8cbe3b32e741dc85.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h4_27"></span><h4><span>4.5.1 2D case</span></h4><p><span>Rotary Positional Embedding - 2D case 是一种用于编码二维序列中位置信息的方法，特别适用于 Transformer 等模型中的注意力机制。</span></p><p><span>在传统的位置嵌入方法中，如正弦/余弦位置嵌入（Sinusoidal Positional Embedding）或学习位置嵌入（Learned Positional Embedding），每个位置的嵌入向量是固定的，不考虑其与其他位置的关系。但对于二维序列，仅使用位置索引的编码方法无法很好地捕捉到元素在二维空间中的相对位置关系。</span></p><p><span>Rotary Positional Embedding - 2D case 通过引入角度信息，能够更好地编码二维序列中元素的位置关系。具体来说，它使用了旋转操作来编码位置信息，这可以看作是将位置嵌入向量绕原点旋转一定的角度。通过在嵌入向量中引入角度信息，可以更好地表示元素在二维空间中的相对位置。</span></p><p><span>在 2D 案例中，Rotary Positional Embedding 通常与自注意力机制（Self-Attention）一起使用。在注意力机制中，通过将位置嵌入向量与注意力权重相乘，并进行相应的运算，将位置信息引入注意力计算中。这样，模型可以更好地理解元素之间的相对位置关系，从而提高序列建模的性能。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>以 2D word vector 为例，第 m 个位置的词语可以用一个二维的向量 xm 表示，我们将它的 query 和 key 向量在 2D 平面上进行逆时针旋转，旋转角度取决于位置索引 m</span></p><ul><li><p><span>dog：单词 dog 在第 0 位，不进行旋转</span></p></li><li><p><span>The dog：单词 dog 在第 1 位，旋转角度θ</span></p></li><li><p><span>The pig chased the dog：单词 dog 在第 4 位，旋转角度 4</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/60/60dc693fb0f12c80e400fd095edfa932.png" referrerpolicy="no-referrer"></span></p><p><span>这样在计算 xm 和 xnquery，key 的点积时，结果仅和 (m-n)θ有关，而非 m 或 n</span></p><p><span>优点：</span></p><ul><li><p><span>计算 self-attention q,k 点积时，保留了词语的相对位置信息（不会因词语的绝对位置发生改变）</span></p></li><li><p><span>前面位置的 positional embedding 不受后续新增 token 的影响（easier to cache）</span></p></li><li><p><span>token 之间的依赖会随着相对距离的增长而逐步衰减（符合认知，距离越远的词普遍关联不大）</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/a9/a9379dde05d359a28b99d0af242c825e.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h4_28"></span><h4><span>4.5.2 general form</span></h4><p><span>Rotary Positional Embedding - general form 是一种用于编码位置信息的方法，通用形式适用于各种序列数据，包括一维、二维或其他维度的序列。</span></p><p><span>在传统的位置嵌入方法中，如正弦/余弦位置嵌入（Sinusoidal Positional Embedding）或学习位置嵌入（Learned Positional Embedding），每个位置的嵌入向量是固定的，不考虑其与其他位置的关系。但是，这种方法无法很好地捕捉到元素在序列中的相对位置关系。</span></p><p><span>Rotary Positional Embedding - general form 通过引入旋转操作，能够更好地编码序列中元素的位置关系。具体来说，它使用了旋转矩阵来对位置嵌入进行变换，这可以看作是将位置嵌入向量绕一个固定的轴旋转一定的角度。通过在嵌入向量中引入旋转信息，可以更好地表示元素在序列中的相对位置。</span></p><p><span>在一般形式中，Rotary Positional Embedding 可以与注意力机制（Attention Mechanism）一起使用。在注意力机制中，通过将位置嵌入向量与注意力权重相乘，并进行相应的运算，将位置信息引入注意力计算中。这样，模型可以更好地理解元素之间的相对位置关系，从而提高序列建模的性能。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><ul><li>将单词的词向量大小设定为 2 的倍数</li><li>第 m 个位置的词向量在第 i 组 2D sub-space（即向量中的 2i，2i+1 元素）的旋转角度为 mθ_i，θ_i 与 i 以及词向量的 hidden size 有关</li></ul><p><span><img src="https://static001.geekbang.org/infoq/c8/c8ad5874bebd3c2658c26afeb91f0787.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h1_29"></span><h1><span><span>二、From GLM to ChatGLM</span></span></h1><span id="OSC_h2_30"></span><h2><span>1.传统 NLP 的挑战</span></h2><span id="OSC_h3_31"></span><h3><span>1.1 挑战 1:传统 NLP vs 复杂问题</span></h3><p><span>传统 NLP（自然语言处理）方法通常用于处理简单的文本任务，例如文本分类、命名实体识别和情感分析等。这些方法主要依赖于规则和模式，以及统计和机器学习算法。</span></p><p><span>对于复杂问题，传统 NLP 方法可能面临一些挑战。复杂问题通常具有多义性、歧义性和上下文依赖性。例如，理解一个句子的意思可能需要考虑上下文信息和背景知识。此外，复杂问题还可能涉及多种语言和跨语言的处理。</span></p><p><span>为了应对复杂问题，研究者们开始使用深度学习方法，如循环神经网络（RNN）和注意力机制等。这些方法能够更好地处理语义理解和生成，以及更好地捕捉文本的上下文信息。</span></p><p><span>复杂问题还可能需要结合其他领域的知识，例如知识图谱、计算机视觉和知识推理等。这样可以提供更全面的语义理解和推理能力。</span></p><p><span><img src="https://static001.geekbang.org/infoq/b5/b596343a38eae8d3a9129133c3284a45.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_32"></span><h3><span>1.2 挑战 2:传统 NLP vs 动态知识</span></h3><p><span>传统 NLP（自然语言处理）是一种基于规则和模式的方法，它主要依赖于人工编码的语言规则和语法结构来理解和处理文本。这些规则和结构需要事先定义，并且通常需要大量的人工工作。</span></p><p><span>动态知识（Dynamic Knowledge）则是一种基于知识图谱和自动学习的方法，它能够根据实时的数据来自动更新和扩展知识库。动态知识利用机器学习和图谱技术，可以从大量的文本和语料库中自动提取和建立知识模型。</span></p><p><span>传统 NLP 的一个主要优势是其可解释性，因为所有的规则和模式都是人工定义的，所以可以清楚地理解其工作原理。然而，它也存在一些缺点，例如需要大量的人工工作来编写和维护规则，而且对于复杂的语言现象和变化的语言规则往往无法适应。</span></p><p><span>相比之下，动态知识能够通过机器学习和自动学习的方式，自动地从大量的文本中提取和建立知识模型。它可以自动学习语言现象和规则的变化，并且可以根据实时的数据来更新和扩展知识库。动态知识的优点是其能够处理复杂的语言现象和变化的语言规则，并且具有较强的适应性和灵活性。</span></p><p><span>但动态知识也存在一些挑战，例如其可解释性相对较差，因为知识模型是通过机器学习自动学习的，所以很难直观地理解其工作原理。此外，动态知识的构建和维护也需要大量的计算资源和数据支持。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>千亿模型的动态知识欠缺、知识陈旧、缺乏可解释性</span></p><ul><li><p><span>知识欠缺：长尾知识</span></p><ul><li>例如: 世界第二高的山峰 (答案: K2 格里峰)</li></ul></li><li><p><span>知识陈日：GPT-3 的训练数据截止 2020 年前</span></p></li><li><p><span>不可解释:缺乏答案的参考源</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/60/6080170bcc2fc2162fa74aedabf7920d.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_33"></span><h3><span>1.3 挑战 3:传统 NLP vs 人类对齐</span></h3><p><span>传统 NLP 是基于机器学习和统计的方法，利用大量已标注的语料库来训练模型。这些模型可以识别和理解文本的语法结构、词义和语义关系等。传统 NLP 方法包括语法分析、词性标注、命名实体识别、情感分析等技术。这些技术可以自动处理大规模的文本数据，并提供一些高级的语言处理功能。</span></p><p><span>人类对齐是指通过人工的方式对文本进行处理和理解。人类对齐可以是通过人工标注和标记的方式，也可以是通过人工阅读和理解的方式。人类对齐可以更准确地理解文本的含义和语境，尤其在处理一些复杂的语言结构和语义问题时更具优势。人类对齐可以包括人工智能助手和人工翻译等应用。</span></p><p><span>传统 NLP 和人类对齐两种方法各有优缺点。传统 NLP 方法可以在处理大规模数据时提供高效的处理能力，但在面对复杂语义问题时可能存在理解不准确或无法捕捉语境的问题。而人类对齐可以更准确地理解文本的含义和语境，但在大规模处理和实时处理方面可能存在效率和成本的问题。</span></p><p><span><strong><code>案例片段介绍如下：</code></strong></span></p><p><span>例如：请用几句话给一个 6 岁小孩解释登月</span></p><ul><li>缺少高效"Prompt 工程"，GPT-3 和 GLM-130B 都很难尽人意</li></ul><p><span><img src="https://static001.geekbang.org/infoq/da/dada2bf6fb98e01f532bdcda5dbaf49c.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_34"></span><h2><span>2.从千亿模型到 ChatGLM 的技术路线</span></h2><p><span>千亿模型 GLM-130B 是一个大规模语言模型，具有 130 亿个参数，用于自然语言处理任务。它采用了 Transformer 架构和大规模预训练技术，可以生成高质量的文本。</span></p><p><span>GLM-130B+是在 GLM-130B 的基础上进行了改进和优化。它针对语言模型的训练过程进行了一些调整，提升了模型的性能和效果。GLM-130B+在更多的自然语言处理任务上具有更好的表现。</span></p><p><span>GLM-130B++是在 GLM-130B+的基础上进一步改进的版本。它引入了更多的新技术和优化策略，使得模型在处理长文本、多语种和多任务上表现更出色。GLM-130B++具有更强大的表达能力和更好的泛化能力。</span></p><p><span>ChatGLM 模型是基于 GLM 系列模型的一种变种，专门用于生成对话文本。它在 GLM-130B++的基础上进行了一些改进，使得模型在对话生成任务上更加适用和有效。ChatGLM 模型在生成对话内容时可以更好地理解上下文和语境，并生成更具连贯性和合理性的对话文本。</span></p><p><span><img src="https://static001.geekbang.org/infoq/6d/6de13d2ba9530137b2656ace3b4a633a.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_35"></span><h2><span>3.ChatGLM 的应用场景</span></h2><span id="OSC_h3_36"></span><h3><span>3.1 撰写博客提纲</span></h3><p><span><img src="https://static001.geekbang.org/infoq/9d/9d13d38b0516f9a2d982eaf70efd15ac.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_37"></span><h3><span>3.2 写邮件</span></h3><p><span><img src="https://static001.geekbang.org/infoq/8b/8bd5452e6da22d5398a1ce56aaab379d.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_38"></span><h3><span>3.3 介绍自己的优点缺点</span></h3><p><span><img src="https://static001.geekbang.org/infoq/42/421e29218719bf6d15768cc3cf345a0a.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_39"></span><h3><span>3.4 写剧本梗概</span></h3><p><span><img src="https://static001.geekbang.org/infoq/e2/e2f7cb53ac7c1a2f3c3f6169d3145e67.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_40"></span><h3><span>3.5 写代码</span></h3><p><span><img src="https://static001.geekbang.org/infoq/a9/a926fcc4ba701256ec42d723ce687afb.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_41"></span><h3><span>3.6 查询常见知识/教程</span></h3><p><span><img src="https://static001.geekbang.org/infoq/9f/9f1ec261b96b5b9b91059e60fb17455c.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_42"></span><h3><span>3.7 多轮问答</span></h3><p><span><img src="https://static001.geekbang.org/infoq/2a/2ad75a59ee31fcf2587b2f9381e245fa.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/e3/e36a74fadde7599d2f7b581e754ca640.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_43"></span><h3><span>3.8 文字冒险游戏</span></h3><p><span><img src="https://static001.geekbang.org/infoq/10/103cecea0a0aba1a97629d9672a73e84.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h1_44"></span><h1><span><span>三、ChatGLM Demo</span></span></h1><p><span>完整的课程学习地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmindspore-courses%2Fstep_into_llm" rel="nofollow" target="_blank">完整的课程学习地址</a></span></p><p><span><img src="https://static001.geekbang.org/infoq/17/174e6a94b6d8988dcf8fc430e4cbbdd9.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_45"></span><h2><span>1.使用 NPU+MindSpore Transformers 试用 ChatGLM 推理</span></h2><span id="OSC_h3_46"></span><h3><span>1.1 OpenI 启智运行 ChatGLM 模型</span></h3><p><span>1、到 OpenI 启智申请账号，开启云脑任务（NPU）/自己用 GPU 创建环境</span></p><p><span>OpenI 启智申请账号地址：https://openi.pcl.ac.cn/user/sign_up</span></p><p>&nbsp;</p><p><span><img src="https://static001.geekbang.org/infoq/0e/0e11bad9d6398b58031b538eb986c59e.png" referrerpolicy="no-referrer"></span></p><p>2、创建项目</p><p>&nbsp;</p><p><span><img src="https://static001.geekbang.org/infoq/de/de290dd58507ada8228b8859b41117c4.png" referrerpolicy="no-referrer"></span></p><p><span>3、打开新创建的项目，点击云脑，新建调试任务</span></p><p><span><img src="https://static001.geekbang.org/infoq/6b/6b022877602bff1996db62679ae88965.png" referrerpolicy="no-referrer"></span></p><p><span>4、点击调试</span></p><p><span><img src="https://static001.geekbang.org/infoq/e6/e6f6ae6a5a3c808b58f95ecc527d198b.png" referrerpolicy="no-referrer"><br> 5、进入终端</span></p><p><span><img src="https://static001.geekbang.org/infoq/63/6306925e6ef5356c9caa7314bc3f0ef7.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/db/db007f9151bc4b2d422674639d34c97c.png" referrerpolicy="no-referrer"></span></p><p><span>其他操作如下面<code>1.2 小结</code>，这边只是用 OpenI 启智 NPU+MindSpore 进行在线部署调试，部署结果如下图：</span></p><p><span><img src="https://static001.geekbang.org/infoq/30/3029472aa56b9869fe9af47fbb593e5a.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_47"></span><h3><span>1.2 MindSpore 运行 ChatGLM 模型</span></h3><p><span>安装 MindSpore 和 MindSpore Transformers</span></p><p><span>a) MindSpore 安装：参考：MindSpore 官网（如果用 OpenI 启智 NPU+MindSpore，可以忽略这一步，这步属于本地部署）</span></p><p><span>b) MindSpore Transformers 安装：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>1、git clone -b dev https://gitee.com/mindspore/mindformers.git 2、cd mindformers 3、bash build.sh 4、如果使用 MindSpore1.10 版本，请安装 MindFormers 0.6 版本（git clone -b r0.6 …） </span></span></span></span></span></span></pre><p><span>c) 克隆升思 MindSpore 技术公开课代码仓：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>git clone https://github.com/mindspore-courses/step_into_llm.git </span></span></span></span></span></span></pre><p><span>d)&nbsp;<code>cd step_into_llm/Season2.step_into_llm/01.ChatGLM/</code></span></p><p><span>e) 下载 ckpt 和 tokenizer 文件</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>1、ckpt：wget https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/glm_6b.ckpt 2、tokenizer：wget https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/ice_text.model </span></span></span></span></span></span></pre><p><span>f) 运行推理部署文件：python cli_demo.py</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>import os import platform import signal import numpy as np import mindspore as ms from mindformers.models.glm import GLMConfig, GLMChatModel from mindformers.models.glm.chatglm_6b_tokenizer import ChatGLMTokenizer from mindformers.models.glm.glm_processor import process_response config = GLMConfig( position_encoding_2d=True, use_past=True, is_sample_acceleration=True) ms.set_context(mode=ms.GRAPH_MODE, device_target="GPU", device_id=0) model = GLMChatModel(config) # https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/glm_6b.ckpt ms.load_checkpoint("./glm_6b.ckpt", model) # https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/ice_text.model tokenizer = ChatGLMTokenizer('./ice_text.model') os_name = platform.system() clear_command = 'cls' if os_name == 'Windows' else 'clear' stop_stream = False def build_prompt(history): prompt = "欢迎使用 ChatGLM-6B 模型，输入内容即可进行对话，clear 清空对话历史，stop 终止程序" for query, response in history: prompt += f"\n\n 用户：{query}" prompt += f"\n\nChatGLM-6B：{response}" return prompt def signal_handler(): global stop_stream stop_stream = True def main(): history = [] global stop_stream print("欢迎使用 ChatGLM-6B 模型，输入内容即可进行对话，clear 清空对话历史，stop 终止程序") while True: query = input("\n 用户：") if query.strip() == "stop": break if query.strip() == "clear": history = [] os.system(clear_command) print("欢迎使用 ChatGLM-6B 模型，输入内容即可进行对话，clear 清空对话历史，stop 终止程序") continue count = 0 inputs = tokenizer(query) outputs = model.generate(np.expand_dims(np.array(inputs['input_ids']).astype(np.int32), 0), max_length=config.max_decode_length, do_sample=False, top_p=0.7, top_k=1) response = tokenizer.decode(outputs) response = process_response(response[0]) history = history + [(query, response)] if stop_stream: stop_stream = False break else: count += 1 if count % 8 == 0: os.system(clear_command) print(build_prompt(history), flush=True) signal.signal(signal.SIGINT, signal_handler) os.system(clear_command) print(build_prompt(history), flush=True) if __name__ == "__main__": main() </span></span></span></span></span></span></pre><span id="OSC_h1_48"></span><h1><span><span>总结</span></span></h1><p><span>MindSpore 作为一种强大的深度学习框架，提供了丰富的工具和功能，使得模型的开发和训练更加高效和灵活。其支持端到端的深度学习解决方案，可以应用于各种任务和场景。而 ChatGLM 作为一种生成式语言模型，通过对话的方式生成自然流畅的文本，可以用于智能对话和智能客服等应用。</span></p><p><span>结合使用 MindSpore 和 ChatGLM，我们可以实现更加智能和交互性的应用。首先，MindSpore 可以用来训练 ChatGLM 模型，通过大量的对话数据进行学习，使得生成的文本更加贴近真实的对话。MindSpore 提供了分布式训练的功能，可以在多个设备和计算节点上进行模型的并行训练，加速训练过程。其自动微分功能也可以帮助优化 ChatGLM 模型的训练效果。</span></p><p><span>通过 MindSpore 的强大功能和 ChatGLM 的生成式语言模型，我们可以构建出高效、准确和自然流畅的智能对话系统，提升用户体验并开拓更多的应用领域。这种结合使用不仅有助于推动机器学习和人工智能的发展，还为带来更多的创新和可能性。</span></p><p>&nbsp;</p><p><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>点击关注，第一时间了解华为云新鲜技术~</strong></a></span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:09:11 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/11047106</guid>
            <link>https://my.oschina.net/u/4526289/blog/11047106</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[睿芯成立 RV64G SIG，携手社区共建 RV64G 软件生态体系！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">2024 年 3 月，经 openKylin 社区技术委员会审议通过，<strong>RV64G SIG</strong>正式成立。</span></p><p><span style="color:#000000">RV64G 是 RISC-V 专门定义的重要子架构（支持 RISC-V imafd 指令集），为广泛的通用计算领域提供了简单且完备的指令集，RV64G SIG 由社区共建单位睿芯发起成立，致力于构建 RV64G 软件生态体系，支持更加广泛的 RISC-V 硬件。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p><strong>01 SIG 目标</strong></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">openKylin RV64G 版本的规划、制作、维护和升级，实现更广泛的硬件支持。</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">探索 RISC-V 各子架构应用兼容问题。</span></p></li></ul><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p><strong>02 SIG 职责及规划</strong></p><p><strong><span style="color:#333333">1、创建并维护 RV64G 版本</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">规划、制作 RV64G 社区版本，维护 RV64G 编译器，提供 RV64G 镜像。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong><span style="color:#333333">2、基于 openKylin RV64G 适配更多硬件</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">基于 openKylin RV64G 支持常用芯片、驱动，帮助芯片、驱动厂家进行系统适配，降低移植难度，丰富 RV64G 可用硬件列表。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong><span style="color:#333333">3、基于 openKylin RV64G 为软件适配提供技术支持</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333"><span>基于 openKylin RV64G 移植常用应用，帮助</span><span style="color:var(--weui-LINK)">第三方软件</span><span>移植到 RV64G，丰富 RV64G 可用软件；</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p><strong>03 欢迎加入 SIG</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">RV64G SIG 基于开发合作的态度，希望构建有活力的社区生态，我们期待对此感兴趣的小伙伴不断加入！</span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">邮箱列表：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#0052ff"><span style="color:#0052ff">rv64g</span>@lists.openkylin.top</span></p></li></ul><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">SIG 主页：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/RV64G</span></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 01:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282990</guid>
            <link>https://www.oschina.net/news/282990</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[荣耀称已投入 100 亿用于 AI 研发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">荣耀笔记本 AI PC 技术沟通会今日举行，荣耀终端有限公司产品线总裁方飞表示，荣耀目前已持续投入 100 亿元 AI 研发费用，完成相关 AI 专利成果 2100 篇，实现 600 类 AI 意图识别，未来 PC 创新将围绕 AI 进行。</span></p><p><span style="color:#000000"><img height="255" src="https://oscimg.oschina.net/oscnet/up-dbcf2c2a6ddd3f664b16e4deaf56cbf8863.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">即将在 3 月 18 日发布的荣耀 MagicBook Pro 16 笔记本，也将通过荣耀 AI 的全方位使能，开启 AI PC 新的时代。</span></p><p><span style="color:#000000">方飞称，荣耀笔记本把 AI 技术与用户体验融合，用 AI 使能智能硬件、人机交互和多端生态来重构 PC 行业。比如，通过 AI 网络调度优先业务加速，带来更低的网络时延；在 PC 交互上实现全局收藏、文档总结、搜索材料、文章撰写等辅助创作能力；基于意图理解的智慧推荐、会议纪要、Magic Text 等 AI 辅助能力。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 01:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282988</guid>
            <link>https://www.oschina.net/news/282988</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[信通院发布报告，研究中国综合算力]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">《中国综合算力评价白皮书（2023 年）》由中国信息通信研究院发布，主要内容包括：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>背景介绍</strong>：随着科技革命和产业变革的加速，算力成为数字化转型的新动能。中国在算力、存力、运力方面的基础设施投入不断加大，形成了支撑数字经济发展的重要力量。</p></li><li><p style="margin-left:0; margin-right:0"><strong>算力发展现状</strong>：截至 2022 年底，中国算力核心产业规模达到 1.8 万亿元，算力总规模达到 180EFLOPS，年增长率近 30%。存力总规模超过 1000EB，网络单向时延降低到 20 毫秒以内。</p></li><li><p style="margin-left:0; margin-right:0"><strong>综合算力评价体系</strong>：白皮书构建了一个涵盖算力、存力、运力、环境等关键因素的综合算力评价指标体系，对我国综合算力的发展情况进行了多维度的客观分析，并给出了发展建议。</p></li><li><p style="margin-left:0; margin-right:0"><strong>评价结果</strong>：综合算力评价结果显示，广东省、江苏省、上海市等东部省份在算力、存力、运力方面整体处于较高水平，而内蒙古自治区、贵州省等西部省份在存力、环境等方面也展现出优势。</p></li><li><p style="margin-left:0; margin-right:0"><strong>发展建议</strong>：白皮书提出了系统布局新型基础设施、加速推动核心技术创新、加快政策标准体系建设、持续构建全产业链生态、激发算力产业创新动力等建议，以推动综合算力的技术创新与基础设施建设。</p></li><li><p style="margin-left:0; margin-right:0"><strong>数据来源和计算方法</strong>：报告的数据来源于工信部、中国信通院等官方机构和公开资料，采用极差标准化法进行指标标准化，并利用层次分析法（AHP）确定指标权重，最后形成各区域的评价结果。</p></li><li><p style="margin-left:0; margin-right:0"><strong>联系方式</strong>：文件最后提供了中国信息通信研究院的地址、邮编、电话、传真和网址信息。</p></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">整体而言，这份白皮书全面阐述了中国综合算力的发展现状、评价体系、评价结果，并对未来的发展提出了建议，旨在为我国综合算力的技术创新与基础设施建设提供参考。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282905</guid>
            <link>https://www.oschina.net/news/282905</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Laravel 11 正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Laravel 11 和 Laravel Reverb 现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel-news.com%2Flaravel-11" target="_blank">发布</a>。Reverb 是 Laravel 生态系统的最新成员，是第一方、可扩展的 WebSocket 服务器，旨在为用户的应用程序提供强大的实时功能。</span></p><p><span style="color:#000000">Laravel 11 引入了：极简应用结构、默认使用 SQLite、实现 health routing、提供每秒速率限制、支持优雅的加密密钥轮换、改进队列测试、引入新的 Artisan 命令、添加 Resend 邮件传输、集成 Prompt validator、新的 Artisan commands、Model Casts 改进、The once function、改进了使用内存数据库进行测试时的性能、改进了对 MariaDB 的支持等等，</span></p><p><span style="color:#000000">Laravel 11 使用的 PHP 版本最低要求是&nbsp;PHP 8.2。</span></p><p><img alt="" height="352" src="https://oscimg.oschina.net/oscnet/up-0453b972568e047b7d57af4dd0cf5cf3c7d.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><strong>极简应用结构</strong></span></p><p><span style="color:#000000">Laravel 11 为新的 Laravel 应用程序引入了极简应用程序结构，无需对现有应用程序进行任何更改。新的应用程序结构旨在提供更精简、更现代的体验，同时保留 Laravel 开发人员已经熟悉的许多概念。</span></p><p><span style="color:#000000">应用程序文件夹已大幅简化；HTTP 内核和控制枱内核都已删除。很少定制的九个中间件现已移至框架本身，异常处理程序已被移除，Providers 目录精简为单一提供程序。</span></p><p><img height="313" src="https://oscimg.oschina.net/oscnet/up-fd30e47727225b78e873f024484cf66b61e.png" width="500" referrerpolicy="no-referrer"></p><p><img height="388" src="https://oscimg.oschina.net/oscnet/up-45a1e9253daae9587fc3b631ede34b2d0a4.png" width="500" referrerpolicy="no-referrer"></p><p>此外，<code>routes</code>文件夹也得到了简化；默认情况下， <code>api.php</code>和<code>channels.php</code>路由文件不再存在，因为许多应用程序不需要这些文件。</p><p><img height="209" src="https://oscimg.oschina.net/oscnet/up-201c1fc787f2da27f81a117792a7429a363.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">可以使用简单的 Artisan 命令来创建它们：</span></p><pre style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><code class="language-shell">php artisan install:api

php artisan install:broadcasting</code></span></pre><p><strong><span style="color:#000000">Laravel Reverb</span></strong></p><p>Laravel Reverb 直接为你的 Laravel 应用程序带来超快且可扩展的实时 WebSocket 通信，并提供与 Laravel 现有事件广播工具套件（例如<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel.com%2Fdocs%2F11.x%2Fbroadcasting" target="_blank">Laravel Echo）</a>的无缝集成。<span style="color:#000000">此外，Reverb 通过 Redis 的发布/订阅功能支持水平扩展，允许用户在多个后端 Reverb 服务器之间分配 WebSocket 流量，所有服务器都支持单个高需求应用程序。</span></p><p><img alt="" height="250" src="https://oscimg.oschina.net/oscnet/up-1afcddc83e166e5471581763d90dca87c48.webp" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">下面是一个压力测试示例，约 30,000 个客户端保持与 Reverb 的开放连接，其中每个连接订阅 10 个不同的通道，每秒交换超过 6,000 条消息：</span></p><p style="margin-left:0; margin-right:0; text-align:start"><img height="343" src="https://oscimg.oschina.net/oscnet/up-03c0f7168a242e4116186204b90cb8da1ed.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start">此外，用户可以在 Laravel Pulse 中监控 Reverb 服务器的性能，以更好地了解正在处理的连接和消息的数量。要深入了解 Laravel Reverb，可参阅完整的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel.com%2Fdocs%2F11.x%2Freverb" target="_blank">Reverb 文档</a>。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><strong><span style="color:#000000">默认情况下的 SQLite</span></strong></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">默认情况下，新的 Laravel 应用程序使用 SQLite 进行数据库存储，以及 Laravel 会话、缓存和队列的<code>database</code>驱动程序。此外，使用<code>composer create-project</code>命令或通过 Laravel 安装程序创建项目将自动创建 SQLite 文件并为你运行初始数据库迁移：</span></p><p style="margin-left:0px; margin-right:0px; text-align:start"><img height="267" src="https://oscimg.oschina.net/oscnet/up-3f2f9c8b6e11b58e504d090a02fccbcd80c.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start"><span style="color:#000000">这允许你在创建新的 Laravel 应用程序后立即开始构建应用程序，而无需安装额外的软件或创建额外的数据库迁移。</span></p><p style="margin-left:0px; margin-right:0px; text-align:start"><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.laravel.com%2Flaravel-11-now-available" target="_blank">查看官方公告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:46:46 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282901/laravel-11-released</guid>
            <link>https://www.oschina.net/news/282901/laravel-11-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美国政府软件要求提供安全软件开发认证表]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">作为改善网络安全持续努力的一部分，拜登-哈里斯政府宣布已批准了一份</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cisa.gov%2Fresources-tools%2Fresources%2Fsecure-software-development-attestation-form" target="_blank">安全软件开发认证表</a>。</p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">该表格由 CISA 和管理和预算办公室 (OMB) 于 2024 年 3 月 11 联合发布，任何提供政府将使用的软件的公司都需要填写该表格。它将有助于确保该软件是由优先考虑安全性的公司开发的。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><img height="250" src="https://oscimg.oschina.net/oscnet/up-5f101db1d80c4331864091d96dc415eac6e.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Endor Labs 首席安全顾问兼 CISA 网络创新研究员 Chris Hughes 表示：「表格中的要求代表了一些基本的安全开发实践，希望向联邦政府出售软件的供应商如果想参与联邦监管的生态系统，就应该能够满足这些要求。」&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">表格中的要求之一是软件必须在安全的环境中开发。这包括分离生产和开发环境，最大限度地减少代码中不安全产品的使用，跨环境强制执行多因素身份验证，加密敏感数据，实施持续监控和警报等防御实践，以及定期记录、监控和审核信任关系。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「分离开发和生产环境、实施日志记录和 MFA 等做法是任何现代安全软件开发环境中都应该存在的关键安全控制措施。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">另一个要求是通过使用自动化工具监控第三方代码并维护内部代码和第三方组件的来源，真诚地努力维护可信的供应链。它还需要定期使用自动化工具来检查安全漏洞，包括制定披露和解决已知漏洞的策略。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">然而 Hughes 认为，这种形式缺少一些元素。例如，它不需要使用威胁建模或内存安全，而这正是 CISA 一直在推动的事情。他表示，它还允许首席执行官指定其他人在证明上签字，以便在出现问题或证明造假时作为潜在的替罪羊。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「一方面，我们听说网络安全需要成为董事会的议题，CISA 甚至呼吁高管层参与其有关安全设计/默认的出版物；但另一方面，这种形式允许将这一关键认证活动委托给某人组织中的其他人，并可能使其无法被最高管理层/首席执行官和执行领导团队看到。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Hughes 认为，最难满足认证要求的软件生产商是那些尚未实施安全软件开发实践的软件生产商。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「他们需要评估当前的开发实践，找出缺陷并实施纠正计划。这当然需要时间和资源，而规模较小的初创公司和不成熟的组织获得这些时间和资源的机会有限，尤其是面对对上市速度、收入、投资者回报、功能速度等方面的竞争需求。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">CISA 的在线表单提交存储库 (</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsoftwaresecurity.cisa.gov%2F" target="_blank">https://softwaresecurity.cisa.gov</a><span style="color:#000000">) 预计将于 2024 年 3 月下旬提供。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282896/secure-software-development-attestation-form</guid>
            <link>https://www.oschina.net/news/282896/secure-software-development-attestation-form</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[全球首位 AI 软件工程师 Devin：能自学新语言、开发迭代 App、自动 Debug]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>初创公司 Cognition 近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fcognition_labs%2Fstatus%2F1767548763134964000" target="_blank">发布公告</a></u>，宣布推出全球首个 AI 软件工程师 Devin，并号称会彻底改变人类构建软件的方式。</p><p><img height="1758" src="https://oscimg.oschina.net/oscnet/up-63fe0533116cdf85964e331427c9d8b851b.png" width="1282" referrerpolicy="no-referrer"></p><p>官方对其的描述如下：Devin 是一位不知疲倦、技术娴熟的队友，随时准备与您并肩作战，或独立完成任务供您审查。有了 Devin，工程师可以专注于更有趣的问题，工程团队可以努力实现更远大的目标。</p><p>Devin 所具备的技能如下：</p><ul><li>快速掌握新技术：只需阅读文档，Devin 就能快速掌握不熟悉的工具和框架；</li><li>开发端到端应用：构建并部署功能齐全的网络应用程序，根据用户反馈逐步增加功能；</li><li>自动化查找 BUG：Devin 擅长识别、调试和修复代码问题，同时为开源和生产级软件仓库作出贡献；</li><li>AI 培训：从研究资料库中获取指令，建立并微调大型语言模型。</li></ul><p>Devin 在 SWE-bench 编码基准测试中取得了突破性的成功，展示了其执行复杂任务的能力，甚至超越了顶尖的人类工程师。</p><p>Devin 擅长长期推理能力，可以自主规划和完成软件项目，并在此过程中做出数以千计的准确决策。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282895/cognition-labs-devin</guid>
            <link>https://www.oschina.net/news/282895/cognition-labs-devin</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Dante Cloud 3.2.3.3 发布，采用领域驱动设计 (DDD) 的微服务框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>Dante Cloud</strong> (但丁，原 Eurynome Cloud) 是一款企业级微服务架构和服务能力开发平台，是采用领域驱动模型 (DDD) 设计思想的、全面拥抱 <strong>Spring Authorization Server</strong> 的、基于 <strong>OAuth2.1</strong> 协议的、支持智能电视、IoT 等物联网设备认证的微服务架构。基于 <strong>Spring Authorization Server</strong> 1.2.2、<strong>Spring Boot</strong> 3.2.3、<strong>Spring Cloud</strong> 2023.0.0、<strong>Spring Cloud Tencent</strong> 1.13.1-2023.0.0、<strong>Spring Cloud Alibaba</strong> 2023.0.0.0、<strong>Nacos</strong> 2.3.1 等主流技术栈开发的多租户系统，遵循 <strong>SpringBoot</strong>&nbsp; 编程思想，高度模块化和可配置化。具备服务发现、配置、熔断、限流、降级、监控、多级缓存、分布式事务、工作流等功能。</p><h2>定位</h2><ul><li>构建成熟的、完善的、全面的，基于 OAuth2.1 的、前后端分离的微服务架构解决方案。</li><li>面向企业级应用和互联网应用设计开发，既兼顾传统项目的微服务化，又满足互联网应用开发建设、快速迭代的使用需求。</li><li>平台架构使用微服务领域及周边相关的各类新兴技术或主流技术进行建设，是帮助快速跨越架构技术选型、研究探索阶段的利器。</li><li>代码简洁规范、结构合理清晰，是新技术开发应用的典型的、综合性案例，助力开发人员对新兴技术的学习和掌握。</li></ul><h2>背景</h2><p><strong>这也是为什么做 Dante Cloud 的初衷</strong>：</p><ul><li>一方面是以 <strong>Dante Cloud</strong> 为载体，潜移默化地将过往项目建设的经验教训融入其中，尽可能地帮助使用者规避或者减少无效工作，提升工作效率和质量，有跟多的时间做更有意义的事情；</li><li>另一方面不断地融合和使用各类新兴技术，帮助使用者尽可能多的了解、学习和运用新技术，让技术不再成为禁锢变为进步和提升的基石。</li></ul><p><strong>这也是为什么 Dante Cloud 与其它项目不同</strong>：</p><p><strong>Dante Cloud</strong> 并不过分强调常规应用功能的堆叠与丰富化，因为作者认为纯开发工作仅占整个项目建设投入的 20%，减少开发投入、提升开发效率未必就能减少整个项目建设周期剩余 80% 工作投入。<strong>Dante Cloud</strong> 的远景目标是可以帮助使用者缩短整个项目的建设周期和减少无意义的工作投入，而不仅仅只是在开发效率方面的提升。</p><blockquote><p>Dante Cloud 一直秉承「简洁、高效、包容、务实」的理念，不会采取任何额外的手段来获取更多的 Star，绝对真实就像其产品一样。如果你认可和喜欢 Dante Cloud，请不要吝啬你的赞美，项目右上角点颗小星星。</p></blockquote><h2>代码分支说明</h2><table border="1" cellpadding="1" cellspacing="1"><tbody><tr><th><strong>分支名称</strong></th><th><strong>对应 Spring 生态版本</strong></th><th><strong>对应 JDK 版本</strong></th><th><strong>用途</strong></th><th><strong>现状</strong></th></tr></tbody><tbody><tr><td><span style="background-color:#ffffff; color:#444444">master</span></td><td><span style="background-color:#ffffff; color:#444444">Spring Boot 3.2 和 Spring Cloud 2023.0.0</span></td><td><span style="background-color:#ffffff; color:#444444">JDK 17</span></td><td><span style="background-color:#ffffff; color:#444444">主要发布分支</span></td><td><span style="background-color:#ffffff; color:#444444">可使用，但 Spring Cloud Alibaba、Tencent 等生态组件尚未发布正式版本</span></td></tr><tr><td><span style="background-color:#f8f8f8; color:#444444">develop</span></td><td><span style="background-color:#f8f8f8; color:#444444">Spring Boot 3.2 和 Spring Cloud 2023.0.0</span></td><td><span style="background-color:#f8f8f8; color:#444444">JDK 17</span></td><td><span style="background-color:#f8f8f8; color:#444444">Development 分支</span></td><td><span style="background-color:#f8f8f8; color:#444444">新功能、ISSUE 均以此分支作为开发，发布后会 PR 至 master 分支。开发分支不保证可用</span></td></tr><tr><td><span style="background-color:#ffffff; color:#444444">reactive-develop</span></td><td><span style="background-color:#ffffff; color:#444444">Spring Boot 3.2 和 Spring Cloud 2023.0.0</span></td><td><span style="background-color:#ffffff; color:#444444">JDK 21</span></td><td><span style="background-color:#ffffff; color:#444444">响应式 Development 分支</span></td><td><span style="background-color:#ffffff; color:#444444">下一代响应式微服务版本开发分支。开发分支不保证可用</span></td></tr><tr><td><span style="background-color:#f8f8f8; color:#444444">3.1.X</span></td><td><span style="background-color:#f8f8f8; color:#444444">Spring Boot 3.1 和 Spring Cloud 2022.0.X</span></td><td><span style="background-color:#f8f8f8; color:#444444">JDK 17</span></td><td><span style="background-color:#f8f8f8; color:#444444">Stable 代码分支</span></td><td><span style="background-color:#f8f8f8; color:#444444">稳定可用版本分支，2024 年 5 月，Spring Boot 3.3 发布后将会停止维护</span></td></tr><tr><td><span style="background-color:#ffffff; color:#444444">2.7.X</span></td><td><span style="background-color:#ffffff; color:#444444">Spring Boot 2.7 和 Spring Cloud 2021.0.X</span></td><td><span style="background-color:#ffffff; color:#444444">JDK 8</span></td><td><span style="background-color:#ffffff; color:#444444">历史代码分支</span></td><td><span style="background-color:#ffffff; color:#444444">基于 Spring Boot 2.7 时代开发的代码分支，不再维护</span></td></tr><tr><td><span style="background-color:#f8f8f8; color:#444444">spring-security-oauth2</span></td><td><span style="background-color:#f8f8f8; color:#444444">Spring Boot 2.6 和 Spring Cloud 2021.0.X</span></td><td><span style="background-color:#f8f8f8; color:#444444">JDK 8</span></td><td><span style="background-color:#f8f8f8; color:#444444">历史代码分支</span></td><td><span style="background-color:#f8f8f8; color:#444444">基于原 Spring Security OAuth2 实现的微服务，因相关组件均不在维护，所以该版本不再维护</span></td></tr></tbody></table><h2>[1] 软件信息</h2><ul><li>软件组成 
  <ul><li>核心组件：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-engine</a>（已上传中央库）</li><li>后端工程：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/dromara/dante-cloud</a></li><li>前端工程：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-cloud-ui</a></li></ul></li><li>软件生态 
  <ul><li>Dante&nbsp;Cloud&nbsp;Athena（Dante&nbsp;Cloud&nbsp;单体版）：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-cloud-athena</a></li><li>Dante&nbsp;OSS （像&nbsp;JPA&nbsp;一样操作&nbsp;OSS）：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-oss</a></li></ul></li><li>软件文档 
  <ul><li>官方文档：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.herodotus.cn" target="_blank">https://www.herodotus.cn</a></li><li>技术手册： 
    <ol><li>《Dante Cloud 及相关知识学习方法和学习路径的建议》</li><li>《OAuth 2 中的 Scope 与 Role 深度解析》</li><li>《Spring Boot 3 之自动配置与注入顺序控制》</li><li>《Spring Cloud 之 Session 共享及一致性处理》</li><li>《OAuth 2 中的鉴权和动态接口鉴权》</li><li>《Spring Boot 3 之 Rest 接口传参方式详解》</li><li>更多详情参见：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.herodotus.cn%2Fcookbook%2F" target="_blank">https://www.herodotus.cn/cookbook/</a></li></ol></li></ul></li></ul><h2>[2] 本次更新内容</h2><ul><li>【<strong>主要更新</strong>】 
  <ul><li>[升级] Spring Boot 版本升级至 3.2.3</li><li>[升级] Spring Boot Admin 版本升级至 3.2.2</li><li>[升级] Spring Authorization Server 版本升级至 1.2.2</li><li>[升级] Spring Cloud Alibaba 版本升级至 2023.0.0.0-RC1</li><li>[升级] Spring Cloud Tencent 版本升级至 1.13.0-2023.0.0-SNAPSHOT</li><li>[升级] Nacos 版本升级至 2.3.1</li><li>[升级] 升级 Antisamy XSS 防护策略配置文件</li></ul></li><li>其它更新 
  <ul><li>[新增] Nacos 2.3.1 SQL 脚本</li><li>[修复] 修复目前已知的所有 Spring Cloud Alibaba Sentinel 与 Spring Cloud 2023.0.0 不兼容问题和代码</li><li>[修复] 恢复所有 Spring Cloud Alibaba Sentinel 相关支持代码及配置</li><li>[修复] 修复前端设计自定义组件模块在新版本 vue 和 vite 环境下，因 Typescirpt 类型错误导致编译失败问题</li><li>[修复] 修复前端粒子效果卡顿问题</li><li>[修复] 修复前端静态路由自动校验错误</li><li>[修复] 临时修复前端 tsparticles 组件最新版本自身 ISSUE 导致前端页面打开没有响应问题</li><li>[修复] 修复伴随 Spring Boot 版本，引起的 Netty 版本升级，导致的 Spring Cloud Tencent 代码不兼容运行出错问题。</li><li>[修复] 临时修复 Spring Cloud Tencent 配置逻辑问题，导致服务启动出现 `The bean 'restTemplateCustomizer', defined in class path resource [com/tencent/cloud/polaris/loadbalancer/PolarisLoadBalancerAutoConfiguration.class], could not be registered. A bean with that name has already been defined in class path resource [org/springframework/cloud/client/loadbalancer/LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration.class] and overriding is disabled</li><li>[修复] 修复 Spring Cloud Tencent 配置错误，导致 Spring Cloud Tencent 熔断相关代码无法注入问题。</li><li>[修复] 临时修复 Spring Cloud Tencent RestTemplateCustomizer bean 冲突导致服务无法正常启动问题</li><li>[修复] 修复伴随 Spring Boot 版本，起的 Netty 版本升级，导致的 Spring Cloud Tencent 代码不兼容运行出错问题。</li><li>[修复] 修复前端提示，在 「module」 模式下无法读取 .eslintrc.js 问题</li><li>[优化] 调整 Spring Cloud Tencent 工程日志输出配置</li><li>[优化] 代码适配 Hutool 6.0.0-M11</li><li>[优化] 去除核心 Dependencies 中无用的依赖配置</li><li>[优化] 优化 Cache 相关模块代码，修改部分包名、代码以及注解的使用，符合 Spring 规范的命名和使用方式</li><li>[优化] 彻底清除系统中 facility 相关模块依赖的 bcpkix-jdk15on，解决 bcpkix 不同版本依赖冲突导致的前后端数据加密异常问题。fix: #I8XHFK</li><li>[优化] 清除为临时解决 SMS4J 启动输出错误信息的相关配置</li><li>[安全] 增加 Hutool 5.X pom 配置，修复 SMS4J 依赖 Hutool 低版本携带的 CVE 问题。</li><li>[安全] 修复 Jayway JsonPath 安全漏洞 (CVE-2023-51074) fix: #I8XWGJ</li><li>[升级] Nacos docker 镜像版本升级至 v2.3.1</li><li>[升级] minio docker 镜像版本升级至 RELEASE.2024-03-07T00-43-48Z</li></ul></li><li>【<strong>依赖更新</strong>】 
  <ul><li>[升级] JetCache 版本升级至 2.7.5</li><li>[升级] maven-gpg-plugin 版本升级至 3.2.0</li><li>[升级] redisson 版本升级至 3.27.2</li><li>[升级] springdoc 版本升级至 2.4.0</li><li>[升级] aws-java-sdk-s3 版本升级至 1.12.676</li><li>[升级] camunda-bpm-spring-boot-starter-rest 版本升级至 7.21.0-alpha4</li><li>[升级] org.json 版本升级至 20240303</li><li>[升级] git-commit-id-maven-plugin 版本升级至 8.0.1</li><li>[升级] minio 版本升级至 8.5.9</li><li>[升级] bootstrap webjars 版本升级至 5.3.3</li><li>[升级] alipay-sdk-java 版本升级至 4.38.221.ALL</li><li>[升级] fastjson2 版本升级至 2.0.47</li><li>[升级] xnio 版本升级至 3.8.13.Final</li><li>[升级] hutool 版本升级至 6.0.0-M11</li><li>[升级] okio 版本升级至 3.8.0</li><li>[升级] antisamy 版本升级至 1.7.5</li><li>[升级] zxing 版本升级至 3.5.3</li><li>[升级] influxdb-client 版本升级至 7.0.0</li><li>[升级] sqlite-jdbc 版本升级至 3.45.1.0</li><li>[升级] sms4j 版本升级至 3.1.1</li><li>[升级] vue webjars 版本升级至 3.4.15</li><li>[升级] mysql-connector-j 版本升级至 8.3.0</li></ul></li></ul><h2>[3] Dante Cloud 特性</h2><h3>1. 核心基础依赖便捷切换</h3><ul><li>新增 <code>Spring Cloud Tencent</code> 和 <code>Spring Cloud</code> 原生微服务全家桶等两种基础设施支持。</li><li>新增 <code>Spring Cloud Alibaba</code>、<code>Spring Cloud Tencent</code> 和 <code>Spring Cloud</code> 原生微服务全家桶三种基础设值切换能力，可以以相对便捷的方式切换使用 Alibaba、Tencent、Spring 等基础设施环境。可根据自身实际需求选择，不再局限于只能在某一种基础设施环境中运行。</li></ul><h3>2. <code>Spring Authorization Server</code> 全特性支持</h3><ul><li>基于 <code>Spring Authorization Server</code> 和 <code>Spring Data JPA</code> 实现多租户系统架构， 支持 Database 和 Schema 两种模式。</li><li>基于 <code>Spring Data JPA</code>，重新构建 <code>Spring Authorization Server</code> 基础数据存储代码，替代原有 JDBC 数据访问方式，破除 <code>Spring Authorization Server</code> 原有数据存储局限，扩展为更符合实际应用的方式和设计。</li><li>基于 <code>Spring Authorization Server</code>，在 OAuth 2.1 规范基础之上，增加自定义 <code>Resource Ownership Password</code> (密码) 认证模式，以兼容现有基于 OAuth 2 规范的、前后端分离的应用，支持 <code>Refresh Token</code> 的使用。</li><li>基于 <code>Spring Authorization Server</code>，在 OAuth 2.1 规范基础之上，增加自定义 <code>Social Credentials</code> (社会化登录) 认证模式，支持手机短信验证码、微信小程序、基于 <code>JustAuth</code> 的第三方应用登录， 支持 <code>Refresh Token</code> 的使用。</li><li>扩展 <code>Spring Authorization Server</code> 默认的 <code>Client Credentials</code> 模式，实现真正的使用 Scope 权限对接口进行验证。 增加客户端 Scope 的权限配置功能，并与已有的用户权限体系解耦</li><li>支持 <code>Spring Authorization Server</code><code>Authorization Code PKCE</code> 认证模式</li><li>在 <code>Spring Authorization Server</code> 的标准的 <code>JWT Token</code> 加密校验方式外，支持基于自定义证书的 <code>JWT Token</code> 加密校验方式，可通过配置动态修改。</li><li>支持 <code>Opaque Token</code> (不透明令牌) 格式及校验方式，降低 <code>JWT Token</code> 被捕获解析的风险。可通过修改配置参数，设置默认 Token 格式是采用 <code>Opaque Token</code> 格式还是 <code>JWT Token</code> 格式。</li><li>全面支持 <code>OpenID Connect</code> (OIDC) 协议，系统使用时可根据使用需求，通过前端开关配置，快速切换 OIDC 模式和传统 OAuth2 模式</li><li>深度扩展 <code>Authorization Code</code>、<code>Resource Ownership Password</code>、<code>Social Credentials</code> 几种模式，全面融合 <code>IdToken</code>、<code>Opaque Token</code>、<code>JWT Token</code> 与现有权限体系，同时提供 <code>IdToken</code> 和，自定义 Token 扩展两种无须二次请求的用户信息传递方式，减少用户信息的频繁请求。</li><li>自定义 <code>Spring Authorization Server</code> 授权码模式登录认证页面和授权确认页面，授权码模式登录采用数据加密传输。支持多种验证码类型，暂不支持行为验证码。</li><li>新增基于 <code>Spring Authorization Server</code> 的、支持智能电视、IoT 等物联网设备认证模式</li><li>无须在代码中配置 <code>Spring Security</code> 权限注解以及权限方法，即可实现接口鉴权以及权限的动态修改。采用分布式鉴权方案，规避 Gateway 统一鉴权的压力以及重复鉴权问题</li><li>OAuth2 UserDetails 核心数据支持直连数据库获取和 Feign 远程调用两种模式。OAuth2 直连数据库模式性能更优，Feign 访问远程调用可扩展性更强。可通过配置动态修改采用策略方式。</li></ul><h3>3. 全体系化应用特性集成</h3><ul><li>微服务架构全体系 Session 共享，实现 Spring Authorization Server、多实例服务、WebSocket、自定义 Session 以及大前端 Session 的统一。<code>微服务架构下的 Session 可以选择不用，但是不能没有</code>。</li><li>混合国密 <code>SM2</code> (非对称) 和 <code>SM4</code> (对称加密) 算法，实现基于数字信封技术的秘钥动态生成加密传输。利用「一人一码机制」，实现前后端数据进行动态加密传输与。Spring Authorization Server OAuth 2.1 授权模式深度融合，构建统一体系的数据传输加密。</li><li>全面整合 <code>@PreAuthorize</code> 注解权限与 <code>URL</code> 权限，通过后端动态配置，无须在代码中配置 <code>Spring Security</code> 权限注解以及权限方法，可实现接口鉴权以及权限的统一管理和动态修改</li><li>融合 Spring Cloud Stream 和 WebSocket，以优雅的方式实现 WebSocket 服务多实例环境下，点对点、广播消息跨实例推送，在线用户实时统计，完美支持 WebSocket 集群化应用。</li><li>借鉴 JPA 标准化设计思想，提取和抽象 OSS 标准化操作，形成统一的 Java OSS API 规范。封装可操作任意厂商的、统一的 REST API，构建定义统一、动态实现的应用模式（类似于 Hibernate 是 JPA 的一种实现，Hibernate 以 Dialect 方式支持不同的数据库一样），在不修改代码的情况下通过修改配置实现 OSS 的无缝切换和迁移</li><li>自研基于 <code>JetCache</code> 分布式两级缓存，完美实现 JPA Hibernate 二级缓存，支持各类查询数据缓存以及 JPA <code>@ManyToMany</code>， <code>@ManyToOne</code>等关联查询。完美解决 Spring Cache 仅使用本地缓存、创建 Key 繁琐和分页数据无法更新的问题。支持多实例服务本地缓存和远程缓存数据同步，同时支持 Mybatis Plus 二级缓存</li><li>平台统一错误处理，支持自定义错误码体系，有效集成 <code>OAuth2</code>、<code>Spring Validation</code> 等多方错误体系并有机整合 HTTP 状态码。采用 Customizer 模式，采用错误码自动计算和创建模式，支持代码模块级错误码灵活定义扩展。响应结果更加多样灵活，反馈结果也更加人性化，便于理解和定位问题。</li><li>全体系 OkHttp 、HttpClient 统一化集成，实现 OkHttp 、HttpClient 与 RestTemplate 、Openfeign 一体化融合。统一使用 Feign 配置参数，对 OkHttp 、HttpClient 进行参数设定，可策略化选择设置使用 OkHttp 或 HttpClient 作为 RestTemplate 、Openfeign 统一的基础 HttpClient</li></ul><h3>4. 采用 <code>pnpm monorepo</code> 重构前端</h3><ul><li>未使用任何流行开源模版，使用全新技术栈，完全纯"手写"全新前端工程。</li><li>借鉴参考流行开源版本的使用和设计，新版前端界面风格和操作习惯尽量与当前流行方式统一。</li><li>充份使用 Typescript 语言特性，解决大量类型校验问题，尽可能规避 "any" 式的 Typescript 编程语言使用方式。</li><li>充份使用 Composition Api 和 Hooks 等 Vue3 框架新版特性进行代码编写。</li><li>充份利用 Component、Hooks 以及 Typescript 面向对象等特性，抽取通用组件和代码，尽可能降低工程重复代码。</li><li>对较多 Quasar 基础组件和应用功能组件进行封装，以方便代码的统一修改维护和开发使用。</li><li>对生产模式下，对基于 Vite3 的工程打包进行深度性能优化。</li><li>提供以 docker-compose 方式，对工程生产代码进行容器化打包和部署。</li><li>该版本基于 pnpm，采用 monorepo 模式对前端工程进行重构。构建 monorepo 版本前端，是为扩展更多功能、增加应用级功能做铺垫</li><li>抽取 utils、components、apis、bpmn-designer 等相关代码，形成共享模块。</li><li>共享模块已进行优化配置，可编译成独立的组件，单独以组件形式进行发布。</li><li>代码以共享模块的方式进行单独维护开发，降低现有工程代码复杂度，便于后续功能的扩展和代码的复用。</li></ul><hr><p style="color:black; margin-left:0; margin-right:0; text-align:left"><strong>欢迎 Star 一波来支持我们！</strong></p><p style="color:black; margin-left:0; margin-right:0; text-align:left"><strong>Gitee</strong>：<a href="https://gitee.com/dromara/dante-cloud">https://gitee.com/dromara/dante-cloud</a><span>&nbsp;</span></p><p style="color:black; margin-left:0; margin-right:0; text-align:left"><strong>Github</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdromara%2Fdante-cloud" target="_blank">https://github.com/dromara/dante-cloud</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 06:28:18 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282891/dante-cloud-3-2-3-3-released</guid>
            <link>https://www.oschina.net/news/282891/dante-cloud-3-2-3-3-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果放宽欧盟 App Store 软件分发规则]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">苹果公司<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fnews%2F%3Fid%3D8c1m8hqt" target="_blank">宣布</a>计划放宽欧盟 App Store 的部分软件分发规则。「我们为在欧盟 (EU) 分发应用程序的开发者提供了更大的灵活性，包括引入一种直接从开发者网站分发应用程序的新方法。」</span></p><p><img height="189" src="https://oscimg.oschina.net/oscnet/up-aeff8c07ddcf1ab5d5c5b257662843ab247.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">据悉，此举将使该公司更容易遵守欧盟立法者于 2022 年通过的《数字服务法》和《数字市场法》这两部反垄断法，分别于上个月和上周生效。</span></p><p><span style="color:#000000">公告指出，已同意欧盟应用程序替代条款附录的开发者可以为其在欧盟的应用程序提供新选项：</span></p><ul><li><span style="color:#000000">备选应用市场（Alternative app marketplaces）。市场可以选择仅提供来自市场开发商的应用程序目录。</span></li><li><span style="color:#000000">Linking out to purchase。修订后的应用商店规则允许欧盟的开发者自定义指向外部网站的应用内链接。软件团队现在可以「选择如何设计促销、折扣和其他交易」。此前，应用程序仅限于使用 Apple 提供的一组界面模板，更新后这些模板将继续作为可选的开发人员资源提供。</span></li></ul><p><span style="color:#000000">预计今年春季晚些时候还将会推出 Web Distribution 功能，授权开发者可以直接通过开发者拥有的网站向欧盟用户分发 iOS 应用程序。Apple 将为授权开发者提供 API 访问权限，以方便他们通过网络发布应用程序、集成系统功能、备份和恢复用户的应用程序等。</span></p><p><span style="color:#000000">更多相关详情可查看&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fsupport%2Fweb-distribution-eu%2F" target="_blank">Getting ready for Web Distribution in&nbsp;the&nbsp;EU</a><span style="color:#1d1d1f">。</span></p><p><strong><span style="color:#1d1d1f">相关阅读：</span></strong></p><ul><li style="margin-left: 0px; margin-right: 0px; text-align: start;"><a href="https://www.oschina.net/news/276674" target="_blank">苹果在欧盟地区放开对浏览器和应用商店的限制</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 06:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282888/apple-app-store-software-distribution-rules-eu</guid>
            <link>https://www.oschina.net/news/282888/apple-app-store-software-distribution-rules-eu</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Tremor —— 模块化组件 React 库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p>Tremor 是一个快速构建仪表板的 React 库，完全开源，由数据科学家和软件工程师打造。</p></div><p><img height="1000" src="https://static.oschina.net/uploads/space/2023/0609/161343_Wiyn_4937141.png" width="3000" referrerpolicy="no-referrer"></p><h2>入门</h2><p>对于新项目，官方建议使用 Next.js 13.4+，要使用该库，还需要在项目中设置 Tailwind CSS。</p><h2>使用 NextJS</h2><p>在终端中，我们会创建一个新的 Next 项目，当提示 <code>Would you like to use Tailwind CSS with this project?</code>时，选择 <code>Yes</code>.</p><div><pre>npx create-next-app@latest my-project
cd my-project</pre></div><h3>使用 Tremor CLI 安装</h3><p>建议使用我们的 CLI 安装 Tremor。 为此，请运行此命令并选择 Next 作为你的框架。</p><div><pre>npx @tremor/cli@latest init</pre></div><p>现在你已经设置好了，就可以启动开发服务器了。</p><div><pre>npm run dev</pre></div><p>&nbsp;</p></div>
                                                                ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 03:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tremor</guid>
            <link>https://www.oschina.net/p/tremor</link>
        </item>
    </channel>
</rss>
