<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 11 Jan 2024 06:42:43 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[2024 年，Linux 内核的开发语言是否要从 C 转换为 C++]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linux 内核邮件列表中一篇<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F152261521484.30503.16131389653845029164.stgit%40warthog.procyon.org.uk%2F" target="_blank">已有六年历史的老帖</a></u>近日再次引发激烈讨论——主题是建议<strong>将 Linux 内核的开发语言从 C 转换为更现代的 C++</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-abd681f1af855365261fbf52b91d3db5752.png" referrerpolicy="no-referrer"></p><p>资深 Linux 开发者 H. Peter Anvin 昨日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F3465e0c6-f5b2-4c42-95eb-29361481f805%40zytor.com%2F" target="_blank">回复</a></u>了这封邮件，<strong>阐述了他为什么认为 C++ 用于 Linux 内核开发的时机终于成熟了。</strong></p><p>H. Peter Anvin 在邮件中提到了 C++14 和 C++20 的一些新特性，包括元编程支持、概念 (concepts) 等，这些新特性可能会使 C++ 成为更适合内核开发和嵌入式编程的编程语言。其他部分开发者也表达了对该提议的支持，他们认为现代 C++ 可能会为内核开发带来一些好处。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-04a0f9dd4092d8600c9e7b02746b2b88545.png" referrerpolicy="no-referrer"></p><p>但是，Linus Torvalds 过去曾对 C++ 持强烈反对态度，因此目前还不清楚这个讨论是否会最终促使 Linux 内核采用现代 C++。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:38:44 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275195</guid>
            <link>https://www.oschina.net/news/275195</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[京东启动鸿蒙原生应用开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">华为与京东宣布达成合作，正式启动鸿蒙原生应用开发。华为常务董事、终端业务 CEO、智能汽车解决方案 BU 董事长余承东在微博发文称：</span></p><blockquote><p><span style="color:#000000">今天我们迎来了重量级合作伙伴@京东 ，奠定了鸿蒙生态今年的又一座重要里程碑！京东将基于 HarmonyOS NEXT 的全场景无缝流转、原生智能等创新特性开发原生应用，为消费者带来简单易用、极致流畅、纯净安全、多快好省的购物体验。欢迎更多伙伴加入我们，共同打造前所未有的鸿蒙新生态，共赢万物互联时代！ </span></p></blockquote><p><img height="274" src="https://oscimg.oschina.net/oscnet/up-ab646a627a11c6fd1cb06db9553c7d9bb4e.png" width="500" referrerpolicy="no-referrer"></p><p>截至目前，国内 200 家头部应用厂商中，已有超百家启动鸿蒙原生应用开发。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:11:44 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275192</guid>
            <link>https://www.oschina.net/news/275192</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Terraform 开源分支 OpenTofu 正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">经过五十多名开发人员历时四个月的开发，Terraform 开源分支 OpenTofu 现已正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fopentofu-announces-general-availability" target="_blank">发布</a>，可供生产使用，为 Terraform 用户提供了一条直接的迁移路径。</span></p><p><span style="color:#000000">公告指出，这个版本发布的过程凸显了 OpenTofu 社区驱动的方法以及开源的价值。其中有两个例子值得注意：</span></p><ul><li><span style="color:#000000">一位社区成员提交了一份用于客户端状态加密的 RFC，自 2016 年以来一直试图将其引入 Terraform。</span></li><li><span style="color:#000000">多个关于 OpenTofu 注册表的 RFC 被提交，导致一个比原来快 10 倍且成本更低的架构。</span></li></ul><p><span style="color:#000000">OpenTofu 1.6 版本中有许多令人期待的功能，包括：</span></p><ul><li><span style="color:#000000">改进的测试功能，提升配置和模块的稳定性。</span></li><li><span style="color:#000000">增强的 S3 状态后端，引入新的身份验证方法，与兼容 S3 的存储保持兼容。</span></li><li><span style="color:#000000">全新的提供者和模块注册表，通过简单的拉取请求提供了一个简化的发布流程。</span></li><li><span style="color:#000000">数百项性能增强、错误修复和其他改进。</span></li></ul><p><span style="color:#000000">与此同时，OpenTofu 社区也在不断壮大，拥有数十名开发人员的贡献、数百名活跃的社区成员。该项目还得到了包括 CloudFlare、BuildKite、GitLab 和 Oracle 在内许多企业支持者和技术合作伙伴的支持。</span></p><p><span style="color:#000000">1.6 版本的目标是尽早发布并尽可能稳定，即将到来的 OpenTofu 1.7 则引入更多 Terraform 中没有的社区请求功能。包括但不限于：</span></p><ul><li><span style="color:#000000">客户端状态加密，通过社区协作开发，非常适合在受监管环境中提高安全性。</span></li><li><span style="color:#000000">可参数化的后端、提供者和模块，以实现更可读、DRY（don't repeat yourself）的代码。</span></li><li><span style="color:#000000">第三方可扩展性，使用插件系统来支持新的状态后端。</span></li></ul><p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fopentofu-announces-general-availability" target="_blank">查看官方公告</a>。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275191/opentofu-announces-general-availability</guid>
            <link>https://www.oschina.net/news/275191/opentofu-announces-general-availability</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Python 3.13 将引入 copy-and-patch JIT 编译器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 12 月下旬，CPython 核心开发者 Brandt Bucher 向 Python 3.13 分支提交了一个添加 JIT 编译器的 PR。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b5143d6ac9bf22233abfdde38e59442ddcb.png" referrerpolicy="no-referrer"></p><p><em>via&nbsp;<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpython%2Fcpython%2Fpull%2F113465" target="_blank">https://github.com/python/cpython/pull/113465</a></u></em></p><p>根据 PR 的描述，该 JIT 编译器采用了名为"copy-and-patch"的设计，其工作原理是将字节码编译成一组「模板」，然后在运行时使用正确的值进行拼接和修补。这意味着普通 Python 用户不需要在他们的 Python 运行时中运行复杂的 JIT 编译器架构。</p><p>copy-and-patch JIT 编译器尽可能使用 LLVM 生态的工具，比如编译器采用 Clang，编译参数设为 -o3 以获取最大的性能，二进制工具用 llvm-objdump 和 llvm-readelf。</p><p>Copy-and-Patch 技术的优点是开发者无需手写汇编代码就可以生成高效的机器码，同时在运行期产生汇编代码的方式是快速的。</p><p>相比于完整的 JIT 编译器，copy-and-patch JIT 编译器<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftonybaloney.github.io%2Fposts%2Fpython-gets-a-jit.html" target="_blank">只需要</a></u>在编译 CPython 的机器上安装 LLVM JIT 工具。这种设计的好处是它减少了额外的开销，同时提高了 Python 的性能。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275190/python-3-13-gets-a-jit</guid>
            <link>https://www.oschina.net/news/275190/python-3-13-gets-a-jit</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sermant 重磅更新，1.3.0 release 版本发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自华为云社区《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F420153%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">新特性速览！Sermant 重磅更新，1.3.0 release 版本发布</a>》，作者：华为云开源。</p><p>Sermant 社区在 12 月份正式发布了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuaweicloud%2FSermant%2Freleases%2Ftag%2Fv1.3.0" rel="nofollow" target="_blank">1.3.0 release 版本</a>，这次更新中，Sermant 新增服务治理插件：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuaweicloud%2FSermant%2Ftree%2Fdevelop%2Fsermant-plugins%2Fsermant-mq-consume-prohibition" rel="nofollow" target="_blank">消息队列禁止消费插件</a>。该插件允许在微服务运行时动态地控制消费者（如 Kafka、RocketMQ）的消费行为，实现禁止或开启消费，强化了 Sermant 的可用性治理能力。</p><p>除此之外，本次版本更新还对 Seramnt 框架存在的已知问题和部分功能进行了修复和优化。（Sermant 官网：https://sermant.io/）</p><span id="OSC_h1_1"></span><h1>一、服务治理能力提升</h1><span id="OSC_h2_2"></span><h2>1.1 动态调整消费者消费行为</h2><p>本次 Sermant 更新新增了消息队列禁止消费插件，该插件允许微服务在运行态根据实际需求动态调整消费者对消息队列中间件的消费行为，确保在非正常环境或状态下，业务处理流程中的消息得到妥善管理，避免不必要的业务影响。例如，在多云多活架构系统中，如果发生区域性故障需要对流量做切流处理，可在发生故障的可用区开启消息队列禁止消费功能，让正常可用区的消费者来处理业务，避免故障区域消费流量导致业务异常，保障系统的高可用。待故障处理完成后，可重新开启消费。</p><p><img alt="图片 1.jpg" src="https://bbs-img.huaweicloud.com/blogs/img/20240109/1704785315029887378.jpg" referrerpolicy="no-referrer"></p><p>图 1 消息队列禁止消费插件故障切流场景使用</p><p>消息队列禁止消费插件目前支持 Kafka 和 RocketMQ 两种消息中间件。在 Kafka 方面，该插件实现了 Topic 级别的禁止和恢复消费功能。对于 RocketMQ， 控制消费的粒度为消费者实例级别。关于消费队列禁止消费插件的具体介绍、配置说明和场景演示等请参考官网文档<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fplugin%2Fmq-consume-prohibition.html" rel="nofollow" target="_blank">消息队列禁止消费</a>。</p><span id="OSC_h1_3"></span><h1>二、Sermant 框架提升</h1><span id="OSC_h2_4"></span><h2>2.1 可观测性能力提升</h2><p>支持通过指令查询 Sermant 对宿主应用的增强信息，包括被增强的类和方法以及具体的 Interceptor，有助于提升 Sermant 的可观测能力。可用于开发调试场景中，判断是否对宿主类增强成功。</p><p>在 Sermant 通过任意方式启动成功后，运行官方提供的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fuser-guide%2Fsermant-agent.html" rel="nofollow" target="_blank">AgentLoader</a>，并传入参数下发查询增强信息的指令 command=CHECK_ENHANCEMENT，即可在日志中查看到 Sermant 已执行的增强信息，打印内容如下所示。具体操作请参考官网文档<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fuser-guide%2Fsermant-agent.html%23%25E5%25A2%259E%25E5%25BC%25BA%25E4%25BF%25A1%25E6%2581%25AF%25E6%259F%25A5%25E8%25AF%25A2" rel="nofollow" target="_blank">增强信息查询</a>。</p><pre>xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:42] [Attach Listener] ---------- PLUGINS ----------  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:44] [Attach Listener] test-plugin-A:1.0.0  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:44] [Attach Listener] test-plugin-B:1.0.0  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:46] [Attach Listener] ---------- ENHANCEMENT ----------  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:58] [Attach Listener] test-plugin-A:1.0.0  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:65] [Attach Listener] xxxxx.xxxx.TestClassA#testFunctionA(boolean,java.lang.String,java.lang.String,java.lang.String)@sun.misc.Launcher$AppClassLoader@5c647e05 [xxxx.xxxx.TestInterceptorA]  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:65] [Attach Listener] xxxxx.xxxx.TestClassB#testFunctionB(boolean,java.lang.String,java.lang.String,java.lang.String)@sun.misc.Launcher$AppClassLoader@5c647e05 [xxxx.xxxx.TestInterceptorB,xxxx.xxxx.TestInterceptorC]</pre><span id="OSC_h2_5"></span><h2>2.2 插件安装机制优化</h2><p>增强 Sermant Agent 插件的安装机制，支持插件重复安装。用于需要动态扩展插件字节码增强范围（类和方法）的场景，如故障注入场景中通过插件的重复安装功能可以在原有故障注入基础上再注入一个新的故障。重复安装插件的实现基于 Sermant 插件的动态安装功能，具体操作请参考官网文档<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fuser-guide%2Fsermant-agent.html%23%25E5%258A%25A8%25E6%2580%2581%25E5%25AE%2589%25E8%25A3%2585%25E6%258F%2592%25E4%25BB%25B6" rel="nofollow" target="_blank">动态安装插件</a>。</p><span id="OSC_h2_6"></span><h2>2.3 问题修复</h2><ul><li>修复个别场景下可以从插件类加载器中加载到宿主类的问题。进一步强化了 Sermant 的类隔离能力，避免与宿主服务发生类冲突问题。</li><li>修复实例化拦截器时，偶发找不到宿主类的问题。从而确保了拦截器在执行增强逻辑时能够正常操作宿主类。</li></ul><span id="OSC_h1_7"></span><h1>三、总结</h1><p>本次版本更新主要为新增消息队列禁止消费插件。基于该插件，Sermant 的服务治理能力得到进一步强化。同时本次版本更新对 Seramnt 框架存在的已知问题和部分功能进行了修复和优化，提升了 Sermant 的高可用性。</p><p>Sermant 作为专注于服务治理领域的字节码增强框架，致力于提供高性能、可扩展、易接入、功能丰富的服务治理体验，并会在每个版本中做好性能、功能、体验的看护，广泛欢迎大家的加入。</p><ul><li>Sermant 官网：https://sermant.io</li><li><div>
    GitHub 仓库地址： 
   <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuaweicloud%2FSermant" rel="nofollow" target="_blank">https://github.com/huaweicloud/Sermant</a></div></li></ul><p>&nbsp;</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>点击关注，第一时间了解华为云新鲜技术~</strong></a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10758484</guid>
            <link>https://my.oschina.net/u/4526289/blog/10758484</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Tachiyomi —— 免费开源漫画阅读器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Tachiyomi 是一款适用于 Android 6.0 及更高版本的免费开源漫画阅读器。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特点包括：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><ul><li>多种来源的在线阅读</li><li>下载内容的本地阅读</li><li>具有多个查看器、阅读方向和其他设置的可配置阅读器。</li><li>跟踪器支持：<a href="https://myanimelist.net/">MyAnimeList</a>、<a href="https://anilist.co/">AniList</a>、<a href="https://kitsu.io/">Kitsu</a>、<a href="https://mangaupdates.com/">MangaUpdates</a>、<a href="https://shikimori.one/">Shikimori</a>和<a href="https://bgm.tv/">Bangumi</a>支持</li><li>分类整理你的图书馆</li><li>浅色和深色主题</li><li>安排更新新章节的时间</li><li>在本地创建备份以离线读取或存储到你所需的云服务</li></ul><p>&nbsp;</p><p><img height="300" src="https://static.oschina.net/uploads/space/2024/0109/162825_aRoD_4252687.png" width="147" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tachiyomi</guid>
            <link>https://www.oschina.net/p/tachiyomi</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | keil MDK 编译信息增强工具 keil-build-viewer]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-keil-build-viewer-v15b" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#keil-build-viewer-v15b"></a>keil-build-viewer v1.5b</h1><h2><a id="user-content-english" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#english"></a><a href="https://gitee.com/DinoHaw/keil-build-viewer/blob/master/README_EN.md">English</a></h2><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/main.png" alt="演示界面" referrerpolicy="no-referrer"></p><h2><a id="user-content-1-介绍" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#1-%E4%BB%8B%E7%BB%8D"></a>1 介绍</h2><p>这是一个 keil 的编译信息展示增强工具，支持芯片存储器的可视化展示，轻量且无任何依赖。具备以下功能：</p><ol><li><p>解析参与编译的每个文件对 RAM 和 flash 的占用情况</p><ul><li>自动忽略不被包含进编译的文件</li><li>自动检索被 keil 改名的文件</li><li><strong>支持双击打开文件</strong></li><li>支持关闭该信息的展示</li><li>支持仅显示文件名</li></ul></li><li><p>分析芯片的 RAM 和 flash 的使用情况，使用进度条可视化展示</p><ul><li><code>■</code> 或 <code>#</code> 或 <code>X</code> 表示实际占用的区域</li><li><code>□</code> 或 <code>O</code>  表示 zero initialize 的区域</li><li><code>_</code> 表示未被使用的区域</li></ul></li><li><p>二次编译后新增与减少的数据量展示</p><ul><li>通过对比上次的编译结果，<strong>显示本次编译新增或减少的数据量大小，单位是 byte</strong></li><li>若是新增的文件，则会显示 <code>[NEW]</code></li></ul></li><li><p>自动搜索本级目录的 keil 工程，因此可无参调用</p><ul><li>默认选择搜索到的最后一个 keil 工程</li><li>支持输入绝对路径指定 keil 工程</li><li>支持仅输入文件名指定 keil 工程（必须是同级目录，可不带文件扩展名）</li><li><strong>若路径或工程名有空格，则使用 <code>""</code> 括起来</strong></li></ul></li><li><p>支持输入参数修改选项</p><ul><li>如第 4 功能所描述的，指定 keil 工程</li><li><code>-OBJ</code>     显示每个文件的 RAM 和 flash 的占用信息（默认）</li><li><code>-NOOBJ</code>   不显示每个文件的 RAM 和 flash 的占用信息</li><li><code>-PATH</code>    显示每个文件的相对路径（默认）</li><li><code>-NOPATH</code>  仅显示每个文件的文件名</li><li><code>以下为 v1.5 新增功能</code></li><li><code>-STYLE0</code>  进度条样式跟随系统（默认）</li><li><code>-STYLE1</code>  进度条样式一： <code>|###OOO____|</code> （非中文环境时默认样式）</li><li><code>-STYLE2</code>  进度条样式二： <code>|XXXOOO____|</code></li><li><strong>以上命令不区分大小写</strong></li></ul></li><li><p>显示最大的栈使用</p><ul><li>数据来自 keil ，静态无法精确分析，数据仅供参考</li></ul></li><li><p>支持放置于公共目录后，可在任意目录调用本工具，无需跟随 keil uvproj(x) 工程</p><ul><li>v1.4 新增功能</li><li><strong>必须设置好系统环境变量，并把 <code>keil-build-viewer.exe</code> 放置于系统环境变量所指定的目录中</strong>，建议使用系统环境变量 <code>Path</code></li><li>可节省拷贝 <code>keil-build-viewer.exe</code> 至对应 keil uvproj(x) 工程的步骤，但 <code>after build</code> 仍需填写，详见 <code>2 在 keil 中使用</code></li></ul></li></ol><blockquote><p><strong>说明：</strong> 本工具的所有参数可不按顺序输入，为空时表示选择默认值，但参数与参数之间需用<strong>空格</strong>隔开</p></blockquote><blockquote><p><strong>双击打开对应文件动画演示</strong><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/open_file.gif" alt="双击打开文件" referrerpolicy="no-referrer"></p></blockquote><h2><a id="user-content-2-在-keil-中使用" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#2-%E5%9C%A8-keil-%E4%B8%AD%E4%BD%BF%E7%94%A8"></a>2 在 keil 中使用</h2><ol><li><p>在 keil 中调用方式很简单，下载<a href="https://gitee.com/DinoHaw/keil-build-viewer/releases">发行版</a>中的 <code>keil-build-viewer.exe</code> 放在 keil 对应的 uvproj(x) 工程的同级目录，按下图进行配置即可。如需输入其他选项，则在 <code>keil-build-viewer.exe</code> 后跟随输入。如仅显示每个文件的文件名，则可填写：<br></p><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">keil-build-viewer.exe -NOPATH</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li><p>在 cmd 或 powershell 中使用同理，仅需添加前缀 <code>.\</code> 即可。如：<br></p><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">.\keil-build-viewer.exe</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li></ol><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/user_command.png" alt="keil 配置" referrerpolicy="no-referrer"></p><h2><a id="user-content-3-我想自己编译这个工具" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#3-%E6%88%91%E6%83%B3%E8%87%AA%E5%B7%B1%E7%BC%96%E8%AF%91%E8%BF%99%E4%B8%AA%E5%B7%A5%E5%85%B7"></a>3 我想自己编译这个工具</h2><p><strong>本代码仅支持 windows 系统</strong></p><h3><a id="user-content-31-预备操作" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#31-%E9%A2%84%E5%A4%87%E6%93%8D%E4%BD%9C"></a>3.1 预备操作</h3><ol start="0"><li><p>如果你已经安装了 gcc ，请忽略本步骤</p></li><li><p>下载 gcc 编译器，为了考虑兼容性，这里提供一个 32 位的 mingw 下载链接： <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FniXman%2Fmingw-builds-binaries%2Freleases%2Fdownload%2F13.1.0-rt_v11-rev1%2Fi686-13.1.0-release-posix-dwarf-ucrt-rt_v11-rev1.7z">i686-13.1.0-release-posix-dwarf-ucrt-rt_v11-rev1.7z</a></p></li><li><p>解压后放在任意路径，此处以 <code>C:\mingw32</code> 为例</p></li><li><p>配置好环境变量
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/path_config.png" alt="配置环境变量" referrerpolicy="no-referrer"></p></li><li><p>打开 <code>powershell</code> 或 <code>cmd</code> 输入 <code>gcc -v</code> ，出现下图内容表示配置成功
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/gcc.png" alt="gcc" referrerpolicy="no-referrer"></p></li></ol><h3><a id="user-content-32-编译" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#32-%E7%BC%96%E8%AF%91"></a>3.2 编译</h3><ol><li><p>打开 <code>powershell</code> 或 <code>cmd</code> 并定位至代码目录</p><ul><li>若使用 <code>powershell</code> ，可在代码目录空白处按住 <code>shift</code> 键同时单击鼠标右键选择打开 <code>powershell</code> ，将自动定位到代码目录</li></ul></li><li><p>执行以下 gcc 命令</p><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gcc .\keil-build-viewer.c -o .\keil-build-viewer.exe</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li><p>无任何提示信息，编译通过
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/gcc_compile.png" alt="gcc 编译通过" referrerpolicy="no-referrer"></p></li></ol><h2><a id="user-content-4-问题解答" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#4-%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94"></a>4 问题解答</h2><ol><li><p>出现 <code>[ERROR] NO keil project found</code> 之类的提示</p><blockquote><p>确认 <code>keil-build-viewer.exe</code> 放在了你需要查看的 keil uvproj(x) 工程同级目录</p></blockquote></li><li><p>出现 <code>[ERROR] listing path is empty</code> 之类的提示</p><blockquote><p>在 keil 中选择你要放置的 listing 相关文件的文件夹
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/select_listing_folder.png" alt="选择 listing 文件夹" referrerpolicy="no-referrer"></p></blockquote></li><li><p>出现 <code>[ERROR] generate map file is not checked</code> 或 <code>[ERROR] Check if a map file exists</code> 之类的提示</p><blockquote><p>确认 keil 已经勾选了下图这些选项
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/create_map.png" alt="创建 map" referrerpolicy="no-referrer"></p></blockquote></li><li><p>若编译信息缺失或与实际有偏差</p><blockquote><p>确认解析的工程为目标工程（同级目录存在多个工程时）<br>
可通过解析出的前置信息核对当前工具所解析的工程，若发现不一致，可在 <code>keil-build-viewer.exe</code> 之后指定工程名，如：</p></blockquote><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">keil-build-viewer.exe TIMER</span><span id="LC2" class="line">或</span><span id="LC3" class="line">keil-build-viewer.exe TIMER.uvprojx</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><blockquote><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/keil_project_name.png" alt="解析的工程" referrerpolicy="no-referrer"></p></blockquote></li><li><p>若工程目录或工程名有空格，将其使用 <code>""</code> 括起来</p><blockquote><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/space_example.png" alt="空格案例" referrerpolicy="no-referrer"></p></blockquote></li><li><p>其他问题请提 issues 或联系作者。</p></li></ol><h2><a id="user-content-重要说明" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#%E9%87%8D%E8%A6%81%E8%AF%B4%E6%98%8E"></a>重要说明</h2><blockquote><p><strong>1. 目前仅支持 keil MDK。</strong></p><p><strong>2. 不支持解析通过 RTE 添加的文件</strong></p></blockquote><h2><a id="user-content-修改记录" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#%E4%BF%AE%E6%94%B9%E8%AE%B0%E5%BD%95"></a>修改记录</h2><table><thead><tr><th align="center">版本</th><th align="center">日期</th><th>修改者</th><th>修改内容</th></tr></thead><tbody><tr><td align="center">v1.0</td><td align="center">2023-11-10</td><td>Dino</td><td>初版发布</td></tr><tr><td align="center">v1.1</td><td align="center">2023-11-11</td><td>Dino</td><td>1. 适配 RAM 和 ROM 的解析</td></tr><tr><td align="center">v1.2</td><td align="center">2023-11-11</td><td>Dino</td><td>1. 适配 keil4 的 map 文件<br>2. 增加检测到开启 LTO 后打印提示信息<br>3. 修复开启 LTO 后无打印 region 的问题</td></tr><tr><td align="center">v1.3</td><td align="center">2023-11-12</td><td>Dino</td><td>1. 修复工程存在多个 lib 时仅解析一个的问题</td></tr><tr><td align="center">v1.4</td><td align="center">2023-11-21</td><td>Dino</td><td>1. 增加将本工具放置于系统环境变量 Path 所含目录的功能</td></tr><tr><td align="center">v1.5</td><td align="center">2023-11-30</td><td>Dino</td><td>1. 新增更多的 progress bar 样式<br>2. 新增解析自定义的 memory area<br>3. 修复 RAM 和 ROM 信息缺失时显示异常的问题</td></tr><tr><td align="center">v1.5a</td><td align="center">2023-11-30</td><td>Dino</td><td>1. 修复 object 数据溢出的问题<br>2. 修改进度条内存大小的显示策略，不再四舍五入</td></tr><tr><td align="center">v1.5b</td><td align="center">2023-12-02</td><td>Dino</td><td>1. 修复保存文件路径内存动态分配过小的问题</td></tr></tbody></table><h2><a id="user-content-参与贡献" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#%E5%8F%82%E4%B8%8E%E8%B4%A1%E7%8C%AE"></a>参与贡献</h2><ol><li>Fork 本仓库</li><li>新建 Feat_xxx 分支</li><li>提交代码</li><li>新建 Pull Request</li></ol>]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:32:16 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/DinoHaw/keil-build-viewer</guid>
            <link>https://gitee.com/DinoHaw/keil-build-viewer</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 前端 monorepo 大仓权限设计的思考与实现]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>一、背景</h1><p style="color:#24292f; text-align:start">前端 monorepo 在试行大仓研发流程过程中，已经包含了多个业务域的应用、共享组件库、工具函数等多种静态资源，在实现包括代码共享、依赖管理的便捷性以及更好的团队协作的时候，也面临大仓代码文件权限的问题。如何让不同业务域的研发能够顺畅的在大仓模式下开发，离不开有效的权限管理方法。好的权限管理方法能够确保研发同学轻松找到和理解项目的不同部分，而不受混乱或不必要的复杂性的影响，并且也应该允许研发同学合作并同时工作，同时也要确保代码合并的更改经过代码审查，以维护代码的质量和稳定性。本文通过实践过程中遇到的一些问题以及逐步沉淀下来的最佳实践，来阐述下前端大仓 monorepo 在权限这块是如何思考以及设计的。</p><span id="OSC_h1_2"></span><h1>二、前期调研</h1><p style="color:#24292f; text-align:start">在做大仓权限设计的时候，前期做了很多的调研，也参考了国内和国外的一些技术文章，总结起来主要是基于以下三点的设计思路去实现：</p><ul><li><strong>文件系统的自研，能够做到文件读写权限的完全控制</strong>：对于文件系统的自研，国外的最佳实践不外乎是 Google 和 Meta，他们都是大仓实践的典范。对于文件系统的权限控制，有一套自研的文件系统，能够对核心代码和配置文件做到读写权限控制。在 Google 发表的一篇论文《Why Google stores billions of lines of code in a single repository》中也有提到：</li></ul><blockquote><p>Since Google’s source code is one of the company’s most important assets, security features are a key consideration in Piper’s design. Piper supports file-level access control lists. Most of the repository is visible to all Piper users;d however, important configuration files or files including businesscritical algorithms can be more tightly controlled. In addition, read and write access to files in Piper is logged. If sensitive data is accidentally committed to Piper, the file in question can be purged. The read logs allow administrators to determine if anyone accessed the problematic file before it was removed.</p></blockquote><p style="color:#24292f; text-align:start">大致的意思是 Google 内部自研了 Piper，能够支持基于文件级别的访问控制列表，大多数仓库对所有 Piper 用户可见，但是重要的配置文件或包含业务关键算法的文件可以进行更严格的控制，并且对 Piper 中的文件的读写访问都会被记录。</p><ul><li><p><strong>基于 Git 提供的钩子函数，能做到文件写权限的控制</strong>：Git 本身是一个分布式文件系统，其提供了代码研发流程中的各种钩子函数，在不同的钩子函数里面对文件的修改做校验，可以做到代码文件写权限的控制，但是做不到代码文件的读权限控制；</p></li><li><p><strong>基于 Gitlab 的能力，对文件目录权限做控制</strong>：<strong>Gitlab</strong><span>&nbsp;</span>开始引入了「<strong>Protected Environments</strong>」的概念，即<strong>允许为具体的文件或目录设置权限</strong>，并指定哪些用户或用户组拥有文件的「Maintainer」权限，以便管理文件的更改和合并请求，可以<strong>用于更细粒度的文件级别权限控制</strong>。当然此种方法也只能做到代码文件写权限的控制，做不到代码文件的读权限控制。</p></li></ul><p style="color:#24292f; text-align:start">从上面的三种调研实现来看，如果要完全做到文件系统的读写权限控制，势必需要自研一套适合研发流程及业务体系的文件系统，这种实现成本会很大，且基于实际的应用场景去考虑，也不是很有必要。所以<strong>本文主要围绕基于 Git 提供的钩子函数和基于 Gitlab 的能力来阐述过程中是如何实践的。</strong></p><span id="OSC_h1_3"></span><h1>三、设计实现</h1><p style="color:#24292f; text-align:start">在前端 monorepo 实践过程中，对于权限模块的设计如果考虑不好的话，会带来很不好的研发体验，同时权限的实现不仅仅是代码逻辑层面，需要考虑很多方面。在实践过程中，具体考虑了分支模型的定义、角色权限的分配、文件目录权限以及研发流程的权限控制四个方面。</p><span id="OSC_h2_4"></span><h2>分支模型的定义</h2><p style="color:#24292f; text-align:start">分支模型的定义即不同业务域在大仓下文件目录的定义，<strong>清晰的目录结构和文件命名规范是非常重要的</strong>，研发可以很快速的检索到所需的文件。前端大仓的分支模型定义如下：<img alt="45.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/45.png" referrerpolicy="no-referrer"></p><ul><li><p><strong>Apps</strong>：各业务域的目录结</p><ul><li><strong>_Share</strong>：业务域下通用依赖目录</li><li><strong>Abroad-Crm-Micro</strong>：具体应用名</li><li><strong>...</strong>：<strong>后续新增的应用都在业务域目录下</strong></li><li><strong>Components</strong>：业务域下通用组件目录（初始化固定目录）</li><li><strong>...</strong>：可以自定义扩展目录</li><li><strong>Global</strong>：国际业务域应用目录</li><li><strong>...：后续新增的业务域目录都在 App 目录下</strong></li></ul></li><li><p><strong>Packages</strong>：前端平台通用组件、工具函数、配置文件、Hooks 依赖</p><ul><li>Components：平台通用组件目录（初始化固定目录）</li><li>Hooks：平台通用 Hooks 目录（初始化固定目录）</li><li><strong>...：可以自定义扩展目录</strong></li></ul></li></ul><p style="color:#24292f; text-align:start">通过使用语义化的文件和目录命名，减少了混淆和错误，使得分支模型的定义更加的清晰，研发成员也可以很清楚的知道自己所关注的业务应用在哪个目录下，同时如果需要看其他业务域的代码，也很容易检索到。</p><blockquote><p>上面只是大仓 B 端应用的分支模型定义，目前融合了 C 端 H5 应用以及 Node 服务应用之后，大仓目录的划分会相对比较复杂的多，这里不再具体赘述。</p></blockquote><span id="OSC_h2_5"></span><h2>角色权限的分配</h2><p style="color:#24292f; text-align:start">在大仓模式下，角色权限没有另辟蹊径，还是沿用 Gitlab 已有的权限配置：Owner、Maintainer 和 Developer。<img alt="43.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/43.png" referrerpolicy="no-referrer"></p><ul><li><p><strong>Owner</strong>：即<strong>代码仓库的所有者</strong>，所有者是拥有最高权限的角色，可以对项目进行完全控制。他们可以添加和删除项目成员，修改项目设置，包括访问级别、分支保护规则和集成设置等。只有项目的所有者才能转让或删除项目；<strong>权限配置角色为 TL</strong>。</p></li><li><p><strong>Maintainer</strong>：即<strong>代码仓库的维护者</strong>，可以管理项目的代码、问题、合并请求等。可以创建和管理分支，添加和删除文件，创建和关闭问题，合并和推送分支等。维护者不能更改项目的访问级别或添加新的维护者；<strong>权限配置角色为 TL/PM</strong>。</p></li><li><p><strong>Developer</strong>：即<strong>代码仓库的开发者</strong>，是项目的一般成员，具有对代码进行修改和提交的权限。他们可以创建和分配问题、合并请求，查看代码、提交变更以及推送和拉取分支等。<strong>权限配置角色为研发人员</strong>。</p></li></ul><p style="color:#24292f; text-align:start">这里需要考虑的是只要开发者具备 Developer 权限，那么他就可以修改大仓任何目录下的代码，并且本地可以提交，这样会导致本地源码依赖出现很大的风险：<strong>会出现本地代码构建和生产环境构建不一致的情况，在研发流程意识不强的情况下很容易引发线上问题。</strong><span>&nbsp;</span>本着对代码共享的原则，对于代码文件读权限不做控制，也允许研发修改代码，但是对修改的代码的发布会做流程上的强管控。这里就会涉及到 Gitlab 的分支保护机制以及文件 Owner 权限配置。</p><span id="OSC_h2_6"></span><h2>文件目录权限配置</h2><p style="color:#24292f; text-align:start">在 GitLab 未支持文件目录权限设置之前，对于文件目录权限的控制主要依赖 Git 的钩子函数，在代码提交的时候，对暂存区的变更文件进行识别并做文件权限校验，流程设计也不怎么复杂，只需要额外再开发文件目录和研发的权限映射配置平台即可。在 GitLab 开始支持文件目录权限设置，可以用于更细粒度的文件级别的权限控制，内部就支持文件目录和研发的权限映射关系，其配置页面如下：<img alt="42.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/42.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>当有对应的文件或者目录路径下的文件变更的时候，在 CodeReview 过程中必须由对应的 Owner 成员确认无误之后，才可以 MR 代码。</strong><span>&nbsp;</span>比如：</p><ul><li><p>.husky/ 表示 .husky 目录下的文件变更，必须由<strong>具体的文件 Owner</strong>评审通过才可以 MR；</p></li><li><p>Apps/XXX/crm/ 表示 Apps/XXX/crm 目录下的文件变更，必须由<strong>对应的文件 Owner</strong><span>&nbsp;</span>其中之一审批通过才可以 MR。</p></li></ul><p style="color:#24292f; text-align:start">通过 GitLab 提供的文件目录权限配置，<strong>即使研发可以修改任意目录下的文件代码，但是最终在 CodeReview 的流程中，需要对应的文件 Owner 进行确认评审</strong>，这样就避免了研发在不注意的情况下，提交了原本不该变更的文件的代码，同时也避免了线上问题的发生。</p><span id="OSC_h2_7"></span><h2>研发流程的权限控制</h2><p style="color:#24292f; text-align:start">前面提到的分支模型的定义、角色权限的分配以及文件目录权限的配置都是需要约定俗成的，但是在真实的研发过程中，需要考虑的场景会复杂的多。比如研发可以绕开 MR 的流程，直接本地合并代码到发布分支。对于这类场景，对大仓下的分支做了规范约束以及 MR&amp;CodeReview 流程中的强管控。</p><span id="OSC_h3_8"></span><h3>保护分支</h3><p style="color:#24292f; text-align:start">在大仓研发模式下，主要有四类分支，其命名规范如下：</p><ul><li><strong>Dev 分支命名规范</strong>：feature-[应用标识]-版本号-自定义</li><li><strong>测试分支命名规范</strong>：test-[应用标识]-版本号</li><li><strong>发布分支命名规范</strong>：release-[应用标识]-版本号</li><li><strong>热修复分支命名规范</strong>：hotfix-[应用标识]-版本号</li></ul><p style="color:#24292f; text-align:start">其中 Feature 分支为开发分支，由 Developer 创建和维护；<strong>Release 和 Hotfix 分支为保护分支</strong>，Developer 和 Maintainer 都可以创建，但是 Developer 角色没有权限直接将 Feature 分支合入 Release 或者 Hotfix 分支，只能由 Maintainer 角色来维护。基于目前不同业务域会经常创建 test 分支用于不同测试环境的部署，这里 test 分支并未设置为保护分支。当然 Matser 分支也是保护分支，只有 Owner 角色才有权限直接将分支代码合并到主干分支。</p><p style="color:#24292f; text-align:start">通过对不同类型的分支的定义，基于 GitLab 提供的保护分支能力，避免了研发本地合并代码的情况，使得 Feature 分支的代码必须走研发流程的 MR&amp;CodeReview 流程，才能最终合入代码。</p><span id="OSC_h3_9"></span><h3>钩子函数</h3><p style="color:#24292f; text-align:start">通过保护分支的约束，避免了本地直接合发布分支带来的风险，但是在本地代码提交的过程中，如果不做权限的校验，就会<strong>在 CodeReview 流程中出现文件 Owner 权限不足的情况，为了在代码提交阶段就能识别到非变更文件的提交</strong>，这里基于 Git 的钩子函数，做了权限校验，其流程如下：<img alt="41.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/41.png" referrerpolicy="no-referrer"></p><blockquote><p>通过 Git Hooks 提供的 Pre-Commit 和 Pre-Push 两个节点做权限校验，防止出错。Pre-Commit 不是必须的，如果影响代码提交的效率，可以跳过这个步骤，Pre-Push 是必须的，不允许非 Owner 做本地发布。</p></blockquote><p style="color:#24292f; text-align:start"><strong>当然这里也会带来一个问题</strong>：当迭代的 Release 分支落后于 Master 分支，此时基于 Master 分支创建的 Feature 分支就会和 Release 分支代码不一致，导致出现很多非必要的变更文件，此时研发会很疑惑为什么会出现没有修改过的变更文件。这个问题在大仓研发模式下是无法避免的，通过分析之后，在本地提交阶段，过滤了 Apps 目录的校验，只保留了大仓顶层部分核心文件的权限校验，因为大部分的变更都在业务域下的应用里面，顶层的文件很少会去修改。</p><span id="OSC_h3_10"></span><h3>MR&amp;CodeReview</h3><p style="color:#24292f; text-align:start">通过保护分支的约束以及钩子函数对部分核心文件的校验，减少了很多在 MR&amp;CodeReview 中本该遇到的问题。<strong>基于文件 Owner 权限的 MR 和 CodeReview 流程</strong>：Commit 阶段 -&gt; Push 阶段 -&gt; 创建 MR -&gt; CodeReview -&gt; 执行 MR，每个阶段的流程如下：<img alt="65.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/65.png" referrerpolicy="no-referrer"></p><ul><li><p>Commit 阶段通过对核心文件的 Owner 校验，避免核心文件被乱改的情况；</p></li><li><p>CodeReview 阶段通过文件 Owner 权限的校验，确保非本身业务域被修改之后被其他业务域的 Owner 知悉。</p></li></ul><p style="color:#24292f; text-align:start"><img alt="66.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/66.png" referrerpolicy="no-referrer"><img alt="67.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/67.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>这里会带来一个问题</strong>：当 Release 分支回合 Master 代码的时候，会创建临时 MR，这个过程也会有文件 Owner 权限的校验（比如客服同学同步代码的时候，也会将商家和供应链的代码一起同步过来），就需要其他业务域的文件 Owner CR 通过才行，但 Master 的代码实际已经是 CR 过的，没有必要重复 CR，并且同步频繁的时候，会经常 CR 确认，导致回合代码的效率非常低。<strong>这里给效率技术那边提了需求，在 Release 分支回合 Master 代码的时候，不做文件 Owner 的校验。</strong></p><p style="color:#24292f; text-align:start">通过上面对研发流程中的权限控制，避免了出现本地代码构建和生产环境构建不一致的情况，确保了提交代码的质量和稳定性。</p><span id="OSC_h1_11"></span><h1>四、扩展思路</h1><p style="color:#24292f; text-align:start">通过以上的设计实现，基本上大仓下的权限设计能满足现有的研发模式了。<strong>为了弥补文件读权限控制的缺陷，过程中，也考虑了访问控制列表以及文件访问日志的实现</strong>，但是最终觉得不是很有必要，就没有在大仓里面应用起来。这里可以分享下访问控制列表以及文件访问日志实现的几种思路。</p><span id="OSC_h2_12"></span><h2>访问控制列表</h2><p style="color:#24292f; text-align:start">访问控制列表即<strong>大仓下对文件目录的访问控制，以便更精确地控制对敏感信息或关键代码的访问</strong>。之前有提到 Google 和 Meta 都是通过自研的文件系统实现，但是如果不是自研，是不是就一定实现不了了呢，其实未必见得。</p><span id="OSC_h3_13"></span><h3>VSCode 设置文件隐藏</h3><p style="color:#24292f; text-align:start">通过在大仓目录下的 .vscode/settings.json 文件配置 files.exclude 属性可以实现文件的显隐，如下：</p><pre><code>{
  "files.exclude": {
    "**/scripts": true
  }
}
</code></pre><p style="color:#24292f; text-align:start">上面的配置表示大仓目录下的 scripts 目录是不可见的。</p><p style="color:#24292f; text-align:start"><strong>存在的问题</strong>： 如果懂 .vscode/settings.json 配置的研发，可以直接本地将 True 改为 False，这里配置就失效了。还有并不是所有研发都是用的 VSCode IDE，还有不少研发用其他的 IDE，每个人的研发习惯不一样，很难做到强约束。</p><span id="OSC_h3_14"></span><h3>MAC 下隐藏文件</h3><p style="color:#24292f; text-align:start">MAC 下可以通过 shell 命令设置文件的显隐，如下：</p><pre><code>chflags hidden **/scripts
</code></pre><p style="color:#24292f; text-align:start">上面的 shell 命令表示隐藏大仓下的 scripts 目录。结合大仓研发模式下提供的代码按需拉取能力，可以在代码拉取的最后环节执行如上的命令，就可以隐藏对应的文件。</p><p style="color:#24292f; text-align:start"><strong>存在的问题</strong>：如果懂 MAC 下文件显隐的设置，可以在 shell 终端上执行 chflags nohidden **/scripts ，这样 scripts 就会变为可见了，达不到最终的效果。</p><p style="color:#24292f; text-align:start">对于访问权限列表的控制，实际上是可以通过一些其他的方式实现，但其实现思路基本都是治根不治本，起不了多大的作用，所以最后都没有在大仓的研发流程里面体现。</p><span id="OSC_h2_15"></span><h2>文件访问日志</h2><p style="color:#24292f; text-align:start">文件访问日志即当研发打开文件的时候，发送一条日志到服务端并保存下来，这样<strong>可以对包含敏感信息的配置文件进行监听， 设置审计日志和监控，以便跟踪谁做了什么操作，并在出现异常情况时能够快速识别和应对问题</strong>。通过 VSCode 插件是可以实现的，VSCode 启动之后，提供了对应文件目录路径的打开事件 onDidOpenTextDocument，当研发打开任何文件的时候，都可以触发监听事件，那么我们就能在监听事件里面去做日志发送相关的逻辑，实现文件访问日志记录的功能，大致的实现如下：</p><pre><code>export function monitorPermissionOfTargetFile(targetFilePath: string, repoRootPath: string) {
  const targetFileFullPath = repoRootPath + targetFilePath;
  // 打开项目目录下任意文件的回调函数
  vscode.workspace.onDidOpenTextDocument(textDocument =&gt; {
    // 获取被打开的文件路径
    const filePath = textDocument.uri.fsPath;
    if (filePath === targetFileFullPath) {
      // 添加日志发送逻辑
    }
  });
}
</code></pre><p style="color:#24292f; text-align:start"><strong>存在的问题</strong>：该功能强依赖 VSCode IDE，只有在 VSCode 里面才能实现，并非所有的研发都在用 VSCode，并且实时监听文件的点击事件也会带来一定的系统开销成本。现在本来打开多个 VSCode IDE，电脑运行就比较慢了，再加上该功能，性能损耗估计会更多。</p><p style="color:#24292f; text-align:start">上面只是提供了大仓权限实践过程中未落地的两个扩展思路，如果还有其他更好的思路能实现文件的读权限控制，欢迎随时沟通交流。</p><span id="OSC_h1_16"></span><h1>五、总结</h1><p style="color:#24292f; text-align:start">前端 monorepo 大仓的权限设计在实现的过程中，遇到了很多的问题，有些时候想的很好，但是实际在研发流程中会因不同的业务域场景存在不一样的问题。比如基于 Master 新建 Feature 分支还是基于 Release 新建 Feature 分支这个问题就尤其突出，起初基于 Master 新建的 Feature 分支，带来的问题是研发在合 Release 分支的时候，有很多非变更文件，导致 CR 都不清楚具体要看哪些文件；然后改成基于 Release 新建的 Feature 分支，带来的问题是会遗漏部分已发版的 Release 分支代码；最后综合考虑还是基于 Master 新建的 Feature 分支。大仓的权限设计也离不开参与研发流程改造的小伙伴以及效能技术的小伙伴，过程中为了适配大仓的权限，做了很多研发流程的改造以及 GitLab 能力的扩展，希望本文能给读者带来一定的帮助。</p><p style="color:#24292f; text-align:start">*<strong>文/Bill</strong></p><p>本文属得物技术原创，更多精彩文章请看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com" rel="nofollow" target="_blank">得物技术官网</a></p><p>未经得物技术许可严禁转载，否则依法追究法律责任！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10750685</guid>
            <link>https://my.oschina.net/u/5783135/blog/10750685</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[为庆祝 OpenWrt 20 周年，官方计划推出 OpenWrt One 路由器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.openwrt.org%2Fpipermail%2Fopenwrt-devel%2F2024-January%2F042018.html" target="_blank">根据 OpenWrt 开发者邮件列表的消息</a></u>，项目贡献者 John Crispin 写道：「OpenWrt 项目即将诞生 20 周年！让我们通过推出<strong>首个完全由上游支持的硬件设计</strong>来庆祝这一周年纪念日。」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-23721defa7c51a2c98299066aecb3478c6e.png" referrerpolicy="no-referrer"></p></blockquote><p>这款路由器将被命名为"<strong>OpenWrt One/AP-24.XY</strong>"，硬件规格暂定如下：</p><ul><li><p>SoC：联发科 MT7981B</p></li><li><p>Wi-Fi：联发科 MT7976C（2x2 2.4 GHz + 3x3/2x2 + 零等待 DFS 5Ghz）</p></li><li><p>内存：1 GiB DDR4</p></li><li><p>闪存： 128 MB SPI NAND+ 4 MB SPI NOR</p></li><li><p>以太网：2.5 GbE + 1 GbE</p></li><li><p>USB（主机）： USB 2.0-A</p></li><li><p>USB（设备、主机）： Holtek HT42B534-2 UART 至 USB-C</p></li><li><p>存储：M.2 2042（PCIe Gen 2 x1）NVMe SSD</p></li><li><p>按钮：2 个（复位 + 用户）</p></li><li><p>机械开关：1 个，用于启动选择（恢复、常规）</p></li><li><p>LED 指示灯：2 个（PWM 驱动），2 个 ETH 指示灯（GPIO 驱动）</p></li><li><p>外部安全硬件： EM Microelectronic EM6324（GPIO 驱动）</p></li><li><p>RTC：NXP PCF8563TS（I2C），带备用电池座（CR1220）</p></li><li><p>电源： USB-C 的 USB-PD-12V （通过 RT5040 模块可选 802.3at / afPoE）。</p></li><li><p>扩展：mikroBUS</p></li><li><p>认证： 符合 FCC / EC / RoHS 标准</p></li><li><p>外壳： PCB 尺寸与 BPi-R4 兼容，外壳采用可再生材料</p></li><li><p>主 SOC 的 JTAG：10 针 1.27 mm 间距（ARM JTAG / SWD）</p></li><li><p>天线连接器： 3x MMCX</p></li><li><p>原理图：将公开（许可证待定）</p></li><li><p>符合 GPL 规范： 3b.</p></li><li><p>价格目标：力争低于 100 美元</p></li></ul><p>John Crispin 表示，早在 2017 年和 2018 年的 OpenWrt 峰会上，他们就首次提到要推出 OpenWrt 路由器。从 2023 年 12 月开始，他们在修复 Banana Pi 设备遇到的 bug 时就清楚地意识到，该设备已经非常接近他们想要在 17/18 年实现的目标。</p><p><span>Banana PI 在社区中越来越受欢迎。它们使用自编译的可信固件-A (TF-A) 和上游 U-Boot&nbsp; 启动，并且某些主板已经得到上游 Linux 内核的完全支持。唯一的非开源组件是在独立内核上运行的 2.5 GbE PHY 和 Wi-Fi 固件 blob，这些内核独立于运行 Linux 的主 SoC 以及在启动早期执行的 DRAM 校准例程。</span></p><p>&nbsp;</p><blockquote><p><em>OpenWrt 项目是一个针对嵌入式设备的 Linux 操作系统。OpenWrt 不是一个单一且不可更改的固件，而是提供了具有软件包管理功能的完全可写的文件系统。这使您可以从供应商提供的应用范围和配置中解脱出来，并且让您通过使用适配任何应用的软件包来定制设备。对于开发人员来说，OpenWrt 是一个无需围绕它构建完整固件就能开发应用程序的框架; 对于普通用户来说，这意味着拥有了完全定制的能力，能以意想不到的方式使用该设备。</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-06cc39c3d21dfb9b7ca4e8e7a72b3cabb1a.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275179/openwrt-one-for-20-yr</guid>
            <link>https://www.oschina.net/news/275179/openwrt-one-for-20-yr</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GPT Store 正式上线]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fintroducing-the-gpt-store" target="_blank">官宣</a> GPTs 应用商店 (GPT Store) 正式上线，面向 ChatGPT Plus、团队和企业用户推出。感兴趣的用户可访问 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fchat.openai.com%2Fgpts" target="_blank">chat.openai.com/gpts</a> 进行探索。</p><p><img height="359" src="https://static.oschina.net/uploads/space/2024/0111/102327_6mDd_4252687.jpg" width="300" referrerpolicy="no-referrer"></p><p>公告指出，自 GPT 发布两个月以来 ，已有用户已经创建了超过 300 万个 ChatGPT 自定义版本。GPT Store 涵盖了由 OpenAI 的合作伙伴和社区开发的各种 GPT，大家可以从中搜寻最适合自己的。</p><p>该公司计划每周在商店内重点展示有用的 GPT，首批推出的一些 GPT 包括：</p><ul><li>AllTrails： 提供个性化徒步路线推荐；</li><li>Consensus： 能够搜索和综合 200M 学术论文的结果；</li><li>Code Tutor： 通过可汗学院的编程导师扩展你的编码技能；</li><li>Canva： 帮你设计演示文稿或社交帖子；</li><li>Books： 帮你查找你的下一本读物；</li><li>CK-12 Flexi AI 导师：随时随地学习数学和科学；</li></ul><p>值得一提的是，商店的收入分成部分还没有启动，因此第三方 GPT 构建者可能还需要再等一段时间才能从他们的定制 GPT 中获得报酬。OpenAI 计划在今年第一季度启动 GPT 构建者收入计划，GPT 构建者将根据用户与聊天机器人的互动程度获得报酬，但该公司尚未分享实际情况的具体细节。</p><p>GPT Store 最初由 OpenAI 首席执行官 Sam Altman 在 2023 年 11 月份的 OpenAI 开发者大会上首次展示。后来计划于 12 月推出，但最终推到了了 1 月份。OpenAI 方面表示，在 GPT Store 开放之前，它已经建立了一个新的审查系统，以确保定制的 GPT 符合其品牌准则和使用政策；还更新了如何报告用户发现有害或不安全的 GPT。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:16:16 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275178/gpt-store-launch</guid>
            <link>https://www.oschina.net/news/275178/gpt-store-launch</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ToolLearning Eval：CodeFuse 发布首个中文 Function Call 的大语言模型评测基准]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><h2><img alt="hjdfsbg.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878404965-d1c416d5-59da-4867-bcbf-ed5f2f607f42.png?x-oss-process=image%2Fresize%2Cw_900%2Climit_0" width="900" referrerpolicy="no-referrer"></h2><span id="OSC_h2_1"></span><h2><span>1.<span>&nbsp;</span></span><span style="color:#000000">背景</span></h2><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">随着 ChatGPT 等通用大模型的出现，它们可以生成令人惊叹的自然语言，使得机器能够更好地理解和回应人类的需求，但在特定领域的任务上仅靠通用问答是无法满足日常工作需要。随着 OpenAI 推出了 Function Call 功能，工具学习能力越来越作为开源模型的标配，目前业界较有影响力的是 ToolBench 的英文数据集。但是中文数据集的稀缺，使得我们很难判断各个模型在中文型工具上 Function Call 的能力差异。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">为弥补这一不足，CodeFuse 发布了首个面向 ToolLearning 领域的中文评测基准 ToolLearning-Eval，以帮助开发者跟踪 ToolLearning 领域大模型的进展，并了解各个 ToolLearning 领域大模型的优势与不足。ToolLearning-Eval 按照 Function Call 流程进行划分，包含工具选择、工具调用、工具执行结果总结这三个过程，方便通用模型可以对各个过程进行评测分析。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">目前，我们已发布了第一期的评测榜单，首批评测大模型包含 CodeFuse、Qwen、Baichuan、Internlm、CodeLLaMa 等开源大语言模型；我们欢迎相关从业者一起来共建 ToolLearning Eval 项目，持续丰富 ToolLearning 领域评测题目或大模型，我们也会定期更新评测集和评测榜单。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#000000">GitHub 地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval" target="_blank" rel="nofollow"><span style="color:#000000">https://github.com/codefuse-ai/codefuse-devops-eval</span></a></p><p style="margin-left:0; margin-right:0"><span style="color:#000000">ModelScope 地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fdatasets%2Fcodefuse-ai%2Fdevopseval-exam%2Fsummary" target="_blank" rel="nofollow"><span style="color:#000000">https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/summary</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_2"></span><h2><span>2.<span>&nbsp;</span></span><span style="color:#000000">评测数据</span></h2><span id="OSC_h3_3"></span><h3><span>2.1.<span>&nbsp;</span></span><span style="color:#000000">数据来源</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">ToolLearning-Eval 最终生成的样本格式都为 Function Call 标准格式，采用此类格式的原因是与业界数据统一，不但能够提高样本收集效率，也方便进行其它自动化评测。经过统计，该项目的数据来源可以分为 3 类：</span></p><ol><li><span style="color:#000000">开源数据：对开源的 ToolBench 原始英文数据进行清洗；</span></li><li><span style="color:#000000">英译中：选取高质量的 ToolBench 数据，并翻译为中文；</span></li><li><span style="color:#000000">大模型生成：采用 Self-Instruct 方法构建了中文 Function Call 训练数据&amp;评测集；</span></li></ol><p style="margin-left:0; margin-right:0"><span style="color:#000000">我们希望越来越多的团队能参与到中文的 functioncall 数据构建，共同优化模型调用工具的能力。我们也会不断地强化这部分开源的数据集。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_4"></span><h3><span>2.2.<span>&nbsp;</span></span><span style="color:#000000">数据类别</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">ToolLearning-Eval 里面包含了两份评测集，fcdata-zh-luban 和 fcdata-zh-codefuse。里面总共包含 239 种工具类别，涵盖了 59 个领域，包含了 1509 条评测数据。ToolLearning-Eval 的具体数据分布可见下图</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/238517/1701934951404-984f915c-550e-4da6-93c0-3bcc70efe66d.png" width="793" referrerpolicy="no-referrer"></p><span id="OSC_h3_5"></span><h3><span>2.3.<span>&nbsp;</span></span><span style="color:#000000">数据样例</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">在数据上我们完全兼容了 OpenAI Function Calling，具体格式如下：</span></p><p style="margin-left:0; margin-right:0"><strong><span>Function Call 的数据格式</span></strong></p><p style="margin-left:0; margin-right:0"><img alt="截屏 2024-01-10 15.00.51.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878469274-e7c2e86e-d595-4095-b7e5-cb4b0c12b2fb.png" width="1516" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong><span>chatrounds 的数据格式</span></strong></p><p style="margin-left:0; margin-right:0"><img alt="截屏 2024-01-10 15.00.19.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878469290-acf7e74e-449a-4244-b911-0cf2273b7aff.png" width="1516" referrerpolicy="no-referrer"></p><pre><code>{
    "functions":
    [
        {
            "name": "get_fudan_university_scoreline",
            "description": "查询复旦大学往年分数线，例如：查询 2020 年复旦大学的分数线",
            "parameters":
            {
                "type": "object",
                "properties":
                {
                    "year":
                    {
                        "type": "string",
                        "description": "年份，例如：2020，2019，2018"
                    }
                },
                "required":
                [
                    "year"
                ]
            }
        }
    ],
    "chatrounds":
    [
        {
            "role": "system",
            "content": "CodeFuse 是一个面向研发领域的智能助手，旨在中立的、无害的帮助用户解决开发相关的问题，所有的回答均使用 Markdown 格式返回。\n 你能利用许多工具和功能来完成给定的任务，在每一步中，你需要分析当前状态，并通过执行函数调用来确定下一步的行动方向。你可以进行多次尝试。如果你计划连续尝试不同的条件，请每次尝试一种条件。若给定了 Finish 函数,则以 Finish 调用结束，若没提供 Finish 函数，则以不带 function_call 的对话结束。"
        },
        {
            "role": "user",
            "content": "查询 2020 年复旦大学的分数线"
        },
        {
            "role": "assistant",
            "content": null,
            "function_call":
            {
                "name": "get_fudan_university_scoreline",
                "arguments": "{\n  \"year\": \"2020\"\n}"
            }
        },
        {
            "role": "function",
            "name": "get_fudan_university_scoreline",
            "content": "{\n    \"scoreline\":{\n        \"文科一批\": 630,    \n        \"文科二批\": 610,  \n        \"理科一批\": 650,  \n        \"理科二批\": 630  \n    }\n}"
        },
        {
            "role": "assistant",
            "content": "2020 年复旦大学的分数线如下：\n\n- 文科一批：630 分\n- 文科二批：610 分\n- 理科一批：650 分\n- 理科二批：630 分"
        }
    ]
}</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#000000">上述 Function Call 的数据样例为给定特定工具集后，用于回答用户查询某高校录取分数线的问题。此外限于篇幅，此处不再其它工具使用样例，具体可以查看 HuggingFace 数据集。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_6"></span><h3><span>2.4.<span>&nbsp;</span></span><span style="color:#000000">数据下载</span></h3><ul><li><span style="color:#000000">方法一： 直接下载（用浏览器打开下面的链接）</span></li></ul><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fdatasets%2Fcodefuse-ai%2Fdevopseval-exam%2Ffiles" target="_blank" rel="nofollow"><span style="color:#000000">https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/files</span></a></p><ul><li><span style="color:#000000">方法二：使用 ModelScope datasets 库函数</span></li></ul><pre><code>from modelscope.msdatasets import MsDataset
MsDataset.clone_meta(dataset_work_dir='./xxx', dataset_id='codefuse-ai/devopseval-exam')
</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><pre><code>sample_data
|- sampleData.json   # 数据样例
train_data
|- fcdata_toolbenchG1.jsonl  # 72783 toolbenchG1 整理数据
|- fcdata_toolbenchG2.jsonl  # 29417 toolbenchG2 整理数据
|- fcdata_toolbenchG3.jsonl  # 24286 toolbenchG3 整理数据
|- fcdata_toolbenchG1_zh.jsonl # 16335 toolbenchG1 部分中文翻译数据
|- fcdata_zh_train_v1.jsonl # 72032 自有采集生成的数据 V1
|- fcdata_zh_train_luban.jsonl  # 10214 自有采集生成的数据 luban
 test_data
 |- fcdata_zh_test_v1.jsonl # 1250 自有采集生成的测试数据 V1
|- fcdata_zh_test_luban.jsonl # 259 自有采集生成的测试数据 luban</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_7"></span><h2><span>3.<span>&nbsp;</span></span><span style="color:#000000">评测设置</span></h2><span id="OSC_h3_8"></span><h3><span>3.1.<span>&nbsp;</span></span><span style="color:#000000">评测模型</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">一期我们选取了比较热门的不同参数大小、不同机构发布的通用大模型和 CodeFuse 大模型，具体细节如下表。后续我们也会评测更多其他的大模型。</span></p><p style="margin-left:0; margin-right:0"><img alt="截屏 2024-01-10 15.29.03.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878469347-f387ec7e-4b93-4600-9f00-6b43aba426e0.png" width="1124" referrerpolicy="no-referrer"></p><span id="OSC_h3_9"></span><h3><span>3.2.<span>&nbsp;</span></span><span style="color:#000000">评测指标</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">由于一般通用模型无法具备工具调用的能力，因此在进行 Tool Learn-Eval 评测之前需要对通用模型进行微调，先让模型学会工具使用的基本范式</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#000000">下面，我们定义了几种评估工具使用的指标：</span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/e4f3eb9ec0085945e108c444bd8744d4.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/c00744c5d702dc52dd785c699051efe0.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/329076d813a344136a96bf6f06ad6e41.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/0bc2c431ba13d7463377259786f2f8b1.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/e1c18467331bc0bd1d2d7bf1ea6c4a4c.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/2aeea17ffa6d1d6e8ae8275cbc63de33.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000">②③④⑤的和为 1，代表工具调用失败的总数，⑤工具幻觉是工具名识别失败的一种特殊情况</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>在此基础上，我们提供了一个相应的评测脚本，具体评测过程欢迎到 Github 项目中进一步了解。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_10"></span><h2><span>4.<span>&nbsp;</span></span><span style="color:#000000">评测结果</span></h2><span id="OSC_h3_11"></span><h3><span>4.1.<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval%23-leaderboard" target="_blank" rel="nofollow"><span>🏆</span></a><span style="color:#1f2328"><span>&nbsp;</span>fcdata_luban_zh 数据集评测</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">如下图所示，在 fcdata_luban_zh 的评测结果中，不同模型在指令微调后 function call 能力存在一定的分化现象。Qwen-14B-Chat 在工具调用准确率 fccr 和 aar 的得分最高，说明通过 Qwen-14B-Chat 遵循指令微调的能力最好，同时也可以看到 Qwen-7b-chat 的 fccr 也基本与 Qwen-14b-chat 持平。Internlm-7B-Base 评分较低相对其它模型的指令微调能力较弱。从总体上来看，各模型经过 FunctionCall 的训练数据微调后，分数区分度不大。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/14156567/1702348998847-95a5ff09-da9b-496e-b3fd-5475ed2f0fed.png" width="1461" referrerpolicy="no-referrer"></p><span id="OSC_h3_12"></span><h3><span>4.2.<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval%23-leaderboard" target="_blank" rel="nofollow"><span>🏆</span></a><span style="color:#1f2328"><span>&nbsp;</span></span><strong><span>fcdata_zh</span></strong><span style="color:#1f2328">数据集评测</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">如下图所示，在 fcdata_zh 的评测结果中，不同模型在指令微调后 function call 能力不存在太大差异。同时也可以看到在 fcdata_zh 数据集上的 arr 评分相较于 luban 数据集有较大的提升，可能是 luban 评测集表述上与整体训练集上的回答存在较大差异，模型无法做出与 luban 数据匹配的合理回答。最好的 aar 得分模型分别是 CodeLLaMa 和 CodeFuse-7b-16k，而 CodeFuse-7b-16k 比 4k 要好也说明长 Token 模型拥有对工具进行总结的更优能力。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/14156567/1702348993031-375fb821-ec90-49e8-99aa-77e04075676f.png" width="1461" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_13"></span><h2><span>5.<span>&nbsp;</span></span><span style="color:#000000">未来展望</span></h2><p style="margin-left:0; margin-right:0"><span style="color:#000000">Tool Learning 现在已然成为大模型领域的研究热点，大模型与 Tool Learning 能碰撞出什么火花也是当前行业内最关心的话题。未来我们将持续对 ToolLearning-Eval 项目进行优化，主要优化方向包括以下几点：</span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000">1）不断优化评测数据集：</span></p><ul><li><ul><li><span style="color:#000000">目前 ToolLearning-Eval 已涵盖日常领域常见的工具集合，后续将继续增加不同领域的 Tool 集合，直至覆盖全领域的所有智能化任务；</span></li><li><span style="color:#000000">Tool Learning 的数据质量决定了模型掌握工具学习范式的上限，后面将通过更完善的数据构造方法和人工评测手段来生成更高质量的数据</span></li></ul></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#000000">2）拓展多工具多轮对话数据集：</span></p><ul><li><ul><li><span style="color:#000000">当前工具评测任务仅限於单工具的评测，对于不同类别之间的数据量存在较大差异，需要持续补充数据集，平衡各类别的数据量；</span></li></ul></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#000000">3）持续增加评测模型：</span></p><ul><li><ul><li><span style="color:#000000">一期主要评测了一些主流的、规模不是很大的开源模型，后续将覆盖更多的模型，并重点跟踪评测面向相关领域的大模型。</span></li></ul></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#000000">希望大家一起来共建 ToolLearning-Eval，期待在大家的努力下，建立更准确、更全面的 ToolLearning 领域大模型评测体系，推动 ToolLearning 领域大模型技术的不断发展与创新。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_14"></span><h2><span>6.<span>&nbsp;</span></span><strong><span style="color:#000000">联系我们</span></strong></h2><p style="margin-left:0; margin-right:0"><span style="color:rgba(0, 0, 0, 0.9)">欢迎使用&amp;讨论&amp;共建</span><br><span>（1）Eval - DevOps 领域 LLM 行业标准评测：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval" target="_blank" rel="nofollow"><span>https://github.com/codefuse-ai/codefuse-devops-eval</span></a><br><span>（2）ChatBot - 开箱即用的 DevOps 智能助手：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-chatbot" target="_blank" rel="nofollow"><span>https://github.com/codefuse-ai/codefuse-chatbot</span></a><br><span>（3）Model - DevOps 领域专属大模型：</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-DevOps-Model" target="_blank" rel="nofollow">https://github.com/codefuse-ai/CodeFuse-DevOps-Model</a><br> &nbsp;&nbsp;</span><span>(4) CodeFuse 官网：<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodefuse.alipay.com%2Fwelcome%2Fproduct" target="_blank" rel="nofollow"><span>https://codefuse.alipay.com</span></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 11:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/10759392</guid>
            <link>https://my.oschina.net/u/6942768/blog/10759392</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[袁进辉新公司再获王慧文等 5000 万投资]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000">硅基流动（SiliconFlow) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW0SAITjjpiJItGe4dYvMCQ" target="_blank">宣布</a></span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">于近日完成 5000 万元天使轮融资。本轮融资由创新工场领投，耀途资本、奇绩创坛以及王慧文等科技界知名人士跟投，华兴资本担任独家财务顾问；</span><span style="background-color:#ffffff; color:#000000">投后估值为数亿元人民币。</span></p><p><span style="background-color:#ffffff; color:#000000">硅基流动是</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">一流科技（OneFlow）</span><span style="background-color:#ffffff; color:#000000">创始人、光年之外联合创始人袁进辉于 </span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">2023 年 8 月</span><span style="background-color:#ffffff; color:#000000">成立的一个新公司，</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">致力于打造大模型时代的 AI 基础设施（AI Infra），降低大模型应用成本和开发门槛，加速 AGI 普惠人类。</span></p><p><img height="283" src="https://oscimg.oschina.net/oscnet/up-21d1e3f3e5cd348650171057db95e4847a6.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">袁进辉在接受《晚点 LatePost》采访时表示，</span><span><span style="color:#000000">新公司延续 OneFlow 的方向，做 AI Infra（AI 基础设施）层中的 「框架」。</span></span></p><div style="text-align:start"><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">AI 框架介于算力层和模型层之间，是一种系统软件，就像电脑操作系统能使普通用户直接用鼠标和键盘操作应用，AI 框架能帮开发者简单方便地设计模型或使用模型，而无需操心底层算力资源的调配。</span></span></p></div><div style="text-align:start"><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">不同的是，OneFlow 当年以通用训练框架为主，服务深度模型的生产；硅基流动则专注做推理框架，服务大模型的应用。</span></span></p></div><div style="text-align:start"><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">袁进辉认为，服务大模型应用比服务大模型生产更容易做出标准化产品，市场空间也大得多：模型生产是阶段性的，且由少数公司主导；大模型应用则会遍布各行各业、无处不在，被各种行业和规模的企业需要。</span></span></p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 10:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275107</guid>
            <link>https://www.oschina.net/news/275107</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[重庆大学 | 面向 RISC-V 架构的 AI 开发框架构建与优化大赛宣讲会成功举办]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">1 月 10 日，</span><strong>面向 RISC-V 架构的 AI 开发框架构建与优化大赛第八场宣讲会</strong><span style="color:#000000">在</span><strong>重庆大学</strong><span style="color:#000000">举行，重庆大学国家卓越工程师学院副院长刘凯、计算机学院副院长钟将、助理教授李荣振、助理教授李楚昭，openKylin 社区秘书长余杰博士、技术委员会委员王文竹博士</span><span style="color:#000000">参与活动。本次宣讲会旨在进一步加深同学们对大赛的了解，鼓励和动员更多同学参与到比赛中来。</span></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e2ac0aa8c27173ea72ce9d177d889d9b978.jpg" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000"><span style="color:#000000">宣讲会上，openKylin 社区技术委员会委员王文竹</span><span style="color:#000000">围绕大赛概述、赛道设置、赛程安排、参赛要求等方面向同学们介绍了面向 RISC-V 架构的 AI 开发框架构建与优化大赛</span><span style="color:#000000">，并向同学们讲解介绍了一系列</span><span style="color:#000000">实践案例</span><span style="color:#000000">，帮助同学解读赛题，理清参赛思路，鼓励同学们积极参与报名。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000"><span style="color:#000000"><span style="color:#000000">希望通过</span><span style="color:#000000">此次宣讲会，能够</span><span style="color:#000000">帮助同学们更好地了解面向 RISC-V 架构的 AI 开发框架构建与优化大赛的相关内容和参赛规则，激发同学们的参赛热情。</span></span></span></p><p><strong>关于大赛</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">面向 RISC-V 架构的 AI 开发框架构建与优化大赛是开放原子开源大赛设立的赛道，由 openKylin 社区、麒麟软件有限公司承办，国防科技大学、信创海河实验室协办，玄铁、北京算能科技有限公司、广东赛昉科技有限公司赞助。通过本项赛事，旨在探索如何将人工智能技术与 RISC-V 架构相结合，以实现高性能和低功耗的目标。各相关单位、高校、个人等均可免费报名参赛，目前正在火热报名中~</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 09:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275095</guid>
            <link>https://www.oschina.net/news/275095</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Atuin 作者宣布辞职，全职从事开源项目]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">流行的 Shell 历史记录管理工具 Atuin 作者 Ellie Huxtable 于近日发文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fellie.wtf%2Fposts%2Fi-quit-my-job-to-work-full-time-on-my-open-source-project" target="_blank">宣布</a>，已经在 2023 年 12 月 22 日辞去了 PostHog 基础设施团队的领导工作。接下来，她将成立一家公司，全职服务于 Atuin 项目。</span></p><p><span style="color:#000000">「Atuin 将继续开源并以当前形式作为自托管工具免费提供。通过全职运营，我希望可以专注于为高级用户添加新的高级托管功能，并开始支持商业用途。」</span></p><p><span style="color:#000000">Atuin 是一款可跨设备同步的 Shell 历史记录工具。可使用 SQLite 数据库取代你现有的 shell 历史，并为你的命令记录额外的内容。此外，它还通过 Atuin 服务器，在机器之间提供可选的、完全加密的历史记录同步功能。</span></p><p><span style="color:#000000"><img alt="" height="222" src="https://oscimg.oschina.net/oscnet/up-204accc133a02e4d3372505f70244790d01.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="222" src="https://oscimg.oschina.net/oscnet/up-ff8b1563ecf919bb0341a800b897e2de8d4.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Ellie 表示，促使她作出这一决定的原因是她开始意识到，付出与收获是成正比的。因为受工作牵绊，她只能在在上班前抽空处理 Atuin 上的问题；但即便如此，很多时候甚至连公开的 PR 和 issue 都没时间处理，遑论开发需要的新 features/fixes。</span></p><p><span style="color:#000000">久而久之，她感觉自己与 Atuin 之间已经渐行渐远。在这一过程中，她的朋友 Conrad 也退出了项目的维护工作。</span></p><blockquote><p><span style="color:#000000">我觉得自己在辜负项目的期望，忽略了自己的社交生活，并且在工作中极力避免分心。</span></p><p><span style="color:#000000">为了按照我的意愿发展这个项目，我需要在全职工作的同时投入更多的时间。</span></p><p><span style="color:#000000">所以，我正在创办一家公司，全职开发 Atuin。</span></p><p><span style="color:#000000">我一直想经营自己的公司，这几乎是我一生的梦想。但我不想为了创业而创业。我想做一些人们喜欢的、有用的东西。</span></p></blockquote><p><span style="color:#000000">谈到资金问题，Ellie 则表示一直在自掏腰包运行 Atuin 服务器；「虽然数额不是很大，但也不小」。直至 2022 年底，她在朋友建议下开通了&nbsp;GitHub 赞助渠道，并收获了意料之外的金额 ——&nbsp;足够支付服务器费用，并抵消她迄今为止所支付的部分费用。</span></p><p><span style="color:#000000">但有一个弊端是，她需要经常提及赞助渠道的存在，否则就容易被遗忘。「这让我感到很奇怪，因为这感觉就像是在乞讨」。而有着与她相同感受的开发者并不在少数。因此，Ellie 引用了&nbsp;Sidekiq 创建者 Mike Perham 的两句话：</span></p><blockquote><p><span style="color:#000000">「最终，OSS 的倦怠将扼杀任何具有吸引力的免费项目」</span></p><p><span style="color:#000000">「如果你创造了一些有价值的东西，那就为它收费」</span></p></blockquote><p><span style="color:#000000">展望未来，Ellie 希望能在现有功能的基础上，开发出一些有价值的商业功能。同时将&nbsp;Atuin 发展到可以传承下去的地步，并对一些提供过帮助的项目和人提供资助。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 08:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275092/atuin-full-time-on-open-source-project</guid>
            <link>https://www.oschina.net/news/275092/atuin-full-time-on-open-source-project</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sealos：在公有云和私有云之间，我选择第三条路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><span style="color:#494949"><span style="background-color:#ffffff"><span style="background-color:#ffffff">【创造者说】&nbsp;Created in the name of FOSS.</span></span></span></p><p style="text-align:center"><img height="450" src="https://oscimg.oschina.net/oscnet/up-aeccf4cfa39fbccb3b91bcb94207696b175.png" width="1080" referrerpolicy="no-referrer"></p><p>前段时间，上云和下云的争议如火如荼，公有云的价格、安全和透明度备受拷问，私有云的服务、维护成本又深受质疑。就在双方互掐不分上下的时候，一个新项目引起了我们的注意——Sealos，一个云操作系统，在公有云和私有云之间，他选择了第三条路——把公有云私有云抽象到一起。</p><p>Sealos 的作者方海涛，曾在讯飞担任容器平台负责人，后来在阿里云负责云原生集成平台，主导了 sealer 项目并捐献给 CNCF 社区。他觉得自己「骨子里就是个创业者」，早在 2016 年就开始了第一次创业，可惜没成。Sealos 每年翻倍的发展速度，让他看到了新的希望。拿到奇绩创坛的投资后，他火速拉上自己的老朋友和同事，出来成立了环界云计算公司。产品 Sealos 自从 2023 年 6 月份上线以来，<strong>仅半年时间注册用户已经突破 8 万，月收入超过 30w。</strong></p><p>方海涛认为，现在的公有云和私有云虽然吵得凶，但其实各有各的问题，也各有各的适用场景，脱离场景谈优势毫无意义。他认为，公有云和私有云并无本质区别，都是连接计算资源，<strong>可以做个</strong><strong>像安卓一样好用的云</strong><strong>操作系统</strong><strong>，谁要用云就装一个就行</strong>。而现在，这个想法实现了。</p><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>01 创业的齿轮重新转动</h1><p>第一次创业失败后，方海涛回归了单纯的程序员身份。一天晚上，为了解决 K8s 早期版本的安装和高可用等问题，方海涛把自己写的一个安装脚本放在了阿里云市场上，命名为「 kubeinit 」，15 块钱一份。没想到的是，还真有人买。看着进账，方海涛很兴奋，仿佛看到了未来的商业帝国。可是，这第一个版本问题太多了，程序也十分复杂，方海涛不得不花了一整天时间为这位客户提供售后服务，电影院里还在帮用户解决问题。</p><p style="text-align:center"><img height="1454" src="https://oscimg.oschina.net/oscnet/up-de8b59708266427e5953e8b36da03e20ebc.png" width="808" referrerpolicy="no-referrer"></p><p>不过，这个好开头，让方海涛重拾了一点创业的信心。随着销量暴增，方海涛也借此换了一部新手机 iPhone 8。但不幸的是，问题也越来越多了，方海涛都抽不出时间进行售后维护。于是，他重写了一个基于 Ansible 的 v2 版本，但 Ansible 也只是使用起来方便许多，并没有解决根本的安装复杂度问题，很多用户安装失败，尤其是在离线环境中更容易出错，需要把 Ansible 放到 Docker 中。</p><p>为了解决这个问题，方海涛思考了很长时间，最后在 kube-proxy 源码上找到了灵感。借用负载均衡器的实现方式，去掉很重的组件，使整个脚本变得简单，于是第三个版本 Golang 解决了以往的问题，在安装方面做到简单极致，一条命令解决一切——这就是后来的 Sealos。</p><p>大概是众人都苦于 K8s 安装久矣，Sealos 口碑打开之后，在 Github 的趋势榜上连续霸榜了一周，可见需求之旺盛。这样出色的表现，也吸引了陆奇团队的注意。2022 年 3 月，Sealos 获得了陆奇团队 200 万的天使投资。方海涛的创业之路，也重新开启了。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>02 独树一帜的设计</h1><p>「上云是未来」虽已达成共识，但上的是公有云还是私有云，却存在分歧。尤其是在今年的公有云故障事件之后，私有云的声音也响亮了起来。毕竟，公有云干的本就是租赁的活儿，不少软件还是开源的，却还卖这么贵，难免让用户心生「割韭菜」的怀疑。而私有云，建设成本又太高，无论是采购还是自建，花销都少不了：采购起步上千万，自建少说 30 人。这也是当下用户纠结的原因。有评论说得好：<strong>云就是一座围城，外面的人想进去，里面的人想出来。</strong></p><p>不过面对这种 A or B 的难题，Sealos 却选择了第三条路：把公有云和私有云抽象到一起，集公有云的弹性、敏捷和私有云的安全可控于一身，同时再把价格给打下去。</p><p>还有这种好事？</p><p>怎么做到的？</p><p><strong>Sealos 将 Kubernetes 作为 「云内核」，基于这个云内核做一个可以运行在多台服务器上的云</strong><strong>操作系统</strong><strong>发行版，系统之上 「一切皆应用」。最终可以把整个数据中心所有服务器变成一台 「逻辑计算机」，让用云变得像用 PC 一样简单：</strong></p><p style="text-align:center"><img height="1974" src="https://oscimg.oschina.net/oscnet/up-1e1316ef681c726943f82545a53d490dd1f.png" width="3840" referrerpolicy="no-referrer"></p><p><strong>云的架构也从传统的 </strong><strong>IaaS</strong><strong>、</strong><strong>PaaS</strong><strong>、SaaS 三层架构，转向以 Kubernetes 为云内核的新架构：</strong></p><p style="text-align:center"><img height="590" src="https://oscimg.oschina.net/oscnet/up-be50dc03448ab6ce8c8b0188df4657401ce.png" width="1060" referrerpolicy="no-referrer"></p><p>最终，Sealos 和 Kubernetes 之间的关系，就像 Red Hat 和 Linux 内核之间的关系，只不过与单机操作系统的区别是，Sealos 是装在整个数据中心的，Sealos 上跑的也不是 QQ 微信这些单机应用，而是开发者需要用到的各种分布式应用。有了 Sealos，整个数据中心就不再是一台一台孤立的服务器，而是一个整体，变成一台超级逻辑计算机。这个时候再去用云，就像是在用一台服务器一样简单。</p><p><strong>哪家企业需要用云，就直接装一个云</strong><strong>操作系统</strong><strong>就搞定了。</strong></p><p>在方海涛看来，云计算的本质在于将计算资源（包括硬件、软件和网络等）通过互联网等方式提供给用户使用，连接单个数据中心的算力资源只给自己用就是私有云，通过公网让大家都能用就是公有云。至于功能上，公有云能做到的理论上私有云都能做到，并无本质区别。未来，公有云和私有云也许会走到一起，变成同一个东西。</p><p>在 Sealos 的设计中，也处处秉承了这样的理念。公有云与私有云是同一套代码，同一个抽象，只是配置与安装的应用不同，运行在企业自己机房就是私有云，对公网提供服务就是公有云。</p><p>两边的用户一手抓了。</p><p>这样的设计还使得 Sealos 简洁又简单，避免了传统用云的「屎山」体验。</p><p><strong>而在高度抽象的架构下，一切具体能力都通过应用去扩展。</strong>用户需要啥就装啥，不要就卸掉，自由灵活，云操作系统也不会随着软件功能的增加而增加复杂度。这样，不管懂不懂 Kubernetes 都能愉快地使用 Sealos 了，云原生专家可以打开终端敲各种原生命令，DBA 也可以直接使用数据库应用，极其灵活。</p><p>「用户需要关心 Kubernetes 吗？其实不需要。我们只要想办法把用户最终需要的应用直接交付给用户就行了，就像你去用 Linux 的时候你很少关心 Kernel 一样，云也是一样的道理，开发者需要用到的能力才是最重要的，未来没有多少人需要再去关心这个内核了。」方海涛说。</p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>03 学习 Linux，成为 Linux</h1><p>在 Sealos 的成长过程中，不难发现，很多产品思路都学习了 Linux。在采访过程中，方海涛也对 Linux 极为推崇。他认为，Linux 简单易用，运行稳定，几乎不用投入太高成本，也基本不需要定制化开发。而 Openstack 专业人士三天都不一定能装起来，还得改一堆代码才能用，实在是太复杂了，不应该成为私有云的代表。Linux 才是学习的榜样。</p><p>「Linux 在哪里用都是同一个 Linux，云也应该这样。否则一味地堆积很多乱七八糟的东西进来，变成一个大杂烩，那 Sealos 只会变成又一个失败的 PaaS 平台。」方海涛说。</p><p><strong>Sealos 目前只有一套</strong><strong>开源</strong><strong>代码，哪个版本都一样，没有分支</strong>。而它能得到众多开发者的欢迎，也是因为它像 Linux 一样低成本、易用和标准化。</p><p>「其实云都是大差不差的，Sealos 能解决的问题，其他的云基本上也能解决。但 Sealos 现在这么受欢迎，就在于它的易用性。」方海涛介绍，「同样的事情，如果放在 Sealos，K8s 集群已经有了，只需点一下按钮 CBT 就能起来。但是如果基于虚拟机去搭的话，你可能需要搞后端的数据库，再去搭建负载均衡，去搞备份恢复等等，才能把整套东西搞起来。成本差异就在这。」</p><p>在运维方面，Sealos 也很稳定。「在我们的理念中，不应该有运维这种角色的存在，整个系统是自运维的，就像 PC 操作系统运行起来很少发生问题的。」</p><p style="text-align:left">而且 Sealos 最小只有 300M，企业装了 Sealos 便能在各种环境中拥有完全属于自己的云。</p><p>「另外，Sealos 有标准化的应用市场。很多人需要的其实只是上层的应用，我们把这些应用封装好，直接给到他们去用就行了。一些云厂商可能也有类似的 Marketplace，可是这些 Marketplace 缺乏标准，软件的生产者跟消费者之间协作就很麻烦。我们以云操作系统的思维，在做这个事情的时候，我们会 follow 云原生生态的事实标准，让软件的生产者和消费者连接起来，相互协作，达成良性循环。」</p><p style="text-align:left">这种以操作系统的思维来做云最终也会改变生产关系，让云的生态可以像安卓生态一样，不再是单一厂商来提供云应用，而是形成多对多的网状协作关系。</p><p>&nbsp;</p><span id="OSC_h1_4"></span><h1>04 神奇的项目：开源、商业不分家</h1><p>截至目前，Sealos 在 Github 上已经拥有了 12000+的 star。良好的群众基础，也给 Sealos 打开了一条丝滑的商业化道路。</p><p>跟别的开源项目不同，Sealos 并没有走「先开源，后收费」的路子，而是从诞生起，就开始收费了。最早期时是卖安装包，代码开源但是安装包收费，如果用户自己根据源码去构建安装包可能需要一周时间，而花 50-168 元就可以立马下载，所以卖了很多，装机量超过 150 万次。</p><p>出来创业之后，Sealos 也开始了正式的商业化。目前主要的商业模式有两大块：公有云和私有云。<strong>但有意思的是，</strong><strong>不管是标准版还是商业版</strong><strong>，不管是公有云还是私有云，Sealos 都只有一套代码。开源和商业化不分家。</strong>那 Sealos 是怎么盈利的呢？</p><p>公有云很简单，打开浏览器，注册登录充值就可以用，按量计费。但真正的盈利点是：<strong>云服务</strong><strong>。</strong></p><p>「很多做开源项目的公司都会有这样的困惑：开源做得太好，用户就不付钱了？为了解决这个问题，很多公司就会做两个版本，一个是开源版，功能少一点；一个是商业版，放一些很强的功能。我就非常不喜欢这样的做法。因为维护两个版本是很累的事，每次都需要考虑哪些东西合并企业版，哪些东西不合并，时间一久两个版本就直接分叉了，后面直接索性开源版不投入了，这种方式很别扭，不高级。</p><p>我喜欢把所有的好东西都开源出去，让开源和商业化尽可能形成合力。那怎么规避'开源做得足够好之后，用户不愿意掏钱'这个问题？很简单——云服务。」方海涛说。</p><p style="text-align:left">即便 Sealos 的开源做得非常完美，用户搭建的时候还是需要掏钱买虚拟机。既然这样，不如直接把这个钱充值给 Sealos。「本质上是成本转移，但是这种模式对三方都好。」对用户来说：</p><ul><li><p><strong>使用上更简单可以打开浏览器直接用，省去自己搭建。</strong></p></li><li><p><strong>专门的团队维护肯定比自己维护专业。</strong></p></li><li><p><strong>用户一多每个用户成本会下降，花钱更少。</strong></p></li><li><p><strong>持续升级更新。</strong></p></li></ul><p>因此，公有云的用户，有非常大的可能性会使用云服务。用户在 Sealos 上花的钱多了，但需要支出的总成本很可能还降低了。Sealos 也获得了更多的资金去做新功能，扩大规模效应。</p><p>另一个商业模式就是私有云。有些用户买了服务器放在自己机房，这时候 Sealos 就延续了一开始的商业模式，但不是收安装包的下载费用，而是在 Sealos 内部实现了计量系统，按量计费，账户余额用完了就得充值了。</p><p>这种方式实现了公有云和私有云计费方式的完全统一，顺便一起解决了企业内部人员配额问题。针对大小不同的客户都有合理的价格，不会出现小客用不起，大客不敢用的情况。</p><p>至于这样收费会不会让用户反感？</p><p>「我还是觉得提供价值合理收费天经地义，原则也是尽可能找到<strong>让客户与项目整体利益最大化的点</strong>，收费贵了伤害了用户利益，收费便宜了我们没法快速前进，要平衡好这中间的利益关系，是个矛盾统一体。现在这种商业模式，能够让开源和商业化形成合力，我们也能放心大胆地投入，把开源做好，而不会有担心用户不付费的顾虑。」方海涛说。</p><p>&nbsp;</p><span id="OSC_h1_5"></span><h1>05 像开源模式的商业团队</h1><p>Sealos 不仅产品有趣，背后的团队也很有意思。</p><p>如今的环界云只有 21 个人，其中 20 个人都是写代码的，包括方海涛自己。即使是运营，也是技术出身。除了在商务方面分工明确一点，其余时候，环界云更像一个开源社区，每个人都在为这个开源项目贡献代码，只是负责的模块不同。这种去中心化的开源协作方式一直顺利运行至今，其中一个很重要的原因是：环界云不太依赖销售，大部分的客户都是自己主动找上门的，因此整个团队得以单纯地搞技术，少了很多传统企业的条条框框。</p><p>当然，这种「人在家中坐，钱从天上来」的舒坦，离不开开源本身给项目带来的流量。Sealos 在社区里的好口碑和高知名度，已经成为了环界云最大的获客点。目前的数据显示，高达 90% 的收入都是来自于社区里这些主动找来的客户。因为他们是主动来寻求解决方案的，因此这也意味着他们对产品的接受度和成交率都相对较高。</p><p>目前，除了 Sealos 之外，环界云还孵化出了两个爆款开源项目：Laf 和 FastGPT。Laf 是个函数计算平台，可以在线直接写代码，至今已有 6000 的 star。FastGPT 是个基于 LLM 大模型的 AI 知识库问答平台，把企业内部的私有化数据跟大模型结合，能变成企业内部的智能问答系统，目前已有 8000+的 star。</p><p style="text-align:center"><img height="184" src="https://oscimg.oschina.net/oscnet/up-f83ed0b7f4872bb32ae1a977145bcbda30b.png" width="438" referrerpolicy="no-referrer"></p><p style="text-align:left">Laf 和 FastGPT 为 Sealos 提供了丰富的应用，FastGPT 和 Laf 之间相互提供了 AI 自动编码能力和插件开发能力，Sealos 则为 Laf 提供扩展、使 FastGPT 得以运行。三个产品相互补充，紧密协同，已形成了一个完整的生态系统。</p><p><strong>三个产品上线半年，环界云计算已累计 8.4 万的注册用户，且拥有 10% 的付费率和超过 70% 的续费率。更难能可贵的是，Sealos 和 Laf 已成功支撑了多款百万注册用户级别的应用，其运行成本仅为传统</strong><strong>云服务</strong><strong>的 1/20。</strong></p><p>Laf 的作者王福根和 FastGPT 的作者余金隆，都是方海涛的创业合伙人。我们发现，环界云招募团队成员和社区贡献者的方式没什么区别，都是按照招募合伙人的方式招的。</p><p>Sealos 的一位开发主力+长期贡献者，原是 Sealos 的用户。当时方海涛做了一个「分享有奖」的活动推广 Sealos，他给社区挣了 100 块，方海涛却奖励他 1500，他觉得这个社区好生奇怪，于是就留了下来。方海涛则认为，一个开源项目背后没有商业化支撑，会走得很慢。而且，开源的贡献者也理应得到回报。于是，为了吸引开源社区，方海涛专门写了一个激励系统，来回馈社区的项目贡献者：当需求被合并完了之后，钱就会自动打到贡献者的支付宝账户里面。这一传统也保留到了现在。</p><p>「那个时候在项目挣到的钱几乎都回馈到社区了。要么给开发者了，要么买服务器提供更好的体验了。」方海涛说，「但我觉得这是挺好玩的一件事情，这个模式形成了一种良性循环，这样项目就会滚滚向前，其实非常好。」</p><p style="text-align:center"><img height="1125" src="https://oscimg.oschina.net/oscnet/up-0fed2c5356b827e053d2ce179e81c714791.png" width="1500" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#999999">环界云计算团队</span></p><p>&nbsp;</p><span id="OSC_h1_6"></span><h1>06 小项目准备挑战大考验</h1><p>目前，Sealos 社区用户 10 万+，不乏各种大企业。</p><p style="text-align:center"><img height="1855" src="https://oscimg.oschina.net/oscnet/up-1be0d9a7470266e6fbb03554af9e5903e0c.png" width="2000" referrerpolicy="no-referrer"></p><p>上线两个月时间注册用户就已破万，云服务共计运行 7000+应用。</p><p>应用的类型也很多，GPT 相关的、大模型、游戏、企业官网和业务系统等等，不一而足。</p><p>但 Sealos 的宏图不止于此，它的目标是进化为一款无所不在的云操作系统，为人们提供如同使用个人电脑般简易的云服务体验。</p><p>方海涛透露，接下来，Sealos 会有两个进化方向：</p><p>一个是产品的稳定性。因为云本质上是一个信任问题。如果产品不稳定，那用户一定不会深度使用，可能就浅尝辄止一下，或者把一些不重要的东西如博客论坛等等往里放。Sealos 刚上线的时候，都是开发者在用，顶多充个十块二十块的。但经过时间的积累，市场上认可了 Sealos 的稳定性之后，慢慢地有企业进来使用，充值数额也上去了。所以说，产品的稳定性才是核心。</p><p>但是，想把稳定性建设得足够好，其实是有一定挑战的，尤其是达到了一定规模之后。「我举个例子，现在市面上几乎所有的云原生网关都不能满足我们的需求，几乎都被我们打爆了。这个时候就需要我们去建设网关，把鲁棒性搞得更强。或者挑一个上下游的开源社区，帮他们做优化，一起变得更好。」方海涛说。</p><p>第二个要做的就是生态建设。「现在已经有不少的应用支持容器和 Kubernetes 了，那首先要做的就是把它们上架到我们的应用市场，拓展应用的宽度跟深度，再把 deploy on Sealos 反馈到社区。这种跟上下游开源项目之间的合作，大家都挺欢迎的。因为一方面 Sealos 有庞大的用户流量，可以给这个开源项目导流。另一方面，这个开源项目也可以为 Sealos 导流，所以是个完全互利互惠的事情。」</p><p>路漫漫其修远兮，这个小项目未来会如何，让我们拭目以待吧。</p><div><hr><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff"><span><strong><strong><span><span style="background-color:#ffffff"><span><span style="color:#27ae60"><span><strong><span><span>【创造者说】</span></span></strong></span></span></span></span></span></strong></strong></span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff"><span><span><span>OSCHINA 全新开源创企访谈栏目【创造者说】。</span></span></span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff"><span><span><span>开源社区需要创造者，他可以是个人，也可以是由个人组成的公司。开源软件发展 20 余年，来自公司的开源贡献者已经成为中坚力量，更是有一批公司围绕开源软件而创办。本栏目将聚焦开源创企和他们的创始人，探讨当下的开源现状，分享开源商业故事，为开源社区添砖加瓦。</span></span></span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">往期回顾：</span></p><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://my.oschina.net/oscpyaqxylk/blog/5578009" target="_blank">一个技术人 「误入歧途」，做了个向量数据库新物种</a></p></div><div><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://my.oschina.net/oscpyaqxylk/blog/5548404" target="_blank">90 后，辞职创业，说要卷死云数据库</a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 08:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10758980</guid>
            <link>https://my.oschina.net/u/6852546/blog/10758980</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[网易有道 Qanything 开源：探索个性化问答的新纪元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>网易有道最新开源力作：QAnything 引擎。</strong>是基于 RAG（Retrieval Augmentated Generation) 的引擎，可以用于建立本地知识库做问答，解锁本土 ChatGPT 般的问答体验。☝</p><p><strong>「QAynthing」<strong>是一个成熟的系统，有着准确率高、速度快、纯离线，易于使用（一键部署），占用资源小</strong>（只要 16G 显存即可）的特点。</strong></p><p>目前，<strong>「QAynthing」</strong>已经在有道的多个产品中落地应用，包括有道词典的文档问答，有道速读，以及有道课程业务（高中、少儿围棋等）的客服系统等，在有道合作的 2B 客户的场景中已经落地应用。</p><p>&nbsp;<img alt="" src="https://oscimg.oschina.net/oscnet/up-3a44e1a3842061c69c8d841262c86d5ea68.png" referrerpolicy="no-referrer"></p><p>chatgpt 的大模型能力很强，但其训练耗时很长，无法利用用户的私有数据，且有胡乱编造的幻觉问题。</p><p><strong><strong>与 ChatGPT 相比，<strong><strong><strong><strong>有道自研的</strong></strong></strong></strong>「<strong><strong><strong><strong>Q</strong></strong></strong></strong>Aynthing</strong>」有自己的突出优势。</strong>它能够快速塞入各种格式的文档，如 doc、ppt、excel、图片、pdf 等，系统将在很短的时间内对这些文档进行处理并根据语义建立知识库，用户可以基于这样的知识库做各种问答。系统将理解用户的意图，在全库中寻找相关的内容，理解、提取用户关心的要点，并加以总结后呈现给用户。</p><p>&nbsp;<img alt="" src="https://oscimg.oschina.net/oscnet/up-28dd89cb825ae0ca3ded8dd7b632f332405.png" referrerpolicy="no-referrer"></p><p><strong>「QAynthing」</strong>包含的模型和系统代码，我们都全面开源了。此次开源还包含了一个应用系统，用户可以通过前端页面上传文档，直接使用。也可以通过我们提供的 API 接口做二次开发，搭建诸如智能客服等应用。用户直接一键下载我们的代码和模型即可开始使用。</p><p>&nbsp;</p><p>&nbsp;&nbsp;<img alt="" height="500" src="https://oscimg.oschina.net/oscnet/up-b05477f7eac27220217144c83707d9f1048.png" width="1000" referrerpolicy="no-referrer"></p><p><strong><strong>在模型部分</strong></strong>，我们开源了有道自研的 BCE embedding 和 rerank，用来做语义检索和相关性排序。得益于有道在翻译领域的积累，有道自研的 embedding/rerank 模型在跨语种场景下表现尤其好。比如知识库的文档有中文、英文混合语种的内容，当用中文去问问题的时候，我们能够很好的检索出英文内容。目前所有的开源 embedding 模型都忽略了跨语种检索的问题，在跨语种上表现不佳。此外，开源的 embedding 很多时候忽略了 RAG 的问题，只是单纯追求语义相似。<strong>而<strong>我们的 embedding 和 rerank 模型专门针对 RAG 的场景做了训练，所以有着更高的准确率</strong></strong>。</p><p><img alt="" height="456" src="https://oscimg.oschina.net/oscnet/up-c8fb3f4f844d6a2d5ac3608bae03fc309f2.png" width="1000" referrerpolicy="no-referrer"></p><p>在<strong><strong>系统部分</strong></strong>，我们对文档的解析、切片、建库、embedding/LLM 的推理做了大量的优化，具有<strong><strong>稳定、速度快、易于安装</strong></strong>使用的特点。</p><p><strong><strong>目前该项目还处于<strong><strong><strong><strong>不断迭代的阶段</strong></strong></strong></strong>，<strong><strong><strong><strong>欢迎大家参与开发，并给予</strong></strong></strong></strong>我们更多反馈</strong></strong>。</p><p>官网地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FQAnything" target="_blank"><u>https://github.com/netease-youdao/QAnything</u></a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 06:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/youdaotech/blog/10739178</guid>
            <link>https://my.oschina.net/youdaotech/blog/10739178</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中文 JDK 教程网站正式上线，助力开发者掌握 Java 编程语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">为了满足日益增长的 Java 开发者学习需求，对官方英文文档理解困难，致力于提供优质编程教育的网站《存在码》宣布推出全新的中文 JDK 教程网站。这一网站的上线标志着学习 Java 编程语言的全新起点，为开发者们提供了丰富而易于理解的学习资源。</span></p><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>网站特色：</strong></span></p><ol><li><p style="margin-left:0; margin-right:0"><strong>全面教程：</strong> 中文 JDK 教程网站提供了覆盖 Java 各个方面的详尽教程，旨在帮助开发者建立坚实的编程基础。</p></li><li><p style="margin-left:0; margin-right:0"><strong>实用示例：</strong> 数百个实用的示例代码将帮助开发者深入理解 Java 语言的概念和技巧，实践中学习。</p></li><li><p style="margin-left:0; margin-right:0"><strong>学习路径：</strong> 精心设计的学习路径，从入门到精通，让开发者能够有系统地提升技能水平。</p></li><li><p style="margin-left:0; margin-right:0"><strong>及时更新：</strong> 网站内容将根据 Java 平台的最新发展和技术趋势进行及时翻译更新，确保学习者始终保持与行业同步。</p></li></ol><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>网站创始人表示：</strong>「我们创建这个网站的目标是为中文用户提供一个高质量、易于理解的 Java 教育平台。我们深知学习编程的挑战，希望通过这个平台让更多人轻松入门，深入学习 Java 编程语言。」</span></p><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">现在，开发者们可以通过访问 </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjava.cunzaima.cn" target="_blank">中文 JDK 教程网站</a><span style="color:#000000">开始他们的 Java 编程之旅。</span></p><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>关于中文 JDK 教程网站：</strong> 中文 JDK 教程网站是一个专注于为中文用户提供 Java 编程语言教育的在线学习平台。通过清晰易懂的教程和实用的示例代码，我们致力于帮助开发者轻松学习 Java，并在编程领域取得成功。访问我们的网站：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjava.cunzaima.cn" target="_blank"><span style="color:#2980b9">https://java.cunzaima.cn/</span></a></p><p><strong>网站截图：</strong></p><p><img height="763" src="https://oscimg.oschina.net/oscnet/up-a4908099ab2cb02c513eecfbe99f50213fd.png" width="1050" referrerpolicy="no-referrer"></p><p><img height="852" src="https://oscimg.oschina.net/oscnet/up-2059c6f708e6ff8119fcdbb4866fa34a17c.png" width="1888" referrerpolicy="no-referrer"></p><p><img height="733" src="https://oscimg.oschina.net/oscnet/up-d84726feca2fd514680bc5a7aaf4848b0a0.png" width="1910" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 05:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275053</guid>
            <link>https://www.oschina.net/news/275053</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[上海 AI 实验室联合港中大（深圳）开源音频生成平台 Amphion]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>上海人工智能实验室（上海 AI 实验室）与香港中文大学（深圳）联合团队<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCjsutc54MgqANMtZj3pOKg" target="_blank">推出</a> AI 音频生成平台安菲翁（Amphion）。现已开源并提供免费商用。</p><p>其不仅具备语音及歌声合成转换、音效及音乐生成等多种能力，更可实现转换过程可视化，有效地降低了应用门槛，助力更广泛的开发者进行 AI 音频研发。</p><p>Amphion 为古希腊神话中的传奇音乐家，传说其弹奏的优美琴声可让顽石感灵。上海 AI 实验室联合团队借此为 AI 音频生成平台命名，希望通过 AI 技术的创新为音频领域注入全新的研究思路，开源开放，「声」生不息。</p><p><img height="195" src="https://oscimg.oschina.net/oscnet/up-50aec28c64a629ade537a270d95c38ed10e.png" width="500" referrerpolicy="no-referrer"></p><h4><strong>集成经典模型架构，实现多项生成任务</strong></h4><p>为帮助初级开发者入门 AI 音频生成研究并使研究过程可复现，Amphion 将当前多个经典模型架构集中于统一平台，使其可实现多项音频生成任务。</p><p><strong>歌声转换 （SVC, Singing Voice Conversion）</strong></p><p>歌声转换是指通过 AI 技术，将一位演唱者的音色转变为另一位演唱者。该技术涉及信号处理、机器学习、深度学习等领域。</p><p>Amphion 系统集成了经典的特征提取模型用于 SVC 任务，包括经典的扩散模型、VITS 模型及 OpenAI 的 Whisper 模型等。基于扩散的架构使用双向扩张 CNN 作为后端，并支持 DDPM、DDIM、PNDM 等多种采样算法。此外，Amphion 还支持基于一致性模型的单步推理。</p><p>目前，Amphion 的特征设计已被当前业内流行的音频生成项目 So-VITS-SVC 5.0 借鉴。</p><p><img height="213" src="https://oscimg.oschina.net/oscnet/up-43ddb9355908a681234f663d7e8c32eb864.png" width="700" referrerpolicy="no-referrer"></p><p><strong>文生语音（TTS, Text To Speech）</strong></p><p>文生语音即输入文字转成相应语音的技术。当前，该模块主要采用了深度学习技术，将文本转换成自然流畅的高拟真度语音。在 TTS 任务模块，Amphion 系统集成了经典 FastSpeech2 模型、VITS 模型以及 zero-shot 语音合成技术，即 Vall-E，NaturalSpeech2。</p><p><img height="196" src="https://oscimg.oschina.net/oscnet/up-34bba51d4fba3469ce72f4d2904a953e523.png" width="700" referrerpolicy="no-referrer"></p><p><strong>文生音频（TTA, Text To Audio）</strong></p><p>文生音频指将文字输入转为音乐、场景音效等特定音频的技术。Amphion 集成了当下主流的文本驱动音频生成模型架构，即基于 VAE Encoder、Decoder 和 Latent Diffusion 的文本驱动的音频生成算法。在该架构下，Latent Diffusion 扩散模型以 T5 编码后的文本为输入，根据文本的指引生成对应的音频效果。</p><p>文生音频模型或将对文化创作产生积极深远的影响，从业者或可利用此项技术，根据特定需求生成场景音效，省去从头采集环节，提升生产效率。</p><p><img height="166" src="https://oscimg.oschina.net/oscnet/up-5675245eb7699e52230f19025f4a496385e.png" width="500" referrerpolicy="no-referrer"></p><p>声码器（Vocoder）是产生高质量音频信号的重要模块。为确保所生成音频的高音质输出，Amphion 集成了目前广泛使用的神经声码器（Neural Vocoders），包括 BigVGAN、HiFi-GAN、DiffWave 等主流声码器。</p><p>技术报告显示，Amphion 中的 HiFi-GAN 声码器在多项指标上领先于当前热门开源工具。</p><p><img height="189" src="https://oscimg.oschina.net/oscnet/up-df33b9c0a05c5f8d220f0d8aaf44e960d53.png" width="500" referrerpolicy="no-referrer"></p><h4><strong>可视化功能</strong></h4><p>与传统的音频开源工具不同，Amphion 提供了生成过程可视化及音频可视化功能。联合团队旨在通过可视化，使初级开发者者更好地理解模型的原理和细节。下图为在扩散模型中的 SVC 任务，形象地呈现出由一位歌手音色转换为另外一位歌手音色的渐变过程。</p><p><img height="242" src="https://oscimg.oschina.net/oscnet/up-a8cbbee92c42b4d6f600a91d234509595e5.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 03:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275031</guid>
            <link>https://www.oschina.net/news/275031</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Solus 4.5 发布，弃用 MATE 转向 XFCE 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Solus 4.5 「Resilience」 现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgetsol.us%2F2024%2F01%2F08%2Fsolus-4-5-released%2F" target="_blank">发布</a>。此版本带来了更新的应用程序和内核、更新的软件堆栈、新的安装程序以及采用 XFCE 桌面环境的新 ISO 版本。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-23a81b7291d2daba437ec478767f1973ee5.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Solus 4.5 带来了使用 Calamares 安装程序的全新安装体验。与此前相比，现在利用 Calamares 可以更轻松地在不同配置中设置 Solus，例如 Btrfs 根文件系统和其他配置。这也是摆脱旧版 os-installer 所使用的 Python 2 的重要一步。</span></p><p><span style="color:#000000">与此同时，新版本默认使用 Pipewire 媒体框架取代了 JACK 和 PulseAudio；UI 方面不会产生太大差异，但是会带来一些性能方面的改进，例如更好、更可靠的蓝牙音频。以及：</span></p><ul><li><span style="color:#000000">为使用受支持的 AMD 硬件的用户打包了 ROCm 5.5。</span></li><li><span style="color:#000000">附带 Linux kernel 6.6.9 以提供最新的硬件支持。</span></li><li><span style="color:#000000">Mesa 已升级至 23.3.2，以提供最新的开源图形驱动程序</span></li></ul><p><span style="color:#000000">桌面环境方面，Solus 4.5 提供了最新版本的 Budgie / GNOME / Plasma，并针对这些桌面环境提供了许多更新；同时发布了 XFCE 的第一个版本。Solus 4.4 发布公告曾宣布计划弃用 MATE 版本，转而使用新的 XFCE 版本。XFCE 版的目标是填补与 MATE 版相同的空白：喜欢更轻量级桌面体验的用户。</span></p><p><span style="color:#000000">鉴于这是 XFCE 版本的首次发布，可能会存在一些明显的不足，所以官方将 4.5 版 XFCE 定义为 beta 版本。新的 XFCE 版本包括：</span></p><ul><li><span style="color:#000000">XFCE version 4.18</span></li><li><span style="color:#000000">Mousepad 0.6.1</span></li><li><span style="color:#000000">Parole 4.18.0</span></li><li><span style="color:#000000">Ristretto 0.13.1</span></li><li><span style="color:#000000">Thunar 4.18.6</span></li><li><span style="color:#000000">Whiskermenu 2.8.0</span></li></ul><p><span style="color:#000000">XFCE 版本采用传统的桌面布局，带有底部面板和 Whiskermenu 作为应用程序菜单。使用 Qogir GTK 主题和 Papirus 图标主题，打造时尚现代的外观。并已安装 Blueman，可满足用户对蓝牙的所有需求。「这一版本耗费了大量心血，我们很高兴能与大家分享！」</span></p><p><span style="color:#000000">此外，官方仍在努力为 MATE 桌面的现有用户提供无缝过渡路径。从广义上讲，将为用户提供一种将其 MATE 安装迁移到 Budgie 或 XFCE 的方法。在成熟的过渡计划出炉之前，MATE 将继续为现有用户提供支持。</span></p><p>展望 2024，项目团队计划在 Plasma 中提供 Discover，并在 GNOME 中提供 Software Center，以实现具有集成 Flatpak 支持的软件管理。以及将通过修复错误、更新系统组件和完成从 python2 的迁移来偿还技术债务。还计划探索如何开始迁移到 Serpent 工具，为 5.0 版本做好准备。</p><p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgetsol.us%2F2024%2F01%2F08%2Fsolus-4-5-released%2F" target="_blank">查看官方公告</a>。</p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgetsol.us%2Fdownload" target="_blank">下载</a></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275026/solus-4-5-released</guid>
            <link>https://www.oschina.net/news/275026/solus-4-5-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GitHub 多项服务出现故障]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GitHub 多项服务昨天出现了故障，具体表现为众多 API 都出现了 HTTP 5xx 错误，错误率上升了 1%~5%，涉及的服务包括但不限于：</p><ul><li>Codespaces</li><li>Packages</li><li>Webhooks</li><li>Git 操作</li><li>Pages</li><li>API 请求</li><li>Actions</li><li>Pull Requests</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.githubstatus.com%2Fincidents%2Fpxg3dz4yg7lp" target="_blank">从事故报告页面来看</a></u>，GitHub 当时的解决方案是<strong>将相关问题隔离到一个数据中心进行处理</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ed70f2066fa0d8193dd82f9badfeb155b0a.png" referrerpolicy="no-referrer"></p><p>不知道 GitHub 最近频发故障是否跟升级 MySQL 有关？<br><u><em><a href="https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0" target="news">GitHub.com 跑了 1200 多台 MySQL 主机，如何无缝升级到 8.0？</a></em></u></p><p><em>延伸阅读：<u><a href="https://www.oschina.net/news/188164/github-recent-service-disruptions" target="news">GitHub 解释近期频繁宕机原因：MySQL 不堪重负</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 02:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275025/github-incident-20230109</guid>
            <link>https://www.oschina.net/news/275025/github-incident-20230109</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
