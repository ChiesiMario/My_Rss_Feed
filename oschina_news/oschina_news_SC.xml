<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 22 Nov 2023 06:09:42 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Redis 之父用纯 C 语言代码实现 Telegram Bot 框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Redis 创始人 antirez 最近开源了一个小项目 BOTLIB&nbsp;<span>——&nbsp;纯 C 语言代码编写的 Telegram Bot 框架 。</span></p><blockquote><p>地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fantirez%2Fbotlib" target="_blank">https://github.com/antirez/botlib</a></u></em></p></blockquote><p><img height="1668" src="https://oscimg.oschina.net/oscnet/up-2def2c40c083bd3744f89db768458900bf1.png" width="2458" referrerpolicy="no-referrer"></p><p>顾名思义，BOTLIB 用于创建 Telegram 对话机器人。目前该项目仍处于开发阶段，请谨慎使用。</p><p><strong>延伸阅读：</strong><em><u><a href="https://www.oschina.net/news/264564" target="_blank">Redis 创始人用 C 语言编写最小聊天服务器：Smallchat</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 04:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267574</guid>
            <link>https://www.oschina.net/news/267574</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sam Altman 与 OpenAI 董事会展开谈判]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">彭博社援引知情人士<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-21%2Faltman-openai-board-open-talks-to-negotiate-his-possible-return%23xj4y7vzkg" target="_blank">消息称</a>，Sam Altman 已经私下和 OpenAI 的新任临时首席执行官 Emmett Shear，以及至少一名董事会成员 Adam D'Angelo 展开了谈判。一些致力于推动 Altman 复职的 OpenAI 投资者也参与了会谈。</span></p><p><span style="color:#000000">多位人士表示，本次谈判是&nbsp;OpenAI 董事会与&nbsp;Altman 沟通之间的一项重大进展，毕竟直到本周一，董事们在很大程度上都拒绝与其接触。</span></p><p><span style="color:#000000">如果 Altman 成功回归，他将继续担任公司的首席执行官一职。在讨论中的另一种方案中，Altman 还将成为过渡董事会的董事，且 Salesforce 公司前联席首席执行官布 Bret Taylor 也可能担任新董事会的董事。</span></p><p><span style="color:#000000">在与董事会的谈判中，由 Airbnb Inc. 首席执行官 Brian Chesky 代表 Altman 进行发言，而 Shear 代表 D’Angelo&nbsp;和董事会。<span style="background-color:#ffffff">Bret Taylor&nbsp;</span>在调解中则更多的扮演的是中立角色。</span></p><p><img height="269" src="https://oscimg.oschina.net/oscnet/up-b769cdef524fa63ef3fca964112655bde21.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">希望 Altman 复职的 OpenAI 股东包括 Thrive Capital、Khosla Ventures 和 Tiger Global Management。董事会和 Altman 希望在感恩节假期前达成解决方案，解决围绕公司领导层的混乱局面。</span></p><p><span style="color:#000000">此外，Shear 也在要求董事会提供 Altman 错失行为的证据。如果董事会不能以书面形式向他明确传达突然解雇 Altman 的理由，他也不打算继续留在该公司。</span></p><p><span style="color:#000000">针对这一事件，彭博社分析师评论称：</span></p><blockquote><p><span style="color:#000000">Sam Altman 可能重返 OpenAI 担任首席执行官，这可能会加强微软的战略定位，尤其是如果微软能够在新董事会中获得一席之地的话。这也可能是微软更希望看到的结果，因为如果微软雇佣了 OpenAI 的大部分员工，将面临很高的法律风险。在监管障碍不断的情况下，我们认为微软收购 OpenAI 的可能性微乎其微。</span></p></blockquote><p>OpenAI 拒绝对谈判发表评论。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 03:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267569/altman-openai-board-open-talks</guid>
            <link>https://www.oschina.net/news/267569/altman-openai-board-open-talks</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国内外开源基金会基于 OpenHarmony 的开源平台 Oniro 达成合作]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>开放原子开源基金会<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGFKMvckBEgo3m6PQNfIV7w" target="_blank">宣布</a></u>与 Eclipse 基金会<strong>基于 OpenHarmony 的开源项目 Oniro 正式签署合作协议</strong>。</p><p><img height="1836" src="https://oscimg.oschina.net/oscnet/up-72d51d192bb234fefe29382583f9e8dc8db.png" width="1588" referrerpolicy="no-referrer"></p><p>据称本次签约开放原子开源基金会创造了两个第一，<strong>一是</strong>开源历史上第一次两个基金会通过代码、品牌、IP、认证等方式共同发展一个开源生态，为开源业内提供了合作的新典范，为开源全球合作探索了发展的新范式。<strong>二是</strong>国内开源基金会第一次同海外基金会完成合作签约，双方在技术项目、开发者生态、营销活动上发挥各自优势，共同在世界范围内推动开源项目发展。</p><p>Oniro 是致力于开发<strong>与供应商无关的开源操作系统 (OS) 平台</strong>。Oniro 项目基于两个全球开源基金会（Eclipse 基金会和 OpenAtom 基金会）之间的合作而建立。Oniro 利用由 OpenAtom 基金会运营的开源项目 OpenHarmony 的坚实基础，构建了一个以其在各种智能设备上的多功能性而闻名的操作系统平台。</p><p>据介绍，Oniro 优先考虑无缝互操作性、模块化和具有视觉吸引力的用户界面——面向消费电子、家用电器、工业物联网设备、智能家居和多媒体等各个行业的技术和应用提供基座。</p><p>他们通过一系列增强功能来实现这些目标，包括采用 React Native 等框架、Servo Web 引擎等系统级操作系统组件。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a180fdd32246279ef20e3577cbca096f455.png" referrerpolicy="no-referrer"></p><p>官方对 Oniro&nbsp;的架构图进行了如下介绍：</p><ul><li>Eclipse Theia 用于简化应用程序开发，增强了开发工作流程。</li><li>React Native 在 OpenHarmony 的基础上扩展了现有应用程序和生态的可用性。</li><li>通过采用 Rust 编程语言，特别是与 Servo Web 引擎的结合，增强了整个系统的安全性。</li><li>未来引入 Eclipse Kanto 和 Matter 等框架将能够集成更多 AIoT 和智能家居用例。</li></ul><p><em>延伸阅读：<strong><u><a href="https://www.oschina.net/news/166170/eclipse-foundation-oniro-os" target="_blank">Eclipse 基金会推出 Oniro OS，OpenHarmony 的独立开源实现</a></u></strong></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 03:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267568</guid>
            <link>https://www.oschina.net/news/267568</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Stability AI 开源视频生成模型 Stable Video Diffusion]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Stability AI <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fnews%2Fstable-video-diffusion-open-ai-video-model" target="_blank">发布了</a></u>开源视频生成模型 Stable Video Diffusion，该模型基于该公司现有的 Stable Diffusion 文本转图像模型，能够通过对现有图像进行动画化生成视频。</p><p><strong>主要特性</strong></p><ul><li>文本到视频</li><li>图像到视频</li><li>14 或 25 帧，576 x 1024 分辨率</li><li>多视图生成</li><li>帧插值</li><li>支持 3D 场景</li><li>通过 LoRA 控制摄像机</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-9679e48d9ea613ddb1fd57e8cec3bf0224a.png" referrerpolicy="no-referrer"></p><p>Stable Video Diffusion 提供两个模型，分别为 SVD 和 SVD-XT。其中，SVD 将静止图像转换为 14 帧的 576x1024 视频，而 SVD-XT 在相同的架构下将帧数提升至 24。</p><p>两者都能以每秒 3 到 30 帧的速度生成视频。白皮书显示，这两个模型最初在数百万个视频的数据集上进行训练，然后在数十万到百万数量级的较小数据集上进行「微调」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-939a57be449351948e8a0334edfe83c2c47.png" referrerpolicy="no-referrer"></p><p>Stability AI 称正在开发一个新的网络平台，包括一个文本到视频的界面。这个工具将展示 Stable Video Diffusion 在广告、教育、娱乐等多个领域的实际应用。</p><p>开源地址</p><ul><li>GitHub：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FStability-AI%2Fgenerative-models" target="_blank">https://github.com/Stability-AI/generative-models</a></li><li>论文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fresearch%2Fstable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets" target="_blank">https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets</a></li><li>HuggingFace：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fstabilityai%2Fstable-video-diffusion-img2vid-xt" target="_blank">https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 03:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267563/stable-video-diffusion</guid>
            <link>https://www.oschina.net/news/267563/stable-video-diffusion</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FastCFS V5.0 发布，原生支持 RDMA]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><span><span>经过 4 个多月的预研、开发和测试，FastCFS 5.0 终于和大家见面了。FastCFS 5.0 使用 ibverbs 原生方式适配了 RDMA 网络，可以充分发挥 RDMA 网络的低延迟和高吞吐特性。在此特别感谢 @Frank 提供 IB 环境的高端服务器供我们预研；非常感谢 @yunqi 在 ibverbs 编程方面耐心的答疑；十分感谢 @AI 墨墨，公众号提供了非常好用的 chatGPT 问答服务，帮助我解答了不少疑惑。</span></span></div><div>
  &nbsp;
 </div></div><div><div><span><span>我们租用阿里云 g8 类型的 ECS，使用其 eRDMA 特性，4KB 随机读在 fuse 场景性能下相比 socket 方式提升了 50%；我们直接调用 API（纯用户态模式）的 fcfs_beachmark，非 busy polling 模式下性能相比 socket 方式提升 80%，而 busy polling 模式下性能提升了 110%。后续我们将找机会在 IB 网络环境下进行性能对比测试，预计性能提升会更加明显。</span></span></div><div>
  &nbsp;
 </div></div><div><div><span><span>是否开启 busy polling，我们 server 端默认配置为智能模式。当一个连接的 QPS 连续 N 秒（如 3 秒）超过阈值（如 10240），则启用 busy polling 模式；连续 N 秒低于阈值，则退回非 busy polling 模式。</span></span></div></div><div><div><span><span>友情提示：配置示例及说明参见源码 conf/full/ 子目录下的配置文件。</span></span></div><div>
  &nbsp;
 </div></div><div><div><span><span>V5.0 修复的 bug 如下：</span></span></div></div><div><div><span><span>[fdir] bugfixed: dentry_create set loaded_flags correctly</span></span></div></div><div><div><span><span>[fdir] bugfixed: must use lock for db skiplist</span></span></div></div><div><div><span><span>[libfdirstorage] bugfixed: set variable normal_update correctly</span></span></div></div><div><div><span><span>[libfsstorage] segment reclaim more robustly</span></span></div><div>
  &nbsp;
 </div></div><div><div><span><span>FastCFS 5.0 通过了比较充分的测试，欢迎有 RDMA 网络环境的朋友进行性能测试。建议使用 FastCFS 老版本的用户，尽快升级到最新版本。有任何问题和建议，欢迎在 gitee 上提交 issue，当然也可以加群交流。</span></span></div></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267561/fastcfs-5-0-released</guid>
            <link>https://www.oschina.net/news/267561/fastcfs-5-0-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 面向所有用户免费开放 ChatGPT Voice]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 今天<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FOpenAI%2Fstatus%2F1727065166188274145" target="_blank">宣布</a></u>面向所有用户免费开放 <strong>ChatGPT Voice。</strong></p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-e1193b4f65f52cea9e6b495cd6f169d3af1.png" referrerpolicy="no-referrer"></p></blockquote><p>OpenAI 于今年 9 月推出了<strong>基于 ChatGPT 的文本转语音功能&nbsp;&nbsp;ChatGPT Voice</strong>——使用神经网络模型从文本生成类似人类的语音。该功能此前仅面向 ChatGPT Plus 订阅用户提供，现在向所有免费用户推出。</p><p>据介绍，ChatGPT Voice 通过采样配音演员录制的几秒钟音频，能够创建具有不同口音和风格的自定义声音。为用户提供对话功能，其整体对话的信息均以对话的形式输入输出，支持暂停、中断、更换音色等功能，并在对话结束后提供文字版进行参考。</p><p>要使用新的语音选项，ChatGPT 用户只需在 Android 或 iOS 上打开应用程序设置，并切换「耳机」图标即可激活文本转语音功能。</p><p>OpenAI 前总裁 Greg Brockman 随后<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fgdb%2Fstatus%2F1727067288740970877" target="_blank">跟帖表示</a></u>：「ChatGPT Voice 已面向所有免费用户推出。欢迎尝试 —— 彻底改变 ChatGPT 体验。」</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267559/chatgpt-voice</guid>
            <link>https://www.oschina.net/news/267559/chatgpt-voice</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox 120.0 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Firefox 120.0 现已发布，具体更新内容如下：</p><p><strong>New</strong></p><ul><li>Firefox 在上下文菜单中支持新的"复制链接不带网站跟踪"功能，确保复制的链接不再包含跟踪信息。</li></ul><p><img alt="" height="361" src="https://oscimg.oschina.net/oscnet/up-e7e4d23ecc050ac3f60820b1fa1946c0f75.png" width="300" referrerpolicy="no-referrer"></p><ul><li>Firefox 现在支持启用"全局隐私控制"的设置（在 Preferences → Privacy &amp; Security 中）。有了这项 opt-in&nbsp;功能，Firefox&nbsp;就会通知网站，用户不希望自己的数据被共享或出售。</li></ul><p><img alt="" height="139" src="https://oscimg.oschina.net/oscnet/up-e2c7de7e40d5068002d7503fbe8daf5795e.png" width="500" referrerpolicy="no-referrer"></p><ul><li>现在，Firefox 的隐私窗口和 ETP-Strict 隐私配置通过指纹保护功能增强了 Canvas API，从而继续保护用户的在线隐私。</li><li>Firefox 已在德国所有用户的隐私窗口中默认启用 Cookie <span style="background-color:#ffffff"><span style="color:#42425a">Banner Blocker</span></span>。对于支持的网站，Firefox 现在会自动拒绝 Cookie 并屏蔽恼人的&nbsp;cookie banners。</li><li><p>Firefox 已在德国所有用户的隐私窗口中默认启用 URL 跟踪保护功能。Firefox 将删除非必要的 URL 查询参数，这些参数通常用于在网络上跟踪用户。</p></li><li><p>Firefox 现在可以从操作系统根存储导入 TLS 信任锚（如证书）。这将在 Windows、macOS 和 Android 上默认启用，如有需要，可在设置（Preferences → Privacy &amp; Security → Certificates）中关闭。</p></li><li><p>现在已添加键盘快捷键，用于在 about:logins 上编辑和删除所选证书。editing - Alt + enter (Option + return on macOS)&nbsp;，deleting - Alt + Backspace (Option + Delete on macOS)。</p></li><li><p>Ubuntu Linux 用户现在可以从作为 Snap 软件包安装的 Chromium 中导入。</p></li><li><p>画中画现在支持 Windows 和 Linux 上的 corner snapping，只需在移动画中画窗口时按住 Ctrl 键即可。</p></li></ul><p><strong>Fixed</strong></p><ul><li><span style="color:#42425a">各种</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2023-49%2F" target="_blank">安全</a>修复<span style="background-color:#ffffff"><span style="color:#42425a">。</span></span></li></ul><p><strong>Developer</strong></p><ul><li>现在已添加 User Activation API，允许 JavaScript 使用 navigator.userActivation 检查用户当前是否或曾否激活页面（点击等）。</li><li>Early Hints Preconnect（信息状态代码 103）现已启用。这允许服务器在最终 HTTP 响应之前发送 resource Link headers，并提高了使用此功能的服务器的性能。(<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fearly-hints%2F" target="_blank">更多信息</a>）</li><li>用户现在可以使用新增的 devtools 功能模拟浏览器标签脱机。</li><li>Style Editor 面板的页脚新增了一个"Pretty Print"按钮，类似于调试器面板中的 Pretty Print 按钮。该按钮可用于格式化样式表（如已精简的样式表）。以前的功能是自动格式化最小化文件，现在已被删除。</li><li>Inspector&nbsp;面板中的"Rules"面板不再以新的 CSS Color 4 格式（如 OKLCH）显示十六进制/命名颜色。这样可以确保与使用的原始值相匹配。</li></ul><p><strong>Web Platform</strong></p><ul><li>lh 和 rlh 单位现在可以作为长度正确解析和计算。这样，作者就可以根据 element's（或 root element's）的行高来指定长度。</li><li>WebAssembly GC 现在已默认启用，这允许新语言（如 Dart 或 Kotlin）在 Firefox 上运行。以便收集 guest language 和 host browser 之间的 reference cycles&nbsp;。</li></ul><p><span style="background-color:#ffffff"><span style="color:#333333">详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fen-US%2Ffirefox%2F120.0%2Freleasenotes%2F" target="_blank">查看更新说明</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 02:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267557/firefox-120-0-released</guid>
            <link>https://www.oschina.net/news/267557/firefox-120-0-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FreeBSD 14.0 正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>FreeBSD 14.0 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.freebsd.org%2Freleases%2F14.0R%2Fannounce%2F" target="_blank">已正式发布</a></u>，这是&nbsp;<span style="background-color:#ffffff; color:#000000"><span>&nbsp;</span>stable/14 分支的首个版本，</span>支持 amd64, aarch64, i386, powerpc, powerpc64, powerpc64le, powerpcspe, armv7, 和 riscv64 架构。</p><p>主要变化：</p><ul><li>OpenSSH 升级至 v9.5p1</li><li>OpenSSL 升级至 v3.0.12<br> FreeBSD 13.2-RELEASE 使用 OpenSSL 1.1.1t，所以这是重大升级</li><li>bhyve 虚拟机管理程序支持 TPM 和 GPU 透传</li><li>FreeBSD 在 amd64 和 arm64 平台支持最多 1024 个内核</li><li>ZFS 升级至 OpenZFS v2.2，显著改进性能</li><li>实验性 ZFS 镜像可用于 AWS 和 Azure</li><li>支持对运行日志软更新的 UFS 文件系统执行后台文件系统检查</li><li>TCP 默认拥塞控制机制为<strong> CUBIC</strong></li><li>……</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.freebsd.org%2Freleases%2F14.0R%2Frelnotes%2F" target="_blank">FreeBSD 14.0-RELEASE Release Notes</a></u></p><hr><p>负责 FreeBSD 发版工作的主管在其个人博客介绍了一些 FreeBSD 14 的破坏性变化，详情查看&nbsp;<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.daemonology.net%2Fblog%2F2023-11-21-late-breaking-FreeBSD-14-breakage.html" target="_blank">https://www.daemonology.net/blog/2023-11-21-late-breaking-FreeBSD-14-breakage.html</a></u></em>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 22 Nov 2023 02:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267555/freebsd-14-0</guid>
            <link>https://www.oschina.net/news/267555/freebsd-14-0</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[scheme-langserver 发布类型推断功能，并整合进入 auto-autocomplete.]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Scheme-langserver 是一款面向 scheme 语言的语言服务器，它基于 LSP 协议（Language Server Protocol）提供了自动补全（auto-complete）、寻找变量定义（goto definition）等功能。</p><p>11 月 21 日，scheme-langserver 发布了类型推断功能，并将该功能整合进入了自动补全。如图所示，在补全光标处的引导词「l」（大写 L）时，scheme-langserver 给出了多个可选项，并且将类型匹配程度较高的「length-a」、「length-b」放到了比较靠前的位置——因为「&gt;=」过程（也就是其他语言中的函数）要求变量必须是「real?」，而上文可以推断出「length-a」、「length-b」为「integer?」类型。</p><p><img alt="" height="1152" src="https://oscimg.oschina.net/oscnet/up-a0cf3214c3d3f798bd3281120b07eb57f92.png" width="732" referrerpolicy="no-referrer"></p><p>这项工作的主要特点在于：</p><ol><li>使用了作者自行开发的 DSL（Domain Specific Language）和解释器实现类型推断功能。这大大降低了编写相关功能的难度，让整个项目的可维护性更强；</li><li>基于 scheme-langserver 的面向「未完成代码」的自动补全功能，能够补全局部变量（这在一些竞品中是不能实现的）；</li><li>实现了「渐进定型」实现为动态类型语言的类型推导。关于这一点，可以看如下案例：</li></ol><p>例如对于 javascript 代码，参数 a 的类型是不清楚的——关于这一点，在 typescript 当中的解决方法是第二行中的案例——添加类型标注（number）。</p><pre><code class="language-javascript">function(a){return 1+a}

function(a : number){return 1+a}</code></pre><p>但是实际上，我们当然知道「+」操作符操作的只能是「number」（当然还有 string 等等）。因此，应当由计算机自行推出「a」的类型为「number」而不需要自行推断（当然，这是有一定的代价和其他问题的）。</p><p>目前这项工作还存在一些问题，主要包括：</p><ol><li>类型推断工作使得索引构建时间较长，较大程度影响用户使用体验；</li><li>类型推断系统引入了一个全排列操作，对于有较多参数（比如 4 个）的过程（或者说函数）的类型推导造成了限制；</li><li>还有大量的测试需要进行，以尽可能减少错误；</li><li>通过一些参数限制了涉及递归函数的类型推断以减少操作间隔感，但是这就在类型推断的可靠性上有了一些问题。</li></ol><p>Scheme-langserver 同时是「2022 中国互联网发展创新与投资大赛公益项目暨 2022 年中国开源创新大赛」二等奖项目。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 16:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267508</guid>
            <link>https://www.oschina.net/news/267508</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「X」Embedding in NLP｜初识自然语言处理（NLP）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>从情感分析到信息提取，再到机器翻译、问答系统、聊天机器人……自然语言处理（Natural Language Processing，NLP）的应用可谓复杂多样。向量数据库的加入，则为 NLP 注入了更多的可能性。</p><p>为了方便大家能够深入了解向量数据库与 NLP 的关系及应用，我们上线了「X」Embedding in NLP 系列专题，分为初阶和进阶两部分。本文为初阶第一篇，将详细介绍 NLP 以及以 Zilliz Cloud、Milvus 为代表的向量数据库是如何为 NLP 赋能的。</p><h2>01.什么是 NLP ？</h2><p>自然语言处理（NLP）是跨学科的机器学习技术，结合了人工智能和计算语言学。其主要目标是让计算机能够以有意义和有价值的方式理解和响应人类语言。</p><p>当然，我们可以构建一个包含所有句子的词典来实现这一目标，但这有些不切实际，因为人类语言中用于构成句子的单词组合无穷无尽。不仅如此，口音、多样的同义词汇、错误发音或句中省略单词等情况，进一步加深了人类语言的复杂性。</p><p>NLP 运用各种技术和算法处理自然语言数据。本质上，NLP 用于处理非结构化数据，特别是非结构化文本，并通过自然语言理解（NLU），使用文本和语音的句法和语义分析来确定句子的含义，并生成计算机可以使用的结构化文本。相反，自然语言生成（NLG）是指计算机根据一些数据输入生成人类语言文本的响应。</p><p>通过利用 NLP 技术，开发人员可以从文本数据中提取信息和洞见，使机器能够理解和响应人类查询，并将所有涉及语言处理的任务自动化。可以说，NLP 使人机交互过程更直观、高效和流畅。NLP 在现实世界中有众多应用，如虚拟助手、聊天机器人、信息检索系统、语言翻译服务、情感分析工具和自动化内容生成等。而向量数据库，尤其是其高效的 embedding 向量存储和检索能力能够为 NLP 领域带来革新，简化相似文档或短语的搜索过程。</p><h2>02.NLP 用例</h2><p>开发人员可以使用 NLP 构建多种应用，包括：</p><h3>情感分析</h3><p>情感分析是指确定文本中表达的情感或情绪。情感分析涉及将文本分类为正面、负面或中性。情感分析技术可能使用机器学习算法在标记数据集上训练模型，或利用预训练模型捕捉单词和短语的情感。情感分析常见的场景之一是电影评论分类，可以统计出正负面的影评占的比例。</p><h3>信息提取</h3><p>信息提取是指从文本中识别特定信息，例如提取名称、日期或数值。信息提取使用命名实体识别（NER）和关系提取从非结构化文本中提取结构化数据。</p><h3>机器翻译</h3><p>NLP 通过利用统计或神经网络机器翻译模型实现机器翻译。这些模型从大量平行文本数据中学习语言之间的模式和关系，允许它们适当借助上下文将文本从一种语言翻译成另一种语言。</p><h3>问答系统</h3><p>问答系统使用 NLP 技术理解用户问题并从给定的文本语料库中检索相关信息。问答系统包含文本理解、文档检索和信息提取等步骤，为用户提供准确和相关的查询答案。</p><h3>虚拟助手或聊天机器人</h3><p>虚拟助手是诸如 Alexa 或 Siri 这样的产品，它们接收人类的话语并从人类语言中推导出命令从而触发动作。（例如：嘿，Alexa，打开灯！）。聊天机器人使用书面语言与人类互动，从而协助用户处理账户或账单问题或其他一般问题。在完成文本处理后，聊天机器人就可以遍历决策树从而做出正确的操作。</p><h3>文本生成</h3><p>NLP 模型可以基于给定的提示或输入生成文本。这包括语言建模、文本摘要和使用诸如循环神经网络（RNN）或 Transformer 模型等技术的文本生成等任务。</p><h3>垃圾邮件检测</h3><p>自然语言处理可以辅助垃圾邮件检测。例如，通过查看过度使用的单词、错误的语法或不适当的紧急声明，检查电子邮件的内容以确定它是否是垃圾邮件。</p><h2>03.NLP 原理</h2><p>NLP 是指通过一系列技术和算法，使计算机能够处理、理解和生成人类语言。以下是 NLP 工作流程：</p><p>文本预处理—— NLP 的初始步骤通常是文本数据的预处理。预处理涉及诸如分段（将句子分解为组成词）、token 化（将文本分割为单个单词或 token）、停用词（去除像停用词和普通词如「the」或「is」这样不携带太多含义的标点）以及应用词干提取（为给定标记推导词干）或词形还原（从字典中获取标记的含义以得到根源）以将单词还原为其基本形式的任务。</p><p>语言理解—— NLP 算法使用各种技术来理解文本的含义和结构。这些技术包括：词性标注（通过为每个单词分配语法标签进行语法分析）、句法解析（分析句子结构）和命名实体识别（识别和分类命名实体，如人物、组织、地点或流行文化参考）等任务。</p><p><em>「观其伴而知其意（You shall know a word by the company it keeps）」</em></p><p>-- 英国语言学家 J. R. Firth</p><h2>04.NLP 模型</h2><p>在大型数据集上接受训练以执行特定 NLP 任务的深度学习模型被称为 NLP 的预训练模型（PTM），它们可以通过避免从头开始训练新模型来帮助下游 NLP 任务。以下是一些著名的自然语言处理模型，以便模型更准确地执行：</p><ul><li><p>BERT（Bidirectional Encoder Representations from Transformer） 是由 Google 开发的自然语言处理模型，可学习文本的双向表示。</p></li><li><p>XLNet 是 CMU 和 Google Brain 团队在 2019 年 6 月份于论文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1906.08237" target="_blank">《XLNet: Generalized Autoregressive Pretraining for Language Understanding》</a>发布的模型。</p></li><li><p>RoBERTa 是 2019 年在论文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1907.11692" target="_blank">《RoBERTa: A Robustly Optimized BERT Pretraining Approach》</a>中被提出的。</p></li><li><p>ALBERT 模型来自 Google 2019 年公布的论文《ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS》。</p></li><li><p>StructBERT 是阿里对 BERT 的一个改进，于 2019 年在论文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1908.04577" target="_blank">《StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding》</a>中提出。</p></li><li><p>PaLM 2 是下一代大语言模型，已经过大量数据训练，能够预测人类输入后的下一个单词。</p></li><li><p>GPT-4 是 OpenAI 开发的多模态大语言模型。它是 GPT 系列中的第四个模型，以其强大的自然语言生成能力而闻名。</p></li><li><p>SentenceTransformers 是一个用于句子、文本和图像 Embedding 的 Python 框架，最初于论文《Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks》中提出。</p></li></ul><h2>05.Zilliz 如何赋能 NLP？</h2><p>开发者正在使用向量数据库革新 NLP 领域。向量数据库能够有效存储和检索 NLP 模型生成的 Embedding <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fglossary%2Fembedding-%25E5%2590%2591%25E9%2587%258F" target="_blank">向量</a>，简化了基于语义相似性寻找相似文档、短语或甚至单个词的过程。此外，使用向量数据库后，开发者可以快速总结 Collection 文档。使用 NLP 算法可以从文本语料库中提取最重要的句子，然后借助 Milvus 便可找到与提取的短语语义上最相似的短语。</p><p>另一个广泛的向量数据库 + NLP 用例就是检索增强生成（Retrieval Augmented Generation，RAG）。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fuse-cases%2Fllm-retrieval-augmented-generation" target="_blank">RAG</a> 通常以聊天机器人的形式出现。大语言模型仅基于公开可用的数据进行训练。因此，它们可能缺乏特定领域知识或者私有信息。开发者可以在 LLM 之外的向量数据库中存储特定领域的数据，进行相似性搜索以返回与用户提问相关的 top-K 结果。最终将这些结果合并发送至 LLM，使其生成准确的答案。</p><h2>06.总结</h2><p>使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fblog%2Fvectordatabase-introduction-milvus" target="_blank">向量数据库</a>，尤其是其高效的 embedding 向量存储和检索能力能够为 NLP 领域带来革新，简化相似文档或短语的搜索过程。NLP 结合了人工智能和计算语言学，帮助计算机理解并响应人类语言，其应用场景广泛，包括虚拟助手、聊天机器人、翻译服务和情感分析等。诸如 BERT、XLNet、RoBERTa、ALBERT 和 GPT-4 之类的 NLP 模型和 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fcloud" target="_blank">Zilliz Cloud</a> 之类的向量数据库能够进一步增强 NLP，简化基于语义相似性检索相似文档或短语的过程。</p><hr><ul><li><p>如果在使用 Milvus 或 Zilliz 产品有任何问题，可添加小助手微信 「zilliz-tech」 加入交流群。</p></li><li><p>欢迎关注微信公众号「Zilliz」，了解最新资讯。</p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 11:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10149535</guid>
            <link>https://my.oschina.net/u/4209276/blog/10149535</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AWebSocket - 基于 OkHttp 封装的 WebSocket]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:left">AWebSocket for Android 一个基于 okhttp 封装的<span>&nbsp;</span><strong>WebSocket</strong>，简洁易用。</p><h2 style="margin-left:0; margin-right:0; text-align:left">Gif 展示</h2><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><img alt="" height="581" src="https://oscimg.oschina.net/oscnet/up-ecbee904460eb28c99bfb586b530b5bbefd.gif" width="300" referrerpolicy="no-referrer"></p><blockquote>&nbsp;</blockquote><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">你也可以直接下载<span>&nbsp;</span><a href="https://gitee.com/link?target=https%3A%2F%2Fraw.githubusercontent.com%2Fjenly1314%2FAWebSocket%2Fmaster%2Fapp%2Frelease%2Fapp-release.apk">演示 App</a><span>&nbsp;</span>体验效果</p><h2 style="margin-left:0; margin-right:0; text-align:left">引入</h2><h3 style="margin-left:0; margin-right:0; text-align:left">Gradle:</h3><ol><li><p style="margin-left:0; margin-right:0">在 Project 的<span>&nbsp;</span><strong>build.gradle</strong><span>&nbsp;</span>或<span>&nbsp;</span><strong>setting.gradle</strong><span>&nbsp;</span>中添加远程仓库</p><div><div><pre><span><strong style="color:#000000">repositories</strong><span>{</span></span><span><span style="color:#888888">//...</span></span><span><span>mavenCentral</span><span>()</span></span><span><span>}</span></span></pre><div style="text-align:center">&nbsp;</div></div></div></li><li><p style="margin-left:0; margin-right:0">在 Module 的<span>&nbsp;</span><strong>build.gradle</strong><span>&nbsp;</span>里面添加引入依赖项</p><div><div><pre><span><span>implementation</span><span style="color:#dd1144">'com.github.jenly1314:awebsocket:1.0.0'</span></span></pre></div></div></li></ol><h2 style="margin-left:0; margin-right:0; text-align:left">使用</h2><h3 style="margin-left:0; margin-right:0; text-align:left">主要使用示例</h3><div style="text-align:left"><div><pre><span><span style="color:#888888">//初始化 AWebSocket</span></span><span><strong>val</strong><strong style="color:#336699">aWebSocket</strong><span>=</span><strong style="color:#445588">AWebSocket</strong><span>(</span><span>url</span><span>)</span></span><span><span style="color:#888888">// 设置监听</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">setWebSocketListener</strong><span>(</span><strong>object</strong><span style="background-color:#ffadad; color:#a61717">: </span><strong style="color:#445588">WebSocketListener</strong><span>()</span><span>{</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onOpen</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>response</span><span>:</span><strong style="color:#445588">Response</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onOpen</strong><span>(</span><span>webSocket</span><span>,</span><span>response</span><span>)</span></span><span><span style="color:#888888">// TODO 连接成功，可以进⾏通信了</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>text</span><span>:</span><strong style="color:#445588">String</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>,</span><span>text</span><span>)</span></span><span><span style="color:#888888">// TODO 接收消息</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>bytes</span><span>:</span><strong style="color:#445588">ByteString</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>,</span><span>bytes</span><span>)</span></span><span><span style="color:#888888">// TODO 接收消息</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onClosing</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>code</span><span>:</span><strong style="color:#445588">Int</strong><span>,</span><span>reason</span><span>:</span><strong style="color:#445588">String</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onClosing</strong><span>(</span><span>webSocket</span><span>,</span><span>code</span><span>,</span><span>reason</span><span>)</span></span><span><span style="color:#888888">// TODO 连接关闭中</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onClosed</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>code</span><span>:</span><strong style="color:#445588">Int</strong><span>,</span><span>reason</span><span>:</span><strong style="color:#445588">String</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onClosed</strong><span>(</span><span>webSocket</span><span>,</span><span>code</span><span>,</span><span>reason</span><span>)</span></span><span><span style="color:#888888">// TODO 连接已关闭</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onFailure</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>t</span><span>:</span><strong style="color:#445588">Throwable</strong><span>,</span><span>response</span><span>:</span><strong style="color:#445588">Response</strong><span>?)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onFailure</strong><span>(</span><span>webSocket</span><span>,</span><span>t</span><span>,</span><span>response</span><span>)</span></span><span><span style="color:#888888">// TODO 连接出错</span></span><span><span>}</span></span><span><span>})</span></span><span><span style="color:#888888">// 连接</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">connect</strong><span>()</span></span><span><span style="color:#888888">//---------------------------</span></span><span><span style="color:#888888">//...</span></span><span><span style="color:#888888">// 发送消息</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">send</strong><span>(</span><span>data</span><span>)</span></span><span><span style="color:#888888">//---------------------------</span></span><span><span style="color:#888888">//...</span></span><span><span style="color:#888888">// 关闭连接</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">close</strong><span>()</span></span></pre></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">更多使用详情，请查看<a href="https://gitee.com/jenly1314/AWebSocket/blob/master/app">Demo</a>中的源码使用示例或直接查看<a href="https://gitee.com/link?target=https%3A%2F%2Fjitpack.io%2Fcom%2Fgithub%2Fjenly1314%2FAWebSocket%2Flatest%2Fjavadoc%2F">API 帮助文档</a></p><h3 style="margin-left:0; margin-right:0; text-align:left">相关推荐</h3><p style="margin-left:0px; margin-right:0px; text-align:left"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fjenly1314%2FANetty">ANetty</a><span>&nbsp;</span>基于 Netty 封装的 Android 链路通讯库，用以快速开发高性能，高可靠性的网络交互。在保证易于开发的同时还保证其应用的性能，稳定性和伸缩性。</p><p style="margin-left:0px; margin-right:0px; text-align:left"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fjenly1314%2FASocket">ASocket</a><span>&nbsp;</span>一个 TCP/UDP 协议的封装库，方便快速实现 TCP 的长连接与 UDP 的单播、组播、广播等相关通信。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 10:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/awebsocket</guid>
            <link>https://www.oschina.net/p/awebsocket</link>
        </item>
        <item>
            <title>
                <![CDATA[微软开源 Terminal Chat]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fcommandline%2Fterminal-chat-in-windows-terminal-canary%2F" target="_blank">宣布</a>开源其 AI 聊天功能 Terminal Chat 的工作，邀请开发人员尝试体验并参与构建。「Windows Terminal 团队致力于提高透明度，我们希望让开源社区有机会帮助我们定义 terminal 应用程序中的人工智能。」</p><p><span style="color:#000000">Terminal Chat 是 Windows Terminal Canary 中的一项功能，允许用户保持在 terminal 上下文中的同时，与 AI 服务聊天以获得智能建议（例如查找命令或解释错误消息）。</span></p><p><img alt="" height="323" src="https://oscimg.oschina.net/oscnet/up-7d85ccd13aaf667d1c3ebcd092187c83cf8.png" width="500" referrerpolicy="no-referrer"></p><p>值得注意的是，Windows Terminal Canary 不提供默认模型或内置 AI 模型。因此要使用 Terminal Chat，用户必须手动在 Windows Terminal Canary 的 Terminal Chat 设置中添加 AI 服务端点和密钥。</p><p>目前，Terminal Chat 仅支持 Azure OpenAI 服务。要获取必要的 Azure OpenAI 服务端点和密钥，用户需要创建和部署 Azure OpenAI 服务资源。</p><p><img alt="" height="337" src="https://oscimg.oschina.net/oscnet/up-3418831b63a1cef6ad618521d5e8e233d0f.png" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="319" src="https://oscimg.oschina.net/oscnet/up-2698239a8126cd25a2f1bab83a5f1c0f605.png" width="500" referrerpolicy="no-referrer"></p><p style="text-align:left"><span><span><span><span><span style="color:#333333"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Windows Terminal Canary 仅在用户发送消息时与 AI 服务进行通信，聊天记录和用户活动 shell 的名称也会附加到发送给 AI 服务的信息中。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>Terminal Chat&nbsp;<span><span><span><span><span style="color:#333333"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>结束后，Windows Terminal Canary 不会保存聊天历史记录。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:left"><span style="color:#000000"><span style="background-color:#ffffff">微软方面表示，他们知道「AI in a terminal」听起来令人生畏，因此他们将致力于提高透明度并积极听取用户反馈。「我们坚信，开源社区的加入将帮助我们确定人工智能路线图，并帮助我们确定可用于核心产品 Windows Terminal 的最基本的 AI 功能集。」</span></span></p><p style="text-align:left"><span style="color:#000000">Terminal Chat&nbsp;<span style="background-color:#ffffff">功能目前仅在 Windows Terminal Canary 中提供，不会包含在 WindowsTerminal 预览版或 Windows Terminal 稳定版的构建中。</span></span></p><p style="text-align:left"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fterminal%23installing-windows-terminal-canary" target="_blank"><span style="color:#2980b9"><span style="background-color:#ffffff">下载地址</span></span></a></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 09:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267428/terminal-chat-in-windows-terminal-canary</guid>
            <link>https://www.oschina.net/news/267428/terminal-chat-in-windows-terminal-canary</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[假如你是开源项目维护者，遇到这种回复能忍到哪步？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>背景：</p><p>Vant 是一个轻量、可定制的移动端组件库，由有赞团队开源。近日，一名开发者在 Vant 的 GitHub 仓库提交了一个 issue：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyouzan%2Fvant%2Fissues%2F12453" target="_blank">https://github.com/youzan/vant/issues/12453</a></u></em>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d12cf1220dd6a3686fc370d6999fa3ad16f.png" referrerpolicy="no-referrer"></p><hr><p>直奔主题，请阅读这名开发者与维护者的问答互动：</p><p>Vant 维护者对该 issue 先是进行了如下回复：</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-9b703d704225830325c310edc6473fdd774.png" referrerpolicy="no-referrer"></p></blockquote><p>提问者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-e6c785757085efeac52ec4017730e405587.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-6b53e369e0f7047d703165ef2353d69ef98.png" referrerpolicy="no-referrer"></p><p>提问者（询问项目维护者这到底是不是 bug）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a454d0c5ff658f495c0a716bfa806fea64.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img height="296" src="https://oscimg.oschina.net/oscnet/up-2d3f37ca3537caa4910f618b2ac40813283.png" width="1684" referrerpolicy="no-referrer"></p><p>提问者（没得到自己想要的答案，开始阴阳怪气）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-7548ef7e9f27dbe02d902b21a805d3c2b83.png" referrerpolicy="no-referrer"></p><p>项目维护者（准备到此为止）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-cfa1f12f75fcdcc6f4445236b19400921df.png" referrerpolicy="no-referrer"></p><p>提问者继续追问：</p><p><img src="https://oscimg.oschina.net/oscnet/up-2ac7c06681f933d411c766346ba126c3860.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-717a1ca2200a63fe14ace932a3754887966.png" referrerpolicy="no-referrer"></p><p>提问者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-30cdb4ece4857089a0c6033e18b4d439231.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-945eaa18e070e9c15264da20b49d0cd9978.png" referrerpolicy="no-referrer"></p><p>最后一个来回：</p><p><img src="https://oscimg.oschina.net/oscnet/up-7617f52c138888233e08e5aedb53a49a012.png" referrerpolicy="no-referrer"></p><p>然后，这名提问者去社区发帖分享了「一次 github 跟开源大佬的抬杠经历」。</p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv2ex.com%2Ft%2F993100" target="_blank">https://v2ex.com/t/993100</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 07:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267411</guid>
            <link>https://www.oschina.net/news/267411</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LineageOS 全球安装量达 150 万台]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LineageOS 团队日前在知名数码 UP 主 MKBHD 播客中回顾了 LineageOS 的历史，<strong>并介绍称目前全球有 150 万台 Android 设备采用 LineageOS</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-45aadd76321a77a1392775596a7127e39cd.png" referrerpolicy="no-referrer"></p><p>LineageOS 是一个面向智能手机和平板电脑的自由、免费、开源的 Android 系统分支。它是深受欢迎的定制 ROM CyanogenMod 的继任者，在 2016 年首次推出，至今仍在积极更新。</p><p>LineageOS 可在不同 Android 品牌的各种不同设备上使用，包括谷歌、HMD Global、三星、索尼、一加、小米等，这款&nbsp;ROM&nbsp;也让一些久远的品牌继续前行，例如早期的 Essential Phone、LG 等。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 07:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267410</guid>
            <link>https://www.oschina.net/news/267410</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[基于 Triple 实现 Web 移动端后端全面打通]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><h1 style="line-height: 1.75em;margin-bottom: 8px;" data-mpa-powered-by="yiban.io"><img class="rich_pages wxw-img" data-backh="81" data-backw="578" data-ratio="0.14106583072100312" src="https://oscimg.oschina.net/oscnet/c03fcfd2-fd29-4f40-8a8b-fbc8acf7f63e.gif" data-w="638" style="outline: 0px;display: initial;visibility: visible !important;width: 677px !important;" referrerpolicy="no-referrer"></h1><section style="margin-bottom: 40px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 14px;">作者：陈有为，陌陌研发工程师、Apache Dubbo PMC</span></em></span></section><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">01</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">RPC 协议开发微服务</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Aliware</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/11f88a4a-39b5-4f5e-9496-4101a228839b.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">在我们正常开发微服务的时候，传统 RPC 服务可能在最底层。上层可能是浏览器、移动端、外界的服务器、自己的测试、curl 等等。我们可能会通过 Tomcat 这种外部服务器去组装我们的 RPC 层，也就是 BFF。或者我们没有 BFF，我们的 RPC 就是对外提供服务。但因为浏览器要访问，所以我们需要有一个网关，比如说 APISIX 或者 ShenYu 等 HTTP 网关。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/79eae4dd-4c7e-45d4-b382-3b7e0fbd8e7a.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">上图展示的是我们的流程，但是存在一些问题。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">如果我们的服务是非常轻的，我们只需要一个转发层，无论是配网关还是起一个 webserver 去转发，怎么做都很麻烦。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">此外，RPC 服务大部分都是基于二进制的，而二进制正常在本地是没法测试的。因此我们的公司内都可能就会开发一种后台或者中间的 Proxy 代理让我们去测试。但这个的前提是你至少得把它部署到测试环境，所以还是没法在本地测试。</span><o:p></o:p></section><p style="line-height: 1.75em;margin-bottom: 40px;"><span style="font-size: 15px;">总体来说，这两个问题会导致易用性比较低，且开发成本相对较高，因为要做一些与业务无关的重复劳动。</span></p><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">02</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">全新升级的 Triple 协议</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Apache Dubbo</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;"></span><o:p></o:p></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/601481f3-b469-46d3-a9e5-6bd230a68166.png" data-type="png" data-w="832" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;" referrerpolicy="no-referrer"><br></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">基于上边的两个问题，我们来介绍一下 Triple 协议。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">先来说一下上一代协议，它产出的原因是什么。我们应该都知道 Dubbo 原来是 Dubbo 协议，它是基于 tcp 的，它只有一个包。因为它的包的设计，导致了网关无法做一些特殊规则判断、过滤等操作。但也不是绝对的，如果你愿意牺牲性能把包完全解出来，组装回去再透传还是可以做到的，但一般大家都不太能接受。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">所以我们就在想能不能把原数据和真正的包分开。现在我们有现成的 HTTP，又有一个业界主流的 gRPC，所以我们的目标就是兼容 gRPC。因为 gRPC 目前都是用 IDL，而 IDL 有一个问题，尤其在 Java 侧。因为大家都是写一些接口，定义一些包去实现，这样就会非常麻烦。Go 侧就还好，因为大家已经习惯了这种开发模式。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">所以我们开发了 Triple 协议，<strong>首先它兼容了 gRPC，</strong>所以我们能实现和 gRPC 的完全互通。<strong>其次，我们兼容了自己定义接口的方法。</strong>虽然会损失一定的性能，但提升了一些易用性。而且 RPC 一般不是业务的瓶颈，大多数瓶颈还是在 DB。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">但还有个问题，虽然我们兼容了 gRPC，但 gRPC 是基于 TPC 的，所以如果前端或者其他第三方系统只有 HTTP，它还是接受不了我们的系统。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/979f4ac2-7a4e-423f-9b1b-b4073e2170ac.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;text-align: left;margin-bottom: 24px;"><span style="font-size: 15px;">基于此，我们想推出一个全新的 Triple 协议。为了解决上述的所有问题，我们参考了 gRPC、gRPC Web、通用 HTTP 等多种协议，做到浏览器访问，支持&nbsp; Streaming，还支持同时运行在 HTTP/1、HTTP/2 协议上。因为目前 HTTP/3 还没有大规模推广，未来也会支持 HTTP/3。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><strong><span style="font-size: 15px;">最终的设计实现是完全基于 HTTP 的，且对人类、开发调试友好。</span></strong><span style="font-size: 15px;">我们可以通过简单的浏览器访问或者 curl 访问，尤其是对 unary RPC。此外，我们和 gRPC 是完全互通的，用 HTTP 的业务不用担心兼容性的问题，也不用担心签协议的问题。为了稳定性，我们只会采用业界流行的网络库，比如 Java 的 native、Go 的基础的 net 包。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/2096d161-0996-43b9-a7ae-13dc12461acf.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;text-align: left;margin-bottom: 24px;"><span style="font-size: 15px;">虽然 Triple 协议和 gRPC 协议都基于 HTTP，但 gRPC 是基于 HTTP/2 的，而 Triple 是基于 HTTP/1 和 HTTP/2 的。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">我们在兼容 gRPC 的同时，我们为了易用性也扩展了一些功能。比如请求里我们支持 Application/Json 的请求格式，支持使用 curl 访问；</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">此外上一版的协议，为了支持传统定义接口的方式，我们有一个二次序列化的过程。我们想在这里通过一个特殊的 content type 来决定我们的 body 的结构，解决二次序列化的问题。同时这个东西是可以扩展的，理论上 HTTP 的所有功能我们在 Triple 协议上都可以实现，也可以拓展。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/df1f6c58-13f2-46f7-be3b-a518882ec9b4.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">用了 Triple 协议之后，我们的开发流程也发生了改变。如果你不需要进行组装，或者没有外层的代理，可能你的接入流程就是从外部的请求浏览器、对方的服务器、curl、自己测试等直接到了 server。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">和其他的 gRPC 的通信也是没有问题的，流程就相当于少了一层。对于大多数用户，如果你不需要这个场景，其实是有很大的好处。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/fbad75ed-0049-4471-83cb-525e33e0e7d0.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;text-align: left;margin-bottom: 24px;"><span style="font-size: 15px;">Triple 协议因为最开始兼容 gRPC，那个时候只基于 HTTP/2，HTTP/2 有 Streaming 的能力，所以它天然支持 Streaming。但这里比较特殊的是，我们新版的协议在 HTTP/1 也支持了 Stream，但因为 HTTP/1 的限制只能支持到 Server Streaming。依赖 HTTP/1 的 Server Push 实现。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/3fc79407-e890-4793-a290-6b9f3bc67dd8.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><p style="line-height: 1.75em;margin-bottom: 40px;"><span style="font-size: 15px;">Client Stream 和 Bi Stream 就没什么可说的了。但有一个特别的是，在 Java 侧没有 Bi Stream，从编码上就没有，但从实现上是有的。</span><o:p></o:p></p><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">03</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">Triple 协议开发微服务</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Apache Dubbo</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/e6931bb8-79f4-4cee-91b6-d5d690516fc9.png" data-type="png" data-w="832" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;" referrerpolicy="no-referrer"><br></section><section style="line-height: 1.75em;margin-bottom: 24px;"><strong><span style="font-size: 15px;">目前 Triple 协议比较灵活的支持两种定义方式，分别是 IDL 定义和直接定义。</span></strong><span style="font-size: 15px;">直接定义支持同步、异步、手写。还有比较极端一点的，比如在自己定义接口的时候使用 IDL 生成 protobuf 的类，我们不定义它的 service，只用它的生成的 request 和&nbsp; response 类也是没问题的，Triple 协议会自动识别接口使用 protobuf 还是不使用 protobuf 进行传输。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/5ff5bab2-f311-4755-830d-b20806c7cf14.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Server 就是把它的务实现一下。上图是一个例子，我就直接拿了 API 的组装方式，真正的业务上可能是注解或者 XML 的方式。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ce5be064-8661-47b0-a30b-78efa617ab67.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">因为我们支持了 HTTP 这个标准的协议，理论上我们的测试就会变得很简单。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">因为我们支持 gRPC，所以我们可以用 gRPC curl 去调用我们的服务。但前提是你得有反射服务，然后手动开启一下，它不是默认开启的。然后它就可以通过反射拿到接口的源数据，通过 Json 转成 protobuf 格式发过去。或者我们直接用 Application/Json 的方式直接调过去。这里有一点比较特别的是在 HTTP/1 下我们也可以用 Sreaming。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">另外，因为我们支持 HTTP，理论上所有第三方的 HTTP 客户端都是可以调用的。然后使用 Dubbo 的 Admin 也可以进行测试，前提是你得把它注册上。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/59b1ddfb-d5b9-492f-b5be-19d98ac1becb.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">调用端不管是 POJO 还是 IDL，它们都没有本质的区别。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/7915eb90-8133-4eac-a8a9-d6ed2e3e85c5.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><p style="line-height: 1.75em;margin-bottom: 40px;"><span style="font-size: 15px;">现在我们有了 Triple 协议，但如果这个协议没有承载方也是行不通的。<strong>因此我们还得有一个框架，有一些服务治理才是我们的微服务。</strong>所以服务治理也是微服务中不可或缺的一部分。</span><o:p></o:p></p><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">04</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">Dubbo 为 Triple 协议带来治理能力</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Apache Dubbo</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/31ad4bc8-c9e8-44c6-be77-ee023944fbba.png" data-type="png" data-w="832" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;" referrerpolicy="no-referrer"><br></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Triple 的定位只是 Dubbo 里的其中一个协议，当然你也可以为了兼容性，用原来的 Dubbo 协议或者其他的协议。而且我们支持在同一个端口上开启多个协议，可以按需选择。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/72e291fc-3bce-4ba4-9b31-bd339eca8655.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">同时 Dubbo 为 Triple 提供了多语言的实现。目前会在 Rust、Go、Java、JS、node、Python 这几部分实现官方的实现。这样用户就不用自己根据实验协议的 spec 去实现了。如果你有一些定制需求，比如内部的一些框架，你根据 spec 实现也是可以的。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/f151c36d-888d-4ca4-b78d-c84b36bae333.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Dubbo 和服务框架集成的很好，理论上在开发流程中，尤其是在 Java 侧服务定义、服务治理、服务注册发现等都不用客户来操心，<strong>是开箱即用的。</strong></span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/e615a1a8-d7bb-4f79-b638-1d3b1fc109d6.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Dubbo 提供了丰富的生态，第三方的生态包括 Nacos、Zookeeper 等等，我们不用创新，直接引入相应的包即可。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/08125323-87f5-4957-bf1f-d44ba434892c.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">这是我们使用 Triple 协议服务注册的例子。上面你可以选 Nacos、Zookeeper、K8s，左边是一个 Client 和一个 Server，这么调用。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/67f6ea46-946c-46a0-a6e4-64776c71c3a6.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">我们在 admin 上看一下实现。这里提一句，我们的 admin 也在新版重构，是用 Go 实现的，大家可以期待一下。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/8bbb56ce-98c2-42b0-91d9-54c1b7a18255.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">我们经常会遇到灰度发布或者流量染色的需求。我们可以从 admin 上发一个 tag 治理规则下去，然后把一些实例打上 tag，然后这个携带 tag 的流量就从入口就会挨个传递下去，从而实现全链路的流量染色。</span><o:p></o:p></section><p style="display: none;margin-bottom: 24px;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Apache Dubbo（ApacheDubbo）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 04:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6214966/blog/10116068</guid>
            <link>https://my.oschina.net/u/6214966/blog/10116068</link>
            <author>
                <![CDATA[ApacheDubbo]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软 CEO：Sam Altman 可能会重返 OpenAI]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Sam Altman 在被 OpenAI 公司解雇后宣布转投微软，但这一决定并非板上钉钉。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2F2023%2F11%2F20%2F23969586%2Fsam-altman-plotting-return-open-ai-microsoft" target="_blank">The Verge</a> 援引多位知情人士消息称，如果解雇 Altman 的其余董事会成员下台，他和联合创始人 Greg Brockman 仍愿意重返 OpenAI。</span></p><p><span style="color:#000000">与此同时，微软首席执行官 Satya Nadella 在接受</span><span style="color:#333333"></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Falexeheath%2Fstatus%2F1726741601278681400" target="_blank">CNBC</a><span style="color:#333333"><span>&nbsp;</span>和<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ftechnology%2Fstatus%2F1726751929475150226" target="_blank">Bloomberg TV</a><span style="color:#333333"><span>&nbsp;</span></span><span style="color:#000000">采访时也明确表示，</span>Altman 可能会以某种身份重返 OpenAI。</p><p>他在被问及&nbsp;<span style="color:#000000">Altman 以及 700 名 OpenAI 员工是否会加入微软时回答道，「这取决于 OpenAI 董事会、管理层和员工的选择」。并表示，无论他们是去是留，他都对这两种选择持开放态度。「显然，如果 Sam 和 Greg 不打算留在 OpenAI，我们希望他们有一个美好的归宿。」</span></p><p><img height="281" src="https://oscimg.oschina.net/oscnet/up-dc4fe464c1a2cd2a935cf44d7d8bd62f0c8.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">关于「明天谁会是 OpenAI 的 CEO」的直白提问，Nadella 也依旧是同样的回答："我会把这个问题留给 OpenAI 和它的董事会"。</span></p><p><span style="color:#000000">此外，当被问及微软是否需要在 OpenAI 董事会中占有一席之地时，他则表示，OpenAI 的治理方面必须做出一些改革，微软方面将就此与其董事会进行对话，并随着事态的发展而逐步推进解决这个问题。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">目前，被认为是此次 「政变」 组织者的 OpenAI 首席科学家 Ilya Sutskever 已经改变了主意，签署联名信要求 </span>Altman 回归。因此，<span style="background-color:#ffffff">OpenAI 剩下的三名董事会成员中只需要有两人反转就能让 Altman 回归。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267384/microsoft-ceo-sam-altman-plotting-return-open-ai</guid>
            <link>https://www.oschina.net/news/267384/microsoft-ceo-sam-altman-plotting-return-open-ai</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TypeScript 5.3 正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TypeScript 5.3 已正式发布。</p><p><strong>主要变化</strong></p><ul><li><p>支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-import-attributes">import attributes</a>&nbsp;提案的最近更新</p></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Ftypescript%2Fannouncing-typescript-5-3%2F%23stable-support-resolution-mode-in-import-types" target="_blank">在 Import Types</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Ftypescript%2Fannouncing-typescript-5-3%2F%23stable-support-resolution-mode-in-import-types" target="_blank">中提供对<code>resolution-mode</code>的稳定支持</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Ftypescript%2Fannouncing-typescript-5-3%2F%23resolution-mode-supported-in-all-module-modes" target="_blank">为所有 Module Modes</a>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Ftypescript%2Fannouncing-typescript-5-3%2F%23resolution-mode-supported-in-all-module-modes" target="_blank">提供</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Ftypescript%2Fannouncing-typescript-5-3%2F%23resolution-mode-supported-in-all-module-modes" target="_blank"><code>resolution-mode</code>支持</a></li><li><p><code>switch (true)</code>Narrowing</p></li><li><p>Narrowing On Comparisons to Booleans</p></li><li><p>检查对实例字段的<code>super</code>属性访问</p></li><li><p>针对类型的交互式嵌套提示 (Interactive Inlay Hints)</p></li><li><p>跳过 JSDoc 解析以进行优化</p></li><li><p>合并<code>tsserverlibrary.js</code>和<code>typescript.js</code></p></li></ul><hr><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-import-attributes">import attributes</a></strong></p><p>import attributes 的一个用例是向运行时提供有关模块预期格式的信息。</p><pre><code class="language-javascript">// We only want this to be interpreted as JSON,
// not a runnable/malicious JavaScript file with a `.json` extension.
import obj from "./something.json" with { type: "json" };
</code></pre><p>TypeScript 不会检查这些属性的内容，因为它们是特定于主机的，因此不会对它们进行检查，只是让浏览器和运行时处理它们（可能会出错）。</p><pre><code class="language-javascript">// TypeScript is fine with this.
// But your browser? Probably not.
import * as foo from "./foo.js" with { type: "fluffy bunny" };
</code></pre><p>动态 import () 调用也可以通过第二个参数使用 import 属性。</p><pre><code class="language-javascript">const obj = await import("./something.json", {
    with: { type: "json" }
});
</code></pre><p>第二个参数的预期类型由一个名为<code>ImportCallOptions</code>的类型定义，默认情况下，该类型只期望调用一个属性<code>with</code>。</p><p>请注意，导入属性是从早期的 "导入断言"（import assertions）提案演变而来的，该提案已在 TypeScript 4.5 中实现。最明显的区别是使用了<code>with</code>关键字而非<code>assert</code>关键字。但不太明显的区别是，运行时现在可以自由使用属性来指导导入路径的解析和解释，而导入断言只能在加载模块后断言某些特性。</p><p>随着时间的推移，TypeScript 将淘汰旧的导入断言语法，转而使用建议的导入属性语法。使用 assert 的现有代码应迁移到 with 关键字。需要导入属性的新代码应只使用<code>with</code>关键字。</p><p><strong><code>switch (true)</code>Narrowing</strong></p><p>TypeScript 5.3 可以根据<code>switch (true)</code>中每个<code>case</code>子句的条件执行 narrowing。</p><pre><code class="language-javascript">function f(x: unknown) {
    switch (true) {
        case typeof x === "string":
            // 'x' is a 'string' here
            console.log(x.toUpperCase());
            // falls through...

        case Array.isArray(x):
            // 'x' is a 'string | any[]' here.
            console.log(x.length);
            // falls through...

        default:
          // 'x' is 'unknown' here.
          // ...
    }
}
</code></pre><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Ftypescript%2Fannouncing-typescript-5-3%2F" target="_blank">详情查看发布公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 03:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267382/typescript-5-3-ga</guid>
            <link>https://www.oschina.net/news/267382/typescript-5-3-ga</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中国操作系统调研]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" height="566" src="https://static.oschina.net/uploads/space/2023/1121/112104_Mhtw_3820517.jpg" width="400" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.qq.com%2Fsheet%2FDQ2hmWHpJdk1WYUl3%3Ftab%3DBB08J2" target="_blank">https://docs.qq.com/sheet/DQ2hmWHpJdk1WYUl3?tab=BB08J2</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 03:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267381</guid>
            <link>https://www.oschina.net/news/267381</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米 2023Q3 财报：总收入 709 亿，研发支出 50 亿]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">小米 2023 Q3 财报现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FopJuLdveNeZPOCiYcNAHkw" target="_blank">公布</a>：总收入 709 亿元，本季重回正增长。经调整净利润 60 亿元，同比增 182.9%。智能电动汽车等创新业务投入 17 亿元。小米持续大规模投入底层核心技术，Q3 研发支出 50 亿元，同比增长 22.0%，研发人员占比已超过 53%。</span></p><p><span style="color:#000000">雷军表示：「作为一家科技公司，小米始终将'技术为本'列为铁律，我们下定决心大规模研发底层核心技术，坚定不移投入其中。我们有充足的现金储备来支持持续创新，本季度末，小米现金总储备达人民币 1276 亿元，又一次创下新高。」</span></p><p><span style="color:#000000">公告指出，本季度小米研发支出人民币 50 亿元，同比增长 22.0%。该公司还计划五年之内（2022-2026）将投入研发 1000 亿元人民币。人才梯队方面，截至第三季度末，小米的工程师人数占比已经超过了 53%。小米的新十年目标（2020-2030）为：大规模投入底层核心技术，致力成为全球新一代硬核科技引领者。</span></p><p><span style="color:#000000">小米智能手机业务在本季度重回增长，全球市占率达 14.1%，连续 3 个季度环比提升。全球智能手机出货量为 4180 万台，同比增长 4.0%，环比增长 27.0%。IoT 业务实现了收入和毛利率的同步增长。Q3 IoT 与生活消费产品收入达到人民币 207 亿元，同比增长 8.5%，毛利率则创下历史新高，达到 17.8%，同比提升 4.3 个百分点。</span></p><p><span style="color:#000000">互联网业务总收入达人民币 78 亿元，创历史新高，毛利率为 74.4%，同比提升 2.3 个百分点。广告收入创下历史新高，达人民币 54 亿元；游戏业务连续 9 个季度实现收入同比增长，达人民币 11 亿元。境外互联网业务本季度收入达到人民币 23 亿元，同比增长 35.8%，占整体互联网收入的比例为 30.0%，同比提升 5.8 个百分点。</span></p><p><span style="color:#000000">本季度，小米全球 MIUI 月活用户达 6.23 亿，同比增长 10.5%；中国大陆 MIUI 月活用户达 1.52 亿，同比增长 7.4%。</span></p><p><span style="color:#000000"><img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-84bfe07342c57c14fda453f243618d607d5.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-24b5b3d9caa05b951e0825aed1626215466.png" width="300" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267376</guid>
            <link>https://www.oschina.net/news/267376</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[发动 OpenAI 「政变」幕后黑手浮出水面：Quora 联合创始人 Adam]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据报道，随着局势日渐明朗，此次宫斗大剧的幕后黑手指向了 OpenAI 董事会成员、问答网站 Quora 联合创始人亚当·德安格洛（Adam D'Angelo），是他煽动并拉拢了公司首席科学家伊尔亚·苏茨克维（Ilya Sutskever）一起驱逐山姆·奥尔特曼（Sam Altman）。</p><p><strong>OpenAI 董事会背景</strong></p><p><img src="https://static.oschina.net/uploads/space/2023/1121/111403_8DJZ_2720166.png" referrerpolicy="no-referrer"></p><p>有人指出，德安格洛不满原因奥尔特曼的原因与 11 月初 OpenAI 开发者大会宣布的 GPTs 有关，德安格洛认为自己创办的 AI 机器人产品 Poe 将会被 GPTs 所淘汰，<strong>他对身为董事会成员却没有提前得知 GPTs 的存在而感到不满</strong>，觉得奥尔特曼不该对自己保密。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-d6576cd6d0b5a4521931becb8dedd5bf47b.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fwilliamlegate%2Fstatus%2F1726715671487156554" target="_blank">https://twitter.com/williamlegate/status/1726715671487156554</a></u></em></p></blockquote><p>据说德安格洛现在正忙着和律师商量应对方案。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ebba8bbe70d3d6091986c34281eacfde3b8.png" referrerpolicy="no-referrer"></p><p>公开资料显示，德安格洛出生于 1984 年，他被《财富》杂志誉为「科技界最聪明的人之一」，大学去了被誉为"天才"摇篮的加州理工，毕业后成为 Facebook 的第一任 CTO，后创办全球领先问答网站 Quora。他 2016 年上了《福布斯》杂志 40 岁以下最富有企业家排行榜。</p><p>此外，在纳德拉宣布 OpenAI 创始人奥尔特曼和格雷格・布罗克曼将<u><a href="https://www.oschina.net/news/267272">加入</a></u>微软领导新的 AI 研究团队后，微软股价盘前大涨 57%。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 03:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267375</guid>
            <link>https://www.oschina.net/news/267375</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
