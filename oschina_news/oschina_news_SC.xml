<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 27 Nov 2023 23:09:37 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[龙芯发布 .NET 8 SDK 8.0.100-ea1（试用版）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>龙芯 .NET 编译器团队发布了龙芯 .NET 8 SDK-8.0.100-ea1（试用版）。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ad83ed3331e20d86735205af7cae82b757f.png" referrerpolicy="no-referrer"></p></blockquote><p>2023 年 11 月 21 日龙芯发布 LoongArch64 架构的 .NET 8.0-SDK 基于上游社区 .NET 8.0-SDK 制作，在生命周期维护范围内，会持续进行更新升级。</p><ul><li><p>龙芯 LoongArch64 版 .NET 8 下载地址：<u><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.loongnix.cn%2Fzh%2Fapi%2Fdotnet" target="_blank">http://www.loongnix.cn/zh/api/dotnet</a></u></p></li><li><p>开发过程中可能需要依赖一些平台相关的 nupkg 资源，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnuget.loongnix.cn%2F" target="_blank">可在龙芯 Nuget 源搜索下载</a></u>。</p></li><li><p>相关配置方法见<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.loongnix.cn%2Fdotnet%2Fsupport%2Flist%2F01.%25E5%25B8%25B8%25E8%25A7%2581%25E9%2597%25AE%25E9%25A2%2598-FAQ.html" target="_blank">龙芯 Nuget 源配置方法</a></u>。</p></li></ul><p>特性更新：</p><ul><li>同步上游社区 v8.0.100&nbsp;新特性。</li></ul><p>关键更新:</p><ul><li><p>同步上游社区 v8.0.100&nbsp;更新。</p></li><li><p>默认开启&nbsp;<code>DOTNET_TC_QuickJitForLoops</code>，支持 OSR 堆栈替换特性。</p></li><li><p>默认集成 PE32 + 格式 System.Private.CoreLib.dll 核心库文件，提升了 .NET8.0 SDK 在 LoongArch64 平台上的性能表现。</p></li><li><p>支持 crossgen2 特性。</p></li></ul><p>龙芯平台 .NET 是龙芯公司基于开源社区 .NET 独立研发适配的龙芯版本，官方称会长期进行安全更新和错误修复，并持续进行性能优化。</p><p>社区 .NET 7 版本开始已经原生支持 LoongArch64 架构源码，具备如下特性：</p><ul><li><p>跟进社区最新版本，获取及时的安全更新和问题修复</p></li><li><p>支持多 OS：Loongnix、Loongnix-Server、统信 UOS、银河麒麟等 64 位操作系统</p></li><li><p>支持 LoongArch 架构</p></li><li><p>明确的、多版本的产品维护计划</p></li><li><p>专业团队支持</p></li></ul><p>从龙芯 2019 年启动 .NET 的研发工作，2022 年完成了 LoongArch64 架构代码合并到 .NET 社区主干分支上，2023 年 LoongArch64 架构代码的开发完全和社区同步，从而保证了同时发布 LoongArch64 的 .NET 8。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268322</guid>
            <link>https://www.oschina.net/news/268322</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox 在 2023 变得更快了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Mozilla 官方博客最近<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhacks.mozilla.org%2F2023%2F10%2Fdown-and-to-the-right-firefox-got-faster-for-real-users-in-2023%2F">发表文章</a>，称 2023 年 Firefox 在提升用户体验方面取得了显著的进展，真实用户使用 Firefox 能感受到速度更快。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-48c6863ad3edd6c093cc619549ed7f30c35.png" referrerpolicy="no-referrer"></p><p>据介绍，Firefox 通过收集与<strong>页面加载、响应速度、启动</strong>等浏览器性能相关的匿名化时间度量指标来衡量用户体验。文章分享了一些对用户浏览器体验至关重要的指标在一年中是如何改进的。</p><ul><li><h4><strong>优化页面加载速度</strong></h4></li></ul><p>Firefox 使用 "First Contentful Paint (FCP)" 这个指标来衡量用户感知的性能。FCP 指的是从网络接收到第一个字节到页面显示内容的时间。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-16ba708b843784921085bfebb7aede81380.png" referrerpolicy="no-referrer"></p><p>数据显示，从年初的大约 250 毫秒，到十月份的 215 毫秒，<strong>页面加载速度提高了约 15%</strong>。这意味着用户能够更快地收到页面加载的反馈信息。</p><ul><li><h4><strong>优化 JavaScript 执行时间</strong></h4></li></ul><p>Firefox 还关注页面加载过程中 JavaScript 代码的执行时间。</p><p>数据显示，95% 的页面中 JavaScript 执行时间从年初的约 1560 毫秒，到十月份的约 1260 毫秒，速度提升了约 20%。这对于减少页面加载时间起到了重要作用。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-180320b8057907172e172bf066f77cc7c79.png" referrerpolicy="no-referrer"></p><ul><li><h4><strong>优化键盘响应速度</strong></h4></li></ul><p>Firefox 还关注页面加载后的响应速度。更具体来说，它关注键盘按下后到屏幕上显示结果的时间。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-19618b78169525abf4262e888f93daec3dc.png" referrerpolicy="no-referrer"></p><p>数据显示，95% 的页面中键盘响应速度从年初的约 65 毫秒，到八月份的约 59 毫秒，速度提升了约 10%。这意味着用户在键入时能够更快地得到反馈，减少了打字时的延迟。</p><p>Firefox 团队表示，通过这些数据可以看出 Firefox 在 2023 年取得了用户体验方面的显著改善。这些改进是通过优化浏览器的性能和 JavaScript 引擎实现的。Firefox 团队还表示他们将继续努力进行更多的优化，并在未来的文章中分享更多细节和进展。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 12:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268242/firefox-got-faster-for-real-users-in-2023</guid>
            <link>https://www.oschina.net/news/268242/firefox-got-faster-for-real-users-in-2023</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[浪潮发布基础大模型「源 2.0」，千亿参数全面开源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>浪潮信息<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrjnsUS83TT7aEN3r2i0IPQ" target="_blank">发布</a></u>「源 2.0」基础大模型，并宣布全面开源</strong>。</p><p>据介绍，源 2.0 基础大模型包括 1026 亿、518 亿、21 亿等三种参数规模的模型，在编程、推理、逻辑等方面展示出了先进的能力。</p><p><strong>算法方面</strong>，源 2.0 提出并采用了一种新型的注意力算法结构：局部注意力过滤增强机制 (LFA：Localized Filtering-based Attention)。LFA 通过先学习相邻词之间的关联性，然后再计算全局关联性的方法，能够更好地学习到自然语言的局部和全局的语言特征，对于自然语言的关联语义理解更准确、更人性，提升了模型的自然语言表达能力，进而提升了模型精度。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184848_muAm_2720166.png" referrerpolicy="no-referrer"></p><p><strong>数据方面</strong>，源 2.0 通过使用中英文书籍、百科、论文等高质量中英文资料，降低了互联网语料内容占比，结合高效的数据清洗流程，为大模型训练提供了高质量的专业数据集和逻辑推理数据集。</p><p>据称，为了更高效地获得相对匮乏的高质量中文数学及代码数据集，源 2.0 采用了基于大模型的数据生产及过滤方法，在保证数据的多样性的同时也在每一个类别上提升数据质量，获取了一批高质量的数学与代码预训练数据。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184918_iLAq_2720166.png" referrerpolicy="no-referrer"></p><p><strong>算力方面</strong>，源 2.0 采用了非均匀流水并行的方法，综合运用流水线并行+优化器参数并行+数据并行的策略，让模型在流水并行各阶段的显存占用量分布更均衡，避免出现显存瓶颈导致的训练效率降低的问题，该方法显著降低了大模型对芯片间 P2P 带宽的需求，为硬件差异较大训练环境提供了一种高性能的训练方法。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184932_0UiQ_2720166.png" referrerpolicy="no-referrer"></p><p>源 2.0 在业界公开的评测上进行了代码生成、数学问题求解、事实问答方面的能力测试，下面是测试结果：</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184945_PzyP_2720166.png" referrerpolicy="no-referrer"></p><p><strong>源 2.0 采用全面开源策略，全系列模型参数和代码均可免费下载使用</strong>。</p><ul><li>代码开源链接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0</a></em></u></li><li>论文链接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0%2Fblob%2Fmain%2Fdocs%2FYuan2.0_paper.pdf" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/Yuan2.0_paper.pdf</a></em></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268384</guid>
            <link>https://www.oschina.net/news/268384</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[字节跳动成立新部门 Flow，发力 AI 应用层]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">36 氪报道称，</span><span style="background-color:#ffffff; color:#222222">字节跳动近期成立了一个新 AI 部门 Flow，技术负责人为字节跳动技术副总裁洪定坤。</span></p><p><span style="background-color:#ffffff; color:#222222">一位知情人士表示，这一新部门的业务带头人，为字节大模型团队的负责人朱文佳。Flow 主要聚焦在 AI 应用层。在字节圈内，Flow 近期发布了活水招聘帖，社会招聘也已经开始一段时间。</span></p><p><span style="background-color:#ffffff; color:#222222">在帖中，其表示是字节跳动旗下 AI 创新业务团队，「目前已经在国内和海外分别上线豆包和 Cici 两款产品，有多个 AI 相关创新产品孵化中」。截止发稿前，字节跳动尚无回应。</span></p><p style="color:#262626; margin-left:0; margin-right:0; text-align:justify">在 11 月初，字节各个事业部都进行了不少业务和架构调整，这些调整仍在进行中，当前 Flow 的架构和汇报线未完全确定。且多位知情人士透露，在此次调整中，字节也从飞书、抖音等各个 BU 抽调人选，到这一部门做一款新的 C 端产品。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268383</guid>
            <link>https://www.oschina.net/news/268383</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云原生周刊：Kubernetes 1.29 中的删除、弃用和主要更改]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyonahd%2Forphaned-configmaps" target="_blank">Orphaned ConfigMaps</a></h3><p>该版本库包含一个脚本，用于识别 Kubernetes 命名空间中的孤立的配置映射。孤立的配置映射是指那些未被命名空间中的任何活动 Pod 或容器引用的配置映射。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmarvasgit%2Fkubernetes-multicooker" target="_blank">Kubernetes Multi Cooker</a></h3><p>该项目包含一个小型 Kubernetes 控制器，用于监视每个节点的 CPU 压力；当超过某个阈值时，节点将被污染（这样就不会在已经超载的节点上调度额外的工作负载），最后控制器将开始从该节点驱逐 Pod。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Femberstack%2Fkubernetes-reflector" target="_blank">Reflector</a></h3><p>Reflector 是一个 Kubernetes 插件，旨在监视资源（秘密和配置映射）的更改并反映相同或其他命名空间中镜像资源的更改。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubernetes.io%2Fblog%2F2023%2F11%2F16%2Fkubernetes-1-29-upcoming-changes%2F" target="_blank">Kubernetes 1.29 中的删除、弃用和主要更改</a></h3><p>和其他每次发布一样，Kubernetes v1.29 将弃用和移除一些特性。一贯以来生成高质量发布版本的能力是开发周期稳健和社区健康的证明。本文列举即将发布的 Kubernetes 1.29 中的一些弃用和移除事项。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-storage-provider-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 大存储提供商工具</a></h3><p>这篇文章介绍了 Kubernetes 的五个存储提供者工具：SeaweedFS、Vitess、TiKV、Rook 和 OpenEBS。这些工具帮助管理 Kubernetes 上的数据工作负载，包括卷供应、复制、备份、加密、压缩和性能调优等功能。它们与 Kubernetes API 和概念无缝集成，并支持持久卷（PV）、持久卷声明（PVC）和存储类（Storage Class）。这篇文章详细介绍了每个工具的工作机制、优势以及在实际使用中的案例和成功故事。通过阅读这篇文章，读者可以了解 Kubernetes 上可用的存储提供者选项，并根据自己的需求选择最合适的工具。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.atatus.com%2Fblog%2Ftroubleshooting-kubernetes-deployment%2F" target="_blank">对各个级别的 Kubernetes 部署进行故障排除</a></h3><p>这篇文章是关于在各个层面上解决 Kubernetes 部署问题的指南。文章首先介绍了 Kubernetes 作为容器编排的事实标准，并提到了它自动化部署、扩展和管理容器化应用程序的能力。然而，即使遵循最佳实践并具备专业知识，Kubernetes 部署有时也是一个复杂而具有挑战性的过程。文章探讨了从应用代码到基础设施和 Kubernetes 组件的各个层面上的部署故障排除过程，并介绍了一些常见问题和挑战，如容器镜像拉取错误、Pod 调度问题、网络连接问题和存储问题。文章还讨论了一些诊断和解决这些问题的最佳实践和工具。通过阅读这篇文章，读者将更好地了解如何在 Kubernetes 部署的每个层面上进行故障排除，并更好地管理其应用程序。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F11%2F20%2Fannouncing-the-platform-engineering-maturity-model%2F" target="_blank">CNCF 平台工程成熟度模型出炉</a></h3><p>CNCF（Cloud Native Computing Foundation）的平台工程成熟度模型首次发布。该模型提供了对平台工程成熟度的具体应用，是今年 4 月份发布的备受欢迎的白皮书的延伸。该模型将平台工程定义为通过在构建平台和其能力的各个方面（包括人员、流程、策略和技术）进行投资，提供内部平台作为产品的实践，从而推动业务结果。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloudnativenow.com%2Ftopics%2Fcloudnativedevelopment%2Fmicrosoft-expands-scope-of-azure-kubernetes-services%2F" target="_blank">微软扩大 Azure Kubernetes 服务范围</a></h3><p>Microsoft 已普遍推出 Azure Kubernetes Fleet Manager，以便更轻松地集中管理多个集群，并可与一组用于优化成本的工具一起分阶段进行。</p><p>与此同时，除了预览 Azure 容器应用程序平台的扩展以增加对事件的支持之外，微软还使用 Kubernetes AI 工具链运算符简化在 Azure Kubernetes 服务 (AKS) 上部署大型语言模型 (LLM) 的过程用于训练 AI 模型的驱动框架，同时支持开源 Qdrant、Milvus 和 Weaviate 矢量数据库。</p><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10293895</guid>
            <link>https://my.oschina.net/u/4197945/blog/10293895</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[What's new in dubbo-go-pixiu v1.0.0]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>dubbo 原生网关 dubbo-go-pixiu v1.0 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Freleases%2Ftag%2Fv1.0.0-rc2" target="_blank">https://github.com/apache/dubbo-go-pixiu/releases/tag/v1.0.0-rc2</a> 正式发版了，项目从 2019 年一路走来，四年磨剑，感谢从，铁城、张天，到 吕梦超，三位负责人。</p><p>目前，dubbo-go-pixiu 可作为 dubbo/dubbogo 服务网关，也可作为 dubbo/dubbogo 服务的 sidecar，还额外基于 Istio v1.14.3 实现了 dubbo 的控制面。</p><p>dubbo-go 和 dubbo-go-pixiu 在 2023 年初被蚂蚁集团采用内部容器 PAAS HCS(Hyper Container Service) 超级容器平台的微服务技术底座， v1.0.0 集成了蚂蚁集团使用过程中的提交的很多改进和优化。感谢本次版本的主要贡献者，胡潇晗、樊凡、龚娜、张国强、【阿里】远云、【蚂蚁】多航、王虓雄、望哥、于雨，等社区同学。</p><h1>1 New Features In v1.0.0</h1><h2>1.1 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F548" target="_blank">Triple 支持传递 Header 和引入 PB 定义</a></h2><p>Triple 代理现在可以正确传递 header 到 Triple 服务，且支持通过引入 protoset 文件来支持未开启 Proto 反射或不支持反射的特定 proto，例如使用旧版本编译的或 gogoproto 编译的服务。</p><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftriple" target="_blank">https://github.com/apache/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/triple</a></p><h2>1.2 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F554" target="_blank">负载均衡 Maglev hashing</a></h2><p>负载均衡支持新算法：Maglev hashing。Maglev 是 Google 开发的基于 kernal bypass 技术实现的 4 层负载均衡，它具有非常强大的负载性能，承载了 Google 绝大部分接入流量。Maglev 在负载均衡算法上采用自行开发的一致性哈希算法被称为 Maglev Hashing，该哈希算法在节点变化时能够尽量少的影响其他几点，且尽可能的保证负载的均衡，是一个非常优秀的一致性哈希算法。</p><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshawnh2%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftraffic" target="_blank">https://github.com/shawnh2/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/traffic</a></p><h2>1.3 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F565" target="_blank">Router 支持 Header 路由</a></h2><p>Router 支持通过 header 路由，可以更方便的管理流量。</p><pre><code class="language-yaml">              http_filters:
                  - name: dgp.filter.http.traffic
                    config:
                      traffics:
                        - name: "user-v1"
                          router: "/user"
                          canary-by-header: v1
                          canary-weight: 0
                        - name: "user-v2"
                          router: "/user"
                          canary-by-header: v2
                          canary-weight: 100
</code></pre><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshawnh2%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftraffic" target="_blank">https://github.com/shawnh2/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/traffic</a></p><h2>1.4 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F571" target="_blank">错误注入</a></h2><p>支持对特定 API 做错误注入，例如返回固定的响应，施加随机性的延时/错误等。</p><pre><code class="language-yaml">                http_filters:
                  - name: dgp.filter.http.faultinjection
                    config:
                      fail_inject_rules:
                        "/UserService/com.dubbogo.pixiu.UserService/GetUserByCode":
                          type: delay
                          trigger_type: random
                          status_code: 500
                          body: 'error'
                          delay: 5s
                          odds: 30
</code></pre><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fblob%2Fdevelop%2Fdocs%2Fsample%2Fothers%2Ffail-inject.md" target="_blank">https://github.com/apache/dubbo-go-pixiu/blob/develop/docs/sample/others/fail-inject.md</a></p><h2>1.5 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F522" target="_blank">Add GracefulShutdown Signal For Windows</a></h2><p>支持 Windows 优雅下线，Pixiu 关闭时避免流量损失。</p><pre><code class="language-yaml">static_resources:
.......
.......
  shutdown_config:
    timeout: "60s"
    step_timeout: "10s"
    reject_policy: "immediacy"
</code></pre><p>配置方式参考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fshutdown" target="_blank">https://github.com/apache/dubbo-go-pixiu-samples/tree/main/shutdown</a></p><h1>2 Enhancement in v1.0.0</h1><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F573" target="_blank">优化 Prometheus 指标上报</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F530" target="_blank">修复一致性 Hash 数组越界</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F521" target="_blank">优化 Timeout 时的 http status code</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F528" target="_blank">优化 Metric 推拉模式</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F524" target="_blank">优化 Nacos 客户端启动时的参数配置</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F517" target="_blank">修复特定 Filter 配置为空时的 NPE 问题</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F515" target="_blank">升级 wasmer-go v1.0.4 以支持 Mac ARM 版本</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F506" target="_blank">fix sample url using github.com/apache/dubbo-go-pixiu-samples</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F507" target="_blank">修复流量管理路由权重计算错误的问题</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F513" target="_blank">修复负载均衡在特定情况下无法正常工作的问题</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F574" target="_blank">移除无用的 imports</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F575" target="_blank">chore: unnecessary use of fmt.Sprintf</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F567" target="_blank">chore:use wasm filter build tags add wasm</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F556" target="_blank">修复无法错误的 samples 链接等</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F557" target="_blank">revert gatewayCmd to Run dubbo go pixiu</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F516" target="_blank">升级 hessian2 依赖到 v1.11.3</a></li></ul><h1>3 参考文档</h1><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRwIA7TitRfUMU8rTI4JsBg" target="_blank">What's new in dubbo-go-pixiu v0.6.0</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5syzT64koPV77aRh04Izsw" target="_blank">What's new in dubbo-go-pixiu 0.5.1</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fdok42ssPJqazjeSRYaifVw" target="_blank">What's new in dubbo-go-pixiu 0.4.0</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC7TxU0Zbee7EZ_6SJOLK8w" target="_blank">Dubbo 跨语言调用神兽：dubbo-go-pixiu</a></li></ul><h1>4 社区</h1><p>欢迎钉钉扫码加入 dubbogo 社区钉钉群【钉钉群号 23331795】进行交流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ff09984b6821a6da40dcdb6db415fcca4b8.png" alt="" referrerpolicy="no-referrer"></p><p>以及 dubbogo 社区微信公众号：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8feb2024cbf754333e9d7564cd0316dbb71.jpg" alt="" referrerpolicy="no-referrer"></p><p>从今年开始，除了以往负责的 dubbogo 社区项目外，于雨还负责了 pika 项目 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenAtomFoundation%2Fpika" target="_blank">https://github.com/OpenAtomFoundation/pika</a>)，如果对该项目感兴趣，请扫码：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3e900aa69386ac2190edb8035f4abb68415.png" alt="" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/dubbogo/blog/10294380</guid>
            <link>https://my.oschina.net/dubbogo/blog/10294380</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 内核开发人员争论基于优先级的 Shutdown 支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Pengutronix 嵌入式 Linux 咨询公司的 Oleksij Rempel 上周五发布了一系列<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F2023112403-laxative-lustiness-6a7f%40gregkh%2FT%2F" target="_blank">补丁</a>，提出了针<span style="background-color:#ffffff">对驱动程序/硬件的</span>基于优先级的 shutdown 支持。</span></p><p><span style="color:#000000">主要目的是<span style="background-color:#ffffff">在主线 Linux 内核提供优先关闭</span><span style="background-color:#ffffff">特定设备的功能</span>，「这在 power loss&nbsp;等情况下尤为重要，如果处理不当，可能会造成硬件损坏」。</span></p><p><span style="color:#000000">其内容<span style="background-color:#ffffff">重点在于，在</span>意外/<span style="background-color:#ffffff">即时&nbsp;shutdown&nbsp;</span>事件（例如电源/电压下降或完全断电）期间正确关闭关键设备。作为补丁系列的一部分，Oleksij Rempel&nbsp;还提出在 shutdown 阶段将 (e)MMC 存储设备设置为更高优先级，以帮助确保数据完整性/损坏。</span></p><p><img height="334" src="https://oscimg.oschina.net/oscnet/up-4ea11ce65c8b13c903a1f017372e8425e3b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Oleksij Rempel 的这一想法引发了 Linux 内核开发人员间的激烈讨论，并形成了<span style="background-color:#ffffff">两极分化的看法。</span><span style="background-color:#ffffff">Greg Kroah-Hartman&nbsp;</span>首先对这种基于优先级的<span style="background-color:#ffffff">&nbsp;shutdown&nbsp;</span>支持提出了质疑。他指出，这一做法会导致驱动程序和子系统之间出现优先级的争夺：</span></p><blockquote><p><span style="color:#000000">每个驱动程序和子系统都坚持认为自己是最重要的！</span></p><p><span style="color:#000000">总之，从长远来看，这样做会带来很多问题，这些硬件有什么特别之处能使得其不可以按照现有顺序 shutdown，而必须比其他人"优先"？这样做究竟是为了防止什么，哪些设备需要这样做？</span></p><p><span style="color:#000000">最重要的是，在过去的 20 多年中，有什么变化导致突然需要这种新功能，其他操作系统是如何处理的？</span></p></blockquote><p><span style="color:#000000">观点双方就<span style="background-color:#ffffff">主线 Linux 内核是否应该具有这样的功能，以有效解决有问题的硬件设计做出了很多讨论。最后事实证明，一些用于汽车行业的外层 Linux 内核版本已经提供了这种优先 shutdown 支持。Oleksij Rempel 将这一需求总结为：</span></span></p><blockquote><p><span style="color:#000000">它能防止硬件损坏。在典型的汽车欠压测试中，通常可以在 Y 个欠压周期内重现 X 个损坏的 eMMC 或 NAND（我现在没有确切的数字）。即使在人工测试中出现的数量不是很多（有时一个月的测试中就会出现一个损坏的设备），但现场的回报率也很高，足以让我们关心这个问题的软件解决方案。</span></p><p><span style="color:#000000">同样的问题不仅出现在汽车设备上，也出现在工业或农业设备上。换句话说，这个问题非常重要，必须要有某种解决方案。</span></p></blockquote><p><span style="color:#000000">对此，<span style="background-color:#ffffff">Greg 则用反问的语气调侃称，「这么说的话，硬件试图依靠软件来防止同一硬件遭到破坏？硬件设计师肯定没那么疯狂吧？」</span></span></p><p><span style="color:#000000">科技网站 Phoronix <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FLinux-Priority-Based-Shutdown" target="_blank">评论</a>称，从较高层次上来看，如果设备/驱动程序有充分的理由希望优先为设备 shutdown&nbsp;做好准备，例如可以防止数据丢失或获得其他重大优势，那么这种基于优先级的 shutdown&nbsp;支持似乎没有问题。但在实践中，如果有多个驱动程序声称在 shutdown&nbsp;过程中拥有"优先权"，并且在确保设计可靠且能妥善解决实际问题方面存在其他障碍，那么具体的实现就会存在一些困难。</span></p><p><span style="color:#000000">目前为止，大家对这种方法的意见还很不统一。现阶段能否设计出一种既能为主线所接受，又能满足汽车和更广泛的嵌入式/工业领域需求的适当解决方案，还有待观察。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268371/linux-priority-based-shutdown</guid>
            <link>https://www.oschina.net/news/268371/linux-priority-based-shutdown</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LG 成立 webOS 开发小组]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LG 电子宣布改革组织架构，并成立 webOS 开发小组。</p><p>11 月 24 日，LG 电子<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lgnewsroom.com%2F2023%2F11%2Flg-electronics-announces-organizational-restructuring-for-future-growth%2F" target="_blank">发布公告</a></u>称将改革组织架构，以提升竞争力、促进增长。重组计划包括为国际业务建立一个新的销售和营销公司，由 LG 电子北美公司前总裁兼首席执行官 Thomas Yoon 负责，管理世界各地的销售子公司，以及直接面向消费者（D2C）的销售业务集团。</p><p>此外，LG 家庭娱乐公司将成立 webOS 软件开发小组，提高这一智能电视操作系统的实力，由该公司总裁直接领导；还将设立总部直属的 XR 事业部。家电和空气解决方案公司将增设工程销售部门，并入其他部门的家居业务，以与家庭空间现有的产品阵容产生协同效应。车辆零部件解决方案公司将设立总部直属的全球客户战略部。</p><blockquote><p><img height="400" src="https://oscimg.oschina.net/oscnet/up-cdf9a79048dc46240b393d4e2278760273b.png" width="1728" referrerpolicy="no-referrer"></p></blockquote><p>webOS 是基于 Linux 内核的智能电视操作系统，其前身是由&nbsp;Palm&nbsp;所开发的智能手机操作系统，最早于 2009 年面向公众发布。2010 年惠普收购 Palm，但之后终止了 Palm 手机和操作系统项目，并在 2011 年<u><a href="https://www.oschina.net/news/23908/hp-make-webos-opensource">决定开源</a></u>&nbsp;webOS。</p><p>2013 年，LG 宣布收购惠普 webOS 部门，包括系统源代码和雇员等。此后该操作系统被 LG 用于智能电视和电冰箱等产品。</p><p><img alt="080830_QqVe_2720166.png" src="https://static.oschina.net/uploads/space/2021/0302/080830_QqVe_2720166.png" referrerpolicy="no-referrer"></p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/131577/lg-says-it-will-license-webos-to-other-tv-mak">LG 将授权 webOS 给其他电视厂商使用</a></li><li><a href="https://www.oschina.net/news/94374/lg-webos-open-source-edition">LG 宣布推出 webOS 开源版本，仍寻求将其商业化</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 06:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268346</guid>
            <link>https://www.oschina.net/news/268346</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[三个月写了个短信平台，开源出来！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-e82e722c7dca4558ca6271436d0dcfe9665.png" alt="" referrerpolicy="no-referrer"></p><h1>1 初心</h1><p>大家好，我是勇哥。花了三个月的时间，我手写了个短信平台服务 <code>platform-sms</code>，今天开源出来 Beta 版本。</p><p>写这个开源项目的初心其实很简单："<strong>帮助初中级研发工程师入门架构设计，提升他们的技术认知</strong>"。</p><p>2018 年，作为架构师，我参与一个短信平台的重构。发送短信的场景包括还款业务、CRM、促销业务等。</p><p>不同的技术团队都是使用客户端模式发送短信，但并不统一，大概分为四种 ：</p><ul><li>使用阿里云提供的短信 SDK 发送短信 。</li><li>根据亿美提供的样例直接发送短信 。</li><li>使用绿城提供的短信 SDK 发送短信。</li><li>架构团队短信 SDK ，类似于 <code>SMS4J</code>的设计方式，支持亿美、绿城短信发送 。</li></ul><p>客户端的模式在多团队协作场景中，缺点还是很明显：</p><ul><li><p><strong>维护成本</strong></p><p>假如运营不再使用某一个短信渠道，那么很多团队将会收到影响，不得不配合重新修改配置，重新上线，耗费的时间成本很高。</p></li><li><p><strong>无法支持高级功能</strong></p><p>客户端实现某些功能比较麻烦，比如：客户端因为偶发情况（网络原因）通过三方渠道发送短信超时，此时需要将短信发送到备份渠道，从而确保短信发送的成功率。</p></li></ul><p>因此，多团队协作的场景中，短信服务的模式应该是<strong>服务端模式</strong>。</p><p><img src="https://javayong.cn/pics/sms/server.png?a=23212" alt="服务端模式" referrerpolicy="no-referrer"></p><p>我参考了腾讯云的短信服务的设计思路 ：</p><ol><li>模仿腾讯云的 SDK 设计，提供简单易用的发送短信方法 （单发，群发，营销单发，营销群发，模板单发，模板群发） ；</li><li>设计短信服务 API 端，接收发短信请求，发送短信信息到消息队列；</li><li>worker 服务消费消息，按照负载均衡的算法，调用不同渠道商的短信接口；</li><li>控制枱可以查看短信发送记录，配置渠道商信息、模版信息等。</li></ol><p><img src="https://oscimg.oschina.net/oscnet/up-a7b05e5217cc92a8d6b17b9741ebb961d66.png" alt="" referrerpolicy="no-referrer"></p><p>短信平台研发完成之后，满足了当时的业务需求，因为短信的管理也归于统一，提升了业务接入短信服务的效率，所以各个技术团队也比较认可。</p><p>随着经验的累积，我见过了不少公司的短信服务，核心问题不外乎两点：</p><ol><li><p>短信服务与业务服务边界问题。</p><p>为了满足业务服务需求，在短信平台中添加过多的业务功能，导致短信服务功能臃肿，也不经意的加入了隐藏的风险 。</p></li><li><p>切换三方渠道非常不方便。</p><p>当运营端需要从三方短信渠道 A 切换到 B 时，因为代码不够抽象，增加三方渠道代码时维护成本较高。</p></li></ol><p>基于这些原因，我想写一个<strong>迷你版</strong>的短信服务，它应该包含如下的功能：</p><ol><li><p>简单的短信 SDK 支持按照模版发送短信 。</p><p>业务服务对于短信是从哪一个三方短信渠道发送出来的并不在乎，只需要确保发送短信的成功率即可。</p><p>因此，SDK 提供的核心接口是：<strong>按照模版编号发送短信</strong>。</p><p>阿里云、腾讯云、华为云提供的都是按照模版发送短信的接口，为了统一管理模版，我们也只提供按照模版发送短信的接口。</p><p>短信平台需要提供业务服务的<code>appKey</code> 和<code>appSecret</code> , SDK 与服务端之间通过固定协议交互。</p></li><li><p>短信平台支持模版的管理 。</p><p>阿里云、腾讯云、华为云都提供签名、模版管理的接口，因此从产品设计层面，理论上，我们可以通过短信平台管理所有的签名和模版。</p><p>短信平台当前提供了手工绑定的短信模版的功能，也就是我们需要先在阿里云或者腾讯云先申请签名和模版，然后绑定到我们在平台创建的模版。</p></li><li><p>适配器模式维护三方短信渠道。</p><p>参考了开源项目<code>canal</code>的适配器模块，将三方短信渠道的 API 独立成模块单独维护，这样可以大大提升代码的可维护性。</p></li></ol><h1>2 架构</h1><p>项目的设计应该设计得简单，因为它的目标首先是让<strong>初中级工程师快速入门架构设计</strong>。</p><p>所以，我将短信平台设计成<strong>单体应用</strong>的模式，架构图如下：</p><p><img src="https://javayong.cn/pics/sms/smsjiagou.png" alt="" referrerpolicy="no-referrer"></p><p>短信平台分为两个部分，<strong>这两部分可以独立部署，也可以将前端文件放置在后端中，生成单部署包。</strong></p><p><strong>1、前端：admin-ui</strong></p><p>控制枱模块是 vue 项目，管理员登录之后可以进行应用管理、渠道管理、短信管理、模版管理。</p><p><strong>2、后端：admin-web</strong></p><p>后端模块按照功能依次分为五个模块：请求控制层、业务服务层、命令处理器、三方渠道适配器插件、数据库访问层。</p><h1>3 演示</h1><h2>3.1 环境准备</h2><p><strong>1、创建数据库以及相关表</strong></p><p>创建数据库<code>tech_platform</code> ，执行<code> doc/sql</code> 目录下的 <code> tech_platform.sql</code>。</p><p>执行后效果如下：</p><p><img src="https://javayong.cn/pics/sms/tables.png" alt="" referrerpolicy="no-referrer"></p><p><strong>2、修改部署包配置</strong></p><p>从 Release 下载 <code>platform-sms-admin.tar.gz</code> ，解压缩后，进入 <code>conf </code>目录 。</p><p><img src="https://javayong.cn/pics/sms//adminconfdir.png" alt="" referrerpolicy="no-referrer"></p><p>编辑 <code>application.yml </code> 文件：</p><p><img src="https://javayong.cn/pics/sms//prepare.png" alt="" referrerpolicy="no-referrer"></p><p>进入 bin 目录，启动服务：</p><pre><code class="language-sh">bin/startup.sh
</code></pre><h2>3.2 操作流程</h2><p><strong>1、登录页面</strong></p><p>服务启动后，访问地址：<code>http://localhost:8089</code> 。 <img src="https://javayong.cn/pics/sms/login.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>用户名和密码存储在 <code>conf</code> 目录的 <code>application.yml</code>，默认用户名密码分别是：admin/admin1984 。</p></blockquote><p><strong>2、新建应用</strong><img src="https://javayong.cn/pics/sms/createapp.png" alt="" referrerpolicy="no-referrer"></p><p>应用信息包含应用名称、应用 <code>appKey</code> , <code>应用秘钥</code>，<code>备注</code>。其中，应用 key 和，密钥在使用客户端 SDK 时需要配置 。</p><p><strong>3、新建三方短信渠道</strong><img src="https://javayong.cn/pics/sms/createchannel.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>注意：因为腾讯云的 SDK 请求，中需要携带 APPID ，所以 Beta 版中将 appId 存储在，附件属性中。</p></blockquote><p><strong>4、创建模版</strong> 在<code>模版管理</code>模块，点击<code>新建模版</code>按钮。</p><p><img src="https://javayong.cn/pics/sms/createtemplate.png" alt="" referrerpolicy="no-referrer"></p><p><strong>新建模版时，签名名称必须和渠道申请的签名必须一致。</strong></p><p>下图展示了笔者的腾讯云申请的签名，笔者创建的模版必须和腾讯云账号的签名保持一致。</p><p><img src="https://javayong.cn/pics/sms/tencentsign.png" alt="" referrerpolicy="no-referrer"></p><p>创建完模版之后，需要绑定渠道，我们需要在三方渠道先创建短信模版，然后提交绑定。</p><ol><li>三方渠道先创建短信模版</li></ol><p><img src="https://javayong.cn/pics/sms/applytencenttemplate.png" alt="" referrerpolicy="no-referrer"></p><p>如上图，笔者创建了编号为 1955325 的短信模版，因为我们需要在绑定界面绑定该渠道的模版，理论上在短信平台创建的模版可以绑定多个渠道。</p><ol start="2"><li><strong>绑定渠道</strong></li></ol><p><img src="https://javayong.cn/pics/sms/bingdingtemplate.png" alt="" referrerpolicy="no-referrer"></p><p>绑定完成之后，可以在模版管理页面查看模版列表 。</p><p><img src="https://javayong.cn/pics/sms/templatelist.png" alt="" referrerpolicy="no-referrer"></p><h2>3.3 发送短信</h2><p>发送短信可以参考 DEMO 模块：</p><p><img src="https://javayong.cn/pics/sms/demoproject.png" alt="" referrerpolicy="no-referrer"></p><p><strong>1、添加依赖</strong></p><pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.courage&lt;/groupId&gt;
    &lt;artifactId&gt;platform-sms-client&lt;/artifactId&gt;
    &lt;version&gt;${parent.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p><strong>2、客户端配置</strong></p><p>首先在 <code>application.yml </code>中配置如下：</p><pre><code class="language-yaml">sms:
  smsServerUrl: http://localhost:8089
  appKey: qQjEiFzn80v8VM4h
  appSecret: 9c465ece754bd26a9be77f3d0e2606bd
</code></pre><p>然后编写配置类：</p><pre><code class="language-java">@Configuration
public class SmsConfiguration {

    @Value("${sms.smsServerUrl}")
    private String smsServerUrl;

    @Value("${sms.appKey}")
    private String appKey;

    @Value("${sms.appSecret}")
    private String appSecret;

    @Bean
    public SmsSenderClient createClient() {
        SmsConfig smsConfig = new SmsConfig();
        smsConfig.setAppKey(appKey);
        smsConfig.setSmsServerUrl(smsServerUrl);
        smsConfig.setAppSecret(appSecret);
        SmsSenderClient smsSenderClient = new SmsSenderClient(smsConfig);
        return smsSenderClient;
    }

}

</code></pre><p><strong>3、单发短信</strong></p><pre><code class="language-java">@Autowired
private SmsSenderClient smsSenderClient;

@GetMapping("/test")
public String test() {
    // 手机号
    String mobile = "15011319235";
    // 短信平台模版编号
    String templateId = "555829270636703745";
    // 模版参数
    Map&lt;String, String&gt; param = new HashMap&lt;String, String&gt;();
    param.put("code", "1234");
    param.put("time", "10");
    SmsSenderResult senderResult = smsSenderClient.sendSmsByTemplateId(mobile, templateId, param);
    System.out.println("senderResult:" + JSON.toJSONString(senderResult));
    return "hello , first short message !";
}
</code></pre><p>调用接口之后，用户就会收到如下的短信：</p><p><img src="https://javayong.cn/pics/sms/sendsmssucceed.png?b" alt="" referrerpolicy="no-referrer"></p><h1>4 开源</h1><p><img src="https://javayong.cn/pics/sms/platformsmsgithub.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>代码库地址：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmakemyownlife%2Fplatform-sms" target="_blank">https://github.com/makemyownlife/platform-sms</a></p></blockquote><p>勇哥想把这个项目做为架构入门的教学项目，您可以从中学到 ：</p><ol><li>设计一个精简的客户端 SDK 。</li><li>理解 SPI 机制以及适配器模式。</li><li>配置合理的线程模型。</li></ol><hr><p>如果我的文章对你有所帮助，还请帮忙<strong>点赞、在看、转发</strong>一下，你的支持会激励我输出更高质量的文章，非常感谢！</p><p><img src="https://javayong.cn/pics/shipinhao/gongzhonghaonew.png" alt="" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 03:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/makemyownlife/blog/10243610</guid>
            <link>https://my.oschina.net/makemyownlife/blog/10243610</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[报告：16% 的 AI 工作者正在使用开源模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">O'Reilly 发布的一份"<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fae.oreilly.com%2FGenerative_AI_in_the_Enterprise" target="_blank">2023 Generative AI in the Enterprise</a>"报告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3711380%2Fgenerative-ai-adoption-speed-unprecedented-oreilly-survey-says.html" target="_blank">指出</a>，由 OpenAI 的 GPT 大型语言模型和 ChatGPT 引领的生成式 AI 浪潮正在经历前所未有的快速普及。</span></p><p><span style="color:#000000">报告基于 2013 年 9 月 14 日至 9 月 23 日期间收到的共 4782 份回复。其中有 2857 名受访者回答了所有问题。74% 的受访者来自北美或欧洲。</span></p><p><img height="415" src="https://static.oschina.net/uploads/space/2023/1127/114145_aRHK_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">有三分之二的受访者表示，他们已经在使用生成式 AI。"我们从未见过一项技术能像生成式 AI 一样被如此快速地采用 -- 很难相信 ChatGPT 才诞生不到一年。"</span></p><p><span style="color:#000000">但与此同时，生成式 AI 技术在采用过程中仍存在一些问题。报告发现，难以找到商业用例以及对法律问题的担忧阻碍了 AI 的发展。AI 解决方案的构思和实施不当可能会造成损害，而使用生成式 AI 的法律后果仍是未知数，例如存在谁拥有 AI 生成结果的版权等问题。</span></p><p><span style="color:#000000">并且一些公司文化还会制约 AI 的应用。另一方面，构建生成式 AI 建设基础设施的难度和高成本也是一个令人担忧的问题。</span></p><p><span style="color:#000000">报告的一些其他发现包括：</span></p><ul><li><span style="color:#000000">54% 的 AI 用户预计 AI 的最大好处是提高生产力。</span></li><li><span style="color:#000000">77% 的受访者使用 AI 来辅助编程。其中提到的具体应用包括欺诈检测、教学和客户关系管理。</span></li><li><span style="color:#000000">AI 用户表示，AI 编程（66%）和数据分析（59%）是最需要的技能。</span></li><li><span style="color:#000000">许多 AI 采用者仍处于早期阶段：26% 的人使用 AI 不到一年，而 18% 的人已经在生产中进行了应用。</span></li><li><span style="color:#000000">16% 的从事 AI 工作的受访者表示正在使用开源模型。</span></li><li><span style="color:#000000">意外结果、安全性、公平性、偏见和隐私是采用者测试的最大风险。</span></li></ul><p><span style="color:#000000">详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fae.oreilly.com%2FGenerative_AI_in_the_Enterprise" target="_blank">查看完整报告</a>。&nbsp;</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268318/generative-ai-in-the-enterprise</guid>
            <link>https://www.oschina.net/news/268318/generative-ai-in-the-enterprise</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Fish Shell 采用 Rust 重写会导致性能下降]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>fish 是适用于 Linux、macOS 的命令行 Shell，其名字取于 "the&nbsp;<strong>f</strong>riendly&nbsp;<strong>i</strong>nteractive&nbsp;<strong>sh</strong>ell" 的简称，最大特点就是方便易用、功能强大、智能并且用户友好。很多其他 Shell 需要配置才有的功能，fish 默认提供，不需要任何配置。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8ac37b9a595ea6b4d16839034fa3b00e68f.png" referrerpolicy="no-referrer"></p><p>项目维护者 Fabian Boehm 今天在 GitHub 回应了<u><a href="https://www.oschina.net/news/226616/fish-shell-be-rewritten-rust">使用 Rust 重写 Fish Shell</a></u>&nbsp;的进度，称已几乎完成。</p><p>根据开发者的说法，他们已经完成了从 C++ 到 Rust 的大部分移植工作，但还有一些剩余的组件需要进行翻译。目前，他们正在处理与输入系统相关的读取器、屏幕处理、输入和分页器等强耦合组件。一旦这些组件完成翻译，剩下的工作就是一些零散的部分和去除构建系统的 C++ 依赖。</p><p>开发者表示，<strong>这不是一个适合临时贡献的项目</strong>，因为还有很多工作要做。</p><p>此外，开发者还回答了一些关于移植的问题和误解。<strong>他们表示不会删除所有的 C++ 代码</strong>，也没有计划移植到 Windows 平台。他们还表示不会更改 Fish Shell 的名称或吉祥物，并且对于最终移植的性能，他们表示早期结果是令人鼓舞的，<strong>但可能在某些情况下会比现有版本慢约 20%</strong>。</p><p>最后，他们提到即使完成了初始移植工作，项目也还有很多工作要做。</p><p>来源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffish-shell%2Ffish-shell%2Fdiscussions%2F10123">https://github.com/fish-shell/fish-shell/discussions/10123</a></u></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 03:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268315</guid>
            <link>https://www.oschina.net/news/268315</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[精选网站流量分析工具]]>
            </title>
            <description>
                <![CDATA[精选网站流量分析工具]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/project/awesome?columnId=65</guid>
            <link>https://www.oschina.net/project/awesome?columnId=65</link>
        </item>
        <item>
            <title>
                <![CDATA[Numbat —— 用于科学计算的静态类型编程语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Numbat 是一种用于科学计算的静态类型编程语言，对物理尺寸和单位具有一流的支持。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>可以使用它进行简单的数学计算：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>&gt;&gt;&gt; 1920/16*9

    = 1080

&gt;&gt;&gt; 2^32

    = 4294967296

&gt;&gt;&gt; sqrt(1.4^2 + 1.5^2) * cos(pi/3)^2

    = 0.512957</code></pre><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>然而，Numbat 的真正优势在于使用物理单位执行计算：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>&gt;&gt;&gt; 8 km / (1 h + 25 min)

  8 kilometer / (1 hour + 25 minute)

    = 5.64706 km/h    [Velocity]

&gt;&gt;&gt; 140 € -&gt; GBP

  140 euro ➞ british_pound

    = 120.768 £    [Money]

&gt;&gt;&gt; atan2(30 cm, 1 m) -&gt; deg

  atan2(30 centimeter, 1 meter) ➞ degree

    = 16.6992°

&gt;&gt;&gt; let ω = 2π c / 660 nm

  let ω: Frequency = 2 π × c / 660 nanometer

&gt;&gt;&gt; ℏ ω -&gt; eV

  ℏ × ω ➞ electronvolt

    = 1.87855 eV    [Energy]</code></pre></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/numbat</guid>
            <link>https://www.oschina.net/p/numbat</link>
        </item>
        <item>
            <title>
                <![CDATA[阿里达摩院撤裁量子实验室，已将实验室及仪器设备赠予浙江大学]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>此前网传阿里巴巴达摩院由于预算及盈利等原因，已经撤裁旗下量子实验室。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f56d238fc4cd0472484cff8074725c56bb7.png" referrerpolicy="no-referrer"></p></blockquote><p>对此，阿里巴巴达摩院相关人士回应九派财经称，为了进一步推动量子科技协同发展，达摩院联合浙江大学发展量子科技，<strong>达摩院将量子实验室及可移交的量子实验仪器设备捐赠予浙江大学</strong>，并向其他高校和科研机构进行开放。</p><p>目前，达摩院量子实验室网站已撤下之前的所有内容 (<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdamo.alibaba.com%2Flabs%2Fquantum%2F%3Flang%3Dzh" target="_blank">https://damo.alibaba.com/labs/quantum/?lang=zh</a></u>)。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1fe3290832247ef64372a3cecccec9e368c.png" referrerpolicy="no-referrer"></p><p>「中国科学院-阿里巴巴量子计算实验室（AQL）」于 2015 年 7 月 30 日揭牌成立，计划在量子信息科学领域开展前瞻性研究，研制量子计算机。根据该联合实验室的研究计划：</p><ul><li><p>预计到 2025 年，量子模拟将达到当今世界最快的超级计算机的水平；</p></li><li><p>到 2030 年，研制具有 50—100 个量子比特的通用量子计算原型机，突破大规模量子计算机的芯片工艺，从物理层设计、制造，到算法运行实现自主研发，全面实现通用量子计算功能，并应用于大数据处理等重大实际问题。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ab648e496bed5f27f8694b13032b63f27da.png" referrerpolicy="no-referrer"></p><p>达摩院此前在该领域进行了长期投入，配置了国际领先的量子实验专用仪器设备，建成 Lab-1、Lab-2 两座硬件实验室，具备量子计算软硬件全栈开发能力。</p><p>除此之外，达摩院在芯片制备、比特相干时长、门操控、量子纠错，量子计算控制架构等领域取得了多个重要成果，包括高精度、多比特超导量子芯片，量子电路经典模拟器「太章」等。</p><hr><p><strong>延伸阅读</strong></p><ul><li><a href="https://www.oschina.net/news/259545" target="news">百度发布首个量子领域大模型</a></li><li><a href="https://www.oschina.net/news/203591/cirq-1-0-released" target="news">谷歌发布量子编程框架 Cirq 1.0 版本</a></li><li><a href="https://www.oschina.net/news/180254/mit-new-language-quantum-computing-twist" target="news">MIT 推出用于量子计算的编程语言 Twist</a></li><li><a href="https://www.oschina.net/news/124369/alibaba-open-source-taizhang-2-0" target="news">阿里开源量子模拟器 「太章 2.0」</a></li><li><a href="https://www.oschina.net/news/122471/china-quantum-hegemony" target="news">中国「量子霸权」成果：比最快超级计算机快一百万亿倍</a></li><li><a href="https://www.oschina.net/news/117459/us-plans-quantum-internet" target="news">美国发布量子互联网蓝图：十年内建成</a></li><li><a href="https://www.oschina.net/news/116574/silq-programming-language-for-quantum-computers" target="news">量子计算机领域内第一种高级编程语言 Silq 诞生</a></li><li><a href="https://www.oschina.net/news/108172/microsoft-quantum-oss-available-github" target="news">微软宣布开源量子开发工具包</a></li><li><a href="https://www.oschina.net/news/98474/google-opensource-cirq" target="news">拥抱新时代，Google 开源量子算法框架 CIRQ</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268299</guid>
            <link>https://www.oschina.net/news/268299</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 轻量级本地化热点检测/降级框架 Akali]]>
            </title>
            <description>
                <![CDATA[<p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fakali.yomahub.com%2F"><img src="https://gitee.com/dromara/Akali/raw/master/static/img/logo-main.svg" height="auto" alt="logo" referrerpolicy="no-referrer"></a></p><h3><a id="user-content-官网 httpsakaliyomahubcom" class="anchor" href="https://gitee.com/dromara/Akali#%E5%AE%98%E7%BD%91httpsakaliyomahubcom"></a>官网：<a href="https://gitee.com/link?target=https%3A%2F%2Fakali.yomahub.com">https://akali.yomahub.com</a></h3><h3><a id="user-content-介绍" class="anchor" href="https://gitee.com/dromara/Akali#%E4%BB%8B%E7%BB%8D"></a>介绍</h3><p>Akali（阿卡丽）是一个轻量级本地化热点检测/降级框架，适用于大流量场景，可轻松解决业务中超高流量的并发查询等场景。并且接入和使用极其简单，10 秒钟即可接入使用！</p><p>Akali 框架的理念就是小巧，实用，来无影去无踪，丝血团战，满血退场，所到之处，皆为虚无。</p><h3><a id="user-content-使用" class="anchor" href="https://gitee.com/dromara/Akali#%E4%BD%BF%E7%94%A8"></a>使用</h3><p>引入依赖：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;dependency&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;groupId&gt;</span>org.dromara<span class="nt">&lt;/groupId&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;artifactId&gt;</span>akali<span class="nt">&lt;/artifactId&gt;</span></span><span id="LC4" class="line"><span class="nt">&lt;version&gt;</span>1.1.3<span class="nt">&lt;/version&gt;</span></span><span id="LC5" class="line"><span class="nt">&lt;/dependency&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-对任意方法进行热点处理" class="anchor" href="https://gitee.com/dromara/Akali#%E5%AF%B9%E4%BB%BB%E6%84%8F%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E7%83%AD%E7%82%B9%E5%A4%84%E7%90%86"></a>对任意方法进行热点处理</h4><p>只需要加上<code>@AkaliHot</code>这个标注，任意方法均可以获得热点检测，并在热点期间用热点数据进行返回，在热点过后，又会自动调用原本业务逻辑。</p><p>举例：比如有一个商品查询的业务，传入 SkuCode，返回商品信息。当某个商品进行促销时，访问的量就会增加，但是对于相同的 SkuCode 而言，其短时间窗口内返回的 SkuInfo 是一致的，我们的目标是当某个商品 sku 被大量查询时，框架能够在短时间内把这个商品 sku 提为热点数据，并通过对其进行缓存返回来降低对下游业务的压力。而当热点值过后，框架又能够自动摘除这个热点值，使其按照原有方式进行查询。</p><p>其本质相当于实时的监测了热点，并对其热点数据做了一个短时间内的缓存。</p><p>以下示例代表了：当相同的 skuCode 在 5 秒内超过 50 次调用时，会自动把这个 skuCode 的值提为热点，并用最后一次的返回值直接返回。当调用低于 5 秒 50 次调用时，框架会自动的摘除掉这个热点。使其正常的调用你原有代码进行逻辑计算并返回。这一切都是自动的。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@AkaliHot</span><span class="o">(</span><span class="n">grade</span><span class="o">=</span><span class="nc">FlowGradeEnum</span><span class="o">.</span><span class="na">FLOW_GRADE_QPS</span><span class="o">,</span><span class="n">count</span><span class="o">=</span><span class="mi">50</span><span class="o">,</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="nc">SkuInfo</span><span class="nf">getSkuInfo</span><span class="o">(</span><span class="nc">String</span><span class="n">skuCode</span><span class="o">){</span></span><span id="LC3" class="line"><span class="c1">//do your biz and return sku info</span></span><span id="LC4" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>其中<code>grade</code>参数除了有以<code>QPS</code>作为维度统计，还有以<code>Thread</code>个数作为维度统计。比如：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@AkaliHot</span><span class="o">(</span><span class="n">grade</span><span class="o">=</span><span class="nc">FlowGradeEnum</span><span class="o">.</span><span class="na">FLOW_GRADE_THREAD</span><span class="o">,</span><span class="n">count</span><span class="o">=</span><span class="mi">50</span><span class="o">,</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="nc">SkuInfo</span><span class="nf">getSkuInfo</span><span class="o">(</span><span class="nc">String</span><span class="n">skuCode</span><span class="o">){</span></span><span id="LC3" class="line"><span class="c1">//do your biz and return sku info</span></span><span id="LC4" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>这就代表了，如果某个 skuCode 在 5 秒之内有超过 50 个线程正在运行，那么就提为热点，并用热点数据直接返回。</p><p>对开源项目比较熟悉的同学看到这肯定想到了京东的框架-<code>hotkey</code>，<code>Akali</code>不同于<code>hotkey</code>，完全是本地运行的，不依赖于服务端，而且接入比<code>hotkey</code> 方便多了。性能完全相当于<code>hotkey</code>。</p><h4><a id="user-content-对任意方法进行降级" class="anchor" href="https://gitee.com/dromara/Akali#%E5%AF%B9%E4%BB%BB%E6%84%8F%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E9%99%8D%E7%BA%A7"></a>对任意方法进行降级</h4><p>只需要加上<code>@AkaliFallback</code>注解。任意方法均可获得降级功能。</p><p>举例：某一个方法需要调用外部的接口，但是外部的接口性能不佳，耗时高。当并发一高时，线程池就会吃满，线程池队列也会逐渐堆积从而导致超时，或者丢弃，严重时会拖垮整个系统。</p><p>这时，我们只要对这个方法加上<code>@AkaliFallback</code>标注，即可解决。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@AkaliFallback</span><span class="o">(</span><span class="n">grade</span><span class="o">=</span><span class="nc">FlowGradeEnum</span><span class="o">.</span><span class="na">FLOW_GRADE_THREAD</span><span class="o">,</span><span class="n">count</span><span class="o">=</span><span class="mi">100</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="nc">String</span><span class="nf">sayHi</span><span class="o">(</span><span class="nc">String</span><span class="n">name</span><span class="o">){</span></span><span id="LC3" class="line"><span class="k">return</span><span class="s">"hi,"</span><span class="o">+</span><span class="n">name</span><span class="o">;</span></span><span id="LC4" class="line"><span class="o">}</span></span><span id="LC5" class="line"></span><span id="LC6" class="line"><span class="kd">public</span><span class="nc">String</span><span class="nf">sayHiFallback</span><span class="o">(</span><span class="nc">String</span><span class="n">name</span><span class="o">){</span></span><span id="LC7" class="line"><span class="k">return</span><span class="s">"fallback str"</span><span class="o">;</span></span><span id="LC8" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>以上注解表示了，当这个方法的同时运行的线程超过 100 个时，触发降级，降级会自动调用<code>原方法名+Fallback</code>方法名 (并且参数要一致)，当降级触发后会直接返回<code>fallback str</code>，当线程数小于 100 时，框架也会自动摘除降级，还是输出<code>hi,xxxx</code>。</p><p>如果你的类中没有定义 fallback 方法，那么触发降级时会报错，当然你可以在降级方法中去抛错，来让上游系统知道你这个方法已经达到了瓶颈。</p><h3><a id="user-content-注意事项" class="anchor" href="https://gitee.com/dromara/Akali#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"></a>注意事项</h3><p>Akali 只针对于 Springboot，Spring 环境，并且所有标注了<code>@AkaliHot</code>或者<code>@AkaliFallback</code>的类一定得注册到 spring 上下文中。</p><p>Akali 在 springboot 中会自动扫描所有标注的类，您无需做任何配置，在 spring 中，你需要配置：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;bean</span><span class="na">class=</span><span class="s">"org.dromara.akali.strategy.FallbackStrategy"</span><span class="nt">/&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;bean</span><span class="na">class=</span><span class="s">"org.dromara.akali.strategy.MethodHotspotStrategy"</span><span class="nt">/&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;bean</span><span class="na">class=</span><span class="s">"org.dromara.akali.spring.AkaliScanner"</span><span class="nt">/&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-交流群" class="anchor" href="https://gitee.com/dromara/Akali#%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>交流群</h3><img src="https://gitee.com/dromara/Akali/raw/master/static/img/chat.png" referrerpolicy="no-referrer">]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/dromara/Akali</guid>
            <link>https://gitee.com/dromara/Akali</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 深入理解 BigBird 的块稀疏注意力]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 编辑器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><span id="OSC_h2_1"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">引言</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">基于 transformer 的模型已被证明对很多 NLP 任务都非常有用。然而，<span style="cursor:pointer;"><span role="presentation" data-formula="O(n^2)" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -833.9 2544.6 1083.9" aria-hidden="true" style="vertical-align: -0.566ex;width: 5.757ex;height: 2.452ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4F" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(763, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(1152, 0)"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(600, 363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(2155.6, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></span></span> 的时间和内存复杂度 (其中 <span style="cursor:pointer;"><span role="presentation" data-formula="n" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 600 453" aria-hidden="true" style="vertical-align: -0.025ex;width: 1.357ex;height: 1.025ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></span></span> 是序列长度) 使得在长序列 (<span style="cursor:pointer;"><span role="presentation" data-formula="n > 512" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -666 3433.6 706" aria-hidden="true" style="vertical-align: -0.09ex;width: 7.768ex;height: 1.597ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(877.8, 0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(1933.6, 0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500, 0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000, 0)"></path></g></g></g></svg></span></span>) 上应用它们变得非常昂贵，因而大大限制了其应用。最近的几篇论文，如 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Longformer</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Performer</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Reformer</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">簇状注意力</code> 都试图通过对完整注意力矩阵进行近似来解决这个问题。如果你不熟悉这些模型，可以查看 🤗 之前的，博文。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> (由，该论文，引入) 是解决这个问题的最新模型之一。 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 依赖于 <strong style="color: black;">块稀疏注意力</strong> 而不是普通注意力 ( <em style="color: black;">即</em> BERT 的注意力)，与 BERT 相比，这一新算法能以低得多的计算成本处理长达 <strong style="color: black;">4096</strong> 的序列。在涉及很长序列的各种任务上，该模型都实现了 SOTA，例如长文档摘要、长上下文问答。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">RoBERTa 架构的 BigBird</strong> 模型现已集成入 🤗 transformers 中。本文的目的是让读者 <strong style="color: black;">深入</strong> 了解 BigBird 的实现，并让读者能在 🤗 transformers 中轻松使用 BigBird。但是，在更深入之前，一定记住 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 注意力只是 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 完全注意力的一个近似，因此我们并不纠结于让它比 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 完全注意力 <strong style="color: black;">更好</strong>，而是致力于让它更有效率。有了它，transformer 模型就可以作用于更长的序列，因为 BERT 的二次方内存需求很快会变得难以为继。简而言之，如果我们有 <span style="cursor:pointer;"><span role="presentation" data-formula="\infty" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 1000 453" aria-hidden="true" style="vertical-align: -0.025ex;width: 2.262ex;height: 1.025ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g></svg></span></span> 计算和 <span style="cursor:pointer;"><span role="presentation" data-formula="\infty" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 1000 453" aria-hidden="true" style="vertical-align: -0.025ex;width: 2.262ex;height: 1.025ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></g></g></g></svg></span></span> 时间，那么用 BERT 注意力就好了，完全没必要用本文讨论的块稀疏注意力。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你想知道为什么在处理较长序列时需要更多计算，那么本文正合你意！</p><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在使用标准的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 类注意力时可能会遇到以下几个主要问题:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      每个词元真的都必须关注所有其他词元吗？ 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      为什么不只计算重要词元的注意力？ 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      如何决定哪些词元重要？ 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      如何以高效的方式处理少量词元？ 
    </section></li></ul><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">本文，我们将尝试回答这些问题。</p><span id="OSC_h3_2"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">应该关注哪些词元？</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">下面，我们将以句子 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird is now available in HuggingFace for extractive Question Answering</code> 为例来说明注意力是如何工作的。在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 这类的注意力机制中，每个词元都简单粗暴地关注所有其他词元。从数学上来讲，这意味着每个查询的词元 <span style="cursor:pointer;"><span role="presentation" data-formula=" \text{query-token} \in {\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering}} " data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.466ex;width: 90.929ex;height: auto;" src="https://oscimg.oschina.net/oscnet/3cb299f5-0dd9-498e-b671-c2cc91093e23.svg" data-type="svg+xml" data-imgfileid="100005775"></span></span>, 将关注每个键词元 <span style="cursor:pointer;"><span role="presentation" data-formula="\text{key-tokens} = \left[\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering} \right]" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.566ex;width: 91.185ex;height: auto;" src="https://oscimg.oschina.net/oscnet/f6bb45bf-4d15-409c-a819-d8e70016a46a.svg" data-type="svg+xml" data-imgfileid="100005777"></span></span>。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我们考虑一下 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">每个查询词元应如何明智地选择它实际上应该关注的键词元</code> 这个问题，下面我们通过编写伪代码的方式来整理思考过程。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">假设 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">available</code> 是当前查询词元，我们来构建一个合理的、需要关注的键词元列表。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;以下面的句子为例</span><br>example&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">'BigBird'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'is'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'now'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'available'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'in'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'HuggingFace'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'for'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'extractive'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'question'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'answering'</span>]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;假设当前需要计算&nbsp;'available'&nbsp;这个词的表征</span><br>query_token&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">'available'</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;初始化一个空集合，用于放&nbsp;'available'&nbsp;这个词的键词元</span><br>key_tokens&nbsp;=&nbsp;[]&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;=&gt;&nbsp;目前，'available'&nbsp;词元不关注任何词元</span><br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">邻近词元当然很重要，因为在一个句子 (单词序列) 中，当前词高度依赖于前后的邻近词。<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">滑动注意力</code> 即基于该直觉。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;考虑滑动窗大小为&nbsp;3,&nbsp;即将&nbsp;'available'&nbsp;的左边一个词和右边一个词纳入考量</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;左词:&nbsp;'now';&nbsp;右词:&nbsp;'in'</span><br>sliding_tokens&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"now"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"available"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"in"</span>]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;用以上词元更新集合</span><br>key_tokens.append(sliding_tokens)<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">长程依赖关系:</strong> 对某些任务而言，捕获词元间的长程关系至关重要。 <em style="color: black;">例如</em> ，在问答类任务中，模型需要将上下文的每个词元与整个问题进行比较，以便能够找出上下文的哪一部分对正确答案有用。如果大多数上下文词元仅关注其他上下文词元，而不关注问题，那么模型从不太重要的上下文词元中过滤重要的上下文词元就会变得更加困难。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 提出了两种允许长程注意力依赖的方法，这两种方法都能保证计算效率。</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">全局词元:</strong> 引入一些词元，这些词元将关注每个词元并且被每个词元关注。例如，对 
     <em style="color: black;">「HuggingFace is building nice libraries for easy NLP」</em> ，现在假设 
     <em style="color: black;">'building'</em> 被定义为全局词元，而对某些任务而言，模型需要知道 
     <em style="color: black;">'NLP'</em> 和 
     <em style="color: black;">'HuggingFace'</em> 之间的关系 (注意: 这 2 个词元位于句子的两端); 现在让 
     <em style="color: black;">'building'</em> 在全局范围内关注所有其他词元，会对模型将 
     <em style="color: black;">'NLP'</em> 与 
     <em style="color: black;">'HuggingFace'</em> 关联起来有帮助。 
    </section></li></ul><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我们假设第一个和最后一个词元是全局的，则有:</span><br>global_tokens&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"BigBird"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"answering"</span>]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;将全局词元加入到集合中</span><br>key_tokens.append(global_tokens)<br></code></pre><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">随机词元:</strong> 随机选择一些词元，这些词元将通过关注其他词元来传输信息，而那些词元又可以传输信息到其他词元。这可以降低直接从一个词元到另一个词元的信息传输成本。 
    </section></li></ul><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;现在，我们可以从句子中随机选择&nbsp;`r`&nbsp;个词元。这里，假设&nbsp;`r`&nbsp;为&nbsp;1，&nbsp;选择了&nbsp;`is`&nbsp;这个词元</span><br><span style="color: #999;font-weight: bold;line-height: 26px;">&gt;&gt;&gt;&nbsp;</span>random_tokens&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"is"</span>]&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;注意:&nbsp;这个是完全随机选择的，因此可以是任意词元。</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;将随机词元加入到集合中</span><br>key_tokens.append(random_tokens)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;现在看下&nbsp;`key_tokens`&nbsp;集合中有哪些词元</span><br>key_tokens<br>{<span style="color: #d14;line-height: 26px;">'now'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'is'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'in'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'answering'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'available'</span>,&nbsp;<span style="color: #d14;line-height: 26px;">'BigBird'</span>}<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;至此，查询词&nbsp;'available'&nbsp;仅关注集合中的这些词元，而不用关心全部</span><br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这样，查询词元仅关注所有词元的一个子集，该子集能够产生完全注意力值的一个不错的近似。相同的方法将用于所有其他查询词元。但请记住，这里的重点是尽可能有效地接近 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 的完全注意力。BERT 那种简单地让每个查询词元关注所有键词元的做法可以建模为一系列矩阵乘法，从而在现代硬件 (如 GPU) 上进行高效计算。然而，滑动、全局和随机注意力的组合似乎意味着稀疏矩阵乘法，这在现代硬件上很难高效实现。<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 的主要贡献之一是提出了 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">块稀疏</code> 注意力机制，该机制可以高效计算滑动、全局和随机注意力。我们来看看吧！</p><span id="OSC_h3_3"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">图解全局、滑动、随机注意力的概念</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先，我们借助图来帮助理解「全局」、「滑动」和「随机」注意力，并尝试理解这三种注意力机制的组合是如何较好地近似标准 BERT 类注意力的。</p><table data-tool="mdnice 编辑器"><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><img data-imgfileid="100005778" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="250" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="250" src="https://oscimg.oschina.net/oscnet/48d8f357-e08b-47a7-8590-a79741e9940f.png" referrerpolicy="no-referrer"></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><img class="rich_pages wxw-img" data-imgfileid="100005780" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="250" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="250" src="https://oscimg.oschina.net/oscnet/bf44ee17-227a-4bd2-8deb-ab00f6efbfa8.png" referrerpolicy="no-referrer"></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><img data-imgfileid="100005781" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="250" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="250" src="https://oscimg.oschina.net/oscnet/5556aef1-ce3e-41a8-b40c-fcb78b4139d8.png" referrerpolicy="no-referrer"></td></tr></tbody></table><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">上图分别把「全局」(左) 、「滑动」(中) 和「随机」(右) 连接建模成一个图。每个节点对应一个词元，每条边代表一个注意力分数。如果 2 个词元之间没有边连接，则其注意力分数为 0。</em></p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005782" data-ratio="0.535" data-type="gif" data-w="600" style="margin-right: auto;margin-left: auto;width: 409px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/b059422c-eedb-4881-8ea4-75aebc73bb2d.gif" referrerpolicy="no-referrer"></figure><img class="rich_pages wxw-img" data-imgfileid="100005779" data-ratio="0.9522058823529411" data-type="png" data-w="544" height="230" style="margin-right: auto;margin-left: auto;width: 385px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="230" src="https://oscimg.oschina.net/oscnet/d3b084c5-9bf4-4c47-a5e7-72edb7d1eb53.png" referrerpolicy="no-referrer"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">BigBird 块稀疏注意力</strong> 是滑动连接、全局连接和随机连接 (总共 10 个连接) 的组合，如上图左侧动图所示。而 <strong style="color: black;">完全注意力</strong> 图 (右侧) 则是有全部 15 个连接 (注意: 总共有 6 个节点)。你可以简单地将完全注意力视为所有词元都是全局词元 <span style="cursor:pointer;"><span role="presentation" data-formula="{}^1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -833.9 403.6 833.9" aria-hidden="true" style="vertical-align: 0px;width: 0.913ex;height: 1.887ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"></g><g data-mml-node="mn" transform="translate(0, 363) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span>。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">完全注意力:</strong> 模型可以直接在单个层中将信息从一个词元传输到另一个词元，因为每个词元都会对每个其他词元进行查询，并且受到其他每个词元的关注。我们考虑一个与上图类似的例子，如果模型需要将 <em style="color: black;">'going'</em> 与 <em style="color: black;">'now'</em> 关联起来，它可以简单地在单层中执行此操作，因为它们两个是有直接连接的。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">块稀疏注意力:</strong> 如果模型需要在两个节点 (或词元) 之间共享信息，则对于某些词元，信息将必须经过路径中的各个其他节点; 因为不是所有节点都有直接连接的。<em style="color: black;">例如</em> ，假设模型需要将 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going</code> 与 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">now</code> 关联起来，那么如果仅存在滑动注意力，则这两个词元之间的信息流由路径 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going -&gt; am -&gt; i -&gt; now</code> 来定义，也就是说它必须经过 2 个其他词元。因此，我们可能需要多个层来捕获序列的全部信息，而正常的注意力可以在单层中捕捉到这一点。在极端情况下，这可能意味着需要与输入词元一样多的层。然而，如果我们引入一些全局词元，信息可以通过以下路径传播 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going -&gt; i -&gt; now</code> ，这可以帮助缩短路径。如果我们再另外引入随机连接，它就可以通过 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">going -&gt; am -&gt; now</code> 传播。借助随机连接和全局连接，信息可以非常快速地 (只需几层) 从一个词元传输到下一个词元。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果我们有很多全局词元，那么我们可能不需要随机连接，因为信息可以通过多个短路径传播。这就是在使用 BigBird 的变体 (称为 ETC) 时设置 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_random_tokens = 0</code> 的动机 (稍后部分将会详细介绍)。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="{}^1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -833.9 403.6 833.9" aria-hidden="true" style="vertical-align: 0px;width: 0.913ex;height: 1.887ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"></g><g data-mml-node="mn" transform="translate(0, 363) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 在这些图中，我们假设注意力矩阵是对称的 <strong style="color: black;">即</strong><span style="cursor:pointer;"><span role="presentation" data-formula="\mathbf{A} _{ij} = \mathbf{A}_ {ji}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -698 4242.1 992.2" aria-hidden="true" style="vertical-align: -0.666ex;width: 9.598ex;height: 2.245ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="41" d="M296 0Q278 3 164 3Q58 3 49 0H40V62H92Q144 62 144 64Q388 682 397 689Q403 698 434 698Q463 698 471 689Q475 686 538 530T663 218L724 64Q724 62 776 62H828V0H817Q796 3 658 3Q509 3 485 0H472V62H517Q561 62 561 63L517 175H262L240 120Q218 65 217 64Q217 62 261 62H306V0H296ZM390 237L492 238L440 365Q390 491 388 491Q287 239 287 237H390Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(869, -150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345, 0)"><path data-c="6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1732.1, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2787.8, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="41" d="M296 0Q278 3 164 3Q58 3 49 0H40V62H92Q144 62 144 64Q388 682 397 689Q403 698 434 698Q463 698 471 689Q475 686 538 530T663 218L724 64Q724 62 776 62H828V0H817Q796 3 658 3Q509 3 485 0H472V62H517Q561 62 561 63L517 175H262L240 120Q218 65 217 64Q217 62 261 62H306V0H296ZM390 237L492 238L440 365Q390 491 388 491Q287 239 287 237H390Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(869, -150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mi" transform="translate(412, 0)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></span></span> 因为在图中如果某个词元 <strong style="color: black;">A</strong> 关注 <strong style="color: black;">B</strong>，那么 <strong style="color: black;">B</strong> 也会关注 <strong style="color: black;">A</strong>。从下一节所示的注意力矩阵图中可以看出，这个假设对于 BigBird 中的大多数词元都成立。</p><section data-tool="mdnice 编辑器" style="overflow-x: auto;"><table><thead><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">注意力类型</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">全局次元</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">滑动词元</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">随机词元</th></tr></thead><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">原始完全注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>n</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">0</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">0</td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">块稀疏注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">2 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">3 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>num_random_blocks</code> x <code>block_size</code></td></tr></tbody></table></section><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">原始完全注意力即 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BERT</code> 的注意力，而块稀疏注意力则是 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBird</code> 的注意力。想知道 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_size</code> 是什么？请继续阅读下文。_现在，为简单起见，将其视为 1。_</p><span id="OSC_h2_4"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">BigBird 块稀疏注意力</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">BigBird 块稀疏注意力是我们上文讨论的内容的高效实现。每个词元都关注某些 <strong style="color: black;">全局词元</strong> 、 <strong style="color: black;">滑动词元</strong> 和 <strong style="color: black;">随机词元</strong>，而不管其他 <strong style="color: black;">所有</strong> 词元。作者分别实现了每类查询注意力矩阵，并使用了一个很酷的技巧来加速 GPU 和 TPU 上的训练/推理。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005786" data-ratio="0.6129629629629629" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 543px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/f653f75a-ff61-452b-b0b1-aedeab166e25.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 块稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">注意: 在上图的顶部有 2 个额外的句子。正如你所注意到的，两个句子中的每个词元都只是交换了一个位置。这就是滑动注意力的实现方式。当 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">q[i]</code> 与 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">k[i,0:3]</code> 相乘时，我们会得到 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">q[i]</code> 的滑动注意力分数 (其中<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">i</code> 是序列中元素的索引)。</em></p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可以在，这儿，找到 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_sparse</code> 注意力的具体实现。现在看起来可能非常可怕😨😨，但这篇文章肯定会让你轻松理解它。</p><span id="OSC_h3_5"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">全局注意力</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">对于全局注意力而言，每个查询词元关注序列中的所有其他词元，并且被其他每个词元关注。我们假设 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Vasudev</code> (第一个词元) 和 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">them</code> (最后一个词元) 是全局的 (如上图所示)。你可以看到这些词元直接连接到所有其他词元 (蓝色框)。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;伪代码</span><br><br>Q&nbsp;-&gt;&nbsp;Query&nbsp;martix&nbsp;(seq_length,&nbsp;head_dim)<br>K&nbsp;-&gt;&nbsp;Key&nbsp;matrix&nbsp;(seq_length,&nbsp;head_dim)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;第一个和最后一个词元关注所有其他词元</span><br>Q[<span style="color: #008080;line-height: 26px;">0</span>]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br>Q[n<span style="color: #008080;line-height: 26px;">-1</span>]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;第一个和最后一个词元也被其他所有词元关注</span><br>K[<span style="color: #008080;line-height: 26px;">0</span>]&nbsp;x&nbsp;[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br>K[n<span style="color: #008080;line-height: 26px;">-1</span>]&nbsp;x&nbsp;[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br></code></pre><span id="OSC_h3_6"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">滑动注意力</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">键词元序列被复制两次，其中一份每个词元向右移动一步，另一份每个词元向左移动一步。现在，如果我们将查询序列向量乘以这 3 个序列向量，我们将覆盖所有滑动词元。计算复杂度就是 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">O(3n) = O(n)</code> 。参考上图，橙色框代表滑动注意力。你可以在图的顶部看到 3 个序列，其中 2 个序列各移动了一个词元 (1 个向左，1 个向右)。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我们想做的</span><br>Q[i]&nbsp;x&nbsp;[K[i<span style="color: #008080;line-height: 26px;">-1</span>],&nbsp;K[i],&nbsp;K[i+<span style="color: #008080;line-height: 26px;">1</span>]]&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;i&nbsp;=&nbsp;<span style="color: #008080;line-height: 26px;">1</span>:<span style="color: #008080;line-height: 26px;">-1</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;高效的代码实现&nbsp;(👇&nbsp;乘法为点乘)</span><br>[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-2</span>],&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">3</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">0</span>]]<br>[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]&nbsp;x&nbsp;[K[n<span style="color: #008080;line-height: 26px;">-1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-2</span>]]<br>[Q[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;Q[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;Q[n<span style="color: #008080;line-height: 26px;">-1</span>]]&nbsp;x&nbsp;[K[<span style="color: #008080;line-height: 26px;">0</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">1</span>],&nbsp;K[<span style="color: #008080;line-height: 26px;">2</span>],&nbsp;......,&nbsp;K[n<span style="color: #008080;line-height: 26px;">-1</span>]]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;每个序列被乘&nbsp;3&nbsp;词，&nbsp;即&nbsp;`window_size&nbsp;=&nbsp;3`。为示意，仅列出主要计算，省略了一些计算。</span><br></code></pre><span id="OSC_h3_7"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">随机注意力</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">随机注意力确保每个查询词元也会关注一些随机词元。对实现而言，这意味着模型随机选取一些词元并计算它们的注意力分数。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;r1,&nbsp;r2,&nbsp;r&nbsp;为随机索引;&nbsp;注意&nbsp;r1,&nbsp;r2,&nbsp;r&nbsp;每行取值不同&nbsp;👇</span><br>Q[<span style="color: #008080;line-height: 26px;">1</span>]&nbsp;x&nbsp;[Q[r1],&nbsp;Q[r2],&nbsp;......,&nbsp;Q[r]]<br>.<br>.<br>.<br>Q[n<span style="color: #008080;line-height: 26px;">-2</span>]&nbsp;x&nbsp;[Q[r1],&nbsp;Q[r2],&nbsp;......,&nbsp;Q[r]]<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;不用管第&nbsp;0&nbsp;个和第&nbsp;n-1&nbsp;个词元，因为它们已经是全局词元了。</span><br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意:</strong> 当前的实现进一步将序列划分为块，并且每个符号都依块而定义而非依词元而定义。我们在下一节中会更详细地讨论这个问题。</p><span id="OSC_h3_8"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">实现</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">回顾:</strong> 在常规 BERT 注意力中，一系列词元，即 <span style="cursor:pointer;"><span role="presentation" data-formula="X = x_1, x_2, …., x_n" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -683 8300.3 877" aria-hidden="true" style="vertical-align: -0.439ex;width: 18.779ex;height: 1.984ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1129.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2185.6, 0)"><g data-mml-node="mi"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(572, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3161.1, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3605.8, 0)"><g data-mml-node="mi"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(572, -150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4581.3, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(5026, 0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(6364.7, 0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(6809.3, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(7254, 0)"><g data-mml-node="mi"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(572, -150) scale(0.707)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></span></span> 通过线性层投影到 <span style="cursor:pointer;"><span role="presentation" data-formula="Q，K，V" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 5234.7 950" aria-hidden="true" style="vertical-align: -0.452ex;width: 11.843ex;height: 2.149ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(1068.8, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(2183.9, 0)"><path data-c="4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mo" transform="translate(3350.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(4465.7, 0)"><path data-c="56" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></svg></span></span>，并基于它们计算注意力分数 <span style="cursor:pointer;"><span role="presentation" data-formula="Z" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -683 723 683" aria-hidden="true" style="vertical-align: 0px;width: 1.636ex;height: 1.545ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="5A" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g></g></g></svg></span></span>，公式为 <span style="cursor:pointer;"><span role="presentation" data-formula="Z=Softmax(QK^T)" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -841.7 9140.4 1091.7" aria-hidden="true" style="vertical-align: -0.566ex;width: 20.68ex;height: 2.47ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="5A" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(1000.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2056.6, 0)"><path data-c="53" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(2701.6, 0)"><path data-c="6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3186.6, 0)"><path data-c="66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(3736.6, 0)"><path data-c="74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4097.6, 0)"><path data-c="6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4975.6, 0)"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5504.6, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6076.6, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6465.6, 0)"><path data-c="51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="msup" transform="translate(7256.6, 0)"><g data-mml-node="mi"><path data-c="4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(947, 363) scale(0.707)"><path data-c="54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mo" transform="translate(8751.4, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></span></span>。使用 BigBird 块稀疏注意力时，我们使用相同的算法，但仅针对一些选定的查询和键向量进行计算。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我们来看看 BigBird 块稀疏注意力是如何实现的。首先，我们用 <span style="cursor:pointer;"><span role="presentation" data-formula="b、r、s、g" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 6004.6 955" aria-hidden="true" style="vertical-align: -0.464ex;width: 13.585ex;height: 2.161ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(706.8, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="mi" transform="translate(1821.9, 0)"><path data-c="72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2550.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="mi" transform="translate(3665.7, 0)"><path data-c="73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(4412.5, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="mi" transform="translate(5527.6, 0)"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g></g></svg></span></span> 分别代表 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_size</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_random_blocks</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_sliding_blocks</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_global_blocks</code> 。我们以 <span style="cursor:pointer;"><span role="presentation" data-formula="b=4，r=1，g=2，s=3，d=5" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 17085.2 955" aria-hidden="true" style="vertical-align: -0.464ex;width: 38.654ex;height: 2.161ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(706.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1762.6, 0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(2540.3, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(3655.4, 0)"><path data-c="72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4384.2, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(5440, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(6217.7, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(7332.8, 0)"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mo" transform="translate(8087.6, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(9143.4, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(9921.2, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(11036.2, 0)"><path data-c="73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(11783, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(12838.8, 0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(13616.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           ， 
         </text></g><g data-mml-node="mi" transform="translate(14731.6, 0)"><path data-c="64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(15529.4, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(16585.2, 0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g></g></g></svg></span></span> 为例来说明 BigBird 块稀疏注意力的机制部分，如下所示:</p><img class="rich_pages wxw-img" data-imgfileid="100005784" data-ratio="0.47685185185185186" data-type="png" data-w="1080" height="250" style="margin-right: auto;margin-left: auto;width: 454px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" width="500" src="https://oscimg.oschina.net/oscnet/fab7065d-9994-4720-bcaf-b18128043c8e.png" referrerpolicy="no-referrer"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="{q} _{1}、{q}_ {2}、{q} _{3:n-2}、{q}_ {n-1}、{q}_{n}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 12388.8 1037.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 28.029ex;height: 2.347ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1127.3, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(2242.4, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3369.7, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(4484.8, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(500, 0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(778, 0)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1378, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2156, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7136.7, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(8251.8, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(600, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1378, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10353.5, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
           、 
         </text></g><g data-mml-node="msub" transform="translate(11468.6, 0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></span></span> 的注意力分数分别计算如下:</p><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="\mathbf{q}_{1}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -450 1010.6 679.4" aria-hidden="true" style="vertical-align: -0.519ex;width: 2.286ex;height: 1.537ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M38 220Q38 273 54 314T95 380T152 421T211 443T264 449Q368 449 429 386L438 377L484 450H540V-132H609V-194H600Q582 -191 475 -191Q360 -191 351 -194H342V-132H411V42Q409 41 399 34T383 25T367 16T347 7T324 1T296 -4T264 -6Q162 -6 100 56T38 220ZM287 46Q368 46 417 127V301L412 312Q398 347 369 371T302 395Q282 395 263 388T225 362T194 308T182 221Q182 126 214 86T287 46Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(607, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></span></span> 的注意力分数由 <span style="cursor:pointer;"><span role="presentation" data-formula="a_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -441 932.6 591" aria-hidden="true" style="vertical-align: -0.339ex;width: 2.11ex;height: 1.337ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(529, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 表示，其中 <span style="cursor:pointer;"><span role="presentation" data-formula="a_1=Softmax(q_1 * K^T)" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -841.7 10352.9 1091.7" aria-hidden="true" style="vertical-align: -0.566ex;width: 23.423ex;height: 2.47ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mn" transform="translate(529, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1210.3, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2266.1, 0)"><path data-c="53" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(2911.1, 0)"><path data-c="6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3396.1, 0)"><path data-c="66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(3946.1, 0)"><path data-c="74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4307.1, 0)"><path data-c="6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5185.1, 0)"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5714.1, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6286.1, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6675.1, 0)"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(7746.9, 0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="msup" transform="translate(8469.1, 0)"><g data-mml-node="mi"><path data-c="4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(947, 363) scale(0.707)"><path data-c="54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g><g data-mml-node="mo" transform="translate(9963.9, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></span></span>，即为第一块中的所有词元与序列中的所有其他词元之间的注意力分数。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005785" data-ratio="0.18981481481481483" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 540px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/e529cce5-c61b-4f5b-aead-50797118edfa.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 块稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="cursor:pointer;"><span role="presentation" data-formula="q_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 表示第 1 块，<span style="cursor:pointer;"><span role="presentation" data-formula="g_i" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 771 647" aria-hidden="true" style="vertical-align: -0.464ex;width: 1.744ex;height: 1.464ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></span></span> 表示第 <span style="cursor:pointer;"><span role="presentation" data-formula="i" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -661 345 672" aria-hidden="true" style="vertical-align: -0.025ex;width: 0.781ex;height: 1.52ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg></span></span> 块。我们仅在 <span style="cursor:pointer;"><span role="presentation" data-formula="q_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 和 &nbsp;<span style="cursor:pointer;"><span role="presentation" data-formula="g" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 477 647" aria-hidden="true" style="vertical-align: -0.464ex;width: 1.079ex;height: 1.464ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g></g></svg></span></span> (即所有键) 之间执行正常的注意力操作。</p><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">为了计算第二块中词元的注意力分数，我们收集前三块、最后一块和第五块。然后我们可以计算 <span style="cursor:pointer;"><span role="presentation" data-formula="a_2 = Softmax(q_2 * concat(k_1, k_2, k_3, k_5, k_7))" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.566ex;width: 42.712ex;height: auto;" src="https://oscimg.oschina.net/oscnet/63e34c61-946b-4bd4-bdd2-31f707091583.svg" data-type="svg+xml" data-imgfileid="100005776"></span></span>。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005783" data-ratio="0.2101851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 546px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bbea6fc-3f75-40d4-ba61-d47c6ec63c69.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 块稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">这里，我用 <span style="cursor:pointer;"><span role="presentation" data-formula="g，r，s" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -750 4182.7 955" aria-hidden="true" style="vertical-align: -0.464ex;width: 9.463ex;height: 2.161ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mo" transform="translate(754.8, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
            ， 
          </text></g><g data-mml-node="mi" transform="translate(1869.9, 0)"><path data-c="72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2598.6, 0)"><text data-variant="normal" transform="matrix(1 0 0 -1 0 0)" font-size="836.9px" font-family="serif">
            ， 
          </text></g><g data-mml-node="mi" transform="translate(3713.7, 0)"><path data-c="73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></span></span> 表示词元只是为了明确地表示它们的性质 (即是全局、随机还是滑动词元)，只用 <span style="cursor:pointer;"><span role="presentation" data-formula="k" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -694 521 705" aria-hidden="true" style="vertical-align: -0.025ex;width: 1.179ex;height: 1.595ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></span></span> 无法表示他们各自的性质。</em></p><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">为了计算 <span style="cursor:pointer;"><span role="presentation" data-formula="{q} _{3:n-2}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 2374.1 729.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 5.371ex;height: 1.65ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(500, 0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(778, 0)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1378, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2156, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></g></svg></span></span> 的注意力分数，我们先收集相应的全局、滑动、随机键向量，并基于它们正常计算 <span style="cursor:pointer;"><span role="presentation" data-formula="{q}_ {3:n-2}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 2374.1 729.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 5.371ex;height: 1.65ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(500, 0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(778, 0)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1378, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2156, 0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></g></svg></span></span> 上的注意力。请注意，正如前面滑动注意力部分所讨论的，滑动键是使用特殊的移位技巧来收集的。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005787" data-ratio="0.1925925925925926" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 518px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d6d57300-3e72-471f-8996-bc71b71674d8.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 块稀疏注意力 
   </figcaption></figure><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">为了计算倒数第二块 (即 <span style="cursor:pointer;"><span role="presentation" data-formula="{q} _{n-1}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 1823.9 729.3" aria-hidden="true" style="vertical-align: -0.65ex;width: 4.127ex;height: 1.65ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(446, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(600, 0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1378, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></span></span>) 中词元的注意力分数，我们收集第一块、最后三块和第三块的键向量。然后我们用公式 <span style="cursor:pointer;"><span role="presentation" data-formula="{a}_ {n-1} = Softmax({q}_{n-1} * concat(k_1, k_3, k_5, k_6, k_7))" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.65ex;width: 47.121ex;height: auto;" src="https://oscimg.oschina.net/oscnet/7d3fe6d1-79cd-4a4f-9b73-e294300d9bb5.svg" data-type="svg+xml" data-imgfileid="100005774"></span></span> 进行计算。这和计算 <span style="cursor:pointer;"><span role="presentation" data-formula="q_2" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></span></span> 非常相似。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005790" data-ratio="0.21481481481481482" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 545px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/807b8c9a-d09f-438b-90a6-3fa86c3ded16.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 块稀疏注意力 
   </figcaption></figure><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">最后一块 <span style="cursor:pointer;"><span role="presentation" data-formula="\mathbf{q}_{n}" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -450 1081.3 687.1" aria-hidden="true" style="vertical-align: -0.537ex;width: 2.446ex;height: 1.555ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="71" d="M38 220Q38 273 54 314T95 380T152 421T211 443T264 449Q368 449 429 386L438 377L484 450H540V-132H609V-194H600Q582 -191 475 -191Q360 -191 351 -194H342V-132H411V42Q409 41 399 34T383 25T367 16T347 7T324 1T296 -4T264 -6Q162 -6 100 56T38 220ZM287 46Q368 46 417 127V301L412 312Q398 347 369 371T302 395Q282 395 263 388T225 362T194 308T182 221Q182 126 214 86T287 46Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(607, -229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></span></span> 的注意力分数由 <span style="cursor:pointer;"><span role="presentation" data-formula="a_n" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -441 1003.3 598.8" aria-hidden="true" style="vertical-align: -0.357ex;width: 2.27ex;height: 1.355ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(529, -150) scale(0.707)"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></span></span> 表示，其中 <span style="cursor:pointer;"><span role="presentation" data-formula="a_n=Softmax(q_n * K^T)" data-formula-type="inline-equation" style=""><embed style="vertical-align: -0.566ex;width: 23.743ex;height: auto;" src="https://oscimg.oschina.net/oscnet/6681adae-1d7d-47f4-bece-c7a7198818a9.svg" data-type="svg+xml" data-imgfileid="100005773"></span></span>，只不过是最后一块中的所有词元与序列中的所有其他词元之间的注意力分数。这与我们对 <span style="cursor:pointer;"><span role="presentation" data-formula="q_1" data-formula-type="inline-equation" style=""><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -442 849.6 636" aria-hidden="true" style="vertical-align: -0.439ex;width: 1.922ex;height: 1.439ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(446, -150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></span></span> 所做的非常相似。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005789" data-ratio="0.1925925925925926" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 539px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1e5c321a-8a47-4f4d-8c68-c55f68e0ba07.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 块稀疏注意力 
   </figcaption></figure><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我们将上面的矩阵组合起来得到最终的注意力矩阵。该注意力矩阵可用于获取所有词元的表征。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005791" data-ratio="0.6916666666666667" data-type="gif" data-w="600" style="margin-right: auto;margin-left: auto;width: 537px;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d02815bd-44c4-4a61-94f0-f8c6e767b059.gif" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     BigBird 块稀疏注意力 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">上图中 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">蓝色 -&gt; 全局块</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">红色 -&gt; 随机块</code> 、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">橙色 -&gt; 滑动块</code> 。在前向传播过程中，我们不存储「白色」块，而是直接为每个单独的部分计算加权值矩阵 (即每个词元的表示)，如上所述。</em></p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">现在，我们已经介绍了块稀疏注意力最难的部分，即它的实现。希望对你更好地理解实际代码有帮助。现在你可以深入研究代码了，在此过程中你可以将代码的每个部分与上面的某个部分联系起来以助于理解。</p><span id="OSC_h2_9"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">时间和内存复杂度</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><section data-tool="mdnice 编辑器" style="overflow-x: auto;"><table><thead><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">注意力类型</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">序列长度</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">时间和内存复杂度</th></tr></thead><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">原始完全注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">512</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><br></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">1024</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">4 x <code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><br></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">4096</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">64 x <code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">块稀疏注意力</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">1024</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">2 x <code>T</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><br></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">4096</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">8 x <code>T</code></td></tr></tbody></table></section><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;">BERT 注意力和 BigBird 块稀疏注意力的时间和空间复杂度之比较。</em></p><summary>展开以了解复杂度的计算过程。</summary><pre style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">BigBird&nbsp;时间复杂度&nbsp;=&nbsp;O(w&nbsp;x&nbsp;n&nbsp;+&nbsp;r&nbsp;x&nbsp;n&nbsp;+&nbsp;g&nbsp;x&nbsp;n)<br>BERT&nbsp;时间复杂度&nbsp;=&nbsp;O(n^2)<br><br>假设:<br><span style="line-height: 26px;">&nbsp;&nbsp;&nbsp;&nbsp;w&nbsp;=&nbsp;3&nbsp;x&nbsp;64</span><br><span style="line-height: 26px;">&nbsp;&nbsp;&nbsp;&nbsp;r&nbsp;=&nbsp;3&nbsp;x&nbsp;64</span><br><span style="line-height: 26px;">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;=&nbsp;2&nbsp;x&nbsp;64</span><br><br>当序列长度为&nbsp;512&nbsp;时<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BERT&nbsp;时间复杂度&nbsp;=&nbsp;512^2**</span><br><br>当序列长度为&nbsp;1024&nbsp;时<br>=&gt;&nbsp;BERT&nbsp;时间复杂度&nbsp;=&nbsp;(2&nbsp;x&nbsp;512)^2<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BERT&nbsp;时间复杂度&nbsp;=&nbsp;4&nbsp;x&nbsp;512^2**</span><br><br>=&gt;&nbsp;BigBird&nbsp;时间复杂度&nbsp;=&nbsp;(8&nbsp;x&nbsp;64)&nbsp;x&nbsp;(2&nbsp;x&nbsp;512)<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BigBird&nbsp;时间复杂度&nbsp;=&nbsp;2&nbsp;x&nbsp;512^2**</span><br><br>当序列长度为&nbsp;4096&nbsp;时<br>=&gt;&nbsp;BERT&nbsp;时间复杂度&nbsp;=&nbsp;(8&nbsp;x&nbsp;512)^2<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BERT&nbsp;时间复杂度&nbsp;=&nbsp;64&nbsp;x&nbsp;512^2**</span><br><br>=&gt;&nbsp;BigBird&nbsp;时间复杂度&nbsp;=&nbsp;(8&nbsp;x&nbsp;64)&nbsp;x&nbsp;(8&nbsp;x&nbsp;512)<br>=&gt;&nbsp;BigBird&nbsp;时间复杂度&nbsp;=&nbsp;8&nbsp;x&nbsp;(512&nbsp;x&nbsp;512)<br>=&gt;&nbsp;<span style="font-weight: bold;line-height: 26px;">**BigBird&nbsp;时间复杂度&nbsp;=&nbsp;8&nbsp;x&nbsp;512^2**</span><br></code></pre><span id="OSC_h2_10"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">ITC 与 ETC</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">BigBird 模型可以使用 2 种不同的策略进行训练: <strong style="color: black;">ITC</strong> 和 <strong style="color: black;">ETC</strong>。 ITC (internal transformer construction，内部 transformer 构建) 就是我们上面讨论的。在 ETC (extended transformer construction，扩展 transformer 构建) 中，会有更多的全局词元，以便它们关注所有词元或者被所有词元关注。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ITC 需要的计算量较小，因为很少有词元是全局的，同时模型可以捕获足够的全局信息 (也可以借助随机注意力)。而 ETC 对于需要大量全局词元的任务非常有帮助，例如对 <strong style="color: black;">问答</strong> 类任务而言，整个问题应该被所有上下文关注，以便能够将上下文正确地与问题相关联。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><em style="color: black;"><strong>注意:</strong> BigBird 论文显示，在很多 ETC 实验中，随机块的数量设置为 0。考虑到我们上文图解部分的讨论，这是合理的。</em></p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">下表总结了 ITC 和 ETC:</p><section data-tool="mdnice 编辑器" style="overflow-x: auto;"><table><thead><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;"><br></th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">ITC</th><th style="border-top-width: 1px;border-color: rgb(204, 204, 204);background-color: rgb(240, 240, 240);text-align: center;min-width: 85px;">ETC</th></tr></thead><tbody style="border-width: 0px;border-style: initial;border-color: initial;"><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">全局注意力的注意力矩阵</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;word-break: break-all;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100005792" data-ratio="0.9011976047904192" data-s="300,640" data-type="png" data-w="334" style="letter-spacing: 0px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3907d2e-c92d-4c77-afbe-06b2b9a87f87.png" referrerpolicy="no-referrer"></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;word-break: break-all;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100005793" data-ratio="0.883054892601432" data-s="300,640" data-type="png" data-w="419" style="letter-spacing: 0px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8082e521-dcef-4270-aee5-5a44b3b87e56.png" referrerpolicy="no-referrer"></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">全局词元</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">2 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>extra_tokens</code> + 2 x <code>block_size</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: white;"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">随机词元</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>num_random_blocks</code> x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;"><code>num_random_blocks</code> x <code>block_size</code></td></tr><tr style="border-width: 1px 0px 0px;border-right-style: initial;border-bottom-style: initial;border-left-style: initial;border-right-color: initial;border-bottom-color: initial;border-left-color: initial;border-top-style: solid;border-top-color: rgb(204, 204, 204);background-color: rgb(248, 248, 248);"><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">滑动词元</td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">3 x <code>block_size</code></td><td style="border-color: rgb(204, 204, 204);text-align: center;min-width: 85px;">3 x <code>block_size</code></td></tr></tbody></table></section><span id="OSC_h2_11"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">在 &nbsp;🤗Transformers 中使用 BigBird</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可以像使用任何其他 🤗 模型一样使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdModel</code> 。我们看一下代码:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="font-weight: bold;line-height: 26px;">from</span>&nbsp;transformers&nbsp;<span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;BigBirdModel<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;从预训练&nbsp;checkpoint&nbsp;中加载&nbsp;bigbird&nbsp;模型</span><br>model&nbsp;=&nbsp;BigBirdModel.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>)<br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;使用默认配置初始化模型，如&nbsp;attention_type&nbsp;=&nbsp;"block_sparse"，num_random_blocks&nbsp;=&nbsp;3，block_size&nbsp;=&nbsp;64</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;你也可以按照自己的需要改变这些参数。这&nbsp;3&nbsp;个参数只改变每个查询词元关注的词元数。</span><br>model&nbsp;=&nbsp;BigBirdModel.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>,&nbsp;num_random_blocks=<span style="color: #008080;line-height: 26px;">2</span>,&nbsp;block_size=<span style="color: #008080;line-height: 26px;">16</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;通过把&nbsp;attention_type&nbsp;设成&nbsp;`original_full`，BigBird&nbsp;就会用复杂度为&nbsp;n^2&nbsp;的完全注意力。此时，BigBird&nbsp;与&nbsp;BERT&nbsp;相似度为&nbsp;99.9%。</span><br>model&nbsp;=&nbsp;BigBirdModel.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>,&nbsp;attention_type=<span style="color: #d14;line-height: 26px;">"original_full"</span>)<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">截至现在， <strong style="color: black;">🤗 Hub</strong> 中总共有 <strong style="color: black;">3 个 BigBird checkpoint</strong>: <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bigbird-roberta-base</code>，<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bigbird-roberta-large</code> 以及 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bigbird-base-trivia-itc</code>。前两个检查点是使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">masked_lm 损失</code> 预训练 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForPretraining</code> 而得; 而最后一个是在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">trivia-qa</code> 数据集上微调 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForQuestionAnswering</code> 而得。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">让我们看一下如果用你自己喜欢的 PyTorch 训练器，最少需要多少代码就可以使用 🤗 的 BigBird 模型来微调你自己的任务。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;以问答任务为例</span><br><span style="font-weight: bold;line-height: 26px;">from</span>&nbsp;transformers&nbsp;<span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;BigBirdForQuestionAnswering,&nbsp;BigBirdTokenizer<br><span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;torch<br><br>device&nbsp;=&nbsp;torch.device(<span style="color: #d14;line-height: 26px;">"cpu"</span>)<br><span style="font-weight: bold;line-height: 26px;">if</span>&nbsp;torch.cuda.is_available():<br>&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;=&nbsp;torch.device(<span style="color: #d14;line-height: 26px;">"cuda"</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我们用预训练权重初始化&nbsp;bigbird&nbsp;模型，并随机初始化其头分类器</span><br>model&nbsp;=&nbsp;BigBirdForQuestionAnswering.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>,&nbsp;block_size=<span style="color: #008080;line-height: 26px;">64</span>,&nbsp;num_random_blocks=<span style="color: #008080;line-height: 26px;">3</span>)<br>tokenizer&nbsp;=&nbsp;BigBirdTokenizer.from_pretrained(<span style="color: #d14;line-height: 26px;">"google/bigbird-roberta-base"</span>)<br>model.to(device)<br><br>dataset&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">"torch.utils.data.DataLoader&nbsp;object"</span><br>optimizer&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">"torch.optim&nbsp;object"</span><br>epochs&nbsp;=&nbsp;...<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;最简训练循环</span><br><span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;e&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;range(epochs):<br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;batch&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;dataset:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.train()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;batch&nbsp;=&nbsp;{k:&nbsp;batch[k].to(device)&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;k&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;batch}<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;前向</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output&nbsp;=&nbsp;model(**batch)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;后向</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output[<span style="color: #d14;line-height: 26px;">"loss"</span>].backward()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.step()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.zero_grad()<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;将最终权重存至本地目录</span><br>model.save_pretrained(<span style="color: #d14;line-height: 26px;">"&lt;YOUR-WEIGHTS-DIR&gt;"</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;将权重推到&nbsp;🤗&nbsp;Hub&nbsp;中</span><br><span style="font-weight: bold;line-height: 26px;">from</span>&nbsp;huggingface_hub&nbsp;<span style="font-weight: bold;line-height: 26px;">import</span>&nbsp;ModelHubMixin<br>ModelHubMixin.push_to_hub(<span style="color: #d14;line-height: 26px;">"&lt;YOUR-WEIGHTS-DIR&gt;"</span>,&nbsp;model_id=<span style="color: #d14;line-height: 26px;">"&lt;YOUR-FINETUNED-ID&gt;"</span>)<br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;使用微调后的模型，以用于推理</span><br>question&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"How&nbsp;are&nbsp;you&nbsp;doing?"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"How&nbsp;is&nbsp;life&nbsp;going?"</span>]<br>context&nbsp;=&nbsp;[<span style="color: #d14;line-height: 26px;">"&lt;some&nbsp;big&nbsp;context&nbsp;having&nbsp;ans-1&gt;"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"&lt;some&nbsp;big&nbsp;context&nbsp;having&nbsp;ans-2&gt;"</span>]<br>batch&nbsp;=&nbsp;tokenizer(question,&nbsp;context,&nbsp;return_tensors=<span style="color: #d14;line-height: 26px;">"pt"</span>)<br>batch&nbsp;=&nbsp;{k:&nbsp;batch[k].to(device)&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;k&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;batch}<br><br>model&nbsp;=&nbsp;BigBirdForQuestionAnswering.from_pretrained(<span style="color: #d14;line-height: 26px;">"&lt;YOUR-FINETUNED-ID&gt;"</span>)<br>model.to(device)<br><span style="font-weight: bold;line-height: 26px;">with</span>&nbsp;torch.no_grad():<br>&nbsp;&nbsp;&nbsp;&nbsp;start_logits,&nbsp;end_logits&nbsp;=&nbsp;model(**batch).to_tuple()<br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;这里，你可以使用自己的策略对&nbsp;start_logits，end_logits&nbsp;进行解码</span><br><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;注意:</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;该代码段仅用于展示即使你想用自己的&nbsp;PyTorch&nbsp;训练器微调&nbsp;BigBrid，这也是相当容易的。</span><br><span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;我会建议使用&nbsp;🤗&nbsp;Trainer，它更简单，功能也更多。</span><br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">使用 BigBird 时，需要记住以下几点:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      序列长度必须是块大小的倍数，即 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">seqlen % block_size = 0</code> 。你不必担心，因为如果 batch 的序列长度不是 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">block_size</code> 的倍数，🤗 transformers 会自动填充至最近的整数倍。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      目前，Hugging Face 的实现 
     <strong style="color: black;">尚不支持 ETC</strong>，因此只有第一个和最后一个块是全局的。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      当前实现不支持 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">num_random_blocks = 0</code> 。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      论文作者建议当序列长度 &lt; 1024 时设置 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type = "original_full"</code> 。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      必须满足: 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">seq_length &gt; global_token + random_tokens + moving_tokens + buffer_tokens</code> ，其中 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">global_tokens = 2 x block_size</code> 、 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">sliding_tokens = 3 x block_size</code> 、 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">random_tokens = num_random_blocks x block_size</code> 且 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">buffer_tokens = num_random_blocks x block_size</code> 。如果你不能满足这一点，🤗 transformers 会自动将 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type</code> 切换为 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">original_full</code> 并告警。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      当使用 BigBird 作为解码器 (或使用 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForCasualLM</code> ) 时， 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type</code> 应该是 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">original_full</code> 。但你不用担心，🤗 transformers 会自动将 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">attention_type</code> 切换为 
     <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">original_full</code> ，以防你忘记这样做。 
    </section></li></ul><span id="OSC_h2_12"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">下一步</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">@patrickvonplaten 建了一个非常酷的，笔记本，以展示如何在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">trivia-qa</code> 数据集上评估 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">BigBirdForQuestionAnswering</code> 。你可以随意用这个笔记本来玩玩 BigBird。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">BigBird 版的 Pegasus</strong> 模型很快就会面世，你可将它们用于 <strong style="color: black;">长文档摘要</strong> 💥。</p><span id="OSC_h2_13"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">尾注</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可在，此处，找到 <strong style="color: black;">块稀疏注意力矩阵</strong> 的原始实现。🤗 版的实现在，这儿。</p><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">🤗 宝子们可以戳 <strong style="color: black;">阅读原文</strong> 查看文中所有的外部链接哟！</p></blockquote><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/big-bird</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Vasudev Gupta</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">译者: Matrix Yao (姚伟峰)，英特尔深度学习工程师，工作方向为 transformer-family 模型在各模态数据上的应用及大规模模型的训练推理。</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Hugging Face（gh_504339124f0f）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10150964</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10150964</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LibreOffice Viewer 重新上架 Google Play 商店]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/news/268085/libreoffice-7-6-3-and-android-viewer-app">LibreOffice 7.6.3</a>&nbsp;于昨日更新，与其同时发布的还有 Android 版 LibreOffice Viewer——已重新<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplay.google.com%2Fstore%2Fapps%2Fdetails%3Fid%3Dorg.documentfoundation.libreoffice" target="_blank">上架至 Google Play 商店</a>。</p><p>LibreOffice Viewer 是 LibreOffice 的轻量级版本，专为 Android 智能手机和平板电脑设计，用于查看 OpenDocument 和 Microsoft Office 格式文档。具体包括：</p><p>• 开放文档格式（odt、ods、odp、odg）<br> • Microsoft Office 2007–365（docx、xlsx 和 pptx）<br> • Microsoft Office 97–2003（doc、xls 和 ppt）</p><p>它与适用于 Windows、macOS 和 Linux 的 LibreOffice 桌面基于相同的 LibreOffice 技术构建，因此它以完全相同的方式显示文档。</p><p><strong>LibreOffice Viewer&nbsp; 运行截图</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-15b7f109e6f110504216473c4672024e086.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-3679fd58f40a452c8afc18ff4d22d3e811f.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.documentfoundation.org%2Fblog%2F2023%2F11%2F24%2Flibreoffice-viewer-app-for-android%2F" target="_blank">LibreOffice Viewer 此前曾上架 Google Play 商店</a>，但由于缺乏维护，于 2020 年被下架。此后，开发团队通过 200 多项变更来改进该应用程序，提升其稳定性和可用性，支持当前的 Android 版本并更好地与系统集成。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 05:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268087/libreoffice-viewer-app-for-android</guid>
            <link>https://www.oschina.net/news/268087/libreoffice-viewer-app-for-android</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LibreOffice 7.6.3 社区版发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LibreOffice 7.6 社区版发布了<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.documentfoundation.org%2Fblog%2F2023%2F11%2F23%2Flibreoffice-763-and-android-viewer-app%2F" target="_blank">第三个补丁更新：7.6.3</a></u>，支持 Windows（Intel/AMD 和 ARM 处理器）、macOS（Apple 和 Intel 处理器），以及 Linux 系统。</p><p><img height="522" src="https://static.oschina.net/uploads/space/2023/1125/125041_9KhN_2720166.png" width="970" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.libreoffice.org%2Fdownload%2Fdownload-libreoffice%2F" target="_blank">下载地址</a></u> | <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.documentfoundation.org%2FReleaseNotes%2F7.6" target="_blank">Release Notes</a></u></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">LibreOffice 7.6 引入的新功能包括：支持触摸板上的缩放手势、支持文档主题、导入和导出 ODF 和 OOXML 文档的主题定义的能力。LibreOffice 7.6 预计会发布总共 7 个维护版本更新，持续支持到 2024 年 6 月 12 日。</p><blockquote><p>延伸阅读：<strong><em><u><a href="https://www.oschina.net/news/267911/libreoffice-24-2-alpha1" target="news">LibreOffice 24.2 Alpha 1 发布，已启用新的版本号命名规则</a></u></em></strong></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 04:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268085/libreoffice-7-6-3</guid>
            <link>https://www.oschina.net/news/268085/libreoffice-7-6-3</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME 拿到 100 万欧元投资后，积极改进基础设施]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GNOME 基金会本月从「Sovereign Tech Fund」获得了 <u><a href="https://www.oschina.net/news/265839/gnome-sovereign-tech-fund">100 万欧元投资</a></u>，用于帮助 GNOME 实现平台现代化、改进工具和可访问性，并支持符合公共利益的功能。</p><p>目前，围绕 systemd-homed 和其他功能集成的新工作正在进行中，通过将 systemd-homed 集成到 GNOME 的 AccountService 中，用户可以为他们的 Home 目录创建加密卷，确保个人数据的安全性。</p><p>本周 GNOME 开发工作的部分亮点包括：</p><ol><li>通过 XDG Desktop Portal，使沙盒应用程序支持文件夹的拖放功能</li><li>改进 GNOME Shell 和合成器的性能，并集成 Tracy 分析器<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-a4ae5a9624f158104c73a6cd332f2a7b75f.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li>提升硬件加速屏幕录制和改进 Linux 蓝牙协议堆栈</li><li>正在开发 Mutter 中对 OpenGL KHR_robustness 扩展的支持，以帮助 GNOME 会话从 GPU 驱动程序崩溃中恢复</li><li>Fractal Matrix 消息应用程序在 Fractal 5 中进行了全面重写，现在使用 GTK 4、libadwaita 和 Matrix Rust SDK。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-aa30c942344821d70d7dffa1d26d5fcf6bf.png" referrerpolicy="no-referrer"></li></ol><p>有关这些最新 GNOME 工作的更多详细信息，请参见本周 GNOME 动态：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthisweek.gnome.org%2Fposts%2F2023%2F11%2Ftwig-123%2F" target="_blank">https://thisweek.gnome.org/posts/2023/11/twig-123/</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 02:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268167</guid>
            <link>https://www.oschina.net/news/268167</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox 121 默认启用 Wayland 支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根据 Firefox 最近的提交信息，Firefox 121 计划在现代 Linux 桌面上默认启用 Wayland 支持，而不是回退到 XWayland。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-af58e5b492ff8f046886d946f3b112b8abc.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f1786452d74604703605a8963620fd4491.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1752398" target="_blank">https://bugzilla.mozilla.org/show_bug.cgi?id=1752398</a></u></em>、<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhg.mozilla.org%2Fmozilla-central%2Frev%2F5ea5f3e31d58" target="_blank">https://hg.mozilla.org/mozilla-central/rev/5ea5f3e31d58</a></em></u></p><p>本周发布了 <u><a href="https://www.oschina.net/news/267557/firefox-120-0-released">Firefox 120 </a></u>稳定版，Firefox 121 现在处于测试阶段 —— Wayland 支持已默认启用，并且截至昨天的 beta 3 版本仍然开启，有望在稳定版中保持该状态。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6256943e2a71993b6018e4b3e5f2199fa60.png" referrerpolicy="no-referrer"></p><p>原生 Firefox Wayland 支持可实现触摸板和触摸屏手势、滑动导航、每个显示器的 DPI 设置、更好的图形性能等等。随着时间的推移，Firefox Wayland 支持已经相当成熟，并且现在处于稳健状态。用户表示在 Firefox 121 beta 测试中，它的表现非常好。</p><p>Firefox 121 计划于 12 月 19 日发布，如果默认启用 Wayland 支持，这将是一个很好的圣诞礼物。随着 KDE Plasma 6.0 默认切换到 Wayland 会话，以及其他地方达到的 Wayland 采用里程碑，2024 年可能成为 Wayland 主导 Linux 桌面的一年。</p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/261201/gnome-mr-drop-x11-session">GNOME 移除对 X.Org 会话支持</a></li><li><a href="https://www.oschina.net/news/263917/linux-mint-wayland-progress">Linux Mint "Cinnamon" 开始支持 Wayland</a></li><li><a href="https://www.oschina.net/news/256249/intellij-based-ide-wayland-support">JetBrains 为基于 IntelliJ 的 IDE 提供 Wayland 支持</a></li><li><a href="https://www.oschina.net/news/241063/asahi-linux-stop-x-org">Asahi Linux 致用户：停止使用 X.Org，Wayland 才是未来</a></li><li><a href="https://www.oschina.net/news/227050/xfce-4-20-wayland-support">Xfce 4.20 将正式支持 Wayland</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 25 Nov 2023 01:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268164/firefox-121-enable-wayland-support-by-default-on-linux</guid>
            <link>https://www.oschina.net/news/268164/firefox-121-enable-wayland-support-by-default-on-linux</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
