<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 22 Feb 2024 06:28:30 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[「未来产业划定发展路线图」出炉]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>近日，工业和信息化部、科技部、交通运输部、文化和旅游部等部门</span><span>联合印发</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMjM5OTUwMTc2OA%3D%3D%26mid%3D2650903280%26idx%3D1%26sn%3Db6edd0ce1c41aac431cd9f9a52eef8be%26chksm%3Dbccfb8578bb831412b6e96f801604afe81effbd68c11d7371507f00349b1b3accc4cc18e01b4%26scene%3D21%23wechat_redirect" target="_blank">《关于推动未来产业创新发展的实施意见》</a><span>，提出到 2025 年，未来产业技术创新、产业培育、安全治理等全面发展，部分领域达到国际先进水平，产业规模稳步提升；到 2027 年，未来产业综合实力显著提升，部分领域实现全球引领。</span></p><p>专家认为，《意见》充分把握全球科技创新和产业发展趋势，前瞻部署了生物制造、量子信息、氢能、核能、基因和细胞技术等多个细分赛道，将全面支撑推进新型工业化，加快形成新质生产力。</p><p style="margin-left:0; margin-right:0"><strong><span>全面布局新赛道</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>未来产业由前沿技术驱动，尚处于孕育萌发阶段或产业化初期，是具有显著战略性、引领性、颠覆性和不确定性的前瞻性新兴产业。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">当前，新一轮科技革命和产业变革加速演进，重大前沿技术、颠覆性技术持续涌现，科技创新和产业发展融合不断加深，催生出元宇宙、人形机器人、脑机接口、量子信息等新产业发展方向。大力培育未来产业已成为引领科技进步、带动产业升级、开辟新赛道、塑造新质生产力的战略选择。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">我国具备工业体系完整、产业规模庞大、应用场景丰富等综合优势，为未来产业发展提供了丰厚的土壤。各省（区、市）积极培育未来产业，北京、上海、江苏、浙江等地出台了培育未来产业的政策文件。但我国未来产业发展也面临系统谋划不足、技术底座不牢等问题。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">针对这些问题，《意见》从技术创新、产品突破、企业培育、场景开拓、产业竞争力等方面提出到 2025 年和 2027 年的发展目标。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">赛迪研究院未来产业研究中心所长韩健介绍，到 2025 年要形成「一批+6 百」的目标体系，建设一批未来产业孵化器和先导区，突破百项前沿关键核心技术，形成百项标志性产品，打造百家领军企业，开拓百项典型应用场景，制定百项关键标准，培育百家专业服务机构，初步形成符合我国实际的未来产业发展模式。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">《意见》重在产业化落地。赛智产业研究院院长赵刚认为，《意见》提出以传统产业的高端化升级和前沿技术的产业化落地为主线，力争做到两年「打基础」，五年「大提升」，成为世界未来产业重要策源地。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">此外，《意见》还详细规划了六大方向超过 50 多个细分领域的未来产业发展，明确提出了下一代智能终端、信息服务产品、未来高端装备三类标志性产品发展路线。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">「设定未来产业发展目标既是我国推进新型工业化的自身现实需求，也是参与国际竞争的外部形势要求。从自身需求看，是我国引领科技进步、带动产业升级、培育新质生产力的战略选择；从外部需求看，是我国主动参与全球未来产业分工合作、深度融入全球创新网络的必然选择。」赵刚说。</p><p style="margin-left:0; margin-right:0"><strong><span>重点瞄准六大方向</span></strong></p><p><span>未来产业发展的核心是前沿技术创新突破。《意见》按照「技术创新—前瞻识别—成果转化」的思路，提出面向未来制造、未来信息、未来材料、未来能源、未来空间、未来健康六大重点方向，实施国家科技重大项目和重大科技攻关，发挥国家实验室、全国重点实验室等创新载体作用，鼓励龙头企业牵头成立创新联合体，体系化推进关键核心技术攻关。</span></p><p>赵刚分析，与优势产业、传统产业、战略性新兴产业相比，未来产业有 3 个明显特征。未来产业技术创新不是渐进式微创新，而是前瞻性、颠覆性重大创新，例如未来信息产业中的通用人工智能和量子信息、未来健康产业中的基因工程、未来材料产业中的超导材料等技术创新；未来产业生产要素配置不是传统要素线性叠加，而是现代要素相互融合和配置效率指数级提升，例如量子计算机能让计算能力实现成千上万倍增加；未来产业边界不是界限清晰，而是呈现出不同产业跨界融合和智能化、绿色化等发展特征，如智能制造、生物材料、人形机器人、脑机接口等。</p><p>对于这六大方向业内已有布局。早在 2016 年，字节跳动公司就成立了人工智能实验室，聚焦研究自然语言处理、机器学习、数据挖掘等方面。2023 年以来，字节跳动公司加码人工智能应用研究，旗下产品不断加入 AIGC（生成式人工智能）功能。比如，结合火山引擎智能创作云的 AIGC 能力，火山引擎视频云在商品营销、互动娱乐、在线教育、智能驾驶等场景引入数字人、虚拟直播间等，助力企业降本增效，提升用户体验。</p><p>「技术创新是经济长期持续增长的不竭动力，发展未来产业是高质量发展的前瞻性战略布局。今天对未来产业 20% 的投入和布局，将为以后带来 80% 的收益，从而建立起我国经济高质量发展的长效创新机制。」赵刚说。</p><p style="margin-left:0; margin-right:0"><strong><span>打造标志性创新产品</span></strong></p><p><span>《意见》提出，打造人形机器人、脑机接口、超大规模新型智算中心、第三代互联网等十大创新标志性产品。</span></p><p>赵刚分析，当颠覆式技术创新呈现出技术性能成倍提升、产品化成本大幅降低、应用场景广泛等特征后，创新产品就形成规模经济效应，具有巨大的市场前景。</p><p>当前，满足这 3 个特征的标志性产品主要有两类。一是通用人工智能产品。由于以 ChatGPT 为代表的通用人工智能技术取得重大进展，围绕通用人工智能技术创新形成的智能产品，如生成式人工智能产品、AI 手机和个人计算机、人形机器人、高级别智能网联汽车、智能装备、智能云服务、超大规模新型智算中心等智能产品和服务就具有较好前景。二是生物科技产品。由于细胞和基因工程等技术取得突破性进展，生物科技创新产品工程化能力加速提升，具有很好的市场前景，如基因编辑、合成生物等。其他一些前瞻性技术尽管在实验室获得了成功，但离大规模产品化和商业化还有很大差距，例如量子信息技术创新。</p><p>国际数据公司 IDC 预测，人工智能电脑在中国个人计算机市场中新机的装配比例将快速攀升，2027 年有望达 85%，成为市场主流。联想集团副总裁、中国区战略及业务拓展副总裁阿不力克木·阿不力米提表示，人工智能电脑是自然语言交互的个人 AI 助理。在过去 40 年发展历程中，联想不断推出变革用户体验的产品，未来还将和生态伙伴携手实现人工智能电脑快速普及，让 AI 惠及每一个人。</p><p>目前我国算力总规模排名全球第二位。但从结构看，通用算力占了大半，高性能算力占比有待提升。浪潮信息高级副总裁刘军表示，高质量算力采用先进的计算架构，具备高算效、高能效、可持续、可获得、可评估五大特征。其中，高算效是实测性能与资源利用率双重提升，是算力供需失衡、算力利用率低等矛盾的破解之道。而高能效是在最低碳排放前提下实现最大化算力输出，确保能源利用最优解。</p><p>脑机接口作为十大标志性产品之一，近年来在电极、算法、芯片等方面取得了重要进展。2023 年 9 月，中国信息通信研究院云计算与大数据研究所牵头在人工智能医疗器械创新合作平台成立脑机接口研究工作组。</p><p>中国信通院云计算与大数据研究所副所长闵栋介绍，脑机接口可应用于医疗、娱乐、智能生活、教育等领域。其中，医疗领域是主要阵地。脑机接口与医疗结合展现出广阔应用前景，为相关疾病诊疗和康复提供了全新手段。此外，脑机接口还可与虚拟现实、人机交互、人工智能等技术结合推动现有产业变革，如脑机接口应用于工业领域，可帮助人们通过意念操控机器人、无人车、工业产线等设备。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">未来产业潜在价值巨大，需要资本持续投入。赵刚建议，要推动制造业转型升级基金、国家中小企业发展基金等加大投入，也可适时组建国家未来产业发展基金，并引导地方设立未来产业专项资金，发挥政府引导基金的引导性作用，吸引社会资本共同投资未来产业。同时，完善金融财税支持政策。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 05:58:15 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279756</guid>
            <link>https://www.oschina.net/news/279756</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[夜莺监控 V7 第一个 beta 版本来了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>夜莺项目从 2024 开始开发 V7 版本，重点做体验优化，V7 和 V6 版本兼容可以平滑升级<span style="background-color:#ffffff; color:#333333">（V6 升级到 V7 只需要替换一下二进制重启即可，如果是容器部署，只需要更新镜像并重启）</span>，今天发布第一个 beta，此 beta 版本的优化项包括：</p><ul><li>全站暗黑主题</li><li>优化边缘机房机器失联告警的实现逻辑，真正做到边缘机房告警自闭环</li><li>优化内置大盘、内置告警规则的列表页面 UI</li><li>全局回调地址页面展示优化，增加详尽的文档提示信息</li></ul><p><span style="background-color:#ffffff; color:#333333">更多优化项正在开发中，V5、V6 用户可以放心升级，V7 会是一个更好的版本。升级之前记得备份以防万一。</span></p><h2>项目介绍</h2><p style="color:#333333; text-align:left">夜莺监控是一款开源云原生观测分析工具，采用 All-in-One 的设计理念，集数据采集、可视化、监控告警、数据分析于一体，与云原生生态紧密集成，提供开箱即用的企业级监控分析和告警能力。夜莺于 2020 年 3 月 20 日，在 github 上发布 v1 版本，已累计迭代 100 多个版本。</p><p style="color:#333333; text-align:left">夜莺最初由滴滴开发和开源，并于 2022 年 5 月 11 日，捐赠予中国计算机学会开源发展委员会（CCF ODC），为 CCF ODC 成立后接受捐赠的第一个开源项目。夜莺的核心研发团队，也是 Open-Falcon 项目原核心研发人员，从 2014 年（Open-Falcon 是 2014 年开源）算起来，也有 10 年了，只为把监控这个事情做好。</p><h2>项目截图</h2><p style="color:#333333; text-align:left"><img alt="20240221141801" src="https://download.flashcat.cloud/ulric/20240221141801.png" referrerpolicy="no-referrer"></p><p style="color:#333333; text-align:left"><img alt="20240221141817" src="https://download.flashcat.cloud/ulric/20240221141817.png" referrerpolicy="no-referrer"></p><h2>项目代码</h2><ul><li>后端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank">💡 https://github.com/ccfos/nightingale</a></li><li>前端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fn9e%2Ffe" target="_blank">💡 https://github.com/n9e/fe</a></li></ul><p style="color:#333333; text-align:left">夜莺项目已收获 8000 多 github stars，1000 多 forks，100 多 contributors 参与其中，欢迎大家在<span>&nbsp;</span><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank"><strong>GitHub</strong></a></strong><span>&nbsp;</span>上关注夜莺项目，及时获取项目更新动态，有任何问题，也欢迎提交 issues，以及提交 pull requests，开源社区需要大家一起参与才能有蓬勃的生命力。</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 04:15:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</guid>
            <link>https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：等到 Sora 开源了立刻推出属于我们自己的大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.21</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/279326/linux-kernel-is-a-cna" target="_blank">2023 年度 Rust 调查报告</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">有 93% 的受访者称自己是 Rust 用户，其中 49% 的人每天（或几乎每天）都会使用 Rust，相较上一年小幅增加 2 个百分点。在没有使用 Rust 的用户中，31% 的人表示主要原因时使用 Rust 有难度；67% 的人表示他们还没有机会优先学习 Rust，这也是最常见的原因。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-335afef97d65f03d34d0f08eb8831153557.png" width="500" referrerpolicy="no-referrer"></span></p><h3><a href="https://www.oschina.net/news/279389/dart-3-3-released" target="_blank">Go 1.22 正式发布</a></h3><p>Go 1.22 中新增的优化之一是改进了虚拟化，允许静态调度更多的接口方法调用。启用 PGO 后，大多数程序的性能将提高 2% 至 14%。 此外，Go 运行时中的内存优化可将 CPU 性能提高 1-3%，同时还可将大多数 Go 程序的内存开销减少约 1%。</p><p>新的 math/rand/v2 软件包提供了更简洁、更一致的应用程序接口，并使用了质量更高、速度更快的伪随机生成算法。&nbsp;</p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-9fc6f45ad8365450e0980fe7fe1855a56c5.png" referrerpolicy="no-referrer"></p><p>- 微博 <u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6640496217%2FO1tM7BenZ" target="_blank">-赤犬龙之介-</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-d423a4b13075c233da7226ccd5235dc0a3e.png" referrerpolicy="no-referrer"></p><p>-&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2F8XMQgC7LlaK" target="_blank">21 世纪经济报道</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-25f6c0a5f5becd775a0ad6bd1080893da87.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>开源之声</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-bbc6216c930e22f859d514d8becc057daae.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p>Gitee 榜单：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5ab4f59bdf01add8c61aac9c617fa074d2c.png" referrerpolicy="no-referrer"></p><hr><p><strong>往期回顾</strong></p><ul><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:47:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279735</guid>
            <link>https://www.oschina.net/news/279735</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[数百位名人签署公开信，呼吁制定反深度伪造立法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>数百名 AI 界人士签署了一封<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">公开信</a>，呼吁严格监管 AI 生成的冒名顶替或深度伪造（Deepfake）内容。</p><p><img height="274" src="https://oscimg.oschina.net/oscnet/up-df56f62fff93b887bf1198aca4ccf4bcb5e.png" width="500" referrerpolicy="no-referrer"></p><p>公开信指出，"深度伪造"是指未经同意或严重误导的人工智能生成的声音、图像或视频，合理的人会误以为是真实的。这不包括对图像或声音的轻微改动，也不包括容易识别为合成的无害娱乐或讽刺。</p><p>如今，深度伪造通常涉及性图像、欺诈或政治虚假信息。由于人工智能发展迅速，使得深度伪造变得更加容易，因此我们需要为数字基础设施的运行和完整性提供保障。「Deepfakes 对社会的威胁日益严重，政府必须在整个供应链中施加义务，以阻止 Deepfakes 的扩散。」</p><p>信中呼吁：</p><ul><li>将深度伪造的儿童性虐待材料（CSAM，又名儿童色情制品）完全定为刑事犯罪，无论所描绘的人物是真实的还是虚构的。</li><li>在任何情况下，如果有人制造或传播有害的深度伪造品，都需要受到刑事处罚。</li><li>要求软件开发商和分销商防止其音频和视频产品被用于制造有害的深度伪造品，如果他们的预防措施不充分，就要承担责任接受处罚。</li></ul><p>他们认为，如果设计得当，这些法律可以在不会造成过重负担的同时，培育有社会责任感的企业。</p><p>这封信中较为知名的签名者包括：</p><ul><li>Jaron Lanier</li><li>Frances Haugen</li><li>Stuart Russell</li><li>Andrew Yang</li><li>Marietje Schaake</li><li>Steven Pinker</li><li>Gary Marcus</li><li>Oren Etzioni</li><li>Genevieve smith</li><li>Yoshua Bengio</li><li>Dan Hendrycks</li><li>Tim Wu</li></ul><p>事实上，这也不是首次出现相关的呼吁。在本月早些时候正式提出之前，欧盟已就此类措施进行了多年辩论。外媒 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F21%2Fhundreds-of-ai-luminaries-sign-letter-calling-for-anti-deepfake-legislation%2F" target="_blank">TechCrunch</a> 指出，也许正是欧盟愿意进行审议和落实，才激活了这些研究人员、创作者和管理人员的发言权。虽然此举不一定能推动真正的立法，但它确实是业界专家们如何看待这一争议问题的风向标。</p><p>更多详情可查看此处：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">https://openletter.net/l/disrupting-deepfakes</a>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:32:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279733/disrupting-deepfakes</guid>
            <link>https://www.oschina.net/news/279733/disrupting-deepfakes</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[出门问问创始人李志飞点评谷歌开源大模型 Gemma：差点意思]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌在北京时间昨晚发布了<u><a href="https://www.oschina.net/news/279713/google-gemma-open-models">开源大模型 Gemma</a></u>，对标 Meta 旗下 Llama 2。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><p>出门问问创始人李志飞发表文章点评，<strong>称 Gemma 推出时间有点晚、开源力度不够、未放下高贵的头颅</strong>。</p><p>李志飞在文章中表示，相比于去年上半年就开源，现在可能要花数倍的努力进行模型的差异化以及推广的投入，才有可能在众多开源模型中脱颖而出。「面对 OpenAI 的强力竞争，只有杀敌一千、自损一千五。」</p><p>以下为李志飞全文：</p><blockquote><p>看到 Google 开源了小的语言模型 Gemma，直接狙击 Llama 2，回顾去年 5 月对 Google 关于开源和竞争的看法，几点思考如下：</p><p>1. 时间有点晚：相比于去年上半年就开源，现在可能要花数倍的努力进行模型的差异化以及推广的投入，才有可能在众多开源模型中脱颖而出。</p><p>2. 开源力度不够：感觉这次开源还是被动防御和略显扭捏的应对之策，不是进攻。比如说，开个 7B 的模型实在是太小儿科了，一点杀伤力都没有。应该直接开源一个超越市场上所有开源的至少 100B 的模型、1M 的超长上下文、完善的推理 infra 方案、外加送一定的 cloud credit。是的，再不歇斯底里 Google 真的就晚了。面对 OpenAI 的强力竞争，只有杀敌一千、自损一千五。</p><p>3. 未放下高贵的头颅：有种感觉，Google 觉得自己还是 AI 王者，放不下高贵的头颅，很多发布都有点不痛不痒，还是沿着过去研发驱动的老路而不是产品和竞争驱动，比如不停发论文、取新名字（多模态相关模型过去半年就发了 Palme、RT-2、Gemini、VideoPoet、W.A.L.T 等）、发布的模型又完整度不够，感觉就没有一个绝对能打的产品。Google 可能要意识到在公众眼中，他在 AI 领域已经是廉颇老矣溃不成军，经常起大早赶晚集（比如说这次 Sora 借鉴的 ViT、ViViT、NaVit、MAGVit 等核心组件技术都是它家写的论文）。</p><p>4. 希望亡羊补牢未为晚也：Google 作为一个僵化的大公司，动作慢一点可以理解，但是如果再不努力是不是就是 PC 互联网的 IBM、移动互联网的 Microsoft？ 作为 Google 的铁粉，还是希望他能打起精神一战，AI 产业需要强力的竞争才能不停向前发展，也需要他在前沿研究和系统的开源才能帮助一大众「贫穷」的 AI 创业公司。</p><p>5. 另外，除了对外开源外，Google 应该组成三个方阵面对大模型的竞争，详见去年 3 月发文。</p><p>回顾科技竞争史，PC 互联网时代的 IBM、移动互联网时代的 Microsoft、AGI 时代的 Google，新时代来临后，难道上一个时代科技霸主都难逃衰落的宿命？</p><p>当然，Microsoft 靠 Office SaaS、云和 OpenAI 又翻盘了。</p><p>历史的铁律，有被改写的可能吗？</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:15:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279728</guid>
            <link>https://www.oschina.net/news/279728</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 员工的一天]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Chain Of Thought (CoT) 第一作者、从谷歌跳槽到 OpenAI 的 Jason Wei 分享了自己在 OpenAI 的一天：</p><blockquote><p>[9:00am] 起床</p><p>[9:30am] 搭乘 Waymo 前往 Mission SF，途中在 Tartine 买个牛油果吐司</p><p>[9:45am] 背诵 OpenAI 章程。向优化之神致敬，学习《The Bitter Lession》（强化学习之父 Rich Sutton 著）</p><p>[10:00am] 在 Google Meet 上开会，讨论如何在更多数据上训练更大的模型</p><p>[11:00am] 敲代码，在更多数据上训练更大的模型。搭档是 Hyung Won Chung</p><p>[12:00pm] 去食堂吃午饭（纯素且无麸质）</p><p>[1:00pm] 真正开始在大量数据上训练大模型</p><p>[2:00pm] 处理基础设施问题（我是脑子被驴踢了吗为啥要从 master 分支拉代码？）</p><p>[3:00pm] 监控模型训练进度，玩 Sora</p><p>[4:00pm] 给刚才训练的大模型上提示工程</p><p>[4:30pm] 短暂休息，坐在牛油果椅子上，思考 Gemini Ultra 的性能到底有多强</p><p>[5:00pm] 头脑风暴模型可能的算法改进</p><p>[5:05pm] 修改算法风险太高，pass。最安全的策略还是力大砖飞（增加算力和数据规模）</p><p>[6:00pm] 晚餐时间，和 Roon 一起享用蛤蜊浓汤</p><p>[7:00pm] 回家</p><p>[8:00pm] 喝点小酒，继续写码。Ballmer’s peak（酒精带来的编码高效阶段）即将到来</p><p>[9:00pm] 分析实验结果，我对 wandb 又爱又恨</p><p>[10:00pm] 启动实验，让它自己跑一晚上，第二天查看结果</p><p>[1:00am] 实验真正开始运行</p><p>[1:15am] 上床睡觉。在纳德拉和黄仁勋的守护下入梦。心想：压缩才是真谛。晚安</p><p><img src="https://oscimg.oschina.net/oscnet/up-3041206e9fa5084776ebedb71c760828888.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2F_jasonwei%2Fstatus%2F1760032264120041684" target="_blank">https://twitter.com/_jasonwei/status/1760032264120041684</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279722</guid>
            <link>https://www.oschina.net/news/279722</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[StarkNet 撒钱，程序员在 Web3 领了 14 万 ​​​]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>StarkNet 启动空投活动，GitHub 排名前 5000 开源项目的贡献者可领取价值 $200 奖励。</p><h2>背景</h2><ul><li>StarkNet 公链项目为了激励开发者参与其平台建设，启动了空投活动。</li><li>如果曾向 GitHub 上获得较多 Star 的项目提交过 PR ，就有资格领取 111.1 STRK 的空投奖励。</li><li>只需要使用 OAuth 2.0 登录，就可以直接领取。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-44f62dafa84c34781d15d46c71c7c8c862c.jpg" referrerpolicy="no-referrer"></p><p>有程序员晒出自己在这次空投活动获得的奖励——近 14 万人民币。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-96e62f68c4891cdbfd1f43b86ddfcdcbf79.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fstrrlthedev%2Fstatus%2F1760182038504837287" target="_blank">https://twitter.com/strrlthedev/status/1760182038504837287</a></u></em></p></blockquote><h2>领取规则</h2><ol><li>截止到 2023 年 11 月 15 日，至少对全球排名前 5000 的仓库提交过三次代码贡献。</li><li>其中至少有一次贡献是在 2018 年或之后完成的。</li></ol><h2>领取步骤</h2><p>领取地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprovisions.starknet.io%2F" target="_blank">https://provisions.starknet.io/</a></u></em></p><ol><li>访问奖励领取页面并连接钱包（推荐使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2Fargent-x-starknet-wallet%2Fdlcobpjiigpikoobohmabehhmhfoodbb" target="_blank">Argent X</a>）。</li><li>通过 GitHub 登录，采用 OAuth 2.0 验证方式。</li><li>直接领取奖励。后续的治理投票和问卷调查可忽略不计。</li></ol></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279720</guid>
            <link>https://www.oschina.net/news/279720</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[华为：2 月 26 日将首发华为通信大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">华为官方微信公众号消息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7dnrCXQoOqWSfKBrCJWl6Q" target="_blank">显示</a>， 在 2 月 26 日华为产品与解决方案发布会上，即将首发华为通信大模型。</span></p><p><img height="677" src="https://oscimg.oschina.net/oscnet/up-59659387ba8ade9e0cf71c6f84d476a728e.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">华为称，2024 年，5G-A 商用元年正式开启！万兆时代已来，共同见证将 5G-A 带入现实。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:23:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279717</guid>
            <link>https://www.oschina.net/news/279717</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌发布轻量级开源大语言模型 Gemma]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌发布了开源大语言模型 Gemma，这是一款轻量级、先进的开源模型，供开发者和研究人员用于 AI 构建。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><p>Gemma 模型家族包括 2B（20 亿参数）和 7B（70 亿参数）两种尺寸，能够在不同的设备类型上运行，包括笔记本电脑、桌面电脑、IoT 设备、移动设备和云端。</p><p><strong>性能和设计</strong></p><p>Gemma 模型在技术和基础设施组件上与 Gemini 共享，这使得 Gemma 2B 和 7B 在其大小范围内相比其他开放模型具有最佳性能。</p><p>Gemma 模型不仅可以直接在开发者的笔记本电脑或桌面电脑上运行，而且在关键基准测试中的表现超过了更大的模型，同时遵循严格的安全和负责任输出标准。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-50f9213a30f71b22bb88d2abb40a2f7a116.png" referrerpolicy="no-referrer"></p><p><strong>主要特点</strong></p><ol><li><strong>轻量级、高性能模型</strong>：Gemma 模型家族包括 Gemma 2B 和 Gemma 7B 两种尺寸，提供预训练和指令调优的变体，针对其大小范围内相比其他开放模型具有最佳性能。</li><li><strong>跨框架工具链支持</strong>：支持 JAX、PyTorch 和 TensorFlow 通过原生 Keras 3.0 进行推理和监督式微调（SFT），适应多种开发需求和环境。</li><li><strong>易于入门和集成</strong>：提供准备就绪的 Colab 和 Kaggle 笔记本，以及与 Hugging Face、MaxText、NVIDIA NeMo 和 TensorRT-LLM 等流行工具的集成，方便开发者快速上手。</li><li><strong>高效的运算能力</strong>：针对多个 AI 硬件平台上进行优化，确保在 NVIDIA GPU 和 Google Cloud TPU 上的行业领先性能。通过与 NVIDIA 的合作，无论是在数据中心、云端还是本地 RTX AI PC 上，都确保了行业领先的性能和与尖端技术的集成。</li></ol><p>Gemma 模型能够在不同的设备类型上运行，包括笔记本电脑、桌面电脑、IoT 设备、移动设备和云端。这种广泛的兼容性使得模型能够适应各种应用场景和需求。</p><ul><li><span>模型地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmodels%3Fother%3Dgemma%26sort%3Dtrending%26search%3Dgoogle" target="_blank">https://huggingface.co/models?other=gemma&amp;sort=trending&amp;search=google…</a><span></span></li><li><span>博客：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fdevelopers%2Fgemma-open-models%2F" target="_blank">https://blog.google/technology/developers/gemma-open-models/</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:17:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279713/google-gemma-open-models</guid>
            <link>https://www.oschina.net/news/279713/google-gemma-open-models</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[你好，iLogtail 2.0！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者：张浩翔（笃敏）</p><h2>概述</h2><p>随着可观测数据采集需求的不断推陈出新，多样化的数据输入输出选项、个性化的数据处理能力组合、以及高性能的数据处理吞吐能力已经成为顶流可观测数据采集器的必备条件。然而，由于历史原因，现有的 iLogtail 架构和采集配置结构已经无法继续满足上述需求，逐渐成为制约 iLogtail 继续向前快速演进的瓶颈：</p><p>▶︎ iLogtail 设计之初完全面向文件日志采集至日志服务的场景：</p><p>1）简单地将日志分为多种格式，每种格式的日志仅支持一种处理方式（如正则解析、Json 解析等）；</p><p>2）功能实现与日志服务相关概念（如 Logstore 等）强绑定；</p><p>基于此设计思想，现有的 iLogtail 架构偏向於单体架构，导致模块间耦合严重，可扩展性和普适性较差，难以提供多个处理流程级联的能力。</p><p>▶︎ Golang 插件系统的引入极大地扩展了 iLogtail 的输入输出通道，且一定程度提升了 iLogtail 的处理能力。然而，囿于 C++ 部分的实现，输入输出与处理模块间的组合能力仍然严重受限：</p><p>1）C++ 部分原生的高性能处理能力仍然仅限于采集日志文件并投递至日志服务的场景使用；</p><p>2）C++ 部分的处理能力无法与插件系统的处理能力相结合，二者只能选其一，从而降低了复杂日志处理场景的性能。</p><p>▶︎ 与 iLogtail 整体架构类似，现有的 iLogtail 采集配置结构也采用平铺结构，缺乏处理流水线的概念，无法表达处理流程级联的语义。</p><p>基于上述原因，在 iLogtail 诞生 10 周年之际，日志服务启动对 iLogtail 的升级改造，寄希望于让 iLogtail 的易用性更佳，性能更优，可扩展性更强，从而更好地服务广大用户。</p><p>目前，经过半年多的重构与优化，iLogtail 2.0 已经呼之欲出。接下来，就让我们来抢先了解一下 iLogtail 2.0 的新特性吧！</p><h2>新特性</h2><h3>（一）【商业版】采集配置全面升级流水线结构</h3><p>为了解决旧版采集配置平铺结构无法表达复杂采集行为的问题，iLogtail 2.0 全面拥抱新版流水线配置，即每一个配置对应一条处理流水线，包括输入模块、处理模块和输出模块，每个模块由若干个插件组成，各模块的插件功能如下：</p><ul><li><strong>输入插件：</strong> 用于从指定输入源获取数据（各插件具体功能详见输入插件 <strong>[</strong><strong>1]</strong> ）</li><li><strong>处理插件：</strong> 用于对日志进行解析和处理（各插件具体功能详见处理插件 <strong>[</strong><strong>2]</strong> ），可进一步分为原生处理插件和扩展处理插件</li></ul><p>&lt;!----&gt;</p><ul><li>原生处理插件：性能较优，适用于大部分业务场景，推荐优先使用</li><li>扩展处理插件：功能覆盖更广，但性能劣于原生处理插件，建议仅在原生处理插件无法完成全部处理需求时使用</li></ul><p>&lt;!----&gt;</p><ul><li><strong>输出插件：</strong> 用于将处理后的数据发送至指定的存储</li></ul><p>我们可以用一个 JSON 对象来表示一个流水线配置：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f6cc95f0ae9e478bd8c674f6fae4ee9ceb9.png" alt="" referrerpolicy="no-referrer"></p><p>其中，inputs、processors 和 flushers 即代表输入、处理和输出模块，列表中的每一个元素 {...} 即代表一个插件；global 代表流水线的一些配置。有关流水线配置结构的具体信息，可参见 iLogtail 流水线配置结构 <strong>[</strong><strong>3]</strong> 。</p><blockquote><p>示例：采集 /var/log 目录下的 test.log，对日志进行 json 解析后发送到日志服务。以下是实现该采集需求对应的旧版和新版配置，可以看到新版配置十分精炼，执行的操作一目了然。</p><p><strong>旧版配置：</strong></p><pre><code>{
&nbsp;&nbsp;&nbsp;&nbsp;"configName":&nbsp;"test-config",
&nbsp;&nbsp;&nbsp;&nbsp;"inputType":&nbsp;"file",
&nbsp;&nbsp;&nbsp;&nbsp;"inputDetail":&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"topicFormat":&nbsp;"none",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"priority":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logPath":&nbsp;"/var/log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filePattern":&nbsp;"test.log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"maxDepth":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"tailExisted":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"fileEncoding":&nbsp;"utf8",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logBeginRegex":&nbsp;".*",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerFile":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerIncludeLabel":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerExcludeLabel":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerIncludeEnv":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerExcludeEnv":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"preserve":&nbsp;true,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"preserveDepth":&nbsp;1,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"delaySkipBytes":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"delayAlarmBytes":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logType":&nbsp;"json_log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"timeKey":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"timeFormat":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"adjustTimezone":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logTimezone":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filterRegex":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filterKey":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"discardNonUtf8":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"sensitive_keys":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"mergeType":&nbsp;"topic",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"sendRateExpire":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"maxSendRate":&nbsp;-1,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"localStorage":&nbsp;true
&nbsp;&nbsp;&nbsp;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;"outputType":&nbsp;"LogService",
&nbsp;&nbsp;&nbsp;&nbsp;"outputDetail":&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logstoreName":&nbsp;"test_logstore"
&nbsp;&nbsp;&nbsp;&nbsp;}
}
</code></pre><p><strong>新版流水线配置：</strong></p><pre><code>{
&nbsp;&nbsp;&nbsp;&nbsp;"configName":&nbsp;"test-config",
&nbsp;&nbsp;&nbsp;&nbsp;"inputs":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"file_log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"FilePaths":&nbsp;"/var/log/test.log"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;"processors":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_json_native"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"content"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;"flushers":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"flusher_sls",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Logstore":&nbsp;"test_logstore"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;]
}
</code></pre><p>如果在执行 json 解析后需要进一步处理，在流水线配置中只需额外增加一个处理插件即可，但是在旧版配置中已经无法表达上述需求。</p></blockquote><p>有关新版流水线配置和旧版配置的兼容性问题，请参见文末兼容性说明板块。</p><h4>全新 API</h4><p>为了支持流水线配置，同时区分旧版配置结构，我们提供了全新的用于管理流水线配置的 API 接口，包括：</p><ul><li>CreateLogtailPipelineConfig</li><li>UpdateCreateLogtailPipelineConfig</li><li>GetLogtailPipelineConfig</li><li>DeleteLogtailPipelineConfig</li><li>ListLogtailPipelineConfig</li></ul><p>有关这些接口的详细信息，请参见 OpenAPI 文档 <strong>[</strong><strong>4]</strong> 。</p><h4>全新控制枱界面</h4><p>与流水线采集配置结构相对应，前端控制枱界面也进行了全新升级，分为了全局配置、输入配置、处理配置和输出配置。</p><p><img src="https://oscimg.oschina.net/oscnet/up-52a9a2935a7738f4ddd6cc8123ae3551f2d.png" alt="" referrerpolicy="no-referrer"></p><p>与旧版控制枱界面相比，新版控制枱具有如下特点：</p><p><strong>参数内聚：</strong> 某一功能相关的参数集中展示，避免了旧版控制枱参数散落各处出现漏配置。</p><blockquote><p>示例：最大目录监控深度与日志路径中的**密切相关，旧版界面中，二者分隔较远，容易遗忘；在新版界面中，二者在一起，便于理解。</p><p><strong>旧版控制枱：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-04d5bc90063cbedb86c8049d54635e3023c.png" alt="" referrerpolicy="no-referrer"></p><p><strong>新版控制枱：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-b559b0e4ad0b5877d16aa684f9ba4d50d00.png" alt="" referrerpolicy="no-referrer"></p></blockquote><p><strong>所有参数均为有效参数：</strong> 在旧版控制枱中，启用插件处理后，部分控制枱参数会失效，从而引起不必要的误解。新版控制枱所有参数均为有效参数。</p><h4>全新 CRD</h4><p>同样，与新版采集配置对应，K8s 场景中与采集配置对应的 CRD 资源也全新升级。与旧版 CRD 相比，新版 CRD 具有如下特点：</p><ul><li>支持新版流水线采集配置</li><li>CRD 类型调整为 Cluster 级别，且将 CRD 名称直接作为采集配置名称，避免同一集群多个不同的 CRD 资源指向同一个采集配置引起冲突</li><li>对所有操作的结果进行定义，避免出现多次操作旧版 CRD 后出现的行为未定义情况</li></ul><pre><code>apiVersion:&nbsp;log.alibabacloud.com/v1alpha1
kind:&nbsp;ClusterAliyunLogConfig
metadata:
&nbsp;&nbsp;name:&nbsp;test-config
spec:
&nbsp;&nbsp;project:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-project
&nbsp;&nbsp;logstore:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-logstore
&nbsp;&nbsp;machineGroup:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-machine_group
&nbsp;&nbsp;config:
&nbsp;&nbsp;&nbsp;&nbsp;inputs:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Type:&nbsp;input_file
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FilePaths:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;/var/log/test.log
&nbsp;&nbsp;&nbsp;&nbsp;processors:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Type:&nbsp;processor_parse_json_native
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SourceKey:&nbsp;content
</code></pre><h3>（二）处理插件组合更加灵活</h3><p>对于文本日志采集场景，当您的日志较为复杂需要多次解析时，您是否在为只能使用扩展处理插件而困惑？是否为因此带来的性能损失和各种不一致问题而烦恼？</p><p>升级 iLogtail 2.0，以上问题都将成为过去！</p><p>iLogtail 2.0 的处理流水线支持全新级联模式，和 1.x 系列相比，有以下能力升级：</p><ul><li><p><strong>原生处理插件可任意组合：</strong></p><p>原有原生处理插件间的依赖限制不复存在，您可以随意组合原生处理插件以满足您的处理需求。</p></li><li><p><strong>原生处理插件和扩展处理插件可同时使用：</strong></p><p>对于复杂日志解析场景，如果仅用原生处理插件无法满足处理需求，您可进一步添加扩展处理插件进行处理。</p></li></ul><p><strong>🔔 注意：</strong> 扩展处理插件只能出现在所有的原生处理插件之后，不能出现在任何原生处理插件之前。</p><blockquote><p>示例：假如您的文本日志为如下内容：</p><p>{"time": "2024-01-22T14:00:00.745074", "level": "warning", "module": "box", "detail": "127.0.0.1 GET 200"}</p><p>您需要将 time、level 和 module 字段解析出来，同时还需要将 detail 字段做进一步正则解析，拆分出 ip、method 和 status 字段，最后丢弃 drop 字段，则您可以按顺序使用「Json 解析原生处理插件」、「正则解析原生处理插件」和「丢弃字段扩展处理插件」完成相关需求：</p><p>【商业版】</p><p><img src="https://oscimg.oschina.net/oscnet/up-6310f6b8a781ce3e256042e7f44ed09a75d.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c5dea6cb6a41a50be2f5eb48e2dbeeda960.png" alt="" referrerpolicy="no-referrer"></p><p>【开源版】</p><pre><code>{
&nbsp;&nbsp;"configName":&nbsp;"test-config"
&nbsp;&nbsp;"inputs":&nbsp;[...],
&nbsp;&nbsp;"processors":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_json_native",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"content"
&nbsp;&nbsp;&nbsp;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_regex_native",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"detail",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Regex":&nbsp;"(\S)+\s(\S)+\s(.*)",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Keys":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"ip",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"method",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"status"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_drop",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"DropKeys":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"module"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;],
&nbsp;&nbsp;"flushers":&nbsp;[...]
}
</code></pre><p>采集结果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f272a5d2ade5c817461bf406d1a73836f89.png" alt="" referrerpolicy="no-referrer"></p></blockquote><h3>（三）新增 SPL 处理模式</h3><p>除了使用处理插件组合来处理日志，iLogtail 2.0 还新增了 SPL（SLS Processing Language）处理模式，即使用日志服务提供的用于统一查询、端上处理、数据加工等的语法，来实现端上的数据处理。使用 SPL 处理模式的优势在于：</p><ul><li>拥有丰富的工具和函数：支持多级管道操作，内置功能丰富的算子和函数</li><li>上手难度低：低代码，简单易学</li><li>【商业版】统一语法：一个语言玩转日志采集、查询、加工和消费</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-4513da15197b25b1099a5707d39a222214d.png" alt="" referrerpolicy="no-referrer"></p><h4>SPL 语法</h4><h5>整体结构：</h5><ul><li>指令式语句，支持结构化数据和非结构化数据统一处理</li><li>管道符（|）引导的探索式语法，复杂逻辑编排简便</li></ul><pre><code>&lt;data-source&gt;&nbsp;
|&nbsp;&lt;spl-cmd&gt;&nbsp;-option=&lt;option&gt;&nbsp;-option&nbsp;...&nbsp;&lt;expression&gt;,&nbsp;...&nbsp;as&nbsp;&lt;output&gt;,&nbsp;...
|&nbsp;&lt;spl-cmd&gt;&nbsp;...
|&nbsp;&lt;spl-cmd&gt;&nbsp;...
</code></pre><h5>结构化数据 SQL 计算指令：</h5><ul><li>where&nbsp;通过 SQL 表达式计算结果产生新字段</li><li>extend&nbsp;根据 SQL 表达式计算结果过滤数据条目</li></ul><pre><code>*
|&nbsp;extend&nbsp;latency=cast(latency&nbsp;as&nbsp;BIGINT)
|&nbsp;where&nbsp;status='200'&nbsp;AND&nbsp;latency&gt;100
</code></pre><h5>非结构化数据提取指令：</h5><ul><li>parse-regexp&nbsp;提取指定字段中的正则表达式分组匹配信息</li><li>parse-json&nbsp;提取指定字段中的第一层 JSON 信息</li><li>parse-csv&nbsp;提取指定字段中的 CSV 格式信息</li></ul><pre><code>*
|&nbsp;project-csv&nbsp;-delim='^_^'&nbsp;content&nbsp;as&nbsp;time,&nbsp;body
|&nbsp;project-regexp&nbsp;body,&nbsp;'(\S+)\s+(\w+)'&nbsp;as&nbsp;msg,&nbsp;user
</code></pre><h3>（四）日志解析控制更加精细</h3><p>对于原生解析类插件，iLogtail 2.0 提供了更精细的解析控制，包括如下参数：</p><ul><li>KeepingSourceWhenParseFail：解析失败时，是否保留原始字段。若不配置，默认不保留。</li><li>KeepingSourceWhenParseSucceed：解析成功时，是否保留原始字段。若不配置，默认不保留。</li><li>RenameSourceKey：当原始字段被保留时，用于存储原始字段的字段名。若不配置，默认不改名。</li></ul><blockquote><p>示例：假设需要在日志字段内容解析失败时在日志中保留该字段，并重命名为 raw，则可配置如下参数：</p><ul><li>KeepingSourceWhenParseFail：true</li><li>RenameSourceKey：raw</li></ul></blockquote><h3>（五）【商业版】日志时间解析支持纳秒级精度</h3><p>在 iLogtail 1.x 版本中，如果您需要提取日志时间字段到纳秒精度，日志服务只能在您的日志中额外添加「纳秒时间戳」字段。在 iLogtail 2.0 版本中，纳秒信息将直接附加至日志采集时间（<strong>time</strong>）而无需额外添加字段，不仅减少了不必要的日志存储空间，也为您在 SLS 控制枱根据纳秒时间精度对日志进行排序提供方便。</p><p>如果需要在 iLogtail 2.0 中提取日志时间字段到纳秒精度，您需要首先配置时间解析原生处理插件，并在「源时间格式（SourceFormat）」的末尾添加「.%f」，然后在全局参数中增加"EnableTimestampNanosecond": true。</p><blockquote><p>示例：假设日志中存在字段 time，其值为 2024-01-23T14:00:00.745074，时区为东 8 区，现在需要解析该时间至纳秒精度并将 <strong>time</strong> 置为该值。</p><p><img src="https://oscimg.oschina.net/oscnet/up-443ebb6650ab6fb7334c3b3b1c5527ac60c.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-6237e2882b874738edda03a89819297d75b.png" alt="" referrerpolicy="no-referrer"></p><p>采集结果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-519f2570442d18bdb7f276c108ff1112546.png" alt="" referrerpolicy="no-referrer"></p></blockquote><p><strong>🔔 注意：</strong> iLogtail 2.0 不再支持 1.x 版本中提取纳秒时间戳的方式，如果您在 1.x 版本中已经使用了提取纳秒时间戳功能，在升级 iLogtail 2.0 后，需要按照上述示例手动开启新版纳秒精度提取功能，详细信息参见文末兼容性说明。</p><h3>（六）【商业版】状态观测更加清晰</h3><p>相比于 iLogtail 1.x 暴露的简单指标，iLogtail 2.0 极大地完善了自身可观测性的建设：</p><ul><li>所有采集配置都有完整指标，可以在 Project/Logstore 等维度上进行不同采集配置的统计与比较</li><li>所有插件都有自己的指标，可以构建完整流水线的拓扑图，每个插件的状态可以进行清楚的观测</li><li>C++ 原生插件提供更加详细的指标，可以用来监控与优化插件的配置参数</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-1eafd646874b01b9014f3feb5edee33dd27.png" alt="" referrerpolicy="no-referrer"></p><h3>（七）运行更快更安全</h3><p>iLogtail 2.0 支持 C++ 17 语法，C++ 编译器升级至 gcc 9，同时更新了 C++ 依赖库的版本，使得 iLogtail 的运行更快更安全。</p><p>表：iLogtail 2.0 单线程处理日志的性能（以单条日志长度 1KB 为例）</p><table><thead><tr><th align="left"><strong>场景</strong></th><th align="left"><strong>CPU（核）</strong></th><th align="left"><strong>内存（MB）</strong></th><th align="left"><strong>处理速率（MB/s）</strong></th></tr></thead><tbody><tr><td align="left">单行日志采集</td><td align="left">1.06</td><td align="left">33</td><td align="left">400</td></tr><tr><td align="left">多行日志采集</td><td align="left">1.04</td><td align="left">33</td><td align="left">150</td></tr></tbody></table><h2>兼容性说明</h2><h3>（一）采集配置</h3><h4>商业版</h4><ul><li>新版流水线采集配置是完全向前兼容旧版采集配置的，因此：</li></ul><p>&lt;!----&gt;</p><ul><li>在您升级 iLogtail 至 2.0 版本的过程中，日志服务会在下发配置时自动将您的旧版配置转换为新版流水线配置，您无需执行任何额外操作。您可以通过 GetLogtailPipelineConfig 接口直接获取旧版配置对应的新版流水线配置</li></ul><p>&lt;!----&gt;</p><ul><li>旧版采集配置并不完全向后兼容新配流水线配置</li></ul><p>&lt;!----&gt;</p><ul><li>如果流水线配置描述的采集处理能力可用旧版配置表达，则该流水线配置依然可以被 iLogtail 0.x 和 1.x 版本使用，日志服务会在向 iLogtail 下发配置时自动将新版流水线配置转换为旧版配置</li><li>反之，该流水线配置会被 iLogtail 0.x 和 1.x 版本忽略</li></ul><h4>开源版</h4><p>新版采集配置与旧版采集配置存在少量不兼容情况，详见 iLogtail 2.0 版本采集配置不兼容变更说明 <strong>[</strong><strong>5]</strong> 。</p><h3>（二）iLogtail 客户端</h3><p><strong>1. 使用扩展处理插件时的 Tag 存储位置</strong></p><p>当您使用扩展插件处理日志时，iLogtail 1.x 版本由于实现原因会将部分 tag 存放在日志的普通字段中，从而为您后续在 SLS 控制枱使用查询、搜索和消费等功能时带来诸多不便。为了解决这一问题，iLogtail 2.0 将默认将所有 tag 归位，如果您仍希望保持 1.x 版本行为，您可以在配置的全局参数中增加"UsingOldContentTag": true。</p><ul><li>对于通过旧版控制枱界面和旧版 API 创建的采集配置，在您升级 iLogtail 2.0 后，tag 的存储位置仍然与 1.x 版本一致；</li><li>对于通过新版控制枱界面和新版 API 创建的采集配置，在您升级 iLogtail 2.0 后，tag 的存储位置将默认归位。</li></ul><p><strong>2. 高精度日志时间提取</strong></p><p>2.0 版本不再支持 1.x 版本的 PreciseTimestampKey 和 PreciseTimestampUnit 参数，当您升级 iLogtail 2.0 版本后，原有纳秒时间戳提取功能将失效，如果您仍需解析纳秒精度时间戳，您需要参照日志时间解析支持纳秒精度板块对配置进行手动更新。</p><p><strong>3. 飞天格式日志微秒时间戳时区调整</strong></p><p>2.0 版本的飞天解析原生处理插件将不再支持 1.x 版本的 AdjustingMicroTimezone 参数，默认微秒时间戳也会根据配置的时区进行正确的时区调整。</p><p><strong>4. 日志解析控制</strong></p><p>对于原生解析类插件，除了日志解析控制更加精细板块中提到的 3 个参数，还存在 CopyingRawLog 参数，该参数仅在 KeepingSourceWhenParseFail 和 KeepingSourceWhenParseSucceed 都为 true 时有效，它将在日志解析失败时，在日志中额外增加 <strong>raw_log</strong> 字段，字段内容为解析失败的内容。</p><p>该参数的存在是为了兼容旧版配置，当您升级 iLogtail 2.0 版本后，建议您及时删去该参数以减少不必要的重复日志上传。</p><h2>总结</h2><p>为用户提供更舒适便捷的用户体验一直是日志服务的宗旨。相比于 iLogtail 1.x 时代，iLogtail 2.0 的变化是比较明显的，但这些转变只是 iLogtail 迈向现代可观测数据采集器的序曲。我们强烈建议您在条件允许的情况下尝试 iLogtail 2.0，也许您在转换之初会有些许的不适应，但我们相信，您很快会被 iLogtail 2.0 更强大的功能和更出色的性能所吸引。</p><p><strong>相关链接：</strong></p><p>[1]&nbsp;输入插件</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-19%3Fspm%3Da2c4g.11186623.0.0.2a755c0dN5uxv4" target="_blank">https://help.aliyun.com/zh/sls/user-guide/overview-19?spm=a2c4g.11186623.0.0.2a755c0dN5uxv4</a></em></p><p>[2]&nbsp;处理插件</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-22%3Fspm%3Da2c4g.11186623.0.0.2f2d1279yGXSce" target="_blank">https://help.aliyun.com/zh/sls/user-guide/overview-22?spm=a2c4g.11186623.0.0.2f2d1279yGXSce</a></em></p><p>[3]&nbsp;iLogtail 流水线配置结构</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnext.api.aliyun.com%2Fstruct%2FSls%2F2020-12-30%2FLogtailPipelineConfig%3Fspm%3Dapi-workbench.api_explorer.0.0.65e61a47jWtoir" target="_blank">https://next.api.aliyun.com/struct/Sls/2020-12-30/LogtailPipelineConfig?spm=api-workbench.api_explorer.0.0.65e61a47jWtoir</a></em></p><p>[4]&nbsp;OpenAPI 文档</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnext.api.aliyun.com%2Fdocument%2FSls%2F2020-12-30%2FCreateLogtailPipelineConfig%3Fspm%3Dapi-workbench.api_explorer.0.0.65e61a47jWtoir" target="_blank">https://next.api.aliyun.com/document/Sls/2020-12-30/CreateLogtailPipelineConfig?spm=api-workbench.api_explorer.0.0.65e61a47jWtoir</a></em></p><p>[5]&nbsp;iLogtail 2.0 版本采集配置不兼容变更说明</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Filogtail%2Fdiscussions%2F1294" target="_blank">https://github.com/alibaba/ilogtail/discussions/1294</a></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:08:47 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/11044307</guid>
            <link>https://my.oschina.net/u/3874284/blog/11044307</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[程序员因 bug 事故被公司强制要求归还 4 万年终奖]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>某程序员在 V2EX 发帖称，因线上流量异常事故，自己被公司进行处罚。处罚的结果是被要求将去年发的 4 万多年终奖归还给公司，如果逾期不还，将以每天万分之 5 的利息收取滞纳金。</p><p>该程序员还称，公司 hr 还扬言三个月内还是不还就免费开除。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-11365064309a71d744e9abe207d19996d40.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1016302" target="_blank">https://www.v2ex.com/t/1016302</a></u></em></p></blockquote><p>最新后续：</p><blockquote><p><img height="4236" src="https://oscimg.oschina.net/oscnet/up-0b14b51439371608fa1837e2222c753a465.png" width="1504" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1017164" target="_blank">https://www.v2ex.com/t/1017164</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 10:31:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279644</guid>
            <link>https://www.oschina.net/news/279644</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[我国 5G 基站总数超 337 万个，5G 移动电话用户达 8.05 亿户]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>工业和信息化部数据指出：截至 2023 年底，我国累计建成 5G 基站 337.7 万个，5G 移动电话用户达 8.05 亿户。</p><p>网络基础日益完备。我国已建成全球最大的光纤和移动宽带网络，全国行政村通 5G 比例超 80%。通信杆塔资源与社会杆塔资源双向共享取得显著成效，目前 90% 以上的基站实现共建共享，5G 基站单站址能耗相较于商用初期降低 20% 以上。</p><p>创新能力不断增强。我国 5G 技术产业在技术标准、网络设备、终端设备等方面创新能力不断增强。轻量化 5G 核心网、定制化基站等实现商用部署。5G 工业网关、巡检机器人等一批新型终端成功研发。5G 标准必要专利声明量全球占比超 42%，持续保持全球领先。</p><p>赋能效应持续凸显。融合应用广度和深度不断拓展，5G 应用已融入 71 个国民经济大类，应用案例数超 9.4 万个，5G 行业虚拟专网超 2.9 万个。5G 应用在工业、矿业、电力、港口、医疗等行业深入推广。「5G+工业互联网」项目数超 1 万个。</p><p>赋值效应更加显著。5G 移动电话用户持续增长、5G 流量消费快速提升，有效拓展了移动通信市场的发展空间。截至 2023 年底，我国 5G 网络接入流量占比达 47%。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 09:01:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279630</guid>
            <link>https://www.oschina.net/news/279630</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[法国电信公司 Orange 违反 GPL 许可协议，被罚 65 万欧元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根据 2024 年 2 月 14 日下达的判决，法国上诉法院判定当地电信公司 <strong>Orange 因未遵守 GNU GPL v2 许可证条款而侵权</strong>，并且需要向 Entr'Ouvert 支付&nbsp;<strong>50 万欧元的经济损失赔偿和 15 万欧元的精神损失赔偿</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aba84da216106bb416ed362f90f6181cab6.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweb.archive.org%2Fweb%2F20240216164701%2Fhttps%3A%2F%2Fwww.legalis.net%2Factualite%2Forange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl%2F" target="_blank">https://web.archive.org/web/20240216164701/https://www.legalis.net/actualite/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6928315e1d404157b8404126515b42d68a7.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.orange.com%2Fen" target="_blank">Orange</a></u><span>&nbsp;是一家法国电信运营商。根据上文的判决，</span>Orange 的 IDMP 平台使用了名叫 Lasso 的库，该库的版权所有者为 Entr'Ouvert 公司。<strong>Lasso 采用 GPLv2 License —— 并为私有项目提供了商业许可证</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-7e59b5839901ae3f8dc0da42fd32d14c3d1.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flasso.entrouvert.org%2F" target="_blank">https://lasso.entrouvert.org/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2d0135e65a7b51a798b2692a65007c31a65.png" referrerpolicy="no-referrer"></p><p>2005 年年底，Orange 参与了电子管理局关于实施 My Public Service 门户网站的招标活动，为身份管理提供一套 IT 解决方案，其中包括<strong>通过软件接口将 IDMP 平台与 Entr'ouvert 公司发布的 Lasso 软件库连接起来，Lasso 库采用 GPL 许可证</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7d0ef557e10594da586685534b7728c372e.png" referrerpolicy="no-referrer"></p><p>法院认为，Entr'Ouvert 首先蒙受了与其在公共市场 Mon.service-public.fr 上收益受损相关的经济损失，「因为如果 Orange 公司遵守许可合同，并签订付费许可，他们就应该向对方支付版税。」</p><p>此外，上诉法院特别指出，「Orange 免费使用 Lasso 软件为这个持续 7 年的大规模公开市场带来了利润，此外还有 Lasso 给这个门户网站在形象方面带来的好处。<strong>这番操作让 Orange 得以节省投入从而受益，因为通过免费使用 Lasso 软件，Orange 公司可以满足通信安全和隐私管理局 (ADAE) 要求的安全标准，从而能够节省研发成本</strong>。」</p><p>Entr'ouvert 着重批评 Orange 违反了 Lasso 程序的许可合同条款，这些条款涉及它作为该程序版权持有人所拥有的知识产权，因此它以涉嫌侵犯其权利为由起诉了 Orange。</p><p>上诉法院首先要求 Entr'ouvert 证明 Lasso 软件具有原创性。</p><p>根据 Entr'ouvert 出示的证据，上诉法院得出的结论是，<strong>Lasso 「在软件组成、结构和表达方面都是原创的，符合版权保护的条件」</strong>。</p><p>上诉法院随后审查了 Entr'Ouvert 援引的三起违反 GNU GPL v2 许可协议的行为。</p><p><strong>首先，法院认为 Orange 违反了许可合同第 2 条，因为它对 IDMP 所基于的 Lasso 进行了修改，却没有将 IDMP 作为一个免费整体授予政府。</strong></p><p><strong>其次，法院判定 Orange 没有进一步遵守第 3 条，因为没有提供修改后的源代码。</strong></p><p><strong>最后，法院特别指出，Orange 在没有遵守许可合同的所有条件、特别是第 4 条的情况下，复制、修改和分发了 Lasso。</strong></p><p><strong>法院还认为 Lasso 被整合到 IDMP 平台中，而 IDMP 平台的发行条件不一样，且没有征得 Entr'Ouvert 公司的授权，此举也违反了许可合同第 10&nbsp;条。</strong></p><p>总而言之，Orange 的 IDMP 产品使用了 Lasso，要么按照 GPLv2 许可证要求公布它的源代码，要么从版权所有者 Entr'Ouvert 购买许可证。Orange 没有付费也没有遵守 GPL 许可协议。法国上诉法庭判决 Orange 侵权行为成立。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 08:09:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</guid>
            <link>https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[清华大学文生视频专利公布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">国家知识产权局网站显示，近日，清华大学申请的「一种定制化多主体文生视频方法、装置、设备及介质」专利公布，发明人为王鑫；朱文武；陈虹。</span></p><p><span style="background-color:#ffffff; color:#222222">摘要显示，该申请涉及神经网络技术领域，通过多种损失对文生视频模型的参数进行优化，使优化的模型基于文本描述生成视频中的图像时，文本描述与定制化主体保持一致，且在每个主体在生成过程中的特征不会发生混淆的同时消除合成痕迹。</span></p><p><span style="background-color:#ffffff; color:#222222"><img alt="" height="453" src="https://oscimg.oschina.net/oscnet/up-1ec28ceb1ad4ccf2dfbde602d461109e5a2.jpg" width="700" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 07:17:06 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279604</guid>
            <link>https://www.oschina.net/news/279604</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.20</strong></span></h3><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要点</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/279326/linux-kernel-is-a-cna" target="_blank">Linux 内核成为 CVE 编号机构 (CNA)</a></u></h3><p>Linux 内核已被接受为 CVE 编号机构 (CNA)，这意味着他们将直接管理内核的 CVE。Linus Torvalds 近日在邮件列表发布了 Linux 6.8-rc5，并介绍称文档添加了 CVE 漏洞处理相关的指南。</p><p>文档写道，Linux 内核开发团队有能力为潜在的内核安全问题分配 CVE，而分配的 CVE 编号将在 linux-cve-announce 邮件列表上公布，修复的安全漏洞才会分配 CVE 编号，未修复的不会自动分配编号。</p><h3><u><a href="https://www.oschina.net/news/279389/dart-3-3-released" target="_blank">Dart 3.3 发布：扩展类型、JavaScript Interop 等</a></u></h3><p>Dart 3.3 现已发布，公告称此版本改变了性能和跨平台开发的游戏规则。</p><p>增强的扩展类型（Extension Types）将彻底改变性能优化以及用户与本地代码的交互方式。JavaScript interop 模型也得到了改进，引入了强大的类型安全性和开发人员友好的方式来利用 Web 平台的强大功能。「所有这些都为 WebAssembly 支持铺平了道路」。此外，新版本还增加了 Google AI 功能。</p><p><img height="300" src="https://oscimg.oschina.net/oscnet/up-3949a01f3c180246795018315421f62eccc.webp" width="300" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日观察</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-50e80801ccee84a0972ddbf9328c862d87b.png" referrerpolicy="no-referrer"></p><p>- 微博 <em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1609119537%2FO1t7Mj9XJ" target="_blank">2gua</a></u></em></p><p><img src="https://oscimg.oschina.net/oscnet/up-1d42d0aba38b933d17c04033962ce1cc5e5.png" referrerpolicy="no-referrer"></p><p>-<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapp.myzaker.com%2Fnews%2Farticle.php%3Fpk%3D65d353d4b15ec004b02314b1" target="_blank">脑极体</a></u></em></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推荐</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-048ed3535e056a8b2c5037aadf05b7b881b.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">开源之声</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-ce33753dcaf6809a8c2305f7b0fee44604a.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日项目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜单：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8d2c1aa11cc57bc0bfb89a2a2bc2f10afdd.png" referrerpolicy="no-referrer"></p><h4><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span><br><em><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf" target="_blank">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></u></em></h4><hr><p><strong>往期回顾</strong></p><ul><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf" target="_blank">开源日报第 011 期：目前还没有「大模型版 Linux」</a></u></li><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></u></li><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf" target="_blank">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></u></li><li><u><a href="https://www.oschina.net/news/277585" target="_blank">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></u></li><li><u><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">开源日报第 006 期：选择技术栈一定要选择开源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 05:47:05 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279578</guid>
            <link>https://www.oschina.net/news/279578</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年度 Rust 调查报告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">2023 年度 Rust 调查报告现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2024%2F02%2F19%2F2023-Rust-Annual-Survey-2023-results.html" target="_blank">出炉</a>，基于 2023 年 12 月 18 日至 2024 年 1 月 15 日期间进行的调查结果。此次调查问卷共收到 11950 份回复，其中 9710 份完成了所有问题。</span></p><p><span style="color:#000000"><strong>参与情况</strong></span></p><p><span style="color:#000000">参与调查的开发者来自世界各地，最多的是美国（22%），其次是德国（12%）、中国（6%）、英国 (6%)、法国 (6) %）、加拿大（3%）、俄罗斯（3%）、荷兰（3%）、日本（3%）和波兰（3%）。92.7% 的受访者更趋向于采用英语交流技术主题，相较 2022 年的 93% 略有下降；中文是第二选择，占比为 6.1%（ 2022 年为 7%）。</span></p><p><span style="color:#000000"><strong>Rust 使用情况</strong></span></p><p><span style="color:#000000">有 93% 的受访者称自己是 Rust 用户，其中 49% 的人每天（或几乎每天）都会使用 Rust，相较上一年小幅增加 2 个百分点。在没有使用 Rust 的用户中，31% 的人表示主要原因时使用 Rust 有难度；67% 的人表示他们还没有机会优先学习 Rust，这也是最常见的原因。</span></p><p><span style="color:#000000">46% 的受访者表示其不再使用 Rust 的原因在于「无法控制的因素」（比 2022 年减少了 1 个百分点），31% 的人是因为更喜欢另一种语言（比 2022 年增加了 9 个百分点），还有 24% 是因为难度（比 2022 年减少了 6 个百分点）。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-335afef97d65f03d34d0f08eb8831153557.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">操作系统的选择方面，Linux 是最受 Rust 用户欢迎的选择，其次是 macOS 和 Windows，两者份额相近。IDE 的选择上，Visual Studio Code 仍然是最受欢迎的选择，RustRover（去年发布）也获得了一些关注。</span></p><p><span style="color:#000000"><strong>Rust 在工作中的使用情况</strong></span></p><p><span style="color:#000000">34% 的受访者表示他们在工作中的大部分编码业务都使用 Rust，相较 2022 年增加了 5 个百分点。86% 的受访者雇主投资 Rust 的首要原因是能够构建相对正确且无 bug 的软件，第二个原因是 Rust 的优秀性能（83%）。77% 的受访者表示，他们的组织可能会在未来再次使用 Rust。</span></p><p><span style="color:#000000">就技术领域而言，Rust 似乎在创建服务器后端、Web 和网络服务以及云技术方面特别受欢迎。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-956fdb129c803494d840f04071cceb0996b.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><strong>对 Rust 未来的担忧和期待</strong></span></p><p><span style="color:#000000">共有 9374 名受访者分享了他们对 Rust 未来的主要担忧，其中 43% 的受访者担心 Rust 变得过于复杂，相较 2022 年增加了 5 个百分点。42% 的受访者担心 Rust 在科技行业的使用率过低。32% 的受访者最担心 Rust 开发人员和维护人员得不到适当的支持，相较 2022 年增加了 6 个百分点。</span></p><p><span style="color:#000000">另一方面，完全不关心 Rust 未来的受访者明显减少，2023 年为 18%，2022 年为 30%。</span></p><p><span style="color:#000000">就 Rust 用户希望实现、稳定或改进的功能而言，最需要的改进是 traits（trait aliases、associated type defaults 等）、const execution（generic const expressions、const trait methodsconst 等）以及 async（async closures、coroutines）。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-bcaf516c155cafe4eb2d721dc6e86434a9e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">可能是出于对复杂度的担忧，还有 20% 的受访者希望 Rust 放慢新功能的开发速度。此外，Rust 中最令用户头疼的似乎是 asynchronous Rust、traits、generics system 以及 borrow checker。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-de1d95566f02a3dccfae6db246605f3684a.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">受访者希望 Rust 维护者主要优先考虑修复编译器错误 (68%)、提高 Rust 程序的运行时性能 (57%) 以及缩短编译时间 (45%)。受访者指出，编译时间是需要改进的最重要领域之一；但有趣的是，受访者似乎也认为运行时性能比编译时间更重要。</span></p><p><span style="color:#000000"><img alt="" height="571" src="https://oscimg.oschina.net/oscnet/up-b59d67be36c91976d230c9e2d43ae22ac9e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">更多详情可查看</span>完整的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fraw.githubusercontent.com%2Frust-lang%2Fsurveys%2Fmain%2Fsurveys%2F2023-annual-survey%2Freport%2Fannual-survey-2023-report.pdf" target="_blank">调查报告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 04:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279563/rust-survey-2023-results</guid>
            <link>https://www.oschina.net/news/279563/rust-survey-2023-results</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024，RISC-V 可期]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>转载自：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6WLBNUfHyfLCq7AR9Ortuw" target="_blank">中国电子报（ID：cena1984）</a></u></em></p></blockquote><p>2023 年，长期被冠以「低端」帽子的 RISC-V 架构，终于实现了高端化过程中的两个「小目标」：一个是单核性能走高，可与 ARM Cortex-A7 对标；另一个是应用场景拓展到 PC 领域，首台搭载 RISC-V 架构的笔记本电脑<u><a href="https://www.oschina.net/news/234292">面世</a></u>。</p><p>如此势头下， 2024 年 RISC-V 的发展似乎「一片坦途」。</p><p><strong>在数据中心市场「掘金」</strong></p><p>为了实现「高端化」转型，RISC-V 架构设计企业在持续尝试将市场拓展到对算力、稳定性等指标要求更高的领域。2023 年，业界推出多个面向数据中心的 RISC-V 产品，其中包括算能科技流片业内首颗 RISC-V 服务器芯片 SG2042、赛昉科技推出的超大规模总线 IP「昉·星链-700」及 256 核 RISC-V 众核 IP 子系统平台。</p><p>在数据中心领域，当前涌现了多家剑指服务器 CPU 的 RISC-V 初创公司。赛昉科技董事长兼 CEO 徐滔认为，不只是服务器 CPU，「数据中心」市场可谓遍地是黄金，BMC 芯片、存储芯片、AI 加速器、DPU 等都可以用 RISC-V 来做。「我认为， 2024 年将有多款不同类型的 RISC-V 芯片在数据中心场景中量产落地。」徐滔向《中国电子报》表示。</p><p>此外，还有多家 RISC-V 厂商设计的 「大芯片」有流片可能，其中包括 Ventana 的 192 核、4nm 的 RISC-V 服务器 CPU——Veyron V2，Tenstorrent 的 3nm AI &amp; CPU Chiplets——Grendel 等，它们都有机会在 2024 年流片。</p><p><strong>赶上「AI 特快」</strong></p><p>「人工智能是目前正在开发的新兴技术中最重要的类别，该类应用需要新型的编程模型、新型的 SoC 以及新型的系统，我们看到 RISC-V 在其中扮演着非常重要的角色。」 SiFive 企业营销与业务开发资深副总裁刚至坚在接受《中国电子报》记者采访时表示。</p><p>刚至坚认为，RISC-V 提供了一个奇妙的、共享的生态系统， 一个 AI 编程环境以及开发新软件的环境，随着性能、可定制化能力不断提升，RISC-V 将越来越多地进入人工智能主导的新兴市场中，其应用场景包括数据中心、汽车以及消费电子等领域。</p><p><strong>高端 SoC 可商用</strong></p><p>在深度数智总裁卜祥敏看来，2024 年最关键的是 SoC 可商用产品的落地。</p><p>「2023 年我们做了一年基于 RISC-V 的整体解决方案，我深刻地感受到，现在 SoC 芯片与真正的可商业化落地之间还有不少距离。」卜祥敏告诉《中国电子报》记者，「2023 年深度数智推出了基于 RISC-V 架构的笔记本电脑。2024 年，我们计划和生态圈的合作伙伴一同推出搭载新一代基于 RISC-V 架构设计的 SoC 笔记本电脑和服务器。」</p><p>2023 年，谷歌与安卓宣布支持 RISC-V 生态。卜祥敏表示，这将推动 RISC-V 的生态系统走向完善。更加完备的生态系统，将有助于提升 RISC-V 在桌面、智能终端等领域的可用性。</p><p>徐滔认为，垂直整合是 RISC-V 处理器在高端市场落地的有效方式。「垂直整合，即通过应用定义芯片。RISC-V 在商业上标准开放、技术上架构灵活，厂商可以更好地根据应用需求设计芯片。高端应用定义芯片，更能释放垂直整合的价值，这也是 RISC-V 最大的机会。」徐滔表示。</p><p><strong>软件生态加速建设</strong></p><p>2023 年 6 月，全球 RISC-V 软件生态计划 RISE（RISC-V Software Ecosystem）组织成立。该计划由谷歌、英特尔、高通、联发科、Andes、平头哥、Rivos、SiFive、Ventana、三星、英伟达、Imagination 等共 13 家产业巨头共同发起的，旨在协助 RISC-V 国际基金会共同加速 RISC-V 商用软件生态建设。它的成立，标志着 RISC-V 软件生态从纯开源主导、基金会主导进入商业化主导、全球大规模共建的时代。</p><p>中国科学院软件研究所副所长、总工程师武延军在接受《中国电子报》记者采访时表示，由于 RISC-V 得到 Debian 和 OpenEuler 两大开源操作系统社区的官方主线支持，加之 RISE 组织成立，头部软硬件企业正式加入 RISC-V 生态，2024 年 RISC-V 软件生态将加速建设。</p><p>武延军认为，2024 年，市面上将会在 2023 年已有产品的基础上，再次出现 RISC-V 标志性高性能处理器，服务器软件生态规模化适配正式开启。开源开放和全球协作理念，使得 RISC-V 开发者的规模持续快速增长。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:24:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279556</guid>
            <link>https://www.oschina.net/news/279556</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 21 虚拟线程如何限流控制吞吐量]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>虚拟线程（Virtual Threads）是 Java 21 所有新特性中最为吸引人的内容，它可以大大来简化和增强 Java 应用的并发性。但是，随着这些变化而来的是如何最好地管理此吞吐量的问题。本文，就让我们看一下开发人员在使用虚拟线程时，应该如何管理吞吐量。</p><p>在大多数情况下，开发人员不需要自己创建虚拟线程。例如，对于 Web 应用程序，Tomcat 或 Jetty 等底层框架将为每个传入请求自动生成一个虚拟线程。</p><p>如果在应用程序内部需要自行调用来提供业务并发能力时，我们可以使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2Fjava21%2Fjep444-virtual-threads.html" target="_blank">Java 21 新特性：虚拟线程（Virtual Threads）</a>中介绍的方法去创建和使用，比如较为常用的就是<code>Executors.newVirtualThreadPerTaskExecutor()</code>。</p><pre><code class="language-java">Runnable runnable = () -&gt; {
    System.out.println("Hello, www.didispace.com");
};

try (ExecutorService executorService = Executors.newVirtualThreadPerTaskExecutor()) {
    for (int i = 0; i &lt; 100; i++) {
        executorService.submit(runnable);
    }
}
</code></pre><p>我们可以像上面开启 100 个虚拟线程来执行任务。那么问题来了，我们要如何对虚拟线程限流控制吞吐量呢？</p><h2>虚拟线程的限流</h2><p>对于虚拟线程并发控制的答案是：信号量！**划重点：不要池化虚拟线程，因为它们不是稀缺资源。**所以，对于虚拟线程并发控制的最佳方案是使用<code>java.util.concurrent.Semaphore</code>。</p><p>下面的代码示例演示了如何实现<code>java.util.concurrent.Semaphore</code>来控制虚拟线程的并发数量：</p><pre><code class="language-java">public class SemaphoreExample {

    // 定义限流并发的信号量，这里设置为：10
private static final Semaphore POOL = new Semaphore(10); 

public void callOldService(...) {
try{
POOL.acquire(); // 尝试通过信号量获取执行许可
} catch(InterruptedException e){
            // 执行许可获取失败的异常处理
}

try {
// 获取到执行许可，这里是使用虚拟线程执行任务的逻辑
} finally {
            // 释放信号量
POOL.release(); 
}
}
}
</code></pre><p>是不是很简单呢？今天的分享就到这里，希望对你有所帮助，更多关于 Java 新特性的学习可以关注我的免费专栏<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2F" target="_blank">Java 新特性</a>。</p><h2>扩展阅读</h2><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Farticle%2Fjava-21-virtaul-threads.html" target="_blank">启动 1000 万个虚拟线程需要多少时间？需要多少平台线程？</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Farticle%2Fspring-boot%2Fspring-boot-virtual-threads-vs-webflux.html" target="_blank">Spring Boot 虚拟线程与 Webflux 在 JWT 验证和 MySQL 查询上的性能比较</a></li></ul><blockquote><p>欢迎关注我的公众号：程序猿 DD。第一时间了解前沿行业消息、分享深度技术干货、获取优质学习资源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:02:42 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/didispace/blog/11044187</guid>
            <link>https://my.oschina.net/didispace/blog/11044187</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[芯片架构师 Jim Keller：英伟达的 CUDA 不是护城河，是沼泽]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>曾从事 x86、Arm、MISC 和 RISC-V 处理器研究的芯片架构师 Jim Keller 批评了英伟达的 CUDA 架构和软件技术栈，他认为 CUDA 是英伟达的沼泽而非护城河。</p><blockquote><p><strong>「CUDA 是沼泽，而不是护城河。x86 也是一片沼泽。[…] CUDA 并不美好，它是通过一次堆积一件东西来构建的。」</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-bb29c91be732d8384401f752fab63b43fa2.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fjimkxa%2Fstatus%2F1758943525662769498" target="_blank">https://twitter.com/jimkxa/status/1758943525662769498</a></u></em></p></blockquote><p>他指出，就连英伟达本身也有多个专用软件包，出于性能原因，这些软件包依赖于开源框架。</p><p>就像 x86 一样，CUDA 在保持软件和硬件向后兼容性的同时逐渐增加了功能。这确保英伟达的平台完整且向后兼容，但它影响了性能并使程序开发变得更加困难。同时，很多开源软件开发框架可以比 CUDA 更高效地使用。</p><p>Jim Keller 写道：「<strong><em>基本上没有人编写 CUDA，如果你确实编写 CUDA，它可能不会很快。[...] Triton、Tensor RT、Neon 和 Mojo 的存在是有充分理由的。</em></strong>」</p><p>甚至英伟达本身也有不完全依赖 CUDA 的工具。例如，Triton Inference Server 是英伟达的一款开源工具，可简化 AI 模型的大规模部署，支持 TensorFlow、PyTorch 和 ONNX 等框架。Triton 还提供模型版本控制、多模型服务和并发模型执行等功能，以优化 GPU 和 CPU 资源的利用率。</p><p>英伟达的 TensorRT 是一种高性能深度学习推理优化器和运行时库，可加速英伟达 GPU 上的深度学习推理。TensorRT 从各种框架（例如 TensorFlow 和 PyTorch）中获取经过训练的模型，并对其进行优化以进行部署，从而减少延迟并提高图像分类、对象检测和自然语言处理等实时应用程序的吞吐量。</p><p>尽管像 Arm、CUDA 和 x86 这样的架构可能会被认为是沼泽，因为它们的演进速度相对较慢、必须向后兼容并且体积庞大，但这些平台也不像 GPGPU 这样分散，这可能根本不是一件坏事。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:01:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279549</guid>
            <link>https://www.oschina.net/news/279549</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MariaDB 可能会以 3700 万美元被私有化]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">MariaDB 董事会<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businesswire.com%2Fnews%2Fhome%2F20240219857559%2Fen%2FAnnouncement-Regarding-Possible-Offer" target="_blank">确认</a>，已于 2024 年 2 月 15 日收到了来自加利福尼亚 K1 投资管理公司的临时收购要约。K1 于 2024 年 2 月 16 日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk1.com%2Fmeridian%2F" target="_blank">公开</a>宣布了这一要约。MariaDB 董事会正在审查可能要约并听取建议。</span></p><p><span style="color:#000000">这是一份非约束性的探索性提议，可能会根据未来几周的谈判进展而发生变化。该提议包括以每股 0.55 美元的价格购买所有 MariaDB 股票，按照该公司 2 月 5 日的收盘估值计算，约合 3700 万美元。</span></p><p><span style="color:#000000">拟定交易将通过爱尔兰法律安排计划进行，K1 或其附属公司将收购该公司 100% 的已发行股份。然而，K1 保留以合同要约的方式实施该提议的权利。尚未确定该提议将采取何种形式。</span></p><p><span style="color:#000000">值得一提的是，这一消息的发布正值该公司发生重大变化和动荡之际，新任首席执行官上任后，该公司进行了大规模裁员，并剥离了数据库即服务和地理空间业务。</span></p><p><img height="223" src="https://oscimg.oschina.net/oscnet/up-1da31f278849ce4cdcc7e6d0a823d84c4f4.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">2009 年，甲骨文公司斥资数十亿美元对 MySQL 进行了一系列收购，使 MySQL 实际上成为甲骨文公司的资产，MySQL 项目的创建者因此对 MySQL 的独立性产生了担忧，于是 MariaD B 在 15 年前作为 MySQL 的一个分支而出现。对于那些寻求完全开源的 MySQL 替代品的人来说，MariaDB 被认为是一个"drop-in"的替代品，并已被一些大公司用于在其应用程序中存储和处理数据。</span></p><p><span style="color:#000000">多年来，MariaDB 背后的商业实体筹集了大约 2.3 亿美元的风险资金，最终于 2022 年 12 月通过 SPAC 上市。但正如 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F19%2Fstruggling-database-company-mariadb-could-be-taken-private-in-a-37m-deal%2F" target="_blank">TechCrunch</a> 所指出，MariaDB 的上市远未取得巨大成功，从 2022 年底上市首日 4.45 亿美元的市值（与之前 D 轮融资时 6.72 亿美元的私有企业价值相比，市值本身已大幅下降）跌入常年低谷，自今年年初以来一直徘徊在 1 千万美元关口附近。</span></p><p><span style="color:#000000">纽约证券交易所曾在 9 月份警告 MariaDB，称其不符合上市规则 —— 该规则规定公司的全球平均市值在连续 30 天的交易期内不得低于 5000 万美元。在随后的几个月里，MariaDB 收到了第一份收购要约，来自其现有投资者 Runa Capital，初步报价为每股 0.56 美元现金。三周后，Runa 表示最终不会收购 MariaDB，而是由一家名为 RP Ventures 的公司提供 2650 万美元的贷款。</span></p><p><span style="color:#000000">今年二月初，MariaDB 宣布与债权人达成临时暂缓协议，即在寻求替代融资方案期间，债权人将不行使贷款协议中规定的任何补救措施。这一消息导致 MariaDB 的股价在几天内上涨了一倍多，这也是为什么 K1 的出价与宣布任何暂缓协议前 MariaDB 的收盘价相对应。</span></p><p><span style="color:#000000">事实上，K1 表示，它的报价比 MariaDB 2 月 5 日的收盘价（0.19 美元）高出 189%，相当于市值约为 1290 万美元。虽然不能保证 K1 会正式竞购 MariaDB，但与更像传统风险投资公司的 Runa Capital 不同，K1 在其 12 年的历史中拥有后期投资记录，这使其更接近私募股权投资领域。且 K1 已经进行了多次收购，包括在 2022 年斥资 3.19 亿美元收购澳大利亚 ELMO 软件公司，并在收购过程中将其私有化。</span></p><p><span style="color:#000000">因此，从很多方面来说，K1 可能比 Runa 更适合接管 MariaDB。根据爱尔兰收购规则第 2.6 条，K1 必须在 2024 年 3 月 29 日下午 5:00（纽约时间）（即 K1 公告后的第 42 天）之前，正式确定其收购要约或完全放弃该计划。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 02:36:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279540/mariadb-could-be-taken-private-37m-k1</guid>
            <link>https://www.oschina.net/news/279540/mariadb-could-be-taken-private-37m-k1</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
