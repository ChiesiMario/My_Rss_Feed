<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 07 Mar 2024 12:53:00 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[前谷歌软件工程师被控窃取机密 AI 技术]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>美联社报道，美国司法部周三表示，Google 公司的一名前软件工程师被指控窃取该公司的人工智能技术，同时与两家位于中国的公司秘密合作。中国公民丁林葳（音译）因四项联邦商业机密盗窃罪在加利福尼亚州纽瓦克市被捕，每项罪名皆最高可判处 10 年监禁。</p><p>总检察长梅里克-加兰（Merrick Garland）在旧金山举行的美国律师协会会议上<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dl64VlrA-GUA" target="_blank">宣布了该案</a></u>，他与其他执法部门领导人曾多次警告中国经济间谍活动的威胁以及人工智能进步带来的国家安全问题。</p><p>联邦调查局局长克里斯托弗-雷（Christopher Wray）在一份声明中说："今天的指控是最新的例证，说明中华人民共和国境内公司的关联公司为窃取美国的创新技术不择手段。窃取美国公司的创新技术和商业机密会造成就业损失，并对经济和国家安全造成破坏性后果。"</p><p>最近几周，美国司法部领导人一直在就外国对手如何利用人工智能技术对美国造成负面影响敲响警钟。</p><p>司法部副部长丽莎-摩纳哥（Lisa Monaco）在上个月的一次演讲中<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapnews.com%2Farticle%2Ffbi-election-interference-wray-2024-campaign-ai-a0c4a95c818839b18f919c6d648c4dcf" target="_blank">表示</a></u>，政府的多机构颠覆性技术打击小组将把人工智能执法放在优先事项的首位。</p><p>加利福尼亚州北区法院周三公布的一份起诉书称，丁在 2019 年受雇于 Google，可以接触到该公司超级计算数据中心的机密信息，但他在两年前开始将数百个文件上传到一个个人持有的 Google 云账户。</p><p>检察官说，在盗窃开始后的几周内，丁被中国一家初创科技公司聘为首席技术官，该公司吹嘘自己使用了人工智能技术。起诉书称，他前往中国，参加了该公司的投资者会议，并试图为其筹集资金。起诉书称，他还单独创办了一家总部位于中国的初创公司，并担任首席执行官，该公司希望训练"由超级计算芯片驱动的大型人工智能模型"，且并没有向 Google 披露这两家公司的关联关系。</p><p>12 月 26 日，他从公司辞职。三天后，Google 相关部门得知他曾以其中一家中国公司首席执行官的身份出席了在北京举行的投资者会议而报警。起诉书称，Google 方面还查看了监控录像，录像显示另一名员工在丁工作的大楼扫描了他的门禁卡，使他看起来不在中国。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9b61448ad14c6ad426c8fb453f0a7042e03.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5d14d945f47b2a80e9f34f07d722e5033ed.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 11:18:59 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282027</guid>
            <link>https://www.oschina.net/news/282027</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LFOSSA 祝大家女神节快乐！助力女性开源职业发展！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><div><div><div><p><img height="1000" src="https://oscimg.oschina.net/oscnet/up-87fca7e99dc80187c6d9bafde6383da273a.png" width="2350" referrerpolicy="no-referrer"></p><p><span style="color:rgba(0, 0, 0, 0.9)">女神节，是一个赞美和庆祝的日子。让我们在这个特殊的日子里，向所有的女性表示最深的敬意和祝福。</span><span style="color:rgba(0, 0, 0, 0.9)">回顾历史，我们可以看到女性在各个领域都取得了令人瞩目的成就。</span><span style="color:rgba(0, 0, 0, 0.9)">无论是在科学、艺术、政治还是商业领域，女性都展现出了她们独特的才华和魅力。</span><span style="color:rgba(0, 0, 0, 0.9)">她们不仅在自己的领域里取得了巨大的成功，还为整个社会带来了积极的影响。</span></p><p><span>在开源领域，虽然</span><span style="color:#000000">开源女性开发者属于少数群体，但女性开发者于开源中扮演重要的角色和贡献。</span><span>LFOSSA 开源软件学园为表达对女性的尊重，认识到女性价值，欣赏女性的才华和贡献，为她们在开源领域提供更多的机会和平台<strong>。在 3 月 8 日国际妇女节来临之际，LFOSSA 开源软件学园为众多开发者送出专属福利</strong>&nbsp;——&nbsp;</span><span style="color:#ff0000"><strong>3 月 7 日 - 3 月 10 日，</strong><strong>Linux Foundation</strong><strong>开源软件学园官方课程及认证考试全场 9 折。</strong></span></p><p><span>Linux Foundation 开源软件学园一直致力于推<span style="color:#000000">动</span></span><span style="color:#000000">开源多样化及包容的开源社区</span><span>，鼓励女性在不同领域挖掘属于自己独特的闪光点。请持续关注我们，之后陆续推出超多女神节的活动，欢迎参加！</span></p><p><span>感谢女性在不同领域取得的成就，每一位女性都拥有源源不断的智慧，同样拥有原原本本的自信。保持女性在开源事业上独特的魅力，能够充分发挥自己的潜力。</span></p><p><span>祝大家女神节快乐，继续持之以恒，卓尔不群！</span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>部份精选官方课程认证超级套购</span></span></span></p><p style="color:#242b3c; text-align:center"><span><img alt="1707387858746433.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707387858746433.png" width="270" referrerpolicy="no-referrer"></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA<span>&amp;CKS&amp;LFS258&amp;LFS260 超级套购</span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 8198 元</span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">，</span><span><span style="color:#ab1942"><span><strong>现价 7378.2 元</strong></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F23" target="_blank">CKS&amp;LFS260&amp;CKA&amp;LFS258 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span style="color:#ab1942"><span><img alt="1707387940238031.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707387940238031.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>KCNA&amp;CKA&amp;LFS250&amp;LFS258 超级套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 6158 元</s><span>，<span style="color:#ab1942"><strong>现价 5542.2 元</strong></span></span></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F57" target="_blank">LFS250&amp;LFS258&amp;KCNA&amp;CKA 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span style="color:#ff0000"><span><span><span style="color:#000000"><img alt="1707388029979327.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388029979327.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span><span>CKA&amp;CKAD&amp;</span>CKS<span>超级套购</span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 7438 元</s><span>，<span style="color:#ab1942"><strong>现价 6694.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F30" target="_blank">CKA&amp;CKAD&amp;CKS 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><img alt="1707388086590851.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388086590851.png" width="270" referrerpolicy="no-referrer"></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;CKS&amp;PCA 超级套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 6528 元</s><span>，<span style="color:#ab1942"><strong>现价 5875.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F69" target="_blank">CKA&amp;CKS&amp;PCA 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><span><img alt="1707388149744838.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388149744838.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;PCA 超级套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 4288 元</s><span>，<span style="color:#ab1942"><strong>现价 3859.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F58" target="_blank">PCA&amp;CKA 双证套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span><span style="color:#ab1942"><img alt="1707388208170950.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388208170950.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKS&amp;CKA 双证套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 5358 元</span></span><span><span style="color:#ab1942">，<strong>现价 4822.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F22" target="_blank">CKS&amp;CKA 双证套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><span><img alt="1707388275334439.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388275334439.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;ICA 双证套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 4288 元</span></span><span>，</span><strong>现价 3859.2 元</strong></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F71" target="_blank">CKA&amp;ICA 双证套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><img alt="1707388329473176.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388329473176.png" width="270" referrerpolicy="no-referrer"></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>RVFA&amp;LFD210-CN 套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 2208 元</span></span><span>，<span><span style="color:#ab1942"><strong>现价 1987.2 元</strong></span></span></span></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F63" target="_blank">RVFA&amp;LFD210-CN 套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9)"><span><span>查看更多 LFOSSA 培训、认证及套购产品：</span></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank"><span>培训</span></a><span>：<span style="color:#245bdb"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank">Linux 系统管理_云技术线上自学课程-Linux Foundation 开源软件学园</a></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank"><span>认证</span></a><span>：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank">Linux 自学考试认证-Linux Foundation 开源软件学园</a></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank">套购</a>:&nbsp;<span style="color:#245bdb"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank">Linux Foundation 开源软件学园-Linux_云技术_Kubernetes 专业考试认证_K8s_CKA_CKS</a></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:justify">&nbsp;</p><p><span><span><span>点击&nbsp;<span style="color:#ff0000"><strong>此网址</strong></span><strong>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2F" target="_blank">Linux Foundation 开源软件学园-Linux_云技术_Kubernetes 专业考试认证_K8s_CKA_CKS</a>&nbsp;</strong></span>进入 LFOSSA 官网。了解更多 Linux 基金会相关课程和认证考试。</span></span></p><p>&nbsp;</p><p><span><strong><span style="color:#000000">来自 LFOSSA 开源软件学园的</span>温馨提示：</strong></span></p><p><span><span><strong>特别需要注意的是，</strong><strong>Linux 基金会</strong><strong>发布了&nbsp;</strong><strong>LF</strong><strong>认证考试政策的变更如下</strong>：</span></span></p><p><span><span style="color:#d83931"><strong>自</strong><strong>北京时间</strong><strong>2024 年 4 月 1 日上午 8 时起，所有 36 个月有效期的</strong><strong>LF</strong><strong>认证考试将缩短为 24 个月有效期。任何在&nbsp;</strong><strong>UTC</strong><strong>&nbsp;时间 2024 年 4 月 1 日 00:00 之前，安排并通过考试的学员仍然将获得 36 个月的认证有效期。</strong></span></span></p><p><span><span>由于考试需求将会急剧增加，我们建议考生尽早安排预约 CKA 考试。你可以在这里了解有关详情：</span></span></p><p><span><span><strong>考试政策的公告</strong>——</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247498227%26idx%3D1%26sn%3D21e81f4521e07892176dc002c59a9162%26chksm%3Dc3595926f42ed030c326966c0fa15c38b502565abf76a791450f1307a12eb9404af897e8b596%26scene%3D21%23wechat_redirect" target="_blank">CNCF 认证考试更新公告</a></span></p><p><span><span><strong>考试贴士</strong>&nbsp;——</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247502744%26idx%3D1%26sn%3Dc67bc4b2851fa8fb16e88e8036810bae%26chksm%3Dc3596b4df42ee25b6513756e28352d3c2b9258a1aa2c352d15eed8aedb2116abacaa1daf085f%26scene%3D21%23wechat_redirect" target="_blank">LF 认证考试考生贴士</a></span></p></div></div></div></div></div></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 10:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282019</guid>
            <link>https://www.oschina.net/news/282019</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[我的历时一年的独立开发故事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 2023 年 2 月 5 日，当我从赫尔辛基飞往上海浦东机场时，并没有预见到接下来一年的生活将会是怎样的。经过几个月悠闲轻松的日子后，我开始了独立开发的征程。首先我会简要介绍一下成果，然后分享我对独立开发的看法以及一些技术层面的经验。 经过一年的努力，截至目前，我的成果如下：</p><ul><li>支出 2000 美元，主要云服务支出</li><li>收入 0，注册用户 0</li><li>一个可运行的系统： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flets-script.com" target="_blank">https://lets-script.com</a></li></ul><p>我不反对独立开发，但要认清现实，如果你的目标是通过独立开发发财致富，那么一个可能的结果是（开玩笑）：</p><ol><li>一年，众叛亲离</li><li>二年，妻离子散</li><li>三年，灰飞烟灭</li></ol><p>如果你有这样的觉悟，或者不是从致富的角度出发，独立开发也是一种宝贵的经历。</p><p>接下来，我将分享我开发的产品以及一些技术经验。请允许我以一个业余选手的身份谈论这些想法。。</p><h2>产品理念</h2><p>我希望打造一个以脚本为核心的简单任务执行平台。市面上的产品往往认为 Shell 脚本不够友好，因此会在外层添加各种包装，有的使用 YAML 配置，有的采用自定义编程逻辑，类似于 Github Action。然而，Github 用一个 checkout 插件来完成 git checkout 的功能，我认为直接使用 git 更为简洁明了。如果你认为 Shell 脚本已经足够强大、方便且经得起考验，那又何必在外面再加一层，用一些功能不强大的方法来掩盖 Linux 脚本系统的强大呢？</p><p>lets-script.com 允许用户部署他们自己的任务运行服务器，无论是在家中、公司还是在互联网上。目前，系统共享了两个运行服务器，一个位于日本，另一个在我家中。</p><h2>不要迷信云和云服务</h2><p>云服务和人工智能无疑都非常有价值。然而，在媒体和云服务提供商的大力宣传下，用户和开发者可能会被迷惑，失去独立思考的能力。</p><p>云服务虽然发展迅速，但单体软件同样在迅速发展。如果你没有充分的理由，就不要轻易将自有系统替换为云服务。比如，消息队列，用微软的 Eventbus 替代 RabbitMQ？我认为毫无必要，何必轻易地将自己锁定在一个厂商身上呢？我最初也使用了 Eventbus，但经过深思熟虑，最终还是切换回了 RabbitMQ。我开始使用 Azure 的容器应用服务，但后来也切换到了 Nginx 架构，所有这些措施都使我后来可以轻松地迁移到其他云平台。</p><h2>不要完全依赖第三方登录</h2><p>要保持自有的登录系统始终可用，然后再选择性的加入协作登录系统。我的系统在初期也是使用第三方的登录系统。后来，架设自己的邮件服务器，重新实现用户登录功能。以 email 为中心的登录系统是非常可靠的系统。</p><h2>Cloudflare 的诱惑和局限</h2><p>个人认为 Cloudflare 是一个非常具有特色的产品，也挺慷慨，一般个人项目基本上不需要花钱。在 https 和 http 场景下几乎是首选，我把所有的域名都交给 Cloudflare 解析了。比如我家里的一台服务器目前用作 lets-script 的命令执行服务器。网址是 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fworker-2.lets-script.com" target="_blank">https://worker-2.lets-script.com</a> , 只要家里的服务器上安装一个 Cloudlared 服务，该 https 加密的网址始终可用。</p><p>但也不要盲目信赖 Cloudflare。它并不适用于所有场景，有时使用你自己的 Nginx 才是最终的解决方案。比如，524 错误，默认超时时间为 100 秒（企业订阅可以自定义超时时间），超过 100 秒就会返回 524 错误。而我的系统，在控制枱交互的情况下，执行 10 分钟的任务是很常见的，因此无法通过 Cloudflare 代理。此外，text/event-stream 或者 ndjson 都无法通过 Cloudflare 代理，至少目前官方不支持。虽然官方支持 WebSocket，但我最终选择了 WebSocket 作为我的系统的解决方案，例如，当您运行系统的 Hello World 示例时，您可以清晰地感受到实时输出。</p><p>接下来谈谈我对独立开发的反思。</p><h2>独立开发是低效的，是一种过时的生产方式</h2><p>除了少数基于命令行的工具类软件，其它软件都需要横跨许多技术，它天然需要协作开发，用一己之力去完成是非常低效的。比如，我的系统，开始使用 Reactjs，Gatsbyjs 使用 js 开发，后来不用框架了，用自己的半通用性 js 库，切换到 typescript，然后大量自定义 Codemirror 的功能，在后端的 Webflux 之间来回切换，无论专注于那一边都可以将代码写的很稳定，但是两头兼顾，两边的代码质量都打折扣。</p><h2>独立开发需要做好充足的准备，包括技术、资金、时间和心理准备。</h2><p>由于社会形态的差异，中国人从事独立开发更需要有强大的心理准备，因为独立开发意味着你像一个工匠，将注意力转移到了产品之上，从而于社会产生距离，要控制好这种孤独感，保持身心健康。</p><h2>如果你正在考虑独立开发，请务必慎重考虑。</h2><p>如果你的主要目的是经济回报，更加需要慎重考虑。</p><p>最后，我的独立开发的产品已经完成，从 azure 平台迁移到一家日本公司的平台之后预计费用减半，就当作日常娱乐开支，让它长期运行吧。</p><p>此外，我正在积极寻找一份软件开发的工作，如果你有碰巧阅读到本文，请帮助我扩散和联系，<em><strong>非常感谢</strong></em>。</p><p>我的联系方式： <a href="https://www.oschina.net/action/GoToLink?url=mailto%3Ajianglibo%40hotmail.com" target="_blank">jianglibo@hotmail.com</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 09:48:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/jianglibo/blog/11046245</guid>
            <link>https://my.oschina.net/jianglibo/blog/11046245</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GreptimeDB v0.7 发布 — 全面支持云原生监控场景]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在上周，我们公布了 GreptimeDB 2024 路线图，揭示了今年 GreptimeDB 的几个重大版本计划。随着三月初春的到来，首个适用于生产级别的 GreptimeDB 开源版也在万物复苏的「惊蛰」时节如约而至。v0.7 版本标志着我们向生产就绪版本迈出的重要一步，我们欢迎社区的每一位成员积极参与使用，并提供宝贵的反馈意见。</p><p>从 v0.6 到 v0.7，Greptime 团队取得了显著的进步：<strong>累计合并了 184 个 Commits，修改了 705 个文件，包括 82 项功能增强、35 项 Bug 修复、19 次代码重构，以及大量的测试工作。</strong> 这期间，一共有 <strong>8 名独立贡献者</strong>参与 GreptimeDB 的代码贡献，<strong>特别感谢 Eugene Tolbakov 作为 GreptimeDB 首位 committer，持续活跃在 GreptimeDB 的代码贡献中</strong>，和我们一同成长！</p><blockquote><p><strong>更新重点（省流版）</strong><strong>Metric Engine</strong>：针对可观测场景设计的全新引擎可被推荐使用，能处理大量的小表，适合云原生监控场景； <strong>Region Migration</strong>：优化了使用体验，可以通过 SQL 方便地执行 Region 迁移； <strong>Inverted Index</strong>：高效定位用户查询所涉及数据段，显著减少扫描数据文件所需 IO 操作，加速查询过程。</p></blockquote><blockquote><p>v0.7 是 GreptimeDB 开源以来少数几次的重大版本更新之一，此次我们也将在视频号直播。了解更多功能细节、观看 demo 演示，或者和我们核心开发团队深入交流，欢迎参与下周四（3 月 14 日）晚 19:30 的直播。</p></blockquote><h2>Region Migration</h2><p>Region Migration 提供在 Datanode 之间迁移数据表的 Region 的能力，借助这个能力，我们可以容易地实现热点数据迁移，以及负载平衡的水平扩展。GreptimeDB 在发布 v0.6 时曾提到初步实现了 Region Migration，此次版本更新完善并优化了使用体验。</p><p>现在，我们可以通过 SQL 方便地执行 Region 迁移：</p><pre><code class="language-sql">select migrate_region(
    region_id,
    from_dn_id,
    to_dn_id,
    [replay_timeout(s)]);
</code></pre><p><img src="https://oscimg.oschina.net/oscnet/up-6b527cc6319d52e06cda4b35c8481e3f486.png" alt="" referrerpolicy="no-referrer"></p><h2>Metric Engine</h2><p>Metric Engine 是针对可观测场景来设计的一个的全新引擎，它的主要目标是能处理大量的小表，特别适合云原生监控比如使用 Prometheus 的场景。通过利用合成的宽表，这个新的 Engine 提供指标数据存储和元数据复用的能力，「表」在它之上变得更轻量，它可以克服现有 Mito 引擎的表过于重量级的一些限制。</p><p><img src="https://oscimg.oschina.net/oscnet/up-34283d2899e494d63d72b44a78def7c94a9.png" alt="" referrerpolicy="no-referrer"></p><ul><li><p><strong>图例 - 原始 Metric 数据</strong></p><ul><li>以下六个 Node Exporter 的 Metrics 为例。在 Prometheus 为代表的单值模型系统中，即使是关联度很高的指标也需要拆成若干个分开存储。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-9f8b2bb0d60477ad713d884fea5bed395ef.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>图例 - 用户视角的逻辑表</strong></p><ul><li>Metric Engine 原汁原味地还原了 Metrics 的结构，用户见到的就是写入的 Metrics 结构。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-7b84dc5597d1cc9db0eb3fd0c6dc5309637.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>图例 - 存储视角的物理表</strong></p><ul><li>在存储层，Metric Engine 进行了映射，使用一张物理表来存储相关的数据，能够降低存储成本，并支撑更大规模的 Metrics 存储。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-cae0172c4a2c1b78bee1eee55e9d221e63f.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>图例 - 接下来的研发计划：Fields 自动分组</strong></p><ul><li>在实际场景产生的 Metrics 中，大部分都是有关联性的。GreptimeDB 可以自动推导相关的指标并放合并到一起，不仅能跨 Metrics 减少时间线的数量，而且对于关联查询也很友好。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-27c251355fb040fe61da01dc3b819b88edb.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>存储成本优化</strong></p></li></ul><p>基于 AWS S3 存储后端进行成本测试，各写入约三十分钟的时长的数据，总和写入量约 30w row/s 。统计过程中的各个操作发生的次数，根据 AWS 的报价估算成本。测试过程中 index 功能均开启。</p><p>报价参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fs3%2Fpricing%2F" target="_blank">https://aws.amazon.com/s3/pricing/</a> 的 Standard 等级</p><p><img src="https://oscimg.oschina.net/oscnet/up-621ba7795c14b78da54e214601f04a07a59.png" alt="" referrerpolicy="no-referrer"></p><p>从上述测试表格可以看到，Metric Engine 能够通过减少物理表的数量大幅降低存储成本，各阶段操作次数均有数量级减少，折算的综合成本相比 Mito Engine 能降低八倍以上。</p><h2>Inverted Index</h2><p>Inverted Index 作为新引入的索引模块，旨在高效定位用户查询所涉及数据段，显著减少扫描数据文件所需 IO 操作，加速查询过程。TSBS 测试场景下场景性能平均提升 50%，部分场景性能提升近 200%。Inverted Index 的核心优势包括：</p><ol><li>开箱即用：系统自动生成合适的索引，用户无需额外指定；</li><li>功能实用：支持多列列值的等值、范围和正则匹配，确保在多数场景下都能迅速定位和过滤数据；</li><li>灵活适应：自动调控内部参数以平衡构建成本和查询效率，有效应对不同场景的索引需求</li></ol><ul><li><strong>图例 - Inverted Index 的逻辑表示及数据定位过程</strong><ul><li>用户在多个列指定过滤条件，经过 Inverted Index 的快速定位，能排除掉大部分不匹配的数据段，最终得到较少的待扫描数据段，实现查询加速。</li></ul></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-6ed07495343672eeb6a785d084409529bc8.png" alt="" referrerpolicy="no-referrer"></p><h2>其他更新</h2><p><strong>1. 数据库的管理功能得到显著增强</strong></p><p>我们对 information_schema 表进行了大幅补充，新增了 SCHEMATA 和 PARTITIONS 等信息。此外，新版本引入了众多新的 SQL 函数以实现对 DB 的管理操作。例如，现在通过 SQL 即可触发 Region Flush、执行 Region 迁移，还可以查询 procedure 的执行状态等。</p><p><strong>2. 性能提升</strong></p><p>在 v0.7 版本中，对 Memtable 进行了重构，提升了数据扫描速度并降低了内存占用。同时，我们针对对象存储的读写性能也做了许多的改进和优化。</p><h2>升级指南</h2><p>由于新版本存在一些重大变更，本次 v0.7 发布需要停机升级，推荐使用官方升级工具，大致升级流程如下：</p><ol><li>创建一个全新的 v0.7 集群</li><li>关闭旧集群流量入口（停写）</li><li>通过 GreptimeDB CLI 升级工具导出表结构和数据</li><li>通过 GreptimeDB CLI 升级工具导入数据到新集群</li><li>入口流量切换至新集群</li></ol><p>详细升级指南请参考：</p><ul><li>中文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.cn%2Fuser-guide%2Fupgrade" target="_blank">https://docs.greptime.cn/user-guide/upgrade</a></li><li>英文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.com%2Fuser-guide%2Fupgrade" target="_blank">https://docs.greptime.com/user-guide/upgrade</a></li></ul><h2>未来展望</h2><p>我们下一个重要的里程碑在四月份，届时将推出 v0.8 版本。这一版本将引入 GreptimeFlow，一款优化的流计算方案，专门用于 GreptimeDB 数据流中执行连续聚合操作。考虑到灵活性的需求，GreptimeFlow 既可以集成进 GreptimeDB 计算层共同部署，也能作为独立服务部署。</p><p>除了功能层面的不断升级，我们在版本性能方面也在持续进行优化，v0.7 版本的性能虽然对比之前已经有了巨大的提升，但在可观测场景下距离部分主流方案还有一些差距，这也将是我们接下来的重点优化方向。</p><p>欢迎阅读 GreptimeDB Roadmap 2024，全面了解我们全年的版本更新计划。也欢迎各位参与代码贡献或功能、性能的反馈和讨论，让我们携手见证 GreptimeDB 持续的成长与精进。</p><h3>关于 Greptime：</h3><p>Greptime 格睿科技致力于为智能汽车、物联网及可观测等产生大量时序数据的领域提供实时、高效的数据存储和分析服务，帮助客户挖掘数据的深层价值。目前主要有以下三款产品：</p><ul><li><p>GreptimeDB 是一款用 Rust 语言编写的时序数据库，具有分布式、开源、云原生和兼容性强等特点，帮助企业实时读写、处理和分析时序数据的同时降低长期存储成本。</p></li><li><p>GreptimeCloud 可以为用户提供全托管的 DBaaS 服务，能够与可观测性、物联网等领域高度结合。</p></li><li><p>GreptimeAI 是为 LLM 应用量身定制的可观测性解决方案。</p></li><li><p>车云一体解决方案是一款深入车企实际业务场景的时序数据库解决方案，解决了企业车辆数据呈几何倍数增长后的实际业务痛点。</p></li></ul><p>GreptimeCloud 和 GreptimeAI 已正式公测，欢迎关注公众号或官网了解最新动态！对企业版 GreptimDB 感兴趣也欢迎联系小助手（微信搜索 greptime 添加小助手）。</p><p>官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreptime.cn%2F" target="_blank">https://greptime.cn/</a></p><p>GitHub: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb" target="_blank">https://github.com/GreptimeTeam/greptimedb</a></p><p>文档：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.cn%2F" target="_blank">https://docs.greptime.cn/</a></p><p>Twitter: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FGreptime" target="_blank">https://twitter.com/Greptime</a></p><p>Slack: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.greptime.com%2Fslack" target="_blank">https://www.greptime.com/slack</a></p><p>LinkedIn: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fgreptime" target="_blank">https://www.linkedin.com/company/greptime</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 09:46:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6839317/blog/11046126</guid>
            <link>https://my.oschina.net/u/6839317/blog/11046126</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年 DevOps 报告：文化、用户中心性和技术能力驱动组织成功]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#060607">《</span>2023 年 DevOps 报告<span style="background-color:#ffffff; color:#060607">》强调了健康文化、用户中心性、技术能力和灵活基础设施在提高组织绩效、团队协作和员工福祉方面的重要性，并探讨了这些因素如何通过各种实践和流程相互影响。</span></p><p><img alt="" height="308" src="https://static.oschina.net/uploads/space/2024/0307/154350_urjp_4700705.png" width="366" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#060607">以下是报告的主要发现和内容概述：</span></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>1. 研究目标和方法</strong></p><ul><li>报告旨在为领导者和实践者提供影响组织、团队和员工福祉的见解。</li><li>研究使用了严格的统计评估方法，调查了超过 36,000 名专业人士，覆盖各种规模的组织和多个行业。</li><li>研究方法包括定量调查研究、日志分析和模拟信念和权力传播的方式。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>2. 关键发现</strong></p><ul><li><strong>文化的重要性</strong>：健康的文化是建立技术能力、提高技术绩效、实现组织绩效目标和帮助员工成功的关键。</li><li><strong>用户中心性</strong>：以用户为中心的开发方法可以显著提高组织绩效。</li><li><strong>软件交付性能</strong>：加快代码审查是提高软件交付性能的有效途径。</li><li><strong>技术能力</strong>：高质量的文档可以增强技术能力对组织绩效的影响。</li><li><strong>基础设施的灵活性</strong>：云计算通过提供灵活的基础设施，有助于提高组织绩效。</li><li><strong>文化投资</strong>：健康的组织文化对员工福祉和组织绩效有积极影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>3. 技术能力和流程</strong></p><ul><li>报告探讨了人工智能、基于主干的开发、松散耦合架构、持续集成和快速代码审查等技术能力如何预测性能。</li><li>这些技术能力对团队绩效、组织绩效、软件交付性能和运营性能有积极影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>4. 文档的作用</strong></p><ul><li>高质量的文档是基础，它推动了技术能力的实施，并放大了这些能力对组织绩效的影响。</li><li>文档质量对团队绩效、组织绩效和运营性能有显著的正面影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>5. 可靠性和性能</strong></p><ul><li>可靠性实践（如服务水平目标和自动化）对运营性能有显著影响，从而提高了团队和组织绩效。</li><li>高运营性能可以减少员工的倦怠感，提高生产力和工作满意度。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>6. 基础设施的灵活性</strong></p><ul><li>使用公共云的团队在基础设施灵活性上有所提高，这反过来又提高了组织绩效。</li><li>云计算对员工福祉有积极影响，包括减少倦怠、提高工作满意度和生产力。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>7. 文化投资</strong></p><ul><li>健康的文化对员工福祉和组织绩效有积极影响，包括减少倦怠、提高工作满意度和生产力。</li><li>文化对技术能力的实施和团队绩效有积极影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>8. 多样性和包容性</strong></p><ul><li>报告发现，被认定为代表性不足的群体和女性或自我描述为女性的人在倦怠感上更高。</li><li>这些群体可能承担更多的重复性工作，这可能解释了他们报告的更高倦怠水平。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>9. 新员工的生产力</strong></p><ul><li>新员工的生产力低于有经验的团队成员，但高质量的文档和人工智能的集成可能有助于他们更快地提高生产力。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>10. 研究方法和社区参与</strong></p><ul><li>报告详细描述了研究方法，包括如何生成假设、开发调查问卷、收集和分析数据。</li><li>鼓励读者加入 DORA 社区，分享经验，学习并从他人的改进实践中获得灵感。</li></ul><p><span style="background-color:#ffffff; color:#060607">报告还包含了关于如何解读报告中的模型和图表的附录，以及如何通过模拟和贝叶斯统计来探索数据的可能解释和不确定性。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:48:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281976</guid>
            <link>https://www.oschina.net/news/281976</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 加速引擎 PAI-TorchAcc：整体介绍与性能概述]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者：沈雯婷、黄奕桐、艾宝乐、王昂、李永</p><h1>1、简介</h1><p>PAI-TorchAcc(Torch Accelerator) 是阿里云人工智能平台开发的 Pytorch 上的大模型训练加速框架。</p><p>PAI-TorchAcc 提供了一套基于 Pytorch 的简洁、易用的接口，无需进行模型转换就可以无缝地接入 HuggingFace 上的模型，并用多种分布式策略进行训练加速。</p><p>PAI-TorchAcc 借助社区 PyTorch/XLA，通过 LazyTensor 技术将 Pytorch 代码转换为静态执行图，基于计算图，结合阿里云上的计算资源情况，进行了大量的 GPU 硬件上模型训练的针对性分布式优化、计算优化。</p><p>得益于简单的模型接入方式、基于计算图的优化，PAI-TorchAcc 能够灵活地支持各种大模型的多种规模，兼容不同的硬件。PAI-TorchAcc 支持常见大模型 1B-175B 的训练，训练吞吐相对 PyTorch 原生、Megatron-LM 均有提升，如 LLaMA 系列模型，相比 PyTorch 原生提升了 140%，相比 Megatron-LM 提升了 5%，在 A100 上 MFU 达到 70%，8 卡到 128 卡线性加速比达到 15.6X。</p><h1>2、背景和需求</h1><h2>2.1 背景</h2><ul><li><strong>大模型训练</strong></li></ul><p>近年来，大语言模型、视频生成类模型迅速发展，它们基于庞大的文本、图片、视频等数据集进行训练，执行多种自然语言处理、图像生成、视频生成等任务，具备强大的理解和生成能力。随着计算资源和技术的不断进步，大模型的参数量已增长到数亿甚至数万亿级别，例如 LLaMA、GPT-3、通义千问、Sora 等，这些模型在许多基准测试上表现出了前所未有的性能。</p><p>然而，训练大模型需要极高的成本。比如使用 Megatron-LM 预训练一个 OPT-175B 模型需要上千张 A100 训练 2 个月[1]，硬件利用率 MFU 约 47%，期间因为硬件故障经历了几十次 checkpoint 的加载和续训练。使用 PyTorch FSDP 进行 LLaMA-2-70B 的微调也需要 16 张 A100 运行约 13.5 小时[2]。NVIDIA A100、H100 等硬件资源价格高昂且不易获取，市面上也逐渐出现了其他性价比更高的硬件资源。</p><p>加速不同的大模型的预训练、续训练、微调，充分利用不同的硬件资源，提升资源利用率，是降低大模型训练成本的一个有效途径。</p><ul><li><strong>Megatron-LM</strong></li></ul><p>NVIDIA Megatron-LM[3]是一个基于 PyTorch 的分布式训练框架，用来训练基于 Transformer 的大模型。Megatron-LM 综合应用了数据并行、模型并行、流水并行来实现 GPT-3 等特定模型的训练。然而，不同的大模型、训练数据集接入 Megatron-LM 十分不灵活，需要将 checkpoint 和数据格式进行转换。同时，Megatron-LM 虽然对一些模型算子做了手动的优化，在面对不同模型的不同计算模式时，难以自动地应用这种手动的优化。</p><ul><li><strong>DeepSpeed</strong></li></ul><p>DeepSpeed[4]是微软开源的一个 PyTorch 上的大模型分布式训练框架，支持 ZeRO 和流水并行，并且可以结合 Megatron-LM 运行 3D 并行。DeepSpeed 已经成为 HuggingFace transformers 库中一个训练组件。然而 DeepSpeed 性能表现较差，并且和 Megatron-LM 同样存在面对不同计算模式时无法灵活优化的限制。</p><ul><li><strong>PyTorch/XLA</strong></li></ul><p>PyTorch/XLA[5]将 PyTorch 和 OpenXLA 相结合，使用 LazyTenor 技术，将 PyTorch 代码转换为静态执行图，在静态图上进行计算图优化和后端编译优化。Pytorch/XLA 主要是针对 TPU 场景进行优化，在 GPU 上还存在一定问题和优化空间，如不支持 Transformers 模型常用的 FlashAttention 加速算子、不支持 torchrun 拉起、计算通信 Overlap 差、显存开销大等问题。</p><h2>2.2 需求</h2><p>基于以上背景，我们需要一个大模型分布式训练引擎，能够方便接入多变的 PyTorch 模型，尤其是 Transformer 类模型，兼容多种硬件。在不同模型变化的计算模式下，在不同硬件变化的硬件架构和计算、访存能力下，能够自动地对计算进行优化，尤其在阿里云的硬件上能够表现较高的性能。同时，大模型导致单卡内存和显存无法完全放下，不同的模型需要结合不同的分布式策略，合理通信，完成多卡训练并提升线性加速比。</p><h1>3、PAI-TorchAcc 核心技术特性</h1><h3>灵活的模型接入</h3><ul><li>支持 LLaMA 系列、Qwen、BaiChuan、ChatGLM、OLMo、Bloom 等常见的大模型 1B-175B 的训练；</li><li>无缝对接 HuggingFace 中的模型；</li><li>一键接入和加速 Pytorch 模型。</li></ul><h3>千亿级模型参数量</h3><ul><li>已经支持 1B 到 175B 大模型训练；</li></ul><h3>全面的训练模式</h3><ul><li>支持混合精度训练，包括 Float32、Float16、BFloat16 等；</li><li>支持 Pytorch 模型的预训练、微调和续训练。</li></ul><h3>组合的分布式策略</h3><ul><li>支持 Data Parallel、Tensor Parallel、Sequence Parallel、Fully Sharded Data Parallel、Pipeline 等分布式策略及其组合。</li></ul><h3>自动计算优化和显存优化</h3><ul><li>使用手动的 Gradient Checkpoint 和自动的 Rematerialization 降低峰值显存；</li><li>自动进行显存规划和管理，降低峰值显存和减少显存碎片化；</li><li>自动对 Kernel 进行编译优化，提高计算效率；</li><li>自动接入 SOTA 的高性能 Kernel。</li></ul><h3>兼容多种硬件</h3><ul><li>兼容 NVIDIA A100/800, H100/800, V100 等；</li><li>兼容阿里云上灵骏集群的硬件资源。</li></ul><h3>与现有框架对比</h3><p><img src="https://oscimg.oschina.net/oscnet/up-16e4c9ebf76f202837eb23fa7d35588c6a8.png" alt="" referrerpolicy="no-referrer"></p><h1>4、PAI-TorchAcc 架构</h1><h2>4.1 总体架构</h2><p><img src="https://oscimg.oschina.net/oscnet/up-b1ac021283f5b408400fb4d7b8ce1ef1ce8.png" alt="" referrerpolicy="no-referrer"></p><p>PAI-TorchAcc 的架构自顶向下分为以下几层：</p><ul><li><strong>模型层</strong>：支持计算机视觉、自然语言处理、语音合成等深度学习模型训练的加速；</li><li><strong>算法库</strong>：支持 HuggingFace Transfomers、PAI-EasyNLP、TIMM 等算法库构建的模型；</li><li><strong>前端</strong>：支持以 PyTorch 为前端语言的模型训练；</li><li><strong>Lowering</strong>：使用 LazyTensor、Symbolic Trace 等技术将前端代码转换为静态执行图;</li><li><strong>IR</strong>：使用多层中间表达，包含 High-Level 的设备无关的 IR 和 Low-Level 的设备相关的 IR，基于两层 IR 上分别做计算图优化和后端编译优化。</li><li><strong>编译优化引擎</strong>：TorchAcc 的编译优化引擎包括计算图优化引擎 TorchAcc Compiler 和多种后端编译优化引擎 BladeDISC 和 OpenXLA。基于两层 IR，进行分布式优化、显存优化、通信优化、计算优化以及算子调度和显存管理等优化，生成优化的设备码。</li><li><strong>硬件</strong>：最终产生硬件相关的设备码在不同算力、带宽和显存的硬件设备上执行。</li></ul><h2>4.2 接口</h2><p>PAI-TorchAcc 抽取了一套简洁的接口，灵活接入并加速任意的 Pytorch 模型，而不需要改动原有的模型代码。</p><p>通过 PAI-TorchAcc 加速模型训练一般需要三步：</p><ol><li>定义 torchacc.Config，并指定加速选项。</li><li>调用 torchacc.accelerate，并传入 model 和 config，完成加速训练的准备。</li><li>通过 torchacc.AsyncLoader 对 torch dataset_loader 进行封装，加速数据加载。</li></ol><pre><code class="language-python">model = ...
  dataloader = ...

+ # 一行代码加速模型，也可传入 Config 配置更丰富的加速功能，如分布式策略、编译优化选项等
+ model = torchacc.accelerate(model)

+ # 异步加速数据加载
+ dataloader = torchacc.AsyncLoader(dataloader, model.device)

  model.train()
  for source, labels in dataloader:
      ...
</code></pre><h2>4.3 编译优化</h2><p>PAI-TorchAcc 通过 LazyTensor、Symbolic Trace 等技术将前端 Pytorch 代码转换为静态执行图，并在静态图上进行自动优化，在分布式的硬件设备上高效运行。</p><h2>4.4 计算图优化</h2><p>在 Tensor Graph 上进行优化，这层优化基于 High-Level IR——StableHLO 进行。</p><ul><li>分布式： 通过分图和通信算子插入，完成流水并行、SPMD 等。</li><li>显存优化：通过算子级别的显存 Live range 和复用分析、静态调度策略、自动重算、显存管理优化等来减少显存的峰值和碎片化。</li><li>计算优化：通过 CSE 等简化计算，通过算子大粒度融合来优化访存密集型算子，减少 kernel launch，减少访存，提升计算效率；通过自动的计算图匹配重写的方式接入 Flash Attention 等高性能 Kernel。</li><li>通信优化：通过通信算子的合并、拆分、异步化以及算子的调度来提升通信效率，提高计算和通信的 overlap。</li></ul><h2>4.5 后端编译优化</h2><p>在 Buffer Graph 上进行优化，这层优化基于 Low-Level 的 IR，包括 LHLO、LLVM IR 和多种 MLIR 的 dialect。</p><ul><li>多后端：支持 OpenXLA 和阿里自研的 BladeDISC 两种编译后端；</li><li>Lowering 和 Codegen：将上层的 StableHLO Lowering 成 LHLO 和多种 MLIR 的 dialect，并在各级 Lowering 过程中进行优化，最终表达为 LLVM IR，通过 LLVM 生成针对硬件的优化代码；</li><li>Custom Call：High-Level IR 自动 Pattern rewrite 的优化 kernel，通过 custom call 调用。</li></ul><h1>5、实践案例和性能</h1><p>PAI-TorchAcc 在 A100 上能够达到 70% 的 MFU，并且在多卡下几乎线性扩展（8 卡到 128 卡加速比 15.6X），在灵活支持各种模型的基础上，性能能够高于 Megatron-LM。我们在常见的开源大模型上做了性能测试，使用相同的硬件资源，PAI-TorchAcc 的训练吞吐相对 PyTorch 原生、Megatron 均有提升，如 LLaMA 系列模型相对 PyTorch 原生提升了 140%，相对 Megatron 提升了 5%。</p><p>我们将在后续的系列文章中提供一个具体的实践案例：PAI-TorchAcc 在 OLMo 模型训练上的接入示例和加速效果，并且给出加速的来源分析。</p><h1>6、总结和未来展望</h1><p>PAI-TorchAcc 可以灵活接入 Pytorch 模型，并通过并行化策略、显存优化、计算优化和调度优化等方法来加速大模型以及视觉类、语音类模型的训练。PAI-TorchAcc 已经在常见大模型上如 LLaMA、LLaMA-2、BaiChuan、ChatGLM、QWen、OLMo、Bloom 取得了不错的效果。<strong>未来我们将从以下方向继续深入优化，以支持更多的场景，取得更好的加速效果。</strong></p><ol><li>Graph Capture 优化和子图编译：在生成计算图的过程中遇到无法识别的算子将导致编译失败，我们将进一步优化 Graph Capture，并支持子图的编译优化。</li><li>自动分布式：PAI-TorchAcc 提供了多种分布式策略，然而在不同的模型和硬件上，使用哪种组合的分布式策略、如何进行分图能够取得最优的性能，仍然需要根据经验手动配置。PAI-TorchAcc 将借助静态计算图和模型、硬件特性，做自动的分布式。</li><li>AutoGC：借助静态计算图和模型、硬件特性，自动进行 checkpoint 选点。</li><li>动态 Shape 性能优化：动态 Shape 导致重编译引起的性能下降，当前我们通过分桶的方式减少了重编译的次数，仍然存在大量的 padding，如何做更高性能的动态 Shape 支持，是一个深入优化的方向。</li><li>自研编译优化引擎 BladeDISC 的优化。</li></ol><h1>引用</h1><p>[1] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2205.01068.pdf" target="_blank">https://arxiv.org/pdf/2205.01068.pdf</a></p><p>[2] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fram-efficient-pytorch-fsdp" target="_blank">https://huggingface.co/blog/ram-efficient-pytorch-fsdp</a></p><p>[3] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FNVIDIA%2FMegatron-LM" target="_blank">https://github.com/NVIDIA/Megatron-LM</a></p><p>[4] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2FDeepSpeed" target="_blank">https://github.com/microsoft/DeepSpeed</a></p><p>[5] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpytorch%2Fxla" target="_blank">https://github.com/pytorch/xla</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:46:12 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/11045933</guid>
            <link>https://my.oschina.net/u/5583868/blog/11045933</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[快手启动鸿蒙原生应用开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">「华为终端云服务」官博消息称，快手宣布全面拥抱鸿蒙生态，启动快手 App 鸿蒙原生应用开发，将推出鸿蒙星河版快手 APP。</span></p><blockquote><p><span style="color:#000000">「快手为鸿蒙生态带来更丰富的内容生态和领先的短视频社交服务能力，HarmonyOS 也为数亿快手用户带来全场景短视频社交新体验和更流畅、智能、便捷的生活服务。」</span></p></blockquote><p><img height="474" src="https://oscimg.oschina.net/oscnet/up-126df7aa28662554855ae07406650e06d46.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">对此，快手官方也在评论区回复称，鸿蒙星河版快手 APP 将为广大用户带来全场景的短视频社交新体验，用户可以在华为手机、平板、车机等多个终端实现短视频内容无缝接续，不因切换场景而中断体验。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:17:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281966</guid>
            <link>https://www.oschina.net/news/281966</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">开发工具供应商 Perforce Software <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perforce.com%2Fpress-releases%2Fannual-java-report-reveals-42-companies-are-dedicating-resources-developer" target="_blank">发布</a>了一份 Java 社区年度调查结果，即 JRebel 2024 年 Java 开发人员生产力报告；提供了有关影响 Java 发展趋势的关键因素的行业数据和分析。</span></p><p><span style="color:#000000">主要调查结果集中在提高 Java 生产力的方法上 —— 42% 的受访者创建了专门的生产力团队或工作组。今年的报告还发现了 Java IDE 偏好的变化、微服务数量的增加以及远程部署时间的延长。</span></p><p><span style="color:#000000">调查发现<strong>对 Java 工具和人才的投资</strong>呈上升趋势。60% 的受访者表示他们的公司计划在未来一年内增加 Java 开发人员，只有 13% 的受访者表示不计划增加 Java 开发人员，另有 27% 的受访者表示不确定。</span></p><p><span style="color:#000000">虽然市场不景气，但开发人员工具预算基本保持稳定。42% 的受访者表示计划增加 Java 工具预算，22% 的受访者不打算增加工具预算，36% 的受访者不确定。此外，31% 的受访者表示他们的年度工具预算（每位开发人员）为 500 美元或以上，相较 2023 年的 22% 有所增长。</span></p><p><img height="231" src="https://oscimg.oschina.net/oscnet/up-7daaf894200c1a119c1d21b6d56e898ec2b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Perforce 首席技术官 Rod Cope 表示："Java 将继续存在"。「这些数字共同传递出一个强烈的信息：Java 将继续成为企业应用的核心部分。事实上，企业在大型 Java 应用程序方面的根深蒂固，将继续成为整个开发人员生态系统雇用 Java 开发人员的推动力。」</span></p><p><span style="color:#000000">就开发人员<strong>最常用的 Java 版本而言</strong>，11% 的受访者表示已经升级到了 Java 21；但仍有 24% 的受访者表示他们正在使用 Java 8，18% 的受访者正在使用 Java 11。</span></p><p><img height="372" src="https://oscimg.oschina.net/oscnet/up-205fcee58753d4df208b0e00bf9e72da113.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Perforce 表示，考虑到 Oracle 分别在 2022 年 3 月和 2023 年 9 月停止了对 Java 8 和 Java 11 的高级支持。因此，不受支持的 JDK 版本的高使用率意味着公司正在获得第三方供应商提供的支持，如 Amazon Corretto、Azul Zulu 和 OpenLogic 等。且随着 Oracle 加快长期支持 JDK 版本的频率（从每三年一次到每两年一次），预计 Java 21 的采用率将会增加。</span></p><p><span style="color:#000000">在 <strong>Java IDE 的偏好</strong>方面，IntelliJ IDEA 再次以 41% 的比例位居榜首。Eclipse 以 23% 位居第二，Microsoft Visual Studio Code 以 19% 的份额排名第三。此外，还有 84% 的 IntelliJ IDEA 用户表示，他们在 Java 开发实践中还使用过其他 IDE，其中 VSCode 是最常见的选择。</span></p><p><span style="color:#000000">受访者的 <strong>Java 技术栈与</strong>往年相比大部分保持不变，Tomcat、Spring Boot 和 Jenkins 等主流技术仍遥遥领先。36% 的受访者表示他们使用 Tomcat 作为主要应用程序的应用服务器，其次是 JBoss/Wildfly (15%)、WebLogic (12%)、WebSphere (10%)、Jetty (10%) 、Glassfish/Payara (8%)。</span></p><p><span style="color:#000000">微服务框架的结果也是类似的，67% 的受访者使用 Spring Boot；其他分别是 DropWizard（11%）、Quarkus（8%）、Micronaut（5%）和 Vert.x（1%）。Jenkins 是迄今为止最流行的 CI/CD 技术，占 37%。TeamCity 的使用率相较 2023 年增长了一倍多（10%）；其他技术的使用率基本保持不变，GitHub Actions（17%）、Travis CI（9%）、Circle CI（8%）和 Bamboo（7%）。</span></p><p><img height="458" src="https://oscimg.oschina.net/oscnet/up-4f9b117abee52a3c46b662a7c76b9502fc6.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Amazon Web Services 是最受欢迎的云供应商，占 31%，其次是 Microsoft Azure，占 18%。表示不使用任何云供应商的受访者比例从去年的 21% 下降至 13%。</span></p><p><span style="color:#000000">当 Java 开发人员被问及，如果开发时间增加 10%，他们会怎么做时？增加功能（26%）和提高测试覆盖率（18%）等务实的答案名列前茅，但其他答案也包括"喝咖啡"和"消除技术债务"等。</span></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jrebel.com%2Fsites%2Fdefault%2Ffiles%2Fpdfs%2Freport-jrebel-2024-dev-productivity.pdf" target="_blank">查看完整报告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281964/perforce-annual-java-report</guid>
            <link>https://www.oschina.net/news/281964/perforce-annual-java-report</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[如果企图在人工智能上搞「小院高墙」，将会犯下新历史错误]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 7 日上午 10 时，十四届全国人大二次会议在梅地亚中心新闻发布厅举行记者会，中共中央政治局委员、外交部长王毅就「中国外交政策和对外关系」相关问题回答中外记者提问。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9567f8c994b50351b847eed70b2d4975657.png" referrerpolicy="no-referrer"></p><p>凤凰衞视记者提问：国际社会非常关注人工智能问题，很多国家提出关于人工智能全球治理方案，我们关注到中国也提出了关于《全球人工智能治理倡议》，中方认为如何才能确保人工智能朝着真正有利于人类文明进步的方向发展？另外，中方对大国人工智能合作持何立场？</p><p>王毅说，人工智能进入爆发式发展的关键阶段。我们主张发展与安全并重，既要拥抱新事物新机遇，也要装好刹车再上路，共同推进人工智能全球治理。去年 10 月，习近平主席提出《全球人工智能治理倡议》，清楚阐明了中方的态度和主张。</p><p>我们关注的主要是三个确保：<strong>一是确保有益</strong>。人工智能的发展有利于人类共同福祉，符合人类伦理规范，符合国际法规则，符合人类文明进步方向。<strong>二是确保安全</strong>。人工智能始终处于人类控制之下，不断提高可解释性和可预测性，为此要建立各种风险评估和管控机制。<strong>三是确保公平</strong>。在联合国框架下成立人工智能国际治理机构，各国都能在人工智能的发展进程中平等参与、平等受益。</p><p>王毅说，我还要强调的是，<strong>如果企图在人工智能上也搞什么「小院高墙」，将会犯下新的历史错误，不仅阻挡不了各国的科技发展，还会破坏国际产业链供应链完整，削弱人类应对风险挑战的能力</strong>。中国对与各国开展人工智能合作持积极开放态度，迄今已经与一些国家建立了对话机制。人工智能大国之间的合作很重要，发展中国家的能力建设也很重要。我们将适时向联大提交「加强人工智能能力建设国际合作」的决议草案，促进各方加强技术共享，努力弥合智能鸿沟，不让任何国家掉队。谢谢！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281963</guid>
            <link>https://www.oschina.net/news/281963</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[星动纪元开源人形机器人训练框架 Humanoid-Gym]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年 3 月 5 日，具身智能与人形机器人公司星动纪元联合清华大学、上海期智研究院开源了<strong>人形机器人强化学习训练框架 Humanoid-Gym</strong>。</p><ul><li>项目主页：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsites.google.com%2Fview%2Fhumanoid-gym%2F" target="_blank">https://sites.google.com/view/humanoid-gym/</a></li><li>代码仓库：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Froboterax%2Fhumanoid-gym" target="_blank">https://github.com/roboterax/humanoid-gym</a></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-03d076aeda9ad21f6cc644bd6eeb25408c4.png" referrerpolicy="no-referrer"></p><p>公开资料显示，星动纪元于 2023 年 8 月在北京成立，由清华大学交叉信息研究院孵化，致力于具身智能以及人形通用机器人技术和产品的研发。创始人陈建宇是清华大学交叉信息研究院助理教授、博士生导师，同时也是清华大学特聘研究员、拥有 10+年机器人和 AI 研发经验。</p><p>这次开源的 Humanoid-Gym 框架，旨在通过精心设计的奖励函数以及域随机化技术， 显著简化人形机器人的训练以及实现 sim-to-real 转换的难度，从而解决由于人形机器人结构高度复杂性导致其在强化学习训练以及从模拟环境向真实世界迁移（即 sim-to-real transfer）的过程中遇到的挑战。</p><p>星动纪元表示，除了用 sim-to-real 验证以外，另一个常见的做法是用第二个更高精度的仿真环境来做初步做验证（sim-to-sim）。Humanoid-Gym 开源后，用户可以通过该框架轻松运用 sim-to-sim 转换功能，先在更高精度的仿真环境 Mujoco 中进行初步验证与筛选，从而提升 sim-to-real 转换的效率和成功率。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-95a8171d1abfb99f48eb5c4100d0f64b981.png" referrerpolicy="no-referrer"></p><p>除此之外，该开源项目还引入了若干评估指标，用以衡量训练策略的效果，包括但不限于速度追踪、动作丝滑程度等。</p><p>目前，星动纪元有两款型号的人形机器人产品：小星（1.2 米高）和小星 max（1.65 米高），来适配不同应用场景的需求。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6e747fd3917cdd43b86821147b1cc37e93c.png" referrerpolicy="no-referrer"></p><p>小星体型更小巧，动态性能强，可完成室内外跑、跳、高速行走等动作。小星 Max 为全尺寸人形机器人，身型高度和成年人相当，手臂、腰部以及全身其他部位具备更高的自由度，还配有高自由度灵巧手，未来目标场景是在工厂制造场景或服务场景，替代人类完成各种各样较为精细的操作。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 06:36:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281958</guid>
            <link>https://www.oschina.net/news/281958</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微信即将推出原生 Linux 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>吾爱破解社区用户 @白水 1573 爆料，微信将迎来 Linux 原生版重构，全新 1.0 版本已开启内测，并放出了测试截图和安装包。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9af837ce67f19fb7b329d4d0fb71207f1ea.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ed1aeefda777af4ff1f935bef63f397b5aa.png" referrerpolicy="no-referrer"></p><p>根据爆料，<strong>微信 Linux 原生版将支持 X86、ARM、龙芯 LoongArch64 架构，系统方面支持麒麟和统信 UOS</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-45d02b4e7f43abf0340d5c2eccc4338b445.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-4ea81dfeb9ddcea5859b67b6c9ce8607969.png" referrerpolicy="no-referrer"></p><p>网友总结原生 Linux 版微信使用体验：</p><blockquote><h3>（一）优点</h3><p><span style="color:#333333">1、运行，不卡顿、不闪退、界面不花屏、托盘提醒正常</span><br><span style="color:#333333">2、能用小程序、视频号、看一看、搜一搜</span><br><span style="color:#333333">3、手机端、电脑端消息同步</span><br><span style="color:#333333">4、截图正常</span><br><span style="color:#333333">5、文件收发正常</span><br><span style="color:#333333">6、可以视频、语音通话</span></p><h3>（二）暂存在缺点</h3><p><span style="color:#333333">1、消息不能撤回</span><br><span style="color:#333333">2、消息转发不能多选</span><br><span style="color:#333333">3、截图快捷键无效</span><br><span style="color:#333333">4.、文件（除视频）接收双击无法调用本地应用，仅打开下载文件夹目录</span><br><span style="color:#333333">5、不能发送语音消息</span><br><span style="color:#333333">6、只能拖入文件，不能拖出</span><br><span style="color:#333333">7、部分 Linux 发行版登录失败（疑是白名单，可以用麒麟商店旧微信登录再安装新微信解决）</span><br><span style="color:#333333">8、不能导入和导出聊天记录</span><br><span style="color:#333333">9、部分发行版托盘显示异常</span></p></blockquote><p>下载地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.cnxclm.com%2Fs%2FXOxIb%3Fpath%3D%252F" target="_blank">https://cloud.cnxclm.com/s/XOxIb?path=%2F</a></p><p><img height="474" src="https://oscimg.oschina.net/oscnet/up-9b3b17a7b964a53f15342935405455f1582.png" width="1884" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 04:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281936/wechat-linux-1-0-beta</guid>
            <link>https://www.oschina.net/news/281936/wechat-linux-1-0-beta</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | Google=开源，好评；Microsoft=闭源收入还低，差评]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.6</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/281751/swift-5-10-released" target="_blank">Swift 5.10 发布</a></h3><p>Swift 5.10 中的完全数据隔离为下一个主要版本 Swift 6 奠定了基础。Swift 6.0 编译器将提供新的、可选的 Swift 6 语言模式，该模式将默认强制执行完全数据隔离，项目团队将着手进行过渡消除所有用 Swift 编写的软件之间的数据竞争。</p><h3><a href="https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management" target="_blank">Linux 基金会推出 「反诈」 开源项目 Tazama，获盖茨基金会资助</a></h3><p style="margin-left:.0001pt; margin-right:0"><span><span><span><span>在比尔及梅琳达・盖茨基金会（Bill &amp; Melinda GatesFoundation）的支持下，Linux 基金会慈善机构（LF Charities）宣布推出 Tazama，这是一套用于实时欺诈预防的开源软件解决方案。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-935f8d1d736dc3d5b53baa4a2e1caebd24b.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img height="754" src="https://oscimg.oschina.net/oscnet/up-a7d0f80f5cc09d8135b50ee8615dcfab582.png" width="3036" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1441019625%2FO3J0EzPjG" target="_blank">雪龙郎</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-d892b5e238e2be9cee6852210c513370dd2.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1644684112%2FO3JANzqLf" target="_blank">木遥</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-67b3f765a8ae3a15bca297368a0aa7ee939.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7ObcyT-kHe-pyhU5rCfFjQ" target="_blank">机器之心</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-c1dd9862156321ccd63412b122bf6c838d6.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmli%2Fautocut" target="_blank">https://github.com/mli/autocut</a></u></em></p><hr><h2><span style="color:#16a085"><strong>开源之声</strong></span></h2><p>&nbsp;<img height="1354" src="https://oscimg.oschina.net/oscnet/up-37f0bd8def5cbfad73ac2145f10540b8f91.png" width="2800" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1908be40e2e08058e93c95f9f86722ac5d1.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-7d1341f9d2e5187641d562c7134862c184d.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精选</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-4191abfd5a0da45ae85d2eb79430cc2e943.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">开源日报第 023 期：Google=开源，好评；Microsoft=闭源收入还低，差评</a></u></em></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">开源日报第 022 期：轻松复现 Sora 模型；事关 CUDA 兼容，英伟达禁止了；百度还差一个「遥遥领先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">开源日报第 021 期：闭源模型就是比开源安全；起诉 OpenAI 不能更赞同；中国算力产业出现五个真问题</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">开源日报第 020 期：为什么王炸都来自 OpenAI；Pingora 最好不要用 YAML 当配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">开源日报第 019 期：我让 AI 用 C 语言写一个算法；微软三进制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">开源日报第 018 期：苹果十年造车梦碎；这个开源项目有点...「大胆」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">开源日报第 017 期：MariaDB 消亡史；写代码我有三不沾；V 神建议马斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 04:11:08 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281931</guid>
            <link>https://www.oschina.net/news/281931</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【比较 ORM 操作数据】总结]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h4>写在最后</h4><p>经过将近一周时间的框架收集、学习、实验、编码、测试市面上常见的 ORM 框架，过程中拜读了很多作者的博文、样例，学习很多收获很多。 重新梳理下整理的框架：mybatis-plus、lazy、sqltoy、mybatis-flex、easy-query、mybatis-mp、jpa、dbvisitor、beetlsql</p><p>下面从一下几点出发作出总结</p><ul><li>文档方面：学习过程中 mybatis-plus、jpa 提供的文档资料是比较全和晚上，经得住市场的考验</li><li>技术方面：beetlsql、easy-query、mybatis 系列，三类框架都已经支持 spring 和 solon 生态，其技术架构设计可以推荐大家学习</li><li>并发方面：jpa、db_visitor 还需要开发时候深度优化处理</li><li>大数据存储方面： Lazy 具有一定优势，大数据查询方面：sqltoy 反射处理的比较优秀</li></ul><p>以上是个人整理的观点，如果大家有不同的想法和意见可以在<a href="https://gitee.com/wujiawei1207537021">gitee</a>或者个人博客留言<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.csdn.net%2Fqq_22903677%3Ftype%3Dblog" target="_blank">CSDN</a></p><p>细节数据对比（一万以内基本相差不大）</p><ul><li>细节数据对比，数据属于并发行测试数据，如果测试总数是一百，那么会执行一百次 batchStory，一百次 findPage 每次执行的条数在之前数据的基础上+1</li></ul><p>从形成的折线图看（具体趋势看排名与测试结果）</p><ul><li>存储性能对比: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql 更适合并发性数据存储。jpa、db_visitor 处理耗时较长</li><li>分页查询性能对比: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、db_visitor、beetlSql 都比较稳定。jpa 处理时间明显起伏</li></ul><p><img height="679" src="https://oscimg.oschina.net/oscnet/up-108d2b6dbb2cbdc219a75ca4040c5d2ab0a.png" width="1406" referrerpolicy="no-referrer"></p><p><img height="698" src="https://oscimg.oschina.net/oscnet/up-0738f46c7c49b88bb0b6c58ca71c33372cd.png" width="1402" referrerpolicy="no-referrer"></p><p>批量保存：</p><ul><li>一万条数据以内 lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql、jpa、db_visitor 性能趋于一致</li><li>十万数据时，处理时间由快到慢依次是: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql、db_visitor、jpa，其中 db_visitor、jpa 处理时间明显起伏</li></ul><p>分页查询：</p><ul><li>一万条数据以内，几款 ORM 均保持在 200 毫秒内</li><li>十万数据时，处理时间由快到慢依次是: sqltoy、db_visitor、easy-query、lazy、beetlSql、mybatis、mybatis-mp、jpa、mybatis-flex</li><li>&nbsp;</li></ul><h3>快速数据对比 (大数据曲线图)</h3><p><img height="674" src="https://oscimg.oschina.net/oscnet/up-b50ab90449379aba424545ef66277f5b0ce.png" width="1391" referrerpolicy="no-referrer"></p><p><img height="691" src="https://oscimg.oschina.net/oscnet/up-15d9a6ed061150752d3225078a5b7199560.png" width="1402" referrerpolicy="no-referrer"></p><h4><a href="https://gitee.com/wujiawei1207537021/wu-compare-orm-demo">当前项目地址</a></h4><h4><a href="https://gitee.com/wujiawei1207537021/wu-framework-parent/tree/master/wu-inner-integration/wu-database-parent">lazy-orm 地址</a></h4><h4><a href="https://gitee.com/baomidou/mybatis-plus">mybatis 地址</a></h4><h4><a href="https://gitee.com/sagacity/sagacity-sqltoy">sqltoy 地址</a></h4><h4><a href="https://gitee.com/mybatis-flex/mybatis-flex">mybatis-flex 地址</a></h4><h4><a href="https://gitee.com/xuejm/easy-query">easy-query 地址</a></h4><h4><a href="https://gitee.com/mybatis-mp/mybatis-mp">mybatis-mp 地址</a></h4><h4><a href="https://gitee.com/zycgit/dbvisitor">dbvisitor 地址</a></h4><h4><a href="https://gitee.com/xiandafu/beetlsql">beetlsql 地址</a></h4></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 03:04:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281908</guid>
            <link>https://www.oschina.net/news/281908</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Node.js 新版官网开启 Beta 测试：全新现代化 UI、优化交互]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Node.js 新版官网已开启 Beta 测试，体验地址：<strong><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbeta-node-js-org.vercel.app%2Fen" target="_blank">https://beta-node-js-org.vercel.app/en</a></u></em></strong>。</p><ul><li><strong>Node.js 新版官网首页</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-d7f75fbfacc0c0f7aa4bd49a44845da9c0e.png" referrerpolicy="no-referrer"></p><ul><li><strong>当前官网首页</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-d7fdf3a71b012fa030e0d8da045acd8a078.png" referrerpolicy="no-referrer"><br><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnodejs.org%2Fen" target="_blank">https://nodejs.org/en</a></u></em></p><p>可以看到，与当前版本相比，新版官网的视觉效果、页面布局、展现内容都有了很大的提升，整体上更大气、更现代化。而且首页关于 Node.js 的介绍也变得更突出、描述更全面。</p><p>新版官网最大的交互变化是在首页添加了「全局搜索」入口，方便用户随时检索文档、博客、下载等信息。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c9984afc8c57cf2cc9b031519ad713980ba.png" referrerpolicy="no-referrer"></p><p>其他子页面一览：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5219eed54c5df5855bb21a3c939725e914b.png" referrerpolicy="no-referrer"></p><p><img height="1854" src="https://oscimg.oschina.net/oscnet/up-82a9406af23007a8c812f31fd7c8bdce52f.png" width="3360" referrerpolicy="no-referrer"></p><p><img height="1852" src="https://oscimg.oschina.net/oscnet/up-c626de0d15afa528c4f04eb59658c79635e.png" width="3360" referrerpolicy="no-referrer"></p><p><img height="1858" src="https://oscimg.oschina.net/oscnet/up-9f4190b429a1060ceb08600f74698605af6.png" width="3360" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-432b101ae6fdf83b85ce42d68b8f7ca2b68.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281899/beta-node-js-org</guid>
            <link>https://www.oschina.net/news/281899/beta-node-js-org</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[零一万物开源 Yi-9B，代码数学综合能力全面增强]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">零一万物<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0CXIBlCZ7DJ2XjYT6Rm8tw" target="_blank">宣布</a>开源 Yi-9B 模型，并声称该模型是当前 Yi 系列模型中的「理科状元」——代码和数学能力表现最佳；不偏科，中文能力也很强。「这是继今年 1 月 23 日开源多模态模型 Yi-VL-34B 之后，零一万物在开源方向上的又一重要成果。 」</span></p><p><span style="color:#000000">根据介绍，Yi-9B 是目前 Yi 系列模型中<strong>代码和数学能力最强</strong>的模型，它的基本信息如下：</span></p><ul><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">参数大小：Yi-9B 的实际参数为 8.8B。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">上下文长度：与 Yi 系列其他模型一样，默认上下文长度是 4K tokens。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">训练数据：</span></p><ul><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">数据量：Yi-9B 是在 Yi-6B （使用了 3.1T tokens 训练）的基础上，使用了 0.8T tokens 进行继续训练。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">数据时间：使用截止至 2023 年 6 月的数据。</span></p></li></ul></li></ul><h4><span style="color:#000000"><strong>模型优势</strong></span></h4><p><span style="color:#000000">一直以来，Yi 系列模型的中英文能力很强 ，但在代码和数学方面还有提升空间。Yi-9B 补足了这一短板，增强了 Yi 系列模型全方位的能力。</span></p><p><span style="color:#000000"><strong>代码和数学能力出色，综合实力强劲</strong></span></p><ul><li><span style="color:#000000">在综合能力方面（Mean-All），Yi-9B 的性能在尺寸相近的开源模型中最好，超越了 DeepSeek-Coder、DeepSeek-Math、Mistral-7B、SOLAR-10.7B 和 Gemma-7B。</span></li></ul><p><span style="color:#000000"><img height="378" src="https://oscimg.oschina.net/oscnet/up-1c17af91388b4e6acdee7ed9bf59f8bd2e5.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在代码能力方面（Mean-Code），Yi-9B 的性能仅次于 DeepSeek-Coder-7B，超越了 Yi-34B、SOLAR-10.7B、Mistral-7B 和 Gemma-7B。</span></li></ul><p><span style="color:#000000"><img height="312" src="https://oscimg.oschina.net/oscnet/up-a90214a7e2dad299b6a03ee6c2e6a898f49.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在数学能力方面（Mean-Math），Yi-9B 的性能仅次于 DeepSeek-Math-7B，超越了 SOLAR-10.7B、Mistral-7B 和 Gemma-7B。</span></li></ul><p><span style="color:#000000"><img height="332" src="https://oscimg.oschina.net/oscnet/up-a0e32de51761ccbe2fc04b4a2faac111e6a.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在常识和推理能力方面（Mean-Text），Yi-9B 的性能与 Mistral-7B、SOLAR-10.7B 和 Gemma-7B 不相上下。</span></li></ul><p><span style="color:#000000"><img height="370" src="https://oscimg.oschina.net/oscnet/up-85575f5ed5226bb33b1b2e59f15b6bc5d36.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在语言能力方面，相比于其他相近尺寸的模型，Yi-9B 不仅具备不错的英文能力，还拥有 Yi 系列模型广受好评的强大中文能力。</span></li></ul><p><span style="color:#000000"><img height="191" src="https://oscimg.oschina.net/oscnet/up-8e95430baa7a029eb10481b6919edfabb7d.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img height="285" src="https://oscimg.oschina.net/oscnet/up-23517d9512aa2906a7fa63e150b50a3f6e7.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><strong>消费级显卡可用，使用成本友好</strong></span></p><ul><li><span style="color:#000000">Yi-9B（BF 16） 和其量化版 Yi-9B（Int8）都能在消费级显卡上轻松部署，使用成本较低，开发者友好。</span></li></ul><p><span style="color:#000000"><img height="182" src="https://oscimg.oschina.net/oscnet/up-8ed07dfa90b5107e5affdd2e39bb9392cac.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong>未来展望</strong>&nbsp;</h4><p style="margin-left:0; margin-right:0">为了最大程度地提高模型性能，团队计划根据 scaling laws 动态调整算力资源在模型大小和数据大小上的分配，因此，团队将继续研究以下方向：</p><ul><li><p style="margin-left:0; margin-right:0">更优化的宽度扩增方法，尽量保留原模型的性能。</p></li><li><p style="margin-left:0; margin-right:0">更高效的分阶段训练和调参方式，尽量让模型收敛得更好。</p></li></ul><p><span style="color:#000000">有关模型训练方面等方面的更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0CXIBlCZ7DJ2XjYT6Rm8tw" target="_blank">查看官方公告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:25:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281895</guid>
            <link>https://www.oschina.net/news/281895</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mac 上 Llama2 大语言模型安装到使用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>LLAMA 介绍</h3><p>LLaMA 是由 Facebook 的母公司 Meta AI 设计的一个新的大型语言模型。LLaMA 拥有 70 亿到 650 亿个参数的模型集合，是目前最全面的语言模型之一。</p><p>Llama 是目前唯一一个可以进行本地部署和本地训练的大型模型，对各种提问有非常好的处理能力。非常适合个人和中小型企业，构建自己的大数据模型。</p><p>很多人都说是 ChatGPT 的平替。通过微调来满足特定小众行业的使用，将会在未来有非常大的潜力。</p><p>Mac 上由于没有 Nvidia 显卡的加持，无法配置 CUDA 进行深度学习。好在有大神制作了 C++的库，能实现小成本在低配 Mac 上跑模型的能力。</p><p><img src="https://oscimg.oschina.net/oscnet/up-64e62fce89bbcc5b1c22eb21b07b7ed543b.png" alt="file" referrerpolicy="no-referrer"></p><h3>llama.cpp</h3><p>是一个推理框架，在没有 GPU 跑 LLAMA 时，利用 Mac M1/M2 的 GPU 进行推理和量化计算。</p><p>Mac 跑 LLAMA 唯一的路。同样也可以在 Windows 下面跑起来。</p><p>它是 ggml 这个机器学习库的衍生项目，专门用于 Llama 系列模型的推理。llama.cpp 和 ggml 均为纯 C/C++实现，针对 Apple Silicon 芯片进行优化和硬件加速，支持模型的整型量化 (Integer Quantization): 4-bit, 5-bit, 8-bit 等。社区同时开发了其他语言的 bindings，例如 llama-cpp-python，由此提供其他语言下的 API 调用。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp" target="_blank">https://github.com/ggerganov/llama.cpp</a></p><h3>安装 llama.cpp</h3><p>本地快速部署体验推荐使用经过指令精调的 Alpaca-2 模型，有条件的推荐使用 6-bit 或者 8-bit 模型，效果更佳。 下面以中文 Alpaca-2-7B 模型为例介绍，运行前请确保： 1、系统应有 make（MacOS/Linux 自带）或 cmake（Windows 需自行安装）编译工具 2、建议使用 Python 3.10 以上编译和运行该工具 3、必装的 mac 依赖 xcode-select --install # Mac 的 Xcode 开发者工具，基本是必装的，很多地方都需要用到。 brew install pkgconfig cmake # c 和 c++的编译工具。</p><p>1、源码编译</p><pre><code>git clone https://github.com/ggerganov/llama.cpp
</code></pre><p>2、编译，对 llama.cpp 项目进行编译，生成./main（用于推理）和./quantize（用于量化）二进制文件。</p><pre><code>make
</code></pre><p>Windows/Linux 用户如需启用 GPU 推理，则推荐与 BLAS（或 cuBLAS 如果有 GPU）一起编译，可以提高 prompt 处理速度。以下是和 cuBLAS 一起编译的命令，适用于 NVIDIA 相关 GPU。</p><pre><code>make LLAMA_CUBLAS=1
</code></pre><p>macOS 用户无需额外操作，llama.cpp 已对 ARM NEON 做优化，并且已自动启用 BLAS。M 系列芯片推荐使用 Metal 启用 GPU 推理，显著提升速度。只需将编译命令改为：LLAMA_METAL=1 make，</p><pre><code>LLAMA_METAL=1 make
</code></pre><p>3、检查，编译成功会在目录下产生 main 等可执行的命令，下面转换量化模型文件时，会用到的命令就准备好了。</p><h3>手动转换模型文件为 GGUF 格式</h3><p>如果下载的是生成好的 gguf 模型就不需要手动转换了。为啥要这个格式。这个格式的 LLAMA.cpp 才认。其它格式的数据不认。</p><p>1、下载 Llama 2 模型，首先，从 Hugging Face <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmeta-llama" target="_blank">https://huggingface.co/meta-llama</a> 上下载你想要使用的 Llama 2 模型，比如 7B-Chat，我的 Mac 是 8G 内存，M2 芯片，估计也只能跑到这个模型，再大的机器跑不动。 值得一提的是：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmeta-llama%2FLlama-2-7b-chat" target="_blank">https://huggingface.co/meta-llama/Llama-2-7b-chat</a> 下载时，第一次需要授权，需要到 meta 官网，下面这个链接 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fllama.meta.com%2Fllama-downloads" target="_blank">https://llama.meta.com/llama-downloads</a></p><p>去提交一下邮件。这里选国家时会有意想不到的结果，自己思考一下。</p><p>如果要体验英文原版，就用上面的，会比较麻烦，但是对英文的回复比较好。 参考教程 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fymcui%2FChinese-LLaMA-Alpaca-2%2Fwiki%2Fmanual_conversion_zh" target="_blank">https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/manual_conversion_zh</a></p><p>如果要使用中文语料库，需要先合并为原始模型和中文的模型，再生成 bin，再去转换为 gguf 格式。喜欢折腾的可以试试。</p><p>如果要使用我这个中文混合模型，可以直接下载 gguf 格式。下面这几步都不用了。省事多了。</p><p>下载地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fhfl%2Fchinese-llama-2-7b-gguf%2Ftree%2Fmain" target="_blank">https://huggingface.co/hfl/chinese-llama-2-7b-gguf/tree/main</a> 记得选 ggml-model-q4_0.gguf 这个模型。</p><p>2、下载 llama.cpp 库，并按上面的流程进行编译安装成功</p><p>3、转换模型格式，然后，你需要把模型的文件转换成 GGUF 格式，使用 llama.cpp 库中的 convert.py 脚本来完成。转换时需要指定模型的路径和上下文长度（模型可以处理的最大的文本长度），不同的模型可能有不同的上下文长度。</p><p>如果模型是 LLaMA v1，则使用 --ctx 2048，如果你的模型是 LLaMA v2，则使用 --ctx 4096。这里使用 --ctx 4096。如下所示：</p><pre><code># 转换模型文件
python3 convert.py models/7B-Chat --ctx 4096
</code></pre><p>如果安装过程缺 python 包直接 pip install 安装即可。</p><p>4、量化模型文件</p><p>使用 llama.cpp 库中的 quantize 程序来进行模型量化，使用 quantize 命令：</p><pre><code># 运行 quantize 程序，指定输入和输出的模型文件和量化方式
./quantize ./models/7B/ggml-model-f16.gguf ./models/7B/ggml-model-q4_0.gguf q4_0
</code></pre><p>这样，在 7B-Chat 文件夹中就生成一个 4 位整数的 GGUF 模型文件。</p><p>5、运行模型</p><pre><code>./main -m ./models/7B/ggml-model-q4_0.bin \
        -t 8 \
        -n 128 \
        -p 'The first president of the USA was '

# run the inference 推理
./main -m ./models/llama-2-7b-hf/ggml-model-q4_0.bin -n 128
#以交互式对话
./main -m ./models/llama-2-7b-hf/ggml-model-q4_0.bin --color -f prompts/alpaca.txt -ins -c 2048 --temp 0.2 -n 256 --repeat_penalty 1.3
#chat with bob
./main -m ./models/llama-2-7b-hf/ggml-model-q4_0.bin -n 256 --repeat_penalty 1.0 --color -i -r "User:" -f prompts/chat-with-bob.txt
</code></pre><p>此步骤过于烦锁，主要是模型文件占了几十 GB。所以我直接下载别人的中文模型进行使用。不需要再手动进行转换、量化等操作。</p><h3>以 WebServer 形式启动</h3><p>调用手册：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp%2Fblob%2Fmaster%2Fexamples%2Fserver%2FREADME.md" target="_blank">https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md</a></p><p>用 WebServer 形式。可以对接到别的系统里面，像 FastGPT 或者一些界面上，就可以无缝使用了。</p><p>1、启动 server 参数请./server -h 查看，或者参考手册</p><pre><code>./server --host 0.0.0.0 -m /Users/kyle/MyCodeEnv/models/ggml-model-q4_0.gguf -c 4096 --n-gpu-layers 1
</code></pre><p>默认会开到 8080 端口上，配置可改。不加 gpu-layers 走 CPU，会报错。设个 1 就行</p><p>2、用 CURL 进行测试</p><pre><code>curl --request POST \
    --url http://127.0.0.1:8080/completion \
    --header "Content-Type: application/json" \
    --data '{"prompt": "给我讲个冷笑话:","n_predict": 128}'
</code></pre><p>3、效果如图 <img src="https://oscimg.oschina.net/oscnet/up-13aad680a24849ac3eac3a0c10ea1a23746.png" alt="file" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-2ec06696d22e9fd8b9ce8c65280167f2454.png" alt="file" referrerpolicy="no-referrer"> 感觉，就是训练的还是量少，有些问题会胡说。理解不了的问题反应会非常慢。会花很长的时间。</p><h3>Python 调用接口库</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fabetlen%2Fllama-cpp-python" target="_blank">https://github.com/abetlen/llama-cpp-python</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fllama-cpp-python.readthedocs.io%2Fen%2Flatest%2Finstall%2Fmacos%2F" target="_blank">https://llama-cpp-python.readthedocs.io/en/latest/install/macos/</a></p><p>1、Mac 用户，pip 编译，最简，安装 llama-cpp-python (with Metal support) 为了启用对于 Metal (Apple 的 GPU 加速框架) 的支持，使用以下命令安装 llama-cpp-python: CMAKE_ARGS="-DLLAMA_METAL=on" FORCE_CMAKE=1 pip install llama-cpp-python</p><p>2、代码中使用，安装好之后可以直接用 requests 调用。无需第 1 步的 llama-cpp-python 依赖包。使用通用的 ChatGPT 的问答形式回答。 也可以不经 Server 直接调用模型文件</p><pre><code># -*- coding: utf-8 -*-
import requests

url = 'http://localhost:8080/v1/chat/completions'
headers = {
    'accept': 'application/json',
    'Content-Type': 'application/json'
}
dataEn = {
    'messages': [
        {
            'content': 'You are a helpful assistant.',
            'role': 'system'
        },
        {
            'content': 'What is the capital of France?',
            'role': 'user'
        }
    ]
}
data = {
    'messages': [
        {
            'content': '你是一个乐于助人的助手',
            'role': 'system'
        },
        {
            'content': '二战是哪一年爆发的?',
            'role': 'user'
        }
    ]
}

response = requests.post(url, headers=headers, json=data)
print(response.json())
print(response.json()['choices'][0]['message']['content'])
</code></pre><p>3、直接调用模型文件，需要安装 llama-cpp-python 包</p><pre><code># -*- coding: utf-8 -*-
from llama_cpp import Llama

# 加截模型
# llm = Llama(model_path='/Users/kyle/MyCodeEnv/models/ggml-model-q4_0.gguf', chat_format="llama-2") # 可以指定聊天格式
llm = Llama(model_path='/Users/kyle/MyCodeEnv/models/ggml-model-q4_0.gguf')

# 提问
response = llm("给我讲一下英国建国多少年了", max_tokens=320, echo=True)
# response = llm.create_chat_completion(
#     messages=[
#         {"role": "system", "content": "你是一个乐于助人的助手"},
#         {
#             "role": "user",
#             "content": "给我讲一个笑话"
#         }
#     ]
# )
# print(response)

# 回答
print(response['choices'][0])
</code></pre><h3>最后贴个官方的教程</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fllama-cpp-python.readthedocs.io%2Fen%2Flatest%2Finstall%2Fmacos%2F" target="_blank">https://llama-cpp-python.readthedocs.io/en/latest/install/macos/</a></p><p>再慢慢研究研究微调和训练自己的语料吧。</p><p>跟上 LLM 的步伐。不接触 AI 就要落后了。 更多精彩内容，请关注我的公众号：青塬科技。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:09:02 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/qyhstech/blog/11046186</guid>
            <link>https://my.oschina.net/qyhstech/blog/11046186</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[德国防部密码 1234，德媒：这真的安全吗]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">近日，德国军方被曝出一段涉及「考虑协助乌克兰袭击克里米亚大桥」的录音，从而遭致其国内的严厉批评。目前德国防部已就此进行回应，但期间又发生了一个令人迷惑的安全细节，再遭当下神经已高度紧绷的德媒质疑。</span></p><p><span style="color:#000000">当地时间 3 月 3 日，德国国防部长鲍里斯·皮斯托留斯（ Boris Pistorius）就窃听丑闻一事举行新闻发布会，其讲话部分于 4 日以加密录音文档的形式被公布在德国防部网站上。德国防部提醒，游客可以通过点击该文档链接进入德国国防军的云存储服务器，并输入密码「1234」来访问一个 13MB 大小的 MP3 录音文档。</span></p><p><span style="color:#000000">3 月 3 日，德国柏林，德国国防部长皮斯托留斯就「德军方谈话遭俄罗斯窃听」一事对媒体发表讲话，指责俄方发动「信息站」。</span></p><p><span style="color:#000000"><strong>虽然该录音文档在云存储上未进行分类，密码「1234」甚至可能只是个临时占位符，但密码的简单性仍遭到德媒批评。</strong>对此，德国《图片报》就将国防部页面的提示截图贴在报道内，并反问「密码是 1234，这真的安全吗？」</span></p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-b2654287246cbfa96b4ee7b4fe41dff8488.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">《图片报》指出，目前仍不清楚俄方究竟是如何通过什么手段窃听获得了长达 38 分钟的德国高层军官通话的录音，但这些高层军官因使用「WebEx」（第三方远程会议软件）进行高度机密的通话而被窃听的事实，已经让外界严重怀疑国防部的保密程度是否出现巨大漏洞。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:00:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281890</guid>
            <link>https://www.oschina.net/news/281890</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 基金会推出「反诈」开源项目 Tazama，获盖茨基金会资助]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gatesfoundation.org%2F" target="_blank">比尔及梅琳达•盖茨基金会</a>（Bill &amp; Melinda GatesFoundation）的支持下，Linux 基金会慈善机构（LF Charities）<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-launches-tazama-for-real-time-fraud-management" target="_blank">宣布</a></u>推出<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">Tazama</a>，这是一套用于实时欺诈预防的开源软件解决方案。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-935f8d1d736dc3d5b53baa4a2e1caebd24b.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gasa.org%2Fglobal-anti-scam-summit-2023" target="_blank">全球反诈骗联盟 (Global Anti-Scam Alliance)</a>报告称，2022 年因在线欺诈损失了近万亿美元。</p><p>Tazama 标志着全球金融监管和合规方式的重大转变。迄今为止，金融业一直在使用专有的、往往成本高昂的解决方案，这些解决方案限制了许多人（尤其是发展中经济体）的使用和适应性。</p><p>Tazama 提供了一种强大、可扩展且成本效益高的开源反欺诈替代解决方案，实现了先进金融监控工具的平民化，有助于打击欺诈行为，从而挑战了这一现状。</p><p>Tazama 解决了政府、民间社会、最终用户、行业机构和金融服务业的主要问题，包括欺诈检测、反洗钱合规性和数字金融交易的成本效益监控。该解决方案的架构强调数据主权、隐私和透明度，与世界各国政府的优先事项保持一致。Tazama 由 LF 慈善基金会主办，该基金会将为项目的运行和功能提供支持，Tazama 展示了开源解决方案的可扩展性和稳健性，尤其是在国家支付交换机等关键基础设施方面。</p><p>一些组织正在探索与 Tazama 的协同作用，包括 BankservAfrica、IPSL、JoPACC 和 BCEAO。协同作用包括评估 Tazama 解决方案在实际应用场景中的有效性、可扩展性和适应性，确保其满足并超越各行业数字金融服务提供商（DFSP）的不同需求。</p><p>Tazama 欢迎各国中央银行、监管机构、移动支付提供商、系统集成商、组织和个人参与其中。欲了解更多有关 Tazama 及其使命、社区和倡议的信息，请访问 Tazama<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">网站</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffrmscoe" target="_blank">GitHub</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 10:03:40 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</guid>
            <link>https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 和 Elon Musk【译】]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>OpenAI 今天在官网<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">发布新闻稿</a></u>，回应</span><span>埃隆·马斯克</span><span>起诉一事。</span></p><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>该文章由 Sam Altman、Greg Brockman、Ilya Sutskever 等人共同署名。文章表示，OpenAI 打算</span><span>驳回</span><span>埃隆·马斯克</span><span>的所有诉讼请求，</span><span>并公布了一些高层和</span><span>埃隆·马斯克</span><span>的历史往来邮件作为证据。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-49bfb7cdaf49904c3a735c17f2ac5c4887e.png" referrerpolicy="no-referrer"></p></blockquote><p>以下为新闻稿原文翻译：</p><p>&nbsp;</p><p>OpenAI 的使命是确保 AGI 造福全人类，这意味着既要构建安全有益的 AGI，又要帮助人类创造收益。现在，我们将与大家分享我们在完成使命方面的心得，以及我们与埃隆之间关系的一些事实情况。</p><p>我们正打算驳回埃隆的所有诉讼请求。</p><h3><strong>我们意识到，构建 AGI 所需的资源远远超出我们最初的想象</strong></h3><hr><p>埃隆说，我们应该布向 OpenAI 提供 10 亿美元的初始资金承诺。实际上，这家非营利组织总共从埃隆那里筹集了不到 4500 万美元，从其他捐赠者那里筹集了 9000 多万美元。</p><p>在 2015 年底创办 OpenAI 时，格雷格和萨姆最初计划筹集 1 亿美元。但是埃隆在一封电子邮件中表示&nbsp;「我们需要一个比 1 亿美元大得多的数字，以免让人听起来觉得毫无希望……我认为我们应该从 10 亿美元的资金承诺开始.如果其他人不提供的，我会承担。「 [1]</p><p>我们花了很多时间来设想通往 AGI 的合理路径。2017 年初，我们意识到构建 AGI 需要大量的计算。我们开始计算 AGI 可能需要多少计算量。我们都明白，要想成功完成使命，我们将需要更多的资金--这将达到每年数十亿美元，远远超出了我们任何人的想象，尤其是埃隆，他认为我们作为非营利组织无法筹集到这么多资金。</p><h3><strong>我们和埃隆都认识到，要获得这些资源，就必须建立一个营利实体。</strong></h3><hr><p>在我们讨论营利性结构以推进使命时，埃隆希望我们与特斯拉合并，否则他需要获得全部的控制权。这之后埃隆离开了 OpenAI，他说需要有一个与谷歌/DeepMind 相对应的竞争对手，而他打算自己来做这件事。他同事表示，他会支持我们找到自己的道路。</p><p>2017 年底，我们和埃隆决定下一步的任务是创建一个营利实体。埃隆希望获得多数股权以及最初的董事会控制权，并担任首席执行官。在这些讨论中，他扣留了资金。Reid Hoffman 填补了资金缺口，为我们支付了工资和运营费用。</p><p>我们无法就营利性公司的条款与埃隆达成一致，因为我们认为任何个人对 OpenAI 拥有绝对控制权都有悖于公司的使命。于是，他建议将 OpenAI 并入特斯拉。2018 年 2 月初，埃隆给我们转发了一封邮件，建议 OpenAI 「依附于特斯拉，将其作为自己的资金来源「，并评论说 「完全正确……特斯拉是唯一一条甚至有望与谷歌相提并论的道路。即便如此，与谷歌抗衡的可能性也很小。但并不是零」。[2]</p><p>埃隆很快选择离开 OpenAI，他说我们的成功概率为 0，他计划在特斯拉内部建立一个 AGI 团队与我们竞争。他在 2018 年 2 月底离开时告诉我们，他支持我们自己寻找筹集数十亿美元的道路。2018 年 12 月，埃隆给我们发邮件说：「即使筹集到几亿美元也不够。这需要每年筹集数十亿美元，否则就算了。「 [3]</p><h3><strong>我们通过构建可广泛使用的有益工具来推进我们的使命</strong></h3><hr><p>我们通过开源等方式，使我们的技术能够广泛使用，从而提高人们的效率，改善他们的日常生活。</p><p>我们向大众提供了当今最强大的人工智能，包括每天有数亿人使用的免费版本。举个例子，阿尔巴尼亚正在使用 OpenAI 的工具将其加入欧盟的时间加快了 5.5 年；数字绿色公司正在帮助肯尼亚和印度提高农民收入，通过在 OpenAI 的基础上将农业推广服务的成本降低 100 倍；罗德岛州最大的医疗保健提供商 Lifespan 使用 GPT-4 将其手术同意书从大学阅读水平简化到六年级水平；而冰岛正在使用 GPT-4 保护越来越少人使用的冰岛语。</p><p>埃隆明白，这些工作并不意味着开源 AGI。正如伊利亚告诉埃隆的那样 「随着我们越来越接近 AGI，开始降低开放程度是有意义的。OpenAI 中的 「开放 「是指人工智能建成后，每个人都应从人工智能的成果中受益，但不分享科学成果也完全没问题……"，埃隆回答道： 「是的」。[4]</p><p>对于埃隆的起诉，我们倍感遗憾。我们深深钦佩的一个人走到了这一步。他曾激励我们向更高的目标迈进，然后告诉我们会失败，建立了一个竞争对手团队，而当我们开始在没有他的情况下朝着 OpenAI 的使命取得有意义的进展时，他又将我们告上法庭。</p><p>我们专注于推进自己的使命，这还有很长的路要走。我们相信随着我们的产品越来越好，他们将更好地为每个人赋权。</p><p>&nbsp;</p><p><strong>以下为往来邮件翻译：</strong></p><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173736_2J68.png" referrerpolicy="no-referrer"></p><p>[1]</p><p>发件人 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;格雷格-布罗克曼</p><p>抄送： Sam Altman</p><p>Date： Sun, Nov 22, 2015 at 7:48 PM</p><p>主题： 通话后续</p><p>博客听起来不错，但要考虑到中立性和以青委会为中心。</p><p>我更倾向于将博客定位为更吸引普通大众－－让大众支持我们取得成功有很大的价值－－然后为招聘工作准备一个更长、更详细、更有内幕的版本，并在普通大众版本的末尾提供链接。</p><p>我们需要一个比 1 亿美元大得多的数字，以避免与谷歌或 Facebook 的支出相比显得毫无希望。我认为我们应该说，我们将从 10 亿美元的资金承诺开始。这是真的。其他人不提供的，我都会提供。</p><p>模板看起来还不错，除了默认转为归属现金红利外，还可以选择将其转为 YC 或 SpaceX（需要了解具体数额）的股票。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_l1GG.png" referrerpolicy="no-referrer"></p><p>[2]</p><p>发件人 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>Date： 2018 年 2 月 1 日，星期四，凌晨 3:52</p><p>主题 Fwd： 今天的顶级人工智能机构</p><p>说得一点没错。我们或许希望如此，但在我看来，特斯拉是唯一能与谷歌抗衡的公司。即便如此，与谷歌抗衡的可能性也很小，但也不是零。</p><p>开始转发信息：</p><p>发件人： &nbsp;&nbsp;&lt;&gt;</p><p>致 &nbsp;埃隆-马斯克 &lt;&gt;</p><p>日期，太平洋标准时间 2018 年 1 月 31 日下午 11:54:30</p><p>主题 Re： 当今顶尖的人工智能机构</p><p>不幸的是，在人工智能的最前沿工作是昂贵的。除了 DeepMind，谷歌还有 Google Brain、Research 和 Cloud。还有 TensorFlow、TPU，它们拥有大约三分之一的研究成果（事实上，它们还举办自己的人工智能会议）。</p><p>我还强烈怀疑，要实现 AGI，计算能力将是必要的。如果历史趋势能够说明问题，那么人工智能的进步主要是由系统－－计算、数据、基础设施－－驱动的。我们今天使用的核心算法与上世纪 90 年代相比基本没有变化。不仅如此，任何发表在论文中的算法进展几乎都可以立即被重新实现和整合。反过来说，如果没有一定的规模，单靠算法的进步是没有生命力的。</p><p>在我看来，如今的 OpenAI 正在烧钱，其融资模式无法达到与谷歌（一家 8000 亿美元的公司）认真竞争的规模。如果你无法与谷歌认真竞争，却继续在开放环境中进行研究，那么你可能会让事情变得更糟，并 「免费 「帮助他们，因为他们很容易复制任何进步，并立即将其规模化。</p><p>以营利为目的的转型可能会随着时间的推移创造出更稳定的收入来源，而就目前的团队而言，很可能会带来大量投资。然而，从零开始打造产品会抢走人工智能研究的重点，而且需要很长时间，目前还不清楚一家公司能否 「赶上 「谷歌的规模，投资者也可能会在错误的方向上施加过多压力。我所能想到的最有希望的方案，正如我之前提到的，就是让 OpenAI 附属于特斯拉，将其作为自己的资金来源。我认为，依附于其他大型公司（如苹果、亚马逊），会因公司基因不兼容而失败。打个比方，特斯拉已经建造了火箭的 「第一级「，包括 Model 3 的整个供应链、车载电脑和持续的互联网连接。第二阶段 「将是基于大规模神经网络训练的完全自动驾驶解决方案，OpenAI 的专业技术可以大大帮助加快这一进程。在大约 2-3 年的时间里，我们就能推出功能完善的完全自动驾驶解决方案，销售大量汽车/卡车。如果我们真的做得很好，运输行业的规模足够大，我们可以将特斯拉的市值提高到 O（约 10 万美金），并利用这笔收入为适当规模的人工智能工作提供资金。</p><p>我看不到有任何其他公司有潜力在十年内达到可持续的谷歌规模资本。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_gNCb.png" referrerpolicy="no-referrer"></p><p>[3]</p><p>发件人 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>抄送： Sam Altman</p><p>Date： Wed, Dec 26, 2018 at 12:07 PM</p><p>主题： 我觉得我应该重申</p><p>在执行和资源没有发生巨大变化的情况下，我对 OpenAI 与 DeepMind/Google 相关性的概率评估是 0%。而不是 1%。我希望不是这样。</p><p>即使筹集到几亿美元也不够。这需要每年立即筹集数十亿美元，否则就算了。</p><p>不幸的是，人类的未来掌握在【未透露名称】手中。</p><p>他们所做的远不止这些。</p><p>我真希望我错了。</p><p>埃隆</p><hr><p><img src="https://oscimg.oschina.net/oscnet/up-9103940e18f26f6ed78e7c0e58a9b0be1dc.png" referrerpolicy="no-referrer"></p><p>【4】</p><p>Fwd: 恭喜猎鹰 9</p><p>包含 3 条信息</p><p>发件人 &nbsp;Elon Musk</p><p>收件人 &nbsp;Sam Altman、Ilya Sutskever、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 8:18 AM</p><p>主题，收件人： 恭喜猎鹰 9 号</p><p>开始转发消息：</p><p>From：&nbsp;未透露姓名</p><p>To： &nbsp;埃隆-马斯克</p><p>日期： 美国中部时间 2016 年 1 月 2 日上午 10:12:32</p><p>主题： 恭喜猎鹰 9 号</p><p>嗨，埃隆</p><p>祝你新年快乐，</p><p>首先祝贺猎鹰 9 号着陆，这是一项了不起的成就。现在是时候组建舰队了！</p><p>我看到你（还有萨姆和其他 OpenAI 人士）最近接受了很多采访，大肆宣扬人工智能开源的优点，但我想你应该意识到，这并不是某种能神奇地解决安全问题的灵丹妙药吧？有很多很好的论据可以说明，为什么你所采取的方法实际上是非常危险的，事实上可能会增加世界的风险。在这篇博文中，一些比较明显的观点得到了很好地阐述，我相信你已经看到了，但还有其他一些重要的考虑因素：</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fslatestarcodex.com%2F2015%2F12%2F17%2Fshould-ai-be-open%2F" target="_blank">http://slatestarcodex.com/2015/12/17/should-ai-be-open/</a></p><p>我很想听听你对这些观点的反驳。</p><p>发件人 &nbsp;Ilya Sutskever</p><p>致 &nbsp;Elon Musk 、Sam Altman、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 9:06 AM</p><p>主题 Fwd: 恭喜猎鹰 9 号</p><p>这篇文章关注的是 「硬起飞 「</p><p>如果发生 「硬起飞「，而安全的人工智能比不安全的人工智能更难构建，那么通过开放一切，我们就会让那些能够获得大量硬件的不法分子轻而易举地构建出不安全的人工智能，从而遭遇 「硬起飞」。</p><p>当我们越来越接近构建人工智能时，开始降低开放程度将变得更有意义。openAI 中的 「开放 「意味着，在人工智能建成后，每个人都应从人工智能的成果中获益，但不分享科学知识也是完全可以的（尽管在短期和中期内，为了招聘的目的，分享一切绝对是正确的策略）。</p><p>来自 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;Ilya Sutskever</p><p>日期 Sat, Jan 2, 2016 at 9:11 AM</p><p>主题 Fwd: 恭喜猎鹰 9 号</p><p>是的</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:37:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281801/openai-elon-musk</guid>
            <link>https://www.oschina.net/news/281801/openai-elon-musk</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【Java 比较 ORM 框架操作数据】操作批量新增、分页查询（七）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>orm 框架使用性能比较</h3><h4>比较 mybatis、lazy、sqltoy、mybatis-flex、easy-query、mybatis-mp、jpa、dbvisitor、beetlsql 操作数据</h4><h4>环境：</h4><pre><code>idea 
jdk17
spring boot 3.0.7
mysql 8.0
</code></pre><h3>测试条件常规对象</h3><table><tbody><tr><th>orm 框架</th><th>是否支持 xml</th><th>是否支持 Lambda</th><th>对比版本</th><th>编码方式</th></tr></tbody><tbody><tr><td>mybatis</td><td>☑️</td><td>☑️</td><td>3.5.4</td><td>lambda +xml 优化</td></tr><tr><td>sqltoy</td><td>☑️</td><td>☑️</td><td>5.2.98</td><td>lambda</td></tr><tr><td>lazy</td><td>✖️</td><td>☑️</td><td>1.2.4-JDK17-SNAPSHOT</td><td>lambda</td></tr><tr><td>mybatis-flex</td><td>☑️</td><td>☑️</td><td>1.8.0</td><td>lambda +xml 优化</td></tr><tr><td>easy-query</td><td>✖️</td><td>☑️</td><td>1.10.31</td><td>lambda</td></tr><tr><td>mybatis-mp</td><td>☑️</td><td>☑️</td><td>1.4.1</td><td>xml 优化</td></tr><tr><td>jpa</td><td>☑️</td><td>☑️</td><td>3.0.7</td><td>----------------------</td></tr><tr><td>dbvisitor</td><td>☑️</td><td>☑️</td><td>5.4.1</td><td>xml 优化</td></tr><tr><td>beetlsql</td><td>支持 md</td><td>☑️</td><td>3.26.0-RELEASE</td><td>insert ignore into 优化</td></tr></tbody></table><h3>数据库表 (含有唯一性索引 s_u)</h3><pre><code class="language-sql">CREATE TABLE `sys_user`
(
    `column_name` varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '额外字段',
    `create_time` datetime                                DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间',
    `id`          bigint NOT NULL AUTO_INCREMENT COMMENT '用户 ID',
    `is_deleted`  tinyint(1) DEFAULT NULL COMMENT 'null',
    `password`    varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '密码',
    `scope`       varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT 'null',
    `status`      tinyint(1) DEFAULT NULL COMMENT '状态',
    `update_time` datetime                                DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    `username`    varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '用户名',
    PRIMARY KEY (`id`) USING BTREE,
    UNIQUE KEY `s_u` (`scope`,`username`)
) ENGINE=InnoDB AUTO_INCREMENT=9223371632070323791 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
</code></pre><h3>比较方法:增加、修改、删除、分页查询（当前项目暂时只比较批量新增和分页）</h3><h4>项目设计</h4><ul><li><p>声明 ORMRepository 接口提供对应增删改查方法&nbsp;</p></li><li><p>声明 ORMComparisonRepository 接口，继承 ORMRepository 下游由不同 ORM 实现</p></li><li><p>声明 SysUserRepository 接口，继承 ORMRepository 用于循环调用不同 orm 实现方法执行方法测试产生测试结果</p></li><li><p>声明抽象类 SysUserRepositoryAbstractRecord 继承 ORMComparisonRepository 并且提供对应的框架执行结果存储&nbsp;</p></li><li><p>不同 ORM 框架创建 ORMComparisonRepository 的实现</p></li><li><p>不同 ORM 操作数据的实现</p></li></ul><h3>测试条件，批量插入数据 10、100、1000、10000、100000 ，分页查询数据 10、100、1000、10000、100000</h3><pre><code>项目启动后使用浏览器打开 http://localhost:1003/sys/user/run-compare
</code></pre><h3>测试条件（细节比较） 批量插入数据 1～10000，分页查询数据 1～10000</h3><pre><code>项目启动后使用浏览器打开 http://localhost:1003/sys/user/run-particulars-compare
</code></pre><h3>测试执行过程</h3><pre><code>清空需要插入表中所有数据
通过三种 ORM 框架进行数据批量新增、而后进行分页查询，记录消耗时间，输出 md 文档
</code></pre><h3><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flocalhost%3A1003%2F" target="_blank">查看结果曲线图</a></h3><p><img height="757" src="https://oscimg.oschina.net/oscnet/up-61371d910485615d211e20a380e8457b728.png" width="1401" referrerpolicy="no-referrer"></p><h3>测试结果（结果只提供参考）</h3><table><tbody><tr><th>MYBATIS_FLEX(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>25 毫秒</strong></td><td><strong>18 毫秒</strong></td><td><strong>73 毫秒</strong></td><td><strong>671 毫秒</strong></td><td><strong>6653 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>51 毫秒</strong></td><td><strong>28 毫秒</strong></td><td><strong>84 毫秒</strong></td><td><strong>601 毫秒</strong></td><td><strong>5963 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>LAZY(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>4 毫秒</strong></td><td><strong>12 毫秒</strong></td><td><strong>48 毫秒</strong></td><td><strong>353 毫秒</strong></td><td><strong>3512 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_MP(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>8 毫秒</strong></td><td><strong>16 毫秒</strong></td><td><strong>66 毫秒</strong></td><td><strong>589 毫秒</strong></td><td><strong>6060 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>DB_VISITOR(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>67 毫秒</strong></td><td><strong>155 毫秒</strong></td><td><strong>897 毫秒</strong></td><td><strong>8368 毫秒</strong></td><td><strong>82348 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>JPA(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>67 毫秒</strong></td><td><strong>64 毫秒</strong></td><td><strong>952 毫秒</strong></td><td><strong>8608 毫秒</strong></td><td><strong>95946 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>EASY_QUERY(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>58 毫秒</strong></td><td><strong>91 毫秒</strong></td><td><strong>395 毫秒</strong></td><td><strong>1608 毫秒</strong></td><td><strong>15802 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>SQLTOY(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>35 毫秒</strong></td><td><strong>36 毫秒</strong></td><td><strong>173 毫秒</strong></td><td><strong>1540 毫秒</strong></td><td><strong>15167 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>BEETL_SQL(batchStory)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>187 毫秒</strong></td><td><strong>106 毫秒</strong></td><td><strong>260 毫秒</strong></td><td><strong>1713 毫秒</strong></td><td><strong>16778 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_FLEX(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>28 毫秒</strong></td><td><strong>8 毫秒</strong></td><td><strong>19 毫秒</strong></td><td><strong>113 毫秒</strong></td><td><strong>865 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>26 毫秒</strong></td><td><strong>7 毫秒</strong></td><td><strong>20 毫秒</strong></td><td><strong>98 毫秒</strong></td><td><strong>732 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>LAZY(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>5 毫秒</strong></td><td><strong>5 毫秒</strong></td><td><strong>9 毫秒</strong></td><td><strong>71 毫秒</strong></td><td><strong>474 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_MP(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>28 毫秒</strong></td><td><strong>5 毫秒</strong></td><td><strong>16 毫秒</strong></td><td><strong>89 毫秒</strong></td><td><strong>752 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>DB_VISITOR(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>14 毫秒</strong></td><td><strong>4 毫秒</strong></td><td><strong>9 毫秒</strong></td><td><strong>50 毫秒</strong></td><td><strong>424 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>JPA(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>85 毫秒</strong></td><td><strong>11 毫秒</strong></td><td><strong>49 毫秒</strong></td><td><strong>117 毫秒</strong></td><td><strong>805 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>EASY_QUERY(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>39 毫秒</strong></td><td><strong>9 毫秒</strong></td><td><strong>22 毫秒</strong></td><td><strong>60 毫秒</strong></td><td><strong>474 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>SQLTOY(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>23 毫秒</strong></td><td><strong>4 毫秒</strong></td><td><strong>10 毫秒</strong></td><td><strong>45 毫秒</strong></td><td><strong>249 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>BEETL_SQL(findPage)</th><th>影响行数:10</th><th>影响行数:100</th><th>影响行数:1000</th><th>影响行数:10000</th><th>影响行数:100000</th></tr></tbody><tbody><tr><td>执行时间:</td><td><strong>43 毫秒</strong></td><td><strong>13 毫秒</strong></td><td><strong>21 毫秒</strong></td><td><strong>76 毫秒</strong></td><td><strong>633 毫秒</strong></td></tr></tbody></table><h4>写在最后</h4><p>细节数据对比（一万以内基本相差不大）</p><ul><li>细节数据对比，数据属于并发行测试数据，如果测试总数是一百，那么会执行一百次 batchStory，一百次 findPage 每次执行的条数在之前数据的基础上+1</li></ul><p>从形成的折线图看（具体趋势看排名与测试结果）</p><ul><li>存储性能对比: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql 更适合并发性数据存储。jpa、db_visitor 处理耗时较长</li><li>分页查询性能对比: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、db_visitor、beetlSql 都比较稳定。jpa 处理时间明显起伏</li></ul><p><img height="679" src="https://oscimg.oschina.net/oscnet/up-f09e3ee8efef84baba88890fb63e6d31a3b.png" width="1406" referrerpolicy="no-referrer"></p><p><img height="698" src="https://oscimg.oschina.net/oscnet/up-928ba767617bad09b2b47481d399c812a70.png" width="1402" referrerpolicy="no-referrer"></p><p>批量保存：</p><ul><li>一万条数据以内 lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql、jpa、db_visitor 性能趋于一致</li><li>十万数据时，处理时间由快到慢依次是: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql、db_visitor、jpa，其中 db_visitor、jpa 处理时间明显起伏</li></ul><p>分页查询：</p><ul><li>一万条数据以内，几款 ORM 均保持在 200 毫秒内</li><li>十万数据时，处理时间由快到慢依次是: sqltoy、db_visitor、easy-query、lazy、beetlSql、mybatis、mybatis-mp、jpa、mybatis-flex</li><li>&nbsp;</li></ul><h3>快速数据对比 (大数据曲线图)</h3><p><img height="674" src="https://oscimg.oschina.net/oscnet/up-6a71c9a1e912b97ed59450e7362b127b8cf.png" width="1407" referrerpolicy="no-referrer"></p><p><img height="686" src="https://oscimg.oschina.net/oscnet/up-f5898a01682ab16289012b658c8c02e3c2c.png" width="1389" referrerpolicy="no-referrer"></p><h4><a href="https://gitee.com/wujiawei1207537021/wu-compare-orm-demo">当前项目地址</a></h4><h4><a href="https://gitee.com/wujiawei1207537021/wu-framework-parent/tree/master/wu-database-parent">lazy-orm 地址</a></h4><h4><a href="https://gitee.com/baomidou/mybatis-plus">mybatis 地址</a></h4><h4><a href="https://gitee.com/sagacity/sagacity-sqltoy">sqltoy 地址</a></h4><h4><a href="https://gitee.com/mybatis-flex/mybatis-flex">mybatis-flex 地址</a></h4><h4><a href="https://gitee.com/xuejm/easy-query">easy-query 地址</a></h4><h4><a href="https://gitee.com/mybatis-mp/mybatis-mp">mybatis-mp 地址</a></h4><h4><a href="https://gitee.com/zycgit/dbvisitor">dbvisitor 地址</a></h4><h4><a href="https://gitee.com/xiandafu/beetlsql">beetlsql 地址</a></h4></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:24:40 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281792</guid>
            <link>https://www.oschina.net/news/281792</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
