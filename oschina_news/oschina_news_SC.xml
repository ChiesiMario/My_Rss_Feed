<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-最新资讯]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 30 Dec 2023 22:54:14 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[致敬过去，迎接未来：DataCap 感恩有您的 2023，翘首期盼 2024 的精进与共创]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>亲爱的 <code>DataCap</code> 软件用户，开发者：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;时光荏苒，<code>2023</code> 年即将成为过去，我们深感荣幸与感慨地站在这个时刻，对您们表达我们最深切的感谢。在过去的一年中，我们一直感受到了您们对我们软件的不离不弃和坚定支持，这是我们最宝贵的动力。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;<code>2023</code> 年是我们 <code>DataCap</code> 软件发展的关键一年。我们荣幸地宣布，预定支持的大部分功能在这一年里得以实现。然而，我们也要坦诚地承认，虽然这些功能在某些方面还存在不足和改进的空间，但正是在这个过程中，您们对我们软件的宽容与理解成为我们前行路上最强大的支持。无论是在社交媒体上的反馈，还是通过邮件和客服的沟通以及 <code>GitHub</code> 和 <code>Gitee</code> 反馈，您们的每一次建议和反馈都是我们前进的明灯，是我们改进的方向。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;在这个感恩的季节，我们要向每一位 <code>DataCap</code> 用户致以最衷心的感谢。是你们的热情使用和持续支持，让我们能够不断发展、完善软件。每一个新的用户，每一个老用户，都是我们成长历程中不可或缺的一部分。感谢您们的信任，让我们得以在软件开发的道路上越走越远。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;随着 <code>2023</code> 年即将谢幕，我们更加兴奋地展望着 <code>2024</code> 年。我们承诺，为了回馈您们的信任，我们将不遗余力地投入到软件的不断完善中。我们将不懈努力，以确保软件在稳定性、安全性和用户友好性方面取得更大的进步。我们也将持续关注用户反馈，不断优化用户体验，确保软件在您们手中能够发挥最大的价值。同时也希望您在使用软件中遇到的任何问题以及技术与我们沟通，我们将会以最大能力去解决并修复它。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;在此，我们要特别感谢那些默默为软件发展贡献的开发者们 (<strong>排名不分先后，开发者的列表为 github 中的 id</strong>，如果您有兴趣可以关注他 (她) 们)。<code>mlboy</code>、<code>why198852</code>、<code>javalover123</code>、<code>pan3793</code>、<code>GtoCm</code>、<code>Smilewh888</code>、<code>chenwenming-zj</code>、<code>Stacey1018</code>、<code>hometownglory</code>、<code>shuangzishuai</code> 等等，感谢你们的辛勤付出和无私奉献。正是有了你们的技术支持，软件才能不断创新、不断进步。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;感谢 <code>GitHub</code>，<code>Gitee</code> 对软件的托管和支持，在此向他们所有的工作人员致敬。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;感谢 <code>OpenTiny</code> 对我们的支持。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;最后，让我们向新老用户们表达最真挚的感激之情。是你们的陪伴，让我们在软件的道路上走得更加坚定。在新的一年里，我们期许能够为您们带来更多的惊喜和便捷。无论您是一位新用户，还是一位老用户，都请相信，您的支持是我们前行的最大动力。</p><p><code>2024</code> 年，愿我们继续携手，共同创造更加美好、更加智能的未来。</p><p>再次感谢您们的支持！</p><p>DataCap 软件团队 (Devlive 开源组织)</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 11:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273459/datacap-news</guid>
            <link>https://www.oschina.net/news/273459/datacap-news</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Farewell to Pika, Embracing the Arrival of PikiwiDB in 2024]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今年 (2023 年)&nbsp;3&nbsp;月份于某接手项目时，OpenAtom&nbsp;基金会&nbsp;Pika&nbsp;项目（ <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenAtomFoundation%2Fpika" target="_blank">https://github.com/OpenAtomFoundation/pika</a> ）对接人告诉我，OpenAtom&nbsp;基金会旗下的多个项目都面临了一个共同问题：项目名称被第三方注册为商标。出于合规要求，余三月份重点工作之一就是给项目重新申请一个全新的名称。</p><p>在与&nbsp;Pika&nbsp;老团队的成员进行商讨后，结合了&nbsp;「兔子哥」&nbsp;和&nbsp;「YYJ」&nbsp;的建议，我决定将其命名为&nbsp;"Pi-kiwi-DB"：</p><ol><li>"Pi"&nbsp;念派 2.&nbsp;"Pik"&nbsp;恰好保留了&nbsp;"Pika"&nbsp;的前三个字母 3.&nbsp;"kiwi"&nbsp;音同&nbsp;"KV"，寓意几维鸟</li></ol><p><img src="https://oscimg.oschina.net/oscnet/up-d73a02aed0d881c1ab72b620a395aac8a55.png" alt="" referrerpolicy="no-referrer"></p><p>Kiwi&nbsp;鸟孵化的鸟蛋占据身体容量的一半，象征着计算机大部分数据存储在磁盘上，代表着&nbsp;「极大容量」；Kiwi&nbsp;鸟羽翼退化，身体小巧，双腿强壮占体重&nbsp;1/3，跑速快如人类，象征着&nbsp;「极致性能」。所以，这一命名的选择充分考虑了项目的发展方向和原有名称的延续。</p><p>在&nbsp;2023&nbsp;年&nbsp;7&nbsp;月底，PikiwiDB（前身为&nbsp;Pika）发布了自&nbsp;2021&nbsp;年加入&nbsp;OpenAtom&nbsp;基金会以来的首个生产可用版本&nbsp;v3.5.0。该版本通过采用&nbsp;C++17&nbsp;对整个代码进行了重构，显著提升了项目的代码质量。全新的全量同步机制取代了备受诟病的&nbsp;Rsync&nbsp;方案，该方案在过去的&nbsp;8&nbsp;年里一直在使用。此外，升级了&nbsp;RocksDB&nbsp;版本、引入新的集群方案、增强了可观测性、跨平台支持&nbsp;Mac&nbsp;等方面都取得了显著的改进。</p><p>在接下来的半年中，PikiwiDB&nbsp;陆续发布了&nbsp;v3.5.1&nbsp;和&nbsp;v3.5.2&nbsp;两个版本，并计划在不久的将来发布&nbsp;v3.5.3。这些版本的更新实现了数据的冷热分离、命令的快慢分离、Redis&nbsp;事务、云原生&nbsp;K8s&nbsp;Operator&nbsp;以及&nbsp;Go&nbsp;测试集的集成。这一系列的改进将读性能提升到了微秒级别，单机读取&nbsp;QPS&nbsp;翻倍，可达&nbsp;60&nbsp;万&nbsp;/s。在稳定性和性能方面都取得了显著的提升。社区活跃度方面，贡献者数量增加了近&nbsp;3&nbsp;倍，达到&nbsp;121&nbsp;人（包括&nbsp;PikiwiDB&nbsp;和&nbsp;Pika），同时&nbsp;PR&nbsp;和&nbsp;Issue&nbsp;的总量也翻番，许多老用户纷纷回归。</p><p>到&nbsp;12&nbsp;月，OpenAtom&nbsp;基金会告知：Pika&nbsp;新名称&nbsp;PikiwiDB&nbsp;已经在政府相关部门获得批准，商标也已审批下来。这标志着整个过程的顺利完成。</p><p>回顾&nbsp;2023&nbsp;年&nbsp;12&nbsp;月份，社会第三方机构对&nbsp;PikiwiDB&nbsp;(原&nbsp;Pika)&nbsp;的评价：</p><p>这一过程展示了&nbsp;PikiwiDB&nbsp;对项目的持续改进，不仅在技术上取得了显著的进步，而且在品牌命名和合规性方面也取得了圆满成功。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dddcab84de08ed2d058294f472911e37f90.png" alt="" referrerpolicy="no-referrer"></p><ul><li>12&nbsp;月&nbsp;08&nbsp;日，Pika&nbsp;社区和&nbsp;dubbogo&nbsp;社区双双荣获&nbsp;Oschina&nbsp;「2023 年度优秀开源技术团队」</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-3d425b37dbb7dcd23e4cdf3d273695db0ad.png" alt="" referrerpolicy="no-referrer"></p><blockquote></blockquote><ul><li>12&nbsp;月&nbsp;13&nbsp;日，Pika[已更名&nbsp;PikiwiDB]&nbsp;被第三方独立机构&nbsp;艾瑞咨询研究院&nbsp;列为&nbsp;2023&nbsp;年&nbsp;&nbsp;「中国基础软件开源产业主要参与者」【DUBBO&nbsp;亦列其中】</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-846de83809b0b9fbab55bee81a04e84f452.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-89332cd585fca59db07e2cedcb162bbf7b3.png" alt="" referrerpolicy="no-referrer"></p><ul><li>12&nbsp;月&nbsp;29&nbsp;日，PikiwiDB(Pika)&nbsp;第一次以&nbsp;PikiwiDB&nbsp;的身份亮相&nbsp;Oschina&nbsp;2023&nbsp;年《中国开源开发者报告》</li></ul><p>展望&nbsp;2024&nbsp;年，PikiwiDB&nbsp;将重点发力于&nbsp;<a href="">云原生方向</a>，继续在&nbsp;「极大容量、极高性能、极致弹性」&nbsp;方向上进行探索。诚邀&nbsp;PikiwiDB（原&nbsp;Pika）社区的用户积极参与共建，共同推动&nbsp;PikiwiDB（原&nbsp;Pika）在云计算时代的发展。</p><p><img src="https://oscimg.oschina.net/oscnet/up-708fbac71201d8d036a6f6efa9fb2e1ed79.png" alt="" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 04:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/dubbogo/blog/10475258</guid>
            <link>https://my.oschina.net/dubbogo/blog/10475258</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Vue 2 生命周期即将结束]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在新的一年即将到来之际，尤雨溪于日前<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.vuejs.org%2Fposts%2Fvue-2-eol" target="_blank">发文</a>提醒 Vue 社区称，Vue 2 将于 2023 年 12 月 31 日达到生命周期结束 (EOL)；并呼吁还在使用 Vue 2 的开发团队考虑迁移至最新的&nbsp;Vue 3 版本。</p><p>Vue 2.0 于 2016 年发布，距今已有 7 年多的时间。尤雨溪表示，2.0 版本是 Vue 成为主流框架历程中的一个重要里程碑。「然而，并行地主动维护两个主要版本对我们来说是不可持续的。随着 Vue 3 及其生态系统的成熟，团队是时候继续前进并将精力集中在最新的主要版本上。」</p><p><img height="303" src="https://oscimg.oschina.net/oscnet/up-624c109953c0efc8aa6cc403c47e6b21d3b.png" width="700" referrerpolicy="no-referrer"></p><p>随着&nbsp;Vue 2.0 版本 EOL 日期的临近，他建议&nbsp;Vue 社区应该为 Vue 2 的弃用做好准备。12 月 31 日，Vue 团队将在 npm 上将以下软件包标记为已弃用：</p><ul><li>Vue 2 核心的所有主要和次要版本</li><li>专门支持 Vue 2 的 vue-router 版本（3.x 及更低版本）</li><li>专门支持 Vue 2 的 vuex&nbsp;版本（3.x 及更低版本）</li></ul><p>2023 年 12 月 31 日之后，Vue 2 将不再接收新功能、更新或修复，但仍可在所有现有分发渠道（CDN、包管理器、GitHub 等）上使用。<span style="color:#374151">换句话说，用户的应用程序可以继续工作，但会从包管理器中收到弃用警告，提醒其 Vue 2 不再是受支持的版本。</span></p><p><span style="color:#374151">Vue 3 自 2022 年 2 月 7 日以来就一直是 Vue 的默认版本。尤雨溪表示，迁移后的用户将可以享受：</span></p><p>&nbsp;</p><ul style="margin-left:0; margin-right:0"><li>更小的包尺寸和更快的渲染带来更好的性能。</li><li>增强的 TypeScript 支持，更轻松地进行大规模应用程序开发。</li><li>更高效的基于代理的反应系统。</li><li>新的内置组件，如 Fragment、Teleport 和 Suspense。</li><li>改进了构建工具支持和 Vue Devtools 体验，等等。</li></ul><p>对于暂时无法迁移或者步向前一的用户，他也提供了一些其他建议：<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:var(--tw-prose-headings)"><span><span><span><span><span><span><span><span><span><span><span><span><span><span>更新到 Vue 2 的最终版本、或购买 Vue 2 的扩展支持，以及和用户分享相关的</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;Vue 2 EOL 计划</span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:var(--tw-prose-headings)"><span><span><span><span><span><span><span><span><span><span><span><span><span><span>。于 12 月 24 日发布的&nbsp;</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff; color:#333333">2.7.16 是 Vue 2 的最终版本，包括了对 2.7 功能的一些最终修复，并改进了与 Vue 3 的类型对齐。</span></p><p><span style="background-color:#ffffff; color:#333333">「Vue 2 的结束仅标志着一个新的开始——2024 年对 Vue 来说将是激动人心的一年！」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 03:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273400/vue-2-eol</guid>
            <link>https://www.oschina.net/news/273400/vue-2-eol</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GitHub Copilot Chat 普遍可用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今年早些时候，GitHub 推出了 Copilot Chat；一个类似于 ChatGPT 的以编程为中心的聊天机器人，适用于订阅 Copilot for Business 的组织。前不久，Copilot Chat 的测试版也面向 Copilot 个人用户推出，每月收费 10 美元。</p><p>时至今日，GitHub 发文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-29-github-copilot-chat-now-generally-available-for-organizations-and-individuals%2F" target="_blank">宣布</a>，GitHub Copilot Chat 现已普遍适用于 Visual Studio Code 和 Visual Studio，经过验证的教师、学生和流行开源项目的维护人员也可以免费使用。</p><p><img alt="" height="266" src="https://oscimg.oschina.net/oscnet/up-a3b881ee5bc1674182cfdc6412c6fab4398.webp" width="500" referrerpolicy="no-referrer"></p><p>「所有 GitHub Copilot 个人用户现在都可使用 GitHub Copilot Chat 功能。企业和组织管理员可通过为其用户启用 Copilot Chat 设置，授予开发团队访问 Copilot Chat 的权限。如果你已经在测试版中使用了 Copilot Chat，或者已经为你的开发团队提供了访问权限，则无需进行其他操作。」</p><p>GitHub Copilot Chat 由 GPT-4 提供支持，并专门针对开发场景进行了微调。开发人员可以用自然语言提示 Copilot Chat，以获得实时指导，例如要求 Copilot Chat 解释概念、检测漏洞或编写单元测试。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 03:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273397/github-copilot-chat-now-generally-available</guid>
            <link>https://www.oschina.net/news/273397/github-copilot-chat-now-generally-available</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Infinigen —— 无限高质量 3D 数据生成器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Infinigen 是无限高质量 3D 数据生成器，使用程序生成的无限逼真世界。这些数据 100% 通过程序化生成，不需要外部资产，也不依赖 AI，并且是免费开源的，生成质量非常高，据称可以达到以假乱真的地步，甚至是花瓣上的皱纹都可定制。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-89f0a56c9b3a6cc8ff8cedb7501aecff0e0.png" referrerpolicy="no-referrer"></p><p>Infinigen 由普林斯顿视觉和学习实验室开发：</p><ul><li>基于 Blender 编写</li><li>每个小细节都是随机的和可定制的，甚至是花瓣上的皱纹</li><li>自然界中多样的物体和场景：植物、动物、地形；火、云、雨和雪</li><li>Groundtruth 自动标注：光流、3D 场景流、深度、表面法线、全景分割、遮挡边界</li></ul><p>其主要特性和功能包括：</p><p>1. 程序化：Infinigen 是一个程序生成器，它完全使用随机的数学规则来创建所有的形状和材料，从宏观结构到微观细节。Infinigen 可以创建无限的变化。用户可以通过覆盖随机化的默认参数来完全控制资产的生成。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f9d8159ed3837b185ace5578b1e2d6b0973.png" referrerpolicy="no-referrer"></p><p>2. 多样化：Infinigen 为自然世界中的多样化对象和场景提供生成器，包括植物、动物、地形，以及火、云、雨、雪等自然现象。当前对自然的关注是由于观察到哺乳动物的视觉在自然世界中进化。然而，预计 Infinigen 将随着时间的推移扩展到覆盖建筑环境和人造物体。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e4874348efa3dd1ae71f5d170027ed35b43.png" referrerpolicy="no-referrer"></p><p>3. 真实的几何形状：Infinigen 针对计算机视觉研究进行了优化，特别是 3D 视觉。Infinigen 不使用 bump/normal-maps、全透明度或其他伪造几何细节的技术。Infinigen 的所有细微的几何细节都是真实的，确保了精确的 3D 地面真实性。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2579dc0164572ce5aa1add312a321e16803.png" referrerpolicy="no-referrer"></p><p>4. 自动注释：Infinigen 可以自动生成各种计算机视觉任务的高质量注释，包括光流、3D 场景流、深度、表面法线、全景分割、遮挡边界。因为用户可以完全访问渲染过程，所以注释很容易定制。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cbb0ac43739fd281ebc6ccdd23cead6aff3.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/infinigen</guid>
            <link>https://www.oschina.net/p/infinigen</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 嵌入式软件平台框架 VSF]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-vsf----versaloon-software-framework" class="anchor" href="https://gitee.com/vsfteam/vsf#vsf----versaloon-software-framework"></a>VSF -- Versaloon Software Framework</h1><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Fblob%2Fmaster%2FLICENSE"><img src="https://img.shields.io/github/license/vsfteam/vsf.svg" alt="GitHub" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fwindows-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/windows-build.yml/badge.svg" alt="windows-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fcmake-native-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/cmake-native-build.yml/badge.svg" alt="cmake-native-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fcmake-arm-cross-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/cmake-arm-cross-build.yml/badge.svg" alt="cmake-arm-cross-build" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fwindows-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/windows-build.yml/badge.svg?branch=vsf-sync" alt="vsf.linux windows build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fcmake-arm-cross-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/cmake-arm-cross-build.yml/badge.svg?branch=vsf-sync" alt="cmake-arm-cross-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fcmake-native-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/cmake-native-build.yml/badge.svg?branch=vsf-sync" alt="cmake-native-build" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/vsfteam/vsf/blob/master/README.md">English</a> |</p><p>VSF 全称是 Versaloon Software Framework，是一个基于 Apache2.0 协议的开源嵌入式软件平台框架。包含了从底层硬件的 hal 驱动、抢占式多任务内核、各种服务和组件。全部代码使用 C 语言，以及面向对象的方式实现。</p><h2><a id="user-content-整体框架" class="anchor" href="https://gitee.com/vsfteam/vsf#%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6"></a>整体框架</h2><h2><a id="user-content-目录" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%9B%AE%E5%BD%95"></a>目录</h2><table><thead><tr><th>目录名</th><th>描述</th></tr></thead><tbody><tr><td>document</td><td>文档</td></tr><tr><td>doxygen</td><td>doxygen 配置</td></tr><tr><td>example</td><td>示例代码</td></tr><tr><td>hardware</td><td>VSF 开发板硬件资料</td></tr><tr><td>patch</td><td>一些补丁（第三方库补丁等等）</td></tr><tr><td>script</td><td>一些工具脚本</td></tr><tr><td> cmake</td><td>cmake 工具脚本</td></tr><tr><td>source</td><td>VSF 源代码</td></tr><tr><td> component</td><td>组件（文件系统、协议栈、UI、外部芯片驱动）</td></tr><tr><td> hal</td><td>硬件抽象层（芯片 arch 支持、芯片驱动）</td></tr><tr><td> kernel</td><td>内核</td></tr><tr><td> osa_service</td><td>依赖内核的软件服务组件</td></tr><tr><td> service</td><td>软件服务组件</td></tr><tr><td> shell</td><td>「皮肤」</td></tr><tr><td> utilities</td><td>基础软件工具（一些预处理功能、编译器支持、列表等等）</td></tr></tbody></table><h2><a id="user-content-内核" class="anchor" href="https://gitee.com/vsfteam/vsf#%E5%86%85%E6%A0%B8"></a>内核</h2><p>基于事件驱动的抢占式多任务内核，支持 51、8bit MCU、32/64 bit arm、riscv、x86 等等各种构架的芯片。</p><ul><li>事件驱动，有事件运行，没事件休眠</li><li>抢占模式下，任务切换由硬件实现，任务优先级就是硬件 swi（software interrupt）的优先级</li><li>不同优先级抢占，同一优先级协作</li><li>可以运行在其他系统或者 RTOS 中，也可以运行在一个或者几个 SWI 中断中（和其他 RTOS 并存）。</li><li>多种任务形式
<ul><li>事件处理任务 -- 最小资源占用，最简配置下占用 20 字节 ram，常用配置下占用 40 字节 ram</li><li>pt 任务 -- 接近独立堆栈任务开发方式的共享堆栈任务</li><li>独立堆栈任务 -- 依赖 libc 中的 setjmp 库</li><li>fsm 状态机任务</li><li>「皮肤」中的其他任务封装形式，比如 pthread</li></ul></li><li>信号量、互斥量、触发器、队列等等常用 IPC 工具</li></ul><h2><a id="user-content-组件" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%BB%84%E4%BB%B6"></a>组件</h2><ul><li>合理的框架设计，软件高度可以复用</li><li>尽可能提供申明式的开发方式</li><li>标准化接口，第三方软件一次性移植，全平台适配</li><li>软件组件/框架
<ul><li>distbus -- 分布式总线框架</li><li>fifo</li><li>heap</li><li>json</li><li>pool -- 内存池</li><li>stream -- 流接口</li><li>trace</li></ul></li><li>组件
<ul><li>fs -- 文件系统，支持 VFS（可使用第三方的文件系统）</li><li>input -- 输入系统</li><li>mal -- 块设备</li><li>scsi -- SCSI 设备</li><li>tcpip -- TCPIP 协议栈以及 netdrv 网络设备（可使用第三方的 TCPIP 协议栈）</li><li>ui -- UI 以及显示设备（可使用第三方的 GUI）</li><li>usb -- USB 主从机协议栈</li><li>bt -- 蓝牙协议栈（使用第三方的 btstack）</li></ul></li></ul><h2><a id="user-content-硬件抽象层" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82"></a>硬件抽象层</h2><ul><li>标准 hal 接口，统一 API -- 比如：vsf_spi_init 可以用于所有 VSF 中支持的 SPI，包括芯片自带 SPI、GPIO 模拟的 SPI、通过 USB 外扩的 SPI，通过分布式总线访问的远端 SPI</li><li>简化开发的 IP 核驱动 -- 移植仅需要实现时钟、复位、中断等等 IP 核心之外的功能</li><li>各种接口封装模板</li><li>接口
<ul><li>PM</li><li>GPIO</li><li>SPI</li><li>I2C</li><li>PWM</li><li>ADC</li><li>SWI</li><li>USART</li><li>FLASH</li><li>USB</li><li>ethernet</li></ul></li></ul><h2><a id="user-content-皮肤" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%9A%AE%E8%82%A4"></a>「皮肤」</h2><p>「皮肤」可以把 VSF「伪装」成其他系统，使得可以直接使用基于其他系统的应用代码。</p><ul><li>SDL -- 可以直接使用一些基于 SDL 的应用层代码</li><li>linux -- 可以直接使用一些基于 linux 的应用层代码
<ul><li>posix</li><li>devfs</li><li>socket</li><li>console</li><li>一些 lib 库的实现
<ul><li>libusb</li><li>libgen</li></ul></li></ul></li></ul><h2><a id="user-content-第三方" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%AC%AC%E4%B8%89%E6%96%B9"></a>第三方</h2><table><thead><tr><th>名字</th><th>路径</th><th>许可</th><th>链接</th></tr></thead><tbody><tr><td>btstack</td><td>source/component/3rd-party/btstack/raw</td><td>Other</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fbluekitchen%2Fbtstack">https://github.com/bluekitchen/btstack</a></td></tr><tr><td>coremark</td><td>source/component/3rd-party/coremark/raw</td><td>Apache</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Feembc%2Fcoremark">https://github.com/eembc/coremark</a></td></tr><tr><td>freetype</td><td>source/component/3rd-party/freetype/raw</td><td>FreeType</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Ffreetype.org%2F">https://freetype.org/</a></td></tr><tr><td>zlib</td><td>source/component/3rd-party/zlib/raw</td><td>zlib</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fzlib.net%2F">http://zlib.net/</a></td></tr><tr><td>nuklear</td><td>source/component/3rd-party/nuklear/raw</td><td>MTI</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FImmediate-Mode-UI%2FNuklear">https://github.com/Immediate-Mode-UI/Nuklear</a></td></tr><tr><td>nnom</td><td>source/component/3rd-party/nnom/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmajianjia%2Fnnom">https://github.com/majianjia/nnom</a></td></tr><tr><td>lua</td><td>source/component/3rd-party/lua/raw</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.lua.org%2F">https://www.lua.org/</a></td></tr><tr><td>lwip</td><td>source/component/3rd-party/lwip/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fsavannah.nongnu.org%2Fprojects%2Flwip%2F">https://savannah.nongnu.org/projects/lwip/</a></td></tr><tr><td>libpng</td><td>source/component/3rd-party/libpng/raw</td><td>PNG2</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flibpng.sf.net">https://libpng.sf.net</a></td></tr><tr><td>libjpeg-turbo</td><td>source/component/3rd-party/libjpeg-turbo/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flibjpeg-turbo.org%2F">https://libjpeg-turbo.org/</a></td></tr><tr><td>SDL_ttf</td><td>source/shell/media/sdl2/3rd-party/SDL_ttf</td><td>zlib</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fhg.libsdl.org%2FSDL_ttf%2F">https://hg.libsdl.org/SDL_ttf/</a></td></tr><tr><td>SDL_image</td><td>source/shell/media/sdl2/3rd-party/SDL_image</td><td>zlib</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fhg.libsdl.org%2FSDL_image%2F">https://hg.libsdl.org/SDL_image/</a></td></tr><tr><td>lvgl</td><td>source/component/3rd-party/lvgl/raw/lvgl</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flvgl.io%2F">https://lvgl.io/</a></td></tr><tr><td>lv_lib_freetype</td><td>source/component/3rd-party/lvgl/extension/lv_lib_freetype/raw</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flvgl.io%2F">https://lvgl.io/</a></td></tr><tr><td>CMSIS</td><td>source/utilities/compiler/arm/3rd-party/CMSIS</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FARM-software%2FCMSIS_5">https://github.com/ARM-software/CMSIS_5</a></td></tr><tr><td>evm</td><td>source/component/3rd-party/evm/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fscriptiot%2Fevm">https://github.com/scriptiot/evm</a></td></tr><tr><td>LingLongGUI</td><td>source/component/3rd-party/LingLongGUI/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/gzbkey/LingLongGUI">https://gitee.com/gzbkey/LingLongGUI</a></td></tr><tr><td>PLOOC</td><td>source/utilities/3rd-party/PLOOC/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FGorgonMeducer%2FPLOOC">https://github.com/GorgonMeducer/PLOOC</a></td></tr><tr><td>mbedtls</td><td>source/component/3rd-party/mbedtls/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Ftls.mbed.org%2F">https://tls.mbed.org/</a></td></tr><tr><td>GuiLite</td><td>source/component/3rd-party/GuiLite/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fidea4good%2FGuiLite">https://github.com/idea4good/GuiLite</a></td></tr><tr><td>Segger_RTT</td><td>source/component/3rd-party/segger/raw/RTT</td><td>segger</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwiki.segger.com%2FRTT">https://wiki.segger.com/RTT</a></td></tr><tr><td>Segger_SystemView</td><td>source/component/3rd-party/segger/raw/SystemView</td><td>segger</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwiki.segger.com%2FSystemView">https://wiki.segger.com/SystemView</a></td></tr><tr><td>nuconsole</td><td>source/component/3rd-party/nuconsole/raw</td><td>nuvoton</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.nuvoton.com.cn%2F">https://www.nuvoton.com.cn/</a></td></tr><tr><td>AIC8800M_SDK</td><td>source/hal/driver/AIC/AIC8800/vendor</td><td>aic</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.aicsemi.com%2F">http://www.aicsemi.com/</a></td></tr><tr><td>awtk</td><td></td><td>LGPL 2.1</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zlg.cn%2Findex%2Fpub%2Fawtk.html">https://www.zlg.cn/index/pub/awtk.html</a></td></tr><tr><td>littlefs</td><td>source/component/3rd-party/littlefs/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flittlefs-project%2Flittlefs">https://github.com/littlefs-project/littlefs</a></td></tr><tr><td>getopt_long</td><td>source/shell/sys/linux/lib/3rd-party/getopt</td><td>OpenBSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fopenbsd%2Fsrc">https://github.com/openbsd/src</a></td></tr><tr><td>regex</td><td>source/shell/sys/linux/lib/3rd-party/regex</td><td>OpenBSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fopenbsd%2Fsrc">https://github.com/openbsd/src</a></td></tr><tr><td>fnmatch</td><td>source/shell/sys/linux/lib/3rd-party/fnmatch</td><td>BSD</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.jbox.dk%2Fsanos%2Fsource%2Flib%2Ffnmatch.c.html">http://www.jbox.dk/sanos/source/lib/fnmatch.c.html</a></td></tr><tr><td>glob</td><td>source/shell/sys/linux/lib/3rd-party/glob</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fcloudius-systems%2Fmusl">https://github.com/cloudius-systems/musl</a></td></tr><tr><td>setjmp</td><td>source/hal/arch/x86/win</td><td>BSD</td><td></td></tr><tr><td>libtuv</td><td>source/shell/sys/linux/lib/3rd-party/libtuv/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FSamsung%2Flibtuv">https://github.com/Samsung/libtuv</a></td></tr></tbody></table><h2><a id="user-content-文档" class="anchor" href="https://gitee.com/vsfteam/vsf#%E6%96%87%E6%A1%A3"></a><a href="https://gitee.com/vsfteam/vsf/blob/master/document/README_zh.md">文档</a></h2>]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/vsfteam/vsf</guid>
            <link>https://gitee.com/vsfteam/vsf</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 混合专家模型 (MoE) 详解]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 编辑器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">随着 Mixtral 8x7B (announcement, model card) 的推出，一种称为混合专家模型 (Mixed Expert Models，简称 MoEs) 的 Transformer 模型在开源人工智能社区引起了广泛关注。在本篇博文中，我们将深入探讨 MoEs 的核心组件、训练方法，以及在推理过程中需要考量的各种因素。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">让我们开始吧！</p><span id="OSC_h2_1"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">简短总结</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合专家模型 (MoEs):</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      与稠密模型相比， 
     <strong style="color: black;">预训练速度更快</strong></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      与具有相同参数数量的模型相比，具有更快的 
     <strong style="color: black;">推理速度</strong></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      需要 
     <strong style="color: black;">大量显存</strong>，因为所有专家系统都需要加载到内存中 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      在 
     <strong style="color: black;">微调方面存在诸多挑战</strong>，但，近期的研究，表明，对混合专家模型进行 
     <strong style="color: black;">指令调优具有很大的潜力</strong>。 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">让我们开始吧！</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">什么是混合专家模型？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">模型规模是提升模型性能的关键因素之一。在有限的计算资源预算下，用更少的训练步数训练一个更大的模型，往往比用更多的步数训练一个较小的模型效果更佳。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合专家模型 (MoE) 的一个显著优势是它们能够在远少于稠密模型所需的计算资源下进行有效的预训练。这意味着在相同的计算预算条件下，您可以显著扩大模型或数据集的规模。特别是在预训练阶段，与稠密模型相比，混合专家模型通常能够更快地达到相同的质量水平。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">那么，究竟什么是一个混合专家模型 (MoE) 呢？作为一种基于 Transformer 架构的模型，混合专家模型主要由两个关键部分组成:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">稀疏 MoE 层</strong>: 这些层代替了传统 Transformer 模型中的前馈网络 (FFN) 层。MoE 层包含若干「专家」(例如 8 个)，每个专家本身是一个独立的神经网络。在实际应用中，这些专家通常是前馈网络 (FFN)，但它们也可以是更复杂的网络结构，甚至可以是 MoE 层本身，从而形成层级式的 MoE 结构。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">门控网络或路由</strong>: 这个部分用于决定哪些令牌 (token) 被发送到哪个专家。例如，在下图中，「More」这个令牌可能被发送到第二个专家，而「Parameters」这个令牌被发送到第一个专家。有时，一个令牌甚至可以被发送到多个专家。令牌的路由方式是 MoE 使用中的一个关键点，因为路由器由学习的参数组成，并且与网络的其他部分一同进行预训练。 
    </section></li></ul><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006177" data-ratio="0.7703703703703704" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8f46f9ec-4ee7-42d6-8b1d-68962ccb7e8b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformers paper 论文中的 MoE layer 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">总结来说，在混合专家模型 (MoE) 中，我们将传统 Transformer 模型中的每个前馈网络 (FFN) 层替换为 MoE 层，其中 MoE 层由两个核心部分组成: 一个门控网络和若干数量的专家。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">尽管混合专家模型 (MoE) 提供了若干显著优势，例如更高效的预训练和与稠密模型相比更快的推理速度，但它们也伴随着一些挑战:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">训练挑战</strong>: 虽然 MoE 能够实现更高效的计算预训练，但它们在微调阶段往往面临泛化能力不足的问题，长期以来易于引发过拟合现象。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">推理挑战</strong>: MoE 模型虽然可能拥有大量参数，但在推理过程中只使用其中的一部分，这使得它们的推理速度快于具有相同数量参数的稠密模型。然而，这种模型需要将所有参数加载到内存中，因此对内存的需求非常高。以 Mixtral 8x7B 这样的 MoE 为例，需要足够的 VRAM 来容纳一个 47B 参数的稠密模型。之所以是 47B 而不是 8 x 7B = 56B，是因为在 MoE 模型中，只有 FFN 层被视为独立的专家，而模型的其他参数是共享的。此外，假设每个令牌只使用两个专家，那么推理速度 (以 FLOPs 计算) 类似于使用 12B 模型 (而不是 14B 模型)，因为虽然它进行了 2x7B 的矩阵乘法计算，但某些层是共享的。 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">了解了 MoE 的基本概念后，让我们进一步探索推动这类模型发展的研究。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">混合专家模型简史</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合专家模型 (MoE) 的理念起源于 1991 年的论文 Adaptive Mixture of Local Experts。这个概念与集成学习方法相似，旨在为由多个单独网络组成的系统建立一个监管机制。在这种系统中，每个网络 (被称为「专家」) 处理训练样本的不同子集，专注于输入空间的特定区域。那么，如何选择哪个专家来处理特定的输入呢？这就是门控网络发挥作用的地方，它决定了分配给每个专家的权重。在训练过程中，这些专家和门控网络都同时接受训练，以优化它们的性能和决策能力。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 2010 至 2015 年间，两个独立的研究领域为混合专家模型 (MoE) 的后续发展做出了显著贡献:</p><ol data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">组件专家</strong>: 在传统的 MoE 设置中，整个系统由一个门控网络和多个专家组成。在支持向量机 (SVMs) 、高斯过程和其他方法的研究中，MoE 通常被视为整个模型的一部分。然而，Eigen、Ranzato 和 Ilya 的研究，探索了将 MoE 作为更深层网络的一个组件。这种方法允许将 MoE 嵌入到多层网络中的某一层，使得模型既大又高效。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">条件计算</strong>: 传统的神经网络通过每一层处理所有输入数据。在这一时期，Yoshua Bengio 等研究人员开始探索基于输入令牌动态激活或停用网络组件的方法。 
    </section></li></ol><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这些研究的融合促进了在自然语言处理 (NLP) 领域对混合专家模型的探索。特别是在 2017 年，Shazeer 等人 (团队包括 Geoffrey Hinton 和 Jeff Dean，后者有时被戏称为 「谷歌的 Chuck Norris」) 将这一概念应用于 137B 的 LSTM (当时被广泛应用于 NLP 的架构，由 Schmidhuber 提出)。通过引入稀疏性，这项工作在保持极高规模的同时实现了快速的推理速度。这项工作主要集中在翻译领域，但面临着如高通信成本和训练不稳定性等多种挑战。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006175" data-ratio="0.48240635641316687" data-type="png" data-w="881" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/48db56ce-0292-4d84-a174-c5c7a03d5e8b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Outrageously Large Neural Network 论文中的 MoE layer 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合专家模型 (MoE) 的引入使得训练具有数千亿甚至万亿参数的模型成为可能，如开源的 1.6 万亿参数的 Switch Transformers 等。这种技术不仅在自然语言处理 (NLP) 领域得到了广泛应用，也开始在计算机视觉领域进行探索。然而，本篇博客文章将主要聚焦于自然语言处理领域的应用和探讨。</p><span id="OSC_h2_4"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">什么是稀疏性?</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稀疏性的概念采用了条件计算的思想。在传统的稠密模型中，所有的参数都会对所有输入数据进行处理。相比之下，稀疏性允许我们仅针对整个系统的某些特定部分执行计算。这意味着并非所有参数都会在处理每个输入时被激活或使用，而是根据输入的特定特征或需求，只有部分参数集合被调用和运行。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">让我们深入分析 Shazeer 对混合专家模型 (MoE) 在翻译应用中的贡献。条件计算的概念 (即仅在每个样本的基础上激活网络的不同部分) 使得在不增加额外计算负担的情况下扩展模型规模成为可能。这一策略在每个 MoE 层中实现了数以千计甚至更多的专家的有效利用。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这种稀疏性设置确实带来了一些挑战。例如，在混合专家模型 (MoE) 中，尽管较大的批量大小通常有利于提高性能，但当数据通过激活的专家时，实际的批量大小可能会减少。比如，假设我们的输入批量包含 10 个令牌， <strong style="color: black;">可能会有五个令牌被路由到同一个专家，而剩下的五个令牌分别被路由到不同的专家。这导致了批量大小的不均匀分配和资源利用效率不高的问题</strong>。在接下来的部分中，将会讨论让 MoE 高效运行的其他挑战以及相应的解决方案。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">那我们应该如何解决这个问题呢？一个可学习的门控网络 (G) 决定将输入的哪一部分发送给哪些专家 (E):</p><span style="cursor:pointer;" data-tool="mdnice 编辑器"><section role="presentation" data-formula="y = \sum_{i=1}^{n} G(x)_i E_i(x)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -1562.5 8246.1 2808.5" aria-hidden="true" style="-webkit-overflow-scrolling: touch;vertical-align: -2.819ex;width: 18.656ex;height: 6.354ex;max-width: 300% !important;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(1823.6, 0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2, -1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(509.9, 1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mi" transform="translate(3434.2, 0)"><path data-c="47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mo" transform="translate(4220.2, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4609.2, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="msub" transform="translate(5181.2, 0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(389, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(5864.2, 0)"><g data-mml-node="mi"><path data-c="45" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(738, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(6896.1, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7285.1, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7857.1, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></section></span><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在这种设置下，虽然所有专家都会对所有输入进行运算，但通过门控网络的输出进行加权乘法操作。但是，如果 G (门控网络的输出) 为 0 会发生什么呢？如果是这种情况，就没有必要计算相应的专家操作，因此我们可以节省计算资源。那么一个典型的门控函数是什么呢？一个典型的门控函数通常是一个带有 softmax 函数的简单的网络。这个网络将学习将输入发送给哪个专家。</p><span style="cursor:pointer;" data-tool="mdnice 编辑器"><section role="presentation" data-formula="G_\sigma(x) = \text{Softmax}(x \cdot W_g)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.667ex;width: 24.749ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/addcdb77-1331-4c14-845f-06df5414abd2.svg" data-type="svg+xml" data-imgfileid="100006169"></section></span><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Shazeer 等人的工作还探索了其他的门控机制，其中包括带噪声的 TopK 门控 (Noisy Top-K Gating)。这种门控方法引入了一些可调整的噪声，然后保留前 k 个值。具体来说:</p><ol data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      添加一些噪声 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 编辑器"><section role="presentation" data-formula="H(x)_i = (x \cdot W_{\text{g}})_i + \text{StandardNormal()} \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.669ex;width: 60.565ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/26f83d98-1595-404e-9d4a-58c616d102c1.svg" data-type="svg+xml" data-imgfileid="100006173"></section></span><ol start="2" data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      选择保留前 K 个值 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 编辑器"><section role="presentation" data-formula="\text{KeepTopK}(v, k)_i = \begin{cases}
v_i &amp; \text{if } v_i \text{ is in the top } k \text{ elements of } v, \\
-\infty &amp; \text{otherwise.}
\end{cases}
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -2.148ex;width: 58.794ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/4505b4a9-5c66-45c5-9f72-1b2377d74dca.svg" data-type="svg+xml" data-imgfileid="100006171"></section></span><ol start="3" data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      应用 Softmax 函数 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 编辑器"><section role="presentation" data-formula="G(x) = \text{Softmax}(\text{KeepTopK}(H(x), k))
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.566ex;width: 37.6ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/70f4a245-7a7f-483c-b524-8795deb3ae04.svg" data-type="svg+xml" data-imgfileid="100006170"></section></span><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这种稀疏性引入了一些有趣的特性。通过使用较低的 k 值 (例如 1 或 2)，我们可以比激活多个专家时更快地进行训练和推理。为什么不仅选择最顶尖的专家呢？最初的假设是，需要将输入路由到不止一个专家，以便门控学会如何进行有效的路由选择，因此至少需要选择两个专家。Switch Transformers 就这点进行了更多的研究。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我们为什么要添加噪声呢？这是为了专家间的负载均衡！</p><span id="OSC_h2_5"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">混合专家模型中令牌的负载均衡</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">正如之前讨论的，如果所有的令牌都被发送到只有少数几个受欢迎的专家，那么训练效率将会降低。在通常的混合专家模型 (MoE) 训练中，门控网络往往倾向于主要激活相同的几个专家。这种情况可能会自我加强，因为受欢迎的专家训练得更快，因此它们更容易被选择。为了缓解这个问题，引入了一个 <strong style="color: black;">辅助损失</strong>，旨在鼓励给予所有专家相同的重要性。这个损失确保所有专家接收到大致相等数量的训练样本，从而平衡了专家之间的选择。接下来的部分还将探讨专家容量的概念，它引入了一个关于专家可以处理多少令牌的阈值。在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 库中，可以通过 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">aux_loss</code> 参数来控制辅助损失。</p><span id="OSC_h2_6"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">MoEs and Transformers</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Transformer 类模型明确表明，增加参数数量可以提高性能，因此谷歌使用 GShard 尝试将 Transformer 模型的参数量扩展到超过 6000 亿并不令人惊讶。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">GShard 将在编码器和解码器中的每个前馈网络 (FFN) 层中的替换为使用 Top-2 门控的混合专家模型 (MoE) 层。下图展示了编码器部分的结构。这种架构对于大规模计算非常有效: 当扩展到多个设备时，MoE 层在不同设备间共享，而其他所有层则在每个设备上覆制。我们将在 「让 MoE 起飞」部分对这一点进行更详细的讨论。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006178" data-ratio="0.6046296296296296" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8246ce4e-437b-4539-bf15-17cea720b24b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     GShard 论文中的 MoE Transformer Encoder 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">为了保持负载平衡和训练效率，GShard 的作者除了引入了上一节中讨论的类似辅助损失外，还引入了一些关键变化:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">随机路由</strong>: 在 Top-2 设置中，我们始终选择排名最高的专家，但第二个专家是根据其权重比例随机选择的。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">专家容量</strong>: 我们可以设定一个阈值，定义一个专家能处理多少令牌。如果两个专家的容量都达到上限，令牌就会溢出，并通过残差连接传递到下一层，或在某些情况下被完全丢弃。专家容量是 MoE 中最重要的概念之一。为什么需要专家容量呢？因为所有张量的形状在编译时是静态确定的，我们无法提前知道多少令牌会分配给每个专家，因此需要一个固定的容量因子。 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">GShard 的工作对适用于 MoE 的并行计算模式也做出了重要贡献，但这些内容的讨论超出了这篇博客的范围。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意</strong>: 在推理过程中，只有部分专家被激活。同时，有些计算过程是共享的，例如自注意力 (self-attention) 机制，它适用于所有令牌。这就解释了为什么我们可以使用相当于 12B 稠密模型的计算资源来运行一个包含 8 个专家的 47B 模型。如果我们采用 Top-2 门控，模型会使用高达 14B 的参数。但是，由于自注意力操作 (专家间共享) 的存在，实际上模型运行时使用的参数数量是 12B。</p><span id="OSC_h2_7"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">Switch Transformers</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">尽管混合专家模型 (MoE) 显示出了很大的潜力，但它们在训练和微调过程中存在稳定性问题。Switch Transformers 是一项非常激动人心的工作，它深入研究了这些话题。作者甚至在 Hugging Face 上发布了一个 1.6 万亿参数的 MoE，拥有 2048 个专家，你可以使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 库来运行它。Switch Transformers 实现了与 T5-XXL 相比 4 倍的预训练速度提升。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006176" data-ratio="0.5101851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/56bee9cf-5842-4bfd-b5a5-cdc79c60b93d.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformer 论文中的 Switch Transformer Layer 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">就像在 GShard 中一样，作者用混合专家模型 (MoE) 层替换了前馈网络 (FFN) 层。Switch Transformers 提出了一个 Switch Transformer 层，它接收两个输入 (两个不同的令牌) 并拥有四个专家。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">与最初使用至少两个专家的想法相反，Switch Transformers 采用了简化的单专家策略。这种方法的效果包括:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      减少门控网络 (路由) 计算负担 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      每个专家的批量大小至少可以减半 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      降低通信成本 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      保持模型质量 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 也对 <strong style="color: black;">专家容量</strong> 这个概念进行了研究。</p><span style="cursor:pointer;" data-tool="mdnice 编辑器"><section role="presentation" data-formula="\text{Expert Capacity} = \left(\frac{\text{tokens per batch}}{\text{number of experts}}\right) \times \text{capacity factor}
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -2.148ex;width: 58.45ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/52d4608e-4c61-4d62-b055-dc8f790f459a.svg" data-type="svg+xml" data-imgfileid="100006172"></section></span><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">上述建议的容量是将批次中的令牌数量均匀分配到各个专家。如果我们使用大于 1 的容量因子，我们为令牌分配不完全平衡时提供了一个缓冲。增加容量因子会导致更高的设备间通信成本，因此这是一个需要考虑的权衡。特别值得注意的是，Switch Transformers 在低容量因子 (例如 1 至 1.25) 下表现出色。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformer 的作者还重新审视并简化了前面章节中提到的负载均衡损失。在训练期间，对于每个 Switch 层的辅助损失被添加到总模型损失中。这种损失鼓励均匀路由，并可以使用超参数进行加权。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">作者还尝试了混合精度的方法，例如用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bfloat16</code> 精度训练专家，同时对其余计算使用全精度进行。较低的精度可以减少处理器间的通信成本、计算成本以及存储张量的内存。然而，在最初的实验中，当专家和门控网络都使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bfloat16</code> 精度训练时，出现了不稳定的训练现象。这种不稳定性特别是由路由计算引起的，因为路由涉及指数函数等操作，这些操作对精度要求较高。因此，为了保持计算的稳定性和精确性，保持更高的精度是重要的。为了减轻不稳定性，路由过程也使用了全精度。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006174" data-ratio="0.2253731343283582" data-type="png" data-w="670" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/66532187-c893-46e4-8d55-3a04955edef9.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     使用混合精度不会降低模型质量并可实现更快的训练 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这个 Jupyter Notebook 展示了如何对 Switch Transformers 进行微调以进行摘要生成的详细指南。然而，在开始微调 Switch Transformers 之前，强烈建议您先阅读关于微调混合专家模型部分的内容。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 采用了编码器 - 解码器的架构，实现了与 T5 类似的混合专家模型 (MoE) 版本。GLaM 这篇工作探索了如何使用仅为原来 1/3 的计算资源 (因为 MoE 模型在训练时需要的计算量较少，从而能够显著降低碳足迹) 来训练与 GPT-3 质量相匹配的模型来提高这些模型的规模。作者专注于仅解码器 (decoder-only) 的模型以及少样本和单样本评估，而不是微调。他们使用了 Top-2 路由和更大的容量因子。此外，他们探讨了将容量因子作为一个动态度量，根据训练和评估期间所使用的计算量进行调整。</p><span id="OSC_h2_8"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">用 Router z-loss 稳定模型训练</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">之前讨论的平衡损失可能会导致稳定性问题。我们可以使用许多方法来稳定稀疏模型的训练，但这可能会牺牲模型质量。例如，引入 dropout 可以提高稳定性，但会导致模型质量下降。另一方面，增加更多的乘法分量可以提高质量，但会降低模型稳定性。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ST-MoE 引入的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Router z-loss</code> 在保持了模型性能的同时显著提升了训练的稳定性。这种损失机制通过惩罚门控网络输入的较大 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">logits</code> 来起作用，目的是促使数值的绝对大小保持较小，这样可以有效减少计算中的舍入误差。这一点对于那些依赖指数函数进行计算的门控网络尤其重要。为了深入了解这一机制，建议参考原始论文以获得更全面的细节。</p><span id="OSC_h2_9"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">专家如何学习？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ST-MoE 的研究者们发现，编码器中不同的专家倾向于专注于特定类型的令牌或浅层概念。例如，某些专家可能专门处理标点符号，而其他专家则专注于专有名词等。与此相反，解码器中的专家通常具有较低的专业化程度。此外，研究者们还对这一模型进行了多语言训练。尽管人们可能会预期每个专家处理一种特定语言，但实际上并非如此。由于令牌路由和负载均衡的机制，没有任何专家被特定配置以专门处理某一特定语言。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006181" data-ratio="0.9258760107816711" data-type="png" data-w="742" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1137474f-1950-4033-8f38-785166343282.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     ST-MoE 论文中显示了哪些令牌组被发送给了哪个专家的表格 
   </figcaption></figure><span id="OSC_h2_10"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">专家的数量对预训练有何影响？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">增加更多专家可以提升处理样本的效率和加速模型的运算速度，但这些优势随着专家数量的增加而递减 (尤其是当专家数量达到 256 或 512 之后更为明显)。同时，这也意味着在推理过程中，需要更多的显存来加载整个模型。值得注意的是，Switch Transformers 的研究表明，其在大规模模型中的特性在小规模模型下也同样适用，即便是每层仅包含 2、4 或 8 个专家。</p><span id="OSC_h2_11"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">微调混合专家模型</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);"><code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">4.36.0</code> 版本的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">transformers</code> 库支持 Mixtral 模型。你可以用以下命令进行安装: <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">pip install "transformers==4.36.0 --upgrade</code></p></blockquote><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稠密模型和稀疏模型在过拟合的动态表现上存在显著差异。稀疏模型更易于出现过拟合现象，因此在处理这些模型时，尝试更强的内部正则化措施是有益的，比如使用更高比例的 dropout。例如，我们可以为稠密层设定一个较低的 dropout 率，而为稀疏层设置一个更高的 dropout 率，以此来优化模型性能。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在微调过程中是否使用辅助损失是一个需要决策的问题。ST-MoE 的作者尝试关闭辅助损失，发现即使高达 11% 的令牌被丢弃，模型的质量也没有显著受到影响。令牌丢弃可能是一种正则化形式，有助于防止过拟合。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 的作者观察到，在相同的预训练困惑度下，稀疏模型在下游任务中的表现不如对应的稠密模型，特别是在重理解任务 (如 SuperGLUE) 上。另一方面，对于知识密集型任务 (如 TriviaQA)，稀疏模型的表现异常出色。作者还观察到，在微调过程中，较少的专家的数量有助于改善性能。另一个关于泛化问题确认的发现是，模型在小型任务上表现较差，但在大型任务上表现良好。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006182" data-ratio="0.38010471204188484" data-type="png" data-w="955" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/47346e7f-b742-4923-a63d-7ccecd2a6427.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     在小任务 (左图) 中，我们可以看到明显的过拟合，因为稀疏模型在验证集中的表现要差得多。在较大的任务 (右图) 中，MoE 则表现良好。该图来自 ST-MoE 论文 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">一种可行的微调策略是尝试冻结所有非专家层的权重。实践中，这会导致性能大幅下降，但这符合我们的预期，因为混合专家模型 (MoE) 层占据了网络的主要部分。我们可以尝试相反的方法: 仅冻结 MoE 层的参数。实验结果显示，这种方法几乎与更新所有参数的效果相当。这种做法可以加速微调过程，并降低显存需求。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006180" data-ratio="0.77" data-type="png" data-w="400" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/401ba984-a5f5-4772-95db-99c12f026ef7.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     通过仅冻结 MoE 层，我们可以在保持质量的同时加快训练速度。该图来自 ST-MoE 论文 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在微调稀疏混合专家模型 (MoE) 时需要考虑的最后一个问题是，它们有特别的微调超参数设置——例如，稀疏模型往往更适合使用较小的批量大小和较高的学习率，这样可以获得更好的训练效果。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006183" data-ratio="0.37570303712035996" data-type="png" data-w="889" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/0f29d064-6852-4055-99ce-fab522c4d6bd.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     降低学习率和调大批量可以提升稀疏模型微调质量。该图来自 ST-MoE 论文 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">此时，您可能会对人们微调 MoE 中遇到的这些挑战而感到沮丧，但最近的一篇论文 《MoEs Meets Instruction Tuning》 (2023 年 7 月) 带来了令人兴奋的发现。这篇论文进行了以下实验:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      单任务微调 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      多任务指令微调 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      多任务指令微调后接单任务微调 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">当研究者们对 MoE 和对应性能相当的 T5 模型进行微调时，他们发现 T5 的对应模型表现更为出色。然而，当研究者们对 Flan T5 (一种 T5 的指令优化版本) 的 MoE 版本进行微调时，MoE 的性能显著提升。更值得注意的是，Flan-MoE 相比原始 MoE 的性能提升幅度超过了 Flan T5 相对于原始 T5 的提升，这意味着 MoE 模型可能从指令式微调中获益更多，甚至超过了稠密模型。此外，MoE 在多任务学习中表现更佳。与之前关闭 <strong style="color: black;">辅助损失</strong> 函数的做法相反，实际上这种损失函数可以帮助防止过拟合。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006179" data-ratio="0.4456140350877193" data-type="png" data-w="855" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/dc2a1d41-2a2d-4e63-b2c3-015fb22f56f3.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     与稠密模型相比，稀疏模型从指令微调中受益更多。该图来自 MoEs Meets instructions Tuning 论文 
   </figcaption></figure><span id="OSC_h2_12"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">稀疏 VS 稠密，如何选择?</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稀疏混合专家模型 (MoE) 适用于拥有多台机器且要求高吞吐量的场景。在固定的预训练计算资源下，稀疏模型往往能够实现更优的效果。相反，在显存较少且吞吐量要求不高的场景，稠密模型则是更合适的选择。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意</strong>: 直接比较稀疏模型和稠密模型的参数数量是不恰当的，因为这两类模型基于的概念和参数量的计算方法完全不同。</p><span id="OSC_h2_13"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">让 MoE 起飞</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">最初的混合专家模型 (MoE) 设计采用了分支结构，这导致了计算效率低下。这种低效主要是因为 GPU 并不是为处理这种结构而设计的，而且由于设备间需要传递数据，网络带宽常常成为性能瓶颈。在接下来的讨论中，我们会讨论一些现有的研究成果，旨在使这些模型在预训练和推理阶段更加高效和实用。我们来看看如何优化 MoE 模型，让 MoE 起飞。</p><span id="OSC_h3_14"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">并行计算</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">让我们简要回顾一下并行计算的几种形式:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">数据并行</strong>: 相同的权重在所有节点上覆制，数据在节点之间分割。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">模型并行</strong>: 模型在节点之间分割，相同的数据在所有节点上覆制。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">模型和数据并行</strong>: 我们可以在节点之间同时分割模型和数据。注意，不同的节点处理不同批次的数据。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">专家并行</strong>: 专家被放置在不同的节点上。如果与数据并行结合，每个节点拥有不同的专家，数据在所有节点之间分割。 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在专家并行中，专家被放置在不同的节点上，每个节点处理不同批次的训练样本。对于非 MoE 层，专家并行的行为与数据并行相同。对于 MoE 层，序列中的令牌被发送到拥有所需专家的节点。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006184" data-ratio="0.5910194174757282" data-type="png" data-w="824" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d166997f-8e65-483f-91e6-e5e4c1ccdf96.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformers 论文中展示如何使用不同的并行技术在节点上分割数据和模型的插图 
   </figcaption></figure><span id="OSC_h3_15"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">容量因子和通信开销</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">提高容量因子 (Capacity Factor, CF) 可以增强模型的性能，但这也意味着更高的通信成本和对保存激活值的显存的需求。在设备通信带宽有限的情况下，选择较小的容量因子可能是更佳的策略。一个合理的初始设置是采用 Top-2 路由、1.25 的容量因子，同时每个节点配置一个专家。在评估性能时，应根据需要调整容量因子，以在设备间的通信成本和计算成本之间找到一个平衡点。</p><span id="OSC_h3_16"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">部署技术</span><span style="display: none;"></span></h3><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">您可以在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">Inference Endpoints</code> 部署 mistralai/Mixtral-8x7B-Instruct-v0.1。</p></blockquote><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">部署混合专家模型 (MoE) 的一个关键挑战是其庞大的参数规模。对于本地使用情况，我们可能希望使用更小的模型。为了使模型更适合部署，下面是几种有用的技术:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      预先蒸馏实验: Switch Transformers 的研究者们进行了预先蒸馏的实验。他们通过将 MoE 模型蒸馏回其对应的稠密模型，成功保留了 30-40% 的由稀疏性带来的性能提升。预先蒸馏不仅加快了预训练速度，还使得在推理中使用更小型的模型成为可能。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      任务级别路由: 最新的方法中，路由器被修改为将整个句子或任务直接路由到一个专家。这样做可以提取出一个用于服务的子网络，有助于简化模型的结构。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      专家网络聚合: 这项技术通过合并各个专家的权重，在推理时减少了所需的参数数量。这样可以在不显著牺牲性能的情况下降低模型的复杂度。 
    </section></li></ul><span id="OSC_h3_17"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">高效训练</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">FasterMoE (2022 年 3 月) 深入分析了 MoE 在不同并行策略下的理论性能极限，并且探索了一系列创新技术，包括用于专家权重调整的方法、减少延迟的细粒度通信调度技术，以及一个基于最低延迟进行专家选择的拓扑感知门控机制。这些技术的结合使得 MoE 运行速度提升高达 17 倍。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Megablocks (2022 年 11 月) 则专注于通过开发新的 GPU kernel 来处理 MoE 模型中的动态性，以实现更高效的稀疏预训练。其核心优势在于，它不会丢弃任何令牌，并能高效地适应现代硬件架构 (支持块稀疏矩阵乘)，从而达到显著的加速效果。Megablocks 的创新之处在于，它不像传统 MoE 那样使用批量矩阵乘法 (这通常假设所有专家形状相同且处理相同数量的令牌)，而是将 MoE 层表示为块稀疏操作，可以灵活适应不均衡的令牌分配。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006185" data-ratio="0.2851851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d09a85e7-f59f-421c-8e9f-d75df34954c8.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     针对不同规模的专家和令牌数量的块稀疏矩阵乘法。该图来自 MegaBlocks 论文 
   </figcaption></figure><span id="OSC_h2_18"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">开源混合专家模型</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">目前，下面这些开源项目可以用于训练混合专家模型 (MoE):</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Megablocks: https://github.com/stanford-futuredata/megablocks 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Fairseq: https://github.com/facebookresearch/fairseq/tree/main/examples/moe_lm 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      OpenMoE: https://github.com/XueFuzhao/OpenMoE 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">对于开源的混合专家模型 (MoE)，你可以关注下面这些:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Switch Transformers (Google): 基于 T5 的 MoE 集合，专家数量从 8 名到 2048 名。最大的模型有 1.6 万亿个参数。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      NLLB MoE (Meta): NLLB 翻译模型的一个 MoE 变体。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      OpenMoE: 社区对基于 Llama 的模型的 MoE 尝试。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixtral 8x7B (Mistral): 一个性能超越了 Llama 2 70B 的高质量混合专家模型，并且具有更快的推理速度。此外，还发布了一个经过指令微调的模型。有关更多信息，可以在 Mistral 的，公告博客文章，中了解。 
    </section></li></ul><span id="OSC_h2_19"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">一些有趣的研究方向</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先是尝试将稀疏混合专家模型 (SMoE) <strong style="color: black;">蒸馏</strong> 回到具有更少实际参数但相似等价参数量的稠密模型。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">MoE 的 <strong style="color: black;">量化</strong> 也是一个有趣的研究领域。例如，QMoE (2023 年 10 月) 通过将 MoE 量化到每个参数不到 1 位，将 1.6 万亿参数的 Switch Transformer 所需的存储从 3.2TB 压缩到仅 160GB。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">简而言之，一些值得探索的有趣领域包括:</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      将 Mixtral 蒸馏成一个稠密模型。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      探索合并专家模型的技术及其对推理时间的影响。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      尝试对 Mixtral 进行极端量化的实验。 
    </section></li></ul><span id="OSC_h2_20"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">相关资源</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Adaptive Mixture of Local Experts (1991) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Learning Factored Representations in a Deep Mixture of Experts (2013) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer (2017) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding (Jun 2020) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      GLaM: Efficient Scaling of Language Models with Mixture-of-Experts (Dec 2021) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity (Jan 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      ST-MoE: Designing Stable and Transferable Sparse Expert Models (Feb 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      FasterMoE: modeling and optimizing training of large-scale dynamic pre-trained models(April 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      MegaBlocks: Efficient Sparse Training with Mixture-of-Experts (Nov 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models (May 2023) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixtral-8x7B-v0.1, Mixtral-8x7B-Instruct-v0.1. 
    </section></li></ul><span id="OSC_h2_21"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">Citation</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">@misc {sanseviero2023moe,<br>    author       = { Omar Sanseviero and<br>                     Lewis Tunstall and<br>                     Philipp Schmid and<br>                     Sourab Mangrulkar and<br>                     Younes Belkada and<br>                     Pedro Cuenca<br>                   },<br>    title        = { Mixture of Experts Explained },<br>    year         = 2023,<br>    url          = { https://huggingface.co/blog/moe },<br>    publisher    = { Hugging Face Blog }<br>}<br></code></pre><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">Sanseviero,&nbsp;et&nbsp;al.,&nbsp;<span style="color: #d14;line-height: 26px;">"Mixture&nbsp;of&nbsp;Experts&nbsp;Explained"</span>,&nbsp;Hugging&nbsp;Face&nbsp;Blog,&nbsp;2023.<br></code></pre><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">🤗 宝子们可以戳 <strong style="color: black;">阅读原文</strong> 查看文中所有的外部链接哟！</p></blockquote><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/moe</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Omar Sanseviero, Lewis Tunstall, Philipp Schmid, Sourab Mangrulkar, Younes Belkada, Pedro Cuenca</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">译者: xinyu66 (Xinyu Yang)</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Hugging Face（gh_504339124f0f）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10444582</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10444582</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[jsoup 1.17.2 发布，Java HTML 解析器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">jsoup 1.17.2 现已发布</span><span style="color:#000000">。jsoup 是一个用于处理 real-world&nbsp;HTML 的 Java 库。它使用最好的 HTML5 DOM 方法和 CSS 选择器提供了一个非常方便的 API 用于提取和操作数据。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">下载地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjsoup.org%2Fdownload" target="_blank">https://jsoup.org/download</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">具体更新内容包括：</span></p><h4><strong><span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>改进</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><strong>Attribute object accessors</strong>：添加<code>Element.attribute(String)</code>和<code>Attributes.attribute(String)</code>以便更简单地获取<code>Attribute</code>对象。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2069" target="_blank">2069</a></li><li><strong>Attribute source tracking</strong>：如果 source tracking 已打开，并且属性的键已更改（通过<code>Attribute.setKey(String)</code>），则现在仍会在<code>Attribute.sourceRange()</code>中跟踪 source range。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2070" target="_blank">2070</a></li><li><strong>Wildcard attribute selector</strong>：添加了对具有任何属性选择器的<code>[*]</code>元素的支持。并且还恢复了对通过空属性名称前缀 (&nbsp;<code>[^]</code>) 选择的支持。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2079" target="_blank">2079</a></li></ul><h4><strong><span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Bug 修复</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><strong>Mixed-cased source position</strong>：跟踪属性的源位置时，如果源属性名称是混合大小写的，但解析器是小写规范化属性名称，则无法正确跟踪该属性的源位置。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2067" target="_blank">2067</a></li><li><strong>Source position NPE</strong>：跟踪正文片段解析的源位置时，抛出空指针异常。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2068" target="_blank">2068</a></li><li><strong>Multi-point emoji entity</strong>：多点编码的表情符号实体可能会被错误地解码为替换字符。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2074" target="_blank">2074</a></li><li><strong>Selector sub-expressions</strong>：（回归）在像<code>parent [attr=va], other</code>之类的选择器中，<code>, OR</code>被绑定到<code>[attr=va]</code>而不是<code>parent [attr=va]</code>，导致不正确的选择。该修复包含一个 EvaluatorDebug 类，可生成一个 sexpr 来表示查询，从而使查询解析测试更简单、更彻底。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2073" target="_blank">2073</a></li><li><strong>XML CData output</strong>：从解析的 HTML 生成 XML 语法输出时，包含（伪）CData 部分的脚本节点将添加无关的 CData 部分，从而导致脚本执行错误。现在，<br> 如果数据尚未位于 CData 部分中，则数据内容将以 HTML/XML/XHTML 多语言格式发出。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2078" target="_blank">2078</a></li><li><strong>Thread safety</strong>：<code>:has</code>evaluator 持有一个非线程安全的迭代器，因此如果多个并发线程共享一个 Evaluator object，可能会抛出 NoSuchElement 异常，并且选择的结果可能不正确。现在，迭代器对象是线程本地的。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Fissues%2F2088" target="_blank">2088</a></li></ul><p><span style="background-color:#ffffff; color:#333333">更新说明：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjhy%2Fjsoup%2Freleases%2Ftag%2Fjsoup-1.17.2" target="_blank">https://github.com/jhy/jsoup/releases/tag/jsoup-1.17.2</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273388/jsoup-1-17-2-released</guid>
            <link>https://www.oschina.net/news/273388/jsoup-1-17-2-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenCV 4.9.0 发布，Intel 开源的计算机视觉库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">OpenCV 是 Intel 开源计算机视觉库，它实现了图像处理和计算机视觉方面的很多通用算法。OpenCV 4.9.0 版本的主要更新内容如下：</span></p><ul><li><p><span style="background-color:#ffffff; color:#1f2328">Core Module</span><span><span>：</span></span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23965" target="_blank">#23965</a>&nbsp;添加<code>cv::broadcast</code></li></ul></li><li>DNN module patches： 
  <ul><li>Experimental transformers 支持</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24476" target="_blank">#24476</a>&nbsp;ONNX Attention layer 支持</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24037" target="_blank">#24037</a>&nbsp;ONNX Einsum layer 支持</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23987" target="_blank">#23987</a>&nbsp;INT8 models 的 OpenVINO 后端</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24092" target="_blank">#24092</a>&nbsp;ONNX Gather Elements layer</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24378" target="_blank">#24378</a>&nbsp;ONNX InstanceNorm layer</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23897" target="_blank">#23897&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24694" target="_blank">#24694&nbsp;</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24509" target="_blank">#24509</a>&nbsp;新的 fastGEMM 实现及其之上的多个层</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23654" target="_blank">#23654</a>&nbsp;ARM 上的 Winograd fp16 优化</li><li>对 Yolo 系列模型支持的测试和多项修复</li><li>CUDA 后端中的新层支持和错误修复：GEMM、Gelu、Add</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24462" target="_blank">#24462</a>&nbsp;CANN 后端：错误修复，支持 HardSwish、LayerNormalization 和 InstanceNormalization</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24552" target="_blank">#24552</a>&nbsp;LayerNormalization：支持 OpenVINO、OpenCL 和 CUDA 后端</li></ul></li><li><p><span><span>G-API 模块：</span></span></p><ul><li>TBD</li></ul></li><li><p><span><span>Objdetect 模块：</span></span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24364" target="_blank">#24364</a>&nbsp;<span style="background-color:#ffffff; color:#1f2328">QR code encoder version estimation&nbsp;</span>中的错误修复</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24479" target="_blank">#24479</a>&nbsp;修复了 ArUco 中的&nbsp;contour filtering</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24598" target="_blank">#24598</a>&nbsp;Android 的&nbsp;QR&nbsp;码检测示例</li><li>针对 Aruco makers、Charuco boards 和 QR 码的多个本地错误修复和文档更新。</li></ul></li><li><p><span><span>Video：</span></span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24201" target="_blank">#24201</a>&nbsp;Google Summer of Code：为基于视觉转换器的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv_zoo%2Ftree%2Fmain%2Fmodels%2Fobject_tracking_vittrack" target="_blank">VitTrack</a>&nbsp;添加了新的对象跟踪 API&nbsp;<code>TrackerVit</code>。</li></ul></li><li><p><span><span>Calibration module：</span></span></p><ul><li>多项修复和改进 chess board calibration rig detector。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23025" target="_blank">#23025</a>&nbsp;如果 calibration system 约束不足，calibrateCamera 会抛出异常。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fissues%2F24482" target="_blank">#24482</a>&nbsp;修复了 USAC 的 findEssentialMat 中的错误</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24527" target="_blank">#24527</a>&nbsp;修复了<code>cv::cornerSubPix</code>中的&nbsp;out-of-image access</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23607" target="_blank">#23607</a>&nbsp;修复了 ap3p 中的崩溃</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24035" target="_blank">#24035</a>&nbsp;修复&nbsp;stereoRectify image boundaries</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24211" target="_blank">#24211</a>&nbsp;修复了 Essential_solver.cpp 中的「use after free」问题</li></ul></li><li><p><span><span>Python 绑定：</span></span></p><ul><li>为遗漏的类型和手动包装的类型添加了类型存根生成。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24026" target="_blank">#24026</a>&nbsp;添加了 Numpy 数组的只读标志处理。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24028" target="_blank">#24028</a>&nbsp;修复了模块内的异常处理和绑定。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23958" target="_blank">#23958</a>&nbsp;改进了 Numpy 数组类型处理中的错误消息。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F24468" target="_blank">#24468</a>&nbsp;修复了 Python 中的构造函数文档。</li></ul></li><li><p><span><span>Android：</span></span></p><ul><li>通过&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcentral.sonatype.com%2Fartifact%2Forg.opencv%2Fopencv%2Foverview" target="_blank">Maven Central 发布</a>的新 Android Archive Package (AAR)</li><li>新的 Android 示例：QR 码检测器、视频 IO 示例。DNN 和人脸检测器示例更新。</li><li>切换到 Gradle 7.6.3，现代 Android 工具。</li></ul></li><li><p><span><span>平台支持：</span></span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fpull%2F23021" target="_blank">#23021</a>&nbsp;在 CMake 中将 CUDA 作为 first class 语言进行实验性支持</li></ul></li><li><p><span><span>其他：</span></span></p><ul><li>TBD</li><li>OpenCV Summer of Code：HAN Liutong 跨多个拉取请求的半自动重构使 CPU 优化代码与可变向量长度的 SIMD (RISC-V RVV) 兼容</li></ul></li></ul><p>更多详情可查看&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencv%2Fopencv%2Fwiki%2FChangeLog%23version490" target="_blank">ChangeLog</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 10:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273327/opencv-4-9-0-released</guid>
            <link>https://www.oschina.net/news/273327/opencv-4-9-0-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 大语言模型技术报告.pdf]]>
            </title>
            <description>
                <![CDATA[看之前先买瓶水，货实在太干了[Facepalm]]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://talk.gitee.com/report/china-open-source-2023-llm-report.pdf?fr=news1229</guid>
            <link>https://talk.gitee.com/report/china-open-source-2023-llm-report.pdf?fr=news1229</link>
        </item>
        <item>
            <title>
                <![CDATA[GreatSQL 8.0.32-25 今日发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>GreatSQL 8.0.32-25 今日发布</h1><h2>版本信息</h2><ul><li><p>发布时间：2023 年 12 月 28 日</p></li><li><p>版本号：8.0.32-25, Revision db07cc5cb73</p></li><li><p>下载链接：<a href="https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.0.32-25">RPM 包</a>、<a href="https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.0.32-25">TAR 包</a>、<a href="https://gitee.com/GreatSQL/GreatSQL/releases/tag/GreatSQL-8.0.32-25">源码包</a></p></li><li><p>用户手册：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fdocs%2F8032-25%2F" target="_blank">GreatSQL 8.0.32-25 User Manual</a></p></li></ul><h2>特性增强</h2><p>GreatSQL 8.0.32-25 版本中首次推出支持高性能的内存查询加速 AP 引擎，可将 GreatSQL 的数据分析性能提升几个数量级；大幅增加 Oracle 兼容特性，支持更多数据类型、SQL 语法、函数及存储过程等；支持异步删除 InnoDB 大表；支持在 MGR 只读节点绑定动态 VIP 以及主节点切换时主动断开当前连接，缩短应用端不可用时长。</p><h3>高可用</h3><ul><li>支持在 MGR 单主（Single Primary）模式下，对只读节点绑定 VIP，业务可以通过该 VIP 来访问只读节点，实现只读节点的动态 VIP 漂移。更详细内容参考：MGR 绑定动态 VIP。</li><li>支持在 MGR 单主（Single Primary）模式下，当主节点切换时会主动关闭当前活跃连接，缩短应用端不可用时长。更详细内容参考：MGR 切主后断开应用连接。</li><li>在跨机房容灾场景，同时开启多源复制和主主复制时，可能出现数据回路问题。新增 replicate_server_mode 选项用于控制只应用多源复制管道内临近主节点上产生的 binlog，不会应用其他的非临近节点产生的 binlog，避免出现数据回路问题。多通道主主复制能减少机房容灾演练和切换时的主从配置变更，该特性由中移智家 DBA 团队（徐良）贡献代码。更多详细内容参考：GreatSQL 高可用特性之主主复制防止回路。</li><li>更多信息详见文档：高可用。</li></ul><h3>高性能</h3><ul><li><p>支持类似 MySQL HeatWave 的大规模并行、高性能的内存查询加速 AP 引擎，可将 GreatSQL 的数据分析性能提升几个数量级。在 32C64G 测试机环境下，TPC-H 100G 测试中 22 条 SQL 总耗时仅需不到 80 秒。更详细内容参考：Rapid 引擎。</p></li><li><p>支持异步删除 InnoDB 大表，删除 10G 以上大表时对系统负载几乎没影响，有效提高 InnoDB 引擎运行时性能的稳定性。更详细内容参考：异步删除 InnoDB 大表。</p></li><li><p>提升 InnoDB PQ 能力，支持 TPC-H Q21 查询优化能力。</p></li><li><p>更多信息详见文档：高性能。</p></li></ul><h3>高兼容</h3><ul><li><p>从 GreatSQL 8.0.32-25 版本开始，在 Oracle 兼容方面有了巨大提升，除了 OCI、DBlink、Packages 之外，支持大多数常用的 SQL 语法、数据类型、函数、存储过程、触发器、视图等功能。支持 CLOB、NUMBER、VARCHAR2、PLS_INTEGER 等数据类型，支持 ADD_MONTHS、CHR、DUMP 等函数，支持 ANY、ALL、Hierarchical Query、FULL JOIN 等 SQL 语法，支持存储过程、触发器、视图等兼容性。</p></li><li><p>更多信息详见文档：高兼容。</p></li></ul><h2>缺陷修复</h2><ul><li>修复当在多子网环境中的 MGR 读写节点绑定 VIP 后需手动刷新 ARP 表的问题 <a href="https://gitee.com/GreatSQL/GreatSQL/issues/I7F3PB">issue#I7F3PB</a>。</li><li>修复当接收端实例设置 <code>innodb_flush_method = O_DIRECT</code> 时，执行加密 CLONE 备份时性能特别差的问题。</li><li>修复启用 InnoDB PQ 特性后，TPC-H Q3、Q5 查询性能反倒下降的问题。</li><li>修复 Oracle 兼容函数 SUBSTR 及 SUBSTRB 在对传入参数自动做四舍五入与 Oracle 处理不一致的问题。</li><li>修复并行 LOAD DATA 无法正确分割复杂文本，同时会有长事务不提交导致 UNDO 持续增长的问题。</li><li>修复在 FOR LOOP 循环中用到 ROWNUM 时，在每轮循环中，数据查询结果集中的 ROWNUM 不能被重置从 0 再开始的问题。</li></ul><h2>注意事项</h2><h2>GreatSQL VS MySQL</h2><table cellspacing="0" style="border-collapse:collapse; box-sizing:border-box !important; display:table; margin:0px 0px 10px; max-width:100%; outline:0px; overflow-wrap:break-word !important; padding:0px; width:657px"><tbody><tr><th style="text-align:left"><strong>1.主要特性</strong></th><th style="text-align:center">GreatSQL 8.0.32-25</th><th style="text-align:center">MySQL 8.0.32</th></tr></tbody><tbody><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">开源</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">ACID 完整性</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MVCC 特性</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">支持行锁</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Crash 自动修复</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">表分区 (Partitioning)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">视图 (Views)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">子查询 (Subqueries)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">触发器 (Triggers)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">存储程序 (Stored Programs)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">外键 (Foreign Keys)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">窗口函数 (Window Functions)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">通用表表达式 CTE</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">地理信息 (GIS)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">基于 GTID 的复制</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">组复制 (MGR)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MyRocks 引擎</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">&nbsp;</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px"><strong>2. 性能提升扩展</strong></td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">GreatSQL 8.0.32-25</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">MySQL 8.0.32</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">AP 引擎</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">仅云上 HeatWave</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnODB 并行查询</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">仅主键扫描</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">并行 LOAD DATA</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 事务 ReadView 无锁优化</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 事务大锁拆分优化</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 资源组</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">自定义 InnoDB 页大小</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Contention-Aware Transaction Scheduling</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB Mutexes 拆分优化</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MEMORY 引擎优化</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB Flushing 优化</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">并行 Doublewrite Buffer</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 快速索引创建优化</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">VARCHAR/BLOB/JSON 类型存储单列压缩</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">数据字典中存储单列压缩信息</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px"><strong>3. 面向开发者提升改进</strong></td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">GreatSQL 8.0.32-25</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">MySQL 8.0.32</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">X API</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">JSON</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">NoSQL Socket-Level 接口</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 全文搜索改进</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">更多 Hash/Digest 函数</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Oracle 兼容-数据类型</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Oracle 兼容-函数</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Oracle 兼容-SQL 语法</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Oracle 兼容-存储程序</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px"><strong>4. 基础特性提升改进</strong></td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">GreatSQL 8.0.32-25</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">MySQL 8.0.32</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MGR 提升-地理标签</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MGR 提升-仲裁节点</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MGR 提升-读写节点绑定 VIP</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MGR 提升-快速单主模式</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MGR 提升-智能选主机制</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">MGR 提升-全新流控算法</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">information_schema 表数量</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">95</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">65</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">全局性能和状态指标</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">853</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">434</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">优化器直方图 (Histograms)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Per-Table 性能指标</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Per-Index 性能指标</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Per-User 性能指标</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Per-Client 性能指标</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Per-Thread 性能指标</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">全局查询相应耗时统计</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">SHOW INNODB ENGINE STATUS 增强</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">回滚段信息增强</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">临时表信息增强</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">用户统计信息增强</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Slow log 信息增强</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px"><strong>5.安全性提升</strong></td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">GreatSQL 8.0.32-25</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">MySQL 8.0.32</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">国密支持</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">备份加密</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">审计日志入库</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">SQL Roles</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">SHA-2 密码 Hashing</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">密码轮换策略</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">PAM 认证插件</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">仅企业版</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">审计插件</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">仅企业版</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Keyring 存储在文件中</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">Keyring 存储在 Hashicorp Vault 中</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">仅企业版</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 数据加密</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 日志加密</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">InnoDB 各种表空间文件加密</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">二进制日志加密</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">临时文件加密</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">强制加密</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px"><strong>6. 运维便利性提升</strong></td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">GreatSQL 8.0.32-25</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">MySQL 8.0.32</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">DDL 原子性</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">数据字典存储 InnoDB 表</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">快速 DDL</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">SET PERSIST</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">不可见索引</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">线程池 (Threadpool)</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">仅企业版</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">备份锁</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">SHOW GRANTS 扩展</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">表损坏动作扩展</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">杀掉不活跃事务</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr><tr><td style="border-color:#cccccc; border-style:solid; border-width:1px">START TRANSACTION WITH CONSISTENT SNAPSHOT 扩展</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">✔️</td><td style="border-color:#cccccc; border-style:solid; border-width:1px; text-align:center">❌</td></tr></tbody></table><p>此外，GreatSQL 8.0.32-25 基于 Percona Server for MySQL 8.0.32 版本，它在 MySQL 8.0.32 基础上做了大量的改进和提升以及众多新特性，详情请见：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.percona.com%2Fpercona-server%2F8.0%2Ffeature-comparison.html" target="_blank"><strong>Percona Server for MySQL feature comparison</strong></a>，这其中包括线程池、审计、数据脱敏等 MySQL 企业版才有的特性，以及 performance_schema 提升、information_schema 提升、性能和可扩展性提升、用户统计增强、PROCESSLIST 增强、Slow log 增强等大量改进和提升，这里不一一重复列出。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273278/greatsql-8-0-32-25-released</guid>
            <link>https://www.oschina.net/news/273278/greatsql-8-0-32-25-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 23.04 将于 2024 年 1 月 25 日结束支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">对 <a href="https://www.oschina.net/news/237763/ubuntu-23-04-released">Ubuntu 23.04「Lunar Lobster」</a>的官方支持将于 2024 年 1 月 25 日结束，还剩不到一个月的时间。</span></p><p><span style="color:#000000">Ubuntu 23.04 版本于 2023 年 4 月正式发布，作为短期支持版本获得 9 个月的支持。还在使用该版本的用户<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F12%2Fubuntu-2304-support-ends-january-2024" target="_blank">建议</a>可以考虑升级到 10 月份发布的 <a href="https://www.oschina.net/news/261571/ubuntu-23-10-ga">Ubuntu 23.10"Mantic Minotaur"</a>，以确保可继续收到来自 Canonical 的安全补丁、关键错误修复以及精选软件的重要更新。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-4bdb313301be4efb73863c20508102b5a86.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Ubuntu 23.10 附带了最新的 GNOME 45 版本（其中包含大量改进）、使用 Linux 6.5 内核、更新了图形驱动程序，并首次发布了 2 个全新的应用程序，这些应用程序目前为该版本<span style="background-color:#ffffff">独有</span>： App Center 和 Firmware。</span></p><p><span style="color:#000000">同样作为短期支持版本，Ubuntu 23.10 计划将于 2024 年 7 月中旬达到 EOL。不过预计明年 4 月下旬，<span style="background-color:#ffffff"><a href="https://www.oschina.net/news/263525/ubuntu-24-04-release-date-april-25-2024">Ubuntu 24.04 LTS</a> 版本就会正式发布，LTS 版本将获得 5 年的安全更新、错误修复和精选应用程序更新；LTS 版本预期每 2 年发布一次。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273275/ubuntu-2304-support-ends-january-2024</guid>
            <link>https://www.oschina.net/news/273275/ubuntu-2304-support-ends-january-2024</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenNJet v2.00 发布啦！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">在最新发布的 v2.0.0 版本中，对基础框架进行了大幅优化，增加对 HTTP/3 的支持，进一步丰富了 OpenNJet 的生态，动态能力逐渐成熟。此次更新主要包括以下五个方面：</p><ul><li><strong>基础框架大幅优化。</strong><span>&nbsp;</span>框架的优化对于 CoPilots 进行了加固，实现了 lua vm、高权限执行框架、配置沙箱等能力，从而进一步提高 OpenNJet 的稳定性以及执行效率。</li><li><strong>成熟的动态能力。</strong><span>&nbsp;</span>对模块继续进行动态化改造，优化了动态证书管理，覆盖企业灰度发布等关键场景，动态 location 能力在 v2.0.0 已经进入成熟阶段。</li><li><strong>加入新协议 HTTP/3 。</strong><span>&nbsp;</span>主要实现了 HTTP/3 的 Server 能力，以及 ftp 协议的代理能力。在安全的基础上实现灵活的负载均衡</li><li><strong>继续强化高效安全。</strong><span>&nbsp;</span>强化系统安全，加固自身；实现了业务安全，业务修复无损性能，更好的保护数据、提供可靠的服务，并简化运维任务。</li><li><strong>两个企业特性。</strong><span>&nbsp;</span>实现集群的基本构建，从而避免在故障转移、集群扩容新增加节点等人工操作，减少业务中断时间而无损性能；尝试引入智能化，合理分配资源。</li></ul><p><strong>详细解读：</strong><a href="https://my.oschina.net/u/6606114/blog/10456620">https://my.oschina.net/u/6606114/blog/10456620</a></p><p><strong>Gitee 仓库：</strong><a href="https://gitee.com/njet-rd/njet">https://gitee.com/njet-rd/njet</a></p><p><strong>官网：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2F" target="_blank">https://njet.org.cn/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273260/opennjet-2-00-released</guid>
            <link>https://www.oschina.net/news/273260/opennjet-2-00-released</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CNCF 报告：Kubernetes 推动云支出增长]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CNCF 发布的一份调查报告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F20%2Fcncf-cloud-native-finops-cloud-financial-management-microsurvey%2F" target="_blank">指出</a>，Kubernetes 的到来导致了云支出急剧增加；有<span style="background-color:#fdfdfd; color:#000000">近一半 (49%) 的受访者表示 Kubernetes 推动了云支出增长。</span>其中，17% 的人表示成本大幅增加，32% 的人表示成本仅略有增加。</p><p>另一方面，13% 的受访者在实施 Kubernetes 后成功显着减少了云支出，11% 的受访者成功略微减少了支出。28% 的受访者表示采用 Kubernetes 后没有任何变化。</p><p><img height="273" src="https://oscimg.oschina.net/oscnet/up-153215e0c5e6743aa6ba642aee27efef80b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">约 28% 的受访者表示，Kubernetes 占用了他们一半的预算，10% 的受访者表示，这一数字高达 75%，还有极少数 5% 的受访者表示，Kubernetes 占用了他们的全部预算。</span></p><p><img height="279" src="https://oscimg.oschina.net/oscnet/up-0189729f7a76027da4a44209791e910f940.png" width="500" referrerpolicy="no-referrer"></p><p>26% 的人每月在云计算上的支出高达 50000 美元；还有 22% 的人表示他们的支出是前者的 20 倍，每月高达 100 万美元以上。此外，21% 的人每月云计算支出不到 1 万美元。</p><p>在受访者中，Kubernetes 基础设施的规模存在很大差异。近一半的受访者 (49%) 只<span style="background-color:#fdfdfd; color:#000000">拥有最多 50 个节点</span>。15% 拥有 51-100 个节点，17% 拥有 101-250 个节点，18% 拥有超过 251 个节点。&nbsp;</p><p>许多人力和技术因素被认为是云环境中支出以及不必要和意外成本增加的原因。过度配置以 70% 的比例遥遥领先，个人或团队层面缺乏责任意识位居第二，为 45%。使用资源后未能停用资源以及存在技术债务（定义为尚未重新架构以利用云原生环境的可扩展性的工作负载）并列第三，各占 43%。</p><p><img alt="" height="417" src="https://oscimg.oschina.net/oscnet/up-4a03450fb93c2128ee80b363c64d6f5c9f6.png" width="500" referrerpolicy="no-referrer"></p><p>只有 19% 的受访者表示他们能够准确监控 Kubernetes 成本。40% 的人只是进行了估计，38% 的人表示他们根本没有进行任何监控。</p><p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F20%2Fcncf-cloud-native-finops-cloud-financial-management-microsurvey%2F" target="_blank">查看完整报告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273259/cncf-report-kubernetes-cloud-spen</guid>
            <link>https://www.oschina.net/news/273259/cncf-report-kubernetes-cloud-spen</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.13.0 - 支持 StarRocks]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>🚀 新功能</h2><ul><li>支持 StarRocks。</li><li>支持 PostgreSQL, Redshift, RisingWave 高级自动补全。</li></ul><h2>🎄 改进</h2><ul><li>支持在 SQL 编辑器的表结构 DDL 弹窗中展示 index 语句。</li><li>支持在 SQL 编辑器中查询 PostgreSQL 外部表。</li><li>汉化钉钉 webhook 消息。</li></ul><h2>🎠 社区</h2><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1TG411r7rr%2F" target="_blank">盘点常用的 MySQL 可视化客户端</a></li></ul><h2>📕 安装及升级</h2><p>参考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升级指南</a>。如果从之前版本升级，获取新版本后，重新启动升级即可。</p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10456200</guid>
            <link>https://my.oschina.net/u/6148470/blog/10456200</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[写给工程师的 MacBook 商用级大模型知识库部署方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;visibility: visible;" data-mpa-powered-by="yiban.io"><img class="rich_pages wxw-img __bg_gif" data-backh="96" data-backw="578" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="96" data-imgfileid="503041736" data-ratio="0.16666666666666666" src="https://oscimg.oschina.net/oscnet/990ffd45-801b-45e6-80cd-1b6ebb403d86.gif" data-type="gif" data-w="636" style="outline: 0px;letter-spacing: 0.544px;font-size: var(--articleFontsize);border-radius: 8px;text-align: justify;width: 100%;visibility: visible !important;background-size: 16px !important;height: auto;" referrerpolicy="no-referrer"><br style="outline: 0px;visibility: visible;"></section><section data-mpa-template="t" data-mpa-template-id="502" data-mpa-category="模板" style="outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);visibility: visible;"><section data-mpa-category="模板" data-mid="" style="padding-right: 1px;padding-left: 1px;outline: 0px;width: 677px;display: flex;justify-content: flex-start;align-items: center;flex-direction: column;visibility: visible;"><section data-mid="" style="outline: 0px;letter-spacing: 0.544px;width: 675px;display: grid;grid-template-columns: 26px auto;visibility: visible;"><section data-mid="" style="outline: 0px;width: 26px;height: 14px;display: flex;justify-content: center;align-items: center;align-self: center;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section data-mid="" style="padding-left: 7px;outline: 0px;display: flex;justify-content: flex-start;align-items: center;visibility: visible;"><section data-mid="" style="margin-right: 7px;outline: 0px;text-align: left;visibility: visible;"><p data-mid="" style="outline: 0px;width: 0px;font-size: 14px;font-family: PingFangSC-Semibold, &quot;PingFang SC&quot;;font-weight: bold;color: rgb(58, 92, 244);line-height: 20px;visibility: visible;"><br style="outline: 0px;visibility: visible;"></p></section><section data-mid="" style="margin-bottom: 4px;outline: 0px;width: 635px;height: 1px;border-top: 1px solid rgb(58, 92, 244);align-self: flex-end;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section></section></section><section data-mid="" style="padding: 7px 14px 9px 19px;outline: 0px;width: 675px;text-align: left;border-bottom: 1px solid rgb(58, 92, 244);visibility: visible;"><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;letter-spacing: 0.578px;text-align: justify;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;white-space-collapse: preserve;text-size-adjust: inherit;text-align: left;caret-color: rgb(23, 26, 29);letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;color: rgb(0, 0, 0);visibility: visible;font-size: 15px;">本文介绍了如何在<span style="font-size: 15px;letter-spacing: 1px;text-wrap: wrap;">自己的 MacBook 上部署一套知识库方案辅助自己的知识管理工作，</span><span style="font-size: 15px;letter-spacing: 1px;text-wrap: wrap;">希望能给每位计划自己搭建大模型知识库应用的工程师一点参考。</span></span></p></section></section></section><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;line-height: 1.75em;"><br style="outline: 0px;visibility: visible;"></p><section style="margin-bottom: 0px;outline: 0px;box-sizing: inherit;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgba(25, 26, 31, 0.9);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;text-align: center;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041735" data-ratio="0.3161764705882353" data-s="300,640" src="https://oscimg.oschina.net/oscnet/1447be7f-ff8f-4af0-a27e-b2863660d071.png" data-type="png" data-w="408" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 113px !important;" referrerpolicy="no-referrer"></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;color: rgb(3, 69, 255);font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;visibility: visible;">背景</span></section><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></h4><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">历史的车轮滚滚向前，大模型技术发展日新月异，每天都有新鲜的技术出炉，让人目不暇接，同时具备可玩性和想象空间的各种应用和开源库，仿佛让自己回到了第一次设置 JAVA_HOME 的日子，作为一枚古典工程师，我专门挑了个可能对手上工作有帮助的方向小试一把，尝试在自己的 MacBook 上部署一套知识库方案，看看能不能辅助自己的知识管理工作。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">我自己的 Macbook 配置情况如下，可以流畅地运行没问题。经过量化处理的大模型，还是对办公本很友好的。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041733" data-ratio="0.24633431085043989" src="https://oscimg.oschina.net/oscnet/f4f317ea-3d61-4055-91c7-8f6534441328.jpg" data-type="other" data-w="682" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">为什么要在 MacBook 搭建而不是直接采用现成的云服务呢？最核心最重要的是我们手上的文档资料出于安全要求，不能随便上传云服务，也就无法实际验证知识库的实际效用；另外对于工程师来说，自己亲手搭建一个完整的方案、能灵活调整和对接各种不同的模型、评测各种模型不同的表现，也是出于对技术的探索本能使然。</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">鉴于大模型已经是大模型及其周边概念已经是大家耳熟能详的东西，我这里就不再重复阐述相关的基础概念和理论了，直接进入动手环节，以用最快的速度部署起一个可用的知识库平台为目标，先用起来，再分各个环节优化。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-bottom: 0px;outline: 0px;box-sizing: inherit;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgba(25, 26, 31, 0.9);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;font-size: 15px;letter-spacing: 1px;visibility: visible;"><img class="rich_pages wxw-img" data-imgfileid="503041732" data-ratio="0.3056872037914692" data-s="300,640" src="https://oscimg.oschina.net/oscnet/476e87ec-3926-4421-826d-d28a2c78789f.png" data-type="png" data-w="422" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 117px !important;" referrerpolicy="no-referrer"></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;visibility: visible;color: rgb(0, 17, 255);">方案概述</span></section><section style="margin-bottom: 8px;"><br></section><span id="OSC_h4_1"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;margin-bottom: 8px;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">应用架构</span></strong></span></h4><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">首先来看一下最终方案的应用架构是什么样子（下图）。在这套方案中，我们采用实力排上游、并且在使用上对学术和商业都友好的国产大模型 ChatGLM3-6B 对话模型和基于 m3e-base 模型的 embedding search RAG 方案；基于这两个模型封装和 ChatGPT 兼容的 API 接口协议；通过引入 One API 接口管理&amp;分发系统，形成统一的 LLM 接口渠道管理平台规范，并把封装好的接口协议注册进去；搭建与 Dify.ai 齐名的开源大模型知识库平台管理系统 FastGPT，实现集私有知识数据源预处理、嵌入检索、大模型对话一体的完整知识库应用流程。麻雀虽小五脏俱全，最终形成一套既满足商用标准、又能在 MacBook 跑起来的的方案。虽然智能程度和实际需求还有一定差距，但至少我们在不用额外购买显卡或云服务的情况下，以最小成本部署运行、并且能导入实际业务数据（如语雀知识库）进行实操验证，值得每位工程师都来动手尝试一下。</span></section><p style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><img class="rich_pages wxw-img" data-imgfileid="503041734" data-ratio="0.7546296296296297" src="https://oscimg.oschina.net/oscnet/aa80fe6e-e7fa-4823-9906-d7c8f3ddcd3e.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></p><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><br></h4><span id="OSC_h4_2"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">成型展示</span></strong></span></h4><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"></h4><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">在用户终端，我们基于 FastGPT 提供知识库管理及使用方案。引用其官网介绍：FastGPT 是一个基于 LLM 大语言模型的知识库问答系统，提供开箱即用的数据处理、模型调用等能力。同时可以通过 Flow 可视化进行工作流编排，从而实现复杂的问答场景。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">先放一张官网上的图片，来增加一点吸引朋友们动手操作的动力：</span></section><section style="margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041740" data-ratio="0.4842592592592593" src="https://oscimg.oschina.net/oscnet/b61b175a-2352-47d3-a57f-826fbb292f26.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><section style="margin-bottom: 8px;"><br></section><span id="OSC_h4_3"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">部署要点</span></strong></span></h4><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">本套方案部署分为四个主要环节、14 个具体步骤，只要一步步实操下去，每位朋友都可以在自己的本本上拥有属于自己的私有大模型知识库系统，步骤清单如下：</span></section><table width="628"><colgroup style="box-sizing: inherit;"><col width="192" style="box-sizing: inherit;"><col width="436" style="box-sizing: inherit;"></colgroup><tbody style="box-sizing: inherit;"><tr data-cangjie-key="87" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="89" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-weight: bold;letter-spacing: 1px;font-size: 15px;">主要环节</span></section></td><td data-cangjie-key="94" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-weight: bold;font-size: 15px;letter-spacing: 1px;">详细步骤</span></section></td></tr><tr data-cangjie-key="99" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="101" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">一、准备大模型</span></section></td><td data-cangjie-key="106" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.1 下载对话语言模型 ChatGLM3-6B</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.2 下载文本嵌入模型 m3e-base</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.3 使用 chatglm.cpp 对 ChatGLM3-6B 进行量化加速</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.4 验证模型问答效果</span></section></td></tr><tr data-cangjie-key="120" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="122" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">二、搭建模型 API 服务</span></section></td><td data-cangjie-key="127" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2.1 搭建模型 API</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2.2 搭建 One API 接口管理/分发系统</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2.3 验证模型接口能力</span></section></td></tr><tr data-cangjie-key="138" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="140" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">三、搭建知识库应用</span></section></td><td data-cangjie-key="145" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.1 安装 MongoDB</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.2 安装 PostgreSQL &amp; pgvector</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.3 搭建 FastGPT 知识库问答系统</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.4 验证模型对话能力</span></section></td></tr><tr data-cangjie-key="159" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="161" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">四、知识库问答实战</span></section></td><td data-cangjie-key="166" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">4.1 准备知识库语料</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">4.2 导入知识库数据</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">4.3 验证知识库问答效果</span></section></td></tr></tbody></table><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">部分步骤可以简单地通过 Docker 镜像一键部署完成，但本着对细节一杆子插到底的部署思路，还是采取了纯手工作业的方法。注意，下面的步骤中仅包含了关键的命令，完整的命令可以参考对应系统的官网介绍。部分安装步骤如果速度不够理想，可以考虑采用国内源，包含但不限于 go、brew、pip、npm 等。</span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;visibility: visible;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041737" data-ratio="0.3056872037914692" data-s="300,640" data-type="png" data-w="422" src="https://oscimg.oschina.net/oscnet/c8d6ad94-b394-4e67-a5c3-8464690e8f51.png" style="outline: 0px;letter-spacing: 0.544px;font-size: 14px;visibility: visible !important;width: 117px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;visibility: visible;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;color: rgb(0, 17, 255);">详细步骤</span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;visibility: visible;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><br></section><section style="margin-bottom: 8px;"><br></section><span id="OSC_h4_4"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">准备离线模型</span></strong></span></h4><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">这个环节我们的主要任务是把模型文件准备好、完成量化，并通过命令行的方式，进行交互式对话验证。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_5"></span><h4 data-cangjie-key="195" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">下载对话语言模型 ChatGLM3-6B</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">为什么选择 ChatGLM3-6B？常年霸榜的开源国产之光。ChatGLM3 一共开源了对话模型 ChatGLM-6B、基础模型 ChatGLM-6B-Base、长文本对话模型 ChatGLM3-6B-32K，对学术研究完全开放，在填写问卷进行登记后亦允许免费商业使用。无论是用来做上手实践还是微调练习，目前看来都是比较好的选择。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">其实最重要的是，看看排行榜上的可选项，我的 MacBook 16G 内存只能带得动 ChatGLM3-6B 量化版本：</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041741" data-ratio="0.37777777777777777" src="https://oscimg.oschina.net/oscnet/08ae148e-39dc-45c8-9196-b121dbef2503.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">ChatGLM3-6B 现在比较方便的下载渠道有 HuggingFace 和 ModelScope，但是很明显能直接下载下来的可能性不大，所以我用家里的旧电脑科学下载后放到私有云 CDN 上，然后再用公司电脑下载，也方便未来随时随地取用，就是要花点小钱。ModelScope 也试过，不能直接下载文件，并且用 git clone 速度也不太理想，遂放弃。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">如果用老一点的版本 ChatGLM2-6B 的话，网上也能找到一些比较好用的第三方镜像站。</span></p><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">HuggingFace:THUDM/chatglm3-6b﻿</span></p></li><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">ModelScope:ZhipuAI/chatglm3-6b（</span><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">地址：https://modelscope.cn/models/ZhipuAI/chatglm3-6b/summary）</span></p></li></ol><section style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><br></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="php"><code><span class="code-snippet_outer">// 从 Git 仓库下载模型文件</span></code><code><span class="code-snippet_outer">// HuggingFace</span></code><code><span class="code-snippet_outer">git lfs install</span></code><code><span class="code-snippet_outer">git clone https://huggingface.co/THUDM/chatglm3-6b</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// ModelScope</span></code><code><span class="code-snippet_outer">git lfs install</span></code><code><span class="code-snippet_outer">git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_6"></span><h4 data-cangjie-key="237" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">下载文本嵌入模型 m3e-base</span></h4></li></ul><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">为什么选择 moka-ai 的 M3E 模型 m3e-base？M3E 向量模型属于小模型，资源使用不高，CPU 也可以运行，使用场景主要是中文，少量英文的情况。用来验证我们的知识库系统足够了</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">官方下载地址：moka-ai/m3e-base，先把所有的模型文件 download 下来，后面使用</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_7"></span><h4 data-cangjie-key="253" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">使用 chatglm.cpp 对 ChatGLM3-6B 进行量化加速</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">当我第一次知道 chatglm.cpp，只能说好人一生平安，chatglm.cpp 的出现拯救了纯 MacBook 党，让我们能在（低性能的）果本上基于 CPU 进行推理，也不会损失过多的精度。（其实损失多少我也不知道，不影响我们正常进行工程部署验证就行）</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">Github Repo: https://github.com/li-plus/chatglm.cpp﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">我使用的 Python 版本：3.11，最好单独准备一个 virtualenv</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041738" data-ratio="0.13240740740740742" src="https://oscimg.oschina.net/oscnet/e1860e0e-5e2f-4eaf-8411-dab67f6a95cd.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">安装依赖：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer">cd /Users/yaolu/AGI/github/chatglm.cpp</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 先初始化 git 仓库</span></code><code><span class="code-snippet_outer">git submodule update --init --recursive</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 构建可执行文件</span></code><code><span class="code-snippet_outer">cmake -B build</span></code><code><span class="code-snippet_outer">cmake --build build -j</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 安装 Python 依赖</span></code><code><span class="code-snippet_outer">pip install .</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">如果发生 No module named 'chatglm_cpp._C' 的错误，把编译出来的文件 _C.cpython-311-darwin.so 放到 chatglm_cpp 目录下。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">对 ChatGLM3-6B 进行 8-bit 量化处理：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="nginx"><code><span class="code-snippet_outer">python ./chatglm_cpp/convert.py -i /Users/yaolu/AGI/huggingface/THUDM/chatglm3-6b -t q8_0 -o chatglm3-ggml-q8.bin</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">如果电脑带不动，还可以尝试 4-bit、5-bit 参数量化，完整参数列表见 chatglm.cpp 的 quantization types</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_8"></span><h4 data-cangjie-key="300" data-cangjie-leaf-block="true" data-type="heading-4" style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">验证模型问答效果</span></h4></li></ul><p style="margin-bottom: 8px;margin-top: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">完成模型量化后，就可以在本地把大模型跑起来了，命令如下：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js"><code><span class="code-snippet_outer">./build/bin/main -m chatglm3-ggml-q8.bin -i</span></code></pre></section><p style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><br></p><p style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;text-align: center;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041739" data-ratio="0.5796296296296296" src="https://oscimg.oschina.net/oscnet/a783a6e0-4e31-4f72-81ca-8f9e37688b7f.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><span id="OSC_h4_9"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">搭建模型 API 服务</span></strong></span></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">我们在这个环节要完成的任务是，按照 ChatGPT 的接口规范、基于 FastAPI 封装 ChatGLM3-6B 的对话和 m3e-base 的嵌入能力；并注册到 One API 接口管理/分发系统中。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_10"></span><h4 data-cangjie-key="325" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">搭建模型 API</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">用 chatglm.cpp 自带的 openai_api.py 魔改了一下，使其支持完成对话和文本 embedding 的两个核心调用：</span></section><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">/v1/chat/completions</span></section></li><li><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">/v1/embeddings</span></section></li></ol><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">代码如下：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer">import asyncio</span></code><code><span class="code-snippet_outer">import logging</span></code><code><span class="code-snippet_outer">import time</span></code><code><span class="code-snippet_outer">from typing import List, Literal, Optional, Union</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">import chatglm_cpp</span></code><code><span class="code-snippet_outer">from fastapi import FastAPI, HTTPException, status, Depends</span></code><code><span class="code-snippet_outer">from fastapi.middleware.cors import CORSMiddleware</span></code><code><span class="code-snippet_outer">from pydantic import BaseModel, Field#, computed_field</span></code><code><span class="code-snippet_outer">#from pydantic_settings import BaseSettings</span></code><code><span class="code-snippet_outer">from sse_starlette.sse import EventSourceResponse</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">from sentence_transformers import SentenceTransformer</span></code><code><span class="code-snippet_outer">from sklearn.preprocessing import PolynomialFeatures</span></code><code><span class="code-snippet_outer">import numpy as np</span></code><code><span class="code-snippet_outer">import tiktoken</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">logging.basicConfig(level=logging.INFO, format=r"%(asctime)s - %(module)s - %(levelname)s - %(message)s")</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class Settings(object):</span></code><code><span class="code-snippet_outer">    model: str = "/Users/yaolu/AGI/github/chatglm.cpp/chatglm3-ggml-q8.bin"</span></code><code><span class="code-snippet_outer">    num_threads: int = 0</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatMessage(BaseModel):</span></code><code><span class="code-snippet_outer">    role: Literal["system", "user", "assistant"]</span></code><code><span class="code-snippet_outer">    content: str</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class DeltaMessage(BaseModel):</span></code><code><span class="code-snippet_outer">    role: Optional[Literal["system", "user", "assistant"]] = None</span></code><code><span class="code-snippet_outer">    content: Optional[str] = None</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionRequest(BaseModel):</span></code><code><span class="code-snippet_outer">    model: str = "default-model"</span></code><code><span class="code-snippet_outer">    messages: List[ChatMessage]</span></code><code><span class="code-snippet_outer">    temperature: float = Field(default=0.95, ge=0.0, le=2.0)</span></code><code><span class="code-snippet_outer">    top_p: float = Field(default=0.7, ge=0.0, le=1.0)</span></code><code><span class="code-snippet_outer">    stream: bool = False</span></code><code><span class="code-snippet_outer">    max_tokens: int = Field(default=2048, ge=0)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    model_config = {</span></code><code><span class="code-snippet_outer">        "json_schema_extra": {"examples": [{"model": "default-model", "messages": [{"role": "user", "content": "你好"}]}]}</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionResponseChoice(BaseModel):</span></code><code><span class="code-snippet_outer">    index: int = 0</span></code><code><span class="code-snippet_outer">    message: ChatMessage</span></code><code><span class="code-snippet_outer">    finish_reason: Literal["stop", "length"] = "stop"</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionResponseStreamChoice(BaseModel):</span></code><code><span class="code-snippet_outer">    index: int = 0</span></code><code><span class="code-snippet_outer">    delta: DeltaMessage</span></code><code><span class="code-snippet_outer">    finish_reason: Optional[Literal["stop", "length"]] = None</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionUsage(BaseModel):</span></code><code><span class="code-snippet_outer">    prompt_tokens: int</span></code><code><span class="code-snippet_outer">    completion_tokens: int</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    #@computed_field</span></code><code><span class="code-snippet_outer">    @property</span></code><code><span class="code-snippet_outer">    def total_tokens(self) -&gt; int:</span></code><code><span class="code-snippet_outer">        return self.prompt_tokens + self.completion_tokens</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionResponse(BaseModel):</span></code><code><span class="code-snippet_outer">    id: str = "chatcmpl"</span></code><code><span class="code-snippet_outer">    model: str = "default-model"</span></code><code><span class="code-snippet_outer">    object: Literal["chat.completion", "chat.completion.chunk"]</span></code><code><span class="code-snippet_outer">    created: int = Field(default_factory=lambda: int(time.time()))</span></code><code><span class="code-snippet_outer">    choices: Union[List[ChatCompletionResponseChoice], List[ChatCompletionResponseStreamChoice]]</span></code><code><span class="code-snippet_outer">    usage: Optional[ChatCompletionUsage] = None</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    model_config = {</span></code><code><span class="code-snippet_outer">        "json_schema_extra": {</span></code><code><span class="code-snippet_outer">            "examples": [</span></code><code><span class="code-snippet_outer">                {</span></code><code><span class="code-snippet_outer">                    "id": "chatcmpl",</span></code><code><span class="code-snippet_outer">                    "model": "default-model",</span></code><code><span class="code-snippet_outer">                    "object": "chat.completion",</span></code><code><span class="code-snippet_outer">                    "created": 1691166146,</span></code><code><span class="code-snippet_outer">                    "choices": [</span></code><code><span class="code-snippet_outer">                        {</span></code><code><span class="code-snippet_outer">                            "index": 0,</span></code><code><span class="code-snippet_outer">                            "message": {"role": "assistant", "content": "你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。"},</span></code><code><span class="code-snippet_outer">                            "finish_reason": "stop",</span></code><code><span class="code-snippet_outer">                        }</span></code><code><span class="code-snippet_outer">                    ],</span></code><code><span class="code-snippet_outer">                    "usage": {"prompt_tokens": 17, "completion_tokens": 29, "total_tokens": 46},</span></code><code><span class="code-snippet_outer">                }</span></code><code><span class="code-snippet_outer">            ]</span></code><code><span class="code-snippet_outer">        }</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">settings = Settings()</span></code><code><span class="code-snippet_outer">app = FastAPI()</span></code><code><span class="code-snippet_outer">app.add_middleware(</span></code><code><span class="code-snippet_outer">    CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]</span></code><code><span class="code-snippet_outer">)</span></code><code><span class="code-snippet_outer">pipeline = chatglm_cpp.Pipeline(settings.model)</span></code><code><span class="code-snippet_outer">lock = asyncio.Lock()</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">embeddings_model = SentenceTransformer('/Users/yaolu/AGI/huggingface/moka-ai/m3e-base', device='cpu')</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">def stream_chat(history, body):</span></code><code><span class="code-snippet_outer">    yield ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">        object="chat.completion.chunk",</span></code><code><span class="code-snippet_outer">        choices=[ChatCompletionResponseStreamChoice(delta=DeltaMessage(role="assistant"))],</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    for piece in pipeline.chat(</span></code><code><span class="code-snippet_outer">        history,</span></code><code><span class="code-snippet_outer">        max_length=body.max_tokens,</span></code><code><span class="code-snippet_outer">        do_sample=body.temperature &gt; 0,</span></code><code><span class="code-snippet_outer">        top_p=body.top_p,</span></code><code><span class="code-snippet_outer">        temperature=body.temperature,</span></code><code><span class="code-snippet_outer">        num_threads=settings.num_threads,</span></code><code><span class="code-snippet_outer">        stream=True,</span></code><code><span class="code-snippet_outer">    ):</span></code><code><span class="code-snippet_outer">        yield ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">            object="chat.completion.chunk",</span></code><code><span class="code-snippet_outer">            choices=[ChatCompletionResponseStreamChoice(delta=DeltaMessage(content=piece))],</span></code><code><span class="code-snippet_outer">        )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    yield ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">        object="chat.completion.chunk",</span></code><code><span class="code-snippet_outer">        choices=[ChatCompletionResponseStreamChoice(delta=DeltaMessage(), finish_reason="stop")],</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">async def stream_chat_event_publisher(history, body):</span></code><code><span class="code-snippet_outer">    output = ""</span></code><code><span class="code-snippet_outer">    try:</span></code><code><span class="code-snippet_outer">        async with lock:</span></code><code><span class="code-snippet_outer">            for chunk in stream_chat(history, body):</span></code><code><span class="code-snippet_outer">                await asyncio.sleep(0)  # yield control back to event loop for cancellation check</span></code><code><span class="code-snippet_outer">                output += chunk.choices[0].delta.content or ""</span></code><code><span class="code-snippet_outer">                yield chunk.model_dump_json(exclude_unset=True)</span></code><code><span class="code-snippet_outer">        logging.info(f'prompt: "{history[-1]}", stream response: "{output}"')</span></code><code><span class="code-snippet_outer">    except asyncio.CancelledError as e:</span></code><code><span class="code-snippet_outer">        logging.info(f'prompt: "{history[-1]}", stream response (partial): "{output}"')</span></code><code><span class="code-snippet_outer">        raise e</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">@app.post("/v1/chat/completions")</span></code><code><span class="code-snippet_outer">async def create_chat_completion(body: ChatCompletionRequest) -&gt; ChatCompletionResponse:</span></code><code><span class="code-snippet_outer">    # ignore system messages</span></code><code><span class="code-snippet_outer">    history = [msg.content for msg in body.messages if msg.role != "system"]</span></code><code><span class="code-snippet_outer">    if len(history) % 2 != 1:</span></code><code><span class="code-snippet_outer">        raise HTTPException(status.HTTP_400_BAD_REQUEST, "invalid history size")</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    if body.stream:</span></code><code><span class="code-snippet_outer">        generator = stream_chat_event_publisher(history, body)</span></code><code><span class="code-snippet_outer">        return EventSourceResponse(generator)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    max_context_length = 512</span></code><code><span class="code-snippet_outer">    output = pipeline.chat(</span></code><code><span class="code-snippet_outer">        history=history,</span></code><code><span class="code-snippet_outer">        max_length=body.max_tokens,</span></code><code><span class="code-snippet_outer">        max_context_length=max_context_length,</span></code><code><span class="code-snippet_outer">        do_sample=body.temperature &gt; 0,</span></code><code><span class="code-snippet_outer">        top_p=body.top_p,</span></code><code><span class="code-snippet_outer">        temperature=body.temperature,</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer">    logging.info(f'prompt: "{history[-1]}", sync response: "{output}"')</span></code><code><span class="code-snippet_outer">    prompt_tokens = len(pipeline.tokenizer.encode_history(history, max_context_length))</span></code><code><span class="code-snippet_outer">    completion_tokens = len(pipeline.tokenizer.encode(output, body.max_tokens))</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    return ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">        object="chat.completion",</span></code><code><span class="code-snippet_outer">        choices=[ChatCompletionResponseChoice(message=ChatMessage(role="assistant", content=output))],</span></code><code><span class="code-snippet_outer">        usage=ChatCompletionUsage(prompt_tokens=prompt_tokens, completion_tokens=completion_tokens),</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class EmbeddingRequest(BaseModel):</span></code><code><span class="code-snippet_outer">    input: List[str]</span></code><code><span class="code-snippet_outer">    model: str</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class EmbeddingResponse(BaseModel):</span></code><code><span class="code-snippet_outer">    data: list</span></code><code><span class="code-snippet_outer">    model: str</span></code><code><span class="code-snippet_outer">    object: str</span></code><code><span class="code-snippet_outer">    usage: dict</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">def num_tokens_from_string(string: str) -&gt; int:</span></code><code><span class="code-snippet_outer">    """Returns the number of tokens in a text string."""</span></code><code><span class="code-snippet_outer">    encoding = tiktoken.get_encoding('cl100k_base')</span></code><code><span class="code-snippet_outer">    num_tokens = len(encoding.encode(string))</span></code><code><span class="code-snippet_outer">    return num_tokens</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">def expand_features(embedding, target_length):</span></code><code><span class="code-snippet_outer">    poly = PolynomialFeatures(degree=2)</span></code><code><span class="code-snippet_outer">    expanded_embedding = poly.fit_transform(embedding.reshape(1, -1))</span></code><code><span class="code-snippet_outer">    expanded_embedding = expanded_embedding.flatten()</span></code><code><span class="code-snippet_outer">    if len(expanded_embedding) &gt; target_length:</span></code><code><span class="code-snippet_outer">        # 如果扩展后的特征超过目标长度，可以通过截断或其他方法来减少维度</span></code><code><span class="code-snippet_outer">        expanded_embedding = expanded_embedding[:target_length]</span></code><code><span class="code-snippet_outer">    elif len(expanded_embedding) &lt; target_length:</span></code><code><span class="code-snippet_outer">        # 如果扩展后的特征少于目标长度，可以通过填充或其他方法来增加维度</span></code><code><span class="code-snippet_outer">        expanded_embedding = np.pad(expanded_embedding, (0, target_length - len(expanded_embedding)))</span></code><code><span class="code-snippet_outer">    return expanded_embedding</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">@app.post("/v1/embeddings", response_model=EmbeddingResponse)</span></code><code><span class="code-snippet_outer">async def get_embeddings(request: EmbeddingRequest):</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # 计算嵌入向量和 tokens 数量 </span></code><code><span class="code-snippet_outer">    embeddings = [embeddings_model.encode(text) for text in request.input]</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # 如果嵌入向量的维度不为 1536，则使用插值法扩展至 1536 维度 </span></code><code><span class="code-snippet_outer">    embeddings = [expand_features(embedding, 1536) if len(embedding) &lt; 1536 else embedding for embedding in embeddings]</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # Min-Max normalization</span></code><code><span class="code-snippet_outer">    embeddings = [embedding / np.linalg.norm(embedding) for embedding in embeddings]</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # 将 numpy 数组转换为列表</span></code><code><span class="code-snippet_outer">    embeddings = [embedding.tolist() for embedding in embeddings]</span></code><code><span class="code-snippet_outer">    prompt_tokens = sum(len(text.split()) for text in request.input)</span></code><code><span class="code-snippet_outer">    total_tokens = sum(num_tokens_from_string(text) for text in request.input)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    response = {</span></code><code><span class="code-snippet_outer">        "data": [</span></code><code><span class="code-snippet_outer">            {</span></code><code><span class="code-snippet_outer">                "embedding": embedding,</span></code><code><span class="code-snippet_outer">                "index": index,</span></code><code><span class="code-snippet_outer">                "object": "embedding"</span></code><code><span class="code-snippet_outer">            } for index, embedding in enumerate(embeddings)</span></code><code><span class="code-snippet_outer">        ],</span></code><code><span class="code-snippet_outer">        "model": request.model,</span></code><code><span class="code-snippet_outer">        "object": "list",</span></code><code><span class="code-snippet_outer">        "usage": {</span></code><code><span class="code-snippet_outer">            "prompt_tokens": prompt_tokens,</span></code><code><span class="code-snippet_outer">            "total_tokens": total_tokens,</span></code><code><span class="code-snippet_outer">        }</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    return response</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ModelCard(BaseModel):</span></code><code><span class="code-snippet_outer">    id: str</span></code><code><span class="code-snippet_outer">    object: Literal["model"] = "model"</span></code><code><span class="code-snippet_outer">    owned_by: str = "owner"</span></code><code><span class="code-snippet_outer">    permission: List = []</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ModelList(BaseModel):</span></code><code><span class="code-snippet_outer">    object: Literal["list"] = "list"</span></code><code><span class="code-snippet_outer">    data: List[ModelCard] = []</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    model_config = {</span></code><code><span class="code-snippet_outer">        "json_schema_extra": {</span></code><code><span class="code-snippet_outer">            "examples": [</span></code><code><span class="code-snippet_outer">                {</span></code><code><span class="code-snippet_outer">                    "object": "list",</span></code><code><span class="code-snippet_outer">                    "data": [{"id": "gpt-3.5-turbo", "object": "model", "owned_by": "owner", "permission": []}],</span></code><code><span class="code-snippet_outer">                }</span></code><code><span class="code-snippet_outer">            ]</span></code><code><span class="code-snippet_outer">        }</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">@app.get("/v1/models")</span></code><code><span class="code-snippet_outer">async def list_models() -&gt; ModelList:</span></code><code><span class="code-snippet_outer">    return ModelList(data=[ModelCard(id="gpt-3.5-turbo")])</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">让他跑起来的命令，跑在 8000 端口下：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="css"><code><span class="code-snippet_outer">uvicorn chatglm_cpp.openai_api:app --host 127.0.0.1 --port 8000</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">运行该程序所需的 Python 依赖项：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="ini"><code><span class="code-snippet_outer">accelerate==0.24.1</span></code><code><span class="code-snippet_outer">aiofiles==23.2.1</span></code><code><span class="code-snippet_outer">aiohttp==3.8.6</span></code><code><span class="code-snippet_outer">aiosignal==1.3.1</span></code><code><span class="code-snippet_outer">altair==5.1.2</span></code><code><span class="code-snippet_outer">annotated-types==0.6.0</span></code><code><span class="code-snippet_outer">anyio==3.7.1</span></code><code><span class="code-snippet_outer">async-timeout==4.0.3</span></code><code><span class="code-snippet_outer">attrs==23.1.0</span></code><code><span class="code-snippet_outer">blinker==1.7.0</span></code><code><span class="code-snippet_outer">cachetools==5.3.2</span></code><code><span class="code-snippet_outer">certifi==2023.7.22</span></code><code><span class="code-snippet_outer">charset-normalizer==3.3.2</span></code><code><span class="code-snippet_outer">click==8.1.7</span></code><code><span class="code-snippet_outer">contourpy==1.2.0</span></code><code><span class="code-snippet_outer">cpm-kernels==1.0.11</span></code><code><span class="code-snippet_outer">cycler==0.12.1</span></code><code><span class="code-snippet_outer">fastapi==0.103.2</span></code><code><span class="code-snippet_outer">ffmpy==0.3.1</span></code><code><span class="code-snippet_outer">filelock==3.13.1</span></code><code><span class="code-snippet_outer">fonttools==4.44.0</span></code><code><span class="code-snippet_outer">frozenlist==1.4.0</span></code><code><span class="code-snippet_outer">fsspec==2023.10.0</span></code><code><span class="code-snippet_outer">gitdb==4.0.11</span></code><code><span class="code-snippet_outer">GitPython==3.1.40</span></code><code><span class="code-snippet_outer">gradio==3.50.2</span></code><code><span class="code-snippet_outer">gradio_client==0.6.1</span></code><code><span class="code-snippet_outer">h11==0.14.0</span></code><code><span class="code-snippet_outer">httpcore==1.0.2</span></code><code><span class="code-snippet_outer">httpx==0.25.1</span></code><code><span class="code-snippet_outer">huggingface-hub==0.19.1</span></code><code><span class="code-snippet_outer">idna==3.4</span></code><code><span class="code-snippet_outer">importlib-metadata==6.8.0</span></code><code><span class="code-snippet_outer">importlib-resources==6.1.1</span></code><code><span class="code-snippet_outer">Jinja2==3.1.2</span></code><code><span class="code-snippet_outer">joblib==1.3.2</span></code><code><span class="code-snippet_outer">jsonschema==4.19.2</span></code><code><span class="code-snippet_outer">jsonschema-specifications==2023.7.1</span></code><code><span class="code-snippet_outer">kiwisolver==1.4.5</span></code><code><span class="code-snippet_outer">latex2mathml==3.76.0</span></code><code><span class="code-snippet_outer">linkify-it-py==2.0.2</span></code><code><span class="code-snippet_outer">Markdown==3.5.1</span></code><code><span class="code-snippet_outer">markdown-it-py==2.2.0</span></code><code><span class="code-snippet_outer">MarkupSafe==2.1.3</span></code><code><span class="code-snippet_outer">matplotlib==3.8.1</span></code><code><span class="code-snippet_outer">mdit-py-plugins==0.3.3</span></code><code><span class="code-snippet_outer">mdtex2html==1.2.0</span></code><code><span class="code-snippet_outer">mdurl==0.1.2</span></code><code><span class="code-snippet_outer">mpmath==1.3.0</span></code><code><span class="code-snippet_outer">multidict==6.0.4</span></code><code><span class="code-snippet_outer">networkx==3.2.1</span></code><code><span class="code-snippet_outer">nltk==3.8.1</span></code><code><span class="code-snippet_outer">numpy==1.26.2</span></code><code><span class="code-snippet_outer">orjson==3.9.10</span></code><code><span class="code-snippet_outer">packaging==23.2</span></code><code><span class="code-snippet_outer">pandas==2.1.3</span></code><code><span class="code-snippet_outer">Pillow==10.1.0</span></code><code><span class="code-snippet_outer">protobuf==4.25.0</span></code><code><span class="code-snippet_outer">psutil==5.9.6</span></code><code><span class="code-snippet_outer">pyarrow==14.0.1</span></code><code><span class="code-snippet_outer">pydantic==2.1.1</span></code><code><span class="code-snippet_outer">pydantic_core==2.4.0</span></code><code><span class="code-snippet_outer">pydeck==0.8.1b0</span></code><code><span class="code-snippet_outer">pydub==0.25.1</span></code><code><span class="code-snippet_outer">Pygments==2.16.1</span></code><code><span class="code-snippet_outer">pyparsing==3.1.1</span></code><code><span class="code-snippet_outer">python-dateutil==2.8.2</span></code><code><span class="code-snippet_outer">python-multipart==0.0.6</span></code><code><span class="code-snippet_outer">pytz==2023.3.post1</span></code><code><span class="code-snippet_outer">PyYAML==6.0.1</span></code><code><span class="code-snippet_outer">referencing==0.30.2</span></code><code><span class="code-snippet_outer">regex==2023.10.3</span></code><code><span class="code-snippet_outer">requests==2.31.0</span></code><code><span class="code-snippet_outer">rich==13.6.0</span></code><code><span class="code-snippet_outer">rpds-py==0.12.0</span></code><code><span class="code-snippet_outer">safetensors==0.4.0</span></code><code><span class="code-snippet_outer">scikit-learn==1.3.2</span></code><code><span class="code-snippet_outer">scipy==1.11.3</span></code><code><span class="code-snippet_outer">semantic-version==2.10.0</span></code><code><span class="code-snippet_outer">sentence-transformers==2.2.2</span></code><code><span class="code-snippet_outer">sentencepiece==0.1.99</span></code><code><span class="code-snippet_outer">six==1.16.0</span></code><code><span class="code-snippet_outer">smmap==5.0.1</span></code><code><span class="code-snippet_outer">sniffio==1.3.0</span></code><code><span class="code-snippet_outer">sse-starlette==1.6.5</span></code><code><span class="code-snippet_outer">starlette==0.27.0</span></code><code><span class="code-snippet_outer">streamlit==1.28.2</span></code><code><span class="code-snippet_outer">sympy==1.12</span></code><code><span class="code-snippet_outer">tabulate==0.9.0</span></code><code><span class="code-snippet_outer">tenacity==8.2.3</span></code><code><span class="code-snippet_outer">threadpoolctl==3.2.0</span></code><code><span class="code-snippet_outer">tiktoken==0.5.1</span></code><code><span class="code-snippet_outer">tokenizers==0.13.3</span></code><code><span class="code-snippet_outer">toml==0.10.2</span></code><code><span class="code-snippet_outer">toolz==0.12.0</span></code><code><span class="code-snippet_outer">torch==2.1.0</span></code><code><span class="code-snippet_outer">torchvision==0.16.0</span></code><code><span class="code-snippet_outer">tornado==6.3.3</span></code><code><span class="code-snippet_outer">tqdm==4.66.1</span></code><code><span class="code-snippet_outer">transformers==4.30.2</span></code><code><span class="code-snippet_outer">typing_extensions==4.6.1</span></code><code><span class="code-snippet_outer">tzdata==2023.3</span></code><code><span class="code-snippet_outer">tzlocal==5.2</span></code><code><span class="code-snippet_outer">uc-micro-py==1.0.2</span></code><code><span class="code-snippet_outer">urllib3==2.1.0</span></code><code><span class="code-snippet_outer">uvicorn==0.24.0.post1</span></code><code><span class="code-snippet_outer">validators==0.22.0</span></code><code><span class="code-snippet_outer">websockets==11.0.3</span></code><code><span class="code-snippet_outer">yarl==1.9.2</span></code><code><span class="code-snippet_outer">zipp==3.17.0</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_11"></span><h4 data-cangjie-key="358" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">搭建 One API 接口管理/分发系统</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">﻿One API 是一套兼容多种 LLM 接口规范的 API 路由方案，支持限额和计费管理，通过标准的 OpenAI API 格式访问所有的大模型，开箱即用，其多模型渠道接入、多用户管理、费用管理、额度管理、以及集群化部署支持等功能，对商用场景都很友好。项目使用 MIT 协议进行开源。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">One API 基于 Go 和 Node.js 开发，搭建之前准备好，我的版本是：go1.21.4、Node.js v20.9.0，构建命令如下：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer">git clone https://github.com/songquanpeng/one-api.git</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 构建前端</span></code><code><span class="code-snippet_outer">cd one-api/web</span></code><code><span class="code-snippet_outer">npm install</span></code><code><span class="code-snippet_outer">npm run build</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 构建后端</span></code><code><span class="code-snippet_outer">cd ..</span></code><code><span class="code-snippet_outer">go mod download</span></code><code><span class="code-snippet_outer">go build -ldflags "-s -w" -o one-api</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">One API 里面预置了很多市面上的可用模型接口，好处是可以直接使用无需配置，缺点是没有添加自定义（本地）接口的能力。由于我们是自己搭建的 LLM 和 embedding 服务，需要修改其源代码，增加 ChatGLM3 和 m3e-base 的选项。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">改动涉及两个文件，分别是 common/model-ratio.go 和 controller/model.go，改动内容如下图：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041746" data-ratio="0.5166666666666667" src="https://oscimg.oschina.net/oscnet/b980c07e-c638-4726-8149-aa6f42f3df6b.jpg" data-type="other" data-w="1080" style="width: 578px;height: auto;" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041745" data-ratio="0.4564814814814815" src="https://oscimg.oschina.net/oscnet/bc153ea4-f8c8-4029-bef4-d61d6562cb64.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;">注意，改完文件后记得重新编译可执行文件。本地的元数据存储我使用了 MySQL，编译+启动命令是：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="bash"><code><span class="code-snippet_outer">go build -ldflags "-s -w" -o one-api</span></code><code><span class="code-snippet_outer">export SQL_DSN=oneapi:oneapi@tcp(localhost:3306)/oneapi &amp;&amp; ./one-api --port 3001 --log-dir ./log</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">初始登录进去，创建一个新令牌用于权限管控和计费：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041742" data-ratio="0.4074074074074074" src="https://oscimg.oschina.net/oscnet/633c7cae-c8f2-479a-abdd-7ea0b14593d1.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">令牌可以从这里复制，下面有用：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="letter-spacing: 1px;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041743" data-ratio="0.2824074074074074" src="https://oscimg.oschina.net/oscnet/22e2145c-3437-4ad8-8052-d99cf2bed6e6.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">One API 的渠道管理界面如下图，我已经配置了俩渠道，一个 chat 渠道，一个 embedding 渠道：</span></p><p><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041744" data-ratio="0.4546296296296296" src="https://oscimg.oschina.net/oscnet/f988f5ad-ffb3-4568-9e4e-12f80431bad8.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">具体的配置值如下图，名称写实际的模型名 ChatGLM3，模型选刚才手动添加上去的 ChatGLM3：</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041751" data-ratio="0.7148148148148148" src="https://oscimg.oschina.net/oscnet/a3ae8bc9-2ce8-466a-8e32-2327dd193a66.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041747" data-ratio="0.7185185185185186" src="https://oscimg.oschina.net/oscnet/af7b338e-56ca-42e3-873a-f194005c09cb.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">配置完后可以在列表页点一下测试验证，连通无问题就行，但现在似乎一测就会把模型 API 服务弄挂，不过没关系，不影响后面验证。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><span id="OSC_h4_12"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">搭建知识库应用</span></strong></span></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">在这个环节里，我们采用类似 Dify.ai （地址：https://dify.ai/）的国产化开源 FastGPT 方案搭建属于自己的本地知识库应用平台。FastGPT 是一个基于 LLM 大语言模型的知识库问答系统，提供开箱即用的数据处理、模型调用等能力。同时可以通过 Flow 可视化进行工作流编排，从而实现复杂的问答场景。FastGPT 遵循 Apache License 2.0 开源协议，我们可以 Fork 之后进行二次开发和发布。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 的核心流程图如下：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041748" data-ratio="0.525" src="https://oscimg.oschina.net/oscnet/dbc410c8-6a51-451c-a9d8-7c05661240c8.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">从 FastGPT 官网得知，这套开源系统基于以下几个基本概念进行知识库检索：</span></p><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">向量：将人类直观的语言（文字、图片、视频等）转成计算机可识别的语言（数组）。</span></p></li><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">向量相似度：两个向量之间可以进行计算，得到一个相似度，即代表：两个语言相似的程度。</span></p></li><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">语言大模型的一些特点：上下文理解、总结和推理。</span></p></li></ol><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">结合上述 3 个概念，便有了 「向量搜索 + 大模型 = 知识库问答」 的公式。下图是 FastGPT V3 中知识库问答功能的完整逻辑：</span></p><section style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041749" data-ratio="0.46296296296296297" src="https://oscimg.oschina.net/oscnet/1bed1c79-1bae-44a9-897a-ac6100c37f67.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 的向量存储方案是 PostgreSQL+pgvector，其他数据放在 MongoDB 里面，因此我们先把这两项依赖搞定。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_13"></span><h4 data-cangjie-key="538" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">安装 MongoDB</span></h4></li></ul><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">MacBook 安装 MongoDB 很简单，如果没有特别的安全诉求，可以先不用设置用户名密码</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer">brew install mongodb-community</span></code><code><span class="code-snippet_outer">brew services start mongodb-community</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 基于 MongoDB 存储知识库索引、会话内容、工作流等管理数据：</span></section><section style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041750" data-ratio="1.3333333333333333" src="https://oscimg.oschina.net/oscnet/72381400-16aa-4e0b-b636-70faee6c5c51.jpg" data-type="other" data-w="450" referrerpolicy="no-referrer"></span></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_14"></span><h4 data-cangjie-key="560" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">安装 PostgreSQL &amp; pgvector</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 采用了 RAG 中的 Embedding 方案构建知识库，PostgresSQL 的 PG Vector 插件作为向量检索器，索引为 HNSW。PostgresSQL 仅用于向量检索，MongoDB 用于其他数据的存取。另外也可以采用第三方模型的 Embedding API，比如 ChatGPT embedding，不过为了实现完整的本地化部署，就没有用外部服务。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">我们可以从 PostgreSQL 的官网下载 PostgreSQL 安装包：https://www.postgresql.org/download/macosx/﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">从源码安装 pgvector：https://github.com/pgvector/pgvector</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="typescript"><code><span class="code-snippet_outer">// 安装 pgvector 前指定 PostgreSQL 位置</span></code><code><span class="code-snippet_outer">export PG_CONFIG=/Library/PostgreSQL/16/bin/pg_config</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// 如果 pgvector 认错了 MacOS SDK 的位置，还得帮他软链一个</span></code><code><span class="code-snippet_outer">sudo ln -s /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk /Library/Developer/CommandLineTools/SDKs/MacOSX11.sdk</span></code><code><span class="code-snippet_outer">// 或者用这个命令</span></code><code><span class="code-snippet_outer">export SDKROOT=$(xcrun --sdk macosx --show-sdk-path)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// 源码编译安装 </span></code><code><span class="code-snippet_outer">make</span></code><code><span class="code-snippet_outer">make install # may need sudo</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// 确保插件已安装到 PostgreSQL 目录下</span></code><code><span class="code-snippet_outer">cd /Library/PostgreSQL/16/share/postgresql/extension/</span></code><code><span class="code-snippet_outer">ls | grep vector</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">完成以上步骤后，打开 PostgreSQL 控制枱，随便建立一个连接，运行下面的查询：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer">CREATE EXTENSION vector;</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">SELECT * FROM pg_extension WHERE extname = 'vector';</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">如果能出现下图结果，说明 pgvector 已经安装成功：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041753" data-ratio="0.44166666666666665" src="https://oscimg.oschina.net/oscnet/dac102ea-3331-4cba-9e81-a7bbf955d8ea.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_15"></span><h4 data-cangjie-key="605" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">搭建 FastGPT 知识库问答系统</span></h4></li></ul><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">好，我们的主角终于上场了，下面有请 FastGPT，安装指南见：https://doc.fastgpt.in/docs/development/intro/﻿</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第一步，按照里面的步骤，配置 .env.local 文件内容，指定 One API、MongoDB 和 PostgreSQL 的访问地址：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041755" data-ratio="0.3675925925925926" src="https://oscimg.oschina.net/oscnet/ad8bc609-8cdc-4490-9d41-6d0cf05d1086.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">这里的 CHAT_API_KEY 填入上面 OneAPI 创建的令牌</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第二步，在 config.local.json 里面注册对话模型和向量嵌入模型，注意这里的 model 值要和 One API 里配置的保持一致：</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041752" data-ratio="0.9101123595505618" src="https://oscimg.oschina.net/oscnet/f5654367-e043-4a33-af56-6fa29b073fd5.jpg" data-type="other" data-w="534" referrerpolicy="no-referrer"></span></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041754" data-ratio="0.5521885521885522" src="https://oscimg.oschina.net/oscnet/cb497e99-311a-46eb-b6fe-bbbf6a4c9531.jpg" data-type="other" data-w="594" style="width: 529px;height: 292px;" referrerpolicy="no-referrer"></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第三步，安装 Node.js 依赖并以开发模式启动：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer"># 代码根目录下执行，会安装根 package、projects 和 packages 内所有依赖</span></code><code><span class="code-snippet_outer">pnpm i</span></code><code><span class="code-snippet_outer"># 切换到应用目录</span></code><code><span class="code-snippet_outer">cd projects/app</span></code><code><span class="code-snippet_outer"># 开发模式运行</span></code><code><span class="code-snippet_outer">pnpm dev</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第四步，访问本地 FastGPT 地址 http://localhost:3000/，如果能顺利登录，则搭建成功。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_16"></span><h4 data-cangjie-key="673" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">验证模型对话能力</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">创建一个应用：</span></section><p style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041756" data-ratio="0.7851851851851852" src="https://oscimg.oschina.net/oscnet/4a48d9ed-303b-4116-ad64-db2e3c14ab62.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">应用创建完成，进入对话界面，注意 AI 模型选择我们在 One API 里配置的 ChatGLM3。试着问他两个问题，可以看到推理速度还是很快的，分别是 5.83s、7.52s：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041759" data-ratio="0.6212962962962963" src="https://oscimg.oschina.net/oscnet/e9a9fe0b-8101-498c-a692-7f17f7d0d35c.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-size: 15px;">点开单条对话响应，详细的对话参数（消耗 token、响应时长、计费信息）清晰可见：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="letter-spacing: 1px;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041758" data-ratio="1.3190184049079754" src="https://oscimg.oschina.net/oscnet/c1f6a537-1bcf-43e7-b191-0339eba66711.jpg" data-type="other" data-w="978" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-size: 15px;">查看 MacBook 上的 ChatGLM3 推理资源占用情况，占用了 3.78GB 内存</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="letter-spacing: 1px;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041760" data-ratio="0.6240740740740741" src="https://oscimg.oschina.net/oscnet/e9008ab1-d693-4941-bd75-cef91cbe81d1.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041757" data-ratio="0.328125" data-s="300,640" src="https://oscimg.oschina.net/oscnet/0fd3c7b5-94e1-4236-9399-af4ec7167e22.png" data-type="png" data-w="256" style="outline: 0px;letter-spacing: 0.544px;font-size: 16px;visibility: visible !important;width: 122px !important;" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;font-size: 18px;color: rgb(0, 17, 255);">知识库问答实战</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><span id="OSC_h4_17"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">准备知识库语料</span></strong></span></h4><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在有知识库使用诉求的场景，我们一般都积累了比较多的私有知识数据，比如：语雀文档、钉钉文档、PDF、Office 文件等，视知识识图的建设标准，需要将它们一一结构化整理。数据的梳理、清洗、结构化是一项繁杂而重要的工作，但也有比较成熟的办法和工具，在此不再赘述。</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></p><span id="OSC_h4_18"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">导入知识库数据</span></strong></span></h4><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 提供了很多种原始数据导入的办法，并且为了更好地和企业系统集成，FastGPT 支持通过 API 的方式地二次开发导入能力，支持和已有知识管理系统更好地自动化集成。常见的导入方法有：</span></section><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">导入数据方案 1 - 直接分段导入：直接分段会利用句子分词器对文本进行一定长度拆分，可以理解为原始文档 Chunk。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">导入数据方案 2 - QA 导入：导入时会调用大模型对分段进行学习，然后直接生成问题-答案。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">导入数据方案 3 - 手动录入：手动录入问题和答案。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">导入数据方案 4 - CSV 录入：批量快速录入问题答案对。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">导入数据方案 5 - API 导入，</span><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">详见：OpenAPI 接口文档（地址：https://doc.fastgpt.in/docs/development/openapi/#%E7%9F%A5%E8%AF%86%E5%BA%93%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE）</span><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿</span></section></li></ol><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">﻿</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">我们先简单地录入几个问题和答案，然后后面快速验证 RAG 效果。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">新建一个知识库，注意，索引模型一旦选择不可更改。这里我们选择刚部署好的 m3e-base</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041761" data-ratio="0.769620253164557" src="https://oscimg.oschina.net/oscnet/d357e075-29d4-4b82-8032-48ddf63a806a.jpg" data-type="other" data-w="790" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">进入知识库初始界面，已经默认有了一个「手动录入」文件夹，我们在这里录入几条测试问答</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041762" data-ratio="0.387037037037037" src="https://oscimg.oschina.net/oscnet/8812cf81-0f6c-4d49-9e3c-900ff61c2b4b.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">录入内容分两种类型，其中：被搜索的内容指将被向量化的部分，通常是问题，或者精炼扼要的描述，需要准确填写</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041763" data-ratio="0.33425925925925926" src="https://oscimg.oschina.net/oscnet/6d02fcef-1034-404e-8fe3-6269dece3ada.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_19"></span><h4 data-cangjie-key="820" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">验证知识库问答效果</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">重新打开应用，关联刚才创建好的知识库（注意这里一定要保证才会生效），问他一个简单的问题，回答的质量看起来还可以。</span></section><blockquote style="box-sizing: inherit;margin-top: 0px;margin-bottom: 0px;margin-left: 2px;padding-top: 0px;padding-left: 11px;opacity: 0.5;border-left-width: 4px;border-left-color: rgb(217, 219, 221);color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;font-size: 14.6667px;letter-spacing: normal;text-align: start;white-space: pre-wrap;background-color: rgb(255, 255, 255);"><p style="text-align: justify;"><span style="box-sizing: inherit;font-size: 15px;">问：简单说一下商家共振模型是个啥呗？</span></p></blockquote><blockquote style="box-sizing: inherit;margin-top: 0px;margin-bottom: 0px;margin-left: 2px;padding-top: 0px;padding-left: 11px;opacity: 0.5;border-left-width: 4px;border-left-color: rgb(217, 219, 221);color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;font-size: 14.6667px;letter-spacing: normal;text-align: start;white-space: pre-wrap;background-color: rgb(255, 255, 255);"><p style="text-align: justify;"><span style="box-sizing: inherit;font-size: 15px;">答：商家共振模型是一种商业策略和运营模式，旨在促进商家和平台之间的合作关系，同时提高用户的粘性和平台的影响力。这个模式通过激励商家在站内和站外进行投放活动，帮助商家获得更多的流量和销售机会，从而促进商家的生意增长。同时，这个模式也能够扩大平台的规模和影响力，增加商家对平台的依赖性和忠诚度。总的来说，商家共振模型是一种有效的商业策略和运营模式，对于猫超等平台来说是一个不错的选择。</span></p></blockquote><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041764" data-ratio="0.6083333333333333" src="https://oscimg.oschina.net/oscnet/ad7951a6-f135-449a-8cc7-0a6081e1a501.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;">点击答案中的「1 条引用」，还可以看到答案的出处来源：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041765" data-ratio="0.6555555555555556" src="https://oscimg.oschina.net/oscnet/af4bb324-f2ed-432d-8dd3-c8c14d6ac63a.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;">至此，我们就完成了一个简单的知识库构建和应用的过程，也验证了整套本地知识库方案的可行性。</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;">﻿</span></p><section style="margin-right: 0cm;margin-bottom: 0px;margin-left: 0cm;outline: 0px;text-wrap: wrap;background-color: rgb(255, 255, 255);font-size: 11pt;font-family: DengXian;color: rgb(0, 0, 0);letter-spacing: normal;text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041766" data-ratio="0.328125" data-s="300,640" data-type="png" data-w="256" src="https://oscimg.oschina.net/oscnet/4454b7bc-70eb-48c3-afc5-445ce122d5f1.png" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 133px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;font-size: 18px;color: rgb(0, 17, 255);">未来展望</span></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">串通了整个知识库应用流程，我们完成了从 0 到 1 的起步。虽然整体应用架构是按实际商用标准来搭建的，但要想使用效果也达到工业级别的标准，还有很多工作值得进一步探索，包括但不限于：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1️⃣ 大模型应用层面：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1、更好的文档 Chunk、Embedding、多路加权平均搜索召回方案，提升 RAG 整体效能</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2、更好的 Prompt Engineering，充分挖掘 LLM 的潜力</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3、工作流编排、CoT、Agent，满足实际的企业应用需求</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2️⃣ 稳定性层面：如果达到商用级别，需要更高配置的软硬件环境</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3️⃣ 落地价值层面：从解决身边的问题开始，解决真金白银的商业问题</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">希望本文能给每位计划自己搭建大模型知识库应用的工程师一点参考，动手跑通一个程序的乐趣是无穷的，更多的实操作经验分享，我们在评论区交流。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041767" data-ratio="0.328125" data-s="300,640" src="https://oscimg.oschina.net/oscnet/1e2db517-aad4-4517-add1-0856c0864c05.png" data-type="png" data-w="256" style="outline: 0px;color: rgb(51, 51, 51);font-size: 20px;font-weight: bold;letter-spacing: 0.578px;visibility: visible !important;width: 134px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;font-size: 18px;color: rgb(0, 17, 255);">团队介绍</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">我们是淘天渠道分销技术团队，负责淘天全渠道一盘货产品技术研发。我们通过用技术手段解决电商多段销售中的多角色商业往来问题，构建了灵活的新零售供应链分销产品平台，致力于为商家提供多元化的供给和销售渠道、助力商家在全平台取得更高的成交额。<br style="background-clip: padding-box;caret-color: rgb(23, 26, 29);color: rgb(23, 26, 29);font-family: -apple-system, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Segoe UI&quot;, system-ui, Roboto, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;font-size: 14px;letter-spacing: normal;text-align: left;white-space: pre-wrap;text-size-adjust: auto;"><br style="background-clip: padding-box;caret-color: rgb(23, 26, 29);color: rgb(23, 26, 29);font-family: -apple-system, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Segoe UI&quot;, system-ui, Roboto, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;font-size: 14px;letter-spacing: normal;text-align: left;white-space: pre-wrap;text-size-adjust: auto;">长期招募人才，欢迎投递简历：xieyi.xie@alibaba-inc.com</span></p><section style="margin-bottom: 8px;"><br></section><section data-role="outer" label="Powered by 135editor.com" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section style="margin-top: 8px;outline: 0px;letter-spacing: 0.544px;word-break: break-all;color: rgb(0, 0, 0);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;text-align: center;line-height: 1.75em;margin-bottom: 8px;"><span style="outline: 0px;color: rgb(0, 17, 255);"><strong style="outline: 0px;">¤</strong></span><span style="outline: 0px;"><strong style="outline: 0px;">&nbsp;拓展阅读&nbsp;</strong></span><span style="outline: 0px;color: rgb(0, 17, 255);"><strong style="outline: 0px;">¤</strong></span></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;word-break: break-all;color: rgb(0, 0, 0);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;text-align: center;line-height: 1.75em;"><br style="outline: 0px;"></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;min-height: 24px;clear: both;visibility: visible;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D2565944923443904512%23wechat_redirect" textvalue="3DXR 技术" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">3DXR 技术</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1533906991218294785%23wechat_redirect" textvalue="终端技术" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">终端技术</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1592015847500414978%23wechat_redirect" textvalue="音视频技术" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">音视频技术</a></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;visibility: visible;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1539610690070642689%23wechat_redirect" textvalue="服务端技术" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">服务端技术</a><span style="outline: 0px;letter-spacing: 0.544px;">&nbsp;|&nbsp;</span><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D2565883875634397185%23wechat_redirect" textvalue="技术质量" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">技术质量</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1522425612282494977%23wechat_redirect" textvalue="数据算法" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">数据算法</a></section><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;visibility: visible;"><br style="outline: 0px;"></p><section class="mp_profile_iframe_wrp" style="margin-bottom: 24px;outline: 0px;"><mp-common-profile class="custom_select_card mp_profile_iframe js_wx_tap_highlight" data-pluginname="mpprofile" data-id="MzAxNDEwNjk5OQ==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/33P2FdAnju8t5nZGhAatCrc4e2iaDfAaoInribRKxc7MOqdTGygfcLqSDxhj0trCHVEh94Sjl7zuWYzwouYtJ0VQ/300?wx_fmt=png&amp;wxfrom=19" data-nickname="大淘宝技术" data-alias="AlibabaMTT" data-signature="大淘宝技术官方账号" data-from="2" data-index="0" data-origin_num="685" data-isban="0" data-weuitheme="light" data-biz_account_status="0" data-is_biz_ban="0"></mp-common-profile><span style="outline: 0px;color: rgb(0, 0, 0);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"></span></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - 大淘宝技术（AlibabaMTT）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4662964/blog/10448445</guid>
            <link>https://my.oschina.net/u/4662964/blog/10448445</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mozilla 和 Firefox 的变迁：市场下滑背后的思考]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近 Mozilla 基金会发布的 2023 年度报告引发了广泛关注。报告显示，在 Mozilla CEO 薪酬大幅上涨的同时，其旗舰产品 Firefox 浏览器的市场份额却持续下滑。这一现象不仅反映出 Mozilla 的财务状况尚佳，也揭示了其业务重心可能正在发生变化，但同时也让人不免对 Firefox 前景产生担忧。</p><p style="text-align:center"><img height="919" src="https://oscimg.oschina.net/oscnet/up-4547075666f5a7674598dca51bafe5cc568.png" width="1920" referrerpolicy="no-referrer"></p><p style="color:#999999; text-align:center">The State of Mozilla 网站截图</p><p>具体来看，2022 年 Mozilla CEO 的年薪高达 690 万美元，较去年增加了 130 万美元，达到创纪录的新高。与此形成对比的是，Mozilla 的整体收入出现轻微下滑，由 2021 年的 6 亿美元降至 2022 年的 5.93 亿美元。这表明，尽管财务资产总额继续增长，达到高达 13 亿美元，但收入增长出现停滞。</p><p>更值得关注的是，在 Mozilla 财务数据保持乐观的背景下，其核心产品 Firefox 的市场表现却难掩颓势。据统计，2022 年 Firefox 的全球浏览器市场份额已从 2021 年底的 3.79% 下降至 3.04%，跌幅达 20%。考虑到近年移动互联网的快速发展，这一数据更显示出 Firefox 在移动端的表现不佳。</p><p>面对 Firefox 市场份额的下滑，业内分析普遍认为其背后反映的是 Mozilla 业务重心的转变。在财务报告中可以看出，Mozilla 的「版税收入」有所下降，而「订阅和广告收入」则有所增加，似乎显示出其正在加速多元化业务，减少对 Firefox 的依赖。而今年早些时候，Mozilla CEO 就明确表示，公司将重点转向人工智能等新兴领域。</p><p>因此，有分析指出，Mozilla 可能正处在从浏览器向人工智能等新业务转型的关键节点上。这可能也解释了为何在 Firefox 表现疲软的情况下，企业高管的薪酬水平还能大幅提升。很显然，Mozilla 领导层正在根据新的发展战略进行调整。</p><p>但业内也存在担忧的声音。毕竟，Firefox 曾是开源运动的一面旗帜，同时也是少数能与 Chrome 竞争的浏览器之一。一旦 Mozilla 继续减少 Firefox 投入，将可能对浏览器市场格局和网络开放性产生一定影响。</p><p>最近，Mozilla 基金会报告在 Hacker News 社区也引发了热烈讨论。许多社区成员对报告反映出的 Mozilla 业务战略转变表示不解甚至失望。他们普遍认为，Mozilla 不应过度减少对 Firefox 的投入，而应更专注于维护其核心产品。</p><p>一些用户还表示，由于 Firefox 的私密性保护功能，其实际用户量可能高于统计数据。他们希望 Mozilla 能继续致力于提升 Firefox 的核心功能，如密码管理、广告屏蔽等，这对维系用户群至关重要。此外，一些社区用户还呼吁 Mozilla 应该采取行动巩固 Firefox 的市场地位，确保浏览器市场的开放和多样。</p><p>综合来看，Mozilla 当前的市场表现确实反映了一家企业在变革中的两难处境。CEO 薪酬的大幅提高似乎预示着企业正根据新的发展战略进行市场调整，这在商业上也许可理解。但作为曾经开源界的领军产品，Firefox 的持续下滑无疑让人担忧。维护核心产品与开拓新业务之间的平衡，可能是 Mozilla 当前面临的主要难题。</p><p>无论前景如何，Firefox 在开源浏览器市场的地位和作用还将持续受到业内关注。而 Mozilla 也面临着在财务增长和维系开源社区期望之间找到最佳路径的挑战。我们期待 Mozilla 能继续致力于开放和创新，同时维护其社区支持度。毕竟，只有在社区的积极参与下，开源精神才能持续发扬光大。</p><blockquote><p>注：Mozilla 的报告总是会滞后一年，所以文中提到了很多 2022 年的信息</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273248</guid>
            <link>https://www.oschina.net/news/273248</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Rust 1.75.0 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333"><span style="color:#333333">Rust 1.75.0 稳定版已正式</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2023%2F12%2F28%2FRust-1.75.0.html" target="_blank">发布</a><span style="background-color:#ffffff; color:#333333"><span style="color:#333333">，主要带来以下变化：</span></span></p><h4 style="text-align:start">traits 中的<code>async fn</code><span>&nbsp;</span>和 return-position<span>&nbsp;</span><code>impl Trait</code></h4><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Rust 1.75 支持在 Trait 中使用<code>async fn</code>和<code>-&gt; impl Trait</code>。但是，此初始版本存在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2023%2F12%2F21%2Fasync-fn-rpit-in-traits.html%23where-the-gaps-lie" target="_blank">公告帖子</a>中描述的一些限制。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>预计这些限制将在未来的版本中取消。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h4><strong><span style="background-color:#ffffff; color:#333333"><span style="color:#333333">指针字节偏移 API</span></span></strong></h4><p style="text-align:start"><span style="background-color:#ffffff; color:#333333">原始指针</span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>（<code>*const T</code>和<code>*mut T</code>）主要用于支持以<code>T</code>为单位的操作。例如，<code>&lt;*const T&gt;::add(1)</code>将&nbsp;<code>size_of::&lt;T&gt;()</code>字节添加到指针的地址。在某些情况下，使用字节偏移量更方便，并且这些新 API 避免了要求调用者首先强制转换为<code>*const u8</code>/&nbsp;<code>*mut u8</code>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_add" target="_blank"><code>pointer::byte_add</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_offset" target="_blank"><code>pointer::byte_offset</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_offset_from" target="_blank"><code>pointer::byte_offset_from</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_sub" target="_blank"><code>pointer::byte_sub</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.wrapping_byte_add" target="_blank"><code>pointer::wrapping_byte_add</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.wrapping_byte_offset" target="_blank"><code>pointer::wrapping_byte_offset</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.wrapping_byte_sub" target="_blank"><code>pointer::wrapping_byte_sub</code></a></li></ul><h4 style="text-align:start"><span><span><strong><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>rustc 的代码布局优化</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></span></span></h4><p><span><span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Rust 编译器的运行速度继续加快，此次发布的二进制版本采用了 BOLT 技术，使基准测试平均运行时间提高了 2%。该工具优化了包含大部分 rustc 代码的 librustc_driver.so 库的布局，从而提高了缓存利用率。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>现在还在使用 -Ccodegen-units=1 构建 rustc，为在 LLVM 中进行优化提供了更多机会。这一优化为基准测试带来了 1.5% </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff; color:#000000">的平均运行时间平均提升。</span></p><p><span><span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>在此版本中，这些优化仅限于 x86_64-unknown-linux-gnu 编译器。项目团队计划随着时间的推移将其扩展到更多平台。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h3 style="text-align:start"><span><span><strong><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>稳定的 API</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></span></span></h3><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fsync%2Fatomic%2Fstruct.AtomicUsize.html%23method.from_ptr" target="_blank"><code>Atomic*::from_ptr</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fstd%2Ffs%2Fstruct.FileTimes.html" target="_blank"><code>FileTimes</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fstd%2Fos%2Fwindows%2Ffs%2Ftrait.FileTimesExt.html" target="_blank"><code>FileTimesExt</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fstd%2Ffs%2Fstruct.File.html%23method.set_modified" target="_blank"><code>File::set_modified</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fstd%2Ffs%2Fstruct.File.html%23method.set_times" target="_blank"><code>File::set_times</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fnet%2Fenum.IpAddr.html%23method.to_canonical" target="_blank"><code>IpAddr::to_canonical</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fnet%2Fstruct.Ipv6Addr.html%23method.to_canonical" target="_blank"><code>Ipv6Addr::to_canonical</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Foption%2Fenum.Option.html%23method.as_slice" target="_blank"><code>Option::as_slice</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Foption%2Fenum.Option.html%23method.as_mut_slice" target="_blank"><code>Option::as_mut_slice</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_add" target="_blank"><code>pointer::byte_add</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_offset" target="_blank"><code>pointer::byte_offset</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_offset_from" target="_blank"><code>pointer::byte_offset_from</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.byte_sub" target="_blank"><code>pointer::byte_sub</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.wrapping_byte_add" target="_blank"><code>pointer::wrapping_byte_add</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.wrapping_byte_offset" target="_blank"><code>pointer::wrapping_byte_offset</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fprimitive.pointer.html%23method.wrapping_byte_sub" target="_blank"><code>pointer::wrapping_byte_sub</code></a></li></ul><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>这些 API 现在在 const</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff; color:#000000"><span>&nbsp;</span>contexts&nbsp;</span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>中是稳定的：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fnet%2Fstruct.Ipv6Addr.html%23method.to_ipv4_mapped" target="_blank"><code>Ipv6Addr::to_ipv4_mapped</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fmem%2Funion.MaybeUninit.html%23method.assume_init_read" target="_blank"><code>MaybeUninit::assume_init_read</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fmem%2Funion.MaybeUninit.html%23method.zeroed" target="_blank"><code>MaybeUninit::zeroed</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fmem%2Ffn.discriminant.html" target="_blank"><code>mem::discriminant</code></a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstable%2Fcore%2Fmem%2Ffn.zeroed.html" target="_blank"><code>mem::zeroed</code></a></li></ul><h4 style="text-align:start"><span><span><strong><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>其他变化</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></span></span></h4><p style="text-align:start"><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>查看&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frust-lang%2Frust%2Freleases%2Ftag%2F1.75.0" target="_blank">Rust</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frust-lang%2Fcargo%2Fblob%2Fmaster%2FCHANGELOG.md%23cargo-175-2023-12-28" target="_blank">Cargo</a>&nbsp;和&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frust-lang%2Frust-clippy%2Fblob%2Fmaster%2FCHANGELOG.md%23rust-175" target="_blank">Clippy</a>&nbsp;中发生的所有变化。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span style="background-color:#ffffff; color:#333333"><span style="color:#333333">详情可</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2023%2F12%2F28%2FRust-1.75.0.html" target="_blank">查看官方公告</a><span style="background-color:#ffffff; color:#333333"><span style="color:#333333">。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273247/rust-1-75-0-released</guid>
            <link>https://www.oschina.net/news/273247/rust-1-75-0-released</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英伟达推出特供中国销售的 GeForce RTX 4090 D]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 GeForce RTX 4090 被列入了出口管控清单之后，英伟达推出了特供中国市场销售的<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nvidia.cn%2Fgeforce%2Fgraphics-cards%2F40-series%2Frtx-4090-d%2F" target="_blank"> GeForce RTX 4090 D</a></u>，建议零售价 1.3 万人民币，1 月 20 日发售。</p><p>作为英伟达针对美国新出口限制的回应，RTX 4090 D 能满足美国的出口管控要求，旨在为中国游戏玩家提供高性能的游戏体验。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a380dbf4c058357511bfd4b9931862b1751.png" referrerpolicy="no-referrer"></p><p>据介绍，RTX 4090 D 有 14592 个 CUDA Core 核心，频率 2.28GHz-2.52GHz，显存 24 GB GDDR6X。相比下原版 RTX 4090 有 16384 个 CUDA Cores 核心。此外，RTX 4090 D 基础频率高于 RTX 4090，但由于综合运算性能的限制，其 CUDA 和 Tensor 核心数量低于 RTX 4090。因此新版本预计会大幅降低 AI 推理性能，游戏性能可能变化不太显著。</p><p>与 RTX 4090 的主要参数对比：</p><ul><li>CUDA 核心数量：从 16384 个减至 14592 个</li><li>Tensor 核心数量：从 512 个减至 456 个</li><li>RT 核心数量：从 128 个减至 114 个</li><li>基础频率：2280 MHz，高于 RTX 4090 的 2235 MHz</li><li>加速频率：与 RTX 4090 相同，均为 2.52 GHz</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-b9e684e4d8fd2a515232e8171aa8f883882.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-68e049a7a0911bd428574a653036dc7f080.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273243/nvidia-rtx-4090-d</guid>
            <link>https://www.oschina.net/news/273243/nvidia-rtx-4090-d</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[告别 2023，迎接 2024]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>顺便带一下开放签开源电子签章上线两周的小结，本周关键字「惊喜」。官网访问量稳定在 200 左右/天，github/gitee:start 总计 130。5 个企业版意向客户，以上便是开放签上线两周的运营数据。</span></span></span></span></span></span></span></span>&nbsp;</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>用「坚持」「艰辛」来总结 2023 年，这是我们真实的写照。团队这几年确实很辛苦，经历了创业的艰辛，失去了几载青春、大把的票子，用很低的收入维持生活，这是我们的现状。但是这些依然打不倒，也压不跨我们，对我们来说也不是什么」苦「。因为我们早已看淡了这些，我们相信我们这些年的积累、经验总有一天有用武之地。因为我们有梦想（说梦想可能会有人笑话吧），我们可以把开放签做好。其实毫不夸张的说，直至开放签上线后，才体会到十年磨一剑的感受。不瞒大家，从开始做电子签直至开放签这个项目上线，真的已经十年了，期间被家人和朋友调侃十年才玩明白这点事儿。调侃归调侃，真正想做好一个产品，我们觉得十年只是一个开始，没有这十来年足够的客户、技术、服务等方方面面积累，以及我们对开放签的坚持，估计开放签上线后也是个没血肉、立不住的产品吧。对开放签来说，十年只是一个开始，我们深知没有任何一件事情可以随便、容易的完成的，接下来的几年、几十年，我们将持续的、顽强的深耕我们的产品、服务，让电子签章更简单不是说说而已。</span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>用「惊喜」「憧憬」来展望 2024 年，惊喜发生在开放签上线后，而且是持续的。惊喜的是没想到有特别多的朋友在关注、关心我们，给我们提了不少战略级别的建议，真的感谢你们。在此特别感谢@jack，感谢你给予我们的指导和建议。你给我们带来了更多的正能量，我们更加坚定了能做好开放签的信心。只要用心做好产品，我们相信 24 年会有更多的惊喜。24 年用「憧憬」一词来展望新年，代表了我们对新的一年美好的期冀。我们期待有更多用户可以低门槛的应用电子签章，电子签章可以更加简单的得到普及。新的一年，我们更加期待开放签可以更多的参与到公益和对社会有益的事业中，让开源、开放的意义更大。</span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>写在最后，我们还很年轻，还有很多不足，肯定在发展的道路上会犯很多错误，但是我们是开放的，有激情的，我们愿意接受各种批评和质疑，最后还是用一句我们自己坚信的话来总结我们「我们相信开源开放会为产品与用户之间带来更多信任「，这就是开放签的价值观，是我们坚定走下去的信念。 </span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>祝各位在新的一年顺遂、如意。新年好！</span></span></span></span></span></span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 28 Dec 2023 08:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273299</guid>
            <link>https://www.oschina.net/news/273299</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
