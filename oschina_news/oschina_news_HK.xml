<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 11 Jan 2024 06:42:43 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[2024 年，Linux 內核的開發語言是否要從 C 轉換為 C++]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linux 內核郵件列表中一篇<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F152261521484.30503.16131389653845029164.stgit%40warthog.procyon.org.uk%2F" target="_blank">已有六年曆史的老帖</a></u>近日再次引發激烈討論——主題是建議<strong>將 Linux 內核的開發語言從 C 轉換為更現代的 C++</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-abd681f1af855365261fbf52b91d3db5752.png" referrerpolicy="no-referrer"></p><p>資深 Linux 開發者 H. Peter Anvin 昨日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F3465e0c6-f5b2-4c42-95eb-29361481f805%40zytor.com%2F" target="_blank">回覆</a></u>了這封郵件，<strong>闡述了他為什麼認為 C++ 用於 Linux 內核開發的時機終於成熟了。</strong></p><p>H. Peter Anvin 在郵件中提到了 C++14 和 C++20 的一些新特性，包括元編程支持、概念 (concepts) 等，這些新特性可能會使 C++ 成為更適合內核開發和嵌入式編程的編程語言。其他部分開發者也表達了對該提議的支持，他們認為現代 C++ 可能會為內核開發帶來一些好處。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-04a0f9dd4092d8600c9e7b02746b2b88545.png" referrerpolicy="no-referrer"></p><p>但是，Linus Torvalds 過去曾對 C++ 持強烈反對態度，因此目前還不清楚這個討論是否會最終促使 Linux 內核採用現代 C++。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:38:44 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275195</guid>
            <link>https://www.oschina.net/news/275195</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[京東啓動鴻蒙原生應用開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">華為與京東宣佈達成合作，正式啓動鴻蒙原生應用開發。華為常務董事、終端業務 CEO、智能汽車解決方案 BU 董事長餘承東在微博發文稱：</span></p><blockquote><p><span style="color:#000000">今天我們迎來了重量級合作伙伴@京東 ，奠定了鴻蒙生態今年的又一座重要里程碑！京東將基於 HarmonyOS NEXT 的全場景無縫流轉、原生智能等創新特性開發原生應用，為消費者帶來簡單易用、極致流暢、純淨安全、多快好省的購物體驗。歡迎更多夥伴加入我們，共同打造前所未有的鴻蒙新生態，共贏萬物互聯時代！ </span></p></blockquote><p><img height="274" src="https://oscimg.oschina.net/oscnet/up-ab646a627a11c6fd1cb06db9553c7d9bb4e.png" width="500" referrerpolicy="no-referrer"></p><p>截至目前，國內 200 家頭部應用廠商中，已有超百家啓動鴻蒙原生應用開發。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:11:44 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275192</guid>
            <link>https://www.oschina.net/news/275192</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Terraform 開源分支 OpenTofu 正式發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">經過五十多名開發人員歷時四個月的開發，Terraform 開源分支 OpenTofu 現已正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fopentofu-announces-general-availability" target="_blank">發佈</a>，可供生產使用，為 Terraform 用户提供了一條直接的遷移路徑。</span></p><p><span style="color:#000000">公告指出，這個版本發佈的過程凸顯了 OpenTofu 社區驅動的方法以及開源的價值。其中有兩個例子值得注意：</span></p><ul><li><span style="color:#000000">一位社區成員提交了一份用於客户端狀態加密的 RFC，自 2016 年以來一直試圖將其引入 Terraform。</span></li><li><span style="color:#000000">多個關於 OpenTofu 註冊表的 RFC 被提交，導致一個比原來快 10 倍且成本更低的架構。</span></li></ul><p><span style="color:#000000">OpenTofu 1.6 版本中有許多令人期待的功能，包括：</span></p><ul><li><span style="color:#000000">改進的測試功能，提升配置和模塊的穩定性。</span></li><li><span style="color:#000000">增強的 S3 狀態後端，引入新的身份驗證方法，與兼容 S3 的存儲保持兼容。</span></li><li><span style="color:#000000">全新的提供者和模塊註冊表，通過簡單的拉取請求提供了一個簡化的發佈流程。</span></li><li><span style="color:#000000">數百項性能增強、錯誤修復和其他改進。</span></li></ul><p><span style="color:#000000">與此同時，OpenTofu 社區也在不斷壯大，擁有數十名開發人員的貢獻、數百名活躍的社區成員。該項目還得到了包括 CloudFlare、BuildKite、GitLab 和 Oracle 在內許多企業支持者和技術合作夥伴的支持。</span></p><p><span style="color:#000000">1.6 版本的目標是儘早發佈並儘可能穩定，即將到來的 OpenTofu 1.7 則引入更多 Terraform 中沒有的社區請求功能。包括但不限於：</span></p><ul><li><span style="color:#000000">客户端狀態加密，通過社區協作開發，非常適合在受監管環境中提高安全性。</span></li><li><span style="color:#000000">可參數化的後端、提供者和模塊，以實現更可讀、DRY（don't repeat yourself）的代碼。</span></li><li><span style="color:#000000">第三方可擴展性，使用插件系統來支持新的狀態後端。</span></li></ul><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fopentofu-announces-general-availability" target="_blank">查看官方公告</a>。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275191/opentofu-announces-general-availability</guid>
            <link>https://www.oschina.net/news/275191/opentofu-announces-general-availability</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Python 3.13 將引入 copy-and-patch JIT 編譯器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 12 月下旬，CPython 核心開發者 Brandt Bucher 向 Python 3.13 分支提交了一個添加 JIT 編譯器的 PR。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b5143d6ac9bf22233abfdde38e59442ddcb.png" referrerpolicy="no-referrer"></p><p><em>via&nbsp;<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpython%2Fcpython%2Fpull%2F113465" target="_blank">https://github.com/python/cpython/pull/113465</a></u></em></p><p>根據 PR 的描述，該 JIT 編譯器採用了名為"copy-and-patch"的設計，其工作原理是將字節碼編譯成一組「模板」，然後在運行時使用正確的值進行拼接和修補。這意味着普通 Python 用户不需要在他們的 Python 運行時中運行復雜的 JIT 編譯器架構。</p><p>copy-and-patch JIT 編譯器儘可能使用 LLVM 生態的工具，比如編譯器採用 Clang，編譯參數設為 -o3 以獲取最大的性能，二進制工具用 llvm-objdump 和 llvm-readelf。</p><p>Copy-and-Patch 技術的優點是開發者無需手寫彙編代碼就可以生成高效的機器碼，同時在運行期產生彙編代碼的方式是快速的。</p><p>相比於完整的 JIT 編譯器，copy-and-patch JIT 編譯器<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftonybaloney.github.io%2Fposts%2Fpython-gets-a-jit.html" target="_blank">只需要</a></u>在編譯 CPython 的機器上安裝 LLVM JIT 工具。這種設計的好處是它減少了額外的開銷，同時提高了 Python 的性能。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 03:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275190/python-3-13-gets-a-jit</guid>
            <link>https://www.oschina.net/news/275190/python-3-13-gets-a-jit</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sermant 重磅更新，1.3.0 release 版本發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自華為雲社區《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F420153%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">新特性速覽！Sermant 重磅更新，1.3.0 release 版本發佈</a>》，作者：華為雲開源。</p><p>Sermant 社區在 12 月份正式發佈了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuaweicloud%2FSermant%2Freleases%2Ftag%2Fv1.3.0" rel="nofollow" target="_blank">1.3.0 release 版本</a>，這次更新中，Sermant 新增服務治理插件：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuaweicloud%2FSermant%2Ftree%2Fdevelop%2Fsermant-plugins%2Fsermant-mq-consume-prohibition" rel="nofollow" target="_blank">消息隊列禁止消費插件</a>。該插件允許在微服務運行時動態地控制消費者（如 Kafka、RocketMQ）的消費行為，實現禁止或開啓消費，強化了 Sermant 的可用性治理能力。</p><p>除此之外，本次版本更新還對 Seramnt 框架存在的已知問題和部分功能進行了修復和優化。（Sermant 官網：https://sermant.io/）</p><span id="OSC_h1_1"></span><h1>一、服務治理能力提升</h1><span id="OSC_h2_2"></span><h2>1.1 動態調整消費者消費行為</h2><p>本次 Sermant 更新新增了消息隊列禁止消費插件，該插件允許微服務在運行態根據實際需求動態調整消費者對消息隊列中間件的消費行為，確保在非正常環境或狀態下，業務處理流程中的消息得到妥善管理，避免不必要的業務影響。例如，在多雲多活架構系統中，如果發生區域性故障需要對流量做切流處理，可在發生故障的可用區開啓消息隊列禁止消費功能，讓正常可用區的消費者來處理業務，避免故障區域消費流量導致業務異常，保障系統的高可用。待故障處理完成後，可重新開啓消費。</p><p><img alt="圖片 1.jpg" src="https://bbs-img.huaweicloud.com/blogs/img/20240109/1704785315029887378.jpg" referrerpolicy="no-referrer"></p><p>圖 1 消息隊列禁止消費插件故障切流場景使用</p><p>消息隊列禁止消費插件目前支持 Kafka 和 RocketMQ 兩種消息中間件。在 Kafka 方面，該插件實現了 Topic 級別的禁止和恢復消費功能。對於 RocketMQ， 控制消費的粒度為消費者實例級別。關於消費隊列禁止消費插件的具體介紹、配置説明和場景演示等請參考官網文檔<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fplugin%2Fmq-consume-prohibition.html" rel="nofollow" target="_blank">消息隊列禁止消費</a>。</p><span id="OSC_h1_3"></span><h1>二、Sermant 框架提升</h1><span id="OSC_h2_4"></span><h2>2.1 可觀測性能力提升</h2><p>支持通過指令查詢 Sermant 對宿主應用的增強信息，包括被增強的類和方法以及具體的 Interceptor，有助於提升 Sermant 的可觀測能力。可用於開發調試場景中，判斷是否對宿主類增強成功。</p><p>在 Sermant 通過任意方式啓動成功後，運行官方提供的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fuser-guide%2Fsermant-agent.html" rel="nofollow" target="_blank">AgentLoader</a>，並傳入參數下發查詢增強信息的指令 command=CHECK_ENHANCEMENT，即可在日誌中查看到 Sermant 已執行的增強信息，打印內容如下所示。具體操作請參考官網文檔<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fuser-guide%2Fsermant-agent.html%23%25E5%25A2%259E%25E5%25BC%25BA%25E4%25BF%25A1%25E6%2581%25AF%25E6%259F%25A5%25E8%25AF%25A2" rel="nofollow" target="_blank">增強信息查詢</a>。</p><pre>xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:42] [Attach Listener] ---------- PLUGINS ----------  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:44] [Attach Listener] test-plugin-A:1.0.0  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:44] [Attach Listener] test-plugin-B:1.0.0  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:46] [Attach Listener] ---------- ENHANCEMENT ----------  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:58] [Attach Listener] test-plugin-A:1.0.0  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:65] [Attach Listener] xxxxx.xxxx.TestClassA#testFunctionA(boolean,java.lang.String,java.lang.String,java.lang.String)@sun.misc.Launcher$AppClassLoader@5c647e05 [xxxx.xxxx.TestInterceptorA]  
xxxx-xx-xx xx:xx:xx.xxx [INFO] [com.huaweicloud.sermant.core.command.CheckEnhancementsCommandExecutor] [execute:65] [Attach Listener] xxxxx.xxxx.TestClassB#testFunctionB(boolean,java.lang.String,java.lang.String,java.lang.String)@sun.misc.Launcher$AppClassLoader@5c647e05 [xxxx.xxxx.TestInterceptorB,xxxx.xxxx.TestInterceptorC]</pre><span id="OSC_h2_5"></span><h2>2.2 插件安裝機制優化</h2><p>增強 Sermant Agent 插件的安裝機制，支持插件重複安裝。用於需要動態擴展插件字節碼增強範圍（類和方法）的場景，如故障注入場景中通過插件的重複安裝功能可以在原有故障注入基礎上再注入一個新的故障。重複安裝插件的實現基於 Sermant 插件的動態安裝功能，具體操作請參考官網文檔<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsermant.io%2Fzh%2Fdocument%2Fuser-guide%2Fsermant-agent.html%23%25E5%258A%25A8%25E6%2580%2581%25E5%25AE%2589%25E8%25A3%2585%25E6%258F%2592%25E4%25BB%25B6" rel="nofollow" target="_blank">動態安裝插件</a>。</p><span id="OSC_h2_6"></span><h2>2.3 問題修復</h2><ul><li>修復個別場景下可以從插件類加載器中加載到宿主類的問題。進一步強化了 Sermant 的類隔離能力，避免與宿主服務發生類衝突問題。</li><li>修復實例化攔截器時，偶發找不到宿主類的問題。從而確保了攔截器在執行增強邏輯時能夠正常操作宿主類。</li></ul><span id="OSC_h1_7"></span><h1>三、總結</h1><p>本次版本更新主要為新增消息隊列禁止消費插件。基於該插件，Sermant 的服務治理能力得到進一步強化。同時本次版本更新對 Seramnt 框架存在的已知問題和部分功能進行了修復和優化，提升了 Sermant 的高可用性。</p><p>Sermant 作為專注於服務治理領域的字節碼增強框架，致力於提供高性能、可擴展、易接入、功能豐富的服務治理體驗，並會在每個版本中做好性能、功能、體驗的看護，廣泛歡迎大家的加入。</p><ul><li>Sermant 官網：https://sermant.io</li><li><div>
    GitHub 倉庫地址： 
   <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuaweicloud%2FSermant" rel="nofollow" target="_blank">https://github.com/huaweicloud/Sermant</a></div></li></ul><p>&nbsp;</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>點擊關注，第一時間瞭解華為雲新鮮技術~</strong></a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10758484</guid>
            <link>https://my.oschina.net/u/4526289/blog/10758484</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Tachiyomi —— 免費開源漫畫閲讀器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Tachiyomi 是一款適用於 Android 6.0 及更高版本的免費開源漫畫閲讀器。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特點包括：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><ul><li>多種來源的在線閲讀</li><li>下載內容的本地閲讀</li><li>具有多個查看器、閲讀方向和其他設置的可配置閲讀器。</li><li>跟蹤器支持：<a href="https://myanimelist.net/">MyAnimeList</a>、<a href="https://anilist.co/">AniList</a>、<a href="https://kitsu.io/">Kitsu</a>、<a href="https://mangaupdates.com/">MangaUpdates</a>、<a href="https://shikimori.one/">Shikimori</a>和<a href="https://bgm.tv/">Bangumi</a>支持</li><li>分類整理你的圖書館</li><li>淺色和深色主題</li><li>安排更新新章節的時間</li><li>在本地創建備份以離線讀取或存儲到你所需的雲服務</li></ul><p>&nbsp;</p><p><img height="300" src="https://static.oschina.net/uploads/space/2024/0109/162825_aRoD_4252687.png" width="147" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tachiyomi</guid>
            <link>https://www.oschina.net/p/tachiyomi</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | keil MDK 編譯信息增強工具 keil-build-viewer]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-keil-build-viewer-v15b" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#keil-build-viewer-v15b"></a>keil-build-viewer v1.5b</h1><h2><a id="user-content-english" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#english"></a><a href="https://gitee.com/DinoHaw/keil-build-viewer/blob/master/README_EN.md">English</a></h2><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/main.png" alt="演示界面" referrerpolicy="no-referrer"></p><h2><a id="user-content-1-介紹" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#1-%E4%BB%8B%E7%BB%8D"></a>1 介紹</h2><p>這是一個 keil 的編譯信息展示增強工具，支持芯片存儲器的可視化展示，輕量且無任何依賴。具備以下功能：</p><ol><li><p>解析參與編譯的每個文件對 RAM 和 flash 的佔用情況</p><ul><li>自動忽略不被包含進編譯的文件</li><li>自動檢索被 keil 改名的文件</li><li><strong>支持雙擊打開文件</strong></li><li>支持關閉該信息的展示</li><li>支持僅顯示文件名</li></ul></li><li><p>分析芯片的 RAM 和 flash 的使用情況，使用進度條可視化展示</p><ul><li><code>■</code> 或 <code>#</code> 或 <code>X</code> 表示實際佔用的區域</li><li><code>□</code> 或 <code>O</code>  表示 zero initialize 的區域</li><li><code>_</code> 表示未被使用的區域</li></ul></li><li><p>二次編譯後新增與減少的數據量展示</p><ul><li>通過對比上次的編譯結果，<strong>顯示本次編譯新增或減少的數據量大小，單位是 byte</strong></li><li>若是新增的文件，則會顯示 <code>[NEW]</code></li></ul></li><li><p>自動搜索本級目錄的 keil 工程，因此可無參調用</p><ul><li>默認選擇搜索到的最後一個 keil 工程</li><li>支持輸入絕對路徑指定 keil 工程</li><li>支持僅輸入文件名指定 keil 工程（必須是同級目錄，可不帶文件擴展名）</li><li><strong>若路徑或工程名有空格，則使用 <code>""</code> 括起來</strong></li></ul></li><li><p>支持輸入參數修改選項</p><ul><li>如第 4 功能所描述的，指定 keil 工程</li><li><code>-OBJ</code>     顯示每個文件的 RAM 和 flash 的佔用信息（默認）</li><li><code>-NOOBJ</code>   不顯示每個文件的 RAM 和 flash 的佔用信息</li><li><code>-PATH</code>    顯示每個文件的相對路徑（默認）</li><li><code>-NOPATH</code>  僅顯示每個文件的文件名</li><li><code>以下為 v1.5 新增功能</code></li><li><code>-STYLE0</code>  進度條樣式跟隨系統（默認）</li><li><code>-STYLE1</code>  進度條樣式一： <code>|###OOO____|</code> （非中文環境時默認樣式）</li><li><code>-STYLE2</code>  進度條樣式二： <code>|XXXOOO____|</code></li><li><strong>以上命令不區分大小寫</strong></li></ul></li><li><p>顯示最大的棧使用</p><ul><li>數據來自 keil ，靜態無法精確分析，數據僅供參考</li></ul></li><li><p>支持放置於公共目錄後，可在任意目錄調用本工具，無需跟隨 keil uvproj(x) 工程</p><ul><li>v1.4 新增功能</li><li><strong>必須設置好系統環境變量，並把 <code>keil-build-viewer.exe</code> 放置於系統環境變量所指定的目錄中</strong>，建議使用系統環境變量 <code>Path</code></li><li>可節省拷貝 <code>keil-build-viewer.exe</code> 至對應 keil uvproj(x) 工程的步驟，但 <code>after build</code> 仍需填寫，詳見 <code>2 在 keil 中使用</code></li></ul></li></ol><blockquote><p><strong>説明：</strong> 本工具的所有參數可不按順序輸入，為空時表示選擇默認值，但參數與參數之間需用<strong>空格</strong>隔開</p></blockquote><blockquote><p><strong>雙擊打開對應文件動畫演示</strong><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/open_file.gif" alt="雙擊打開文件" referrerpolicy="no-referrer"></p></blockquote><h2><a id="user-content-2-在-keil-中使用" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#2-%E5%9C%A8-keil-%E4%B8%AD%E4%BD%BF%E7%94%A8"></a>2 在 keil 中使用</h2><ol><li><p>在 keil 中調用方式很簡單，下載<a href="https://gitee.com/DinoHaw/keil-build-viewer/releases">發行版</a>中的 <code>keil-build-viewer.exe</code> 放在 keil 對應的 uvproj(x) 工程的同級目錄，按下圖進行配置即可。如需輸入其他選項，則在 <code>keil-build-viewer.exe</code> 後跟隨輸入。如僅顯示每個文件的文件名，則可填寫：<br></p><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">keil-build-viewer.exe -NOPATH</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li><p>在 cmd 或 powershell 中使用同理，僅需添加前綴 <code>.\</code> 即可。如：<br></p><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">.\keil-build-viewer.exe</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li></ol><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/user_command.png" alt="keil 配置" referrerpolicy="no-referrer"></p><h2><a id="user-content-3-我想自己編譯這個工具" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#3-%E6%88%91%E6%83%B3%E8%87%AA%E5%B7%B1%E7%BC%96%E8%AF%91%E8%BF%99%E4%B8%AA%E5%B7%A5%E5%85%B7"></a>3 我想自己編譯這個工具</h2><p><strong>本代碼僅支持 windows 系統</strong></p><h3><a id="user-content-31-預備操作" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#31-%E9%A2%84%E5%A4%87%E6%93%8D%E4%BD%9C"></a>3.1 預備操作</h3><ol start="0"><li><p>如果你已經安裝了 gcc ，請忽略本步驟</p></li><li><p>下載 gcc 編譯器，為了考慮兼容性，這裏提供一個 32 位的 mingw 下載鏈接： <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FniXman%2Fmingw-builds-binaries%2Freleases%2Fdownload%2F13.1.0-rt_v11-rev1%2Fi686-13.1.0-release-posix-dwarf-ucrt-rt_v11-rev1.7z">i686-13.1.0-release-posix-dwarf-ucrt-rt_v11-rev1.7z</a></p></li><li><p>解壓後放在任意路徑，此處以 <code>C:\mingw32</code> 為例</p></li><li><p>配置好環境變量
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/path_config.png" alt="配置環境變量" referrerpolicy="no-referrer"></p></li><li><p>打開 <code>powershell</code> 或 <code>cmd</code> 輸入 <code>gcc -v</code> ，出現下圖內容表示配置成功
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/gcc.png" alt="gcc" referrerpolicy="no-referrer"></p></li></ol><h3><a id="user-content-32-編譯" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#32-%E7%BC%96%E8%AF%91"></a>3.2 編譯</h3><ol><li><p>打開 <code>powershell</code> 或 <code>cmd</code> 並定位至代碼目錄</p><ul><li>若使用 <code>powershell</code> ，可在代碼目錄空白處按住 <code>shift</code> 鍵同時單擊鼠標右鍵選擇打開 <code>powershell</code> ，將自動定位到代碼目錄</li></ul></li><li><p>執行以下 gcc 命令</p><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gcc .\keil-build-viewer.c -o .\keil-build-viewer.exe</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li><p>無任何提示信息，編譯通過
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/gcc_compile.png" alt="gcc 編譯通過" referrerpolicy="no-referrer"></p></li></ol><h2><a id="user-content-4-問題解答" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#4-%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94"></a>4 問題解答</h2><ol><li><p>出現 <code>[ERROR] NO keil project found</code> 之類的提示</p><blockquote><p>確認 <code>keil-build-viewer.exe</code> 放在了你需要查看的 keil uvproj(x) 工程同級目錄</p></blockquote></li><li><p>出現 <code>[ERROR] listing path is empty</code> 之類的提示</p><blockquote><p>在 keil 中選擇你要放置的 listing 相關文件的文件夾
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/select_listing_folder.png" alt="選擇 listing 文件夾" referrerpolicy="no-referrer"></p></blockquote></li><li><p>出現 <code>[ERROR] generate map file is not checked</code> 或 <code>[ERROR] Check if a map file exists</code> 之類的提示</p><blockquote><p>確認 keil 已經勾選了下圖這些選項
<img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/create_map.png" alt="創建 map" referrerpolicy="no-referrer"></p></blockquote></li><li><p>若編譯信息缺失或與實際有偏差</p><blockquote><p>確認解析的工程為目標工程（同級目錄存在多個工程時）<br>
可通過解析出的前置信息核對當前工具所解析的工程，若發現不一致，可在 <code>keil-build-viewer.exe</code> 之後指定工程名，如：</p></blockquote><div class="monokai"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">keil-build-viewer.exe TIMER</span><span id="LC2" class="line">或</span><span id="LC3" class="line">keil-build-viewer.exe TIMER.uvprojx</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><blockquote><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/keil_project_name.png" alt="解析的工程" referrerpolicy="no-referrer"></p></blockquote></li><li><p>若工程目錄或工程名有空格，將其使用 <code>""</code> 括起來</p><blockquote><p><img src="https://gitee.com/DinoHaw/keil-build-viewer/raw/master/images/space_example.png" alt="空格案例" referrerpolicy="no-referrer"></p></blockquote></li><li><p>其他問題請提 issues 或聯繫作者。</p></li></ol><h2><a id="user-content-重要説明" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#%E9%87%8D%E8%A6%81%E8%AF%B4%E6%98%8E"></a>重要説明</h2><blockquote><p><strong>1. 目前僅支持 keil MDK。</strong></p><p><strong>2. 不支持解析通過 RTE 添加的文件</strong></p></blockquote><h2><a id="user-content-修改記錄" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#%E4%BF%AE%E6%94%B9%E8%AE%B0%E5%BD%95"></a>修改記錄</h2><table><thead><tr><th align="center">版本</th><th align="center">日期</th><th>修改者</th><th>修改內容</th></tr></thead><tbody><tr><td align="center">v1.0</td><td align="center">2023-11-10</td><td>Dino</td><td>初版發佈</td></tr><tr><td align="center">v1.1</td><td align="center">2023-11-11</td><td>Dino</td><td>1. 適配 RAM 和 ROM 的解析</td></tr><tr><td align="center">v1.2</td><td align="center">2023-11-11</td><td>Dino</td><td>1. 適配 keil4 的 map 文件<br>2. 增加檢測到開啓 LTO 後打印提示信息<br>3. 修復開啓 LTO 後無打印 region 的問題</td></tr><tr><td align="center">v1.3</td><td align="center">2023-11-12</td><td>Dino</td><td>1. 修復工程存在多個 lib 時僅解析一個的問題</td></tr><tr><td align="center">v1.4</td><td align="center">2023-11-21</td><td>Dino</td><td>1. 增加將本工具放置於系統環境變量 Path 所含目錄的功能</td></tr><tr><td align="center">v1.5</td><td align="center">2023-11-30</td><td>Dino</td><td>1. 新增更多的 progress bar 樣式<br>2. 新增解析自定義的 memory area<br>3. 修復 RAM 和 ROM 信息缺失時顯示異常的問題</td></tr><tr><td align="center">v1.5a</td><td align="center">2023-11-30</td><td>Dino</td><td>1. 修復 object 數據溢出的問題<br>2. 修改進度條內存大小的顯示策略，不再四捨五入</td></tr><tr><td align="center">v1.5b</td><td align="center">2023-12-02</td><td>Dino</td><td>1. 修復保存文件路徑內存動態分配過小的問題</td></tr></tbody></table><h2><a id="user-content-參與貢獻" class="anchor" href="https://gitee.com/DinoHaw/keil-build-viewer#%E5%8F%82%E4%B8%8E%E8%B4%A1%E7%8C%AE"></a>參與貢獻</h2><ol><li>Fork 本倉庫</li><li>新建 Feat_xxx 分支</li><li>提交代碼</li><li>新建 Pull Request</li></ol>]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:32:16 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/DinoHaw/keil-build-viewer</guid>
            <link>https://gitee.com/DinoHaw/keil-build-viewer</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 前端 monorepo 大倉權限設計的思考與實現]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>一、背景</h1><p style="color:#24292f; text-align:start">前端 monorepo 在試行大倉研發流程過程中，已經包含了多個業務域的應用、共享組件庫、工具函數等多種靜態資源，在實現包括代碼共享、依賴管理的便捷性以及更好的團隊協作的時候，也面臨大倉代碼文件權限的問題。如何讓不同業務域的研發能夠順暢的在大倉模式下開發，離不開有效的權限管理方法。好的權限管理方法能夠確保研發同學輕鬆找到和理解項目的不同部分，而不受混亂或不必要的複雜性的影響，並且也應該允許研發同學合作並同時工作，同時也要確保代碼合併的更改經過代碼審查，以維護代碼的質量和穩定性。本文通過實踐過程中遇到的一些問題以及逐步沉澱下來的最佳實踐，來闡述下前端大倉 monorepo 在權限這塊是如何思考以及設計的。</p><span id="OSC_h1_2"></span><h1>二、前期調研</h1><p style="color:#24292f; text-align:start">在做大倉權限設計的時候，前期做了很多的調研，也參考了國內和國外的一些技術文章，總結起來主要是基於以下三點的設計思路去實現：</p><ul><li><strong>文件系統的自研，能夠做到文件讀寫權限的完全控制</strong>：對於文件系統的自研，國外的最佳實踐不外乎是 Google 和 Meta，他們都是大倉實踐的典範。對於文件系統的權限控制，有一套自研的文件系統，能夠對核心代碼和配置文件做到讀寫權限控制。在 Google 發表的一篇論文《Why Google stores billions of lines of code in a single repository》中也有提到：</li></ul><blockquote><p>Since Google’s source code is one of the company’s most important assets, security features are a key consideration in Piper’s design. Piper supports file-level access control lists. Most of the repository is visible to all Piper users;d however, important configuration files or files including businesscritical algorithms can be more tightly controlled. In addition, read and write access to files in Piper is logged. If sensitive data is accidentally committed to Piper, the file in question can be purged. The read logs allow administrators to determine if anyone accessed the problematic file before it was removed.</p></blockquote><p style="color:#24292f; text-align:start">大致的意思是 Google 內部自研了 Piper，能夠支持基於文件級別的訪問控制列表，大多數倉庫對所有 Piper 用户可見，但是重要的配置文件或包含業務關鍵算法的文件可以進行更嚴格的控制，並且對 Piper 中的文件的讀寫訪問都會被記錄。</p><ul><li><p><strong>基於 Git 提供的鈎子函數，能做到文件寫權限的控制</strong>：Git 本身是一個分佈式文件系統，其提供了代碼研發流程中的各種鈎子函數，在不同的鈎子函數裏面對文件的修改做校驗，可以做到代碼文件寫權限的控制，但是做不到代碼文件的讀權限控制；</p></li><li><p><strong>基於 Gitlab 的能力，對文件目錄權限做控制</strong>：<strong>Gitlab</strong><span>&nbsp;</span>開始引入了「<strong>Protected Environments</strong>」的概念，即<strong>允許為具體的文件或目錄設置權限</strong>，並指定哪些用户或用户組擁有文件的「Maintainer」權限，以便管理文件的更改和合並請求，可以<strong>用於更細粒度的文件級別權限控制</strong>。當然此種方法也只能做到代碼文件寫權限的控制，做不到代碼文件的讀權限控制。</p></li></ul><p style="color:#24292f; text-align:start">從上面的三種調研實現來看，如果要完全做到文件系統的讀寫權限控制，勢必需要自研一套適合研發流程及業務體系的文件系統，這種實現成本會很大，且基於實際的應用場景去考慮，也不是很有必要。所以<strong>本文主要圍繞基於 Git 提供的鈎子函數和基於 Gitlab 的能力來闡述過程中是如何實踐的。</strong></p><span id="OSC_h1_3"></span><h1>三、設計實現</h1><p style="color:#24292f; text-align:start">在前端 monorepo 實踐過程中，對於權限模塊的設計如果考慮不好的話，會帶來很不好的研發體驗，同時權限的實現不僅僅是代碼邏輯層面，需要考慮很多方面。在實踐過程中，具體考慮了分支模型的定義、角色權限的分配、文件目錄權限以及研發流程的權限控制四個方面。</p><span id="OSC_h2_4"></span><h2>分支模型的定義</h2><p style="color:#24292f; text-align:start">分支模型的定義即不同業務域在大倉下文件目錄的定義，<strong>清晰的目錄結構和文件命名規範是非常重要的</strong>，研發可以很快速的檢索到所需的文件。前端大倉的分支模型定義如下：<img alt="45.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/45.png" referrerpolicy="no-referrer"></p><ul><li><p><strong>Apps</strong>：各業務域的目錄結</p><ul><li><strong>_Share</strong>：業務域下通用依賴目錄</li><li><strong>Abroad-Crm-Micro</strong>：具體應用名</li><li><strong>...</strong>：<strong>後續新增的應用都在業務域目錄下</strong></li><li><strong>Components</strong>：業務域下通用組件目錄（初始化固定目錄）</li><li><strong>...</strong>：可以自定義擴展目錄</li><li><strong>Global</strong>：國際業務域應用目錄</li><li><strong>...：後續新增的業務域目錄都在 App 目錄下</strong></li></ul></li><li><p><strong>Packages</strong>：前端平台通用組件、工具函數、配置文件、Hooks 依賴</p><ul><li>Components：平台通用組件目錄（初始化固定目錄）</li><li>Hooks：平台通用 Hooks 目錄（初始化固定目錄）</li><li><strong>...：可以自定義擴展目錄</strong></li></ul></li></ul><p style="color:#24292f; text-align:start">通過使用語義化的文件和目錄命名，減少了混淆和錯誤，使得分支模型的定義更加的清晰，研發成員也可以很清楚的知道自己所關注的業務應用在哪個目錄下，同時如果需要看其他業務域的代碼，也很容易檢索到。</p><blockquote><p>上面只是大倉 B 端應用的分支模型定義，目前融合了 C 端 H5 應用以及 Node 服務應用之後，大倉目錄的劃分會相對比較複雜的多，這裏不再具體贅述。</p></blockquote><span id="OSC_h2_5"></span><h2>角色權限的分配</h2><p style="color:#24292f; text-align:start">在大倉模式下，角色權限沒有另闢蹊徑，還是沿用 Gitlab 已有的權限配置：Owner、Maintainer 和 Developer。<img alt="43.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/43.png" referrerpolicy="no-referrer"></p><ul><li><p><strong>Owner</strong>：即<strong>代碼倉庫的所有者</strong>，所有者是擁有最高權限的角色，可以對項目進行完全控制。他們可以添加和刪除項目成員，修改項目設置，包括訪問級別、分支保護規則和集成設置等。只有項目的所有者才能轉讓或刪除項目；<strong>權限配置角色為 TL</strong>。</p></li><li><p><strong>Maintainer</strong>：即<strong>代碼倉庫的維護者</strong>，可以管理項目的代碼、問題、合併請求等。可以創建和管理分支，添加和刪除文件，創建和關閉問題，合併和推送分支等。維護者不能更改項目的訪問級別或添加新的維護者；<strong>權限配置角色為 TL/PM</strong>。</p></li><li><p><strong>Developer</strong>：即<strong>代碼倉庫的開發者</strong>，是項目的一般成員，具有對代碼進行修改和提交的權限。他們可以創建和分配問題、合併請求，查看代碼、提交變更以及推送和拉取分支等。<strong>權限配置角色為研發人員</strong>。</p></li></ul><p style="color:#24292f; text-align:start">這裏需要考慮的是隻要開發者具備 Developer 權限，那麼他就可以修改大倉任何目錄下的代碼，並且本地可以提交，這樣會導致本地源碼依賴出現很大的風險：<strong>會出現本地代碼構建和生產環境構建不一致的情況，在研發流程意識不強的情況下很容易引發線上問題。</strong><span>&nbsp;</span>本着對代碼共享的原則，對於代碼文件讀權限不做控制，也允許研發修改代碼，但是對修改的代碼的發佈會做流程上的強管控。這裏就會涉及到 Gitlab 的分支保護機制以及文件 Owner 權限配置。</p><span id="OSC_h2_6"></span><h2>文件目錄權限配置</h2><p style="color:#24292f; text-align:start">在 GitLab 未支持文件目錄權限設置之前，對於文件目錄權限的控制主要依賴 Git 的鈎子函數，在代碼提交的時候，對暫存區的變更文件進行識別並做文件權限校驗，流程設計也不怎麼複雜，只需要額外再開發文件目錄和研發的權限映射配置平台即可。在 GitLab 開始支持文件目錄權限設置，可以用於更細粒度的文件級別的權限控制，內部就支持文件目錄和研發的權限映射關係，其配置頁面如下：<img alt="42.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/42.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>當有對應的文件或者目錄路徑下的文件變更的時候，在 CodeReview 過程中必須由對應的 Owner 成員確認無誤之後，才可以 MR 代碼。</strong><span>&nbsp;</span>比如：</p><ul><li><p>.husky/ 表示 .husky 目錄下的文件變更，必須由<strong>具體的文件 Owner</strong>評審通過才可以 MR；</p></li><li><p>Apps/XXX/crm/ 表示 Apps/XXX/crm 目錄下的文件變更，必須由<strong>對應的文件 Owner</strong><span>&nbsp;</span>其中之一審批通過才可以 MR。</p></li></ul><p style="color:#24292f; text-align:start">通過 GitLab 提供的文件目錄權限配置，<strong>即使研發可以修改任意目錄下的文件代碼，但是最終在 CodeReview 的流程中，需要對應的文件 Owner 進行確認評審</strong>，這樣就避免了研發在不注意的情況下，提交了原本不該變更的文件的代碼，同時也避免了線上問題的發生。</p><span id="OSC_h2_7"></span><h2>研發流程的權限控制</h2><p style="color:#24292f; text-align:start">前面提到的分支模型的定義、角色權限的分配以及文件目錄權限的配置都是需要約定俗成的，但是在真實的研發過程中，需要考慮的場景會複雜的多。比如研發可以繞開 MR 的流程，直接本地合併代碼到發佈分支。對於這類場景，對大倉下的分支做了規範約束以及 MR&amp;CodeReview 流程中的強管控。</p><span id="OSC_h3_8"></span><h3>保護分支</h3><p style="color:#24292f; text-align:start">在大倉研發模式下，主要有四類分支，其命名規範如下：</p><ul><li><strong>Dev 分支命名規範</strong>：feature-[應用標識]-版本號-自定義</li><li><strong>測試分支命名規範</strong>：test-[應用標識]-版本號</li><li><strong>發佈分支命名規範</strong>：release-[應用標識]-版本號</li><li><strong>熱修復分支命名規範</strong>：hotfix-[應用標識]-版本號</li></ul><p style="color:#24292f; text-align:start">其中 Feature 分支為開發分支，由 Developer 創建和維護；<strong>Release 和 Hotfix 分支為保護分支</strong>，Developer 和 Maintainer 都可以創建，但是 Developer 角色沒有權限直接將 Feature 分支合入 Release 或者 Hotfix 分支，只能由 Maintainer 角色來維護。基於目前不同業務域會經常創建 test 分支用於不同測試環境的部署，這裏 test 分支並未設置為保護分支。當然 Matser 分支也是保護分支，只有 Owner 角色才有權限直接將分支代碼合併到主幹分支。</p><p style="color:#24292f; text-align:start">通過對不同類型的分支的定義，基於 GitLab 提供的保護分支能力，避免了研發本地合併代碼的情況，使得 Feature 分支的代碼必須走研發流程的 MR&amp;CodeReview 流程，才能最終合入代碼。</p><span id="OSC_h3_9"></span><h3>鈎子函數</h3><p style="color:#24292f; text-align:start">通過保護分支的約束，避免了本地直接合發佈分支帶來的風險，但是在本地代碼提交的過程中，如果不做權限的校驗，就會<strong>在 CodeReview 流程中出現文件 Owner 權限不足的情況，為了在代碼提交階段就能識別到非變更文件的提交</strong>，這裏基於 Git 的鈎子函數，做了權限校驗，其流程如下：<img alt="41.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/41.png" referrerpolicy="no-referrer"></p><blockquote><p>通過 Git Hooks 提供的 Pre-Commit 和 Pre-Push 兩個節點做權限校驗，防止出錯。Pre-Commit 不是必須的，如果影響代碼提交的效率，可以跳過這個步驟，Pre-Push 是必須的，不允許非 Owner 做本地發佈。</p></blockquote><p style="color:#24292f; text-align:start"><strong>當然這裏也會帶來一個問題</strong>：當迭代的 Release 分支落後於 Master 分支，此時基於 Master 分支創建的 Feature 分支就會和 Release 分支代碼不一致，導致出現很多非必要的變更文件，此時研發會很疑惑為什麼會出現沒有修改過的變更文件。這個問題在大倉研發模式下是無法避免的，通過分析之後，在本地提交階段，過濾了 Apps 目錄的校驗，只保留了大倉頂層部分核心文件的權限校驗，因為大部分的變更都在業務域下的應用裏面，頂層的文件很少會去修改。</p><span id="OSC_h3_10"></span><h3>MR&amp;CodeReview</h3><p style="color:#24292f; text-align:start">通過保護分支的約束以及鈎子函數對部分核心文件的校驗，減少了很多在 MR&amp;CodeReview 中本該遇到的問題。<strong>基於文件 Owner 權限的 MR 和 CodeReview 流程</strong>：Commit 階段 -&gt; Push 階段 -&gt; 創建 MR -&gt; CodeReview -&gt; 執行 MR，每個階段的流程如下：<img alt="65.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/65.png" referrerpolicy="no-referrer"></p><ul><li><p>Commit 階段通過對核心文件的 Owner 校驗，避免核心文件被亂改的情況；</p></li><li><p>CodeReview 階段通過文件 Owner 權限的校驗，確保非本身業務域被修改之後被其他業務域的 Owner 知悉。</p></li></ul><p style="color:#24292f; text-align:start"><img alt="66.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/66.png" referrerpolicy="no-referrer"><img alt="67.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/67.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>這裏會帶來一個問題</strong>：當 Release 分支回合 Master 代碼的時候，會創建臨時 MR，這個過程也會有文件 Owner 權限的校驗（比如客服同學同步代碼的時候，也會將商家和供應鏈的代碼一起同步過來），就需要其他業務域的文件 Owner CR 通過才行，但 Master 的代碼實際已經是 CR 過的，沒有必要重複 CR，並且同步頻繁的時候，會經常 CR 確認，導致回合代碼的效率非常低。<strong>這裏給效率技術那邊提了需求，在 Release 分支回合 Master 代碼的時候，不做文件 Owner 的校驗。</strong></p><p style="color:#24292f; text-align:start">通過上面對研發流程中的權限控制，避免了出現本地代碼構建和生產環境構建不一致的情況，確保了提交代碼的質量和穩定性。</p><span id="OSC_h1_11"></span><h1>四、擴展思路</h1><p style="color:#24292f; text-align:start">通過以上的設計實現，基本上大倉下的權限設計能滿足現有的研發模式了。<strong>為了彌補文件讀權限控制的缺陷，過程中，也考慮了訪問控制列表以及文件訪問日誌的實現</strong>，但是最終覺得不是很有必要，就沒有在大倉裏面應用起來。這裏可以分享下訪問控制列表以及文件訪問日誌實現的幾種思路。</p><span id="OSC_h2_12"></span><h2>訪問控制列表</h2><p style="color:#24292f; text-align:start">訪問控制列表即<strong>大倉下對文件目錄的訪問控制，以便更精確地控制對敏感信息或關鍵代碼的訪問</strong>。之前有提到 Google 和 Meta 都是通過自研的文件系統實現，但是如果不是自研，是不是就一定實現不了了呢，其實未必見得。</p><span id="OSC_h3_13"></span><h3>VSCode 設置文件隱藏</h3><p style="color:#24292f; text-align:start">通過在大倉目錄下的 .vscode/settings.json 文件配置 files.exclude 屬性可以實現文件的顯隱，如下：</p><pre><code>{
  "files.exclude": {
    "**/scripts": true
  }
}
</code></pre><p style="color:#24292f; text-align:start">上面的配置表示大倉目錄下的 scripts 目錄是不可見的。</p><p style="color:#24292f; text-align:start"><strong>存在的問題</strong>： 如果懂 .vscode/settings.json 配置的研發，可以直接本地將 True 改為 False，這裏配置就失效了。還有並不是所有研發都是用的 VSCode IDE，還有不少研發用其他的 IDE，每個人的研發習慣不一樣，很難做到強約束。</p><span id="OSC_h3_14"></span><h3>MAC 下隱藏文件</h3><p style="color:#24292f; text-align:start">MAC 下可以通過 shell 命令設置文件的顯隱，如下：</p><pre><code>chflags hidden **/scripts
</code></pre><p style="color:#24292f; text-align:start">上面的 shell 命令表示隱藏大倉下的 scripts 目錄。結合大倉研發模式下提供的代碼按需拉取能力，可以在代碼拉取的最後環節執行如上的命令，就可以隱藏對應的文件。</p><p style="color:#24292f; text-align:start"><strong>存在的問題</strong>：如果懂 MAC 下文件顯隱的設置，可以在 shell 終端上執行 chflags nohidden **/scripts ，這樣 scripts 就會變為可見了，達不到最終的效果。</p><p style="color:#24292f; text-align:start">對於訪問權限列表的控制，實際上是可以通過一些其他的方式實現，但其實現思路基本都是治根不治本，起不了多大的作用，所以最後都沒有在大倉的研發流程裏面體現。</p><span id="OSC_h2_15"></span><h2>文件訪問日誌</h2><p style="color:#24292f; text-align:start">文件訪問日誌即當研發打開文件的時候，發送一條日誌到服務端並保存下來，這樣<strong>可以對包含敏感信息的配置文件進行監聽， 設置審計日誌和監控，以便跟蹤誰做了什麼操作，並在出現異常情況時能夠快速識別和應對問題</strong>。通過 VSCode 插件是可以實現的，VSCode 啓動之後，提供了對應文件目錄路徑的打開事件 onDidOpenTextDocument，當研發打開任何文件的時候，都可以觸發監聽事件，那麼我們就能在監聽事件裏面去做日誌發送相關的邏輯，實現文件訪問日誌記錄的功能，大致的實現如下：</p><pre><code>export function monitorPermissionOfTargetFile(targetFilePath: string, repoRootPath: string) {
  const targetFileFullPath = repoRootPath + targetFilePath;
  // 打開項目目錄下任意文件的回調函數
  vscode.workspace.onDidOpenTextDocument(textDocument =&gt; {
    // 獲取被打開的文件路徑
    const filePath = textDocument.uri.fsPath;
    if (filePath === targetFileFullPath) {
      // 添加日誌發送邏輯
    }
  });
}
</code></pre><p style="color:#24292f; text-align:start"><strong>存在的問題</strong>：該功能強依賴 VSCode IDE，只有在 VSCode 裏面才能實現，並非所有的研發都在用 VSCode，並且實時監聽文件的點擊事件也會帶來一定的系統開銷成本。現在本來打開多個 VSCode IDE，電腦運行就比較慢了，再加上該功能，性能損耗估計會更多。</p><p style="color:#24292f; text-align:start">上面只是提供了大倉權限實踐過程中未落地的兩個擴展思路，如果還有其他更好的思路能實現文件的讀權限控制，歡迎隨時溝通交流。</p><span id="OSC_h1_16"></span><h1>五、總結</h1><p style="color:#24292f; text-align:start">前端 monorepo 大倉的權限設計在實現的過程中，遇到了很多的問題，有些時候想的很好，但是實際在研發流程中會因不同的業務域場景存在不一樣的問題。比如基於 Master 新建 Feature 分支還是基於 Release 新建 Feature 分支這個問題就尤其突出，起初基於 Master 新建的 Feature 分支，帶來的問題是研發在合 Release 分支的時候，有很多非變更文件，導致 CR 都不清楚具體要看哪些文件；然後改成基於 Release 新建的 Feature 分支，帶來的問題是會遺漏部分已發版的 Release 分支代碼；最後綜合考慮還是基於 Master 新建的 Feature 分支。大倉的權限設計也離不開參與研發流程改造的小夥伴以及效能技術的小夥伴，過程中為了適配大倉的權限，做了很多研發流程的改造以及 GitLab 能力的擴展，希望本文能給讀者帶來一定的幫助。</p><p style="color:#24292f; text-align:start">*<strong>文/Bill</strong></p><p>本文屬得物技術原創，更多精彩文章請看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com" rel="nofollow" target="_blank">得物技術官網</a></p><p>未經得物技術許可嚴禁轉載，否則依法追究法律責任！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10750685</guid>
            <link>https://my.oschina.net/u/5783135/blog/10750685</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[為慶祝 OpenWrt 20 週年，官方計劃推出 OpenWrt One 路由器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.openwrt.org%2Fpipermail%2Fopenwrt-devel%2F2024-January%2F042018.html" target="_blank">根據 OpenWrt 開發者郵件列表的消息</a></u>，項目貢獻者 John Crispin 寫道：「OpenWrt 項目即將誕生 20 週年！讓我們通過推出<strong>首個完全由上游支持的硬件設計</strong>來慶祝這一週年紀念日。」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-23721defa7c51a2c98299066aecb3478c6e.png" referrerpolicy="no-referrer"></p></blockquote><p>這款路由器將被命名為"<strong>OpenWrt One/AP-24.XY</strong>"，硬件規格暫定如下：</p><ul><li><p>SoC：聯發科 MT7981B</p></li><li><p>Wi-Fi：聯發科 MT7976C（2x2 2.4 GHz + 3x3/2x2 + 零等待 DFS 5Ghz）</p></li><li><p>內存：1 GiB DDR4</p></li><li><p>閃存： 128 MB SPI NAND+ 4 MB SPI NOR</p></li><li><p>以太網：2.5 GbE + 1 GbE</p></li><li><p>USB（主機）： USB 2.0-A</p></li><li><p>USB（設備、主機）： Holtek HT42B534-2 UART 至 USB-C</p></li><li><p>存儲：M.2 2042（PCIe Gen 2 x1）NVMe SSD</p></li><li><p>按鈕：2 個（復位 + 用户）</p></li><li><p>機械開關：1 個，用於啓動選擇（恢復、常規）</p></li><li><p>LED 指示燈：2 個（PWM 驅動），2 個 ETH 指示燈（GPIO 驅動）</p></li><li><p>外部安全硬件： EM Microelectronic EM6324（GPIO 驅動）</p></li><li><p>RTC：NXP PCF8563TS（I2C），帶備用電池座（CR1220）</p></li><li><p>電源： USB-C 的 USB-PD-12V （通過 RT5040 模塊可選 802.3at / afPoE）。</p></li><li><p>擴展：mikroBUS</p></li><li><p>認證： 符合 FCC / EC / RoHS 標準</p></li><li><p>外殼： PCB 尺寸與 BPi-R4 兼容，外殼採用可再生材料</p></li><li><p>主 SOC 的 JTAG：10 針 1.27 mm 間距（ARM JTAG / SWD）</p></li><li><p>天線連接器： 3x MMCX</p></li><li><p>原理圖：將公開（許可證待定）</p></li><li><p>符合 GPL 規範： 3b.</p></li><li><p>價格目標：力爭低於 100 美元</p></li></ul><p>John Crispin 表示，早在 2017 年和 2018 年的 OpenWrt 峯會上，他們就首次提到要推出 OpenWrt 路由器。從 2023 年 12 月開始，他們在修復 Banana Pi 設備遇到的 bug 時就清楚地意識到，該設備已經非常接近他們想要在 17/18 年實現的目標。</p><p><span>Banana PI 在社區中越來越受歡迎。它們使用自編譯的可信固件-A (TF-A) 和上游 U-Boot&nbsp; 啓動，並且某些主板已經得到上游 Linux 內核的完全支持。唯一的非開源組件是在獨立內核上運行的 2.5 GbE PHY 和 Wi-Fi 固件 blob，這些內核獨立於運行 Linux 的主 SoC 以及在啓動早期執行的 DRAM 校準例程。</span></p><p>&nbsp;</p><blockquote><p><em>OpenWrt 項目是一個針對嵌入式設備的 Linux 操作系統。OpenWrt 不是一個單一且不可更改的固件，而是提供了具有軟件包管理功能的完全可寫的文件系統。這使您可以從供應商提供的應用範圍和配置中解脱出來，並且讓您通過使用適配任何應用的軟件包來定製設備。對於開發人員來説，OpenWrt 是一個無需圍繞它構建完整固件就能開發應用程序的框架; 對於普通用户來説，這意味着擁有了完全定製的能力，能以意想不到的方式使用該設備。</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-06cc39c3d21dfb9b7ca4e8e7a72b3cabb1a.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275179/openwrt-one-for-20-yr</guid>
            <link>https://www.oschina.net/news/275179/openwrt-one-for-20-yr</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GPT Store 正式上線]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fintroducing-the-gpt-store" target="_blank">官宣</a> GPTs 應用商店 (GPT Store) 正式上線，面向 ChatGPT Plus、團隊和企業用户推出。感興趣的用户可訪問 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fchat.openai.com%2Fgpts" target="_blank">chat.openai.com/gpts</a> 進行探索。</p><p><img height="359" src="https://static.oschina.net/uploads/space/2024/0111/102327_6mDd_4252687.jpg" width="300" referrerpolicy="no-referrer"></p><p>公告指出，自 GPT 發佈兩個月以來 ，已有用户已經創建了超過 300 萬個 ChatGPT 自定義版本。GPT Store 涵蓋了由 OpenAI 的合作伙伴和社區開發的各種 GPT，大家可以從中搜尋最適合自己的。</p><p>該公司計劃每週在商店內重點展示有用的 GPT，首批推出的一些 GPT 包括：</p><ul><li>AllTrails： 提供個性化徒步路線推薦；</li><li>Consensus： 能夠搜索和綜合 200M 學術論文的結果；</li><li>Code Tutor： 通過可汗學院的編程導師擴展你的編碼技能；</li><li>Canva： 幫你設計演示文稿或社交帖子；</li><li>Books： 幫你查找你的下一本讀物；</li><li>CK-12 Flexi AI 導師：隨時隨地學習數學和科學；</li></ul><p>值得一提的是，商店的收入分成部分還沒有啓動，因此第三方 GPT 構建者可能還需要再等一段時間才能從他們的定製 GPT 中獲得報酬。OpenAI 計劃在今年第一季度啓動 GPT 構建者收入計劃，GPT 構建者將根據用户與聊天機器人的互動程度獲得報酬，但該公司尚未分享實際情況的具體細節。</p><p>GPT Store 最初由 OpenAI 首席執行官 Sam Altman 在 2023 年 11 月份的 OpenAI 開發者大會上首次展示。後來計劃於 12 月推出，但最終推到了了 1 月份。OpenAI 方面表示，在 GPT Store 開放之前，它已經建立了一個新的審查系統，以確保定製的 GPT 符合其品牌準則和使用政策；還更新瞭如何報告用户發現有害或不安全的 GPT。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 11 Jan 2024 02:16:16 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275178/gpt-store-launch</guid>
            <link>https://www.oschina.net/news/275178/gpt-store-launch</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ToolLearning Eval：CodeFuse 發佈首箇中文 Function Call 的大語言模型評測基準]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><h2><img alt="hjdfsbg.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878404965-d1c416d5-59da-4867-bcbf-ed5f2f607f42.png?x-oss-process=image%2Fresize%2Cw_900%2Climit_0" width="900" referrerpolicy="no-referrer"></h2><span id="OSC_h2_1"></span><h2><span>1.<span>&nbsp;</span></span><span style="color:#000000">背景</span></h2><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">隨着 ChatGPT 等通用大模型的出現，它們可以生成令人驚歎的自然語言，使得機器能夠更好地理解和迴應人類的需求，但在特定領域的任務上僅靠通用問答是無法滿足日常工作需要。隨着 OpenAI 推出了 Function Call 功能，工具學習能力越來越作為開源模型的標配，目前業界較有影響力的是 ToolBench 的英文數據集。但是中文數據集的稀缺，使得我們很難判斷各個模型在中文型工具上 Function Call 的能力差異。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">為彌補這一不足，CodeFuse 發佈了首個面向 ToolLearning 領域的中文評測基準 ToolLearning-Eval，以幫助開發者跟蹤 ToolLearning 領域大模型的進展，並瞭解各個 ToolLearning 領域大模型的優勢與不足。ToolLearning-Eval 按照 Function Call 流程進行劃分，包含工具選擇、工具調用、工具執行結果總結這三個過程，方便通用模型可以對各個過程進行評測分析。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">目前，我們已發佈了第一期的評測榜單，首批評測大模型包含 CodeFuse、Qwen、Baichuan、Internlm、CodeLLaMa 等開源大語言模型；我們歡迎相關從業者一起來共建 ToolLearning Eval 項目，持續豐富 ToolLearning 領域評測題目或大模型，我們也會定期更新評測集和評測榜單。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#000000">GitHub 地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval" target="_blank" rel="nofollow"><span style="color:#000000">https://github.com/codefuse-ai/codefuse-devops-eval</span></a></p><p style="margin-left:0; margin-right:0"><span style="color:#000000">ModelScope 地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fdatasets%2Fcodefuse-ai%2Fdevopseval-exam%2Fsummary" target="_blank" rel="nofollow"><span style="color:#000000">https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/summary</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_2"></span><h2><span>2.<span>&nbsp;</span></span><span style="color:#000000">評測數據</span></h2><span id="OSC_h3_3"></span><h3><span>2.1.<span>&nbsp;</span></span><span style="color:#000000">數據來源</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">ToolLearning-Eval 最終生成的樣本格式都為 Function Call 標準格式，採用此類格式的原因是與業界數據統一，不但能夠提高樣本收集效率，也方便進行其它自動化評測。經過統計，該項目的數據來源可以分為 3 類：</span></p><ol><li><span style="color:#000000">開源數據：對開源的 ToolBench 原始英文數據進行清洗；</span></li><li><span style="color:#000000">英譯中：選取高質量的 ToolBench 數據，並翻譯為中文；</span></li><li><span style="color:#000000">大模型生成：採用 Self-Instruct 方法構建了中文 Function Call 訓練數據&amp;評測集；</span></li></ol><p style="margin-left:0; margin-right:0"><span style="color:#000000">我們希望越來越多的團隊能參與到中文的 functioncall 數據構建，共同優化模型調用工具的能力。我們也會不斷地強化這部分開源的數據集。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_4"></span><h3><span>2.2.<span>&nbsp;</span></span><span style="color:#000000">數據類別</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">ToolLearning-Eval 裏麪包含了兩份評測集，fcdata-zh-luban 和 fcdata-zh-codefuse。裏面總共包含 239 種工具類別，涵蓋了 59 個領域，包含了 1509 條評測數據。ToolLearning-Eval 的具體數據分佈可見下圖</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/238517/1701934951404-984f915c-550e-4da6-93c0-3bcc70efe66d.png" width="793" referrerpolicy="no-referrer"></p><span id="OSC_h3_5"></span><h3><span>2.3.<span>&nbsp;</span></span><span style="color:#000000">數據樣例</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">在數據上我們完全兼容了 OpenAI Function Calling，具體格式如下：</span></p><p style="margin-left:0; margin-right:0"><strong><span>Function Call 的數據格式</span></strong></p><p style="margin-left:0; margin-right:0"><img alt="截屏 2024-01-10 15.00.51.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878469274-e7c2e86e-d595-4095-b7e5-cb4b0c12b2fb.png" width="1516" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong><span>chatrounds 的數據格式</span></strong></p><p style="margin-left:0; margin-right:0"><img alt="截屏 2024-01-10 15.00.19.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878469290-acf7e74e-449a-4244-b911-0cf2273b7aff.png" width="1516" referrerpolicy="no-referrer"></p><pre><code>{
    "functions":
    [
        {
            "name": "get_fudan_university_scoreline",
            "description": "查詢復旦大學往年分數線，例如：查詢 2020 年復旦大學的分數線",
            "parameters":
            {
                "type": "object",
                "properties":
                {
                    "year":
                    {
                        "type": "string",
                        "description": "年份，例如：2020，2019，2018"
                    }
                },
                "required":
                [
                    "year"
                ]
            }
        }
    ],
    "chatrounds":
    [
        {
            "role": "system",
            "content": "CodeFuse 是一個面向研發領域的智能助手，旨在中立的、無害的幫助用户解決開發相關的問題，所有的回答均使用 Markdown 格式返回。\n 你能利用許多工具和功能來完成給定的任務，在每一步中，你需要分析當前狀態，並通過執行函數調用來確定下一步的行動方向。你可以進行多次嘗試。如果你計劃連續嘗試不同的條件，請每次嘗試一種條件。若給定了 Finish 函數,則以 Finish 調用結束，若沒提供 Finish 函數，則以不帶 function_call 的對話結束。"
        },
        {
            "role": "user",
            "content": "查詢 2020 年復旦大學的分數線"
        },
        {
            "role": "assistant",
            "content": null,
            "function_call":
            {
                "name": "get_fudan_university_scoreline",
                "arguments": "{\n  \"year\": \"2020\"\n}"
            }
        },
        {
            "role": "function",
            "name": "get_fudan_university_scoreline",
            "content": "{\n    \"scoreline\":{\n        \"文科一批\": 630,    \n        \"文科二批\": 610,  \n        \"理科一批\": 650,  \n        \"理科二批\": 630  \n    }\n}"
        },
        {
            "role": "assistant",
            "content": "2020 年復旦大學的分數線如下：\n\n- 文科一批：630 分\n- 文科二批：610 分\n- 理科一批：650 分\n- 理科二批：630 分"
        }
    ]
}</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#000000">上述 Function Call 的數據樣例為給定特定工具集後，用於回答用户查詢某高校錄取分數線的問題。此外限於篇幅，此處不再其它工具使用樣例，具體可以查看 HuggingFace 數據集。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_6"></span><h3><span>2.4.<span>&nbsp;</span></span><span style="color:#000000">數據下載</span></h3><ul><li><span style="color:#000000">方法一： 直接下載（用瀏覽器打開下面的鏈接）</span></li></ul><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fdatasets%2Fcodefuse-ai%2Fdevopseval-exam%2Ffiles" target="_blank" rel="nofollow"><span style="color:#000000">https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/files</span></a></p><ul><li><span style="color:#000000">方法二：使用 ModelScope datasets 庫函數</span></li></ul><pre><code>from modelscope.msdatasets import MsDataset
MsDataset.clone_meta(dataset_work_dir='./xxx', dataset_id='codefuse-ai/devopseval-exam')
</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><pre><code>sample_data
|- sampleData.json   # 數據樣例
train_data
|- fcdata_toolbenchG1.jsonl  # 72783 toolbenchG1 整理數據
|- fcdata_toolbenchG2.jsonl  # 29417 toolbenchG2 整理數據
|- fcdata_toolbenchG3.jsonl  # 24286 toolbenchG3 整理數據
|- fcdata_toolbenchG1_zh.jsonl # 16335 toolbenchG1 部分中文翻譯數據
|- fcdata_zh_train_v1.jsonl # 72032 自有采集生成的數據 V1
|- fcdata_zh_train_luban.jsonl  # 10214 自有采集生成的數據 luban
 test_data
 |- fcdata_zh_test_v1.jsonl # 1250 自有采集生成的測試數據 V1
|- fcdata_zh_test_luban.jsonl # 259 自有采集生成的測試數據 luban</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_7"></span><h2><span>3.<span>&nbsp;</span></span><span style="color:#000000">評測設置</span></h2><span id="OSC_h3_8"></span><h3><span>3.1.<span>&nbsp;</span></span><span style="color:#000000">評測模型</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">一期我們選取了比較熱門的不同參數大小、不同機構發佈的通用大模型和 CodeFuse 大模型，具體細節如下表。後續我們也會評測更多其他的大模型。</span></p><p style="margin-left:0; margin-right:0"><img alt="截屏 2024-01-10 15.29.03.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704878469347-f387ec7e-4b93-4600-9f00-6b43aba426e0.png" width="1124" referrerpolicy="no-referrer"></p><span id="OSC_h3_9"></span><h3><span>3.2.<span>&nbsp;</span></span><span style="color:#000000">評測指標</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">由於一般通用模型無法具備工具調用的能力，因此在進行 Tool Learn-Eval 評測之前需要對通用模型進行微調，先讓模型學會工具使用的基本範式</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#000000">下面，我們定義了幾種評估工具使用的指標：</span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/e4f3eb9ec0085945e108c444bd8744d4.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/c00744c5d702dc52dd785c699051efe0.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/329076d813a344136a96bf6f06ad6e41.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/0bc2c431ba13d7463377259786f2f8b1.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/e1c18467331bc0bd1d2d7bf1ea6c4a4c.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><img src="https://intranetproxy.alipay.com/skylark/lark/__latex/2aeea17ffa6d1d6e8ae8275cbc63de33.svg" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000">②③④⑤的和為 1，代表工具調用失敗的總數，⑤工具幻覺是工具名識別失敗的一種特殊情況</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>在此基礎上，我們提供了一個相應的評測腳本，具體評測過程歡迎到 Github 項目中進一步瞭解。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_10"></span><h2><span>4.<span>&nbsp;</span></span><span style="color:#000000">評測結果</span></h2><span id="OSC_h3_11"></span><h3><span>4.1.<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval%23-leaderboard" target="_blank" rel="nofollow"><span>🏆</span></a><span style="color:#1f2328"><span>&nbsp;</span>fcdata_luban_zh 數據集評測</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">如下圖所示，在 fcdata_luban_zh 的評測結果中，不同模型在指令微調後 function call 能力存在一定的分化現象。Qwen-14B-Chat 在工具調用準確率 fccr 和 aar 的得分最高，説明通過 Qwen-14B-Chat 遵循指令微調的能力最好，同時也可以看到 Qwen-7b-chat 的 fccr 也基本與 Qwen-14b-chat 持平。Internlm-7B-Base 評分較低相對其它模型的指令微調能力較弱。從總體上來看，各模型經過 FunctionCall 的訓練數據微調後，分數區分度不大。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/14156567/1702348998847-95a5ff09-da9b-496e-b3fd-5475ed2f0fed.png" width="1461" referrerpolicy="no-referrer"></p><span id="OSC_h3_12"></span><h3><span>4.2.<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval%23-leaderboard" target="_blank" rel="nofollow"><span>🏆</span></a><span style="color:#1f2328"><span>&nbsp;</span></span><strong><span>fcdata_zh</span></strong><span style="color:#1f2328">數據集評測</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#000000">如下圖所示，在 fcdata_zh 的評測結果中，不同模型在指令微調後 function call 能力不存在太大差異。同時也可以看到在 fcdata_zh 數據集上的 arr 評分相較於 luban 數據集有較大的提升，可能是 luban 評測集表述上與整體訓練集上的回答存在較大差異，模型無法做出與 luban 數據匹配的合理回答。最好的 aar 得分模型分別是 CodeLLaMa 和 CodeFuse-7b-16k，而 CodeFuse-7b-16k 比 4k 要好也説明長 Token 模型擁有對工具進行總結的更優能力。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/14156567/1702348993031-375fb821-ec90-49e8-99aa-77e04075676f.png" width="1461" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_13"></span><h2><span>5.<span>&nbsp;</span></span><span style="color:#000000">未來展望</span></h2><p style="margin-left:0; margin-right:0"><span style="color:#000000">Tool Learning 現在已然成為大模型領域的研究熱點，大模型與 Tool Learning 能碰撞出什麼火花也是當前行業內最關心的話題。未來我們將持續對 ToolLearning-Eval 項目進行優化，主要優化方向包括以下幾點：</span></p><p style="margin-left:0; margin-right:0"><span style="color:#000000">1）不斷優化評測數據集：</span></p><ul><li><ul><li><span style="color:#000000">目前 ToolLearning-Eval 已涵蓋日常領域常見的工具集合，後續將繼續增加不同領域的 Tool 集合，直至覆蓋全領域的所有智能化任務；</span></li><li><span style="color:#000000">Tool Learning 的數據質量決定了模型掌握工具學習範式的上限，後面將通過更完善的數據構造方法和人工評測手段來生成更高質量的數據</span></li></ul></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#000000">2）拓展多工具多輪對話數據集：</span></p><ul><li><ul><li><span style="color:#000000">當前工具評測任務僅限於單工具的評測，對於不同類別之間的數據量存在較大差異，需要持續補充數據集，平衡各類別的數據量；</span></li></ul></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#000000">3）持續增加評測模型：</span></p><ul><li><ul><li><span style="color:#000000">一期主要評測了一些主流的、規模不是很大的開源模型，後續將覆蓋更多的模型，並重點跟蹤評測面向相關領域的大模型。</span></li></ul></li></ul><p style="margin-left:0; margin-right:0"><span style="color:#000000">希望大家一起來共建 ToolLearning-Eval，期待在大家的努力下，建立更準確、更全面的 ToolLearning 領域大模型評測體系，推動 ToolLearning 領域大模型技術的不斷髮展與創新。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_14"></span><h2><span>6.<span>&nbsp;</span></span><strong><span style="color:#000000">聯繫我們</span></strong></h2><p style="margin-left:0; margin-right:0"><span style="color:rgba(0, 0, 0, 0.9)">歡迎使用&amp;討論&amp;共建</span><br><span>（1）Eval - DevOps 領域 LLM 行業標準評測：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-devops-eval" target="_blank" rel="nofollow"><span>https://github.com/codefuse-ai/codefuse-devops-eval</span></a><br><span>（2）ChatBot - 開箱即用的 DevOps 智能助手：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-chatbot" target="_blank" rel="nofollow"><span>https://github.com/codefuse-ai/codefuse-chatbot</span></a><br><span>（3）Model - DevOps 領域專屬大模型：</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-DevOps-Model" target="_blank" rel="nofollow">https://github.com/codefuse-ai/CodeFuse-DevOps-Model</a><br> &nbsp;&nbsp;</span><span>(4) CodeFuse 官網：<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodefuse.alipay.com%2Fwelcome%2Fproduct" target="_blank" rel="nofollow"><span>https://codefuse.alipay.com</span></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 11:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/10759392</guid>
            <link>https://my.oschina.net/u/6942768/blog/10759392</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[袁進輝新公司再獲王慧文等 5000 萬投資]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000">硅基流動（SiliconFlow) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW0SAITjjpiJItGe4dYvMCQ" target="_blank">宣佈</a></span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">於近日完成 5000 萬元天使輪融資。本輪融資由創新工場領投，耀途資本、奇績創壇以及王慧文等科技界知名人士跟投，華興資本擔任獨家財務顧問；</span><span style="background-color:#ffffff; color:#000000">投後估值為數億元人民幣。</span></p><p><span style="background-color:#ffffff; color:#000000">硅基流動是</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">一流科技（OneFlow）</span><span style="background-color:#ffffff; color:#000000">創始人、光年之外聯合創始人袁進輝於 </span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">2023 年 8 月</span><span style="background-color:#ffffff; color:#000000">成立的一個新公司，</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">致力於打造大模型時代的 AI 基礎設施（AI Infra），降低大模型應用成本和開發門檻，加速 AGI 普惠人類。</span></p><p><img height="283" src="https://oscimg.oschina.net/oscnet/up-21d1e3f3e5cd348650171057db95e4847a6.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">袁進輝在接受《晚點 LatePost》採訪時表示，</span><span><span style="color:#000000">新公司延續 OneFlow 的方向，做 AI Infra（AI 基礎設施）層中的 「框架」。</span></span></p><div style="text-align:start"><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">AI 框架介於算力層和模型層之間，是一種系統軟件，就像電腦操作系統能使普通用户直接用鼠標和鍵盤操作應用，AI 框架能幫開發者簡單方便地設計模型或使用模型，而無需操心底層算力資源的調配。</span></span></p></div><div style="text-align:start"><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">不同的是，OneFlow 當年以通用訓練框架為主，服務深度模型的生產；硅基流動則專注做推理框架，服務大模型的應用。</span></span></p></div><div style="text-align:start"><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">袁進輝認為，服務大模型應用比服務大模型生產更容易做出標準化產品，市場空間也大得多：模型生產是階段性的，且由少數公司主導；大模型應用則會遍佈各行各業、無處不在，被各種行業和規模的企業需要。</span></span></p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 10:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275107</guid>
            <link>https://www.oschina.net/news/275107</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[重慶大學 | 面向 RISC-V 架構的 AI 開發框架構建與優化大賽宣講會成功舉辦]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">1 月 10 日，</span><strong>面向 RISC-V 架構的 AI 開發框架構建與優化大賽第八場宣講會</strong><span style="color:#000000">在</span><strong>重慶大學</strong><span style="color:#000000">舉行，重慶大學國家卓越工程師學院副院長劉凱、計算機學院副院長鍾將、助理教授李榮振、助理教授李楚昭，openKylin 社區秘書長餘傑博士、技術委員會委員王文竹博士</span><span style="color:#000000">參與活動。本次宣講會旨在進一步加深同學們對大賽的瞭解，鼓勵和動員更多同學參與到比賽中來。</span></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e2ac0aa8c27173ea72ce9d177d889d9b978.jpg" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000"><span style="color:#000000">宣講會上，openKylin 社區技術委員會委員王文竹</span><span style="color:#000000">圍繞大賽概述、賽道設置、賽程安排、參賽要求等方面向同學們介紹了面向 RISC-V 架構的 AI 開發框架構建與優化大賽</span><span style="color:#000000">，並向同學們講解介紹了一系列</span><span style="color:#000000">實踐案例</span><span style="color:#000000">，幫助同學解讀賽題，理清參賽思路，鼓勵同學們積極參與報名。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000"><span style="color:#000000"><span style="color:#000000">希望通過</span><span style="color:#000000">此次宣講會，能夠</span><span style="color:#000000">幫助同學們更好地瞭解面向 RISC-V 架構的 AI 開發框架構建與優化大賽的相關內容和參賽規則，激發同學們的參賽熱情。</span></span></span></p><p><strong>關於大賽</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">面向 RISC-V 架構的 AI 開發框架構建與優化大賽是開放原子開源大賽設立的賽道，由 openKylin 社區、麒麟軟件有限公司承辦，國防科技大學、信創海河實驗室協辦，玄鐵、北京算能科技有限公司、廣東賽昉科技有限公司贊助。通過本項賽事，旨在探索如何將人工智能技術與 RISC-V 架構相結合，以實現高性能和低功耗的目標。各相關單位、高校、個人等均可免費報名參賽，目前正在火熱報名中~</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 09:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275095</guid>
            <link>https://www.oschina.net/news/275095</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Atuin 作者宣佈辭職，全職從事開源項目]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">流行的 Shell 歷史記錄管理工具 Atuin 作者 Ellie Huxtable 於近日發文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fellie.wtf%2Fposts%2Fi-quit-my-job-to-work-full-time-on-my-open-source-project" target="_blank">宣佈</a>，已經在 2023 年 12 月 22 日辭去了 PostHog 基礎設施團隊的領導工作。接下來，她將成立一家公司，全職服務於 Atuin 項目。</span></p><p><span style="color:#000000">「Atuin 將繼續開源並以當前形式作為自託管工具免費提供。通過全職運營，我希望可以專注於為高級用户添加新的高級託管功能，並開始支持商業用途。」</span></p><p><span style="color:#000000">Atuin 是一款可跨設備同步的 Shell 歷史記錄工具。可使用 SQLite 數據庫取代你現有的 shell 歷史，併為你的命令記錄額外的內容。此外，它還通過 Atuin 服務器，在機器之間提供可選的、完全加密的歷史記錄同步功能。</span></p><p><span style="color:#000000"><img alt="" height="222" src="https://oscimg.oschina.net/oscnet/up-204accc133a02e4d3372505f70244790d01.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="222" src="https://oscimg.oschina.net/oscnet/up-ff8b1563ecf919bb0341a800b897e2de8d4.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Ellie 表示，促使她作出這一決定的原因是她開始意識到，付出與收穫是成正比的。因為受工作牽絆，她只能在在上班前抽空處理 Atuin 上的問題；但即便如此，很多時候甚至連公開的 PR 和 issue 都沒時間處理，遑論開發需要的新 features/fixes。</span></p><p><span style="color:#000000">久而久之，她感覺自己與 Atuin 之間已經漸行漸遠。在這一過程中，她的朋友 Conrad 也退出了項目的維護工作。</span></p><blockquote><p><span style="color:#000000">我覺得自己在辜負項目的期望，忽略了自己的社交生活，並且在工作中極力避免分心。</span></p><p><span style="color:#000000">為了按照我的意願發展這個項目，我需要在全職工作的同時投入更多的時間。</span></p><p><span style="color:#000000">所以，我正在創辦一家公司，全職開發 Atuin。</span></p><p><span style="color:#000000">我一直想經營自己的公司，這幾乎是我一生的夢想。但我不想為了創業而創業。我想做一些人們喜歡的、有用的東西。</span></p></blockquote><p><span style="color:#000000">談到資金問題，Ellie 則表示一直在自掏腰包運行 Atuin 服務器；「雖然數額不是很大，但也不小」。直至 2022 年底，她在朋友建議下開通了&nbsp;GitHub 贊助渠道，並收穫了意料之外的金額 ——&nbsp;足夠支付服務器費用，並抵消她迄今為止所支付的部分費用。</span></p><p><span style="color:#000000">但有一個弊端是，她需要經常提及贊助渠道的存在，否則就容易被遺忘。「這讓我感到很奇怪，因為這感覺就像是在乞討」。而有着與她相同感受的開發者並不在少數。因此，Ellie 引用了&nbsp;Sidekiq 創建者 Mike Perham 的兩句話：</span></p><blockquote><p><span style="color:#000000">「最終，OSS 的倦怠將扼殺任何具有吸引力的免費項目」</span></p><p><span style="color:#000000">「如果你創造了一些有價值的東西，那就為它收費」</span></p></blockquote><p><span style="color:#000000">展望未來，Ellie 希望能在現有功能的基礎上，開發出一些有價值的商業功能。同時將&nbsp;Atuin 發展到可以傳承下去的地步，並對一些提供過幫助的項目和人提供資助。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 08:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275092/atuin-full-time-on-open-source-project</guid>
            <link>https://www.oschina.net/news/275092/atuin-full-time-on-open-source-project</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sealos：在公有云和私有云之間，我選擇第三條路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><span style="color:#494949"><span style="background-color:#ffffff"><span style="background-color:#ffffff">【創造者説】&nbsp;Created in the name of FOSS.</span></span></span></p><p style="text-align:center"><img height="450" src="https://oscimg.oschina.net/oscnet/up-aeccf4cfa39fbccb3b91bcb94207696b175.png" width="1080" referrerpolicy="no-referrer"></p><p>前段時間，上雲和下雲的爭議如火如荼，公有云的價格、安全和透明度備受拷問，私有云的服務、維護成本又深受質疑。就在雙方互掐不分上下的時候，一個新項目引起了我們的注意——Sealos，一個雲操作系統，在公有云和私有云之間，他選擇了第三條路——把公有云私有云抽象到一起。</p><p>Sealos 的作者方海濤，曾在訊飛擔任容器平台負責人，後來在阿里雲負責雲原生集成平台，主導了 sealer 項目並捐獻給 CNCF 社區。他覺得自己「骨子裏就是個創業者」，早在 2016 年就開始了第一次創業，可惜沒成。Sealos 每年翻倍的發展速度，讓他看到了新的希望。拿到奇績創壇的投資後，他火速拉上自己的老朋友和同事，出來成立了環界雲計算公司。產品 Sealos 自從 2023 年 6 月份上線以來，<strong>僅半年時間註冊用户已經突破 8 萬，月收入超過 30w。</strong></p><p>方海濤認為，現在的公有云和私有云雖然吵得兇，但其實各有各的問題，也各有各的適用場景，脱離場景談優勢毫無意義。他認為，公有云和私有云並無本質區別，都是連接計算資源，<strong>可以做個</strong><strong>像安卓一樣好用的雲</strong><strong>操作系統</strong><strong>，誰要用雲就裝一個就行</strong>。而現在，這個想法實現了。</p><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>01 創業的齒輪重新轉動</h1><p>第一次創業失敗後，方海濤迴歸了單純的程序員身份。一天晚上，為瞭解決 K8s 早期版本的安裝和高可用等問題，方海濤把自己寫的一個安裝腳本放在了阿里雲市場上，命名為「 kubeinit 」，15 塊錢一份。沒想到的是，還真有人買。看着進賬，方海濤很興奮，彷彿看到了未來的商業帝國。可是，這第一個版本問題太多了，程序也十分複雜，方海濤不得不花了一整天時間為這位客户提供售後服務，電影院裏還在幫用户解決問題。</p><p style="text-align:center"><img height="1454" src="https://oscimg.oschina.net/oscnet/up-de8b59708266427e5953e8b36da03e20ebc.png" width="808" referrerpolicy="no-referrer"></p><p>不過，這個好開頭，讓方海濤重拾了一點創業的信心。隨着銷量暴增，方海濤也藉此換了一部新手機 iPhone 8。但不幸的是，問題也越來越多了，方海濤都抽不出時間進行售後維護。於是，他重寫了一個基於 Ansible 的 v2 版本，但 Ansible 也只是使用起來方便許多，並沒有解決根本的安裝複雜度問題，很多用户安裝失敗，尤其是在離線環境中更容易出錯，需要把 Ansible 放到 Docker 中。</p><p>為瞭解決這個問題，方海濤思考了很長時間，最後在 kube-proxy 源碼上找到了靈感。借用負載均衡器的實現方式，去掉很重的組件，使整個腳本變得簡單，於是第三個版本 Golang 解決了以往的問題，在安裝方面做到簡單極致，一條命令解決一切——這就是後來的 Sealos。</p><p>大概是眾人都苦於 K8s 安裝久矣，Sealos 口碑打開之後，在 Github 的趨勢榜上連續霸榜了一週，可見需求之旺盛。這樣出色的表現，也吸引了陸奇團隊的注意。2022 年 3 月，Sealos 獲得了陸奇團隊 200 萬的天使投資。方海濤的創業之路，也重新開啓了。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>02 獨樹一幟的設計</h1><p>「上雲是未來」雖已達成共識，但上的是公有云還是私有云，卻存在分歧。尤其是在今年的公有云故障事件之後，私有云的聲音也響亮了起來。畢竟，公有云乾的本就是租賃的活兒，不少軟件還是開源的，卻還賣這麼貴，難免讓用户心生「割韭菜」的懷疑。而私有云，建設成本又太高，無論是採購還是自建，花銷都少不了：採購起步上千萬，自建少説 30 人。這也是當下用户糾結的原因。有評論説得好：<strong>雲就是一座圍城，外面的人想進去，裏面的人想出來。</strong></p><p>不過面對這種 A or B 的難題，Sealos 卻選擇了第三條路：把公有云和私有云抽象到一起，集公有云的彈性、敏捷和私有云的安全可控於一身，同時再把價格給打下去。</p><p>還有這種好事？</p><p>怎麼做到的？</p><p><strong>Sealos 將 Kubernetes 作為 「雲內核」，基於這個雲內核做一個可以運行在多台服務器上的雲</strong><strong>操作系統</strong><strong>發行版，系統之上 「一切皆應用」。最終可以把整個數據中心所有服務器變成一台 「邏輯計算機」，讓用雲變得像用 PC 一樣簡單：</strong></p><p style="text-align:center"><img height="1974" src="https://oscimg.oschina.net/oscnet/up-1e1316ef681c726943f82545a53d490dd1f.png" width="3840" referrerpolicy="no-referrer"></p><p><strong>雲的架構也從傳統的 </strong><strong>IaaS</strong><strong>、</strong><strong>PaaS</strong><strong>、SaaS 三層架構，轉向以 Kubernetes 為雲內核的新架構：</strong></p><p style="text-align:center"><img height="590" src="https://oscimg.oschina.net/oscnet/up-be50dc03448ab6ce8c8b0188df4657401ce.png" width="1060" referrerpolicy="no-referrer"></p><p>最終，Sealos 和 Kubernetes 之間的關係，就像 Red Hat 和 Linux 內核之間的關係，只不過與單機操作系統的區別是，Sealos 是裝在整個數據中心的，Sealos 上跑的也不是 QQ 微信這些單機應用，而是開發者需要用到的各種分佈式應用。有了 Sealos，整個數據中心就不再是一台一台孤立的服務器，而是一個整體，變成一台超級邏輯計算機。這個時候再去用雲，就像是在用一台服務器一樣簡單。</p><p><strong>哪家企業需要用雲，就直接裝一個雲</strong><strong>操作系統</strong><strong>就搞定了。</strong></p><p>在方海濤看來，雲計算的本質在於將計算資源（包括硬件、軟件和網絡等）通過互聯網等方式提供給用户使用，連接單個數據中心的算力資源只給自己用就是私有云，通過公網讓大家都能用就是公有云。至於功能上，公有云能做到的理論上私有云都能做到，並無本質區別。未來，公有云和私有云也許會走到一起，變成同一個東西。</p><p>在 Sealos 的設計中，也處處秉承了這樣的理念。公有云與私有云是同一套代碼，同一個抽象，只是配置與安裝的應用不同，運行在企業自己機房就是私有云，對公網提供服務就是公有云。</p><p>兩邊的用户一手抓了。</p><p>這樣的設計還使得 Sealos 簡潔又簡單，避免了傳統用雲的「屎山」體驗。</p><p><strong>而在高度抽象的架構下，一切具體能力都通過應用去擴展。</strong>用户需要啥就裝啥，不要就卸掉，自由靈活，雲操作系統也不會隨着軟件功能的增加而增加複雜度。這樣，不管懂不懂 Kubernetes 都能愉快地使用 Sealos 了，雲原生專家可以打開終端敲各種原生命令，DBA 也可以直接使用數據庫應用，極其靈活。</p><p>「用户需要關心 Kubernetes 嗎？其實不需要。我們只要想辦法把用户最終需要的應用直接交付給用户就行了，就像你去用 Linux 的時候你很少關心 Kernel 一樣，雲也是一樣的道理，開發者需要用到的能力才是最重要的，未來沒有多少人需要再去關心這個內核了。」方海濤説。</p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>03 學習 Linux，成為 Linux</h1><p>在 Sealos 的成長過程中，不難發現，很多產品思路都學習了 Linux。在採訪過程中，方海濤也對 Linux 極為推崇。他認為，Linux 簡單易用，運行穩定，幾乎不用投入太高成本，也基本不需要定製化開發。而 Openstack 專業人士三天都不一定能裝起來，還得改一堆代碼才能用，實在是太複雜了，不應該成為私有云的代表。Linux 才是學習的榜樣。</p><p>「Linux 在哪裏用都是同一個 Linux，雲也應該這樣。否則一味地堆積很多亂七八糟的東西進來，變成一個大雜燴，那 Sealos 只會變成又一個失敗的 PaaS 平台。」方海濤説。</p><p><strong>Sealos 目前只有一套</strong><strong>開源</strong><strong>代碼，哪個版本都一樣，沒有分支</strong>。而它能得到眾多開發者的歡迎，也是因為它像 Linux 一樣低成本、易用和標準化。</p><p>「其實雲都是大差不差的，Sealos 能解決的問題，其他的雲基本上也能解決。但 Sealos 現在這麼受歡迎，就在於它的易用性。」方海濤介紹，「同樣的事情，如果放在 Sealos，K8s 集羣已經有了，只需點一下按鈕 CBT 就能起來。但是如果基於虛擬機去搭的話，你可能需要搞後端的數據庫，再去搭建負載均衡，去搞備份恢復等等，才能把整套東西搞起來。成本差異就在這。」</p><p>在運維方面，Sealos 也很穩定。「在我們的理念中，不應該有運維這種角色的存在，整個系統是自運維的，就像 PC 操作系統運行起來很少發生問題的。」</p><p style="text-align:left">而且 Sealos 最小隻有 300M，企業裝了 Sealos 便能在各種環境中擁有完全屬於自己的雲。</p><p>「另外，Sealos 有標準化的應用市場。很多人需要的其實只是上層的應用，我們把這些應用封裝好，直接給到他們去用就行了。一些雲廠商可能也有類似的 Marketplace，可是這些 Marketplace 缺乏標準，軟件的生產者跟消費者之間協作就很麻煩。我們以雲操作系統的思維，在做這個事情的時候，我們會 follow 雲原生生態的事實標準，讓軟件的生產者和消費者連接起來，相互協作，達成良性循環。」</p><p style="text-align:left">這種以操作系統的思維來做雲最終也會改變生產關係，讓雲的生態可以像安卓生態一樣，不再是單一廠商來提供雲應用，而是形成多對多的網狀協作關係。</p><p>&nbsp;</p><span id="OSC_h1_4"></span><h1>04 神奇的項目：開源、商業不分家</h1><p>截至目前，Sealos 在 Github 上已經擁有了 12000+的 star。良好的羣眾基礎，也給 Sealos 打開了一條絲滑的商業化道路。</p><p>跟別的開源項目不同，Sealos 並沒有走「先開源，後收費」的路子，而是從誕生起，就開始收費了。最早期時是賣安裝包，代碼開源但是安裝包收費，如果用户自己根據源碼去構建安裝包可能需要一週時間，而花 50-168 元就可以立馬下載，所以賣了很多，裝機量超過 150 萬次。</p><p>出來創業之後，Sealos 也開始了正式的商業化。目前主要的商業模式有兩大塊：公有云和私有云。<strong>但有意思的是，</strong><strong>不管是標準版還是商業版</strong><strong>，不管是公有云還是私有云，Sealos 都只有一套代碼。開源和商業化不分家。</strong>那 Sealos 是怎麼盈利的呢？</p><p>公有云很簡單，打開瀏覽器，註冊登錄充值就可以用，按量計費。但真正的盈利點是：<strong>雲服務</strong><strong>。</strong></p><p>「很多做開源項目的公司都會有這樣的困惑：開源做得太好，用户就不付錢了？為瞭解決這個問題，很多公司就會做兩個版本，一個是開源版，功能少一點；一個是商業版，放一些很強的功能。我就非常不喜歡這樣的做法。因為維護兩個版本是很累的事，每次都需要考慮哪些東西合併企業版，哪些東西不合並，時間一久兩個版本就直接分叉了，後面直接索性開源版不投入了，這種方式很彆扭，不高級。</p><p>我喜歡把所有的好東西都開源出去，讓開源和商業化儘可能形成合力。那怎麼規避'開源做得足夠好之後，用户不願意掏錢'這個問題？很簡單——雲服務。」方海濤説。</p><p style="text-align:left">即便 Sealos 的開源做得非常完美，用户搭建的時候還是需要掏錢買虛擬機。既然這樣，不如直接把這個錢充值給 Sealos。「本質上是成本轉移，但是這種模式對三方都好。」對用户來説：</p><ul><li><p><strong>使用上更簡單可以打開瀏覽器直接用，省去自己搭建。</strong></p></li><li><p><strong>專門的團隊維護肯定比自己維護專業。</strong></p></li><li><p><strong>用户一多每個用户成本會下降，花錢更少。</strong></p></li><li><p><strong>持續升級更新。</strong></p></li></ul><p>因此，公有云的用户，有非常大的可能性會使用雲服務。用户在 Sealos 上花的錢多了，但需要支出的總成本很可能還降低了。Sealos 也獲得了更多的資金去做新功能，擴大規模效應。</p><p>另一個商業模式就是私有云。有些用户買了服務器放在自己機房，這時候 Sealos 就延續了一開始的商業模式，但不是收安裝包的下載費用，而是在 Sealos 內部實現了計量系統，按量計費，賬户餘額用完了就得充值了。</p><p>這種方式實現了公有云和私有云計費方式的完全統一，順便一起解決了企業內部人員配額問題。針對大小不同的客户都有合理的價格，不會出現小客用不起，大客不敢用的情況。</p><p>至於這樣收費會不會讓用户反感？</p><p>「我還是覺得提供價值合理收費天經地義，原則也是儘可能找到<strong>讓客户與項目整體利益最大化的點</strong>，收費貴了傷害了用户利益，收費便宜了我們沒法快速前進，要平衡好這中間的利益關係，是個矛盾統一體。現在這種商業模式，能夠讓開源和商業化形成合力，我們也能放心大膽地投入，把開源做好，而不會有擔心用户不付費的顧慮。」方海濤説。</p><p>&nbsp;</p><span id="OSC_h1_5"></span><h1>05 像開源模式的商業團隊</h1><p>Sealos 不僅產品有趣，背後的團隊也很有意思。</p><p>如今的環界雲只有 21 個人，其中 20 個人都是寫代碼的，包括方海濤自己。即使是運營，也是技術出身。除了在商務方面分工明確一點，其餘時候，環界雲更像一個開源社區，每個人都在為這個開源項目貢獻代碼，只是負責的模塊不同。這種去中心化的開源協作方式一直順利運行至今，其中一個很重要的原因是：環界雲不太依賴銷售，大部分的客户都是自己主動找上門的，因此整個團隊得以單純地搞技術，少了很多傳統企業的條條框框。</p><p>當然，這種「人在家中坐，錢從天上來」的舒坦，離不開開源本身給項目帶來的流量。Sealos 在社區裏的好口碑和高知名度，已經成為了環界雲最大的獲客點。目前的數據顯示，高達 90% 的收入都是來自於社區裏這些主動找來的客户。因為他們是主動來尋求解決方案的，因此這也意味着他們對產品的接受度和成交率都相對較高。</p><p>目前，除了 Sealos 之外，環界雲還孵化出了兩個爆款開源項目：Laf 和 FastGPT。Laf 是個函數計算平台，可以在線直接寫代碼，至今已有 6000 的 star。FastGPT 是個基於 LLM 大模型的 AI 知識庫問答平台，把企業內部的私有化數據跟大模型結合，能變成企業內部的智能問答系統，目前已有 8000+的 star。</p><p style="text-align:center"><img height="184" src="https://oscimg.oschina.net/oscnet/up-f83ed0b7f4872bb32ae1a977145bcbda30b.png" width="438" referrerpolicy="no-referrer"></p><p style="text-align:left">Laf 和 FastGPT 為 Sealos 提供了豐富的應用，FastGPT 和 Laf 之間相互提供了 AI 自動編碼能力和插件開發能力，Sealos 則為 Laf 提供擴展、使 FastGPT 得以運行。三個產品相互補充，緊密協同，已形成了一個完整的生態系統。</p><p><strong>三個產品上線半年，環界雲計算已累計 8.4 萬的註冊用户，且擁有 10% 的付費率和超過 70% 的續費率。更難能可貴的是，Sealos 和 Laf 已成功支撐了多款百萬註冊用户級別的應用，其運行成本僅為傳統</strong><strong>雲服務</strong><strong>的 1/20。</strong></p><p>Laf 的作者王福根和 FastGPT 的作者餘金隆，都是方海濤的創業合夥人。我們發現，環界雲招募團隊成員和社區貢獻者的方式沒什麼區別，都是按照招募合夥人的方式招的。</p><p>Sealos 的一位開發主力+長期貢獻者，原是 Sealos 的用户。當時方海濤做了一個「分享有獎」的活動推廣 Sealos，他給社區掙了 100 塊，方海濤卻獎勵他 1500，他覺得這個社區好生奇怪，於是就留了下來。方海濤則認為，一個開源項目背後沒有商業化支撐，會走得很慢。而且，開源的貢獻者也理應得到回報。於是，為了吸引開源社區，方海濤專門寫了一個激勵系統，來回饋社區的項目貢獻者：當需求被合併完了之後，錢就會自動打到貢獻者的支付寶賬户裏面。這一傳統也保留到了現在。</p><p>「那個時候在項目掙到的錢幾乎都回饋到社區了。要麼給開發者了，要麼買服務器提供更好的體驗了。」方海濤説，「但我覺得這是挺好玩的一件事情，這個模式形成了一種良性循環，這樣項目就會滾滾向前，其實非常好。」</p><p style="text-align:center"><img height="1125" src="https://oscimg.oschina.net/oscnet/up-0fed2c5356b827e053d2ce179e81c714791.png" width="1500" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#999999">環界雲計算團隊</span></p><p>&nbsp;</p><span id="OSC_h1_6"></span><h1>06 小項目準備挑戰大考驗</h1><p>目前，Sealos 社區用户 10 萬+，不乏各種大企業。</p><p style="text-align:center"><img height="1855" src="https://oscimg.oschina.net/oscnet/up-1be0d9a7470266e6fbb03554af9e5903e0c.png" width="2000" referrerpolicy="no-referrer"></p><p>上線兩個月時間註冊用户就已破萬，雲服務共計運行 7000+應用。</p><p>應用的類型也很多，GPT 相關的、大模型、遊戲、企業官網和業務系統等等，不一而足。</p><p>但 Sealos 的宏圖不止於此，它的目標是進化為一款無所不在的雲操作系統，為人們提供如同使用個人電腦般簡易的雲服務體驗。</p><p>方海濤透露，接下來，Sealos 會有兩個進化方向：</p><p>一個是產品的穩定性。因為雲本質上是一個信任問題。如果產品不穩定，那用户一定不會深度使用，可能就淺嘗輒止一下，或者把一些不重要的東西如博客論壇等等往裏放。Sealos 剛上線的時候，都是開發者在用，頂多充個十塊二十塊的。但經過時間的積累，市場上認可了 Sealos 的穩定性之後，慢慢地有企業進來使用，充值數額也上去了。所以説，產品的穩定性才是核心。</p><p>但是，想把穩定性建設得足夠好，其實是有一定挑戰的，尤其是達到了一定規模之後。「我舉個例子，現在市面上幾乎所有的雲原生網關都不能滿足我們的需求，幾乎都被我們打爆了。這個時候就需要我們去建設網關，把魯棒性搞得更強。或者挑一個上下游的開源社區，幫他們做優化，一起變得更好。」方海濤説。</p><p>第二個要做的就是生態建設。「現在已經有不少的應用支持容器和 Kubernetes 了，那首先要做的就是把它們上架到我們的應用市場，拓展應用的寬度跟深度，再把 deploy on Sealos 反饋到社區。這種跟上下游開源項目之間的合作，大家都挺歡迎的。因為一方面 Sealos 有龐大的用户流量，可以給這個開源項目導流。另一方面，這個開源項目也可以為 Sealos 導流，所以是個完全互利互惠的事情。」</p><p>路漫漫其修遠兮，這個小項目未來會如何，讓我們拭目以待吧。</p><div><hr><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff"><span><strong><strong><span><span style="background-color:#ffffff"><span><span style="color:#27ae60"><span><strong><span><span>【創造者説】</span></span></strong></span></span></span></span></span></strong></strong></span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff"><span><span><span>OSCHINA 全新開源創企訪談欄目【創造者説】。</span></span></span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff"><span><span><span>開源社區需要創造者，他可以是個人，也可以是由個人組成的公司。開源軟件發展 20 餘年，來自公司的開源貢獻者已經成為中堅力量，更是有一批公司圍繞開源軟件而創辦。本欄目將聚焦開源創企和他們的創始人，探討當下的開源現狀，分享開源商業故事，為開源社區添磚加瓦。</span></span></span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">往期回顧：</span></p><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://my.oschina.net/oscpyaqxylk/blog/5578009" target="_blank">一個技術人 「誤入歧途」，做了個向量數據庫新物種</a></p></div><div><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://my.oschina.net/oscpyaqxylk/blog/5548404" target="_blank">90 後，辭職創業，説要卷死雲數據庫</a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 08:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10758980</guid>
            <link>https://my.oschina.net/u/6852546/blog/10758980</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[網易有道 Qanything 開源：探索個性化問答的新紀元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>網易有道最新開源力作：QAnything 引擎。</strong>是基於 RAG（Retrieval Augmentated Generation) 的引擎，可以用於建立本地知識庫做問答，解鎖本土 ChatGPT 般的問答體驗。☝</p><p><strong>「QAynthing」<strong>是一個成熟的系統，有着準確率高、速度快、純離線，易於使用（一鍵部署），佔用資源小</strong>（只要 16G 顯存即可）的特點。</strong></p><p>目前，<strong>「QAynthing」</strong>已經在有道的多個產品中落地應用，包括有道詞典的文檔問答，有道速讀，以及有道課程業務（高中、少兒圍棋等）的客服系統等，在有道合作的 2B 客户的場景中已經落地應用。</p><p>&nbsp;<img alt="" src="https://oscimg.oschina.net/oscnet/up-3a44e1a3842061c69c8d841262c86d5ea68.png" referrerpolicy="no-referrer"></p><p>chatgpt 的大模型能力很強，但其訓練耗時很長，無法利用用户的私有數據，且有胡亂編造的幻覺問題。</p><p><strong><strong>與 ChatGPT 相比，<strong><strong><strong><strong>有道自研的</strong></strong></strong></strong>「<strong><strong><strong><strong>Q</strong></strong></strong></strong>Aynthing</strong>」有自己的突出優勢。</strong>它能夠快速塞入各種格式的文檔，如 doc、ppt、excel、圖片、pdf 等，系統將在很短的時間內對這些文檔進行處理並根據語義建立知識庫，用户可以基於這樣的知識庫做各種問答。系統將理解用户的意圖，在全庫中尋找相關的內容，理解、提取用户關心的要點，並加以總結後呈現給用户。</p><p>&nbsp;<img alt="" src="https://oscimg.oschina.net/oscnet/up-28dd89cb825ae0ca3ded8dd7b632f332405.png" referrerpolicy="no-referrer"></p><p><strong>「QAynthing」</strong>包含的模型和系統代碼，我們都全面開源了。此次開源還包含了一個應用系統，用户可以通過前端頁面上傳文檔，直接使用。也可以通過我們提供的 API 接口做二次開發，搭建諸如智能客服等應用。用户直接一鍵下載我們的代碼和模型即可開始使用。</p><p>&nbsp;</p><p>&nbsp;&nbsp;<img alt="" height="500" src="https://oscimg.oschina.net/oscnet/up-b05477f7eac27220217144c83707d9f1048.png" width="1000" referrerpolicy="no-referrer"></p><p><strong><strong>在模型部分</strong></strong>，我們開源了有道自研的 BCE embedding 和 rerank，用來做語義檢索和相關性排序。得益於有道在翻譯領域的積累，有道自研的 embedding/rerank 模型在跨語種場景下表現尤其好。比如知識庫的文檔有中文、英文混合語種的內容，當用中文去問問題的時候，我們能夠很好的檢索出英文內容。目前所有的開源 embedding 模型都忽略了跨語種檢索的問題，在跨語種上表現不佳。此外，開源的 embedding 很多時候忽略了 RAG 的問題，只是單純追求語義相似。<strong>而<strong>我們的 embedding 和 rerank 模型專門針對 RAG 的場景做了訓練，所以有着更高的準確率</strong></strong>。</p><p><img alt="" height="456" src="https://oscimg.oschina.net/oscnet/up-c8fb3f4f844d6a2d5ac3608bae03fc309f2.png" width="1000" referrerpolicy="no-referrer"></p><p>在<strong><strong>系統部分</strong></strong>，我們對文檔的解析、切片、建庫、embedding/LLM 的推理做了大量的優化，具有<strong><strong>穩定、速度快、易於安裝</strong></strong>使用的特點。</p><p><strong><strong>目前該項目還處於<strong><strong><strong><strong>不斷迭代的階段</strong></strong></strong></strong>，<strong><strong><strong><strong>歡迎大家參與開發，並給予</strong></strong></strong></strong>我們更多反饋</strong></strong>。</p><p>官網地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FQAnything" target="_blank"><u>https://github.com/netease-youdao/QAnything</u></a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 06:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/youdaotech/blog/10739178</guid>
            <link>https://my.oschina.net/youdaotech/blog/10739178</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中文 JDK 教程網站正式上線，助力開發者掌握 Java 編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">為了滿足日益增長的 Java 開發者學習需求，對官方英文文檔理解困難，致力於提供優質編程教育的網站《存在碼》宣佈推出全新的中文 JDK 教程網站。這一網站的上線標誌着學習 Java 編程語言的全新起點，為開發者們提供了豐富而易於理解的學習資源。</span></p><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>網站特色：</strong></span></p><ol><li><p style="margin-left:0; margin-right:0"><strong>全面教程：</strong> 中文 JDK 教程網站提供了覆蓋 Java 各個方面的詳盡教程，旨在幫助開發者建立堅實的編程基礎。</p></li><li><p style="margin-left:0; margin-right:0"><strong>實用示例：</strong> 數百個實用的示例代碼將幫助開發者深入理解 Java 語言的概念和技巧，實踐中學習。</p></li><li><p style="margin-left:0; margin-right:0"><strong>學習路徑：</strong> 精心設計的學習路徑，從入門到精通，讓開發者能夠有系統地提升技能水平。</p></li><li><p style="margin-left:0; margin-right:0"><strong>及時更新：</strong> 網站內容將根據 Java 平台的最新發展和技術趨勢進行及時翻譯更新，確保學習者始終保持與行業同步。</p></li></ol><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>網站創始人表示：</strong>「我們創建這個網站的目標是為中文用户提供一個高質量、易於理解的 Java 教育平台。我們深知學習編程的挑戰，希望通過這個平台讓更多人輕鬆入門，深入學習 Java 編程語言。」</span></p><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">現在，開發者們可以通過訪問 </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjava.cunzaima.cn" target="_blank">中文 JDK 教程網站</a><span style="color:#000000">開始他們的 Java 編程之旅。</span></p><p style="color:#d1d5db; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>關於中文 JDK 教程網站：</strong> 中文 JDK 教程網站是一個專注於為中文用户提供 Java 編程語言教育的在線學習平台。通過清晰易懂的教程和實用的示例代碼，我們致力於幫助開發者輕鬆學習 Java，並在編程領域取得成功。訪問我們的網站：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjava.cunzaima.cn" target="_blank"><span style="color:#2980b9">https://java.cunzaima.cn/</span></a></p><p><strong>網站截圖：</strong></p><p><img height="763" src="https://oscimg.oschina.net/oscnet/up-a4908099ab2cb02c513eecfbe99f50213fd.png" width="1050" referrerpolicy="no-referrer"></p><p><img height="852" src="https://oscimg.oschina.net/oscnet/up-2059c6f708e6ff8119fcdbb4866fa34a17c.png" width="1888" referrerpolicy="no-referrer"></p><p><img height="733" src="https://oscimg.oschina.net/oscnet/up-d84726feca2fd514680bc5a7aaf4848b0a0.png" width="1910" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 05:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275053</guid>
            <link>https://www.oschina.net/news/275053</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[上海 AI 實驗室聯合港中大（深圳）開源音頻生成平台 Amphion]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>上海人工智能實驗室（上海 AI 實驗室）與香港中文大學（深圳）聯合團隊<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCjsutc54MgqANMtZj3pOKg" target="_blank">推出</a> AI 音頻生成平台安菲翁（Amphion）。現已開源並提供免費商用。</p><p>其不僅具備語音及歌聲合成轉換、音效及音樂生成等多種能力，更可實現轉換過程可視化，有效地降低了應用門檻，助力更廣泛的開發者進行 AI 音頻研發。</p><p>Amphion 為古希臘神話中的傳奇音樂家，傳説其彈奏的優美琴聲可讓頑石感靈。上海 AI 實驗室聯合團隊藉此為 AI 音頻生成平台命名，希望通過 AI 技術的創新為音頻領域注入全新的研究思路，開源開放，「聲」生不息。</p><p><img height="195" src="https://oscimg.oschina.net/oscnet/up-50aec28c64a629ade537a270d95c38ed10e.png" width="500" referrerpolicy="no-referrer"></p><h4><strong>集成經典模型架構，實現多項生成任務</strong></h4><p>為幫助初級開發者入門 AI 音頻生成研究並使研究過程可復現，Amphion 將當前多個經典模型架構集中於統一平台，使其可實現多項音頻生成任務。</p><p><strong>歌聲轉換 （SVC, Singing Voice Conversion）</strong></p><p>歌聲轉換是指通過 AI 技術，將一位演唱者的音色轉變為另一位演唱者。該技術涉及信號處理、機器學習、深度學習等領域。</p><p>Amphion 系統集成了經典的特徵提取模型用於 SVC 任務，包括經典的擴散模型、VITS 模型及 OpenAI 的 Whisper 模型等。基於擴散的架構使用雙向擴張 CNN 作為後端，並支持 DDPM、DDIM、PNDM 等多種採樣算法。此外，Amphion 還支持基於一致性模型的單步推理。</p><p>目前，Amphion 的特徵設計已被當前業內流行的音頻生成項目 So-VITS-SVC 5.0 借鑑。</p><p><img height="213" src="https://oscimg.oschina.net/oscnet/up-43ddb9355908a681234f663d7e8c32eb864.png" width="700" referrerpolicy="no-referrer"></p><p><strong>文生語音（TTS, Text To Speech）</strong></p><p>文生語音即輸入文字轉成相應語音的技術。當前，該模塊主要採用了深度學習技術，將文本轉換成自然流暢的高擬真度語音。在 TTS 任務模塊，Amphion 系統集成了經典 FastSpeech2 模型、VITS 模型以及 zero-shot 語音合成技術，即 Vall-E，NaturalSpeech2。</p><p><img height="196" src="https://oscimg.oschina.net/oscnet/up-34bba51d4fba3469ce72f4d2904a953e523.png" width="700" referrerpolicy="no-referrer"></p><p><strong>文生音頻（TTA, Text To Audio）</strong></p><p>文生音頻指將文字輸入轉為音樂、場景音效等特定音頻的技術。Amphion 集成了當下主流的文本驅動音頻生成模型架構，即基於 VAE Encoder、Decoder 和 Latent Diffusion 的文本驅動的音頻生成算法。在該架構下，Latent Diffusion 擴散模型以 T5 編碼後的文本為輸入，根據文本的指引生成對應的音頻效果。</p><p>文生音頻模型或將對文化創作產生積極深遠的影響，從業者或可利用此項技術，根據特定需求生成場景音效，省去從頭採集環節，提升生產效率。</p><p><img height="166" src="https://oscimg.oschina.net/oscnet/up-5675245eb7699e52230f19025f4a496385e.png" width="500" referrerpolicy="no-referrer"></p><p>聲碼器（Vocoder）是產生高質量音頻信號的重要模塊。為確保所生成音頻的高音質輸出，Amphion 集成了目前廣泛使用的神經聲碼器（Neural Vocoders），包括 BigVGAN、HiFi-GAN、DiffWave 等主流聲碼器。</p><p>技術報告顯示，Amphion 中的 HiFi-GAN 聲碼器在多項指標上領先於當前熱門開源工具。</p><p><img height="189" src="https://oscimg.oschina.net/oscnet/up-df33b9c0a05c5f8d220f0d8aaf44e960d53.png" width="500" referrerpolicy="no-referrer"></p><h4><strong>可視化功能</strong></h4><p>與傳統的音頻開源工具不同，Amphion 提供了生成過程可視化及音頻可視化功能。聯合團隊旨在通過可視化，使初級開發者者更好地理解模型的原理和細節。下圖為在擴散模型中的 SVC 任務，形象地呈現出由一位歌手音色轉換為另外一位歌手音色的漸變過程。</p><p><img height="242" src="https://oscimg.oschina.net/oscnet/up-a8cbbee92c42b4d6f600a91d234509595e5.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 03:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275031</guid>
            <link>https://www.oschina.net/news/275031</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Solus 4.5 發佈，棄用 MATE 轉向 XFCE 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Solus 4.5 「Resilience」 現已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgetsol.us%2F2024%2F01%2F08%2Fsolus-4-5-released%2F" target="_blank">發佈</a>。此版本帶來了更新的應用程序和內核、更新的軟件堆棧、新的安裝程序以及採用 XFCE 桌面環境的新 ISO 版本。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-23a81b7291d2daba437ec478767f1973ee5.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Solus 4.5 帶來了使用 Calamares 安裝程序的全新安裝體驗。與此前相比，現在利用 Calamares 可以更輕鬆地在不同配置中設置 Solus，例如 Btrfs 根文件系統和其他配置。這也是擺脱舊版 os-installer 所使用的 Python 2 的重要一步。</span></p><p><span style="color:#000000">與此同時，新版本默認使用 Pipewire 媒體框架取代了 JACK 和 PulseAudio；UI 方面不會產生太大差異，但是會帶來一些性能方面的改進，例如更好、更可靠的藍牙音頻。以及：</span></p><ul><li><span style="color:#000000">為使用受支持的 AMD 硬件的用户打包了 ROCm 5.5。</span></li><li><span style="color:#000000">附帶 Linux kernel 6.6.9 以提供最新的硬件支持。</span></li><li><span style="color:#000000">Mesa 已升級至 23.3.2，以提供最新的開源圖形驅動程序</span></li></ul><p><span style="color:#000000">桌面環境方面，Solus 4.5 提供了最新版本的 Budgie / GNOME / Plasma，並針對這些桌面環境提供了許多更新；同時發佈了 XFCE 的第一個版本。Solus 4.4 發佈公告曾宣佈計劃棄用 MATE 版本，轉而使用新的 XFCE 版本。XFCE 版的目標是填補與 MATE 版相同的空白：喜歡更輕量級桌面體驗的用户。</span></p><p><span style="color:#000000">鑑於這是 XFCE 版本的首次發佈，可能會存在一些明顯的不足，所以官方將 4.5 版 XFCE 定義為 beta 版本。新的 XFCE 版本包括：</span></p><ul><li><span style="color:#000000">XFCE version 4.18</span></li><li><span style="color:#000000">Mousepad 0.6.1</span></li><li><span style="color:#000000">Parole 4.18.0</span></li><li><span style="color:#000000">Ristretto 0.13.1</span></li><li><span style="color:#000000">Thunar 4.18.6</span></li><li><span style="color:#000000">Whiskermenu 2.8.0</span></li></ul><p><span style="color:#000000">XFCE 版本採用傳統的桌面佈局，帶有底部面板和 Whiskermenu 作為應用程序菜單。使用 Qogir GTK 主題和 Papirus 圖標主題，打造時尚現代的外觀。並已安裝 Blueman，可滿足用户對藍牙的所有需求。「這一版本耗費了大量心血，我們很高興能與大家分享！」</span></p><p><span style="color:#000000">此外，官方仍在努力為 MATE 桌面的現有用户提供無縫過渡路徑。從廣義上講，將為用户提供一種將其 MATE 安裝遷移到 Budgie 或 XFCE 的方法。在成熟的過渡計劃出爐之前，MATE 將繼續為現有用户提供支持。</span></p><p>展望 2024，項目團隊計劃在 Plasma 中提供 Discover，並在 GNOME 中提供 Software Center，以實現具有集成 Flatpak 支持的軟件管理。以及將通過修復錯誤、更新系統組件和完成從 python2 的遷移來償還技術債務。還計劃探索如何開始遷移到 Serpent 工具，為 5.0 版本做好準備。</p><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgetsol.us%2F2024%2F01%2F08%2Fsolus-4-5-released%2F" target="_blank">查看官方公告</a>。</p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgetsol.us%2Fdownload" target="_blank">下載</a></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275026/solus-4-5-released</guid>
            <link>https://www.oschina.net/news/275026/solus-4-5-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GitHub 多項服務出現故障]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GitHub 多項服務昨天出現了故障，具體表現為眾多 API 都出現了 HTTP 5xx 錯誤，錯誤率上升了 1%~5%，涉及的服務包括但不限於：</p><ul><li>Codespaces</li><li>Packages</li><li>Webhooks</li><li>Git 操作</li><li>Pages</li><li>API 請求</li><li>Actions</li><li>Pull Requests</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.githubstatus.com%2Fincidents%2Fpxg3dz4yg7lp" target="_blank">從事故報告頁面來看</a></u>，GitHub 當時的解決方案是<strong>將相關問題隔離到一個數據中心進行處理</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ed70f2066fa0d8193dd82f9badfeb155b0a.png" referrerpolicy="no-referrer"></p><p>不知道 GitHub 最近頻發故障是否跟升級 MySQL 有關？<br><u><em><a href="https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0" target="news">GitHub.com 跑了 1200 多台 MySQL 主機，如何無縫升級到 8.0？</a></em></u></p><p><em>延伸閲讀：<u><a href="https://www.oschina.net/news/188164/github-recent-service-disruptions" target="news">GitHub 解釋近期頻繁宕機原因：MySQL 不堪重負</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 10 Jan 2024 02:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/275025/github-incident-20230109</guid>
            <link>https://www.oschina.net/news/275025/github-incident-20230109</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
