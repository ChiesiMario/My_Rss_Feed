<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 12 Dec 2023 14:08:28 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[雲原生週刊：Kubernetes v1.29 新特性一覽]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>開源項目推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwerf%2Fkubedog" title="kubedog" target="_blank">kubedog</a></h3><p>Kubedog 是一個用於在 CI/CD 部署管道中監視和跟蹤 Kubernetes 資源的庫。</p><p>這個庫被用於 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwerf%2Fwerf" title="werf CI/CD" target="_blank">werf CI/CD</a> 工具中，在部署過程中跟蹤資源。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frunwhen-contrib%2Frunwhen-local" title="RunWhen Local" target="_blank">RunWhen Local</a></h3><p>runwhen-local 是一個工具，用於在本地環境中運行 runwhen 腳本。runwhen 是一個靈活的任務調度工具，可以根據條件和時間表來執行任務。通過 runwhen-local，開發者可以在本地測試和調試 runwhen 腳本，以確保其正確運行。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewharf%2Fkubegateway" title="KubeGateway" target="_blank">KubeGateway</a></h3><p>kube-gateway 是字節跳動內部管理海量 kubernetes 集羣的最佳實踐。 它是為 kube-apiserver 的 HTTP2 流量專門設計並定製的七層負載均衡代理。 目標是為海量的大規模 kubernetes 集羣（千級 node 以上）提供靈活的穩定的流量治理方案。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fflannel-io%2Fflannel" title="flannel" target="_blank">flannel</a></h3><p>Flannel 是為 Kubernetes 設計的一種簡單且易於配置的第三層網絡結構的解決方案。</p><h2>文章推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmoelove.info%2F2023%2F12%2F10%2FKubernetes-v1.29-%25E6%2596%25B0%25E7%2589%25B9%25E6%2580%25A7%25E4%25B8%2580%25E8%25A7%2588%2F" target="_blank">Kubernetes v1.29 新特性一覽</a></h3><p>這篇文章介紹了 Kubernetes v1.29 版本的新特性。該版本包含了 49 個主要的更新，其中有 19 個增強功能進入 Alpha 階段，19 個升級到 Beta 階段，還有 11 個升級到穩定版。</p><p>文章重點介紹了兩個重要的特性：基於 CEL 的 CRD 規則校驗和為動態和靜態分配預留 NodePort 端口範圍。基於 CEL 的 CRD 規則校驗是一種在 CRD 聲明中編寫校驗規則的方式，簡化了開發和維護成本。而為動態和靜態分配預留 NodePort 端口範圍的特性解決了在創建 NodePort 時可能產生的端口衝突問題。總體而言，Kubernetes v1.29 版本的新特性為用户提供了更好的功能擴展和更可靠的輸入校驗。</p><h3>[Kubernetes：Pod 和 WorkerNodes – 控制 Pod 在節點上的放置</h3><p>](<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frtfm.co.ua%2Fen%2Fkubernetes-pods-and-workernodes-control-the-placement-of-the-pods-on-the-nodes%2F" target="_blank">https://rtfm.co.ua/en/kubernetes-pods-and-workernodes-control-the-placement-of-the-pods-on-the-nodes/</a>)</p><p>這篇文章介紹了在 Kubernetes 中如何控制 Pods 在 WorkerNodes 上的部署位置。它提供了四種主要的方法來實現這種控制：</p><ul><li>配置節點</li><li>Taints 和 Tolerations</li><li>配置 Pod 本身</li><li>Pod 親和性和反親和性</li></ul><p>此外，文章還提到了 Pod 拓撲分佈約束（Pod Topology Spread Constraints），即根據失敗域（regions、可用區或節點）的規則來放置 Pod。</p><p>文章還提供了一些使用 kubectl explain 命令來查看相關參數和資源文檔的技巧。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40geoffrey.muselli%2Fargocd-multi-tenancy-strategy-94d72183c94" title="ArgoCD：多租户策略" target="_blank">ArgoCD：多租户策略</a></h3><p>這篇文章介紹了使用 ArgoCD 實現多租户策略的方法。在使用 ArgoCD 時，通常會允許所有用户自由操作，直到進入生產環境後才意識到某個人通過刪除應用程序而刪除了命名空間或 CRD。為瞭解決這個問題，需要使用訪問控制和多租户策略。文章詳細介紹瞭如何利用 ArgoCD 的原生功能實現多租户策略，並提供了一個示例來演示如何在大型組織中使用企業敏捷框架（例如 SAFe）來實施。文章還討論了 ArgoCD 中的 AppProject、RBAC 和命名空間等概念，以及如何配置和使用它們來實現多租户策略。最後，文章提供了一個具體的示例，展示瞭如何根據團隊和項目的需求來配置 AppProject 和 RBAC。</p><h2>雲原生動態</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F05%2Fkyverno-completes-third-party-security-audit%2F" title="Kyverno 完成第三方安全審計" target="_blank">Kyverno 完成第三方安全審計</a></h3><p>Kyverno 項目宣佈完成了第三方安全審計。該審計是由 Ada Logics 與 Kyverno 維護人員、開源技術改進基金合作進行，由 CNCF 資助。</p><p>該安全審計是一個全面的安全審計，有以下四個目標：</p><ul><li>為 Kyverno 定義一個正式的威脅模型。</li><li>對代碼進行手動安全漏洞審計。</li><li>根據威脅模型評估 Kyverno 的模糊測試套件。</li><li>針對 SLSA 評估 Kyverno 的供應鏈風險。</li></ul><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 11:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10320847</guid>
            <link>https://my.oschina.net/u/4197945/blog/10320847</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[.NET 8 極致性能優化 - Reflection（反射）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1><span><strong><span style="color:#3c70c6">前言</span></strong></span></h1><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>反射一直是性能的瓶頸，所以無論哪個.NET 版本反射的優化必然少不了。主要是集中在兩個方面優化，分配和緩存。.NET8 自然也不例外。本篇看下。</span></p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">原文:<u><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5NDYwNjU4MA%3D%3D%26mid%3D2247485722%26idx%3D1%26sn%3Da126d8687afbc4b980533ec7fd239026%26chksm%3Dc01c4481f76bcd97a92c031859b0327a4460f7b4c73dad11cb0f45fa9c283954e5c95f442eec%26token%3D322944710%26lang%3Dzh_CN%23rd" rel="nofollow" target="_blank">.NET8 極致性能優化 Reflection</a></strong></u></p><span id="OSC_h1_2"></span><h1><span><strong><span style="color:#3c70c6">概述</span></strong></span></h1><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>比如針對 GetCustomAttributes 通過反射獲取屬性的優化，以下例子</span></p><pre><code><span><em>// dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</em></span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">object</span>[] <span style="color:#dd1144">GetCustomAttributes</span>()</span> =&gt; <span style="color:#ca7d37">typeof</span>(C).GetCustomAttributes(<span style="color:#ca7d37">typeof</span>(MyAttribute), inherit: <span style="color:#0e9ce5">true</span>);</span></code><code><span>    [<span style="color:#afafaf">My(Value1 = 1, Value2 = 2)</span>]</span></code><code><span><span style="color:#ca7d37">class</span><span style="color:#dd1144">C</span> { }</span></code><code><span>    [<span style="color:#afafaf">AttributeUsage(AttributeTargets.All)</span>]</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">MyAttribute</span> : <span style="color:#dd1144">Attribute</span></span></code><code><span>    {</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">int</span> Value1 { <span style="color:#ca7d37">get</span>; <span style="color:#ca7d37">set</span>; }</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">int</span> Value2 { <span style="color:#ca7d37">get</span>; <span style="color:#ca7d37">set</span>; }</span></code><code><span>    }</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET7 和.NET8 明顯的差異，它主要是優化了</span><span>避免分配一個 object[1]數組來設置屬性的值</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>運行時</th><th>平均值</th><th>比率</th><th>分配</th><th>分配比率</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetCustomAttributes</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1,287.1 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">296 B</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetCustomAttributes</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">994.0 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.77</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">232 B</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.78</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">其它的比如減少反射堆棧中的分配，比如通過更自由的 spans。改進了 Type 上的泛型處理，從而提升各種與泛型相關的成員性能，比如 GetGenericTypeDefinition，它的結果現在被緩存在了 Type 對象上​​​​​​​</p><pre><code><span><em>// dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</em></span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span> Type _type = <span style="color:#ca7d37">typeof</span>(List&lt;<span style="color:#ca7d37">int</span>&gt;);</span></code><code><span>&nbsp;&nbsp;&nbsp;&nbsp;<span><span style="color:#ca7d37">public</span>&nbsp;Type&nbsp;<span style="color:#dd1144">GetGenericTypeDefinition</span>()</span>&nbsp;=&gt;&nbsp;_type.GetGenericTypeDefinition();</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET7 和.NET8 如下</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>運行時</th><th>平均值</th><th>比</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetGenericTypeDefinition</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">47.426 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">GetGenericTypeDefinition</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">3.289 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.07</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span><span style="background-color:#ffffff">這</span>些<span style="background-color:#ffffff">都是細枝末節，影響反射性能最大的一塊是 MethodBase.Invoke。</span><span style="background-color:#ffffff">當在編譯的時候，知道方法的簽名並且通過反射來調用方法。</span><span style="background-color:#ffffff">就可以通過使用</span></span><span style="background-color:#ffffff">CreateDelegate</span><span>來獲取和緩存該方法的委託，然後通過該委託執行所有的調用。從而實現性</span><span>能最佳化，但是如果在編譯的時候你不知道</span><span>方法的簽名，則需要依賴動態的方法。比如 MethodBase.Invoke，這個方法降低性能並且更耗</span><span>時。一些比較瞭解.NET 開</span><span>發的人員會用 emit 避免這種開銷。.NET7 裏面採用這種方式。.NET8 裏面，為許多這樣的情況進行了改進，以前，emitter 總是生成可以容納 ref/out 參數的代碼，但許多方法不提供這樣的參數，當不需要考慮這些因素時，生成的代碼可以更高效。</span>​​​​​​​</p><pre><code><span><em>// If you have .NET 6 installed, you can update the csproj to include a net6.0 in the target frameworks, and then run:</em></span></code><code><span><em>//     dotnet run -c Release -f net6.0 --filter "*" --runtimes net6.0 net7.0 net8.0</em></span></code><code><span><em>// Otherwise, you can run:</em></span></code><code><span><em>//     dotnet run -c Release -f net7.0 --filter "*" --runtimes net7.0 net8.0</em></span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Attributes;</span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Running;</span></code><code><span><span style="color:#ca7d37">using</span> System.Reflection;</span></code><code><span>BenchmarkSwitcher.FromAssembly(<span style="color:#ca7d37">typeof</span>(Tests).Assembly).Run(args);</span></code><code><span>[<span style="color:#afafaf">HideColumns(<span>"Error"</span>, <span>"StdDev"</span>, <span>"Median"</span>, <span>"RatioSD"</span>)</span>]</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span style="color:#ca7d37">private</span> MethodInfo _method0, _method1, _method2, _method3;</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args1 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">1</span> };</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args2 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">2</span>, <span style="color:#0e9ce5">3</span> };</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args3 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">4</span>, <span style="color:#0e9ce5">5</span>, <span style="color:#0e9ce5">6</span> };</span></code><code><span>    [<span style="color:#afafaf">GlobalSetup</span>]</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Setup</span>()</span></span></code><code><span>    {</span></code><code><span>        _method0 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod0"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method1 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod1"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method2 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod2"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method3 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod3"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>    }</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method0</span>()</span> =&gt; _method0.Invoke(<span style="color:#0e9ce5">null</span>, <span style="color:#0e9ce5">null</span>);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method1</span>()</span> =&gt; _method1.Invoke(<span style="color:#0e9ce5">null</span>, _args1);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method2</span>()</span> =&gt; _method2.Invoke(<span style="color:#0e9ce5">null</span>, _args2);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>] <span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Method3</span>()</span> =&gt; _method3.Invoke(<span style="color:#0e9ce5">null</span>, _args3);</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod0</span>()</span> { }</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod1</span>(<span><span style="color:#ca7d37">int</span> arg1</span>)</span> { }</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod2</span>(<span><span style="color:#ca7d37">int</span> arg1, <span style="color:#ca7d37">int</span> arg2</span>)</span> { }</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod3</span>(<span><span style="color:#ca7d37">int</span> arg1, <span style="color:#ca7d37">int</span> arg2, <span style="color:#ca7d37">int</span> arg3</span>)</span> { }</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET6 以及 7 和 8 的情況分別如下：</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>運行時</th><th>平均值</th><th>比率</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">91.457 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">7.205 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.08</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">5.719 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.06</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method1</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">132.832 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method1</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">26.151 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.20</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method1</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">21.602 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.16</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method2</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">172.224 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method2</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">37.937 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.22</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method2</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">26.951 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.16</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method3</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 6.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">211.247 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method3</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 7.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">42.988 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.20</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">Method3</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">.NET 8.0</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">34.112 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.16</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">這裏有一些問題，每次調用都會涉及到一些性能開銷，每次調用都會重複。如果我們可以提取這些重複性的工作，對它們進行緩存。就可以實現更好的性能。.NET8 裏面通過 MethodInvoker 和 ConstructorInvoker 類型中實現了這些功能。這些並沒有包含所有 MethodBase.Invoke 處理的不常見錯誤（如特別識別和處理 Type.Missing），但對於其他所有情況，它為優化在構建時未知簽名的方法的重複調用提供了一個很好的解決方案。​​​​​​​</p><pre><code><span><em>// dotnet run -c Release -f net8.0 --filter "*"</em></span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Attributes;</span></code><code><span><span style="color:#ca7d37">using</span> BenchmarkDotNet.Running;</span></code><code><span><span style="color:#ca7d37">using</span> System.Reflection;</span></code><code><span>BenchmarkSwitcher.FromAssembly(<span style="color:#ca7d37">typeof</span>(Tests).Assembly).Run(args);</span></code><code><span>[<span style="color:#afafaf">HideColumns(<span>"Error"</span>, <span>"StdDev"</span>, <span>"Median"</span>, <span>"RatioSD"</span>)</span>]</span></code><code><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">class</span><span style="color:#dd1144">Tests</span></span></code><code><span>{</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span> _arg0 = <span style="color:#0e9ce5">4</span>, _arg1 = <span style="color:#0e9ce5">5</span>, _arg2 = <span style="color:#0e9ce5">6</span>;</span></code><code><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">readonly</span><span style="color:#ca7d37">object</span>[] _args3 = <span style="color:#ca7d37">new</span><span style="color:#ca7d37">object</span>[] { <span style="color:#0e9ce5">4</span>, <span style="color:#0e9ce5">5</span>, <span style="color:#0e9ce5">6</span> };</span></code><code><span><span style="color:#ca7d37">private</span> MethodInfo _method3;</span></code><code><span><span style="color:#ca7d37">private</span> MethodInvoker _method3Invoker;</span></code><code><span>    [<span style="color:#afafaf">GlobalSetup</span>]</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">Setup</span>()</span></span></code><code><span>    {</span></code><code><span>        _method3 = <span style="color:#ca7d37">typeof</span>(Tests).GetMethod(<span style="color:#dd1144">"MyMethod3"</span>, BindingFlags.NonPublic | BindingFlags.Static);</span></code><code><span>        _method3Invoker = MethodInvoker.Create(_method3);</span></code><code><span>    }</span></code><code><span>    [<span style="color:#afafaf">Benchmark(Baseline = true)</span>] </span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MethodBaseInvoke</span>()</span> =&gt; _method3.Invoke(<span style="color:#0e9ce5">null</span>, _args3);</span></code><code><span>    [<span style="color:#afafaf">Benchmark</span>]</span></code><code><span><span><span style="color:#ca7d37">public</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MethodInvokerInvoke</span>()</span> =&gt; _method3Invoker.Invoke(<span style="color:#0e9ce5">null</span>, _arg0, _arg1, _arg2);</span></code><code><span><span><span style="color:#ca7d37">private</span><span style="color:#ca7d37">static</span><span style="color:#ca7d37">void</span><span style="color:#dd1144">MyMethod3</span>(<span><span style="color:#ca7d37">int</span> arg1, <span style="color:#ca7d37">int</span> arg2, <span style="color:#ca7d37">int</span> arg3</span>)</span> { }</span></code><code><span>}</span></code></pre><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>.NET8 的情況如下</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:system-ui,-apple-system,BlinkMacSystemFont,&quot;Helvetica Neue&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei UI&quot;,&quot;Microsoft YaHei&quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:676.989px; word-spacing:0px"><tbody><tr><th>方法</th><th>平均值</th><th>比率</th></tr></tbody><tbody><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">MethodBaseInvoke</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">32.42 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">1.00</td></tr><tr><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">MethodInvokerInvoke</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">11.47 ns</td><td style="border-collapse:collapse; border-color:#c0c0c0; border-style:solid; border-width:1px">0.35</td></tr></tbody></table><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span>這些類型被 Microsoft.Extensions.DependencyInjection.Abstractions 中的 ActivatorUtilities.CreateFactory 方法使用，以進一步提高 DI 服務構建性能。通過添加額外的緩存層進一步改進，進一步避免每次構建時的反射。</span></p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left">作者:jianghupt</p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><strong>歡迎關注公眾號 (jianghupt），文章首發地。</strong></p><p style="color:#4a4a4a; margin-left:0; margin-right:0; text-align:left"><span><img alt="" height="430" src="https://oscimg.oschina.net/oscnet/up-3243ba74c89867eabc4277de83aa83aa7bb.png" width="430" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5407571/blog/10320411</guid>
            <link>https://my.oschina.net/u/5407571/blog/10320411</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FastUI —— 更快地構建更好的 UI]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FastUI 是一種構建由聲明式 Python 代碼來構建 Web 應用程序用户界面的新方法。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>這意味着：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><strong>如果你是一名 Python 開發人員</strong>，可以使用 React 構建響應式 Web 應用程序，而無需編寫任何 JavaScript 代碼，也無需接觸<code>npm</code>。</li><li><strong>如果你是前端開發人員</strong>，可以專注於構建真正可重用的神奇組件，無需為每個視圖複製粘貼組件。</li><li><strong>對於每個人來説&nbsp;</strong>—— 真正的關注點分離，後端定義了整個應用程序；而前端可以自由地僅實現用户界面</li></ul><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FastUI 的核心是一組匹配的&nbsp;<a href="https://docs.pydantic.dev/">Pydantic</a>&nbsp;模型和 TypeScript </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>interfaces<span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>，允許你定義用户界面。其在構建時由 TypeScript 和 Pyright/mypy 進行驗證，並在運行時由 Pydantic 進行驗證。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FastUI 由 4 部分組成：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><a href="https://pypi.python.org/pypi/fastui"><code>fastui</code>PyPI 包</a>— UI 組件的 Pydantic 模型和一些實用程序。雖然它與<a href="https://fastapi.tiangolo.com/">FastAPI</a>配合良好，但它不依賴於 FastAPI，並且其中大部分可以與任何 Python Web 框架一起使用。</li><li><a href="https://www.npmjs.com/package/@pydantic/fastui"><code>@pydantic/fastui</code>npm 包</a>— 一個 React TypeScript 包，讓你在實現自己的組件時重用 FastUI 的機制和類型</li><li><a href="https://www.npmjs.com/package/@pydantic/fastui-bootstrap"><code>@pydantic/fastui-bootstrap</code>npm 包</a> — 使用&nbsp;<a href="https://getbootstrap.com/">Bootstrap</a>&nbsp;實現/定製所有 FastUI 組件</li><li><a href="https://www.jsdelivr.com/package/npm/@pydantic/fastui-prebuilt"><code>@pydantic/fastui-prebuilt</code>npm 包</a>（在&nbsp;<a href="https://www.jsdelivr.com/package/npm/@pydantic/fastui-prebuilt">jsdelivr.com CDN</a>&nbsp;上提供）提供了 FastUI React 應用程序的預構建版本，因此你無需安裝任何 npm 包或自行構建任何內容即可使用它。Python 包提供了一個簡單的 HTML 頁面來服務此應用程序。</li></ul><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>以下是一個簡單但完整的 FastAPI 應用程序，它使用 FastUI 來顯示一些用户配置文件：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>from datetime import date

from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
from fastui import FastUI, AnyComponent, prebuilt_html, components as c
from fastui.components.display import DisplayMode, DisplayLookup
from fastui.events import GoToEvent, BackEvent
from pydantic import BaseModel, Field

app = FastAPI()


class User(BaseModel):
    id: int
    name: str
    dob: date = Field(title='Date of Birth')


# define some users
users = [
    User(id=1, name='John', dob=date(1990, 1, 1)),
    User(id=2, name='Jack', dob=date(1991, 1, 1)),
    User(id=3, name='Jill', dob=date(1992, 1, 1)),
    User(id=4, name='Jane', dob=date(1993, 1, 1)),
]


@app.get("/api/", response_model=FastUI, response_model_exclude_none=True)
def users_table() -&gt; list[AnyComponent]:
    """
    Show a table of four users, `/api` is the endpoint the frontend will connect to
    when a user fixes `/` to fetch components to render.
    """
    return [
        c.Page(  # Page provides a basic container for components
            components=[
                c.Heading(text='Users', level=2),  # renders `&lt;h2&gt;Users&lt;/h2&gt;`
                c.Table[User](  # c.Table is a generic component parameterized with the model used for rows
                    data=users,
                    # define two columns for the table
                    columns=[
                        # the first is the users, name rendered as a link to their profile
                        DisplayLookup(field='name', on_click=GoToEvent(url='/user/{id}/')),
                        # the second is the date of birth, rendered as a date
                        DisplayLookup(field='dob', mode=DisplayMode.date),
                    ],
                ),
            ]
        ),
    ]


@app.get("/api/user/{user_id}/", response_model=FastUI, response_model_exclude_none=True)
def user_profile(user_id: int) -&gt; list[AnyComponent]:
    """
    User profile page, the frontend will fetch this when the user visits `/user/{id}/`.
    """
    try:
        user = next(u for u in users if u.id == user_id)
    except StopIteration:
        raise HTTPException(status_code=404, detail="User not found")
    return [
        c.Page(
            components=[
                c.Heading(text=user.name, level=2),
                c.Link(components=[c.Text(text='Back')], on_click=BackEvent()),
                c.Details(data=user),
            ]
        ),
    ]


@app.get('/{path:path}')
async def html_landing() -&gt; HTMLResponse:
    """Simple HTML page which serves the React app, comes last as it matches all paths."""
    return HTMLResponse(prebuilt_html(title='FastUI Demo'))</code></pre></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/fastui</guid>
            <link>https://www.oschina.net/p/fastui</link>
        </item>
        <item>
            <title>
                <![CDATA[🎁有獎問答 | 聊聊 NGINX 向雲原生演進那點兒事]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4700705_2331501">高手問答第 311 期 —— 聊聊 NGINX 向雲原生演進那點兒事</a><div class="ui red label horizontal" data-tooltip="置頂">頂</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4700705" class="__user"><span>小白兔愛吃大灰狼</span></a> 發佈於，今天 11:35
                    </div><div class="item">閲讀 153</div><div class="item collect-btn " data-id="2331501" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331501" data-obj-type="2">0</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4700705_2331501#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">0</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手問答</a></div><div class="content" id="articleContent"><p><span><span>據 Gartner 預測，到 2025 年，雲原生架構將成為超過 95% 的新數字計劃基礎，高於 2021 年的不到 40%，雲原生架構市場佔有率不斷提高。而如今，全球半數以上（55%） 的網站都基於 NGINX 運行，差不多相同比例 (53.7%) 的中國網站在 NGINX 開源版上運行。而 NGINX 存在難於動態配置、管理功能影響業務等問題，為瞭解決這些問題，OpenNJet 由此誕生。</span></span></p><p><span><span>OpenNJet 基於 NGINX1.19 基礎 fork 並獨立演進，具有高性能、穩定、易擴展的特點，通過數據面與控制面的隔離，能夠在不重啓進程的情況下基於動態配置能力進行配置的實時更新。最近還推出了 OpenNJet K8s Ingress Controller 1.0，基於 OpenNJet 的動態特性、高性能實現，彌補了 NGINX 在雲原生場景中不足，而且提供了豐富的流量管理功能，如動態 location、host/path 路由、負載均衡、動態 upstream、金絲雀發佈、SNI 等。</span></span></p><p><strong><span><span>OSCHINA 本期高手問答（12 月 13 日 - 12 月 19 日）我們請來了嘉賓<a href="https://my.oschina.net/u/6606114" rel="nofollow">單雷老師</a>和大家一起聊聊 NGINX 向雲原生演進那點兒事。</span></span></strong></p><p><strong><span><span>可討論的問題包括但不限於</span></span></strong><strong><span><span>：</span></span></strong></p><ul><li><span><span style="background-color:white"><span>OpenNJet 和 NGINX 是什麼關係？</span></span></span></li><li><span><span style="background-color:white"><span>什麼是雲原生應用引擎？OpenNJet 的有哪些優勢</span></span></span></li><li><span><span style="background-color:white"><span>我們如何解決數據面控制面隔離、國密、動態配置等問題？</span></span></span></li><li><span><span style="background-color:white"><span>讀 NGINX/OpenNJet 源碼的建議</span></span></span></li><li><span><span style="background-color:white"><span>如何上手開發一個開源項目？</span></span></span></li></ul><p><span><span style="background-color:white"><span>其他關於 NGINX、OpenNJet 的更多內容，也歡迎積極提問。</span></span></span></p><h2><span><span style="background-color:white"><span><strong>嘉賓介紹</strong></span></span></span></h2><p><img alt="" height="534" src="https://oscimg.oschina.net/oscnet/up-774dc1b75df829000896339c602574ff319.jpg" width="400" referrerpolicy="no-referrer"></p><p><span><span><strong><span><span style="color:#7030a0">通明智雲產品總監，單雷</span></span></strong></span></span></p><p><span><span>20 年的 IT 行業經驗，精通雲原生以及高性能應用引擎技術。曾在亞信科技歷任研發主管、首席架構師等職務，並主導多個雲原生、高性能應用網關項目的設計開發工作，現任公司應用引擎產品總監。</span></span></p><hr><p><span><span style="background-color:white"><span><span>🎁</span> 為了鼓勵踴躍提問，下一代雲原生應用引擎 OpenNJet 開源社區會在問答結束後從提問者中抽取 5 名幸運會員，贈予精美棉馬甲一件。</span></span></span></p><p><img alt="" height="436" src="https://oscimg.oschina.net/oscnet/up-6f9dfb1df3b4d3c9f22f9a02a21c1be62d5.jpg" width="400" referrerpolicy="no-referrer"></p><blockquote><p><span><span>OpenNJet&nbsp;應用引擎是基於 NGINX 的面向互聯網和<strong>雲原生</strong>應用提供的運行時組態服務程序，作為底層引擎，OpenNJet 實現了 NGINX 雲原生功能增強、安全加固和代碼重構，利用<strong>動態加載機制</strong>可以實現不同的產品形態，如 Web 服務器、流媒體服務器、負載均衡、代理 (Proxy)、應用中間件、API 網關、消息隊列等產品形態等等。OpenNJet 在雲原生架構中作為數據平面，除了提供南北向通信網關的功能以外，還提供了服務網格中東西向通信能力。在原有功能基礎上增加了透明流量劫持、熔斷、遙測與故障注入等新功能特性。</span></span></p><p><span><span>Gitee：<a href="https://gitee.com/njet-rd/njet" rel="nofollow"><span><span>https://gitee.com/njet-rd/njet</span></span></a></span></span></p><p><span><span>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnjet.org.cn%2F" rel="nofollow" target="_blank">https://njet.org.cn/</a></span></span></p></blockquote><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手問答一貫的風格，不歡迎任何與主題無關的討論和噴子。</span></p><p>下面歡迎大家就 「<span><span>NGINX 向雲原生演進</span></span>」<span><span>&nbsp;</span>相關</span>問題向<span>&nbsp;<a href="https://my.oschina.net/u/6606114" rel="nofollow">單雷老師</a></span><a href="https://my.oschina.net/klblog" rel="nofollow"><strong><span style="color:#000000">&nbsp;</span></strong></a>提問，直接回帖提問既可。</p></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331501" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331501" data-obj-type="2">0</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331501" data-obj-type="2" data-url="https://www.oschina.net/question/4700705_2331501"><i class="flag red icon"></i>舉報</a></div></div>
            ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4700705_2331501</guid>
            <link>https://www.oschina.net/question/4700705_2331501</link>
        </item>
        <item>
            <title>
                <![CDATA[新技術 LINT 可強制 LLM 回答有毒問題]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美國普渡大學（Purdue University）的研究人員發佈了，一篇名為《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.04782" target="_blank"><span style="background-color:#ffffff">Make Them Spill the Beans! Coercive Knowledge Extraction from (Production) LLMs</span></a>》的論文。描述了他們通過利用大模型廠商傾向於公開與提示響應相關的概率數據的特點，設計出了一種可以打破現有 LLM 規則，使其給出「有害」回答的新穎方法。</span></p><p><span style="color:#000000">研究人員使用了一種名為 LINT (LLM interrogation) 的技術，與繞過安全提示的一般越獄方式不同的是，這種技術更具強制性。它涉及到對概率值（logits）或軟標籤（soft labels）的理解 —— 從統計學上講，其可以有效區分安全響應與有害響應。</span></p><blockquote><p><span style="color:#000000">「在我們的研究中，我們揭示了當不良行為者可以訪問模型的輸出 logits 時，LLM alignment 面臨的的一種新威脅，這是開源 LLM 和許多商業 LLM API（如某些 GPT 模型）的共同特徵。它並不依賴於製作特定的提示。相反，它利用了這樣一個事實：即使 LLM 拒絕了有毒請求，有害響應也往往隱藏在輸出 logits 的深處。通過在自動迴歸生成過程中在幾個關鍵輸出位置強行選擇排名較低的輸出&nbsp;tokens，我們可以迫使模型揭示這些隱藏的響應。我們將這一過程稱為模型審訊（model interrogation）。」</span></p></blockquote><p><span style="color:#000000">具體<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F12%2F11%2Fchatbot_models_harmful_content%2F" target="_blank">表現為</a>，LINT 使用 LLM-based classifier 向 LLM 提出一個有害的問題：比如"説明如何將槍改裝成全自動的"。然後，對響應中的前九個 tokens（如 "It's"、"It"、"We"和 "I"）進行排序，並用這些詞組創建新句子，這樣該 LLM 就會不斷生成回覆。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-a4cca4832d0d4ac8918b03eacf880f3455b.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">研究人員在創建 LINT 原型時，在一個包含 50 個有毒問題的數據集上詢問了 7 個開源 LLM 和 3 個商業 LLM。他們稱：「當模型只被審訊一次時，ASR（攻擊成功率）達到 92%，當被詢問五次時，ASR 可以達到達到 98%。」</span></p><p><span style="color:#000000">這種方法與越獄方法不同，但性能要<span style="background-color:#ffffff">遠遠優於目前最先進的兩種越獄技術：GCG 和 GPTFuzzer。</span>相比之下越獄方法的 ASR 僅為 62%，且運行時間要長&nbsp;10 到 20 倍。「通過我們的方法揭露的有害內容更加相關、完整、清晰。此外，它可以補充越獄策略，從而進一步提高攻擊性能。」</span></p><p><span style="color:#000000">更重要的是，這種技術甚至適用於根據特定任務（如代碼生成）的基礎模型定製的 LLM。研究人員還聲稱，這種技術可以用來損害隱私和安全，迫使模型公開電子郵件地址和猜測弱密碼。</span></p><p><span style="color:#000000">因此，研究人員警告稱，AI&nbsp;界在考慮是否開源 LLM 時應謹慎；並建議最好的解決方案是確保有毒內容被清除，而不是將其隱藏起來。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.04782" target="_blank">查看完整論文</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 09:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270686/lint-llm-harmful-content</guid>
            <link>https://www.oschina.net/news/270686/lint-llm-harmful-content</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Apache StreamPark 2.1.2 穩定版正式發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img height="460" src="https://oscimg.oschina.net/oscnet/up-223b657c0b3fdd8242108df64be06aa7cf7.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#333333">近日 Apache StreamPark<span>(Incubating)&nbsp;</span>社區正式發佈了 StreamPark 2.1.2 版本</span></strong><span style="color:#333333">，</span></span><span>在 2.1.2 版本中，支持了最新的 Flink 1.18，Flink Jar 類型的作業支持指定依賴，</span><span>修復了</span><span style="color:#333333">諸多 Bug 和大量改進</span><span>，穩定性和可用性進一步提升，建議所有用户升級到這個版本</span><span>。</span></p><p><span style="color:#646464"><strong><span>Github:&nbsp;</span></strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark" target="_blank">https://github.com/apache/streampark</a></p><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#646464"><strong>官&nbsp; &nbsp; &nbsp;網:&nbsp;</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstreampark.apache.org%2Fdownload" target="_blank">https://streampark.apache.org/download</a></p><p><span style="color:#444444">歡迎&nbsp;</span><strong><span style="color:#444444">使用、關注、star、fork</span></strong><span style="color:#444444">&nbsp;</span></p><h1><span>新特性解讀</span></h1><h4><span style="color:#0052ff"><span style="background-color:#0053cd"><strong>&nbsp;</strong></span><span>&nbsp; </span></span><strong>更好的支持 JAR 類型作業</strong></h4><p><span><span>在&nbsp;StreamPark 中將 Flink 作業按照開發模式分為&nbsp;Custom Code&nbsp;和 Flink SQL<span>&nbsp;</span><span>兩種類型</span>，Custom Code 是需要用户編寫代碼編譯成 JAR 類型的 Flink 作業，在以前的版本中該類型的作業不支持在 StreamPark 平台側指定作業依賴，要求用户自己解決作業需要的依賴，通常做法是需要將這些依賴打包到項目裏，生成一個 FatJar (uber-jar)。社區收到很多用户的反饋，大家普遍希望 StreamPark 平台側針對 JAR 類型的作業能像 Flink SQL 作業一樣，可以自由的指定作業的依賴。</span></span></p><p><span><span>同時，我們也看到 Apache Doris, Apache Paimon 等社區都開發了基於 Flink CDC 一鍵集成數據的組件&nbsp;</span><span style="color:#888888">(doris-flink-connector 和 paimon-action)</span><span>，該組件都提供了作業遷移的入口，但作業運行時依賴需要用户手動添加。</span></span></p><p><span><span>鑑於這些原因，在 StreamPark 2.1.2 裏，特別針對 JAR 類型的作業支持了指定依賴的能力，使得用户部署這類作業更加簡單。</span></span><span>以下是兩個示例，演示瞭如何利用該特性，來快速部署 Doris 和 Paimon 數據遷移類型的作業：</span></p><p><iframe frameborder="0" height="370" scrolling="no" src="https://player.bilibili.com/player.html?aid=280306310&amp;bvid=BV17c411d7Jy&amp;cid=1317452428&amp;p=1&amp;autoplay=0" style="box-sizing: inherit; color: rgb(51, 51, 51); font-family: -apple-system, BlinkMacSystemFont, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;, &quot;Segoe UI&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;" width="750" referrerpolicy="no-referrer"></iframe></p><p><span style="background-color:#000000; color:#ffffff">StreamPark 讓 Doris 數據集成更簡單&nbsp;</span><br> &nbsp;</p><p><iframe frameborder="0" height="370" scrolling="no" src="https://player.bilibili.com/player.html?aid=323428873&amp;bvid=BV1Sw411W7QK&amp;cid=1333574131&amp;p=1&amp;autoplay=0" style="box-sizing: inherit; color: rgb(51, 51, 51); font-family: -apple-system, BlinkMacSystemFont, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;, &quot;Segoe UI&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;" width="760" referrerpolicy="no-referrer"></iframe></p><p><span style="background-color:#000000; color:#ffffff">&nbsp;StreamPark 讓 Paimon 數據集成更簡單&nbsp;</span></p><h4><span style="color:#0052ff"><span style="background-color:#0053cd"><strong>&nbsp;</strong></span><span>&nbsp; </span></span><strong>支持 Flink 1.18</strong></h4><p style="margin-left:0; margin-right:0"><span>作為流處理開發管理框架，StreamPark 在對 Apache Flink 的支持上，一如既往的走在前列。得益於 StreamPark 良好的架構設計，使得支持一個新<span>版本</span>的 Flink 非常容易，因此我們率先支持了<span>&nbsp;</span></span><span style="color:#ff4c00"><span>Flink 1.18</span><span><span>&nbsp;</span><span style="background-color:#ffffff">[1]</span></span></span><span>。在使用上非常的簡單，用户只需要添加一個 Flink 1.18 的環境即可，作業可以自由的選擇 Flink 版本<span>。</span></span></p><p style="margin-left:0; margin-right:0"><span><span>並且本次適配了更多發行版 Flink，如 CDH 版本的 Flink, 華為雲，騰訊雲 Flink 等。</span></span></p><div style="margin-left:0px; margin-right:0px; text-align:left"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px"><div style="margin-left:0px; margin-right:0px">
          &nbsp;
         </div></div></div></div></div></div></div></div></div></div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><iframe frameborder="0" height="370" scrolling="no" src="https://player.bilibili.com/player.html?aid=264867610&amp;bvid=BV16Y41117kt&amp;cid=953529774&amp;p=1&amp;autoplay=0" style="box-sizing: inherit;" width="750" referrerpolicy="no-referrer"></iframe></p><p><span style="background-color:#000000; color:#ffffff">&nbsp;支持 Flink 多版本&nbsp;</span></p><p><span style="color:rgba(0, 0, 0, 0.9)"><span style="background-color:#0053cd"><strong><span style="color:#0053cd">&nbsp;</span></strong></span><span>&nbsp;<span>&nbsp;</span></span></span><span style="color:#0053dc"><strong>其他改進和更新</strong></span></p><ul><li><p><span style="color:#444444">修復作業狀態重新映射不生效的 Bug</span>&nbsp;<u>#2822</u></p></li><li><p>改進 Flink 版本的校驗邏輯，適配更多的&nbsp;Flink 版本&nbsp;<u>#2832</u></p></li><li><p>修復作業 「取消狀態」 下可能存在的無法發送報警信息的 Bug&nbsp;<u>#3157</u></p></li><li><p style="margin-left:0; margin-right:0"><span>修復 Ingress 訪問 Flink UI 可能存在的 404 Bug&nbsp;<u>#3302</u></span></p></li><li><p><span><span style="color:#444444">修復團隊為空，導致查詢錯誤的 Bug&nbsp;</span><u>#3365</u></span></p></li><li><p>修復作業參數解析，特定字符解析錯誤導致作業失敗的&nbsp;Bug</p></li><li><p><span style="color:#0052ff"><span style="color:#444444">修復項目編譯時 maven-wrapper 文件損壞導致失敗的 Bug</span></span></p></li><li><p><span style="color:#0052ff"><span style="color:#444444"><span style="color:#444444">Flink 作業的 Pom 信息支持&nbsp;exclusion，有效避免 JAR 衝突問題</span></span></span></p></li></ul><h1><span>Release Note</span></h1><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span><span style="color:#333333">本次 StreamPark 2.1.2 版本的，完整 Release Note 請訪問：</span><br><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstreampark.apache.org%2Fdownload%2Frelease-note%2F2.1.2" target="_blank">https://streampark.apache.org/download/release-note/2.1.2</a></span></p><h1><span style="color:#000000">感謝貢獻者</span></h1><p><span style="color:#333333"><span>StreamPark 開源社區的發展，離不開廣大用户羣體的積極反饋和宣傳佈道，更離不開貢獻者們的無私貢獻<span>，</span></span><span style="color:#333333">感謝對此版本做出貢獻的每一位貢獻者<span style="background-color:#ffffff">。</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#444444"><span style="background-color:#ffffff">特別感謝本次的 Release Manager</span>&nbsp;</span><span style="color:#ff4c00">@龔中強<span style="background-color:#ffffff">[2]</span></span><span style="color:#444444">，<span style="background-color:#ffffff; color:#444444">中強</span></span><span><span style="background-color:#ffffff; color:#444444">在<span style="background-color:#ffffff; color:#444444">發版過程中<span style="background-color:#ffffff">積極的跟蹤問題和推進進度</span>，完美勝任了此次發版工作。</span>感謝<span style="background-color:#ffffff; color:#444444">中強</span>為社區做出的貢獻，也歡迎其他<span>&nbsp;</span><span style="background-color:#ffffff">PPMC member 和&nbsp;</span>Committer 在後續的發版中擔任 Release Manager，幫助社區更快捷、高質量地完成發版。</span></span></p><h1><span>什麼是 StreamPark</span></h1><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>StreamPark 是一個流處理應用程序開發管理框架。初衷是讓流處理更簡單，旨在輕鬆構建和管理流處理應用程序，提供使用 Apache Flink 和 Apache Spark 編寫流處理應用程序的開發框架。同時 StreamPark 提供了一個流處理應用管理平台，核心能力包括但不限於應用開發、調試、交互查詢、部署、運維、實時數倉等，最初開源時項目名稱叫 StreamX ，於 2022 年 8 月更名為 StreamPark，隨後通過投票正式成為 Apache 開源軟件基金會的孵化項目。目前已有騰訊<span>、</span>百度<span>、</span>聯通<span>、天翼雲<span>、</span></span>自如<span>、</span>馬蜂窩<span>、</span>長安汽車等數百家公司生產環境使用。</span></p><h1><span style="color:#000000">🫵&nbsp;加入我們</span></h1><p><span><span style="color:#333333"><span style="background-color:#ffffff">StreamPark 社區一直以來都以用心做好一個項目為原則</span><span style="background-color:#ffffff">，</span><span style="background-color:#ffffff">高度關注項目質量</span><span style="background-color:#ffffff">，努力</span><span style="background-color:#ffffff">建設發展社區。</span><span>加入 Apache 孵化器以來，</span><span style="background-color:#ffffff">認真學習和遵循「The Apache Way」，我們將秉承更加兼容幷包的心態，迎接更多的機遇與挑戰。誠摯</span><span>歡迎更多的貢獻者參與到社區建設中來，和我們一道攜手共建。</span></span></span></p><p><span><span style="color:#333333"><strong>💻 項目地址：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark" target="_blank">https://github.com/apache/streampark</a></span></p><p><span><span style="color:#333333"><strong>🧐 提交問題和建議：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fissues" target="_blank">https://github.com/apache/streampark/issues</a></span></p><p><span><span style="color:#333333"><strong>🥁 貢獻代碼：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fpulls" target="_blank">https://github.com/apache/streampark/pulls</a></span></p><p><span><span style="color:#333333"><strong><strong>📮&nbsp;</strong>Proposal：</strong></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FINCUBATOR%2FStreamPark%2BProposal" target="_blank">https://cwiki.apache.org/confluence/display/INCUBATOR/StreamPark+Proposal</a></span></p><p><span><span style="color:#333333"><strong>📧 訂閲社區開發郵件列表：</strong></span><span style="color:#0080ff">dev@streampark.apache.org</span><span style="color:#0080ff">&nbsp;</span><span style="color:#0080ff"><span style="color:#ff4c00">[3]</span>&nbsp;</span></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span><span style="color:#444444"><strong>💁‍♀️</strong></span><span style="color:#444444"><strong>社區溝通：</strong></span></span></p><p><img height="500" src="https://oscimg.oschina.net/oscnet/up-07a7e385d033088436872afd0571e4c3482.png" width="900" referrerpolicy="no-referrer"></p><p><span style="color:#444444"><strong>參考資料</strong></span></p><p><span><em><span style="color:#666666">[1]&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.18%2Frelease-notes%2Fflink-1.18" target="_blank">https://nightlies.apache.org/flink/flink-docs-release-1.18/release-notes/flink-1.18</a></span></em></span></p><p><em><span style="color:#666666">[2]&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGOODBOY008" target="_blank">https://github.com/GOODBOY008</a></span></em></p><p><span><em><span style="color:#666666">[3]&nbsp;<em><span>mailto:dev@streampark.apache.org</span></em></span></em></span><br> &nbsp;</p><p><span style="color:#333333">祝大家安裝、升級順利~~&nbsp;&nbsp;</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270652/apache-streampark-2-1-2-released</guid>
            <link>https://www.oschina.net/news/270652/apache-streampark-2-1-2-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[鎧俠向 Linux 基金會捐贈 Software-Enabled Flash SDK]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#121212">幾年前從東芝分離出來的存儲公司 Kioxia（</span>鎧俠<span style="background-color:#ffffff; color:#121212">）向 Linux 基金會捐贈了一個軟件開發工具包 (SDK)，用於建立 Software-Enabled Flash SDK。</span></p><p><span style="background-color:#ffffff; color:#121212">Linux 基金會發布<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fsoftware-enabled-flash-announces-software-development-kit-sdk" target="_blank">公告稱</a>，「SEF SDK 的發佈是存儲技術領域的一個重要里程碑......SEF 項目對 KIOXIA 突破性地捐贈軟件定義閃存原生 SDK 表示熱烈歡迎，這將為開發人員提供前所未有的能力，使他們能夠為閃存存儲（flash storage）應用開發定製的獨特軟件。」</span></p><p><img alt="" height="228" src="https://oscimg.oschina.net/oscnet/up-67690b065c2207474d1a67124aa3ef403da.png" width="300" referrerpolicy="no-referrer">&nbsp; &nbsp;<img alt="" height="228" src="https://oscimg.oschina.net/oscnet/up-1056c78ed4258dcb84497a6e896204821c0.jpg" width="300" referrerpolicy="no-referrer"></p><p>該 SEF SDK 包括示例代碼和文檔，以充分利用 flash media control 的潛力；包括 WAF 減少、延遲控制、對 ZNS 和 FDP 或 Block 等多種協議的支持等。</p><p>SEF 項目旨在通過加強對驅動器的管理、增強工作負載隔離、加強延遲控制以及實現對閃存管理的更多&nbsp;host-control，在現代數據中心中開闢新的用途並最大限度地發揮基於閃存的存儲潛力。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270608/software-enabled-flash-sdk</guid>
            <link>https://www.oschina.net/news/270608/software-enabled-flash-sdk</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[芯瞳正式加入 openKylin，為社區貢獻高質量的國產 GPU 解決方案！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，芯瞳半導體技術（山東）有限公司（以下簡稱「芯瞳」），簽署 openKylin 社區 CLA（Contributor License Agreement 貢獻者許可協議），正式加入 openKylin 開源社區。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-4c9b13fca5452f4a217f1494d816e96a799.png" width="829" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>芯瞳（Sietium）成立於 2019 年，是一家自主設計研發 GPU 芯片及 GPU 解決方案的高科技公司，以行業先進的計算和圖形渲染平台為依託，用高質量的產品和服務為雲端、終端客户提供可持續發展的國產 GPU 解決方案；為數字時代的創新與發展提供算力支撐，構建自由算力的文明世界。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-6914c94ad47861f5f685cb96e9bc21450f1.png" width="940" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong><span>加入 openKylin 社區後，芯瞳將參與維護社區 GPU SIG 和 Wayland SIG</span></strong><span>。<strong>憑藉其自研的 GPU 顯卡和深厚的行業經驗，優化 openKylin 環境中顯卡驅動的兼容性，確保與芯瞳顯卡的完美適配</strong>。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>在 openKylin 平台上，芯瞳顯卡將展現其在圖形顯示、渲染、視頻編解碼和大規模計算等方面的優勢，以此提升 openKylin 的用户體驗，並提供持續的 GPU 產品升級和技術支持，為用户提供安全可靠的使用體驗。具體計劃如下：</span></p><ul><li><p style="margin-left:0; margin-right:0"><span>積極參與社區合作，緊密關注社區的發展動態，與社區成員攜手推動 openKylin 社區的生態及品牌建設，努力構建一個健康的生態環境，為開源生態的發展貢獻力量。</span></p></li><li><p style="margin-left:0; margin-right:0"><span>尋求與社區的技術合作，通過聯合調試等方式，使 openKylin 的相關產品能更好地兼容並適應芯瞳的全新系列顯卡，從而提高產品的穩定性和性能。</span></p></li><li><p style="margin-left:0; margin-right:0"><span>在應用層面，芯瞳將持續優化軟件算法，提高系統效率，充分發掘 openKylin 在芯瞳顯卡平台上的性能潛力，從而提升整體性能，為用户提供卓越的產品體驗。</span></p></li></ul><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>通過這一系列的舉措，芯瞳將與 openKylin 社區並肩前行，共同推動 openKylin 社區生態良好發展，為用户帶來更多的創新和驚喜。同時，芯瞳期待與社區成員進行深入的交流和分享，以推動技術的進步和產業的協同發展，共同為中國開源生態的繁榮作出貢獻。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270607</guid>
            <link>https://www.oschina.net/news/270607</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Facebook 開源 StyleX —— 在 JavaScript 中寫 CSS]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Meta（原 Facebook）<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstylexjs.com%2Fblog%2Fintroducing-stylex%2F" target="_blank">開源</a></u>了全新的 CSS-in-JS 庫 StyleX。</p><p><img src="https://oscimg.oschina.net/oscnet/up-30f683ba9535a9f16ce5e615736da0460cd.png" referrerpolicy="no-referrer"></p><blockquote><p><em>GitHub 地址：<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffacebook%2Fstylex" target="_blank">https://github.com/facebook/stylex</a></u></strong></em></p></blockquote><p>官方介紹道，StyleX 是一個富有表現力、具有確定性、可靠且可擴展的樣式系統。它通過使用編譯時 (compile-time) 工具融合了靜態 CSS 的性能和可擴展性。</p><p>此外，StyleX 不僅僅是一個基於編譯器的 CSS-in-JS 庫，它經過精心設計，可以滿足大型應用程序、可複用組件庫和靜態類型代碼庫的要求。Meta 旗下多款產品如 Facebook、WhatsApp、Instagram、Workplace、Threads 等都在使用 StyleX 作為其 CSS 樣式解決方案。</p><p>StyleX 主要特性</p><ul><li><p><strong>快速</strong>：StyleX 在編譯時和運行時都具備高效的性能。Babel 轉換不會對構建過程產生顯著影響。在運行時，StyleX 避免了使用 JavaScript 插入樣式的開銷，並僅在必要時高效地組合類名字符串。生成的 CSS 經過優化，確保即使是大型網站的樣式也能被瀏覽器快速解析。</p></li><li><p><strong>可擴展</strong>：StyleX 旨在適應像 Meta 這樣的超大型代碼庫。通過原子構建和文件級緩存，Babel 插件能夠處理數萬個組件在編譯時的樣式處理。由於 StyleX 設計為封裝樣式，它允許在隔離環境中開發新組件，並期望一旦在其他組件中使用時能夠可預測地呈現。</p></li><li><p><strong>可預測性</strong>：StyleX 會自動管理 CSS 選擇器的特異性，以確保生成的規則之間不會發生衝突。它為開發人員提供了一個可靠地應用樣式的系統，並確保「最後應用的樣式始終生效」。</p></li><li><p><strong>類型安全</strong>：使用 TypeScript 或 Flow 類型來約束組件接受的樣式，每個樣式屬性和變量都具有完全的類型定義。這有助於提高代碼的可讀性和可維護性，同時減少潛在的錯誤和衝突。</p></li><li><p><strong>樣式去重</strong>：StyleX 鼓勵在同一文件中編寫樣式和組件。這種方法有助於使樣式在長期內更具可讀性和可維護性。StyleX 能夠利用靜態分析和構建時工具來跨組件去重樣式，並刪除未使用的樣式。</p></li><li><p><strong>可測試性</strong>：StyleX 可以配置為輸出調試類名，而不是功能性的原子類名。這可以用於生成快照，以便在對設計進行輕微更改時不會經常變化。通過這種方式，開發人員可以更輕鬆地測試和驗證樣式的正確性，從而提高開發效率和產品質量。</p></li></ul><p><strong>示例代碼</strong></p><pre><code class="language-javascript">import stylex from '@stylexjs/stylex';

const styles = stylex.create({
  root: {
    padding: 10,
  },
  element: {
    backgroundColor: 'red',
  },
});

const styleProps = stylex.apply(styles.root, styles.element);</code></pre><p><strong>下面是一個按鈕組件的示例代碼</strong></p><pre><code class="language-javascript">import * as stylex from "@stylexjs/stylex";

const styles = stylex.create({
  base: {
    appearance: "none",
    borderWidth: 0,
    borderStyle: "none",
    backgroundColor: "blue",
    color: "white",
    borderRadius: 4,
    paddingBlock: 4,
    paddingInline: 8,
  },
});

export default function Button({
  onClick,
  children,
}: Readonly&lt;{
  onClick: () =&gt; void;
  children: React.ReactNode;
}&gt;) {
  return (
    &lt;button {...stylex.props(styles.base)} onClick={onClick}&gt;
      {children}
    &lt;/button&gt;
  );
}</code></pre></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270597/facebook-stylex-css-in-js</guid>
            <link>https://www.oschina.net/news/270597/facebook-stylex-css-in-js</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Arc 瀏覽器開始 Windows 版 Beta 測試]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 11 日，Arc 瀏覽器開始 Windows 版 Beta 測試，第一批邀請已在加入等待隊列的用户中篩選併發送完畢。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e387f48e7934b2c6d34f92595dbaea17a39.png" referrerpolicy="no-referrer"></p><p>感興趣的用户可以在上線的&nbsp;<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.isarconwindowsyet.com%2F" target="_blank">IsArcOnWindowsYet</a></u>&nbsp;頁面中，填寫表單加入等待隊列。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-688afd52e0b014510739c8706073d792afb.png" referrerpolicy="no-referrer"></p><p><strong>Arc 基於 Chromium 並用 Swift 語言編寫</strong>。它支持 Chrome 瀏覽器擴充功能，同時默認使用 Google 搜索。7 月份，Arc 正式發佈了 1.0。</p><blockquote><p><u><strong><em><a href="https://www.oschina.net/news/251034/arc-browser-1-0-mac-released">Arc 瀏覽器正式發佈 1.0，聲稱是 Chrome 的替代品</a></em></strong></u></p></blockquote><p>Arc 旨在成為一個 「萬維網的操作系統」，並試圖將網頁瀏覽與內置應用程序和功能整合在一起。其內置的功能包括虛擬記事本、拼貼風格的 「easel」 和 「boosts」，該功能允許用户美化和重新設計網站界面。Arc 的選項卡垂直排列在側邊欄中，側邊欄包含除瀏覽窗口之外的所有瀏覽器功能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-34b7b76a856863e0f84e96557bd15c058e6.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270593/arc-for-windows-is-in-beta</guid>
            <link>https://www.oschina.net/news/270593/arc-for-windows-is-in-beta</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google Colab 現已支持直接使用 🤗 transformers 庫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 編輯器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Google Colab，全稱 Colaboratory，是 Google Research 團隊開發的一款產品。在 Colab 中，任何人都可以通過瀏覽器編寫和執行任意 Python 代碼。它尤其適合機器學習、數據分析和教育目的。從技術上來説，Colab 是一種託管式 Jupyter 筆記本服務。用户無需設置，就可以直接使用，同時還能獲得 GPU 等計算資源的免費使用權限。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005864" data-ratio="0.6592592592592592" src="https://oscimg.oschina.net/oscnet/6aca6440-d2d5-4972-8624-54894772e85a.jpg" data-type="jpeg" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;" referrerpolicy="no-referrer"></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">通過與 Colab 團隊的共同努力，Colab 託管的運行時鏡像現已默認集成了 Hugging Face transformers 庫，只需簡單執行 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">import transformers</code> 即可輕鬆接入！對於使用 Colab 進行機器學習和深度學習研究的開發者來説，這是一個非常重要的更新。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你想使用最新版本的 transformers，Colab 團隊也提供了一個簡單的命令 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">!pip install transformers --upgrade</code>，以便於隨時更新至最新版本。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">除了提升用户體驗，這一更新還開啓了一些有趣的新功能。例如，用户現在可以直接從 Pandas 讀取 Hugging Face 數據集，這將大大簡化數據處理和模型訓練的工作流程。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100005865" data-ratio="0.4203703703703704" src="https://oscimg.oschina.net/oscnet/8ecbb7d1-9659-48de-9e0f-64e60f62d9ef.jpg" data-type="jpeg" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;" referrerpolicy="no-referrer"></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">本合作和更新還開啓了一些有趣的新功能。例如，用户現在可以直接從 Pandas 讀取 Hugging Face 數據集，這將大大簡化數據處理和模型訓練的工作流程。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你可以通過 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">hf://datasets/</code> 的方式在 Pandas 中直接讀取 Hugging Face Hub 上的數據集。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">感謝 Colab 團隊的朋友們，也希望社區的成員們喜歡本次的合作和功能更新！</p></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10316003</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10316003</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 開源調試工具 ixGDB]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-readme-for-ixgdb-release" class="anchor" href="https://gitee.com/deep-spark/ixgdb#readme-for-ixgdb-release"></a>README for ixGDB release</h1><h2><a id="user-content-introduction" class="anchor" href="https://gitee.com/deep-spark/ixgdb#introduction"></a>INTRODUCTION</h2><p>ixGDB is Iluvatar CUDA source-level debugger for Linux OS, based on NVIDIA <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FNVIDIA%2Fcuda-gdb">CUDA-GDB</a> 10.2.</p><p>ixGDB provides the following capabilities:</p><ul><li>Provides a seamless debugging environment that allows simultaneous debugging of both GPU and CPU code within the same application.</li><li>Supports debugging C/C++ applications and all CUDA applications, which might use CUDA driver APIs or CUDA runtime APIs.</li><li>Supports setting breakpoints.</li></ul><h2><a id="user-content-build-instructions-example-only-adjust-as-needed" class="anchor" href="https://gitee.com/deep-spark/ixgdb#build-instructions-example-only-adjust-as-needed"></a>BUILD INSTRUCTIONS (example only, adjust as needed)</h2><p>First, make sure that libtermcap and other required dependent packages are
installed (try "sudo yum install ncurses-devel"). The "configure" command will
report an error if some packages are missing.</p><p>Please note that the libexpat development headers must be present if ixGDB is to be used for cross-platform debugging.</p><p>Issue the following commands to build ixGDB:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./configure --program-prefix=cuda- \</span><span id="LC2" class="line">    --enable-cuda \</span><span id="LC3" class="line">    --enable-targets="x86_64-apple-darwin,x86_64-unknown-linux-gnu,\</span><span id="LC4" class="line">    arm-elf-linux-gnu,m68k-unknown-linux-gnu" \</span><span id="LC5" class="line">    CFLAGS='-I/usr/local/cuda/include' \</span><span id="LC6" class="line">    LDFLAGS='-lpthread'</span><span id="LC7" class="line">make</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-using-ixgdb" class="anchor" href="https://gitee.com/deep-spark/ixgdb#using-ixgdb"></a>USING ixGDB</h2><p>All standard GDB commands could be used for both CPU and GPU code debugging. In addition to that, ixGDB provides CUDA-specific command families like "info cuda ..." to query GPU states, "cuda .." to control debugger focus on GPU and "[get|set] cuda .." to alter/query CUDA debugger configuration. If you want to know more about how to use ixGDB, please go to Iluvatar CoreX support <a href="https://gitee.com/link?target=https%3A%2F%2Fsupport.iluvatar.com%2F%23%2FDocumentCentre%3Fid%3D1%26nameCenter%3D1%26productId%3D">official site</a> and use "ixgdb" as the keyword to find document "SDK Tools User Guide", which includes detailed usage of ixGDB.</p><h2><a id="user-content-communication" class="anchor" href="https://gitee.com/deep-spark/ixgdb#communication"></a>COMMUNICATION</h2><p><a href="https://gitee.com/deep-spark/ixgdb/issues">Gitee Issues</a>: bug reports, feature requests, install issues, usage issues, etc.</p><h2><a id="user-content-license" class="anchor" href="https://gitee.com/deep-spark/ixgdb#license"></a>LICENSE</h2><p>Licensee's use of the GDB third party component is subject to the terms and conditions of GNU GPL v3:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">This product includes copyrighted third-party software licensed under the terms of the GNU General Public License v3 ("GPL v3"). All third-party software packages are copyright by their respective authors.</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Consistent with these licensing requirements, the software listed below is provided under the terms of the specified open source software licenses.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">Component    License</span><span id="LC2" class="line">ixGDB        GPL v3</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/deep-spark/ixgdb</guid>
            <link>https://gitee.com/deep-spark/ixgdb</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 語言大模型的推理技巧]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><img src="https://oscimg.oschina.net/oscnet/7d0eafbb-7a1e-416d-83e4-ac07a8583a4b.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:8px; margin-right:8px"><span>本文探討了一系列<span style="background-color:#efefef">語言大模型的</span>推理優化技巧，涵蓋 KV 緩存、量化和稀疏性等方法，並分享瞭如何有效實施這些技術。對於想要優化 Transformer 模型，以期提升推理速度或效</span><span>率的人來説</span><span>值得一讀。</span></p><p>&nbsp;</p><p><span>本文作者為機器學習研究員 Finbarr Timbers，他曾是 DeepMind 的工程師。</span><span>（本文由 OneFlow 編譯發佈，轉載請聯繫授權。原文：</span><span>https://www.artfintel.com/p/transformer-inference-tricks）</span></p><p>&nbsp;</p><p><strong><span style="color:#3f3f3f">作者 |&nbsp;</span></strong><strong><span>Finbarr Timbers</span></strong></p><p><strong><span style="color:#3f3f3f">OneFlow 編譯</span></strong></p><p><strong><span style="color:#3f3f3f">翻譯｜楊婷、宛子琳</span></strong></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">1</span></strong></span></p><span id="OSC_h2_1"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">鍵值（KV）緩存</span></strong></span></h2><p>&nbsp;</p><p><span>目前，鍵值（KV）緩存是最常見（也是最重要）的解碼器優化方法。在解碼器模型中，對於每次解碼迭代，提示的鍵和值將是相同的。此外，一旦你運行了一個詞元，該詞元的鍵和值將在後續的每個迭代中保持不變。因此，你可以緩存提示，並在解碼時逐漸將每個詞元的 KV 張量添加到緩存中，這樣可以減少大量計算。在注意力機制中，我們能夠將形狀為（batch, context_length, feature_dim）的兩個張量相乘，變為將形狀為（batch, 1, feature_dim）的查詢張量與形狀為（batch, context_length, feature_dim）的 KV 張量相乘。因此，採樣的複雜度不再是二次方，這使我們能夠獲得更長上下文長度的良好解碼（採樣）性能。</span></p><p>&nbsp;</p><p><span>實際上，這會在你的實現中增加複雜性，因為現在你不僅僅是運行純函數，而且有了狀態（state），所以即便一個序列已經完成了推理，你仍需要持續運行推理（<span style="color:#888888"><em>參見 Google MaxText 的實現，https://github.com/google/maxtext</em></span>）。</span></p><p>&nbsp;</p><p><span>KV 緩存需要 2 * n_layers * n_heads * d_head 個參數。對於 GPT-3，其中 n_layers = 96，n_heads = 96，d_head = 128，這意味着每個上下文中的詞元需要 2.4m 個參數。使用典型的 16 位精度，每個詞元需要 5MB；如果上下文窗口有 2048 個詞元，那就需要將 10GB 的 HBM 用於 KV 緩存。這雖然昂貴，但每 GB 的消耗都物有所值。</span></p><p>&nbsp;</p><p><span>這些內存需求是在消費級 GPU 上訓練語言大模型如此困難的重要原因之一。目前最強大的消費級顯卡是 4090，只有 24GB 的 HBM。雖然其每秒浮點運算次數（FLOPS）可與企業級芯片相媲美，但其內存限制要低得多，這使得難以將權重和 KV 緩存置入內存。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">2</span></strong></span></p><span id="OSC_h2_2"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">推測性解碼</span></strong></span></h2><p>&nbsp;</p><p><span>推測性解碼是一種在計算能力充裕時使用的技術，通常用於本地推理設置。它利用了現代加速器的特性，即在批次數據上運行推理所需的時間與在單個數據點上運行推理的時間相同。以 A100 為例，你可以在相同的時間內對多達 160 個數據點進行推理，所需推理時間與單個數據點相同。因此，現在已經出現了許多利用這一特性的技術，如束搜索（beam search）、MCTS（蒙特卡洛樹搜索）或推測性解碼。</span></p><p>&nbsp;</p><p><span>推測性解碼包括兩個模型：一個小而快的模型以及大而慢的模型。由於現代解碼器的推理速度與參數數量成正比，使用較小的模型可以在大型模型運行一次推理所需的時間內運行多次推理。</span></p><p>&nbsp;</p><p><span>現代解碼器模型（如 GPT 系列）使用了自迴歸採樣技術，即要對 N 個詞元的序列進行採樣，模型會進行 N 次推理，每次推理都要使用前一次推理的結果。</span></p><p>&nbsp;</p><p><span>在推測性解碼中，你會並行運行這兩個模型。快速模型會運行一批推理並猜測大模型將預測哪些詞元，然後將這些猜測相疊加。與此同時，大模型在後台運行，檢查較小模型是否記錄了相同結果。較小模型能夠在大模型進行一次推理的時間內進行多次猜測。然而，鑑於我們有多餘的計算能力，大模型能夠並行評估所有猜測。因此，我們支付順序生成序列成本的唯一地方是在較小的模型上。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/59e12167-b54f-4b1c-bcb5-4479facca980.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>推測性解碼的主要缺點是它需要一個「草稿（draft）」模型，該模型能夠預測較大模型的輸出，而且你必須讓兩個模型同時存在於同一台機器的內存中（或者在多 GPU 設置下的同一節點上）。這增加了複雜性，需要額外的工作，因為你必須訓練兩個模型（原始模型和「草稿」模型）。此外，任何性能提升都受限於小模型能夠在多大程度上精確地預測大模型。如果小模型始終能夠準確預測大模型的行為，那麼我們就可以直接使用它！因此，推測性解碼能夠發揮作用的程度存在根本差距。HuggingFace 聲稱它通常可以將解碼速率提高一倍，這與原始論文（<span style="color:#888888"><em>https://arxiv.org/abs/2211.17192</em></span>）中聲稱的 2 至 3 倍的提升一致。</span></p><p>&nbsp;</p><p><span>最近出現了一種試圖改進推測性解碼的前向解碼（Lookahead Decoding）技術（<span style="color:#888888"><em>https://lmsys.org/blog/2023-11-21-lookahead-decoding/</em></span>），該技術讓模型生成 n-gram，然後在無需草稿模型的情況下遞歸匹配這些 n-gram。這種技術被稱為 Jacobi 解碼（來自他們的博客截圖），可能是對貪婪解碼的潛在改進。Jacobi 解碼的工作原理是在生成詞元的每一點上生成 n 個詞元，對整個序列進行「猜測」。然後，將其與先前的猜測相驗證，如果兩者匹配，就接受該猜測。這可以在沒有副作用的情況下減少時延，因為在最壞的情況下，它會變成貪婪解碼。</span></p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/d545a2df-0729-4b32-a7dc-390784598002.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>前向解碼通過保留解碼過程中生成的 n-gram，並嘗試將它們用作猜測，進一步改進了這一技術。鑑於已生成的文本與將要生成的文本之間存在很高的相關性，這也有可能以極低的成本，顯著改進時延。這一技巧非常巧妙。考慮到這項技術才發佈不久，我非常好奇它在實際場景中的性能表現。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/cdf7da2f-7ac8-475c-90ff-a2baacf4b4c3.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">3</span></strong></span></p><span id="OSC_h2_3"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">有效稀疏性</span></strong></span></h2><p>&nbsp;</p><p><span>在僅解碼器 Transformer 中，模型核心是注意力機制，可總結為如下的注意力方程：</span></p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/51f1f3da-d1e8-4cff-b3c2-b1f2f9a7af30.png" referrerpolicy="no-referrer"></p><p><span>softmax 操作會使非最大值變得很小。</span></p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/a66d9144-d636-4c8e-a891-8a79045d5e40.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="text-align:left"><span>因此，我們將數值張量（在注意力方程中用 V 表示）與一個主要由零（zero）組成的張量相乘。結果，注意力機制的輸出中包含了大量的零，最高可達 97%（<span style="color:#888888"><em>https://x.com/YesThisIsLion/status/1647747069086666752?s=20）</em></span>。類似地，在多層感知器網絡（MLP）中的每個 ReLU 之後，我們也得到了大量稀疏性。</span></p><p>&nbsp;</p><p><span>不幸的是，現在要實際利用這一點比較困難。如果權重中存在稀疏性，那麼可通過結構化稀疏性（例如</span><span>tor<span>‍</span>ch.sparse</span><span>）做大量工作，但目前還不清楚系統能夠多大程度地利用激活的稀疏性。</span></p><p>&nbsp;</p><p><span>可以進行的一個優化是：如果某個激活為零，那麼可以跳過加載與該激活對應的權重，並避免相應計算。據我所知，這並未很好地得到主流張量計算程序的支持，但對於</span><span>Llama.cpp</span><span>等自定義推理實現來説，這一優化比較容易實現。</span></p><p>&nbsp;</p><p><span>這是因為激活是每個詞元的函數，因此有效稀疏性也是隨機分佈在詞元上。因此，這種優化的效果會隨着批大小的增加呈指數級衰減。假設我們的有效稀疏性為 X%，批大小為 N，那麼對於一個給定激活的所有條目在整個批次中都為零的概率可以表示為 X^N。我製作了一張表格，列出了不同 X 和 N 值的情況。這種衰減效應非常顯著。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/a82589c0-f80d-4a43-aab4-348ae7b1f293.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>因此，除批大小為 1 的情況，利用這一方法十分困難，即使在這種情況下，使用推測性解碼通常更為有效。但如果你想要在本地運行推理，並且確實需要降低時延，這可能是一個很棒的技巧。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span><strong><span style="color:#f6ab00">4</span></strong></span></p><span id="OSC_h2_4"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">量化</span></strong></span></h2><p>&nbsp;</p><p><span>量化是人們更為熟悉的技巧之一。我之前已經寫過量化的相關內容 (<span style="color:#888888"><em>https://finbarrtimbers.substack.com/p/efficient-llm-inference</em></span>），所以不打算在具體方法上花費太多時間。我們很難精確度量量化的效果。GPTQ 論文等文獻所使用的模型與 SOTA 模型差距較大，因為大型實驗室並未公開其所使用的模型，並且學術界無法與大型實驗室所擁有的資源相匹敵。</span></p><p>&nbsp;</p><p><img src="https://oscimg.oschina.net/oscnet/1bcc4196-002b-475d-a149-812f9b6e70b7.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span>例如，GPTQ 報告了 OPT 和 BLOOM 模型的量化結果，這些結果遠不如當前的一系列開源模型，更不用説 GPT-4 了。</span></p><p>&nbsp;</p><p><span>當然，大型實驗室並未公開其研究進展，而我看到的大部分個案報告都來自那些試圖在消費級硬件上運行較小模型的人，這種硬件的內存非常有限。我認為，很多業餘愛好者（即非大型實驗室研究人員）都被在本地運行龐大模型的吸引力所誘惑，因此他們對量化產生了濃厚興趣。但實際上，量化並不具備固有優勢！從第一性原則出發，如果你有兩個位數相同的模型，它們應該具有相同數量的詞元/秒，並且應該具有類似的性能水平。只有在使用更高精度格式的位數時做得很糟，才會有較大差異。</span></p><p>&nbsp;</p><p><span>但文獻中的觀點與我的直覺不一致。上述 GPTQ 論文發現，將模型量化為低至 4 倍的精度時，性能的下降微乎其微。我認為，這是因為性能更差的模型更容易在量化過程中保持其性能不受損。如果假設兩個相同的 LLM，一個經過 2 萬億詞元的訓練，另一個經過 5000 億詞元的訓練（分別稱為 LLM-2T、LLM-500B），在進行量化時，我認為經過更多詞元訓練的模型在性能上受到的影響更大，因為它應該更充分地利用這些詞元。我們仍然預計經過量化的 LLM-2T 會優於 LLM-500B，但我認為從 LLM-2T 到經過量化的 LLM-2T 的性能下降，會比從 LLM-500B 到經過量化的 LLM-500B 的下降更顯著。</span></p><p>&nbsp;</p><p><span>注：雖然上述論點很有説服力，但實際上並沒有相關的文獻支持。量化似乎確實非常接近於「免費的午餐」。</span></p><p>&nbsp;</p><p style="text-align:left"><span>近期的研究，如關於 k-bit 推理規模定律的論文（<span style="color:#888888"><em>https://arxiv.org/abs/2212.09720</em></span>），在一系列 LLM 架構上進行了大量實驗，得出了不同的位數分配對模型性能的影響。他們研究了在給定精度水平下使用 N 個參數的模型與使用 2N 個參數和一半精度的模型之間的權衡。其結果非常引人注目，與未進行量化的性能幾乎沒有差別（至少對於 4 位或更多位而言）。</span></p><p>&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/e695f055-912b-4be6-99bf-e046a7191224.png" referrerpolicy="no-referrer"></p><p><span>基本上，他們發現可以將精度降至 4 位而不損失任何性能，量化幾乎不會導致任何權衡。你可以運行一個小 4 倍的模型而不會顯著降低性能。由於在現代加速器上推理性能等於處理的位數（即使用較少精度時每秒可以獲得更多的運算次數），這點很有幫助。</span></p><p>&nbsp;</p><p><span>因此，我的結論是：推薦採納「k-bit 推理論文」的建議。然而，對於生產負載，我對使用低於 8 位的精度還有些猶豫。fp8 是目前現代加速器本地支持的最低精度浮點格式，即使如此，支持也是有限的。我建議在 fp8 精度下進行訓練和推理，並觀察進一步量化可能帶來的精度損失對你的用例來説是否可以接受。當生產環境中缺乏來自這些平台（例如 Nvidia 和 Torch/JAX 團隊）的本地支持時，我很難推薦在生產環境中使用更低級別的精度。</span></p><p>&nbsp;</p><p><span>根據我從文獻中瞭解到的（這與我的直覺相符），fp8 嚴格來説優於 int8，但在硬件上的支持有限。如果你在一個 GPU 資源充沛的組織，並且能夠將 H100 用於所有任務，那麼請使用 fp8。否則，也可以使用 int8，而且相比起來要容易得多（PyTorch 使其變得相當容易，儘管 API 不太穩定）。</span></p><p>&nbsp;</p><p><span>關於實際進行模型量化，PyTorch 團隊已經撰寫了一篇關於如何具體操作的文章（<span style="color:#888888"><em>https://pytorch.org/blog/accelerating-generative-ai/</em></span>），並提供了一系列 API 用於簡化操作，儘管它們不太穩定。此外，bitsandbytes 是另一個出色的量化庫，不過我個人還未使用過。</span></p><p>&nbsp;</p><p><span>（特別感謝@cis_female 與我討論稀疏性的複雜性，以及@nostalgebraist 糾正量化部分中的錯誤。我現在認為，證據表明，至少量化到 4 位或更多位，在性能方面的權衡非常小。）</span></p><p>&nbsp;</p><p>&nbsp;</p><span id="OSC_h2_5"></span><h2 style="margin-left:8px; margin-right:8px; text-align:left">&nbsp;</h2><p><span style="background-color:#ffffff; color:#888888">其他人都在看</span></p><span id="OSC_h3_6"></span><h3 style="text-align:left">&nbsp;</h3><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491309%26idx%3D1%26sn%3D407fefb7ec76a2c9fdfe1ae960f7de4d%26chksm%3Dfe4190dbc93619cd0b9bfecb979e142a125fd8548d323dd9bdc2cbeb619400202e6e1affced0%26scene%3D21%23wechat_redirect" target="_blank">大型語言模型的推理演算</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493088%26idx%3D1%26sn%3Dff319e3b8cc19f165232c3226779588c%26chksm%3Dfe426bd6c935e2c0946fdaa96378d04123f31eb797e39c8ab0d619bbb00db8b665354a167583%26scene%3D21%23wechat_redirect" target="_blank">LoRA 微調語言大模型的實用技巧</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492976%26idx%3D1%26sn%3Dd919a508ce238048ae44e58b9cc06b71%26chksm%3Dfe426b46c935e2500178c2d2c8845fcd3e47fdeb5ec51f55b80cbca5f7b78382cdb3e6fe6a32%26scene%3D21%23wechat_redirect" target="_blank">可復現的語言大模型推理性能指標</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492990%26idx%3D1%26sn%3D50844c8911834baf44863a9e3754175f%26chksm%3Dfe426b48c935e25ede3f772624ba262011b1b48f8ee78ac6d3b1daa5aaf71e7583828740b5cd%26scene%3D21%23wechat_redirect" target="_blank">ChatGPT 規模化服務的經驗與教訓</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493053%26idx%3D1%26sn%3Dfe7a51fbda920626b55d8919dd780e05%26chksm%3Dfe426b8bc935e29d3a806dfd6682619ee46effa39b09777907d5bccfd80d8cd639580c6f6e23%26scene%3D21%23wechat_redirect" target="_blank">機器學習硬件十年：性能變遷與趨勢</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492951%26idx%3D1%26sn%3D873b7c63ea18d638a9570bb582cddbb5%26chksm%3Dfe426b61c935e277e17fd2d4b06fa3ec998479ae87d84312f064dbae0e65875a7cb45829807d%26scene%3D21%23wechat_redirect" target="_blank">微調語言大模型選 LoRA 還是全參數？</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492811%26idx%3D1%26sn%3D916e330a2a4152dab3192635c3e475fa%26chksm%3Dfe426afdc935e3eb2f371ff5f56247c95800ce91a950a89bea871c26ddc4c3d13371acf03978%26scene%3D21%23wechat_redirect" target="_blank">語言大模型推理性能工程：最佳實踐</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493030%26idx%3D1%26sn%3D58a43ed078977019c997a110526d7c02%26chksm%3Dfe426b90c935e28688b6e317a991bedaaa164471a275d64e60851a09b00f7f6b718e27d7b411%26scene%3D21%23wechat_redirect" target="_blank">語言大模型的分佈式訓練與高效微調指南</a></p></li></ul><span id="OSC_h3_7"></span><h3 style="text-align:left">&nbsp;</h3><p><strong><span>試用 OneFlow: <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank">github.com/Oneflow-Inc/oneflow/</a></span></strong></p><p style="color:#3f3f3f; margin-left:8px; margin-right:8px; text-align:left"><img src="https://oscimg.oschina.net/oscnet/f2b38f8c-5887-4315-9787-03816b68ada4.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br> 如有侵權，請聯繫 support@oschina.cn 刪除。<br> 本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 01:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10320747</guid>
            <link>https://my.oschina.net/oneflow/blog/10320747</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源 MoE 模型 Mixtral 8x7B 性能超過 GPT-3.5]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>大模型創業公司 Mistral AI 終於<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-of-experts%2F" target="_blank">介紹了</a></u>前兩天「開源」的&nbsp;MoE 模型 <strong>Mixtral 8x7B</strong>。</p><blockquote><p><strong><em><u><a href="https://www.oschina.net/news/270317/mixtral-8x7b-32kseqlen">Mistral AI 用「磁鏈鏈接」開源了 87 GB 的 8x7B MoE 模型</a></u></em></strong></p></blockquote><p>官方稱，Mixtral 8x7B 是開放權重的高質量<strong>稀疏混合專家模型 (SMoE)</strong>，採用 Apache 2.0 License 開源。在大多數基準測試中，Mixtral 的成績都優於 Llama 2-70B，且推理速度提升了 6 倍。而且在大多數標準基準測試中超過 GPT-3.5。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7a689c4f538b591b9744038a052717945e6.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-84fefd9ee6c091c07c894031a1af2faf2e3.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f9aaad324856028fb1e796beb2d7685020.png" referrerpolicy="no-referrer"></p><p>因此，Mistral AI 稱 Mixtral 是最強大的開放權重模型，也是成本/性能權衡方面的最佳模型。</p><p><strong>Mixtral 主要特性</strong></p><p>• 32k 上下文<br> • 支持英語、法語、意大利語、德語和西班牙語<br> • 性能超過 Llama 2 系列和 GPT-3.5<br> • 在代碼生成方面具有強勁性能<br> • 在 MT-Bench 上獲得 8.3 分</p><p>Mixtral 作為稀疏混合專家網絡，是一個純解碼器模型，其中前饋塊從 8 組不同的參數組中選擇。在每一層，對於每個 token，路由網絡選擇兩組「專家」來處理 token 並相加地結合它們的輸出。</p><p>Mixtral 總共有 45B 個參數，但每個 token 只使用 12B 個參數。因此，它以與 12B 模型相同的速度和成本處理輸入和生成輸出。</p><p>更多細節查看：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-of-experts%2F" target="_blank">https://mistral.ai/news/mixtral-of-experts/</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 10:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270511/mixtral-of-experts</guid>
            <link>https://www.oschina.net/news/270511/mixtral-of-experts</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[榮耀申請魔方大模型商標]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">天眼查信息顯示，榮耀終端有限公司近日申請註冊「榮耀魔方大模型」商標，國際分類為網站服務，當前商標狀態為等待實質審查。</span></p><p><img height="275" src="https://oscimg.oschina.net/oscnet/up-7baf34d7d00360b976559630121d67b0da4.png" width="700" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#222222">此前，該公司曾申請兩枚「MAGIC&nbsp;大模型」商標。榮耀 CEO 趙明曾發文稱，榮耀即將推出自研端側 AI 大模型和全新雲服務。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 08:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270492</guid>
            <link>https://www.oschina.net/news/270492</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[HashiCorp 採用 BSL 後續，Linux 基金會孵化 Vault 開源替代品]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">今年 8 月，<span style="background-color:#ffffff">專注於雲基礎設施的軟件供應商 HashiCorp&nbsp;</span>宣佈<span style="background-color:#ffffff">修改其核心產品的開源協議。</span><strong style="color:#333333">所有 HashiCorp 產品的未來版本</strong><span style="background-color:#ffffff">將從 Mozilla Public License v2.0 (MPL 2.0) 變更為&nbsp;</span><strong style="color:#333333">Business Source License (BSL, also known as BUSL) v1.1</strong><span style="background-color:#ffffff">，其中包括&nbsp;Vault、Boundary、Consul、Nomad、Packer、Terraform、Vagrant 和 Waypoint 等。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">採用 BSL 1.1 的項目，其代碼仍會公開 (source-available)，</span><strong style="color:#333333">但只允許在特定條件下進行復制、修改、重新分發、非商業使用和商業使用</strong><span style="background-color:#ffffff">&nbsp;—— 主要是添加了商業使用方面的限制。</span></span></p><p><span style="color:#000000">此後，社區在抗議無效後選擇創建了 Terraform 的分支項目 OpenTofu（原名 OpenTF），並託管在了 Linux 基金會下。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">時至今日，有消息稱 Linux 基金會正計劃幫助孵化一個私密信息管理工具 Vault 的開源替代品。DevOps 自動化公司 Scalr 的聯合創始人兼首席執行官 Sebastian Stadil 和 OpenTofu 的組織者之一<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F12%2F08%2Fhashicorp_openbao_fork%2F" target="_blank">透露</a>，Vault 開源替代品的項目名為 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.lfedge.org%2Fdisplay%2FOH%2FOpenBao%2B%2528Hashicorp%2BVault%2BFork%2Beffort%2529%2BFAQ" target="_blank">OpenBao</a>，是競爭對手在 MPL 2.0 協議下創建的一個&nbsp;Vault 分支。</span></span></p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-1f318fa9f93212c7ed6a67c0b91e135c731.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><span style="background-color:#ffffff">OpenTofu 計劃在本月晚些時候發佈候選版本，OpenBao 也將開始接受新的貢獻。Stadil 表示，「如果有兩個相同的項目，一個是開源的，一個不是，我個人認為，道德上的選擇是使用開源項目，並以某種方式提供幫助。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">不過鑑於 OpenTofu 和 OpenBao 都是新近開發的項目，項目的可行性和持久性受到了很多關注。針對這一擔憂，Stadil 表示拒絕代表其他公司發言。事實上，他還被告知不要透露任何關於其他組織支持這些項目的消息。對於那些想要了解更多詳情的人，他建議可以訪問項目的 repos。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">當被問及 HashiCorp 重新授權其軟件的理由時，Stadil 回答稱，官方的説法是 Terraform 對互聯網至關重要，而長期以來人們一直希望將其置於 Linux 基金會的監督之下。「如果 HashiCorp 將來願意加入我們的 OpenTofu，我們會很樂見其成」。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">但</span><span style="background-color:#ffffff">他無法推測 HashiCorp 的內部決策過程。Stadil 指出，Hashicorp 一直在燒錢，隨着利率的上升，這家軟件公司選擇採取措施創造更多收入也不足為奇。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">上週，HashiCorp 公佈了 2024 財年第三財季的營收報告。營收 1.461 億美元，同比增長 17%。按照美國通用會計準則（GAAP），淨虧損為 3950 萬美元，低於去年同期的 7200 萬美元。</span></span></p><p><strong><span style="color:#000000"><span style="background-color:#ffffff">相關閲讀：</span></span></strong></p><ul><li><a href="https://www.oschina.net/news/253275/hashicorp-adopts-business-source-license" target="_blank">HashiCorp 核心產品變更開源協議，未來將採用 BSL</a></li><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/255700/opentf-fork-terraform" target="_blank">HashiCorp 採用 BSL 後，社區創建 Terraform 分支 OpenTF</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 07:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270477/hashicorp-vault-openbao-fork</guid>
            <link>https://www.oschina.net/news/270477/hashicorp-vault-openbao-fork</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[周熱點 | Linus 收斂火爆脾氣，談內核社區「老齡化」問題；Firefox 或將被淘汰；谷歌發佈最強 AI 模型 Gemini............]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2023.12.04-2023.12.10]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 06:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094041&#38;idx=1&#38;sn=18ed1a99fdf7fbbbc52688a346795664&#38;chksm=880c4c8abf7bc59cbaf66865402e963af1309b4bb627cd89ae402f319f12ce5c56561126ea09&#38;token=1220110296&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094041&#38;idx=1&#38;sn=18ed1a99fdf7fbbbc52688a346795664&#38;chksm=880c4c8abf7bc59cbaf66865402e963af1309b4bb627cd89ae402f319f12ce5c56561126ea09&#38;token=1220110296&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[GitHub.com 跑了 1200 多台 MySQL 主機，如何無縫升級到 8.0？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GitHub 團隊近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-07-upgrading-github-com-to-mysql-8-0%2F" target="_blank">分享</a></u>了他們將 GitHub.com 的底層數據庫無縫升級到 MySQL 8.0 的經驗。</p><p>據介紹，GitHub 使用 MySQL 來存儲大量關係數據，因此在不影響網站服務級別目標 (SLO) 的情況下升級主機集羣（<strong>1200 多台 MySQL 主機</strong>）絕非易事。其團隊表示，為了升級到 MySQL 8.0，他們規劃、測試和升級本身總共花費了一年多的時間，並且需要 GitHub 內部多個團隊的協作。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-613c88c0257637ef029cdd9528c6f8a3217.png" referrerpolicy="no-referrer"></p><p><strong>GitHub 的 MySQL 基礎設施概覽：</strong></p><ul><li>由 1200 多台主機組成，包括數據中心中的<strong> Azure 虛擬機和裸機主機</strong></li><li>存儲超過 300 TB 的數據，並在 50 多個數據庫集羣中每秒處理 550 萬次查詢</li><li>每個集羣都配置為具有主副設置的高可用性</li><li>分區存儲數據——利用水平和垂直分片來擴展 MySQL 集羣，以及使用 MySQL 集羣來存儲特定產品領域的數據。此外還為大結構域 (large-domain) 提供了水平分片的 Vitess 集羣，這些區域的增長超出了單主 MySQL 集羣的規模</li><li>龐大的工具生態，包括 Percona Toolkit、gh-ost、orchestrator、freno 和用於操作主機集羣的內部自動化工具</li></ul><p>由於需要操作兩個版本的 MySQL，因此 GitHub 內部使用的工具和自動化設施需要能夠兼容處理混合版本，並瞭解 5.7 和 8.0 之間<strong>新的、不同的或已棄用的語法</strong>。</p><p>為了滿足可用性標準，GitHub 團隊採取了逐步升級策略，滿足在整個過程中進行 checkpoint 和回滾的需求。下面是他們制定的升級計劃：</p><ul><li><strong>步驟 1：升級滾動副本 (rolling replica)</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9d574db1e2fec9bf7da0d7c92091b0fb19.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步驟 2：升級備份拓撲 (replication topology)</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-305231a10282f80062ca4f1d665c36305ee.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步驟 3：將 MySQL 8.0 主機提升為主集羣</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e9f6defe7e920b0167c797000292c7e390.png" referrerpolicy="no-referrer"><p>&nbsp;</p></li><li><strong>步驟 4：升級面向內部的實例類型</strong></li><li><strong>步驟 5：清理，</strong>確認集羣不需要回滾併成功升級到 MySQL 8.0 後，刪除 5.7 服務器。驗證工作會至少經歷一個完整的 24 小時流量週期，以確保在高峯流量期間不會出現問題。</li></ul><p>至於為什麼要升級到 MySQL 8.0，GitHub 團隊表示主要是因為 MySQL 5.7 的生命週期即將結束。此外升級後可以獲得最新安全補丁、錯誤修復和性能增強的 MySQL 版本。他們還希望測試 8.0 中的新功能並從中受益，包括即時 DDL、隱形索引和壓縮的 bin 日誌等。</p><p>詳細的技術細節查看：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-07-upgrading-github-com-to-mysql-8-0%2F" target="_blank">https://github.blog/2023-12-07-upgrading-github-com-to-mysql-8-0/</a></u></em></p><hr><p>延伸閲讀</p><ul><li><u><a href="https://www.oschina.net/news/188164/github-recent-service-disruptions">GitHub 解釋近期頻繁宕機原因：MySQL 不堪重負</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 05:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0</guid>
            <link>https://www.oschina.net/news/270460/upgrading-github-com-to-mysql-8-0</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TIOBE 12 月：C# 有望成為年度編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">TIOBE 公佈了 2023&nbsp;年 12 月的</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">編程語言排行榜</a><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">。</span></span></p><p><img height="77" src="https://oscimg.oschina.net/oscnet/up-e944f70ee629593d3b3ba2ac7d008e89e4b.png" width="700" referrerpolicy="no-referrer"></p><p>2023 年度 TIOBE 編程語言名單即將出爐，其中最有望勝出的當屬&nbsp;C#。事實上，早在 2022 年&nbsp;C# 就有望奪得該桂冠，但卻在最後時刻被&nbsp;C++ 反超。而在今年，C# 的勝率又多出了幾分；因為該語言在一年內的增長率為 +2.38%，與其最接近的競爭者 Fortran 和 F# 的增長率則僅分別上漲了 +0.64% 和 +0.48%。</p><p>此外，Top 20 中的大部分語言人氣都出現了下降。<span style="background-color:#ffffff; color:#000000">TIOBE CEO&nbsp;Paul Jansen 評論稱，</span>「答案就在所有小語言所在的長尾（long tail）部分。這些語言的受歡迎程度都在上升，而且越來越接近大語言」。例如：一年前，排名第 50 位的語言得分僅為 0.14%，但現在第 50 位語言的得分已經達到了 0.24%。</p><p><strong style="color:#333333">TIOBE 12 月 TOP 20 編程語言</strong></p><p><img height="414" src="https://oscimg.oschina.net/oscnet/up-b25283a71bbac81145079c4b2848ccc6e95.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">相較上月，除了 Ruby<span>&nbsp;</span>(18→19)、R (19→20) 以及 Rust (20→18) 之間出現了小範圍波動外，Top&nbsp;10-20 榜單沒有其他任何排名變化，這也是近期以來榜單變動最小的一次。</span></p><p><strong style="color:#333333">TOP 10 編程語言 TIOBE 指數走勢（2002-2024）</strong></p><p><img height="228" src="https://oscimg.oschina.net/oscnet/up-c048f61fdb18f5fa94fbc07b575f6acc8f9.png" width="700" referrerpolicy="no-referrer"></p><p><strong style="color:#333333">第 21-50 名編程語言排行</strong></p><p><img height="430" src="https://oscimg.oschina.net/oscnet/up-e1c00e5bc23507475a73c563cbdb213cdc9.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">第 51-100 名如下，由於它們之間的數值差異較小，僅以文本形式列出（按字母排序）：</span></p><p>&nbsp;</p><blockquote><p>4th Dimension/4D, ABC, Algol, Apex, ATLAS, AutoLISP, Bash, Boo, Carbon, CIL, CL (OS/400), Clipper, Clojure, Curl, Eiffel, Elm, Erlang, GAMS, Groovy, Icon, Inform, Io, J#, LabVIEW, Ladder Logic, LiveCode, Maple, Modula-2, MOO, MQL5, NATURAL, Nim, OCaml, OpenEdge ABL, PostScript, Pure Data, Q, Racket, Ring, RPG, Smalltalk, Snap!, Solidity, SPARK, SPSS, Tcl, VHDL, Wolfram, X10, Zig</p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">TIOBE 編程社區指數（The TIOBE Programming Community index）是一個衡量編程語言受歡迎程度的指標，該指數每月更新一次。評判的依據來自世界範圍內的工程師、課程和第三方供應商，包括流行的搜索引擎，如 Google、必應、雅虎、維基百科、亞馬遜、YouTube 和百度都被用於指數計算。值得注意的是，TIOBE 指數並不代表編程語言的好壞或編寫代碼的多少。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">該指數可以用來檢查你的編程技能是否還能跟上時代的步伐，或者在開始建立一個新的軟件系統時，基於指數對採用何種編程語言做出決策。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F" target="_blank">TIOBE 指數</a><span style="color:#000000">的定義方式，以及詳細榜單信息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">均可查看官網</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 03:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270438/tiobe-index-2023012</guid>
            <link>https://www.oschina.net/news/270438/tiobe-index-2023012</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[因 EXT4 數據損壞錯誤，Debian 12.3 推遲發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Debian 團隊發佈公告稱，由於 Linux 內核 6.1.64-1 中的<strong> ext4 文件系統出現數據損壞問題</strong>，因此原計劃昨天發佈的 Debian 12.3 將會被推遲，同時進行修復。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-6b960c796ab8ff358469f03578c81866ec1.png" referrerpolicy="no-referrer"></p><p>來源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.debian.org%2FNews%2F2023%2F2023120902" target="_blank">https://www.debian.org/News/2023/2023120902</a></u></p></blockquote><p>據介紹，此 bug 由從 Linux 6.5 回溯的一個有問題補丁導致，它引起了 EXT4 和 iomap 代碼之間的幹擾，可能導致舊內核上的數據損壞。</p><p>這個問題主要出現在最近的 Linux 6.1 LTS 點版本中，新的 Linux 6.1.66 版本已經回滾了有問題的提交。Debian 的 bug 報告稱這個問題為「非嚴重的數據丟失」，因此應該是可以恢復的。</p><p>但由於 Debian 12.3 原本計劃發佈的內核版本受到了影響，因此被推遲發佈。建議 Debian 12 用户在 Linux 6.1.66 內核鏡像推出之前不要升級系統。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 11 Dec 2023 03:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270435/debian-12-3-delayed-ext4-corrupt</guid>
            <link>https://www.oschina.net/news/270435/debian-12-3-delayed-ext4-corrupt</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
