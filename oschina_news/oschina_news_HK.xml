<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 06 Mar 2024 11:22:00 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Linux 基金會推出「反詐」開源項目 Tazama，獲蓋茨基金會資助]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gatesfoundation.org%2F" target="_blank">比爾及梅琳達•蓋茨基金會</a>（Bill &amp; Melinda GatesFoundation）的支持下，Linux 基金會慈善機構（LF Charities）<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-launches-tazama-for-real-time-fraud-management" target="_blank">宣佈</a></u>推出<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">Tazama</a>，這是一套用於實時欺詐預防的開源軟件解決方案。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-935f8d1d736dc3d5b53baa4a2e1caebd24b.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gasa.org%2Fglobal-anti-scam-summit-2023" target="_blank">全球反詐騙聯盟 (Global Anti-Scam Alliance)</a>報告稱，2022 年因在線欺詐損失了近萬億美元。</p><p>Tazama 標誌着全球金融監管和合規方式的重大轉變。迄今為止，金融業一直在使用專有的、往往成本高昂的解決方案，這些解決方案限制了許多人（尤其是發展中經濟體）的使用和適應性。</p><p>Tazama 提供了一種強大、可擴展且成本效益高的開源反欺詐替代解決方案，實現了先進金融監控工具的平民化，有助於打擊欺詐行為，從而挑戰了這一現狀。</p><p>Tazama 解決了政府、民間社會、最終用户、行業機構和金融服務業的主要問題，包括欺詐檢測、反洗錢合規性和數字金融交易的成本效益監控。該解決方案的架構強調數據主權、隱私和透明度，與世界各國政府的優先事項保持一致。Tazama 由 LF 慈善基金會主辦，該基金會將為項目的運行和功能提供支持，Tazama 展示了開源解決方案的可擴展性和穩健性，尤其是在國家支付交換機等關鍵基礎設施方面。</p><p>一些組織正在探索與 Tazama 的協同作用，包括 BankservAfrica、IPSL、JoPACC 和 BCEAO。協同作用包括評估 Tazama 解決方案在實際應用場景中的有效性、可擴展性和適應性，確保其滿足並超越各行業數字金融服務提供商（DFSP）的不同需求。</p><p>Tazama 歡迎各國中央銀行、監管機構、移動支付提供商、系統集成商、組織和個人參與其中。欲瞭解更多有關 Tazama 及其使命、社區和倡議的信息，請訪問 Tazama<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">網站</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffrmscoe" target="_blank">GitHub</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 10:03:40 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</guid>
            <link>https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 和 Elon Musk【譯】]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>OpenAI 今天在官網<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">發佈新聞稿</a></u>，迴應</span><span>埃隆·馬斯克</span><span>起訴一事。</span></p><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>該文章由 Sam Altman、Greg Brockman、Ilya Sutskever 等人共同署名。文章表示，OpenAI 打算</span><span>駁回</span><span>埃隆·馬斯克</span><span>的所有訴訟請求，</span><span>並公佈了一些高層和</span><span>埃隆·馬斯克</span><span>的歷史往來郵件作為證據。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-49bfb7cdaf49904c3a735c17f2ac5c4887e.png" referrerpolicy="no-referrer"></p></blockquote><p>以下為新聞稿原文翻譯：</p><p>&nbsp;</p><p>OpenAI 的使命是確保 AGI 造福全人類，這意味着既要構建安全有益的 AGI，又要幫助人類創造收益。現在，我們將與大家分享我們在完成使命方面的心得，以及我們與埃隆之間關係的一些事實情況。</p><p>我們正打算駁回埃隆的所有訴訟請求。</p><h3><strong>我們意識到，構建 AGI 所需的資源遠遠超出我們最初的想象</strong></h3><hr><p>埃隆説，我們應該布向 OpenAI 提供 10 億美元的初始資金承諾。實際上，這家非營利組織總共從埃隆那裏籌集了不到 4500 萬美元，從其他捐贈者那裏籌集了 9000 多萬美元。</p><p>在 2015 年底創辦 OpenAI 時，格雷格和薩姆最初計劃籌集 1 億美元。但是埃隆在一封電子郵件中表示&nbsp;「我們需要一個比 1 億美元大得多的數字，以免讓人聽起來覺得毫無希望……我認為我們應該從 10 億美元的資金承諾開始.如果其他人不提供的，我會承擔。「 [1]</p><p>我們花了很多時間來設想通往 AGI 的合理路徑。2017 年初，我們意識到構建 AGI 需要大量的計算。我們開始計算 AGI 可能需要多少計算量。我們都明白，要想成功完成使命，我們將需要更多的資金--這將達到每年數十億美元，遠遠超出了我們任何人的想象，尤其是埃隆，他認為我們作為非營利組織無法籌集到這麼多資金。</p><h3><strong>我們和埃隆都認識到，要獲得這些資源，就必須建立一個營利實體。</strong></h3><hr><p>在我們討論營利性結構以推進使命時，埃隆希望我們與特斯拉合併，否則他需要獲得全部的控制權。這之後埃隆離開了 OpenAI，他説需要有一個與谷歌/DeepMind 相對應的競爭對手，而他打算自己來做這件事。他同事表示，他會支持我們找到自己的道路。</p><p>2017 年底，我們和埃隆決定下一步的任務是創建一個營利實體。埃隆希望獲得多數股權以及最初的董事會控制權，並擔任首席執行官。在這些討論中，他扣留了資金。Reid Hoffman 填補了資金缺口，為我們支付了工資和運營費用。</p><p>我們無法就營利性公司的條款與埃隆達成一致，因為我們認為任何個人對 OpenAI 擁有絕對控制權都有悖於公司的使命。於是，他建議將 OpenAI 併入特斯拉。2018 年 2 月初，埃隆給我們轉發了一封郵件，建議 OpenAI 「依附於特斯拉，將其作為自己的資金來源「，並評論説 「完全正確……特斯拉是唯一一條甚至有望與谷歌相提並論的道路。即便如此，與谷歌抗衡的可能性也很小。但並不是零」。[2]</p><p>埃隆很快選擇離開 OpenAI，他説我們的成功概率為 0，他計劃在特斯拉內部建立一個 AGI 團隊與我們競爭。他在 2018 年 2 月底離開時告訴我們，他支持我們自己尋找籌集數十億美元的道路。2018 年 12 月，埃隆給我們發郵件説：「即使籌集到幾億美元也不夠。這需要每年籌集數十億美元，否則就算了。「 [3]</p><h3><strong>我們通過構建可廣泛使用的有益工具來推進我們的使命</strong></h3><hr><p>我們通過開源等方式，使我們的技術能夠廣泛使用，從而提高人們的效率，改善他們的日常生活。</p><p>我們向大眾提供了當今最強大的人工智能，包括每天有數億人使用的免費版本。舉個例子，阿爾巴尼亞正在使用 OpenAI 的工具將其加入歐盟的時間加快了 5.5 年；數字綠色公司正在幫助肯尼亞和印度提高農民收入，通過在 OpenAI 的基礎上將農業推廣服務的成本降低 100 倍；羅德島州最大的醫療保健提供商 Lifespan 使用 GPT-4 將其手術同意書從大學閲讀水平簡化到六年級水平；而冰島正在使用 GPT-4 保護越來越少人使用的冰島語。</p><p>埃隆明白，這些工作並不意味着開源 AGI。正如伊利亞告訴埃隆的那樣 「隨着我們越來越接近 AGI，開始降低開放程度是有意義的。OpenAI 中的 「開放 「是指人工智能建成後，每個人都應從人工智能的成果中受益，但不分享科學成果也完全沒問題……"，埃隆回答道： 「是的」。[4]</p><p>對於埃隆的起訴，我們倍感遺憾。我們深深欽佩的一個人走到了這一步。他曾激勵我們向更高的目標邁進，然後告訴我們會失敗，建立了一個競爭對手團隊，而當我們開始在沒有他的情況下朝着 OpenAI 的使命取得有意義的進展時，他又將我們告上法庭。</p><p>我們專注於推進自己的使命，這還有很長的路要走。我們相信隨着我們的產品越來越好，他們將更好地為每個人賦權。</p><p>&nbsp;</p><p><strong>以下為往來郵件翻譯：</strong></p><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173736_2J68.png" referrerpolicy="no-referrer"></p><p>[1]</p><p>發件人 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;格雷格-布羅克曼</p><p>抄送： Sam Altman</p><p>Date： Sun, Nov 22, 2015 at 7:48 PM</p><p>主題： 通話後續</p><p>博客聽起來不錯，但要考慮到中立性和以青委會為中心。</p><p>我更傾向於將博客定位為更吸引普通大眾－－讓大眾支持我們取得成功有很大的價值－－然後為招聘工作準備一個更長、更詳細、更有內幕的版本，並在普通大眾版本的末尾提供鏈接。</p><p>我們需要一個比 1 億美元大得多的數字，以避免與谷歌或 Facebook 的支出相比顯得毫無希望。我認為我們應該説，我們將從 10 億美元的資金承諾開始。這是真的。其他人不提供的，我都會提供。</p><p>模板看起來還不錯，除了默認轉為歸屬現金紅利外，還可以選擇將其轉為 YC 或 SpaceX（需要了解具體數額）的股票。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_l1GG.png" referrerpolicy="no-referrer"></p><p>[2]</p><p>發件人 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>Date： 2018 年 2 月 1 日，星期四，凌晨 3:52</p><p>主題 Fwd： 今天的頂級人工智能機構</p><p>説得一點沒錯。我們或許希望如此，但在我看來，特斯拉是唯一能與谷歌抗衡的公司。即便如此，與谷歌抗衡的可能性也很小，但也不是零。</p><p>開始轉發信息：</p><p>發件人： &nbsp;&nbsp;&lt;&gt;</p><p>致 &nbsp;埃隆-馬斯克 &lt;&gt;</p><p>日期，太平洋標準時間 2018 年 1 月 31 日下午 11:54:30</p><p>主題 Re： 當今頂尖的人工智能機構</p><p>不幸的是，在人工智能的最前沿工作是昂貴的。除了 DeepMind，谷歌還有 Google Brain、Research 和 Cloud。還有 TensorFlow、TPU，它們擁有大約三分之一的研究成果（事實上，它們還舉辦自己的人工智能會議）。</p><p>我還強烈懷疑，要實現 AGI，計算能力將是必要的。如果歷史趨勢能夠説明問題，那麼人工智能的進步主要是由系統－－計算、數據、基礎設施－－驅動的。我們今天使用的核心算法與上世紀 90 年代相比基本沒有變化。不僅如此，任何發表在論文中的算法進展幾乎都可以立即被重新實現和整合。反過來説，如果沒有一定的規模，單靠算法的進步是沒有生命力的。</p><p>在我看來，如今的 OpenAI 正在燒錢，其融資模式無法達到與谷歌（一家 8000 億美元的公司）認真競爭的規模。如果你無法與谷歌認真競爭，卻繼續在開放環境中進行研究，那麼你可能會讓事情變得更糟，並 「免費 「幫助他們，因為他們很容易複製任何進步，並立即將其規模化。</p><p>以營利為目的的轉型可能會隨着時間的推移創造出更穩定的收入來源，而就目前的團隊而言，很可能會帶來大量投資。然而，從零開始打造產品會搶走人工智能研究的重點，而且需要很長時間，目前還不清楚一家公司能否 「趕上 「谷歌的規模，投資者也可能會在錯誤的方向上施加過多壓力。我所能想到的最有希望的方案，正如我之前提到的，就是讓 OpenAI 附屬於特斯拉，將其作為自己的資金來源。我認為，依附於其他大型公司（如蘋果、亞馬遜），會因公司基因不兼容而失敗。打個比方，特斯拉已經建造了火箭的 「第一級「，包括 Model 3 的整個供應鏈、車載電腦和持續的互聯網連接。第二階段 「將是基於大規模神經網絡訓練的完全自動駕駛解決方案，OpenAI 的專業技術可以大大幫助加快這一進程。在大約 2-3 年的時間裏，我們就能推出功能完善的完全自動駕駛解決方案，銷售大量汽車/卡車。如果我們真的做得很好，運輸行業的規模足夠大，我們可以將特斯拉的市值提高到 O（約 10 萬美金），並利用這筆收入為適當規模的人工智能工作提供資金。</p><p>我看不到有任何其他公司有潛力在十年內達到可持續的谷歌規模資本。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_gNCb.png" referrerpolicy="no-referrer"></p><p>[3]</p><p>發件人 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>抄送： Sam Altman</p><p>Date： Wed, Dec 26, 2018 at 12:07 PM</p><p>主題： 我覺得我應該重申</p><p>在執行和資源沒有發生巨大變化的情況下，我對 OpenAI 與 DeepMind/Google 相關性的概率評估是 0%。而不是 1%。我希望不是這樣。</p><p>即使籌集到幾億美元也不夠。這需要每年立即籌集數十億美元，否則就算了。</p><p>不幸的是，人類的未來掌握在【未透露名稱】手中。</p><p>他們所做的遠不止這些。</p><p>我真希望我錯了。</p><p>埃隆</p><hr><p><img src="https://oscimg.oschina.net/oscnet/up-9103940e18f26f6ed78e7c0e58a9b0be1dc.png" referrerpolicy="no-referrer"></p><p>【4】</p><p>Fwd: 恭喜獵鷹 9</p><p>包含 3 條信息</p><p>發件人 &nbsp;Elon Musk</p><p>收件人 &nbsp;Sam Altman、Ilya Sutskever、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 8:18 AM</p><p>主題，收件人： 恭喜獵鷹 9 號</p><p>開始轉發消息：</p><p>From：&nbsp;未透露姓名</p><p>To： &nbsp;埃隆-馬斯克</p><p>日期： 美國中部時間 2016 年 1 月 2 日上午 10:12:32</p><p>主題： 恭喜獵鷹 9 號</p><p>嗨，埃隆</p><p>祝你新年快樂，</p><p>首先祝賀獵鷹 9 號着陸，這是一項了不起的成就。現在是時候組建艦隊了！</p><p>我看到你（還有薩姆和其他 OpenAI 人士）最近接受了很多采訪，大肆宣揚人工智能開源的優點，但我想你應該意識到，這並不是某種能神奇地解決安全問題的靈丹妙藥吧？有很多很好的論據可以説明，為什麼你所採取的方法實際上是非常危險的，事實上可能會增加世界的風險。在這篇博文中，一些比較明顯的觀點得到了很好地闡述，我相信你已經看到了，但還有其他一些重要的考慮因素：</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fslatestarcodex.com%2F2015%2F12%2F17%2Fshould-ai-be-open%2F" target="_blank">http://slatestarcodex.com/2015/12/17/should-ai-be-open/</a></p><p>我很想聽聽你對這些觀點的反駁。</p><p>發件人 &nbsp;Ilya Sutskever</p><p>致 &nbsp;Elon Musk 、Sam Altman、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 9:06 AM</p><p>主題 Fwd: 恭喜獵鷹 9 號</p><p>這篇文章關注的是 「硬起飛 「</p><p>如果發生 「硬起飛「，而安全的人工智能比不安全的人工智能更難構建，那麼通過開放一切，我們就會讓那些能夠獲得大量硬件的不法分子輕而易舉地構建出不安全的人工智能，從而遭遇 「硬起飛」。</p><p>當我們越來越接近構建人工智能時，開始降低開放程度將變得更有意義。openAI 中的 「開放 「意味着，在人工智能建成後，每個人都應從人工智能的成果中獲益，但不分享科學知識也是完全可以的（儘管在短期和中期內，為了招聘的目的，分享一切絕對是正確的策略）。</p><p>來自 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;Ilya Sutskever</p><p>日期 Sat, Jan 2, 2016 at 9:11 AM</p><p>主題 Fwd: 恭喜獵鷹 9 號</p><p>是的</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:37:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281801/openai-elon-musk</guid>
            <link>https://www.oschina.net/news/281801/openai-elon-musk</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【Java 比較 ORM 框架操作數據】操作批量新增、分頁查詢（七）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>orm 框架使用性能比較</h3><h4>比較 mybatis、lazy、sqltoy、mybatis-flex、easy-query、mybatis-mp、jpa、dbvisitor、beetlsql 操作數據</h4><h4>環境：</h4><pre><code>idea 
jdk17
spring boot 3.0.7
mysql 8.0
</code></pre><h3>測試條件常規對象</h3><table><tbody><tr><th>orm 框架</th><th>是否支持 xml</th><th>是否支持 Lambda</th><th>對比版本</th><th>編碼方式</th></tr></tbody><tbody><tr><td>mybatis</td><td>☑️</td><td>☑️</td><td>3.5.4</td><td>lambda +xml 優化</td></tr><tr><td>sqltoy</td><td>☑️</td><td>☑️</td><td>5.2.98</td><td>lambda</td></tr><tr><td>lazy</td><td>✖️</td><td>☑️</td><td>1.2.4-JDK17-SNAPSHOT</td><td>lambda</td></tr><tr><td>mybatis-flex</td><td>☑️</td><td>☑️</td><td>1.8.0</td><td>lambda +xml 優化</td></tr><tr><td>easy-query</td><td>✖️</td><td>☑️</td><td>1.10.31</td><td>lambda</td></tr><tr><td>mybatis-mp</td><td>☑️</td><td>☑️</td><td>1.4.1</td><td>xml 優化</td></tr><tr><td>jpa</td><td>☑️</td><td>☑️</td><td>3.0.7</td><td>----------------------</td></tr><tr><td>dbvisitor</td><td>☑️</td><td>☑️</td><td>5.4.1</td><td>xml 優化</td></tr><tr><td>beetlsql</td><td>支持 md</td><td>☑️</td><td>3.26.0-RELEASE</td><td>insert ignore into 優化</td></tr></tbody></table><h3>數據庫表 (含有唯一性索引 s_u)</h3><pre><code class="language-sql">CREATE TABLE `sys_user`
(
    `column_name` varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '額外字段',
    `create_time` datetime                                DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '創建時間',
    `id`          bigint NOT NULL AUTO_INCREMENT COMMENT '用户 ID',
    `is_deleted`  tinyint(1) DEFAULT NULL COMMENT 'null',
    `password`    varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '密碼',
    `scope`       varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT 'null',
    `status`      tinyint(1) DEFAULT NULL COMMENT '狀態',
    `update_time` datetime                                DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新時間',
    `username`    varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '用户名',
    PRIMARY KEY (`id`) USING BTREE,
    UNIQUE KEY `s_u` (`scope`,`username`)
) ENGINE=InnoDB AUTO_INCREMENT=9223371632070323791 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
</code></pre><h3>比較方法:增加、修改、刪除、分頁查詢（當前項目暫時只比較批量新增和分頁）</h3><h4>項目設計</h4><ul><li><p>聲明 ORMRepository 接口提供對應增刪改查方法&nbsp;</p></li><li><p>聲明 ORMComparisonRepository 接口，繼承 ORMRepository 下游由不同 ORM 實現</p></li><li><p>聲明 SysUserRepository 接口，繼承 ORMRepository 用於循環調用不同 orm 實現方法執行方法測試產生測試結果</p></li><li><p>聲明抽象類 SysUserRepositoryAbstractRecord 繼承 ORMComparisonRepository 並且提供對應的框架執行結果存儲&nbsp;</p></li><li><p>不同 ORM 框架創建 ORMComparisonRepository 的實現</p></li><li><p>不同 ORM 操作數據的實現</p></li></ul><h3>測試條件，批量插入數據 10、100、1000、10000、100000 ，分頁查詢數據 10、100、1000、10000、100000</h3><pre><code>項目啓動後使用瀏覽器打開 http://localhost:1003/sys/user/run-compare
</code></pre><h3>測試條件（細節比較） 批量插入數據 1～10000，分頁查詢數據 1～10000</h3><pre><code>項目啓動後使用瀏覽器打開 http://localhost:1003/sys/user/run-particulars-compare
</code></pre><h3>測試執行過程</h3><pre><code>清空需要插入表中所有數據
通過三種 ORM 框架進行數據批量新增、而後進行分頁查詢，記錄消耗時間，輸出 md 文檔
</code></pre><h3><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flocalhost%3A1003%2F" target="_blank">查看結果曲線圖</a></h3><p><img height="757" src="https://oscimg.oschina.net/oscnet/up-61371d910485615d211e20a380e8457b728.png" width="1401" referrerpolicy="no-referrer"></p><h3>測試結果（結果只提供參考）</h3><table><tbody><tr><th>MYBATIS_FLEX(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>25 毫秒</strong></td><td><strong>18 毫秒</strong></td><td><strong>73 毫秒</strong></td><td><strong>671 毫秒</strong></td><td><strong>6653 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>51 毫秒</strong></td><td><strong>28 毫秒</strong></td><td><strong>84 毫秒</strong></td><td><strong>601 毫秒</strong></td><td><strong>5963 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>LAZY(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>4 毫秒</strong></td><td><strong>12 毫秒</strong></td><td><strong>48 毫秒</strong></td><td><strong>353 毫秒</strong></td><td><strong>3512 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_MP(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>8 毫秒</strong></td><td><strong>16 毫秒</strong></td><td><strong>66 毫秒</strong></td><td><strong>589 毫秒</strong></td><td><strong>6060 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>DB_VISITOR(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>67 毫秒</strong></td><td><strong>155 毫秒</strong></td><td><strong>897 毫秒</strong></td><td><strong>8368 毫秒</strong></td><td><strong>82348 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>JPA(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>67 毫秒</strong></td><td><strong>64 毫秒</strong></td><td><strong>952 毫秒</strong></td><td><strong>8608 毫秒</strong></td><td><strong>95946 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>EASY_QUERY(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>58 毫秒</strong></td><td><strong>91 毫秒</strong></td><td><strong>395 毫秒</strong></td><td><strong>1608 毫秒</strong></td><td><strong>15802 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>SQLTOY(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>35 毫秒</strong></td><td><strong>36 毫秒</strong></td><td><strong>173 毫秒</strong></td><td><strong>1540 毫秒</strong></td><td><strong>15167 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>BEETL_SQL(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>187 毫秒</strong></td><td><strong>106 毫秒</strong></td><td><strong>260 毫秒</strong></td><td><strong>1713 毫秒</strong></td><td><strong>16778 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_FLEX(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>28 毫秒</strong></td><td><strong>8 毫秒</strong></td><td><strong>19 毫秒</strong></td><td><strong>113 毫秒</strong></td><td><strong>865 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>26 毫秒</strong></td><td><strong>7 毫秒</strong></td><td><strong>20 毫秒</strong></td><td><strong>98 毫秒</strong></td><td><strong>732 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>LAZY(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>5 毫秒</strong></td><td><strong>5 毫秒</strong></td><td><strong>9 毫秒</strong></td><td><strong>71 毫秒</strong></td><td><strong>474 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_MP(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>28 毫秒</strong></td><td><strong>5 毫秒</strong></td><td><strong>16 毫秒</strong></td><td><strong>89 毫秒</strong></td><td><strong>752 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>DB_VISITOR(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>14 毫秒</strong></td><td><strong>4 毫秒</strong></td><td><strong>9 毫秒</strong></td><td><strong>50 毫秒</strong></td><td><strong>424 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>JPA(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>85 毫秒</strong></td><td><strong>11 毫秒</strong></td><td><strong>49 毫秒</strong></td><td><strong>117 毫秒</strong></td><td><strong>805 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>EASY_QUERY(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>39 毫秒</strong></td><td><strong>9 毫秒</strong></td><td><strong>22 毫秒</strong></td><td><strong>60 毫秒</strong></td><td><strong>474 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>SQLTOY(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>23 毫秒</strong></td><td><strong>4 毫秒</strong></td><td><strong>10 毫秒</strong></td><td><strong>45 毫秒</strong></td><td><strong>249 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>BEETL_SQL(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>43 毫秒</strong></td><td><strong>13 毫秒</strong></td><td><strong>21 毫秒</strong></td><td><strong>76 毫秒</strong></td><td><strong>633 毫秒</strong></td></tr></tbody></table><h4>寫在最後</h4><p>細節數據對比（一萬以內基本相差不大）</p><ul><li>細節數據對比，數據屬於併發行測試數據，如果測試總數是一百，那麼會執行一百次 batchStory，一百次 findPage 每次執行的條數在之前數據的基礎上+1</li></ul><p>從形成的折線圖看（具體趨勢看排名與測試結果）</p><ul><li>存儲性能對比: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql 更適合併發性數據存儲。jpa、db_visitor 處理耗時較長</li><li>分頁查詢性能對比: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、db_visitor、beetlSql 都比較穩定。jpa 處理時間明顯起伏</li></ul><p><img height="679" src="https://oscimg.oschina.net/oscnet/up-f09e3ee8efef84baba88890fb63e6d31a3b.png" width="1406" referrerpolicy="no-referrer"></p><p><img height="698" src="https://oscimg.oschina.net/oscnet/up-928ba767617bad09b2b47481d399c812a70.png" width="1402" referrerpolicy="no-referrer"></p><p>批量保存：</p><ul><li>一萬條數據以內 lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql、jpa、db_visitor 性能趨於一致</li><li>十萬數據時，處理時間由快到慢依次是: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy、beetlSql、db_visitor、jpa，其中 db_visitor、jpa 處理時間明顯起伏</li></ul><p>分頁查詢：</p><ul><li>一萬條數據以內，幾款 ORM 均保持在 200 毫秒內</li><li>十萬數據時，處理時間由快到慢依次是: sqltoy、db_visitor、easy-query、lazy、beetlSql、mybatis、mybatis-mp、jpa、mybatis-flex</li><li>&nbsp;</li></ul><h3>快速數據對比 (大數據曲線圖)</h3><p><img height="674" src="https://oscimg.oschina.net/oscnet/up-6a71c9a1e912b97ed59450e7362b127b8cf.png" width="1407" referrerpolicy="no-referrer"></p><p><img height="686" src="https://oscimg.oschina.net/oscnet/up-f5898a01682ab16289012b658c8c02e3c2c.png" width="1389" referrerpolicy="no-referrer"></p><h4><a href="https://gitee.com/wujiawei1207537021/wu-compare-orm-demo">當前項目地址</a></h4><h4><a href="https://gitee.com/wujiawei1207537021/wu-framework-parent/tree/master/wu-database-parent">lazy-orm 地址</a></h4><h4><a href="https://gitee.com/baomidou/mybatis-plus">mybatis 地址</a></h4><h4><a href="https://gitee.com/sagacity/sagacity-sqltoy">sqltoy 地址</a></h4><h4><a href="https://gitee.com/mybatis-flex/mybatis-flex">mybatis-flex 地址</a></h4><h4><a href="https://gitee.com/xuejm/easy-query">easy-query 地址</a></h4><h4><a href="https://gitee.com/mybatis-mp/mybatis-mp">mybatis-mp 地址</a></h4><h4><a href="https://gitee.com/zycgit/dbvisitor">dbvisitor 地址</a></h4><h4><a href="https://gitee.com/xiandafu/beetlsql">beetlsql 地址</a></h4></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:24:40 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281792</guid>
            <link>https://www.oschina.net/news/281792</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌在其搜索排名系統中對垃圾郵件和人工智能進行降級]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2F2024%2F3%2F5%2F24091099%2Fgoogle-search-high-quality-results-spam-ai-content" target="_blank">據 The Verge 報道</a></u>，谷歌正在對其搜索排名系統進行一些新的更改，這些更改旨在幫助在結果中顯示好的內容，並隱藏網絡上一些最糟糕和最憤世嫉俗的內容。</p><p>該公司表示，它在降級內容方面做得更好，這些內容只是為了總結其他內容——有時可能是正常的搜索引擎優化內容，但也越來越多地成為生成人工智能工具的工作——並打擊人們用來欺騙的一些技巧它的排名系統。</p><p>谷歌搜索副總裁潘杜·納亞克 (Pandu Nayak) 列舉了谷歌現在認為是垃圾郵件行為並打算降低排名的三個例子。</p><p>第一個是大規模內容：這些網站每天通過低薪承包商或人工智能生成器創建數千篇低質量文章，並將這些內容定位在搜索結果中。</p><p>第二種垃圾郵件行為是 Nayak 所説的「網站聲譽濫用」。這是指一個原本受人尊敬的網站出租其部分網站來傳播垃圾郵件。</p><p>第三就是人工智能，人工智能生成的內容應該如何排名的問題才剛剛開始，因為它既試圖將人工智能帶給每個人，又試圖拯救網絡免於被淘汰。甚至谷歌自己的搜索引擎也成為人工智能機器。而且總會有新的方法來讓它在搜索結果中名列前茅。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:03:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281786/google-search-high-quality-results-spam-ai-content</guid>
            <link>https://www.oschina.net/news/281786/google-search-high-quality-results-spam-ai-content</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CSIS：2023 年全球人工智能發展回顧及 2024 年人工智能政策預測]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">2024 年 1 月 30 日，戰略與國際問題研究中心 CSIS 發佈報告《2024 年人工智能政策預測》，回顧了 2023 年全球人工智能的發展，提出了 2024 年在 AI 政策方面需要關注的 10 個重點，以及 AI 領域關鍵技術術語。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" height="301" src="https://static.oschina.net/uploads/space/2024/0306/162236_PCSo_4700705.png" width="360" referrerpolicy="no-referrer"></span></p><p>以下是報告主要內容：</p><div><div><ol><li><p style="margin-left:0; margin-right:0"><strong>2023 年 AI 發展回顧</strong>：</p><ul><li>中國實施了管理深度偽造的新法律。</li><li>微軟對 OpenAI 進行了鉅額投資。</li><li>美國國防部更新了關於武器系統中自主性的指令。</li><li>NIST 發佈了 AI 風險管理框架。</li><li>美國與歐盟宣佈加速聯合 AI 研究。</li><li>荷蘭和日本加入美國限制對中國半導體製造設備出口的努力。</li><li>OpenAI 的 ChatGPT 成為歷史上增長最快的應用。</li><li>美國和歐盟簽署了關於 AI 治理的協議。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AI 技術影響</strong>：</p><ul><li>AI 聊天機器人用户數量激增，尤其是 OpenAI 的 ChatGPT。</li><li>大型語言模型（LLM）如 GPT-4 和 Meta 的 LLaMA 不斷推出，模型規模和參數不斷增大。</li><li>AI 在多個科學領域取得突破，如材料科學和氣象學。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AI 治理與監管</strong>：</p><ul><li>美國、歐盟和中國等地區採取了 AI 監管措施。</li><li>美國商務部發布了 AI 風險管理框架，旨在增強 AI 的透明度和安全性。</li><li>歐盟通過了 AI 法案，這是迄今為止最全面的 AI 監管法規。</li><li>中國發布了關於生成性 AI 服務的監管措施，包括確保數據訓練的合法性。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>國際合作與治理</strong>：</p><ul><li>英國舉辦了全球 AI 安全峯會，簽署了 Bletchley 宣言，旨在促進 AI 的透明度和問責制。</li><li>G7 和聯合國等國際組織在 AI 治理方面進行了討論，強調了國際合作的重要性。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>私營部門的角色</strong>：</p><ul><li>私營部門在 AI 治理中扮演了重要角色，與政府合作管理 AI 技術。</li><li>AI 相關訴訟數量增加，涉及數據隱私、版權和專利法等問題。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>軍事應用</strong>：</p><ul><li>美國國防部更新了關於武器系統中自主性的指令，並推出了 Replicator 計劃，旨在加速 AI 啓用的自主系統的部署。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>企業投資與市場動態</strong>：</p><ul><li>AI 成為企業投資的熱點，尤其是「Magnificent Seven」（Meta、亞馬遜、蘋果、微軟、谷歌、特斯拉和英偉達）等科技巨頭在股市中表現突出。</li><li>私人投資在生成性 AI 領域達到歷史新高。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>2024 年展望</strong>：</p><ul><li>報告提出了 2024 年值得關注的 AI 發展，包括全球 AI 治理的實質性影響、第三方紅隊測試的實踐、國會是否能通過全面的 AI 立法等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>術語定義</strong>：</p><ul><li>報告最後提供了 2024 年關鍵 AI 術語的定義，如智能體、生成性 AI、大型語言模型（LLM）、自然語言處理（NLP）等。</li></ul></li></ol><p style="margin-left:0; margin-right:0">報告強調了 AI 技術的快速發展和其在各個領域的廣泛應用，同時也指出了隨之而來的監管挑戰和國際合作的重要性。報告還提到了 AI 在軍事應用、企業投資以及國際政策制定中的作用，以及對未來一年 AI 發展的預測和展望。</p></div><div><div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">報告詳情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「開源中國 APP - 報告模塊」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下載地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前僅提供 Android 版本</em>）</strong></p></div></div></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 08:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281773</guid>
            <link>https://www.oschina.net/news/281773</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Swift 5.10 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Swift 5.10 現已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fblog%2Fswift-5.10-released%2F" target="_blank">發佈</a>，此版本<span style="color:#000000"><strong>在併發語言模型中實現了完全的數據隔離。</strong>公告稱，「這一重要的里程碑經過了多年的積極開發，歷經多個版本。」</span></p><p><span style="color:#000000">併發模型是在 Swift 5.5 中引入的，包括</span><code class="language-plaintext">async</code><span style="color:#000000">/</span><code class="language-plaintext">await</code><span style="color:#000000">、actors 和結構化併發 (structured concurrency)。Swift 5.7 引入了<code class="language-plaintext">Sendable</code>線程安全類型的基本概念，其值可以在任意併發上下文之間共享，而不會引入數據競爭的風險。現在，在 Swift 5.10 中，當啓用完整的併發檢查選項時，語言的所有區域都會在編譯時強制執行完全數據隔離。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Swift 5.10 中的完全數據隔離為下一個主要版本 Swift 6 奠定了基礎。Swift 6.0 編譯器將提供新的、可選的 Swift 6 語言模式，該模式將默認強制執行完全數據隔離，項目團隊將着手進行過渡消除所有用 Swift 編寫的軟件之間的數據競爭。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Swift 5.10 會在某些情況下產生數據競爭警告，而在這些情況下，通過額外的編譯器分析可以證明代碼是安全的。Swift 6 版本的語言開發的一個主要重點是通過減少已證明安全的常見代碼模式中的誤報併發錯誤，來提高嚴格併發檢查的可用性。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><strong><span style="color:#000000">完全數據隔離</span></strong></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Swift 5.10 完善了語言各個角落的數據競爭安全語義，並修復了<code class="language-plaintext">Sendable</code>和 actor isolation checking 中的大量錯誤，以加強完整併發檢查的保證。使用編譯器 flag<code class="language-plaintext">-strict-concurrency=complete</code>構建代碼時，Swift 5.10 將在編譯時診斷數據競爭的可能性，除非使用 explicit unsafe opt-out（例如<code class="language-plaintext">nonisolated(unsafe)</code>或<code class="language-plaintext">@unchecked Sendable</code>）。</span></p><pre><code> warning: expression is 'async' but is not marked with 'await'
    let model = MyModel.shared
                ^~~~~~~~~~~~~~
                await</code></pre><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">解決數據競爭的可能修復方法有：</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">1)&nbsp;</span><span style="color:#000000">access&nbsp;</span><code class="language-plaintext">MyModel.shared</code><span style="color:#000000">&nbsp;asynchronously using&nbsp;</span><code class="language-plaintext">await</code></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">2) 使<code class="language-plaintext">MyModel.init</code>和<code class="language-plaintext">MyModel.shared</code>兩者都<code class="language-plaintext">nonisolated</code>，並將需要 main actor 的代碼移到單獨的隔離方法中，或 </span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">3) 將<code class="language-plaintext">useShared()</code>隔離到<code class="language-plaintext">@MainActor</code>。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fswift%2Fblob%2Frelease%2F5.10%2FCHANGELOG.md" target="_blank">可以在 Swift 5.10 發行説明</a>中查看更多詳細信息。</span></p><p><strong>Unsafe opt-outs</strong></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Swift 5.10 引入了一個新<code class="language-plaintext">nonisolated(unsafe)</code>keyword，用於 opt out 對存儲的屬性和變量的 actor isolation checking。<code class="language-plaintext">nonisolated(unsafe)</code>可用於任何形式的存儲，包括存儲屬性、局部變量和全局/靜態變量。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><code class="language-plaintext">nonisolated(unsafe)</code>還消除了對<code class="language-plaintext">@unchecked Sendable</code>wrapper types 的需要，</span>這些類型僅用於在不存在併發訪問可能性時跨隔離邊界傳遞非<span style="color:#000000"><code class="language-plaintext">Sendable</code></span>值的特定實例：</p><pre><code>// 'MutableData' is not 'Sendable'
class MutableData { ... }

func processData(_: MutableData) async { ... }

@MainActor func send() async {
  nonisolated(unsafe) let data = MutableData()
  await processData(data)
}</code></pre><h4><strong>Swift 6 之前的語言演變</strong></h4><p>Swift 的下一個版本將是 Swift 6。鑑於 Swift 5.10 中的完整併發模型限制過多，團隊目前正在積極開發幾項 Swift Evolution 提議，以通過消除誤報數據競爭錯誤來提高完整數據隔離的可用性。</p><p>這項工作包括：當編譯器確定沒有併發訪問的可能性時，取消對跨隔離邊界傳遞 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fswift-evolution%2Fblob%2Fmain%2Fproposals%2F0414-region-based-isolation.md" target="_blank">non-<code class="language-plaintext">Sendable</code></a>值的限制；為&nbsp;functions 和 key-paths&nbsp;提供更有效的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fswift-evolution%2Fblob%2Fmain%2Fproposals%2F0418-inferring-sendable-for-methods.md" target="_blank"><code class="language-plaintext">Sendable</code>&nbsp;inference</a>&nbsp;等。可以在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fswift-evolution%2F%23%3Fversion%3D6.0" target="_blank">Swift.org/swift-evolution</a>&nbsp;上找到將完善 Swift 6 的提案集。</p><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fblog%2Fswift-5.10-released%2F" target="_blank">查看官方博客</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 07:07:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281751/swift-5-10-released</guid>
            <link>https://www.oschina.net/news/281751/swift-5-10-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Open-Sora：開源 Sora 復現方案，成本降低 46%，序列擴充至近百萬]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Colossal-AI 開源了完整的 Sora 復現架構方案 Open-Sora，聲稱可降低 46% 復現成本，並將模型訓練輸入序列長度擴充至 819K patches。</p><h2><strong>Sora 算法復現方案</strong></h2><p>在 Sora 的技術報告中，Sora 使用了一個視頻壓縮網絡將各種尺寸的視頻壓縮成一個隱空間 (latent space) 的時空塊序列 (a sequence of patial temporal patch)，然後使用了 Diffusion Transformer 進行去噪，最後進行解碼生成視頻。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f00afc0ec2f11a40cd894bf027b8730d85.png" referrerpolicy="no-referrer"></p><p>Open-Sora 將 Sora 可能使用的訓練 pipeline 歸納為下圖。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e8f00fbfc988a866c34ebecf3e2bf47c561.png" referrerpolicy="no-referrer"></p><p>目前 Open-Sora 已涵蓋：</p><ul><li><p>提供<strong>完整的 Sora 復現架構方案</strong>，包含從數據處理到訓練推理全流程。</p></li><li><p>支持<strong>動態分辨率</strong>，訓練時可直接訓練任意分辨率的視頻，無需進行縮放。</p></li><li><p>支持<strong>多種模型結構</strong>。由於 Sora 實際模型結構未知，我們實現了 adaLN-zero、cross attention、in-context conditioning(token concat) 等三種常見的多模態模型結構。</p></li><li><p>支持<strong>多種視頻壓縮方法</strong>。用户可自行選擇使用原始視頻、VQVAE（視頻原生的模型）、SD-VAE（圖像原生的模型）進行訓練。</p></li><li><p>支持<strong>多種<strong><strong>並行</strong></strong>訓練優化</strong>。包括結合 Colossal-AI 的 AI 大模型系統優化能力，及 Ulysses 和 FastSeq 的混合序列並行。</p></li></ul><h2>性能</h2><p>以在單台 H800 SXM 8*80GB GPU 上使用 DiT-XL/2 模型的性能測試為例。在 600K 的序列長度時，Open-Sora 的方案比基線方案有<strong>40%<strong><strong>以上</strong></strong>的性能提升和成本降低</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25ab5d8374c10bc5678d1da4ec093be7aa4.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-da251590ba84c47683092b37c9ad6f1896c.png" referrerpolicy="no-referrer"></p><p>Open-Sora 開源地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FOpen-Sora" target="_blank">https://github.com/hpcaitech/Open-Sora</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 06:14:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281739</guid>
            <link>https://www.oschina.net/news/281739</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟將 CBL-Mariner Linux 重命名為 Azure Linux]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">微軟內部用於各種用途的 Linux 發行版曾被稱為 CBL-Mariner，意為"Common Base Linux"，而現在似乎正在向 Azure Linux 過渡。</span></p><p><span style="color:#000000">Azure Linux 是從 CBL-Mariner 演化而來的，但注意不要將其與微軟基於 Linux 的 Azure Sphere 操作系統混淆，後者是物聯網/微控制器的使用平台。</span></p><p><span style="color:#000000"><img alt="" height="333" src="https://oscimg.oschina.net/oscnet/up-bcba0fe512236d7141e4845b2311f73e148.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">隨着 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazurelinux%2Freleases%2Ftag%2F2.0.20240301-2.0" target="_blank">CBL-Mariner 2.0.20240301</a> 的發佈，該項目現在已重定向到 GitHub 上的 Microsoft/AzureLinux 項目。CBL-Mariner 存儲庫已更名為"AzureLinux"，其他對 CBL-Mariner 的引用也已過渡到 Azure Linux 品牌，但仍保留了一些 CBL-Mariner 標記。</span></p><p><span style="color:#000000">在新發布的 v2.0.20240301 版本中，還有一些源代碼更新<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazurelinux%2Fpull%2F7664%2Ffiles" target="_blank">開始重命名工件</a>，例如 Azure Linux 從"MARINER_VERSION"更名為"AZL_VERSION"。</span></p><p><span style="color:#000000">微軟是否會更好地公開定位其內部 Linux 平台，或者 Azure Linux 還會有哪些其他變化，值得進一步的探究。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 06:13:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281738/microsoft-cbl-mariner-azure-linux</guid>
            <link>https://www.oschina.net/news/281738/microsoft-cbl-mariner-azure-linux</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[有道 QAnything 背後的故事 --- 關於 RAG 的一點經驗分享]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，我們開源了有道自研的 RAG（Retrieval Augmented Generation) 引擎 QAnything。該引擎允許用户上傳 PDF、圖片、Word、Excel、PowerPoint 等多種格式的文檔，並實現類似於 ChatGPT 的互動問答功能，其中每個答案都能精確追溯到相應的文檔段落來源。QAnything 支持純本地部署，上傳文檔數量無上限，問答準確率高。</p><p>QAnything 自開源以來，迅速吸引了開發者社區的廣泛關注，並很快登上了 GitHub trending 榜單。短短一個月內，下載次數已達數萬次，其中，我們的語義嵌入排序模型 BCEmbedding 更是達到了驚人的 60 萬次下載。根據社區的熱情反饋，我們決定分享 QAnything 背後的研發故事、技術路線選擇以及我們的經驗，希望能夠為社區帶來啓發。</p><p><strong>QAnything 的起源</strong></p><p>與市場上的其他 Retrieval Augmented Generation (RAG) 產品相比，QAnything 引擎的研發軌跡略顯不同。它不是一開始就被設定為一個具體的項目目標，而是在項目進展中，通過不斷的探索和實踐，逐步成形的。這個過程雖然經歷了一些波折，但正是這些經歷，讓我們在 RAG 領域積累了豐富的實踐經驗。</p><p><strong>從文檔翻譯到文檔問答</strong></p><p>QAnything 的研發團隊最初專注於文檔翻譯。2022 年我們啓動了一個為期一年的文檔翻譯的升級的項目，到 2023 年 3 月份上線，效果提升顯著。正好那時候 ChatGPT 和類似技術正在興起，我們意識到這正是將我們現有技術擴展至文檔問答的絕佳時機。因此，我們毫不猶豫地為我們的文檔翻譯服務增添了問答功能，該功能能夠根據文檔內容自動推薦問題並提供答案，於 5 月份正式推出。</p><p><img alt="" height="381" src="https://oscimg.oschina.net/oscnet/up-f997fd94e09af0d0e75e09aa1f1778b3dd5.png" width="676" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#303030">(視頻鏈接：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fwww.bilibili.com%252Fvideo%252FBV1fw4m1Z7QX%252F" rel="nofollow" target="_blank"><span style="color:#3db24b !important">https://www.bilibili.com/video/BV1fw4m1Z7QX/</span></a><span style="background-color:#ffffff; color:#303030">）</span></p><p>之所以能夠輕鬆地擴展到文檔問答，是因為有道在文檔翻譯領域的深厚積累。我們的文檔翻譯服務因其卓越的性能而聞名，這主要得益於兩大核心技術：先進的翻譯引擎和精準的文檔解析/OCR 技術。多年來，在翻譯和 OCR 領域的持續探索和創新，為我們構建 Retrieval Augmented Generation (RAG) 系統提供了堅實的基礎。</p><p>首先，核心技術方面，我們的翻譯模型基於 Transformer 架構，這與當前研究領域的大型語言模型（LLM）緊密相連，實質上並無顯著區別。所謂 LLM，就是很大的 Transformer 模型，就是我們天天在研究的東西。ChatGPT 出來後，我們之所以能迅速掌握並擴展我們的模型，例如開發了針對教育場景的「子曰」大模型，這一切都得益於我們對 Transformer 模型的深入理解和應用。</p><p>接着，關於 RAG 系統，它不僅僅是外部數據和 LLM 的簡單疊加。鑑於用户文檔的多樣性，特別是 PDF 文件中複雜的圖文混排，僅僅提取文本往往會帶來信息的失真。例如，將具有邏輯連貫性的文本分割成多個片段，或者將圖表數據錯誤地融入文本，這些都會嚴重影響信息的準確性。正因如此，我們長期致力於文檔解析技術的研發，能夠精確地識別和分析文檔中的每一部分，無論是段落、圖表、公式還是其他元素，確保將用户的查詢以最適合機器處理的方式進行組織和檢索。</p><p>藉助有道翻譯龐大的用户基礎，我們得以在實際應用中不斷完善和優化我們的系統。日均活躍用户數達百萬級別的大數據反饋，為我們提供了寶貴的實踐經驗，使我們能夠持續提升系統性能，滿足用户對高質量翻譯和問答服務的需求。</p><p><br><strong>從文檔問答到速讀</strong></p><p>有道速讀 ([https://read.youdao.com](https://read.youdao.com/)) 是我們算法研究員從自己的需求出發做的產品。有道翻譯桌面端雖然已經上線了文檔問答，但是它主要是面向大眾設計的，適合通用的文檔。我們經常讀論文，希望有一些論文相關的更個性一點的功能。而有道翻譯用户量太大了，不方便隨意改動。</p><p><br> 我們做有道速讀，一開始主要是面向論文閲讀做的。這也是我們新技術的試驗田，迭代快一點。我們看到了 wordtune 出了個段落摘要和對照的功能，用着特別爽，但是很貴，我們就把那個功能與 RAG 整合在一起，又能摘要讀段落，又能問答，方便溯源。論文一般都會講自己方法多好，我們就把其他人對這篇論文的評價信息也給整合起來了，做了論文口碑，把一篇論文的優勢和侷限更客觀的展示出來。在內部做研發的過程中，有個研究人員希望能自動寫綜述，我們就在速讀上加上了自動綜述的功能，對每一篇論文，把前後引用的論文全部抓來，自動做問答，然後整理成報告。</p><p>有道速讀可以看作是 RAG 在某個垂直領域的應用。因為裏面的口碑、綜述、文章解讀等功能，都可以認為是先設置一個模版，有一堆問題（或者自動生成的），然後通過自問自答的方式，生成關鍵信息，最後再總結潤色成文，這一切過程都是全自動的。</p><p>速讀給了我們一個訓練場，讓我們調試應用新技術，這個過程也學到了很多，團隊進步很大。當然，速讀現在也不只侷限於論文閲讀了。</p><p><img alt="" height="801" src="https://oscimg.oschina.net/oscnet/up-6f955fec46dcbc86a2e0a7cca2c0797fac3.png" width="1280" referrerpolicy="no-referrer"></p><p><strong>從速讀到 Qanything</strong></p><p>速讀主要是單篇問答（6 月份剛上線時候只支持單篇，現在也支持多篇問答了，和 QAnything 主要區別是速讀更偏重閲讀的場景，QAnything 偏重問答的場景，底層引擎是一樣的），且只支持 pdf 的格式。QAnything 是支持多文檔問答的，不限文檔格式。</p><p>做 Qanything 有個契機。去年 7 月份的時候，網易的 IT 集團想升級他們的客服系統，找到我們，問能否基於他們的 IT 文檔做一個自動問答機器人，因為他們看到了我們的文檔問答效果，覺得做的不錯。於是我們就拿着他們的文檔和歷史的問答數據快速實驗了一下，發現經過我們的系統後，70% 的轉人工的次數都可以被省下來，由 AI 來回答。</p><p>客服這個場景，用户的文檔格式非常多樣，回答問題需要綜合各種文檔的內容。於是我們在這個場景需求的推動下，做了多文檔問答。我們給這個多文檔問答系統取了一個大氣的名字，叫 Qanything，中文名字叫「萬物皆可問」。</p><p>QAnything，也是我們的願景。QAnything 的前兩個字母是 Q 和 A，也是問答的意思，後面是 anything，希望什麼都可以放進去，什麼東西都可以提問。</p><p>在去年 8 月份的時候，除了內部客户要，有道智雲的外部 B 端客户也需要這樣的多文檔問答系統，還需要私有化。於是我們就做了大模型的小型化適配，做了私有化的版本，可以直接跑在遊戲本上的。整個系統是完整的，可直接使用，也可以通過 API 調用。給了客户，賣了點錢。</p><p><img alt="" height="379" src="https://oscimg.oschina.net/oscnet/up-db8c48d9e609a5a09c0233eef0aeced2c29.png" width="676" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#303030">（視頻鏈接：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fwww.bilibili.com%252Fvideo%252FBV1FC411s7gQ%252F" rel="nofollow" target="_blank">https://www.bilibili.com/video/BV1FC411s7gQ/</a><span style="background-color:#ffffff; color:#303030">）</span></p><p><strong>從 QAanyhing 到升學諮詢</strong><br> &nbsp;<br> 我們一直將 qanything 的體驗頁掛在網上，主要是為了做，有道智雲 toB 生意的時候給外部用户體驗的，也沒怎麼宣傳。去年 9 月份的時候，突然有一天，我們的精品課事業部（有道領世）的人找上門來，説希望合作 QAnything。原來，他們不知道通過哪裏的渠道知道了我們的 QAnything，去體驗了下，發現效果很好。比他們自己用 langchain/lamma index+chatgpt 搭建了很久的系統，效果要好很多。</p><p>有道領世在高中升學領域深耕多年，積累了海量的升學數據資料，有幾萬份的文檔，還有大量的數據存儲在數據庫裏。我們的任務是通過 QAnything，結合這樣的積累的數據，打造出一個私人 AI 規劃師，針對每個家長和學生，提供個性化、更加全面、專業、及時的升學規劃服務。</p><p>一開始，我們把全部數據直接塞入我們 QAnything 系統，升學百科問答只有 45% 的準確率。經過一段時間的反覆迭代優化，我們把確確率提升到了 95%。目前系統可以解答用户關於高考政策、升學路徑、學習生活以及職業規劃等各種問題。未來隨着不斷地數據補充和更新，準確率會一直上漲。</p><p>有道 AI 升學規劃師產品做出來後，我們都為它的體驗感到驚豔。</p><p><img alt="" height="505" src="https://oscimg.oschina.net/oscnet/up-f77f7ac44e748438e8d3638886acd511458.png" width="674" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#303030">（視頻鏈接：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fwww.bilibili.com%252Fvideo%252FBV1Bt421b7am%252F" rel="nofollow" target="_blank">https://www.bilibili.com/video/BV1Bt421b7am/</a><span style="background-color:#ffffff; color:#303030">）</span></p><p><br><strong>Qanything 開源</strong></p><p>今年 1 月份，我們整理了下我們的 QAnything 的代碼和模型，將適合開源的部分開放出來了。我們做這事，希望能和社區一起，共同推動 RAG 技術應用的發展。最近這個月，社區給了我們很對反饋，也讓我們受益良多。</p><p>QAnything 架構解析</p><p>這次開源包括了模型和系統等所有必要的模塊。模型方面包括 ocr 解析、embedding/rerank，以及大模型。系統方面包括向量數據庫、mysql 數據庫、前端、後端等必要的模塊。整個引擎的功能完整，用户可以直接下載，不需要再搭配其他的模塊即可使用。系統可擴展性也非常好，只要硬盤內存足夠，就可以一直建庫，支持無上限的文檔。<br><img alt="" height="1016" src="https://oscimg.oschina.net/oscnet/up-e97bf7c2bc4e2b7c629959740e9a816df26.png" width="1146" referrerpolicy="no-referrer"></p><p>系統的工作流程主要包含三個環節：</p><p>- &nbsp; 索引（indexing）：文本索引的構建包括以下步驟：文檔解析、文本分塊、Embedding 向量化和創建索引。先將不同格式的原始文件解析轉換為純文本，再把文本切分成較小的文本塊。通過 Embedding 為每一個文本塊生成一個向量表示，用於計算文本向量和問題向量之間的相似度。創建索引將原始文本塊和 Embedding 向量以鍵值對的形式存儲，以便將來進行快速和頻繁的搜索。<br> - &nbsp; 檢索（Retrieval）：使用 Embedding 模型將用户輸入問題轉換為向量，計算問題的 Embedding 向量和語料庫中文本塊 Embedding 向量之間的相似度，選擇相似度最高的前 K 個文檔塊作為當前問題的增強上下文信息。<br> - &nbsp; 生成（Generation）：將檢索得到的前 K 個文本塊和用户問題一起送進大模型，讓大模型基於給定的文本塊來回答用户的問題。</p><p><br><strong>Bcembedding 模型</strong></p><p>Embedding 是 RAG 系統裏面最關鍵的模塊。為啥要自己訓練 embedding 模型？一開始我們也是直接去嘗試 openai 的 ada embedding 以及開源的 embedding 模型。但是我們很快發現，這樣做有很大弊端。首先，在我們的業務場景下，外部的 embedding 效果並不如宣傳的那麼好。openai 的 embedding 接口除了效果不好外，還很慢。我們後來自研了 embedding，因為是放在自己服務器上，調用起來比 openai 接口快一百倍。其次，很多開源的 embedding 模型在 mteb 等地方刷傍刷的很高，但是那些刷榜的分值並不完全能反映真實的效果。第三，我們業務場景有很多混合語言的情況，比如庫裏面放的是英文的文檔，用户用中文去問答。這種跨語種的能力，現有模型支持不好。第四，單純的 embedding 在檢索排序上天花板比較低，所以我們在 embedding 的基礎上又做了 rerank，共享同樣的底座，head 不一樣。</p><p>為啥我們自己訓練的模型會比 openai 的效果好？我們認為可能是通才和專才的區別。openai 是通才，但是它的效果遠未達到萬能的地步，大家不必迷信。在我們的場景下 (客服問答以及一些 toB 客户的場景），openai 的 ada2 embedding 的檢索準確率只有 60%，而經過訓練的 bcembedding 檢索準確率可以達到 95%。</p><p>我們自研的[BCEmbedding](https://github.com/netease-youdao/BCEmbedding)，總的來講有兩個特色：</p><p>- &nbsp; 中英雙語和跨語種能力</p><p>我們收集開源數據集（包括摘要、翻譯、語義改寫、問答等），來實現模型通用的基礎語義表徵能力。為了實現一個模型就可以實現中英雙語、跨語種的檢索任務，我們依賴網易有道多年積累的強大的翻譯引擎，對數據進行處理，獲得中英雙語和跨語種數據集。實現一個模型就可以完成雙語和跨語種任務。</p><p>- &nbsp; 多領域覆蓋</p><p>我們分析現有市面上常見或可能的應用場景，收集了包括：教育、醫療、法律、金融、百科、科研論文、客服 (faq)、通用 QA 等場景的語料，使得模型可以覆蓋儘可能多的應用場景。同樣的依靠網易有道翻譯引擎，獲得多領域覆蓋的中英雙語和跨語種數據集。實現一個模型就可以支持多業務場景，用户可以開箱即用。 &nbsp;<br> 我們在訓練的過程中，發現一個有意思的現象，數據標籤的構建對模型的效果影響非常大。相信大家一定聽過「難例挖掘」的概念，在機器學習中模型性能上不去時候，經常是因為一些例子比較難，模型訓練時候見的比較少，多挖掘一些難例給模型，就能夠提升模型的性能。但是在 embedding 訓練的時候，我們發現難例挖掘反而會降低模型的性能。我們猜測原因是 embedding 模型本身的能力有限，不應該給過難的任務。我們想要讓模型做多領域覆蓋，多語種、跨語種覆蓋（還要覆蓋代碼檢索和工具檢索），這已經給 Embedding 增加很多負擔了，應該想想怎麼給 Embedding「減負」。</p><p>因為 Embedding 模型是 dual-encoder，query 和 passage 在「離線」地語義向量提取時沒有信息交互，全靠模型將 query 和 passages「硬」編碼到語義空間中，再去語義檢索。而 rerank 的階段，cross-encoder 可以充分交互 query 和 passage 信息，潛力大的多。所以我們定了目標，embedding 儘可能提高召回，rerank 儘可能提高精度。</p><p>我們在 Embedding 模型訓練中，不使用難負樣例挖掘，只在 Reranker 中使用。以下是我們的幾點看法，供參考。</p><p>1. &nbsp;我們在訓練 Embedding 模型時發現，過難的負樣本對模型訓練有損害，訓練過程中會使模型「困惑」，影響模型最終性能[19]。Embedding 模型算法本身性能上限有限，很多難負樣本只有細微差異，「相似」程度很高。就像讓一個小學生強行去學習微積分，這種數據對 Embedding 訓練是「有毒」的。<br> 1. &nbsp;在大量的語料庫中，沒有人工校驗的自動化難負樣例挖掘，難免會「挖到正例」。語料庫很大，裏面經常會混有正例，利用已有 Embedding 模型去挖掘正例，經常會挖到正例，毒害模型訓練。應該有不少調參工程師有這種慘痛經歷。<br> 1. &nbsp;其實所謂的「正例」和「難負樣例」應該是根據你業務的定義來的。RAG 場景下，之前人們認為的難負樣例可能就成為了正例。比如要回答「小明喜歡吃蘋果嗎？」，RAG 場景下召回「小明喜歡吃蘋果」和「小明不喜歡吃蘋果」都是符合目標的，而學術定義的語義相似這兩句話又是難負樣例。</p><p>所以迴歸我們業務目標和好檢索器的「評判標準」，Embedding 模型應該能儘量召回相關片段，不要將精排 Reranker 要乾的事強壓在 Embedding 身上，「越俎代庖」終究會害了它。</p><p>檢索排序效果**評測方式**LlamaIndex（https://github.com/run-llama/llama_index）是一個著名的大模型應用的開源框架，在 RAG 社區中很受歡迎。最近，LlamaIndex 博客（https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83）對市面上常用的 embedding 和 reranker 模型進行 RAG 流程的評測，吸引廣泛關注。</p><p>為了公平起見，我們復刻 LlamaIndex 博客評測流程，將 bce-embedding-base_v1 和 bce-reranker-base_v1 與其他 Embedding 和 Reranker 模型進行對比分析。在此，我們先明確一些情況，LlamaIndex 博客（https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83）的評測只使用了 llama v2（https://arxiv.org/abs/2307.09288）這一篇英文論文來進行評測的，所以該評測是在純英文、限定語種（英文）、限定領域（人工智能）場景下進行的。<br><img alt="" height="832" src="https://oscimg.oschina.net/oscnet/up-5f9db64da828a15a1df04e374a64f33307f.png" width="1280" referrerpolicy="no-referrer"></p><p>如上表所示，</p><p>- &nbsp; 在沒有 Reranker 模塊的設置下，bce-embedding-base_v1 顯著優於其他常見的開源和閉源英文 embedding 模型。<br> - &nbsp; 在相同 reranker 配置下（豎排對比），bce-embedding-base_v1 也都是優於其他開源、閉源 embedding 模型。<br> - &nbsp; 在相同的 embedding 配置下（橫排對比），利用 reranker 模型可以顯著提升檢索效果，印證前面所述二階段檢索的優勢。bce-reranker-base_v1 比其他常見的開源、閉源 reranker 模型具備更好的精排能力。<br> - &nbsp; 綜上，bce-embedding-base_v1 和 bce-reranker-base_v1 的組合可以實現最好的效果。</p><p>多領域、多語種和跨語種 RAG 效果正如上所述的 LlamaIndex 博客（https://huggingface.co/datasets/maidalun1020/CrosslingualMultiDomainsDataset）評測有些侷限，為了兼容更真實更廣的用户使用場景，評測算法模型的，領域泛化性，雙語和跨語種能力，我們按照該博客的方法構建了一個多領域（計算機科學，物理學，生物學，經濟學，數學，量化金融等領域）的中英雙語種和中英跨語種評測數據，CrosslingualMultiDomainsDataset（https://huggingface.co/datasets/maidalun1020/CrosslingualMultiDomainsDataset）。</p><p>為了使我們這個數據集質量儘可能高，我們採用 OpenAI 的 gpt-4-1106-preview 用於數據生成。為了防止數據泄漏，評測用的英文數據我們選擇了 ArXiv 上 2023 年 12 月 30 日最新的各領域英文文章；中文數據選擇 Semantic Scholar 相應領域高質量的儘可能新的中文文章。<br><img alt="" height="661" src="https://oscimg.oschina.net/oscnet/up-10bf37226f5b2453ffbbe931fa45b495af1.jpg" width="1280" referrerpolicy="no-referrer"><br> 我們針對市面上最強的常用開源、閉源 embedding 和 reranker 模型，進行系統性評測分析，結果如上圖所示。</p><p>- &nbsp; 豎排對比，bce-embedding-base_v1 的表現和之前一樣，具備很好的效果，語種支持和領域覆蓋都很不錯。最新的 openai-embed-3 和 bge-m3 表現出頑強的性能，具備良好的多語種和跨語種能力，具備良好的領域泛化性。Cohere 和 e5 的多語種 embedding 模型同樣表現出不錯的效果。而其他單語種 embedding 模型表現卻不盡如人意（JinaAI-v2-Base-zh 和 bge-large-zh-v1.5 稍好一些）。</p><p>- &nbsp; 橫排對比，reranker 模塊可以顯著改善檢索效果。其中 CohereRerank 和 bge-reranker-large 效果相當，bce-reranker-base_v1 具備比前二者更好的精排能力。</p><p>- &nbsp; 綜上，bce-embedding-base_v1 和 bce-reranker-base_v1 的組合可以實現最好的檢索效果（93.46/77.02），比其他開源閉源最好組合（bge-m3-large+bge-reranker-large， 89.94/70.17），hit rate 提升 3.53%，mrr 提升 6.85%。</p><p><br><strong>Rerank 的必要性</strong></p><p>為啥需要 rerank，上面數字可能還不直觀。我們在開源的 github 上放了一張圖，意思是 QAnything 在知識庫的數據越多，準確率越高。而一般搭建的 RAG，如果沒有 rerank 這一環節，在數據輸入多了以後，效果反而下降了。<br><img alt="" height="776" src="https://oscimg.oschina.net/oscnet/up-72860571cf331d8baaf1fe6c6d6a32aff62.jpg" width="1235" referrerpolicy="no-referrer"><br> 我們在做升學問答的時候，遇到一個有趣的現象：我們分批往 RAG 知識庫中灌入數據，每加一批數據都做一次評測，觀察隨着數據量變大，問答效果的變化情況：</p><p>- &nbsp; baseline：第一批數據加入後問答正確率有 42.6%，此時有一些問題沒回答上來是因為確實缺少相關資料。我們繼續加數據…<br> - &nbsp; 迎來上漲：第二批加了更多數據，覆蓋知識範圍更廣。準確率提升到了 60.2%，提升非常明顯，看來加數據確實還是挺有用的。<br> - &nbsp; 壞消息：當加入第三批數據的時候，我們最擔心的事情還是發生了。正確率急劇下降，跌了將近 8 個百分點。</p><p><img alt="" height="591" src="https://oscimg.oschina.net/oscnet/up-8319017eaecc4989a5540acd83a2c9bbc3c.png" width="1280" referrerpolicy="no-referrer"></p><p>不是所的 RAG 系統都能保證：數據越多，效果越好。隨着數據的增多，數據之間可能會有相互幹擾，導致檢索退化的問題，影響問答的質量。</p><p>這個現象在最近的一篇論文：The Power of Noise: Redefining Retrieval for RAG Systems （arXiv:2401.14887v2）也有一些解釋，對於 RAG 系統，如果餵給大模型的輸入是相近容易混淆的話，對正確性的影響是最大的。</p><p>&nbsp;以我們遇到的一個 case 為例，大連醫科大學怎麼樣？這個問題在 v2 版本（加入第三批數據前）是能回答對的，v3 版本（加入第三批數據後）回答錯了。看了一下送到 LLM 的文本片段，居然全部都是大連理工大學相關的信息。<br><img alt="" height="750" src="https://oscimg.oschina.net/oscnet/up-bf69d543bfb43367e7dda1a555252c893fe.png" width="952" referrerpolicy="no-referrer"></p><p>主要原因是第三批加入的某些文檔中恰好有 "大連理工大學 xxx 怎麼樣？" 的句子，和 query "大連醫科大學怎麼樣？" 表面上看起來確實非常像，Embedding 給它打了比較高的分。</p><p>而類似大連醫科大學師資介紹這樣的片段相關性就稍微低了些。LLM 輸入 token 有限制，前面兩個最相關但是實際並不能回答 query 問題的片段就已經佔滿了 token 的窗口，只能把他倆送進 LLM 裏。結果可想而知，啥都不知道。</p><p>文本片段與 query 的相似性和文本片段是否包含 query 的答案（相關性）是兩回事。RAG 中一個非常重要的矛盾點在於檢索召回的片段比較多，但是 LLM 輸入 token 是有限制，所以必須把能回答 query 問題的片段（和問題最相關）給 LLM。 Embedding 可以給出一個得分，但是這個得分描述的更多的是相似性。Embedding 本質上是一個雙編碼器，兩個文本在模型內部沒有任何信息交互。只在最後計算兩個向量的餘弦相似度時才進行唯一一次交互。所以 Embedding 檢索只能把最相似的文本片段給你，沒有能力來判斷候選文本和 query 之間的相關性。但是相似又不等於相關。&nbsp;</p><p>如下圖所示，從某種程度上，Embedding 其實就是在算兩個文本塊中相似字符的個數佔比，它分不清 query 中的重點是大連醫科大學，在它看來每個字符的重要性都是一樣的。感興趣的話可以計算一下下圖中紅字部分的佔比，和最後餘弦相似度的得分基本是吻合的。<br><img alt="" height="662" src="https://oscimg.oschina.net/oscnet/up-e03af7dedb9142ae03fae273c1f835b55e1.png" width="1240" referrerpolicy="no-referrer"><br> Rerank 本質是一個 Cross-Encoder 的模型。Cross-Encoder 能讓兩個文本片段一開始就在 BERT 模型各層中通過 self-attention 進行交互。它能夠用 self-attention 判斷出來這 query 中的重點在於大連醫科大學，而不是怎麼樣？所以，如下圖所示，大連醫科大學怎麼樣？這個 query 和大連醫科大學創建於 1947 年…更相關。<br><img alt="" height="517" src="https://oscimg.oschina.net/oscnet/up-d1e3389e4d05a523535c92a8547bd1b39da.png" width="1240" referrerpolicy="no-referrer"></p><p>加上兩階段檢索後，重新跑一下實驗：<br><img alt="" height="488" src="https://oscimg.oschina.net/oscnet/up-5ed99ad8f15fe754f53ea8b2d3672258b98.png" width="1280" referrerpolicy="no-referrer"><br> 在數據不變的情況，兩階段檢索問答準確率從 52.8% 提升到 65.9%，這個結果再次證明瞭一階段檢索中存在數據互相干擾的情況。兩階段檢索可以最大化的挖掘出數據的潛力，我們繼續加數據，效果能夠穩定提升。如下圖所示，兩階段檢索最大的意義不是在某一個實驗上面提升了 10 個點。它最大的意義在於讓「數據越多，效果越好」變成了現實。 在實際使用中，因為 rerank 比 embedding 慢得多，所以一般用兩階段檢索。速度慢不是 cross-encoder 的模型比 bi-encoder 的模型速度慢。關鍵在於，bi-encoder 可以離線計算海量文本塊的向量化表示，把它們暫存在向量數據庫中，在問答檢索的時候只需要計算一個 query 的向量化表示就可以了。拿着 query 的向量表示去庫裏找最相似的文本即可。但是 cross-encoder 需要實時計算兩個文本塊的相關度，如果候選文本有幾萬條，每一條都需要和 query 一起送進 BERT 模型中算一遍，需要實時算幾萬次。這個成本是非常巨大的。所以，我們可以把檢索過程分為兩個階段：召回（粗排）和重排:</p><p>- &nbsp; 第一個階段的目標是儘可能多的召回相似的文本片段，這個階段的文本得分排序不是特別靠譜，所以候選的 topK 可以設置大一些，比如 topK=100；<br> - &nbsp; 第二個階段的目標是對 100 個粗排的候選文本片段進行重新排序，用 cross-encoder 計算 100 個候選文本和 query 的相關度得分；<br> 兩階段檢索結合可以兼顧效果和效率。</p><p><br><strong>LLM 模型微調</strong></p><p>我們的開源項目 QAnything 引入了一款 7B 參數規模的大型語言模型 Qwen-7B-QAnything，該模型是在 Qwen-7B 基礎上，通過使用我們團隊精心構建的中英文高質量指令數據進行微調得到的。隨着開源大型語言模型（LLM）基座模型的能力不斷增強，我們通過在這些優秀的基座模型上進行後續訓練，包括繼續預訓練、指令微調（SFT）和偏好對齊等工作，以更有效地滿足 RAG 應用對大模型的特定需求，從而實現高性價比的模型優化。</p><p>為什麼要微調？</p><p>RAG 技術結合了知識檢索與生成模型，通過從外部知識源檢索信息，並將這些信息與用户問題整合成完整的 Prompt 輸入到大模型中，以便根據這些參考信息回答問題。然而，當面對含有專業術語或通俗縮寫的開放性問題時，**直接使用開源 Chat 模型可能會導致模型回答不準確。** 此外，為了最大化利用大模型的上下文窗口，RAG 應用傾向於保留儘可能多的檢索信息，這可能會使得模型的注意力分散，降低其遵循指令的能力，進而引發回答中的重複內容、關鍵信息丟失等問題。為了提高大模型在參考信息不足時的誠實度，加入與用户問題關聯度低的負樣本進行微調訓練變得必要。</p><p>在選擇基座模型時，我們尋找能夠支持中英文、至少具備 4K 上下文窗口的模型，且能在單塊 GPU 上部署，優先考慮 7B 以下參數規模的模型以便於未來在消費級硬件上部署。Qwen-7B，一個阿里雲研發的 70 億參數的通用大模型，以其在多個基準測試中的卓越表現成為我們的選擇。該模型通過在超過 2.4 萬億 tokens 的數據上預訓練，包含了豐富的中英文、多語言、編程、數學等領域數據，確保了廣泛的覆蓋面。考慮到 7B 參數規模的限制，我們在指令微調時採用了結構化指令模板，以增強模型在實際應用中的指令遵循能力。<br><img alt="" height="522" src="https://oscimg.oschina.net/oscnet/up-2d3d3662175b7c878cee7ead4d0fbfabf5d.png" width="1280" referrerpolicy="no-referrer"></p><p>如何微調？&nbsp;</p><p><strong>1. 指令微調數據構造</strong></p><p>我們為 Qwen-7B-QAnything 模型構造了豐富的指令微調數據集，涵蓋了多種類型的數據，包括基於參考信息的結構化問答數據（單文檔/多文檔的事實問答、多文檔的歸納總結/推理類問答、信息抽取）、多輪對話查詢重寫、段落摘要、開放域問答、中英文翻譯以及跨學科問答等。<br> &nbsp;<br><strong>2. 指令微調模型訓練</strong></p><p>儘管與大模型的預訓練相比，指令微調成本較低，但在微調數據不完整或比例不平衡的初期探索階段，採用全參數微調的代價依然較高。為了儘可能降低實驗成本並快速驗證微調效果，我們首先採用 LoRA 方法進行微調探索，待實驗條件穩定後，再轉向全參數微調。我們的 LoRA 微調配置如下：使用 8 張 A40 顯卡的單機環境，初始學習率設為 3e-5，每張卡的批量大小為 2，採用 16 步的梯度累積，同時利用 bfloat16 精度訓練以避免溢出並增強穩定性。此外，我們採用 QLoRA + DeepSpeed Zero2 + FlashAttention 配置以節約訓練所需的顯存。QLoRA 通過 4 比特量化技術壓縮預訓練語言模型，使用 NormalFloat4 數據類型存儲基模型權重，凍結基模型參數，並以低秩適配器（LoRA 參數）形式添加少量可訓練參數。在微調階段，QLoRA 將權重從 NormalFloat4 數據類型反量化為 bfloat16 進行前向和後向傳播，僅更新 bfloat16 格式的 LoRA 參數權重梯度。與 LoRA 原論文不同，針對指令微調數據規模達到百萬級別的情況，我們在所有線性層添加低秩適配器，並發現增加 lora_rank 和 lora_alpha 參數能顯著提升微調效果。因此，我們為 Qwen-7B 模型微調採取了特定的 LoRA 參數配置，以實現最佳效果。<br><img alt="" height="208" src="https://oscimg.oschina.net/oscnet/up-c858a0c049064dc4013ed8f4baa1752ba72.png" width="1280" referrerpolicy="no-referrer"><br> 3. 指令微調模型問答效果評估</p><p>我們參考了這篇文章：Benchmarking Large Language Models in Retrieval-Augmented Generation，使用開源 Benchmark 的事實型文檔問答測試集，對微調過後的 LLM 做質量評估。中、英文測試集分別包含 300 條，Context Noise Ratio （0～0.8）表示 LLM 輸入 Context 中不相關噪聲片段的比例。回答準確率指標結果説明：Qwen-7B-Chat (QwenLM 2023) 表示論文中的結果，[Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat) 表示使用開源 Chat 模型和結構化指令模版的結果，Qwen-7B-QAnything 表示 QAnything 開源項目微調模型的結果。模型評估時使用了 top_p 採樣。結果表明 Qwen-7B-QAnything 對檢索外部知識源包含不相關信息的魯棒性更好。<br><img alt="" height="354" src="https://oscimg.oschina.net/oscnet/up-ed9e217a1a740f3ce947701f20f6d010c7e.png" width="1080" referrerpolicy="no-referrer"></p><p><img alt="" height="386" src="https://oscimg.oschina.net/oscnet/up-843d77dce42bf3ef921d246f501de5dd78e.png" width="1280" referrerpolicy="no-referrer"><br> 公開數據集的 benchmark 的評測結果</p><p>此外，團隊內部針對業務場景構造 700 條問答對作為評測集，覆蓋多種文檔類型和問題，其中相關參考信息由 BCE Embedding 和 Rerank 模型檢索重排序得到，參考答案由 GPT4 生成，結合人工修正得到。結合 Ragas 評測框架實現對 LLM 的自動化評測。評測指標採用 [answer_correctness],通過計算 LLM 回答內容 answer 和參考答案的 factual correctness 和 semantic similarity 加權和得到，其中 factual correctness（權重係數 0.75）利用 GPT4 根據 answer 和參考答案生成 TP/FN/FP 表述計算得分，semantic similarity（權重係數 0.25）利用 BCE Embedding 計算 answer 和參考答案的語義相似度。以下是評測結果及部分示例。<br><img alt="" height="260" src="https://oscimg.oschina.net/oscnet/up-5361f664da82c8a631079da21799447d774.png" width="820" referrerpolicy="no-referrer"></p><p><strong>本地部署</strong></p><p>QAnything 開源項目為本地部署的大型語言模型（LLM）提供了三種推理框架後端選項：FasterTransformer、vLLM 和 Huggingface Transformers。這些選項滿足了不同用户對於部署 LLM 的需求，實現了在高性能與通用性之間的平衡。</p><p>FasterTransformer (&lt;https://github.com/NVIDIA/FasterTransformer&gt;) 是由 NVIDIA 開源的一個高性能 LLM 推理框架，專為 NVIDIA GPU 優化。它的優點在於支持大型模型的 INT8-Weight-Only 推理，能在保持模型精度的同時減少推理延時和 GPU 顯存使用，提高了在相同 GPU 配置下的多併發吞吐性能。FasterTransformer 的模型權重轉換與具體 GPU 型號無關，提供了一定的部署靈活性，但需要 GPU 具備一定的計算能力（FP16 推理支持計算能力 7.0 及以上，INT8-Weight-Only 支持 7.5 及以上）。此外，FasterTransformer 作為 Triton Inference Server 的後端 (&lt;https://github.com/triton-inference-server/fastertransformer_backend&gt;) 實施 LLM 推理，支持 Linux/Windows 11 WSL2 部署。NVIDIA 還基於 FasterTransformer 和 TensorRT 開發了新的推理框架 TensorRT-LLM (&lt;https://github.com/NVIDIA/TensorRT-LLM&gt;)，進一步提高了推理性能，但這也意味着與 NVIDIA GPU 的綁定更緊密，犧牲了一定的靈活性和通用性。</p><p>vLLM (&lt;https://github.com/vllm-project/vllm&gt;) 是由 UC Berkeley LMSYS 團隊開發的另一款高性能 LLM 推理框架，其利用 PagedAttention 技術優化 KV Cache 管理，並結合並行採樣和連續批處理請求調度管理，支持 NVIDIA 和 AMD GPU，提高了系統吞吐性能。通過 Huggingface Transformers 訓練的模型可以輕鬆部署為 Python 服務，展現出良好的系統靈活性。vLLM 通過 AWQ 和 GPTQ 等算法支持 INT4-Weight-Only 推理，節省顯存同時減少推理延時，但可能會輕微影響模型精度和生成質量。QAnything 利用 FastChat (&lt;https://github.com/lm-sys/FastChat&gt;) 提供的接口使用 vLLM 後端，提供了兼容 OpenAI API 的調用接口，默認採用 bfloat16 推理，對 GPU 和算力有一定要求。</p><p>Huggingface Transformers (&lt;https://github.com/huggingface/transformers&gt;) 是由 Huggingface 團隊開發的一個通用性強、靈活性高的 Transformer 模型庫，與 PyTorch 等深度學習框架配合，支持模型訓練和 Python 服務部署。雖然在多數情況下，其推理性能可能不及 FasterTransformer 和 vLLM，但它兼容不同算力等級的 GPU。QAnything 通過複用 FastChat(&lt;https://github.com/lm-sys/FastChat&gt;) 提供的接口使用 Huggingface Transformers 後端，實現了兼容 OpenAI API 的調用，採用 load_in_8bit 配置加載模型以節省顯存，同時使用 bfloat16 進行推理。</p><p><strong>關於開源</strong></p><p>自從「QAnything」項目開放源代碼以來，受到了開發社區的熱烈歡迎和廣泛認可。截至 2024 年 2 月 29 日，項目在 GitHub 上已經積累近 5000 個星標，這反映出了其流行度和用户對其價值的高度評價。</p><p>歡迎點擊下面的鏈接下載試用：</p><p>QAnything github: &nbsp;&lt;https://github.com/netease-youdao/QAnything&gt;<br> QAnything gitee: &nbsp;&lt;https://gitee.com/netease-youdao/QAnything&gt;<br> 歡迎大家在 GitHub 上為[「QAnything」](https://github.com/netease-youdao/QAnything) 加星助力，方便收到新版本更新的通知！<br> &nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 06:02:56 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/youdaotech/blog/11045422</guid>
            <link>https://my.oschina.net/youdaotech/blog/11045422</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | 輕鬆復現 Sora 模型；事關 CUDA 兼容，英偉達禁止了；百度還差一個「遙遙領先」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.5</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/281597/bitwarden-mobile-native" target="_blank">密碼管理工具 Bitwarden 宣佈淘汰 Xamarin 框架，轉向原生開發</a></h3><p>密碼管理工具 Bitwarden 開發者在 Reddit 發佈消息，稱當下自家應用的 iOS 和 Android 客户端採用微軟 Xamarin 框架，不僅早已過時且消耗資源較多。開發者表示他們正在使用 Kotlin 開發 Android 客户端、使用 Swift 來開發 iOS 客户端，正式上線還需要再等待幾個月的時間。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8fbf5f9731de815a67f0b226b6125d4495b.png" referrerpolicy="no-referrer"></p><h3><a href="https://www.oschina.net/news/281566" target="_blank">Linux 桌面操作系統的市場份額超過 4%</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">截至 2024 年 2 月，<strong>Linux 在全球桌面操作系統市場份額的佔比已超過 4%</strong>。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-32e040790feadfaa2ba3b7c7366a87eec23.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-1123ac30b2d25f778d2d273a031471c592c.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2082348875%2FO3BAkjZCu" target="_blank">伯克利_尤洋</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-dd51dcd7c7b84633a9e7f39d113d7df4d01.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fuser.guancha.cn%2Fmain%2Fcontent%3Fid%3D1191772" target="_blank">科技新知</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-3c72fbaae4c6f2b4a0a86043e9b60a28a3f.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.36kr.com%2Fp%2F2675982080800514" target="_blank">半導體行業觀察</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-6097a7d202474dee1620add69e8449b7a6b.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FPrefectHQ%2Fprefect" target="_blank">https://github.com/PrefectHQ/prefect</a></u></em></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p>&nbsp;<img src="https://oscimg.oschina.net/oscnet/up-a696a9aacc9990b2b0ebdf6bb5ccd9d77d1.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c809c148077fe0b9ca74b2150495cad2c73.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精選</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-98fdfe8bf3d3dee3bbfe35b4feba428f637.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">開源日報第 22 期：輕鬆復現 Sora 模型；事關 CUDA 兼容，英偉達禁止了；百度還差一個「遙遙領先」</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">開源日報第 021 期：閉源模型就是比開源安全；起訴 OpenAI 不能更贊同；中國算力產業出現五個真問題</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">開源日報第 020 期：為什麼王炸都來自 OpenAI；Pingora 最好不要用 YAML 當配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">開源日報第 019 期：我讓 AI 用 C 語言寫一個算法；微軟三進制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">開源日報第 018 期：蘋果十年造車夢碎；這個開源項目有點...「大膽」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">開源日報第 017 期：MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 04:04:35 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281719</guid>
            <link>https://www.oschina.net/news/281719</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 迴應被起訴：馬斯克曾意圖獲得公司「絕對控制權」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">針對被聯合創始人和前贊助人埃隆·馬斯克<a href="https://www.oschina.net/news/281047/elon-musk-sues-openai-over-ai-threat">起訴</a>一事，OpenAI 在其網站上發佈博文作出了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">迴應</a>，稱馬斯克曾一度希望通過與特斯拉合併來「絕對控制」該公司，包括「多數股權、初始董事會控制權以及擔任首席執行官」。</span></p><blockquote><p><span style="color:#000000">「在我們討論營利性結構以推進使命時，Elon 希望我們與特斯拉合併，否則他就想要完全控制權。埃隆離開了 OpenAI，他説需要有一個能與 Google/DeepMind 相抗衡的競爭對手，而且他打算自己來做這件事。他説，他會支持我們找到自己的道路。」</span></p></blockquote><p><span style="color:#000000">OpenAI 表示，他們無法與馬斯克就營利性條款達成一致，因為他們認為任何個人對 OpenAI 擁有絕對控制權都是違背使命的。在相關事項討論期間，馬斯克還扣留了資金，是 Reid Hoffman 彌補了工資和運營方面的缺口。</span></p><p><span style="color:#000000">而馬斯克在試圖將該公司納入特斯拉但未能成功後，對公司大加撻伐。「我們很遺憾，和一位我們一直深感欽佩的人走到這一步。他曾激勵我們志存高遠，然後告訴我們會失敗，進而創立了一個競爭對手，終至於在我們開始朝着 OpenAI 的使命取得有意義的進展時把我們告上公堂。」</span></p><p><span style="color:#000000">另一方面，OpenAI 還為其不開源的舉措進行了辯解。「我們正在通過開源貢獻等方式，使我們的技術能夠廣泛應用，從而增強人們的能力，改善他們的日常生活。我們提供對當今最強大人工智能的廣泛訪問，包括每天有數億人使用的免費版本。」</span></p><p><span style="color:#000000">「Elon 明白這一使命並不意味着開源 AGI」。該公司在博文中指出，OpenAI 首席科學家曾在與馬斯克的溝通中提到，"隨着我們越來越接近 building AI，開始降低開放程度是有意義的。openAI 中的 Open 是指 AI 建成後，每個人都應從 AI 的成果中受益，但不分享科學成果也完全沒問題......"。而對於這番言論，馬斯克彼時也表明了贊同的態度。</span></p><p><img height="342" src="https://oscimg.oschina.net/oscnet/up-0683231baadda6cd1bbc78a08aa3f0b3340.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">查看官方博客</a>。</span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/281047/elon-musk-sues-openai-over-ai-threat" target="_blank">馬斯克起訴 OpenAI 及其 CEO 奧特曼，要求公司恢復開源狀態</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 03:41:35 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281710/openai-response-elon-musk-lawsuit</guid>
            <link>https://www.oschina.net/news/281710/openai-response-elon-musk-lawsuit</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟將終止對 WSA 的支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微軟<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fwindows%2Fandroid%2Fwsa%2F" target="_blank">宣佈</a>將逐步停止對適用於 Android 的 Windows 子系統 (Windows Subsystem for Android，WSA) 的支持，截止時間為 2025 年 3 月 5 日。</p><p><img height="335" src="https://oscimg.oschina.net/oscnet/up-39b6577bcae20f6f2829c6ca55936d9cae2.png" width="500" referrerpolicy="no-referrer"></p><p>WSA 類似於 Windows Subsystem for Linux（WSL），但其目的是在 Windows 11 上運行 Amazon Appstore 中的 Android 應用程序。公告寫道：</p><blockquote><p>微軟將終止對 Windows Subsystem for Android (WSA) 的支持。因此，從 2025 年 3 月 5 日開始，Windows 上的 Amazon Appstore 以及依賴於 WSA 的所有應用程序和遊戲將不再受到支持。在此之前，客户仍可獲得技術支持。</p><p>在 2024 年 3 月 5 日之前安裝了 Amazon Appstore 或 Android 應用程序的客户，在 2025 年 3 月 5 日停用日期之前仍可繼續訪問這些應用程序。如有其他問題，請通過<span style="color:#161616">&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.microsoft.com%2F" target="_blank">support.microsoft.com</a>&nbsp;聯繫我們的支持團隊。</p></blockquote><p>這一更改僅針對 Windows Subsystem for Android，對 Windows Subsystem for Linux 並無明顯影響。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 02:34:37 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281692/microsoft-dropping-wsa</guid>
            <link>https://www.oschina.net/news/281692/microsoft-dropping-wsa</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[倒了一個 Yuzu，還有千千萬萬個「轉世」開源模擬器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>開源 Switch 模擬器 Yuzu 昨天突然的「滑跪」着實讓人大跌眼鏡——<u><a href="https://www.oschina.net/news/281570/switch-emulator-yuzu-shut-down-pay-24-million-to-settle-lawsuit">宣佈項目關閉</a></u>、刪除託管在 GitHub 的代碼倉庫，並向任天堂支付 240 萬美元和解訴訟。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a754bb26a7ca77ccb496a39c5eecc8de82.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-f9ab7fe69c73d0aa85fe5a02118cb044ead.png" referrerpolicy="no-referrer"></p><p>然而這並不意味「開源模擬器」就此銷聲匿跡——號稱是 Yuzu 轉世的 "Suyu" 直接在 GitHub 挑釁任天堂：</p><blockquote><p>致任天堂法律團隊：</p><p>你無法擊敗我們，即使你們把我打倒，也會有更多的人來。即使你把它們都下架，還會有更多人前僕後繼。你輸了這場戰役。</p><p>這個項目不支持盜版，你需要自己提供遊戲和 key，我們不從這個項目中賺錢（主要是為了讓任天堂不起訴我們，哈哈）。</p><p>這個分支版本是確保任天堂無法幹掉 Yuzu，模擬器長存！</p><p>此 repo 基於 Yuzu EA 4176 創建，歡迎貢獻。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a4166af65954610888a3fc09d77a754eaf9.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCrimson-Hawk%2Fsuyu" target="_blank">https://github.com/Crimson-Hawk/suyu</a></u></em></p></blockquote><p>可以看到，Suyu 是基於 Yuzu 模擬器最新版本的開源項目，並聲明自己不以任何方式支持盜版，目前正在尋找開發者。</p><p><img alt="" height="333" src="https://oscimg.oschina.net/oscnet/up-3d744fffcfd16f042f26222c57fcc388a01.png" width="300" referrerpolicy="no-referrer"></p><p>目前該項目已遷移至 GitLab：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.com%2Fsuyu-emu%2Fsuyu" target="_blank">https://gitlab.com/suyu-emu/suyu</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 02:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281690/yuzu-fork-suyu</guid>
            <link>https://www.oschina.net/news/281690/yuzu-fork-suyu</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 新增朗讀功能，支持 37 種語言、5 種聲音]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">OpenAI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FOpenAI%2Fstatus%2F1764712432939995549" target="_blank">宣佈</a>為 ChatGPT 推出了名為「朗讀」（ ReadAloud）的新功能。</span><span style="background-color:#ffffff; color:#222222">不僅支持 37 種語言，還可以自動檢測文本語言並進行朗讀。</span></p><p><span style="color:#000000">與"朗讀"同時推出的還有一個新的設置菜單選項，讓你可以對播報的語音進行選擇。該功能可以讓 ChatGPT 用五種不同的聲音朗讀其回覆，旨在為用户提供更加便捷的交互體驗。目前，「朗讀」功能已上線 ChatGPT 的網頁端、iOS 和安卓應用。該功能同時適用於 GPT-4 和 GPT-3.5 版本的 ChatGPT。</span></p><p><img height="280" src="https://oscimg.oschina.net/oscnet/up-4e53e10a9fbe9117ef7dac4953b4ab2da25.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">該功能可通過消息下方的一個新的揚聲器圖標進行訪問，它採用了與移動應用程序上的 ChatGPT Voice 背後相同的技術。即使離開 ChatGPT 頁面，語音播報也會繼續，因此用户可以在處理其他事情時保持收聽狀態。</span></p><p><span style="color:#000000">OpenAI 表示，"朗讀"功能適用於那些"需要免提的時刻，或者大聲朗讀信息有助於更好地理解信息的情況"。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 02:05:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281682/chatgpt-readaloud</guid>
            <link>https://www.oschina.net/news/281682/chatgpt-readaloud</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘇州科達加入 openKylin，為社區提供領先的視訊系統解決方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>近日，蘇州科達科技股份有限公司（以下簡稱「蘇州科達」）簽署了 openKylin 社區 CLA(Contributor License Agreement 貢獻者許可協議)，正式加入 openKylin 開源社區。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-60b7982651cc2dbe678ab7f58ddaca6ff8f.png" width="829" referrerpolicy="no-referrer"></p><p><span><span><span style="color:var(--weui-LINK)">蘇州科達</span><span>成立於 1995 年，是領先的視訊與安防產品及解決方案提供商，致力於以視頻會議、視頻監控以及豐富的視頻應用解決方案幫助各類政府及企業客户解決可視化溝通與管理難題。</span></span></span></p><p><span>在視頻會議領域，<span>蘇州科達</span>可提供全場景會議解決方案，覆蓋高端會議廳、大中小型會議室、桌面、移動等不同場景，滿足視頻會議、指揮調度、會商協作、移動辦公等多樣化需求。在視頻監控領域，<span><span>蘇州</span></span>科達擁有前端、平台、存儲等近千款產品，以及針對不同領域的視頻信息解決方案。同時基於視頻會議與視頻監控兩大領域的技術積累，蘇州科達公司產品及解決方案已覆蓋 200 多個行業，並在國內外獲得了廣泛應用。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-22a96ab807cbe2a9524d906354710cea835.png" width="940" referrerpolicy="no-referrer"></p><p><span><span>加入 openKylin 社區後，蘇州科達將利用自身在視頻會議、視頻監控兩大領域的技術積累以及在專業解決方案上的經驗沉澱，結合 openKylin 社區版本，一方面為行業客户提供安全可信的系統解決方案；另一方面，解決會議和監控專用硬件終端與</span><span style="color:var(--weui-LINK)">主流 CPU</span><span>、操作系統進行成功集成後的持續迭代更新問題，推動社區在行業解決方案、軟件生態建設方面的持續進步。</span></span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 01:25:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281670</guid>
            <link>https://www.oschina.net/news/281670</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[App Store 與 Spotify 撕逼，蘋果表示約 86% 開發者從未需要向其支付費用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歐盟委員會最近的一項決定，指責 App Store 對數字音樂市場的競爭構成了阻礙，這一決定似乎為 Spotify 的立場提供了支持。然而，Apple 並不認同這一觀點，他們認為這一市場是繁榮的，並且競爭是充分的。</p><p>Spotify，這個總部位於瑞典的音樂流媒體巨頭，是這一決定的主要推動者。儘管 Spotify 在歐洲市場上佔據了主導地位，擁有超過 50% 的市場份額，但它從未為在 App Store 上的成功支付過任何費用。Spotify 的成功，部分歸功於 App Store 提供的平台和技術支持，這些幫助它構建和更新應用，以及與全球 Apple 用户分享其服務。</p><p>Apple 對此表示自豪，他們認為<strong> App Store 為開發者提供了一個公平的競爭環境，並且為用户創造了一個安全可靠的市場。App Store 的規則旨在保護用户安全，並且讓開發者能夠觸達全球超過 10 億台設備。大多數開發者（約 86%）實際上從未需要向 Apple 支付費用。</strong></p><p>Spotify 的成功故事是 App Store 成功的縮影。然而，Spotify 並不滿足於現狀，他們試圖改變 App Store 的規則，以獲取更多的利益。<strong>Spotify 希望在不使用 App Store 的內購系統的情況下，直接在應用內嵌入訂閲價格。這與 Apple 的政策相沖突，因為 Apple 不會對通過 App Store 進行的交易收取佣金。</strong></p><p>這場爭議的核心是 Spotify 與歐盟委員會的合作。自 2015 年以來，Spotify 一直在推動對 Apple 的調查，聲稱 Apple 在限制競爭對手的發展。儘管 Spotify 自身在 App Store 的幫助下取得了顯著增長，但歐盟委員會在數字市場法案（DMA）即將生效之際，公佈了這一決定。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com.cn%2Fnewsroom%2F2024%2F03%2Fthe-app-store-spotify-and-europes-thriving-digital-music-market%2F" target="_blank">Apple 對此表示不滿，並計劃提起上訴</a>。</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 12:01:04 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281630/the-app-store-spotify-and-europes-thriving-digital-music-market</guid>
            <link>https://www.oschina.net/news/281630/the-app-store-spotify-and-europes-thriving-digital-music-market</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🎁有獎問答|如何高效處理電子表格辦公文檔]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4700705_2331750">高手問答第 313 期 —— 如何高效處理電子表格辦公文檔</a><div class="ui red label horizontal" data-tooltip="置頂">頂</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4700705" class="__user"><span>小白兔愛吃大灰狼</span></a> 發佈於，今天 14:24
                    </div><div class="item">閲讀 29</div><div class="item collect-btn " data-id="2331750" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331750" data-obj-type="2">0</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4700705_2331750#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">0</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手問答</a></div><div class="content" id="articleContent"><p>以 Excel 為代表的電子表格應用已廣泛應用於各行各業，隨着企業數智化進程的加速，開發者通過編程的方式對辦公文檔的自動化處理場景越來越多。</p><p><strong><span><span>OSCHINA 本期高手問答（3 月 6 日 - 3 月 12 日）我們請來了嘉賓</span></span></strong><a href="https://my.oschina.net/xuri" rel="nofollow"><strong>續日</strong></a><strong><span><span>和大家一起聊聊，高效處理電子表格辦公文檔，那些事。</span></span></strong></p><p><strong>可討論的問題包括但不限於：</strong></p><ul><li>帶有高階複雜功能工作表的自動化處理方法</li><li>遇到包含大規模數據工作簿時如何優化讀寫性能</li><li>Excelize 適合的應用場景</li><li>如何藉助 WebAssembly 在瀏覽器中使用 Excelize</li><li>............</li></ul><p>其他相關的問題，也歡迎提問！</p><h2>嘉賓介紹：</h2><p><img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-0d2b62bc6b36ebd12c11a32d3f77ec4d739.jpg" width="300" referrerpolicy="no-referrer"></p><p>續日（GitHub: @xuri），軟件工程師，阿里巴巴技術專家，曾就職於百度、360 等公司從事網絡服務框架與基礎軟件研發，在辦公文檔軟件研發領域有着豐富的經驗。他是知名開源電子表格基礎庫 Excelize 的作者。</p><blockquote><p>Excelize 是一款用於操作 Office Excel 文檔的開源基礎庫，遵循 BSD 3-clause 開源協議，基於 ISO/IEC 29500 國際標準。可以使用它來讀取、寫入由 Excel 、WPS 、OpenOffice 等辦公軟件創建的電子表格文檔。支持 XLAM / XLSM / XLSX / XLTM / XLTX 等多種文檔格式，高度兼容帶有樣式、圖片 (表)、切片器等複雜組件的文檔。可應用於各類報表平台、雲計算、邊緣計算等系統。正在被廣泛應用於大型互聯網公司、中小企業客户和初創公司。</p><p>項目地址：<br> https://github.com/xuri/excelize<br> https://gitee.com/xurime/excelize<br> https://www.oschina.net/p/excelize</p></blockquote><p><span style="background-color:#ffffff; color:#333333">🎁</span><span style="background-color:#ffffff; color:#333333"><span>&nbsp;</span>為了鼓勵踴躍提問，問答結束後我們將從提問者中抽取 3 名幸運會員，贈予開源魔方一個。</span></p><p><span style="background-color:#ffffff; color:#333333"><img alt="" height="267" src="https://oscimg.oschina.net/oscnet/up-1afbf8f3e292f5abf1de816cca143b906b8.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手問答一貫的風格，不歡迎任何與主題無關的討論和噴子。</span></p><p>下面歡迎大家就 「高效處理電子表格辦公文檔」<span><span>&nbsp;</span>相關</span>問題向<strong><a href="https://my.oschina.net/xuri" rel="nofollow">續日</a></strong>老師提問，直接回帖提問既可。</p></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331750" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331750" data-obj-type="2">0</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331750" data-obj-type="2" data-url="https://www.oschina.net/question/4700705_2331750"><i class="flag red icon"></i>舉報</a></div></div>
            ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 11:08:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4700705_2331750</guid>
            <link>https://www.oschina.net/question/4700705_2331750</link>
        </item>
        <item>
            <title>
                <![CDATA[科大訊飛董事長劉慶峯：建議制定國家《通用人工智能發展規劃》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 全國「兩會」期間，全國人大代表、科大訊飛董事長劉慶峯建議，在 2017 年《新一代人工智能發展規劃》的基礎上，瞄準我國通用人工智能發展中需要重點補上的短板進行設計，圍繞自主可控算力生態構建、高質量數據開放共享、科學的評測標準制定、源頭技術前瞻研發、人才培養、法律制定和倫理人文等維度，系統性制定國家《通用人工智能發展規劃》，由國家高位推動規劃的制定和落地，不斷縮小中美通用人工智能產業在通用底座平台方面的差距，並在行業應用和價值創造上打造我國的比較優勢。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fa6b56a2cceac0c35759f54de9f877e3b82.png" referrerpolicy="no-referrer"></p><p>劉慶峯表示，國家在制定《規劃》的同時，應該加快推動通用人工智能的相關工作，他提出 9 點建議：</p><p><strong>第一，建議發揮舉國體制優勢，加大並保持對通用大模型底座「主戰場」的持續投入。</strong></p><p>建議以專項的形式從算力、數據、算法上在未來 5 年內持續支持我國通用大模型的研發攻關；建議支持有條件的地方政府，以專項債的形式支持通用和行業大模型研發以及應用生態發展所需的算力基礎設施建設；建議制訂相關政策，推動工業和民生等領域的大模型應用，從而讓「底座大模型+行業應用」形成相互促進的良好局面；建議鼓勵國資央企優先應用國產大模型，在關鍵敏感領域和核心戰略領域只能用自主可控的大模型；建議面向「一帶一路」設立專項，支持多語種大模型技術研發，以及在主要產業鏈合作國家、地區的落地應用。</p><p><strong>第二，建議加快形成圍繞國產大模型的自主可控產業生態。</strong></p><p>大模型是典型的平台賦能性技術，要加快我國大模型開發者生態體系建設和運營，支持國產大模型向開發者開放，開展大模型評測體系和開源社區建設，降低研發和使用成本。支持工業大模型在工業互聯網領域的賦能，支持軟件大模型對軟件行業的賦能，支持行業大模型對汽車、家電、服務機器人等行業領域的應用，以「人工智能+」推動我國自主可控的大模型產業生態蓬勃發展。</p><p><strong>第三，建議推動國家級高質量訓練數據開放和共享。</strong></p><p>推動國家層面高質量數據平台的設立和資源共享，加大政府和市場協同，合理解決知識產權問題，構建包括國家公共數據資源、高質量電子圖書、高質量音視頻、多渠道行業應用數據及互聯網開源數據資源等多源多模態的國家級數據資源匯聚平台，支持國家實驗室、全國重點實驗室、國家人工智能開放創新平台、行業領軍企業等國家戰略科技力量以揭榜掛帥形式優先、低成本使用。</p><p><strong>第四，建議出台更加客觀、公正、可信的評測方法，加快大模型在行業領域的應用落地。</strong></p><p>聯合國家級權威機構和行業龍頭企業等組織，共同發佈具有公信力的大模型評測標準和應用指南，並定期組織系統全面的科學評測，指導各行業甄別和選型大模型，避免各家大模型刻意刷榜和各種不權威的商業評測擾亂正常市場秩序。在行業應用方面，建議首批可以加快開發面向金融、工業、汽車、文旅、政務、教育、醫療等關鍵行業的應用場景，加快打造標杆示範，在成效驗證後向全國規模化推廣。</p><p><strong>第五，建議堅持源頭核心技術系統性創新，在戰略性、前瞻性的基礎研究領域做好佈局。</strong></p><p>佈局投入大模型的寬基礎研究，在大模型能力湧現機理、大模型可信訓練推理、強化學習技術、自主學習技術等方面形成突破。建議加快腦科學與類腦智能、量子計算等領域與人工智能關鍵研究的協同攻關，形成交叉學科的突破，助力我國通用人工智能彎道超車。建議推動大模型與科學研究的深度結合，打造 AI for Science 的科研新範式，研究基於科學數據的 AI 建模和科學知識提取技術，助力科研人員更高效地進行科學研究和探索。在生命科學、化學、製藥、物理、材料等多個科研領域，引入人工智能通識課，培養一批具備專業科研能力以及高水平通用人工智能理解能力的人才，為可能湧現的交叉學科重大突破做儲備。</p><p><strong>第六，建議加快推廣大模型賦能全學段，以全新機制加快探索我國人工智能拔尖創新人才培養。</strong></p><p>建議加快運用大模型的現有能力打造教師和學生的助手，賦能從中小學到職業教育和大學的教育教學提質增效。設立國家人工智能學院，以「核心+基地」的組織形式和全新機制推動我國面對中美競爭的拔尖人工智能人才培養。加強人工智能一級學科建設，聯合頭部企業打造一批人工智能人才產教融合培養基地，打造優秀人才專項遴選機制和通道等。</p><p><strong>第七，建議研究通用人工智能時代人才能力素質模型和培養方案，加快應用型人才培養。</strong></p><p>針對未來可能被人工智能大量替代的行業和崗位，對勞動力培養及再就業做專項研究，並且提前、主動做好應對。關注通用人工智能對社會各行業帶來的衝擊，加快建設新的人才能力素質模型和課程培養體系，特別是加快用通用人工智能賦能軟件代碼、語言學習、藝術創意等應用型人才的培養，助力我國軟件行業和數字經濟發展。</p><p><strong>第八，建議加速通用人工智能技術相關的法律法規制定與審議。</strong></p><p>建議圍繞大模型的數據安全、隱私泄露、可靠性、知識產權等幾大關鍵方面制定法律法規，提升通用人工智能技術可靠性與規範性。同時，完善向社會開放的大模型的准入和運行規則，明確責任分配與問責機制，並明確大模型知識產權與保護方式。</p><p><strong>第九，建議設立軟課題進行通用人工智能相關的倫理人文研究。</strong></p><p>堅持科學、獨立原則，針對通用人工智能技術可能帶來的社會風險、倫理挑戰和人類文明變化進行開放式課題研究。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 10:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281604</guid>
            <link>https://www.oschina.net/news/281604</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[知乎創始人兼 CEO 周源：中國大模型面臨中文語料資源短缺的挑戰]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 2024 年全國兩會上，全國政協委員、知乎創始人兼 CEO 周源提交多份提案，重點關注補齊優質中文語料數據短板、激發互聯網平台企業創新熱情、以高質量技能人才供給推動新質生產力快速發展等內容。</p><p><img alt="" height="322" src="https://oscimg.oschina.net/oscnet/up-7f20232feea611c54f6dff70e0d906765cd.png" width="400" referrerpolicy="no-referrer"></p><p><strong>▍補齊優質中文語料數據短板</strong></p><p>截至 2023 年年底，我國累計發佈了 200 多個人工智能大模型，其中有 20 多個大模型產品獲批向公眾提供服務。儘管我國在大模型領域取得了一定的成就，但仍面臨着一些挑戰，其中最顯著的問題之一是高質量中文語料資源的短缺。</p><p>2021-2026 年中國數據量規模將由 18.51ZB 增長至 56.16ZB，年均複合增長率達到 24.9%，高於全球平均水平。雖然國內存量數據資源豐富，但目前中文優質數據仍然稀缺，如 ChatGPT 訓練數據中文資料比重不足千分之一，而英文資料佔比超過 92.6%。</p><p>對此，周源建議，建立數據合規的監管機制，推動完善 AIGC 監管立法，保護和規範人工智能領域的數據合規。對大模型的數據採集來源、處理方法、合規性等進行監督和審查。此外，應加強對大模型的社會影響和風險評估，及時發現和解決可能存在的問題。此外，要加強數據安全和知識產權的保護措施，並加快高質量中文數據集的開發與利用，數據作為新型生產要素已經成為驅動全球數字經濟的動力引擎，國內數據要素市場起步較晚，標準、權屬、交易、商業模式、監管等相關環節還有待完善。</p><p><strong>▍激發互聯網平台企業創新活力</strong></p><p>2024 年將迎來中國全功能接入互聯網 30 週年的重要里程碑。歷經近三十載的發展，互聯網不僅重塑了人們的工作模式、生活形態，甚至改變了思維方式，是我國科技創新體系的核心力量，為推動創新驅動發展戰略提供了強大動力。</p><p>對此，周源建議，加強政策法規保障，提振互聯網平台企業發展信心 。要加快促進民營經濟發展立法進程。要科學設置監管政策。完善市場準入負面清單制度，明確禁止和限制進入的領域。對於尚未納入監管範圍的產業，應遵循「法無禁止即可為」的原則，支持互聯網平台企業探索未知領域，為培育未來產業奠定堅實基礎。</p><p>要完善科技創新機制，激發互聯網平台企業創新熱情。優化產業和科技扶持資金和項目的組織方式，更大比例吸收科技創新型互聯網平台企業及其產業科學家、企業家深度參與。提供税收優惠和政府引導基金支持，降低互聯網企業研發成本，激發其持續投入研發的熱情。</p><p><strong>▍以高質量技能人才供給，推動新質生產力快速發展</strong></p><p>新質生產力的源頭在科技創新，落腳點在產業升級，關鍵因素在人才支撐。加快形成新質生產力，不僅需要「高精尖缺」科技人才，還要有一大批高素質技術技能人才、大國工匠、能工巧匠等。</p><p>周源表示，人工智能技術為技能培訓行業帶來了更多的創新機會，促進了技能培訓行業更加豐富的應用場景落地。通過人工智能技術的運用，職業技能培訓行業可以實現更加個性、靈活、高效的教學模式，為學生提供更精準的學習體驗。同時，教師也能借助 AI 工具提升教學效果，更好地滿足學生的學習需求，促進技能培訓向更高水平發展。</p><p>他建議，應鼓勵並引導培訓機構和教師更加積極主動地適應和掌握 AI 技術，提升自身的專業能力和教育素養，藉助人工智能技術和 AI 大模型的發展，不斷探索創新，賦能技能培訓行業實現變革式發展，可促進高質量技能人才培養效率和有效供給。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 09:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281602</guid>
            <link>https://www.oschina.net/news/281602</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【比較 ORM 操作數據】操作批量新增、分頁查詢（四）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>orm 框架使用性能比較</h3><h4>比較 mybatis、lazy、sqltoy、mybatis-flex、easy-query、mybatis-mp 操作數據</h4><h4>環境：</h4><pre><code>idea 
jdk17
spring boot 3.0.7
mysql 8.0
</code></pre><h3>測試條件常規對象</h3><table><tbody><tr><th>orm 框架</th><th>是否支持 xml</th><th>是否支持 Lambda</th><th>對比版本</th><th>編碼方式</th></tr></tbody><tbody><tr><td>mybatis</td><td>☑️</td><td>☑️</td><td>3.5.4</td><td>lambda +xml 優化</td></tr><tr><td>sqltoy</td><td>☑️</td><td>☑️</td><td>5.2.98</td><td>lambda</td></tr><tr><td>lazy</td><td>✖️</td><td>☑️</td><td>1.2.4-JDK17-SNAPSHOT</td><td>lambda</td></tr><tr><td>mybatis-flex</td><td>☑️</td><td>☑️</td><td>1.8.0</td><td>lambda +xml 優化</td></tr><tr><td>easy-query</td><td>✖️</td><td>☑️</td><td>1.10.31</td><td>lambda</td></tr><tr><td>mybatis-mp</td><td>☑️</td><td>☑️</td><td>1.4.1</td><td>xml 優化</td></tr></tbody></table><h3>數據庫表 (含有唯一性索引 s_u)</h3><pre><code class="language-sql">CREATE TABLE `sys_user`
(
    `column_name` varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '額外字段',
    `create_time` datetime                                DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '創建時間',
    `id`          bigint NOT NULL AUTO_INCREMENT COMMENT '用户 ID',
    `is_deleted`  tinyint(1) DEFAULT NULL COMMENT 'null',
    `password`    varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '密碼',
    `scope`       varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT 'null',
    `status`      tinyint(1) DEFAULT NULL COMMENT '狀態',
    `update_time` datetime                                DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新時間',
    `username`    varchar(255) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '用户名',
    PRIMARY KEY (`id`) USING BTREE,
    UNIQUE KEY `s_u` (`scope`,`username`)
) ENGINE=InnoDB AUTO_INCREMENT=9223371632070323791 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
</code></pre><h3>比較方法:增加、修改、刪除、分頁查詢（當前項目暫時只比較批量新增和分頁）</h3><h4>項目設計</h4><ul><li><p>聲明 ORMRepository 接口提供對應增刪改查方法&nbsp;</p></li><li><p><img height="310" src="https://oscimg.oschina.net/oscnet/up-3346115676879f0de40c1bad7135e582e46.png" width="624" referrerpolicy="no-referrer"></p></li><li><p>聲明 ORMComparisonRepository 接口，繼承 ORMRepository 下游由不同 ORM 實現</p></li><li><p>聲明 SysUserRepository 接口，繼承 ORMRepository 用於循環調用不同 orm 實現方法執行方法測試產生測試結果</p></li><li><p>聲明抽象類 SysUserRepositoryAbstractRecord 繼承 ORMComparisonRepository 並且提供對應的框架執行結果存儲&nbsp;</p></li><li><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-0c6ab47e6cc9cf0b11b58f0fd93c14d685d.png" width="774" referrerpolicy="no-referrer"></p></li><li><p>不同 ORM 框架 mybatis、sqltoy、Lazy、easy-query、mybatis-mp 創建 ORMComparisonRepository 的實現&nbsp;</p></li><li><p><img height="414" src="https://oscimg.oschina.net/oscnet/up-108f97de1127f946f2245344b28456680d4.png" width="376" referrerpolicy="no-referrer"></p></li><li><p>不同 ORM 操作數據的實現</p></li><li><p><img height="824" src="https://oscimg.oschina.net/oscnet/up-e5825f9d18ef85c3461696ee4479b06df24.png" width="2278" referrerpolicy="no-referrer"></p></li></ul><h3>測試條件，批量插入數據 10、100、1000、10000、100000 ，分頁查詢數據 10、100、1000、10000、100000</h3><pre><code>項目啓動後使用瀏覽器打開 http://localhost:1003/sys/user/run-compare
</code></pre><h3>測試條件（細節比較） 批量插入數據 1～10000，分頁查詢數據 1～10000</h3><pre><code>項目啓動後使用瀏覽器打開 http://localhost:1003/sys/user/run-particulars-compare
</code></pre><h3>測試執行過程</h3><pre><code>清空需要插入表中所有數據
通過三種 ORM 框架進行數據批量新增、而後進行分頁查詢，記錄消耗時間，輸出 md 文檔
</code></pre><h3><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flocalhost%3A1003%2F" target="_blank">查看結果曲線圖</a></h3><p><img height="716" src="https://oscimg.oschina.net/oscnet/up-f4601e49790693dc379f3e55184b70f116d.png" width="1411" referrerpolicy="no-referrer"></p><h3>測試結果（結果只提供參考）</h3><table><tbody><tr><th>MYBATIS_FLEX(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>9 毫秒</strong></td><td><strong>25 毫秒</strong></td><td><strong>79 毫秒</strong></td><td><strong>624 毫秒</strong></td><td><strong>6682 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>34 毫秒</strong></td><td><strong>28 毫秒</strong></td><td><strong>121 毫秒</strong></td><td><strong>647 毫秒</strong></td><td><strong>6704 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>LAZY(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>4 毫秒</strong></td><td><strong>21 毫秒</strong></td><td><strong>53 毫秒</strong></td><td><strong>350 毫秒</strong></td><td><strong>3663 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_MP(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>8 毫秒</strong></td><td><strong>20 毫秒</strong></td><td><strong>92 毫秒</strong></td><td><strong>601 毫秒</strong></td><td><strong>6768 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>EASY_QUERY(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>100 毫秒</strong></td><td><strong>150 毫秒</strong></td><td><strong>423 毫秒</strong></td><td><strong>1965 毫秒</strong></td><td><strong>19030 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>SQLTOY(batchStory)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>40 毫秒</strong></td><td><strong>133 毫秒</strong></td><td><strong>390 毫秒</strong></td><td><strong>1617 毫秒</strong></td><td><strong>15982 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_FLEX(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>60 毫秒</strong></td><td><strong>13 毫秒</strong></td><td><strong>20 毫秒</strong></td><td><strong>106 毫秒</strong></td><td><strong>681 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>834 毫秒</strong></td><td><strong>740 毫秒</strong></td><td><strong>691 毫秒</strong></td><td><strong>702 毫秒</strong></td><td><strong>783 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>LAZY(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>14 毫秒</strong></td><td><strong>13 毫秒</strong></td><td><strong>19 毫秒</strong></td><td><strong>82 毫秒</strong></td><td><strong>492 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>MYBATIS_MP(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>621 毫秒</strong></td><td><strong>657 毫秒</strong></td><td><strong>652 毫秒</strong></td><td><strong>607 毫秒</strong></td><td><strong>687 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>EASY_QUERY(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>85 毫秒</strong></td><td><strong>14 毫秒</strong></td><td><strong>25 毫秒</strong></td><td><strong>76 毫秒</strong></td><td><strong>522 毫秒</strong></td></tr></tbody></table><table><tbody><tr><th>SQLTOY(findPage)</th><th>影響行數:10</th><th>影響行數:100</th><th>影響行數:1000</th><th>影響行數:10000</th><th>影響行數:100000</th></tr></tbody><tbody><tr><td>執行時間:</td><td><strong>62 毫秒</strong></td><td><strong>43 毫秒</strong></td><td><strong>49 毫秒</strong></td><td><strong>107 毫秒</strong></td><td><strong>248 毫秒</strong></td></tr></tbody></table><h4>寫在最後</h4><h4>細節數據對比（一萬以內基本相差不大，一萬以後數據差距明顯拉開）</h4><p><img height="679" src="https://oscimg.oschina.net/oscnet/up-deb279dde27bdae5608578a4fbe03a0c130.png" width="1396" referrerpolicy="no-referrer"></p><p>批量保存：</p><ul><li>一萬條數據以內，性能由高到低 mybatis-flex 、mybatis-mp、mybatis、lazy 性能趨於一致 sqltoy、easy-query 耗時出現明顯起伏</li><li>十萬數據時，處理時間由快到慢依次是: lazy、mybatis-flex、mybatis-mp、mybatis、easy-query、sqltoy</li></ul><p>分頁查詢：</p><ul><li>一萬條數據以內，性能由高到低 lazy、mybatis-flex 、sqltoy、easy-query、mybatis、mybatis-mp</li><li>十萬數據時，處理時間由快到慢依次是: sqltoy、lazy、easy-query、mybatis-mp、mybatis-flex、mybatis</li><li>&nbsp;</li></ul><h3>快速數據對比 (大數據曲線圖)</h3><p><img height="686" src="https://oscimg.oschina.net/oscnet/up-44e961497942eab56e2db6f73c3744e0484.png" width="1420" referrerpolicy="no-referrer"></p><p><img height="693" src="https://oscimg.oschina.net/oscnet/up-2c078b6fe860207c2c0d019e4e202f389e0.png" width="1397" referrerpolicy="no-referrer"></p><h4><a href="https://gitee.com/wujiawei1207537021/wu-compare-orm-demo">當前項目地址</a></h4><h4><a href="https://gitee.com/wujiawei1207537021/wu-framework-parent/tree/master/wu-inner-intergration/wu-database-parent">lazy-orm 地址</a></h4><h4><a href="https://gitee.com/baomidou/mybatis-plus">mybatis 地址</a></h4><h4><a href="https://gitee.com/sagacity/sagacity-sqltoy">sqltoy 地址</a></h4><h4><a href="https://gitee.com/mybatis-flex/mybatis-flex">mybatis-flex 地址</a></h4><h4><a href="https://gitee.com/xuejm/easy-query">easy-query 地址</a></h4><h4><a href="https://gitee.com/mybatis-mp/mybatis-mp">mybatis-mp 地址</a></h4></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 09:40:06 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281600</guid>
            <link>https://www.oschina.net/news/281600</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
