<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 22 Feb 2024 04:24:53 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[夜鶯監控 V7 第一個 beta 版本來了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>夜鶯項目從 2024 開始開發 V7 版本，重點做體驗優化，V7 和 V6 版本兼容可以平滑升級<span style="background-color:#ffffff; color:#333333">（V6 升級到 V7 只需要替換一下二進制重啓即可，如果是容器部署，只需要更新鏡像並重啓）</span>，今天發佈第一個 beta，此 beta 版本的優化項包括：</p><ul><li>全站暗黑主題</li><li>優化邊緣機房機器失聯告警的實現邏輯，真正做到邊緣機房告警自閉環</li><li>優化內置大盤、內置告警規則的列表頁面 UI</li><li>全局回調地址頁面展示優化，增加詳盡的文檔提示信息</li></ul><p><span style="background-color:#ffffff; color:#333333">更多優化項正在開發中，V5、V6 用户可以放心升級，V7 會是一個更好的版本。升級之前記得備份以防萬一。</span></p><h2>項目介紹</h2><p style="color:#333333; text-align:left">夜鶯監控是一款開源雲原生觀測分析工具，採用 All-in-One 的設計理念，集數據採集、可視化、監控告警、數據分析於一體，與雲原生生態緊密集成，提供開箱即用的企業級監控分析和告警能力。夜鶯於 2020 年 3 月 20 日，在 github 上發佈 v1 版本，已累計迭代 100 多個版本。</p><p style="color:#333333; text-align:left">夜鶯最初由滴滴開發和開源，並於 2022 年 5 月 11 日，捐贈予中國計算機學會開源發展委員會（CCF ODC），為 CCF ODC 成立後接受捐贈的第一個開源項目。夜鶯的核心研發團隊，也是 Open-Falcon 項目原核心研發人員，從 2014 年（Open-Falcon 是 2014 年開源）算起來，也有 10 年了，只為把監控這個事情做好。</p><h2>項目截圖</h2><p style="color:#333333; text-align:left"><img alt="20240221141801" src="https://download.flashcat.cloud/ulric/20240221141801.png" referrerpolicy="no-referrer"></p><p style="color:#333333; text-align:left"><img alt="20240221141817" src="https://download.flashcat.cloud/ulric/20240221141817.png" referrerpolicy="no-referrer"></p><h2>項目代碼</h2><ul><li>後端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank">💡 https://github.com/ccfos/nightingale</a></li><li>前端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fn9e%2Ffe" target="_blank">💡 https://github.com/n9e/fe</a></li></ul><p style="color:#333333; text-align:left">夜鶯項目已收穫 8000 多 github stars，1000 多 forks，100 多 contributors 參與其中，歡迎大家在<span>&nbsp;</span><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank"><strong>GitHub</strong></a></strong><span>&nbsp;</span>上關注夜鶯項目，及時獲取項目更新動態，有任何問題，也歡迎提交 issues，以及提交 pull requests，開源社區需要大家一起參與才能有蓬勃的生命力。</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 04:15:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</guid>
            <link>https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報：等到 Sora 開源了立刻推出屬於我們自己的大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.21</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/279326/linux-kernel-is-a-cna" target="_blank">2023 年度 Rust 調查報告</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">有 93% 的受訪者稱自己是 Rust 用户，其中 49% 的人每天（或幾乎每天）都會使用 Rust，相較上一年小幅增加 2 個百分點。在沒有使用 Rust 的用户中，31% 的人表示主要原因時使用 Rust 有難度；67% 的人表示他們還沒有機會優先學習 Rust，這也是最常見的原因。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-335afef97d65f03d34d0f08eb8831153557.png" width="500" referrerpolicy="no-referrer"></span></p><h3><a href="https://www.oschina.net/news/279389/dart-3-3-released" target="_blank">Go 1.22 正式發佈</a></h3><p>Go 1.22 中新增的優化之一是改進了虛擬化，允許靜態調度更多的接口方法調用。啓用 PGO 後，大多數程序的性能將提高 2% 至 14%。 此外，Go 運行時中的內存優化可將 CPU 性能提高 1-3%，同時還可將大多數 Go 程序的內存開銷減少約 1%。</p><p>新的 math/rand/v2 軟件包提供了更簡潔、更一致的應用程序接口，並使用了質量更高、速度更快的偽隨機生成算法。&nbsp;</p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-9fc6f45ad8365450e0980fe7fe1855a56c5.png" referrerpolicy="no-referrer"></p><p>- 微博 <u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6640496217%2FO1tM7BenZ" target="_blank">-赤犬龍之介-</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-d423a4b13075c233da7226ccd5235dc0a3e.png" referrerpolicy="no-referrer"></p><p>-&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2F8XMQgC7LlaK" target="_blank">21 世紀經濟報道</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-25f6c0a5f5becd775a0ad6bd1080893da87.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-bbc6216c930e22f859d514d8becc057daae.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p>Gitee 榜單：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5ab4f59bdf01add8c61aac9c617fa074d2c.png" referrerpolicy="no-referrer"></p><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:47:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279735</guid>
            <link>https://www.oschina.net/news/279735</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[數百位名人簽署公開信，呼籲制定反深度偽造立法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>數百名 AI 界人士簽署了一封<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">公開信</a>，呼籲嚴格監管 AI 生成的冒名頂替或深度偽造（Deepfake）內容。</p><p><img height="274" src="https://oscimg.oschina.net/oscnet/up-df56f62fff93b887bf1198aca4ccf4bcb5e.png" width="500" referrerpolicy="no-referrer"></p><p>公開信指出，"深度偽造"是指未經同意或嚴重誤導的人工智能生成的聲音、圖像或視頻，合理的人會誤以為是真實的。這不包括對圖像或聲音的輕微改動，也不包括容易識別為合成的無害娛樂或諷刺。</p><p>如今，深度偽造通常涉及性圖像、欺詐或政治虛假信息。由於人工智能發展迅速，使得深度偽造變得更加容易，因此我們需要為數字基礎設施的運行和完整性提供保障。「Deepfakes 對社會的威脅日益嚴重，政府必須在整個供應鏈中施加義務，以阻止 Deepfakes 的擴散。」</p><p>信中呼籲：</p><ul><li>將深度偽造的兒童性虐待材料（CSAM，又名兒童色情製品）完全定為刑事犯罪，無論所描繪的人物是真實的還是虛構的。</li><li>在任何情況下，如果有人制造或傳播有害的深度偽造品，都需要受到刑事處罰。</li><li>要求軟件開發商和分銷商防止其音頻和視頻產品被用於製造有害的深度偽造品，如果他們的預防措施不充分，就要承擔責任接受處罰。</li></ul><p>他們認為，如果設計得當，這些法律可以在不會造成過重負擔的同時，培育有社會責任感的企業。</p><p>這封信中較為知名的簽名者包括：</p><ul><li>Jaron Lanier</li><li>Frances Haugen</li><li>Stuart Russell</li><li>Andrew Yang</li><li>Marietje Schaake</li><li>Steven Pinker</li><li>Gary Marcus</li><li>Oren Etzioni</li><li>Genevieve smith</li><li>Yoshua Bengio</li><li>Dan Hendrycks</li><li>Tim Wu</li></ul><p>事實上，這也不是首次出現相關的呼籲。在本月早些時候正式提出之前，歐盟已就此類措施進行了多年辯論。外媒 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F21%2Fhundreds-of-ai-luminaries-sign-letter-calling-for-anti-deepfake-legislation%2F" target="_blank">TechCrunch</a> 指出，也許正是歐盟願意進行審議和落實，才激活了這些研究人員、創作者和管理人員的發言權。雖然此舉不一定能推動真正的立法，但它確實是業界專家們如何看待這一爭議問題的風向標。</p><p>更多詳情可查看此處：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">https://openletter.net/l/disrupting-deepfakes</a>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:32:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279733/disrupting-deepfakes</guid>
            <link>https://www.oschina.net/news/279733/disrupting-deepfakes</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[出門問問創始人李志飛點評谷歌開源大模型 Gemma：差點意思]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌在北京時間昨晚發佈了<u><a href="https://www.oschina.net/news/279713/google-gemma-open-models">開源大模型 Gemma</a></u>，對標 Meta 旗下 Llama 2。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><p>出門問問創始人李志飛發表文章點評，<strong>稱 Gemma 推出時間有點晚、開源力度不夠、未放下高貴的頭顱</strong>。</p><p>李志飛在文章中表示，相比於去年上半年就開源，現在可能要花數倍的努力進行模型的差異化以及推廣的投入，才有可能在眾多開源模型中脱穎而出。「面對 OpenAI 的強力競爭，只有殺敵一千、自損一千五。」</p><p>以下為李志飛全文：</p><blockquote><p>看到 Google 開源了小的語言模型 Gemma，直接狙擊 Llama 2，回顧去年 5 月對 Google 關於開源和競爭的看法，幾點思考如下：</p><p>1. 時間有點晚：相比於去年上半年就開源，現在可能要花數倍的努力進行模型的差異化以及推廣的投入，才有可能在眾多開源模型中脱穎而出。</p><p>2. 開源力度不夠：感覺這次開源還是被動防禦和略顯扭捏的應對之策，不是進攻。比如説，開個 7B 的模型實在是太小兒科了，一點殺傷力都沒有。應該直接開源一個超越市場上所有開源的至少 100B 的模型、1M 的超長上下文、完善的推理 infra 方案、外加送一定的 cloud credit。是的，再不歇斯底里 Google 真的就晚了。面對 OpenAI 的強力競爭，只有殺敵一千、自損一千五。</p><p>3. 未放下高貴的頭顱：有種感覺，Google 覺得自己還是 AI 王者，放不下高貴的頭顱，很多發佈都有點不痛不癢，還是沿着過去研發驅動的老路而不是產品和競爭驅動，比如不停發論文、取新名字（多模態相關模型過去半年就發了 Palme、RT-2、Gemini、VideoPoet、W.A.L.T 等）、發佈的模型又完整度不夠，感覺就沒有一個絕對能打的產品。Google 可能要意識到在公眾眼中，他在 AI 領域已經是廉頗老矣潰不成軍，經常起大早趕晚集（比如説這次 Sora 借鑑的 ViT、ViViT、NaVit、MAGVit 等核心組件技術都是它家寫的論文）。</p><p>4. 希望亡羊補牢未為晚也：Google 作為一個僵化的大公司，動作慢一點可以理解，但是如果再不努力是不是就是 PC 互聯網的 IBM、移動互聯網的 Microsoft？ 作為 Google 的鐵粉，還是希望他能打起精神一戰，AI 產業需要強力的競爭才能不停向前發展，也需要他在前沿研究和系統的開源才能幫助一大眾「貧窮」的 AI 創業公司。</p><p>5. 另外，除了對外開源外，Google 應該組成三個方陣面對大模型的競爭，詳見去年 3 月發文。</p><p>回顧科技競爭史，PC 互聯網時代的 IBM、移動互聯網時代的 Microsoft、AGI 時代的 Google，新時代來臨後，難道上一個時代科技霸主都難逃衰落的宿命？</p><p>當然，Microsoft 靠 Office SaaS、雲和 OpenAI 又翻盤了。</p><p>歷史的鐵律，有被改寫的可能嗎？</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:15:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279728</guid>
            <link>https://www.oschina.net/news/279728</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 員工的一天]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Chain Of Thought (CoT) 第一作者、從谷歌跳槽到 OpenAI 的 Jason Wei 分享了自己在 OpenAI 的一天：</p><blockquote><p>[9:00am] 起牀</p><p>[9:30am] 搭乘 Waymo 前往 Mission SF，途中在 Tartine 買個牛油果吐司</p><p>[9:45am] 背誦 OpenAI 章程。向優化之神致敬，學習《The Bitter Lession》（強化學習之父 Rich Sutton 著）</p><p>[10:00am] 在 Google Meet 上開會，討論如何在更多數據上訓練更大的模型</p><p>[11:00am] 敲代碼，在更多數據上訓練更大的模型。搭檔是 Hyung Won Chung</p><p>[12:00pm] 去食堂吃午飯（純素且無麩質）</p><p>[1:00pm] 真正開始在大量數據上訓練大模型</p><p>[2:00pm] 處理基礎設施問題（我是腦子被驢踢了嗎為啥要從 master 分支拉代碼？）</p><p>[3:00pm] 監控模型訓練進度，玩 Sora</p><p>[4:00pm] 給剛才訓練的大模型上提示工程</p><p>[4:30pm] 短暫休息，坐在牛油果椅子上，思考 Gemini Ultra 的性能到底有多強</p><p>[5:00pm] 頭腦風暴模型可能的算法改進</p><p>[5:05pm] 修改算法風險太高，pass。最安全的策略還是力大磚飛（增加算力和數據規模）</p><p>[6:00pm] 晚餐時間，和 Roon 一起享用蛤蜊濃湯</p><p>[7:00pm] 回家</p><p>[8:00pm] 喝點小酒，繼續寫碼。Ballmer’s peak（酒精帶來的編碼高效階段）即將到來</p><p>[9:00pm] 分析實驗結果，我對 wandb 又愛又恨</p><p>[10:00pm] 啓動實驗，讓它自己跑一晚上，第二天查看結果</p><p>[1:00am] 實驗真正開始運行</p><p>[1:15am] 上牀睡覺。在納德拉和黃仁勳的守護下入夢。心想：壓縮才是真諦。晚安</p><p><img src="https://oscimg.oschina.net/oscnet/up-3041206e9fa5084776ebedb71c760828888.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2F_jasonwei%2Fstatus%2F1760032264120041684" target="_blank">https://twitter.com/_jasonwei/status/1760032264120041684</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279722</guid>
            <link>https://www.oschina.net/news/279722</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[StarkNet 撒錢，程序員在 Web3 領了 14 萬 ​​​]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>StarkNet 啓動空投活動，GitHub 排名前 5000 開源項目的貢獻者可領取價值 $200 獎勵。</p><h2>背景</h2><ul><li>StarkNet 公鏈項目為了激勵開發者參與其平台建設，啓動了空投活動。</li><li>如果曾向 GitHub 上獲得較多 Star 的項目提交過 PR ，就有資格領取 111.1 STRK 的空投獎勵。</li><li>只需要使用 OAuth 2.0 登錄，就可以直接領取。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-44f62dafa84c34781d15d46c71c7c8c862c.jpg" referrerpolicy="no-referrer"></p><p>有程序員曬出自己在這次空投活動獲得的獎勵——近 14 萬人民幣。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-96e62f68c4891cdbfd1f43b86ddfcdcbf79.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fstrrlthedev%2Fstatus%2F1760182038504837287" target="_blank">https://twitter.com/strrlthedev/status/1760182038504837287</a></u></em></p></blockquote><h2>領取規則</h2><ol><li>截止到 2023 年 11 月 15 日，至少對全球排名前 5000 的倉庫提交過三次代碼貢獻。</li><li>其中至少有一次貢獻是在 2018 年或之後完成的。</li></ol><h2>領取步驟</h2><p>領取地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprovisions.starknet.io%2F" target="_blank">https://provisions.starknet.io/</a></u></em></p><ol><li>訪問獎勵領取頁面並連接錢包（推薦使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2Fargent-x-starknet-wallet%2Fdlcobpjiigpikoobohmabehhmhfoodbb" target="_blank">Argent X</a>）。</li><li>通過 GitHub 登錄，採用 OAuth 2.0 驗證方式。</li><li>直接領取獎勵。後續的治理投票和問卷調查可忽略不計。</li></ol></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279720</guid>
            <link>https://www.oschina.net/news/279720</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為：2 月 26 日將首發華為通信大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">華為官方微信公眾號消息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7dnrCXQoOqWSfKBrCJWl6Q" target="_blank">顯示</a>， 在 2 月 26 日華為產品與解決方案發佈會上，即將首發華為通信大模型。</span></p><p><img height="677" src="https://oscimg.oschina.net/oscnet/up-59659387ba8ade9e0cf71c6f84d476a728e.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">華為稱，2024 年，5G-A 商用元年正式開啓！萬兆時代已來，共同見證將 5G-A 帶入現實。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:23:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279717</guid>
            <link>https://www.oschina.net/news/279717</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌發佈輕量級開源大語言模型 Gemma]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌發佈了開源大語言模型 Gemma，這是一款輕量級、先進的開源模型，供開發者和研究人員用於 AI 構建。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><p>Gemma 模型家族包括 2B（20 億參數）和 7B（70 億參數）兩種尺寸，能夠在不同的設備類型上運行，包括筆記本電腦、桌面電腦、IoT 設備、移動設備和雲端。</p><p><strong>性能和設計</strong></p><p>Gemma 模型在技術和基礎設施組件上與 Gemini 共享，這使得 Gemma 2B 和 7B 在其大小範圍內相比其他開放模型具有最佳性能。</p><p>Gemma 模型不僅可以直接在開發者的筆記本電腦或桌面電腦上運行，而且在關鍵基準測試中的表現超過了更大的模型，同時遵循嚴格的安全和負責任輸出標準。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-50f9213a30f71b22bb88d2abb40a2f7a116.png" referrerpolicy="no-referrer"></p><p><strong>主要特點</strong></p><ol><li><strong>輕量級、高性能模型</strong>：Gemma 模型家族包括 Gemma 2B 和 Gemma 7B 兩種尺寸，提供預訓練和指令調優的變體，針對其大小範圍內相比其他開放模型具有最佳性能。</li><li><strong>跨框架工具鏈支持</strong>：支持 JAX、PyTorch 和 TensorFlow 通過原生 Keras 3.0 進行推理和監督式微調（SFT），適應多種開發需求和環境。</li><li><strong>易於入門和集成</strong>：提供準備就緒的 Colab 和 Kaggle 筆記本，以及與 Hugging Face、MaxText、NVIDIA NeMo 和 TensorRT-LLM 等流行工具的集成，方便開發者快速上手。</li><li><strong>高效的運算能力</strong>：針對多個 AI 硬件平台上進行優化，確保在 NVIDIA GPU 和 Google Cloud TPU 上的行業領先性能。通過與 NVIDIA 的合作，無論是在數據中心、雲端還是本地 RTX AI PC 上，都確保了行業領先的性能和與尖端技術的集成。</li></ol><p>Gemma 模型能夠在不同的設備類型上運行，包括筆記本電腦、桌面電腦、IoT 設備、移動設備和雲端。這種廣泛的兼容性使得模型能夠適應各種應用場景和需求。</p><ul><li><span>模型地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmodels%3Fother%3Dgemma%26sort%3Dtrending%26search%3Dgoogle" target="_blank">https://huggingface.co/models?other=gemma&amp;sort=trending&amp;search=google…</a><span></span></li><li><span>博客：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fdevelopers%2Fgemma-open-models%2F" target="_blank">https://blog.google/technology/developers/gemma-open-models/</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:17:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279713/google-gemma-open-models</guid>
            <link>https://www.oschina.net/news/279713/google-gemma-open-models</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[你好，iLogtail 2.0！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者：張浩翔（篤敏）</p><h2>概述</h2><p>隨着可觀測數據採集需求的不斷推陳出新，多樣化的數據輸入輸出選項、個性化的數據處理能力組合、以及高性能的數據處理吞吐能力已經成為頂流可觀測數據採集器的必備條件。然而，由於歷史原因，現有的 iLogtail 架構和採集配置結構已經無法繼續滿足上述需求，逐漸成為制約 iLogtail 繼續向前快速演進的瓶頸：</p><p>▶︎ iLogtail 設計之初完全面向文件日誌採集至日誌服務的場景：</p><p>1）簡單地將日誌分為多種格式，每種格式的日誌僅支持一種處理方式（如正則解析、Json 解析等）；</p><p>2）功能實現與日誌服務相關概念（如 Logstore 等）強綁定；</p><p>基於此設計思想，現有的 iLogtail 架構偏向於單體架構，導致模塊間耦合嚴重，可擴展性和普適性較差，難以提供多個處理流程級聯的能力。</p><p>▶︎ Golang 插件系統的引入極大地擴展了 iLogtail 的輸入輸出通道，且一定程度提升了 iLogtail 的處理能力。然而，囿於 C++ 部分的實現，輸入輸出與處理模塊間的組合能力仍然嚴重受限：</p><p>1）C++ 部分原生的高性能處理能力仍然僅限於採集日誌文件並投遞至日誌服務的場景使用；</p><p>2）C++ 部分的處理能力無法與插件系統的處理能力相結合，二者只能選其一，從而降低了複雜日誌處理場景的性能。</p><p>▶︎ 與 iLogtail 整體架構類似，現有的 iLogtail 採集配置結構也採用平鋪結構，缺乏處理流水線的概念，無法表達處理流程級聯的語義。</p><p>基於上述原因，在 iLogtail 誕生 10 週年之際，日誌服務啓動對 iLogtail 的升級改造，寄希望於讓 iLogtail 的易用性更佳，性能更優，可擴展性更強，從而更好地服務廣大用户。</p><p>目前，經過半年多的重構與優化，iLogtail 2.0 已經呼之欲出。接下來，就讓我們來搶先了解一下 iLogtail 2.0 的新特性吧！</p><h2>新特性</h2><h3>（一）【商業版】採集配置全面升級流水線結構</h3><p>為瞭解決舊版採集配置平鋪結構無法表達複雜採集行為的問題，iLogtail 2.0 全面擁抱新版流水線配置，即每一個配置對應一條處理流水線，包括輸入模塊、處理模塊和輸出模塊，每個模塊由若干個插件組成，各模塊的插件功能如下：</p><ul><li><strong>輸入插件：</strong> 用於從指定輸入源獲取數據（各插件具體功能詳見輸入插件 <strong>[</strong><strong>1]</strong> ）</li><li><strong>處理插件：</strong> 用於對日誌進行解析和處理（各插件具體功能詳見處理插件 <strong>[</strong><strong>2]</strong> ），可進一步分為原生處理插件和擴展處理插件</li></ul><p>&lt;!----&gt;</p><ul><li>原生處理插件：性能較優，適用於大部分業務場景，推薦優先使用</li><li>擴展處理插件：功能覆蓋更廣，但性能劣於原生處理插件，建議僅在原生處理插件無法完成全部處理需求時使用</li></ul><p>&lt;!----&gt;</p><ul><li><strong>輸出插件：</strong> 用於將處理後的數據發送至指定的存儲</li></ul><p>我們可以用一個 JSON 對象來表示一個流水線配置：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f6cc95f0ae9e478bd8c674f6fae4ee9ceb9.png" alt="" referrerpolicy="no-referrer"></p><p>其中，inputs、processors 和 flushers 即代表輸入、處理和輸出模塊，列表中的每一個元素 {...} 即代表一個插件；global 代表流水線的一些配置。有關流水線配置結構的具體信息，可參見 iLogtail 流水線配置結構 <strong>[</strong><strong>3]</strong> 。</p><blockquote><p>示例：採集 /var/log 目錄下的 test.log，對日誌進行 json 解析後發送到日誌服務。以下是實現該採集需求對應的舊版和新版配置，可以看到新版配置十分精煉，執行的操作一目瞭然。</p><p><strong>舊版配置：</strong></p><pre><code>{
&nbsp;&nbsp;&nbsp;&nbsp;"configName":&nbsp;"test-config",
&nbsp;&nbsp;&nbsp;&nbsp;"inputType":&nbsp;"file",
&nbsp;&nbsp;&nbsp;&nbsp;"inputDetail":&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"topicFormat":&nbsp;"none",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"priority":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logPath":&nbsp;"/var/log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filePattern":&nbsp;"test.log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"maxDepth":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"tailExisted":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"fileEncoding":&nbsp;"utf8",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logBeginRegex":&nbsp;".*",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerFile":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerIncludeLabel":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerExcludeLabel":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerIncludeEnv":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerExcludeEnv":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"preserve":&nbsp;true,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"preserveDepth":&nbsp;1,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"delaySkipBytes":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"delayAlarmBytes":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logType":&nbsp;"json_log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"timeKey":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"timeFormat":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"adjustTimezone":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logTimezone":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filterRegex":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filterKey":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"discardNonUtf8":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"sensitive_keys":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"mergeType":&nbsp;"topic",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"sendRateExpire":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"maxSendRate":&nbsp;-1,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"localStorage":&nbsp;true
&nbsp;&nbsp;&nbsp;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;"outputType":&nbsp;"LogService",
&nbsp;&nbsp;&nbsp;&nbsp;"outputDetail":&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logstoreName":&nbsp;"test_logstore"
&nbsp;&nbsp;&nbsp;&nbsp;}
}
</code></pre><p><strong>新版流水線配置：</strong></p><pre><code>{
&nbsp;&nbsp;&nbsp;&nbsp;"configName":&nbsp;"test-config",
&nbsp;&nbsp;&nbsp;&nbsp;"inputs":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"file_log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"FilePaths":&nbsp;"/var/log/test.log"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;"processors":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_json_native"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"content"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;"flushers":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"flusher_sls",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Logstore":&nbsp;"test_logstore"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;]
}
</code></pre><p>如果在執行 json 解析後需要進一步處理，在流水線配置中只需額外增加一個處理插件即可，但是在舊版配置中已經無法表達上述需求。</p></blockquote><p>有關新版流水線配置和舊版配置的兼容性問題，請參見文末兼容性説明板塊。</p><h4>全新 API</h4><p>為了支持流水線配置，同時區分舊版配置結構，我們提供了全新的用於管理流水線配置的 API 接口，包括：</p><ul><li>CreateLogtailPipelineConfig</li><li>UpdateCreateLogtailPipelineConfig</li><li>GetLogtailPipelineConfig</li><li>DeleteLogtailPipelineConfig</li><li>ListLogtailPipelineConfig</li></ul><p>有關這些接口的詳細信息，請參見 OpenAPI 文檔 <strong>[</strong><strong>4]</strong> 。</p><h4>全新控制枱界面</h4><p>與流水線採集配置結構相對應，前端控制枱界面也進行了全新升級，分為了全局配置、輸入配置、處理配置和輸出配置。</p><p><img src="https://oscimg.oschina.net/oscnet/up-52a9a2935a7738f4ddd6cc8123ae3551f2d.png" alt="" referrerpolicy="no-referrer"></p><p>與舊版控制枱界面相比，新版控制枱具有如下特點：</p><p><strong>參數內聚：</strong> 某一功能相關的參數集中展示，避免了舊版控制枱參數散落各處出現漏配置。</p><blockquote><p>示例：最大目錄監控深度與日誌路徑中的**密切相關，舊版界面中，二者分隔較遠，容易遺忘；在新版界面中，二者在一起，便於理解。</p><p><strong>舊版控制枱：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-04d5bc90063cbedb86c8049d54635e3023c.png" alt="" referrerpolicy="no-referrer"></p><p><strong>新版控制枱：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-b559b0e4ad0b5877d16aa684f9ba4d50d00.png" alt="" referrerpolicy="no-referrer"></p></blockquote><p><strong>所有參數均為有效參數：</strong> 在舊版控制枱中，啓用插件處理後，部分控制枱參數會失效，從而引起不必要的誤解。新版控制枱所有參數均為有效參數。</p><h4>全新 CRD</h4><p>同樣，與新版採集配置對應，K8s 場景中與採集配置對應的 CRD 資源也全新升級。與舊版 CRD 相比，新版 CRD 具有如下特點：</p><ul><li>支持新版流水線採集配置</li><li>CRD 類型調整為 Cluster 級別，且將 CRD 名稱直接作為採集配置名稱，避免同一集羣多個不同的 CRD 資源指向同一個採集配置引起衝突</li><li>對所有操作的結果進行定義，避免出現多次操作舊版 CRD 後出現的行為未定義情況</li></ul><pre><code>apiVersion:&nbsp;log.alibabacloud.com/v1alpha1
kind:&nbsp;ClusterAliyunLogConfig
metadata:
&nbsp;&nbsp;name:&nbsp;test-config
spec:
&nbsp;&nbsp;project:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-project
&nbsp;&nbsp;logstore:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-logstore
&nbsp;&nbsp;machineGroup:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-machine_group
&nbsp;&nbsp;config:
&nbsp;&nbsp;&nbsp;&nbsp;inputs:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Type:&nbsp;input_file
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FilePaths:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;/var/log/test.log
&nbsp;&nbsp;&nbsp;&nbsp;processors:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Type:&nbsp;processor_parse_json_native
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SourceKey:&nbsp;content
</code></pre><h3>（二）處理插件組合更加靈活</h3><p>對於文本日誌採集場景，當您的日誌較為複雜需要多次解析時，您是否在為只能使用擴展處理插件而困惑？是否為因此帶來的性能損失和各種不一致問題而煩惱？</p><p>升級 iLogtail 2.0，以上問題都將成為過去！</p><p>iLogtail 2.0 的處理流水線支持全新級聯模式，和 1.x 系列相比，有以下能力升級：</p><ul><li><p><strong>原生處理插件可任意組合：</strong></p><p>原有原生處理插件間的依賴限制不復存在，您可以隨意組合原生處理插件以滿足您的處理需求。</p></li><li><p><strong>原生處理插件和擴展處理插件可同時使用：</strong></p><p>對於複雜日誌解析場景，如果僅用原生處理插件無法滿足處理需求，您可進一步添加擴展處理插件進行處理。</p></li></ul><p><strong>🔔 注意：</strong> 擴展處理插件只能出現在所有的原生處理插件之後，不能出現在任何原生處理插件之前。</p><blockquote><p>示例：假如您的文本日誌為如下內容：</p><p>{"time": "2024-01-22T14:00:00.745074", "level": "warning", "module": "box", "detail": "127.0.0.1 GET 200"}</p><p>您需要將 time、level 和 module 字段解析出來，同時還需要將 detail 字段做進一步正則解析，拆分出 ip、method 和 status 字段，最後丟棄 drop 字段，則您可以按順序使用「Json 解析原生處理插件」、「正則解析原生處理插件」和「丟棄字段擴展處理插件」完成相關需求：</p><p>【商業版】</p><p><img src="https://oscimg.oschina.net/oscnet/up-6310f6b8a781ce3e256042e7f44ed09a75d.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c5dea6cb6a41a50be2f5eb48e2dbeeda960.png" alt="" referrerpolicy="no-referrer"></p><p>【開源版】</p><pre><code>{
&nbsp;&nbsp;"configName":&nbsp;"test-config"
&nbsp;&nbsp;"inputs":&nbsp;[...],
&nbsp;&nbsp;"processors":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_json_native",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"content"
&nbsp;&nbsp;&nbsp;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_regex_native",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"detail",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Regex":&nbsp;"(\S)+\s(\S)+\s(.*)",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Keys":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"ip",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"method",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"status"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_drop",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"DropKeys":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"module"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;],
&nbsp;&nbsp;"flushers":&nbsp;[...]
}
</code></pre><p>採集結果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f272a5d2ade5c817461bf406d1a73836f89.png" alt="" referrerpolicy="no-referrer"></p></blockquote><h3>（三）新增 SPL 處理模式</h3><p>除了使用處理插件組合來處理日誌，iLogtail 2.0 還新增了 SPL（SLS Processing Language）處理模式，即使用日誌服務提供的用於統一查詢、端上處理、數據加工等的語法，來實現端上的數據處理。使用 SPL 處理模式的優勢在於：</p><ul><li>擁有豐富的工具和函數：支持多級管道操作，內置功能豐富的算子和函數</li><li>上手難度低：低代碼，簡單易學</li><li>【商業版】統一語法：一個語言玩轉日誌採集、查詢、加工和消費</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-4513da15197b25b1099a5707d39a222214d.png" alt="" referrerpolicy="no-referrer"></p><h4>SPL 語法</h4><h5>整體結構：</h5><ul><li>指令式語句，支持結構化數據和非結構化數據統一處理</li><li>管道符（|）引導的探索式語法，複雜邏輯編排簡便</li></ul><pre><code>&lt;data-source&gt;&nbsp;
|&nbsp;&lt;spl-cmd&gt;&nbsp;-option=&lt;option&gt;&nbsp;-option&nbsp;...&nbsp;&lt;expression&gt;,&nbsp;...&nbsp;as&nbsp;&lt;output&gt;,&nbsp;...
|&nbsp;&lt;spl-cmd&gt;&nbsp;...
|&nbsp;&lt;spl-cmd&gt;&nbsp;...
</code></pre><h5>結構化數據 SQL 計算指令：</h5><ul><li>where&nbsp;通過 SQL 表達式計算結果產生新字段</li><li>extend&nbsp;根據 SQL 表達式計算結果過濾數據條目</li></ul><pre><code>*
|&nbsp;extend&nbsp;latency=cast(latency&nbsp;as&nbsp;BIGINT)
|&nbsp;where&nbsp;status='200'&nbsp;AND&nbsp;latency&gt;100
</code></pre><h5>非結構化數據提取指令：</h5><ul><li>parse-regexp&nbsp;提取指定字段中的正則表達式分組匹配信息</li><li>parse-json&nbsp;提取指定字段中的第一層 JSON 信息</li><li>parse-csv&nbsp;提取指定字段中的 CSV 格式信息</li></ul><pre><code>*
|&nbsp;project-csv&nbsp;-delim='^_^'&nbsp;content&nbsp;as&nbsp;time,&nbsp;body
|&nbsp;project-regexp&nbsp;body,&nbsp;'(\S+)\s+(\w+)'&nbsp;as&nbsp;msg,&nbsp;user
</code></pre><h3>（四）日誌解析控制更加精細</h3><p>對於原生解析類插件，iLogtail 2.0 提供了更精細的解析控制，包括如下參數：</p><ul><li>KeepingSourceWhenParseFail：解析失敗時，是否保留原始字段。若不配置，默認不保留。</li><li>KeepingSourceWhenParseSucceed：解析成功時，是否保留原始字段。若不配置，默認不保留。</li><li>RenameSourceKey：當原始字段被保留時，用於存儲原始字段的字段名。若不配置，默認不改名。</li></ul><blockquote><p>示例：假設需要在日誌字段內容解析失敗時在日誌中保留該字段，並重命名為 raw，則可配置如下參數：</p><ul><li>KeepingSourceWhenParseFail：true</li><li>RenameSourceKey：raw</li></ul></blockquote><h3>（五）【商業版】日誌時間解析支持納秒級精度</h3><p>在 iLogtail 1.x 版本中，如果您需要提取日誌時間字段到納秒精度，日誌服務只能在您的日誌中額外添加「納秒時間戳」字段。在 iLogtail 2.0 版本中，納秒信息將直接附加至日誌採集時間（<strong>time</strong>）而無需額外添加字段，不僅減少了不必要的日誌存儲空間，也為您在 SLS 控制枱根據納秒時間精度對日誌進行排序提供方便。</p><p>如果需要在 iLogtail 2.0 中提取日誌時間字段到納秒精度，您需要首先配置時間解析原生處理插件，並在「源時間格式（SourceFormat）」的末尾添加「.%f」，然後在全局參數中增加"EnableTimestampNanosecond": true。</p><blockquote><p>示例：假設日誌中存在字段 time，其值為 2024-01-23T14:00:00.745074，時區為東 8 區，現在需要解析該時間至納秒精度並將 <strong>time</strong> 置為該值。</p><p><img src="https://oscimg.oschina.net/oscnet/up-443ebb6650ab6fb7334c3b3b1c5527ac60c.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-6237e2882b874738edda03a89819297d75b.png" alt="" referrerpolicy="no-referrer"></p><p>採集結果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-519f2570442d18bdb7f276c108ff1112546.png" alt="" referrerpolicy="no-referrer"></p></blockquote><p><strong>🔔 注意：</strong> iLogtail 2.0 不再支持 1.x 版本中提取納秒時間戳的方式，如果您在 1.x 版本中已經使用了提取納秒時間戳功能，在升級 iLogtail 2.0 後，需要按照上述示例手動開啓新版納秒精度提取功能，詳細信息參見文末兼容性説明。</p><h3>（六）【商業版】狀態觀測更加清晰</h3><p>相比於 iLogtail 1.x 暴露的簡單指標，iLogtail 2.0 極大地完善了自身可觀測性的建設：</p><ul><li>所有采集配置都有完整指標，可以在 Project/Logstore 等維度上進行不同採集配置的統計與比較</li><li>所有插件都有自己的指標，可以構建完整流水線的拓撲圖，每個插件的狀態可以進行清楚的觀測</li><li>C++ 原生插件提供更加詳細的指標，可以用來監控與優化插件的配置參數</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-1eafd646874b01b9014f3feb5edee33dd27.png" alt="" referrerpolicy="no-referrer"></p><h3>（七）運行更快更安全</h3><p>iLogtail 2.0 支持 C++ 17 語法，C++ 編譯器升級至 gcc 9，同時更新了 C++ 依賴庫的版本，使得 iLogtail 的運行更快更安全。</p><p>表：iLogtail 2.0 單線程處理日誌的性能（以單條日誌長度 1KB 為例）</p><table><thead><tr><th align="left"><strong>場景</strong></th><th align="left"><strong>CPU（核）</strong></th><th align="left"><strong>內存（MB）</strong></th><th align="left"><strong>處理速率（MB/s）</strong></th></tr></thead><tbody><tr><td align="left">單行日誌採集</td><td align="left">1.06</td><td align="left">33</td><td align="left">400</td></tr><tr><td align="left">多行日誌採集</td><td align="left">1.04</td><td align="left">33</td><td align="left">150</td></tr></tbody></table><h2>兼容性説明</h2><h3>（一）採集配置</h3><h4>商業版</h4><ul><li>新版流水線採集配置是完全向前兼容舊版採集配置的，因此：</li></ul><p>&lt;!----&gt;</p><ul><li>在您升級 iLogtail 至 2.0 版本的過程中，日誌服務會在下發配置時自動將您的舊版配置轉換為新版流水線配置，您無需執行任何額外操作。您可以通過 GetLogtailPipelineConfig 接口直接獲取舊版配置對應的新版流水線配置</li></ul><p>&lt;!----&gt;</p><ul><li>舊版採集配置並不完全向後兼容新配流水線配置</li></ul><p>&lt;!----&gt;</p><ul><li>如果流水線配置描述的採集處理能力可用舊版配置表達，則該流水線配置依然可以被 iLogtail 0.x 和 1.x 版本使用，日誌服務會在向 iLogtail 下發配置時自動將新版流水線配置轉換為舊版配置</li><li>反之，該流水線配置會被 iLogtail 0.x 和 1.x 版本忽略</li></ul><h4>開源版</h4><p>新版採集配置與舊版採集配置存在少量不兼容情況，詳見 iLogtail 2.0 版本採集配置不兼容變更説明 <strong>[</strong><strong>5]</strong> 。</p><h3>（二）iLogtail 客户端</h3><p><strong>1. 使用擴展處理插件時的 Tag 存儲位置</strong></p><p>當您使用擴展插件處理日誌時，iLogtail 1.x 版本由於實現原因會將部分 tag 存放在日誌的普通字段中，從而為您後續在 SLS 控制枱使用查詢、搜索和消費等功能時帶來諸多不便。為瞭解決這一問題，iLogtail 2.0 將默認將所有 tag 歸位，如果您仍希望保持 1.x 版本行為，您可以在配置的全局參數中增加"UsingOldContentTag": true。</p><ul><li>對於通過舊版控制枱界面和舊版 API 創建的採集配置，在您升級 iLogtail 2.0 後，tag 的存儲位置仍然與 1.x 版本一致；</li><li>對於通過新版控制枱界面和新版 API 創建的採集配置，在您升級 iLogtail 2.0 後，tag 的存儲位置將默認歸位。</li></ul><p><strong>2. 高精度日誌時間提取</strong></p><p>2.0 版本不再支持 1.x 版本的 PreciseTimestampKey 和 PreciseTimestampUnit 參數，當您升級 iLogtail 2.0 版本後，原有納秒時間戳提取功能將失效，如果您仍需解析納秒精度時間戳，您需要參照日誌時間解析支持納秒精度板塊對配置進行手動更新。</p><p><strong>3. 飛天格式日誌微秒時間戳時區調整</strong></p><p>2.0 版本的飛天解析原生處理插件將不再支持 1.x 版本的 AdjustingMicroTimezone 參數，默認微秒時間戳也會根據配置的時區進行正確的時區調整。</p><p><strong>4. 日誌解析控制</strong></p><p>對於原生解析類插件，除了日誌解析控制更加精細板塊中提到的 3 個參數，還存在 CopyingRawLog 參數，該參數僅在 KeepingSourceWhenParseFail 和 KeepingSourceWhenParseSucceed 都為 true 時有效，它將在日誌解析失敗時，在日誌中額外增加 <strong>raw_log</strong> 字段，字段內容為解析失敗的內容。</p><p>該參數的存在是為了兼容舊版配置，當您升級 iLogtail 2.0 版本後，建議您及時刪去該參數以減少不必要的重複日誌上傳。</p><h2>總結</h2><p>為用户提供更舒適便捷的用户體驗一直是日誌服務的宗旨。相比於 iLogtail 1.x 時代，iLogtail 2.0 的變化是比較明顯的，但這些轉變只是 iLogtail 邁向現代可觀測數據採集器的序曲。我們強烈建議您在條件允許的情況下嘗試 iLogtail 2.0，也許您在轉換之初會有些許的不適應，但我們相信，您很快會被 iLogtail 2.0 更強大的功能和更出色的性能所吸引。</p><p><strong>相關鏈接：</strong></p><p>[1]&nbsp;輸入插件</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-19%3Fspm%3Da2c4g.11186623.0.0.2a755c0dN5uxv4" target="_blank">https://help.aliyun.com/zh/sls/user-guide/overview-19?spm=a2c4g.11186623.0.0.2a755c0dN5uxv4</a></em></p><p>[2]&nbsp;處理插件</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-22%3Fspm%3Da2c4g.11186623.0.0.2f2d1279yGXSce" target="_blank">https://help.aliyun.com/zh/sls/user-guide/overview-22?spm=a2c4g.11186623.0.0.2f2d1279yGXSce</a></em></p><p>[3]&nbsp;iLogtail 流水線配置結構</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnext.api.aliyun.com%2Fstruct%2FSls%2F2020-12-30%2FLogtailPipelineConfig%3Fspm%3Dapi-workbench.api_explorer.0.0.65e61a47jWtoir" target="_blank">https://next.api.aliyun.com/struct/Sls/2020-12-30/LogtailPipelineConfig?spm=api-workbench.api_explorer.0.0.65e61a47jWtoir</a></em></p><p>[4]&nbsp;OpenAPI 文檔</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnext.api.aliyun.com%2Fdocument%2FSls%2F2020-12-30%2FCreateLogtailPipelineConfig%3Fspm%3Dapi-workbench.api_explorer.0.0.65e61a47jWtoir" target="_blank">https://next.api.aliyun.com/document/Sls/2020-12-30/CreateLogtailPipelineConfig?spm=api-workbench.api_explorer.0.0.65e61a47jWtoir</a></em></p><p>[5]&nbsp;iLogtail 2.0 版本採集配置不兼容變更説明</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Filogtail%2Fdiscussions%2F1294" target="_blank">https://github.com/alibaba/ilogtail/discussions/1294</a></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:08:47 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/11044307</guid>
            <link>https://my.oschina.net/u/3874284/blog/11044307</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[程序員因 bug 事故被公司強制要求歸還 4 萬年終獎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>某程序員在 V2EX 發帖稱，因線上流量異常事故，自己被公司進行處罰。處罰的結果是被要求將去年發的 4 萬多年終獎歸還給公司，如果逾期不還，將以每天萬分之 5 的利息收取滯納金。</p><p>該程序員還稱，公司 hr 還揚言三個月內還是不還就免費開除。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-11365064309a71d744e9abe207d19996d40.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1016302" target="_blank">https://www.v2ex.com/t/1016302</a></u></em></p></blockquote><p>最新後續：</p><blockquote><p><img height="4236" src="https://oscimg.oschina.net/oscnet/up-0b14b51439371608fa1837e2222c753a465.png" width="1504" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1017164" target="_blank">https://www.v2ex.com/t/1017164</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 10:31:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279644</guid>
            <link>https://www.oschina.net/news/279644</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[我國 5G 基站總數超 337 萬個，5G 移動電話用户達 8.05 億户]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>工業和信息化部數據指出：截至 2023 年底，我國累計建成 5G 基站 337.7 萬個，5G 移動電話用户達 8.05 億户。</p><p>網絡基礎日益完備。我國已建成全球最大的光纖和移動寬帶網絡，全國行政村通 5G 比例超 80%。通信杆塔資源與社會杆塔資源雙向共享取得顯著成效，目前 90% 以上的基站實現共建共享，5G 基站單站址能耗相較於商用初期降低 20% 以上。</p><p>創新能力不斷增強。我國 5G 技術產業在技術標準、網絡設備、終端設備等方面創新能力不斷增強。輕量化 5G 核心網、定製化基站等實現商用部署。5G 工業網關、巡檢機器人等一批新型終端成功研發。5G 標準必要專利聲明量全球佔比超 42%，持續保持全球領先。</p><p>賦能效應持續凸顯。融合應用廣度和深度不斷拓展，5G 應用已融入 71 個國民經濟大類，應用案例數超 9.4 萬個，5G 行業虛擬專網超 2.9 萬個。5G 應用在工業、礦業、電力、港口、醫療等行業深入推廣。「5G+工業互聯網」項目數超 1 萬個。</p><p>賦值效應更加顯著。5G 移動電話用户持續增長、5G 流量消費快速提升，有效拓展了移動通信市場的發展空間。截至 2023 年底，我國 5G 網絡接入流量佔比達 47%。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 09:01:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279630</guid>
            <link>https://www.oschina.net/news/279630</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[法國電信公司 Orange 違反 GPL 許可協議，被罰 65 萬歐元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根據 2024 年 2 月 14 日下達的判決，法國上訴法院判定當地電信公司 <strong>Orange 因未遵守 GNU GPL v2 許可證條款而侵權</strong>，並且需要向 Entr'Ouvert 支付&nbsp;<strong>50 萬歐元的經濟損失賠償和 15 萬歐元的精神損失賠償</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aba84da216106bb416ed362f90f6181cab6.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweb.archive.org%2Fweb%2F20240216164701%2Fhttps%3A%2F%2Fwww.legalis.net%2Factualite%2Forange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl%2F" target="_blank">https://web.archive.org/web/20240216164701/https://www.legalis.net/actualite/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6928315e1d404157b8404126515b42d68a7.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.orange.com%2Fen" target="_blank">Orange</a></u><span>&nbsp;是一家法國電信運營商。根據上文的判決，</span>Orange 的 IDMP 平台使用了名叫 Lasso 的庫，該庫的版權所有者為 Entr'Ouvert 公司。<strong>Lasso 採用 GPLv2 License —— 併為私有項目提供了商業許可證</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-7e59b5839901ae3f8dc0da42fd32d14c3d1.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flasso.entrouvert.org%2F" target="_blank">https://lasso.entrouvert.org/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2d0135e65a7b51a798b2692a65007c31a65.png" referrerpolicy="no-referrer"></p><p>2005 年年底，Orange 參與了電子管理局關於實施 My Public Service 門户網站的招標活動，為身份管理提供一套 IT 解決方案，其中包括<strong>通過軟件接口將 IDMP 平台與 Entr'ouvert 公司發佈的 Lasso 軟件庫連接起來，Lasso 庫採用 GPL 許可證</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7d0ef557e10594da586685534b7728c372e.png" referrerpolicy="no-referrer"></p><p>法院認為，Entr'Ouvert 首先蒙受了與其在公共市場 Mon.service-public.fr 上收益受損相關的經濟損失，「因為如果 Orange 公司遵守許可合同，並簽訂付費許可，他們就應該向對方支付版税。」</p><p>此外，上訴法院特別指出，「Orange 免費使用 Lasso 軟件為這個持續 7 年的大規模公開市場帶來了利潤，此外還有 Lasso 給這個門户網站在形象方面帶來的好處。<strong>這番操作讓 Orange 得以節省投入從而受益，因為通過免費使用 Lasso 軟件，Orange 公司可以滿足通信安全和隱私管理局 (ADAE) 要求的安全標準，從而能夠節省研發成本</strong>。」</p><p>Entr'ouvert 着重批評 Orange 違反了 Lasso 程序的許可合同條款，這些條款涉及它作為該程序版權持有人所擁有的知識產權，因此它以涉嫌侵犯其權利為由起訴了 Orange。</p><p>上訴法院首先要求 Entr'ouvert 證明 Lasso 軟件具有原創性。</p><p>根據 Entr'ouvert 出示的證據，上訴法院得出的結論是，<strong>Lasso 「在軟件組成、結構和表達方面都是原創的，符合版權保護的條件」</strong>。</p><p>上訴法院隨後審查了 Entr'Ouvert 援引的三起違反 GNU GPL v2 許可協議的行為。</p><p><strong>首先，法院認為 Orange 違反了許可合同第 2 條，因為它對 IDMP 所基於的 Lasso 進行了修改，卻沒有將 IDMP 作為一個免費整體授予政府。</strong></p><p><strong>其次，法院判定 Orange 沒有進一步遵守第 3 條，因為沒有提供修改後的源代碼。</strong></p><p><strong>最後，法院特別指出，Orange 在沒有遵守許可合同的所有條件、特別是第 4 條的情況下，複製、修改和分發了 Lasso。</strong></p><p><strong>法院還認為 Lasso 被整合到 IDMP 平台中，而 IDMP 平台的發行條件不一樣，且沒有徵得 Entr'Ouvert 公司的授權，此舉也違反了許可合同第 10&nbsp;條。</strong></p><p>總而言之，Orange 的 IDMP 產品使用了 Lasso，要麼按照 GPLv2 許可證要求公佈它的源代碼，要麼從版權所有者 Entr'Ouvert 購買許可證。Orange 沒有付費也沒有遵守 GPL 許可協議。法國上訴法庭判決 Orange 侵權行為成立。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 08:09:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</guid>
            <link>https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[清華大學文生視頻專利公佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">國家知識產權局網站顯示，近日，清華大學申請的「一種定製化多主體文生視頻方法、裝置、設備及介質」專利公佈，發明人為王鑫；朱文武；陳虹。</span></p><p><span style="background-color:#ffffff; color:#222222">摘要顯示，該申請涉及神經網絡技術領域，通過多種損失對文生視頻模型的參數進行優化，使優化的模型基於文本描述生成視頻中的圖像時，文本描述與定製化主體保持一致，且在每個主體在生成過程中的特徵不會發生混淆的同時消除合成痕跡。</span></p><p><span style="background-color:#ffffff; color:#222222"><img alt="" height="453" src="https://oscimg.oschina.net/oscnet/up-1ec28ceb1ad4ccf2dfbde602d461109e5a2.jpg" width="700" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 07:17:06 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279604</guid>
            <link>https://www.oschina.net/news/279604</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.20</strong></span></h3><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要點</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/279326/linux-kernel-is-a-cna" target="_blank">Linux 內核成為 CVE 編號機構 (CNA)</a></u></h3><p>Linux 內核已被接受為 CVE 編號機構 (CNA)，這意味着他們將直接管理內核的 CVE。Linus Torvalds 近日在郵件列表發佈了 Linux 6.8-rc5，並介紹稱文檔添加了 CVE 漏洞處理相關的指南。</p><p>文檔寫道，Linux 內核開發團隊有能力為潛在的內核安全問題分配 CVE，而分配的 CVE 編號將在 linux-cve-announce 郵件列表上公佈，修復的安全漏洞才會分配 CVE 編號，未修復的不會自動分配編號。</p><h3><u><a href="https://www.oschina.net/news/279389/dart-3-3-released" target="_blank">Dart 3.3 發佈：擴展類型、JavaScript Interop 等</a></u></h3><p>Dart 3.3 現已發佈，公告稱此版本改變了性能和跨平台開發的遊戲規則。</p><p>增強的擴展類型（Extension Types）將徹底改變性能優化以及用户與本地代碼的交互方式。JavaScript interop 模型也得到了改進，引入了強大的類型安全性和開發人員友好的方式來利用 Web 平台的強大功能。「所有這些都為 WebAssembly 支持鋪平了道路」。此外，新版本還增加了 Google AI 功能。</p><p><img height="300" src="https://oscimg.oschina.net/oscnet/up-3949a01f3c180246795018315421f62eccc.webp" width="300" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日觀察</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-50e80801ccee84a0972ddbf9328c862d87b.png" referrerpolicy="no-referrer"></p><p>- 微博 <em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1609119537%2FO1t7Mj9XJ" target="_blank">2gua</a></u></em></p><p><img src="https://oscimg.oschina.net/oscnet/up-1d42d0aba38b933d17c04033962ce1cc5e5.png" referrerpolicy="no-referrer"></p><p>-<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapp.myzaker.com%2Fnews%2Farticle.php%3Fpk%3D65d353d4b15ec004b02314b1" target="_blank">腦極體</a></u></em></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推薦</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-048ed3535e056a8b2c5037aadf05b7b881b.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">開源之聲</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-ce33753dcaf6809a8c2305f7b0fee44604a.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日項目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜單：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8d2c1aa11cc57bc0bfb89a2a2bc2f10afdd.png" referrerpolicy="no-referrer"></p><h4><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span><br><em><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf" target="_blank">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></u></em></h4><hr><p><strong>往期回顧</strong></p><ul><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf" target="_blank">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></u></li><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></u></li><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf" target="_blank">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></u></li><li><u><a href="https://www.oschina.net/news/277585" target="_blank">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></u></li><li><u><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 05:47:05 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279578</guid>
            <link>https://www.oschina.net/news/279578</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年度 Rust 調查報告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">2023 年度 Rust 調查報告現已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2024%2F02%2F19%2F2023-Rust-Annual-Survey-2023-results.html" target="_blank">出爐</a>，基於 2023 年 12 月 18 日至 2024 年 1 月 15 日期間進行的調查結果。此次調查問卷共收到 11950 份回覆，其中 9710 份完成了所有問題。</span></p><p><span style="color:#000000"><strong>參與情況</strong></span></p><p><span style="color:#000000">參與調查的開發者來自世界各地，最多的是美國（22%），其次是德國（12%）、中國（6%）、英國 (6%)、法國 (6) %）、加拿大（3%）、俄羅斯（3%）、荷蘭（3%）、日本（3%）和波蘭（3%）。92.7% 的受訪者更趨向於採用英語交流技術主題，相較 2022 年的 93% 略有下降；中文是第二選擇，佔比為 6.1%（ 2022 年為 7%）。</span></p><p><span style="color:#000000"><strong>Rust 使用情況</strong></span></p><p><span style="color:#000000">有 93% 的受訪者稱自己是 Rust 用户，其中 49% 的人每天（或幾乎每天）都會使用 Rust，相較上一年小幅增加 2 個百分點。在沒有使用 Rust 的用户中，31% 的人表示主要原因時使用 Rust 有難度；67% 的人表示他們還沒有機會優先學習 Rust，這也是最常見的原因。</span></p><p><span style="color:#000000">46% 的受訪者表示其不再使用 Rust 的原因在於「無法控制的因素」（比 2022 年減少了 1 個百分點），31% 的人是因為更喜歡另一種語言（比 2022 年增加了 9 個百分點），還有 24% 是因為難度（比 2022 年減少了 6 個百分點）。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-335afef97d65f03d34d0f08eb8831153557.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">操作系統的選擇方面，Linux 是最受 Rust 用户歡迎的選擇，其次是 macOS 和 Windows，兩者份額相近。IDE 的選擇上，Visual Studio Code 仍然是最受歡迎的選擇，RustRover（去年發佈）也獲得了一些關注。</span></p><p><span style="color:#000000"><strong>Rust 在工作中的使用情況</strong></span></p><p><span style="color:#000000">34% 的受訪者表示他們在工作中的大部分編碼業務都使用 Rust，相較 2022 年增加了 5 個百分點。86% 的受訪者僱主投資 Rust 的首要原因是能夠構建相對正確且無 bug 的軟件，第二個原因是 Rust 的優秀性能（83%）。77% 的受訪者表示，他們的組織可能會在未來再次使用 Rust。</span></p><p><span style="color:#000000">就技術領域而言，Rust 似乎在創建服務器後端、Web 和網絡服務以及雲技術方面特別受歡迎。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-956fdb129c803494d840f04071cceb0996b.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><strong>對 Rust 未來的擔憂和期待</strong></span></p><p><span style="color:#000000">共有 9374 名受訪者分享了他們對 Rust 未來的主要擔憂，其中 43% 的受訪者擔心 Rust 變得過於複雜，相較 2022 年增加了 5 個百分點。42% 的受訪者擔心 Rust 在科技行業的使用率過低。32% 的受訪者最擔心 Rust 開發人員和維護人員得不到適當的支持，相較 2022 年增加了 6 個百分點。</span></p><p><span style="color:#000000">另一方面，完全不關心 Rust 未來的受訪者明顯減少，2023 年為 18%，2022 年為 30%。</span></p><p><span style="color:#000000">就 Rust 用户希望實現、穩定或改進的功能而言，最需要的改進是 traits（trait aliases、associated type defaults 等）、const execution（generic const expressions、const trait methodsconst 等）以及 async（async closures、coroutines）。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-bcaf516c155cafe4eb2d721dc6e86434a9e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">可能是出於對複雜度的擔憂，還有 20% 的受訪者希望 Rust 放慢新功能的開發速度。此外，Rust 中最令用户頭疼的似乎是 asynchronous Rust、traits、generics system 以及 borrow checker。</span></p><p><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-de1d95566f02a3dccfae6db246605f3684a.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">受訪者希望 Rust 維護者主要優先考慮修復編譯器錯誤 (68%)、提高 Rust 程序的運行時性能 (57%) 以及縮短編譯時間 (45%)。受訪者指出，編譯時間是需要改進的最重要領域之一；但有趣的是，受訪者似乎也認為運行時性能比編譯時間更重要。</span></p><p><span style="color:#000000"><img alt="" height="571" src="https://oscimg.oschina.net/oscnet/up-b59d67be36c91976d230c9e2d43ae22ac9e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">更多詳情可查看</span>完整的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fraw.githubusercontent.com%2Frust-lang%2Fsurveys%2Fmain%2Fsurveys%2F2023-annual-survey%2Freport%2Fannual-survey-2023-report.pdf" target="_blank">調查報告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 04:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279563/rust-survey-2023-results</guid>
            <link>https://www.oschina.net/news/279563/rust-survey-2023-results</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024，RISC-V 可期]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>轉載自：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6WLBNUfHyfLCq7AR9Ortuw" target="_blank">中國電子報（ID：cena1984）</a></u></em></p></blockquote><p>2023 年，長期被冠以「低端」帽子的 RISC-V 架構，終於實現了高端化過程中的兩個「小目標」：一個是單核性能走高，可與 ARM Cortex-A7 對標；另一個是應用場景拓展到 PC 領域，首台搭載 RISC-V 架構的筆記本電腦<u><a href="https://www.oschina.net/news/234292">面世</a></u>。</p><p>如此勢頭下， 2024 年 RISC-V 的發展似乎「一片坦途」。</p><p><strong>在數據中心市場「掘金」</strong></p><p>為了實現「高端化」轉型，RISC-V 架構設計企業在持續嘗試將市場拓展到對算力、穩定性等指標要求更高的領域。2023 年，業界推出多個面向數據中心的 RISC-V 產品，其中包括算能科技流片業內首顆 RISC-V 服務器芯片 SG2042、賽昉科技推出的超大規模總線 IP「昉·星鏈-700」及 256 核 RISC-V 眾核 IP 子系統平台。</p><p>在數據中心領域，當前湧現了多家劍指服務器 CPU 的 RISC-V 初創公司。賽昉科技董事長兼 CEO 徐滔認為，不只是服務器 CPU，「數據中心」市場可謂遍地是黃金，BMC 芯片、存儲芯片、AI 加速器、DPU 等都可以用 RISC-V 來做。「我認為， 2024 年將有多款不同類型的 RISC-V 芯片在數據中心場景中量產落地。」徐滔向《中國電子報》表示。</p><p>此外，還有多家 RISC-V 廠商設計的 「大芯片」有流片可能，其中包括 Ventana 的 192 核、4nm 的 RISC-V 服務器 CPU——Veyron V2，Tenstorrent 的 3nm AI &amp; CPU Chiplets——Grendel 等，它們都有機會在 2024 年流片。</p><p><strong>趕上「AI 特快」</strong></p><p>「人工智能是目前正在開發的新興技術中最重要的類別，該類應用需要新型的編程模型、新型的 SoC 以及新型的系統，我們看到 RISC-V 在其中扮演着非常重要的角色。」 SiFive 企業營銷與業務開發資深副總裁剛至堅在接受《中國電子報》記者採訪時表示。</p><p>剛至堅認為，RISC-V 提供了一個奇妙的、共享的生態系統， 一個 AI 編程環境以及開發新軟件的環境，隨着性能、可定製化能力不斷提升，RISC-V 將越來越多地進入人工智能主導的新興市場中，其應用場景包括數據中心、汽車以及消費電子等領域。</p><p><strong>高端 SoC 可商用</strong></p><p>在深度數智總裁卜祥敏看來，2024 年最關鍵的是 SoC 可商用產品的落地。</p><p>「2023 年我們做了一年基於 RISC-V 的整體解決方案，我深刻地感受到，現在 SoC 芯片與真正的可商業化落地之間還有不少距離。」卜祥敏告訴《中國電子報》記者，「2023 年深度數智推出了基於 RISC-V 架構的筆記本電腦。2024 年，我們計劃和生態圈的合作伙伴一同推出搭載新一代基於 RISC-V 架構設計的 SoC 筆記本電腦和服務器。」</p><p>2023 年，谷歌與安卓宣佈支持 RISC-V 生態。卜祥敏表示，這將推動 RISC-V 的生態系統走向完善。更加完備的生態系統，將有助於提升 RISC-V 在桌面、智能終端等領域的可用性。</p><p>徐滔認為，垂直整合是 RISC-V 處理器在高端市場落地的有效方式。「垂直整合，即通過應用定義芯片。RISC-V 在商業上標準開放、技術上架構靈活，廠商可以更好地根據應用需求設計芯片。高端應用定義芯片，更能釋放垂直整合的價值，這也是 RISC-V 最大的機會。」徐滔表示。</p><p><strong>軟件生態加速建設</strong></p><p>2023 年 6 月，全球 RISC-V 軟件生態計劃 RISE（RISC-V Software Ecosystem）組織成立。該計劃由谷歌、英特爾、高通、聯發科、Andes、平頭哥、Rivos、SiFive、Ventana、三星、英偉達、Imagination 等共 13 家產業巨頭共同發起的，旨在協助 RISC-V 國際基金會共同加速 RISC-V 商用軟件生態建設。它的成立，標誌着 RISC-V 軟件生態從純開源主導、基金會主導進入商業化主導、全球大規模共建的時代。</p><p>中國科學院軟件研究所副所長、總工程師武延軍在接受《中國電子報》記者採訪時表示，由於 RISC-V 得到 Debian 和 OpenEuler 兩大開源操作系統社區的官方主線支持，加之 RISE 組織成立，頭部軟硬件企業正式加入 RISC-V 生態，2024 年 RISC-V 軟件生態將加速建設。</p><p>武延軍認為，2024 年，市面上將會在 2023 年已有產品的基礎上，再次出現 RISC-V 標誌性高性能處理器，服務器軟件生態規模化適配正式開啓。開源開放和全球協作理念，使得 RISC-V 開發者的規模持續快速增長。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:24:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279556</guid>
            <link>https://www.oschina.net/news/279556</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 21 虛擬線程如何限流控制吞吐量]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>虛擬線程（Virtual Threads）是 Java 21 所有新特性中最為吸引人的內容，它可以大大來簡化和增強 Java 應用的併發性。但是，隨着這些變化而來的是如何最好地管理此吞吐量的問題。本文，就讓我們看一下開發人員在使用虛擬線程時，應該如何管理吞吐量。</p><p>在大多數情況下，開發人員不需要自己創建虛擬線程。例如，對於 Web 應用程序，Tomcat 或 Jetty 等底層框架將為每個傳入請求自動生成一個虛擬線程。</p><p>如果在應用程序內部需要自行調用來提供業務併發能力時，我們可以使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2Fjava21%2Fjep444-virtual-threads.html" target="_blank">Java 21 新特性：虛擬線程（Virtual Threads）</a>中介紹的方法去創建和使用，比如較為常用的就是<code>Executors.newVirtualThreadPerTaskExecutor()</code>。</p><pre><code class="language-java">Runnable runnable = () -&gt; {
    System.out.println("Hello, www.didispace.com");
};

try (ExecutorService executorService = Executors.newVirtualThreadPerTaskExecutor()) {
    for (int i = 0; i &lt; 100; i++) {
        executorService.submit(runnable);
    }
}
</code></pre><p>我們可以像上面開啓 100 個虛擬線程來執行任務。那麼問題來了，我們要如何對虛擬線程限流控制吞吐量呢？</p><h2>虛擬線程的限流</h2><p>對於虛擬線程併發控制的答案是：信號量！**劃重點：不要池化虛擬線程，因為它們不是稀缺資源。**所以，對於虛擬線程併發控制的最佳方案是使用<code>java.util.concurrent.Semaphore</code>。</p><p>下面的代碼示例演示瞭如何實現<code>java.util.concurrent.Semaphore</code>來控制虛擬線程的併發數量：</p><pre><code class="language-java">public class SemaphoreExample {

    // 定義限流併發的信號量，這裏設置為：10
private static final Semaphore POOL = new Semaphore(10); 

public void callOldService(...) {
try{
POOL.acquire(); // 嘗試通過信號量獲取執行許可
} catch(InterruptedException e){
            // 執行許可獲取失敗的異常處理
}

try {
// 獲取到執行許可，這裏是使用虛擬線程執行任務的邏輯
} finally {
            // 釋放信號量
POOL.release(); 
}
}
}
</code></pre><p>是不是很簡單呢？今天的分享就到這裏，希望對你有所幫助，更多關於 Java 新特性的學習可以關注我的免費專欄<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2F" target="_blank">Java 新特性</a>。</p><h2>擴展閲讀</h2><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Farticle%2Fjava-21-virtaul-threads.html" target="_blank">啓動 1000 萬個虛擬線程需要多少時間？需要多少平台線程？</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Farticle%2Fspring-boot%2Fspring-boot-virtual-threads-vs-webflux.html" target="_blank">Spring Boot 虛擬線程與 Webflux 在 JWT 驗證和 MySQL 查詢上的性能比較</a></li></ul><blockquote><p>歡迎關注我的公眾號：程序猿 DD。第一時間瞭解前沿行業消息、分享深度技術乾貨、獲取優質學習資源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:02:42 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/didispace/blog/11044187</guid>
            <link>https://my.oschina.net/didispace/blog/11044187</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[芯片架構師 Jim Keller：英偉達的 CUDA 不是護城河，是沼澤]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>曾從事 x86、Arm、MISC 和 RISC-V 處理器研究的芯片架構師 Jim Keller 批評了英偉達的 CUDA 架構和軟件技術棧，他認為 CUDA 是英偉達的沼澤而非護城河。</p><blockquote><p><strong>「CUDA 是沼澤，而不是護城河。x86 也是一片沼澤。[…] CUDA 並不美好，它是通過一次堆積一件東西來構建的。」</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-bb29c91be732d8384401f752fab63b43fa2.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fjimkxa%2Fstatus%2F1758943525662769498" target="_blank">https://twitter.com/jimkxa/status/1758943525662769498</a></u></em></p></blockquote><p>他指出，就連英偉達本身也有多個專用軟件包，出於性能原因，這些軟件包依賴於開源框架。</p><p>就像 x86 一樣，CUDA 在保持軟件和硬件向後兼容性的同時逐漸增加了功能。這確保英偉達的平台完整且向後兼容，但它影響了性能並使程序開發變得更加困難。同時，很多開源軟件開發框架可以比 CUDA 更高效地使用。</p><p>Jim Keller 寫道：「<strong><em>基本上沒有人編寫 CUDA，如果你確實編寫 CUDA，它可能不會很快。[...] Triton、Tensor RT、Neon 和 Mojo 的存在是有充分理由的。</em></strong>」</p><p>甚至英偉達本身也有不完全依賴 CUDA 的工具。例如，Triton Inference Server 是英偉達的一款開源工具，可簡化 AI 模型的大規模部署，支持 TensorFlow、PyTorch 和 ONNX 等框架。Triton 還提供模型版本控制、多模型服務和併發模型執行等功能，以優化 GPU 和 CPU 資源的利用率。</p><p>英偉達的 TensorRT 是一種高性能深度學習推理優化器和運行時庫，可加速英偉達 GPU 上的深度學習推理。TensorRT 從各種框架（例如 TensorFlow 和 PyTorch）中獲取經過訓練的模型，並對其進行優化以進行部署，從而減少延遲並提高圖像分類、對象檢測和自然語言處理等實時應用程序的吞吐量。</p><p>儘管像 Arm、CUDA 和 x86 這樣的架構可能會被認為是沼澤，因為它們的演進速度相對較慢、必須向後兼容並且體積龐大，但這些平台也不像 GPGPU 這樣分散，這可能根本不是一件壞事。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 03:01:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279549</guid>
            <link>https://www.oschina.net/news/279549</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MariaDB 可能會以 3700 萬美元被私有化]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">MariaDB 董事會<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businesswire.com%2Fnews%2Fhome%2F20240219857559%2Fen%2FAnnouncement-Regarding-Possible-Offer" target="_blank">確認</a>，已於 2024 年 2 月 15 日收到了來自加利福尼亞 K1 投資管理公司的臨時收購要約。K1 於 2024 年 2 月 16 日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk1.com%2Fmeridian%2F" target="_blank">公開</a>宣佈了這一要約。MariaDB 董事會正在審查可能要約並聽取建議。</span></p><p><span style="color:#000000">這是一份非約束性的探索性提議，可能會根據未來幾周的談判進展而發生變化。該提議包括以每股 0.55 美元的價格購買所有 MariaDB 股票，按照該公司 2 月 5 日的收盤估值計算，約合 3700 萬美元。</span></p><p><span style="color:#000000">擬定交易將通過愛爾蘭法律安排計劃進行，K1 或其附屬公司將收購該公司 100% 的已發行股份。然而，K1 保留以合同要約的方式實施該提議的權利。尚未確定該提議將採取何種形式。</span></p><p><span style="color:#000000">值得一提的是，這一消息的發佈正值該公司發生重大變化和動盪之際，新任首席執行官上任後，該公司進行了大規模裁員，並剝離了數據庫即服務和地理空間業務。</span></p><p><img height="223" src="https://oscimg.oschina.net/oscnet/up-1da31f278849ce4cdcc7e6d0a823d84c4f4.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">2009 年，甲骨文公司斥資數十億美元對 MySQL 進行了一系列收購，使 MySQL 實際上成為甲骨文公司的資產，MySQL 項目的創建者因此對 MySQL 的獨立性產生了擔憂，於是 MariaD B 在 15 年前作為 MySQL 的一個分支而出現。對於那些尋求完全開源的 MySQL 替代品的人來説，MariaDB 被認為是一個"drop-in"的替代品，並已被一些大公司用於在其應用程序中存儲和處理數據。</span></p><p><span style="color:#000000">多年來，MariaDB 背後的商業實體籌集了大約 2.3 億美元的風險資金，最終於 2022 年 12 月通過 SPAC 上市。但正如 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F19%2Fstruggling-database-company-mariadb-could-be-taken-private-in-a-37m-deal%2F" target="_blank">TechCrunch</a> 所指出，MariaDB 的上市遠未取得巨大成功，從 2022 年底上市首日 4.45 億美元的市值（與之前 D 輪融資時 6.72 億美元的私有企業價值相比，市值本身已大幅下降）跌入常年低谷，自今年年初以來一直徘徊在 1 千萬美元關口附近。</span></p><p><span style="color:#000000">紐約證券交易所曾在 9 月份警告 MariaDB，稱其不符合上市規則 —— 該規則規定公司的全球平均市值在連續 30 天的交易期內不得低於 5000 萬美元。在隨後的幾個月裏，MariaDB 收到了第一份收購要約，來自其現有投資者 Runa Capital，初步報價為每股 0.56 美元現金。三週後，Runa 表示最終不會收購 MariaDB，而是由一家名為 RP Ventures 的公司提供 2650 萬美元的貸款。</span></p><p><span style="color:#000000">今年二月初，MariaDB 宣佈與債權人達成臨時暫緩協議，即在尋求替代融資方案期間，債權人將不行使貸款協議中規定的任何補救措施。這一消息導致 MariaDB 的股價在幾天內上漲了一倍多，這也是為什麼 K1 的出價與宣佈任何暫緩協議前 MariaDB 的收盤價相對應。</span></p><p><span style="color:#000000">事實上，K1 表示，它的報價比 MariaDB 2 月 5 日的收盤價（0.19 美元）高出 189%，相當於市值約為 1290 萬美元。雖然不能保證 K1 會正式競購 MariaDB，但與更像傳統風險投資公司的 Runa Capital 不同，K1 在其 12 年的歷史中擁有後期投資記錄，這使其更接近私募股權投資領域。且 K1 已經進行了多次收購，包括在 2022 年斥資 3.19 億美元收購澳大利亞 ELMO 軟件公司，並在收購過程中將其私有化。</span></p><p><span style="color:#000000">因此，從很多方面來説，K1 可能比 Runa 更適合接管 MariaDB。根據愛爾蘭收購規則第 2.6 條，K1 必須在 2024 年 3 月 29 日下午 5:00（紐約時間）（即 K1 公告後的第 42 天）之前，正式確定其收購要約或完全放棄該計劃。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 02:36:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279540/mariadb-could-be-taken-private-37m-k1</guid>
            <link>https://www.oschina.net/news/279540/mariadb-could-be-taken-private-37m-k1</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[紅帽改變發佈 RHEL Beta 測試版本的更新策略]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>紅帽<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.redhat.com%2Fen%2Fblog%2Fupcoming-improvements-red-hat-enterprise-linux-minor-release-betas" target="_blank">宣佈</a></u>對 RHEL Beta 測試版本的更新策略進行改進。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1c1f35a138e6545bd30f1e3fb14505f82f2.png" referrerpolicy="no-referrer"></p><p>目前 RHEL 新版本正式發佈之前，紅帽大致提供了一個月的測試期。但紅帽及其客户發現，長達一個月的 RHEL 測試期通常太短，意義不大。</p><p>從 RHEL 9.5 開始，<strong>紅帽將開始更早且持續地發佈"beta"軟件包</strong>。在即將發佈的次要版本完成初始測試後，這些軟件包將開始推送到其測試版渠道。<strong>因此，它的測試期長達 4 個月，而不僅僅是 1 個月的週期</strong>。</p><p>但隨着測試期的延長以及每週發佈測​​試包更新，RHEL 次要版本測試版的安裝介質（例如預構建的 ISO 和雲/VM 鏡像）將不再存在。</p><p>此更改僅影響 RHEL 9.5 及更高版本，並將持續到從 RHEL 10.1 開始的點版本。RHEL 8 或更早版本中的點版本更新都不會發生變化。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 02:28:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279538/red-hat-changes-beta-timing</guid>
            <link>https://www.oschina.net/news/279538/red-hat-changes-beta-timing</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
