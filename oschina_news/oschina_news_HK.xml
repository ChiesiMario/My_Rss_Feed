<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 17 Feb 2024 06:17:38 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[谷歌建議舊版 Windows 10 PC 用户遷移到 ChromeOS Flex]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微軟將於 2025 年 10 月 14 日停止為 Windows 10 提供官方支持，由於缺乏免費的安全更新和技術支持，這可能導致消費者和企業的 2.4 億台 PC 被淘汰。</p><p>此外，由於許多運行 Windows 10 系統的設備過於老舊，不滿足運行 Windows 11 的要求，許多用户將不得不向微軟支付延期支持費用或購買新電腦。有些人可能想保留現有機器而不向微軟付費，但這樣做會因缺乏安全更新而帶來危險。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-316aa08dcd289eb3c3a832b2e231a7bd87b.png" referrerpolicy="no-referrer"></p><p>谷歌為這些用户<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tomshardware.com%2Fsoftware%2Foperating-systems%2Fgoogle-proposes-users-of-older-windows-10-pcs-to-migrate-to-chromeos-flex-600-devices-certified" target="_blank">提出</a>瞭解決方案 —— 通過 ChromeOS Flex 提供"自動更新"硬件兼容性。</p><p>ChromeOS 商業產品主管寫道：「微軟 Windows 10 即將進入報廢狀態，這可能會對環境產生重大影響。數百萬台完全能夠運行 Windows 10 但與 Windows 11 不兼容的電腦可能最終被填埋。」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-e30c3cdf91fd4c11ad29cb8337d074e8ef2.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fchrome-enterprise%2F11-ways-you-win-with-chromeos-flex" target="_blank">https://cloud.google.com/blog/products/chrome-enterprise/11-ways-you-win-with-chromeos-flex</a></u></em></p></blockquote><p>因此谷歌建議為搭載 Windows 10 的舊電腦安裝 ChromeOS Flex，從而轉換為雲電腦，以延長其使用壽命。有了 ChromeOS Flex，公司和消費者就可以安裝一個新的操作系統，即使在 Windows 10 於明年年底停止提供安全補丁後，該系統仍會自動更新，提供未來數年的安全補丁。</p><p>谷歌表示 Flex 是專為傳統 PC 硬件設計的 ChromeOS 分支，是 Windows 或 macOS 等傳統操作系統的理想替代品，並列舉了其基於雲的現代操作系統成為 Windows 10 優秀替代品的 11 種方式。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-770d2dc5bed7dfe03e07f3f19937d88ec0d.png" referrerpolicy="no-referrer"></p><p>ChromeOS Flex 非常安全，它具有數據加密、自動更新和應用程序沙箱等功能，可以保護用户免受惡意軟件和其他網絡威脅的侵害。谷歌聲稱，勒索軟件攻擊者從未入侵過這款輕量級操作系統。</p><p>ChromeOS Flex 易於使用，特別是對於熟悉 Chrome 瀏覽器或 Google 工作空間的人來説。該操作系統啓動速度快，不會出現一直困擾 Windows 的運行速度變慢（臃腫）問題，從而提高了工作效率。藉助 Google 管理控制枱，該系統還易於遠程管理。</p><p>ChromeOS Flex 非常"靈活"，經認證可在近 600 種 OEM 品牌設備上運行，這意味着該雲操作系統幾乎可以在企業組織部署的任何設備上運行。</p><p>ChromeOS Flex 可降低 IT 支持和硬件成本，防止 Windows 10 機器成為電子垃圾，而且高效節能。該操作系統適用於大型或小型企業。</p><p>ChromeOS Flex 還支持第三方業務應用程序，至少在基於網絡的服務方面是如此。得益於虛擬應用交付技術，"傳統"Windows 應用程序和微軟 Office 等生產力套件可以從互聯網流式傳輸，實現"無縫"集成。</p><p>然而 ChromeOS 並不是一個特別受歡迎的替代操作系統。根據 StatCounter.com 的數據，截至 2024 年 1 月，ChromeOS 在全球 PC 操作系統市場中僅佔據 1.78% 的份額，遠遠落後於 Windows 佔主導地位的 73% 和 macOS 的 16.11% 市場份額。</p><p>延伸閲讀：<strong><em><u><a href="https://www.oschina.net/news/238374/pirg-chromebook-churn" target="news">電子垃圾 Chromebook</a></u></em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 17 Feb 2024 04:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278904</guid>
            <link>https://www.oschina.net/news/278904</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌發佈 Gemini 1.5，最高支持百萬級 token 上下文]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在推出號稱最強大的<a href="https://www.oschina.net/news/278397/bard-gemini-advanced-app"> Gemini Ultra </a>模型一週後，谷歌今天發佈了擁有最長上下文窗口的下一代大模型<strong>&nbsp;Gemini 1.5&nbsp;</strong>—— 最高支持&nbsp;<span style="font-family:-apple-system,BlinkMacSystemFont,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Segoe UI&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei&quot;,&quot;Helvetica Neue&quot;,Helvetica,Arial,sans-serif">100 萬 token 的上下文長度。</span></p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a51e6f59a5c0b7d4a14179ec0b37415c657.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-gemini-next-generation-model-february-2024" target="_blank">https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024</a></u></em></p></blockquote><p>谷歌首席科學家 Jeff Dean <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FJeffDean%2Fstatus%2F1758146022726041615" target="_blank">表示</a>，Gemini 1.5 的上下文理解能力可支持百萬級 token 的多模態輸入，讓用户能夠使用該模型與數十萬字的超長文檔、擁有數百個文件的數十萬行代碼庫、一部完整的電影等進行交互。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8a4bdc73436da787fcfab9be022109f6e7d.gif" referrerpolicy="no-referrer"></p><p>Gemini 1.5 介紹</p><ol><li>性能提升：Gemini 1.5 在多個維度上展現出顯著的性能提升，特別是在處理長上下文信息的能力上實現了重大突破，可以連續處理高達 100 萬個標記（tokens），擁有迄今為止所有大型基礎模型中最長的上下文窗口。</li><li>高效架構：Gemini 1.5 採用了新的 Mixture-of-Experts（MoE）架構，使模型更高效地進行訓練和服務，同時在維持類似於 1.0 Ultra 模型的質量的同時，減少了計算需求。</li><li>長上下文窗口：這一特點允許 Gemini 1.5 處理並分析大量信息，比如 1 小時的視頻、11 小時的音頻、超過 30,000 行代碼的代碼庫或超過 700,000 字的文本。</li><li>跨模態理解和推理：Gemini 1.5 能夠對不同模態的內容（包括文本、代碼、圖像、音頻和視頻）進行高度複雜的理解和推理，例如，分析 44 分鐘的默片並準確捕捉情節要點和細節。</li><li>增強性能：在文本、代碼、圖像、音頻和視頻評估的綜合面板上測試時，Gemini 1.5 Pro 在用於開發我們的大型語言模型（LLMs）的 87% 的基準測試中表現優於 1.0 Pro，並且與 1.0 Ultra 在同樣的基準測試中表現大致相當。</li></ol><p>Gemini 1.5 技術報告：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstorage.googleapis.com%2Fdeepmind-media%2Fgemini%2Fgemini_v1_5_report.pdf" target="_blank">https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 16 Feb 2024 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278829/google-gemini-1-5-next-generation-model-</guid>
            <link>https://www.oschina.net/news/278829/google-gemini-1-5-next-generation-model-</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 發佈文本生成視頻模型 Sora]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 今天凌晨發佈了其首個視頻生成模型 Sora。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-80cdbef18c0af0f443e5c577f0b8b7d9f0d.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fsora" target="_blank">https://openai.com/sora</a></u></em></p></blockquote><p>Sora 可根據文本描述生成長達 60 秒的視頻，其中包含精細複雜的場景、生動的角色表情以及複雜的鏡頭運動。</p><p><img src="https://oscimg.oschina.net/oscnet/up-76a85f538720e72217484164ce80b7b5532.png" referrerpolicy="no-referrer"></p><p>目前，Sora 已對網絡安全的紅隊成員開放，以評估其可能存在的風險或潛在傷害。同時，OpenAI 也邀請了視覺藝術家、設計師和電影製作人使用 Sora，收集他們的反饋，以使模型更好地服務於創意行業。</p><p>OpenAI 在技術報告介紹道，<strong>他們將 Sora 視頻生成模型視作世界模擬器</strong>。具體來説就是通過跨越不同持續時間、寬高比和分辨率的視頻和圖像，從而生成最高可達一分鐘的高清視頻。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-0710069f6fe95eaeadb0508d60ddd79f7b4.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fresearch%2Fvideo-generation-models-as-world-simulators" target="_blank">https://openai.com/research/video-generation-models-as-world-simulators</a></p></blockquote><p>Sora 使用了一種特殊的深度學習模型（即 Transformer）來處理視頻和圖像數據。這種處理方式首先將視頻和圖像編碼成潛在代碼，然後將這些代碼分解成包含時間和空間信息的小塊（即時空補丁），最後利用 Transformer 模型在這些補丁上進行操作。</p><p>這樣的處理方法能夠有效地捕捉和生成視頻和圖像數據中的複雜時空動態，為生成高質量的視頻和圖像提供了一種強大的方法。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 16 Feb 2024 04:47:35 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278821/openai-text-to-video-sora</guid>
            <link>https://www.oschina.net/news/278821/openai-text-to-video-sora</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[與 F5 產生分歧，核心 Nginx 開發者創建新分支 Freenginx]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作為 Nginx Web 服務器的長期核心開發人員之一，Maxim Dounin&nbsp;宣佈創建該項目的一個新分支，名為 Freenginx。</p><p><img height="203" src="https://oscimg.oschina.net/oscnet/up-000ebc1841ce52b742123227a39fe25f18d.png" width="500" referrerpolicy="no-referrer"></p><p>Maxim Dounin 決定分叉 Nginx 是因為與 F5 發生了分歧，F5 於 2019 年收購了 Nginx 公司。Dounin 在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmailman.nginx.org%2Fpipermail%2Fnginx-devel%2F2024-February%2FK5IC6VYO2PB7N4HRP2FUQIBIBCGP4WAU.html" target="_blank">宣佈 Freenginx</a>&nbsp;時解釋道：</p><blockquote>
 大家可能都知道，F5 於 2022 年關閉了莫斯科辦事處，從那時起我就不再為 F5 工作了。不過，我們已經達成協議，我將繼續作為志願者參與 nginx 開發。近兩年來，我一直致力於改進 nginx，免費為大家提供更好的服務。
 <br><br> 不幸的是，F5 的一些新的非技術管理層最近認為，他們要更瞭解如何運行開源項目。特別是，他們決定干涉 nginx 多年來使用的安全策略，無視策略和開發人員的立場。
 <br><br> 這是可以理解的：他們擁有該項目，並且可以用它做任何事情，包括以營銷為目的，無視開發者的立場和社區。儘管如此，這還是違背了我們的協議。更重要的是，我再也無法控制 F5 內部對 nginx 的修改，也不再將 nginx 視為一個為公眾利益而開發和維護的免費開源項目。
 <br><br> 因此，從今天起，我將不再參與由 F5 負責的 nginx 開發。取而代之的是，我將啓動另一個項目，由開發人員而非公司實體來運行：
 <br><br><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffreenginx.org%2F" target="_blank">http://freenginx.org/</a><br><br> 我們的目標是使 nginx 開發免受任意公司行為的影響。歡迎提供幫助和貢獻。希望大家都能從中受益。&nbsp;
</blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 16 Feb 2024 04:33:35 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278819/nginx-forked-freenginx</guid>
            <link>https://www.oschina.net/news/278819/nginx-forked-freenginx</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 稱 AI 潛在風險會讓人「徹夜難眠」，呼籲建立國際機構監督 AI 發展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#252a2d; margin-left:0; margin-right:0; text-align:justify">2 月 14 日消息，當地時間週二，OpenAI CEO 阿爾特曼在迪拜舉行的世界政府峯會上通過視頻電話致辭，其呼籲建立一個國際性的機構（類似國際原子能機構）來監督 AI 發展。</p><p style="color:#252a2d; margin-left:0; margin-right:0; text-align:justify">「我經常以國際原子能機構為例，將其作為處理最強大人工智能系統影響的典範。在部署超級智能或通用人工智能（注：AGI）之前，建立審計和安全措施至關重要。」</p><p style="color:#252a2d; margin-left:0; margin-right:0; text-align:justify">阿爾特曼還提到，一個非常微妙的「社會失衡」就能給 AI 系統帶來嚴重破壞，自己曾為此徹夜難眠。「我對機器人在街上行走的想法不太感興趣，我更關心非常微妙的社會失衡，即在社會中擁有這些系統，沒有特別的邪惡意圖，事情卻出了大問題。」</p><p style="color:#252a2d; margin-left:0; margin-right:0; text-align:justify">然而他還強調，OpenAI 公司這樣的人工智能行業不應在制定管理涉及 AI 行業的法規時處於領先地位。「我認為我們仍處於需要進行健康辯論的階段。」</p><p style="color:#252a2d; margin-left:0; margin-right:0; text-align:justify">他認為，AI 將會廣泛普及，且價格低廉，成為人類「創造未來的工具」。但與此同時，AI 的全面進步和發展仍需要時間與耐心，「就像手機從原始的移動電話發展到如今的 iPhone 一樣。」</p><p style="color:#252a2d; margin-left:0; margin-right:0; text-align:justify">此外，阿爾特曼還稱當前的世界仍處於 AI 早期階段，「我們從未見過世界發生很大的變化，我認為原因在於我們目前擁有的技術就像黑白電視一樣，還有很長的路要走。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 15 Feb 2024 12:25:31 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278781</guid>
            <link>https://www.oschina.net/news/278781</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲計算 - 負載均衡 SLB 方案全解與實戰]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>雲計算 - 負載均衡 SLB 方案全解與實戰，介紹 SLB 的核心技術、用户最佳實踐、阿里雲 SLB 產品舉例、應用場景。</p></blockquote><blockquote><p>關注【TechLeadCloud】，分享互聯網架構、雲服務技術的全維度知識。作者擁有 10+年互聯網服務架構、AI 產品研發經驗、團隊管理經驗，同濟本復旦碩，復旦機器人智能實驗室成員，阿里雲認證的資深架構師，項目管理專業人士，上億營收 AI 產品研發負責人。</p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-5da5d794e329cfd040f4842da9b8aae7da2.png" alt="file" referrerpolicy="no-referrer"></p><h1>一、引言</h1><p>雲計算作為現代信息技術的基石，正在以前所未有的速度推動着各行各業的數字化進程。其中，負載均衡（Server Load Balancer, SLB）技術是保證雲服務高效、穩定運行的重要組成部分。它通過分配網絡或應用流量到多個服務器，確保了服務的高可用性和高性能。在本篇引言中，我們將探討雲計算與負載均衡的關係以及 SLB 的重要性，並通過實際的例子來揭示其背後的技術原理。</p><h2>雲計算與負載均衡的關係</h2><p>雲計算提供了一種靈活、可擴展的服務運行環境，使得企業和開發者能夠快速響應市場變化，優化資源配置。而負載均衡技術在其中起到了至關重要的作用。</p><p>例如，假設一個電子商務網站在黑色星期五這一天迎來了巨大的流量激增。如果沒有負載均衡技術，單一的服務器可能會因為超負荷而崩潰，導致用户無法訪問網站，從而造成嚴重的經濟損失。而有了負載均衡技術，網絡流量會被均勻分配到多個服務器上，確保每個服務器的負載都保持在一個可接受的範圍內，從而保證了網站的正常運行和用户的訪問體驗。</p><h2>SLB 的重要性</h2><p>SLB 作為負載均衡技術在雲計算環境中的具體實現，它不僅能夠保證服務的高可用性，還能通過優化資源分配，提升服務的響應速度和處理能力。</p><p>以一個在線視頻平台為例，平台需要保證無論用户數量多少，視頻的播放都要流暢無卡頓。通過 SLB，平台可以將用户的請求分配到不同的服務器上，確保每個服務器的負載都在可控範圍內，從而為用户提供高質量的觀看體驗。同時，當某個服務器發生故障時，SLB 能夠自動將流量重新分配到其他健康的服務器上，保證了服務的持續可用。</p><p>通過以上兩個實際的例子，我們可以看到負載均衡技術和 SLB 在雲計算環境中的重要作用。它們為企業和開發者提供了強大的工具，以應對網絡流量的波動和系統負載的變化，是實現高效、穩定雲服務的關鍵。</p><hr><h1>二、SLB 核心技術解析</h1><p>Server Load Balancer (SLB) 是一種負載均衡技術，它在雲計算環境中扮演着至關重要的角色。通過 SLB，可以將網絡流量和請求有效地分配到多個服務器上，從而保證了應用的高可用性和高性能。在本節中，我們將深入解析 SLB 的核心技術，包括負載均衡算法、會話保持技術以及健康檢查。</p><h2>2.1 負載均衡算法</h2><p>負載均衡算法是 SLB 的核心，它決定了如何將流量分配到不同的服務器上。常見的負載均衡算法有輪詢法、最少連接法和 IP Hash 法。</p><h3>2.1.1 輪詢法</h3><p>輪詢法是最簡單也最直接的負載均衡算法，它將每個新的請求按照順序分配到服務器列表中的服務器上。</p><p>例如，假設有三個服務器 A、B 和 C，輪詢法會依次將請求分配給 A、B、C、A、B、C，如此循環。這種方法簡單公平，但可能不適用於服務器性能不均的場景。</p><h3>2.1.2 最少連接法</h3><p>最少連接法是一種動態的負載均衡算法，它會將新的請求分配給當前連接數最少的服務器。</p><p>舉例來説，假設在一個購物網站的高峯期，服務器 A 已經有 30 個連接，而服務器 B 只有 10 個連接，最少連接法會將新的請求分配給服務器 B，從而儘量保持服務器之間的負載均衡。</p><h3>2.1.3 IP Hash 法</h3><p>IP Hash 法根據客户端的 IP 地址計算一個哈希值，然後根據哈希值將請求分配給特定的服務器。</p><p>這種方法能夠保證來自同一 IP 的請求總是被分配到同一個服務器，有助於保持會話的一致性。例如，在一個在線遊戲場景中，玩家的所有請求需要被髮送到同一個服務器以保證遊戲狀態的一致。</p><h2>2.2 會話保持技術</h2><p>會話保持是負載均衡中的另一個重要概念，它能保證一個用户的多個請求被髮送到同一個服務器。</p><h3>2.2.1 Cookie 保持</h3><p>通過在 HTTP 響應中設置特定的 Cookie，SLB 可以識別來自同一用户的請求，並將它們路由到同一服務器。這對於保持用户登錄狀態和購物車信息等非常重要。</p><h3>2.2.2 IP 綁定</h3><p>IP 綁定是另一種會話保持技術，它根據用户的 IP 地址將所有請求路由到同一服務器。與 IP Hash 法類似，這種方法適用於需要保持會話狀態的應用。</p><h2>2.3 健康檢查</h2><p>健康檢查是 SLB 中用於監控服務器狀態的機制。通過定期檢查服務器的響應，SLB 能夠判斷服務器是否健康，從而確保流量只被路由到健康的服務器。</p><h3>2.3.1 TCP 健康檢查</h3><p>通過發送 TCP 探測包來檢查服務器的可達性和響應時間，是判斷服務器健康狀態的一種簡單有效的方法。</p><h3>2.3.2 HTTP 健康檢查</h3><p>HTTP 健康檢查則通過發送 HTTP 請求，並檢查 HTTP 響應的狀態碼和內容，來判斷服務器的健康狀態。</p><p>例如，在一個在線訂餐平台中，通過 HTTP 健康檢查，SLB 能夠實時監控每個服務器的狀態，一旦發現某個服務器的響應時間超過預設的閾值或返回錯誤碼，SLB 會將該服務器標記為不健康，從而避免用户請求被路由到出現問題的服務器，保證了服務的高可用性和用户體驗。</p><p>通過以上深入的技術解析和實際例子，我們可以更清晰地理解 SLB 的核心技術和其在雲計算環境中的重要作用。</p><hr><h1>三、SLB 用户最佳實踐</h1><p>在實際的雲計算環境中，有效地使用 Server Load Balancer (SLB) 是確保應用高可用性和高性能的關鍵。本節將為讀者展示一些 SLB 的用户最佳實踐，包括 SLB 的配置和優化，以及如何應對常見的問題和挑戰。</p><h2>3.1 部署與配置 SLB</h2><p>部署和配置 SLB 是最基本也是最重要的步驟。正確的配置能確保流量得到有效分配，同時保證應用的穩定運行。</p><h3>3.1.1 選擇合適的負載均衡算法</h3><p>不同的負載均衡算法適用於不同的場景。例如，對於請求處理時間相對固定的應用，輪詢法可能是一個合適的選擇。而對於處理時間波動較大的應用，最少連接法可能更為合適。</p><p>舉例來説，在一個在線視頻處理服務中，由於視頻文件大小和編碼複雜度的不同，處理時間可能會有很大的波動。在這種情況下，最少連接法能夠保證新的請求更可能被分配到當前負載較低的服務器，從而實現更好的負載均衡。</p><h3>3.1.2 設置合理的會話保持</h3><p>會話保持對於需要保持用户狀態的應用非常重要。通過配置合理的會話保持，可以確保用户的連續請求被髮送到同一服務器，從而保持應用的狀態一致。</p><p>例如，在一個在線購物平台中，用户的購物車信息需要在多個請求之間保持一致。通過使用 Cookie 保持或 IP 綁定，可以保證用户的所有請求都被路由到同一服務器，從而保持購物車狀態的一致。</p><h2>3.2 優化 SLB 性能</h2><p>SLB 的性能直接影響到應用的響應時間和用户體驗。通過一些優化措施，可以進一步提升 SLB 的性能。</p><h3>3.2.1 調優負載均衡算法</h3><p>根據應用的實際負載和服務器性能，調整負載均衡算法的參數，以實現更好的負載均衡效果。</p><h3>3.2.2 優化健康檢查配置</h3><p>合理的健康檢查配置能夠及時發現服務器的故障，同時避免對服務器造成額外的負擔。例如，可以通過調整健康檢查的間隔和超時時間，來平衡健康檢查的準確性和資源消耗。</p><h3>3.2.3 使用高效的會話保持機制</h3><p>選擇高效的會話保持機制，如使用 Cookie 保持而非 IP 綁定，可以減少服務器的負擔，同時保證應用的狀態一致。</p><h2>3.3 處理常見問題</h2><p>在實際使用 SLB 時，可能會遇到一些常見的問題和挑戰，如服務器故障、流量激增等。通過一些預防和應對措施，可以減少這些問題對應用的影響。</p><p>例如，在遭遇流量激增時，可以通過預先擴展服務器資源，或使用自動擴展功能，來應對可能的服務器超負荷問題。同時，通過合理的流量控制和優先級設置，可以保證關鍵服務的可用性和性能。</p><p>通過以上的最佳實踐，用户可以更有效地利用 SLB，提升雲應用的可用性和性能，同時應對實際運營中可能遇到的各種問題和挑戰。</p><hr><h1>四、阿里雲 SLB 多種規格舉例</h1><p><img src="https://oscimg.oschina.net/oscnet/up-135c5f9e2fa4270648b02351e71d04ee5c3.png" alt="file" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-c06ba677661c1157b2788ebccc51ee7db6a.png" alt="file" referrerpolicy="no-referrer"></p><hr><h1>五、應用場景</h1><p><img src="https://oscimg.oschina.net/oscnet/up-0d9060a5c0eb4b3aee77921b3593c4ea83a.png" alt="file" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-dfbf500e869785bf734a386e1c86320519a.png" alt="file" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-0ed01d7e27b70bcbab145e0edc7289156e0.png" alt="file" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-de11d78c80025ba2523ce4fd2201169dfbb.png" alt="file" referrerpolicy="no-referrer"></p><blockquote><p>關注【TechLeadCloud】，分享互聯網架構、雲服務技術的全維度知識。作者擁有 10+年互聯網服務架構、AI 產品研發經驗、團隊管理經驗，同濟本復旦碩，復旦機器人智能實驗室成員，阿里雲認證的資深架構師，項目管理專業人士，上億營收 AI 產品研發負責人。 如有幫助，請多關注 TeahLead KrisChang，10+年的互聯網和人工智能從業經驗，10 年+技術和業務團隊管理經驗，同濟軟件工程本科，復旦工程管理碩士，阿里雲認證雲服務資深架構師，上億營收 AI 產品業務負責人。</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 15 Feb 2024 12:22:31 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6723965/blog/11043804</guid>
            <link>https://my.oschina.net/u/6723965/blog/11043804</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為工程師提交 Linux 內核補丁——添加「沙盒模式」 (SBM)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>華為工程師 Petr Tesarik 向 Linux 內核提交了添加「沙盒模式」(SandBox Mode, SBM) 的新補丁——用於提升內存安全性。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-69b0075c015343103fb4626bc5e726f044c.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20240214113035.2117-1-petrtesarik%40huaweicloud.com%2F" target="_blank">https://lore.kernel.org/lkml/20240214113035.2117-1-petrtesarik@huaweicloud.com/</a></u></em></p></blockquote><p>Petr Tesarik 在郵件寫道：</p><blockquote><p>沙盒模式的最終目標是<strong>在只允許訪問預定義地址內存的環境中執行本地內核代碼</strong>，因此潛在漏洞無法被利用，或不會對內核的其他部分產生影響。</p><p>該補丁為內核添加了沙盒模式的 API 和獨立於操作系統的基礎架構。它在所有輸入和輸出數據的 vmalloc() 副本上運行目標函數。由於有了保護頁，僅此一項就能防止一些越界訪問。</p></blockquote><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20240214113035.2117-6-petrtesarik%40huaweicloud.com%2F" target="_blank">根據文檔的描述</a></u>，沙盒模式的主要目標是通過分解內核來減少內核代碼中潛在內存安全錯誤的影響。SBM API 支持在隔離的執行環境中運行每個組件，特別是用作輸入的內存區域和 / 或輸出與內核的其餘部分隔離，並被保護頁包圍。</p><p>在實現必要的 arch hook 的架構上，沙盒模式利用硬件分頁設施和 CPU 特權級別來強制僅使用這些預定義的內存區域。有了 arch 的支持，SBM 還可以從 protection violation 進行恢復。這意味着 SBM 可強制終止沙盒，並向調用者返回錯誤代碼（例如<code>-EFAULT</code>），以便執行可以繼續。這種實現提供了強隔離機制。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 15 Feb 2024 11:29:58 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278775</guid>
            <link>https://www.oschina.net/news/278775</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[更穩定、更便捷、更 AI 的編程語言 — 洛書 24.1.4 階段版本發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>更穩定、更便捷、更 AI 的編程語言 — 洛書 24.1.4 階段版本發佈</h1><p><span style="background-color:#fdfdfe; color:#05073b">洛書開發團隊很高興地宣佈，最新的 24.1.4 階段版本正式發佈。本次更新彙集了上一階段版本以來近 4 個月的開發成果，致力於提升語言效率、優化用户體驗，並引入了一系列新功能與改進。</span></p><h2>問題與修復&nbsp;</h2><ol><li><p style="margin-left:0; margin-right:0">修復了一些偶發性的編譯錯誤和運行時異常。</p></li><li><p style="margin-left:0; margin-right:0">修復了 class 構造函數的行為異常問題。</p></li><li><p style="margin-left:0; margin-right:0">修復 API 中部分函數行為異常問題。</p></li><li><p style="margin-left:0; margin-right:0">修復 GC 在 Windows 下內存泄漏的異常</p></li></ol><h2>更新與優化</h2><h3>速度與穩定性優化</h3><ol><li>字符串儲存結構更新，統一 byte 與 string 數據類型的儲存模式&nbsp;</li><li>取消 32 位字節碼模式下的內存保護運算，該功能在 16 位模式下得到保留</li><li>更新多線程模型，放棄常見的 GIL 解決方案，初步支持 Actor 模型</li></ol><h3>模塊與拓展優化</h3><ol><li>模塊管理器第一階段所有功能開發基本完成，這包括：安裝、卸載、查找、升級、搜索、獲取文檔、獲取源代碼、模塊配置、膠水代碼生成、批量更新、批量卸載、版本更新等多種功能</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flosu.tech%2Fstudio" target="_blank">在線服務站點</a>初步搭建完成，可視化的模塊管理操作。</li><li>自動集成部署工具上線，自動化構建與打包。正式改用，時間關聯的版本號規則</li></ol><h3>AI 編碼體驗優化</h3><p><span style="background-color:#fdfdfe; color:#05073b">AI 代碼助手作為一種智能化的編程輔助工具，可以極大地提升編程效率和代碼質量，降低編程門檻。這種工具的出現，為國產編程語言的發展提供了有力的支持。AI 編碼體驗已經被洛書開發團隊視作編程語言使用體驗的重要一環。</span></p><p><span style="background-color:#fdfdfe; color:#05073b">洛書已經可以與現有的部分代碼助手結合使用，為用户提供便捷、高效、多選擇的 AI 編碼體驗。包括，自動補全、代碼註釋、代碼解釋、跨語言翻譯等多種功能。</span></p><p><span style="background-color:#fdfdfe; color:#05073b">同時，AI 編程助手則的智能化輔助與洛書的中文代碼拓展結合，提供更加貼近中文用户的思維方式和表達習慣的編程體驗，新手可以</span><span style="background-color:#fdfdfe; color:#05073b">更輕鬆地學習和掌握洛書。</span></p><p><u><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1kZ421U78U%2F%3Fvd_source%3D3551aa6dd84c8edd774341fc07a29cdc" target="_blank">演示視頻</a></strong></u></p><p><img height="1056" src="https://oscimg.oschina.net/oscnet/up-e1fbe8c5ae780d427aff8987b64127e2b93.png" width="1259" referrerpolicy="no-referrer"></p><pre><code>針對部分反饋信息，我們採取了相應的優化方案。
1. 保持 23.10 版本以來的類 python 關鍵詞設計。
2. 新增數箇中文關鍵詞，增加中文關鍵詞拓展與編譯器核心間的解耦機制。
3. 新增等效關鍵詞概念（僅限中文拓展）</code></pre><ol></ol><h2>兼容性説明</h2><p>我們提供了適用於 amd64 架構下的 Windows 與 Linux 的二進制文件，包括： Windows 10、Windows 11、Ubuntu 18.04.6 LTS + 、UOS/Deepin、Openkylin 等操作系統</p><p>Ubuntu amd64 版本構建環境</p><pre><code>Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 7.5.0-3ubuntu1~18.04' --with-bugurl=file:///usr/share/doc/gcc-7/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-7 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)

ldd (Ubuntu GLIBC 2.27-3ubuntu1.6) 2.27
Copyright (C) 2018 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
Written by Roland McGrath and Ulrich Drepper.</code></pre><p>Windows x64 版本構建環境</p><pre><code>Using built-in specs.
COLLECT_GCC=x86_64-w64-mingw32-gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-w64-mingw32/7.3-win32/lto-wrapper
Target: x86_64-w64-mingw32
Configured with: ../../src/configure --build=x86_64-linux-gnu --prefix=/usr --includedir='/usr/include' --mandir='/usr/share/man' --infodir='/usr/share/info' --sysconfdir=/etc --localstatedir=/var --disable-silent-rules --libdir='/usr/lib/x86_64-linux-gnu' --libexecdir='/usr/lib/x86_64-linux-gnu' --disable-maintainer-mode --disable-dependency-tracking --prefix=/usr --enable-shared --enable-static --disable-multilib --with-system-zlib --libexecdir=/usr/lib --without-included-gettext --libdir=/usr/lib --enable-libstdcxx-time=yes --with-tune=generic --with-headers=/usr/x86_64-w64-mingw32/include --enable-version-specific-runtime-libs --enable-fully-dynamic-string --enable-libgomp --enable-languages=c,c++,fortran,objc,obj-c++,ada --enable-lto --with-plugin-ld --enable-threads=win32 --program-suffix=-win32 --program-prefix=x86_64-w64-mingw32- --target=x86_64-w64-mingw32 --with-as=/usr/bin/x86_64-w64-mingw32-as --with-ld=/usr/bin/x86_64-w64-mingw32-ld --enable-libatomic --enable-libstdcxx-filesystem-ts=yes
Thread model: win32
gcc version 7.3-win32 20180312 (GCC)</code></pre><p>如果您有高版本工具鏈的構建需求，可以參考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flosu.tech%2Fwiki" target="_blank">相關文檔</a>自行編譯</p><p><img height="1349" src="https://oscimg.oschina.net/oscnet/up-e7d0f47712f7374ea8524067a5ef39bd491.png" width="2466" referrerpolicy="no-referrer"></p><h2>致謝</h2><p style="color:#05073b; margin-left:0; margin-right:0; text-align:start">感謝所有洛書的關注者一直以來的支持和反饋。我們珍視每一條用户意見，並將其作為改進的動力。如果您在使用洛書過程中遇到任何問題或有任何建議，請隨時與我們聯繫。</p><p style="color:#05073b; margin-left:0; margin-right:0; text-align:start">期待與您共同見證洛書的成長與進步！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 15 Feb 2024 07:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278754/luoshu-24-1-4-released</guid>
            <link>https://www.oschina.net/news/278754/luoshu-24-1-4-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mozilla 裁員 60 人，提升 Firefox Mobile 優先級]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">在任命 Laura Chambers 擔任臨時 CEO 不到一週後，Mozilla 宣佈裁員約 60 人並縮減多項產品的投資。</p><p style="color:#000000; text-align:start">Mozilla 將縮減 VPN、Relay 和 Online Footprint Scrubber 等的投資，關閉 2018 年推出的 3D 虛擬世界 Hubs，縮減對 Mastodon 實例 mozilla.social 的投資。和今天的很多科技公司類似，Mozilla 將專注於將可信賴的 AI 引入到 Firefox。</p><p style="color:#000000; text-align:start">Mozilla 在一份聲明中寫道：「我們正在縮減對某些產品的投資，以便將重點放在我們認為最有可能取得成功的領域。我們打算將資源重新優先用於 Firefox Mobile 等產品，因為這些產品有很大的發展機會，並能為業界建立更好的模式。」</p><p style="color:#000000; text-align:start">相關鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F13%2Fmozilla-downsizes-as-it-refocuses-on-firefox-and-ai-read-the-memo%2F" target="_blank">https://techcrunch.com/2024/02/13/mozilla-downsizes-as-it-refocuses-on-firefox-and-ai-read-the-memo</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 15 Feb 2024 02:24:18 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278738/firefox-maker-mozilla-cutting-60</guid>
            <link>https://www.oschina.net/news/278738/firefox-maker-mozilla-cutting-60</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[凹語言發佈 v0.9.1，支持 P5 兒童編程]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><hr><p style="margin-left:0; margin-right:0">凹語言設計的目標之一是簡單易用。但是對於新接觸編程的兒童教學來説依然有一定的門檻。為此開發組嘗試將面向創意編程的<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprocessing.org%2F" target="_blank">Processing</a><span>&nbsp;</span>理念引入凹語言，通過<span>&nbsp;</span><code>js/p5</code><span>&nbsp;</span>包可以輕鬆實現一些簡單的互動創意設計。</p><p style="margin-left:0; margin-right:0">下面是來自杭州一小學三年級小學生的第一個凹語言程序：</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://wa-lang.org/st0037-01.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">通過 VS Code 將以上的程序輸入電腦，編譯並執行的效果如下：</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://wa-lang.org/st0037-02.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">程序本身也非常簡單：首先通過<span>&nbsp;</span><code>import</code><span>&nbsp;</span>引入 P5 包；然後在<span>&nbsp;</span><code>init</code><span>&nbsp;</span>初始化一個長寬都是 400 的畫布並設置一個灰色背景色；<code>Draw</code><span>&nbsp;</span>函數負責每一幀的繪製，根據鼠標是否按下繪製不同大小的圓形。</p><p style="margin-left:0; margin-right:0">下面是杭州一小學二年級的小學生通過一個繪製線段的程序互動的效果：</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://wa-lang.org/st0037-03.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">目前<span>&nbsp;</span><code>js/p5</code><span>&nbsp;</span>包的功能還有限，我們會在小朋友學習的過程中逐步完善。希望未來每個中國的小學生都能通過我國的編程語言入門並進行日常開發。</p></div></div><div><div>
  &nbsp;
 </div></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 14 Feb 2024 09:21:14 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278688/walang-0-9-1-released</guid>
            <link>https://www.oschina.net/news/278688/walang-0-9-1-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[.NET 9 首個預覽版發佈 —— 打造面向雲原生 & AI 的開發平台]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微軟 .NET 團隊今天重磅推出 .NET 9 首個預覽版，並強調稱該版本重點關注<strong>針對雲原生和人工智能領域的應用程序開發</strong>。當然也會在<strong>性能、生產力和安全性</strong>方面投入大量資源。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fa16ed25472b80c577b0fd4589fe48a2320.png" referrerpolicy="no-referrer"></p><p>微軟稱他們希望<strong>將 .NET 9 打造成雲原生開發平台和工具</strong>。在過去的幾年裏，.NET 一直在構建強大的雲原生基礎設施，例如運行時性能和應用程序監控。</p><p>新版本繼續往該方向前進，並將重點轉向<strong>為流行的生產基礎設施和服務提供便捷的使用方式</strong>，例如在 Kubernetes 中運行 .NET，以及使用託管的數據庫和緩存服務（如 Redis）。微軟將在 .NET 技術棧的多個層面提供這些改進。所有這些功能都會與 .NET Aspire 結合，從而降低構建雲應用程序的成本和複雜性，縮短從開發到上線至生產環境的時間。</p><p>在 .NET 8 中，微軟針對修剪和 AOT 優化了 Web API 應用程序（使用<code>webapiaot</code>模板）。在 .NET 9 中，他們正在積極對其他應用程序類型執行相同的操作，並改進所有 ASP.NET Core 應用程序的 DATAS GC。</p><p>除了雲原生，.NET 9 的另一個重點是讓 .NET 開發者更輕鬆地將人工智能集成到他們現有的和新的應用程序中。因此開發者可在 .NET 9 便捷地訪問用於使用 OpenAI 和 OSS 模型的優秀庫和文檔。微軟會繼續在 Semantic Kernel、OpenAI 和 Azure SDK 上開展合作，以確保 .NET 開發者在構建 AI 應用程序時獲得優秀的開發體驗。</p><p>詳情查看：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdotnet%2Fcore%2Fdiscussions%2F9167" target="_blank">https://github.com/dotnet/core/discussions/9167</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Four-vision-for-dotnet-9%2F" target="_blank">https://devblogs.microsoft.com/dotnet/our-vision-for-dotnet-9/</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 14 Feb 2024 07:04:41 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278672/dotnet-9-preview1</guid>
            <link>https://www.oschina.net/news/278672/dotnet-9-preview1</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FreeBSD 計劃停止支持 32 位架構]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>FreeBSD 宣佈了停止支持 32 位架構的未來計劃：</p><ul><li><strong>FreeBSD 15.0 將不包含 armv6、i386 和 powerpc 架構</strong></li><li><strong>FreeBSD 16.0 將不包含 armv7 架構</strong></li><li><strong>v16 分支至少會一直支持在 64 位內核執行 32 位二進制文件</strong></li></ul><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-b964dcee9fc7b5c4fb099529ab79248effc.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.freebsd.org%2Farchives%2Ffreebsd-announce%2F2024-February%2F000117.html" target="_blank">https://lists.freebsd.org/archives/freebsd-announce/2024-February/000117.html</a></u></em></p></blockquote><p>FreeBSD 開發者&nbsp;<span>John Baldwin 稱</span>此舉是為了整合資源，他認為 32 位硬件平台正處於「市場衰退期」，而且積極支持 32 位硬件平台的開發人員也越來越少。只有在有需求並承諾增加開發者資源的情況下，FreeBSD 才會考慮延長對 32 位架構的支持。</p><p>除了逐漸停止支持現有的 32 位架構，FreeBSD 不會引入新的 32 位架構如 32 位 RISC-V。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 14 Feb 2024 05:49:06 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278661</guid>
            <link>https://www.oschina.net/news/278661</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 創始研究員 Andrej Karpathy 離職]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 創始團隊成員之一 Andrej Karpathy 宣佈已從 OpenAI 離職。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2c452527d22668eb17cf65b15fdc8cf9247.png" referrerpolicy="no-referrer"></p><p>Andrej Karpathy 在社交平台寫道：</p><blockquote><p>大家好，確實，我在昨天離開了 OpenAI。首先要説明的是，這並不是因為任何特別的事件、問題或是爭議所導致的（不過，那些陰謀論真的挺有趣的，繼續來吧:）。實際上，過去大約一年在 OpenAI 的經歷非常美好——團隊非常出色，同事們都非常友好，而且我們的發展藍圖充滿了激動人心的前景，我相信我們都有很多值得期待的事情。我目前打算專注於我的個人項目，看看未來會有什麼樣的發展。那些一直關注我的朋友，可能對我接下來可能會做什麼有一定的預期;) 敬請期待吧!</p><p><img src="https://oscimg.oschina.net/oscnet/up-45bb33268b7e3fcf856d0246233225ec689.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fkarpathy%2Fstatus%2F1757600075281547344" target="_blank">https://twitter.com/karpathy/status/1757600075281547344</a></u></em></p></blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fopenai-researcher-andrej-karpathy-departs" target="_blank">據 Information 獨家報道稱</a>，Karpathy 正開發一個全新的「AI 助手」，而且與 OpenAI 的研究主管 Bob McGrew 保持着密切合作。</p><p>Karpathy 曾在特斯拉擔任 AI 高級總監、自動駕駛負責人，並於 2022 年 7 月宣佈離職。在特斯拉任職期間，Karpathy 主要負責 Autopilot 半自動駕駛軟件的研發工作。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 14 Feb 2024 05:10:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278657</guid>
            <link>https://www.oschina.net/news/278657</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Strimzi 加入 CNCF 孵化器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CNCF 技術監督委員會（TOC）投票接受 Strimzi 作為 CNCF 孵化項目。</p><p>Strimzi 專注於在 Kubernetes 上部署和運行 Apache Kafka 集羣。Apache Kafka 是構建基於事件的微服務架構和實時數據流水線的領先平台，它在設計上具有水平可擴展性和容錯性。在 Kubernetes 上運行 Apache Kafka 可能會很複雜，但是 Strimzi 通過使用操作器（operator）模式來減少複雜性。這包括初始安裝以及升級和安全性的日常操作。</p><p>Strimzi 由 Red Hat 於 2017 年開發，並於 2019 年 8 月進入 CNCF 沙箱。該項目現在擁有來自 180 多個組織的 1600 多名貢獻者，並有 15 個公開<strong>採用者</strong>在生產環境中使用 Strimzi，其中包括 Axual、Atruvia、Decathlon、LittleHorse 和 SBB 等。</p><p>「Strimzi 在使 Kafka 在 Kubernetes 上安裝和管理方面做得非常出色。該項目已經發展到獲得了眾多生產用户的信任的程度。圍繞它的社區不斷壯大，並建立了處理這一增長的流程。我很高興看到 Strimzi 進入孵化級別。」 - Matt Farina，Strimzi TOC 贊助人</p><p>「我感到非常謙卑，也為我們所創造的東西為如此多的人服務而感到自豪，我認為 Strimzi 有着光明的未來。數據流架構和 Apache Kafka 的採用率仍在以非常顯著的速度增長。我們能夠降低這些技術的運營成本和負擔，越多的人和組織將能夠從中受益。實現這一願景還有很多工作要做，但是通過 Strimzi 成為 CNCF 孵化器的一部分，我對我們能夠擴大用户羣體、貢獻者羣體以及維護者羣體的前景非常樂觀。」 - Tom Bentley，Strimzi 項目創始人和維護者</p><p>「在 Kubernetes 上運行 Apache Kafka 集羣並不容易，但是自成立以來，Strimzi 一直在這個領域扮演着改變者的角色。通過利用基於操作器的方法來處理日常操作負擔的機會，再加上使用自定義資源利用 Kubernetes 的聲明性特性，這一方法得到了廣泛的認可。與用户一起，Strimzi 多年來不斷髮展，增加了新功能、改進和錯誤修復，使其穩定並適用於生產環境。社區始終是一個成功的開源項目的核心，而 Strimzi 有一個非常積極參與的社區。我非常自豪 Strimzi 被接受為 CNCF 孵化項目，因為這將使更多的人能夠信任它，並看到它在在雲原生環境中開發生產級數據和事件流架構方面所帶來的機會。」 - Paolo Patierno，Strimzi 項目創始人和維護者。</p><p><strong>主要組件：</strong></p><p>Strimzi 提供了三種不同的操作器：</p><ul><li><p>集羣操作器負責通過啓動具有所需配置的代理器來部署 Apache Kafka 集羣。它還負責在需要時逐個滾動代理器來處理任何 Apache Kafka 版本升級。它還支持其他操作數，如 Kafka Connect、Mirror Maker 2 等。</p></li><li><p>主題操作器負責處理主題，允許用户使用 KafkaTopic 自定義資源創建、更新和刪除主題。</p></li><li><p>用户操作器負責處理集羣用户和相關 ACL（在主題上定義權限）的操作，使用 KafkaUser 自定義資源進行操作。</p></li><li><p>其他附加組件提供了在 Kafka 中支持 OAuth 2.0 協議的功能，與 Kafka 集羣進行基於 HTTP 的交互的端點，並通過 ConfigMap 或環境變量進行配置。</p></li></ul><p><strong>Strimzi 的重要里程碑：</strong></p><ul><li><p>4,200+ GitHub 星星</p></li><li><p>5,300+ 拉取請求</p></li><li><p>2,300+ 問題</p></li><li><p>230+ 貢獻者</p></li><li><p>131 個發佈版本</p></li><li><p>15 個公開生產用户</p></li><li><p>2800+位於#strimzi CNCF Slack 頻道的用户</p></li></ul><p>由於使 Apache Kafka 在 Kubernetes 上以「雲原生」方式運行的能力，Strimzi 與其他 CNCF 項目集成，包括 Prometheus、OpenTelemetry、KeyCloak、OPA、Helm 等。</p><p>Strimzi 不斷增加新功能和功能，包括：</p><ul><li><p>完全支持基於 KRaft 的 Apache Kafka 集羣，並刪除了對 ZooKeeper 的依賴，還允許用户輕鬆從 ZooKeeper 遷移到 KRaft 模式。</p></li><li><p>更好地支持 Kafka 代理器的自動擴展。</p></li><li><p>更好地與諸如 cert-manager 之類的 TLS 證書管理工具集成。</p></li><li><p>在多個 Kubernetes 集羣上運行延展的 Kafka 集羣。</p></li><li><p>發佈 Strimzi 1.0 版本。</p></li></ul><p>Strimzi 社區還宣佈了<strong>StrimziCon</strong>，這是一個為開發人員、DevOps 工程師和解決方案架構師舉辦的活動，旨在瞭解 Strimzi 和事件流。虛擬會議將於 5 月 22 日舉行，<strong>論文徵集</strong>截止日期為 3 月 10 日。</p><p>作為 CNCF 託管的項目，Strimzi 是一個與其技術利益一致的中立基金會的一部分，同時也是更大的 Linux 基金會的一部分，後者提供治理、市場支持和社區外展工作。有關每個級別的成熟度要求的更多信息，可訪問<strong>CNCF 畢業標準</strong>頁面。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 14 Feb 2024 03:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278648</guid>
            <link>https://www.oschina.net/news/278648</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟電腦管家慎用：被指會拖慢 PC 電腦速度]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>國內各類電腦管家、安全衞士見多了，連微軟也開發了類似的軟件——微軟電腦管家。</p><p>從功能上來講，這款軟件也可以實現諸如一鍵為系統加速、清理緩存及磁盤空間、攔截彈窗廣告、病毒查殺等功能。</p><p><img height="202" src="https://oscimg.oschina.net/oscnet/up-f5f170b353c163cbc8f58503698f7eb2a04.png" width="500" referrerpolicy="no-referrer"></p><p>不過就有外媒 Neowin 報導，指出微軟電腦管家的深度清理功能，會導致電腦速度變慢，該功能會尋找用户電腦內不再需要的文件和緩存並刪掉，從而釋放出空間，以達致加快電腦運行速度的目的。</p><p><strong>然而結果卻適得其反，深度清理這個功能會清除電腦 Prefetch 文件夾內所有文件，而電腦則需要利用這個文件夾，保存有關用户運行的應用程序信息，以便下次啓動時能更快速。</strong></p><p>刪除後自然就無法進行快速啓動了，也就是説，存儲空間和快速啓動，這倆只能二選一了。</p><p>建議用户在使用類似軟件時，如無特殊需要，Prefetch 文件夾儘量避免清理，以保證電腦的正常運行。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 13 Feb 2024 12:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278611</guid>
            <link>https://www.oschina.net/news/278611</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Zadig vs. Jenkins 詳細比對：時代的選擇與開發者之選]]>
            </title>
            <description>
                <![CDATA[作為 Zadig 的創造者，我認為有必要與大家分享一份詳細的比較文章。我的職業生涯伴隨着工具、技術和基礎設施的不斷迭代，從十幾年前的 TeamCity、Hudson，到 Jenkins、Travis、CircleCI 和 ...]]>
            </description>
            <pubDate>Tue, 13 Feb 2024 12:25:00 GMT</pubDate>
            <guid isPermaLink="false">Zadig vs. Jenkins 詳細比對：時代的選擇與開發者之選</guid>
            <link></link>
        </item>
        <item>
            <title>
                <![CDATA[Mitchell Baker 辭去 Mozilla 公司 CEO 職務]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>備受爭議的 Mozilla 聯合創始人 Mitchell Baker 宣佈辭去 CEO 一職。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-24ada4c3707caefa6869cb60d019439e5e6.png" referrerpolicy="no-referrer"></p><p>她將繼續留在 Mozilla 擔任執行主席專注於戰略層面：</p><ul><li>通過在社區中發表演講和直接參與，更加一致地在公眾中代表 Mozilla – 重點關注政策、開源和社區。</li><li>將 Mozilla 視為一個統一的實體——比各個部分的總和還要大，將繼續加強和完善所有實體的合作方式，以更大的緊迫性和速度推進我們的政策和社區目標。</li></ul><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-fff4e4ddc2fa484029434ab29518c8734e0.png" referrerpolicy="no-referrer"></p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Fen%2Fmozilla%2Fa-new-chapter-for-mozilla-laura-chambers-expanded-role%2F" target="_blank">https://blog.mozilla.org/en/mozilla/a-new-chapter-for-mozilla-laura-chambers-expanded-role/</a></em></p></blockquote><p>Mozilla 董事會成員、曾在 Airbnb、PayPal 和 eBay 工作過的 Laura Chambers 擔任臨時 CEO，負責公司運營直到找到新 CEO 為止。Baker 表示辭職是她做出的決定，以迴應對互聯網當前狀況和公眾信任的緊迫感。</p><p>Mitchell Baker 稱 Laura 的重點將放在 Mozilla 公司上，主要為兩個關鍵目標負責：</p><ol><li>未來願景和戰略：完善公司願景並調整其背後的公司和產品戰略。這將植根於 Mozilla 的使命和獨特優勢，並由他們對技術未來和我們在其中的作用的觀點所塑造。</li><li>出色的執行力：加倍努力開發核心產品（例如 Firefox），並構建創新渠道，將引人注目的新產品推向市場。</li></ol></div>
                                    ]]>
            </description>
            <pubDate>Tue, 13 Feb 2024 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278569</guid>
            <link>https://www.oschina.net/news/278569</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[保護我方水晶，2024 數據庫安全工具盤點]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在數據價值堪比石油的數字時代，對每個組織而言，保護這一核心資產顯得尤為重要。無論是來自外部的黑客攻擊和惡意軟件，還是源於內部的人為失誤和內鬼行為，威脅無處不在。本文將介紹幾款先進的數據庫安全工具，從不同維度確保數據安全。</p><ul><li>網絡安全：<strong>Tailscale</strong></li><li>數據庫密鑰管理：<strong>Infisical</strong></li><li>按需數據庫訪問：<strong>Indent</strong></li><li>全方位人到數據庫操作管理：<strong>Bytebase</strong></li></ul><h2>Tailscale</h2><p>Tailscale 是一種 VPN 服務，它讓您能夠不論身在何處，都能安全便捷地連接到自己的設備和應用。這項服務利用了開源的 WireGuard® 協議來建立加密的直連，確保只有你的私有網絡內的設備才能互相通信。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c248ef0ce5c9806c26445fe197bcbb48f42.png" alt="file" referrerpolicy="no-referrer"></p><p>對於數據庫應用，Tailscale 使你可以從世界任意地點安全地連接到數據庫，而無需將數據庫對公網開放或額外配置 SSH 隧道。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6e737f7e9c19c7c8b1ee19f5dd8e0a07b38.png" alt="file" referrerpolicy="no-referrer"></p><p>Tailscale 的免費版本支持最多 3 名用户和 100 台設備，適合個人使用或小企業。如果你需要更高級的功能，如訪問控制和審計日誌，付費方案的價格從每月每用户 6 美元起。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9f5a9eb7501069457905f4d17c6096b3850.png" alt="file" referrerpolicy="no-referrer"></p><h2>Infisical</h2><p>Infisical 是一款開源的密鑰管理平台，具備端到端加密功能，專為存儲、管理和在各種應用及其基礎架構之間同步如 API 密鑰、數據庫登錄信息及環境變量等敏感信息而設計。它可作為 HashiCorp Vault 和 AWS Secrets Manager 的替代方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-efccb11a9c8887cfd0dfeb73e71b21e5f8a.png" alt="file" referrerpolicy="no-referrer"></p><p>你既可以選擇在自己的服務器上部署 Infisical，也可以使用其提供的雲服務。</p><p>通過 Infisical，你的數據庫登錄信息能夠被安全地保存在一個加密的存儲空間裏，僅在應用程序需要時才被調用，從而避免將這些信息直接嵌入到應用程序的代碼或配置文件中。你可以通過 CLI、SDK、Docker、Kubernetes 或者 REST API 等多種方式來訪問這些信息。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ae449b1ce237cf8c2d755dc35228f6342d4.png" alt="file" referrerpolicy="no-referrer"></p><p>Infisical 的免費版本提供給最多 5 名開發人員和 3 個環境使用，滿足業餘愛好者的需求。如果你需要更高級的功能，如訪問控制和審計日誌，付費方案從每月每位開發人員 6 美元起。</p><p><img src="https://oscimg.oschina.net/oscnet/up-2d1ea3cf8e1045666d9c02621a2e5e25f92.png" alt="file" referrerpolicy="no-referrer"></p><h2>Indent</h2><p>Indent 使團隊成員能夠在數秒之內實現對雲應用和基礎架構的按需訪問。這項服務被形象地比喻為一個「請求訪問」按鈕。</p><p><img src="https://oscimg.oschina.net/oscnet/up-2d6b0094eabe262bea970f66a21c9f05ee6.png" alt="file" referrerpolicy="no-referrer"></p><p>在數據庫訪問管理方面，Indent 允許你為處理客户數據的系統設置時間限制的訪問權限，並能夠精確控制訪問的範圍。它支持三種集成方式：</p><ol><li>零信任網絡 (ZTN) - 如 Tailscale</li><li>身份組 - 如 Okta</li><li>自定義集成</li></ol><p><img src="https://oscimg.oschina.net/oscnet/up-f35fbc40ac93cd84dcff83e9819ad4ff48a.png" alt="file" referrerpolicy="no-referrer"></p><p>Indent 為小型團隊提供了一個默認具備安全保障的免費試用版本。對於那些需要更多高級功能的用户，付費方案的起價是每個用户每月 8 美元。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e271910a957ca962a453ac6f3e2e4cceb69.png" alt="file" referrerpolicy="no-referrer"></p><h2>Bytebase</h2><p>Bytebase 是一款開源的數據庫 DevOps 工具，被譽為數據庫管理領域的 GitLab/GitHub，它支持應用程序開發生命週期中的數據庫管理。這款工具為數據庫管理員（DBA）、開發人員和平台工程師提供了一個集中的網絡協作平台，將 DBeaver、Liquibase、Flyway 等多種數據庫工具整合在一起，方便使用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f1b18c17c00f2a03eb67abfede9552ce6a1.png" alt="file" referrerpolicy="no-referrer"></p><p>Bytebase 旨在涵蓋人與數據庫在各個環節的交互，無論是變更管理、數據查詢、訪問控制等。憑藉自動 SQL 審核、數據庫持續集成/持續部署（CI/CD）、數據訪問管理、數據脱敏等功能，Bytebase 確保所有數據庫操作都能按照標準流程執行，並且完全可審計。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fc2a3785dd735d27901d22db677437a46c0.png" alt="file" referrerpolicy="no-referrer"></p><p>在社區版計劃下，你可以免費使用，支持最多 10 名用户和 5 個數據庫實例。對於規模較大的中型至大型組織，企業版提供了包括數據訪問管理、審計日誌在內的更多高級功能。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c6439bbd59d93b65bba3da3210e50912b81.png" alt="file" referrerpolicy="no-referrer"></p><h2>Of Course</h2><p>上述介紹的每一款工具都有其特色和強項。通過瞭解你的特定需求，可以挑選最適合自己場景的工具。</p><hr><p>💡 更多資訊，請關注 Bytebase 公號：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 12 Feb 2024 15:50:04 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/11033157</guid>
            <link>https://my.oschina.net/u/6148470/blog/11033157</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中國科學院自動化研究所研發 Q 系列人形機器人系統]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>中國科學院自動化研究所人形機器人攻關團隊研製的<strong>譜系化人形機器人 Q 系列</strong>於日前亮相。</p><p>人形機器人攻關團隊在中國科學院院士、多模態人工智能系統全國重點實驗室主任喬紅帶領下，面向國家航天、製造產業等重大需求，基於「環境吸引域」高精度作業和類腦智能機器人理論等原始創新積累，<strong>自主突破了高爆發一體化關節、AI 賦能設計、機器人大模型、類人柔順控制等核心技術，研製了人形機器人設計組裝「大工廠」，可以快速設計構建人形機器人硬件和軟件系統，形成了從學術理論、關鍵技術到系列人形機器人研製創新鏈</strong>，目前已設計出多台 Q 系列人形機器人樣機，初步實現了面向不同場景的技術驗證。</p><p><strong>➤面向自適應室外複雜地形、抗未知幹擾的需求</strong>，「大工廠」通過 AI 賦能設計構建了可實現機器人全身姿態準確跟蹤與平衡控制的仿生高動態機器人 Q1，可實現室內外各種複雜地形的自適應與穩定運動的多地形適應機器人 Q2，以及可實現批量化機器人魯棒控制與不同環境適應能力的高爆發運動機器人 Q3，並通過「大工廠」的系列化、模塊化軟件訓練系統，為面向農田作業、野外巡邏等室外場景應用需求賦能人形機器人感認知-決策-控制智能；</p><p><strong>➤面向進一步探索人類運動特性、精準操作機理的科學研究需求</strong>，基於人類肌肉骨骼系統的肌肉非線性特性、肌肉分佈特徵、運動皮層-小腦-脊髓環路控制等機理，構建了可實現高柔順、高精度運動的類人形機器人 Q4，為進一步構建機理上模擬人、性能上趕超人的新一代人形機器人奠定基礎；</p><p><strong>➤面向人形機器人在室內場景完成多類任務的智能化需求</strong>，「大工廠」在機器人系統中融入自動化所自研的紫東太初多模態大模型，構建了對物理環境下機器人任務的快速、準確邏輯推理和執行的高併發推理人形機器人 Q5，可為智慧工廠作業、家庭生活服務提供重要支撐。</p><p>人形機器人「大工廠」可以充分融合智能、機構、部件、控制和決策等單元技術，快速生成各類人形機器人系統，為形成人形機器人技術標準和產業化，並在人類難以到達的環境中進行人形機器人自生產、自構建、自進化打下基礎。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-962b946894124d8a3cc02a2abe7dc23e811.png" referrerpolicy="no-referrer"></p><p><em>多機器人協作</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d3ba6121308939361cd68c15575630993ff.png" referrerpolicy="no-referrer"></p><p><em>人機協作</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1173f08f5757657dfc11625f85b8741529c.png" referrerpolicy="no-referrer"></p><p><em>機器人裝配</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1f71506ce9569870168614179a4758675cf.png" referrerpolicy="no-referrer"></p><p><em>機器人射箭</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9fd9db2f5b2741665261dbd1d82a3b93b73.png" referrerpolicy="no-referrer"></p><p><em>機器人充電</em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 12 Feb 2024 06:16:53 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278515</guid>
            <link>https://www.oschina.net/news/278515</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[EVA-CLIP-18B：性能最強的開源 CLIP 視覺大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong><span>近日，智源視覺團隊成功訓練併發布世界最大最強的 CLIP 模型 EVA-CLIP-18B，擁有 180 億參數。EVA-CLIP-18B 大幅突破了圖像、視頻和 3D 上的零樣本識別能力</span></strong><span>，在 27 個圖像分類基準測試上取得了 80.7% 的零樣本準確率，這一成績顯著優於其前代模型 EVA-CLIP-5B 和 Google, Apple 等公司取得 SOTA 的其他開源 CLIP 模型。</span></p><p><span>EVA-CLIP-18B 的成功訓練進一步驗證了 EVA 系列 weak-to-strong 規模擴增策略的潛力和有效性。團隊將公開 EVA-CLIP 18B 模型的權重和訓練代碼，為未來的計算機視覺和視覺-語言多模態研究提供強大的視覺基礎模型。</span></p><h3><span><strong><span style="color:#0052ff">技術亮點</span></strong></span></h3><h4><span style="color:#0052ff"><strong><span style="color:#0052ff">Weak-to-strong 策略：以小教大，以弱引強</span></strong></span></h4><div><div><p><span>EVA-CLIP-18B 沿用了 EVA 系列 weak-to-strong 的視覺模型 scale up 策略，實現了視覺模型規模的漸進式擴增。該策略遵循「<strong>以小教大，以弱引強</strong>」的規模擴增思想。</span></p><p><span>具體而言，團隊首先使用一個較小的 EVA-CLIP-5B 模型作為教師，以掩碼圖像建模為訓練目標，蒸餾出一個較大的 EVA-18B 純視覺模型。隨後，EVA-18B 作為 EVA-CLIP-18B 視覺-語言對比訓練中視覺編碼器的初始化，幫助 EVA-CLIP 模型進一步 scale up。</span></p><p><span>研究結果表明，使用較弱的 EVA-CLIP 模型引導更大的 EVA 模型完成視覺訓練，再使用得到的 EVA 模型作為更大 EVA-CLIP 訓練的初始化，這種漸進式地用弱模型引導大模型的 scale up 方式，<strong>可以有效解決大型視覺模型訓練中的不穩定問題，並加速模型訓練收斂。</strong></span></p><p><img height="216" src="https://oscimg.oschina.net/oscnet/up-2a0718f4131f0c98941eddf277470f57c44.png" width="500" referrerpolicy="no-referrer"></p><h4><strong><span style="color:#0052ff">Scaling Behaviour</span></strong></h4><p><span>除了最大規模的 EVA- CLIP-18B 模型，團隊還訓練了中等規模的 EVA-CLIP-8B 模型，並在實驗中設置不同規模的模型使用近乎相同規模的訓練數據，考察 EVA weak-to-strong vision scaling 在擴大模型規模方面的有效性。</span></p><p><span>實驗結果表明，在保持數據量幾乎不變的條件下，按照 EVA weak-to-strong 方法僅對模型規模進行擴增，模型性能實現了持續、穩定地提升，驗證了 EVA weak-to-strong 方法在擴大視覺模型規模方面的有效性。同時，<strong>模型性能並未呈現飽和趨勢</strong>，體現了 EVA weak-to-strong 方法的潛力。</span></p><p><img alt="" height="469" src="https://oscimg.oschina.net/oscnet/up-7e4bbe03c868bc9dc72fb6e1439b8b08e8a.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#888888">EVA-CLIP 系列模型隨着模型規模擴大性能變化曲線，和現存最大（InternVL-C）和最強（DFN5B）的 CLIP 模型對比</span></p><h4><strong><span style="color:#0052ff">更高的訓練效率</span></strong></h4><p><span>受益於 weak-to-strong 算法在 scale up 模型方面的高效性，相比於其他 CLIP 模型，EVA-CLIP-18B 具有更高的訓練效率，在 360 塊 40G A100 上 600 小時完成訓練。</span></p><p><span>值得注意的是，EVA-CLIP-18B 在僅僅使用 6B 訓練樣本的情況下，就取得了最先進的性能，而其他先進的 CLIP 模型通常需要在 10B+ 的樣本上進行訓練。</span></p><h4><strong><span style="color:#0052ff">有限數據規模下的無限潛力</span></strong></h4><p><span>數據集方面，EVA-CLIP-18B 模型的訓練僅使用了可公開獲取的 LAION-2B，COYO-700M 和少量的 LAION-COCO（僅 20M）數據集，相比於前代模型並沒有對數據規模進行擴大。</span></p><p><span>值得注意的是，此前最強的 CLIP 模型——Apple 公司的 DFN-5B 是在公司私有數據集上訓練的，比我們使用的公開數據集規模更大、質量更好。這進一步證明瞭 EVA weak-to-strong vision scaling 方法的優越性，以及 EVA-CLIP 模型在有限數據規模下的出色泛化能力。</span></p><p><span>在模型訓練的最後階段，團隊引入少量視頻數據（23M），顯著增強了模型零樣本視頻分類的性能。未來通過擴大數據集規模可以進一步提升模型性能，推動 EVA-CLIP-18B 模型的性能邊界。</span></p><h4><strong><span><span style="color:#0052ff">全方位最強性能的 CLIP 模型</span></span></strong></h4><p><span>相比於世界其他先進 CLIP 模型，EVA-CLIP-18B 取得了全方位的最強性能。我們的評估基準涵蓋了圖像分類、視頻分類、圖文檢索領域的 33 個常用評估數據集。EVA-CLIP-18B 在 27 個圖像分類的基準測試上取得了 80.7% 的零樣本分類準確率，相比於此前最強的 CLIP 模型（Apple 公司 DFN-5B）取得了 1.5% 的領先。</span></p><p><img height="177" src="https://oscimg.oschina.net/oscnet/up-b6a0157fcce3637965ddcc3a5ddc712474e.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#888888">EVA-CLIP 零樣本圖片分類性能</span></p><p><span>在視頻分類任務上，EVA-CLIP-18B 在 UCF-101、K-400/600/700 四個常用視頻理解基準上進行測試。相比於最先進的 CLIP 模型，上海人工智能實驗室的同期工作 InternVL，取得了平均 1.8% 的分類準確率提升。</span></p><p><img height="323" src="https://oscimg.oschina.net/oscnet/up-277e73aeebadcafbea7eac4dd4c3f939b1a.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#888888">EVA-CLIP 零樣本視頻分類性能</span></p><p><span>在另一項常用於 CLIP 模型評估的圖文檢索任務上，EVA-CLIP-18B 同樣取得了世界領先的最強性能。</span></p><p><img height="183" src="https://oscimg.oschina.net/oscnet/up-d18714f14fe80b1389a0a158a0735f69469.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#888888">EVA</span><span style="color:#888888">-CLIP 零樣本圖文檢索性能</span></p><p><span>在 3D 表示學習領域，使用和 Uni3D 一樣的訓練設置，我們使用更大的 EVA-CLIP 模型作為教師。實驗結果表明，CLIP 教師模型的 scale up 能夠對 3D 表示學習有恆定的提升作用，穩定增強模型 3D 零樣本分類的性能。</span></p><p><img height="205" src="https://oscimg.oschina.net/oscnet/up-7c46b9bf029b10537b0f8b46d7b60eb76d7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#888888">EVA-CLIP 模型增強零樣本 3D 分類的性能</span></p></div></div></div>
                                    ]]>
            </description>
            <pubDate>Sun, 11 Feb 2024 11:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278472</guid>
            <link>https://www.oschina.net/news/278472</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
