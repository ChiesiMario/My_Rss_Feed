<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 02 Dec 2023 17:58:24 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[算力基礎設施領域國家標準發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0">2023 年 11 月 27 日，國家標準 GB/T 43331-2023《互聯網數據中心（IDC）技術和分級要求》正式發佈。中國信息通信研究院（簡稱「中國信通院」）聯合多家企事業單位編制的這一國家標準正契合當前國家算力基礎設施建設和算力產業高質量發展需要。</p><p style="margin-left:0; margin-right:0"><img alt="" height="292" src="https://oscimg.oschina.net/oscnet/up-cc1753c1d4186d7e0e332aeaa3974d09ff3.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">該標準規定了互聯網數據中心（IDC）在綠色、可用性、安全性、服務能力、算力算效、低碳等六大方面的技術及分級要求，適用於互聯網數據中心（IDC）的規劃、設計、建設、運維和評估，期望更好的為不同行業深化賦能作用。</p><p style="margin-left:0; margin-right:0">2013 年以來，中國信通院雲計算與大數據研究所數據中心團隊基於中國通信標準化協會編制發佈了數項數據中心評級通信行業標準，對數據中心的綠色、可靠和安全性進行分級分類。經過多年實踐迭代，團隊聯合業界眾多使用方、設計方和供應方共同編制了該國家標準，以期更好地指導我國數據中心的健康發展。</p><p style="margin-left:0; margin-right:0">高能效一直是數據中心發展過程中廣受關注的問題，該國家標準將在綠色技術應用和運維制度管理等方面提出促進數據中心能效水平提升的具體要求；服務能力是數據中心對外服務的綜合體現，通過對服務能力的客觀評價，有利於數據中心的自我改進提升，也有利於客户根據業務需求選擇合適的數據中心；可用性方面，通過提高設備冗餘，可以在架構方面更好地保障數據中心應對突發情況的能力；安全性有助於保障數據中心設備運行及人員的安全。通過綜合評估數據中心等級情況，有利於運營者加強自我瞭解，更有利於行業按需選擇。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 08:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269062</guid>
            <link>https://www.oschina.net/news/269062</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國產編程語言 MoonBit（月兔）需要支持中文關鍵字嗎？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>MoonBit（月兔）是中國開發者團隊創建的編程語言，由粵港澳大灣區數字經濟研究院（IDEA 研究院）基礎軟件中心負責人張宏波領導的團隊開發。</p><p>張宏波本人不僅為多種編程語言做出了貢獻，包括 OCaml、ReScript（原 ReasonML/BuckleScript）和 Flow，還曾是 Rescript 語言工具鏈幾乎所有關鍵組件的作者，包括高速編譯器、標準庫以及構建系統等。</p><blockquote><p>MoonBit 專為雲計算、邊緣計算設計，是一個用於雲計算和邊緣計算的 WebAssembly 端到端編程語言工具鏈，集開發、編譯、測試、部署於一體 —— 涵蓋了通用程序語言設計、編譯器、構建系統、IDE、部署工具等。在語言設計、編譯器和構建系統上實現高度的垂直整合，為用户提供更佳的開發體驗和性能，致力打造未來世界級的基礎軟件生態。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8f1d876877f96c97b9e12b93fb1fef4c7ec.gif" referrerpolicy="no-referrer"></p></blockquote><p>昨天，張宏波在知乎發表提問：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F632589892" target="_blank">《MoonBit 國產編程語言提供中文關鍵字的可能性？》</a></u>，希望收集一些關於為 MoonBit 提供中文關鍵字支持的反饋，主要是有兩方面考慮：一是支持中文關鍵字從社區來説會帶來什麼潛在的負面作用？另外就是了解下真實的中文編程用户有多少。</p><p>張宏波説道：</p><blockquote><p>對於專業人士來説，中文確實不是學習編程的主要難點，但是從討論熱烈的程度來説，好像對一部分人來説或多或少是個門檻。<strong>從技術實現來講，可能就是一個上午就能大概支持了</strong>。</p><p>我提這個問題是想從兩方面收集一些反饋：<strong>一方面是支持中文關鍵字從社區來説會帶來什麼潛在的負面作用？另一方面是瞭解下真實的中文編程用户有多少，你會因問 MoonBit 支持中文關鍵字而更多地使用或者推薦給其他人嗎？</strong></p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-11a36224f77741f56eab1b317a5008a9d60.png" referrerpolicy="no-referrer"></p><p>下面是用 MoonBit 語言實現<code>fib</code>函數的示例代碼：</p><pre><code>// Moonbit
func fib(num : Int) -&gt; Int {
  fn aux(n, acc1, acc2) {
    match n {
      0 =&gt; acc1
      1 =&gt; acc2
      _ =&gt; aux(n - 1, acc2, acc1 + acc2)
    }
  }

  aux(num, 0, 1)
}
</code></pre><p><strong>延伸閲讀：</strong></p><ul><li><strong><em><u><a href="https://www.oschina.net/news/255951/moonbit-first-announce" target="_blank">中國開發者團隊創建的編程語言：MoonBit（月兔）</a></u></em></strong></li><li><strong><em><u><a href="https://www.oschina.net/project/awesome?columnId=20" target="_blank">中國人主導編程語言列表</a></u></em></strong></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 08:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269052</guid>
            <link>https://www.oschina.net/news/269052</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AWS 全面推出適用於 Rust 和 Kotlin 的 SDK]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">自 2021 年 12 月首次公開預覽兩年後，AWS 宣佈已全面推出適用於 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fblogs%2Fdeveloper%2Fannouncing-general-availability-of-the-aws-sdk-for-rust%2F" target="_blank">Rust</a> 和 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fblogs%2Fdeveloper%2Faws-sdk-for-kotlin-ga%2F" target="_blank">Kotlin</a> 的 SDK 並支持生產使用。&nbsp;</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">官方介紹稱，</span>AWS SDK for Rust 提供了慣用的類型安全 API；以及涵蓋了 Rust 語言的優勢，例如性能、可靠性和生產力。該 SDK 支持 async/await、非阻塞 IO 和構建器等現代 Rust 語言特性。並提供對 300 多個 AWS 服務的訪問，每個服務都有自己的 &nbsp;crate；項目團隊後續計劃將繼續增加對新服務和功能的支持。</span></p><p><span style="color:#000000">該 SDK 使用合理的默認值開箱即用，但它也是可擴展的，允許用户根據自己獨特的用例對其進行自定義。SDK 是模塊化的，允許客户僅為他們使用的服務編譯 crate。它的設計速度也很快。藉助 Rust SDK，用户可以在 Amazon Simple Storage Service (Amazon S3)、Amazon Elastic Compute Cloud (Amazon EC2) 和 Amazon DynamoDB 之間快速傳輸數據。</span></p><p><img height="300" src="https://oscimg.oschina.net/oscnet/up-79f46fd536e1e97a2b7983b321eed1fb7f8.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">事實上，對 AWS 服務的非官方 Rust 支持至少從 2015 年就開始存在了，當時 Matthew Mayer 和 Anthony DiMarco 在 Rust 1.0 發佈後不久啓動了一個名為 Rusoto 的獨立項目，目標包括學習 Rust。根據 Rust crate 存儲庫 crates.io 上的統計，Rusoto 已被下載超過 1100 萬次。2021 年，AWS Rust SDK 的第一個 alpha 版本由當時在 AWS 工作的 iliana etaoin 推出，她也是 Rusoto 的聯合維護者。</span></p><p><span style="color:#000000">另一方面，AWS SDK for Kotlin 採用了從頭開始設計。AWS 方面表示，此舉旨在為用户您提供慣用的 Kotlin 體驗，包括特定域語言 (DSL) 構建器，以及使用例程對異步 AWS 服務調用的支持。新發布的版本使開發人員能夠使用 JVM 平台或 Android API Level 24+，未來版本還將支持 Kotlin/Native 等其他平台。</span></p><p><span style="color:#000000">那麼就有人問了，既然 Kotlin 可以輕鬆地與現有的 Java SDK 進行互操作，那麼&nbsp;AWS 為什麼還要為 Kotlin 製作 SDK 呢？對此，AWS 解釋原因有三：</span></p><ul><li style="text-align:start"><span style="color:#000000">首先，Kotlin 比 Java 具有更多的互操作性，包括 null-safety、coroutines、extension functions 和 smart casting。AWS 希望提供一個能夠充分利用該語言並且讓 Kotlin 開發者感到符合語言習慣的 SDK。</span></li><li style="text-align:start"><span style="color:#000000">其次，自 2019 年以來，Android 移動開發一直以 Kotlin 為先。Android 開發人員應該能夠使用支持所有 AWS 服務的現代 SDK。這也是 AWS SDK for Kotlin 支持 Android API 24+ 的首要原因。事實上，AWS Amplify for Android v2 就是在 AWS SDK for Kotlin 的基礎上構建的。</span></li><li style="text-align:start"><span style="color:#000000">最後，Kotlin 並不是一種僅限 JVM 的語言。Kotlin multiplatform 允許用户編寫針對 JVM、本機二進制文件（Linux、Windows、macOS 和 iOS）、JavaScript 和 WASM 的 Kotlin 代碼。因此該 SDK 從一開始也就被定位開發為多平台庫，項目團隊計劃在未來支持更多目標。</span></li></ul><p><span style="color:#000000">瞭解有關未來版本計劃推出的功能的詳細信息，可查看</span><span style="color:#333333">&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Forgs%2Fawslabs%2Fprojects%2F50%2F" target="_blank">AWS SDK for Rust 路線圖</a>&nbsp;<span style="color:#333333">和&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fawslabs%2Faws-sdk-kotlin%2Fprojects%2F2" target="_blank">AWS SDK for Kotlin 路線圖</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 04:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269167/aws-sdks-for-rust-and-kotlin</guid>
            <link>https://www.oschina.net/news/269167/aws-sdks-for-rust-and-kotlin</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米迴應「雷軍最落魄時只剩冰冷的 40 億」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">近日，存在兩張有關小米創始人雷軍的圖片在網絡上廣為流傳。圖片文案顯示，「雷軍最落魄的時候，只剩下銀行卡里冰冷的 40 億」。</span></p><p><span style="background-color:#ffffff; color:#222222"><img alt="" height="392" src="https://oscimg.oschina.net/oscnet/up-90e839ec6755aa3946e458eff583478c12a.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#222222">對此，小米公司發言人官方微博昨日發文迴應稱：</span></p><blockquote><p><span style="color:#333333">今日網上出現大量關於本集團創始人雷軍的不實傳聞，所謂「冰冷的 40 億」 純屬子虛烏有、完全失實。請大家勿信、勿傳。 人生從來不是爽文，而是腳踏實地的歷程，感謝大家的理解與支持。 ​​​</span></p></blockquote><p>雷軍本人也在評論區評論稱：</p><blockquote><p><span style="color:#333333">人生從來不是爽文，都是腳踏實地的歷程，感謝大家的理解與支持。</span>&nbsp;</p></blockquote><p><img height="308" src="https://oscimg.oschina.net/oscnet/up-bf1373ae5fb064655792a016bd1dc5ca6d7.png" width="500" referrerpolicy="no-referrer">&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269159</guid>
            <link>https://www.oschina.net/news/269159</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[gkd —— 自定義屏幕點擊 APP]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>gdk 是一個<span style="background-color:#ffffff; color:#1f2328">基於<span>&nbsp;</span></span><strong style="color:#1f2328">無障礙</strong><span style="background-color:#ffffff; color:#1f2328"><span>&nbsp;</span>+<span>&nbsp;</span></span><strong style="color:#1f2328">高級選擇器</strong><span style="background-color:#ffffff; color:#1f2328"><span>&nbsp;</span>+<span>&nbsp;</span></span><strong style="color:#1f2328">訂閲規則</strong><span style="background-color:#ffffff; color:#1f2328"><span>&nbsp;</span>的自定義屏幕點擊 APP。</span></p><p style="color:#1f2328; text-align:start">基於<span>&nbsp;</span><a href="https://github.com/gkd-kit/selector">高級選擇器</a><span>&nbsp;</span>+<span>&nbsp;</span><a href="https://github.com/gkd-kit/subscription">訂閲規則</a><span>&nbsp;</span>+<span>&nbsp;</span><a href="https://github.com/gkd-kit/inspect">快照審查</a>，它可以實現</p><ul><li>點擊跳過任意開屏廣告/點擊關閉應用內部任意彈窗廣告, 如關閉百度貼吧帖子廣告卡片/知乎回答底部推薦廣告卡片</li><li>一些快捷操作, 如微信電腦登錄自動同意/微信掃描登錄自動同意/微信自動領取紅包</li></ul><p><img alt="" height="667" src="https://static.oschina.net/uploads/space/2023/1120/165010_l9Dm_4252687.jpg" width="300" referrerpolicy="no-referrer">&nbsp;<img alt="" height="667" src="https://static.oschina.net/uploads/space/2023/1120/165048_Krg3_4252687.jpg" width="300" referrerpolicy="no-referrer"></p><p><img alt="" height="674" src="https://static.oschina.net/uploads/space/2023/1120/165057_bqXk_4252687.gif" width="300" referrerpolicy="no-referrer"></p><p>&nbsp;<img alt="" height="500" src="https://static.oschina.net/uploads/space/2023/1120/165116_uE95_4252687.gif" width="300" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/gkd</guid>
            <link>https://www.oschina.net/p/gkd</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 在純 WebGPU/Rust 中實現 RWKV 語言模型]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-web-rwkv" class="anchor" href="https://gitee.com/cryscan/web-rwkv#web-rwkv"></a>Web-RWKV</h1><p><a href="https://gitee.com/link?target=https%3A%2F%2Fcrates.io%2Fcrates%2Fweb-rwkv"><img src="https://img.shields.io/crates/v/web-rwkv" alt="crates.io" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fdocs.rs%2Fweb-rwkv"><img src="https://docs.rs/web-rwkv/badge.svg" alt="docs.rs" referrerpolicy="no-referrer"></a></p><p align="center"></p><p>This is an inference engine for the <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FBlinkDL%2FRWKV-LM">language model of RWKV</a> implemented in pure WebGPU.</p><h2><a id="user-content-features" class="anchor" href="https://gitee.com/cryscan/web-rwkv#features"></a>Features</h2><ul><li>No dependencies on CUDA/Python.</li><li>Support Nvidia/AMD/Intel GPUs, including integrated GPUs.</li><li>Vulkan/Dx12/OpenGL backends.</li><li>Batched inference.</li><li>Int8 and NF4 quantization.</li><li>Very fast.</li><li>LoRA merging at loading time.</li><li>Support RWKV V4, V5 and V6.</li></ul><p align="center"></p><p>Note that <code>web-rwkv</code> is only an inference engine. It only provides the following functionalities:</p><ul><li>A tokenizer.</li><li>Model loading.</li><li>State creation and updating.</li><li>A <code>run</code> function that takes in prompt tokens and returns logits (predicted next token probabilities after calling <code>softmax</code>).</li></ul><p>It <em>does not</em> provide the following:</p><ul><li>OpenAI API or APIs of any kind.
<ul><li>If you would like to deploy an API server, check <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fcgisky1980%2Fai00_rwkv_server">AI00 RWKV Server</a> which is a fully-functional OpenAI-compatible API server built upon <code>web-rwkv</code>.</li><li>You could also check the <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FPrunoideae%2Fweb-rwkv-axum"><code>web-rwkv-axum</code></a> project if you want some fancy inference pipelines, including Classifier-Free Guidance (CFG), Backus–Naur Form (BNF) guidance, and more.</li></ul></li><li>Samplers, though in the examples a basic nucleus sampler is implemented, this is <em>not</em> included in the library itself.</li><li>State caching or management system.</li><li>Python (or any other languages) binding.</li><li>Runtime. Without a runtime makes it easy to be integrated into any applications from servers, front-end apps (yes, <code>web-rwkv</code> can run in browser) to game engines.</li></ul><h2><a id="user-content-compile-and-run" class="anchor" href="https://gitee.com/cryscan/web-rwkv#compile-and-run"></a>Compile and Run</h2><ol><li><a href="https://gitee.com/link?target=https%3A%2F%2Frustup.rs%2F">Install Rust</a>.</li><li>Download the model from <a href="https://gitee.com/link?target=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-5-world">HuggingFace</a>, and convert it using <a href="https://gitee.com/cryscan/web-rwkv/blob/main/convert_safetensors.py"><code>convert_safetensors.py</code></a>. Put the <code>.st</code> model under <code>assets/models</code>.</li><li>To generate 100 tokens and measure the time cost, run
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> gen</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To chat with the model, run
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To generate 4 batches of text with various lengths simultaneously, run
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> batch</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To specify the location of your safetensors model, use
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat <span class="nt">--</span><span class="nt">--model</span> /path/to/model</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li>To load custom prompts for chat, use
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat <span class="nt">--</span><span class="nt">--prompt</span> /path/to/prompt</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>
See <a href="https://gitee.com/cryscan/web-rwkv/blob/main/assets/prompt.json"><code>assets/prompt.json</code></a> for details.</li><li>To specify layer quantization, use <code>--quant &lt;LAYERS&gt;</code> or <code>--quant-nf4 &lt;LAYERS&gt;</code> to quantize the first <code>&lt;LAYERS&gt;</code> layers. For example, use
<div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--example</span> chat <span class="nt">--</span><span class="nt">--quant</span> 32</span></pre><div class="markdown-code-block-copy-btn"></div></div></div>
to quantize all 32 layers.</li><li>Use <code>--turbo</code> flag to switch to alternative <code>GEMM</code> kernel when inferring long prompts.</li></ol><h2><a id="user-content-use-in-your-project" class="anchor" href="https://gitee.com/cryscan/web-rwkv#use-in-your-project"></a>Use in Your Project</h2><p>To use in your own rust project, simply add <code>web-rwkv = "0.4"</code> as a dependency in your <code>Cargo.toml</code>.
Check examples on how to create the environment, the tokenizer and how to run the model.</p><h3><a id="user-content-explanation-of-batched-inference" class="anchor" href="https://gitee.com/cryscan/web-rwkv#explanation-of-batched-inference"></a>Explanation of Batched Inference</h3><p>Since version v0.2.4, the engine supports batched inference, i.e., inference of a batch of prompts (with different length) in parallel.
This is achieved by a modified <code>WKV</code> kernel.</p><p>When building the model, the user specifies <code>token_chunk_size</code> (default: 32, but for powerful GPUs this could be much higher), which is the maximum number of tokens the engine could process in one <code>run</code> call.</p><p>After creating the model, the user creates a <code>ModelState</code> with <code>max_batch</code> specified.
This means that there are <code>max_batch</code> slots that could consume the inputs in parallel.</p><p>Before calling <code>run()</code>, the user fills each slot with some tokens as prompt.
If a slot is empty, no inference will be run for it.</p><p>After calling <code>run()</code>, some (but may not be all) input tokens are consumed, and <code>logits</code> appears in their corresponding returned slots if the inference of that slot is finished during this run.
Since there are only <code>token_chunk_size</code> tokens are processed during each <code>run()</code> call, there may be none of <code>logits</code> appearing in the results.</p><h2><a id="user-content-convert-models" class="anchor" href="https://gitee.com/cryscan/web-rwkv#convert-models"></a>Convert Models</h2><p><em>You must download the model and put in <code>assets/models</code> before running if you are building from source.</em>
You can now download the converted models <a href="https://gitee.com/link?target=https%3A%2F%2Fhuggingface.co%2Fcgisky%2FRWKV-safetensors-fp16">here</a>.</p><p>You may download the official RWKV World series models from <a href="https://gitee.com/link?target=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-5-world">HuggingFace</a>, and convert them via the provided <a href="https://gitee.com/cryscan/web-rwkv/blob/main/convert_safetensors.py"><code>convert_safetensors.py</code></a>.</p><p>If you don't have python installed or don't want to, there is a pure rust converter that you can run</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span><span class="nb">cd</span> ./crates/web-rwkv-converter</span><span id="LC2" class="line"><span class="nv">$ </span>cargo run <span class="nt">--release</span><span class="nt">--</span><span class="nt">--input</span> /path/to/model.pth</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-troubleshoot" class="anchor" href="https://gitee.com/cryscan/web-rwkv#troubleshoot"></a>Troubleshoot</h2><ul><li><p>"thread 'main' panicked at 'called <code>Result::unwrap()</code> on an <code>Err</code> value: HeaderTooLarge'"</p><p>Your model is broken, mainly because you cloned the repo but did not set up git-lfs.Please download the model manually and overwrite that one in <code>assets/models</code>.</p></li><li><p>"thread 'main' panicked at 'Error in Queue::submit: parent device is lost'"</p><p>Your GPU is not responding.
Maybe you are running a model that is just too big for your device. If the model doesn't fit into your VRam, the driver needs to constantly swap and transfer the model parameters, causing it to be 10x slower.
Try to quantize your model first.</p></li></ul><h2><a id="user-content-credits" class="anchor" href="https://gitee.com/cryscan/web-rwkv#credits"></a>Credits</h2><ul><li>Tokenizer is implemented by <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkoute%2Frwkv_tokenizer">@koute</a>.</li></ul>]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/cryscan/web-rwkv</guid>
            <link>https://gitee.com/cryscan/web-rwkv</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 七年 4 個階段：滴滴可觀測架構演進與實踐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一分鐘精華速覽</h1><p>在當前階段，可觀測性的建設並沒有統一的執行路徑。每家公司會根據自身的業務需求、運營模式和規模，形成一套獨特的實踐方案。為了應對業務規模的擴大和需求的變化，可觀測團隊必須持續優化和升級其架構，並始終保證可觀測系統本身的高可用性。</p><p>本文詳盡地描繪了滴滴從 2017 年至今，在四個不同階段所遭遇的技術挑戰，如單體應用階段的資源瓶頸、運維成本的上升、分佈式服務的通信問題等等。滴滴通過尋找並應用適宜的技術方案，逐漸戰勝了這些技術難題，使其可觀測架構始終能為業務提供強大的支持。 <img src="https://oscimg.oschina.net/oscnet/up-37ea3e51d7965f7f81e1f723481e1d1511f.png" alt="file" referrerpolicy="no-referrer"></p><p>作者介紹 <img src="https://oscimg.oschina.net/oscnet/up-0a5962d122ef197918b9378c33d36a225a4.png" alt="file" referrerpolicy="no-referrer"></p><p>滴滴出行可觀測架構負責人——錢威</p><p>TakinTalks 穩定性社區專家團成員，滴滴出行可觀測架構負責人。深耕可觀測領域多年，專注於架構設計與優化。帶領團隊完成了滴滴第二代到第四代的架構迭代。多個可觀測開源項目的 Contributor。目前聚焦在滴滴可觀測的穩定性建設和滴滴場景下的可觀測性的實現與落地工作。</p><p>温馨提醒：本文約 7500 字，預計花費 12 分鐘閲讀。</p><p>「TakinTalks 穩定性社區」公眾號後台回覆 「交流」 進入讀者交流羣；回覆「1026」獲取課件資料；</p><h1>背景</h1><p>大家先來看一個故事——</p><p>「20 世紀初，當時處於高速發展期的福特公司。有一天一台電機壞了，相關生產工作被迫停止。很多工人和專家都找不到問題在哪。直到請到了一個叫斯坦門茨的人，斯坦門茨檢查後用粉筆在電機外殼畫了一條線，説打開電機，把記號處的線圈減少 16 圈。修理工照做後，故障排除，生產隨即恢復。」</p><p>我們在工作或在開發過程中，時常會遇到這樣的場景——讓你一頭霧水，不知道從何下手的難題，但是總有那麼一兩個「專家」一眼就能洞察問題所在。那麼，我們需要思考一下，這到底是好事還是壞事？</p><p>滴滴作為一家出行平台，業務涵蓋快車、專車、順風車、共享單車等多個領域。每天有千萬的用户和司機在平台上進行交互和使用，服務之間形成了複雜的依賴關係。在如此大規模的分佈式系統中，故障排查和性能優化無疑是一項複雜的任務。</p><p>每次都依賴於個別專家的經驗顯然是無法控制的，也無法保證結果。因此，我們更願意通過不斷地演進可觀測的架構，來支持業務的快速迭代和創新。</p><h1>一、可觀測架構演進解決了哪些問題？</h1><h2>1.1 滴滴可觀測系統通用架構</h2><p>滴滴可觀測系統通用架構主要包含幾個部分，如下圖所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-41df9f4c584d6ec7df86ea7af9d0dfc6121.png" alt="file" referrerpolicy="no-referrer"></p><p>我們會採集目標主機或其他的相關指標，經過傳輸鏈路後，某些指標可能會經過計算模塊進行處理，然後再寫回系統中。隨後，這些數據會被存儲起來。基於這些存儲的數據，查詢功能可以為上層應用提供數據展示，如儀錶板、數據大盤、報警和事件等。</p><p>需要注意的是，每個模塊需要完成的任務或實現的功能各不相同。例如，查詢模塊可能需要負責數據路由、聚合以及實現 DSL 等功能，這些功能通常在查詢層進行實現。</p><p>數據存儲的實現方式有很多種，如 InfluxDB、RRDtool、Prometheus、Druid、ClickHouse 等，都可以作為可觀測系統的存儲方案。</p><p>傳輸模塊在系統中起到連接的作用，常見的消息隊列就是用在這一模塊中。當我們提到消息隊列時，大家首先想到的可能是 Kafka，當然也有一些較為小眾的選擇，如 NSQ。</p><p>計算模塊的任務則是將大量的指標轉換成我們所需的形式，可能會去除一些維度進行計算。Flink、Spark 等工具在這一模塊中都是常見的選擇。</p><p>對於數據採集，也有許多豐富的工具可以選擇，如 Telegraf、Node exporter，以及最近推出的 Grafana Agent 等。</p><h2>1.2 可觀測架構演進的 4 個階段</h2><h3>1.2.1 階段一：2017 年以前</h3><p>當業務需求發生變化時，存儲模塊的性能問題通常是最先暴露出來的。在 2017 年以前，滴滴主要使用 InfluxDB 作為存儲選擇。我們根據業務服務的維度將 InfluxDB 實例進行了拆分，這樣的設計便帶來了一些問題。</p><p>首先，單機版本的性能存在瓶頸。例如，我們可能會遇到查詢量較大的情況，如查詢跨度長或查詢數據多，這種情況下很可能會出現內存溢出（OOM）的問題。這也是社區中經常討論的問題。 <img src="https://oscimg.oschina.net/oscnet/up-416c08cc213a26dc5a99ac0e2175637595c.png" alt="file" referrerpolicy="no-referrer"></p><p>再者，我們採用的分片方式也存在問題。我們是按照服務進行拆分的，例如，如果今天有 50 個服務，那可能需要 50 個或更少的實例。但如果服務數量在明天增加到 500 個，那麼運維成本將隨之顯著增加。特別是在當前大家普遍採用微服務架構的情況下，這種運維成本將會非常高。</p><h3>1.2.2 階段二：2017-2018 年</h3><p>為瞭解決上述問題，我們在 2017 年引入了 RRDTool。在此期間，RRDTool 取代了 InfluxDB，成為滴滴可觀測的主要存儲工具。</p><p>在 RRDTool 的設計中，我們採用了一致性哈希算法，在讀寫鏈路中進行多個 RRDTool 實例的分片。這種哈希算法的過程是先將所有的 Tag 打平，然後排序，最後再進行哈希，分配到各個實例中。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7ac44d840041980a63c09d3c56e62770b70.png" alt="file" referrerpolicy="no-referrer"></p><p>除此之外，我們還引入了一個名為「索引」的服務。這個服務的主要任務是滿足產品需求。比如，我們可能需要提供服務列表，當用户選擇了他們自己的服務後，需要知道該服務下有哪些指標，以及每個指標下有哪些 Tag。這種需求需要一個高效的索引服務來完成。</p><p>基於 RRDTool 的架構改進帶來了兩大成果。首先，它解決了 InfluxDB 的熱點問題。我們原來是按照服務去拆分實例，現在我們將這些曲線分散到各個實例上。其次，這也減輕了 InfluxDB 的運維成本，因為我們採用了相對自動化的分片方式。</p><h3>1.2.3 階段三：2018-2020 年</h3><p>在 2018 年以後，我們面臨了新的挑戰。由於 RRDTool 的設計原理是每條曲線一個文件，因此，當數據規模擴大時，對 IO 的需求也隨之增大。我們的 IOPS 已經超過了 3 萬，這就需要我們增加更多的設備，例如具有高 IO 性能的機器，以解決這個問題。但是，這導致成本逐漸增高，且問題愈發嚴重。同時，可觀測性中的讀寫是正交的，讀寫優化存在衝突——寫通常是所有曲線寫入最新的部分，而讀通常是讀取多條曲線或某條曲線長時間的數據。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d81c56d2f84ab2161a197aedd244e17e750.png" alt="file" referrerpolicy="no-referrer"></p><p>（縱向為 Writes，橫向為 Reads)</p><p>那麼，我們如何解決這個問題呢？經過分析，我們發現 80% 的查詢都集中在最近兩個小時內，因此，我們設計了一個冷熱分層策略。這個策略的核心就是將壓縮後的數據存儲在內存中。壓縮主要針對兩個方面，一是時間戳，二是值。由於時間戳產生的時間間隔通常比較固定，而值的變化往往較為平緩，這為我們的壓縮策略提供了依據。</p><p>基於這個原理，我們內部創建了一個名為"Cacheserver"的服務，主要服務於最近兩小時的數據，採用了全內存的設計。這種設計使得用户查詢的延遲從 10 秒降低到了 1 秒以內，每個數據點的存儲由原來的 16 字節降低到了 1.64 字節。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a65d91b989d8dd692a5abc11952dddb1621.png" alt="file" referrerpolicy="no-referrer"></p><p>整個設計可以通過上述圖示來理解。首先是冷熱分層，RRDTool 和 Cacheserver 共同完成了整個存儲任務。以圖示右半部分為例，原始的時間戳為 350、360、370、381，存儲這些數據需要 256 比特。但經過壓縮後，只需要 88 比特就足夠了。這只是四個時間戳的情況，如果時間戳更多，那麼壓縮效果會更加顯著。</p><h3>1.2.4 階段四：2020-至今</h3><p>隨着用户接入的組件不斷增多，用户的查詢需求也變得越來越複雜。在我們的使用場景中，一旦 RRDTool 進行了降採，我們就無法再查看到原始數據。</p><p>面對這種情況，我們開始思考如何設計一個能滿足用户當前和未來需求的系統。我們改變了問題解決的策略，不再針對每個具體情況單獨設計方案。例如，如果過去有新增的查詢形態，我們會需要編碼並上線一個新的函數。而現在，我們選擇直接利用業界的生態。</p><p>當時，Prometheus 是非常流行的。我們將目標從引入生態轉變為引入 Prometheus 的生態。選擇 Prometheus 的原因是，隨着 K8s 的普及，Prometheus 已經成為了監控系統的事實標準。許多業界大廠和流行的廠商都在為 Prometheus 持續貢獻代碼和架構。</p><p>然而，如果我們選擇引入 Prometheus 的生態，就無法繼續使用 RRDTool，因為它無法兼容 Prometheus 的生態。這就需要我們尋找新的存儲方案。</p><p>難點 1：新的存儲方案如何選擇？</p><p>在面臨新的存儲方案選擇時，我們主要考慮了 Cortex、Thanos 和 VictoriaMetrics（簡稱 VM）。這些方案都是為了彌補 Prometheus 本身的一些缺陷而設計的，因為 Prometheus 從誕生之初就定位為單機存儲，不支持長期存儲，也沒有高可用性。因此，Cortex 和 Thanos 在當時成為了業界主要的解決方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-176778420cc3bcd7e50c8134538547fba02.png" alt="file" referrerpolicy="no-referrer"></p><p>（調研業界 Prometheus 相關方案）</p><p>在對比這些方案時，我們發現 Cortex 和 Thanos 都能有效解決 Prometheus 的原生缺點。從成本角度考慮，由於 Thanos 和 Cortex 都採用了對象存儲，因此它們的成本相對較低。但是，這兩個方案由於使用了大量的第三方服務，如果公司沒有對象存儲或者沒有云服務，那麼這些組件的維護工作可能就需要由可觀測團隊來完成。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1d163b32eaf5437ddae21f7a3ecc49ca221.png" alt="file" referrerpolicy="no-referrer"></p><p>(RRDTool 與 VictoriaMetrics 方案對比）</p><p>相比之下，VM 與 RRDTool 相比，它是完全兼容 Prometheus 的。此外，我們之前提到過降採策略，RRDTool 的數據在超過兩小時後會進行降採，一旦降採，我們就無法查看到原始數據。而 VM 本身不進行降採，這為我們帶來了更多可能性。在降低存儲成本方面，VM 的表現較好，在我們的環境測試中，其存儲成本只有 RRDTool 的 1/20 左右。在數據上報形態上，Prometheus 是 Pull 形式，而 RRDTool 只能支持 Push 形式，並且只支持私有協議。但 VM 既支持 Pull 也支持 Push，對流行的數據上報協議也有良好的支持。</p><p>難點 2：如何引入 Prometheus 生態？</p><p>那麼，我們是否可以簡單地將存儲方案替換為 VM 呢？實際上，答案是否定的。在引入新的生態系統時，我們首先需要考慮現有的公司方案。引入新的生態並不意味着要完全顛覆現有的產品架構，不能簡單地進行替換。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4ced98fb48857f34094958a2cf4099a710e.png" alt="file" referrerpolicy="no-referrer"></p><p>為了引入新的生態，滴滴進行了一些改造。如圖所示，綠色部分是使用 Prometheus 原生方案所需完成的工作。只要被監控的對象支持"/metrics"這樣的接口，Prometheus 便可以進行數據拉取。對滴滴而言，我們原來的架構是基於採集、傳輸、存儲的 Push 模型。因此，我們在採集部分增加了一個兼容 Prometheus 的 Adapter。在原有基礎上，對於那些新增並且支持 Prometheus 拉取的服務，我們也可以使用自有的採集方法進行數據拉取。</p><p>在生態引入的成果方面，我們已經支持了 Prometheus 的數據採集，並且可以支持 PromQL 的圖表查看和報警這兩個常見場景。此外，我們還在圖表查看這個維度上增加了一些新的功能，比如增加了 TopK/BottomK 等圖表維度的 Outlier 能力。這樣，如果一個服務有很多個實例，我們就可以利用 TopK/BottomK 這樣的功能找出異常點。</p><p>在回饋社區方面，我們向 VM 官方和 Prometheus 社區遞交了一些 PR，以此為整個社區做出貢獻。</p><h1>二、如何保障可觀測系統自身穩定性？</h1><p>眾所周知，可觀測系統的目的是保障業務的穩定性。那麼，我們如何保障可觀測系統本身的穩定性呢？首先，我們需要探討如何監測這個可觀測的系統。是否可以在自身的系統上配置一些策略？或者建立一些儀表盤？或者採取其他一些方式？在這方面，我將分享一些我們的實驗和思考。</p><h2>2.1 如何觀測可觀測系統？</h2><p>我們不能讓可觀測的系統對其本身做觀測。例如，如果存儲系統出現故障，而查詢數據的方式是從自身的存儲中查詢，那麼就會形成循環依賴。因此，第一個原則就是不能讓可觀測的系統自觀測。第二個原則與第一個原則有關，即需要一套獨立的數據採集和報警服務來進行觀測。</p><p>在我們的實踐中，主要採用了兩種方法。</p><p><img src="https://oscimg.oschina.net/oscnet/up-2baf281d16b9116d4a30925231fa56d1a24.png" alt="file" referrerpolicy="no-referrer"></p><p>第一種方法用於監測流量，適用於數據採集、傳輸和存儲。這種方法主要通過使用 Exporter、Prometheus 和 Alertmanager 來進行自我監測。例如，如果存儲寫入流量突然變化，就可以使用這套系統進行自我監測。</p><p>另一種方法是監測能力。以報警為例，最簡單的方法是設置一條始終會觸發閾值的報警，但可能不會發送實時消息或短信通知。一旦報警事件中斷，可能是因為報警系統本身存在問題，或者報警系統所依賴的存儲查詢存在問題。在這種情況下，我們可以通過設置探測器和進行端到端的檢查來解決問題。</p><h2>2.2 如何保障可觀測架構始終穩定？</h2><p>我們可以從兩個方面來考慮：一是通過架構優化, 二是採取常用的保障手段。</p><h3>2.2.1 架構優化</h3><p>要點 1：雞蛋不要放在一個籃子裏</p><p>對於架構優化，一個簡單的原則就是不要把所有的雞蛋放在一個籃子裏。我們可以通過以下的設計實現這一點。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8c1c833a7b8db7fbd51e4b6d56286bd0b83.png" alt="file" referrerpolicy="no-referrer"></p><p>（VictoriaMetrics 存儲多集羣設計）</p><p>滴滴主要從事打車業務，我們的網約車和非網約車業務的觀測數據各自存儲在不同的存儲集羣上，這就是我們採用的 VM 多集羣設計。例如，如果非網約車業務實例出現問題，我們希望這不會影響到網約車業務，反之亦然。因此，我們在存儲方面進行了多集羣的設計。</p><p><img src="https://oscimg.oschina.net/oscnet/up-cd3d73594c6c53d06c8471fcc73d75d357f.png" alt="file" referrerpolicy="no-referrer"></p><p>（傳輸多集羣設計）</p><p>在數據傳輸方面，我們的設計理念也是類似的，但有一點區別在於，傳輸和存儲會用到不同的分片策略，這是因為它們的負載特性不同。例如，某個業務的傳輸量非常大，但存儲查詢的量卻非常小，這種情況下，我們會在傳輸端對數據進行拆分，在存儲端只需要保證數據的寫入即可。它們可以共享同一存儲集羣。</p><p>要點 2：及時扔掉壞雞蛋</p><p>另外還有一個原則，我們稱之為「及時扔掉壞雞蛋」。在傳輸模塊中，除了寫入存儲，還有其他的下游模塊，如流式報警等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e7a9c8c431cd89da042a2190e0ddb20e84f.png" alt="file" referrerpolicy="no-referrer"></p><p>因此，如果某個子系統因為某些原因運行變慢，從而影響了整個傳輸模塊，這是我們不願看到的。我們希望在子系統運行變慢或出現問題時，能夠及時將其剔除出系統，即熔斷策略。在某些情況下，我們可以自動進行熔斷，並嘗試不斷恢復這個子系統。如果它成功恢復，那我們就會重新將這個系統接入。</p><h3>2.2.2 其他常用保障手段</h3><p>熔斷、降級、多維度限流：</p><p>除了熔斷和降級，我們還有其他保障手段，如多維度的限流。多維度限流採取靈活策略對請求進行限制，例如，一些持續且高頻的跨度長時間的查詢，比如幾個月甚至幾年的數據查詢，我們就會應用多維度的限流手段。</p><p>慢查治理：</p><p>另一個保障手段是慢查的治理，這涉及到對大量曲線的查詢。比如，一次查詢涉及到了上百萬的曲線，此時我們需要進行慢查發現，然後進行治理。在一些重點保障的時期，我們會開啓這些策略，一旦識別到異常，就採用多維度限流，根據它的特徵進行限流或者直接禁用。</p><p>多活：</p><p>內部可觀測的多活，我們採用的方式是做單元化。例如，如果 A 機房和 B 機房的專線中斷，我們需要保障用户可以單獨訪問相應機房的數據。</p><p>容量評估體系：</p><p>我們還有容量評估體系。因為在可觀測架構和業務流量或訂單量的增長可能不成正比，所以需要一套自身的容量評估體系。每家公司的業務模型可能不同，所以這個體系需要建立起來，對於保障手段來説，這是有幫助的。</p><p>預案、演練：</p><p>我們還會制定預案並進行演練，以保證這些手段是有效的。</p><h1>三、可觀測性在滴滴是怎麼實現的？</h1><h2>3.1 策略選擇</h2><p>可觀測性這個主題在 2021 或 2022 年是一個非常熱門的話題。有人可能會覺得，如果不談論可觀測性，就相當落後了。我們先來看一下各大廠對可觀測性的定義。</p><p>可觀測性是可幫助團隊有效調試其系統的工具或技術解決方案。可觀測性基於對事先未定義的屬性和模式的探索。——來源 Google</p><p>可觀測性是指能夠通過檢查系統或應用的輸出、日誌和性能指標來監控、測量和理解系統或應用的狀態。——來源 RedHat</p><p>可觀測性是指您僅根據所瞭解的外部輸出對複雜系統內部狀態或條件的理解程度。——來源 IBM</p><p>我在這裏分別引用了 Google、RedHat 和 IBM 對可觀測性的定義，他們有兩個共識。第一個是，可觀測性是能從外部理解系統內部的狀態，而這些狀態並不需要是已知的。第二個共識是，可觀測性有許多手段，包括日誌、指標、事件等。</p><p>那麼，如何實現可觀測性呢？各大廠都有自己的實現方式。Google 推薦使用其雲平台 GCP，RedHat 推薦使用 OpenShift Observability，IBM 有其自己的產品 Instana Observability，而 Grafana 推薦使用 LGTM(Loki、Tempo、Mimir)。</p><p>綜合來看，實現可觀測性的方法大概有三種。第一種是購買 SaaS 廠商的服務，第二種是儘可能地採集和存儲詳盡的可觀測數據，第三種是關聯多種觀測數據。</p><h2>3.2 方案對比</h2><p>對於滴滴，第一種實現方式並不適合，因此我們優先排除。</p><p>至於第二種實現方式是「儘可能詳盡」，於是我們將觀測數據分為兩個維度，即 Dimensionality 和 Cardinality。Dimensionality 類似於標籤的概念，例如時間戳、版本、顧客 ID 等。Cardinality 則以顧客 ID 為例，可能有從 1 萬 01 到 1 萬 9999 的數據。這種方案優點是能採集大量數據，但缺點是實現成本高、資源消耗大，且數據利用率偏低。</p><p>第三種實現方式是關聯多種觀測數據，常見的觀測數據包括 Metric、Trace、Log。Metric 數據屬於高層次抽象，能告訴你錯誤數，但無法提供具體錯誤信息。Trace 數據主要用於跨服務關聯，比如一個請求經歷了哪些服務。Log 數據則是開發人員偏好的信息，它提供最詳細的、人類可讀的數據。然而，這種關聯多種觀測數據的方式，其缺點是架構實現相對複雜。</p><h2>3.3 架構設計</h2><p>在滴滴，我們借鑑了上述兩種方法，將數據分為低基數和高基數兩類。低基數指的是指標數據，而高基數則是日誌數據。我們將這兩種數據分別存儲在不同的數據庫中，並建立它們的關聯關係。 <img src="https://oscimg.oschina.net/oscnet/up-0c28337ec890c982e26ae239ad7987fc15e.png" alt="file" referrerpolicy="no-referrer"></p><p>舉個例子，如果在一段時間內我們收集到兩個錯誤日誌，我們就會將這個錯誤數「2」上報到時序數據庫。同時，我們將對其中一條錯誤日誌進行採樣，並將其存儲在 Exemplar DB 中。然後，我們會通過標籤將時序數據庫和 Exemplar DB 進行關聯。</p><h2>3.4 實踐成果</h2><p>滴滴的可觀測性實踐成果非常顯著。在建立可觀測性之前，我們在排查故障時需要登錄到機器上並檢索日誌。如果有幸找到了問題所在的機器，那就算是幸運的。但如果並非問題出在這台機器，甚至不是這個服務，我們就需要重複上述的操作。而且，即使經過這樣的操作，是否能找到問題也是不確定的。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b9ba869b9b09a5cf7b46c0cc30f7de8a81a.png" alt="file" referrerpolicy="no-referrer"></p><p>然而，在建立了可觀測性之後，當我們收到報警消息時，我們可以直接查看與這條報警相關聯的日誌原文。查閲了日誌原文之後，如果認為沒有大問題，可以暫時不進行處理。如果是緊急情況，我們就會啓動緊急處理流程。</p><p>此外，當我們在查看圖表時，如果發現某個指標突然升高，想要知道是什麼原因導致的，我們可以使用下鑽功能。這個功能不僅可以讓我們查看日誌原文，如果日誌中包含 Trace 信息，還可以將這個 Trace 信息提取出來。然後可以將 Trace 信息下鑽到專門的 Trace 產品進行進一步的處理。</p><p>四、總結展望，滴滴的可觀測性架構的發展實際上是基於不同的需求、場景和時代背景，選擇了最適宜的解決方案。</p><p>我們對接了業界一些成熟的生態系統，並將這些生態系統融入到我們的系統中，這極大地幫助我們完成了許多工作，也提升了我們的工作效率。同時，在建設可觀測性平台的過程中，我們也採用了一些策略來實現觀測系統自身的穩定性保障。</p><p>值得注意的是，可觀測性的建設並沒有一種統一的實現方式，每家公司都有其自身的特色。因此，各公司需要根據自己的特點去定製專門的解決方案，並根據實際情況不斷選擇和調整最合適的方案。（全文完）</p><h1>Q&amp;A</h1><p>1、滴滴是否有專門的技術團隊去維護可觀測架構？Prometheus 的橫向擴展能力相對有限。InfluxDB 具體有哪些問題？</p><p>2、如何去度量一個架構的可觀測性？有什麼建議嗎？</p><p>3、Metric 的時效性有必要做到秒級嗎？</p><p>4、接口偶發性超時，調用鏈只能看到超時接口名稱，看不到內部方法，無法定位根因，也難以復現，怎麼辦？</p><p>以上問題答案，歡迎點擊<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.shulie.io%2F%3Fp%3D7518" target="_blank">「閲讀全文」</a>，觀看完整版解答！</p><p>聲明：本文由公眾號「TakinTalks 穩定性社區」聯合社區專家共同原創撰寫，如需轉載，請後台回覆「轉載」獲得授權。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 01 Dec 2023 03:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/5129714/blog/10315681</guid>
            <link>https://my.oschina.net/5129714/blog/10315681</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[崑崙萬維發佈「天工 SkyAgents」平台，零代碼打造 AI 智能體]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">12 月 1 日，崑崙萬維正式發佈「天工 SkyAgents」平台，助力大模型走入千家萬户。「天工 SkyAgents」是國內領先的 AI Agents 開發平台，基於崑崙萬維「天工大模型」打造，具備從感知到決策，從決策到執行的自主學習和獨立思考能力。用户可以通過自然語言構建自己的單個或多個「私人助理」。並且將不同任務模塊化，通過操作系統模塊的方式，實現執行包括問題預設、指定回覆、知識庫創建與檢索、意圖識別、文本提取、http 請求等任務。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">在「天工 SkyAgents」平台上，用户可以通過自然語言和簡單操作，無需代碼編程，即可在幾分鐘之內部署屬於自己的 AI Agents，完成行業研究報告、單據填寫、商標設計、甚至健身計劃、旅行航班預定等多項私人定製需求。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">對於企業用户而言，「天工 SkyAgents」則可以按需拼裝成企業 IT、智能客服、企業培訓、HR、法律顧問等眾多個性化的應用，並支持一鍵服務部署，確保其在不同業務系統中的無縫接入。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-b2d9f445592d6b227dc00b733eb3b8eff7b.jpg" width="1268" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">AI Agent 一般譯為「人工智能體」或「人工智能代理」，是一種能夠感知環境、進行決策和執行動作的智能實體。不同於傳統的人工智能程序，基於大模型能力打造的 AI Agent 具備通過獨立思考、調用工具去逐步完成給定目標的能力。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">模塊交互，更易用</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">當前，多數用户既不具備代碼開發經驗，也不具備訓練大模型提示詞工程（Prompt Engineering）的能力，難以將眾多日常生活的實際需求通過對話問答形式快速實現，無法將大模型能力發揮到極致。「天工 SkyAgents」正是為瞭解決這一痛點而研發的一款產品。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">「天工 SkyAgents」通過將 Agent-to-Agent，Human-to-Agent 的交互模式集成在高度模塊化的大語言模型構件中，實現完全無代碼化操作，並通過簡單直觀的圖形界面進行任務設定和部署，為廣大用户提供了一個全面、高效且易於使用的 AI 產品，能夠幫助用户輕鬆利用大模型能力應對複雜任務，滿足日常需求、驅動業務增長、激發靈感創新。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">數據導入，更靈活</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-6d36ddc7cbd9554af55070f2b41d742d529.jpg" width="1268" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">大模型能力雖強，但也有其天生的弱項。一方面，大模型通過參數訓練獲得的知識只能停留在某一時點，更新成本很高；另一方面，大模型的訓練數據通常以通用知識為主，細分領域的數據往往缺乏。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">為瞭解決這一問題， 「天工 SkyAgents」具備數據檢索增強（RAG）的能力， 能夠支持導入更多格式和更大規模的數據和知識，相當於給大模型增加了「智能知識庫外腦」。結合人工智能技術，平台能夠從導入的數據中自動識別關鍵信息點，形成結構化的知識體系。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">從此，「天工 SkyAgents」不僅能夠成為你的私人 AI 助理，還能是你的私人法律專家、私人人力顧問、私人 IT 大神……</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">技術領先，更強大</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">對話問答類大模型應用遇到需要多流程、多步驟處理的複雜業務，往往要麼容易產生「幻覺」，輸出錯誤回答，要麼容易錯步、漏步、跳步，直接輸出結果。然而不幸的是，人們在現實生活中遇到的大多數問題，往往都是複雜流程任務。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">為瞭解決這一問題，「天工 SkyAgents」在原有大模型技術基礎上進一步了強化自然語言處理能力，輔之以先進的目標理解與工作流自動化技術，使得「天工 SkyAgents」能更精準地識別和解析複雜的業務目標，自動生成定製化的工作流程，甚至預測並建議潛在的優化方案。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-c7e6afa126be7553e35e2f575f2b5953f3c.jpg" width="1268" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">本次「天工 SkyAgents」的發佈，將有助於缺乏代碼開發能力的個人與中小企業積極擁抱大模型技術，以簡單的模塊化操作，設計出專屬於自己的大模型 AI 助手，從而推動大模型技術的行業落地與普惠化，助力大模型走入千家萬户，為人工智能產業發展貢獻力量。前往天工開放平台預約申請：</span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagentspro.cn%2F%23%2F" target="_blank"><span><span><span><span style="color:#3370ff">https://agentspro.cn/#/</span></span></span></span></a></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><strong><span><span><span><span style="color:#1f2329">崑崙萬維集團</span></span></span></span></strong></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">崑崙萬維於 2008 年成立，2015 年深交所上市，從遊戲起家到 AII In AGI 與 AIGC， 全面構建多元化的業務生態，至今十餘年的發展，我們始終致力於為全球用户提供領先的互聯網產品與服務。現今，崑崙萬維還在不斷探索 AI 領域的無限可能。目前崑崙萬維逐漸構建了 AGI 與 AIGC、海外信息分發與元宇宙、投資三大業務板塊，業務覆蓋全球一百多個國家和地區，全球平均月活躍用户近 4 億。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#1f2329">憑藉對科技發展趨勢的超前預判，崑崙萬維早在 2020 年便已開始佈局 AIGC 領域。至今，已積累近三年的相關工程研發經驗，並建立了行業領先的預訓練數據深度處理能力，崑崙萬維也在人工智能領域取得了重大突破，目前已形成 AI 大模型、AI 搜索、AI 遊戲、AI 音樂、AI 動漫、AI 社交六大 AI 業務矩陣，是國內模型技術與工程能力最強，佈局最全面，同時全身心投入開源社區建設的企業之一。</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 09:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269081</guid>
            <link>https://www.oschina.net/news/269081</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[支持 Upsert、Kafka Connector、集成 Airbyte，Milvus 助力高效數據流處理]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Milvus 已支持 Upsert、 Kafka Connector、Airbyte！</p><p>在上週的文章中《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzMDI5OTA5NQ%3D%3D%26mid%3D2247499457%26idx%3D1%26sn%3D210ed71ffaa36d4220df3907a9a0ab41%26chksm%3Dfa515f79cd26d66f573354b0dc98dba492b925b1db63fbf5e5ad8b4cafb3f3b315d2bf6c5502%26scene%3D21%23wechat_redirect" target="_blank">登陸 Azure、發佈新版本……Zilliz 昨夜今晨發生了什麼？</a>》，我們已經透露過 Milvus（Zilliz Cloud）為提高數據流處理效率， 先後支持了 Upsert、 Kafka Connector、Airbyte，而這些功能的作用都是簡化數據處理和集成流程，為開發人員提供更高效的工具來管理複雜的數據，今天我們將向大家一一介紹。</p><h2>01.Upsert：簡化數據更新流程</h2><p>Upsert 功能上線以前，在 Milvus 中的更新數據需要兩個步驟：刪除數據，然後再插入新數據。雖然這種方法也可行，但無法確保數據原子性，且操作過於繁瑣。Milvus 2.3 版本發佈了全新的 Upsert 功能。（Zilliz Cloud 海外版也已上線 Upsert 功能 Beta 版）。</p><p>可以説，Upsert 功能重新定義了數據更新和管理方式。使用 Upsert 時，Milvus 會判斷數據是否已經存在。如果數據不存在則插入數據，如果已存在則更新數據。這種具有原子性的方法對 Milvus 這樣單獨管理插入和刪除數據的系統中尤為重要。</p><p>Upsert 具體的順序為：先插入數據，然後刪除重複數據。這樣可以確保了操作期間的數據仍然可見。</p><p>此外，Upsert 功能還特別考慮了修改主鍵的場景。在數據更新過程中無法更改主鍵列。這與 Milvus 根據主鍵哈希跨分片（shard）管理數據的原則一致。這種限制避免了跨 Shard 操作帶來的複雜性和潛在的數據不一致性。</p><p>Upsert 使用方法簡單，類似於插入操作。用户可以輕鬆將 Upsert 集成到現有的工作流程中，無需對原有流程進行大改。在 Pymilvus 等 SDK 中，Upsert 命令調用和插入命令完全一致。熟悉 Milvus 的用户使用起來沒有任何難度，可以獲得一致和絲滑的用户體驗。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f41551a015823f1b2df852545459520d410.png" alt="" referrerpolicy="no-referrer"></p><p>執行命令時，Upsert 會提供關於操作成功與否以及受影響的數據的反饋，進一步增加了開發者的使用便利性。這種易於使用且穩定的功能能夠助力數據管理。更多詳情，請查看 Upsert 文檔。</p><p>但是使用 Upsert 功能時還需要考慮以下兩點：</p><ul><li><p>AutoID 限制：使用 Upsert 功能的前提條件是將 AutoID 設置為 false。如果 Collection Schema 中將 AutoID 設置為 true，則無法執行 Upsert 操作。我們設置了這個限制的主要考量是，Upsert 也包含數據更新操作，更新的數據需要有新的主鍵值。如果用户提供的主鍵值與 AutoID 自動生成的主鍵值發生衝突，那可能會導致數據被覆蓋。所以，已經開啓了 AutoID 的 Collection 不可使用 Upsert 功能。後續新版本中我們可能會取消這一限制。</p></li><li><p>性能開銷：Upsert 可能會導致性能成本。Milvus 使用 WAL 架構，過多刪除操作可能會導致性能下滑。Milvus 中的刪除操作不會立即清除數據，而是為數據打上刪除標記。隨後在數據壓縮過程中才會根據這些標記真正清除數據。因此，頻繁的刪除操作可能會導致數據膨脹，影響性能。我們建議不要太過於頻繁地使用 Upsert 功能，以確保最佳性能。</p></li></ul><h2>02.Kafka Connector：賦能實時數據處理</h2><p>近期，Milvus 和 Zilliz Cloud 接入了 Kafka Sink Connector，向量數據可以無縫絲滑地通過 Confluent/Kafka 實時導入 Milvus 或 Zilliz Cloud 向量數據庫中。本次集成能夠進一步釋放向量數據庫潛能，助力實時生成式 AI 應用，尤其是使用 OpenAI GPT-4 這種大模型的場景。</p><p>如今，我們所獲取的信息中，非結構化數據已佔據 80% 以上，且這類數據還在呈爆炸式增長。Zilliz 與 Confluent 的合作標誌着非結構化數據管理和分析的重大進步，我們能夠更高效存儲、處理實時向量數據流，將其轉化為易於搜索的數據。</p><p>Kafka Connector + Milvus / Zilliz Cloud 的常見用例包括：</p><p>增強生成式 AI：為 GenAI 應用提供最新的向量數據，從而確保生成的準確性和及時性。這兩點對於金融和媒體等領域尤為重要，因為都需要實時處理各種來源的流式數據。</p><p>優化電商推薦系統：電商平台需要實時根據庫存和客户行為動態調整其推薦商品或內容以提升用户體驗。</p><p>在 Zilliz Cloud 中使用 Kafka Connector 的步驟也十分簡單：</p><ul><li><p>從 GitHub 或 Confluent Hub 下載 Kafka Sink Connector。</p></li><li><p>配置 Confluent 和 Zilliz Cloud 賬號。</p></li><li><p>閲讀在 GitHub 倉庫中提供的指南並配置 Kafka Connector。</p></li><li><p>運行 Kafka Connector，將實時流數據導入 Zilliz Cloud。</p></li></ul><p>如需更深入瞭解如何設置 Kafka Connector 和相關用例，請前往 GitHub 倉庫或訪問此網頁。</p><h2>03.集成 Airbyte：數據處理更高效</h2><p>近期，Milvus 與 Airbyte 團隊合作，在 Milvus 中集成 Airbyte，增強了大語言模型（LLM）和向量數據庫中的數據獲取和使用流程。本次集成能增強開發者存儲、索引和搜索高維向量數據的能力，大大簡化生成式聊天機器人和產品推薦等應用搭建流程。</p><p>本次集成的主要亮點包括：</p><ul><li><p>數據傳輸更高效：Airbyte 能夠無縫將數據從各種來源傳輸到 Milvus 或 Zilliz Cloud，即時將數據轉化為 Embedding 向量，簡化了數據處理流程。</p></li><li><p>搜索功能更強大：此次集成增強了向量數據庫的語義搜索能力。基於 Embedding 向量，系統可以自動識別並搜索出語義相似性高的相關內容，能夠為需要高效檢索非結構化數據的應用賦能。</p></li><li><p>設置過程更簡單：設置 Milvus 集羣和配置 Airbyte 同步數據的步驟十分簡單。如果需要使用 Streamlit 和 OpenAI Embedding API 構建應用也是同樣的設置步驟。</p></li></ul><p>此次集成簡化了數據傳輸和處理，釋放實時 AI 應用的無限可能性。例如，在客户支持系統中，使用 Milvus 或 Zilliz Cloud 集成 Airbyte 可以創建基於語義搜索的智能技術支持工單系統，從而為用户提供即時、有用的信息，減少人工幹預，提升用户體驗。</p><p>Zilliz 始終致力於提升非結構化數據管理和處理能力和技術，本次推出的 Upsert、Kafka Connector、Airbyte 等工具的集成都展現了這一點。後續，我們將進一步優化數據獲取和數據 Pipeline 功能，敬請期待！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 08:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10315720</guid>
            <link>https://my.oschina.net/u/4209276/blog/10315720</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AYANEO 新品復古 Mini PC：R3 3200U/R7 5700U 可選]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">遊戲硬件公司 Ayaneo 於近日<span style="background-color:#ffffff">正式發佈了旗下首款迷你主機：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ayaneo.com%2Fproduct%2FAYANEO-Retro-Mini-PC-AM01.html" target="_blank">Ayaneo Retro Mini PC AM01</a>，號稱引領 Mini PC 2.0 時代。該公司全新的 Mini PC 系列旨在滿足玩家的多樣化需求，打造無縫的遊戲體驗。</span></p><p><span style="color:#000000">Retro Mini PC AM01 整體設計致敬了蘋果公司經典的&nbsp;Macintosh。精緻復古的造型設計搭配<span style="background-color:#ffffff">僅 1L 的小巧體積，輕巧且便攜，Bare System 重量約為 466 克。機身正面帶有一個可自主更換的磁吸裝飾件，虛擬屏幕（僅用於裝飾目的，不可拆卸）同樣也可以使用自定義貼紙進行裝飾。</span></span></p><p><span style="color:#000000">雖然&nbsp;<span style="background-color:#ffffff">Ayaneo Retro Mini PC 具有蘋果風格的外觀，但實際上運行的卻是 Windows 11；支持安裝 Windows 和 Ubuntu、Debian 等 Linux 系統，以及 Steam OS 和 Batocera 等遊戲系統。它可以配置為軟件路由器或個人 NAS 系統使用。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">核心配置方面，AYANEO Retro Mini PC AM01&nbsp;配備 AMD Ryzen 3 3200U 或 Ryzen 7 5700U，提供多種處理器選項以適應各種用途需要。並且具有良好的可擴展性，配備五個 USB 端口（一個 USB-C 和四個 USB-A），另外還有 HDMI、DisplayPort、耳機插孔、以太網、藍牙和 Wi-Fi。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">散熱方面採用了高性能四銅管導熱結構、35W 大尺寸高壓渦輪風扇、60008 mm² 鋁製散熱片的設計；</span></span><span style="color:#000000"><span style="background-color:#ffffff">立體環繞進排氣</span></span><span style="color:#000000"><span style="background-color:#ffffff">系統，智能風扇控制。</span></span></p><p><img height="430" src="https://oscimg.oschina.net/oscnet/up-d080ffb024ee9f3cec60c28fd06a4058905.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">AM01 的<span style="background-color:#ffffff">早鳥優惠價格為 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.indiegogo.com%2Fprojects%2Fayaneo-retro-mini-pc-creator-of-mini-pc-2-0-era%23%2F" target="_blank">149 美元起</a>，最高為 459 美元。</span>現已接受預訂，官方計劃於 12 月開始發貨。<span style="background-color:#ffffff">具體的價格矩陣如下所示：</span></span></p><p><img alt="" height="267" src="https://oscimg.oschina.net/oscnet/up-0cd8ae66a9a0393d2fb33a48f61a185f409.jpg" width="500" referrerpolicy="no-referrer"></p><p><strong>外觀：</strong></p><p><img alt="" height="359" src="https://oscimg.oschina.net/oscnet/up-f8a5d7972d50038132cff8a992237d7b940.webp" width="500" referrerpolicy="no-referrer"></p><p><img height="376" src="https://oscimg.oschina.net/oscnet/up-e356e6ca490bb95486b9e1c3f8430ed747b.png" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="399" src="https://oscimg.oschina.net/oscnet/up-062ac361b585bde3beff445262346fb83b7.webp" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="472" src="https://oscimg.oschina.net/oscnet/up-79b4dd3419f6dc327dc82be45836609e8cb.webp" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="115" src="https://oscimg.oschina.net/oscnet/up-9517c76acb34e140a6044d3e7472437369f.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">詳情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ayaneo.com%2Fproduct%2FAYANEO-Retro-Mini-PC-AM01.html" target="_blank">官網</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 07:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269045/ayaneo-retro-mini-pc-am01</guid>
            <link>https://www.oschina.net/news/269045/ayaneo-retro-mini-pc-am01</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Turbo Pascal 誕生 40 年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Turbo Pascal <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.marcocantu.com%2Fblog%2F2023-november-turbopascal40.html" target="_blank">迎來了 40 歲生日</a></u>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-48365f6b4678042d953b96727360a44c28a.png" referrerpolicy="no-referrer"></p><p>1983 年 11 月 20 日，Borland 公司發佈了 Turbo Pascal 的第一個版本。<strong>該版本的編譯器核心部分由&nbsp;<span style="background-color:#ffffff; color:#333333">Anders Hejlsberg&nbsp;</span>授權給 Borland 公司</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-55fee9e8e268162cefc3a9f34a094250bdc.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwinworldpc.com%2Fproduct%2Fturbo-pascal%2F100" target="_blank">https://winworldpc.com/product/turbo-pascal/100</a></u></em></p><p>Anders Hejlsberg 為 MS-DOS 和 CP/M 設計了 Pascal 編譯器，Borland 買下該編譯器並改稱 <strong>Turbo Pascal</strong>，之後 Anders Hejlsberg 也加入了 Borland 公司，並且是後來所有 Turbo Pascal 版本與 Delphi 前 3 個版本的架構師。</p><p>再後來 Anders Hejlsberg 被比爾·蓋茨下重本挖到了微軟，先後創造了 Visual J++、.NET、C#&nbsp;和&nbsp;TypeScript。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f1f3c48731e272b9d855120589ccc1969de.png" referrerpolicy="no-referrer"></p><p>説回 Turbo Pascal，它作為一種結構化編程語言對計算機編程產生了重大影響，併成為了許多程序員的入門語言。</p><p>Turbo Pascal 的設計目標是提供一種易於學習和使用的編程語言，同時具有高效的編譯器和強大的功能。它採用了 Pascal 語言的語法和結構，但在性能和功能上進行了優化和擴展。Turbo Pascal 的編譯器非常快速，可以在幾秒鐘內將源代碼編譯成可執行文件。這使得程序員能夠快速地進行開發和調試。</p><p>Turbo Pascal 在教育領域也非常受歡迎。許多學校和大學使用 Turbo Pascal 作為計算機科學課程的教學工具。它的簡單易學的語法和清晰的結構使得初學者能夠快速上手，並理解編程的基本概念。</p><hr><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/130871/26-years-of-delphi" target="news">Delphi 26 歲</a></li><li><a href="https://www.oschina.net/news/241121/delphi-11-n-cbuilder-11-ce-released" target="news">Delphi 11 和 C++Builder 11 社區版發佈</a></li><li><a href="https://www.oschina.net/news/265941/rad-studio-12-athens" target="news">Delphi 12 &amp; C++ Builder 12、RAD Studio 12 發佈</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269027/turbo-pascal-turns-40</guid>
            <link>https://www.oschina.net/news/269027/turbo-pascal-turns-40</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Sailfish OS 開發商 Jolla 已被其前管理層收購]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>芬蘭科技公司 Jolla 的前管理層收購了 Jolla Ltd. 的全部業務和員工。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjolla.com%2Fcontent%2Fuploads%2F2023%2F11%2FFormer_leadership_buys_Jolla_Business_Pressrelease_271123_.pdf" target="_blank">根據 Jolla 發佈的新聞稿</a></u>，Jolla Ltd 專注於操作系統和汽車軟件的全部業務和員工將被轉移到一家新公司，這家新公司已被 Jolla 前管理層收購。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-a0fea2cd154728b4d75b4df0ee0fe5f1894.png" referrerpolicy="no-referrer"></p></blockquote><p>由於烏克蘭戰爭，<strong>俄羅斯在 Jolla 集團結構中的所有權成為員工和客户面臨的一個緊迫問題</strong>，最終導致該公司於 2023 年春季開始實施企業重組計劃。2023 年 11 月 24 日，Pirkanmaa 地方法院就重組計劃做出了決定，並責成將業務完全出售給另一家公司。目前 Jolla 的前管理層已經收購了該公司。</p><p>Jolla 是一家曾經致力於開發智能手機和平板電腦的公司，但是這些產品並沒有取得成功。後來 Jolla 將重心轉向了基於 Linux 的 Sailfish OS<span style="background-color:#ffffff; color:#333333">（旗魚）</span>，並將其應用於現有設備上。<span style="background-color:#ffffff; color:#333333">Sailfish OS 是由 Jolla 在 MeeGo 基礎上開發的移動操作系統。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-11949d06737c31b962048e00e7e15b11d7f.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7f799a724c401bfe3018e347c698e78405b.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><img height="1476" src="https://oscimg.oschina.net/oscnet/up-7b2f29a69cf34959186e9e7746927ce1a22.png" width="3226" referrerpolicy="no-referrer"></p><p>新公司將繼續致力於開發 Sailfish OS，並向全球客户銷售。他們還計劃將 Sailfish OS 引入新的「人工智能時代」。Jolla 還將通過自己的子公司 Seafarix 為汽車行業提供軟件。</p><p><strong>延伸閲讀：<em><u><a href="https://www.oschina.net/news/266231">俄羅斯操作系統 Aurora OS 5.0 全新 UI 亮相</a></u></em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269024/jolla-acquired-by-management</guid>
            <link>https://www.oschina.net/news/269024/jolla-acquired-by-management</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 表達式引擎選型調研分析]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><p><span style="letter-spacing: 1px;display: none;line-height: 0px;">‍‍</span></p><p style="margin-bottom: 24px;line-height: 1.6em;margin-top: 0px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.22676579925650558" src="https://oscimg.oschina.net/oscnet/73c34fc7-7990-4717-b675-aba8baad56ca.gif" data-type="gif" data-w="1076" style="" referrerpolicy="no-referrer"></p><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 編輯器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">一、簡介</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"></h1><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">我們項目組主要負責面向企業客户的業務系統，<strong>企業的需求往往是多樣化且複雜的，對接不同企業時會有不同的定製化的業務模型和流程</strong>。我們在業務系統中<strong>使用表達式引擎，集中配置管理業務規則，並實現實時決策和計算，可以提高系統的靈活性和響應能力</strong>，從而更好地滿足業務的需求。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">舉個簡單的例子，假設我們有一個業務場景，在返利系統中，當推廣員滿足一定的獎勵條件時，就會給其對應的獎勵金額。例如某個產品的具體獎勵規則如下：</span></section><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100024223" data-ratio="0.3739612188365651" data-s="300,640" src="https://oscimg.oschina.net/oscnet/1bb246c0-169f-4742-ab48-5956e774e993.png" data-type="png" data-w="361" style="" referrerpolicy="no-referrer"></p><section style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">這個規則看起來很好實現，只要在代碼裏寫幾個 if else 分支就可以了。但是如果返利系統對接了多家供應商，且每家提供的產品的獎勵規則都不同呢？再通過硬編碼的方式寫 if else 似乎就不太好了，每次增加修改刪除規則都需要系統發版上線。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">引入規則引擎似乎就能解決這個問題，規則引擎的一個好處就是可以使業務規則和業務代碼分離，從而降低維護難度，同時它還可以滿足業務人員通過編寫 DSL 或通過界面指定規則的訴求，這樣就可以在沒有開發人員參與的情況下建立規則了，這種説法聽起來似乎很有道理，但在實踐中卻很少行得通。首先，規則引擎有一定的學習成本，即使開發人員使用也需要進行專門的學習，更何況沒有任何編程背景的業務人員，其次，其實現的複雜度也高，如果業務規則複雜，規則制定者對規則引擎內部隱藏的程序流程不瞭解，很可能會得到意想不到的結果，最後，有些規則引擎還存在性能瓶頸。如果對規則引擎和表達式引擎都不熟悉，抽離的業務規則又需要由開發人員來制定，那麼<strong>相比之下表達式引擎就要容易上手得多，其語法更接近 Java，而且有些表達式引擎還會將表達式編譯成字節碼，在執行速度和資源利用方面可能就更有優勢。</strong>所以，對於此類業務場景，使用表達式引擎似乎更加合適一些。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">本文主要對 Java 表達式引擎進行概要性介紹和分析，並提供一定建議，為團隊研發過程中對錶達式引擎的技術選型提供輸入。</span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 編輯器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">二、技術棧簡介</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;visibility: visible;"></h1><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"></h2><section style="margin-top: 24px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;visibility: visible;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">本文將針對</span>AviatorScript 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>MVEL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>OGNL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>SpEL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>QLExpress 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>JEXL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">、</span>JUEL 
  <span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">幾種常見表達式引擎進行選型調研。先簡單介紹一下這幾種表達式引擎。</span></section><span id="OSC_h2_1"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.1 AviatorScript</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript 是一門高性能、輕量級寄宿於 JVM 之上的腳本語言。AviatorScript 可將表達式編譯成字節碼。它原來的定位一直只是一個表達式引擎，不支持 if/else 條件語句，也不支持 for/while 循環語句等，隨着 5.0 的發佈變身為一個通用腳本語言，支持了這些語言特性。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：https://www.yuque.com/boyan-avfmj/aviatorscript﻿</span></section><span id="OSC_h2_2"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.2 MVEL (MVFLEX Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">MVEL 是一種混合的動態/靜態類型的、可嵌入 Java 平台的表達式語言，MVEL 被眾多 Java 項目使用。MVEL 在很大程度上受到 Java 語法的啓發，但也有一些本質區別，目的是使其作為一種表達式語言更加高效，例如直接支持集合、數組和字符串匹配的操作符，以及正則表達式。最早版本發佈於 2007 年。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：http://mvel.documentnode.com/﻿</span></section><span id="OSC_h2_3"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.3 OGNL (Object-Graph Navigation Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">OGNL 是 Object-Graph Navigation Language（對象圖導航語言）的縮寫；它是一種表達式語言，用於獲取和設置 Java 對象的屬性，以及其他額外功能，如列表投影和選擇以及 lambda 表達式。於 2005 年發佈 2.1.4 版。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：https://commons.apache.org/dormant/commons-ognl/language-guide.html﻿</span></section><span id="OSC_h2_4"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.4 SpEL (Spring Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">SpEL 是一種功能強大的表達式語言，支持在運行時查詢和操作對象圖。該語言的語法與 Unified EL 相似，但提供了更多的功能，其中最主要的是方法調用和基本的字符串模板功能。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：https://docs.spring.io/spring-framework/docs/5.3.x/reference/html/core.html#expressions﻿</span></section><span id="OSC_h2_5"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.5 QLExpress</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由阿里的電商業務規則、表達式（布爾組合）、特殊數學公式計算（高精度）、語法分析、腳本二次定製等強需求而設計的一門動態腳本引擎解析工具，於 2012 年開源。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：https://github.com/alibaba/QLExpress﻿</span></section><span id="OSC_h2_6"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.6 JEXL (Java Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JEXL 旨在促進在 Java 編寫的應用程序和框架中實現動態腳本功能。JEXL 基於對 JSTL 表達式語言的一些擴展實現了一種表達式語言，支持 shell 腳本或 ECMAScript 中的大部分構想。1.0 版發佈於 2005 年。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：https://commons.apache.org/proper/commons-jexl/reference/syntax.html﻿</span></section><span id="OSC_h2_7"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.7 JUEL (Java Unified Expression Language)</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JUEL 是統一表達式語言 (EL) 的實現，該語言是 JSP 2.1 標準 (JSR-245) 的一部分，已在 JEE5 中引入。此外，JUEL 2.2 實現了 JSP 2.2 維護版本規範，完全符合 JEE6 標準。於 2006 年發佈 2.1.0 版本，2.2.7 發佈於 2014 年。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：https://juel.sourceforge.net/guide/start.html﻿</span></section><span id="OSC_h2_8"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.8 Janino</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">Janino 是一個超小、超快的 Java 編譯器，也可以用作表達式引擎，它的性能非常出色，根據官網介紹，Apache Spark、Apache Flink、Groovy 等優秀的開源項目都在用 Janino。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">文檔：http://janino-compiler.github.io/janino/﻿</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由於 Janino 實際是一個 Java 編譯器，理論上其性能應該更接近於直接執行 Java 代碼，其次作為表達式引擎使用起來比較複雜。因此，下面的對比中，Janino 不參與比較，可以將其作為一個參照。</span></section><span id="OSC_h2_9"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">2.9 其他</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如下一些表達式引擎雖然也常見於各技術博客，但由於長期沒有更新維護，因此沒有納入此次選型比較</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">Fel</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">Fel 是輕量級的高效的表達式計算引擎。Fel 源自於企業項目，設計目標是為了滿足不斷變化的功能需求和性能需求。項目託管於 Google Code，上次更新是 2012 年，已經十幾年沒有更新了，所以沒有納入此次選型。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">ik-expression</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">IK Expression 是一個開源的（OpenSource)，可擴展的（Extensible），基於 java 語言開發的一個超輕量級（Super lightweight）的公式化語言解析執行工具包。2009 年 2 月發佈第一個版本，2009 年 10 月發佈最後一個版本後再沒有新版本發佈，所以沒有納入此次選型。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">JSEL</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JSEL 是一個兼容 JavaScript 運算規則的簡單的表達式解釋引擎，你可以通過 Map 接口，或者 JavaBean 給出一個變量集合，能後通過表達式從這個集合中抽取變量，再通過表達式邏輯生成你需要的數據。2009 年發佈第一個版本，2011 年發佈最後一個版本後未再更新，所以沒有納入此次選型。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">此外規則引擎如 Drools， urule， easy-rules 不參與此次選型比較。相對比較成熟完善的腳本語言如 Groovy 也不參與選型比較。這篇文章主要針對相對輕量簡單的表達式引擎進行選型。</span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 編輯器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">三、技術棧選型評估</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"></h1><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">選擇表達式引擎，我們希望其社區支持情況良好、實現複雜度適中、執行速度快、安全並且簡單易學。所以，接下來將<strong>從社區支持情況、引入的大小和依賴、性能、安全性、使用案例和語法幾個方面對幾種表達式引擎進行比較評估。</strong></span></section><span id="OSC_h2_10"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.1 社區支持情況</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">社區支持情況可以輔助評估項目的健康度，有問題是不是能及時解決，項目是不是能持續演進等等</span></strong><span style="font-size: 15px;letter-spacing: 1px;">，下面列出了 GitHub star，watch，fork，last commit 等數據，可以作為參考，由於數據隨着時間推移會產生變化，以下僅針對 2023.10.29 的數據進行分析。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><img class="rich_pages wxw-img" data-imgfileid="100024219" data-ratio="0.28055555555555556" src="https://oscimg.oschina.net/oscnet/c39b5f24-498a-493f-a227-256df954a368.png" data-type="png" data-w="1080" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">﻿﻿由於 Spring 項目被廣泛使用，而 SpEl 又是 Spring 的一個子項目，所以從各項數據來看 SpEl 的社區支持情況是最好的。下面先排除 SpEl 分析其他幾個表達式引擎。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">QLExpress，AviatorScript 和 MVEL 在國內使用比較多，這可能是他們 star，watch，fork 數較高的原因。説明這幾個項目受歡迎度，受認可度，影響力應該較高。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">從 issues，pull requests 數來分析，可以看到 MVEL，AviatorScript 和 QLExpress 高於其他腳本引擎，説明他們的用户需求和反饋較多，也可能意味着項目面臨較多問題和挑戰。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">MVEL，JEXL，OGNL 均有較多貢獻者參與。他們的社區協作、項目可持續性方面應該都比較不錯。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">綜合以上分析，除 SpEl 外，QLExpress，AviatorScript 和 MVEL 的社區支持情況都相對較好。</span></strong></section><span id="OSC_h2_11"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.2 引入大小和依賴</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">代碼大小和依賴可以輔助評估代碼的複雜性，下面列出了各個 Github 倉庫的代碼大小，可以作為一個參考（實際並不完全準確反映其實現的複雜性）。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">以下是 2023.10.29 的數據</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024218" data-ratio="1.41635687732342" src="https://oscimg.oschina.net/oscnet/afac92d7-a244-4283-bc12-84e3f543152c.png" data-type="png" data-w="269" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">﻿﻿JUEL，QLExpress 代碼大小最小，都在 600 多 KB；其次是 OGNL 1MB 多一點；AviatorScript，MVEL，JEXL 大小都在 2MB 左右；SpEl 由於在 spring-framework 倉庫中，上表中統計的是 spring-framework 的總量，單純看 SpEl 的模塊 spring-expression 的話，大小是 1.3MB 左右。但是其還依賴了 spring-core 和 spring-jcl，再含這兩個的話，大小 7.4MB 左右。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">我們再結合各個項目的依賴來分析一下。</span></section><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="ruby"><code><span class="code-snippet_outer">+- org.mvel:mvel2:jar:2.5.0.Final:compile</span></code><code><span class="code-snippet_outer">+- com.googlecode.aviator:aviator:jar:5.3.3:compile</span></code><code><span class="code-snippet_outer">+- com.alibaba:QLExpress:jar:3.3.1:compile</span></code><code><span class="code-snippet_outer">|  +- commons-beanutils:commons-beanutils:jar:1.8.2:compile</span></code><code><span class="code-snippet_outer">|  |  \- (commons-logging:commons-logging:jar:1.1.1:compile - omitted for conflict with 1.2)</span></code><code><span class="code-snippet_outer">|  \- commons-lang:commons-lang:jar:2.4:compile</span></code><code><span class="code-snippet_outer">+- org.codehaus.janino:janino:jar:3.1.10:compile</span></code><code><span class="code-snippet_outer">|  \- org.codehaus.janino:commons-compiler:jar:3.1.10:compile</span></code><code><span class="code-snippet_outer">+- ognl:ognl:jar:3.4.2:compile</span></code><code><span class="code-snippet_outer">|  \- org.javassist:javassist:jar:3.29.2-GA:compile</span></code><code><span class="code-snippet_outer">+- org.apache.commons:commons-jexl3:jar:3.3:compile</span></code><code><span class="code-snippet_outer">|  \- commons-logging:commons-logging:jar:1.2:compile</span></code><code><span class="code-snippet_outer">+- org.springframework:spring-expression:jar:5.3.29:compile</span></code><code><span class="code-snippet_outer">|  \- org.springframework:spring-core:jar:5.3.29:compile</span></code><code><span class="code-snippet_outer">|     \- org.springframework:spring-jcl:jar:5.3.29:compile</span></code><code><span class="code-snippet_outer">+- de.odysseus.juel:juel-api:jar:2.2.7:compile</span></code><code><span class="code-snippet_outer">+- de.odysseus.juel:juel-impl:jar:2.2.7:compile</span></code><code><span class="code-snippet_outer">+- de.odysseus.juel:juel-spi:jar:2.2.7:compile</span></code></pre></section></pre><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">除了 SpEl 外，QLExpress，OGNL，JEXL 也都有其他依賴。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如果考慮 commons-beanutils， commons-lang， commons-logging 三個依賴，QLExpress 引入的大小在 10MB 左右。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如果考慮 javassist 依賴，OGNL 引入的大小是 4MB 多。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">如果考慮 commons-logging 依賴，JEXL 引入的大小是 2.5MB 左右。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">綜合來看，JUEL，AviatorScript，MVEL，JEXL 在引入大小和依賴方面要好於其他。</span></strong></section><span id="OSC_h2_12"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3 性能</span></strong></span></h2><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">較好的性能意味着系統能夠快速地響應用户的請求，減少等待時間，提升體驗。</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">性能方面主要通過 JMH 在字面量表達式、含有變量的表達式以及含有方法調用的表達式等使用場景對幾個表達式引擎進行測試。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">JMH（Java Microbenchmark Harness），是用於代碼微基準測試的工具套件，主要是基於方法層面的基準測試，精度可以達到納秒級。該工具是由 Oracle 內部實現 JIT 的大牛們編寫的，他們應該比任何人都瞭解 JIT 以及 JVM 對於基準測試的影響。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由於不同表達式引擎語法或特性稍有差別，下面測試中對於差異項會進行説明。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">性能測試代碼地址：</span><span style="letter-spacing: 1px;font-size: 15px;">GitHub</span><span style="font-size: 15px;">-https://github.com/howiefh/expression-engine-benchmark</span></section><span id="OSC_h3_13"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.1 字面量表達式</span></strong></h3><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024215" data-ratio="0.43444730077120824" src="https://oscimg.oschina.net/oscnet/57f87300-b4c2-48fe-bb02-d1bd3b156186.svg" data-type="svg" data-w="1556" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: left;"><span style="font-size: 15px;letter-spacing: 1px;text-align: justify;background-color: rgb(2, 30, 170);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;text-align: justify;">：1000 + 100.0 * 99 - (600 - 3 * 15) / (((68 - 9) - 3) * 2 - 100) + 10000 % 7 * 71</span></section><section style="line-height: 1.6em;margin-top: 16px;margin-bottom: 16px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(61, 170, 214);">&nbsp;&nbsp; </span><span style="font-size: 15px;letter-spacing: 1px;">：6.7 - 100 &gt; 39.6 ? 5 == 5 ? 4 + 5 : 6 - 1 : !(100 % 3 - 39.0 &lt; 27) ? 8 * 2 - 199 : 100 % 3</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">説明：</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">由於 QlExpress 執行第 2 個表達式時報錯，需要增加圓括號，實際執行的是 6.7 - 100 &gt; 39.6 ? (5 == 5 ? 4 + 5 : 6 - 1) : (!(100 % 3 - 39.0 &lt; 27) ? 8 * 2 - 199 : 100 % 3)</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">結果分析:</span></strong></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">可以明顯看到 JEXL，JUEL，QlExpress 這三個表達式引擎性能明顯不如其他引擎。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">SpEl 在執行第 1 個算數操作時表現出色，但是在執行第 2 個嵌套三元操作時明顯不如 AviatorScript，MVEL，OGNL 引擎。</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">此輪測試中 AviatorScript，OGNL，MVEL 表現出色。AviatorScript，OGNL 執行兩個表達式表現都比較出色，其中 AviatorScript 略好於 OGNL。MVEL 在執行第 1 個算數操作時表現最出色，但是在執行第 2 個嵌套三元操作時慢於 AviatorScript，OGNL 引擎。</span></section><span id="OSC_h3_14"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.2 含有變量的表達式</span></strong></h3><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024217" data-ratio="0.8046272493573264" src="https://oscimg.oschina.net/oscnet/cf08fbe6-72a8-45dc-bf9e-1303f1f07414.svg" data-type="svg" data-w="1556" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;"><span style="letter-spacing: 1px;background-color: rgb(2, 30, 170);">&nbsp; &nbsp;</span>：pi * d + b - (1000 - d * b / pi) / (pi + 99 - i * d) - i * pi * d / b</span><br></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(61, 170, 214);background-color: rgb(61, 170, 214);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：piDecimal * dDecimal + bDecimal - (1000 - dDecimal * bDecimal / piDecimal) / (piDecimal + 99 - iDecimal * dDecimal) - iDecimal * piDecimal * dDecimal / bDecimal</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(0, 128, 255);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：i * pi + (d * b - 199) / (1 - d * pi) - (2 + 100 - i / pi) % 99 == i * pi + (d * b - 199) / (1 - d * pi) - (2 + 100 - i / pi) % 99</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(0, 209, 0);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：(clientVersion == '1.9.0' || clientVersion == '1.9.1' || clientVersion == '1.9.2') &amp;&amp; deviceType == 'Xiaomi' &amp;&amp; weight &gt;= 4 &amp;&amp; osVersion == 'Android 9.0' &amp;&amp; osType == 'Android' &amp;&amp; clientIp != null &amp;&amp; requestTime &lt;= now&amp;&amp; customer.grade &gt; 1 &amp;&amp; customer.age &gt; 18</span></section><section style="margin-top: 24px;margin-bottom: 24px;line-height: 1.6em;"><span style="font-size: 15px;letter-spacing: 1px;">説明：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="font-size: 15px;"><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由於不同的表達式引擎在執行第 2 個表達式時底層實現除法時有所差別，MVEL，AviatorScript，JEXL 執行 decimal.divide(otherDecimal, java.math.MathContext.DECIMAL128)，其他實際執行的是 decimal.divide(otherDecimal, scale, roundingMode)，只是參數略有不同，分析時分組進行。</span></p></li><li style="font-size: 15px;"><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由於 QlExpress 執行第 3 個表達式時報錯，不支持非整型 mod 操作，需要增加類型轉換，實際執行的是 i * pi + (d * b - 199) / (1 - d * pi) - (int)(2 + 100 - i / pi) % 99 == i * pi + (d * b - 199) / (1 - d * pi) - (int)(2 + 100 - i / pi) % 99</span></p></li><li><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由於 A</span><span style="font-size: 15px;letter-spacing: 1px;">viatorScript 執行第 4 個表達式時報錯，null 的字面量是 nil，實際執行的是 (clientVersion == '1.9.0' || clientVersion == '1.9.1' || clientVersion == '1.9.2') &amp;&amp; deviceType == 'Xiaomi' &amp;&amp; weight &gt;= 4 &amp;&amp; osVersion == 'Android 9.0' &amp;&amp; osType == 'Android' &amp;&amp; clientIp != nil &amp;&amp; requestTime &lt;= now&amp;&amp; customer.grade &gt; 1 &amp;&amp; customer.age &gt; 18</span></p></li></ul><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">結果分析：</span></strong></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 1 個基本類型包裝類的算術計算 SpEl 最優。其次是 AviatorScript，MVEL，OGNL。而 JEXL，JUEL，QlExpress 則不如其他引擎。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 2 個 BigDecimal 類型的算術計算。由於底層實現不同，分為兩組。第 1 組 MVEL、AviatorScript 和 JEXL，AviatorScript 優於 MVEL 優於 JEXL。第 2 組 JUEL，QlExpress，OGNL 和 SpEl，性能由優到差依次是 OGNL，SpEl，JUEL，QlExpress。並且第 1 組由於精度更高，性能明顯都差於第 2 組。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 3 個含有基本類型包裝類算數計算的布爾表達式。SpEl 最優，AviatorScript 次之，接下來依次是 OGNL, MVEL，JUEL，JEXL，QlExpress。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">第 4 個含有字符串比較的布爾表達式。AviatorScript，MVEL，JEXL，OGNL 性能優於 JUEL，QlExpress，SpEl。</span></p><span id="OSC_h3_15"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.3 含有方法調用的表達式</span></strong></h3><p style="margin-top: 24px;margin-bottom: 24px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="100024216" data-ratio="0.6195372750642674" src="https://oscimg.oschina.net/oscnet/f7706f84-f707-493c-8470-1d59715d2194.svg" data-type="svg" data-w="1556" style="border-width: 0px;border-style: none;border-color: rgb(235, 238, 245);" referrerpolicy="no-referrer"></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(2, 30, 170);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：new java.util.Date()</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(61, 170, 214);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：s.substring(b.d)</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;background-color: rgb(0, 128, 255);">&nbsp; &nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;">：s.substring(b.d).substring(a, b.c.e)</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">説明：</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="font-size: 15px;"><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由於 JUEL 執行 new java.util.Date() 時報錯，不支持 new 實例，本輪實際執行的是自定義函數 fn:date()</span></p></li><li><p style="margin-top: 16px;margin-bottom: 16px;"><span style="letter-spacing: 1px;font-size: 15px;">由於 A</span><span style="font-size: 15px;letter-spacing: 1px;">viatorScript 執行 s.substring 時報錯，需使用其提供的內部函數，本輪實際執行的是其內部函數 string.substring</span></p></li></ul><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">結果分析：</span></strong></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">此輪測試中 SpEl 的表現最優，甚至比 Janino 還要快。MVEL，AviatorScript 次之，在執行構造方法時 MVEL 要好於 AviatorScript。JEXL 表現也比較出色。QlExpress，JUEL，OGNL 這三個表達式引擎則不如其他引擎。</span></p><span id="OSC_h3_16"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.3.4 總結</span></strong></h3><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">綜合以上測試結果，AviatorScript，SpEl，MVEL，OGNL 性能表現相對較好。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript 性能相對較好，表現均衡，但其語法相較其他引擎跟 Java 的差異略大。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">SpEl 除了在個別場景下性能較差，大部分場景表現非常出色，尤其是在字面量和含有變量的算數計算及方法調用場景下。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">MVEL 性能表現相對均衡，含有變量的算術計算略差於 AviatorScript，其在字面量算術計算，方法調用場景下表現都非常出色。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">OGNL 性能表現也相對均衡，但方法調用場景下表現不佳。</span></p><span id="OSC_h2_17"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><span style="color: rgb(2, 30, 170);"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.4 安全</span></strong></span></h2><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">引入表達式引擎，應該重視系統的安全性和可靠性，比如要防止在不可信環境中被注入惡意腳本，越權執行某些系統命令或使應用停止服務等。</span></strong><span style="font-size: 15px;letter-spacing: 1px;">安全性方面主要通過漏洞披露、安全指南和配置比較幾種表達式引擎。</span></p><span id="OSC_h3_18"></span><h3 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.4.1 漏洞</span></strong></h3><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">首先在 https://cve.mitre.org/cve/search_cve_list.html 通過關鍵字搜索的方式粗略瞭解一下不同表達式引擎被公開的漏洞。這種方式可能不是非常的準確，由於不同表達式引擎的使用場景、使用方式、關注度的不同可能導致被公開的漏洞存在差異。比如我們所熟悉的 OGNL、SpEl 的關鍵字出現在漏洞中的頻率明顯高於其他表達式引擎。OGNL 在 MyBatis 和 Struts 中被使用，SpEl 則在 Spring 中被廣泛使用，這兩個表達式引擎會被大部分項目間接使用，直接將用户輸入作為表達式的一部分執行，很容易導致出現漏洞。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">我們<strong>可以從這些公佈的漏洞中瞭解不同表達式引擎可能存在的安全隱患及其修復情況，在使用過程中儘可能避免出現類似問題。</strong></span></p><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">此外，不推薦將表達式執行直接開放到不可信的環境，如果確實需要，應該詳細瞭解選擇的表達式引擎，是否提供了必要的設置選項可以避免某些安全隱患。</span></strong></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100024222" data-ratio="0.5028901734104047" data-s="300,640" src="https://oscimg.oschina.net/oscnet/3f83fb13-b9be-47be-bbef-ecbcbf8b045c.png" data-type="png" data-w="519" style="" referrerpolicy="no-referrer"></p><p><strong><span style="font-size: 15px;letter-spacing: 1px;">3.4.2 安全設置</span></strong><br></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript，QLExpress，JEXL 均從不同程度提供了一些安全選項設置。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">AviatorScript</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">設置白名單</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="php"><code><span class="code-snippet_outer">// 在 new 語句和靜態方法調用中允許使用的類白名單，默認 null 表示無限制</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.ALLOWED_CLASS_SET, Sets.newHashSet(List.class));</span></code><code><span class="code-snippet_outer">// 在 new 語句和靜態方法調用中允許使用的類白名單，包含子類，默認 null 表示無限制</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.ASSIGNABLE_ALLOWED_CLASS_SET, Sets.newHashSet(List.class));</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">防止死循環</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">// 循環最大次數，默認 0 表示無限制</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.MAX_LOOP_COUNT, 10000);</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">特性開關</span></p></li></ul><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="php"><code><span class="code-snippet_outer">// 關閉某些特性</span></code><code><span class="code-snippet_outer">AviatorEvaluator.getInstance().disableFeature(Feature.Module);</span></code><code><span class="code-snippet_outer">AviatorEvaluator.getInstance().disableFeature(Feature.NewInstance);</span></code><code><span class="code-snippet_outer">// 只開啓需要的特性</span></code><code><span class="code-snippet_outer">AviatorEvaluator.setOption(Options.FEATURE_SET, Feature.asSet(Feature.If));</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">QLExpress</span></strong></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">開啓沙箱模式</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">QLExpressRunStrategy.setSandBoxMode(true);</span></code></pre></section></pre><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">在沙箱模式中，不可以：</span></p><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">import Java 類</span></section><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">顯式引用 Java 類，比如 String a = 'mmm'</span></section><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">取 Java 類中的字段：a = new Integer(11); a.value</span></section><section style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">調用 Java 類中的方法：Math.abs(12)</span></section><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">可以：</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">使用 QLExpress 的自定義操作符/宏/函數，以此實現與應用的受控交互</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">使用. 操作符獲取 Map 的 key 對應的 value，比如 a 在應用傳入的表達式中是一個 Map，那麼可以通過 a.b 獲取</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">所有不涉及應用 Java 類的操作</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">設置白名單</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="swift"><code><span class="code-snippet_outer">// 設置編譯期白名單</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.setCompileWhiteCheckerList(Arrays.asList(</span></code><code><span class="code-snippet_outer">    // 精確設置</span></code><code><span class="code-snippet_outer">    CheckerFactory.must(Date.class),</span></code><code><span class="code-snippet_outer">    // 子類設置</span></code><code><span class="code-snippet_outer">    CheckerFactory.assignable(List.class)</span></code><code><span class="code-snippet_outer">));</span></code><code><span class="code-snippet_outer">// 設置運行時白名單// 必須將該選項設置為 true</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.setForbidInvokeSecurityRiskMethods(true);</span></code><code><span class="code-snippet_outer">// 有白名單設置時, 則黑名單失效</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.addSecureMethod(RiskBean.class, "secureMethod");</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">設置黑名單</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="swift"><code><span class="code-snippet_outer">// 必須將該選項設置為 true</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.setForbidInvokeSecurityRiskMethods(true);</span></code><code><span class="code-snippet_outer">// 這裏不區分靜態方法與成員方法, 寫法一致</span></code><code><span class="code-snippet_outer">// 不支持重載, riskMethod 的所有重載方法都會被禁止</span></code><code><span class="code-snippet_outer">QLExpressRunStrategy.addSecurityRiskMethod(RiskBean.class, "riskMethod");</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">QLExpess 目前默認添加的黑名單有：</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.System.exit</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.Runtime.exec</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.ProcessBuilder.start</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.Method.invoke</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.Class.forName</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.ClassLoader.loadClass</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span data-w-e-reserve="true" style="border-width: 0px;border-style: solid;border-color: rgb(235, 238, 245);">◦</span><span style="font-size: 15px;letter-spacing: 1px;">java.lang.reflect.ClassLoader.findClass</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">防止死循環</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">//可通過 timeoutMillis 參數設置腳本的運行超時時間:1000ms</span></code><code><span class="code-snippet_outer">Object r = runner.execute(express, context, null, true, false, 1000);</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><p style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">JEXL</span></strong></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">使用沙箱</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">// 使用中應該通過 JexlSandbox 的重載構造方法進行配置</span></code><code><span class="code-snippet_outer">new JexlBuilder().sandbox(new JexlSandbox()).create();</span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">設置白名單權限</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="css"><code><span class="code-snippet_outer">new JexlBuilder().permissions(JexlPermissions.RESTRICTED.compose("com.jd.*")).create();</span></code></pre></section></pre><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">特性開關</span></p></li></ul><pre data-slate-node="element" data-slate-inline="false"><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="javascript"><code><span class="code-snippet_outer">// 關閉循環、new 實例，import 等特性</span></code><code><span class="code-snippet_outer">new JexlBuilder().features(new JexlFeatures().loops(false).newInstance(false).importPragma(false)).create();</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section></pre><span id="OSC_h2_19"></span><h2 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"><strong><span style="font-size: 15px;letter-spacing: 1px;">3.5 使用案例</span></strong></h2><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">從業界使用情況可以瞭解不同表達式引擎的可行性、生態和整合性，以及最佳實踐，進而借鑑。從下表可以看到 AviatorScript，MVEL，QLExpress 在國內業務線均有使用案例，有些企業也有文章輸出，我們可以借鑑使用。</span></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100024221" data-ratio="0.8702064896755162" data-s="300,640" src="https://oscimg.oschina.net/oscnet/7351a73e-f1e0-4db3-a3d3-b3fe2ca7815b.png" data-type="png" data-w="339" style="" referrerpolicy="no-referrer"></p><p><strong style="color: rgb(2, 30, 170);font-size: 16px;letter-spacing: 0.034em;"><span style="font-size: 15px;letter-spacing: 1px;">3.6 語法</span></strong><br></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">易於理解和使用的語法可以提高開發效率，並降低學習成本。接下來從類型、操作符、控制語句、集合、方法定義幾方面比較一下不同表達式引擎的語法設計。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">類型方面，AviatorScript 設計了特有的類型，使用時需要注意其類型轉換的優先級 long-&gt;bigint-&gt;decimal-&gt;double。AviatorScript、MVEL、OGNL、JEXL 都支持 BigInteger、BigDecimal 字面量，這意味着進行精確計算時可以使用字面量，將更方便，如 10.24B 就表示一個 BigDecimal 字面量（AviatorScript 中 BigDecimal 字面量後綴是 M）。此外 AviatorScript、QLExpress 還支持高精度計算的設置項。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">操作符方面，QLExpress 支持替換、自定義操作符及添加操作符別名，這可能有助於簡化複雜表達式或使表達式更加直觀，不過添加預置函數應該可以達到差不多的效果。AviatorScript 也支持自定義部分操作符，不過支持數量相當有限。AviatorScript、SpEl、JEXL 支持正則匹配操作符。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">控制語句方面，除 OGNL、SpEl、JUEL 不支持控制語句外，其他都支持，不過需要注意 AviatorScript 的 else if 語法有些特殊寫作 elsif，foreach 語句跟 Java 也有所不同。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">集合方面，除 JUEL 外其他都提供了快捷定義的方式，只不過語法不同。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">函數定義方面，SpEl、JUEL 均不支持，OGNL 支持偽 lambda 定義，其他都支持定義函數。QLExpress 不支持定義 lambda。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">綜合來看，和 Java 語法都或多或少存在一些差異。<strong>AviatorScript 設計了自己特有的一些語法，使用的話需要熟悉一下。QLExpress 支持自定義操作符，可以使表達式看起來更直觀。MVEL、JEXL 的語法可能更接近 Java，讓人更容易接受一些。OGNL、SpEl、JUEL 的語法更簡單一些，不支持控制語句和函數定義，當然也可以通過預置一些函數變通解決一些較複雜的問題。</strong></span></p><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section data-role="paragraph" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section data-role="outer" label="edit by 135editor" style="outline: 0px;visibility: visible;"><section data-role="title" data-tools="135 編輯器" data-id="114995" style="margin-bottom: 24px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, Arial, sans-serif;visibility: visible;"><section style="margin: 20px auto;outline: 0px;visibility: visible;"><section style="outline: 0px;display: flex;justify-content: flex-start;visibility: visible;"><section style="outline: 0px;display: flex;align-items: center;visibility: visible;"><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;background-color: rgb(10, 77, 209);height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="outline: 0px;color: rgb(34, 34, 34);font-size: 16px;width: 5px;height: 41.5938px;overflow: hidden;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section style="padding: 8px 30px;outline: 0px;background-image: linear-gradient(to left, transparent 0%, transparent 50%, rgb(198, 217, 240) 100%);background-position: initial;background-size: initial;background-repeat: initial;background-attachment: initial;background-origin: initial;background-clip: initial;visibility: visible;"><span style="outline: 0px;color: rgb(2, 30, 170);font-size: 15px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">四、選型建議</strong></span></section></section></section></section></section></section></section></section><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 24px;"></h1><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">社區方面，SpEl 無疑是最活躍的。AviatorScript，QLExpress，MVEL 在國內很受歡迎，QLExpress 有阿里背書。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">代碼大小和依賴方面，AviatorScript，MVEL 依賴少，並且代碼大小也偏小。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">性能方面，如果你使用表達式引擎執行字面量算術計算或方法調用偏多可以選用 SpEl，MVEL。如果希望整體性能表現較好可以選用 AviatorScript。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">安全方面，如果想自定義安全選項，可以考慮 AviatorScript，QLExpress 和 JEXL。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">使用案例方面，AviatorScript，MVEL，QLExpress 在國內都有實際使用案例可循。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">語法方面，可能存在一些主觀因素，僅供參考，個人覺得 MVEL、JEXL 的語法設計使用起來會更容易一些。</span></p><p style="margin-top: 24px;margin-bottom: 24px;"><span style="font-size: 15px;letter-spacing: 1px;">通過對以上幾個方面的評估和分析，希望可以幫助團隊基於自身情況及偏好選擇最適合自己項目的 Java 表達式引擎。</span></p><span id="OSC_h1_20"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 24px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">參考資料</span></h1><span id="OSC_h1_21"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[1]</span><span style="outline: 0px;">&nbsp;QLExpress：</span></span><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">https://github.com/alibaba/QLExpress﻿</span></h1><span id="OSC_h1_22"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">[2] AviatorScript：https://github.com/killme2008/aviatorscript﻿</span></h1><span id="OSC_h1_23"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">[3] MVEL：https://github.com/mvel/mvel﻿</span></h1><span id="OSC_h1_24"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">[4] OGNL：https://github.com/orphan-oss/ognl﻿</span></h1><span id="OSC_h1_25"></span><h1 data-slate-node="element" data-slate-inline="false" style="margin-top: 8px;margin-bottom: 8px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="outline: 0px;">[5]&nbsp;SpEl</span>：</span><span style="outline: 0px;color: rgb(136, 136, 136);font-size: 15px;">https://github.com/spring-projects/spring-framework</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">﻿</span></h1><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">[6]&nbsp;</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">Janino：</span><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/janino-compiler/janino</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[7]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">JUEL：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/beckchr/juel</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[8]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">JEXL：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/apache/commons-jexl</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[9]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">Fel：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://github.com/dbcxy/fast-el</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">﻿</span></span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">[10]&nbsp;</span><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">ik-expression：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://code.google.com/archive/p/ik-expression/</span></span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">﻿</span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">[11]&nbsp;</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">JS</span><span style="color: rgb(136, 136, 136);font-size: 15px;"><span style="color: rgb(136, 136, 136);outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;">EL：</span><span style="color: rgb(136, 136, 136);outline: 0px;">https://code.google.com/archive/p/lite/wikis/JSEL.wiki</span></span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">﻿</span></p><p style="outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.6em;margin-top: 8px;margin-bottom: 8px;"><span style="color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">[1]&nbsp;</span><span style="outline: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 15px;">JMH：https://www.cnblogs.com/wupeixuan/p/13091381.html</span></p><p style="margin-top: 8px;margin-bottom: 8px;"><span style="display: none;line-height: 0px;">‍</span></p><section style="margin-bottom: 8px;margin-top: 32px;text-align: center;"><span style="color: rgb(136, 136, 136);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 255);">-end-</span></section><section class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzU1OTgxMTg2Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/9K73WSRq6BWyKqhKFzMgibicMuLCqmmqWpOmQ2tovCBswRKVxdO6zaiarVIPc83MibTauxLibnACJWk48ibUyAXBF7dw/0?wx_fmt=png" data-nickname="京東雲開發者" data-alias="JDT_Developers" data-signature="京東雲開發者（Developer of JD Technology）是京東科技集團旗下為 AI、雲計算、IoT 等相關領域開發者提供技術分享交流的平台。平台將發佈京東產品技術信息、行業技術內容、技術活動等資訊。擁抱技術，與開發者攜手預見未來！" data-from="0" data-is_biz_ban="0"></mp-common-profile></section><p><span style="letter-spacing: 1px;display: none;line-height: 0px;">‍</span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - 京東雲開發者（JDT_Developers）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10315584</guid>
            <link>https://my.oschina.net/u/4090830/blog/10315584</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JumpServer 開源堡壘機 V2 社區版即將停止維護]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">尊敬的 JumpServer 開源堡壘機用户：您好！</p><p style="color:#000000; text-align:start">如《關於 JumpServer 開源堡壘機 V2 版本產品生命週期的相關説明》所示，<span style="color:#3e3e3e">JumpServer 開源堡壘機 V2 版本（社區版）將於</span><strong><span style="color:#28937c">2023 年 12 月 31 日</span></strong>停止維護支持。</p><p style="color:#000000; text-align:start">在過去兩年多的時間裏，JumpServer 開源堡壘機 V2 版本獲得了眾多用户的支持和喜愛。出於產品自身迭代和用户需求升級的要求，<strong>2023 年 2 月 27 日，JumpServer 開源堡壘機正式發佈 v3.0 版本，目前已更新至 v3.9.2 版本。</strong>JumpServer 開源項目組<strong><span style="color:#28937c">建議社區版和企業版用户更新至 JumpServe v3.x 版本</span></strong>，以使用更多的新增功能並獲取更好的軟件使用體驗。</p><p style="color:#000000; text-align:start">JumpServer V2 版本（企業版）維護支持截止日期為<strong><span style="color:#28937c">2025 年 12 月 31 日</span></strong>。</p><p style="color:#000000; text-align:start">aJumpServer 開源堡壘機 V2 版本產品生命週期具體如下，廣大用户可以根據時間表合理安排系統升級及遷移工作。</p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3c2a04eded6684a1a8f9948a1e26454f4ef.jpg" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><span>▲ JumpServer 開源堡壘機 V2 版本產品生命週期</span></p><p style="color:#000000; text-align:start">感謝您長期以來對 JumpServer 開源項目的支持與厚愛。如果您在升級過程中遇到問題，可以聯繫 JumpServer 開源項目組獲取升級建議和指導。</p><p style="color:#000000; text-align:right"><span><span style="color:#000000">JumpServer 開源項目組</span></span></p><p style="color:#000000; text-align:right"><span><span style="color:#000000">2023 年 12 月 1 日</span></span></p><p style="color:#000000; text-align:start"><span><strong><span style="color:#000000">關於 JumpServer 開源堡壘機</span></strong></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">JumpServer（jumpserver.org）是廣受歡迎的開源堡壘機，遵循 GPL v3 開源許可協議，是符合 4A（包含認證 Authentication 、授權 Authorization、 賬號 Accounting 和審計 Auditing）規範的運維安全審計系統。它通過企業版或者軟硬件一體機的方式，向企業級用户交付開源增值的運維安全審計解決方案。</span></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">JumpServer 開源堡壘機在分佈式架構設計、多雲環境支持、大規模資產納管、容器化部署、使用體驗等方面極具領先性，能夠很好地滿足企業用户在混合 IT 環境中運維安全審計需求。</span></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">目前，JumpServer 開源項目在代碼託管平台 Github 上的 Star 數量已經超過 22,400 個。在中國的企業用户羣中，JumpServer 堡壘機擁有廣泛的安裝基礎，社區版軟件的累計安裝部署次數超過 250,000 次，用户遍及金融、製造、物流、媒體、互聯網等各行各業。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 06:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/10315623</guid>
            <link>https://my.oschina.net/u/4736111/blog/10315623</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里雲開源通義千問 720 億參數模型 Qwen-72B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今天，阿里雲舉辦通義千問發佈會，開源通義千問 720 億參數模型 Qwen-72B。</p><p>地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fqwen%2FQwen-72B%2Fsummary" target="_blank">https://modelscope.cn/models/qwen/Qwen-72B/</a></u></em></p><p>據介紹，Qwen-72B 在 10 個權威基準測評創下開源模型最優成績，<strong>成為業界最強開源大模型</strong>，性能超越開源標杆 Llama 2-70B 和大部分商用閉源模型。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dbe96cabe4027456789b8a9e0043edf0f57.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-dbb7cbd494ee0a9564f0102e1d5aa832bb9.png" referrerpolicy="no-referrer"></p><p>通義千問-72B (Qwen-72B) 主要特性：</p><ol><li><strong>大規模高質量訓練語料</strong>：使用超過 3 萬億 tokens 的數據進行預訓練，包含高質量中、英、多語言、代碼、數學等數據，涵蓋通用及專業領域的訓練語料。通過大量對比實驗對預訓練語料分佈進行了優化。</li><li><strong>強大的性能</strong>：Qwen-72B 在多箇中英文下游評測任務上（涵蓋常識推理、代碼、數學、翻譯等），效果顯著超越現有的開源模型。具體評測結果請詳見下文。</li><li><strong>覆蓋更全面的詞表</strong>：相比目前以中英詞表為主的開源模型，</li></ol><p>通義千問還開源了 18 億參數模型 Qwen-1.8B 和音頻大模型 Qwen-Audio。至此，通義千問共開源 18 億、70 億、140 億、720 億參數的 4 款大語言模型，以及視覺理解、音頻理解兩款多模態大模型，實現「全尺寸、全模態」開源。</p><p><img height="727" src="https://static.oschina.net/uploads/space/2023/1201/134056_Rt7C_2720166.png" width="1280" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1201/134308_ZNwt_2720166.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlFeZToVywbkDUvKhsrKY7A" target="_blank">https://mp.weixin.qq.com/s/lFeZToVywbkDUvKhsrKY7A</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 05:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/269015</guid>
            <link>https://www.oschina.net/news/269015</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Rust std fs 比 Python 慢！真的嗎！？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>作者：Xuanwo</p><p>Databend Labs 成員，數據庫研發工程師</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxuanwo" target="_blank">https://github.com/xuanwo</a></p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-380bdbcb15f94b1c42039337e7daa46badb.png" alt="" referrerpolicy="no-referrer"></p><p>我即將分享一個冗長的故事，從 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal" target="_blank">OpenDAL</a> 的 <code>op.read()</code>開始，以一個意想不到的轉折結束。這個過程對我來説非常有啓發性，我希望你也能感受到。我會盡力重現這個經歷，並附上我一路學到的教訓。讓我們開始吧！</p><blockquote><p>所有的代碼片段和腳本都可以在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow" target="_blank">Xuanwo/when-i-find-rust-is-slow</a> 中找到。</p></blockquote><h2>OpenDAL Python 綁定比 Python 慢？</h2><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal" target="_blank">OpenDAL</a> 是一個數據訪問層，允許用户以統一的方式從各種存儲服務中輕鬆高效地獲取數據。我們通過 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FPyO3%2Fpyo3" target="_blank">pyo3</a> 為 OpenDAL 提供了 python 綁定。</p><p>有一天，@beldathas 在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscord.com%2Fchannels%2F1081052318650339399%2F1174840499576770560" target="_blank">discord</a> 向我報告了一個案例，即 OpenDAL 的 python 綁定比 python 慢：</p><pre><code>import&nbsp;pathlib
import&nbsp;timeit

import&nbsp;opendal

root&nbsp;=&nbsp;pathlib.Path(__file__).parent
op&nbsp;=&nbsp;opendal.Operator("fs",&nbsp;root=str(root))
filename&nbsp;=&nbsp;"lorem_ipsum_150mb.txt"

def&nbsp;read_file_with_opendal()&nbsp;-&gt;&nbsp;bytes:
&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;op.open(filename,&nbsp;"rb")&nbsp;as&nbsp;fp:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fp.read()
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;result

def&nbsp;read_file_with_normal()&nbsp;-&gt;&nbsp;bytes:
&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;open(root&nbsp;/&nbsp;filename,&nbsp;"rb")&nbsp;as&nbsp;fp:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fp.read()
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;result

if&nbsp;__name__&nbsp;==&nbsp;"__main__":
&nbsp;&nbsp;&nbsp;&nbsp;print("normal:&nbsp;",&nbsp;timeit.timeit(read_file_with_normal,&nbsp;number=100))
&nbsp;&nbsp;&nbsp;&nbsp;print("opendal:&nbsp;",&nbsp;timeit.timeit(read_file_with_opendal,&nbsp;number=100))
</code></pre><p>結果顯示</p><pre><code>(venv)&nbsp;$&nbsp;python&nbsp;benchmark.py
normal:&nbsp;&nbsp;4.470868484000675
opendal:&nbsp;&nbsp;8.993250704006641
&nbsp;&nbsp;&nbsp;&nbsp;
</code></pre><p>Emmm，我對這些結果有點尷尬。以下是一些快速的假設：</p><ul><li><p>Python 是否有內部緩存可以重複使用相同的內存？</p></li><li><p>Python 是否擁有加速文件讀取的一些技巧？</p></li><li><p>PyO3 是否引入了額外的開銷？</p></li></ul><p>我將代碼重構如下：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fpython-fs-read%2Ftest.py" target="_blank">python-fs-read</a></p><pre><code>with&nbsp;open("/tmp/file",&nbsp;"rb")&nbsp;as&nbsp;fp:
&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fp.read()
assert&nbsp;len(result)&nbsp;==&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024
</code></pre><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fpython-opendal-read%2Ftest.py" target="_blank">python-opendal-read</a></p><pre><code>import&nbsp;opendal

op&nbsp;=&nbsp;opendal.Operator("fs",&nbsp;root=str("/tmp"))

result&nbsp;=&nbsp;op.read("file")
assert&nbsp;len(result)&nbsp;==&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024
</code></pre><p>結果顯示，Python 比 OpenDAL 快得多：</p><pre><code>Benchmark&nbsp;1:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.9&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.7&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.6&nbsp;ms,&nbsp;System:&nbsp;10.1&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;14.9&nbsp;ms&nbsp;…&nbsp;&nbsp;21.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;180&nbsp;runs
&nbsp;&nbsp;
Benchmark&nbsp;2:&nbsp;python-opendal-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;32.9&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;1.3&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;6.1&nbsp;ms,&nbsp;System:&nbsp;26.6&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;31.4&nbsp;ms&nbsp;…&nbsp;&nbsp;42.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;85&nbsp;runs
&nbsp;&nbsp;
Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;2.07&nbsp;±&nbsp;0.12&nbsp;times&nbsp;faster&nbsp;than&nbsp;python-opendal-read/test.py
</code></pre><p>OpenDAL 的 Python 綁定似乎比 Python 本身運行得更慢，這並不是個好消息。讓我們來探究其背後的原因。</p><h2>OpenDAL Fs 服務比 Python 慢？</h2><p>這個謎題涉及到許多元素，如 rust、opendal、python、pyo3 等。讓我們集中精力嘗試找出根本原因。</p><p>我在 rust 中通過 opendal fs 服務實現了相同的邏輯：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Frust-opendal-fs-read%2Fsrc%2Fmain.rs" target="_blank">rust-opendal-fs-read</a></p><pre><code>use&nbsp;std::io::Read;
use&nbsp;opendal::services::Fs;
use&nbsp;opendal::Operator;

fn&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;cfg&nbsp;=&nbsp;Fs::default();
&nbsp;&nbsp;&nbsp;&nbsp;cfg.root("/tmp");
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;op&nbsp;=&nbsp;Operator::new(cfg).unwrap().finish().blocking();

&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;bs&nbsp;=&nbsp;vec![0;&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024];

&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;f&nbsp;=&nbsp;op.reader("file").unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;ts&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;loop&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;buf&nbsp;=&nbsp;&amp;mut&nbsp;bs[ts..];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;f.read(buf).unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;n&nbsp;as&nbsp;usize;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;0&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ts&nbsp;+=&nbsp;n;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;assert_eq!(ts,&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024);
}
</code></pre><p>然而，結果顯示即使 opendal 是用 rust 實現的，它的速度仍然比 python 慢：</p><pre><code>Benchmark&nbsp;1:&nbsp;rust-opendal-fs-read/target/release/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.8&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;2.0&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.4&nbsp;ms,&nbsp;System:&nbsp;23.4&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;21.8&nbsp;ms&nbsp;…&nbsp;&nbsp;34.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;121&nbsp;runs
&nbsp;
Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.6&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.5&nbsp;ms,&nbsp;System:&nbsp;10.0&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;14.4&nbsp;ms&nbsp;…&nbsp;&nbsp;20.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;166&nbsp;runs
&nbsp;
Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.52&nbsp;±&nbsp;0.15&nbsp;times&nbsp;faster&nbsp;than&nbsp;rust-opendal-fs-read/target/release/test
</code></pre><p>雖然&nbsp; rust-opendal-fs-read&nbsp;的表現略優於 python-opendal-read，這暗示了在綁定和 pyo3 中有改進的空間，但這些並非核心問題。我們需要進一步深入探究。</p><p>啊，opendal fs 服務比 python 慢。</p><h2>Rust std fs 比 Python 慢？</h2><p>OpenDAL 通過 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fstd%2Ffs%2Findex.html" target="_blank">std::fs</a> 實現文件系統服務。OpenDAL 本身會產生額外的開銷嗎？</p><p>我使用 <code>std::fs</code> 在 Rust 中實現了相同邏輯：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Frust-std-fs-read%2Fsrc%2Fmain.rs" target="_blank">rust-std-fs-read</a></p><pre><code>use&nbsp;std::io::Read;
use&nbsp;std::fs::OpenOptions;

fn&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;bs&nbsp;=&nbsp;vec![0;&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024];
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;f&nbsp;=&nbsp;OpenOptions::new().read(true).open("/tmp/file").unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;ts&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;loop&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;buf&nbsp;=&nbsp;&amp;mut&nbsp;bs[ts..];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;f.read(buf).unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;n&nbsp;as&nbsp;usize;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;0&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ts&nbsp;+=&nbsp;n;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;assert_eq!(ts,&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024);
}
</code></pre><p>但是：</p><pre><code>Benchmark&nbsp;1:&nbsp;rust-std-fs-read/target/release/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.1&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;2.5&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.3&nbsp;ms,&nbsp;System:&nbsp;22.8&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;21.0&nbsp;ms&nbsp;…&nbsp;&nbsp;37.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;124&nbsp;runs
&nbsp;
Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.2&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;1.1&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.4&nbsp;ms,&nbsp;System:&nbsp;9.7&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;14.3&nbsp;ms&nbsp;…&nbsp;&nbsp;21.4&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;178&nbsp;runs

Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.52&nbsp;±&nbsp;0.20&nbsp;times&nbsp;faster&nbsp;than&nbsp;rust-std-fs-read/target/release/test
</code></pre><p>哇，Rust 的 std fs 比 Python 還慢？這怎麼可能呢？無意冒犯，但是這怎麼可能呢？</p><h2>Rust std fs 比 Python 還慢？真的嗎！？</h2><p>我無法相信這個結果：Rust std fs 的速度竟然比 Python 還要慢。</p><p>我嘗試學會瞭如何使用 <code>strace</code>&nbsp;進行系統調用分析。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstrace.io%2F" target="_blank"><code>strace</code></a>是一個 Linux 系統調用追蹤器，它讓我們能夠監控系統調用並理解其過程。</p><p>strace 將包含程序發出的所有系統調用。我們應該關注與<code>/tmp/file</code>&nbsp;相關的方面。每一行 strace 輸出都以系統調用名稱開始，後跟輸入參數和輸出。</p><p>比如：</p><pre><code>openat(AT_FDCWD,&nbsp;"/tmp/file",&nbsp;O_RDONLY|O_CLOEXEC)&nbsp;=&nbsp;3
</code></pre><p>這意味着我們使用參數 <code>AT_FDCWD</code>，<code>"/tmp/file"</code> 和 <code>O_RDONLY|O_CLOEXEC</code>調用 <code>openat</code>系統調用。這將返回輸出 <code>3</code> ，這是在後續的系統調用中引用的文件描述符。</p><p>好了，我們已經掌握了 <code>strace</code>。讓我們開始使用它吧！</p><p><code>rust-std-fs-read</code> 的 strace:</p><pre><code>&gt;&nbsp;strace&nbsp;./rust-std-fs-read/target/release/test
...
mmap(NULL,&nbsp;67112960,&nbsp;PROT_READ|PROT_WRITE,&nbsp;MAP_PRIVATE|MAP_ANONYMOUS,&nbsp;-1,&nbsp;0)&nbsp;=&nbsp;0x7f290dd40000
openat(AT_FDCWD,&nbsp;"/tmp/file",&nbsp;O_RDONLY|O_CLOEXEC)&nbsp;=&nbsp;3
read(3,&nbsp;"\tP\201A\225\366&gt;\260\270R\365\313\220{E\372\274\6\35\"\353\204\220s\2|7C\205\265\6\263"...,&nbsp;67108864)&nbsp;=&nbsp;67108864
read(3,&nbsp;"",&nbsp;0)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
munmap(0x7f290dd40000,&nbsp;67112960)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
...
</code></pre><p><code>python-fs-read</code> 的 strace:</p><pre><code>&gt;&nbsp;strace&nbsp;./python-fs-read/test.py
...
openat(AT_FDCWD,&nbsp;"/tmp/file",&nbsp;O_RDONLY|O_CLOEXEC)&nbsp;=&nbsp;3
newfstatat(3,&nbsp;"",&nbsp;{st_mode=S_IFREG|0644,&nbsp;st_size=67108864,&nbsp;...},&nbsp;AT_EMPTY_PATH)&nbsp;=&nbsp;0
ioctl(3,&nbsp;TCGETS,&nbsp;0x7ffe9f844ac0)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;-1&nbsp;ENOTTY&nbsp;(Inappropriate&nbsp;ioctl&nbsp;for&nbsp;device)
lseek(3,&nbsp;0,&nbsp;SEEK_CUR)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
lseek(3,&nbsp;0,&nbsp;SEEK_CUR)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
newfstatat(3,&nbsp;"",&nbsp;{st_mode=S_IFREG|0644,&nbsp;st_size=67108864,&nbsp;...},&nbsp;AT_EMPTY_PATH)&nbsp;=&nbsp;0
mmap(NULL,&nbsp;67112960,&nbsp;PROT_READ|PROT_WRITE,&nbsp;MAP_PRIVATE|MAP_ANONYMOUS,&nbsp;-1,&nbsp;0)&nbsp;=&nbsp;0x7f13277ff000
read(3,&nbsp;"\tP\201A\225\366&gt;\260\270R\365\313\220{E\372\274\6\35\"\353\204\220s\2|7C\205\265\6\263"...,&nbsp;67108865)&nbsp;=&nbsp;67108864
read(3,&nbsp;"",&nbsp;1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
rt_sigaction(SIGINT,&nbsp;{sa_handler=SIG_DFL,&nbsp;sa_mask=[],&nbsp;sa_flags=SA_RESTORER|SA_ONSTACK,&nbsp;sa_restorer=0x7f132be5c710},&nbsp;{sa_handler=0x7f132c17ac36,&nbsp;sa_mask=[],&nbsp;sa_flags=SA_RESTORER|SA_ONSTACK,&nbsp;sa_restorer=0x7f132be5c710},&nbsp;8)&nbsp;=&nbsp;0
munmap(0x7f13277ff000,&nbsp;67112960)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
...
</code></pre><p>從分析 strace 來看，很明顯 <code>python-fs-read</code> 的系統調用比 <code>rust-std-fs-read</code> 多，兩者都利用了<code>mmap</code>。那為什麼 Python 要比 Rust 更快呢？</p><h3>👨🏻‍💻 <strong>我們這裏為什麼用了 <code>mmap</code>？</strong></h3><p>我最初認為<code>mmap</code>僅用於將文件映射到內存，從而通過內存訪問文件。然而，<code>mmap</code>還有其他用途。它通常被用來為應用程序分配大塊的內存區域。</p><p>這可以在 strace 的結果中看到：</p><pre><code>mmap(NULL,&nbsp;67112960,&nbsp;PROT_READ|PROT_WRITE,&nbsp;MAP_PRIVATE|MAP_ANONYMOUS,&nbsp;-1,&nbsp;0)&nbsp;=&nbsp;0x7f13277ff000
</code></pre><p>這個系統調用的含義是</p><ul><li><p><code>NULL</code>：第一個參數表示要映射的內存區域的起始地址。<code>NULL</code>將讓操作系統為我們選擇一個合適的地址。</p></li><li><p><code>67112960</code>：要映射的內存區域的大小。我們在這裏分配 64MiB + 4KiB 內存，額外的頁面用於存儲此內存區域的元數據。</p></li><li><p><code>PROT_READ|PROT_WRITE</code>：該內存區域可讀寫。</p></li><li><p><code>MAP_PRIVATE|MAP_ANONYMOUS</code>:</p></li><li><p><code>MAP_PRIVATE</code>意味着對此內存區域進行更改不會對其他映射相同區域的進程可見，並且不會傳遞到底層文件（如果有）。</p></li><li><p><code>MAP_ANONYMOUS</code>意味着我們正在分配與文件無關聯匿名內存.</p></li><li><p><code>-1</code>: 要的映射文件描述符. <code>-1</code> 表示我們沒有映射文件。</p></li><li><p><code>0</code>: 文件中要從哪個偏移量開始映射. 我們並沒有映射文件，所以使用 <code>0</code></p></li></ul><h3>👨🏻‍💻 <strong>但是我們代碼裏沒有調用 <code>mmap</code> 啊？</strong></h3><p><code>mmap</code>系統調用由<code>glibc</code>分派。我們使用<code>malloc</code>向系統請求內存，作為迴應， <code>glibc</code>採用了 <code>brk</code> 和 <code>mmap</code> 系統調用來根據我們的請求大小分配內存。如果請求的大小足夠大，那麼 <code>glibc</code> 會選擇使用 <code>mmap</code>, 這有助於緩解內存碎片問題。</p><p>默認情況下，所有以目標 <code>x86_64-unknown-linux-gnu</code> 編譯的 Rust 程序都使用由 <code>glibc</code> 提供的 <code>malloc</code> 實現。</p><h3>👨🏻‍💻 <strong>Python 和 Rust 是否使用相同的內存分配器？</strong></h3><p>默認情況下，Python 使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fc-api%2Fmemory.html%23default-memory-allocators" target="_blank"><code>pymalloc</code></a>，這是一個針對小型分配進行優化的內存分配器。Python 具有三個內存域，每個代表不同的分配策略，並針對各種目的進行了優化。</p><p><code>pymalloc</code> 有如下行為：</p><blockquote><p>Python has a <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Fc-api%2Fmemory.html%23default-memory-allocators" target="_blank"><code>pymalloc</code></a> allocator optimized for small objects (smaller or equal to 512 bytes) with a short lifetime. It uses memory mappings called 「arenas」 with a fixed size of either 256 KiB on 32-bit platforms or 1 MiB on 64-bit platforms. It falls back to PyMem_RawMalloc() and PyMem_RawRealloc() for allocations larger than 512 bytes.</p></blockquote><h2>Rust 默認的內存分配器比 Python 慢嗎？</h2><p>我懷疑<code>mmap</code>是導致這個問題的原因。如果我切換到<code>jemalloc</code>，會發生什麼情況？</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Frust-std-fs-read-with-jemalloc%2Fsrc%2Fmain.rs" target="_blank">rust-std-fs-read-with-jemalloc</a></p><pre><code>use&nbsp;std::io::Read;
use&nbsp;std::fs::OpenOptions;

#[global_allocator]
static&nbsp;GLOBAL:&nbsp;jemallocator::Jemalloc&nbsp;=&nbsp;jemallocator::Jemalloc;

fn&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;bs&nbsp;=&nbsp;vec![0;&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024];
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;f&nbsp;=&nbsp;OpenOptions::new().read(true).open("/tmp/file").unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;mut&nbsp;ts&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;loop&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;buf&nbsp;=&nbsp;&amp;mut&nbsp;bs[ts..];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;f.read(buf).unwrap();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;let&nbsp;n&nbsp;=&nbsp;n&nbsp;as&nbsp;usize;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;0&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ts&nbsp;+=&nbsp;n;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;assert_eq!(ts,&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024);
}
</code></pre><p><strong>Wooooooooooooooow?!</strong></p><pre><code>Benchmark&nbsp;1:&nbsp;rust-std-fs-read-with-jemalloc/target/release/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.7&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.3&nbsp;ms,&nbsp;System:&nbsp;9.4&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9.0&nbsp;ms&nbsp;…&nbsp;&nbsp;12.4&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;259&nbsp;runs
&nbsp;
Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.8&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.9&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;5.9&nbsp;ms,&nbsp;System:&nbsp;9.8&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;15.0&nbsp;ms&nbsp;…&nbsp;&nbsp;21.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;169&nbsp;runs

Summary
&nbsp;&nbsp;rust-std-fs-read-with-jemalloc/target/release/test&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.64&nbsp;±&nbsp;0.14&nbsp;times&nbsp;faster&nbsp;than&nbsp;python-fs-read/test.py
</code></pre><p>什麼？！我知道 <code>jemalloc</code>&nbsp;是一個高效的內存分配器，但它為啥會這麼優秀呢？</p><h2>只有在我的電腦上，Rust 運行速度比 Python 慢！</h2><p>隨着更多的朋友加入討論，我們發現只有在我的機器上，Rust 運行速度比 Python 慢。</p><p>我的 CPU:</p><pre><code>&gt;&nbsp;lscpu
Architecture:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x86_64
&nbsp;&nbsp;CPU&nbsp;op-mode(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;32-bit,&nbsp;64-bit
&nbsp;&nbsp;Address&nbsp;sizes:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;48&nbsp;bits&nbsp;physical,&nbsp;48&nbsp;bits&nbsp;virtual
&nbsp;&nbsp;Byte&nbsp;Order:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Little&nbsp;Endian
CPU(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;32
&nbsp;&nbsp;On-line&nbsp;CPU(s)&nbsp;list:&nbsp;&nbsp;&nbsp;0-31
Vendor&nbsp;ID:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AuthenticAMD
&nbsp;&nbsp;Model&nbsp;name:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AMD&nbsp;Ryzen&nbsp;9&nbsp;5950X&nbsp;16-Core&nbsp;Processor
&nbsp;&nbsp;&nbsp;&nbsp;CPU&nbsp;family:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;25
&nbsp;&nbsp;&nbsp;&nbsp;Model:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;33
&nbsp;&nbsp;&nbsp;&nbsp;Thread(s)&nbsp;per&nbsp;core:&nbsp;&nbsp;2
&nbsp;&nbsp;&nbsp;&nbsp;Core(s)&nbsp;per&nbsp;socket:&nbsp;&nbsp;16
&nbsp;&nbsp;&nbsp;&nbsp;Socket(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1
&nbsp;&nbsp;&nbsp;&nbsp;Stepping:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;Frequency&nbsp;boost:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enabled
&nbsp;&nbsp;&nbsp;&nbsp;CPU(s)&nbsp;scaling&nbsp;MHz:&nbsp;&nbsp;53%
&nbsp;&nbsp;&nbsp;&nbsp;CPU&nbsp;max&nbsp;MHz:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5083.3979
&nbsp;&nbsp;&nbsp;&nbsp;CPU&nbsp;min&nbsp;MHz:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2200.0000
&nbsp;&nbsp;&nbsp;&nbsp;BogoMIPS:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6787.49
&nbsp;&nbsp;&nbsp;&nbsp;Flags:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fpu&nbsp;vme&nbsp;de&nbsp;pse&nbsp;tsc&nbsp;msr&nbsp;pae&nbsp;mce&nbsp;cx8&nbsp;apic&nbsp;sep&nbsp;mtrr&nbsp;pge&nbsp;mca&nbsp;cmov&nbsp;pat&nbsp;pse36&nbsp;clflush&nbsp;mmx&nbsp;fxsr&nbsp;sse&nbsp;sse2&nbsp;ht&nbsp;syscall&nbsp;nx&nbsp;mmxext&nbsp;fxsr_opt&nbsp;pdpe1gb&nbsp;rdtscp&nbsp;lm&nbsp;con
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stant_tsc&nbsp;rep_good&nbsp;nopl&nbsp;nonstop_tsc&nbsp;cpuid&nbsp;extd_apicid&nbsp;aperfmperf&nbsp;rapl&nbsp;pni&nbsp;pclmulqdq&nbsp;monitor&nbsp;ssse3&nbsp;fma&nbsp;cx16&nbsp;sse4_1&nbsp;sse4_2&nbsp;movbe&nbsp;popcnt&nbsp;aes&nbsp;xsave&nbsp;avx&nbsp;f
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16c&nbsp;rdrand&nbsp;lahf_lm&nbsp;cmp_legacy&nbsp;svm&nbsp;extapic&nbsp;cr8_legacy&nbsp;abm&nbsp;sse4a&nbsp;misalignsse&nbsp;3dnowprefetch&nbsp;osvw&nbsp;ibs&nbsp;skinit&nbsp;wdt&nbsp;tce&nbsp;topoext&nbsp;perfctr_core&nbsp;perfctr_nb&nbsp;bpex
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t&nbsp;perfctr_llc&nbsp;mwaitx&nbsp;cpb&nbsp;cat_l3&nbsp;cdp_l3&nbsp;hw_pstate&nbsp;ssbd&nbsp;mba&nbsp;ibrs&nbsp;ibpb&nbsp;stibp&nbsp;vmmcall&nbsp;fsgsbase&nbsp;bmi1&nbsp;avx2&nbsp;smep&nbsp;bmi2&nbsp;erms&nbsp;invpcid&nbsp;cqm&nbsp;rdt_a&nbsp;rdseed&nbsp;adx&nbsp;smap
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;clflushopt&nbsp;clwb&nbsp;sha_ni&nbsp;xsaveopt&nbsp;xsavec&nbsp;xgetbv1&nbsp;xsaves&nbsp;cqm_llc&nbsp;cqm_occup_llc&nbsp;cqm_mbm_total&nbsp;cqm_mbm_local&nbsp;user_shstk&nbsp;clzero&nbsp;irperf&nbsp;xsaveerptr&nbsp;rdpru&nbsp;wb
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;noinvd&nbsp;arat&nbsp;npt&nbsp;lbrv&nbsp;svm_lock&nbsp;nrip_save&nbsp;tsc_scale&nbsp;vmcb_clean&nbsp;flushbyasid&nbsp;decodeassists&nbsp;pausefilter&nbsp;pfthreshold&nbsp;avic&nbsp;v_vmsave_vmload&nbsp;vgif&nbsp;v_spec_ctrl
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;umip&nbsp;pku&nbsp;ospke&nbsp;vaes&nbsp;vpclmulqdq&nbsp;rdpid&nbsp;overflow_recov&nbsp;succor&nbsp;smca&nbsp;fsrm&nbsp;debug_swap
Virtualization&nbsp;features:
&nbsp;&nbsp;Virtualization:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AMD-V
Caches&nbsp;(sum&nbsp;of&nbsp;all):
&nbsp;&nbsp;L1d:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;512&nbsp;KiB&nbsp;(16&nbsp;instances)
&nbsp;&nbsp;L1i:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;512&nbsp;KiB&nbsp;(16&nbsp;instances)
&nbsp;&nbsp;L2:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8&nbsp;MiB&nbsp;(16&nbsp;instances)
&nbsp;&nbsp;L3:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;64&nbsp;MiB&nbsp;(2&nbsp;instances)
NUMA:
&nbsp;&nbsp;NUMA&nbsp;node(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1
&nbsp;&nbsp;NUMA&nbsp;node0&nbsp;CPU(s):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0-31
Vulnerabilities:
&nbsp;&nbsp;Gather&nbsp;data&nbsp;sampling:&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Itlb&nbsp;multihit:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;L1tf:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Mds:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Meltdown:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Mmio&nbsp;stale&nbsp;data:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Retbleed:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Spec&nbsp;rstack&nbsp;overflow:&nbsp;&nbsp;Vulnerable
&nbsp;&nbsp;Spec&nbsp;store&nbsp;bypass:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vulnerable
&nbsp;&nbsp;Spectre&nbsp;v1:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vulnerable:&nbsp;__user&nbsp;pointer&nbsp;sanitization&nbsp;and&nbsp;usercopy&nbsp;barriers&nbsp;only;&nbsp;no&nbsp;swapgs&nbsp;barriers
&nbsp;&nbsp;Spectre&nbsp;v2:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vulnerable,&nbsp;IBPB:&nbsp;disabled,&nbsp;STIBP:&nbsp;disabled,&nbsp;PBRSB-eIBRS:&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Srbds:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
&nbsp;&nbsp;Tsx&nbsp;async&nbsp;abort:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Not&nbsp;affected
</code></pre><p>我的內存:</p><pre><code>&gt;&nbsp;sudo&nbsp;dmidecode&nbsp;--type&nbsp;memory
#&nbsp;dmidecode&nbsp;3.5
Getting&nbsp;SMBIOS&nbsp;data&nbsp;from&nbsp;sysfs.
SMBIOS&nbsp;3.3.0&nbsp;present.

Handle&nbsp;0x0014,&nbsp;DMI&nbsp;type&nbsp;16,&nbsp;23&nbsp;bytes
Physical&nbsp;Memory&nbsp;Array
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Location:&nbsp;System&nbsp;Board&nbsp;Or&nbsp;Motherboard
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Use:&nbsp;System&nbsp;Memory
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Error&nbsp;Correction&nbsp;Type:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;Capacity:&nbsp;64&nbsp;GB
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Error&nbsp;Information&nbsp;Handle:&nbsp;0x0013
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Number&nbsp;Of&nbsp;Devices:&nbsp;4

Handle&nbsp;0x001C,&nbsp;DMI&nbsp;type&nbsp;17,&nbsp;92&nbsp;bytes
Memory&nbsp;Device
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Array&nbsp;Handle:&nbsp;0x0014
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Error&nbsp;Information&nbsp;Handle:&nbsp;0x001B
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total&nbsp;Width:&nbsp;64&nbsp;bits
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data&nbsp;Width:&nbsp;64&nbsp;bits
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Size:&nbsp;16&nbsp;GB
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Form&nbsp;Factor:&nbsp;DIMM
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Locator:&nbsp;DIMM&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bank&nbsp;Locator:&nbsp;P0&nbsp;CHANNEL&nbsp;A
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Type:&nbsp;DDR4
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Type&nbsp;Detail:&nbsp;Synchronous&nbsp;Unbuffered&nbsp;(Unregistered)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Speed:&nbsp;3200&nbsp;MT/s
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Manufacturer:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Serial&nbsp;Number:&nbsp;04904740
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Asset&nbsp;Tag:&nbsp;Not&nbsp;Specified
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Part&nbsp;Number:&nbsp;LMKUFG68AHFHD-32A
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rank:&nbsp;2
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Configured&nbsp;Memory&nbsp;Speed:&nbsp;3200&nbsp;MT/s
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Minimum&nbsp;Voltage:&nbsp;1.2&nbsp;V
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Maximum&nbsp;Voltage:&nbsp;1.2&nbsp;V
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Configured&nbsp;Voltage:&nbsp;1.2&nbsp;V
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Technology:&nbsp;DRAM
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Operating&nbsp;Mode&nbsp;Capability:&nbsp;Volatile&nbsp;memory
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Firmware&nbsp;Version:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Module&nbsp;Manufacturer&nbsp;ID:&nbsp;Bank&nbsp;9,&nbsp;Hex&nbsp;0xC8
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Module&nbsp;Product&nbsp;ID:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Subsystem&nbsp;Controller&nbsp;Manufacturer&nbsp;ID:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memory&nbsp;Subsystem&nbsp;Controller&nbsp;Product&nbsp;ID:&nbsp;Unknown
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Non-Volatile&nbsp;Size:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Volatile&nbsp;Size:&nbsp;16&nbsp;GB
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cache&nbsp;Size:&nbsp;None
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Logical&nbsp;Size:&nbsp;None
</code></pre><p>所以我嘗試了以下事情：</p><h3>👨🏻‍💻 開啓 Mitigations</h3><p>CPU 擁有許多可能將私有數據暴露給攻擊者的漏洞，其中<code>Spectre</code>是最知名的之一。Linux 內核已經開發了各種緩解這些漏洞的措施，並且默認啓用它們。然而，這些緩解措施可能會增加額外的系統成本。因此，Linux 內核也為希望禁用它們的用户提供了一個<code>mitigations</code>開關。</p><p>我過去禁用了所有的 mitigations：</p><pre><code>title&nbsp;Arch&nbsp;Linux
linux&nbsp;/vmlinuz-linux-zen
initrd&nbsp;/amd-ucode.img
initrd&nbsp;/initramfs-linux-zen.img
options&nbsp;root="PARTUUID=206e7750-2b89-419d-978e-db0068c79c52"&nbsp;rw&nbsp;mitigations=off
</code></pre><p>啓用它並不能改變結果</p><h3>👨🏻‍💻 調整透明大頁</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kernel.org%2Fdoc%2Fhtml%2Fnext%2Fadmin-guide%2Fmm%2Ftranshuge.html" target="_blank">透明大頁</a>可以顯著影響性能。大多數現代發行版默認啓用它。</p><pre><code>&gt;&nbsp;cat&nbsp;/sys/kernel/mm/transparent_hugepage/enabled
[always]&nbsp;madvise&nbsp;never
</code></pre><p>切換到 <code>madvise</code>&nbsp;或 <code>never</code>&nbsp;會改變絕對結果，但相對比例保持一致。</p><h3>👨🏻‍💻 Tune CPU 核心親和度</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 猜測這可能與 <code>CPU 核心間距</code> 有關。我試圖使用 <a href="https://my.oschina.net/u/5489811/blog/*https://docs.rs/core_affinity/latest/core_affinity/*">core_affinity</a>將進程綁定到特定的 CPU，但結果仍然相同。</p><h3>👨🏻‍💻 <strong>使用 eBPF 精確測量 syscall 延遲</strong></h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 也為我創建了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fscripts%2Fread-latency.py" target="_blank">一個 eBPF 程序</a>，以便我衡量讀取系統調用的延遲。研究結果表明，Rust 在系統調用級別上就比 Python 慢。</p><blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 寫一篇文章來分享關於這個 eBPF 程序的故事！</p></blockquote><pre><code>   #&nbsp;python&nbsp;fs&nbsp;read
   Process&nbsp;57555&nbsp;read&nbsp;file&nbsp;8134049&nbsp;ns
   Process&nbsp;57555&nbsp;read&nbsp;file&nbsp;942&nbsp;ns

   #&nbsp;rust&nbsp;std&nbsp;fs&nbsp;read
   Process&nbsp;57634&nbsp;read&nbsp;file&nbsp;24636975&nbsp;ns
   Process&nbsp;57634&nbsp;read&nbsp;file&nbsp;1052&nbsp;ns
</code></pre><p>觀察：在我的電腦上，Rust 運行速度比 Python 慢，而且這似乎與軟件無關。</p><h2>C 比 Python 慢？</h2><p>當用户想要進行大數據分析時，心裏所期望的基本是：</p><p>我感到相當困惑，無法準確指出差異。我懷疑這可能與 CPU 有關，但我不確定是哪個方面：緩存？頻率？核間距？核親和性？架構？</p><p>根據 Telegram 羣組 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Frust_zh" target="_blank">Rust 眾</a> 的建議，我開發了一個 C 版本：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow%2Fblob%2Fmain%2Fc-fs-read%2Ftest.c" target="_blank">c-fs-read</a></p><pre><code>#include&nbsp;&lt;stdio.h&gt;
#include&nbsp;&lt;stdlib.h&gt;

#define&nbsp;FILE_SIZE&nbsp;64&nbsp;*&nbsp;1024&nbsp;*&nbsp;1024&nbsp;&nbsp;//&nbsp;64&nbsp;MiB

int&nbsp;main()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;FILE&nbsp;*file;
&nbsp;&nbsp;&nbsp;&nbsp;char&nbsp;*buffer;
&nbsp;&nbsp;&nbsp;&nbsp;size_t&nbsp;result;

&nbsp;&nbsp;&nbsp;&nbsp;file&nbsp;=&nbsp;fopen("/tmp/file",&nbsp;"rb");
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(file&nbsp;==&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fputs("Error&nbsp;opening&nbsp;file",&nbsp;stderr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;1;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;buffer&nbsp;=&nbsp;(char&nbsp;*)malloc(sizeof(char)&nbsp;*&nbsp;FILE_SIZE);
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(buffer&nbsp;==&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fputs("Memory&nbsp;error",&nbsp;stderr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fclose(file);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;2;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;fread(buffer,&nbsp;1,&nbsp;FILE_SIZE,&nbsp;file);
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(result&nbsp;!=&nbsp;FILE_SIZE)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fputs("Reading&nbsp;error",&nbsp;stderr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fclose(file);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;free(buffer);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;3;
&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;fclose(file);
&nbsp;&nbsp;&nbsp;&nbsp;free(buffer);

&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;0;
}

</code></pre><p>但是......</p><pre><code>Benchmark&nbsp;1:&nbsp;c-fs-read/test
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.8&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.9&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.3&nbsp;ms,&nbsp;System:&nbsp;23.6&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;23.0&nbsp;ms&nbsp;…&nbsp;&nbsp;27.1&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;120&nbsp;runs

Benchmark&nbsp;2:&nbsp;python-fs-read/test.py
&nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19.1&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.3&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;8.6&nbsp;ms,&nbsp;System:&nbsp;10.4&nbsp;ms]
&nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;18.6&nbsp;ms&nbsp;…&nbsp;&nbsp;20.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;146&nbsp;runs

Summary
&nbsp;&nbsp;python-fs-read/test.py&nbsp;ran
&nbsp;&nbsp;&nbsp;&nbsp;1.25&nbsp;±&nbsp;0.05&nbsp;times&nbsp;faster&nbsp;than&nbsp;c-fs-read/test
</code></pre><p>C 版本也比 Python 慢！Python 有魔法嗎？</p><h2><strong>在指定的偏移量下，C 語言比 Python 慢！</strong></h2><p>當用户想要進行大數據分析時，心裏所期望的基本是：</p><p>在這個時候，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flilydjwg" target="_blank">@lilydjwg</a> 加入了討論，並注意到 C 和 Python 之間的內存區域偏移存在差異。</p><blockquote><p><code>strace -e raw=read,mmap ./program</code>被用來打印系統調用的未解碼參數：指針地址。</p></blockquote><pre><code>`c-fs-read` 的 strace:

    &gt;&nbsp;strace&nbsp;-e&nbsp;raw=read,mmap&nbsp;./c-fs-read/test
    ...
    mmap(0,&nbsp;0x4001000,&nbsp;0x3,&nbsp;0x22,&nbsp;0xffffffff,&nbsp;0)&nbsp;=&nbsp;0x7f96d1a18000
    read(0x3,&nbsp;0x7f96d1a18010,&nbsp;0x4000000)&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0x4000000
    close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
    python-fs-read&nbsp;的&nbsp;strace

`python-fs-read` 的 strace

    &gt;&nbsp;strace&nbsp;-e&nbsp;raw=read,mmap&nbsp;./python-fs-read/test.py
    ...
    mmap(0,&nbsp;0x4001000,&nbsp;0x3,&nbsp;0x22,&nbsp;0xffffffff,&nbsp;0)&nbsp;=&nbsp;0x7f27dcfbe000
    read(0x3,&nbsp;0x7f27dcfbe030,&nbsp;0x4000001)&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0x4000000
    read(0x3,&nbsp;0x7f27e0fbe030,&nbsp;0x1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
    close(3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;0
</code></pre><p>在 <code>c-fs-read</code> 中，<code>mmap</code>返回 <code>0x7f96d1a18000</code>，但是 read 系統調用使用 <code>0x7f96d1a18010</code>作為起始地址，偏移量是 <code>0x10</code>。在 <code>python-fs-read</code>中， <code>mmap</code> 返回 <code>0x7f27dcfbe000</code>, 並且 read 系統調用使用 <code>0x7f27dcfbe030</code> 作為起始地址, 偏移量是 <code>0x30</code>.</p><p>所以 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flilydjwg" target="_blank">@lilydjwg</a>&nbsp;嘗試用相同的偏移量來調用 'read'。</p><pre><code>    :)&nbsp;./bench&nbsp;c-fs-read&nbsp;c-fs-read-with-offset&nbsp;python-fs-read
    ['hyperfine',&nbsp;'c-fs-read/test',&nbsp;'c-fs-read-with-offset/test',&nbsp;'python-fs-read/test.py']
    Benchmark&nbsp;1:&nbsp;c-fs-read/test
    &nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.7&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.8&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.2&nbsp;ms,&nbsp;System:&nbsp;23.6&nbsp;ms]
    &nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;23.0&nbsp;ms&nbsp;…&nbsp;&nbsp;25.5&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;119&nbsp;runs

    &nbsp;&nbsp;Warning:&nbsp;Statistical&nbsp;outliers&nbsp;were&nbsp;detected.&nbsp;Consider&nbsp;re-running&nbsp;this&nbsp;benchmark&nbsp;on&nbsp;a&nbsp;quiet&nbsp;system&nbsp;without&nbsp;any&nbsp;interferences&nbsp;from&nbsp;other&nbsp;programs.&nbsp;It&nbsp;might&nbsp;help&nbsp;to&nbsp;use&nbsp;the&nbsp;'--warmup'&nbsp;or&nbsp;'--prepare'&nbsp;options.

    Benchmark&nbsp;2:&nbsp;c-fs-read-with-offset/test
    &nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8.9&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.4&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;0.2&nbsp;ms,&nbsp;System:&nbsp;8.8&nbsp;ms]
    &nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8.3&nbsp;ms&nbsp;…&nbsp;&nbsp;10.6&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;283&nbsp;runs

    Benchmark&nbsp;3:&nbsp;python-fs-read/test.py
    &nbsp;&nbsp;Time&nbsp;(mean&nbsp;±&nbsp;σ):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19.1&nbsp;ms&nbsp;±&nbsp;&nbsp;&nbsp;0.3&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;[User:&nbsp;8.6&nbsp;ms,&nbsp;System:&nbsp;10.4&nbsp;ms]
    &nbsp;&nbsp;Range&nbsp;(min&nbsp;…&nbsp;max):&nbsp;&nbsp;&nbsp;&nbsp;18.6&nbsp;ms&nbsp;…&nbsp;&nbsp;20.0&nbsp;ms&nbsp;&nbsp;&nbsp;&nbsp;147&nbsp;runs

    Summary
    &nbsp;&nbsp;c-fs-read-with-offset/test&nbsp;ran
    &nbsp;&nbsp;&nbsp;&nbsp;2.15&nbsp;±&nbsp;0.11&nbsp;times&nbsp;faster&nbsp;than&nbsp;python-fs-read/test.py
    &nbsp;&nbsp;&nbsp;&nbsp;2.68&nbsp;±&nbsp;0.16&nbsp;times&nbsp;faster&nbsp;than&nbsp;c-fs-read/test
</code></pre><p>！！！</p><p>在<code>c-fs-read</code>中對<code>buffer</code>應用偏移量可以提高其速度，超過 Python！此外，我們已經驗證了這個問題在 <code>AMD Ryzen 9 5900X</code> 和 <code>AMD Ryzen 7 5700X</code> 上都能復現。</p><p>新的信息讓我找到了關於類似問題的其他報告，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fusers.rust-lang.org%2Ft%2Fstd-read-slow%2F85424" target="_blank">Std::fs::read slow?</a>。在這篇帖子中，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fambiso" target="_blank">@ambiso</a> 發現系統調用性能與內存區域的偏移量有關。他指出當從每頁的前 <code>0x10</code> 字節寫入時，這款 CPU 會變慢。</p><pre><code>    offset&nbsp;milliseconds
    &nbsp;...
    &nbsp;14&nbsp;&nbsp;&nbsp;130
    &nbsp;15&nbsp;&nbsp;&nbsp;130
    &nbsp;16&nbsp;&nbsp;&nbsp;&nbsp;46&nbsp;&nbsp;&nbsp;&lt;-----&nbsp;0x10!
    &nbsp;17&nbsp;&nbsp;&nbsp;&nbsp;48
    &nbsp;...
</code></pre><h2>在指定的偏移量下，AMD Ryzen 9 5900X 很慢！</h2><p>我們已確認這個問題與 CPU 有關。然而，我們仍然不確定其可能的原因。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a>&nbsp;已邀請內核開發者 <a href="https://my.oschina.net/u/5489811/blog/*https://github.com/ryncsn*">@ryncsn</a> 加入討論。</p><p>他可以在 <code>AMD Ryzen 9 5900HX</code> 上使用我們的 <code>c-fs-read</code> 和 <code>c-fs-read-with-offset</code> 重現相同的結果。他還嘗試使用 <code>perf</code> 對兩個程序進行性能分析。</p><p><strong>沒有 offset:</strong></p><pre><code>perf&nbsp;stat&nbsp;-d&nbsp;-d&nbsp;-d&nbsp;--repeat&nbsp;20&nbsp;./a.out
&nbsp;Performance&nbsp;counter&nbsp;stats&nbsp;for&nbsp;'./a.out'&nbsp;(20&nbsp;runs):

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;30.89&nbsp;msec&nbsp;task-clock&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.968&nbsp;CPUs&nbsp;utilized&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.35%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;context-switches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.000&nbsp;/sec
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu-migrations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.000&nbsp;/sec
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;598&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;page-faults&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;19.362&nbsp;K/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;0.05%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;90,321,344&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cycles&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;2.924&nbsp;GHz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.12%&nbsp;)&nbsp;&nbsp;(40.76%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;599,640&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-frontend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.66%&nbsp;frontend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;2.19%&nbsp;)&nbsp;&nbsp;(42.11%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;398,016&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-backend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.44%&nbsp;backend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;22.41%&nbsp;)&nbsp;&nbsp;(41.88%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;43,349,705&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instructions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.48&nbsp;&nbsp;insn&nbsp;per&nbsp;cycle
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.01&nbsp;&nbsp;stalled&nbsp;cycles&nbsp;per&nbsp;insn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.32%&nbsp;)&nbsp;&nbsp;(41.91%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7,526,819&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;243.701&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;5.01%&nbsp;)&nbsp;&nbsp;(41.22%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37,541&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branch-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.50%&nbsp;of&nbsp;all&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;4.62%&nbsp;)&nbsp;&nbsp;(41.12%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;127,845,213&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;4.139&nbsp;G/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.14%&nbsp;)&nbsp;&nbsp;(39.84%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,172,628&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;2.48%&nbsp;of&nbsp;all&nbsp;L1-dcache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.34%&nbsp;)&nbsp;&nbsp;(38.46%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-loads
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-load-misses
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;654,651&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;21.196&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.71%&nbsp;)&nbsp;&nbsp;(38.72%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2,828&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.43%&nbsp;of&nbsp;all&nbsp;L1-icache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;2.35%&nbsp;)&nbsp;&nbsp;(38.67%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15,615&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;505.578&nbsp;K/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.28%&nbsp;)&nbsp;&nbsp;(38.82%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12,825&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;82.13%&nbsp;of&nbsp;all&nbsp;dTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.15%&nbsp;)&nbsp;&nbsp;(38.88%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;518.043&nbsp;/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;27.06%&nbsp;)&nbsp;&nbsp;(38.82%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2,202&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;13762.50%&nbsp;of&nbsp;all&nbsp;iTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;23.62%&nbsp;)&nbsp;&nbsp;(39.38%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1,843,493&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;59.688&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.36%&nbsp;)&nbsp;&nbsp;(39.40%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetch-misses

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.031915&nbsp;+-&nbsp;0.000419&nbsp;seconds&nbsp;time&nbsp;elapsed&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.31%&nbsp;)
</code></pre><p>有 offset:</p><pre><code>perf&nbsp;stat&nbsp;-d&nbsp;-d&nbsp;-d&nbsp;--repeat&nbsp;20&nbsp;./a.out
&nbsp;Performance&nbsp;counter&nbsp;stats&nbsp;for&nbsp;'./a.out'&nbsp;(20&nbsp;runs):

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.39&nbsp;msec&nbsp;task-clock&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.937&nbsp;CPUs&nbsp;utilized&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.24%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;context-switches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;64.972&nbsp;/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;17.62%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cpu-migrations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.000&nbsp;/sec
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;598&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;page-faults&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;38.854&nbsp;K/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;0.06%&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;41,239,117&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cycles&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;2.679&nbsp;GHz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;1.95%&nbsp;)&nbsp;&nbsp;(40.68%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;547,465&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-frontend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;1.33%&nbsp;frontend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.43%&nbsp;)&nbsp;&nbsp;(40.60%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;413,657&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stalled-cycles-backend&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;1.00%&nbsp;backend&nbsp;cycles&nbsp;idle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;20.37%&nbsp;)&nbsp;&nbsp;(40.50%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37,009,429&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instructions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.90&nbsp;&nbsp;insn&nbsp;per&nbsp;cycle
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.01&nbsp;&nbsp;stalled&nbsp;cycles&nbsp;per&nbsp;insn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.13%&nbsp;)&nbsp;&nbsp;(40.43%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5,410,381&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;351.526&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.24%&nbsp;)&nbsp;&nbsp;(39.80%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;34,649&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;branch-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.64%&nbsp;of&nbsp;all&nbsp;branches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;4.04%&nbsp;)&nbsp;&nbsp;(39.94%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;13,965,813&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;907.393&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.37%&nbsp;)&nbsp;&nbsp;(39.44%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,623,350&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;25.94%&nbsp;of&nbsp;all&nbsp;L1-dcache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.56%&nbsp;)&nbsp;&nbsp;(39.52%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-loads
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LLC-load-misses
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;590,613&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;38.374&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.39%&nbsp;)&nbsp;&nbsp;(39.67%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1,995&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-icache-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;0.34%&nbsp;of&nbsp;all&nbsp;L1-icache&nbsp;accesses&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;4.18%&nbsp;)&nbsp;&nbsp;(39.67%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16,046&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;1.043&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.28%&nbsp;)&nbsp;&nbsp;(39.78%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14,040&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;87.50%&nbsp;of&nbsp;all&nbsp;dTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.24%&nbsp;)&nbsp;&nbsp;(39.78%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-loads&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;714.697&nbsp;/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;29.56%&nbsp;)&nbsp;&nbsp;(39.77%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3,657&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iTLB-load-misses&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;33245.45%&nbsp;of&nbsp;all&nbsp;iTLB&nbsp;cache&nbsp;accesses&nbsp;&nbsp;(&nbsp;+-&nbsp;14.61%&nbsp;)&nbsp;&nbsp;(40.30%)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;395,578&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetches&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;&nbsp;&nbsp;25.702&nbsp;M/sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.34%&nbsp;)&nbsp;&nbsp;(40.10%)
&nbsp;&nbsp;&nbsp;&lt;not&nbsp;supported&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;L1-dcache-prefetch-misses

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.016429&nbsp;+-&nbsp;0.000521&nbsp;seconds&nbsp;time&nbsp;elapsed&nbsp;&nbsp;(&nbsp;+-&nbsp;&nbsp;3.17%&nbsp;)
</code></pre><p>他發現<code>L1-dcache-prefetches</code>和<code>L1-dcache-loads</code>的值差異很大。</p><ul><li><p><code>L1-dcache-prefetches</code>是 CPU L1 數據緩存的預取。</p></li><li><p><code>L1-dcache-loads</code>是 CPU L1 數據緩存的加載。</p></li></ul><p>如果沒有指定偏移量，CPU 將執行更多的加載和預取操作，導致系統調用時間增加。</p><p>他對熱點 ASM 進行了進一步研究：</p><pre><code>Samples:&nbsp;15K&nbsp;of&nbsp;event&nbsp;'cycles:P',&nbsp;Event&nbsp;count&nbsp;(approx.):&nbsp;6078132137
&nbsp;&nbsp;Children&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Self&nbsp;&nbsp;Command&nbsp;&nbsp;&nbsp;&nbsp;Shared&nbsp;Object&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Symbol
-&nbsp;&nbsp;&nbsp;94.11%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.00%&nbsp;&nbsp;a.out&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[kernel.vmlinux]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[k]&nbsp;entry_SYSCALL_64_after_hwframe&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;-&nbsp;entry_SYSCALL_64_after_hwframe&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;94.10%&nbsp;do_syscall_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;86.66%&nbsp;__x64_sys_read&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ksys_read&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;vfs_read&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;85.94%&nbsp;shmem_file_read_iter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;77.17%&nbsp;copy_page_to_iter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;75.80%&nbsp;_copy_to_iter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;19.41%&nbsp;asm_exc_page_fault&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.71%&nbsp;__might_fault&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;4.87%&nbsp;shmem_get_folio_gfp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.76%&nbsp;folio_mark_accessed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;4.38%&nbsp;__x64_sys_munmap&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;1.02%&nbsp;0xffffffffae6f6fe8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;0.79%&nbsp;__x64_sys_execve&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;0.58%&nbsp;__x64_sys_mmap&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</code></pre><p><code>_copy_to_iter</code> 中的 ASM：</p><pre><code>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copy_user_generic():
    &nbsp;&nbsp;2.19&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mov&nbsp;&nbsp;&nbsp;&nbsp;%rdx,%rcx
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mov&nbsp;&nbsp;&nbsp;&nbsp;%r12,%rsi
    &nbsp;92.45&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rep&nbsp;&nbsp;&nbsp;&nbsp;movsb&nbsp;%ds:(%rsi),%es:(%rdi)
    &nbsp;&nbsp;0.49&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nop
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nop
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nop
</code></pre><p>這裏的關鍵區別是<code>rep movsb</code>的性能。</p><h2>AMD Ryzen 9 5900X 因為 FSRM 慢！</h2><p>在這個時候，我的一個朋友給我發送了一個關於<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugs.launchpad.net%2Fubuntu%2F%2Bsource%2Fglibc%2F%2Bbug%2F2030515" target="_blank">Terrible memcpy performance on Zen 3 when using rep movsb</a>的鏈接。其中也指向了<code>rep movsb</code>：</p><blockquote><p>I've found this using a memcpy benchmark at <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fska-sa%2Fkatgpucbf%2Fblob%2F69752be58fb8ab0668ada806e0fd809e782cc58b%2Fscratch%2Fmemcpy%5C%5C_loop.cpp" target="_blank">https://github.com/ska-sa/katgpucbf/blob/69752be58fb8ab0668ada806e0fd809e782cc58b/scratch/memcpy\\_loop.cpp</a> (compiled with the adjacent Makefile). To demonstrate the issue, run</p><p>./memcpy_loop -b 2113 -p 1000000 -t mmap -S 0 -D 1 0</p><p>This runs:</p><ul><li><p>•&nbsp;2113-byte memory copies</p></li><li><p>•&nbsp;1,000,000 times per timing measurement</p></li><li><p>•&nbsp;in memory allocated with mmap</p></li><li><p>•&nbsp;with the source 0 bytes from the start of the page</p></li><li><p>•&nbsp;with the destination 1 byte from the start of the page</p></li><li><p>•&nbsp;on core 0.</p></li></ul><p>It reports about 3.2 GB/s. Change the -b argument to 2111 and it reports over 100 GB/s. So the REP MOVSB case is about 30× slower!</p></blockquote><p><code>FSRM</code>，即 <code>Fast Short REP MOV</code>，是英特爾最初的創新，近期也被 AMD 採納，用以提升 <code>rep movsb</code> 和 <code>rep movsd</code> 的速度。它旨在提高大量內存複製的效率。聲明支持它的 CPU 將在 <code>glibc</code> 中默認使用 <code>FSRM</code>。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fryncsn" target="_blank">@ryncsn</a> 進一步研究並發現它與 L1 預取無關。</p><blockquote><p>It seems that <code>rep movsb</code> performance poorly when DATA IS PAGE ALIGNED, and perform better when DATA IS NOT PAGE ALIGNED, this is very funny...</p></blockquote><h2>總結</h2><p>總的來説，這個問題並非與軟件有關。由於 AMD 的一個錯誤，Python 在性能上超過了 C/Rust。（我終於可以好好睡覺了。）</p><p>然而，我們的用户仍然需要面對這個問題。不幸的是，像<code>FSRM</code>這樣的功能將會被實現在<code>ucode</code>中，我們別無選擇只能等待 AMD 的迴應。另一種可能的解決方案是不使用<code>FSRM</code>或者提供一個標誌來禁用它。Rust 開發者可能會考慮切換到 <code>jemallocator</code>以提高性能 ，即使沒有 AMD CPU Bug 存在，這也是一個好主意！</p><h2>回顧</h2><p>我花了近三天的時間來解決這個問題，它始於 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal" target="_blank">opendal:</a> 用户的投訴，並最終引導我到 CPU 的微代碼。這次旅程讓我對<code>strace</code>、<code>perf</code>和<code>eBPF</code>有了深入的瞭解。這是我第一次使用 <code>eBPF</code>進行診斷。我還探索了各種收效甚微的途徑，比如研究 rust 的 <code>std::fs</code> 和 Python &amp; CPython 的讀取實現細節。起初，我希望能在更高層面上解決這個問題，但發現有必要深入挖掘。</p><p>對於所有參與尋找答案的人，我表示衷心感謝：</p><ul><li><p>感謝 opendal 的 Discord 上的 @beldathas 發現了這個問題。</p></li><li><p>感謝 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs" target="_blank">@datafuselabs</a> 團隊提供的建議。</p></li><li><p>感謝我們在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Frust_zh" target="_blank">Rust 眾</a>&nbsp;的朋友們給出的建議和復現努力。</p></li><li><p>感謝 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FZheaoLi" target="_blank">@Manjusaka</a> 復現問題並使用 eBPF 進行調查，這幫助我們將問題定位到系統調用本身。</p></li><li><p>感謝 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flilydjwg" target="_blank">@lilydjwg</a> 找出根本原因：內存中<code>0x20</code>偏移量 -感謝 <a href="https://my.oschina.net/u/5489811/blog/*https://github.com/ryncsn*">@ryncsn</a> 他對此事進行了徹底分析。</p></li><li><p>•&nbsp;還有一位分享了關於 FSRM 有用鏈接的朋友。</p></li></ul><p>期待我們下次旅程！</p><h2>引用</h2><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanwo%2Fwhen-i-find-rust-is-slow" target="_blank">Xuanwo/when-i-find-rust-is-slow</a>&nbsp;有所有的樣例和腳本</p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fusers.rust-lang.org%2Ft%2Fstd-read-slow%2F85424" target="_blank">Std::fs::read slow?</a> 是來自 Rust 社區的彙報</p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugs.launchpad.net%2Fubuntu%2F%2Bsource%2Fglibc%2F%2Bbug%2F2030515" target="_blank">Terrible memcpy performance on Zen 3 when using rep movsb</a> 是來自 ubuntu glibc 的報告</p></li><li><p>[binding/python](rust std fs is slower than python fs:&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fincubator-opendal%2Fissues%2F3665" target="_blank">https://github.com/apache/incubator-opendal/issues/3665</a>)</p></li></ul><h2>關於&nbsp;Databend</h2><p>Databend 是一款開源、彈性、低成本，基於對象存儲也可以做實時分析的新式數倉。期待您的關注，一起探索雲原生數倉解決方案，打造新一代開源 Data Cloud。</p><p>👨‍💻‍ Databend Cloud：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatabend.cn" target="_blank">https://databend.cn</a></p><p>📖 Databend 文檔：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatabend.rs%2F" target="_blank">https://databend.rs/</a></p><p>💻 Wechat：Databend</p><p>✨ GitHub：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdatafuselabs%2Fdatabend" target="_blank">https://github.com/datafuselabs/databend</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 05:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5489811/blog/10314995</guid>
            <link>https://my.oschina.net/u/5489811/blog/10314995</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[恭喜 Devlive DataCap 新晉一位前端 Committer]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>非常感謝所有對 DataCap 項目的支持和貢獻，我們迎來了新的一位來自互聯網行業的美女前端工程師，感謝她對 DataCap 的支持已經代碼的貢獻。</p></blockquote><p><img alt="8AA600FB-3F02-4229-8353-EA4400BCE1D7.jpg" src="https://images.edurt.io/devlive.org/2023-12-1/8AA600FB-3F02-4229-8353-EA4400BCE1D7.jpg" referrerpolicy="no-referrer"></p><h3>關於 DataCap</h3><hr><p>DataCap 是數據轉換、集成和可視化的集成軟件。支持多種數據源，文件類型，大數據相關數據庫，關係型數據庫，NoSQL 數據庫等。通過軟件可以實現管理多種數據源，對該源下的數據進行各種操作轉換，製作數據圖表，監控數據源等各種功能。</p><h3>DataCap 喜迎一位 Committer 成員</h3><hr><table><tbody><tr><th>名字</th><th>職業</th><th>GitHub ID</th></tr></tbody><tbody><tr><td>張揚</td><td>前端工程師</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FStacey1018" target="_blank">Stacey1018</a></td></tr></tbody></table><h4>個人描述</h4><hr><p>一名熱情富有經驗的前端開發者，我曾參與過多個前端項目，從小型網站到大型應用都有涉獵。熟悉 <code>react</code>、<code>vue</code>、<code>angular</code> 等多個前端框架。熟悉打包工具如 <code>Webpack</code>，能夠優化前端資源的加載和管理，從而提高網站的性能。</p><h4>對 DataCap 的認識</h4><hr><p>在做公司數據部門項目時，從 github 中搜索，發現 datacap 項目，結合公司內部業務，經過一段時間運行後發現頁面組件出現層級問題和 MonacoEditor 組件渲染問題，特意在源碼中修復了以上兩個問題。</p><h4>代碼提交之路</h4><hr><ol><li>在 datacap 上提交了相關代碼 (commit 9afddb4f4edb529cc80dda76a9c52acb33e933dd (HEAD -&gt; fixbug/zy))</li></ol><h4>得到的收穫</h4><hr><ol><li>藉此機會學習了新技術，工具，是提升自己技能和知識的寶貴機會</li><li>很榮幸參與 datacap 開源項目，熟悉了開源項目整個開發流程</li></ol><h4>對新人的建議</h4><hr><ol><li>參與項目開發時，可以先從一些小任務，小問題入手，有助於熟悉項目代碼</li><li>建議從自己熟悉的技術棧入手，這樣可以更快的融入項目</li><li>建議將項目部署下來，這樣才能得到真實的體驗</li></ol><h4>如何參與 DataCap</h4><hr><ul><li>參考官網 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fdatacap.devlive.org%2Fdeveloper_guide%2Fenv.html" target="_blank">開發者文檔</a></li><li>通過 Issues 列表參與 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdevlive-community%2Fdatacap%2Fissues" target="_blank">GitHub</a> &amp; <a href="https://gitee.com/devlive-community/datacap/issues">Gitee</a></li><li>加入我們的微信羣&amp;釘釘羣（在代碼倉庫中可以看到二維碼）</li><li>微信公眾號後台留言（搜索微信公公眾號 <code>devlive-sf</code> 關注，標記 DataCap 項目給我們留言即可）</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268990</guid>
            <link>https://www.oschina.net/news/268990</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Android Studio Hedgehog (2023.1.1) 穩定版發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Android Studio 2023.1.1&nbsp;<span>穩定版</span><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fandroid-studio-hedgehog-is-stable.html" target="_blank">已發佈</a></u><span>，代號 "</span>Hedgehog<span>"。</span></p><p>下載地址：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.android.com%2Fstudio%3Fhl%3Dzh-cn" target="_blank">https://developer.android.com/studio</a></u></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb7ce431349064dcf0ec711ab407e8f5cc7.png" referrerpolicy="no-referrer"></p><p>Android Studio Hedgehog 將底層 IntelliJ 平台升級到了 2023.1，添加了新功能，旨在提高應用程序性能和電池壽命，使升級到最新 Android 版本的應用程序更容易，並且提升使用 Jetpack Compose 的開發速度，以提高開發者的生產力。</p><p>以下是一些主要的功能和改進：</p><ol><li><p><strong>應用程序性能</strong>：Android Studio Hedgehog 提供了 App Quality Insights 工具，其中包括 Android vitals 數據。通過 Android vitals，開發者可以查看在 Google Play 商店發佈的任何應用程序的崩潰報告，無需在應用程序中進行額外的儀器化。開發者可以查看 Android vitals 問題、篩選它們，並從 Play 中查看崩潰的原因，從堆棧跟蹤跳轉到代碼，快速瞭解和解決崩潰。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-abcd5ef88e1fb351967ac0d35d842b2130a.png" referrerpolicy="no-referrer"><br> &nbsp;</p></li><li><p><strong>電源分析器</strong>：新的 Power Profiler 可以顯示設備上的電源消耗情況。它將電源消耗信息按子系統（稱為「Power Rails」）進行分段。這有助於開發者可視化電源消耗與應用程序中發生的操作之間的關聯。通過瞭解這些信息，開發者可以通過運行 A/B 測試來比較不同算法、功能甚至應用程序的不同版本的功耗，從而可能識別和修復應用程序中的功耗問題。優化功耗較低的應用程序可以改善電池和熱性能，最終提供更好的用户體驗。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-3ebcd51b6c8babaede19a4faa95fb8d39d0.png" referrerpolicy="no-referrer"><br> &nbsp;</p></li><li><p><strong>編碼生產力</strong>：Android Studio Hedgehog 引入了 Android SDK Upgrade Assistant，它提供了一個逐步向導流程，幫助開發者升級到目標 SDK 版本。它將文檔直接引入 IDE，節省時間和精力。Hedgehog 版本還添加了額外的相關性過濾器，以刪除不必要的步驟，並且在某些情況下，升級助手將準確指出需要進行更改的代碼位置。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-f3c9eb53c6f9692cca6fe995cb22f8f0415.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></li><li><p><strong>新的用户界面</strong>：在 Giraffe 版本中，我們推出了一個全新的用户界面。這個重新設計的主題減少了視覺複雜性，提供了更容易訪問的基本功能，使界面看起來更加現代和清晰。在 Hedgehog 版本中，我們根據用户的反饋進行了更新，添加了緊湊模式、垂直和水平分割以及 Mac OS 的項目選項卡。<br><img alt="" src="https://oscimg.oschina.net/oscnet/up-ec74c1d250255dab48c8691f8f1a467d857.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p></li><li><p><strong>設備鏡像</strong>：您現在可以在 Android Studio 的 Running Devices 窗口中鏡像您的物理 Android 設備。通過通過 ADB 通過 USB 或 Wi-Fi 直接在 Android Studio 中鏡像設備的顯示屏，您可以執行常見操作，如啓動和與應用程序交互、旋轉屏幕、摺疊和展開手機、調整音量等。這樣可以方便地在 Android Studio 內部完成這些操作，而無需切換到設備上進行操作。<br><img src="https://oscimg.oschina.net/oscnet/up-e948c8fe967e8a8edccd6df3a0c819f7fed.gif" referrerpolicy="no-referrer"></p></li></ol><p>詳情查看<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fandroid-studio-hedgehog-is-stable.html" target="_blank">發佈公告</a></u>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 03:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268979/android-studio-hedgehog-stable</guid>
            <link>https://www.oschina.net/news/268979/android-studio-hedgehog-stable</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[袋鼠數據庫工具 v3.99.2 已發佈，第一個完成 GTK4 升級的大型應用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>重點特性介紹</h2><ol><li>這是兩個版本（3.99.1 / 3.99.2）的合併新聞稿</li><li>連接管理頁面支持分組和添加機構；</li><li>起始頁支持自定義默認頁面</li><li>對象瀏覽器全字段過濾支持</li><li>App 實現激活支持</li></ol><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">袋鼠從第一行代碼到成長為 GTK3 應用中的頂流槓把子，又經過兩年多夜以繼日的升級開發，成為第一個完成 GTK4 升級的大型 GTK 應用，開發團隊為此付出了艱苦卓絕的努力，克服了重重困難。數據庫引擎從 libgda 5.0 到 libgda 6.0，然後升級到 ODBC，再升級為 DirectAccess；SQLite 支持從 SQLite 到 SQLCiphper，再到 SQLite3MC。。。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">如果您能體驗到袋鼠的生產力和絲滑功能，也請您為袋鼠團隊加油，謝謝。</p><h2>新特性或修復的缺陷列表</h2><ul><li>起始頁支持自定義默認首頁</li><li>更新模塊文件屬性</li><li>調整數據網格列寬度</li><li>重構執行行為支持多語句執行</li><li>數據庫連接添加分組和機構支持</li><li>改進對象瀏覽器全字段過濾支持</li><li>更新數據網格當前單元格背景顏色</li><li>App 實現激活支持</li><li>添加多模型視圖支持</li><li>工作台關閉時添加提示和確認支持</li><li>SQLite: 替換 SQLCipher 為 SQLite3MC</li><li>SQLite: 增加兼容性支持提示</li><li>SQLite: 調整表設計界面字段類型</li><li>PostgreSQL: 隱藏模板和臨時數據庫</li><li>更新中文語言支持 (zh-CN/zh-TW/zh-SG/zh-HK)</li><li>改進，空值 (NULL) 支持</li><li>修復: MySQL/MariaDB 導出崩潰問題</li><li>修復: 快速打開並關閉連接空間時崩潰問題</li><li>修復: 導出表結構和數據到文件時崩潰問題</li><li>修復: 源碼編輯器顯示樣式問題</li><li>修復: SQL 格式化和縮微化丟失內容問題</li><li>修復: 連接空間視圖佈局加載問題</li><li>修復: App 關閉時無法保存空間佈局問題</li><li>修復: 實體關係模型視圖關閉時崩潰問題</li><li>修復: 使用錯誤的類型封裝用户數據</li></ul><h2>下載與安裝</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv3.99.2.231201.html" target="_blank">袋鼠數據庫管理工具 3.99.1</a></p><h2>新版本功能快照</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2F" target="_blank"><img alt="連接分組" src="https://oscimg.oschina.net/oscnet/up-bae7af3d082e6a4a7194345022123e1606f.gif" referrerpolicy="no-referrer"></a><span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2F" target="_blank"><img alt="首頁默認頁定製" src="https://oscimg.oschina.net/oscnet/up-5e72dbe9eda442c20c3aef0fa33d34c1412.png" referrerpolicy="no-referrer"></a><span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.datatable.online%2Fzh%2Fdownload%2Fv3.93.1.230928.html" target="_blank"><img alt="袋鼠數據庫工具 v3.93.1 快照" src="https://oscimg.oschina.net/oscnet/up-e0853214711ebcdc88b4aa8ddeff6e5f7c6.png" referrerpolicy="no-referrer"></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268976/kangaroo-3-99-2-released</guid>
            <link>https://www.oschina.net/news/268976/kangaroo-3-99-2-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[哈工大人工智能專業大一學生寫了 70 萬行代碼？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>哈爾濱工業大學近日在其公眾號發表的一篇文章引起了不小爭議。</p><p>該文章介紹稱，哈工大計算學部人工智能專業的一名 2022 級學生在中國機器人及人工智能大賽總決賽上獲得了<strong>機器人應用賽（自動駕駛仿真）一等獎</strong>。</p><p>據瞭解，該比賽涉及人工智能、無人駕駛 &nbsp;和虛擬仿真等學科領域，還涉及高精地圖、定位、感知 &nbsp;預測、規劃與控制等模塊的運行機制和代碼架構。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-4e9f3dd3dff3e07407fc1c6d36c7929e333.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c32e0b9e93b8ada29cac4146e775157de9d.png" referrerpolicy="no-referrer"></p></blockquote><p>但寫這篇文章的人顯然不瞭解編程，所以鬧出了下圖中「連續幾個月寫了 70 萬行代碼」的抽象現場。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-08391d81d81371237587ffa244dd02b6ae9.png" referrerpolicy="no-referrer"></p><p><img height="714" src="https://static.oschina.net/uploads/space/2023/1201/105216_eog8_2720166.png" width="1400" referrerpolicy="no-referrer"></p><p><img height="668" src="https://static.oschina.net/uploads/space/2023/1201/103954_yEjJ_2720166.png" width="1406" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKyBMh6QHPZ3yUxRxjFKIJQ" target="_blank">https://mp.weixin.qq.com/s/KyBMh6QHPZ3yUxRxjFKIJQ</a></u></em><br><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrAjBwbzKwmxMNrzBOAUy6w" target="_blank">https://mp.weixin.qq.com/s/rAjBwbzKwmxMNrzBOAUy6w</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 30 Nov 2023 02:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268970</guid>
            <link>https://www.oschina.net/news/268970</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
