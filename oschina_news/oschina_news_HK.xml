<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 10 Oct 2023 03:54:34 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Ardour 8.0 正式發佈，開源數字音頻工作站]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>開源數字音頻工作站 Ardour 8.0 已正式發佈。</p><blockquote><p>Ardour 是開源的數字音頻工作站軟件，支持 Linux、macOS 和 Windows 系統。你可以使用它來錄製、編輯和混合多軌音頻，或者只是嘗試新的想法、音樂和聲音。</p><p>Ardour 的功能包括：多通道錄音，非破壞性編輯，無限撤銷 / 重做，全自動化的支持，一個強大的調音台，無限軌道 / 總線 / 插件，時間碼同步和硬件控制。</p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f349693e8ee83064bf20e39114d2484b76e.png" referrerpolicy="no-referrer"></p><p>8.0 除了修復 bug 外，還包含大量改進用户體驗的變更 (Quality Of Life)：</p><ul><li>在用户長期要求下加入了調整 MIDI 音鍵速度的傳統 Lollipops 編輯界面</li><li>允許用户根據需要編排音樂</li><li>支持 3 點編輯（3-point edits）</li><li>新的 MIDI Track Piano Roll Header</li><li>支持 Launchpad Pro</li><li>Quick Groups</li></ul><p>詳情查看更新説明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fardour.org%2Fwhatsnew.html%23" target="_blank">https://ardour.org/whatsnew.html</a><br> 下載地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.ardour.org%2Fdownload" target="_blank">https://community.ardour.org/download</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 03:49:31 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261119/ardour-8-0-ga</guid>
            <link>https://www.oschina.net/news/261119/ardour-8-0-ga</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 移動應用 9 月收入高達 458 萬美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">市場情報公司 Appfigures 的最新分析數據<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fappfigures.com%2Fresources%2Finsights%2F20231006%3Ff%3D2" target="_blank">顯示</a>，OpenAI 的官方 ChatGPT 應用程序安裝數量和收入持續增長，9 月份創下了兩項新紀錄：全球 iOS 和 Android 應用程序的下載量達到 1560 萬次，其中 Google Play 的下載量為 900 萬，App Store 的下載量為 660 萬。以及總收入接近 460 萬美元，淨收入 320 萬美元；其中 300 萬美元，自 iPhone 用户，其餘來自 Google Play。</span></p><p><span style="color:#000000">ChatGPT 官方應用自 5 月起在 App Store 上架，7 月正式登錄 Google Play 平台。自推出以來，ChatGPT 應用的總安裝量已達到 5220 萬次。該應用在 6、7、8 月份的總營收分別為 210 萬美元、274 萬美元以及 381 萬美元。</span></p><p><span style="color:#000000">目前為止，美國仍是 ChatGPT 的最大市場，貢獻了該應用程序生命週期收入的約 60%。</span></p><p><img height="285" src="https://oscimg.oschina.net/oscnet/up-fd19ce9c3118494505c250065e7d0da18c7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">但數據也顯示，移動端 ChatGPT 應用的收入增長已經開始放緩。前幾個月的收入增長率高達 30% (7 月為 31%，8 月為 39%)，但 9 月份已降至 20%，是迄今為止最低數值。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F09%2Fchatgpts-mobile-app-hit-record-4-58m-in-revenue-last-month-but-growth-is-slowing%2F" target="_blank">TechCrunch</a> 指出，收入增長放緩可能是 ChatGPT 接近飽和的第一個跡象，表明願意為每月 19.99 美元的 ChatGPT+ 訂閲服務付費的用户可能已經達到了上限。</span></p><p><span style="color:#000000">不過 ChatGPT 並不是收入最高的 AI 應用。Appfigures 數據顯示，一款名為 Ask AI 的競爭對手由於大量的廣告支出而獲得了更多的收入；從 ChatGPT 移動版推出時的 5 月份的 648 萬美元上升到了 8 月份的峯值 655 萬美元。9 月份略有下降，降至 551 萬美元，但仍高於 ChatGPT。其他競爭者如 Genie 和 AI Chat Smith 的增長幅度都不及 Ask AI。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 03:37:31 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261118/chatgpts-mobile-app-revenue-4-58m</guid>
            <link>https://www.oschina.net/news/261118/chatgpts-mobile-app-revenue-4-58m</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[一站式服務，openKylin 系統小管家懂你所需！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">openKylin 社區 SystemManager SIG 致力於開發一款面向社區用户，能傾聽用户煩惱和訴求，也能提供便利途徑、解決用户問題的麒麟管家應用。在 openKylin 1.0.1 版本中，麒麟管家新增了服務支持模塊，用於收集問題和建議。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">同時，社區還發布了</span><strong><span style="color:#0052ff">有獎參與活動</span></strong><span style="color:#000000">，</span><strong><span style="color:#000000">邀請所有用户把大家在系統使用過程中遇到的問題，通過麒麟管家的服務支持模塊快速提交至 gitee 平台，幫助快速排查和解決問題，參與就有機會獲得社區定製獎品～活動詳情可戳下方鏈接：</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left">https://mp.weixin.qq.com/s/EYaiHBM-VhiDg80Knbr_FA&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">在前面的活動中，我們為大家着重講解了</span><strong><span style="color:#000000">服務支持模塊</span></strong><span style="color:#000000">。今天，我們就來給大家詳細介紹下麒麟管家的其餘三個模塊，包括</span><strong><span style="color:#000000">故障檢測、垃圾清理、百寶箱</span></strong><span style="color:#000000">。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">一、網絡連接不成功，管家幫您找問題</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">首先要為大家介紹的功能是「故障檢測」。當前故障檢測內容還相對單一，只包含「網絡檢測」，後續會陸續增加其他檢測類型，及「一鍵修復」功能。</span></span></p><div><p style="text-align:center"><img alt="" height="673" src="https://oscimg.oschina.net/oscnet/up-d1b0a902ea99d05ab092028116240aaec7b.png" width="1066" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">使用方法非常簡單，只需點擊「一鍵檢測」按鈕，管家會自動逐項排查網絡問題，並給出提示。</span></span></p><div><p style="text-align:center"><img alt="" height="672" src="https://oscimg.oschina.net/oscnet/up-c749e6d50d7191e33aa355e6da5b6efc899.png" width="1059" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">此外，還可以根據每個人不同的上網需求，將經常訪問的網站加入自動檢測隊列中。點擊右下角的「內網檢測設置」，打開「開啓內網檢測」開關，然後將要檢測的網絡地址填寫到對應的位置，點擊右側的加號可以添加多個地址，添加完成後點擊「保存」。</span></span></p><div><p style="text-align:center"><img alt="" height="704" src="https://oscimg.oschina.net/oscnet/up-bd51680a0542c4e4754f3b24a69585376ef.png" width="1095" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">二、系統垃圾不用慌，麒麟管家幫您忙</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本節要為大家介紹的功能是「垃圾清理」。可以一鍵清理 openKylin 操作系統中的垃圾文件，當前支持系統緩存、瀏覽器 cookies 及系統使用痕跡的清理。</span></span></p><div><p style="text-align:center"><img alt="" height="668" src="https://oscimg.oschina.net/oscnet/up-8055700cec2b846eca2ad5bd53aeb7038b1.png" width="1052" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">使用方法非常簡單，只需點擊「開始掃描」等待掃描完成，然後點擊「一鍵清理」即可自動完成清理操作。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bae775d8d6b2e43c75703c1b94faaf395d0.png" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">此外，還可以根據每個人不同的清理需求，自定義垃圾清理類型。點擊垃圾清理首頁的垃圾分類比如「系統緩存」即可彈出清理列表選項，勾選的清理項不同，掃描的結果也會不同。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c82351d8f8a62816ef181bf2ad234c52dc2.png" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">三、管家百寶箱上新啦</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">最後要為大家介紹的功能是「百寶箱」，其中會收錄一些精緻而實用的小工具。隨着 openKylin 1.0.1 版本發佈，百寶箱中也加入了新成員。</span></span></p><div><p style="text-align:center"><img alt="" height="699" src="https://oscimg.oschina.net/oscnet/up-ac1e256da0171f9ac9a7ed6a957d7028954.png" width="1095" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">在之前的版本，百寶箱中收錄了「文件粉碎機」，可以讓您輕鬆粉碎機密和隱私文件，避免被恢復。操作也很簡單，從百寶箱點擊「文件粉碎機」卡片，點擊「添加」按鈕添加待粉碎的文件，然後點擊「粉碎」按鈕即可開始粉碎操作。</span></span></p><div><p style="text-align:center"><img alt="" height="684" src="https://oscimg.oschina.net/oscnet/up-fca6200212c5658abca6d8585f0c7881d52.png" width="1072" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">此外，百寶箱還新增了「win 遷移工具」，用於將 windows 系統中的數據遷移至 openKylin。首先點擊「win 遷移工具」卡片，在設置中選擇「win 端如何設置」查看設置教程，根據教程設置 windows 端共享，然後將 win 端的連接信息「ip 地址」、「工作組」、「用户名」、「密碼」填寫在對應位置點擊「建立連接」。之後界面會根據 win 端共享的目錄結構生成樹狀圖表，在圖表中勾選要遷移的文件後點擊「開始遷移」即可自動遷移數據。</span></span></p><div><p style="text-align:center"><img alt="" height="696" src="https://oscimg.oschina.net/oscnet/up-907f36fa35cdf22684b187d1f14e47dea5b.png" width="1084" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">四、管家後續開發計劃</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">目前，小管家還有很多要完善的地方，如上文提到的故障檢測新增檢測項和一鍵修復功能，除此之外，還將新增驅動精靈板塊自動匹配和安裝外設驅動，百寶箱新增崩潰收集工具以及垃圾清理交互體驗優化等。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區 SystemManager SIG 組會持續努力，打造更好用的小管家，讓其成為您使用 openKylin 系統時最知心的「朋友」。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">關於 SystemManager SIG</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">SystemManager SIG 組致力於組建系統管家開源社區，負責開發和維護系統管家及附屬工具，為 openKylin 生態和實用性添磚加瓦，歡迎各位的加入！</span></span></p><ul><li><span><span style="color:#000000">郵件列表：</span></span></li><li><span><span style="color:#0052ff">systemmanager@lists.openkylin.top</span></span></li><li><span><span style="color:#000000">SIG 主頁：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/SystemManager</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 03:26:31 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261115</guid>
            <link>https://www.oschina.net/news/261115</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[curl 8.4.0 將修復高危安全漏洞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>curl 創始人&nbsp;Daniel Stenberg（社區稱號 bagder）表示將於 10 月 11 日發佈的 curl 8.4.0 會修復高危安全漏洞，並稱該漏洞可能是很長一段時間以來<strong> curl 遇到的最嚴重漏洞 (the worst curl security flaw in a long time)</strong>，同時影響到 libcurl 庫和 curl 工具。</p><p>此外還會修復被評級為"LOW"的安全漏洞——僅 libcurl 受影響。</p><ul><li>CVE-2023-38545: severity HIGH (affects both libcurl and the curl tool)</li><li>CVE-2023-38546: severity LOW (affects libcurl only, not the tool)</li></ul><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1010/105819_w1di_2720166.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcurl%2Fcurl%2Fdiscussions%2F12026" target="_blank">https://github.com/curl/curl/discussions/12026</a></p></blockquote><p>bagder 表示目前無法透露有關受影響的版本範圍，因為這會導致漏洞被高精確地針對性利用。他只説到「過去幾年」發佈的版本都會受影響。</p><p>bagder 已在郵件列表宣佈該消息，建議使用 curl 的開發者密切關注即將發佈的 curl 8.4.0，同時梳理在項目中使用該庫的情況，以便及時安裝更新。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 03:14:46 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261110/curl-8-4-coming</guid>
            <link>https://www.oschina.net/news/261110/curl-8-4-coming</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Unity 首席執行官 John Riccitiello 離職]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根據 Unity 官方消息，Unity 首席執行官 John Riccitiello 已宣佈離職，該事宜即日生效。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6c10a9521e4d9916a0e7e7d57f5f97d17cb.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.businesswire.com%2Fnews%2Fhome%2F20231009494331%2Fen%2FUnity-Announces-Leadership-Transition" target="_blank">Unity 在一份聲明中表示</a>，已任命 James Whitehurst 為臨時首席執行官，Roelof Botha 為董事長。Riccitiello 將繼續為 Unity 提供建議，以確保平穩過渡，董事會將啓動任命一位永久首席執行官的流程。</p><p><img src="https://static.oschina.net/uploads/space/2023/1010/103434_WHy2_2720166.png" referrerpolicy="no-referrer"></p><p>此前 Unity 宣佈了新的收費規則，引起業內人士的強烈不滿。之後 Unity 向公眾和業內人士道歉，並調整了收費規則。</p><p><strong>延伸閲讀</strong></p><ul><li><a href="https://www.oschina.net/news/257929/unity-runtime-fee">Unity 引擎明年起根據遊戲安裝量收費 (runtime fee)</a></li><li><a href="https://www.oschina.net/news/258513/unity-apologize-for-runtime-fee">Unity 道歉：將修改 "runtime fee" 收費政策</a></li><li><a href="https://www.oschina.net/news/258477/wait-is-unity-allowed-to-just-change-its-fee-structure-like-that">走近「收費門」：互相矛盾的服務條款導致 Unity 面臨被起訴的風險</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261101/unity-ceo-john-riccitiello-is-retiring</guid>
            <link>https://www.oschina.net/news/261101/unity-ceo-john-riccitiello-is-retiring</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【SIG 月報】9 月 openKylin 社區 SIG 組最新進展分享]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">為推動社區繁榮發展，打造開源操作系統創新生態，openKylin 社區圍繞</span><strong><span style="color:#000000">創新硬件、人機交互、智能支撐、終端安全、互聯協同、雲端融合</span></strong><span style="color:#000000">等多個技術領域，以技術小組的形式開展深入研究和技術創新。接下來，讓我們一起盤點 9 月份 openKylin 社區 SIG 組的最新進展：</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#4f9eff">9 月社區新增 SIG</span></span></strong></span></p><h1>9 月社區新增 1 個 SIG 組，目前已累計成立 86 個 SIG 組，新增 SIG 組信息如下：</h1><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#ff9b0e"><span style="background-color:#f5faff">01</span></span><span style="color:#1c9cee"><span style="background-color:#f5faff">AI4OS SIG</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000"><span style="background-color:#f5faff">操作系統智能化（Artificial Intelligence for Operating System）由社區愛好者發起成立，致力於將人工智能（AI）與操作系統（OS）相結合，以實現操作系統的智能化和性能優化。將大模型為代表的 AI 技術嵌入 openKylin 操作系統，讓 AI 深扎底層操作系統，可以在沒有任何應用作為中介的情況下，直接調用 AI 大模型能力完成任務。</span></span></span></p><ul><li><span><span style="color:#000000">SIG 主頁：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/AI4OS</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#4f9eff">9 月社區 SIG 活躍度彙總</span></span></strong></span></p><p>9 月社區新增有效 PR 數 559 個、倉庫 Fork 數新增 104 個、SIG 組公開例會召開 7 次。截至目前，社區累計有效 PR 數 11122 個、倉庫 Fork 數 4364 個、SIG 組公開例會召開 93 次，其中：</p><ul><li><span><span style="color:#000000">9 月社區 SIG 組 PR 貢獻 top15 如下：</span></span></li></ul><div><p style="text-align:center"><img alt="" height="556" src="https://oscimg.oschina.net/oscnet/up-f6da435acfce936b5ba91e340785173187f.png" width="794" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">9 月社區 SIG 組活躍地圖分佈情況（顏色越深代表越活躍，參考維度：PR、issue、SIG 會議）如下：</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-13b61252308faea98672ac9805bdafca274.png" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#4f9eff">9 月社區技術進展與成果</span></span></strong></span></p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>一、UKUI SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">UKUI(Ultimate Kylin User Interface) SIG 小組致力於桌面環境相關軟件包的規劃、維護和升級工作，滿足各種設備和用户需求的桌面環境程序，主要包含程序啓動器（開始菜單）、用户配置、文件管理、登錄鎖屏、桌面、網絡工具、快捷配置等，為用户提供基本的圖形化操作平台。桌面核心組件開發工具以 Qt、C++為主，宗旨是始終如一地提升系統的操作體驗，提供集穩定性、美觀性、流暢性和便捷性為一體的桌面環境。9 月進展如下：</span></span></p><ul><li><span><span style="color:#000000">系統監視器新增後台運行功能並註冊託盤圖標；</span></span></li><li><span><span style="color:#000000">搜索、開始菜單適配多 Display 場景下；</span></span></li><li><span><span style="color:#000000">優化搜索設置項顯示策略、優化內存操作邏輯和若干 bug；</span></span></li><li><span><span style="color:#000000">修復文件管理器操作相關的若干問題；</span></span></li><li><span><span style="color:#000000">修復切換語言後立刻重啓計算機後桌面出現多餘圖標問題；</span></span></li><li><span><span style="color:#000000">修復桌面目錄後出現「鎖狀」圖標問題；</span></span></li><li><span><span style="color:#000000">修復任務欄預覽窗口操作顯示邏輯問題；</span></span></li><li><span><span style="color:#000000">修復控制面板關於模塊部分名詞拼寫問題；</span></span></li><li><span><span style="color:#000000">修復系統安裝完成後應用通知按鈕為關閉狀態的問題；</span></span></li><li><span><span style="color:#000000">完成 3 篇桌面協議相關翻譯；</span></span></li><li><span><span style="color:#000000">UKUI-Lite 技術方案評審；</span></span></li><li><span><span style="color:#000000">UKUI Framework 後續規劃及統一接口方案評審。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎各位感興趣的社區開發者加入我們，一起打造 openKylin 桌面系統穩定易用的桌面環境！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>二、RISC-V SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#333333">本</span>SIG 組主要負責 RISC-V 架構開源軟件包的維護，發佈 openKylin 的 RISC-V 版本，進行軟件包構建、系統構建等工作。9 月 RISC-V SIG 組進展如下：</span></p><ul><li><span><span style="color:#000000">解決了 VisionFive2 開發板在 wayland 模式下鼠標指針不顯示的問題；</span></span></li><li><span><span style="color:#000000">製作 roma 筆記本新版 sdk3.6.1 的鏡像；</span></span></li><li><span><span style="color:#000000">更新併發布 VisionFive2 和荔枝派的 openKylin1.0.1 版本鏡像；</span></span></li><li><span><span style="color:#000000">獲取 electron 的包，通過安裝高版本依賴的方式解決了 electron 的啓動問題，目前可以在 xorg 模式下正常運行 electron；</span></span></li><li><span><span style="color:#000000">嘗試在荔枝派開發板中適配 gpu，和廠商溝通聯調；</span></span></li><li><span><span style="color:#000000">調試並進行 box64 代碼梳理。主要學習動態重編譯部分，梳理了運行微信從模擬運行入口，到 opcode 翻譯，到彙編指令執行的流程。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 RISC-V 開發平台技術方向感興趣的愛好者加入到 RISC-V SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>三、Release SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Release SIG 主要負責協調各個 SIG 組，把控版本開發進度和風險，制定版本發佈計劃，完成版本發佈工作等。Release SIG 9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">推動 openKylin 1.0.1 各架構版本集成、測試驗收等工作，完成 1.0.1 版本發佈；</span></span></li><li><span><span style="color:#000000">推動搜狗輸入法 NG 版本和 openKylin 1.0.1 適配；</span></span></li><li><span><span style="color:#000000">編寫 openKylin 1.0.1 版本更新日誌；</span></span></li><li><span><span style="color:#000000">openKylin 2.0 版本規劃，需求討論、推進，啓動基礎庫選型等工作；</span></span></li><li><span><span style="color:#000000">和儒特科技討論 QSFramework 在社區合作落地、代碼持續集成等事宜。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區版本集成、版本管理、版本發行等工作感興趣的愛好者加入到 Release SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>四、Packaging SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Packaging SIG 負責維護 openKylin 社區的軟件包打包規範，維護公共軟件包，以及協調和決策社區版本發佈過程中的包依賴問題。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">《openKylin 生態應用自主選型構建》任務第一階段選型報告評審；</span></span></li><li><span><span style="color:#000000">cme 程序無法使用（Compilation failed），執行報錯問題分析修改；</span></span></li><li><span><span style="color:#000000">解決 arm64 架構基礎構建工具 cmake 運行報符號未定義的問題；</span></span></li><li><span><span style="color:#000000">軟件包源碼信息整改。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區軟件自主選型、編譯打包工作感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>五、QA SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">QA SIG 組致力於提升 openKylin 社區版本質量，包括社區版本測試、質量保障等。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">openKylin-1.0-2309-beta-0901 版本測試；</span></span></li><li><span><span style="color:#000000">窗管替換 wlcom 專項測試；</span></span></li><li><span><span style="color:#000000">openKylin-1.0-2309-beta-0908 版本測試；</span></span></li><li><span><span style="color:#000000">openKylin-1.0.1-0918 版本測試。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區版本測試、質量管理感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>六、SecurityGovernance SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin SecurityGovernance SIG 通過接收和響應 openKylin 社區的產品安全問題報告、提供社區安全指導，開展安全治理等活動提升社區產品的安全性。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">Genmai 開發：新增安全漏洞自動化用例 poc40 個；解決某些架構下返回值異常導致崩潰問題；適配龍芯架構,適配 risc-v 架構，進度 80%；解決漏洞用例 yaml 文件格式錯誤問題；解決 kysec、Selinux 導致 poc 及基線掃描出錯問題；增加「將 root 權限傳入基線腳本」的功能；開發根據服務端版本自動更新功能；解決 C/S 架構漏洞檢測傳輸時長過長造成超時問題；新增原創安全漏洞 5 個；</span></span></li><li><span><span style="color:#000000">參加在西班牙畢爾巴鄂由 Linux 基金會主辦的 2023 Linux 安全峯會，並發表主題演講。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 版本安全全漏洞挖掘/驗證、安全漏洞修復等安全方面工作感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>七、OpenSDK SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">OpenSDK SIG 組負責開發者套件（base、system、applications）規劃、開發、維護等工作，致力於解決應用在多操作系統中的兼容性問題。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">完成配置化模塊的 conf2 表結構設計、xml2yaml 特定格式轉換工具開發工作；後端服務支持數據寫入以及鍵值對變更信號發送；</span></span></li><li><span><span style="color:#000000">優化並協助其他組件排查解決問題共 21 個：優化開發手冊易用性，包括 man 手冊以及開發指南中 API 引入的 sdk 版本號；優化應用埋點接口功能。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對開發者套件感興趣的社區愛好者們加入 OpenSDK SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>八、CompatWinApp SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">CompatWinApp SIG 組致力於將大量的 Windows 系統應用程序引入到 openKylin 系統。SIG 組將通過研究應用兼容技術和指令翻譯技術，研製完善的 windows 應用兼容方案，讓更多的 windows 應用能兼容運行於 openKylin 系統，不斷繁榮 openKylin 軟件生態。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">修改 wine 助手下載流程，直接下載應用修改為先跳轉到應用程序下載頁面；在當前應用配置文件中增加應用下載頁參數；</span></span></li><li><span><span style="color:#000000">下載應用時增加對用户的操作提示；修復當應用下載鏈接更新時無法下載的問題；修復下載鏈接重定向時無法下載的問題；</span></span></li><li><span><span style="color:#000000">研究解決了 wine riched20 模塊中導致的微信編輯輸入框右鍵不顯示菜單的問題，初步解決了編輯框光標位置錯亂的問題；</span></span></li><li><span><span style="color:#000000">在 wine-program 倉庫 wiki 界面增加 wine 助手的使用説明。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對應用兼容技術和指令翻譯技術感興趣的愛好者加入到 CompatWinApp SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>九、Infrastructure SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Infrastructure SIG 負責 openKylin 社區的基礎平台系統功能的開發、維護。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">優化 openKylin 看板結合 SIG 狀態自動更新 SIG 數量問題；</span></span></li><li><span><span style="color:#000000">openKylin 看板增加任務平台積分更新功能；</span></span></li><li><span><span style="color:#000000">優化 openKylin 看板前端，增加頁面緩存 TAB；</span></span></li><li><span><span style="color:#000000">CLA 開放企業管理員手動添加簽署員工限制；</span></span></li><li><span><span style="color:#000000">CLA 修復企業管理員後台一些內容未國際化問題；</span></span></li><li><span><span style="color:#000000">openKylin 看板增加 commit 信息統計，支持 commit 記錄導出。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區基礎設施平台開發維護感興趣的愛好者加入到 Infrastructure SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十、Connectivity SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本 SIG 組致力於 openKylin 社區的互聯互通基礎能力開發與維護，9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">優化文件管理其插件相關能力，解決線程安全問題。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎各位感興趣的社區開發者加入 Connectivity SIG 小組，一起共建 openKylin 桌面系統互聯互通能力！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十一、I18n SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">I18N SIG 組負責 openKylin 社區國際化和本地化相關工作，包括多語言開發框架、多語言平台開發和維護，以及社區、版本內文檔的翻譯管理相關工作。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">翻譯官網新聞 18 篇；</span></span></li><li><span><span style="color:#000000">翻譯 openKylin 基於 RISC-V 的主要工作介紹；</span></span></li><li><span><span style="color:#000000">校驗 openKylin 個人信息保護及隱私政策聲明。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對操作系統、網站網頁、文檔等翻譯工作感興趣的社區愛好者們加入 I18n SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十二、InputMethod SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本 SIG 組致力於組建輸入法開源社區，推進開源輸入法框架及開源輸入法在社區維護。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">定位分析搜狗輸入法問題，包括 wayland 環境輸入窗口顯示異常、託盤菜單圖標顯示異常和候選詞上屏異常等問題；</span></span></li><li><span><span style="color:#000000">討論 OK 輸入法進展，完成 OK 輸入法設計文檔；</span></span></li><li><span><span style="color:#000000">分析拼音輸入法右鍵菜單顯示異常問題，與 fcitx 社區討論修改情況；</span></span></li><li><span><span style="color:#000000">完成虛擬鍵盤支持動畫效果開發，提高 UI 美觀度；</span></span></li><li><span><span style="color:#000000">完成虛擬鍵盤支持多語言輸入開發，其中包括哈薩克語、維吾爾語、柯爾克孜語和藏語等。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區 fcitx 輸入法框架、桌面虛擬鍵盤開發工作感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十三、Kernel SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Kernel SIG 組致力於新硬件適配、新功能、新特性開發。不斷提升內核健壯性、穩定性，能更好的為 openKylin 系統和應用程序提供底層技術支持。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">6.1 內核從 6.1.43 更新到 6.1.55。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對內核感興趣的社區小夥伴加入 openKylin 社區 Kernel SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十四、Virtualization SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Virtualization SIG 組致力於構建 openKylin 社區系統虛擬化技術，打造面向端、邊、雲的全場景虛擬化解決方案。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">qemu:修復了 CVE-2023-0330 漏洞。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對虛擬化組件或軟件包技術感興趣的社區小夥伴加入 openKylin 社區 Virtualization SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十五、Framework SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本 SIG 組致力於為 openKylin 社區提供集程序編輯、編譯、調試、發佈、分析等全套開發功能的編程環境，涵蓋通用集成開發環境、編譯工具鏈、運行時環境、類庫等，9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">Kylin-Code 發佈 v0.1.3，修復諸多問題，並上架應用商店；</span></span></li></ul><ul><li><span><span style="color:#000000">C/C++調試，Java 調試，插件依賴管理，死鎖檢測等插件發佈新版本。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎對集成開發環境研發感興趣的社區開發者和愛好者加入 Framework SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十六、Cutefish SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Cutefish SIG 負責移植 Cutefish 桌面環境及其組件，專注於打造美觀易用、極簡操作的桌面環境。9 月進展如下：</span></span></p><ul><li><span><span style="color:#000000">完成 RISC-V 架構開發板 VisionFive2 的適配工作；</span></span></li><li><span><span style="color:#000000">完成 ARM 架構開發板 CoolPi 4B 的適配工作。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">如果您對移植桌面環境有興趣，或者有相關打包經驗，歡迎加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十七、KernelBuilder SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">KernelBuilder SIG 組負責 openKylin 內核預覽版本的自動化構建，構建工具（kernel-builder）的規劃、開發、維護等工作。同時積極維護了 openkylin-rootfs 和 openkylin-wsl 倉庫，為 openKylin 提供了可用的根文件系統、wsl 開發環境為 openKylin 在 docker 容器化創造了條件。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">rootfs 根文件系統迭代更新；</span></span></li><li><span><span style="color:#000000">docker 鏡像打包製作；</span></span></li><li><span><span style="color:#000000">利用 github actions 自動打包製作 rootfs 根文件系統和 docker 鏡像，並更新內部環境；</span></span></li><li><span><span style="color:#000000">distcc 軟件適配進行中；</span></span></li><li><span><span style="color:#000000">為內核自動化構建創造 docker 預運行環境；</span></span></li><li><span><span style="color:#000000">同時本月聯合 opendde sig 開展共同開發計劃；</span></span></li><li><span><span style="color:#000000">香橙派 kernel 適配中、根文件系統適配中；</span></span></li><li><span><span style="color:#000000">內部測試 apt 源已搭建完成、目前可以小範圍通過 apt 分發測試版內核。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區內核構建及應用、docker 容器化、根文件系統、wsl 開發環境感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十八、RTHypervisor SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">RTHypervisor SIG 小組致力於實時虛擬化技術的研究，目前主要包括 Jailhouse，提供工控、車載等領域實時控制的虛擬化解決方案，Jailhouse 項目 9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">新增 arm64 平台上通過將 pcie rc 和 its 隔離給 non root cel 的方式，將 pcie 設備隔離給 non root cell，實現 pcie 設備直通功能。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區實時虛擬化技術感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十九、FAQ SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">FAQ SIG 小組致力於收集各渠道社區開發者、愛好者等用户反饋的問題，並建立相關標準化流程推動問題解答或解決同時，在這一過程中不斷為 openKylin 社區積累 FAQ 知識庫。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">召開 1 次 SIG 例會，和 UKUI SIG，Docs SIG，Community SIG 組交流和討論當前待解決的問題；</span></span></li><li><span><span style="color:#000000">收集論壇、社羣高頻問題並提交 issue 指派給開發，解決 10+高頻問題；</span></span></li><li><span><span style="color:#000000">社羣用户答疑與指導，指導用户解決系統下載安裝、軟件商店、桌面環境等相關問題。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>二十、OpenDDE SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">OpenDDE SIG 致力於維護 openKylin 的 DDE 桌面環境以及相關組件，專注於打造美觀易用、極簡操作的桌面環境。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">聯合 KernelBuilder SIG 研究了 VisionFive2 EDK2 UEFI 鏡像製作流程；</span></span></li><li><span><span style="color:#000000">DDE 桌面軟件包更新工作。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">如果您對移植桌面環境有興趣，或者有相關打包經驗，歡迎加入我們！</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261098</guid>
            <link>https://www.oschina.net/news/261098</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[搞流式計算，大廠也沒有什麼神話]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p>抖音、今日頭條，是字節跳動旗下最受用户歡迎的兩款產品，也是字節跳動的門面。而在這背後，是眾多技術團隊在支撐，流式計算就是其中一支。</p><p>不過，即使是在字節跳動，搞流式計算也沒有神話。只有一羣年輕人，花了六年時間，一步一個腳印，從一開始的「不懂技術不懂業務」，最後承載起了字節內部流式計算平台以及應用場景的構建，支撐了機器學習平台、推薦、數倉、搜索、廣告、流媒體、安全和風控等眾多核心業務。2022 年，該團隊完成了對 Flink 計算引擎的雲原生化改造，並通過火山引擎正式對外提供雲上能力。</p><p>這不是一個挽狂瀾於既倒的英雄故事，沒有什麼跌宕起伏的情節，也沒有耀眼的鮮花與掌聲。而是千千萬萬個普通開發者中的一小羣人，一邊在業務中被動接受成長，一邊在開源中主動尋求突破的一段記錄。</p><span id="OSC_h3_1"></span><h3><span style="color:#2980b9">01 <strong>代碼要寫，業務也要拉</strong></span></h3><p>2019 年，隨着抖音的爆發，字節跳動站在了高速增長的起點，直播、短視頻，廣告等業務也都乘勢而起。這些業務，都需要流式計算來支撐。</p><p><strong>字節流式計算團隊負責人張光輝，正面臨諸多棘手的問題。</strong></p><p>先把時間線往前推兩年，彼時張光輝剛加入字節跳動，計算引擎用的還是 Apache<em></em>Storm——誕生於 2011 年的、Twitter 開發的第一代流處理系統，只支持一些 low level 的 API。</p><p>「所有的 Storm 任務都是在開發機上用腳本提交，運維平台處於非常原始的狀態。如果 Storm 集羣故障，作業都無法自動恢復，甚至無法找到所有存量作業。」張光輝對此記憶猶新。</p><p>話雖這麼説，但誰也別嫌棄誰。那時張光輝的履歷上，並沒有流式計算產品的經驗，不過有些「沾親帶故」——參與過流式計算的上下游產品開發，比如數據採集、消息隊列。</p><p>好在趁着字節的業務場景偏單一，主要聚焦在機器學習場景，張光輝和其團隊將流式計算引擎從 Apache Storm 切換到了 Apache Flink。所謂團隊，其實連他在內，也僅有兩人。之後又在 2018 年與數據流團隊合作完成了流式計算平台化的構建，包括任務的監控、報警，日誌採集，異常診斷等工具體系。</p><p>來到 2019 年，流式計算要支撐的業務場景已經相當豐富，擴展到了實時數倉、安全和風控等，並且還在不斷增加。單個場景需求也變得更加複雜：推薦業務越來越大，單個作業超過 5 萬 Cores；實時數倉業務場景需要 SQL 來開發，且對數據準確性有了更高要求。</p><p>然而，由於團隊人手嚴重不足，工作進展很是緩慢。「只有兩個人，Oncall 輪流值周。不用值周的時候，往往都在解決上一週 Oncall 遺留的問題。」張光輝如此形容。</p><p>張光輝不得不一邊擴充人員，一邊與數據集成團隊着手構建 SQL 平台。李本超正是這個時候加入了流式計算團隊，並且在不久之後，就成為了 Flink SQL 方向的技術負責人。</p><p><strong>然而，用 </strong><strong>SQL</strong><strong> 來開發</strong><strong>流式計算</strong><strong>任務</strong><strong>，李本超也沒有太多經驗：「一開始，技術也不懂，業務也不懂。」</strong></p><p>在此之前，他在一家中小型企業任職，工作範圍涉及廣泛，流式計算只能算其中一個方向。加入字節後，李本超這才意識到，字節的流式計算規模遠超自己的想象。之前只能看到 1 個併發的任務，而在字節，一個任務的併發卻可以上萬，僅單個任務使用的計算資源就比其上家公司所有任務加起來都多。</p><p>但李本超不能不懂。一週五天上班時間，其中有三天，張光輝早上第一件事情就逮着他問，跟哪個業務聊了，能新建幾個 SQL 任務。</p><p><strong>指標每天都在頭頂打轉，李本超不得不給團隊「拉業務」。</strong>用的話術就跟在大街上攔住路人賣產品一樣，只不過地點換成了字節在北京的各個工區。</p><p>「哎，這個流式計算我們可以通過 SQL 開發，你們感不感興趣？想不想了解一下？」李本超沒事就聯繫電商、直播、廣告、遊戲、教育等業務部門負責人。只要人家點頭，李本超二話不説，馬上坐班車跑去工區現場交流。</p><p>張光輝評價：「那個時候，真的是‘無所不用其極’。」</p><p>有了 SQL 平台，開發及維護效率飛速提升。「原來一個人開發一個任務，需要一兩天。而現在，一個人一天直接就能搞定十個任務。此外，業務方與我們的溝通方式也更簡單了，對方寫的代碼我們也都能看懂，優化起來很方便。」</p><p>除此之外，字節在 Flink 穩定性方面做了大量的工作，比如支持黑名單機制，單點故障恢復，Gang 調度，推測執行等功能。由於業務對數據的準確性要求更高了，團隊支持作業開啓 Checkpoint 機制來保證數據不丟失，並在字節得到了大面積的推廣和落地。</p><p>在這個過程中，李本超也發現，Flink 可能沒有想象得那麼強大、易用，比如隨便改一改 SQL 狀態就沒法兼容。針對這類尚未被社區解決的問題，字節內部也進行了大量的優化方案探索。</p><p style="text-align:center"><img height="600" src="https://oscimg.oschina.net/oscnet/up-e8d825d23950c5e2d58dc9a101db0d82ab1.png" width="600" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#8f959e"><em>字節跳動 </em></span><span style="color:#8f959e"><em>Flink</em></span><span style="color:#8f959e"><em></em></span><span style="color:#8f959e"><em>SQL</em></span><span style="color:#8f959e"><em> 任務佔比</em></span></p><span id="OSC_h3_2"></span><h3><span style="color:#2980b9">02 <strong>Flink</strong><strong>，原來不止於流式計算</strong></span></h3><p>字節跳動選用 Flink 作為流式計算處理引擎後，每天有數萬個 Flink 作業運行在內部集羣上，峯值流量高達每秒 100 億條數據。單個作業的規模也非常大，每個計算節點使用 3 萬左右的併發，整個作業使用 300 多台物理機。Flink 集羣的穩定性和性能優化，以及單個超大作業的部署、執行和 Failover 等優化，面臨的問題在整個業界都難覓第二。</p><p>由於 Flink 是一個流批一體計算引擎，字節跳動內部也在積極推動 Flink 流批一體落地，上線了 2 萬多個 Flink 批式作業，在這個過程中解決了很多穩定性和性能問題，比如 Hive 語法兼容、慢節點、推測執行等。</p><p>同時，字節跳動內部啓動了 ByteHTAP 項目，結合字節內部的 OLTP 系統，已經能夠支持數據延時低（亞秒級）、數據一致性要求高的分析型計算，但還缺一個計算引擎來支持 OLAP 計算。由於字節在 Flink 做了大量的深入優化，最終將其作為 ByteHTAP 的 OLAP 引擎。</p><p style="text-align:center"><img height="630" src="https://oscimg.oschina.net/oscnet/up-0bdaccfa52987511e6780144f12d4450ee4.png" width="772" referrerpolicy="no-referrer"></p><p><strong>然而，</strong><strong>在 ByteHTAP </strong><strong>開始給業務方提供線上 </strong><strong>OLAP</strong><strong> 服務時，新的問題又出現了。</strong>業務方不僅對單併發查詢的 latency （延遲）有要求，還希望團隊提供的 OLAP 服務能夠支持高併發度。</p><p>正值 2021 年年初，方勇加入了字節跳動，擔任流式計算架構師。為了支撐線上業務，方勇和團隊要儘快把這塊的能力給補齊。</p><p>「整個開發過程非常煎熬，壓力非常大。」方勇説：」ByteHTAP 已經提供了線上服務，我們需要快速迭代，使 Flink 支持更高的併發查詢。」</p><p>每次團隊開週會，方勇都會盯着 QPS 指標。用了近半年的時間，「總算把 QPS 從個位數優化到十幾、幾十，直到線上單集羣支持幾百 QPS」。</p><p>近兩年，字節正在將 Flink OLAP 諸多優化貢獻回社區。 Flink OLAP 的相關內容也加入了到了 Apache Flink 2. 0 的 Roadmap 中。</p><p>一條完整的數據生產鏈路，分為三個計算場景，分別是流式、批式和 OLAP 計算。在實時數倉場景，需要 Storm 或 Flink 來支撐流式計算；在批式場景，則要依靠 Hive 或 Spark。當計算語義不一樣時，兩套引擎會導致流式結果和批式結果不一致。而且，流批一體數據計算完成之後，還需導入數倉或者離線存儲，此時還要引入一套新的 OLAP 引擎去探查、分析，這就更加無法保證正確性和一致性。</p><p>而且，優化及維護也頗為麻煩。三套系統就意味着，要建三個團隊去分別維護。一旦遇到需要優化或者解決 bug 等情況，還要分別到三個社區提 issue 討論。</p><p>Flink 社區提出了 Streaming Warehouse 解決這個問題，字節調研了目前流式計算發展方向和 Streaming Warehouse 系統，基於 Flink 和 Paimon 構建了 Streaming Warehouse 系統，分別統一流批一體的計算和存儲，增加了作業和數據血緣管理、數據一致性管理、流式數據訂正和回溯等核心功能，解決流式計算的準確性和數據運維等問題。</p><p style="text-align:center"><img height="259" src="https://oscimg.oschina.net/oscnet/up-fca6618852b7122974aca81d2377233a202.png" width="600" referrerpolicy="no-referrer"></p><p><strong>最終，「三套引擎，三個團隊」變成「一套引擎，一個團隊」。</strong>用方勇的話來説，使用 Flink 作為整個數據生產鏈路統一的流式、批式和 OLAP 一體的計算引擎，已經完全就不用擔心數據的實時性、業務分析的複雜性。</p><p>至於 Flink 的未來，方勇已經有了設想。他希望能夠集合社區的研發能力，一起完善整個 Flink 的計算生態，將 Flink 打造成統一流、批和 OLAP 的 Streaming Warehouse 系統。</p><span id="OSC_h3_3"></span><h3><span style="color:#2980b9">03 新業務，新場景，新挑戰</span></h3><p>2022 年，字節流式計算團隊支撐研發的計算引擎商業化產品「流式計算 Flink 版」上線火山引擎，正式對外提供雲上計算能力，而不是僅僅服務於字節內部業務。</p><p>在字節，這款產品被稱為「Serverless Flink」。Serverless Flink 依託於字節跳動在業內最大規模實時計算集羣實踐，基於火山引擎容器服務（VKE/VCI），提供 Serverless 極致彈性，是開箱即用的新一代雲原生全託管實時計算平台。</p><p><strong>事實上，將</strong><strong> Serverless </strong><strong>Flink</strong><strong> 稱之為一款</strong><strong>新上線的產品</strong><strong>可能並不合適。</strong>李本超解釋，所謂「流式計算 flink 版」，其實就是團隊在六年時間裏，讓 Apache Flink 在字節內部實現了大規模應用，並把積累的大量的產品經驗和技術能力「包裝」了一下，而不是重新做了一個產品。</p><p>它是基於 Apache Flink 衍生出來的，可以理解為 Apache Flink 增強版，並且 100% 兼容 Apache Flink，包含諸多特性：</p><ul><li><p>開發效率提升。 流式計算 Flink 版支持算子級別 Debug 輸出、Queryable State、Temporal Table Function DDL，在開發效率上對開源版本 Flink 有顯著提升。</p></li><li><p>可靠性提升。 流式計算 Flink 版針對單個 Task 進行 Checkpoint，提高了大併發下的 Checkpoint 成功率。單點任務恢復和節點黑名單機制功能，保障了對故障節點的快速響應，避免業務整體重啓。</p></li><li><p>Serverless 雲原生架構。 極致彈性，1‰ 核精細調度。</p></li><li><p>易用性增強。 極簡 SQL 開發，開箱即用、免運維、支持流式數據全生命週期管理。</p></li><li><p>高性能低價格。 高性價比、高 SLA 保證、超低 TCO。</p></li></ul><p style="text-align:center"><img height="312" src="https://oscimg.oschina.net/oscnet/up-94e4c01fd23fdb7e7327a975d5f2575b6dd.png" width="800" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#8f959e"><em>流式計算</em></span><span style="color:#8f959e"><em>Flink</em></span><span style="color:#8f959e"><em>版，架構圖</em></span></p><p><strong>在 Serverless </strong><strong>Flink</strong><strong> 上線火山引擎之後，方勇發現，外部客户需求與內部業務需求很是不同。</strong>比如有的客户還在使用 Storm、Samza 等相對較為早期的流式技術棧。因此，團隊不僅要對客户進行技術培訓和技術支持，還要幫助技術支持人員理解客户的作業邏輯，以更好地服務其業務。</p><p>這意味着，流式計算團隊面臨的是新的場景與挑戰，有時甚至要從零開始構建一個新的系統。</p><p>不過，一切工作都在有條不紊地展開。近兩年，團隊成員已經擴展到 30 人，並對 Serverless Flink 在調度、運行時、SQL 等各個方面都進行了全方面的優化，極大提升性能。</p><p>此外，基於 Apache Flink 及 Apache Paimon，團隊在 Streaming Warehouse 實時數倉場景也有了新的突破，實現了支持數據的一致性、血緣，以及數據回溯等實時數倉的產品能力。</p><p>截止目前，基於流式計算 Flink 構建的實時業務場景已經涉及到字節幾乎所有的業務和產品，包括實時數倉、實時風控、商業化、電商、遊戲、小説、教育、房產、財經等，日常實時峯值超 100 億 QPS。與此同時，流批一體在特徵工程，數據同步，計數服務，電商等場景均得到了廣泛的使用和落地，已上線將近 2 萬 Flink Batch SQL 任務。</p><p><strong>此刻，張光輝才終於敢説：「 經歷了從 0 到 1 的過程之後，今天字節的流式計算平台，</strong><strong>已經可以打 8 分了。</strong><strong>」</strong></p><p>方勇提到，未來，團隊將在可用性、穩定性、性能等方面持續優化流式計算平台，並繼續深入 Flink OLAP 生產實踐，建設和完善穩定性和可用性等周邊系統，比如 Debug 能力、 Auto Scaling 系統。</p><p>除了流式計算之外，團隊在 Flink 批式方面也做了很多的優化和嘗試， 比如兼容 Hive SQL 語法等。同時，一些超大規模的作業，也在往 Flink 批式方向上去嘗試。在 Flink 批式場景積累經驗之後，團隊將會持續推動 Flink 流批一體的應用和實踐，同時結合社區需求，貢獻一些新的能力。</p><p>Native Engine 也將成為團隊探索的一大方向。Flink 以 Java 語言為主，部分技術涉及行式計算，導致它並不能很好地利用 CPU，以及更新迭代的一些新功能。而如何利用 Native Engine 提升性能及運算能力，降低成本，是大勢所趨。</p><span id="OSC_h3_4"></span><h3><span style="color:#2980b9">04 開源是一件自然而然的事</span></h3><p>從服務內部業務到服務外部客户，字節對 Apache Flink 的應用愈加深入。當然，字節之於 Apache Flink，並非只停留在「用」的層面，而是源源不斷地將其創新成果貢獻到開源社區中，更是成為了研發 Flink OLAP 等方向的主要牽頭企業。在眾多為 Flink 社區貢獻的國內企業中，字節參與度能排到第二。</p><p><strong>除了 </strong><strong>Apache Flink</strong><strong>，流式計算團隊還為 </strong><strong>Apache</strong><strong> Calcite 、Apache Paimon 這兩個項目做出了不小的貢獻，並在社區構建了一定的影響力。</strong></p><p>Apache Calcite 是一個動態的數據管理框架，它可以實現 SQL 的解析、驗證、優化和執行。當前，字節是該項目核心貢獻公司之一，參與 plan 優化、方言生態增強、運行時優化等工作。Apache Paimon (incubating) 則是一項流式數據湖存儲技術，可以為用户提供高吞吐、低延遲的數據攝入、流式訂閲以及實時查詢能力。字節是該項目的創始貢獻公司之一。</p><p>截至目前，字節流式計算團隊培養了包括李本超、方勇等在內共 8 名 Apache 項目 committer，為 Flink 社區貢獻了 174 個 commits，為 Calcite 社區貢獻了 47 個 commits，以及為 Paimon 社區貢獻了 107 個 commits。</p><p><strong>雖説開源成果豐碩，但在流式計算團隊，並沒有安排專門的人去貢獻開源。於他們而言，開源是一個自然而然的過程。</strong></p><p>「我們用開源的組件來搭建產品，鼓勵組員在日常開發過程中，將新增的功能特性、bug 修復以及一些優化，貢獻到社區。這就是我們日常的工作模式。希望大家在社區交流中，可以提升代碼質量以及保持對技術的探索。」張光輝補充説：「當然，最開始，也沒有什麼開源的氛圍，每個人都忙着業務。不過，李本超和方勇這兩個開源積極分子起了帶頭作用，其他團隊成員在其影響下，也逐漸接觸開源。」</p><p>李本超也提到，社區和公司之間沒有明顯界限。「上游項目 Apache Flink 跟我們的 Serverless Flink 其實是一個項目，只不過我們在用 Serverless Flink 來支撐一個更具體的公司業務場景。公司非常鼓勵我們把成果貢獻給社區。但如果內部需求更着急，或者説很難有一個非常快速且完整通用的方案，就會在內部先上線試用。」</p><p>團隊也不強制要求研發人員一定要參加社區。</p><p>「參與開源是一件比較偏個人的事情，看他自己個人興趣，以及對職業生涯、技術方面的規劃。不過為了保證內外系統的一致性，以及我們系統後續發展的兼容性，增進研發同學之間的技術交流及合作，我們非常鼓勵大家把遇到的問題提交到社區。有一些需要內部討論或支持方案，如果剛好也是外部開源社區所需要的，我們都會考慮把這些需求引進到內部。這樣可以做到內部統一開發，然後統一推進。」方勇解釋。</p><span id="OSC_h3_5"></span><h3><span style="color:#2980b9">05 要貢獻開源，其實並不容易</span></h3><p>如李本超所言，所有有利於社區變的更好的事情，都是一種貢獻，比如用户問答、代碼 review、文檔的維護、不穩定測試的修復、build 系統的提升、技術討論、release 等等。</p><p><strong>但對於從未參與過開源的人來説，開始可能是最困難的一步。</strong></p><p>「在 Apache Calcite 、Apache Flink 以及 Apache Paimon 等社區，開發者非常活躍，很多人提 issue 都會得到解答。但沒參與之前，去哪裏去找 issue，怎麼寫代碼，怎麼提 PR，怎麼新建 feature，整個流程完全是陌生的。這個過程其實聽起來比較簡單，但真正去實踐的時候，發現它還是有一定門檻。」方勇提到。</p><p><strong>即使已經有了一些重大的開發成果，要貢獻給社區，也並不是簡單地把代碼從內部拿到外部。</strong></p><p>一些針對專項業務定製化開發的功能，在開源社區可能會被認為不夠通用。李本超説，一些新開發的功能特性，即使已經在業務上驗證過，但在回饋開源社區時，往往需要重新思考和設計，使其在滿足業務訴求的基礎上，又能抽象出更通用的能力。</p><p>當然，對李本超和方勇而言，字節業務的優先級自然是更高的，技術架構的普適性、能力的通用性方面的優先級稍微低一點。但在面對業務和社區共同的需求時，他們還是儘可能做到同時兼顧。也許最後開發出來的解決方案並不是最完美的，但已經能解決 80% 的問題。</p><p><strong>再進一步，如果已經抽象出一些功能特性，想把代碼貢獻到社區，也不代表這個過程會很順利。</strong>由於社區對核心組件的代碼要求比較高，在代碼被合併之前，包括 API 設計、PR 合理性等在內的各方面問題，都需要經過社區討論。</p><p>方勇曾向 Flink 提了一個 PR :在 job manager 節點進行內存優化。 一位德國的項目成員 review 代碼後，認為原理上可以。但他還問了幾個問題：為什麼要提交這個 PR，你們遇到了什麼問題，為什麼要採用這種方式修復它？ 因為 Flink JVM 的 Java 代碼從實現上來看，並沒有內存問題。</p><p>由於該部分涉及到 JVM 層的 classloader 和 full GC 優化，在此之前，方勇就曾與 JVM 系統組有過深入研究探討。他們發現，JVM 不僅有 Java 代碼實現， 還有 C++ 代碼實現，而 C++ 實現的代碼如果有一些複用情況，會出現內存泄露，導致 job manager 節點的 full GC 變多，處理性能下降。當方勇把這一分析過程以及 Benchmark 測試貼到社區後，最終獲得了認可。PR 也很快就被合併了。</p><p><strong>此外，貢獻開源還要從代碼架構的角度來思考，是否與現有系統兼容。</strong>李本超説，要獲得業務部門的認可，要求開發人員對業務有深入的理解，幫助業務部門解決問題，達到預期收益就可以。但在開源社區，想要貢獻代碼，不僅要考慮事件本身的合理性，還要考慮其通用性是否夠強，是否會跟已有功能衝突，未來怎麼維護，如何演進等等。</p><p>方勇就曾遇到過一個案例。一個容災體系，要先靠外部的數據流生成容災 ID，Flink 再通過該 ID 實現整個作業容災。社區為了支持這一功能，做了特定的 API 的開發。方勇在將部分功能代碼提交到倉庫時，就要考慮是否兼容特定的 API 。「不能讓這個 API 受到幹擾，否則 Flink 用户升級版本之後，原先功能就運行不起來了。這對 Flink 的穩定性以及後續發展都是不利的。」</p><span id="OSC_h3_6"></span><h3><span style="color:#2980b9">06 加入 PMC/PPMC，責任更大了</span></h3><p>今年，李本超、方勇先後分別成為了 Apache Calcite、Apache Paimon（incubating）的 PMC member（項目管理委員會成員）、PPMC member（孵化器項目管理委員會成員）。</p><p>這意味着，二人為開源社區做出的貢獻，得到了認可。這並不容易。在社區想要獲得認可，不僅僅只看代碼，還要看技術能力、溝通能力、持續貢獻的意願，以及行為是否符合社區文化（比如 Apache 之道）。如何在日常參與社區事務的過程中，將能力和素質展現出來，是很有挑戰性的。</p><p><strong>李本超有一次印象深刻的經歷。</strong>在 Apache Calcite 社區，他從創建 issue，討論 issue，寫代碼，提交 PR ，到最終合入代碼，前後一共用了五個月的時間。</p><p>「不是説這個 issue 複雜到需要五個月，也不是説這五個月只做這一件事。社區成員都是異步溝通，大部分人都在利用業餘時間來討論問題和貢獻代碼。加上社區對代碼質量要求高，項目本身很複雜，在討論過程中，經常會產生不同的想法和建議。」這個過程對李本超來説，還是挺煎熬的。</p><p>「因為實現方案可能會換好幾次，不同方案要寫不同的代碼。最後討論來討論去，可能還是原來的好，又要在原來的基礎上再改。反反覆覆。最終代碼量也沒多大。」他補充説：「但這個過程能夠很好地展現出個人素質和能力。」</p><p>具備耐心，並且長期堅持，在開源社區是很必要的。方勇認為，成為 PPMC 需要持續關注和投入，保持在自己在社區的活躍度。「持續關注新的 issue，把自己的工作整理出來，再去社區提 issue，然後在社區發起討論，一起評估方案。最終把任務分解後，再開發代碼，再把它合進去，花費的時間週期可能會非常長。在 Flink 社區，如果要合入一些對公共 API 有修改的代碼，從設計討論，到投票，再到開發以及推進，整個過程至少需要 3 個月。」</p><p><strong>對李本超來説，成為 </strong><strong>Apache</strong><strong> Calcite 的 </strong><strong>PMC</strong><strong> member 就意味着肩負了起更大的責任。</strong>「我在社區沒有任何角色的時候，只關心是不是把問題解決了。而且社區裏一定會有更資深的人去幫我去確認代碼有沒有問題，有人在後背託着我。」</p><p>現在，他的身份變了，不再只是貢獻代碼，而是輔助他人貢獻。「我就是把好最後那道關的那個人，壓力和責任更大了。心裏會想着，這個東西我一定得想清楚，一定得為了社區健康、長遠的發展去思考，而不只是把代碼快速合入，把問題快速地解決掉。總之，更小心，更謹慎，思考維度也更多了。」</p><p>李本超還需要承擔很多非代碼的工作，比如代表社區跟 Apache 軟件基金會的基礎設施團隊討論社區機制、流程等問題，讓新加入的開發者在為項目做貢獻的時候，更容易、更方便。「很多時候，付出就不只是單純貢獻的維度了。投入到社區，需要自己有很大的興趣和足夠的精力。」</p><p><strong>同樣深感責任重大的，還有方勇。</strong>他見到過一些開源社區，在成員慢慢變少後，不再活躍，對項目造成了嚴重打擊。每年都有很多新的項目開源，也有很多老的開源項目死掉。</p><p>「既然給了 PPMC 這麼大的權限，作為成員之一，我對整個項目的發展方向就要有更多的考量。 PPMC 最主要的責任，就是對開源項目的把控，包括方向的抉擇、重大 feature 的演進。」</p><p>不同公司及團隊源源不斷地加入社區，會貢獻很多新的功能，有些甚至能夠拿來就用，無需重新開發，在加快項目和社區發展的同時，也在幫助字節完善其內部相關係統功能。當然，字節在將項目用於實際生產業務中時，也會為項目開發很多新的功能特性，並且經過了大量場景的驗證和錘鍊。因此，在規劃項目演進方向時，方勇除了考量外部需求以及其他 PPMC 的提議，會更加主動地去展現公司內部開發的功能，這樣既可以讓內外系統保持一致，也能推動項目更好地往前走。</p><span id="OSC_h3_7"></span><h3><span style="color:#2980b9">07 有了開源社區，好像有了靠山</span></h3><p>大部分人對開源的認知，都發端於使用開源項目。「但如果只是使用一個開源軟件，對社區的感知幾乎是沒有的。」張光輝雖然並未獲得 Apache Flink 的 committer 或 PMC member 的身份，但他和很多人一樣，也在為項目貢獻着自己的力量。</p><p>「以前覺得開源離我們很遠。尤其是在中國，這種感受更加明顯。但是在參與 Apache Flink 社區以及線下大會之後，跟開發者有了交流和接觸，自然而然就產生了情感上的鏈接，促使你主動回饋，促使你去成長。」<strong>張光輝自己也是從開源社區中成長起來的。</strong>此前在將流式計算引擎遷移到 Flink 時，張光輝就曾遇到過不少問題，經常會跟阿里、美團等公司的開發者在 Apache Flink 社區中討論。</p><p><strong>開源給李本超帶來了很強的踏實感。</strong>「我和這個領域最優秀的一羣人站在了一起。有什麼問題一起討論，一起解決，好像多了一個非常強大的虛擬團隊，即使是在處理內部業務的時候，也感覺自己有靠山了。社區裏邊有很多寫代碼超過 30 年的資深專家，不管是在技術領域，還是非技術領域，我都能從他們身上學到很多。」</p><p>在 Flink 社區，很多用户都會在郵件組提一些涉及使用、調優等方面的問題。也許問題本身並不複雜，但因為 Flink 系統很複雜，對初學者而言，門檻還是有點高。</p><p><strong>同樣經歷過新手期的方勇，很能理解這種情況。</strong>「有時候，對方郵件提到的 bug 或者 issue，我們沒有遇到過，但我們仍然會去研究了相關的代碼，幫他解答，甚至直接提交代碼。問題解決之後，我經常會收到感謝郵件，這時候就覺得付出有回報，非常有成就感。」</p><p style="text-align:left">參與社區之後，方勇與開源社區成員見面的機會也更多了，經常與其深入交流項目演進、技術發展、行業趨勢等各方面的想法，同時也在促進各開源項目、社區之間的結合。現在，他正琢磨着，怎麼把 Apache Flink 和 Apache Paimon 更好地結合，做下一代流式計算解決方案。</p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 01:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oscpyaqxylk/blog/10116398</guid>
            <link>https://my.oschina.net/oscpyaqxylk/blog/10116398</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源框架 NanUI 作者轉行賣鋼材，項目暫停開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>NanUI 作者在國慶節發佈了停更公告，稱該項目將暫停開發，原因是去年被裁員失業後，<strong>他已轉行銷售鋼材</strong>，現在很難騰出時間來開發和維護 NanUI 項目。</p><p>他説道：</p><blockquote><p>為了生存，本人只能花費更多的時間和精力去談單，去銷售，去收款，因此已經很難再騰出時間來開發和維護 NanUI 項目，對此我深感無奈，也希望後面生活和工作穩定後能騰出時間來繼續維護 NanUI。</p></blockquote><p>NanUI 作者表示，他所在公司因疫情於去年（2022 年）初徹底宣佈裁減所有開發崗位，因此他也只能順應大流在 36 歲這個尷尬的年紀失業。</p><p><img height="1285" src="https://static.oschina.net/uploads/space/2023/1009/173727_oVGe_2720166.png" width="1980" referrerpolicy="no-referrer"></p><p><em>via&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanchenLin%2FNanUI%2Fdiscussions%2F367" target="_blank">https://github.com/XuanchenLin/NanUI/discussions/367</a></em></p><blockquote><p>NanUI 界面組件是一個開放源代碼的 .NET / .NET Core 窗體應用程序（WinForms）界面框架。它適用於希望使用 HTML5/CSS3 等前端技術來構建 Windows 窗體應用程序用户界面的 .NET 開發人員。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-060f8d602f0ac9de0bb5953b554b233f62e.png" referrerpolicy="no-referrer"></p><p>NanUI 基於谷歌可嵌入的瀏覽器框架 Chromium Embedded Framework (CEF)，因此用户可以使用各種前端技術 HTML5/CSS3/JavaScript 和流行前端框架 React/Vue/Angular/Blazor 設計和開發 .NET 桌面應用程序的用户界面。</p><p>同時，NanUI 獨創的 JavaScript Bridge 可以方便地實現瀏覽器端與 .NET 之間的通信和數據交換。</p><p>使用 NanUI 界面框架將為傳統的 WinForm 應用程序的用户界面設計和開發工作帶來無限種可能！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 09:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261033</guid>
            <link>https://www.oschina.net/news/261033</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[非凸科技受邀出席源創會，探討數據技術的未來發展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:center"><img height="466" src="https://oscimg.oschina.net/oscnet/up-c551fe1ce356a89e7e8b392055164817d4f.jpg" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>9</span></span><span><span>月</span></span><span><span>23</span></span><span><span>日</span></span><span><span>，</span></span><span><span>由開源中國聯合騰訊雲</span></span><span><span>TVP</span></span><span><span>開展的「數據與前沿技術」源創會活動在成都順利舉行</span></span><span><span>，</span></span><span><span>非凸科技受邀出席</span></span><span><span>，</span></span><span><span>與業界專家們共同探討了數據存儲</span></span><span><span>、</span></span><span><span>數據分析</span></span><span><span>、</span></span><span><span>數據挖掘等前沿技術</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>會上</span></span><span><span>，</span></span><span><span>非凸科技成都分公司研發總監趙海峯以「量化交易的數據驅動」為主題進行了分享</span></span><span><span>。</span></span><span><span>在量化交易領域如何高效地獲取行情數據</span></span><span><span>，</span></span><span><span>如何將行情數據轉發到需要的服務器</span></span><span><span>，</span></span><span><span>如何處理大量歷史行情數據的存放和讀取</span></span><span><span>，</span></span><span><span>又是如何通過行情數據進行模型的訓練</span></span><span><span>，</span></span><span><span>趙海峯老師一一做出了精彩的解答</span></span><span><span>。</span></span><span><span>活動後</span></span><span><span>，</span></span><span><span>引發線上熱烈交流討論</span></span><span><span>。</span></span></span></span></p><p style="text-align:center"><img height="358" src="https://oscimg.oschina.net/oscnet/up-dd23c7e0f8444597f06f020859cc3e800bb.png" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>量化交易主要通過行情數據進行交易決策</span></span><span><span>，</span></span><span><span>那麼如何通過券商獲取行情</span></span><span><span>，</span></span><span><span>進行行情低延遲接收的軟硬件方案呢</span></span><span><span>？</span></span><span><span>交易所發佈</span></span><span><span>的</span></span><span><span>行情</span></span><span><span>會</span></span><span><span>經過券商的處理再轉發給交易機構</span></span><span><span>，</span></span><span><span>其轉發途徑主要有</span></span><span><span>TCP、UDP、FPGA</span></span><span><span>加速的 UDP 和</span></span><span><span>ASIC</span></span><span><span>加速的 UDP</span></span><span><span>行情</span></span><span><span>等</span></span><span><span>。</span></span><span><span>然而</span></span><span><span>，</span></span><span><span>券商通過</span></span><span><span>TCP</span></span><span><span>連接將處理後的行情數據轉發給交易機構</span></span><span><span>，</span></span><span><span>會存在延遲大</span></span><span><span>、</span></span><span><span>應用層</span></span><span><span>丟包</span></span><span><span>（非 TCP 協議丟包）、發送端負載大</span></span><span><span>等問題</span></span><span><span>。</span></span><span><span>為瞭解決這些問題</span></span><span><span>，</span></span><span><span>券商又通過</span></span><span><span>UDP</span></span><span><span>組播或廣播的方式</span></span><span><span>，</span></span><span><span>將處理後的行情或交易所原始行情轉發給交易機構</span></span><span><span>。</span></span><span><span>為了達到極致的低延遲，</span></span><span><span>券商端將會通過多種方式來解決</span></span><span><span>，</span></span><span><span>其中一個</span></span><span><span>特別有效</span></span><span><span>的方式是使用</span></span><span><span>L1</span></span><span><span>交換機</span></span><span><span>，在一層轉發光或電信號給客户，其轉發延遲可以低至 4ns。</span></span><span><span>需要注意的是</span></span><span><span>，</span></span><span><span>雖然 UDP 不是一個可靠傳輸協議，但</span></span><span><span>在同一個交換機連接的服務器</span></span><span><span>之間使用 UDP 進行通信</span></span><span><span>，</span></span><span><span>正常情況下</span></span><span><span>在網絡上幾乎不</span></span><span><span>會</span></span><span><span>丟包</span></span><span><span>。然而，</span></span><span><span>在客户端程序和服務器的網卡上可能</span></span><span><span>會</span></span><span><span>丟包</span></span><span><span>。</span></span><span><span>因此</span></span><span><span>，</span></span><span><span>客户在接收行情時</span></span><span><span>，</span></span><span><span>可以使用</span></span><span><span>無鎖的</span></span><span><span>ring buffer</span></span><span><span>轉發數據到處理線程</span></span><span><span>，</span></span><span><span>以並</span></span><span><span>行處理</span></span><span><span>不同股票的行情，</span></span><span><span>然後</span></span><span><span>將處理結果</span></span><span><span>寫入共享內存</span></span><span><span>，</span></span><span><span>以供交易系統讀取</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>收到行情後</span></span><span><span>，</span></span><span><span>如何將行情數據轉發給內部的其他消費者呢</span></span><span><span>？</span></span><span><span>如果對延遲要求沒有太高</span></span><span><span>，</span></span><span><span>可以使用</span></span><span><span>TCP</span></span><span><span>轉發行情</span></span><span><span>，</span></span><span><span>能夠自己控制丟包率</span></span><span><span>，為了降低延遲和增加吞吐，也可以使用 UDP 轉發行情。</span></span><span><span>由於逐筆行情不允許丟包</span></span><span><span>，</span></span><span><span>所以在使用</span></span><span><span>UDP</span></span><span><span>轉發行情時</span></span><span><span>，</span></span><span><span>可以搭配</span></span><span><span>TCP</span></span><span><span>行情重傳服務</span></span><span><span>，</span></span><span><span>通過</span></span><span><span>多路行情匯聚</span></span><span><span>、R</span></span><span><span>oc</span></span><span><span>ksdb</span></span><span><span>持久化</span></span><span><span>等方式對 UDP 轉發行情進行補充</span></span><span><span>。</span></span><span><span>如果</span></span><span><span>轉發行情前</span></span><span><span>進行數據壓縮</span></span><span><span>，</span></span><span><span>那麼延遲</span></span><span><span>和吞吐量可能會更優秀</span></span><span><span>。</span></span><span><span>行情壓縮主要有兩種方式</span></span><span><span>：</span></span><span><span>行情消息的壓縮</span></span><span><span>、</span></span><span><span>消息內部</span></span><span><span>字段</span></span><span><span>的壓縮</span></span><span><span>（</span></span><span><span>股票代碼</span></span><span><span>、</span></span><span><span>價格</span></span><span><span>）。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>行情轉發之後</span></span><span><span>，</span></span><span><span>如何使用行情數據分析交易執行情況</span></span><span><span>，</span></span><span><span>又該如何訓練模型呢</span></span><span><span>？</span></span><span><span>收取到行情後</span></span><span><span>，</span></span><span><span>其中一種應用場景是訓練量化交易模型</span></span><span><span>，</span></span><span><span>將收取到的行情數據進行特徵處理</span></span><span><span>，</span></span><span><span>提取因子</span></span><span><span>，並利用 AI</span></span><span><span>進行模型訓練</span></span><span><span>，</span></span><span><span>然後將訓練好的模型解析出來以備高效地計算</span></span><span><span>實時</span></span><span><span>信號</span></span><span><span>，</span></span><span><span>在接收到實時信號值之後</span></span><span><span>，</span></span><span><span>再</span></span><span><span>極速</span></span><span><span>推送到交易系統</span></span><span><span>，</span></span><span><span>就可以根據不同的策略配置觸發交易</span></span><span><span>；</span></span><span><span>另一種場景應用是把收取到的行情數據與</span></span><span><span>C</span></span><span><span>l</span></span><span><span>ickHouse</span></span><span><span>集成</span></span><span><span>，</span></span><span><span>這</span></span><span><span>不僅能提供高效的聚合和分析查詢</span></span><span><span>功能</span></span><span><span>，</span></span><span><span>還能使用流式聚合表自動計算</span></span><span><span>交易數據，如實時</span></span><span><span>交易盈虧</span></span><span><span>，風險指標等</span></span><span><span>。</span></span></span></span></p><p style="text-align:center"><img height="466" src="https://oscimg.oschina.net/oscnet/up-14ae8244232acc42aea0b9bf638cf1632ff.jpg" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>非凸科技正在加大對金融科技研究的投入</span></span><span><span>，</span></span><span><span>持續以行業技術交流與合作的方式</span></span><span><span>，</span></span><span><span>整合行業生態優勢資源</span></span><span><span>，</span></span><span><span>加快創新技術在實際業務場景中的落地</span></span><span><span>。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 09:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261029</guid>
            <link>https://www.oschina.net/news/261029</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[學習 DevOps 落地實踐，全面提升技術水平]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在我們高速發展的技術時代，DevOps 已經成為企業持續交付和優化業務的關鍵。但是目前市場寒冬、經濟下行，各大企業紛紛裁員。作為天選打工人的我們，收入鋭減、就業困難，普通人如何應對？大齡 IT 從業者，職業迷茫、焦慮恐慌，如何加強學習快速成長？</p><p style="text-align:center"><img height="249" src="https://static.oschina.net/uploads/space/2023/1009/165530_PSgw_2720166.png" width="400" referrerpolicy="no-referrer"></p><p>為了幫助社區成員解決以上問題，我們特別推出了一套針對技術社區的《DevOps 落地實踐訓練營》。這個訓練營將帶您全面瞭解 DevOps 的核心理念和實踐方法，從產品設計、需求管理、代碼管理、持續集成、部署發佈、數據度量、業務運營等各個領域，帶您端到端的學習 DevOps 相關知識。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165548_jSD5_2720166.png" referrerpolicy="no-referrer"></p><p>參加我們的 DevOps 落地實踐訓練營，您將會有以下收穫：</p><ol><li>提升技術能力：通過系統的培訓，您將對 DevOps 有更深入的理解，提升您的技術實力。</li><li>提高溝通能力：訓練營將幫助您更好地與開發、測試和運維團隊溝通，提高團隊協作效率。</li><li>拓寬知識視野：訓練營將邀請業內專家分享經驗，幫助您掌握最新的 DevOps 工具和技術。</li><li>發掘最佳實踐：通過案例分析和實踐操作，您將瞭解到更多的 DevOps 最佳實踐，為您的工作帶來更多靈感。</li></ol><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165712_fZMA_2720166.png" referrerpolicy="no-referrer"></p><p>我們的訓練營有以下亮點：</p><p>1、現在大多數的培訓都是線上，效果如何，相信大家都有自己的判斷。小編在以前學習線上課程時，超不過半小時就走神犯困。<strong>《DevOps 落地實踐訓練營》採用線下培訓形式，確保學員能夠親身體驗和實踐所學內容</strong>。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165732_9QiG_2720166.png" referrerpolicy="no-referrer"></p><p>2、術業有專攻，單一講師的培訓並不能做到全棧貫通賦能。本訓練營邀請多位專業講師聯袂推出端到端的實踐技能培訓，內容包含 25 個章節，<strong>全面講解軟件開發過程中產品設計、項目管理、開發、測試、架構等多個領域的知識實踐</strong>。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165752_0tuV_2720166.png" referrerpolicy="no-referrer"></p><p>3、職業技能培訓，最終的目的是學以致用。有別於其他認證類培訓，本次訓練營更為重要的是，<strong>每個環節都有動手練習環節，確保學員真正掌握所學技能</strong>。而且能夠將理論知識與實際工作緊密結合，為學員提供貫通全棧賦能的培訓。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165814_dmE9_2720166.png" referrerpolicy="no-referrer"></p><p>4、「天下苦高價培訓久矣。」本次訓練營，以 480 元的價格提供了一種高性價比的培訓方式，讓學員不再因價格而猶豫。如果你想在學習技能的同時，還想獲得一個職業技能證書，980 的價格，你就能獲得由」中國管理科學院「頒發的《專業人才培訓證書》。此處注意，培訓和證書並不強制綁定，本土培訓，僅此一家。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165830_KvDB_2720166.png" referrerpolicy="no-referrer"></p><p>DevOps 落地實踐訓練營是一個全面提升技術水平的絕佳機會，不僅能幫助您更深入地理解 DevOps，還能提升您的團隊協作能力，拓寬知識視野，並讓您有機會接觸到更多的最佳實踐。我們邀請您積極參與，與業內專家和同行一起共創。我們期待在未來的交流和合作中與您共同成長，創造更多的可能性！</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 09:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261024</guid>
            <link>https://www.oschina.net/news/261024</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[聯想計劃推出 Android PC]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">聯想於近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techradar.com%2Fcomputing%2Fdesktop-pcs%2Flenovo-shifts-direction-with-new-android-based-pcs-and-they-look-powerful" target="_blank">宣佈</a>計劃生產&nbsp;Android PC。該公司將於&nbsp;<span style="background-color:#ffffff">Esper&nbsp;</span>合作，<span style="background-color:#ffffff">重新設計其台式一體機 ThinkCentre M70a，「</span><span style="background-color:#ffffff">這台一體機將代表着聯想進軍 Android 領域的第一步」。Esper 是一家專門提供 Android 定製服務以及設備管理產品的公司。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">ThinkCentre M70a 採用 21.5 英寸 FHD 無邊框顯示屏，</span>現有版本採用英特爾處理器，可以從入門級 i3 一直配置到功能強大的 i9 芯片。M70a 目前採用的是 Windows 11 操作系統，但據透露新版本將採用 Android 系統。</span></p><p><img height="401" src="https://oscimg.oschina.net/oscnet/up-5eda0c1eee499fc80e95d2f72bb2c76eeee.png" width="500" referrerpolicy="no-referrer"></p><p><img height="399" src="https://oscimg.oschina.net/oscnet/up-98d83cf5f92a9b40a586a0f0345868a918a.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">聯想方面表示，ThinkCentre M70a 主要面向企業客户，希望它能吸引零售和酒店業的企業使用。除此之外，聯想還計劃與 Esper 合作推出基於 Android 系統的 ThinkCentre M70q，以及基於 Windows 系統的 ThinkEdge SE30 和 ThinkCentre M90n-1 IoT。</span></p><p><span style="color:#000000">目前在台式電腦領域最接近 Android 系統的是惠普的 Chromebase AIO 等產品，由於採用了 ChromeOS，它可以通過谷歌 Play 商店運行 Android 應用程序。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 07:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260995/lenovo-esper-android-pc</guid>
            <link>https://www.oschina.net/news/260995/lenovo-esper-android-pc</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 易語言開發的服務器軟件 MODHTTP SERVER]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-modhttp-server" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#modhttp-server"></a>MODHTTP SERVER</h1><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/fw.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>項目地址：<a href="https://gitee.com/wxgshuju/modhttp-server">https://gitee.com/wxgshuju/modhttp-server</a></p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/oschina.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>開源中國：<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.oschina.net%2Fp%2Fmodhttp-server">https://www.oschina.net/p/modhttp-server</a></p><h4><a id="user-content-介紹" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E4%BB%8B%E7%BB%8D"></a>介紹</h4><p>MODHTTP SERVER 是採用國產化編程易語言開發的網站服務器軟件。</p><p>該程序集成 Nginx+ASP+PHP+MySQL+Openssl+HOSTS+MYSQL-FORM+Sqlite 數據庫管理器+Access 數據庫管理器;</p><p>支持 HTTP1.1 協議、HTTP2 協議、HTTP3 協議，該工具實現 NGINX 配置可視化編輯、PHP 可視化配置可視化編輯，</p><p>該程序不僅包括 ASP、PHP、Modhttp 調試環境，還包括了 MODHTTP 網頁視圖模塊開發工具、開發手冊等</p><h4><a id="user-content-聲明" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E5%A3%B0%E6%98%8E"></a>聲明</h4><p>本軟件基於開源協議 Apache 發佈，允許轉發，允許第三方修改，本軟件永久免費，終身免費</p><p>軟件開發者：魔帝本尊</p><p>支持平台：Windows</p><p>優點：綠色服務解壓即可安裝，一鍵可視化配置即可使用</p><p>項目狀態：持續更新維護中...</p><p>本軟件已經開源，如需要程序源碼請在 OPEN-SOURCE 中查看.</p><h4><a id="user-content-軟件架構" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84"></a>軟件架構</h4><p>本軟件需要安裝以下運行庫庫
Microsoft Visual C++ 2015-2022 Redistributable 14.38.32919.0 (2023-08-09)</p><p>x64 <a href="https://gitee.com/link?target=https%3A%2F%2Fdownload.visualstudio.microsoft.com%2Fdownload%2Fpr%2F02a6d5c5-3e10-47de-8025-d97a1321d3e3%2F5F60592799FAE0C82578112D4B621438FFC976AB39D848D8F7623F5705A83E27%2FVC_redist.x64.exe">https://download.visualstudio.microsoft.com/download/pr/02a6d5c5-3e10-47de-8025-d97a1321d3e3/5F60592799FAE0C82578112D4B621438FFC976AB39D848D8F7623F5705A83E27/VC_redist.x64.exe</a></p><p>x86 <a href="https://gitee.com/link?target=https%3A%2F%2Fdownload.visualstudio.microsoft.com%2Fdownload%2Fpr%2F02a6d5c5-3e10-47de-8025-d97a1321d3e3%2FAD573D3198853FC71137A88E51ABDE844B84F29B0CE6DD91BBEC661BC0143B36%2FVC_redist.x86.exe">https://download.visualstudio.microsoft.com/download/pr/02a6d5c5-3e10-47de-8025-d97a1321d3e3/AD573D3198853FC71137A88E51ABDE844B84F29B0CE6DD91BBEC661BC0143B36/VC_redist.x86.exe</a></p><h4><a id="user-content-下載路徑" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E4%B8%8B%E8%BD%BD%E8%B7%AF%E5%BE%84"></a>下載路徑</h4><p>最新版本：32.02</p><p>Gitee（含源碼）：<a href="https://gitee.com/wxgshuju/modhttp-server/raw/master/MODHTTP_SERVER32.02.7z">https://gitee.com/wxgshuju/modhttp-server/raw/master/MODHTTP_SERVER32.02.7z</a></p><p>代碼庫中所有文件經過病毒掃描查殺</p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t0.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>.e 文件，是易語言源代碼</p><p>.api 文件，是 MODHTTP 專屬的易語言網頁視圖模塊文件，作用等同 PHP、ASP</p><p>內存加速 1.7.ec  來源為彙編大神，白銀大佬 (2962946246) 無償提供</p><p>e2ee.fne e2ee_staticlib e2ee_static.res 來源為 E2EE 網站迅捷開發羣 (536544662)</p><p>2.3.2 免費版支持庫</p><p>源碼中用到了編碼轉換類，動態內存庫類等...</p><p>本地調試器.exe   是 MODHTTP 專屬視圖模塊的調試工具，可以清晰看到瀏覽器請求到 MODHTTP 8081 端口的各種信息</p><p>如果僅用 PHP、ASP、MySQL 等集成環境，不使用 MODHTTP 網頁視圖模塊文件則無需打開本地調試器.exe</p><h4><a id="user-content-安裝教程" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B"></a>安裝教程</h4><ol><li><p>解壓後打開&lt;&lt;MODHTTP.exe&gt;&gt;</p></li><li><p>解壓路徑中不允許有空格，建議解壓到根目錄，例如 C:\ D：\等</p></li></ol><h4><a id="user-content-使用説明" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"></a>使用説明</h4><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t1.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><ol><li>打開&lt;&lt;MODHTTP.exe&gt;&gt;</li></ol><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t2.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><ol start="2"><li><p>首次使用打開後點擊左上角菜單&gt;網站管理;打開網站管理器增填、修改網站目錄，修改完成後點擊【保存配置】按鈕，關閉此窗口</p></li><li><p>點擊啓動,在首頁右側找到擴展項&gt;Nginx&gt;配置調試，點擊【配置調試】按鈕，頁面顯示以下內容則配置成功，可以啓動服務。</p></li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">nginx: the configuration </span><span id="LC2" class="line">conf/nginx.conf syntax is ok</span><span id="LC3" class="line">nginx: configuration file D:\modhttp32.02A202310072215\modhttp-server\nginx/conf</span><span id="LC4" class="line">/nginx.conf test is successful</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t3.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>4.按需要勾選組件，如 Nginx，Mysql，ASP，PHP 等，在選項前面打勾啓動服務，如需關閉請再次點擊取消√則停止服務</p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t4.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>5.啓動服務後點擊右上角【訪問 nginx 頁面】按鈕，開始盡情的寫 BUG 吧</p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t5.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><h4><a id="user-content-幫助" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E5%B8%AE%E5%8A%A9"></a>幫助</h4><p>鼠標光標移動到功能，文字標題會顯示幫助提示和信息</p>]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 06:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/wxgshuju/modhttp-server</guid>
            <link>https://gitee.com/wxgshuju/modhttp-server</link>
        </item>
        <item>
            <title>
                <![CDATA[兩行代碼解決大語言模型對話侷限！港中文賈佳亞團隊聯合 MIT 發佈超長文本擴展技術]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">中途迷失、模型偷懶、上下文越長大模型越笨......如果體驗過大語言模型產品,用户多少會對文本輸入長度帶來的限制有所感觸，比如當想和大模型討論一些稍長的內容，需要拆分輸入，而前面輸入的要點，很快就會被大模型忘記。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">這是典型的大語言模型對話缺陷！就像先天有注意力缺陷的兒童，難以專注看完一本新書。而缺陷的關鍵，在於模型缺乏長文本處理能力。這個局面如今被打破。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">近日，賈佳亞團隊聯合 MIT 發佈的新技術和新模型悄然登上各大開源網站的熱榜：hugging face 熱榜第一、paperwithcode 熱度第一，Github 全部 python 項目熱度第五、github stars 一週內破千，Twitter 上的相關技術帖子瀏覽量近 18 萬......</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p7.itc.cn/q_70/images01/20231009/02802a3fa205413abde6f1ea42885d02.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">github stars 已達 1.3k</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p5.itc.cn/q_70/images01/20231009/598154ce3152480c8164e0cfab8efabb.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">Twitter 上的相關技術帖子瀏覽量近 18 萬</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">這項名為 LongLoRA 的技術實用但卻簡單得令人驚訝：只需兩行代碼、一台 8 卡 A100 機器，便可將 7B 模型的文本長度拓展到 100k tokens，70B 模型的文本長度拓展到 32k tokens；同時，該研究團隊還發布了首個擁有 70B 參數量的長文本對話大語言模型 LongAlpaca。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><strong>全球首個 70B 長文本大語言模型發佈</strong></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">LongLoRA 的提出，讓全球大語言模型的對話缺陷第一次得到解決，自此，幾十頁的論文、幾百頁的報告、鴻篇鉅製不再成為大模型盲區。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">對此，有專業人士激動地表示，LongLoRA 是大語言模型迷宮中的希望之燈！它代表着業界對長文本大語言模型的重新思考和關注，有效擴展了大語言模型的上下文窗口，允許模型考慮和處理較長的文本序列，是大語言模型的革新性發明。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p9.itc.cn/q_70/images01/20231009/cbe10d2967664215bffee1abef01d462.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">除了技術革新外，大語言模型處理長文本問題的一大難點還在於缺少公開的長文本對話數據。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">為此，研究團隊特意收集了 9k 條長文本問答語料對，包含針對名著、論文、深度報道甚至財務報表的各類問答。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">光會回答長問題還不夠，該團隊又挑選了 3k 的短問答語料與 9K 的長問答語料混合訓練，讓長文本大模型同時具備短文本對話能力。這個完整的數據集被稱為 LongAlpaca-12k，目前已經開源。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在 LongAlpaca-12k 數據集基礎上，研究團隊對不同參數大小 7B、13B、70B 進行了訓練和評測，開源模型包括 LongAlpaca-7B, LongAlpaca-13B 和 LongAlpaca-70B。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><strong>看小説、改論文、指點經濟堪稱全能王</strong></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">話不多説，盲選幾個 demo,一起看看應用了 LongLoRA 技術疊加 12K 問答語料的大模型 LongAlpaca 效果。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p3.itc.cn/q_70/images01/20231009/e0807c4fbd0e428da6cc72b9e4c566dc.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">讓系統新讀一篇論文，並根據 ICLR 的審查指南，對其提出修改意見，從而提升該論文的接收率。LongAlpaca 的意見是：通過更精確地闡明新穎性，提供更嚴格和更有對比性的實驗結果 (包括具體的數據集和指標)、更廣泛的應用和未來發展方向，重點呈現關鍵貢獻和影響，論文被接受的機會將得到提高。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p3.itc.cn/q_70/images01/20231009/783214e5577d4580a8f89721e98f148e.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">現在，讓系統讀兩篇新的不同的論文，讓 LongAlpaca 概括 ICLR 和 CVPR 兩個會議之間的風格區別。LongAlpaca 總結認為，CVPR 論文傾向更具結構性和實驗性的風格，專注於實用性和技術性。而 ICLR 的論文風格更加靈活，側重關鍵的理論分析和數學推導，而非標準格式。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">可以看出，經過訓練的 LongAlpaca 模型已經可以很輕鬆地接受新的長篇學術論文，在學術相關問題的回答上相當精準。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">接下來，再看看 LongAlpaca 模型在頗高閲讀和理解門檻的經濟領域的解讀表現。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p3.itc.cn/q_70/images01/20231009/e6eb1abcb4944627935707701425aa11.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p5.itc.cn/q_70/images01/20231009/a6f419f9eb03497e9aa357e147b61085.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">根據國際貨幣基金組織從 2012 年到 2023 年的全球經濟展望的概述合集，對經濟形勢進行逐年總結以及對未來經濟趨勢進行預測。LongAlpaca 告訴我們，2023 年全球經濟形勢不明朗，跟 2022 年相比，增長預計放緩;未來幾年，全球經濟擴張速度偏温和並將低於預期，而地緣政治緊張、金融市場波動等大的挑戰依然存在，需通過多邊合作和結構性改革小心應對。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">LongAlpaca 還可以讀新的長篇小説，讀完後對內容進行分析。下面選取的對比模型是 13B 參數的 LongAlpaca 和 Llama2，且看各自表現。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p1.itc.cn/q_70/images01/20231009/72aeb31905df4635a8f3001fced32892.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">名著《西遊記》中，為什麼孫悟空在大鬧天宮時很厲害，但取，經路上卻屢屢受挫?LongAlpaca 給出了 5 點原因，大概可總結為 「孫悟空的不成熟、強大的對手、力量的限制、敵人的欺騙、最初，缺少同伴等因素導致了他在旅途中的失敗。但隨着時間推移，他獲，得了智慧、經驗和戰友，使他最終戰勝了最強大的敵人。」</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">而 Llama2 的回答較為簡單。「雖然他確實大鬧天宮，但説他代表着不敗的力量並不一定準確。事實上，他最終在西遊記中被強大的唐三藏打敗。」Llama2 沒有給出正確答案，並且還提出需要更多的內容信息。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p0.itc.cn/q_70/images01/20231009/a29c650d3a144a18afaf5e7b4d374559.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">這一次讓系統新讀一次《三體》，然後問第一部中，葉文潔為什麼要聯繫外星人，而後期又為什麼後悔？LongAlpaca 認為，葉文潔最初接觸外星人是出於理想主義和復仇，但隨着時間的推移，她對人類的看法發生了變化，意識到自己可能給全人類帶來的危險，她的悔恨與日俱增。回答得十分清晰。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">而 Llama2 的回答則是，「通過與外星人的互動，她希望能更深入地瞭解宇宙的本質，以及自己在宇宙中的位置。葉文潔逐漸意識到，外星人和他們的技術並不能解決她的問題。」回答籠統，之後開始對小説整體進行評論，答非所問。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">從模型給出的答案可發現，一些模型如 Llama2 [2] 可能在預訓練過程中見過相關小説，但如果在提問時進行僅根據小説題目進行短文本提問的話，回答並不理想。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">兩個模型的回答對比，高下立見。LongAlpaca 改學術論文、點評全球經濟大勢和讀小説，都是一把好手，完勝 Llama2。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><strong>兩行代碼和三個關鍵結論</strong></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">Llama2 可以説是 AI 社區內最強大的開源大模型之一，行業位置領先，LongAlpaca 居然可以完勝。其背後的 LongLoRA 技術成功引起網友們的注意，到底是怎麼做到的？</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">原來大語言模型對長文本處理過程中，計算量的主要開銷集中在自注意力機制 (self-attention)，其開銷隨着文本長度成平方次地增加。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">針對這個問題，研究團隊提出 LongLoRA 技術，並用分組和偏移的方式來對全局自注意力機制進行模擬。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p0.itc.cn/q_70/images01/20231009/e9c924b5c8564afa9f24a208a98eeb8c.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">簡單來説，就是將長文本對應的 tokens 拆分成不同的組，在每組內部做自注意力計算，而分組的方式在不同注意力頭 (attention head) 上有所偏移。這樣的方式既可以大幅度節約計算量，又可以維持全局感受野的傳遞。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">而這個實現方法也非常簡潔，僅兩行代碼即可完成！</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p9.itc.cn/q_70/images01/20231009/096cdf76e3394df796ed04057a1cb6c2.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">LongLoRA 還探索了低秩訓練的方式。原有的低秩訓練方式，如 LoRA [5]，無法在文本長度遷移上取得良好的效果。而 LongLoRA 在低秩訓練的基礎上，引入嵌入層 (Embedding layer 和 Normalization layers) 進行微調，從而達到可以和全參數微調 (Full fine-tune) 逼近的效果。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p7.itc.cn/q_70/images01/20231009/c684b6990a394aacb2859a1f064e09b9.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">進行不同長度文本擴展和訓練時，LongLoRA、LoRA 和全參數微調不同技術的具體效果如何，可以參考三個維度表現：</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在 Perplexity-困惑度上，原有 LoRA 方法的性能在不斷惡化，而 LongLoRA 和全參數微調都能在各種文本長度下維持很好的效果；</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在顯存消耗上，相比於全參數微調，LongLoRA 和原有 LoRA 都有大幅度的節省。例如，對於 8k 長度的模型訓練，相比於全參數微調，LongLoRA 將顯存消耗從 46.3GB 降低到 25.6GB；</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在訓練時間上，對於 64k 長度的模型訓練，相比於常規 LoRA，LongLoRA 將訓練時間從 90～100 小時左右降低到 52.4 小時，而全參數微調超過 1000 小時。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">極簡的訓練方法、極少的計算資源和時間消耗，以及極佳的準確性，令 LongLoRA 大規模推廣成為可能。目前，相關技術與模型已全部開源，感興趣的用户們可以自己部署感受。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">值得一提的是，這是賈佳亞團隊繼 8 月 9 日發佈的「可以分割一切」的多模態大模型 LISA 後的又一力作。相距不過短短兩個月，不得不説，這研究速度和能力跟 LongLoRA 一樣驚人。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">代碼和 Demo 地址：https://github.com/dvlab-research/LongLoRA</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">論文地址：https://arxiv.org/pdf/2309.12307.pdf</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">參考文獻</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[1] LLaMA team. Llama: Open and efficient foundation language models. Arxiv, 2302.13971, 2023a.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[2] Llama2 team. Llama 2: Open foundation and fine-tuned chat models. Arxiv, 2307.09288, 2023b.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[3] Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending context window of large language models via positional interpolation. Arxiv, 2306.15595, 2023.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[4] Szymon Tworkowski, Konrad Staniszewski, Mikolaj Pacek, Yuhuai Wu, Henryk Michalewski, and Piotr Milos. Focused transformer: Contrastive training for context scaling. Arxiv, 2307.03170, 2023.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[5] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. In ICLR, 2022.</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 05:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260968</guid>
            <link>https://www.oschina.net/news/260968</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百度加緊訓練文心大模型 4.0，或將於 10 月 17 日發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>據科創板日報報道，百度正在加緊訓練文心大模型 4.0，或將在 10 月 17 日百度世界大會上發佈。</p><p>據消息人士透露，文心大模型 4.0 的進展比預期快很多，將是基礎模型的大升級，<strong>理解、生成、邏輯、記憶</strong>四大核心能力都將提升，尤其在邏輯推理、代碼和數學等方面提升最明顯。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-741c4810e55393b362a8f9a60b8c98a65dd.png" referrerpolicy="no-referrer"></p><p>今年 8 月，<a href="https://www.oschina.net/news/256156" target="_blank">百度宣佈文心一言率先向全社會全面開放</a>，所有用户都能下載文心一言 App 或在官網體驗。</p><hr><p>延伸閲讀：<a href="https://www.oschina.net/news/256949">挑戰 ChatGPT，國產有這 8 款 AI 大模型產品</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 04:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260957</guid>
            <link>https://www.oschina.net/news/260957</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲原生週刊：Docker 推出 Docker Debug]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>開源項目推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fschemahero%2Fschemahero" target="_blank">SchemaHero</a></h3><p>SchemaHero 是一個 Kubernetes Operator，用於各種數據庫的聲明式架構管理。SchemaHero 有以下目標：</p><ul><li>數據庫表模式可以表示為可以部署到集羣的 Kubernetes 資源。</li><li>可以編輯數據庫模式並將其部署到集羣。SchemaHero 將計算所需的更改（<code>ALTER TABLE</code> 語句）並應用它。</li><li>SchemaHero 可以管理部署到集羣或集羣外部的數據庫（RDS、Google CloudSQL 等）。</li></ul><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fproject-copacetic%2Fcopacetic" target="_blank">copacetic</a></h3><p>copacetic 是一款基於 buildkit 並用 Go 編寫的 CLI 工具，可用於根據 Trivy 等流行工具的漏洞掃描結果直接修補容器鏡像。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubernetes-sigs%2Fkueue" target="_blank">Kueue</a></h3><p>Kueue 是一套用於作業隊列的 API 和控制器。它是作業級管理器，可決定何時允許作業啓動（如創建 pod），何時停止作業（如刪除活動 pod）。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Foslabs-beta%2Fspyglass" target="_blank">Spyglass</a></h3><p>Spyglass 是一款開源工具，允許用户在一個集中位置監控 Kubernetes 集羣指標並跟蹤集羣部署成本。</p><h2>文章推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.devops.dev%2Fsurviving-2400-hours-of-multi-tenancy-what-i-know-now-9c48694aa75d" target="_blank">多租户 2400 小時的生存之道： 我現在知道了什麼</a></h3><p>這篇文章是關於作者在處理多租户環境下的經驗和教訓的分享。作者介紹了他們所面臨的挑戰：由於項目請求的激增，現有的基礎設施無法滿足存儲需求。為瞭解決這個問題，他們開始尋找一個強大的多租户解決方案。</p><p>作者詳細介紹了他們的多租户方法和使用 vcluster 的經驗。他們採用了 Virtual-Kubernetes-as-a-Service (VKaaS) 的模型，通過在共享集羣中運行 vcluster 來為新項目提供無縫的啓動體驗。他們為每個團隊分配了一個獨立的 Argo CD 實例，以保持單一集羣使用的標準。他們努力提供儘可能多的自治權給團隊，同時保持多租户架構的完整性。</p><p>文章還介紹了他們的工作流程和實施策略。他們利用節點池來區分共享工作負載和項目相關的非關鍵應用程序，並詳細解釋了他們在共享集羣中的工作方式。他們還強調了災難恢復方案對於多租户方法的重要性，並提供了一些實施策略的示例。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.devopsschool.com%2Fblog%2Fkubernetes-tutorials-what-is-preemption-in-kubernetes-with-example%2F" target="_blank">Kubernetes 教程：Kubernetes 中的 Preemption（搶佔）機制</a></h3><p>這篇文章是關於 Kubernetes 中的 Preemption（搶佔）機制的介紹和示例。Preemption 是一種允許高優先級 Pod 搶佔低優先級 Pod 的機制，當資源不足以調度高優先級 Pod 時使用。文章首先介紹了 PriorityClass，它是一個非命名空間對象，定義了優先級類名稱與優先級整數值的映射關係。數值越高，優先級越高。</p><p>文章還介紹了兩個內置的優先級類：system-cluster-critical 和 system-node-critical，它們分別具有值 2000001000 和 2000000000，確保這些 Pod 始終被首先調度，並且永遠不會被搶佔。文章通過一個示例説明瞭 Preemption 在 Kubernetes 中的工作原理。文章還提供瞭如何在 Pod 中設置 Preemption 策略的示例。</p><h2>雲原生動態</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F10%2F05%2Funveiling-litmuschaos-3-0-embracing-evolution-in-chaos-engineering%2F" target="_blank">LitmusChaos 3.0 發佈</a></h3><p>LitmusChaos 3.0 已正式發佈，此版本主要變化如下：</p><ul><li>改進的用户體驗</li><li>混沌基礎設施組織的環境</li><li>用於簡化實驗調整的 Chaos Studio</li><li>彈性探針現在支持即插即用</li><li>支持 MongoDB 高可用性</li></ul><p>發行説明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flitmuschaos%2Flitmus%2Freleases%2Ftag%2F3.0.0%E3%80%82" target="_blank">https://github.com/litmuschaos/litmus/releases/tag/3.0.0。</a></p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F10%2F03%2Fcncf-archives-the-service-mesh-interface-smi-project%2F" target="_blank">服務網格接口（SMI）項目進入歸檔階段</a></h3><p>CNCF TOC（技術監督委員會，Technical Oversight Committee）已投票批准將 SMI（Service Mesh Interface，服務網格接口）項目歸檔。</p><p>SMI 的創建是為了為 Kubernetes 上的服務網格提供標準接口和最常見服務網格使用案例的基本功能集。它於 2020 年 3 月被接受為 CNCF 沙箱項目。</p><p>SMI 是第五個被 CNCF 歸檔的項目。開源項目有其生命週期，項目可能因各種原因而不再活躍。還有一些情況是項目可能不再希望得到 CNCF、維護人員或 TOC 的支持。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Fannouncing-openpubkey-project" target="_blank">Linux 基金會、BastionZero 和 Docker 宣佈啓動 OpenPubkey 項目</a></h3><p>Linux 基金會、BastionZero 和 Docker 宣佈 OpenPubkey 作為 Linux 基金會開源項目的啓動。與 OpenPubkey 的啓動同時，BastionZero 宣佈將 OpenPubkey 集成到 Docker 容器簽名中，以通過零信任無密碼身份驗證來保護開源軟件生態系統。</p><p>OpenPubkey 協議是作為 BastionZero 安全基礎設施訪問產品的一部分開發的。OpenPubkey 使用户能夠通過將 OpenID Connect 身份提供者（Identity Provider，IdP）轉換為證書頒發機構（Certificate Authority，CA）來安全準確地將加密密鑰與用户和工作負載綁定。隨着這個集成的推出，Docker 用户可以增強軟件供應鏈安全性。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevclass.com%2F2023%2F10%2F04%2Fdocker-introduces-seems-like-magic-container-debug-tool-and-cloud-driven-build-service%2F" target="_blank">Docker 推出容器調試工具和雲驅動的構建服務</a></h3><p>在 2023 年的 DockerCon 活動上，Docker 推出了名為 Docker Debug 的容器調試工具，推出了下一代雲輔助的 Docker Build 功能，Docker Scout 漏洞掃描工具也正式發佈。</p><p>Docker Debug 解決了在容器中運行應用程序時出現故障時很難跟蹤問題的問題。它是一個容器，包含開發人員所需的調試工具，它會掛載故障容器的文件系統，並提供了更好的用户體驗，幫助開發人員理解問題所在。</p><p>Docker Scout 是一個漏洞掃描工具，可以找出應用程序所使用的庫中存在的已報告漏洞。它與第三方工具 Sysdig 集成，可以在運行時顯示實際使用的代碼，並幫助開發人員優先處理與其應用相關的漏洞。</p><p>下一代 Docker Build 是一個將構建過程從本地轉移到雲端的工具。通過一條命令，開發人員可以將構建過程交給雲端完成，從而加快構建速度。這得益於雲端使用更強大的計算資源以及緩存機制的支持。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 03:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10116369</guid>
            <link>https://my.oschina.net/u/4197945/blog/10116369</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[當尺度感知調製遇上 Transformer，會碰撞出怎樣的火花？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者 ｜ AFzzz</p><p><img src="https://oscimg.oschina.net/oscnet/up-9688cc4b384ef1a2912634e0129648db315.png" alt="" referrerpolicy="no-referrer"></p><h2>1 文章介紹</h2><p>近年來，基於 Transformer 和 CNN 的視覺基礎模型取得巨大成功。有許多研究進一步地將 Transformer 結構與 CNN 架構結合，設計出了更為高效的 hybrid CNN-Transformer Network，但它們的精度仍然不盡如意。本文介紹了一種新的基礎模型 SMT（Scale-Aware Modulation Transformer），它以更低的參數量（params）和計算量（flops）取得了大幅性能的提升。</p><p>不同於其他 CNN-Transformer 結合的方案，SMT 基於卷積計算設計了<strong>一個新穎的輕量尺度感知調製單元 Scale-Aware Modulation（SAM）</strong> ，它能夠捕捉多尺度特徵的同時擴展感受野，進一步增強卷積調製能力。此外，SMT 提出了一種<strong>進化混合網絡 Evolutionary Hybrid Network（EHN）</strong> ，它能夠有效地模擬網絡從淺層變深時捕捉依賴關係從局部到全局的轉變，從而實現更優異的性能。在 ImagNet、COCO 以及 ADE20k 等任務上都驗證了該模型的有效性。<strong>值得一提的是，SMT 在 ImageNet-22k 上預訓練後以僅僅 80.5M 的參數量在 ImageNet-1k 上達到了 88.1% 的精度。</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-f4be367414a72c6d4c94a5fd903dea0125c.png" alt="" referrerpolicy="no-referrer"></p><h2>2 出發點</h2><ul><li><p>對於多層級的網絡架構來説，由於淺層特徵圖分辨率大的原因，自注意力的二次複雜性會帶來嚴重的計算負擔。因此，如何為淺層 stage 設計高效的 attention 計算機制是十分重要的。</p><p>回顧以往的大部分 Hierarchical（Multi-scale）的模型，以 Swin 為代表，以及後續的 CvT，PvT，Shunted Transformer 等等，它們的主要貢獻點都是設計出了一種更高效的 attention 計算單元，比如 local attention，lightweight convolution attention 等等。</p></li><li><p>ViT 論文中提出，Transformer 模型的注意力捕捉依賴關係為，淺層捕捉 local 信息，深層捕捉 global 信息，而這種特性在多層級網絡架構上也會出現。</p><p>作者認為，模擬並建模這種捕捉依賴過渡是重要且有效的。</p></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-07e0ea4d6cb05fd437951f9be3d1577e60b.png" alt="" referrerpolicy="no-referrer"></p><h2>3 SMT 框架算法</h2><p><img src="https://oscimg.oschina.net/oscnet/up-53c347eac02866a8ce9f8e0747e1eca5f0d.png" alt="" referrerpolicy="no-referrer"></p><p>SMT 的總體框架如圖 1 所示。整個網絡包括四個階段，每個階段的下采樣率為{4, 8, 16, 32}。我們並非和 FocalNet 一樣構建一個無注意力機制的網絡，而是首先在前兩個階段採用文章提出的尺度感知調製（SAM），然後在倒數第二個階段中依次堆疊一個 SAM Block 和一個多頭自注意力（MSA） Block，以建模從捕捉局部到全局依賴關係的轉變。對於最後一個階段，我們僅使用 MSA 塊來有效地捕捉長距離依賴關係。</p><h3>3.1 Scale-Aware Modulation 模塊</h3><p><img src="https://oscimg.oschina.net/oscnet/up-af9a13c41ea967982c091cce0b4aac2f242.png" alt="" referrerpolicy="no-referrer"></p><ul><li><strong>多頭混合卷積 MHMC（Multi-Head Mixed Convolution）</strong></li></ul><p>在 MHMC 中，我們引入了具有不同卷積核大小的多個卷積層，使其能夠捕捉多個尺度上的空間特徵。當我們將 N head 設置得較大時，能夠引入大卷積核來擴大感受野，增強其建模長距離依賴關係的能力。如圖 2(b) 所示，MHMC 將輸入通道分為 N 個頭，對每個頭應用獨立的深度可分離卷積。我們將卷積核大小初始化為 3x3，並逐頭遞增。這種方法使得我們能夠人為的通過調整頭的數量來調節感受野的範圍和多粒度信息。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6af95c745f4f313605d63309b5f471adc73.png" alt="" referrerpolicy="no-referrer"></p><ul><li><strong>多尺度感知聚合 SAA（Scale-Aware Aggregation）</strong></li></ul><p>為了增強 MHMC 中多個頭之間的信息交互，我們引入了一種新的輕量化聚合模塊，稱為多尺度感知聚合（SAA），如圖 2(c) 所示。SAA 首先對 MHMC 生成的不同粒度的特徵進行重組和分組。具體而言，我們從每個頭中選擇一個通道來構建一個組，然後在每個組內進行 up-down 的特徵融合，從而增強多尺度特徵的多樣性。值得注意的是，Num_group = C / N_head，C 為輸入通道數，這意味着組的數量與 MHMC 中頭的數量成反比，每個組裏只包含 N 個特徵通道。隨後，我們使用 1x1 卷積進行組內-組間模式的跨組信息融合，從而實現輕量且高效的聚合效果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fa073ddec726a81685efb58c66e2582adc1.png" alt="" referrerpolicy="no-referrer"></p><p>如圖 3 所示，我們可視化出 SAA 前和 SAA 後的特徵圖，可以觀察到 SAA 模塊加強了語義相關的低頻信號，並準確地聚焦於目標物體最重要的部分。與聚合之前的卷積映射相比，SAA 模塊展示了更好的能力來捕捉和表示視覺識別任務的關鍵特徵。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5fd6c072492140075ffca7fc81b8d04de41.png" alt="" referrerpolicy="no-referrer"></p><ul><li><strong>尺度感知調製器 SAM（Scale-Aware Modulation）</strong></li></ul><p>如圖 2(a) 所示，在使用 MHMC 捕捉多尺度空間特徵並通過 SAA 進行聚合後，我們獲得一個輸出特徵圖，我們稱之為調製器 Modulator。然後，我們使用標量乘積採用這個調製器來調製 value V。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1076102f25eb2d8f13b60d04633b5460c4d.png" alt="" referrerpolicy="no-referrer"></p><h3>3.2 混合進化網絡 Evolutionary Hybrid Network</h3><p><img src="https://oscimg.oschina.net/oscnet/up-2c7f96d61daf6d0c0b91670c1198e60ba98.png" alt="" referrerpolicy="no-referrer"></p><p>在本節中，我們提出根據網絡的捕捉範圍依賴關係的變化模式重新分配適當的計算模塊，以實現更好的計算性能。我們提出了兩種混合堆疊策略用於倒數第二個階段，(i) 依次堆疊一個 SAM 塊和一個 MSA 塊。(ii) 在 stage 的前半部分使用 SAM 塊，在後半部分使用 MSA 塊。為了評估這兩種混合堆疊策略的有效性，我們在 ImageNet-1K 上評估了它們的 top-1 準確率。可以看到，(i) 混合堆疊策略更加有效。</p><p><img src="https://oscimg.oschina.net/oscnet/up-339767d0b9c4a55b9298904a5d9171562b9.png" alt="" referrerpolicy="no-referrer"></p><p>不僅如此，我們還計算了倒數第二個階段中 MSA 塊的相對感受野。值得注意的是，淺層 layer 的相對感受野開始階段有一個輕微的下降趨勢。作者認為這種下降可以歸因於 SAM 對早期 MSA Block 的影響，我們將這種現象稱為計算單元磨合適應期。而隨着網絡的加深，我們可以看到感受野呈平穩上升的趨勢，這表明我們提出的進化混合網絡有效地模擬了從局部到全局依賴捕捉的過渡。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8f3c21623fff8bcda5df6a79d0a14a8918c.png" alt="" referrerpolicy="no-referrer"></p><h2>4 實驗</h2><h3>4.1 分類實驗</h3><p><img src="https://oscimg.oschina.net/oscnet/up-8d488d75e796b97b54cee5d2f21eaab63ba.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-0b7d3d0ff76a3d5ade3fa45d963c46d9b04.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-558613af385ccdc706134277fb52196b0f4.png" alt="" referrerpolicy="no-referrer"></p><p>上表給出了不同模型大小在 ImageNet-1k 上的性能對比，從中可以看到：</p><ul><li>SMT 在 tiny、small 和 base 規模上都以更低的參數量和計算量達到了更優的性能；</li><li>SMT-B 在僅僅 32.0M 和 7.7GFlops 下就取得了 84.3% 的精度，甚至比大多數 80M 和 15G 以上的模型更好。</li><li>當採用 ImageNet-22k 與大尺度數據預訓練之後，SMT-L 精度提升到 87.1% 和 88.1%，優於現有的 CNN 和 Transformer 模型。<strong>特別地，SMT-L 用 4x 低的參數量和 3x 低的計算量就超過了 InternImage-XL(88.0%)</strong></li><li>這些結果表明 SMT 是一個 scalability 能力很強的模型，在各種尺度參數下都具有優異的性能。</li></ul><h3><strong>4</strong>.2 目標檢測實驗</h3><p><img src="https://oscimg.oschina.net/oscnet/up-a821c93b982a12ec1c606a55f466e9dd394.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-b7aaf64cebf88d47c1e2a5729fe4338091c.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-5821b176f43f9ac39fd69bb6afe6c189926.png" alt="" referrerpolicy="no-referrer"></p><p>上述三個表格是在多個檢測框架上的性能對比實驗，可以看到</p><ul><li>在多個檢測框架上，包括 Mask R-CNN、Cascade R-CNN、RetinaNet、Sparse R-CNN、ATSS 和 DINO 中，SMT 都獲得了更優的性能。</li><li>對於 Mask R-CNN，<strong>在 1x 和 3x 中，SMT-B 分別比 Swin-B 高 2.1mAP 和 1.3mAP，同時參數量只有 Swin-B 的一半。</strong></li><li>對於 DINO 檢測框架，<strong>SMT-S 僅僅用 39.9M 的參數量就達到了 54.0mAP</strong>，超越了現有同等規模大小的其他模型。</li></ul><h3><strong>4</strong>.3 分割實驗</h3><p><img src="https://oscimg.oschina.net/oscnet/up-690b693f0e3f3dd3a355ac034a56bed1967.png" alt="" referrerpolicy="no-referrer"></p><p>上表給出了 ADE20K 分割任務上的性能對比，從中可以看到當我們使用 uperNet 框架時，SMT 在不同尺度下擁有更低的參數量和計算量，同時精度也優於其他模型。</p><h3>4.4 消融實驗</h3><p><img src="https://oscimg.oschina.net/oscnet/up-f3060b4818bf5c64f1eca9716a3e9f6ac68.png" alt="" referrerpolicy="no-referrer"></p><h2>5 總結與展望</h2><p>總的來説，在視覺基礎模型 backbone 的探索路程中，我們有着對未來的展望：</p><ul><li>以視覺 Transformer 為例，除了在自監督學習等預訓練中依舊用着 ViT 這種 plain Vision Transformer，大部分視覺基礎模型都以 Swin 和 PvT 這種 Hierarchical 架構為基礎設計範式。而這種範式需要解決的問題就是如何在淺層 stage 中設計更高效的注意力機制計算來解決自注意力的二次複雜性帶來的計算負擔。是否有更優秀的計算模塊能夠代替 SAM 或者是 MSA 是我們後續需要繼續探索的路。</li><li>2023 年，更多的視覺 Transformer 模型和 CNN 基礎大模型被提出，它們在各大榜單上你追我趕，可以發現 CV 領域中 CNN 依舊有着一席之地。如果 Transformer 不能夠在 CV 領域完全替代 cnn 神經網絡，那麼將兩者的優勢結合起來是否是更好的選擇？因此，我們希望 SMT 可以作為 Hybrid CNN-Transformer 方向新的 baseline，推動該領域的進步和發展。</li></ul><hr><p><strong>●</strong><strong>Arxiv 地址：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.08579" target="_blank">https://arxiv.org/abs/2307.08579</a></p><p><strong>●</strong><strong>Github 地址：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAFeng-x%2FSMT" target="_blank">https://github.com/AFeng-x/SMT</a></p><p><strong>●</strong><strong>modelscope 地址：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FPAI%2FSMT%2Fsummary" target="_blank">https://modelscope.cn/models/PAI/SMT/summary</a></p><p><strong>●</strong><strong>論文鏈接：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2307.08579.pdf" target="_blank">https://arxiv.org/pdf/2307.08579.pdf</a></p><p><strong>●</strong><strong>代碼鏈接：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAFeng-x%2FSMT" target="_blank">https://github.com/AFeng-x/SMT</a></p><h2>Reference</h2><p>[1] Scale-Aware Modulation Meet Transformer[<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Farxiv.org%2Fabs%2F2307.08579" target="_blank">https://arxiv.org/abs/2307.08579</a>]</p><p>[2] An image is worth 16x16 words transformers for image recognition at scale [<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Farxiv.org%2Fpdf%2F2010.11929.pdf" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a>]</p><p>[2] Focal Modulation Network [<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Farxiv.org%2Fabs%2F2203.11926" target="_blank">https://arxiv.org/abs/2203.11926</a>]</p><p>[3] MixConv: Mixed Depthwise Convolutional Kernels [<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Farxiv.org%2Fabs%2F1907.09595" target="_blank">https://arxiv.org/abs/1907.09595</a>]</p><p>[4] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows [<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Farxiv.org%2Fabs%2F2103.14030" target="_blank">https://arxiv.org/abs/2103.14030</a>]</p><p>[5] InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions [<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Farxiv.org%2Fabs%2F2211.05778" target="_blank">https://arxiv.org/abs/2211.05778</a>]</p><h2>論文信息</h2><p>● <strong>論文標題：</strong></p><p>Scale-Aware Modulation Meet Transformer</p><p>● <strong>論文作者：</strong></p><p>林煒豐、吳梓恆、陳佳禹、黃俊、金連文</p><p>● <strong>論文 PDF 鏈接：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2307.08579.pdf" target="_blank">https://arxiv.org/pdf/2307.08579.pdf</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 03:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/10116363</guid>
            <link>https://my.oschina.net/u/5583868/blog/10116363</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TIOBE 10 月榜單：Java 跌幅最大，C# 逼近 Java]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">TIOBE 公佈了 2023&nbsp;年 10 月的</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">編程語言排行榜</a><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">。</span></span></p><p><img height="63" src="https://oscimg.oschina.net/oscnet/up-214d9b336ca0795bea8f9d57ecba2126c95.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">C# 和 Java 之間的差距越來越小，達到了歷史新低，目前兩者的差距僅為 1.2%。<span style="background-color:#ffffff">TIOBE CEO&nbsp;Paul Jansen&nbsp;</span><span style="background-color:#ffffff">認為，</span>如果這一趨勢繼續保持，那麼 C# 將在兩個月後超過 Java。</span></p><p><span style="color:#000000">在所有編程語言中，Java 的跌幅最大，為 -3.92%；C# 的漲幅最大，為 +3.29%（年度）。這兩種語言一直用於類似的領域，因此在過去 20 多年裏一直是競爭對手。<span style="background-color:#ffffff">Paul Jansen 指出，</span>Java 受歡迎程度下降的主要原因是甲骨文公司決定在 Java 8 之後引入付費許可模式，反觀微軟在 C# 上則採取了相反的做法。</span></p><p><span style="color:#000000">過去，C# 只能作為商業工具 Visual Studio 的一部分使用；如今的 C# 卻是免費開源的，從而受到許多開發人員的歡迎。此外，Java 衰落的原因還在於：該語言的定義在過去幾年裏沒有太大變化，其完全兼容的直接競爭對手 Kotlin 卻易於使用且免費。</span></p><p><strong style="color:#333333">TIOBE 9 月 TOP 20 編程語言</strong></p><p><img height="423" src="https://oscimg.oschina.net/oscnet/up-4edc1a0b402b29b97063d531852386e2273.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><span style="background-color:#ffffff">相較上月，T</span><span style="background-color:#ffffff">op&nbsp;10 榜單中的 SQL (10</span><span style="background-color:#ffffff">→9) 和 </span>Assembly language&nbsp;<span style="background-color:#ffffff">(9</span><span style="background-color:#ffffff">→10) </span>位置進行了互換，除此之外排名沒有任何變動。<span style="background-color:#ffffff">Top 11-20 中其他語言的一些排名變化有包括：</span></span></p><ul style="list-style-type:disc; margin-left:0; margin-right:0"><li><span style="color:#000000">Go&nbsp;<span style="background-color:#ffffff">的排名從 12 升至 11</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Scratch&nbsp;的排名從 14 升至 12</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Delphi/Object Pascal&nbsp;</span><span style="background-color:#ffffff">的排名持續攀升，自上月由 &nbsp;23 位回升至 15 位後，本月又升至了第 13 位</span></span></li><li><span style="color:#000000">MATLAB&nbsp;<span style="background-color:#ffffff">的排名從 13 跌至 14</span></span></li><li><span style="color:#000000">Swift&nbsp;<span style="background-color:#ffffff">的排名從 16 升至 15</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Fortran 的排名從 11 跌至 16</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">R 的排名從 18 升至 17</span></span></li><li><span style="color:#000000">Kotlin&nbsp;<span style="background-color:#ffffff">的排名從 20 升至 18</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Ruby 保持 19 不變</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Rust 的排名從 17&nbsp;跌至 20</span></span></li></ul><p><strong style="color:#333333">TOP 10 編程語言 TIOBE 指數走勢（2002-2022）</strong></p><p><img height="225" src="https://oscimg.oschina.net/oscnet/up-57b49445bfd6503a6c77c205f16ec8d2025.png" width="700" referrerpolicy="no-referrer"></p><p><strong style="color:#333333">第 21-50 名編程語言排行</strong></p><p><img height="426" src="https://oscimg.oschina.net/oscnet/up-b2036ba4f7fc158784908e321739a960260.png" width="500" referrerpolicy="no-referrer">&nbsp;</p><p><span style="color:#000000"><span style="background-color:#ffffff">第 51-100 名如下，由於它們之間的數值差異較小，僅以文本形式列出（按字母排序）：</span></span></p><p>&nbsp;</p><blockquote><p><span style="color:#000000">4th Dimension/4D, ABC, ActionScript, Apex, APL, Ballerina, bc, CL (OS/400), Clean, Clipper, CLIPS, Clojure, Crystal, Curl, Eiffel, Elixir, Erlang, Forth, Groovy, Hack, Icon, IDL, Io, J, J#, LabVIEW, Ladder Logic, LiveCode, ML, Modula-2, MQL5, NATURAL, Nim, OCaml, OpenEdge ABL, PL/I, PostScript, Pure Data, Q, Racket, Raku, REXX, RPG, Smalltalk, SPARK, SQR, Tcl, TOM, VHDL, Wolfram</span></p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">TIOBE 編程社區指數（The TIOBE Programming Community index）是一個衡量編程語言受歡迎程度的指標，該指數每月更新一次。評判的依據來自世界範圍內的工程師、課程和第三方供應商，包括流行的搜索引擎，如 Google、必應、雅虎、維基百科、亞馬遜、YouTube 和百度都被用於指數計算。值得注意的是，TIOBE 指數並不代表編程語言的好壞或編寫代碼的多少。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">該指數可以用來檢查你的編程技能是否還能跟上時代的步伐，或者在開始建立一個新的軟件系統時，基於指數對採用何種編程語言做出決策。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F" target="_blank">TIOBE 指數</a><span style="color:#000000">的定義方式，以及詳細榜單信息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">均可查看官網</a>。</span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 03:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260951/tiobe-index-2023010</guid>
            <link>https://www.oschina.net/news/260951/tiobe-index-2023010</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TypeScript 5.3 Beta]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TypeScript 5.3 已發佈 Beta 測試版。</p><p><strong>主要變化</strong></p><ul><li><p>支持&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-import-attributes" target="_blank">import attributes</a> 提案的最近更新</p></li><li><p><code>switch (true)</code>Narrowing</p></li><li><p>Narrowing On Comparisons to Booleans</p></li><li><p>檢查對實例字段的<code>super</code>屬性訪問</p></li><li><p>針對類型的交互式嵌套提示 (Interactive Inlay Hints)</p></li><li><p>跳過 JSDoc 解析以進行優化</p></li><li><p>合併 <code>tsserverlibrary.js</code>和<code>typescript.js</code></p></li></ul><hr><p><strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-import-attributes" target="_blank">import attributes</a></u></strong></p><p>import attributes 的一個用例是向運行時提供有關模塊預期格式的信息。</p><pre><code class="language-javascript">// We only want this to be interpreted as JSON,
// not a runnable/malicious JavaScript file with a `.json` extension.
import obj from "./something.json" with { type: "json" };</code></pre><p>TypeScript 不會檢查這些屬性的內容，因為它們是特定於主機的，因此不會對它們進行檢查，只是讓瀏覽器和運行時處理它們（可能會出錯）。</p><pre><code class="language-javascript">// TypeScript is fine with this.
// But your browser? Probably not.
import * as foo from "./foo.js" with { type: "fluffy bunny" };</code></pre><p>動態 import() 調用也可以通過第二個參數使用 import 屬性。</p><pre><code class="language-javascript">const obj = await import("./something.json", {
    with: { type: "json" }
});</code></pre><p>第二個參數的預期類型由一個名為<code>ImportCallOptions</code>的類型定義，默認情況下，該類型只期望調用一個屬性<code>with</code>。</p><p>請注意，導入屬性是從早期的 "導入斷言"（import assertions）提案演變而來的，該提案已在 TypeScript 4.5 中實現。最明顯的區別是使用了<code>with</code>關鍵字而非<code>assert</code>關鍵字。但不太明顯的區別是，運行時現在可以自由使用屬性來指導導入路徑的解析和解釋，而導入斷言只能在加載模塊後斷言某些特性。</p><p>隨着時間的推移，TypeScript 將淘汰舊的導入斷言語法，轉而使用建議的導入屬性語法。使用 assert 的現有代碼應遷移到 with 關鍵字。需要導入屬性的新代碼應只使用<code>with</code>關鍵字。</p><p><strong><code>switch (true)</code>Narrowing</strong></p><p>TypeScript 5.3 可以根據<code>switch (true)</code>中每個<code>case</code>子句的條件執行 narrowing。</p><pre><code class="language-javascript">function f(x: unknown) {
    switch (true) {
        case typeof x === "string":
            // 'x' is a 'string' here
            console.log(x.toUpperCase());
            // falls through...

        case Array.isArray(x):
            // 'x' is a 'string | any[]' here.
            console.log(x.length);
            // falls through...

        default:
          // 'x' is 'unknown' here.
          // ...
    }
}</code></pre><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Ftypescript%2Fannouncing-typescript-5-3-beta%2F" target="_blank">詳情查看發佈公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 08:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261022/typescript-5-3-beta</guid>
            <link>https://www.oschina.net/news/261022/typescript-5-3-beta</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 聊聊前端框架的未來 Signals]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>Signals 在目前前端框架的選型中遙遙領先！</p></blockquote><p>國慶節前最後一週在 Code Review 新同學的 React 代碼，發現他想通過 memo 和 useCallback 只渲染被修改的子組件部分。事實上該功能在 React 中是難以做到的。因為 React 狀態變化後，會重新執行 render 函數。也就是在組件中調用 setState 之後，整個函數將會重新執行一次。</p><p>React 本身做不到。但是基於 Signals 的框架卻不會這樣，它通過自動狀態綁定和依賴跟蹤使得當前狀態變化後僅僅只會重新執行用到該狀態代碼塊。</p><p>個人當時沒有過多的解釋這個問題，只是匆匆解釋了一下 React 的渲染機制。在這裏做一個 Signals 的梳理。</p><h2>優勢</h2><p>對比 React，基於 Signals 的框架狀態響應粒度非常細。這裏以 Solid 為例：</p><pre><code class="language-js">import { createSignal, onCleanup } from "solid-js";

const CountingComponent = () =&gt; {
  // 創建一個 signal
  const [count, setCount] = createSignal(0);

  // 創建一個 signal
  const [count2] = createSignal(666);

  // 每一秒遞增 1
  const interval = setInterval(() =&gt; {
    setCount((c) =&gt; c + 1);
  }, 1000);

  // 組件銷燬時清除定時器
  onCleanup(() =&gt; clearInterval(interval));

  return (
    &lt;div&gt;
      &lt;div&gt;
        count: {count()}
        {console.log("count is", count())}
      &lt;/div&gt;
      &lt;div&gt;
        count2: {count2()}
        {console.log("count2 is", count2())}
      &lt;/div&gt;
    &lt;/div&gt;
  );
};
</code></pre><p>上面這段代碼在 count 單獨變化時，只會打印 count，壓根不會打印 count2 數據。</p><p>控制枱打印如下所示：</p><ul><li>count is 0</li><li>count2 is 666</li><li>count is 1</li><li>count is 2</li><li>...</li></ul><p>從打印結果來看，Solid 只會在最開始執行一次渲染函數，後續僅僅只會渲染更改過的 DOM 節點。這在 React 中是不可能做到的，React 是基於視圖驅動的，狀態改變會重新執行整個渲染函數，並且 React 完全無法識別狀態是如何被使用的，開發者甚至可以通過下面的代碼來實現 React 的重新渲染。</p><pre><code class="language-js">const [, forceRender] = useReducer((s) =&gt; s + 1, 0);
</code></pre><p>除了更新粒度細之外，使用 Signals 的框架心智模型也更加簡單。其中最大的特點是：開發者完全不必在意狀態在哪定義，也不在意對應狀態在哪渲染。如下所示：</p><pre><code class="language-js">import { createSignal } from "solid-js";

// 把狀態從過組件中提取出來
const [count, setCount] = createSignal(0);
const [count2] = createSignal(666);

setInterval(() =&gt; {
  setCount((c) =&gt; c + 1);
}, 1000);

// 子組件依然可以使用 count 函數
const SubCountingComponent = () =&gt; {
  return &lt;div&gt;{count()}&lt;/div&gt;;
};

const CountingComponent = () =&gt; {
  return (
    &lt;div&gt;
      &lt;div&gt;
        count: {count()}
        {console.log("count is", count())}
      &lt;/div&gt;
      &lt;div&gt;
        count2: {count2()}
        {console.log("count2 is", count2())}
      &lt;/div&gt;
      &lt;SubCountingComponent /&gt;
    &lt;/div&gt;
  );
};
</code></pre><p>上述代碼依然可以正常運行。因為它是基於狀態驅動的。開發者在組件內使用 Signal 是本地狀態，在組件外定義 Signal 就是全局狀態。</p><p>Signals 本身不是那麼有價值，但結合派生狀態以及副作用就不一樣了。代碼如下所示：</p><pre><code class="language-js">import {
  createSignal,
  onCleanup,
  createMemo,
  createEffect,
  onMount,
} from "solid-js";

const [count, setCount] = createSignal(0);

setInterval(() =&gt; {
  setCount((c) =&gt; c + 1);
}, 1000);

// 計算緩存
const doubleCount = createMemo(() =&gt; count() * 2);

// 基於當前緩存
const quadrupleCount = createMemo(() =&gt; doubleCount() * 2);

// 副作用
createEffect(() =&gt; {
  // 在 count 變化時重新執行 fetch
  fetch(`/api/${count()}`);
});

const CountingComponent = () =&gt; {
  // 掛載組件時執行
  onMount(() =&gt; {
    console.log("start");
  });

  // 銷燬組件時執行
  onCleanup(() =&gt; {
    console.log("end");
  });

  return (
    &lt;div&gt;
      &lt;div&gt;Count value is {count()}&lt;/div&gt;
      &lt;div&gt;doubleCount value is {doubleCount()}&lt;/div&gt;
      &lt;div&gt;quadrupleCount value is {quadrupleCount()}&lt;/div&gt;
    &lt;/div&gt;
  );
};
</code></pre><p>從上述代碼可以看到，派生狀態和副作用都不需要像 React 一樣填寫依賴項，同時也將副作用與生命週期分開 (代碼更好閲讀)。</p><h2>實現機制</h2><p>細粒度，高性能，同時還沒有什麼限制。不愧被譽為前端框架的未來。那麼它究竟是如何實現的呢？</p><p>本質上，Signals 是一個在訪問時跟蹤依賴、在變更時觸發副作用的值容器。</p><p>這種基於響應性基礎類型的範式在前端領域並不是一個特別新的概念：它可以追溯到十多年前的 Knockout observables 和 Meteor Tracker 等實現。Vue 的選項式 API 也是同樣的原則，只不過將基礎類型這部分隱藏在了對象屬性背後。依靠這種範式，Vue2 基本不需要優化就有非常不錯的性能。</p><h3>依賴收集</h3><p>React useState 返回當前狀態和設置值函數，而 Solid 的 createSignal 返回兩個函數。即：</p><pre><code class="language-TypeScript">type useState = (initial: any) =&gt; [state, setter];

type createSignal = (initial: any) =&gt; [getter, setter];
</code></pre><p>為什麼 createSignal 要傳遞 getter 方法而不是直接傳遞對應的 state 值呢？這是因為框架為了具備響應能力，Signal 必須要收集誰對它的值感興趣。僅僅傳遞狀態是無法提供 Signal 任何信息的。而 getter 方法不但返回對應的數值，同時執行時創建一個訂閲，以便收集所有依賴信息。</p><h3>模版編譯</h3><p>要保證 Signals 框架的高性能，就不得不結合模版編譯實現該功能，框架開發者通過模版編譯實現動靜分離，配合依賴收集，就可以做到狀態變量變化時點對點的 DOM 更新。所以目前主流的 Signals 框架沒有使用虛擬 DOM。而基於虛擬 DOM 的 Vue 目前依靠編譯器來實現類似的優化。</p><p>下面我們先看看 Solid 的模版編譯：</p><pre><code class="language-js">const CountingComponent = () =&gt; {
  const [count, setCount] = createSignal(0);
  const interval = setInterval(() =&gt; {
    setCount((c) =&gt; c + 1);
  }, 1000);

  onCleanup(() =&gt; clearInterval(interval));
  return &lt;div&gt;Count value is {count()}&lt;/div&gt;;
};
</code></pre><p>對應編譯後的的組件代碼。</p><pre><code class="language-js">const _tmpl$ = /*#__PURE__*/ _$template(`&lt;div&gt;Count value is `);

const CountingComponent = () =&gt; {
  const [count, setCount] = createSignal(0);
  const interval = setInterval(() =&gt; {
    setCount((c) =&gt; c + 1);
  }, 1000);

  onCleanup(() =&gt; clearInterval(interval));
  return (() =&gt; {
    const _el$ = _tmpl$(),
      _el$2 = _el$.firstChild;
    _$insert(_el$, count, null);
    return _el$;
  })();
};
</code></pre><ul><li>執行 _tmpl$ 函數，獲取對應組件的靜態模版</li><li>提取組件中的 count 函數，通過 _$insert 將狀態函數和對應模版位置進行綁定</li><li>調用 setCount 函數更新時，比對一下對應的 count，然後修改對應的 _el$ 對應數據</li></ul><h2>其他</h2><p>大家可以看一看使用 Signals 的主流框架：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.vuejs.org%2Fapi%2Freactivity-core.html%23ref" target="_blank">Vue Ref</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fangular.io%2Fguide%2Fsignals" target="_blank">Angular Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpreactjs.com%2Fguide%2Fv10%2Fsignals%2F" target="_blank">Preact Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.solidjs.com%2Fdocs%2Flatest%2Fapi%23createsignal" target="_blank">Solid Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwik.builder.io%2Fdocs%2Fcomponents%2Fstate%2F%23usesignal" target="_blank">Qwik Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsvelte.dev%2Fblog%2Frunes" target="_blank">Svelte 5(即將推出)</a></li></ul><p>不過目前來看 React 團隊可能不會使用 Signals。</p><ul><li>Signals 性能很好，但不是編寫 UI 代碼的好方式</li><li>計劃通過編譯器來提升性能</li><li>可能會添加類似 Signals 的原語</li></ul><p>PREACT 作者編寫了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2F%40preact%2Fsignals-react" target="_blank">@preact/signals-react </a> 為 React 提供了 Signals。不過個人不建議在生產環境使用。</p><p>篇幅有限，後續個人會解讀 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2F%40preact%2Fsignals-core" target="_blank">@preact/signals-core</a> 的源碼。</p><h2>參考資料</h2><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7137100589208436743%3FsearchId%3D2023100323265799EF4CF92C95049F6276" target="_blank">精讀《SolidJS》</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.solidjs.com%2F" target="_blank">Solid.js</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsvelte.dev%2Fblog%2Frunes" target="_blank">Introducing runes</a></p></li></ul><h2>鼓勵一下</h2><p>如果你覺得這篇文章不錯，希望可以給與我一些鼓勵，在我的 github 博客下幫忙 star 一下。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwsafight%2FpersonBlog" target="_blank">博客地址</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 06:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/wsafight/blog/10115779</guid>
            <link>https://my.oschina.net/wsafight/blog/10115779</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Apache Hudi 0.14.0 版本發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Apache Hudi 0.14.0 現已發佈。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FATf-92UzW5iOGXYODYn0ug" target="_blank">公告</a>指出，該版本標誌着一個重要的里程碑，具有一系列新功能和增強功能。其中包括引入<strong>Record Level Index</strong>、<strong>自動生成記錄鍵</strong>&nbsp;、用於增量讀取的&nbsp;<code>hudi_table_changes</code>函數等等。</p><p>值得注意的是，此版本還包含對&nbsp;<strong>Spark 3.4 的支持</strong>。在 Flink 方面，0.14.0 版本帶來了一些令人興奮的功能，例如<strong>一致哈希索引支持、支持 Flink 1.17 以及支持更新和刪除語句</strong>。此外此版本還升級了 Hudi 表版本，提示用户查閲下面提供的遷移指南。我們鼓勵用户在採用 0.14.0 版本之前查看重大特性、重大變化和行為變更。</p><h1>遷移指南</h1><p>在 0.14.0 版本進行了一些更改，例如從 ".aux" 文件夾中刪除壓縮計劃以及引入新的日誌塊版本。作為此版本的一部分，表版本更新到版本 6。在具有舊錶版本的表上運行版本 0.14.0 的 Hudi 作業時，會觸發自動升級過程以將表升級到版本 6。升級對於每個 Hudi 表都是一次性的，因為升級完成後&nbsp;<code>hoodie.table.version</code>&nbsp;會在屬性文件中更新。此外還包括用於降級的命令行工具，允許用户從表版本 6 降級到 5，或從 Hudi 0.14.0 恢復到 0.14.0 之前的版本。請從 0.14.0 環境使用此工具。有關更多詳細信息，請參閲&nbsp;hudi-cli。</p><blockquote><p>注意：如果從舊版本（0.14.0 之前）遷移，建議按順序檢查每個舊版本的升級説明。</p></blockquote><h1>Bundle 包更新</h1><h3>新 Spark Bundle 包</h3><p>在此版本擴展了支持範圍，包括 Spark 3.4 (hudi-spark3.4-bundle_2.12) 和 Spark 3.0 (hudi-spark3.0-bundle_2.12) 的 Bundle 包。請注意，在 Hudi 0.10.1 版本之後，對 Spark 3.0 的支持已停止，但由於社區的強烈興趣，在此版本中恢復了對 Spark 3.0 的支持。</p><h1>重大變化</h1><h3>Spark SQL INSERT INTO 行為</h3><p>在 0.14.0 版本之前，Spark SQL 中通過 INSERT INTO 攝取的數據遵循 upsert 流程，其中多個版本的記錄將合併為一個版本。但是從 0.14.0 開始更改了 INSERT INTO 的默認行為，默認行為更改為<code>insert</code>流。此更改顯着提高了寫入性能，因為它繞過了索引查找。</p><p>如果使用 preCombine 鍵創建表，則 INSERT INTO 的默認操作仍為&nbsp;<code>upsert</code>。相反如果沒有設置 preCombine 鍵，則 INSERT INTO 的底層寫操作默認為&nbsp;<code>insert</code>。用户可以根據自己的要求顯式設置配置&nbsp;<code>hoodie.spark.sql.insert.into.operation</code>&nbsp;的值來靈活地覆蓋此行為。此配置的可能值包括&nbsp;<code>insert</code>、<code>bulk_insert</code>&nbsp;和&nbsp;<code>upsert</code>。</p><p>此外在 0.14.0 版本中棄用了兩個相關的舊配置</p><ul><li><p>hoodie.sql.insert.mode</p></li><li><p>hoodie.sql.bulk.insert.enable</p></li></ul><h1>行為變更</h1><h3>使用 Spark SQL Inserts 簡化重複處理</h3><p>如果操作類型配置為 Spark SQL INSERT INTO 流的插入，用户現在可以選擇使用配置設置 hoodie.datasource.insert.dup.policy 強制執行重複策略。此策略確定當正在攝取的傳入記錄已存在於存儲中時採取的操作。此配置的可用值如下：</p><ul><li><p>none：不採取任何特定操作，如果傳入記錄包含重複項，則允許 Hudi 表中存在重複項。</p></li><li><p>drop：傳入寫入中的匹配記錄將被刪除，其餘記錄將被攝取。</p></li><li><p>fail：如果重新攝取相同的記錄，寫入操作將失敗。本質上由鍵生成策略確定的給定記錄只能被攝取到目標表中一次。</p></li></ul><p>通過添加此配置，舊的相關配置&nbsp;<code>hoodie.datasource.write.insert.drop.duplicates</code>&nbsp;現已棄用。當兩者都指定時，新配置將優先於舊配置。如果未提供特定配置，則將採用較新配置的默認值。強烈鼓勵用户遷移到使用這些較新的配置。</p><h3>MOR 表 Compaction</h3><p>對於 Spark 批寫入器（Spark Datasource 和 Spark SQL），默認情況下會自動為 MOR（讀取時合併）表啓用壓縮，除非用户顯式覆蓋此行為。用户可以選擇通過將&nbsp;<code>hoodie.compact.inline</code>設置為&nbsp;<code>false</code>&nbsp;顯式禁用壓縮。如果用户不覆蓋此配置，大約每 5 個增量提交（<code>hoodie.compact.inline.max.delta.commits</code>的默認值）會觸發 MOR 表的壓縮。</p><h3>HoodieDeltaStreamer 更名為 HoodieStreamer</h3><p>從版本 0.14.0 開始將 HoodieDeltaStreamer 重命名為 HoodieStreamer。同時確保了向後兼容性，以便現有的用户作業不受影響。但是在即將發佈的版本中可能會停止對 Deltastreamer 的支持。因此強烈建議用户改用 HoodieStreamer。</p><h3>MERGE INTO JOIN CONDITION</h3><p>從 0.14.0 版本開始，當用户沒有提供明確的規範時，Hudi 能夠自動生成主記錄鍵。此增強功能使&nbsp;<code>MERGE INTO JOIN</code>&nbsp;子句能夠引用 Hudi 表中連接條件的任何數據列，其中主鍵由 Hudi 本身生成。但是在用户配置主記錄鍵的情況下，連接條件仍然需要用户指定的主鍵字段。</p><h1>重大特性</h1><h3>Record Level Index</h3><p>Hudi 版本 0.14.0 引入了新的索引實現 -&nbsp;Record Level Index。記錄級索引通過有效存儲每條記錄的位置並在索引查找操作期間實現快速檢索，顯着增強了大型表的寫入性能。它可以有效地替代 Hudi 中常用的其他全局索引，例如 Global_bloom、Global_Simple 或 Hbase。</p><p>由於在查找過程中從各種數據文件收集索引數據的成本很高，布隆索引和簡單索引對於大型數據集表現出較低的性能。而且，這些索引不保留一對一的記錄鍵來記錄文件路徑映射；相反，他們在查找時通過優化搜索來推斷映射。這些索引所需的每個文件的開銷使得它們對於具有大量文件或記錄的數據集效率較低。</p><p>另一方面，Hbase 索引為每個記錄鍵保存一對一的映射，從而實現隨數據集大小擴展的快速性能。然而，它需要一個單獨的 HBase 集羣來進行維護，這在操作上具有挑戰性且資源密集型，需要專門的專業知識。</p><p>記錄索引結合了 HBase 索引的速度和可擴展性，而沒有其限制和開銷。作為 HUDI 元數據表的一部分，未來寫入和查詢方面的任何性能增強都將自動轉化為記錄索引性能的改進。採用記錄級索引有可能將索引查找性能提高 4 到 10 倍，具體取決於工作負載，即使對於超大規模數據集（例如 1TB）也是如此。</p><p>通過記錄級別索引，可以觀察到大型數據集的顯着性能改進，因為延遲與攝取的數據量成正比。這與其他全局索引形成鮮明對比，其中索引查找時間隨着表大小線性增加。記錄級索引專門設計用於有效處理此類大規模數據的查找，而查找時間不會隨着表大小的增長而線性增加。</p><p>為了利用這種快速的索引的優勢，用户需要啓用兩種配置：</p><ul><li><p>必須啓用&nbsp;<code>hoodie.metadata.record.index.enable</code>&nbsp;才能將記錄級別索引寫入元數據表。</p></li><li><p><code>hoodie.index.type</code>&nbsp;需要設置為&nbsp;<code>RECORD_INDEX</code>&nbsp;以便索引查找利用記錄級別索引。</p></li></ul><h3>支持 Hudi 表自動生成鍵</h3><p>從 Hudi 最初的正式版本開始，主鍵是用户需要為任何 Hudi 表配置的必填字段。從 0.14.0 開始，我們放寬了這一限制。此增強功能解決了社區內的長期需求，其中某些用例不具有主鍵。版本 0.14.0 現在為用户提供了創建 Hudi 表的靈活性，而無需顯式配置主鍵（通過省略配置設置 -&nbsp;<code>hoodie.datasource.write.recordkey.field</code>）。這種情況下 Hudi 將自動生成主鍵。此功能僅適用於新表，不能更改現有表。</p><p>所有 Spark 寫入器都提供此功能，但有一定限制。對於僅追加類型的用例，如下四個寫入器都允許插入和批量插入 - Spark Datasource、Spark SQL、Spark Streaming、Hoodie Streamer。僅使用 Spark SQL MERGE INTO 、 UPDATE 和 DELETE 語句支持更新和刪除。對於 Spark Datasource，僅當 DataFrame 包含 Hudi 的元字段時才支持 UPDATE 和 DELETE。請查看快速入門指南，瞭解有關自動生成鍵的 Hudi 表 CRUD 操作的代碼片段。</p><h3>Spark 3.4 版本支持</h3><p>添加 Spark 3.4 支持， Spark 3.4 的用户可以使用&nbsp;hudi-spark3.4-bundle。Spark 3.2、Spark 3.1、Spark3.0 和 Spark 2.4 將繼續受支持。請檢查遷移指南以獲取 Bundle 包更新。可以瀏覽快速入門指南快速開始使用 Hudi 和 Spark 3.4。</p><h3>查詢端改進</h3><h4>Athena 的元數據表支持</h4><p>用户現在可以與 Athena 無縫地利用 Hudi 的元數據表。文件列表索引通過從維護分區到文件映射的索引檢索信息，消除了對遞歸文件系統調用（如「列表文件」）的需要。事實證明這種方法非常高效，尤其是在處理大量數據集時。使用 Hudi 0.14.0，用户可以在為其 Hudi 表執行 Glue 目錄同步時激活基於元數據表的文件列表。要啓用此功能，用户可以配置&nbsp;<code>hoodie.datasource.meta.sync.glue.metadata_file_listing</code>&nbsp;並在 Glue 同步過程中將其設置為 true。</p><h4>查詢利用 Parquet 布隆過濾器</h4><p>在 Hudi 0.14.0 中，用户現在可以使用原生 Parquet 布隆過濾器，前提是他們的計算引擎支持 Apache Parquet 1.12.0 或更高版本。這種支持涵蓋了數據集的寫入和讀取。Hudi 通過 Hadoop 配置方便使用原生 Parquet 布隆過濾器。用户需要使用代表要應用布隆過濾器的列的特定鍵來設置 Hadoop 配置。例如，&nbsp;<code>parquet.bloom.filter.enabled#rider=true</code>&nbsp;為 rider 列創建布隆過濾器。每當查詢涉及 rider 列上的謂詞時，布隆過濾器就會發揮作用，從而增強讀取性能。</p><h4>多寫入器的增量查詢</h4><p>在多寫入器場景中，由於併發寫入活動，時間線中可能會出現間隙（requested 或 inflight 時刻不是最新時刻）。在執行增量查詢時，這些間隙可能會導致結果不一致。為瞭解決這個問題，Hudi 0.14.0 引入了一個新的配置設置&nbsp;<code>hoodie.read.timeline.holes.resolution.policy</code>，專門用於處理增量查詢中的這些不一致問題。該配置提供了三種可能的策略：</p><ul><li><p>FAIL：這是默認策略，當增量查詢期間發現此類時間線間隙時，會引發異常。</p></li><li><p>BLOCK：在此策略中，增量查詢的結果僅限於時間線中空洞之間的時間範圍。例如，如果在 t0 到 t2 的增量查詢範圍內，在 t1 時刻檢測到間隙，則查詢將僅顯示 t0 到 t1 之間的結果，而不會失敗。</p></li><li><p>USE_TRANSITION_TIME：此策略是實驗性的，涉及在增量查詢期間使用狀態轉換時間，該時間基於時間線中提交元數據文件的文件修改時間。</p></li></ul><h4>Hive 3.x 的 Timestamp 類型支持</h4><p>相當長一段時間以來，Hudi 用户在讀取 Spark 的 Timestamp 類型列以及隨後嘗試使用 Hive 3.x 讀取它們時遇到了挑戰。在 Hudi 0.13.x 中，我們引入了一種解決方法來緩解此問題，0.14.0 版本現在確保 HiveAvroSerializer 與 Hive 3.x 完全兼容以解決此問題。</p><h4>Google BigQuery 同步增強功能</h4><p>在 0.14.0 中，BigQuerySyncTool&nbsp;支持使用清單將表同步到 BigQuery。與傳統方式相比，這預計將具有更好的查詢性能。模式演進由清單方法支持。由於新的 schema 處理改進，不再需要從文件中刪除分區列。要啓用此功能，用户可以將&nbsp;<code>hoodie.gcp.bigquery.sync.use_bq_manifest_file</code>設置為&nbsp;<code>true</code>。</p><h3>Spark 讀取端改進</h3><h4>MOR Bootstrap 表的快照讀取支持</h4><p>在 0.14.0 中，為引導表添加了 MOR 快照讀取支持。默認行為已通過多種方式進行了更改，以匹配非引導 MOR 表的行為。快照讀取現在將成為默認讀取模式。使用&nbsp;<code>hoodie.datasource.query.type=read_optimized</code>&nbsp;進行讀取優化查詢，這是以前的默認行為。此類表的 Hive 同步將導致表名帶有 _ro 和 _rt 後綴，分別表示讀取優化和快照讀取。</p><h4>用於增量讀取的表值函數 hudi_table_changes</h4><p>Hudi 已經提供了使用增量查詢類型獲取自給定提交時間戳以來更改的記錄流的功能。在 Hudi 0.14.0 中，我們添加了一種新的、更簡單的方法，使用名為 hudi_table_changes 的表值函數來獲取 Hudi 數據集的最新狀態或更改流。以下是有關如何使用此函數的語法和一些示例。</p><pre><code>SYNTAX
hudi_table_changes(table,&nbsp;queryType,&nbsp;beginTime&nbsp;[,&nbsp;endTime]);
--&nbsp;table:&nbsp;table&nbsp;identifier,&nbsp;example:&nbsp;db.tableName,&nbsp;tableName,&nbsp;or&nbsp;path&nbsp;for&nbsp;the&nbsp;table,&nbsp;example:&nbsp;hdfs://path/to/hudiTable.
--&nbsp;queryType:&nbsp;incremental&nbsp;query&nbsp;mode,&nbsp;valid&nbsp;values:&nbsp;latest_state,&nbsp;cdc
(for&nbsp;cdc&nbsp;query,&nbsp;first&nbsp;enable&nbsp;cdc&nbsp;for&nbsp;the&nbsp;table&nbsp;by&nbsp;setting&nbsp;cdc.enabled=true),
--&nbsp;beginTime:&nbsp;instantTime&nbsp;to&nbsp;begin&nbsp;query&nbsp;from,&nbsp;example:&nbsp;earliest,&nbsp;202305150000,
--&nbsp;endTime:&nbsp;optional&nbsp;instantTime&nbsp;to&nbsp;end&nbsp;query&nbsp;at,&nbsp;example:&nbsp;202305160000,

EXAMPLES
--&nbsp;incrementally&nbsp;query&nbsp;data&nbsp;by&nbsp;table&nbsp;name
--&nbsp;start&nbsp;from&nbsp;earliest&nbsp;available&nbsp;commit,&nbsp;end&nbsp;at&nbsp;latest&nbsp;available&nbsp;commit.
SELECT&nbsp;*&nbsp;FROM&nbsp;hudi_table_changes('db.table',&nbsp;'latest_state',&nbsp;'earliest');

--&nbsp;start&nbsp;from&nbsp;earliest,&nbsp;end&nbsp;at&nbsp;202305160000.
SELECT&nbsp;*&nbsp;FROM&nbsp;hudi_table_changes('table',&nbsp;'latest_state',&nbsp;'earliest',&nbsp;'202305160000');

--&nbsp;incrementally&nbsp;query&nbsp;data&nbsp;by&nbsp;path
--&nbsp;start&nbsp;from&nbsp;earliest&nbsp;available&nbsp;commit,&nbsp;end&nbsp;at&nbsp;latest&nbsp;available&nbsp;commit.
SELECT&nbsp;*&nbsp;FROM&nbsp;hudi_table_changes('path/to/table',&nbsp;'cdc',&nbsp;'earliest');

</code></pre><p>查看快速入門以獲取更多示例。</p><h4>Spark 中新的 MOR 文件格式讀取器</h4><p>基於&nbsp;RFC-72&nbsp;旨在重新設計 Hudi-Spark 集成的提案，我們引入了用於 MOR（讀取合併）表的實驗性文件格式讀取器。與舊文件格式相比，該讀取器預計可將讀取延遲顯着降低 20% 至 40%，特別是對於快照和引導查詢。目標是使延遲更接近 COW（寫入時複製）文件格式的延遲。要利用這種新文件格式，用户需要設置&nbsp;<code>hoodie.datasource.read.use.new.parquet.file.format=true</code>。值得注意的是，此功能仍處於實驗階段，並且存在一些限制。有關更多詳細信息以及有興趣做出貢獻，請參閲&nbsp;HUDI-6568。</p><h3>Spark 寫入端改進</h3><h4>Bulk_Insert 和行寫入器增強</h4><p>0.14.0 版本支持在執行 INSERT OVERWRITE TABLE 和 INSERT OVERWRITE PARTITION 等 SQL 操作時使用批量插入操作。要啓用批量插入，請將配置&nbsp;<code>hoodie.spark.sql.insert.into.operation</code>&nbsp;設置為值<code>bulk_insert</code>。與插入操作相比，批量插入具有更好的寫入性能。另外簡單存儲桶索引也支持了行寫入器。</p><h3>Hoodie DeltaStreamer 增強</h3><h4>動態配置更新</h4><p>當 Hoodie Streamer 以連續模式運行時，可以在每次同步調用之前刷新/更新屬性。有興趣的用户可以實現&nbsp;<code>org.apache.hudi.utilities.deltastreamer.ConfigurationHotUpdateStrategy</code>&nbsp;來利用它。</p><h4>HoodieStreamer 基於 SQL 文件的源</h4><p>HoodieStreamer 中添加了一個新源 -&nbsp;SqlFileBasedSource，旨在促進一次性回填場景。</p><h3>Flink 增強功能</h3><p>以下是 0.14.0 版本中基於 Flink Engine 的增強功能。</p><h4>一致的哈希索引支持</h4><p>與靜態哈希索引（BUCKET 索引）相比，一致性哈希索引為寫入者提供了數據桶的動態可擴展性。要利用此功能，請將選項<code>index.type</code>配置為 BUCKET 並將<code>hoodie.index.bucket.engine</code>設置為<code>CONSISTENT_HASHING</code>。</p><p>啓用一致性哈希索引時，在寫入器中激活異步 Clustering 調度非常重要。Clustering 計劃應通過離線作業執行。在此過程中，寫入器將在 Clustering Pending 時對新舊數據桶執行雙重寫入。雖然雙寫不會影響正確性，但強烈建議儘快執行 Clustering。</p><h4>用於流式讀取的動態分區修剪</h4><p>在 0.14.0 之前，當查詢具有恆定日期時間過濾的謂詞時，Flink 流式讀取器無法正確修剪日期時間分區。自此版本以來，Flink 流式查詢已得到修復，以支持任何過濾謂詞模式，包括但不限於日期時間過濾。</p><h4>簡單桶索引表查詢加速（帶索引字段）</h4><p>對於一個簡單的桶索引表，如果查詢對索引鍵字段採用等式過濾謂詞，Flink 引擎會優化規劃，只包含來自非常特定數據桶的源數據文件；此類查詢預計平均性能將提高近&nbsp;<code>hoodie.bucket.index.num.buckets</code>&nbsp;倍。</p><h4>Flink 1.17 支持</h4><p>Flink 1.17 支持新的編譯 maven 配置文件 flink1.17，在 Flink Hudi Bundle 包 jar 的編譯 cmd 中添加配置文件 -Pflink1.17 以啓用與 Flink 1.17 的集成。</p><h4>Flink 更新刪除語句</h4><p>自此版本以來，UPDATE 和 DELETE 語句已集成用於批量查詢。當前只有定義主鍵的表可以正確處理該語句。</p><pre><code>UPDATE&nbsp;hudi_table&nbsp;SET&nbsp;...&nbsp;WHERE&nbsp;...
DELETE&nbsp;FROM&nbsp;hudi_table&nbsp;WHERE&nbsp;...

EXAMPLES
--&nbsp;update&nbsp;the&nbsp;specific&nbsp;records&nbsp;with&nbsp;constant&nbsp;age
UPDATE&nbsp;hudi_table&nbsp;SET&nbsp;age=19&nbsp;WHERE&nbsp;UUID&nbsp;in&nbsp;('id1',&nbsp;'id2');
--&nbsp;delete&nbsp;all&nbsp;the&nbsp;records&nbsp;that&nbsp;with&nbsp;age&nbsp;greater&nbsp;than&nbsp;23
DELETE&nbsp;FROM&nbsp;hudi_table&nbsp;WHERE&nbsp;age&nbsp;&gt;&nbsp;23;

</code></pre><h3>Java 增強功能</h3><p>Java 引擎已擴展支持許多寫操作，使其與其他引擎保持一致。例如 Java Engine 0.14.0 中添加了壓縮、Clustering 和元數據表支持。</p><h3>已知回退</h3><p>在 Hudi 0.14.0 中，當查詢使用 ComplexKeyGenerator 或 CustomKeyGenerator 的表時，分區值以字符串形式返回。請注意，存儲上沒有類型更改，即分區字段以存儲上的用户定義類型寫入。這對於上述鍵生成器來説是一個重大變化，將在 0.14.1 中修復。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 03:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260955/apache-hudi-0-14-0-released</guid>
            <link>https://www.oschina.net/news/260955/apache-hudi-0-14-0-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
