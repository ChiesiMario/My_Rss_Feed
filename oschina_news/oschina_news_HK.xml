<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 10 Nov 2023 03:00:53 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[文心一言用户規模已達 7000 萬]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在前沿數字技術創新與安全論壇和人工智能賦能產業發展論壇上，百度 CTO 王海峯</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbH6zON1itJDh9bwCAeLfWw" target="_blank"><span style="color:#2980b9">披露</span></a><span style="color:#000000">，文心一言自 8 月 31 日面向全社會開放至今，用户規模現已達到 7000 萬，場景 4300 個，應用 2492 個。</span></p><p><span style="color:#000000">王海峯表示，人工智能是新一輪科技革命和產業變革的重要驅動力量，深度學習作為人工智能的核心技術，具有很強的通用性，並具備標準化、自動化和模塊化的工業大生產特徵，而大模型的興起，使得人工智能應用的深度和廣度進一步拓展。人工智能已進入工業大生產階段。</span></p><p><span style="color:#000000">例如，標準化方面，框架和模型聯合優化，多硬件統一適配，應用模式簡潔高效，大幅降低人工智能應用門檻；自動化方面，從訓練、適配，到推理部署，提升人工智能研發全流程效率；模塊化方面，豐富的產業級模型庫，支撐人工智能在廣泛場景的便捷應用。</span></p><p><span style="color:#000000">王海峯認為，人工智能具有多種典型能力，理解、生成、邏輯、記憶是其中的基礎能力，這四項能力越強，越接近通用人工智能，而大語言模型具備了這四項能力，且越來越強，為通用人工智能帶來了曙光。</span></p><p><span style="color:#000000">面對大模型產業化的挑戰，王海峯表示，類似芯片代工廠模式，可以採用「集約化生產，平台化應用」的模式，即具有算法、算力和數據綜合優勢的企業將模型生產的複雜過程封裝起來，通過低門檻、高效率的生產平台，為千行百業提供大模型服務。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 02:47:51 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265847</guid>
            <link>https://www.oschina.net/news/265847</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME 獲 100 萬歐元投資]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">GNOME 基金會<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffoundation.gnome.org%2F2023%2F11%2F09%2Fgnome-recognized-as-public-interest-infrastructure%2F" target="_blank">宣佈</a></u>收到了來自「<span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund</span>」的 100 萬歐元投資，並表示這筆資金將用於實現平台現代化、改進工具和可訪問性，並支持符合公共利益的功能。</p><p>具體包括：</p><ul><li>改進當前的可訪問性狀態</li><li>設計新的輔助功能堆棧並製作原型</li><li>支持單獨加密 user 主目錄</li><li>實現現代化的秘密存儲</li><li>擴大硬件支持的範圍和質量</li><li>為質量保證和開發者體驗投入資源</li><li>擴展和拓寬 freedesktop API</li><li>整合和改進平台組件</li></ul><p><span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund 是</span>德國政府資助的一項計劃，由 Adriana Groh 和 Fiona Krakenbürg 運營，他們在國家和國際層面擁有「多年推廣開源技術的經驗」。目標是支持「開源數字基礎設施的開發、改進和維護」，這與 GNOME 項目的協同作用是顯而易見的。</p><p>他們在官方網站寫道：「.....開源生態雖然非常成功，但也越來越脆弱。因為使用開源軟件的人永遠比為該軟件做出貢獻的人多。現在是投資數字共享、志願者社區和開源來建設我們希望看到的數字世界的時候了。」</p><p><span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund 投資過的項目</span>包括 curl、Fortran、WireGuard、OpenSSH、Yocto，以及與 OpenJS 基金會合作「改進 Javascript 生態基礎設施和安全性」。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 02:34:19 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265839/gnome-sovereign-tech-fund</guid>
            <link>https://www.oschina.net/news/265839/gnome-sovereign-tech-fund</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[正在被代碼折磨到深夜的你，何不請 AI 幫幫你]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在生成式 AI 工具規模化應用仍被質疑和觀望的時候，由其生成的內容、視覺、代碼程序已經高速湧入大眾視野。AI 技術一日千里，擁抱 AI 開發工具或將成為向未來工程師的進化的必經之路。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/204756_bv5c_2720166.gif" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="text-align:center"><strong>「半天時間就能梳理 20000 行代碼」</strong></p><p>大星是某電商業務的後端核心研發，入行 3 年，成長很快，已經是項目 owner 獨當一面。但是大星也自有煩惱，電商促銷活動頻繁，且因為需求方複雜，經常需要處理突發狀況，還有一個「重災區」就是頻繁修復歷史技術債，不斷打補丁，使得系統的可維護性越來越差，重構迫在眉睫。</p><p>今年提前兩個月，雙十一大促進入籌備期。大星發現，如果不盡快重構系統，不僅很難繼續補丁式的開發新活動，甚至穩定性也存在風險。但是重構系統又與新的開發工作存在矛盾，人力有限，極容易顧此失彼。這時，大星想到了近期在試用的百度 Comate 研發插件，在理解老代碼、生成註釋方面都有不錯的表現，於是大星和小夥伴，迅速梳理了遺留的老代碼，制定了新優惠邏輯的實現融合方案，快速融合了新舊優惠邏輯，2 名研發只用了半天時間完成了 20000 多行代碼的梳理。</p><p>後來，大星多次分享了這次經歷：「這不僅等於增派了研發人力，更重要的是百度 Comate 理解更準確，註釋生成更規範。這次成功救場，啓發我作為工程師，更應該超前使用新工具，這樣才能跑得更快。」</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/204929_EoB7_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><strong>「不被語言所困，我就是研發 E 人！」</strong></p><p>去年畢業的小韓，作為優秀校招生入職大廠，工作一年有餘，由於好學愛折騰，已經接了不少項目。最近，小韓接手了一個新項目，該項目的實現語言是 Go，但是小韓不太擅長，另外，由於對項目的已有代碼不熟悉，讓他接手項目和快速修改其中的內容有了不少阻礙。</p><p>他想到平時使用的百度 Comate，利用其代碼解釋和使用其它語言實現的能力，快速理解了項目已有的代碼，高質量實現了快速接手任務，得到了團隊內其他成員的一致好評。</p><p>「我屬於程序員 E 人，平時喜歡多交流，百度 Comate 就是小夥伴推薦的，我發現，面對短板，找到方法其實就能快速彎道超車，這對研發新人很重要。」小韓直言不諱。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205015_NLab_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><strong>「用好工具，重組生產要素，提升研發生產力」</strong></p><p>作為研發團隊管理者，大剛最近痛失兩名 QA，新的 QA 遲遲招不到，團隊的 bug 數直線上升，質量危機迫在眉睫，將近年底，眼看質量指標達成就要灰飛煙滅。多年的經驗告訴大剛要沉下心來，仔細分析找到解法，在角色、人力、環節、工時、質量幾個維度上設計出最優解。</p><p>通過分析，大剛逐步梳理出了解法：既然人力缺失，是否儘可能利用自動化能力來減少人工的投入，如在每次迴歸測試中釋放 QA 的人力。再推導一步：如果對現有代碼批量生成單元測試，對於緩解 QA 人力緊缺也將有非常大的幫助。</p><p>最後，大剛決定使用百度 Comate 插件來解決這些問題。大剛和團隊研發成員一起，針對遺留代碼和新增的代碼，使用百度 Comate 的單測生成能力，快速的生成了滿足業務要求的單元測試代碼，通過自動化的方式實現迴歸驗證，保證代碼在變更後的運行結果符合預期情況，將測試環節左移，更早發現問題，減少後續環節的人力投入。</p><p>大剛團隊的案例，是通過百度 Comate 生成了主要流程的單元測試用例，雖然在研發過程中看上去對單個功能的開發時間加長了，但是方案保證了核心流程的正確性，提高驗證效率，最大化的緩解了人員緊缺的情況。</p><p>後來大剛在覆盤中，這樣總結：「研發是一個系統性工程，不僅有人人協同，還有人機協同，用好工具提升人機協同能力，重組生產要素，用技術的力量提升研發生產力。」</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205101_OWD9_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205125_R8fr_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><h3 style="text-align:center"><strong>⭐ 百度 Comate SaaS 有哪些優勢？</strong></h3><p>依託文心大模型，百度 Comate SaaS 支持單行推薦、多行推薦、多條推薦、代碼知識的問答、代碼生成、註釋生成、註釋文檔生成、代碼解釋、生成行間註釋、函數拆分、優化和重構等一系列編碼相關的能力，在編程現場實現幫你想、幫你寫、幫你改代碼的效果。</p><p>此外，經過測試，百度 Comate 在易用性、速度、安全性、使用體驗上具有明顯優勢。功能完備，開箱即用，後續支持私域數據索引，推理結果更精準。在使用體驗上，支持全中文交互，交互速度更快，體驗更好；領先的安全機制保證代碼數據的安全，同時成本和部署方式上也更靈活、更具高性價比。</p><h3 style="text-align:center"><strong>🌈 限時福利！</strong></h3><p><span style="color:#2980b9"><strong>福利一：限時免費試用</strong></span>（活動時間：即日起- 11 月 20 日）</p><ul><li><p>掃描或長按下圖二維碼，即裝即用，<span style="color:#c0392b"><strong>限時領取免費試用 1 個月！</strong></span></p></li><li><p>邀請其他人註冊，<span style="color:#c0392b"><strong>每分享 1 人註冊成功，即可獲得+1 個月免費試用期，總計最高獲得 6 個月免費試用</strong>。</span></p></li></ul><p><span style="color:#2980b9"><strong>福利二：限時特價</strong></span>（活動時間：即日起- 11 月 20 日）</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205713_POpJ_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><span style="color:#c0392b"><strong>以上福利掃碼立即獲得！</strong></span></p><p>下載下面圖片➡️轉發小夥伴，成功推薦其他新用户，即可延長免費試用時間，最高得 6 個月免費試用～</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205507_xM4u_2720166.jpg" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 12:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265796</guid>
            <link>https://www.oschina.net/news/265796</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Servo 獲 NLnet 資助，開發 HTML <table> 支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Servo 是使用 Rust 開發的實驗性瀏覽器引擎，最初由 Mozilla 發起，目前由 Linux Foundation Europe&nbsp;與來自 Igalia 和其他組織的貢獻者共同開發。與其他瀏覽器引擎相比，Servo 在內存安全性、速度和併發性方面具有優勢。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><span style="background-color:#ffffff">Servo 的最新消息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fservo.org%2Fblog%2F2023%2F11%2F06%2Fnlgrant-announcement%2F" target="_blank">宣佈</a>，他們在今年 7 月份收到了來自 NLnet 基金會的資助，但並未透露具體數額。項目團隊表示，打算利用這筆資金對&nbsp;Servo&nbsp;</span></span><span style="background-color:#ffffff; color:#121212">的多個領域進行改進。主要重點在於：</span></p><ul><li><strong><span style="background-color:#ffffff; color:#121212">完成 Servo 中的 float 支持</span></strong></li></ul><p><span style="color:#000000">自 2023 年中期以來，Servo 團隊一直在致力於 Servo 中的 floats&nbsp;支持，也取得了一些進展。但他們表示，在 Servo 能夠實現完全兼容的 CSS floats&nbsp;之前，仍有一些問題需要解決。</span></p><p><span style="color:#000000">其目標是使<code>/css/CSS2/floats/</code>&nbsp;和<code>/css/CSS2/floats-clear/</code>的平均通過率超過 80%。上週的測試結果如下：</span></p><p><img height="251" src="https://oscimg.oschina.net/oscnet/up-564a17db0733b5b2eefc783c368e79fc50f.png" width="500" referrerpolicy="no-referrer"></p><p><img height="239" src="https://oscimg.oschina.net/oscnet/up-d117d3239a7ac67e6f87d96586abbba2a05.png" width="500" referrerpolicy="no-referrer"></p><ul><li><strong><span style="background-color:#ffffff; color:#121212">支持更多語言的內聯佈局。</span></strong></li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left">Servo 的佈局引擎缺乏渲染不使用拉丁字母的語言的關鍵功能，包括正確的字體選擇、對從右到左腳本的支持以及邏輯屬性。項目團隊的目標是改進 Servo 對顯示更廣泛內容的支持。</p><ul><li><strong><span style="background-color:#ffffff; color:#121212">以及添加初始「table」支持</span></strong></li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"><span style="color:#000000"><span style="background-color:#ffffff">HTML tables 尚未在 Servo 中實現，從而導致許多網頁佈局的不正確。在此範圍內，項目團隊的主要重點是在 Servo 中實現對該功能的初步支持，重點是初步滿足維基百科上 HTML tables 的需求。</span></span></p><hr><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:left"><span style="color:#000000">相關閲讀：</span></p><ul><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/227154/servo-2023-roadmap" target="news">重啓所有常規活動，瀏覽器引擎 Servo 發佈 2023 年路線圖</a></p></li><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/258440/servo-new-browser-ui" target="_blank">Rust 瀏覽器引擎 Servo 啓用新的默認 UI</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 10:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265765/servo-table-support</guid>
            <link>https://www.oschina.net/news/265765/servo-table-support</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟計劃為 Windows 10 提供 AI 助手 Copilot]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fwindows-10%2Fexclusive-microsoft-plans-to-bring-its-ai-copilot-to-1-billion-windows-10-users" target="_blank">根據 Windows Central 的報道</a></u>，微軟計劃將 Copilot 引入 Windows 10。該公司做出這一決定的主要原因是希望為 Copilot 增加更多用户。</p><p>Windows 11 最近發佈的重大更新 v23H2 包含了 AI 助手 Copilot，它直接添加到了桌面的工具欄上。但 Windows 11 的用户數目前還遠不及上一代的 Windows 10，而微軟致力於讓每個用户都能使用 Copilot，它正計劃向有 10 億用户的 Windows 10 提供 Copilot。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7b7b3e6ab4e1286eb6e8ecd2789040a2a53.png" referrerpolicy="no-referrer"></p><p>Windows 10 的 Copilot 和 Windows 11 基本一致，Copilot 按鈕放置在工具欄上，點擊該按鈕會顯示一個可用於對話的側邊欄。</p><p>報道還指出，Windows 10 和 Windows 11 的 Copilot 體驗將是相同的，包括插件的兼容性。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265760</guid>
            <link>https://www.oschina.net/news/265760</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[reverse_sql —— MySQL 數據閃回恢復工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">reverse_sql 是一個用於解析和轉換 MySQL 二進制日誌（binlog）的工具。它可以將二進制日誌文件中記錄的數據庫更改操作（如插入、更新、刪除）轉換為反向的 SQL 語句，以便進行數據恢復。其運行模式需二進制日誌設置為 ROW 格式。</p><p style="color:#1f2328; text-align:start">該工具的主要功能和特點包括：</p><p style="color:#1f2328; text-align:start">1、解析二進制日誌：reverse_sql 能夠解析 MySQL 的二進制日誌文件，並還原出其中的 SQL 語句。</p><p style="color:#1f2328; text-align:start">2、生成可讀的 SQL：生成原始 SQL 和反向 SQL。</p><p style="color:#1f2328; text-align:start">3、支持過濾和篩選：可以根據時間範圍、表、DML 操作等條件來過濾出具體的誤操作 SQL 語句。</p><p style="color:#1f2328; text-align:start">4、支持多線程併發解析 binlog 事件。</p><h3 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#%E4%BD%BF%E7%94%A8">使用</a></h3><div style="text-align:start"><pre><code>shell&gt; chmod 755 reverse_sql
shell&gt; ./reverse_sql --help
usage: reverse_sql [-h] [-ot ONLY_TABLES [ONLY_TABLES ...]] [-op ONLY_OPERATION] -H MYSQL_HOST
                   -P MYSQL_PORT -u MYSQL_USER -p MYSQL_PASSWD -d MYSQL_DATABASE
                   [-c MYSQL_CHARSET] --binlog-file BINLOG_FILE [--binlog-pos BINLOG_POS]
                   --start-time ST --end-time ET [--max-workers MAX_WORKERS] [--print]

Binlog 數據恢復，生成反向 SQL 語句。

options:
  -h, --help            show this help message and exit
  -ot ONLY_TABLES [ONLY_TABLES ...], --only-tables ONLY_TABLES [ONLY_TABLES ...]
                        設置要恢復的表，多張表用,逗號分隔
  -op ONLY_OPERATION, --only-operation ONLY_OPERATION
                        設置誤操作時的命令（insert/update/delete）
  -H MYSQL_HOST, --mysql-host MYSQL_HOST
                        MySQL 主機名
  -P MYSQL_PORT, --mysql-port MYSQL_PORT
                        MySQL 端口號
  -u MYSQL_USER, --mysql-user MYSQL_USER
                        MySQL 用户名
  -p MYSQL_PASSWD, --mysql-passwd MYSQL_PASSWD
                        MySQL 密碼
  -d MYSQL_DATABASE, --mysql-database MYSQL_DATABASE
                        MySQL 數據庫名
  -c MYSQL_CHARSET, --mysql-charset MYSQL_CHARSET
                        MySQL 字符集，默認 utf8
  --binlog-file BINLOG_FILE
                        Binlog 文件
  --binlog-pos BINLOG_POS
                        Binlog 位置，默認 4
  --start-time ST       起始時間
  --end-time ET         結束時間
  --max-workers MAX_WORKERS
                        線程數，默認 4（併發越高，鎖的開銷就越大，適當調整併發數）
  --print               將解析後的 SQL 輸出到終端
  --replace             將 update 轉換為 replace 操作

Example usage:
    shell&gt; ./reverse_sql -ot table1 -op delete -H 192.168.198.239 -P 3336 -u admin -p hechunyang -d hcy \
            --binlog-file mysql-bin.000124 --start-time "2023-07-06 10:00:00" --end-time "2023-07-06 22:00:00" 
</code></pre><div>&nbsp;</div></div><p><a href="https://github.com/hcymysql/reverse_sql#%E5%BD%93%E5%87%BA%E7%8E%B0%E8%AF%AF%E6%93%8D%E4%BD%9C%E6%97%B6%E5%8F%AA%E9%9C%80%E6%8C%87%E5%AE%9A%E8%AF%AF%E6%93%8D%E4%BD%9C%E7%9A%84%E6%97%B6%E9%97%B4%E6%AE%B5%E5%85%B6%E5%AF%B9%E5%BA%94%E7%9A%84binlog%E6%96%87%E4%BB%B6%E9%80%9A%E5%B8%B8%E4%BD%A0%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87show-master-status%E5%BE%97%E5%88%B0%E5%BD%93%E5%89%8D%E7%9A%84binlog%E6%96%87%E4%BB%B6%E5%90%8D%E4%BB%A5%E5%8F%8A%E5%88%9A%E6%89%8D%E8%AF%AF%E6%93%8D%E4%BD%9C%E7%9A%84%E8%A1%A8%E5%92%8C%E5%85%B7%E4%BD%93%E7%9A%84dml%E5%91%BD%E4%BB%A4%E6%AF%94%E5%A6%82update%E6%88%96%E8%80%85delete">當出現誤操作時，只需指定誤操作的時間段，其對應的 binlog 文件（通常你可以通過 show master status 得到當前的 binlog 文件名）以及剛才誤操作的表，和具體的 DML 命令，比如 update 或者 delete。</a></p><p style="color:#1f2328; text-align:start">工具運行時，首先會進行 MySQL 的環境檢測（if binlog_format != 'ROW' and binlog_row_image != 'FULL'），如果不同時滿足這兩個條件，程序直接退出。</p><p style="color:#1f2328; text-align:start">工具運行後，會在當前目錄下生成一個{db}_{table}_recover.sql 文件，保存着原生 SQL（原生 SQL 會加註釋） 和，反向 SQL，如果想將結果輸出到前台終端，可以指定--print 選項。</p><p style="color:#1f2328; text-align:start">如果你想把 update 操作轉換為 replace，指定--replace 選項即可，同時會在當前目錄下生成一個{db}_{table}_recover_replace.sql 文件。</p><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/251670057-b06528a6-fbff-4e00-8adf-0cba19737d66.png" target="_blank"><img alt="圖片" src="https://static.oschina.net/uploads/img/202311/08114920_eBdc.png" referrerpolicy="no-referrer"></a></p><p style="color:#1f2328; text-align:start">MySQL 最小化用户權限：</p><div style="text-align:start"><pre><code>&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO `yourname`@`%`;

&gt; GRANT SELECT ON `test`.* TO `yourname`@`%`;
</code></pre></div><h3 style="text-align:start"><br><a href="https://github.com/hcymysql/reverse_sql#%E6%81%A2%E5%A4%8D">恢復</a></h3><p style="color:#1f2328; text-align:start">在{db}_{table}_recover.sql 文件中找到你剛才誤操作的 DML 語句，然後在 MySQL 數據庫中執行逆向工程後的 SQL 以恢復數據。</p><p style="color:#1f2328; text-align:start">如果{db}_{table}_recover.sql 文件的內容過多，也可以通過 awk 命令進行分割，以便更容易進行排查。</p><div style="text-align:start"><pre><code>shell&gt; awk '/^-- SQL 執行時間/{filename = "output" ++count ".sql"; print &gt; filename; next} {print &gt; filename}' test_t1_recover.sql
</code></pre><div>&nbsp;</div></div><p style="color:#1f2328; text-align:start">不支持 drop 和 truncate 操作，因為這兩個操作屬於物理性刪除，需要通過歷史備份進行恢復。</p><h4 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#%E6%B3%A8reverse_sql-%E6%94%AF%E6%8C%81mysql-5780-%E5%92%8C-mariadb%E9%80%82%E7%94%A8%E4%BA%8Ecentos-7%E7%B3%BB%E7%BB%9F">注：reverse_sql 支持 MySQL 5.7/8.0 和 MariaDB，適用於 CentOS 7 系統。</a></h4><hr><h3 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#docker%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8">Docker 部署使用</a></h3><p style="color:#1f2328; text-align:start">shell&gt; wget<span>&nbsp;</span><a href="https://github.com/hcymysql/reverse_sql/archive/refs/heads/reverse_sql_progress.zip">https://github.com/hcymysql/reverse_sql/archive/refs/heads/reverse_sql_progress.zip</a></p><p style="color:#1f2328; text-align:start">shell&gt; unzip reverse_sql_progress.zip</p><p style="color:#1f2328; text-align:start">shell&gt; cd reverse_sql_progress</p><p style="color:#1f2328; text-align:start">shell&gt; vim Dockerfile</p><div style="text-align:start"><pre><code>FROM centos:7

COPY reverse_sql /root/
RUN chmod 755 /root/reverse_sql
</code></pre></div><p style="color:#1f2328; text-align:start">shell&gt; docker build -t reverse_sql .</p><p style="color:#1f2328; text-align:start">shell&gt; docker run -itd --name reverse_sql reverse_sql /bin/bash</p><p style="color:#1f2328; text-align:start">shell&gt; docker exec -it reverse_sql /root/reverse_sql --help</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/reverse-sql</guid>
            <link>https://www.oschina.net/p/reverse-sql</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | Android 發熱監控實踐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一、背景</h1><p>相信移動端高度普及的現在，大家或多或少都會存在電量焦慮，擁有過手機發熱發燙的糟糕體驗。而發熱問題是一個長時間、多場景的指標存在，且涉及到端側應用層、手機 ROM 廠商系統、外界環境等多方面的影響。如何有效衡量發熱場景、定位發熱現場、以及歸因發熱問題成為了端側應用層發熱監控的面前的三座大山。本文通過得物 Android 端側現有的一些監控實踐，不深入功耗計算場景無法自拔，優先聚焦於發熱場景本身，希望能給大家一些參考。</p><h1>二、發熱定義</h1><p>温度是最直觀能反映發熱問題的指標，當前 Android 側，我們以體感温度 37° 以上作為分界線，向上每 3° 作為一個發熱温度區間，區間細分上限温度 49° ，即劃分出 37-40，40-43，43-46，46-49，49+ 五個等級。</p><p>以手機温度、CPU 使用率作為第一、第二要素來判斷用户是否發熱的同時，獲取其他參數來支撐發熱現場情況。</p><p><strong>具體指標如下:</strong></p><p>手機温度 CPU 使用率、GPU 使用率；</p><p>線程堆棧；</p><p>系統服務使用頻次；</p><p>設備前後台、亮滅屏時長；</p><p>電量、充電情況；</p><p>熱緩解發熱等級；</p><p>系統機型、版本；</p><p>....</p><h1>三、指標獲取</h1><h2>温度</h2><ul><li><strong>電池温度</strong></li></ul><p>系統 BatteryManger 已經提供了一系列自帶的接口和粘性廣播獲取電池信息。</p><p>BatteryManager.EXTRA_TEMPERATURE 廣播，獲取的温度值是攝氏度為單位的 10 倍數值。</p><pre><code>//獲取電池温度 BatteryManager.EXTRA_TEMPERATURE，華氏温度需要除以 10
fun getBatteryTempImmediately(context: Context): Float {
    return try {
        val batIntent = getBatteryStickyIntent(context) ?: return 0f
        batIntent.getIntExtra(BatteryManager.EXTRA_TEMPERATURE, 0) / 10F
    } catch (e: Exception) {
        0f
    }
}

private fun getBatteryStickyIntent(context: Context): Intent? {
    return try {
        context.registerReceiver(null, IntentFilter(Intent.ACTION_BATTERY_CHANGED))
    } catch (e: Exception) {
        null
    }
}
</code></pre><p>BatteryManager 除支持電池温度的系統廣播外，也包含電量、充電狀態等額外信息的讀取，均定義在其源碼中。</p><pre><code>以下羅列幾個值得關注的:
//BATTERY_PROPERTY_CHARGE_COUNTER 剩餘電池容量，單位為微安時
//BATTERY_PROPERTY_CURRENT_NOW 瞬時電池電流，單位為微安
//BATTERY_PROPERTY_CURRENT_AVERAGE 平均電池電流，單位為微安
//BATTERY_PROPERTY_CAPACITY 剩餘電池容量，顯示為整數百分比
//BATTERY_PROPERTY_ENERGY_COUNTER 剩餘能量，單位為納瓦時
// EXTRA_BATTERY_LOW  是否認為電量低
// EXTRA_HEALTH  電量健康常量的常數
// EXTRA_LEVEL  電量值
// EXTRA_VOLTAGE 電壓
// ACTION_CHARGING   進入充電狀態
// ACTION_DISCHARGING  進入放電狀態
</code></pre><ul><li><strong>傳感器温度</strong></li></ul><p>Android 是基於 Linux 基礎上修改的開源操作系統，同樣的在手機系統 sys/class/thermal/ 目錄下存在以 thermal_zoneX 為代表各傳感器的温度分區，以及 cooling_deviceX 為代表風扇或散熱器等冷卻設備。</p><p>以一加 9 為例，共存在 105 個温度傳感器 or 温度分區，以及 48 個冷卻設備。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b5cf3938151953ff43b21f0a681ce4c9b65.jpg" alt="" referrerpolicy="no-referrer"></p><p>每個温度分區下記錄下具體的參數類型，我們重點關注的是 type 文件和&nbsp;temp 文件，分別記錄了該傳感器設備的名稱，以及當前的傳感器温度。以 thermal_zone29 為例，代表了 CPU 第一核心的，第五處理單元的温度值為 33.2 攝氏度。而對單一設備來説分區對應的名稱是固定的，從而我們可以通過讀取 thermal_zone 文件的方式來記錄當前第一個 type 文件名稱包含&nbsp;CPU&nbsp;的傳感器作為&nbsp;CPU&nbsp;温度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f2279774ca9ce74031e6897a9db4a7ea9dc.jpg" alt="" referrerpolicy="no-referrer"></p><ul><li><strong>殼温</strong></li></ul><p>Android 10 Google 官方推出了熱緩解框架，通過 HAL2.0 框架監聽底層硬件傳感器（主要為 USB 傳感器、Skin 傳感器）提供 USB、殼温的熱信號等級變更監聽， 系統 PowerManager 源碼提供了對應發熱等級變更的回調和發熱等級的獲取，共 7 個等級，提供給開發者主動或被動獲取。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1110179d6d33bc1f87ed57c99e6797dc931.jpg" alt="" referrerpolicy="no-referrer"></p><pre><code>final PowerManager powerManager = (PowerManager) mContext.getSystemService(Context.POWER_SERVICE);
powerManager.addThermalStatusListener(new PowerManager.OnThermalStatusChangedListener() {
    @Override
    public void onThermalStatusChanged(int status) {
       //返回對應的熱狀態
    }
});
</code></pre><p>但對於發熱等級來説，殼温無疑是最為能夠反應手機的發熱情況的。可以看到 Android 系統的 API 實際上是提供了 AIDL 接口，可以直接註冊 Thermal 變更事件的監聽，獲取到 Temperature 對象。但由於標識了 Hide API 。常規應用層是無法獲取到的，在考慮好 Android 版本兼容性前提下，通過反射代理 ThermalManagerService 方式進行讀取。</p><p><img src="https://oscimg.oschina.net/oscnet/up-50f7b8b0252859eb185129ba23e59b367cb.jpg" alt="" referrerpolicy="no-referrer"></p><p>但事與願違，國內廠商並沒有完全適配官方熱緩解框架，熱狀態回調時常不夠準確，而是需要單獨接入每個廠商的熱緩解 SDK 去直接獲取到殼温，具體 API 則以各應用廠商的內部接入文檔為準。</p><h2>CPU 使用率</h2><p>CPU 使用率的採集通過讀取解析 Proc stat 文件的方式進行計算。</p><p>在系統 proc/[pid]/stat&nbsp; 和&nbsp; /proc/[pid]/task/[tid]/stat &nbsp;分別記錄了對應進程 ID、進程 ID 下的線程 ID 的 CPU 信息。具體的字段描述在此不進行贅述，詳見：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fman7.org%2Flinux%2Fman-pages%2Fman5%2Fprocfs.5.html" target="_blank">https://man7.org/linux/man-pages/man5/procfs.5.html</a> 。</p><p><img src="https://oscimg.oschina.net/oscnet/up-49d2512961ec5d6361ee15326af3c2c5885.jpg" alt="" referrerpolicy="no-referrer"></p><p>我們重點關注 14.15 位的信息，分別代表進程/線程的用户態運行的時間和內核態運行的時間。 <img src="https://oscimg.oschina.net/oscnet/up-30cbd118f0cbd9df3ddf67043cc22b050ea.jpg" alt="" referrerpolicy="no-referrer"></p><p>通過解析當前進程的 Stat 文件，以及 Task 目錄下所有線程的 Stat 文件，在兩次採樣週期內 (當前設置為 1s) 的 utime+stime 之和的差值/採樣間隔，即可認為是進線程的 CPU 的使用率。即，進線程 CPU 使用率 = ((utime+stime)-(lastutime+laststime)) / period</p><h2>GPU 使用率</h2><p>高通芯片的設備，我們可以參考&nbsp;/sys/class/kgsl/kgsl-3d0/gpubusy&nbsp;下文件內容，參考高通官網的説明。</p><p>GPU 的使用率 = (下圖) 數值 1 / 數值 2 * 100，經過驗證與 SnapDragonProfiler 信息採集獲取的數值基本一致。 <img src="https://oscimg.oschina.net/oscnet/up-0be7cfc4a8df3b97c0a5600c5512c4e415e.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-9496bbec4a96755eb7d59997c3ac6fd12bc.jpg" alt="" referrerpolicy="no-referrer"></p><p>聯發科芯片的設備，我們可以直接通過讀取&nbsp;<strong>/d/ged/hal/gpu_utilization</strong> 下的使用率數值。</p><p>同樣的通過指定週期 (每秒 1 次) 的採樣間隔，即可獲取到每秒的當前 GPU 使用率。</p><h2>系統服務使用</h2><p>Android 系統服務包括 Warelock、Alarm、Sensor、Wifi、Net、Location、Bluetooth、Camera 等。</p><p>與市面上常規的監控手段差異不大，都是通過系統 Hook ServiceManager 的方式，監聽系統服務的 Binder 通信，匹配對應的調用方法名，做對應中間層監控的回調記錄處理。</p><p>熟悉 Android 開發的同學知道 Android 的 Zygote 進程是 Android 系統啓動時的第一個進程。在 Zygote Fork 進程中會孵化出系統服務相關的進程 SystemServer，在其核心的 RUN 方法中，會註冊啓動大量的系統服務，並通過 ServiceManager 進行管理。 <img src="https://oscimg.oschina.net/oscnet/up-f43504f6a7801c8edffd8a299338158a10c.jpg" alt="" referrerpolicy="no-referrer"></p><p>故我們可以通過反射代理 ServiceManager 的方式，以 LocationManager 為例進行監聽，攔截對應 LocationManager 內對應的方法，記錄我們期望獲取的數據。</p><pre><code>// 獲取 ServiceManager 的 Class 對象
Class&lt;?&gt; serviceManagerClass = Class.forName("android.os.ServiceManager");
// 獲取 getService 方法
Method getServiceMethod = serviceManagerClass.getDeclaredMethod("getService", String.class);
// 通過反射調用 getService 方法獲取原始的 IBinder 對象
IBinder originalBinder = (IBinder) getServiceMethod.invoke(null, "location");
// 創建一個代理對象 Proxy
Class&lt;?&gt; iLocationManagerStubClass = Class.forName("android.location.ILocationManager$Stub");
Method asInterfaceMethod = iLocationManagerStubClass.getDeclaredMethod("asInterface", IBinder.class);
final Object originalLocationManager = asInterfaceMethod.invoke(null, originalBinder);
Object proxyLocationManager = Proxy.newProxyInstance(context.getClassLoader(),
        new Class[]{Class.forName("android.location.ILocationManager")},
        new InvocationHandler() {
            @Override
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                // 在這裏進行方法的攔截和處理
                Log.d("LocationManagerProxy", "Intercepted method: " + method.getName());
                // 執行原始的方法
                return method.invoke(originalLocationManager, args);
            }
        });
// 替換原始的 IBinder 對象
getServiceMethod.invoke(null, "location", proxyLocationManager);
</code></pre><p>同理，我們獲取在固定採樣週期內，各系統服務對應，申請次數、計算間隔時長等進行記錄。</p><p>源碼&nbsp;Power_profile&nbsp;文件中定義了每個系統服務狀態下的電流量定義。</p><p>我們在需要記錄每個元器件在不同狀態的工作時間之後，通過以下計算方式，可以得出元器件的發熱貢獻排行，即：</p><p>元器件，電量消耗（發熱貢獻） &nbsp;~~ &nbsp;電流量 * 運行時長 * 電壓（一般為固定值，可忽略）</p><p><img src="https://oscimg.oschina.net/oscnet/up-95b4814576aef6a67210588b65b259c9abf.jpg" alt="" referrerpolicy="no-referrer"></p><h2>線程堆棧</h2><p>由於發熱問題是一個綜合性的問題，並不像 Crash 問題一樣，在發生現場我們就可以知道是哪個線程觸發的。如果將所有線程的堆棧都進行 Dump 記錄的話，得物當前運行時的子線程數量在 200+，全部進行存儲的話無疑是不合理的。問題就轉變為，如何較為準確的找到發熱代碼的線程堆棧？</p><p>上文説到，在計算 CPU 使用率的時讀取進程下所有線程的 Stat 文件，我們可以獲取到子線程的 CPU 使用率，對其使用率進行倒排，篩選超過閾值（當前定義 50% ) 或，佔用 Top N 的線程進行存儲。由於堆棧頻繁採集時機上是有性能折損的，故犧牲了部分的堆棧採樣精度和準確性，在温度、CPU 使用率等指標超過閾值定義後，才開始採集，指定下發時間的堆棧信息。</p><p>我們還要明確一個概念，線程 Stat 文件的文件名即為線程標識名，Thread.id 是指線程 ID。</p><p>其兩者並不等價，但 Native 方法中給我們提供了對應的方式去建立兩者的映射關係。</p><p>在 Art &nbsp;Thread.cc 方法中，將 Java 中的 Thread 對象轉換成 C++ 中的 Thread 對象，調用 ShortDump 打印線程的相關信息，我們通過字符串匹配到核心的 Tid= 的信息，即可獲取到線程的 Tid。 <img src="https://oscimg.oschina.net/oscnet/up-6e69839410035c1793072333c26c962790c.jpg" alt="" referrerpolicy="no-referrer"></p><p>核心代碼邏輯如下:</p><pre><code>//獲取隊列中最近一次 cpu 採樣的數據
 val threadCpuUsageData = cpuProfileStoreQueue.last().threadUsageDataList
       val hotStacks = mutableListOf&lt;HotStack&gt;()
        if (threadCpuUsageData != null) {
            val dataCount = if (threadCpuUsageData.size &lt;= TOP_THREAD_COUNT) {
                threadCpuUsageData.size
            } else {
                TOP_THREAD_COUNT
            }
            val traces: MutableMap&lt;Thread, Array&lt;StackTraceElement&gt;&gt; = Thread.getAllStackTraces()
            //定義 tid 和 thread 的映射關係 map
            val tidMap: MutableMap&lt;String, Thread&gt; = mutableMapOf()
            traces.keys.forEach { thread -&gt;
                //調用 native 方法獲取到 tid 信息
                val tidInfo = hotMonitorListener?.findTidInfoByThread(thread)
                tidInfo?.let {
                    findTidByTidInfo(tidInfo).let { tid -&gt;
                        if (tid.isNotEmpty()) {
                            tidMap[tid] = thread
                        }
                    }
                }
            }
            //採集 topN 的發熱堆棧
            for (index in 1..dataCount) {
                val singleThreadData = threadCpuUsageData[index - 1]
                val isMainThread = singleThreadData.pid == singleThreadData.tid
                val thread = tidMap[singleThreadData.tid.toString()]
                thread?.let { findThread -&gt;
                    traces[findThread]?.let { findStackTrace -&gt;
                        //獲取當前的線程堆棧
                        val sb = StringBuilder()
                        for (element in findStackTrace) {
                            sb.append(element.toString()).append("\n")
                        }
                        sb.append("\n")
                        if (findStackTrace.isNotEmpty()) {
                            //是否為主線程
                            //組裝 hotStack
                            val hotStack = HotStack(
                                //進程 id
                                singleThreadData.pid,
                                singleThreadData.tid,
                                singleThreadData.name,
                                singleThreadData.cpuUseRate,
                                sb.toString(),
                                thread.state
                                isMainThread
                            )
//                        Log.d("HotMonitor", sb.toString())
                            hotStacks.add(hotStack)
                        }
                    }
                }

            }
        }
</code></pre><h1>四、監控方案</h1><p>瞭解核心指標數據是如何獲取的前提下，其實監控方案的核心思路無非就是通過遠端 APM 配置中心下發的採樣閾值、採樣週期、各模塊數據開關等限定採樣配置，子線程 Handler 定時發消息，採集各個模塊的數據進行組裝，在合適的時機進行數據上報即可，具體的數據拆解、分析工作則由發熱平台進一步處理。</p><p><strong>模塊整體架構</strong><img src="https://oscimg.oschina.net/oscnet/up-b5030680856c30aab1b0a1b2d301fbbeea8.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>上報時機</strong><img src="https://oscimg.oschina.net/oscnet/up-0cbaca499275d7a3292d7a5990c26ced860.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>核心採集流程</strong><img src="https://oscimg.oschina.net/oscnet/up-81a16007734e761fbece449580c494a4ccb.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>線上線下區分</strong></p><p>由於所有子線程的 CPU 採集、堆棧採集實際上是會對性能有折損的，200+ 的線程的讀取耗時整體在 200ms 左右，採樣子線程的 CPU 使用率在 10%，考慮到線上用户體驗問題，並不能全量開啓高頻率採樣。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b83fd9a6c760d788fb151f04d854e8c40eb.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-2e9a9a66b142535b29d5dc9793467e73fdf.jpg" alt="" referrerpolicy="no-referrer"></p><p>故整體方案來説: 線下場景以重點側重發現、排查、治理全量問題，上報全量日誌，以 CPU、GPU 使用率為第一衡量指標；</p><p>線上場景以重點側重觀察整體發熱大盤趨勢、分析潛在問題場景，上報核心日誌，以電池温度為第一衡量指標。</p><p><strong>發熱平台</strong></p><p>在平台側同學的支持下，發熱現場數據經過平台側進行消費，將核心的發熱堆棧經過 Android 堆棧反混淆服務進行聚合，補齊充電狀態、主線程 CPU 使用率、問題類型、電池温度等基礎字段，平台側就具備發現、分析、解決的流程化監控推進的能力。</p><p>具體的堆棧信息 &amp; 發熱信息平台展示如下:</p><p><img src="https://oscimg.oschina.net/oscnet/up-3251d963a881ef9e7f09fcc6d73d9b2925d.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-04b122e8d11a65f06b2ed4f71062b718945.jpg" alt="" referrerpolicy="no-referrer"></p><p>由於電池温度、CPU 使用率是針對運行時發熱場景最直觀的指標，且我們一期重點關注發熱場景的治理，不針對元器件 Hook 等耗電場景進行持續深入分析，故當前得物側是以電池温度、CPU 使用率為第一第二指標 &nbsp;建立核心的發熱問題四象限，優先關注高温、高 CPU 的問題場景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5a65d936a2e2676307b5562a55eb4fca2e7.jpg" alt="" referrerpolicy="no-referrer"></p><p>在數據分析過程中，我們遇到了數據上的效率排查效率不夠高、問題精度不夠準的情況。</p><ul><li>如何定位是高温場景是發生在 App 內部，且在使用過程中明顯上升的？ 通過過濾從啓動開始即高温、後台切換回來即高温的場景，重點關注在 App 內部温度上升的場景。</li><li>線上的採樣後仍舊單日有 6w+ 數據的上報，我們如何篩選出更為核心的數據？當前的做法是定義了温度跨度的概念，優先看在 App 內部温度跨度較大的 Case。</li><li>線程存在調用 Wait 等方法阻塞的堆棧，消耗內核態的時間分配，但實際不消耗整體 CPU 的誤報數據。 補充了線程的運行狀態和 Proc 文件中記錄的 State，方便優先處理 RUNNABLE 線程的 CPU 高温高佔用問題。</li><li>手機温度上升作為漸進式的場景，如何實現温度上升場景下的頁面精確歸因？增加温度採樣頻率的同時，彙總 CPU 使用率和實時堆棧等瞬時數據作為數據支撐，但考慮到數據體量的情況，數據上報聚合裁剪方式仍在逐步探索更為合理的方式，力求在兩者之間找到一個平衡點。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-838ac3d056faa216013c5cf2b87b08cbf57.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-abcc4634539696d10682e28632c278d9415.jpg" alt="" referrerpolicy="no-referrer"></p><h1>五、收益</h1><p>Android 端側發熱監控自上線以來，背靠平台側的支撐，陸續發現了一些問題並聯合開發同學做了對應場景的治理優化工作，如：</p><p>耗時獨立線程任務，接入統一線程池調度管理；</p><p>動畫執行死循環監測修復；</p><p>高 IO 場景的文件讀寫策略優化；</p><p>高併發任務鎖粒度優化；</p><p>日誌庫等 Json 解析頻繁場景，採用效率更高的序列化方；</p><p>系統相機等系統功率過高的採集參數設備分級嘗試；</p><p>基於 Webgl 的遊戲場景，幀率降低和資源及時回收優化運行時內存；</p><p>....</p><p>這無疑給未來體驗工作的場景技術選型、技術實現沉澱了一些有價值的經驗，符合對 App 體驗追求極致的高標準、高要求。</p><h1>六、未來展望</h1><p>手機發熱作為漸進式的體驗場景，涉及手機硬件、系統服務、軟件使用、外界環境多方位因素。對於端側的排查上來説，當前優先級聚焦於應用層的不合理使用上，對於排查工具鏈路增強、問題業務歸因、低電量、低功耗模式下的動態策略降低、自動化診斷報告等環節仍舊有很多值得深入挖掘的點，例如：</p><p><strong>監控/工具增強</strong></p><ul><li>App 浮層分析工具 (CPU\GPU/頻率/温度/功耗等信息)</li><li>借鑑 BatteryHistorian、SnapdragonProfiler、Systrace 等工具，實現自研 TeslaLab 能力增強。</li></ul><p><strong>業務歸因</strong></p><ul><li>發熱堆棧自動分配</li><li>調用溯源歸因精細化</li></ul><p><strong>場景策略、降級</strong></p><ul><li>CPU 調頻、動態幀率、分辨率降級</li><li>端內低功耗模式探索</li></ul><p><strong>自動化診斷報告</strong></p><ul><li>單用户定向自動化分析輸出診斷報告</li></ul><p>‍</p><h1>七、總結</h1><p>在此也只是粗略介紹當前已經做的針對發熱治理的一些初步工作，以及對未來發熱功耗相關開展的思路，希望能讓 App 帶來更好的體驗，給用户帶來更對美好事物的嚮往的感受。</p><p>*文 / GavinX</p><p>本文屬得物技術原創，更多精彩文章請看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2F" target="_blank">得物技術官網</a></p><p>未經得物技術許可嚴禁轉載，否則依法追究法律責任！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10141675</guid>
            <link>https://my.oschina.net/u/5783135/blog/10141675</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英偉達或將推出針對中國區的最新改良版 AI 芯片]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chinastarmarket.cn%2Fdetail%2F1512299" target="_blank">據<span style="background-color:#ffffff">《科創板日報》</span>報道</a></u>，產業鏈人士稱英偉達現已開發出針對中國區的最新改良版 AI 芯片：HGX H20、L20 PCle 和 L2 PCle。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-edecf0f4b0f979b064fa454bfd31a0ec4e3.png" referrerpolicy="no-referrer"></p><p>知情人士稱，最新三款芯片是由 H100 改良而來，英偉達最快或將於本月 16 號之後公佈，國內廠商最快將在這幾天拿到產品。</p><p>NVIDIA H100 Tensor Core GPU&nbsp;採用全新 Hopper 架構，基於台積電 N4 工藝，集成了 800 億個晶體管。與上一代產品相比，可為多專家 (MoE) 模型提供高 9 倍的訓練速度。</p><p>它配備第四代 Tensor Core 和 Transformer 引擎（FP8 精度），還具有高度可擴展的 NVLink 互連技術（最多可連接達 256 個 H100 GPU，相較於上一代採用 HDR&nbsp;Quantum&nbsp;InfiniBand 網絡，帶寬高出 9 倍，帶寬速度為 900GB/s）等功能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-acc6975ca53f0be377caf78b3f05ea055f8.png" referrerpolicy="no-referrer"></p><p>記者向英偉達求證該消息的真實性，但截至發稿，英偉達方面暫無迴應。</p><hr><p>2023 年 10 月 17 日，CNBC 報道稱，美國商務部計劃在未來幾周內限制向中國出售更先進的人工智能芯片。高級政府官員表示，<strong>新政策將限制 NVIDIA A800 和 H800 芯片的出口</strong>。詳情：<em><u><a href="https://www.oschina.net/news/262251/us-bans-export-of-more-ai-chips-including-nvidia-h800-to-china">美國政府限制向中國出口 NVIDIA H800 GPU</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 07:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265728</guid>
            <link>https://www.oschina.net/news/265728</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美團招兵買馬，擬開發鴻蒙系統 App]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美團招聘官網近日更新了多個鴻蒙相關的社招開發崗位，為鴻蒙原生應用開發招兵買馬。主要開發美團鴻蒙 App、大眾點評鴻蒙 App。</span></p><p><span style="color:#000000">其中的一個「鴻蒙高級工程師（C++）」職位就是面向美團鴻蒙 App 研發團隊。根據介紹，具體的崗位職責為：</span></p><ol><li><span style="color:#000000">參與鴻蒙端動態化容器的架構設計，確保項目研發質量和代碼的可維護性；</span></li><li><span style="color:#000000">負責鴻蒙端動態化容器的模塊設計與實現，實現高性能、高質量的容器模塊；</span></li><li><span style="color:#000000">對項目中的技術難點和重點進行深入研究和總結，積累可複用的經驗。</span></li><li><span style="color:#000000">能夠主動解決和推動項目前鴻蒙端動態化容器技術領域的阻塞點和難點；</span></li><li><span style="color:#000000">結合美團的業務需求，探索行業前沿技術，規劃容器技術路線。</span></li></ol><p><span style="color:#000000">且滿足「熟悉 ArkTS 和鴻蒙上的主流開發框架（例如 ArkUI）；作為主要貢獻者參與過有影響力的開源產品的開發；瞭解 Web 開發，熟悉瀏覽器內核的運行機制；瞭解動態化容器原理，熟悉 Hybrid、React Native、Flutter 等前沿技術之一；樂於分享和溝通，活躍於 GitHub 和各大技術社區，或有自己的高質量原創博客」等條件的將優先考慮。</span></p><p><span style="color:#000000"><img alt="" height="267" src="https://oscimg.oschina.net/oscnet/up-ae63f8c42eec2e0095d1026cb5f531df31b.png" width="500" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 07:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265725</guid>
            <link>https://www.oschina.net/news/265725</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[vivo 公佈藍心大模型 BlueLM-7B 開源地址]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>vivo 已在&nbsp;Hugging Face 上正式開源藍心大模型 BlueLM-7B。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7b7b72160940bf13dc85103adc480ff135f.png" referrerpolicy="no-referrer"></p><p>地址：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fvivo-ai" target="_blank">https://huggingface.co/vivo-ai</a></u></p><p>BlueLM-7B 開源大模型包括&nbsp;<strong>7B 基礎模型和 7B 對話模型</strong>，vivo 還開源了支持&nbsp;32K&nbsp;的長文本基礎模型和對話模型。</p><p>據介紹，BlueLM 採用高質量語料庫進行訓練，<strong>規模達到了&nbsp;2.6 萬億&nbsp;的 token 數，該語料庫包含中文、英文以及少量日韓數據</strong>。其中 BlueLM-7B-Chat 在&nbsp;C-Eval&nbsp;和&nbsp;CMMLU&nbsp;上均取得領先結果。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-032d6f2119d13af32e2019c475fa5b87681.png" referrerpolicy="no-referrer"></p><p>BlueLM-7B-Base-32K 和 BlueLM-7B-Chat-32K 均支持&nbsp;32K&nbsp;長文本，在保持基礎能力相當情況下，能夠支持更長上下文理解。</p><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/264455" target="_blank">vivo 開源藍心大模型-7B：70 億參數、適閤中國開發者</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 06:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265715</guid>
            <link>https://www.oschina.net/news/265715</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 服務中斷近 2 小時，CEO 奧特曼道歉：流量遠超預期]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京時間 11 月 8 日晚 22 點左右，OpenAI 旗下 ChatGPT 以及相關 API 出現中斷故障，導致面向用户和開發者的服務近 2 小時無法正常使用。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/114753_pknp_2720166.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstatus.openai.com%2F" target="_blank">隨後 OpenAl 更新事故報告稱</a></u>，已確定了一個導致 API 和 ChatGPT 錯誤率高的問題，正在努力修復。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/114923_hRcd_2720166.png" referrerpolicy="no-referrer"></p><p>與此同時，OpenAI CEO 山姆・奧特曼<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1722315204242149788">公開致歉稱</a></u>，本週發佈的新功能遇到遠超預期的使用量。公司原計劃在週一為所有訂閲者啓用 GPTs 服務，但目前還無法實現。由於負載的原因，短期內可能會出現服務不穩定的情況，對此情況向用户道歉。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/1109/113902_kyvS_2720166.png" referrerpolicy="no-referrer"></p><hr><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/265330">OpenAI 開發者大會：GPT-4 Turbo、GPTs 商店、128k 上下文窗口、大降價</a></li><li><a href="https://www.oschina.net/news/265331/openai-custom-versions-chatgpt">OpenAI 推出用户自定義版 ChatGPT</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265693</guid>
            <link>https://www.oschina.net/news/265693</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘋果正在利用 LLM 徹底改造 Siri，將成為殺手級 AI 應用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>爆料者 Tech_Reve 發表推文<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTech_Reve%2Fstatus%2F1722418466647625999" target="_blank">表示</a></u>，蘋果公司正在使用大語言模型 (LLM) 將 Siri 徹底改造成「終極虛擬助理」，並準備將其開發為「最強大的殺手級 AI 應用」。</p><p>目前蘋果正在積極推進這項開發工作，首款產品預計將在 WWDC 2024 上亮相。改進後的 Siri 將成為 iPhone 16 及後續機型的標配功能。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/111614_rFyz_2720166.png" referrerpolicy="no-referrer"></p><p>Tech_Reve 還説道，蘋果和三星一樣<strong>，整體思路都是專注於在設備側運行，同時配合雲端實現相關 AI 服務</strong>，這是因為 AI 在本地運行響應時間更快、不需要網絡連接，且更具隱私性。</p><p>上個月<u><a href="https://www.oschina.net/news/263067">彭博社的報道</a></u>也提到了蘋果公司內部對如何部署生成式 AI 的爭論：<strong>完全在設備上運行、基於雲運行或介於兩者之間</strong>。</p><p><span style="background-color:#ffffff; color:#333333">部署在設備上會運行得更快，並有助於保護隱私，但通過雲部署大模型將允許更高級的操作。部署在設備端的策略也會讓蘋果更難更新其技術並適應快速變化的行業。考慮到這一點，該公司很可能採用組合方法：<strong>使用設備上的部署處理某些功能，使用雲來處理更高級的任務</strong>。</span></p><p>彭博社還提到，今年 7 月，蘋果公司構建了自己的大型語言模型，<a href="https://www.oschina.net/news/250184/apple-gpt"><strong>稱為 Ajax</strong></a>，並推出了一個名為 「Apple GPT」 的內部聊天機器人來測試其功能。下一步的關鍵是確定該技術是否能夠應對競爭對手，以及蘋果如何將其實際應用到產品中。</p><p>分別負責人工智能和軟件工程的高級副總裁 John Giannandrea 以及 Craig Federighi 正在帶頭開展這項工作，服務主管 Eddy Cue 也參與其中。目前，3 人計劃每年在該項目上花費約 10 億美元。</p><p>據介紹，John Giannandrea 主要負責全新 AI 系統的底層技術，他的團隊目前正在改進 Siri，這個更智能的 Siri 最早可能會在明年準備就緒。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265689</guid>
            <link>https://www.oschina.net/news/265689</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 工程師年薪中位數高達 92.5 萬美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">來自美國薪資跟蹤網站 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.levels.fyi%2Fcompanies%2Fopenai%2Fsalaries%2Fsoftware-engineer" target="_blank">Levels.fyi</a> 的數據顯示，OpenAI 軟件工程師的年薪中位數高達 92.5 萬美元，其中包括基本工資以及潛在的股票報酬和獎金。</span></p><p><span style="color:#000000">目前 OpenAI 薪酬最低的工程師底薪為 21 萬美元，擁有約 2 至 4 年的行業從業經驗。L5 軟件工程師（擁有 10 年以上工作經驗的軟件工程師）的底薪為 30 萬美元，另外還可以獲得 62.5 萬美元的股票薪酬。此外，該公司的一些高級軟件工程師的薪酬甚至更高，年薪最高達到 140 萬美元。</span></p><p><img height="139" src="https://oscimg.oschina.net/oscnet/up-540ee3f9087289680579b5a9f2e340b6bf7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenAI 提供的高薪不僅對公司本身，而且對整個行業都具有深遠影響。根據 Levels.fyi 的數據，以科技中心和人才庫著稱的舊金山，為 AI 軟件開發人員提供的薪酬中位數一般約為 30 萬美元。「通過提供近三倍的薪酬，OpenAI 為該地區的薪酬設定了新的基準，並表明其致力於吸引和留住頂尖 AI 人才的承諾。」</span></p><p><span style="color:#000000">OpenAI 的員工薪資由「基本工資」和「Profit Participation Units(PPU)」兩個部分組成。PPU 是 OpenAI 獨創的分潤機制，該公司以 PPU 的形式提供股票薪酬，讓員工分享公司的利潤。</span></p><p><img height="291" src="https://oscimg.oschina.net/oscnet/up-9f5f514ce43285fd98946d201453956b368.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">而 PPU 的價值取決於公司未來的表現或被收購時的估值。9 月份有消息稱，<span style="background-color:#ffffff">OpenAI&nbsp;</span><span style="background-color:#ffffff">正在與投資者討論股票出售事宜</span><span style="background-color:#ffffff">，其</span><span style="background-color:#ffffff">估值大概在 800 億至 900 億美元之間，約是今年早些時候水平的三倍。今年 4 月，OpenAI 曾從紅杉資本、Andreessen Horowitz、Thrive 和 K2 Global 等支持者那裏獲得了略高於 3 億美元的融資，估值為 290 億美元。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265688/openai-software-engineer-pay</guid>
            <link>https://www.oschina.net/news/265688/openai-software-engineer-pay</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[魅族為 Flyme 徵集中文名，入選者將獲贈「華小魅」手機組合包]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>魅族科技今日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2683843043%2FNrJHikCZG%3Fpagetype%3Dprofilefeed" target="_blank">發佈公告稱</a></u>，集魅友力量，<strong>為 Flyme 徵集中文 OS 名稱</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-75abc601083ca8c26ecda32cafc7d8aac84.png" referrerpolicy="no-referrer"></p><p>魅族在公告寫道：「再一次，華為、小米、魅族奔跑在了同一條道路上，一條由中國企業定義、引領的手機、汽車、AR 等多終端全場景生態融合發展的道路。」</p><p>在這樣一個奔湧的時代，<strong>Flyme 也需要擁有像鴻蒙、澎湃一樣響亮的中文名</strong>。和用户共創是魅族的傳統，魅族科技將 Flyme 的中文 OS 命名權交給魅友。</p><p>該公司將選取三個意向名稱，創作者可獲贈「華小魅」手機組合一份（<strong>包含華為 Mate 60 Pro、小米 14 Pro、魅族 20 PRO 各一部</strong>）。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 02:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265679</guid>
            <link>https://www.oschina.net/news/265679</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 11 原生支持 7z 和 .tar 壓縮文件格式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>推特用户 @PhantomOfEarth <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FPhantomOfEarth%2Fstatus%2F1722334216199766161" target="_blank">發現</a></u>，最新的 Windows 11 Canary 版本支持將文件壓縮為另外兩種存檔格式：.<strong>7z 和 .tar</strong>。雖然 RAR 格式仍然缺失，但至少不再侷限於 zip。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bac57f48d11859af0d2e31f42856329e753.png" referrerpolicy="no-referrer"></p><p>微軟沒有在第 25992 版的發佈説明中提及這一變更。此外，它已在默認情況下啓用，因此無需執行特殊命令即可讓 Windows 11 將文件打包為 7z 和 TAR 格式。將系統更新至版本 25992 後，選擇要存檔的文件，然後從右鍵菜單中選擇"壓縮至"即可實現。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/101016_c73D_2720166.png" referrerpolicy="no-referrer"></p><p>除了可以處理更多的歸檔類型，Windows 11 版本 25992 還提高了處理大型 ZIP 文件時的性能。發佈説明中提到了這一點：</p><blockquote><p>做了一些工作，應有助於明顯改善在文件資源管理器中打開大型 .zip 文件的性能。</p></blockquote><p>Windows 11 build 25992 中的其他更改包括 SMB 升級、已知問題修復和剪切工具中的 HDR 支持改進。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265668</guid>
            <link>https://www.oschina.net/news/265668</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[以瀏覽器為開端，海泰方圓聯合 openKylin 持續開展安全創新]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，北京海泰方圓科技股份有限公司（以下簡稱「海泰方圓」）簽署 openKylin 社區 CLA（Contributor License Agreement 貢獻者許可協議），正式加入 openKylin 開源社區</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-30204f1812a28ab7bf8a53b135c586e329b.png" width="829" referrerpolicy="no-referrer"></p><p><span>海泰方圓是一家以密碼全能力和可信數據管理為核心，全面服務網信大時代的領軍安全企業。公司擁有國家保密局頒發的多項甲級資質、軍工三證，並具備各類檔案、載體的數字化加工資質和能力。海泰方圓成立於 2003 年，作為一家密碼基因深厚的技術型企業，公司以「讓信息世界充滿信任」為使命，聚焦密碼、數據治理、數據安全、國密瀏覽器、移動安全、物聯及工控安全等多個領域，為黨政、金融和大型企事業等客户提供全方位的專業安全解決方案及服務，以雲化、智能化、平台化的密碼服務和保障，護航數字中國，建設網絡強國。</span></p><p style="text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-0bb93bbd9a72f5673030aaf3710c92897b7.png" width="940" referrerpolicy="no-referrer"></p><p><span>海泰方圓作為 openKylin（開放麒麟）社區共建夥伴，在加入社區後便積極開展雙方產品的適配認證工作，於近期<strong>正式完成 openKylin 開源操作系統 V1.0 與紅蓮花安全瀏覽器 V5.0 的適配測試工作，並上架應用商店</strong>。測試結果表明，<strong>紅蓮花瀏覽器在 openKylin 操作系統上運行穩定，使用流暢。</strong></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a6d035f42cfa9089f7d758b91dc0fc6016c.png" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888">適配證書</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-27a21c058492459d08169c4b606e5cbd3a8.png" width="1920" referrerpolicy="no-referrer"></span></p><p style="text-align:center"><span style="color:#888888">紅蓮花安全瀏覽器已上架 openKylin 應用商店</span></p><p><span>瀏覽器作為操作系統必不可少的基礎軟件和業務應用的承載容器，在 IT 環境中，發揮着舉足輕重的作用。海泰方圓紅蓮花安全瀏覽器，融入我國國產密碼算法和一系列安全功能，打造了更安全的架構，支持自主網絡信任體系。全面兼容龍芯（MIPS)、龍芯（LoongArch)、飛騰、兆芯、鯤鵬、海光、申威等國產處理器；全面兼容麒麟操作系統；全面兼容金山 WPS、數科、書生、點聚等電子公文、電子簽章、電子文檔、中間件以及數據庫等基礎軟硬件產品。</span></p><p><span>未來，海泰方圓將持續與 openKylin 社區開展深入合作，共同開展面向安全和密碼領域的合作，共建桌面操作系統根社區創新技術生態。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 01:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265665</guid>
            <link>https://www.oschina.net/news/265665</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[目標智能體社會，MetaGPT 攜手 Jürgen Schmidhuber 團隊]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6a26cdfc68540cd8ce50fd07f1d06aa~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=530&amp;s=59164&amp;e=webp&amp;b=fcfbfb" referrerpolicy="no-referrer"><img alt="" height="335" src="https://oscimg.oschina.net/oscnet/up-35f95b18cb984ecd9e8659b66778355d901.jpg" width="800" referrerpolicy="no-referrer"></p><p>過去數月，MetaGPT [1] 的智能體（Agents）軟件公司實例讓人印象深刻，它迅速在 GitHub 獲得了 30k star，也獲得了數十個全球專業媒體與大 V 報道。但智能體軟件公司只是智能體社會（Agent Society）的一個縮影。智能體社會或許會有軟件公司、電商公司、遊戲公司，也會擁有大量的獨立智能體提供生產力。現代人工智能之父 Jürgen Schmidhuber 也非常認可智能體社會的理念，他與其團隊對 MetaGPT 做出了顯著貢獻，列入了 MetaGPT 作者名單。</p><p>早在 1986 年，馬文·明斯基以《心智社會》（Society of Mind, SOM）[2] 之作引領了人工智能領域的一場思想革命。他提出了一個極具創見的理論：心智不需由具有智能的單獨部件構成，反而是由一系列簡單部件的相互作用集結而成的複雜系統，正是這種集結，催生了我們所認識的智能和意識。這一理念對於構建自主智能體以及其後續發展，產生了不可估量的深遠影響。</p><p>隨着人工智能技術至 2023 年的飛躍，我們現在可以設想，如果每個微小部件本身都擁有一定程度的智能，它們將如何相互作用，產生何種層次的集體智能。2023 年上半年關於自然語言心智社會（NLSOM, Language Agent Society）的研究論文 [3] 中，來自阿卜杜拉國王科技大學、瑞士人工智能實驗室、牛津大學以及蘇黎世聯邦理工學院等知名研究機構的科學家們共同探討了智能體社羣的可能性。</p><p>他們提出，構建成由語言驅動的智能體社區，能夠協同完成單一智能體無法或難以獨立完成的任務。研究中提出了一系列實驗構想，這些實驗構想不僅僅是概念驗證，它們被視作邁向一個包含萬億級智能體社會的先導，這個社會可能也會包括人類成員。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/21644b3cc3a84c2db0d0da75652a0cb0~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=981&amp;h=1280&amp;s=170610&amp;e=webp&amp;b=fcfbfb" referrerpolicy="no-referrer"><img alt="" height="1044" src="https://oscimg.oschina.net/oscnet/up-2ee6f8c420b35e61bc71e31c9228d6fcd13.png" width="800" referrerpolicy="no-referrer"></p><p>在 2023 年的 CogX Festival 上，Jürgen 向聽眾展示了他對於大型語言模型（LLMs）的深刻見解。他在討論智能體（Agents）相關的話題時，提到了構建自我改進系統的多種途徑，包括通用圖靈機（Universal Turing Machine）[4] 和哥德爾機（Gödel machines）[5]。他指出，目前的大語言模型為我們提供了一種全新的思維模式 — 通過使用通用符號語言（例如：自然語言或編程代碼）作為接口，來串聯不同的模型。這些模型能夠與其他語言模型進行交流，共同構建起一個自然語言心智社會（NLSOM）的範例。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/51d8e153f5514d13820c1d67539ede46~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1920&amp;h=1080&amp;s=66142&amp;e=webp&amp;b=7d5c3e" referrerpolicy="no-referrer"><img alt="" height="450" src="https://oscimg.oschina.net/oscnet/up-f4af29afe3864c3625875a198b225f27628.jpg" width="800" referrerpolicy="no-referrer"></p><p>Jürgen Schmidhuber 教授是瑞士人工智能實驗室 (IDSIA) 的科學主任，以及阿卜杜拉國王科技大學人工智能中心 (AI Initiative, KAUST) 的主任。他的工作對強化學習（Reinforcement Learning），元學習（Meta Learning），以及神經網絡（Neural Network）等重要人工智能方向有着深刻的影響。</p><p>截止目前，Schmidhuber 教授的谷歌學術引用為 21 萬，其中作為共同發明人的長短時記憶（LSTM）論文單篇引用過 9 萬。他在 15 歲就希望能開發一種比它聰明並且能夠自我完善的人工智能，然後他就可以退休了。DeepMind 創始初期四人中的兩人以及他們招募的第一個人工智能博士都來自 Jürgen Schmidhuber 的實驗室。</p><p>在 Jürgen 構想的這一社會中，所有的交流都是透明且易於解釋的。他提到了一個被稱作「Mindstorm」的概念，即當給定一個問題時，這個自然語言心智社會能夠協同合作進行解答。</p><p>在這個過程中，社會中的每個成員可能會有不同的想法和視角，它們將收集並整合這些不同的思路，從而做出集體決策。</p><p>這種方式特別適合於解決那些單個智能體無法有效解決的問題。Jürgen 進一步舉例説明，這種問題可以是編程性質的，如使用 Python 語言解決一個具體的編程難題。通過這種協同作用，智能體社會的智能集結，將能夠實現超越個體能力的解決方案。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5cc7dc94e9a64bebb63187c960442abd~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1269&amp;h=635&amp;s=49620&amp;e=webp&amp;b=fdfaf9" referrerpolicy="no-referrer"><img alt="" height="401" src="https://oscimg.oschina.net/oscnet/up-0a2e1cb3557ba4e33b63ccceca6b4647eb2.png" width="800" referrerpolicy="no-referrer"></p><p>此次 MetaGPT 項目的迭代獲得了 Jürgen 直接指導，其團隊也在代碼、寫作、工程上做了大量支持。</p><p>接下來，本文將詳細解析 MetaGPT 論文的更新內容，以便讓讀者能夠更加深入地理解其細節。</p><p><strong>1、論文與框架更新</strong></p><p>論文 3.1 節更新：闡述了 MetaGPT 框架中的角色專業化設計和角色分工概念，説明瞭單個智能體在 MetaGPT 中的行為模式和 SOPs 下的組織方式。</p><p>論文 3.2 節更新：介紹 MetaGPT 框架中的通信機制，包括結構化通信接口設計和發佈-訂閲機制。</p><p>論文 3.3 節更新：引入了可執行反饋機制，它是一種在代碼執行過程中進行持續迭代和自我糾正的機制。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/52272b7b6df4434589d9071492e7d736~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=636&amp;s=82808&amp;e=webp&amp;b=fdfcfc" referrerpolicy="no-referrer"><img alt="" height="401" src="https://oscimg.oschina.net/oscnet/up-47bacc68b62b046bdc40b461241d7a1ab26.jpg" width="800" referrerpolicy="no-referrer"></p><p>Fig.2. 通信協議示例（左）和運行中可執行反饋的迭代編程示例（右）。左圖：Agents 使用共享消息池發佈結構化消息。它們還可以根據自己的配置訂閲相關消息。右圖：生成初始代碼後，工程師 Agent 可執行代碼並檢查運行中是否報錯。如果出現報錯，Agent 會檢查執行結果，並將它們與 PRD、系統設計和代碼文件進行比較，進行代碼的重寫和優化。</p><p><strong>1.1、智能體通信協議</strong></p><p>目前大部分多智能體都是通過以自然語言為主的對話形式來完成協作，但這對於解決具體特定任務而言並不是最優的方式。</p><p>沒有約束和特定要求的自然語言輸出，可能會導致信息內容的失真或者語義焦點的偏移。</p><p>因此，結構化的通信內容和接口形式有助於智能體之間進行快速準確的任務要求理解，也有利於信息內容的最大化保留。參考人類 SOPs 中對不同崗位的角色要求，我們給每個角色設定了符合人類對應崗位專家的輸出規範，要求智能體將原始自然語言信息轉換為更結構化的表達（如下圖所示），如數據結構、API 設計和時序圖。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39c4bc32ea9644b9b0f383b5b9810d81~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=1235&amp;s=146554&amp;e=webp&amp;b=ddecfb" referrerpolicy="no-referrer"><img alt="" height="779" src="https://oscimg.oschina.net/oscnet/up-3cb7baa9146b4b2f65471d6d5f4e2f4f4a7.jpg" width="800" referrerpolicy="no-referrer"></p><p>Fig.3 MetaGPT 軟件開發流程示意圖，表明結構化的 SOPs 可以帶來較好的效果 。更詳細的演示見附錄 B</p><p>在後續的實驗中，我們對比了 MetaGPT 和 ChatDev（使用聊天形式的溝通協作機制）來進行軟件開發的這一複雜任務的實際解決效果，結果説明結構化的通信接口設計對於智能體協作能帶來顯著效果。</p><p><strong>發佈-訂閲機制</strong></p><p>在多智能體的通信過程中，僅僅依賴 1v1 的單點通信方式不僅會加劇通信拓撲的複雜度，導致協作的效率低下，也會急劇增加開發成本。因此，我們通過【發佈-訂閲】的消息機制，在框架內實現了共享消息池和基於興趣的訂閲方式。</p><p>具體來説，環境提供共享的消息池，智能體可以從中直接獲取信息，無需逐一詢問其他智能體。與此同時，智能體可根據自己興趣/關注的行為來進行消息的過濾和篩選，從而減少消息/記憶的過載。如圖 3 所示，架構師主要關注產品經理的 PRD 文檔輸出，而對測試工程師的文檔則關注較少。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f4cb736da0047778cb331c48db14fb9~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1266&amp;h=705&amp;s=29794&amp;e=webp&amp;b=f9fbfe" referrerpolicy="no-referrer"><img alt="" height="445" src="https://oscimg.oschina.net/oscnet/up-fa141e11ff2fb59723d29e9be1259680890.jpg" width="800" referrerpolicy="no-referrer"></p><p><strong>1.2、可執行迭代反饋設計</strong></p><p>調試和執行反饋在日常編程任務中發揮着重要作用。然而，現有方法往往缺乏自我糾正機制，僅通過代碼審查和評審機制進行代碼可行性評估。為了進一步減少 LLM 在生成代碼上的幻覺問題，我們引入了可執行反饋機制，對代碼進行迭代改進。通過自動的代碼執行測試結果反饋，進行代碼可行性評估和判斷，促進 LLM 進行自我的迭代和優化。如圖 2 所示，工程師可根據代碼執行結果持續更新代碼，迭代測試，直到測試通過或者最大 N 次重試退出。</p><p><strong>2、實驗更新</strong></p><p>在實驗部分，我們增加了對 SOPs 引入多智能體框架效果的探索實驗，和可執行迭代反饋帶來的代碼質量的提升實驗。在數據集上：</p><ol><li>針對代碼質量的效果評估：我們使用了兩個公共基準數據集：HumanEval 和 MBPP。<br> 1）HumanEval 包括 164 個手寫編程任務。這些任務包括功能説明、描述、參考代碼和測試。<br> 2）MBPP 包含 427 個 Python 任務。這些任務涵蓋核心概念和標準庫功能，幷包括説明、參考代碼和自動測試。</li><li>我們提出了更具有挑戰性的軟件開發任務的基準數據集 SoftwareDev：我們的 SoftwareDev 數據集收集了 70 個具有代表性的軟件開發任務實例，每個實例都有自己的任務提示（見論文表 5）。這些任務的範圍多種多樣（見論文圖 5），如迷你遊戲、圖像處理算法、數據可視化等。它們為真實的開發任務提供了一個強大的測試平台。與之前的數據集不同，SoftwareDev 側重於工程方面。在比較中，我們隨機選擇了七個具有代表性的任務進行評估。</li></ol><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a63997ca887a49a1a619d93e208c164d~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=703&amp;h=727&amp;s=87524&amp;e=webp&amp;b=fbfafa" referrerpolicy="no-referrer"><img alt="" height="620" src="https://oscimg.oschina.net/oscnet/up-762eec7feede0d100b7ae1c5039f8331f71.jpg" width="600" referrerpolicy="no-referrer"></p><p><strong>2.1、可執行迭代反饋設計</strong></p><p>圖 4 表明，MetaGPT 在 HumanEval 和 MBPP 基準測試中均優於之前的所有方法。當 MetaGPT（使用 GPT-4 作為基礎模型），與 GPT-4 相比，它在 HumanEval 基準測試中的 Pass @1 顯著提高。它在這兩個公共基準測試中達到了 85.9% 和 87.7%（考慮到實驗成本，部分模型的數值結果直接使用的 Dong et al. (2023). 所提供的結果 [6]）。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6749bae368dd4f4d86ac44a57ace9c82~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1280&amp;h=382&amp;s=31468&amp;e=webp&amp;b=fdfdfd" referrerpolicy="no-referrer"><img alt="" height="239" src="https://oscimg.oschina.net/oscnet/up-55fc3e480ea87fb5c5872f15472848bf135.jpg" width="800" referrerpolicy="no-referrer"></p><p>Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.</p><p><strong>2.2、軟件開發任務數據集 &amp; 評價指標</strong></p><p>對於 SoftwareDev，我們優先考慮生成項目的實際可用性，並通過人工評估（A、E）或統計分析（B、C、D）來評估性能，我們通過可視化示例展示了 MetaGPT 的自主軟件生成能力（論文圖 5）。有關其他實驗和分析，可參閲論文附錄 C：</p><p>（A）可執行性：該指標將生成代碼從 1（失敗/無功能）到 4（無缺陷）進行評級。1 代表無功能，2 代表可運行但不完美，3 代表接近完美，4 代表無缺陷。</p><p>（B）成本：這裏的成本評估包括（1）項目運行時間（2）Token 消耗量和（3）實際費用。</p><p>（C）代碼統計信息：包括（1）代碼文件數量（2）每個文件的平均代碼行數，以及（3）總代碼行數。</p><p>（D）生產效率：基本定義為 Token 使用量除以代碼行數，即每行代碼消耗的 Token，該數值越小説明代碼生產效率越高。</p><p>（E）人工修訂成本：以確保代碼順利運行所需的修訂輪數來量化，這表示人工幹預的頻率，如調試或導入依賴等修訂。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7cce3f4c622541ea856eb3dc0e1fd9b8~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1266&amp;h=761&amp;s=58372&amp;e=webp&amp;b=f8f7f7" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-58d8c9338be9e954eee491611053ad8b451.png" width="800" referrerpolicy="no-referrer"></p><p><strong>2.3、SOPs vs ChatChain</strong></p><p>在解決特定任務的場景中，為了探索 SOPs 對多智能體協作的效果，我們選擇了開源工作中支持軟件開發任務的智能體框架 ChatDev 作為實驗比較對象。ChatDev 是基於 ChatChain 和軟件開發瀑布流的角色分工進行智能體組織和協作的框架。我們從 SoftwareDev 選擇了 7 個任務進行對比，並比較了上述的相關指標來説明差異。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2c3560be06bd46feab9b37a51b03e6aa~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=741&amp;s=67220&amp;e=webp&amp;b=ffffff" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-06aa7e7223004b9c3b2ca38b88efa69b92d.png" width="800" referrerpolicy="no-referrer"></p><p>如論文表 1 所示，在具有挑戰性的 SoftwareDev 數據集上，MetaGPT 幾乎在所有指標上都優於 ChatDev。</p><p>例如：在可執行性方面，MetaGPT 得到了 3.75 分，非常接近 4 分（完美無缺）。此外，它花費的時間（503 秒）也明顯少於 ChatDev。</p><p>在代碼統計和人工修改的成本上也明顯優於 ChatDev。雖然 MetaGPT 需要更多的 Token（24,613 或 31,255，而 ChatDev 為 19,292 ），但它只需要 126.5/124.3 個 Tokens 就能生成一行代碼。相比之下，ChatDev 使用了 248.9 個 Tokens。</p><p>這些結果凸顯了 SOPs 在多智能體協作中的優勢。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2c8b076075554df5a425342a9c1940e7~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=817&amp;h=263&amp;s=24046&amp;e=webp&amp;b=f4f4f4" referrerpolicy="no-referrer"><img alt="" height="258" src="https://oscimg.oschina.net/oscnet/up-b7e033a3dab2d9dbc88391df2712d572478.jpg" width="800" referrerpolicy="no-referrer"></p><p><strong>3、致謝</strong></p><p>感謝來自 KAUST AI 中心的執行秘書 Sarah Salhi，博士後王宇輝，以及博士生王文一對於此論文提供的建議以及幫助。</p><p>[1] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fpdf%252F2308.00352.pdf" target="_blank">arxiv.org/pdf/2308.00…</a></p><p>[2] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FSociety_of_Mind" target="_blank">en.wikipedia.org/wiki/Societ…</a></p><p>[3] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fpdf%252F2305.17066.pdf" target="_blank">arxiv.org/pdf/2305.17…</a></p><p>[4] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FUniversal_Turing_machine" target="_blank">en.wikipedia.org/wiki/Univer…</a></p><p>[5] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FG%2525C3%2525B6del_machine" target="_blank">en.wikipedia.org/wiki/Gödel_…</a></p><p>[6] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fabs%252F2304.07590" target="_blank">arxiv.org/abs/2304.07…</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 08 Nov 2023 10:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265625</guid>
            <link>https://www.oschina.net/news/265625</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為與西工大合作，發佈首款流體力學大模型「秦嶺・翱翔」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>華為近日宣佈，與西北工業大學聯合研發的首個面向飛行器的流體力學大模型「秦嶺・翱翔」現已正式發佈。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ff4d245868c9104fe5ffe5ca0fd9c6111a1.png" referrerpolicy="no-referrer"></p><p>秦嶺・翱翔大模型是西工大流體力學智能化國際聯合研究所攜手華為 AI4Sci Lab 在國產開源流體計算軟件風雷的基礎上，依託昇騰 AI 澎湃算力及昇思 MindSpore AI 框架共同研發的面向飛行器流體仿真的智能化模型。</p><p>大模型通過打造智能通用的流體力學軟件平台與流體工業全場景應用底座，旨在實現全場景流場準確預測。同時結合業界領先的數據同化、AI 湍流模型、流場快速預測等技術，支撐流體力學大模型的基礎構架。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d498c2db0add1f15cf241f0aff43d998bfb.png" referrerpolicy="no-referrer"></p><p>具體來説，大模型採用自研多級分佈式並行自適應框架，多層級融合流體力學經典理論和人工智能方法，構造數學物理關聯特徵、開展多範式一體化建模、搭建不變性可實現性多模態統一框架。同時，在模型算法設計、混合精度加速，以及數值求解耦合並行優化等方面進行了創新與驗證，實現了高置信度流場重構、全速域湍流場求解和複雜流場近實時預測。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 08 Nov 2023 08:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265612</guid>
            <link>https://www.oschina.net/news/265612</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[NetBSD 10.0 發佈首個 RC，類 UNIX 操作系統]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>自去年發佈 NetBSD 10.0 Beta 以來，已過去接近一年，現在終於進入了 RC 階段。開發團隊稱將在未來幾個月內發佈正式版。</p><p>NetBSD 10 的開發工作於 2019 年底啓動，這將是重大版本更新。<u><a href="https://www.oschina.net/news/222371/netbsd-10-0-beta">根據之前的報道</a></u>，新版本在性能提升方面將會是一個重要里程碑，尤其是 NetBSD 10 的多核操作系統性能比以前的版本要快許多。</p><p><strong>其他重要變化</strong></p><ul><li>支持 WireGuard</li><li>支持自動為 SWAP 分區進行加密</li><li>引入新的磁盤加密方法</li><li>在內核實現 CPU 加速</li><li>支持更多采用 Arm 架構的硬件，包括 Rockchip RK356X, NXP <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fi.MX" target="_blank">i.MX</a> 8M, Amlogic G12, Apple M1 和 Raspberry Pi 4</li><li>支持最新 ARM CPU 中的新安全功能</li><li>支持新的網絡適配器，包括 Realtek 2.5 千兆以太網和新的 Intel 10/25/40 千兆以太網適配器</li><li>將 compat_linux 移植到 AArch64 架構</li><li>將 DTrace 移植到 MIPS</li><li>改進對多處理器的支持，提供更多的 iMac G5 支持</li><li>對 Xen 虛擬機管理程序支持進行重大修改</li><li>為用户空間引入新的程序，包括用於手動修剪磁盤空間的 blkdiscard (8)、用於控制音頻音量的 aiomixer (1)、realpath (1) 和 fsck_udf (8)……</li><li>針對多核系統顯著提升性能</li><li>用於啓用更新組件的無數其他硬件驅動程序改進</li></ul><p>下載地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnycdn.netbsd.org%2Fpub%2FNetBSD-daily%2Fnetbsd-10%2F202311070920Z%2Fimages%2F" target="_blank">https://nycdn.netbsd.org/pub/NetBSD-daily/netbsd-10/202311070920Z/images/</a></p><p>NetBSD 是一個免費的、安全的及高度可移植的類 UNIX 操作系統，它適合於很多種平台，從 64 位的 AlphaServers 及桌面系統到手持及嵌入式系統。它在設計上非常整潔，並擁有先進的特性，這使得它在業界和學術界都有口皆碑。用户可通過完整的源代碼來獲得支持。很多應用程序都可容易地從 NetBSD Packages Collection 獲得。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9ddeb287fa441bf078d01f543c60856a06d.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cb37485c28b1322211fac5a6819cf507b8b.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 08 Nov 2023 02:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265677/netbsd-10-0-rc</guid>
            <link>https://www.oschina.net/news/265677/netbsd-10-0-rc</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[用於 SuiteCRM 的 ONLYOFFICE 連接器現已推出]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 發佈了 SuiteCRM 的集成連接器。現在，您可以在 SuiteCRM 文檔模塊中編輯和協作處理 Office 文件。繼續閲讀瞭解詳情。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="用於 SuiteCRM 的 ONLYOFFICE 連接器現已推出" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/11/07162428/ONLYOFFICE-SuiteCRM-integration.png" referrerpolicy="no-referrer"></p><h2>關於 ONLYOFFICE 文檔</h2><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite.aspx" target="_blank">ONLYOFFICE 文檔</a></strong><span style="background-color:#ffffff; color:#4d4d4d">是一款全面的在線辦公工具，提供了文本文檔、電子表格和演示文稿的查看和編輯功能。它高度兼容微軟 Office 格式，包括 .docx、.xlsx 和 .pptx 等文件格式，並支持實時協作編輯，使團隊成員能夠同時在同一文檔上進行實時協作。</span></p><p>ONLYOFFICE 文檔可與多種雲服務進行集成，如：CMS 框架（WordPress/Strapi/Drupal）、協作與內容平台（ONLYOFFICE 工作區/Nextcloud/Seafile/Confluence/Alfresco）、問題跟蹤工具（Jira/Redmine）、線上教育解決方案（Moodle/Chamilo/HumHub）等等。您還可將編輯器嵌入至自建 Web 服務中。</p><h2><strong>關於 SuiteCRM</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsuitecrm.com%2F" target="_blank">SuiteCRM</a>&nbsp;是一款開源的，面向企業的客户關係管理應用程序，可作為 SaaS 或本地部署使用。它有多個功能模塊，用於管理和自動化銷售、建立關係、吸引客户、監控業務數據等。</p><h2><strong>用於 SuiteCRM 的 ONLYOFFICE 連接器</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">利用 ONLYOFFICE 可以直接在 SuiteCRM 文檔模塊中查看、編輯和協作文檔、工作表、幻燈片、表單和 PDF：</p><ul><li>單擊該文件打開「詳細信息視圖」頁面。</li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="用於 SuiteCRM 的 ONLYOFFICE 連接器現已推出" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/11/07155648/onlyoffice-suitecrm-files.png" referrerpolicy="no-referrer"></p><ul><li>單擊「操作」下拉菜單中的「在 ONLYOFFICE 中打開」。</li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="用於 SuiteCRM 的 ONLYOFFICE 連接器現已推出" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/11/07155448/open-in-onlyoffice.png" referrerpolicy="no-referrer"></p><ul><li>該文件會在相應 ONLYOFFICE 編輯器的新選項卡中打開。</li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="用於 SuiteCRM 的 ONLYOFFICE 連接器現已推出" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/11/07160003/onlyoffice-presentation-editor-in-suitecrm.png" referrerpolicy="no-referrer"></p><h2><strong>如何安裝連接器</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">要在 SuiteCRM 中處理辦公文檔，需要一個 ONLYOFFICE 文檔實例。您可以選擇<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload-docs.aspx" target="_blank"><u>自託管版本</u></a>或無需要下載和安裝的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocs-registration.aspx" target="_blank"><u>雲實例</u></a>。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 連接器可在<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2Fonlyoffice-suitecrm" target="_blank">GitHub</a><span>&nbsp;</span>上獲取。安裝請按照下列步驟操作：</p><ol><li>啓動 SuiteCRM，切換到管理 -&gt; 管理工具 -&gt; 模塊加載器並上傳<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2Fonlyoffice-suitecrm%2Freleases" target="_blank">連接器存檔</a>。</li><li>選擇相應按鈕，安裝上傳的模塊。</li><li>切換到管理 -&gt; 管理工具 -&gt; 修復並運行快速修復和重建。</li></ol><h2><strong>如何配置集成</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">要配置連接器，請轉至管理 -&gt; ONLYOFFICE -&gt; ONLYOFFICE 設置，設置以下參數：</p><ul><li><strong>文檔編輯服務地址。</strong>輸入安裝的 ONLYOFFICE 文檔服務器的名稱或 ONLYOFFICE 文檔雲的地址。</li><li><strong>密鑰。</strong>從 ONLYOFFICE 文檔 7.2 版本開始，默認啓用<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2022%2F09%2Fwhat-is-jwt" target="_blank"><u>JWT</u></a>，並出於安全原因和數據完整性的原因，會自動生成密鑰限制對編輯器的訪問。如果需要，您可以指定自己的密鑰。在這種情況下，請在 ONLYOFFICE 文檔<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapi.onlyoffice.com%2Feditors%2Fsignature%2F" target="_blank"><u>配置文件</u></a>中指定相同的密鑰以啓用驗證。</li><li><strong>授權標頭。</strong></li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="用於 SuiteCRM 的 ONLYOFFICE 連接器現已推出" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/11/07155724/onlyoffice-suitecrm-settings.png" referrerpolicy="no-referrer"></p><div><h3><strong>相關鏈接</strong></h3><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2Fonlyoffice-suitecrm" target="_blank"><u>GitHub 上用於 SuiteCRM 的 ONLYOFFICE 連接器</u></a></p><p style="color:#333333; margin-left:0; margin-right:0">ONLYOFFICE 文檔：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload-docs.aspx" target="_blank"><u>自託管版</u></a><span>&nbsp;</span>/<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocs-registration.aspx" target="_blank"><u>雲</u><u>端</u><u>版</u></a></p><p style="color:#333333; margin-left:0; margin-right:0">最新文檔更新：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2023%2F10%2Fonlyoffice-docs-7-5-released" target="_blank"><u>版本 7.5</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fall-connectors.aspx" target="_blank"><u>ONLYOFFICE<span>&nbsp;</span></u><u>的</u><u>所有</u><u>集成</u></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 13:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265635</guid>
            <link>https://www.oschina.net/news/265635</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
