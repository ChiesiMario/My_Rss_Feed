<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 23 Feb 2024 06:55:04 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Oracle 致力解決 Java 虛擬線程「Pinning」問題]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>虛擬線程在 2023 年 9 月發佈的 JDK 21 中正式成為一項穩定功能。該功能在 Java 生態系統中反響極佳，但仍存在一些痛點。Oracle 日前在&nbsp;Inside Java 網站上詳細<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finside.java%2F2024%2F02%2F21%2Fquality-heads-up%2F" target="_blank">介紹</a>了虛擬線程的「Pinning」問題。</p><p>最常見的兩種情況是：(a) 虛擬線程在 synchronized method 中駐留（如執行 socket I/O）；(b) <span style="color:#333333">虛擬線程阻塞進入&nbsp;synchronized method</span>，因為對象的相關監視器被另一個線程持有。</p><p>在這兩種情況下，載體或本地線程都不會被釋放去做其他工作。因此可能會影響性能和可擴展性，並可能<span style="color:#333333">在某些情況下</span>導致飢餓和死鎖。官方最近發佈的一個<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finside.java%2F2024%2F02%2F17%2Fvirtual-threads-next-steps%2F" target="_blank">Virtual Threads Next Steps</a>&nbsp;視頻中則更詳細地解釋了其中的原因，並討論了一些潛在的解決方案。</p><p><img height="196" src="https://oscimg.oschina.net/oscnet/up-6a2e93ce6802a570c1704258c9a589e998e.png" width="500" referrerpolicy="no-referrer"></p><p>項目團隊正在努力解決這些問題。Java Project Loom 的新早期訪問版本<span style="color:#4e4242">引入了對對象監視器實現的更改</span><span style="color:#333333">，但不適用這兩種常見情況。因此 </span><span style="color:#4e4242">Loom&nbsp;</span><span style="color:#333333">團隊正在尋求用户的幫助，以測試這些更新的對象監控器在使用虛擬線程的代碼和大量同步的庫中的可靠性和性能。可通過&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmail.openjdk.org%2Fpipermail%2Floom-dev%2F" target="_blank">Loom 郵件列表</a>&nbsp;<span style="color:#333333">報告或反饋問題。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 06:47:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279954/java-virtual-threads-pinning-issue</guid>
            <link>https://www.oschina.net/news/279954/java-virtual-threads-pinning-issue</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | 目前的人工智能技術連貓的智能水平都沒達到]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.22</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/279713/google-gemma-open-models" target="_blank">谷歌發佈輕量級開源大語言模型 Gemma</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Gemma 是一款輕量級、先進的開源模型，供開發者和研究人員用於 AI 構建。Gemma 模型家族包括 2B（20 億參數）和 7B（70 億參數）兩種尺寸，能夠在不同的設備類型上運行，包括筆記本電腦、桌面電腦、IoT 設備、移動設備和雲端。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><h3><a href="https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released" target="_blank">夜鶯監控 V7 第一個 beta 版本</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">夜鶯項目從 2024 開始開發 V7 版本，重點做體驗優化，V7 和 V6 版本兼容可以平滑升級<span style="background-color:#ffffff; color:#333333">（V6 升級到 V7 只需要替換一下二進制重啓即可，如果是容器部署，只需要更新鏡像並重啓）</span>，第一個 beta 的優化項包括：</p><ul><li>全站暗黑主題</li><li>優化邊緣機房機器失聯告警的實現邏輯，真正做到邊緣機房告警自閉環</li><li>優化內置大盤、內置告警規則的列表頁面 UI</li><li>全局回調地址頁面展示優化，增加詳盡的文檔提示信息</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="20240221141801" src="https://download.flashcat.cloud/ulric/20240221141801.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img height="554" src="https://oscimg.oschina.net/oscnet/up-14e1acb77ab8633d225b3117ebbc7dc7920.png" width="1522" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博<span>&nbsp;</span></span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FO1MdFaqZm" target="_blank">高飛</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-a2ff0599a45c140a6bf468a7d85524102fa.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博<span>&nbsp;</span></span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1856404484%2FO1JFSAEg0" target="_blank">鳳凰網科技</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-da11d19579f9cc14d57a12c12f4479f067a.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-33430582a60711cf56a923991e1fef04da9.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p>GitHub Trending</p><p><img src="https://oscimg.oschina.net/oscnet/up-291d0213846cc3efbd09b526da6bac5ae29.png" referrerpolicy="no-referrer"></p><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 03:53:48 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279923</guid>
            <link>https://www.oschina.net/news/279923</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 迴應 7 萬億美元半導體計劃：所需投資遠超想象]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在英偉達發佈了強勁的 2024 財年第四季度財報之後的幾小時，英特爾首席執行官 Pat Gelsinger 和 OpenAI 首席執行官 Sam Altman 在加利福尼亞州聖何塞的一個會議中心展開了一場對話，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapnews.com%2Farticle%2Fintel-openai-nvidia-chips-boom-dbf20077caafc9b33870f9f6d32d3794" target="_blank">暢談</a>半導體在 AI 時代塑造社會所扮演的角色。</span></p><p><span style="color:#000000"><img alt="" height="375" src="https://oscimg.oschina.net/oscnet/up-67bd113ff9160357624584468c53d04258a.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">在活動中，Gelsinger 詢問了 Altman 有關最近報道的計劃從中東地區籌集高達 7 萬億美元的資金，以支持 OpenAI 的一項半導體計劃，並與英偉達展開競爭的傳聞。對此，Altman 則反駁稱，這種匿名人士未經證實的説法比比皆是，「我的主要工作不是到處修正這些錯誤的文章」。</span></p><p><span style="color:#000000">但 Altman 同時也承認，AI 的發展需要大量的資金。「事實是，我們認為世界將需要更多的 AI 計算（芯片）。這將需要全球範圍內大量的投入，超出我們的想象。我們現在還沒有一個具體數字。」</span></p><p><span style="color:#000000">他還強調了過去一年加快人工智能發展的重要性。他認為人工智能的進步將為人類帶來更美好的未來，不過奧特曼也承認，在前進的過程中會有不利的一面。"我們正在走向這樣一個世界：人工智能生成的內容將多於人類生成的內容。這將不僅僅是一個 good story，而是一個 net good story。"</span></p><p><span style="color:#000000">此外，Altman 重申了在 AI 領域進行監管的必要性，強調了政府在制定框架以降低潛在風險方面的關鍵作用。</span></p><p><span style="color:#000000">Gelsinger 預測，</span><span style="background-color:#ffffff; color:#000000">到 2030 年，英特爾將成為全球第二大代工企業，僅次於台積電。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279911/intel-openai-chips</guid>
            <link>https://www.oschina.net/news/279911/intel-openai-chips</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Apache ECharts 5.5.0 引入服務端渲染的新利器：1KB 的客户端輕量運行時]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Apache ECharts 5.5.0 版本已於 2024.2.18 正式發佈。</p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fecharts%2Freleases%2Ftag%2F5.5.0" target="_blank">https://github.com/apache/echarts/releases/tag/5.5.0</a></u></em></p><p><strong>主要變化</strong></p><ul><li><p>增強了代碼的 ESM 識別，對&nbsp;Node.js&nbsp;環境開發更加友好；</p></li><li><p>為服務端渲染方案提供了一個 gzip 後僅 1KB 的輕量運行時，極大地降低了加載時間；</p></li><li><p>為數據下鑽支持了過渡動畫，開發者可以方便地實現多級數據的動畫效果；</p></li><li><p>為餅圖和極座標系圖表增加了更多配置項，可以實現更豐富的樣式；</p></li><li><p>新增阿拉伯語和荷蘭語兩種語言的翻譯</p></li><li><p>……</p></li></ul><p>以下內容轉自：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIpGQS1GspyXzNe-u9F4B-A" target="_blank">https://mp.weixin.qq.com/s/IpGQS1GspyXzNe-u9F4B-A</a></u></em></p><hr><h2>增強的 ESM 支持</h2><p>為了讓開發者在測試和 Node.js 環境使用更方便，我們在這個版本中對 ESM 的識別問題進行了優化。</p><p>以前，ECharts 只在 npm（npm 包的 lib 目錄中）導出&nbsp;<code>*.esm</code>&nbsp;文件。雖然這在 bundlers 環境表現良好，但 Node.js 環境和一些基於 Node.js 的測試框架（如 vitest 和 jest）中的表現並不理想。</p><p>有了這個新功能，我們做了幾個改變以改善這個問題：</p><ul><li><p>在&nbsp;<code>package.json</code>&nbsp;中添加了&nbsp;<code>"type": "module"</code></p></li><li><p>在&nbsp;<code>package.json</code>&nbsp;中添加了&nbsp;<code>"exports": {...}</code></p></li><li><p>在子目錄中添加了一些只包含&nbsp;<code>"type": "commonjs"</code>&nbsp;的&nbsp;<code>package.json</code>&nbsp;文件</p></li></ul><p>這些改變意味着，像&nbsp;<code>echarts/core.js</code>&nbsp;這樣的文件現在可以在像純 Node.js、vitest、jest 和 create-react-app 這樣的環境中解析為 ESM。</p><p>我們還確保了這個新功能與各種環境兼容，包括運行時（Node.js/vitest/jest（create-react-app）/ssr/…）和打包器（webpack/rollup/vite/esbuild/…）。</p><p>我們非常期待這一新功能，並相信它將極大地改善開發者的體驗。</p><h2>服務端渲染 + 客户端輕量運行時</h2><p>Apache ECharts 功能強大，相應地，包體積也比較大。我們在之前的版本中也做了各種努力來改進這一點。開發者可以使用 TreeShaking 按需加載部分代碼，以減少加載的代碼量。從 Apache ECharts 5.3 版本起，我們支持了零依賴的服務端 SVG 字符串渲染方案，並支持圖表的初始動畫。這樣，使用服務端渲染的結果作為首屏渲染的畫面，可以大大減少首屏加載時間。</p><p>服務端渲染雖然是一種很有效減少包體積的解決方案，但如果需要在客户端實現一些交互，那麼不得不仍舊加載 echarts.js，這可能會增加更多的加載時間。對於一些對頁面加載速度要求較高的場景，這可能不是一個理想的選擇。</p><p><strong>在 5.5.0 版本中，我們新增了客户端輕量運行時</strong>，客户端無需加載完整 ECharts 即可實現部分交互。這樣，我們可以在服務端渲染圖表，然後在客户端加載輕量運行時，實現一些常見的交互。這意味着，<strong>只需要加載&nbsp;4KB 的輕量運行時（gzip 後 1KB），即可實現帶初始動畫和部分常用交互形式的圖表</strong>。這一改進將極大地提升頁面加載速度，特別是對於移動端的體驗。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5c9857523986e92155d29f453c6307014c1.png" referrerpolicy="no-referrer"></p><p>以這個帶標題的餅圖為例，如果按客户端僅打包餅圖和標題組件的方案，gzip 後需要 135KB；如果按服務端渲染的方案，渲染結果 SVG gzip 後 1 KB、客户端運行時 gzip 後 1KB，僅為前者體積的 1.5%。交互方面，後者也可以做到初始動畫、鼠標移動到圖表元素後的高亮，並且獲取到點擊事件，能夠滿足大部分的常見交互需求。</p><p>如需使用客户端輕量運行時方案，服務端代碼和之前一樣，但需要保證 ECharts 版本號在 5.5.0 以上。</p><pre><code>//&nbsp;服務端代碼
const&nbsp;echarts&nbsp;=&nbsp;require('echarts');

//&nbsp;在&nbsp;SSR&nbsp;模式下第一個參數不需要再傳入&nbsp;DOM&nbsp;對象
const&nbsp;chart&nbsp;=&nbsp;echarts.init(null,&nbsp;null,&nbsp;{
&nbsp;&nbsp;renderer:&nbsp;'svg',&nbsp;//&nbsp;必須使用&nbsp;SVG&nbsp;模式
&nbsp;&nbsp;ssr:&nbsp;true,&nbsp;//&nbsp;開啓&nbsp;SSR
&nbsp;&nbsp;width:&nbsp;400,&nbsp;//&nbsp;需要指明高和寬，如果是根據客户端容器大小動態的，該值需要從客户端得到
&nbsp;&nbsp;height:&nbsp;300
});

//&nbsp;像正常使用一樣&nbsp;setOption
chart.setOption({
&nbsp;&nbsp;//...
});

//&nbsp;輸出字符串
const&nbsp;svgStr&nbsp;=&nbsp;chart.renderToSVGString();

//&nbsp;調用&nbsp;dispose&nbsp;以釋放內存
chart.dispose();
chart&nbsp;=&nbsp;null;

//&nbsp;通過 HTTP Response 返回 svgStr 給前端或者緩存到本地（這裏以 Express.js 為例）：
res.writeHead(200,&nbsp;{
&nbsp;&nbsp;'Content-Type':&nbsp;'application/xml'
});
res.write(svgStr);
res.end();

</code></pre><p>客户端將得到的 SVG 字符串添加到容器中，並綁定輕量運行時：</p><pre><code>&lt;div&nbsp;id="chart-container"&nbsp;style="width:800px;height:600px"&gt;&lt;/div&gt;

&lt;script&nbsp;src="https://cdn.jsdelivr.net/npm/echarts/ssr/client/dist/index.js"&gt;&lt;/script&gt;
&lt;script&gt;
const&nbsp;ssrClient&nbsp;=&nbsp;window['echarts-ssr-client'];

let&nbsp;isSeriesShown&nbsp;=&nbsp;{
&nbsp;&nbsp;a:&nbsp;true,
&nbsp;&nbsp;b:&nbsp;true
};

function&nbsp;updateChart(svgStr)&nbsp;{
&nbsp;&nbsp;const&nbsp;container&nbsp;=&nbsp;document.getElementById('chart-container');
&nbsp;&nbsp;container.innerHTML&nbsp;=&nbsp;svgStr;

&nbsp;&nbsp;//&nbsp;使用輕量運行時賦予圖表交互能力
&nbsp;&nbsp;ssrClient.hydrate(main,&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;on:&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;click:&nbsp;(params)&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(params.ssrType&nbsp;===&nbsp;'legend')&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;點擊圖例元素，請求服務器進行二次渲染
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;isSeriesShown[params.seriesName]&nbsp;=&nbsp;!isSeriesShown[params.seriesName];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fetch('...?series='&nbsp;+&nbsp;JSON.stringify(isSeriesShown))
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.then(res&nbsp;=&gt;&nbsp;res.text())
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.then(svgStr&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updateChart(svgStr);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;});
}

//&nbsp;通過&nbsp;AJAX&nbsp;請求獲取服務端渲染的&nbsp;SVG&nbsp;字符串
fetch('...')
&nbsp;&nbsp;.then(res&nbsp;=&gt;&nbsp;res.text())
&nbsp;&nbsp;.then(svgStr&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;updateChart(svgStr);
&nbsp;&nbsp;});
&lt;/script&gt;
</code></pre><p>客户端輕量運行時必須配合 SVG 形式的服務端渲染結果使用，支持以下交互：</p><ul><li><p>圖表初始動畫（實現原理：服務端渲染的 SVG 帶有 CSS 動畫）</p></li><li><p>高亮樣式（實現原理：服務端渲染的 SVG 帶有 CSS 動畫）</p></li><li><p>動態改變數據（實現原理：輕量運行時請求服務器進行二次渲染）</p></li><li><p>點擊圖例切換系列是否顯示（實現原理：輕量運行時請求服務器進行二次渲染）</p></li></ul><p>可以發現，這能夠滿足大部分的交互場景需求。如果需要更復雜的交互，則客户端需要加載&nbsp;<code>echarts.js</code>&nbsp;實現完整功能。</p><p>完整的介紹請參見官網使用手冊的「應用篇 - 跨平台方案 - 服務端渲染」。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279907/echarts-5-5-0</guid>
            <link>https://www.oschina.net/news/279907/echarts-5-5-0</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[和 Gmail 基本 HTML 視圖説再見]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌已開始<u><a href="https://www.oschina.net/news/259383">停止支持 Gmail </a><a href="https://www.oschina.net/news/259383">基本 HTML 視圖</a></u>。自 2024 年 2 月起，Gmail 會自動將用户從基本 HTML 視圖轉換為標準視圖。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0cdd4e28b49bf3c37718b40baee96da1d75.png" referrerpolicy="no-referrer"></p><p><em>基本 HTML 視圖允許用户以簡陋的方式查看電子郵件，但對所有的瀏覽器提供了最大的兼容性。</em></p><p>Gmail 更新了其<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fmail%2Fanswer%2F15049%3Fhl%3Dzh-Hans" target="_blank">支持頁面</a>，以反映 Gmail 將在截止日期後自動切換到標準視圖。不僅如此，有用户在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D37558372" target="_blank">Hacker News</a>上發帖稱，他們收到了一封來自 Google 的郵件，表明該功能已經結束。</p><blockquote><p>"我們寫信通知您，從 2024 年 1 月初開始，桌面網頁和移動網頁的 Gmail Basic HTML 視圖將被禁用。Gmail Basic HTML 視圖是 Gmail 的舊版本，10 多年前就已被現代版本取代，不包含完整的 Gmail 功能。"</p></blockquote><p>即使在今天，當你嘗試訪問 HTML 版本時，Google 也會顯示一條信息，稱該版本是為"較慢的連接速度和傳統瀏覽器"設計的，並要求你確認是否不想使用標準版本。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cca03ff735c3d625769511865800215a87d.png" referrerpolicy="no-referrer"></p><p>HTML 版本缺少很多功能，如聊天、拼寫檢查、搜索過濾器、鍵盤快捷鍵和豐富的格式。但在連接性較差的地區或只想瀏覽電子郵件而不想使用任何額外功能的情況下，HTML 版還是很有用的。目前還不清楚 Google 是否計劃添加低連接模式。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:41:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279900/goodbye-html-gmail</guid>
            <link>https://www.oschina.net/news/279900/goodbye-html-gmail</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[記一次 Rust 內存泄漏排查之旅]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在某次持續壓測過程中，我們發現 GreptimeDB 的 Frontend 節點內存即使在請求量平穩的階段也在持續上漲，直至被 OOM kill。我們判斷 Frontend 應該是有內存泄漏了，於是開啓了排查內存泄漏之旅。</p><h2>Heap Profiling</h2><p>大型項目幾乎不可能只通過看代碼就能找到內存泄漏的地方。所以我們首先要對程序的內存用量做統計分析。幸運的是，GreptimeDB 使用的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjemalloc%2Fjemalloc%2Fwiki%2FUse-Case%253A-Heap-Profiling" target="_blank">jemalloc 自帶 heap profiling</a>，我們也<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb%2Fblob%2Fdevelop%2Fsrc%2Fcommon%2Fmem-prof%2FREADME.md" target="_blank">支持了導出 jemalloc 的 profile dump 文件</a>。於是我們在 GreptimeDB 的 Frontend 節點內存達到 300MB 和 800MB 時，分別 dump 出了其內存 profile 文件，再用 jemalloc 自帶的 <code>jeprof</code> 分析兩者內存差異（<code>--base</code> 參數），最後用火焰圖顯示出來：</p><p><img src="https://oscimg.oschina.net/oscnet/up-002154d38e6da2e50485895918972b1b8a1.png" alt="" referrerpolicy="no-referrer"></p><p>顯然圖片中間那一大長塊就是不斷增長的 500MB 內存佔用了。仔細觀察，居然有 thread 相關的 stack trace。難道是創建了太多線程？簡單用 <code>ps -T -p</code> 命令看了幾次 Frontend 節點的進程，線程數穩定在 84 個，而且都是預知的會創建的線程。所以「線程太多」這個原因可以排除。</p><p>再繼續往下看，我們發現了很多 Tokio runtime 相關的 stack trace，而 Tokio 的 task 泄漏也是常見的一種內存泄漏。這個時候我們就要祭出另一個神器：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftokio-rs%2Fconsole" target="_blank">Tokio-console</a>。</p><h2>Tokio Console</h2><p>Tokio Console 是 Tokio 官方的診斷工具，輸出結果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-1772a99dbc1b17d9b0ab49532e083a4234f.png" alt="" referrerpolicy="no-referrer"></p><p>我們看到居然有 5559 個正在運行的 task，且絕大多數都是 Idle 狀態！於是我們可以確定，內存泄漏發生在 Tokio 的 task 上。 現在問題就變成了：GreptimeDB 的代碼裏，哪裏 spawn 了那麼多的無法結束的 Tokio task？</p><p>從上圖的 "Location" 列我們可以看到 task 被 spawn 的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb%2Fblob%2Fdevelop%2Fsrc%2Fcommon%2Fruntime%2Fsrc%2Fruntime.rs%23L63" target="_blank">地方</a>：</p><pre><code class="language-rust">impl Runtime {
    /// Spawn a future and execute it in this thread pool
    ///
    /// Similar to Tokio::runtime::Runtime::spawn()
    pub fn spawn&lt;F&gt;(&amp;self, future: F) -&gt; JoinHandle&lt;F::Output&gt;
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        self.handle.spawn(future)
    }
}
</code></pre><p>接下來的任務是找到 GreptimeDB 裏所有調用這個方法的代碼。</p><h2><code>..Default::default()</code>！</h2><p>經過一番看代碼的仔細排查，我們終於定位到了 Tokio task 泄漏的地方，並在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb%2Fpull%2F1512" target="_blank">PR #1512</a> 中修復了這個泄漏。簡單地説，就是我們在某個會被經常創建的 struct 的構造方法中，spawn 了一個可以在後台持續運行的 Tokio task，卻未能及時回收它。對於資源管理來説，在構造方法中創建 task 本身並不是問題，只要在 <code>Drop</code> 中能夠順利終止這個 task 即可。而我們的內存泄漏就壞在忽視了這個約定。</p><p>這個構造方法同時在該 struct 的 <code>Default::default()</code> 方法當中被調用了，更增加了我們找到根因的難度。</p><p>Rust 有一個很方便的，可以用另一個 struct 來構造自己 struct 的方法，即 "<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.rust-lang.org%2Fbook%2Fch05-01-defining-structs.html%23creating-instances-from-other-instances-with-struct-update-syntax" target="_blank">Struct Update Syntax</a>"。如果 struct 實現了 <code>Default</code>，我們可以簡單的在 struct 的 field 構造中使用 <code>..Default::default()</code>。如果 <code>Default::default()</code> 內部有 「side effect」（比如我們本次內存泄漏的原因——創建了一個後台運行的 Tokio task），一定要特別注意：struct 構造完成後，<code>Default</code> 創建出來的臨時 struct 就被丟棄了，一定要做好資源回收。</p><p>例如下面這個小例子：（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplay.rust-lang.org%2F%3Fversion%3Dstable%26mode%3Ddebug%26edition%3D2021%26gist%3Dc121ffd32d2ff0fa8e1241a62809bcef" target="_blank">Rust Playground</a>）</p><pre><code class="language-rust">struct A {
    i: i32,
}

impl Default for A {
    fn default() -&gt; Self {
        println!("called A::default()");
        A { i: 42 }
    }
}

#[derive(Default)]
struct B {
    a: A,
    i: i32,
}

impl B {
    fn new(a: A) -&gt; Self {
        B {
            a,
            // A::default() is called in B::default(), even though "a" is provided here.
            ..Default::default()
        }
    }
}

fn main() {
    let a = A { i: 1 };
    let b = B::new(a);
    println!("{}", b.a.i);
}
</code></pre><p>struct A 的 <code>default</code> 方法是會被調用的，打印出 <code>called A::default()</code>。</p><h2>總結</h2><ul><li>排查 Rust 程序的內存泄漏，我們可以用 jemalloc 的 heap profiling 導出 dump 文件；再生成火焰圖可直觀展現內存使用情況。</li><li>Tokio-console 可以方便地顯示出 Tokio runtime 的 task 運行情況；要特別注意不斷增長的 idle tasks。</li><li>儘量不要在常用 struct 的構造方法中留下有副作用的代碼。</li><li><code>Default</code> 只應該用於值類型 struct。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-3d33a6c61f7c37725020cbe267d0c2d0f01.jpg" alt="" referrerpolicy="no-referrer"></p><h3>關於 Greptime</h3><p>Greptime 格睿科技於 2022 年創立，目前正在完善和打造時序數據庫 GreptimeDB 和格睿雲 GreptimeCloud 這兩款產品。</p><p>GreptimeDB 是一款用 Rust 語言編寫的時序數據庫，具有分佈式、開源、雲原生、兼容性強等特點，幫助企業實時讀寫、處理和分析時序數據的同時，降低長期存儲的成本。</p><p>GreptimeCloud 基於開源的 GreptimeDB，為用户提供全託管的 DBaaS，以及與可觀測性、物聯網等領域結合的應用產品。利用雲提供軟件和服務，可以達到快速的自助開通和交付，標準化的運維支持，和更好的資源彈性。GreptimeCloud 已正式開放內測，歡迎關注公眾號或官網瞭解最新動態！</p><p>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreptime.com%2F" target="_blank">https://greptime.com/</a></p><p>公眾號：GreptimeDB</p><p>GitHub: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb" target="_blank">https://github.com/GreptimeTeam/greptimedb</a></p><p>文檔：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.com%2F" target="_blank">https://docs.greptime.com/</a></p><p>Twitter: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FGreptime" target="_blank">https://twitter.com/Greptime</a></p><p>Slack: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreptime.com%2Fslack" target="_blank">https://greptime.com/slack</a></p><p>LinkedIn: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fgreptime%2F" target="_blank">https://www.linkedin.com/company/greptime/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:23:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6839317/blog/11044292</guid>
            <link>https://my.oschina.net/u/6839317/blog/11044292</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Stability AI 發佈 Stable Diffusion 3 早期預覽版]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>AI 創業公司 Stability AI <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fnews%2Fstable-diffusion-3" target="_blank">宣佈</a></u>其最新一代的文本圖像模型 Stable Diffusion 3 開放預覽，該版本目前僅限部分用户參與測試，主要是為了在正式發佈前收集與性能和安全性相關的用户反饋。感興趣的用户可以申請加入等候名單。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3fa2fd390f1fbdd7808ee91a4ed1a0ef4fd.png" referrerpolicy="no-referrer"></p><p>Stable Diffusion 3 早期預覽版相比前代產品在圖片質量、多主題展示和文字展示方面有大幅提升。Stable Diffusion 3 模型的參數規模從 8 億，到 80 億不等，其架構組合了 diffusion transformer（擴散變換架構）和 flow matching（流匹配），技術報告將在晚些時候公佈。</p><p><img height="582" src="https://oscimg.oschina.net/oscnet/up-25784ed1b6a0b80ca5fc50b3c842456064f.png" width="3052" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-377f7b831888b11ab490f50cafe8931753d.png" referrerpolicy="no-referrer"></p><p>性能的具體提升內容包括：</p><ol><li>多主題提示處理能力： 新模型對於包含多個主題或元素的提示具有更好的理解和處理能力。這意味着用户可以在一個提示中描述更復雜的場景，而模型能夠更準確地根據這些描述生成圖像。</li><li>圖像質量： Stable Diffusion 3 在生成的圖像質量上有顯著提高，包括更細膩的細節表現、更準確的顏色匹配以及更自然的光影處理。這些改進使得生成的圖像更加逼真，更能捕捉到用户的創意意圖。</li><li>拼寫和文本處理能力： 這個版本在處理文本元素，尤其是在圖像中直接展現的文本（如標語、標籤等）時，有更好的拼寫能力和文本理解。這包括更準確地識別和渲染用户提示中的文字，甚至是在複雜的視覺背景中。</li></ol><p>Stable Diffusion 3 的性能提升不僅基於其先進的擴散變換架構，還包括了以下關鍵的技術創新和改進：</p><ol><li>新型擴散變換器： Stable Diffusion 3 採用了一種新型的擴散變換技術，與 Sora 類似，這種新技術為模型提供了更強大的圖像生成能力。 Transformer 是一種深度學習模型，專門設計來逐步構建圖像的細節，從而生成高質量的視覺內容。</li><li>流匹配與其他改進： 模型還整合了流匹配技術和其他技術改進，進一步增強了生成圖像的質量和多樣性。流匹配技術有助於模型更好地理解和模擬圖像中的動態元素和結構，使得生成的圖像在視覺上更加連貫和自然。</li><li>利用 Transformer 的改進： Stable Diffusion 3 充分利用了 Transformer 技術的最新進展，這不僅使模型能夠進一步擴展其能力，還使其能夠接受多模態輸入。這意味着模型能夠處理更復雜和多樣化的數據類型，如結合文本和圖像的輸入，從而在理解和生成圖像內容方面提供更大的靈活性和精確度。</li></ol><p>加入等候名單：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fstablediffusion3" target="_blank">https://stability.ai/stablediffusion3</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 23 Feb 2024 02:12:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279886/stable-diffusion-3-preview</guid>
            <link>https://www.oschina.net/news/279886/stable-diffusion-3-preview</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「未來產業劃定發展路線圖」出爐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>近日，工業和信息化部、科技部、交通運輸部、文化和旅遊部等部門</span><span>聯合印發</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMjM5OTUwMTc2OA%3D%3D%26mid%3D2650903280%26idx%3D1%26sn%3Db6edd0ce1c41aac431cd9f9a52eef8be%26chksm%3Dbccfb8578bb831412b6e96f801604afe81effbd68c11d7371507f00349b1b3accc4cc18e01b4%26scene%3D21%23wechat_redirect" target="_blank">《關於推動未來產業創新發展的實施意見》</a><span>，提出到 2025 年，未來產業技術創新、產業培育、安全治理等全面發展，部分領域達到國際先進水平，產業規模穩步提升；到 2027 年，未來產業綜合實力顯著提升，部分領域實現全球引領。</span></p><p>專家認為，《意見》充分把握全球科技創新和產業發展趨勢，前瞻部署了生物製造、量子信息、氫能、核能、基因和細胞技術等多個細分賽道，將全面支撐推進新型工業化，加快形成新質生產力。</p><p style="margin-left:0; margin-right:0"><strong><span>全面佈局新賽道</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>未來產業由前沿技術驅動，尚處於孕育萌發階段或產業化初期，是具有顯著戰略性、引領性、顛覆性和不確定性的前瞻性新興產業。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">當前，新一輪科技革命和產業變革加速演進，重大前沿技術、顛覆性技術持續湧現，科技創新和產業發展融合不斷加深，催生出元宇宙、人形機器人、腦機接口、量子信息等新產業發展方向。大力培育未來產業已成為引領科技進步、帶動產業升級、開闢新賽道、塑造新質生產力的戰略選擇。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">我國具備工業體系完整、產業規模龐大、應用場景豐富等綜合優勢，為未來產業發展提供了豐厚的土壤。各省（區、市）積極培育未來產業，北京、上海、江蘇、浙江等地出台了培育未來產業的政策文件。但我國未來產業發展也面臨系統謀劃不足、技術底座不牢等問題。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">針對這些問題，《意見》從技術創新、產品突破、企業培育、場景開拓、產業競爭力等方面提出到 2025 年和 2027 年的發展目標。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">賽迪研究院未來產業研究中心所長韓健介紹，到 2025 年要形成「一批+6 百」的目標體系，建設一批未來產業孵化器和先導區，突破百項前沿關鍵核心技術，形成百項標誌性產品，打造百家領軍企業，開拓百項典型應用場景，制定百項關鍵標準，培育百家專業服務機構，初步形成符合我國實際的未來產業發展模式。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">《意見》重在產業化落地。賽智產業研究院院長趙剛認為，《意見》提出以傳統產業的高端化升級和前沿技術的產業化落地為主線，力爭做到兩年「打基礎」，五年「大提升」，成為世界未來產業重要策源地。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">此外，《意見》還詳細規劃了六大方向超過 50 多個細分領域的未來產業發展，明確提出了下一代智能終端、信息服務產品、未來高端裝備三類標誌性產品發展路線。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">「設定未來產業發展目標既是我國推進新型工業化的自身現實需求，也是參與國際競爭的外部形勢要求。從自身需求看，是我國引領科技進步、帶動產業升級、培育新質生產力的戰略選擇；從外部需求看，是我國主動參與全球未來產業分工合作、深度融入全球創新網絡的必然選擇。」趙剛説。</p><p style="margin-left:0; margin-right:0"><strong><span>重點瞄準六大方向</span></strong></p><p><span>未來產業發展的核心是前沿技術創新突破。《意見》按照「技術創新—前瞻識別—成果轉化」的思路，提出面向未來製造、未來信息、未來材料、未來能源、未來空間、未來健康六大重點方向，實施國家科技重大項目和重大科技攻關，發揮國家實驗室、全國重點實驗室等創新載體作用，鼓勵龍頭企業牽頭成立創新聯合體，體系化推進關鍵核心技術攻關。</span></p><p>趙剛分析，與優勢產業、傳統產業、戰略性新興產業相比，未來產業有 3 個明顯特徵。未來產業技術創新不是漸進式微創新，而是前瞻性、顛覆性重大創新，例如未來信息產業中的通用人工智能和量子信息、未來健康產業中的基因工程、未來材料產業中的超導材料等技術創新；未來產業生產要素配置不是傳統要素線性疊加，而是現代要素相互融合和配置效率指數級提升，例如量子計算機能讓計算能力實現成千上萬倍增加；未來產業邊界不是界限清晰，而是呈現出不同產業跨界融合和智能化、綠色化等發展特徵，如智能製造、生物材料、人形機器人、腦機接口等。</p><p>對於這六大方向業內已有佈局。早在 2016 年，字節跳動公司就成立了人工智能實驗室，聚焦研究自然語言處理、機器學習、數據挖掘等方面。2023 年以來，字節跳動公司加碼人工智能應用研究，旗下產品不斷加入 AIGC（生成式人工智能）功能。比如，結合火山引擎智能創作雲的 AIGC 能力，火山引擎視頻雲在商品營銷、互動娛樂、在線教育、智能駕駛等場景引入數字人、虛擬直播間等，助力企業降本增效，提升用户體驗。</p><p>「技術創新是經濟長期持續增長的不竭動力，發展未來產業是高質量發展的前瞻性戰略佈局。今天對未來產業 20% 的投入和佈局，將為以後帶來 80% 的收益，從而建立起我國經濟高質量發展的長效創新機制。」趙剛説。</p><p style="margin-left:0; margin-right:0"><strong><span>打造標誌性創新產品</span></strong></p><p><span>《意見》提出，打造人形機器人、腦機接口、超大規模新型智算中心、第三代互聯網等十大創新標誌性產品。</span></p><p>趙剛分析，當顛覆式技術創新呈現出技術性能成倍提升、產品化成本大幅降低、應用場景廣泛等特徵後，創新產品就形成規模經濟效應，具有巨大的市場前景。</p><p>當前，滿足這 3 個特徵的標誌性產品主要有兩類。一是通用人工智能產品。由於以 ChatGPT 為代表的通用人工智能技術取得重大進展，圍繞通用人工智能技術創新形成的智能產品，如生成式人工智能產品、AI 手機和個人計算機、人形機器人、高級別智能網聯汽車、智能裝備、智能雲服務、超大規模新型智算中心等智能產品和服務就具有較好前景。二是生物科技產品。由於細胞和基因工程等技術取得突破性進展，生物科技創新產品工程化能力加速提升，具有很好的市場前景，如基因編輯、合成生物等。其他一些前瞻性技術儘管在實驗室獲得了成功，但離大規模產品化和商業化還有很大差距，例如量子信息技術創新。</p><p>國際數據公司 IDC 預測，人工智能電腦在中國個人計算機市場中新機的裝配比例將快速攀升，2027 年有望達 85%，成為市場主流。聯想集團副總裁、中國區戰略及業務拓展副總裁阿不力克木·阿不力米提表示，人工智能電腦是自然語言交互的個人 AI 助理。在過去 40 年發展歷程中，聯想不斷推出變革用户體驗的產品，未來還將和生態夥伴攜手實現人工智能電腦快速普及，讓 AI 惠及每一個人。</p><p>目前我國算力總規模排名全球第二位。但從結構看，通用算力佔了大半，高性能算力佔比有待提升。浪潮信息高級副總裁劉軍表示，高質量算力採用先進的計算架構，具備高算效、高能效、可持續、可獲得、可評估五大特徵。其中，高算效是實測性能與資源利用率雙重提升，是算力供需失衡、算力利用率低等矛盾的破解之道。而高能效是在最低碳排放前提下實現最大化算力輸出，確保能源利用最優解。</p><p>腦機接口作為十大標誌性產品之一，近年來在電極、算法、芯片等方面取得了重要進展。2023 年 9 月，中國信息通信研究院雲計算與大數據研究所牽頭在人工智能醫療器械創新合作平台成立腦機接口研究工作組。</p><p>中國信通院雲計算與大數據研究所副所長閔棟介紹，腦機接口可應用於醫療、娛樂、智能生活、教育等領域。其中，醫療領域是主要陣地。腦機接口與醫療結合展現出廣闊應用前景，為相關疾病診療和康復提供了全新手段。此外，腦機接口還可與虛擬現實、人機交互、人工智能等技術結合推動現有產業變革，如腦機接口應用於工業領域，可幫助人們通過意念操控機器人、無人車、工業產線等設備。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">未來產業潛在價值巨大，需要資本持續投入。趙剛建議，要推動製造業轉型升級基金、國家中小企業發展基金等加大投入，也可適時組建國家未來產業發展基金，並引導地方設立未來產業專項資金，發揮政府引導基金的引導性作用，吸引社會資本共同投資未來產業。同時，完善金融財税支持政策。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 05:58:15 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279756</guid>
            <link>https://www.oschina.net/news/279756</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[夜鶯監控 V7 第一個 beta 版本來了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>夜鶯項目從 2024 開始開發 V7 版本，重點做體驗優化，V7 和 V6 版本兼容可以平滑升級<span style="background-color:#ffffff; color:#333333">（V6 升級到 V7 只需要替換一下二進制重啓即可，如果是容器部署，只需要更新鏡像並重啓）</span>，今天發佈第一個 beta，此 beta 版本的優化項包括：</p><ul><li>全站暗黑主題</li><li>優化邊緣機房機器失聯告警的實現邏輯，真正做到邊緣機房告警自閉環</li><li>優化內置大盤、內置告警規則的列表頁面 UI</li><li>全局回調地址頁面展示優化，增加詳盡的文檔提示信息</li></ul><p><span style="background-color:#ffffff; color:#333333">更多優化項正在開發中，V5、V6 用户可以放心升級，V7 會是一個更好的版本。升級之前記得備份以防萬一。</span></p><h2>項目介紹</h2><p style="color:#333333; text-align:left">夜鶯監控是一款開源雲原生觀測分析工具，採用 All-in-One 的設計理念，集數據採集、可視化、監控告警、數據分析於一體，與雲原生生態緊密集成，提供開箱即用的企業級監控分析和告警能力。夜鶯於 2020 年 3 月 20 日，在 github 上發佈 v1 版本，已累計迭代 100 多個版本。</p><p style="color:#333333; text-align:left">夜鶯最初由滴滴開發和開源，並於 2022 年 5 月 11 日，捐贈予中國計算機學會開源發展委員會（CCF ODC），為 CCF ODC 成立後接受捐贈的第一個開源項目。夜鶯的核心研發團隊，也是 Open-Falcon 項目原核心研發人員，從 2014 年（Open-Falcon 是 2014 年開源）算起來，也有 10 年了，只為把監控這個事情做好。</p><h2>項目截圖</h2><p style="color:#333333; text-align:left"><img alt="20240221141801" src="https://download.flashcat.cloud/ulric/20240221141801.png" referrerpolicy="no-referrer"></p><p style="color:#333333; text-align:left"><img alt="20240221141817" src="https://download.flashcat.cloud/ulric/20240221141817.png" referrerpolicy="no-referrer"></p><h2>項目代碼</h2><ul><li>後端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank">💡 https://github.com/ccfos/nightingale</a></li><li>前端：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fn9e%2Ffe" target="_blank">💡 https://github.com/n9e/fe</a></li></ul><p style="color:#333333; text-align:left">夜鶯項目已收穫 8000 多 github stars，1000 多 forks，100 多 contributors 參與其中，歡迎大家在<span>&nbsp;</span><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale" target="_blank"><strong>GitHub</strong></a></strong><span>&nbsp;</span>上關注夜鶯項目，及時獲取項目更新動態，有任何問題，也歡迎提交 issues，以及提交 pull requests，開源社區需要大家一起參與才能有蓬勃的生命力。</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 04:15:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</guid>
            <link>https://www.oschina.net/news/279741/nightingale-7-0-0-beta-0-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報：等到 Sora 開源了立刻推出屬於我們自己的大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.21</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/279326/linux-kernel-is-a-cna" target="_blank">2023 年度 Rust 調查報告</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">有 93% 的受訪者稱自己是 Rust 用户，其中 49% 的人每天（或幾乎每天）都會使用 Rust，相較上一年小幅增加 2 個百分點。在沒有使用 Rust 的用户中，31% 的人表示主要原因時使用 Rust 有難度；67% 的人表示他們還沒有機會優先學習 Rust，這也是最常見的原因。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><img alt="" height="429" src="https://oscimg.oschina.net/oscnet/up-335afef97d65f03d34d0f08eb8831153557.png" width="500" referrerpolicy="no-referrer"></span></p><h3><a href="https://www.oschina.net/news/279389/dart-3-3-released" target="_blank">Go 1.22 正式發佈</a></h3><p>Go 1.22 中新增的優化之一是改進了虛擬化，允許靜態調度更多的接口方法調用。啓用 PGO 後，大多數程序的性能將提高 2% 至 14%。 此外，Go 運行時中的內存優化可將 CPU 性能提高 1-3%，同時還可將大多數 Go 程序的內存開銷減少約 1%。</p><p>新的 math/rand/v2 軟件包提供了更簡潔、更一致的應用程序接口，並使用了質量更高、速度更快的偽隨機生成算法。&nbsp;</p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-9fc6f45ad8365450e0980fe7fe1855a56c5.png" referrerpolicy="no-referrer"></p><p>- 微博 <u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6640496217%2FO1tM7BenZ" target="_blank">-赤犬龍之介-</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-d423a4b13075c233da7226ccd5235dc0a3e.png" referrerpolicy="no-referrer"></p><p>-&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2F8XMQgC7LlaK" target="_blank">21 世紀經濟報道</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-25f6c0a5f5becd775a0ad6bd1080893da87.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-bbc6216c930e22f859d514d8becc057daae.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p>Gitee 榜單：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5ab4f59bdf01add8c61aac9c617fa074d2c.png" referrerpolicy="no-referrer"></p><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:47:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279735</guid>
            <link>https://www.oschina.net/news/279735</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[數百位名人簽署公開信，呼籲制定反深度偽造立法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>數百名 AI 界人士簽署了一封<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">公開信</a>，呼籲嚴格監管 AI 生成的冒名頂替或深度偽造（Deepfake）內容。</p><p><img height="274" src="https://oscimg.oschina.net/oscnet/up-df56f62fff93b887bf1198aca4ccf4bcb5e.png" width="500" referrerpolicy="no-referrer"></p><p>公開信指出，"深度偽造"是指未經同意或嚴重誤導的人工智能生成的聲音、圖像或視頻，合理的人會誤以為是真實的。這不包括對圖像或聲音的輕微改動，也不包括容易識別為合成的無害娛樂或諷刺。</p><p>如今，深度偽造通常涉及性圖像、欺詐或政治虛假信息。由於人工智能發展迅速，使得深度偽造變得更加容易，因此我們需要為數字基礎設施的運行和完整性提供保障。「Deepfakes 對社會的威脅日益嚴重，政府必須在整個供應鏈中施加義務，以阻止 Deepfakes 的擴散。」</p><p>信中呼籲：</p><ul><li>將深度偽造的兒童性虐待材料（CSAM，又名兒童色情製品）完全定為刑事犯罪，無論所描繪的人物是真實的還是虛構的。</li><li>在任何情況下，如果有人制造或傳播有害的深度偽造品，都需要受到刑事處罰。</li><li>要求軟件開發商和分銷商防止其音頻和視頻產品被用於製造有害的深度偽造品，如果他們的預防措施不充分，就要承擔責任接受處罰。</li></ul><p>他們認為，如果設計得當，這些法律可以在不會造成過重負擔的同時，培育有社會責任感的企業。</p><p>這封信中較為知名的簽名者包括：</p><ul><li>Jaron Lanier</li><li>Frances Haugen</li><li>Stuart Russell</li><li>Andrew Yang</li><li>Marietje Schaake</li><li>Steven Pinker</li><li>Gary Marcus</li><li>Oren Etzioni</li><li>Genevieve smith</li><li>Yoshua Bengio</li><li>Dan Hendrycks</li><li>Tim Wu</li></ul><p>事實上，這也不是首次出現相關的呼籲。在本月早些時候正式提出之前，歐盟已就此類措施進行了多年辯論。外媒 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F02%2F21%2Fhundreds-of-ai-luminaries-sign-letter-calling-for-anti-deepfake-legislation%2F" target="_blank">TechCrunch</a> 指出，也許正是歐盟願意進行審議和落實，才激活了這些研究人員、創作者和管理人員的發言權。雖然此舉不一定能推動真正的立法，但它確實是業界專家們如何看待這一爭議問題的風向標。</p><p>更多詳情可查看此處：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenletter.net%2Fl%2Fdisrupting-deepfakes" target="_blank">https://openletter.net/l/disrupting-deepfakes</a>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:32:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279733/disrupting-deepfakes</guid>
            <link>https://www.oschina.net/news/279733/disrupting-deepfakes</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[出門問問創始人李志飛點評谷歌開源大模型 Gemma：差點意思]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌在北京時間昨晚發佈了<u><a href="https://www.oschina.net/news/279713/google-gemma-open-models">開源大模型 Gemma</a></u>，對標 Meta 旗下 Llama 2。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><p>出門問問創始人李志飛發表文章點評，<strong>稱 Gemma 推出時間有點晚、開源力度不夠、未放下高貴的頭顱</strong>。</p><p>李志飛在文章中表示，相比於去年上半年就開源，現在可能要花數倍的努力進行模型的差異化以及推廣的投入，才有可能在眾多開源模型中脱穎而出。「面對 OpenAI 的強力競爭，只有殺敵一千、自損一千五。」</p><p>以下為李志飛全文：</p><blockquote><p>看到 Google 開源了小的語言模型 Gemma，直接狙擊 Llama 2，回顧去年 5 月對 Google 關於開源和競爭的看法，幾點思考如下：</p><p>1. 時間有點晚：相比於去年上半年就開源，現在可能要花數倍的努力進行模型的差異化以及推廣的投入，才有可能在眾多開源模型中脱穎而出。</p><p>2. 開源力度不夠：感覺這次開源還是被動防禦和略顯扭捏的應對之策，不是進攻。比如説，開個 7B 的模型實在是太小兒科了，一點殺傷力都沒有。應該直接開源一個超越市場上所有開源的至少 100B 的模型、1M 的超長上下文、完善的推理 infra 方案、外加送一定的 cloud credit。是的，再不歇斯底里 Google 真的就晚了。面對 OpenAI 的強力競爭，只有殺敵一千、自損一千五。</p><p>3. 未放下高貴的頭顱：有種感覺，Google 覺得自己還是 AI 王者，放不下高貴的頭顱，很多發佈都有點不痛不癢，還是沿着過去研發驅動的老路而不是產品和競爭驅動，比如不停發論文、取新名字（多模態相關模型過去半年就發了 Palme、RT-2、Gemini、VideoPoet、W.A.L.T 等）、發佈的模型又完整度不夠，感覺就沒有一個絕對能打的產品。Google 可能要意識到在公眾眼中，他在 AI 領域已經是廉頗老矣潰不成軍，經常起大早趕晚集（比如説這次 Sora 借鑑的 ViT、ViViT、NaVit、MAGVit 等核心組件技術都是它家寫的論文）。</p><p>4. 希望亡羊補牢未為晚也：Google 作為一個僵化的大公司，動作慢一點可以理解，但是如果再不努力是不是就是 PC 互聯網的 IBM、移動互聯網的 Microsoft？ 作為 Google 的鐵粉，還是希望他能打起精神一戰，AI 產業需要強力的競爭才能不停向前發展，也需要他在前沿研究和系統的開源才能幫助一大眾「貧窮」的 AI 創業公司。</p><p>5. 另外，除了對外開源外，Google 應該組成三個方陣面對大模型的競爭，詳見去年 3 月發文。</p><p>回顧科技競爭史，PC 互聯網時代的 IBM、移動互聯網時代的 Microsoft、AGI 時代的 Google，新時代來臨後，難道上一個時代科技霸主都難逃衰落的宿命？</p><p>當然，Microsoft 靠 Office SaaS、雲和 OpenAI 又翻盤了。</p><p>歷史的鐵律，有被改寫的可能嗎？</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 03:15:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279728</guid>
            <link>https://www.oschina.net/news/279728</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 員工的一天]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Chain Of Thought (CoT) 第一作者、從谷歌跳槽到 OpenAI 的 Jason Wei 分享了自己在 OpenAI 的一天：</p><blockquote><p>[9:00am] 起牀</p><p>[9:30am] 搭乘 Waymo 前往 Mission SF，途中在 Tartine 買個牛油果吐司</p><p>[9:45am] 背誦 OpenAI 章程。向優化之神致敬，學習《The Bitter Lession》（強化學習之父 Rich Sutton 著）</p><p>[10:00am] 在 Google Meet 上開會，討論如何在更多數據上訓練更大的模型</p><p>[11:00am] 敲代碼，在更多數據上訓練更大的模型。搭檔是 Hyung Won Chung</p><p>[12:00pm] 去食堂吃午飯（純素且無麩質）</p><p>[1:00pm] 真正開始在大量數據上訓練大模型</p><p>[2:00pm] 處理基礎設施問題（我是腦子被驢踢了嗎為啥要從 master 分支拉代碼？）</p><p>[3:00pm] 監控模型訓練進度，玩 Sora</p><p>[4:00pm] 給剛才訓練的大模型上提示工程</p><p>[4:30pm] 短暫休息，坐在牛油果椅子上，思考 Gemini Ultra 的性能到底有多強</p><p>[5:00pm] 頭腦風暴模型可能的算法改進</p><p>[5:05pm] 修改算法風險太高，pass。最安全的策略還是力大磚飛（增加算力和數據規模）</p><p>[6:00pm] 晚餐時間，和 Roon 一起享用蛤蜊濃湯</p><p>[7:00pm] 回家</p><p>[8:00pm] 喝點小酒，繼續寫碼。Ballmer’s peak（酒精帶來的編碼高效階段）即將到來</p><p>[9:00pm] 分析實驗結果，我對 wandb 又愛又恨</p><p>[10:00pm] 啓動實驗，讓它自己跑一晚上，第二天查看結果</p><p>[1:00am] 實驗真正開始運行</p><p>[1:15am] 上牀睡覺。在納德拉和黃仁勳的守護下入夢。心想：壓縮才是真諦。晚安</p><p><img src="https://oscimg.oschina.net/oscnet/up-3041206e9fa5084776ebedb71c760828888.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2F_jasonwei%2Fstatus%2F1760032264120041684" target="_blank">https://twitter.com/_jasonwei/status/1760032264120041684</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279722</guid>
            <link>https://www.oschina.net/news/279722</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[StarkNet 撒錢，程序員在 Web3 領了 14 萬 ​​​]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>StarkNet 啓動空投活動，GitHub 排名前 5000 開源項目的貢獻者可領取價值 $200 獎勵。</p><h2>背景</h2><ul><li>StarkNet 公鏈項目為了激勵開發者參與其平台建設，啓動了空投活動。</li><li>如果曾向 GitHub 上獲得較多 Star 的項目提交過 PR ，就有資格領取 111.1 STRK 的空投獎勵。</li><li>只需要使用 OAuth 2.0 登錄，就可以直接領取。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-44f62dafa84c34781d15d46c71c7c8c862c.jpg" referrerpolicy="no-referrer"></p><p>有程序員曬出自己在這次空投活動獲得的獎勵——近 14 萬人民幣。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-96e62f68c4891cdbfd1f43b86ddfcdcbf79.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fstrrlthedev%2Fstatus%2F1760182038504837287" target="_blank">https://twitter.com/strrlthedev/status/1760182038504837287</a></u></em></p></blockquote><h2>領取規則</h2><ol><li>截止到 2023 年 11 月 15 日，至少對全球排名前 5000 的倉庫提交過三次代碼貢獻。</li><li>其中至少有一次貢獻是在 2018 年或之後完成的。</li></ol><h2>領取步驟</h2><p>領取地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprovisions.starknet.io%2F" target="_blank">https://provisions.starknet.io/</a></u></em></p><ol><li>訪問獎勵領取頁面並連接錢包（推薦使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2Fargent-x-starknet-wallet%2Fdlcobpjiigpikoobohmabehhmhfoodbb" target="_blank">Argent X</a>）。</li><li>通過 GitHub 登錄，採用 OAuth 2.0 驗證方式。</li><li>直接領取獎勵。後續的治理投票和問卷調查可忽略不計。</li></ol></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279720</guid>
            <link>https://www.oschina.net/news/279720</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為：2 月 26 日將首發華為通信大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">華為官方微信公眾號消息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7dnrCXQoOqWSfKBrCJWl6Q" target="_blank">顯示</a>， 在 2 月 26 日華為產品與解決方案發佈會上，即將首發華為通信大模型。</span></p><p><img height="677" src="https://oscimg.oschina.net/oscnet/up-59659387ba8ade9e0cf71c6f84d476a728e.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">華為稱，2024 年，5G-A 商用元年正式開啓！萬兆時代已來，共同見證將 5G-A 帶入現實。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:23:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279717</guid>
            <link>https://www.oschina.net/news/279717</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌發佈輕量級開源大語言模型 Gemma]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌發佈了開源大語言模型 Gemma，這是一款輕量級、先進的開源模型，供開發者和研究人員用於 AI 構建。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb557d3a75a71eccd7300352b8e419f6dd5.png" referrerpolicy="no-referrer"></p><p>Gemma 模型家族包括 2B（20 億參數）和 7B（70 億參數）兩種尺寸，能夠在不同的設備類型上運行，包括筆記本電腦、桌面電腦、IoT 設備、移動設備和雲端。</p><p><strong>性能和設計</strong></p><p>Gemma 模型在技術和基礎設施組件上與 Gemini 共享，這使得 Gemma 2B 和 7B 在其大小範圍內相比其他開放模型具有最佳性能。</p><p>Gemma 模型不僅可以直接在開發者的筆記本電腦或桌面電腦上運行，而且在關鍵基準測試中的表現超過了更大的模型，同時遵循嚴格的安全和負責任輸出標準。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-50f9213a30f71b22bb88d2abb40a2f7a116.png" referrerpolicy="no-referrer"></p><p><strong>主要特點</strong></p><ol><li><strong>輕量級、高性能模型</strong>：Gemma 模型家族包括 Gemma 2B 和 Gemma 7B 兩種尺寸，提供預訓練和指令調優的變體，針對其大小範圍內相比其他開放模型具有最佳性能。</li><li><strong>跨框架工具鏈支持</strong>：支持 JAX、PyTorch 和 TensorFlow 通過原生 Keras 3.0 進行推理和監督式微調（SFT），適應多種開發需求和環境。</li><li><strong>易於入門和集成</strong>：提供準備就緒的 Colab 和 Kaggle 筆記本，以及與 Hugging Face、MaxText、NVIDIA NeMo 和 TensorRT-LLM 等流行工具的集成，方便開發者快速上手。</li><li><strong>高效的運算能力</strong>：針對多個 AI 硬件平台上進行優化，確保在 NVIDIA GPU 和 Google Cloud TPU 上的行業領先性能。通過與 NVIDIA 的合作，無論是在數據中心、雲端還是本地 RTX AI PC 上，都確保了行業領先的性能和與尖端技術的集成。</li></ol><p>Gemma 模型能夠在不同的設備類型上運行，包括筆記本電腦、桌面電腦、IoT 設備、移動設備和雲端。這種廣泛的兼容性使得模型能夠適應各種應用場景和需求。</p><ul><li><span>模型地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmodels%3Fother%3Dgemma%26sort%3Dtrending%26search%3Dgoogle" target="_blank">https://huggingface.co/models?other=gemma&amp;sort=trending&amp;search=google…</a><span></span></li><li><span>博客：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fdevelopers%2Fgemma-open-models%2F" target="_blank">https://blog.google/technology/developers/gemma-open-models/</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:17:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279713/google-gemma-open-models</guid>
            <link>https://www.oschina.net/news/279713/google-gemma-open-models</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[你好，iLogtail 2.0！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者：張浩翔（篤敏）</p><h2>概述</h2><p>隨着可觀測數據採集需求的不斷推陳出新，多樣化的數據輸入輸出選項、個性化的數據處理能力組合、以及高性能的數據處理吞吐能力已經成為頂流可觀測數據採集器的必備條件。然而，由於歷史原因，現有的 iLogtail 架構和採集配置結構已經無法繼續滿足上述需求，逐漸成為制約 iLogtail 繼續向前快速演進的瓶頸：</p><p>▶︎ iLogtail 設計之初完全面向文件日誌採集至日誌服務的場景：</p><p>1）簡單地將日誌分為多種格式，每種格式的日誌僅支持一種處理方式（如正則解析、Json 解析等）；</p><p>2）功能實現與日誌服務相關概念（如 Logstore 等）強綁定；</p><p>基於此設計思想，現有的 iLogtail 架構偏向於單體架構，導致模塊間耦合嚴重，可擴展性和普適性較差，難以提供多個處理流程級聯的能力。</p><p>▶︎ Golang 插件系統的引入極大地擴展了 iLogtail 的輸入輸出通道，且一定程度提升了 iLogtail 的處理能力。然而，囿於 C++ 部分的實現，輸入輸出與處理模塊間的組合能力仍然嚴重受限：</p><p>1）C++ 部分原生的高性能處理能力仍然僅限於採集日誌文件並投遞至日誌服務的場景使用；</p><p>2）C++ 部分的處理能力無法與插件系統的處理能力相結合，二者只能選其一，從而降低了複雜日誌處理場景的性能。</p><p>▶︎ 與 iLogtail 整體架構類似，現有的 iLogtail 採集配置結構也採用平鋪結構，缺乏處理流水線的概念，無法表達處理流程級聯的語義。</p><p>基於上述原因，在 iLogtail 誕生 10 週年之際，日誌服務啓動對 iLogtail 的升級改造，寄希望於讓 iLogtail 的易用性更佳，性能更優，可擴展性更強，從而更好地服務廣大用户。</p><p>目前，經過半年多的重構與優化，iLogtail 2.0 已經呼之欲出。接下來，就讓我們來搶先了解一下 iLogtail 2.0 的新特性吧！</p><h2>新特性</h2><h3>（一）【商業版】採集配置全面升級流水線結構</h3><p>為瞭解決舊版採集配置平鋪結構無法表達複雜採集行為的問題，iLogtail 2.0 全面擁抱新版流水線配置，即每一個配置對應一條處理流水線，包括輸入模塊、處理模塊和輸出模塊，每個模塊由若干個插件組成，各模塊的插件功能如下：</p><ul><li><strong>輸入插件：</strong> 用於從指定輸入源獲取數據（各插件具體功能詳見輸入插件 <strong>[</strong><strong>1]</strong> ）</li><li><strong>處理插件：</strong> 用於對日誌進行解析和處理（各插件具體功能詳見處理插件 <strong>[</strong><strong>2]</strong> ），可進一步分為原生處理插件和擴展處理插件</li></ul><p>&lt;!----&gt;</p><ul><li>原生處理插件：性能較優，適用於大部分業務場景，推薦優先使用</li><li>擴展處理插件：功能覆蓋更廣，但性能劣於原生處理插件，建議僅在原生處理插件無法完成全部處理需求時使用</li></ul><p>&lt;!----&gt;</p><ul><li><strong>輸出插件：</strong> 用於將處理後的數據發送至指定的存儲</li></ul><p>我們可以用一個 JSON 對象來表示一個流水線配置：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f6cc95f0ae9e478bd8c674f6fae4ee9ceb9.png" alt="" referrerpolicy="no-referrer"></p><p>其中，inputs、processors 和 flushers 即代表輸入、處理和輸出模塊，列表中的每一個元素 {...} 即代表一個插件；global 代表流水線的一些配置。有關流水線配置結構的具體信息，可參見 iLogtail 流水線配置結構 <strong>[</strong><strong>3]</strong> 。</p><blockquote><p>示例：採集 /var/log 目錄下的 test.log，對日誌進行 json 解析後發送到日誌服務。以下是實現該採集需求對應的舊版和新版配置，可以看到新版配置十分精煉，執行的操作一目瞭然。</p><p><strong>舊版配置：</strong></p><pre><code>{
&nbsp;&nbsp;&nbsp;&nbsp;"configName":&nbsp;"test-config",
&nbsp;&nbsp;&nbsp;&nbsp;"inputType":&nbsp;"file",
&nbsp;&nbsp;&nbsp;&nbsp;"inputDetail":&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"topicFormat":&nbsp;"none",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"priority":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logPath":&nbsp;"/var/log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filePattern":&nbsp;"test.log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"maxDepth":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"tailExisted":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"fileEncoding":&nbsp;"utf8",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logBeginRegex":&nbsp;".*",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerFile":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerIncludeLabel":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerExcludeLabel":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerIncludeEnv":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"dockerExcludeEnv":&nbsp;{},
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"preserve":&nbsp;true,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"preserveDepth":&nbsp;1,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"delaySkipBytes":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"delayAlarmBytes":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logType":&nbsp;"json_log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"timeKey":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"timeFormat":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"adjustTimezone":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logTimezone":&nbsp;"",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filterRegex":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"filterKey":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"discardNonUtf8":&nbsp;false,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"sensitive_keys":&nbsp;[],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"mergeType":&nbsp;"topic",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"sendRateExpire":&nbsp;0,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"maxSendRate":&nbsp;-1,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"localStorage":&nbsp;true
&nbsp;&nbsp;&nbsp;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;"outputType":&nbsp;"LogService",
&nbsp;&nbsp;&nbsp;&nbsp;"outputDetail":&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"logstoreName":&nbsp;"test_logstore"
&nbsp;&nbsp;&nbsp;&nbsp;}
}
</code></pre><p><strong>新版流水線配置：</strong></p><pre><code>{
&nbsp;&nbsp;&nbsp;&nbsp;"configName":&nbsp;"test-config",
&nbsp;&nbsp;&nbsp;&nbsp;"inputs":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"file_log",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"FilePaths":&nbsp;"/var/log/test.log"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;"processors":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_json_native"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"content"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;],
&nbsp;&nbsp;&nbsp;&nbsp;"flushers":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"flusher_sls",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Logstore":&nbsp;"test_logstore"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;]
}
</code></pre><p>如果在執行 json 解析後需要進一步處理，在流水線配置中只需額外增加一個處理插件即可，但是在舊版配置中已經無法表達上述需求。</p></blockquote><p>有關新版流水線配置和舊版配置的兼容性問題，請參見文末兼容性説明板塊。</p><h4>全新 API</h4><p>為了支持流水線配置，同時區分舊版配置結構，我們提供了全新的用於管理流水線配置的 API 接口，包括：</p><ul><li>CreateLogtailPipelineConfig</li><li>UpdateCreateLogtailPipelineConfig</li><li>GetLogtailPipelineConfig</li><li>DeleteLogtailPipelineConfig</li><li>ListLogtailPipelineConfig</li></ul><p>有關這些接口的詳細信息，請參見 OpenAPI 文檔 <strong>[</strong><strong>4]</strong> 。</p><h4>全新控制枱界面</h4><p>與流水線採集配置結構相對應，前端控制枱界面也進行了全新升級，分為了全局配置、輸入配置、處理配置和輸出配置。</p><p><img src="https://oscimg.oschina.net/oscnet/up-52a9a2935a7738f4ddd6cc8123ae3551f2d.png" alt="" referrerpolicy="no-referrer"></p><p>與舊版控制枱界面相比，新版控制枱具有如下特點：</p><p><strong>參數內聚：</strong> 某一功能相關的參數集中展示，避免了舊版控制枱參數散落各處出現漏配置。</p><blockquote><p>示例：最大目錄監控深度與日誌路徑中的**密切相關，舊版界面中，二者分隔較遠，容易遺忘；在新版界面中，二者在一起，便於理解。</p><p><strong>舊版控制枱：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-04d5bc90063cbedb86c8049d54635e3023c.png" alt="" referrerpolicy="no-referrer"></p><p><strong>新版控制枱：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-b559b0e4ad0b5877d16aa684f9ba4d50d00.png" alt="" referrerpolicy="no-referrer"></p></blockquote><p><strong>所有參數均為有效參數：</strong> 在舊版控制枱中，啓用插件處理後，部分控制枱參數會失效，從而引起不必要的誤解。新版控制枱所有參數均為有效參數。</p><h4>全新 CRD</h4><p>同樣，與新版採集配置對應，K8s 場景中與採集配置對應的 CRD 資源也全新升級。與舊版 CRD 相比，新版 CRD 具有如下特點：</p><ul><li>支持新版流水線採集配置</li><li>CRD 類型調整為 Cluster 級別，且將 CRD 名稱直接作為採集配置名稱，避免同一集羣多個不同的 CRD 資源指向同一個採集配置引起衝突</li><li>對所有操作的結果進行定義，避免出現多次操作舊版 CRD 後出現的行為未定義情況</li></ul><pre><code>apiVersion:&nbsp;log.alibabacloud.com/v1alpha1
kind:&nbsp;ClusterAliyunLogConfig
metadata:
&nbsp;&nbsp;name:&nbsp;test-config
spec:
&nbsp;&nbsp;project:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-project
&nbsp;&nbsp;logstore:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-logstore
&nbsp;&nbsp;machineGroup:
&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;test-machine_group
&nbsp;&nbsp;config:
&nbsp;&nbsp;&nbsp;&nbsp;inputs:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Type:&nbsp;input_file
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FilePaths:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;/var/log/test.log
&nbsp;&nbsp;&nbsp;&nbsp;processors:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;Type:&nbsp;processor_parse_json_native
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SourceKey:&nbsp;content
</code></pre><h3>（二）處理插件組合更加靈活</h3><p>對於文本日誌採集場景，當您的日誌較為複雜需要多次解析時，您是否在為只能使用擴展處理插件而困惑？是否為因此帶來的性能損失和各種不一致問題而煩惱？</p><p>升級 iLogtail 2.0，以上問題都將成為過去！</p><p>iLogtail 2.0 的處理流水線支持全新級聯模式，和 1.x 系列相比，有以下能力升級：</p><ul><li><p><strong>原生處理插件可任意組合：</strong></p><p>原有原生處理插件間的依賴限制不復存在，您可以隨意組合原生處理插件以滿足您的處理需求。</p></li><li><p><strong>原生處理插件和擴展處理插件可同時使用：</strong></p><p>對於複雜日誌解析場景，如果僅用原生處理插件無法滿足處理需求，您可進一步添加擴展處理插件進行處理。</p></li></ul><p><strong>🔔 注意：</strong> 擴展處理插件只能出現在所有的原生處理插件之後，不能出現在任何原生處理插件之前。</p><blockquote><p>示例：假如您的文本日誌為如下內容：</p><p>{"time": "2024-01-22T14:00:00.745074", "level": "warning", "module": "box", "detail": "127.0.0.1 GET 200"}</p><p>您需要將 time、level 和 module 字段解析出來，同時還需要將 detail 字段做進一步正則解析，拆分出 ip、method 和 status 字段，最後丟棄 drop 字段，則您可以按順序使用「Json 解析原生處理插件」、「正則解析原生處理插件」和「丟棄字段擴展處理插件」完成相關需求：</p><p>【商業版】</p><p><img src="https://oscimg.oschina.net/oscnet/up-6310f6b8a781ce3e256042e7f44ed09a75d.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c5dea6cb6a41a50be2f5eb48e2dbeeda960.png" alt="" referrerpolicy="no-referrer"></p><p>【開源版】</p><pre><code>{
&nbsp;&nbsp;"configName":&nbsp;"test-config"
&nbsp;&nbsp;"inputs":&nbsp;[...],
&nbsp;&nbsp;"processors":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_json_native",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"content"
&nbsp;&nbsp;&nbsp;&nbsp;},
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_parse_regex_native",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"SourceKey":&nbsp;"detail",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Regex":&nbsp;"(\S)+\s(\S)+\s(.*)",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Keys":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"ip",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"method",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"status"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Type":&nbsp;"processor_drop",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"DropKeys":&nbsp;[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"module"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;],
&nbsp;&nbsp;"flushers":&nbsp;[...]
}
</code></pre><p>採集結果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f272a5d2ade5c817461bf406d1a73836f89.png" alt="" referrerpolicy="no-referrer"></p></blockquote><h3>（三）新增 SPL 處理模式</h3><p>除了使用處理插件組合來處理日誌，iLogtail 2.0 還新增了 SPL（SLS Processing Language）處理模式，即使用日誌服務提供的用於統一查詢、端上處理、數據加工等的語法，來實現端上的數據處理。使用 SPL 處理模式的優勢在於：</p><ul><li>擁有豐富的工具和函數：支持多級管道操作，內置功能豐富的算子和函數</li><li>上手難度低：低代碼，簡單易學</li><li>【商業版】統一語法：一個語言玩轉日誌採集、查詢、加工和消費</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-4513da15197b25b1099a5707d39a222214d.png" alt="" referrerpolicy="no-referrer"></p><h4>SPL 語法</h4><h5>整體結構：</h5><ul><li>指令式語句，支持結構化數據和非結構化數據統一處理</li><li>管道符（|）引導的探索式語法，複雜邏輯編排簡便</li></ul><pre><code>&lt;data-source&gt;&nbsp;
|&nbsp;&lt;spl-cmd&gt;&nbsp;-option=&lt;option&gt;&nbsp;-option&nbsp;...&nbsp;&lt;expression&gt;,&nbsp;...&nbsp;as&nbsp;&lt;output&gt;,&nbsp;...
|&nbsp;&lt;spl-cmd&gt;&nbsp;...
|&nbsp;&lt;spl-cmd&gt;&nbsp;...
</code></pre><h5>結構化數據 SQL 計算指令：</h5><ul><li>where&nbsp;通過 SQL 表達式計算結果產生新字段</li><li>extend&nbsp;根據 SQL 表達式計算結果過濾數據條目</li></ul><pre><code>*
|&nbsp;extend&nbsp;latency=cast(latency&nbsp;as&nbsp;BIGINT)
|&nbsp;where&nbsp;status='200'&nbsp;AND&nbsp;latency&gt;100
</code></pre><h5>非結構化數據提取指令：</h5><ul><li>parse-regexp&nbsp;提取指定字段中的正則表達式分組匹配信息</li><li>parse-json&nbsp;提取指定字段中的第一層 JSON 信息</li><li>parse-csv&nbsp;提取指定字段中的 CSV 格式信息</li></ul><pre><code>*
|&nbsp;project-csv&nbsp;-delim='^_^'&nbsp;content&nbsp;as&nbsp;time,&nbsp;body
|&nbsp;project-regexp&nbsp;body,&nbsp;'(\S+)\s+(\w+)'&nbsp;as&nbsp;msg,&nbsp;user
</code></pre><h3>（四）日誌解析控制更加精細</h3><p>對於原生解析類插件，iLogtail 2.0 提供了更精細的解析控制，包括如下參數：</p><ul><li>KeepingSourceWhenParseFail：解析失敗時，是否保留原始字段。若不配置，默認不保留。</li><li>KeepingSourceWhenParseSucceed：解析成功時，是否保留原始字段。若不配置，默認不保留。</li><li>RenameSourceKey：當原始字段被保留時，用於存儲原始字段的字段名。若不配置，默認不改名。</li></ul><blockquote><p>示例：假設需要在日誌字段內容解析失敗時在日誌中保留該字段，並重命名為 raw，則可配置如下參數：</p><ul><li>KeepingSourceWhenParseFail：true</li><li>RenameSourceKey：raw</li></ul></blockquote><h3>（五）【商業版】日誌時間解析支持納秒級精度</h3><p>在 iLogtail 1.x 版本中，如果您需要提取日誌時間字段到納秒精度，日誌服務只能在您的日誌中額外添加「納秒時間戳」字段。在 iLogtail 2.0 版本中，納秒信息將直接附加至日誌採集時間（<strong>time</strong>）而無需額外添加字段，不僅減少了不必要的日誌存儲空間，也為您在 SLS 控制枱根據納秒時間精度對日誌進行排序提供方便。</p><p>如果需要在 iLogtail 2.0 中提取日誌時間字段到納秒精度，您需要首先配置時間解析原生處理插件，並在「源時間格式（SourceFormat）」的末尾添加「.%f」，然後在全局參數中增加"EnableTimestampNanosecond": true。</p><blockquote><p>示例：假設日誌中存在字段 time，其值為 2024-01-23T14:00:00.745074，時區為東 8 區，現在需要解析該時間至納秒精度並將 <strong>time</strong> 置為該值。</p><p><img src="https://oscimg.oschina.net/oscnet/up-443ebb6650ab6fb7334c3b3b1c5527ac60c.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-6237e2882b874738edda03a89819297d75b.png" alt="" referrerpolicy="no-referrer"></p><p>採集結果如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-519f2570442d18bdb7f276c108ff1112546.png" alt="" referrerpolicy="no-referrer"></p></blockquote><p><strong>🔔 注意：</strong> iLogtail 2.0 不再支持 1.x 版本中提取納秒時間戳的方式，如果您在 1.x 版本中已經使用了提取納秒時間戳功能，在升級 iLogtail 2.0 後，需要按照上述示例手動開啓新版納秒精度提取功能，詳細信息參見文末兼容性説明。</p><h3>（六）【商業版】狀態觀測更加清晰</h3><p>相比於 iLogtail 1.x 暴露的簡單指標，iLogtail 2.0 極大地完善了自身可觀測性的建設：</p><ul><li>所有采集配置都有完整指標，可以在 Project/Logstore 等維度上進行不同採集配置的統計與比較</li><li>所有插件都有自己的指標，可以構建完整流水線的拓撲圖，每個插件的狀態可以進行清楚的觀測</li><li>C++ 原生插件提供更加詳細的指標，可以用來監控與優化插件的配置參數</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-1eafd646874b01b9014f3feb5edee33dd27.png" alt="" referrerpolicy="no-referrer"></p><h3>（七）運行更快更安全</h3><p>iLogtail 2.0 支持 C++ 17 語法，C++ 編譯器升級至 gcc 9，同時更新了 C++ 依賴庫的版本，使得 iLogtail 的運行更快更安全。</p><p>表：iLogtail 2.0 單線程處理日誌的性能（以單條日誌長度 1KB 為例）</p><table><thead><tr><th align="left"><strong>場景</strong></th><th align="left"><strong>CPU（核）</strong></th><th align="left"><strong>內存（MB）</strong></th><th align="left"><strong>處理速率（MB/s）</strong></th></tr></thead><tbody><tr><td align="left">單行日誌採集</td><td align="left">1.06</td><td align="left">33</td><td align="left">400</td></tr><tr><td align="left">多行日誌採集</td><td align="left">1.04</td><td align="left">33</td><td align="left">150</td></tr></tbody></table><h2>兼容性説明</h2><h3>（一）採集配置</h3><h4>商業版</h4><ul><li>新版流水線採集配置是完全向前兼容舊版採集配置的，因此：</li></ul><p>&lt;!----&gt;</p><ul><li>在您升級 iLogtail 至 2.0 版本的過程中，日誌服務會在下發配置時自動將您的舊版配置轉換為新版流水線配置，您無需執行任何額外操作。您可以通過 GetLogtailPipelineConfig 接口直接獲取舊版配置對應的新版流水線配置</li></ul><p>&lt;!----&gt;</p><ul><li>舊版採集配置並不完全向後兼容新配流水線配置</li></ul><p>&lt;!----&gt;</p><ul><li>如果流水線配置描述的採集處理能力可用舊版配置表達，則該流水線配置依然可以被 iLogtail 0.x 和 1.x 版本使用，日誌服務會在向 iLogtail 下發配置時自動將新版流水線配置轉換為舊版配置</li><li>反之，該流水線配置會被 iLogtail 0.x 和 1.x 版本忽略</li></ul><h4>開源版</h4><p>新版採集配置與舊版採集配置存在少量不兼容情況，詳見 iLogtail 2.0 版本採集配置不兼容變更説明 <strong>[</strong><strong>5]</strong> 。</p><h3>（二）iLogtail 客户端</h3><p><strong>1. 使用擴展處理插件時的 Tag 存儲位置</strong></p><p>當您使用擴展插件處理日誌時，iLogtail 1.x 版本由於實現原因會將部分 tag 存放在日誌的普通字段中，從而為您後續在 SLS 控制枱使用查詢、搜索和消費等功能時帶來諸多不便。為瞭解決這一問題，iLogtail 2.0 將默認將所有 tag 歸位，如果您仍希望保持 1.x 版本行為，您可以在配置的全局參數中增加"UsingOldContentTag": true。</p><ul><li>對於通過舊版控制枱界面和舊版 API 創建的採集配置，在您升級 iLogtail 2.0 後，tag 的存儲位置仍然與 1.x 版本一致；</li><li>對於通過新版控制枱界面和新版 API 創建的採集配置，在您升級 iLogtail 2.0 後，tag 的存儲位置將默認歸位。</li></ul><p><strong>2. 高精度日誌時間提取</strong></p><p>2.0 版本不再支持 1.x 版本的 PreciseTimestampKey 和 PreciseTimestampUnit 參數，當您升級 iLogtail 2.0 版本後，原有納秒時間戳提取功能將失效，如果您仍需解析納秒精度時間戳，您需要參照日誌時間解析支持納秒精度板塊對配置進行手動更新。</p><p><strong>3. 飛天格式日誌微秒時間戳時區調整</strong></p><p>2.0 版本的飛天解析原生處理插件將不再支持 1.x 版本的 AdjustingMicroTimezone 參數，默認微秒時間戳也會根據配置的時區進行正確的時區調整。</p><p><strong>4. 日誌解析控制</strong></p><p>對於原生解析類插件，除了日誌解析控制更加精細板塊中提到的 3 個參數，還存在 CopyingRawLog 參數，該參數僅在 KeepingSourceWhenParseFail 和 KeepingSourceWhenParseSucceed 都為 true 時有效，它將在日誌解析失敗時，在日誌中額外增加 <strong>raw_log</strong> 字段，字段內容為解析失敗的內容。</p><p>該參數的存在是為了兼容舊版配置，當您升級 iLogtail 2.0 版本後，建議您及時刪去該參數以減少不必要的重複日誌上傳。</p><h2>總結</h2><p>為用户提供更舒適便捷的用户體驗一直是日誌服務的宗旨。相比於 iLogtail 1.x 時代，iLogtail 2.0 的變化是比較明顯的，但這些轉變只是 iLogtail 邁向現代可觀測數據採集器的序曲。我們強烈建議您在條件允許的情況下嘗試 iLogtail 2.0，也許您在轉換之初會有些許的不適應，但我們相信，您很快會被 iLogtail 2.0 更強大的功能和更出色的性能所吸引。</p><p><strong>相關鏈接：</strong></p><p>[1]&nbsp;輸入插件</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-19%3Fspm%3Da2c4g.11186623.0.0.2a755c0dN5uxv4" target="_blank">https://help.aliyun.com/zh/sls/user-guide/overview-19?spm=a2c4g.11186623.0.0.2a755c0dN5uxv4</a></em></p><p>[2]&nbsp;處理插件</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-22%3Fspm%3Da2c4g.11186623.0.0.2f2d1279yGXSce" target="_blank">https://help.aliyun.com/zh/sls/user-guide/overview-22?spm=a2c4g.11186623.0.0.2f2d1279yGXSce</a></em></p><p>[3]&nbsp;iLogtail 流水線配置結構</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnext.api.aliyun.com%2Fstruct%2FSls%2F2020-12-30%2FLogtailPipelineConfig%3Fspm%3Dapi-workbench.api_explorer.0.0.65e61a47jWtoir" target="_blank">https://next.api.aliyun.com/struct/Sls/2020-12-30/LogtailPipelineConfig?spm=api-workbench.api_explorer.0.0.65e61a47jWtoir</a></em></p><p>[4]&nbsp;OpenAPI 文檔</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnext.api.aliyun.com%2Fdocument%2FSls%2F2020-12-30%2FCreateLogtailPipelineConfig%3Fspm%3Dapi-workbench.api_explorer.0.0.65e61a47jWtoir" target="_blank">https://next.api.aliyun.com/document/Sls/2020-12-30/CreateLogtailPipelineConfig?spm=api-workbench.api_explorer.0.0.65e61a47jWtoir</a></em></p><p>[5]&nbsp;iLogtail 2.0 版本採集配置不兼容變更説明</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Filogtail%2Fdiscussions%2F1294" target="_blank">https://github.com/alibaba/ilogtail/discussions/1294</a></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 22 Feb 2024 02:08:47 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/11044307</guid>
            <link>https://my.oschina.net/u/3874284/blog/11044307</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[程序員因 bug 事故被公司強制要求歸還 4 萬年終獎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>某程序員在 V2EX 發帖稱，因線上流量異常事故，自己被公司進行處罰。處罰的結果是被要求將去年發的 4 萬多年終獎歸還給公司，如果逾期不還，將以每天萬分之 5 的利息收取滯納金。</p><p>該程序員還稱，公司 hr 還揚言三個月內還是不還就免費開除。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-11365064309a71d744e9abe207d19996d40.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1016302" target="_blank">https://www.v2ex.com/t/1016302</a></u></em></p></blockquote><p>最新後續：</p><blockquote><p><img height="4236" src="https://oscimg.oschina.net/oscnet/up-0b14b51439371608fa1837e2222c753a465.png" width="1504" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1017164" target="_blank">https://www.v2ex.com/t/1017164</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 10:31:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279644</guid>
            <link>https://www.oschina.net/news/279644</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[我國 5G 基站總數超 337 萬個，5G 移動電話用户達 8.05 億户]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>工業和信息化部數據指出：截至 2023 年底，我國累計建成 5G 基站 337.7 萬個，5G 移動電話用户達 8.05 億户。</p><p>網絡基礎日益完備。我國已建成全球最大的光纖和移動寬帶網絡，全國行政村通 5G 比例超 80%。通信杆塔資源與社會杆塔資源雙向共享取得顯著成效，目前 90% 以上的基站實現共建共享，5G 基站單站址能耗相較於商用初期降低 20% 以上。</p><p>創新能力不斷增強。我國 5G 技術產業在技術標準、網絡設備、終端設備等方面創新能力不斷增強。輕量化 5G 核心網、定製化基站等實現商用部署。5G 工業網關、巡檢機器人等一批新型終端成功研發。5G 標準必要專利聲明量全球佔比超 42%，持續保持全球領先。</p><p>賦能效應持續凸顯。融合應用廣度和深度不斷拓展，5G 應用已融入 71 個國民經濟大類，應用案例數超 9.4 萬個，5G 行業虛擬專網超 2.9 萬個。5G 應用在工業、礦業、電力、港口、醫療等行業深入推廣。「5G+工業互聯網」項目數超 1 萬個。</p><p>賦值效應更加顯著。5G 移動電話用户持續增長、5G 流量消費快速提升，有效拓展了移動通信市場的發展空間。截至 2023 年底，我國 5G 網絡接入流量佔比達 47%。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 09:01:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279630</guid>
            <link>https://www.oschina.net/news/279630</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[法國電信公司 Orange 違反 GPL 許可協議，被罰 65 萬歐元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根據 2024 年 2 月 14 日下達的判決，法國上訴法院判定當地電信公司 <strong>Orange 因未遵守 GNU GPL v2 許可證條款而侵權</strong>，並且需要向 Entr'Ouvert 支付&nbsp;<strong>50 萬歐元的經濟損失賠償和 15 萬歐元的精神損失賠償</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aba84da216106bb416ed362f90f6181cab6.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweb.archive.org%2Fweb%2F20240216164701%2Fhttps%3A%2F%2Fwww.legalis.net%2Factualite%2Forange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl%2F" target="_blank">https://web.archive.org/web/20240216164701/https://www.legalis.net/actualite/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6928315e1d404157b8404126515b42d68a7.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.orange.com%2Fen" target="_blank">Orange</a></u><span>&nbsp;是一家法國電信運營商。根據上文的判決，</span>Orange 的 IDMP 平台使用了名叫 Lasso 的庫，該庫的版權所有者為 Entr'Ouvert 公司。<strong>Lasso 採用 GPLv2 License —— 併為私有項目提供了商業許可證</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-7e59b5839901ae3f8dc0da42fd32d14c3d1.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flasso.entrouvert.org%2F" target="_blank">https://lasso.entrouvert.org/</a></u></em></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2d0135e65a7b51a798b2692a65007c31a65.png" referrerpolicy="no-referrer"></p><p>2005 年年底，Orange 參與了電子管理局關於實施 My Public Service 門户網站的招標活動，為身份管理提供一套 IT 解決方案，其中包括<strong>通過軟件接口將 IDMP 平台與 Entr'ouvert 公司發佈的 Lasso 軟件庫連接起來，Lasso 庫採用 GPL 許可證</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7d0ef557e10594da586685534b7728c372e.png" referrerpolicy="no-referrer"></p><p>法院認為，Entr'Ouvert 首先蒙受了與其在公共市場 Mon.service-public.fr 上收益受損相關的經濟損失，「因為如果 Orange 公司遵守許可合同，並簽訂付費許可，他們就應該向對方支付版税。」</p><p>此外，上訴法院特別指出，「Orange 免費使用 Lasso 軟件為這個持續 7 年的大規模公開市場帶來了利潤，此外還有 Lasso 給這個門户網站在形象方面帶來的好處。<strong>這番操作讓 Orange 得以節省投入從而受益，因為通過免費使用 Lasso 軟件，Orange 公司可以滿足通信安全和隱私管理局 (ADAE) 要求的安全標準，從而能夠節省研發成本</strong>。」</p><p>Entr'ouvert 着重批評 Orange 違反了 Lasso 程序的許可合同條款，這些條款涉及它作為該程序版權持有人所擁有的知識產權，因此它以涉嫌侵犯其權利為由起訴了 Orange。</p><p>上訴法院首先要求 Entr'ouvert 證明 Lasso 軟件具有原創性。</p><p>根據 Entr'ouvert 出示的證據，上訴法院得出的結論是，<strong>Lasso 「在軟件組成、結構和表達方面都是原創的，符合版權保護的條件」</strong>。</p><p>上訴法院隨後審查了 Entr'Ouvert 援引的三起違反 GNU GPL v2 許可協議的行為。</p><p><strong>首先，法院認為 Orange 違反了許可合同第 2 條，因為它對 IDMP 所基於的 Lasso 進行了修改，卻沒有將 IDMP 作為一個免費整體授予政府。</strong></p><p><strong>其次，法院判定 Orange 沒有進一步遵守第 3 條，因為沒有提供修改後的源代碼。</strong></p><p><strong>最後，法院特別指出，Orange 在沒有遵守許可合同的所有條件、特別是第 4 條的情況下，複製、修改和分發了 Lasso。</strong></p><p><strong>法院還認為 Lasso 被整合到 IDMP 平台中，而 IDMP 平台的發行條件不一樣，且沒有徵得 Entr'Ouvert 公司的授權，此舉也違反了許可合同第 10&nbsp;條。</strong></p><p>總而言之，Orange 的 IDMP 產品使用了 Lasso，要麼按照 GPLv2 許可證要求公佈它的源代碼，要麼從版權所有者 Entr'Ouvert 購買許可證。Orange 沒有付費也沒有遵守 GPL 許可協議。法國上訴法庭判決 Orange 侵權行為成立。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 21 Feb 2024 08:09:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</guid>
            <link>https://www.oschina.net/news/279616/orange-condamne-a-650-000-e-pour-non-respect-de-la-licence-gpl</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
