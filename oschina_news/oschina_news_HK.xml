<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 14 Dec 2023 07:00:39 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[中國法院做出全球首個 5G 費率判決]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">日前，重慶市第一中級人民法院就 OPPO 訴諾基亞標準必要專利使用費糾紛一案作出判決，判決確認了諾基亞 2G-5G 標準必要專利的全球性的公平、合理和無歧視（FRAND）費率：針對 5G 多模手機，在全球第一區的單台許可費為 1.151 美元/台，在第二區（中國大陸地區）及第三區的單台許可費為 0.707 美元/台。針對 4G 多模手機，在第一區的單台許可費為 0.777 美元/台，在第二區及第三區的單台許可費為 0.477 美元/台。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">本次判決是中國法院首次對標準必要專利訴訟作出全球費率判決。2021 年，最高人民法院首次在「OPPO 夏普標準必要專利許可糾紛案」中終審裁定中國法院對標準專利具備全球費率管轄權。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">此外，判決首次確定了手機行業 5G 標準累積費率為 4.341%-5.273%。按照本次裁決，不考慮多模製式佔比，一部 200 美元的純 5G 手機，整機收取 5G 專利費的上限為 10.55 美元。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 06:20:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271007</guid>
            <link>https://www.oschina.net/news/271007</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【直播預告】上雲 vs 下雲：降本增笑？割韭菜？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本月，滴滴崩潰事件鬧得轟轟烈烈，各種離譜派單層出不窮，而造成這一混亂的，則是底層出故障的阿里雲。尷尬的是，這已經不是它第一次崩潰了，距離上一次，還不到一個月。</p><p>一時之間，各種有關「雲」的討論紛紛揚揚：有人眼饞馬斯克的 X 下雲省錢，覺得反正都有風險，還不如自己弄，這樣更可掌控，也更清楚；有人則認為上雲才是未來的趨勢，想要發揮出軟件的最大優勢，上雲更合適。</p><p>那麼，你怎麼看呢——</p><p><strong>公有云崩潰，到底是必然事件，還是事出偶然？</strong></p><p><strong>X 的案例參考性有多大？想省錢是該上雲 or 下雲呢？</strong></p><p><strong>到底是自建雲更安全，還是公有云更有保障？</strong></p><p><strong>對普通的廠商而言，該怎麼選擇呢？</strong></p><p>本期，OSCHINA【開源漫談】特地邀請了 5 位業內具有代表性的專家，直播探討一下，接下來，我們該上雲還是下雲？</p><p>&nbsp;</p><p><strong>直播主題：</strong>上雲 vs 下雲：降本增笑？割韭菜？</p><p><strong>直播時間：</strong>12 月 20 日 19:00 - 20:30</p><p><strong>直播平台：</strong>「OSC 開源社區」視頻號</p><p><strong>主辦方：</strong>開源中國</p><p>&nbsp;</p><div><div><p><strong>直播嘉賓：</strong></p><div><div><p>&nbsp;&nbsp;<strong>主持人：</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;李鶴，kinitiras、kluster-capacity 作者，kubernetes、karmada 社區貢獻者，前滴滴軟件開發工程師。16 年起一直從事容器相關工作，公眾號雲原生散修，個人 blog https://www.likakuli.com，目前在蝦皮北京，做資源利用率優化相關工作。</p><p>&nbsp;</p></div><div><p>&nbsp;&nbsp;<strong>正方：</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;周新宇，AutoMQ 聯合創始人 &amp; CTO，是 Apache 軟件基金會成員，Apache RocketMQ 聯合創始人 &amp; PMC 成員。有近十年的雲計算從業經歷，完整經歷了阿里雲中間件上雲歷程，是雲原生上雲理念的倡導者。</p><p>&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp;蔣明，前淘寶 DBA。</p><p>&nbsp;</p></div><div><p>&nbsp;&nbsp;<strong>反方：</strong></p><p style="text-align:left">&nbsp;&nbsp;&nbsp;&nbsp;馮若航，磐吉雲數 CEO / 創始人，Pigsty 作者，PostgreSQL 中文社區開源技術委員。公眾號《非法加馮》主理人，下雲倡導者。</p><p>&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp;馬工，在北歐從事 Infra 工程師，公眾號《瑞典馬工》主理人。主張雲計算是新的操作系統，其用户是軟件開發者，簡單的搬遷上雲沒有意義。他認為目前雲計算廠商有太多的草台班子，80% 的乙方員工都不會用自家的雲。</p></div></div></div></div><p>&nbsp;</p><p>公有云崩潰屢屢出現，我們仍該堅持上雲還是掉頭選擇下雲？你怎麼看呢？快掃碼預約直播，一起討論吧~還可以進我們的 OSC 技術交流羣，分享你的想法哦~</p><p style="text-align:center"><img height="2895" src="https://oscimg.oschina.net/oscnet/up-b9c174de1a7a4b314f3ff751d6e6e2ad5e0.png" width="750" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="text-align:left"><strong>直播福利</strong></p><ul><li><p>互動抽獎：在直播評論區提問，被直播嘉賓回覆的用户可獲 OSC 魔方一個，名額不限。</p></li><li><p>福袋抽獎：直播中將有多輪抽獎，參與就有機會獲得 OSC T 恤、魔方等。</p></li></ul><p style="text-align:center"><img height="2160" src="https://oscimg.oschina.net/oscnet/up-555ffa0866e12bdebcbbab1295b7fef43bc.png" width="3840" referrerpolicy="no-referrer"></p><p>我們直播間見吧~</p><p>&nbsp;</p><p><strong>特別鳴謝本次合作社區：</strong></p><ul><li><p><strong>PostgreSQL</strong><strong>中文社區</strong></p></li></ul><p>PostgreSQL 中文社區是一個非盈利的民間組織，目前成員都以志願者身份加入，成立的目的在於構建 PG 數據庫技術生態圈子 (內核、用户培訓機構、廠商、服務商、軟件開發商、高校形成 「業務與利益雙向驅動」 的良性發展生態圈); 幫助企業解決人才培養和企業商用數據庫成本問題，社區會在各運營平台發佈 PostgreSQL 最新信息和 PostgreSQL 相關技術文章，推動 PG 技術在中國的發展。 官網鏈接：http://www.postgres.cn/index.php/v2/home</p><p>&nbsp;</p><ul><li><p><strong>Pigsty</strong></p></li></ul><p style="text-align:left">Pigsty 是本地優先的 RDS 開源替代，開箱即用的 PostgreSQL 發行版，自帶高可用、監控系統，PITR，IaC 與部署方案。</p><p style="text-align:left">官網鏈接：https://pigsty.cc</p><p>&nbsp;</p><ul><li><p><strong>AutoMQ 開源社區</strong></p></li></ul><p>AutoMQ 社區聚集了一羣熱衷於雲原生技術的開源愛好者，他們曾經見證並應對了消息隊列基礎設施在大型互聯網公司和雲計算公司面臨的種種挑戰，希望與廣大開發者共同探索，以雲原生技術為基礎，重新塑造這一關鍵領域，探索雲原生消息隊列的更多可能性。目前，AutoMQ 社區以 Apache 協議開源了雲原生版本的 Kafka 和 RocketMQ 實現，致力於用雲原生的技術棧，大幅度降低企業的雲資源成本，以及提高運維效率。</p><p>社區地址：https://github.com/AutoMQ</p><p>&nbsp;</p><ul><li><p><strong>TiDB</strong></p></li></ul><p>由 TiDB 生態中的開發者、用户、合作伙伴一起建立的分享、學習平台。TiDB 線上社區匯聚了 33448 位 TiDB 資深用户（註冊用户數），所有成員都可以在這裏自由發聲，互相協助解決問題。社區線上論壇 asktug.com 已經積累 23,000+ 個問題帖（主題帖數），90 % 的問題都得到了解決，累計總回覆 243,000+ 個（主題帖回覆數）。</p><p>社區地址：asktug.com</p><p>&nbsp;</p><ul><li><p><strong>Apache</strong><strong> IoTDB </strong></p></li></ul><p>Apache IoTDB 是一款低成本、高可用的物聯網原生時序數據庫，採用端邊雲協同的輕量化結構，支持一體化的物聯網時序數據收集、存儲、管理與分析，具有多協議兼容、超高壓縮比、高通量讀寫、工業級穩定、極簡運維等特點。IoTDB 自研完整的存儲引擎、查詢引擎、計算引擎，並支持權限管理、集羣管理、系統監控、可視化呈現等多項功能，可實現物聯網時序數據全生命週期，也就是涵蓋寫入、存儲、處理、查詢、分析、展示等多個維度的時序數據高效管理，助力企業構建時序數據高可用、高穩定解決方案。</p><p>作為全球性開源項目，Apache IoTDB 已成為 Apache 基金會頂級項目，並建成全球認可的國際開源社區。目前，Apache IoTDB 社區擁有超過 260 名代碼提交者，完成 9000 餘次提交，收穫 4100 餘次 stars，代碼活躍度於 Apache 350 餘個項目中排名第三。</p><p>社區地址：https://iotdb.apache.org</p><p>&nbsp;</p><ul><li><p><strong>StarRocks</strong></p></li></ul><p>Linux 基金會項目 StarRocks 是數據分析新範式的開創者、新標準的領導者。面世三年來，StarRocks 一直專注打造世界頂級的新一代極速全場景 MPP 數據庫，幫助企業構建極速統一的湖倉分析新範式，是實現數字化轉型和降本增效的關鍵基礎設施。</p><p>社區地址：https://www.starrocks.io/</p><p>項目鏈接：https://github.com/StarRocks/starrocks</p><p>&nbsp;</p><ul><li><p><strong>Gitee</strong></p></li></ul><p>Gitee（碼雲）是開源中國於 2013 年推出的基於 Git 的代碼託管平台、企業級研發效能平台，提供中國本土化的代碼託管服務。</p><p>截止 2023 年 7 月，Gitee 已經有 1000 萬名註冊用户和 2500 萬個代碼倉庫，是中國境內規模最大的代碼託管平台。同時，旗下企業級 DevOps 研發效能管理平台 Gitee 企業版已服務超過 26 萬家企業。</p><p>網址：https://gitee.com/</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10321438</guid>
            <link>https://my.oschina.net/u/6852546/blog/10321438</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mate 60 Pro 的 5G 調制解調器和射頻技術遙遙領先]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TechInsights 對華為 Mate 60 Pro 的持續分析顯示，中國在繞過技術封鎖方面取得了重大進展。<strong>這種進步不僅體現在應用處理器片上系統 (SoC) 上，還體現在 5G 基帶處理器和移動射頻技術上</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb55239889638f62fda03f236e44ce5e085.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ftechinsightsinc%2Fstatus%2F1734034686689661432" target="_blank">https://twitter.com/techinsightsinc/status/1734034686689661432</a></u></em></p><p>搭載於 Mate 60 Pro 的麒麟 9000S 證明，華為和中芯國際可以在沒有美國公司和其他被禁止與這兩家中國實體合作的實體的幫助下，繼續大規模生產移動芯片。</p><p>不止麒麟 9000S，最近的一項分析顯示，除了芯片組外，<strong>旗艦產品中使用的先進 5G 調制解調器和射頻技術也使華為可以與其他高端智能手機和芯片製造商相媲美</strong>。</p><p>TechInsights 分析稱：「中國在開發先進的（2D）系統級封裝（SiP）模塊和射頻濾波器方面也取得了飛躍，採用了聲波濾波器的改進技術以及基於薄膜集成無源器件（IPD）和低温共燒陶瓷（LTCC）的混合技術。與 2015 年和 2016 年之前的射頻 FE 5G 架構相比，這是一個重大進步。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c43c2606127ed23640e66b732ba55f6a808.png" referrerpolicy="no-referrer"></p><p>該公司憑藉其 5G 調制解調器和射頻技術跨越了這些令人生畏的障礙，使華為成為其他巨頭中的佼佼者。鑑於蘋果公司已經投資數十億美元努力製造自己的基帶芯片，其中包括收購英特爾的 5G 調制解調器業務，但仍然遇到了無數的開發問題，這證明製造這些芯片是多麼困難，但華為已經想出了辦法。</p><p>不僅如此，華為和中芯國際還悄然發佈了一款 5 納米芯片，雖然是用於筆記本電腦，但突破 7 納米大關足以證明，明年我們可能會看到新的麒麟芯片與新的 5G 調制解調器一起出現在 P70 系列上。儘管如此，中國的芯片技術仍比美國落後幾年，但以目前的速度，這一差距可能會持續縮小。</p><p>原文：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techinsights.com%2Fblog%2Fmate-60-pro-mobile-rf-architecture-proves-huawei-can-compete-top-tier-smartphone-oems" target="_blank">https://www.techinsights.com/</a></u></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270978</guid>
            <link>https://www.oschina.net/news/270978</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CNCF 首個雲原生多雲容器編排項目 Karmada 正式晉級孵化]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>文分享自華為雲社區《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F417774%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">CNCF 首個雲原生多雲容器編排項目 Karmada 正式晉級孵化】</a>》，作者：雲容器大未來。</p><p>近日，雲原生計算基金會（CNCF）宣佈，CNCF 技術監督委員會（TOC）已投票通過 Karmada 為正式孵化項目。Karmada 是華為雲捐贈的雲計算開源技術，是業界首個多雲多集羣容器編排項目。 正式晉升 CNCF 孵化級，也意味着 Karmada 的技術生態受到全球業界廣泛認可，在分佈式雲原生技術領域進入了成熟新階段。</p><p>作為 CNCF 首個跨雲跨集羣容器編排引擎，Karmada 由華為雲、工商銀行、小紅書、中國一汽等八家企業聯合發起。項目於 2021 年 4 月正式開源，2021 年 9 月加入 CNCF 成為沙箱項目。Karmada 的貢獻者來自世界各地，覆蓋全球 22 個國家和地區的 60 多家組織，包括華為、DaoCloud、浙江大學、滴滴、騰訊、小紅書、新浪、Intel、IBM、Red Hat、Comcast 等公司。截至目前，項目在開源軟件項目託管平台 GitHub 已收穫超過 3600 Star。</p><p><img alt="cncf.png" src="https://bbs-img.huaweicloud.com/blogs/img/20231213/1702453150429804713.png" referrerpolicy="no-referrer"></p><p><strong>華為雲</strong><strong>CTO 張宇昕表示</strong>，華為雲長期致力於雲原生技術、產業和生態的建設。Karmada 源於社區和華為雲在多雲管理領域的深厚沉澱，為企業提供了從單集羣到分佈式雲架構的平滑演進方案。「作為 Karmada 項目的發起者和主要貢獻者之一，華為雲將繼續與 CNCF 和社區合作，釋放無處不在的雲原生價值。」</p><p>「Karmada 開源以來受到了廣泛的關注和支持，並幫助越來越多的最終用户在多雲環境中高效管理 Kubernetes 集羣和分佈式應用。」<strong>Karmada 社區創始人兼維護者王澤鋒表示</strong>，「我們很高興 Karmada 已達到 CNCF 孵化狀態，並將繼續致力於將其發展成更為完善的國際化社區。」</p><p><strong>CNCF 技術監督委員會（TOC）Nikhita Raghunath 表示</strong>，Karmada 填補了 Kubernetes 多雲和多集羣環境中的調度和編排方面的空白，可以為分佈式組織提供更好的性能並降低成本。「自從加入 CNCF Sandbox 以來，項目團隊一直不懈地努力添加新特性和功能，以融入更廣闊的雲原生生態。我們期待看到該項目的持續成長。」</p><p>目前，項目已在華為雲、興業數金、中國移動雲、中國聯通、攜程、vivo、颶風引擎、VIPKID、有贊、網易、快手、之江實驗室等 20 多家企業和單位落地應用，以開源創新促進雲原生產業發展，項目全球生態發展迅速。Karmada 的創新優勢，也得到了企業用户的高度認可。</p><p>「Karmada 使我們能夠為 Zendesk 的內部工程團隊提供多集羣架構，同時保持身份驗證、配置交付和服務管理的單點訪問。」<strong>Zendesk 計算團隊工程經理 Adam Minasian</strong>説到，「隨着 Karmada 項目進入 CNCF 孵化階段，我們很高興能夠繼續與該項目合作。」</p><p>「Karmada 為企業落地多雲戰略提供了便捷的基礎設施。它基於中立、廠商無關的設計，讓用户在極小代價情況下，靈活接入和切換多雲和混合雲；同時它為客户在微服務跨集羣編排、跨集羣彈性伸縮，多雲化的訪問、容災等場景帶來了便利性。」<strong>DaoCloud 聯合創始人兼首席架構師顏開</strong>表示。</p><p>基於對可持續供應的考慮，以及對業務快速擴展的需求，混合雲多雲已成為攜程集團的技術優選。「Karmada 以其標準的 K8s API 兼容性、關注點分離的原則、活躍的社區，幫助我們構建了混合多雲的控制面，降低了架構遷移成本和異構環境的管理複雜性。」<strong>攜程集團容器與混合雲團隊總監樂鴻輝</strong>表示，攜程藉助於 Karmada 實現的故障隔離架構和多集羣 HPA，也幫助公司成功應對旅遊業的強勁復甦。</p><p>「Karmada 簡化了多集羣環境中的集羣與應用的交付和管理，實現跨集羣的資源協調，以增強應用程序的可用性和彈性。它確保穩定、高效、可控的應用程序部署和更新。」<strong>Shopee 專家工程師李鶴</strong>表示。</p><p>「Karmada 作為開源的多雲容器編排平台，為雲原生中間件提供了靈活性和可靠的跨平台、跨區域、跨雲的資源管理，為中間件同城跨機房高可用提供了基石。」<strong>網易資深開發工程師孟祥勇</strong>表示。</p><p>目前，Karmada 社區已累計更新 67 個版本。晉級 CNCF 孵化項目後，項目進一步規劃了社區發展路標，並正在積極添加新功能和特性，如多集羣安全、大規模場景應用、多集羣可觀測性、多集羣應用分發、生態融合發展等。</p><p>作為 CNCF 亞洲唯一創始成員、白金會員，華為雲在 CNCF 貢獻量、Kubernetes 社區和 Istio 社區的代碼貢獻量持續多年穩居亞洲第一，已向 CNCF 貢獻了業界首個雲原生邊緣計算項目 KubeEdge、首個雲原生批量算力項目 Volcano 等多個重量級雲原生開源項目，並持續開源 Kurator、Kappital、Kuasar 等創新項目，與全球雲原生社區共同發展。華為雲 UCS 作為業界首發的分佈式雲原生服務，基於 Karmada 項目構建全新的應用算力供給模式，覆蓋中心 Region、專有 Region、邊緣雲、客户數據中心和第三方雲場景，提供無處不在的雲原生能力，為雲原生服務提供跨雲跨地域一致性體驗。</p><p>Karmada 正式晉級 CNCF 孵化項目，進一步展現了華為雲持續踐行開源、擁抱開源，與全球開發者共創先進技術的理念，持續助力雲上開源創新生態發展。未來，Karmada 將持續探索雲原生多雲多集羣領域技術創新，讓基於 Karmada 的多雲方案融入更廣泛的雲原生技術生態。</p><p>Karmada 官網：<u>https://karmada.io/</u></p><p>項目地址：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkarmada-io%2Fkarmada" rel="nofollow" target="_blank">https://github.com/karmada-io/karmada</a></u></p><p>Slack 地址：https://slack.cncf.io/</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>點擊關注，第一時間瞭解華為雲新鮮技術~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10321412</guid>
            <link>https://my.oschina.net/u/4526289/blog/10321412</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年，PHP 停滯不前]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>熱心開發者分析了一波 GitHub 的數據後發現，<strong>編程語言為 PHP 的 PR 數量逐年下降</strong>。</p><p><strong>GitHut&nbsp;</strong>是通過 GitHub 數據專門分析編程語言的項目。它基於各種編程語言在 GitHub 中的使用情況，挖掘編程語言在開發者中的受歡迎程度，並發現每種語言的獨特之處。</p><p>GitHub 本身提供了公開的 API，支持與其龐大的事件數據集與託管倉庫進行交互。GitHub Archive 則更進一步，彙總並存儲了 API 的長期數據。</p><p>GitHut 2.0 使用的定量數據通過 Google BigQuery 從 GitHub Archive 數據集進行收集。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmadnight.github.io%2Fgithut%2F%23%2Fpull_requests%2F2023%2F3" target="_blank">從 GitHut 最新公佈的數據來看</a></u>，<strong>開發者在 GitHub 提交的 PR 中，所使用語言為 PHP 的數量逐年下降</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8f21cb80016974c4473515841593e0a1dbd.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-48434852dee054fa4d246d1387188cac51e.png" referrerpolicy="no-referrer"></p><p>因此，有人直言：「<strong>2023 年，PHP 停滯不前</strong>」：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8ebd5b97a696dcedfeafd1c2b1a5e6a9bbb.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F18hgduc%2Fgithub_says_php_is_the_most_stagnating_language%2F" target="_blank">https://www.reddit.com/</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270973</guid>
            <link>https://www.oschina.net/news/270973</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[數據庫圈的夜郎自大，危！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>作者：尹海文，Oracle ACE，OCM 11g/12c/19c，MySQL 8.0 OCP，墨天輪 MVP、技術專家，ITPUB 核心專家，OCM 講師，網思科技 DBA 總監。</p><p>微信公眾號：<span style="color:#576b95">胖頭魚的魚缸</span></p><p><img height="200" src="https://oscimg.oschina.net/oscnet/up-2246bd76f586b377330839cc13eda5af742.jpg" width="200" referrerpolicy="no-referrer"></p></blockquote><p>今天看到薛首席在 OSCHINA 邀稿的一篇文章<a href="https://my.oschina.net/u/3859945/blog/10321019">《國產數據庫的出現和消失，都不是技術問題》</a>及其評論，感觸頗多，忍不住得寫一篇文章。</p><span id="OSC_h2_1"></span><h2>0 和 1 的藝術</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">現在計算機，歸根結底是二極管的使用藝術，即開與合，0 和 1，運行在硬件之上無論是操作系統、軟件還是其他什麼的，都是對二進制的使用，本質還是和數學打交道。以數據庫為例，其中的各項算法都得和這最基礎的數學打交道，涉及基本的二進制、硬件固件、硬件指令集、硬件驅動等等與軟件運行之間的結合。我一直沒搞懂總有人在説，近幾十年來很多涉及數據庫數學層面的東西沒有進步，我們隨隨便便就能趕超？！</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">我是一個高中文科大學園林設計專業的 DBA，我無法從深層次的數學層面來解釋一些東西，但是我可以通過一些方法來展現結果：安安分分用相同的配置在 Oracle 11g vs 19c、MySQL 5.6 vs 8.0、PG 9 vs 16 跑跑完全相同的東西，抹平所謂的硬件帶來的進步，看看性能有沒有提升（別説難搞，大不了一台 4C16GB 虛擬機輪流測試）。</p><span id="OSC_h2_2"></span><h2>帶寬的瓶頸</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">説起帶寬瓶頸以前一直説是磁盤 IO 瓶頸，傳統的 HDD 頂多 300MB/s 和幾百幾千 IOPS 的性能確實不夠看。但現在的傳輸帶寬，還是存在一個比較尷尬的情況，大多數網絡都是以萬兆為主，之前我的文章也講過，現在主流的 PCIe4.0 x4 NVMe SSD 單盤極限帶寬能來到 4000MB/s，即是一塊 SSD 即可佔滿萬兆網絡（1250MB/s），而主流的 32GBps 的 HBA 卡也可以一塊 SSD 佔滿，40GBps 的 IB 交換機勉強支撐一塊 SSD，100GBps 的 RoCE 交換機 3 塊 SSD 即超越，再往上多路的話依次類推，總之在 NVMe SSD 越來越廉價的今天，即使考慮<span>隨機讀寫</span>的性能衰減問題，數量不多的 SSD 也能佔滿單機的帶寬。</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">在磁盤性能&gt;傳輸性能的當下，我仍然能聽到，就對比 Oracle Exadata 的基於 X86 服務器的分佈式存儲來説，專用存儲設備更好。Oracle Exadata 存儲層做了啥，Exadata Storage Software 充分利用了硬件特性與軟件結合，在存儲內部就實現數據的過濾篩選，<span style="background-color:#fbfbfb; color:#24292e">減少網絡傳輸層面的帶寬需求，</span>讓 NVMe SSD、PMEM 這些高性能磁盤設備發揮真正的作用而不是去撐爆網絡。就專用存儲而言，無法突破使用服務器的傳輸瓶頸，即使 IO 再強勁，出口帶寬再大，也只能突增使用存儲設備的服務器數量；而對於單機服務器配置大量高性能磁盤來説，特別是用於分佈式數據庫中的跨分片操作，只要數據量稍微大一些，網絡就很難扛得住（不一定是磁盤引起的也可以是內存），這也是為啥分佈式數據庫建議把關聯數據放在一個分片內（這得從數據庫層面幹掉多少需求或者説是一些需求就不能用分佈式數據庫實現）。</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">回頭看看本節一開始，為啥當年有分佈式，我個人認為單機性能不足需要更多機器來堆，但是現在一塊小小的 SSD 比曾經幾十上百台集羣整體 IO 性能還好的情況下，分佈式是不是又成為了一個偽需求。再看 Exadata 的解決方案，充分利用硬件的存儲分佈式+數據庫集中式，是不是更合理呢。</p><p style="margin-left:0px; margin-right:0px; text-align:center"><img height="541" src="https://oscimg.oschina.net/oscnet/up-96f480f7817145b83bf512d2552cbc09163.png" width="1080" referrerpolicy="no-referrer"></p><span id="OSC_h2_3"></span><h2>「遙遙領先」</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">不知何時開始，估摸着是電影《西紅柿首富》的「卧龍鳳雛」開始，很多曾經的讚美之詞，現在也蒙上了貶義詞的陰影，其中就有來自某大廠某大嘴的「遙遙領先」。我已經不止一次在國產數據庫溝通、宣傳材料（包含潛台詞）、行業形勢宣傳中看到，<span>咱們的很多產品已經遙遙領先於 Oracle、DB2、SQLServer、MySQL、PostgreSQL</span>這些國外數據庫產品（我也不知道後兩個那麼多套殼的好意思説出口）。</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">回到之前寫過的，數據庫是一個需要長期時間去磨礪的基礎系統工程，不是把一大堆所謂的「先進理念、先進架構、先進算法（特別是隻會拿來用不知道到底怎麼實現的算法）」縫合在一起，倒騰出數據庫產品就能很牛逼的？！這樣帶來的只能是所謂的快速追趕進度，真要追得上，以這種忽略地基的方式是不可能實現的。</p><span id="OSC_h2_4"></span><h2>總結</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">數據庫圈，正視差距不丟人，夜郎自大才丟人，所謂的「遙遙領先」最終帶來的是系統的危險。&nbsp;&nbsp;&nbsp;&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10321420</guid>
            <link>https://my.oschina.net/u/3859945/blog/10321420</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Kubernetes v1.29 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">Kubernetes v1.29：Mandala (The Universe) 現已發佈，這是 2023 年的最後一個版本。</span><span style="background-color:#ffffff; color:#222222">該版本包含 49 項增強功能。其中 11 項已升級到穩定版，19 項進入 </span><span style="background-color:#ffffff; color:#333333">Beta&nbsp;</span><span style="background-color:#ffffff; color:#222222">版，19 項升級到 Alpha 版。</span></p><p><span style="background-color:#ffffff; color:#222222">v1.29 的主題&nbsp;Mandala 旨在反映社區的相互關聯性 —— 由愛好者和專家組成，每個貢獻者都是至關重要的一部分。「Kubernetes 在協作中蓬勃發展，與 Mandala&nbsp;創作中的和諧相呼應。」</span></p><p><span style="background-color:#ffffff; color:#222222"><img alt="" height="200" src="https://oscimg.oschina.net/oscnet/up-95f4c6a09987ead5e1c311f201c9cbf42ad.png" width="200" referrerpolicy="no-referrer"></span></p><p><strong><span style="background-color:#ffffff; color:#222222">在 Kubernetes v1.29 中升級到穩定版的改進功能</span></strong></p><ul><li><span style="color:#000000"><span style="background-color:#ffffff">新的 ReadWriteOncePod PersistentVolume 訪問模式</span></span></li></ul><p><span style="color:#000000"><span style="background-color:#ffffff">ReadWriteOncePod 作為 Alpha 功能在&nbsp;v1.22 被引入。</span>如果你使用使用 ReadWriteOncePod 訪問模式的 PVC 創建 pod，Kubernetes 將確保該 pod 是整個集羣中唯一可以讀取該 PVC 或寫入該 PVC 的 pod。在 v1.29 中，此功能變得普遍可用。</span></p><ul><li><span style="color:#000000"><span style="background-color:#ffffff">CSI Node Expand Secret</span></span></li></ul><p style="text-align:left"><span><span><span><span><span style="color:#222222"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Kubernetes v1.25 中引入了 CSI Node Expand Secret 功能。它允許 CSI 驅動程序將可選的 secret field 作為 NodeExpandVolumeRequest 的一部分發送，以便可以使用底層存儲系統執行節點卷擴展操作。在 Kubernetes v1.29 中，此功能變得普遍可用。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>KMS v2 靜態加密普遍可用</li></ul><p style="text-align:left"><span><span><span><span><span style="color:#222222"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>在確保 Kubernetes 集羣安全時，首先要考慮的是對靜態持久化 API 數據進行加密。KMS 提供了一個接口，供提供者利用存儲在外部密鑰服務中的密鑰執行加密。在 Kubernetes v1.29 中，KMS v2 已成為一項穩定的功能，在性能、密鑰輪換、運行狀況檢查和狀態以及可觀察性方面帶來了大量改進。這些增強功能為用户提供了可靠的解決方案來加密 Kubernetes 集羣中的所有資源。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkep.k8s.io%2F3299" target="_blank">可以在 KEP-3299</a>&nbsp;中閲讀更多相關信息。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><hr><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">此外，v1.29 中還棄用或刪除了許多功能。包括刪除與雲廠商的樹內集成、移除&nbsp;v1beta2 flow control&nbsp;API 組、棄用 status.nodeInfo.kubeProxyVersion 字段以及棄用舊版 Linux 軟件包存儲庫。&nbsp;</span></span></p><p style="text-align:left">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubernetes.io%2Fblog%2F2023%2F12%2F13%2Fkubernetes-v1-29-release%2F" target="_blank">查看發佈公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270970/kubernetes-v1-29-released</guid>
            <link>https://www.oschina.net/news/270970/kubernetes-v1-29-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[VMware 產品全面改為訂閲制]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Broadcom 發佈新聞稿稱，公司已大幅簡化了 VMware 的產品線，<strong>並完成了所有 VMware 產品從買斷制向訂閲制的轉變</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-8022b562fee7c21769f54eba21a0318e820.png" referrerpolicy="no-referrer"></p><p>來源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.vmware.com%2Fcompany%2Fvmware-by-broadcom-business-transformation" target="_blank">https://news.vmware.com/company/vmware-by-broadcom-business-transformation</a></u></p></blockquote><p><strong>從 12 月 11 日開始，VMware 停止永久許可證的銷售</strong>，此前購買過永久授權的用户可以獲得訂閲購買計劃的積分 (trade in)，以便將永久許可證產品換到新訂閲產品。永久許可證以及支持和訂閲續訂結束後，產品將僅以訂閲或定期許可證的形式提供。此外，已擁有永久許可證的用户還能夠繼續獲得使用許可和產品支持。</p><p>VMware 稱，其旗艦企業級混合雲解決方案 VMware Cloud Foundation 訂閲價降低一半，並推出新的面向中小企業的產品 VMware vSphere Foundation。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270967/vmware-by-broadcom-business-transformation</guid>
            <link>https://www.oschina.net/news/270967/vmware-by-broadcom-business-transformation</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[刪庫並嘲諷同事，雲工程師被判處兩年監禁、賠款 52.9 萬美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">disgruntled-cloud-engineer-sentenced-two-years-prison</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">美國司法部 (DoJ) 發佈了一則公告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.justice.gov%2Fusao-ndca%2Fpr%2Fdisgruntled-cloud-engineer-sentenced-two-years-prison-intentionally-damaging-his" target="_blank">宣佈</a>，因入侵網絡和向政府機構作虛假陳述，判處 38 歲的雲工程師 Miklos Daniel Brody 兩年監禁，並支付 529266.37 美元的賠償金。&nbsp;</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Brody 曾在舊金山第一共和銀行 (FRB) 擔任雲工程師，直到 2020 年 3 月 11 日因為違反公司政策被解僱。原因是他將包含色情內容的 USB 驅動器連接到公司計算機，因此被終止了僱傭關係。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">被解僱後，Brody 拒絕歸還他的工作筆記本電腦，並在被解僱當晚繼續使用他仍然有效的賬户訪問銀行的計算機網絡，展開一系列報復。在量刑聽證會上，法官判定因 Brody 所造成的銀行系統損壞的總成本至少為 220,621.22 美元。</span></span></p><blockquote><p><span style="color:#000000">「Brody 刪除了銀行的代碼庫，運行惡意腳本刪除日誌，在銀行代碼中留下對前同事的嘲諷，並冒充銀行的其他員工以他們的名義打開會話。他還通過電子郵件向自己發送了他作為員工時編寫的銀行專有代碼，價值超過 5000 美元。」</span></p></blockquote><p style="margin-left:0; margin-right:0; text-align:start"><img height="307" src="https://oscimg.oschina.net/oscnet/up-388d14f405275a3f7c1595c9aff84cc89a7.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">總的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Fcloud-engineer-gets-2-years-for-wiping-ex-employers-code-repos%2F" target="_blank">來説</a>，在 2020 年 3 月 12 日最終終止對 FRB 網絡的訪問之前，Brody 共執行了以下操作：</span></span></p><ul><li><span style="color:#000000">運行名為「dar.sh」的惡意腳本來清除 FRB 的服務器</span></li><li><span style="color:#000000">刪除了特定腳本的 git 日誌和 git 提交歷史記錄</span></li><li><span style="color:#000000">訪問 FRB 的 GitHub 存儲庫並刪除所託管的代碼</span></li><li><span style="color:#000000">在代碼中插入「嘲諷」語句，包括對「grok」的引用</span></li><li><span style="color:#000000">冒充 FRB 的另一位雲工程師訪問該公司的網絡並進行配置更改</span></li></ul><p><span style="color:#000000">之後為了逃避責任，<span style="background-color:#ffffff">Brody 向警局謊稱&nbsp;</span>FRB <span style="background-color:#ffffff">配發的筆記本電腦被人偷走。且在&nbsp;2021 年 3 月被捕後，在向美國國家安全局特工發表的聲明中進一步強調了這一虛假指控。最終在 2023 年 4 月，Brody 承認了自己在筆記本電腦問題上進行了虛假陳述，並承認兩項有關違反《計算機欺詐和濫用法》的指控：</span></span></p><ul><li><span style="color:#000000"><span style="background-color:#ffffff">從受保護的計算機獲取信息，違反了 18 USC § 1030(a)(2)(C) (c)(2)(B)</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">以及故意損壞受保護的計算機，違反 18 USC § 1030(a)(5)(A) 和 (c)(4)(B)(i) </span></span></li></ul><p><span style="color:#000000">還有<span style="background-color:#ffffff">一項向政府機構做出虛假陳述的指控，違反了 18 USC § 1001(a)(2)</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270966/disgruntled-cloud-engineer-sentenced-two-years-prison</guid>
            <link>https://www.oschina.net/news/270966/disgruntled-cloud-engineer-sentenced-two-years-prison</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 內核刪除「高齡」驅動補丁，但它支持的設備似乎從未存在過？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>英特爾多年來一直為其硬件產品提供非常及時的 Linux 上游支持。通常來説，他們會在產品計劃公開發布很早之前就啓動相關工作。</p><p>在許多情況下，這就意味着英特爾在 Linux 內核中添加了某些硬件支持補丁——<strong>但這些硬件最終不會面向消費者發佈</strong>。比如最近的 Thunder Bay 支持，在明確 SoC 永遠不會發布後，內核就刪除了對該硬件的支持。</p><p>但現在出現了一個更極端的情況，<strong>一個驅動程序在主線內核中存在了 15 年，卻是為了支持從未發佈的硬件</strong>。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20231208224703.1603264-1-willy%40infradead.org%2F" target="_blank">根據 Linux 內核最近的提交</a></u>，維護者準備刪除支持英特爾"Carillo Ranch"硬件產品的&nbsp;<span>2000 多行驅動程序代碼（</span>fbdev 驅動，和 backlight 驅動）<span>，刪除的原因是</span>"Carillo Ranch"<span>似乎根本就不存在。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-5fcc2aa84734ff67c32a2166c1742c636e4.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FLinux-Drop-Intel-Carillo-Ranch" target="_blank">據瞭解</a></u>，Carillo Ranch 是一款 90 納米的 32 位單核處理器，主頻為 1.2GHz，熱設計功耗為 19 瓦，適用於嵌入式設備。</p><blockquote><p>「據任何人所知，這款產品從未發佈。即使發佈了，它也是在 2007 年推出的，再也沒有人能夠使用它了。」</p></blockquote><p>早在 2007 年，英特爾就資助了 Tungsten Graphics（該公司在被 VMware 收購之前推動了 Mesa 的開發），為 Carillo Ranch 開發<strong>幀緩衝區 (FBDEV) 驅動程序</strong>。還有一個<strong> MTD Carillo Ranch 驅動程序</strong>，英特爾在 2006 年資助 MontaVista 開發該驅動程序。</p><p>如果在谷歌搜索"Intel Carillo Range"以尋找出處，會被重定向至「Intel Carrillo Range」(注意多了個字母 r)，而唯一的搜索結果會跳轉到 MontaVista 的一份聯繫方式表格。表格裏有一句話：「<em>我們希望聽到關於這款主板的更多信息：兼容英特爾 Carrillo Ranch 奔騰 M，集成 Vermillion Range</em>」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-f1e624bba0ef26989427fb903aea4efe72c.png" referrerpolicy="no-referrer"></p><p>來源&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mvista.com%2Fcontactus%2FBoard%3A%2520Intel%2520Carrillo%2520Ranch%2520Pentium%2520M%2520compatible%2520Vermillion%2520Range%2FICH7%2520based%2520dev%2520platform" target="_blank">https://www.mvista.com</a></em></u></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 02:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270960/linux-drop-intel-carillo-ranch</guid>
            <link>https://www.oschina.net/news/270960/linux-drop-intel-carillo-ranch</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[cprobe —— All-in-One 的探針採集器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start">cprobe 是一個縫合怪，整合 Prometheus 服務發現的能力以及各類 Exporter 的能力，預期是做一個 All-in-One 的探針採集器。為何有此想法呢？主要是社區裏各類 Exporter 存在以下問題：</p><ul><li>良莠不齊：有的 Exporter 寫的非常棒，有的則並不完善，有些監控類別甚至有多個 Exporter，選擇困難</li><li>寫法各異：Exporter 所用的日誌庫、配置文件管理方式、命令行傳參方式各異</li><li>倚重邊車模式：有些 Exporter 和採集目標之間是一對一的關係，有幾個採集目標就需要部署幾個 Exporter，在 Kubernetes 環境下相對容易管理，在物理機虛擬機環境下管理起來就比較複雜了，而且多個 Exporter 還會帶來資源成本的提升</li><li>配置文件切分：對於非邊車模式的 Exporter，即一個 Exporter 對應多個採集目標的，通常很難做到不同的採集目標不同的配置，期望能有一種配置文件切分 INCLUDE 機制，不同的採集目標採用不同的配置</li><li>缺乏監控目標服務發現：對於支持 /probe 模式的 Exporter，服務發現就通過 Prometheus + relabel 模式來實現了，如果不支持 /probe 模式的 Exporter 則缺乏監控目標的服務發現機制</li></ul><p>要是能有一個統一的採集器把這些能力集成起來，統一規範化設計就好了，cprobe 應運而生。</p><h2 style="text-align:start">對比</h2><p style="color:#1f2328; text-align:start">社區有一些其他採集器，比如 grafana-agent，也是一個縫合怪，也是把各類 Exporter 的能力整合在一起，但是整合的非常生硬，缺少統一化設計，對目標實例的服務發現支持較弱；telegraf 和 categraf 則自成一派，指標體系沒有擁抱 Prometheus exporter 生態，相關儀表盤、告警規則資源匱乏，另外服務發現機製做的也不好。datadog-agent 確實比較完備，但是生態上也是自成一派，服務於自身的 SaaS 服務，較少有開源用户採用。</p><p style="color:#1f2328; text-align:start">以我當前的認知，監控數據的採集大抵需要三個角色，一個是部署在所有的目標機器上的，比如使用 categraf，中心端需要兩個採集器，一個用於採集 Prometheus 協議的端點數據，可以使用 vmagent 或 Prometheus agent mode，另外一個用於採集所有非 Prometheus 協議的端點數據，計劃就是 cprobe。</p><h2 style="text-align:start">當前進展</h2><p style="color:#1f2328; text-align:start">cprobe 剛剛起步，目前主要是在完善基礎框架，框架層面已經達到 GA 的水平，插件已經整合進來了 mysql_exporter、redis_exporter、kafka_exporter、blackbox_exporter。這個時候的代碼是最為簡單清晰的最小功能集，如果大家想要參與，建議閲讀此時的代碼。</p><p style="color:#1f2328; text-align:start">代碼倉庫：<a href="https://github.com/cprobe/cprobe">https://github.com/cprobe/cprobe</a></p><h2 style="text-align:start">安裝</h2><p style="color:#1f2328; text-align:start">到 cprobe 的 releases 頁面<span>&nbsp;</span><a href="https://github.com/cprobe/cprobe/releases">https://github.com/cprobe/cprobe/releases</a><span>&nbsp;</span>下載發佈包。解包之後核心就是那個二進制 cprobe，通過如下命令安裝：</p><div style="text-align:start"><pre>./cprobe --install
./cprobe --start
</pre></div><p style="color:#1f2328; text-align:start">如果是支持 systemd 的 OS，上面的安裝過程實際就是自動創建了 service 文件，你可以通過下面的命令查看：</p><div style="text-align:start"><pre>systemctl status cprobe
</pre></div><p style="color:#1f2328; text-align:start">如果不是 systemd 的 OS，會採用其他進程管理方式，比如 Windows，會創建 cprobe 服務。</p><h2 style="text-align:start">配置</h2><p style="color:#1f2328; text-align:start">解壓縮之後應該可以看到 conf.d 目錄，這是配置文件所在目錄，未來的規劃是 writer.yaml + 一堆插件目錄，當然項目起步階段，所以只有 writer.yaml + mysql，因為只有 mysql 一個插件得到支持。</p><p style="color:#1f2328; text-align:start">writer.yaml 是配置 remote write 地址（不知道什麼是 remote write 地址，請自行 Google：Prometheus remote write），可以配置多個，默認配置如下：</p><div style="text-align:start"><pre><span style="color:var(--color-prettylights-syntax-entity-tag)">global</span>:
  <span style="color:var(--color-prettylights-syntax-entity-tag)">extra_labels</span>:
    <span style="color:var(--color-prettylights-syntax-entity-tag)">colld</span>: <span style="color:var(--color-prettylights-syntax-string)">cprobe</span><span style="color:var(--color-prettylights-syntax-entity-tag)">writers</span>:
- <span style="color:var(--color-prettylights-syntax-entity-tag)">url</span>: <span style="color:var(--color-prettylights-syntax-string)">http://127.0.0.1:9090/api/v1/write</span></pre></div><p style="color:#1f2328; text-align:start">這是一個極簡配置，也基本夠用，實際 writer.yaml 中還可以配置不同時序庫後端的認證信息以及 relabel 的配置，同級目錄下有個 backup.yaml 可以看到一些配置樣例。</p><p style="color:#1f2328; text-align:start">不同的插件的配置會散落在各個插件目錄裏，以 mysql 插件舉例，相關配置在<span>&nbsp;</span><code>conf.d/mysql</code><span>&nbsp;</span>下面，入口文件是 main.yaml，用於定義需要採集的 mysql target，計劃至少提供三種 service discovery 機制：static_configs、http_sd_configs、file_sd_configs，這個配置和 Prometheus 的 scrape 配置基本保持一致。</p><p style="color:#1f2328; text-align:start">在 cprobe 場景下，cprobe 會直連監控目標，比如 mysql 的監控，Prometheus 是從 mysqld_exporter 獲取監控數據，而 cprobe 是直連 mysql，所以 main.yaml 中要配置一些採集規則，即 scrape_rule_files。scrape_rule_files 是個數組，即可以把配置文件切分管理，這提供了極大的管理靈活性，各位自行發揮了。</p><p style="color:#1f2328; text-align:start">mysql 的採集插件 fork 自 mysqld_exporter，所以相關指標體系、儀表盤都可以複用。當然，也做了一些改造，原來 mysqld_exporter 是一套採集規則應用到所有的 target，在 cprobe 這裏，不同的 target 可以採用不同的 scrape_rules，修改了原來通過命令行傳參的機制以支持併發。另外就是擴展了自定義 SQL 能力，通過自定義 SQL 來抓取更多監控指標。更多信息可以參考：<a href="https://github.com/cprobe/cprobe/tree/main/conf.d/mysql/doc">mysql 插件文檔</a>。</p><h2 style="text-align:start">後續規劃</h2><p style="color:#1f2328; text-align:start">最核心的是增加更多插件，不同的插件要整理儀表盤、告警規則。框架層面，希望增加更多自埋點數據，通過 HTTP 的方式暴露更多調試信息。另外就是完善中英文文檔。當然，大家如有建議也歡迎留言給我們。</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/cprobe</guid>
            <link>https://www.oschina.net/p/cprobe</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 自主開發的網絡協議棧 onps]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-onps 網絡協議棧" class="anchor" href="https://gitee.com/Neo-T/open-npstack#onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88"></a>onps 網絡協議棧</h1><h4><a id="user-content-背景" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%83%8C%E6%99%AF"></a>背景</h4><p>大約是 06 年，因項目之需我開始接觸應用於單片機系統的國外開源 tcp/ip 協議棧——LwIP，並藉此順勢創作了我的第一本印成鉛字的書——《嵌入式網絡系統設計——基於 Atmel ARM7 系列》。這本書的反響還不錯，好多人給我發 msn（可惜這麼好的一個即時通訊工具就這麼被微軟放棄了，好多聯繫人就此失聯， <img class="emoji" alt=":persevere:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/persevere-1f8fa05847efd349c0f2c62b1cee5bd1.png" width="14" height="14" referrerpolicy="no-referrer"> ）或郵件諮詢相關問題。在我原來的寫作計劃中，這本書的出版只是一個開始，接下來還要寫第二本——系統介紹 LwIP 包含的 ppp 協議棧的移植、應用及設計實現等相關內容。但，事與願違，這本書跳票了，且這一跳就是十二年……</p><p>細細想來，當初跳票的主因有二：其一，因家庭、工作等致可支配時間太少；其二，缺乏足夠的 ppp 協議相關知識及技術儲備致信心不足，畏首畏尾，裹足不前。但，這件事始終是我的一個遺憾。十二年的時間，不長亦不短，但足夠讓心底的遺憾變成一粒小小的種子並茁壯成長為一棵夢想的參天大樹。</p><p>如今，世界來到了疫情肆虐的二零年代。我的可支配時間多了起來，技術能力亦遠非當年可比。夢想之樹到了開花結果的時候了。遙想當初，入行還沒幾年，技術能力有限，我只能站在大神的肩膀上研究如何移植、使用 LwIP，ppp 棧碰都沒敢碰。現在，如果還只是延續十幾年前的工作，那這件事做起來就無甚意義。基於對自身技術實力的準確認識，我決定自己從零開始搭建一個完整的網絡協議棧。終，歷 6 個月餘，onps 協議棧（onps，open net protocol stack）完成初版開發，並內部測試通過。十餘年的遺憾今日得償。另，從業 20 餘年，內心終有一個做核心基礎軟件的夢。今，這二之夢想亦藉此得償。</p><p>新鶯初啼，總免不了會有諸多不盡如人意的地方。開源，則可與志趣相投者共享、共用、共研，歷諸位嚴苛手段使之快速迭代，快速成熟，比肩 LwIP 可期 <img class="emoji" alt=":blush:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/blush-85d11d8b7459d18f70eab0659c19a266.png" width="14" height="14" referrerpolicy="no-referrer"> 。</p><h4><a id="user-content-簡介" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%AE%80%E4%BB%8B"></a>簡介</h4><p>onps 是一個開源且完全自主開發的國產網絡協議棧，適用於資源受限的單片機系統，提供完整地 ethernet/ppp/tcp/ip 協議族實現，同時提供 sntp、dns、ping 等網絡工具，支持以太網環境下 dhcp 動態 ip 地址申請，也支持動態及靜態路由表。協議棧還封裝實現了一個伯克利套接字（Berkeley sockets）層。該層並沒有完全按照 Berkeley sockets 標準設計實現，而是我根據以往 socket 編程經驗，以方便用户使用、簡化用户編碼為設計目標，重新聲明並定義了一組常見 socket 接口函數：</p><ul><li>socket：創建一個 socket，目前僅支持 udp 和 tcp 兩種類型</li><li>close：關閉一個 socket，釋放當前佔用的協議棧資源</li><li>connect：與目標 tcp 服務器建立連接（阻塞型）或綁定一個固定的 udp 服務器地址</li><li>connect_nb：與目標 tcp 服務器建立連接（非阻塞型）</li><li>is_tcp_connected：獲取當前 tcp 鏈路的連接狀態</li><li>send：數據發送函數，tcp 鏈路下為阻塞型</li><li>send_nb：數據發送函數，非阻塞型</li><li>is_tcp_send_ok：數據是否已成功送達 tcp 鏈路的對端（收到 tcp ack 報文）</li><li>sendto：udp 數據發送函數，發送數據到指定目標地址</li><li>recv：數據接收函數，udp/tcp 鏈路通用</li><li>recvfrom：數據接收函數，用於 udp 鏈路，接收數據的同時函數會返回數據源的地址信息</li><li>socket_set_rcv_timeout：設定 recv() 函數接收等待的時長，單位：秒</li><li>bind：綁定一個固定端口、地址</li><li>listen：tcp 服務器進入監聽狀態</li><li>accept：接受一個到達的 tcp 連接請求</li><li>tcpsrv_recv_poll：tcp 服務器專用函數，等待任意一個或多個 tcp 客户端數據到達信號</li><li>socket_get_last_error：獲取 socket 最近一次發生的錯誤信息</li><li>socket_get_last_error_code：獲取 socket 最近一次發生的錯誤編碼</li></ul><p>協議棧簡化了傳統 BSD socket 編程需要的一些繁瑣操作，將一些不必要的操作細節改為底層實現，比如 select/poll 模型、阻塞及非阻塞讀寫操作等。簡化並不意味着推翻，socket 接口函數的基本定義、主要參數、使用方法並沒有改變，你完全可以根據以往經驗及編程習慣快速上手並熟練使用 onps 棧 sockets。 <strong>無須過多關注協議棧底層，利用 socket api 編程即可完全滿足複雜通訊應用的需求，而不像 LwIp 一樣需要使用它自定義的一組接口函數才能達成同樣的目標。</strong></p><p>為了適應單片機系統對內存使用極度變態的苛刻要求，onps 協議棧在設計之初即考慮採用寫時零複製（zero copy）技術。用户層數據在向下層協議傳遞過程中，協議棧採用 buf list 鏈表技術將它們鏈接到一起，直至將其發送出去，均無須任何內存複製操作。另外，協議棧採用 buddy 算法提供安全、可靠的動態內存管理功能，以期最大限度地提高協議棧運行過程中的內存利用率並儘可能地減少內存碎片。</p><p>不同於本世紀 00 到 10 年代初，單片機的應用場景中 ucosii 等 rtos 尚未大規模普及，前後台系統還大行其道的時代，現如今大部分的應用場景下開發人員選擇使用 rtos 已成為主流。因此，協議棧在設計之初即不支持前後台模式，其架構設計建立在時下流行的 rtos（RT-Thread、ucosii/iii 等）之上。協議棧移植的主要工作也就自然是針對不同 rtos 編寫相關 os 適配層功能函數了。當然，如果你有着極其特定的應用場景，需要將 onps 棧移植到採用前後台模式的單片機上，我的建議是保留 tcp/udp 之下協議層的通訊處理邏輯，調整上層的系統架構使其適應目標系統運行模式。</p><h4><a id="user-content-軟件架構" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84"></a>軟件架構</h4><p>onps 棧設計實現了一套完整的 tcp/ip 協議模型。從數據鏈路層到 ip 層，再到 tcp/udp 層以及之上的伯克利 socket 層，最後是用户自己的通訊應用層，onps 棧實現了全棧覆蓋，能夠滿足絕大部分的網絡編程需求。其架構如下：
<img src="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="onps 棧架構" referrerpolicy="no-referrer"></p><p>可以看出，其與傳統的網絡編程模型並沒有什麼不同，用户仍然是繼續利用 socket api 編寫常見的 tcp 及 udp 網絡應用。同時你還可以利用協議棧提供的幾個網絡工具進行網絡校時、dns 查詢等操作。</p><h4><a id="user-content-目錄結構" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"></a>目錄結構</h4><table><thead><tr><th>名稱</th><th>描述</th></tr></thead><tbody><tr><td>bsd</td><td>伯克利 sockets 層的相關接口函數實現源文件</td></tr><tr><td>ethernet</td><td>以太網協議族如 ethernet-ii/arp 及 emac 層、dhcp 客户端等的相關實現源文件</td></tr><tr><td>include</td><td>協議棧的頭文件</td></tr><tr><td>ip</td><td>ip 及其上層 icmp/tcp/udp 協議族的相關實現源文件</td></tr><tr><td>mmu</td><td>協議棧內存管理模塊的相關實現源文件</td></tr><tr><td>net_tools</td><td>網絡工具實現源文件，如 dns 查詢、網絡校時、ping、telnet 等</td></tr><tr><td>netif</td><td>網卡及路由管理等相關接口實現源文件</td></tr><tr><td>port</td><td>協議棧移植相關的源文件</td></tr><tr><td>ppp</td><td>ppp 鏈路層相關實現源文件，包括 lcp/ipcp/chap/pap 等協議族的實現源文件</td></tr><tr><td>TcpServerForStackTesting</td><td>用於協議棧測試的 tcp 服務器，IDE 為 vs2015 開發，目標系統為 win7 及以上</td></tr><tr><td>test_code</td><td>linux 下的 ppp 撥號原理驗證文件</td></tr></tbody></table><h4><a id="user-content-移植及使用説明" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A7%BB%E6%A4%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"></a>移植及使用説明</h4><p>協議棧支持主流的 ARM Cortex 系列 MCU，支持 Keil MDK、IAR 等常見 IDE。移植的核心工作就是完成 RTOS 模擬層的編寫及適配，詳細的移植説明請參考《onps 網絡協議棧移植及使用説明 v1.0》一文，點此<a href="https://gitee.com/Neo-T/open-npstack/releases/download/v1.0.0.221017/onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E7%A7%BB%E6%A4%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8Ev1.0.7z">下載</a>。本説明提供了 STM32F103RCT6 及 STM32F407VET6 兩種硬件平台的移植樣例，每種樣例分別針對 RT-Thread 和 ucosii 兩種 RTOS。樣例工程經過了嚴格的內部測試，可以直接使用。</p><p>如果你沒有太多時間，或者樣例工程與你的目標平台並不匹配，你可以直接參考協議棧移植的一般性指導文件<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E7%A7%BB%E6%A4%8D%E6%89%8B%E5%86%8C.pdf">《onps 棧移植手冊》</a>。</p><p>協議棧開發的一般性指導文件請參考<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88API%E6%8E%A5%E5%8F%A3%E6%89%8B%E5%86%8C.pdf">《onps 棧 API 接口手冊》</a>及<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.pdf">《onps 棧用户使用手冊》</a>。</p><h4><a id="user-content-移植樣例" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A7%BB%E6%A4%8D%E6%A0%B7%E4%BE%8B"></a>移植樣例</h4><p><strong>STM32F407VET6 平台</strong> ：
<a href="https://gitee.com/Neo-T/onps-rtthread">RT-Thread 移植樣例</a><a href="https://gitee.com/Neo-T/onps-ucosii">ucos-ii 移植樣例</a></p><p><strong><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307">沁恆 CH32V307 平台</a></strong> ：
<a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/HarmonyOS/LiteOS_m">鴻蒙 LiteOS-M 移植樣例</a><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/FreeRTOS">Free-rtos 移植樣例</a><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/rt-thread">RT-Thread 移植樣例</a></p><h4><a id="user-content-社區支持" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A4%BE%E5%8C%BA%E6%94%AF%E6%8C%81"></a>社區支持</h4><p>您可以隨時訪問<a href="https://gitee.com/link?target=http%3A%2F%2Fwww.onps.org.cn"><strong>onps 棧官方網站</strong></a>，獲取協議棧研發進度、後續計劃、最新版本等相關信息。<br>如您在使用過程中遇到任何問題或建議，您可以到 <strong><a href="https://gitee.com/link?target=http%3A%2F%2Fneo.onps.org.cn">onps 棧交流社區</a></strong> 提出您的建議或問題，新版本發佈也會在交流社區第一時間通知。<br>您也可以加入 QQ 羣進行在線技術交流：<br><img src="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81%E7%BE%A4%E7%BE%A4%E4%BA%8C%E7%BB%B4%E7%A0%81.png" alt="qq 交流羣" referrerpolicy="no-referrer"></p><h4><a id="user-content-許可協議" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE"></a>許可協議</h4><p>Apache License 2.0 開源許可協議</p><h4><a id="user-content-通過 oscs 安全認證" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E9%80%9A%E8%BF%87oscs%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81"></a>通過 OSCS 安全認證</h4><p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.murphysec.com%2Faccept%3Fcode%3D64bea0edfe145ac454cc464b23659406%26type%3D1%26from%3D2%26t%3D2"><img src="https://www.murphysec.com/platform3/v3/badge/1615596818625232896.svg?t=1" alt="Security Status" referrerpolicy="no-referrer"></a></p><h4><a id="user-content-後續計劃" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E5%90%8E%E7%BB%AD%E8%AE%A1%E5%88%92"></a>後續計劃</h4><ul><li>更多目標平台的適配工作， 提供相應移植樣例</li><li>重構部分代碼， 進一步降低代碼尺寸及內存消耗</li><li>支持 ftp 客户端/服務器</li><li>支持 http 客户端/服務器</li></ul><h4><a id="user-content-捐贈" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E6%8D%90%E8%B5%A0"></a>捐贈</h4><p>為了項目能夠持續下去，期望得到您的支持，您可以掃描下面的二維碼通過支付寶/微信向本項目捐款：</p><p><img src="https://gitee.com/Neo-T/open-npstack/raw/master/alipayn.jpg" alt="支付寶" referrerpolicy="no-referrer"><img src="https://gitee.com/Neo-T/open-npstack/raw/master/tencentpay.jpg" alt="微信" referrerpolicy="no-referrer"></p>]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/Neo-T/open-npstack</guid>
            <link>https://gitee.com/Neo-T/open-npstack</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 深度解讀 Cascades 查詢優化器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>數據庫中查詢優化器是數據庫的核心組件，其決定着 SQL 查詢的性能。Cascades 優化器是 Goetz 在 volcano optimizer generator 的基礎上優化之後誕生的一個搜索框架。</p><p>本期技術貼將帶大家瞭解 Cascades 查詢優化器。首先介紹 SQL 查詢優化器，接着分析查詢優化基本原理，最後對 Cascades 查詢優化器進行重點介紹。</p><span id="OSC_h1_1"></span><h1>一、SQL 查詢優化器</h1><p>用户與數據庫交互時只需要輸入聲明式 SQL 語句，數據庫優化器則負責將用户輸入的 SQL 語句進行各種規則優化，生成最優的執行計劃，並交由執行器執行。優化器對於 SQL 查詢具有十分重要的意義。</p><p>如圖 1 所示，SQL 語句經過語法和詞法解析生成抽象語法樹 (AST)，經過**基於規則的查詢優化（Rule-Based Optimizer）<strong>和</strong>基於代價的查詢優化（Cost-Based Optimizer）**生成可執行計劃。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-2f53e715e5e2dc13da2ae7593b5a622c7a2.png" referrerpolicy="no-referrer"></p><p style="text-align:center">圖 1</p><ul><li><p><strong>基於規則的優化算法</strong>:&nbsp;基於規則的優化方法的要點在於結構匹配和替換。應用規則的算法一般需要先在關係代數結構上匹配一部分局部的結構，再根據結構的特點進行變換乃至替換操作。</p></li><li><p><strong>基於成本的優化算法</strong>:&nbsp;現階段主流的方法都是基於成本（Cost）估算的方法。給定某一關係代數代表的執行方案，對這一方案的執行成本進行估算，最終選擇估算成本最低的方案。儘管被稱為基於成本的方法，這類算法仍然往往要結合規則進行方案的探索。基於成本的方法其實是通過不斷的應用規則進行變換得到新的執行方案，然後對比方案的成本優劣進行最終選擇。</p></li></ul><span id="OSC_h1_2"></span><h1>二、查詢優化的基本原理</h1><p>優化器一般由三個組件組成：<strong>統計信息收集</strong>、<strong>開銷模型</strong>、<strong>計劃列舉</strong>。</p><p>如圖 2 所示，開銷模型使用收集到的統計信息以及構造的不同開銷公式，估計某個特定查詢計劃的成本，幫助優化器從眾多備選方案中找到開銷最低的計劃。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-74c10d3f0e3e2443c51805fe0a0d7742ec4.png" referrerpolicy="no-referrer"></p><p style="text-align:center">圖 2</p><p><strong>SQL 語句查詢優化基於關係代數這一模型：</strong></p><ul><li><p>SQL 查詢可以轉化為關係代數；</p></li><li><p>關係代數可以進行局部的等價變換，變換前後返回的結果不變但是執行成本不同；</p></li><li><p>通過尋找執行成本最低的關係代數表示，我們就可以將一個 SQL 查詢優化成更為高效的方案。</p></li></ul><p>尋找執行成本最低的關係代數表示，可以分為<strong>基於動態規劃的自底向上</strong>和<strong>基於 Cascades/Volcano 的自頂向下</strong>兩個流派。</p><ul><li><p><strong>自底向上搜索</strong>：從葉子節點開始計算最低成本，並利用已經計算好的子樹成本計算出母樹的成本，就可以得到最優方案；</p></li><li><p><strong>自頂向下搜索</strong>：先從關係算子樹的頂層開始，以深度優先的方式來向下遍歷，遍歷過程中進行剪枝。</p></li></ul><p>自底向上的優化器從零開始構建最優計劃，這類方法通常採用動態規劃策略進行優化，採用這類方法的優化器包括&nbsp;IBMSystem R。自頂向下的優化策略的優化器包括基於 Volcano 和 Cascades 框架的優化器。</p><span id="OSC_h1_3"></span><h1>三、Cascades 查詢優化器</h1><p>Cascades 查詢優化器採用自頂向下的搜索策略，並在搜索過程中利用 Memo 結構保存搜索的狀態。</p><p><strong>Cascades 關鍵組件構成：</strong></p><ul><li><p><strong>Expression</strong>：Expression 表示一個邏輯算子或物理算子。如 Scan、Join 算子；</p></li><li><p><strong>Group</strong>：表示等價 Expression 的集合，即同一個 Group 中的 Expression 在邏輯上等價。Expression 的每個子節點都是以一個 Group 表示的。一個邏輯算子可能對應多個物理算子，例如一個邏輯算子 Join(a,b)，它對應的物理算子包括{HJ(a, b), HJ(b, a), MJ(a, b), MJ(b, a), NLJ(a, b), NLJ(b, a)}。我們將這些邏輯上等價的物理算子稱為一個 Group（組）。注：HJ 表示 HashJoin 算子，MJ 表示 MergeJoin 算子，NLJ 表示 NestLoopJoin 算子；</p></li><li><p><strong>Memo</strong>：由於 Cascades 框架採用自頂向下的方式進行枚舉，因此，枚舉過程中可能產生大量的重複計劃。為了防止出現重複枚舉，Cascades 框架採用 Memo 數據結構。Memo 採用一個類似樹狀（實際是一個圖狀）的數據結構，它的每個節點對應一個組，每個組的成員通過鏈表組織起來；</p></li><li><p><strong>Transformation Rule</strong>：是作用於 Expression 和 Group 上的等價變化規則，用來擴大優化器搜索空間。</p></li></ul><p>Cascades 首先將整個 Operator Tree 按節點拷貝到一個 Memo 的數據結構中，Memo 由一系列的 Group 構成，每個算子放在一個 Group，對於有子節點的算子來説，將原本對算子的直接引用，變成對 Group 的引用。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8f15c28ea323e3c6c3812cb4345b2668089.png" referrerpolicy="no-referrer"></p><p style="text-align:center">圖 3</p><p>如圖 3 所示，生成該語法樹的 Memo 初始結構。Memo 結構中一個圓角框代表一個算子，圓角框右下角是對其 Children’s Groups 的引用，左下角是唯一標識符。生成初始的 Memo 結構後，可以採用 transform rule 進行邏輯等價轉換，規則如下：</p><ul><li><p>對於一個邏輯算子，其所有基於關係代數的等價表達式保存在同一個 Group 內，例如 join(A,B) -&gt; join(B,A)；</p></li><li><p>在一個 Group 內，對於一個邏輯算子，會生成一個或多個物理算子，例如 join -&gt; hash join,merge join，NestLoop join；</p></li><li><p>一個 Group 內，一個算子，其輸入（也可以理解為 subplan）可以來自多個 Group 的表達式。</p></li></ul><p>在圖 4 中，描述了一個部分擴展的 Memo&nbsp;結構，與圖 1 中的初始 Memo 相比，在同一個 Group 內，增加了等價的邏輯算子，以及對應的物理算子。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-be8b645c303e9167ab3ab1936afe751448f.png" referrerpolicy="no-referrer"></p><p style="text-align:center">圖 4</p><p>在探索的過程中，優化器就會通過開銷模型 Coster 藉助統計信息來計算子步驟的開銷，遍歷完每個 Memo Group 之後，歸總得到每個完整計劃的總開銷，最終選擇 Memo 中開銷最低的計劃。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-11ec37fc83f5aeeb91f0464308b62d14ecb.png" referrerpolicy="no-referrer"></p><p style="text-align:center">圖&nbsp;5</p><p>圖 5 中有三個 Group，分別對應三個邏輯算子：Join(a, b), GET(a) 和 GET(b)。Group 1（Group 2）中包含了所有對應 GET(a) （GET(b)）的物理算子，我們可以估算每個物理算子的代價，選取其中最優的算子保留下來。</p><p>為了防止枚舉過程出現重複枚舉某個表達式，Memo 結構體中還包含一個哈希表（exprHT），它以表達式為哈希表的鍵，用來快速查找某個表達式是否已經存在於 Memo 結構體中。</p><p>Cascades 採用自頂向下的方式來進行優化，以計劃樹的根節點為輸入，遞歸地優化每個節點或表達式組。如圖所示，整個優化過程從 Group 0 開始，實際上要先遞歸地完成兩個子節點（Group 1 和 Group 2）的優化。</p><p>因此，實際的優化完成次序是 Group 1 -&gt; Group2 -&gt; Group 0。在優化每個 Group 時，依次優化每個組員；在優化每個組員時，依次遞歸地優化每個子節點。依次估算當前組裏每個表達式 e 的代價 cost(e)，選擇最低得代價結果保存在 bestHT 中。優化結束時，查詢 Join(a,b) 對應的 Memo 結構體，獲取最低的執行計劃。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5148943/blog/10320570</guid>
            <link>https://my.oschina.net/u/5148943/blog/10320570</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Soul 上線自研語言大模型 SoulX]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>社交平台 Soul 正式上線自研語言大模型 SoulX。作為生成式人工智能最基礎、最核心的工具，SoulX 將作為 Soul 「AIGC+社交」佈局的重要基建，垂直應用於平台上多元社交互動場景，例如智能對話機器人「AI 苟蛋」、AI 輔助聊天、虛擬陪伴等諸多工具和創新功能，進一步豐富平台用户的社交體驗。</p><p>根據介紹，該模型基於海量數據訓練，具備 prompt 驅動、條件可控生成、上下文理解、多模態理解等能力。在保證對話流暢、自然、具備情感温度的同時，SoulX 覆蓋百種細粒度風險類別，通過訓練數據安全篩選、安全 SFT 數據構造、RLHF 安全對齊、推理攔截等策略來構建安全體系，保證了大模型的內容生產質量和安全性。</p><p><img height="444" src="https://oscimg.oschina.net/oscnet/up-83bee0805ad5819554ad5c4bf7d1885d136.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 10:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270889</guid>
            <link>https://www.oschina.net/news/270889</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MegEngine 正式支持 XLA 啦！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>XLA（Accelerated Linear Algebra）是 Google 提出的一個神經網絡編譯器，可以用於加速 AI 模型的訓練和推理。MegEngine 1.13.1 中也已經支持了 XLA，在訓練模型時可以選擇開啓此項功能，不同的模型可以獲得 10%~80% 不等的速度提升。</p><h2>主要的目標場景</h2><p>MegEngine 現在是動態執行的，即 python 中每一個 mge.functional 的調用都對應着底層 gpu 上的一次 kernel 執行。這種模式的好處在於實際的執行方式與代碼邏輯一致，所見即所得，非常的靈活；不過其問題是難以優化，性能可能不是最優。</p><p>而 XLA 採取靜態執行的方式，會將模型計算過程表達成一張靜態計算圖，稱為 「HLO」 （High-Level Optimized）。HLO 中包含計算圖的相關操作，張量的數據流程和形狀等信息。XLA 隨後會對 HLO 進行一系列的優化，並最終生成一個更優的計算圖，從而更快的完成計算。而 XLA 的侷限性就在於不夠靈活，對於 Tensor Shape 改變或者控制流等信息無法很好的表達。</p><p>現在 MegEngine 中已經支持了 XLA，模型訓練中一些比較靜態的場景，我們可以使用 XLA 來進行加速，從而縮短整個訓練過程的時間。</p><h2>使用方法與效果</h2><p>在使用 MegEngine 進行訓練時，可以通過對原來的訓練函數增加 xla_trace/partial_trace 裝飾器來啓用 XLA 編譯優化。</p><p>當整個模型是完全靜態時，我們可以使用 xla_trace 將整張網絡表達成一張靜態圖，然後交由 XLA 做後續的優化編譯，後續的執行過程將執行這張優化後的計算圖提升速度。</p><p>而如果我們模型中有一些動態性，比如訓練過程中一些 Tensor Shape 會發生變化，亦或者是存在控制流，我們可以使用 partial_trace，將網絡中靜態的部分 trace 成一些子圖並分別交給 XLA 進行編譯優化，而網絡中其他部分仍然保持動態執行，同時保證性能與靈活性。</p><p>下面展示了在 MegEngine 中，XLA 功能開啓前後，主流的神經網絡模型性能變化。其中藍色為 XLA 開啓之前的訓練速度，橙色為 XLA 開啓之後的訓練速度。在開啓 XLA 後，大部分模型的性能可以獲得 10%~40% 的提升，最多可以超過 80%。 <img src="https://data.megengine.org.cn/engine-website/assets/images/38f415d8-9963-11ee-a7f5-8272bed56fd1.png" alt="1.png" referrerpolicy="no-referrer"></p><p>關於 XLA 的更多信息及具體的使用方法可以參考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.megengine.org.cn%2Fdoc%2Fstable%2Fzh%2Fuser-guide%2Fmodel-development%2Fjit%2Fxla.html" target="_blank">https://www.megengine.org.cn/doc/stable/zh/user-guide/model-development/jit/xla.html</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 10:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5265910/blog/10321024</guid>
            <link>https://my.oschina.net/u/5265910/blog/10321024</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[麟卓發佈多平台軟件安裝包構建系統，支持 Windows 和 Linux]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京麟卓<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9I8Xo7H_LLHPmSy_HMY24A" target="_blank">宣佈推出</a></u>「多平台軟件安裝包構建系統」，用於解決 Windows 和 Linux 系統中傳統軟件封裝、安裝過程繁瑣、平台差異嚴重等諸多問題。</p><p>據介紹，該工具提供「一站式構建、安裝」功能，讓用户能夠輕鬆製作軟件安裝包程序，提升工作效率，簡化軟件封裝、安裝以及卸載流程。</p><blockquote><strong>下載地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linzhuotech.com%2FProduct%2FDownLoadWindows" target="_blank">https://www.linzhuotech.com/Product/DownLoadWindows</a></u></em></strong></blockquote><p>「多平台軟件安裝包構建系統」是利用統一交互界面和配置機制生成多平台軟件安裝包的系統，支持在 Windows、Linux 平台上進行目標軟件的多層級模塊化封裝以及安裝功能，主要具備以下優勢：</p><ul><li>軟件安裝便捷：簡化傳統軟件安裝流程中的解壓、拷貝以及配置環境等繁瑣操作。</li><li>人機交互統一：在不同的操作系統平台上，具備統一人機交互，方便用户進行多平台封裝。</li><li>功能操作簡單：具備多層級可選控制、安裝信息配置、自定義安裝腳本、環境配置等豐富功能的同時保證軟件操作簡潔，易學易用。</li></ul><p><img height="779" src="https://oscimg.oschina.net/oscnet/up-346f799048871759324d7ded950e159fa0d.png" width="1280" referrerpolicy="no-referrer"><img src="https://static.oschina.net/uploads/space/2023/1213/174623_Cjur_2720166.png" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-401cdffba4679c3bdb8ae9bb0feea96f222.png" referrerpolicy="no-referrer"></p><ul></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 09:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270878</guid>
            <link>https://www.oschina.net/news/270878</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟推出小模型 Phi-2，性能優於 Llama 2/Mistral 7B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">微軟<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fphi-2-the-surprising-power-of-small-language-models%2F" target="_blank">宣佈</a>推出一個 27 億參數的語言模型 Phi-2，並聲稱其性能可與大 25 倍的模型相匹配或優於。「展示了出色的推理和語言理解能力，展示了參數少於 130 億的基礎語言模型中最先進的性能。」</span></p><p><span style="color:#000000">其基準測試結果表明，只需 27 億個參數，Phi-2 就能在各種綜合基準測試中超越 Mistral 和 Llama-2 模型在 7B 和 13B 參數下的性能。與大 25 倍的 Llama-2-70B 模型相比，Phi-2 在多步推理任務（即編碼和數學）上實現了更好的性能。</span></p><p><span style="color:#000000">此外，Phi-2 的性能與最近發佈的 Google Gemini Nano 2 不相上下，甚至更勝一籌。</span></p><p><img height="179" src="https://oscimg.oschina.net/oscnet/up-195920a0bfb4c87cd5ca00cc5d3edd0c25d.png" width="500" referrerpolicy="no-referrer"></p><p><img height="101" src="https://oscimg.oschina.net/oscnet/up-00457009ea9fb83c5e5802e175d784bd463.png" width="500" referrerpolicy="no-referrer"></p><p>且<span style="background-color:#ffffff; color:#000000">與經過調整的現有開源模型相比，</span><span style="color:#000000">Phi-2 </span><span style="color:#1a202c">響應中的「毒性」和偏差也要更少。</span></p><p><span style="color:#1a202c"><img alt="" height="243" src="https://oscimg.oschina.net/oscnet/up-36ec3b182b6104dcd29d01e7b450d2cb42c.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">此前，谷歌發佈的 Gemini 演示視頻曾展示了其解決複雜物理問題，以及對學生進行糾錯的能力。微軟研究人員也將&nbsp;Phi-2 進行了同樣的測試，並表示它同樣能夠正確回答問題，和使用相同的提示糾錯。</span></p><p><img height="282" src="https://oscimg.oschina.net/oscnet/up-11a57788ae91ebd7277cc00ee2b3ab55339.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Phi-2 是微軟「小語言模型（SLM）」系列中的最新版本。第一個版本是擁有 13 億參數的 Phi-1，針對基本的 Python 編碼任務進行了微調。9 月，該公司將重點擴展到常識推理和語言理解，推出了一個新的 13 億參數模型 Phi-1.5，性能可與大 5 倍的模型相媲美。</span></p><p><span style="color:#000000">微軟表示，Phi-2 的效率使其成為想要探索增強人工智能安全性、可解釋性和語言模型道德發展等領域的研究人員的理想平台。目前，</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fml.azure.com%2Fregistries%2Fazureml-msr%2Fmodels%2Fmicrosoft-phi-2%2Fversion%2F3%3Ftid%3D72f988bf-86f1-41af-91ab-2d7cd011db47%23overview" target="_blank">Phi-2</a><span style="color:#000000"> 現已通過 Microsoft Azure AI Studio 的模型目錄發佈。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fphi-2-the-surprising-power-of-small-language-models%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270831/microsoft-phi-2-small-language-model</guid>
            <link>https://www.oschina.net/news/270831/microsoft-phi-2-small-language-model</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Wi-Fi 7 將於 2024 年初全面登場，速度比 Wi-Fi 6 提升 5 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#262626">WiFi 聯盟<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wi-fi.org%2Fdiscover-wi-fi%2Fwi-fi-certified-7" target="_blank">宣佈</a></u>將在明年 1 月 9 日至 12 日參加 CES 2024，並確認基於 IEEE 802.11be 的 Wi-Fi CERTIFIED 7 認證標準將於第一季度末之前正式推出。</span>與目前的 Wi-Fi 6 標準相比，該標準有望提供千兆位速度和其他改進。</p><p><img src="https://oscimg.oschina.net/oscnet/up-bf8bb1d4062d6abcdd5bde367ecbe4cc108.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0cc0e98c02c1b0b058bc6ac02b0b37ea771.png" referrerpolicy="no-referrer"></p><p>英特爾（Intel）和博通（Broadcom）去年展示的 Wi-Fi 7（也稱 802.11be）速度高達 5 Gbps，大大超過了 Wi-Fi 6 的典型最高速度約 1.7 Gbps。<strong>Wi-Fi 7 允許在 2.4GHz、5GHz 和 6GHz 頻率之間無縫切換</strong>，兼容設備可同時使用這些頻率，從而實現了這一目標。</p><p>此外，6GHz 頻譜可提供 320MHz 的超寬信道，吞吐量比 Wi-Fi 6 翻了一番，這是速度提升的關鍵因素。通過從 1024 QAM 升級到 4K QAM，新標準還將傳輸速率提高了 20%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-68acdc34185024028d7aabf4f9b688fd47e.png" referrerpolicy="no-referrer"></p><p>Wi-Fi 7 連接也有望比以前的規格更加穩定。多鏈路操作可智能平衡流量，使網絡能有效容納更多設備。聯盟表示，新標準將非常適合增強現實和虛擬現實應用。美國聯邦通信委員會（FCC）最近初步批准了 6GHz 頻譜上的超高速 Wi-Fi 關聯，這是使 VR 和 AR 設備能夠利用 Wi-Fi 7 的重要一步。</p><p>2024 年的推出日期與英特爾 2022 年的預測基本吻合。該公司計劃從明年開始推出支持 Wi-Fi 7 的個人電腦，並於 2025 年在市場上普及。高通公司也對 Wi-Fi 7 持樂觀態度，並將其與 5G 一起納入了 FastConnect 計劃。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 05:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270823/wi-fi-certified-7</guid>
            <link>https://www.oschina.net/news/270823/wi-fi-certified-7</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Log4Shell 兩週年，仍有不少項目使用包含漏洞的版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Log4Shell 是 Log4j 2.0（Log4J2）的一個 0day 遠程代碼執行漏洞，被定性為「過去十年來最大、最關鍵的漏洞」，最早由阿里巴巴集團於 2021 年 11 月 24 日發現並報告給 Apache 軟件基金會。</p><p>儘管已經過去了兩年，<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.veracode.com%2Fblog%2Fresearch%2Fstate-log4j-vulnerabilities-how-much-did-log4shell-change" target="_blank">但根據安全公司 Veracode 的報告</a></u></strong>，該漏洞的影響仍然存在。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-73861b3642e119baf3ccca3f3a037679b4f.png" referrerpolicy="no-referrer"></p><p>Veracode 分析了 2023 年 8 月 15 日至 11 月 15 日期間 90 天內的軟件掃描數據，針對 3,866 個組織運行 Log4j 版本 1.1 至 3.0.0-alpha1 的 38,278 個獨特應用程序。</p><p>在 Log4j 1.1 到 3.0.0-alpha1 版本中，有超過三分之一的應用程序使用了存在漏洞的 Log4j 版本。具體來説：</p><ul><li>2.8% 的應用程序仍在使用 Log4j2 2.0-beta9 到 2.15.0 之間的版本，這些版本存在 Log4Shell 漏洞。</li><li>另外 3.8% 的應用程序使用的是 Log4j2 2.17.0 版本，雖然該版本已修復了 Log4Shell 漏洞，但仍然存在 CVE-2021-44832 漏洞，這是一個高危的遠程代碼執行漏洞。</li><li>還有 32% 的應用程序使用的是 Log4j2 1.2.x 版本，這個版本在 2015 年 8 月已經停止維護，但在 2022 年 1 月 ASF 宣佈了三個影響該版本的關鍵漏洞。</li></ul><p>這些數據表明，儘管各方對 Log4Shell 漏洞進行了大規模的修復工作，但仍然存在許多應用程序使用了存在漏洞的 Log4j 版本。</p><p>Veracode 的研究還發現，許多開發者在將第三方庫引入到代碼後從未更新過這些庫。這也解釋了為什麼有如此大比例的應用程序在運行已經停止維護的 Log4j 版本。</p><p>此外，研究還發現，一旦開發者通過掃描發現了漏洞，他們通常會相對迅速地進行修復。但是，一些外部因素會拖慢開發人員的修復速度，例如缺乏信息或資源。</p><hr><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/173273/log4j-maintainer-response" target="_blank">Log4j 維護者：為向後兼容沒移除導致漏洞的舊功能</a></li><li><a href="https://www.oschina.net/news/174752/impact-of-apache-log4j" target="_blank">Apache Log4j 漏洞的影響規模</a></li><li><a href="https://www.oschina.net/news/203874/log4j-the-pain-just-keeps-going-and-going" target="_blank">「核彈級」 Log4j 漏洞仍普遍存在，並造成持續影響</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270803/state-log4j-vulnerabilities-2023</guid>
            <link>https://www.oschina.net/news/270803/state-log4j-vulnerabilities-2023</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 11 記事本的底部狀態欄將顯示「字符數統計」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Windows 11 內置的文本編輯器「記事本」添加了一項重要功能：在底部狀態欄顯示<strong>字符數統計</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-876aae8d39e39c30417766c1912f6ab4e65.png" referrerpolicy="no-referrer"></p><p>該功能會顯示使用者輸入的<strong>字符總數</strong>，包括字母、數字、符號、空格、標點符號等。「字符統計」與「字數統計」不一樣，字數統計僅計算文檔中的單詞總數，有人會覺得它比字符數統計更有用。</p><p>根據微軟的<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ghacks.net%2F2023%2F12%2F08%2Fwindows-11s-notepad-is-getting-a-character-count-on-the-status-bar%2F" target="_blank">公告</a></u>，記事本中的字符數統計有兩種工作方式。默認情況下，文本編輯器將在窗口底部的狀態欄上顯示文檔的字符數。如果使用者在文檔中選擇了文本，記事本將分別顯示所選文本的字符數和文檔的總計數。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270799/windows-11s-notepad-character-count-on-the-status-bar</guid>
            <link>https://www.oschina.net/news/270799/windows-11s-notepad-character-count-on-the-status-bar</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
