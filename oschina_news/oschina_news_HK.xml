<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 14 Mar 2024 12:31:03 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[中國 AIGC 產業全景報告：萬億市場潛力解析、全景圖譜揭秘及 50 家機構矚目亮相！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">《中國 AIGC 產業全景報告》（2023 年 3 月版）由量子位智庫出品。報告詳細分析了中國 AIGC（人工智能生成內容）產業的市場規模、產業全景圖譜、行業變革分析、代表案例以及值得關注的 AIGC 機構。</p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><img height="787" src="https://static.oschina.net/uploads/space/2024/0314/165804_tahR_4700705.png" width="1119" referrerpolicy="no-referrer"></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">以下是報告的核心內容概要：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>市場規模</strong>：</p><ul><li>預計到 2030 年，中國 AIGC 市場規模將達到萬億級別。</li><li>2023-2025 年為培育摸索期，2025-2027 年為應用蓬勃期，2028 年後為整體加速期。</li><li>AIGC 產業的營收模式主要包括 MaaS（Model as Service）、按產出內容量付費、軟件訂閲付費和模型定製開發費。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>產業全景圖譜</strong>：</p><ul><li>AIGC 產業分為基礎設施層、模型層和應用層。</li><li>基礎設施層包括數據層、算力層、計算平台等。</li><li>模型層主要分為底層通用大模型和中間層模型。</li><li>應用層涉及直接生產可消費內容、結合底層系統生產高附加值內容、提供內容生產輔助工具和提供體系化解決方案。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>行業變革分析</strong>：</p><ul><li>AIGC 技術將深刻影響線上遊戲、影視傳媒、內容資訊、電子商務等多個行業。</li><li>AIGC 技術的應用將提高創作靈活度、激發內容生產多樣性、降低內容創作門檻等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>代表案例</strong>：</p><ul><li>報告列舉了多家中國 AIGC 產業的代表性公司及其產品，如百度的「文心一言」、科大訊飛的 SMART-TTS 系統、阿里巴巴的達摩院和阿里雲、騰訊的 AlLab 等。</li><li>這些案例展示了 AIGC 技術在不同領域的應用，包括數字人生成、內容創作、虛擬主播、AI 寫作等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>中國最值得關注的 50 家 AIGC 機構（AIGC50）</strong>：</p><ul><li>報告評選出了中國最值得關注的 50 家 AIGC 機構，包括百度、阿里巴巴、騰訊、華為、京東科技、小冰公司等，這些機構在 AIGC 領域具有顯著的技術實力和市場影響力。</li></ul></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">報告強調了 AIGC 產業的快速發展和巨大潛力，同時也指出了產業發展中的挑戰和機遇。通過對市場規模的預測、產業圖譜的梳理、行業變革的分析以及代表性案例的展示，報告為讀者提供了一個全面的中國 AIGC 產業現狀和未來趨勢的視角。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">報告詳情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「開源中國 APP - 報告模塊」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下載地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前僅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 09:07:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283068</guid>
            <link>https://www.oschina.net/news/283068</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[VLC 下載量突破 50 億，計劃推出 Vision Pro 應用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">開發 VLC 及相關技術的非營利組織 VideoLAN 的總裁 Jean-Baptiste Kempf <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lowpass.cc%2Fp%2Fvlc-five-billion-downloads-vision-pro-app" target="_blank">透露</a>，開源多媒體播放器 VLC 在桌面和移動平台上的下載量已超過了 50 億次。</span></p><p><span style="color:#000000">VLC 於 2001 年首次發佈，是有史以來最成功、最知名的開源桌面應用程序之一。2019 年初，該應用的下載量突破了 30 億次；儘管 Netflix 等流媒體服務近年來有所增長，但大眾對它的興趣依然濃厚。就 11 月發佈的最新 VLC 版本而言，僅桌面用户的下載量就已達到了 3.35 億次。</span></p><p><img height="281" src="https://oscimg.oschina.net/oscnet/up-4d9be4beeb6dac65d1b5272e14016566b55.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">VLC 在移動設備上的使用量也在持續增加，Android 和 iOS 版本的應用程序總下載量約為 3.18 億次。Kempf 稱，「大家仍然在大量下載 VLC。」</span></p><p><span style="color:#000000">談到項目的未來規劃時，Videolan 團隊並不滿足於成為桌面設備上最受歡迎的多媒體播放器，並已經把目光投向了下一代平台。Kempf 表示，除了繼續開發 VLC 4.0，Videolan 團隊還在將 VLC 移植到蘋果的 Vision Pro 頭戴式耳機，未來甚至可能提供對 FAST 頻道和其他廣告支持的在線媒體的訪問。</span></p><p><span style="color:#000000">他們已經在 Vision Pro 上運行了一個版本的 VLC。不過，該應用程序尚未發佈。Kempf 稱，部分原因是潛在用户羣仍然很小。「我還不確定是否有任何用例」。Kempf 表示，他也願意為 Meta 的 Quest 耳機開發一個版本，雖然該平台上已經有「許多優秀的播放器」可用。</span></p><p><span style="color:#000000">Kempf 還解釋道，VLC 4.0 版本原本應在前段時間發佈，但由於其複雜程度高於預期所以導致了推遲。「我們一直在重寫 VLC 的整個核心」。此外，Videolan 團隊還在開發 VLC 的 WebAssembly 版本。</span></p><p><span style="color:#000000">Videolan 4 的 Nightly 版本提供了一個更加以內容為中心的界面，它將默認播放器窗口替換成了 someone’s library。不過，Kempf 提醒道，其中一些改動很可能會在應用程序正式發佈前被還原。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 08:40:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283057/vlc-five-billion-downloads</guid>
            <link>https://www.oschina.net/news/283057/vlc-five-billion-downloads</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[System76 計劃 5 月底發佈 COSMIC Desktop Alpha]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>System76 原計劃在第一季度末發佈 Rust 編寫的 COSMIC 桌面環境的第一個 alpha 版本，但現在他們將時間推遲到了 5 月下旬，以便有時間完成新桌面應用程序的功能開發工作。</p><p>最初，System76 打算將其首個 COSMIC alpha 版本與 Pop!_OS 22.04 上的 GNOME 應用程序一起發佈，但隨着 COSMIC <span style="color:#121212">應用程序取得良好進展</span>，他們打算將 alpha 版本的發佈時間推遲兩個月，以便使其應用程序處於更好的狀態。</p><p>System76 在終端編輯器、文本編輯器、文件管理器和應用程序商店方面都取得了不錯的進展。雖然首個 alphas 版本已經推遲發佈，但 System76 的目標仍然是在今年發佈 COSMIC 桌面穩定版，同時發佈的還有基於 Ubuntu 24.04 LTS 的 Pop!_OS 24.04。</p><p>COSMIC 開發人員最近完成了混合圖形支持、窗口最小化和還原、新壁紙、平鋪小程序和輸入設備設置等方面的工作。COSMIC 今後的工作主要集中在應用程序、圖標和其他用户界面方面。</p><p><img alt="" height="282" src="https://oscimg.oschina.net/oscnet/up-ac24e7f96ded9d378f335ac724fc52b08b7.webp" width="500" referrerpolicy="no-referrer"></p><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.system76.com%2Fpost%2Fcosmic-more-alpha-more-fun" target="_blank">查看官方博客</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 07:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283047/system76-cosmic-alpha-may</guid>
            <link>https://www.oschina.net/news/283047/system76-cosmic-alpha-may</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linus Torvalds 不滿 Linux 6.9 中的一些 Bcachefs 代碼]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Bcachefs 文件系統自從被納入 Linux 6.7 內核的上游版本以來，一直保持着良好的運行狀態。但現如今，隨着 Bcachefs 的功能更新被提交到 Linux 6.9 合併窗口，引發了 Linus Torvalds 對其中一些 proposed code 的不滿。</span></p><p><span style="color:#000000">維護者 Kent Overstreet 將針對 Linux 6.9 的 Bcachefs 改動的拉取請求<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2Flfypw4vqq3rkohlh2iwhub3igjopdy26lfforfcjws2dfizk7d%4032yk5dnemi4u%2F" target="_blank">總結為</a>：</span></p><ul><li><span style="color:#000000">Subvolume children btree；是為 walking subvolumes 提供用户空間界面所必需的，計劃在稍後提供</span></li><li><span style="color:#000000">對目錄結構檢查進行了大量改進</span></li><li><span style="color:#000000">改進了日誌管道，顯着提高了 high iodepth write workloads 的性能</span></li><li><span style="color:#000000">Discard path 改進：Discard path 更加高效，並且不再不必要地刷新日誌</span></li><li><span style="color:#000000">Buffered write path 現在可以避免佔用 inode lock</span></li><li><span style="color:#000000">調出用於 XFS 的各種庫代碼：time stats、mean_and_variance、darray、eytzinger、thread_with_file</span></li><li><span style="color:#000000">新的 mm helper：memalloc_flags_{save|restore}</span></li><li><span style="color:#000000">mempool now does kvmalloc mempools</span></li></ul><p><span style="color:#000000">但讓 Linus Torvalds 感到不解的是，這些補丁把 Bcachefs 代碼中的一些元素移到了一些 library-type 的代碼中，以至於可以輕鬆地被其他文件系統重用。</span></p><p><span style="color:#000000">Linus Torvalds 在</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3Dwg3djFJMeN3L_zx3P-6eN978Y1JTssxy81RhAbxB%3D%3DL8Q%40mail.gmail.com%2F" target="_blank">迴應</a><span style="color:#000000">相關 PR 時表示：「我看了看'make random bcachefs code be a library function'的內容，覺得毫無意義，最終決定在沒有進一步解釋的情況下我不會使用它（老實説，我不認為這些解釋站得住腳）。」</span></p><p><span style="color:#000000">並直言 "stdio_redirect_printf() "和 darray_char 都很「噁心」。建議 Overstreet 將其保留在自己的代碼中就好，不要試圖提交上來。如果實在不死心的話，建議他先做好以下幾點：</span></p><ul><li><span style="color:#000000">多加解釋</span></li><li><span style="color:#000000">有更合理的命名，減少噁心和完全無意義的 interfaces ("DARRAY()")。</span></li></ul><p><img height="318" src="https://oscimg.oschina.net/oscnet/up-87349de7cf38ec24e77d98c8c7165c68d31.png" width="500" referrerpolicy="no-referrer"></p><blockquote><p><span style="color:#000000">而且，僅僅找到一個其他文件系統來共享這種代碼並不足以證明它是一個合理的 interfaces 和合理的命名。</span></p><p><span style="color:#000000">但是，最主要的問題是瘋狂的數學計算。該死的，我們很久以前就討論過"mean and variance"這種愚蠢的垃圾。當時就錯了，現在還是錯的。你沒有解釋為什麼它不能使用簡單得多的 MAD（<em>median absolute deviation</em>），而不是使用 variance。這個錯誤的決定直接導致無意義地使用過於複雜的 128 位數學。</span></p><p><span style="color:#000000">我當時稱其為瘋狂的過度工程化，而就我所知，除了一些輕微的類型名稱細節外，絕對沒有任何變化。</span></p><p><span style="color:#000000">只要你把它改成某種只適用於 bcachefs 的東西，我就不介意。但現在，你卻試圖把這些垃圾作為通用庫代碼推向市場，讓其他人也能使用，這就意味着，我會介意這種過度設計的 interfaces。</span></p><p><span style="color:#000000">在其他方面，time_stats 看上去就像是一個有名稱和用途的正常 interfaces，但使用了這種可怕的基礎架構後，它就變得不倫不類了。</span></p></blockquote><p><span style="color:#000000">在 Overstreet 爭辯之後，Linus 進一步</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3DwhbgtooUErM9bOP2iWimndpkPLaPy1YZmbmHACU07h3Mw%40mail.gmail.com%2F" target="_blank">補充道</a><span style="color:#000000">：</span></p><blockquote><p><span style="color:#000000">加權版本的代碼字面上沒有任何變化。</span></p><p><span style="color:#000000">variance value 是不同的，但 MAD 和 standard deviation&nbsp;之間的區別基本上只是一個 constant factor（不同的分佈會有所不同，但那又怎樣？任何特定情況都會有特定的分佈）。那麼，為什麼 constant factor&nbsp;會對指數加權產生任何影響呢？</span></p><p><span style="color:#000000">不管怎樣，請隨意將您的代碼保存在 bcachefs 中。也許 xfs 甚至想複製該代碼。我不在乎，這看起來很愚蠢，但這是文件系統的選擇。但如果我們要把它打造成一個通用的內核庫，它就必須是健全的。不要讓人們僅僅為了隨機統計元素而進行 64 位平方根和 128 位除法。</span></p></blockquote><p><span style="color:#000000">因此，就目前情況而言，Linus Torvalds 並沒有接受這個針對 Linux 6.9 內核的 Bcachefs 拉取請求。至於後續如何，就要看新的 PR 會不會放棄這些補丁或以其他方式重新修改以滿足&nbsp;Linus 的要求。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 07:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283043/linux-6-9-bcachefs-attempt</guid>
            <link>https://www.oschina.net/news/283043/linux-6-9-bcachefs-attempt</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[不卡科技系列全新 Logo 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img height="1395" src="https://oscimg.oschina.net/oscnet/up-d91ca53fe6e4275e089c404f966b1009a32.jpg" width="1073" referrerpolicy="no-referrer"></p><p>新 Logo 由前 vivo 官網設計師操刀，更加高端大氣上檔次，有圓角也有稜角，預示着產品有態度也有温度。</p><p><img height="1298" src="https://oscimg.oschina.net/oscnet/up-0d5d0bafee553d66a62a40447c60c3e6116.png" width="2534" referrerpolicy="no-referrer"></p><p>也和官網整體風格匹配，更加成熟，商務和技術風格相融合，也是產品的基本調性。打造酷炫且實用的產品體驗。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283025</guid>
            <link>https://www.oschina.net/news/283025</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | 全球首位 AI 軟件工程師 Devin；谷歌承認「竊取」OpenAI 模型關鍵信息]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.13</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><strong><a href="https://www.oschina.net/news/282901/laravel-11-released" target="_blank">Laravel 11 正式發佈</a></strong></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Laravel 11 和 Laravel Reverb 現已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel-news.com%2Flaravel-11" target="_blank">發佈</a>。Reverb 是 Laravel 生態系統的最新成員，是第一方、可擴展的 WebSocket 服務器，旨在為用户的應用程序提供強大的實時功能。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Laravel 11 引入了：極簡應用結構、默認使用 SQLite、實現 health routing、提供每秒速率限制、支持優雅的加密密鑰輪換、改進隊列測試、引入新的 Artisan 命令、添加 Resend 郵件傳輸、集成 Prompt validator、新的 Artisan commands、Model Casts 改進、The once function、改進了使用內存數據庫進行測試時的性能、改進了對 MariaDB 的支持等等。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="352" src="https://oscimg.oschina.net/oscnet/up-0453b972568e047b7d57af4dd0cf5cf3c7d.png" width="500" referrerpolicy="no-referrer"></p><h3><strong><a href="https://www.oschina.net/news/282895/cognition-labs-devin" target="_blank">全球首位 AI 軟件工程師 Devin：能自學新語言、開發迭代 App、自動 Debug</a></strong></h3><p>初創公司 Cognition 近日發佈公告，宣佈推出全球首個 AI 軟件工程師 Devin，並號稱會徹底改變人類構建，軟件的方式。官方描述如下：Devin 是一位不知疲倦、技術嫺熟的隊友，隨時準備與您並肩作戰，或獨立完成，任務供您審查。有了 Devin，工程師可以專注於更有趣的問題，工程團隊可以努力實現更遠大的目標。Devin 在 SWE-bench 編碼基準測試中取得了突破性的成功，展示了執行復雜任務的能力，甚至超越了頂尖的人類工師。</p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-9eca7b14f877d8f53cdbf3e675e1942c4a7.png" width="500" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img height="160" src="https://oscimg.oschina.net/oscnet/up-4101ac3e993fdd0d11ceb478c4000751d2b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微信&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU4ODQwNTIxMw%3D%3D%26mid%3D2247526466%26idx%3D1%26sn%3D50c1810505d13cd76439d7099e062905%26scene%3D0" target="_blank">人工智能產業鏈 union</a></em></u></p><p><img height="123" src="https://oscimg.oschina.net/oscnet/up-26d3c03709ed15944aee6780c7a432211d8.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.cn%2Farticle_5182171545_134e1a99902001pzg3.html" target="_blank">界面新聞</a></em></u></p><p><img height="218" src="https://oscimg.oschina.net/oscnet/up-413b05deedd40f689af0d5326b693b401dc.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2Fusstock%2Fmggd%2F2024-03-13%2Fdetail-inanefqq3854800.d.html" target="_blank">環球市場播報</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img height="401" src="https://oscimg.oschina.net/oscnet/up-1b97b2ca5e5274365ef49658a177ccdc3d9.png" width="500" referrerpolicy="no-referrer"></p><p><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftremorlabs%2Ftremor" target="_blank">https://github.com/tremorlabs/tremor</a></em></u></p><hr><h2><span style="color:#16a085"><strong>事件點評</strong></span></h2><p><img height="527" src="https://oscimg.oschina.net/oscnet/up-8c63b78a5992700821d2183b90b07e6027b.png" width="500" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong><span style="background-color:#e67e22">每日 GitHub 精選</span></strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="659" src="https://oscimg.oschina.net/oscnet/up-07e7c0e0484d7ed9ad4c32f79130e119b77.png" width="500" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/q35lx4s6qq9ls4r/28_cognition_labs_devin_Epbxne3xzN.pdf" target="_blank">開源日報第 028 期：全球首位 AI 軟件工程師 Devin；谷歌承認「竊取」OpenAI 模型關鍵信息</a></u></em></h4></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>往期回顧</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/hh291xp9mxksc9i/27_ai_google_50_gpt_4_KfagjDXXfZ.pdf" target="_blank">開源日報第 027 期：AI 接連翻車的 Google 要變天了；互聯網大廠 50 款大模型及應用，能否全面超越 GPT-4？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/uwsizmmsnhq8zdk/26_git_hub_22_web_os_22_vue_rolldown_FpVykoR7rJ.pdf" target="_blank">開源日報第 026 期：大模型替代程序員根本就是一個偽命題；GitHub 頂流 "Web OS"</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6ho57sxydzsh9jh/25_ai_5_ax1LWz5GP5.pdf" target="_blank">開源日報第 025 期：買手機送大模型；「釣魚式維權」 須遏制；「AI 原生」 騙局江湖</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7xd6teyhekcvamw/24_risc_v_x86_arm_5LsjoStPUn.pdf" target="_blank">開源日報第 024 期：RISC-V 能否和 x86、Arm 一起成為三大主流架構；給閻王開發地府管理系統</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">開源日報第 023 期：Google = 開源，好評；Microsoft = 閉源收入還低，差評</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">開源日報第 022 期：輕鬆復現 Sora 模型；事關 CUDA 兼容，英偉達禁止了；百度還差一個 「遙遙領先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">開源日報第 021 期：閉源模型就是比開源安全；起訴 OpenAI 不能更贊同</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">開源日報第 020 期：為什麼王炸都來自 OpenAI；Pingora 最好不要用 YAML 當配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">開源日報第 019 期：我讓 AI 用 C 語言寫一個算法；微軟三進制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">開源日報第 018 期：蘋果十年造車夢碎；這個開源項目有點...「大膽」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">開源日報第 017 期：MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有 「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 06:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283024</guid>
            <link>https://www.oschina.net/news/283024</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[首款基於 RISC-V 的安卓設備將於 2024 年大規模商業化落地]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在阿里巴巴平頭哥玄鐵 RISC-V 生態大會上，阿里巴巴達摩院院長張建鋒在演講中指出，RISC-V 開源指令集架構發展迅速，在主流市場年平均增長率超過 40%，在主流應用佔比超過 30%，用 10 年時間完成了 Arm 30 年的歷史。 </span></p><p><span style="color:#000000">會上，達摩院還宣佈了多款玄鐵處理器的升級：玄鐵 C907 首次實現矩陣運算（Matrix）擴展，為未來 AI 加速計算提供更多選擇，並將集成到其他玄鐵處理器中；下一代旗艦處理器 C930 也將於年內推出。</span></p><p><span style="color:#000000">據悉，首款基於 RISC-V 的安卓設備也將於 2024 年大規模商業化落地。目前，國際及國內主流操作系統已完成與 RISC-V 的全適配，包括安卓、Linux、OpenHarmony、Debian、Fedora、Gentoo、Ubuntu、龍蜥、統信、openKylin、創維酷開系統、RTT 等操作系統。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283009</guid>
            <link>https://www.oschina.net/news/283009</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JetBrains 公佈 Ktor 2024 路線圖]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">JetBrains <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2024%2F03%2Fthe-ktor-roadmap-for-2024%2F" target="_blank">公佈</a>了 Ktor 的 0224 年開發路線圖。Ktor 是一個基於 Kotlin 的異步框架，用於創建微服務、Web 應用等。</span></p><p><span style="color:#000000">該公司在路線圖中表示，他們對 Ktor 的持續計劃和目標與前幾年保持一致。旨在努力保持框架的輕量級、靈活和透明，以便用户可以輕鬆創建強大且可維護的服務和客户端。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-085d99ec88e786fe7765205a2d60852b18c.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">項目團隊將致力於在每個新版本中提高所提供功能的質量和性能，同時擴展 Ktor 插件生態系統。此舉將涉及引入新插件來簡化現有用例（例如事務處理）並添加對新用例（例如 Observability 和 gRPC）的支持。</span></p><p><span style="color:#000000">在改進核心產品的同時，還將為用户提供更輕鬆的開發體驗。使插件生態系統更易於使用，並消除社區貢獻的障礙。以及致力於提高所提供文檔的範圍、質量和多樣性。並利用 Kotlin Multiplatform (KMP) 的穩定性和不斷髮展的多平台庫生態系統，讓 Ktor 開發人員能夠享受到 KMP 的優勢，創建多平台應用程序。</span></p><p><span style="color:#000000">計劃在 2024 年提供以下<strong>新功能</strong>：</span></p><ul><li><span style="color:#000000"><strong>OpenTelemetry 插件。</strong>計劃為 Ktor 客户端和服務器引入 OpenTelemetry 插件，這將使用户能夠生成遙測數據（指標、日誌和跟蹤）並公佈它以供收集。</span></li><li><span style="color:#000000"><strong>基於 gRPC 的服務。</strong>團隊正在努力添加 gPRC 支持。計劃 2024 年將通過慣用的 Kotlin 實現將 gRPC 集成到 Ktor 客户端和服務器中。JetBrains 表示，這將使創建和使用基於 gRPC 的服務像 HTTP 和 REST 一樣自然和熟悉。</span></li><li><span style="color:#000000"><strong>在 Ktor 3.0.0 中遷移到 Kotlinx-io。</strong>用 Kotlinx-io 提供的網絡類型替換現有的定製網絡類型，以使得多平台庫的創建者更容易支持 Ktor 客户端和服務器。通過此更新，現有 IO 功能將在 Ktor 3.0.0 中棄用，並將在 Ktor 4.0.0 中刪除。</span></li><li><span style="color:#000000"><strong>添加對託管事務的支持。</strong>目前 Ktor 服務需要手動管理數據庫事務，適合複雜的場景。但是，在許多情況下，最好在請求開始時啓動事務並在請求結束時提交事務，前提是沒有錯誤。JetBrains 計劃在 2024 年推出一個實現此行為的官方插件，簡化數據庫訪問，同時提供從 SQL 和特定於應用程序的異常中恢復的支持。</span></li><li><span style="color:#000000"><strong>簡化的依賴注入。</strong>將於 2024 年正式在 Ktor Server 中添加對 DI 的支持，併發布有關如何最好地集成現有 DI 庫的指南。</span></li></ul><p><span style="color:#000000">除了向 Ktor 添加新功能外，JetBrains 還將進行一些更改。包括對文檔進行改進，2024 年的重點是提高當前內容質量並擴大對新材料的支持，計劃通過多次迭代來支持：</span></p><ul><li><span style="color:#000000">擴展、改進和簡化 Ktor 服務器和 Ktor 客户端文檔的入門部分中的教程。</span></li><li><span style="color:#000000">解決雲部署和配置主題。</span></li><li><span style="color:#000000">介紹使用 Kotlin Multiplatform 進行全棧開發的綜合指南。</span></li><li><span style="color:#000000">擴大文檔中 API 的覆蓋範圍。</span></li></ul><p><span style="color:#000000">以及計劃進行結構性變革。教程將無縫地相互補充，更有效地鏈接主題，並且服務器和客户端內容將被重新組織以確保更清晰的區別。所有這些新增內容都將利用現代化的外觀和感覺，並與其他 JetBrains 框架和庫的文檔集成。</span></p><p><span style="color:#000000">JetBrains 還計劃引入一種接受第三方 Ktor 插件的機制。包括用於創建 Ktor 插件的新的簡化格式、項目生成器的新版本以及向 Ktor 團隊提交拉取請求的過程。</span></p><p><span style="color:#000000">此外，JetBrains 將在 2024 年發佈 Ktor CLI 工具。滿足對 JetBrains Intellij IDEA Ultimate IDE 中在線項目生成器或嚮導的基於命令行替代方案的需求。這一舉措將允許用户在終端或 shell 中創建和修改項目。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2024%2F03%2Fthe-ktor-roadmap-for-2024%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283003/ktor-roadmap-for-2024</guid>
            <link>https://www.oschina.net/news/283003/ktor-roadmap-for-2024</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[DeviceScript —— 用於微型物聯網設備的 TypeScript]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>DeviceScript 為基於低資源微控制器的設備帶來了專業的 TypeScript 開發人員體驗。DeviceScript 被編譯為自定義 VM 字節碼，可以在非常受限的環境中運行。</p><p><img alt="" height="313" src="https://static.oschina.net/uploads/space/2023/0530/145731_bXBv_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><strong>特性：</strong></p><ul><li><strong><a href="https://microsoft.github.io/devicescript/language">TypeScript for IoT</a></strong></li></ul><p>熟悉的語法和工具，盡在你的指尖。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/devices">Small Runtime</a></strong></li></ul><p>低功耗/閃存/內存的字節碼解釋器。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/developer/clients">Hardware as Services</a></strong></li></ul><p>傳感器和執行器的客户端/服務器架構。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/getting-started/vscode/debugging">Debugging</a></strong></li></ul><p>在 Visual Studio Code 中，用於嵌入式硬件或模擬設備。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/developer/simulation">Simulation and Testing</a></strong></li></ul><p>使用硬件/模擬傳感器開發和測試你的固件。CI 友好。</p><ul><li><strong><a href="https://microsoft.github.io/devicescript/developer/cloud/gateway">Development Gateway</a></strong></li></ul><p>具有設備管理、固件部署和消息隊列的 Prototype cloud service。</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/devicescript</guid>
            <link>https://www.oschina.net/p/devicescript</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 異構數據源同步服務 DatalinkX]]>
            </title>
            <description>
                <![CDATA[<p><img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/project_name.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FSplitfireUptown%2Fdatalinkx"><img src="https://img.shields.io/github/stars/SplitfireUptown/datalinkx.svg?style=flat&amp;label=GithubStars" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx"><img src="https://gitee.com/atuptown/datalinkx/badge/star.svg?theme=dark" alt="Gitee Starts" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx"><img src="https://gitee.com/atuptown/datalinkx/badge/fork.svg?theme=dark" alt="Gitee Starts" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#"><img src="https://img.shields.io/badge/Author-%E5%9C%A8%E4%B8%8Buptown-orange.svg" alt="作者" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/JDK-21-red.svg" alt="jdk 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/SpringBoot-3.2.1-green.svg" alt="SpringBoot 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/MySQL-8.0-orange.svg" alt="MySQL 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/Redis-5.0-green.svg" alt="Redis 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Redis%20Stream-red.svg" alt="Redis 版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/ORM-SpringData%20JPA-blue.svg" alt="ORM 框架" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1-xxljob-green.svg" alt="分佈式定時任務" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-Flink-red.svg" alt="計算引擎" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2-Docker%20&amp;%20DockerCompose-yellow.svg" alt="部署" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%89%8D%E7%AB%AF-Vue2.x-green.svg" alt="部署" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%89%8D%E7%AB%AFUI-AntDesignUI-red.svg" alt="前端" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/RPC-Retrofit2-blue.svg" alt="RPC 框架" referrerpolicy="no-referrer"></a><a href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"><img src="https://img.shields.io/badge/%E5%90%8C%E6%AD%A5%E6%A1%86%E6%9E%B6-Chunjun(FlinkX)-green.svg" alt="同步框架" referrerpolicy="no-referrer"></a></p><h2><a id="user-content-異構數據源同步服務 datalinkx 介紹" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%BC%82%E6%9E%84%E6%95%B0%E6%8D%AE%E6%BA%90%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1datalinkx%E4%BB%8B%E7%BB%8D"></a>異構數據源同步服務 DatalinkX 介紹</h2><p><strong>核心功能</strong> ：在不同的異構數據源中進行數據同步，對同步任務進行管理和維護</p><p><strong>意義</strong>：只要公司規模較大，部門與部門之間有數據協作都應該有類似 DatalinkX 的項目，比如爬蟲組的同事爬下來數據要定時同步到數倉組負責的庫下。同步服務會集中管理同步任務，收攏同步日誌、提高內部工作效率。</p><p><img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/image.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><h2><a id="user-content-項目特性" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E7%89%B9%E6%80%A7"></a>項目特性</h2><ul><li><strong>簡單易用</strong>：通過 Web 頁面快速創建數據源、同步任務，操作簡單，一分鐘上手</li><li><strong>定時觸發</strong>：對接 xxl-job 定時，設置 cron 表達式觸發同步任務</li><li><strong>配置化任務對接</strong>：將數據庫信息、任務詳情界面化配置</li><li><strong>高性能同步</strong>：使用高性能流式 flink 計算引擎</li><li><strong>容器化部署</strong>：支持 docker 部署</li></ul><h2><a id="user-content-項目技術棧" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%8A%80%E6%9C%AF%E6%A0%88"></a>項目技術棧</h2><table><thead><tr><th>依賴</th><th>版本</th><th>描述</th></tr></thead><tbody><tr><td>Spring Boot</td><td>3.2.1</td><td>項目腳手架</td></tr><tr><td>SpringData JPA</td><td>3.2.1</td><td>持久層框架</td></tr><tr><td>MySQL</td><td>8.0</td><td>DB 數據庫</td></tr><tr><td>ElasticSearch</td><td>7.x</td><td>支持流轉的數據庫</td></tr><tr><td>Redis</td><td>5.0 ↑</td><td>緩存數據庫</td></tr><tr><td>ChunJun(原 FlinkX)</td><td>1.10_release</td><td>袋鼠雲開源數據同步框架</td></tr><tr><td>Flink</td><td>1.10.3</td><td>分佈式大數據計算引擎</td></tr><tr><td>Xxl-job</td><td>2.3.0</td><td>分佈式調度框架</td></tr><tr><td>Retrofit2</td><td>2.9.0</td><td>RPC 通信服務</td></tr><tr><td>Jackson</td><td>2.11.4</td><td>反序列化框架</td></tr><tr><td>Maven</td><td>3.6.X</td><td>Java 包管理</td></tr><tr><td>Vue.js</td><td>2.X</td><td>前端框架</td></tr><tr><td>AntDesignUI</td><td>3.0.4</td><td>前端 UI</td></tr><tr><td>Docker</td><td></td><td>容器化部署</td></tr></tbody></table><h2><a id="user-content-啓動姿勢" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%90%AF%E5%8A%A8%E5%A7%BF%E5%8A%BF"></a>啓動姿勢</h2><h4><a id="user-content-中間件" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E4%B8%AD%E9%97%B4%E4%BB%B6"></a>中間件</h4><p>執行 <code>docker compose -p datalinkx up -d</code> 命令將各組件啓動</p><h5><a id="user-content-手動搭建組件 linux" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E7%BB%84%E4%BB%B6linux"></a>手動搭建組件（linux）：</h5><p>xxl-job: <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fxuxueli%2Fxxl-job%2Farchive%2Frefs%2Ftags%2F2.3.0.zip">https://github.com/xuxueli/xxl-job/archive/refs/tags/2.3.0.zip</a>
純 Java 項目，可 clone 代碼後打包成 jar 包啓動，xxl-job 依賴 mysql，需要修改對應數據庫地址配置，表結構在/xxl-job-2.3.0/doc/db/tables_xxl_job.sql，導入 mysql 即可。</p><p>flink：<a href="https://gitee.com/link?target=https%3A%2F%2Farchive.apache.org%2Fdist%2Fflink%2Fflink-1.10.3%2F">https://archive.apache.org/dist/flink/flink-1.10.3/</a>
選擇 flink-1.10.3-bin-scala_2.12.tgz 下載，解壓進入 bin 目錄執行./start-cluster.sh，首次運行默認只有一個任務 slot，訪問<a href="https://gitee.com/link?target=http%3A%2F%2Flocalhost%3A8081">http://localhost:8081</a> 進去 flink 後台頁面。</p><h4><a id="user-content-db 層" class="anchor" href="https://gitee.com/atuptown/datalinkx#db%E5%B1%82"></a>DB 層</h4><p>執行  /datalinkx-server/src/main/resources/db.sql</p><h4><a id="user-content-後端" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%90%8E%E7%AB%AF"></a>後端</h4><ol><li>運行<code>datalinkx-server</code>與<code>datalinkx-job</code>模塊
<ol><li><strong>datalinkx-server</strong>與 front 交互，依賴 mysql、redis</li><li><strong>datalinkx-job</strong>負責提交、維護任務的生命週期，依賴 xxl-job、flink
<ol><li>服務啓動後會默認使用 netty 啓動<code>${xxl.job.executor.port}</code> 負責監聽 xxl-job 的任務事件</li><li>任務執行詳細信息通過 datalinkx-client 的 rpc 能力訪問<code>${client.dataserver}</code></li><li>如果更改了 datalinkx-server 端口需要同步更改 datalinkx-job 配置項<code>${client.dataserver}</code>。</li><li><code>${flinkx.path}</code>配置 flinkx 模塊的路徑</li></ol></li><li>遇到依賴問題執行 <code>mvn clean -U </code></li></ol></li><li>flinkx 模塊為單獨的項目
<ol><li>需要手動執行<code>mvn clean install -U -Dmaven.test.skip=true -Dcheckstyle.skip=true</code>將插件打包</li><li>打包後配置好 flinkx/flinkconf 中 flink 的地址<code>jobmanager.rpc.address:</code>和端口<code>rest.port</code>即可</li></ol></li></ol><h4><a id="user-content-前端" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E5%89%8D%E7%AB%AF"></a>前端</h4><p><code>yarn install &amp;&amp; export NODE_OPTIONS=--openssl-legacy-provider &amp;&amp; yarn run serve</code></p><h2><a id="user-content-使用姿勢" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E4%BD%BF%E7%94%A8%E5%A7%BF%E5%8A%BF"></a>使用姿勢</h2><ol><li>登錄系統，默認密碼 admin、admin 登錄，沒有權限相關控制
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/login.png" alt="img.png" referrerpolicy="no-referrer"></li><li>數據源管理，配置數據流轉數據源信息
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/ds_config.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任務管理，配置 from_db 與 to_db 構造 job_graph
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/job_config.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任務級聯配置
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/job_cascade.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任務血緣
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/job_relation.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任務調度
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/xxl.png" alt="img.png" referrerpolicy="no-referrer"></li><li>任務執行
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/flink.png" alt="img.png" referrerpolicy="no-referrer"></li></ol><h2><a id="user-content-datalinkx 交流羣" class="anchor" href="https://gitee.com/atuptown/datalinkx#datalinkx%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>datalinkx 交流羣</h2><p>私聊進羣我會拉到項目交流羣中
<img src="https://gitee.com/atuptown/datalinkx/raw/main/datalinkx-server/src/main/resources/readme/author.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><h2><a id="user-content-項目文檔" class="anchor" href="https://gitee.com/atuptown/datalinkx#%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3"></a>項目文檔</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fnote.youdao.com%2Fs%2Fa9ltzlc1">細緻文檔帶你吃透 DatalinkX</a></p>]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/atuptown/datalinkx</guid>
            <link>https://gitee.com/atuptown/datalinkx</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 萬字帶你瞭解 ChatGLM]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>本文分享自華為雲社區《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F420208%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">【雲駐共創】華為雲之昇思 MindSpore 大模型專題（第二期）-第一課：ChatGLM</a>》，作者： 愚公搬代碼。</span></p><span id="OSC_h1_1"></span><h1><span><span>前言</span></span></h1><span id="OSC_h2_2"></span><h2><span>1.昇思 MindSpore</span></h2><p><span>昇思 MindSpore 是華為公司推出的一款全場景 AI 計算框架。它提供了自動微分、分佈式訓練和推理、模型部署等功能，支持多種硬件平台，包括 CPU、GPU 和 Ascend AI 處理器。MindSpore 採用圖和算子相結合的編程模型，能夠高效地處理複雜的深度學習任務。它具有靈活的設計、高效的性能和易於使用的接口，使開發者能夠更快地開發和部署 AI 應用。MindSpore 還支持自定義操作和算法，可以滿足不同場景下的需求。</span></p><span id="OSC_h2_3"></span><h2><span>2.大模型</span></h2><p><span>大模型是指具有數百萬到數十億個參數的深度學習模型。這些模型通常用於處理大規模數據集，並能夠在各種任務上取得出色的性能。大模型通常需要大量的計算資源進行訓練，並且需要更長的時間來收斂。然而，由於其具有更多的參數，大模型可以更好地捕捉數據中的複雜關係，從而提升模型的預測性能。大模型的應用範圍非常廣泛，包括自然語言處理、計算機視覺、語音識別等領域。</span></p><span id="OSC_h2_4"></span><h2><span>3.ChatGLM</span></h2><p><span>ChatGLM 是一種生成式語言模型，用於聊天和對話任務。它是基於 OpenAI 的 GPT 模型框架構建的，採用了大規模的預訓練數據集來學習語言模式和生成文本的能力。ChatGLM 可以理解上下文並生成連貫、自然的回覆。它可以用於構建對話系統、智能客服、聊天機器人等應用，能夠提供更加交互性和人性化的對話體驗。ChatGLM 模型的訓練和優化過程需要大量的計算資源和數據，而且模型的生成性質也需要進行適當的監督和過濾，以確保生成的回覆符合預期的行為準則和標準。</span></p><span id="OSC_h1_5"></span><h1><span><span>一、GLM Model Architecture</span></span></h1><span id="OSC_h2_6"></span><h2><span>1.Evolution Tree of LLMs</span></h2><p><span>Evolution Tree of LLMs（Language Model Megasuite 的演化樹）是指由 OpenAI 發佈的一系列語言模型的歷史和演化關係圖。</span></p><p><span>OpenAI 的 LLMs 系列是一系列基於深度學習的語言模型，旨在生成人類語言的自然文本。這些模型中的每一個都是通過對大量文本進行訓練而得到的，可以用於自動回答問題、生成文章、翻譯文本等自然語言處理任務。</span></p><p><span>Evolution Tree of LLMs 圖中展示了這些模型的發展歷程。從最早的模型開始，每個後續模型都是在前一個模型的基礎上進行改進和擴展。這些改進可能涉及模型的規模增加、訓練數據的增加、架構的改進等。通過不斷地改進和提升模型，OpenAI 致力於推動語言模型的發展，使其在各種自然語言處理任務上表現更加出色。</span></p><p><span>Evolution Tree of LLMs 圖不僅展示了各個模型之間的關係，還反映了 OpenAI 在不同時間點的研究重點和技術進展。這個圖可以幫助研究人員和開發者瞭解 LLMs 系列的發展歷程，從而更好地理解和應用這些語言模型。</span></p><p><span><img src="https://static001.geekbang.org/infoq/84/84d7f15028efbda63b9a3553a51913e6.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_7"></span><h2><span>2.Autoregressive Blank Infilling</span></h2><span id="OSC_h3_8"></span><h3><span>2.1 Autoregressive、Autoencoding、Encoder-Decoder</span></h3><p><span>「Autoregressive」、"Autoencoding"和"Encoder-Decoder"是三種常見的神經網絡模型結構，用於處理序列數據或生成模型。</span></p><p><span>Autoregressive（自迴歸）模型是一種生成模型，它將序列數據的生成建模為一個逐步預測每個元素的條件概率的過程。在每個時間步，模型根據之前生成的元素預測當前元素的概率分佈。常見的 Autoregressive 模型包括語言模型，如 OpenAI GPT 模型，它可以生成與輸入序列相似的新文本。</span></p><p><span>Autoencoding（自編碼）模型是一類無監督學習方法，用於學習輸入數據的緊湊表示。它由一個編碼器和一個解碼器組成。編碼器將輸入數據映射到低維表示，解碼器將該低維表示恢復到原始數據空間。Autoencoding 模型的目標是儘可能準確地重建輸入數據，同時學習到有用的特徵表示。常見的 Autoencoding 模型包括 Variational Autoencoder (VAE) 和 Denoising Autoencoder。</span></p><p><span>Encoder-Decoder（編碼器-解碼器）模型是一種常用的序列到序列（Sequence-to-Sequence）模型，用於處理輸入和輸出都是序列數據的任務。它由兩個部分組成：編碼器和解碼器。編碼器將輸入序列映射為固定大小的向量表示，解碼器使用該向量表示生成輸出序列。Encoder-Decoder 模型可以在不同長度的輸入和輸出序列之間進行轉換，例如機器翻譯和文本摘要等任務。</span></p><p><span>GLM（自迴歸填空）模型是一種靈活且多樣化的語言模型，可以根據給定的上下文生成缺失的部分內容。根據已知的部分文本內容生成可能的填空內容。它可以用於自動文本補全、問答系統、語義理解和生成等多個自然語言處理任務中。</span></p><p><span><img src="https://static001.geekbang.org/infoq/d0/d0d722561e2136aecdbee22b8cc9e4f2.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/b6/b69d1b89caf74a34b44f39dda2ecc13c.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_9"></span><h3><span>2.1 OpenAI GPT 系列模型</span></h3><p><span>自然語言處理領域的 GPT（Generative Pre-trained Transformer）系列模型是由 OpenAI 開發的一系列強大的自然語言處理模型。下面是 GPT 系列模型的發展歷程：</span></p><p><span>GPT-1: GPT 模型是於 2018 年發佈的第一代模型。它使用了 Transformer 架構，預訓練了一個大規模的語言模型，並使用無標籤的文本數據進行模型訓練。這個模型的特點是生成連貫的文本，能夠完成一些基礎的自然語言處理任務，如語言模型、文本分類和文本生成等。</span></p><p><span>GPT-2: 在 2019 年，OpenAI 發佈了 GPT-2 模型作為 GPT 的後續版本。GPT-2 模型採用了更大的預訓練模型，使用無標籤的互聯網文本進行訓練。這個模型在生成文本方面取得了突破性的進展，可以生成高質量、連貫的文本，使得生成的文本內容更具有逼真性。由於考慮到模型被濫用可能帶來的風險，OpenAI 最初限制了 GPT-2 的訪問，並未發佈完整的模型。</span></p><p><span>GPT-3: GPT-3 是在 2020 年發佈的 GPT 系列的第三代模型。參數量達到了 1750 億個，訓練了十幾萬小時。GPT-3 在文本生成、文本補全、問答系統等任務上表現出色，其生成的文本能夠接近人類水平的表達能力。GPT-3 還可以通過提供一些文本提示來理解並回答問題，具有較強的語言理解和推理能力。</span></p><p><span>GPT-4：在 2023 年，OpenAI 發佈了 GPT-4，這是 GPT 系列的第四個模型。GPT-4 比 GPT-3 系列大得多，具有 1.8 萬億個參數，而 GPT-3 只有 1750 億個參數。GPT4 是一種多模態模型，而 GPT3 系列是一種自然語言處理模型。自然語言模型只能聽或看懂語言，而多模態模型可以處理多種媒體數據，並且將他們整合到統一的語義空間之中。GPT4 可接收的文字輸入長度達到了驚人的 32000 字，而 GPT3 系列，只能輸入 3000 字。</span></p><p><span><img src="https://static001.geekbang.org/infoq/22/22cd98f7991e34b325e96903d431ee3d.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_10"></span><h3><span>2.3 Autoregressive Blank Infilling</span></h3><p><span>Autoregressive Blank Infilling（ABI）是一種用於填充時間序列數據中缺失值的方法。在時間序列數據中，由於種種原因，可能會存在一些缺失值，這些缺失值會影響數據的完整性和準確性。ABI 方法通過基於自迴歸模型，利用其他已有的數據來預測並填補缺失值。</span></p><p><span>ABI 方法的基本思想是根據時間序列數據的自相關性，使用已有的數據點來逐個預測缺失值。具體來説，ABI 方法使用 AR 模型（自迴歸模型）來建模時間序列數據中的缺失值和非缺失值之間的關係。然後，根據該模型，利用其他已有的數據點來預測缺失值的數值。</span></p><p><span>ABI 方法在填充缺失值時，通常還會考慮一些其他因素，如數據的趨勢、季節性和週期性等。通過綜合考慮這些因素，ABI 方法能夠更準確地填充缺失值，從而提高數據的完整性和可靠性。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>順序分為 A 部分和 B 部分：</span></p><ul><li><p><span>A 部分：帶掩碼跨度的序列</span></p></li><li><p><span>B 部分：在 A 部分中被掩蓋的原始跨度</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/9c/9cd53a85acf9c50e4dbcb787418f89ca.png" referrerpolicy="no-referrer"></span></p><p><span>如果多個跨度被遮罩，它們將在 B 部分中被打亂</span></p><p><span><img src="https://static001.geekbang.org/infoq/ec/ec1a49a4c5ef4e94bfeb66406fd923af.png" referrerpolicy="no-referrer"></span></p><p><span>B 部分中的每個跨度都以[S]作為輸入，以[E]作為輸出。</span></p><p><span>該模型自迴歸生成 B 部分——它基於前一部分預測下一個令牌。</span></p><p><span><img src="https://static001.geekbang.org/infoq/e4/e4dce02ba15e65d99610952f3fea5f95.png" referrerpolicy="no-referrer"></span></p><p><span>A 部分可以自行處理，但不能處理 B 部分</span></p><p><span><img src="https://static001.geekbang.org/infoq/85/85f78a3971bae19c0a1af660f7d7a638.png" referrerpolicy="no-referrer"></span></p><p><span>B 部分可以關注 A 及其在 B 中的經歷</span></p><p><span><img src="https://static001.geekbang.org/infoq/22/223329a780e3153f4dbf92f8ddc72574.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_11"></span><h3><span>2.4 Multi-Task Pretraining</span></h3><p><span>Multi-Task Pretraining 是一種多任務預訓練的方法。在傳統的預訓練方法中，語言模型通過在大規模文本數據上進行訓練來學習語言的通用模式和表示。然而，在 Multi-Task Pretraining 中，模型同時在多個任務上進行訓練，這些任務需要不同類型的語言理解能力。</span></p><p><span>Multi-Task Pretraining 的思想是通過在多個任務上訓練語言模型，可以學習到更加通用和魯棒的語言表示。這是因為不同的任務需要不同的語言技能，如句法分析、語義理解或文檔級連貫性。通過讓模型接觸多樣化的任務，它可以學習捕捉不同任務之間的共同語言模式，並利用這些模式更好地泛化到新任務上。</span></p><p><span>Multi-Task Pretraining 已被證明可以提高語言模型在下游任務上的性能。例如，預訓練在多個任務上的模型在各種自然語言處理基準測試中取得了最先進的結果，如問答、文本分類和命名實體識別。</span></p><p><span>其中一種常見的 Multi-Task Pretraining 方法是基於 Transformer 的模型，如 BERT（雙向編碼器表示來自 Transformer 的方法）和 RoBERTa（經過優化的魯棒 BERT 方法）。這些模型在掩碼語言建模、下一個句子預測和其他輔助任務上進行預訓練。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>通過改變遮蓋內容的長度和數量，從而使模型能夠基於 natural language understanding, conditional generation, unconditional generation 三類任務進行預訓練，實現「三合一」</span></p><p><span>改變缺失跨度的數量和長度：</span></p><p><span><img src="https://static001.geekbang.org/infoq/1c/1cb25c4d2b09190bff8a46554eb25a72.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_12"></span><h3><span>2.5 Finetuning</span></h3><p><span>Finetuning 是指在預訓練的基礎上，將模型進一步調整和優化以適應特定任務或特定數據集的過程。在機器學習中，預訓練模型通常在大規模的數據上進行訓練，學習到通用的模式和特徵表示。然而，這些預訓練模型可能不直接適用於特定的任務或數據集。</span></p><p><span>通過 Finetuning，可以利用預訓練模型的通用知識和特徵表示來快速適應特定的任務或數據集。這通常涉及解凍預訓練模型的一部分或全部層，並在目標任務上進行進一步的訓練。通過在目標任務上微調模型參數，可以使其更好地適應任務的特定要求和數據特徵。</span></p><p><span>Finetuning 的過程通常包括以下步驟：</span></p><ol><li>選擇預訓練模型：選擇與目標任務相匹配的預訓練模型，如 BERT 或 GPT 等。</li><li>初始化參數：將預訓練模型加載到模型中，並凍結所有或部分層的參數。</li><li>構建任務特定層：根據目標任務的需求，構建一個或多個任務特定的層。</li><li>訓練：使用目標任務的數據集，通過反向傳播和梯度下降等優化算法，更新模型的參數。</li><li>調整超參數：對模型進行驗證和評估，並根據結果調整超參數，如學習率、批大小等。</li><li>重複迭代：根據需要，多次迭代訓練和調整模型，直到達到滿意的性能。</li></ol><p><span>Finetuning 可以大大減少在特定任務上的訓練時間和樣本需求，同時利用預訓練模型的知識提供了更好的初始參數和特徵表示。它已經被廣泛應用於自然語言處理、計算機視覺和其他領域中的許多任務，如文本分類、問答、命名實體識別等。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>GLM 將 NLG 和 NLU 類下游任務統一為完型填空的生成式任務，如對於分類任務，將輸入 x 寫成一個填空問題 c(x)，後將生成的答案 v(y) 映射至標籤 y</span></p><p><span><img src="https://static001.geekbang.org/infoq/9c/9cf3b6f327ad83502cfc914715d24411.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_13"></span><h3><span>2.6 LLM Reversal Curse</span></h3><p><span>LLM（Large Language Model）是指一種非常大的語言模型，它由數十億個參數組成，具有強大的語言理解和生成能力。大模型 LLM 可以實現諸如問答、摘要、對話生成等任務，被廣泛應用於自然語言處理領域。</span></p><p><span>LLM Reversal Curse（逆轉詛咒）是指在使用大模型 LLM 進行任務生成時，其生成結果出現明顯的逆轉或反轉現象。具體而言，當模型用於生成某個任務的結果時，相比原始輸入，生成的結果可能會出現與原始意圖相反的內容或表達。</span></p><p><span>例如，在問答任務中，當用户提出一個問題時，大模型 LLM 應該生成一個準確且與問題相符的答案。然而，由於模型的複雜性和訓練數據的特點，有時候模型會出現生成與問題相反甚至荒謬的答案的情況。</span></p><p><span>這種逆轉詛咒可能是由於模型在訓練過程中接觸到了大量的噪聲數據、錯誤標註的數據或具有偏見的數據，導致模型在生成過程中出現了一些意料之外的結果。</span></p><p><span>為瞭解決大模型 LLM 的逆轉詛咒問題，需要進一步優化模型的訓練數據、標註過程和生成算法，以提高模型的生成質量和準確性。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span><img src="https://static001.geekbang.org/infoq/47/470e1c92bd0f829635ac34d21389bfe2.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_14"></span><h2><span>3. 2D Positional Encoding</span></h2><p><span>2D positional encoding 是一種將 2D 網格或圖像中元素的位置信息進行編碼的技術。位置編碼通常在自然語言處理任務中使用，例如機器翻譯或語言建模，來表示句子中單詞的順序或位置。然而，它也可以應用於 2D 網格或圖像。</span></p><p><span>對於 2D 網格或圖像，位置編碼可以用於編碼每個元素的空間位置。這樣，模型可以有一種對元素之間的相對位置的感知，並捕捉它們之間的空間關係。</span></p><p><span>一個常見的 2D 位置編碼的方法是使用不同頻率的正弦和餘弦函數。其思想是創建一個根據網格或圖像內位置而變化的正弦信號。然後將這個位置編碼作為每個元素在網格或圖像中的額外輸入或特徵。</span></p><p><span>位置編碼可以使用以下公式定義：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>PE(x,2i) = sin(x / (10000^(2i / d_model))) PE(x,2i+1) = cos(x / (10000^(2i / d_model))) </span></span></span></span></span></span></pre><p><span>其中，PE(x, i) 表示位置 i 處元素 x 的位置編碼，d_model 是模型的維度。</span></p><p><span>通過使用正弦和餘弦函數的不同頻率，位置編碼可以捕捉位置信息中的不同模式或關係。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>模型輸入的 position ids 分為兩種，從而使得模型可以學習到片段生成的長度</span></p><p><span>Position 1： Part A 中 token 的絕對位置</span></p><ul><li><p><span>Part A：從 1 開始排列</span></p></li><li><p><span>Part B：每一個 span 對應 Part A 中[MASK]的位置</span></p></li></ul><p><span>Position 2：intra-span position，masked span 內部的相對位置</span></p><ul><li>Part A：0</li><li>Part B：每個 span 的 token 從 1 開始排列</li></ul><p><span><img src="https://static001.geekbang.org/infoq/30/30383d2e7f2fa1315a66adc3ee5da034.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/c7/c793beb9a4581f4044b058e18a2af481.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_15"></span><h3><span>3.1 大模型訓練最大挑戰:訓練穩定性</span></h3><ul><li><p><span>權衡利弊：訓練穩定性（高精度低效）還是訓練效率（低精度高效）</span></p></li><li><p><span>目前已開源訓練過程大模型的解決方案</span></p><ul><li>FB OPT-175B：訓練崩潰時反覆調整學習率/跳過數據（權宜之計，損失性能）</li><li>HF BLOOM 176B：embedding norm 和 BF16（損失性能，有限適配平台）</li></ul></li></ul><p><span><img src="https://static001.geekbang.org/infoq/2e/2e62e9e0874e3f25b7539be3f325e2ce.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_16"></span><h3><span>3.2 GLM-130B：穩定訓練方法</span></h3><p><span>GLM-130B 是一個穩定訓練方法，它是機器學習中的一種算法。GLM 代表廣義線性模型，130B 表示這個算法的特定版本。</span></p><p><span>穩定訓練方法是指通過一定的技巧和策略來增強模型的穩定性和魯棒性，使其能夠更好地處理噪聲和異常數據。在訓練過程中，穩定訓練方法會對輸入樣本或特徵進行一些改變或調整，以減少模型對於噪聲的敏感性。</span></p><p><span>GLM-130B 的穩定訓練方法可能包括以下幾個方面：</span></p><ol><li>數據預處理：對輸入數據進行去噪、歸一化、特徵選擇等預處理操作，以減少噪聲對模型訓練的影響。</li><li>正則化：通過添加正則化項來限制模型的複雜度，防止過擬合，提高模型的泛化能力。</li><li>異常值處理：通過識別和處理異常值，減少它們對模型訓練的影響。</li><li>隨機化：引入隨機化因素，如隨機選擇樣本、隨機初始化參數等，以增加模型的穩定性和抗噪能力。</li><li>交叉驗證：使用交叉驗證來評估模型的性能，並選擇最佳的參數配置，避免對特定數據集過擬合。</li><li>集成學習：通過集成多個模型的預測結果，綜合考慮它們的意見，提高整體模型的性能和穩定性。</li></ol><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>Attention score 層：Softmax in 32 避免上下溢出</span></p><p><span><img src="https://static001.geekbang.org/infoq/eb/eb9466cc9a9e1358eed2e03385231462.png" referrerpolicy="no-referrer"></span></p><p><span>調小 Embedding 層梯度，緩解前期梯度爆炸問題</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>word_embedding = word_embedding * alpha + word_embedding .detach() * (1 ‒ alpha) </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/02/0231e5136feafcb716c06bfcca29c53e.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/3a/3a35d951843f5cd1436a49bc8915d3ef.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_17"></span><h3><span>3.2 GLM-130B：大量實驗確定最優架構</span></h3><p><span>有時候需要進行多次實驗來確定最佳的架構設計。這些實驗可能包括調整不同的參數、添加或移除不同的組件，以及測試不同的配置選項。GLM-130B 是根據這些實驗的結果和分析，確定出的最佳架構。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>DeepNorm：穩定訓練 1000 層 Post-LN 的方法</span></p><p><span><img src="https://static001.geekbang.org/infoq/30/302dcbc2e7fcda7ad9f07eae3f114634.png" referrerpolicy="no-referrer"></span></p><p><span>旋轉位置編碼 (RoPE)：適用於 GLM 的相對位置編碼</span></p><p><span><img src="https://static001.geekbang.org/infoq/d1/d1bf3e06247efeb07a892962f7cad23a.png" referrerpolicy="no-referrer"></span></p><p><span>門控注意單元 (GLU)：FFN 層的替換，穩定提升模型性能</span></p><p><span><img src="https://static001.geekbang.org/infoq/5b/5b8a177e8e00a66dcdf3c8f225804f82.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/73/73f81d7a3a8b7ecbc268a63a89c879e6.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_18"></span><h3><span>3.3 Post LayerNorm</span></h3><p><span>Post LayerNorm（後層歸一化）是一種神經網絡層歸一化的方法，用於解決深層神經網絡中梯度消失和梯度爆炸問題。傳統的 LayerNorm（層歸一化）是在每個神經網絡層的輸入上進行歸一化操作，而 Post LayerNorm 是在每個神經網絡層的輸出上進行歸一化操作。</span></p><p><span>具體來説，在每個神經網絡層的輸入和激活函數之間，先進行 LayerNorm 的歸一化操作，然後再進行激活函數的計算。這樣可以使得每個神經網絡層的輸出都在相似的尺度上，避免了梯度消失和梯度爆炸的問題。</span></p><p><span>與之相比，傳統的 LayerNorm 在每個神經網絡層的輸入上進行歸一化操作，但在深層網絡中，由於每層的輸入分佈不穩定，因此歸一化操作的效果可能會下降。而 Post LayerNorm 能夠在每個神經網絡層的輸出上進行歸一化操作，保證了歸一化的效果，提高了網絡的穩定性和訓練效果。</span></p><p><span>Post LayerNorm 是在 Transformer 網絡中被提出的，並在各個任務上取得了顯著的性能提升。它被認為是一種更加有效和穩定的歸一化方法，在大規模深層網絡的訓練中具有重要的作用。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>重新排列層規範化和剩餘連接的順序</span></p><p><span><img src="https://static001.geekbang.org/infoq/d3/d3c43cdb9d19825a5f54d683e7b8787e.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_19"></span><h3><span>3.4 GLU</span></h3><p><span>GLU（Gated Linear Unit）是一種門控線性單元，用於增強神經網絡的表示能力。通過將 GLU 應用於 MindSpore 框架中的大型模型，可以進一步提升模型的性能和效果。</span></p><p><span>GLU 的核心思想是將輸入進行分割成兩部分，然後通過門控機制控制兩部分的信息傳遞。這種門控機制可以幫助模型更好地理解輸入數據中的相關性，從而提高模型的表達能力和泛化能力。</span></p><p><span>在 MindSpore 框架中，GLU 可以被用於各種任務，包括自然語言處理、計算機視覺和語音識別等。通過使用 MindSpore 大模型 GLU，研究人員和開發人員可以更輕鬆地構建和訓練複雜的模型，並獲得更好的結果。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>用 GeLU 替換 ReLU 激活</span></p><p><span><img src="https://static001.geekbang.org/infoq/6d/6da4d692af614635c3118af36ff1e85f.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_20"></span><h3><span>3.5 並行策略：高效訓練千億模型</span></h3><p><span>存下 GPT-3 模型需要 2.8T 顯存存放訓練狀態 + 中間激活函數值</span></p><p><span><img src="https://static001.geekbang.org/infoq/f5/f5b86a4417a834ee3b785f509cb03691.png" referrerpolicy="no-referrer"></span></p><p><span>挑戰：遠超單卡顯存（40GB），採取何種並行方式高效訓練？</span></p><ul><li>採用 ZeRO 優化器在數據並行組內分攤優化器狀態 → ~25%</li></ul><p><span><img src="https://static001.geekbang.org/infoq/d8/d8e3bbef5f09de2a7896ec693dfbb1fd.png" referrerpolicy="no-referrer"></span></p><p><span>遠超單卡顯存，如何高效訓練？</span></p><p><span><span>模型並行：將模型參數分佈到多個 GPU 上</span></span></p><ul><li>張量並行：切分參數矩陣，每 GPU 計算一部分 → 額外通信，降低計算粒度</li><li>流水線並行：將網絡分成多段並行 → 引入流水線氣泡</li><li>ZeRO-3：將參數分佈到數據並行組中，算之前先取回參數 → 額外通信時間</li></ul><p><span>分析：流水線的氣泡佔比： 𝑛⁄𝑡 $ 1 ，n / t &lt;&lt; 4m 的時候可以忽略不計</span></p><p>並行策略：張量並行隨着模型規模增大緩慢擴展，但不超過單機規模（<br> &lt;=8），其餘全部使用流水線並行，通過調整微批處理大小減少氣泡佔比</p><p><span><img src="https://static001.geekbang.org/infoq/fe/fe19784afba50f126511687410ba6880.png" referrerpolicy="no-referrer"></span></p><p><span><span>其他優化</span></span></p><ul><li>算子融合：融合多個 element-wise 算子 → 提升 ~10% 計算速度</li><li>流水線平衡：流水線首尾階段各少放置一個層平衡佔用 → 節省 ~10% 顯存</li></ul><p><span><span>跨平台兼容：swDeepSpeed 訓練庫  與 DeepSpeed API 兼容</span></span></p><ul><li>支持申威架構，一行代碼無縫替換兼容</li><li>實現並行通信策略，混合精度策略，ZeRO 優化器</li><li>同一套訓練框架可在三個集羣上對齊訓練曲線</li></ul><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>import swDeepSpeed as deepspeed model, optimizer, _, _ = deepspeed.initialize( model=model, model_parameters=param_groups, args=args, mpu=mpu, dist_init_required=False, config_params=config_params ) </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/79/795f6c20368e1406f95a5bb8482c06d4.png" referrerpolicy="no-referrer"></span></p><p><span><span>測試集羣配置：</span></span></p><ul><li>A100 集羣（A100）： 96 台 DGX-A100，每台 2 張 200GB IB 網卡，硬件差異性大</li><li>海光 GPU（Hygon）：3000 台機器，每台 4 張 DCU 加速卡、4 張 50G IB 網卡</li><li>申威處理器（Sunway）：8192 個節點，每節點一塊 SW26010-PRO 處理器</li></ul><p>訓練 GPT-3 175B 規模的模型，按照相同的 300B 單詞量估計訓練時間：</p><p><span><img src="https://static001.geekbang.org/infoq/85/851274d88bafc04b1eb34d7889c30d5e.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_21"></span><h2><span>4.Rotary Positional Embedding</span></h2><span id="OSC_h3_22"></span><h3><span>4.1 Introduction of Positional Embedding</span></h3><p><span>Positional Embedding（位置編碼）是一種用於處理序列數據的技術，主要應用於自然語言處理（NLP）任務中。在序列數據中，單詞的順序和位置對於語義的理解非常重要。位置編碼的目的是為了將單詞的位置信息融入到模型的表示中，使得模型能夠更好地理解單詞的順序和上下文關係。</span></p><p><span>傳統的詞向量表示只考慮了單詞的語義信息，而沒有考慮單詞的位置。位置編碼通過為每個單詞分配一個唯一的位置向量來解決這個問題。常用的位置編碼方法包括相對位置編碼、絕對位置編碼、正弦位置編碼等。</span></p><p><span>在相對位置編碼中，每個單詞的位置編碼是相對於其他單詞的位置差異而得到的。絕對位置編碼則是將每個單詞的位置映射為一個唯一的位置向量。正弦位置編碼是一種常用的絕對位置編碼方法，通過使用正弦和餘弦函數來生成位置向量，從而捕捉到不同位置之間的相對關係。</span></p><p><span>位置編碼的作用是為模型提供位置信息，幫助模型在處理序列數據時更好地理解單詞的上下文和關係。它通常與注意力機制和 Transformer 等模型結構一起使用，為模型提供更豐富的上下文信息。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>自注意力機制主要關注詞語之間的相互關係，在計算中，根據詞語之間的語義關係來計算注意力分數，並不會考慮詞語之間的位置關係。</span></p><p><span>即使打亂序列中詞語的順序，依舊會得到相同的語義表達因此需要額外增加位置信息。</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>The dog chased the pig. = The pig chased the dog. = chased pig The the dog. </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/33/3307391c156e6459b1b234929bde6337.png" referrerpolicy="no-referrer"></span></p><p><span>位置信息的表示有很多種，如</span></p><p><span><span><strong>absolute positional embeddings：</strong></span></span></p><ul><li>原理：對於第 k 個位置的向量 xk，添加位置向量 pk（僅依賴於位置編號 k），得到 xk+pk</li><li>舉例/應用模型：sinusoidal positional embedding（Transformer）、learned absolute positional embedding（BERT/RoBERTa/GPT）</li></ul><p><span><span><strong>relative positional embeddings:</strong></span></span></p><ul><li>原理：對於第 m 個和第 n 個位置的向量 xm、xn，將相對位置 m-n 的信息添加到 self-attention matrix 中</li><li>舉例/應用模型：T5</li></ul><p><span><span><strong>rotary positional embeddings</strong></span></span></p><ul><li>原理：使用旋轉矩陣對絕對位置進行編碼，並同時在自注意力公式中引入了顯式的相對位置依賴。</li><li>舉例/應用模型：PaLM/GPT-Neo/GPT-J/LLaMa1&amp;2/ChatGLM1&amp;2</li></ul><span id="OSC_h3_23"></span><h3><span>4.2 Sinusoidal Positional Embedding</span></h3><p><span>Sinusoidal Positional Embedding（正弦位置編碼）是一種用於編碼序列數據中單詞位置信息的方法，最初在 Transformer 模型中被引入。它是一種絕對位置編碼方法，通過正弦和餘弦函數來生成位置向量，從而捕捉到不同位置之間的相對關係。</span></p><p><span>在正弦位置編碼中，每個單詞的位置編碼由兩個維度的正弦和餘弦函數計算得到。具體計算公式如下：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>PE(pos,2i) = sin(pos / 10000^(2i/d_model)) PE(pos,2i+1) = cos(pos / 10000^(2i/d_model)) </span></span></span></span></span></span></pre><p><span>其中，pos 表示單詞在序列中的位置，i 表示位置向量的維度索引，d_model 表示模型的維度。這樣，每個單詞的位置編碼可以由位置索引 pos 和維度索引 i 計算得到。</span></p><p><span>正弦位置編碼的特點是，不同位置之間的位置向量是正弦和餘弦函數的週期函數。這使得不同位置之間的位置向量能夠保持一定的相似性，從而幫助模型更好地理解位置信息並捕捉到序列中的順序關係。</span></p><p><span>正弦位置編碼通常與注意力機制和 Transformer 模型一起使用，用於為模型提供序列數據的位置信息。它的優點是簡單且可解釋，能夠有效地表達不同位置之間的相對關係。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>通過 sine 和 cosine 函數計算每個位置的 positional embedding</span></p><ul><li><p><span>優點：1. 可以反應相對位置信息；2. 模型可以接受不同長度的輸入</span></p></li><li><p><span>缺點：數值為固定值，無法參與學習</span></p></li></ul><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>PE(pos, 2i)=sin(pos/10000^2i/d_model) PE(pos, 2i+1)=cos⁡(pos/10000^2i/d_model) </span></span></span></span></span></span></pre><p><span><img src="https://static001.geekbang.org/infoq/59/5991a37b1ee92ffd917cb742725276c3.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_24"></span><h3><span>4.3 Learned Positional Embedding</span></h3><p><span>Learned Positional Embedding 是一種在自然語言處理任務中用於編碼位置信息的技術。在傳統的 Transformer 模型中，位置編碼是通過固定的數學公式（如正弦函數或餘弦函數）來計算得到的。而 Learned Positional Embedding 則是通過在模型的嵌入層中引入可學習的參數來學習位置信息的表示。</span></p><p><span>傳統的位置編碼方法只能對句子的位置進行大致的編碼，而 Learned Positional Embedding 可以更準確地表示不同位置的信息。當模型學習到不同位置的嵌入表示時，它可以更好地區分不同位置的詞語，並捕捉到位置信息對任務的影響。</span></p><p><span>Learned Positional Embedding 的一個優點是可以根據任務的需要進行調整。傳統的位置編碼是固定的，不會隨着訓練進行調整。而 Learned Positional Embedding 可以通過反向傳播算法來優化參數，以更好地適應不同任務的需求。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>將表示位置的 position ids 放入 nn.Embedding，獲取大小為 hidden size 的 positional embedding</span></p><ul><li><p><span>優點：可以隨模型訓練進行參數更新</span></p></li><li><p><span>缺點：可擴展性差，只能表徵在 max_seq_length 以內的位置</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/aa/aab0c97c5cad3ea7b922666b58d78e16.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_25"></span><h3><span>4.4 Relative Positional Embedding</span></h3><p><span>相對位置嵌入（Relative Positional Embedding）是一種用於編碼序列中元素之間相對位置關係的技術，常用於自然語言處理和序列建模任務中。</span></p><p><span>在傳統的位置嵌入方法中，如正弦/餘弦位置嵌入（Sinusoidal Positional Embedding）或學習位置嵌入（Learned Positional Embedding），每個位置的嵌入向量是固定的，不考慮其與其他位置的關係。但在很多任務中，序列中的元素之間的相對位置關係對於理解序列的語義和結構非常重要。</span></p><p><span>相對位置嵌入通過將每個元素的位置嵌入向量與其他位置的偏移向量進行組合，來編碼元素之間的相對距離。這樣，每個元素的位置嵌入向量會隨着其與其他元素的位置關係而變化，從而更好地捕捉序列中的局部結構信息。</span></p><p><span>相對位置嵌入常用於 Transformer 模型中，在自注意力機制（Self-Attention）中使用。通過引入相對位置嵌入，Transformer 可以更好地處理序列中元素之間的相對位置關係，從而提高序列建模的性能。在相對位置嵌入中，常見的方法是使用距離編碼矩陣（Distance Encoding Matrix）來計算偏移向量，然後與位置嵌入向量相加。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>在計算自注意力分數時，在 query 和 key 的 dot product，以及最終注意力權重和 value 矩陣乘時，分別額外添加一個表示位置 m 和位置 n 相對位置信息的 bias，僅依賴於 m-n</span></p><p><span>優點：</span></p><ul><li><p><span>可以直觀記錄詞語的相對位置信息</span></p></li><li><p><span>模型可接受不同長度的輸入</span></p></li></ul><p><span>缺點：</span></p><ul><li>訓練和推理速度慢（尤其是長序列的時候）</li></ul><p><span><img src="https://static001.geekbang.org/infoq/76/760ef0b0234b9fa018bde315640a7b98.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/52/52d0da76f1a528e963667f604e7667ea.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_26"></span><h3><span>4.5 Rotary Positional Embedding</span></h3><p><span>相關代碼如下：</span></p><p><span><img src="https://static001.geekbang.org/infoq/9b/9b38ccc9f634a10b8cbe3b32e741dc85.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h4_27"></span><h4><span>4.5.1 2D case</span></h4><p><span>Rotary Positional Embedding - 2D case 是一種用於編碼二維序列中位置信息的方法，特別適用於 Transformer 等模型中的注意力機制。</span></p><p><span>在傳統的位置嵌入方法中，如正弦/餘弦位置嵌入（Sinusoidal Positional Embedding）或學習位置嵌入（Learned Positional Embedding），每個位置的嵌入向量是固定的，不考慮其與其他位置的關係。但對於二維序列，僅使用位置索引的編碼方法無法很好地捕捉到元素在二維空間中的相對位置關係。</span></p><p><span>Rotary Positional Embedding - 2D case 通過引入角度信息，能夠更好地編碼二維序列中元素的位置關係。具體來説，它使用了旋轉操作來編碼位置信息，這可以看作是將位置嵌入向量繞原點旋轉一定的角度。通過在嵌入向量中引入角度信息，可以更好地表示元素在二維空間中的相對位置。</span></p><p><span>在 2D 案例中，Rotary Positional Embedding 通常與自注意力機制（Self-Attention）一起使用。在注意力機制中，通過將位置嵌入向量與注意力權重相乘，並進行相應的運算，將位置信息引入注意力計算中。這樣，模型可以更好地理解元素之間的相對位置關係，從而提高序列建模的性能。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>以 2D word vector 為例，第 m 個位置的詞語可以用一個二維的向量 xm 表示，我們將它的 query 和 key 向量在 2D 平面上進行逆時針旋轉，旋轉角度取決於位置索引 m</span></p><ul><li><p><span>dog：單詞 dog 在第 0 位，不進行旋轉</span></p></li><li><p><span>The dog：單詞 dog 在第 1 位，旋轉角度θ</span></p></li><li><p><span>The pig chased the dog：單詞 dog 在第 4 位，旋轉角度 4</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/60/60dc693fb0f12c80e400fd095edfa932.png" referrerpolicy="no-referrer"></span></p><p><span>這樣在計算 xm 和 xnquery，key 的點積時，結果僅和 (m-n)θ有關，而非 m 或 n</span></p><p><span>優點：</span></p><ul><li><p><span>計算 self-attention q,k 點積時，保留了詞語的相對位置信息（不會因詞語的絕對位置發生改變）</span></p></li><li><p><span>前面位置的 positional embedding 不受後續新增 token 的影響（easier to cache）</span></p></li><li><p><span>token 之間的依賴會隨着相對距離的增長而逐步衰減（符合認知，距離越遠的詞普遍關聯不大）</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/a9/a9379dde05d359a28b99d0af242c825e.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h4_28"></span><h4><span>4.5.2 general form</span></h4><p><span>Rotary Positional Embedding - general form 是一種用於編碼位置信息的方法，通用形式適用於各種序列數據，包括一維、二維或其他維度的序列。</span></p><p><span>在傳統的位置嵌入方法中，如正弦/餘弦位置嵌入（Sinusoidal Positional Embedding）或學習位置嵌入（Learned Positional Embedding），每個位置的嵌入向量是固定的，不考慮其與其他位置的關係。但是，這種方法無法很好地捕捉到元素在序列中的相對位置關係。</span></p><p><span>Rotary Positional Embedding - general form 通過引入旋轉操作，能夠更好地編碼序列中元素的位置關係。具體來説，它使用了旋轉矩陣來對位置嵌入進行變換，這可以看作是將位置嵌入向量繞一個固定的軸旋轉一定的角度。通過在嵌入向量中引入旋轉信息，可以更好地表示元素在序列中的相對位置。</span></p><p><span>在一般形式中，Rotary Positional Embedding 可以與注意力機制（Attention Mechanism）一起使用。在注意力機制中，通過將位置嵌入向量與注意力權重相乘，並進行相應的運算，將位置信息引入注意力計算中。這樣，模型可以更好地理解元素之間的相對位置關係，從而提高序列建模的性能。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><ul><li>將單詞的詞向量大小設定為 2 的倍數</li><li>第 m 個位置的詞向量在第 i 組 2D sub-space（即向量中的 2i，2i+1 元素）的旋轉角度為 mθ_i，θ_i 與 i 以及詞向量的 hidden size 有關</li></ul><p><span><img src="https://static001.geekbang.org/infoq/c8/c8ad5874bebd3c2658c26afeb91f0787.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h1_29"></span><h1><span><span>二、From GLM to ChatGLM</span></span></h1><span id="OSC_h2_30"></span><h2><span>1.傳統 NLP 的挑戰</span></h2><span id="OSC_h3_31"></span><h3><span>1.1 挑戰 1:傳統 NLP vs 複雜問題</span></h3><p><span>傳統 NLP（自然語言處理）方法通常用於處理簡單的文本任務，例如文本分類、命名實體識別和情感分析等。這些方法主要依賴於規則和模式，以及統計和機器學習算法。</span></p><p><span>對於複雜問題，傳統 NLP 方法可能面臨一些挑戰。複雜問題通常具有多義性、歧義性和上下文依賴性。例如，理解一個句子的意思可能需要考慮上下文信息和背景知識。此外，複雜問題還可能涉及多種語言和跨語言的處理。</span></p><p><span>為了應對複雜問題，研究者們開始使用深度學習方法，如循環神經網絡（RNN）和注意力機制等。這些方法能夠更好地處理語義理解和生成，以及更好地捕捉文本的上下文信息。</span></p><p><span>複雜問題還可能需要結合其他領域的知識，例如知識圖譜、計算機視覺和知識推理等。這樣可以提供更全面的語義理解和推理能力。</span></p><p><span><img src="https://static001.geekbang.org/infoq/b5/b596343a38eae8d3a9129133c3284a45.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_32"></span><h3><span>1.2 挑戰 2:傳統 NLP vs 動態知識</span></h3><p><span>傳統 NLP（自然語言處理）是一種基於規則和模式的方法，它主要依賴於人工編碼的語言規則和語法結構來理解和處理文本。這些規則和結構需要事先定義，並且通常需要大量的人工工作。</span></p><p><span>動態知識（Dynamic Knowledge）則是一種基於知識圖譜和自動學習的方法，它能夠根據實時的數據來自動更新和擴展知識庫。動態知識利用機器學習和圖譜技術，可以從大量的文本和語料庫中自動提取和建立知識模型。</span></p><p><span>傳統 NLP 的一個主要優勢是其可解釋性，因為所有的規則和模式都是人工定義的，所以可以清楚地理解其工作原理。然而，它也存在一些缺點，例如需要大量的人工工作來編寫和維護規則，而且對於複雜的語言現象和變化的語言規則往往無法適應。</span></p><p><span>相比之下，動態知識能夠通過機器學習和自動學習的方式，自動地從大量的文本中提取和建立知識模型。它可以自動學習語言現象和規則的變化，並且可以根據實時的數據來更新和擴展知識庫。動態知識的優點是其能夠處理複雜的語言現象和變化的語言規則，並且具有較強的適應性和靈活性。</span></p><p><span>但動態知識也存在一些挑戰，例如其可解釋性相對較差，因為知識模型是通過機器學習自動學習的，所以很難直觀地理解其工作原理。此外，動態知識的構建和維護也需要大量的計算資源和數據支持。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>千億模型的動態知識欠缺、知識陳舊、缺乏可解釋性</span></p><ul><li><p><span>知識欠缺：長尾知識</span></p><ul><li>例如: 世界第二高的山峯 (答案: K2 格里峯)</li></ul></li><li><p><span>知識陳日：GPT-3 的訓練數據截止 2020 年前</span></p></li><li><p><span>不可解釋:缺乏答案的參考源</span></p></li></ul><p><span><img src="https://static001.geekbang.org/infoq/60/6080170bcc2fc2162fa74aedabf7920d.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_33"></span><h3><span>1.3 挑戰 3:傳統 NLP vs 人類對齊</span></h3><p><span>傳統 NLP 是基於機器學習和統計的方法，利用大量已標註的語料庫來訓練模型。這些模型可以識別和理解文本的語法結構、詞義和語義關係等。傳統 NLP 方法包括語法分析、詞性標註、命名實體識別、情感分析等技術。這些技術可以自動處理大規模的文本數據，並提供一些高級的語言處理功能。</span></p><p><span>人類對齊是指通過人工的方式對文本進行處理和理解。人類對齊可以是通過人工標註和標記的方式，也可以是通過人工閲讀和理解的方式。人類對齊可以更準確地理解文本的含義和語境，尤其在處理一些複雜的語言結構和語義問題時更具優勢。人類對齊可以包括人工智能助手和人工翻譯等應用。</span></p><p><span>傳統 NLP 和人類對齊兩種方法各有優缺點。傳統 NLP 方法可以在處理大規模數據時提供高效的處理能力，但在面對複雜語義問題時可能存在理解不準確或無法捕捉語境的問題。而人類對齊可以更準確地理解文本的含義和語境，但在大規模處理和實時處理方面可能存在效率和成本的問題。</span></p><p><span><strong><code>案例片段介紹如下：</code></strong></span></p><p><span>例如：請用幾句話給一個 6 歲小孩解釋登月</span></p><ul><li>缺少高效"Prompt 工程"，GPT-3 和 GLM-130B 都很難盡人意</li></ul><p><span><img src="https://static001.geekbang.org/infoq/da/dada2bf6fb98e01f532bdcda5dbaf49c.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_34"></span><h2><span>2.從千億模型到 ChatGLM 的技術路線</span></h2><p><span>千億模型 GLM-130B 是一個大規模語言模型，具有 130 億個參數，用於自然語言處理任務。它採用了 Transformer 架構和大規模預訓練技術，可以生成高質量的文本。</span></p><p><span>GLM-130B+是在 GLM-130B 的基礎上進行了改進和優化。它針對語言模型的訓練過程進行了一些調整，提升了模型的性能和效果。GLM-130B+在更多的自然語言處理任務上具有更好的表現。</span></p><p><span>GLM-130B++是在 GLM-130B+的基礎上進一步改進的版本。它引入了更多的新技術和優化策略，使得模型在處理長文本、多語種和多任務上表現更出色。GLM-130B++具有更強大的表達能力和更好的泛化能力。</span></p><p><span>ChatGLM 模型是基於 GLM 系列模型的一種變種，專門用於生成對話文本。它在 GLM-130B++的基礎上進行了一些改進，使得模型在對話生成任務上更加適用和有效。ChatGLM 模型在生成對話內容時可以更好地理解上下文和語境，並生成更具連貫性和合理性的對話文本。</span></p><p><span><img src="https://static001.geekbang.org/infoq/6d/6de13d2ba9530137b2656ace3b4a633a.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_35"></span><h2><span>3.ChatGLM 的應用場景</span></h2><span id="OSC_h3_36"></span><h3><span>3.1 撰寫博客提綱</span></h3><p><span><img src="https://static001.geekbang.org/infoq/9d/9d13d38b0516f9a2d982eaf70efd15ac.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_37"></span><h3><span>3.2 寫郵件</span></h3><p><span><img src="https://static001.geekbang.org/infoq/8b/8bd5452e6da22d5398a1ce56aaab379d.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_38"></span><h3><span>3.3 介紹自己的優點缺點</span></h3><p><span><img src="https://static001.geekbang.org/infoq/42/421e29218719bf6d15768cc3cf345a0a.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_39"></span><h3><span>3.4 寫劇本梗概</span></h3><p><span><img src="https://static001.geekbang.org/infoq/e2/e2f7cb53ac7c1a2f3c3f6169d3145e67.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_40"></span><h3><span>3.5 寫代碼</span></h3><p><span><img src="https://static001.geekbang.org/infoq/a9/a926fcc4ba701256ec42d723ce687afb.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_41"></span><h3><span>3.6 查詢常見知識/教程</span></h3><p><span><img src="https://static001.geekbang.org/infoq/9f/9f1ec261b96b5b9b91059e60fb17455c.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_42"></span><h3><span>3.7 多輪問答</span></h3><p><span><img src="https://static001.geekbang.org/infoq/2a/2ad75a59ee31fcf2587b2f9381e245fa.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/e3/e36a74fadde7599d2f7b581e754ca640.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_43"></span><h3><span>3.8 文字冒險遊戲</span></h3><p><span><img src="https://static001.geekbang.org/infoq/10/103cecea0a0aba1a97629d9672a73e84.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h1_44"></span><h1><span><span>三、ChatGLM Demo</span></span></h1><p><span>完整的課程學習地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmindspore-courses%2Fstep_into_llm" rel="nofollow" target="_blank">完整的課程學習地址</a></span></p><p><span><img src="https://static001.geekbang.org/infoq/17/174e6a94b6d8988dcf8fc430e4cbbdd9.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h2_45"></span><h2><span>1.使用 NPU+MindSpore Transformers 試用 ChatGLM 推理</span></h2><span id="OSC_h3_46"></span><h3><span>1.1 OpenI 啓智運行 ChatGLM 模型</span></h3><p><span>1、到 OpenI 啓智申請賬號，開啓雲腦任務（NPU）/自己用 GPU 創建環境</span></p><p><span>OpenI 啓智申請賬號地址：https://openi.pcl.ac.cn/user/sign_up</span></p><p>&nbsp;</p><p><span><img src="https://static001.geekbang.org/infoq/0e/0e11bad9d6398b58031b538eb986c59e.png" referrerpolicy="no-referrer"></span></p><p>2、創建項目</p><p>&nbsp;</p><p><span><img src="https://static001.geekbang.org/infoq/de/de290dd58507ada8228b8859b41117c4.png" referrerpolicy="no-referrer"></span></p><p><span>3、打開新創建的項目，點擊雲腦，新建調試任務</span></p><p><span><img src="https://static001.geekbang.org/infoq/6b/6b022877602bff1996db62679ae88965.png" referrerpolicy="no-referrer"></span></p><p><span>4、點擊調試</span></p><p><span><img src="https://static001.geekbang.org/infoq/e6/e6f6ae6a5a3c808b58f95ecc527d198b.png" referrerpolicy="no-referrer"><br> 5、進入終端</span></p><p><span><img src="https://static001.geekbang.org/infoq/63/6306925e6ef5356c9caa7314bc3f0ef7.png" referrerpolicy="no-referrer"></span></p><p><span><img src="https://static001.geekbang.org/infoq/db/db007f9151bc4b2d422674639d34c97c.png" referrerpolicy="no-referrer"></span></p><p><span>其他操作如下面<code>1.2 小結</code>，這邊只是用 OpenI 啓智 NPU+MindSpore 進行在線部署調試，部署結果如下圖：</span></p><p><span><img src="https://static001.geekbang.org/infoq/30/3029472aa56b9869fe9af47fbb593e5a.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_47"></span><h3><span>1.2 MindSpore 運行 ChatGLM 模型</span></h3><p><span>安裝 MindSpore 和 MindSpore Transformers</span></p><p><span>a) MindSpore 安裝：參考：MindSpore 官網（如果用 OpenI 啓智 NPU+MindSpore，可以忽略這一步，這步屬於本地部署）</span></p><p><span>b) MindSpore Transformers 安裝：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>1、git clone -b dev https://gitee.com/mindspore/mindformers.git 2、cd mindformers 3、bash build.sh 4、如果使用 MindSpore1.10 版本，請安裝 MindFormers 0.6 版本（git clone -b r0.6 …） </span></span></span></span></span></span></pre><p><span>c) 克隆昇思 MindSpore 技術公開課代碼倉：</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>git clone https://github.com/mindspore-courses/step_into_llm.git </span></span></span></span></span></span></pre><p><span>d)&nbsp;<code>cd step_into_llm/Season2.step_into_llm/01.ChatGLM/</code></span></p><p><span>e) 下載 ckpt 和 tokenizer 文件</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>1、ckpt：wget https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/glm_6b.ckpt 2、tokenizer：wget https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/ice_text.model </span></span></span></span></span></span></pre><p><span>f) 運行推理部署文件：python cli_demo.py</span></p><pre><span><span style="background-color:#f8f8f8"><span><span><span><span>import os import platform import signal import numpy as np import mindspore as ms from mindformers.models.glm import GLMConfig, GLMChatModel from mindformers.models.glm.chatglm_6b_tokenizer import ChatGLMTokenizer from mindformers.models.glm.glm_processor import process_response config = GLMConfig( position_encoding_2d=True, use_past=True, is_sample_acceleration=True) ms.set_context(mode=ms.GRAPH_MODE, device_target="GPU", device_id=0) model = GLMChatModel(config) # https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/glm_6b.ckpt ms.load_checkpoint("./glm_6b.ckpt", model) # https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/glm/ice_text.model tokenizer = ChatGLMTokenizer('./ice_text.model') os_name = platform.system() clear_command = 'cls' if os_name == 'Windows' else 'clear' stop_stream = False def build_prompt(history): prompt = "歡迎使用 ChatGLM-6B 模型，輸入內容即可進行對話，clear 清空對話歷史，stop 終止程序" for query, response in history: prompt += f"\n\n 用户：{query}" prompt += f"\n\nChatGLM-6B：{response}" return prompt def signal_handler(): global stop_stream stop_stream = True def main(): history = [] global stop_stream print("歡迎使用 ChatGLM-6B 模型，輸入內容即可進行對話，clear 清空對話歷史，stop 終止程序") while True: query = input("\n 用户：") if query.strip() == "stop": break if query.strip() == "clear": history = [] os.system(clear_command) print("歡迎使用 ChatGLM-6B 模型，輸入內容即可進行對話，clear 清空對話歷史，stop 終止程序") continue count = 0 inputs = tokenizer(query) outputs = model.generate(np.expand_dims(np.array(inputs['input_ids']).astype(np.int32), 0), max_length=config.max_decode_length, do_sample=False, top_p=0.7, top_k=1) response = tokenizer.decode(outputs) response = process_response(response[0]) history = history + [(query, response)] if stop_stream: stop_stream = False break else: count += 1 if count % 8 == 0: os.system(clear_command) print(build_prompt(history), flush=True) signal.signal(signal.SIGINT, signal_handler) os.system(clear_command) print(build_prompt(history), flush=True) if __name__ == "__main__": main() </span></span></span></span></span></span></pre><span id="OSC_h1_48"></span><h1><span><span>總結</span></span></h1><p><span>MindSpore 作為一種強大的深度學習框架，提供了豐富的工具和功能，使得模型的開發和訓練更加高效和靈活。其支持端到端的深度學習解決方案，可以應用於各種任務和場景。而 ChatGLM 作為一種生成式語言模型，通過對話的方式生成自然流暢的文本，可以用於智能對話和智能客服等應用。</span></p><p><span>結合使用 MindSpore 和 ChatGLM，我們可以實現更加智能和交互性的應用。首先，MindSpore 可以用來訓練 ChatGLM 模型，通過大量的對話數據進行學習，使得生成的文本更加貼近真實的對話。MindSpore 提供了分佈式訓練的功能，可以在多個設備和計算節點上進行模型的並行訓練，加速訓練過程。其自動微分功能也可以幫助優化 ChatGLM 模型的訓練效果。</span></p><p><span>通過 MindSpore 的強大功能和 ChatGLM 的生成式語言模型，我們可以構建出高效、準確和自然流暢的智能對話系統，提升用户體驗並開拓更多的應用領域。這種結合使用不僅有助於推動機器學習和人工智能的發展，還為帶來更多的創新和可能性。</span></p><p>&nbsp;</p><p><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>點擊關注，第一時間瞭解華為雲新鮮技術~</strong></a></span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 03:09:11 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/11047106</guid>
            <link>https://my.oschina.net/u/4526289/blog/11047106</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[睿芯成立 RV64G SIG，攜手社區共建 RV64G 軟件生態體系！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">2024 年 3 月，經 openKylin 社區技術委員會審議通過，<strong>RV64G SIG</strong>正式成立。</span></p><p><span style="color:#000000">RV64G 是 RISC-V 專門定義的重要子架構（支持 RISC-V imafd 指令集），為廣泛的通用計算領域提供了簡單且完備的指令集，RV64G SIG 由社區共建單位睿芯發起成立，致力於構建 RV64G 軟件生態體系，支持更加廣泛的 RISC-V 硬件。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p><strong>01 SIG 目標</strong></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">openKylin RV64G 版本的規劃、製作、維護和升級，實現更廣泛的硬件支持。</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">探索 RISC-V 各子架構應用兼容問題。</span></p></li></ul><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p><strong>02 SIG 職責及規劃</strong></p><p><strong><span style="color:#333333">1、創建並維護 RV64G 版本</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">規劃、製作 RV64G 社區版本，維護 RV64G 編譯器，提供 RV64G 鏡像。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong><span style="color:#333333">2、基於 openKylin RV64G 適配更多硬件</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">基於 openKylin RV64G 支持常用芯片、驅動，幫助芯片、驅動廠家進行系統適配，降低移植難度，豐富 RV64G 可用硬件列表。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong><span style="color:#333333">3、基於 openKylin RV64G 為軟件適配提供技術支持</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333"><span>基於 openKylin RV64G 移植常用應用，幫助</span><span style="color:var(--weui-LINK)">第三方軟件</span><span>移植到 RV64G，豐富 RV64G 可用軟件；</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p><strong>03 歡迎加入 SIG</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">RV64G SIG 基於開發合作的態度，希望構建有活力的社區生態，我們期待對此感興趣的小夥伴不斷加入！</span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">郵箱列表：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#0052ff"><span style="color:#0052ff">rv64g</span>@lists.openkylin.top</span></p></li></ul><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">SIG 主頁：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/RV64G</span></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 01:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282990</guid>
            <link>https://www.oschina.net/news/282990</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[榮耀稱已投入 100 億用於 AI 研發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">榮耀筆記本 AI PC 技術溝通會今日舉行，榮耀終端有限公司產品線總裁方飛表示，榮耀目前已持續投入 100 億元 AI 研發費用，完成相關 AI 專利成果 2100 篇，實現 600 類 AI 意圖識別，未來 PC 創新將圍繞 AI 進行。</span></p><p><span style="color:#000000"><img height="255" src="https://oscimg.oschina.net/oscnet/up-dbcf2c2a6ddd3f664b16e4deaf56cbf8863.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">即將在 3 月 18 日發佈的榮耀 MagicBook Pro 16 筆記本，也將通過榮耀 AI 的全方位使能，開啓 AI PC 新的時代。</span></p><p><span style="color:#000000">方飛稱，榮耀筆記本把 AI 技術與用户體驗融合，用 AI 使能智能硬件、人機交互和多端生態來重構 PC 行業。比如，通過 AI 網絡調度優先業務加速，帶來更低的網絡時延；在 PC 交互上實現全局收藏、文檔總結、搜索材料、文章撰寫等輔助創作能力；基於意圖理解的智慧推薦、會議紀要、Magic Text 等 AI 輔助能力。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Mar 2024 01:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282988</guid>
            <link>https://www.oschina.net/news/282988</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[信通院發佈報告，研究中國綜合算力]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">《中國綜合算力評價白皮書（2023 年）》由中國信息通信研究院發佈，主要內容包括：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>背景介紹</strong>：隨着科技革命和產業變革的加速，算力成為數字化轉型的新動能。中國在算力、存力、運力方面的基礎設施投入不斷加大，形成了支撐數字經濟發展的重要力量。</p></li><li><p style="margin-left:0; margin-right:0"><strong>算力發展現狀</strong>：截至 2022 年底，中國算力核心產業規模達到 1.8 萬億元，算力總規模達到 180EFLOPS，年增長率近 30%。存力總規模超過 1000EB，網絡單向時延降低到 20 毫秒以內。</p></li><li><p style="margin-left:0; margin-right:0"><strong>綜合算力評價體系</strong>：白皮書構建了一個涵蓋算力、存力、運力、環境等關鍵因素的綜合算力評價指標體系，對我國綜合算力的發展情況進行了多維度的客觀分析，並給出了發展建議。</p></li><li><p style="margin-left:0; margin-right:0"><strong>評價結果</strong>：綜合算力評價結果顯示，廣東省、江蘇省、上海市等東部省份在算力、存力、運力方面整體處於較高水平，而內蒙古自治區、貴州省等西部省份在存力、環境等方面也展現出優勢。</p></li><li><p style="margin-left:0; margin-right:0"><strong>發展建議</strong>：白皮書提出了系統佈局新型基礎設施、加速推動核心技術創新、加快政策標準體系建設、持續構建全產業鏈生態、激發算力產業創新動力等建議，以推動綜合算力的技術創新與基礎設施建設。</p></li><li><p style="margin-left:0; margin-right:0"><strong>數據來源和計算方法</strong>：報告的數據來源於工信部、中國信通院等官方機構和公開資料，採用極差標準化法進行指標標準化，並利用層次分析法（AHP）確定指標權重，最後形成各區域的評價結果。</p></li><li><p style="margin-left:0; margin-right:0"><strong>聯繫方式</strong>：文件最後提供了中國信息通信研究院的地址、郵編、電話、傳真和網址信息。</p></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">整體而言，這份白皮書全面闡述了中國綜合算力的發展現狀、評價體系、評價結果，並對未來的發展提出了建議，旨在為我國綜合算力的技術創新與基礎設施建設提供參考。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">報告詳情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「開源中國 APP - 報告模塊」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下載地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前僅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282905</guid>
            <link>https://www.oschina.net/news/282905</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Laravel 11 正式發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Laravel 11 和 Laravel Reverb 現已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel-news.com%2Flaravel-11" target="_blank">發佈</a>。Reverb 是 Laravel 生態系統的最新成員，是第一方、可擴展的 WebSocket 服務器，旨在為用户的應用程序提供強大的實時功能。</span></p><p><span style="color:#000000">Laravel 11 引入了：極簡應用結構、默認使用 SQLite、實現 health routing、提供每秒速率限制、支持優雅的加密密鑰輪換、改進隊列測試、引入新的 Artisan 命令、添加 Resend 郵件傳輸、集成 Prompt validator、新的 Artisan commands、Model Casts 改進、The once function、改進了使用內存數據庫進行測試時的性能、改進了對 MariaDB 的支持等等，</span></p><p><span style="color:#000000">Laravel 11 使用的 PHP 版本最低要求是&nbsp;PHP 8.2。</span></p><p><img alt="" height="352" src="https://oscimg.oschina.net/oscnet/up-0453b972568e047b7d57af4dd0cf5cf3c7d.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><strong>極簡應用結構</strong></span></p><p><span style="color:#000000">Laravel 11 為新的 Laravel 應用程序引入了極簡應用程序結構，無需對現有應用程序進行任何更改。新的應用程序結構旨在提供更精簡、更現代的體驗，同時保留 Laravel 開發人員已經熟悉的許多概念。</span></p><p><span style="color:#000000">應用程序文件夾已大幅簡化；HTTP 內核和控制枱內核都已刪除。很少定製的九個中間件現已移至框架本身，異常處理程序已被移除，Providers 目錄精簡為單一提供程序。</span></p><p><img height="313" src="https://oscimg.oschina.net/oscnet/up-fd30e47727225b78e873f024484cf66b61e.png" width="500" referrerpolicy="no-referrer"></p><p><img height="388" src="https://oscimg.oschina.net/oscnet/up-45a1e9253daae9587fc3b631ede34b2d0a4.png" width="500" referrerpolicy="no-referrer"></p><p>此外，<code>routes</code>文件夾也得到了簡化；默認情況下， <code>api.php</code>和<code>channels.php</code>路由文件不再存在，因為許多應用程序不需要這些文件。</p><p><img height="209" src="https://oscimg.oschina.net/oscnet/up-201c1fc787f2da27f81a117792a7429a363.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">可以使用簡單的 Artisan 命令來創建它們：</span></p><pre style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><code class="language-shell">php artisan install:api

php artisan install:broadcasting</code></span></pre><p><strong><span style="color:#000000">Laravel Reverb</span></strong></p><p>Laravel Reverb 直接為你的 Laravel 應用程序帶來超快且可擴展的實時 WebSocket 通信，並提供與 Laravel 現有事件廣播工具套件（例如<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel.com%2Fdocs%2F11.x%2Fbroadcasting" target="_blank">Laravel Echo）</a>的無縫集成。<span style="color:#000000">此外，Reverb 通過 Redis 的發佈/訂閲功能支持水平擴展，允許用户在多個後端 Reverb 服務器之間分配 WebSocket 流量，所有服務器都支持單個高需求應用程序。</span></p><p><img alt="" height="250" src="https://oscimg.oschina.net/oscnet/up-1afcddc83e166e5471581763d90dca87c48.webp" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">下面是一個壓力測試示例，約 30,000 個客户端保持與 Reverb 的開放連接，其中每個連接訂閲 10 個不同的通道，每秒交換超過 6,000 條消息：</span></p><p style="margin-left:0; margin-right:0; text-align:start"><img height="343" src="https://oscimg.oschina.net/oscnet/up-03c0f7168a242e4116186204b90cb8da1ed.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start">此外，用户可以在 Laravel Pulse 中監控 Reverb 服務器的性能，以更好地瞭解正在處理的連接和消息的數量。要深入瞭解 Laravel Reverb，可參閲完整的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaravel.com%2Fdocs%2F11.x%2Freverb" target="_blank">Reverb 文檔</a>。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><strong><span style="color:#000000">默認情況下的 SQLite</span></strong></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">默認情況下，新的 Laravel 應用程序使用 SQLite 進行數據庫存儲，以及 Laravel 會話、緩存和隊列的<code>database</code>驅動程序。此外，使用<code>composer create-project</code>命令或通過 Laravel 安裝程序創建項目將自動創建 SQLite 文件併為你運行初始數據庫遷移：</span></p><p style="margin-left:0px; margin-right:0px; text-align:start"><img height="267" src="https://oscimg.oschina.net/oscnet/up-3f2f9c8b6e11b58e504d090a02fccbcd80c.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start"><span style="color:#000000">這允許你在創建新的 Laravel 應用程序後立即開始構建應用程序，而無需安裝額外的軟件或創建額外的數據庫遷移。</span></p><p style="margin-left:0px; margin-right:0px; text-align:start"><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.laravel.com%2Flaravel-11-now-available" target="_blank">查看官方公告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:46:46 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282901/laravel-11-released</guid>
            <link>https://www.oschina.net/news/282901/laravel-11-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美國政府軟件要求提供安全軟件開發認證表]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">作為改善網絡安全持續努力的一部分，拜登-哈里斯政府宣佈已批准了一份</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cisa.gov%2Fresources-tools%2Fresources%2Fsecure-software-development-attestation-form" target="_blank">安全軟件開發認證表</a>。</p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">該表格由 CISA 和管理和預算辦公室 (OMB) 於 2024 年 3 月 11 聯合發佈，任何提供政府將使用的軟件的公司都需要填寫該表格。它將有助於確保該軟件是由優先考慮安全性的公司開發的。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><img height="250" src="https://oscimg.oschina.net/oscnet/up-5f101db1d80c4331864091d96dc415eac6e.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Endor Labs 首席安全顧問兼 CISA 網絡創新研究員 Chris Hughes 表示：「表格中的要求代表了一些基本的安全開發實踐，希望向聯邦政府出售軟件的供應商如果想參與聯邦監管的生態系統，就應該能夠滿足這些要求。」&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">表格中的要求之一是軟件必須在安全的環境中開發。這包括分離生產和開發環境，最大限度地減少代碼中不安全產品的使用，跨環境強制執行多因素身份驗證，加密敏感數據，實施持續監控和警報等防禦實踐，以及定期記錄、監控和審核信任關係。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「分離開發和生產環境、實施日誌記錄和 MFA 等做法是任何現代安全軟件開發環境中都應該存在的關鍵安全控制措施。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">另一個要求是通過使用自動化工具監控第三方代碼並維護內部代碼和第三方組件的來源，真誠地努力維護可信的供應鏈。它還需要定期使用自動化工具來檢查安全漏洞，包括制定披露和解決已知漏洞的策略。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">然而 Hughes 認為，這種形式缺少一些元素。例如，它不需要使用威脅建模或內存安全，而這正是 CISA 一直在推動的事情。他表示，它還允許首席執行官指定其他人在證明上簽字，以便在出現問題或證明造假時作為潛在的替罪羊。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「一方面，我們聽説網絡安全需要成為董事會的議題，CISA 甚至呼籲高管層參與其有關安全設計/默認的出版物；但另一方面，這種形式允許將這一關鍵認證活動委託給某人組織中的其他人，並可能使其無法被最高管理層/首席執行官和執行領導團隊看到。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Hughes 認為，最難滿足認證要求的軟件生產商是那些尚未實施安全軟件開發實踐的軟件生產商。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「他們需要評估當前的開發實踐，找出缺陷並實施糾正計劃。這當然需要時間和資源，而規模較小的初創公司和不成熟的組織獲得這些時間和資源的機會有限，尤其是面對對上市速度、收入、投資者回報、功能速度等方面的競爭需求。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">CISA 的在線表單提交存儲庫 (</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsoftwaresecurity.cisa.gov%2F" target="_blank">https://softwaresecurity.cisa.gov</a><span style="color:#000000">) 預計將於 2024 年 3 月下旬提供。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282896/secure-software-development-attestation-form</guid>
            <link>https://www.oschina.net/news/282896/secure-software-development-attestation-form</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[全球首位 AI 軟件工程師 Devin：能自學新語言、開發迭代 App、自動 Debug]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>初創公司 Cognition 近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fcognition_labs%2Fstatus%2F1767548763134964000" target="_blank">發佈公告</a></u>，宣佈推出全球首個 AI 軟件工程師 Devin，並號稱會徹底改變人類構建軟件的方式。</p><p><img height="1758" src="https://oscimg.oschina.net/oscnet/up-63fe0533116cdf85964e331427c9d8b851b.png" width="1282" referrerpolicy="no-referrer"></p><p>官方對其的描述如下：Devin 是一位不知疲倦、技術嫺熟的隊友，隨時準備與您並肩作戰，或獨立完成任務供您審查。有了 Devin，工程師可以專注於更有趣的問題，工程團隊可以努力實現更遠大的目標。</p><p>Devin 所具備的技能如下：</p><ul><li>快速掌握新技術：只需閲讀文檔，Devin 就能快速掌握不熟悉的工具和框架；</li><li>開發端到端應用：構建並部署功能齊全的網絡應用程序，根據用户反饋逐步增加功能；</li><li>自動化查找 BUG：Devin 擅長識別、調試和修復代碼問題，同時為開源和生產級軟件倉庫作出貢獻；</li><li>AI 培訓：從研究資料庫中獲取指令，建立並微調大型語言模型。</li></ul><p>Devin 在 SWE-bench 編碼基準測試中取得了突破性的成功，展示了其執行復雜任務的能力，甚至超越了頂尖的人類工程師。</p><p>Devin 擅長長期推理能力，可以自主規劃和完成軟件項目，並在此過程中做出數以千計的準確決策。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282895/cognition-labs-devin</guid>
            <link>https://www.oschina.net/news/282895/cognition-labs-devin</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Dante Cloud 3.2.3.3 發佈，採用領域驅動設計 (DDD) 的微服務框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>Dante Cloud</strong> (但丁，原 Eurynome Cloud) 是一款企業級微服務架構和服務能力開發平台，是採用領域驅動模型 (DDD) 設計思想的、全面擁抱 <strong>Spring Authorization Server</strong> 的、基於 <strong>OAuth2.1</strong> 協議的、支持智能電視、IoT 等物聯網設備認證的微服務架構。基於 <strong>Spring Authorization Server</strong> 1.2.2、<strong>Spring Boot</strong> 3.2.3、<strong>Spring Cloud</strong> 2023.0.0、<strong>Spring Cloud Tencent</strong> 1.13.1-2023.0.0、<strong>Spring Cloud Alibaba</strong> 2023.0.0.0、<strong>Nacos</strong> 2.3.1 等主流技術棧開發的多租户系統，遵循 <strong>SpringBoot</strong>&nbsp; 編程思想，高度模塊化和可配置化。具備服務發現、配置、熔斷、限流、降級、監控、多級緩存、分佈式事務、工作流等功能。</p><h2>定位</h2><ul><li>構建成熟的、完善的、全面的，基於 OAuth2.1 的、前後端分離的微服務架構解決方案。</li><li>面向企業級應用和互聯網應用設計開發，既兼顧傳統項目的微服務化，又滿足互聯網應用開發建設、快速迭代的使用需求。</li><li>平台架構使用微服務領域及周邊相關的各類新興技術或主流技術進行建設，是幫助快速跨越架構技術選型、研究探索階段的利器。</li><li>代碼簡潔規範、結構合理清晰，是新技術開發應用的典型的、綜合性案例，助力開發人員對新興技術的學習和掌握。</li></ul><h2>背景</h2><p><strong>這也是為什麼做 Dante Cloud 的初衷</strong>：</p><ul><li>一方面是以 <strong>Dante Cloud</strong> 為載體，潛移默化地將過往項目建設的經驗教訓融入其中，儘可能地幫助使用者規避或者減少無效工作，提升工作效率和質量，有跟多的時間做更有意義的事情；</li><li>另一方面不斷地融合和使用各類新興技術，幫助使用者儘可能多的瞭解、學習和運用新技術，讓技術不再成為禁錮變為進步和提升的基石。</li></ul><p><strong>這也是為什麼 Dante Cloud 與其它項目不同</strong>：</p><p><strong>Dante Cloud</strong> 並不過分強調常規應用功能的堆疊與豐富化，因為作者認為純開發工作僅佔整個項目建設投入的 20%，減少開發投入、提升開發效率未必就能減少整個項目建設週期剩餘 80% 工作投入。<strong>Dante Cloud</strong> 的遠景目標是可以幫助使用者縮短整個項目的建設週期和減少無意義的工作投入，而不僅僅只是在開發效率方面的提升。</p><blockquote><p>Dante Cloud 一直秉承「簡潔、高效、包容、務實」的理念，不會採取任何額外的手段來獲取更多的 Star，絕對真實就像其產品一樣。如果你認可和喜歡 Dante Cloud，請不要吝嗇你的讚美，項目右上角點顆小星星。</p></blockquote><h2>代碼分支説明</h2><table border="1" cellpadding="1" cellspacing="1"><tbody><tr><th><strong>分支名稱</strong></th><th><strong>對應 Spring 生態版本</strong></th><th><strong>對應 JDK 版本</strong></th><th><strong>用途</strong></th><th><strong>現狀</strong></th></tr></tbody><tbody><tr><td><span style="background-color:#ffffff; color:#444444">master</span></td><td><span style="background-color:#ffffff; color:#444444">Spring Boot 3.2 和 Spring Cloud 2023.0.0</span></td><td><span style="background-color:#ffffff; color:#444444">JDK 17</span></td><td><span style="background-color:#ffffff; color:#444444">主要發佈分支</span></td><td><span style="background-color:#ffffff; color:#444444">可使用，但 Spring Cloud Alibaba、Tencent 等生態組件尚未發佈正式版本</span></td></tr><tr><td><span style="background-color:#f8f8f8; color:#444444">develop</span></td><td><span style="background-color:#f8f8f8; color:#444444">Spring Boot 3.2 和 Spring Cloud 2023.0.0</span></td><td><span style="background-color:#f8f8f8; color:#444444">JDK 17</span></td><td><span style="background-color:#f8f8f8; color:#444444">Development 分支</span></td><td><span style="background-color:#f8f8f8; color:#444444">新功能、ISSUE 均以此分支作為開發，發佈後會 PR 至 master 分支。開發分支不保證可用</span></td></tr><tr><td><span style="background-color:#ffffff; color:#444444">reactive-develop</span></td><td><span style="background-color:#ffffff; color:#444444">Spring Boot 3.2 和 Spring Cloud 2023.0.0</span></td><td><span style="background-color:#ffffff; color:#444444">JDK 21</span></td><td><span style="background-color:#ffffff; color:#444444">響應式 Development 分支</span></td><td><span style="background-color:#ffffff; color:#444444">下一代響應式微服務版本開發分支。開發分支不保證可用</span></td></tr><tr><td><span style="background-color:#f8f8f8; color:#444444">3.1.X</span></td><td><span style="background-color:#f8f8f8; color:#444444">Spring Boot 3.1 和 Spring Cloud 2022.0.X</span></td><td><span style="background-color:#f8f8f8; color:#444444">JDK 17</span></td><td><span style="background-color:#f8f8f8; color:#444444">Stable 代碼分支</span></td><td><span style="background-color:#f8f8f8; color:#444444">穩定可用版本分支，2024 年 5 月，Spring Boot 3.3 發佈後將會停止維護</span></td></tr><tr><td><span style="background-color:#ffffff; color:#444444">2.7.X</span></td><td><span style="background-color:#ffffff; color:#444444">Spring Boot 2.7 和 Spring Cloud 2021.0.X</span></td><td><span style="background-color:#ffffff; color:#444444">JDK 8</span></td><td><span style="background-color:#ffffff; color:#444444">歷史代碼分支</span></td><td><span style="background-color:#ffffff; color:#444444">基於 Spring Boot 2.7 時代開發的代碼分支，不再維護</span></td></tr><tr><td><span style="background-color:#f8f8f8; color:#444444">spring-security-oauth2</span></td><td><span style="background-color:#f8f8f8; color:#444444">Spring Boot 2.6 和 Spring Cloud 2021.0.X</span></td><td><span style="background-color:#f8f8f8; color:#444444">JDK 8</span></td><td><span style="background-color:#f8f8f8; color:#444444">歷史代碼分支</span></td><td><span style="background-color:#f8f8f8; color:#444444">基於原 Spring Security OAuth2 實現的微服務，因相關組件均不在維護，所以該版本不再維護</span></td></tr></tbody></table><h2>[1] 軟件信息</h2><ul><li>軟件組成 
  <ul><li>核心組件：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-engine</a>（已上傳中央庫）</li><li>後端工程：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/dromara/dante-cloud</a></li><li>前端工程：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-cloud-ui</a></li></ul></li><li>軟件生態 
  <ul><li>Dante&nbsp;Cloud&nbsp;Athena（Dante&nbsp;Cloud&nbsp;單體版）：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-cloud-athena</a></li><li>Dante&nbsp;OSS （像&nbsp;JPA&nbsp;一樣操作&nbsp;OSS）：<a href="https://gitee.com/herodotus/dante-engine">https://gitee.com/herodotus/dante-oss</a></li></ul></li><li>軟件文檔 
  <ul><li>官方文檔：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.herodotus.cn" target="_blank">https://www.herodotus.cn</a></li><li>技術手冊： 
    <ol><li>《Dante Cloud 及相關知識學習方法和學習路徑的建議》</li><li>《OAuth 2 中的 Scope 與 Role 深度解析》</li><li>《Spring Boot 3 之自動配置與注入順序控制》</li><li>《Spring Cloud 之 Session 共享及一致性處理》</li><li>《OAuth 2 中的鑑權和動態接口鑑權》</li><li>《Spring Boot 3 之 Rest 接口傳參方式詳解》</li><li>更多詳情參見：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.herodotus.cn%2Fcookbook%2F" target="_blank">https://www.herodotus.cn/cookbook/</a></li></ol></li></ul></li></ul><h2>[2] 本次更新內容</h2><ul><li>【<strong>主要更新</strong>】 
  <ul><li>[升級] Spring Boot 版本升級至 3.2.3</li><li>[升級] Spring Boot Admin 版本升級至 3.2.2</li><li>[升級] Spring Authorization Server 版本升級至 1.2.2</li><li>[升級] Spring Cloud Alibaba 版本升級至 2023.0.0.0-RC1</li><li>[升級] Spring Cloud Tencent 版本升級至 1.13.0-2023.0.0-SNAPSHOT</li><li>[升級] Nacos 版本升級至 2.3.1</li><li>[升級] 升級 Antisamy XSS 防護策略配置文件</li></ul></li><li>其它更新 
  <ul><li>[新增] Nacos 2.3.1 SQL 腳本</li><li>[修復] 修復目前已知的所有 Spring Cloud Alibaba Sentinel 與 Spring Cloud 2023.0.0 不兼容問題和代碼</li><li>[修復] 恢復所有 Spring Cloud Alibaba Sentinel 相關支持代碼及配置</li><li>[修復] 修復前端設計自定義組件模塊在新版本 vue 和 vite 環境下，因 Typescirpt 類型錯誤導致編譯失敗問題</li><li>[修復] 修復前端粒子效果卡頓問題</li><li>[修復] 修復前端靜態路由自動校驗錯誤</li><li>[修復] 臨時修復前端 tsparticles 組件最新版本自身 ISSUE 導致前端頁面打開沒有響應問題</li><li>[修復] 修復伴隨 Spring Boot 版本，引起的 Netty 版本升級，導致的 Spring Cloud Tencent 代碼不兼容運行出錯問題。</li><li>[修復] 臨時修復 Spring Cloud Tencent 配置邏輯問題，導致服務啓動出現 `The bean 'restTemplateCustomizer', defined in class path resource [com/tencent/cloud/polaris/loadbalancer/PolarisLoadBalancerAutoConfiguration.class], could not be registered. A bean with that name has already been defined in class path resource [org/springframework/cloud/client/loadbalancer/LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration.class] and overriding is disabled</li><li>[修復] 修復 Spring Cloud Tencent 配置錯誤，導致 Spring Cloud Tencent 熔斷相關代碼無法注入問題。</li><li>[修復] 臨時修復 Spring Cloud Tencent RestTemplateCustomizer bean 衝突導致服務無法正常啓動問題</li><li>[修復] 修復伴隨 Spring Boot 版本，起的 Netty 版本升級，導致的 Spring Cloud Tencent 代碼不兼容運行出錯問題。</li><li>[修復] 修復前端提示，在 「module」 模式下無法讀取 .eslintrc.js 問題</li><li>[優化] 調整 Spring Cloud Tencent 工程日誌輸出配置</li><li>[優化] 代碼適配 Hutool 6.0.0-M11</li><li>[優化] 去除核心 Dependencies 中無用的依賴配置</li><li>[優化] 優化 Cache 相關模塊代碼，修改部分包名、代碼以及註解的使用，符合 Spring 規範的命名和使用方式</li><li>[優化] 徹底清除系統中 facility 相關模塊依賴的 bcpkix-jdk15on，解決 bcpkix 不同版本依賴衝突導致的前後端數據加密異常問題。fix: #I8XHFK</li><li>[優化] 清除為臨時解決 SMS4J 啓動輸出錯誤信息的相關配置</li><li>[安全] 增加 Hutool 5.X pom 配置，修復 SMS4J 依賴 Hutool 低版本攜帶的 CVE 問題。</li><li>[安全] 修復 Jayway JsonPath 安全漏洞 (CVE-2023-51074) fix: #I8XWGJ</li><li>[升級] Nacos docker 鏡像版本升級至 v2.3.1</li><li>[升級] minio docker 鏡像版本升級至 RELEASE.2024-03-07T00-43-48Z</li></ul></li><li>【<strong>依賴更新</strong>】 
  <ul><li>[升級] JetCache 版本升級至 2.7.5</li><li>[升級] maven-gpg-plugin 版本升級至 3.2.0</li><li>[升級] redisson 版本升級至 3.27.2</li><li>[升級] springdoc 版本升級至 2.4.0</li><li>[升級] aws-java-sdk-s3 版本升級至 1.12.676</li><li>[升級] camunda-bpm-spring-boot-starter-rest 版本升級至 7.21.0-alpha4</li><li>[升級] org.json 版本升級至 20240303</li><li>[升級] git-commit-id-maven-plugin 版本升級至 8.0.1</li><li>[升級] minio 版本升級至 8.5.9</li><li>[升級] bootstrap webjars 版本升級至 5.3.3</li><li>[升級] alipay-sdk-java 版本升級至 4.38.221.ALL</li><li>[升級] fastjson2 版本升級至 2.0.47</li><li>[升級] xnio 版本升級至 3.8.13.Final</li><li>[升級] hutool 版本升級至 6.0.0-M11</li><li>[升級] okio 版本升級至 3.8.0</li><li>[升級] antisamy 版本升級至 1.7.5</li><li>[升級] zxing 版本升級至 3.5.3</li><li>[升級] influxdb-client 版本升級至 7.0.0</li><li>[升級] sqlite-jdbc 版本升級至 3.45.1.0</li><li>[升級] sms4j 版本升級至 3.1.1</li><li>[升級] vue webjars 版本升級至 3.4.15</li><li>[升級] mysql-connector-j 版本升級至 8.3.0</li></ul></li></ul><h2>[3] Dante Cloud 特性</h2><h3>1. 核心基礎依賴便捷切換</h3><ul><li>新增 <code>Spring Cloud Tencent</code> 和 <code>Spring Cloud</code> 原生微服務全家桶等兩種基礎設施支持。</li><li>新增 <code>Spring Cloud Alibaba</code>、<code>Spring Cloud Tencent</code> 和 <code>Spring Cloud</code> 原生微服務全家桶三種基礎設值切換能力，可以以相對便捷的方式切換使用 Alibaba、Tencent、Spring 等基礎設施環境。可根據自身實際需求選擇，不再侷限於只能在某一種基礎設施環境中運行。</li></ul><h3>2. <code>Spring Authorization Server</code> 全特性支持</h3><ul><li>基於 <code>Spring Authorization Server</code> 和 <code>Spring Data JPA</code> 實現多租户系統架構， 支持 Database 和 Schema 兩種模式。</li><li>基於 <code>Spring Data JPA</code>，重新構建 <code>Spring Authorization Server</code> 基礎數據存儲代碼，替代原有 JDBC 數據訪問方式，破除 <code>Spring Authorization Server</code> 原有數據存儲侷限，擴展為更符合實際應用的方式和設計。</li><li>基於 <code>Spring Authorization Server</code>，在 OAuth 2.1 規範基礎之上，增加自定義 <code>Resource Ownership Password</code> (密碼) 認證模式，以兼容現有基於 OAuth 2 規範的、前後端分離的應用，支持 <code>Refresh Token</code> 的使用。</li><li>基於 <code>Spring Authorization Server</code>，在 OAuth 2.1 規範基礎之上，增加自定義 <code>Social Credentials</code> (社會化登錄) 認證模式，支持手機短信驗證碼、微信小程序、基於 <code>JustAuth</code> 的第三方應用登錄， 支持 <code>Refresh Token</code> 的使用。</li><li>擴展 <code>Spring Authorization Server</code> 默認的 <code>Client Credentials</code> 模式，實現真正的使用 Scope 權限對接口進行驗證。 增加客户端 Scope 的權限配置功能，並與已有的用户權限體系解耦</li><li>支持 <code>Spring Authorization Server</code><code>Authorization Code PKCE</code> 認證模式</li><li>在 <code>Spring Authorization Server</code> 的標準的 <code>JWT Token</code> 加密校驗方式外，支持基於自定義證書的 <code>JWT Token</code> 加密校驗方式，可通過配置動態修改。</li><li>支持 <code>Opaque Token</code> (不透明令牌) 格式及校驗方式，降低 <code>JWT Token</code> 被捕獲解析的風險。可通過修改配置參數，設置默認 Token 格式是採用 <code>Opaque Token</code> 格式還是 <code>JWT Token</code> 格式。</li><li>全面支持 <code>OpenID Connect</code> (OIDC) 協議，系統使用時可根據使用需求，通過前端開關配置，快速切換 OIDC 模式和傳統 OAuth2 模式</li><li>深度擴展 <code>Authorization Code</code>、<code>Resource Ownership Password</code>、<code>Social Credentials</code> 幾種模式，全面融合 <code>IdToken</code>、<code>Opaque Token</code>、<code>JWT Token</code> 與現有權限體系，同時提供 <code>IdToken</code> 和，自定義 Token 擴展兩種無須二次請求的用户信息傳遞方式，減少用户信息的頻繁請求。</li><li>自定義 <code>Spring Authorization Server</code> 授權碼模式登錄認證頁面和授權確認頁面，授權碼模式登錄採用數據加密傳輸。支持多種驗證碼類型，暫不支持行為驗證碼。</li><li>新增基於 <code>Spring Authorization Server</code> 的、支持智能電視、IoT 等物聯網設備認證模式</li><li>無須在代碼中配置 <code>Spring Security</code> 權限註解以及權限方法，即可實現接口鑑權以及權限的動態修改。採用分佈式鑑權方案，規避 Gateway 統一鑑權的壓力以及重複鑑權問題</li><li>OAuth2 UserDetails 核心數據支持直連數據庫獲取和 Feign 遠程調用兩種模式。OAuth2 直連數據庫模式性能更優，Feign 訪問遠程調用可擴展性更強。可通過配置動態修改採用策略方式。</li></ul><h3>3. 全體系化應用特性集成</h3><ul><li>微服務架構全體系 Session 共享，實現 Spring Authorization Server、多實例服務、WebSocket、自定義 Session 以及大前端 Session 的統一。<code>微服務架構下的 Session 可以選擇不用，但是不能沒有</code>。</li><li>混合國密 <code>SM2</code> (非對稱) 和 <code>SM4</code> (對稱加密) 算法，實現基於數字信封技術的秘鑰動態生成加密傳輸。利用「一人一碼機制」，實現前後端數據進行動態加密傳輸與。Spring Authorization Server OAuth 2.1 授權模式深度融合，構建統一體系的數據傳輸加密。</li><li>全面整合 <code>@PreAuthorize</code> 註解權限與 <code>URL</code> 權限，通過後端動態配置，無須在代碼中配置 <code>Spring Security</code> 權限註解以及權限方法，可實現接口鑑權以及權限的統一管理和動態修改</li><li>融合 Spring Cloud Stream 和 WebSocket，以優雅的方式實現 WebSocket 服務多實例環境下，點對點、廣播消息跨實例推送，在線用户實時統計，完美支持 WebSocket 集羣化應用。</li><li>借鑑 JPA 標準化設計思想，提取和抽象 OSS 標準化操作，形成統一的 Java OSS API 規範。封裝可操作任意廠商的、統一的 REST API，構建定義統一、動態實現的應用模式（類似於 Hibernate 是 JPA 的一種實現，Hibernate 以 Dialect 方式支持不同的數據庫一樣），在不修改代碼的情況下通過修改配置實現 OSS 的無縫切換和遷移</li><li>自研基於 <code>JetCache</code> 分佈式兩級緩存，完美實現 JPA Hibernate 二級緩存，支持各類查詢數據緩存以及 JPA <code>@ManyToMany</code>， <code>@ManyToOne</code>等關聯查詢。完美解決 Spring Cache 僅使用本地緩存、創建 Key 繁瑣和分頁數據無法更新的問題。支持多實例服務本地緩存和遠程緩存數據同步，同時支持 Mybatis Plus 二級緩存</li><li>平台統一錯誤處理，支持自定義錯誤碼體系，有效集成 <code>OAuth2</code>、<code>Spring Validation</code> 等多方錯誤體系並有機整合 HTTP 狀態碼。採用 Customizer 模式，採用錯誤碼自動計算和創建模式，支持代碼模塊級錯誤碼靈活定義擴展。響應結果更加多樣靈活，反饋結果也更加人性化，便於理解和定位問題。</li><li>全體系 OkHttp 、HttpClient 統一化集成，實現 OkHttp 、HttpClient 與 RestTemplate 、Openfeign 一體化融合。統一使用 Feign 配置參數，對 OkHttp 、HttpClient 進行參數設定，可策略化選擇設置使用 OkHttp 或 HttpClient 作為 RestTemplate 、Openfeign 統一的基礎 HttpClient</li></ul><h3>4. 採用 <code>pnpm monorepo</code> 重構前端</h3><ul><li>未使用任何流行開源模版，使用全新技術棧，完全純"手寫"全新前端工程。</li><li>借鑑參考流行開源版本的使用和設計，新版前端界面風格和操作習慣儘量與當前流行方式統一。</li><li>充份使用 Typescript 語言特性，解決大量類型校驗問題，儘可能規避 "any" 式的 Typescript 編程語言使用方式。</li><li>充份使用 Composition Api 和 Hooks 等 Vue3 框架新版特性進行代碼編寫。</li><li>充份利用 Component、Hooks 以及 Typescript 面向對象等特性，抽取通用組件和代碼，儘可能降低工程重複代碼。</li><li>對較多 Quasar 基礎組件和應用功能組件進行封裝，以方便代碼的統一修改維護和開發使用。</li><li>對生產模式下，對基於 Vite3 的工程打包進行深度性能優化。</li><li>提供以 docker-compose 方式，對工程生產代碼進行容器化打包和部署。</li><li>該版本基於 pnpm，採用 monorepo 模式對前端工程進行重構。構建 monorepo 版本前端，是為擴展更多功能、增加應用級功能做鋪墊</li><li>抽取 utils、components、apis、bpmn-designer 等相關代碼，形成共享模塊。</li><li>共享模塊已進行優化配置，可編譯成獨立的組件，單獨以組件形式進行發佈。</li><li>代碼以共享模塊的方式進行單獨維護開發，降低現有工程代碼複雜度，便於後續功能的擴展和代碼的複用。</li></ul><hr><p style="color:black; margin-left:0; margin-right:0; text-align:left"><strong>歡迎 Star 一波來支持我們！</strong></p><p style="color:black; margin-left:0; margin-right:0; text-align:left"><strong>Gitee</strong>：<a href="https://gitee.com/dromara/dante-cloud">https://gitee.com/dromara/dante-cloud</a><span>&nbsp;</span></p><p style="color:black; margin-left:0; margin-right:0; text-align:left"><strong>Github</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdromara%2Fdante-cloud" target="_blank">https://github.com/dromara/dante-cloud</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 06:28:18 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282891/dante-cloud-3-2-3-3-released</guid>
            <link>https://www.oschina.net/news/282891/dante-cloud-3-2-3-3-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘋果放寬歐盟 App Store 軟件分發規則]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">蘋果公司<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fnews%2F%3Fid%3D8c1m8hqt" target="_blank">宣佈</a>計劃放寬歐盟 App Store 的部分軟件分發規則。「我們為在歐盟 (EU) 分發應用程序的開發者提供了更大的靈活性，包括引入一種直接從開發者網站分發應用程序的新方法。」</span></p><p><img height="189" src="https://oscimg.oschina.net/oscnet/up-aeff8c07ddcf1ab5d5c5b257662843ab247.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">據悉，此舉將使該公司更容易遵守歐盟立法者於 2022 年通過的《數字服務法》和《數字市場法》這兩部反壟斷法，分別於上個月和上週生效。</span></p><p><span style="color:#000000">公告指出，已同意歐盟應用程序替代條款附錄的開發者可以為其在歐盟的應用程序提供新選項：</span></p><ul><li><span style="color:#000000">備選應用市場（Alternative app marketplaces）。市場可以選擇僅提供來自市場開發商的應用程序目錄。</span></li><li><span style="color:#000000">Linking out to purchase。修訂後的應用商店規則允許歐盟的開發者自定義指向外部網站的應用內鏈接。軟件團隊現在可以「選擇如何設計促銷、折扣和其他交易」。此前，應用程序僅限於使用 Apple 提供的一組界面模板，更新後這些模板將繼續作為可選的開發人員資源提供。</span></li></ul><p><span style="color:#000000">預計今年春季晚些時候還將會推出 Web Distribution 功能，授權開發者可以直接通過開發者擁有的網站向歐盟用户分發 iOS 應用程序。Apple 將為授權開發者提供 API 訪問權限，以方便他們通過網絡發佈應用程序、集成系統功能、備份和恢復用户的應用程序等。</span></p><p><span style="color:#000000">更多相關詳情可查看&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fsupport%2Fweb-distribution-eu%2F" target="_blank">Getting ready for Web Distribution in&nbsp;the&nbsp;EU</a><span style="color:#1d1d1f">。</span></p><p><strong><span style="color:#1d1d1f">相關閲讀：</span></strong></p><ul><li style="margin-left: 0px; margin-right: 0px; text-align: start;"><a href="https://www.oschina.net/news/276674" target="_blank">蘋果在歐盟地區放開對瀏覽器和應用商店的限制</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 06:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282888/apple-app-store-software-distribution-rules-eu</guid>
            <link>https://www.oschina.net/news/282888/apple-app-store-software-distribution-rules-eu</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Tremor —— 模塊化組件 React 庫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p>Tremor 是一個快速構建儀錶板的 React 庫，完全開源，由數據科學家和軟件工程師打造。</p></div><p><img height="1000" src="https://static.oschina.net/uploads/space/2023/0609/161343_Wiyn_4937141.png" width="3000" referrerpolicy="no-referrer"></p><h2>入門</h2><p>對於新項目，官方建議使用 Next.js 13.4+，要使用該庫，還需要在項目中設置 Tailwind CSS。</p><h2>使用 NextJS</h2><p>在終端中，我們會創建一個新的 Next 項目，當提示 <code>Would you like to use Tailwind CSS with this project?</code>時，選擇 <code>Yes</code>.</p><div><pre>npx create-next-app@latest my-project
cd my-project</pre></div><h3>使用 Tremor CLI 安裝</h3><p>建議使用我們的 CLI 安裝 Tremor。 為此，請運行此命令並選擇 Next 作為你的框架。</p><div><pre>npx @tremor/cli@latest init</pre></div><p>現在你已經設置好了，就可以啓動開發服務器了。</p><div><pre>npm run dev</pre></div><p>&nbsp;</p></div>
                                                                ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 03:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tremor</guid>
            <link>https://www.oschina.net/p/tremor</link>
        </item>
    </channel>
</rss>
