<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 06 Feb 2024 11:42:36 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[央行發佈《金融業開源軟件應用，評估規範》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">1 月 15 日，人民銀行發佈金融行業標準《金融業開源軟件應用，評估規範》（JR/T 0291-2024）（以下簡稱「《規範》」），於當天實施。</span></p><p><span style="color:#000000"><img alt="" height="412" src="https://oscimg.oschina.net/oscnet/up-d702051be7eaa2a8e19b671e9fec9c74ac8.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">據悉，在金融業信息系統建設過程中，開源軟件得到了廣泛應用，在促進金融機構科技創新和數字化轉型等方面發揮了積極作用，但也帶來安全、合規等方面的風險與挑戰。因此，有必要對開源軟件的引入、維護、退出階段進行規範，提出相應的評估指標。</span></p><p><span style="color:#000000">《規範》旨在針對開源軟件使用過程中的風險與難點，提出一套完整的開源軟件生命週期管理各階段評估項與評估方法，降低金融機構開源軟件評估過程的複雜度和時間成本，提升金融機構開源治理能力。</span></p><p><span style="color:#000000">《規範》規定了金融機構在應用開源軟件時的評估要求，對開源軟件的引入、維護和退出提出實現要求、評估方法和判定準則。適用於金融機構對應用的開源軟件進行評估。</span></p><p><span style="color:#000000">《規範》提到，引入的開源軟件按照實際應用情況，可分為開源基礎軟件、開源組件和開源工具 3 類。</span></p><p><span style="color:#000000"><strong>開源軟件引入評估</strong></span></p><p><span style="color:#000000">開源軟件引入流程分為 3 個階段：</span></p><ul><li><span style="color:#000000">一是需求確定階段。應明確軟件功能需求與非功能需求。</span></li><li><span style="color:#000000">二是初步篩選階段。應根據需求展開調研，依照初選評估要求，對開源軟件進行評估，建立若干可進入終選評估的開源軟件名單。</span></li><li><span style="color:#000000">三是終選評估階段。應根據初選階段建立的開源軟件名單，依照終選評估要求進行評估，並確定最終引入的開源軟件。</span></li></ul><p><span style="color:#000000">在初選評估要求上，評估維度包括：</span></p><p><span style="color:#000000">1、開源許可證。金融機構在選用開源軟件時，應遵守該開源許可證對使用、修改等行為的規定。 2、產品認可度。產品認可度反映了開源軟件在行業生產實踐中的應用情況。 3、產品活躍度。產品活躍度反映了開源軟件的可持續性和可進化能力，主要從開源軟件的版本發佈情況、開源社區情況、軟件關注情況等方面進行評估。 4、行業支持情況。行業支持情況反映開源軟件在業界提供專業化服務的情況。 5、功能特性。不同軟件用於解決不同場景的特定問題，其功能特性也不相同，對於功能的評測應結合具體場景進行。 6、安全性。初步篩選階段安全性重點考查已暴露的漏洞情況。 7、可靠性。重點考察開源軟件自身或者結合其他開源軟件的高可用性，在出現故障時是否具備自動故障切換能力和容錯能力。 8、兼容性。可通過查看文檔的方式評估開源軟件的兼容性，例如開源軟件對不同硬件的兼容性、對不同操作系統的兼容性。</span></p><p><span style="color:#000000">在終選評估要求上，評估維度則包括：</span></p><p><span style="color:#000000">1、安全性。終選階段安全性重點考查安全機制方面的支持情況。 2、可靠性。終選階段可靠性重點考察外部開源軟件長時間無故障運行的能力，系統可在極限情況下長時間穩定運行，保證業務成功率以及執行效率。 3、性能效率。終選階段性能效率重點考查在實際壓測環境下開源軟件的 TPS、QPS、平均響應時間、最大響應時間、最大併發數、服務調用成功率、時間標準差、CPU 使用率、內存佔用率、帶寬佔用及 I/O 情況。 4、兼容性。兼容性包括硬件兼容性、操作系統平台兼容性、數據庫兼容性、開源軟件版本之間的兼容性，以及編程語言的兼容性、協議兼容性、同一運行環境的其他組件兼容性、開源軟件與國產操作系統兼容性。 5、可維護性。可維護性即維護人員對該開源軟件進行維護的難易程度，具體包括理解、改正、改動和改進該軟件的難易程度。 6、可擴展性。可擴展性主要包括分佈式系統下節點的水平擴展、動態擴展及代碼擴展能力。 7、易用性。易用性描述了開源軟件的學習成本、安裝和部署的難易程度等。</span></p><p><span style="color:#000000"><strong>開源軟件維護評估</strong></span></p><p><span style="color:#000000">在開源軟件維護過程中，金融機構應根據開源軟件的自主可控程度將開源軟件進行分類管理，根據其對主營業務的影響程度分為 3 類：</span></p><ul><li><span style="color:#000000">簡單使用類開源軟件：可搭建環境，且功能可正常使用。</span></li><li><span style="color:#000000">深度使用類開源軟件：在滿足簡單使用類開源軟件要求基礎上，掌握開源軟件容災容錯機制、實現原理、核心算法等重要內容。</span></li><li><span style="color:#000000">定製開發類開源軟件：在滿足深度使用類開源軟件要求基礎上，熟悉代碼實現、設計思路，通過定製開發能夠較好地滿足平台需求。</span></li></ul><p><span style="color:#000000">其中，簡單實用類開源軟件維護評估內容有：</span></p><p><span style="color:#000000"><img alt="" height="364" src="https://oscimg.oschina.net/oscnet/up-09331353c70a84785f1975e432d5f805b0a.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">深度使用類開源軟件維護評估內容為：</span></p><p><span style="color:#000000"><img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-536ed6dd8f5f3d1ff3e7a20ba421c81f313.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">定製開發類開源軟件維護評估內容為：</span></p><p><span style="color:#000000"><img alt="" height="369" src="https://oscimg.oschina.net/oscnet/up-30dfc33dfd5d8956fcecfbf08ff14c65dcd.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><strong>開源軟件退出評估</strong></span></p><p><span style="color:#000000">對於開源軟件當前版本已無法滿足功能、性能需求，或發現當前版本存在重大風險隱患，或該開源軟件已停止更新等情況，應進行退出評估。開源軟件的退出可通過開源軟件版本升級或開源軟件更換來實現。</span></p><p><span style="color:#000000">開源軟件退出評估內容包括：開源軟件退出機制、開源軟件的升級具備兼容性、開源軟件在升級後開源許可證的變化，以及更換的開源軟件。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 08:13:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278033</guid>
            <link>https://www.oschina.net/news/278033</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌向 Rust 基金會捐贈 100 萬美元，改進 Rust 與 C++ 的互操作性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsecurity.googleblog.com%2F2024%2F02%2Fimproving-interoperability-between-rust-and-c.html" target="_blank">宣佈</a></u>向 Rust 基金會捐贈 100 萬美元，這筆資金將用於支持名為<strong>「Interop Initiative」</strong>的新計劃——專注提升 C++ 與 Rust&nbsp;互操作性。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-8a0f4a84a2a1250ba949160c21a66e31916.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffoundation.rust-lang.org%2Fnews%2Fgoogle-contributes-1m-to-rust-foundation-to-support-c-rust-interop-initiative%2F" target="_blank">https://foundation.rust-lang.org/</a></u></em></p></blockquote><p>據介紹，谷歌的核心產品採用了數百萬行 C++ 代碼進行編寫，由於無數的業務相關或技術因素，在合理的時間內用 Rust 重寫這些代碼並不實際。因此在谷歌的支持下，Rust 基金會創建了新的"Interop Initiative"計劃，讓全世界正在使用 C++ 的組織更順利地做出採用 Rust 的決策和流程。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-58623854011083ebd628e8852dfca87752d.png" referrerpolicy="no-referrer"></p><p>谷歌稱早已在 Android 和其他產品中廣泛使用 Rust 編程語言，並表示 Rust 是他們解決內存安全問題的最強大的工具之一。而且整體來看，谷歌在 Android 中使用 Rust 的增長最為顯著。</p><p>Android 安全與隱私工程副總裁 Dave Kleidermacher 表示，根據歷史漏洞密度統計數據，Rust 已主動阻止數百個漏洞影響 Android 生態系統。目前這項投資旨在擴大 Rust 在平台各個組件中的採用。</p><p>除了 Android，谷歌也積極在其他應用程序和產品中採用 Rust，包括客户端和服務器硬件。</p><p>Rust 基金會董事會主席兼谷歌成員總監 Lars Bergstrom 説道：「谷歌相信 Rust 等內存安全語言所發揮的關鍵作用，以及解決各個領域內存安全問題的迫切需要。我們支持 Rust 基金會的&nbsp;<strong>Interop Initiative</strong>&nbsp;計劃，因為與 C++ 更好的互操作性將是 Rust 被採用的關鍵，並讓更多組織和社區從內存安全系統中受益。」</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 08:09:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278032/google-contributes-1m-to-rust-foundation</guid>
            <link>https://www.oschina.net/news/278032/google-contributes-1m-to-rust-foundation</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MetaBCI —— 腦機接口開源軟件平台]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>MetaBCI 是中國首個腦機接口開源軟件平台，由離線分析模塊 Brainda、刺激呈現模塊 Brainstim 和在線數據流模塊 Brainflow 三大部分構成，提供了面向 BCI 軟件層面全鏈條開發的解決方案。</p><ul style="list-style-type:disc; margin-left:0; margin-right:0"><li>面向離線分析需求，Brainda 統一了現有公開數據集接口，優化了腦電數據讀取、處理流程，復現多種主要 BCI 數據分析及解碼算法，以此提高研究者的算法開發效率；</li><li>面向刺激呈現需求，Brainstim 提供了簡潔高效的範式設計模塊，可快速創建腦機接口範式刺激界面；</li><li>面向在線開發需求，Brainflow 利用雙線程、雙進程編程方法實現了實時高速的數據讀取、數據處理、結果反饋等功能，幫助開發者輕鬆搭建腦機接口在線實驗系統。</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-8f4d4e3e7fbcc8a74be3635f43436fba05b.png" referrerpolicy="no-referrer"></p><p>相較於現有的腦機接口軟件工具包，MetaBCI 基於開源語言 Python 編寫，並且能夠涵蓋腦機接口全鏈條功能。MetaBCI 完全打通了腦機接口軟硬件開發與設計鏈路，可為腦機接口在科學研究、醫療康復、娛樂生活、特種控制等領域的應用提供重要支撐，持續推動新一代腦機智能快速發展。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:59:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/metabci</guid>
            <link>https://www.oschina.net/p/metabci</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 一文詳解靜態圖和動態圖中的自動求導機制]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4a0c43362f56c1a7d9d7eaa7f9a9328a225.png" referrerpolicy="no-referrer"></p><p>作者 | FesianXu</p><blockquote><p>導讀</p><p>4 年前在《AutoDiff 理解》 之第一篇「自動求導技術在深度學習中的應用」[1]中打算寫一個關於 autodiff 的系列文章，因為工作和學習上比較忙碌（Lan Duo :P），就一直拖到了現在。剛好最近又在學習 OPEN MLSYS[2]，藉此機會將靜態圖中的 autodiff 筆記也一併寫完吧。如有謬誤請聯繫指出。</p><p>（注意，在閲讀本文之前，請確保已經閲讀過[1]，瞭解為什麼深度學習以自動求導作為主要的訓練方式，會對理解本文有所幫助。）</p></blockquote><blockquote><p><em>全文 8965 字，預計閲讀時間 23 分鐘。</em></p></blockquote><span id="OSC_h1_1"></span><h1><strong>01 靜態圖與動態圖的區別</strong></h1><p>之前在[1]中提到過，自動求導（AutoDiff）機制是當前深度學習模型訓練採用的主要方法，而在靜態圖和動態圖中對於自動求導的處理是不一樣的。作為前置知識，這裏簡單進行介紹。</p><p>我們都知道靜態圖建模（如 TensorFlow，<a href="https://www.oschina.net/action/visit/ad?id=1185">paddle</a> fluid）是聲明式編程，其建圖過程和計算過程是分開的，而對於動態圖建模而言（如 pytorch，<a href="https://www.oschina.net/action/visit/ad?id=1185">paddle</a>）是命令式編程，其計算伴隨着建圖一起進行。注意，這兩種編程範式有着根本上的區別，相信用過 tensorflow 和 pytorch 的小夥伴能感受得到。總的來説，動態圖邊建圖邊計算的方式容易理解，而靜態圖先建圖，後計算的方式並不是很容易理解，我們完全可以把靜態圖語言（比如 TensorFlow，<a href="https://www.oschina.net/action/visit/ad?id=1185">Paddle</a>）看成是獨立於 python 之外的建圖的一種描述語言，其任務主要是建計算圖，而其計算部分完全由其 C++後端進行計算。靜態圖的建圖和計算獨立的過程和示意代碼，可以用 Fig 1.1 進行</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-c4bc16ff7bc7f8c10fd88d122b341233392.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 1.1 靜態圖建圖和計算的過程示意</strong></em></p><p>注意到，動態圖邊建圖邊計算，也即是每一次的模型訓練都會進行重新建圖和計算，這意味着：</p><p>1、系統無法感知整個動態圖模型的全局信息。有些變量可能後續不會再被引用了，可以釋放內存，在動態圖系統中由於無法感知到後續圖的結構，因此就必須保留下來（除非工程師手動釋放），導致顯存佔用一般會大於靜態圖（當然也並不一定）。</p><p>2、每次都需要重新建圖，在計算效率上不如靜態圖，靜態圖是一次建圖，後續永遠都是在這個建圖結果的基礎上進行計算的。這個就類似於解釋性語言（如 python）和編譯性語言（如 C 和 C++）的區別。</p><p>3、由於動態圖需要每次重新建圖，導致其無法在嵌入式設備上進行部署（兩種原因，1 是效率問題，2 是嵌入式設備通常不具有網站的建圖運行時，只支持推理模式），通常需要其以某種形式（比如 ONNX）轉化為靜態圖的參數後，通過靜態圖部署。常見的部署方式包括 TensorRT，<a href="https://www.oschina.net/action/visit/ad?id=1189">Paddle Lite</a>，TensorFlow Lite，TensorFlow Serving，NCNN（手機端居多）等等。</p><span id="OSC_h1_2"></span><h1><strong>02 自動求導 AutoDiff</strong></h1><span id="OSC_h2_3"></span><h2><strong>2.1 動態圖</strong></h2><p>動態圖是完全的邊建圖邊計算，注意到是完全，完全，完全！重要的事情説三遍，這意味着在動態圖裏面的自動求導過程也是邊建圖邊計算完成了。如 Fig 2.1 所示，在進行前向計算的過程中，除了對前向計算結果進行保存外（簡稱為前向計算緩存，forward cache），還會同時進行當前可計算的反向梯度的計算（簡稱為反向計算緩存，backward cache），並且將反向梯度的計算結果同樣保存下來。在需要進行端到端的梯度計算的時候，比如調用了 pytorch 的 output.backward()，此時會分析輸出節點 output 和每個葉子節點的拓撲關係，進行反向鏈式求導。此時其實每一步的梯度都已經求出來了，只需要拼在一起，形成一個鏈路即可。將早已計算得到的前向緩存和反向緩存結果代入拓撲中，得到最終每個葉子節點的梯度。如式子 (2-1) 和 (2-2) 所示。這就是動態圖的前向和反向計算邏輯，在建圖的同時完成前向計算和反向計算。這種機制使得模型的在線調試變得容易（對比靜態圖而言），我們待會將會看到靜態圖是多麼的「反人類」（對比動態圖而言）。</p><p><span class="math-tex">\(\begin{align} \dfrac{\partial H_3}{\partial X_1} &amp;= \dfrac{\partial H_3}{\partial H_2} (\dfrac{\partial H_2}{\partial X_1}+\dfrac{\partial H_2}{\partial H_1} \dfrac{\partial H_1}{\partial X_1}) \ &amp;= 5(1+1*0.2) = 6 \end{align} \tag{2-1}\)</span></p><p><span class="math-tex">\(\begin{align} \dfrac{\partial H_3}{\partial X_2} &amp;= \dfrac{\partial H_3}{\partial X_2} + \dfrac{\partial H_3}{\partial H_2} (\dfrac{\partial H_2}{\partial H_1} \dfrac{\partial H_1}{\partial X_2}) \ &amp;= -18 + 510.6 = -15 \end{align} \tag{2-2}\)</span></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-0023ca7b570f61d4ebaf2280addb4e4dc37.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 2.1 動態圖的前向和反向計算過程是在建圖的時候一起完成的</strong></em>_</p><p>不難發現，在進行反向傳播的時候整個系統需要緩存，維護多種類型的變量，包括前向計算的結果緩存，反向梯度的緩存，參數矩陣等等。這些都是模型訓練過程中佔據顯存使用的大頭。</p><span id="OSC_h2_4"></span><h2><strong>2.2&nbsp;靜態圖</strong></h2><p>對於靜態圖而言，建圖是一次性完成的，計算可以在這個建好的計算圖上反覆進行。如 Fig 3.2 所示，靜態圖在建圖階段同時將前向計算圖和反向計算圖都一併建好了（除非指定了在推理模型，此時沒有反向建圖的過程），當 placeholder 輸入真實的 Tensor 數據時（也就是 feed_list），在指定了輸出節點的情況下（也就是 fetch_list），執行器會解析整個計算圖，得到每個節點的計算順序，並對 Tensor 進行相對應的處理。如以下代碼所示，通過 tf.gradients(Y, X) 可以顯式拿到梯度節點，在執行器運行過程中 sess.run()，只需要指定需要的輸出節點（比如是前向輸出 output 或者是梯度輸出 grad）和喂入數據 feed_list，即可在計算圖上計算得到結果。</p><pre><code>import tensorflow as tf

X1 = tf.placeholder(tf.float32, shape=(1,), name="X1")
X2 = tf.placeholder(tf.float32, shape=(1,), name="X2")

h1 = tf.multiply(X1, X2)
h2 = tf.add(h1, X1)
output = tf.div(h2, X2)

grad = tf.gradients(output, [X1, X2])

feed_dict = {
    "X1": 0.6, "X2": 0.2
}
sess = tf.Session()
output_v = sess.run(output, feed_dict)
grad_v = sess.run(grad, feed_dict)



</code></pre><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-efd595949c5802c6f69794361d2b29297ea.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.2 靜態圖的正向建圖和反向建圖都在建圖階段一併完成了</strong></em></p><p>由此我們發現了靜態圖和動態圖自動求導機制的不同點，靜態圖在執行計算過程中，其實並不區分前向計算和反向計算。對於執行器而言，無論是前向過程建的圖，亦或是反向過程建的圖都是等價的，執行器不需要區分，因此只需要一套執行器即可，將自動求導機制的實現嵌入到了建圖過程中。而由於動態圖的建圖和計算同時進行，導致其執行器也必須區分前向和反向的過程。從靜態圖的實現機制上看，我們也不難發現，由於靜態圖提前已經對整個計算圖的拓撲結構有所感知，就能對其中不合理的內存使用進行優化，並且可以對節點進行融合優化，也可以靜態分析得到更合理的節點執行順序，從而實現更大的並行度。靜態圖的這些性質決定了其更適合於模型部署，計算效率和內存使用效率都比動態圖更高。但是靜態圖也有一個最大麻煩，就是模型調試麻煩。首先由於對整個圖都建好了後才能執行，因此並不能動態往裏面添加原生 python 的 print 操作——此時 Tensor 都還沒計算出來呢，你打印出來的只是該計算節點本身而已，並沒有輸入任何數值信息。為了 print 其中的節點以進行模型調試，可以往裏面插入 TensorFlow 的 tf.Print 操作節點，如 Fig 3.3 所示。當然，你也可以單純在執行器運行時，通過指定 fetch_list=[h2]進行中間變量的獲取。但是不管是哪種方法，都顯然比動態圖的調試更為麻煩。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-378415e5011770ede0f66dc0c731563b7fa.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.3 在計算圖中插入 Print 節點，以進行模型調試</strong></em></p><p>靜態圖對於數據流控制的操作，也遠比動態圖麻煩。以條件判斷為例子，在動態圖中只需要實時計算判斷條件，實時建圖計算即可，一切都是那麼地順滑。但是靜態圖是必須得提前建圖的，這意味着無法實時進行分支判斷，因此所有可能的分支都需要進行建圖，如 Fig 3.4 所示，實現了以下的條件判斷邏輯。</p><pre><code>if (X &gt; 2) {
    return X * X3
} else {
    return X4 - X
}



</code></pre><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-2f84a6626d0c423dfe41347b905584f1311.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.4 靜態圖中對於所有可能的條件判斷分支，都需要提前建圖</strong></em></p><span id="OSC_h1_5"></span><h1><strong>03 靜態圖自動求導的實現示例</strong></h1><span id="OSC_h2_6"></span><h2><strong>3.1 前向建圖和反向建圖</strong></h2><p>以上講了那麼多動態圖和靜態圖的差別，看似有些跑題了，我們説好的自動求導實現呢？嗯嗯，本章在讀者對靜態圖和動態圖有了充分的認知之後，將會討論如何實現靜態圖的自動求導機制。筆者已經將代碼開源_（ <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFesianXu%2FToyAutoDiff" target="_blank">https://github.com/FesianXu/ToyAutoDiff</a> ）_，有興趣的讀者可以自行嘗試。在這個代碼庫中，主要有兩種數據結構類，Node 和 Op。Node 是節點類，如下所示，其主要定義了輸入列表 self.inputs，這個輸入列表用於儲存當前節點的所有輸入信息，而其本身則是作為輸出存在，通過這種方式可以建立一個前向圖，如 Fig 3.5 所示，通過維護 Node 類中的 inputs 列表，就足以維護前向圖的拓撲關係，其是一個有向無環圖（Directed Acyclic Cycle, DAG）。同時，Node 類中還具有一個 const_attr 用於描述 Tensor 與常數的一些操作，如果想要引入類型推斷系統，那麼還需要加入 self.shape，但是本文中並沒有引入這個機制。</p><pre><code>class Node(object):
    def __init__(self):
        self.inputs = []
        self.op = None
        self.const_attr = None
        self.name = ""

    def __add__(self, other):
        if isinstance(other, Node):
            new_node = add_op(self, other)
        else:
            new_node = add_byconst_op(self, other)
        return new_node

    def __mul__(self, other):
        if isinstance(other, Node):
            new_node = mul_op(self, other)
        else:
            new_node = mul_byconst_op(self, other)
        return new_node

    def __truediv__(self, other):
        raise ValueError('No implement div')

    # Allow left-hand-side add and multiply.
    __radd__ = __add__
    __rmul__ = __mul__

    def __str__(self):
        return self.name

    __repr__ = __str__



</code></pre><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-0a120695cc882c7543516445b214cfcc60d.png" referrerpolicy="no-referrer"></p><p><em><strong>△Fig 3.5 通過組織 Node 裏面的 inputs 列表，既可以維護一個前向圖關係的描述</strong></em></p><p>通過實現一個抽象類 Op，我們把所有算子的基類需要的共有接口給定義了，第一個是計算方法（Compute），注意到該操作並不區分前向或者反向，在執行器調用這個 compute 的時候，只是對輸入的實際 Tensor 進行指定計算而已，因此這個方法其實就是在圖計算中實現惰性計算（Lazy Compute）的實際計算方法。第二個是反向建圖方法（gradient），該方法對當前輸入節點和輸出節點（也即是自身）進行反向求導建圖。同時注意到在__call__方法中，Op 將輸出節點 new_node = Node() 進行定義，並且將其納入自己類中 new_node.op = self。</p><pre><code>class Op(object):
    def __call__(self):
        new_node = Node()
        new_node.op = self
        return new_node

    def compute(self, node, input_vals):
        raise NotImplementedError

    def gradient(self, node, output_grad):
        raise NotImplementedError



</code></pre><p>該 Op 類是一個抽象類，需要集成它實現其他具體的算子，比如矩陣乘法算子 MatMulOp。該矩陣乘法算子的輸入是兩個 Op，分別是 node_A 和 node_B。其在 compute 方法中，傳入的 Tensor 是基於 numpy array 的，因此直接採用 np.dot() 進行計算即可，當然也可以加入類型斷言，形狀斷言用以判斷傳入的 Tensor 符合計算圖的要求。在 gradient 方法中，我們知道對於矩陣乘法而言，其微分如 (3-1) 所示，將每個輸入節點的對應微分寫到 gradient 中，此時的<span class="math-tex">\(\partial \mathbf{Y}\)</span>就是前繼節點的求導累積結果，在代碼中記為 output_grad。</p><p><span class="math-tex">\(\begin{align} \mathbf{Y} &amp;= \mathbf{A} \mathbf{B} \ \partial \mathbf{A} &amp;= \partial \mathbf{Y} \cdot \mathbf{B}^{\mathrm{T}} \ \partial \mathbf{B} &amp;= \mathbf{A}^{\mathrm{T}} \cdot \partial \mathbf{Y} \end{align} \tag{3-1}\)</span></p><pre><code>class MatMulOp(Op):
    """Op to matrix multiply two nodes."""
    def __call__(self, node_A, node_B, trans_A=False, trans_B=False):
        new_node = Op.__call__(self)
        new_node.matmul_attr_trans_A = trans_A
        new_node.matmul_attr_trans_B = trans_B
        new_node.inputs = [node_A, node_B]
        new_node.name = "MatMul(%s,%s,%s,%s)" % (node_A.name, node_B.name, str(trans_A), str(trans_B))
        return new_node

    def compute(self, node, input_vals):
        assert len(input_vals) == 2
        assert type(input_vals[0]) == np.ndarray and type(input_vals[1]) == np.ndarray
        return np.dot(input_vals[0], input_vals[1])

    def gradient(self, node, output_grad):
        """
    if Y=AB, then dA=dY B^T, dB=A^T dY
        """
        return [matmul_op(output_grad, transpose_op(node.inputs[1])), matmul_op(transpose_op(node.inputs[0]), output_grad)]




</code></pre><p>通過類似的方法還可以實現其他很多算子操作，比如加減乘除等等。前向建圖很容易完成，我們討論下如何進行反向建圖。在該試驗代碼中，實現了一個 gradients 函數，如下所示，該函數對輸出節點 output_node 和指定的節點列表（node_list）中的每個節點進行求導操作。在實現這個的過程中，我們調用了一個叫做 find_topo_sort 的函數，對以這個輸出節點 output_node 為起始點進行深度優先搜尋（Depth First Search），然後進行逆序就得到了反拓撲結構。還是以 Fig 3.2 的拓撲結構為例子，對其輸出 H3 進行 DFS，得到的拓撲序為 X2 -&gt; X1 -&gt; H1 -&gt; H2 -&gt; H3，進行翻轉後得到 H3 -&gt; H2 -&gt; H1 -&gt; X1 -&gt; X2。我們發現翻轉後的序，和 Fig 3.2 的反向建圖的序是一致的。因此以此為序，遍歷的過程中不斷地調用當前遍歷節點的 op.gradient 方法，實現層次反向建圖。</p><pre><code>def gradients(output_node, node_list):
    """Take gradient of output node with respect to each node in node_list.
    Parameters
    ----------
    output_node: output node that we are taking derivative of.
    node_list: list of nodes that we are taking derivative wrt.
    Returns
    -------
    A list of gradient values, one for each node in node_list respectively.
    Something wrong, should be the backward graph of the gradients
    """
    node_to_output_grads_list = {}
    node_to_output_grads_list[output_node] = [oneslike_op(output_node)]
    reverse_topo_order = reversed(find_topo_sort([output_node]))

    for ind, each in enumerate(reverse_topo_order):
        if ind == 0:
            gg = each.op.gradient(each, oneslike_op(output_node))
        else:
            gg = each.op.gradient(each, node_to_output_grads_list[each])

        if gg is None:
            continue
        for indv, eachv in enumerate(gg):
            if each.inputs[indv] in node_to_output_grads_list.keys():
                node_to_output_grads_list[each.inputs[indv]] += gg[indv]
            else:
                node_to_output_grads_list[each.inputs[indv]] = gg[indv]

        node_to_output_grad[each] = each
    grad_node_list = [node_to_output_grads_list[node] for node in node_list]
    return grad_node_list

def find_topo_sort(node_list):
    """Given a list of nodes, return a topological sort list of nodes ending in them.

    A simple algorithm is to do a post-order DFS traversal on the given nodes, 
    going backwards based on input edges. Since a node is added to the ordering
    after all its predecessors are traversed due to post-order DFS, we get a topological
    sort.
    """
    visited = set()
    topo_order = []
    for node in node_list:
        topo_sort_dfs(node, visited, topo_order)
    return topo_order

def topo_sort_dfs(node, visited, topo_order):
    """Post-order DFS"""
    if node in visited:
        return
    visited.add(node)
    for n in node.inputs:
        topo_sort_dfs(n, visited, topo_order)
    topo_order.append(node)



</code></pre><p>建圖完後我們就需要進行計算了，而計算是有執行器（Executor）進行的。執行器中最主要的方法是 run，這個相當於 TensorFlow 中的 sess.run()，不同的在於，這裏的執行器是在構造器中指定 fetch_list，在 run() 中指定喂入的 Tensor 數據。在 run 方法中，我們同樣需要採用 DFS 對計算圖進行遍歷（不區分前向還是反向，再強調一遍），得到了計算序後，依次喂入 tensor 數據，調用 op.compute() 進行 tensor 計算即可。</p><pre><code>class Executor:
    """Executor computes values for a given subset of nodes in a computation graph."""
    def __init__(self, eval_node_list):
        self.eval_node_list = eval_node_list

    def run(self, feed_dict):
        node_to_val_map = dict(feed_dict)
        # Traverse graph in topological sort order and compute values for all nodes.
        topo_order = find_topo_sort(self.eval_node_list)
        for each in topo_order:
            if each.inputs:
                input_vals = []
                for each_input in each.inputs:
                    input_vals += [node_to_val_map[each_input]]
                node_to_val_map[each]  = each.op.compute(node=each, input_vals=input_vals)
        node_val_results = [node_to_val_map[node] for node in self.eval_node_list]
        return node_val_results



</code></pre><p>至此，我們就實現了一個簡單的靜態圖 autodiff 機製得到試驗，後續可以加入形狀推斷機制，抽象出 Layer 神經網絡層，參數初始化器 Initiator，優化器 Optimizer，損失 Loss，模型層 Model，那麼我們就可以構建出一個玩具版本的 TensorFlow 啦，嘿嘿嘿~~</p><p>————END————</p><p><strong>參考資料：</strong></p><p>[1].&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.csdn.net%2FLoseInVain%2Farticle%2Fdetails%2F88557173" target="_blank">https://blog.csdn.net/LoseInVain/article/details/88557173</a>, 《AutoDiff 理解》 之第一篇， 自動求導技術在深度學習中的應用</p><p>[2].&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenmlsys.github.io%2Fchapter_preface%2Findex.html" target="_blank">https://openmlsys.github.io/chapter_preface/index.html</a>, OPEN MLSYS</p><p>[3].&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFesianXu%2FToyAutoDiff" target="_blank">https://github.com/FesianXu/ToyAutoDiff</a></p><p><strong>推薦閲讀：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576591%26idx%3D1%26sn%3D308b40799e498afc211537944424e429%26chksm%3Dc03f9c73f7481565df2f217d1417bf381ec406c10ac50796cd678c0ae51168a408c0e301e576%26scene%3D21%23wechat_redirect" target="_blank">千萬級高性能長連接 Go 服務架構實踐</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576575%26idx%3D1%26sn%3D2d4638ad0c3235d958e724cc6cf1aaf9%26chksm%3Dc03f9b83f7481295dd1eefab21d11828a366851c427abcc588a28f0555d4ec9cda0173914c91%26scene%3D21%23wechat_redirect" target="_blank">百度搜索 Push 個性化：新的突破</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576268%26idx%3D1%26sn%3Dede6034f715c60a750d08a6191985ff8%26chksm%3Dc03f9ab0f74813a6b5f236490e30555546de98117a902557c6ccf3e370b1ba6dcd6743458954%26scene%3D21%23wechat_redirect" target="_blank">數據交付變革：研發到產運自助化的轉型之路</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247576227%26idx%3D1%26sn%3Daf13e8a1c98b8948fd29dc5acaa4054c%26chksm%3Dc03f9adff74813c9f993092cf59b2f29578e5583a05c4ad5d2e0fd46e5d665959c4abb12db20%26scene%3D21%23wechat_redirect" target="_blank">百度搜索 exgraph 圖執行引擎設計與實踐</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247575843%26idx%3D1%26sn%3D52fc61ebc3de5d36c75061a6ca2f7dfe%26chksm%3Dc03f995ff74810492986bf919bbb764fee89153a04d5d6faa2a80aaa4a23a5d391403c01da6e%26scene%3D21%23wechat_redirect" target="_blank">百度搜索&amp;金融：構建高時效、高可用的分佈式數據傳輸系統</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:53:32 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/11032933</guid>
            <link>https://my.oschina.net/u/4939618/blog/11032933</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Go 語言之父總結成功因素：吉祥物功不可沒]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Go 語言之父 Rob Pike 在澳大利亞悉尼舉行的 GopherCon AU 大會上，為紀念 Go 編程語言發佈 14 週年 (&nbsp;2009 年 11 月 10 日) 發表了一場演講，主題旨在回顧： "我們做對了什麼以及做錯了什麼 (What We Got Right, What We Got Wrong)"。</span></p><p><span style="color:#000000">Pike <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommandcenter.blogspot.com%2F2024%2F01%2Fwhat-we-got-right-what-we-got-wrong.html" target="_blank">分享</a>了許多關於 Go 早期歷史的內部記憶，以及在開發過程中有關一些重要因素的見解。不過他也聲明稱，本次發言僅代表個人觀點，與&nbsp;Go 團隊或谷歌沒有關係。</span></p><blockquote><p><span style="color:#000000">"Go 過去是、現在仍然是一個敬業的團隊和一個龐大的社區所付出的巨大努力。所以如果你同意我説的任何話，請感謝他們。如果你不同意，可以責怪我，但請不要説出來。"</span></p></blockquote><p><span style="color:#000000">Pike 補充到，編程語言的好壞在很大程度上是一個見仁見智的問題，而不是事實。在 2022 年發表的一篇討論了 Go 流行原因的文章中，Pike 與 Ken Thompson、Russ Cox、Robert Griesemer 和 Ian Lance Taylor 曾共同<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthenewstack.io%2Fgolang-co-creator-rob-pike-what-go-got-right-and-wrong%2F" target="_blank">指出</a>，Go 是專門為併發和並行性而設計的，在處理大規模工作負載的同時利用了新的多核芯片的強大功能。但他們也將 Go 的成功歸功於其持續的「以開發為中心的理念」，以及其蓬勃發展的社區及其貢獻（包括新包）。</span></p><p><span style="color:#000000">在演講中 Pike 再次提到了這個主題表示，「我們最初的目標不是創造一種新的編程語言，而是創造一種編寫軟件的更好方法.....如果我當時不花 45 分鐘來構建二進制文件，Go 就不會出現。」</span></p><p><span style="color:#000000">簡而言之，Pike 指出，Go 是一種編程語言，但也不僅僅是一種編程語言。它的目的是幫助提供一種開發高質量軟件的更好方法。時至今日，這仍然是它的目標；Go 是一個讓生產軟件的開發更簡單、更高效的項目。</span></p><p><span style="color:#000000">出人意料的是，Pike 在例舉 Go 語言的成功之處時，首先提及的是吉祥物 (Go gopher )，並將之譽為 Go 成功的最早因素之一、對 Go 的發展至關重要。他認為，呆萌有趣辨識度高的吉祥物很好的團結了社區氛圍，為社區參與項目奠定了基調 —— 即卓越的技術與真正的樂趣相結合。</span></p><p><span style="color:#000000">但對於以 CC 許可發佈 Gopher 的設計，Pike 則坦言，這"也許不是最好的選擇"，如果再重來一次他們會慎重考慮。</span></p><p><span style="color:#000000"><img alt="" height="451" src="https://oscimg.oschina.net/oscnet/up-a004fea240880685504378aa24a754146e5.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">在提到 Go 語言發展過程中所做出的一些正確決策時，Pike 提到了：確保 Go 易於解析，此舉反過來又使得創建 IDE 等工具以及 Go 的官方語言服務器 gopls（也提供 IDE 功能）變得容易；以及為編譯器添加了自動測試和代碼審查工具。其他還包括：</span></p><ul><li><span style="color:#000000">gofmt 自動格式化工具</span></li><li><span style="color:#000000">Go 的軟件包庫</span></li><li><span style="color:#000000">發佈了 Go 語言的正式規範</span></li><li><span style="color:#000000">在早期就發佈了 Go 語言的兼容性保證，等等。</span></li></ul><p><span style="color:#000000">此外，Pike 還透露了一些他期待出現的功能，包括：允許使用任意精度的整數，他認為這將消除一整類安全隱患；以及希望看到編譯器對 Go 的動態接口進行更多自動檢查，並檢查資源共享可能導致的進度停滯死鎖。"任何能讓程序在編譯時更安全的東西都是好東西。"</span></p><p><span style="color:#000000">Pike 指出，Go 語言的另一個關鍵之處在於它的可移植性；也就是説，它可以輕鬆地為其他平台編譯代碼。這在一定程度上得益於 Ken Thompson 用 C 語言編寫的編譯器，儘管其他人認為編譯器應該用 Go 本身編寫（或使用 LLVM 中的工具）。Pike 也將該編譯器描述為「an odd duck」，但無論如何，他認為這對於當時的處境來説是一個正確的選擇。直到 2015 年，Russ Cox 編寫了一個工具，可以將編譯器從 C 半自動編譯為 Go。</span></p><p><span style="color:#000000">而有關 Go 最具影響力的決定 —— 「併發」。在分享這一故事時，Pike 首先描述了 2002 年自己剛加入 Google 時的世界。在他的記憶中，彼時的谷歌似乎一直在迴避進程線程的併發執行，甚至採取"幾乎完全禁止"的態度，這也讓他感到很苦惱。</span></p><p><span style="color:#000000">「自 20 世紀 70 年代以來，我一直在做類似併發的事情，甚至是在無意識的情況下」。事實上，除了 Pike 外，當時許多其他語言、論文甚至書籍都寫過關於併發編程的內容，並表明併發編程可以做得很好。只是當時的併發還沒有成為主流理念，Go 的誕生部分就是為瞭解決這個問題，而它最終也成為了 Go 最大的亮點之一。</span></p><p><span style="color:#000000">"</span><span><span style="color:#222222"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span><span>回顧過去，我認為可以公平地説，Go 在&nbsp;</span></span></span></span></span></span></span><span style="background-color:#ffffff"><span><span><span><span><span>讓編程世界相信併發是一個強大的工具（尤其是在多核網絡世界中）方面發揮了重要作用，並且它可以比 pthread 做得更好。如今，</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="color:#000000">大多數主流語言都對併發提供了良好的支持。但在當時，這讓 Go 看起來像是一種新事物......Go 對併發的支持是一個主要的吸引因素，它幫助增加了早期的採用率，吸引了那些之前沒有使用過併發但對其可能性很感興趣的程序員"。</span></p><p><span style="color:#000000">Pike 認為，這是一個絕對成功的舉措，Go"幫助普及了併發作為服務器軟件結構的一種方式"。</span></p><p><span style="color:#000000">最後，</span><span style="color:#000000">Pike 簡潔的總結了一些促使 Go 成功的因素，「最重要的是，我們得到了 Gophers 這個樂於助人、多元化社區的大力支持。」</span></p><p><span style="color:#000000"><img height="246" src="https://oscimg.oschina.net/oscnet/up-0480c7a61fc3b60e8358dbf35422313383c.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">更多詳情<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommandcenter.blogspot.com%2F2024%2F01%2Fwhat-we-got-right-what-we-got-wrong.html" target="_blank">可查看博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278027/golang-rob-pike-what-go-got-right-and-wrong</guid>
            <link>https://www.oschina.net/news/278027/golang-rob-pike-what-go-got-right-and-wrong</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國產數據庫管理工具 CloudDM v2.4.4 發佈，支持更多數據庫對象查看]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><p style="margin-left:0; margin-right:0"><span>CloudDM<span>&nbsp;</span></span><span style="color:#333333">是<span>&nbsp;</span></span><span>ClouGence</span><span style="color:#333333"><span>&nbsp;</span>公司推出的一款</span><strong><span>一站式多數據源開發管理工具</span></strong><span style="color:#333333">，使用它可以方便地訪問和管理<span>&nbsp;</span></span><span>MySQL、Oracle、PostgreSQL、阿里雲 RDS、Greenplum、TiDB、Redis、StarRocks、Doris、SelectDB、SQL SERVER、ClickHouse、OceanBase 、PolarDB-X 、IBM Db2 等多種不同類型的數據庫。通過 CloudDM 豐富的數據源支持可以避免在多個專業工具之間切換，從而提高工作效率。</span></p><p style="margin-left:0; margin-right:0"><span>它是本地化的應用程序，沒有後台進程。和<span>&nbsp;</span></span><strong><span>DataGrip</span></strong><span>、</span><strong><span>Navicat</span></strong><span><span>&nbsp;</span>一樣在安裝完成後，只需要雙擊應用程序圖標，便可以方便的管理位於本地計算機或遠程計算機上的數據庫。已經支持<span>&nbsp;</span></span><strong><span>Windows</span></strong><span>、</span><strong><span>MacOS</span></strong><span><span>&nbsp;</span>和<span>&nbsp;</span></span><strong><span>Linux</span></strong><span><span>&nbsp;</span>主流操作系統。</span></p></div></div><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><img src="https://oscimg.oschina.net/oscnet/up-c0a92ca7654a775e970ab24569abe3fe44d.png" referrerpolicy="no-referrer"></p><div><div><h2><span>更新內容</span></h2><div><ul><li><span>[新增]</span><ul><li><span>針對 MySQL 數據源在數據庫對象視圖中可以看到，存儲過程、觸發器、視圖、函數</span></li><li><span>針對 Oracle&nbsp;數據源在數據庫對象視圖中可以看到，存儲過程、觸發器、視圖、函數、</span>序列、物化視圖</li><li>針對 <span>PostgreSQL&nbsp;</span>數據源在數據庫對象視圖中可以看到，存儲過程、觸發器、視圖、函數<span>、</span>序列、物化視圖</li><li>針對 <span>Oceanbase&nbsp;</span>數據源在數據庫對象視圖中可以看到，存儲過程、觸發器、視圖、函數</li><li>針對 <span>SQL SERVER</span><span>&nbsp;數據源在數據庫對象視圖中可以看到，存儲過程、觸發器、視圖、函數</span><span>、</span>序列</li></ul></li><li><span style="color:#333333">[優化]</span><ul><li>優化，移除 TiDB 數據庫不兼容的數據庫對象，詳情請參照 TiDB 官方文檔 v7.5</li></ul></li><li><span style="color:#333333">[修復]</span><ul><li><p>修復，內置用户出現多條記錄而導致的報錯問題</p></li><li><p>修復 Oracle 數據庫查看普通表時連同物化視圖一起獲取的問題</p></li><li><p>修復 Oracle 數據庫訪問部分 Schema 時，由於使用權限需求過高的語句，而出現表或視圖不存在報錯的問題</p></li></ul></li></ul></div></div><h2><span>下載與反饋</span></h2><ul><li><span>產品官網：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.clougence.com%2Fclouddm-personal" target="_blank"><span>https://www.clougence.com/clouddm-personal</span></a></li><li><span>問題反饋：</span><a href="https://gitee.com/clougence/clouddm-issue/issues" target="_blank"><span>https://gitee.com/clougence/clouddm-issue/issues</span></a></li><li>Release Node：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.clougence.com%2Fdmp-doc%2Freleaseinfo%2Fdesktop_2_4_2" target="_blank">https://www.clougence.com/dmp-doc/releaseinfo/desktop_2_4_2</a></li><li><span style="color:#333333">微信交流羣：訪問產品官網，掃描右側二維碼即可加入</span></li></ul></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 07:00:11 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/278017/clouddm-2-4-4</guid>
            <link>https://www.oschina.net/news/278017/clouddm-2-4-4</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源 - 奮進者的盛宴 | Apache StreamPark in 2023]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ed43d3f9ec4da28ec68103abf6c2af05c00.png" referrerpolicy="no-referrer"></p><p>時間的指針已跨過 2023，對於 Apache StreamPark 社區而言，這是一個值得書寫回顧的時刻。Apache StreamPark 從最初的個人項目到加入全球最大的開源軟件基金會（Apache Software Foundation），一路走來我們始終相信堅持和協作的力量，相信社區的力量。開源，不是天才的甜點，而是奮進者的盛宴。此時此刻，讓我們一起回顧 Apache StreamPark 社區過去一年的精彩時刻。</p><span id="OSC_h1_1"></span><h1>社區向好發展</h1><p>在過去一年，Apache StreamPark 一直在積極地建設社區，大力地培養開發者，遵循 Apache 軟件基金會的「Community over Code」原則來運營社區，以開放包容、自由平等的態度對待每位參與者，在 2023 年社區有許多值得被分享的事情：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-549cf545062bc87773f5f663f719934c10a.png" referrerpolicy="no-referrer"></p><ul><li><p>全年發佈了&nbsp;<strong>2.0.0 -&nbsp;2.1.2</strong>&nbsp;共&nbsp;**<code>4</code>**個 Apache 版本。</p></li><li><p>社區參加了 2023 年 8 月「Community over Code」ASIA 大會，帶來**<code>3</code>**場 Apache StreamPark 相關的主題分享。</p></li><li><p>投票推選了&nbsp;<strong><code>2</code></strong>&nbsp;位&nbsp;PPMC Member&nbsp;和**<code>5</code>**位新晉 Committer，分別是：Chunjin Mu、Sizhu Wang、Li Zhou、Zhongqiang Gong、Yuepeng Pan、Cancai Cai、Chao Zhang，恭喜他們，感謝他們為 Apache StreamPark 所做的貢獻。</p></li><li><p>重新制作上線了官網，整理上線了 <strong><code>8</code></strong>&nbsp; 篇生產實踐的文章。</p></li><li><p>項目 Star 新增 <strong><code>800+</code></strong>，累積 <strong><code>3.5k</code></strong>&nbsp;, 項目 fork 累積 <strong><code>900+</code></strong>。</p></li><li><p>貢獻者總數達到&nbsp;<strong><code>130+</code></strong>&nbsp;&nbsp;相比 2022 年新增了&nbsp;<strong><code>40+</code></strong>。</p></li><li><p>共計 <strong><code>59</code></strong> 位開發者提交了超過 <strong><code>550</code></strong> 個 commit。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bd5f43f528488dde6a0b7be9e8847ef2234.png" referrerpolicy="no-referrer"></p><p>2023 年 9 月 1 日，是 Apache StreamPark 孵化整整一週年的日子，在這個值得紀唸的日子裏，我們特此剪輯了一個短片，回顧 Apache StreamPark 的發展歷程：</p><p><iframe frameborder="no" height="400px" scrolling="no" src="https://player.bilibili.com/player.html?aid=275553707&amp;bvid=BV1aF41167pF&amp;cid=1255969269&amp;p=1" width="720px" referrerpolicy="no-referrer"></iframe></p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>項目關鍵進展</h1><p>2023 年 Apache StreamPark&nbsp;在開發新功能的同時，對項目的穩定性持續打磨，在對 Apache Flink 的基礎能力支持上日益成熟，以下是項目的關鍵進展:</p><ol><li><strong>更好的 Flink 支持</strong>：在 Flink 作業的部署模式和版本支持上都做大量改進，開發管理 Flink 作業更加的簡單絲滑。重構了 Flink on K8s 作業部署和狀態監控，整體穩定性達到生產可用級別，並經過用户 500+&nbsp;生產環境作業的驗證。</li><li><strong>新功能持續更新</strong>：項目在功能上持續更新，新增了團隊管理、LDAP 登錄、變量等深受歡迎的企業級特性和能力，更貼合企業的使用。基於 Vue3 重構了項目前端，顯著提升了項目的可讀性、可維護性，前端的構建和啓動速度提升了 5~10&nbsp;倍。</li><li><strong>產品越發成熟</strong>：這一年我們發佈了三個改進 &amp; Bug 修復版本，在此過程中我們收集了大量的用户反饋，項目從前端到後台，不論是作業的開發部署，還是狀態管理，使用體驗...方方面面都做了大量改進，產品綜合表現越發成熟穩定。</li><li><strong>支持生態項目:</strong> &nbsp;無縫地支持對接 Apache Doris、Paimon 等數據集成作業。</li><li><strong>安全性 &amp; 合規性</strong>：作為孵化中的項目，項目合規是重要的一環，我們排查解決了項目中存在漏洞的依賴，修復了項目自身的漏洞，4 次發版通過 Apache 的檢查，項目合規性得到有效保證。</li></ol><span id="OSC_h1_3"></span><h1><strong>用户持續增長</strong></h1><p>在 2023 年，我們迎來了越來越多的用户，公開收集的登記使用用户新增 24 位。目前如，百度、騰訊、聯通、天翼雲、自如、圓通、網易智企、同程數科、長安汽車、馬蜂窩，等一二線大廠都在使用，其他使用或者基於 Apache StreamPark 二次開發的公司更是不計其數。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-60000a0362483b96361b6cadac51b0d8ebb.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_4"></span><h1><strong>榮獲多項殊榮</strong></h1><p>在 2023 年，Apache StreamPark 社區獲得了多項榮譽。Apache StreamPark&nbsp;作為一個年輕的開源項目，能在多個評選中獲得各個不同主辦方對項目的認可並被授予表彰，不僅證明瞭項目的價值，更提高了項目的知名度，這是對我們多年來堅持不懈努力的嘉許。這些獎項不僅肯定了我們才華橫溢的貢獻者，更見證了開源社區的繁榮與創新。感謝各個主辦方，感謝我們的導師和所有的貢獻者們。讓我們牢記這份珍貴的榮譽，我們將繼續努力，爭取更好的成績。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e30c75b0c6a7af48c7d9547919e21a28e1a.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_5"></span><h1>持續分享輸出</h1><p>2023 Apache StreamPark 社區在技術分享上持續輸出，在&nbsp;2023 年 8 月「Community over Code」ASIA 大會，帶來&nbsp;<strong><code>3</code></strong> 場 Apache StreamPark 相關的主題分享。此外產生了來自 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247553003%26idx%3D1%26sn%3D0b5647ba233dd7fdb3f86c6365366503%26chksm%3Dc04d717ff73af869c31ec1db46beb48c9a36ede1dbe525c4660862e55a77d584de5ffa440624%26scene%3D21%23wechat_redirect" target="_blank">自如</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247547381%26idx%3D1%26sn%3D071f941543a2b9539d14f5d51275d9bd%26chksm%3Dc04d4761f73ace77c9bd3d07284ea506173dcd7722c0d75a6827c3f9f63391adf1735840a841%26scene%3D21%23wechat_redirect" target="_blank">、</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247547381%26idx%3D1%26sn%3D071f941543a2b9539d14f5d51275d9bd%26chksm%3Dc04d4761f73ace77c9bd3d07284ea506173dcd7722c0d75a6827c3f9f63391adf1735840a841%26scene%3D21%23wechat_redirect" target="_blank">順網科技</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247544817%26idx%3D1%26sn%3Dca8a8978254e5e38042ad729766e67e8%26chksm%3Dc04d5165f73ad873f836d114fb3b16a4877ce19182d11043ebfd759f1ef5f73c34e71b4aa2ef%26scene%3D21%23wechat_redirect" target="_blank">、</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247544817%26idx%3D1%26sn%3Dca8a8978254e5e38042ad729766e67e8%26chksm%3Dc04d5165f73ad873f836d114fb3b16a4877ce19182d11043ebfd759f1ef5f73c34e71b4aa2ef%26scene%3D21%23wechat_redirect" target="_blank">海程邦達&nbsp;等企業的</a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5OTcwNTg1MQ%3D%3D%26mid%3D2247544817%26idx%3D1%26sn%3Dca8a8978254e5e38042ad729766e67e8%26chksm%3Dc04d5165f73ad873f836d114fb3b16a4877ce19182d11043ebfd759f1ef5f73c34e71b4aa2ef%26scene%3D21%23wechat_redirect" target="_blank">多篇</a> 生產實踐文章，並且生產了數十個原創視頻，在各個渠道累計播放量 <strong><code>20W+</code></strong> &nbsp;。在此非常感謝各合作社區的關照和傳播，正是各個合作社區夥伴們的幫襯和關照才能使得 Apache StreamPark 項目的影響力不斷上升。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-99395c3375f020ad6ffa87b072eafe03929.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><span id="OSC_h1_6"></span><h1><strong>展，望 2024</strong></h1><p>如果用一個詞概括總結 Apache StreamPark 的 2023, 我想就是: 奮進，持志如心痛，我們始終以奮進的姿態推動項目發展，為用户的使用落地保駕護航。停留片刻，歲月扉頁已翻到 2024，2024 Apache&nbsp;StreamPark 有哪些期待呢？<br> Apache StremaPark 最初的想法就是簡化 Flink | Spark 的開發和管理，讓流處理更簡單，因此會繼續加大，對 Flink 的支持力度，包括不限於支持 PyFlink，探索 Sql-gateway 等交互式方面的體驗，繼續完善底層基礎建設，改進 Flink on K8S 的基礎能力，加強完善&nbsp;SLA&nbsp;的方面的保障體系，和生態項目共同建設發展，更好的支持和集成 Apache Paimon/Doris 和 Flink CDC 等生態項目。 Apache&nbsp;StreamPark 從來都不是一個獨立的平台，也並非綁定在某個流計算引擎之上，因此，在 2024 年社區會發起討論，啓動對 Apache Spark 的支持，包括不限於開發框架和作業管控平台，使其真正做到讓流處理更簡單，成為流處理開發管理和實時計算平台事實上的最佳選擇。</p><span id="OSC_h1_7"></span><h1>加入我們</h1><p>Apache&nbsp;StreamPark 是一個流處理應用程序開發管理框架。旨在輕鬆構建和管理流處理應用程序，提供使用 Apache Flink 和 Apache Spark 編寫流處理應用程序的開發框架。同時 Apache&nbsp;StreamPark 提供了一個流處理應用管理平台，核心能力包括但不限於應用開發、調試、交互查詢、部署、運維、實時數倉等，最初開源時項目名稱叫 StreamX ，於 2022 年 8 月更名為 StreamPark，隨後通過投票正式成為 Apache 軟件基金會的孵化項目。目前已有騰訊、百度、聯通、天翼雲、自如、馬蜂窩、同程數科、長安汽車、大健雲倉等眾多公司在生產環境使用。</p><p>Apache StreamPark 社區一直以來都以用心做好一個項目為原則，高度關注項目質量，努力建設發展社區。加入 Apache 孵化器以來，認真學習和遵循「The Apache Way」，我們將秉承更加兼容幷包的心態，迎接更多的機遇與挑戰。誠摯歡迎更多的貢獻者參與到社區建設中來，和我們一道攜手共建。</p><p><strong>💻 項目地址：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark" target="_blank">https://github.com/apache/streampark</a><br><strong>🧐 提交問題和建議：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fissues" target="_blank">https://github.com/apache/streampark/issues</a><br><strong>🥁 貢獻代碼：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fpulls" target="_blank">https://github.com/apache/streampark/pulls</a><br><strong><strong>📮&nbsp;<strong>Proposal：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FINCUBATOR%2FStreamPark%2BProposal" target="_blank">https://cwiki.apache.org/confluence/display/INCUBATOR/StreamPark+Proposal</a><br> 📧 訂閲社區開發郵件列表：dev@streampark.apache.org<br> 💁‍♀️</strong></strong>社區溝通：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-463ce49840586bf1b6c38042bd20495d7ba.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 06:19:16 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/streampark/blog/11027473</guid>
            <link>https://my.oschina.net/streampark/blog/11027473</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報：「小而美」 Tauri 已支持 Android 和 iOS；蘋果開源 Pkl]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><p><strong># 2024.2.5</strong></p><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要點</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/277597/vuejs-10yr" target="_blank">Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Tauri v2 首個 Beta 已發佈，新版本添加了<strong>對移動端（iOS 和 Android）的支持</strong>。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a84ea1fdc7a280dc620420b12cee4e8bf63.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">公告<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbeta.tauri.app%2Fblog%2Ftauri-2-0-0-beta%2F" target="_blank">寫道</a></u>：「Tauri v2 是支持跨平台開發的一個重大里程碑，開發桌面和移動應用程序從未如此簡單。你可以將現有的桌面程序無縫遷移到移動設備，並獲得原生 API 和 Tauri CLI 的出色開發者體驗。」</p><h3><u><a href="https://www.oschina.net/news/277816/apple-pkl-lang" target="_blank">蘋果開源 Pkl —— 用於生成配置的編程語言</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">蘋果發佈了專用於創建配置文件的腳本編程語言&nbsp;Pkl（發音為 Pickle）。Pkl 團隊<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpkl-lang.org%2Fblog%2Fintroducing-pkl.html" target="_blank">介紹稱</a></u>，該項目旨在應對 JSON、YAML 和屬性列表等靜態配置格式的不足，提供一種介於靜態語言和通用語言之間、「兩全其美」的方案。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Pkl 的三個設計目標是語法安全、可擴展和 IDE 集成，使用聲明式語法、易讀易寫，但也支持類、函數、條件和循環等常見的編程語言功能。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>示例代碼</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">bird.pkl</p><pre style="margin-left:0; margin-right:0; text-align:left"><code class="language-json"><span style="color:#6f42c1">name</span> = <span style="color:#032f62">"Swallow"</span><span style="color:#6f42c1">job</span><span style="color:#032f62">{</span><span style="color:#6f42c1">title</span> = <span style="color:#032f62">"Sr. Nest Maker"</span><span style="color:#6f42c1">company</span> = <span style="color:#032f62">"Nests R Us"</span><span style="color:#6f42c1">yearsOfExperience</span> = <span style="color:#032f62">2</span><span style="color:#6f42c1">}</span></code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">↓</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">bird.json</p><pre style="margin-left:0; margin-right:0; text-align:left"><code class="language-json">{
  <span style="color:#6f42c1">"name"</span>: <span style="color:#032f62">"Swallow"</span>,
  <span style="color:#6f42c1">"job"</span>: {
    <span style="color:#6f42c1">"title"</span>: <span style="color:#032f62">"Sr. Nest Maker"</span>,
    <span style="color:#6f42c1">"company"</span>: <span style="color:#032f62">"Nests R Us"</span>,
    <span style="color:#6f42c1">"yearsOfExperience"</span>: <span>2</span>
  }
}</code></pre><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推薦</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-41e1b46b27f9899b2f2893d8ed2b70534e9.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">開源之聲</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-e3a4add7186ca1ff7c533ae75453c1ebc93.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日項目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜單：</p><p><img src="https://oscimg.oschina.net/oscnet/up-a1f42bf84d0c31d454864b491f232d5f371.png" referrerpolicy="no-referrer"></p><hr><p><strong>往期回顧</strong></p><ul><li><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf" target="_blank">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></u></li><li><u><a href="https://www.oschina.net/news/277585" target="_blank">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></u></li><li><u><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 06 Feb 2024 04:49:20 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277997</guid>
            <link>https://www.oschina.net/news/277997</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Anolis OS 獲 Gitee 最有價值開源項目稱號]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="text-align: justify;margin-left: 8px;margin-right: 8px;margin-bottom: 8px;line-height: 1.75em;" data-mpa-powered-by="yiban.io"><ne-clipboard source="https%3A%2F%2Faliyuque.antfin.com%2Fhd01475069%2Fnzgfgg%2Fczegeetz123okfva%3FsingleDoc%23"></ne-clipboard></section><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 24px;"><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">近日，龍蜥操作系統 Anolis OS 獲得 Gitee 認可，在眾多開源項目中脱穎而出，榮獲 GVP（ Gitee Most Valuable Project，即最有價值開源項目）稱號。</span></p><article data-identifier-application__slash__x-doc-key="ABmOor4xydxWqawZ"><article data-clipboard-cangjie="[&quot;root&quot;,{},[&quot;p&quot;,{&quot;uuid&quot;:&quot;lrezcm8lam8s8sce36&quot;,&quot;jc&quot;:&quot;center&quot;},[&quot;img&quot;,{&quot;src&quot;:&quot;https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOor4rBQ3yqawZ/img/923b311f-c690-47e0-968b-cf7192fd62ea.jpg&quot;,&quot;width&quot;:341,&quot;height&quot;:455,&quot;opacity&quot;:1,&quot;uuid&quot;:&quot;ls2t7an6bcla5vee0pa&quot;,&quot;extraData&quot;:{&quot;resourceId&quot;:&quot;923b311f-c690-47e0-968b-cf7192fd62ea&quot;,&quot;metaData&quot;:{&quot;size&quot;:2830050,&quot;originWidth&quot;:3024,&quot;originHeight&quot;:4032,&quot;format&quot;:&quot;jpg&quot;,&quot;ratio&quot;:1}},&quot;rotation&quot;:0},[&quot;span&quot;,{&quot;data-type&quot;:&quot;text&quot;},[&quot;span&quot;,{&quot;data-type&quot;:&quot;leaf&quot;},&quot;&quot;]]]]]" data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnV1aWQlMjIlM0ElMjJscmV6Y204bGFtOHM4c2NlMzYlMjIlMkMlMjJqYyUyMiUzQSUyMmNlbnRlciUyMiU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJpbmxpbmUlMjIlMkMlMjJ0eXBlJTIyJTNBJTIyaW1hZ2UlMjIlMkMlMjJkYXRhJTIyJTNBJTdCJTIyc3JjJTIyJTNBJTIyaHR0cHMlM0ElMkYlMkZhbGlkb2NzLm9zcy1jbi16aGFuZ2ppYWtvdS5hbGl5dW5jcy5jb20lMkZyZXMlMkZBQm1Pb3I0ckJRM3lxYXdaJTJGaW1nJTJGOTIzYjMxMWYtYzY5MC00N2UwLTk2OGItY2Y3MTkyZmQ2MmVhLmpwZyUyMiUyQyUyMndpZHRoJTIyJTNBMzQxJTJDJTIyaGVpZ2h0JTIyJTNBNDU1JTJDJTIyb3BhY2l0eSUyMiUzQTElMkMlMjJ1dWlkJTIyJTNBJTIybHMydDdhbjZiY2xhNXZlZTBwYSUyMiUyQyUyMmV4dHJhRGF0YSUyMiUzQSU3QiUyMnJlc291cmNlSWQlMjIlM0ElMjI5MjNiMzExZi1jNjkwLTQ3ZTAtOTY4Yi1jZjcxOTJmZDYyZWElMjIlMkMlMjJtZXRhRGF0YSUyMiUzQSU3QiUyMnNpemUlMjIlM0EyODMwMDUwJTJDJTIyb3JpZ2luV2lkdGglMjIlM0EzMDI0JTJDJTIyb3JpZ2luSGVpZ2h0JTIyJTNBNDAzMiUyQyUyMmZvcm1hdCUyMiUzQSUyMmpwZyUyMiUyQyUyMnJhdGlvJTIyJTNBMSU3RCU3RCUyQyUyMnJvdGF0aW9uJTIyJTNBMCU3RCUyQyUyMm5vZGVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJ0ZXh0JTIyJTJDJTIybGVhdmVzJTIyJTNBJTVCJTdCJTIya2xhc3MlMjIlM0ElMjJsZWFmJTIyJTJDJTIydGV4dCUyMiUzQSUyMiUyMiUyQyUyMm1hcmtzJTIyJTNBJTVCJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTdEJTVEJTdE" data-identifier-application__slash__x-doc-key="ABmOor4xydxWqawZ"><article data-clipboard-cangjie="[&quot;root&quot;,{},[&quot;p&quot;,{&quot;uuid&quot;:&quot;ls2w8i6r6ruyj6gisz9&quot;,&quot;jc&quot;:&quot;justify&quot;},[&quot;img&quot;,{&quot;id&quot;:&quot;uip7mi&quot;,&quot;name&quot;:&quot;bf5edbe747ed2378318be806f1952707.jpeg&quot;,&quot;size&quot;:1934061,&quot;width&quot;:748,&quot;height&quot;:561,&quot;uuid&quot;:&quot;ls2xnew0h5jwcuopd9o&quot;,&quot;src&quot;:&quot;https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOor4xydxWqawZ/img/c54a56e0-b42d-4fea-aff1-df1f042076f8.jpeg&quot;,&quot;extraData&quot;:{&quot;resourceId&quot;:&quot;c50ad89f-46e1-40f0-98b6-79ee3aa06e8d&quot;,&quot;metaData&quot;:{&quot;size&quot;:1934061,&quot;originWidth&quot;:3648,&quot;originHeight&quot;:2736,&quot;format&quot;:&quot;jpg&quot;,&quot;ratio&quot;:0}}},[&quot;span&quot;,{&quot;data-type&quot;:&quot;text&quot;},[&quot;span&quot;,{&quot;data-type&quot;:&quot;leaf&quot;},&quot;&quot;]]]]]" data-identifier-application__slash__x-cangjie-fragment="JTdCJTIya2xhc3MlMjIlM0ElMjJkb2N1bWVudCUyMiUyQyUyMmRhdGElMjIlM0ElN0IlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIyYmxvY2slMjIlMkMlMjJ0eXBlJTIyJTNBJTIycGFyYWdyYXBoJTIyJTJDJTIyZGF0YSUyMiUzQSU3QiUyMnV1aWQlMjIlM0ElMjJsczJ3OGk2cjZydXlqNmdpc3o5JTIyJTJDJTIyamMlMjIlM0ElMjJqdXN0aWZ5JTIyJTdEJTJDJTIybm9kZXMlMjIlM0ElNUIlN0IlMjJrbGFzcyUyMiUzQSUyMmlubGluZSUyMiUyQyUyMnR5cGUlMjIlM0ElMjJpbWFnZSUyMiUyQyUyMmRhdGElMjIlM0ElN0IlMjJpZCUyMiUzQSUyMnVpcDdtaSUyMiUyQyUyMm5hbWUlMjIlM0ElMjJiZjVlZGJlNzQ3ZWQyMzc4MzE4YmU4MDZmMTk1MjcwNy5qcGVnJTIyJTJDJTIyc2l6ZSUyMiUzQTE5MzQwNjElMkMlMjJ3aWR0aCUyMiUzQTc0OCUyQyUyMmhlaWdodCUyMiUzQTU2MSUyQyUyMnV1aWQlMjIlM0ElMjJsczJ4bmV3MGg1andjdW9wZDlvJTIyJTJDJTIyc3JjJTIyJTNBJTIyaHR0cHMlM0ElMkYlMkZhbGlkb2NzLm9zcy1jbi16aGFuZ2ppYWtvdS5hbGl5dW5jcy5jb20lMkZyZXMlMkZBQm1Pb3I0eHlkeFdxYXdaJTJGaW1nJTJGYzU0YTU2ZTAtYjQyZC00ZmVhLWFmZjEtZGYxZjA0MjA3NmY4LmpwZWclMjIlMkMlMjJleHRyYURhdGElMjIlM0ElN0IlMjJyZXNvdXJjZUlkJTIyJTNBJTIyYzUwYWQ4OWYtNDZlMS00MGYwLTk4YjYtNzllZTNhYTA2ZThkJTIyJTJDJTIybWV0YURhdGElMjIlM0ElN0IlMjJzaXplJTIyJTNBMTkzNDA2MSUyQyUyMm9yaWdpbldpZHRoJTIyJTNBMzY0OCUyQyUyMm9yaWdpbkhlaWdodCUyMiUzQTI3MzYlMkMlMjJmb3JtYXQlMjIlM0ElMjJqcGclMjIlMkMlMjJyYXRpbyUyMiUzQTAlN0QlN0QlN0QlMkMlMjJub2RlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIydGV4dCUyMiUyQyUyMmxlYXZlcyUyMiUzQSU1QiU3QiUyMmtsYXNzJTIyJTNBJTIybGVhZiUyMiUyQyUyMnRleHQlMjIlM0ElMjIlMjIlMkMlMjJtYXJrcyUyMiUzQSU1QiU1RCU3RCU1RCU3RCU1RCU3RCU1RCU3RCU1RCU3RA==" data-identifier-application__slash__x-doc-key="ABmOor4xydxWqawZ"><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-backh="434" data-backw="578" data-imgfileid="100038991" data-ratio="0.75" src="https://oscimg.oschina.net/oscnet/f0a958d9-c9d1-4b5e-a125-a1badd9c34d6.jpg" data-type="jpeg" data-w="1080" style="width: 100%;height: auto;" referrerpolicy="no-referrer"></p></article></article><p style="text-align: center;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 16px;"><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">（圖</span><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">/&nbsp;Gitee&nbsp;最有價值開源項目獎</span><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">牌</span><span style="color: rgb(136, 136, 136);font-family: Arial, Helvetica, sans-serif;font-size: 14px;letter-spacing: 0.2px;text-align: start;">）</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 16px;"><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">Gitee 是全球規模第二大的代碼託管平台，為超過 500&nbsp;萬名開發者和 10&nbsp;萬家企業提供服務，該平台託管的開源項目超過 1000&nbsp;萬，匯聚了眾多國內知名的優秀開源項目，是國內首屈一指的代碼託管平台。</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">GVP 是 Gitee 綜合評定的優秀開源項目展示平台，其評選</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">既要獲得開發者廣泛認可、滿足客觀硬性指標，也要通過評委會專家的共同評定才可入選。</span></p><p style="text-align: justify;margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 16px;"><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">龍蜥社區（OpenAnolis）是立足中國面向國際的 Linux 服務器操作系統開源根社區，引領雲智融合技術浪潮下國產操作系統的創新發展。</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">龍蜥操作系統 Anolis OS 搭載了 ANCK 版本的內核，性能和穩定性經過歷年「雙 11」歷練，能為雲上典型用户場景帶來 40%&nbsp;的綜合性能提升，故障率降低 50%，兼容 CentOS 生態，提供平滑的 CentOS 遷移方案，並提供全棧國密能力。</span><span style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">龍蜥社區圍繞芯片、內核、編譯器、安全、虛擬化及雲原生等操作系統核心領域進行技術創新，已發佈首款擁抱智算時代的<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MTMyMTUwMQ%3D%3D%26mid%3D2247516403%26idx%3D1%26sn%3D0a18dcbe8891f369111d1e6deae3804b%26chksm%3Dcf657381f812fa97e04d6f05257b62da1880ef327a4b10372b4b89cb5882b90d9ceb751a0d6b%26scene%3D21%23wechat_redirect" textvalue="國產操作系統 Anolis OS 23" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">國產操作系統 Anolis OS 23</a>、 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MTMyMTUwMQ%3D%3D%26mid%3D2247491504%26idx%3D1%26sn%3Dea85642b4e5891ef3dee243a4bbf8628%26chksm%3Dcf66ecc2f81165d4f652c5538771320030ac4ff3f511bbeb278561301bed339e7e43bf627d3b%26scene%3D21%23wechat_redirect" textvalue="LoongArch GA" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">LoongArch GA</a>、Anolis OS 7.9、 8.4 、8.6、8.8 等多個社區版本，超萬名開發者參與貢獻。</span></p></article><section style="margin-right: 8px;margin-bottom: 16px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.75em;text-align: center;"><span style="outline: 0px;font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;color: rgb(136, 136, 136);">—— 完 ——</span></section><section style="margin-right: 8px;margin-bottom: 16px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.75em;"><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">Alib</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">aba Cloud Lin</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">ux 誠邀廣大企業用</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">户加入，首批招募 30 傢伙伴單位，一起共建雲</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">上軟件生</span><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;">態繁榮！</span></section><section style="margin-right: 8px;margin-bottom: 16px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);line-height: 1.75em;"><span style="outline: 0px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 15px;letter-spacing: 0.2px;text-align: start;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MTMyMTUwMQ%3D%3D%26mid%3D2247520955%26idx%3D1%26sn%3D7a02bf5e9ea85f2af75d19d0bee04120%26chksm%3Dcf6561c9f812e8df7dd7d4d5da9b4b3d6ffa8f89111a5b8c35bfe2295ee5420ff02280183356%26scene%3D21%23wechat_redirect" textvalue="你已選中了添加鏈接的內容" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="1"><span class="js_jump_icon h5_image_link" style="outline: 0px;vertical-align: bottom;user-select: none;width: 100%;"><img class="rich_pages wxw-img" data-backh="250" data-backw="562" data-imgfileid="100038588" data-ratio="0.4444444444444444" src="https://oscimg.oschina.net/oscnet/a899e876-a6bd-473a-b20a-3e5ee6535362.jpg" data-w="900" style="outline: 0px;border-width: 0px;border-style: initial;border-color: initial;border-radius: 18px;width: 100%;visibility: visible !important;height: auto;" referrerpolicy="no-referrer"></span></a></span></section><section style="display: none;line-height: 1.75em;"><br></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - OpenAnolis 龍蜥（OpenAnolis）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 11:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5265430/blog/11030226</guid>
            <link>https://my.oschina.net/u/5265430/blog/11030226</link>
            <author>
                <![CDATA[OpenAnolis 龍蜥社區]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[用 AI 大模型在線寫春聯]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/2720166_2331677">用 AI 大模型在線寫春聯，歡迎來玩</a><div class="ui red label horizontal" data-tooltip="置頂">頂</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/hardbone" class="__user"><span>局</span></a> 發佈於，今天 16:33
                    </div><div class="item">閲讀 78</div><div class="item collect-btn " data-id="2331677" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331677" data-obj-type="2">0</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/2720166_2331677#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">0</span></a></div></div><div class="content" id="articleContent"><p>體驗地址：</p><h4><u><em><strong><a href="https://tool.oschina.net/ai_couplet" target="_blank" rel="nofollow">https://tool.oschina.net/ai_couplet</a></strong></em></u></h4><p>對聯成品：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f31a898dac4327a0da89726e61fbecde959.png" referrerpolicy="no-referrer"></p><p>使用方法：</p><p>在輸入框寫提示詞，點擊「生成春聯」即可。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0e8f04687bd6129ce3854330412d0c2ddf2.png" referrerpolicy="no-referrer"></p></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331677" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331677" data-obj-type="2">0</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331677" data-obj-type="2" data-url="https://www.oschina.net/question/2720166_2331677"><i class="flag red icon"></i>舉報</a></div></div>
            ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 11:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/2720166_2331677</guid>
            <link>https://www.oschina.net/question/2720166_2331677</link>
        </item>
        <item>
            <title>
                <![CDATA[PostgreSQL 90% 的新代碼僅由 50 人完成，拓數派榮佔一席]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>PostgreSQL 作為世界上最受歡迎的開源數據庫之一，於去年榮獲&nbsp;DB-Engines 2023 年度數據庫，其全球 Committer 人數卻長期維持在較少的數目（約 30 人），全球 Contributor 名單也罕見中國人身影。<strong>拓數派長期以來一直以強大的技術能力，用高質量、高數量的代碼貢獻力參與到 PostgreSQL 社區的產品和生態建設中。</strong></p><p>EnterpriseDB 首席數據庫科學家 Robert Haas 是 PostgreSQL 主要貢獻者，自 2009 年開始就作為 PostgreSQL Committer 參與到 PostgreSQL 的代碼 commit、review 和 merge 工作中。自 2017 年起，Robert&nbsp;已經連續 8 年持續統計 PostgreSQL 的貢獻者情況，並在其於 1 月 29 日發佈的《Who Contributed to PostgreSQL Development in 2023》博文中提到：</p><blockquote><p><strong>「2023 年，PostgreSQL 66% 的新代碼是由其中的 18 人貢獻的，而 90% 的新代碼貢獻是由 50 人完成的。」</strong></p></blockquote><p>這 50 位主要貢獻者中，僅有 2 名中國人，<strong>拓數派技術專家 Richard Guo 便是其中之一，這已經是 Richard 榮登該榜單的第二年。</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e337e187374f776c9e8c21e63805794e579.png" referrerpolicy="no-referrer"></p><p style="text-align:center">拓數派&nbsp;Richard&nbsp;Guo&nbsp;連續兩年被列為&nbsp;PostgreSQL&nbsp;主要貢獻者</p><p>在 Robert 的統計中，2023 年，Richard 為 PostgreSQL 貢獻了 1710 行代碼，提交了 40 個 Commits，在名單中排名 25 名。2022 年的統計中，Richard 同樣榮登代碼主要貢獻榜單，以 1071 行代碼，24 個 Commits，在 40 名主要代碼貢獻者中排名 38 名。</p><p>由於 Robert 的統計數據僅包括 Commits 所涉及的第一作者（Principle Author），Richard 的貢獻量遠不止這些。<strong>經統計，Richard 在 PostgreSQL 16 版本中參與的 Commits 數為 118。</strong></p><p>除了 Richard，拓數派多位研發同事均對 PostgreSQL 多個版本做出了代碼貢獻，尤其是在 PostgreSQL 16 發佈中，共有 33 名貢獻者來自中國，<strong>而拓數派佔據其中 5 席，並以接近一半的 Commits 次數在國內獨佔鰲頭</strong>。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-161a9945b89959aba9dd3b332765f0873e3.png" referrerpolicy="no-referrer"></p><p style="text-align:center">PostgreSQL 16&nbsp;中拓數派貢獻量在國內獨佔鰲頭</p><p>不管是代碼貢獻質量，或是數量上，拓數派團隊一如既往的引領 PostgreSQL 中國貢獻力。<strong>這一成績充分説明瞭拓數派團隊的技術實力與擁抱開放的企業文化。</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-62da53dc8790271b70bb5370ee426da3059.png" referrerpolicy="no-referrer"></p><p style="text-align:center">拓數派獲得的 PostgreSQL 社區代碼貢獻致謝獎章</p><p>除了 PostgreSQL 社區,拓數派團隊還一直以代碼貢獻、講師佈道等多種形式活躍於 PostgreSQL、Clickhouse、Kubernetes、Spark 等開源社區，<strong>並利用長期積累的技術能力為雲原生虛擬數倉 PieCloudDB 「添磚加瓦」</strong> ，為用户帶來更靈活、更安全、更易用的使用體驗和性能特性。未來，拓數派團隊將繼續努力，在技術之路上不斷創新，引領行業前行。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 09:42:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277896</guid>
            <link>https://www.oschina.net/news/277896</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[深圳開放智算中心點亮運營]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">昨日，深圳開放智算中心點亮運營，同期深圳市智慧城市算力統籌調度平台揭牌，這意味着深圳正加快打造 10 萬卡級別的超強算力集羣。多家人工智能頭部企業、電信運營商、行業協會在現場與運營方深智城集團簽約開展智能算力合作。</span></p><p><img height="333" src="https://oscimg.oschina.net/oscnet/up-1a3542f35ffad419079830641f01c95149c.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">該「中心+平台」的算力供給調度規模將超 30000P，深圳開放智算中心基於國際主流智能算力芯片，可實現高複雜度、高計算需求的千億級大模型訓練，協助打造「河套-西麗湖-光明科學城」AI 科創算力走廊，助力深圳加快構築大灣區算力供給高地。</span></p><p><span style="color:#000000">市智慧城市算力統籌調度平台將積極承擔公共算力調度、創新服務等功能，探索通過標準化接口匯聚全市多元異構算力、以算網大腦實現算力的彈性分配，全力提供具有公信力、安全性和普惠性的算力供給服務，努力構建超高可靠、極低時延、極速帶寬、極高性能、綠色低碳的算力調度體系，助力深圳人工智能產業高質量發展。</span></p><p><span style="color:#000000">據瞭解，「萬卡」是指人工智能大模型產品的開發需要多達一萬塊 GPU 芯片的智算算力支持，也是指超大型智算中心的規模「門檻」是一萬塊 GPU 芯片。此次活動由市工信局、市政數局、市科創局、市國資委指導，福田區政府、深智城集團主辦。</span></p><p><em><span style="color:#000000">來源：深圳特區報</span></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 08:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277880</guid>
            <link>https://www.oschina.net/news/277880</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeFuse-VLM 開源，支持多模態多任務預訓練 / 微調]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1707121095833-b957fd4f-440e-46d0-8084-86c8bab7a005.png" width="900" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>CodeFuse-MFT-VLM 項目地址：</span></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-MFT-VLM" target="_blank" rel="nofollow"><span>https://github.com/codefuse-ai/CodeFuse-MFT-VLM</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>CodeFuse-</span><span style="color:#1f2328">VLM-14B</span><span><span>&nbsp;</span>模型地址：</span></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fss41979310%2FCodeFuse-VLM-14B%2Ffiles" target="_blank" rel="nofollow"><span>https://modelscope.cn/models/ss41979310/CodeFuse-VLM-14B/files</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_1"></span><h3><span style="color:#333333">CodeFuse-VLM 框架簡介</span></h3><p style="margin-left:0; margin-right:0"><span style="color:#333333">隨着 huggingface 開源社區的不斷更新，會有更多的 vision encoder 和 LLM 底座發佈，這些 vision encoder 和 LLM 底座都有各自的強項，例如 code-llama 適合生成代碼類任務，但是不適合生成中文類的任務，因此用户常常需要根據 vision encoder 和 LLM 的特長來搭建自己的多模態大語言模型。針對多模態大語言模型種類繁多的落地場景，我們搭建了 CodeFuse-VLM 框架，支持多種視覺模型和語言大模型，使得 MFT-VLM 可以適應不同種類的任務。</span></p><p style="margin-left:0; margin-right:0"><span>CodeFuse-VLM 支持多種視覺達模型：CLIP，CLIP-336px，Chinese Clip，Chinese Clip-336px，Qwen Clip；多種語言達模型：Vicuna-7B，Vicunam-13B，LLAMA-2-7B，Qwen-7B，Qwen-14B。用户可以根據自己的需求，通過配置文件的方式搭配 VL-MFTCoder 中不同的 Vision Encoder 和 LLM，使用同一套框架去適配的不同的模型，大大提高了開發效率。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705576530632-29cdc597-d396-4bbd-b02f-310015e7fcda.png" width="1688" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="color:#333333">我們在 2024 年 1 月開源了多模態多任務微調框架——CodeFuse-VLM。在 CodeFuse 多任務微調的基礎上，CodeFuse-VLM 可以實現在多個模態，多個任務上同時並行地進行微調。通過結合多種損失函數，我們有效地解決了多任務學習中常見的任務間數據量不平衡、難易不一和收斂速度不一致等挑戰。此外，CodeFuse-VLM 框架具備高效訓練特徵，支持高效的 PEFT 微調，能有效提升微調訓練速度並降低對資源的需求。</span></p><div><div class="ckeditor-html5-video"><video controls="controls">
     &nbsp; 
   </video></div><p>&nbsp;</p></div><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_2"></span><h3><span>CodeFuse-VLM-14B 模型</span></h3><p style="margin-left:0; margin-right:0"><span>我們基於 Qwen-VL 的視覺編碼器和 Qwen-14B 大語言模型，在 CodeFuse-VLM 框架下訓練了 CodeFuse-VLM-14B 模型，在多個通用和代碼任務上的性能超過 LLAVA-1.5 和 Qwen-VL。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_3"></span><h4><span>預訓練數據</span></h4><p style="margin-left:0; margin-right:0"><span>參考了 Qwen-VL 的 Multi-Task Pretraining 數據集，我們準備使用多種數據對齊 Qwen-VL-14B 的模態。在預訓練當中我們使用多任務訓練的方式，每一個數據集都是一個訓練任務任務。</span></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:750px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>dataset</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>type</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>number of samples</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>synthdog-en</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w<span>&nbsp;</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>synthdog-zh</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>cc3m(downsampled)</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Image Caption</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>55w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>SBU</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Image Caption</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>85w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome Region descriptions</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Ref Grouding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome objects</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Caption With Grouding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR_VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR and VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>50w</span></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>我們使用預訓練數據集訓練模態對齊的 cross attention 模塊，可以執行以下代碼來啓動模型預訓練</span></p><pre><code>sh scripts/pretrain_multinode.sh</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_4"></span><h4><span>指令微調數據</span></h4><p style="margin-left:0; margin-right:0"><span>我們使用了 LLAVA-1.5 的指令微調數據，總共 65w 樣本，LLAVA 的指令微調數據集包含複雜圖片的推理分析，對 LLM 理解視覺特徵很有幫助。</span></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2023/png/23956347/1701595326578-2fa8ac49-a3a6-413f-9a44-c9fb9416e5eb.png" width="369" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>指令微調數據構成如下，在視覺指令微調當中我們使用多任務訓練的方式，每一個數據集都是一個訓練任務任務。</span></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:750px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>dataset</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>type</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>number of samples</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR_VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>OCR and VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>7w<span>&nbsp;</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>GQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Image Caption</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>8w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Visual Genome</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Ref Grouding and Caption With Grouding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>10w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>COCO</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Detailed Description and Complex Reasoning</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>37w</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Text-VQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Detailed Description and Complex Reasoning</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>3w</span></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>我們使用指令微調數據訓練 CodeFuse-VLM-14B 中的 Qwen-14B 大語言模型，可以執行以下代碼來啓動模型的指令微調</span></p><pre><code>sh scripts/finetune_multinode.sh</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_5"></span><h4><span>模型性能</span></h4><p style="margin-left:0; margin-right:0"><span>我們訓練的 CodeFuse-VLM-14B 模型在多個 benchmark 上的表現超過 Qwen-VL 和 LLAVA-1.5, 具體得分參考下面的圖表。</span></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705311351163-de87fc69-620f-46f7-9e58-fe48e9d32ee6.png" width="514" referrerpolicy="no-referrer"></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:1000px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Benchmark</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>LLAVA-1.5</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>Qwen-VL</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0px; margin-right:0px; text-align:center"><span>CodeFuse-VLM-14B</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>MM_Bench</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span style="color:#4d4d4d">67.7</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>60.6</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><strong><span>75.7</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>MM_Bench_CN</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span style="color:#4d4d4d">63.6</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>56.7</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><strong><span>69.8</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>VqaV2</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><strong><span style="color:#4d4d4d">80.0</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>78.2</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>79.3</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>GQA</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span style="color:#4d4d4d">63.3</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>57.5</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>59.4</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>TextVqa</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span style="color:#4d4d4d">61.3</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>63.8</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>63.9</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>VizWiz</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span style="color:#4d4d4d">53.6</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>35.25</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>45.3</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>Sketch2Code</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>-</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>90.7</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>94.4</span></strong></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>我們的 CodeFuse-VLM-14B 在 MMBenchmark 的</span><strong><span>中英文榜單</span></strong><span>分別取得第</span><strong><span>13/21</span></strong><span>名的排名，高於 Qwen-VL 第</span><strong><span>29/36</span></strong><span>名的排名</span></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmmbench.opencompass.org.cn%2Fleaderboard" target="_blank" rel="nofollow"><span>https://mmbench.opencompass.org.cn/leaderboard</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_6"></span><h3><span>產品圖片</span></h3><p style="margin-left:0; margin-right:0"><span>我們通過 CodeFuse-VLM 在螞蟻內部訓練了網頁圖片到前端代碼的多模態大模型，並把大模型集成到內部的 Visual Studio Code 插件中。如下面兩站圖所示，左邊的圖片是網頁原圖，右邊的圖片是大模型生成的前端代碼渲染出的圖片，多模態大模型生成的前端代碼渲染出的圖片對網頁原圖有很高的還原性，很大地提高了前端工程師開發的效率。</span></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705907166749-474f92e8-31c1-4b38-9cba-5bd06165c311.png" width="3048" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/23956347/1705907389506-fac00ebc-2646-41fa-b847-7d40a6f2a1de.png" width="1560" referrerpolicy="no-referrer"></p></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 08:33:23 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/11030240</guid>
            <link>https://my.oschina.net/u/6942768/blog/11030240</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><p><strong># 2024.2.4</strong></p><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要點</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/277597/vuejs-10yr" target="_blank">10 年前的今天 —— Vue.js 正式問世</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">10 年前的今天（2014 年 2 月 3 日），Vue 在 Hacker News 上首次對外亮相：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D7169288" target="_blank">news.ycombinator.com/item?id=7169288</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">10 年後，Vue 已成為使用最廣泛的前端項目之一，在世界各地擁有多元化的社區。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-581bff0bf554afab956437fa62cb1777d18.png" referrerpolicy="no-referrer"></p><h3><u><a href="https://www.oschina.net/news/277568" target="_blank">扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Meta 開源其 AI 技術是出於推動技術創新、提升模型質量、建立行業標準、吸引人才、增加透明度和支持其長期戰略的考慮。這不僅有助於 Meta 在競爭激烈的 AI 領域保持領先地位，也有助於推動整個行業的前進。</p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日推薦</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-41e1b46b27f9899b2f2893d8ed2b70534e9.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">開源之聲</span></span></span></span></span></span></strong></h2><p><img height="1430" src="https://oscimg.oschina.net/oscnet/up-32c6e76e1aeb2f3d27d77abe42640a381f6.png" width="2400" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日項目榜</span></span></span></span></span></span></strong></h2><p>Gitee 榜單：</p><p><img src="https://oscimg.oschina.net/oscnet/up-c6a5d161821e5d48ee96c57b0e92da312f7.png" referrerpolicy="no-referrer"></p><blockquote><h4><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span><br><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC008%E6%9C%9F%EF%BC%9A%E6%8E%A8%E5%8A%A8%E4%B8%AD%E5%9B%BD%E5%BC%80%E6%BA%90%E8%BD%AF%E7%A1%AC%E4%BB%B6%E5%8F%91%E5%B1%95%E7%9A%84%E7%BB%8F%E9%AA%8C%E4%B8%8E%E5%BB%BA%E8%AE%AE.pdf" target="_blank">開源日報 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><u><a href="https://www.oschina.net/news/277585" target="_blank">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></u></li><li><u><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></u></li><li><u><a href="https://www.oschina.net/news/277214" target="_blank">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></u></li><li><a href="http://www.oschina.net/news/277040"><u>開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</u></a></li><li><u><a href="https://www.oschina.net/news/276864" target="news">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 04:09:04 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277841</guid>
            <link>https://www.oschina.net/news/277841</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[KubeEdge v1.16.0 版本發佈！10 項新增特性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自華為雲社區《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F421489%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">KubeEdge v1.16.0 版本發佈！集羣升級部署易用性大幅提升</a>》，作者： 容器大未來。</p><p>北京時間 2024 年 1 月 23 日，KubeEdge 發佈 1.16.0 版本。新版本新增多個增強功能，在集羣升級、集羣易用性、邊緣設備管理等方面均有大幅提升。</p><p><strong>KubeEdge v1.16.0 新增特性：</strong></p><ul><li><div>
    集羣升級：支持雲邊組件自動化升級 
  </div></li><li><div>
    支持邊緣節點的鏡像預下載 
  </div></li><li><div>
    支持使用 Keadm 安裝 Windows 邊緣節點 
  </div></li><li><div>
    增加多種容器運行時的兼容性測試 
  </div></li><li><div>
    EdgeApplication 中支持更多 Deployment 對象字段的 Override 
  </div></li><li><div>
    支持基於 Mapper-Framework 的 Mapper 升級 
  </div></li><li><div>
    DMI 數據面內置集成 Redis 與 TDEngine 數據庫 
  </div></li><li><div>
    基於 Mapper-Framework 的 USB-Camera Mapper 實現 
  </div></li><li><div>
    易用性提升：基於 Keadm 的部署能力增強 
  </div></li><li>升級 K8s 依賴到 v1.27</li></ul><div><div><div><div><div><div><div><div><div><div><img alt="kubeedge.jpeg" src="https://bbs-img.huaweicloud.com/blogs/img/20240202/1706837744174647751.jpeg" referrerpolicy="no-referrer"></div></div></div><div><span id="OSC_h1_1"></span><h1>新特性概覽</h1></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div><div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div></div></div></div></div><span id="OSC_h3_2"></span><h3>集羣升級：支持雲邊組件自動化升級</h3><p>隨着 KubeEdge 社區的持續發展，社區版本不斷迭代；用户環境版本升級的訴求亟需解決。針對升級步驟難度大，邊緣節點重複工作多的問題，v1.16.0 版本的 KubeEdge 支持了雲邊組件的自動化升級。用户可以通過 Keadm 工具一鍵化升級雲端，並且可以通過創建相應的 Kubernetes API，批量升級邊緣節點。</p><ul><li><strong>雲端升級</strong></li></ul><p>雲端升級指令使用了三級命令與邊端升級進行了區分，指令提供了讓用户使用更便捷的方式來對雲端的 KubeEdge 組件進行升級。當前版本升級完成後會打印 ConfigMap 歷史配置，如果用户手動修改過 ConfigMap，用户可以選擇通過歷史配置信息來還原配置文件。我們可以通過 help 參數查看指令的指導信息：</p><div><pre>keadm upgrade cloud --help
Upgrade the cloud components to the desired version, it uses helm to upgrade the installed release of cloudcore chart, which includes all the cloud components

Usage:
  keadm upgrade cloud [flags]

Flags:
      --advertise-address string    Please set the same value as when you installed it, this value is only used to generate the configuration and does not regenerate the certificate. eg: 10.10.102.78,10.10.102.79
  -d, --dry-run                     Print the generated k8s resources on the stdout, not actual execute. Always use in debug mode
      --external-helm-root string   Add external helm root path to keadm
      --force                       Forced upgrading the cloud components without waiting
  -h, --help                        help for cloud
      --kube-config string          Use this key to update kube-config path, eg: $HOME/.kube/config (default "/root/.kube/config")
      --kubeedge-version string     Use this key to set the upgrade image tag
      --print-final-values          Print the final values configuration for debuging
      --profile string              Sets profile on the command line. If '--values' is specified, this is ignored
      --reuse-values                reuse the last release's values and merge in any overrides from the command line via --set and -f.
      --set stringArray             Sets values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --values stringArray          specify values in a YAML file (can specify multiple)</pre></div><p>升級指令樣例：</p><div><pre>keadm upgrade cloud --advertise-address=&lt;init 時設置的值&gt; --kubeedge-version=v1.16.0</pre></div><ul><li><strong>邊端升級</strong></li></ul><p>v1.16.0 版本的 KubeEdge 支持通過 NodeUpgradeJob 的 Kubernetes API 進行邊緣節點的一鍵化、批量升級。API 支持邊緣節點的升級預檢查、併發升級、失敗閾值、超時處理等功能。對此，KubeEdge 支持了雲邊任務框架。社區開發者將無需關注任務控制、狀態上報等邏輯實現，只需聚焦雲邊任務功能本身。</p><p>升級 API 樣例：</p><div><pre>apiVersion: operations.kubeedge.io/v1alpha1
kind: NodeUpgradeJob
metadata:
  name: upgrade-example
  labels:
    description: upgrade-label
spec:
  version: "v1.16.0"
  checkItems:
    - "cpu"
    - "mem"
    - "disk"
  failureTolerate: "0.3"
  concurrency: 2
  timeoutSeconds: 180
  labelSelector:
    matchLabels:
      "node-role.kubernetes.io/edge": ""
      node-role.kubernetes.io/agent: ""</pre></div><ul><li><strong>兼容測試</strong></li></ul><p>KubeEdge 社區提供了完備的版本兼容性測試，用户在升級時僅需要保證雲邊版本差異不超過 2 個版本，就可以避免升級期間雲邊版本不一致帶來的問題。</p><div>
  更多信息可參考： 
</div><p>https://github.com/kubeedge/kubeedge/pull/5330</p><p>https://github.com/kubeedge/kubeedge/pull/5229</p><div>
  https://github.com/kubeedge/kubeedge/pull/5289 
</div><span id="OSC_h3_3"></span><h3>支持邊緣節點的鏡像預下載</h3><p>新版本引入了鏡像預下載新特性，用户可以通過 ImagePrePullJob 的 Kubernetes API 提前在邊緣節點上加載鏡像，該特性支持在批量邊緣節點或節點組中預下載多個鏡像，幫助減少加載鏡像在應用部署或更新過程，尤其是大規模場景中，帶來的失敗率高、效率低下等問題。</p><p>鏡像預下載 API 示例：</p><div><pre>apiVersion: operations.kubeedge.io/v1alpha1
kind: ImagePrePullJob
metadata:
  name: imageprepull-example
  labels:
    description:ImagePrePullLabel
spec:
  imagePrePullTemplate：
    images:
      - image1
      - image2
    nodes：
      - edgenode1
      - edgenode2
    checkItems:
      - "disk"
    failureTolerate: "0.3"
    concurrency: 2
    timeoutSeconds: 180
    retryTimes: 1</pre></div><p>更多信息可參考：</p><p>https://github.com/kubeedge/kubeedge/pull/5310</p><p>https://github.com/kubeedge/kubeedge/pull/5331</p><span id="OSC_h3_4"></span><h3>支持使用 Keadm 安裝 Windows 邊緣節點</h3><p>KubeEdge 1.15.0 版本實現了在 Windows 上運行邊緣節點，在新版本中，我們支持使用安裝工具 Keadm 直接安裝 Windows 邊緣節點，操作命令與 Linux 邊緣節點相同，簡化了邊緣節點的安裝步驟。</p><p>更多信息可參考：https://github.com/kubeedge/kubeedge/pull/4968</p><span id="OSC_h3_5"></span><h3>增加多種容器運行時的兼容性測試</h3><p>新版本中新增了多種容器運行時的兼容性測試，目前已集成了<strong>containerd</strong>，<strong>docker</strong>，<strong>isulad</strong><span>&nbsp;</span>和<span>&nbsp;</span><strong>cri-o<span>&nbsp;</span></strong>4 種主流容器運行時，保障 KubeEdge 版本發佈質量，用户在安裝容器運行時過程中也可以參考該 PR 中的適配安裝腳本。</p><p>更多信息可參考：https://github.com/kubeedge/kubeedge/pull/5321</p><span id="OSC_h3_6"></span><h3>EdgeApplication 中支持更多 Deployment 對象字段的 Override</h3><p>在新版本中，我們擴展了 EdgeApplication 中的差異化配置項（overriders），主要的擴展有環境變量、命令參數和資源。當您不同區域的節點組環境需要鏈接不同的中間件時，就可以使用環境變量（env）或者命令參數（command, args）去重寫中間件的鏈接信息。或者當您不同區域的節點資源不一致時，也可以使用資源配置（resources）去重寫 cpu 和內存的配置。</p><p>更多信息可參考：</p><div>
  https://github.com/kubeedge/kubeedge/pull/5262 
</div><p>https://github.com/kubeedge/kubeedge/pull/5370</p><span id="OSC_h3_7"></span><h3>支持基於 Mapper-Framework 的 Mapper 升級</h3><p>1.16.0 版本中，基於 Mapper 開發框架 Mapper-Framework 構建了 Mapper 組件的升級能力。新框架生成的 Mapper 工程以依賴引用的方式導入原有 Mapper-Framework 的部分功能，在需要升級時，用户能夠以升級依賴版本的方式完成，簡化 Mapper 升級流程。</p><ul><li><div><strong>Mapper-Framework 代碼解耦:</strong></div></li></ul><div>
  1.16.0 版本中將 Mapper-Framework 中的代碼解耦為用户層和業務層。用户層功能包括設備驅動及與之強相關的部分管理面數據面能力，仍會隨 Mapper-Framework 生成在用户 Mapper 工程中，用户可根據實際情況修改。業務層功能包括 Mapper 向雲端註冊、雲端下發 Device 列表等能力，會存放在 kubeedge/mapper-framework 子庫中。 
</div><ul><li><strong>Mapper 升級框架:</strong></li></ul><p>1.16.0 版本 Mapper-Framework 生成的用户 Mapper 工程通過依賴引用的方式使用 kubeedge/mapper-framework 子庫中業務層功能，實現完整的設備管理功能。後續用户能夠通過升級依賴版本的方式達到升級 Mapper 的目的，不再需要手動修改大範圍代碼。</p><p>更多信息可參考：</p><div>
  https://github.com/kubeedge/kubeedge/pull/5308 
</div><p>https://github.com/kubeedge/kubeedge/pull/5326</p><span id="OSC_h3_8"></span><h3>DMI 數據面內置集成 Redis 與 TDEngine 數據庫</h3><p>1.16.0 版本中進一步增強 DMI 數據面中向用户數據庫推送數據的能力，增加 Redis 與 TDengine 數據庫作為內置數據庫。用户能夠直接在 device-instance 配置文件中定義相關字段，實現 Mapper 自動向 Redis 與 TDengine 數據庫推送設備數據的功能，相關數據庫字段定義為：</p><div><pre>type DBMethodRedis struct {
 // RedisClientConfig of redis database
 // +optional
 RedisClientConfig *RedisClientConfig `json:"redisClientConfig,omitempty"`
}
type RedisClientConfig struct {
 // Addr of Redis database
 // +optional
 Addr string `json:"addr,omitempty"`
 // Db of Redis database
 // +optional
 DB int `json:"db,omitempty"`
 // Poolsize of Redis database
 // +optional
 Poolsize int `json:"poo lsize,omitempty"`
 // MinIdleConns of Redis database
 // +optional
 MinIdleConns int `json:"minIdleConns,omitempty"`
}</pre><pre>type DBMethodTDEngine struct {
 // tdengineClientConfig of tdengine database
 // +optional
 TDEngineClientConfig *TDEngineClientConfig `json:"TDEngineClientConfig,omitempty"`
}
type TDEngineClientConfig struct {
 // addr of tdEngine database
 // +optional
 Addr string `json:"addr,omitempty"`
 // dbname of tdEngine database
 // +optional
 DBName string `json:"dbName,omitempty"`
}</pre></div><p>更多信息可參考：https://github.com/kubeedge/kubeedge/pull/5064</p><span id="OSC_h3_9"></span><h3>基於 Mapper-Framework 的 USB-Camera Mapper 實現</h3><p>基於 KubeEdge 的 Mapper-Framework，新版本提供了 USB-Camera 的 Mapper 樣例，該 Mapper 根據 USB 協議的 Camera 開發，用户可根據該樣例和 Mapper-Framework 更輕鬆地開發具體業務相關的 Mapper。</p><p>在樣例中提供了 helm chart 包，用户可以通過修改 usbmapper-chart/values.yaml 部署 UBS-Camera Mapper，主要添加 USB-Camera 的設備文件, nodeName, USB-Camera 的副本數，其餘配置修改可根據具體情況而定，通過樣例目錄中的 Dockerfile 製作 Mapper 鏡像。</p><div><pre>global: 
  replicaCounts:
......   
    cameraUsbMapper:
      replicaCount: 2  #USB-Camera 的副本數
      namespace: default
......  
  nodeSelectorAndDevPath:
    mapper:  
       - edgeNode: "edgenode02"  #USB-Camera 連接的緣節點 nodeName
         devPath: "/dev/video0"  #USB-Camera 的設備文件 
       - edgeNode: "edgenode1"  
         devPath: "/dev/video17"
......</pre></div><p>USB-Camera Mapper 的部署命令如下：</p><div><pre>helm install usbmapper-chart ./usbmapper-chart</pre></div><div>
  更多信息可參考：https://github.com/kubeedge/mappers-go/pull/122 
</div><span id="OSC_h3_10"></span><h3>易用性提升：基於 Keadm 的部署能力增強</h3><ul><li><strong>添加雲邊通信協議配置參數</strong></li></ul><p>在 KubeEdge v1.16.0 中，使用 keadm join 邊緣節點時，支持使用--hub-protocol 配置雲邊通信協議。目前 KubeEdge 支持 websocket 和 quic 兩種通信協議，默認為 websocket 協議。</p><p>命令示例：</p><div><pre>keadm join --cloudcore-ipport &lt;雲節點 ip&gt;:10001 --hub-protocol=quic --kubeedge-version=v1.16.0 --token=xxxxxxxx</pre></div><p><strong>説明：</strong>當--hub-protocol 設置為 quic 時，需要將--cloudcore-ipport 的端口設置為 10001，並需在 CloudCore 的 ConfigMap 中打開 quic 開關，即設置 modules.quic.enable 為 true。</p><p><strong>操作示例</strong>：使用 kubectl edit cm -n kubeedge cloudcore，將 quic 的 enable 屬性設置成 true，保存修改後重啓 CloudCore 的 pod。</p><div><pre>modules：
......
  quic:
    address: 0.0.0.0
    enable: true  #quic 協議開關
    maxIncomingStreams: 10000
    port: 10001
......</pre></div><p>更多信息可參考：https://github.com/kubeedge/kubeedge/pull/5156</p><ul><li><strong>keadm join 與 CNI 插件解耦</strong></li></ul><p>在新版本中，keadm join 邊緣節點時，不需要再提前安裝 CNI 插件，已將邊緣節點的部署與 CNI 插件解耦。同時該功能已同步到 v1.12 及更高版本，歡迎用户使用新版本或升級老版本。</p><p><strong>説明</strong>：如果部署在邊緣節點上的應用程序需要使用容器網絡，則在部署完 EdgeCore 後仍然需要安裝 CNI 插件。</p><p>更多信息可參考：</p><p>https://github.com/kubeedge/kubeedge/pull/5196</p><span id="OSC_h3_11"></span><h3>升級 K8s 依賴到 v1.27</h3><p>新版本將依賴的 Kubernetes 版本升級到 v1.27.7，您可以在雲和邊緣使用新版本的特性。</p><p>更多信息可參考：</p><div>
  https://github.com/kubeedge/kubeedge/pull/5121 
</div><div><div><div><div><div><div><div><div><span id="OSC_h1_12"></span><h1>版本升級注意事項</h1></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div><div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div></div></div></div></div><p>新版本我們使用 DaemonSet 來管理邊端的 MQTT 服務 Eclipse Mosquitto 了，我們能夠通過雲端 Helm Values 配置來設置是否要開啓 MQTT 服務。使用 DaemonSet 管理 MQTT 後，我們可以方便的對邊端 MQTT 進行統一管理，比如我們可以通過修改 DaemonSet 的配置將邊端 MQTT 替換成 EMQX。</p><p>但是如果您是從老版本升級到最新版本，則需要考慮版本兼容問題，同時使用原本由靜態 Pod 管理的 MQTT 和使用新的 DaemonSet 管理的 MQTT 會產生端口衝突。兼容操作步驟參考：</p><div><strong>1、您可以在雲端執行命令，將舊的邊緣節點都打上自定義標籤</strong></div><div><pre>kubectl label nodes --selector=node-role.kubernetes.io/edge without-mqtt-daemonset=""</pre></div><div><strong>2、您可以修改 MQTT DaemonSet 的節點親和性</strong></div><div><pre>nodeAffinity:
  requiredDuringSchedulingIgnoredDuringExecution:
    nodeSelectorTerms:
      - matchExpressions:
          - ...
          - key: without-mqtt-daemonset
            operator: Exists</pre></div><div><strong>3、將節點 MQTT 改為由 DaemonSet 管理</strong></div><div><pre># ------ 邊端 ------
# 修改/lib/systemd/system/edgecore.service，將環境變量 DEPLOY_MQTT_CONTAINER 設置成 false
# 這步可以放在更新 EdgeCore 前修改，這樣就不用重啓 EdgeCore 了
sed -i '/DEPLOY_MQTT_CONTAINER=/s/true/false/' /etc/systemd/system/edgecore.service

# 停止 EdgeCore
systemctl daemon-reload &amp;&amp; systemctl stop edgecore

# 刪除 MQTT 容器，Containerd 可以使用 nerdctl 替換 docker
docker ps -a | grep mqtt-kubeedge | awk '{print $1}' | xargs docker rm -f

# 啓動 EdgeCore
systemctl start edgecore

# ------ 雲端 ------
# 刪除節點標籤
kubectl label nodes &lt;NODE_NAME&gt; without-mqtt-daemonset</pre></div><div>
  新版本的 keadm join 命令會隱藏 with-mqtt 參數，並且將默認值設置成 false，如果您還想使用靜態 Pod 管理 MQTT，您仍然可以設置參數--with-mqtt 來使其生效。with-mqtt 參數在 v1.18 版本中將會被移除。 
</div><div><div><div><div><div><div><div><div><span id="OSC_h1_13"></span><h1>致謝</h1></div></div></div></div><div><div><div><div><div><div><div>
            &nbsp; 
          </div></div></div></div></div></div></div></div></div></div></div><p>感謝 KubeEdge 社區技術指導委員會 (TSC)、各 SIG 成員對 v1.16.0 版本開發的支持與貢獻，未來 KubeEdge 將持續在新場景探索與支持、穩定性、安全性、可擴展性等方面持續發展與演進！</p><div><strong>相關鏈接</strong></div><p>Release Notes：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubeedge%2Fkubeedge%2Fblob%2Fmaster%2FCHANGELOG%2FCHANGELOG-1.16.md" rel="nofollow" target="_blank">https://github.com/kubeedge/kubeedge/blob/master/CHANGELOG/CHANGELOG-1.16.md</a></p><p>&nbsp;</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>點擊關注，第一時間瞭解華為雲新鮮技術~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 04:04:04 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/11030176</guid>
            <link>https://my.oschina.net/u/4526289/blog/11030176</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ReactOS 最新測試版已引入 GUI 安裝程序]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>ReactOS 最近進行了一次重要的更新。去年 11 月，ReactOS 開發團隊宣佈其 64 位 UEFI 啓動功能已經支持更廣泛的設備。而此次更新主要集中在改善圖形用户界面（GUI）安裝程序上。</p><p>與文本模式的安裝程序"USETUP"相比，GUI 界面更加直觀易用，尤其對普通用户而言。對於被稱為「開源的 Windows」的 ReactOS 來説，擁有一個定義良好的 GUI 顯然是必不可少的。</p><p>ReactOS 在博客文章中<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Freactos.org%2Fblogs%2Fgui-setup-part2-partitioning%2F" target="_blank">寫道</a></u>：「雖然文本模式的 USETUP 使用合理的工作流程（每個操作都在不同的屏幕上進行；只允許向前進行，一旦選擇了一個操作就無法撤銷），但 GUI 模式安裝程序改變了其中一些假設。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-287edd3bc4a4238feae4013db6436bcf869.png" referrerpolicy="no-referrer"></p><p>「GUI 設置嚮導式的風格允許在不同的頁面之間來回跳轉。它的分區頁面顯示了一個簡約的界面，類似於文本模式的界面，但更讓人聯想到其他 GUI 分區軟件。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-01c01deb4f0860a4323ef7f1277f8ded9a5.png" referrerpolicy="no-referrer"></p><p>從公佈截圖來看，ReactOS 的 GUI 安裝程序與經典 Windows 設置相似，例如 Windows 95。用户可以選擇安裝目錄，但目前 GPT（GUID 分區表）尚未得到支持。</p><ul><li>延伸閲讀：<em><a href="https://www.oschina.net/news/260162/reactos-gui-setup-project" target="_blank">「開源 Windows」 ReactOS 改進 GUI 設置 / 安裝</a></em></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 03:47:07 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277838/reactos-gui-mode-installer-goes</guid>
            <link>https://www.oschina.net/news/277838/reactos-gui-mode-installer-goes</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | npm 存在大量武林外傳視頻；大神只用 Excel 就構建了一顆 CPU；Linus 怒懟谷歌內核貢獻者.....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2024.01.29-2024.02.04]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 03:29:07 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094157&#38;idx=1&#38;sn=b292847617ebe4004a3e8540053cfca7&#38;chksm=880c431ebf7bca0826725b540f3eaf79a7f51f14a56ae6297cce70671c632efc8a32903fc6fd&#38;token=1893846415&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094157&#38;idx=1&#38;sn=b292847617ebe4004a3e8540053cfca7&#38;chksm=880c431ebf7bca0826725b540f3eaf79a7f51f14a56ae6297cce70671c632efc8a32903fc6fd&#38;token=1893846415&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[蘋果開源 Pkl —— 用於生成配置的編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>蘋果發佈了專用於創建配置文件的腳本編程語言&nbsp;Pkl（發音為 Pickle）。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fd76c052669ab34b0879a64a839ee812dd1.png" referrerpolicy="no-referrer"></p><p><em>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsspai.com%2Flink%3Ftarget%3Dhttps%253A%252F%252Fpkl-lang.org%252F" target="_blank">pkl-lang.org</a>&nbsp;</em></p><p>Pkl 團隊<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpkl-lang.org%2Fblog%2Fintroducing-pkl.html" target="_blank">介紹稱</a></u>，該項目旨在應對 JSON、YAML 和屬性列表等靜態配置格式的不足，提供一種介於靜態語言和通用語言之間、「兩全其美」的方案。</p><div><div><div><div><div><p style="margin-left:0; margin-right:0"><strong>示例代碼</strong></p><p style="margin-left:0; margin-right:0">bird.pkl</p><pre><code class="language-json">name = "Swallow"

job {
  title = "Sr. Nest Maker"
  company = "Nests R Us"
  yearsOfExperience = 2
}</code></pre><p style="margin-left:0; margin-right:0">↓</p><p style="margin-left:0; margin-right:0">bird.json</p><pre><code class="language-json">{
  "name": "Swallow",
  "job": {
    "title": "Sr. Nest Maker",
    "company": "Nests R Us",
    "yearsOfExperience": 2
  }
}</code></pre><p style="margin-left:0; margin-right:0">Pkl 的三個設計目標是語法安全、可擴展和 IDE 集成，使用聲明式語法、易讀易寫，但也支持類、函數、條件和循環等常見的編程語言功能。</p></div></div></div></div></div><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-22c3ee52b4d47fa7152e2e262ed4b875edd.png" referrerpolicy="no-referrer"></p></blockquote><p>根據文檔，Pkl 可用於生成任何格式的靜態配置文件，也可以作為庫嵌入在 Java、Kotlin、Swift、Go 等語言的代碼中運行。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d89a660e2346e9f1536d4df60f0ba725793.png" referrerpolicy="no-referrer"></p><p>部分代碼示例倉庫：</p><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-go-examples" target="_blank">https://github.com/apple/pkl-go-examples</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-jvm-examples" target="_blank">https://github.com/apple/pkl-jvm-examples</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-k8s-examples" target="_blank">https://github.com/apple/pkl-k8s-examples</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapple%2Fpkl-swift-examples" target="_blank">https://github.com/apple/pkl-swift-examples</a></p></li></ul><p>蘋果還同步推出了支持 IntelliJ、Visual Studio Code 和 Neovim 等編輯器的 Pkl 插件，但沒有為自家 IDE Xcode 開發插件。</p><p><img src="https://oscimg.oschina.net/oscnet/up-eff9cd63e6a81ddfe145eb97dcacb4fed4f.gif" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 05 Feb 2024 02:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277816/apple-pkl-lang</guid>
            <link>https://www.oschina.net/news/277816/apple-pkl-lang</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟為 Windows 11 引入原生 Sudo 命令支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">網曝微軟正在 Windows 11 中測試類似 macOS 或 Linux 的原生 Sudo 命令支持。Windows Latest <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowslatest.com%2F2024%2F02%2F01%2Ffirst-look-windows-11-is-getting-native-macos-or-linux-like-sudo-command%2F" target="_blank">報道</a>稱，Windows Update 服務器上日前出現了一個泄露的 Windows Server 預覽版，包含了一些正在開發的新功能，其中就有 Windows "sudo"命令的新設置。</span></p><p><span style="color:#000000">Sudo「superuser do」命令將作為開發人員設置的一部分出現在 Windows 11 中。它可能允許用户管理需要管理權限的設置，例如卸載應用程序、更改系統設置或其他與開發人員相關的設置。用户將可在 Windows 11 的開發者設置中找到 Sudo 的開關選項。</span></p><blockquote><p><span style="color:#000000">Superuser do (或 sudo) 是一種 Linux 控制枱程序，允許低權限用户以提升的權限（通常是 root）執行命令。該命令提高了 Linux 的安全性，因為服務器可以在低權限賬户下正常使用，同時還允許用户在運行特定命令時根據需要提升權限。</span></p></blockquote><p><span style="color:#000000">使用 Sudo 命令前提是需要開啓開發者模式，但目前這一功能在泄露的預覽版中尚未啓用。</span></p><p><span style="color:#000000"><img alt="" height="292" src="https://oscimg.oschina.net/oscnet/up-bb4f7cbad244d7fcc09d756b8b7f03ebbbd.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="312" src="https://oscimg.oschina.net/oscnet/up-83a013eb2b6863974cb93e72362fe94a81f.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">用户可以通過設置使用 Sudo 運行命令的偏好來自定義 Sudo 命令的行為：</span></p><ul><li><span style="color:#000000">開啓新窗口：這可能意味着當你使用 Sudo 運行命令時，它會在一個單獨的新窗口（可能是終端窗口）中打開，並在該窗口中執行命令。</span></li><li><span style="color:#000000">禁用輸入：尚不清楚此切換如何工作。但是從名稱來看，它可能表示一種安全功能，即在 Sudo 命令運行時暫時禁用鍵盤或鼠標的輸入，以防止在執行期間發生未經授權的操作。</span></li><li><span style="color:#000000">內聯：這可能允許 Sudo 命令在當前窗口或上下文中執行，而無需打開新窗口，這對於快速任務或在集成開發環境 (IDE) 中工作時可能很有幫助。</span></li></ul><p><span style="color:#000000">此外，Sudo 設置還警告稱，運行命令可能會使設備和個人數據面臨安全風險，並有可能損害用户的設備，但卻沒有解釋其中的貓膩。 只要啓用該功能並開啓開發者模式，你就可以使用命令提示符、PowerShell 或 Windows 上的任何終端界面訪問 Sudo 命令。</span></p><p><span style="color:#000000">目前尚未明確 Sudo 命令何時會出現在生產（穩定）版本中。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 04 Feb 2024 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/277814/microsoft-linux-sudo-command-windows</guid>
            <link>https://www.oschina.net/news/277814/microsoft-linux-sudo-command-windows</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gradle 8.6 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">Gradle 8.6&nbsp;現已</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Frelease-notes.html" target="_blank">發佈</a><span style="background-color:#ffffff; color:#333333">。Gradle&nbsp;是一個基於&nbsp;Apache Ant&nbsp;和&nbsp;Apache Maven&nbsp;概念的項目自動化構建工具，支持依賴管理和多項目，類似&nbsp;Maven，但比之簡單輕便。它使用一種基於&nbsp;Groovy&nbsp;的特定領域語言來聲明項目設置，而不是傳統的&nbsp;XML。</span></p><p><span style="background-color:#ffffff; color:#333333">此版本支持配置緩存的自定義加密密鑰，對 build init 進行了多項改進，並更新了 build authoring API。還為 IDE integrators 提供了更多有用的錯誤和警告信息以及新的 API。</span></p><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>配置緩存改進</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>配置<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fconfiguration_cache.html" target="_blank">緩存</a>通過緩存配置階段的結果並將其重用於後續構建來縮短構建時間。此功能可以顯着提高構建性能。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>自定義加密密鑰</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>配置緩存經過加密，可降低敏感數據意外泄露的風險。默認情況下，Gradle 會自動創建並管理密鑰，並將其存儲在 Gradle 用户主目錄的密鑰庫中。這樣做雖然方便，但在某些環境下可能並不合適。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>現在用户可以向 Gradle 提供用於通過<code>GRADLE_ENCRYPTION_KEY</code>環境變量加密緩存配置數據的密鑰。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>更多詳細信息查看 Gradle 用户手冊的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fconfiguration_cache.html%23config_cache%3Asecrets%3Aconfiguring_encryption_key" target="_blank">配置緩存</a>部分。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Build init 改進</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fbuild_init_plugin.html" target="_blank">build init 插件</a>允許用户輕鬆創建新的 Gradle 構建，支持各種類型的項目。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Simpler source package handling</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>你不再需要回答有關源包的交互式問題。取而代之的是使用<code>org.example</code>的默認值。你可以使用<code>init</code>任務的現有選項<code>--package</code>flag 來覆蓋它。此外，還可以通過在 Gradle 用户主頁的<code>gradle.properties</code>中添加<code>org.gradle.buildinit.source.package</code>新屬性來設置默認值。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>// ~/.gradle/gradle.properties org.gradle.buildinit.source.package=my.corp.domain </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>生成的 convention plugins 的名稱現在以<code>buildlogic</code>開頭，而不是軟件包名稱，從而使名稱更簡短、更整潔。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Generating without interactive questions</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>新增的 --use-defaults 選項可為未明確配置的選項應用默認值。它還能確保 init 命令在沒有交互式用户輸入的情況下完成。這在 shell 腳本中非常方便，可確保腳本不會意外掛起。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>例如，你可以在不回答任何問題的情況下生成 Kotlin 庫：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><code>gradle init --use-defaults --type kotlin-library
</code></pre><p style="color:#02303a; text-align:start"><strong>Simpler assignment syntax in Kotlin DSL</strong></p><p style="color:#02303a; text-align:start">示例：</p><pre><code>application {
mainClass = "org.example.AppKt"
}</code></pre><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Build authoring 改進</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Gradle 為插件作者和構建工程師提供了豐富的 API 來開發自定義構建邏輯。如果執行構建不需要任務，則任務配置避免 API 會避免配置任務<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Ftask_configuration_avoidance.html" target="_blank">。</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Lazy name-based filtering of tasks</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start">示例：</p><pre><code>tasks.named { it.contains("pack") }.configureEach {
    // lazily configure details of all '*pack*' tasks that are part of the task graph
}</code></pre><p style="text-align:start"><strong>Allow Providers to be used with dependency capabilities</strong></p><p style="text-align:start">Gradle 支持<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fcomponent_capabilities.html" target="_blank">聲明</a>組件的功能，以便允許 Gradle 在構建時檢測和解決依賴項之間的衝突，從而更好地管理依賴項。</p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>dependencies { implementation("org.foo:bar:1.0") { capabilities { // Values in the interpolated String below are lazily evaluated, allowing them to be set after this block requireCapability(project.provider(() -&gt; "${project.group}:${project.name}-platform:${project.version}")) } } } // Later, the version of the project is set. // Without the provider above, this change would not be reflected in the capability. project.version = "1.0.0" </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><h4><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>錯誤和警告報告改進</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Gradle 提供了一組豐富的錯誤和警告消息來幫助用户理解和解決構建中的問題。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>出現依賴鎖定錯誤時更清晰的建議操作</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>此版本通過將錯誤與可能的操作分開以修復控制枱輸出中的問題，改進了依賴鎖定中的錯誤消息。啓用 strict mode 時，由於鎖定文件格式無效或缺少鎖定狀態而導致的錯誤現在顯示如下：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>FAILURE: Build failed with an exception. * What went wrong: Execution failed for task ':dependencies'. &gt; Could not resolve all dependencies for configuration ':lockedConf'. &gt; Invalid lock state for lock file specified in '&lt;project&gt;/lock.file'. Line: '&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD' * Try: &gt; Verify the lockfile content. For more information on lock file format, please refer to https://docs.gradle.org/8.6/userguide/dependency_locking.html#lock_state_location_and_format in the Gradle documentation. &gt; Run with --info or --debug option to get more log output. &gt; Run with --scan to get full insights. &gt; Get more help at https://help.gradle.org. </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><p style="text-align:start"><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>更好地報告 providers 中的循環引用的錯誤</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><pre><span><span><span><span style="background-color:#f7f7f8"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><code>FAILURE: Build failed with an exception. * Where: Build file '&lt;project&gt;/build.gradle' line: 7 * What went wrong: A problem occurred evaluating root project 'test'. &gt; Circular evaluation detected: property(java.lang.String, map(java.lang.String map(&lt;CIRCULAR REFERENCE&gt;) check-type())) -&gt; map(java.lang.String map(property(java.lang.String, &lt;CIRCULAR REFERENCE&gt;)) check-type()) -&gt; map(property(java.lang.String, map(java.lang.String &lt;CIRCULAR REFERENCE&gt; check-type()))) -&gt; property(java.lang.String, map(java.lang.String map(&lt;CIRCULAR REFERENCE&gt;) check-type())) </code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><h4><strong><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>IDE 集成改進</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="text-align:start"><span><span><span><span style="color:#02303a"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Fuserguide%2Fthird_party_integration.html" target="_blank">Gradle 使用 Tooling API</a>&nbsp;集成到許多 IDE 中。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><hr><p style="text-align:start">此外，<span style="background-color:#ffffff; color:#02303a">Gradle 8.6 中還修復了 86 個&nbsp;issue。更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gradle.org%2F8.6%2Frelease-notes.html" target="_blank">查看官方公告</a>。</span></p></div>
                                    ]]>
            </description>
            <guid isPermaLink="false">https://www.oschina.net/news/277856/gradle-8-6-released</guid>
            <link>https://www.oschina.net/news/277856/gradle-8-6-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
