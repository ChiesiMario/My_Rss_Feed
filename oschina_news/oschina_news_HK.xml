<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 06 Nov 2023 13:15:33 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[龍芯 3A6000 國產桌面處理器本月底發佈，對標英特爾 10 代酷睿]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日的龍芯中科 2023 年第三季度業績説明會上，龍芯中科宣佈&nbsp;3A6000 國產桌面處理器初步定於<strong>11 月 28 日發佈</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-033f0723def37a98686c0268285f4fe7284.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frsc.sseinfo.com%2FroadshowIndex.do%3Fid%3D16536" target="_blank">https://rsc.sseinfo.com/roadshowIndex.do?id=16536</a></em></u></p><p>龍芯 3A6000 是基於龍架構的新一代四核處理器，於今年 8 月流片成功。綜合相關測試結果，<strong>龍芯 3A6000 處理器總體性能與英特爾公司 2020 年上市的第 10 代酷睿四核處理器相當</strong>，因此也是不少國內用户期待的一款高性能國產處理器。</p><p>龍芯中科在業績説明會上透露，龍芯 3A6000 將於 11 月底正式發佈（初步定於 11 月 28 日），<strong>十幾家整機 / ODM 企業將發佈其整機產品</strong>。</p><p><img height="1098" src="https://static.oschina.net/uploads/space/2023/1106/145609_pmei_2720166.png" width="2910" referrerpolicy="no-referrer"></p><p>在談到後續產品龍芯 3B6000 時，龍芯中科董事長、總經理胡偉武表示：「龍芯走的是提高效率路線，爭取每 GHz 性能接近或達到蘋果 CPU 的水平。<strong>3B6000 爭取每 GHz 的性能再提高 20%-30%</strong>，在此基礎上再用先進工藝提高主頻，這時候龍芯 CPU 性能就處於世界領先行列了。當然，我們也會努力提高 3B6000 的主頻。」</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 06:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265161</guid>
            <link>https://www.oschina.net/news/265161</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[崑崙萬維「天工」大模型正式向全社會開放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 11 月 3 日，崑崙萬維「天工」大模型通過《生成式人工智能服務管理暫行辦法》備案，面向全社會開放服務！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>用户在應用商店下載「天工</span></span><span><span>APP」或登陸「天工官網」（www.tiangong.cn）均可直接註冊使用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>「天工」是國內首個對標</span></span><span><span>ChatGPT 的雙千億級大語言模型，也是一個 AI 搜索引擎，一個對話式 AI 助手。「天工」擁有強大的自然語言處理和智能交互能力，能夠實現個性化 AI 搜索、智能問答、聊天互動、文本生成、編寫代碼、語言翻譯等多種應用場景，並且具有豐富的知識儲備，涵蓋科學、技術、文化、藝術、歷史等領域。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span>&nbsp;<img alt="" height="589" src="https://oscimg.oschina.net/oscnet/up-d32a56bf391efe8f4eb7543b06215352058.png" width="1265" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2022 年 12 月 15 日，崑崙萬維在北京舉行 AIGC 技術發佈會，發佈自研 AIGC 全系列算法與模型，覆蓋了圖像、音樂、文本、編程等多模態的 AI 內容生成能力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 4 月 17 日，崑崙萬維正式發佈自研千億級大語言模型「天工」，同時宣佈啓動邀請測試。「天工」用過通過自然語言與用户進行問答式交互，AI 生成能力可滿足文案創作、知識問答、代碼編程、邏輯推演、數理推算等多元化需求。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 5 月 19 日，北京市經濟和信息化局公佈第一批《北京市通用人工智能產業創新夥伴計劃成員名單》。崑崙萬維憑藉在 AIGC 領域的前沿探索和投資佈局，成為第一批模型夥伴和投資夥伴。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 8 月 23 日，崑崙萬維推出國內第一款 AI 搜索產品——「天工 AI 搜索」，並開啓內測申請。「天工 AI 搜索」深度融合 AI 大模型能力，通過人性化、智能化的方式全面提升用户的搜索體驗，為用户提供快速、可靠的交互式搜索服務，並集成 AI 對話、AI 寫作等常用功能，幫助用户提升工作效率，全面重塑中文搜索體驗。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月，崑崙萬維多模態大模型 Skywork-MM 在騰訊優圖實驗室聯合廈門大學開展的多模態大語言模型測評 MME 中，綜合得分排名第一。該評測首次對全球範圍內 MLLM 模型進行了全面定量評測並公佈了 16 個排行榜，包含感知、認知兩個總榜單以及 14 個子榜單。Skywork-MM 模型位列綜合榜單第一，其中，感知榜單排名第一、認知榜單排名第二。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 16 日，在權威推理榜單 Benchmark GSM8K 測試中，崑崙萬維「天工」大模型以 80% 的正確率脱穎而出，大幅領先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%），這標誌着天工的推理能力達到全球領先，接近 GPT-4。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 17 日，崑崙萬維通過信通院「可信 AI」評估，並被評選為人工智能實驗室副組長單位。經中國信通院評估，崑崙萬維天工大模型符合 AIIA/PG 0071-2023、AIIA/PG 0072-2023 評估標準，模型開發、以及模型能力均達到了「4+級」。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>10 月 30 日，崑崙萬維開源百億級大語言模型「天工」Skywork-13B 系列，並配套開源了 600GB、150B Tokens 的超大高質量開源中文數據集。「天工」Skywork-13B 系列目前包括 130 億參數的兩大模型，Skywork-13B-Base 模型、Skywork-13B-Math 模型，它們在 CEVAL、GSM8K 等多個權威評測與基準測試上都展現了同等規模模型的最佳效果，其中文能力尤為出色，在中文科技、金融、政務等領域表現均高於其他開源模型。同時，崑崙萬維「天工」Skywork-13B 系列大模型全面開</span></span><span><span>放商用——開發者無需申請，即可商用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>一直以來，崑崙萬維致力於在</span></span><span><span>AIGC 模型算法方面的技術創新和開拓，致力於降低 AIGC 技術在各行各業的使用和學習門檻。通過《生成式人工智能服務管理暫行辦法》備案後，崑崙萬維將面向全社會開放 AI 服務，持續推動天工大模型及 AIGC 業務邁向新高度，提高多款生成式 AI 產品的用户體驗，探索未知世界、創造美好未來。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265122</guid>
            <link>https://www.oschina.net/news/265122</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox Android 版擴展支持即將推出]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Mozilla 計劃在 Firefox 120 版本發佈 (預計於 11 月 21 日) 後為 Android 版 Firefox 提供瀏覽器擴展，並督促開發者評估其擴展代碼，為此做好準備。</span></p><blockquote><p><span style="color:#000000">在 Firefox 120 的發佈週期中，我們將開始在 addons.mozilla.org (AMO) 上看到數十個新的、可在 Firefox for Android 上公開使用的擴展。我們正在採取穩定的方法來開放移動擴展生態系統，以確保 Firefox for Android 在首次在移動環境中使用大量新擴展的同時，保持強大的性能標準。如果測試進展順利，我們預計將在 12 月的某個時候推出完全開放的 Firefox for Android 擴展生態系統。</span></p></blockquote><p><img height="241" src="https://oscimg.oschina.net/oscnet/up-8be59849e0793fa2d91bbfbcf62cde5001d.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">事實上，早在 2019 年 Firefox&nbsp;移動產品戰略負責人 Vesta Zare 就曾<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmozilla-mobile%2Ffenix%2Fissues%2F5315" target="_blank">提出</a>有關<span style="background-color:#ffffff">移動版擴展的</span>想法。但因為安全等方面的擔憂，導致進展緩慢。現如今，</span><span style="color:#000000"><span style="background-color:#ffffff">Firefox 擴展程序的編輯部經理 Scott DeVaney 認為，預計用户將對此產生濃厚的興趣。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">DeVaney 指出，按照當下的趨勢，當 12 月份正式開放時 AMO 上將提供至少 200 多個新的 Firefox Android 擴展。</span>「雖然數百個擴展比你能在任何其他移動瀏覽器上找到的擴展都要多，<span style="background-color:#ffffff">但與 AMO 上近 40,000 個</span>桌面 Firefox 擴展<span style="background-color:#ffffff">相比，還是少得多</span>。因此，提高新用户可發現性的機會可能會吸引一些開發人員。」</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Chrome 瀏覽器的&nbsp;</span>Android 版尚不支持擴展功能。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F11%2F03%2Fmozilla_android_extensions%2F" target="_blank">The Register </a>指出，谷歌公司此舉可能是因為擔心&nbsp;Android 用户會使用插件屏蔽廣告，從而影響其廣告收益。不過，谷歌目前正在對其 Chrome 瀏覽器擴展架構 (Manifest v3) 進行修訂。如果谷歌選擇在 Android 版 Chrome 中添加擴展支持以避免被競爭對手甩在後面，那麼 Manifest v3 擴展將更適合移動設備。值得注意的是，蘋果、Mozilla 和微軟都計劃在各自的瀏覽器中支持 Manifest v3，但會有所變化。</span></p><p><span style="background-color:#ffffff; color:#000000">俄羅斯流行的 Yandex 移動瀏覽器已經在 2016 年增加了對 Android 擴展的支持，Kiwi 等其他基於 Android 的瀏覽器也均已實現。2021 年 9 月，蘋果公司也在 iOS 15 中推出了對 Safari 擴展程序的支持。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 09:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265222/mozilla-android-extensions</guid>
            <link>https://www.oschina.net/news/265222/mozilla-android-extensions</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[釋永信在 Meta 舊金山總部的分享：《禪宗遇到 AI》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>少林寺方丈釋永信前幾天在 Meta 舊金山總部進行了一場線下分享：《禪宗遇到 AI》。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-20a03a09dd590e8667727ffe3480e4cfe14.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28ccc5a8d3722013dfb80753592032c7d65.png" referrerpolicy="no-referrer"></p><p>以下內容轉載自<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.facebook.com%2FrealShiYongxin%2Fposts%2Fpfbid02BeBDeptmeVZLMuPyk6SXFqgFkz5DcQraoethMkiATQ4sxefEMic5ubBogwmNpW5Sl" target="_blank"> 釋永信 Facebook 帳號</a></u></em>。</p><hr><p>釋永信方丈 2023 年 11 月 2 日於舊金山臉書 (∞ Meta) 公司總部/Abbot Shi Yongxin at Meta Company Headquarters in San Francisco on November 2, 2023.</p><p>尊敬的各位來賓和朋友：</p><p>大家好！</p><p>今天非常榮幸能同各位朋友分享「禪宗遇到 AI」這個話題。隨着人工智能技術的不斷髮展，它正在逐漸滲透到我們生活的各個領域。與此同時，這種技術的普及也對傳統信仰產生了巨大影響。當古老的東方禪宗思想遇到 21 世紀尖端技術的人工智能，人文與科技的交匯勢必會給當今世界的人們帶來新的啓示。</p><p>佛教到今天已經有 2500 餘年的發展歷史。禪宗是中國佛教影響最大、傳播最廣、發展最成熟的宗派，其中心思想可概括為「不立文字，教外別傳，直指人心，見性成佛」。禪宗追求心靈的覺悟，它是對佛陀思想的繼承和創新，同時又融匯了中國傳統的儒家、道家思想，其修行方法以真修實證為主，不受任何知識、邏輯、思維乃至意識所束縛，是修禪者對解脱智慧的流露。禪宗思想深刻影響了中國的哲學、文學、藝術等領域，同時也在服務社會、淨化人心、開啓心智等方面做出了積極貢獻。</p><p>少林寺始建於公元 495 年，禪宗初祖菩提達摩在少林寺面壁九年創立禪宗。少林寺作為禪宗祖庭，1500 多年來傳承不斷，其主要以「禪」為核心，以養生、功夫、醫藥和禪藝等為表現形式，方便度化眾生。少林養生功法以習練《易筋經》等氣功為主，輔以素食、坐禪、經行等方法，以達到涵養精氣神之妙用。少林功夫是中國首批非物質文化遺產，以佛教信仰和禪宗智慧為基礎，具有完整的技擊理論體系，形成有擒拿、格鬥、卸骨、點穴、拳械等多種功法，並形成了標準化、規範化的少林功夫段品制的修學體系，其最高境界為「禪武合一」。少林醫藥來自對佛學「醫方明」的繼承，結閤中國傳統中醫，主張運用佛法治心、草本治身，以達到調養身心之功效。少林禪藝則以繪畫、書法、雕刻、梵唄、茶器及圍棋等為載體，以藝入禪來傳播禪宗文化。</p><p>少林文化通過不斷的傳承與交流，已在韓國、日本、東南亞等地區得到廣泛傳播，近幾十年來，歐美各國也湧現出許多少林文化的愛好者。少林寺還積極參與國際交流活動，為服務人類健康做出了積極貢獻。目前，少林寺在全世界 150 多個國家 200 多個地區都有少林文化交流中心。</p><p>少林寺在歷史發展中幾經興衰，但是如今依然傳承不斷，其原因在於少林文化的內動力，它兼容幷蓄，並且提倡人與自然，人與社會，人與自身的和合共生，同時少林文化在溝通國際關係、推動世界和平方面發揮了積極作用。少林寺在未來也依然會堅持傳播平等、慈悲、清淨、圓融的佛教普世價值觀，更好的服務全人類。</p><p>當禪宗遇到人工智能時會發生什麼？技術進步能否取代道德倫理進步？人工智能具有強大的數據處理和分析能力，並且經由程序和算法可能會表現出類似於人類的感知，但是人工智能並不能具備我們禪宗所講的覺悟的心性。人類面對此人工智能應該保持頭腦清醒，應該如禪宗所倡導的那樣向內尋求，得到超越解脱的本覺智慧。</p><p>禪宗是強調修禪者通過自身的精進和努力，逐漸提升覺悟的境界，在這個過程中，常常會遇到諸多困惑和煩惱，AI 作為一作工具，可以檢索查找相關經典，從而對治各種疑惑，為修禪者提供輔助和便利。</p><p>科技的進步讓人們的閒暇時間增多，我們不希望因為閒暇時間的增多而使大眾變得懶散放逸。在未來，我希望禪宗智慧和人工智能可以有更多互動，特別是在少林文化方面，能夠攜手搭建一個交流平台，讓大眾在修學體驗少林禪、武、醫、藝文化時，能夠更加身臨其境地感受少林文化的獨特魅力，追求精神上的圓滿，也讓少林文化更好地服務全人類身心靈健康。</p><p>最後，祝願大家一切吉祥！阿彌陀佛!</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 08:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265201</guid>
            <link>https://www.oschina.net/news/265201</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[踐行「人人可用」，DataEase 開源數據可視化分析平台發佈 v2.0 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0">2023 年 11 月 6 日，DataEase 開源數據可視化分析平台正式發佈 v2.0 版本。DataEase 開源項目創立於 2021 年 1 月，於 2021 年 6 月發佈 v1.0 版本。相比 v1.x 版本，DataEase v2.0 版本<strong><span style="color:#0a7be0">採用了更加輕量級的架構設計</span></strong>，功能模塊在保留原有「儀錶板」模塊的基礎上，<span style="color:#0a7be0"><strong>新增「數據大屏」模塊和「工作台」模塊</strong></span>，同時<strong><span style="color:#0a7be0">引入開源動態數據管理框架 Apache Calcite 來統一數據集的創建與管理</span></strong>，並在嵌入式方面做了擴展，<span style="color:#0a7be0"><strong>支持圖表、儀錶板、數據大屏、設計器等豐富的嵌入場景</strong></span>，力求深入踐行 DataEase「人人可用」的產品設計理念，為用户提供更輕量、更好用、更優雅、更全面的 BI 工具。</p><p style="margin-left:0; margin-right:0">DataEase（<em>https://github.com/dataease</em>）是一款人人可用的開源數據可視化分析工具，它能夠幫助用户快速分析數據並洞察業務趨勢，從而實現業務的改進與優化。DataEase 支持豐富的數據源連接，能夠通過拖拉拽方式快速製作圖表，並且可以方便地與他人分享。截至 2023 年 11 月，DataEase 在代碼託管平台 GitHub 上的 Star 數量已經超過 13,200 個，並多次登陸 GitHub 趨勢榜單。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-950b7a9f8532d628f09bacbc5a767c3185b.png" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px"><span>▲圖 1 DataEase GitHub Star 增長趨勢圖&nbsp;</span></p><p style="margin-left:0; margin-right:0">DataEase 自 v1.0 版本至今，在開源社區獲得了廣泛的安裝基礎，DataEase v1.x 版本的社區累計下載總數已經超過 89,000 次。每天都有新用户認識、下載並使用 DataEase 開源數據可視化分析工具。社區用户通過提交 GitHub Issue、技術交流羣互動、論壇互動等多種方式向 DataEase 項目組反饋各種需求和問題。</p><p style="margin-left:0; margin-right:0">在為用户實現需求、解決問題的過程中，DataEase 的產品研發團隊也意識到，受限於 DataEase v1.x 版本的架構設計，用户的部分需求難以在原有的架構中實現。為了讓 DataEase 變得更好，真正實現「人人可用」的願景，研發團隊自 2023 年 1 月啓動 DataEase 的大規模重構工作，歷經 11 個月的產品開發、測試和改進，DataEase v2.0 版本誕生。</p><p><img alt="" height="280" src="https://static.oschina.net/uploads/space/2023/1106/164717_MQkq_4252687.jpg" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px"><span>▲圖 2 DataEase v2 版本產品功能架構圖</span></p><h1>更輕量</h1><p style="margin-left:0; margin-right:0">在 v1 版本中，DataEase 集成了 Apache Doris 與 Kettle 以滿足數據的同步需求。但在這兩個組件的影響下，DataEase v1 版本的安裝包體積隨着版本更新日漸增大，應用整體更顯笨重，不利於適應更多的終端或場景需求，也難以通過縮減基本功能模塊內存大小的方法來緩解 DataEase 的內存壓力。同時，在 DataEase 的實際使用過程中，Apache Doris 與 Kettle 起到的作用相對較小，且並非不可替代。</p><p style="margin-left:0; margin-right:0">為瞭解決 DataEase v1 版本軟件臃腫的問題，DataEase v2 版本將 Apache Doris 和 Kettle 從 DataEase 中分離出來，並選擇引用其他輕量級的第三方組件來支持 DataEase v2 版本新的功能和架構設計。此舉讓 DataEase 整體應用更加輕便與靈活，同時也為 DataEase v2 版本的全場景支持打下了良好的基礎。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-057c76e0683a7e640bf2779ee754ae988fc.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px"><span>▲ 圖 3 DataEase v1 和 v2 版本安裝包大小對比示意</span></p><h1>更好用</h1><p style="margin-left:0; margin-right:0">作為一款人人可用的開源數據可視化分析工具，DataEase 長期貫徹「易用且好用」的設計理念，並將這一理念延續至 DataEase v2 版本序列。</p><p style="margin-left:0; margin-right:0">深入瞭解用户在 DataEase v1 版本中的軟件使用習慣與可視化應用場景後，DataEase v2.0 版本在軟件的模塊設計方面進行了改進與優化，以提供更加順暢的操作手感與優秀的使用體驗。</p><p style="margin-left:0; margin-right:0">DataEase v2.0 版本在保留原有的「儀錶板」模塊的基礎上，新增了「數據大屏」模塊。DataEase 為這兩個模塊提供了不同的功能特性，讓用户可以更精確地選擇適合自己需求的模塊，並且更高效地完成工作任務。</p><p style="margin-left:0; margin-right:0">通過「儀錶板」模塊，用户可以方便快捷地進行數據分析、創建數據報告和簡易數據報表等；而通過「數據大屏」模塊，用户可以創造出更加註重視覺效果的數據大屏，專供顯示器終端展示使用。這種差異化的設計讓產品更具靈活性，旨在更好地滿足用户不同的需求和使用場景。</p><p style="margin-left:0; margin-right:0">同時，DataEase v2.0 版本新增「工作台」模塊，為用户提供個人在 DataEase 中的信息彙總展示。用户可以通過「工作台」模塊查看管理儀錶板或數據大屏的最近使用記錄、我的收藏、我的分享等相關信息，前往 DataEase 模板市場，也可以在「工作台」模塊中快速創建各類資源的便捷入口。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a721b348b8f9a46a32f830fcb09080e4232.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px"><span>▲ 圖 4 DataEase v2.0 版本產品工作原理圖</span></p><p style="margin-left:0; margin-right:0">為了提升軟件在功能交互方面的能力，DataEase v2 版本對大量 v1 版本的功能進行了優化和改進。例如，調整「數據源」模塊的操作流程，讓用户可以快速高效地引用新建數據源或歷史數據源來創建數據集；調整儀錶板和數據大屏設計器的佈局，讓用户可以更簡單、便捷地引入新組件或設計儀錶板。這些改進加強了用户與產品之間的互動，使 DataEase v2 版本更加易用、好用，為用户提供優秀的使用體驗。</p><p style="margin-left:0; margin-right:0"><img alt="" height="754" src="https://oscimg.oschina.net/oscnet/up-b384a2a194282e0c03b0e0cfb10ea6a4eed.jpg" width="1415" referrerpolicy="no-referrer"></p><p><span>▲ 圖 5 DataEase v2.0 版本儀錶板製作界面</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-de21372a3f0b434b7b3c41c508cd8686db9.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px"><span>▲ 圖 6 DataEase v2.0 版本數據大屏製作界面</span></p><h1>更優雅</h1><p style="margin-left:0; margin-right:0">DataEase v2 版本引入了強大的開源動態數據管理框架 Apache Calcite。利用 Apache Calcite 開源框架「允許應用程序使用標準的 SQL 語言查詢多種後端數據源，而無需為每個數據源編寫特定的查詢代碼」的特點，DataEase v2 版本極大地簡化了數據集的創建和管理過程，同時實現了數據集類型的統一，讓用户能夠更輕鬆地進行數據處理和分析操作。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c77d6779e73ff55fcf359e3df86a9f5148c.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px"><span>▲ 圖 7 DataEase v2.0 版本統一數據集類型展示</span></p><h1>更全面</h1><p style="margin-left:0; margin-right:0">隨着 DataEase 用户數量的不斷增加，DataEase 項目組注意到，越來越多的用户需要將 DataEase 無縫嵌入到公司的其他系統中，即越來越多的用户具有 DataEase 的嵌入式集成需求。大部分用户希望將已創建的儀錶板頁面嵌入到其他系統頁面中，以取代原本需要開發的數據可視化頁面。</p><p style="margin-left:0; margin-right:0">針對以上需求，DataEase v2.0 版本在嵌入式方面進行了顯著增強，為用户提供單一圖表嵌入、儀錶板或數據大屏頁面嵌入和設計器嵌入三種嵌入方式，讓用户可以依照自身需求將 DataEase 嵌入其公司系統。這樣一來，用户就可以在自己的工作流程中直接訪問和使用數據可視化分析功能，而無需切換至獨立的應用程序。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb24d4cb3d66a9a7667703862e6b26672df.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px"><span>▲ 圖 8 DataEase v2.0 版本嵌入式方案展示</span></p><p style="margin-left:0; margin-right:0">此外，DataEase 項目組還瞭解到，許多用户在 DataEase 中實際常用的只有基本的數據可視化分析功能，並不需要「系統管理」模塊中一些與他人協作的功能。DataEase 後續還計劃推出基於 Windows 和 Mac 兩種操作系統的桌面版本，供無需開展系統協作的用户免費下載並使用，力求在降低 DataEase 安裝和使用門檻的同時，讓軟件的使用更加輕便。</p><p style="margin-left:0; margin-right:0">目前，DataEase v2.0 版本還未完全覆蓋 v1.18.x 版本的全部功能。但在輕量級的全新架構下，DataEase v2 版本將更快、更好地實現之前 v1 版本中已實現的，以及難以實現的場景。DataEase v2 版本將進入按月迭代的軌道，DataEase 項目組也會持續關注大家的反饋，聽取廣大社區用户的建議，不斷完善產品功能和使用體驗。</p><p style="margin-left:0; margin-right:0">需要説明的是，DataEase 不支持直接從 v1.18.x 版本升級到 v2.0.0 版本。但 DataEase v1.18.x 版本的維護和更新將會長期持續進行。未來，DataEase 將並行支持 v2.x 和 v1.18.x 兩個大版本，用户可以根據自身的實際情況選擇使用某個版本，以更好地滿足自己的數據可視化需求。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 07:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265186/dataease-2-0-released</guid>
            <link>https://www.oschina.net/news/265186/dataease-2-0-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | VS Code 史上呼聲最高的特性終於實現；vivo 發佈自研操作系統藍河 (BlueOS)....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2023.10.31-2023.11.05]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 07:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[DHorse 即將支持更多的登錄方式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>現狀</h2><p>在 v1.4.0 版本之前，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F512team%2Fdhorse" target="_blank">DHorse</a>支持的登錄方式有：DHorse 系統本身、Ldap 兩種；但是，既然作為企業級服務，只支持以上兩種方式是不夠的。當下，越來越多的企業使用釘釘和企業微信進行溝通和辦公，支持這兩種登錄方式也勢在必行，此外，還有傳統的 SSO 登錄，在未來的 v1.5.0 的版本里即將支持以上登錄方式。</p><p>下面，簡單介紹一下即將支持的這三種登錄方式。</p><h3>釘釘登錄</h3><p>開啓釘釘登錄，需要具備以下幾個條件：</p><ul><li>需要擁有釘釘後台的管理權限；</li><li>需要創建釘釘應用；</li><li>需要進行 DHorse 的釘釘配置；</li></ul><h3>企業微信登錄</h3><p>開啓企業微信登錄，需要具備以下幾個條件：</p><ul><li>需要擁有企業微信的後台管理權限；</li><li>需要創建企業微信的應用；</li><li>需要配置 DHorse 的企業微信；</li></ul><h3>SSO 登錄</h3><p>CAS 是 SSO 登錄的主流實現者，DHorse 也使用 CAS 登錄來實現 SSO 登錄的功能；</p><p>開啓 SSO 登錄，需要具備以下幾個條件：</p><ul><li>需要企業提供自己的 CAS 服務；</li><li>需要配置 DHorse 的 CAS 登錄；</li></ul><h2>結論</h2><p>為了更好的與企業管理員工方式的多樣性相結合，簡化企業管理，支持儘可能多的登錄方式勢在必行。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265154</guid>
            <link>https://www.oschina.net/news/265154</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[系統清理工具 BleachBit 時隔兩年發佈 v4.6.0]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>BleachBit 4.6.0 現已發佈，這是自 2021 年 11 月 BleachBit 4.4.2 發佈之後的首個主要穩定版更新。BleachBit 是一款開源系統清理工具，可用於 Windows 和 Linux，由 Python 和 GTK 編寫。</p><p><img height="334" src="https://oscimg.oschina.net/oscnet/up-42bc5335f34eaa0c4cc8e570bb998db4da1.png" width="500" referrerpolicy="no-referrer"></p><p>該版本擴展了清理功能，修復了許多錯誤，並更新了翻譯。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleachbit.org%2Fnews%2Fbleachbit-442" target="_blank">自 4.4.2</a>&nbsp;版本以來的更改：</p><ul><li>清理 Firefox 上最近關閉的標籤頁。</li><li>清理基於 Chromium 的瀏覽器中的自動填充數據。</li><li>清理&nbsp;Firefox 的更多內容：AlternativeServices.txt。</li><li>改進對 FileZilla 的支持。</li><li>支持新版本的 GIMP 並添加運行時檢測。</li><li>修復清理 Firefox 時的 AttributeError 和「OperationalError: no such table」 。</li><li>添加 DLL&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbleachbit%2Fbleachbit%2Fsecurity%2Fadvisories%2FGHSA-j8jc-f6p7-55p8" target="_blank">安全</a>漏洞的解決方法。</li><li>製作 chaff 時防止打開其他對話框。</li><li>添加對話框的標題。</li><li>允許翻譯更多字符串。</li><li>改進 CLI 中 --help 的組織。</li><li>僅當設置了--debug 或--preset 時才在 CLI 中顯示調試信息。</li><li>修復了使用巴西葡萄牙語擦除可用空間時發生的崩潰。</li><li>特定於&nbsp;<strong>Linux</strong><ul><li>清理 Mozilla Firefox snap。</li><li>清理 Linux 版 Microsoft Edge。</li><li>清理 Mozilla Firefox、Thunderbird 和 Google Chrome Flatpaks。</li><li>清理 KDE 5 上的最近文檔列表。</li><li>為 KDE 添加&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbleachbit%2Fbleachbit%2Fpull%2F1400" target="_blank">shred context menu</a>。</li><li>在 Firefox 中保留書籤圖標。</li><li>將 xauth 文件保留在 /tmp 中。</li><li>修復「Permission denied: /proc/」。</li><li>在應用程序啓動器中使用品牌圖標。</li><li>修復無效 .desktop 文件的檢測。</li><li>修復錯誤「he child memory-wiping process returned code 9」。</li><li>當以 root 身份使用 Wayland 運行時通知用户。</li><li>修復 ModuleNotFoundError 。</li><li>再次從 Linux 軟件包中刪除 Windows-specific files。</li><li>刪除導致 Python 3.12 span class="credit"&gt; 啓動錯誤的不需要的 SafeConfigParser。</li><li>添加 python3-psutil 依賴項。</li></ul></li><li>特定於&nbsp;<strong>Windows</strong><ul><li>清理更多 Windows 更新。</li><li>修復 Internet Explorer 中的 Windows 重定向。</li><li>修復全屏錯誤。</li><li>國際化 Windows 安裝程序並翻譯為意大利語。</li><li>在安裝程序中添加組件的描述。</li><li>擦除不存在的路徑時不報錯。</li><li>不顯示錯誤&nbsp;"Gtk-CRITICAL **: gtk_text_view_scroll_mark_onscreen"。</li><li>允許 Winapp 的驅動器號後跟文件名。</li><li>將捆綁的 SQLite 從 3.37.2 更新到 3.43.2。</li><li>將 UPX 可執行壓縮器更新到 4.1.0。</li></ul></li><li><strong>Developers</strong><ul><li>參閲&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbleachbit%2Fbleachbit%2Fcompare%2Fv4.4.2...v4.6.0" target="_blank">commits 列表</a>或<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbleachbit%2Fbleachbit%2Fmilestone%2F15" target="_blank">已關閉問題列表</a>。</li><li>Translation 已從 Launchpad 轉移到&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhosted.weblate.org%2Fprojects%2Fbleachbit%2F%23languages" target="_blank">Weblate</a>，後者通過 Git 自動提交更改，進而觸發&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fci.bleachbit.org%2F" target="_blank">CI 構建</a>。這意味着你可以在進行翻譯更改後立即下載 Windows 版本。Weblate 還具有可用性改進和提高質量的功能。</li><li>在 Travis 上安裝&nbsp;depdendency chardet。</li><li>重構。</li><li>使用 make clean 清理更多文件</li></ul></li></ul><p><span style="color:#000000">詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleachbit.org%2Fnews%2Fbleachbit-460" target="_blank">查看官方公告</a>。&nbsp;</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 06:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265152/beachbit-4-6-0-released</guid>
            <link>https://www.oschina.net/news/265152/beachbit-4-6-0-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[李開復旗下 AI 公司發佈 Yi 系列開源大模型，估值超 10 億美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>創新工場董事長兼 CEO 李開復於今年創辦了 AI 大模型創業公司「<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.01.ai%2F" target="_blank">零一萬物</a></u>」。<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2506227176630145" target="_blank">根據 36 氪的獨家報道</a></u>，零一萬物已完成新一輪融資，由阿里雲領投。目前，<strong>零一萬物估值已超 10 億美元，躋身獨角獸行列</strong>。</p><p><strong>該公司已推出&nbsp;Yi-34B 和&nbsp;Yi-6B 兩個開源大模型</strong>，號稱對學術研究完全開放，同步開放免費商用申請。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4ab5886e43554fd3233305e7c8264217507.png" referrerpolicy="no-referrer"></p><blockquote><p>Hugging Face：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B" target="_blank">https://huggingface.co/01-ai/Yi-34B</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-6B" target="_blank">https://huggingface.co/01-ai/Yi-6B</a></p><p>ModelScope：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-34B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-34B/summary</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-6B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-6B/summary</a></p><p>GitHub：<br><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F01-ai%2FYi" target="_blank">https://github.com/01-ai/Yi</a></p></blockquote><p><span>據介紹，Yi 目前擁有 200K 上下文窗口，可處理約 40 萬字的文本——這也是目前全球大模型中最長的上下文窗口。其中 Yi-34B 在 Hugging Face 英文測試榜單中位列第一，在 C-Eval 中文能力排行榜中超越所有開源模型。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e1c843e9962b9e9aecc13487da3270520c.png" referrerpolicy="no-referrer"><br><em>Hugging Face Open LLM Leaderboard (pretrained) 大模型排行榜，Yi-34B 高居榜首 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-03d63eae8034e7ca5d0e28148b2fb94dc3f.png" referrerpolicy="no-referrer"><br><em>C-Eval 排行榜:公開訪問的模型，Yi-34B 全球第一 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e5919449029e62b8bf111322f96af0dcb3.png" referrerpolicy="no-referrer"></p><p>Yi-34B 和 Yi-6B 的表現：</p><ul><li><strong>C-Eval 中文能力排行榜</strong>：Yi-34B 在 C-Eval 中文能力排行榜上超越了所有開源模型，這意味着在中文語言理解和生成方面，Yi-34B 的性能優於其他所有開源的大模型。</li><li><strong>中文綜合能力</strong>：在 CMMLU、E-Eval、Gaokao 等中文評測指標上，Yi-34B 明顯領先於 GPT-4，展現了其在中文語境下的強大理解和應用能力。</li><li><strong>中文問答能力</strong>：在 BooIQ、OBQA 兩個中文問答指標上，Yi-6B 和 Yi-34B 與 GPT-4 的表現水平相當，這表明它們在理解中文問題和提供準確答案方面具有很高的能力。</li><li><strong>超長文本處理</strong>：200K 上下文窗口，Yi-34B 能夠處理大約 40 萬漢字的超長文本輸入，這在處理長篇中文文檔、書籍或報告時尤為重要，能夠理解和生成連貫、準確的中文文本。</li><li><strong>技術創新</strong>：零一萬物自研規模化訓練實驗平台和智能數據處理管線。強大的 AI 基礎設施支持，提高了訓練效率和降低了成本。</li></ul><p>「零一萬物」在官網寫道，他們深信「以大語言模型為突破的 AI 2.0 正在掀起技術、平台到應用多個層面的革命」。根據他們的判斷，AI 2.0 時代將誕生「比移動互聯網大十倍的平台機會」，將把既有的軟件、使用界面和應用重寫一次，改寫用户的交互和入口。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 05:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</guid>
            <link>https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenHarmony 4.0 開發數據：華為貢獻者 1800 名、增刪改代碼 8849882 行]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenHarmony <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW9H8Yyq6-jK-35FnIsafSQ" target="_blank">公佈</a></u>了關於 4.0 Release 版本的開發數據。</p><p>據介紹，<u><a href="https://www.oschina.net/news/264989/openharmony-4-0-released">OpenAtom OpenHarmony 4.0 Release 版本</a></u>於 10 月 27 日發佈，經過了 32 周的開發週期。</p><p>在此期間，有 65499 個 Committs 進入了版本。共有 2220 位貢獻者為 4.0 Release 版本做出了貢獻。其中，華為貢獻者 1800 名，累計 2000+名，共增刪改代碼 8849882 行，佔比 80.03%。</p><p>華為的 5 名頂級貢獻者和華為以外的 15 名頂級貢獻者如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb921b7f488f8d9d32c10bfb308ed11d6fe.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">以下的單位參與了 OpenHarmony 4.0 Release 版本的工作，較活躍的如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-baa6184ec3c30845abf2d57faddb063630b.png" referrerpolicy="no-referrer"></p><p>不同單位在不同子系統的貢獻比例：</p><p>華為的貢獻覆蓋 30 多個核心子系統，其他頂級共建單位在各領域的貢獻情況如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9045d86ad3cdc74208e832cc5a7cc327d37.png" referrerpolicy="no-referrer"></p><p>這些單位對 OpenHarmony 4.0 Release 版本的工作主要集中在以下領域：</p><p>• 深開鴻的工作主要集中在短距，驅動，XTS，開發工具，ArkUI 子系統中，包括藍牙&amp;wifi 增強，ArkUI 運行時，ArkUI 組件增強，NAPI 框架生成工具，ALSA 驅動 HDI 插件平台解耦，codec 驅動 HDI 接口，ArkUI XTS 套件支持，RK3568 開發板等特性。</p><p>• 開鴻智谷的工作主要集中在開發樣例，開發板，輕內核子系統中，包括輕內核 queue 讀寫增強，ArkUI 組件集合樣例，場景化仿應用開發（設備管理，通信，數據庫，相機，語音）和 Niobe 開發板等特性。</p><p>• 軟通動力的工作主要集中在 ArkUI，XTS，開發板子系統中，包括 ArkUI 組件（TextInput，TextTimer，邊框）增強，wpt 套件 Reftest 自動化測試，ArkUI 佈局 XTS 套件，UnionPi Tiger 開發板,揚帆致遠開發板等特性。</p><p>• 九聯科技的工作主要集中在開發樣例，芯片內核驅動，HDF 驅動子系統中，包括温濕度傳感器驅動，開發樣例（通知，分佈式賬號管理，資源授權訪問，一多交互等場景），A311D 芯片適配，UnionPi Tiger 開發板適配等特性。</p><p>• 潤開鴻的工作主要集中在芯片開發板，ArkUI，驅動子系統中，包括 arkcompiler 中 arraybuffer 功能增強，啓動流程優化，DAYU210 開發板，Neptune100 開發板適配等特性。</p><p>• 誠邁的工作主要在多模輸入子系統中。</p><p>據稱華為、深開鴻、軟通動力、開鴻智谷分別建設超過 5 萬+行代碼並持續貢獻中，成為 2023 年《百人代碼貢獻單位》。九聯開鴻、潤開鴻、京東、誠邁科技、中科院軟件所、中軟國際持續貢獻中，計劃今年 12 月 31 日前貢獻 5 萬+行功能特性代碼。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 04:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265135</guid>
            <link>https://www.oschina.net/news/265135</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[馬斯克旗下 xAI 發佈首個 AI 大模型產品 Grok]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">馬斯克旗下 xAI 團隊發佈其首個 AI 大模型產品 —— <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.ai%2F" target="_blank">Grok</a>；目前只訓練了 2 個月左右的時間，因此尚處於非常早期的測試階段。</span></p><blockquote><p><span style="color:#000000">Grok 是一款仿照《銀河系漫遊指南》設計的人工智能，可以回答幾乎任何問題，更難能可貴的是，它甚至可以建議你要問什麼問題！</span></p><p><span style="color:#000000">Grok 在回答問題時略帶詼諧和反叛，因此如果你討厭幽默，請不要使用它！</span></p><p><span style="color:#000000">Grok 的一個獨特且根本的優勢是它可以通過 𝕏 平台實時瞭解世界。它還能回答被大多數其他人工智能系統拒絕的尖鋭問題。</span></p></blockquote><p><img height="316" src="https://oscimg.oschina.net/oscnet/up-95e999fb26b9fab921735913d2139b7577d.jpg" width="300" referrerpolicy="no-referrer"></p><p><img height="388" src="https://oscimg.oschina.net/oscnet/up-c1e26f5d404c988b2332dcab2ffaa7becdc.jpg" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Grok 基於&nbsp;xAI 團隊於 11 月發佈的自研大語言模型&nbsp;Grok-1。在&nbsp;xAI 宣佈成立後，項目團隊就用 330 億個參數訓練了一個 LLM 原型（Grok-0），這一<span style="background-color:#ffffff">早期模型</span>自稱與 LLaMA 2 (70B) 能力相當，但只使用了一半的訓練資源。</span></p><p><span style="color:#000000">Grok-1 則在此基礎上改進了推理和編碼能力。Grok-1 是一個基於 Transformer 的自迴歸模型，經過預先訓練以執行 next-token 預測。然後利用人類和早期 Grok-0 模型的廣泛反饋對該模型進行微調，初始 Grok-1 的上下文長度為 8192 個 token。</span></p><p><span style="color:#000000">一些評測結果如下所示：</span></p><p><span style="color:#000000"><img height="238" src="https://oscimg.oschina.net/oscnet/up-78c5896454178aea96eb296a0a2beeb7faf.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img height="96" src="https://oscimg.oschina.net/oscnet/up-ff9e8be5f7abf6322719c422a60352348a7.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Grok-1 也存在一些侷限性，該語言模型不具備獨立搜索網絡的能力，官方建議在 Grok 中部署搜索工具和數據庫可以增強模型的能力和真實性。並警告稱，儘管可以訪問外部信息源，但該模型仍會產生幻覺。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">為了創建 Grok，</span>xAI 團隊還<span style="background-color:#ffffff">構建了一個基於 Kubernetes、Rust 和 JAX 的自定義訓練和推理堆棧。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「</span>Rust 已被證明是構建可擴展、可靠且可維護的基礎架構的理想選擇。它提供高性能、豐富的生態系統，並防止分佈式系統中通常會發現的大多數錯誤。鑑於我們的團隊規模較小，基礎架構的可靠性至關重要，否則維護就會缺乏創新。Rust 讓我們充滿信心，任何代碼修改或重構都可能產生可以在最少監督的情況下運行數月的工作程序。<span style="background-color:#ffffff">」</span></span></p><p><span style="color:#000000">目前&nbsp;<span style="background-color:#ffffff">Grok 僅面向少數美國用户<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrok.x.ai%2F" target="_blank">開放測試</a>。</span></span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><a href="https://www.oschina.net/news/249159/elonmusk-announced-xai" target="_blank">馬斯克宣佈成立 xAI 公司</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265129/xai-grok</guid>
            <link>https://www.oschina.net/news/265129/xai-grok</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[承載微軟跨平台生態之夢的 UWP，正在消亡]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>開發者發現，微軟最新的 Windows&nbsp;11&nbsp;Canary Build 25987 預覽版已經開始提供兩個版本的 XAML Shell 服務，<strong>新的版本直接基於 Win32 + XAML</strong>，曾經被寄予厚望的 UWP 在新版本里已經不見蹤影。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1106/113836_8gF1_2720166.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fthebookisclosed%2Fstatus%2F1720108362275213594" target="_blank">https://twitter.com/thebookisclosed/status/1720108362275213594</a></em></u></p></blockquote><p>據介紹，新增的 dll 名為 ControlCenter.dll，這是控制中心的文件，目前已經同時提供舊版本和新的基於 Win32+XAML 的版本，即用户可以通過 ViveTool 啓用這種新變體。</p><p>一般來説能被發現已經可以通過 ViveTool 啓用，那麼這個新變化基本已經開發完畢，後續就會分別面向不同的用户進行測試，收集運行數據。</p><p>延伸閲讀</p><ul><li><strong><a href="https://www.oschina.net/news/165300/ms-officially-deprecates-uwp">微軟正式棄用 UWP</a></strong></li><li><strong><a href="https://www.oschina.net/news/149997/winui-3-uwp-win32-apps-windows11">WinUI 3 仍專注於 Win32 應用，暫無面向 UWP 的計劃</a></strong></li><li><strong><a href="https://www.oschina.net/news/107123/microsofts-uwp-app-dream-is-dead">Win32 應用進入微軟應用商店，UWP 怎麼辦？</a></strong></li><li><strong><a href="https://www.oschina.net/news/149797/ms-store-xmal">Microsoft Store 完全使用 XAML 以替代 HTML，Visual Studio 預計年底上架商店</a></strong></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265128</guid>
            <link>https://www.oschina.net/news/265128</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國內最大開源模型發佈，650 億參數無條件免費商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">元象 XVERSE 公司宣佈開源 650 億參數高性能通用大模型 XVERSE-65B，無條件免費商用。</span></p><p><span style="color:#000000">XVERSE-65B 採用了 Transformer 網絡結構，模型通過訓練了 2.6 萬億個令牌的高質量多樣化數據，包含了 40 多種語言。具有 16K 的上下文長度，適用於多輪對話、知識問答和摘要等任務。</span></p><p><span style="color:#000000">主要特點如下:</span></p><ul><li><span style="color:#000000"><strong>模型結構</strong>：XVERSE-65B 使用主流 Decoder-only 的標準 Transformer 網絡結構，支持 16K 的上下文長度（Context Length），能滿足更長的多輪對話、知識問答與摘要等需求，模型應用場景更廣泛。</span></li><li><span style="color:#000000"><strong>訓練數據</strong>：構建了 2.6 萬億 token 的高質量、多樣化的數據對模型進行充分訓練，包含中、英、俄、西等 40 多種語言，通過精細化設置不同類型數據的採樣比例，使得中英兩種語言表現優異，也能兼顧其他語言效果。</span></li><li><span style="color:#000000"><strong>分詞</strong>：基於 BPE（Byte-Pair Encoding）算法，使用上百 GB 語料訓練了一個詞表大小為 100,534 的分詞器，能夠同時支持多語言，而無需額外擴展詞表。</span></li><li><span style="color:#000000"><strong>訓練框架</strong>：訓練中採用 FlashAttention2 加速計算，3D 並行基礎上採用虛擬流水線（virtual pipeline）技術，降低較長流水線和 16k 上下文窗口產生的過高氣泡率，在千卡集羣的峯值算力利用率達到業界前列。同時通過集羣基礎設施運營、資源調度、訓練框架和調度平台協同等持續優化，打造出高穩定、低中斷、強容錯的訓練系統，將每週有效訓練率提升至 98.6%。</span></li></ul><p><span style="color:#000000"><strong>評測結果</strong></span></p><p><span style="color:#000000"><img height="454" src="https://oscimg.oschina.net/oscnet/up-2cd1eb2bb0579c1ae7d9b7cdba455e38df6.png" width="500" referrerpolicy="no-referrer">&nbsp;</span></p><blockquote><p><span style="color:#000000">元象 XVERSE 於 2021 年初在深圳成立，主營 AI 與 3D 技術，創始人姚星是前騰訊副總裁和騰訊 AI Lab 創始人。該公司目前累計融資金額超過 2 億美元，投資機構包括騰訊、高榕資本、五源資本、高瓴創投、紅杉中國、淡馬錫和 CPE 源峯等。</span></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265120</guid>
            <link>https://www.oschina.net/news/265120</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[從科幻走向現實，LLM Agent 做到哪一步了？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LLM 洪流滾滾，AI 浪潮席捲全球，在這不斷衝擊行業認知的一年中，Agent 以冉冉新星之態引起開發者側目。OpenAI 科學家 Andrej Karpathy 曾言「OpenAI 在大模型領域快人一步，但在 Agent 領域，卻是和大家處在同一起跑線上。」</p><p>在此背景下，AI 從業者堅信：基於 LLM 的 Agent 會是一個嶄新並且充滿着機會的藍海領域。</p><p>那麼，究竟什麼是 Agent？它的框架工作方式是什麼？現階段存在哪些問題？未來有着怎樣的可能性？本文將分享一些思考。</p><h2>01.什麼是 Agent？</h2><p><img src="https://oscimg.oschina.net/oscnet/up-1f337817172f1c53b43dbdb7e958d8fe1a8.png" alt="" referrerpolicy="no-referrer"></p><p>根據 OpenAI 科學家 Lilian Weng 的一張 Agent 示意圖 [1] 我們可以瞭解 Agent 由一些組件來組成。</p><h3>規劃模塊</h3><ul><li><p>子目標分解：Agent 將目標分為更小的、易於管理的子目標，從而更高效地處理複雜的任務。</p></li><li><p>反省和調整：Agent 可以對過去的行為進行自我批評和自我反思，從錯誤中吸取教訓，並針對未來的步驟進行完善，從而提高最終結果的質量。</p></li></ul><h3>記憶模塊</h3><ul><li><p>短期記憶：在這裏通常是指 in-context learning，即利用提示工程來讓模型進行一定的學習。</p></li><li><p>長期記憶：這為 Agent 提供了長時間保留和召回信息的能力，通常是通過利用外部向量存儲和快速檢索。</p></li></ul><h3>工具使用模塊</h3><p>代理學習調用外部 API 來獲取模型權重中缺失的額外信息（通常在預訓練後很難更改），包括當前信息、代碼執行能力、對專有信息源的訪問等。</p><p>所以當 Agent 接收到一個處理複雜任務的目標時，它會首先進行任務的拆解，並去執行子任務，每次大模型調用之間通過短期記憶連接，使得大模型能理解當前任務處理的狀態。接下來 Agent 需要根據任務的狀態來獲取能夠幫助模型處理任務的信息，這些信息可以是歷史信息以及與任務有關的額外信息。</p><p>由於大模型擁有一定的認知能力，所以在無法精準定義所需信息的情況下，我們可以將與當前狀態有相關性的信息組織起來，讓大模型自主地去摘取它需要的內容。所以，比起基於關鍵字精準的匹配的搜索方法，向量數據庫所擁有的根據語義相關性的模糊搜索在這一點上受到了 Agent 框架的廣泛青睞。通過將長期記憶存放在一個數據庫（向量數據庫或傳統數據庫），並且在執行過程中根據需要進行檢索，模型能夠在任務的執行中獲取執行經驗以及認識到總體的狀態。</p><h2>02.Agent 框架工作方式</h2><p>我們以 AutoGPT 為例，看看一個 Agent 框架具體是如何工作的：</p><p><img src="https://oscimg.oschina.net/oscnet/up-0eb6a67673ebe44e8085f325471e525612a.png" alt="" referrerpolicy="no-referrer"></p><p>AutoGPT[2] 使用 GPT-4 來生成任務、確定優先級並執行任務，同時使用插件進行互聯網瀏覽和其他訪問。AutoGPT 使用外部記憶來跟蹤它正在做什麼並提供上下文，使其能夠評估其情況，生成新任務或自我糾正，並將新任務添加到隊列中，然後對其進行優先級排序。</p><p>另一個著名的項目 babyagi[3] 也是採取類似工作的方式。Agent 與一般的 LLM 最大的不同點在於，LLM Agent 通常根據任務的總體目標來去指定以及編排子目標，而 LLM 通常是作為一個被調用的工具，在一個工作流中擔任一個具體任務的執行者。</p><h2>03.LLM Agent 現階段出現的問題</h2><p>由於一些 LLM（GPT-4）帶來了驚人的自然語言理解和生成能力，並且能處理非常複雜的任務，一度讓 LLM Agent 成為滿足人們對科幻電影所有憧憬的最終答案。但是在實際使用過程中，大家逐漸發現了通往通用人工智能的道路並不是一蹴而就的，目前 Agent 很容易在一些情況下失敗：</p><ul><li><p>Agent 會在處理某一個任務上陷入一個循環</p></li><li><p>prompt 越來越長，最終甚至超出最大內容長度</p></li><li><p>記憶模塊的策略沒有給 LLM 某些關鍵的信息而導致執行失敗</p></li><li><p>LLM 由於幻覺問題錯誤使用工具，或者讓事情半途而廢</p></li></ul><p>上述問題隨着大家對於 Agent 的瞭解開始浮出水面，這些問題一部分需要 LLM 自身來解決，另一部分也需要 Agent 框架來進行解決，通用的 Agent 仍需進一步打磨。</p><h2>04.Agent 的展望</h2><p>目前，LLM Agent 大多是處於實驗和概念驗證的階段，持續提升 Agent 的能力才能讓它真正從科幻走向現實。當然，我們也可以看到，圍繞 LLM Agent 的生態也已經開始逐漸豐富，大部分工作都可以歸類到以下三個方面進行探索：</p><h3>Agent 模型</h3><p>AgentBench[4] 指出了不同的 LLM 對於 Agent 的處理能力有很大區別，當前的 gpt-4（0613）版本以極大的優勢領先於同類競品，LLM 本身的邏輯推理能力以及更長的 prompt 處理能力都會是 Agent 中極其重要的因素。</p><p>sToolLLM[5] 則使用輕量級的 LLaMA 向更加複雜的大模型學習理解 API 和使用 API 的能力，希望能夠將這種能力運用在更輕量的模型上。</p><h3>Agent 框架</h3><p>由 Lilian Weng 列出來的每一個組件都有探索的空間，目前學術探索較多的是利用框架提升 LLM 推理的能力，從 COT[6]、ReAct[7]、Reflexion[8] 等一系列方法，都是在不改變大模型的方法下，利用 prompt 去提升大模型的理性。關於記憶和搜索，目前普遍是將內容存儲在數據庫和搜索引擎中，Refexion 認為可以將執行過程中的觀察以軌跡的形式存儲在短期記憶中，而將接受反饋後的評估和自我反省總結的經驗放在長期記憶中。在其他方向，AutoGen[9] 也在探索多智能體之間的通信與協作。</p><h3>Agent 應用</h3><p>實現真正意義上的 Agent 道阻且長，因為現實世界具有太多不確定性。在特定、具體的可控環境下，Agent 便可以如工廠中實現一道道供需的機器人一般，針對更多的場景特點進行針對性的設計，從而更好的去完成一些特定的任務，達到預期的效果。</p><p>MetaGPT[10] 是一個針對軟件開發場景的 Agent，針對這一具體場景設計了各種具有不同技能的角色協作完成這一任務。Voyager[11] 是一個可以在 Minecraft 中可以進行自主探索、學習技能，並且會合成道具的 Agent。VoxPoser 結合了 RGB-D 信息以及 LLM 的推理能力後，可以完成更多複雜的機器人抓取操作。當下，Agent 尚不能做到完全可靠，針對更多場景的設計可以保障 Agent 不會在大部分簡單場景下失敗。</p><p>我們置身於一個充滿無限可能性的時刻，人工智能的進步將繼續塑造我們的未來，而 LLM Agent 無疑是這一演進過程中的亮點之一。人們探索人工智能，最終還是希望能夠讓人工智幫助人類完成自己無法做到的複雜任務，而 Agent 恰恰是從自動化走向智能化的一個關鍵的里程碑……</p><h3>參考鏈接</h3><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flilianweng.github.io%2F" target="_blank">https://lilianweng.github.io/</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSignificant-Gravitas%2FAuto-GPT" target="_blank">https://github.com/Significant-Gravitas/Auto-GPT</a></p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyoheinakajima%2Fbabyagi" target="_blank">https://github.com/yoheinakajima/babyagi</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.03688" target="_blank">https://arxiv.org/abs/2308.03688</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.16789" target="_blank">https://arxiv.org/abs/2307.16789</a></p><p>[6]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2201.11903" target="_blank">https://arxiv.org/abs/2201.11903</a></p><p>[7]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a></p><p>[8]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2303.11366" target="_blank">https://arxiv.org/abs/2303.11366</a></p><p>[9]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.08155" target="_blank">https://arxiv.org/abs/2308.08155</a></p><p>[10]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.00352" target="_blank">https://arxiv.org/abs/2308.00352</a></p><p>[11]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.16291" target="_blank">https://arxiv.org/abs/2305.16291</a></p><p>[12]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.05973" target="_blank">https://arxiv.org/abs/2307.05973</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10140821</guid>
            <link>https://my.oschina.net/u/4209276/blog/10140821</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[螞蟻集團百靈大模型通過備案，採用 Transfromer 架構]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 6 日，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jiemian.com%2Farticle%2F10342101_sina.html" target="_blank">界面新聞從螞蟻集團獲悉</a></u>，根據國家七部委聯合公佈的《生成式人工智能服務管理暫行辦法》指導要求，螞蟻百靈大模型已完成備案，基於百靈大模型的多款產品已陸續完成內測，將向公眾開放。</p><p>本次通過備案的是<strong>螞蟻百靈語言大模型，該大模型採用 Transfromer 架構</strong>，基於萬億級 Token 語料訓練而成，支持窗口長度達 32K。</p><p>目前，螞蟻大模型已形成包括大模型底層基礎設施、基礎大模型、行業大模型、應用產品在內的完整技術鏈條。</p><p>在基礎大模型層面，除了本次通過備案的百靈語言大模型，螞蟻集團也在研發百靈多模態大模型，並已內測。</p><blockquote><p><a href="https://www.oschina.net/news/257409/codefuse-ai" target="_blank">螞蟻集團正式開源 CodeFuse 代碼大模型</a><br><a href="https://www.oschina.net/news/246241" target="_blank">螞蟻集團證實正研發語言和多模態大模型，命名「貞儀」</a></p></blockquote><p>國內第二批通過備案的 AI 大模型包括 11 家公司，部分已面向全社會開放服務。加上首批的 10&nbsp;餘個大模型，目前已有超過 20&nbsp;個大模型獲得備案。</p><p>新一批備案名單包括：網易有道（「子曰」大模型）、螞蟻集團（百靈大模型）、面壁智能（「面壁露卡 Luca」）、出門問問（「序列猴子」）、崑崙萬維（「天工」大模型）、美團（模型）、知乎（「知海圖 AI」模型）、月之暗面（moonshot）、金山辦公（WPS AI）、好未來（MathGPT 大模型）等。</p><p>8 月 31 日首批通過備案的 AI&nbsp;大模型包括百度文心一言、百川智能、商湯商量 SenseChat、抖音（雲雀大模型）、智譜 AI（GLM 大模型）、中科院（紫東太初大模型）、上海 MiniMax（ABAB 大模型）、上海人工智能實驗室（書生通用大模型）、「360 智腦」等等。</p><blockquote><p><a href="https://www.oschina.net/news/256949" target="_blank">挑戰 ChatGPT，國產有這 8 款 AI 大模型產品</a></p></blockquote><p>據悉，今年 8 月 15 日正式施行的《生成式人工智能服務管理暫行辦法》 ，提供具有輿論屬性或者社會動員能力的生成式人工智能服務的，應當按照國家有關規定開展安全評估，並按照《互聯網信息服務算法推薦管理規定》履行算法備案和變更、註銷備案手續。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265114</guid>
            <link>https://www.oschina.net/news/265114</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🎁有獎問答 | 程序員如何入門大數據]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4855753_2331281">高手問答第 308 期 —— 程序員如何入門大數據？</a><div class="ui red label horizontal" data-tooltip="置頂">頂</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4855753" class="__user"><span>OSC 噠噠</span></a><span class="org-label org-label--simple primary" data-tooltip="認證官方賬號"><i class="oicon oicon-org"></i></span> 發佈於 10/31 12:14
                    </div><div class="item">閲讀 2K+</div><div class="item collect-btn " data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331281" data-obj-type="2">6</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4855753_2331281#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">7</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手問答</a></div><div class="content" id="articleContent"><div><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>市面上不少公司都在做用户畫像的相關工作，無論是電商行業、金融行業、視頻行業等等，都有這樣的產品。那到底怎麼去定義用户畫像呢？</span></span></span></span></span></span></span></span></span></span></span></div><div>
  &nbsp; 
</div><div><strong>OSCHINA 本期高手問答 (10 月 31 日 - 11 月 6 日) 我們請來</strong><strong>了嘉賓&nbsp;</strong><strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">諸葛子房</a>老師&nbsp;</span></strong><strong>來和大家一起探討關於從 0 到 1 入門用户畫像掌握大數據技術的問題。</strong></div><div>
  &nbsp; 
</div><div><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>可討論的問題包括但不限於：</span></span></span></span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>想入門用户畫像需要掌握哪些技術棧？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>沒有企業的大量用户或者行為數據，普通用户該如何真實地模擬企業級的畫像項目？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>程序員如何入門大數據？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大數據</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>行業都有哪些職位，以及在公司中發揮的作用如何</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大數據行業未來的發展如何，以 ChatGPT&nbsp;為代表的 AI 浪潮是否會讓大數據行業走向</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>沒落</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li></ul><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>有其他相關問題，也歡迎大家積極提問！</span></span></span></span></span></span></span></span></span></span></span></p><hr><h2>嘉賓介紹</h2><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>段小秋，網名：諸葛子房，先後就職於京東和 BAT，在大數據領域有多年工作經驗，也是多個 Apache&nbsp;項目的貢獻者。藍橋杯藍橋雲課《用户畫像案例精講》專欄作者，也是開源項目 DataCompare&nbsp;作者。</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>微信</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>：zhugezifang001，歡迎交流溝通。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>個人</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>主頁：</span></span></span></span></span></span></span></span><a href="https://gitee.com/ZhuGeZiFang" rel="nofollow"><span><span><span><u><span style="color:#1e6fff"><span><span>https://gitee.com/ZhuGeZiFang</span></span></span></u></span></span></span></a></span></span></span></p><p><img height="639" src="https://oscimg.oschina.net/oscnet/up-5e58f5cf142af8e6ec1a3b8c3dc1cef16ec.png" width="500" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>為了鼓勵踴躍提問，會在問答結束後從提問者中抽取 2 名幸運會員贈予《</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户畫像案例精講》專欄電子版！</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="516" src="https://oscimg.oschina.net/oscnet/up-71771b786f7cc1bd0161793b6af70daf066.png" width="310" referrerpolicy="no-referrer"></p><p><img height="574" src="https://oscimg.oschina.net/oscnet/up-c2d9d9ce8dd66a412d3ef791ee45548dc45.png" width="311" referrerpolicy="no-referrer"></p></div><div><div><hr><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户</span></span></span></span></strong></span></span></span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>畫像概念</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户畫像，即：用標籤的方式去描述一個人或者一台手機、一台電腦，有些公司稱之為」用户畫像「，有一些公司稱之為」用户特徵「，其實是一個意思。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>舉個簡單的例子：</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>袁小青，性別：女，年齡：22 歲，職業：時尚編輯，愛好：音樂、拍照，居住地：北京，消費情況：年薪 10w，喜歡的 app：抖音</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="310" src="https://oscimg.oschina.net/oscnet/up-d3e2ad6f2150ece5dd0882380562cb797a7.png" width="488" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>因此我們概念中描述的用户畫像，其實是用標籤的方式對於一個用户、一個賬號、一部手機進行描述。</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="368" src="https://oscimg.oschina.net/oscnet/up-adc4c1c21829279233af14e8d74631dfab4.png" width="400" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户畫像常見標籤</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>既然上面講到了對於用户進行標籤化，那究竟要給用户打哪些標籤呢？如何對標籤進行分類呢？</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>畫像核心標籤以及其分類：</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="589" src="https://oscimg.oschina.net/oscnet/up-9efa6c4c17cb0bd2647c8d303db9def85cc.png" width="868" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户畫像的作用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>1. 個性化推薦</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>在使用一些社區產品、電商產品、短視頻 app、音樂 app 的時候，經常會遇到推薦的場景，根據不同的人推薦不同的內容或者商品。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>這其實是用户畫像其中的一個應用，根據用户查詢用户的標籤數據，來進行推薦用户感興趣的內容</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>2. 營銷圈選 (短信營銷、PUSH 營銷)</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>相信不少用户收到過類似的營銷短信，或者一些 app&nbsp;彈窗，這個也是用户畫像常見的應用場景</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>3. 策略引擎</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>根據用户的標籤展示不同頁面，比如説：北京地區的用户能才能領取北京的優惠券，以及只有高消費值的用户才有淘寶上奢侈品 Luxury 入口的界面。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>4. 算法模型</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>算法模型的訓練，比如説：推薦模型、廣告模型，需要用到畫像數據來優化推薦模型。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>5. 畫像報告</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>不少商業公司會出一些行業報告，比如説下圖的小紅書、鎖屏 app&nbsp;的行業畫像報告；還有我們經常看到的一些個人年度榜單。</span></span></span></span></span></span></span></span></span></span></span></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>大數據技術在用户畫像中的實際應用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>由於</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>畫像涉及到的一些行為數據，包括用户購物行為、觀影行為，一些較為大型一些的公司數據日均都涉及 PB，因此需要處理的數據量非常大。在其中就會用到一些大數據的處理和存儲技術，比如説：Hadoop、Spark、Hbase&nbsp;等等。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>同時隨着業務發展，一些廣告和推薦場景對於實時需求也更加明顯，所以實時數據處理領域，Flink、Kafka 等實時相關技術領域也越來越重要了。</span></span></span></span></span></span></span></span></span></span></span></p><hr><div><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手問答一貫的風格，不歡迎任何與主題無關的討論和噴子。</span></p><p>下面歡迎大家就<span>用户畫像和大數據技術相關</span>問題向&nbsp;<strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">諸葛子房</a></span></strong><span style="color:#000000">老師</span><strong><span style="color:#000000">&nbsp;</span></strong>提問，直接回帖提問既可。</p></div></div></div></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331281" data-obj-type="2">6</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331281" data-obj-type="2" data-url="https://www.oschina.net/question/4855753_2331281"><i class="flag red icon"></i>舉報</a></div></div>
            ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4855753_2331281</guid>
            <link>https://www.oschina.net/question/4855753_2331281</link>
        </item>
        <item>
            <title>
                <![CDATA[MyBatis 分頁插件 PageHelper 6.0.0 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="MyBatis Pagination - PageHelper" src="https://github.com/pagehelper/Mybatis-PageHelper/raw/master/logo.png" referrerpolicy="no-referrer"></p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpagehelper%2FMybatis-PageHelper%2Fblob%2Fmaster%2Fwikis%2Fzh%2FChangelog.md%23600---2023-11-05" target="_blank">6.0.0 - 2023-11-05</a></h3><ul><li>基於 jdk8 適配，6.0 開始不支持 jdk6 和 7，如果有需要可以使用 5.x 版本</li><li>增加異步 count 支持，全局配置<code>asyncCount</code>，默認<code>false</code>，單次設置：<code>PageHelper.startPage(1, 10).enableAsyncCount()</code>; 異步使用獨立連接（事務）查詢，有增刪改操作影響查詢時不適合開啓異步查詢。closed #334</li><li>JSqlParser 默認開啓<span>&nbsp;</span><code>parser.withSquareBracketQuotation(true)</code>，支持 SqlServer<span>&nbsp;</span><code>[]</code></li><li>feat: 在<code>PageInfo</code>類中新增了用以進行數據對象轉換的方法<span>&nbsp;</span><code> &lt;E&gt; PageInfo&lt;E&gt; convert(Page.Function&lt;T, E&gt; function)</code><span>&nbsp;</span><strong>by codeke</strong></li><li><code>CountSqlParser</code>改為接口，允許通過<code>countSqlParser</code>參數替換為自己的實現，支持 #772</li><li><code>dialectAlias</code>支持簡化配置，例如<code>dm=oracle;oracle=oracle9i</code>，直接引用現在的縮寫，不用寫類全名</li><li><code>countColumn</code>添加註入檢測，fixed #686</li><li>增加<code>PageParam</code>類，不內嵌對象（會影響使用），如果想用可以繼承該對象，closed #562</li><li>所有異常信息改為英文提示</li><li>放開<span>&nbsp;</span><code>setLocalPage</code>，支持 #771</li><li>解決<code>sqlserver</code>帶 union sql 解析時處理 order by 錯誤的問題，fixed #768</li><li>優化 total 邏輯，解決指定不分頁查詢，同時指定 order by 時無效的問題，fixed #641</li><li>修改 dialect 實例化邏輯，保證類完成配置後使用，fixed #742</li><li><code>dialectAliasMap</code>改為<code>LinkedHashMap</code>，可以按配置順序進行匹配，fixed #758</li><li>行雲數據庫分頁 BUG 修復<span>&nbsp;</span><strong>by maimaitiyaer_bonc</strong></li></ul><p><span style="background-color:#ffffff; color:#1f2328">該插件目前支持以下數據庫的</span><strong>物理分頁</strong><span style="background-color:#ffffff; color:#1f2328"><span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpagehelper%2FMybatis-PageHelper%2Fblob%2Fmaster%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgithub%2Fpagehelper%2Fpage%2FPageAutoDialect.java" target="_blank">PageAutoDialect</a><span style="background-color:#ffffff; color:#1f2328">:</span></p><pre><code class="language-java">static {
    //註冊別名
    registerDialectAlias("hsqldb",HsqldbDialect.class);
    registerDialectAlias("h2",HsqldbDialect.class);
    registerDialectAlias("phoenix",HsqldbDialect.class);
    
    registerDialectAlias("postgresql",PostgreSqlDialect.class);
    
    registerDialectAlias("mysql",MySqlDialect.class);
    registerDialectAlias("mariadb",MySqlDialect.class);
    registerDialectAlias("sqlite",MySqlDialect.class);
    
    registerDialectAlias("herddb",HerdDBDialect.class);
    
    registerDialectAlias("oracle",OracleDialect.class);
    registerDialectAlias("oracle9i",Oracle9iDialect.class);
    registerDialectAlias("db2",Db2Dialect.class);
    registerDialectAlias("as400",AS400Dialect.class);
    registerDialectAlias("informix",InformixDialect.class);
    //解決 informix-sqli #129，仍然保留上面的
    registerDialectAlias("informix-sqli",InformixDialect.class);
    
    registerDialectAlias("sqlserver",SqlServerDialect.class);
    registerDialectAlias("sqlserver2012",SqlServer2012Dialect.class);
    
    registerDialectAlias("derby",SqlServer2012Dialect.class);
    //達夢數據庫,https://github.com/mybatis-book/book/issues/43
    registerDialectAlias("dm",OracleDialect.class);
    //阿里雲 PPAS 數據庫,https://github.com/pagehelper/Mybatis-PageHelper/issues/281
    registerDialectAlias("edb",OracleDialect.class);
    //神通數據庫
    registerDialectAlias("oscar",OscarDialect.class);
    registerDialectAlias("clickhouse",MySqlDialect.class);
    //瀚高數據庫
    registerDialectAlias("highgo",HsqldbDialect.class);
    //虛谷數據庫
    registerDialectAlias("xugu",HsqldbDialect.class);
    registerDialectAlias("impala",HsqldbDialect.class);
    registerDialectAlias("firebirdsql",FirebirdDialect.class);
    //人大金倉數據庫
    registerDialectAlias("kingbase",PostgreSqlDialect.class);
    // 人大金倉新版本 kingbase8
    registerDialectAlias("kingbase8",PostgreSqlDialect.class);
    //行雲數據庫
    registerDialectAlias("xcloud",CirroDataDialect.class);
    
    //openGauss 數據庫
    registerDialectAlias("opengauss",PostgreSqlDialect.class);
    
    //註冊 AutoDialect
    //想要實現和以前版本相同的效果時，可以配置 autoDialectClass=old
    registerAutoDialectAlias("old",DefaultAutoDialect.class);
    registerAutoDialectAlias("hikari",HikariAutoDialect.class);
    registerAutoDialectAlias("druid",DruidAutoDialect.class);
    registerAutoDialectAlias("tomcat-jdbc",TomcatAutoDialect.class);
    registerAutoDialectAlias("dbcp",DbcpAutoDialect.class);
    registerAutoDialectAlias("c3p0",C3P0AutoDialect.class);
    //不配置時，默認使用 DataSourceNegotiationAutoDialect
    registerAutoDialectAlias("default",DataSourceNegotiationAutoDialect.class);
}</code></pre><p style="color:#656d76; text-align:start">如果你使用的數據庫不在這個列表時，你可以配置<span>&nbsp;</span><code>dialectAlias</code><span>&nbsp;</span>參數。</p><p style="color:#656d76; text-align:start">這個參數允許配置自定義實現的別名，可以用於根據 JDBCURL 自動獲取對應實現，允許通過此種方式覆蓋已有的實現，配置示例如（多個配置時使用分號隔開）：</p><pre><code class="language-xml">&lt;property name="dialectAlias" value="oracle=com.github.pagehelper.dialect.helper.OracleDialect"/&gt;
&lt;!-- 6.0 支持下面的引用方式，引用 Oracle9iDialect.class 的實現 --&gt;
&lt;property name="dialectAlias" value="oracle=oracle9i"/&gt;
&lt;!-- 6.0 支持下面的引用方式，達夢使用 oracle 語法分頁，簡化類全名寫法 --&gt;
&lt;property name="dialectAlias" value="dm=oracle"/&gt;</code></pre><p><strong>PageHelper Spring Boot Starter 發佈 2.0.0</strong></p><h2><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpagehelper%2Fpagehelper-spring-boot%23v200---2023-11-05" target="_blank">v2.0.0 - 2023-11-05</a></h2><ul><li>升級 PageHelper 到 6.0.0，支持異步 count 等功能，詳細查看<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpagehelper%2FMybatis-PageHelper%2Freleases%2Ftag%2Fv6.0.0" target="_blank">6.0</a></li><li>升級 MyBatis 到 3.5.15</li><li>升級 springboot 到 2.7.17</li><li>新增參數<span>&nbsp;</span><code>asyncCount</code>，增加異步 count 支持，默認<code>false</code>，單次設置：<code>PageHelper.startPage(1, 10).enableAsyncCount()</code>;</li><li>新增參數<span>&nbsp;</span><code>countSqlParser</code>，<code>CountSqlParser</code>改為接口，允許通過<code>countSqlParser</code>參數替換為自己的實現</li></ul><p style="color:#1f2328; text-align:start">在 pom.xml 中添加依賴：</p><pre><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;
  &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;
  &lt;version&gt;2.0.0&lt;/version&gt;
&lt;/dependency&gt;</code></pre></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265110/mybatis-pagehelper-6-0-0</guid>
            <link>https://www.oschina.net/news/265110/mybatis-pagehelper-6-0-0</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲幾何內核開源平台 —— OpenGeometry 開源社區正式發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 5 日，由廣東省工業和信息化廳、廣東省科學技術廳、廣東省教育廳、深圳市人民政府主辦，工業和信息化部第五研究所、廣東省數字化學會承辦，深圳市工業和信息化局、深圳市龍崗區人民政府、深圳市福田區人民政府協辦的 2023 工業軟件生態大會在廣東省深圳市召開。</p><p>在大會主論壇上，國內備受關注的雲幾何內核開源平台——OpenGeometry 開源社區正式發佈。</p><p><img src="https://static.oschina.net/uploads/space/2023/1106/104536_bRwO_2720166.png" referrerpolicy="no-referrer"></p><p>據介紹，OpenGeometry Group（簡稱 OGG）是由數字化工業軟件聯盟孵化，並由開元幾何（深圳）科技有限公司作為服務公司運營的開源項目。OpenGeometry 開源社區將通過搭建雲幾何內核的開源軟件開發平台，構建新一代工業軟件的核心「根」技術，為工業軟件的產品研發提供支持，並帶動上下游廠商、服務商等合作伙伴共同參與，最終形成產業鏈協同發展的良性循環。</p><p>OpenGeometry 開源社區表示，未來將積極與科研院校、工業軟件廠商、工業軟件應用企業、開發者等合作伙伴進行廣泛的技術交流和合作，引進國內外最先進的技術、吸引頂尖的人才，引入數字化工業軟件聯盟的生態資源，深入電子、汽車、裝備製造等行業應用中進行場景化聯合研發，真正做到以高質量的技術更好地服務產業實體經濟。</p><div>
 北師大港浸大的單肖文教授代在會上表示，OpenGeometry 開源社區對中國工業軟件界意義很大，是構築工業軟件的「根」，只有「根」扎得深，工業軟件的樹才能枝繁葉茂。
</div></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265108</guid>
            <link>https://www.oschina.net/news/265108</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[輕鬆理解 Transformers (3): Feed-Forward Layer 部分]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>編者按：隨着人工智能技術的不斷髮展 Transformer 架構已經成為了當今最為熱門的話題之一。前饋層作為 Transformer 架構中的重要組成部分，其作用和特點備受關注。本文通過淺顯易懂的語言和生活中的例子，幫助讀者逐步理解 Transformers 中的前饋層。</p><p>本文是 Transformers 系列的第三篇。作者的觀點是：前饋層在 Transformer 架構中扮演着至關重要的角色，它能夠有效地提高計算效率，同時也是集體智慧的體現。</p><p>文章作者首先介紹了前饋層的基本結構，它由全連接層組成，進行線性變換和線性計算。但也存在侷限性，不能進行復雜的非線性變換。所以前饋層需要激活函數（如 ReLU）進行非線性轉換，增強網絡的表達能力。為防止模型僅記憶數據特徵而不具備推理能力，需要使用正則化技術如 dropout。相信通過本文的閲讀，讀者將對 Transformer 中的前饋層有更深入的理解。</p><p>隨着深度學習在語音、圖像、自然語言處理等領域取得突破，人工智能或許正向着真正的通用人工智能邁進。但要培養通用人工智能，我們還需不斷深入理解其中的原理和相關機制。</p><p>以下是譯文，enjoy！</p></blockquote><p><strong>作者 | Chen Margalit</strong></p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fchen-margalit%2F" target="_blank">https://www.linkedin.com/in/chen-margalit/</a></strong></p><p><strong>編譯 | 嶽揚</strong></p><p><em><strong>本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。</strong></em></p><p><em>原文鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftowardsdatascience.com%2Fsimplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9" target="_blank">https://towardsdatascience.com/simplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9</a></em></p><p>本節將介紹前饋層（Feed-Forward layer），這是大多數深度學習架構中的基礎元素。在有關深度學習的常見話題交流時，一般都會強調它們在構造 Transformer 架構中的重要作用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a856aacefd53ae8070b810c099e0da6711.png" alt="" referrerpolicy="no-referrer"><em>原論文中的圖片[1]</em></p><p>前饋全連接層（feed-forward linear layer）基本上就是一堆神經元，每個神經元都與其他神經元相連接。請看下圖，其中 a、b、c 和 d 是神經元。這些神經元包含了一些 input（即一些我們想要理解的數據（像素值（pixels）、詞嵌入（word embeddings）等））。它們與編號為 1 的神經元相連。每兩個神經元之間的連接都有不同的連接權重值（connection strength）。例如，a-1 是 0.12，b-1 是-0.3，等等。實際上，左列中的所有神經元都與右列中的所有神經元相連。但是為了清晰起見，我沒有在圖像中展示全部的連接，你需要了解這一情況。就像圖中有 a-1 一樣，還應該有 a-2、b-2、c-2、d-3 等。兩個神經元之間的每個連接都有不同的「連接權重」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f139aa760b0e5733e14a61f50803820e023.png" alt="" referrerpolicy="no-referrer"></p><p><em>該圖由原文作者繪製</em></p><p>該架構有兩點值得注意：</p><ol><li>如前所述，每個節點（神經元）都與其他節點相連。所有的 a、b、c、d 都與其他神經元（1、2、3）相連。可以將這幅圖像看作是一條軍隊指揮鏈。1、2、3 是指揮官。他們從士兵 a、b、c、d 那裏得到情報。a 知道某件事情的一些細節，但它的情報不夠全面。1 知道的就更多了，因為它能夠從 a、b、c 和 d 那裏同時得到情報。2 和 3 也是指揮官，同樣從 a、b、c、d 那裏獲取情報。這些指揮官（1、2、3）也會向更高級的指揮官傳遞報告。在他們之後的指揮官既從 a、b、c、d 那裏得到情報，也從 1、2、3 那裏得到情報，因為下一層（每列神經元為一層）也是以完全相同的方式進行全連接的。因此，首先要明白的是， 1 的情報比 a 更全面，而下一層指揮官的情報也比 1 更全面。</li><li>第二點需要注意的是，每個節點與下一層的每個其他節點之間的連接權重是不同的。a-1 是 0.12，b-1 是-0.3。我在這裏給出的數字顯然是虛構的，但它們也是在合理的範圍內，並且它們都是自動學習調整的參數（learned parameters）（例如，它們在訓練過程中會發生變化）。把這些數字看作是 1 對 a、b 等的影響程度。從 1 號指揮官的角度來看，a 的情報有一定的可信度。但不應該想當然地相信他説的每一句話，可以選擇性地相信他説的某些話。b 則截然不同。這個節點通常會低估它接收到的輸入（情報）的重要性，就像一個悠閒的人一樣。「這是一隻 tiger 嗎？不，只是一隻 big cat。」 這是對發生的事情的過度簡化，但重要的是要注意這一點：<strong>每個神經元都掌握着一些 input（無論是原始輸入還是經過處理的 input）並進行處理後將其傳遞下去。</strong></li></ol><p>你知道「傳話遊戲」嗎？你和其他 10 個人坐成一排，然後你向下一個人耳語一個詞，比如説「Pizza」。第 2 個人聽成了類似「Pazza」的詞，於是他們把「Pazza」傳給了第 3 個人。第 3 個人聽成了 「Lassa」（畢竟是耳語），於是他把 「Lassa」傳給了第 4 個人。第 4 個人聽成了 「Batata」，於是他又轉述了 「Batata」，以此類推。當你問第 10 個人他聽到了什麼？結果他回答「Shambala」，我們是怎麼從「Pizza」到「Shambala」的？這個遊戲與神經網絡的區別在於，每個人都會對信息進行處理。第二個人不會説 「Pazza」，他會説「Pazza 是意大利菜，很好吃」。第三個人會説：「Lassa 是一道意大利菜，在全世界都很常見」，等等。每個人（層）都會補充一些他們希望有用的東西。</p><p>基本情況就是這樣。<strong>每個神經元獲得輸入，處理輸入，然後繼續傳遞。</strong> 為了與全連接層（fully connected layer）相匹配，我建議對這個遊戲進行升級：從現在開始，在遊戲中引入多行人，每個人都可以對每一行中的其他人説悄悄話。從每一行的第 2 位開始，每個人都會收到很多人的悄悄話，他們需要了解每個人説的話語的「權重」（重要性），這就是前饋層（Feed Forward Layer）。</p><p><strong>為什麼我們要使用前饋層？因為它們使我們的計算能夠更加有效，可以將其類比為集體智慧的體現。</strong> 講一個關於「猜測一頭牛重量」的故事吧！1906 年，在英國的某個地方，有人把一頭牛帶到一個展覽會上。主持人隨機挑選了 787 名觀覽者，請他們猜測這頭牛的重量。你認為他們猜測的結果會是多少？這頭牛的實際體重是多少呢？</p><p>他們猜測的平均值是 1197 磅（542 公斤）。這些都是隨機抽取的羣眾對牛體重的估計。這個平均猜測值離真實重量相差多遠呢？只有 1 磅差距，也就是 450 克。這頭牛的重量是 1198 磅。這個故事來自這裏[2]，我不確定細節是否準確，但回到本文的主題，我們可以把線性層 <em>（譯者</em><em>注：此處即本文所説的前饋層）</em> 看作是在做類似的事情。通過增加更多的參數、更多的計算（更多的猜測），就可以得到更準確的結果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1dd0ad28fe0fffea90238839fce31188c1e.png" alt="" referrerpolicy="no-referrer"></p><p><em>照片由 Larry Costales[3] 在 Unsplash[4] 上發佈</em></p><p>讓我們試着想象一個真實的使用場景。給神經網絡輸入一張圖片，讓它判斷圖片裏的是蘋果還是橙子。這種架構基於卷積神經網絡（CNN）層，本文不會深入討論這個知識點，因為其超出了本系列文章的範圍。但該層是一個能夠學習和識別圖像中特定模式（specific patterns）的計算層。 <em>（譯者注：這些特定模式的識別有助於網絡進行更準確的分類和判斷，例如判斷圖像中是蘋果還是橙子。）</em> 每一層都能識別更復雜的模式。例如，第一層幾乎不能識別出任何東西，該層只是傳遞原始像素，第二層就能夠識別出垂直線條。如果下一層同時接收到有垂直線條的信息，並從其他神經元那裏聽説還有非常接近的垂直線條。它會將兩者綜合起來進行計算、分析，然後思考：不錯！這是一個角落。這就是從多個來源獲取輸入信息的好處。</p><p>我們可能會認為，進行計算的次數越多，得到的結果就越好。但事實上，並非完全是這樣，但確實有一定的道理。如果我們做更多的計算，諮詢更多人（神經元）的意見，通常就能得出更好的結果。</p><h1><strong>01 激活函數 Activation Function</strong></h1><p>接下來將介紹深度學習中另一個非常重要的基本概念的關鍵組成部分——激活函數，並探討它與 Transformer 的關係，以便更好地理解兩者之間的關聯。</p><p>儘管全連接層（Fully connected layers）的使用非常廣泛，但也存在一個很大的缺點——<strong>它們是線性層（linear layers），只能進行線性變換和線性計算。全連接層可以進行加法和乘法運算，但無法以「創造性」的方式轉換輸入（input）。有時候，僅僅增加計算量是不夠的，需要以完全不同的思考方式來解決問題。</strong></p><p>如果我每天工作 10 個小時，每天賺 10 美元，如果我想更快地存下 1 萬美元，我可以每週工作更多天，或者每天工作更多小時。但是肯定還有其他解決方案，對吧？有很多人不需要他們擁有的錢（我可以更好地利用它），或者我可以找到更高薪的工作等等。解決辦法並不總是千篇一律。</p><p>同理，在本文的情況下，激活函數可以來提供幫助。激活函數能夠幫助我們進行非線性變換（non-linear transformation）。例如，將一個數字列表[1, 4, -3, 5.6]轉換為概率分佈，就是 Softmax 激活函數的作用。該激活函數能夠將這些數字轉換為[8.29268754e-03, 1.66563082e-01, 1.51885870e-04, 8.24992345e-01]這樣的輸出。這 5 個數字相加等於 1。雖然這些數字看起來有些混亂，但 e-03 表示第一個數字（8）在小數點後 3 個零開始（例如 0.00，然後是 82926。實際上該數字是 0.00829268754）。<strong>這個 Softmax 激活函數將整數轉換為 0 到 1 之間的浮點數，轉換後的浮點數仍然保持了原始整數之間的相對大小關係。這種保持相對大小關係的特性在統計學中非常有用。</strong></p><p>還有其他類型的激活函數，其中最常用的之一是 ReLU（修正線性單元）。這是一種非常簡單（同時也非常有用）的激活函數，它能夠將任何負數轉化為 0，而非負數保持不變。非常簡單且實用。如果我將列表[1, -3, 2]輸入 ReLU 函數，會得到[1, 0, 2]。</p><p>在介紹完複雜的 Softmax 之後，你可能會期望一些更復雜的東西，但有人曾經告訴我「Luck is useful」。有了激活函數後，我們就走運了。</p><p>我們之所以需要這些激活函數，是因為非線性關係（nonlinear relationship）無法通過線性計算（全連接層）來表示。如果我每工作一小時就能得到 10 美元，那麼收入就是線性關係。如果我每連續工作 5 個小時，接下來的 5 個小時就能增加 10%，那麼這種關係就不再是線性的了。我的工資不再是工作小時數乘以固定的小時工資。<strong>在文本生成等更復雜的任務中使用深度學習，就是因為我們要建模的關係高度非線性。</strong> 在「我喜歡」之後能出現的詞並不是固定的。</p><p>ReLU 的一大優勢，也許可以解釋它為何被廣泛使用，就是<strong>對大量數據進行計算的成本非常低。</strong> 當神經元數量較少時（比方説幾萬個），計算量並不重要。但是當像大語言模型那樣使用數千億個神經元時，一種更高效的計算方式會帶來巨大差異。</p><h1><strong>02 正則化 Regularization</strong></h1><p>在解釋 Transformer 中如何實現正則化（非常簡單）之前，我們將介紹最後一個概念——dropout，這是一種正則化技術。由於算法是基於數據的，並且它們的任務是儘可能逼近訓練目標，所以對於一個大腦聰明的人來説，有時僅僅記住一點點東西就足夠了。正如我們在學校中所受到的教育，學習複雜的邏輯並不總是有用的，我們有時只需記住我們所見過的，或者記住與之接近的東西。第二次世界大戰是什麼時候發生的？嗯...它受到了第一次世界大戰、經濟危機、人民憤怒等等因素的影響...大約是 1917 年左右...所以我們就説是 1928 年吧。記住確切的日期可能更好。</p><p>可以想象，這對機器學習來説並不是好事。如果我們需要的是已經有答案的問題的答案，我們就不需要這些複雜的技術了。我們需要一個聰明的算法，因為我們無法記住所有的東西。我們需要它進行實時推理，進行思考。<strong>正則化（Regularization）是讓算法僅學習不記憶的一系列技術的總稱。在這些正則化技術中，一種常用的技術就是 dropout。</strong></p><h1><strong>03 Dropout</strong></h1><p>dropout 可以説是一種相當簡單的技術。還記得我們説過全連接層（fully connected layers）是完全連接的嗎？dropout 打破了這種邏輯。dropout 技術將「連接權重（connection strength）」設置為 0，這意味着該連接不會產生任何影響。對於 1 號指揮官來説，連接到士兵「a」的輸入變為 0 時，「a」傳遞的情報會變得完全無用。不回答，不肯定，也不否定。<strong>我們在每一層中使用 dropout 技術時，會隨機選擇一定數量的神經元（由開發者配置），並將它們與其他神經元的連接權重設為 0。</strong> 每次指揮官會被迫忽略不同的士兵，因此無法記住其中任何一個士兵，因為下次可能不會再遇到它們傳遞情報。</p><h1><strong>04 回到 Transformer！</strong></h1><p>現在我們已經掌握了理解 Transformer 中前饋層工作原理所需的所有基礎知識。接下來解釋實現過程就會非常簡單了。It will now be very simple.</p><p><img src="https://oscimg.oschina.net/oscnet/up-d58c4da377e46953ddd77cd2bcb9c4fdd64.png" alt="" referrerpolicy="no-referrer"></p><p><em>圖片來自 Vaswani, A. 等人的論文[5]</em></p><p>在原論文中的架構圖中，前饋線性層只做了四件事情：</p><ul><li><strong>對文本中的每個位置 (用向量表示)，進行逐位置的線性計算。</strong></li><li><strong>對線性運算的輸出應用 ReLU 函數。</strong></li><li><strong>對上一步驟 ReLU 運算的輸出進行再一次線性運算。</strong></li><li><strong>最後，將其添加到第 3 層的輸出中。</strong></li></ul><p>就是這樣。如果你有深度學習領域的相關經驗，那麼理解這一部分對你來説可能很容易。如果你沒有經驗，可能稍顯吃力，但你已經理解了深度學習中一個極為重要的組成部分。</p><p>在下一部分,我們將介紹 Transformer 中的解碼器 (Decoder) 部分相關知識！</p><p><strong>END</strong></p><h1><strong>參考資料</strong></h1><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wondriumdaily.com%2Fthe-wisdom-of-crowds%2F%23%3A%7E%3Atext%3DAn%2520Astonishing%2520Example%2520of%2520the%2520Wisdom%2520of%2520Crowds%26text%3DThe%2520actual%2520weight%2520of%2520the%2Cthat%2520weight%2520was%25201%252C197%2520pounds" target="_blank">https://www.wondriumdaily.com/the-wisdom-of-crowds/#:~:text=An%20Astonishing%20Example%20of%20the%20Wisdom%20of%20Crowds&amp;text=The%20actual%20weight%20of%20the,that%20weight%20was%201%2C197%20pounds</a>.</p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2F%40larry3%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/@larry3?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2Fphotos%2FAhf1ZmcKzgE%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/photos/Ahf1ZmcKzgE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/10141048</guid>
            <link>https://my.oschina.net/IDP/blog/10141048</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[私域管理平台，LinkWeChat V4.9.8 版本發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">LinkWeChat 是國內首個基於企業微信的開源 SCRM，在集成了企微強大的開放能力的基礎上，進一步升級拓展靈活高效的客户運營能力及多元化精準營銷能力，讓客户與企業之間建立強鏈接，幫助企業提高客户運營效率，強化營銷能力，拓展盈利空間，是企業私域流量管理與營銷的綜合解決方案，目前已經受到企業微信的官方推薦和國家級木蘭開源社區進行孵化，同時也是國家工信部重點扶持項目，同時也獲得 2022 年中國開源創新大賽二等獎。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>LinkWeChat v4.9.8 主要的升級內容如下：</strong></p><p><span style="background-color:#ffffff; color:#40485b">1.新客拉羣全面功能全面升級。</span></p><p><img height="1546" src="https://oscimg.oschina.net/oscnet/up-d30b09016eb3d60391627a8d946d2a4a2d0.png" width="2878" referrerpolicy="no-referrer"></p><p><img height="1432" src="https://oscimg.oschina.net/oscnet/up-fd3b292eed49db590d07d6316b8e2d3148e.png" width="2880" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#40485b">2.客羣活碼新增標籤功能。</span></p><p><img height="1528" src="https://oscimg.oschina.net/oscnet/up-f195ef36ba86355f0514250c17935b5fee4.png" width="2872" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 01:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265081/linkwechat-4-9-8-released</guid>
            <link>https://www.oschina.net/news/265081/linkwechat-4-9-8-released</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
