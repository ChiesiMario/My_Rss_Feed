<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-最新資訊]]>
        </title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="https://rsshub.app/oschina/news" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 31 Oct 2023 03:45:15 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[小米免費可商用字體 MiSans L3 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">隨着小米澎湃 OS（Xiaomi HyperOS）的發佈，其設計團隊也對原先提供的可免費商用字體 MiSans&nbsp;進行了更新。本次更新帶來了大量生僻字支持，並符合最新 L3 級別&nbsp;GB18030-2022 國標。</span></p><p><span style="color:#000000">根據介紹，GB18030-2022 強制規範三個實現級別，於 2023 年 8 月 1 日起開始執行。實現級別 1 共 27,584 個漢字；實現級別 2 包含實現級別 1，此外，實現級別 2 還支持《通用規範漢字表》中的沒有包含在實現級別 1 之內的編碼漢字，共計 27,780 個漢字；實現級別 3 包含實現級別 2，此外，實現級別 3 還支持新標準件規定的全部漢字及表 3 中的康熙部首，總計 87,887 個漢字，用於政務服務和公共服務的產品應滿足實現級別 3 的要求。</span></p><p><span style="color:#000000">MiSans 包含級別 1+級別 2，MiSans L3 為級別 3 字庫（該字庫不包含級別 1 和級別 2）。目前，小米提供的多種字體中只有 MiSans L3 滿足新國標要求並增加了大量生僻字支持。</span></p><p><span style="color:#000000"><img height="1081" src="https://oscimg.oschina.net/oscnet/up-9d9e4a6db81c509dd3ee1d3fcdcda093c61.png" width="500" referrerpolicy="no-referrer"></span></p><p><strong><span style="color:#000000">下載地址：</span></strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhyperos.mi.com%2Ffont%2Fdownload" target="_blank">https://hyperos.mi.com/font/download</a></p><p><span style="color:#000000">附字體許可協議：</span></p><blockquote><p><span style="color:#000000">本《MiSans 字體知識產權許可協議》 (以下簡稱「協議」) 是您與小米科技有限責任公司 (以下簡稱「小米」或「許可方」) 之間有關安裝、使用 MiSans 字體 (以下簡稱「MiSans」或「MiSans 字體」) 的法律協議。您在使用 MiSans 的所有或任何部分前，應接受本協議中規定的所有條款和條件安裝、使用 MiSans 的行為表示您同意接受本協議所有條款的約束。否則，請不要安裝或使用 MiSans，並應立即銷燬和刪除所有 MiSans 字體包。</span></p><p><span style="color:#000000">根據本協議的條款和條件，許可方在此授予您一份不可轉讓的、非獨佔的、免版税的、可撤銷的、全球性的版權許可，使您依照本協議約定使用 MiSans 字體，前提是符合下列條件：</span></p><ol><li><span style="color:#000000">您應在軟件中特別註明使用了 MiSans 字體。</span></li><li><span style="color:#000000">您不得對 MiSans 字體或其任何單獨組件進行改編或二次開發。</span></li><li><span style="color:#000000">您不得單獨將 MiSans 字體或其組件對外租賃、再許可、給予、出借或進一步分發字體軟件或其任何副本以及重新分發或售賣。此限制不適用於您使用 MiSans 字體創作的任何其他作品。如您使用 MiSans 字體創作宣傳素材、logo、應用 App 等，您有權分發或出售該作品。</span></li></ol></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 03:13:01 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264234</guid>
            <link>https://www.oschina.net/news/264234</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘋果發佈 M3 系列芯片，採用 3nm 工藝、支持「動態緩存」技術]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>蘋果今天在「來勢迅猛」發佈會上正式推出 M3、M3 Pro、M3 Max 芯片，是首款採用 3 納米工藝技術的 PC 芯片。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-71f73fe69b327c0080613e563857425d4b4.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a5ffd09ef952faf193b698712952791bef6.png" referrerpolicy="no-referrer"></p><p>蘋果介紹稱，M3 系列芯片搭載的新一代圖形處理器實現了 Apple 芯片史上最大幅的圖形處理器架構飛躍。這款圖形處理器不僅速度更快、能效更高，還引入一項全新技術 —— <strong>動態緩存</strong>，同時帶來首次登陸 Mac 的硬件加速光線追蹤和網格着色等全新渲染功能。渲染速度與 M1 系列芯片相比最快可達 2.5 倍。中央處理器搭載的高性能核心和高能效核心比 M1 中的相應核心分別快 30% 和 50%，神經網絡引擎也比 M1 系列芯片上的快 60%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dc04539ba6a94757f1c3fab246b75cd579a.png" referrerpolicy="no-referrer"></p><blockquote><p>M3 配備 8 核 CPU，10 核 GPU，24GB 統一內存，速度最高比 M2 提升 20%；</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-623eac3535af9db850bfb2d64ea6ab5b3dd.png" referrerpolicy="no-referrer"></p><p>M3 Pro 配備 12 核 CPU，18 核 GPU，36GB 統一內存，速度最高比 M2 Pro 提升 10%；</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28da4c8dc357151c24fb01ea6b31a70e3e5.png" referrerpolicy="no-referrer"></p><p>M3 Max 配備 16 核 CPU，40 核 GPU，128GB 統一內存，速度最高比 M2 Max 提升 20%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25db54ce704b69c46fa5dc54117b8d2ca78.png" referrerpolicy="no-referrer"></p></blockquote><p>據介紹，M3 系列芯片中的新一代圖形處理器實現了 Apple 芯片史上最大幅的圖形處理器架構飛躍。不同於傳統圖形處理器，它具備動態緩存功能，因而可對硬件中本地內存的使用進行實時分配。在動態緩存功能的加持下，每項任務對內存的消耗精準符合所需。</p><p>此項業界首創技術對開發者透明，為打造全新圖形處理器架構提供了基石。它大幅提高了圖形處理器的平均利用率，進而給要求更苛刻的專業級 App 及遊戲的表現帶來顯著提升。</p><p>在 M3 系列芯片的支持下，硬件加速光線追蹤功能首度登陸 Mac。光線追蹤技術能夠模擬光線在場景中的表現，從而幫助 App 創造出栩栩如生、逼真的畫面。通過這一功能和全新圖形處理器架構的加成，專業級 App 的運行速度最高可達到 M1 系列芯片的 2.5 倍。</p><p>此外，全新圖形處理器還給 Mac 帶來硬件加速網格着色功能，實現圖形處理能力和能效的雙重提升，更可支持遊戲和對圖形處理要求高的 App 呈現視覺效果更復雜的場景。官方稱，M3 圖形處理器在功耗減半的情況下，即可達到與 M1 相當的性能，而在峯值功耗下更可實現高達 65% 的性能提升。</p><p>M3 家族中的所有芯片均搭載 Apple 芯片標誌性的統一內存架構。這帶來了高帶寬、低延遲，以及無出其右的高能效。此外，M3 芯片支持的內存容量最高達 128GB，這使過去無法在筆記本電腦上處理的工作流成為可能，例如 AI 開發者現可運行包含數十億個參數的規模更大的 Transformer 模型。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4b873d2a11a318754f6315c42b0e6c81f6f.png" referrerpolicy="no-referrer"></p><p>M3、M3 Pro 和 M3 Max 芯片還引入增強型神經網絡引擎，用於加速強大的機器學習（ML）模型。與 M1 系列芯片相比，新的神經網絡引擎帶來最高達 60% 的速度提升，在進一步加速 AI / ML 工作流的同時，還可將數據保留在設備上，以保護用户隱私。</p><p>此外，M3、M3 Pro 和 M3 Max 還支持多種編解碼器，例如 H.264、HEVC、ProRes 和 ProRes RAW 以及 AV1。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 03:04:01 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264233</guid>
            <link>https://www.oschina.net/news/264233</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【直播預告】關於開源創業的 15 件小事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p>只要軟件開源了，就會有人用？</p><p>開源軟件有漏洞，跟作者沒關係？</p><p>開源軟件協議應當選擇最寬鬆的？</p><p style="text-align:left">應該努力地將軟件捐獻給基金會？</p><p>開源後，會有很多人來完善項目？</p><p>開源不是為了錢？</p><p>開源軟件靠服務和捐助就可以賺錢？</p><p><strong>以上七個問題，禪道創始人王春生的回答都是「 NO 」。</strong>他用自己的親身經歷告訴大家，很多我們想當然的事情，其實並非如此。</p><p>11 月 2 日 19:00，OSCHINA 直播——【開源漫談】第 5 期，邀請了三位大咖，請他們來聊一聊開源創業遇到的一些難題。他們分別是：</p><ul><li><strong>高春輝</strong>，中國第一個人站長，卓越網、手機之家、ECSHOP 軟件、《愛壁紙 HD》應用創始人，全球領先級 ip 庫 http://ipip.net 創始人</li><li><strong>王春生</strong>，禪道軟件公司的創始人，二十年的 IT 老兵，14 年的創業者</li><li><strong>朱峯</strong>，津津樂道播客網絡創始人、主播。連續創業者，商業經驗豐富；有多年社區運營經驗；資深開發者</li></ul><p>這次直播，不講大道理，就講講開源創業實務，話題不設限，怎麼選開源協議，要不要把開源項目捐給基金會，出現了負面輿論怎麼「公關」，公司沒錢了去哪裏找錢，怎麼給員工福利，等等，都拿出來講一講。</p><p><strong>直播主題：</strong>關於開源創業的 15 件小事</p><p style="text-align:left"><strong>直播時間：</strong>11 月 2 日（週四） 19:00-20:00</p><p style="text-align:left"><strong>直播平台：</strong>「OSC 開源社區」 視頻號</p><p><strong>主辦方：</strong>開源中國</p><p><span style="background-color:#ffffff; color:#333333">微信掃碼預約直播，歡迎加入 OSC 直播交流羣，一起嘮嗑～</span></p><p><img height="2542" src="https://oscimg.oschina.net/oscnet/up-cb4840eb78bf9005dfd68ff7cb9ce43c4eb.jpg" width="750" referrerpolicy="no-referrer"></p><p><strong>直播福利</strong></p><ul><li><p style="margin-left:0; margin-right:0">互動抽獎：在直播評論區提問，被直播嘉賓回覆的用户可獲 OSC T 恤 1 件，名額不限。</p></li><li><p style="margin-left:0; margin-right:0">福袋抽獎：直播中將有多輪抽獎，參與就有機會獲得 OSC T 恤、筆記本、馬克杯 、前沿技術書籍等。</p></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">我們直播間見吧～</p><div><hr></div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>另外，本次直播得到了諸多社區或組織的大力支持，在此特別表示感謝：</strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>渠成開源社區</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>渠成開源社區由禪道項目管理軟件團隊發起，社區的經營主體為青島渠成開源計算機網絡技術研究中心，是非營利性社會服務活動的社會組織。 渠成開源社區主要面向一線開源軟件生產者、貢獻者、組織者、贊助商和用户，以解決具體實際問題為宗旨，旨在打造以開源軟件為核心紐帶的開源生態系統，真正做到讓每一個優秀的開源軟件都能實現商業化。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.qucheng.cc" target="_blank">www.qucheng.cc</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>禪道</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>禪道是一款開源的全生命週期項目管理軟件，基於敏捷和 CMMI 管理理念進行設計，集產品管理、項目管理、質量管理、文檔管理、組織管理和事務管理於一體，完整地覆蓋了項目管理的核心流程。 禪道自 2009 年發佈至今，累計為國內數十萬計的公司或團隊提供了專業的項目管理工具。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zentao.net%2F" target="_blank">https://www.zentao.net/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>津津樂道博客</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>津津樂道播客成立於 2016 年 2 月，是天津猿行天下科技有限公司旗下的播客品牌。津津樂道播客主創團隊由多位行業資深人士組成，本着分享體驗、傳播經驗的原則，團隊在 IT、科技、旅遊、教育等領域，製作了多檔播客節目，並獲得市場好評。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdao.fm%2F" target="_blank">https://dao.fm/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>IPIP.net &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>IPIP 專注 IP 地理位置以及 IP 畫像數據的研究、整理與發行，我們的主力產品 IP 地理位置數據庫主要基於 BGP/ASN 數據以及遍佈全球的網絡監測點進行城市級 IP 地域數據標註，準確度遠高於國內國外同類產品。 &nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ipip.net%2F" target="_blank">https://www.ipip.net/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>GreatSQL 社區 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>GreatSQL 社區成立於 2021 年，由萬裏數據庫發起，致力於通過開放的社區合作，構建國內自主開源數據庫版本及開源數據庫技術，推動中國開源數據庫及應用生態繁榮發展。GreatSQL 是適用於金融級應用的國內自主開源數據庫，具備高性能、高可靠、高易用性、高安全等多個核心特性，可以作為 MySQL 或 Percona Server 的可選替換，用於線上生產環境，且完全免費併兼容 MySQL 或 Percona Server。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2F" target="_blank">https://greatsql.cn/ </a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>Gitee 倉庫：<a href="https://gitee.com/GreatSQL">https://gitee.com/GreatSQL</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>愛可生開源社區</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>愛可生開源社區，一個有深度的 MySQL 開源社區。社區成立於 2017 年，以開源高質量的運維工具、日常分享技術乾貨內容、數據庫技術佈道為己任；目前開源的產品有：SQL 審核工具 SQLE、分佈式中間件 DBLE 和數據傳輸組件 DTLE。在這裏，你將收穫：高質量的技術內容，企業級數據庫工具及服務，豐富的社區活動。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.actionsky.com%2F" target="_blank">https://opensource.actionsky.com/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>PG 中文社區</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>PostgreSQL 中文社區是一個非盈利的民間組織，目前成員都以志願者身份加入，成立的目的在於構建 PG 數據庫技術生態圈子 (內核、用户培訓機構、廠商、服務商、軟件開發商、高校形成 「業務與利益雙向驅動」 的良性發展生態圈)；幫助企業解決人才培養和企業商用數據庫成本問題，社區會在各運營平台發佈 PostgreSQL 最新信息和 PostgreSQL 相關技術文章，推動 PG 技術在中國的發展。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網鏈接：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.postgres.cn%2Findex.php%2Fv2%2Fhome" target="_blank">http://www.postgres.cn/index.php/v2/home</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>凹語言</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>凹語言是一個面向 WebAssembly 設計的靜態類型編譯型語言，目標是簡化 WASM 應用的開發。目前已經發布 MVP 版本，並提供了在線的純瀏覽器 Playground 和貪吃蛇案例實現。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>主頁： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwa-lang.org" target="_blank">https://wa-lang.org</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>KCL 社區 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>KCL&nbsp;是一個開源的基於約束的記錄及函數語言，作為沙盒項目託管在 CNCF 基金會。KCL 通過成熟的編程語言技術和實踐來改進對大量繁雜配置比如雲原生 Kubernetes 配置場景的編寫，致力於構建圍繞配置的更好的模塊化、擴展性和穩定性，更簡單的邏輯編寫，以及更簡單的自動化和生態工具集成。 &nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkcl-lang.io+GitHub" target="_blank">https://kcl-lang.io GitHub </a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>倉庫：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkcl-lang" target="_blank">https://github.com/kcl-lang</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span><strong>AllData</strong></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>AllData 大數據產品是可定義數據中台，以數據平台為底座，以數據中台為橋樑，以機器學習平台，GPT 平台為框架，提供全鏈路數字化解決方案。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>項目地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falldatacenter%2Falldata" target="_blank">https://github.com/alldatacenter/alldata </a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>社區官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falldata.readthedocs.io%2Fzh%2Fmaster%2F" target="_blank">https://alldata.readthedocs.io/zh/master/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>得物技術</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>得物技術一直以"上海最好的技術團隊"為目標，現已建立上海、北京、杭州三地研發協同與管理機制，實現研發過程數據化、自動化；覆蓋供應鏈、業務支撐、算法、前端等領域，是得物業務背後強有力的技術力量支撐。 &nbsp;&nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2F" target="_blank">https://tech.dewu.com/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>重慶軟件園 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>重慶軟件園位於重慶經開區，佔地 110 萬平方米，佈局四大組團，是重慶市首批軟件產業園 (綜合型)、A 區入選重慶市軟件和信息服務業「滿天星」示範樓宇 (首批)，於 2019 年 9 月 16 日正式開園，堅持「做生態=做產業，做人才=做產業，做服務=做產業」的發展理念，建設集科技、人文、生態、智慧為一體的領軍型軟件園區。聚焦「3+2」產業佈局，實現新一代信息技術產業集羣發展。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>園區聚集軟件類企業近 2000 家，軟件人才近 3 萬人，已登記 4000 多項軟件著作權，研發投入超 50 億，40 餘項專利將獲得科技獎，營收上億企業近 20 家。立足南岸區、重慶經開區優質產業資源，聚焦軟件信息服務業、智能製造、綠色環保 、汽車軟件汽車電子、大健康等產業，推動軟件產業高質量發展，重慶軟件園將全面貫徹落實「滿天星」計劃，力爭到 2026 年成功建成中國軟件名園。 &nbsp;</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>園區官網：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.chongqingpark.com%2F" target="_blank">http://www.chongqingpark.com/</a></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><strong><span><span><span><span><span><span><span style="color:#000000"><span><span>東方瑞通 &nbsp;</span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>東方瑞通成立於 1998 年，是國內較早的 IT 高級技術培訓企業之一，擁有華為、紅帽、微軟、PMI、VMware、Oracle 等 33 餘家國際廠商授權資質，以培養 it 人才為主，目前覆蓋領域：虛擬化、操作系統、網絡、安全、數據庫、IT 管理、軟件開發等細分領域，提供線上，線下交流培訓課程與活動。 </span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span><span>官網鏈接：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.easthome.com" target="_blank">www.easthome.com</a></span></span></span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 02:45:01 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10139755</guid>
            <link>https://my.oschina.net/u/3859945/blog/10139755</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[企業部署 Elasticsearch 因漏洞導致數據泄露，被罰款 5 萬]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify">北京市網信辦依據《中華人民共和國數據安全法》對屬地三家企業<strong>涉嫌存在網絡數據安全違法行為</strong>進行立案調查並作出行政處罰。</p><p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify">據稱，三家企業違反《中華人民共和國數據安全法》第二十七條規定，<strong>未履行數據安全保護義務，<span style="color:#e67e22">部署的 ElasticSearch 數據庫存在未授權訪問漏洞，造成部分數據泄露</span></strong>。</p><p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"><img src="https://static.oschina.net/uploads/space/2023/1031/104106_Il49_2720166.png" referrerpolicy="no-referrer"></p><p>北京市網信辦依據《中華人民共和國數據安全法》第四十五條第一款規定，對三家企業分別作出責令改正，給予警告，<strong>並處 5 萬元罰款的行政處罰，對直接主管人員和其他責任人員處以 1 萬元罰款處罰</strong>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 02:37:01 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264219</guid>
            <link>https://www.oschina.net/news/264219</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ollama —— 在本地啓動並運行大語言模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="project_detail_above_text_link_1" data-tracepid="project_detail_above_text_link"><a style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代 <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p><span style="color:#000000">Ollama 是一款命令行工具，可在 macOS 和 Linux 上本地運行 Llama 2、Code Llama 和其他模型。目前適用於 macOS 和 Linux，並計劃支持 Windows。</span></p><p><span style="color:#000000">Ollama 目前支持近二十多個語言模型系列，每個模型系列都有許多可用的"tags"。Tags&nbsp;是模型的變體，這些模型使用不同的微調方法以不同的規模進行訓練，並以不同的級別進行量化，以便在本地良好運行。量化級別越高，模型越精確，但運行速度越慢，所需的內存也越大。</span></p><p><span style="background-color:#ffffff; color:#1f2328">以下是一些可以下載的開源模型示例：</span></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#1f2328; display:block; font-family:-apple-system,BlinkMacSystemFont,&quot;Segoe UI&quot;,&quot;Noto Sans&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; max-width:100%; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:max-content; word-spacing:0px"><thead><tr><th>Model</th><th>Parameters</th><th>Size</th><th>Download</th></tr></thead><tbody><tr><td style="border-style:solid; border-width:1px">Mistral</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">4.1GB</td><td style="border-style:solid; border-width:1px"><code>ollama run mistral</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2</code></td></tr><tr><td style="border-style:solid; border-width:1px">Code Llama</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run codellama</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2 Uncensored</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2-uncensored</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2 13B</td><td style="border-style:solid; border-width:1px">13B</td><td style="border-style:solid; border-width:1px">7.3GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2:13b</code></td></tr><tr><td style="border-style:solid; border-width:1px">Llama 2 70B</td><td style="border-style:solid; border-width:1px">70B</td><td style="border-style:solid; border-width:1px">39GB</td><td style="border-style:solid; border-width:1px"><code>ollama run llama2:70b</code></td></tr><tr><td style="border-style:solid; border-width:1px">Orca Mini</td><td style="border-style:solid; border-width:1px">3B</td><td style="border-style:solid; border-width:1px">1.9GB</td><td style="border-style:solid; border-width:1px"><code>ollama run orca-mini</code></td></tr><tr><td style="border-style:solid; border-width:1px">Vicuna</td><td style="border-style:solid; border-width:1px">7B</td><td style="border-style:solid; border-width:1px">3.8GB</td><td style="border-style:solid; border-width:1px"><code>ollama run vicuna</code></td></tr></tbody></table><blockquote><p><span style="color:#000000">注意：需要至少有 8 GB 的 RAM 來運行 3B 模型，16 GB 的 RAM 來運行 7B 模型，32 GB 的 RAM 來運行 13B 模型。</span></p></blockquote></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 02:29:01 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/ollama</guid>
            <link>https://www.oschina.net/p/ollama</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 工作流引擎 FlowLong]]>
            </title>
            <description>
                <![CDATA[<img src="https://foruda.gitee.com/images/1693470775312764207/27440c57_12260.png" alt="flowlong" width="100px" height="113px" referrerpolicy="no-referrer"><h1><a id="user-content-項目介紹" class="anchor" href="https://gitee.com/aizuda/flowlong#%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D"></a>項目介紹</h1><p>FlowLong🐉飛龍工作流</p><ul><li>項目説明  <code>flowlong</code> 中文名 <code>飛龍</code> 在天美好願景！</li></ul><blockquote><p>⭕本項目採用 <code>AGPL</code> 開源協議（抄襲牟利索賠 100 萬），</p></blockquote><blockquote><p>使用必須遵守國家法律法規，⛔不允許非法項目使用，後果自負❗</p></blockquote><p><a href="https://gitee.com/aizuda/flowlong/issues/I7XGP5">使用源碼登記入口</a></p><p><a href="https://flowlong.gitee.io/" rel="nofollow">打開官方開發文檔</a></p><p><a href="https://flowlong.gitee.io/flowlong-designer" rel="nofollow">點擊設計器在線演示</a></p><p><a href="https://gitee.com/flowlong/flowlong-designer">點擊設計器源碼下載</a></p><p>英文字母 <code>flw</code> 為 <code>flowlong workflow</code> 飛龍工作流的縮寫</p><p>🚩中國特色流程操作概念</p><table><thead><tr><th>支持功能</th><th>功能描述</th><th>完成程度</th></tr></thead><tbody><tr><td>順序會籤</td><td>指同一個審批節點設置多個人，如 A、B、C 三人，三人按順序依次收到待辦，即 A 先審批，A 提交後 B 才能審批，需全部同意之後，審批才可到下一審批節點。</td><td>✅</td></tr><tr><td>並行會籤</td><td>指同一個審批節點設置多個人，如 A、B、C 三人，三人會同時收到待辦任務，需全部同意之後，審批才可到下一審批節點。</td><td>✅</td></tr><tr><td>或籤</td><td>一個流程審批節點裏有多個處理人，任意一個人處理後就能進入下一個節點</td><td>✅</td></tr><tr><td>抄送</td><td>將審批結果通知給抄送列表對應的人</td><td>✅</td></tr><tr><td>駁回</td><td>將審批重置發送給某節點，重新審批。駁回也叫退回，也可以分退回申請人、退回上一步、任意退回等</td><td>✅</td></tr><tr><td>分配</td><td>允許用户自行決定任務轉辦、委派、主辦，及其它</td><td>✅</td></tr><tr><td>轉辦</td><td>A 轉給其 B 審批，B 審批後，進入下一節點</td><td>✅</td></tr><tr><td>委派</td><td>A 轉給其 B 審批，B 審批後，轉給 A，A 審批後進入下一節點</td><td>✅</td></tr><tr><td>跳轉</td><td>可以將當前流程實例跳轉到任意辦理節點</td><td>✅</td></tr><tr><td>拿回</td><td>在當前辦理人尚未處理文件前，允許上一節點提交人員執行拿回</td><td>✅</td></tr><tr><td>撤銷</td><td>流程發起者可以對流程進行撤銷處理</td><td>✅</td></tr><tr><td>加簽</td><td>允許當前辦理人根據需要自行增加當前辦理節點的辦理人員</td><td>✅</td></tr><tr><td>減籤</td><td>在當前辦理人操作之前減少辦理人</td><td>✅</td></tr><tr><td>認領</td><td>公共任務認領</td><td>✅</td></tr><tr><td>已閲</td><td>任務是否查看狀態顯示</td><td>✅</td></tr><tr><td>催辦</td><td>通知當前活動任務處理人辦理任務</td><td>✅</td></tr><tr><td>溝通</td><td>與當前活動任務處理人溝通</td><td>✅</td></tr><tr><td>終止</td><td>在任意節點終止流程實例</td><td>✅</td></tr></tbody></table><h1><a id="user-content-貢獻力量" class="anchor" href="https://gitee.com/aizuda/flowlong#%E8%B4%A1%E7%8C%AE%E5%8A%9B%E9%87%8F"></a>貢獻力量</h1><ul><li><a href="https://gitee.com/aizuda/flowlong/wikis/%E8%BF%90%E8%A1%8C%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95">運行單元測試</a></li><li>PR 請參考現在代碼規範註釋説明</li></ul><h1><a id="user-content-使用文檔" class="anchor" href="https://gitee.com/aizuda/flowlong#%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3"></a>使用文檔</h1><ul><li>設計器源碼 <a href="https://gitee.com/flowlong/flowlong-designer">https://gitee.com/flowlong/flowlong-designer</a></li></ul><img src="https://foruda.gitee.com/images/1683680723972384655/f957e75d_12260.png" alt="flowlong" width="500px" height="262px" referrerpolicy="no-referrer"><h1><a id="user-content-其它説明" class="anchor" href="https://gitee.com/aizuda/flowlong#%E5%85%B6%E5%AE%83%E8%AF%B4%E6%98%8E"></a>其它説明</h1><ul><li>基於 <a href="https://gitee.com/link?target=https%3A%2F%2Fbaomidou.com">MybatisPlus</a> 為 <code>ORM</code> 層實現</li><li>後端設計參考了 <a href="https://gitee.com/yuqs/snakerflow">snakerflow</a> 開源工作流實體劃分</li></ul>]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 02:24:01 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/aizuda/flowlong</guid>
            <link>https://gitee.com/aizuda/flowlong</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 淺析 Redis 大 Key]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><span id="OSC_h1_1"></span><h1>一、背景</h1><p><span style="color:#393c5a">在京東到家購物車系統中，用户基於門店能夠對商品進行加車操作。用户與門店商品使用 Redis 的 Hash 類型存儲，如下代碼塊所示。不知細心的你有沒有發現，如果單門店加車商品過多，或者門店過多時，此 Key 就會越來越大，從而影響線上業務。</span></p><pre><code>userPin:{
      storeId:{門店下加車的所有商品基本信息},
      storeId:{門店下加車的所有商品基本信息},
      ......
}

</code></pre><span id="OSC_h1_2"></span><h1>二、BigKey 的界定和如何產生</h1><span id="OSC_h3_3"></span><h3>2.1、BigKey 的界定</h3><p><span style="color:#393c5a">BigKey 稱為大 Key，通常以 Key 對應 Value 的存儲大小，或者 Key 對應 Value 的數量來進行綜合判斷。對於大 Key 也沒有嚴格的定義區分，針對 String 與非 String 結構，給出如下定義：</span></p><ul><li><span style="color:#333333">String：String 類型的 Key 對應的 Value 超過 10KB</span></li><li><span style="color:#333333">非 String 結構（Hash</span><span style="color:#777777">，</span>Set<span style="color:#777777">，</span>ZSet<span style="color:#777777">，</span>List）：Value 的數量達到 10000 個，或者 Vaule 的總大小為 100KB</li><li><span style="color:#333333">集羣中 Key 的總數超過 1 億</span></li></ul><span id="OSC_h3_4"></span><h3>2.2、如何產生</h3><p><span style="color:#393c5a">1、數據結構設置不合理，例如集合中元素唯一時，應該使用 Set 替換 List；</span></p><p><span style="color:#393c5a">2、針對業務缺少預估性，沒有預見 Value 動態增長；</span></p><p><span style="color:#393c5a">3、Key 沒有設置過期時間，把緩存當成垃圾桶，一直再往裏面扔，但是從不處理。</span></p><span id="OSC_h1_5"></span><h1>三、BigKey 的危害</h1><span id="OSC_h3_6"></span><h3>3.1、數據傾斜</h3><p><span style="color:#393c5a">redis 數據傾斜分為</span><strong><span style="color:#393c5a">數據訪問傾斜</span></strong><span style="color:#393c5a">和</span><strong><span style="color:#393c5a">數據量傾斜，</span></strong><span style="color:#393c5a">會導致該 Key 所在的數據分片節點 CPU 使用率、帶寬使用率升高，從而影響該分片上所有 Key 的處理。</span></p><p><strong><span style="color:#393c5a">數據訪問傾斜：</span></strong><span style="color:#393c5a">某節點中 key 的 QPS 高於其他節點中的 Key</span></p><p><strong><span style="color:#393c5a">數據量傾斜：</span></strong><span style="color:#393c5a">某節點中 key 的大小高於其他節點中的 Key，如下圖，實例 1 中的 Key1 存儲高於其他實例。</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=MTY3YzQ1ODcwZjZkOGYzYTc0YzljYjg4ZmVkMTZlNTEsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><span id="OSC_h3_7"></span><h3>﻿3.2、網絡阻塞</h3><p><span style="color:#393c5a">Redis 服務器是一個事件驅動程序，有文件事件和時間事件，文件事件和時間事件都是主線程完成。其中文件事件就是服務器對套接字操作的抽象，客户端與服務端的通信會產生相應的文件事件，服務器通過監聽並處理這些事件來完成一系列網絡通信操作。</span></p><p><span style="color:#393c5a">Redis 基於 Reactor 模式開發了自己的網絡事件處理器，即文件事件處理器，該處理器內部使用 I/O 多路複用程序，可同時監聽多個套接字，並根據套接字執行的任務來關聯不同的事件處理器。文件事件處理器以單線程的方式運行，但是通過 I/O 多路複用程序來監聽多個套接字，既實現了高性能網絡通信模型，又保持了內部單線程設計的簡單性。文件事件處理器構成如下圖：</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=OWJmZjdlMWNjNDIyMmJjMWYwNDU4YjI4NTM0YmQwYmIsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><p>﻿﻿<span style="color:#393c5a">文件事件是對套接字操作的抽象，包括連接應答，寫入，讀取，關閉，因為一個服務器會連接多個套接字，所以文件事件可能併發出現，即使文件事件併發的出現，但是</span><strong><span style="color:#f5222d">I/O 多路複用程序會將套接字放入一個隊列，通過隊列有序的，同步的每次一個套接字的方式</span></strong>向文件事件分派器傳送套接字，當讓一個套接字產生的事件被<strong><span style="color:#f5222d">處理完畢</span></strong>後，I/O 多路複用程序才會繼續向文件事件分派器傳送下一個套接字，當有大 key 時，單次操作時間延長，導致網絡阻塞。</p><span id="OSC_h3_8"></span><h3>3.3、慢查詢</h3><p><span style="color:#393c5a">嚴重影響 QPS 、TP99 等指標，對大 Key 進行的慢操作會導致後續的命令被阻塞，從而導致一系列慢查詢。</span></p><span id="OSC_h3_9"></span><h3>3.4、CPU 壓力</h3><p><span style="color:#393c5a">當單 Key 過大時，每一次訪問此 Key 都可能會造成 Redis 阻塞，其他請求只能等待了。如果應用中設置了超時等，那麼上層就會拋出異常信息。最後刪除的時候也會造成 redis 阻塞，到時候內存中數據量過大，就會造成 CPU 負載過高。單個分片 cpu 佔用率過高，其他分片無法擁有 cpu 資源，從而被影響。此外，大 key 對持久化也有些影響。fork 操作會拷貝父進程的頁表項，如果過大，會佔用更多頁表，主線程阻塞拷貝需要一定的時間。</span></p><span id="OSC_h1_10"></span><h1>四、如何檢測 BigKey</h1><span id="OSC_h3_11"></span><h3>4.1、redis-cli --bigkeys</h3><p><span style="color:#393c5a">首先我們從運行結果出發。首先通過腳本插入一些數據到 redis 中，然後執行 redis-cli 的--bigkeys 選項</span></p><pre><code>$ redis-cli --bigkeys

# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.01 to sleep 0.01 sec
# per SCAN command (not usually needed).
-------- 第一部分 start -------
[00.00%] Biggest string found so far 'key-419' with 3 bytes
[05.14%] Biggest list   found so far 'mylist' with 100004 items
[35.77%] Biggest string found so far 'counter:__rand_int__' with 6 bytes
[73.91%] Biggest hash   found so far 'myobject' with 3 fields

-------- 第一部分 end -------

-------- summary -------

-------- 第二部分 start -------
Sampled 506 keys in the keyspace!
Total key length in bytes is 3452 (avg len 6.82)

Biggest string found 'counter:__rand_int__' has 6 bytes
Biggest   list found 'mylist' has 100004 items
Biggest   hash found 'myobject' has 3 fields
-------- 第二部分 end -------

-------- 第三部分 start -------
504 strings with 1403 bytes (99.60% of keys, avg size 2.78)
1 lists with 100004 items (00.20% of keys, avg size 100004.00)
0 sets with 0 members (00.00% of keys, avg size 0.00)
1 hashs with 3 fields (00.20% of keys, avg size 3.00)
0 zsets with 0 members (00.00% of keys, avg size 0.00)
-------- 第三部分 end -------

</code></pre><p><span style="color:#393c5a">以下我們分三步對 bigkeys 選項源碼原理進行解析，簡要流程如下圖：</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=NjgyZWM5MDg1MDBlNDc0MzQwZDc5NDAwMjUxYWJiMGIsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><span id="OSC_h4_12"></span><h4>﻿﻿4.1.1、第一部分是如何進行找 key 的呢？</h4><p><span style="color:#393c5a">Redis 找 bigkey 的函數是 static void findBigKeys(int memkeys, unsigned memkeys_samples)，因為--memkeys 選項和--bigkeys 選項是公用同一個函數，所以使用 memkeys 時會有額外兩個參數 memkeys、memkeys_sample，但這和--bigkeys 選項沒關係，所以不用理會。findBigKeys 具體函數框架為：</span></p><p><span style="color:#393c5a">1.申請 6 個變量用以統計 6 種數據類型的信息（每個變量記錄該數據類型的 key 的總數量、bigkey 是哪個等信息）</span></p><pre><code>typedef struct {
    char *name;//數據類型，如 string
    char *sizecmd;//查詢大小命令，如 string 會調用 STRLEN
    char *sizeunit;//單位，string 類型為 bytes，而 hash 為 field
    unsigned long long biggest;//最大 key 信息域，此數據類型最大 key 的大小，如 string 類型是多少 bytes，hash 為多少 field
    unsigned long long count;//統計信息域，此數據類型的 key 的總數
    unsigned long long totalsize;//統計信息域，此數據類型的 key 的總大小，如 string 類型是全部 string 總共多少 bytes，hash 為全部 hash 總共多少 field
    sds biggest_key;//最大 key 信息域，此數據類型最大 key 的鍵名，之所以在數據結構末尾是考慮字節對齊
} typeinfo;

    dict *types_dict = dictCreate(&amp;typeinfoDictType);
    typeinfo_add(types_dict, "string", &amp;type_string);
    typeinfo_add(types_dict, "list", &amp;type_list);
    typeinfo_add(types_dict, "set", &amp;type_set);
    typeinfo_add(types_dict, "hash", &amp;type_hash);
    typeinfo_add(types_dict, "zset", &amp;type_zset);
    typeinfo_add(types_dict, "stream", &amp;type_stream);

</code></pre><p><span style="color:#393c5a">2.調用 scan 命令迭代地獲取一批 key（注意只是 key 的名稱，類型和大小 scan 命令不返回）</span></p><pre><code>/* scan 循環掃描 */
do {
    /* 計算完成的百分比情況 */
    pct = 100 * (double)sampled/total_keys;//這裏記錄下掃描的進度

    /* 獲取一些鍵並指向鍵數組 */
    reply = sendScan(&amp;it);//這裏發送 SCAN 命令，結果保存在 reply 中
    keys  = reply-&gt;element[1];//keys 來保存這次 scan 獲取的所有鍵名，注意只是鍵名，每個鍵的數據類型是不知道的。
    ......

} while(it != 0); 

</code></pre><p><span style="color:#393c5a">3.對每個 key 獲取它的數據類型（type）和 key 的大小（size）</span></p><pre><code>/* 檢索類型，然後檢索大小*/
getKeyTypes(types_dict, keys, types);
getKeySizes(keys, types, sizes, memkeys, memkeys_samples);

</code></pre><p><span style="color:#393c5a">4.如果 key 的大小大於已記錄的最大值的 key，則更新最大 key 的信息</span></p><pre><code>/* Now update our stats */
for(i=0;i&lt;keys-&gt;elements;i++) {
    ......//前面已解析

    //如果遍歷到比記錄值更大的 key 時
    if(type-&gt;biggest&lt;sizes[i]) {
        /* Keep track of biggest key name for this type */
        if (type-&gt;biggest_key)
            sdsfree(type-&gt;biggest_key);
        //更新最大 key 的鍵名
        type-&gt;biggest_key = sdscatrepr(sdsempty(), keys-&gt;element[i]-&gt;str, keys-&gt;element[i]-&gt;len);
        if(!type-&gt;biggest_key) {
            fprintf(stderr, "Failed to allocate memory for key!\n");
            exit(1);
        }

        //每當找到一個更大的 key 時則輸出該 key 信息
        printf(
            "[%05.2f%%] Biggest %-6s found so far '%s' with %llu %s\n",
            pct, type-&gt;name, type-&gt;biggest_key, sizes[i],
            !memkeys? type-&gt;sizeunit: "bytes");

        /* Keep track of the biggest size for this type */
        //更新最大 key 的大小
        type-&gt;biggest = sizes[i];
    }

    ......//前面已解析
}

</code></pre><p><span style="color:#393c5a">5.對每個 key 更新對應數據類型的統計信息</span></p><pre><code>/* 現在更新統計數據 */
for(i=0;i&lt;keys-&gt;elements;i++) {
    typeinfo *type = types[i];
    /* 跳過在 SCAN 和 TYPE 之間消失的鍵 */
    if(!type)
        continue;

    //對每個 key 更新每種數據類型的統計信息
    type-&gt;totalsize += sizes[i];//某數據類型（如 string）的總大小增加
    type-&gt;count++;//某數據類型的 key 數量增加
    totlen += keys-&gt;element[i]-&gt;len;//totlen 不針對某個具體數據類型，將所有 key 的鍵名的長度進行統計，注意只統計鍵名長度。
    sampled++;//已經遍歷的 key 數量

    ......//後續解析

    /* 更新整體進度 */
    if(sampled % 1000000 == 0) {
        printf("[%05.2f%%] Sampled %llu keys so far\n", pct, sampled);
    }
}

</code></pre><span id="OSC_h4_13"></span><h4>4.1.2、第二部分是如何執行的？</h4><p><span style="color:#393c5a">1.輸出統計信息、最大 key 信息</span></p><pre><code>   /* We're done */
    printf("\n-------- summary -------\n\n");
    if (force_cancel_loop) printf("[%05.2f%%] ", pct);
    printf("Sampled %llu keys in the keyspace!\n", sampled);
    printf("Total key length in bytes is %llu (avg len %.2f)\n\n",
       totlen, totlen ? (double)totlen/sampled : 0);

</code></pre><p><span style="color:#393c5a">2.首先輸出總共掃描了多少個 key、所有 key 的總長度是多少。</span></p><pre><code>/* Output the biggest keys we found, for types we did find */
    di = dictGetIterator(types_dict);
    while ((de = dictNext(di))) {
        typeinfo *type = dictGetVal(de);
        if(type-&gt;biggest_key) {
            printf("Biggest %6s found '%s' has %llu %s\n", type-&gt;name, type-&gt;biggest_key,
               type-&gt;biggest, !memkeys? type-&gt;sizeunit: "bytes");
        }
    }
    dictReleaseIterator(di);

</code></pre><span id="OSC_h4_14"></span><h4>4.1.3、第三部分是如何執行的？</h4><p><span style="color:#393c5a">di 為字典迭代器，用以遍歷 types_dict 裏面的所有 dictEntry。de = dictNext(di) 則可以獲取下一個 dictEntry，de 是指向 dictEntry 的指針。又因為 typeinfo 結構體保存在 dictEntry 的 v 域中，所以用 dictGetVal 獲取。然後就是輸出 typeinfo 結構體裏面保存的最大 key 相關的數據，包括最大 key 的鍵名和大小。</span></p><pre><code>  di = dictGetIterator(types_dict);
    while ((de = dictNext(di))) {
        typeinfo *type = dictGetVal(de);
        printf("%llu %ss with %llu %s (%05.2f%% of keys, avg size %.2f)\n",
           type-&gt;count, type-&gt;name, type-&gt;totalsize, !memkeys? type-&gt;sizeunit: "bytes",
           sampled ? 100 * (double)type-&gt;count/sampled : 0,
           type-&gt;count ? (double)type-&gt;totalsize/type-&gt;count : 0);
    }
    dictReleaseIterator(di);

</code></pre><span id="OSC_h3_15"></span><h3>4.2、使用開源工具發現大 Key</h3><p><span style="color:#393c5a">在不影響線上服務的同時得到精確的分析報告。使用 redis-rdb-tools 工具以定製化方式找出大 Key，該工具能夠對 Redis 的 RDB 文件進行定製化的分析，但由於分析 RDB 文件為離線工作，因此對線上服務不會有任何影響，這是它的最大優點但同時也是它的最大缺點：離線分析代表着分析結果的較差時效性。對於一個較大的 RDB 文件，它的分析可能會持續很久很久。</span></p><p><span style="color:#393c5a">redis-rdb-tools 的項目地址為：https://github.com/sripathikrishnan/redis-rdb-tools﻿</span></p><span id="OSC_h1_16"></span><h1>五、如何解決 Bigkey</h1><span id="OSC_h3_17"></span><h3>5.1、提前預防</h3><ul><li><span style="color:#333333">設置過期時間，儘量過期時間分散，防止同一時間過期；</span></li><li><span style="color:#333333">存儲為 String 類型的 JSON，可以刪除不使用的 Filed；</span></li></ul><p><span style="color:#393c5a">例如對象為</span><span style="color:#2ea121">{"userName":"京東到家","ciyt":"北京"}</span>，如果只需要用到 userName 屬性，那就定義新對象，只具有 userName 屬性，精簡緩存中數據</p><ul><li><span style="color:#333333">存儲為 String 類型的 JSON，利用@JsonProperty 註解讓 FiledName 字符集縮小，代碼例子如下。但是存在緩存數據識別性低的缺點；</span></li></ul><pre><code>import org.codehaus.jackson.annotate.JsonProperty;
import org.codehaus.jackson.map.ObjectMapper;
import java.io.IOException;
public class JsonTest {
    @JsonProperty("u")
    private String userName;

    public String getUserName() {
        return userName;
    }
    public void setUserName(String userName) {
        this.userName = userName;
    }
    public static void main(String[] args) throws IOException {
        JsonTest output = new JsonTest();
        output.setUserName("京東到家");
        System.out.println(new ObjectMapper().writeValueAsString(output));

        String json = "{\"u\":\"京東到家\"}";
        JsonTest r1 = new ObjectMapper().readValue(json, JsonTest.class);
        System.out.println(r1.getUserName());
    }
}

{"u":"京東到家"}
京東到家

</code></pre><ul><li><span style="color:#333333">採用壓縮算法，利用時間換空間，進行序列化與反序列化。同時也存在緩存數據識別性低的缺點；</span></li><li><span style="color:#333333">在業務上進行幹預，設置閾值。比如用户購物車的商品數量，或者領券的數量，不能無限的增大；</span></li></ul><span id="OSC_h3_18"></span><h3>5.2、如何優雅刪除 BigKey</h3><span id="OSC_h4_19"></span><h4>5.2.1、DEL</h4><p><span style="color:#393c5a">此命令在 Redis 不同版本中刪除的機制並不相同，以下分別進行分析：</span></p><p><strong><span style="color:#393c5a">redis_version &lt; 4.0 版本</span></strong><span style="color:#393c5a">：在主線程中同步刪除，刪除大 Key 會阻塞主線程，見如下源碼基於 redis 3.0 版本。那針對非 String 結構數據，可以先通過 SCAN 命令讀取部分數據，然後逐步進行刪除，避免一次性刪除大 key 導致 Redis 阻塞。</span></p><pre><code>// 從數據庫中刪除給定的鍵，鍵的值，以及鍵的過期時間。
// 刪除成功返回 1，因為鍵不存在而導致刪除失敗時，返回 0 
int dbDelete(redisDb *db, robj *key) {
    // 刪除鍵的過期時間
    if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr);

    // 刪除鍵值對
    if (dictDelete(db-&gt;dict,key-&gt;ptr) == DICT_OK) {
        // 如果開啓了集羣模式，那麼從槽中刪除給定的鍵
        if (server.cluster_enabled) slotToKeyDel(key);
        return 1;
    } else {
        // 鍵不存在
        return 0;
    }
}

</code></pre><p><strong><span style="color:#393c5a">4.0 版本 &lt; redis_version &lt; 6.0 版本</span></strong><span style="color:#393c5a">：引入 lazy-free</span><strong><span style="color:#393c5a">，</span></strong><span style="color:#393c5a">手動開啓 lazy-free 時，有 4 個選項可以控制，分別對應不同場景下，是否開啓異步釋放內存機制：</span></p><ul><li><span style="color:#333333">lazyfree-lazy-expire：key 在過期刪除時嘗試異步釋放內存</span></li><li><span style="color:#333333">lazyfree-lazy-eviction：內存達到 maxmemory 並設置了淘汰策略時嘗試異步釋放內存</span></li><li><span style="color:#333333">lazyfree-lazy-server-del：執行 RENAME/MOVE 等命令或需要覆蓋一個 key 時，刪除舊 key 嘗試異步釋放內存</span></li><li><span style="color:#333333">replica-lazy-flush：主從全量同步，從庫清空數據庫時異步釋放內存</span></li></ul><p><span style="color:#4a4a4a">開啓 lazy-free 後，Redis 在釋放一個 key 的內存時，首先會評估代價，如果釋放內存的代價很小，那麼就直接在主線程中操作了，沒必要放到異步線程中執行</span></p><p><strong><span style="color:#393c5a">redis_version &gt;= 6.0 版本</span></strong><span style="color:#393c5a">：引入 lazyfree-lazy-user-del</span><span style="color:#4a4a4a">，只要開啓了，del 直接可以異步刪除 key，不會阻塞主線程。具體是為什麼呢，現在先賣個關子，在下面進行解析。</span></p><span id="OSC_h4_20"></span><h4>5.2.2、SCAN</h4><p><span style="color:#393c5a">SCAN 命令可以幫助在不阻塞主線程的情況下逐步遍歷大量的鍵，以及避免對數據庫的阻塞。以下代碼是利用 scan 來掃描集羣中的 Key。</span></p><pre><code>public void scanRedis(String cursor,String endCursor) {
        ReloadableJimClientFactory factory = new ReloadableJimClientFactory();
        String jimUrl = "jim://xxx/546";
        factory.setJimUrl(jimUrl);
        Cluster client = factory.getClient();
        ScanOptions.ScanOptionsBuilder scanOptions = ScanOptions.scanOptions();
        scanOptions.count(100);
 
        Boolean end = false;
        int k = 0;
        while (!end) {
            KeyScanResult&lt; String &gt; result = client.scan(cursor, scanOptions.build());
            for (String key :result.getResult()){
                if (client.ttl(key) == -1){
                    logger.info("永久 key 為:{}" , key);
                }
            }
            k++;
            cursor = result.getCursor();
            if (endCursor.equals(cursor)){
                break;
            }
        }
    }

</code></pre><span id="OSC_h4_21"></span><h4>5.2.3、UNLINK</h4><p><span style="color:#393c5a">Redis 4.0 提供了 lazy delete (unlink 命令) ，下面基於源碼（redis_version:7.2 版本）分析下實現原理</span></p><ul><li><span style="color:#333333">del 與 unlink 命令底層都調用了 delGenericCommand() 方法；</span></li></ul><pre><code>void delCommand(client *c) {
    delGenericCommand(c,server.lazyfree_lazy_user_del);
}
void unlinkCommand(client *c) {
    delGenericCommand(c,1);
}

</code></pre><ul><li><span style="color:#333333">lazyfree-lazy-user-del 支持 yes 或者 no。默認是 no；</span></li><li><span style="color:#333333">如果設置為 yes，那麼 del 命令就等價於 unlink，也是異步刪除，這也同時解釋了之前咱們的問題，為什麼設置了 lazyfree-lazy-user-del 後，del 命令就為異步刪除。</span></li></ul><pre><code>void delGenericCommand(client *c, int lazy) {
    int numdel = 0, j;
    // 遍歷所有輸入鍵
    for (j = 1; j &lt; c-&gt;argc; j++) {
        // 先刪除過期的鍵
        expireIfNeeded(c-&gt;db,c-&gt;argv[j],0);
        int deleted  = lazy ? dbAsyncDelete(c-&gt;db,c-&gt;argv[j]) :
                              dbSyncDelete(c-&gt;db,c-&gt;argv[j]);
        // 嘗試刪除鍵
        if (deleted) {
            // 刪除鍵成功，發送通知
            signalModifiedKey(c,c-&gt;db,c-&gt;argv[j]);
            notifyKeyspaceEvent(NOTIFY_GENERIC,"del",c-&gt;argv[j],c-&gt;db-&gt;id);
            server.dirty++;
            // 成功刪除才增加 deleted 計數器的值
            numdel++;
        }
    }
    // 返回被刪除鍵的數量
    addReplyLongLong(c,numdel);
}

</code></pre><p><span style="color:#393c5a">下面分析異步刪除 dbAsyncDelete() 與同步刪除 dbSyncDelete()，底層同時也是調用 dbGenericDelete() 方法</span></p><pre><code>int dbSyncDelete(redisDb *db, robj *key) {
    return dbGenericDelete(db, key, 0, DB_FLAG_KEY_DELETED);
}

int dbAsyncDelete(redisDb *db, robj *key) {
    return dbGenericDelete(db, key, 1, DB_FLAG_KEY_DELETED);
}

int dbGenericDelete(redisDb *db, robj *key, int async, int flags) {
    dictEntry **plink;
    int table;
    dictEntry *de = dictTwoPhaseUnlinkFind(db-&gt;dict,key-&gt;ptr,&amp;plink,&amp;table);
    if (de) {
        robj *val = dictGetVal(de);
        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we need to incr to retain val */
        incrRefCount(val);
        /* Tells the module that the key has been unlinked from the database. */
        moduleNotifyKeyUnlink(key,val,db-&gt;id,flags);
        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */
        signalDeletedKeyAsReady(db,key,val-&gt;type);
        // 在調用用 freeObjAsync 之前，我們應該先調用 decrRefCount。否則，引用計數可能大於 1，導致 freeObjAsync 無法正常工作。
        decrRefCount(val);
        // 如果是異步刪除，則會調用 freeObjAsync 異步釋放 value 佔用的內存。同時，將 key 對應的 value 設置為 NULL。
        if (async) {
            /* Because of dbUnshareStringValue, the val in de may change. */
            freeObjAsync(key, dictGetVal(de), db-&gt;id);
            dictSetVal(db-&gt;dict, de, NULL);
        }
        // 如果是集羣模式，還會更新對應 slot 的相關信息
        if (server.cluster_enabled) slotToKeyDelEntry(de, db);

        /* Deleting an entry from the expires dict will not free the sds of the key, because it is shared with the main dictionary. */
        if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr);
        // 釋放內存
        dictTwoPhaseUnlinkFree(db-&gt;dict,de,plink,table);
        return 1;
    } else {
        return 0;
    }
}

</code></pre><p><span style="color:#393c5a">如果為異步刪除，調用 freeObjAsync() 方法，根據以下代碼分析：</span></p><pre><code>#define LAZYFREE_THRESHOLD 64

/* Free an object, if the object is huge enough, free it in async way. */
void freeObjAsync(robj *key, robj *obj, int dbid) {
    size_t free_effort = lazyfreeGetFreeEffort(key,obj,dbid);
    if (free_effort &gt; LAZYFREE_THRESHOLD &amp;&amp; obj-&gt;refcount == 1) {
        atomicIncr(lazyfree_objects,1);
        bioCreateLazyFreeJob(lazyfreeFreeObject,1,obj);
    } else {
        decrRefCount(obj);
    }
}

size_t lazyfreeGetFreeEffort(robj *key, robj *obj, int dbid) {
    if (obj-&gt;type == OBJ_LIST &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_QUICKLIST) {
        quicklist *ql = obj-&gt;ptr;
        return ql-&gt;len;
    } else if (obj-&gt;type == OBJ_SET &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_HT) {
        dict *ht = obj-&gt;ptr;
        return dictSize(ht);
    } else if (obj-&gt;type == OBJ_ZSET &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_SKIPLIST){
        zset *zs = obj-&gt;ptr;
        return zs-&gt;zsl-&gt;length;
    } else if (obj-&gt;type == OBJ_HASH &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_HT) {
        dict *ht = obj-&gt;ptr;
        return dictSize(ht);
    } else if (obj-&gt;type == OBJ_STREAM) {
        ...
        return effort;
    } else if (obj-&gt;type == OBJ_MODULE) {
        size_t effort = moduleGetFreeEffort(key, obj, dbid);
        /* If the module's free_effort returns 0, we will use asynchronous free
         * memory by default. */
        return effort == 0 ? ULONG_MAX : effort;
    } else {
        return 1; /* Everything else is a single allocation. */
    }
}

</code></pre><p><span style="color:#393c5a">分析後咱們可以得出如下結論：</span></p><ul><li><span style="color:#333333">當 Hash/Set 底層採用哈希表存儲（非 ziplist/int 編碼存儲）時，並且元素數量超過 64 個</span></li><li><span style="color:#333333">當 ZSet 底層採用跳錶存儲（非 ziplist 編碼存儲）時，並且元素數量超過 64 個</span></li><li><span style="color:#333333">當 List 鏈表節點數量超過 64 個（注意，不是元素數量，而是鏈表節點的數量，List 的實現是在每個節點包含了若干個元素的數據，這些元素採用 ziplist 存儲）</span></li><li><span style="color:#333333">refcount == 1 就是在沒有引用這個 Key 時</span></li></ul><p><span style="color:#393c5a">只有以上這些情況，在刪除 key 釋放內存時，才會真正放到異步線程中執行，其他情況一律還是在主線程操作。也就是説 String（不管內存佔用多大）、List（少量元素）、Set（int 編碼存儲）、Hash/ZSet（ziplist 編碼存儲）這些情況下的 key 在釋放內存時，依舊在主線程中操作。</span></p><span id="OSC_h3_22"></span><h3>5.3、分而治之</h3><p><span style="color:#393c5a">採用經典算法「分治法」，將大而化小。針對 String 和集合類型的 Key，可以採用如下方式：</span></p><ul><li><span style="color:#333333">String 類型的大 Key：可以嘗試將對象分拆成幾個 Key-Value， 使用 MGET 或者多個 GET 組成的 pipeline 獲取值，分拆單次操作的壓力，對於集羣來説可以將操作壓力平攤到多個分片上，降低對單個分片的影響。</span></li><li><span style="color:#333333">集合類型的大 Key，並且需要整存整取要在設計上嚴格禁止這種場景的出現，如無法拆分，有效的方法是將該大 Key 從 JIMDB 去除，單獨放到其他存儲介質上。</span></li><li><span style="color:#333333">集合類型的大 Key，每次只需操作部分元素：將集合類型中的元素分拆。以 Hash 類型為例，可以在客户端定義一個分拆 Key 的數量 N，每次對 HGET 和 HSET 操作的 field 計算哈希值並取模 N，確定該 field 落在哪個 Key 上。</span></li></ul><p><span style="color:#393c5a">如果線上服務強依賴 Redis，需要考慮到如何做到「無感」，並保證數據一致性。咱們基本上可以採用三步走策略，如下圖所示。分別是進行雙寫，雙讀校驗，最後讀新 Key。在此基礎上可以設置開關，做到上線後的平穩遷移。</span></p><div><img src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=ZGE3YWQ4ZDZiZDE4ZjM5MzU1YTRiMTExOWZjY2UxYmMsMTY5ODcxODQzNDA3Nw==" referrerpolicy="no-referrer"></div><span id="OSC_h1_23"></span><h1>﻿﻿六、總結</h1><p><span style="color:#393c5a">綜上所述，針對文章開頭咱們購物車大 Key 問題，相信你已經有了答案。咱們可以限制門店數，限制門店中的商品數。如果不作限制，咱們也能進行拆分，將大 Key 分散存儲。例如。將 Redis 中 Key 類型改為 List，key 為用户與門店唯一鍵，Value 為用户在此門店下的商品。</span></p><pre><code>存儲結構拆分成兩種：
第一種：
    userPin：storeId 的集合
第二種：
    userPin_storeId1:{門店下加車的所有商品基本信息}；
    userPin_storeId2:{門店下加車的所有商品基本信息}     

</code></pre><p><span style="color:#393c5a">以上介紹了大 key 的產生、識別、處理，以及如何使用合理策略和技術來應對。在使用 Redis 過程中，防範大於治理，在治理過程中也要做到業務無感。</span></p><span id="OSC_h1_24"></span><h1>七、參考</h1><p><span style="color:#393c5a">﻿https://github.com/redis/redis.git﻿</span></p><p><span style="color:#393c5a">﻿http://redisbook.com/﻿</span></p><p><span style="color:#393c5a">﻿https://github.com/huangz1990/redis-3.0-annotated.git﻿</span></p><p><span style="color:#393c5a">﻿https://blog.csdn.net/ldw201510803006/article/details/124790121﻿</span></p><p><span style="color:#393c5a">﻿https://blog.csdn.net/kuangd_1992/article/details/130451679﻿</span></p><p><span style="color:#393c5a">﻿http://sd.jd.com/article/4930?shareId=119428&amp;isHideShareButton=1﻿</span></p><p><span style="color:#393c5a">﻿https://www.liujiajia.me/2023/3/28/redis-bigkeys﻿</span></p><p><span style="color:#393c5a">﻿https://www.51cto.com/article/701990.html﻿</span></p><p><span style="color:#393c5a">﻿https://help.aliyun.com/document_detail/353223.html﻿</span></p><p><span style="color:#393c5a">﻿https://juejin.cn/post/7167015025154981895﻿</span></p><p><span style="color:#393c5a">﻿https://www.jianshu.com/p/9e150d72ffc9﻿</span></p><p><span style="color:#393c5a">﻿https://zhuanlan.zhihu.com/p/449648332</span></p><blockquote><p>作者：京東零售&nbsp;高凱</p><p>來源：京東雲開發者社區，轉載請註明來源</p></blockquote><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 02:22:01 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10139889</guid>
            <link>https://my.oschina.net/u/4090830/blog/10139889</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[基於模式挖掘的可靠性治理探索與實踐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><blockquote><p>本文整理自美團技術沙龍第 77 期《美團億級流量系統的質量風險防控和穩定性治理實踐》。本文介紹了基於模式挖掘的可靠性治理探索，為通過技術手段解決該領域代表性問題開啓了新的思路。文章第一部分介紹可靠性治理的痛點；第二部分引入模式的概念；第三部分討論新基建下的新嘗試；第四部分分享三個典型的實踐案例。</p></blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-df29f8b032fe5944a8d7b649041f72acc43.jpg" alt="" referrerpolicy="no-referrer"></p><h2>1 可靠性治理的痛點</h2><p>對於億級流量的線上系統來説，可靠性是至關重要的。從字面上理解，可靠性要求故障少、可信賴。與安全性一樣，它們都是信息系統的固有屬性之一，也是保障產品質量的關鍵因素。</p><p>對照 Google 的可靠性模型來看，測試同學會投入很多精力在用例設計、測試執行、持續交付等環節上，研發同學則會更多關注監控、應急和故障分析等。但往往由於項目進度和人力因素，在設計和編碼階段對可靠性的投入和關注不足，導致後續需要付出更高的成本發現和解決潛在隱患。有鑑於此，我們希望能找到更低成本且以更有效的方式發現和治理這些隱患，從而提升系統整體的可靠性。</p><p><img src="https://p0.meituan.net/travelcube/d94c2805fc7216f7058b60b25dee9c2d521185.png" alt="" referrerpolicy="no-referrer"></p><p>在研發設計階段，我們需要關注系統彈性，考慮潛在故障風險、適應流量變化等，其中相關治理涉及冪等性、健壯性、一致性、超時、限流、熔斷等場景。與一般功能測試相比，可靠性治理需要面對不同的服務和系統，發現並治理技術問題，在模糊度上有較大的提升和挑戰。就目前而言，質量問題非常明確，但潛在風險策略和解決路徑比較模糊。因此，我們希望能找到辦法識別並解決這些問題。</p><p><img src="https://p0.meituan.net/travelcube/9fde4b0cae296d02895a1d03351043e3159517.png" alt="" referrerpolicy="no-referrer"></p><p>模糊度的提升會帶來兩種最常見的現象：</p><ul><li>一種是過於具體，Case by Case 解決問題，類似算法的過擬合，過擬合的問題在於對更廣泛範圍內的問題缺乏有效性。以冪等性為例，想驗證一個接口是否冪等可以很快完成並很快補充接口冪等相關的測試用例，但是對不同的接口、服務、系統以及不同的冪等性設計，還有哪些問題和風險，我們沒有辦法關注到並控制這些風險。</li><li>另一種是過於泛化，類似算法的欠擬合，欠擬合的問題在於過度虛化導致沒有抓住問題的共性特徵。以主從延遲為例，主從延遲會給系統帶來一致性風險，需要針對性做保護，並進行相關驗證，因此我們可以制定規範、梳理 Check List 和測試模板，雖然這樣可以最大程度在產研各環節提醒大家關注到這類問題，但並沒有找到徹底解決問題的方法。</li></ul><p><img src="https://p0.meituan.net/travelcube/fa0db198a1641d7c6fff31be835b8753341300.png" alt="" referrerpolicy="no-referrer"></p><h2>2 模式的定義</h2><p>類似這些問題如何找到更好的解決辦法？我們重點看一下模式對可靠性治理的啓發。模式在維基百科的定義是：揭示了這個世界上人工設計和抽象思想中的規律。</p><p>例如下圖所示，計算機圖形學中的經典分形圖案柯赫雪花，是 1904 年瑞典數學家科赫提出。可以看到它有明顯的規律，這樣的分形規律在自然界無處不在。</p><p><img src="https://p0.meituan.net/travelcube/650b75a49ab89c3f5c5204c5f712e0f6435079.png" alt="" referrerpolicy="no-referrer"></p><p>技術場景的模式會更加豐富些，這類模式和可靠性治理想找到的模式非常接近。</p><p>舉例緩存設計的兩種常見模式：</p><ul><li>第一種是 Cache-Aside（旁路緩存），也是使用比較廣泛的一種方式，它只有在緩存沒有命中時，才會查詢數據庫並更新緩存。</li><li>另外一種是 Write-throught（只寫模式），這種模式在每次數據庫變更時都會同步更新緩存。</li></ul><p>對比第一種模式，第二種模式的優點是邏輯更清晰、操作簡單、緩存命中率更高；缺點是不常請求的數據會被寫到緩存中，導致緩存更大。</p><p><img src="https://p1.meituan.net/travelcube/fe10478804776789b284dc94e48f97e1215075.png" alt="" referrerpolicy="no-referrer"></p><p>那麼，我們如何找到這些潛在模式並應用到可靠性治理呢？我們現有的業務測試數據、專業知識積累、相關問題分析和覆盤經驗，都可以幫助我們找到治理這些通用技術場景的規律。在這裏，很重要的一部分是真實的業務數據，我們可以從最基礎的數據提取信息，找到解決共性問題的思路。</p><h2>3 大數據下的嘗試</h2><p>隨着 JVM 非侵入式 AOP 解決方案的成熟，現在我們已經可以採集任意環境下的任意協議流量，以及這些流量依賴的數據關係，也可以在測試環境回放這些流量，包括線上真實採集的流量。這裏依賴兩個關鍵點：一是流量採集，這裏涉及很多技術方案，這裏分享主要是作為一個基礎設施；二是有了全鏈路 Mock 能力，我們才能在測試環境進行各種流量的回放和驗證。</p><p><img src="https://p0.meituan.net/travelcube/3df2f4a8531888d62d0b81cc965ebdba289384.png" alt="" referrerpolicy="no-referrer"></p><p>另一個重要基礎設施是環境隔離技術，經過快速發展，它已經具備了泳道級別的數據複製隔離，也支持一站式數據消息和部署環境的即拿即用。從最開始通過泳道降低人工測試相互影響，到現在一站式拉出一套環境，能支持各類專項檢查獨立運行，使用線下數據且不污染主幹環境。</p><p><img src="https://p0.meituan.net/travelcube/2fb9dcf93574ab8e46e16237551501ad496283.png" alt="" referrerpolicy="no-referrer"></p><p>基於流量採集和環境隔離這兩個能力的成熟，給自動化領域帶來了很多新可能。流量採集信息包含了請求參數、返回值和調用鏈路等信息；環境隔離技術支持數據隔離、消息隔離、各種協議以及部署版本隔離。</p><p>在這種情況下，海量的業務流量可以直接轉化成基於規則驗證的接口自動化用例，也可以應用到基於業務模型的場景級用例，模式在這裏更像是兩者之間的「折中」，我們希望通過這種「折中」來解決可靠性治理的難題。</p><h2>4 典型實踐分享</h2><p>接下來，我們重點介紹基於模式的三個可靠性治理的典型實踐，主要包括冪等性治理、依賴治理和越權治理三個方向。</p><h3>4.1 冪等性治理</h3><p>維基百科中，冪等的定義是數學和計算機科學中某些運算的性質，可以被多次應用，而不會改變最初應用之外的結果。在數學中也有相關的定義，就以一元運算為例，當 f(f(x))=f(x) 時，可以認為這個運算符 f 是冪等的；在計算機科學領域，HTTP 規範中也有對冪等的定義，即多個相同請求的副作用與單個請求相同，例如 GET、PUT 和 DELETE 是冪等的。</p><p><img src="https://p1.meituan.net/travelcube/902fbbee65d75ac506adbbf9db8ebb28204176.png" alt="" referrerpolicy="no-referrer"></p><p>在大部分分佈式系統中，請求超時、網絡抖動等在線上環境中隨時可能發生。冪等性設計是保證服務在高併發情況下高可用的關鍵。對於每天產生海量訂單的線上業務，比如庫存、交易、支付和財務等系統都需要通過冪等性避免超賣、重複支付、重複打款等問題的發生；同時冪等性也是消息隊列、定時任務、分佈式事務等技術類場景穩定運行的基礎。</p><p>如下圖舉例，當一次調用部分成功的情況下，系統會觸發重試，而冪等性可以保證在重試時，成功部分不再被重複執行。</p><p><img src="https://p1.meituan.net/travelcube/22c38c3a5234bf04d0059508d0278c17289045.png" alt="" referrerpolicy="no-referrer"></p><p>我們要挖掘通用模式，就需要分析冪等性所有可能的實現方案。</p><p>如下圖是幾種常見的冪等性實現方案：數據庫層面的唯一索引；通過版本或其他狀態、條件來限制操作執行的悲觀鎖和樂觀鎖；通過具體業務屬性參數，構造具有唯一性的 Token 以及分佈式系統中廣泛使用的分佈式鎖等。</p><p><img src="https://p0.meituan.net/travelcube/20c2de394399fddbb90f8348429f4020332786.png" alt="" referrerpolicy="no-referrer"></p><p>儘管冪等性的實現方案有多種，但回到冪等性的本質，我們希望多次調用不會產生新的副作用，而系統中副作用的產生往往是通過「寫」操作發生。</p><p>分析調用鏈路發現，當鏈路上某個節點不冪等而對資源產生副作用後，其後的多個節點都可以檢測到相關變化。例如，前序節點通過數據庫的寫入生成了新的單號，後序節點的參數和返回值很可能會出現這個新單號。這樣，我們就可以構造多次同樣的請求，之後檢查鏈路上的這些變化來驗證冪等性。</p><p><img src="https://p0.meituan.net/travelcube/feded9ba45e7cc6113b8f3c123d5d707559000.png" alt="" referrerpolicy="no-referrer"></p><p>調用鏈路節點的類型包括了 MYBATIS、RPC、HTTP、MAFKA、CRANE 等，不同冪等性方案在不同類型的節點上有相應的表現，例如唯一索引，更多在 MYBATIS 節點上，不同類型節點的檢查策略和優先級也不同。</p><p><img src="https://p0.meituan.net/travelcube/076a87994f48ccad52ebee631b292ba2547874.png" alt="" referrerpolicy="no-referrer"></p><p>如下圖，列舉了部分節點檢查策略和降噪策略。以 MYBATIS 為例，我們會關注到寫 SQL 的內容和返回結果，結合索引衝突、鎖失敗等節點的異常返回進行降噪。比如 THRIFT 節點，我們會關注接口的參數和返回值變化，考慮隨機 ID 的生成、時間戳字段等進行相關降噪，最終針對不同冪等性方案和不同節點類型形成通用整體策略。</p><p><img src="https://p0.meituan.net/travelcube/8c2706b169067b4e53e9fa1d6b362cd0229473.png" alt="" referrerpolicy="no-referrer"></p><p>基於通用檢查能力，我們可以應用在場景用例編寫、流量用例生成和離線流量的自動分析上，通過分析每天線上、線下環境產生的真實流量，我們可以對增量和存量問題進行差異化治理和跟進。</p><p><img src="https://p0.meituan.net/travelcube/2bb82708ca65eccf9942c5515998e20b151408.png" alt="" referrerpolicy="no-referrer"></p><h3>4.2 依賴治理</h3><p>隨着微服務的發展，我們的系統變得越來越複雜，調用鏈路越來越長，例如單接口的下游依賴多達上百個，任何外部依賴的抖動都會成為核心業務的威脅，很多時候系統內部或外部的一些錯誤被激活，沒有得到正確處理，就會在服務內部不斷傳播，導致系統偏離正確的服務狀態，造成服務失敗，最終導致業務失敗，引起用户可以感知的故障。</p><p><img src="https://p0.meituan.net/travelcube/7aa84a6c96587c952494f351b41bd834559746.png" alt="" referrerpolicy="no-referrer"></p><p>在業務上可以通過依賴分級和熔斷策略，保障弱依賴發生故障時，核心流程依然可用。因此我們需要進行依賴治理，而依賴的治理關鍵在於如何自動化完成分級合理性以及熔斷策略有效性的驗證。</p><p>類似前面，我們會採用回放業務流量的方式，但基於依賴治理，我們的策略是修改依賴的 Mock 結構，構造依賴故障場景，進行相關驗證。</p><p>我們的預期是如果命中了弱依賴，我們期望業務主流程不被阻塞，調用鏈路也沒有阻塞，日誌打印和返回信息都符合預期，沒有異常表現；如果命中強依賴，驗證策略則相反。</p><p><img src="https://p0.meituan.net/travelcube/ea65f83998fd281afb61f0210ffc3115679867.png" alt="" referrerpolicy="no-referrer"></p><p>具體的策略是我們依據接口和依賴關係構造指定依賴故障場景，注入異常後，分析這個異常是否被捕獲。如果直接拋到了外層或者接口返回值有相關的異常信息，那當前是強依賴；如果注入依賴後，後續的調用鏈路被阻斷，認為當前依賴是強依賴。反之，則是弱依賴。</p><p>具備這樣閉環依賴分級識別以及熔斷有效性的治理能力後，我們就可以週期性地對核心服務進行下游依賴等級治理和對熔斷策略有效性進行自動驗證。</p><p>運營內容主要包括兩方面：配置檢查和業務驗證。</p><p><img src="https://p1.meituan.net/travelcube/21cacef713e1c515e75ad0be73c48182459214.pngv" alt="" referrerpolicy="no-referrer"></p><ul><li>對於依賴等級正確與否的檢查，每週運行，發現依賴等級與熔斷策略不相符的情況，推動治理。</li><li>對於業務驗證，每天運行，持續產生每天增量報告，針對強依賴業務未被阻斷、弱依賴業務未被處理，對應的異常等問題推動修改。</li></ul><p><img src="https://p0.meituan.net/travelcube/46852b87e0993671f0f3dd3c788ce537337387.png" alt="" referrerpolicy="no-referrer"></p><h3>4.3 越權治理</h3><p>越權訪問是 Web 應用程序中一種常見的漏洞，它存在範圍廣、危害大，被 OWASP 應用程序安全項目列為 Web 應用十大安全隱患第二名。對於這種商户、用户規模大，交易頻繁的線上業務來説，更是存在比較大的安全和合規風險。</p><p>越權就是兩個同等級用户，一個可以操作另一個數據；垂直越權則涉及到不同等級用户，例如普通用户可以操作管理員才有的權限數據。</p><p><img src="https://p0.meituan.net/travelcube/bd1d73c092a90fd955b014315529d5fb435342.png" alt="" referrerpolicy="no-referrer"></p><p>典型的有越權處理接口在收到請求後經歷以下三個階段：</p><ul><li>第一步是身份認證，讓系統明確當前登錄的用户是誰，是後續進行鑑權的基礎條件，每家公司和業務可能會有多套鑑權系統。</li><li>第二步是系統決策判斷，基於當前登錄用户信息，根據身份權限判斷是否可以繼續操作。</li><li>第三步是數據權限驗證，判斷當前數據是否是該用户所屬，即數據歸屬判斷。</li></ul><p>當系統未做角色判斷時，容易發生垂直越權問題；當系統未做數據歸屬判斷時，容易發生水平越權問題。</p><p><img src="https://p0.meituan.net/travelcube/445e4b25c3642b3285bc4c6610720183385165.png" alt="" referrerpolicy="no-referrer"></p><p>我們可以通過回放業務流量構造對應場景，驗證接口是否有做權限控制。</p><p>第一次回放，會結合識別到當前流量鑑權方式，構造一個無權限賬户進行回放，其餘的依賴數據保持不變；第二次回放與第一次類似，只不過需要構造一個有權限賬户信息進行回放；比對兩次回放結果以及調用鏈路，驗證這個接口是否有相關的鑑權邏輯；再結合調用鏈路對比以及原始流量的調用鏈路，比較有效地識別當前的鑑權場景，兼容一些場景通過返回值沒有辦法完全識別到是否有做鑑權的情況。</p><p><img src="https://p1.meituan.net/travelcube/987a046ffe53e98a2b3a372e5e9470a6616863.png" alt="" referrerpolicy="no-referrer"></p><p>在實際應用中，要考慮我們所使用的流量質量、有效性以及鑑權方式等進行篩選。目前越權檢查經過優化和適配不同業務，已經可以自動化、常態化對新增流量進行檢測，並將結果同步到報告中，進行日常運營，也支持問題確認、加白和工單創建等。</p><p><img src="https://p0.meituan.net/travelcube/fc1ad4d32886ca9e572b9289ec7fecaa309813.png" alt="" referrerpolicy="no-referrer"></p><p>以上三個治理能力，已經對美團優選部分核心服務默認開啓，可以低成本自動化實現相關問題的常態治理及運營。目前覆蓋了 500+服務、2 萬+接口和 8000+下游、累計發現並治理問題有 1000+。近期已經開始陸續接入到公司內其他業務線進行應用。</p><p><img src="https://p0.meituan.net/travelcube/1ed53bd18db0f07796de4255709e5406164876.png" alt="" referrerpolicy="no-referrer"></p><p>通過以上 3 個案例，我們可以看到共性能力和解法，因此後續的規劃主要是建設通用基礎設施，包含線上、線下以及不同來源的流量積累、流量分析，在其上進行模式挖掘、結果跟進和運營，在這樣體系基礎上，不斷迭代底層能力，構建更豐富的可靠性治理場景。</p><p><img src="https://p0.meituan.net/travelcube/559a1aaa265cec97745263e1d470c0ef548540.png" alt="" referrerpolicy="no-referrer"></p><h2>5 Q&amp;A</h2><p><strong>Q1：怎樣預防配置異常造成的故障？</strong></p><p><strong>A</strong>：用相關事件舉例，我們的一些配置平台包含一些規則，可以字符串形式或者一些類型形式存儲，系統對這些配置的兼容性或表現，我們可以構造這些配置的異常場景，比如它當前是一個數值類型的配置，那我們可以構造這個配置的異常值、邊界值以及空值，比如它包含分隔符的字符串，我們可以用特殊分隔符以及特殊字符，構造異常配置的獲取，驗證一個配置的兼容性和可靠性的規則是當讀取到這樣的異常配置後，我們本來能正確回放的流量，在返回值、拋出異常、日誌和調用鏈路層面有哪些相應表現。很多線上配置變更，因為人為原因和系統默認規則沒有兜住的情況下，會引入這樣的異常配置健壯性驗證，有比較好的保障。</p><p><strong>Q2：越權場景檢查，鏈路對比是指走過的鏈路對比嗎？還是每個調用點數據對比？</strong></p><p><strong>A</strong>：對於越權場景，我們可以識別到它在哪個環節進行了鑑權相關調用，不同的鑑權體系，有對應的權限相關服務和基礎接口，構造有權限和沒權限的場景後，它會識別沒權限後的鏈路調用變化，比如鏈路節點數量以及哪個節點返回可以發現大部分問題，如果在這層沒有識別到是否做鑑權，我們會關注每個節點的請求和返回，通過其他維度信息增強發現的有效性，降低噪聲。</p><p><strong>Q3：怎麼自動構造接口裏沒有權限的用户？</strong></p><p><strong>A</strong>：在原始流量裏，我們可以識別到它當前的鑑權方式以及它使用了哪些鑑權服務。這樣，我們可以基於這個鑑權方式和服務構造有權限或者沒有權限的用户。</p><p><strong>Q4：可靠性治理系統是自研的，還是開源的，研發工作量多少人月？</strong></p><p><strong>A</strong>：可靠性系統建設的思路，目前是自研，它基於美團的基礎設施和能力，展開上層解決可靠性問題的實踐；研發工作量其實還好，它的點在於我們能找到哪些可以進行治理，快速迭代相關能力，並且在這一過程中不斷補全新能力加進去，因此它是一個持續的過程，整體規劃上，我們會考慮可靠性，從服務和代碼的每一層，從機器、資源、基礎組件到服務自身、上游流量和網關分層，拆分不同節點，構建不同策略，這樣會有一個整體投入。</p><p><strong>Q5：流量限流和服務降級如何實現？</strong></p><p><strong>A</strong>：美團有服務限流和降級能力的基礎設施 Rhino 平台，服務降級是研發根據當前依賴等級，結合具體業務分析它是否是一個可降級的依賴，再配置對應的熔斷策略，當降級時，是繞過當前故障進行降級還是在故障恢復後 Fallback，這樣的相關規則和策略都可以配置化，自動化驗證這些策略是否生效、是否符合預期。</p><p><strong>Q6：在有了這些能力基礎上，基於模式的可靠性治理用例佔比多少？價值怎樣評價？</strong></p><p><strong>A</strong>：我們想基於模式找到一個通用的治理策略和能力，這樣的話，我們就可以將線上、線下海量流量數據都應用到這裏，不需要 QA 同學投入成本，編寫對應的用例，對於研發來説，我們希望直接確認和解決一些已識別到的問題，只需要花費問題確認和修復的成本。對於可識別用例佔比，因為它是基於全量流量，所以隨着時間的積累，歷史場景以及新場景會相應覆蓋到，它的用例有多少，取決於流量池以及流量質量和代表性。</p><p><strong>Q7：流量回放 Mock，使用字節碼，還是沙箱模式？</strong></p><p><strong>A</strong>：這裏用到美團的基礎設施能力，它在採集過程中，基於字節碼增強採集，回放能力也是使用到了同樣的能力。</p><p><strong>|</strong> 在美團公眾號菜單欄對話框回覆【2022 年貨】、【2021 年貨】、【2020 年貨】、【2019 年貨】、【2018 年貨】、【2017 年貨】等關鍵詞，可查看美團技術團隊歷年技術文章合集。</p><p><img src="https://p1.meituan.net/travelcube/b0364d579285ab22aa6235bd100d7c22178175.png" alt="" referrerpolicy="no-referrer"></p><p>| <a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%9C%AC%E6%96%87%E7%B3%BB%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E5%87%BA%E5%93%81%EF%BC%8C%E8%91%97%E4%BD%9C%E6%9D%83%E5%BD%92%E5%B1%9E%E7%BE%8E%E5%9B%A2%E3%80%82%E6%AC%A2%E8%BF%8E%E5%87%BA%E4%BA%8E%E5%88%86%E4%BA%AB%E5%92%8C%E4%BA%A4%E6%B5%81%E7%AD%89%E9%9D%9E%E5%95%86%E4%B8%9A%E7%9B%AE%E7%9A%84%E8%BD%AC%E8%BD%BD%E6%88%96%E4%BD%BF%E7%94%A8%E6%9C%AC%E6%96%87%E5%86%85%E5%AE%B9%EF%BC%8C%E6%95%AC%E8%AF%B7%E6%B3%A8%E6%98%8E%E2%80%9C%E5%86%85%E5%AE%B9%E8%BD%AC%E8%BD%BD%E8%87%AA%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E2%80%9D%E3%80%82%E6%9C%AC%E6%96%87%E6%9C%AA%E7%BB%8F%E8%AE%B8%E5%8F%AF%EF%BC%8C%E4%B8%8D%E5%BE%97%E8%BF%9B%E8%A1%8C%E5%95%86%E4%B8%9A%E6%80%A7%E8%BD%AC%E8%BD%BD%E6%88%96%E8%80%85%E4%BD%BF%E7%94%A8%E3%80%82%E4%BB%BB%E4%BD%95%E5%95%86%E7%94%A8%E8%A1%8C%E4%B8%BA%EF%BC%8C%E8%AF%B7%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E8%87%B3tech%40meituan.com%E7%94%B3%E8%AF%B7%E6%8E%88%E6%9D%83%E3%80%82" target="_blank">本文系美團技術團隊出品，著作權歸屬美團。歡迎出於分享和交流等非商業目的轉載或使用本文內容，敬請註明「內容轉載自美團技術團隊」。本文未經許可，不得進行商業性轉載或者使用。任何商用行為，請發送郵件至 tech@meituan.com 申請授權。</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 31 Oct 2023 02:15:01 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/10117396</guid>
            <link>https://my.oschina.net/meituantech/blog/10117396</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[📙《高併發的哲學原理》紙質版書稿完全開源，共 16 萬多字]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><img alt="" height="600" src="https://oscimg.oschina.net/oscnet/up-1fb8b3621b91010af5c26e565583383ab83.png" width="1762" referrerpolicy="no-referrer"></p><p><strong>閲讀地址：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpphc.lvwenhan.com" target="_blank">https://pphc.lvwenhan.com</a></p><p style="color:#24292f; text-align:start"><strong>pdf 下載鏈接在網站右上角。</strong></p><h3>寫作目標</h3><p style="color:#2c3e50; text-align:start">本書的目標是在作者有限的認知範圍內，討論一下高併發問題背後隱藏的一個哲學原理——找出單點，進行拆分。</p><h3>內容梗概</h3><p style="color:#2c3e50; text-align:start">我們將從動靜分離講起，一步步深入 Apache、Nginx、epoll、虛擬機、k8s、異步非阻塞、協程、應用網關、L4/L7 負載均衡器、路由器 (網關)、交換機、LVS、軟件定義網絡 (SDN)、Keepalived、DPDK、ECMP、全冗餘架構、用户態網卡、集中式存儲、分佈式存儲、PCIe 5.0、全村的希望 CXL、InnoDB 三級索引、內存緩存、KV 數據庫、列存儲、內存數據庫、Shared-Nothing、計算存儲分離、Paxos、微服務架構、削峯、基於地理位置拆分、高可用等等等等。並最終基於地球和人類社會的基本屬性，設計出可以服務地球全體人類的高併發架構。</p><p style="color:#2c3e50; text-align:start"><br> 全書共 167674 字。</p><h3>讀者評價</h3><blockquote><p>會上一談到架構和 I/O，我都想到你的文章。主講解答清楚和沒解答清楚的，都沒你的文章清楚。</p><p>—— 秋收，於 RubyConf 2023</p></blockquote><hr><blockquote><p>像看小説一樣把文章都看完了，全程無尿點，作者的腦袋是在哪裏開過光，知識儲備竟如此紮實</p><p>—— 觀東山</p></blockquote><hr><blockquote><p>非常棒的技術分享！深入淺出，娓娓道來，讓我想起了那本 csapp。</p><p>—— drhrchen</p></blockquote><hr><blockquote><p>寫得真好，膜拜！作者願意出書嗎，一定買！</p><p>—— bean</p></blockquote><hr><blockquote><p>拜讀了！應該算是架構頂級總結！！</p><p>—— 雨山前</p></blockquote><hr><blockquote><p>看完了，博主好厲害，學習到了各種騷技巧，和知識，膜拜</p><p>—— evanxian</p></blockquote><hr><blockquote><p>寫的太好了，不僅充滿了理工科的嚴謹較真，也充滿了文科的浪漫</p><p>—— 一秒</p></blockquote><hr><blockquote><p>寫得很好，視角也是我喜歡的，站在地球表面，述事宏大，思維自信。</p><p>—— 納秒時光</p></blockquote><hr><blockquote><p>全部看完，博主太強了，很受啓發</p><p>—— Bruce</p></blockquote><hr><blockquote><p>棒</p><p>—— JuniaWonter</p></blockquote><h2>作者信息</h2><h3>呂文翰</h3><ol><li>GitHub：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjohnlui" target="_blank">johnlui</a></li><li>職位：住範兒創始成員，CTO，監事</li></ol><h4>高併發系統處理經驗</h4><ol><li>2017 年維護的單體 CMS 系統頂住了每日兩百萬 PV 的壓力</li><li>2020 年優化一個單機 PHP 商城頂住了 QPS 1000+ 的壓力</li><li>2021 年設計的分佈式電商秒殺系統在實際業務中跑到了最高一分鐘 GMV 500 萬，QPS 10000+</li></ol><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e128c2c71f79a9f5c551fa204024a7d6d1.jpg" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p>&nbsp;</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c1a9c97d554a8c227a53037467944206a7c.jpg" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ce3364f3899525cd6ffc33de9d05faf6e73.jpg" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-03c79aa58b98f1f7f757bc4647cc40a81b0.jpg" referrerpolicy="no-referrer"></p><p><img alt="" height="1818" src="https://oscimg.oschina.net/oscnet/up-bbca5aa6d8d33372882757c429ad5a13815.jpg" width="3320" referrerpolicy="no-referrer"></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 05:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264073</guid>
            <link>https://www.oschina.net/news/264073</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Hugging Face 分詞器新增聊天模板屬性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 編輯器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);"><em style="color: black;">一個幽靈，格式不正確的幽靈，在聊天模型中游蕩！</em></p></blockquote><span id="OSC_h2_1"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">太長不看版</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">現存的聊天模型使用的訓練數據格式各各不同，我們需要用這些格式將對話轉換為單個字符串並傳給分詞器。如果我們在微調或推理時使用的格式與模型訓練時使用的格式不同，通常會導致嚴重的、無聲的性能下降，因此匹配訓練期間使用的格式極其重要！Hugging Face 分詞器新增了 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 屬性，可用於保存模型訓練時使用的聊天格式。此屬性包含一個 Jinja 模板，可將對話歷史記錄格式化為正確的字符串。請參閲，技術文檔，以瞭解有關如何在代碼中編寫和應用聊天模板。</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">引言</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你熟悉 🤗 transformers 庫，你可能寫過如下代碼:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">tokenizer&nbsp;=&nbsp;AutoTokenizer.from_pretrained(checkpoint)<br>model&nbsp;=&nbsp;AutoModel.from_pretrained(checkpoint)<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">通過從同一個 checkpoint 中加載分詞器和模型，可以確保對輸入字符串使用的分詞方法符合模型預期。如果你從另一個模型中選擇分詞器，則其分詞結果很可能會完全不同，此時模型的性能就會受到嚴重損害。這種現象叫 <strong style="color: black;">分佈漂移 (distribution shift)</strong>: 模型一直從一種分佈學習 (即訓練分詞器)，突然，數據分佈變成了另一個不同的分佈。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">無論你是微調模型還是直接用它進行推理，讓這種分佈上的變化儘可能小，並保持提供的輸入儘可能與訓練時的輸入一致總是一個好主意。對於常規語言模型，做到這一點相對容易 - 只需從同一檢查點加載分詞器和模型，就可以了。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">然而，對於聊天模型來説，情況有點不同。這是因為「聊天」不僅僅是直接對單個文本字符串進行分詞 - 它需要對一系列消息進行分詞。每個消息都包含一個 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">角色</code> 及其 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">內容</code> ，其內容是消息的實際文本。最常見的，角色是「用户」(用於用户發送的消息) 、「助理」(用於模型生成的響應)，以及可選的「系統」(指在對話開始時給出的高級指令)。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">幹講可能有點抽象，下面我們給出一個示例聊天，把問題具象化:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">[<br>&nbsp;&nbsp;&nbsp;&nbsp;{<span style="color: #d14;line-height: 26px;">"role"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"user"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"content"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"Hi&nbsp;there!"</span>},<br>&nbsp;&nbsp;&nbsp;&nbsp;{<span style="color: #d14;line-height: 26px;">"role"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"assistant"</span>,&nbsp;<span style="color: #d14;line-height: 26px;">"content"</span>:&nbsp;<span style="color: #d14;line-height: 26px;">"Nice&nbsp;to&nbsp;meet&nbsp;you!"</span>}<br>]<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">此消息序列需要先轉換為一個文本字符串，然後才能對其進行分詞以輸入給模型。但問題是，轉換方法有很多！例如，你可以將消息列表轉換為「即時消息」格式:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">User:&nbsp;Hey&nbsp;there!<br>Bot:&nbsp;Nice&nbsp;to&nbsp;meet&nbsp;you!<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">或者你可以添加特殊詞元來指示角色:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">[USER]&nbsp;Hey&nbsp;there!&nbsp;[/USER]<br>[ASST]&nbsp;Nice&nbsp;to&nbsp;meet&nbsp;you!&nbsp;[/ASST]<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">抑或你可以添加詞元以指示消息之間的邊界，而將角色信息作為字符串插入:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">&lt;|im_start|&gt;user<br>Hey&nbsp;there!&lt;|im_end|&gt;<br>&lt;|im_start|&gt;assistant<br>Nice&nbsp;to&nbsp;meet&nbsp;you!&lt;|im_end|&gt;<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">方法多種多樣，但沒有哪種方法是最好的或是最正確的。因此，不同的模型會採用截然不同的格式進行訓練。上面這些例子不是我編造的，它們都是真實的，並且至少被一個現存模型使用過！但是，一旦模型接受了某種格式的訓練，你需要確保未來的輸入使用相同的格式，否則就可能會出現損害性能的分佈漂移。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">模板: 一種保存格式信息的方式</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">當前的狀況是: 如果幸運的話，你需要的格式已被正確記錄在模型卡中的某個位置; 如果不幸的話，它不在，那如果你想用這個模型的話，只能祝你好運了; 在極端情況下，我們甚至會將整個提示格式放在，相應模型的博文，中，以確保用户不會錯過它！但即使在最好的情況下，你也必須找到模板信息並在微調或推理流水線中手動將其寫進代碼。我們認為這是一個特別危險的做法，因為使用錯誤的聊天格式是一個 <strong style="color: black;">靜默錯誤</strong> - 一旦出了錯，不會有顯式的失敗或 Python 異常來告訴你出了什麼問題，模型的表現只會比用正確格式時差多了，但很難調試其原因！</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這正是 <strong style="color: black;">聊天模板</strong> 旨在解決的問題。聊天模板是一個 Jinja 模板字符串，你可以使用分詞器保存和加載它。聊天模板包含了將聊天消息列表轉換為模型所需的、格式正確的輸入字符串所需要的全部信息。下面是三個聊天模板字符串，分別對應上文所述的三種消息格式:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">{% for message in messages %}<br>    {% if message['role'] == 'user' %}<br>        {{ "User : " }}<br>    {% else %}<br>        {{ "Bot : " }}<br>    {{ message['content'] + '\n' }}<br>{% endfor %}<br></code></pre><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">{% for message in messages %}<br>    {% if message['role'] == 'user' %}<br>        {{ "[USER]" + message['content'] + " [/USER]" }}<br>    {% else %}<br>        {{ "[ASST]" + message['content'] + " [/ASST]" }}<br>    {{ message['content'] + '\n' }}<br>{% endfor %}<br></code></pre><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">"{% for message in messages %}"<br>    "{{'&lt;|im_start|&gt;' + message['role'] + '\n' + message['content'] + '&lt;|im_end|&gt;' + '\n'}}"<br>"{% endfor %}"<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你不熟悉 Jinja，我強烈建議你花點時間研究下這些模板字符串及其相應的模板輸出，看看你是否可以弄清楚這些模板如何將消息列表轉換為格式化的消息字符串！其語法在很多方面與 Python 非常相似。</p><span id="OSC_h2_4"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">為什麼要使用模板？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你不熟悉 Jinja，一開始上手可能會有點困惑，但我們在實踐中發現 Python 程序員可以很快上手它。在開發此功能的過程中，我們考慮了其他方法，例如允許用户按角色指定消息的前綴和後綴。我們發現該方法會變得令人困惑且笨重，而且它非常不靈活，以至於對一些模型而言，我們得需要一些巧妙的變通才行。而另一方面，模板功能強大到足以完全支持我們所知的所有消息格式。</p><span id="OSC_h2_5"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">為什麼要這樣做呢？為什麼大家不統一到一個標準格式呢？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">好主意！不幸的是，為時已晚，因為現有的多個重要模型已經基於迥異的聊天格式進行了訓練。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">然而，我們仍然可以稍微緩解下這個問題。我們認為最接近「標準」的格式是 OpenAI 創建的 ChatML 格式。如果你正在訓練新的聊天模型，並且此格式適合你，我們建議你使用它並給分詞器添加特殊的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">&lt;|im_start|&gt;</code> 和 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">&lt;|im_end|&gt;</code> 詞元。它的優點是角色非常靈活，因為角色只是作為字符串插入，而不是特定的角色詞元。如果你想使用這個，它是上面的第三個模板，你可以簡單地使用一行代碼進行設置:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">tokenizer.chat_template&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">"{%&nbsp;for&nbsp;message&nbsp;in&nbsp;messages&nbsp;%}{{'&lt;|im_start|&gt;'&nbsp;+&nbsp;message['role']&nbsp;+&nbsp;'\n'&nbsp;+&nbsp;message['content']&nbsp;+&nbsp;'&lt;|im_end|&gt;'&nbsp;+&nbsp;'\n'}}{%&nbsp;endfor&nbsp;%}"</span><br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">不過，除了格式林立的現狀之外，還有第二個不硬設標準格式的原因 - 我們預計模板將廣泛用於多種類型模型的預處理，包括那些可能與標準聊天操作迥異的模型。硬設標準格式限制了模型開發人員使用此功能完成我們尚未想到的任務的能力，而模板則為用户和開發人員提供了最大的自由度。甚至可以在模板中加入邏輯檢查和判斷，這是目前任何默認模板中都沒有深入使用的功能，但我們希望它能成為喜歡冒險的用户手中的利刃。我們堅信，開源生態系統應該讓你能夠做你想做的事，而不是命令你做什麼。</p><span id="OSC_h2_6"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">模板如何工作？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">聊天模板是 <strong style="color: black;">分詞器</strong> 的一部分，因為它們履行與分詞器相同的角色: 存儲有關如何預處理數據的信息，以確保你以與訓練時相同的格式將數據提供給模型。我們的設計使得用户非常容易將模板信息添加到現有分詞器並將其保存或上傳到 Hub。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在有聊天模板這個功能之前，聊天格式信息都存儲在 <strong style="color: black;">類級別</strong> - 這意味着，例如，所有 LLaMA checkpoint 都將使用同一個硬設在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 的 LLaMA 模型類代碼中的聊天格式。為了向後兼容，目前具有自定義聊天格式方法的模型類也已被賦予了 <strong style="color: black;">默認聊天模板</strong>。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在類級別設置默認聊天模板，用於告訴 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">ConversationPipeline</code> 等類在模型沒有聊天模板時如何格式化輸入，這樣做 <strong style="color: black;">純粹是為了向後兼容</strong>。我們強烈建議你在任何聊天模型上顯式設置聊天模板，即使默認聊天模板是合適的。這可以確保默認聊天模板中的任何未來的更改或棄用都不會破壞你的模型。儘管我們將在可預見的將來保留默認聊天模板，但我們希望隨着時間的推移將所有模型轉換為顯式聊天模板，屆時默認聊天模板可能會被完全刪除。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">有關如何設置和應用聊天模板的詳細信息，請參閲，技術文檔。</p><span id="OSC_h2_7"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">我該如何開始使用模板？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">很簡單！如果分詞器設置了 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 屬性，則它已準備就緒。你可以在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">ConversationPipeline</code> 中使用該模型和分詞器，也可以調用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">tokenizer.apply_chat_template()</code> 來格式化聊天以進行推理或訓練。請參閲我們的，開發者指南，或 如何應用聊天模板的文檔，以瞭解更多！</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果分詞器沒有 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 屬性，它可能仍然可以工作，但它將使用該模型類的默認聊天模板。正如我們上面提到的，這是脆弱的，並且當類模板與模型實際訓練的內容不匹配時，它同樣會導致靜默錯誤。如果你想使用沒有 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 的 checkpoint，我們建議檢查模型卡等文檔以確保使用正確的格式，然後為該格式添加正確的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 。即使默認聊天模板是正確的，我們也建議這樣做 - 它可以使模型面向未來，並且還可以清楚地表明該模板是存在的且是適用的。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">即使不是你的 checkpoint，你也可以通過提交，合併請求 (pull request) &nbsp;的方式為其添加 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 。僅需將 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">tokenizer.chat_template</code> 屬性設置為 Jinja 模板字符串。完成後，推送更改就可以了！</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">如果你想在你的聊天應用中使用某 checkpoint，但找不到有關其使用的聊天格式的任何文檔，你可能應該在 checkpoint 上提出問題或聯繫其所有者！一旦你弄清楚模型使用的格式，請提交一個 PR 以添加合適的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">chat_template</code> 。其他用户將會非常感激你的貢獻！</p><span id="OSC_h2_8"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">總結: 模板理念</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我們認為模板是一個非常令人興奮的新特性。除了解決大量無聲的、影響性能的錯誤之外，我們認為它們還開闢了全新的方法和數據模式。但最重要的也許是，它們還代表了一種理念轉變: 從核心 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 代碼庫中挪出一個重要功能，並將其轉移到各自模型的倉庫中，用户可以自由地做各種奇怪、狂野抑或奇妙的事情。我們迫不及待想看看你會發現哪些用途！</p><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">🤗 寶子們可以戳 <strong style="color: black;">閲讀原文</strong> 查看文中所有的外部鏈接喲！</p></blockquote><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/chat-templates</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Matthew Carrigan</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">譯者: Matrix Yao (姚偉峯)，英特爾深度學習工程師，工作方向為 transformer-family 模型在各模態數據上的應用及大規模模型的訓練推理。</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">審校/排版: zhongdongy (阿東)</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 29 Oct 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10120361</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10120361</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 可以做 WebRTC 音視頻質量性能優化，驚豔到我了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p><strong>摘要</strong></p><blockquote><p>隨着 GPT-4 的發佈，AI 的風越吹越旺。GPT-4 可以回答問題，可以寫作，甚至可以基於一張草圖生成 html 代碼搭建一個網站。即構社區的一位開發者@倪同學就基於目前在研究的 WebRTC QOS 技術點對 GPT-3.5 跟 GPT-4 進行一場實驗，ChatGPT 會取代程序員還是成為最強輔助？</p></blockquote><p><strong>以下為@倪同學的博文。</strong></p><hr><h1>ChatGPT 取代程序員還是給程序員加 Buff？</h1><p>這兩週，AI 新聞一個接着一個，3 月 23 日，Google 開放了內測已久的 AI 對話服務 Bard，Google 強調，這是一款定位為用户提供創意之源的產品，可生成寫作草稿或生活中的聊天機器人。早在一週前 3 月 15 日凌晨，OpenAi 距發佈 GPT-3.5 後四個月發佈了升級版模型 GPT-4，據發佈會説，GPT-4 可支持圖片輸入，角色扮演，寫作能力更強了。緊接着 3 月 16 日百度發佈了文心一言，一共有五大功能：文學創作、商業文案創作、數理邏輯推算、中文理解、多模態生成。</p><p>隨着近日各大廠商 AI 產品的接連發布，<strong>AI 取代人工</strong>這個話題持續在發酵。AI 大幅解放人的生產力或是將衝擊一大批職業？</p><p>博主近期在輸出 WebRTC 相關的技術博客，不如向 AI 提問看他有什麼見解。</p><p>和大部分人一樣，博主都還沒拿到 Bard 跟文心一言的內測資格。得知 NewBing 用的是 GPT-4 的模型，下面就着<strong>WebRTC 通過哪些 QOS 技術提升音視頻通話質量</strong>，向 GPT-3.5 和 Newbing（GPT-4）分別提問，看看他們的答案有何差異。</p><p>如下圖，技術科普類問題都難不倒 GPT-3.5 和 GPT-4，我就該問題繼續深挖讓它們舉實例説明：</p><p>NewBing(GPT-4)</p><p><img src="https://oscimg.oschina.net/oscnet/up-4629da845197985993c293d94127cc0c271.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-3.5 給出的結果</p><p><img src="https://oscimg.oschina.net/oscnet/up-54f9e77266206f54ed5b4f0946988bcca36.png" alt="" referrerpolicy="no-referrer"></p><p>NewBing(GPT-4) 直接給出了具體操作實例</p><p><img src="https://oscimg.oschina.net/oscnet/up-d7d0918e1048c337e7d4649564b3858f3f3.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-3.5 給出的結果（有些空泛）</p><p><img src="https://oscimg.oschina.net/oscnet/up-e9dc01bfdceb3cc698a4093d5b1d46da426.png" alt="" referrerpolicy="no-referrer"></p><h1>GPT-4 和 GPT-3.5 對比結論</h1><p>通過實驗，我們比較了同一問題兩個版本的回答。在普通的文本處理當中，GPT-4 和 GPT-3.5 的區別可能比較小，但是當問題足夠具體和複雜時，GPT-4 就會比 GPT-3.5 更精準、更有創意，而且能夠處理用户更細微的指令。</p><p>當然，本篇內容不是要討論 GPT-3.5 跟 GPT-4 的具體差別，而是程序員如何利用 ChatGPT 提升工作效率，加上最強 Buff。以下我將以個人開發經驗為音視頻開發者分享《<strong>WebRTC 的 QOS 如何提升音視頻質量》。</strong></p><h1><strong>WebRTC 技術概述</strong></h1><p>WebRTC 通過一系列的 QOS 技術來提升音視頻通話質量: 抗丟包策略 (NACK、 FEC), 擁塞控制策略 (TWCC/REMB), SVC 或多視軌, 視頻質量自適應策略， Pacer、JitterBuffer 等.</p><p>總體 QOS 架構如下圖所示：</p><p><img src="https://oscimg.oschina.net/oscnet/up-ce883c8c8e5fbb12f3bd9320f13c85cb0aa.png" alt="" referrerpolicy="no-referrer"></p><p>圖 1</p><h1><strong>1</strong><strong>丟包恢復策略</strong></h1><h2><strong>1.1 NACK</strong></h2><p>NACK(Negative Acknowledgment) 相較於 ACK 是通過"非到達確認"進行選擇性重傳的機制。基本原理是發送端對數據進行緩存，接收端通過到達包連續性檢測丟包，結合 rtt 和亂序情況在合適的時機向發送端發起重傳請求。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1d2480e0c83a78a74feed657cd91b53ff67.png" alt="" referrerpolicy="no-referrer"></p><p>圖 2</p><p>如圖所示,Receiver 在收到報文 4 之後發現報文 2、3 未到達，暫時將報文 2、3 放入丟失 nack 列表。在超過一定亂序閾值 (通過亂序直方圖計算得到，假設這裏是 2，那麼收到包 4 可認為包 2 丟失)，或者超過一定抖動時間 (根據 rtt 計算)，向 Sender 請求重傳丟失的報文 2、3。 Receiver 的請求通過 RTP FB 發送給 Sender, 具體 NACK 請求格式參考 RFC4585。Sender 在收到 NACK 請求後重新發送報文 2、3。</p><p><strong>值得注意的是</strong>，NACK 策略丟包恢復效果取決於重傳請求時機。一是 rtt 的計算 (webrtc 默認 rtt 是 100ms)，一是亂序閾值計算。重傳請求節奏控制不好容易造成重傳風暴，加重擁塞導致拉流出現卡頓。</p><p>參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc4585.html%23page-34%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc4585.html#page-34</a></p><h2><strong>1.2</strong><strong>FEC</strong></h2><p>FEC(Forward Error Correction),前向糾錯, 在數據傳輸和存儲中普遍用於數據糾錯。WebRTC 中也使用了該技術進行丟包恢復。</p><p>webrtc 實現該冗餘功能，有三種方式：</p><h3><strong>1.2.1、RED</strong></h3><p>將前面的報文直接打入到新包裏面，在接收端解析主包和冗餘包。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dcd63ecbf52cf04e410e589f927271b375a.png" alt="" referrerpolicy="no-referrer"></p><p>圖 3</p><p>如圖，後面的報文直接包含前面報文，所以當其中某個報文丟失了，可以通過其相鄰報文直接恢復。這種方式缺點是抗連續丟包效果差，但是實現簡單。</p><p>Opus In-band FEC 正是使用這種方式進行糾錯： 將重要信息以較低的比特率再次編碼之後添加到後續數據包中，opsu 解碼器根據收包情況決定是否利用當前包攜帶的冗餘包進行丟包恢復。</p><p>Opus In-band FEC 詳細參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Frfc6716%23section-2.1.7" target="_blank">https://datatracker.ietf.org/doc/html/rfc6716#section-2.1.7</a></p><p>RED 詳細介紹參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc2198.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc2198.html</a></p><h3><strong>1.2.2、ULPFEC</strong></h3><p>在多個數據包之間使用 XOR 來生成此冗餘信息，並能夠在需要時在接收方恢復丟失的數據包。 ULPFEC 能夠通過選擇受保護的字節數並應用 XOR 的先前數據包的數量，為不同的數據包提供不同級別的保護。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dbc67f90d60129a5ac409477503478c5928.png" alt="" referrerpolicy="no-referrer"></p><p>圖 4</p><p>如圖，FEC packet 1 保護 L0 級報文 A、B。 FEC packet 2 及保護 L0 級的 A、B, 也保護 L1 級報文 C、D。</p><p>參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc5109.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc5109.html</a></p><h3><strong>1.2.3、FLEXFEC</strong></h3><p>較 ULPFEC，FLEXFEC 可以靈活選擇 1D 行異或、列異或以及 2D 行列異或，增加網絡抗丟包能力。</p><p>1-D 行異或糾錯</p><p><img src="https://oscimg.oschina.net/oscnet/up-10096bc8991b4dd01f54dfc56124b023479.png" alt="" referrerpolicy="no-referrer"></p><p>圖 5</p><p>1-D 列異或糾錯</p><p><img src="https://oscimg.oschina.net/oscnet/up-b5c40a4c18f39836dbb9e92fc3017670964.png" alt="" referrerpolicy="no-referrer"></p><p>圖 6</p><p>2-D 行列異或糾錯</p><p><img src="https://oscimg.oschina.net/oscnet/up-36d1716da02b29d6139ec01f2c1ca7a4845.png" alt="" referrerpolicy="no-referrer"></p><p>圖 7</p><p>FLEXFEC 雖然相比前面兩個有更強的恢復能力，行列交錯丟包比如圖 7 中 (1、2、5、6) 丟失就會出現無法糾錯的情況。</p><p>WebRTC 用到 FEC 策略整體丟包恢復能力都偏弱，業界普遍應用 Reed-Solomon FEC 進行丟包恢復，Reed-Solomon FEC(K + N : K 個數據包 N 個 FEC 包) 可以真正恢復分組內任意 &lt;=N 個丟包。</p><p>FLEXFEC 詳細實現可以參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc8627.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc8627.html</a></p><h1><strong>2 帶寬評估及碼率控制</strong></h1><h2><strong>2.1 REMB-GCC</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-0651b1a1da43906fa2e59639953688b12dc.png" alt="" referrerpolicy="no-referrer"></p><p>圖 8</p><p>圖 8 是 REMB-GCC 架構圖，基本思想是通過接收端評估帶寬， 然後通過 RTCP REMB 將帶寬反饋給發送端。 發送端結合丟包率計算一個帶寬結果 As,和 RMEB 的結果 Ar, 取 min(As, Ar) 作為最終帶寬結果。</p><h2><strong>2.2 SendSide BWE</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-c4f0e4a20b5e2e2bc5801517dce2e63525b.png" alt="" referrerpolicy="no-referrer"></p><p>圖 9</p><p>跟<strong>REMB-GCC</strong> 相比，TFB-GCC 主要區別在於大部分帶寬計算都轉移到發端計算，濾波器的實現不再用 Kalman 濾波，而是變成<strong>TrendLine 濾波器</strong>。</p><p>發送端發送的包需在擴展頭帶： Transport-wide sequence number.</p><p>接收端定期發送 Transport-wide feedback 報文，通知發送端和接收端接收報文的相關信息，包括報文到達時間、報文到達時間、報文格式等信息。發送端收到 Transport-wide feedback 報文之後，根據報文攜帶的信息進行延遲濾波計算 (Trandline).</p><p>Transport-wide feedback 報文格式參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Fdraft-holmer-rmcat-transport-wide-cc-extensions-01%3Fsource%3Doschina%26article64" target="_blank">https://datatracker.ietf.org/doc/html/draft-holmer-rmcat-transport-wide-cc-extensions-01</a></p><h2><strong>2.3 速率控制</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-cf155320998fb6f015ca55496f9b6716354.png" alt="" referrerpolicy="no-referrer"></p><p>圖 10</p><p><img src="https://oscimg.oschina.net/oscnet/up-6c862c3581fe6d7a57ae15e961f84f7db78.png" alt="" referrerpolicy="no-referrer"></p><p>圖 11</p><p>根據過載檢測器產生的信號 s，驅動如圖 10 所示的有限狀態機來調整碼率。</p><p>GCC 算法原理詳細參考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fc3lab.poliba.it%2Fimages%2F6%2F65%2FGcc-analysis.pdf%3Fsource%3Doschina%26article64" target="_blank">https://c3lab.poliba.it/images/6/65/Gcc-analysis.pdf</a></p><h1><strong>3</strong><strong>SVC</strong><strong>、多視軌</strong></h1><h2><strong>3.1</strong><strong>SVC</strong></h2><p>SVC (Scalable Video Coding，可適性視頻編碼或可分級視頻編碼) 是傳統 H.264/MPEG-4 AVC 編碼的延伸，可提升更大的編碼彈性，並具有時間可適性 (Temporal Scalability)、空間可適性 (Spatial Scalability) 及質量可適性 (SNR/Quality/Fidelity Scalability) 三大特性。</p><p>WebRTC 中 h264 不支持 svc 編碼，Vp8 僅支持 Temporal Scalability, VP9 和 AV1 支持時間可適性 (Temporal Scalability)、空間可適性 (Spatial Scalability)。</p><p><img src="https://oscimg.oschina.net/oscnet/up-973028f5afa2ef31a24851f224e9e74bd0e.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-e52d6c53588cf1a352975f823e2cef803dd.png" alt="" referrerpolicy="no-referrer"></p><p>圖 12</p><p>上面是時間可適應示意圖。假設圖例中顯示的圖層以 30 fps 的幀速率顯示。如果我們移除所有 L2 層的圖片，剩下層（L0 和 L1）仍然可以成功解碼，並且產生一個 15fps 的視頻。如果我們進一步刪除所有的 L1 圖像，那麼剩下的 L0 層依然可以被解碼併產生一個 7.5fps 的視頻, 所以即便是出現丟包，相比不可分級編碼可明顯提升弱網視頻流暢度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b2dfcbe88b9bfb1b8f3f1f22ad9267f43be.png" alt="" referrerpolicy="no-referrer"></p><p>圖 13</p><p>如圖 12，L0 基層為分辨率最小編碼數據，級別越高，分辨率越高。當實際應用中需要較低分辨率時，只需丟棄高 Level 層級數據進行解碼。</p><p>針對不同的帶寬條件用户和以及不同設備性能的用户可以靈活調整分辨。</p><p>SVC 擴展參考： <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fip.hhi.de%2Fimagecom_G1%2Fassets%2Fpdfs%2FOverview_SVC_IEEE07.pdf%3Fsource%3Doschina%26article64" target="_blank">http://ip.hhi.de/imagecom_G1/assets/pdfs/Overview_SVC_IEEE07.pdf</a></p><p>SVC 與 H264 結合參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.itu.int%2Frec%2FT-REC-H.264-201704-I%3Fsource%3Doschina%26article64" target="_blank">https://www.itu.int/rec/T-REC-H.264-201704-I</a></p><h2><strong>3.2 多視軌</strong></h2><p>目前主流瀏覽器都支持 unified-plan sdp, 我們可以在 sdp 協商的時候添加多個視軌，業務上比較常見的就是添加兩條視軌 (類似於 SVC 的 Spatial Scalability)，複用相同 DTLS 傳輸通道。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e11f7f6b5c3c71a6cc86c76a69182dc2ddf.png" alt="" referrerpolicy="no-referrer"></p><p>圖 14</p><p>圖 12 典型利用 WebRTC 支持多視軌特性編碼一大一小兩條流的出幀示意圖。</p><p>支持多視軌 (大小流) 可以讓接收端在下行帶寬受限的情況下動態切換到可以支持的分辨率，提升弱網體驗。</p><p>多視軌 (大小流) 在對網絡丟包及帶寬受限情況的適應不如 SVC 靈活，但是多視軌實現簡單，編碼、解碼性能消耗較低，在實際的業務場景中得到廣泛應用。</p><p>多視軌需要支持 Unified Plan SDP 協商, 參考 WebRTC 相關説明：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwebrtc.github.io%2Fwebrtc-org%2Fweb-apis%2Fchrome%2Funified-plan%2F%3Fsource%3Doschina%26article64" target="_blank">https://webrtc.github.io/webrtc-org/web-apis/chrome/unified-plan/</a></p><h1><strong>4 視頻質量調整策略</strong></h1><p>在網絡傳輸質量變差 (上行帶寬不足)、CPU 佔有率過高，編碼器編碼質量 QP 值過大等情況下，WebRTC 會通過降質量來保障視頻通話。降質量策略主要分降幀率 (即清晰優先模式) 和降分辨率 (即流暢優先模式)，通過 MediaStreamTrack Content Hints 來設置。</p><p><strong>清晰優先模式</strong> WebRTC 在編碼的時候更注重視頻細節，在出現上述情況需要降質量時，會通過降低幀率、保持分辨率不變來保障拉流用户的主觀感受。對於推流端做屏幕分享內容是 PPT 或者拉流用户大屏顯示的業務場景尤為重要。</p><p><strong>流暢優先模式</strong> 推流端在需要降質量的時候優先降低分辨率、保持一定的幀率來保障拉流用户的流暢體驗。</p><p>在帶寬或 CPU 資源等不再受限時，WebRTC 會根據降質量偏好設置逆向提升視頻質量。</p><p>使用者應該根據自己的業務場景進行適當設置，才能在極端情況下保證主觀體驗不至於太差。</p><h1><strong>5 Pacer</strong></h1><p>WebRTC 的 Pacer 模塊主要是讓需要發送的包根據評估的網絡帶寬儘量均勻的分佈在每個發送時間窗口發出，起到平滑發包、避免網絡擁塞的作用。</p><p>假設有一條 5Mbps 和 30fps 的視頻流。 在理想情況下，每個幀大小約為 21kB，打包成 18 個 RTP 數據包。 按照一秒時間窗口統計的平均比特率是 5Mbps，但在更短的時間範圍內，它可以被視為每 33 毫秒突發 167Mbps。 此外，視頻編碼器在突然移動的情況下會超過目標幀率，尤其是在處理屏幕共享時，幀比目標尺寸大 10 倍甚至 100 倍很常見。 這些數據包如果編碼完成馬上發出去會導致幾個問題: 網絡擁塞、緩衝區膨脹、甚至數據包丟失。 大多數會話都有不止一條媒體流，可能同時包含音頻流、視頻流、數據流。 如果你一次性將一個幀放在一條傳輸通道發送，這些數據包需要 100 毫秒才能發出，這可能阻止了任何音頻數據包及時發送出去。 Pacer 通過有一個緩衝區來解決這個問題。 媒體包在其中排隊，然後使用漏桶算法將它們調整到網絡上。 緩衝區包含所有媒體軌道的獨立 fifo 流，例如，音頻可以優先於視頻 - 可以以循環方式發送相同優先級的流，以避免任何一個流阻塞其他流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3b894e7d0824cc00b76bb2b75a11c932177.png" alt="" referrerpolicy="no-referrer"></p><p>圖 15</p><h1><strong>6 JitterBuffer</strong></h1><p><img src="https://oscimg.oschina.net/oscnet/up-0a330d475cd478eb5ad7158389b8d6b3362.png" alt="" referrerpolicy="no-referrer"></p><p>圖 16</p><p>WebRTC 接收端收到 RTP 包後，放到 PacketBuffer 進行緩存和排序。如上圖，在收到 Mark(幀結束) 標誌之後，從後往前開始組幀。組完一幀會放到該幀所在 GOP 的緩存裏面，根據幀間參考順序進行調整，當幀間參考關係建立好之後就會放到解碼器進行解碼。可以認為 Jitter 主要先後做包排序、幀排序、GOP 排序。之所以要進行着一系工作是因為網絡本身存在一定的抖動、甚至有丟包，如果有丟包還得等丟包恢復才能完整組幀，所以導致幀到達時間跟發送時間存在一定抖動。Jitter buffer 的存在就很好的解決這個問題，能夠在拉流端對待解碼數據進行平滑處理，保證我們渲染出來視頻是平滑、流暢的。</p><h1><strong>7 關鍵幀請求</strong></h1><p>視頻流通常是以 1 個關鍵幀+ N 個增量幀的方式發送，這些增量幀依賴於先前的幀進行解碼和顯示。如果因為一些原因導致 sps/pps 丟失、 組包錯誤等，如果不採取任何補救措施，就很難繼續解碼視頻流，視頻就會卡主, 直到下個關鍵幀。很多時候為了編碼穩定 GOP 設置很大，這個時候意味着長時間卡頓或者黑屏。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a58f2b74a6631610904cf29d65b3ff8ec98.png" alt="" referrerpolicy="no-referrer"></p><p>圖 17</p><p>如圖接收端因為丟包不能恢復導致 Frame 9 組幀失敗，後面即使能組幀成功也無法解碼，此時需要從發送端請求一個 I 幀解碼刷新當前視頻流。</p><p>WebRTC 通過 RTCP 報文向發送端請求發送關鍵幀，關鍵幀請求 RTCP 報文格式比較簡單，在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc4585" target="_blank">RFC4585</a>（RTP/AVPF）以及<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc5104" target="_blank">RFC5104</a>（AVPF）規定了兩種不同的關鍵幀請求報文格式：Picture Loss Indication (PLI)、Full Intra Request (FIR)。從目前的實現看 WebRTC 在收到 PLI 或者 FIR 之後，都是讓編碼器編碼輸出關鍵幀，然後發送給接收端。</p><p>PLI 報文格式參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc4585.html%23page-36%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc4585.html#page-36</a></p><p>FIR 參考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rfc-editor.org%2Frfc%2Frfc5104.html%3Fsource%3Doschina%26article64" target="_blank">https://www.rfc-editor.org/rfc/rfc5104.html</a></p><h1><strong>QOS 技術總結：</strong></h1><p>本文簡單介紹了 WebRTC 中所使用到的 Qos 技術，這些技術從不同的角度去提升 Qos 質量。包括通過<strong>NACK、FEC</strong>技術對丟包進行恢復，解決丟包導致的音、視頻卡頓。通過<strong>帶寬評估和擁塞控制</strong>技術調整編碼和發送碼率來自動適應網絡帶寬的變化情況。通過 SVC、多視軌技術保障不同網絡質量的拉流的用户差異的視頻質量。 而<strong>Pacer、JitterBuffer</strong>分別在發送端和接收端提升音視頻的平滑、流暢度。<strong>關鍵幀請求</strong>對極端網絡抖動之後的快速視頻恢復起了重要作用。WebRTC 利用這些技術協同作用，提升整體的 Qos 質量，需要了解技術細節最好的方式還是去閲讀 WebRTC 源碼。</p><p>WebRTC 的 Qos 技術對提升整體音視頻質量效果顯著、但 WebRTC 的這些技術還是存在有很多可以優化的地方。音視頻廠商 ZEGO 即構自研的 WebRTC 網關對這些策略都做了一定的優化：包括自研帶寬評估算法、NACK 算法、大小流等。</p><p>所以，如果你的業務需要一款穩定可靠的音視頻服務，可以試試即構實時音視頻 RTC 服務。</p><p><strong>點擊跳轉<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc-zh.zego.im%2Farticle%2F9675%3Fsource%3Doschina%26article64" target="_blank">ZEGO 即構實時音視頻服務</a>瞭解更多 WebRTC 最佳實踐內容。</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 12:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5818436/blog/8590740</guid>
            <link>https://my.oschina.net/u/5818436/blog/8590740</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國家廣電總局公示《雲遊戲總體技術要求》等行業標準]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>國家廣播電視總局科技司<u><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.nrta.gov.cn%2Fart%2F2023%2F10%2F30%2Fart_113_65962.html" target="_blank">發佈公告稱</a></u>，按照廣播電視和網絡視聽行業標準制定程序要求和計劃安排，國家廣播電視總局組織相關單位編制《沉浸式終端通用技術要求》《雲遊戲總體技術要求》《自由視角視頻系統技術要求》行業標準，現對已通過全國廣播電影電視標準化技術委員會審查的報批稿予以公示。</p><p><img height="1820" src="https://oscimg.oschina.net/oscnet/up-ad5c1b15dcc8e8faf28a1caa2fb63e4aefb.png" width="2436" referrerpolicy="no-referrer"></p><p>根據《雲遊戲總體技術要求》行業標準的報批稿，<strong>該文件規定了雲遊戲的總體技術架構，以及雲遊戲平台、網絡、雲遊戲終端和雲遊戲安全的技術要求</strong>，並針對未成年人用户對雲遊戲平台和雲遊戲終端提出了要求。</p><p>該標準的起草單位包括：</p><blockquote><p>國家廣播電視總局廣播電視科學研究院、騰訊科技（上海）有限公司、中國廣播電視網絡集團有限公司、咪咕互動娛樂有限公司、元境生生（北京）科技有限公司、浙江華數廣電網絡股份有限公司、江蘇省廣電有線信息網絡股份有限公司、中國廣電湖南網絡股份有限公司、國廣東方網絡（北京）有限公司、青島西發廣電傳媒科技有限公司、互影科技（北京）有限公司、北京決策數科技有限公司、北京和創摩爾科技有限公司。</p></blockquote><p>雲遊戲總體技術架構包括雲遊戲平台、網絡、雲遊戲終端和雲遊戲安全四個部分：</p><ul><li><p>雲遊戲平台接收用户操作指令，完成遊戲畫面的渲染、音視頻編解碼和遊戲推流等操作，將遊戲內容以音視頻流的形式通過網絡傳輸到用户側的終端進行呈現；</p></li><li><p>用户使用終端通過網絡發送操作指令到雲遊戲平台進行下一步遊戲畫面的渲染、遊戲推流等；</p></li><li><p>雲遊戲安全貫穿雲遊戲的各個環節，實現對用户信息、賬號信息、遊戲行為信息等的保護。</p></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c3dafe5b6f038392293411fb97f761a26cb.png" referrerpolicy="no-referrer"></p><p>文件顯示，雲遊戲平台應具備基於獨立 GPU 的畫面渲染能力，應符合 GY / T 353—2021 中的視頻格式要求，<strong>應具備 1080P / 50fps 或 1080P / 60fps 的畫面渲染能力</strong>，宜支持 2K / 60fps、4K / 50fps、4K / 60fps 等的畫面渲染。</p><p>網絡方面，根據遊戲畫面質量的不同，對網絡的要求也有所不同，<strong>比如 1080p 50/60fps 要求下行帶寬為 20Mbps。</strong></p><p><img alt="" src="https://img.ithome.com/newsuploadfiles/2023/10/a00f64bc-0450-4e75-bd10-557e31022a27.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3d6e9bf9cf65cd2abe5e3c9e79a1f6eb0b9.png" referrerpolicy="no-referrer"></p><p>雲遊戲終端方面，文件要求設備應滿足以下硬件配置要求：</p><ul><li><p>CPU：不低於 4 個處理核心，最高頻率不低於 1.5GHz；</p></li><li><p>內存：至少 1GB，建議 2GB 或以上；</p></li><li><p>存儲：4GB 或以上，高速 eMMC 或者 UFS。</p></li></ul><p>雲遊戲終端的解碼時延應滿足幀率為 30fps 時，解碼時延在 20ms 以內；幀率為 50/60fps 時，解碼時延在 10ms 以內。終端設備渲染的每一幀畫面和播放的聲音應嚴格同步，音畫同步時間宜不超過 + 90ms 和-185ms，其中，正值表示聲音超前於圖像，負值表示聲音滯後於圖像。<strong>額外操作時延應不大於 150ms，宜不大於 100ms</strong>。</p><p>對未滿 18 週歲的未成年人用户，雲遊戲平台應提供以下保護功能：</p><ul><li><p>具備對用户賬號進行實名管理的能力；</p></li><li><p>具備控制未成年人使用遊戲時段和時長的能力；</p></li><li><p>具備對未成年人用户遊戲消費管理的能力；</p></li><li><p>具備至少通過一種方式向監護者進行提醒通知的能力。</p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 10:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264148</guid>
            <link>https://www.oschina.net/news/264148</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[崑崙萬維開源「天工」Skywork-13B 系列大模型，0 門檻商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">崑崙萬維宣佈開源百億級大語言模型「天工」Skywork-13B 系列，並配套開源了 600GB、150B Tokens 的超大高質量開源中文數據集。崑崙萬維「天工」Skywork-13B 系列目前包括 130 億參數的兩大模型：Skywork-13B-Base 模型、Skywork-13B-Math 模型。</span></p><p><span style="color:#000000">除模型開源外，Skywork-13B 系列大模型還將開源 600GB、150B Tokens 的高質量中文語料數據集 Skypile/Chinese-Web-Text-150B。公告稱，這是目前最大的開源中文數據集之一。同時，崑崙萬維「天工」Skywork-13B 系列大模型即將全面開放商用；開發者無需申請，即可商用。</span></p><p><span style="background-color:#ffffff; color:#000000">「此次 Skywork-13B 系列大模型將全面開放商用許可，用户在下載模型並同意並遵守《Skywork 模型社區許可協議》後，無需再次申請授權即可將大模型進行商業用途。希望用户能夠更便捷地探索 Skywork-13B 系列大模型技術能力，探索在不同場景下的商業化應用。」</span></p><p><strong><span style="color:#000000">Skywork-13B-Base 模型</span></strong></p><blockquote><p><span style="color:#000000">Skywork-13B-Base 模型是 Skywork-13B 的基礎模型，其經由 3.2 萬億個多語言高質量數據訓練，在 CEVAL、CMMLU、MMLUGSM8K 等評測與基準測試上都展現了同等規模模型的最佳效果。</span></p></blockquote><p><strong><span style="color:#000000">Skywork-13B-Math 模型</span></strong>&nbsp;</p><blockquote><p><span style="color:#000000">Skywork-13B-Math 模型經過專門的數學能力強化訓練，在 GSM8K 等數據集上取得了同等規模模型的最佳效果。&nbsp;</span></p></blockquote><p><strong><span style="color:#000000">Skypile/Chinese-Web-Text-150B 數據集</span></strong>&nbsp;</p><blockquote><p><span style="color:#000000">該數據集是根據崑崙天工團隊方面經過精心過濾的數據處理流程從中文網頁中篩選出的高質量數據。本次開源的數據集大小約為 600GB，總 token 數量約為 150B，目前開源最大的中文數據集之一。</span></p></blockquote><p>一些評測結果如下所示：</p><p><img height="232" src="https://oscimg.oschina.net/oscnet/up-1db28014754e9cdff9ea99cd4870f7d3ee1.png" width="500" referrerpolicy="no-referrer">&nbsp;</p><p><img height="267" src="https://oscimg.oschina.net/oscnet/up-091dc8c601db00caf525c2b1517e82fda18.png" width="500" referrerpolicy="no-referrer"></p><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FQTe6pILo6jehgC7fiZBmmQ" target="_blank">查看官方公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 09:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264137</guid>
            <link>https://www.oschina.net/news/264137</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[為什麼好好的一個開源項目，商業化卻往往撲街？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div><p>數字化產品如何做商業化？為什麼有些開源項目這麼優秀，商業化卻老是撲街？第四期《開源漫談》，我們邀請了<strong>王曄倞（頭哥）</strong>和<strong>厲啓鵬（寈峯）</strong>，一起來聊聊，<strong>開源項目的商業化變現，到底該怎麼做？</strong></p><ul><li><p><strong>王曄倞（頭哥）</strong>，「頭哥侃碼」主理人，專注分享技術、創業與產品創新等主題內容。</p></li><li><p><strong>厲啓鵬（寈峯）</strong>，現為 vanus.ai CEO，曾就職於阿里雲，Apache RocketMQ PMC ，長期專注於 AI 基礎設施軟件及中間件。</p></li></ul><p>&nbsp;</p><p><strong>頭哥：</strong>技術，和一坨代碼，和一個好的產品，中間沒有直接的關係，只有間接的關係。所以你會發現很多人，他開源做得很好，但商業化做得很差。反過來有的人他商業化做得很好，但社區不會做。現在的 AI 類產品、大模型產品、開源產品，其實都是數字化產品。那麼第一個問題來了：</p><p><strong>數字化產品如何實現商業化？中間有什麼樣的途徑嗎？</strong></p><p>&nbsp;</p><p><strong>厲啓鵬：</strong>我先分享一下開源產品吧。一般來説，我們會先把產品在 Github 上開源，吸引一些人氣。這樣一來可以找到最初的用户，（畢竟開源是一種很好的推廣方式），二來可以通過開源快速地打磨這個產品，在開發者們的幫助下讓產品快速迭代，迅速成熟。第二步就是商業化了，在國內的話，像我們做基礎設施類的，一般都是以 license 的方式去售賣，或者去拿一些大項目。我們之前服務過大客户，像銀行、Saas 公司等等。除此之外，還有一種方式就是提供 Saas 服務，我們會先把產品託管到公有云上去，這樣用户在使用產品的時候就不需要自己去部署、自己去運維，需要的時候開箱即用即可。</p><p>不過，不同的項目，它的形態和在商業化的時候需要考慮的東西是不一樣的。舉個例子，我們現在 vanus 產品的用户有國內的也有國外的，但以我們的經驗來説，不同點在於：在國內，提供軟件服務的公司，很難避免去做私有化的交付方式。在中國現在的環境下去運營一個純產品類的公司還是蠻難的。我自己在甲方待過，也在乙方待過，我的感受就是：在中國的軟件市場裏邊，甲方是非常強勢的，軟件用户的邊界感也比較差，如果買了你的產品，就會希望你給他解決所有的問題，無論是軟件的問題還是周邊的問題，你都要給他解決。現在連我們國內用户做招聘，都要問我們給建議，我還幫我的甲方去面試過（笑~）</p><p>不過話説回來，這種方式還是有它的好處的。首先呢你會跟客户建立一個很強的連接，因為你服務時間長所以他會很信任你，很多東西都給到你，可能你會更容易拿到單子。像中國政企的一些客户，他們的項目都是一年到三年的，這對你的企業來講，可能毛利不是特別高，但是會讓你有持續的現金流輸入，對整個企業的發展都有好處。</p><p>當然，這種方式的弊端也很明顯。像我現在的產品服務了幾十個客户，每個客户都有一個代碼分支，每個客户手裏的都不一樣，這對於我們產品的維護、運維的壓力就蠻大的。你會發現，一個軟件公司到後期會越做越大，這不是説產品或生意越做越大，而是人員越來越多了，尤其是實施側的人員、維護的人員，越來越多。這樣下來，整體的毛利就會比較低，產品本身也比較割裂，最後可能形成了好幾個產品而不是一個產品了。這也算是個有趣的中國特色吧。</p><p>從市場來看，中國純產品型的軟件公司還是比較少的，更多的是項目型的公司。但海外就不一樣，就我們接觸的經驗而言，海外的客户他的邊界感非常強，續費率又高，這就很有利於你費心思去打磨自己的產品。不過這種方式也有弊端，那就是他不願意跟你建立太多的連接。我們之前想做個用户訪談，想問問產品的使用體驗，看看你還有哪些場景是我們的產品可以滿足的，但就遇到了困難。他可能會覺得，這個產品我用着沒事，我也付錢了，你幹嘛老找我？</p><p>哈哈，總之，這個市場的差別就非常明顯。我個人覺得這兩種形態都是比較典型的，也各有利弊，如果要做一個創業項目的話，還要結合具體的產品、不同的團隊風格，甚至是創始人的風格，來做選擇。</p><p>&nbsp;</p><p><strong>頭哥：</strong>剛剛啓鵬説的，我真是感同身受啊。我分享一下我的經驗吧，我工作比較早，2001 年開始接觸 Java，2004 年開始接觸 IOE 架構，上海有個電視購物叫東方購物就是我們做的。七八年前，中國是沒有基礎軟件廠商的，更早一點，十五年前，你説要找數據庫，那隻能想到 Oracle，這是一方面；另一方面，以神州數碼為代表的基於標準廠商上面的第三方服務公司大行其道，我們的甲方之所以這麼強勢，就是被這些人給哄出來的。</p><p>當年我在東方購物的時候，我們一開始買了 Oracle 原廠的服務，Oracle 的工程師來這裏支持，1 天 8 小時就要給 1 萬塊錢，加班另算。你想想 04 年 1 天 1 萬是什麼水平？後面我們把原廠的服務包給神州數碼，服務非常好，價格還只要一半，加班不要錢。就這樣，甲方慢慢地就被捧出來了。如果你不能全包，那我就不選你。反正我只是花錢解決問題，卻還要我分清問題分開花錢，那我為什麼不選一個全包的呢？我自己要是運維這麼強還用找你嗎？</p><p>所以，現在的甲方都很喜歡把項目總包給阿里雲、華為雲，這些雲廠商都有行業解決方案架構師，他們做的都是解決方案，下面的產品都是模糊的，能用就行。內卷就是這麼出來的。不過話説回來，市場沒有好壞，關鍵是你要去適應它，而不是從自己的技術經驗出發來判定這個市場好不好，這個思維要不得。</p><p>&nbsp;</p><p><strong>厲啓鵬：</strong>是的，你在不同的市場做，就是要尊重不同市場的規則。像國內就是用這種方式去驅動產業的發展的。你也很難用好壞來評判一個市場。我上個月去考察了日本的市場，發現日本市場特別難進入，當時同行有個公司，花了一年的時間，才從日本市場拿了一個 80 萬的單子。因為它那裏有 POC 、安全認證等等的審核，門檻比較高。但是呢，一旦你吃下這個市場，你就可以一直吃下去，因為他們很少會主動更換供應商。所以，這也是日本市場的一個特點，我們要是想做的話也一樣要尊重它的規則，國內國外都一樣。</p><p>&nbsp;</p><p><strong>頭哥：</strong>説得很好。剛剛啓鵬也提到了一個點，就是國內的集成商比較厲害，<strong>很多甲方也會把你當外包看待，壓根不管你的產品標不標準，還提一堆有關無關的需求，每個項目按人頭算錢，對於這種現象，你怎麼看呢？</strong></p><p>&nbsp;</p><p><strong>厲啓鵬：</strong>我個人感覺，在國內做項目，要是想做得比較大，那對於這個項目負責人的要求還蠻高的，負責人他可能需要考慮很多方面。我見過一種情況就是，因為一個項目孵化了一個產品，通過這個產品打下了一個行業。之前有個做監控的公司就是這樣，剛開始的時候是從建行做起來，後來把產品完善之後推到了浦發等等別的銀行去了。那我覺得這種類型還是蠻有價值的，因為你解決的這個問題是一些通用的問題，你把它抽象成了產品，實現了規模化。</p><p>當然，更多的是頭哥你説的那種，根本不管你產品如何是不是要做商業化，他只想解決他的問題。當然，這也沒有問題，畢竟人家是甲方，出了錢的嘛。對於這種情況，可能這個項目負責人就要考慮下投入的問題，或者是怎麼投入這個項目。一種是直接讓自己的研發上，all in 到這個項目裏邊，還有一種方式是去找一些合作伙伴一起把這個項目拿下。甚至很多公司可能會先臨時找些外包，因為你如果只要人頭，那我就只給你人頭，然後我只賺人頭的錢。但有的公司呢可能會説對不起這人頭錢我不賺，這個項目我不做了。</p><p>我覺得還是要想清楚吧，因為你要是沒想清楚的話，可能會對公司的影響比較大，它會衝擊你整個研發體系，甚至會影響整個產品的正常迭代。所以去做項目的時候一定要想清楚，你要做什麼樣的項目，你要服務什麼樣的用户，你要以什麼樣的方式去服務他。這個用户畫像一定要清楚，不然就會把你的節奏帶亂。</p><p>&nbsp;</p><p><strong>頭哥：還有一個問題，作為我們這種普通的技術人，如何把我們手上的技術變現呢？</strong></p><p>&nbsp;</p><p><strong>厲啓鵬：</strong>加入一家大公司，我覺得可能是一個比較好的方式。因為我自己的體會就是這樣的，當時我在阿里做社區，看到不少小夥伴當時還在一家小公司，但是他在我們這個社區裏邊比較活躍，貢獻了很多代碼，這給他的經驗、經歷做了很大的加持，後來他們就都跳槽到大公司去了。從 ROI 的角度，或者從收益的角度來看，這是一個收益很高的事情，通過在知名項目做貢獻，提升自己的技術和影響力，從而提升自己的職業生涯，我覺得這是最直接的一種方式。</p><p>第二種方式我也見過好多，就是技術經驗豐富之後，去做諮詢，或者是指導別人寫代碼，出書，出課程，做培訓等等，也都做得挺不錯的。</p><p>最後一種就是創業了，不過如果純技術人想要創業的話，我建議你可以先加入一家創業公司，如果你能適應的話。假如公司靠譜，那之後它發達了你也就財富自由了。加入一家創業公司工作跟在大公司做一個具體細分的工作差異肯定非常大，在創業公司，假如説要做一輛勞斯萊斯，説不定得先從一輛自行車做起，然後做一輛電動車，再做一輛奧拓，再到寶馬，最後才到勞斯萊斯，他是這麼一個過程。絕對不是説我給你幾年時間，讓你做一輛勞斯萊斯，那樣公司在市場上很難活下去的。但是在這種逐漸發展的過程中，對於一個技術人的技術視野，甚至商業的視野都會打開很多。我也見過很多這種人，之前是純做技術的，加入這家創業公司之後，可能剛開始是做技術，後來他可能要做產品經理，再後來他可能是負責整個的售前，這對他個人能力就會有非常大的提升。</p><p>當然，選擇也跟年齡段有關係。比如説工作五年以前的，我覺得還是可以去大廠看一看，體驗一下。但是如果工作 5 年到 10 年甚至更久的時間了，我覺得加入一家創業公司還是一個不錯的選擇。但是，如果你説你要作為一個合夥人甚至是創始人去創辦一家商業公司，那説實話我個人不是特別推薦。因為如果你是作為合夥人的身份的話，你會發現到後面你首先關注的不是技術了，而是用户，是融資，是市場，你要花很大的精力去做這些事情，可能有些人不一定喜歡。可能你後面做着做着發現自己成了一個銷售，當然不是説銷售不好，但他可能之前不喜歡，但是後邊需要他做這個工作。所以第二個要考慮的就是，這是不是你能力範圍內的事情，有些人他快速成長，快速改變，他的適應力非常強，那就沒有問題。</p><p>&nbsp;</p><p><strong>頭哥：最後一個問題，作為一個優秀的開源項目，如果想嘗試商業化，有哪些方式呢？</strong></p><p>&nbsp;</p><p><strong>厲啓鵬：</strong>如果是大廠想通過開源實現商業化的話，現在最典型的路徑就是捐到基金會去，然後再通過運營社區的方式去獲客。這種方式尤其適合基礎軟件，如果是一個特別垂類的軟件倒不一定合適了。個人更贊同的一種方式是通過開源樹立一個標杆，獲得某些標杆企業的開發者的認可，這時候你再去複製可能就會非常快。比方説我這個軟件，如果大廠採用了，那下面的二三線廠商可能也會跟進。影響力打出去了之後，再尋求付費可能就會容易一點了。</p><p>但是在當下，2023 年，這個節點，你建立一個項目去創業，那是比較難的。第一，開源商業化的路徑比較長，你得先有項目，然後通過運營社區把這個影響力做起來，再出商業版去變現，那可能意味着這家創業公司要一年兩年甚至三年沒有收入，或者養活不了自己。在目前的這種就業環境包括投融資環境下，你能不能活兩三年，這是一個非常大的問題，很多人撐不住的。</p><p>還有就是，以我自己的感受來講，很多用户他只用開源版本，他從來就沒有想過要用你的商業版，或者你出了商業版之後他就直接走了，這種就很難轉化。有些開源公司做商業化成功了，並不是因為轉化了開源用户為商業化用户，而是因為這個項目影響力起來之後，影響了那些不使用開源項目的用户，從而實現了商業化。這屬於間接影響，你不好量化，從頂上來看的話，你都不好去制定一個考核機制，讓大家知道哪些事有價值和引導他們做事。所以我覺得，如果是 Saas 的話，會比開源更能解決你打磨產品的問題，因為上面有數據，他們用了多少你看得到。</p><p>最後，我覺得開源最大的價值就是標準化，比如 Conflict ，它是構建大數據平台的一個標準，不管用它的開源還是買它的商業版，只要構建大數據平台都會想到它。其次就是開源有助於國際化，給了中國的企業出海或者是服務海外客户的一個機會，這是本土閉源的軟件公司很難做到的。我一度認為開源加上雲，是一個蠻好的方式，能夠助力中國的軟件企業成為一個服務全球的企業。以前沒有云，想服務海外客户還得建本地團隊，現在託 AWS 就可以了，大大節省了成本。</p><p>當然，開源好處多多，明天也很美好，現在的挑戰就是看你能不能活到明天了。（笑~）</p><p>&nbsp;</p><p>本期直播回放如下，大家快掃碼查看吧~</p><p><img height="355" src="https://oscimg.oschina.net/oscnet/up-41198acd2e49349768fe28449ea945e7227.png" width="385" referrerpolicy="no-referrer"></p></div></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 09:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10139809</guid>
            <link>https://my.oschina.net/u/6852546/blog/10139809</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌承諾 20 億美元投資 OpenAI 對手 Anthropic]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">谷歌發言人日前表示，該公司已同意向 OpenAI 的強力競爭對手 Anthropic 投資最多 20 億美元。目前已預先投資了 5 億美元，隨着時間的推移將再追加 15 億美元。</span></p><p><span style="color:#000000">Anthropic 成立於 2021 年，是一家由前 OpenAI 團隊成員創立的人工智能初創公司。其在 ChatGPT 發佈兩個月後，就推出了 GPT-4 的重要競品 Claude，並在 7 月初推出了升級版的 Claude 2。在今年上半年，Anthropic 的估值已達到了約 41 億美元。</span></p><p><img height="277" src="https://oscimg.oschina.net/oscnet/up-cdc73121940d2bf6a2632504928ecf5790a.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Anthropic 的一份<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F04%2F06%2Fanthropics-5b-4-year-plan-to-take-on-openai%2F" target="_blank">內部文件透露</a>，該公司計劃籌集 50 億美元或更多以直接與 OpenAI 較量。並預計花費 10 億美元，在 2024 年底推出自己的新一代大語言模型「Claude-Next」。</span></p><p><span style="color:#000000">Anthropic 首席執行官兼聯合創始人 Dario Amodei 曾在上個月的一次談話中稱，「我們只成立了兩年半多一點……在這段時間裏，我們已經籌集了 15 億美元，這是一個很大的數字。我們的團隊規模相較來説要小得多，但我們已經成功地保持了自己的地位。我們真正做到了少花錢多辦事，我認為很快我們就能用更多的資源做更多的事。」</span></p><p><span style="color:#000000">而除谷歌外，Anthropic 還獲得了 Salesforce 和 Zoom 的融資。亞馬遜也已經向 Anthropic 投資了 12.5 億美元；並在 9 月份承諾，後續計劃共向 Anthropic 投資高達 40 億美元。</span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><a href="https://www.oschina.net/news/232921/claude-ai" target="_blank">Anthropic 推出 「更理性的 Claude」，正面硬剛 ChatGPT</a></li><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/263552/frontier-model-forum-ai-safety" target="_blank">OpenAI、谷歌微軟等設立 1000 萬美元 AI 安全基金</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 08:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264126/google-invest-2-billion-anthropic</guid>
            <link>https://www.oschina.net/news/264126/google-invest-2-billion-anthropic</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百川智能發佈 Baichuan2-192K 大模型，上下文窗口全球最長]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>10 月 30 日，百川智能發佈<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlAJh6qGG27u_qCl0kI-0lA" target="_blank">Baichuan2-192K 大模型</a></u>，其上下文窗口長度高達 192K，是目前全球最長的上下文窗口。</p><blockquote><p>上下文窗口長度是大模型的核心技術之一，通過更大的上下文窗口，模型能夠結合更多上下文內容獲得更豐富的語義信息，更好的捕捉上下文的相關性、消除歧義，進而更加準確、流暢的生成內容，提升模型能力。</p></blockquote><p>據介紹，<strong>Baichuan2-192K 能夠處理約 35 萬個漢字</strong>，是目前支持長上下文窗口最優秀大模型 Claude2（支持 100K 上下文窗口，實測約 8 萬字）的 4.4 倍，更是 GPT-4（支持 32K 上下文窗口，實測約 2.5 萬字）的 14 倍。Baichuan2-192K 不僅在上下文窗口長度上超越 Claude2，在長窗口文本生成質量、長上下文理解以及長文本問答、摘要等方面的表現也全面領先 Claude2。</p><p><img height="708" src="https://static.oschina.net/uploads/space/2023/1030/143754_9Lc3_2720166.png" width="1280" referrerpolicy="no-referrer"></p><p>Baichuan2-192K 在 Dureader、NarrativeQA、LSHT、TriviaQA 等 10 項中英文長文本問答、摘要的評測集上表現優異，有 7 項取得 SOTA，顯著超過其他長窗口模型。</p><p><img src="https://static.oschina.net/uploads/space/2023/1030/143926_8N50_2720166.png" referrerpolicy="no-referrer"></p><p>此外，LongEval 的評測結果顯示，在窗口長度超過 100K 後 Baichuan2-192K 依然能夠保持非常強勁的性能，而其他開源或者商用模型在窗口長度增長後效果都出現了近乎直線下降的情況。Claude2 也不例外，在窗口長度超過 80K 後整體效果下降非常嚴重。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e09d70b43d3d3782cda3982ae4d742587e1.png" referrerpolicy="no-referrer"></p><p>今年 9 月 25 日，百川智能已開放了 Baichuan2 的 API 接口，正式進軍企業級市場，開啓商業化進程。<strong>此次 Baichuan2-192K 將以 API 調用和私有化部署的方式提供給企業用户</strong>，目前百川智能已經啓動 Baichuan2-192K 的 API 內測，開放給法律、媒體、金融等行業的核心合作伙伴。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 06:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264086</guid>
            <link>https://www.oschina.net/news/264086</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[IntelliJ IDEA 2023.3 EAP 6 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">IntelliJ IDEA 2023.3 EAP 6 現已發佈。這是 IntelliJ IDEA 2023.3 Beta 發佈之前的最終 EAP 版本，帶來了更多新功能和增強功能的預覽。</span></p><p><span style="color:#000000">一些亮點更新內容如下：</span></p><h4><span style="color:#000000"><strong>遠程開發（</strong>Beta<strong>）</strong></span></h4><p><span style="color:#000000"><strong>改進了對 </strong></span><strong><span>Dev Containers&nbsp;</span></strong><span style="color:#000000"><strong>的支持</strong></span></p><p><span style="color:#000000">IntelliJ IDEA 2023.3 EAP 6 引入了對&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcontainers.dev%2Fimplementors%2Ffeatures%2F" target="_blank">Dev Container Features</a>&nbsp;<span style="color:#000000">的支持，提供了一種方便快捷的方式來集成開發所需的其他工具、運行時和庫。雖然你仍然可以依靠 Dockerfile 和腳本來實現此目的，但功能的引入簡化了基本組件的安裝，確保更快的設置過程。</span></p><p><img height="201" src="https://oscimg.oschina.net/oscnet/up-a0e771254565fb54b102aec6ea08d0134b5.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#19191c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>還在 Dev Containers 中引入了對 Docker Compose 的支持，從而可以使用 IDE 無縫啓動主容器以及任何依賴容器，例如那些在開發過程中非常有用的數據庫或消息隊列容器。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><code>dockerComposeFile</code>屬性指向<code>docker-compose.yml</code>文件的位置。</li><li><code>service</code>屬性指定主容器的位置。</li><li><code>runServices</code>是一組依賴容器，應與開發環境一起啓動或停止。</li></ul><p><img height="199" src="https://oscimg.oschina.net/oscnet/up-e1c2ac5ebcff62d528e76feb866f3f96732.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#19191c">此外，還實現了自動端口轉發，以便應用程序在 Dev Container 中開始偵聽的任何端口都可以無縫轉發。</span>&nbsp;</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3cb3ff996796f85f50d2b39712f1baae583.gif" width="500" referrerpolicy="no-referrer"></p><div><h4><strong><span>Clouds</span></strong></h4></div><div><p style="margin-left:0px; margin-right:0px"><strong><span>Bicep 支持</span></strong></p><p style="margin-left:0px; margin-right:0px">引入了對<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fazure%2Fazure-resource-manager%2Fbicep%2F" target="_blank">Bicep</a>的初步支持，這是一種專為 Azure 量身定製的基礎設施即代碼語言。它轉換為 Azure Resource Manager (ARM) 模板，旨在與 Azure 服務緊密集成。IDE 現在通過 Bicep 語言服務器協議提供代碼高亮顯示和代碼自動補全功能。</p><p style="margin-left:0px; margin-right:0px"><img height="252" src="https://oscimg.oschina.net/oscnet/up-17ae979ece3e8edab2008933b09a0c423f6.png" width="500" referrerpolicy="no-referrer"></p><div><h4><strong><span><span><span><span><span><span><span><span style="color:#19191c"><span><span><span><span><span>Kubernetes</span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4></div><div><p style="margin-left:0px; margin-right:0px"><span><span><span><span><span><span><span><span style="color:#19191c"><span><span><span><span><span><strong>在 Kubernetes 中使用數據庫</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#19191c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>IntelliJ IDEA 2023.3 EAP 6 在處理 Kubernetes 中託管的數據庫時提供了增強的用户體驗。現在，數據庫工具允許你在建立數據庫連接時在 Kubernetes 中配置端口轉發。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div></div><p><img height="251" src="https://oscimg.oschina.net/oscnet/up-5e1ba9fa01eae8e9110b323f19a180ecfe9.png" width="500" referrerpolicy="no-referrer">&nbsp;</p><div><p style="margin-left:0px; margin-right:0px"><strong><span><span><span><span style="color:#19191c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span><span><span><span><span><span style="color:#19191c"><span><span><span><span><span>支持 YAML 文件註釋中的<code>$schema</code></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p></div><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#19191c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>IDE 現在可以識別對作為註釋包含的特定 YAML 架構的引用，並根據指定架構在 YAML 文件內提供代碼補全和語法驗證，無論其是本地存儲還是遠程訪問。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#19191c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><img alt="" src="https://oscimg.oschina.net/oscnet/up-3a6382c981094f7c13aba8dc94f37056d50.gif" width="500" referrerpolicy="no-referrer"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h4><strong><span><span><span><span><span style="color:#19191c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Build tools</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><p style="margin-left:0px; margin-right:0px; text-align:start"><strong><span><span><span><span><span style="color:#19191c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>基於限定模塊名稱的 Maven 項目模塊分組</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:0px; margin-right:0px; text-align:start">新版本改進了 IDE 處理項目模塊分組的方式。現在，它會根據模塊的限定名稱自動對模塊進行分組。如有需要，你可以手動重命名模塊，這些名稱將在後續 Maven 項目重新加載期間保留。</p><p style="margin-left:0px; margin-right:0px; text-align:start">詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2023%2F10%2Fintellij-idea-2023-3-eap-6%2F" target="_blank">查看官方博客</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 06:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264082/intellij-idea-2023-3-eap-6</guid>
            <link>https://www.oschina.net/news/264082/intellij-idea-2023-3-eap-6</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為申請註冊「遙遙領先」商標]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>近日，華為技術有限公司申請註冊「遙遙領先」商標，國際分類為運輸工具、科學儀器，當前商標狀態為等待實質審查。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2632d0767a23ab6a185920e5193ba46340f.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-84f3e8ecf2f2e09c7cf0b5e8bafc4e67698.png" referrerpolicy="no-referrer"></p><p>最近因華為 Mate60 系列手機發售，「遙遙領先」成為網絡熱詞。</p><p>「遙遙領先」一詞最先是出現在華為手機 Mate40 的發佈會上，餘承東在介紹手機的處理器、屏幕、電池、充電、攝像頭、音質等狀況時，曾經説了 14 次「遙遙領先」。去年的 Mate50 發佈，全球首發了衞星通信功能，餘承東再次提及「遙遙領先」，並稱其為捅破天的技術，又將「遙遙領先」的熱度推高。</p><p>隨後，華為的粉絲也經常在華為發佈會上喊「遙遙領先」為華為加油。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c2112b8f18f699b1b8299410458e1811c69.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 06:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264078</guid>
            <link>https://www.oschina.net/news/264078</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Spring Framework 6.1 RC2]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>Spring Framework 6.1 發佈了<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fblog%2F2023%2F10%2F26%2Fspring-framework-6-1-rc2-released" target="_blank">第 2 個 RC</a></u>，開發團隊稱這是 11 月正式發佈前的最後一個版本。</p><p><img src="https://static.oschina.net/uploads/space/2023/1030/120256_ZKGg_2720166.png" referrerpolicy="no-referrer"></p><p>此版本包含 51 項錯誤修復和改進，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Freleases%2Ftag%2Fv6.1.0-RC2" target="_blank">點此查看詳情</a>。</p><p>Spring Framework 文檔<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fwiki%2FWhat%2527s-New-in-Spring-Framework-6.x">顯示</a>，Spring 6.1 已全面兼容虛擬線程 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F23443">Virtual Threads</a>) 和 JDK 21。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0817/140919_ppSy_2720166.png" referrerpolicy="no-referrer"></p><p>虛擬線程配置選項：專用的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-framework%2Fdocs%2F6.1.0-SNAPSHOT%2Fjavadoc-api%2Forg%2Fspringframework%2Fcore%2Ftask%2FVirtualThreadTaskExecutor.html">VirtualThreadTaskExecutor</a>&nbsp;和&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-framework%2Fdocs%2F6.1.0-SNAPSHOT%2Fjavadoc-api%2Forg%2Fspringframework%2Fcore%2Ftask%2FSimpleAsyncTaskExecutor.html%23setVirtualThreads%28boolean%29">SimpleAsyncTaskExecutor 上的虛擬線程模式</a>，以及類似的具有 new-thread-per-task strategy 和虛擬線程模式的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-framework%2Fdocs%2F6.1.0-SNAPSHOT%2Fjavadoc-api%2Forg%2Fspringframework%2Fscheduling%2Fconcurrent%2FSimpleAsyncTaskScheduler.html">SimpleAsyncTaskScheduler</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 04:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264062/spring-framework-6-1-rc2-released</guid>
            <link>https://www.oschina.net/news/264062/spring-framework-6-1-rc2-released</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 11 已原生支持 11 種文件存檔格式，包括 7-Zip 和 RAR]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">在今年 5 月份，微軟方面曾<a href="https://www.oschina.net/news/242230/windows-11-supports-rar">宣佈</a>將在&nbsp;<span style="background-color:#ffffff">Windows 11 系統中原生增加對 RAR、7-Zip 等壓縮文件格式的解壓支持。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">時至今日，該公司已通過本月的可選&nbsp;KB5031455&nbsp;預覽累積更新添加了對 11 種新文件存檔格式的支持，Windows 11 22H2 現在原生支持近十幾種附加存檔格式。</span></span><span style="color:#000000"><span style="background-color:#ffffff">Windows 11 中支持的存檔類型的更新列表現在添加了：.rar、.7z、.tar、.tar.gz、.tar.bz2、.tar.zst、.tar.xz、.tgz、.tbz2、.tzst、和 .txz。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">不過目前還不支持密碼加密文件，微軟<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fmicrosoft%2Fwindows-11-adds-support-for-11-file-archives-including-7-zip-and-rar%2F" target="_blank">發言人</a>也沒有透露更多的相關信息；其後續可能還將添加對&nbsp;LZH、LZH 和 XAR 等其他格式的支持。</span></span></p><p><span style="color:#000000">「我們使用 </span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flibarchive%2Flibarchive" target="_blank">libarchive</a><span style="color:#000000"> 開源項目添加了對其他存檔格式的原生支持，包括 tar、7-Zip、RAR、gz 和許多其他格式。現在，你可以在 Windows 上的壓縮過程中獲得更高的存檔功能性能。」</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">libarchive 是一個開源的 C 庫，旨在為各種不同的壓縮格式提供讀取和寫入支持。它支持許多常見的壓縮格式，並提供了許多高級功能，例如加密、數字簽名、多卷支持等。libarchive 的主要優點是它的跨平台支持，它可以在各種操作系統上運行，包括 Linux、Windows、macOS 等。它還提供了多種語言的綁定，如 Python、Ruby、Perl 等，使得開發人員可以方便地在自己喜歡的編程語言中使用它。</span></p><p><span style="color:#000000">由於 KB5031455 是一個可選更新，Windows 用户必須手動安裝。這項新功能還將通過計劃在 11 月份的"</span>Patch Tuesday<span style="color:#000000">"發佈的累積更新向所有 Windows 11 用户推出。</span></p><p><img height="271" src="https://oscimg.oschina.net/oscnet/up-2a02652354dae96fd940ccc4d707d65e355.png" width="500" referrerpolicy="no-referrer"></p><p><strong>延伸閲讀：</strong></p><ul><li><a href="https://www.oschina.net/news/242230/windows-11-supports-rar" target="_blank">Windows 將原生支持解壓 RAR 和 7Z</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 03:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264054/windows-11-support-11-file-archives-7-zip-rar</guid>
            <link>https://www.oschina.net/news/264054/windows-11-support-11-file-archives-7-zip-rar</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
