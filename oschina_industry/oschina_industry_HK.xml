<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 08 Jan 2024 17:54:31 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[年度盤點｜深圳工信十件大事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>「i 深圳」官微<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_8-u5N6_fIBUYJZGu1fGYg" target="_blank">發文</a>盤點了 2023 年深圳工信十大事件，具體如下：</p><p><span style="color:#007aaa"><strong>一、企業創新主體地位不斷強化，「深圳製造」爆款迭出</strong></span></p><p><span style="color:#595959">企業研發投入達 1784.6 億元，約佔全社會研發投入比重 94.9%，位居全國第一。華為推出全球首款支持衞星通話和應用星閃技術的 Mate 60 系列手機產品，引發線上線下搶購熱潮；榮耀推出全球最輕薄大內折高端機 Magic V2，引領摺疊屏厚度進入「毫米時代」；仰望 U8、問界 M9 等高端車型先後發佈，搭載業內領先的自研車身控制系統和智能科技配置，代表了全球高端新能源汽車前沿水平。</span></p><p><img height="383" src="https://oscimg.oschina.net/oscnet/up-c427126861041278cce2734057b420f8024.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#007aaa"><strong>二、「新一代世界一流汽車城」建設全面提速，比亞迪勇奪全球新能源汽車銷冠</strong></span></p><p><span style="color:#595959">高標準規劃建設「新一代世界一流汽車城」，全市全年新能源汽車產量繼續實現翻倍增長。汽車出口屢創新高，全市新車電動化滲透率、充電基礎設施密度全國領先，新能源汽車保有量超 96 萬輛，入圍國家首批公共領域全面電動化一類試點城市。全力支持深汕特別合作區建設世界級汽車製造城，深汕比亞迪汽車工業園二期建成投產，東風李爾、壁虎科技、佛吉亞等一批新能源汽車產業鏈上下游明星企業集聚深汕。比亞迪累計下線超 600 萬輛新能源汽車，2023 年全年銷售汽車 302.44 萬輛，同比增長 61.9%，一舉奪得全國汽車年度銷冠、全球新能源汽車銷冠，創下中國汽車年銷量最高紀錄，新能源汽車行業邁向規模化、全球化高質量發展之路。</span></p><p><img height="395" src="https://oscimg.oschina.net/oscnet/up-37f0d216108702b10da9071d67a72e94422.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>三、優質通用大模型接連推出，人工智能全域全時場景應用加快拓展</strong></span></p><p><span style="color:#595959">印發實施《深圳市加快推動人工智能高質量發展高水平應用行動方案（2023-2024 年）》，構建「一條例、一方案、一清單、一基金羣」的政策體系。華為雲盤古 3.0。騰訊混元、雲天勵飛天書等一批高水平通用大模型陸續推出。昇騰系列芯片成為國內具備全棧技術的最高水平的人工智能算力芯片。累計發佈人工智能清掃等 41 個「城市+AI」場景，舉辦人工智能專場產學研對接系列活動，人工智能全域全時場景應用加快拓展。</span></p><p><img height="323" src="https://oscimg.oschina.net/oscnet/up-09bda6383445c51b8c4c7c3c38d87601298.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>四、開源鴻蒙歐拉產業高地建設再上台階，「軟件名城」獲評「三星級」</strong></span></p><p><span style="color:#595959">印發實施《深圳市推動開源鴻蒙歐拉產業創新發展行動計劃（2023—2025 年）》，全體系增強操作系統技術能力，開源鴻蒙裝機量已超過 7 億台，開源歐拉裝機量佔據國內服務器市場份額近 4 成。落地全球智慧物聯網聯盟等國際組織，建設鴻蒙生態創新中心，加快推動我國操作系統技術創新和高水平自立自強。在全國「軟件名城」考核中名列前茅，獲評最高等次「三星級」。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="275" src="https://oscimg.oschina.net/oscnet/up-45f99849e79a7af19baff203be73c45bcee.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>五、75 個「工業上樓」項目開工建設，高標準謀劃共建產業園區</strong></span></p><p><span style="color:#595959">持續加大產業用地用房供應，積極穩妥推進「工業上樓」，為製造業高質量發展提供強有力空間保障。2023 年開工建設 75 個「工業上樓」項目，預計可提供總建築面積超 2000 萬㎡。龍崗寶龍專精特新產業園正式開園，全國首個全裝配式智能產業園坪山區新能源汽車產業園交付使用，推廣實現「上下游就是上下樓，產業園就是產業鏈」。與汕頭、潮州等地加大產業合作力度，高標準謀劃共建產業園區，努力實現優勢互補、合作共贏。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="351" src="https://oscimg.oschina.net/oscnet/up-0e185217af6add18c0a3dc295242507811b.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#007aaa"><strong>六、中小企業發展環境綜合排名全國第一，專精特新「小巨人」增量全國第一</strong></span></p><p><span style="color:#595959">《2022 年度中小企業發展環境評估報告》發佈，深圳中小企業發展環境綜合排名全國第一。「深 i 企」平台用户數突破 300 萬。創新開展「我幫企業找市場」等系列行動，線上打造供需對接平台，線下開展上百場各類主題的「鏈上配對」精準對接服務，幫助企業拿訂單、拓市場，打通上下游合作「最後一公里」。2023 年新增專精特新「小巨人」企業 309 家，新增數量居全國大中城市第一，總數達 742 家、位列全國第二。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="350" src="https://oscimg.oschina.net/oscnet/up-bb68fd01669b2204acf6e1a401f88b4d831.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>七、千兆城市建設水平領跑全國，率先邁入 5G-A 時代</strong></span></p><p><span style="color:#595959">啓動「極速寬帶先鋒城市」建設行動，全年新增 5G 基站超 1 萬個、累計建成超 7.5 萬個，重點場所 5G 網絡通達率 100%，多項千兆城市指標位居全國大中城市首位。啓動數字家庭 3T 躍升行動試點，深圳市公共場所 WIFI 管理平台累計服務近 3 億人次，為市民節省約 1.7 億元流量費，市民生活數字化服務水平得到大幅提升。出台《深圳市算力基礎設施高質量發展行動計劃（2024-2025）》，力爭將算力打造成像水、電「一點接入、即取即用」的基礎設施，夯實數字經濟發展「底座」。全面加速 5G-A 行業應用創新與產業融合發展，成為全球首個邁入 5G-A 時代的城市。</span></p><p><span style="color:#007aaa"><strong>八、一批重大先進製造業項目落地，工業投資實現高速增長</strong></span></p><p><span style="color:#595959">市區協同、部門聯動，赴法國、德國、馬來西亞、沙特等 25 個國家和北京、上海等 30 多個城市精準招商，招引西門子、橢圓星池、京西重工、壁虎科技等一批國內外知名企業重點項目成功落地。推動與中國一汽、中國化學、中汽中心等一批央企簽署合作協議，打造央地產業合作新典範。全年先進製造業領域成功招引落地百億以上項目 8 個，10 億以上項目超 80 個，投資金額合計超 4000 億元。2023 年工業投資規模再創歷史新高，實現增長超 30%。出台《深圳市關於新形勢下加快工業企業技術改造升級的若干措施》，將重大項目支持金額上限提高至 1 億元，推動 1200 餘家企業開展技術改造。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="318" src="https://oscimg.oschina.net/oscnet/up-d1e0659e29ba6df8968fad30a54240bfb54.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>九、國際星閃無線短距通信聯盟落户河套，高水平產業創新平台加快打造</strong></span></p><p><span style="color:#595959">國際星閃無線短距通信聯盟正式落户河套深港科技創新合作區，成為第二個註冊地設立在深圳的國際性產業與標準組織。聯盟已發佈星閃芯片、測試儀表等產品，加快在智能汽車、智能家居、智能終端等領域推進產業化和國際化進程。新增 1 家國家級「雙跨」平台、總數佔全國十分之一，電子元器件和集成電路國際交易中心交易規模突破 500 億元。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="357" src="https://oscimg.oschina.net/oscnet/up-56ac4a5cdf50607b2958f21ad8d17cac815.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#007aaa">十、中國—東盟新興產業論壇成功舉辦，國際產業交流合作成效斐然</span></strong></p><p><span style="color:#595959">成功舉辦中國-東盟新興產業論壇，來自東盟各國的 9 位部長、29 位東盟國家駐華使領館代表以及相關國際組織、商協會、智庫、企業共計 180 餘位外方嘉賓參加盛會，共話新興產業發展。發佈《新興產業合作倡議（深圳倡議）》，舉辦中國-東盟產業對接會（深圳），達成 20 項戰略合作框架協議，意向合作金額超 50 億元。延伸舉辦中國（深圳、香港）-東盟（吉隆坡）新興產業對接會，深港攜手「並船出海」，達成 22 項合作協議，簽約金額超 100 億元。</span></p><p><img height="640" src="https://oscimg.oschina.net/oscnet/up-3b53abdd29e47790a9ca14a4c7ddea89cdd.png" width="936" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 09:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274769</guid>
            <link>https://www.oschina.net/news/274769</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[祝賀！openKylin 社區再次入選「科創中國」開源創新榜]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">近日，由中國科協科學技術傳播中心、中國計算機學會、中國通信學會和中國科學院軟件研究所聯合主辦，CSDN 承辦的</span><strong><span style="color:#333333">2023 年開源創新榜專家評審會</span></strong><span style="color:#333333">圓滿落幕。</span><span style="color:#0060e8"><strong><span>openKylin 社區榮獲「2023 開源創新榜」優秀開源社區獎，這也是 openKylin 社區<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg2MDc5MDU1OQ%3D%3D%26mid%3D2247488006%26idx%3D1%26sn%3D9829fb8b7f075f1239b239d4be35d36b%26chksm%3Dce205876f957d160ca609fd7c95b3f6698bd2fddacb2697724ae7a20292e6780bd3b7ba44906%26scene%3D21%23wechat_redirect" target="_blank">連續兩年</a>入選該榜單。</span></strong></span></p><p style="text-align:center"><img alt="" height="1654" src="https://oscimg.oschina.net/oscnet/up-5a2d6ec6c333def9c35daa719508157beef.png" width="2339" referrerpolicy="no-referrer"></p><p><span style="color:#333333">2023 開源創新榜面向中國開源行業領域，評選具有創新性、貢獻度和影響力的開源項目、社區、人物。突出「與時俱進、鼓勵創新」的原則，旨在挖掘和推廣我國在開源技術領域的優秀成果和先進經驗。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">相較於往年，2023 年開源創新榜在</span><strong><span style="color:#333333">權威性、公信力和專業度</span></strong><span style="color:#333333">方面均有顯著提升。</span></p><ul><li><p style="margin-left:0; margin-right:0">權威性。主辦單位新加入中國計算機學會、中國通信學會、中國科學院軟件研究所，四家主辦單位優勢互補，共同推動榜單策劃、徵集申報、專家評審等工作重點。</p></li><li><p style="margin-left:0; margin-right:0">公信力。由王懷民院士擔任評委會主任，指導組建了結構更加科學、領域更加全面的評審專家庫，從中提名形成最終評審專家。</p></li><li><p style="margin-left:0; margin-right:0">專業度。圍繞項目、社區、人物三大類別，四家主辦單位打磨了更加客觀、嚴謹、貼合實際的評審標準和更加開放、公平、科學的評審辦法，在徵集過程中公開標準細節，接受社會的意見反饋，形成良性循環。</p></li></ul><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">作為中國領先的開源操作系統根社區，openKylin 社區自成立以來便積極推動開源生態建設。截至目前，openKylin 社區已累計發佈 6 個社區版本，下載量達 100 萬+；聚合 400+家單位會員，涵蓋操作系統、數據庫、辦公軟件、CPU、GPU、整機、人工智能優勢企業及高等院校；擁有 5700+位開發者，並累計成立 95 個 SIG 組開展技術研究與創新。廣泛的產、學、研、用各領域力量加入社區共建之中，為操作系統根技術創新奠定智囊基礎。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">此次入選科創中國「開源創新榜」是對 openKylin 社區開源創新能力和行業影響力的高度肯定。未來，openKylin 也將保持初心，聚焦開源創新生態建設、為營造良好開源生態持續努力。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 09:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274766</guid>
            <link>https://www.oschina.net/news/274766</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeFuse 開源這半年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="hjfgjkf.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704681398439-ec399b89-4898-4a2c-94e5-3981b90ed95d.png?x-oss-process=image%2Fresize%2Cw_900%2Climit_0" width="900" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>2023 年可以稱得上是大模型元年，在過去的這一年裏，大模型領域飛速發展，新的大模型紛紛湧現，基於大模型的新產品也吸引着大家的眼球，未來，這個領域又會給大家帶來多少驚喜？</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>螞蟻也推出了自己的百靈代碼大模型 CodeFuse，經歷近半年內部打磨後，在 9 月正式對外開源。下面就讓我們來看一下，在過去的半年裏，CodeFuse 在開源方面取得了哪些進展？</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_1"></span><h2><span>一、讓研發變得更簡單</span></h2><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>在大模型落地到多個場景的過程中，代碼自動生成，成為技術實現的必要環節。在這一趨勢下，螞蟻集團基於百靈大模型，推出了螞蟻百靈研發助手，幫助開發者自動生成代碼、註釋、測試用例等，提高研發效率。</span></p><p style="margin-left:0; margin-right:0"><br><span>CodeFuse 源於螞蟻自身的開發場景及代碼庫沉澱，基於海量高質量代碼數據和代碼領域特色詞表，和多任務微調技術 MFT，在螞蟻一萬多內部研發人員的日常編碼、測試、運維等場景中，經過反覆驗證與迭代。當前，CodeFuse 從研發效能、DevOps 衍生到了企業 IT 智能化場景智能體的探索。同時，基於 CodeFuse，螞蟻集團打造了代碼大模型的完整工具鏈，包括：模型服務、風險防護、數據質量、平台工程。</span></p><p style="margin-left:0; margin-right:0"><br><span>2023 年中，CodeFuse 及其必要的工具鏈，面向技術社區開源開放，幫助社區開發人員在此之上作研究、評價和二次開發和訓練。</span></p><p style="margin-left:0; margin-right:0"><br><span>目前，CodeFuse 在螞蟻各部門落地支持 40 多種編程語言，10 多個主流 IDE 平台。整體採納率 30%，代碼通過 AI 佔比 20%。比如，CodeFuse 在螞蟻數字科技的 SOFAStack 雲原生應用智能商業產品線全面融合，涵蓋設計、研發、測試、運維等領域，形成從領域建模到智能運維端到端 Copilot 產品解決方案，提升了企業級應用的交付效率和質量，加速行業數字化降本增效。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_2"></span><h2><span>二、豐富的開源內容</span></h2><p style="margin-left:0; margin-right:0"><span>CodeFuse 的使命是開發專門設計用於支持整個軟件開發生命週期的大型代碼語言模型（Code LLMs），當前內容涵蓋代碼、運維、分析、測試、推理、評價六大方向。截止 2023.12.31，CodeFuse 已累計開源了 11 個代碼倉庫、4 個數據集、11 個大模型參數文件，總計關注/點贊數超過 3000、下載量超過 2.4 萬，並有 1 篇論文已被接收，2 篇預影印在 Arxiv 上。</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/276193/1704259197296-b8ea3135-7387-4a92-a84f-d02643811793.png" width="739" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_3"></span><h4><strong>1、代碼 - MFTCoder 系列：</strong></h4><p>國際首個高精度、高效率、多任務、多模型支持、多訓練算法，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder" target="_blank" rel="nofollow"><span>大模型代碼能力微調框架</span></a><span>；多任務微調的技術細節已在 Arxiv 公佈，可參考</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2311.02303" target="_blank" rel="nofollow"><span>MFTCoder 論文</span></a><span>，以及</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484188%26idx%3D1%26sn%3D27c9fe0e849f9f27eac588fda76574be%26chksm%3Dc139d02df64e593b2fcb9101cea55c4b78af5a6b4dd0f6518d7993bc864a36150ae438abc902%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前發佈的文章</span></a></p><div><p style="margin-left:0; margin-right:0"><span>預訓練語言模型可以在大量的文本數據上學習通用的語言模式和結構。通過運用無監督學習技術，模型可以基於前面的詞序列來預測句子中的下一個詞。然而，僅僅進行預訓練並不能在特定的自然語言處理任務上取得高性能。因此，需要在特定任務的小型數據集上對預訓練模型進行微調，以學習任務特定的特徵並提高性能。微調過程使用監督學習技術將預訓練模型適應到特定的任務上。將訓練過程分為預訓練和微調兩個階段，可以使自然語言處理模型充分發揮無監督學習和有監督學習的優勢。</span></p><p style="margin-left:0; margin-right:0"><span>但是，需要注意的是，當模型的參數量巨大時，為每一個下游任務獨立進行微調並部署將需要大量的資源。然而，是否存在一種方法可以讓一個模型同時支持所有的下游任務呢？答案是肯定的，多任務微調（multitask fine-tuning，MFT）為解決這個問題提供了一種有效的途徑。</span></p><p style="margin-left:0; margin-right:0"><span>多任務微調不僅能夠節省資源，還能夠帶來其他優勢。通過聯合訓練，模型可以學習到多個任務之間的特徵和規律。相比於針對每一個任務單獨進行微調，多任務微調能夠更好地完成各種任務。同時，由於學習到的特徵和規律是相互聯繫的，模型的泛化能力也會得到提高。這意味着，即使在面對未見過的任務時，模型也能夠表現出色，因為它已經學習到了許多相關任務的特徵和規律。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_4"></span><h4>2、運維 - DevOps 系列：</h4><p>業界首個開源的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-DevOps-Model" target="_blank" rel="nofollow"><span>中文開發運維大模型</span></a><span>，能夠幫助工程師回答在 DevOps 生命週期中遇到的問題，並提供通過檢索增強生成、工具學習和沙盒環境來構建軟件開發全生命週期的<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-chatbot" target="_blank" rel="nofollow"><span>AI 智能助手</span></a><span>；詳細介紹可以參看此前文章<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484045%26idx%3D1%26sn%3D838d9de49922b0d04bcffb3efbeec4df%26chksm%3Dc139d1bcf64e58aa0c92696d74ccebc64281a9ed287f88333bdd139e34ee5e8d46726ef9cd6e%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>DevOps-Eval</span></a><span>、</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484350%26idx%3D1%26sn%3Dc9875496ec1b2c75f47db73986007a05%26chksm%3Dc139d08ff64e5999b5c55f727d1b98475cc50a328662b5c84d921fe8c45a477f452effc2c41f%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>DevOps-Model</span></a><span>、</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484642%26idx%3D1%26sn%3De7dde520532b0868d267cff5ff4bc449%26chksm%3Dc139d7d3f64e5ec53f110495dbefc8e1903c9f09e13c909b2d236b1808bb9683d034b065e007%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>DevOps-Chatbot</span></a></p><div><p style="margin-left:0; margin-right:0"><span>我們希望用户逐漸從各處資料查詢、獨立分散平台操作的傳統開發運維模式轉變到大模型問答的智能化開發運維模式，改變人們的開發運維習慣。</span></p><p style="margin-left:0; margin-right:0"><span>核心差異技術、功能點：</span></p><ul><li><span>智能調度核心： 構建了體系鏈路完善的調度核心，支持多模式一鍵配置，簡化操作流程。</span></li><li><span>代碼整庫分析： 實現了倉庫級的代碼深入理解，以及項目文件級的代碼編寫與生成，提升了開發效率。</span></li><li><span>文檔分析增強： 融合了文檔知識庫與知識圖譜，通過檢索和推理增強，為文檔分析提供了更深層次的支持。</span></li><li><span>垂類專屬知識： 為 DevOps 領域定製的專屬知識庫，支持垂類知識庫的自助一鍵構建，便捷實用。</span></li><li><span>垂類模型兼容： 針對 DevOps 領域的小型模型，保證了與 DevOps 相關平台的兼容性，促進了技術生態的整合。</span></li></ul><p style="margin-left:0; margin-right:0"><span>依託於開源的 LLM 與 Embedding 模型，可實現基於開源模型的離線私有部署，此外，也支持 OpenAI API 的調用。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_5"></span><h4><span>3、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-Query" target="_blank" rel="nofollow">分析 - CodeFuse-Query</a></span><span>：</span></h4><p><span style="color:#000000">基於查詢的代碼分析引擎，適合大規模、複雜的代碼庫分析場景。可參考論文<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.01571" target="_blank" rel="nofollow"><span>https://arxiv.org/abs/2401.01571</span></a><span>；詳細介紹可以參看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484536%26idx%3D1%26sn%3D2e985b431ff9bd219c93b97ce4f4f444%26chksm%3Dc139d749f64e5e5f96f248f99d18bc55a5cd75fcb58c7726f52cfd6cd131f640d09e7d0e122a%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a></p><div><p style="margin-left:0; margin-right:0"><span>CodeFuse-Query 的特點和優勢可以概括為以下幾點：</span></p><ul><li><span>高度可擴展：CodeQuery 可以處理大規模的代碼庫，且能夠適應不同的分析需求。這種高度的可擴展性使得 CodeQuery 可以在大型組織中發揮重要作用。</span></li><li><span>以數據為中心：CodeQuery 將源代碼和分析結果視作數據，這種以數據為中心的方法使其在處理大數據環境中的代碼分析問題時具有獨特優勢。</span></li><li><span>高度集成：CodeQuery 能夠無縫地融入大型組織的各種系統中，包括數據倉庫、數據計算設施、對象存儲和靈活計算資源等。這種高度的集成性使得 CodeQuery 在大型組織中的使用變得更加方便和高效。</span></li><li><span>支持多元化的需求：CodeQuery 不僅可以處理大規模的代碼庫，還可以應對各種複雜的分析需求，包括服務質量分析需求、跨編程語言分析需求、算法需求和性能需求等。</span><br> &nbsp;</li></ul></div><span id="OSC_h4_6"></span><h4><span>4、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FTest-Agent" target="_blank" rel="nofollow">測試 - Test-Agent</a></span><span>：</span></h4><p><span>測試領域的「智能體」，打造創新的測試領域解決方案，構建 24 小時在線的測試助理服務；詳細介紹可以參看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247483884%26idx%3D3%26sn%3Db92d3cbbe82c9487777f63ad6a38851b%26chksm%3Dc139d2ddf64e5bcb2246335bf6ee327900c789dbfead77bfc3c325a8a4854f5d50bd839eb8ad%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a></p><div><p style="margin-left:0; margin-right:0"><span>大模型的號角已經吹響，測試領域大模型也在不斷進化中，通過預訓練過程中積累的豐富世界知識，在複雜交互環境中展現出了非凡的推理與決策能力。</span></p><p style="margin-left:0; margin-right:0"><span>儘管在測試領域中，基礎模型取得了顯著的成果，但仍然存在一些侷限性，特定領域的測試任務通常需要專業化的工具或領域知識來解決。例如，基礎模型可以通過預訓練知識完成單次測試代碼生成和測試文本生成等任務，但處理複雜的集成用例生成、特定領域用例生成和測試流程 pipeline 交互等問題時，需要更專業的工具和領域知識。</span></p><p style="margin-left:0; margin-right:0"><span>因此將專用工具與基礎模型整合在一起，可以充分發揮它們各自的優勢。專用工具可以解決模型時效性不足、增強專業知識、提高可解釋性和魯棒性的問題。而基礎模型則具備類人的推理規劃能力，可以理解複雜的數據和場景，並與現實世界進行交互。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_7"></span><h4><span>5、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-ModelCache%2Fblob%2Fmain%2FREADME_CN.md" target="_blank" rel="nofollow">推理 - ModelCache</a></span><span>：</span></h4><p><span>大模型語義緩存系統，通過緩存已生成的模型結果，降低類似請求的響應時間，提升用户體驗；詳細介紹可以參看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484139%26idx%3D1%26sn%3Df6b0fbe4d4dc7b47759146de60a1c820%26chksm%3Dc139d1daf64e58ccd522435f3769c2dd5b1953b7974c5efbb53ef0f9247ae3c037428a1770bf%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a><span>。</span></p><div><p style="margin-left:0; margin-right:0"><span>當前大模型服務面臨以下三個挑戰：</span></p><ul><li><span>成本高：大模型參數量千億級別，單實例就需要多張 A10 卡，規模化部署成本高昂。因此，當前大模型服務基本按照處理的 token 數量計費，導致用户側使用成本也居高不下。</span></li><li><span>速度慢：大型模型的推理速度也是一個關鍵問題。在許多實時應用中，如對話系統、業務助手，響應時間要求非常高，通常在毫秒級別。然而，大型模型的推理速度往往較慢，在秒級，導致無法實時返回結果，用户體驗下降。</span></li><li><span>穩定性無保障：由於單實例部署成本高昂，當前大模型服務接受到大流量請求時，通過限流的方式，防止服務不可用。</span></li></ul><p style="margin-left:0; margin-right:0"><span>針對上述挑戰，引入大模型緩存可以解決當前問題：通過引入 Cache 機制，緩存已計算的結果，當接收到類似請求，可以直接從緩存獲取結果，避免重複計算，節約計算資源，顯著提升響應時間，提升用户體驗；同時，緩存可以起到分流的作用，降低透傳到後端的請求量，降低後端壓力，提升服務穩定性。因此，Cache 作為一種重要的大模型服務部署解決方案，在資源有限和對實時性要求較高的場景下，可以幫助企業和研究機構更好地應用大型語言模型，提升模型性能和效率。未來，隨着大型模型在各個領域的廣泛應用，Cache 的重要性將不斷凸顯。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_8"></span><h4><span>6、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-evaluation%2Fblob%2Fmaster%2FREADME_CN.md" target="_blank" rel="nofollow">評測 - CodeFuse-Evaluation</a></span><span>：</span></h4><p><span>在 HumanEval-x、MBPP 的基準上開發的編程領域多任務的評測基準， 可用於評估大模型在代碼補全，自然語言生成代碼，測試用例生成、跨語言代碼翻譯、中文指令生成代碼等多類任務的性能；詳細介紹可以參看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484436%26idx%3D1%26sn%3D55ad2d46c2d6b8e9ef0d3e94201945b0%26chksm%3Dc139d725f64e5e331deb25933742bc70e9b608756059458bfa3700e16974711000ad20a32a86%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a><span>。</span></p><div><p style="margin-left:0; margin-right:0"><span>目前對於大語言模型評估的按照生成的結果是否可定量衡量比如數學計算和文章生成分為客觀評測和主觀評測。客觀評測：基於業界影響力較高評測基準對生成內容進行各維度評估；主觀評測：組織多位有專業背景知識的專家進行相關維度評估。</span></p><p style="margin-left:0; margin-right:0"><span>按照評測執行方式可分為自動化評測，人工評測和模型評測三類。</span></p><p style="margin-left:0; margin-right:0"><span>模型訓練完成後，基於評估基準跑出評分，這個過程可以完全工程化的執行因此成為自動化評測。人工評測特別是領域知識需要着急各領域專家進行測評，此種方式評估成本較高但是評估結果更具有説服力。模型（如 PandaLM）評測模型即通過訓練大模型學習到人類對不同生成文本的總體偏好，並作出基於習得的人類偏好的相對評價，這種評價方式相比人工更穩定、高效。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h2_9"></span><h2><span>三、精彩的社區活動</span></h2><p style="margin-left:0; margin-right:0"><span>我們深知，開源不只是開放代碼，還包括在社區的分享與交流。在開源內容上乾貨滿滿，社區活動定也不落下風，讓我們看看都有哪些吧！！</span></p><p style="margin-left:0; margin-right:0"><span>8 月，我們在 AI+ 軟件研發數字峯會上進行了專場分享《基於 AIGC 的測試生成》；</span></p><p style="margin-left:0; margin-right:0"><span>9 月，外灘大會上正式對外宣佈 CodeFuse 開源；</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420417098-5d63a0fa-ef73-4abe-8569-db04857eddef.png" width="540" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>10 月，在 MLSummit 2023 上，對外分享了 CodeFuse 研發經驗；</span></p><p style="margin-left:0; margin-right:0"><span>11 月初，在雲棲大會上進行 CodeFuse 專題演講；</span></p><p style="margin-left:0; margin-right:0"><span>11 月，和始智 AI 等聯合舉辦了「代碼大模型技術與應用發展」論壇；</span></p><p style="margin-left:0; margin-right:0"><span>12 月初，在 CCF 中國軟件大會上，與參會者現場體驗、互動交流；</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420830670-62d284f9-b89c-4c3f-9f10-1bc174d4154e.png" width="480" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>12 月末，在全球軟件開發者大會 QCon 上經驗分享《基於 CodeFuse 的下一代研發探索》。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_10"></span><h2><span>四、獲得業界認可</span></h2><p style="margin-left:0; margin-right:0"><span>今年，CodeFuse 還獲得了多個獎項，感謝業界的認可：</span></p><ul><li><span>榮獲開源中國 2023 年度優秀開源技術團隊</span></li></ul><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420476632-42355276-1d79-46dd-bcb6-eb0c29a62311.png" width="540" referrerpolicy="no-referrer"></p><ul><li><span>入選極客公園 2023 大模型先鋒案例 TOP10</span></li></ul><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420452319-a2eabbe9-21a1-47e2-a54f-84d5fce1b04b.png" width="540" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:center">&nbsp;</p><span id="OSC_h2_11"></span><h2><span>五、2024 新的期待</span></h2><p style="margin-left:0; margin-right:0"><br><span>2023 年以來，大模型在代碼領域落地不斷深入。經過一年的實踐，我們對相關的技術也有了更深層次的理解與認識。也看到了很多有趣的方向與落地實踐。在 2024 新的一年裏，我們還會繼續深耕開源：</span></p><ul><li><span>更多創新功能發佈，例如近期 1 月份將發佈支持 MoE 的 MFTCoder v0.2; 2 月份將發佈支持前端設計到代碼的訓練框架和模型；</span></li><li><span>更多的線下活動，會組織多次 CodeFuse 線下 meetup，歡飲感興趣的同行多多參與；也會積極參與國內和國際行業會議/論壇更多分享 CodeFuse 的實踐經驗；</span></li><li><span>更多的社區參與和互動，會社區調研，讓大家能夠參與到項目中來；包括不限於發起社區一起捉蟲、一起貢獻新特性，推動相關體系的標準化，甚至組織相關比賽活動等。</span></li></ul><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>非常歡迎大家能夠跟我們一起交流探索，一起來定義下一代基於大模型的全生命週期研發解決方案。歡迎大家參與到我們社區中，一起探討、交流。 2024，一起向未來！</span></p><p style="margin-left:0; margin-right:0"><span style="color:rgba(0, 0, 0, 0.9)">CodeFuse 官網：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodefuse.alipay.com" rel="nofollow" target="_blank"><span style="color:#0080ff">https://codefuse.alipay.com</span></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 07:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/10678192</guid>
            <link>https://my.oschina.net/u/6942768/blog/10678192</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[商湯科技：前海深港人工智能算力中心正式啓動]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>商湯科技發文宣佈，前海深港人工智能算力中心正式點亮啓動；目標打造粵港澳大灣區大規模、領先算力的智算中心。</p><p>一期建設算力將達 500 Petaflops（FP16），AI 算力規模每秒 50 億億次，相當於一小時可完成 16 億張圖像處理、190 萬小時語音翻譯、0.7 萬公里自動駕駛 AI 數據處理；</p><p>該算力中心坐落於深圳市前海信息樞紐大廈，由深圳前海管理局、商湯科技、香港科技園公司三方共同推進，前海科技創新集團與商湯科技聯合投資建設。</p><p>商湯科技董事長兼 CEO 徐立表示：</p><blockquote><p>「人工智能在 2023 年實現了跨越式發展，進入以大模型為基礎的 AI 2.0 時代，先進智能算力作為當前最具活力的新型生產力，已成為重要的戰略資源。前海加大科技基礎設施建設和科技領域投入，又一次走在了全國新舊發展動能轉換的前列。基於建成亞洲最大 AIDC 智算中心之一的成功經驗，商湯願意充分發揮在人工智能行業的優勢，在深港合作、算法大模型、人工智能產業與投資等領域加強產業帶動與應用示範，協同香港與前海融合發展做出貢獻。」</p></blockquote><p>活動現場<span style="background-color:#ffffff; color:#4c4c4c">還舉行了智算中心意向客户簽約儀式，並與前海大數據資源管理中心有限公司簽訂了委託運營協議。</span></p><p><img height="292" src="https://oscimg.oschina.net/oscnet/up-f2e6b62e914595ab3929261a6cb9b2e07c8.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 07:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274742</guid>
            <link>https://www.oschina.net/news/274742</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[R 語言社區知名開發者「謝益輝」被 RStudio/Posit 解僱]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>R Markdown、knitr、blogdown 和 bookdown 等 R 軟件包的創建者<span style="background-color:#ffffff; color:#191b1f">謝益輝</span>於日前<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyihui.org%2Fen%2F2024%2F01%2Fbye-rstudio%2F" target="_blank">發佈博客表示</a>，自己已於 2023 年底被 Posit (原 Rstudio) 公司解僱，並於 2024 年 1 月 1 日正式離開該公司。</p><blockquote><p><span style="color:#000000">在寫了這麼多年的 「*down」 packages 後，我在這裏宣佈「Yihui-down」。</span></p><p>誰倒下了？我。在 RStudio/Posit 工作了 10 多年之後，<span style="color:#000000">現在是我探索其他機會的時候了</span>。兩個多星期前，我被告知被裁員了，最後一天是 2023-12-31。坦率地説，我感到非常驚訝，但只是短暫的驚訝。我完全尊重 Posit 的決定，並很快接受了我的貢獻不再配得上這裏的全職工作這一結論。一段關係的結束往往並不意味着任何一方做錯了什麼或失敗了什麼。相反，它可能只是表明雙方不匹配，這很正常。人就是會變。<span style="color:#000000">回想起這些美好的歲月，我離開時大多懷着感激之情。</span></p></blockquote><p><span style="background-color:#ffffff; color:#191b1f">謝益輝表示，</span><span style="background-color:#ffffff; color:#000000">Posit 同時</span><span style="background-color:#ffffff; color:#111111">為他提供了一個合同工方案；因此這一離開並不意味着訣別，他後續將繼續維護 R Markdown 系列包（暫定一年）。現有的 R 軟件包仍將得到維護。但 DT 軟件包是唯一的例外，因為它不在合同之列，Posit 計劃為它尋找新的維護者。</span></p><p><span style="background-color:#ffffff; color:#111111">但這一合同工並不足以維生，</span><span style="background-color:#ffffff; color:#191b1f">謝益輝也在需找新的工作機會，希望同時能夠滿足可以自由靈活地繼續為 R 生態系統和開源做出貢獻。</span></p><p><span style="background-color:#ffffff; color:#191b1f">考慮到被突然解僱後所面臨的經濟壓力，謝益輝還發布了一個眾籌的贊助頁面，以尋求大家的幫助：</span><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsponsors%2Fyihui" target="_blank">https://github.com/sponsors/yihui</a></strong></p><p>「我以前從未向社區請求過經濟支持，因為我從來沒有感覺到有必要（感謝 Posit）。現在情況變得不一樣了......如果有人能在我過渡到下一個穩定的生活階段之前支持我幾個月，我將非常感激。當我不再需要贊助時，我會通知大家，如果你們是月度贊助，可以取消贊助。我很樂意提供一些臨時性的幫助作為回報。」</p><p><img height="250" src="https://oscimg.oschina.net/oscnet/up-53f457f44cfc3d2e70079cb04b2ef93e18a.png" width="500" referrerpolicy="no-referrer"></p><p>一些 R 用户對於<span style="background-color:#ffffff; color:#191b1f">謝益輝的離開</span>表達了震驚，研究軟件工程師 Zhian N. Kamvar 在 Mastodon 上<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhachyderm.io%2F%40zkamvar%2F111699279163834211" target="_blank">發帖稱</a>，「這絕對是毀滅性的消息。如果沒有<span style="background-color:#ffffff; color:#191b1f">益</span>輝在 knitr 上的工作，我不可能取得過去十年的成就。如果你最近有使用過 RStats 構建的網站、報告或書籍，你都要感謝<span style="background-color:#ffffff; color:#191b1f">益</span>輝。」</p><p>外媒&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3712061%2Fposit-lays-off-r-markdown-knitr-creator-yihui-xie.html" target="_blank">InfoWorld</a> 認為，<span style="background-color:#ffffff; color:#191b1f">謝益輝的離開再次表明了一個信號，即&nbsp;Posit&nbsp;</span>正在專注於提供 R 和 Python 之間互操作性的產品。一個相關的佐證就是 2022 年發佈的 Quarto 開源技術發佈平台，該平台不區分語言，同樣支持 R 和 Python，以及 Julia 和 Observable JavaScript。該公司當時表示，Quarto 將是下一代 R Markdown。</p><p>在<span style="background-color:#ffffff; color:#191b1f">謝益輝</span>被解僱的前一個月，Python pandas 創建者 Wes McKinney 也加入了 Posit，這也表明該公司正在認真地將其業務重點擴大到 R 之外。McKinney 當時表示，他將「在 Posit 的工作中倡導 PyData 生態系統的需求，並繼續推進重要的開源計劃。」</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274729/posit-lays-off-yihui-xie</guid>
            <link>https://www.oschina.net/news/274729/posit-lays-off-yihui-xie</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | 「後開源」 時代已來；Redis 之父 「鋭評」 LLM 編程；2024 前端圈「開年之戰」上演....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2024.01.01-2024.01.07]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 06:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094095&#38;idx=1&#38;sn=ef33510eefe489ba79639ee09ff10152&#38;chksm=880c4cdcbf7bc5ca1ab8725a741382ed6cce96c7493e27dbb87e559dde82be3bbeb14def9960&#38;token=1679093283&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094095&#38;idx=1&#38;sn=ef33510eefe489ba79639ee09ff10152&#38;chksm=880c4cdcbf7bc5ca1ab8725a741382ed6cce96c7493e27dbb87e559dde82be3bbeb14def9960&#38;token=1679093283&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[App 跨平台框架 VS 原生開發深度評測之 2023 版]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>App 跨平台框架歷史悠久，從<code>cordova</code>、<code>react native</code>、<code>flutter</code>，直到最近的<code>uni-app x</code>。江山代有才人出，每個都試圖顛覆原生，但過去卻一直未成功。</p><p>過去的問題到底在哪裏？</p><p>我們先捋一捋各種技術路線，分析這些跨平台開發框架和原生應用的差別具體在哪裏。</p><table><thead><tr><th>邏輯層</th><th>渲染層</th><th>類型</th><th>代表作</th></tr></thead><tbody><tr><td>webview</td><td>webview</td><td>弱類型</td><td>5+App、cordova</td></tr><tr><td>js 引擎</td><td>webview</td><td>弱類型</td><td>uni-app 之<code>app-vue</code> 、小程序（dount）</td></tr><tr><td>js 引擎</td><td>原生渲染</td><td>弱類型</td><td>react native、uni-app 之<code>app-nvue</code>、weex</td></tr><tr><td>dart 引擎</td><td>flutter 渲染引擎</td><td>強類型</td><td>flutter</td></tr><tr><td>js 引擎</td><td>flutter 渲染引擎</td><td>弱類型</td><td>微信 skyline、webF、ArkUI-x</td></tr><tr><td>kotlin</td><td>原生渲染</td><td>強類型</td><td>uni-app x</td></tr><tr><td>kotlin</td><td>原生渲染</td><td>強類型</td><td>原生應用</td></tr></tbody></table><p>上面的表格，除了行尾的原生應用外，各個跨平台框架按出現時間排序，可以看到跨平台框架是如何演進的。</p><p>上表中，<code>uni-app x</code>和原生應用是一樣的，邏輯層和渲染層都是原生，都是強類型；而其他跨平台框架或者在邏輯層、或者在渲染層與原生不一致。</p><p><code>webview</code>不行已經是業內常識了，啓動慢、渲染慢、內存佔用高。這塊本文不再詳述。</p><p>但那些非 web-view 的框架到底哪裏不如原生？</p><h2>1. js 邏輯+ 原生渲染</h2><p><code>react native</code>、<code>weex</code>等拋棄<code>webview</code>，改由原生渲染的跨平台方案，2014 年就推出了。 如今手機硬件也越來越好了，為什麼性能還達不到原生？</p><p>js+原生渲染的方案主要有 2 點缺陷：</p><ul><li>JS 引擎自身的性能問題</li><li>JS 和原生之間的通信延遲</li></ul><h3>1.1 js 引擎慢，啓動速度和運行速度都弱於原生</h3><p>所以很多開發者即便使用這類方案，首頁也還是原生來寫。</p><p>React Native 的<code>Hermes</code>引擎和華為的<code>arkUI</code>，提供了 js 編譯為字節碼的方案，這是一種空間換時間的方案，啓動速度有了一定優化，但仍然比不過原生。</p><p>弱類型在編譯期可優化的幅度有限，還是需要一個運行時來跑，無法像強類型那樣直接深入底層。</p><p>以數字運算為例，js 的<code>number</code>運算確實比強類型的<code>int</code>慢，內存開銷也更大。</p><h3>1.2 js 語言與原生之間通信卡頓</h3><p>每個語言有自己的內存空間，跨語言通信都有折損，每次通信幾十到幾百毫秒不等，視手機當時的狀態。一旦頻繁通信，就會明顯卡頓。</p><p>邏輯層的 js，即要和原生渲染層通信，還要和原生 API 通信：</p><h4>1.2.1 js 與原生 ui 通信</h4><p>舉個簡單的場景例子，在 js 裏監聽滾動，根據滾動變化實時調整界面上某些元素的高度變化。這個問題能難倒一大批跨平台開發框架。</p><p>如果全部在 webview 裏，js 操作 ui 還好一些，所以 uni-app 的 app-vue 裏的 renderjs 操作 UI 性能高，就是這個道理。同理還有微信小程序的<code>wsx</code>。</p><p>雖然小程序和 uni-app 都是 js，但實際上邏輯層在獨立 js 引擎裏，通過原生橋來控制 web-view，通信成本很高。</p><p>weex 提供了<code>bindingx</code>技術，這是一種弱編程，渲染層預先定義了一些操作 UI 的方式，調用時全部在渲染層運行，不會來回與邏輯層通信。但這種預定義方式的適應面有限，無法做到在 js 裏高性能、自由的操作所有 UI。</p><h4>1.2.2 js 操作原生 api</h4><p>操作系統和三方 SDK 的 API 都是原生的，js 調用這些能力也需要跨語言通信。比如 js 調用原生的 Storage 或 IO，數據較多時遍歷的性能非常差。</p><p>當然在 js API 的封裝上可以做些優化，比如微信的 storage 提供了<code>wx.batchGetStorageSync</code>這種批量讀取的 API，既然遍歷性能差，那乾脆一次性從原生讀出來再傳給 js。</p><p>這也只能是無奈的方案，如果在遍歷時想用 js 做什麼判斷就實現不了了，而且一次性讀出很大的數據後傳給 js 這一下，也需要通信時間。</p><h2>2. flutter 方案</h2><p>flutter 在 2018 年發佈，第一次統一了邏輯層和渲染層，而且使用了強類型。</p><p>它沒有使用原生渲染，而是使用由<code>dart</code>驅動的渲染引擎，這樣邏輯層的 dart 代碼操作 UI 時，再也沒有延時了！bindingx、wxs 這種補丁方案再也不需要了。</p><p>並且 dart 作為強類型，編譯優化很好做，啓動速度和運行速度都勝過 js。</p><p>在這個開源項目下<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_flutter_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_flutter_slider_100</a>，提供了一個 flutter 編寫的 100 個 slider 同時滑動的示例， 項目下有源碼也有打包好 apk，可以直接安裝體驗。</p><p>100 個 slider 同時滑動，非常考驗邏輯和 UI 的通信。如果在 webview 內部，html 和 js 寫 100 個這樣的 slider，在新的手機上表現也還 ok。但在小程序和 react native 這種邏輯和 UI 分離的模式下，100 個 slider 是災難。</p><p>下載安裝 apk 後可以看到 dart 操作 flutter 的 UI 真的沒有通信折損，100 個 slider 的拖動非常流暢。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317188140437864502%3FlogTag%3Dfd9af6e9d0d98f40568e" target="_blank">點擊查看視頻</a></p><p>flutter 看起來很完美。但為什麼也沒有成為主流呢？很多大廠興奮的引入後為何又不再擴大使用範圍呢？</p><h3>2.1 dart 與原生 API 的通信</h3><p>別忘了上面 1.2.2 提到的原生 API 通信。flutter 雖然在邏輯層和渲染層都是 dart，但要調用原生 API 時，還是要通信。</p><p>操作系統和三方 SDK 的 API 是原生的，讓 dart 調用需要做一層封裝，又落到了跨語言通信的坑裏。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest_flutter_message_channel" target="_blank">https://gitcode.net/dcloud/test_flutter_message_channel</a>這是一個開源測試項目，來測試原生的 claas 數據與 dart 的通信耗時。</p><p>項目裏面有源碼，大家可自行編譯；根目錄有打包好的 apk，也可以直接安裝體驗。</p><p>這個項目首先在 kotlin 中構建了包含不同數據量的 class，傳遞到 dart 然後渲染在界面上，並且再寫回到原生層。</p><p>有 0.1k 和 1k 兩種數據量（點擊界面上的 1k 數字可切換），有讀和讀並寫 2 個按鈕，各自循環 1000 次。</p><p>以下截圖的測試環境是華為 mate 30 5G，麒麟 990。手機上所有進程殺掉。如下圖：</p><ul><li>1k 數據從原生讀到 dart 並渲染</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-b6da22344a6d16c9d69b06e7e643d8693c1.jpg" alt="flutter_1k_read.jpeg" referrerpolicy="no-referrer"></p><ul><li>1k 數據從原生讀到 dart 並渲染再寫回</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-bf956b25b963ff74a653cb15558cad78f00.jpg" alt="flutter_1k_readwrite.jpeg" referrerpolicy="no-referrer"></p><ul><li>0.1k 數據從原生讀到 dart 並渲染</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-eec96c5ae67f8c3db0137dc2f84f5c757c3.jpg" alt="flutter_0.1k_read.jpeg" referrerpolicy="no-referrer"></p><ul><li>0.1k 數據從原生讀到 dart 並渲染再寫回</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-6df9c0934af2fed44809afdcad596493c1e.jpg" alt="flutter_0.1k_readwrite.jpeg" referrerpolicy="no-referrer"></p><p>通信損耗非常明顯。並且數據量從 1k 降低到 0.1k 時，通信時間並沒有減少 10 倍，這是因為通信耗時有一個基礎線，數據再小也降不下去。</p><p>為什麼會這樣？因為<code>dart</code>和<code>kotlin</code>不是一種編程語言，不能直接調用<code>kotlin</code>的<code>class</code>，只能先序列化成字符串，把字符串數據從原生傳到 dart，然後在 dart 層再重新構造。</p><p>當然也可以在原生層為 dart 封裝 API 時提供 wx.batchGetStorageSync 這類批處理 API，把數據一次讀好再給 dart，但這種又會遇到靈活性問題。</p><p>而在<code>uni-app x</code>中，這種跨語言通信是不存在的，不需要序列化，因為 uni-app x 使用的編程語言 uts，在 android 上就編譯為了 kotlin，它可以直接調用 kotlin 的 class 而無需通信和封裝。示例如下，具體 uni-app x 的原理後續章節會專題介紹。</p><pre><code>&lt;template&gt;
&lt;/template&gt;
&lt;script lang="uts"&gt;
import Build from 'android.os.Build';
export default {
onLoad() {
console.log(Build.MODEL); //uts 可以直接導入並使用原生對象，不需要封裝，沒有跨語言通信折損
}
}
&lt;/script&gt;
</code></pre><p>再分享一個知識：</p><p>很多人都知道 iPhone 上跨平台框架的應用，表現比 android 好。但大多數人只知道是因為 iPhone 的硬件好。</p><p>其實還有一個重要原因，iOS 的 jscore 是 c 寫的，OS 的 API 及渲染層也都是 ObjectC，js 調用原生時，某些類型可以做共享內存的優化。但複雜對象也還是無法直接丟一個指針過去共享使用內存。</p><p>而 android，不管 java 還是 kotlin，他們和 v8、dart 通信仍然需要跨語言通信。</p><h3>2.2 flutter 渲染和原生渲染的並存問題</h3><p>flutter 的自渲染引擎，在技術上是不錯的。但在生態兼容上有問題。</p><p>很多三方軟件和 SDK 是原生的，原生渲染和 flutter 自渲染並存時，問題很多。</p><p>flutter 開發者都知道的一個常見坑是輸入法，因為輸入法是典型的原生 UI，它和 flutter 自繪 UI 並存時各種兼容問題，輸入框被遮擋、窗體 resize 適應，輸入法有很多種，很難適配。</p><p>混合渲染，還有信息流廣告、map、圖表、動畫等很多三方 sdk 涉及。這個時候內存佔用高、渲染幀率下降、不同渲染方式字體不一致、暗黑主題不一致、國際化、無障礙、UI 自動化測試，各種不一致。。。</p><p>這裏沒有提供開源示例，因為 flutter 官方是承認這個問題的，它提供了 2 種方式：混合集成模式和虛擬顯示模式模式。</p><p>但在渲染速度、內存佔用、版本兼容、鍵盤交互上都各自有各自的問題。詳見 flutter 官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.flutter.dev%2Fplatform-integration%2Fandroid%2Fplatform-views%23performance" target="_blank">https://docs.flutter.dev/platform-integration/android/platform-views#performance</a>。這個是中文翻譯：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fflutter.cn%2Fdocs%2Fplatform-integration%2Fandroid%2Fplatform-views%23performance" target="_blank">https://flutter.cn/docs/platform-integration/android/platform-views#performance</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fflutter.cn%2Fdocs%2Fplatform-integration%2Fandroid%2Fplatform-views%23performance" target="_blank"></a></p><p>在各大 App 中，微信的小程序首頁是為數不多的使用 flutter UI 的界面，已經上線 1 年以上。</p><p>下面是微信 8.0.44（此刻最新版），從微信的發現頁面進入小程序首頁。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317194438416007206%3FlogTag%3D8165f43a009f28425f24" target="_blank">點擊查看視頻</a></p><p>視頻中手機切換暗黑主題後，這個 UI 卻還是白的，而且 flutter 的父容器原生 view 已經變黑了，它又在黑底上繪製了一個白色界面，體驗非常差。</p><p>這個小程序首頁界面很簡單，沒有輸入框，規避了混合渲染，點擊搜索圖標後又跳轉到了黑色的原生渲染的界面裏。</p><p>假使這個界面再內嵌一個原生的信息流 SDK，那會看到白色 UI 中的信息流廣告是黑底的，更無法接受。</p><p>當然這不是説 flutter 沒法做暗黑主題，重啓微信後這個界面會變黑。這裏只是説明渲染引擎不一致帶來的各種問題。</p><blockquote><p>注：如何識別一個界面是不是用 flutter 開發的？在手機設置的開發者選項裏，有一個 GPU 呈現模式分析，flutter 的 UI 不觸發這個分析。且無法審查佈局邊界。</p></blockquote><p>flutter 的混合渲染的問題，在所有使用原生渲染的跨平台開發框架中都不存在，比如 react native、weex、uni-app x。</p><p>總結下 flutter：邏輯層和 UI 層交互沒有通信折損，但邏輯層 dart 和原生 api 有通信成本，自繪 UI 和原生 ui 的混合渲染問題很多。</p><h2>3. js+flutter 渲染</h2><p>flutter 除了上述提到的原生通信和混合渲染，還有 3 個問題：dart 生態、熱更新、以及比較難用的嵌套寫法。</p><p>一些廠商把 flutter 的 dart 引擎換成了 js 引擎，來解決上述 3 個問題。比如微信 skyline、webF、ArkUI-x。</p><p>其實這是讓人困惑的行為。因為這又回到了 react native 和 weex 的老路了，只是把原生渲染換成了 flutter 渲染。</p><p>flutter 最大的優勢是 dart 操作 UI 不需要通信，以及強類型，而改成 js，操作 UI 再次需要通信，又需要 js 運行時引擎。</p><p>為瞭解決 js 和 flutter 渲染層的通信問題，微信的 skyline 又推出了補丁技術 worklet 動畫，讓這部分代碼運行在 UI 層。（當然微信的通信，除了跨語言，還有跨進程通信，會更明顯）</p><p>這個項目<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_arkuix_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_arkuix_slider_100</a>， 使用 ArkUI-x 做了 100 個 slider，大家可以看源碼，下載 apk 體驗，明顯能看到由於邏輯層和 UI 層通信導致的卡頓。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317196064589627411%3FlogTag%3D368ecfd6c36a3f4fe41a" target="_blank">點擊查看視頻</a></p><p>上述視頻中，注意看手指按下的那 1 個 slider，和其他 99 個通過數據通訊指揮跟隨一起行動的 slider，無法同步，並且界面掉幀。</p><p>不過自渲染由於無法通過 Android 的開發者工具查看 GPU 呈現模式，所以無法從條狀圖直觀反映出掉幀。</p><blockquote><p>注意 ArkUI-x 不支持<code>Android8.0</code>以下的手機，不要找太老的手機測試。</p></blockquote><p>很多人以為自渲染是王道，但其實自渲染是坑。因為 flutter 的 UI 還會帶來混合渲染問題。</p><p>也就是説，js+flutter 渲染，和 js+原生渲染，這 2 個方案相比，都是 js 弱類型、都有邏輯層和渲染層的通信問題、都有原生 API 通信問題，而 js+flutter 還多了一個混合渲染問題。</p><p>可能有的同學會説，原生渲染很難在 iOS、Android 雙端一致，自渲染沒有這個問題。</p><p>但其實完全可以雙端一致，如果你使用某個原生渲染框架遇到不一致問題，那只是這個框架廠商做的不好而已。</p><p>是的，很遺憾 react native 在跨端組件方面投入不足，官方連 slider 組件都沒有，導致本次評測中未提供 react native 下 slider-100 的示例和視頻。</p><h2>4. uni-app x</h2><p>2022 年，uts 語言發佈。2023 年，uni-app x 發佈。</p><p>uts 語言是基於 typescript 修改而來的強類型語言，編譯到不同平台時有不同的輸出：</p><ul><li>編譯到 web，輸出 js</li><li>編譯到 Android，輸出 kotlin</li><li>編譯到 iOS，輸出 swift</li></ul><p>而 uni-app x，是基於 uts 語言重新開發了一遍 uni-app 的組件、API 以及 vue 框架。</p><p>如下這段示例，前端的同學都很熟悉，但它在編譯為 Android App 時，變成了一個純的 kotlin app，裏面沒有 js 引擎、沒有 flutter、沒有 webview，從邏輯層到 UI 層都是原生的。</p><pre><code>&lt;template&gt;
&lt;view class="content"&gt;
&lt;button @click="buttonClick"&gt;{{title}}&lt;/button&gt;
&lt;/view&gt;
&lt;/template&gt;

&lt;script&gt; //這裏只能寫 uts
export default {
data() {
return {
title: "Hello world"
}
},
onLoad() {
console.log('onLoad')
},
methods: {
buttonClick: function () {
uni.showModal({
"showCancel": false,
"content": "點了按鈕"
})
}
}
}
&lt;/script&gt;

&lt;style&gt;
.content {
width: 750rpx;
background-color: white;
}
&lt;/style&gt;
</code></pre><p>這聽起來有點天方夜譚，很多人不信。DCloud 不得不反覆告訴大家，可以使用如下方式驗證：</p><ul><li><p>在編譯 uni-app x 項目時，在項目的 unpackage 目錄下看看編譯後生成的 kt 文件</p></li><li><p>解壓打包後的 apk，看看裏面有沒有 js 引擎或 flutter 引擎</p></li><li><p>手機端審查佈局邊界，看看渲染是不是原生的（flutter 和 webview 都無法審查佈局邊界）</p></li></ul><p>但是開發者也不要誤解之前的 uni-app 代碼可以無縫遷移。</p><ul><li><p>之前的 js 要改成 uts。uts 是強類型語言，上面的示例恰好類型都可以自動推導，不能推導的時候，需要用<code>:</code>和<code>as</code>聲明和轉換類型。</p></li><li><p>uni-app x 支持 css，但是 css 的子集，不影響開發者排版出所需的界面，但並非 web 的 css 全都兼容。</p></li></ul><p>瞭解了 uni-app x 的基本原理，我們來看下 uni-app x 下的 100 個 slider 效果怎麼樣。</p><p>項目<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_uniappx_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_uniappx_slider_100</a>下有源碼工程和編譯好的 apk。</p><p>如下視頻，打開了 GPU 呈現模式，可以看到沒有一條豎線突破那條紅色的掉幀安全橫線，也就是沒有一幀掉幀。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317198768934715433%3FlogTag%3D89299d3c416b4e9e6de7" target="_blank">點擊查看視頻</a></p><p>uni-app x 在 app 端，不管邏輯層、渲染層，都是 kotlin，沒有通信問題、沒有混合渲染問題。不是達到了原生的性能，而是它本身就是原生應用，它和原生應用的性能沒差別。</p><p>這也是其他跨平台開發框架做不到的。</p><p>uni-app x 是一次大膽的技術突破，分享下 DCloud 選擇這條技術路線的思路：</p><p>DCloud 做了很多年跨平台開發，uni-app 在 web 和小程序平台取得了很大的成功，不管規模大小的開發者都在使用；但在 app 平台，大開發者只使用 uni 小程序 sdk，中小開發者的 app 會整體使用。</p><p>究其原因，uni-app 在 web 和小程序上，沒有性能問題，直接編譯為了 js 或 wxml，uni-app 只是換了一種跨平台的寫法，不存在用 uni-app 開發比原生 js 或原生 wxml 性能差的説法。</p><p>但過去基於小程序架構的 app 端，性能確實不及原生開發。</p><p>那麼 App 平台，為什麼不能像 web 和小程序那樣，直接編譯為 App 平台的原生語言呢？</p><p>uni-app x，目標不是改進跨平台框架的性能，而是給原生應用提供一個跨平台的寫法。</p><p>這個思路的轉換使得 uni-app x 超越了其他跨平台開發框架。</p><p>在 web 端編譯為 js，在小程序端編譯為 wxml 等，在 app 端編譯為 kotlin。每個平台都只是幫開發者換種一致的寫法而已，運行的代碼都是該平台原生的代碼。</p><p>然而在 2 年前，這條路線有 2 個巨大的風險：</p><ol><li><p>從來沒有人走通過</p></li><li><p>即便能走通，工作量巨大</p></li></ol><p>沒有人確定這個產品可以做出來，DCloud 內部爭議也很多。</p><p>還好，經歷了無數的困難和挑戰，這個產品終於面世了。</p><p>換個寫法寫原生應用，還帶來另一個好處。</p><p>同樣業務功能的 app，使用 vue 的寫法，比手寫純原生快多了。也就是 uni-app x 對開發效率的提升不只是因為跨平台，單平台它的開發效率也更高。</p><p>其實 google 自己也知道原生開發寫法太複雜，關於換種更高效的寫法來寫原生應用，他們的做法是推出了 compose UI。</p><p>不過遺憾的是這個方案引入了性能問題。我們專門測試使用 compose UI 做 100 個 slider 滑動的例子，流暢度也掉幀。</p><p>源碼見：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_compose_ui_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_compose_ui_slider_100</a>， 項目下有打包後的 apk 可以直接安裝體驗。</p><p>打開 GPU 呈現模式，可以看到 compose ui 的 100 個 slider 拖動時，大多數豎線都突破那條紅色的掉幀安全橫線，也就是掉幀嚴重。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317199270568787978%3FlogTag%3D198750168701d834e8ac" target="_blank">點擊查看視頻</a></p><p>既然已經把不同開發框架的 slider-100 應用打包出來了，我們順便也比較了不同框架下的包體積大小、內存佔用：</p><table><thead><tr><th></th><th>包體積（單位:M）</th><th>內存佔用（單位:Kb）</th></tr></thead><tbody><tr><td>flutter</td><td>18</td><td>141324.8</td></tr><tr><td>ArtUI-x</td><td>45.7</td><td>133091.2</td></tr><tr><td>uni-app x</td><td>8.5</td><td>105451.2</td></tr><tr><td>compose ui</td><td>4.5</td><td>97683.2</td></tr></tbody></table><p><strong>包體積數據説明：</strong></p><ul><li><p>包含 3 個 CPU 架構：arm64、arm32、x86_64。</p></li><li><p>flutter 的代碼都是編譯為 so 文件，支持的 cpu 類型和包體積是等比關係，1 個 cpu 最小需要 6M 體積，業務代碼越多，cpu 翻倍起來越多。</p></li><li><p>ArtUI-x 的業務代碼雖然寫在 js 裏，但除了引用了 flutter 外還引用了 js 引擎，這些 so 庫體積都不小且按 cpu 分類型翻倍。</p></li><li><p>uni-app x 裏主業務都在 kotlin 裏，kotlin 和 Android x 的兼容庫佔據了不少體積。局部如圖片引用了 so 庫，1 個 cpu 最小需要 7M 體積。但由於 so 庫小，增加了 2 個 cpu 類型只增加了不到 1M。</p></li><li><p>compose ui 沒有使用 so 庫，體積裁剪也更徹底。</p></li><li><p>uni-app x 的常用模塊並沒有裁剪出去，比如 slider100 的例子其實沒有用到圖片，但圖片使用的 fesco 的 so 庫還是被打進去了。實際業務中不可能不用圖片，所以實際業務中 uni-app x 並不會比 compose ui 體積大多少。</p></li></ul><p><strong>內存佔用數據説明：</strong></p><ul><li>在頁面中操作 slider 數次後停止，獲取應用內存使用信息 VmRSS: 進程當前佔用物理內存的大小</li><li>表格中的內存數據是運行 5 次獲取的值取平均值</li><li>自渲染會佔據更多內存，如果還涉及混合渲染那內存佔用更高</li></ul><h2>5. 後記</h2><p>跨語言通信、弱類型、混合渲染、包體積、內存佔用，這些都是過去跨平台框架不如原生的地方。</p><p>這些問題在<code>uni-app x</code>都不存在，它只是換了一種寫法的原生應用。</p><table><thead><tr><th>各種框架</th><th>類型</th><th>邏輯層與 UI 通信折損</th><th>邏輯層與 OS API 通信折損</th><th>混合渲染</th></tr></thead><tbody><tr><td>react native、nvue、weex</td><td>弱</td><td>有</td><td>有</td><td>無</td></tr><tr><td>flutter</td><td>強</td><td>無</td><td>有</td><td>有</td></tr><tr><td>微信 skyline、webF、ArkUI-x</td><td>弱</td><td>有</td><td>有</td><td>有</td></tr><tr><td>uni-app x</td><td>強</td><td>無</td><td>無</td><td>無</td></tr><tr><td>原生應用</td><td>強</td><td>無</td><td>無</td><td>無</td></tr></tbody></table><p>當然，作為一個客觀的分析，這裏需要強調<code>uni-app x</code>剛剛面世，還有很多不成熟的地方。比如前文 diss 微信的暗黑模式，其實截止到目前 uni-app x 還不支持暗黑模式。甚至 iOS 版現在只能開發 uts 插件，還不能做完整 iOS 應用。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvote.dcloud.net.cn%2F%23%2F%3Fname%3Duni-app%2520x" target="_blank">需求牆</a>裏都是 uni-app x 該做還未做的。也歡迎大家投票。</p><p>另外，原生 Android 中一個界面不能有太多元素，否則性能會拉胯。flutter 的自渲染和 compose ui 解決了這個問題。而原生中解決這個問題需要引入自繪機制來降低元素數量，這個在<code>uni-app x</code>裏對應的是 draw 自繪 API。</p><p>uni-app x 這個技術路線是產業真正需要的東西，隨着產品的迭代完善，它能真正幫助開發者即提升開發效率又不犧牲性能。</p><p>讓跨平台開發不如原生，成為歷史。</p><p>歡迎體驗 uni-app x 的示例應用，感受它的啓動速度，渲染流暢度。</p><p>源碼在：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Fhello-uni-app-x%2F" target="_blank">https://gitcode.net/dcloud/hello-uni-app-x/</a>； 或者掃描下方二維碼下載打包後的 apk 文件：</p><p><img src="https://oscimg.oschina.net/oscnet/up-832ea9b51d5b53048d6ab133b791cc54ecb.png" alt="uts-01.png" referrerpolicy="no-referrer"></p><p>這個示例裏有幾個例子非常考驗通信性能，除了也內置了 slider-100 外，另一個是「模版-scroll-view 自定義滾動吸頂」，在滾動時實時修改元素 top 值始終為一個固定值，一點都不抖動。</p><p>我們不遊説您使用任何開發技術，但您應該知道它們的原理和差別。</p><p>歡迎指正和討論。</p><h2>橄欖枝</h2><p><a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%AC%A2%E8%BF%8E%E5%AF%B9uni-app%E5%9B%A2%E9%98%9F%E6%84%9F%E5%85%B4%E8%B6%A3%E7%9A%84%E5%90%84%E4%BD%8D%E5%90%8C%E5%AD%A6%EF%BC%8C%E6%8A%95%E7%AE%80%E5%8E%86%E5%88%B0hr2013%40dcloud.io%E3%80%82" target="_blank">歡迎對 uni-app 團隊感興趣的各位同學，投簡歷到 hr2013@dcloud.io。</a></p><p>DCloud 是一個純粹的工程師團隊，公司 90% 的職員都是寫代碼的工程師，無需見客户、寫方案，大部分都有原始股權，歡迎有好奇心、追求卓越的極客加盟。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 06:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/hbcui/blog/10590182</guid>
            <link>https://my.oschina.net/hbcui/blog/10590182</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Pulsar3.0 新功能介紹]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://s2.loli.net/2024/01/03/1QuX3wI6P8hefLa.png" alt="Pulsar3.0-NewFeature.png" referrerpolicy="no-referrer"></p><p>在上一篇文章 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrossoverjie.top%2F2023%2F12%2F24%2Fob%2FPulsar3.0-upgrade%2F" target="_blank">Pulsar3.0 升級指北</a>講了關於升級 Pulsar 集羣的關鍵步驟與災難恢復，本次主要分享一些 <code>Pulsar3.0</code> 的新功能與可能帶來的一些問題。</p><h1>升級後所遇到的問題</h1><p>先來個欲揚先抑，聊聊升級後所碰到的問題吧。</p><p>其中有兩個問題我們感知比較明顯，特別是第一個。</p><h2>topic 被刪除</h2><p>我們在上個月某天凌晨從 <code>2.11.2</code> 升級到 <code>3.0.1</code> 之後，進行了上一篇文章中所提到的功能性測試，發現沒什麼問題，覺得一切都還挺順利的，半個小時搞定後就下班了。</p><p>結果哪知道第二天是被電話叫醒的，有部分業務反饋業務重啓之後就無法連接到 Pulsar 了。</p><p><img src="https://s2.loli.net/2024/01/02/KUAnZ8W65jO3x7d.png" alt="image.png" referrerpolicy="no-referrer"> 最終定位是 topic 被刪除了。</p><blockquote><p>其中的細節還蠻多的，修復過程也是一波三折，後面我會單獨寫一篇文章來詳細梳理這個過程。</p></blockquote><p>在這個 issue 和 PR 中有詳細的描述： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F21653" target="_blank">https://github.com/apache/pulsar/issues/21653</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fpull%2F21704" target="_blank">https://github.com/apache/pulsar/pull/21704</a></p><p>感興趣的朋友也可以先看看。</p><h2>監控指標丟失</h2><p>第二個問題不是那麼嚴重，是升級後發現 bookkeeper 的一些監控指標丟失了，比如這裏的寫入延遲： <img src="https://s2.loli.net/2024/01/02/9c7qs4CX1lejOIn.png" alt="image.png" referrerpolicy="no-referrer"> 我也定位了蠻久，但不管是官方的 docker 鏡像還是源碼編譯都無法復現這個問題。</p><p>最終丟失的指標有這些：</p><ul><li>bookkeeper_server_ADD_ENTRY_REQUEST</li><li>bookkeeper_server_ADD_ENTRY_BLOCKED</li><li>bookkeeper_server_READ_ENTRY_BLOCKED</li><li>bookie_journal_JOURNAL_CB_QUEUE_SIZE</li><li>bookie_read_cache_hits_count</li><li>bookie_read_cache_misses_count</li><li>bookie_DELETED_LEDGER_COUNT</li><li>bookie_MAJOR_COMPACTION_COUNT</li></ul><p>詳細內容可以參考這個 issue： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F21766" target="_blank">https://github.com/apache/pulsar/issues/21766</a></p><h1>新特性</h1><p>講完了遇到的 bug，再來看看帶來的新特性，重點介紹我們用得上的特性。</p><h2>支持低負載均衡</h2><p><img src="https://s2.loli.net/2024/01/02/KVpW4DyNimlMhqH.png" alt="image.png" referrerpolicy="no-referrer"></p><p>當我們升級或者是重啓 broker 的時候，全部重啓成功後其實會發現最後重啓的那個 broker 是沒有流量的。</p><p>這個原理和優化在之前寫過的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrossoverjie.top%2F2023%2F02%2F07%2Fpulsar%2Fpulsar-load-banance%2F%23Pulsar-%25E8%25B4%259F%25E8%25BD%25BD%25E5%259D%2587%25E8%25A1%25A1%25E5%258E%259F%25E7%2590%2586" target="_blank">Pulsar 負載均衡原理及優化</a> 其實有詳細介紹。</p><p>本次 3.0 終於將那個優化發版了，之後只要我們配置 <code>lowerBoundarySheddingEnabled: true</code> 就能開啓這個低負載均衡的一個特性，使得低負載的 broker 依然有流量進入。</p><h2>跳過空洞消息</h2><p><img src="https://s2.loli.net/2024/01/02/nj2IyteVUQ79SBZ.png" alt="image.png" referrerpolicy="no-referrer"> Pulsar 可能會因為消息消費異常導致遊標出現空洞，從而導致磁盤得不到釋放；</p><p>所以我們有一個定時任務，會定期掃描積壓消息的 topic 判斷是否存在空洞消息，如果存在便可以在管理台使用 skipMessage API 跳過空洞消息，從而釋放磁盤。</p><p>但在 3.0 之前這個跳過 API 存在 bug，只要跳過的數量超過 8 時，實際跳過的數量就會小於 8.</p><p>具體 issue 和修復過程在這裏： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F20262" target="_blank">https://github.com/apache/pulsar/issues/20262</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fpull%2F20326" target="_blank">https://github.com/apache/pulsar/pull/20326</a></p><p>總之這個問題在 3.0 之後也是修復了，有類似需求的朋友也可以使用。</p><h2>新的負載均衡器</h2><p>同時也支持了一個新的負載均衡器，解決了以下問題：</p><ul><li>以前的負載均衡大量依賴 zk，當 topic 數量增多時對擴展性帶來問題。 
  <ul><li>新的負載均衡器使用 <code>non-persistent</code> 來存儲負載信息，就不再依賴 zk 。</li></ul></li><li>以前的負載均衡器需要依賴 <code>leader broker</code> 進行重定向到具體的 broker，其實這些重定向並無意義，徒增了系統開銷。 
  <ul><li>新的負載均衡器使用了 SystemTopic 來存放 topic 的所有權信息，這樣每個 broker 都可以拿到數據，從而不再需要從 leader broker 重定向了。</li></ul></li></ul><p>更多完整信息可以參考這個 PIP: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F16691" target="_blank">PIP-192: New Pulsar Broker Load Balancer</a></p><h2>支持大規模延遲消息</h2><p>第二個重大特性是支持大規模延遲消息，相信是有不少企業選擇 Pulsar 也是因為他原生就支持延遲消息。</p><p>我們也是大量在業務中使用延遲消息，以往的延遲消息有着以下一些問題：</p><ul><li>內存開銷過大，延遲消息的索引都是保存在內存中，即便是可以分佈在多個 broker 中分散存儲，但消耗依然較大 
  <ul><li>重點優化了索引的內存佔有量。</li></ul></li><li>重啓 broker 時會消耗大量時候重建索引 
  <ul><li>支持了索引快照，最大限度的降低了構建索引的資源消耗。</li></ul></li></ul><h1>待優化功能</h1><h2>監控面板優化</h2><p>最後即便是升級到了 3.0 依然還有一些待優化的功能，在之前的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrossoverjie.top%2F2023%2F08%2F03%2Fob%2FPulsar-Client%2F" target="_blank">從 Pulsar Client 的原理到它的監控面板</a>中有提到給客户端加了一些監控埋點信息。</p><p>最終使用下來發現還缺一個 ack 耗時的一個面板，其實日常碰到最多的問題就是突然不能消費了（或者消費過慢）。</p><p>這時如果有這樣的耗時面板，首先就可以定位出是否是消費者本身的問題。</p><p><img src="https://s2.loli.net/2024/01/03/YFoy4PfnRbz72qX.png" alt="image.png" referrerpolicy="no-referrer"> 目前還在開發中，大概類似於這樣的數據。</p><h1>總結</h1><p>Pulsar3.0 是 Pulsar 的第一個 LTS 版本，推薦儘快升級可以獲得長期支持。 但只要是軟件就會有 bug，即便是 LTS 版本，所以大家日常使用碰到 Bug 建議多向社區反饋，一起推動 Pulsar 的進步。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 04:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/crossoverjie/blog/10678357</guid>
            <link>https://my.oschina.net/crossoverjie/blog/10678357</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 大模型首次牽手國民級綜藝，崑崙萬維天工 AI 聯合《最強大腦》加速大模型落地]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>1 月 5 日週五晚 21:20，由崑崙萬維「天工 APP」特約贊助的《最強大腦》第 11 季正式播出。</span></span></span></span></span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>這是 AI 大模型技術與國民級綜藝 IP 的首度深度合作</span></span></span></span></strong><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>，在節目中，「天工 APP」將發揮其能搜、能聊、能寫的多項超級 AI 大模型能力，與嘉賓選手深度互動，參與趣味腦力競技環節，從而進一步推動大模型技術的普適應用，降低技術門檻，讓越來越多的用户能夠輕鬆、便捷地擁抱大模型。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-0d6fccfb6752359be7a21bfe88595876a12.png" width="1267" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>作為一檔國內影響力最廣、最具代表性的國民級的大型科學競技綜藝節目，《最強大腦》在過去十年間已成功舉辦了 10 期，在 372 個挑戰項目中</span></span></span></span></span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>，</span></span></span></span></span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>近 600 位中外選手齊聚舞台，參與腦力競技、傳播科學知識，鼓勵越來越多的觀眾們不斷突破能力邊界，開拓大腦潛能。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:justify"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-b1a63ff1d5fe64826bead3eefd0c56b6bad.png" width="1267" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>本次「天工 APP」與《最強大腦》第 11 季的深度合作，既是《最強大腦》在科學科普、賽制創新上的又一次嘗試，</span></span></span></span></span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>也是以「天工 APP」為代表的 AI 大模型技術在用户更多日常使用場景中的推廣與落地。</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img alt="" height="976" src="https://oscimg.oschina.net/oscnet/up-9741a5d12eccfbcf9dc28df09dd2ede734a.png" width="720" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>比如，在節目第一期的「天工開悟」環節中，用户可以通過在「天工 APP」中實時搜索「大位數速算法」，與台上的選手們同步學習運用心算技巧，挑戰最強大腦。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img alt="" height="751" src="https://oscimg.oschina.net/oscnet/up-ea25660c5d5c9745295d24537388f01df14.png" width="661" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>與此同時，「天工 APP」還與《最強大腦》聯合發起了</span></span></span></span></span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>腦力挑戰賽</span></span></span></span></strong><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>，用户可進入「天工 APP」最強大腦專區，通過 15 道邏輯、計算、觀察、記憶、空間、創造題目的作答，分析出用户專屬的「腦力潛能六維圖」，識別個人腦力潛能所在，從而有針對性地開發鍛鍊。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span><span><span><span><span style="color:#222222"><span>用户還可以在「天工 APP」裏為喜歡的選手投票助威，並贏得親臨現場的機會，共同見證本季腦王奪冠時刻。</span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>隨着後續節目的播出，還將有更多來自「天工 APP」的「驚喜彩蛋」，全方位地展現 AI 大模型技術在不同場景中如何為用户學習生活帶來便利，降低技術門檻，推動大模型技術走入千家萬户，讓 AI 觸手可及。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>每週五晚 21:20 鎖定江蘇衞視，崑崙萬維天工 APP 攜手《最強大腦》第 11 季，天賦迴歸，腦力封神。</span></span></span></span></strong></span></span></span></span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 04:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274703</guid>
            <link>https://www.oschina.net/news/274703</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[某中學採購「智能互動宣泄儀」——實則為任天堂 Wii 的套殼]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近，廣州某中學的學生在網上發帖稱，該校採購了「智能互動宣泄儀」幫助學生們釋放壓力，該設備功能特徵包括：人機互動、體感訓練、體能檢測、力學感知、身心平衡訓練、虛擬運動訓練、建立宣泄檔案。</p><p>根據學生在微博上發佈的視頻，所謂「智能互動宣泄儀」<strong>其實是一台任天堂 Wii 遊戲機連接了一個顯示屏</strong>，但其採購價高達 46000 元。而在電商平台上，任天堂 Wii 遊戲機價格為 600 元左右。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1c72c99904de625f4332ee6f95291e7b59c.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-10711ecb9c79de2a4a684bd2258d3c2b699.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ff968abd3c6c2bc39a5823ed41712f0c0ce.png" referrerpolicy="no-referrer"></p><p>參見下圖，這確實是物理意義上的「套殼」：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-58cd5cf8c2ac60c565c31e8513b12e1ec64.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 03:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274693</guid>
            <link>https://www.oschina.net/news/274693</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TIOBE 2023 年度編程語言：C#]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TIOBE&nbsp;宣佈&nbsp;2023 年度編程語言花落&nbsp;C#，這是&nbsp;C# 在 TIOBE 指數歷史上首次榮獲年度編程語言的獎項。</p><p><img height="64" src="https://oscimg.oschina.net/oscnet/up-db2c2ac24b28289dd46cdbf4bea8067aa28.png" width="700" referrerpolicy="no-referrer"></p><p>一直以來，C# 都穩居榜單前十名，去年則成為了年度漲幅最大的語言（+1.43%）。緊隨其後的是 Scratch（+0.83%）和 Fortran（+0.64%）</p><p><span style="color:#000000">TIOBE CEO&nbsp;Paul Jansen 認為，</span>C# 正在追趕四大語言的步伐，蠶食 Java 的市場份額，並在<span style="color:#24292e">Web 應用程序後端和遊戲</span>（得益於 Unity）等領域越來越受歡迎。「C# 可以免費使用，而且發展速度穩定，每次發佈新版本都會使語言更具表現力。C# 將繼續存在，甚至可能很快超過 Java。」</p><p>除此之外，去年的 TIOBE 指數還發生了一些其他的有趣變化。Fortran 和 Kotlin 取代了 R 和 Perl，常駐榜單 Top 20。一個有趣的問題是：2024 年，哪些語言將進入 TIOBE 指數前 20 名？</p><p><span style="color:#000000">Paul 的觀點是：</span>很難預測。2023 年，Julia 曾短暫進入 TIOBE 指數，但未能保持這一位置；要想獲得第二次機會，則需要 Julia 語言和社區的成熟。「我會把賭注押在 Dart（with&nbsp;Flutter）和 TypeScript 上。後者已經在業界得到了廣泛應用，但由於某些原因，它還沒有在 TIOBE 指數中取得突破。讓我們拭目以待 2024 年的發展。」</p><p><strong style="color:#333333">TIOBE 1 月 TOP 20 編程語言</strong></p><p><img height="413" src="https://oscimg.oschina.net/oscnet/up-51cde871f2fcdc7b05035d73cd44695f53c.png" width="500" referrerpolicy="no-referrer"></p><p>Scratch 相較上月上升一位&nbsp;<span style="background-color:#ffffff; color:#000000">(11→10)</span>，進入&nbsp;Top 10 榜單；Assembly language 被擠落，從第 10 位跌至 15。<span style="background-color:#ffffff; color:#000000">其他語言的一些波動還包括：</span></p><ul><li><span style="background-color:#ffffff; color:#333333">Go<span>&nbsp;</span></span><span style="background-color:#ffffff; color:#000000">的排名從 13 又回升至 11</span></li><li><span style="background-color:#ffffff; color:#000000">Delphi/Object Pascal&nbsp;</span><span style="background-color:#ffffff; color:#000000">的排名從 16 升至 13</span></li><li><span style="color:#000000">Swift&nbsp;<span style="background-color:#ffffff">的排名從 </span></span><span style="background-color:#ffffff; color:#000000">17 升至 16</span></li><li><span style="color:#000000">Kotlin&nbsp;<span style="background-color:#ffffff">的排名從 15&nbsp;跌至 17</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Ruby 的排名從 19 升至 18</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Rust 的排名從 18 跌至 19</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">COBOL&nbsp;的排名從 23 升至 20</span></span></li><li><span style="background-color:#ffffff; color:#000000">Fortran、MATLAB 則分別保持第 12、14 位不變；上月榜單中第 20 位的 R 語言，在本月榜單中跌至了第 23 位，與&nbsp;</span><span style="color:#000000"><span style="background-color:#ffffff">COBOL 排名進行了互換。</span></span></li></ul><p><strong style="color:#333333">TOP 10 編程語言 TIOBE 指數走勢（2002-2024）</strong></p><p><img height="222" src="https://oscimg.oschina.net/oscnet/up-dc9e870242c6d049337fb838adea09a3236.png" width="700" referrerpolicy="no-referrer"></p><p><strong style="color:#333333">第 21-50 名編程語言排行</strong></p><p><img height="439" src="https://oscimg.oschina.net/oscnet/up-a98ae6f64844c6dc2d91b93487afbf1725d.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">第 51-100 名如下，由於它們之間的數值差異較小，僅以文本形式列出（按字母排序）：</span></p><blockquote><p>Algol, AutoLISP, Avenue, Bash, bc, Boo, CIL, CL (OS/400), CLIPS, Clojure, CLU, Curl, DiBOL, Erlang, Forth, Hack, Icon, Io, J, J#, JScript, LabVIEW, Ladder Logic, Lingo, LiveCode, M4, Maple, MQL5, NATURAL, Nim, OpenEdge ABL, PL/I, PostScript, PowerShell, Pure Data, Q, Racket, REXX, Ring, RPG, Scheme, Snap!, Solidity, SPARK, SPSS, Squirrel, Stata, Wolfram, Xojo, XQuery</p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">TIOBE 編程社區指數（The TIOBE Programming Community index）是一個衡量編程語言受歡迎程度的指標，該指數每月更新一次。評判的依據來自世界範圍內的工程師、課程和第三方供應商，包括流行的搜索引擎，如 Google、必應、雅虎、維基百科、亞馬遜、YouTube 和百度都被用於指數計算。值得注意的是，TIOBE 指數並不代表編程語言的好壞或編寫代碼的多少。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">該指數可以用來檢查你的編程技能是否還能跟上時代的步伐，或者在開始建立一個新的軟件系統時，基於指數對採用何種編程語言做出決策。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F" target="_blank">TIOBE 指數</a><span style="color:#000000">的定義方式，以及詳細榜單信息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">均可查看官網</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 03:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274691/tiobe-index-202401</guid>
            <link>https://www.oschina.net/news/274691/tiobe-index-202401</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[歡迎 Tianai-Captcha 加入 Dromara 開源社區，可能是開源界最好用的行為驗證碼工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>作者介紹</h2><blockquote><p>95 後大齡程序員，一名野生的民間技術愛好者，15 年學習編程技術，迫於生計於 17 年就職於某電商公司， 在從業生涯中，本項目 2020 年發佈後，後續也是改改停停，自古閒人出金貨，也許有一天筆者自由了，會好好的完善這套框架。</p></blockquote><h2>引言:</h2><blockquote><p>譬如在今之網絡世界，為保障資訊之安全，凡入網之人或事，多須經由驗證之法以證實己身之真實性。是以，驗證碼乃必不可少之一環也。其重要性備矣，具誠信者無不體知。</p><p>朕觀網絡之變幻，驗證碼多以隨機字母構成者為眾所周知。然而，此類驗證碼對於一般用户而言，尤其易於應用。蓋因滑動、點選等高級驗證碼，雖能提供更加友好之體驗，然然不易於普通用户之應用。</p><p>吾觀察於平民百姓，多未涉獵於技術深處，對於複雜之滑動、點選類驗證碼而言，或存不解其所在。且諸多普通用户或使用傳統設備，或因技術限制而難以適用此等新穎驗證碼。是以，此類驗證碼對於普羅百姓而言，未免難以為繼。</p><p>嗟乎！有智者聞我國民之難，乃發明滑動及點選驗證碼以應民需，其善心可嘉。彼將此等驗證碼開源，使廣大百姓得以輕鬆接納，實屬可喜可賀。</p><p>滑動及點選驗證碼之開源，如一泓清泉，滌盪網絡之隱憂。於此，一般百姓不復為驗證碼所困，得以輕鬆、便利之享用。其操作簡便，貼近生活，解民憂而廣受歡迎，實為普及網絡安全之一良策。</p><p>開源此等驗證碼者，其舉措實乃有益於民眾。不僅促進了網絡安全，亦鼓舞了普羅百姓參與其中之熱情。願諸般良好之舉措，皆能為社會大眾所接納，盛行於世。</p></blockquote><hr><h2>關於 TIANAI-CAPTCHA</h2><p><code>tianai-captcha</code>簡稱<code>tac</code>，是一款集成滑動類、點選類的一款行為驗證碼，以使用簡單、安全性強、界面美觀、接入方便而，是為集好看、功能多、安全性強的一款開源行為驗證碼工具。</p><hr><p><img alt="" src="https://files.mdnice.com/user/29321/f7dbe307-c5c2-4ee4-b3ec-1434a22b5b28.jpg" referrerpolicy="no-referrer"></p><p><img alt="" src="https://files.mdnice.com/user/29321/98590d8c-b83d-40d1-a136-028372f94236.jpg" referrerpolicy="no-referrer"></p><h2>在線體驗</h2><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcaptcha.tianai.cloud" target="_blank">http://captcha.tianai.cloud</a></p><h2>使用方式</h2><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fdoc.captcha.tianai.cloud" target="_blank">http://doc.captcha.tianai.cloud</a></p><h2>源碼地址</h2><p><a href="https://gitee.com/dromara/tianai-captcha">https://gitee.com/dromara/tianai-captcha</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdromara%2Ftianai-captcha" target="_blank">https://github.com/dromara/tianai-captcha</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274680</guid>
            <link>https://www.oschina.net/news/274680</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[馬化騰迴應早期微信「偷窺」用户相冊：圖片緩存加速造成的誤會]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>據 CSDN 報道，針對早前有軟件工程師爆料稱包括微信等在內的多款國民級 App 在後台反覆讀取用户相冊一事，1 月 5 日，馬化騰獨家迴應：「應該是 21 年 10 月的事了，圖片緩存加速造成的誤會，後面應該用 iOS 新的解決卡頓的 API 解決了」。並特別表示，「可以幫忙闢謠」。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-61301141026d7bfed6e78fc18961393ff36.png" referrerpolicy="no-referrer"></p><p>事情的前因還要追溯到 2021 年 10 月 8 日，當時蘋果 iOS 15 剛剛推出隱私新特性 「記錄 App 活動」，對所有 App 的隱私讀取行為進行了 7 天的監控，並使用 App Privacy Insights 對記錄進行讀取。 &nbsp;數碼博主、軟件開發工程師 @Hackl0us 發現微信在用户未主動激活 App 的情況下，在後台數次讀取用户相冊，每次讀取時間長達 40 秒，至 1 分鐘不等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5c44695ad62718318a0289820dd5dc8bb89.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274667</guid>
            <link>https://www.oschina.net/news/274667</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ParadeDB —— 基於 Postgres 的 ElasticSearch 替代方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">ParadeDB 是</span>基於 Postgres 構建的開源 ElasticSearch 替代方案<span style="color:#000000">。開發團隊正在構建 ElasticSearch 產品套件的功能，首先是搜索。</span></p><p><span style="color:#000000">ParadeDB 提供所有 Postgres 數據庫中最全面的 Postgres 原生搜索功能。</span></p><ul><li><strong>全文搜索</strong>。使用可配置的分詞器、17 種語言的詞幹以及基於 SQL 的可擴展查詢語言按關鍵字或短語進行搜索。</li><li><strong>相似性搜索</strong>。使用預安裝的 pgvector 擴展和工作流程按語義進行搜索，逐步保持向量同步。</li><li><strong>混合搜索</strong>。通過混合搜索提供更高精確度和召回率的結果，該搜索結合了全文搜索和相似性搜索的優勢。</li><li><strong>BM25 Scoring</strong>。全文搜索結果按 BM25 排序，BM25 是 ElasticSearch 使用的基於術語的排名算法。</li><li><strong>分面搜索</strong>。通過分面搜索存儲和收集搜索結果的統計指標。</li><li><strong>分佈式搜索</strong>。ParadeDB 自動對索引進行分片，使開發人員的搜索速度比單節點 Postgres 快數百倍。</li></ul><p>ParadeDB 的搜索引擎基於 Tantivy 開發，Tantivy 是 Apache Lucene 的基於 Rust 的實現。</p></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/paradedb</guid>
            <link>https://www.oschina.net/p/paradedb</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 輕量級隱私計算任務編排框架 Kuscia]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-kuscia" class="anchor" href="https://gitee.com/secretflow/kuscia#kuscia"></a>Kuscia</h1><p><a href="https://gitee.com/link?target=https%3A%2F%2Fdl.circleci.com%2Fstatus-badge%2Fredirect%2Fgh%2Fsecretflow%2Fkuscia%2Ftree%2Fmain"><img src="https://dl.circleci.com/status-badge/img/gh/secretflow/kuscia/tree/main.svg?style=svg" alt="CircleCI" referrerpolicy="no-referrer"></a></p><p align="center"><a href="https://gitee.com/secretflow/kuscia/blob/main/README.zh-CN.md">簡體中文</a>｜<a href="https://gitee.com/secretflow/kuscia/blob/main/README.md">English</a></p><p>Kuscia（Kubernetes-based Secure Collaborative InfrA）是一款基於 K3s 的輕量級隱私計算任務編排框架，旨在屏蔽異構基礎設施和協議，並提供統一的隱私計算底座。通過 Kuscia：</p><ul><li>你可以快速體驗隱私計算功能。</li><li>你可以獲得完整的隱私計算生產能力。</li><li>你可以與行業內多種隱私計算系統進行互聯互通。</li><li>你可以使用不同的中心化或點對點業務組網模式。</li></ul><p><img src="https://gitee.com/secretflow/kuscia/raw/main/docs/imgs/kuscia_architecture.png" alt="Kuscia" referrerpolicy="no-referrer"></p><h2><a id="user-content-文檔" class="anchor" href="https://gitee.com/secretflow/kuscia#%E6%96%87%E6%A1%A3"></a>文檔</h2><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2F">Kuscia</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Fgetting_started%2Findex.html">準備開始</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Freference%2Findex.html">參考手冊</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Ftutorial%2Findex.html">教程</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Fdevelopment%2Findex.html">開發</a></li></ul><h2><a id="user-content-貢獻代碼" class="anchor" href="https://gitee.com/secretflow/kuscia#%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81"></a>貢獻代碼</h2><p>請查閲 <a href="https://gitee.com/secretflow/kuscia/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></p><h2><a id="user-content-聲明" class="anchor" href="https://gitee.com/secretflow/kuscia#%E5%A3%B0%E6%98%8E"></a>聲明</h2><p>非正式發佈的 Kusica 版本僅用於演示，請勿在生產環境中使用。儘管此版本已涵蓋 Kuscia 的基礎功能，但由於項目存在功能不足和待完善項，可能存在部分安全問題和功能缺陷。因此，我們歡迎你積極提出建議，並期待正式版本的發佈。</p>]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/secretflow/kuscia</guid>
            <link>https://gitee.com/secretflow/kuscia</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 米哈遊大數據雲原生實踐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><em>作者：米哈遊大數據開發</em></p><p>近年來，容器、微服務、Kubernetes 等各項雲原生技術的日漸成熟，越來越多的公司開始選擇擁抱雲原生，並開始將 AI、大數據等類型的企業應用部署運行在雲原生之上。以 Spark 為例，在雲上運行 Spark 可以充分享有公共雲的彈性資源、運維管控和存儲服務等，並且業界也湧現了不少 Spark on Kubernetes 的優秀實踐。</p><p>在剛剛結束的 2023 雲棲大會上，米哈遊數據平台組大數據技術專家杜安明分享了米哈遊大數據架構向雲原生化升級過程中的目標、探索和實踐，以及如何通過以阿里雲容器服務 ACK 為底座的 Spark on K8s 架構，獲得在彈性計算、成本節約以及存算分離方面的價值。</p><h2>背景簡介</h2><p>隨着米哈遊業務的高速發展，大數據離線數據存儲量和計算任務量增長迅速，早期的大數據離線架構已不再滿足新場景和需求。</p><p>為瞭解決原有架構缺乏彈性、運維複雜、資源利用率低等問題，2022 年下半年，我們着手調研將大數據基礎架構雲原生化，並最終在阿里雲上落地了 Spark on K8s + OSS-HDFS 方案，目前在生產環境上已穩定運行了一年左右的時間，並獲得了彈性計算、成本節約以及存算分離這三大收益。</p><p><strong>1. 彈性計算</strong></p><p>由於遊戲業務會進行週期版本更新、開啓活動以及新遊戲的上線等，對離線計算資源的需求與消耗波動巨大，可能是平時水位的幾十上百倍。利用 K8s 集羣天然的彈性能力，將 Spark 計算任務調度到 K8s 上運行，可以比較輕鬆的解決這類場景下資源消耗洪峯問題。</p><p><strong>2. 成本節約</strong></p><p>依託阿里雲容器服務 Kubernetes 版 ACK 集羣自身強大的彈性能力，所有計算資源按量申請、用完釋放，再加上我們對 Spark 組件的定製改造，以及充分利用 ECI Spot 實例，在承載同等計算任務和資源消耗下，成本節約達 50%。</p><p><strong>3. 存算分離</strong></p><p>Spark 運行在 K8s 之上，完全使用 K8s 集羣的計算資源，而訪問的則數據也由 HDFS、OSS 逐步切換到 OSS-HDFS 上，中間 Shuffle 數據的讀寫採用 Celeborn，整套架構實現了計算和存儲的解耦，易於維護和擴展。</p><h2>Spark on K8s&nbsp;架構演進</h2><p>眾所周知，Spark 引擎可以支持並運行在多種資源管理器之上，比如 Yarn、K8s、Mesos 等。在大數據場景下，目前國內大多公司的 Spark 任務還是運行在 Yarn 集羣之上的，Spark 在 2.3 版本首次支持 K8s，並於 2021 年 3 月發佈的 Spark3.1 版本才正式 GA。</p><p>相較於 Yarn，Spark 在 K8s 上起步較晚，儘管在成熟度、穩定性等方面還存在一定的欠缺，但是 Spark on K8s 能夠實現彈性計算以及成本節約等非常突出的收益，所以各大公司也都在不斷進行嘗試和探索，在此過程中，Spark on K8s 的運行架構也在不斷的向前迭代演進。</p><p><img src="https://oscimg.oschina.net/oscnet/up-91f57f93e692da3c3bc6738e3cbe09d8dce.png" alt="" referrerpolicy="no-referrer"></p><h3>1. 在離線混部</h3><p>目前，將 Spark 任務運行在 K8s 上，大多公司採用的方案依舊是在線與離線混合部署的方式。架構設計依據的原理是，不同的業務系統會有不同的業務高峯時間。大數據離線業務系統典型任務高峯期間會是凌晨的&nbsp;0&nbsp;點到 9 點鐘，而像是各種應用微服務、Web 提供的 BI 系統等，常見的業務高峯期是白天時間，在這個時間以外的其它時間中，可以將業務系統的機器 Node 加入到 Spark 所使用的 K8s NameSpace &nbsp;中。如下圖所示，將 Spark 與其他在線應用服務等都部署在一套 K8s 集羣之上。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c37f20f1df91812d5e7c562815e3b9f0ed4.png" alt="" referrerpolicy="no-referrer"></p><p>該架構的優點是可以通過在離線業務的混合部署和錯峯運行，來提升機器資源利用率並降低成本，但是缺點也比較明顯，即架構實施起來複雜，維護成本比較高，而且難以做到嚴格的資源隔離，尤其是網絡層面的隔離，業務之間不可避免的會產生一定的相互影響，此外，我們認為該方式也不符合雲原生的理念和未來發展趨勢。</p><h3>2. Spark&nbsp;on&nbsp;K8s&nbsp;+&nbsp;OSS-HDFS</h3><p>考慮到在離線混合部署的弊端，我們設計採用了一種新的、也更加符合雲原生的實現架構：底層存儲採用 OSS-HDFS(JindoFs)，計算集羣採用阿里雲的容器服務 ACK，Spark 選擇功能相對豐富且比較穩定的 3.2.3 版本。</p><p>OSS-HDFS 完全兼容了 HDFS 協議，除了具備 OSS 無限容量、支持數據冷熱存儲等優點以外，還支持了目錄原子性、毫秒級 rename 操作，非常適用於離線數倉，可以很好的平替現有 HDFS 和 OSS。</p><p>阿里雲 ACK 集羣提供了高性能、可伸縮的容器應用管理服務，可以支持企業級 Kubernetes 容器化應用的生命週期管理，ECS 是大家所熟知的阿里雲服務器，而彈性容器實例 ECI 是一種 Serverless 容器運行服務，可以按量秒級申請與釋放。</p><p>該架構簡單易維護，底層利用 ECI 的彈性能力，Spark 任務可以較為輕鬆的應對高峯流量，將 Spark 的 Executor 調度在 ECI 節點上運行，可最大程度的實現計算任務彈性與最佳的降本效果，整體架構的示意圖如下所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-02cd50d97a62975f921948f5fa16139e6dc.png" alt="" referrerpolicy="no-referrer"></p><h2>雲原生架構設計與實現</h2><h3>1. 基本原理</h3><p>在闡述具體實現之前，先簡要介紹一下 Spark 在 K8s 上運行的基本原理。Pod 在 K8s 中是最小的調度單元，Spark 任務的 Driver 和 Executor 都是一個單獨 Pod，每個 Pod 都分配了唯一的 IP 地址，Pod 可以包含一個或多個 Container，無論是 Driver 還是 Executor 的 JVM 進程，都是在 Container 中進行啓動、運行與銷燬的。</p><p>一個 Spark 任務被提交到 K8s 集羣之後，首先啓動的是 Driver Pod，而後 Driver 會向 Apiserver 按需申請 Executor，並由 Executor 去執行具體的 Task，作業完成之後由 Driver 負責清理所有的 Executor Pod，以下是這幾者關係的簡要示意圖。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f76c245cf83130f4a99cf98056228951683.png" alt="" referrerpolicy="no-referrer"></p><h3>2. 執行流程</h3><p>下圖展示了完整的作業執行流程，用户在完成 Spark 作業開發後，會將任務發佈到調度系統上並進行相關運行參數的配置，調度系統定時將任務提交到自研的 Launcher 中間件，並由中間件來調用 spark-k8s-cli，最終由 Cli 將任務提交至 K8s 集羣上。任務提交成功之後，Spark Driver Pod 最先啓動，並向集羣申請分配 Executor Pod，Executor 在運行具體的 Task 時，會與外部 Hive、Iceberg、OLAP 數據庫、OSS-HDFS 等諸多大數據組件進行數據的訪問與交互，而 Spark Executor 之間的數據 Shuffle 則由 CeleBorn 來實現。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f5d39e0da69d013c767af359682cf71fc2a.png" alt="" referrerpolicy="no-referrer"></p><h3>3. 任務提交</h3><p>關於如何將 Spark 任務提交到 K8s 集羣上，各個公司的做法不盡相同，下面先簡要描述下目前比較常規的做法，然後再介紹目前我們線上所使用的任務提交和管理方式。</p><h4>3.1 使用原生 spark-submit</h4><p>通過 spark-submit 命令直接提交，Spark 原生就支持這種方式，集成起來比較簡單，也符合用户的習慣，但是不方便進行作業狀態跟蹤和管理，無法自動配置 Spark UI 的 Service 和 Ingress，任務結束後也無法自動清理資源等，在生產環境中並不適合。</p><h4>3.2 使用 spark-on-k8s-operator</h4><p>這是目前較常用的一種提交作業方式，K8s 集羣需要事先安裝 spark-operator，客户端通過 kubectl 提交 yaml 文件來運行 Spark 作業。本質上這是對原生方式的擴展，最終提交作業依然是使用 spark-submit 方式，擴展的功能包括：作業管理，Service/Ingress 創建與清理，任務監控，Pod 增強等。此種方式可在生產環境中使用，但與大數據調度平台集成性不太好，對於不熟悉 K8s 的用户來説，使用起來複雜度和上手門檻相對較高。</p><h4>3.3 使用 spark-k8s-cli</h4><p>在生產環境上，我們採用 spark-k8s-cli 的方式進行任務的提交。spark-k8s-cli 本質上是一個可執行的文件，基於阿里雲 emr-spark-ack 提交工具我們進行了重構、功能增強和深度的定製。</p><p>spark-k8s-cli 融合 spark-submit 和 spark-operator 兩種作業提交方式的優點，使得所有作業都能通過 spark-operator 管理，支持運行交互式 spark-shell 和本地依賴的提交，並且在使用方式上與原生 spark-submit 語法完全一致。</p><p>在上線使用初期，我們所有任務的 Spark Submit JVM 進程都啓動在 Gateway Pod 中，在使用一段時間後，發現該方式穩定性不足，一旦 Gateway Pod 異常，其上的所有正在 Spark 任務都將失敗，另外 Spark 任務的日誌輸出也不好管理。鑑於此種情況，我們將 spark-k8s-cli 改成了每個任務使用單獨一個 Submit Pod 的方式，由 Submit Pod 來申請啓動任務的 Driver，Submit Pod 和 Driver Pod 一樣都運行在固定的 ECS 節點之上，Submit Pod 之間完全獨立，任務結束後 Submit Pod 也會自動釋放。spark-k8s-cli 的提交和運行原理如下圖所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-727f4fc057aedcd02fbc83b3b98bce9db35.png" alt="" referrerpolicy="no-referrer"></p><p>關於 spark-k8s-cli，除了上述基本的任務提交以外，我們還做了其他一些增強和定製化的功能。</p><ul><li>支持提交任務到同地域多個不同的 K8s 集羣上，實現集羣之間的負載均衡和故障轉移切換</li><li>實現類似 Yarn 資源不足時的自動排隊等待功能&nbsp;（K8s 如果設置了資源 Quota，當 Quota 達到上限後，任務會直接失敗）</li><li>增加與 K8s 網絡通信等異常處理、創建或啓動失敗重試等，對偶發的集羣抖動、網絡異常進行容錯</li><li>支持按照不同部門或業務線，對大規模補數任務進行限流和管控功能</li><li>內嵌任務提交失敗、容器創建或啓動失敗以及運行超時等告警功能</li></ul><h3>4. 日誌採集與展示</h3><p>K8s 集羣本身並沒有像 Yarn 那樣提供日誌自動聚合和展示的功能，Driver 和 Executor 的日誌收集需要用户自己來完成。目前比較常見的方案是在各個 K8s Node 上部署 Agent，通過 Agent 把日誌採集並落在第三方存儲上，比如 ES、SLS 等，但這些方式對於習慣了在 Yarn 頁面上點擊查看日誌的用户和開發者來説，使用起來很不方便，用户不得不跳轉到第三方系統上撈取查看日誌。</p><p>為實現 K8s Spark 任務日誌的便捷查看，我們對 Spark 代碼進行了改造，使 Driver 和 Executor 日誌最終都輸出到 OSS 上，用户可以在 Spark UI 和 Spark Jobhistory 上，直接點擊查看日誌文件。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0eace11cc08cce9ab78ba861cb398c35717.png" alt="" referrerpolicy="no-referrer"></p><p>上圖所示為日誌的收集和展示原理，Spark 任務在啓動時，Driver 和 Executor 都會首先註冊一個 Shutdown Hook，當任務結束 JVM 退出時，調用 Hook 方法把完整的日誌上傳到 OSS 上。此外，想要完整查看日誌，還需要對 Spark 的 Job History 相關代碼做下改造，需要在 History 頁面顯示 stdout 和 stderr，並在點擊日誌時，從 OSS 上拉取對應 Driver 或 Executor 的日誌文件，最終由瀏覽器渲染查看。另外，對於正在運行中的任務，我們會提供一個 Spark Running Web UI 給用户，任務提交成功後，spark-operator&nbsp;會自動生成的 Service 和 Ingress 供用户查看運行詳情，此時日誌的獲取通過訪問 K8s 的 api 拉取對應 Pod 的運行日誌即可。</p><h3>5. 彈性與降本</h3><p>基於 ACK 集羣提供的彈性伸縮能力，再加上對 ECI 的充分利用，同等規模量級下的 Spark 任務，運行在 K8s 的總成本要明顯低於在 Yarn 固定集羣上，同時也大大提高了資源利用率。</p><p>彈性容器實例 ECI 是一種 Serverless 容器運行服務，ECI 和 ECS 最大的不同就在於 ECI 是按量秒級計費的，申請與釋放速度也是秒級的，所以 ECI 很適合 Spark 這一類負載峯谷明顯的計算場景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-265d37ec5e9ec1a64b70219ca89169e35bc.png" alt="" referrerpolicy="no-referrer"></p><p>上圖示意了 Spark 任務在 ACK 集羣上如何申請和使用 ECI，使用前提是在集羣中安裝 ack-virtual-node 組件，並配置好 Vswitch 等信息，在任務運行時，Executor 被調度到虛擬節點上，並由虛擬節點申請創建和管理 ECI。</p><p>ECI 分為普通實例和搶佔式實例，搶佔式實例是一種低成本競價型實例，默認有 1 小時的保護期，適用於大部分 Spark 批處理場景，超出保護期後，搶佔式實例可能被強制回收。為進一步提升降本效果，充分利用搶佔式實例的價格優勢，我們對 Spark 進行改造，實現了 ECI 實例類型自動轉換的功能。Spark 任務的 Executor Pod 都優先運行在搶佔式 ECI 實例上，當發生庫存不足或其他原因無法申請創建搶佔式實例，則自動切換為使用普通 ECI 實例，保證任務的正常運行。&nbsp;具體實現原理和轉換邏輯如下圖所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-47f719ef69ab5b6992ea95f746548cc8ab4.png" alt="" referrerpolicy="no-referrer"></p><h3>6. Celeborn</h3><p>由於 K8s 節點的磁盤容量很小，而且節點都是用時申請、用完釋放的，無法保存大量的 Spark Shuffle 數據。如果對 Executor Pod 掛載雲盤，掛載盤的大小難以確定，考慮到數據傾斜等因素，磁盤的使用率也會比較低，使用起來比較複雜。此外，雖然 Spark 社區在 3.2 提供了 Reuse PVC 等功能，但是調研下來覺得功能尚不完備且穩定性不足。</p><p>為解決 Spark 在 K8s 上數據 Shuffle 的問題，在充分調研和對比多家開源產品後，最終採用了阿里開源的 Celeborn 方案。Celeborn 是一個獨立的服務，專門用於保存 Spark 的中間 Shuffle 數據，讓 Executor 不再依賴本地盤，該服務 K8s 和 Yarn 均可以使用。Celeborn 採用了 Push Shuffle 的模式，Shuffle 過程為追加寫、順序讀，提升數據讀寫性能和效率。</p><p>基於開源的 Celeborn 項目，我們內部也做了一些數據網絡傳輸方面的功能增強、Metrics 豐富、監控告警完善、Bug 修復等工作，目前已形成了內部穩定版本。</p><p><img src="https://oscimg.oschina.net/oscnet/up-08142d767f6df474b0c291a38b188840ab2.png" alt="" referrerpolicy="no-referrer"></p><h3>7. Kyuubi&nbsp;on&nbsp;K8s</h3><p>Kyuubi 是一個分佈式和多租户的網關，可以為 Spark、Flink 或 Trino 等提供 SQL 等查詢服務。在早期，我們的 Spark Adhoc 查詢是發送到 Kyuubi 上執行的。為瞭解決 Yarn 隊列資源不足，用户的查詢 SQL 無法提交和運行的問題，在 K8s 上我們也支持了 Kyuubi Server 的部署運行，當 Yarn 資源不足時，Spark 查詢自動切換到 K8s 上運行。鑑於 Yarn 集羣規模逐漸縮減，查詢資源無法保證，以及保障相同的用户查詢體驗，目前我們已將所有的 SparkSQL Adhoc 查詢提交到 K8s 上執行。</p><p>為了讓用户的 Adhoc 查詢也能在 K8s 上暢快運行，我們對 Kyuubi 也做了一些源碼改造，包括對 Kyuubi 項目中 docker-image-tool.sh、Deployment.yaml、Dockfile 文件的改寫，重定向 Log 到 OSS 上，Spark Operator 管理支持、權限控制、便捷查看任務運行 UI 等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a97f1245c24b11a2c25c62b1bf824f0c0eb.png" alt="" referrerpolicy="no-referrer"></p><h3>8. K8s&nbsp;Manager</h3><p>在 Spark on K8s 場景下，儘管 K8s 有集羣層面的監控告警，但是還不能完全滿足我們的需求。在生產環境中，我們更加關注的是在集羣上的 Spark 任務、Pod 狀態、資源消耗以及 ECI 等運行情況。利用 K8s 的 Watch 機制，我們實現了自己的監控告警服務 K8s Manager，下圖所示為該服務的示意圖。</p><p><img src="https://oscimg.oschina.net/oscnet/up-530ec8ff85f98c8ff44efed2349011ef832.png" alt="" referrerpolicy="no-referrer"></p><p>K8sManager 是內部實現的一個比較輕量的 Spring Boot 服務，實現的功能就是對各個 K8s 集羣上的 Pod、Quota、Service、ConfigMap、Ingress、Role 等各類資源信息監聽和彙總處理，從而生成自定義的 Metrics 指標，並對指標進行展示和異常告警，其中包括集羣 CPU 與 Memory 總使用量、當前運行的 Spark 任務數、Spark 任務內存資源消耗與運行時長 Top 統計、單日 Spark 任務量彙總、集羣 Pod 總數、Pod 狀態統計、ECI 機器型號與可用區分佈統計、過期資源監控等等，這裏就不一一列舉了。</p><h3>9. 其他工作</h3><h4>9.1 調度任務自動切換</h4><p>在我們的調度系統中，Spark 任務支持配置 Yarn、K8s、Auto 三種執行策略。如果用户任務指明瞭需要運行使用的資源管理器，則任務只會在 Yarn 或 K8s 上運行，若用户選擇了 Auto，則任務具體在哪裏執行，取決於當前 Yarn 隊列的資源使用率，如下圖所示。由於總任務量較大，且 Hive 任務也在不斷遷移至 Spark，目前仍然有部分任務運行在 Yarn 集羣上，但最終的形態所有任務將由 K8s 來託管。</p><p><img src="https://oscimg.oschina.net/oscnet/up-35f4cbad3736b91872ac6f9bd97d486d940.png" alt="" referrerpolicy="no-referrer"></p><h4>9.2 多可用區、多交換機支持</h4><p>Spark 任務運行過程中大量使用 ECI，ECI 創建成功有兩個前提條件: 1、能夠申請到 IP 地址；2、當前可用區有庫存。&nbsp;實際上，單個交換機提供的可用 IP 數量有限，單個可用區擁有的搶佔式實例的總個數也是有限的，因此在實際生產環境中，無論是使用普通 ECI 還是 Spot 類型的 ECI，比較好的實踐方式是配置支持多可用區、多交換機。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f08f0ecc5c0e2ea97499e52e5fd1a5f60c4.png" alt="" referrerpolicy="no-referrer"></p><h4>9.3 成本計算</h4><p>由於在 Spark 任務提交時，都已明確指定了每個 Executor 的 Cpu、Memory 等型號信息，在任務結束 SparkContxt 關閉之前，我們可以從任務的中拿到每個 Executor 的實際運行時長，再結合單價，即可計算出 Spark 任務的大致花費。由於 ECI Spot 實例是隨着市場和庫存量隨時變動的，該方式計算出來的單任務成本是一個上限值，主要用於反映趨勢。</p><h4>9.4 優化 Spark&nbsp;Operator</h4><p>在上線初期任務量較少時，Spark Operator 服務運行良好，但隨着任務不斷增多，Operator 處理各類 Event 事件的速度越來越慢，甚至集羣出現大量的 ConfigMap、Ingress、Service 等任務運行過程中產生的資源無法及時清理導致堆積的情況，新提交 Spark 任務的 Web UI 也無法打開訪問。發現問題後，我們調整了 Operator 的協程數量，並實現對 Pod Event 的批量處理、無關事件的過濾、TTL 刪除等功能，解決了 Spark Operator 性能不足的問題。</p><h4>9.5 升級 Spark&nbsp;K8s&nbsp;Client</h4><p>Spark3.2.2 採用 fabric8(Kubernetes Java Client) 來訪問和操作 K8s 集羣中的資源，默認客户端版本為 5.4.1，在此版本中，當任務結束 Executor 集中釋放時，Driver 會大量發送 Delete Pod 的 Api 請求到 K8s Apiserver 上，對集羣 Apiserver 和 ETCD 造成較大的壓力，Apiserver 的 cpu 會瞬間飆高。</p><p>目前我們的內部 Spark 版本，已將 kubernetes-client 升級到 6.2.0，支持 pod 的批量刪除，解決 Spark 任務集中釋放時，由大量的刪除 Api 請求操作的集羣抖動。</p><h2>問題與解決方案</h2><p>在整個 Spark on K8s 的方案設計以及實施過程中，我們也遇到了各種各樣的問題、瓶頸和挑戰，這裏做下簡單的介紹，並給出我們的解決方案。</p><h3>1.&nbsp;彈性網卡釋放慢</h3><p>彈性網卡釋放速度慢的問題，屬於 ECI 大規模應用場景下的性能瓶頸，該問題會導致交換機上 IP 的劇烈消耗，最終導致 Spark 任務卡住或提交失敗，具體觸發原因如下圖所示。目前阿里雲團隊已通過技術升級改造解決，並大幅提升了釋放速度和整體性能。</p><p><img src="https://oscimg.oschina.net/oscnet/up-24660bc811456fd79a7853a00ff0a09a121.png" alt="" referrerpolicy="no-referrer"></p><h3>2.&nbsp;Watcher 失效</h3><p>Spark 任務在啓動 Driver 時，會創建對 Executor 的事件監聽器，用於實時獲取所有 Executor 的運行狀態，對於一些長時運行的 Spark 任務，這個監聽器往往會由於資源過期、網絡異常等情況而失效，因此在此情況下，需要對 Watcher 進行重置，否則任務可能會跑飛。該問題屬於 Spark 的一個 Bug，當前我們內部版本已修復，並將 PR 提供到了 Spark 社區。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fe6ab9a8837a6d715aa3dbadb128573dc1d.png" alt="" referrerpolicy="no-referrer"></p><h3>3.&nbsp;任務卡死</h3><p>如上圖所示，Driver 通過 List 和 Watch 兩種方式來獲取 Executor 的運行狀況。Watch 採用被動監聽機制，但是由於網絡等問題可能會發生事件漏接收或漏處理，但這種概率比較低。List 採用主動請求的方式，比如每隔 3 分鐘，Driver 可向 Apiserver 請求一次自己任務當前全量 Executor 的信息。</p><p>由於 List 請求任務所有 Pod 信息，當任務較多時，頻繁 List 對 K8s 的 Apiserver 和 ETCD 造成較大壓力，早期我們關閉了定時 List，只使用 Watch。當 Spark 任務運行異常，比如有很多 Executor OOM 了，有一定概率會導致 Driver Watch 的信息錯誤，儘管 Task 還沒有運行完，但是 Driver 卻不再申請 Executor 去執行任務，發生任務卡死。對此我們的解決方案如下:</p><ul><li>在開啓 Watch 機制的同時，也開啓 List 機制，並將 List 時間間隔拉長，設置每 5 分鐘請求一次</li><li>修改 ExecutorPodsPollingSnapshotSource 相關代碼，允許 Apiserver 服務端緩存，從緩存中獲取全量 Pod 信息，降低 List 對集羣的壓力</li></ul><h3>4. Celeborn 讀寫超時、失敗</h3><p>ApacheCeleborn 是阿里開源的一款產品，前身為 RSS(Remote Shuffle Service)。在早期成熟度上還略有欠缺，在對網絡延遲、丟包異常處理等方面處理的不夠完善，導致線上出現一些有大量 Shuffle 數據的 Spark 任務運行時間很長、甚至任務失敗，以下三點是我們針對此問題的解決辦法。</p><ul><li>優化 Celeborn，形成內部版本，完善網絡包傳輸方面的代碼</li><li>調優 Celeborn&nbsp;Master 和 Worker 相關參數，提升 Shuffle 數據的讀寫性能</li><li>升級 ECI 底層鏡像版本，修復 ECI&nbsp;Linux 內核 Bug</li></ul><h3>5. 批量提交任務時，Quota 鎖衝突</h3><p>為了防止資源被無限使用，我們對每個 K8s 集羣都設置了 Quota 上限。在 K8s 中，Quota 也是一種資源，每一個 Pod 的申請與釋放都會修改 Quota 的內容 (Cpu/Memory 值)，當很多任務併發提交時，可能會發生 Quota 鎖衝突，從而影響任務 Driver 的創建，任務啓動失敗。</p><p>應對這種情況導致的任務啓動失敗，我們修改 Spark Driver Pod 的創建邏輯，增加可配置的重試參數，當檢測到 Driver Pod 創建是由於 Quota 鎖衝突引起時，進行重試創建。Executor Pod 的創建也可能會由於 Quota 鎖衝突而失敗，這種情況可以不用處理，Executor 創建失敗 Driver 會自動申請創建新的，相當於是自動重試了。</p><h3>6.&nbsp;批量提交任務時，UnknownHost 報錯</h3><p>當瞬時批量提交大量任務到集羣時，多個 Submit Pod 會同時啓動，並向 Terway 組件申請 IP 同時綁定彈性網卡，存在一定概率出現以下情況，即 Pod 已經啓動了，彈性網卡也綁定成功但是實際並沒有完全就緒，此時該 Pod 的網絡通信功能實際還無法正常使用，任務訪問 Core DNS 時，請求無法發出去，Spark 任務報錯 UnknownHost 並運行失敗。該問題我們通過下面這兩個措施進行規避和解決：</p><ul><li>為每台 ECS 節點，都分配一個 Terway&nbsp;Pod</li><li>開啓 Terway 的緩存功能，提前分配好 IP 和彈性網卡，新 Pod 來的直接從緩存池中獲取，用完之後歸還到緩存池中</li></ul><h3>7. 可用區之間網絡丟包</h3><p>為保障庫存的充足，各 K8s 集羣都配置了多可用區，但跨可用區的網絡通信要比同可用區之間通信的穩定性略差，即可用區之間就存在一定概率的丟包，表現為任務運行時長不穩定。</p><p>對於跨可用區存在網絡丟包的現象，可嘗試將 ECI 的調度策略設定為 VSwitchOrdered，這樣一個任務的所有 Executor 基本都在一個可用區，避免了不同可以區 Executor 之間的通信異常，導致的任務運行時間不穩定的問題。</p><h2>總結與展望</h2><p>最後，非常感謝阿里雲容器、ECI、EMR 等相關團隊的同學，在我們整個技術方案的落地與實際遷移過程中，給予了非常多的寶貴建議和專業的技術支持。</p><p>目前新的雲原生架構已在生產環境上穩定運行了近一年左右的時間，在未來，我們將持續對整體架構進行優化和提升，主要圍繞以下幾個方面:</p><ol><li><p>持續優化雲原生的整體方案，進一步提升系統承載與容災能力</p></li><li><p>雲原生架構升級，更多大數據組件容器化，讓整體架構更加徹底的雲原生化</p></li><li><p>更加細粒度的資源管理和精準的成本控制</p></li></ol></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/10404597</guid>
            <link>https://my.oschina.net/u/3874284/blog/10404597</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微信團隊確認私密朋友圈存在 bug，現已修復]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微信團隊今日上午通過微博迴應了「<strong>私密朋友圈存在 bug</strong>」的問題。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-34320da0579bfc83ad3cb597de2fb3f1a80.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1930378853%2FNAIzytG5Y%23comment" target="_blank">https://weibo.com/1930378853/NAIzytG5Y</a></u></em></p></blockquote><p>從網友的反饋來看，許多微信用户最近在發佈私密朋友圈時，好友會在入口看到提醒朋友圈更新的「小紅點頭像」。但點進去卻發現對方並沒有發佈新內容。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-b0fe2ae650294a4d3684dc3e1ef41cb7cc6.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-30399efe2ea7df75517428697b41ed60bf4.png" referrerpolicy="no-referrer"></p><p><img height="1168" src="https://oscimg.oschina.net/oscnet/up-03c6871c585c1eec034fbf03e988cee454d.png" width="994" referrerpolicy="no-referrer"></p></blockquote><p>根據微信團隊的迴應，「私密朋友圈顯示提醒」的 bug 僅在 1 月 1 日當天出現，並且是極小部分用户受影響。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 06:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274592</guid>
            <link>https://www.oschina.net/news/274592</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源之旅，.NET 流行框架 Furion 2023 年終總結]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一年又一年，已是物是人非</h1><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><img height="383" src="https://oscimg.oschina.net/oscnet/up-2cb38aa868c8eb4fa8ae6cfd1adb53f6921.png" width="900" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>開源之旅，曲折而又意義非凡。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">回想三年前，我初次邁出 Furion 開源項目的步伐，面對着一片質疑和嘲笑的聲音。雖然這些聲音刺痛了我的內心，但我並沒有放棄。我選擇專注於用户需求，持之以恆地改進代碼質量和文檔。艱辛與困難並沒有打敗我，相反，它們讓我變得更堅定，更成熟。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>開源世界從來不是一個人的舞台，它需要眾多開發者和用户的支持和參與。我深知，無論我怎樣努力和完善我的項目，總會有人不喜歡，不認同。</strong>&nbsp;然而，這並不是我成長的障礙，反而是我成長的催化劑。<strong>我逐漸明白，不追求所有人的贊同，而是專注於為那些真正認可和喜歡我的工作的人提供更好的服務，才是更重要的。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">在這段開源之路上，我亦流連於困境和挫折中。<strong>磨難並不使人成長，但它們教會了我成熟和堅韌。我深知，每個人都會有自己的獨特感受和看法，只有接受這個事實，並用成熟的心態去面對，才能不斷髮展自己，走向更高的成就。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">同時，我對國內開源人的不易有着深切的感受。在商業導向的社會中，選擇投身開源事業需要巨大的勇氣和決心。開源項目的作者們需要面對各種挑戰和批評，但正是因為他們對開源事業的執着，社區才得以繁榮。我向每一位國內的開源愛好者致以崇高的敬意，你們是開源事業中不可或缺的一環。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">回首三週年的開源項目，我的內心充滿了感慨。這段經歷錘鍊了我的意志和技術能力，讓我從一個技術懵懂的新手成長為一個在領域中有所建樹的人。雖然這個過程中並非一帆風順，但我感激每一個困難和挑戰，它們讓我更加堅定地走在開源之路上。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>最後，我要衷心感謝所有支持和鼓勵我的人。感謝那些相信我能夠創造出有價值的開源項目的人，感謝那些給予我反饋和建議的人。</strong>&nbsp;同時，我也要向所有國內開源人表達我的敬意和感激之情。正因為有你們的努力和奉獻，才有了開源事業的繁榮和進步。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>願每一個開源愛好者都能堅守初心，用心對待用户需求，不斷提升自己的技術水平。我們的開源項目不僅僅是一個代碼庫，更是我們對技術和自由精神的執着追求。</strong>&nbsp;相信自己，相信開源的力量，讓我們繼續前行，創造出更美好的明天！</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>開源 Furion 本是 ⌈無心之舉⌋，未成想它成為我人生 ⌈志心之源⌋</strong></p><hr><h1>避不開的話題：開源與商業</h1><p><img height="1322" src="https://oscimg.oschina.net/oscnet/up-5ab9cc31a4279de753c445b4e2937ee94af.png" width="1710" referrerpolicy="no-referrer"></p><h2>自身價值</h2><p><span style="background-color:#ffffff; color:#3f3f3f">在面對外界的評價和期待時，我要保持內心的寧靜和堅定。我的價值和能力不應該被別人的意見所影響，而應該建立在我對自己的自信和對用户需求的關注之上。通過堅持初衷和不斷進步，我相信我可以為用户創造出更優秀的產品和服務。</span></p><p><strong><span style="background-color:#ffffff; color:#3f3f3f">知不足而奮進，望遠山而前行。感謝一路同行</span></strong></p><h2>市場選擇</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Furion 於 2020 年 09 月 01 日開源，在質疑和不被看好的環境中逐漸成長起來。<strong>與其説它的流行歸結於自身的努力，不如説是市場的選擇。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>任何東西都有其生命週期，適者生存。如果它哪天不 「適」 了，自然會消失；如果它一直 「適」 着，也就會一直存在着。</strong><span>&nbsp;</span>主要還是看它的特性有沒有持續生命力。如果大家一直反饋，一直使用，那麼它也將一直維護，一直更新，一直存在。</p><h2>開源商業</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">開源很困難，盈利也很困難，將開源與盈利結合更是難上加難。這個難題不在於技術，而在於思維的轉變。困難的不是堅持，而是放下那種深藏心底的幫助他人並受到感激的情感。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>很多開源項目之所以未能實現商業化，主要原因是創作者對自己產品的價值持懷疑態度，他們質疑別人是否真的願意為自己的產品付費。同時，他們在為自己的產品收費時會感到羞愧和愧疚。這也是許多開源項目無法實現商業化的主要原因。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">孔子雖滿懷救國救民的良策，但深知天道不可違、人力有限，故一生顛簸坎坷。若想成就一番大事，不僅需要實力和經濟支持，還要有不被現實所裹挾的決心。我們必須時刻保持警惕，不斷磨礪自己，才能迎接未來的挑戰。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>世俗的成功給人自由，你可以不屠龍，但是不能不磨劍。</strong></p><h2>命運之門</h2><p>網絡中流行的一句熱詞是"命運的齒輪開始轉動"，它源於日本動漫《命運石之門》。<strong>這句話傳達了我們每一次的選擇都有可能引發巨大的命運變化，從而導致完全不同的人生軌跡</strong>。</p><p><strong>此刻，命運的齒輪再次緩慢地轉動......</strong></p><p><img height="450" src="https://oscimg.oschina.net/oscnet/up-c7eee0cfc9b9a6acaf5859d843f608145ed.png" width="720" referrerpolicy="no-referrer"></p><hr><h1>發展事記</h1><h2>2020 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232020-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2020 年 06 月 22 日</strong>，<code>Fur</code><span>&nbsp;</span>在 Gitee 平台創建空倉庫<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/commit/25de190d83027fab58e72714ca7c044206607127" target="_blank">25de190</a>。</li><li><strong>2020 年 09 月 01 日</strong>，<code>Fur</code><span>&nbsp;</span>正式寫下第一行代碼。</li><li><strong>2020 年 10 月 01 日</strong>，<strong><code>Fur</code><span>&nbsp;</span>獲得 Gitee 最有價值開源項目<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fimg%2Fgvp.png" target="_blank">GVP</a><span>&nbsp;</span>證書</strong>。</li><li><strong>2020 年 10 月 22 日</strong>，<code>Fur</code><span>&nbsp;</span>在 Gitee 平台獲得 1000 stars.</li><li><strong>2020 年 11 月 11 日</strong>，<code>Fur</code><span>&nbsp;</span>單身節當天發佈了<span>&nbsp;</span><code>1.0.0</code><span>&nbsp;</span>正式版。</li><li><strong>2020 年 11 月 18 日</strong>，<strong><code>Fur</code><span>&nbsp;</span>改名為<span>&nbsp;</span><code>Furion</code></strong>。<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/commit/a24acd44a70bac94d2af8ab290197478aa10ef51" target="_blank">a24acd4</a><span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/commit/97011efab563d88b3d369d4a6a8c9e7ac324123f" target="_blank">97011ef</a></li><li><strong>2020 年 11 月 23 日</strong>，<code>Furion</code><span>&nbsp;</span>Logo 由之前的<span>&nbsp;</span><code>奶牛</code><span>&nbsp;</span>更換為<span>&nbsp;</span><code>袋鼠</code>。</li><li><strong>2020 年 12 月 22 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 2000 stars。</li></ul><h2>2021 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232021-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2021 年 03 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>捐贈項目到<span>&nbsp;</span><a href="https://gitee.com/dotnetchina" target="_blank">dotNET China</a><span>&nbsp;</span>組織。</li><li><strong>2021 年 03 月 05 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 3000 stars。</li><li><strong>2021 年 04 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>所在羣<span>&nbsp;</span><code>dotNET China</code><span>&nbsp;</span>突破 5000 人。</li><li><strong>2021 年 04 月 06 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 4000 stars。</li><li><strong>2021 年 04 月 19 日</strong>，<code>Furion</code><span>&nbsp;</span>正式發佈<span>&nbsp;</span><code>2.0.0</code><span>&nbsp;</span>版本，並支持控制枱應用開發。</li><li><strong>2021 年 04 月 29 日</strong>，<code>Furion</code><span>&nbsp;</span>所在羣<span>&nbsp;</span><code>dotNET China</code><span>&nbsp;</span>突破 6000 人。</li><li><strong>2021 年 05 月 13 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 5000 stars。</li><li><strong>2021 年 06 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>所在羣<span>&nbsp;</span><code>dotNET China</code><span>&nbsp;</span>突破 7000 人。</li><li><strong>2021 年 06 月 22 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 6000 stars。</li><li><strong>2021 年 07 月 04 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>登頂 Gitee 平台<span>&nbsp;</span><code>C#</code><span>&nbsp;</span>語言板塊第一名。</strong></li><li><strong>2021 年 07 月 16 日</strong>，<code>Furion</code><span>&nbsp;</span>採用<span>&nbsp;</span><code>百小僧</code><span>&nbsp;</span>頭像作為<span>&nbsp;</span><code>Logo</code>。</li><li><strong>2021 年 07 月 20 日</strong>，<code>Furion</code><span>&nbsp;</span>將<span>&nbsp;</span><code>Apache 2.0</code><span>&nbsp;</span>開源協議修改為<span>&nbsp;</span><code>MulanPSL-2.0</code><span>&nbsp;</span>（木蘭寬鬆許可證）</li><li><strong>2021 年 07 月 27 日</strong>，<code>Furion</code><span>&nbsp;</span>正式支持全平台、<code>.NET</code><span>&nbsp;</span>全平台項目開發。</li><li><strong>2021 年 08 月 11 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>加入<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fportal.mulanos.cn%2F" target="_blank">木蘭開源社區</a><span>&nbsp;</span>重點孵化。</strong></li><li><strong>2021 年 08 月 21 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>100 萬</code><span>&nbsp;</span>下載量。</strong></li><li><strong>2021 年 08 月 30 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 7000 stars。</li><li><strong>2021 年 09 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>誕生一週年。</li><li><strong>2021 年 11 月 09 日</strong>，<code>Furion</code><span>&nbsp;</span>正式發佈<span>&nbsp;</span><code>3.0.0</code><span>&nbsp;</span>版本，全新的<span>&nbsp;</span><code>.NET6</code><span>&nbsp;</span>架構。</li><li><strong>2021 年 11 月 22 日</strong>，<code>Furion</code><span>&nbsp;</span>迎來了第一個贊助商。</li></ul><h2>2022 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232022-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2022 年 05 月 20 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 8000 Stars。</li><li><strong>2022 年 05 月 28 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>200 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2022 年 06 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>有了自己的入口函數<span>&nbsp;</span><code>Serve.Run()</code><span>&nbsp;</span>和錯誤頁。</li><li><strong>2022 年 06 月 20 日</strong>，<code>Furion</code><span>&nbsp;</span>項目貢獻者突破 200 人。</li><li><strong>2022 年 07 月 25 日</strong>，<code>Furion</code><span>&nbsp;</span>正式發佈<span>&nbsp;</span><code>4.0.0</code><span>&nbsp;</span>版本，徹底實現大一統（<code>.NET5</code>-<code>.NET N</code>）都可以升級。</li><li><strong>2022 年 08 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>將<span>&nbsp;</span><code>MulanPSL-2.0</code><span>&nbsp;</span>開源協議修改為<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/blob/v4/LICENSE" target="_blank">MIT</a>。</li><li><strong>2022 年 08 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>300 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2022 年 09 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>誕生兩週年。</li><li><strong>2022 年 09 月 18 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>解散<span>&nbsp;</span><code>QQ</code><span>&nbsp;</span>羣，迴歸最初的開源協作模式，<a href="https://gitee.com/dotnetchina/Furion/issues/I5RWYL" target="_blank">瞭解更多</a></strong>。</li><li><strong>2022 年 10 月 29 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>400 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2022 年 11 月 08 日</strong>，<code>Furion</code><span>&nbsp;</span>正式適配<span>&nbsp;</span><code>.NET7</code><span>&nbsp;</span>架構。</li><li><strong>2022 年 11 月 24 日</strong>，<code>Furion</code><span>&nbsp;</span>發佈了全新的分佈式定時任務模塊<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Sundial" target="_blank">Sundial</a>。</li><li><strong>2022 年 12 月 07 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>500 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2022 年 12 月 29 日</strong>，<code>Furion</code><span>&nbsp;</span>獲得開源雲聯盟優秀開源項目獎項：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2zW-WnBbzs8rOdQ8AfwVag" target="_blank">查看獲獎</a>。</li></ul><h2>2023 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232023-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2023 年 02 月 04 日</strong>，<code>Furion</code><span>&nbsp;</span>獲得《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkaiyuanshe.feishu.cn%2Fwiki%2FwikcnnJ8b90pOoDRFzXngfRslkd" target="_blank">2022 年中國開源年度報告</a>》<span>&nbsp;</span><code>Gitee</code><span>&nbsp;</span>指數<span>&nbsp;</span><code>Top 10</code><span>&nbsp;</span>項目：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkaiyuanshe.feishu.cn%2Fwiki%2FwikcnnJ8b90pOoDRFzXngfRslkd" target="_blank">查看報告</a>。</li><li><strong>2023 年 02 月 06 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>600 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2023 年 03 月 15 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>700 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2023 年 04 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 9000 Stars。</li><li><strong>2023 年 04 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>800 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2023 年 06 月 07 日</strong>，<code>Furion</code><span>&nbsp;</span>正式開通微信公眾號<span>&nbsp;</span><code>Furion</code>。</li><li><strong>2023 年 06 月 08 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>成功購買下<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffurion.net%2F" target="_blank">furion.net</a><span>&nbsp;</span>域名：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4OTI0ODg3MA%3D%3D%26mid%3D2247483653%26idx%3D1%26sn%3D36d046a0369beb24a60aa9bd0499ea2e%26chksm%3Dcfef8c0cf898051a6637c1bb2643249b0b3d08017cc5ea5d0901a3d3fd127a1cc3fad1e06ace%26token%3D162131388%26lang%3Dzh_CN%23rd" target="_blank">查看官宣</a>。</strong></li><li><strong>2023 年 06 月 14 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>900 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2023 年 08 月 22 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>1000 萬</code><span>&nbsp;</span>下載量。</strong></li><li><strong>2023 年 09 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>誕生三週年。</li><li><strong>2023 年 09 月 05 日</strong>，<code>Furion</code><span>&nbsp;</span>申請從<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fportal.mulanos.cn%2F" target="_blank">木蘭開源社區</a><span>&nbsp;</span>畢業。</li><li><strong>2023 年 10 月 19 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>1100 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2023 年 11 月 03 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>推出官方<span>&nbsp;</span><code>VIP</code><span>&nbsp;</span>服務。</strong></li><li><strong>2023 年 11 月 15 日</strong>，<code>Furion</code><span>&nbsp;</span>正式適配<span>&nbsp;</span><code>.NET8</code><span>&nbsp;</span>架構。</li><li><strong>2023 年 11 月 17 日</strong>，<code>Furion</code><span>&nbsp;</span>通過<span>&nbsp;</span><a href="https://www.oschina.net/news/267981/furion-4-9-1-7-released" target="_blank">⌈中國電子技術標準化研究院⌋</a><span>&nbsp;</span>成熟度評估。</li><li><strong>2023 年 11 月 26 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>推出文檔付費瀏覽服務。</strong></li><li><strong>2023 年 12 月 13 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>上線新官網<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffurion.net%2F" target="_blank">furion.net</a>。</strong></li><li><strong>2023 年 12 月 19 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>1200 萬</code><span>&nbsp;</span>下載量。</li><li><strong>2023 年 12 月 28 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台獲得 10000 Stars。</li></ul><h2>2024 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232024-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2024 年 ?? 月 ?? 日</strong>，<code>Furion</code><span>&nbsp;</span>正式發佈<span>&nbsp;</span><code>5.0.0</code><span>&nbsp;</span>版本，一次徹底的革新。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 04:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274711/furion-2023</guid>
            <link>https://www.oschina.net/news/274711/furion-2023</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME 支持 RDP 協議，可通過圖形界面進行遠程登錄]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FGNOME-RDP-Remote-Login" target="_blank">根據 Phoronix 的報道</a></u>，GNOME 桌面環境<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.gnome.org%2FGNOME%2Fgnome-remote-desktop%2F-%2Fmerge_requests%2F139" target="_blank">最近合併的 PR</a></u>&nbsp;實現了對遠程桌面協議 (RDP) 支持的重要部分。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f8bcbc9835268555ad0adf16dcf7ea5a915.png" referrerpolicy="no-referrer"></p><p>正如 PR 所述，這項功能用於提供圖形化遠程登錄支持。該 PR 自 2022 年 8 月以來一直處於開啓狀態，直到 2024 年 1 月才被合併。該功能的實現依賴於 GNOME Session、GDM 和 GNOME Settings Daemon 等方面的變化，這些變化在過去一年內已經合併。這意味着在&nbsp;3 月發佈的 GNOME 46 版本中，這項功能將會正式上線。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-066aac4e76b43f37a7382fdcadcbfa32300.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c76d08a2fa57ee735cdd5820ccbdc09d20f.png" referrerpolicy="no-referrer"></p><p>這個功能的具體實現細節包括對標準守護進程的抽象，以及實現了兩種新的行為。第一種是作為系統服務運行，它會在新的 RDP 連接時請求 GDM 啓動一個無 header GDM 登錄會話。第二種是在無 header 用户會話中運行（又名 daemon-handover），它會告訴系統服務使用 handover dbus 接口啓動交接過程。這兩種行為的實現使得 GNOME 桌面環境可以處理圖形遠程登錄的需求。</p><p>此外，這項功能還支持 Wayland。這意味着它不僅可以在 X11 上運行，還可以在 Wayland 上運行。這對於用户來説是一個好消息，因為他們可以在不同的顯示服務器上使用這項功能。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 03:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274575/gnome-rdp-remote-login</guid>
            <link>https://www.oschina.net/news/274575/gnome-rdp-remote-login</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[用 Socket.D 替代原生 WebSocket 做前端開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start">socket.d.js 是基於 websocket 包裝的 socket.d 協議的實現。就是用 ws 傳輸數據，但功能更強大。</p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&quot;system-ui&quot;,&quot;Segoe UI&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"><tbody><tr><th>功能</th><th>原生 websocket</th><th>socket.d</th><th>説明</th></tr></tbody><tbody><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">listen</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">監聽消息</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">send</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">發消息</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndRequest</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">無</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">發消息並接收一個響應（類似於 http）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndSubscribe</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">無</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">發消息並接收多個響應（也叫訂閲）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">event(or path)</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">無</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消息有事件或路徑（可對消息，進行業務路由）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">meta(or header)</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">無</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消息有元信息或頭信息（可為數據，標註業務語義）</td></tr></tbody></table><p style="color:#24292e; text-align:start">下面感受下開發方面的差異！</p><h3>1、客户端示例代碼</h3><p style="color:#24292e; text-align:start">使用時，可以根據自己的業務對原生接口包裝，進一步簡化使用。</p><pre><code class="language-html language-xml"><span>&lt;<span style="color:#e45649">script</span><span style="color:#986801">src</span>=<span style="color:#50a14f">"js/socket.d.js"</span>&gt;</span><span>&lt;/<span style="color:#e45649">script</span>&gt;</span><span>&lt;<span style="color:#e45649">script</span>&gt;
<span style="color:#a626a4">async</span><span style="color:#a626a4">function</span><span style="color:#4078f2">init</span>(){
    <em>//構建事件監聽</em><span style="color:#a626a4">const</span> eventListener = <span style="color:#a626a4">await</span><span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">newEventListener</span>().<span style="color:#4078f2">doOnMessage</span>(<span>(<span>s,m</span>)=&gt;</span>{
       <em>//監聽所有消息（可能不需要）</em>
    }).<span style="color:#4078f2">doOn</span>(<span style="color:#50a14f">"/im/user.upline"</span>, <span>(<span>s,m</span>)=&gt;</span>{ <em>//事件的應用</em><em>//監聽用户上線</em><span style="color:#a626a4">let</span> user_id = m.<span style="color:#4078f2">meta</span>(<span style="color:#50a14f">"user_id"</span>);
    }).<span style="color:#4078f2">doOn</span>(<span style="color:#50a14f">"/im/user.downline"</span>, <span>(<span>s,m</span>)=&gt;</span>{
        <em>//監聽用户下線</em><span style="color:#a626a4">let</span> user_id = m.<span style="color:#4078f2">meta</span>(<span style="color:#50a14f">"user_id"</span>); <em>//元信息的應用</em>
    });

    <em>//創建單例</em><span style="color:#986801">window</span>.<span>clientSession</span> = <span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">createClient</span>(<span style="color:#50a14f">"sd:</span></span><span style="color:#50a14f">ws://127.0.0.1:8602/?u=a&amp;p=2"</span>)</code><code class="language-html language-xml"><span>            .<span style="color:#4078f2">listen</span>(eventListener)
            .<span style="color:#4078f2">open</span>();
}

<span style="color:#a626a4">function</span><span style="color:#4078f2">join</span>(){
    clientSession.<span style="color:#4078f2">sendAndRequest</span>(<span style="color:#50a14f">"/user/join"</span>, <span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">newEntity</span>()).<span style="color:#4078f2">thenReply</span>(r-&gt;{
        <em>//加入成功</em>
    });
}

<span style="color:#4078f2">init</span>();
</span><span>&lt;/<span style="color:#e45649">script</span>&gt;</span></code></pre><p style="color:#24292e; text-align:start">Socket.D 有三個發消息的接口：</p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&quot;system-ui&quot;,&quot;Segoe UI&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"><tbody><tr><th>接口</th><th>説明</th></tr></tbody><tbody><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">send</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">像 websocket。多了事件與元信息屬性</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndRequest</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">像 http</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndSubscribe</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">像 reactive stream 。多了事件與元信息屬性</td></tr></tbody></table><h3>2、服務端示例代碼（用 java 演示）</h3><pre><code class="language-java"><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">Demo</span> {
    <span style="color:#a626a4">public</span><span style="color:#a626a4">static</span><span style="color:#a626a4">void</span><span style="color:#4078f2">main</span><span>(String[] args)</span><span style="color:#a626a4">throws</span> Throwable {
        List&lt;Session&gt; userSessions = <span style="color:#a626a4">new</span><span style="color:#c18401">ArrayList</span>&lt;Session&gt;();
        <em>//創建監聽器</em><span style="color:#986801">Listener</span><span style="color:#986801">listener</span><span>=</span><span style="color:#a626a4">new</span><span style="color:#c18401">EventListener</span>().doOnOpen(s-&gt;{
            <em>//鑑權</em><span style="color:#a626a4">if</span>(<span style="color:#50a14f">"a"</span>.equals(s.param(<span style="color:#50a14f">"u"</span>)) == <span style="color:#0184bb">false</span>){
                s.close();
            }<span style="color:#a626a4">else</span>{
                <em>//加入用户表</em>
                s.attrPut(<span style="color:#50a14f">"user_id"</span>, s.param(<span style="color:#50a14f">"u"</span>));
                userSessions.add(s);
            }
        }).doOn(<span style="color:#50a14f">"/user/join"</span>, (s,m)-&gt;{
            <span style="color:#a626a4">if</span>(m.isRequest()){
                s.reply(m, <span style="color:#a626a4">new</span><span style="color:#c18401">StringEntity</span>());
            }
            
            <span style="color:#a626a4">for</span>(Session s1: userSessions){
                <em>//告訴所有用户，有人上線</em>
                s1.send(<span style="color:#50a14f">"/im/user.upline"</span>, <span style="color:#a626a4">new</span><span style="color:#c18401">StringEntity</span>().metaPut(<span style="color:#50a14f">"user_id"</span>), s.attr(<span style="color:#50a14f">"userId"</span>));
            }
        });
        
        <em>//啓動服務</em>
        SocketD.createServer(<span style="color:#50a14f">"sd:ws"</span>)
                .config(c -&gt; c.port(<span style="color:#986801">8602</span>))
                .listen(listener)
                .start();
    }
}
</code></pre><h3>3、Socket.D 是什麼東東？</h3><p style="color:#24292e; text-align:start">Socket.D 是一個基於「事件」和「語義消息」「流」的網絡應用層協議（聽起來好像很 ao 口）。支持 tcp, udp, ws, kcp 傳輸。有用户説，「Socket.D 之於 Socket，尤如 Vue 之於 Js、Mvc 之於 Http」。</p><p style="color:#24292e; text-align:start">協議之所有強大，有三個關鍵基礎因素：</p><ul><li>事件</li><li>語義消息</li><li>流</li></ul><p style="color:#24292e; text-align:start">它的幀碼結構：</p><pre><code class="language-css"><span style="color:#986801">[len:int]</span><span style="color:#986801">[flag:int]</span><span style="color:#986801">[sid:str(&lt;64)]</span><span style="color:#986801">[\n]</span><span style="color:#986801">[event:str(&lt;512)]</span><span style="color:#986801">[\n]</span><span style="color:#986801">[metaString:str(&lt;4k)]</span><span style="color:#986801">[\n]</span><span style="color:#986801">[data:byte(&lt;16m)]</span></code></pre><p style="color:#24292e; text-align:start">因為是應用層協議，所以可以建立在任意傳輸層協議之上。比如 websocket。</p><h3>4、開源倉庫</h3><ul><li>github:<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnoear%2Fsocket.d" target="_blank">https://github.com/noear/socket.d</a></li><li>gitee:<span>&nbsp;</span><a href="https://gitee.com/noear/socket.d">https://gitee.com/noear/socket.d</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 02:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274678</guid>
            <link>https://www.oschina.net/news/274678</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
