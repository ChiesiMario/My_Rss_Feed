<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 14 Nov 2023 05:45:27 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[【店滴雲】兼容手機端再深化更新，手機端體驗更好]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:center">【店滴雲】兼容手機端再深化更新，手機端體驗更好</p><p><span style="background-color:#ffffff; color:#40485b">&nbsp; &nbsp; &nbsp; &nbsp; 店滴雲，讓經營場所，更智能。圍繞茶室、酒店、健身房、公寓、出租房等經營性場所進行物聯網改造。同時支持多種物聯網通信協議，開放智能門鎖，智能開關，智能手環的 sdk 供開發者使用。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fcd18117e2cca5d8d73ac6371a8729a52fa.png" referrerpolicy="no-referrer"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;作為國內一流的業務管理 saas 系統店滴雲，我們秉承客户至上，體驗至上的原則，每天堅持多次更新代碼。我們包含了商機端，用户端 ，管理端。管理端可以滿足多商户，集團化的業務，在權限管理方便更是適應了當前 vue 為主流的大前端開發環境。我們來看下我們的手機端 ：</p><p><img alt="" height="667" src="https://oscimg.oschina.net/oscnet/up-b76c0d4b1c10df35d7699c51e889dd2c8ee.jpg" width="374" referrerpolicy="no-referrer"><img alt="" height="660" src="https://oscimg.oschina.net/oscnet/up-841ec370324656e9f997b3160181571817d.jpg" width="367" referrerpolicy="no-referrer"><img alt="" height="665" src="https://oscimg.oschina.net/oscnet/up-13d3083cc95756bfa6bca8cb6ce89c3019c.jpg" width="368" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 14 Nov 2023 04:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266386/ddiot-updated</guid>
            <link>https://www.oschina.net/news/266386/ddiot-updated</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | 阿里雲嚴重故障；開源軟件 OBS Studio 被賣 43 元；蘋果迴應 8GB 近似於其它系統的 16GB.....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2023.11.06-2023.11.12]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 03:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093948&#38;idx=1&#38;sn=706606fa2f64f52b06fc8b4cee57747b&#38;chksm=880c4c2fbf7bc5397b5a8f8cf06c3879715d17a1760fae142652daea51d149d354fc1dcbc442&#38;token=293181062&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093948&#38;idx=1&#38;sn=706606fa2f64f52b06fc8b4cee57747b&#38;chksm=880c4c2fbf7bc5397b5a8f8cf06c3879715d17a1760fae142652daea51d149d354fc1dcbc442&#38;token=293181062&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[Google Play 收緊 Android 應用開發者規則]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fensuring-high-quality-apps-on-google-play.html" target="_blank">宣佈</a>收緊在 Google Play 商店發佈應用程序的 Android 開發者規則，引入了一些新的政策和計劃，以提高整個平台的應用程序質量。</span></p><p><span style="color:#000000">公告指出，現在將要求擁有新創建的個人 Play Console 帳户的開發者在發佈前，至少 2 周內與至少 20 人一起測試他們的應用程序。他們認為，此舉將幫助開發人員提前發現問題獲得用户反饋，預計該</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgoogleplay%2Fandroid-developer%2Fanswer%2F14151465" target="_blank">要求</a><span style="color:#000000">將在「未來幾天」出現在 Play 管理中心。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">與此同時，</span>Google Play 的<span style="background-color:#ffffff">審核團隊還將加強對應用程序的審核，預計整體應用程序審核時間表不會發生重大變化。</span></span><span style="color:#000000"><span style="background-color:#ffffff">但該公司</span>警告稱，隨着這些變化的推出，少數應用程序的審批時間可能會加長，<span style="background-color:#ffffff">例如為兒童設計的應用程序或請求某些設備權限的應用程序。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「</span>我們的全球審核團隊現在花更多時間評估新應用程序，以確保它們提供有價值的用户體驗，不會通過應用程序或場外活動欺騙或欺詐用户，並遵守我們的政策。<span style="background-color:#ffffff">」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">此前，谷歌方面曾宣佈所有開發者在 Google Play 上發佈應用程序前必須滿足一系列擴展的驗證要求，以打擊惡意軟件行為。時至今日，該公司還</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgoogleplay%2Fandroid-developer%2Fanswer%2F14177239" target="_blank"><span style="color:#2980b9">分享</span></a><span style="color:#000000">了一些內容，指導幫助擁有現有帳户的開發者如何完成這些驗證，以符合更新後的&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgoogleplay%2Fandroid-developer%2Fanswer%2F10788890" target="_blank">Play 管理中心要求政策</a><span style="color:#000000">。</span></p><p><span style="color:#000000">開發者將可以自行選擇完成賬户驗證的截止日期。截止日期以先到先得的方式提供，因此官方建議用户儘早進行選擇，以確保能在合適的時間內完成驗證。如果開發者沒有在 2024 年 2 月 29 日之前選擇截止日期，平台將自動為其指定一個截止日期。</span></p><p><span style="color:#000000"><img alt="" height="237" src="https://oscimg.oschina.net/oscnet/up-bdd9ea4f2ac3077b8a399d99314c569aae1.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">另一方面，公告表示，為了繼續為用户提供優質內容，回報開發者在質量方面的投資，該公司<span style="background-color:#ffffff">已經開始：</span></span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">向用户提供有關應用程序是否在其設備（包括手機、大屏幕和可穿戴設備）上運行不佳的信息</span></li><li><span style="color:#000000">呈現更多高質量的本地和區域內容</span></li></ul><p><span style="color:#000000">並計劃將從 2024 年開始添加一個標識官方應用程序的徽章標識，以幫助用户找到所需的應用程序。&nbsp;</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fensuring-high-quality-apps-on-google-play.html" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266381/google-play-tightens-up-rules-android-app-developers</guid>
            <link>https://www.oschina.net/news/266381/google-play-tightens-up-rules-android-app-developers</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[李開復旗下 AI 公司「零一萬物」開源的 Yi 大模型被指抄襲]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>「</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.01.ai%2F">零一萬物</a><span>」是創新工場董事長兼 CEO 李開復於今年創辦的 AI 大模型創業公司。上週該公司<u><a href="https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm">宣佈</a></u></span><strong>推出&nbsp;Yi-34B 和&nbsp;Yi-6B 兩個開源大模型。</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-4ab5886e43554fd3233305e7c8264217507.png" referrerpolicy="no-referrer"></p><p>在公開的報道中，該公司稱 Yi 系列大模型擁有全球大模型中最長的上下文窗口。其中 Yi-34B 在 Hugging Face 英文測試榜單中位列第一，在 C-Eval 中文能力排行榜中超越所有開源模型。</p><p>不過在&nbsp;Yi-34B 的 Hugging Face 主頁上，有人指出<strong> Yi 完全使用了 Llama 的架構</strong>——前者只是對後者的兩個張量 (Tensor) 名稱進行了修改，具體為 input_layernorm 和 post_attention_layernorm。</p><blockquote><p>Llama 全稱為 "Large Language Model Meta AI"，是 Meta 創建的大語言模型。今年 7 月，<u><a href="https://www.oschina.net/news/249944/meta-llama-2">Meta 發佈了 Llama 2</a></u>，宣佈完全開源，並可免費商用。</p><p><img src="https://static.oschina.net/uploads/space/2023/0719/103048_jW9B_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1114/111349_Novu_2720166.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B%2Fdiscussions%2F11" target="_blank">https://huggingface.co/01-ai/Yi-34B/discussions/11</a></u></em></p><p>AI 領域知名專家賈揚清昨晚也在個人朋友圈點評了此事——不過並沒有指名道姓：</p><p><img src="https://static.oschina.net/uploads/space/2023/1114/111004_dOrQ_2720166.png" referrerpolicy="no-referrer"></p><blockquote><p>賈揚清是開源深度學習框架&nbsp;<span>Caffe 創始人、TensorFlow 作者之一、也是 PyTorch 1.0 的共同創始人。</span></p><p>今年 3 月，賈揚清從阿里離職後聯合創立了一家新的 AI 公司 Lepton AI，旨在建立高效的 AI 應用平台。</p><p>Lepton AI 總部位於美國加利福尼亞州帕洛阿託，官網宣稱可通過 Lepton AI 在幾分鐘內高效、大規模地運行 AI 應用。相比大模型，賈揚清團隊更偏重 AI 能力的開發。</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 03:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266377</guid>
            <link>https://www.oschina.net/news/266377</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[指針沒用好，一行代碼讓公司損失 6000 萬美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1990 年 1 月 15 日，AT&amp;T 的新澤西運營中心檢測到大範圍的系統故障，網絡顯示屏上出現了大量紅色警告。</p><p>儘管試圖排除故障，但網絡故障仍持續了 9 個小時，導致呼叫連接故障率達到 50%。</p><p><strong>AT&amp;T 因此損失了 6000 多萬美元，6 萬多名美國人的電話完全無法接通</strong>。</p><p>此外，500 個航班延誤，8.5 萬人受到影響。</p><p>按理説，AT&amp;T 的長途網絡是高效率的典範，它利用先進的電子交換機和信號系統處理了全國大部分的電話。該系統通常能在幾秒鐘內完成電話路由選擇。</p><p>然而，就在這一天，從紐約的一個交換機開始，整個網絡出現了故障。這是由於最近一次更新中的一個軟件錯誤造成的，該錯誤影響了網絡中的 114 個交換機。當紐約的交換機復位併發出信號時，這個錯誤引發了多米諾骨牌效應，導致大範圍的網絡中斷。</p><p><strong>有趣的是，這個軟件並沒有經過測試。由於代碼改動較小，因此按照管理層的要求繞過了測試</strong>。</p><h3>問題所在</h3><p>追根溯源，原因在於網絡交換機實施的軟件更新中出現了編碼錯誤。</p><p>該錯誤發生在一個 C 語言程序中，涉及嵌套條件語句中一個錯位的中斷語句，導致數據覆蓋和系統重置。</p><p>偽代碼</p><pre><code>1  while (ring receive buffer not empty 
          and side buffer not empty):

2    Initialize pointer to first message in side buffer
     or ring receive buffer

3    get copy of buffer

4    switch (message):

5       case (incoming_message):

6             if (sending switch is out of service):

7                 if (ring write buffer is empty):

8                     send "in service" to status map

9                 else:

10                    break // The error was here!

                  END IF

11           process incoming message, set up pointers to
             optional parameters

12           break
       END SWITCH


13   do optional parameter work</code></pre><h3>問題分析</h3><ul><li>如果環寫入緩衝區不是空的，那麼第 7 行的 `if` 語句就會被跳過，取而代之的是第 10 行的中斷語句。</li><li>然而，為了使程序正常運行，本應執行第 11 行。</li><li>當中斷語句被執行，而不是處理傳入的信息併為可選參數設置指針時，數據（本應保留的指針）就會被覆蓋</li><li>糾錯軟件識別出數據被覆蓋，並啓動關閉開關進行重置。由於網絡中的所有交換機都使用了這種有缺陷的軟件，導致了連鎖重置反應，最終癱瘓了整個網絡系統，使問題變得更加複雜。</li></ul><p>儘管進行了嚴格的測試，網絡的設計也非常靈活，但一行代碼還是導致了半個國家的主要通信線路癱瘓。</p><h3><strong>修復</strong></h3><p>工程師們花了 9 個小時才使 AT&amp;T 的系統完全恢復正常。他們主要是通過將交換機回滾到之前的代碼工作版本來實現的。</p><p>實際上，軟件工程師花了兩週時間進行嚴格的代碼閲讀、測試和複製，才真正弄清了錯誤所在。</p><h3><strong>結論</strong></h3><p>對於 AT&amp;T 來説，不幸的是，這還不是他們 90 年代最大的系統崩潰。在這十年的後期，他們還遇到了更多的問題。</p><p>今天的公司擁有更好的流程，但即便如此，還是會有漏洞漏網。谷歌撰寫了一篇關於網站可靠性工程 20 年的精彩回顧文章，其中對 2016 年 YouTube 的首次全球故障進行了反思。</p><p>對於公司來説，故障的規模是巨大的，每次故障都會給我們帶來教訓。然而，對於大多數公司來説，故障歸根結底是人為錯誤和流程漏洞造成的。</p><p>原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fengineercodex.substack.com%2Fp%2Fhow-one-line-of-code-caused-a-60" target="_blank">https://engineercodex.substack.com/p/how-one-line-of-code-caused-a-60</a><br> 轉自：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jdon.com%2F69737.html" target="_blank">https://www.jdon.com/69737.htm</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 03:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266368/one-line-of-code-caused-a-60</guid>
            <link>https://www.oschina.net/news/266368/one-line-of-code-caused-a-60</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[遊戲黨福音！MakerFrame SIG 跨平台遊戲引擎上線]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px"><span><span style="color:#000000">近日，經 openKylin 社區技術委員會審議通過，</span><strong><span style="color:#000000">鷹歌框架引擎技術小組—MakerFrame SIG</span></strong><span style="color:#000000">正式成立。</span></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">MakerFrame SIG 由</span><strong><span style="color:#000000">社區愛好者劉帥</span></strong><span style="color:#000000">發起成立，負責為 openKylin 社區開發簡單高效的遊戲框架引擎，致力於讓專業人士和非專業人士都來開發跨平台的遊戲和應用，大力促進 openKylin 社區遊戲生態推廣。</span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">01</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 目標</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">MakerFrame（鷹歌框架引擎）作為默認組件集成至 openKylin 社區版本中，讓社區愛好者基於遊戲引擎快捷的開發各種遊戲，拓展社區遊戲生態。</span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">02</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 職責</span></strong></span></p><ul><li><span><span style="color:#000000">MakerFrame 遊戲框架的開發維護和各平台適配；</span></span></li><li><span><span style="color:#000000">負責解答使用和開發過程中的技術問題。</span></span></li></ul><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">03</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 現階段成果</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#0052ff">1、完成框架引擎的各平台適配。</span></strong></span></p><div><p style="text-align:center"><img alt="" height="746" src="https://oscimg.oschina.net/oscnet/up-df30540c26560597e288fdc15418de64b32.png" width="1366" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#000000">目前，MakerFrame 遊戲框架已在 openKylin 社區開源，項目地址如下：</span></strong></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span><span style="color:#0052ff">https://gitee.com/openkylin/maker-frame</span></span></p><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#0052ff">2、完成《俠道仙緣》遊戲的開發和各平台適配。</span></strong></span></p><div><p style="text-align:center"><img alt="" height="745" src="https://oscimg.oschina.net/oscnet/up-c7c3e0bed2a046e5195847baed2814b8100.png" width="436" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="margin-left:0; margin-right:0"><span><strong><span style="color:#000000">目前，MakerFrame 框架引擎和《俠道仙緣》遊戲已上架至 openKylin 軟件商店，感興趣的小夥伴趕快下載體驗吧~</span></strong></span></p><p style="margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">04</span></strong></span></em><span><strong><span style="color:#0b43d1">歡迎加入 SIG</span></strong></span></p><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">歡迎所有對 openKylin 社區遊戲開發感興趣的社區愛好者加入我們！</span></span></p><ul><li><span><span style="color:#000000">郵件列表：</span></span></li><li><span><span style="color:#0052ff">markerframe@lists.openkylin.top</span></span></li><li><span><span style="color:#000000">SIG 主頁：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/MakerFrame</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266366</guid>
            <link>https://www.oschina.net/news/266366</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[信通院牽頭的服務器無感知（Serverless）國際標準在 ITU 成功立項]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">國際電信聯盟第十三研究組（簡稱 ITU-T SG13）於 2023 年 10 月 23 日-11 月 3 日在瑞士日內瓦召開全體會議，來自世界各國的百餘名代表參加會議。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">會上，由中國信息通信研究院（簡稱「中國信通院」）牽頭提出的 ITU-T Y.FaaS-reqts「Cloud computing - Functional requirements of function as a service（雲計算-函數即服務功能要求）」國際標準成功立項，並計劃於 2025 年正式發佈。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">本國際標準依託中國信通院牽頭制定的行業標準 YD/T 3764.9-2021《雲計算服務客户信任體系能力要求，第 9 部分：函數即服務》提出。本標準計劃給出函數即服務（FaaS）的清晰定義，界定 FaaS 與服務器無感知（Serverless）計算、雲計算之間的關係，梳理 FaaS 與周邊生態的交互關係，並詳細列出 FaaS 的功能要求，同時將通過典型場景下 FaaS 的應用案例輔助驗證本標準的適用性與準確性。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">FaaS 是 Serverless 計算最典型的形態，Serverless 體現了將基礎設施資源抽象成按需使用的服務，用户只需關注應用邏輯，而無需管理複雜的基礎設施運維工作的設計模式，被視作雲計算的下一步。中國信通院在此領域深耕多年，目前已建立國內十分完善的 Serverless 標準與評估體系，涵蓋 Serverless 計算、Serverless 工具、泛 Serverless 化服務等多個維度。未來，中國信通院將針對 Serverless 性能基準、Serverless BaaS 服務、典型 Serverless 應用場景解決方案等領域進一步開展深入研究。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266363</guid>
            <link>https://www.oschina.net/news/266363</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英偉達發佈 AI 芯片 H200]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>英偉達昨晚正式發佈了 AI 芯片 H100 GPU 的後續產品<strong> HGX H200 GPU</strong>，可大幅提高大語言模型的能力。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b02e195462bf252f5b2f437a4a1ecdeca2d.png" referrerpolicy="no-referrer"></p><p>據悉，HGX H200 GPU 基於英偉達的「Hopper」架構，相比前代產品內存帶寬增加了 1.4 倍，內存容量增加了 1.8 倍。H200 GPU 使用了 HBM3e 內存的芯片，能夠以每秒 4.8 TB 的速度提供 141GB 的內存。</p><p>英偉達表示，H200 更大、更快的內存可加快生成式人工智能和大語言模型的速度，與 H100 GPU 相比，H200 在處理 Llama2 等大語言模型時可將推理速度提高 2 倍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b6cc928aec01bd10e6b92f2644ee04f7881.png" referrerpolicy="no-referrer"></p><p>H200 還與已經支持 H100 的系統兼容。英偉達表示，客户在添加 H200 時不需要做任何改動。亞馬遜、谷歌、微軟和甲骨文的雲計算部門將在明年率先使用到新的 GPU。</p><p>預計 H200 將於 2024 年第二季度上市，屆時將與 AMD 的 MI300X GPU 展開競爭。與 H200 相似，AMD 的新芯片相比前代產品擁有更多內存，這對運行大型語言模型的推理計算有幫助。</p><p>據美國金融機構 Raymond James 透露，H100 芯片的成本僅為 3320 美元，但英偉達對其客户的批量價格卻高達 2.5 萬至 4 萬美元。這使得 H100 的利潤率可能高達 1000%，成為有史以來最賺錢的芯片之一。</p><p>在訓練大型語言模型時，通常需要數千個 H100 集羣協同工作，因此科技巨頭、初創公司和政府機構都在爭奪英偉達有限的芯片供應。</p><p>由於對其產品的需求看似無窮無盡，英偉達今年的銷售額大幅增長，股價上漲了 230%，市值突破了 1.2 萬億美元大關。截至週一收盤，該股收漲 0.59%，報 486.2 美元。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266361</guid>
            <link>https://www.oschina.net/news/266361</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TGFX —— 跨平台 2D 繪圖引擎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TGFX (Tencent Graphics)&nbsp;是一個輕量級 2D 圖形庫，設計用於渲染文本、幾何圖形和圖像。它提供高性能的 API，可在各種 GPU 硬件和軟件平台上運行，包括 iOS、Android、macOS、Windows、Linux、Web 等。</p><p>TGFX 最初是作為 PAG 項目的核心組件創建的，從 4.0 版開始成為 libpag 庫的默認圖形引擎。它的主要目標是在保持更小二進制文件大小的同時，為 Skia 圖形庫提供令人信服的替代方案。隨着時間的推移，它已被許多其他產品採用，如 Hippy、騰訊文檔和各種視頻編輯應用程序。</p><p style="margin-left:0px; margin-right:0px"><strong style="color:#1a1a1a">包體優化</strong></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>TGFX 最終以 400K 左右的大小覆蓋了 Skia 近 2M 包體的絕大部分功能。核心優化策略主要有兩點：</span></p><p><img height="231" src="https://static.oschina.net/uploads/space/2023/1108/105501_oKgt_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start"><strong style="color:#1a1a1a">調度優化</strong></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span>TGFX 並不只是做 Skia 的簡化，還把一些在業務上調用起來非常複雜的通用性流程進行了抽</span><span>象封裝</span><span>：</span></p><p><img alt="" height="102" src="https://static.oschina.net/uploads/space/2023/1108/105526_HLW4_4252687.png" width="700" referrerpolicy="no-referrer"></p><p>在性能和架構方面，還做了這些額外的優化：</p><ul><li>默認開啓了 HardwareBuffer 的支持，來全面加速紋理的提交，包括 Android 端。</li><li>暴露了引擎內部 Path 對應的 GPU 高速緩存，避免矢量繪製充分進行三角剖分操作。</li><li>GPU 對象支持在任意線程釋放，等關聯的上下文激活時才清理，避免隨機 Crash 問題。</li><li>約束圖片解碼完會盡可能只緩存 GPU 的紋理部分，理論上全局可以降低一半的內存佔用。</li><li>將絕大部分緩存都交給了上層業務精確管理，避免隨機繪製的緩存持續佔用額外的內存。</li><li>在全平台都實現了默認字體的讀取能力，包括瀏覽器，避免下載上百兆 CJK 字體的壓力。</li><li>增加了對各種硬解視頻幀格式的直接繪製能力，可以一次性上屏無需通過 CPU 轉換格式。</li><li>放棄了 SKSL 的統一 Shader 語言設計，更加符合原生接口調用習慣，既節省了包體，也減少了 GPU Program 的編譯耗時。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tgfx</guid>
            <link>https://www.oschina.net/p/tgfx</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 面向 AI 的下一代富文本編輯器 AiEditor]]>
            </title>
            <description>
                <![CDATA[<p><img src="https://gitee.com/aieditor-team/aieditor/raw/main/docs/assets/image/screenshot.png" alt="screenshot.png" referrerpolicy="no-referrer"></p><h1><a id="user-content-aieditor" class="anchor" href="https://gitee.com/aieditor-team/aieditor#aieditor"></a>AiEditor</h1><p>關於 AiEditor</p><blockquote><p>AiEditor 是一個面向 AI 的下一代富文本編輯器，她基於 Web Component，因此支持 Layui、Vue、React、Angular 等幾乎任何前端框架。她適配了 PC Web 端和手機端，並提供了，亮色，和 暗色，兩個主題。除此之外，她還提供了靈活的配置，開發者可以方便的使用其開發任何文字編輯的應用。</p></blockquote><h2><a id="user-content-在線演示" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%9C%A8%E7%BA%BF%E6%BC%94%E7%A4%BA"></a>在線演示</h2><p><a href="https://gitee.com/link?target=http%3A%2F%2Faieditor.jpress.cn">http://aieditor.jpress.cn</a></p><h2><a id="user-content-已完善" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%B7%B2%E5%AE%8C%E5%96%84"></a>已完善</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 基礎：標題、正文、字體、字號、加粗、斜體、下劃線、刪除線、鏈接、行內代碼、上標、下標、分割線、引用、打印</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 增強：撤回、重做、格式刷、橡皮擦、待辦事項、字體顏色、背景顏色、Emoji 表情、對齊方式、行高、有（無）序列表、段落縮進、強制換行</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 附件：支持圖片、視頻、文件功能，支持選擇上傳、粘貼上傳、拖拽上傳、支持拖動調整大小...</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 代碼：行內代碼、代碼塊、代碼語言選擇</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 表格：左增右增、左減右減、上增下增、上減下減、合併單元格、解除合併</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> A I：AI 續寫、AI 優化、AI 校對、AI 翻譯、自定義 AI 菜單及其 Prompts</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 更多：亮色主題、暗色主題、手機版適配、全屏編輯、@某某某（提及）...</li></ul><h2><a id="user-content-待完善計劃中" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E5%BE%85%E5%AE%8C%E5%96%84%E8%AE%A1%E5%88%92%E4%B8%AD"></a>待完善（計劃中...）</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 國際化</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 團隊協作</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 自動化測試</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 插入圖片</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 圖生圖（AI 圖片優化）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> AI 一鍵排版</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 進一步強化增貼功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 上傳視頻自動獲取縮略圖</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> WORD 導入、導出</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> PDF 導出、PDF 預覽</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 類騰訊文檔 UI 風格</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 類 Notion 拖拽功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 更多的大模型對接：文心一言、ChatGPT</li></ul><h2><a id="user-content-構建運行" class="anchor" href="https://gitee.com/aieditor-team/aieditor#%E6%9E%84%E5%BB%BA%E8%BF%90%E8%A1%8C"></a>構建&amp;運行</h2><p><strong>構建</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://gitee.com/aieditor-team/aieditor.git</span><span id="LC2" class="line"></span><span id="LC3" class="line"><span class="nb">cd </span>aieditor</span><span id="LC4" class="line"></span><span id="LC5" class="line"><span class="c"># 安裝依賴</span></span><span id="LC6" class="line">npm <span class="nb">install</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>運行</strong></p><p>修改 <code>demos/main.ts</code> 下的內容為：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">點擊輸入內容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一個面向 AI 的開源富文本編輯器。輸入，空格 + "/" 可以快速彈出 AI 菜單哦 </span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">ai</span><span class="p">:</span><span class="p">{</span></span><span id="LC6" class="line"><span class="na">model</span><span class="p">:</span><span class="p">{</span></span><span id="LC7" class="line"><span class="na">xinghuo</span><span class="p">:</span><span class="p">{</span></span><span id="LC8" class="line"><span class="na">appId</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC9" class="line"><span class="na">apiKey</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC10" class="line"><span class="na">apiSecret</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="p">}</span></span><span id="LC13" class="line"><span class="p">}</span></span><span id="LC14" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>或者直接移除 AI 的配置，如下所示（移除後，則不能使用 AI 功能）：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">點擊輸入內容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一個面向 AI 的開源富文本編輯器。輸入，空格 + "/" 可以快速彈出 AI 菜單哦 </span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>然後再命令行下執行：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm run dev</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-ai-功能配置" class="anchor" href="https://gitee.com/aieditor-team/aieditor#ai-%E5%8A%9F%E8%83%BD%E9%85%8D%E7%BD%AE"></a>AI 功能配置</h2><ul><li>1、去科大訊飛註冊賬號 <a href="https://gitee.com/link?target=https%3A%2F%2Fxinghuo.xfyun.cn">https://xinghuo.xfyun.cn</a></li><li>2、在科大訊飛服務管理中（<a href="https://gitee.com/link?target=https%3A%2F%2Fconsole.xfyun.cn%2Fservices%2Fbm2">https://console.xfyun.cn/services/bm2</a> ） 獲取 appId、apiKey、apiSecret。</li><li>3、在配置中添加科大訊飛星火大模型配置</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">new</span><span class="nx">AiEditor</span><span class="p">({</span></span><span id="LC2" class="line"><span class="na">element</span><span class="p">:</span><span class="dl">"</span><span class="s2">#aiEditor</span><span class="dl">"</span><span class="p">,</span></span><span id="LC3" class="line"><span class="na">placeholder</span><span class="p">:</span><span class="dl">"</span><span class="s2">點擊輸入內容...</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">content</span><span class="p">:</span><span class="dl">'</span><span class="s1">AiEditor 是一個面向 AI 的開源富文本編輯器。</span><span class="dl">'</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">ai</span><span class="p">:</span><span class="p">{</span></span><span id="LC6" class="line"><span class="na">model</span><span class="p">:</span><span class="p">{</span></span><span id="LC7" class="line"><span class="na">xinghuo</span><span class="p">:</span><span class="p">{</span></span><span id="LC8" class="line"><span class="na">appId</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC9" class="line"><span class="na">apiKey</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC10" class="line"><span class="na">apiSecret</span><span class="p">:</span><span class="dl">"</span><span class="s2">***</span><span class="dl">"</span><span class="p">,</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="p">}</span></span><span id="LC13" class="line"><span class="p">}</span></span><span id="LC14" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/aieditor-team/aieditor</guid>
            <link>https://gitee.com/aieditor-team/aieditor</link>
        </item>
        <item>
            <title>
                <![CDATA[Linux 基金會創建高性能軟件基金會 (HPSF)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linux 基金會<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-announces-intent-to-form-high-performance-software-foundation-hpsf" target="_blank">宣佈</a>，他們正在組建<strong>高性能軟件基金會</strong>(High Performance Software Foundation, HPSF)，以幫助推進高性能計算 (HPC) 核心開源項目的發展，包括 Spack, Kokkos, AMReX, VTK-m, HPCToolkit, E4S, Charliecloud, WarpX，以及其他面向 HPC 的項目。</p><p>部分國家實驗室，知名科技公司如英特爾、英偉達和其他利益相關者已經參與其中（暫未發現 AMD 參與）。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1d45e285c4d0bd80c3829c1c4df3a8b4906.png" referrerpolicy="no-referrer"></p><p>HPSF 已制定了明確的目標：</p><ul><li>成為高性能軟件生態系統中關鍵項目的中立家園；</li><li>在開源社區和組織中推廣 HPSF 項目的使用；</li><li>提供透明的治理模式，讓政府、行業和學術界的利益相關者共同管理生態系統；</li><li>提供清晰的路徑來孵化和啓動有前景的新項目；</li><li>通過提供 CI 和 turn-key 構建，確保 HPC 軟件可訪問且可靠；</li><li>通過與 CNCF 和 OpenSSF 合作，確保 HPC 軟件安全併為上雲做好準備；</li><li>贊助活動和培訓，為 HPSF 生態系統中的軟件培養一支多元化、熟練的勞動力隊伍。</li></ul><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-announces-intent-to-form-high-performance-software-foundation-hpsf" target="_blank">更多內容查看官方新聞稿</a></u>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266356/lf-high-performance-software-foundation-hpsf</guid>
            <link>https://www.oschina.net/news/266356/lf-high-performance-software-foundation-hpsf</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | GPU 架構與計算入門指南]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><img src="https://oscimg.oschina.net/oscnet/86cf28df-e180-4a38-9a4b-768dae1aa92b.jpg" referrerpolicy="no-referrer"></p><p><span><span>大多數工程師對 CPU 和順序編程都十分熟悉，這是因為自從他們開始編寫 CPU 代碼以來，就與之密切接觸。然而，對於 GPU 的內部工作原理及其獨特之處，他們的瞭解則相對較少。過去十年，由於 GPU 在深度學習中得到廣泛應用而變得極為重要。因此，每位軟件工程師都有必要了解其基本工作原理。本文旨在為讀者提供這方面的背景知識。</span></span></p><p>&nbsp;</p><p><span><span>本文作者為軟件工程師 Abhinav Upadhyay，他在《大規模並行處理器編程》第四版（Hwu 等）的基礎上編寫了本文大部分內容，其中介紹了包括 GPU 體系結構和執行模型等內容。當然，文中 GPU 編程的基本概念和方法同樣適用於其他供應商的產品。</span></span></p><p>&nbsp;</p><p style="text-align:left"><span><span>（本文由 OneFlow 編譯發佈，轉載請聯繫授權。</span><span>原文：</span>https://codeconfessions.substack.com/p/gpu-computing）</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>作者 | Abhinav Upadhyay</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>OneFlow 編譯</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span><span style="color:#3f3f3f"><strong><span>翻譯｜宛子琳、楊婷</span></strong></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><strong><span><span><strong><span style="color:#f6ab00">1</span></strong></span></span></strong></span></span></p><span id="OSC_h2_1"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><strong><span><span style="color:#1e2380"><strong><span style="color:#1e2380">比較 CPU 與 GPU</span></strong></span></span></strong></span></span></p><p><span style="color:#3f3f3f"><span><strong><span><span>&nbsp;</span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">首先，我們會比較 CPU 和 GPU，這能幫助我們更好地瞭解 GPU 的發展狀況，但這應該作為一個獨立的主題，因為我們難以在一節中涵蓋其所有的內容。因此，我們將着重介紹一些關鍵點。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">CPU 和 GPU 的主要區別在於它們的設計目標。CPU 的設計初衷是執行順序指令[1]。一直以來，為提高順序執行性能，CPU 設計中引入了許多功能。其重點在於減少指令執行時延，使 CPU 能夠儘可能快地執行一系列指令。這些功能包括指令流水線、亂序執行、預測執行和多級緩存等（此處僅列舉部分）。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">而 GPU 則專為大規模並行和高吞吐量而設計，但這種設計導致了中等至高程度的指令時延。這一設計方向受其在視頻遊戲、圖形處理、數值計算以及現如今的深度學習中的廣泛應用所影響，所有這些應用都需要以極高的速度執行大量線性代數和數值計算，因此人們傾注了大量精力以提升這些設備的吞吐量。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我們來思考一個具體的例子：由於指令時延較低，CPU 在執行兩個數字相加的操作時比 GPU 更快。在按順序執行多個這樣的計算時，CPU 能夠比 GPU 更快地完成。然而，當需要進行數百萬甚至數十億次這樣的計算時，由於 GPU 具有強大的大規模並行能力，它將比 CPU 更快地完成這些計算任務。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我們可以通過具體數據來進行説明。硬件在數值計算方面的性能以每秒浮點運算次數（FLOPS）來衡量。NVIDIA 的 Ampere A100 在 32 位精度下的吞吐量為 19.5 TFLOPS。相比之下，Intel 的 24 核處理器在 32 位精度下的吞吐量僅為 0.66 TFLOPS（2021 年）。同時，隨時間推移，GPU 與 CPU 在吞吐量性能上的差距逐年擴大。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">下圖對 CPU 和 GPU 的架構進行了比較。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><img height="auto" src="https://oscimg.oschina.net/oscnet/bdd6d31c-c5ec-4301-a326-11b2bdc1264b.png" width="auto" referrerpolicy="no-referrer"><span style="color:#888888"><em><span style="color:#888888">圖 1：CPU 與 GPU 的芯片設計對比。引自《CUDA C++編程指南》（NVIDIA）</span></em></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">如圖所示，CPU 在芯片領域中主要用於降低指令時延的功能，例如大型緩存、較少的算術邏輯單元（ALU）和更多的控制單元。與此相比，GPU 則利用大量的 ALU 來最大化計算能力和吞吐量，只使用極小的芯片面積用於緩存和控制單元，這些元件主要用於減少 CPU 時延。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><strong><span>時延容忍度<strong style="color:#3f3f3f"><span>和</span></strong>高吞吐量</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">或許你會好奇，GPU 如何能夠容忍高時延並同時提供高性能呢？GPU 擁有大量線程和強大的計算能力，使這一點成為可能。即使單個指令具有高延遲，GPU 也會有效地調度線程運行，以便它們在任意時間點都能利用計算能力。例如，當某些線程正在等待指令結果時，GPU 將切換到運行其他非等待線程。這可確保 GPU 上的計算單元在所有時間點都以其最大容量運行，從而提供高吞吐量。稍後當我們討論 kernel 如何在 GPU 上運行時，我們將對此有更清晰的瞭解。</span></span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><span><strong><span style="color:#f6ab00">2</span></strong></span></span></span></span></p><span id="OSC_h2_2"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><span style="color:#1e2380"><strong><span style="color:#1e2380">GPU 架構</span></strong></span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">我們已經瞭解到 GPU 有利於實現高吞吐量，但它們是通過怎樣的架構來實現這一目標的呢？本節將對此展開探討。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><strong><span>GPU 的計算架構</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">GPU 由一系列流式多處理器（SM）組成，其中每個 SM 又由多個流式處理器、核心或線程組成。例如，NVIDIA H100 GPU 具有 132 個 SM，每個 SM 擁有 64 個核心，總計核心高達 8448 個。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">每個 SM 都擁有一定數量的片上內存（on-chip memory），通常稱為共享內存或臨時存儲器，這些共享內存被所有的核心所共享。同樣，SM 上的控制單元資源也被所有的核心所共享。此外，每個 SM 都配備了基於硬件的線程調度器，用於執行線程。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">除此之外，每個 SM 還配備了幾個功能單元或其他加速計算單元，例如張量核心（tensor core）或光線追蹤單元（ray tracing unit），用於滿足 GPU 所處理的工作負載的特定計算需求。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><span><img height="auto" src="https://oscimg.oschina.net/oscnet/c25e87f8-efab-4e56-b903-e657474e8026.png" width="auto" referrerpolicy="no-referrer"></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="color:#494949; text-align:center"><span style="color:#3f3f3f"><span><span><span style="color:#888888"><em><span style="color:#888888">圖 2：GPU 的計算架構</span></em></span></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">接下來，讓我們深入剖析 GPU 內存並瞭解其中的細節。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span>GPU 的內存架構</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span>&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 具有多層不同類型的內存，每一層都有其特定用途。下圖顯示了 GPU 中一個 SM 的內存層次結構。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/94a4fe5d-80dd-4461-b5af-4587fd012f16.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 3：基於康奈爾大學虛擬工作坊（Virtual Workshop）的 GPU 內存架構</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">讓我們對其進行剖析：</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><ul style="margin-left:8px; margin-right:8px"><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">寄存器</span></strong><span style="color:#3f3f3f">：讓我們從寄存器開始。GPU 中的每個 SM 都擁有大量寄存器。例如，NVIDIA 的 A100 和 H100 模型中，每個 SM 擁有 65536 個寄存器。這些寄存器在核心之間共享，並根據線程需求動態分配。在執行過程中，每個線程都被分配了私有寄存器，其他線程無法讀取或寫入這些寄存器。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">常量緩存</span></strong><span style="color:#3f3f3f">：接下來是芯片上的常量緩存。這些緩存用於緩存 SM 上執行的代碼中使用的常量數據。為利用這些緩存，程序員需要在代碼中明確將對象聲明為常量，以便 GPU 可以將其緩存並保存在常量緩存中。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">共享內存</span></strong><span style="color:#3f3f3f">：每個 SM 還擁有一塊共享內存或臨時內存，它是一種小型、快速且低時延的片上可編程 SRAM 內存，供運行在 SM 上的線程塊共享使用。共享內存的設計思路是，如果多個線程需要處理相同的數據，只需要其中一個線程從全局內存（global memory）加載，而其他線程將共享這一數據。合理使用共享內存可以減少從全局內存加載重複數據的操作，並提高內核執行性能。共享內存還可以用作線程塊（block）內的線程之間的同步機制。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">L1 緩存</span></strong><span style="color:#3f3f3f">：每個 SM 還擁有一個 L1 緩存，它可以緩存從 L2 緩存中頻繁訪問的數據。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">L2 緩存</span></strong><span style="color:#3f3f3f">：所有 SM 都共享一個 L2 緩存，它用於緩存全局內存中被頻繁訪問的數據，以降低時延。需要注意的是，L1 和 L2 緩存對於 SM 來説是公開的，也就是説，SM 並不知道它是從 L1 還是 L2 中獲取數據。SM 從全局內存中獲取數據，這類似於 CPU 中 L1/L2/L3 緩存的工作方式。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><strong><span style="color:#3f3f3f">全局內存</span></strong><span style="color:#3f3f3f">：GPU 還擁有一個片外全局內存，它是一種容量大且帶寬高的動態隨機存取存儲器（DRAM）。例如，NVIDIA H100 擁有 80 GB 高帶寬內存（HBM），帶寬達每秒 3000 GB。由於與 SM 相距較遠，全局內存的時延相當高。然而，芯片上還有幾個額外的存儲層以及大量的計算單元有助於掩飾這種時延。</span></span></span></span></p></li></ul><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">現在我們已經瞭解 GPU 硬件的關鍵組成部分，接下來我們深入一步，瞭解執行代碼時這些組件是如何發揮作用的。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">3</span></strong></span></span></span></p><span id="OSC_h2_3"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">瞭解 GPU 的執行模型</span></strong></span></span></span></p><p>&nbsp;</p><p style="color:#494949"><span style="color:#3f3f3f"><span>&nbsp;</span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">要理解 GPU 如何執行 kernel，我們首先需要了解什麼是 kernel 及其配置。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>CUDA Kernel 與線程塊簡介</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">CUDA 是 NVIDIA 提供的編程接口，用於編寫運行在其 GPU 上的程序。在 CUDA 中，你會以類似於 C/C++函數的形式來表達想要在 GPU 上運行的計算，這個函數被稱為 kernel。kernel 在並行中操作向量形式的數字，這些數字以函數參數的形式提供給它。一個簡單的例子是執行向量加法的 kernel，即接受兩個向量作為輸入，逐元素相加，並將結果寫入第三個向量。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">要在 GPU 上執行 kernel，我們需要啓用多個線程，這些線程總體上被稱為一個網格（grid），但網格還具有更多的結構。一個網格由一個或多個線程塊（有時簡稱為塊）組成，而每個線程塊又由一個或多個線程組成。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">線程塊和線程的數量取決於數據的大小和我們所需的並行度。例如，在向量相加的示例中，如果我們要對 256 維的向量進行相加運算，那麼可以配置一個包含 256 個線程的單個線程塊，這樣每個線程就可以處理向量的一個元素。如果數據更大，GPU 上也許沒有足夠的線程可用，這時我們可能需要每個線程能夠處理多個數據點。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/7e96e636-6948-48f2-adc5-bbc37c3a1f19.png" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 4：線程塊網格。引自《CUDA C++編程指南》（NVIDIA）</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">編寫一個 kernel 需要兩步。第一步是運行在 CPU 上的主機代碼，這部分代碼用於加載數據，為 GPU 分配內存，並使用配置的線程網格啓動 kernel；第二步是編寫在 GPU 上執行的設備（GPU）代碼。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">對於向量加法示例，下圖顯示了主機代碼。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/bc098e64-ceb7-4b8c-8e4b-607b56d471d4.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 5：CUDA kernel 的主機代碼，用於將兩個向量相加。</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">下圖為設備代碼，它定義了實際的 kernel 函數。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/1d2f6102-c267-4b78-ba9e-880c832009d1.jpg" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 6：包含向量相加 kernel 定義的設備代碼。</span></em></span></span></span></p><blockquote><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由於本文的重點不在於教授 CUDA，因此我們不會更深入地討論此段代碼。現在，讓我們看看在 GPU 上執行 kernel 的具體步驟。</span></span></span></blockquote><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">4</span></strong></span></span></span></p><span id="OSC_h2_4"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">在 GPU 上執行 Kernel 的步驟</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><strong style="color:#3f3f3f"><span>1. 將數據從主機複製到設備</span></strong></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span><span style="color:#3f3f3f">在調度執行 kernel 之前，必須將其所需的全部數據從主機（即 CPU）內存複製到 GPU 的全局內存（即設備內存）。</span><span style="color:#3f3f3f">儘管如此，在最新的 GPU 硬件中，我們還可以使用統一虛擬內存直接從主機內存中讀取數據（可參閲論文《EMOGI: Efficient Memory-access for Out-of-memory Graph-traversal in GPUs》）。</span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>2. SM 上線程塊的調度</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">當 GPU 的內存中擁有全部所需的數據後，它會將線程塊分配給 SM。同一個塊內的所有線程將同時由同一個 SM 進行處理。為此，GPU 必須在開始執行線程之前在 SM 上為這些線程預留資源。在實際操作中，可以將多個線程塊分配給同一個 SM 以實現並行執行。</span></span></span></p><p style="color:#494949">&nbsp;</p><p><span style="color:#3f3f3f"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/a5075db0-bd48-4627-a342-c93f06482fca.png" width="auto" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#888888"><em><span style="color:#888888">圖 7：將線程塊分配給 SM</span></em></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由於 SM 的數量有限，而大型 kernel 可能包含大量線程塊，因此並非所有線程塊都可以立即分配執行。GPU 會維護一個待分配和執行的線程塊列表，當有任何一個線程塊執行完成時，GPU 會從該列表中選擇一個線程塊執行。</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span>3. 單指令多線程 (SIMT) 和</span></strong><strong><span>線程束（Warp）</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">眾所周知，一個塊（block）中的所有線程都會被分配到同一個 SM 上。但在此之後，線程還會進一步劃分為大小為 32 的組（稱為 warp[2]），並一起分配到一個稱為處理塊（processing block）的核心集合上進行執行。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">SM 通過獲取並向所有線程發出相同的指令，以同時執行 warp 中的所有線程。然後這些線程將在數據的不同部分，同時執行該指令。在向量相加的示例中，一個 warp 中的所有線程可能都在執行相加指令，但它們會在向量的不同索引上進行操作。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">由於多個線程同時執行相同的指令，這種 warp 的執行模型也稱為單指令多線程 （SIMT）。這類似於 CPU 中的單指令多數據（SIMD）指令。</span></span></span></p><blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">Volta 及其之後的新一代 GPU 引入了一種替代指令調度的機制，稱為獨立線程調度（Independent Thread Scheduling）。它允許線程之間完全併發，不受 warp 的限制。獨立線程調度可以更好地利用執行資源，也可以作為線程之間的同步機制。本文不會涉及獨立線程調度的相關內容，但你可以在 CUDA 編程指南中瞭解更多相關信息。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f">4. Warp 調度和時延容忍度</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">關於 warp 的運行原理，有一些值得討論的有趣之處。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">即使 SM 內的所有處理塊（核心組）都在處理 warp，但在任何給定時刻，只有其中少數塊正在積極執行指令。因為 SM 中可用的執行單元數量是有限的。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">有些指令的執行時間較長，這會導致 warp 需要等待指令結果。在這種情況下，SM 會將處於等待狀態的 warp 休眠，並執行另一個不需要等待任何結果的 warp。這使得 GPU 能夠最大限度地利用所有可用計算資源，並提高吞吐量。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">零計算開銷調度：由於每個 warp 中的每個線程都有自己的一組寄存器，因此 SM 從執行一個 warp 切換到另一個 warp 時沒有額外計算開銷。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">與 CPU 上進程之間的上下文切換方式（context-switching）不同。如果一個進程需要等待一個長時間運行的操作，CPU 在此期間會在該核心上調度執行另一個進程。然而，在 C</span><span style="color:#3f3f3f">PU 中進行上下文切換的代價昂貴，這是因為 CPU 需要將寄存器狀態保存到主內存中，並恢復另一個進程的狀態。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f">5. 將結果數據從設備複製到主機內存</span></strong></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">最後，當 kernel 的所有線程都執行完畢後，最後一步就是將結果複製回主機內存。</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">儘管我們涵蓋了有關典型 kernel 執行的全部內容，但還有一點值得討論：動態資源分區。</span></span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">5</span></strong></span></span></span></p><span id="OSC_h2_5"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">資源劃分和佔用概念</span></strong></span></span></span></p><p><span style="color:#3f3f3f"><span><span style="color:#494949">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">我們通過一個稱為「occupancy（佔用率）」的指標來衡量 GPU 資源的利用率，它表示分配給 SM 的 warp 數量與 SM 所能支持的最大 warp 數量之間的比值。為實現最大吞吐量，我們希望擁有 100% 的佔用率。然而，在實踐中，由於各種約束條件，這並不容易實現。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">為什麼我們無法始終達到 100% 的佔用率呢？SM 擁有一組固定的執行資源，包括寄存器、共享內存、線程塊槽和線程槽。這些資源根據需求和 GPU 的限制在線程之間進行動態劃分。例如，在 NVIDIA H100 上，每個 SM 可以處理 32 個線程塊、64 個 warp（即 2048 個線程），每個線程塊擁有 1024 個線程。如果我們啓動一個包含 1024 個線程的網格，GPU 將把 2048 個可用線程槽劃分為 2 個線程塊。</span></span></span></span></span></p><blockquote><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">動態分區 vs 固定分區：動態分區能夠更為有效地利用 GPU 的計算資源。相比之下，固定分區為每個線程塊分配了固定數量的執行資源，這種方式並不總是最有效的。在某些情況下，固定分區可能會導致線程被分配多於其實際需求的資源，造成資源浪費和吞吐量降低。</span></span></span></p></blockquote><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">下面我們通過一個例子説明資源分配對 SM 佔用率的影響。假設我們使用 32 個線程的線程塊，並需要總共 2048 個線程，那麼我們將需要 64 個這樣的線程塊。然而，每個 SM 一次只能處理 32 個線程塊。因此，即使一個 SM 可以運行 2048 個線程，但它一次也只能同時運行 1024 個線程，佔用率僅為 50%。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">同樣地，每個 SM 具有 65536 個寄存器。要同時執行 2048 個線程，每個線程最多有 32 個寄存器（65536/2048 =32）。如果一個 kernel 需要每個線程有 64 個寄存器，那麼每個 SM 只能運行 1024 個線程，佔用率同樣為 50%。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">佔用率不足的挑戰在於，可能無法提供足夠的時延容忍度或所需的計算吞吐量，以達到硬件的最佳性能。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">高效創建 GPU kernel 是一項複雜任務。我們必須合理分配資源，在保持高佔用率的同時儘量降低時延。例如，擁有大量寄存器可以加快代碼的運行速度，但可能會降低佔用率，因此謹慎優化代碼至關重要。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span><strong><span style="color:#f6ab00">6</span></strong></span></span></span></p><span id="OSC_h2_6"></span><h2 style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</h2><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#3f3f3f"><span><span style="color:#1e2380"><strong><span style="color:#1e2380">總結</span></strong></span></span></span></p><p><span style="color:#3f3f3f"><span><span style="color:#494949">&nbsp;</span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">我理解眾多的新術語和新概念可能令讀者望而生畏，因此文章最後對要點進行了總結，以便快速回顧。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><ul style="margin-left:8px; margin-right:8px"><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 由多個 SM 組成，每個 SM 又包含多個處理核心。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 上存在着一個片外全局內存，通常是高帶寬內存（HBM）或動態隨機存取內存（DRAM）。它與芯片上的 SM 相距較遠，因此時延較高。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 中有兩個級別的緩存：片外 L2 緩存和片上 L1 緩存。L1 和 L2 緩存的工作方式類似於 CPU 中的 L1/L2 緩存。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">每個 SM 上都有一小塊可配置的共享內存。這塊共享內存在處理核心之間共享。通常情況下，線程塊內的線程會將一段數據加載到共享內存中，並在需要時重複使用，而不是每次再從全局內存中加載。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">每個 SM 都有大量寄存器，寄存器會根據線程需求進行劃分。NVIDIA H100 每個 SM 有 65536 個寄存器。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">在 GPU 上執行 kernel 時，我們需要啓動一個線程網格。網格由一個或多個線程塊組成，而每個線程塊又由一個或多個線程組成。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">根據資源可用性，GPU 會分配一個或多個線程塊在 SM 上執行。同一個線程塊中的所有線程都會被分配到同一個 SM 上執行。這樣做的目的是為了充分利用數據的局部性（data locality），並實現線程之間的同步。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">被分配給 SM 的線程進一步分為大小為 32 的組，稱為 warp。一個 warp 內的所有線程同時執行相同的指令，但在數據的不同部分上執行（SIMT）（儘管新一代 GPU 也支持獨立的線程調度）。</span></span></span></span></span></p></li><li><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">GPU 根據每個線程的需求和 SM 的限制，在線程之間進行動態資源劃分。程序員需要仔細優化代碼，以確保在執行過程中達到最高的 SM 佔用率。</span></span></span></span></span></p></li></ul><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">&nbsp;</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><strong><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">腳註</span></span></span></strong></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify">&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">[1]沒錯，得益於超線程技術和多核處理器，CPU 也可以並行執行任務。但長期以來，大量工作都致力於提高順序執行的性能。</span></span></span></span></span></p><p style="margin-left:8px; margin-right:8px; text-align:justify"><span style="color:#3f3f3f"><span><span style="color:#3f3f3f"><span><span style="color:#3f3f3f">[2]在當前一代的 NVIDIA GPU 中，warp 大小為 32。但在未來的硬件迭代中，這個大小可能會發生改變。</span></span></span></span></span></p><span id="OSC_h2_7"></span><h2 style="margin-left:8px; margin-right:8px">&nbsp;</h2><p style="text-align:left">&nbsp;</p><p style="text-align:left"><span style="color:#3f3f3f"><span><span style="background-color:#ffffff; color:#888888">其他人都在看</span></span></span></p><span id="OSC_h3_8"></span><h3>&nbsp;</h3><ul><li><p><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492657%26idx%3D1%26sn%3Da71795c583da44c805f79630f2ef635a%26chksm%3Dfe426a07c935e3112422680f4942c0b372c01db1e63e044010f03cd72689bce2563e8672136b%26scene%3D21%23wechat_redirect" target="_blank">開源語言大模型的正確姿勢</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492610%26idx%3D1%26sn%3D9b92f3efa0d85cb1bb689efab362c3e8%26chksm%3Dfe426a34c935e32200b2d9cc84916eb980ba3c8ab1eceafa9834e38049e5243ca8aa77564a68%26scene%3D21%23wechat_redirect" target="_blank">為什麼開源大模型終將勝出</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492849%26idx%3D1%26sn%3D51f53e04b4b97cd9dd38429784015c98%26chksm%3Dfe426ac7c935e3d1b5970441a68c53b6dae05792cd9a244ad8efb40ffc5ab4c60cdf3a7181b0%26scene%3D21%23wechat_redirect" target="_blank">LoRA 和 QLoRA 微調語言大模型</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492767%26idx%3D1%26sn%3Ded8acf6d7e9117b5ab3ea0de8e540460%26chksm%3Dfe426aa9c935e3bfb8b3e2ffc7cb6349f076f4f25d2fbe13b6e8e2c30ea010261c57f8d6cacb%26scene%3D21%23wechat_redirect" target="_blank">OpenAI 規模經濟與第二護城河</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492787%26idx%3D1%26sn%3Dc5d16b72e94079bb20e9772cad81e703%26chksm%3Dfe426a85c935e393a9962ab763fc1f06ebaf1bd75331cc089ff61f8655c0e8ecbb8211264544%26scene%3D21%23wechat_redirect" target="_blank">全面對比 GPT-3.5 與 LLaMA 2 微調</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492811%26idx%3D1%26sn%3D916e330a2a4152dab3192635c3e475fa%26chksm%3Dfe426afdc935e3eb2f371ff5f56247c95800ce91a950a89bea871c26ddc4c3d13371acf03978%26scene%3D21%23wechat_redirect" target="_blank">語言大模型推理性能工程：最佳實踐</a></span></span></p></li><li><p style="text-align:left"><span style="color:#3f3f3f"><span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492618%26idx%3D1%26sn%3Da20f4828b9ab3e3cee3fedfd906e0eb2%26chksm%3Dfe426a3cc935e32a8312ce9efbb4f2640787508d3e811579bbffe918685cdb07a8bd8e3ffc4b%26scene%3D21%23wechat_redirect" target="_blank">LLVM 之父:我的 AI 基礎設施軟件構建理念</a></span></span></p></li></ul><span id="OSC_h3_9"></span><h3>&nbsp;</h3><p><strong><span style="color:#3f3f3f"><span><span>試用 OneFlow: <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank">github.com/Oneflow-Inc/oneflow/</a></span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2FOneflow-Inc%2Foneflow%2F" target="_blank"></a></span></span></strong></p><p style="margin-left:8px; margin-right:8px"><span style="color:#3f3f3f"><span><img src="https://oscimg.oschina.net/oscnet/b316e9d8-4d68-4323-98d4-8e2e62cf5163.png" referrerpolicy="no-referrer"></span></span></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br> 如有侵權，請聯繫 support@oschina.cn 刪除。<br> 本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10140417</guid>
            <link>https://my.oschina.net/oneflow/blog/10140417</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為與美團達成合作，正式啓動鴻蒙原生應用開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>華為迎來又一個鴻蒙生態的重要合作伙伴，宣佈與美團以 HarmonyOS 為基礎進行產業創新、技術應用、商業發展等方面展開全面合作，全力支持美團啓動開發鴻蒙原生應用工作。</p><p>自 9 月 25 日華為宣佈全新 HarmonyOS NEXT 蓄勢待發、鴻蒙原生應用全面啓動以來，已有金融、旅行、社交等多個領域的企業和開發者陸續宣佈加入鴻蒙生態。此次美團成為最新加速融入鴻蒙生態的行業頭部夥伴，形成「鴻蒙千帆起」的景象。</p><p>週一，在北京舉行的「鴻蒙原生應用開發啓動儀式」上，華為終端雲服務總裁朱勇剛表示：「很高興美團成為鴻蒙生態重要的合作伙伴，鴻蒙正在致力於打造一個‘一切皆服務，萬物可分享’的新生態。鴻蒙獨有的分佈式技術，以及一次開發、多端部署，能讓美團的服務在手機、平板、車機等設備上無縫流轉，為用户提供場景化、智慧化的「服務合時宜」新體驗。未來華為希望與美團基於端到端的鴻蒙生態，持續源源不斷地的創新，助力美團等互聯網企業獲取新流量和商機，創造更大的商業價值。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-36c3813f9e9377dea1c3a86232a7923485a.png" referrerpolicy="no-referrer"></p><p>作為紮根本地的中國科技零售企業，美團通過「零售+科技」的戰略踐行「幫大家吃得更好，生活更好」的公司使命。美團高級副總裁李樹斌表示：「美團始終以客户為中心，不斷加大在新技術上的研發投入，這與華為鴻蒙操作系統在前沿領先領域的探索努力不謀而合。我們希望與華為共同努力，在鴻蒙系統生態裏為用户提供更好的服務和體驗。」</p><p>作為鴻蒙生態社交領域的重要夥伴，美團與華為早有深厚的鴻蒙生態合作基礎，此前美團就已基於鴻蒙系統特點和用户需求，有針對性地率先開發和適配了多項功能，包括上線華為手機桌面「萬能卡片」元服務、Push Kit 實況窗功能等。</p><p>未來，華為將攜手美團等更多合作伙伴，持續共同建設鴻蒙生態，依託於 HarmonyOS 原生應用在全場景多設備高效協同、原生智能、更強大的 AI 能力、更高的安全和隱私保護體驗等獨特的技術優勢，展開全方位深層次的合作，為消費者帶來更流暢、更智能、更安全的服務體驗。</p><p>數據顯示，截至今年 8 月份，鴻蒙生態設備數量超過 7 億台，已有 220 萬開發者投入到鴻蒙生態的開發，華為始終與夥伴共享鴻蒙生態新機遇，共創萬物互聯新未來。</p><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/266107">多家互聯網公司急招鴻蒙程序員</a></li><li><a href="https://www.oschina.net/news/265725">美團招兵買馬，擬開發鴻蒙系統 App</a></li><li><a href="https://www.oschina.net/news/261747">深圳信息職業技術學院開設「開源鴻蒙班」</a></li><li><a href="https://www.oschina.net/news/252658">HarmonyOS NEXT：使用全自研內核</a></li><li><a href="https://www.oschina.net/news/252385/harmonyos-4">華為正式發佈 HarmonyOS 4</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266352</guid>
            <link>https://www.oschina.net/news/266352</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 原生編譯的 Solon 回憶錄]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start">最近和<code>@雨韻詩澤</code>、<code>@讀釣</code>兩個小夥伴一起（主要是他們兩在出力），適配了<span>&nbsp;</span><strong>Solon Native</strong><span>&nbsp;</span>的第一個開源項目：<a href="https://gitee.com/dromara/neutrino-proxy">dromara/neutrino-proxy</a><span>&nbsp;</span>（里程碑案例啊！有點修行大成的味道了！）。總體來説：</p><ul><li>適配調整完後，代碼變化不太大</li><li>整個過程是很麻煩的。因為 graalvm native image 社區版不能調試，只能不斷試（發現缺什麼，就補什麼配置）</li></ul><h3>1、緣起</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2021 年的深秋</span>，有個叫<span>&nbsp;</span><code>@饅頭蟲</code><span>&nbsp;</span>的男人。跑過來講，他有個項目需求是（給一個美國大廠做的）：存放空間只有 100M，內存只有 100M，在硬件裏運行一個管理界面系統。他研究了 spring native，因為它的基礎就太大沒過；研究了 go，做複雜的界面系統不好預期沒過。所以選擇嘗試 solon。</p><p style="color:#24292e; text-align:start">於是他種下了一顆 solon native 的種子。開始澆水、施肥。前後一兩個月的時間，真的也開花了（最後好像只有 53m 大小）。這 365 萬字省去，他怎麼不哭呢？</p><p style="color:#24292e; text-align:start">這個男人總結出了三條經驗：</p><ul><li>所有的反射需要提前登記（放到特定的配置文件裏），並通過配置獲取反射導引（比如一個類有哪些字段，哪些方法）</li><li>所有的資源文件獲取需要提前登記（放到特定的配置文件裏）</li><li>所有的動態編譯、類字節碼，不能用</li></ul><p style="color:#24292e; text-align:start">説起來，<a href="https://gitee.com/noear/solon">Solon 框架</a><span>&nbsp;</span>真的是好啊（按那男人的講法：小是真的小，快是真的快）：</p><ul><li>啓動快 5 ～ 10 倍；</li><li>qps 高 2～ 3 倍；</li><li>運行時內存節省 1/3 ~ 1/2；</li><li>打包可以縮到 1/2 ~ 1/10；</li></ul><h3>2、認識 APT</h3><p style="color:#24292e; text-align:start">後面很長的時間，我沒再碰它（主要是無知，無從下手。懵！）。偶然的一天，路過 mybatis-plus 4.x 項目倉庫，看到 APT 這幾個字眼。我對 java 確實是無知，百度後才知道神器 lombok 就是基於 APT 實現的。然後，我想起了那個男人總結的三條經驗：</p><ul><li>所有的反射需要提前登記</li><li>所有的資源文件獲取需要提前登記</li><li>所有的動態編譯、類字節碼，不能用</li></ul><p style="color:#24292e; text-align:start">是不是可以藉助 APT，去提前生成類的代理代碼，去完成資源文件、反射的登記？我估計是行的。</p><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的初春</span>，花了一週時間，把類的代理用 APT 在編譯時生成了。開心是開心的。但是，怎樣獲取需要代理的類，成了一個不解的題。路很長。然後，暫時沒有然後了！</p><h3>3、認識 AOT</h3><p style="color:#24292e; text-align:start">好多年前就聽過 AOT，大概知道它是幹嘛的。但是，還是一臉懵。</p><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的春後</span>，有個叫<span>&nbsp;</span><code>@李總</code><span>&nbsp;</span>的男人。他説，我有個項目想要用 solon 的原生編譯，而且可以叫個人幫忙搞。最後出現的男人叫<span>&nbsp;</span><code>@讀釣</code>，不知道是<span>&nbsp;</span><code>@李總</code><span>&nbsp;</span>忽悠過來的，還是我把他忽悠過來的（後來，據他説是自己跑來的）。他説，我們應該 A,B,C...這麼這麼搞！</p><p style="color:#24292e; text-align:start">還有個加強版的 AOT。原來如此，原來如此：</p><ul><li>在編譯後 -&gt; 運行項目並獲取運行中的信息 -&gt; 然後完成各種預編譯和登記 -&gt; 再進行原生編譯</li><li>一氣呵成</li></ul><p style="color:#24292e; text-align:start">這個男人從春天搞到了夏天。成了！（當中略過 365 萬字...），一直搞，不知道有沒有洗過澡， 有沒有換過衣服。</p><h3>4、我們發佈第一個 Solon Native 版本</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的夏天</span>，有個新男人來。説是要用 Solon Native。我心裏其實沒底，原生這東西太難用了。必須得忍住不哭才行。後來他招乎也沒打，跑了。</p><p style="color:#24292e; text-align:start">真的是太難用了：</p><ul><li>目前沒有哪個框架是開箱即用的（Spring Native 和 Quarkus 也一樣）</li><li>框架不一定把生態內的所有包都適配好了</li><li>第三方的包，框架沒法照顧到。只能自己試着做些補充登記（沒法調試，只能嘗試或實驗）</li><li>隨便升級某個第三方包，就可能不兼容了（需要重新適配）</li></ul><h3>5、你信輪迴？</h3><p style="color:#24292e; text-align:start"><span style="background-color:#f1c40f">2023 年的深秋</span>，又是一個深秋。男人<span>&nbsp;</span><code>@雨韻詩澤</code>，説想把他的<span>&nbsp;</span><a href="https://gitee.com/dromara/neutrino-proxy">dromara/neutrino-proxy</a><span>&nbsp;</span>開源項目搞成原生編譯的。我説，那得忍住不哭才行。他説，他不會哭（其實，他動得不多。哈哈）。<code>@讀釣</code>又開始忙了。</p><p style="color:#24292e; text-align:start">説起來，<code>@讀釣</code><span>&nbsp;</span>是從春天干到了秋天。終於成了：<a href="https://www.oschina.net/news/264550/solon-2-5-12-released">《Solon v2.5.12 發佈，Java 原生編譯再起》</a>。我們也是正經的支持 Java 原生編譯的生態型框架了。且是，國產的。</p><p style="color:#24292e; text-align:start"><span style="background-color:#ffffff; color:#24292e">開源，讓很多人的願望和努力匯聚一處，也記錄了共同的回憶。</span></p><p style="color:#24292e; text-align:start">人生路，且短且長，只怪情深緣淺，你信輪迴？</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 01:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266350</guid>
            <link>https://www.oschina.net/news/266350</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘋果將禁止「搖一搖」跳轉廣告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tfcaijing.com%2Farticle%2Fpage%2F474a676e737050677a746a63653436332f646c3554773d3d" target="_blank">據時代財經報道</a></u>，互聯網大廠內部人士常樂年稱，11 月以來，蘋果公司已通知國內多家頭部 App 要求它們移除陀螺儀權限，搖一搖跳轉廣告被禁止。</p><p>據報道，11 月以來，蘋果公司已通知在線視頻軟件、短視頻軟件、音頻軟件、郵箱軟件等多種類型的 App，<strong>要求它們取消搖一搖跳轉廣告的功能</strong>。常樂年所在公司的 App 也在通知的範圍內。他透露，接下來公司可能會發布新版本 App，在蘋果的 App Store 上架，新版本將沒有搖一搖跳轉廣告，具體發佈時間還不確定。</p><p>另一位廣告從業者也證實了這一消息，他的客户也是互聯網大廠，旗下有行業頭部 App。他説，收到通知的不只是頭部 App，還有很多其他的 App，範圍很廣。</p><p>搖一搖功能調用的是陀螺儀權限，這是一種很早就有的功能，可以用來搶電視紅包、識別歌曲等，但現在被用來做廣告跳轉，而有些手機沒有陀螺儀權限開關，用户無法自行關閉。</p><p><img src="https://static.oschina.net/uploads/space/2023/1114/084659_fhVb_2720166.png" referrerpolicy="no-referrer"></p><p>一位手機大廠的工作人員説，這種跳轉是 App 開發出來的商業模式，手機廠商很難做系統性的調整。</p><p>中國信息通信研究院此前聯合華為、小米、OPPO、阿里巴巴等企業制定了團體標準 T / TAF 078.7—2022，於 2022 年 11 月由電信終端產業協會發布實施，該標準進一步細化了 App 信息窗口通過「搖一搖」等方式觸發頁面或跳轉至第三方應用的相關參數，提出「搖一搖」動作的設備加速度應不小於 15m/s2，轉動角度不小於 35°，操作時間不少於 3s 等系列參考數值。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 12 Nov 2023 00:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266344</guid>
            <link>https://www.oschina.net/news/266344</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Kotlin 1.9.20 現已發佈，KMP 進入穩定階段]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><section style="font-size: 15px;box-sizing: border-box;font-style: normal;font-weight: 400;text-align: justify;margin-bottom: 0px;" data-mpa-powered-by="yiban.io"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="margin: 30px 0% 10px;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;background-color: rgb(237, 238, 242);align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="display: flex;width: 100%;flex-flow: column;box-sizing: border-box;" powered-by="xiumi.us"><section style="z-index: auto;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: flex;flex-flow: row;justify-content: flex-start;transform: translate3d(18px, 0px, 0px);-webkit-transform: translate3d(18px, 0px, 0px);-moz-transform: translate3d(18px, 0px, 0px);-o-transform: translate3d(18px, 0px, 0px);margin: -16px 0% 0px;box-sizing: border-box;"><section style="display: inline-block;vertical-align: top;width: 15%;flex: 0 0 auto;height: auto;align-self: flex-start;box-sizing: border-box;"><section style="text-align: center;margin: -16px 0px 0px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img class="rich_pages wxw-img" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/857c41ff-cddd-4928-8250-1a8458f95df4.png" data-w="707" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 auto;align-self: flex-start;min-width: 10%;max-width: 100%;height: auto;box-sizing: border-box;"><section style="transform: translate3d(5px, 0px, 0px);-webkit-transform: translate3d(5px, 0px, 0px);-moz-transform: translate3d(5px, 0px, 0px);-o-transform: translate3d(5px, 0px, 0px);box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;color: rgb(115, 119, 173);padding: 0px 7px;line-height: 1.2;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="box-sizing: border-box;"><strong style="box-sizing: border-box;">記得加關注， Kotlin 之路不迷路！</strong></span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;font-size: 12px;color: rgb(221, 18, 101);line-height: 1.2;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="box-sizing: border-box;">&nbsp; &nbsp; Kotlinlang.org</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section></section></section></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin 1.9.20 版本已發佈，適用於所有目標的<strong style="box-sizing: border-box;"> K2 編譯器</strong>現已進入<strong style="box-sizing: border-box;">測試版</strong>階段，<strong style="box-sizing: border-box;">Kotlin Multiplatform </strong>現已進入<strong style="box-sizing: border-box;">穩定階段</strong><sup style="box-sizing: border-box;">1</sup>。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">以下是此版本的一些亮點：</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><ul class="list-paddingleft-1" style="list-style-type: disc;box-sizing: border-box;padding-left: 40px;list-style-position: outside;"><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">適用於所有目標的 K2 現已進入測試版階段</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">穩定的 Kotlin Multiplatform</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">用於設置多平台項目的新默認層次結構模板</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin Multiplatform 中全面支持 Gradle 配置緩存</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Native 中默認啓用自定義內存分配器</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Native 中垃圾回收器的性能改進</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Wasm 中的新目標和重命名目標，支持最新的 Wasm GC</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin/Wasm 的標準庫中支持 WASI API</p></li></ul></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">有關完整的更改列表，請參閲&nbsp;<strong style="box-sizing: border-box;">Kotlin 1.9.20 最新變化</strong><sup style="font-size: 11px;box-sizing: border-box;">2</sup>或&nbsp;<strong style="box-sizing: border-box;">GitHub 上的版本説明</strong><sup style="font-size: 11px;box-sizing: border-box;">3</sup>。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">適用於所有目標的新 Kotlin K2 編譯器已進入測試版階段</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">JetBrains 的 Kotlin 團隊正在繼續穩定新 K2 編譯器，這將帶來重大性能改進，加快新語言功能的開發，統一 Kotlin 支持的所有平台，併為多平台項目提供更好的架構。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;"></strong></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">隨着 1.9.20 版本的發佈，新 K2 編譯器已面向所有平台進入測試版階段：JVM、Native、JS 和 Wasm。這意味着您現在可以在任何 Kotlin 項目中試用 K2。</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin 團隊通過成功編譯數十個用户和內部項目，確保了新編譯器的質量。大量用户也參與了穩定過程，在他們的項目中試用新 K2 編譯器，並報告他們發現的任何問題。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">Kotlin 1.9.20 版本還在 kapt 編譯器插件中引入了 K2 支持。</strong>&nbsp;現在，所有必要的 Kotlin 編譯器插件都支持 K2。這些包括 kapt、serialization、AtomicFU、Lombok、SAM with receiver、all-open、no-arg、jvm-abi-gen、Android Lint 和 Jetpack Compose 編譯器插件。支持 K2 的 Kotlin Symbol Processing (KSP) 將在 Kotlin 1.9.20 發佈後一週內發佈。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">如果您使用任何其他編譯器插件，請查看相關文檔以瞭解其是否與 K2 兼容。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">下一站是 Kotlin 2.0</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">Kotlin 的下一個主要版本是 2.0.0，新 K2 編譯器將作為默認的穩定編譯器面向所有目標提供。</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">為了儘快解決發現的任何問題，我們計劃頻繁發佈一系列小型 Kotlin 2.0 穩定版本。這些版本將包括 Beta1、Beta2、Beta3、RC1 和 RC2。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">在 Kotlin 2.0.0-RC1 發佈時，我們計劃確保與其他版本 Kotlin 編譯器編譯的代碼的二進制文件兼容性，並消除使用 K2 編譯的二進制文件時的中毒現象。這樣您就能夠在生產環境中使用新的 K2 編譯器。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">參與進來：立即塑造 Kotlin 2.0 並試用 K2 編譯器</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">K2 編譯器即將完成其穩定過程，並在 Kotlin 2.0 中默認啓用。至關重要的是，我們呼籲儘可能多的開發者試用 K2 並報告任何潛在問題。&nbsp;</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">您的反饋將幫助我們解決任何問題，並確保 K2 即使在最複雜的場景中也能完美運行。只需使用 K2 對您的項目進行一次編譯就可以為達到 Kotlin 2.0 里程碑做出顯著貢獻。<strong style="box-sizing: border-box;"> 立即試用 K2！</strong><sup style="box-sizing: border-box;">4</sup></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">如何安裝 Kotlin 1.9.20</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">如果您已經在使用<strong style="box-sizing: border-box;">&nbsp;IntelliJ IDEA</strong><sup style="box-sizing: border-box;">5</sup>&nbsp;2023.1 或 2023.2，IDE 會自動建議將 Kotlin 更新到 1.9.20。您也可以按照<strong style="box-sizing: border-box;">這些説明</strong><sup style="box-sizing: border-box;">6</sup>手動更新。IntelliJ IDEA 2023.3 將包含 Kotlin 1.9.20 插件。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">對於 Android Studio Hedgehog (231) 和 Iguana (232)，Kotlin 1.9.20 插件將包含在即將推出的 Android Studio 更新中。如果需要命令行編譯器，請從<strong style="box-sizing: border-box;">&nbsp;GitHub 版本頁面</strong><sup style="box-sizing: border-box;">7</sup>下載。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">如果您遇到任何問題</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><ul class="list-paddingleft-1" style="list-style-type: disc;box-sizing: border-box;padding-left: 40px;list-style-position: outside;"><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">在&nbsp;<strong style="box-sizing: border-box;">Slack</strong><sup style="font-size: 11px;box-sizing: border-box;">8</sup>（<strong style="box-sizing: border-box;">獲得邀請</strong><sup style="font-size: 11px;box-sizing: border-box;">9</sup>）上獲取幫助。</p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">向我們的問題跟蹤器&nbsp;<strong style="box-sizing: border-box;">YouTrack</strong><sup style="box-sizing: border-box;">10</sup>&nbsp;報告問題。</p></li></ul><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">特別感謝我們的 EAP Champions 🥇👏</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;">Zac Sweers、Alexander Nozik、Oleg Yukhnevich、Josh Friend、Łukasz Wasylkowski、Simon Marquis、Benoit ‘BoD’ Lubek、Yang、Rustam Musin、Russell Wolf、Jake Wharton、Rick Clephas、Artyom Shendrik、Johannes Svensson、Sterling Albury、David Lopez。</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin: 10px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;box-sizing: border-box;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;box-sizing: border-box;"><img data-ratio="1" data-s="300,640" data-w="500" src="https://oscimg.oschina.net/oscnet/6bfa4c27-1a25-41fd-9125-da620c956bf6.png" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding: 0px 0px 0px 10px;box-sizing: border-box;"><section style="text-align: left;margin: 10px 0px 0px;box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">更多文章和視頻</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 2px 0px 8px;box-sizing: border-box;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;box-sizing: border-box;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: justify;box-sizing: border-box;"><ul class="list-paddingleft-1" style="list-style-type: disc;box-sizing: border-box;padding-left: 40px;list-style-position: outside;"><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">「Kotlin 1.9.20 最新變化」文檔：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="color: rgb(0, 86, 150);font-size: 14px;box-sizing: border-box;">https://kotlinlang.org/docs/whatsnew1920.html</span></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin 1.9.20 最新變化 YouTube 視頻：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(0, 86, 150);box-sizing: border-box;">https://youtu.be/Ol_96CHKqg8</span><br style="box-sizing: border-box;"></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">K2 編譯器將在 Kotlin 2.0 中進入穩定狀態：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(0, 86, 150);box-sizing: border-box;">https://blog.jetbrains.com/zh-hans/kotlin/2023/02/k2-kotlin-2-0/</span></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin Multiplatform 已經穩定並且可以投入生產環境：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="color: rgb(0, 86, 150);font-size: 14px;box-sizing: border-box;">https://blog.jetbrains.com/kotlin/2023/11/kotlin-multiplatform-stable/</span></p></li><li style="box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Kotlin EAP Champion：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(0, 86, 150);box-sizing: border-box;">https://blog.jetbrains.com/kotlin/2022/11/eap-champions/</span><br style="box-sizing: border-box;"></p></li></ul></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin-top: 10px;margin-bottom: 10px;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(120, 85, 245);padding: 10px;box-shadow: rgb(204, 204, 204) 0.2em 0.2em 0.3em;box-sizing: border-box;"><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">相關鏈接：</strong></p><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: left;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">1. Kotlin Multiplatform 現已進入穩定階段：</span></p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://blog.jetbrains.com/kotlin/2023/11/kotlin-multiplatform-stable/https://github.com/jetbrains/exposed</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="text-align: left;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">2. Kotlin 1.9.20 最新變化：&nbsp;</span></p><p style="margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">http://kotlinlang.org/docs/whatsnew1920.html</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">3. GitHub 上的版本説明：</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://github.com/JetBrains/kotlin/releases/tag/v1.9.20</span></p><p style="margin-bottom: 0px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">4. 立即試用 K2！：</span></p><p style="margin-bottom: 0px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;color: rgb(51, 122, 183);">https://kotlinlang.org/docs/whatsnew1920.html</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">5. IntelliJ IDEA：</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://www.jetbrains.com.cn/idea/download/</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">6. 這些説明：</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://kotlinlang.org/docs/releases.html#update-to-a-new-release</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">7. GitHub 版本頁面:&nbsp;</span></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="color: rgb(51, 122, 183);font-size: 14px;text-align: left;box-sizing: border-box;">https://github.com/JetBrains/kotlin/releases/tag/v1.9.20</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">8. Slack:&nbsp;</span></p><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">http://kotlinlang.slack.com/</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">9. 獲得邀請：</span></p><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://surveys.jetbrains.com/s3/kotlin-slack-sign-up</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="box-sizing: border-box;"><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;">10. YouTrack：</span></p><p style="text-align: left;white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><span style="font-size: 14px;color: rgb(51, 122, 183);box-sizing: border-box;">https://youtrack.jetbrains.com/issues/KT</span></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><br style="box-sizing: border-box;"></p><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 10px 0px 0px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding: 0px 0px 0px 8px;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="box-sizing: border-box;" powered-by="xiumi.us"><section style="color: rgb(125, 125, 125);font-size: 12px;box-sizing: border-box;"><p style="margin: 0px;padding: 0px;box-sizing: border-box;">本博文英文原作者：</p><p style="margin: 0px;padding: 0px;box-sizing: border-box;">Andrey Polyakov</p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section></section></section><section style="margin: 10px 0% 0px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;background-position: 97.529% 66.6681%;background-repeat: repeat;background-size: 171.01%;background-attachment: scroll;align-self: flex-start;flex: 0 0 auto;height: auto;background-image: url(&quot;https://oscimg.oschina.net/oscnet/0eddb263-e655-40fb-bb29-ad40b1263907.png&quot;);box-sizing: border-box;"><section style="text-align: justify;justify-content: flex-start;display: flex;flex-flow: row;box-sizing: border-box;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;padding: 26px;align-self: flex-start;flex: 0 0 auto;box-sizing: border-box;"><section style="margin: -9px 0px 7px;box-sizing: border-box;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(248, 248, 248);box-sizing: border-box;"><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">這就是 Kotlin 編程語言</strong></p><p style="white-space: normal;margin: 0px;padding: 0px;box-sizing: border-box;"><strong style="box-sizing: border-box;">簡潔、跨平台、且有趣！</strong></p></section><grazie-editor-wrapper style="box-sizing: border-box;"></grazie-editor-wrapper></section><section style="margin: 0px;box-sizing: border-box;" powered-by="xiumi.us"><section class="mp_profile_iframe_wrp" style="box-sizing: border-box;"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-id="Mzg4MzkxMzg3MQ==" data-pluginname="mpprofile" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/y4ibuu6gd7d4NyzPduLLqtqddBasicL77gAgbLQD89CyYm1n7icODFhBr3xMoloOA7yicfjR8Bv0oaRP3CJuRLIO4Q/0?wx_fmt=png" data-nickname="Kotlin 開發者" data-alias="" data-signature="現代、簡潔、安全的編程語言，由 JetBrains 打造。面向服務器、Android、Web 和原生平台，提供多種在平台間重用代碼的方式以實現高效編程。官網：kotlinlang.org" data-from="0" data-is_biz_ban="0"></mp-common-profile></section></section><section style="text-align: center;margin: 7px 0px 0px;line-height: 0;box-sizing: border-box;" powered-by="xiumi.us"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;width: 45%;height: auto;box-sizing: border-box;"><img class="rich_pages wxw-img" data-ratio="0.4119760479041916" data-s="300,640" src="https://oscimg.oschina.net/oscnet/3798f3e4-8493-496c-9edb-4fd1944d295e.png" data-w="835" style="vertical-align: middle;max-width: 100%;width: 100%;box-sizing: border-box;" width="100%" referrerpolicy="no-referrer"></section></section></section></section></section></section></section><p style="display: none;margin-bottom: 0px;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - JetBrains（JetBrainsChina）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 11 Nov 2023 11:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5494143/blog/10142143</guid>
            <link>https://my.oschina.net/u/5494143/blog/10142143</link>
            <author>
                <![CDATA[JetBrains 中國]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JetBrains 推出新的 C/C++ IDE：CLion Nova]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">JetBrains 宣佈推出全新的&nbsp;CLion Nova 早期預覽版，<span style="background-color:#ffffff">使用 ReSharper C++/Rider C++ 語言引擎而不是 CLion「傳統」引擎。「我們將新的實驗預覽版命名為 CLion Nova，而當前的 CLion 版本則是 CLion Classic。未來，我們計劃將 CLion Nova 併入 CLion Classic。我們不打算推出新產品。」</span></span></p><p><span style="color:#000000">該公司打算先收集用户反饋，然後在 2024 年的某個時刻根據具體的反饋結果將&nbsp;<span style="background-color:#ffffff">CLion Nova 合併到&nbsp;CLion Classic。在此之前，預覽版本將免費提供，並且可以與 CLion (Classic) 安裝並行安裝。目前&nbsp;CLion Nova&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Ftoolbox-app%2F" target="_blank">只能通過 Toolbox 應用程序</a><span style="color:#000000">獲得。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-d8f4e7450a6ce6527151f7d97e3629a6f59.png" width="500" referrerpolicy="no-referrer"></span></span></p><p><span style="color:#000000">CLion Nova&nbsp;重點關注 IDE 的響應能力、準確性和性能。有兩個主要目標：</span></p><ul style="margin-left:0; margin-right:0"><li><span style="color:#000000">解決 CLion 因使用「傳統」引擎而導致的長期存在的<strong>性能</strong>和<strong>質量問題。</strong></span></li><li><span style="color:#000000">統一 JetBrains 所有 C++ 工具（即 CLion、Rider 和 ReSharper C++）的用户體驗。</span></li></ul><p><span style="color:#000000">&nbsp;<img alt="" height="211" src="https://oscimg.oschina.net/oscnet/up-d18769c1e056c9bdb1ea86ad5ce12804963.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">CLion Nova 仍然使用兩種 C++ 語言引擎：基於 clangd 的引擎和 ReSharper C++/Rider 使用的引擎，且&nbsp;CLion Nova 包含了 CLion Classic 的大部分功能。</span></p><p><span style="color:#000000">CLion Nova </span>的性能優勢主要在於：</p><ul style="margin-left:0; margin-right:0"><li>更快的高亮顯示速度，尤其是在代碼增量更新的情況下</li><li>響應速度更快的&nbsp;UI</li><li>查找使用速度更快</li><li>重構時的凍結和掛起情況顯着減少</li><li>更快的測試索引</li></ul><p>此外，CLion Nova 還增添了一些 CLion Classic 中未包含的新功能：&nbsp;</p><ul style="margin-left:0; margin-right:0"><li>新的重構，例如<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23intro_field" target="_blank">引入字段</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23namespace_alias" target="_blank">引入命名空間別名</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23using_enum" target="_blank">引入 using 枚舉</a>以及<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FRefactorings_for_CPP.html%23convert_to_scoped" target="_blank">轉換為作用域枚舉</a>。</li><li>新的檢查、快速修復和意圖，例如冗餘限定符、用明確的類型聲明替換<code>auto</code>以及<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FCode_Style_Assistance_in_CPP.html%23sort_includes" target="_blank"><code>#include</code>指令排序</a>。</li><li>新的代碼提示，例如<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FSettings_Inlay_Hints_CPP_Other.html%23preprocessor-directive" target="_blank">預處理指令提示</a>﻿和&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fresharper%2FInline_Parameter_Name_Hints.html%23push-to-hint-mode" target="_blank">Push-to-Hint 模式</a>。</li></ul><p><img alt="" height="183" src="https://oscimg.oschina.net/oscnet/up-13d64d47fd11ccfff6297a4bd485597e5e7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">與 CLion Classic 不同的是，CLion Nova 不使用&nbsp;<strong style="color:#19191c">clangd&nbsp;</strong>來實現代碼完成或高亮顯示等核心 IDE 功能。不過，JetBrains 的 clangd 分支仍然與新引擎一起運行，以執行各種任務（ClangFormat、Clang-Tidy、MISRA 檢查、數據流分析等）。&nbsp;</span></p><p>公告指出，對於&nbsp;<span style="color:#000000">CLion Classic </span>而言，使用&nbsp;<span style="color:#000000">CLion Nova </span>將擁有一些全新的體驗：</p><ul style="margin-left:0; margin-right:0"><li>用户鍵入時 IDE 的一些反應方式會有所差異。</li><li>與代碼洞察功能相關的某些 UI 元素和設置可能看起來不尋常或位於不熟悉的位置。</li><li>某些與代碼相關的設置在 CLion Nova 中可能具有不同的默認值。首次啓動時，CLion Nova 將從 CLion Classic 遷移一些按項目和應用程序設置，但不是全部。</li><li>在不同語言配置（即調試/發佈）之間切換可能需要更多時間來讓代碼洞察引擎跟上。也沒有選項可以切換每個文件的解析上下文。</li><li>ReSharper C++ 僅適用於 Windows，而 Rider 則支持跨平台。ReSharper C++/Rider 引擎可能無法像 Windows 環境那樣無縫地支持非 Windows 環境。</li></ul><p><img alt="" height="382" src="https://oscimg.oschina.net/oscnet/up-c2c732eb8e4fd3d5f0bda9c1c6c3a7e2241.png" width="500" referrerpolicy="no-referrer"></p><p>&nbsp;<span style="color:#000000">CLion Nova 目前確實的功能包括：</span></p><ul style="margin-left:0; margin-right:0"><li><strong>工具鏈</strong>：存在多種選項可用於在 CLion 中設置<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fclion%2F2023.3%2Fremote-development.html" target="_blank">遠程工作</a>。CLion Nova 支持本地資源的遠程工作，但瘦客户端 (Gateway)&nbsp; 的遠程工作尚不可用。</li><li><strong>語言</strong>：Objective-C 語言、CUDA（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FRSCPP-613" target="_blank">RSCPP-613</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-26144" target="_blank">CPP-26144</a>）和一些特定於供應商的編譯器擴展尚不受支持。</li><li>目前不支持某些 intentions 和 quick-fixes，例如&nbsp;Simplify 語句 (&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35879" target="_blank">CPP-35879</a>&nbsp;)。</li><li>一些流行度不高的 refactorings 也不支持。官方計劃稍後重新引入 Move<span style="background-color:#ffffff; color:#19191c"><span>&nbsp;</span>(</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35867" target="_blank">CPP-35867</a><span style="background-color:#ffffff; color:#19191c">) 和<span>&nbsp;</span></span>Inline Parameter<span style="background-color:#ffffff; color:#19191c"><span>&nbsp;</span>refactorings (</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35868" target="_blank">CPP-35868</a><span style="background-color:#ffffff; color:#19191c">)</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissue%2FCPP-35868" target="_blank">。</a></li><li>JetBrains 的 AI 助手尚不適用於 CLion Nova。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 11 Nov 2023 10:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/266295/jetbrains-clion-nova</guid>
            <link>https://www.oschina.net/news/266295/jetbrains-clion-nova</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[正式開源！網易有道上線 「易魔聲」 語音合成引擎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>剛剛，我們上線了「易魔聲」開源語音合成（TTS）引擎！🎉🎉🎉</strong></p><p>「易魔聲」，是一款有道自研 TTS 引擎，目前支持中英文雙語，包含<strong>2000 多種不同的音色</strong>，更有特色的情感合成功能，支持合成包含<strong>快樂、興奮、悲傷、憤怒</strong>等廣泛情感的語音。</p><p style="text-align:center"><strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fpan.baidu.com%2Fs%2F1Gl7irtGrXoqFwgox3UzlgA%3Fpwd%3Dtwck" rel="nofollow" target="_blank">「易魔聲」中文&nbsp; 網易有道</a></strong></p><p style="text-align:center">（我們用「易魔聲」將以上這段話進行了技術合成，點擊試聽 ）</p><p>用户可免費在開源社區 GitHub 進行下載使用（地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FEmotiVoice" rel="nofollow" target="_blank">https://github.com/netease-youdao/EmotiVoice</a>），通過我們提供的 web 界面、及批量生成結果的腳本接口，輕鬆實現音色的情感合成與應用。</p><p style="text-align:center"><img alt="" src="https://mp.weixin.qq.com/s/WktfW3t1O5vn4QJWoRVLuA" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-9d1543d602359db470e97a2559595b763a6.png" referrerpolicy="no-referrer"></p><p style="text-align:center">（<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FEmotiVoice" rel="nofollow" target="_blank">GitHub 開源界面</a></strong>，點擊藍字可跳轉）</p><p>在你過往的回憶裏，是不是也有一些特別的聲音，比如：偶像的聲音激勵人心、媽媽的聲音讓我們一秒回憶起小時候......聲音，作為語言維度的一種，總是藴含着人類充沛的情感表達。<strong>而富有情感的合成語音，是能夠為應用和內容增色的 AI 功能。</strong></p><p>現在通過「易魔聲」，簡單通過在文本中加入情感的描述提示，開發者或者內容創作者就可以自由合成符合自己需求的帶有情感的語音，比傳統 TTS 更加自然逼真！👍</p><p>「易魔聲」，是有道 AI 團隊今年開發的一個項目。隨着基於 GAN 等現代 AI 技術的語音能力越來越成熟，實現一個質量較高的 TTS 系統的門檻越來越低。但即使如此，中英雙語的高質量、現代 TTS 模塊還是不容易找到，要在自己的應用與內容中<strong>加入高逼真度且高度可控的語音，特別是中英雙語的語音，依然比較麻煩</strong>。</p><p>這也是我們將這個項目開源的初衷，希望能幫助有需求的開發者與內容創作者，並不斷擴大高質量 TTS 的應用範圍。<strong>目前該項目還處於初期階段，期待大家在</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FEmotiVoice" rel="nofollow" target="_blank"><strong>開源網站</strong></a><strong>給予我們更多反饋</strong>，我們非常希望聽到大家的使用體驗與建議💪，<strong>歡迎各位掃碼進羣交流～</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-95a884f5c1625d1bcc2e8d42937f33d0cb9.jpg" referrerpolicy="no-referrer"></p><p style="text-align:center"><strong>若二維碼失效，可掃描下方二維碼，添加我們工作人員的企業微信申請進羣~</strong></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c7306442e032ed93adbdf1a5fecf938d6b4.jpg" referrerpolicy="no-referrer"></p><p>藉此機會，我們也邀請您瞭解和探索有道的更多酷炫 AI 技術👇</p><ul><li>您可以嘗試我們的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.youdao.com%2Fpersonalized-voice.s" rel="nofollow" target="_blank"><strong>聲音定製和聲音復刻功能</strong></a>（點擊藍字即可試用）。從用户錄製到試聽整個過程只需 5 分鐘，即可完成個性化的聲音定製。</li><li>您也可以和**<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhiecho.youdao.com%2F%23%2Fweb" rel="nofollow" target="_blank">Hi Echo 虛擬人口語私教</a>**（點擊藍字即可跳轉）聊一聊。通過有道的「子曰」教育大模型、語音和虛擬人技術，Echo 可以陪你輕鬆練習地道的英語口語。每天練習 10 分鐘，口語水平快速提高哦。</li><li>您還可以微信搜索**「有道智雲體驗中心」小程序**。在這裏，可以訪問我們已經對開發者通過 API 等形式開放的文本和圖像翻譯、文字和各類圖片識別、作文批改等各類 AI 技術。</li></ul><p><strong>關於有道智雲</strong></p><p>有道智雲 AI 開放平台，是網易有道旗下一站式人工智能服務提供商，為開發者、企業和政府機構等提供自然語言翻譯、文字識別、OCR、語音識別等服務以及行業解決方案，致力於提供安全、可靠和高效的雲服務。</p><p>聯繫電話：010-8255-8901；商務合作：AIcloud_Business@corp.youdao.com.</p><p>想了解更多關於有道人工智能的內容，可訪問「有道智雲」官網👉<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.youdao.com%2F" rel="nofollow" target="_blank"><strong>https://ai.youdao.com</strong></a>.</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 11 Nov 2023 10:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/youdaotech/blog/10142807</guid>
            <link>https://my.oschina.net/youdaotech/blog/10142807</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[完蛋！我被 Out of Memory 包圍了！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><ul><li><p>是極致魅惑、灑脱自由的<code>Java heap space</code>？</p></li><li><p>是知性柔情、温婉大氣的<code>GC overhead limit exceeded</code>？</p></li><li><p>是純真無邪、活潑可愛的<code>Metaspace</code>？</p></li><li><p>如果以上不是你的菜，那還有……</p></li><li><p>刁蠻任性，無跡可尋的<code>CodeCache</code>！</p></li><li><p>性感火辣、心思細膩的<code>Direct Memory</code></p></li><li><p>高貴冷豔，獨愛你一人的<code>OOM Killer</code>！</p></li><li><p>總有一款，能讓你鍾情！BUG 選擇權，現在交由你手！</p></li></ul><p><img alt="image.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-02-10-57XocqTnPFlxTzDLX.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_1"></span><h1>Java heap space</h1><p>這是最常見的一個 OOM 問題了，誰還沒經歷過一個 Heap OOM 呢？</p><p>當堆內存被塞滿之後，一邊 GC 無法及時回收，一邊又在繼續創建新對象，Allocator 無法分配新的內存之後，就會送一個 OOM 的錯誤：</p><pre><code>java.lang.OutOfMemoryError: Java heap space

</code></pre><p>分析解決起來無非是那幾步：</p><ol><li><p>dump 堆內存</p></li><li><p>通過 MAT、YourKit、JProfiler 、IDEA Profiler 等一系列工具分析 dump 文件</p></li><li><p>找到佔用內存最多、最大的對象，看看是哪個小可愛乾的</p></li><li><p>分析代碼，嘗試優化代碼、減少對象創建</p></li><li><p>增加 JVM 堆內存、限制請求數、線程數、增加節點數量等</p></li></ol><span id="OSC_h3_2"></span><h3>常見類庫使用誤區</h3><p>尤其是一些工具庫，儘可能的避免每次新建對象，從而節省內存提升性能。</p><p>大多數主流的類庫，入口類都保證了單例線程安全，全局維護一份即可</p><p>舉一些常見的錯誤使用例子：</p><span id="OSC_h4_3"></span><h4>Apache HttpClient</h4><p>CloseableHttpClient ，這玩意相當於一個「瀏覽器進程」了，背後有連接池連接複用，一堆機制的輔助類，如果每次都 new 一個，不僅速度慢，而且浪費了大量資源。</p><p>比較正常的做法是，全局維護一個（或者根據業務場景分組，每組一個）實例，服務啓動時創建，服務關閉時銷燬：</p><pre><code>CloseableHttpClient httpClient = HttpClients.custom()
                .setMaxConnPerRoute(maxConnPerRoute)
                .setMaxConnTotal(maxConnTotal)
                /// ...
                                 .build();

</code></pre><span id="OSC_h4_4"></span><h4>Gson</h4><p>畢竟是 Google 的項目，入口類自然也是實現了線程安全，全局維護一份 Gson 實例即可</p><span id="OSC_h4_5"></span><h4>Jackson</h4><p>Jackson 作為 Spring MVC 默認的 JSON 處理庫，功能強大、用户眾多，xml/json/yaml/properties/csv 各種主流格式都支持，單例線程安全自然也是 ok 的，全局維護一份 ObjectMapper 即可。</p><span id="OSC_h1_6"></span><h1>GC overhead limit exceeded</h1><p>這個錯誤比較有意思，上面的 Java heap space 是內存徹底滿了之後，還在持續的創建新對象，此時服務會徹底假死，無法處理新的請求。</p><p>而這個錯誤，只是表示 GC 開銷過大，Collector 花了大量的時間回收內存，但釋放的堆內存卻很小，並不代表服務死了</p><p>此時程序處於一種很微妙的狀態：堆內存滿了（或者達到回收閾值），不停的觸發 GC 回收，但大多數對象都是可達的無法回收，同時 Mutator 還在低頻率的創建新對象。</p><p>出現這個錯誤，一般都是流量較低的場景，有太多常駐的可達對象無法回收，但是吧，GC 後空閒的內存還可以滿足服務的基本使用</p><p>不過此時，已經在頻繁的老年代 GC 了，老年代又大對象又多、在現有的回收算法下，GC 效率非常低並切資源佔用巨大，甚至會出現把 CPU 打滿的情況。</p><p>出現這個錯誤的時候，從監控角度看起來可能是這個樣子：</p><ol><li><p>請求量可能並不大</p></li><li><p>不停 GC，並切暫停時間很長</p></li><li><p>時不時的還有新的請求，但響應時間很高</p></li><li><p>CPU 利用率很高</p></li></ol><p>畢竟還是堆內存的問題，排查思路和上面的<code>Java heap space</code>沒什麼區別。</p><span id="OSC_h1_7"></span><h1>Metaspace/PermGen</h1><p>Metaspace 區域裏，最主要的就是 Class 的元數據了，ClassLoader 加在的數據，都會存儲在這裏。</p><p>MetaSpace 初始值很小，默認是沒有上限的。當利用率超過 40%（默認值 MinMetaspaceFreeRatio）會進行擴容，每次擴容一點點，擴容也不會直接 FullGC。</p><p>比較推薦的做法，是不給初始值，但限制最大值：</p><pre><code>-XX:MaxMetaspaceSize=

</code></pre><p>不過還是得小心，這玩意滿了後果很嚴重，輕則 Full GC，重則 OOM：</p><pre><code>java.lang.OutOfMemoryError: Metaspace

</code></pre><p>排查 MetaSpace 的問題，主要思路還是追蹤 Class Load 數據，比較主流的做法是：</p><ol><li><p>通過 Arthas 之類的工具，查看 ClassLoader、loadClassess 的數據，分析數量較多的 ClassLoader 或者 Class</p></li><li><p>打印每個 class 的加載日誌：<code>-XX:+TraceClassLoading -XX:+TraceClassUnloading</code></p></li></ol><p>下面介紹幾個常見的，可能導致 MetaSpace 增長的場景：</p><span id="OSC_h3_8"></span><h3>反射使用不當</h3><p>JAVA 裏的反射，性能是非常低的，以反射的對象必須得緩存起來。尤其是這個<code>Method</code>對象，如果在併發的場景下，每次都獲取新的 Method，然後 invoke 的話，用不了多久 MetaSpace 就給你打爆！</p><p>簡單的説，併發場景下，Method.invoke 會重複的動態創建 class，從而導致 MetaSpace 區域增長，具體分析可以參考笨神的文章《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fheapdump.cn%2Farticle%2F54786" rel="nofollow" target="_blank">從一起 GC 血案談到反射原理</a>》。</p><p>用反射時，儘可能的用成熟的工具類，Spring 的、Apache 的都可以。它們都內置了 reflection 相關對象的緩存，功能又全性能又好，足以解決日常的使用需求。</p><span id="OSC_h3_9"></span><h3>一些 Agent 的 bug</h3><p>一些 Java Agent，靜態的和運行時注入的都算。基於 Instrumentation 這套 API 做了各種增強，一會 load 一會 redefine 一會 remove 的，如果不小心出現 BUG，也很容易生成大量動態的 class，從而導致 metaspace 打滿。</p><span id="OSC_h3_10"></span><h3>動態代理問題</h3><p>像 Spring 的 AOP ，也是基於動態代理實現的，不管是 CgLib 還是 JDK Proxy，不管是 ASM 還是 ByteBuddy。最終的結果都逃不開動態創建、加載 Class，有這兩個操作，那 Metaspace 必定受影響。</p><p>Spring 的 Bean 默認是<code>singleton</code>的，如果配置為<code>prototype</code>，那麼每次 getBean 就會創建新的代理對象，重新生成動態的 class、重新 define，MetaSpace 自然越來越大。</p><span id="OSC_h1_11"></span><h1>Code Cache</h1><p>Code Cache 區域，存儲的是 JIT 編譯後的熱點代碼緩存（注意，編譯過程中使用的內存不屬於 Code cache），也屬於 non heap 。</p><p>如果 Code cache 滿了，你可能會看到這麼一條日誌：</p><pre><code>Server VM warning: CodeCache is full. Compiler has been disabled.

</code></pre><p>此時 JVM 會禁用 JIT 編譯，你的服務也會開始變慢。</p><p>Code Cache 的上限默認比較低，一般是 240MB/128MB，不同平台可能有所區別。</p><p>可以通過參數來調整 Code Cache 的上限：</p><pre><code>-XX:ReservedCodeCacheSize=

</code></pre><p>只要儘量避免過大的 Class、Method ，一般也不太會出現這個區域被打滿的問題，默認的 240MB/128MB 也足夠了</p><span id="OSC_h1_12"></span><h1>Direct Memory</h1><p>Direct Memory 區域，一般稱之為直接內存，很多涉及到，磁盤 I/O ，Socket I/O 的場景，為了「Zero Copy」提升性能都會使用 Direct Memory。</p><p>就比如 Netty ，它真的是把 Direct Memory 玩出了花（有空寫一篇 Netty 內存管理分析）……</p><p>使用 Direct Memory 時，相當於直接繞過 JVM 內存管理，調用 malloc() 函數，體驗手動管理內存的樂趣～</p><p>不過吧，這玩意使用比較危險，一般都配合 Unsafe 操作，一個不小心地址讀寫的地址錯誤，就能得到一個 JVM 給你的驚喜：</p><pre><code>#
# A fatal error has been detected by the Java Runtime Environment:
#
#  EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x00007ffdbd5d19b4, pid=1208, tid=0x0000000000002ee0
#
# JRE version: Java(TM) SE Runtime Environment (8.0_301-b09) (build 1.8.0_301-b09)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.301-b09 mixed mode windows-amd64 compressed oops)  
# Problematic frame:
# C  [msvcr100.dll+0x119b4]
# 
# No core dump will be written. Minidumps are not enabled by default on client versions of Windows
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.java.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#

</code></pre><p><img alt="image.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-02-10-369sm6Shj7lkLZQao.png" referrerpolicy="no-referrer"></p><p>更多的解釋，可以參考我這篇《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsegmentfault.com%2Fa%2F1190000020228048" rel="nofollow" target="_blank">Java 中的 Heap Buffer 與 Direct Buffer</a>》</p><p>這個 Direct Memory 區域，默認是無上限的，但為了防止被 OS Kill，還是會限制一下，給個 256MB 或者更小的值，防止內存無限增長：</p><pre><code>-XX:MaxDirectMemorySize=

</code></pre><p>如果 Direct Memory 達到 MaxDirectMemorySize 並且無法釋放時，就會得到一個 OOM 錯誤：</p><pre><code>java.lang.OutOfMemoryError: Direct buffer memory

</code></pre><span id="OSC_h1_13"></span><h1>Linux OOM Killer</h1><p>跳出 JVM 內存管理之後，當 OS 內存耗盡時，Linux 會選擇內存佔用最多，優先級最低或者最不重要的進程殺死。</p><p>一般在容器裏，主要的進程就是肯定是我們的 JVM ，一旦內存滿，第一個殺的就是它，而且還是 kill -TERM (-9) 信號，打你一個猝不及防。</p><p>如果 JVM 內存參數配置合理，遠低於容器內存限制，還是出現了 OOM Killer 的話，那麼恭喜你，大概率是有什麼 Native 內存泄漏。</p><p>這部分內存，JVM 它還管不了。</p><p>除了 JVM 內部的 Native 泄漏 BUG 這種小概率事件外，大概率是你引用的第三方庫導致的。</p><p>這類問題排查起來非常麻煩，畢竟在 JVM 之外，只能靠一些原生的工具去分析。</p><p>而且吧，這種動不動就要 root 權限的工具，可是得領導審批申請權限的……排查成本真的很高</p><p><img alt="image.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-02-10-39aqlx39acVlRQ29Qrm.png" referrerpolicy="no-referrer"></p><p>排查 Native 內存的基本的思路是：</p><ol><li><p>pmap 查看內存地址映射，定位可疑內存塊、分析內存塊數據</p></li><li><p>strace 手動追蹤進程系統調用，分析內存分配的系統調用鏈路</p></li><li><p>更換 jemalloc/tcmalloc 之類的內存分配器（或者 async-profiler 有個支持 native 分析的分支）追蹤 malloc 的調用鏈路</p></li></ol><p>目前最常見的 Native 內存泄漏場景，是 JDK 的 Inflater/Deflater 這倆卧龍鳳雛，功能是提供 GZIP 的壓縮、解壓，在默認 glibc 的 malloc 實現下，很容易出現「內存泄漏」。如果出現 Native 內存泄漏，可以先看看應用裏有沒有 GZIP 相關操作，説不定有驚喜。</p><hr><p>好了，各類風格的 OOM 都感受完了，到底哪一個更能打動你呢？</p><blockquote><p>作者：京東保險，蔣信</p><p>來源：京東雲開發者社區，轉載請註明來源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 11 Nov 2023 10:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10141303</guid>
            <link>https://my.oschina.net/u/4090830/blog/10141303</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【直播回顧】開源創業：要怎麼推廣項目，去哪裏找錢？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 8 日，OSCHINA 直播——【開源漫談】第 5 期，邀請了中國第一個人站長高春輝、禪道軟件公司創始人王春生、津津樂道創始人朱峯，聊了聊開源創業相關的話題，涉及開源協議、開源漏洞、項目捐贈、創業賽道等方向。</p><p>其中，關於開源協議的選擇、開源項目漏洞責任歸屬，以及是否要將開源項目捐贈給基金會，王春生已經在《<a href="https://my.oschina.net/oscpyaqxylk/blog/10114031">關於開源軟件的七大錯誤認知</a>》一文做了詳細解答。另外《<a href="https://my.oschina.net/u/6852546/blog/10118120">開源軟件有漏洞，作者需要負責嗎？是的！</a>》《<a href="https://my.oschina.net/oscpyaqxylk/blog/10140275">項目捐給了開源基金會，作者手上還剩了什麼？</a>》等文章也對相關問題進行了詳細分析，本文不再贅述，而是主要將關注點放在如何推廣開源項目，怎麼選擇創業賽道等等話題上。</p><p>想了解更多精彩內容，可以微信掃描下方二維碼，觀看完整直播：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28f36ff6e308f95d2736438e921e43f2dca.png" referrerpolicy="no-referrer"></p><span id="OSC_h3_1"></span><h3><span style="color:#3498db"><strong>01 自己的開源項目，能不能拿來創業？</strong></span></h3><p><strong>朱峯：</strong>怎麼判斷自己的開源項目能不能拿來創業？</p><p><strong>王春生：</strong>首先，軟件一定要有價值，能夠幫助用户解決問題，這是一個大前提，不管是什麼方向的創業，這是基本的。</p><p>二是要考慮軟件面向的用户羣體。如果你的開源軟件純粹是面向開發者，那麼將很難實現商業上的轉化。如果是面向企業內部的，這個方向還是有大作為的。</p><p>現在也一些很好的方向，比如工業化這塊，有技術的可以朝着這個方向發展，這也是屬於國家「卡脖子」的技術領域，是能夠賺到錢的。我一個朋友做了一個仿真相關領域的開源平台，前段時間拿到了投資。未來這些方向還有很大機會。</p><p>不是説 to c 屬性不能做，但你要拿來創業，最好不要去碰 to c 屬性的開源軟件。因為 to c 屬性的產品，已經有互聯網大廠在跟進，他們的打法是個人完全沒辦法複製的。</p><p><strong>朱峯：</strong>老高你認為如何？當初做 ECShop（國內第一個開源的電商建站軟件） 的時候，國內還沒有這麼健全的開源生態。是怎麼想到要將 ECShop 開源的？</p><p><strong>高春輝：</strong>開源確實是能夠吸引很多用户。但項目和公司能否持續，和你開源不開源關係並不大，跟商業模式本身是否健康有很大關係。當時最有意思的一個事兒，是做網站模板的，也就是做外圍工作的能賺錢，但我們做軟件的人並不賺錢。</p><p>國內國外對開源的認可度是不一樣的。在國內，用户很大可能就想省錢，你開源了，我就用你的開源版本，寧可自己改一改，也不願意花錢。但國外對開源軟件付費認可度會更高。同樣一個軟件，國外有人能成立公司，能成功，在國內可能不會那麼順利。</p><p>我們當時還有一個大問題，就是我們的軟件，自始至終都是自己人在做開發。開源只是開放的源代碼，真正願意來貢獻代碼的人非常少。</p><p><strong>朱峯：</strong>如果我沒有記錯的話，你做 ECShop 的時候開源生態還沒有現在這麼好。</p><p><strong>高春輝：</strong>那時候沒有。但我覺得，就是國內有了好的開源生態，可能情況也不會好很多。軟件複雜度上來以後，真的願意花時間把軟件看懂，並在上面貢獻的人也很少。現在 GitHub 比較火的項目，貢獻多的大多是全職開發者，個人貢獻者能有幾個？大家都很忙，工作 996 ，回家了只想睡覺。在國內做開源還是要審慎。</p><span id="OSC_h3_2"></span><h3><span style="color:#3498db"><strong>02 免費用户提需求，心態是怎樣嗎？</strong></span></h3><p><strong>朱峯：</strong>很多時候免費用户會提出一些功能改進、BUG 修復、技術支持等要求，你們在遇到這些問題的時候，心態是怎麼樣的？我記得當年老高搞 ECShop，也有很多用户提各種各樣的需求，然後還催着趕緊搞定。作為開發者，在這個時候心裏會不會有一點點不舒服？</p><p><strong>高春輝：</strong>我覺得我的心態分成兩個階段，第一個階段是很開心，因為有人給你提需求。但後面會發現，一旦你的資源不夠，他提需求還用道德綁架的口吻來跟你聊，你就會覺得不爽了。這個東西我是免費的，你憑什麼逼着我去做這個功能？</p><p>現在有些開源的維護者寫的文章非常灰心喪氣。原因很多，一是自己花了很多精力時間去維護這個軟件，二是沒有報酬，三是有些大公司用了他的東西，也沒有什麼支持。</p><p><strong>朱峯：</strong>春生怎麼看這件事情？今天整個開源生態的情況跟當年老高那會兒又不太一樣，你看到免費用户的這些訴求是怎麼樣的？</p><p><strong>王春生：</strong>首先，有人用肯定是好事情。我經常辦一些線下商務活動，很多用户都會跟我説，他們用禪道很久了，一直也沒付費，其實挺不好意思的。但我説，這就很好，你們用我們的軟件，就是對我們最大的支持。他可能在當時不會買，但是員工會流動，會帶着禪道到新公司，產生新的機會。所以從這一點來講，有用户來提需求，提 bug，然後甚至有可能 diss 你等等，我覺得這都是好事情，就説明軟件是真的有人在用，有人在乎你。如果你發佈一個產品，都沒人反饋，那就是另外一個悽慘的故事了。</p><p>第二，要區分對待用户需求，同時也要有引導。對同一件事，大家的價值認知其實是不太一樣的。站在提需求或者提 bug 的用户角度，我已經對你的產品付出了很多心血，花了很大的力氣來跟你討論，還幫你提建議，提改進，你們應該立即去響應，處理這些問題。</p><p>站在開發者角度，正如老高所説的，資源確實是有限的，沒辦法響應所有需求。我覺得還是要保持平常心，因為不可能讓每人都完全贊同。</p><p>面對用户的需求和反饋，還是需要甄別。不能被用户的反饋影響你產品的發展方向，得要有自己的主線。有的需求非常合理，邏輯也非常自洽，但只是代表的是一小部分的場景，放在通用產品角度來看，就不見得合適。如果梳理出來的需求，是絕大多數用户都有可能能用到的，那麼就要第一時間去響應，然儘可能快地處理。此外，對於一些通用性可能並沒有那麼強的功能需求，我們也可以通過插件的方式來解決。</p><span id="OSC_h3_3"></span><h3><span style="color:#3498db"><strong>03 做產品變成了二次開發的外包公司，你們怎麼看？</strong></span></h3><p><strong>朱峯：</strong>談到二次開發也是一個挺有意思的話題，很多的做產品的公司最後都變成了做二次開發的外包公司。你怎麼看待這件事？</p><p><strong>王春生：</strong>我覺得要抵住誘惑，尤其是剛開始的時候。</p><p><strong>朱峯：</strong>但是這個誘惑往往很難抵得住，當你沒有錢的時候，人家拍給你幾十萬讓把這事兒給幹了，你説你能不幹嗎？</p><p><strong>王春生：</strong>我們也遇到過，這會讓我們不停懷疑自己，走的方向是不是正確的，再重新堅定，然後再重新懷疑，再重新堅定，再重新懷疑，一直處於這樣的過程中。</p><p>這麼些年，不斷地會有客户提出定製需求，訂單金額少則十幾萬、幾十萬，多的可能過百萬。做還是不做，確實是一個很大的選擇。我的建議是，定製開發可以做，但是不要影響產品發展的主線，不要被定製開發項目拉歪整個團隊的方向。如果定製開發的項目龐大，我們一般都不接；要求駐場我們也不接。人力有限，大項目很可能把整個團隊都給拖過去，挺要命的。</p><span id="OSC_h3_4"></span><h3><span style="color:#3498db"><strong>04 怎麼推廣自己的開源軟件？</strong></span></h3><p><strong>朱峯：</strong>怎麼讓你的開源項目有更多的人用，有更多人能參與其中？</p><p><strong>王春生：</strong>一是 release often，就是儘可能早、儘可能快地發佈。開源軟件天然就有這種屬性，通過快速、持續地產品交付，就能自然而然地獲得用户關注。新產品總是會有早期的種子用户，會很喜歡去嘗試一些新的東西。禪道早期也是這麼起來的。</p><p>比如一個以 GitHub 為內容來源的公眾號，為了流量，它會定期地去挖掘一些比較好的項目並對外宣傳，這就相當於有人去幫你做這個事情。</p><p>除了在產品方面儘可能早地發佈，還要去寫文章進行宣傳，當時我們也在開源中國做了很多推廣，對我們有很大的幫助。同時也在其他地方比如一些新聞網站做 SEO 優化，交換鏈接，參與活動，贊助等等，一些常規的運營手段都得用起來。</p><p>所以説，在早期的時候，開源軟件作者在埋頭寫產品之外，還是要花一定的心思在運營上。有人認為產品做出來之後，用户自然而然就來了，這不太現實。</p><p><strong>高春輝：</strong>做開源軟件跟做網站，沒有本質的區別，它就是一個產品。產品推廣，無非是看它的用途和你的受眾。你的受眾是做電商的，那你就要找這個圈子去曝光你的新功能，特性，用户會很好奇地去使用。</p><p>當年的做電商有兩個思路：是跟着淘寶混還是自己做個站？</p><p>為了流量，大家都會選擇淘寶。只有大公司才有可能會建自己的電商站，但維護很重。我們當時接過摩托羅拉項目，建個站然後通過廣告引流，促成銷售，但最後摩托羅拉還是選擇了淘寶、京東渠道。因為對他們來説，不管是淘寶還是個站，最後只要能夠實現銷售額就可以。</p><p>至少在那個時候，有個站在自己的控制之下，用户是有興趣去嘗試的。國內用户都喜歡把數據放在自己手裏，喜歡私有化部署，如果相關功能做得好，其實是很有吸引力的。</p><p><strong>朱峯：</strong>去建立個人影響力，建立自己的個人品牌，我覺得是合適的。如果你自己是一個自帶流量的 KOL，去推自己的項目往往會事半功倍。但如果你是一個悶頭寫代碼的素人，這件事情可能就比較難。</p><p>現在流量太貴了，買流量投廣告去推廣開源項目，顯然不現實。所以你怎麼把信任你的人留存在自己的私域裏，把自己就變成了一個 KOL，這個事情才重要。</p><p>剛才春生也提到，他早先用三分之一時間開發，三分之一時間寫文檔，三分之一時間寫文章。為什麼他要用三分之一時間寫文章？他就是要建立自己的影響力，因為只有個人私域自帶的流量才真正是你的流量，才能夠為你當前的項目，甚至説以後的項目去做轉化。</p><span id="OSC_h3_5"></span><h3><span style="color:#3498db"><strong>05 軟件開源，培訓收費，這個思路可行嗎？</strong></span></h3><p><strong>朱峯：</strong>有直播間網友提問，軟件開源，培訓收費，這個思路可行嗎？</p><p><strong>高春輝： </strong>那成本會很高的。除非你是在線培訓，或者是錄製好的課程，但錄製好的課程一旦泄露出去，也很麻煩。</p><p><strong>王春生：</strong>你讓我提建議的話，那就是不要想着通過技術支持或者培訓去收費。</p><p><strong>高春輝：</strong>對，還得通過產品本身掙錢。</p><p><strong>王春生：</strong>這塊兒我想多説幾句。我覺得很多開源開發者對技術支持這件事情理解得不太正確。我所接觸的很多些開源軟件的微信羣、QQ 羣，全是網友自己在互相抱團取暖，官方作者基本上不出來回答問題。</p><p>作者會認為，軟件是免費的，有 FAQ（Frequently Asked Questions，常見問題解答），有文檔，甚至可能還錄了視頻，該做的我都做了，你要想解決問題，就應該自己動手。我接觸過很多的開源軟件作者，基本上都是這麼一種心態。如果開源作者只是為了自己的興趣而開發軟件，這麼做是完全沒問題的。</p><p>但如果要做商業化，還是要把這些用户當做潛在客户去對待，認真地、紮紮實實地給人家提供技術支持，讓他把產品用起來，讓他感知到你和團隊是在認真做產品，做事情。這樣才有可能跟用户之間建立起信任，才有可能去做下一步商業上的轉化。</p><p>你想，我們進店吃飯，店員愛理不理地説，筷子在這兒，茶水在那兒，甚至鍋灶在那兒，你可以自己炒，你肯定就不開心了。雖然目前我沒有付費，你怎麼知道我將來就不會付費？</p><p>所以我們的策略就是，對開源版本投入大量的人力和資源，甚至會要求第一時間響應開源版本的免費用户。對開源用户做好支持了，才有源源不斷的用户，才會產生收費版本的需求。</p><span id="OSC_h3_6"></span><h3><span style="color:#3498db"><strong>06 禪道掙到錢了嗎？</strong></span></h3><p><strong>朱峯：</strong>做開源項目到底掙不掙錢？禪道掙錢了嗎？盈利方面有沒有向好的趨勢？</p><p><strong>王春生：</strong>早期的話，真的是在用愛發電，苦哈哈地做開源。從 2012 年下半年開始，現金流基本上已經盈虧平衡了。</p><p>2011 年的時候，我們是十多人的一個小團隊，已經有一定的支出了，確實遇到了資金不足的問題。老高二話不説就打了第一筆錢，是我的天使投資人。 到了年底，其他幾位股東也陸陸續續湊了一筆錢，準備好了 2012 年的運營費用，決定開始招聘銷售、技術支持等等崗位上的人才。當時做了打算，成不成就看這一把了。如果不行了，就再去打工。</p><p>在 2012 年的上半年，我們就推出了第一個收費版本，到了下半年，現金流基本上就實現了盈虧平衡。</p><p><strong>朱峯：</strong>老高當年的 ECShop 是怎麼賺錢的？</p><p><strong>高春輝：</strong>軟件本身不賺錢，靠賣了賺錢。那時候做 ECShop 是 2006 年左右，電商在國內還不被看好。沒有錢怎麼辦？那時候肯定去融資。結果跟投資人聊了大概十分鐘，人家就説，十年內中國電商都不會有什麼大的發展。這就把我説泄氣了，那就賣了吧。</p><p>那時候淘寶、京東在往上走了，但大家都不知道它能做多大。現在你回頭看， ECShop 模式在國內確實會有天花板。因為國內都是走平台策略，流量給平台拉走了，單店的模式基本上不會有太多用户。反而做淘寶的生態服務商會有更大的發展空間。但它的天花板也很低，每年能賺錢但有限，想上市基本沒戲。</p><span id="OSC_h3_7"></span><h3><span style="color:#3498db"><strong>07 創業去哪裏找錢？</strong></span></h3><p><strong>朱峯：</strong>大家都知道這幾年，創業行情不是特別好，想找一些投資人更是尤為困難。請兩位老兵跟大家聊聊怎麼找錢的事兒。</p><p><strong>高春輝：</strong>我當時投資禪道的錢，也是到處湊出來的。春生要再多，我也給不起了。錢當時湊得也比較難，但是對我來説，就算都給虧光了，公司關門了，我也還好。當時我覺得，春生只要能夠認真做，不走錯，他就能賺錢。</p><p>至於現在，我覺得就別想着去融資這個事，先踏踏實把這個東西先做出來，哪怕利用這業餘時間做，把它跑起來，你的壓力就小很多。</p><p>千萬不要以為，你拿了錢之後壓力會小，你拿了錢壓力會變大。因為現在的投資幾乎就都是有連帶擔保的。但凡是你求 vc 的，連帶擔保是跑不了的。 我前幾天看到一個廣東的創業者説，醫保攢的錢都被投資人凍結了，理論上這是救命錢。也不多，可能就幾萬塊錢，但是連醫保卡的錢都不放過，你想這個錢好拿嗎？</p><p><strong>朱峯：</strong>春生在疫情期間拿到了投資，這一輪融資估值還不低。那在這個過程當中，你是怎麼去選擇這些投資人？</p><p><strong>王春生：</strong>也是機緣巧合，朋友介紹促成的。我們的投資人是高成資本，是中國專注於企服賽道的投資機構。彼此之間都非常認同：高成資本對我們的經營方式比較認同，我們對高成資本的投資理念也非常認同。高成資本創始合夥人洪婧是對企服賽道非常瞭解，而且投的都是長期項目。</p><p>到今天來看，其實大家都不太看好企服賽道這個大方向了。因為受中美關係、經濟環境等各方面的影響，企服賽道正處於低谷期。風險投資商更關注硬科技、人工智能這些方向，所以現在想拿錢不太容易。再一個，美元基金基本上都撤了，人民幣基金投資比較謹慎。</p><p>如果你想創業的話，我覺得這時候不是一個好時機。</p><p><strong>高春輝：</strong>我個人覺得這個時候適合積蓄力量。你可以做事兒，不要去融資。</p><span id="OSC_h3_8"></span><h3><span style="color:#3498db"><strong>08 一個有 4000 多 star 的開源聊天軟件，怎麼往下走？</strong></span></h3><p><strong>朱峯：</strong>直播間有網友問題，他有一個開源項目，是一個聊天軟件，有 4000 多，的 star，要怎麼往下走，能給點兒建議嗎？</p><p><strong>王春生：</strong>我覺得還是要收費。通過開源版和收費版，把軟件功能區分開。 在國內，經常會有一些説法：中國企業不樂意為軟件付費。我認為這個觀點是錯誤的。我所接觸的客户，再小的客户，都非常樂意為軟件付費。不過有個前提，就是這個軟件需要具備很高的性價比。如果人家花個幾千塊或者兩三萬的費用就能解決一個問題，哪怕企業規模不是很大，還是會樂意掏錢。現在很多企服賽道軟件不太好賣。為什麼？因為動不動一個人一年的授權就要好幾千，這個價格，很多消費者真的接受不了。</p><p>一個聊天軟件有 4000 多，的 star，首先就有了比較好的基礎，可以嘗試去推收費的版本。</p><p><strong>朱峯：</strong>那如果他賣付費版本了，但是收入不高，那你怎麼辦？</p><p><strong>高春輝：</strong>他得先去想，那些給他打 4000 多個 star 的人的想法是啥。人家都有動手能力，就不需要買付費版。你的軟件越專業，用户付費的可能性才越大。你的軟件簡單安裝就能用，願意付費的人可能就會很少。</p><p><strong>王春生：</strong>我們也有一個聊天的軟件，叫喧喧，最開始也是開源的，後來沒用開源方式去做。一年下來，有零零星星的收入，沒幾個錢，也就能把我們開發團隊的工資賺出來。我覺得這可能是跟方向有關係，因為現在國內企業微信、釘釘、飛書太強了。</p><p>但我覺得也不要灰心，還是要找準自己的定位，就是跟其他軟件的不同點是什麼，不要把東西做得跟別人一樣。飛書有什麼功能，釘釘有什麼功能，我們也要有這些功能，這是不行的，一定要有自己的差異點，把自己的這個定位搞清楚，面向的是什麼樣的用户場景。比如轉轉打入軍工行業，那它就做最安全的私有部署軟件。</p><p>這純粹是當參考哈，因為我們也沒有完全做出來，也還在摸索方向。</p><p>第二，從經營上來講，經營企業，確實會有很多的事情，需要你耐心去打磨。比如説定價策略。很多開源軟件作者特別具有程序員特質，定價非常直爽，100 塊錢或者 1000 塊錢就能買終身版，或者定個 1000 塊的早鳥價，後期還會再漲價。</p><p>就這種定價方式而言，太過於草率。定價是有技巧的。比如在超市，有個東西價格比較貴，但它會襯託另一個價格更低的產品很實惠，這是一種策略；還有一種就是打包策略，在麥當勞、肯德基，花了 20 塊錢就買了一個漢堡，再多花兩三塊錢就能得到一包薯條或者一杯可樂，消費者就會覺得很實惠。</p><p>有觀點認為，定價就相當於定生死。定價，就決定了產品在市場上面向的用户羣體、銷售模式、商業模式、漏斗轉化模式。在企服賽道，有的產品賣得非常貴，一個人一年授權是幾千塊錢，甚至國外產品一個人一年的授權能賣到 2 萬塊錢。但人家可以賣，我們就賣不了，而且人家賣的體量要比我們大太多了。所以還是要找準自己的市場。</p><span id="OSC_h3_9"></span><h3><span style="color:#3498db"><strong>09 出現負面輿情，怎麼公關？</strong></span></h3><p><strong>朱峯：</strong>出現負面輿情，你怎麼去公關？這對於開源軟件還挺重要的。</p><p><strong>王春生：</strong>早些年發佈禪道的時候，確實有很多人説，市面上已經有很多開源的缺陷管理工具，bug 管理工具，為什麼還要重新造輪子。那時候是要花一部分的精力來回應這些質疑和吐槽的聲音。</p><p>很多朋友在勸我，説沒必要去理會這些。但我説一定要正面去迴應，站在我的角度給大家解釋，可能產品有不盡人意的地方，但也不像你説的那麼不堪。</p><p>正面迴應，最重要的不是讓這個人去認同你的觀點，而是要給「旁觀者」信心。站在旁觀者角度，軟件作者不正面迴應的話，就會覺得產品真的有問題，肯定會去對產品失去信心，有句話叫三言成虎嘛！</p><p>禪道是我的飯碗，是我們整個團隊衣食住行的來源，所以我一定會正面迴應，去影響旁觀的用户，這還是蠻關鍵的。</p><p><strong>高春輝：</strong>這讓我想起來個事，嚴格地講是被敲詐。 他説：「我知道你這個地方有漏洞，是你給我錢我幫你修復好，還是我把它賣給別人？」</p><p>最後我們認栽。還好就那個錢並不多，人家也不是為了指望你給他掙多少錢，我們也覺得，花錢把這個問題消滅在萌芽之中也沒有錯。畢竟代碼可能有幾萬行，有時候真的沒法面面俱到，也很難一下就發現。能找上門願意跟你談的，都算是給你幫忙。要是被別有用心的人拿在手裏，那可能給你的打擊會更大。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 11 Nov 2023 09:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10142795</guid>
            <link>https://my.oschina.net/u/3859945/blog/10142795</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
    </channel>
</rss>
