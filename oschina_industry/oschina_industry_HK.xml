<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 30 Dec 2023 02:52:50 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Infinigen —— 無限高質量 3D 數據生成器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Infinigen 是無限高質量 3D 數據生成器，使用程序生成的無限逼真世界。這些數據 100% 通過程序化生成，不需要外部資產，也不依賴 AI，並且是免費開源的，生成質量非常高，據稱可以達到以假亂真的地步，甚至是花瓣上的皺紋都可定製。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-89f0a56c9b3a6cc8ff8cedb7501aecff0e0.png" referrerpolicy="no-referrer"></p><p>Infinigen 由普林斯頓視覺和學習實驗室開發：</p><ul><li>基於 Blender 編寫</li><li>每個小細節都是隨機的和可定製的，甚至是花瓣上的皺紋</li><li>自然界中多樣的物體和場景：植物、動物、地形；火、雲、雨和雪</li><li>Groundtruth 自動標註：光流、3D 場景流、深度、表面法線、全景分割、遮擋邊界</li></ul><p>其主要特性和功能包括：</p><p>1. 程序化：Infinigen 是一個程序生成器，它完全使用隨機的數學規則來創建所有的形狀和材料，從宏觀結構到微觀細節。Infinigen 可以創建無限的變化。用户可以通過覆蓋隨機化的默認參數來完全控制資產的生成。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f9d8159ed3837b185ace5578b1e2d6b0973.png" referrerpolicy="no-referrer"></p><p>2. 多樣化：Infinigen 為自然世界中的多樣化對象和場景提供生成器，包括植物、動物、地形，以及火、雲、雨、雪等自然現象。當前對自然的關注是由於觀察到哺乳動物的視覺在自然世界中進化。然而，預計 Infinigen 將隨着時間的推移擴展到覆蓋建築環境和人造物體。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e4874348efa3dd1ae71f5d170027ed35b43.png" referrerpolicy="no-referrer"></p><p>3. 真實的幾何形狀：Infinigen 針對計算機視覺研究進行了優化，特別是 3D 視覺。Infinigen 不使用 bump/normal-maps、全透明度或其他偽造幾何細節的技術。Infinigen 的所有細微的幾何細節都是真實的，確保了精確的 3D 地面真實性。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2579dc0164572ce5aa1add312a321e16803.png" referrerpolicy="no-referrer"></p><p>4. 自動註釋：Infinigen 可以自動生成各種計算機視覺任務的高質量註釋，包括光流、3D 場景流、深度、表面法線、全景分割、遮擋邊界。因為用户可以完全訪問渲染過程，所以註釋很容易定製。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cbb0ac43739fd281ebc6ccdd23cead6aff3.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:40:45 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/infinigen</guid>
            <link>https://www.oschina.net/p/infinigen</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 嵌入式軟件平台框架 VSF]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-vsf----versaloon-software-framework" class="anchor" href="https://gitee.com/vsfteam/vsf#vsf----versaloon-software-framework"></a>VSF -- Versaloon Software Framework</h1><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Fblob%2Fmaster%2FLICENSE"><img src="https://img.shields.io/github/license/vsfteam/vsf.svg" alt="GitHub" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fwindows-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/windows-build.yml/badge.svg" alt="windows-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fcmake-native-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/cmake-native-build.yml/badge.svg" alt="cmake-native-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fcmake-arm-cross-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/cmake-arm-cross-build.yml/badge.svg" alt="cmake-arm-cross-build" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fwindows-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/windows-build.yml/badge.svg?branch=vsf-sync" alt="vsf.linux windows build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fcmake-arm-cross-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/cmake-arm-cross-build.yml/badge.svg?branch=vsf-sync" alt="cmake-arm-cross-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fcmake-native-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/cmake-native-build.yml/badge.svg?branch=vsf-sync" alt="cmake-native-build" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/vsfteam/vsf/blob/master/README.md">English</a> |</p><p>VSF 全稱是 Versaloon Software Framework，是一個基於 Apache2.0 協議的開源嵌入式軟件平台框架。包含了從底層硬件的 hal 驅動、搶佔式多任務內核、各種服務和組件。全部代碼使用 C 語言，以及面向對象的方式實現。</p><h2><a id="user-content-整體框架" class="anchor" href="https://gitee.com/vsfteam/vsf#%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6"></a>整體框架</h2><h2><a id="user-content-目錄" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%9B%AE%E5%BD%95"></a>目錄</h2><table><thead><tr><th>目錄名</th><th>描述</th></tr></thead><tbody><tr><td>document</td><td>文檔</td></tr><tr><td>doxygen</td><td>doxygen 配置</td></tr><tr><td>example</td><td>示例代碼</td></tr><tr><td>hardware</td><td>VSF 開發板硬件資料</td></tr><tr><td>patch</td><td>一些補丁（第三方庫補丁等等）</td></tr><tr><td>script</td><td>一些工具腳本</td></tr><tr><td> cmake</td><td>cmake 工具腳本</td></tr><tr><td>source</td><td>VSF 源代碼</td></tr><tr><td> component</td><td>組件（文件系統、協議棧、UI、外部芯片驅動）</td></tr><tr><td> hal</td><td>硬件抽象層（芯片 arch 支持、芯片驅動）</td></tr><tr><td> kernel</td><td>內核</td></tr><tr><td> osa_service</td><td>依賴內核的軟件服務組件</td></tr><tr><td> service</td><td>軟件服務組件</td></tr><tr><td> shell</td><td>「皮膚」</td></tr><tr><td> utilities</td><td>基礎軟件工具（一些預處理功能、編譯器支持、列表等等）</td></tr></tbody></table><h2><a id="user-content-內核" class="anchor" href="https://gitee.com/vsfteam/vsf#%E5%86%85%E6%A0%B8"></a>內核</h2><p>基於事件驅動的搶佔式多任務內核，支持 51、8bit MCU、32/64 bit arm、riscv、x86 等等各種構架的芯片。</p><ul><li>事件驅動，有事件運行，沒事件休眠</li><li>搶佔模式下，任務切換由硬件實現，任務優先級就是硬件 swi（software interrupt）的優先級</li><li>不同優先級搶佔，同一優先級協作</li><li>可以運行在其他系統或者 RTOS 中，也可以運行在一個或者幾個 SWI 中斷中（和其他 RTOS 並存）。</li><li>多種任務形式
<ul><li>事件處理任務 -- 最小資源佔用，最簡配置下佔用 20 字節 ram，常用配置下佔用 40 字節 ram</li><li>pt 任務 -- 接近獨立堆棧任務開發方式的共享堆棧任務</li><li>獨立堆棧任務 -- 依賴 libc 中的 setjmp 庫</li><li>fsm 狀態機任務</li><li>「皮膚」中的其他任務封裝形式，比如 pthread</li></ul></li><li>信號量、互斥量、觸發器、隊列等等常用 IPC 工具</li></ul><h2><a id="user-content-組件" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%BB%84%E4%BB%B6"></a>組件</h2><ul><li>合理的框架設計，軟件高度可以複用</li><li>儘可能提供申明式的開發方式</li><li>標準化接口，第三方軟件一次性移植，全平台適配</li><li>軟件組件/框架
<ul><li>distbus -- 分佈式總線框架</li><li>fifo</li><li>heap</li><li>json</li><li>pool -- 內存池</li><li>stream -- 流接口</li><li>trace</li></ul></li><li>組件
<ul><li>fs -- 文件系統，支持 VFS（可使用第三方的文件系統）</li><li>input -- 輸入系統</li><li>mal -- 塊設備</li><li>scsi -- SCSI 設備</li><li>tcpip -- TCPIP 協議棧以及 netdrv 網絡設備（可使用第三方的 TCPIP 協議棧）</li><li>ui -- UI 以及顯示設備（可使用第三方的 GUI）</li><li>usb -- USB 主從機協議棧</li><li>bt -- 藍牙協議棧（使用第三方的 btstack）</li></ul></li></ul><h2><a id="user-content-硬件抽象層" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82"></a>硬件抽象層</h2><ul><li>標準 hal 接口，統一 API -- 比如：vsf_spi_init 可以用於所有 VSF 中支持的 SPI，包括芯片自帶 SPI、GPIO 模擬的 SPI、通過 USB 外擴的 SPI，通過分佈式總線訪問的遠端 SPI</li><li>簡化開發的 IP 核驅動 -- 移植僅需要實現時鐘、復位、中斷等等 IP 核心之外的功能</li><li>各種接口封裝模板</li><li>接口
<ul><li>PM</li><li>GPIO</li><li>SPI</li><li>I2C</li><li>PWM</li><li>ADC</li><li>SWI</li><li>USART</li><li>FLASH</li><li>USB</li><li>ethernet</li></ul></li></ul><h2><a id="user-content-皮膚" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%9A%AE%E8%82%A4"></a>「皮膚」</h2><p>「皮膚」可以把 VSF「偽裝」成其他系統，使得可以直接使用基於其他系統的應用代碼。</p><ul><li>SDL -- 可以直接使用一些基於 SDL 的應用層代碼</li><li>linux -- 可以直接使用一些基於 linux 的應用層代碼
<ul><li>posix</li><li>devfs</li><li>socket</li><li>console</li><li>一些 lib 庫的實現
<ul><li>libusb</li><li>libgen</li></ul></li></ul></li></ul><h2><a id="user-content-第三方" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%AC%AC%E4%B8%89%E6%96%B9"></a>第三方</h2><table><thead><tr><th>名字</th><th>路徑</th><th>許可</th><th>鏈接</th></tr></thead><tbody><tr><td>btstack</td><td>source/component/3rd-party/btstack/raw</td><td>Other</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fbluekitchen%2Fbtstack">https://github.com/bluekitchen/btstack</a></td></tr><tr><td>coremark</td><td>source/component/3rd-party/coremark/raw</td><td>Apache</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Feembc%2Fcoremark">https://github.com/eembc/coremark</a></td></tr><tr><td>freetype</td><td>source/component/3rd-party/freetype/raw</td><td>FreeType</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Ffreetype.org%2F">https://freetype.org/</a></td></tr><tr><td>zlib</td><td>source/component/3rd-party/zlib/raw</td><td>zlib</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fzlib.net%2F">http://zlib.net/</a></td></tr><tr><td>nuklear</td><td>source/component/3rd-party/nuklear/raw</td><td>MTI</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FImmediate-Mode-UI%2FNuklear">https://github.com/Immediate-Mode-UI/Nuklear</a></td></tr><tr><td>nnom</td><td>source/component/3rd-party/nnom/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmajianjia%2Fnnom">https://github.com/majianjia/nnom</a></td></tr><tr><td>lua</td><td>source/component/3rd-party/lua/raw</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.lua.org%2F">https://www.lua.org/</a></td></tr><tr><td>lwip</td><td>source/component/3rd-party/lwip/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fsavannah.nongnu.org%2Fprojects%2Flwip%2F">https://savannah.nongnu.org/projects/lwip/</a></td></tr><tr><td>libpng</td><td>source/component/3rd-party/libpng/raw</td><td>PNG2</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flibpng.sf.net">https://libpng.sf.net</a></td></tr><tr><td>libjpeg-turbo</td><td>source/component/3rd-party/libjpeg-turbo/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flibjpeg-turbo.org%2F">https://libjpeg-turbo.org/</a></td></tr><tr><td>SDL_ttf</td><td>source/shell/media/sdl2/3rd-party/SDL_ttf</td><td>zlib</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fhg.libsdl.org%2FSDL_ttf%2F">https://hg.libsdl.org/SDL_ttf/</a></td></tr><tr><td>SDL_image</td><td>source/shell/media/sdl2/3rd-party/SDL_image</td><td>zlib</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fhg.libsdl.org%2FSDL_image%2F">https://hg.libsdl.org/SDL_image/</a></td></tr><tr><td>lvgl</td><td>source/component/3rd-party/lvgl/raw/lvgl</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flvgl.io%2F">https://lvgl.io/</a></td></tr><tr><td>lv_lib_freetype</td><td>source/component/3rd-party/lvgl/extension/lv_lib_freetype/raw</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flvgl.io%2F">https://lvgl.io/</a></td></tr><tr><td>CMSIS</td><td>source/utilities/compiler/arm/3rd-party/CMSIS</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FARM-software%2FCMSIS_5">https://github.com/ARM-software/CMSIS_5</a></td></tr><tr><td>evm</td><td>source/component/3rd-party/evm/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fscriptiot%2Fevm">https://github.com/scriptiot/evm</a></td></tr><tr><td>LingLongGUI</td><td>source/component/3rd-party/LingLongGUI/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/gzbkey/LingLongGUI">https://gitee.com/gzbkey/LingLongGUI</a></td></tr><tr><td>PLOOC</td><td>source/utilities/3rd-party/PLOOC/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FGorgonMeducer%2FPLOOC">https://github.com/GorgonMeducer/PLOOC</a></td></tr><tr><td>mbedtls</td><td>source/component/3rd-party/mbedtls/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Ftls.mbed.org%2F">https://tls.mbed.org/</a></td></tr><tr><td>GuiLite</td><td>source/component/3rd-party/GuiLite/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fidea4good%2FGuiLite">https://github.com/idea4good/GuiLite</a></td></tr><tr><td>Segger_RTT</td><td>source/component/3rd-party/segger/raw/RTT</td><td>segger</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwiki.segger.com%2FRTT">https://wiki.segger.com/RTT</a></td></tr><tr><td>Segger_SystemView</td><td>source/component/3rd-party/segger/raw/SystemView</td><td>segger</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwiki.segger.com%2FSystemView">https://wiki.segger.com/SystemView</a></td></tr><tr><td>nuconsole</td><td>source/component/3rd-party/nuconsole/raw</td><td>nuvoton</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.nuvoton.com.cn%2F">https://www.nuvoton.com.cn/</a></td></tr><tr><td>AIC8800M_SDK</td><td>source/hal/driver/AIC/AIC8800/vendor</td><td>aic</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.aicsemi.com%2F">http://www.aicsemi.com/</a></td></tr><tr><td>awtk</td><td></td><td>LGPL 2.1</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zlg.cn%2Findex%2Fpub%2Fawtk.html">https://www.zlg.cn/index/pub/awtk.html</a></td></tr><tr><td>littlefs</td><td>source/component/3rd-party/littlefs/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flittlefs-project%2Flittlefs">https://github.com/littlefs-project/littlefs</a></td></tr><tr><td>getopt_long</td><td>source/shell/sys/linux/lib/3rd-party/getopt</td><td>OpenBSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fopenbsd%2Fsrc">https://github.com/openbsd/src</a></td></tr><tr><td>regex</td><td>source/shell/sys/linux/lib/3rd-party/regex</td><td>OpenBSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fopenbsd%2Fsrc">https://github.com/openbsd/src</a></td></tr><tr><td>fnmatch</td><td>source/shell/sys/linux/lib/3rd-party/fnmatch</td><td>BSD</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.jbox.dk%2Fsanos%2Fsource%2Flib%2Ffnmatch.c.html">http://www.jbox.dk/sanos/source/lib/fnmatch.c.html</a></td></tr><tr><td>glob</td><td>source/shell/sys/linux/lib/3rd-party/glob</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fcloudius-systems%2Fmusl">https://github.com/cloudius-systems/musl</a></td></tr><tr><td>setjmp</td><td>source/hal/arch/x86/win</td><td>BSD</td><td></td></tr><tr><td>libtuv</td><td>source/shell/sys/linux/lib/3rd-party/libtuv/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FSamsung%2Flibtuv">https://github.com/Samsung/libtuv</a></td></tr></tbody></table><h2><a id="user-content-文檔" class="anchor" href="https://gitee.com/vsfteam/vsf#%E6%96%87%E6%A1%A3"></a><a href="https://gitee.com/vsfteam/vsf/blob/master/document/README_zh.md">文檔</a></h2>]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:35:45 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/vsfteam/vsf</guid>
            <link>https://gitee.com/vsfteam/vsf</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 混合專家模型 (MoE) 詳解]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 編輯器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">隨着 Mixtral 8x7B (announcement, model card) 的推出，一種稱為混合專家模型 (Mixed Expert Models，簡稱 MoEs) 的 Transformer 模型在開源人工智能社區引起了廣泛關注。在本篇博文中，我們將深入探討 MoEs 的核心組件、訓練方法，以及在推理過程中需要考量的各種因素。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們開始吧！</p><span id="OSC_h2_1"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">簡短總結</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoEs):</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      與稠密模型相比， 
     <strong style="color: black;">預訓練速度更快</strong></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      與具有相同參數數量的模型相比，具有更快的 
     <strong style="color: black;">推理速度</strong></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      需要 
     <strong style="color: black;">大量顯存</strong>，因為所有專家系統都需要加載到內存中 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      在 
     <strong style="color: black;">微調方面存在諸多挑戰</strong>，但，近期的研究，表明，對混合專家模型進行 
     <strong style="color: black;">指令調優具有很大的潛力</strong>。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們開始吧！</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">什麼是混合專家模型？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">模型規模是提升模型性能的關鍵因素之一。在有限的計算資源預算下，用更少的訓練步數訓練一個更大的模型，往往比用更多的步數訓練一個較小的模型效果更佳。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoE) 的一個顯著優勢是它們能夠在遠少於稠密模型所需的計算資源下進行有效的預訓練。這意味着在相同的計算預算條件下，您可以顯著擴大模型或數據集的規模。特別是在預訓練階段，與稠密模型相比，混合專家模型通常能夠更快地達到相同的質量水平。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">那麼，究竟什麼是一個混合專家模型 (MoE) 呢？作為一種基於 Transformer 架構的模型，混合專家模型主要由兩個關鍵部分組成:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">稀疏 MoE 層</strong>: 這些層代替了傳統 Transformer 模型中的前饋網絡 (FFN) 層。MoE 層包含若干「專家」(例如 8 個)，每個專家本身是一個獨立的神經網絡。在實際應用中，這些專家通常是前饋網絡 (FFN)，但它們也可以是更復雜的網絡結構，甚至可以是 MoE 層本身，從而形成層級式的 MoE 結構。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">門控網絡或路由</strong>: 這個部分用於決定哪些令牌 (token) 被髮送到哪個專家。例如，在下圖中，「More」這個令牌可能被髮送到第二個專家，而「Parameters」這個令牌被髮送到第一個專家。有時，一個令牌甚至可以被髮送到多個專家。令牌的路由方式是 MoE 使用中的一個關鍵點，因為路由器由學習的參數組成，並且與網絡的其他部分一同進行預訓練。 
    </section></li></ul><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006177" data-ratio="0.7703703703703704" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8f46f9ec-4ee7-42d6-8b1d-68962ccb7e8b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformers paper 論文中的 MoE layer 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">總結來説，在混合專家模型 (MoE) 中，我們將傳統 Transformer 模型中的每個前饋網絡 (FFN) 層替換為 MoE 層，其中 MoE 層由兩個核心部分組成: 一個門控網絡和若干數量的專家。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">儘管混合專家模型 (MoE) 提供了若干顯著優勢，例如更高效的預訓練和與稠密模型相比更快的推理速度，但它們也伴隨着一些挑戰:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">訓練挑戰</strong>: 雖然 MoE 能夠實現更高效的計算預訓練，但它們在微調階段往往面臨泛化能力不足的問題，長期以來易於引發過擬合現象。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">推理挑戰</strong>: MoE 模型雖然可能擁有大量參數，但在推理過程中只使用其中的一部分，這使得它們的推理速度快於具有相同數量參數的稠密模型。然而，這種模型需要將所有參數加載到內存中，因此對內存的需求非常高。以 Mixtral 8x7B 這樣的 MoE 為例，需要足夠的 VRAM 來容納一個 47B 參數的稠密模型。之所以是 47B 而不是 8 x 7B = 56B，是因為在 MoE 模型中，只有 FFN 層被視為獨立的專家，而模型的其他參數是共享的。此外，假設每個令牌只使用兩個專家，那麼推理速度 (以 FLOPs 計算) 類似於使用 12B 模型 (而不是 14B 模型)，因為雖然它進行了 2x7B 的矩陣乘法計算，但某些層是共享的。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">瞭解了 MoE 的基本概念後，讓我們進一步探索推動這類模型發展的研究。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">混合專家模型簡史</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoE) 的理念起源於 1991 年的論文 Adaptive Mixture of Local Experts。這個概念與集成學習方法相似，旨在為由多個單獨網絡組成的系統建立一個監管機制。在這種系統中，每個網絡 (被稱為「專家」) 處理訓練樣本的不同子集，專注於輸入空間的特定區域。那麼，如何選擇哪個專家來處理特定的輸入呢？這就是門控網絡發揮作用的地方，它決定了分配給每個專家的權重。在訓練過程中，這些專家和門控網絡都同時接受訓練，以優化它們的性能和決策能力。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 2010 至 2015 年間，兩個獨立的研究領域為混合專家模型 (MoE) 的後續發展做出了顯著貢獻:</p><ol data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">組件專家</strong>: 在傳統的 MoE 設置中，整個系統由一個門控網絡和多個專家組成。在支持向量機 (SVMs) 、高斯過程和其他方法的研究中，MoE 通常被視為整個模型的一部分。然而，Eigen、Ranzato 和 Ilya 的研究，探索了將 MoE 作為更深層網絡的一個組件。這種方法允許將 MoE 嵌入到多層網絡中的某一層，使得模型既大又高效。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">條件計算</strong>: 傳統的神經網絡通過每一層處理所有輸入數據。在這一時期，Yoshua Bengio 等研究人員開始探索基於輸入令牌動態激活或停用網絡組件的方法。 
    </section></li></ol><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這些研究的融合促進了在自然語言處理 (NLP) 領域對混合專家模型的探索。特別是在 2017 年，Shazeer 等人 (團隊包括 Geoffrey Hinton 和 Jeff Dean，後者有時被戲稱為 「谷歌的 Chuck Norris」) 將這一概念應用於 137B 的 LSTM (當時被廣泛應用於 NLP 的架構，由 Schmidhuber 提出)。通過引入稀疏性，這項工作在保持極高規模的同時實現了快速的推理速度。這項工作主要集中在翻譯領域，但面臨着如高通信成本和訓練不穩定性等多種挑戰。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006175" data-ratio="0.48240635641316687" data-type="png" data-w="881" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/48db56ce-0292-4d84-a174-c5c7a03d5e8b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Outrageously Large Neural Network 論文中的 MoE layer 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoE) 的引入使得訓練具有數千億甚至萬億參數的模型成為可能，如開源的 1.6 萬億參數的 Switch Transformers 等。這種技術不僅在自然語言處理 (NLP) 領域得到了廣泛應用，也開始在計算機視覺領域進行探索。然而，本篇博客文章將主要聚焦於自然語言處理領域的應用和探討。</p><span id="OSC_h2_4"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">什麼是稀疏性?</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稀疏性的概念採用了條件計算的思想。在傳統的稠密模型中，所有的參數都會對所有輸入數據進行處理。相比之下，稀疏性允許我們僅針對整個系統的某些特定部分執行計算。這意味着並非所有參數都會在處理每個輸入時被激活或使用，而是根據輸入的特定特徵或需求，只有部分參數集合被調用和運行。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們深入分析 Shazeer 對混合專家模型 (MoE) 在翻譯應用中的貢獻。條件計算的概念 (即僅在每個樣本的基礎上激活網絡的不同部分) 使得在不增加額外計算負擔的情況下擴展模型規模成為可能。這一策略在每個 MoE 層中實現了數以千計甚至更多的專家的有效利用。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這種稀疏性設置確實帶來了一些挑戰。例如，在混合專家模型 (MoE) 中，儘管較大的批量大小通常有利於提高性能，但當數據通過激活的專家時，實際的批量大小可能會減少。比如，假設我們的輸入批量包含 10 個令牌， <strong style="color: black;">可能會有五個令牌被路由到同一個專家，而剩下的五個令牌分別被路由到不同的專家。這導致了批量大小的不均勻分配和資源利用效率不高的問題</strong>。在接下來的部分中，將會討論讓 MoE 高效運行的其他挑戰以及相應的解決方案。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">那我們應該如何解決這個問題呢？一個可學習的門控網絡 (G) 決定將輸入的哪一部分發送給哪些專家 (E):</p><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="y = \sum_{i=1}^{n} G(x)_i E_i(x)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -1562.5 8246.1 2808.5" aria-hidden="true" style="-webkit-overflow-scrolling: touch;vertical-align: -2.819ex;width: 18.656ex;height: 6.354ex;max-width: 300% !important;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(1823.6, 0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2, -1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(509.9, 1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mi" transform="translate(3434.2, 0)"><path data-c="47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mo" transform="translate(4220.2, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4609.2, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="msub" transform="translate(5181.2, 0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(389, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(5864.2, 0)"><g data-mml-node="mi"><path data-c="45" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(738, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(6896.1, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7285.1, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7857.1, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在這種設置下，雖然所有專家都會對所有輸入進行運算，但通過門控網絡的輸出進行加權乘法操作。但是，如果 G (門控網絡的輸出) 為 0 會發生什麼呢？如果是這種情況，就沒有必要計算相應的專家操作，因此我們可以節省計算資源。那麼一個典型的門控函數是什麼呢？一個典型的門控函數通常是一個帶有 softmax 函數的簡單的網絡。這個網絡將學習將輸入發送給哪個專家。</p><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="G_\sigma(x) = \text{Softmax}(x \cdot W_g)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.667ex;width: 24.749ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/addcdb77-1331-4c14-845f-06df5414abd2.svg" data-type="svg+xml" data-imgfileid="100006169"></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Shazeer 等人的工作還探索了其他的門控機制，其中包括帶噪聲的 TopK 門控 (Noisy Top-K Gating)。這種門控方法引入了一些可調整的噪聲，然後保留前 k 個值。具體來説:</p><ol data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      添加一些噪聲 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="H(x)_i = (x \cdot W_{\text{g}})_i + \text{StandardNormal()} \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.669ex;width: 60.565ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/26f83d98-1595-404e-9d4a-58c616d102c1.svg" data-type="svg+xml" data-imgfileid="100006173"></section></span><ol start="2" data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      選擇保留前 K 個值 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="\text{KeepTopK}(v, k)_i = \begin{cases}
v_i &amp; \text{if } v_i \text{ is in the top } k \text{ elements of } v, \\
-\infty &amp; \text{otherwise.}
\end{cases}
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -2.148ex;width: 58.794ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/4505b4a9-5c66-45c5-9f72-1b2377d74dca.svg" data-type="svg+xml" data-imgfileid="100006171"></section></span><ol start="3" data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      應用 Softmax 函數 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="G(x) = \text{Softmax}(\text{KeepTopK}(H(x), k))
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.566ex;width: 37.6ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/70f4a245-7a7f-483c-b524-8795deb3ae04.svg" data-type="svg+xml" data-imgfileid="100006170"></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這種稀疏性引入了一些有趣的特性。通過使用較低的 k 值 (例如 1 或 2)，我們可以比激活多個專家時更快地進行訓練和推理。為什麼不僅選擇最頂尖的專家呢？最初的假設是，需要將輸入路由到不止一個專家，以便門控學會如何進行有效的路由選擇，因此至少需要選擇兩個專家。Switch Transformers 就這點進行了更多的研究。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我們為什麼要添加噪聲呢？這是為了專家間的負載均衡！</p><span id="OSC_h2_5"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">混合專家模型中令牌的負載均衡</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">正如之前討論的，如果所有的令牌都被髮送到只有少數幾個受歡迎的專家，那麼訓練效率將會降低。在通常的混合專家模型 (MoE) 訓練中，門控網絡往往傾向於主要激活相同的幾個專家。這種情況可能會自我加強，因為受歡迎的專家訓練得更快，因此它們更容易被選擇。為了緩解這個問題，引入了一個 <strong style="color: black;">輔助損失</strong>，旨在鼓勵給予所有專家相同的重要性。這個損失確保所有專家接收到大致相等數量的訓練樣本，從而平衡了專家之間的選擇。接下來的部分還將探討專家容量的概念，它引入了一個關於專家可以處理多少令牌的閾值。在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 庫中，可以通過 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">aux_loss</code> 參數來控制輔助損失。</p><span id="OSC_h2_6"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">MoEs and Transformers</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Transformer 類模型明確表明，增加參數數量可以提高性能，因此谷歌使用 GShard 嘗試將 Transformer 模型的參數量擴展到超過 6000 億並不令人驚訝。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">GShard 將在編碼器和解碼器中的每個前饋網絡 (FFN) 層中的替換為使用 Top-2 門控的混合專家模型 (MoE) 層。下圖展示了編碼器部分的結構。這種架構對於大規模計算非常有效: 當擴展到多個設備時，MoE 層在不同設備間共享，而其他所有層則在每個設備上覆制。我們將在 「讓 MoE 起飛」部分對這一點進行更詳細的討論。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006178" data-ratio="0.6046296296296296" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8246ce4e-437b-4539-bf15-17cea720b24b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     GShard 論文中的 MoE Transformer Encoder 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">為了保持負載平衡和訓練效率，GShard 的作者除了引入了上一節中討論的類似輔助損失外，還引入了一些關鍵變化:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">隨機路由</strong>: 在 Top-2 設置中，我們始終選擇排名最高的專家，但第二個專家是根據其權重比例隨機選擇的。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">專家容量</strong>: 我們可以設定一個閾值，定義一個專家能處理多少令牌。如果兩個專家的容量都達到上限，令牌就會溢出，並通過殘差連接傳遞到下一層，或在某些情況下被完全丟棄。專家容量是 MoE 中最重要的概念之一。為什麼需要專家容量呢？因為所有張量的形狀在編譯時是靜態確定的，我們無法提前知道多少令牌會分配給每個專家，因此需要一個固定的容量因子。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">GShard 的工作對適用於 MoE 的並行計算模式也做出了重要貢獻，但這些內容的討論超出了這篇博客的範圍。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意</strong>: 在推理過程中，只有部分專家被激活。同時，有些計算過程是共享的，例如自注意力 (self-attention) 機制，它適用於所有令牌。這就解釋了為什麼我們可以使用相當於 12B 稠密模型的計算資源來運行一個包含 8 個專家的 47B 模型。如果我們採用 Top-2 門控，模型會使用高達 14B 的參數。但是，由於自注意力操作 (專家間共享) 的存在，實際上模型運行時使用的參數數量是 12B。</p><span id="OSC_h2_7"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">Switch Transformers</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">儘管混合專家模型 (MoE) 顯示出了很大的潛力，但它們在訓練和微調過程中存在穩定性問題。Switch Transformers 是一項非常激動人心的工作，它深入研究了這些話題。作者甚至在 Hugging Face 上發佈了一個 1.6 萬億參數的 MoE，擁有 2048 個專家，你可以使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 庫來運行它。Switch Transformers 實現了與 T5-XXL 相比 4 倍的預訓練速度提升。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006176" data-ratio="0.5101851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/56bee9cf-5842-4bfd-b5a5-cdc79c60b93d.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformer 論文中的 Switch Transformer Layer 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">就像在 GShard 中一樣，作者用混合專家模型 (MoE) 層替換了前饋網絡 (FFN) 層。Switch Transformers 提出了一個 Switch Transformer 層，它接收兩個輸入 (兩個不同的令牌) 並擁有四個專家。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">與最初使用至少兩個專家的想法相反，Switch Transformers 採用了簡化的單專家策略。這種方法的效果包括:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      減少門控網絡 (路由) 計算負擔 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      每個專家的批量大小至少可以減半 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      降低通信成本 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      保持模型質量 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 也對 <strong style="color: black;">專家容量</strong> 這個概念進行了研究。</p><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="\text{Expert Capacity} = \left(\frac{\text{tokens per batch}}{\text{number of experts}}\right) \times \text{capacity factor}
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -2.148ex;width: 58.45ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/52d4608e-4c61-4d62-b055-dc8f790f459a.svg" data-type="svg+xml" data-imgfileid="100006172"></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">上述建議的容量是將批次中的令牌數量均勻分配到各個專家。如果我們使用大於 1 的容量因子，我們為令牌分配不完全平衡時提供了一個緩衝。增加容量因子會導致更高的設備間通信成本，因此這是一個需要考慮的權衡。特別值得注意的是，Switch Transformers 在低容量因子 (例如 1 至 1.25) 下表現出色。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformer 的作者還重新審視並簡化了前面章節中提到的負載均衡損失。在訓練期間，對於每個 Switch 層的輔助損失被添加到總模型損失中。這種損失鼓勵均勻路由，並可以使用超參數進行加權。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">作者還嘗試了混合精度的方法，例如用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bfloat16</code> 精度訓練專家，同時對其餘計算使用全精度進行。較低的精度可以減少處理器間的通信成本、計算成本以及存儲張量的內存。然而，在最初的實驗中，當專家和門控網絡都使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bfloat16</code> 精度訓練時，出現了不穩定的訓練現象。這種不穩定性特別是由路由計算引起的，因為路由涉及指數函數等操作，這些操作對精度要求較高。因此，為了保持計算的穩定性和精確性，保持更高的精度是重要的。為了減輕不穩定性，路由過程也使用了全精度。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006174" data-ratio="0.2253731343283582" data-type="png" data-w="670" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/66532187-c893-46e4-8d55-3a04955edef9.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     使用混合精度不會降低模型質量並可實現更快的訓練 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這個 Jupyter Notebook 展示瞭如何對 Switch Transformers 進行微調以進行摘要生成的詳細指南。然而，在開始微調 Switch Transformers 之前，強烈建議您先閲讀關於微調混合專家模型部分的內容。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 採用了編碼器 - 解碼器的架構，實現了與 T5 類似的混合專家模型 (MoE) 版本。GLaM 這篇工作探索瞭如何使用僅為原來 1/3 的計算資源 (因為 MoE 模型在訓練時需要的計算量較少，從而能夠顯著降低碳足跡) 來訓練與 GPT-3 質量相匹配的模型來提高這些模型的規模。作者專注於僅解碼器 (decoder-only) 的模型以及少樣本和單樣本評估，而不是微調。他們使用了 Top-2 路由和更大的容量因子。此外，他們探討了將容量因子作為一個動態度量，根據訓練和評估期間所使用的計算量進行調整。</p><span id="OSC_h2_8"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">用 Router z-loss 穩定模型訓練</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">之前討論的平衡損失可能會導致穩定性問題。我們可以使用許多方法來穩定稀疏模型的訓練，但這可能會犧牲模型質量。例如，引入 dropout 可以提高穩定性，但會導致模型質量下降。另一方面，增加更多的乘法分量可以提高質量，但會降低模型穩定性。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ST-MoE 引入的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Router z-loss</code> 在保持了模型性能的同時顯著提升了訓練的穩定性。這種損失機制通過懲罰門控網絡輸入的較大 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">logits</code> 來起作用，目的是促使數值的絕對大小保持較小，這樣可以有效減少計算中的舍入誤差。這一點對於那些依賴指數函數進行計算的門控網絡尤其重要。為了深入瞭解這一機制，建議參考原始論文以獲得更全面的細節。</p><span id="OSC_h2_9"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">專家如何學習？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ST-MoE 的研究者們發現，編碼器中不同的專家傾向於專注於特定類型的令牌或淺層概念。例如，某些專家可能專門處理標點符號，而其他專家則專注於專有名詞等。與此相反，解碼器中的專家通常具有較低的專業化程度。此外，研究者們還對這一模型進行了多語言訓練。儘管人們可能會預期每個專家處理一種特定語言，但實際上並非如此。由於令牌路由和負載均衡的機制，沒有任何專家被特定配置以專門處理某一特定語言。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006181" data-ratio="0.9258760107816711" data-type="png" data-w="742" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1137474f-1950-4033-8f38-785166343282.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     ST-MoE 論文中顯示了哪些令牌組被髮送給了哪個專家的表格 
   </figcaption></figure><span id="OSC_h2_10"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">專家的數量對預訓練有何影響？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">增加更多專家可以提升處理樣本的效率和加速模型的運算速度，但這些優勢隨着專家數量的增加而遞減 (尤其是當專家數量達到 256 或 512 之後更為明顯)。同時，這也意味着在推理過程中，需要更多的顯存來加載整個模型。值得注意的是，Switch Transformers 的研究表明，其在大規模模型中的特性在小規模模型下也同樣適用，即便是每層僅包含 2、4 或 8 個專家。</p><span id="OSC_h2_11"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">微調混合專家模型</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);"><code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">4.36.0</code> 版本的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">transformers</code> 庫支持 Mixtral 模型。你可以用以下命令進行安裝: <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">pip install "transformers==4.36.0 --upgrade</code></p></blockquote><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稠密模型和稀疏模型在過擬合的動態表現上存在顯著差異。稀疏模型更易於出現過擬合現象，因此在處理這些模型時，嘗試更強的內部正則化措施是有益的，比如使用更高比例的 dropout。例如，我們可以為稠密層設定一個較低的 dropout 率，而為稀疏層設置一個更高的 dropout 率，以此來優化模型性能。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在微調過程中是否使用輔助損失是一個需要決策的問題。ST-MoE 的作者嘗試關閉輔助損失，發現即使高達 11% 的令牌被丟棄，模型的質量也沒有顯著受到影響。令牌丟棄可能是一種正則化形式，有助於防止過擬合。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 的作者觀察到，在相同的預訓練困惑度下，稀疏模型在下游任務中的表現不如對應的稠密模型，特別是在重理解任務 (如 SuperGLUE) 上。另一方面，對於知識密集型任務 (如 TriviaQA)，稀疏模型的表現異常出色。作者還觀察到，在微調過程中，較少的專家的數量有助於改善性能。另一個關於泛化問題確認的發現是，模型在小型任務上表現較差，但在大型任務上表現良好。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006182" data-ratio="0.38010471204188484" data-type="png" data-w="955" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/47346e7f-b742-4923-a63d-7ccecd2a6427.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     在小任務 (左圖) 中，我們可以看到明顯的過擬合，因為稀疏模型在驗證集中的表現要差得多。在較大的任務 (右圖) 中，MoE 則表現良好。該圖來自 ST-MoE 論文 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">一種可行的微調策略是嘗試凍結所有非專家層的權重。實踐中，這會導致性能大幅下降，但這符合我們的預期，因為混合專家模型 (MoE) 層佔據了網絡的主要部分。我們可以嘗試相反的方法: 僅凍結 MoE 層的參數。實驗結果顯示，這種方法幾乎與更新所有參數的效果相當。這種做法可以加速微調過程，並降低顯存需求。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006180" data-ratio="0.77" data-type="png" data-w="400" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/401ba984-a5f5-4772-95db-99c12f026ef7.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     通過僅凍結 MoE 層，我們可以在保持質量的同時加快訓練速度。該圖來自 ST-MoE 論文 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在微調稀疏混合專家模型 (MoE) 時需要考慮的最後一個問題是，它們有特別的微調超參數設置——例如，稀疏模型往往更適合使用較小的批量大小和較高的學習率，這樣可以獲得更好的訓練效果。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006183" data-ratio="0.37570303712035996" data-type="png" data-w="889" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/0f29d064-6852-4055-99ce-fab522c4d6bd.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     降低學習率和調大批量可以提升稀疏模型微調質量。該圖來自 ST-MoE 論文 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">此時，您可能會對人們微調 MoE 中遇到的這些挑戰而感到沮喪，但最近的一篇論文 《MoEs Meets Instruction Tuning》 (2023 年 7 月) 帶來了令人興奮的發現。這篇論文進行了以下實驗:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      單任務微調 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      多任務指令微調 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      多任務指令微調後接單任務微調 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">當研究者們對 MoE 和對應性能相當的 T5 模型進行微調時，他們發現 T5 的對應模型表現更為出色。然而，當研究者們對 Flan T5 (一種 T5 的指令優化版本) 的 MoE 版本進行微調時，MoE 的性能顯著提升。更值得注意的是，Flan-MoE 相比原始 MoE 的性能提升幅度超過了 Flan T5 相對於原始 T5 的提升，這意味着 MoE 模型可能從指令式微調中獲益更多，甚至超過了稠密模型。此外，MoE 在多任務學習中表現更佳。與之前關閉 <strong style="color: black;">輔助損失</strong> 函數的做法相反，實際上這種損失函數可以幫助防止過擬合。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006179" data-ratio="0.4456140350877193" data-type="png" data-w="855" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/dc2a1d41-2a2d-4e63-b2c3-015fb22f56f3.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     與稠密模型相比，稀疏模型從指令微調中受益更多。該圖來自 MoEs Meets instructions Tuning 論文 
   </figcaption></figure><span id="OSC_h2_12"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">稀疏 VS 稠密，如何選擇?</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稀疏混合專家模型 (MoE) 適用於擁有多台機器且要求高吞吐量的場景。在固定的預訓練計算資源下，稀疏模型往往能夠實現更優的效果。相反，在顯存較少且吞吐量要求不高的場景，稠密模型則是更合適的選擇。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意</strong>: 直接比較稀疏模型和稠密模型的參數數量是不恰當的，因為這兩類模型基於的概念和參數量的計算方法完全不同。</p><span id="OSC_h2_13"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">讓 MoE 起飛</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">最初的混合專家模型 (MoE) 設計採用了分支結構，這導致了計算效率低下。這種低效主要是因為 GPU 並不是為處理這種結構而設計的，而且由於設備間需要傳遞數據，網絡帶寬常常成為性能瓶頸。在接下來的討論中，我們會討論一些現有的研究成果，旨在使這些模型在預訓練和推理階段更加高效和實用。我們來看看如何優化 MoE 模型，讓 MoE 起飛。</p><span id="OSC_h3_14"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">並行計算</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們簡要回顧一下並行計算的幾種形式:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">數據並行</strong>: 相同的權重在所有節點上覆制，數據在節點之間分割。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">模型並行</strong>: 模型在節點之間分割，相同的數據在所有節點上覆制。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">模型和數據並行</strong>: 我們可以在節點之間同時分割模型和數據。注意，不同的節點處理不同批次的數據。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">專家並行</strong>: 專家被放置在不同的節點上。如果與數據並行結合，每個節點擁有不同的專家，數據在所有節點之間分割。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在專家並行中，專家被放置在不同的節點上，每個節點處理不同批次的訓練樣本。對於非 MoE 層，專家並行的行為與數據並行相同。對於 MoE 層，序列中的令牌被髮送到擁有所需專家的節點。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006184" data-ratio="0.5910194174757282" data-type="png" data-w="824" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d166997f-8e65-483f-91e6-e5e4c1ccdf96.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformers 論文中展示如何使用不同的並行技術在節點上分割數據和模型的插圖 
   </figcaption></figure><span id="OSC_h3_15"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">容量因子和通信開銷</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">提高容量因子 (Capacity Factor, CF) 可以增強模型的性能，但這也意味着更高的通信成本和對保存激活值的顯存的需求。在設備通信帶寬有限的情況下，選擇較小的容量因子可能是更佳的策略。一個合理的初始設置是採用 Top-2 路由、1.25 的容量因子，同時每個節點配置一個專家。在評估性能時，應根據需要調整容量因子，以在設備間的通信成本和計算成本之間找到一個平衡點。</p><span id="OSC_h3_16"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">部署技術</span><span style="display: none;"></span></h3><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">您可以在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">Inference Endpoints</code> 部署 mistralai/Mixtral-8x7B-Instruct-v0.1。</p></blockquote><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">部署混合專家模型 (MoE) 的一個關鍵挑戰是其龐大的參數規模。對於本地使用情況，我們可能希望使用更小的模型。為了使模型更適合部署，下面是幾種有用的技術:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      預先蒸餾實驗: Switch Transformers 的研究者們進行了預先蒸餾的實驗。他們通過將 MoE 模型蒸餾回其對應的稠密模型，成功保留了 30-40% 的由稀疏性帶來的性能提升。預先蒸餾不僅加快了預訓練速度，還使得在推理中使用更小型的模型成為可能。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      任務級別路由: 最新的方法中，路由器被修改為將整個句子或任務直接路由到一個專家。這樣做可以提取出一個用於服務的子網絡，有助於簡化模型的結構。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      專家網絡聚合: 這項技術通過合併各個專家的權重，在推理時減少了所需的參數數量。這樣可以在不顯著犧牲性能的情況下降低模型的複雜度。 
    </section></li></ul><span id="OSC_h3_17"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">高效訓練</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">FasterMoE (2022 年 3 月) 深入分析了 MoE 在不同並行策略下的理論性能極限，並且探索了一系列創新技術，包括用於專家權重調整的方法、減少延遲的細粒度通信調度技術，以及一個基於最低延遲進行專家選擇的拓撲感知門控機制。這些技術的結合使得 MoE 運行速度提升高達 17 倍。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Megablocks (2022 年 11 月) 則專注於通過開發新的 GPU kernel 來處理 MoE 模型中的動態性，以實現更高效的稀疏預訓練。其核心優勢在於，它不會丟棄任何令牌，並能高效地適應現代硬件架構 (支持塊稀疏矩陣乘)，從而達到顯著的加速效果。Megablocks 的創新之處在於，它不像傳統 MoE 那樣使用批量矩陣乘法 (這通常假設所有專家形狀相同且處理相同數量的令牌)，而是將 MoE 層表示為塊稀疏操作，可以靈活適應不均衡的令牌分配。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006185" data-ratio="0.2851851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d09a85e7-f59f-421c-8e9f-d75df34954c8.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     針對不同規模的專家和令牌數量的塊稀疏矩陣乘法。該圖來自 MegaBlocks 論文 
   </figcaption></figure><span id="OSC_h2_18"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">開源混合專家模型</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">目前，下面這些開源項目可以用於訓練混合專家模型 (MoE):</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Megablocks: https://github.com/stanford-futuredata/megablocks 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Fairseq: https://github.com/facebookresearch/fairseq/tree/main/examples/moe_lm 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      OpenMoE: https://github.com/XueFuzhao/OpenMoE 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">對於開源的混合專家模型 (MoE)，你可以關注下面這些:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Switch Transformers (Google): 基於 T5 的 MoE 集合，專家數量從 8 名到 2048 名。最大的模型有 1.6 萬億個參數。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      NLLB MoE (Meta): NLLB 翻譯模型的一個 MoE 變體。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      OpenMoE: 社區對基於 Llama 的模型的 MoE 嘗試。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixtral 8x7B (Mistral): 一個性能超越了 Llama 2 70B 的高質量混合專家模型，並且具有更快的推理速度。此外，還發布了一個經過指令微調的模型。有關更多信息，可以在 Mistral 的，公告博客文章，中瞭解。 
    </section></li></ul><span id="OSC_h2_19"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">一些有趣的研究方向</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先是嘗試將稀疏混合專家模型 (SMoE) <strong style="color: black;">蒸餾</strong> 回到具有更少實際參數但相似等價參數量的稠密模型。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">MoE 的 <strong style="color: black;">量化</strong> 也是一個有趣的研究領域。例如，QMoE (2023 年 10 月) 通過將 MoE 量化到每個參數不到 1 位，將 1.6 萬億參數的 Switch Transformer 所需的存儲從 3.2TB 壓縮到僅 160GB。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">簡而言之，一些值得探索的有趣領域包括:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      將 Mixtral 蒸餾成一個稠密模型。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      探索合並專家模型的技術及其對推理時間的影響。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      嘗試對 Mixtral 進行極端量化的實驗。 
    </section></li></ul><span id="OSC_h2_20"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">相關資源</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Adaptive Mixture of Local Experts (1991) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Learning Factored Representations in a Deep Mixture of Experts (2013) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer (2017) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding (Jun 2020) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      GLaM: Efficient Scaling of Language Models with Mixture-of-Experts (Dec 2021) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity (Jan 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      ST-MoE: Designing Stable and Transferable Sparse Expert Models (Feb 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      FasterMoE: modeling and optimizing training of large-scale dynamic pre-trained models(April 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      MegaBlocks: Efficient Sparse Training with Mixture-of-Experts (Nov 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models (May 2023) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixtral-8x7B-v0.1, Mixtral-8x7B-Instruct-v0.1. 
    </section></li></ul><span id="OSC_h2_21"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">Citation</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">@misc {sanseviero2023moe,<br>    author       = { Omar Sanseviero and<br>                     Lewis Tunstall and<br>                     Philipp Schmid and<br>                     Sourab Mangrulkar and<br>                     Younes Belkada and<br>                     Pedro Cuenca<br>                   },<br>    title        = { Mixture of Experts Explained },<br>    year         = 2023,<br>    url          = { https://huggingface.co/blog/moe },<br>    publisher    = { Hugging Face Blog }<br>}<br></code></pre><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">Sanseviero,&nbsp;et&nbsp;al.,&nbsp;<span style="color: #d14;line-height: 26px;">"Mixture&nbsp;of&nbsp;Experts&nbsp;Explained"</span>,&nbsp;Hugging&nbsp;Face&nbsp;Blog,&nbsp;2023.<br></code></pre><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">🤗 寶子們可以戳 <strong style="color: black;">閲讀原文</strong> 查看文中所有的外部鏈接喲！</p></blockquote><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/moe</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Omar Sanseviero, Lewis Tunstall, Philipp Schmid, Sourab Mangrulkar, Younes Belkada, Pedro Cuenca</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">譯者: xinyu66 (Xinyu Yang)</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:32:45 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10444582</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10444582</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[恭喜 LinkWeChat 榮獲 2023 開源創新榜「優秀開源項目」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>&nbsp; &nbsp; &nbsp; 近日，由<strong>中國科協科學技術傳播中心、中國計算機學會、中國通信學會、中國科學院軟件研究所</strong>共同主辦，CSDN 承辦的 2023 開源創新榜專家評審會在國家科技傳播中心成功舉辦。評委會主任、中國計算機學會開源發展委員會主任王懷民院士，評委會副主任、中國科協科學技術傳播中心副主任陳鋭，評委會副主任、中國通信學會副理事長兼秘書長張延川，評委會副主任、中國科學院軟件研究所所長趙琛與來自全國學會、大學、科研院所、企業、開源基金會、行業聯盟等二十多位開源專家共同參與了本屆榜單評審工作，會議由陳鋭主持。</span></p><p><span>&nbsp; &nbsp; &nbsp; &nbsp; 2023 年開源創新榜相較往年有以下幾個變化。<strong>一是進一步提升權威性，</strong>主辦單位新加入中國計算機學會、中國通信學會、中國科學院軟件研究所，四家主辦單位優勢互補，共同推動榜單策劃、徵集申報、專家評審等工作重點。<strong>二是進一步提升公信力，</strong>由王懷民院士擔任評委會主任，指導組建了結構更加科學、領域更加全面的評審專家庫，從中提名形成最終評審專家。<strong>三是進一步提升專業度，</strong>圍繞項目、社區、人物三大類別，四家主辦單位打磨了更加客觀、嚴謹、貼合實際的評審標準和更加開放、公平、科學的評審辦法，在徵集過程中公開標準細節，接受社會的意見反饋，形成良性循環。</span></p><p><span>評委會最終評選出優秀開源項目 20 個，LinkWeChat<span style="color:#f2622e"><strong>成功入選。</strong></span></span></p><p><span><span style="color:#f2622e"><strong><img alt="" height="472" src="https://oscimg.oschina.net/oscnet/up-c75591fff8654955776eeed8c0294671c38.png" width="284" referrerpolicy="no-referrer"></strong></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 15:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273361</guid>
            <link>https://www.oschina.net/news/273361</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[告別 2023，迎接 2024]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>順便帶一下開放籤開源電子簽章上線兩週的小結，本週關鍵字「驚喜」。官網訪問量穩定在 200 左右/天，github/gitee:start 總計 130。5 個企業版意向客户，以上便是開放簽上線兩週的運營數據。</span></span></span></span></span></span></span></span>&nbsp;</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>用「堅持」「艱辛」來總結 2023 年，這是我們真實的寫照。團隊這幾年確實很辛苦，經歷了創業的艱辛，失去了幾載青春、大把的票子，用很低的收入維持生活，這是我們的現狀。但是這些依然打不倒，也壓不跨我們，對我們來説也不是什麼」苦「。因為我們早已看淡了這些，我們相信我們這些年的積累、經驗總有一天有用武之地。因為我們有夢想（説夢想可能會有人笑話吧），我們可以把開放籤做好。其實毫不誇張的説，直至開放簽上線後，才體會到十年磨一劍的感受。不瞞大家，從開始做電子籤直至開放籤這個項目上線，真的已經十年了，期間被家人和朋友調侃十年才玩明白這點事兒。調侃歸調侃，真正想做好一個產品，我們覺得十年只是一個開始，沒有這十來年足夠的客户、技術、服務等方方面面積累，以及我們對開放籤的堅持，估計開放簽上線後也是個沒血肉、立不住的產品吧。對開放籤來説，十年只是一個開始，我們深知沒有任何一件事情可以隨便、容易的完成的，接下來的幾年、幾十年，我們將持續的、頑強的深耕我們的產品、服務，讓電子簽章更簡單不是説説而已。</span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>用「驚喜」「憧憬」來展望 2024 年，驚喜發生在開放簽上線後，而且是持續的。驚喜的是沒想到有特別多的朋友在關注、關心我們，給我們提了不少戰略級別的建議，真的感謝你們。在此特別感謝@jack，感謝你給予我們的指導和建議。你給我們帶來了更多的正能量，我們更加堅定了能做好開放籤的信心。只要用心做好產品，我們相信 24 年會有更多的驚喜。24 年用「憧憬」一詞來展望新年，代表了我們對新的一年美好的期冀。我們期待有更多用户可以低門檻的應用電子簽章，電子簽章可以更加簡單的得到普及。新的一年，我們更加期待開放籤可以更多的參與到公益和對社會有益的事業中，讓開源、開放的意義更大。</span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>寫在最後，我們還很年輕，還有很多不足，肯定在發展的道路上會犯很多錯誤，但是我們是開放的，有激情的，我們願意接受各種批評和質疑，最後還是用一句我們自己堅信的話來總結我們「我們相信開源開放會為產品與用户之間帶來更多信任「，這就是開放籤的價值觀，是我們堅定走下去的信念。 </span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>祝各位在新的一年順遂、如意。新年好！</span></span></span></span></span></span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 08:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273299</guid>
            <link>https://www.oschina.net/news/273299</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 大語言模型技術報告.pdf]]>
            </title>
            <description>
                <![CDATA[看之前先買瓶水，貨實在太乾了[Facepalm]]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://talk.gitee.com/report/china-open-source-2023-llm-report.pdf?fr=news1229</guid>
            <link>https://talk.gitee.com/report/china-open-source-2023-llm-report.pdf?fr=news1229</link>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 23.04 將於 2024 年 1 月 25 日結束支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">對 <a href="https://www.oschina.net/news/237763/ubuntu-23-04-released">Ubuntu 23.04「Lunar Lobster」</a>的官方支持將於 2024 年 1 月 25 日結束，還剩不到一個月的時間。</span></p><p><span style="color:#000000">Ubuntu 23.04 版本於 2023 年 4 月正式發佈，作為短期支持版本獲得 9 個月的支持。還在使用該版本的用户<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F12%2Fubuntu-2304-support-ends-january-2024" target="_blank">建議</a>可以考慮升級到 10 月份發佈的 <a href="https://www.oschina.net/news/261571/ubuntu-23-10-ga">Ubuntu 23.10"Mantic Minotaur"</a>，以確保可繼續收到來自 Canonical 的安全補丁、關鍵錯誤修復以及精選軟件的重要更新。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-4bdb313301be4efb73863c20508102b5a86.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Ubuntu 23.10 附帶了最新的 GNOME 45 版本（其中包含大量改進）、使用 Linux 6.5 內核、更新了圖形驅動程序，並首次發佈了 2 個全新的應用程序，這些應用程序目前為該版本<span style="background-color:#ffffff">獨有</span>： App Center 和 Firmware。</span></p><p><span style="color:#000000">同樣作為短期支持版本，Ubuntu 23.10 計劃將於 2024 年 7 月中旬達到 EOL。不過預計明年 4 月下旬，<span style="background-color:#ffffff"><a href="https://www.oschina.net/news/263525/ubuntu-24-04-release-date-april-25-2024">Ubuntu 24.04 LTS</a> 版本就會正式發佈，LTS 版本將獲得 5 年的安全更新、錯誤修復和精選應用程序更新；LTS 版本預期每 2 年發佈一次。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273275/ubuntu-2304-support-ends-january-2024</guid>
            <link>https://www.oschina.net/news/273275/ubuntu-2304-support-ends-january-2024</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 mybatis-mp - 亮點一：可自定義默認值]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1：默認值設置&nbsp;</p><div><pre><span style="color:#9e880d">@Table
</span><span style="color:#9e880d">@Data
</span><span style="color:#0033b3">public class </span><span style="color:#000000">DefaultValueTest </span>{

    <span style="color:#9e880d">@TableId
</span><span style="color:#9e880d"></span><span style="color:#0033b3">private </span><span style="color:#000000">Integer </span><span style="color:#871094">id</span>;

    <span style="color:#9e880d">@TableField</span>(defaultValue = <span style="color:#067d17">"{BLANK}"</span>)
    <span style="color:#0033b3">private </span><span style="color:#000000">String </span><span style="color:#871094">value1</span>;

    <span style="color:#9e880d">@TableField</span>(defaultValue = <span style="color:#067d17">"1"</span>)
    <span style="color:#0033b3">private </span><span style="color:#000000">Integer </span><span style="color:#871094">value2</span>;

    <span style="color:#9e880d">@TableField</span>(defaultValue = <span style="color:#067d17">"{NOW}"</span>)
    <span style="color:#0033b3">private </span><span style="color:#000000">LocalDateTime </span><span style="color:#871094">createTime</span>;
}
</pre></div><p>2：如何自定義默認值：</p><pre><code class="language-java">MybatisMpConfig.setDefaultValue("{NOW}", (type) -&gt; {
    if (type == LocalDateTime.class) {
        return LocalDateTime.now();
    } else if (type == LocalDate.class) {
        return LocalDate.now();
    } else if (type == Date.class) {
        return new Date();
    } else if (type == Long.class) {
        return System.currentTimeMillis();
    } else if (type == Integer.class) {
        return (int) (System.currentTimeMillis() / 1000);
    }
    throw new RuntimeException("Inconsistent types");
});</code></pre></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273274</guid>
            <link>https://www.oschina.net/news/273274</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CNCF 報告：Kubernetes 推動雲支出增長]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CNCF 發佈的一份調查報告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F20%2Fcncf-cloud-native-finops-cloud-financial-management-microsurvey%2F" target="_blank">指出</a>，Kubernetes 的到來導致了雲支出急劇增加；有<span style="background-color:#fdfdfd; color:#000000">近一半 (49%) 的受訪者表示 Kubernetes 推動了雲支出增長。</span>其中，17% 的人表示成本大幅增加，32% 的人表示成本僅略有增加。</p><p>另一方面，13% 的受訪者在實施 Kubernetes 後成功顯着減少了雲支出，11% 的受訪者成功略微減少了支出。28% 的受訪者表示採用 Kubernetes 後沒有任何變化。</p><p><img height="273" src="https://oscimg.oschina.net/oscnet/up-153215e0c5e6743aa6ba642aee27efef80b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">約 28% 的受訪者表示，Kubernetes 佔用了他們一半的預算，10% 的受訪者表示，這一數字高達 75%，還有極少數 5% 的受訪者表示，Kubernetes 佔用了他們的全部預算。</span></p><p><img height="279" src="https://oscimg.oschina.net/oscnet/up-0189729f7a76027da4a44209791e910f940.png" width="500" referrerpolicy="no-referrer"></p><p>26% 的人每月在雲計算上的支出高達 50000 美元；還有 22% 的人表示他們的支出是前者的 20 倍，每月高達 100 萬美元以上。此外，21% 的人每月雲計算支出不到 1 萬美元。</p><p>在受訪者中，Kubernetes 基礎設施的規模存在很大差異。近一半的受訪者 (49%) 只<span style="background-color:#fdfdfd; color:#000000">擁有最多 50 個節點</span>。15% 擁有 51-100 個節點，17% 擁有 101-250 個節點，18% 擁有超過 251 個節點。&nbsp;</p><p>許多人力和技術因素被認為是雲環境中支出以及不必要和意外成本增加的原因。過度配置以 70% 的比例遙遙領先，個人或團隊層面缺乏責任意識位居第二，為 45%。使用資源後未能停用資源以及存在技術債務（定義為尚未重新架構以利用雲原生環境的可擴展性的工作負載）並列第三，各佔 43%。</p><p><img alt="" height="417" src="https://oscimg.oschina.net/oscnet/up-4a03450fb93c2128ee80b363c64d6f5c9f6.png" width="500" referrerpolicy="no-referrer"></p><p>只有 19% 的受訪者表示他們能夠準確監控 Kubernetes 成本。40% 的人只是進行了估計，38% 的人表示他們根本沒有進行任何監控。</p><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F20%2Fcncf-cloud-native-finops-cloud-financial-management-microsurvey%2F" target="_blank">查看完整報告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273259/cncf-report-kubernetes-cloud-spen</guid>
            <link>https://www.oschina.net/news/273259/cncf-report-kubernetes-cloud-spen</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.13.0 - 支持 StarRocks]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>🚀 新功能</h2><ul><li>支持 StarRocks。</li><li>支持 PostgreSQL, Redshift, RisingWave 高級自動補全。</li></ul><h2>🎄 改進</h2><ul><li>支持在 SQL 編輯器的表結構 DDL 彈窗中展示 index 語句。</li><li>支持在 SQL 編輯器中查詢 PostgreSQL 外部表。</li><li>漢化釘釘 webhook 消息。</li></ul><h2>🎠 社區</h2><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1TG411r7rr%2F" target="_blank">盤點常用的 MySQL 可視化客户端</a></li></ul><h2>📕 安裝及升級</h2><p>參考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升級指南</a>。如果從之前版本升級，獲取新版本後，重新啓動升級即可。</p><hr><p>💡 更多資訊，請關注 Bytebase 公號：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10456200</guid>
            <link>https://my.oschina.net/u/6148470/blog/10456200</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[寫給工程師的 MacBook 商用級大模型知識庫部署方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;visibility: visible;" data-mpa-powered-by="yiban.io"><img class="rich_pages wxw-img __bg_gif" data-backh="96" data-backw="578" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="96" data-imgfileid="503041736" data-ratio="0.16666666666666666" src="https://oscimg.oschina.net/oscnet/990ffd45-801b-45e6-80cd-1b6ebb403d86.gif" data-type="gif" data-w="636" style="outline: 0px;letter-spacing: 0.544px;font-size: var(--articleFontsize);border-radius: 8px;text-align: justify;width: 100%;visibility: visible !important;background-size: 16px !important;height: auto;" referrerpolicy="no-referrer"><br style="outline: 0px;visibility: visible;"></section><section data-mpa-template="t" data-mpa-template-id="502" data-mpa-category="模板" style="outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);visibility: visible;"><section data-mpa-category="模板" data-mid="" style="padding-right: 1px;padding-left: 1px;outline: 0px;width: 677px;display: flex;justify-content: flex-start;align-items: center;flex-direction: column;visibility: visible;"><section data-mid="" style="outline: 0px;letter-spacing: 0.544px;width: 675px;display: grid;grid-template-columns: 26px auto;visibility: visible;"><section data-mid="" style="outline: 0px;width: 26px;height: 14px;display: flex;justify-content: center;align-items: center;align-self: center;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section><section data-mid="" style="padding-left: 7px;outline: 0px;display: flex;justify-content: flex-start;align-items: center;visibility: visible;"><section data-mid="" style="margin-right: 7px;outline: 0px;text-align: left;visibility: visible;"><p data-mid="" style="outline: 0px;width: 0px;font-size: 14px;font-family: PingFangSC-Semibold, &quot;PingFang SC&quot;;font-weight: bold;color: rgb(58, 92, 244);line-height: 20px;visibility: visible;"><br style="outline: 0px;visibility: visible;"></p></section><section data-mid="" style="margin-bottom: 4px;outline: 0px;width: 635px;height: 1px;border-top: 1px solid rgb(58, 92, 244);align-self: flex-end;visibility: visible;"><br style="outline: 0px;visibility: visible;"></section></section></section><section data-mid="" style="padding: 7px 14px 9px 19px;outline: 0px;width: 675px;text-align: left;border-bottom: 1px solid rgb(58, 92, 244);visibility: visible;"><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;letter-spacing: 0.578px;text-align: justify;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;white-space-collapse: preserve;text-size-adjust: inherit;text-align: left;caret-color: rgb(23, 26, 29);letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;color: rgb(0, 0, 0);visibility: visible;font-size: 15px;">本文介紹瞭如何在<span style="font-size: 15px;letter-spacing: 1px;text-wrap: wrap;">自己的 MacBook 上部署一套知識庫方案輔助自己的知識管理工作，</span><span style="font-size: 15px;letter-spacing: 1px;text-wrap: wrap;">希望能給每位計劃自己搭建大模型知識庫應用的工程師一點參考。</span></span></p></section></section></section><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;line-height: 1.75em;"><br style="outline: 0px;visibility: visible;"></p><section style="margin-bottom: 0px;outline: 0px;box-sizing: inherit;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgba(25, 26, 31, 0.9);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;text-align: center;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041735" data-ratio="0.3161764705882353" data-s="300,640" src="https://oscimg.oschina.net/oscnet/1447be7f-ff8f-4af0-a27e-b2863660d071.png" data-type="png" data-w="408" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 113px !important;" referrerpolicy="no-referrer"></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;color: rgb(3, 69, 255);font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;visibility: visible;">背景</span></section><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></h4><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">歷史的車輪滾滾向前，大模型技術發展日新月異，每天都有新鮮的技術出爐，讓人目不暇接，同時具備可玩性和想象空間的各種應用和開源庫，彷彿讓自己回到了第一次設置 JAVA_HOME 的日子，作為一枚古典工程師，我專門挑了個可能對手上工作有幫助的方向小試一把，嘗試在自己的 MacBook 上部署一套知識庫方案，看看能不能輔助自己的知識管理工作。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">我自己的 Macbook 配置情況如下，可以流暢地運行沒問題。經過量化處理的大模型，還是對辦公本很友好的。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041733" data-ratio="0.24633431085043989" src="https://oscimg.oschina.net/oscnet/f4f317ea-3d61-4055-91c7-8f6534441328.jpg" data-type="other" data-w="682" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">為什麼要在 MacBook 搭建而不是直接採用現成的雲服務呢？最核心最重要的是我們手上的文檔資料出於安全要求，不能隨便上傳雲服務，也就無法實際驗證知識庫的實際效用；另外對於工程師來説，自己親手搭建一個完整的方案、能靈活調整和對接各種不同的模型、評測各種模型不同的表現，也是出於對技術的探索本能使然。</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">鑑於大模型已經是大模型及其周邊概念已經是大家耳熟能詳的東西，我這裏就不再重複闡述相關的基礎概念和理論了，直接進入動手環節，以用最快的速度部署起一個可用的知識庫平台為目標，先用起來，再分各個環節優化。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-bottom: 0px;outline: 0px;box-sizing: inherit;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgba(25, 26, 31, 0.9);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;font-size: 15px;letter-spacing: 1px;visibility: visible;"><img class="rich_pages wxw-img" data-imgfileid="503041732" data-ratio="0.3056872037914692" data-s="300,640" src="https://oscimg.oschina.net/oscnet/476e87ec-3926-4421-826d-d28a2c78789f.png" data-type="png" data-w="422" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 117px !important;" referrerpolicy="no-referrer"></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(34, 34, 34);text-align: center;visibility: visible;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;visibility: visible;color: rgb(0, 17, 255);">方案概述</span></section><section style="margin-bottom: 8px;"><br></section><span id="OSC_h4_1"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;margin-bottom: 8px;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">應用架構</span></strong></span></h4><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">首先來看一下最終方案的應用架構是什麼樣子（下圖）。在這套方案中，我們採用實力排上游、並且在使用上對學術和商業都友好的國產大模型 ChatGLM3-6B 對話模型和基於 m3e-base 模型的 embedding search RAG 方案；基於這兩個模型封裝和 ChatGPT 兼容的 API 接口協議；通過引入 One API 接口管理&amp;分發系統，形成統一的 LLM 接口渠道管理平台規範，並把封裝好的接口協議註冊進去；搭建與 Dify.ai 齊名的開源大模型知識庫平台管理系統 FastGPT，實現集私有知識數據源預處理、嵌入檢索、大模型對話一體的完整知識庫應用流程。麻雀雖小五臟俱全，最終形成一套既滿足商用標準、又能在 MacBook 跑起來的的方案。雖然智能程度和實際需求還有一定差距，但至少我們在不用額外購買顯卡或雲服務的情況下，以最小成本部署運行、並且能導入實際業務數據（如語雀知識庫）進行實操驗證，值得每位工程師都來動手嘗試一下。</span></section><p style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><img class="rich_pages wxw-img" data-imgfileid="503041734" data-ratio="0.7546296296296297" src="https://oscimg.oschina.net/oscnet/aa80fe6e-e7fa-4823-9906-d7c8f3ddcd3e.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></p><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><br></h4><span id="OSC_h4_2"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">成型展示</span></strong></span></h4><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"></h4><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">在用户終端，我們基於 FastGPT 提供知識庫管理及使用方案。引用其官網介紹：FastGPT 是一個基於 LLM 大語言模型的知識庫問答系統，提供開箱即用的數據處理、模型調用等能力。同時可以通過 Flow 可視化進行工作流編排，從而實現複雜的問答場景。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">先放一張官網上的圖片，來增加一點吸引朋友們動手操作的動力：</span></section><section style="margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041740" data-ratio="0.4842592592592593" src="https://oscimg.oschina.net/oscnet/b61b175a-2352-47d3-a57f-826fbb292f26.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><section style="margin-bottom: 8px;"><br></section><span id="OSC_h4_3"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">部署要點</span></strong></span></h4><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">本套方案部署分為四個主要環節、14 個具體步驟，只要一步步實操下去，每位朋友都可以在自己的本本上擁有屬於自己的私有大模型知識庫系統，步驟清單如下：</span></section><table width="628"><colgroup style="box-sizing: inherit;"><col width="192" style="box-sizing: inherit;"><col width="436" style="box-sizing: inherit;"></colgroup><tbody style="box-sizing: inherit;"><tr data-cangjie-key="87" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="89" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-weight: bold;letter-spacing: 1px;font-size: 15px;">主要環節</span></section></td><td data-cangjie-key="94" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-weight: bold;font-size: 15px;letter-spacing: 1px;">詳細步驟</span></section></td></tr><tr data-cangjie-key="99" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="101" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">一、準備大模型</span></section></td><td data-cangjie-key="106" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.1 下載對話語言模型 ChatGLM3-6B</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.2 下載文本嵌入模型 m3e-base</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.3 使用 chatglm.cpp 對 ChatGLM3-6B 進行量化加速</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1.4 驗證模型問答效果</span></section></td></tr><tr data-cangjie-key="120" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="122" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">二、搭建模型 API 服務</span></section></td><td data-cangjie-key="127" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2.1 搭建模型 API</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2.2 搭建 One API 接口管理/分發系統</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2.3 驗證模型接口能力</span></section></td></tr><tr data-cangjie-key="138" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="140" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">三、搭建知識庫應用</span></section></td><td data-cangjie-key="145" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.1 安裝 MongoDB</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.2 安裝 PostgreSQL &amp; pgvector</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.3 搭建 FastGPT 知識庫問答系統</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3.4 驗證模型對話能力</span></section></td></tr><tr data-cangjie-key="159" data-sticky="false" style="box-sizing: inherit;height: 33px;"><td data-cangjie-key="161" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">四、知識庫問答實戰</span></section></td><td data-cangjie-key="166" data-type="table-cell" rowspan="1" colspan="1" data-container-block="true" style="box-sizing: inherit;padding: 8px;border-color: rgba(88, 104, 144, 0.24);"><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">4.1 準備知識庫語料</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">4.2 導入知識庫數據</span></section><section style="line-height: normal;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">4.3 驗證知識庫問答效果</span></section></td></tr></tbody></table><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">部分步驟可以簡單地通過 Docker 鏡像一鍵部署完成，但本着對細節一杆子插到底的部署思路，還是採取了純手工作業的方法。注意，下面的步驟中僅包含了關鍵的命令，完整的命令可以參考對應系統的官網介紹。部分安裝步驟如果速度不夠理想，可以考慮採用國內源，包含但不限於 go、brew、pip、npm 等。</span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;visibility: visible;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041737" data-ratio="0.3056872037914692" data-s="300,640" data-type="png" data-w="422" src="https://oscimg.oschina.net/oscnet/c8d6ad94-b394-4e67-a5c3-8464690e8f51.png" style="outline: 0px;letter-spacing: 0.544px;font-size: 14px;visibility: visible !important;width: 117px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;visibility: visible;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 18px;letter-spacing: 1px;color: rgb(0, 17, 255);">詳細步驟</span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;visibility: visible;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><br></section><section style="margin-bottom: 8px;"><br></section><span id="OSC_h4_4"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">準備離線模型</span></strong></span></h4><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">這個環節我們的主要任務是把模型文件準備好、完成量化，並通過命令行的方式，進行交互式對話驗證。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_5"></span><h4 data-cangjie-key="195" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">下載對話語言模型 ChatGLM3-6B</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">為什麼選擇 ChatGLM3-6B？常年霸榜的開源國產之光。ChatGLM3 一共開源了對話模型 ChatGLM-6B、基礎模型 ChatGLM-6B-Base、長文本對話模型 ChatGLM3-6B-32K，對學術研究完全開放，在填寫問卷進行登記後亦允許免費商業使用。無論是用來做上手實踐還是微調練習，目前看來都是比較好的選擇。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">其實最重要的是，看看排行榜上的可選項，我的 MacBook 16G 內存只能帶得動 ChatGLM3-6B 量化版本：</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041741" data-ratio="0.37777777777777777" src="https://oscimg.oschina.net/oscnet/08ae148e-39dc-45c8-9196-b121dbef2503.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">ChatGLM3-6B 現在比較方便的下載渠道有 HuggingFace 和 ModelScope，但是很明顯能直接下載下來的可能性不大，所以我用家裏的舊電腦科學下載後放到私有云 CDN 上，然後再用公司電腦下載，也方便未來隨時隨地取用，就是要花點小錢。ModelScope 也試過，不能直接下載文件，並且用 git clone 速度也不太理想，遂放棄。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">如果用老一點的版本 ChatGLM2-6B 的話，網上也能找到一些比較好用的第三方鏡像站。</span></p><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">HuggingFace:THUDM/chatglm3-6b﻿</span></p></li><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">ModelScope:ZhipuAI/chatglm3-6b（</span><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">地址：https://modelscope.cn/models/ZhipuAI/chatglm3-6b/summary）</span></p></li></ol><section style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><br></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="php"><code><span class="code-snippet_outer">// 從 Git 倉庫下載模型文件</span></code><code><span class="code-snippet_outer">// HuggingFace</span></code><code><span class="code-snippet_outer">git lfs install</span></code><code><span class="code-snippet_outer">git clone https://huggingface.co/THUDM/chatglm3-6b</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// ModelScope</span></code><code><span class="code-snippet_outer">git lfs install</span></code><code><span class="code-snippet_outer">git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_6"></span><h4 data-cangjie-key="237" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">下載文本嵌入模型 m3e-base</span></h4></li></ul><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">為什麼選擇 moka-ai 的 M3E 模型 m3e-base？M3E 向量模型屬於小模型，資源使用不高，CPU 也可以運行，使用場景主要是中文，少量英文的情況。用來驗證我們的知識庫系統足夠了</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">官方下載地址：moka-ai/m3e-base，先把所有的模型文件 download 下來，後面使用</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_7"></span><h4 data-cangjie-key="253" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">使用 chatglm.cpp 對 ChatGLM3-6B 進行量化加速</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">當我第一次知道 chatglm.cpp，只能説好人一生平安，chatglm.cpp 的出現拯救了純 MacBook 黨，讓我們能在（低性能的）果本上基於 CPU 進行推理，也不會損失過多的精度。（其實損失多少我也不知道，不影響我們正常進行工程部署驗證就行）</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">Github Repo: https://github.com/li-plus/chatglm.cpp﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">我使用的 Python 版本：3.11，最好單獨準備一個 virtualenv</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041738" data-ratio="0.13240740740740742" src="https://oscimg.oschina.net/oscnet/e1860e0e-5e2f-4eaf-8411-dab67f6a95cd.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">安裝依賴：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer">cd /Users/yaolu/AGI/github/chatglm.cpp</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 先初始化 git 倉庫</span></code><code><span class="code-snippet_outer">git submodule update --init --recursive</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 構建可執行文件</span></code><code><span class="code-snippet_outer">cmake -B build</span></code><code><span class="code-snippet_outer">cmake --build build -j</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 安裝 Python 依賴</span></code><code><span class="code-snippet_outer">pip install .</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">如果發生 No module named 'chatglm_cpp._C' 的錯誤，把編譯出來的文件 _C.cpython-311-darwin.so 放到 chatglm_cpp 目錄下。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">對 ChatGLM3-6B 進行 8-bit 量化處理：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="nginx"><code><span class="code-snippet_outer">python ./chatglm_cpp/convert.py -i /Users/yaolu/AGI/huggingface/THUDM/chatglm3-6b -t q8_0 -o chatglm3-ggml-q8.bin</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">如果電腦帶不動，還可以嘗試 4-bit、5-bit 參數量化，完整參數列表見 chatglm.cpp 的 quantization types</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_8"></span><h4 data-cangjie-key="300" data-cangjie-leaf-block="true" data-type="heading-4" style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">驗證模型問答效果</span></h4></li></ul><p style="margin-bottom: 8px;margin-top: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">完成模型量化後，就可以在本地把大模型跑起來了，命令如下：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js"><code><span class="code-snippet_outer">./build/bin/main -m chatglm3-ggml-q8.bin -i</span></code></pre></section><p style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;"><br></p><p style="line-height: 1.75em;margin-bottom: 8px;margin-top: 8px;text-align: center;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041739" data-ratio="0.5796296296296296" src="https://oscimg.oschina.net/oscnet/a783a6e0-4e31-4f72-81ca-8f9e37688b7f.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><span id="OSC_h4_9"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">搭建模型 API 服務</span></strong></span></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">我們在這個環節要完成的任務是，按照 ChatGPT 的接口規範、基於 FastAPI 封裝 ChatGLM3-6B 的對話和 m3e-base 的嵌入能力；並註冊到 One API 接口管理/分發系統中。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_10"></span><h4 data-cangjie-key="325" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">搭建模型 API</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">用 chatglm.cpp 自帶的 openai_api.py 魔改了一下，使其支持完成對話和文本 embedding 的兩個核心調用：</span></section><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">/v1/chat/completions</span></section></li><li><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">/v1/embeddings</span></section></li></ol><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">代碼如下：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer">import asyncio</span></code><code><span class="code-snippet_outer">import logging</span></code><code><span class="code-snippet_outer">import time</span></code><code><span class="code-snippet_outer">from typing import List, Literal, Optional, Union</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">import chatglm_cpp</span></code><code><span class="code-snippet_outer">from fastapi import FastAPI, HTTPException, status, Depends</span></code><code><span class="code-snippet_outer">from fastapi.middleware.cors import CORSMiddleware</span></code><code><span class="code-snippet_outer">from pydantic import BaseModel, Field#, computed_field</span></code><code><span class="code-snippet_outer">#from pydantic_settings import BaseSettings</span></code><code><span class="code-snippet_outer">from sse_starlette.sse import EventSourceResponse</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">from sentence_transformers import SentenceTransformer</span></code><code><span class="code-snippet_outer">from sklearn.preprocessing import PolynomialFeatures</span></code><code><span class="code-snippet_outer">import numpy as np</span></code><code><span class="code-snippet_outer">import tiktoken</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">logging.basicConfig(level=logging.INFO, format=r"%(asctime)s - %(module)s - %(levelname)s - %(message)s")</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class Settings(object):</span></code><code><span class="code-snippet_outer">    model: str = "/Users/yaolu/AGI/github/chatglm.cpp/chatglm3-ggml-q8.bin"</span></code><code><span class="code-snippet_outer">    num_threads: int = 0</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatMessage(BaseModel):</span></code><code><span class="code-snippet_outer">    role: Literal["system", "user", "assistant"]</span></code><code><span class="code-snippet_outer">    content: str</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class DeltaMessage(BaseModel):</span></code><code><span class="code-snippet_outer">    role: Optional[Literal["system", "user", "assistant"]] = None</span></code><code><span class="code-snippet_outer">    content: Optional[str] = None</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionRequest(BaseModel):</span></code><code><span class="code-snippet_outer">    model: str = "default-model"</span></code><code><span class="code-snippet_outer">    messages: List[ChatMessage]</span></code><code><span class="code-snippet_outer">    temperature: float = Field(default=0.95, ge=0.0, le=2.0)</span></code><code><span class="code-snippet_outer">    top_p: float = Field(default=0.7, ge=0.0, le=1.0)</span></code><code><span class="code-snippet_outer">    stream: bool = False</span></code><code><span class="code-snippet_outer">    max_tokens: int = Field(default=2048, ge=0)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    model_config = {</span></code><code><span class="code-snippet_outer">        "json_schema_extra": {"examples": [{"model": "default-model", "messages": [{"role": "user", "content": "你好"}]}]}</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionResponseChoice(BaseModel):</span></code><code><span class="code-snippet_outer">    index: int = 0</span></code><code><span class="code-snippet_outer">    message: ChatMessage</span></code><code><span class="code-snippet_outer">    finish_reason: Literal["stop", "length"] = "stop"</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionResponseStreamChoice(BaseModel):</span></code><code><span class="code-snippet_outer">    index: int = 0</span></code><code><span class="code-snippet_outer">    delta: DeltaMessage</span></code><code><span class="code-snippet_outer">    finish_reason: Optional[Literal["stop", "length"]] = None</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionUsage(BaseModel):</span></code><code><span class="code-snippet_outer">    prompt_tokens: int</span></code><code><span class="code-snippet_outer">    completion_tokens: int</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    #@computed_field</span></code><code><span class="code-snippet_outer">    @property</span></code><code><span class="code-snippet_outer">    def total_tokens(self) -&gt; int:</span></code><code><span class="code-snippet_outer">        return self.prompt_tokens + self.completion_tokens</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ChatCompletionResponse(BaseModel):</span></code><code><span class="code-snippet_outer">    id: str = "chatcmpl"</span></code><code><span class="code-snippet_outer">    model: str = "default-model"</span></code><code><span class="code-snippet_outer">    object: Literal["chat.completion", "chat.completion.chunk"]</span></code><code><span class="code-snippet_outer">    created: int = Field(default_factory=lambda: int(time.time()))</span></code><code><span class="code-snippet_outer">    choices: Union[List[ChatCompletionResponseChoice], List[ChatCompletionResponseStreamChoice]]</span></code><code><span class="code-snippet_outer">    usage: Optional[ChatCompletionUsage] = None</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    model_config = {</span></code><code><span class="code-snippet_outer">        "json_schema_extra": {</span></code><code><span class="code-snippet_outer">            "examples": [</span></code><code><span class="code-snippet_outer">                {</span></code><code><span class="code-snippet_outer">                    "id": "chatcmpl",</span></code><code><span class="code-snippet_outer">                    "model": "default-model",</span></code><code><span class="code-snippet_outer">                    "object": "chat.completion",</span></code><code><span class="code-snippet_outer">                    "created": 1691166146,</span></code><code><span class="code-snippet_outer">                    "choices": [</span></code><code><span class="code-snippet_outer">                        {</span></code><code><span class="code-snippet_outer">                            "index": 0,</span></code><code><span class="code-snippet_outer">                            "message": {"role": "assistant", "content": "你好👋！我是人工智能助手 ChatGLM2-6B，很高興見到你，歡迎問我任何問題。"},</span></code><code><span class="code-snippet_outer">                            "finish_reason": "stop",</span></code><code><span class="code-snippet_outer">                        }</span></code><code><span class="code-snippet_outer">                    ],</span></code><code><span class="code-snippet_outer">                    "usage": {"prompt_tokens": 17, "completion_tokens": 29, "total_tokens": 46},</span></code><code><span class="code-snippet_outer">                }</span></code><code><span class="code-snippet_outer">            ]</span></code><code><span class="code-snippet_outer">        }</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">settings = Settings()</span></code><code><span class="code-snippet_outer">app = FastAPI()</span></code><code><span class="code-snippet_outer">app.add_middleware(</span></code><code><span class="code-snippet_outer">    CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]</span></code><code><span class="code-snippet_outer">)</span></code><code><span class="code-snippet_outer">pipeline = chatglm_cpp.Pipeline(settings.model)</span></code><code><span class="code-snippet_outer">lock = asyncio.Lock()</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">embeddings_model = SentenceTransformer('/Users/yaolu/AGI/huggingface/moka-ai/m3e-base', device='cpu')</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">def stream_chat(history, body):</span></code><code><span class="code-snippet_outer">    yield ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">        object="chat.completion.chunk",</span></code><code><span class="code-snippet_outer">        choices=[ChatCompletionResponseStreamChoice(delta=DeltaMessage(role="assistant"))],</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    for piece in pipeline.chat(</span></code><code><span class="code-snippet_outer">        history,</span></code><code><span class="code-snippet_outer">        max_length=body.max_tokens,</span></code><code><span class="code-snippet_outer">        do_sample=body.temperature &gt; 0,</span></code><code><span class="code-snippet_outer">        top_p=body.top_p,</span></code><code><span class="code-snippet_outer">        temperature=body.temperature,</span></code><code><span class="code-snippet_outer">        num_threads=settings.num_threads,</span></code><code><span class="code-snippet_outer">        stream=True,</span></code><code><span class="code-snippet_outer">    ):</span></code><code><span class="code-snippet_outer">        yield ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">            object="chat.completion.chunk",</span></code><code><span class="code-snippet_outer">            choices=[ChatCompletionResponseStreamChoice(delta=DeltaMessage(content=piece))],</span></code><code><span class="code-snippet_outer">        )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    yield ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">        object="chat.completion.chunk",</span></code><code><span class="code-snippet_outer">        choices=[ChatCompletionResponseStreamChoice(delta=DeltaMessage(), finish_reason="stop")],</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">async def stream_chat_event_publisher(history, body):</span></code><code><span class="code-snippet_outer">    output = ""</span></code><code><span class="code-snippet_outer">    try:</span></code><code><span class="code-snippet_outer">        async with lock:</span></code><code><span class="code-snippet_outer">            for chunk in stream_chat(history, body):</span></code><code><span class="code-snippet_outer">                await asyncio.sleep(0)  # yield control back to event loop for cancellation check</span></code><code><span class="code-snippet_outer">                output += chunk.choices[0].delta.content or ""</span></code><code><span class="code-snippet_outer">                yield chunk.model_dump_json(exclude_unset=True)</span></code><code><span class="code-snippet_outer">        logging.info(f'prompt: "{history[-1]}", stream response: "{output}"')</span></code><code><span class="code-snippet_outer">    except asyncio.CancelledError as e:</span></code><code><span class="code-snippet_outer">        logging.info(f'prompt: "{history[-1]}", stream response (partial): "{output}"')</span></code><code><span class="code-snippet_outer">        raise e</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">@app.post("/v1/chat/completions")</span></code><code><span class="code-snippet_outer">async def create_chat_completion(body: ChatCompletionRequest) -&gt; ChatCompletionResponse:</span></code><code><span class="code-snippet_outer">    # ignore system messages</span></code><code><span class="code-snippet_outer">    history = [msg.content for msg in body.messages if msg.role != "system"]</span></code><code><span class="code-snippet_outer">    if len(history) % 2 != 1:</span></code><code><span class="code-snippet_outer">        raise HTTPException(status.HTTP_400_BAD_REQUEST, "invalid history size")</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    if body.stream:</span></code><code><span class="code-snippet_outer">        generator = stream_chat_event_publisher(history, body)</span></code><code><span class="code-snippet_outer">        return EventSourceResponse(generator)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    max_context_length = 512</span></code><code><span class="code-snippet_outer">    output = pipeline.chat(</span></code><code><span class="code-snippet_outer">        history=history,</span></code><code><span class="code-snippet_outer">        max_length=body.max_tokens,</span></code><code><span class="code-snippet_outer">        max_context_length=max_context_length,</span></code><code><span class="code-snippet_outer">        do_sample=body.temperature &gt; 0,</span></code><code><span class="code-snippet_outer">        top_p=body.top_p,</span></code><code><span class="code-snippet_outer">        temperature=body.temperature,</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer">    logging.info(f'prompt: "{history[-1]}", sync response: "{output}"')</span></code><code><span class="code-snippet_outer">    prompt_tokens = len(pipeline.tokenizer.encode_history(history, max_context_length))</span></code><code><span class="code-snippet_outer">    completion_tokens = len(pipeline.tokenizer.encode(output, body.max_tokens))</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    return ChatCompletionResponse(</span></code><code><span class="code-snippet_outer">        object="chat.completion",</span></code><code><span class="code-snippet_outer">        choices=[ChatCompletionResponseChoice(message=ChatMessage(role="assistant", content=output))],</span></code><code><span class="code-snippet_outer">        usage=ChatCompletionUsage(prompt_tokens=prompt_tokens, completion_tokens=completion_tokens),</span></code><code><span class="code-snippet_outer">    )</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class EmbeddingRequest(BaseModel):</span></code><code><span class="code-snippet_outer">    input: List[str]</span></code><code><span class="code-snippet_outer">    model: str</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class EmbeddingResponse(BaseModel):</span></code><code><span class="code-snippet_outer">    data: list</span></code><code><span class="code-snippet_outer">    model: str</span></code><code><span class="code-snippet_outer">    object: str</span></code><code><span class="code-snippet_outer">    usage: dict</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">def num_tokens_from_string(string: str) -&gt; int:</span></code><code><span class="code-snippet_outer">    """Returns the number of tokens in a text string."""</span></code><code><span class="code-snippet_outer">    encoding = tiktoken.get_encoding('cl100k_base')</span></code><code><span class="code-snippet_outer">    num_tokens = len(encoding.encode(string))</span></code><code><span class="code-snippet_outer">    return num_tokens</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">def expand_features(embedding, target_length):</span></code><code><span class="code-snippet_outer">    poly = PolynomialFeatures(degree=2)</span></code><code><span class="code-snippet_outer">    expanded_embedding = poly.fit_transform(embedding.reshape(1, -1))</span></code><code><span class="code-snippet_outer">    expanded_embedding = expanded_embedding.flatten()</span></code><code><span class="code-snippet_outer">    if len(expanded_embedding) &gt; target_length:</span></code><code><span class="code-snippet_outer">        # 如果擴展後的特徵超過目標長度，可以通過截斷或其他方法來減少維度</span></code><code><span class="code-snippet_outer">        expanded_embedding = expanded_embedding[:target_length]</span></code><code><span class="code-snippet_outer">    elif len(expanded_embedding) &lt; target_length:</span></code><code><span class="code-snippet_outer">        # 如果擴展後的特徵少於目標長度，可以通過填充或其他方法來增加維度</span></code><code><span class="code-snippet_outer">        expanded_embedding = np.pad(expanded_embedding, (0, target_length - len(expanded_embedding)))</span></code><code><span class="code-snippet_outer">    return expanded_embedding</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">@app.post("/v1/embeddings", response_model=EmbeddingResponse)</span></code><code><span class="code-snippet_outer">async def get_embeddings(request: EmbeddingRequest):</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # 計算嵌入向量和 tokens 數量 </span></code><code><span class="code-snippet_outer">    embeddings = [embeddings_model.encode(text) for text in request.input]</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # 如果嵌入向量的維度不為 1536，則使用插值法擴展至 1536 維度 </span></code><code><span class="code-snippet_outer">    embeddings = [expand_features(embedding, 1536) if len(embedding) &lt; 1536 else embedding for embedding in embeddings]</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # Min-Max normalization</span></code><code><span class="code-snippet_outer">    embeddings = [embedding / np.linalg.norm(embedding) for embedding in embeddings]</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    # 將 numpy 數組轉換為列表</span></code><code><span class="code-snippet_outer">    embeddings = [embedding.tolist() for embedding in embeddings]</span></code><code><span class="code-snippet_outer">    prompt_tokens = sum(len(text.split()) for text in request.input)</span></code><code><span class="code-snippet_outer">    total_tokens = sum(num_tokens_from_string(text) for text in request.input)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    response = {</span></code><code><span class="code-snippet_outer">        "data": [</span></code><code><span class="code-snippet_outer">            {</span></code><code><span class="code-snippet_outer">                "embedding": embedding,</span></code><code><span class="code-snippet_outer">                "index": index,</span></code><code><span class="code-snippet_outer">                "object": "embedding"</span></code><code><span class="code-snippet_outer">            } for index, embedding in enumerate(embeddings)</span></code><code><span class="code-snippet_outer">        ],</span></code><code><span class="code-snippet_outer">        "model": request.model,</span></code><code><span class="code-snippet_outer">        "object": "list",</span></code><code><span class="code-snippet_outer">        "usage": {</span></code><code><span class="code-snippet_outer">            "prompt_tokens": prompt_tokens,</span></code><code><span class="code-snippet_outer">            "total_tokens": total_tokens,</span></code><code><span class="code-snippet_outer">        }</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    return response</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ModelCard(BaseModel):</span></code><code><span class="code-snippet_outer">    id: str</span></code><code><span class="code-snippet_outer">    object: Literal["model"] = "model"</span></code><code><span class="code-snippet_outer">    owned_by: str = "owner"</span></code><code><span class="code-snippet_outer">    permission: List = []</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">class ModelList(BaseModel):</span></code><code><span class="code-snippet_outer">    object: Literal["list"] = "list"</span></code><code><span class="code-snippet_outer">    data: List[ModelCard] = []</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">    model_config = {</span></code><code><span class="code-snippet_outer">        "json_schema_extra": {</span></code><code><span class="code-snippet_outer">            "examples": [</span></code><code><span class="code-snippet_outer">                {</span></code><code><span class="code-snippet_outer">                    "object": "list",</span></code><code><span class="code-snippet_outer">                    "data": [{"id": "gpt-3.5-turbo", "object": "model", "owned_by": "owner", "permission": []}],</span></code><code><span class="code-snippet_outer">                }</span></code><code><span class="code-snippet_outer">            ]</span></code><code><span class="code-snippet_outer">        }</span></code><code><span class="code-snippet_outer">    }</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">@app.get("/v1/models")</span></code><code><span class="code-snippet_outer">async def list_models() -&gt; ModelList:</span></code><code><span class="code-snippet_outer">    return ModelList(data=[ModelCard(id="gpt-3.5-turbo")])</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">讓他跑起來的命令，跑在 8000 端口下：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="css"><code><span class="code-snippet_outer">uvicorn chatglm_cpp.openai_api:app --host 127.0.0.1 --port 8000</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">運行該程序所需的 Python 依賴項：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="ini"><code><span class="code-snippet_outer">accelerate==0.24.1</span></code><code><span class="code-snippet_outer">aiofiles==23.2.1</span></code><code><span class="code-snippet_outer">aiohttp==3.8.6</span></code><code><span class="code-snippet_outer">aiosignal==1.3.1</span></code><code><span class="code-snippet_outer">altair==5.1.2</span></code><code><span class="code-snippet_outer">annotated-types==0.6.0</span></code><code><span class="code-snippet_outer">anyio==3.7.1</span></code><code><span class="code-snippet_outer">async-timeout==4.0.3</span></code><code><span class="code-snippet_outer">attrs==23.1.0</span></code><code><span class="code-snippet_outer">blinker==1.7.0</span></code><code><span class="code-snippet_outer">cachetools==5.3.2</span></code><code><span class="code-snippet_outer">certifi==2023.7.22</span></code><code><span class="code-snippet_outer">charset-normalizer==3.3.2</span></code><code><span class="code-snippet_outer">click==8.1.7</span></code><code><span class="code-snippet_outer">contourpy==1.2.0</span></code><code><span class="code-snippet_outer">cpm-kernels==1.0.11</span></code><code><span class="code-snippet_outer">cycler==0.12.1</span></code><code><span class="code-snippet_outer">fastapi==0.103.2</span></code><code><span class="code-snippet_outer">ffmpy==0.3.1</span></code><code><span class="code-snippet_outer">filelock==3.13.1</span></code><code><span class="code-snippet_outer">fonttools==4.44.0</span></code><code><span class="code-snippet_outer">frozenlist==1.4.0</span></code><code><span class="code-snippet_outer">fsspec==2023.10.0</span></code><code><span class="code-snippet_outer">gitdb==4.0.11</span></code><code><span class="code-snippet_outer">GitPython==3.1.40</span></code><code><span class="code-snippet_outer">gradio==3.50.2</span></code><code><span class="code-snippet_outer">gradio_client==0.6.1</span></code><code><span class="code-snippet_outer">h11==0.14.0</span></code><code><span class="code-snippet_outer">httpcore==1.0.2</span></code><code><span class="code-snippet_outer">httpx==0.25.1</span></code><code><span class="code-snippet_outer">huggingface-hub==0.19.1</span></code><code><span class="code-snippet_outer">idna==3.4</span></code><code><span class="code-snippet_outer">importlib-metadata==6.8.0</span></code><code><span class="code-snippet_outer">importlib-resources==6.1.1</span></code><code><span class="code-snippet_outer">Jinja2==3.1.2</span></code><code><span class="code-snippet_outer">joblib==1.3.2</span></code><code><span class="code-snippet_outer">jsonschema==4.19.2</span></code><code><span class="code-snippet_outer">jsonschema-specifications==2023.7.1</span></code><code><span class="code-snippet_outer">kiwisolver==1.4.5</span></code><code><span class="code-snippet_outer">latex2mathml==3.76.0</span></code><code><span class="code-snippet_outer">linkify-it-py==2.0.2</span></code><code><span class="code-snippet_outer">Markdown==3.5.1</span></code><code><span class="code-snippet_outer">markdown-it-py==2.2.0</span></code><code><span class="code-snippet_outer">MarkupSafe==2.1.3</span></code><code><span class="code-snippet_outer">matplotlib==3.8.1</span></code><code><span class="code-snippet_outer">mdit-py-plugins==0.3.3</span></code><code><span class="code-snippet_outer">mdtex2html==1.2.0</span></code><code><span class="code-snippet_outer">mdurl==0.1.2</span></code><code><span class="code-snippet_outer">mpmath==1.3.0</span></code><code><span class="code-snippet_outer">multidict==6.0.4</span></code><code><span class="code-snippet_outer">networkx==3.2.1</span></code><code><span class="code-snippet_outer">nltk==3.8.1</span></code><code><span class="code-snippet_outer">numpy==1.26.2</span></code><code><span class="code-snippet_outer">orjson==3.9.10</span></code><code><span class="code-snippet_outer">packaging==23.2</span></code><code><span class="code-snippet_outer">pandas==2.1.3</span></code><code><span class="code-snippet_outer">Pillow==10.1.0</span></code><code><span class="code-snippet_outer">protobuf==4.25.0</span></code><code><span class="code-snippet_outer">psutil==5.9.6</span></code><code><span class="code-snippet_outer">pyarrow==14.0.1</span></code><code><span class="code-snippet_outer">pydantic==2.1.1</span></code><code><span class="code-snippet_outer">pydantic_core==2.4.0</span></code><code><span class="code-snippet_outer">pydeck==0.8.1b0</span></code><code><span class="code-snippet_outer">pydub==0.25.1</span></code><code><span class="code-snippet_outer">Pygments==2.16.1</span></code><code><span class="code-snippet_outer">pyparsing==3.1.1</span></code><code><span class="code-snippet_outer">python-dateutil==2.8.2</span></code><code><span class="code-snippet_outer">python-multipart==0.0.6</span></code><code><span class="code-snippet_outer">pytz==2023.3.post1</span></code><code><span class="code-snippet_outer">PyYAML==6.0.1</span></code><code><span class="code-snippet_outer">referencing==0.30.2</span></code><code><span class="code-snippet_outer">regex==2023.10.3</span></code><code><span class="code-snippet_outer">requests==2.31.0</span></code><code><span class="code-snippet_outer">rich==13.6.0</span></code><code><span class="code-snippet_outer">rpds-py==0.12.0</span></code><code><span class="code-snippet_outer">safetensors==0.4.0</span></code><code><span class="code-snippet_outer">scikit-learn==1.3.2</span></code><code><span class="code-snippet_outer">scipy==1.11.3</span></code><code><span class="code-snippet_outer">semantic-version==2.10.0</span></code><code><span class="code-snippet_outer">sentence-transformers==2.2.2</span></code><code><span class="code-snippet_outer">sentencepiece==0.1.99</span></code><code><span class="code-snippet_outer">six==1.16.0</span></code><code><span class="code-snippet_outer">smmap==5.0.1</span></code><code><span class="code-snippet_outer">sniffio==1.3.0</span></code><code><span class="code-snippet_outer">sse-starlette==1.6.5</span></code><code><span class="code-snippet_outer">starlette==0.27.0</span></code><code><span class="code-snippet_outer">streamlit==1.28.2</span></code><code><span class="code-snippet_outer">sympy==1.12</span></code><code><span class="code-snippet_outer">tabulate==0.9.0</span></code><code><span class="code-snippet_outer">tenacity==8.2.3</span></code><code><span class="code-snippet_outer">threadpoolctl==3.2.0</span></code><code><span class="code-snippet_outer">tiktoken==0.5.1</span></code><code><span class="code-snippet_outer">tokenizers==0.13.3</span></code><code><span class="code-snippet_outer">toml==0.10.2</span></code><code><span class="code-snippet_outer">toolz==0.12.0</span></code><code><span class="code-snippet_outer">torch==2.1.0</span></code><code><span class="code-snippet_outer">torchvision==0.16.0</span></code><code><span class="code-snippet_outer">tornado==6.3.3</span></code><code><span class="code-snippet_outer">tqdm==4.66.1</span></code><code><span class="code-snippet_outer">transformers==4.30.2</span></code><code><span class="code-snippet_outer">typing_extensions==4.6.1</span></code><code><span class="code-snippet_outer">tzdata==2023.3</span></code><code><span class="code-snippet_outer">tzlocal==5.2</span></code><code><span class="code-snippet_outer">uc-micro-py==1.0.2</span></code><code><span class="code-snippet_outer">urllib3==2.1.0</span></code><code><span class="code-snippet_outer">uvicorn==0.24.0.post1</span></code><code><span class="code-snippet_outer">validators==0.22.0</span></code><code><span class="code-snippet_outer">websockets==11.0.3</span></code><code><span class="code-snippet_outer">yarl==1.9.2</span></code><code><span class="code-snippet_outer">zipp==3.17.0</span></code><code><span class="code-snippet_outer"><br></span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_11"></span><h4 data-cangjie-key="358" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">搭建 One API 接口管理/分發系統</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">﻿One API 是一套兼容多種 LLM 接口規範的 API 路由方案，支持限額和計費管理，通過標準的 OpenAI API 格式訪問所有的大模型，開箱即用，其多模型渠道接入、多用户管理、費用管理、額度管理、以及集羣化部署支持等功能，對商用場景都很友好。項目使用 MIT 協議進行開源。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">One API 基於 Go 和 Node.js 開發，搭建之前準備好，我的版本是：go1.21.4、Node.js v20.9.0，構建命令如下：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer">git clone https://github.com/songquanpeng/one-api.git</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 構建前端</span></code><code><span class="code-snippet_outer">cd one-api/web</span></code><code><span class="code-snippet_outer">npm install</span></code><code><span class="code-snippet_outer">npm run build</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"># 構建後端</span></code><code><span class="code-snippet_outer">cd ..</span></code><code><span class="code-snippet_outer">go mod download</span></code><code><span class="code-snippet_outer">go build -ldflags "-s -w" -o one-api</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">One API 裏面預置了很多市面上的可用模型接口，好處是可以直接使用無需配置，缺點是沒有添加自定義（本地）接口的能力。由於我們是自己搭建的 LLM 和 embedding 服務，需要修改其源代碼，增加 ChatGLM3 和 m3e-base 的選項。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">改動涉及兩個文件，分別是 common/model-ratio.go 和 controller/model.go，改動內容如下圖：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041746" data-ratio="0.5166666666666667" src="https://oscimg.oschina.net/oscnet/b980c07e-c638-4726-8149-aa6f42f3df6b.jpg" data-type="other" data-w="1080" style="width: 578px;height: auto;" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041745" data-ratio="0.4564814814814815" src="https://oscimg.oschina.net/oscnet/bc153ea4-f8c8-4029-bef4-d61d6562cb64.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;">注意，改完文件後記得重新編譯可執行文件。本地的元數據存儲我使用了 MySQL，編譯+啓動命令是：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="bash"><code><span class="code-snippet_outer">go build -ldflags "-s -w" -o one-api</span></code><code><span class="code-snippet_outer">export SQL_DSN=oneapi:oneapi@tcp(localhost:3306)/oneapi &amp;&amp; ./one-api --port 3001 --log-dir ./log</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">初始登錄進去，創建一個新令牌用於權限管控和計費：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041742" data-ratio="0.4074074074074074" src="https://oscimg.oschina.net/oscnet/633c7cae-c8f2-479a-abdd-7ea0b14593d1.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">令牌可以從這裏複製，下面有用：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="letter-spacing: 1px;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041743" data-ratio="0.2824074074074074" src="https://oscimg.oschina.net/oscnet/22e2145c-3437-4ad8-8052-d99cf2bed6e6.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">One API 的渠道管理界面如下圖，我已經配置了倆渠道，一個 chat 渠道，一個 embedding 渠道：</span></p><p><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041744" data-ratio="0.4546296296296296" src="https://oscimg.oschina.net/oscnet/f988f5ad-ffb3-4568-9e4e-12f80431bad8.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">具體的配置值如下圖，名稱寫實際的模型名 ChatGLM3，模型選剛才手動添加上去的 ChatGLM3：</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041751" data-ratio="0.7148148148148148" src="https://oscimg.oschina.net/oscnet/a3ae8bc9-2ce8-466a-8e32-2327dd193a66.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041747" data-ratio="0.7185185185185186" src="https://oscimg.oschina.net/oscnet/af7b338e-56ca-42e3-873a-f194005c09cb.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">配置完後可以在列表頁點一下測試驗證，連通無問題就行，但現在似乎一測就會把模型 API 服務弄掛，不過沒關係，不影響後面驗證。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><span id="OSC_h4_12"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">搭建知識庫應用</span></strong></span></h4><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">在這個環節裏，我們採用類似 Dify.ai （地址：https://dify.ai/）的國產化開源 FastGPT 方案搭建屬於自己的本地知識庫應用平台。FastGPT 是一個基於 LLM 大語言模型的知識庫問答系統，提供開箱即用的數據處理、模型調用等能力。同時可以通過 Flow 可視化進行工作流編排，從而實現複雜的問答場景。FastGPT 遵循 Apache License 2.0 開源協議，我們可以 Fork 之後進行二次開發和發佈。</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 的核心流程圖如下：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041748" data-ratio="0.525" src="https://oscimg.oschina.net/oscnet/dbc410c8-6a51-451c-a9d8-7c05661240c8.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">從 FastGPT 官網得知，這套開源系統基於以下幾個基本概念進行知識庫檢索：</span></p><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">向量：將人類直觀的語言（文字、圖片、視頻等）轉成計算機可識別的語言（數組）。</span></p></li><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">向量相似度：兩個向量之間可以進行計算，得到一個相似度，即代表：兩個語言相似的程度。</span></p></li><li><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">語言大模型的一些特點：上下文理解、總結和推理。</span></p></li></ol><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">結合上述 3 個概念，便有了 「向量搜索 + 大模型 = 知識庫問答」 的公式。下圖是 FastGPT V3 中知識庫問答功能的完整邏輯：</span></p><section style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041749" data-ratio="0.46296296296296297" src="https://oscimg.oschina.net/oscnet/1bed1c79-1bae-44a9-897a-ac6100c37f67.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 的向量存儲方案是 PostgreSQL+pgvector，其他數據放在 MongoDB 裏面，因此我們先把這兩項依賴搞定。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_13"></span><h4 data-cangjie-key="538" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">安裝 MongoDB</span></h4></li></ul><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">MacBook 安裝 MongoDB 很簡單，如果沒有特別的安全訴求，可以先不用設置用户名密碼</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer">brew install mongodb-community</span></code><code><span class="code-snippet_outer">brew services start mongodb-community</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 基於 MongoDB 存儲知識庫索引、會話內容、工作流等管理數據：</span></section><section style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041750" data-ratio="1.3333333333333333" src="https://oscimg.oschina.net/oscnet/72381400-16aa-4e0b-b636-70faee6c5c51.jpg" data-type="other" data-w="450" referrerpolicy="no-referrer"></span></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_14"></span><h4 data-cangjie-key="560" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">安裝 PostgreSQL &amp; pgvector</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 採用了 RAG 中的 Embedding 方案構建知識庫，PostgresSQL 的 PG Vector 插件作為向量檢索器，索引為 HNSW。PostgresSQL 僅用於向量檢索，MongoDB 用於其他數據的存取。另外也可以採用第三方模型的 Embedding API，比如 ChatGPT embedding，不過為了實現完整的本地化部署，就沒有用外部服務。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">我們可以從 PostgreSQL 的官網下載 PostgreSQL 安裝包：https://www.postgresql.org/download/macosx/﻿</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">從源碼安裝 pgvector：https://github.com/pgvector/pgvector</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="typescript"><code><span class="code-snippet_outer">// 安裝 pgvector 前指定 PostgreSQL 位置</span></code><code><span class="code-snippet_outer">export PG_CONFIG=/Library/PostgreSQL/16/bin/pg_config</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// 如果 pgvector 認錯了 MacOS SDK 的位置，還得幫他軟鏈一個</span></code><code><span class="code-snippet_outer">sudo ln -s /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk /Library/Developer/CommandLineTools/SDKs/MacOSX11.sdk</span></code><code><span class="code-snippet_outer">// 或者用這個命令</span></code><code><span class="code-snippet_outer">export SDKROOT=$(xcrun --sdk macosx --show-sdk-path)</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// 源碼編譯安裝 </span></code><code><span class="code-snippet_outer">make</span></code><code><span class="code-snippet_outer">make install # may need sudo</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">// 確保插件已安裝到 PostgreSQL 目錄下</span></code><code><span class="code-snippet_outer">cd /Library/PostgreSQL/16/share/postgresql/extension/</span></code><code><span class="code-snippet_outer">ls | grep vector</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">完成以上步驟後，打開 PostgreSQL 控制枱，隨便建立一個連接，運行下面的查詢：</span></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer">CREATE EXTENSION vector;</span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer">SELECT * FROM pg_extension WHERE extname = 'vector';</span></code></pre></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">如果能出現下圖結果，説明 pgvector 已經安裝成功：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041753" data-ratio="0.44166666666666665" src="https://oscimg.oschina.net/oscnet/dac102ea-3331-4cba-9e81-a7bbf955d8ea.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_15"></span><h4 data-cangjie-key="605" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">搭建 FastGPT 知識庫問答系統</span></h4></li></ul><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">好，我們的主角終於上場了，下面有請 FastGPT，安裝指南見：https://doc.fastgpt.in/docs/development/intro/﻿</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第一步，按照裏面的步驟，配置 .env.local 文件內容，指定 One API、MongoDB 和 PostgreSQL 的訪問地址：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041755" data-ratio="0.3675925925925926" src="https://oscimg.oschina.net/oscnet/ad8bc609-8cdc-4490-9d41-6d0cf05d1086.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">這裏的 CHAT_API_KEY 填入上面 OneAPI 創建的令牌</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第二步，在 config.local.json 裏面註冊對話模型和向量嵌入模型，注意這裏的 model 值要和 One API 裏配置的保持一致：</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041752" data-ratio="0.9101123595505618" src="https://oscimg.oschina.net/oscnet/f5654367-e043-4a33-af56-6fa29b073fd5.jpg" data-type="other" data-w="534" referrerpolicy="no-referrer"></span></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041754" data-ratio="0.5521885521885522" src="https://oscimg.oschina.net/oscnet/cb497e99-311a-46eb-b6fe-bbbf6a4c9531.jpg" data-type="other" data-w="594" style="width: 529px;height: 292px;" referrerpolicy="no-referrer"></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第三步，安裝 Node.js 依賴並以開發模式啓動：</span></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer"># 代碼根目錄下執行，會安裝根 package、projects 和 packages 內所有依賴</span></code><code><span class="code-snippet_outer">pnpm i</span></code><code><span class="code-snippet_outer"># 切換到應用目錄</span></code><code><span class="code-snippet_outer">cd projects/app</span></code><code><span class="code-snippet_outer"># 開發模式運行</span></code><code><span class="code-snippet_outer">pnpm dev</span></code></pre></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">第四步，訪問本地 FastGPT 地址 http://localhost:3000/，如果能順利登錄，則搭建成功。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_16"></span><h4 data-cangjie-key="673" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">驗證模型對話能力</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">創建一個應用：</span></section><p style="margin-top: 8px;line-height: 1.75em;text-align: center;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041756" data-ratio="0.7851851851851852" src="https://oscimg.oschina.net/oscnet/4a48d9ed-303b-4116-ad64-db2e3c14ab62.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">應用創建完成，進入對話界面，注意 AI 模型選擇我們在 One API 裏配置的 ChatGLM3。試着問他兩個問題，可以看到推理速度還是很快的，分別是 5.83s、7.52s：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041759" data-ratio="0.6212962962962963" src="https://oscimg.oschina.net/oscnet/e9a9fe0b-8101-498c-a692-7f17f7d0d35c.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-size: 15px;">點開單條對話響應，詳細的對話參數（消耗 token、響應時長、計費信息）清晰可見：</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="letter-spacing: 1px;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041758" data-ratio="1.3190184049079754" src="https://oscimg.oschina.net/oscnet/c1f6a537-1bcf-43e7-b191-0339eba66711.jpg" data-type="other" data-w="978" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="letter-spacing: 1px;font-size: 15px;">查看 MacBook 上的 ChatGLM3 推理資源佔用情況，佔用了 3.78GB 內存</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><span style="letter-spacing: 1px;font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503041760" data-ratio="0.6240740740740741" src="https://oscimg.oschina.net/oscnet/e9008ab1-d693-4941-bd75-cef91cbe81d1.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><p style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041757" data-ratio="0.328125" data-s="300,640" src="https://oscimg.oschina.net/oscnet/0fd3c7b5-94e1-4236-9399-af4ec7167e22.png" data-type="png" data-w="256" style="outline: 0px;letter-spacing: 0.544px;font-size: 16px;visibility: visible !important;width: 122px !important;" referrerpolicy="no-referrer"></p><p style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;font-size: 18px;color: rgb(0, 17, 255);">知識庫問答實戰</span></p><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><span id="OSC_h4_17"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">準備知識庫語料</span></strong></span></h4><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在有知識庫使用訴求的場景，我們一般都積累了比較多的私有知識數據，比如：語雀文檔、釘釘文檔、PDF、Office 文件等，視知識識圖的建設標準，需要將它們一一結構化整理。數據的梳理、清洗、結構化是一項繁雜而重要的工作，但也有比較成熟的辦法和工具，在此不再贅述。</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></p><span id="OSC_h4_18"></span><h4 data-lake-id="ca6fa186228ff7efaa653334195896c8" data-wording="true" style="margin-top: 0.5em;margin-bottom: 8px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 1.75em;"><span style="outline: 0px;visibility: visible;letter-spacing: 1px;color: rgb(0, 17, 255);"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">▐</span></strong><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="outline: 0px;visibility: visible;"><span style="color: rgb(0, 17, 255);outline: 0px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;">導入知識庫數據</span></strong></span></h4><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">FastGPT 提供了很多種原始數據導入的辦法，並且為了更好地和企業系統集成，FastGPT 支持通過 API 的方式地二次開發導入能力，支持和已有知識管理系統更好地自動化集成。常見的導入方法有：</span></section><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">導入數據方案 1 - 直接分段導入：直接分段會利用句子分詞器對文本進行一定長度拆分，可以理解為原始文檔 Chunk。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">導入數據方案 2 - QA 導入：導入時會調用大模型對分段進行學習，然後直接生成問題-答案。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">導入數據方案 3 - 手動錄入：手動錄入問題和答案。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">導入數據方案 4 - CSV 錄入：批量快速錄入問題答案對。</span></section></li><li><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">導入數據方案 5 - API 導入，</span><span style="font-size: 15px;letter-spacing: 1px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">詳見：OpenAPI 接口文檔（地址：https://doc.fastgpt.in/docs/development/openapi/#%E7%9F%A5%E8%AF%86%E5%BA%93%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE）</span><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;">﻿</span></section></li></ol><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">﻿</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">我們先簡單地錄入幾個問題和答案，然後後面快速驗證 RAG 效果。</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">新建一個知識庫，注意，索引模型一旦選擇不可更改。這裏我們選擇剛部署好的 m3e-base</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041761" data-ratio="0.769620253164557" src="https://oscimg.oschina.net/oscnet/d357e075-29d4-4b82-8032-48ddf63a806a.jpg" data-type="other" data-w="790" referrerpolicy="no-referrer"></span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">進入知識庫初始界面，已經默認有了一個「手動錄入」文件夾，我們在這裏錄入幾條測試問答</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041762" data-ratio="0.387037037037037" src="https://oscimg.oschina.net/oscnet/8812cf81-0f6c-4d49-9e3c-900ff61c2b4b.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">錄入內容分兩種類型，其中：被搜索的內容指將被向量化的部分，通常是問題，或者精煉扼要的描述，需要準確填寫</span></section><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041763" data-ratio="0.33425925925925926" src="https://oscimg.oschina.net/oscnet/6d02fcef-1034-404e-8fe3-6269dece3ada.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li style="color: rgb(0, 17, 255);"><span id="OSC_h4_19"></span><h4 data-cangjie-key="820" data-cangjie-leaf-block="true" data-type="heading-4" style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(0, 17, 255);">驗證知識庫問答效果</span></h4></li></ul><section style="margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="font-size: 15px;letter-spacing: 1px;">重新打開應用，關聯剛才創建好的知識庫（注意這裏一定要保證才會生效），問他一個簡單的問題，回答的質量看起來還可以。</span></section><blockquote style="box-sizing: inherit;margin-top: 0px;margin-bottom: 0px;margin-left: 2px;padding-top: 0px;padding-left: 11px;opacity: 0.5;border-left-width: 4px;border-left-color: rgb(217, 219, 221);color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;font-size: 14.6667px;letter-spacing: normal;text-align: start;white-space: pre-wrap;background-color: rgb(255, 255, 255);"><p style="text-align: justify;"><span style="box-sizing: inherit;font-size: 15px;">問：簡單説一下商家共振模型是個啥唄？</span></p></blockquote><blockquote style="box-sizing: inherit;margin-top: 0px;margin-bottom: 0px;margin-left: 2px;padding-top: 0px;padding-left: 11px;opacity: 0.5;border-left-width: 4px;border-left-color: rgb(217, 219, 221);color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;font-size: 14.6667px;letter-spacing: normal;text-align: start;white-space: pre-wrap;background-color: rgb(255, 255, 255);"><p style="text-align: justify;"><span style="box-sizing: inherit;font-size: 15px;">答：商家共振模型是一種商業策略和運營模式，旨在促進商家和平台之間的合作關係，同時提高用户的粘性和平台的影響力。這個模式通過激勵商家在站內和站外進行投放活動，幫助商家獲得更多的流量和銷售機會，從而促進商家的生意增長。同時，這個模式也能夠擴大平台的規模和影響力，增加商家對平台的依賴性和忠誠度。總的來説，商家共振模型是一種有效的商業策略和運營模式，對於貓超等平台來説是一個不錯的選擇。</span></p></blockquote><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;text-align: center;"><img class="rich_pages wxw-img" data-imgfileid="503041764" data-ratio="0.6083333333333333" src="https://oscimg.oschina.net/oscnet/ad7951a6-f135-449a-8cc7-0a6081e1a501.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;">點擊答案中的「1 條引用」，還可以看到答案的出處來源：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;text-align: center;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-imgfileid="503041765" data-ratio="0.6555555555555556" src="https://oscimg.oschina.net/oscnet/af4bb324-f2ed-432d-8dd3-c8c14d6ac63a.jpg" data-type="other" data-w="1080" referrerpolicy="no-referrer"></span></p><section style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><br></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;">至此，我們就完成了一個簡單的知識庫構建和應用的過程，也驗證了整套本地知識庫方案的可行性。</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;">﻿</span></p><section style="margin-right: 0cm;margin-bottom: 0px;margin-left: 0cm;outline: 0px;text-wrap: wrap;background-color: rgb(255, 255, 255);font-size: 11pt;font-family: DengXian;color: rgb(0, 0, 0);letter-spacing: normal;text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041766" data-ratio="0.328125" data-s="300,640" data-type="png" data-w="256" src="https://oscimg.oschina.net/oscnet/4454b7bc-70eb-48c3-afc5-445ce122d5f1.png" style="outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;visibility: visible !important;width: 133px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;font-size: 18px;color: rgb(0, 17, 255);">未來展望</span></section><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;"><br></span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">串通了整個知識庫應用流程，我們完成了從 0 到 1 的起步。雖然整體應用架構是按實際商用標準來搭建的，但要想使用效果也達到工業級別的標準，還有很多工作值得進一步探索，包括但不限於：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1️⃣ 大模型應用層面：</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">1、更好的文檔 Chunk、Embedding、多路加權平均搜索召回方案，提升 RAG 整體效能</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2、更好的 Prompt Engineering，充分挖掘 LLM 的潛力</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3、工作流編排、CoT、Agent，滿足實際的企業應用需求</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">2️⃣ 穩定性層面：如果達到商用級別，需要更高配置的軟硬件環境</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">3️⃣ 落地價值層面：從解決身邊的問題開始，解決真金白銀的商業問題</span></p><p style="margin-top: 8px;margin-bottom: 8px;line-height: 1.75em;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">﻿</span></p><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">希望本文能給每位計劃自己搭建大模型知識庫應用的工程師一點參考，動手跑通一個程序的樂趣是無窮的，更多的實操作經驗分享，我們在評論區交流。</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="color: rgb(64, 64, 64);font-family: &quot;zh quote&quot;, &quot;Helvetica Neue&quot;, -apple-system, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, STHeiti, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;;text-align: left;white-space: break-spaces;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: 1px;"><br></span></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;line-height: normal;"><img class="rich_pages wxw-img" data-imgfileid="503041767" data-ratio="0.328125" data-s="300,640" src="https://oscimg.oschina.net/oscnet/1e2db517-aad4-4517-add1-0856c0864c05.png" data-type="png" data-w="256" style="outline: 0px;color: rgb(51, 51, 51);font-size: 20px;font-weight: bold;letter-spacing: 0.578px;visibility: visible !important;width: 134px !important;" referrerpolicy="no-referrer"></section><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);color: rgb(100, 99, 99);font-size: 15px;text-align: center;line-height: normal;"><span style="outline: 0px;font-family: -apple-system, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;font-size: 18px;color: rgb(0, 17, 255);">團隊介紹</span></section><section style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><br></section><p style="margin-top: 8px;line-height: 1.75em;margin-bottom: 8px;"><span style="box-sizing: inherit;font-size: 15px;letter-spacing: 1px;">我們是淘天渠道分銷技術團隊，負責淘天全渠道一盤貨產品技術研發。我們通過用技術手段解決電商多段銷售中的多角色商業往來問題，構建了靈活的新零售供應鏈分銷產品平台，致力於為商家提供多元化的供給和銷售渠道、助力商家在全平台取得更高的成交額。<br style="background-clip: padding-box;caret-color: rgb(23, 26, 29);color: rgb(23, 26, 29);font-family: -apple-system, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Segoe UI&quot;, system-ui, Roboto, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;font-size: 14px;letter-spacing: normal;text-align: left;white-space: pre-wrap;text-size-adjust: auto;"><br style="background-clip: padding-box;caret-color: rgb(23, 26, 29);color: rgb(23, 26, 29);font-family: -apple-system, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Segoe UI&quot;, system-ui, Roboto, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;font-size: 14px;letter-spacing: normal;text-align: left;white-space: pre-wrap;text-size-adjust: auto;">長期招募人才，歡迎投遞簡歷：xieyi.xie@alibaba-inc.com</span></p><section style="margin-bottom: 8px;"><br></section><section data-role="outer" label="Powered by 135editor.com" style="outline: 0px;letter-spacing: 0.544px;visibility: visible;"><section style="margin-top: 8px;outline: 0px;letter-spacing: 0.544px;word-break: break-all;color: rgb(0, 0, 0);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;text-align: center;line-height: 1.75em;margin-bottom: 8px;"><span style="outline: 0px;color: rgb(0, 17, 255);"><strong style="outline: 0px;">¤</strong></span><span style="outline: 0px;"><strong style="outline: 0px;">&nbsp;拓展閲讀&nbsp;</strong></span><span style="outline: 0px;color: rgb(0, 17, 255);"><strong style="outline: 0px;">¤</strong></span></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;letter-spacing: 0.544px;word-break: break-all;color: rgb(0, 0, 0);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &quot;PingFang SC&quot;, Cambria, Cochin, Georgia, Times, &quot;Times New Roman&quot;, serif;text-align: center;line-height: 1.75em;"><br style="outline: 0px;"></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;min-height: 24px;clear: both;visibility: visible;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D2565944923443904512%23wechat_redirect" textvalue="3DXR 技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">3DXR 技術</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1533906991218294785%23wechat_redirect" textvalue="終端技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">終端技術</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1592015847500414978%23wechat_redirect" textvalue="音視頻技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">音視頻技術</a></section><section style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;visibility: visible;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1539610690070642689%23wechat_redirect" textvalue="服務端技術" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">服務端技術</a><span style="outline: 0px;letter-spacing: 0.544px;">&nbsp;|&nbsp;</span><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D2565883875634397185%23wechat_redirect" textvalue="技術質量" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">技術質量</a>&nbsp;|&nbsp; 
   <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzAxNDEwNjk5OQ%3D%3D%26action%3Dgetalbum%26album_id%3D1522425612282494977%23wechat_redirect" textvalue="數據算法" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">數據算法</a></section><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;min-height: 24px;font-family: -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-indent: 0em;text-align: center;line-height: 1.75em;visibility: visible;"><br style="outline: 0px;"></p><section class="mp_profile_iframe_wrp" style="margin-bottom: 24px;outline: 0px;"><mp-common-profile class="custom_select_card mp_profile_iframe js_wx_tap_highlight" data-pluginname="mpprofile" data-id="MzAxNDEwNjk5OQ==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/33P2FdAnju8t5nZGhAatCrc4e2iaDfAaoInribRKxc7MOqdTGygfcLqSDxhj0trCHVEh94Sjl7zuWYzwouYtJ0VQ/300?wx_fmt=png&amp;wxfrom=19" data-nickname="大淘寶技術" data-alias="AlibabaMTT" data-signature="大淘寶技術官方賬號" data-from="2" data-index="0" data-origin_num="685" data-isban="0" data-weuitheme="light" data-biz_account_status="0" data-is_biz_ban="0"></mp-common-profile><span style="outline: 0px;color: rgb(0, 0, 0);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 1px;"></span></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - 大淘寶技術（AlibabaMTT）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4662964/blog/10448445</guid>
            <link>https://my.oschina.net/u/4662964/blog/10448445</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mozilla 和 Firefox 的變遷：市場下滑背後的思考]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近 Mozilla 基金會發布的 2023 年度報告引發了廣泛關注。報告顯示，在 Mozilla CEO 薪酬大幅上漲的同時，其旗艦產品 Firefox 瀏覽器的市場份額卻持續下滑。這一現象不僅反映出 Mozilla 的財務狀況尚佳，也揭示了其業務重心可能正在發生變化，但同時也讓人不免對 Firefox 前景產生擔憂。</p><p style="text-align:center"><img height="919" src="https://oscimg.oschina.net/oscnet/up-4547075666f5a7674598dca51bafe5cc568.png" width="1920" referrerpolicy="no-referrer"></p><p style="color:#999999; text-align:center">The State of Mozilla 網站截圖</p><p>具體來看，2022 年 Mozilla CEO 的年薪高達 690 萬美元，較去年增加了 130 萬美元，達到創紀錄的新高。與此形成對比的是，Mozilla 的整體收入出現輕微下滑，由 2021 年的 6 億美元降至 2022 年的 5.93 億美元。這表明，儘管財務資產總額繼續增長，達到高達 13 億美元，但收入增長出現停滯。</p><p>更值得關注的是，在 Mozilla 財務數據保持樂觀的背景下，其核心產品 Firefox 的市場表現卻難掩頹勢。據統計，2022 年 Firefox 的全球瀏覽器市場份額已從 2021 年底的 3.79% 下降至 3.04%，跌幅達 20%。考慮到近年移動互聯網的快速發展，這一數據更顯示出 Firefox 在移動端的表現不佳。</p><p>面對 Firefox 市場份額的下滑，業內分析普遍認為其背後反映的是 Mozilla 業務重心的轉變。在財務報告中可以看出，Mozilla 的「版税收入」有所下降，而「訂閲和廣告收入」則有所增加，似乎顯示出其正在加速多元化業務，減少對 Firefox 的依賴。而今年早些時候，Mozilla CEO 就明確表示，公司將重點轉向人工智能等新興領域。</p><p>因此，有分析指出，Mozilla 可能正處在從瀏覽器向人工智能等新業務轉型的關鍵節點上。這可能也解釋了為何在 Firefox 表現疲軟的情況下，企業高管的薪酬水平還能大幅提升。很顯然，Mozilla 領導層正在根據新的發展戰略進行調整。</p><p>但業內也存在擔憂的聲音。畢竟，Firefox 曾是開源運動的一面旗幟，同時也是少數能與 Chrome 競爭的瀏覽器之一。一旦 Mozilla 繼續減少 Firefox 投入，將可能對瀏覽器市場格局和網絡開放性產生一定影響。</p><p>最近，Mozilla 基金會報告在 Hacker News 社區也引發了熱烈討論。許多社區成員對報告反映出的 Mozilla 業務戰略轉變表示不解甚至失望。他們普遍認為，Mozilla 不應過度減少對 Firefox 的投入，而應更專注於維護其核心產品。</p><p>一些用户還表示，由於 Firefox 的私密性保護功能，其實際用户量可能高於統計數據。他們希望 Mozilla 能繼續致力於提升 Firefox 的核心功能，如密碼管理、廣告屏蔽等，這對維繫用户羣至關重要。此外，一些社區用户還呼籲 Mozilla 應該採取行動鞏固 Firefox 的市場地位，確保瀏覽器市場的開放和多樣。</p><p>綜合來看，Mozilla 當前的市場表現確實反映了一家企業在變革中的兩難處境。CEO 薪酬的大幅提高似乎預示着企業正根據新的發展戰略進行市場調整，這在商業上也許可理解。但作為曾經開源界的領軍產品，Firefox 的持續下滑無疑讓人擔憂。維護核心產品與開拓新業務之間的平衡，可能是 Mozilla 當前面臨的主要難題。</p><p>無論前景如何，Firefox 在開源瀏覽器市場的地位和作用還將持續受到業內關注。而 Mozilla 也面臨着在財務增長和維繫開源社區期望之間找到最佳路徑的挑戰。我們期待 Mozilla 能繼續致力於開放和創新，同時維護其社區支持度。畢竟，只有在社區的積極參與下，開源精神才能持續發揚光大。</p><blockquote><p>注：Mozilla 的報告總是會滯後一年，所以文中提到了很多 2022 年的信息</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273248</guid>
            <link>https://www.oschina.net/news/273248</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英偉達推出特供中國銷售的 GeForce RTX 4090 D]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 GeForce RTX 4090 被列入了出口管控清單之後，英偉達推出了特供中國市場銷售的<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nvidia.cn%2Fgeforce%2Fgraphics-cards%2F40-series%2Frtx-4090-d%2F" target="_blank"> GeForce RTX 4090 D</a></u>，建議零售價 1.3 萬人民幣，1 月 20 日發售。</p><p>作為英偉達針對美國新出口限制的迴應，RTX 4090 D 能滿足美國的出口管控要求，旨在為中國遊戲玩家提供高性能的遊戲體驗。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a380dbf4c058357511bfd4b9931862b1751.png" referrerpolicy="no-referrer"></p><p>據介紹，RTX 4090 D 有 14592 個 CUDA Core 核心，頻率 2.28GHz-2.52GHz，顯存 24 GB GDDR6X。相比下原版 RTX 4090 有 16384 個 CUDA Cores 核心。此外，RTX 4090 D 基礎頻率高於 RTX 4090，但由於綜合運算性能的限制，其 CUDA 和 Tensor 核心數量低於 RTX 4090。因此新版本預計會大幅降低 AI 推理性能，遊戲性能可能變化不太顯著。</p><p>與 RTX 4090 的主要參數對比：</p><ul><li>CUDA 核心數量：從 16384 個減至 14592 個</li><li>Tensor 核心數量：從 512 個減至 456 個</li><li>RT 核心數量：從 128 個減至 114 個</li><li>基礎頻率：2280 MHz，高於 RTX 4090 的 2235 MHz</li><li>加速頻率：與 RTX 4090 相同，均為 2.52 GHz</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-b9e684e4d8fd2a515232e8171aa8f883882.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-68e049a7a0911bd428574a653036dc7f080.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273243/nvidia-rtx-4090-d</guid>
            <link>https://www.oschina.net/news/273243/nvidia-rtx-4090-d</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ODC —— 全場景數據庫開發和數據管理協同工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#1f2328">OceanBase 開發者中心（簡稱 ODC）是&nbsp;</span>Oceanbase 開源的<span style="background-color:#ffffff; color:#1f2328">全場景數據庫開發和數據管理協同工具，通過協同開發解決數據庫的變更風險管控、數據管理和數據安全問題。</span></p><p><span style="background-color:#ffffff; color:#1f2328">優點：</span></p><p style="text-align:start"><strong>隨時隨地高效 SQL 開發</strong></p><ul><li>ODC 基於現代 WEB 架構，隨時隨地，只要有瀏覽器就可以訪問您的數據庫。</li><li>ODC SQL 開發功能全面且易用，桌面開發工具有的功能 ODC 也有，甚至支持 PL 調試。</li></ul><p style="text-align:start"><strong>守護 SQL 開發過程的每一次變更</strong></p><ul><li>在 SQL 開發過程的全部場景，包括可視化對象管理、SQL 查詢、數據編輯、數據導入和導出、... ，ODC 都內置了風險控制。</li><li>ODC 提供基於項目的協同和變更審批流程，並且內置了 SQL 檢查規則、SQL 窗口規範、風險等級識別。</li></ul><p style="text-align:start"><strong>自動數據生命週期管理</strong></p><ul><li>ODC 支持數據按照保留時長清理或歸檔，5 分鐘構建你的冷熱數據分離系統。</li><li>ODC 不僅支持按照數據的時間標記處理，也支持按照分區批量處理。</li><li>還可以通過 ODC SQL 計劃任務完成計算任務，為什麼還要繼續使用你的 CRONTAB ？</li></ul><p style="text-align:start"><strong>全場景敏感數據保護</strong></p><ul><li>ODC 數據脱敏支持靜態場景也支持動態場景，結構變更、SQL 查詢、結果集導出、數據導出，全部開發場景都會脱敏。</li><li>安全管理員配置敏感數據規則和脱敏算法，DBA 和，開發，都無法接觸敏感數據。</li></ul><p style="text-align:start"><strong>無需改變已有系統就可以集成 ODC 到當前工作流程</strong></p><ul><li>無需改變你的系統就可以把 ODC 集成到你當前的數據庫開發協同工作流程中.</li><li>SSO、審批集成、SQL 審核集成、堡壘機集成、審計集成，企業管控集成需要的能力全都有。</li></ul><h4 style="text-align:start"><strong>功能特性</strong></h4><p style="color:#1f2328; text-align:start">ODC 產品功能包括 SQL 開發和管控協同 2 個方面，核心功能列舉如下。</p><p style="text-align:start"><strong>SQL 開發</strong></p><ul><li>多數據源：支持 OceanBase MySQL 模式/Oracle 模式、ODP Sharing、MySQL 等數據庫（不斷增加中）。</li><li>數據庫對象：表、視圖、序列、同義詞、觸發器、存儲過程、函數、程序包、類型，等對象的可視化管理。</li><li>SQL 執行：SQL 編輯和執行、命令行窗口、腳本、代碼片段。</li><li>數據查看與編輯：數據查看、數據編輯、結果集 Excel 互操作。</li><li>監控診斷：執行計劃、執行剖析、數據庫全鏈路 TRACE。</li><li>數據生成：測試數據生成，場景化數據生成。</li><li>導入和導出：結構導入、結構導出、數據導入、數據導出、整庫導入、整庫導出。</li><li>PL 生命週期：PL 對象的執行、編譯和調試。</li><li>數據庫運維：回話管理、變量管理、回收站管理、權限管理（規劃中）。</li></ul><p style="text-align:start"><strong>管控協同</strong></p><ul><li>權限管理：用户管理、基於 RBAC 模型的自定義角色。</li><li>團隊協同：基於項目的管理員、DBA、開發多角色協同、庫級別訪問權限管理。</li><li>變更管控：自定義審批流程、基於語法規則的 SQL 檢查。</li><li>穩定變更：無鎖結構變更、無鎖數據變更（規劃中）。</li><li>數據生命週期：數據清理、數據歸檔、自動分區、SQL 定時任務。</li><li>數據安全：敏感列管理、數據導出脱敏、數據查詢脱敏、敏感列權限。</li><li>合規審計：操作審計、SQL 審計、審計集成。</li><li>協同效率：批量導入配置、自動授權規則、通知中心。</li><li>系統集成：OAuth2、OIDC 賬號集成、堡壘機集成、審批集成、SQL 審核集成。</li><li>體驗學習：實驗資源、教程和課程、代碼庫（規劃中）。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/odc</guid>
            <link>https://www.oschina.net/p/odc</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 基於 Kotlin 開發的播放器軟件 MXVideo]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-mxvideo" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#mxvideo"></a>MXVideo</h1><h4><a id="user-content-介紹" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#%E4%BB%8B%E7%BB%8D"></a>介紹</h4><p>基於 Kotlin 開發的播放器，默認支持 MediaPlayer 播放器，可擴展 IJK 播放器、EXO 播放器、阿里雲播放器、以及任何使用 TextureView 的播放器, 開箱即用，歡迎提 issue 和 pull request</p><blockquote><p>簡書相關介紹（待完善）：<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.jianshu.com%2Fnb%2F50294642">https://www.jianshu.com/nb/50294642</a></p></blockquote><p>最新版本：<a href="https://gitee.com/link?target=https%3A%2F%2Fjitpack.io%2F%23zhangmengxiong%2FMXVideo"><img src="https://jitpack.io/v/zhangmengxiong/MXVideo.svg" alt="" referrerpolicy="no-referrer"></a></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="n">implementation</span><span class="s1">'com.github.zhangmengxiong:MXVideo:1.9.0'</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><img src="https://gitee.com/zhangmengxiong/MXVideo/raw/master/imgs/1.png" alt="Normal" referrerpolicy="no-referrer"><img src="https://gitee.com/zhangmengxiong/MXVideo/raw/master/imgs/2.png" alt="Land Screen" referrerpolicy="no-referrer"><img src="https://gitee.com/zhangmengxiong/MXVideo/raw/master/imgs/3.png" alt="Touch Seek" referrerpolicy="no-referrer"><img src="https://gitee.com/zhangmengxiong/MXVideo/raw/master/imgs/4.png" alt="Pause" referrerpolicy="no-referrer"><img src="https://gitee.com/zhangmengxiong/MXVideo/raw/master/imgs/5.png" alt="Rotation" referrerpolicy="no-referrer"><img src="https://gitee.com/zhangmengxiong/MXVideo/raw/master/imgs/6.png" alt="Light Seek" referrerpolicy="no-referrer"></p><h4><a id="user-content-功能特性" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7"></a>功能特性</h4><ul><li>任意播放器內核（包含開源 IJK、谷歌 Exo、阿里雲等等）</li><li>單例播放，只能同時播放一個節目</li><li>0 代碼集成全屏功能</li><li>可以調節音量、屏幕亮度</li><li>可以註冊播放狀態監聽回調</li><li>播放器高度可以根據視頻高度自動調節</li><li>播放器支持設置寬高比，設置寬高比後，高度固定。</li><li>自動保存與恢復播放進度（可關閉）</li><li>支持循環播放、全屏時豎屏模式、可關閉快進快退功能、可關閉全屏功能、可關閉非 WiFi 環境下流量提醒</li><li>支持播放時獲取實時截屏 Bitmap</li></ul><h5><a id="user-content-1 通過-dependence-引入 mxvideo" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#1%E9%80%9A%E8%BF%87-dependence-%E5%BC%95%E5%85%A5mxvideo"></a>1、通過 dependence 引入 MXVideo</h5><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="n">dependencies</span><span class="o">{</span></span><span id="LC2" class="line"><span class="n">implementation</span><span class="s1">'com.github.zhangmengxiong:MXVideo:x.x.x'</span></span><span id="LC3" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-2 頁面集成" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#2%E9%A1%B5%E9%9D%A2%E9%9B%86%E6%88%90"></a>2、頁面集成</h5><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;com.mx.video.MXVideoStd</span></span><span id="LC2" class="line"><span class="na">android:id=</span><span class="s">"@+id/mxVideoStd"</span></span><span id="LC3" class="line"><span class="na">android:layout_width=</span><span class="s">"match_parent"</span></span><span id="LC4" class="line"><span class="na">android:layout_height=</span><span class="s">"wrap_content"</span><span class="nt">/&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// Activity 或者 Fragment 中生命週期變更，處理進入後台/前台時的暫停/續播功能</span></span><span id="LC2" class="line"><span class="k">override</span><span class="k">fun</span><span class="nf">onStart</span><span class="p">()</span><span class="p">{</span></span><span id="LC3" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">onStart</span><span class="p">()</span></span><span id="LC4" class="line"><span class="k">super</span><span class="p">.</span><span class="nf">onStart</span><span class="p">()</span></span><span id="LC5" class="line"><span class="p">}</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="k">override</span><span class="k">fun</span><span class="nf">onStop</span><span class="p">()</span><span class="p">{</span></span><span id="LC8" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">onStop</span><span class="p">()</span></span><span id="LC9" class="line"><span class="k">super</span><span class="p">.</span><span class="nf">onStop</span><span class="p">()</span></span><span id="LC10" class="line"><span class="p">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-3 開始播放" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#3%E5%BC%80%E5%A7%8B%E6%92%AD%E6%94%BE"></a>3、開始播放</h5><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 設置播放佔位圖</span></span><span id="LC2" class="line"><span class="nc">Glide</span><span class="p">.</span><span class="nf">with</span><span class="p">(</span><span class="k">this</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="s">"http://www.xxx.com/xxx.png"</span><span class="p">).</span><span class="nf">into</span><span class="p">(</span><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getPosterImageView</span><span class="p">())</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c1">// 默認從上一次進度播放</span></span><span id="LC5" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setSource</span><span class="p">(</span><span class="nc">MXPlaySource</span><span class="p">(</span><span class="nc">Uri</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="s">"https://aaa.bbb.com/xxx.mp4"</span><span class="p">),</span><span class="s">"標題 1"</span><span class="p">))</span></span><span id="LC6" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">startPlay</span><span class="p">()</span></span><span id="LC7" class="line"></span><span id="LC8" class="line"><span class="c1">// 從頭開始播放</span></span><span id="LC9" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setSource</span><span class="p">(</span><span class="nc">MXPlaySource</span><span class="p">(</span><span class="nc">Uri</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="s">"https://aaa.bbb.com/xxx.mp4"</span><span class="p">),</span><span class="s">"標題 1"</span><span class="p">),</span><span class="n">seekTo</span><span class="p">=</span><span class="mi">0</span><span class="p">)</span></span><span id="LC10" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">startPlay</span><span class="p">()</span></span><span id="LC11" class="line"></span><span id="LC12" class="line"><span class="c1">// 從第 10 秒開始播放</span></span><span id="LC13" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setSource</span><span class="p">(</span><span class="nc">MXPlaySource</span><span class="p">(</span><span class="nc">Uri</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="s">"https://aaa.bbb.com/xxx.mp4"</span><span class="p">),</span><span class="s">"標題 1"</span><span class="p">),</span><span class="n">seekTo</span><span class="p">=</span><span class="mi">10</span><span class="p">)</span></span><span id="LC14" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">startPlay</span><span class="p">()</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><blockquote><p>MXPlaySource 可選參數説明：</p></blockquote><table><thead><tr><th align="left">參數</th><th align="center">説明</th><th align="right">默認值</th></tr></thead><tbody><tr><td align="left">title</td><td align="center">標題</td><td align="right">""</td></tr><tr><td align="left">headerMap</td><td align="center">網絡請求頭部</td><td align="right">null</td></tr><tr><td align="left">isLooping</td><td align="center">是否循環播放</td><td align="right">false</td></tr><tr><td align="left">enableSaveProgress</td><td align="center">是否存儲、讀取播放進度</td><td align="right">true</td></tr><tr><td align="left">isLiveSource</td><td align="center">是否直播源，當時直播時，不顯示進度，無法快進快退暫停</td><td align="right">false</td></tr></tbody></table><h5><a id="user-content-4 監聽播放進度" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#4%E7%9B%91%E5%90%AC%E6%92%AD%E6%94%BE%E8%BF%9B%E5%BA%A6"></a>4、監聽播放進度</h5><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">addOnVideoListener</span><span class="p">(</span><span class="kd">object</span><span class="err">: </span><span class="nc">MXVideoListener</span><span class="p">()</span><span class="p">{</span></span><span id="LC2" class="line"><span class="c1">// 播放狀態變更</span></span><span id="LC3" class="line"><span class="k">override</span><span class="k">fun</span><span class="nf">onStateChange</span><span class="p">(</span><span class="n">state</span><span class="p">:</span><span class="nc">MXState</span><span class="p">)</span><span class="p">{</span></span><span id="LC4" class="line"><span class="p">}</span></span><span id="LC5" class="line"></span><span id="LC6" class="line"><span class="c1">// 播放時間變更</span></span><span id="LC7" class="line"><span class="k">override</span><span class="k">fun</span><span class="nf">onPlayTicket</span><span class="p">(</span><span class="n">position</span><span class="p">:</span><span class="nc">Int</span><span class="p">,</span><span class="n">duration</span><span class="p">:</span><span class="nc">Int</span><span class="p">)</span><span class="p">{</span></span><span id="LC8" class="line"><span class="p">}</span></span><span id="LC9" class="line"><span class="p">})</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h5><a id="user-content-5 全屏返回--釋放資源" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#5%E5%85%A8%E5%B1%8F%E8%BF%94%E5%9B%9E--%E9%87%8A%E6%94%BE%E8%B5%84%E6%BA%90"></a>5、全屏返回 + 釋放資源</h5><blockquote><p>這裏 MXVideo 默認持有當前播放的 MXVideoStd，可以使用靜態方法操作退出全屏、釋放資源等功能。</p><p>也可以直接使用 viewId：mxVideoStd.isFullScreen()，mxVideoStd.isFullScreen()，mxVideoStd.release() 等方法。</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">override</span><span class="k">fun</span><span class="nf">onBackPressed</span><span class="p">()</span><span class="p">{</span></span><span id="LC2" class="line"><span class="k">if</span><span class="p">(</span><span class="nc">MXVideo</span><span class="p">.</span><span class="nf">isFullScreen</span><span class="p">())</span><span class="p">{</span></span><span id="LC3" class="line"><span class="nc">MXVideo</span><span class="p">.</span><span class="nf">gotoNormalScreen</span><span class="p">()</span></span><span id="LC4" class="line"><span class="k">return</span></span><span id="LC5" class="line"><span class="p">}</span></span><span id="LC6" class="line"><span class="k">super</span><span class="p">.</span><span class="nf">onBackPressed</span><span class="p">()</span></span><span id="LC7" class="line"><span class="p">}</span></span><span id="LC8" class="line"></span><span id="LC9" class="line"><span class="k">override</span><span class="k">fun</span><span class="nf">onDestroy</span><span class="p">()</span><span class="p">{</span></span><span id="LC10" class="line"><span class="nc">MXVideo</span><span class="p">.</span><span class="nf">releaseAll</span><span class="p">()</span></span><span id="LC11" class="line"><span class="k">super</span><span class="p">.</span><span class="nf">onDestroy</span><span class="p">()</span></span><span id="LC12" class="line"><span class="p">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-功能相關" class="anchor" href="https://gitee.com/zhangmengxiong/MXVideo#%E5%8A%9F%E8%83%BD%E7%9B%B8%E5%85%B3"></a>功能相關</h3><ul><li>切換播放器內核</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 默認 MediaPlayer 播放器，庫默認內置</span></span><span id="LC2" class="line"><span class="n">com</span><span class="p">.</span><span class="n">mx</span><span class="p">.</span><span class="n">video</span><span class="p">.</span><span class="n">player</span><span class="p">.</span><span class="nc">MXSystemPlayer</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c1">// 谷歌的 Exo 播放器</span></span><span id="LC5" class="line"><span class="n">com</span><span class="p">.</span><span class="n">mx</span><span class="p">.</span><span class="n">mxvideo_demo</span><span class="p">.</span><span class="n">player</span><span class="p">.</span><span class="n">exo</span><span class="p">.</span><span class="nc">MXExoPlayer</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="c1">// IJK 播放器</span></span><span id="LC8" class="line"><span class="n">com</span><span class="p">.</span><span class="n">mx</span><span class="p">.</span><span class="n">mxvideo_demo</span><span class="p">.</span><span class="n">player</span><span class="p">.</span><span class="nc">MXIJKPlayer</span></span><span id="LC9" class="line"></span><span id="LC10" class="line"><span class="c1">// 阿里雲播放器，僅支持 」armeabi-v7a「、」arm64-v8a「 兩種 CPU</span></span><span id="LC11" class="line"><span class="n">com</span><span class="p">.</span><span class="n">mx</span><span class="p">.</span><span class="n">mxvideo_demo</span><span class="p">.</span><span class="n">player</span><span class="p">.</span><span class="nc">MXAliPlayer</span></span><span id="LC12" class="line"></span><span id="LC13" class="line"><span class="c1">// 設置播放源是可以設置內核，默認 = MXSystemPlayer</span></span><span id="LC14" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setPlayer</span><span class="p">(</span><span class="nc">MXSystemPlayer</span><span class="o">::</span><span class="k">class</span><span class="p">.</span><span class="n">java</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置播放地址，標題，跳轉等信息</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setSource</span><span class="p">(</span><span class="nc">MXPlaySource</span><span class="p">(</span><span class="nc">Uri</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="s">"xxx"</span><span class="p">),</span><span class="n">title</span><span class="p">=</span><span class="s">"xxx"</span><span class="p">),</span><span class="n">seekTo</span><span class="p">=</span><span class="mi">0</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>視頻渲染旋轉角度</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 默認旋轉角度 = MXOrientation.DEGREE_0</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setTextureOrientation</span><span class="p">(</span><span class="nc">MXOrientation</span><span class="p">.</span><span class="nc">DEGREE_90</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置當前視頻靜音,不會影響系統音量</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 默認=false</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setAudioMute</span><span class="p">(</span><span class="k">true</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置播放器音量百分比，實際音量 = (volume * 系統當前音量)</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 默認=1f，當設置=0f 時，視頻則靜音</span></span><span id="LC2" class="line"><span class="c1">// 取值範圍：0f -&gt; 1f</span></span><span id="LC3" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setVolumePercent</span><span class="p">(</span><span class="mf">0.5f</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>視頻填充規則</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 強制填充寬高 MXScale.FILL_PARENT</span></span><span id="LC2" class="line"><span class="c1">// 根據視頻大小，自適應寬高 MXScale.CENTER_CROP</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c1">// 默認填充規則 = MXScale.CENTER_CROP</span></span><span id="LC5" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setScaleType</span><span class="p">(</span><span class="nc">MXScale</span><span class="p">.</span><span class="nc">CENTER_CROP</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>MXVideoStd 控件寬高約束</li></ul><blockquote><p>在頁面 xml 中添加，layout_width 一般設置 match_parent，高度 wrap_content</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;com.mx.video.MXVideoStd</span></span><span id="LC2" class="line"><span class="na">android:id=</span><span class="s">"@+id/mxVideoStd"</span></span><span id="LC3" class="line"><span class="na">android:layout_width=</span><span class="s">"match_parent"</span></span><span id="LC4" class="line"><span class="na">android:layout_height=</span><span class="s">"wrap_content"</span><span class="nt">/&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><blockquote><p>可以設置任意寬高比，如果設置寬高比，則控件高度需要設置 android:layout_height="wrap_content"，否則不生效。</p><p>當取消約束、MXVideo 高度自適應、填充規則=MXScale.CENTER_CROP 時，控件高度會自動根據視頻寬高自動填充高度</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// MXVideoStd 控件設置寬高比= 16：9</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setDimensionRatio</span><span class="p">(</span><span class="mf">16.0</span><span class="p">/</span><span class="mf">9.0</span><span class="p">)</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c1">// MXVideoStd 控件設置寬高比= 4：3</span></span><span id="LC5" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setDimensionRatio</span><span class="p">(</span><span class="mf">4.0</span><span class="p">/</span><span class="mf">3.0</span><span class="p">)</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="c1">// 取消約束</span></span><span id="LC8" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">setDimensionRatio</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>進度跳轉</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 進度單位：秒，可以在啓動播放後、錯誤或播完之前調用</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">seekTo</span><span class="p">(</span><span class="mi">55</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置不能快進快退</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">canSeekByUser</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置不能全屏</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">canFullScreen</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置緩衝時顯示網速信息</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">canShowNetSpeed</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>沒有設置 source 時不顯示播放按鈕</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=false</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">hidePlayBtnWhenNoSource</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置全屏按鈕是否顯示</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="c1">// 全屏按鈕只有在  canFullScreen=true &amp;&amp; showFullScreenButton=true 時顯示</span></span><span id="LC3" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">showFullScreenButton</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置不顯示控件右上角時間</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">canShowSystemTime</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置不顯示底部 1dp 高度的進度條</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">canShowBottomSeekBar</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置不顯示控件右上角電量圖</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">canShowBatteryImg</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置關閉 WiFi 環境播放前提醒</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">showTipIfNotWifi</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置打開 TextureView 的水平鏡像模式</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=false</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">mirrorMode</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">true</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置播放完成後自動退出全屏</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">gotoNormalScreenWhenComplete</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置播放錯誤後自動退出全屏</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">gotoNormalScreenWhenError</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置播放時用户不可以暫停</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=true</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">canPauseByUser</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">false</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置播放時如果手機橫屏則自動進入全屏播放</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=false</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">autoFullScreenBySensor</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">true</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置全屏播放時屏幕方向自動跟隨重力方向</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=MXSensorMode.SENSOR_FIT_VIDEO</span></span><span id="LC2" class="line"><span class="c1">// MXSensorMode.SENSOR_AUTO = 跟隨重力方向</span></span><span id="LC3" class="line"><span class="c1">// MXSensorMode.SENSOR_FIT_VIDEO = 跟隨視頻寬高自動旋轉 0 或 180 度</span></span><span id="LC4" class="line"><span class="c1">// MXSensorMode.SENSOR_NO = 根據視頻寬高比固定橫屏/豎屏，橫屏 = 視頻寬&gt;=高   --   豎屏 = 視頻寬&lt;高</span></span><span id="LC5" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">fullScreenSensorMode</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="nc">MXSensorMode</span><span class="p">.</span><span class="nc">SENSOR_AUTO</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置直播流播放錯誤時自動重試</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放前設置，默認=false</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">replayLiveSourceWhenError</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">true</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>設置播放器內控件動畫效果</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 將動畫時長設置為 &lt;=0 時，禁止動畫效果</span></span><span id="LC2" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">animatorDuration</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="mi">0L</span><span class="p">)</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c1">// 默認時長 200 毫秒</span></span><span id="LC5" class="line"><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getConfig</span><span class="p">().</span><span class="n">animatorDuration</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="mi">200L</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>播放時截屏</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">if</span><span class="p">(</span><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">isPlaying</span><span class="p">())</span><span class="p">{</span></span><span id="LC2" class="line"><span class="kd">val</span><span class="py">bitmap</span><span class="p">:</span><span class="nc">Bitmap</span><span class="p">?</span><span class="p">=</span><span class="n">mxVideoStd</span><span class="p">.</span><span class="nf">getTextureView</span><span class="p">()</span><span class="o">?.</span><span class="n">bitmap</span></span><span id="LC3" class="line"><span class="n">screenCapImg</span><span class="p">.</span><span class="nf">setImageBitmap</span><span class="p">(</span><span class="n">bitmap</span><span class="p">)</span></span><span id="LC4" class="line"><span class="p">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>非全屏時，設置支持滑動快進快退/音量調節/亮度調節功能</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 默認非全屏時不支持滑動相關操作</span></span><span id="LC2" class="line"><span class="n">config</span><span class="p">.</span><span class="n">enableTouchWhenNormalScreen</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="k">true</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>播放倍數設置</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 播放倍數設置，默認 1.0 倍數播放</span></span><span id="LC2" class="line"><span class="n">config</span><span class="p">.</span><span class="n">playSpeed</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/zhangmengxiong/MXVideo</guid>
            <link>https://gitee.com/zhangmengxiong/MXVideo</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 探索 Seata 項目開源開發之旅]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><em>作者：尹祥琨，清華大學，Seata 開源之夏學生參與者</em></p><p>Seata 是一款開源的分佈式事務解決方案，致力於在微服務架構下提供高性能和簡單易用的分佈式事務服務。在今年的開源之夏活動中，我加入了 Apache Seata (Incubator) 社區，完成了開源之夏的課題，並從此一直積極參與社區。我有幸在雲棲大會-開發者秀場上分享了我的開發者經驗。在本文中，我將與大家分享我在 Seata 社區中的開發者之旅，以及在這個旅程中積累的經驗和見解。希望通過我的故事，能夠激勵更多人踏上這充滿挑戰和激勵的開源之路，為開源社區的繁榮做出自己的貢獻。</p><p><img src="https://oscimg.oschina.net/oscnet/up-aebda794f193baa6a525759178f78ec45b8.png" alt="" referrerpolicy="no-referrer"></p><h2>相關背景</h2><p>在正式介紹我的經歷之前，我想先提供一些相關的背景信息，以解釋為什麼我要參與開源以及如何參與開源。關於參與開源的原因，我相信每個人都有不同的動機。以下是我認為一些主要的原因：</p><ul><li><strong>學習：</strong> 參與開源使我們有機會為不同組織開發的開源項目做出貢獻，與行業專家互動，提供了學習的機會。</li><li><strong>技能提升：</strong> 以我為例，我通常使用 Java 和 Python 進行後端開發。但在參與 Seata 項目時，我有機會學習 Go 語言，拓寬了我的後端技術棧。此外作為學生，我很難接觸到生產級框架或應用，而開源社區為我提供了這個機會。</li><li><strong>興趣：</strong> 我身邊的朋友都是熱衷於開源的，他們享受編程，對開源充滿熱情。</li><li><strong>求職：</strong> 參與開源可以豐富我們的作品集，為簡歷增加分量。</li><li><strong>工作需求：</strong> 有時參與開源是為瞭解決工作中遇到的問題或滿足工作需求。</li></ul><p>這些都是參與開源的原因，對我來説，學習、技能提升和興趣是我參與開源的主要動機。無論你是在校學生還是在職人員，如果你有參與開源的意願，不要猶豫，任何人都可以為開源項目做出貢獻。年齡、性別、工作和所在地都不重要，關鍵是你的熱情和對開源項目的好奇心。</p><p><strong>我參與開源的契機是參加了中科院軟件所舉辦的開源之夏活動。</strong></p><p>開源之夏是一個面向高校開發者的開源活動，社區發佈開源項目，學生開發者在導師的指導下完成項目的開發，結項成果貢獻給社區，合入社區倉庫，獲得項目獎金和證書。開源之夏是踏入開源社區的一個絕佳契機，也是我第一次比較正式地接觸開源項目，而這個經歷為我打開了一扇全新的大門。自此我深刻地認識到參與開源項目的建設，分享自己的技術成果，讓更多的開發者能夠使用你所貢獻的東西，是一件極富樂趣和意義的事情。</p><p>下面我分享的這張圖片是開源之夏官方公開的數據，從 2020 年開始參與的社區數量還有學生數量都在逐年增加，活動也是越辦越好。可以看到今年的參與的社區項目共有 133 個，每個社區又提供了若干個課題，而每位學生只能選擇一個課題。想要在這麼多個社區中找到想要參與的社區和適合自己的課題是一個相對複雜的任務。</p><p><img src="https://oscimg.oschina.net/oscnet/up-2cb63ff2fddcde028ba35a97e0ee5b21e2f.png" alt="" referrerpolicy="no-referrer"></p><p><strong>綜合考慮社區的活躍程度、技術棧契合度、新人引導情況等，最終我選擇加入 Seata 社區。</strong></p><p>Seata 是一款開源的分佈式事務框架，提供了完整的分佈式事務解決方案，包括 AT、TCC、Saga 和 XA 事務模式，可支持多種編程語言和數據存儲方案。從 19 年開源起到今年已經走過了&nbsp;<strong>5</strong>&nbsp;個年頭，社區中有超過 <strong>300</strong> 多位貢獻者，項目收穫了&nbsp;<strong>24k+</strong> &nbsp;星標，是一個非常成熟的社區。同時 Seata 兼容&nbsp;<strong>10</strong>&nbsp;餘種主流 RPC 框架和 RDBMS，與&nbsp;<strong>20</strong>&nbsp;多個社區存在集成和被集成的關係，被<strong>幾千</strong>家客户應用到業務系統中，可以説是分佈式事務解決方案的事實標準。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1322af951d1654325b68bb62db27ac119fe.png" alt="" referrerpolicy="no-referrer"></p><p>2023 年 10 月 29 日，Seata 正式捐贈給了 Apache 軟件基金會，成為孵化項目。經過孵化之後，Seata 將有望成為首個 Apache 軟件基金會的分佈式事務框架頂級項目。這次捐贈也將推動 Seata 更廣泛地發展，對生態系統的建設產生深遠的影響，從而使更多的開發者受益。這個重要的里程碑也為 Seata 帶來更廣闊的發展空間。</p><h2>開發之旅</h2><p><strong>介紹完了一些基本情況，後文中我將分享我在 Seata 社區的開發之旅。</strong></p><p>在正式開始開發之前，我進行了許多準備工作。因為 Seata 已經經歷了五年的發展，積累了數十萬行代碼，因此直接參與開發需要一定的上手成本。我分享了一些準備經驗，希望能夠為大家提供一些啓發。</p><h3>1. 文檔和博客是第一手材料</h3><p>文檔和博客這類的文本材料可以幫助社區新人迅速瞭解項目背景和代碼結構。</p><p>首先，官方文檔是最主要的參考資料，從這裏可以瞭解到一切官方認為你需要了解的東西。</p><p><img src="https://oscimg.oschina.net/oscnet/up-00cfd6de008e0436da49cf6e2ced547e0ad.png" alt="" referrerpolicy="no-referrer"></p><p>博客，僅次於官方文檔的材料，一般是開發者或者是深度用户編寫的，和文檔不同的點在於博客可能會更深入到某個專項上去介紹，比如一些項目的理論模型、項目結構、某個模塊的源碼分析等等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3fa38a82a0fb5a68516e1f8917a6bcf914e.png" alt="" referrerpolicy="no-referrer"></p><p>公眾號，和博客類似，一般是偏技術性的文章，公眾號還有個優點是可以訂閲推送，利用碎片時間閲讀一些技術。</p><p><img src="https://oscimg.oschina.net/oscnet/up-66dba9d75a4371e6cec17b1f6bcde799b7b.png" alt="" referrerpolicy="no-referrer"></p><p>此外，開源社區的一些在線分享或線下 Meetup 公開的幻燈片也是非常有意義的文本資料。</p><p><img src="https://oscimg.oschina.net/oscnet/up-36ffca7b98bc0d65f0567e08e6e57c3913b.png" alt="" referrerpolicy="no-referrer"></p><p>除了官方資料之外，還有許多第三方資料可供學習，比如可以通過用户分享的 use cases 瞭解項目的具體實施和實踐；通過第三方社區的集成文檔瞭解項目的生態；還有就是通過第三方的視頻教程來學習。但在所有這些資料中，我認為官方文檔和博客是最有幫助的。</p><h3>2. 熟悉使用框架</h3><p>當然剛才説的這些文本資料肯定不需要面面俱到的看完，紙上得來終覺淺，看到感覺差不多明白了就可以去實踐了。可以按照官方文檔的"Get Started"章節逐步瞭解項目的基本流程。另一種方法是查找官方提供的示例或演示，構建並運行它們，理解代碼和配置的含義，並通過使用項目瞭解項目的需求、目標以及現有功能和架構。</p><p>例如，Seata 有一個名為 seata-samples 的倉庫，其中包含 20 多種用例，比如 Seata 和 Dubbo 集成，和 SCA, Nacos 集成的案例，基本可以覆蓋到支持的所有場景。</p><h3>3. 粗略閲讀源代碼把握主要邏輯</h3><p>在準備階段，粗略地閲讀源代碼以把握項目的主要邏輯也很重要。瞭解如何高效地把握項目的主要內容是一個需要長期積累的技能。首先，通過前述的準備步驟，瞭解項目的概念、交互和流程模型是很有幫助的。</p><p>以 Seata 為例，通過官方文檔和實際操作，可以瞭解 Seata 事務領域的三個角色：TC（Transaction Coordinator）、TM（Transaction Manager）和 RM（Resource Manager）。TC 作為獨立部署的 Server 用於維護全局和分支事務的狀態，是 Seata 實現高可用的關鍵；TM 用於與 TC 交互，定義全局事務的開始、提交或回滾；RM 用於管理分支事務處理的資源，與 TC 交互以註冊分支事務和報告分支事務的狀態，並驅動分支事務提交或回滾。粗略地瞭解這些角色之間的交互後，可以更輕鬆地把握項目的主要邏輯。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5c6f741753e54c13960a277e28738b6a8b6.png" alt="" referrerpolicy="no-referrer"></p><p>腦海裏刻下了這些模型的印象，對源碼的主幹提取就相對得心應手了一些。比如 Seata TC 事務協調者，作為 Server 端，是一個獨立於業務部署的單獨應用。那為了分析源碼，就可以直接在本地把 server 起起來，通過啓動類開始追蹤。可以分析到一些初始化的邏輯比如服務註冊、全局鎖的初始化等等。還有可以通過 RPC 的調用來追蹤到交互邏輯的代碼，比如 TC 是如何對全局事務和分支事務進行持久化，如何驅動全局事務提交或者回滾的。</p><p>然而內嵌客户端的框架代碼，沒有一個啓動類入口可以入手分析。那其實可以從一個 sample 入手，找到其對框架代碼的引用從而進行閲讀。比如 Seata 一個很重要的註解是 GlobalTransaction，用於標識一個全局事務。想要知道 TM 是如何對這個註解分析的，那我們通過 IDE 的搜索功能，找到 GlobalTransaction 的攔截器即可分析其中的邏輯。</p><p>還有一個小 tips 分享給大家，往往來説單測注重於單一模塊的職能，可以通過閲讀單測可以瞭解一個模塊的輸入輸出、邏輯邊界，也可以順着單測的調用鏈去閲讀代碼，也是理解源碼一個很重要的手段。</p><p><strong>萬事俱備只欠東風，做完充足的準備，下一步就是區積極參與到社區之中。</strong></p><p>參與的方式也有很多種，最常見的參與方式是查看項目的 Issues 列表，社區通常會為新貢獻者標記一些帶有特殊標籤的 Issue，如「good-first-issue」、「contributions-welcome」和「help-wanted」等。可以通過這些標籤篩選感興趣的任務。</p><p><img src="https://oscimg.oschina.net/oscnet/up-77fc64ac1ba403624668e51380910130c78.png" alt="" referrerpolicy="no-referrer"></p><p>除了 Issues，GitHub 還提供了討論的功能，可以參與一些公開的討論並獲取新的想法。</p><p><img src="https://oscimg.oschina.net/oscnet/up-658832d16529452411c236cdae75a8df324.png" alt="" referrerpolicy="no-referrer"></p><p>此外，社區通常會定期舉行會議，比如週會或雙週會，可以通過參加這些會議來瞭解社區的最新進展，提出問題以及與其他社區成員交流。</p><h2>總結與心得</h2><p>我加入 Seata 社區最初是通過開源之夏活動。我完成了我的課題，為 Seata Saga 實現了一些新的功能，也做了一系列的優化。但我不止於此，因為在 Seata 的開源經歷中我獲得了學生生涯中最寶貴的一次開發者體驗，在之後的時間我也持續通過上述參與方式持續活躍在社區中。這主要得益於以下幾個方面：</p><ul><li><p><strong>溝通與社交</strong></p><p>導師制度為我提供了重要的支持。在開發過程中，我與我的導師亦夏之間的密切合作對我適應社區文化和工作流程起到了關鍵作用。他不僅幫助我適應了社區，還為我提供了程序設計的思路，也與我分享了一些在工作中的經驗和見解，這些都對我的發展非常有幫助。此外，Seata 社區創始人清銘也提供了很多幫助，包括建立了與其他同學的聯繫，幫助我進行 Code Review，也為我提供了許多機會。</p></li><li><p><strong>正反饋</strong></p><p>在 Seata 的開發過程中，我經歷了一個良性的循環。許多細節為我提供了許多正反饋，例如我的貢獻能被用户廣泛使用和受益，比如開發得到了社區的認可。這些正反饋加強了我繼續在 Seata 社區貢獻的意願。</p></li><li><p><strong>技能提升</strong>再就是參與 Seata 開發，對我能力的提升也是巨大的。在這裏，我能學習到生產級別的代碼，包括性能優化，接口設計，邊界判斷的技巧。可以直接參與一個開源項目的運作，包括項目計劃，安排，溝通等。當然還瞭解一個分佈式事務框架是如何設計並實現的。</p></li></ul><p>除了這些寶貴的開發者體驗，我也從這次經歷中體悟到了一些關於參與開源的個人心得，為激勵其他有興趣參與開源社區的同學，我做了簡單的總結：</p><ul><li><p><strong>瞭解和學習社區文化和價值觀</strong></p><p>每個開源社區都有不同的文化和價值觀。瞭解社區的文化和價值觀對於成功參與社區至關重要。觀察和了解社區其他成員的日常開發和交流方式是學習社區文化的好方法。在社區中要尊重他人的意見和包容不同的觀點。</p></li><li><p><strong>敢於邁出第一步</strong></p><p>不要害怕面對困難，邁出第一步是參與開源社區的關鍵。可以通過領取標有"good-first-issue"等標籤的 Issue，編寫文檔、單元測試等方式來開始。重要的是要克服畏難情緒，積極嘗試並學習。</p></li><li><p><strong>對自己的工作要充滿信心</strong></p><p>不要懷疑自己的能力。每個人都是從零開始的，沒有人天生就是專家。參與開源社區是一個學習和成長的過程，需要不斷的實踐和積累經驗。</p></li><li><p><strong>積極參與討論，持續學習不同技術</strong></p><p>不要害怕提出問題，無論是關於項目的具體技術還是開發過程中的挑戰。同時也不要侷限於一個領域。嘗試學習和掌握不同編程語言、框架和工具，這可以拓寬技術視野，為項目提供有價值的洞見。</p></li></ul><hr><p>通過我的開源之旅，我積累了寶貴的經驗和技能，這些不僅幫助我成長為一個更有價值的開發者，也讓我深刻地瞭解了開源社區的力量。然而，我不僅僅是個別的參與者，我代表着 Seata 社區的一部分。Seata 作為一個正在不斷成長和演變的開源項目，有着巨大的潛力，同時也面臨着新的挑戰。因此我要強調 Seata 社區的重要性和未來的潛力，它已經進入 Apache 軟件基金會的孵化階段，這個重要的里程碑將為 Seata 帶來更廣闊的發展空間。Seata 歡迎更多的開發者和貢獻者的加入，讓我們共同推動這個開源項目的發展，為分佈式事務領域的進步貢獻一份力量。</p><p>搜索釘釘羣號</p><p>加入 Seata Group 開源交流羣（羣號：32033786）</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 02:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/10439711</guid>
            <link>https://my.oschina.net/u/3874284/blog/10439711</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Apideploy 重磅開源，在成熟 API 文檔解決方案中又多了一個攪局者]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>背景</h3><p style="color:#333333; text-align:start">當前，在很多中、小型的開發團隊或創業團隊中，依然用着落後的方式進行着 API 接口的交互，他們寫完文檔來寫代碼，或者，寫完代碼來補文檔，更甚者，文檔全靠一張嘴，接口描述信息在 IM 中溝通飛揚，在聯調的過程中前後端相互扯皮、苦不堪言。</p><p style="color:#333333; text-align:start">當然，也有很多優秀的團隊，在使用較成熟的解決方案，諸如：swagger、springfox、springdoc、knife4j、apifox、eolink、smart-doc 等等。作者基於自己多年的研發經驗，參考和對比了諸如上述國內外多個 API 管理工具和實現，始終覺得一款精美、高效的 API 平台工具，對開發者的意義重大。在苦苦找尋與對比下，各 API 管理工具依舊沒有達到作者的期望，於是親自下場，一怒之下寫下了 Apideploy。</p><h3>設計理念</h3><p style="color:#333333; text-align:start">Apideploy 遵從以下設計理念：</p><ul><li><strong>代碼即文檔。</strong>API 文檔應該通過代碼自動生成，並能保持與代碼的同步性，而不是通過手寫文檔來與前端、測試等進行協作；</li><li><strong>主流標準友好。</strong>文檔應該支持主流的 OpenAPI 2（OAS2.0）、OpenAPI 3（OAS3.0）等協議標準，同時需要支持 HTTP、WebSocket、SSE 等協議；</li><li><strong>版本可追溯。</strong>每一次的版本迭代，可以快速查閲接口變更的明細，支持不同版本的差異對比，並能支持回滾文檔版本；</li><li><strong>接口可 mock。</strong>可以直接在該產品上完成接口的測試、聯調甚至接口自動化；</li><li><strong>界面要精美。</strong>友好的用户界面與交互；</li><li><strong>第三方兼容。</strong>支持導入常見的 API 協議標準文檔，也支持導出常用的文檔格式。</li></ul><h3>產品架構</h3><p style="color:#333333; text-align:start"><img alt="en_intro" src="https://doc.apideploy.cn/getting-started/en_intro.jpg" referrerpolicy="no-referrer"></p><p style="color:#333333; text-align:start">Apideploy 核心分為兩部分：<strong>API 文檔生成 SDK+API 託管與調試平台</strong>。</p><p style="color:#333333; text-align:start"><strong>API 文檔生成 SDK</strong>是完全開放源碼的，訪問<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapideploy-team" target="_blank">https://github.com/apideploy-team</a><span>&nbsp;</span>可以查閲。目前僅支持 Java 語言實現，其他語言社區用户可以貢獻，或自行直接通過<strong>API 託管與調試平台</strong>的 RESTFull API 進行對接。Java 語言 SDK 實現基於 javadoc 註釋方式自動生成 API 文檔（無代碼侵入方式），也兼容了基於 swagger 的實現。具體使用請參考：</p><p style="color:#333333; text-align:start"><strong>API 託管與調試平台</strong>主要功能包括：項目管理、團隊協作、權限管理、API 文檔託管、文檔調試、接口數據 mock、版本更新記錄、版本對比、個性化文檔導出、多格式文檔導入等，是一個集 API 全生命週期管理的平台，非常適合團隊協作。目前<strong>支持公有云與私有化部署</strong>，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.apideploy.cn%2Fgetting-started%2Fwww.apideploy.com" target="_blank">www.apideploy.com</a>是公有云的解決方案。</p><h3>文檔生成原理</h3><p style="color:#333333; text-align:start">Apideploy 推崇<strong>文檔即代碼</strong>的設計理念，所以作者<strong>強烈推薦基於代碼註釋的文檔生成方式</strong>，它不像<strong>swagger</strong>的實現那麼笨重。</p><h4>基於代碼註釋生成文檔</h4><p style="color:#333333; text-align:start">基於代碼註釋生成文檔，Apideploy 的實現參考並依賴了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTongchengOpenSource%2Fsmart-doc" target="_blank">smart-doc</a>的開源代碼，smart-doc 是一款基於<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpaul-hammant%2Fqdox" target="_blank">qdox</a>優秀的 Java 文檔解析工具，它很方便的實現了基於代碼註釋到 API 文檔的過程。</p><p style="color:#333333; text-align:start">Apideploy 開源了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapideploy-team%2Fapideploy-jakarta-client" target="_blank">Java 代碼註釋生成文檔</a>的所有代碼。</p><h4>基於 Swagger / OpenAPI 的文檔生成</h4><p style="color:#333333; text-align:start">在基於 Java Web 項目開發的 Swagger 實現中，目前用的比較多的開源實現是<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspringfox%2Fspringfox" target="_blank">Springfox</a>(包括國內的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoc.xiaominfo.com%2F" target="_blank">Knife4j</a>) 與<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspringdoc%2Fspringdoc-openapi" target="_blank">Springdoc-openapi</a>。Springfox 的用户較多，但貌似已經停止更新，已經不再支持 springboot3.0+的項目。</p><p style="color:#333333; text-align:start">Apideploy 兼容了 springfox 和 springdoc-openapi 的全部實現，所以如果之前的項目使用的是 swagger 項目，也非常方便切換到 Apideploy 進行文檔託管和測試。</p><h3>API 託管與調試平台預覽</h3><p style="color:#333333; text-align:start"><img src="https://i.v2ex.co/vjQiUAMZl.jpeg" referrerpolicy="no-referrer"></p><p><img height="631" src="https://oscimg.oschina.net/oscnet/up-f3b7e7b16ff2539848c29736048a80f0a60.png" width="1280" referrerpolicy="no-referrer"></p><p><img height="1916" src="https://oscimg.oschina.net/oscnet/up-12ef3871f6c01d514e945c6e367e56b6f84.png" width="3742" referrerpolicy="no-referrer"></p><p><img height="1869" src="https://oscimg.oschina.net/oscnet/up-314606b0148f12694dd771012925d45e33c.png" width="3756" referrerpolicy="no-referrer"></p><p><img height="1600" src="https://oscimg.oschina.net/oscnet/up-ad5b3c3b4d97c98ae6e693a1c749587a94f.png" width="3812" referrerpolicy="no-referrer"></p><p><img height="1893" src="https://oscimg.oschina.net/oscnet/up-e1f3e4b1e7e6abeebdab56dd886314c62ec.png" width="3840" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 28 Dec 2023 15:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273213/apideploy-opensource</guid>
            <link>https://www.oschina.net/news/273213/apideploy-opensource</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百度 CTO 王海峯：文心一言用户規模破 1 億]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span><span><span><span>「文心一言用户規模突破</span></span></span><span><span><span>1</span></span></span><span><span><span>億。」1</span></span></span><span><span><span>2 月 28 日，</span></span></span><span><span><span>百度首席技術官</span></span></span><span><span><span>、深度學習技術及應用國家工程</span></span></span><span><span><span>研究中心</span></span></span><span><span><span>主任</span></span></span><span><span><span>王海峯在第十屆</span></span></span><span><span><span>WAVE SUMMIT 深度學習開發者</span></span></span><span><span><span>大</span></span></span><span><span><span>會</span></span></span><span><span><span>上宣佈。會上，王海峯以《文心加飛槳，翩然赴星河》為題作了主旨演講，分享了飛槳和文心的最新成果。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img height="284" src="https://static.oschina.net/uploads/space/2023/1228/192946_d8IJ_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span><strong><span><span><span><strong>飛槳開發者已達 1</strong></span></span></span></strong><strong><span><span><span><strong>070</strong></span></span></span></strong><strong><span><span><span><strong>萬</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span>WAVE SUMMIT 深度學習開發者大會</span></span></span><span><span><span>始於</span></span></span><span><span><span>2019 年 4 月，每年兩次與開發者相聚，如今</span></span></span><span><span><span>已是</span></span></span><span><span><span>五載十屆</span></span></span><span><span><span>。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span><span>回顧五年</span></span></span><span><span><span>，</span></span></span><span><span><span>大會一路</span></span></span><span><span><span>見證了</span></span></span><span><span><span>百度對人工智能技術和產業趨勢的前瞻判斷，指引了技術創新和產業實踐的方向。2</span></span></span><span><span><span>019</span></span></span><span><span><span>年王海峯在</span></span></span><span><span><span>首屆大會上</span></span></span><span><span><span>提出，深度學習框架是智能時代的操作系統。深度學習的通用性特點，以及深度學習框架及平台的發展，推動人工智能標準化、自動化和模塊化，進入工業大生產階段。2</span></span></span><span><span><span>020</span></span></span><span><span><span>年，王海峯提出了打造 AI 新型基礎設施，雲智一體加速產業智能化，將 AI 大生產平台升級為雲智一體的新型基礎設施，為產業智能化奠定堅實的基礎。2</span></span></span><span><span><span>021</span></span></span><span><span><span>年，王海峯表示，人工智能呈現出「融合創新」和「降低門檻」的特點：一方面，AI 技術及產業的融合創新越來越多；另一方面，雖然 AI 技術越來越複雜，但 A</span></span></span><span><span><span>I</span></span></span><span><span><span>開發與應用的門檻卻越來越低。2</span></span></span><span><span><span>022</span></span></span><span><span><span>年，王海峯進一步提出，深度學習平台加上大模型，貫通了從硬件適配、模型訓練、推理部署，到場景應用的 AI 全產業鏈，夯實了產業智能化基座。今年，大語言模型的出現，為通用人工智能帶來曙光。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span>五年來，在持續技術創新和賦能產業的發展歷程中，飛槳自身也在不斷升級，從深度學習框架，到平台生態，發展成為技術領先、功能豐富的產業級深度學習開源開放平台。飛槳集核心框架、基礎模型庫、開發套件、工具組件，以及助力開發者成長的星河社區於一體，具有動靜統一的深度學習框架、端到端自適應大規模分佈式訓練、雲邊端全場景高性能推理等關鍵核心技術。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span><span>飛槳生態愈加繁榮，</span></span></span><span><span><span>2019 年，凝聚在飛槳平台的開發者規模 150 萬，到今年 8 月的 Wave Summit，已經達到 800 萬，服務的企業數量、基於飛槳創建的模型數量，也都高速增長</span></span></span><span><span><span>。王海峯現場公佈了飛槳生態最新成果，截至 2</span></span></span><span><span><span>023</span></span></span><span><span><span>年 1</span></span></span><span><span><span>2</span></span></span><span><span><span>月底，飛槳已凝聚</span></span></span><span><span><span>1070</span></span></span><span><span><span>萬開發者，服務 2</span></span></span><span><span><span>3.5</span></span></span><span><span><span>萬家企事業單位，基於飛槳創建了</span></span></span><span><span><span>86</span></span></span><span><span><span>萬個模型。</span></span></span></span></span></span></span></span></p><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span><span><strong><span><span><span><strong>文心一言用户規模破億，日提問量快速增長</strong></span></span></span></strong></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span><span>據瞭解，百度自</span></span></span><span><span><span>2019</span></span></span><span><span><span>年起深耕預訓練模型研發，發佈了文心大模型 1</span></span></span><span><span><span>.0</span></span></span><span><span><span>。經過近四年積累，百度於今年 3 月在全球科技大廠中率先發布了知識增強大語言模型文心一言。1</span></span></span><span><span><span>0</span></span></span><span><span><span>月，文心一言的基礎模型升級到 4</span></span></span><span><span><span>.0</span></span></span><span><span><span>，理解、生成、邏輯和記憶四大人工智能基礎能力全面提升。文心大模型</span></span></span><span><span><span>4.0</span></span></span><span><span><span>過去兩個多月整體效果又提升了</span></span></span><span><span><span>32%</span></span></span><span><span><span>。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img height="283" src="https://static.oschina.net/uploads/space/2023/1228/193026_HXnt_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span><span>王海峯現場披露，文心一言用户規模已突破</span></span></span><span><span><span>1</span></span></span><span><span><span>億，自 8 月 3</span></span></span><span><span><span>1</span></span></span><span><span><span>日</span></span></span><span><span><span>獲準開放對公眾提供服務</span></span></span><span><span><span>以來，文心一言的用户提問量一路上揚，基本與文心大模型的效果提升同步。越來越多的用户在信任和使用文心一言。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span><span>王海峯最後表示：「</span></span></span><span><span><span>五</span></span></span><span><span><span>載</span></span></span><span><span><span>十屆，</span></span></span><span><span><span>我們與所有開發者一起，踔厲奮發，篤行不怠。願繼續與所有開發者攜手並肩，在飛槳和文心的支持下，共赴通用人工智能的星辰大海！」</span></span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 28 Dec 2023 11:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273184</guid>
            <link>https://www.oschina.net/news/273184</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[廣電運通加入 openKylin，助力社區創新技術發展！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，廣電運通集團股份有限公司（以下簡稱」廣電運通「）簽署了 openKylin 社區 CLA（Contributor License Agreement 貢獻者許可協議），正式加入 openKylin 開源社區。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-cab724551f7e2a4ba37a2d71058d9f83c08.png" referrerpolicy="no-referrer"></p><p><span>廣電運通創立於 1999 年，隸屬於廣州無線電集團，是國有控股的高科技上市企業，主營業務覆蓋智能金融、公共安全、智能交通、數字政府、大文旅、新零售及智慧教育等領域，為全球客户提供具有競爭力的智能終端、運營服務及大數據解決方案。</span></p><p><span>廣電運通已連續 15 年位列智能金融設備市場第一，是國內最大的金融智能自助設備供應商和服務商，旗下信創軟硬件產品已在各大金融機構廣泛應用和驗證，持續為金融信創繁榮發展輸入源源不斷的動能。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e6b2fb1b3ecd1366d41e1da581a52ad6d78.png" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>加入 openKylin 社區後，廣電運通將充分發揮自身在金融科技領域的技術和資源優勢，聯合上下游合作伙伴，建立互利共贏的良性循環，與社區在金融智能終端技術遷移等方面開展合作，豐富產業生態，助力創新技術發展。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 28 Dec 2023 09:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273155</guid>
            <link>https://www.oschina.net/news/273155</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[深耕開發者生態，openKylin 入選 2023 中國技術品牌影響力企業榜]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>2023 年 12 月 26 日，中國技術先鋒年度評選&nbsp;| 2023 中國技術品牌影響力企業榜單正式發佈。作為中國領先的新一代開發者社區，SegmentFault 思否依託數百萬開發者用户數據分析，各科技企業在國內技術領域的行為及影響力指標，最終評選出 30 家上榜企業。<strong>openKylin 作為中國領先的開源操作系統根社區，憑藉在技術領域和開發者生態領域的持續貢獻，入選 30 強之列。</strong></span></p><p style="text-align:center"><img alt="" height="3508" src="https://oscimg.oschina.net/oscnet/up-f71b87d34c96069fbcb15077685dcb8cfdf.png" width="2481" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>相信開發者的力量，一直以來 openKylin 社區都堅持大力推動開發者生態建設。2023 年，openKylin 社區曾組織和參與頂級技術大會、開發者大賽、技術沙龍</span><span>等活動</span><span><strong>70+</strong>場，以領先技術回饋社區。截至目前，openKylin 已累計發佈<strong>6</strong>個社區版本，下載量<strong>100 萬+</strong>；匯聚<strong>400+</strong>社區會員<strong>、5500+</strong>開發者加入社區，並累計成立<strong>94</strong>個 SIG 組開展技術研究與創新，<span>和開發者共同成長。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>未來，openKylin 也將保持初心，加強生態建設，服務廣大開發者，為營造良好開源生態和技術發展持續努力，也期待越來越多的開發者參與進來，為建設開源、貢獻開源添磚加瓦！&nbsp;</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="color:#7f7f7f">附：《2023 中國技術品牌影響力企業》</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5f8de216bffebbb3744628f4612997a427f.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>openKylin（開放麒麟）社區旨在以「共創」為核心，在開源、自願、平等、協作的基礎上，通過開源、開放的方式與企業構建合作伙伴生態體系，共同打造桌面操作系統頂級社區，推動 Linux 開源技術及其軟硬件生態繁榮發展。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff">社區理事成員單位包括麒麟軟件、普華基礎軟件、中科方德、麒麟信安、凝思軟件、一銘軟件、中興新支點、元心科技、中國電科 32 所、技德系統、北京麟卓、先進操作系統創新中心、飛騰、兆芯、龍芯中科、景美、京東科技、玄鐵、申泰信息、海光等 21 家產業同仁和行業機構。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 28 Dec 2023 09:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273154</guid>
            <link>https://www.oschina.net/news/273154</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
