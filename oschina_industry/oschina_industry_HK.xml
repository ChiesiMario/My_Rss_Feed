<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 26 Dec 2023 06:23:42 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[WAVE SUMMIT 迎來第十屆，文心一言將有最新披露！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>1</span></span><span><span>0</span></span><span><span>句話 2 分鐘，挑戰成功説服宿管阿姨開門，這個人羣中的「顯眼包」是一個接入文心大模型 4</span></span><span><span>.0</span></span><span><span>遊戲裏的 NPC，妥妥 「工具人」實錘～</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>嘗試用</span></span><span><span>AI</span></span><span><span>一鍵自動識別好壞咖啡豆，看一眼便知好壞，真正「顏值即正義」，讓咖啡星人狂喜～</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>藉助 AI 在</span></span><span><span>任何平面上模擬</span></span><span><span>的</span></span><span><span>鋼琴，</span></span><span><span>即興「彈奏」世界名曲，開一場科技感滿滿的專屬演奏會～</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>在虛擬世界</span></span><span><span>的</span></span><span><span>神奇辦公室，輸入你的創業方向，智慧打工人們將為你的項目勤勞奔走，並在過程中，把日報</span></span><span><span>、</span></span><span><span>週報寫好，讓你隨時掌握項目進度和最終成果</span></span><span><span>……</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img height="280" src="https://static.oschina.net/uploads/space/2023/1226/134838_ASJC_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>這些聽起來新奇而有趣的 A</span></span><span><span>I</span></span><span><span>應用，都將在兩天後舉行的 W</span></span><span><span>AVE SUMMIT+深度學習開發者大會 2023</span></span><span><span>開發者市集亮相。</span></span><span><span>作為業界影響力最大的深度學習與大模型開發者大會，WAVE SUMMIT+ 2023</span></span><span><span>定於</span></span><span><span>12 月 28 日</span></span><span><span>在</span></span><span><span>北京開啓</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img height="285" src="https://static.oschina.net/uploads/space/2023/1226/134858_tJnB_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>現場大咖雲集，</span></span><span><span>百度首席技術官</span></span><span><span>、</span></span><span><span>深度學習技術及應用國家工程研究中心主任王海峯</span></span><span><span>及數百位</span></span><span><span>產業大咖、知名學者、技術大牛、頂尖開源項目發起人等重磅嘉賓，從大模型技術、開源開放、產業護航、軟硬一體等議題出發，</span></span><span><span>為開發者奉上大模型時代低門檻開發和創建應用的硬核乾貨。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>倒計時 2 天，大會的五大亮點帶大家搶鮮看。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>亮點一：趨勢引領，「扛把子」文心一言將曝新進展</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>今年 1</span></span><span><span>0</span></span><span><span>月 1</span></span><span><span>7</span></span><span><span>日，迄今為止綜合實力最強的文心大模型 4</span></span><span><span>.0</span></span><span><span>重磅面世，</span></span><span><span>理解、生成、邏輯、記憶</span></span><span><span>四大能力得到</span></span><span><span>顯著提升，大語言模型</span></span><span><span>正在</span></span><span><span>為通用人工智能帶來曙光。</span></span><span><span>截至 1</span></span><span><span>1</span></span><span><span>月初，文心一言用户數達到 7</span></span><span><span>000</span></span><span><span>萬，場景達</span></span><span><span>4300</span></span><span><span>個。這</span></span><span><span>得益於飛槳與文心的協同優化，</span></span><span><span>文心大模型 4</span></span><span><span>.0</span></span><span><span>的</span></span><span><span>模型周均訓練有效率超過 98%，</span></span><span><span>相比於 3 月份，</span></span><span><span>訓練算法效率提升</span></span><span><span>至</span></span><span><span>3.6 倍</span></span><span><span>，推理性能提升至 5</span></span><span><span>0</span></span><span><span>倍。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>本次大會，文心一言以及飛槳將披露技術和生態層面的最新進展，更關乎千萬開發者的切身使用體驗和權益～第十屆</span></span><span><span>WAVE SUMMIT</span></span><span><span>，值得期待。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>亮點二：乾貨十足，硬核低門檻開發秘籍大放送</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>當今，技術圈萬眾矚目的</span></span><span><span>A</span></span><span><span>gent 到底是何方神聖，應該怎麼打造</span></span><span><span>A</span></span><span><span>gent？</span></span><span><span>大模型與開發工具鏈相結合，為開發提效提供了哪些</span></span><span><span>新</span></span><span><span>可能？</span></span><span><span>硬件-框架-模型到底怎樣協同優化發揮最大效能？開發者們的「趁手利器」</span></span><span><span>C</span></span><span><span>omate 還能怎麼用？你想了解的各類技術乾貨，前沿的科技圈熱點，來</span></span><span><span>WAVE SUMMIT+2023</span></span><span><span>，不容錯過！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span>亮點三：蓄勢待發，大模型賦能產業正當時</span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>大會主論壇之後，聚焦前沿、產業、硬件、開發應用等主題的五大平行論壇同步舉行，將</span></span><span><span>大模型前沿技術分享與產業落地的</span></span><span><span>心法一一奉上。</span></span><span><span>科學啓智</span></span><span><span>、</span></span><span><span>AI 賦能</span></span><span><span>，</span></span><span><span>AI for Science 塑造多學科研究新範式</span></span><span><span>，跨界融合創新展現</span></span><span><span>巨大應用潛能</span></span><span><span>；大模型產業應用中的標杆先行者放大招：華晨寶馬將帶來企</span></span><span><span>業級大模型 Agent 服務平台</span></span><span><span>、東方電科新能源功率準確性提升實現能效優化……</span></span><span><span>主流硬件廠商悉數亮相：NVIDIA、Intel、中科曙光、昇騰、燧原科技、太初</span></span><span><span>……</span></span><span><span>飛槳硬件生態朋友圈再擴大，生態勢能貫通產業鏈。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>亮點四：羣星閃耀，AI 產業生態星河萬裏</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>開源開放、眾行致遠</span></span><span><span>。為</span></span><span><span>持續引導探索產業 AI 關鍵場景，大會</span></span><span><span>還從</span></span><span><span>開源開放、產業創新等多個維度</span></span><span><span>，</span></span><span><span>評選出 「星河產業應用創新獎」，「文心 x 飛槳最具影響力開發者」</span></span><span><span>等大獎</span></span><span><span>，</span></span><span><span>並將於大會</span></span><span><span>現場頒獎，激發開源創新活力，</span></span><span><span>賦能產業繁榮生態，</span></span><span><span>助推產業智能化</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>W</span></span><span><span>AVE</span></span>&nbsp;<span><span>SUMMIT</span></span><span><span>&nbsp;五年十屆，這也是中</span></span><span><span>國 AI 技術生態繁榮與崛起的關鍵時期。</span></span><span><span>開發者作為中堅力量，為智能世界貢獻出自己的智慧；飛槳星河社區以開源開放的姿態，匯聚了開發者們最聰明的大腦。大會將設有開發者相關環節，讓大家看到羣像背後的一個個故事，感受一點點星光、見證科技讓世界更有温度。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span>亮點五：</span></span></strong><strong><span><span><strong>應用繁榮，創意市集與</strong></span></span></strong><strong><span><span><strong>AI</strong></span></span></strong><strong><span><span><strong>原生</strong></span></span></strong><strong><span><span><strong>W</strong></span></span></strong><strong><span><span><strong>orkshop 盡顯極客範</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>這次</span></span><span><span>WAVE SUMMIT+ 2023 為開發者專設多個體驗互動環節，</span></span><span><span>前面</span></span><span><span>提到的開發者市集就是其中之一</span></span><span><span>。本次開發者市集上，幾十款開發者打造的</span></span><span><span>AI</span></span><span><span>互動小應用，帶你沉浸式感受技術的魅力，現場還有開發者親自講解、示範，零距離接觸那些開發者大神。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img height="265" src="https://static.oschina.net/uploads/space/2023/1226/134921_vHME_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>此外，大會還為開發者們精心準備了三場</span></span><span><span>Workshop</span></span><span><span>，</span></span><span><span>現場</span></span><span><span>手把手教你</span></span><span><span>打造自己的 AI</span></span><span><span>原生</span></span><span><span>應用</span></span><span><span>。星河探索，智能應用，志在推進高質量、高可用的</span></span><span><span>AI</span></span><span><span>原生應用落地的最後一公里，</span></span><span><span>現場</span></span><span><span>將帶來星河社區</span></span><span><span>ERNIE Bot</span></span>&nbsp;<span><span>SDK</span></span><span><span>的能力講解與實戰，幫你解鎖文心一言無限可能，還有更多</span></span><span><span>AI</span></span><span><span>原生應用落地和開發實戰，</span></span><span><span>玩轉原生應用</span></span><span><span>，感受 AI 原生應用魅力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>在經歷過下午一系列酣暢的技術燒腦與極客碰撞後，晚上，開發者們可以到「</span></span><span><span>AI 開發者之夜</span></span><span><span>」好好放鬆一下，在這不僅可以挑戰</span></span><span><span>AI 原生小遊戲</span></span><span><span>，觀看精彩表演，也能「以 AI 會友」，共同奔赴 AI 時代的「詩與遠方」。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>隨着大模型的爆發，人工智能</span></span><span><span>的風已經吹到</span></span><span><span>社會的</span></span><span><span>各個</span></span><span><span>角落。</span></span><span><span>W</span></span><span><span>AVE SUMMIT+ 2023</span></span><span><span>這場 AI 開發者的「嘉年華」，讓每位參會者深入探索基於大模型的 AI 應用，瞭解技術發展前沿信息和應用風向，在新時代新機遇來臨之際，抓住先機，創造更多可能。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 05:49:39 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272772</guid>
            <link>https://www.oschina.net/news/272772</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Kuasar 成為 CNCF 官方項目，探索容器運行時新紀元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自華為雲社區《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F418445%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">Kuasar 成為 CNCF 官方項目，探索容器運行時新紀元！</a>》，作者：雲容器大未來。</p><p>北京時間 12 月 20 日，雲原生計算基金會（CNCF）正式接納多沙箱容器運行時項目<span>&nbsp;</span><strong>Kuasar</strong>（https://github.com/kuasar-io/kuasar）。Kuasar 的加入，極大地推動了雲原生領域容器運行時技術的探索、創新和發展。</p><p><img alt="11.png" src="https://bbs-img.huaweicloud.com/blogs/img/20231222/1703228593906841756.png" referrerpolicy="no-referrer"></p><p>作為 CNCF 首個多沙箱容器運行時項目，Kuasar 於 2023 年 4 月在 KubeCon + CloudNativeCon Europe 上由華為雲、中國農業銀行以及 openEuler 社區、WasmEdge 社區和 Quark Containers 社區聯合發起。Kuasar 融入了各企業和社區在容器運行時領域的前沿探索、技術積累和生產實踐，開源至今受到業界的廣泛關注和支持，已收穫 900 多個 GitHub Star 和 70 多個 Fork，數十位來自外部企業、高校的開源愛好者參與開發貢獻和積極落地應用，Kuasar 正以開源創新的姿態促進雲原生產業發展。</p><div><div><div><div><div><p><strong>「WebAssembly 正在快速成為雲原生技術棧的一個關鍵部分，Kuasar 深度集成了高性能、輕量級的 WasmEdge 沙箱，Kuasar 的加入使得 WebAssembly 生態和 CNCF 生態聯繫更加緊密，未來 WasmEdge 和 Kuasar 將共同推動在大模型、邊緣計算和函數計算等領域的發展。」</strong><strong>—— WasmEdge 項目創始人 Michael Yuan</strong></p></div></div></div></div></div><div><div><div><div><div><p><strong>「openEuler 社區在 Kuasar 項目發佈之初就率先完成與 Kuasar 多沙箱生態的對接，推出基於 iSulad + Kuasar + StratoVirt 的極速輕量安全容器解決方案。未來 openEuler 社區將繼續深化與 CNCF 社區項目的合作，為用户提供更輕量、更安全、更多樣的容器化底座。」—— openEuler 技術委員會主席，胡欣蔚</strong></p></div></div></div></div></div><div><div><div><div><div><p><strong>「Kuasar 項目融入了華為雲在容器運行時領域多年的積累，結合了社區合作伙伴的實踐經驗。成為 CNCF 官方項目，表明了 Kuasar 社區開放治理的決心，致力於為企業和開發者提供廠商中立、多方協作的開放環境，促進各種沙箱技術的商用成熟，為用户帶來極致體驗。」—— CNCF 官方大使，華為云云原生開源團隊負責人，王澤鋒</strong></p></div></div></div></div></div><div><div><div><div><div><p><strong>「雲原生場景多樣化促進了多種沙箱技術的蓬勃發展，沙箱技術接入北向生態成為普遍需求，Kuasar 推動了 Containerd 中沙箱技術標準的統一，提供了多種沙箱技術實現，為 CNCF 的容器運行時板塊注入了新鮮活力。」—— CNCF 官方大使 Containerd 社區維護者，蔡威</strong></p></div></div></div></div></div><span id="OSC_h2_1"></span><h2>Kuasar 項目介紹</h2><p>為了滿足企業在雲原生場景下的訴求，業界出現了多種沙箱容器隔離技術。然而，應用雲原生的沙箱技術仍面臨挑戰。一方面，各類雲原生場景對沙箱提出更高要求，單一沙箱無法同時滿足用户雲上業務對安全隔離、極速低噪、標準通用等多個維度的要求，企業面臨雲原生業務場景全覆蓋問題；另一方面，支持多類沙箱帶來運維壓力顯著上升，當前業界沙箱技術對接容器運行時的實現缺乏統一開發框架，因此關鍵日誌、重要事件、沙箱管理邏輯等均存在差異，新引入沙箱的同時運維壓力陡增。</p><p>Kuasar 在保留傳統容器運行時功能的基礎上，與 Containerd 社區一起推動新的沙箱接口統一標準，並通過全面 Rust 化以及優化管理模型框架等手段，進一步降低管理開銷，簡化調用鏈路，靈活擴展對業界主流沙箱技術的支持。此外，通過支持多安全沙箱共節點部署，Kuasar 可以充分利用節點資源、降本增效，為用户提供更安全高效的沙箱場景解決方案。</p><p><img alt="12.png" src="https://bbs-img.huaweicloud.com/blogs/img/20231222/1703228609750179875.png" referrerpolicy="no-referrer"></p><p>▲ Kuasar 項目全景圖</p><p>南向沙箱方面，Kuasar 已支持基於輕量級虛擬化技術的安全容器沙箱（Cloud Hypervisor、Qemu、StratoVirt），基於新興的 WebAssembly 沙箱（WasmEdge、Wasmtime），基於進程級虛擬化的 App Kernel 沙箱（Quark）以及基於內核的原生普通容器沙箱（runC）；北向引擎方面，Kuasar 已與 Containerd 聯合構建最新的沙箱接口標準，並共同推動該標準在 Containerd v2.0 版本的完整實現。此外，輕量級容器引擎 iSulad 項目也已經完成與 Kuasar 項目的深度集成，支持在 openEuler 23.09 創新版本上一鍵部署。</p><span id="OSC_h2_2"></span><h2>未來可期</h2><p>此次 CNCF 正式將 Kuasar 接納為官方項目，將極大促進 Kuasar 上下游社區生態構建及合作。Kuasar 將持續探索雲原生容器運行時領域技術創新，在企業數字化、雲原生轉型過程中發揮作用，讓基於 Kuasar 的多沙箱容器運行時方案融入更廣泛的雲原生技術生態。</p><p>作為 CNCF 亞洲唯一創始成員、白金會員，華為雲在 CNCF 貢獻量、Kubernetes 社區和 Istio 社區的代碼貢獻量持續多年穩居亞洲第一，已向 CNCF 貢獻了業界首個雲原生邊緣計算項目 KubeEdge、首個雲原生批量算力項目 Volcano、首個多雲容器編排項目 Karmada 等多個重量級雲原生開源項目，並持續開源 Kurator、Kappital、Kmesh 等創新項目，與全球雲原生社區共同發展。</p><span id="OSC_h3_3"></span><h3>Kuasar 社區技術交流地址</h3><p>Kuasar 官網：https://kuasar.io</p><p>項目地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkuasar-io%2Fkuasar" rel="nofollow" target="_blank">https://github.com/kuasar-io/kuasar</a></p><p>Twitter:<span>&nbsp;</span>https://twitter.com/Kuasar_io</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>點擊關注，第一時間瞭解華為雲新鮮技術~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10412251</guid>
            <link>https://my.oschina.net/u/4526289/blog/10412251</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲原生週刊：Karmada 成為 CNCF 孵化項目]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>開源項目推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Femberstack%2Fkubernetes-reflector" target="_blank">kubernetes-reflector</a></h3><p>Reflector 是一個 Kubernetes 的插件，旨在監視資源（secrets 和 configmaps）的變化，並將這些變化反映到同一命名空間或其他命名空間中的鏡像資源中。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsubstratusai%2Flingo" target="_blank">Lingo</a></h3><p>Lingo 是適用於 K8s 的 OpenAI 兼容 LLM 代理和自動縮放器。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fflanksource%2Fcanary-checker" target="_blank">canary-checker</a></h3><p>canary-checker 是一個基於 Kubernetes 的本地平台，用於通過被動和主動（合成）機制監控應用程序和基礎架構的健康狀況。</p><h2>文章推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40elementtech.dev%2Fkubernetes-image-proxy-cache-from-minutes-to-milliseconds-fd14173e831f" target="_blank">Kubernetes Harbor 圖像代理緩存 — 從幾分鐘到幾毫秒</a></h3><p>這篇文章介紹瞭如何通過使用 Harbor 作為 Kubernetes 的代理緩存來提高容器鏡像的拉取速度。文章首先解釋了 Kubernetes 中容器鏡像的拉取過程和現有的緩存機制的侷限性，然後介紹了 Harbor 作為一個 CNCF 項目的作用，並詳細説明瞭 Harbor 的 Pull Through Proxy Cache 機制。該機制可以在本地緩存中存儲常用的鏡像，當節點需要拉取鏡像時，可以直接從本地緩存中獲取，減少了網絡延遲和帶寬消耗。文章還介紹瞭如何在 Kubernetes 上安裝和配置 Harbor，並提供了使用 Harbor 的示例命令。最後，文章介紹瞭如何通過使用 Harbor Cache Mutating Webhook 來自動讓 Kubernetes 使用代理緩存。總體而言，這篇文章詳細介紹瞭如何通過 Harbor 實現快速的鏡像緩存，提高容器化環境中的部署效率。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40sushantkapare1717%2Fhelm-vs-kustomize-in-kubernetes-cc063bbb4b0e" target="_blank">Kubernetes 中的 Helm 與 Kustomize</a></h3><p>這篇文章比較了 Helm 和 Kustomize 這兩個用於管理 Kubernetes 清單文件的工具。文章首先介紹了 Kubernetes 在現代 IT 基礎架構中作為容器編排和管理的事實標準，並指出在規模化部署應用程序時，管理複雜配置和清單文件變得至關重要。然後詳細介紹了 Helm 和 Kustomize 這兩個工具的特點和優勢。Helm 是一個用於簡化應用程序部署和管理的 Kubernetes 包管理器，具有模板化、可重用性、版本管理和社區支持等優點。Kustomize 是另一個用於自定義 Kubernetes 清單文件的工具，採用"patch"的方法，支持聲明性修改現有清單文件和配置覆蓋。文章還提供了使用 Helm 和 Kustomize 的示例，並對它們進行了比較，包括模板化與補丁應用、靈活性和學習曲線等方面。最後，文章強調了根據具體需求和偏好選擇適合的工具的重要性，並鼓勵讀者保持對最新工具和最佳實踐的瞭解，以提高部署效率。</p><h2>雲原生動態</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthenewstack.io%2Fkarmada-finally-brings-multicloud-control-to-kubernetes%2F" target="_blank">Karmada 成為 CNCF 孵化項目</a></h3><p>日前，雲原生計算基金會的技術監督委員會 (TOC) 投票決定接受 Karmada 作為 CNCF 孵化項目。</p><p>Karmada 通過一組 Kubernetes 原生 API 和高級調度功能，提供了一種跨不同雲提供商運行 Kubernetes 集羣的方法。它不需要對應用程序本身進行任何更改。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevclass.com%2F2023%2F12%2F12%2Fdocker-buys-atomicjar-to-integrate-container-based-test-automation%2F" target="_blank">Docker 購買 AtomicJar 以集成基於容器的測試自動化</a></h3><p>Docker 購買了 AtomicJar 及其 Testcontainer 項目，為 Docker 提供了更好的測試方案，但引發了對未來許可成本和對其他容器運行時支持的擔憂。</p><p>Docker 首席執行官 Scott Johnston 表示，添加 TestContainers 使 Docker 的開發人員工作流程更加完整，為涵蓋構建、驗證、運行、調試和共享的現有功能添加了測試。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F21%2Fciliums-2023-annual-report%2F" target="_blank">Cilium 2023 年年度報告</a></h3><p>2023 年對於 Cilium 來説是一個重要的里程碑，被稱為 Cilium 畢業年。今年，我們看到 Cilium 生態系統在貢獻和採用方面都取得了顯着增長。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcilium%2Fcilium.io%2Fblob%2Fmain%2FAnnual-Reports%2FCilium%2520Annual%2520Report%25202023.pdf" target="_blank">2023 年 Cilium 年度報告</a>旨在強調這些進步，重點關注 Cilium 貢獻者和最終用户社區的增長和活動。</p><p>該報告通過項目里程碑和承諾等數字數據以及社區領導者、最終用户和貢獻者的個人見解，全面介紹了社區的健康狀況。它深入探討了幾個關鍵領域：Cilium 畢業進度、貢獻者增長、主要發佈亮點、2023 年 Cilium 用户調查的反饋、Cilium 在生產環境中的使用情況、社區參與和報價、社區活動以及 2024 年項目方向。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10398476</guid>
            <link>https://my.oschina.net/u/4197945/blog/10398476</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Fedora 40 計劃統一 /usr/bin 和 /usr/sbin]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>早在多年前，Fedora 曾合併了 /bin 和 /usr/bin。時至今日，針對 Fedora 40&nbsp;提交的一項最新更改<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffedoraproject.org%2Fwiki%2FChanges%2FUnify_bin_and_sbin" target="_blank">提案</a>則提出，統一其&nbsp;/usr/bin&nbsp;和&nbsp;/usr/sbin&nbsp;位置；因為&nbsp;<span style="background-color:#ffffff; color:#121212">/bin 和 /sbin 之間的劃分已不再有用，且無人使用。</span></p><p>提案解釋稱：</p><blockquote><p>/usr/sbin 目錄成為 bin 的 symlink，這意味着 /usr/bin/foo 和 /usr/sbin/foo 等路徑指向同一個地方。/bin 和 /sbin 已經是 /usr/bin 和 /usr/sbin 的 symlink，因此 /bin/foo 和 /sbin/foo 實際上也指向同一個地方。/usr/sbin 將從默認的 $PATH 中刪除。</p></blockquote><p><img height="219" src="https://oscimg.oschina.net/oscnet/up-ed7d7efd2d93feaf5de7d017798772f87b4.png" width="700" referrerpolicy="no-referrer"></p><p>該變更提案認為這對 packagers 和 end-users 來説都是一種簡化，且 Fedora 將與 Debian 等其他 Linux 發行版更加兼容。</p><p><strong><span><span><span style="color:#373a3c"><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span><span>對 Fedora 的好處：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><ul><li>Packagers&nbsp;不必考慮是將程序安裝在<code>%_bindir</code>還是<code>%_sbindir</code>。</li><li>用户不必考慮程序是安裝在<code>%_bindir</code>還是<code>%_sbindir</code>.</li><li>Fedora 與其他發行版變得更加兼容。「例如，我們有 /sbin/ip，而 Debian 有 /bin/ip；我們有 /bin/chmem 和 /bin/isosize，而 Debian 有 /sbin/chmem 和 /sbin/isosize、 我們還有 /sbin/{addpart,delpart,lnstat,nstat,partx,ping,rdma,resizeepart,ss,udevadm,update-alternatives}，而 Debian 的這些都在 /bin 下，等等。」</li><li>Fedora 與 Arch 更加兼容，Arch 於幾年前進行了合併。</li><li><code>execvp</code>和相關函數遍歷的目錄更少。這對於速度可能並不重要，但在查看日誌或<code>strace</code>輸出時是一個很好的簡化。</li></ul><p><strong><span><span><span style="color:#373a3c"><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span><span>升級/兼容性影響</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span style="color:#373a3c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>對於用户來説，這種變化基本上是不可見的。在過渡過程中，兩套路徑都應正常工作，用户在<code>$PATH</code>中應同時擁有這兩個目錄。一旦過渡完成，兩套路徑都將正常工作，但用户在<code>$PATH</code>中只能看到<code>/usr/bin</code>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>目前，該變更提案仍處於擬議狀態，需得到 FESCo 的批准後才能應用在四月發佈的 Fedora 40 中。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272754/fedora-40-unify-usr-bin-sbin</guid>
            <link>https://www.oschina.net/news/272754/fedora-40-unify-usr-bin-sbin</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年度低代碼企業 TOP50 榜單公佈 — JeecgBoot 連續兩年榮登榜單]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p style="margin-left:0; margin-right:0">近日，中國科學院主管、科學出版社主辦的國家級核心期刊《互聯網週刊》聯合 eNet 研究院、德本諮詢評選的《2023 低代碼企業 50 強》榜單正式公佈。這一榜單的公佈引起了業內外的廣泛關注，因為其中涵蓋了低代碼開發領域的眾多傑出企業，展現了低代碼產業的發展趨勢和行業格局。</p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">在這份備受矚目的榜單中，知名企業釘釘、騰訊雲、華為雲等行業優秀廠商的產品悉數入選，充分展現了它們在低代碼領域的技術實力和市場影響力。而更加令人矚目的是，<code>JeecgBoot</code><span>&nbsp;</span>作為低代碼開發領域的領軍企業，連續兩年榮登榜單，憑藉其卓越的產品實力和市場表現，再次彰顯了其在行業中的領先地位和影響力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">JeecgBoot 低代碼平台作為備受認可的低代碼開發平台，一直以來致力於為企業提供高效、靈活、可定製的低代碼開發解決方案。其產品以簡單易用、快速開發、可視化操作等特點而著稱，深受廣大企業用户的青睞。JeecgBoot 連續兩年榮登《2023 低代碼企業 50 強》榜單，再次印證了其在低代碼開發領域的卓越地位和不斷增長的市場影響力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">www.jeecg.com</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" height="330" src="https://oscimg.oschina.net/oscnet/up-458906dcd2cc0cb63a454761d96b1602826.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">同時在 2023 年，JeecgBoot 又推出了 「敲敲雲」 零代碼產品，將為低代碼市場帶來新的競爭對手和發展動力。這不僅豐富了 JeecgBoot 的產品線，也為企業用户提供了更多元化的選擇。隨着低代碼和零代碼市場的不斷髮展，我們有理由相信，這將為整個數字化轉型領域帶來更多的機遇和活力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">www.qiaoqiaoyun.com</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-cad61647c80a1dbdedac3adc1d490cb1917.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" height="2516" src="https://oscimg.oschina.net/oscnet/up-c3e1f9901ed0f7fbba1f83cc3cf120a9ab1.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272750</guid>
            <link>https://www.oschina.net/news/272750</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[上雲？下雲？降本增笑？割韭菜？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本月，滴滴崩潰事件鬧得轟轟烈烈，各種離譜派單層出不窮，而造成這一混亂的，則是底層出故障的雲。尷尬的是，這已經不是第一次雲崩潰事件了，距離上一次阿里雲事件，還不到一個月。</p><p>一時之間，各種有關「雲」的討論紛紛揚揚：有人眼饞馬斯克的 X 下雲省錢，覺得反正都有風險，還不如自己弄，這樣更可掌控，也更清楚；有人則認為上雲才是未來的趨勢，想要發揮出軟件的最大優勢，上雲更合適。</p><p>那麼，實際操作中，到底是自建雲更安全，還是公有云更有保障？對普通的廠商而言，該怎麼選擇呢？對此，開源中國邀請了前滴滴軟件開發工程師李鶴、AutoMQ 聯合創始人 &amp; CTO 周新宇、前淘寶 DBA 蔣明、磐吉雲數 CEO 馮若航、公眾號《瑞典馬工》主理人馬工，一起來討論。</p><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>上雲到底有沒有必要？雲是不是在割韭菜？</h1><p><strong>正方：周新宇 speaking ——</strong></p><p>我個人大概是在 16 年就加入阿里巴巴巴的中間件團隊了，服務了很多客户。從我個人的經驗來講：</p><p><strong>第一，沒有云之前，硬件出了問題，解決的門檻很高。</strong>阿里內部上雲之前，因為消息中間件集羣規模很大，硬件它總是在出問題，比如説因為網卡問題導致了 TCD 重視率很高，硬盤出現局部的不可寫；比如服務器某個硬件温度過高，導致一些局部的節點不可用。好在阿里有專業的團隊幫忙解決，但這在小企業就很難負擔了。</p><p><strong>第二，公有云比專有云效率高。</strong>像我們專門做交付，交付完才是第一步，後面有很多的運維工作，這些運維工作，如果我們遠程去做的話，效率比較低，如果去駐廠的話，成本又比較高。公有云的模式，通過聚集算力和統一標準，帶來了很多效率上的提升。</p><p><strong>第三，雲計算能加速業務的創新，提高社會運轉效率。</strong>像在線教育行業，幾年前，基本上都利用了公有云的優勢來快速進行業務的創新。如果沒有云計算，如果不上雲，這些完全不可能發生。還有疫情期間的遠程會議，一定程度上保障了社會各方面的正常運轉。背後的釘釘這些企業軟件，也都是雲計算在提供算力。</p><p>過去，大部分企業還是以雲託管的方式上雲為主，基本上就是傳統的軟件架構，通過這個方式進行上雲。但不管怎麼樣，一定程度上解決了效率和創新問題。今天在降本增效的浪潮下，企業用雲，可能不能暴力地照搬以前的架構了，架構需要面向雲的能力去設計、去優化，把雲原生的能力發揮出來。</p><p>&nbsp;</p><p><strong>反方：馮若航 speaking ——</strong></p><p>我比較喜歡用實打實的數據來定量分析雲。我的觀點是：在降本增效成為主旋律的大背景下，對於有一定規模的雲上企業來説，下雲自建是一個非常經濟務實的選項。我認為公有云它是有適用光譜的，絕對不是他們宣稱的數字化萬金油。不在這個光譜範圍內的業務，如果選擇上雲，或者是留在雲上，那就是被割韭菜了。</p><p><strong>我這有歪詩一首：世人常道雲上好，託管服務煩惱少。我言云乃殺豬盤，溢價百倍實厚顏。賽博地主搞壟斷，坐地起價剝血汗。運維外包嫖開源，租賃電腦炒概念。</strong></p><p>公有云的商業模式概括起來就是一個事兒：租——租服務器租帶寬租磁盤租運維，這跟租房沒有什麼本質的區別，自建我們就可以類比為買房。那麼租房還是買房的決定性因素是什麼？我認為是租售比。房子的租售比一般在幾百一個月，那大家買房可能要掂量。那麼，服務器的租售比、雲算力的租售比一般在半年左右使用費=購買價格。雲磁盤的租售比就更離譜了，只有十幾天到一個月。你用一塊雲盤十幾天就能買下來，你用一台雲服務器，六個月就能把它買下來，那麼你為什麼要把一個業務跑在這租的東西上，而不是直接把它買下來？如果你的業務生命週期超過六個月，你可以考慮把它買下來，而不是租。</p><p>為什麼雲的價格這麼貴？我認為根本原因在硬件上。硬件遵循着摩爾定律在指數增長，成本在指數下降，而這個指數變化並沒有在公有云的價格上反映出來，所以公有云從最開始的普惠基礎設施，發展到今天變成了一個殺豬盤。它的資源租賃價格已經達到了自建單價的幾十倍上百倍，堪稱終極的成本刺客。</p><p>這也引發了一些新的變化，比如説馬斯克的 X（Twitter）、DHH 的 37Signals，算了賬單之後，明智地選擇了從雲上搬遷下來，節約了每年上千萬甚至上億的成本。我認為，這些案例對於整個行業，都是非常具有借鑑意義的里程碑標誌。</p><p>所以，<strong>我認為雲的適用光譜就是三件事——小規模，高彈性，全球化。不在這三個場景之內的業務，你選擇留在雲上，就是在為幾倍幾十倍的溢價交智商税、被割韭菜。</strong></p><p>&nbsp;</p><p><strong>正方：周新宇 speaking ——</strong></p><p>我覺得這裏面有一個誤區，<strong>不能拿這個硬件的成本去跟軟件、甚至跟雲服務對比。</strong>比如説馮總以前寫過一篇文章，就是拿本地盤跟 EBS 價格做對比。實際上我認為 EBS 它本身是一個軟件服務，它背後是一整套的完整的分佈式系統，雲服務已經提供了至少三個九的可用性。但本地盤它是硬件，它的故障概率是比較高的，不同的廠商，年化的故障率可能都有差異，有些可能甚至高達 5% 左右。任何硬件壞了都可能導致無法訪問這個本地盤的數據，但在雲上，ECS 也好 EBS 也好，它們都是軟件，你可以理解為它們就是存算分離的。從應用角度來看，ECS、EBS 都是無狀態的，EBS 還解決了一個多副本問題。</p><p>如果今天要用本地盤，肯定得主副本，那數據的複製帶來的網絡帶寬消耗、計算資源消耗、存儲空間消耗，都需要考慮到成本里面。另外，EBS 它後面是一個大規模的存儲節點區域，是能夠應對大量磁盤故障的，也能夠解決這個數據完整性問題。如果真的要拿 EBS 跟本地盤去對比的話，我覺得至少得讓用户去自建一套分佈式存儲系統，跟使用 EBS 做對比，還得把運維的人力成本也考慮進去。這些在自建、規模比較小的情況下，是很難算清楚的。</p><p>&nbsp;</p><p><strong>反方：馮若航 speaking ——</strong></p><p><strong>上雲的成本比自建要高得多。</strong>我自己 15 年的時候在淘寶的 CNZZ，友盟+這個部門算是第一波被推上阿里雲的內部 BU。在上雲之前，我們有一個自己的機房，幾百台服務器，一年所有成本算進去 1000 萬。後來上了阿里雲大數據全家桶數據庫 ODPS 這些東西，每年計算 3000 萬存儲 4000 萬。從 1000 萬變成 7000 萬這件事直接給了我對雲的第一印象，因為阿里雲是手把手出工程師加入我們團隊幫我們改造業務搬上雲的，從原來的每年 1000 萬搬到了後來的每年 7000 萬，而乾的事情，本質上卻還是一模一樣的，都是統計和計算規模，也沒有出現特別的變化。在上完雲之後，我們的效能並沒有出現變化，但是成本卻是實打實地翻了七倍。</p><p>這是我自己親身經歷的一個案例。如果説更有共性的一件事，我覺得可以參考一下 Amazon。AWS 在 2013 年提出的公有云價值，他舉了六個點：彈性、敏捷、全球化出海、將資本支出轉變為運營支出，以及更低的成本、消除重複建設。</p><p>但是，<strong>這些公有云價值主張在 2023 年很多已經不成立了，</strong>甚至説很多已經沒有價值了。我認為還有價值的點就是彈性、agility 和全球化出海，但是這裏面覆蓋的光譜其實並不多，特別是在高價值用户羣體裏面並沒有覆蓋那麼多，更多是小微初創小規模業務會用到這些點。</p><p>比如這個 CAPEX 轉為 OPEX，將資本支出轉為運營支出。這一點，我認為除了對於那種連六個月都活不過的小業務有價值之外，凡是超過六個月，買肯定比租合算了。lower cost 是 AWS 當初相對於這些企業級解決方案來説的，它更便宜。比如説 Oracle 一盒 1 月你要付一萬塊錢，那麼 AWS 上的 RDS 每個月只要 1000 塊錢，是不是很便宜？但是那個時候，你可以説只有我這一家有云，所以我可以用這個價值定價，但現在誰家沒有一個 RDS ？開源的 RDS 管控都出來了。那麼這就變成了成本定價。既然是成本定價，我用雲數據庫加硬件，用這種開源的方案加上硬件 20 塊錢一盒，1 月不比這 1000 塊錢或者 400 塊錢的 RDS 要香嗎？lower cost 這個事兒已經完全變味兒了，現在不是 lower cost 是 higher cost。</p><p>至於消除重複建設這個事，我認為現在開源幹得已經比這好了，各家都有自己的 EC2 VPS，但是 K8s 很明顯一統了這些無狀態服務調度天下，所以我認為在 2023 年公有云的價值就剩下了全球化合規出海，它的適用光譜已經縮小到了小規模業務和高彈性業務和出海業務這三樣。以前我們業界大概有一個規模估算，你在雲上的年消費在 100 到 300 萬這個區間，你就應該考慮下雲了。我認為，隨着資源雲和開源平替的出現，100 萬-300 萬的閾值將會被進一步拉低至 10 萬-30 萬或者 1 萬-3 萬。我認為這件事很有可能會發生，而且正在發生。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>如今上雲還安全嗎？穩定性有多強？</h1><p><strong>反方：馬工 speaking ——</strong></p><p>對於安全，我有很多話説。作為一個軟件工程師最基本的是，你不能把密碼直接寫死、hard code 就編碼到你的代碼裏面，更不能把它提交到 Github 上，這屬於初級的實習生犯的錯誤對不對？</p><p>但是我看了一下，國內的騰訊雲阿里雲和華為雲什麼的，全都教用户把那個 Access ID，編碼到代碼裏面。阿里雲和騰訊雲去年已經改正了，因為我寫文章揭露他們。但是至今為止，華為雲和火山引擎上面的範例裏面還是頁編碼，Access key，這是非常不負責任的一個做法。</p><p>我為什麼説他們是一個草台班子，因為這就相當於修了一座橋，然後把橋的地基給抽掉了，或者説做了一個保險庫，但是把鑰匙給插在那個鎖上了。就這樣還談安全？</p><p>我們可以看一下更近的例子，滴滴出了事故影響了上千萬的出行，它連具體的技術原因都沒提出來，只説我們會改進、我們是一個內部系統。但這個內部系統是什麼？你怎麼改進這個系統？基礎系統是外購的，還是自研的？什麼都沒説，但是北京那個地鐵追尾，人家就成立調查組了，調查組就會有調查結論，就會有限期改正通知書，你得覆盤，你得彙報，監管部門會過來檢查，然後發通知給其他的地鐵公司，讓別人吸取他的教訓。這才是一個真正的工程行業。</p><p>我贊同周新宇説的「雲廠商的故障比自建機房的故障更令人矚目」，但是，<strong>我的機房出故障，我可以得到最全面的信息，雲廠商出故障，我得不到所有的信息，甚至他不給我信息。</strong>比如阿里雲至今也沒有披露技術細節。甚至有一些廠商，他是隱瞞故障，他不會跟你通知，而是想着偷偷修復了你就不知道了。這是一個非常讓我們擔心的問題：沒有透明度。這樣你也無法從業務上規避它，只能求它別出事了。這是非常危險的。</p><p>&nbsp;</p><p><strong>正方：周新宇 speaking ——</strong></p><p>今天雲廠商確實做得不夠好，但這也是會改進的。雲廠商在安全和數據完成這塊都有很大的投入，我們以前做一個架構，要經過很多層的安全架構評審，並不是説啥都不做。當然，雲計算這個技術也好，雲計算這種商業模式也好，它肯定是有進步空間的，不能因為當前雲廠商某些地方還不夠成熟，就完全否定上雲的優勢或者是雲計算的優勢。</p><p>&nbsp;</p><p><strong>正方：蔣明 speaking ——</strong></p><p>尤其是大規模的數據庫用户，還是上雲才能解決需求。像肯德基，阿里雲出事以後，他們就把業務遷到了抖音建的雲上，並沒有遷到自己的機房裏。</p><p>根據我的經驗，自建機房的話，如果只是一兩台機器託管一下的話，還是比較簡單的。但是當機器達到四五千台的時候，那你就會遇到 CPU 的故障、內存的故障和磁盤的故障，這時候，你就會很依賴監控系統。我有過大概 4000 多台物理機的這種機房託管經驗，當時用的是南京的管理系統，也是騰訊的開源軟件，實時監控用的是阿里的監控軟件 SLS，哪個磁盤出故障了，就發給線下的運維，讓他去換。如果全部都是自建的話，根本就做不到。</p><p>像我們現在的政務雲、水電煤背後的技術支持，全部都是在雲上的，政府的政務處理系統，銀行的交易系統也全部都在雲上，如果雲真的一無是處，那我們生活當中，支付寶就沒辦法掃了，錢也付不出去。</p><p>&nbsp;</p><p><strong>反方：馮若航 speaking ——</strong></p><p>我覺得你説的問題非常嚴峻，就是所謂的雲集中的問題。Gartner 最近發佈的 2023 年三季度新興風險報告裏面，<strong>雲集中風險已經連續第二年進入「五大新興風險」綜合榜單，在中國排第三位。</strong>雲集中説的就是雲廠商已成為了新的單點，爆炸半徑極大。阿里雲這一掛，有多少服務宕機了？如果政務雲金融雲這些都跑在阿里雲，那掛了怎麼辦？</p><p>去年阿里雲香港區域故障就導致香港政府很多單位的網站和電子政務不能用。</p><p>所以，<strong>這就是一個下雲的重要 argument ——為了安全性和自主可控。</strong>上雲其實就是放棄了自主可控，放棄了一部分的安全性。你沒有辦法對機密性、完整性去進行任何的驗證，甚至是追索。</p><p>我是搞信息安全的，安全裏面有三個點：CIA ——機密性，數據完整性和可用性。就是不丟，不壞，不宕。但是雲廠商它不給你兜機密性和完整性，它只給你兜可用性，而且是非常遜色的可用性。</p><p>比如説雲 RDS for PostgreSQL，這個雲數據庫的基礎版甚至都沒有望歸檔，也就是説它沒有數據庫 PITR 時間點恢復的能力，一個數據庫服務竟然沒有基礎的時間點恢復能力，我認為這對於一個數據庫用户來説是完全不可接受的。至於機密性，那就更沒法保證了，你甚至沒有辦法去驗證發現任何數據丟失。但要是自建機房，就不會存在這樣的風險。</p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>中小企業該怎麼選？</h1><p><strong>正方：周新宇 speaking ——</strong></p><p>如果是一家初創企業，那肯定是毫無疑問要上雲，第一天就應該把你的 IT 設施構建在雲上，這樣未來的業務創新或試錯成本都非常低。這是，如果你的企業已經在重度用雲，今天因為成本的問題在考慮是否下雲，那我覺得是要慎重的，因為不管是上雲還是下雲，折騰一次代價是比較大的。所以説更好的方式是去分析雲上的賬單，這裏相對於自建有很大的優勢：在雲上你的一切價格賬單都是透明的，到底貴在哪裏，可以針對性地去降本。</p><p>&nbsp;</p><p><strong>正方：蔣明 speaking ——</strong></p><p>可以用阿里雲、騰訊雲、AWS 的基礎建設能力，比如 ECS 或 OSS，加上第三方的開源軟件，比如 TiDB、AutoMQ，這些軟件，它價格便宜，又能用雲廠商最便宜的基礎能力構建一個企業的自動化 DevOps 系統，讓你用最低的成本，在雲上創業。至於後面企業大了，像馬斯克的 X 公司，那自建雲是最佳的選擇，畢竟成本會更低。</p><p>&nbsp;</p><p><strong>反方：馮若航 speaking ——</strong></p><p>從務實的角度來講，小企業其實是適合雲的，但是你也不要把所有的東西都深度依賴雲。</p><p>第一，你有自建能力，這是你跟雲廠商談價格折扣的最大籌碼！</p><p>第二，優先使用資源雲。什麼是資源雲？像租用它的虛擬機，儘可能的避免使用它的專有服務、被供應商鎖定。</p><p>第三，如果你在雲上非要用這些服務，請避免使用 AKSKIAM 這些讓你陷入供應商鎖定的東西。這些不僅會讓你陷入雲單點故障中，更是會把你綁在一個你下不來的賬單下。</p><p>&nbsp;</p><p><strong>反方：馬工 speaking ——</strong></p><p>我覺得雲是一個操作系統，你用雲就相當於從 Windows 系統切換到 Linux，這需要非常大的努力，需要一個範式轉移。這個轉移路上，你必須要有人帶着你走。但我目前看雲自己也不知道怎麼走。這有一個大膽的估測：</p><p>90% 的雲廠商的員工，沒有自己的雲賬號；</p><p>90% 的雲廠商的員工，沒有考過雲的認證；</p><p>90% 的雲廠商的員工，從來沒有在雲上維護過或者部署過一個生產系統。</p><p>我覺得大家還是謹慎一點，除非雲廠商能夠證明雲計算的價值點，然後給出一個很明確的路徑，不然的話你就不要那麼急躁地為了雲而云。另外，騰訊會議或者釘釘那不是雲，跟微信一樣，只是一個很普通的 Saas 系統，這個跟你要負責任的企業 IT 系統是完全不一樣的。</p><p>&nbsp;</p><p>大家對此怎麼看呢？快留言説説你的經驗吧~</p><p>&nbsp;</p><p>直播回放如下，錯過的趕緊掃碼看看回放吧↓↓↓</p><p style="text-align:center"><img height="255" src="https://oscimg.oschina.net/oscnet/up-0da327351049eec05882b4fa1fb0a6df839.png" width="257" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10398475</guid>
            <link>https://my.oschina.net/u/6852546/blog/10398475</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中國網絡安全審查認證和市場監管大數據中心正式掛牌]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 25 日，中國網絡安全審查認證和市場監管大數據中心（下稱網數中心）正式掛牌成立。</p><blockquote><p>根據中央編辦批覆，中國網絡安全審查技術與認證中心更名為中國網絡安全審查認證和市場監管大數據中心，整建制劃入市場監管總局信息中心，同時劃入競爭政策與大數據中心部分職能。主要職責是承擔網絡安全審查與認證相關標準研究和技術支撐、市場監管信息化建設、大數據分析應用、智慧監管建設等工作。</p></blockquote><p><img alt="" height="324" src="https://oscimg.oschina.net/oscnet/up-b50e4470001eac5b4504facfa10718e4195.jpg" width="500" referrerpolicy="no-referrer"></p><p>具體來説，網數中心的主要職責是：</p><p>依據《網絡安全法》《數據安全法》《個人信息保護法》《網絡安全審查辦法》及國家有關強制性產品認證法律法規，承擔網絡安全審查技術與方法研究、網絡安全審查技術支撐工作；在批准範圍內開展與網絡安全相關的產品、管理體系、服務、人員認證和培訓、檢驗檢測等工作；參與研究擬訂市場監管信息化發展規劃，協助指導全國市場監管系統信息化建設、管理和應用推廣工作；承擔市場監管業務應用系統和總局政務信息系統建設、運維及技術保障工作；承擔市場監管行業標準組織協調工作，承擔全國統一的市場監管信息化標準體系的建立完善工作；負責市場監管大數據中心建設、管理和運行維護工作，支撐智慧監管建設；受委託承擔市場監測技術支撐工作；開展網絡安全認證、市場監管信息化與大數據分析應用、智慧監管等領域的國際合作與交流。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272732</guid>
            <link>https://www.oschina.net/news/272732</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟 Bing Chat 接入 GPT-4 Turbo 模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowslatest.com%2F2023%2F12%2F25%2Fmicrosoft-bing-chat-gets-chatgpt-4-turbo-for-free-code-interpreter-big-upgrade-ahead%2F" target="_blank">根據&nbsp;Windows Latest&nbsp;的報道</a></u>，微軟現已將 GPT-4 Turbo 模型接入 Bing Chat，並向部分用户免費開放。</p><p>GPT-4 Turbo 模型是 OpenAI 在 11 月的開發者大會上公佈的最新模型，能力相比 GPT-4 更加強大。正常來説，該模型需要付費使用，<strong>但被選中的 Bing Chat 測試用户可以免費體驗該模型的能力</strong>。微軟表示，測試用户的選擇完全隨機，微軟稱之為稱之為「A / B」測試。</p><p>因此能否通過必應聊天使用 GPT-4 Turbo 完全憑運氣，但微軟已確認計劃在未來幾周內擴大推廣範圍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1fe3a67b4f285f9fe3161322aa93bb4efc4.png" referrerpolicy="no-referrer"></p><p>微軟還計劃升級代碼解釋器功能，使其與 OpenAI 的功能保持一致。這意味着微軟 Copilot 中的代碼解釋器很快就能處理更復雜的編程或數據問題。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272729/bing-chat-gets-chatgpt-4-turbo</guid>
            <link>https://www.oschina.net/news/272729/bing-chat-gets-chatgpt-4-turbo</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openKylin 榮譽+1！榮獲人民網【人民企業社會責任獎「年度案例獎」】]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>12 月 21 日，由人民日報社指導、人民網主辦的 2023 人民企業社會責任榮譽盛典暨第 18 屆人民企業社會責任獎頒獎活動在京順利舉辦，<strong>開放麒麟（openKylin）1.0 憑藉在開源創新領域的突出貢獻，榮獲人民企業社會責任獎年度案例獎。</strong></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-fba19d23cce6b40aadd0f4220d261f5d981.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:justify"><span>「人民企業社會責任獎」評選活動創設於 2006 年，是中央重點新聞網站在企業社會責任領域最早發起的活動之一。本次活動以「權威性、大眾化、公信力」為宗旨，以「勇毅實幹&nbsp;共向未來」為主題，設置了「年度企業獎」「年度案例獎」「鄉村振興獎」「綠色發展獎」「築夢未來獎」和「特別貢獻獎」六大獎項。分別從企業履責、公益行動、鄉村振興、綠色發展、兒童事業、共建「一帶一路」等維度徵集企業履行社會責任的實踐案例。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span>其中，「年度案例獎」重點關注 2023 年度企業、機構策劃並開展實施的具有深刻影響力的社會責任行動案例。與<span>開放麒麟（openKylin）1.0 一同入圍的<span><span>獲獎案例</span></span>還有：天貓黃扶手計劃「觀·愛」行動、安踏茁壯成長公益計劃、<span><span>亞馬遜雲科技「AI 在未來」公益計劃</span></span>等。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>今年 7 月 5 日，開放麒麟（openKylin）1.0 正式發佈，標誌着我國擁有了操作系統組件自主選型、操作系統獨立構建的能力，填補了我國在這一領域的空白。作為國內開源操作系統根社區，開放麒麟（openKylin）社區自成立起便積極推動開源生態建設。截至目前，openKylin 已累計發佈 6 個社區版本，下載量達 100 萬+；匯聚 400+社區會員、5500+開發者加入社區，並累計成立 94 個 SIG 組開展技術研究與創新。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>未來，開放麒麟（openKylin）社區也將保持初心，為構建良好開源生態發展持續努力，並攜手各界夥伴共築開源生態，用持續的技術創新和更加活躍的社區運營推動我國開源產業快速發展。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272719</guid>
            <link>https://www.oschina.net/news/272719</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LobeChat —— 聊天機器人框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LobeChat 是一個開源、高性能的聊天機器人框架，支持語音合成、多模態和可擴展的功能調用插件系統。支持一鍵式免費部署私人 ChatGPT/LLM 網絡應用程序。</p><p><img height="190" src="https://static.oschina.net/uploads/space/2023/1218/154744_PdXB_4252687.png" width="500" referrerpolicy="no-referrer"></p><p>特性一覽：</p><h4 style="text-align:start">GPT 視覺認知</h4><p><img height="192" src="https://static.oschina.net/uploads/space/2023/1218/154508_TIgb_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#1f2328; text-align:start">LobeChat 已經支持 OpenAI 最新的<span>&nbsp;</span><a href="https://platform.openai.com/docs/guides/vision"><code>gpt-4-vision</code></a><span>&nbsp;</span>支持視覺識別的模型，這是一個具備視覺識別能力的多模態智能。 用户可以輕鬆上傳圖片或者拖拽圖片到對話框中，助手將能夠識別圖片內容，並在此基礎上進行智能對話，構建更智能、更多元化的聊天場景。</p><p style="color:#1f2328; text-align:start">這一特性打開了新的互動方式，使得交流不再侷限於文字，而是可以涵蓋豐富的視覺元素。無論是日常使用中的圖片分享，還是在特定行業內的圖像解讀，助手都能提供出色的對話體驗。</p><h4 style="text-align:start">TTS &amp; STT 語音會話</h4><p><img height="194" src="https://static.oschina.net/uploads/space/2023/1218/154539_jFKr_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#1f2328; text-align:start">LobeChat 支持文字轉語音（Text-to-Speech，TTS）和語音轉文字（Speech-to-Text，STT）技術，能夠將文本信息轉化為清晰的語音輸出，用户可以像與真人交談一樣與我們的對話代理進行交流。 用户可以從多種聲音中選擇，給助手搭配合適的音源。 同時，對於那些傾向於聽覺學習或者想要在忙碌中獲取信息的用户來説，TTS 提供了一個極佳的解決方案。</p><p style="color:#1f2328; text-align:start">在 LobeChat 中，項目團隊精心挑選了一系列高品質的聲音選項 (OpenAI Audio, Microsoft Edge Speech)，以滿足不同地域和文化背景用户的需求。用户可以根據個人喜好或者特定場景來選擇合適的語音，從而獲得個性化的交流體驗。</p><h4 style="text-align:start">Function Calling 插件系統</h4><p style="color:#1f2328; text-align:start">LobeChat 的插件生態系統是其核心功能的重要擴展，它極大地增強了 ChatGPT 的實用性和靈活性。通過利用插件，ChatGPT 能夠實現實時信息的獲取和處理，例如自動獲取最新新聞頭條，為用户提供即時且相關的資訊。 此外，這些插件不僅侷限於新聞聚合，還可以擴展到其他實用的功能，如快速檢索文檔、獲取電商平台數據、以及其他各式各樣的第三方服務。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/lobechat</guid>
            <link>https://www.oschina.net/p/lobechat</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 跨平台的截圖/錄屏/錄音/錄像軟件 pear-rec]]>
            </title>
            <description>
                <![CDATA[<p align="center"><img src="https://027xiguapi.github.io/pear-rec/logo.png" height="120" referrerpolicy="no-referrer"></p><h1><a id="user-content-pear-rec" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#pear-rec"></a>pear-rec</h1><p><img src="https://img.shields.io/github/stars/027xiguapi/pear-rec" alt="stars" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/react-v18-blue" alt="react" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/electron-v26-blue" alt="react" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/express-v4-blue" alt="react" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/-TypeScript-blue?logo=typescript&amp;logoColor=white" alt="typescript" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/-Vite-646cff?logo=vite&amp;logoColor=white" alt="vite" referrerpolicy="no-referrer"></p><hr><h2><a id="user-content-readme" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#readme"></a>README</h2><p><a href="https://gitee.com/xiguapi027/pear-rec/blob/main/README.zh-CN.md">中文</a> | <a href="https://gitee.com/xiguapi027/pear-rec/blob/main/README.md">English</a> | <a href="https://gitee.com/xiguapi027/pear-rec/blob/main/README.de-DE.md">Deutsch</a></p><h2><a id="user-content-架構" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E6%9E%B6%E6%9E%84"></a>架構</h2><img src="https://027xiguapi.github.io/pear-rec/imgs/1700442414996.jpg" referrerpolicy="no-referrer"><h2><a id="user-content-簡介" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E7%AE%80%E4%BB%8B"></a>簡介</h2><blockquote><p>pear-rec(梨子 rec) 是一個跨平台的截圖、錄屏、錄音、錄像、錄製 (動圖)gif、查看圖片、查看視頻、查看音頻和修改圖片的軟件。</p><p>pear-rec(pear rec) 是基於 react + electron + vite + viewerjs + plyr + aplayer + react-screenshots + tui-image-editor + gif.js 的一個項目。</p><p>更多功能和 api 可以查看<a href="https://gitee.com/link?target=https%3A%2F%2F027xiguapi.github.io%2Fpear-rec">官網 (https://027xiguapi.github.io/pear-rec)</a> 或 <a href="https://xiguapi027.gitee.io/pear-rec" rel="nofollow">https://xiguapi027.gitee.io/pear-rec</a></p></blockquote><h2><a id="user-content-例子" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E4%BE%8B%E5%AD%90"></a>例子</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fpear-rec-xiguapi.vercel.app%2F">網頁</a></p><h2><a id="user-content-下載地址" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80"></a>下載地址</h2><blockquote><p>gitee: <a href="https://gitee.com/xiguapi027/pear-rec">https://gitee.com/xiguapi027/pear-rec</a></p><p>github: <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2F027xiguapi%2Fpear-rec">https://github.com/027xiguapi/pear-rec</a></p></blockquote><h2><a id="user-content-源碼運行編譯" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E6%BA%90%E7%A0%81%E8%BF%90%E8%A1%8C%E7%BC%96%E8%AF%91"></a>源碼運行&amp;編譯</h2><p>編譯需要<code>nodejs</code>和<code>pnpm</code>環境</p><h3><a id="user-content-測試環境" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83"></a>測試環境</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">nodejs: 18</span><span id="LC2" class="line">pnpm: 8</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-開始" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%BC%80%E5%A7%8B"></a>開始</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c"># 拷貝代碼</span></span><span id="LC2" class="line">git clone https://gitee.com/xiguapi027/pear-rec.git</span><span id="LC3" class="line"><span class="c"># 進入項目</span></span><span id="LC4" class="line"><span class="nb">cd </span>pear-rec</span><span id="LC5" class="line"><span class="c"># 安裝依賴</span></span><span id="LC6" class="line">pnpm <span class="nb">install</span></span><span id="LC7" class="line"><span class="c"># 調試頁面</span></span><span id="LC8" class="line">pnpm run dev:web</span><span id="LC9" class="line"><span class="c"># 調試服務</span></span><span id="LC10" class="line">pnpm run dev:server</span><span id="LC11" class="line"><span class="c"># 調試軟件</span></span><span id="LC12" class="line">pnpm run dev:desktop</span><span id="LC13" class="line"><span class="c"># 運行頁面</span></span><span id="LC14" class="line">pnpm run start:web</span><span id="LC15" class="line"><span class="c"># 運行軟件</span></span><span id="LC16" class="line">pnpm run start:desktop</span><span id="LC17" class="line"><span class="c"># 編譯軟件</span></span><span id="LC18" class="line">pnpm run build:desktop</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-功能" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%8A%9F%E8%83%BD"></a>功能</h2><p>已經勾選的功能是開發過程最新功能，但可能還沒發佈在最新版本</p><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 截屏 (react-screenshots)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 框選裁切</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 框選大小位置可調整</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 取色器</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 放大鏡</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 畫筆（自由畫筆）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 幾何形狀（邊框填充支持調節）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 高級畫板設置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 圖像濾鏡（支持局部馬賽克模糊和色彩調節）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 自定義框選鬆開後的操作</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 以圖搜圖</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 掃描二維碼</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 快速截取全屏到剪貼板或自定義的目錄</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 截屏歷史記錄</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 窗口和控件選擇（使用 OpenCV 邊緣識別）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 長截屏</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 多屏幕</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 錄屏 (WebRTC)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 錄製全屏</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 截圖</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 自定義大小</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 靜音</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 按鍵提示</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 光標位置提示</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 錄製欄</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 流寫入</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 錄音 (WebRTC)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 錄音設置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 查看錄音</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 下載錄音</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 編輯錄音</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 錄像
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 自定義比特率</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 圖片預覽 (viewerjs)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 放大</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 縮小</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 拖拽</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 翻轉</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 釘上層</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 查看</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 下載</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 打印</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> ocr</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 查看列表</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 以圖搜圖</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 掃描二維碼</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 圖片編輯 (tui-image-editor)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 視頻預覽 (plyr)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 音頻預覽 (aplayer)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 動圖 (gif) 編輯 (gif.js)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 基本設置
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 用户 uuid</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 保存地址</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 開機自啓動</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 國際化 (中、英、德)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 服務設置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 快捷鍵設置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 重置設置</li></ul></li></ul><h2><a id="user-content-國際化 i18n" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%9B%BD%E9%99%85%E5%8C%96i18n"></a>國際化 (I18n)</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 簡體中文</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 英語</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 德語</li></ul><h2><a id="user-content-download" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#download"></a>Download</h2><table><thead><tr><th>系統</th><th>Windows</th><th>Linux</th><th>Macos</th></tr></thead><tbody><tr><td>鏈接</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2F027xiguapi%2Fpear-rec%2Freleases">下載</a></td><td>◯</td><td>◯</td></tr></tbody></table><p>國內可以用 <a href="https://gitee.com/link?target=https%3A%2F%2Fghproxy.com%2F">GitHub Proxy</a> 加速下載</p><h2><a id="user-content-反饋和交流" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%8F%8D%E9%A6%88%E5%92%8C%E4%BA%A4%E6%B5%81"></a>反饋和交流</h2><p>我們推薦使用 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2F027xiguapi%2Fpear-rec%2Fissues">issue</a> 列表進行最直接有效的反饋，也可以下面的方式</p><ul><li>qq 羣</li></ul><p align="center"><img src="https://027xiguapi.github.io/pear-rec/imgs/pear-rec_qq_qrcode.png" referrerpolicy="no-referrer"></p><h2><a id="user-content-開源協議" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE"></a>開源協議</h2><p><a href="https://gitee.com/xiguapi027/pear-rec/blob/main/LICENSE">pear-rec(梨子 rec) 可在 Apache License V2 下使用。</a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FMDN%2FCommunity%2FOpen_source_etiquette">開源項目禮節</a></p>]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 01:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/xiguapi027/pear-rec</guid>
            <link>https://gitee.com/xiguapi027/pear-rec</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 揭開事件循環的神秘面紗]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-f9d098f5cee0090732c3958edc97164b6c7.png" alt="" referrerpolicy="no-referrer"></p><p>作者 |&nbsp;小萱</p><blockquote><p>導讀&nbsp;</p><p>這篇文章會全方位講解事件循環機制，從這篇文章你可以學到，「事件循環」和「瀏覽器渲染」的關係，瀏覽器 setTimeout、requestAnimationFrame（RAF）、requestIdleCallback（RIC）等 API 在事件循環的「執行時機」，導致瀏覽器卡頓的原因、交互指標是如何測量的以及如何提升網站的交互性能。</p></blockquote><blockquote><p><em>全文 10503 字，預計閲讀時間 27 分鐘。</em></p></blockquote><h1><strong>01 前言</strong></h1><p>我們常常會提到頁面性能，為什麼要優化長任務，又為什麼 React 要做時間切片呢。這篇文章把瀏覽器的渲染、事件循環與頁面性能串聯起來。</p><p>從這篇文章你可以學到，「事件循環」和「瀏覽器渲染」的關係，瀏覽器 setTimeout、</p><p>requestAnimationFrame（RAF）、requestIdleCallback（RIC）等 API 在事件循環的「執行時機」，導致瀏覽器卡頓的原因、交互指標是如何測量的以及如何提升網站的交互性能。</p><p>學完這些，你可以對為什麼動畫要用 RAF、又何時去用 RIC、該不該選擇 setTimeout、如何規避長任務之類的問題應對自如。</p><h1><strong>02 事件循環概述</strong></h1><h2><strong>2.1 為什麼要了解事件循環？</strong></h2><p>深入瞭解事件循環是性能優化的基礎。在討論事件循環之前，我們需要先了解瀏覽器的多進程和多線程架構。</p><h2><strong>2.2 瀏覽器的架構</strong></h2><p>回顧瀏覽器的架構，現代瀏覽器都是多進程和多線程的。</p><h3><strong>2.2.1 多進程</strong></h3><p>Chrome 瀏覽器使用多進程架構，意味着每個標籤頁（在某些瀏覽器中也包括每個擴展程序）通常在其自己的進程中運行。這樣做的好處是，一個標籤頁崩潰不會影響到其他標籤頁。</p><p>站點隔離特性，瀏覽器每個 tab，都是獨立的渲染進程，這點的好處是假設你打開三個標籤頁，一個標籤卡死不影響其他兩個。但如果三個標籤共用一個進程，一個卡死會導致全部都卡，這樣體驗很差。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ea0fa24c2b466fa5d6ee4b2d3f43537fb03.png" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△瀏覽器的多進程示意圖</strong></strong></p><h3><strong>2.2.2 多線程</strong></h3><p>每個瀏覽器進程都可以包含多個線程。例如，主線程用於執行 JavaScript 代碼和處理頁面佈局，而其他線程可能用於網絡請求、渲染等任務。</p><p><strong>主線程</strong></p><p>Web 應用程序需要在此單個主線程上執行某些關鍵操作。當您導航到 Web 應用程序時，瀏覽器將創建並向您的應用程序授予該線程，以便您的代碼在其上執行。</p><p>主線程指的是渲染進程下的主線程，負責解析 HTML、計算 CSS 樣式、執行 JavaScript、計算佈局、繪製圖層等任務。</p><p><img src="https://oscimg.oschina.net/oscnet/up-835102f787ff8cc334c66e30face4316758.png" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△主進程即渲染進程包含的線程圖</strong></strong></p><p>某些任務<strong>必須</strong> 在主線程上運行。例如，任何直接需要訪問 DOM（即 DOM ﻿document﻿）的操作都必須在主線程上運行（因為 DOM 不是線程安全的）。這將包括大多數 UI 相關代碼。</p><p>主線程上一次只能運行 <strong>一個任務</strong>。</p><p>此外，一個任務<strong>必須在主線程上運行完成</strong>，然後才能運行另一個任務。瀏覽器沒有「部分」執行任務的機制，每個任務都完整地運行直至完成。</p><p>在下面的示例中，在瀏覽器展示界面的時候，按順序運行下面的任務，並且每個任務都在主線程上完成：</p><p><img src="https://oscimg.oschina.net/oscnet/up-b89c629a6370f9eaf9aeae593adc5bc8d21.png" alt="圖片" referrerpolicy="no-referrer"></p><h1><strong>03 事件循環的具體流程</strong></h1><p>我們這裏主要討論的是&nbsp;window event loop。也就是瀏覽器一個渲染進程內主線程所控制的&nbsp;Event Loop。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7597949bda55e109f8b7f0eef42bde61edd.png" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△發生一次事件循環的具體流程</strong></strong></p><p>發生一次事件循環，也就是瀏覽器一幀中可以用於執行﻿JS﻿的流程如下：</p><p>從 task queue 取出一個 task(宏任務) 執行並刪除 &nbsp;-&gt; 執行並清空隊列中全部 job(微任務) -&gt; requestAnimationFrame -- 瀏覽器更新渲染 -- requestIdleCallback</p><p><strong>3.1 更新渲染的步驟</strong></p><p>前兩個步驟，耳熟能詳，這裏不再討論，重點討論「更新渲染」之後的步驟。</p><p>1. Rendering opportunities: 標誌是否一次事件循環後會發生渲染。在每次事件循環的結束，不一定會發生渲染。導致不渲染的可能：無法維持當前刷新率、瀏覽器上下文不可見、瀏覽器判斷更新不會造成視覺改變並且 raf 的回調為空。</p><p>如果這些條件都不滿足，當前文檔不為空，設置 hasARenderingOpportunity 為 true。</p><p>2.如果窗口變化，執行 resize。</p><p>3.如果滾動，執行 scroll。</p><p>4.媒體查詢。</p><p>5.canvas 。</p><p>6.執行 RAF 回掉，傳遞迴掉參數 DOMHighResTimeStamp，開始執行回調的時間。</p><p>7.重新執行 Layout 等計算，渲染繪製界面。</p><p>8.如果滿足，任務隊列和微任務隊列都為空，並且渲染時機 hasARenderingOpportunity 為 false，執行算法是否執行 requestIdleCallback 的回調函數。</p><p><strong>3.2</strong><strong>執行順序與渲染</strong></p><p>來一道簡單的題目，將創建宏任務、微任務、RIC、RAF 的代碼同時定義，輸出執行順序。</p><pre><code>console.log('開始執行');
console.log('start');
setTimeout(() =&gt; {
  console.log('setTimeout');
}, 0);

requestAnimationFrame(() =&gt; {
  console.log('requestAnimationFrame');
});
new Promise((resolve, reject) =&gt; {
  console.log('Promise');
  resolve('promise resolved');
})

requestIdleCallback(() =&gt; {
  console.log('requestIdleCallback');
});

(async function asyncFunction() {
  console.log(await 'asyncFunction');
})();

console.log('執行結束');
// 開始執行
// Promise
// 執行結束
// promise resolved
// asyncFunction
// setTimeout
// requestAnimationFrame
// requestIdleCallback
</code></pre><p>你可能會疑問為什麼 RAF 會在 setTimeout(fn, 0) 之前執行，setTimeout(fn, 0) 的執行時機是延遲 0-4ms，RAF 可以粗暴理解為 settimeout(fn, Math.random() * 16.6)，因此 setTimeout 會優先。但如果在 setTimeout 執行之前主線程被其他的任務跑滿了，超過了一幀的耗時，setTimeout 會在 RAF 的回調之後執行（用例見下面的代碼段），因此 setTimeout 的延遲時間並不穩定，RAF 的執行時機穩定，在一幀內註冊的，都會在這一幀的結束，下一幀的開始之前執行。</p><pre><code>  let task = new Array(10000).fill(null).map((_, i) =&gt; () =&gt; {
    const span = document.createElement("span");
    span.innerText = i;
    console.log("==&gt;task", i);
  });
  task.forEach((i) =&gt; i());
  requestAnimationFrame(() =&gt; {
    console.log("===&gt;requestAnimationFrame");
  });
  setTimeout(() =&gt; {
    console.log("===&gt;setTimeout");
  }, 0);
  //輸出：
  // ===&gt;requestAnimationFrame
  // ===&gt;setTimeout
</code></pre><p>注意，Promise.then 的回調可以保證第一輪的準確性，如果繼續.then 發生的行為和瀏覽器版本有關，開發時不要過分依賴多.then 的回調順序，這是不可靠的。</p><p>上面提到渲染是在一次事件循環的「最後」發生，那麼對於多次「修改 dom」的操作，是會被合併取最後一次的結果作為佈局渲染。</p><pre><code>    const btn = document.querySelector(".btn");
    btn.addEventListener("click", () =&gt; {
      box.style.transform = "translateX(400px)";
      box.style.transition = "transform 1s ease-in-out";
      box.style.transform = "translateX(200px)";
    });
</code></pre><p>外層父容器 400px，這段代碼，表現是盒子從 0 到 200px，盒子設置 400px 的動作，被合併掉了。那如何實現盒子從 400px 呢，可以採取延遲到下一幀渲染。</p><p><img src="https://oscimg.oschina.net/oscnet/up-12acd27c0e4668c804c101feaff4900b941.gif" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△演示效果</strong></strong></p><pre><code>    btn.addEventListener("click", () =&gt; {
      box.style.transform = "translateX(400px)";
      requestAnimationFrame(() =&gt; {
        requestAnimationFrame(() =&gt; {
          box.style.transition = "transform 1s ease-in-out";
          box.style.transform = "translateX(200px)";
        });
      });
    });
</code></pre><p>「嵌套的 RAF」可以保證回調在下一幀執行。當然，此處用 setTimeout 也可以達到同樣的延遲效果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-aba5e3515d83ac5a4002123ffa2fe772441.gif" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△延遲後的演示效果</strong></strong></p><h1><strong>04 任務隊列與執行時機</strong></h1><p><strong>執行 JavaScript task 是在渲染之前，如果在一幀之內 JavaScript 執行時間過長就會阻塞渲染，同樣會導致丟幀、卡頓</strong>，這裏的 js 執行時間過長，就是長任務，下面會仔細介紹。</p><p>對長任務的定義：如果任務耗時<strong>超過 50ms</strong>，則認為該任務是長任務。</p><p>當我們談到長任務造成頁面卡頓時，通常指的是主線程（Main Thread）上的任務。主線程指的是渲染進程下的主線程，負責解析 HTML、計算 CSS 樣式、執行 JavaScript、計算佈局、繪製圖層等任務。當主線程上的一個任務（例如一個 JavaScript 函數）運行時間過長時，它會阻塞主線程上的其他任務，包括但不限於 UI 更新和用户交互事件的處理，從而導致頁面卡頓或不響應。</p><p><strong>JS 的執行和渲染的關係：</strong></p><p>JS 執行與 Paint 任務都發生在主線程，具體的繪製操作是交由合成線程完成，與主線程並不互斥，但是 JS 的執行時間過長，會導致 Paint 整理好的數據沒有及時提交給合成線程，因此頁面有幀沒有執行繪製，也就是掉幀。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a9ff20ab17a1d01227807dc759a9caafc2e.png" alt="圖片" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-45b704b84e7ef58a85990b189f3cefe42ce.png" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△JS 的執行和渲染的關係圖</strong></strong></p><h2><strong>4.1 為什麼不使用 setTimeout 做動畫</strong></h2><p><strong>raf 和 setTimeout 對比:</strong></p><p><em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjsfiddle.net%2Fhixuanxuan%2Fmrw6upgs%2F3%2F__%EF%BC%89" target="_blank">https://jsfiddle.net/hixuanxuan/mrw6upgs/3/__）</a></em></p><p><strong>1.不同步與顯示刷新率：</strong></p><p>瀏覽器通常以每秒 60 幀的速度刷新，大約每 16.67 毫秒刷新一次。如果你使用 setTimeout 來創建動畫，並嘗試每 16.67 毫秒運行一幀，你的代碼不會完全與瀏覽器的刷新速率同步，導致丟幀</p><p><strong>2.延遲執行：</strong></p><p>setTimeout 的延遲時間參數只是一個最小延遲時間，而不是保證執行的精確時間。如果主線程忙於其他任務，setTimeout 的回調可能會被延遲，導致丟幀</p><p><strong>3.計時器合併：</strong></p><p>瀏覽器渲染有渲染時機（Rendering opportunity），也就是瀏覽器會根據當前的瀏覽上下文判斷是否進行渲染，因為考慮到硬件的刷新頻率限制、頁面性能以及頁面是否存在後台等等因素，宏任務之間不一定會伴隨着瀏覽器繪製。如果兩個 Task 距離的很近，他們可能會被合併在一次渲染任務，得到的結果是意料之外的，如果 Task 距離較大，那他跟不上瀏覽器的刷新頻率，會導致丟幀。</p><p>RAF 的執行時機是在下一次渲染前調用，也就是説使用這個 API 允許你在下一次渲染開始之前更改 DOM，然後在本次渲染中立即體現，因此他是製作動畫的絕佳選擇。</p><p><strong>4.2 requestIdleCallback 的執行時機</strong></p><p>主要在瀏覽器的主線程空閒時執行，為了保證響應性，會計算一個截止時間，computeDeadline，它將決定何時執行&nbsp;requestIdleCallback&nbsp;中註冊的回調。下面是計算截止時間算法的簡要概述：</p><p><strong>1.設置初始截止時間：</strong></p><p>初始化時，將事件循環的最後閒置週期開始時間設置為當前時間。</p><p>設置一個基本的截止時間，該時間是事件循環的最後閒置週期開始時間加上 50 毫秒（為了保證對新用户輸入的響應性）。為什麼要加這個 50ms，是因為瀏覽器為了提前應對一些可能會突發的用户交互操作，比如用户輸入文字。如果給的時間太長了，你的任務把主線程卡住了，那麼用户的交互就得不到迴應了。50ms 可以確保用户在無感知的延遲下得到迴應。</p><p><strong>2.檢查是否有待處理的渲染：</strong></p><p>初始化一個變量 hasPendingRenders 為 false。</p><p>遍歷相同事件循環的所有窗口，檢查每個窗口是否有未執行的 RAF 回調或可能的渲染更新。如果有，將 hasPendingRenders 設置為 true。</p><p><strong>3.基於 timeout 調整截止時間：</strong></p><p>如果 RIC 傳入第二個參數 timeout，更新截止時間為 timeout。這會強制瀏覽器不管多忙，都在超過這個時間之後去執行 rIC 的回調函數。</p><p><strong>4.考慮渲染的時間：</strong></p><p>如果 hasPendingRenders 為 true，計算下一個渲染的截止時間，基於事件循環的最後渲染機會時間和當前的刷新率。</p><p>如果下一個渲染的截止時間早於當前設置的截止時間，那麼更新截止時間為下一個渲染的截止時間。</p><p><strong>5.返回最終的截止時間：</strong></p><p>返回計算出的截止時間，這個時間將用於確定何時執行 requestIdleCallback 中註冊的回調。</p><p><strong>6.開始空閒期：</strong></p><p>對於相同事件循環的每個窗口，執行「開始空閒期」算法，使用 computeDeadline 作為參數，確定何時執行 requestIdleCallback 中註冊的回調。</p><p>也就是説，這個&nbsp;timeRemaining()&nbsp;的計算非常動態，會根據上面這些因素去決定。</p><h2><strong>4.3 React 如何實現 Time slice，沒有使用 RIC、setTimeout 的原因是什麼</strong></h2><p>沒使用 RIC 的原因是他在部分瀏覽器表現不佳，比如 safari。</p><p>需要滿足的條件：</p><p>1.暫停 JS 執行，將主線程去執行 style、layout、paint 等任務，讓瀏覽器有機會更新頁面。</p><p>2.在未來某個時刻可以繼續調度任務，執行上次還沒有完成的任務。</p><p>對於 react 的 Time Slice，他的目的是中斷當前 js 的執行，讓他去執行渲染相關任務，因此需要的 API 是在瀏覽器的 Paint 之後執行，瀏覽器並未提供除了 RIC 這樣的 API。RAF 的執行時機是在一幀的結束，此時創建宏任務開啓下一輪 Task，渲染的任務放在 RAF 裏在這一幀執行。如果使用 setTimeout(fn, 0) 創建宏任務，如果 timeout 嵌套的層級超過了 5 層，最低會有 4ms 的延遲，具體定義的代碼可以參考<strong>chrome 對計時器的定義</strong><em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchromium.googlesource.com%2Fchromium%2Fblink%2F%2B%2Fmaster%2FSource%2Fcore%2Fframe%2FDOMTimer.cpp%EF%BC%89" target="_blank">https://chromium.googlesource.com/chromium/blink/+/master/Source/core/frame/DOMTimer.cpp）</a></em>，因此首選的是 message channel，優先級高於 setTimeout 可以在上一幀渲染結束後立即執行，這樣就實現了<strong>可以中斷的 JS 執行的效果</strong>。</p><h2><strong>4.4 模擬實現 requestIdecallback</strong></h2><p>要模擬實現 requestIdecallback 的效果，定義的任務隊列在瀏覽器完成渲染任務之後執行，擴展來説也可以用來測量瀏覽器渲染任務的執行時間。</p><p><strong>Background Tasks API - Web API 接口參考 | MDN</strong>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FAPI%2FBackground_Tasks_API%EF%BC%89" target="_blank">https://developer.mozilla.org/zh-CN/docs/Web/API/Background_Tasks_API）</a></p><pre><code>  // 當到時間了，立即執行的函數
  const performWorkUntilDeadline = () =&gt; {
    if (scheduledHostCallback !== null) {
      const currentTime = getCurrentTime();
      // 分配任務的剩餘時間，這個可執行時間是根據 fps 動態算的
      deadline = currentTime + yieldInterval;
      const hasTimeRemaining = true;
      // 調用已計劃的回調，並傳遞剩餘時間和當前時間。
      const hasMoreWork = scheduledHostCallback(
          hasTimeRemaining,
          currentTime,
        );
        if (!hasMoreWork) {
          isMessageLoopRunning = false;
          scheduledHostCallback = null;
        } else {
          // If there's more work, schedule the next message event at the end
          // of the preceding one.
          port.postMessage(null);
        }
    } else {
      isMessageLoopRunning = false;
    }
    // 給瀏覽器一個繪製的機會，並重置需要繪製的標誌。
    needsPaint = false;
  };
  
 
  const channel = new MessageChannel();
  const port = channel.port2;
  channel.port1.onmessage = performWorkUntilDeadline;

  requestHostCallback = function(callback) {
    scheduledHostCallback = callback;
    if (!isMessageLoopRunning) {
      isMessageLoopRunning = true;
      port.postMessage(null);
    }
  };
</code></pre><h1><strong>05 交互性能指標與優化方法</strong></h1><p>長任務對頁面的影響，帶來「卡頓」、「掉幀」等不好的體驗，常用衡量交互性能的指標有 TTI 和 FID，這些均可使用 web-vital 庫進行測量。下面展開對指標的詳細介紹。</p><h2><strong>5.1 交互性能的衡量指標</strong></h2><p>衡量交互性能的指標主要關注以下幾個方面：</p><h3><strong>5.1.1&nbsp;TTI （理想可交互時間）</strong></h3><p><strong>1.定義可交互：</strong></p><p>首先，需要明確什麼是「可交互」。一個頁面被認為是可交互的，意味着頁面的主要內容已經加載完畢，用户可以進行點擊、輸入等交互操作，而且頁面能夠快速響應。</p><p><strong>2.監測首次內容繪製 (FCP) 和 DOMContentLoaded：</strong></p><p>測量 TTI 的過程通常開始於監測首次內容繪製 (FCP) 和 DOMContentLoaded 事件。這兩個事件分別表示瀏覽器開始繪製頁面內容和 DOM 結構加載完畢的時刻。</p><p><strong>3.長任務監測：</strong></p><p>長任務是指那些執行時間超過 50 毫秒的任務。長任務通常會阻塞主線程，延遲頁面的交互可用性。通過監測長任務，可以瞭解主線程何時變得空閒。</p><p><strong>4.尋找交互窗口：</strong></p><p>為了確定 TTI，需要找到一個至少 5 秒鐘主線程空閒的窗口，且該窗口應在首次內容繪製 (FCP) 之後。在這個 5 秒空閒窗口期間，沒有長任務執行，意味着用户可以與頁面交互。一旦找到這個空閒窗口，記錄 TTI。如果未找到長任務，則 TTI 與 FCP 相同。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f839eeb20c4ce164ffb346f0ee1b8f69072.png" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△TTI 測量示意圖（源於 web.dev）</strong></strong></p><h3><strong>5.1.2&nbsp;FID（首次輸入延遲）</strong></h3><p>FID，即 First Input Delay，用於量化用户在頁面加載時首次交互的響應延遲。一個低的 FID 表示頁面是快速響應用户交互的，而一個高的 FID 表示頁面在響應用户交互時有延遲。</p><p><strong>1.事件監聽:</strong></p><p>為了計算 FID，瀏覽器需要監聽用户的交互事件，如點擊、鍵盤輸入或者觸摸事件。當用户與頁面交互時，會觸發這些事件。</p><p><strong>2.事件處理時間:</strong></p><p>當事件被觸發時，瀏覽器會計算從事件觸發到瀏覽器開始處理事件的時間。這個時間就是 FID。它包括了瀏覽器將事件放入事件隊列、事件隊列的等待時間、以及瀏覽器開始處理事件的時間。</p><p><strong>3.事件處理:</strong></p><p>一旦事件開始被處理，瀏覽器會記錄下處理開始的時間。如果頁面在處理事件時非常忙碌，或者有其他高優先級的任務，那麼事件處理可能會被延遲，這會增加 FID。</p><h3><strong>5.1.3 INP（交互到下一次繪製）</strong></h3><p>INP，即 Interaction to Next Paint，主要關注的是用户交互（如點擊、滾動或按鍵操作）到頁面響應的時間長度，具體到頁面上的某個元素的可視更新。</p><p>比起來 FID 關注的是頁面加載完成後用户<strong>首次交互</strong>，INP 關注的是<strong>所有交互的最長渲染延遲</strong>，因此 INP 不僅僅代表第一印象，可以全面評估響應情況， 使 INP 比 FID 在衡量用户交互體驗上更為可靠。</p><p>INP 將會在 2024 年 3 月取代 FID 成為標準性能指標。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3bf10348f63ae93f27266efad4b84531629.png" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△交互到繪製的時間</strong></strong></p><h2><strong>5.2 如何優化交互性能指標</strong></h2><p><strong>1、拆分任務，這是避免長任務的有效手段。</strong></p><ul><li><p>利用 performance 進行分析，找出 long task</p></li><li><p>針對 long task，進行每個步驟的任務拆分，執行優先級高的，剩下的部分利用延遲代碼執行的方法進行中斷。</p></li></ul><p>比如，有個 Input 框，當輸入的內容發生變更，需要進行大量計算/創建 dom 等耗時操作，造成輸入卡頓。因此我們需要在用户「嘗試發生互動」的時候，「退讓主線程」。</p><pre><code>// 通過 Promise 實現中斷後繼續執行，setTimeout 調用來延遲任務
function yieldToMain () {
  return new Promise(resolve =&gt; {
    setTimeout(resolve, 0);
  });
}
    async function saveSettings(tasks) {
      let deadline = performance.now() + 50;

      while (tasks.length &gt; 0) {
        // 判斷當前是否有用户交互，isInputPending Chrome87+支持。
        // 可以採用判斷 Expire Time 達到類似效果
        if (
          navigator.scheduling?.isInputPending() ||
          performance.now() &gt;= deadline
        ) {
         // 如果有，退讓主線程，等主線程任務完成再回來繼續執行。
          await yieldToMain();
          deadline = performance.now() + 50;
          continue;
        }
        const task = tasks.shift();
        task();
      }
    }

    const performLongTask = () =&gt; {
       // 創建耗時的任務
      let task = new Array(10000).fill(null).map((_, i) =&gt; () =&gt; {
        const span = document.createElement("span");
        span.innerText = i;
      });
      saveSettings(task); // 任務切片
    };
    input.addEventListener("input", (e) =&gt; {
      input.value = e.target.value;
      performLongTask();
    });
</code></pre><p>2、非關鍵模塊，延遲執行。對於點擊率不高、非核心模塊等，採取 dynamic import 的方式，用到了再加載，或是延遲到一定時間後再加載，減少首次主線程所需要執行的任務。</p><p>3、對於視口內不可見的內容，延遲加載。</p><ul><li><p>圖片的延遲加載。</p></li><li><p>為 img 標籤 loading 設為 lazy，延遲加載資源，直到資源達到與視口的計算距離，Chrome77+支持。</p></li><li><p>利用 IntersectionObserver 監測圖片是否在可視區域，再進行渲染。推薦使用<strong>lazy-load-image-component</strong><em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2Freact-lazy-load-image-component%EF%BC%89" target="_blank">https://www.npmjs.com/package/react-lazy-load-image-component）</a></em> 等庫。</p></li><li><p>減少大量 dom 的渲染。使用 content-visibility 延遲渲染屏幕外元素，Chrome85+支持。</p></li></ul><p>4、靈活的緩存策略。</p><ul><li>用 service-worker 跨站資源共享。</li></ul><p>除了資源可以採取強緩存+協商緩存配合的方式，用 service-worker 實現更為靈活的緩存策略。比如站點 a 和站點 b 僅滿足同源，技術棧渲染方式都完全不同，如何實現在訪問 a 的時候可以預取 b 的資源。站點 a 空閒的時候註冊 service-worker，訪問站點 b 即可從 cache 裏讀取緩存，提升加載速度。sw 不僅在緩存方面表現優秀，也可以幫我們實現離線應用，以及無法被瀏覽器強緩存的文件手動添加緩存（不同瀏覽器對可以強緩存的文件的體積限制不同）。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6d991b243783e8ba64b09daeb68baf2d6b8.png" alt="圖片" referrerpolicy="no-referrer"></p><p><strong><strong>△使用 sw 做跨站資源預取</strong></strong></p><h1><strong>06 總結</strong></h1><p>1.瀏覽器是多進程和多線程的，通常説主線程指的是渲染進程下的主線程。</p><p>2.主線程上一次只能運行一個任務，瀏覽器的繪製和主線程並不互斥，但長任務會導致延遲進入合成，甚至在這一幀不發生合成也就是掉幀。</p><p>3.在每次事件循環的結束，不一定會發生渲染。setTimeout 的執行時機並不穩定。</p><p>4.RAF 的執行時機穩定是在當前幀的最後，下一幀的開始之前，非常適合做動畫。</p><p>5.RIC 的執行時機並不穩定，computeDeadline 由被多因素影響計算得出，但可以傳遞 timeout 控制執行的 deadline。</p><p>6.用 TTI 和 FID（INP）去衡量頁面的交互性能。</p><p>7.用長任務拆分、延遲非關鍵模塊執行、延遲非可視區域圖片加載、減少頁面渲染以及配置靈活的緩存策略等手段，提升網站的交互性能。</p><p>——END——</p><p><strong>參考資料：</strong></p><p>[1]HTML living standand - evnet loop processing model:</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhtml.spec.whatwg.org%2Fmultipage%2Fwebappapis.html%23event-loop-processing-model" target="_blank">https://html.spec.whatwg.org/multipage/webappapis.html#event-loop-processing-model</a></p><p><strong>推薦閲讀：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574835%26idx%3D1%26sn%3D31d1b6ec0ecf857f5fb12ca8a2816fb1%26chksm%3Dc03f954ff7481c599d34556eeaba1960a4261d2e304e86989a54fa9e334c15a9ff8d58aa00b1%26scene%3D21%23wechat_redirect" target="_blank">百度搜索展現服務重構：進步與優化</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574780%26idx%3D1%26sn%3D8eda1e3f3dc06d6f10394be4a9df86f8%26chksm%3Dc03f9480f7481d968a54f75a113c16651a5c371ae43f078705f965d0a51a19491f41d2179ab7%26scene%3D21%23wechat_redirect" target="_blank">百度 APP iOS 端包體積 50M 優化實踐 (七) 編譯器優化</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574670%26idx%3D1%26sn%3D45e9f922faad4fffceca07bc116b15eb%26chksm%3Dc03f94f2f7481de45ad4b17e0235eb0074e4d78dff760654e44aed98d6684d7e0ba1ccbeffcd%26scene%3D21%23wechat_redirect" target="_blank">百度搜索內容 HTAP 表格存儲系統</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574408%26idx%3D1%26sn%3Dfc0f0b325a348a401d647f3cb048b68a%26chksm%3Dc03f93f4f7481ae2c964c6fd7ab54a8291edb7b2dae16c20c5e30e998a0bceb418d631d40abf%26scene%3D21%23wechat_redirect" target="_blank">大模型時代，「人人可 AI」的百度開發者平台長什麼樣？</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574315%26idx%3D1%26sn%3De1fe788ba3ae4f0b2d503bfac899cefa%26chksm%3Dc03f9357f7481a413ba7325eb9064078f097e7586136b885d11db67b4a5955412312d2428869%26scene%3D21%23wechat_redirect" target="_blank">數十萬 QPS，百度熱點大事件搜索的穩定性保障實踐</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 01:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/10322486</guid>
            <link>https://my.oschina.net/u/4939618/blog/10322486</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源，想説愛你不容易~]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>前言</h3><p>其實很早以前，我就想寫一篇文章，聊聊我之前的開源歷程，我不是什麼大牛，只是 github 上千萬項目中一名普通 owner，但是我熱愛開源，熱愛分享，熱愛編程，正因為如此，我打算藉着 teamlinker 開源之際，從一名普通開源從業者的角度和大家聊聊我開源生涯中的種種過往，對自己對別人也算是一種借鑑和啓發吧。</p><p>我不是計算機科班出身，只是秉持着從小對編程的熱愛，通過自學走上了軟件開發的道路，這一路上有風雨有彩虹，受到過質疑，但也受到過更多的鼓勵和支持，也正因為如此，我格外能感受到所謂的自我學習和提升是一件多麼不容易的事情，所以當我接觸到開源的時候，自然而然的就有種説不出的親切感，看着那些工整的源碼，就彷彿像一個老師，循循善誘的給我們講解着它的結構和功能，只要你願意探索，就可以在其中發現無窮的樂趣。</p><h3>從開源走向創業</h3><p>還記得在 2016 年的時候，我當時在一家軟件公司擔任技術總監的職務，其中遇到的一個令人頭疼的問題就是前後端總是為接口文檔的同步問題爭執不下，我當時就想如何有一個產品可以管理並且自動的同步接口文檔，讓前後端都有一個唯一的參照物的話，這個問題就可以得到很大的緩解，在網上找了一遍後並沒有發現滿意的產品，於是我決定自力更生，利用業餘時間，完成了這個接口文檔管理軟件的開發，取名為：DOClever（老粉應該還記得這個產品一開始的名字叫 SBDoc ~）。</p><p>其實在一開始的時候，我並沒有想太多，當時只是試探性的放到 github 上，並且給我的一些朋友試用，卻出乎意料的大受好評。看見大家的積極的反饋以及 github 上 star 數目的與日俱增，我獲得了作為程序員生涯以來第一次無與倫比的滿足感。真正感受到原來開源是一件這麼美妙的事情。</p><p>隨着 DOClever 業務的加劇以及用户的擴大，在 2017 年的時候，我決定將 DOClever 做大做強，找了一些朋友，我們決定出來創業，當時也正值創業風口，我們的這個項目也很快受到了不少關注。我們當時主要的宣傳窗口就是開源中國，在這裏我們認識了很多志同道合的朋友，也得到了編輯們對我們項目的各種肯定與支持，在此我還是要好好感謝下開源中國，感謝你們對中國開源事業所做的貢獻。</p><h3>商業化的探索與反思</h3><p>創業後很快我面臨的便是廣大開源軟件共同遇到的一個問題：盈利。當時我試過很多方案，比如開源版本與收費版本分開，打造收費插件，產品免費服務收費等，但最後都發現很難真正落地，而我當時的想法也很單純，覺得只要產品好，用户愛用就一定會有辦法掙錢，所以我當時的精力全部扎進了產品研發中，開發了接口自動化測試模塊，還大膽做出了一個決定：利用 electron 打造了桌面端，在當時的競品中，敢做桌面端的我們算是第一個了，桌面端出來後用户的反饋很好，但是我們還是陷入無法盈利的惡性循環。也就是説你的產品不錯，大家愛用，給你捐點小錢也 ok，但是一旦觸及商業化，那麼對不起在下告辭了~</p><p>後來我們也接過一些企業的定製化服務，週期長，任務重，有的甚至要駐點，但是為了團隊的發展我們又不得不做，我內心知道這個不是長久之計，也實在不想把我們做成一個外包公司，我更希望大家能認可我們統一化的產品，如果你有什麼需求，可以給我們一點時間，我們可以把它打造成模塊化的功能。但是往往甲方爸爸告訴我：不行，你需要專門為我定製一個 VVVVVVIP 至尊特供版。</p><p>其實我事後有認真反思過商業化的問題，覺得主要有兩點，接口管理平台本身市場就那麼大，競品也不少，而且軟件的門檻也低，我之所以能脱穎而出無非是我免費開源，功能也不差，但用户不是非我不可，很多用户都是因為 postman 的協作功能需要收費而轉向了我們，這些人的需求也很明確，就是要用免費的。第二點就是對於稍微大一點公司，他們內部都有自己的 api 接口管理，不會輕易的去使用外面的平台，就算去使用，也會對你原來的平台改的面目全非，有點公司良心點的還會請你去做個宣講啥的，感謝你下。有的就直接 copy 你的代碼把它變成他們內部開發的一個平台，這對於我們開源創業者可謂是竹籃打水一場空。</p><h3>創業失敗</h3><p>在 2018 年年中的時候，我向現實做出了屈服，我解散了我們團隊，我也去了一家大廠面試。我記得當時那個面試官問我做過哪些項目的時候，我把我的 github 給他看了下，他滿意的笑了笑，於是我很快就被錄取了。DOClever 自此也停止了更新，我把精力都投入了新的工作中，日子就這樣一天天波瀾不驚的過去，直到有一天羣裏的一個小夥伴給我發了一個鏈接，我點進去一看直接無語了，也是一個接口管理平台，但是裏面的功能，業務邏輯甚至頁面的佈局和按鈕的擺放都和 DOClever 一摸一樣，霎那間我明白我們被抄襲了。可是我又能做些什麼呢，DOClever 很久沒有更新了，我當時的公司也註銷了，軟件著作權也失效了，我能做的就是祝福他們做的比我更好吧！</p><p>時光荏苒，如今，我也從那個大廠離開了，慶幸的是我在此期間積累了一些資本，至少可以做幾年自己想做的事情，回顧過往，你問我開源後悔嘛，我不後悔，卻又五味雜陳，因為開源我可以讓更多人認識我，瞭解我，實現自我價值，也能找到滿意的工作，五味雜陳是因為開源只是一個商業化的手段，不是目的，開源不光是源碼的公開，更是一種價值的傳遞，內心的堅持，精神的坦誠，它對於創業者的要求更高，而我還遠遠不夠。</p><h3>感悟</h3><p>我個人認為，開源創業需要滿足兩個條件：<br> 1、你的產品所在市場潛力夠大，而你的產品的業務和功能又有一定的不可替代性。<br> 2、必須要有一套清晰的盈利模式，哪些東西可以通過開源來吸引流量，哪些東西是你的壓箱底的寶貝，真正能讓用户掏錢買單，這些我們自己是必須清楚的。很多人會吐槽國內的開源氛圍太差，全是伸手黨，你辛辛苦苦寫的東西，別人給你一包裝就是他自己的了。其實很多時候我們自己又何嘗不是呢，我們的產品幾乎沒有哪個不用開源框架或者開源庫的，但是不代表我們不尊重開源，國外的很多商用軟件都會把用到的開源包列舉出來一一感謝，這就是一個很好的例子，國內最近關於開源協議的幾起民事訴訟的勝訴我相信也將成為一個很好的典範。</p><h3>新的征程</h3><p>回到我現在在做的事情 Teamlinker，這是一個基於人工智能的團隊協作平台，融入了項目管理，視頻會議，文件共享等功能，可以最大程度的讓團隊成員協同辦公。很多人勸我 teamlinker 不要開源，但是我覺得作為一個技術從業者，我的骨子裏有一種自由分享的精神，我也非常期望能和別人的交流來讓我的產品變得更好，我想再試一試，失敗並不可怕，可怕是在同樣的地方跌倒卻再也不敢站起來了~</p><p>開源，想説愛你不容易，但是我卻甘之如飴。</p><p>後記：歡迎大家給我們的 teamlinker 提出一點建議和批評，如果能有一點小小的鼓勵那就更好啦。<br> 官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fteam-linker.com" target="_blank">https://team-linker.com</a><br> Github：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTeamlinker%2FTeamlinker" target="_blank">https://github.com/Teamlinker/Teamlinker</a><br> Gitee：<a href="https://gitee.com/sx1989827/teamlinker">https://gitee.com/sx1989827/teamlinker</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 10:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272643</guid>
            <link>https://www.oschina.net/news/272643</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 也可以用 eBPF 了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>此項目<span style="background-color:#ffffff; color:#1f2328">允許在 Windows 上使用 Linux 生態中熟悉的現有 eBPF 工具鏈和應用接口。也就是説，該項目將現有的 eBPF 項目作為子模塊，並添加中間層，使其能在 Windows 上運行。</span></p><p><span style="background-color:#ffffff; color:#1f2328">下圖顯示了本項目的基本架構和相關組件：</span><img height="1140" src="https://static.oschina.net/uploads/space/2023/1225/174251_tkYJ_3820517.png" width="1556" referrerpolicy="no-referrer"></p><p style="text-align:start"><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>現有的 eBPF 工具鏈（clang 等）可用於從各種語言的源代碼生成 eBPF 字節碼。字節碼可以被任何應用程序使用，也可以通過 bpftool 或 Netsh 命令行工具使用。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>eBPF 字節碼會被髮送到一個靜態驗證器（PREVAIL 驗證器），該驗證器託管在一個安全的用户模式環境中，如系統服務、飛地或可信虛擬機。如果 eBPF 程序通過了驗證器的所有檢查，就可以加載到內核模式執行上下文中。通常情況下，這是通過 JIT 編譯器（通過 uBPF JIT 編譯器）將程序編譯成本地代碼並傳遞給執行上下文來實現的。在調試構建中，字節碼可直接加載到解釋器（從內核模式執行上下文中的 uBPF），但解釋器不會僅在調試模式中支持，不提供發佈構建頻道支持，因為它被認為安全性較低。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>安裝到內核模式執行上下文中的 eBPF 程序可以附加到各種鈎子上，並調用 eBPF shim 公開的各種輔助 API，eBPF shim 內部封裝了公共 Windows 內核 API，允許在現有版本的 Windows 上使用 eBPF。許多輔助程序已經存在，隨着時間的推移，還將添加更多鈎子和輔助程序。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start">此項目並不是 eBPF 的分支，<span style="background-color:#ffffff; color:#1f2328">eBPF for Windows 利用現有項目，包括 IOVisor uBPF 項目和 PREVAIL 校驗器，通過為代碼添加 Windows 特定的託管環境，將它們運行在 Windows 上。</span></p><p style="text-align:start"><span style="background-color:#ffffff; color:#1f2328">Linux 提供了許多鈎子和輔助工具，其中有些是 Linux 特有的（例如，使用 Linux 內部數據結構），不適用於其它平台，而其它鈎子和輔助工具則是通用的，目的是為 eBPF 程序提供支持。</span></p><p style="text-align:start"><span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>eBPF 還可以與 </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>HyperVisor-enforced Code Integrity（<span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>HyperVisor 強制代碼完整性，HVCI）一起使用</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff; color:#1f2328">。啓用 HVCI 後，eBPF 程序無法進行 JIT 編譯，但可以以本地模式或解釋模式運行。</span></p></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 10:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/ebpf-for-windows</guid>
            <link>https://www.oschina.net/p/ebpf-for-windows</link>
        </item>
        <item>
            <title>
                <![CDATA[崑崙萬維「天工 SkyAgents」Beta 版全網測試]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><strong><span><span><span><span style="color:#1f2329">12 月 25 日，崑崙萬維 AI Agents 開發平台「天工 SkyAgents」Beta 版正式開放測試，用户可在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodel-platform.tiangong.cn%2F" target="_blank">https://model-platform.tiangong.cn/ </a>立即體驗。</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">崑崙萬維「天工 SkyAgents」AI Agents 開發平台，基於崑崙萬維「天工大模型」打造，具備從感知到決策，從決策到執行的自主學習和獨立思考能力。用户可以通過自然語言構建自己的單個或多個「私人助理」，並能將不同任務模塊化，通過操作系統模塊的方式，實現執行包括問題預設、指定回覆、知識庫創建與檢索、意圖識別、文本提取、http 請求等</span></span></span></span><span><span><span>任務。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>在大模型技術高速發展、AI Agents 應用不斷進步的當下，</span></span></span><span><span><span><span style="color:#1f2329">崑崙萬維「天工 SkyAgents」是我們在智能體領域的一次探索與嘗試。這個平台也許並不完美，但我們希望與廣大開發者們攜手共建、互助成長，不斷開拓人工智能技術的應用邊界。</span></span></span></span><span><span><span>現在不完美是為了未來的完美，我們一直在技術追求的過程中，堅信而勇於突破。</span></span></span></span></span></span></span></p><h4><span><span><span><span><strong><span><span><span>攜手探索，合作共創</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>大模型時代，交互式 AI 有望成為未來大模型技術的主流落地方向。歷史告訴我們，新興事物的演進總會找到一個穩定的術語來描述這種載體，而 AI Agents（智能體）已經顯現出了巨大潛力。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>目前，全球對智能體的關注異常熱烈，OpenAI 高度關注智能體領域，並在 OpenAI dev day 發佈會上發佈了自定義 GPTs 以及 Assistance API；DeepMind 的聯合創始人最近</span></span></span><span><span><span>也</span></span></span><span><span><span>提到下一代人工智能技術的發展方向將是交互式 AI，而不是生成式 AI。這種交互式 AI 很大程度上與智能體的描述是相符的，用户可以通過要求智能體完成各種任務，而智能體則可以操作軟件或與人類協作，完成複雜場景的工作。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>在技術範式上，崑崙萬維也在不斷思考驅動智能體技術快速發展的底層技術和架構。我們同時也清楚地認識到，即使在大模型的語言交互能力的加持下，我們離一個完全可以自動做決策並執行任務的智能體還有距離。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>今天，崑崙萬維正式開放「天工 SkyAgents」Beta 版，</span></span></span><strong><u><span><span><span><u><span>作為我們在 AI Agents 技術能力和應用能力上的一次探索</span></u></span></span></span></u></strong><span><span><span>。我們希望通過此次探索，能讓越來越多的用户與開發者能夠將大</span></span></span><span><span><span><span style="color:#1f2329">模型技術應用到工作生活中，打造出滿足日常需求、激發靈感創新的專屬 AI Agents。我們也希望更多對 AI Agents 感興趣的朋友們能夠與我們一同攜手共創。歡迎廣大夥伴們提出建議與意見。 </span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="619" src="https://oscimg.oschina.net/oscnet/up-e7a06ccac57f87401c80becb561193a4041.png" width="1265" referrerpolicy="no-referrer"></p><h4><span><span><span><span><strong><span><span><span>什麼是 AI Agents？</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">Agent 一般譯為「智能體」或「代理」，其概念最早由麻省理工學院人工智能實驗室（MIT AI Lab）創始人之一 Marvin Minsky 在其 1986 年出版的《思維的社會》一書中提出。它由社會與社會行為概念被引入計算系統內，指的是在某一環境下，能持續自主地發揮作用的計算實體。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">AI Agents 指的則是由人工智能技術驅動，能夠感知環境、進行決策和執行動作的智能實體。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">AI Agents 並不是一個新興的概念，自人工智能技術學科建立以來，就陸續有圍繞 AI Agents 的研究出現。2012 年深度神經網絡浪潮興起後，有一支以強化學習訓練 AI Agents 的學術派系誕生，轟動全球的圍棋機器人 AlphaGo 可以看作是這一流派的研究成果。不過，此類 AI Agents 更適合對抗性遊戲場景，在真實世界中較難落地。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">然而，大模型的出現改變了這一切。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">2023 年，隨着大模型技術在自然語言理解、工程能力、數據能力、存儲能力等領域的突破，大量對話交互類「GPT」湧現，以大模型技術驅動的 AI Agents 在通用性、實用性、可落地性等都得到了飛速發展，在全球掀起了又一陣 AI Agents 熱潮。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">傳統大模型應用大多基於 Prompt（用户提示詞）實現，Prompt 的質量將直接影響大模型的回答效果，</span></span></span></span><strong><span><span><span><span style="color:#1f2329">缺乏提示詞工程能力的普通用户難以將大模型的真正能力發揮到極致</span></span></span></span></strong><span><span><span><span style="color:#1f2329">。而 AI Agents 只需要用户給定工作目標，就可以通過獨立思考、調用工具去逐步完成任務，極大降低大模型技術應用門檻。</span></span></span></span></span></span></span></span></p><h4><span><span><span><span><strong><span><span><span>AI Agents 三大核心模塊：大腦、感知、執行</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">根據復旦大學論文《The Rise and Potential of Large Language Model Based Agents: A Survey》，AI Agents 可以劃分為大腦（Brain），感知（Perception）、執行（Action）三大模塊化能力。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><img alt="" height="497" src="https://oscimg.oschina.net/oscnet/up-e9dac7f27a534b98ae08bc84f655f2b0dff.png" width="828" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">（圖片來源：《The Rise and Potential of Large Language Model Based Agents: A Survey》） </span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">1. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">大腦（Brain）</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">大腦是 AI Agents 的「核心信息處理中心」，具備理解當前環境並形成「記憶（Memory）」的能力，同時也具備存儲並檢索長期記憶的能力。「大腦」可以根據「記憶」和當前接收的信息進行邏輯推理，並將複雜問題拆解成可實現的子任務，應對複雜場景任務。同時，通過 RAG（檢索增強生成）技術，AI Agent 可以根據當前場景和用户設定的目標進行進一步決策，實現獨立思考、規劃（Planning）和推理（Reasoning）。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">2. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">感知（Perception）</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">感知模塊能夠讓 AI Agents 基於當前的環境和場景獲取足夠的信息，這正是其與傳統 RPA 系統的區別之處。RPA 系統在面對大量未知信息、難以預測的環境時無法進行工作，AI Agents 則可以通過感知信息並做出對應的思考和行動，從而實現感知、理解和自主探索世界。 </span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">3. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">執行（Action）</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">執行模塊賦予了 AI Agents 執行任務的權限和能力。AI Agents 在接收到用户任務指令後，結合由感知模塊收集的當前場景信息，通過大腦進行總結和推理後，輸出到執行模塊中，使 AI Agents 能夠根據用户需求完成指令。同時，AI Agents 擁有調用、使用工具（Tool use）的能力，這些工具可以幫助 Agents 更高效地完成複雜任務，同時也提高了其在某些具體場景中的可信度和靈活度，相關應用場景包括讓 AI Agents 購買飛機票、點外賣、完成企業 IT/客服/法律任務等。</span></span></span></span></span></span></span></span></p><h4><span><span><span><span><strong><span><span><span>天工 SkyAgents</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">「天工 SkyAgents」基於崑崙萬維「天工大模型」打造，擁有專屬「大腦」、「感知」、「執行」模塊。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">個人用户/開發者可以通過「天工 SkyAgents」進行自然語言和簡單操作，無需代碼編程能力，即可在幾分鐘之內部署屬於自己的 AI Agents，完成行業研究報告、單據填寫、商標設計、甚至健身計劃、旅行航班預定等多項私人定製需求。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">企業用户/開發者則可以將「天工 SkyAgents」的眾多能力按需拼裝成企業 IT、智能客服、企業培訓、HR、法律顧問等眾多個性化的應用，並支持一鍵服務部署，確保其在不同業務系統中的無縫接入。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">「天工 SkyAgents」的 AI 能力背後，是崑崙萬維 AI Agents 技術在模塊化任務組件、智能知識庫構建、第三方工具調用、個性化 AI Agents 一鍵分享等領域的能力積累。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">1. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">模塊化任務組件，零代碼打造專屬 AI Agents</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">當前，多數用户既不具備代碼開發經驗，也不具備訓練大模型提示詞工程（Prompt Engineering）的能力，難以將眾多日常生活的實際需求通過對話問答形式快速實現，無法將大模型能力發揮到極致。為瞭解決這一問題，「天工 SkyAgents」將大量任務組件模塊化，集成了智能對話、信息加工、信息提取、信息分類、第三方數據獲取、向量檢索等能力。</span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">智能對話：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">智能對話模塊藉助 AI 能力，將用户發送的內容，通過大語言模型進行處理並回復給用户指定內容。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">信息加工：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">通過預設提示詞（Prompt）的方式讓大模型對特定信息輸入進行加工，以獲得符合需求的內容。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">信息提取：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">通過大模型對語義的理解，可以從輸入信息中提取目標信息</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">信息分類：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">藉助大模型的智能分析，將用户問題進行分類，針對不同類型的問題執行不同操作，方便進行個性化處理；</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">第三方數據獲取：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">第三方數據接入會攜帶相關的參數，系統向指定地址發送 POST 請求，並接收響應。系統在攜帶相關參數的同時，可以實現與其他應用服務的數據互聯互通。基於第三方數據獲取模塊可以極大擴展 AI Agents 的能力，打通數據庫操作、聯網搜索等更多場景。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">向量檢索：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">針對常見的用户提問，系統可以將問題添加進知識庫，便於搜索和查找。而對於「知識庫」模塊而言，用户可以輸入問題，系統將在知識庫中搜索相關問題與解答，並用自然語言進行輸出。</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">2. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">智能知識庫構建，支持大規模知識導入</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">大模型能力雖強，但也有其天生的弱項。一方面，大模型通過參數訓練獲得的知識只能停留在某一時點，更新成本很高；另一方面，大模型的訓練數據通常以通用知識為主，細分領域的數據往往缺乏。為瞭解決這一問題，「天工 SkyAgents」支持導入更多格式和更大規模的數據和知識，給大模型增加了「知識庫外腦」。</span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">支持多種數據導入形式：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">文本、文件、網站、問答對、在線文檔等方式，輕鬆將已有知識進行導入</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">知識庫 Embedding：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">將知識庫中的內容元素表示為低維度的向量，使得知識庫中的元素可以更容易地進行計算相似性、尋找相鄰的實體等數學運算，從而提高了知識庫在 AI Agents 中的可操作性。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">知識庫自由鏈接：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">每個 AI Agents 可以自由鏈接所屬知識庫並同時由多個知識庫進行內容供給，每個知識庫也可以同時鏈接多個 AI Agents，知識庫內容可根據需要啓用和棄用，實現更靈活的知識內容管理。</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">3. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">第三方工具調用，多場景隨心應對</span></span></span></span></strong></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">第三方工具調用：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">工具調用能力是將 AI Agents 與大量對話類 GPT 區別開來的核心能力之一，比如在機票預訂場景中，除了對用户需求與航班信息進行分析判斷，AI Agents 還需要調用票務平台、電子支付等不同工具。因此，除了基礎的模塊外，「天工 SkyAgents」還支持各類第三方工具的調用，用户可以根據自身需要進行工具的開發，使得構建 AI Agent 時擁有更多靈活的自由度。</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">4. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">個性化 AI Agents 一鍵分享</span></span></span></span></strong></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">一鍵分享：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">為了回饋廣大用户與開發者們，更便捷地打造與使用 AI Agents，「天工 SkyAgents」上線新年專屬活動，推出理想伴侶、有緣機伴、暖心家園三款官方新年模版，並全面簡化了分發和使用流程。用户根據自己的創意設計出的 AI Agents 可以通過鏈接的方式向更多人分享，使用者只需點擊鏈接，即可獲得對該 AI Agents 的訪問權。點擊創建：https://model-platform.tiangong.cn/</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">能力更全面、應用更智能、分享更便捷、平台更好用。本次「天工 SkyAgents」beta 版的正式開放內容，將進一步推動大模型技術的普惠化，幫助缺乏代碼開發能力的個人與中小企業積極擁抱大模型技術，助力大模型走入千家萬户，為人工智能生態發展貢獻力量。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><span><span><span><span><strong><span><span style="background-color:#fbbfbc"><span><span>掃碼進入「天工開放平台」 ，快速構建 AI Agent</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><img alt="" height="280" src="https://oscimg.oschina.net/oscnet/up-9032e1a9041a11a6ce891a3020335655fae.png" width="280" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 09:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272624</guid>
            <link>https://www.oschina.net/news/272624</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[燧原科技增資至 1 億元，騰訊為第一大股東]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">天眼查 App 顯示，上海燧原科技股份有限公司於近日發生工商變更，註冊資本由約 443 萬人民幣增至 1 億人民幣。</span></p><p><span style="color:#000000">上海燧原科技股份有限公司（曾用名：上海燧原科技有限公司）成立於 2018 年 3 月，法定代表人、董事長兼總經理為趙立東（ZHAO LIDONG），經營範圍含集成電路、計算機硬件研發、批發、零售，自有研發成果轉讓，並提供相關技術諮詢與技術服務，銷售自產產品，集成電路製造等。</span></p><p><span style="color:#000000">股東信息顯示，<span style="background-color:#ffffff">該公司由騰訊科技（上海）有限公司、趙立東、張亞林、國家集成電路產業投資基金二期股份有限公司等共同持股。其中，騰訊科技（上海）有限公司持股約 21.37%，為第一大股東。</span></span></p><p><img height="250" src="https://oscimg.oschina.net/oscnet/up-1732a5466871889cdbf8c8cbb652bc144ab.png" width="700" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 09:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272620</guid>
            <link>https://www.oschina.net/news/272620</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[和 ChatGPT 聊天費水，提 10 個問題或消耗半升水]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>《央視財經》報道稱，如果一個用户向 ChatGPT 問了 10 到 50 個問題，可能會消耗掉 500 毫升的水。</p><p>因為訓練和運行 AI 大模型通常需要數以萬計的服務器來提供計算資源、存儲資源以及低延遲的網絡連接，這些服務器會以集羣的方式部署在名為「數據中心」的物理場所，當它們一起工作時，會在短時間內產生高度集中的熱量，所以需要大量的水資源進行冷卻。</p><p><img height="240" src="https://oscimg.oschina.net/oscnet/up-07526f86e0540f3acb7c39b414feef1d080.png" width="500" referrerpolicy="no-referrer"></p><p>以微軟和谷歌為例。2022 年，微軟一共用掉了約 17 億加侖（約 64 億升）水，相當於可以填滿約 2500 個奧運會規格的泳池；而谷歌的數據中心和辦公室則用掉了總計 56 億加侖（約 212 億升）水，相當於 8500 個奧運會規格的游泳池。</p><p>數據顯示，現在 AI 所需要的算力預計每 100 天就會翻一番，並且在未來五年內可能會增長超過一百萬倍。研究人員預計，到 2027 年，全球範圍內的 AI 需求可能會需要消耗掉 66 億立方米的水資源，幾乎相當於美國華盛頓州全年的取水量。</p><p>美國聖克拉拉大學馬庫拉應用倫理學中心高級主管，安·斯基特表示：「我認為很快就會有監管機構開始行動，而歐盟明年就會提高相關的監管要求，要求公司披露它們的用水情況。」</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 07:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272594</guid>
            <link>https://www.oschina.net/news/272594</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openKylin 社區第三次理事會會議成功召開！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">2023 年 12 月 22 日下午，openKylin 社區第三次理事會會議在北京成功召開。本次會議由 openKylin 社區秘書長餘傑主持，麒麟軟件、普華基礎軟件、中科方德、麒麟信安、凝思軟件、中興新支點、元心科技、中國電科 32 所、技德系統、北京麟卓、先進操作系統創新中心、飛騰、兆芯、龍芯中科、景美、京東科技、玄鐵、申泰信息、海光等 21 家社區理事單位代表參會。</span></span></p><div><img alt="" height="720" src="https://oscimg.oschina.net/oscnet/up-89ff214b26c58cc74cf9c9fcbb41c82fefe.png" width="1080" referrerpolicy="no-referrer"></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區諮詢委員會委員韓乃平為本次會議作開場致辭，向出席會議的各位來賓致以歡迎和感謝，並表示一個社區的良性發展，不僅需要主流軟硬件廠商的積極合作，更需要吸引全球眾多開源社區開發者不斷湧入。openKylin 作為我國開源操作系統根社區，通過聚合產、學、研、用等開源力量，在過去一年取得了行業矚目的成績，希望通過本次會議，共同商討如何更好推進社區發展，挖掘社區更多潛能，為推進中國信息化產業的發展作出更大的貢獻。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-b126e34cb4bad1857b66cf44f36cad418cf.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#6ec1f5"><span style="background-color:#f7fcff">社區工作彙報</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區副秘書長劉敏以線上形式參與會議，圍繞社區治理、基礎設施、SIG 組、社區版本、社區會員和品牌推廣等維度，向理事單位代表彙報 2023 年社區運營進展及 2024 年發展規劃。openKylin 社區技術委員會委員李劍峯從系統版本構建和社區技術創新等維度向理事單位代表進行彙報。</span></span></p><div><p style="text-align:center"><img alt="" height="2432" src="https://oscimg.oschina.net/oscnet/up-c40a204c7c674be4aca5f9baa697d7f0959.jpg" width="3648" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">2023 年，openKylin 社區發佈了 3 個系統版本，並圍繞桌面操作系統底層核心技術和用户體驗提升，推出了「分級凍結」應用生命週期管理機制、軟硬件生態「原生兼容」技術、VirtIO-GPU 硬件視頻加速機制、新一代圖形顯示框架 wlcom 合成器、開明軟件包格式等一系列創新成果。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">此外，面向快速發展的人工智能技術領域，openKylin 社區積極佈局，2023 年 6 月啓動了對 AI 大模型產品的生態兼容和系統級融合，發佈 openKylin AI 框架安裝助手，並在 openKylin 1.0 版本中支持桌面 AI 大模型插件和智能語音助手功能，推動桌面操作系統智能交互創新發展。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#6ec1f5"><span style="background-color:#f7fcff">理事單位貢獻分享</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">北京麟卓總經理温研發表《繪製輝煌，驅動未來--圖形 SIG 組工作彙報》主題分享，基於社區平台，北京麟卓成立了 GraphicSystem SIG，負責 openKylin 社區中 GPU 驅動的適配與優化、圖形軟件棧優化、基於 GPU 的通用計算、圖形處理系統綜合測試評估等與圖形系統相關的信息交流和配套軟件開發工作。未來，麟卓將於與社區加深合作，為拓展社區應用生態提供支撐。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8281f0b89a1a8051710c2f34a8299ec7806.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">元心科技研究院副院長李何佳發表《Flutter SIG 組的工作進展及後續工作方向》主題分享，加入社區後，元心科技參與了 Security SIG 相關工作，並對相關倉庫進行了 CVE 的漏洞修復。同時發起成立了 Flutter SIG，致力於為推進 Flutter 應用開發框架在 openKylin 社區的支持，包括對 Flutter 開發環境支持和 Flutter 應用運行支持。後續，將與 openKylin 社區緊密協作，共同開展更多技術嘗試與創新探索。</span></span></p><div><p style="text-align:center"><img alt="" height="2432" src="https://oscimg.oschina.net/oscnet/up-c1d070fd8ccd1211a40b6ec0ef66c5d8f84.jpg" width="3648" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">飛騰軟件支持經理鄭俊普發表《與開放的麒麟共飛騰》主題分享，飛騰與 openKylin 社區在技術支持、開源社區建設和生態活動等方面有着密切合作。基於社區，創建了 Phytium SIG，2024 年，飛騰將圍繞服務器平台上的 openKylin 內核和軟件適配開展工作，為社區生態繁榮貢獻一份力量。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-42ac95fa812d4ddef5b497314b302201ea9.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">阿里巴巴達摩院，RISC-V 及生態高級技術專家王雲龍發表《openKylin&amp;玄鐵 RISC-V 合作進展》主題分享，王雲龍表示，玄鐵與 openKylin 社區在技術融合、軟件適配和生態推廣方面有着深度合作，基於玄鐵 CPU+openKylin 操作系統的基礎平台，聯合釘釘，三方共同努力完成了 27000+文件的編譯、Qt&amp;CEF 等核心組件、17 個第三方庫的構建工作，在 RISC-V 架構上首次實現了大型商業 IM 的流暢運行。</span></span></p><div><p style="text-align:center"><img alt="" height="2432" src="https://oscimg.oschina.net/oscnet/up-086ff4a6aea5896e7cea8088376720081e1.jpg" width="3648" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">景美產品總監邱江發表《國產 GPU 的 openKylin 開源之路》主題分享，景美在加入 openKylin 社區後發起成立 GPU SIG 組，並邀請了國內多家 GPU 廠商陸續加入並貢獻社區，目前已正式完成景美 JM9100 顯卡與 openKylin 1.0 版本操作系統的適配工作，其適配成果後續也將逐步合併到 openKylin 2.0 版本中。</span></span></p><div><p style="text-align:center"><img alt="" height="2432" src="https://oscimg.oschina.net/oscnet/up-4c6fb975407dd2b4754514f4b7c64beac2d.jpg" width="3648" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">兆芯高級產品經理張偉發表《共建 openKylin 社區》主題分享，兆芯加入社區 GPU SIG 後，積極開展 openKylin 內核在兆芯 CPU 平台上的驗證適配、性能優化、新需求支持等相關工作，協助社區有序推進 openKylin 開源操作系統的完善和版本更新，目前，兆芯最新一代開先 KX-6000G 處理器已與 openKylin 操作系統完成適配認證工作，並在 openKylin 社區代碼貢獻位列前茅。</span></span></p><div><p style="text-align:center"><img alt="" height="2432" src="https://oscimg.oschina.net/oscnet/up-7fbab6bb17d73843fd51af01b0036d508af.jpg" width="3648" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#6ec1f5"><span style="background-color:#f7fcff">閉門討論</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區理事會作為社區決策機構和領導機構，主要職責為指導社區的發展方向，制定長期發展規劃和實施指導意見。會上，openKylin 副秘書長劉敏就 openKylin 社區章程更新向理事單位進行彙報。隨後，各理事單位圍繞</span><strong><span style="color:#000000">社區運營、生態共建、技術創新發展方向</span></strong><span style="color:#000000">等重大事宜發表了各自意見，並進行了深入討論。</span></span></p><div><p style="text-align:center"><img alt="" height="1549" src="https://oscimg.oschina.net/oscnet/up-ec6edfcdc1519d9b04b5729e9a7ed94fa38.jpg" width="3921" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#6ec1f5"><span style="background-color:#f7fcff">總結致辭</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">最後，由社區理事長朱晨對本次理事會進行總結致辭，朱晨表示，openKylin 社區的繁榮發展，離不開每一位貢獻者的辛勤付出。在今天上午的社區 2023 年度夥伴暨開發者大會上，我們對參與社區共建的優秀企業夥伴和個人開發者進行了表彰頒獎。我們很高興地看到，越來越多優秀夥伴加入，為打造國產開源操作系統根社區貢獻力量。</span></span></p><div><p style="text-align:center"><img alt="" height="720" src="https://oscimg.oschina.net/oscnet/up-6daf096096b8cee46f43e5562cd5d447400.png" width="1080" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">未來，openKylin 將繼續秉持「開源聚力、共創未來」的社區理念，持續推動技術創新和生態拓展，打造一個更加強大和優秀的桌面操作系統開源社區，同時將不斷提升自身在開源技術發展中的影響力，為推進中國信息化產業的發展作出更大的貢獻。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 06:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272584</guid>
            <link>https://www.oschina.net/news/272584</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源共創，攜手成長 | openKylin 夥伴暨開發者年度會議圓滿落幕！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">12 月 22 日，openKylin 夥伴暨開發者年度會議在北京成功召開。本次會議以「開源共創，攜手成長」為主題，邀請了社區傑出共建單位和開發者代表線下相聚，共鑑社區新進展、共享開源操作系統新技術、共研產業未來新趨勢。</span></span></p><div><p style="text-align:center"><img height="1280" src="https://oscimg.oschina.net/oscnet/up-95191a5aa9adb13597715074c98ca955469.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><em><span><strong><span style="color:#ffce73">01</span></strong></span></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#57b8f6">會議開場致辭</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區理事、麒麟軟件總經理孔金珠在開場致辭中表示，過去一年裏，越來越多優秀的企業夥伴和開發者加入到 openKylin 開源大家庭中，為操作系統根技術創新奠定智囊基礎。在社區 400+生態夥伴和 5500+開發者的攜手共創下，openKylin 社區取得多項技術創新成果，實現了從系統效能、功能體驗、生態融合、應用開發等方面的全棧技術創新。此次會議是一次技術的交流，也是一次思想的碰撞，更是一次創新的啓程。希望通過交流和分享，碰撞出智慧的火花，進一步推動操作系統創新技術融合。</span></span></p><div><p style="text-align:center"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-5f02f52e732f362c83ecc5301f00c9bc212.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><em><span><strong><span style="color:#ffce73">02</span></strong></span></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#57b8f6">社區成果回顧</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區生態委員會主任李震寧分享了 openKylin 進展成果及未來展望，李震寧表示，2023 年，在建立中國開源操作系統根社區的信念引領下，openKylin 社區匯聚了社會各界的產業力量、院士專家、高校師生、個人開發者，共同推動社區治理體系完善、社區產品打造、系統生態建設及使用體驗提升。openKylin 社區的快速發展，充分體現了開源作為一種創新的軟件協同生產模式所綻放的活力和無限潛能。</span></span></p><div><p style="text-align:center"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-08a7ee5efbc0ff067ea9d9b9ea7e78bc67e.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><ul><li><span><strong><span style="color:#000000">生態共建</span></strong><span style="color:#000000">方面，目前，openKylin 社區已匯聚了涵蓋操作系統、數據庫、辦公軟件、CPU、GPU、整機、人工智能等在內的 400+企業會員和 36 所研究型、教學型、應用型的各層次高等院校。</span></span></li><li><span><strong><span style="color:#000000">版本發佈</span></strong><span style="color:#000000">方面，openKylin 社區累計發佈 6 個版本，完成 20+核心組件選型工作，累計下載量超百萬。</span></span></li><li><span><strong><span style="color:#000000">創新演進</span></strong><span style="color:#000000">方面，成立 94 個 SIG 開展技術研究與創新，其中，開明包格式環境、wlcom 合成器、KARE 生態兼容、不可變系統和跨版本升級工具等社區最新重大技術成果都將融入到 openKylin 2.0 版本中，顛覆性創新帶來全新體驗。目前 openKylin 2.0 alpha 版本已發佈，面向開發者和嘗新用户體驗。</span></span></li><li><span><strong><span style="color:#000000">智能融合</span></strong><span style="color:#000000">方面，發佈 openKylin AI 框架安裝助手，實現一鍵安裝 AI 框架，並在 openKylin 1.0 版本中實現支持桌面 AI 大模型插件和智能語音助手功能，從智能輸入、智能輸出兩方面入手，深度融合 AI 技術，推動桌面操作系統智能交互創新發展。</span></span></li><li><span><strong><span style="color:#000000">RISC-V 布</span></strong><span style="color:#000000">局方面，openKylin 社區正式加入 RISC-V 基金會，從源碼級別自主構建了 RISC-V 開源桌面操作系統版本成為其產業聯盟成員，支持 80% 以上市場主流 RISC-V 芯片，並攜手深度數智發佈全球首款 RISC-V 筆記本電腦 DC-ROMA。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">邁向 2024 年，openKylin 社區將立足新起點、實現新跨越。以開源、開放、平等、協作模式融智共創，為用户及開發者創造全新體驗及價值。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><em><span><strong><span style="color:#ffce73">03</span></strong></span></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#57b8f6">年度貢獻榜單揭曉</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區的繁榮發展，離不開每一位貢獻者的辛勤付出。會上，openKylin 社區公佈了 2023 年度貢獻榜單並進行頒獎，以表彰在過去一年中為社區做出突出貢獻的傑出企業夥伴、高校共建先鋒、SIG 團隊和開發者菁英等。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#888888">感謝每一位參與社區共建的小夥伴！歡迎更多企業、高校和開發者加入社區，共同打造中國開源操作系統根社區！以下為現場部分頒獎留影：</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ec33487714ec154fceead05a87ff6e18c15.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-055afff730218da4aae68795a967a3d0076.jpg" referrerpolicy="no-referrer"></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-28988997294bf968c922166fab67c3b46e8.jpg" referrerpolicy="no-referrer"></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-538daf8e0d17bd318f74522b98e8a380362.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><em><span><strong><span style="color:#ffce73">04</span></strong></span></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#57b8f6">共建夥伴成果分享</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><span style="color:#000000">格蘭菲市場支持科主管嶽曉帥發表《格蘭菲 openKylin 社區會員開源實踐技術分享》主題演講，嶽曉帥表示，在加入 openKylin 社區後，格蘭菲積極參與社區共建，並加入社區 GPU SIG，目前已完成了 Arise1 平台與 openKylin 操作系統的兼容適配認證工作，並在功能、性能及兼容性方面表現優異。</span></span></p><div><p style="text-align:center"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-6caa8d88cb5fad2a0b4f66d85c5519373b4.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">信創海河實驗室副研究員王文竹發表《信創海河實驗室 openKylin 社區會員開源實踐分享》主題演講，王文竹表示，信創海河實驗室與 openKylin 社區在 RISC-V 版本共建、運營推廣和人才培養等方面有着緊密的合作關係。雙方攜手從源碼級別自主構建了 RISC-V 開源桌面操作系統版本，目前已實現 openKylin 對算能 RISC-V 產品的全方位支持，涵蓋了桌面環境、軟件生態、容器化部署和人工智能等多個關鍵領域。未來雙方將深化合作，共同推進 RISC-V 生態技術發展。</span></span></p><div><p style="text-align:center"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-488499cad322a4e5f7f7ca8e2efe730b22a.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">南開大學軟件學院團委書記王真發表《南開大學+openKylin: 共同推動開源社區國際化建設》主題演講，王真表示，南開大學軟件學院作為 openKylin 社區共建夥伴，創建了 InternationalPromotion SIG，負責對接 30+國家，103 位國外留學生開展相關國際化推廣工作，目前已開展四屆國際推廣交流活動，頒發尼泊爾、肯尼亞、塞拉利昂等 11 個國家星級推廣站點授權證書。未來，雙方將進一步攜手擴大國際項目交流圈，推動 openKylin 社區科技創新合作、技術推廣交流和成果轉化應用。</span></span></p><div><p style="text-align:center"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-a2b78bd919f34e066c3561280f2edccd3c0.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">儒特科技 CEO 馬鐵發表《QSFramework SIG 貢獻及成果分享》主題演講，儒特科技加入社區後，發起成立了 QSFramework SIG，SIG 團隊維護的開源項目青霜框架（QSFramework），是一款新形態、輕量化、微內核 Web 引擎。目前，已正式完成 QSFramework 與 openKylin 操作系統的兼容適配，並已發佈到 openKylin 2.0 軟件倉庫，感興趣的小夥伴可以下載體驗。</span></span></p><div><p style="text-align:center"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-09f68cf3fcaad8955597abd5839fa41d054.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">社區個人開發者孫聖博也分享了他與 openKylin 社區的結緣故事以及在社區的開源實踐之旅，孫聖博作為一名高中生，在加入社區後，發起成立了 Cutefish SIG 等，完成了 Cutefish 等桌面環境及相關組件與 openKylin 的兼容適配。同時，還積極參與社區 RISC-V 生態共建，併成立了 FAQ SIG，負責收集各渠道開發者、愛好者等用户反饋的問題，建立相關標準化流程推動問題解答或解決。孫聖博的發言引發陣陣掌聲，讓更多的開發者感受到了開源的魅力與活力。</span></span></p><div><p style="text-align:center"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-b66fe15ad20ef69fcfdceeb97f16025fe9d.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><em><span><strong><span style="color:#ffce73">05</span></strong></span></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#57b8f6">會議落幕致辭</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區生態委員會主任李震寧在總結致辭中提到，過去一年，正是有了大家的共同努力，openKylin 才能取得今天的靚麗成績。在 openKylin 社區，各界夥伴都可以在開源、開放、協作的模式下，基於產業發展現狀、院校科研積累和開發者實踐經驗等，開放自由的交流想法與建議，並進行實踐、檢驗與完善。通過本次會議，不僅加深了社區與企業夥伴、社區與個人開發者之間的瞭解，也為 openKylin 的發展提供了新的思路和方向。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-55cfd98b21f0d69d4c5e8f11a5b09378305.jpg" referrerpolicy="no-referrer"></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-863b3b1f00649033bd11bb0edd70ec04d76.jpg" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">展望未來，openKylin 社區也將持續把握髮展機遇，聚焦操作系統根技術，發揮社區平台支撐作用，聚合產、學、研、用及國內外開源力量，加速系統創新迭代，共同推動 openKylin 開源操作系統根社區構建，為推動形成眾研眾用眾創的開源軟件生態添磚加瓦，逐步走向同國際頂尖開源社區比肩的星辰大海。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 06:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272582</guid>
            <link>https://www.oschina.net/news/272582</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GTA 5 完整源代碼被公開泄露]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在國外正值聖誕假期之際，一個匿名用户公開<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cyberkendra.com%2F2023%2F12%2Fgta-5-source-code-leaked-on-christmas.html" target="_blank">泄露</a>了 Rockstar 旗下知名遊戲《俠盜獵車手 5》（GTA 5）的所有源代碼。</span></p><p><span style="color:#000000">泄露的文件大約有 4GB，其中包含與遊戲 RAGE 引擎相關的關鍵文件、概念圖、遊戲聖安地列斯背景的早期地圖以及其他敏感資料。此外，還包括未發佈的《GTA 6》中的一些 Python 腳本文件和<span style="background-color:#ffffff">一個 Bully 2 文件</span>。</span></p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-cea5c5b3990f3c01ce94728fdbbf1d3c3ad.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">早在 2022 年 9 月，就有一匿名黑客聲稱獲得了《GTA 5》和《GTA 6》的源代碼，並威脅要公開這些數據企圖敲詐 Rockstar 遊戲公司。此後，Rockstar 官方也發佈聲明<span style="background-color:#ffffff">確認遭遇網絡入侵，證實了</span>大規模的《GTA 6》泄漏。</span></p><p><span style="color:#000000">時至今日，《GTA 5》的完整源代碼似乎又被泄露，並在幾個文件共享網站和專門討論《GTA》修改和黑客問題的論壇上公開。目前尚未清楚相關的泄露事件是如何發生的。但有人<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FGTAFocal%2Fstatus%2F1739051532149039111" target="_blank">推測</a>，早自 2022 年泄露事件以來，遊戲完整的源代碼就一直在被交易。</span></p><p><span style="color:#000000"><img alt="" height="500" src="https://oscimg.oschina.net/oscnet/up-9cc40522a4d848442c48a30ddc5b5226046.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Rockstar Games 及其母公司 Take-Two Interactive 尚未就最新泄露事件發表官方聲明。</span></span></p><p><strong><span style="color:#000000"><span style="background-color:#ffffff">相關閲讀：</span></span></strong></p><ul><li><a href="https://www.oschina.net/news/210946/gta-6-leak" target="_blank">官方確認，GTA 6 源代碼泄漏</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 06:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272581/gta-5-source-code-leaked-on-christmas</guid>
            <link>https://www.oschina.net/news/272581/gta-5-source-code-leaked-on-christmas</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
