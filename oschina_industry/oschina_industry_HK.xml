<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 07 Mar 2024 13:06:10 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[前谷歌軟件工程師被控竊取機密 AI 技術]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>美聯社報道，美國司法部週三表示，Google 公司的一名前軟件工程師被指控竊取該公司的人工智能技術，同時與兩家位於中國的公司秘密合作。中國公民丁林葳（音譯）因四項聯邦商業機密盜竊罪在加利福尼亞州紐瓦克市被捕，每項罪名皆最高可判處 10 年監禁。</p><p>總檢察長梅里克-加蘭（Merrick Garland）在舊金山舉行的美國律師協會會議上<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dl64VlrA-GUA" target="_blank">宣佈了該案</a></u>，他與其他執法部門領導人曾多次警告中國經濟間諜活動的威脅以及人工智能進步帶來的國家安全問題。</p><p>聯邦調查局局長克里斯托弗-雷（Christopher Wray）在一份聲明中説："今天的指控是最新的例證，説明中華人民共和國境內公司的關聯公司為竊取美國的創新技術不擇手段。竊取美國公司的創新技術和商業機密會造成就業損失，並對經濟和國家安全造成破壞性後果。"</p><p>最近幾周，美國司法部領導人一直在就外國對手如何利用人工智能技術對美國造成負面影響敲響警鐘。</p><p>司法部副部長麗莎-摩納哥（Lisa Monaco）在上個月的一次演講中<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapnews.com%2Farticle%2Ffbi-election-interference-wray-2024-campaign-ai-a0c4a95c818839b18f919c6d648c4dcf" target="_blank">表示</a></u>，政府的多機構顛覆性技術打擊小組將把人工智能執法放在優先事項的首位。</p><p>加利福尼亞州北區法院週三公佈的一份起訴書稱，丁在 2019 年受僱於 Google，可以接觸到該公司超級計算數據中心的機密信息，但他在兩年前開始將數百個文件上傳到一個個人持有的 Google 雲賬户。</p><p>檢察官説，在盜竊開始後的幾周內，丁被中國一家初創科技公司聘為首席技術官，該公司吹噓自己使用了人工智能技術。起訴書稱，他前往中國，參加了該公司的投資者會議，並試圖為其籌集資金。起訴書稱，他還單獨創辦了一家總部位於中國的初創公司，並擔任首席執行官，該公司希望訓練"由超級計算芯片驅動的大型人工智能模型"，且並沒有向 Google 披露這兩家公司的關聯關係。</p><p>12 月 26 日，他從公司辭職。三天後，Google 相關部門得知他曾以其中一家中國公司首席執行官的身份出席了在北京舉行的投資者會議而報警。起訴書稱，Google 方面還查看了監控錄像，錄像顯示另一名員工在丁工作的大樓掃描了他的門禁卡，使他看起來不在中國。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9b61448ad14c6ad426c8fb453f0a7042e03.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5d14d945f47b2a80e9f34f07d722e5033ed.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 11:18:59 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282027</guid>
            <link>https://www.oschina.net/news/282027</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LFOSSA 祝大家女神節快樂！助力女性開源職業發展！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><div><div><div><p><img height="1000" src="https://oscimg.oschina.net/oscnet/up-87fca7e99dc80187c6d9bafde6383da273a.png" width="2350" referrerpolicy="no-referrer"></p><p><span style="color:rgba(0, 0, 0, 0.9)">女神節，是一個讚美和慶祝的日子。讓我們在這個特殊的日子裏，向所有的女性表示最深的敬意和祝福。</span><span style="color:rgba(0, 0, 0, 0.9)">回顧歷史，我們可以看到女性在各個領域都取得了令人矚目的成就。</span><span style="color:rgba(0, 0, 0, 0.9)">無論是在科學、藝術、政治還是商業領域，女性都展現出了她們獨特的才華和魅力。</span><span style="color:rgba(0, 0, 0, 0.9)">她們不僅在自己的領域裏取得了巨大的成功，還為整個社會帶來了積極的影響。</span></p><p><span>在開源領域，雖然</span><span style="color:#000000">開源女性開發者屬於少數羣體，但女性開發者於開源中扮演重要的角色和貢獻。</span><span>LFOSSA 開源軟件學園為表達對女性的尊重，認識到女性價值，欣賞女性的才華和貢獻，為她們在開源領域提供更多的機會和平台<strong>。在 3 月 8 日國際婦女節來臨之際，LFOSSA 開源軟件學園為眾多開發者送出專屬福利</strong>&nbsp;——&nbsp;</span><span style="color:#ff0000"><strong>3 月 7 日 - 3 月 10 日，</strong><strong>Linux Foundation</strong><strong>開源軟件學園官方課程及認證考試全場 9 折。</strong></span></p><p><span>Linux Foundation 開源軟件學園一直致力於推<span style="color:#000000">動</span></span><span style="color:#000000">開源多樣化及包容的開源社區</span><span>，鼓勵女性在不同領域挖掘屬於自己獨特的閃光點。請持續關注我們，之後陸續推出超多女神節的活動，歡迎參加！</span></p><p><span>感謝女性在不同領域取得的成就，每一位女性都擁有源源不斷的智慧，同樣擁有原原本本的自信。保持女性在開源事業上獨特的魅力，能夠充分發揮自己的潛力。</span></p><p><span>祝大家女神節快樂，繼續持之以恆，卓爾不羣！</span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>部份精選官方課程認證超級套購</span></span></span></p><p style="color:#242b3c; text-align:center"><span><img alt="1707387858746433.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707387858746433.png" width="270" referrerpolicy="no-referrer"></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA<span>&amp;CKS&amp;LFS258&amp;LFS260 超級套購</span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原價 8198 元</span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">，</span><span><span style="color:#ab1942"><span><strong>現價 7378.2 元</strong></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F23" target="_blank">CKS&amp;LFS260&amp;CKA&amp;LFS258 超級套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span style="color:#ab1942"><span><img alt="1707387940238031.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707387940238031.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>KCNA&amp;CKA&amp;LFS250&amp;LFS258 超級套購</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原價 6158 元</s><span>，<span style="color:#ab1942"><strong>現價 5542.2 元</strong></span></span></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F57" target="_blank">LFS250&amp;LFS258&amp;KCNA&amp;CKA 超級套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:#242b3c; text-align:center"><span><span style="color:#ff0000"><span><span><span style="color:#000000"><img alt="1707388029979327.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388029979327.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span><span>CKA&amp;CKAD&amp;</span>CKS<span>超級套購</span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原價 7438 元</s><span>，<span style="color:#ab1942"><strong>現價 6694.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F30" target="_blank">CKA&amp;CKAD&amp;CKS 超級套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><img alt="1707388086590851.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388086590851.png" width="270" referrerpolicy="no-referrer"></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;CKS&amp;PCA 超級套購</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原價 6528 元</s><span>，<span style="color:#ab1942"><strong>現價 5875.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F69" target="_blank">CKA&amp;CKS&amp;PCA 超級套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><span><img alt="1707388149744838.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388149744838.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;PCA 超級套購</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原價 4288 元</s><span>，<span style="color:#ab1942"><strong>現價 3859.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F58" target="_blank">PCA&amp;CKA 雙證套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span><span style="color:#ab1942"><img alt="1707388208170950.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388208170950.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKS&amp;CKA 雙證套購</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原價 5358 元</span></span><span><span style="color:#ab1942">，<strong>現價 4822.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F22" target="_blank">CKS&amp;CKA 雙證套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><span><img alt="1707388275334439.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388275334439.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;ICA 雙證套購</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原價 4288 元</span></span><span>，</span><strong>現價 3859.2 元</strong></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F71" target="_blank">CKA&amp;ICA 雙證套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:#242b3c; text-align:center"><span><span><img alt="1707388329473176.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388329473176.png" width="270" referrerpolicy="no-referrer"></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>RVFA&amp;LFD210-CN 套購</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原價 2208 元</span></span><span>，<span><span style="color:#ab1942"><strong>現價 1987.2 元</strong></span></span></span></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F63" target="_blank">RVFA&amp;LFD210-CN 套購_專業課程-Linux Foundation 開源軟件學園</a></span></p><p style="color:#242b3c; text-align:center">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9)"><span><span>查看更多 LFOSSA 培訓、認證及套購產品：</span></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank"><span>培訓</span></a><span>：<span style="color:#245bdb"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank">Linux 系統管理_雲技術線上自學課程-Linux Foundation 開源軟件學園</a></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank"><span>認證</span></a><span>：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank">Linux 自學考試認證-Linux Foundation 開源軟件學園</a></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank">套購</a>:&nbsp;<span style="color:#245bdb"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank">Linux Foundation 開源軟件學園-Linux_雲技術_Kubernetes 專業考試認證_K8s_CKA_CKS</a></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:justify">&nbsp;</p><p><span><span><span>點擊&nbsp;<span style="color:#ff0000"><strong>此網址</strong></span><strong>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2F" target="_blank">Linux Foundation 開源軟件學園-Linux_雲技術_Kubernetes 專業考試認證_K8s_CKA_CKS</a>&nbsp;</strong></span>進入 LFOSSA 官網。瞭解更多 Linux 基金會相關課程和認證考試。</span></span></p><p>&nbsp;</p><p><span><strong><span style="color:#000000">來自 LFOSSA 開源軟件學園的</span>温馨提示：</strong></span></p><p><span><span><strong>特別需要注意的是，</strong><strong>Linux 基金會</strong><strong>發佈了&nbsp;</strong><strong>LF</strong><strong>認證考試政策的變更如下</strong>：</span></span></p><p><span><span style="color:#d83931"><strong>自</strong><strong>北京時間</strong><strong>2024 年 4 月 1 日上午 8 時起，所有 36 個月有效期的</strong><strong>LF</strong><strong>認證考試將縮短為 24 個月有效期。任何在&nbsp;</strong><strong>UTC</strong><strong>&nbsp;時間 2024 年 4 月 1 日 00:00 之前，安排並通過考試的學員仍然將獲得 36 個月的認證有效期。</strong></span></span></p><p><span><span>由於考試需求將會急劇增加，我們建議考生儘早安排預約 CKA 考試。你可以在這裏瞭解有關詳情：</span></span></p><p><span><span><strong>考試政策的公告</strong>——</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247498227%26idx%3D1%26sn%3D21e81f4521e07892176dc002c59a9162%26chksm%3Dc3595926f42ed030c326966c0fa15c38b502565abf76a791450f1307a12eb9404af897e8b596%26scene%3D21%23wechat_redirect" target="_blank">CNCF 認證考試更新公告</a></span></p><p><span><span><strong>考試貼士</strong>&nbsp;——</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247502744%26idx%3D1%26sn%3Dc67bc4b2851fa8fb16e88e8036810bae%26chksm%3Dc3596b4df42ee25b6513756e28352d3c2b9258a1aa2c352d15eed8aedb2116abacaa1daf085f%26scene%3D21%23wechat_redirect" target="_blank">LF 認證考試考生貼士</a></span></p></div></div></div></div></div></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 10:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282019</guid>
            <link>https://www.oschina.net/news/282019</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[我的歷時一年的獨立開發故事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 2023 年 2 月 5 日，當我從赫爾辛基飛往上海浦東機場時，並沒有預見到接下來一年的生活將會是怎樣的。經過幾個月悠閒輕鬆的日子後，我開始了獨立開發的征程。首先我會簡要介紹一下成果，然後分享我對獨立開發的看法以及一些技術層面的經驗。 經過一年的努力，截至目前，我的成果如下：</p><ul><li>支出 2000 美元，主要雲服務支出</li><li>收入 0，註冊用户 0</li><li>一個可運行的系統： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flets-script.com" target="_blank">https://lets-script.com</a></li></ul><p>我不反對獨立開發，但要認清現實，如果你的目標是通過獨立開發發財致富，那麼一個可能的結果是（開玩笑）：</p><ol><li>一年，眾叛親離</li><li>二年，妻離子散</li><li>三年，灰飛煙滅</li></ol><p>如果你有這樣的覺悟，或者不是從致富的角度出發，獨立開發也是一種寶貴的經歷。</p><p>接下來，我將分享我開發的產品以及一些技術經驗。請允許我以一個業餘選手的身份談論這些想法。。</p><h2>產品理念</h2><p>我希望打造一個以腳本為核心的簡單任務執行平台。市面上的產品往往認為 Shell 腳本不夠友好，因此會在外層添加各種包裝，有的使用 YAML 配置，有的採用自定義編程邏輯，類似於 Github Action。然而，Github 用一個 checkout 插件來完成 git checkout 的功能，我認為直接使用 git 更為簡潔明瞭。如果你認為 Shell 腳本已經足夠強大、方便且經得起考驗，那又何必在外面再加一層，用一些功能不強大的方法來掩蓋 Linux 腳本系統的強大呢？</p><p>lets-script.com 允許用户部署他們自己的任務運行服務器，無論是在家中、公司還是在互聯網上。目前，系統共享了兩個運行服務器，一個位於日本，另一個在我家中。</p><h2>不要迷信雲和雲服務</h2><p>雲服務和人工智能無疑都非常有價值。然而，在媒體和雲服務提供商的大力宣傳下，用户和開發者可能會被迷惑，失去獨立思考的能力。</p><p>雲服務雖然發展迅速，但單體軟件同樣在迅速發展。如果你沒有充分的理由，就不要輕易將自有系統替換為雲服務。比如，消息隊列，用微軟的 Eventbus 替代 RabbitMQ？我認為毫無必要，何必輕易地將自己鎖定在一個廠商身上呢？我最初也使用了 Eventbus，但經過深思熟慮，最終還是切換回了 RabbitMQ。我開始使用 Azure 的容器應用服務，但後來也切換到了 Nginx 架構，所有這些措施都使我後來可以輕鬆地遷移到其他雲平台。</p><h2>不要完全依賴第三方登錄</h2><p>要保持自有的登錄系統始終可用，然後再選擇性的加入協作登錄系統。我的系統在初期也是使用第三方的登錄系統。後來，架設自己的郵件服務器，重新實現用户登錄功能。以 email 為中心的登錄系統是非常可靠的系統。</p><h2>Cloudflare 的誘惑和侷限</h2><p>個人認為 Cloudflare 是一個非常具有特色的產品，也挺慷慨，一般個人項目基本上不需要花錢。在 https 和 http 場景下幾乎是首選，我把所有的域名都交給 Cloudflare 解析了。比如我家裏的一台服務器目前用作 lets-script 的命令執行服務器。網址是 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fworker-2.lets-script.com" target="_blank">https://worker-2.lets-script.com</a> , 只要家裏的服務器上安裝一個 Cloudlared 服務，該 https 加密的網址始終可用。</p><p>但也不要盲目信賴 Cloudflare。它並不適用於所有場景，有時使用你自己的 Nginx 才是最終的解決方案。比如，524 錯誤，默認超時時間為 100 秒（企業訂閲可以自定義超時時間），超過 100 秒就會返回 524 錯誤。而我的系統，在控制枱交互的情況下，執行 10 分鐘的任務是很常見的，因此無法通過 Cloudflare 代理。此外，text/event-stream 或者 ndjson 都無法通過 Cloudflare 代理，至少目前官方不支持。雖然官方支持 WebSocket，但我最終選擇了 WebSocket 作為我的系統的解決方案，例如，當您運行系統的 Hello World 示例時，您可以清晰地感受到實時輸出。</p><p>接下來談談我對獨立開發的反思。</p><h2>獨立開發是低效的，是一種過時的生產方式</h2><p>除了少數基於命令行的工具類軟件，其它軟件都需要橫跨許多技術，它天然需要協作開發，用一己之力去完成是非常低效的。比如，我的系統，開始使用 Reactjs，Gatsbyjs 使用 js 開發，後來不用框架了，用自己的半通用性 js 庫，切換到 typescript，然後大量自定義 Codemirror 的功能，在後端的 Webflux 之間來回切換，無論專注於那一邊都可以將代碼寫的很穩定，但是兩頭兼顧，兩邊的代碼質量都打折扣。</p><h2>獨立開發需要做好充足的準備，包括技術、資金、時間和心理準備。</h2><p>由於社會形態的差異，中國人從事獨立開發更需要有強大的心理準備，因為獨立開發意味着你像一個工匠，將注意力轉移到了產品之上，從而於社會產生距離，要控制好這種孤獨感，保持身心健康。</p><h2>如果你正在考慮獨立開發，請務必慎重考慮。</h2><p>如果你的主要目的是經濟回報，更加需要慎重考慮。</p><p>最後，我的獨立開發的產品已經完成，從 azure 平台遷移到一家日本公司的平台之後預計費用減半，就當作日常娛樂開支，讓它長期運行吧。</p><p>此外，我正在積極尋找一份軟件開發的工作，如果你有碰巧閲讀到本文，請幫助我擴散和聯繫，<em><strong>非常感謝</strong></em>。</p><p>我的聯繫方式： <a href="https://www.oschina.net/action/GoToLink?url=mailto%3Ajianglibo%40hotmail.com" target="_blank">jianglibo@hotmail.com</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 09:48:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/jianglibo/blog/11046245</guid>
            <link>https://my.oschina.net/jianglibo/blog/11046245</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GreptimeDB v0.7 發佈 — 全面支持雲原生監控場景]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在上週，我們公佈了 GreptimeDB 2024 路線圖，揭示了今年 GreptimeDB 的幾個重大版本計劃。隨着三月初春的到來，首個適用於生產級別的 GreptimeDB 開源版也在萬物復甦的「驚蟄」時節如約而至。v0.7 版本標誌着我們向生產就緒版本邁出的重要一步，我們歡迎社區的每一位成員積極參與使用，並提供寶貴的反饋意見。</p><p>從 v0.6 到 v0.7，Greptime 團隊取得了顯著的進步：<strong>累計合併了 184 個 Commits，修改了 705 個文件，包括 82 項功能增強、35 項 Bug 修復、19 次代碼重構，以及大量的測試工作。</strong> 這期間，一共有 <strong>8 名獨立貢獻者</strong>參與 GreptimeDB 的代碼貢獻，<strong>特別感謝 Eugene Tolbakov 作為 GreptimeDB 首位 committer，持續活躍在 GreptimeDB 的代碼貢獻中</strong>，和我們一同成長！</p><blockquote><p><strong>更新重點（省流版）</strong><strong>Metric Engine</strong>：針對可觀測場景設計的全新引擎可被推薦使用，能處理大量的小表，適合雲原生監控場景； <strong>Region Migration</strong>：優化了使用體驗，可以通過 SQL 方便地執行 Region 遷移； <strong>Inverted Index</strong>：高效定位用户查詢所涉及數據段，顯著減少掃描數據文件所需 IO 操作，加速查詢過程。</p></blockquote><blockquote><p>v0.7 是 GreptimeDB 開源以來少數幾次的重大版本更新之一，此次我們也將在視頻號直播。瞭解更多功能細節、觀看 demo 演示，或者和我們核心開發團隊深入交流，歡迎參與下週四（3 月 14 日）晚 19:30 的直播。</p></blockquote><h2>Region Migration</h2><p>Region Migration 提供在 Datanode 之間遷移數據表的 Region 的能力，藉助這個能力，我們可以容易地實現熱點數據遷移，以及負載平衡的水平擴展。GreptimeDB 在發佈 v0.6 時曾提到初步實現了 Region Migration，此次版本更新完善並優化了使用體驗。</p><p>現在，我們可以通過 SQL 方便地執行 Region 遷移：</p><pre><code class="language-sql">select migrate_region(
    region_id,
    from_dn_id,
    to_dn_id,
    [replay_timeout(s)]);
</code></pre><p><img src="https://oscimg.oschina.net/oscnet/up-6b527cc6319d52e06cda4b35c8481e3f486.png" alt="" referrerpolicy="no-referrer"></p><h2>Metric Engine</h2><p>Metric Engine 是針對可觀測場景來設計的一個的全新引擎，它的主要目標是能處理大量的小表，特別適合雲原生監控比如使用 Prometheus 的場景。通過利用合成的寬表，這個新的 Engine 提供指標數據存儲和元數據複用的能力，「表」在它之上變得更輕量，它可以克服現有 Mito 引擎的表過於重量級的一些限制。</p><p><img src="https://oscimg.oschina.net/oscnet/up-34283d2899e494d63d72b44a78def7c94a9.png" alt="" referrerpolicy="no-referrer"></p><ul><li><p><strong>圖例 - 原始 Metric 數據</strong></p><ul><li>以下六個 Node Exporter 的 Metrics 為例。在 Prometheus 為代表的單值模型系統中，即使是關聯度很高的指標也需要拆成若干個分開存儲。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-9f8b2bb0d60477ad713d884fea5bed395ef.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>圖例 - 用户視角的邏輯表</strong></p><ul><li>Metric Engine 原汁原味地還原了 Metrics 的結構，用户見到的就是寫入的 Metrics 結構。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-7b84dc5597d1cc9db0eb3fd0c6dc5309637.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>圖例 - 存儲視角的物理表</strong></p><ul><li>在存儲層，Metric Engine 進行了映射，使用一張物理表來存儲相關的數據，能夠降低存儲成本，並支撐更大規模的 Metrics 存儲。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-cae0172c4a2c1b78bee1eee55e9d221e63f.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>圖例 - 接下來的研發計劃：Fields 自動分組</strong></p><ul><li>在實際場景產生的 Metrics 中，大部分都是有關聯性的。GreptimeDB 可以自動推導相關的指標並放合併到一起，不僅能跨 Metrics 減少時間線的數量，而且對於關聯查詢也很友好。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-27c251355fb040fe61da01dc3b819b88edb.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>存儲成本優化</strong></p></li></ul><p>基於 AWS S3 存儲後端進行成本測試，各寫入約三十分鐘的時長的數據，總和寫入量約 30w row/s 。統計過程中的各個操作發生的次數，根據 AWS 的報價估算成本。測試過程中 index 功能均開啓。</p><p>報價參考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fs3%2Fpricing%2F" target="_blank">https://aws.amazon.com/s3/pricing/</a> 的 Standard 等級</p><p><img src="https://oscimg.oschina.net/oscnet/up-621ba7795c14b78da54e214601f04a07a59.png" alt="" referrerpolicy="no-referrer"></p><p>從上述測試表格可以看到，Metric Engine 能夠通過減少物理表的數量大幅降低存儲成本，各階段操作次數均有數量級減少，折算的綜合成本相比 Mito Engine 能降低八倍以上。</p><h2>Inverted Index</h2><p>Inverted Index 作為新引入的索引模塊，旨在高效定位用户查詢所涉及數據段，顯著減少掃描數據文件所需 IO 操作，加速查詢過程。TSBS 測試場景下場景性能平均提升 50%，部分場景性能提升近 200%。Inverted Index 的核心優勢包括：</p><ol><li>開箱即用：系統自動生成合適的索引，用户無需額外指定；</li><li>功能實用：支持多列列值的等值、範圍和正則匹配，確保在多數場景下都能迅速定位和過濾數據；</li><li>靈活適應：自動調控內部參數以平衡構建成本和查詢效率，有效應對不同場景的索引需求</li></ol><ul><li><strong>圖例 - Inverted Index 的邏輯表示及數據定位過程</strong><ul><li>用户在多個列指定過濾條件，經過 Inverted Index 的快速定位，能排除掉大部分不匹配的數據段，最終得到較少的待掃描數據段，實現查詢加速。</li></ul></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-6ed07495343672eeb6a785d084409529bc8.png" alt="" referrerpolicy="no-referrer"></p><h2>其他更新</h2><p><strong>1. 數據庫的管理功能得到顯著增強</strong></p><p>我們對 information_schema 表進行了大幅補充，新增了 SCHEMATA 和 PARTITIONS 等信息。此外，新版本引入了眾多新的 SQL 函數以實現對 DB 的管理操作。例如，現在通過 SQL 即可觸發 Region Flush、執行 Region 遷移，還可以查詢 procedure 的執行狀態等。</p><p><strong>2. 性能提升</strong></p><p>在 v0.7 版本中，對 Memtable 進行了重構，提升了數據掃描速度並降低了內存佔用。同時，我們針對對象存儲的讀寫性能也做了許多的改進和優化。</p><h2>升級指南</h2><p>由於新版本存在一些重大變更，本次 v0.7 發佈需要停機升級，推薦使用官方升級工具，大致升級流程如下：</p><ol><li>創建一個全新的 v0.7 集羣</li><li>關閉舊集羣流量入口（停寫）</li><li>通過 GreptimeDB CLI 升級工具導出表結構和數據</li><li>通過 GreptimeDB CLI 升級工具導入數據到新集羣</li><li>入口流量切換至新集羣</li></ol><p>詳細升級指南請參考：</p><ul><li>中文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.cn%2Fuser-guide%2Fupgrade" target="_blank">https://docs.greptime.cn/user-guide/upgrade</a></li><li>英文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.com%2Fuser-guide%2Fupgrade" target="_blank">https://docs.greptime.com/user-guide/upgrade</a></li></ul><h2>未來展望</h2><p>我們下一個重要的里程碑在四月份，屆時將推出 v0.8 版本。這一版本將引入 GreptimeFlow，一款優化的流計算方案，專門用於 GreptimeDB 數據流中執行連續聚合操作。考慮到靈活性的需求，GreptimeFlow 既可以集成進 GreptimeDB 計算層共同部署，也能作為獨立服務部署。</p><p>除了功能層面的不斷升級，我們在版本性能方面也在持續進行優化，v0.7 版本的性能雖然對比之前已經有了巨大的提升，但在可觀測場景下距離部分主流方案還有一些差距，這也將是我們接下來的重點優化方向。</p><p>歡迎閲讀 GreptimeDB Roadmap 2024，全面瞭解我們全年的版本更新計劃。也歡迎各位參與代碼貢獻或功能、性能的反饋和討論，讓我們攜手見證 GreptimeDB 持續的成長與精進。</p><h3>關於 Greptime：</h3><p>Greptime 格睿科技致力於為智能汽車、物聯網及可觀測等產生大量時序數據的領域提供實時、高效的數據存儲和分析服務，幫助客户挖掘數據的深層價值。目前主要有以下三款產品：</p><ul><li><p>GreptimeDB 是一款用 Rust 語言編寫的時序數據庫，具有分佈式、開源、雲原生和兼容性強等特點，幫助企業實時讀寫、處理和分析時序數據的同時降低長期存儲成本。</p></li><li><p>GreptimeCloud 可以為用户提供全託管的 DBaaS 服務，能夠與可觀測性、物聯網等領域高度結合。</p></li><li><p>GreptimeAI 是為 LLM 應用量身定製的可觀測性解決方案。</p></li><li><p>車雲一體解決方案是一款深入車企實際業務場景的時序數據庫解決方案，解決了企業車輛數據呈幾何倍數增長後的實際業務痛點。</p></li></ul><p>GreptimeCloud 和 GreptimeAI 已正式公測，歡迎關注公眾號或官網瞭解最新動態！對企業版 GreptimDB 感興趣也歡迎聯繫小助手（微信搜索 greptime 添加小助手）。</p><p>官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreptime.cn%2F" target="_blank">https://greptime.cn/</a></p><p>GitHub: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb" target="_blank">https://github.com/GreptimeTeam/greptimedb</a></p><p>文檔：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.cn%2F" target="_blank">https://docs.greptime.cn/</a></p><p>Twitter: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FGreptime" target="_blank">https://twitter.com/Greptime</a></p><p>Slack: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.greptime.com%2Fslack" target="_blank">https://www.greptime.com/slack</a></p><p>LinkedIn: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fgreptime" target="_blank">https://www.linkedin.com/company/greptime</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 09:46:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6839317/blog/11046126</guid>
            <link>https://my.oschina.net/u/6839317/blog/11046126</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年 DevOps 報告：文化、用户中心性和技術能力驅動組織成功]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#060607">《</span>2023 年 DevOps 報告<span style="background-color:#ffffff; color:#060607">》強調了健康文化、用户中心性、技術能力和靈活基礎設施在提高組織績效、團隊協作和員工福祉方面的重要性，並探討了這些因素如何通過各種實踐和流程相互影響。</span></p><p><img alt="" height="308" src="https://static.oschina.net/uploads/space/2024/0307/154350_urjp_4700705.png" width="366" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#060607">以下是報告的主要發現和內容概述：</span></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>1. 研究目標和方法</strong></p><ul><li>報告旨在為領導者和實踐者提供影響組織、團隊和員工福祉的見解。</li><li>研究使用了嚴格的統計評估方法，調查了超過 36,000 名專業人士，覆蓋各種規模的組織和多個行業。</li><li>研究方法包括定量調查研究、日誌分析和模擬信念和權力傳播的方式。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>2. 關鍵發現</strong></p><ul><li><strong>文化的重要性</strong>：健康的文化是建立技術能力、提高技術績效、實現組織績效目標和幫助員工成功的關鍵。</li><li><strong>用户中心性</strong>：以用户為中心的開發方法可以顯著提高組織績效。</li><li><strong>軟件交付性能</strong>：加快代碼審查是提高軟件交付性能的有效途徑。</li><li><strong>技術能力</strong>：高質量的文檔可以增強技術能力對組織績效的影響。</li><li><strong>基礎設施的靈活性</strong>：雲計算通過提供靈活的基礎設施，有助於提高組織績效。</li><li><strong>文化投資</strong>：健康的組織文化對員工福祉和組織績效有積極影響。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>3. 技術能力和流程</strong></p><ul><li>報告探討了人工智能、基於主幹的開發、鬆散耦合架構、持續集成和快速代碼審查等技術能力如何預測性能。</li><li>這些技術能力對團隊績效、組織績效、軟件交付性能和運營性能有積極影響。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>4. 文檔的作用</strong></p><ul><li>高質量的文檔是基礎，它推動了技術能力的實施，並放大了這些能力對組織績效的影響。</li><li>文檔質量對團隊績效、組織績效和運營性能有顯著的正面影響。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>5. 可靠性和性能</strong></p><ul><li>可靠性實踐（如服務水平目標和自動化）對運營性能有顯著影響，從而提高了團隊和組織績效。</li><li>高運營性能可以減少員工的倦怠感，提高生產力和工作滿意度。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>6. 基礎設施的靈活性</strong></p><ul><li>使用公共雲的團隊在基礎設施靈活性上有所提高，這反過來又提高了組織績效。</li><li>雲計算對員工福祉有積極影響，包括減少倦怠、提高工作滿意度和生產力。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>7. 文化投資</strong></p><ul><li>健康的文化對員工福祉和組織績效有積極影響，包括減少倦怠、提高工作滿意度和生產力。</li><li>文化對技術能力的實施和團隊績效有積極影響。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>8. 多樣性和包容性</strong></p><ul><li>報告發現，被認定為代表性不足的羣體和女性或自我描述為女性的人在倦怠感上更高。</li><li>這些羣體可能承擔更多的重複性工作，這可能解釋了他們報告的更高倦怠水平。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>9. 新員工的生產力</strong></p><ul><li>新員工的生產力低於有經驗的團隊成員，但高質量的文檔和人工智能的集成可能有助於他們更快地提高生產力。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>10. 研究方法和社區參與</strong></p><ul><li>報告詳細描述了研究方法，包括如何生成假設、開發調查問卷、收集和分析數據。</li><li>鼓勵讀者加入 DORA 社區，分享經驗，學習並從他人的改進實踐中獲得靈感。</li></ul><p><span style="background-color:#ffffff; color:#060607">報告還包含了關於如何解讀報告中的模型和圖表的附錄，以及如何通過模擬和貝葉斯統計來探索數據的可能解釋和不確定性。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">報告詳情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「開源中國 APP - 報告模塊」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下載地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前僅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:48:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281976</guid>
            <link>https://www.oschina.net/news/281976</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 加速引擎 PAI-TorchAcc：整體介紹與性能概述]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者：沈雯婷、黃奕桐、艾寶樂、王昂、李永</p><h1>1、簡介</h1><p>PAI-TorchAcc(Torch Accelerator) 是阿里雲人工智能平台開發的 Pytorch 上的大模型訓練加速框架。</p><p>PAI-TorchAcc 提供了一套基於 Pytorch 的簡潔、易用的接口，無需進行模型轉換就可以無縫地接入 HuggingFace 上的模型，並用多種分佈式策略進行訓練加速。</p><p>PAI-TorchAcc 藉助社區 PyTorch/XLA，通過 LazyTensor 技術將 Pytorch 代碼轉換為靜態執行圖，基於計算圖，結合阿里雲上的計算資源情況，進行了大量的 GPU 硬件上模型訓練的針對性分佈式優化、計算優化。</p><p>得益於簡單的模型接入方式、基於計算圖的優化，PAI-TorchAcc 能夠靈活地支持各種大模型的多種規模，兼容不同的硬件。PAI-TorchAcc 支持常見大模型 1B-175B 的訓練，訓練吞吐相對 PyTorch 原生、Megatron-LM 均有提升，如 LLaMA 系列模型，相比 PyTorch 原生提升了 140%，相比 Megatron-LM 提升了 5%，在 A100 上 MFU 達到 70%，8 卡到 128 卡線性加速比達到 15.6X。</p><h1>2、背景和需求</h1><h2>2.1 背景</h2><ul><li><strong>大模型訓練</strong></li></ul><p>近年來，大語言模型、視頻生成類模型迅速發展，它們基於龐大的文本、圖片、視頻等數據集進行訓練，執行多種自然語言處理、圖像生成、視頻生成等任務，具備強大的理解和生成能力。隨着計算資源和技術的不斷進步，大模型的參數量已增長到數億甚至數萬億級別，例如 LLaMA、GPT-3、通義千問、Sora 等，這些模型在許多基準測試上表現出了前所未有的性能。</p><p>然而，訓練大模型需要極高的成本。比如使用 Megatron-LM 預訓練一個 OPT-175B 模型需要上千張 A100 訓練 2 個月[1]，硬件利用率 MFU 約 47%，期間因為硬件故障經歷了幾十次 checkpoint 的加載和續訓練。使用 PyTorch FSDP 進行 LLaMA-2-70B 的微調也需要 16 張 A100 運行約 13.5 小時[2]。NVIDIA A100、H100 等硬件資源價格高昂且不易獲取，市面上也逐漸出現了其他性價比更高的硬件資源。</p><p>加速不同的大模型的預訓練、續訓練、微調，充分利用不同的硬件資源，提升資源利用率，是降低大模型訓練成本的一個有效途徑。</p><ul><li><strong>Megatron-LM</strong></li></ul><p>NVIDIA Megatron-LM[3]是一個基於 PyTorch 的分佈式訓練框架，用來訓練基於 Transformer 的大模型。Megatron-LM 綜合應用了數據並行、模型並行、流水並行來實現 GPT-3 等特定模型的訓練。然而，不同的大模型、訓練數據集接入 Megatron-LM 十分不靈活，需要將 checkpoint 和數據格式進行轉換。同時，Megatron-LM 雖然對一些模型算子做了手動的優化，在面對不同模型的不同計算模式時，難以自動地應用這種手動的優化。</p><ul><li><strong>DeepSpeed</strong></li></ul><p>DeepSpeed[4]是微軟開源的一個 PyTorch 上的大模型分佈式訓練框架，支持 ZeRO 和流水並行，並且可以結合 Megatron-LM 運行 3D 並行。DeepSpeed 已經成為 HuggingFace transformers 庫中一個訓練組件。然而 DeepSpeed 性能表現較差，並且和 Megatron-LM 同樣存在面對不同計算模式時無法靈活優化的限制。</p><ul><li><strong>PyTorch/XLA</strong></li></ul><p>PyTorch/XLA[5]將 PyTorch 和 OpenXLA 相結合，使用 LazyTenor 技術，將 PyTorch 代碼轉換為靜態執行圖，在靜態圖上進行計算圖優化和後端編譯優化。Pytorch/XLA 主要是針對 TPU 場景進行優化，在 GPU 上還存在一定問題和優化空間，如不支持 Transformers 模型常用的 FlashAttention 加速算子、不支持 torchrun 拉起、計算通信 Overlap 差、顯存開銷大等問題。</p><h2>2.2 需求</h2><p>基於以上背景，我們需要一個大模型分佈式訓練引擎，能夠方便接入多變的 PyTorch 模型，尤其是 Transformer 類模型，兼容多種硬件。在不同模型變化的計算模式下，在不同硬件變化的硬件架構和計算、訪存能力下，能夠自動地對計算進行優化，尤其在阿里雲的硬件上能夠表現較高的性能。同時，大模型導致單卡內存和顯存無法完全放下，不同的模型需要結合不同的分佈式策略，合理通信，完成多卡訓練並提升線性加速比。</p><h1>3、PAI-TorchAcc 核心技術特性</h1><h3>靈活的模型接入</h3><ul><li>支持 LLaMA 系列、Qwen、BaiChuan、ChatGLM、OLMo、Bloom 等常見的大模型 1B-175B 的訓練；</li><li>無縫對接 HuggingFace 中的模型；</li><li>一鍵接入和加速 Pytorch 模型。</li></ul><h3>千億級模型參數量</h3><ul><li>已經支持 1B 到 175B 大模型訓練；</li></ul><h3>全面的訓練模式</h3><ul><li>支持混合精度訓練，包括 Float32、Float16、BFloat16 等；</li><li>支持 Pytorch 模型的預訓練、微調和續訓練。</li></ul><h3>組合的分佈式策略</h3><ul><li>支持 Data Parallel、Tensor Parallel、Sequence Parallel、Fully Sharded Data Parallel、Pipeline 等分佈式策略及其組合。</li></ul><h3>自動計算優化和顯存優化</h3><ul><li>使用手動的 Gradient Checkpoint 和自動的 Rematerialization 降低峯值顯存；</li><li>自動進行顯存規劃和管理，降低峯值顯存和減少顯存碎片化；</li><li>自動對 Kernel 進行編譯優化，提高計算效率；</li><li>自動接入 SOTA 的高性能 Kernel。</li></ul><h3>兼容多種硬件</h3><ul><li>兼容 NVIDIA A100/800, H100/800, V100 等；</li><li>兼容阿里雲上靈駿集羣的硬件資源。</li></ul><h3>與現有框架對比</h3><p><img src="https://oscimg.oschina.net/oscnet/up-16e4c9ebf76f202837eb23fa7d35588c6a8.png" alt="" referrerpolicy="no-referrer"></p><h1>4、PAI-TorchAcc 架構</h1><h2>4.1 總體架構</h2><p><img src="https://oscimg.oschina.net/oscnet/up-b1ac021283f5b408400fb4d7b8ce1ef1ce8.png" alt="" referrerpolicy="no-referrer"></p><p>PAI-TorchAcc 的架構自頂向下分為以下幾層：</p><ul><li><strong>模型層</strong>：支持計算機視覺、自然語言處理、語音合成等深度學習模型訓練的加速；</li><li><strong>算法庫</strong>：支持 HuggingFace Transfomers、PAI-EasyNLP、TIMM 等算法庫構建的模型；</li><li><strong>前端</strong>：支持以 PyTorch 為前端語言的模型訓練；</li><li><strong>Lowering</strong>：使用 LazyTensor、Symbolic Trace 等技術將前端代碼轉換為靜態執行圖;</li><li><strong>IR</strong>：使用多層中間表達，包含 High-Level 的設備無關的 IR 和 Low-Level 的設備相關的 IR，基於兩層 IR 上分別做計算圖優化和後端編譯優化。</li><li><strong>編譯優化引擎</strong>：TorchAcc 的編譯優化引擎包括計算圖優化引擎 TorchAcc Compiler 和多種後端編譯優化引擎 BladeDISC 和 OpenXLA。基於兩層 IR，進行分佈式優化、顯存優化、通信優化、計算優化以及算子調度和顯存管理等優化，生成優化的設備碼。</li><li><strong>硬件</strong>：最終產生硬件相關的設備碼在不同算力、帶寬和顯存的硬件設備上執行。</li></ul><h2>4.2 接口</h2><p>PAI-TorchAcc 抽取了一套簡潔的接口，靈活接入並加速任意的 Pytorch 模型，而不需要改動原有的模型代碼。</p><p>通過 PAI-TorchAcc 加速模型訓練一般需要三步：</p><ol><li>定義 torchacc.Config，並指定加速選項。</li><li>調用 torchacc.accelerate，並傳入 model 和 config，完成加速訓練的準備。</li><li>通過 torchacc.AsyncLoader 對 torch dataset_loader 進行封裝，加速數據加載。</li></ol><pre><code class="language-python">model = ...
  dataloader = ...

+ # 一行代碼加速模型，也可傳入 Config 配置更豐富的加速功能，如分佈式策略、編譯優化選項等
+ model = torchacc.accelerate(model)

+ # 異步加速數據加載
+ dataloader = torchacc.AsyncLoader(dataloader, model.device)

  model.train()
  for source, labels in dataloader:
      ...
</code></pre><h2>4.3 編譯優化</h2><p>PAI-TorchAcc 通過 LazyTensor、Symbolic Trace 等技術將前端 Pytorch 代碼轉換為靜態執行圖，並在靜態圖上進行自動優化，在分佈式的硬件設備上高效運行。</p><h2>4.4 計算圖優化</h2><p>在 Tensor Graph 上進行優化，這層優化基於 High-Level IR——StableHLO 進行。</p><ul><li>分佈式： 通過分圖和通信算子插入，完成流水並行、SPMD 等。</li><li>顯存優化：通過算子級別的顯存 Live range 和複用分析、靜態調度策略、自動重算、顯存管理優化等來減少顯存的峯值和碎片化。</li><li>計算優化：通過 CSE 等簡化計算，通過算子大粒度融合來優化訪存密集型算子，減少 kernel launch，減少訪存，提升計算效率；通過自動的計算圖匹配重寫的方式接入 Flash Attention 等高性能 Kernel。</li><li>通信優化：通過通信算子的合併、拆分、異步化以及算子的調度來提升通信效率，提高計算和通信的 overlap。</li></ul><h2>4.5 後端編譯優化</h2><p>在 Buffer Graph 上進行優化，這層優化基於 Low-Level 的 IR，包括 LHLO、LLVM IR 和多種 MLIR 的 dialect。</p><ul><li>多後端：支持 OpenXLA 和阿里自研的 BladeDISC 兩種編譯後端；</li><li>Lowering 和 Codegen：將上層的 StableHLO Lowering 成 LHLO 和多種 MLIR 的 dialect，並在各級 Lowering 過程中進行優化，最終表達為 LLVM IR，通過 LLVM 生成針對硬件的優化代碼；</li><li>Custom Call：High-Level IR 自動 Pattern rewrite 的優化 kernel，通過 custom call 調用。</li></ul><h1>5、實踐案例和性能</h1><p>PAI-TorchAcc 在 A100 上能夠達到 70% 的 MFU，並且在多卡下幾乎線性擴展（8 卡到 128 卡加速比 15.6X），在靈活支持各種模型的基礎上，性能能夠高於 Megatron-LM。我們在常見的開源大模型上做了性能測試，使用相同的硬件資源，PAI-TorchAcc 的訓練吞吐相對 PyTorch 原生、Megatron 均有提升，如 LLaMA 系列模型相對 PyTorch 原生提升了 140%，相對 Megatron 提升了 5%。</p><p>我們將在後續的系列文章中提供一個具體的實踐案例：PAI-TorchAcc 在 OLMo 模型訓練上的接入示例和加速效果，並且給出加速的來源分析。</p><h1>6、總結和未來展望</h1><p>PAI-TorchAcc 可以靈活接入 Pytorch 模型，並通過並行化策略、顯存優化、計算優化和調度優化等方法來加速大模型以及視覺類、語音類模型的訓練。PAI-TorchAcc 已經在常見大模型上如 LLaMA、LLaMA-2、BaiChuan、ChatGLM、QWen、OLMo、Bloom 取得了不錯的效果。<strong>未來我們將從以下方向繼續深入優化，以支持更多的場景，取得更好的加速效果。</strong></p><ol><li>Graph Capture 優化和子圖編譯：在生成計算圖的過程中遇到無法識別的算子將導致編譯失敗，我們將進一步優化 Graph Capture，並支持子圖的編譯優化。</li><li>自動分佈式：PAI-TorchAcc 提供了多種分佈式策略，然而在不同的模型和硬件上，使用哪種組合的分佈式策略、如何進行分圖能夠取得最優的性能，仍然需要根據經驗手動配置。PAI-TorchAcc 將藉助靜態計算圖和模型、硬件特性，做自動的分佈式。</li><li>AutoGC：藉助靜態計算圖和模型、硬件特性，自動進行 checkpoint 選點。</li><li>動態 Shape 性能優化：動態 Shape 導致重編譯引起的性能下降，當前我們通過分桶的方式減少了重編譯的次數，仍然存在大量的 padding，如何做更高性能的動態 Shape 支持，是一個深入優化的方向。</li><li>自研編譯優化引擎 BladeDISC 的優化。</li></ol><h1>引用</h1><p>[1] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2205.01068.pdf" target="_blank">https://arxiv.org/pdf/2205.01068.pdf</a></p><p>[2] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fram-efficient-pytorch-fsdp" target="_blank">https://huggingface.co/blog/ram-efficient-pytorch-fsdp</a></p><p>[3] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FNVIDIA%2FMegatron-LM" target="_blank">https://github.com/NVIDIA/Megatron-LM</a></p><p>[4] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2FDeepSpeed" target="_blank">https://github.com/microsoft/DeepSpeed</a></p><p>[5] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpytorch%2Fxla" target="_blank">https://github.com/pytorch/xla</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:46:12 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/11045933</guid>
            <link>https://my.oschina.net/u/5583868/blog/11045933</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[快手啓動鴻蒙原生應用開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">「華為終端雲服務」官博消息稱，快手宣佈全面擁抱鴻蒙生態，啓動快手 App 鴻蒙原生應用開發，將推出鴻蒙星河版快手 APP。</span></p><blockquote><p><span style="color:#000000">「快手為鴻蒙生態帶來更豐富的內容生態和領先的短視頻社交服務能力，HarmonyOS 也為數億快手用户帶來全場景短視頻社交新體驗和更流暢、智能、便捷的生活服務。」</span></p></blockquote><p><img height="474" src="https://oscimg.oschina.net/oscnet/up-126df7aa28662554855ae07406650e06d46.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">對此，快手官方也在評論區回覆稱，鴻蒙星河版快手 APP 將為廣大用户帶來全場景的短視頻社交新體驗，用户可以在華為手機、平板、車機等多個終端實現短視頻內容無縫接續，不因切換場景而中斷體驗。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:17:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281966</guid>
            <link>https://www.oschina.net/news/281966</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">開發工具供應商 Perforce Software <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perforce.com%2Fpress-releases%2Fannual-java-report-reveals-42-companies-are-dedicating-resources-developer" target="_blank">發佈</a>了一份 Java 社區年度調查結果，即 JRebel 2024 年 Java 開發人員生產力報告；提供了有關影響 Java 發展趨勢的關鍵因素的行業數據和分析。</span></p><p><span style="color:#000000">主要調查結果集中在提高 Java 生產力的方法上 —— 42% 的受訪者創建了專門的生產力團隊或工作組。今年的報告還發現了 Java IDE 偏好的變化、微服務數量的增加以及遠程部署時間的延長。</span></p><p><span style="color:#000000">調查發現<strong>對 Java 工具和人才的投資</strong>呈上升趨勢。60% 的受訪者表示他們的公司計劃在未來一年內增加 Java 開發人員，只有 13% 的受訪者表示不計劃增加 Java 開發人員，另有 27% 的受訪者表示不確定。</span></p><p><span style="color:#000000">雖然市場不景氣，但開發人員工具預算基本保持穩定。42% 的受訪者表示計劃增加 Java 工具預算，22% 的受訪者不打算增加工具預算，36% 的受訪者不確定。此外，31% 的受訪者表示他們的年度工具預算（每位開發人員）為 500 美元或以上，相較 2023 年的 22% 有所增長。</span></p><p><img height="231" src="https://oscimg.oschina.net/oscnet/up-7daaf894200c1a119c1d21b6d56e898ec2b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Perforce 首席技術官 Rod Cope 表示："Java 將繼續存在"。「這些數字共同傳遞出一個強烈的信息：Java 將繼續成為企業應用的核心部分。事實上，企業在大型 Java 應用程序方面的根深蒂固，將繼續成為整個開發人員生態系統僱用 Java 開發人員的推動力。」</span></p><p><span style="color:#000000">就開發人員<strong>最常用的 Java 版本而言</strong>，11% 的受訪者表示已經升級到了 Java 21；但仍有 24% 的受訪者表示他們正在使用 Java 8，18% 的受訪者正在使用 Java 11。</span></p><p><img height="372" src="https://oscimg.oschina.net/oscnet/up-205fcee58753d4df208b0e00bf9e72da113.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Perforce 表示，考慮到 Oracle 分別在 2022 年 3 月和 2023 年 9 月停止了對 Java 8 和 Java 11 的高級支持。因此，不受支持的 JDK 版本的高使用率意味着公司正在獲得第三方供應商提供的支持，如 Amazon Corretto、Azul Zulu 和 OpenLogic 等。且隨着 Oracle 加快長期支持 JDK 版本的頻率（從每三年一次到每兩年一次），預計 Java 21 的採用率將會增加。</span></p><p><span style="color:#000000">在 <strong>Java IDE 的偏好</strong>方面，IntelliJ IDEA 再次以 41% 的比例位居榜首。Eclipse 以 23% 位居第二，Microsoft Visual Studio Code 以 19% 的份額排名第三。此外，還有 84% 的 IntelliJ IDEA 用户表示，他們在 Java 開發實踐中還使用過其他 IDE，其中 VSCode 是最常見的選擇。</span></p><p><span style="color:#000000">受訪者的 <strong>Java 技術棧與</strong>往年相比大部分保持不變，Tomcat、Spring Boot 和 Jenkins 等主流技術仍遙遙領先。36% 的受訪者表示他們使用 Tomcat 作為主要應用程序的應用服務器，其次是 JBoss/Wildfly (15%)、WebLogic (12%)、WebSphere (10%)、Jetty (10%) 、Glassfish/Payara (8%)。</span></p><p><span style="color:#000000">微服務框架的結果也是類似的，67% 的受訪者使用 Spring Boot；其他分別是 DropWizard（11%）、Quarkus（8%）、Micronaut（5%）和 Vert.x（1%）。Jenkins 是迄今為止最流行的 CI/CD 技術，佔 37%。TeamCity 的使用率相較 2023 年增長了一倍多（10%）；其他技術的使用率基本保持不變，GitHub Actions（17%）、Travis CI（9%）、Circle CI（8%）和 Bamboo（7%）。</span></p><p><img height="458" src="https://oscimg.oschina.net/oscnet/up-4f9b117abee52a3c46b662a7c76b9502fc6.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Amazon Web Services 是最受歡迎的雲供應商，佔 31%，其次是 Microsoft Azure，佔 18%。表示不使用任何雲供應商的受訪者比例從去年的 21% 下降至 13%。</span></p><p><span style="color:#000000">當 Java 開發人員被問及，如果開發時間增加 10%，他們會怎麼做時？增加功能（26%）和提高測試覆蓋率（18%）等務實的答案名列前茅，但其他答案也包括"喝咖啡"和"消除技術債務"等。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jrebel.com%2Fsites%2Fdefault%2Ffiles%2Fpdfs%2Freport-jrebel-2024-dev-productivity.pdf" target="_blank">查看完整報告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281964/perforce-annual-java-report</guid>
            <link>https://www.oschina.net/news/281964/perforce-annual-java-report</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[如果企圖在人工智能上搞「小院高牆」，將會犯下新歷史錯誤]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 7 日上午 10 時，十四屆全國人大二次會議在梅地亞中心新聞發佈廳舉行記者會，中共中央政治局委員、外交部長王毅就「中國外交政策和對外關係」相關問題回答中外記者提問。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9567f8c994b50351b847eed70b2d4975657.png" referrerpolicy="no-referrer"></p><p>鳳凰衞視記者提問：國際社會非常關注人工智能問題，很多國家提出關於人工智能全球治理方案，我們關注到中國也提出了關於《全球人工智能治理倡議》，中方認為如何才能確保人工智能朝着真正有利於人類文明進步的方向發展？另外，中方對大國人工智能合作持何立場？</p><p>王毅説，人工智能進入爆發式發展的關鍵階段。我們主張發展與安全並重，既要擁抱新事物新機遇，也要裝好剎車再上路，共同推進人工智能全球治理。去年 10 月，習近平主席提出《全球人工智能治理倡議》，清楚闡明瞭中方的態度和主張。</p><p>我們關注的主要是三個確保：<strong>一是確保有益</strong>。人工智能的發展有利於人類共同福祉，符合人類倫理規範，符合國際法規則，符合人類文明進步方向。<strong>二是確保安全</strong>。人工智能始終處於人類控制之下，不斷提高可解釋性和可預測性，為此要建立各種風險評估和管控機制。<strong>三是確保公平</strong>。在聯合國框架下成立人工智能國際治理機構，各國都能在人工智能的發展進程中平等參與、平等受益。</p><p>王毅説，我還要強調的是，<strong>如果企圖在人工智能上也搞什麼「小院高牆」，將會犯下新的歷史錯誤，不僅阻擋不了各國的科技發展，還會破壞國際產業鏈供應鏈完整，削弱人類應對風險挑戰的能力</strong>。中國對與各國開展人工智能合作持積極開放態度，迄今已經與一些國家建立了對話機制。人工智能大國之間的合作很重要，發展中國家的能力建設也很重要。我們將適時向聯大提交「加強人工智能能力建設國際合作」的決議草案，促進各方加強技術共享，努力彌合智能鴻溝，不讓任何國家掉隊。謝謝！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281963</guid>
            <link>https://www.oschina.net/news/281963</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[星動紀元開源人形機器人訓練框架 Humanoid-Gym]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年 3 月 5 日，具身智能與人形機器人公司星動紀元聯合清華大學、上海期智研究院開源了<strong>人形機器人強化學習訓練框架 Humanoid-Gym</strong>。</p><ul><li>項目主頁：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsites.google.com%2Fview%2Fhumanoid-gym%2F" target="_blank">https://sites.google.com/view/humanoid-gym/</a></li><li>代碼倉庫：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Froboterax%2Fhumanoid-gym" target="_blank">https://github.com/roboterax/humanoid-gym</a></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-03d076aeda9ad21f6cc644bd6eeb25408c4.png" referrerpolicy="no-referrer"></p><p>公開資料顯示，星動紀元於 2023 年 8 月在北京成立，由清華大學交叉信息研究院孵化，致力於具身智能以及人形通用機器人技術和產品的研發。創始人陳建宇是清華大學交叉信息研究院助理教授、博士生導師，同時也是清華大學特聘研究員、擁有 10+年機器人和 AI 研發經驗。</p><p>這次開源的 Humanoid-Gym 框架，旨在通過精心設計的獎勵函數以及域隨機化技術， 顯著簡化人形機器人的訓練以及實現 sim-to-real 轉換的難度，從而解決由於人形機器人結構高度複雜性導致其在強化學習訓練以及從模擬環境向真實世界遷移（即 sim-to-real transfer）的過程中遇到的挑戰。</p><p>星動紀元表示，除了用 sim-to-real 驗證以外，另一個常見的做法是用第二個更高精度的仿真環境來做初步做驗證（sim-to-sim）。Humanoid-Gym 開源後，用户可以通過該框架輕鬆運用 sim-to-sim 轉換功能，先在更高精度的仿真環境 Mujoco 中進行初步驗證與篩選，從而提升 sim-to-real 轉換的效率和成功率。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-95a8171d1abfb99f48eb5c4100d0f64b981.png" referrerpolicy="no-referrer"></p><p>除此之外，該開源項目還引入了若干評估指標，用以衡量訓練策略的效果，包括但不限於速度追蹤、動作絲滑程度等。</p><p>目前，星動紀元有兩款型號的人形機器人產品：小星（1.2 米高）和小星 max（1.65 米高），來適配不同應用場景的需求。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6e747fd3917cdd43b86821147b1cc37e93c.png" referrerpolicy="no-referrer"></p><p>小星體型更小巧，動態性能強，可完成室內外跑、跳、高速行走等動作。小星 Max 為全尺寸人形機器人，身型高度和成年人相當，手臂、腰部以及全身其他部位具備更高的自由度，還配有高自由度靈巧手，未來目標場景是在工廠製造場景或服務場景，替代人類完成各種各樣較為精細的操作。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 06:36:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281958</guid>
            <link>https://www.oschina.net/news/281958</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微信即將推出原生 Linux 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>吾愛破解社區用户 @白水 1573 爆料，微信將迎來 Linux 原生版重構，全新 1.0 版本已開啓內測，並放出了測試截圖和安裝包。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9af837ce67f19fb7b329d4d0fb71207f1ea.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ed1aeefda777af4ff1f935bef63f397b5aa.png" referrerpolicy="no-referrer"></p><p>根據爆料，<strong>微信 Linux 原生版將支持 X86、ARM、龍芯 LoongArch64 架構，系統方面支持麒麟和統信 UOS</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-45d02b4e7f43abf0340d5c2eccc4338b445.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-4ea81dfeb9ddcea5859b67b6c9ce8607969.png" referrerpolicy="no-referrer"></p><p>網友總結原生 Linux 版微信使用體驗：</p><blockquote><h3>（一）優點</h3><p><span style="color:#333333">1、運行，不卡頓、不閃退、界面不花屏、託盤提醒正常</span><br><span style="color:#333333">2、能用小程序、視頻號、看一看、搜一搜</span><br><span style="color:#333333">3、手機端、電腦端消息同步</span><br><span style="color:#333333">4、截圖正常</span><br><span style="color:#333333">5、文件收發正常</span><br><span style="color:#333333">6、可以視頻、語音通話</span></p><h3>（二）暫存在缺點</h3><p><span style="color:#333333">1、消息不能撤回</span><br><span style="color:#333333">2、消息轉發不能多選</span><br><span style="color:#333333">3、截圖快捷鍵無效</span><br><span style="color:#333333">4.、文件（除視頻）接收雙擊無法調用本地應用，僅打開下載文件夾目錄</span><br><span style="color:#333333">5、不能發送語音消息</span><br><span style="color:#333333">6、只能拖入文件，不能拖出</span><br><span style="color:#333333">7、部分 Linux 發行版登錄失敗（疑是白名單，可以用麒麟商店舊微信登錄再安裝新微信解決）</span><br><span style="color:#333333">8、不能導入和導出聊天記錄</span><br><span style="color:#333333">9、部分發行版託盤顯示異常</span></p></blockquote><p>下載地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.cnxclm.com%2Fs%2FXOxIb%3Fpath%3D%252F" target="_blank">https://cloud.cnxclm.com/s/XOxIb?path=%2F</a></p><p><img height="474" src="https://oscimg.oschina.net/oscnet/up-9b3b17a7b964a53f15342935405455f1582.png" width="1884" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 04:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281936/wechat-linux-1-0-beta</guid>
            <link>https://www.oschina.net/news/281936/wechat-linux-1-0-beta</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | Google=開源，好評；Microsoft=閉源收入還低，差評]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.6</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/281751/swift-5-10-released" target="_blank">Swift 5.10 發佈</a></h3><p>Swift 5.10 中的完全數據隔離為下一個主要版本 Swift 6 奠定了基礎。Swift 6.0 編譯器將提供新的、可選的 Swift 6 語言模式，該模式將默認強制執行完全數據隔離，項目團隊將着手進行過渡消除所有用 Swift 編寫的軟件之間的數據競爭。</p><h3><a href="https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management" target="_blank">Linux 基金會推出 「反詐」 開源項目 Tazama，獲蓋茨基金會資助</a></h3><p style="margin-left:.0001pt; margin-right:0"><span><span><span><span>在比爾及梅琳達・蓋茨基金會（Bill &amp; Melinda GatesFoundation）的支持下，Linux 基金會慈善機構（LF Charities）宣佈推出 Tazama，這是一套用於實時欺詐預防的開源軟件解決方案。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-935f8d1d736dc3d5b53baa4a2e1caebd24b.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img height="754" src="https://oscimg.oschina.net/oscnet/up-a7d0f80f5cc09d8135b50ee8615dcfab582.png" width="3036" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1441019625%2FO3J0EzPjG" target="_blank">雪龍郎</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-d892b5e238e2be9cee6852210c513370dd2.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1644684112%2FO3JANzqLf" target="_blank">木遙</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-67b3f765a8ae3a15bca297368a0aa7ee939.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7ObcyT-kHe-pyhU5rCfFjQ" target="_blank">機器之心</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-c1dd9862156321ccd63412b122bf6c838d6.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmli%2Fautocut" target="_blank">https://github.com/mli/autocut</a></u></em></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p>&nbsp;<img height="1354" src="https://oscimg.oschina.net/oscnet/up-37f0bd8def5cbfad73ac2145f10540b8f91.png" width="2800" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1908be40e2e08058e93c95f9f86722ac5d1.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-7d1341f9d2e5187641d562c7134862c184d.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精選</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-4191abfd5a0da45ae85d2eb79430cc2e943.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">開源日報第 023 期：Google=開源，好評；Microsoft=閉源收入還低，差評</a></u></em></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">開源日報第 022 期：輕鬆復現 Sora 模型；事關 CUDA 兼容，英偉達禁止了；百度還差一個「遙遙領先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">開源日報第 021 期：閉源模型就是比開源安全；起訴 OpenAI 不能更贊同；中國算力產業出現五個真問題</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">開源日報第 020 期：為什麼王炸都來自 OpenAI；Pingora 最好不要用 YAML 當配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">開源日報第 019 期：我讓 AI 用 C 語言寫一個算法；微軟三進制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">開源日報第 018 期：蘋果十年造車夢碎；這個開源項目有點...「大膽」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">開源日報第 017 期：MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 04:11:08 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281931</guid>
            <link>https://www.oschina.net/news/281931</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Node.js 新版官網開啓 Beta 測試：全新現代化 UI、優化交互]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Node.js 新版官網已開啓 Beta 測試，體驗地址：<strong><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbeta-node-js-org.vercel.app%2Fen" target="_blank">https://beta-node-js-org.vercel.app/en</a></u></em></strong>。</p><ul><li><strong>Node.js 新版官網首頁</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-d7f75fbfacc0c0f7aa4bd49a44845da9c0e.png" referrerpolicy="no-referrer"></p><ul><li><strong>當前官網首頁</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-d7fdf3a71b012fa030e0d8da045acd8a078.png" referrerpolicy="no-referrer"><br><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnodejs.org%2Fen" target="_blank">https://nodejs.org/en</a></u></em></p><p>可以看到，與當前版本相比，新版官網的視覺效果、頁面佈局、展現內容都有了很大的提升，整體上更大氣、更現代化。而且首頁關於 Node.js 的介紹也變得更突出、描述更全面。</p><p>新版官網最大的交互變化是在首頁添加了「全局搜索」入口，方便用户隨時檢索文檔、博客、下載等信息。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c9984afc8c57cf2cc9b031519ad713980ba.png" referrerpolicy="no-referrer"></p><p>其他子頁面一覽：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5219eed54c5df5855bb21a3c939725e914b.png" referrerpolicy="no-referrer"></p><p><img height="1854" src="https://oscimg.oschina.net/oscnet/up-82a9406af23007a8c812f31fd7c8bdce52f.png" width="3360" referrerpolicy="no-referrer"></p><p><img height="1852" src="https://oscimg.oschina.net/oscnet/up-c626de0d15afa528c4f04eb59658c79635e.png" width="3360" referrerpolicy="no-referrer"></p><p><img height="1858" src="https://oscimg.oschina.net/oscnet/up-9f4190b429a1060ceb08600f74698605af6.png" width="3360" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-432b101ae6fdf83b85ce42d68b8f7ca2b68.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281899/beta-node-js-org</guid>
            <link>https://www.oschina.net/news/281899/beta-node-js-org</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[零一萬物開源 Yi-9B，代碼數學綜合能力全面增強]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">零一萬物<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0CXIBlCZ7DJ2XjYT6Rm8tw" target="_blank">宣佈</a>開源 Yi-9B 模型，並聲稱該模型是當前 Yi 系列模型中的「理科狀元」——代碼和數學能力表現最佳；不偏科，中文能力也很強。「這是繼今年 1 月 23 日開源多模態模型 Yi-VL-34B 之後，零一萬物在開源方向上的又一重要成果。 」</span></p><p><span style="color:#000000">根據介紹，Yi-9B 是目前 Yi 系列模型中<strong>代碼和數學能力最強</strong>的模型，它的基本信息如下：</span></p><ul><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">參數大小：Yi-9B 的實際參數為 8.8B。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">上下文長度：與 Yi 系列其他模型一樣，默認上下文長度是 4K tokens。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">訓練數據：</span></p><ul><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">數據量：Yi-9B 是在 Yi-6B （使用了 3.1T tokens 訓練）的基礎上，使用了 0.8T tokens 進行繼續訓練。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#000000">數據時間：使用截止至 2023 年 6 月的數據。</span></p></li></ul></li></ul><h4><span style="color:#000000"><strong>模型優勢</strong></span></h4><p><span style="color:#000000">一直以來，Yi 系列模型的中英文能力很強 ，但在代碼和數學方面還有提升空間。Yi-9B 補足了這一短板，增強了 Yi 系列模型全方位的能力。</span></p><p><span style="color:#000000"><strong>代碼和數學能力出色，綜合實力強勁</strong></span></p><ul><li><span style="color:#000000">在綜合能力方面（Mean-All），Yi-9B 的性能在尺寸相近的開源模型中最好，超越了 DeepSeek-Coder、DeepSeek-Math、Mistral-7B、SOLAR-10.7B 和 Gemma-7B。</span></li></ul><p><span style="color:#000000"><img height="378" src="https://oscimg.oschina.net/oscnet/up-1c17af91388b4e6acdee7ed9bf59f8bd2e5.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在代碼能力方面（Mean-Code），Yi-9B 的性能僅次於 DeepSeek-Coder-7B，超越了 Yi-34B、SOLAR-10.7B、Mistral-7B 和 Gemma-7B。</span></li></ul><p><span style="color:#000000"><img height="312" src="https://oscimg.oschina.net/oscnet/up-a90214a7e2dad299b6a03ee6c2e6a898f49.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在數學能力方面（Mean-Math），Yi-9B 的性能僅次於 DeepSeek-Math-7B，超越了 SOLAR-10.7B、Mistral-7B 和 Gemma-7B。</span></li></ul><p><span style="color:#000000"><img height="332" src="https://oscimg.oschina.net/oscnet/up-a0e32de51761ccbe2fc04b4a2faac111e6a.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在常識和推理能力方面（Mean-Text），Yi-9B 的性能與 Mistral-7B、SOLAR-10.7B 和 Gemma-7B 不相上下。</span></li></ul><p><span style="color:#000000"><img height="370" src="https://oscimg.oschina.net/oscnet/up-85575f5ed5226bb33b1b2e59f15b6bc5d36.png" width="500" referrerpolicy="no-referrer"></span></p><ul><li><span style="color:#000000">在語言能力方面，相比於其他相近尺寸的模型，Yi-9B 不僅具備不錯的英文能力，還擁有 Yi 系列模型廣受好評的強大中文能力。</span></li></ul><p><span style="color:#000000"><img height="191" src="https://oscimg.oschina.net/oscnet/up-8e95430baa7a029eb10481b6919edfabb7d.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img height="285" src="https://oscimg.oschina.net/oscnet/up-23517d9512aa2906a7fa63e150b50a3f6e7.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><strong>消費級顯卡可用，使用成本友好</strong></span></p><ul><li><span style="color:#000000">Yi-9B（BF 16） 和其量化版 Yi-9B（Int8）都能在消費級顯卡上輕鬆部署，使用成本較低，開發者友好。</span></li></ul><p><span style="color:#000000"><img height="182" src="https://oscimg.oschina.net/oscnet/up-8ed07dfa90b5107e5affdd2e39bb9392cac.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong>未來展望</strong>&nbsp;</h4><p style="margin-left:0; margin-right:0">為了最大程度地提高模型性能，團隊計劃根據 scaling laws 動態調整算力資源在模型大小和數據大小上的分配，因此，團隊將繼續研究以下方向：</p><ul><li><p style="margin-left:0; margin-right:0">更優化的寬度擴增方法，儘量保留原模型的性能。</p></li><li><p style="margin-left:0; margin-right:0">更高效的分階段訓練和調參方式，儘量讓模型收斂得更好。</p></li></ul><p><span style="color:#000000">有關模型訓練方面等方面的更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0CXIBlCZ7DJ2XjYT6Rm8tw" target="_blank">查看官方公告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:25:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281895</guid>
            <link>https://www.oschina.net/news/281895</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mac 上 Llama2 大語言模型安裝到使用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>LLAMA 介紹</h3><p>LLaMA 是由 Facebook 的母公司 Meta AI 設計的一個新的大型語言模型。LLaMA 擁有 70 億到 650 億個參數的模型集合，是目前最全面的語言模型之一。</p><p>Llama 是目前唯一一個可以進行本地部署和本地訓練的大型模型，對各種提問有非常好的處理能力。非常適合個人和中小型企業，構建自己的大數據模型。</p><p>很多人都説是 ChatGPT 的平替。通過微調來滿足特定小眾行業的使用，將會在未來有非常大的潛力。</p><p>Mac 上由於沒有 Nvidia 顯卡的加持，無法配置 CUDA 進行深度學習。好在有大神製作了 C++的庫，能實現小成本在低配 Mac 上跑模型的能力。</p><p><img src="https://oscimg.oschina.net/oscnet/up-64e62fce89bbcc5b1c22eb21b07b7ed543b.png" alt="file" referrerpolicy="no-referrer"></p><h3>llama.cpp</h3><p>是一個推理框架，在沒有 GPU 跑 LLAMA 時，利用 Mac M1/M2 的 GPU 進行推理和量化計算。</p><p>Mac 跑 LLAMA 唯一的路。同樣也可以在 Windows 下面跑起來。</p><p>它是 ggml 這個機器學習庫的衍生項目，專門用於 Llama 系列模型的推理。llama.cpp 和 ggml 均為純 C/C++實現，針對 Apple Silicon 芯片進行優化和硬件加速，支持模型的整型量化 (Integer Quantization): 4-bit, 5-bit, 8-bit 等。社區同時開發了其他語言的 bindings，例如 llama-cpp-python，由此提供其他語言下的 API 調用。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp" target="_blank">https://github.com/ggerganov/llama.cpp</a></p><h3>安裝 llama.cpp</h3><p>本地快速部署體驗推薦使用經過指令精調的 Alpaca-2 模型，有條件的推薦使用 6-bit 或者 8-bit 模型，效果更佳。 下面以中文 Alpaca-2-7B 模型為例介紹，運行前請確保： 1、系統應有 make（MacOS/Linux 自帶）或 cmake（Windows 需自行安裝）編譯工具 2、建議使用 Python 3.10 以上編譯和運行該工具 3、必裝的 mac 依賴 xcode-select --install # Mac 的 Xcode 開發者工具，基本是必裝的，很多地方都需要用到。 brew install pkgconfig cmake # c 和 c++的編譯工具。</p><p>1、源碼編譯</p><pre><code>git clone https://github.com/ggerganov/llama.cpp
</code></pre><p>2、編譯，對 llama.cpp 項目進行編譯，生成./main（用於推理）和./quantize（用於量化）二進制文件。</p><pre><code>make
</code></pre><p>Windows/Linux 用户如需啓用 GPU 推理，則推薦與 BLAS（或 cuBLAS 如果有 GPU）一起編譯，可以提高 prompt 處理速度。以下是和 cuBLAS 一起編譯的命令，適用於 NVIDIA 相關 GPU。</p><pre><code>make LLAMA_CUBLAS=1
</code></pre><p>macOS 用户無需額外操作，llama.cpp 已對 ARM NEON 做優化，並且已自動啓用 BLAS。M 系列芯片推薦使用 Metal 啓用 GPU 推理，顯著提升速度。只需將編譯命令改為：LLAMA_METAL=1 make，</p><pre><code>LLAMA_METAL=1 make
</code></pre><p>3、檢查，編譯成功會在目錄下產生 main 等可執行的命令，下面轉換量化模型文件時，會用到的命令就準備好了。</p><h3>手動轉換模型文件為 GGUF 格式</h3><p>如果下載的是生成好的 gguf 模型就不需要手動轉換了。為啥要這個格式。這個格式的 LLAMA.cpp 才認。其它格式的數據不認。</p><p>1、下載 Llama 2 模型，首先，從 Hugging Face <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmeta-llama" target="_blank">https://huggingface.co/meta-llama</a> 上下載你想要使用的 Llama 2 模型，比如 7B-Chat，我的 Mac 是 8G 內存，M2 芯片，估計也只能跑到這個模型，再大的機器跑不動。 值得一提的是：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmeta-llama%2FLlama-2-7b-chat" target="_blank">https://huggingface.co/meta-llama/Llama-2-7b-chat</a> 下載時，第一次需要授權，需要到 meta 官網，下面這個鏈接 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fllama.meta.com%2Fllama-downloads" target="_blank">https://llama.meta.com/llama-downloads</a></p><p>去提交一下郵件。這裏選國家時會有意想不到的結果，自己思考一下。</p><p>如果要體驗英文原版，就用上面的，會比較麻煩，但是對英文的回覆比較好。 參考教程 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fymcui%2FChinese-LLaMA-Alpaca-2%2Fwiki%2Fmanual_conversion_zh" target="_blank">https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/manual_conversion_zh</a></p><p>如果要使用中文語料庫，需要先合併為原始模型和中文的模型，再生成 bin，再去轉換為 gguf 格式。喜歡折騰的可以試試。</p><p>如果要使用我這個中文混合模型，可以直接下載 gguf 格式。下面這幾步都不用了。省事多了。</p><p>下載地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fhfl%2Fchinese-llama-2-7b-gguf%2Ftree%2Fmain" target="_blank">https://huggingface.co/hfl/chinese-llama-2-7b-gguf/tree/main</a> 記得選 ggml-model-q4_0.gguf 這個模型。</p><p>2、下載 llama.cpp 庫，並按上面的流程進行編譯安裝成功</p><p>3、轉換模型格式，然後，你需要把模型的文件轉換成 GGUF 格式，使用 llama.cpp 庫中的 convert.py 腳本來完成。轉換時需要指定模型的路徑和上下文長度（模型可以處理的最大的文本長度），不同的模型可能有不同的上下文長度。</p><p>如果模型是 LLaMA v1，則使用 --ctx 2048，如果你的模型是 LLaMA v2，則使用 --ctx 4096。這裏使用 --ctx 4096。如下所示：</p><pre><code># 轉換模型文件
python3 convert.py models/7B-Chat --ctx 4096
</code></pre><p>如果安裝過程缺 python 包直接 pip install 安裝即可。</p><p>4、量化模型文件</p><p>使用 llama.cpp 庫中的 quantize 程序來進行模型量化，使用 quantize 命令：</p><pre><code># 運行 quantize 程序，指定輸入和輸出的模型文件和量化方式
./quantize ./models/7B/ggml-model-f16.gguf ./models/7B/ggml-model-q4_0.gguf q4_0
</code></pre><p>這樣，在 7B-Chat 文件夾中就生成一個 4 位整數的 GGUF 模型文件。</p><p>5、運行模型</p><pre><code>./main -m ./models/7B/ggml-model-q4_0.bin \
        -t 8 \
        -n 128 \
        -p 'The first president of the USA was '

# run the inference 推理
./main -m ./models/llama-2-7b-hf/ggml-model-q4_0.bin -n 128
#以交互式對話
./main -m ./models/llama-2-7b-hf/ggml-model-q4_0.bin --color -f prompts/alpaca.txt -ins -c 2048 --temp 0.2 -n 256 --repeat_penalty 1.3
#chat with bob
./main -m ./models/llama-2-7b-hf/ggml-model-q4_0.bin -n 256 --repeat_penalty 1.0 --color -i -r "User:" -f prompts/chat-with-bob.txt
</code></pre><p>此步驟過於煩鎖，主要是模型文件佔了幾十 GB。所以我直接下載別人的中文模型進行使用。不需要再手動進行轉換、量化等操作。</p><h3>以 WebServer 形式啓動</h3><p>調用手冊：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp%2Fblob%2Fmaster%2Fexamples%2Fserver%2FREADME.md" target="_blank">https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md</a></p><p>用 WebServer 形式。可以對接到別的系統裏面，像 FastGPT 或者一些界面上，就可以無縫使用了。</p><p>1、啓動 server 參數請./server -h 查看，或者參考手冊</p><pre><code>./server --host 0.0.0.0 -m /Users/kyle/MyCodeEnv/models/ggml-model-q4_0.gguf -c 4096 --n-gpu-layers 1
</code></pre><p>默認會開到 8080 端口上，配置可改。不加 gpu-layers 走 CPU，會報錯。設個 1 就行</p><p>2、用 CURL 進行測試</p><pre><code>curl --request POST \
    --url http://127.0.0.1:8080/completion \
    --header "Content-Type: application/json" \
    --data '{"prompt": "給我講個冷笑話:","n_predict": 128}'
</code></pre><p>3、效果如圖 <img src="https://oscimg.oschina.net/oscnet/up-13aad680a24849ac3eac3a0c10ea1a23746.png" alt="file" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-2ec06696d22e9fd8b9ce8c65280167f2454.png" alt="file" referrerpolicy="no-referrer"> 感覺，就是訓練的還是量少，有些問題會胡説。理解不了的問題反應會非常慢。會花很長的時間。</p><h3>Python 調用接口庫</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fabetlen%2Fllama-cpp-python" target="_blank">https://github.com/abetlen/llama-cpp-python</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fllama-cpp-python.readthedocs.io%2Fen%2Flatest%2Finstall%2Fmacos%2F" target="_blank">https://llama-cpp-python.readthedocs.io/en/latest/install/macos/</a></p><p>1、Mac 用户，pip 編譯，最簡，安裝 llama-cpp-python (with Metal support) 為了啓用對於 Metal (Apple 的 GPU 加速框架) 的支持，使用以下命令安裝 llama-cpp-python: CMAKE_ARGS="-DLLAMA_METAL=on" FORCE_CMAKE=1 pip install llama-cpp-python</p><p>2、代碼中使用，安裝好之後可以直接用 requests 調用。無需第 1 步的 llama-cpp-python 依賴包。使用通用的 ChatGPT 的問答形式回答。 也可以不經 Server 直接調用模型文件</p><pre><code># -*- coding: utf-8 -*-
import requests

url = 'http://localhost:8080/v1/chat/completions'
headers = {
    'accept': 'application/json',
    'Content-Type': 'application/json'
}
dataEn = {
    'messages': [
        {
            'content': 'You are a helpful assistant.',
            'role': 'system'
        },
        {
            'content': 'What is the capital of France?',
            'role': 'user'
        }
    ]
}
data = {
    'messages': [
        {
            'content': '你是一個樂於助人的助手',
            'role': 'system'
        },
        {
            'content': '二戰是哪一年爆發的?',
            'role': 'user'
        }
    ]
}

response = requests.post(url, headers=headers, json=data)
print(response.json())
print(response.json()['choices'][0]['message']['content'])
</code></pre><p>3、直接調用模型文件，需要安裝 llama-cpp-python 包</p><pre><code># -*- coding: utf-8 -*-
from llama_cpp import Llama

# 加截模型
# llm = Llama(model_path='/Users/kyle/MyCodeEnv/models/ggml-model-q4_0.gguf', chat_format="llama-2") # 可以指定聊天格式
llm = Llama(model_path='/Users/kyle/MyCodeEnv/models/ggml-model-q4_0.gguf')

# 提問
response = llm("給我講一下英國建國多少年了", max_tokens=320, echo=True)
# response = llm.create_chat_completion(
#     messages=[
#         {"role": "system", "content": "你是一個樂於助人的助手"},
#         {
#             "role": "user",
#             "content": "給我講一個笑話"
#         }
#     ]
# )
# print(response)

# 回答
print(response['choices'][0])
</code></pre><h3>最後貼個官方的教程</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fllama-cpp-python.readthedocs.io%2Fen%2Flatest%2Finstall%2Fmacos%2F" target="_blank">https://llama-cpp-python.readthedocs.io/en/latest/install/macos/</a></p><p>再慢慢研究研究微調和訓練自己的語料吧。</p><p>跟上 LLM 的步伐。不接觸 AI 就要落後了。 更多精彩內容，請關注我的公眾號：青塬科技。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:09:02 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/qyhstech/blog/11046186</guid>
            <link>https://my.oschina.net/qyhstech/blog/11046186</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[德國防部密碼 1234，德媒：這真的安全嗎]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">近日，德國軍方被曝出一段涉及「考慮協助烏克蘭襲擊克里米亞大橋」的錄音，從而遭致其國內的嚴厲批評。目前德國防部已就此進行迴應，但期間又發生了一個令人迷惑的安全細節，再遭當下神經已高度緊繃的德媒質疑。</span></p><p><span style="color:#000000">當地時間 3 月 3 日，德國國防部長鮑里斯·皮斯托留斯（ Boris Pistorius）就竊聽醜聞一事舉行新聞發佈會，其講話部分於 4 日以加密錄音文檔的形式被公佈在德國防部網站上。德國防部提醒，遊客可以通過點擊該文檔鏈接進入德國國防軍的雲存儲服務器，並輸入密碼「1234」來訪問一個 13MB 大小的 MP3 錄音文檔。</span></p><p><span style="color:#000000">3 月 3 日，德國柏林，德國國防部長皮斯托留斯就「德軍方談話遭俄羅斯竊聽」一事對媒體發表講話，指責俄方發動「信息站」。</span></p><p><span style="color:#000000"><strong>雖然該錄音文檔在雲存儲上未進行分類，密碼「1234」甚至可能只是個臨時佔位符，但密碼的簡單性仍遭到德媒批評。</strong>對此，德國《圖片報》就將國防部頁面的提示截圖貼在報道內，並反問「密碼是 1234，這真的安全嗎？」</span></p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-b2654287246cbfa96b4ee7b4fe41dff8488.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">《圖片報》指出，目前仍不清楚俄方究竟是如何通過什麼手段竊聽獲得了長達 38 分鐘的德國高層軍官通話的錄音，但這些高層軍官因使用「WebEx」（第三方遠程會議軟件）進行高度機密的通話而被竊聽的事實，已經讓外界嚴重懷疑國防部的保密程度是否出現巨大漏洞。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 02:00:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281890</guid>
            <link>https://www.oschina.net/news/281890</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 基金會推出「反詐」開源項目 Tazama，獲蓋茨基金會資助]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gatesfoundation.org%2F" target="_blank">比爾及梅琳達•蓋茨基金會</a>（Bill &amp; Melinda GatesFoundation）的支持下，Linux 基金會慈善機構（LF Charities）<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-launches-tazama-for-real-time-fraud-management" target="_blank">宣佈</a></u>推出<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">Tazama</a>，這是一套用於實時欺詐預防的開源軟件解決方案。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-935f8d1d736dc3d5b53baa4a2e1caebd24b.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gasa.org%2Fglobal-anti-scam-summit-2023" target="_blank">全球反詐騙聯盟 (Global Anti-Scam Alliance)</a>報告稱，2022 年因在線欺詐損失了近萬億美元。</p><p>Tazama 標誌着全球金融監管和合規方式的重大轉變。迄今為止，金融業一直在使用專有的、往往成本高昂的解決方案，這些解決方案限制了許多人（尤其是發展中經濟體）的使用和適應性。</p><p>Tazama 提供了一種強大、可擴展且成本效益高的開源反欺詐替代解決方案，實現了先進金融監控工具的平民化，有助於打擊欺詐行為，從而挑戰了這一現狀。</p><p>Tazama 解決了政府、民間社會、最終用户、行業機構和金融服務業的主要問題，包括欺詐檢測、反洗錢合規性和數字金融交易的成本效益監控。該解決方案的架構強調數據主權、隱私和透明度，與世界各國政府的優先事項保持一致。Tazama 由 LF 慈善基金會主辦，該基金會將為項目的運行和功能提供支持，Tazama 展示了開源解決方案的可擴展性和穩健性，尤其是在國家支付交換機等關鍵基礎設施方面。</p><p>一些組織正在探索與 Tazama 的協同作用，包括 BankservAfrica、IPSL、JoPACC 和 BCEAO。協同作用包括評估 Tazama 解決方案在實際應用場景中的有效性、可擴展性和適應性，確保其滿足並超越各行業數字金融服務提供商（DFSP）的不同需求。</p><p>Tazama 歡迎各國中央銀行、監管機構、移動支付提供商、系統集成商、組織和個人參與其中。欲瞭解更多有關 Tazama 及其使命、社區和倡議的信息，請訪問 Tazama<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">網站</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffrmscoe" target="_blank">GitHub</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 10:03:40 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</guid>
            <link>https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 和 Elon Musk【譯】]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>OpenAI 今天在官網<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">發佈新聞稿</a></u>，迴應</span><span>埃隆·馬斯克</span><span>起訴一事。</span></p><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>該文章由 Sam Altman、Greg Brockman、Ilya Sutskever 等人共同署名。文章表示，OpenAI 打算</span><span>駁回</span><span>埃隆·馬斯克</span><span>的所有訴訟請求，</span><span>並公佈了一些高層和</span><span>埃隆·馬斯克</span><span>的歷史往來郵件作為證據。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-49bfb7cdaf49904c3a735c17f2ac5c4887e.png" referrerpolicy="no-referrer"></p></blockquote><p>以下為新聞稿原文翻譯：</p><p>&nbsp;</p><p>OpenAI 的使命是確保 AGI 造福全人類，這意味着既要構建安全有益的 AGI，又要幫助人類創造收益。現在，我們將與大家分享我們在完成使命方面的心得，以及我們與埃隆之間關係的一些事實情況。</p><p>我們正打算駁回埃隆的所有訴訟請求。</p><h3><strong>我們意識到，構建 AGI 所需的資源遠遠超出我們最初的想象</strong></h3><hr><p>埃隆説，我們應該布向 OpenAI 提供 10 億美元的初始資金承諾。實際上，這家非營利組織總共從埃隆那裏籌集了不到 4500 萬美元，從其他捐贈者那裏籌集了 9000 多萬美元。</p><p>在 2015 年底創辦 OpenAI 時，格雷格和薩姆最初計劃籌集 1 億美元。但是埃隆在一封電子郵件中表示&nbsp;「我們需要一個比 1 億美元大得多的數字，以免讓人聽起來覺得毫無希望……我認為我們應該從 10 億美元的資金承諾開始.如果其他人不提供的，我會承擔。「 [1]</p><p>我們花了很多時間來設想通往 AGI 的合理路徑。2017 年初，我們意識到構建 AGI 需要大量的計算。我們開始計算 AGI 可能需要多少計算量。我們都明白，要想成功完成使命，我們將需要更多的資金--這將達到每年數十億美元，遠遠超出了我們任何人的想象，尤其是埃隆，他認為我們作為非營利組織無法籌集到這麼多資金。</p><h3><strong>我們和埃隆都認識到，要獲得這些資源，就必須建立一個營利實體。</strong></h3><hr><p>在我們討論營利性結構以推進使命時，埃隆希望我們與特斯拉合併，否則他需要獲得全部的控制權。這之後埃隆離開了 OpenAI，他説需要有一個與谷歌/DeepMind 相對應的競爭對手，而他打算自己來做這件事。他同事表示，他會支持我們找到自己的道路。</p><p>2017 年底，我們和埃隆決定下一步的任務是創建一個營利實體。埃隆希望獲得多數股權以及最初的董事會控制權，並擔任首席執行官。在這些討論中，他扣留了資金。Reid Hoffman 填補了資金缺口，為我們支付了工資和運營費用。</p><p>我們無法就營利性公司的條款與埃隆達成一致，因為我們認為任何個人對 OpenAI 擁有絕對控制權都有悖於公司的使命。於是，他建議將 OpenAI 併入特斯拉。2018 年 2 月初，埃隆給我們轉發了一封郵件，建議 OpenAI 「依附於特斯拉，將其作為自己的資金來源「，並評論説 「完全正確……特斯拉是唯一一條甚至有望與谷歌相提並論的道路。即便如此，與谷歌抗衡的可能性也很小。但並不是零」。[2]</p><p>埃隆很快選擇離開 OpenAI，他説我們的成功概率為 0，他計劃在特斯拉內部建立一個 AGI 團隊與我們競爭。他在 2018 年 2 月底離開時告訴我們，他支持我們自己尋找籌集數十億美元的道路。2018 年 12 月，埃隆給我們發郵件説：「即使籌集到幾億美元也不夠。這需要每年籌集數十億美元，否則就算了。「 [3]</p><h3><strong>我們通過構建可廣泛使用的有益工具來推進我們的使命</strong></h3><hr><p>我們通過開源等方式，使我們的技術能夠廣泛使用，從而提高人們的效率，改善他們的日常生活。</p><p>我們向大眾提供了當今最強大的人工智能，包括每天有數億人使用的免費版本。舉個例子，阿爾巴尼亞正在使用 OpenAI 的工具將其加入歐盟的時間加快了 5.5 年；數字綠色公司正在幫助肯尼亞和印度提高農民收入，通過在 OpenAI 的基礎上將農業推廣服務的成本降低 100 倍；羅德島州最大的醫療保健提供商 Lifespan 使用 GPT-4 將其手術同意書從大學閲讀水平簡化到六年級水平；而冰島正在使用 GPT-4 保護越來越少人使用的冰島語。</p><p>埃隆明白，這些工作並不意味着開源 AGI。正如伊利亞告訴埃隆的那樣 「隨着我們越來越接近 AGI，開始降低開放程度是有意義的。OpenAI 中的 「開放 「是指人工智能建成後，每個人都應從人工智能的成果中受益，但不分享科學成果也完全沒問題……"，埃隆回答道： 「是的」。[4]</p><p>對於埃隆的起訴，我們倍感遺憾。我們深深欽佩的一個人走到了這一步。他曾激勵我們向更高的目標邁進，然後告訴我們會失敗，建立了一個競爭對手團隊，而當我們開始在沒有他的情況下朝着 OpenAI 的使命取得有意義的進展時，他又將我們告上法庭。</p><p>我們專注於推進自己的使命，這還有很長的路要走。我們相信隨着我們的產品越來越好，他們將更好地為每個人賦權。</p><p>&nbsp;</p><p><strong>以下為往來郵件翻譯：</strong></p><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173736_2J68.png" referrerpolicy="no-referrer"></p><p>[1]</p><p>發件人 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;格雷格-布羅克曼</p><p>抄送： Sam Altman</p><p>Date： Sun, Nov 22, 2015 at 7:48 PM</p><p>主題： 通話後續</p><p>博客聽起來不錯，但要考慮到中立性和以青委會為中心。</p><p>我更傾向於將博客定位為更吸引普通大眾－－讓大眾支持我們取得成功有很大的價值－－然後為招聘工作準備一個更長、更詳細、更有內幕的版本，並在普通大眾版本的末尾提供鏈接。</p><p>我們需要一個比 1 億美元大得多的數字，以避免與谷歌或 Facebook 的支出相比顯得毫無希望。我認為我們應該説，我們將從 10 億美元的資金承諾開始。這是真的。其他人不提供的，我都會提供。</p><p>模板看起來還不錯，除了默認轉為歸屬現金紅利外，還可以選擇將其轉為 YC 或 SpaceX（需要了解具體數額）的股票。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_l1GG.png" referrerpolicy="no-referrer"></p><p>[2]</p><p>發件人 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>Date： 2018 年 2 月 1 日，星期四，凌晨 3:52</p><p>主題 Fwd： 今天的頂級人工智能機構</p><p>説得一點沒錯。我們或許希望如此，但在我看來，特斯拉是唯一能與谷歌抗衡的公司。即便如此，與谷歌抗衡的可能性也很小，但也不是零。</p><p>開始轉發信息：</p><p>發件人： &nbsp;&nbsp;&lt;&gt;</p><p>致 &nbsp;埃隆-馬斯克 &lt;&gt;</p><p>日期，太平洋標準時間 2018 年 1 月 31 日下午 11:54:30</p><p>主題 Re： 當今頂尖的人工智能機構</p><p>不幸的是，在人工智能的最前沿工作是昂貴的。除了 DeepMind，谷歌還有 Google Brain、Research 和 Cloud。還有 TensorFlow、TPU，它們擁有大約三分之一的研究成果（事實上，它們還舉辦自己的人工智能會議）。</p><p>我還強烈懷疑，要實現 AGI，計算能力將是必要的。如果歷史趨勢能夠説明問題，那麼人工智能的進步主要是由系統－－計算、數據、基礎設施－－驅動的。我們今天使用的核心算法與上世紀 90 年代相比基本沒有變化。不僅如此，任何發表在論文中的算法進展幾乎都可以立即被重新實現和整合。反過來説，如果沒有一定的規模，單靠算法的進步是沒有生命力的。</p><p>在我看來，如今的 OpenAI 正在燒錢，其融資模式無法達到與谷歌（一家 8000 億美元的公司）認真競爭的規模。如果你無法與谷歌認真競爭，卻繼續在開放環境中進行研究，那麼你可能會讓事情變得更糟，並 「免費 「幫助他們，因為他們很容易複製任何進步，並立即將其規模化。</p><p>以營利為目的的轉型可能會隨着時間的推移創造出更穩定的收入來源，而就目前的團隊而言，很可能會帶來大量投資。然而，從零開始打造產品會搶走人工智能研究的重點，而且需要很長時間，目前還不清楚一家公司能否 「趕上 「谷歌的規模，投資者也可能會在錯誤的方向上施加過多壓力。我所能想到的最有希望的方案，正如我之前提到的，就是讓 OpenAI 附屬於特斯拉，將其作為自己的資金來源。我認為，依附於其他大型公司（如蘋果、亞馬遜），會因公司基因不兼容而失敗。打個比方，特斯拉已經建造了火箭的 「第一級「，包括 Model 3 的整個供應鏈、車載電腦和持續的互聯網連接。第二階段 「將是基於大規模神經網絡訓練的完全自動駕駛解決方案，OpenAI 的專業技術可以大大幫助加快這一進程。在大約 2-3 年的時間裏，我們就能推出功能完善的完全自動駕駛解決方案，銷售大量汽車/卡車。如果我們真的做得很好，運輸行業的規模足夠大，我們可以將特斯拉的市值提高到 O（約 10 萬美金），並利用這筆收入為適當規模的人工智能工作提供資金。</p><p>我看不到有任何其他公司有潛力在十年內達到可持續的谷歌規模資本。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_gNCb.png" referrerpolicy="no-referrer"></p><p>[3]</p><p>發件人 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>抄送： Sam Altman</p><p>Date： Wed, Dec 26, 2018 at 12:07 PM</p><p>主題： 我覺得我應該重申</p><p>在執行和資源沒有發生巨大變化的情況下，我對 OpenAI 與 DeepMind/Google 相關性的概率評估是 0%。而不是 1%。我希望不是這樣。</p><p>即使籌集到幾億美元也不夠。這需要每年立即籌集數十億美元，否則就算了。</p><p>不幸的是，人類的未來掌握在【未透露名稱】手中。</p><p>他們所做的遠不止這些。</p><p>我真希望我錯了。</p><p>埃隆</p><hr><p><img src="https://oscimg.oschina.net/oscnet/up-9103940e18f26f6ed78e7c0e58a9b0be1dc.png" referrerpolicy="no-referrer"></p><p>【4】</p><p>Fwd: 恭喜獵鷹 9</p><p>包含 3 條信息</p><p>發件人 &nbsp;Elon Musk</p><p>收件人 &nbsp;Sam Altman、Ilya Sutskever、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 8:18 AM</p><p>主題，收件人： 恭喜獵鷹 9 號</p><p>開始轉發消息：</p><p>From：&nbsp;未透露姓名</p><p>To： &nbsp;埃隆-馬斯克</p><p>日期： 美國中部時間 2016 年 1 月 2 日上午 10:12:32</p><p>主題： 恭喜獵鷹 9 號</p><p>嗨，埃隆</p><p>祝你新年快樂，</p><p>首先祝賀獵鷹 9 號着陸，這是一項了不起的成就。現在是時候組建艦隊了！</p><p>我看到你（還有薩姆和其他 OpenAI 人士）最近接受了很多采訪，大肆宣揚人工智能開源的優點，但我想你應該意識到，這並不是某種能神奇地解決安全問題的靈丹妙藥吧？有很多很好的論據可以説明，為什麼你所採取的方法實際上是非常危險的，事實上可能會增加世界的風險。在這篇博文中，一些比較明顯的觀點得到了很好地闡述，我相信你已經看到了，但還有其他一些重要的考慮因素：</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fslatestarcodex.com%2F2015%2F12%2F17%2Fshould-ai-be-open%2F" target="_blank">http://slatestarcodex.com/2015/12/17/should-ai-be-open/</a></p><p>我很想聽聽你對這些觀點的反駁。</p><p>發件人 &nbsp;Ilya Sutskever</p><p>致 &nbsp;Elon Musk 、Sam Altman、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 9:06 AM</p><p>主題 Fwd: 恭喜獵鷹 9 號</p><p>這篇文章關注的是 「硬起飛 「</p><p>如果發生 「硬起飛「，而安全的人工智能比不安全的人工智能更難構建，那麼通過開放一切，我們就會讓那些能夠獲得大量硬件的不法分子輕而易舉地構建出不安全的人工智能，從而遭遇 「硬起飛」。</p><p>當我們越來越接近構建人工智能時，開始降低開放程度將變得更有意義。openAI 中的 「開放 「意味着，在人工智能建成後，每個人都應從人工智能的成果中獲益，但不分享科學知識也是完全可以的（儘管在短期和中期內，為了招聘的目的，分享一切絕對是正確的策略）。</p><p>來自 &nbsp;埃隆-馬斯克</p><p>收件人 &nbsp;Ilya Sutskever</p><p>日期 Sat, Jan 2, 2016 at 9:11 AM</p><p>主題 Fwd: 恭喜獵鷹 9 號</p><p>是的</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:37:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281801/openai-elon-musk</guid>
            <link>https://www.oschina.net/news/281801/openai-elon-musk</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌在其搜索排名系統中對垃圾郵件和人工智能進行降級]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2F2024%2F3%2F5%2F24091099%2Fgoogle-search-high-quality-results-spam-ai-content" target="_blank">據 The Verge 報道</a></u>，谷歌正在對其搜索排名系統進行一些新的更改，這些更改旨在幫助在結果中顯示好的內容，並隱藏網絡上一些最糟糕和最憤世嫉俗的內容。</p><p>該公司表示，它在降級內容方面做得更好，這些內容只是為了總結其他內容——有時可能是正常的搜索引擎優化內容，但也越來越多地成為生成人工智能工具的工作——並打擊人們用來欺騙的一些技巧它的排名系統。</p><p>谷歌搜索副總裁潘杜·納亞克 (Pandu Nayak) 列舉了谷歌現在認為是垃圾郵件行為並打算降低排名的三個例子。</p><p>第一個是大規模內容：這些網站每天通過低薪承包商或人工智能生成器創建數千篇低質量文章，並將這些內容定位在搜索結果中。</p><p>第二種垃圾郵件行為是 Nayak 所説的「網站聲譽濫用」。這是指一個原本受人尊敬的網站出租其部分網站來傳播垃圾郵件。</p><p>第三就是人工智能，人工智能生成的內容應該如何排名的問題才剛剛開始，因為它既試圖將人工智能帶給每個人，又試圖拯救網絡免於被淘汰。甚至谷歌自己的搜索引擎也成為人工智能機器。而且總會有新的方法來讓它在搜索結果中名列前茅。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:03:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281786/google-search-high-quality-results-spam-ai-content</guid>
            <link>https://www.oschina.net/news/281786/google-search-high-quality-results-spam-ai-content</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CSIS：2023 年全球人工智能發展回顧及 2024 年人工智能政策預測]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">2024 年 1 月 30 日，戰略與國際問題研究中心 CSIS 發佈報告《2024 年人工智能政策預測》，回顧了 2023 年全球人工智能的發展，提出了 2024 年在 AI 政策方面需要關注的 10 個重點，以及 AI 領域關鍵技術術語。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" height="301" src="https://static.oschina.net/uploads/space/2024/0306/162236_PCSo_4700705.png" width="360" referrerpolicy="no-referrer"></span></p><p>以下是報告主要內容：</p><div><div><ol><li><p style="margin-left:0; margin-right:0"><strong>2023 年 AI 發展回顧</strong>：</p><ul><li>中國實施了管理深度偽造的新法律。</li><li>微軟對 OpenAI 進行了鉅額投資。</li><li>美國國防部更新了關於武器系統中自主性的指令。</li><li>NIST 發佈了 AI 風險管理框架。</li><li>美國與歐盟宣佈加速聯合 AI 研究。</li><li>荷蘭和日本加入美國限制對中國半導體製造設備出口的努力。</li><li>OpenAI 的 ChatGPT 成為歷史上增長最快的應用。</li><li>美國和歐盟簽署了關於 AI 治理的協議。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AI 技術影響</strong>：</p><ul><li>AI 聊天機器人用户數量激增，尤其是 OpenAI 的 ChatGPT。</li><li>大型語言模型（LLM）如 GPT-4 和 Meta 的 LLaMA 不斷推出，模型規模和參數不斷增大。</li><li>AI 在多個科學領域取得突破，如材料科學和氣象學。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AI 治理與監管</strong>：</p><ul><li>美國、歐盟和中國等地區採取了 AI 監管措施。</li><li>美國商務部發布了 AI 風險管理框架，旨在增強 AI 的透明度和安全性。</li><li>歐盟通過了 AI 法案，這是迄今為止最全面的 AI 監管法規。</li><li>中國發布了關於生成性 AI 服務的監管措施，包括確保數據訓練的合法性。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>國際合作與治理</strong>：</p><ul><li>英國舉辦了全球 AI 安全峯會，簽署了 Bletchley 宣言，旨在促進 AI 的透明度和問責制。</li><li>G7 和聯合國等國際組織在 AI 治理方面進行了討論，強調了國際合作的重要性。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>私營部門的角色</strong>：</p><ul><li>私營部門在 AI 治理中扮演了重要角色，與政府合作管理 AI 技術。</li><li>AI 相關訴訟數量增加，涉及數據隱私、版權和專利法等問題。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>軍事應用</strong>：</p><ul><li>美國國防部更新了關於武器系統中自主性的指令，並推出了 Replicator 計劃，旨在加速 AI 啓用的自主系統的部署。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>企業投資與市場動態</strong>：</p><ul><li>AI 成為企業投資的熱點，尤其是「Magnificent Seven」（Meta、亞馬遜、蘋果、微軟、谷歌、特斯拉和英偉達）等科技巨頭在股市中表現突出。</li><li>私人投資在生成性 AI 領域達到歷史新高。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>2024 年展望</strong>：</p><ul><li>報告提出了 2024 年值得關注的 AI 發展，包括全球 AI 治理的實質性影響、第三方紅隊測試的實踐、國會是否能通過全面的 AI 立法等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>術語定義</strong>：</p><ul><li>報告最後提供了 2024 年關鍵 AI 術語的定義，如智能體、生成性 AI、大型語言模型（LLM）、自然語言處理（NLP）等。</li></ul></li></ol><p style="margin-left:0; margin-right:0">報告強調了 AI 技術的快速發展和其在各個領域的廣泛應用，同時也指出了隨之而來的監管挑戰和國際合作的重要性。報告還提到了 AI 在軍事應用、企業投資以及國際政策制定中的作用，以及對未來一年 AI 發展的預測和展望。</p></div><div><div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">報告詳情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「開源中國 APP - 報告模塊」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下載地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前僅提供 Android 版本</em>）</strong></p></div></div></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 08:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281773</guid>
            <link>https://www.oschina.net/news/281773</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
