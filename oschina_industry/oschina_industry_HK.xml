<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 26 Oct 2023 20:00:34 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[DHorse 改用 fabric8 的 SDK 與 K8s 集羣交互]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><h2>現狀</h2><p>在 dhorse 1.4.0 版本之前，一直使用 k8s 官方提供的 sdk 與 k8s 集羣交互，官方 sdk 的 Maven 座標如下：</p><pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;io.kubernetes&lt;/groupId&gt;
    &lt;artifactId&gt;client-java&lt;/artifactId&gt;
    &lt;version&gt;18.0.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>但是自從 1.4.0 版本以後，dhorse 開始支持 fabric8 的 sdk，fabric8 的 sdk 的 Maven 座標如下：</p><pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;io.fabric8&lt;/groupId&gt;
    &lt;artifactId&gt;kubernetes-client&lt;/artifactId&gt;
    &lt;version&gt;6.9.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>那麼，為什麼要替換為 fabric8 的 sdk 與 k8s 交互呢？</p><h2>k8s 官方與 fabric8 的對比</h2><p>1.社區方面</p><p>兩者的關注度上，都差不多，沒有太大差別；</p><p>但是，fabric8 的 sdk 提供的文檔和示例更加完善，而 k8s 官方提供的示例較少；</p><p>2.功能方面</p><p>fabric8 不僅支持 k8s，同時也支持 OpenShift，而官方 sdk 支持 k8s；</p><p>3.包大小</p><p>k8s 官方 sdk 依賴的 sdk 過大，有 30M 左右，而 fabric8 只有不到 10M；</p><p>使用官方的 sdk 也會導致 dhorse 的安裝包過大。</p><p>4.API 使用方面</p><p>舉個例子，以查詢 k8s 集羣的命名空間列表為例，説明代碼如下。</p><p>官方：</p><pre><code class="language-java">ApiClient apiClient = this.apiClient(clusterPO.getClusterUrl(), clusterPO.getAuthToken());
CoreV1Api coreApi = new CoreV1Api(apiClient);
List&lt;ClusterNamespace&gt; namespaces = new ArrayList&lt;&gt;();
String labelSelector = null;
if(pageParam != null &amp;&amp; !StringUtils.isBlank(pageParam.getNamespaceName())) {
    labelSelector = "kubernetes.io/metadata.name=" + pageParam.getNamespaceName();
}
try {
    V1NamespaceList namespaceList = coreApi.listNamespace(null, null, null, null,
        labelSelector, null, null, null, null, null);
} catch (ApiException e) {
    String message = e.getResponseBody() == null ? e.getMessage() : e.getResponseBody();
    LogUtils.throwException(logger, message, MessageCodeEnum.CLUSTER_NAMESPACE_FAILURE);
}
</code></pre><p>fabric8:</p><pre><code class="language-java">try(KubernetesClient client = client(clusterPO.getClusterUrl(), clusterPO.getAuthToken())){
    ListOptions o = new ListOptions();
    if(pageParam != null &amp;&amp; !StringUtils.isBlank(pageParam.getNamespaceName())) {
        o.setLabelSelector("kubernetes.io/metadata.name=" + pageParam.getNamespaceName());
    }
    namespaceList = client.namespaces().list(o);
}
</code></pre><p>可以看出，官方提供的 API 接口不夠簡潔，而且拋出了不必要的異常。</p><h2>結論</h2><p>綜上，dhorse 後續版本會默認選擇 fabric8 的 sdk 與 k8s 器羣交互，並計劃在 v1.6 的版本里下掉 k8s 官方的 sdk。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 25 Oct 2023 05:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263516</guid>
            <link>https://www.oschina.net/news/263516</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ONLYOFFICE 桌面編輯器現已上架至麒麟軟件商店]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdesktop.aspx" target="_blank"><u>ONLYOFFICE 桌面編輯器</u></a><span style="color:#333333">現已上架麒麟軟件商店。請閲讀下文了解詳情。</span></p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="ONLYOFFICE 桌面編輯器：現已在 Kylin 軟件商店上架" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/10/24093055/ONLYOFFICE-Desktop-on-Kylin.png" referrerpolicy="no-referrer"></p><h2><strong>關於麒麟</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kylinos.cn%2F" target="_blank"><u>麒麟</u></a>是一款國產操作系統，主要是為了滿足中國市場的需求和偏好而設計的。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">它能夠與各種硬件平台和軟件應用程序的廣泛兼容，因而受到認可。它支持從台式機到服務器的個人和企業硬件，能確保與現有基礎設施的無縫集成。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">2022 年 10 月，ONLYOFFICE 文檔獲得了與麒麟系統完全兼容的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2022%2F11%2Fonlyoffice-got-certified-by-kylin-os" target="_blank"><u>認證</u></a>。這意味着用户可以在他們的系統上無縫運行我們的在線編輯器，而不會出現任何兼容性問題。</p><h2><strong>ONLYOFFICE 桌面編輯器在</strong><strong>麒麟軟件商店</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">現在您可以使用預裝的軟件商店，在麒麟桌面環境中輕鬆獲取 ONLYOFFICE 桌面編輯器。只需打開麒麟軟件商店，搜索 ONLYOFFICE 桌面編輯器並單擊「安裝」按鈕。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="ONLYOFFICE 桌面編輯器：現已在 Kylin 軟件商店上架" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/10/24093250/ONLYOFFICE-on-Kylin-Software-Store.png" referrerpolicy="no-referrer"></p><p>安裝應用程序後，點擊 ONLYOFFICE 桌面編輯器圖標啓動。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="ONLYOFFICE 桌面編輯器：現已在 Kylin 軟件商店上架" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/10/24093801/kylin-desktops.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">如果您想要手動安裝，可以在終端中鍵入以下命令來獲取 ONLYOFFICE 桌面編輯器：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><code>sudo apt-get install onlyoffice-desktopeditors</code></p><div><h3>相關鏈接</h3><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kylinos.cn%2F" target="_blank"><u>麒麟官網</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2022%2F11%2Fonlyoffice-got-certified-by-kylin-os" target="_blank"><u>ONLYOFFICE 獲得麒麟操作系統認證</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fblog%2Fzh-hans%2F2023%2F10%2Fonlyoffice-desktop-editors-v7-5" target="_blank"><u>ONLYOFFICE 桌面編輯器</u><u>最新版</u><u><span>&nbsp;</span>7.5</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Ftechnology-partners.aspx" target="_blank"><u>成為 ONLYOFFICE<span>&nbsp;</span></u><u>的</u><u>技術合作夥伴</u></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 12:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263436</guid>
            <link>https://www.oschina.net/news/263436</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[no-GIL Python，啓動！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>CPython 核心開發者 Thomas Wouters 代表 Python 指導委員會宣佈：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.python.org%2Ft%2Fpep-703-making-the-global-interpreter-lock-optional-in-cpython-acceptance%2F37075" target="_blank"><strong>正式接受 PEP 703 提案</strong></a></u>。</p><blockquote><p>PEP 703（Making the Global Interpreter Lock Optional，讓全局解釋器鎖成為可選），簡稱<strong> no-GIL</strong>，也被稱為自由線程 (free-threaded)。</p></blockquote><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-c596a475dbbae0dd91e3f3072a9b309f794.png" referrerpolicy="no-referrer"></p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">根據提案的描述，CPython 的全局解釋器鎖 (GIL) 阻止了同時多線程執行代碼，成為了在多核 CPU 上提高 Python 代碼運行效率的一大障礙。PEP 703 提案建議向 CPython 添加構建配置 (<code>--disable-gil</code>)，使其在沒有全局解釋器鎖的情況下運行 Python 代碼，並進行必要的更改以保證解釋器線程安全。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Thomas Wouters 表示，Python 指導委員會當然很清楚 no-GIL 意味着什麼，社區普遍也是秉承支持的態度，畢竟它為 Python 帶來巨大好處。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">但與此同時，<span><span><span>委員會擔心移除 GIL 會破壞目前的所有擴展模塊，或者顯着降低 CPython 的性能或可維護性。</span></span></span><span><span><span>此外，</span></span><span><span>第三方 PyPI 軟件包生態系是 Python 的一大優勢，與 C 語言庫的緊密、高效集成則是 CPython 的優勢之一。</span></span><span><span>它們使得存在多種軟件包選擇成為可能，這是 Python 的獨特賣點。</span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span><span>因此他們需要謹慎實現 no-GIL，避免破壞這些優勢，或者導致其他開發者放棄數十年的軟件包開發。</span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span><span>由於還沒有實現 no-GIL，評估實際影響以及讓第三方軟件包適應新的自由線程的實用性是很困難的。尤其是</span></span><span><span>與線程相關的問題的不可預測性更是讓難度升級，</span></span></span><span><span><span>因為有些問題只有在顯着負載下才會暴露。</span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span><span>目前</span></span></span> Python 指導委員針對 no-GIL 的實現計劃分成三個階段：</p><ol><li style="text-align:left"><strong>實驗階段</strong>。通過提供 build-time 選項，讓開發者在構建時選擇啓用自由線程 (free-threaded)。在此階段對外明確告知<span><span><span>是實驗性的，不支持用於生產環境。</span></span></span></li><li style="text-align:left"><strong>支持但不默認階段</strong>。<span><span><span>該階段將在 API 和 ABI 變更充分解決，並且有足夠的社區支持時開始啓動。</span></span></span></li><li style="text-align:left"><strong>默認階段</strong>。此時默認啓用自由線程（初期仍支持禁用），但此階段確切的標準很難確定，目標是使開發者儘可能無縫且無痛地進行升級和兼容。</li></ol><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.python.org%2Ft%2Fpep-703-making-the-global-interpreter-lock-optional-in-cpython-acceptance%2F37075" target="_blank">點此查看詳情</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 10:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263570/pep-703-acceptance</guid>
            <link>https://www.oschina.net/news/263570/pep-703-acceptance</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI、谷歌微軟等設立 1000 萬美元 AI 安全基金]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">谷歌、微軟、OpenAI 和 Anthropic <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Ffrontier-model-forum-updates" target="_blank">發佈聯合聲明</a>，任命美國智庫學會高管 Chris Meserole 為前沿模型論壇 (Frontier Model Forum) 首任執行董事。並宣佈設立 1000 萬美元的 AI 安全基金，「以推動正在進行的工具開發研究，幫助社會能夠有效地測試和評估最有能力的 AI 模型。」</span></p><p><span style="color:#000000">前沿模型論壇由微軟、OpenAI、谷歌和 Anthropic 在今年 7 月聯合創立而成，是一個專注於確保安全和負責任地開發前沿人工智能模型的行業機構。該論壇旨在幫助：</span></p><ul><li><span style="color:#000000">推動人工智能安全研究，促進負責任地開發前沿模型並最大限度地降低潛在風險；</span></li><li><span style="color:#000000">確定前沿模型的安全最佳實踐；</span></li><li><span style="color:#000000">與政策制定者、學術界、民間社會和其他方面分享知識，推動負責任的人工智能發展；</span></li><li><span style="color:#000000">以及<span style="background-color:#ffffff">大力支持開發有助於應對社會挑戰的 AI 應用程序</span>。</span></li></ul><p><img height="243" src="https://oscimg.oschina.net/oscnet/up-08b8848cddef1c10504a853bad39c129725.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">公告指出，AI 安全基金<span style="background-color:#ffffff">將支持來自世界各地附屬於學術機構、研究機構和初創公司的獨立研究人員。初始資金來自 Anthropic、谷歌、微軟和 OpenAI，以及其他慈善合作伙伴。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">基金的主要重點將在於，</span><span style="background-color:#ffffff">支持開發新的模型評估技術，以幫助開發和測試前沿系統潛在危險能力的評估技術。「我們相信，增加該領域的資金將有助於提高安全標準，併為行業、政府和民間社會應對 AI 系統帶來的挑戰所需的緩解和控制提供見解。&nbsp;」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">該基金將在未來幾個月內徵集提案。</span>前沿模型論壇還計劃<span style="background-color:#ffffff">成立一個顧問委員會，以幫助指導其戰略和優先事項。</span></span></p><hr><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">1000 萬美元不算小數目，但在 AI 安全研究的背景下以及與前沿模式論壇成員在商業活動上的花費相比，這一數目就「顯得相當保守了」。科技媒體&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F25%2Fai-titans-throw-a-tiny-bone-to-ai-safety-researchers%2F" target="_blank">TechCrunch</a> 指出，僅今年一年，Anthropic 就從亞馬遜籌集了數十億美元，用於開發下一代 AI 助手，此前谷歌也向其投資了 300 美元。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">且與其他 AI 安全基金相比，該基金的規模也很小。根據博客 Less Wrong 的</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGpFFJo2uFe5ssgEb%2Fan-overview-of-the-ai-safety-funding-situation" target="_blank">分析</a><span style="color:#000000">，由 Facebook 創始人 (Dustin Moskovitz 聯合創辦的資助和研究基金會 Open Philanthropy 已為 AI 安全捐贈了約 3.07 億美元。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">公益公司「The Survival and Flourishing Fund」也已向 AI 安全項目捐贈了約 3000 萬美元。美國國家科學基金會表示，未來兩年將斥資 2000 萬美元用於 AI 安全研究，部分資金由 Open Philanthropy 資助。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「</span><span style="color:#000000">前沿模型論壇暗示下一步將成立一個規模更大的基金。如果這一目標實現，它可能有機會推動 AI 安全研究 —— 前提是我們相信該基金的明確營利性支持者不會對研究施加不當影響。但無論你如何劃分，<strong>首批資金似乎都過於有限，無法取得多大成就。</strong></span><span style="color:#000000">」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 08:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263552/frontier-model-forum-ai-safety</guid>
            <link>https://www.oschina.net/news/263552/frontier-model-forum-ai-safety</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 11 和 Java 17 使用率均超 Java 8]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">Java 軟件供應商&nbsp;Azul <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.azul.com%2Fnewsroom%2Fazul-state-of-java-survey-report-2023-businesses-exploring-java-alternatives%2F" target="_blank">發佈</a>了首份年度 Java 現狀調查報告，基於對全球 2062 名 Java 專業人士和基於 Java 的應用程序用户進行的調查。調查探討的領域包括 Java 採用趨勢、Oracle 最新 Java 定價變化的影響、Java 應用程序向雲的遷移以及公司如何優化雲成本，以及常見漏洞和暴露 (CVE) 的安全注意事項。</span></p><p><span style="color:#000000"><img alt="" height="340" src="https://oscimg.oschina.net/oscnet/up-ae384b843fd1f2008ed4e7affed0c1bd24a.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">結果表明，<strong>Java 的採用依然強勁</strong>，98% 的受訪者表示在他們的軟件應用程序或基礎架構中使用了 Java。其中 57% 的受訪者表示，他們至少 60% 的應用程序是基於 Java 的；有&nbsp;<span style="background-color:#ffffff">66% 的公司為 Java 支持付費。</span></span></p><p><span style="color:#000000">2018 年 9 月發佈的 Java 11 和 2020 年 9 月發佈的 Java 17 是使用最廣泛的 Java 版本，使用率分別為 48% 和 45%。其次是 2014 年 3 月發佈的 Java&nbsp;8，使用率為 40%。<span style="background-color:#ffffff">85% 的受訪者使用的是 LTS 版本的 Java，64% 的受訪者使用了多個 Java 版本。</span></span></p><p><span style="color:#000000"><strong>Oracle 的 Java 市場份額正在下降</strong>。在使用 Oracle Java 的受訪者中，82% 的人表示對 1 月份推出的新 Java SE 通用訂閲定價模式感到擔憂。受 Oracle 最新的定價政策影響，72% 的受訪者表示他們正在考慮使用 OpenJDK 等開源替代品；而在沒有考慮採用開源替代方案的受訪者中，有 14% 的人表示，是因為他們沒有想到可以這樣做。</span></p><p><span style="color:#000000">但僅管如此，Oracle 仍然是 Java 市場的強大參與者。42% 的受訪者表示他們仍然使用至少一個 Oracle Java 實例，不過其中 74% 的組織表示他們還使用至少一個 OpenJDK 供應商的 JDK。大約 60% 的公司選擇了 OpenJDK 發行版而不是 Oracle Java SE。</span></p><p><span style="color:#000000"><strong>90% 的受訪者在雲環境中使用 Java</strong>：公有 (48%)、私有 (47%) 或混合 (40%)。雲格局正在迅速轉變，組織不斷向雲邁進，以實現可擴展性、靈活性、生產力和敏捷性，但成本和安全性仍然是兩個主要挑戰。</span></p><p><span style="color:#000000">近 70% 的公司表示，他們正在為至少 20% 的未使用雲容量付費，「這是過度配置雲資源的明顯跡象」。<span style="background-color:#ffffff">95% 的公司在過去一年中採取了降低雲成本的措施</span>，46% 的企業正在利用高性能 Java 平台更有效地使用雲資源。</span></p><p><span style="color:#000000"><strong>Log4Shell 漏洞對組織產生了廣泛的安全影響。</strong>近 80% 的受訪者表示受到了 2021 年 Log4J 庫漏洞的影響。近一半的公司在該漏洞出現後不得不分配額外的工程時間，30% 的公司受到嘗試利用此漏洞的影響。</span></p><p><span style="color:#000000">近三分之二的調查受訪者明確表示，第三方和開源應用程序及庫是最令人擔憂的 CVE 來源。其中 57% 的受訪者將開源庫和應用程序列為最令人擔憂的 CVE 來源，51% 的受訪者認為第三方庫和應用程序是最令人擔憂的 CVE 來源。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.azul.com%2Freport%2F2023-state-of-java%2F" target="_blank">查看完整報告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 07:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263544/azul-state-of-java-survey-report-2023</guid>
            <link>https://www.oschina.net/news/263544/azul-state-of-java-survey-report-2023</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[騰訊混元大模型正式開放「文生圖」功能、代碼能力提升 20%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.75)">今天上午，騰訊混元大模型迎來全新升級，<strong>並正式對外開放「文生圖」功能</strong>。</span></p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1026/153337_LfTH_2720166.jpg" referrerpolicy="no-referrer"></p></blockquote><p>進入「騰訊混元助手」小程序即可使用騰訊混元大模型：</p><p><img height="754" src="https://static.oschina.net/uploads/space/2023/1026/165557_Bc0Q_2720166.png" width="400" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.75)"><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fu0AGtpwm_LmgnDY7OQhKGg" target="_blank">官方公告稱</a></u>，升級後的騰訊混元中文效果整體超過 GPT-3.5，<strong>代碼能力大幅提升 20%</strong>，達到業界領先水平。</span></p><p>據介紹，經過對 32 種主流語言代碼文件、各類計算機書籍和博客的學習增訓，騰訊混元代碼處理水平提升超過 20%，代碼處理效果勝出 ChatGPT 6.34%，在 HumanEval 公開測試集指標上全面超過 Starcoder、Codellama 等業界頭部開源代碼大模型。</p><p>只需輸入簡單的指令如「幫我用前端語言實現一個貪吃蛇」，騰訊混元便能自動生成可運行的代碼，快速製作出一個貪吃蛇小遊戲。此外，騰訊混元還支持 Python、C++、Java、JavaScript 等多種語言的指令生成，比如輸入「用 Python 畫紅色的心形線」，騰訊混元會提供代碼庫選擇、安裝命令、繪製代碼等具體操作步驟的指引。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-74216bf9be5ab9c4baadcbe9551410b8953.png" referrerpolicy="no-referrer"></p><p>對於大模型文生圖功能，騰訊稱其難點體現在<strong>對提示詞的語義理解，生成內容的合理性以及生成圖片的效果</strong>。針對這三個技術難點，騰訊進行了專項的技術研究，提出了一系列原創算法，來保證生成圖片的可用性和畫質。</p><p>1、<strong>在語義理解方面，騰訊混元採用了中英文雙語細粒度的模型</strong>，模型同時建模中英文實現雙語理解，而不是通過翻譯，通過優化算法提升了模型對細節的感知能力與生成效果，有效避免多文化差異下的理解錯誤。</p><p>2、<strong>在內容合理性方面</strong>，AI 生成人體結構和手部經常容易變形。<strong>混元文生圖通過增強算法模型的圖像二維空間位置感知能力</strong>，並講人體骨架和人手結構等先驗信息引入到生成過程中，讓生成的圖像結構更合理，減少錯誤率。</p><p>3、<strong>在畫面質感方面，混元文生圖基於多模型融合的方法，提升生成質感</strong>。經過模型算法的優化之後，混元文生圖的人像模型，包含髮絲、皺紋等細節的效果提升了 30%，場景模型，包含草木、波紋等細節的效果提升了 25%。</p><hr><p>下面是官方提供的「騰訊混元文生圖」使用案例。</p><ul><li>生成一幅照片：亞洲女子，魅力，中短髮，戴墨鏡，站在長城上，背景有紅葉</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-68d0953d2980101a5d24fe95c964a701946.png" referrerpolicy="no-referrer"></p><ul><li>生成一張長城的照片，攝影風，真實感</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3d745e8069507f0664da26f405ccddc4bc5.png" referrerpolicy="no-referrer"></p><ul><li>幫我畫一個拿着奶茶的甄嬛，扁平插畫，可愛 Q 版</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b61d22330c53d477f4669f355753becd266.png" referrerpolicy="no-referrer"></p><ul><li>生成 3D 遊戲軍事場景動漫，城市戰區，廢墟瓦礫，焦黑的建築，空氣中瀰漫硝煙</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f900d701ddb927a9b2fdb40caa870f9d736.png" referrerpolicy="no-referrer"></p><ul><li>畫一幅漁舟唱晚的畫</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-58f36165a591c6630cd605fb7afb63f5e47.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 07:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263543</guid>
            <link>https://www.oschina.net/news/263543</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 更新「知識」數據，截至 2023 年 4 月]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>ChatGPT 剛剛宣佈，其「知識」數據已進行更新，當前的知識截止日期是 2023 年 4 月。</p><p><img height="786" src="https://static.oschina.net/uploads/space/2023/1026/143656_e72e_2720166.png" width="1651" referrerpolicy="no-referrer"></p><p>注意，此次知識數據更新僅面向 GPT-4 版本提供。</p><p>ChatGPT 官方提供瞭如下示例。</p><p>提問：<strong>請列出最近發生的 10 次災難，以及在您的知識截止日期前的傷亡人數。災難至少應始於 2022 年之後。</strong></p><blockquote><p>Here are 10 significant catastrophes that occurred after 2022, up to my knowledge cutoff in April 2023, along with their associated casualties:</p><ol><li><p><strong>Earthquake in Turkey and Syria (February 6, 2023):</strong> This devastating earthquake, with a magnitude of 7.8, struck southeastern Turkey and northern Syria, leading to widespread destruction. The death toll exceeded 47,000 people, making it one of the deadliest earthquakes in recent history.</p></li><li><p><strong>Floods in Brazil (January 2023):</strong> Severe floods and landslides hit the state of São Paulo in Brazil, resulting in over 50 deaths. Several cities, including São Sebastião and Ubatuba, were significantly impacted.</p></li><li><p><strong>Train Derailment in Greece (March 1, 2023):</strong> A passenger train and a freight train collided in central Greece, near the city of Larissa, causing the death of at least 57 people.</p></li><li><p><strong>Earthquake in Afghanistan (June 22, 2022):</strong> A powerful earthquake with a magnitude of 5.9 struck eastern Afghanistan, particularly affecting the Paktika and Khost provinces. The catastrophe resulted in the death of over 1,000 people.</p></li><li><p><strong>Floods in Pakistan (Mid-2022):</strong> Monsoon floods in Pakistan, particularly severe in the Sindh and Balochistan provinces, led to the deaths of over 1,000 people and displaced millions.</p></li><li><p><strong>Tornado Outbreak in the United States (March 2023):</strong> A series of tornadoes swept across several states in the U.S., including Mississippi, Alabama, and Georgia. The outbreak caused at least 25 fatalities.</p></li><li><p><strong>Ferry Fire in the Philippines (March 28, 2023):</strong> A fire broke out on a ferry in the Philippines, leading to at least 31 deaths. The incident occurred near the island of Basilan.</p></li><li><p><strong>Typhoon Noru in the Philippines (September 2022):</strong> This powerful typhoon, also known as Karding, caused widespread destruction in the Philippines, resulting in the deaths of at least 8 people.</p></li><li><p><strong>Landslides in Peru (January 2023):</strong> Heavy rains triggered landslides in the Cusco region of Peru, leading to at least 36 deaths. The town of Santa Teresa, near the tourist attraction Machu Picchu, was particularly affected.</p></li><li><p><strong>Cyclone Gabrielle in New Zealand (February 2023):</strong> This powerful cyclone caused significant flooding and landslides in New Zealand's North Island, leading to at least 11 deaths.</p></li></ol><p>Please note that the number of casualties and the impact of these catastrophes might have changed after my last update in April 2023.</p></blockquote><p>via <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.openai.com%2Fshare%2F3b088460-86f8-4fa6-afd1-802b7f9a5e9f" target="_blank">https://chat.openai.com/share/3b088460-86f8-4fa6-afd1-802b7f9a5e9f</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 06:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263533</guid>
            <link>https://www.oschina.net/news/263533</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Vercel 為]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>一個多月前，Vercel <a href="https://www.oschina.net/news/258259/v0-dev-by-vercel">推出</a>根據文本生成 UI 界面代碼的新產品：v0，官方稱其為<strong>「生成式 UI」 (Generative UI)</strong>。</p><p><img alt="https://static.oschina.net/uploads/space/2023/0915/154136_ygaU_2720166.png" src="https://static.oschina.net/uploads/space/2023/0915/154136_ygaU_2720166.png" referrerpolicy="no-referrer"></p><p>只需要輸入文字提示，v0 即可生成需要的 UI 組件界面，而且可以直接複製代碼粘貼到需要使用的任何地方。</p><p><strong>主要特性</strong></p><ul><li>即時生成：可以根據用户的文本提示即時生成 UI 組件，這為用户提供了快速的實時反饋和迭代能力。</li><li>支持實時修改：通過提供更具體和詳細的提示來獲得更精確的結果。</li><li>簡單易用：用户只需提供簡單的文本提示，無需複雜的設計或編程知識。</li><li>集成多種組件：提供了多種 UI 組件的示例，如音樂播放器、發票表格等，這為用户提供了豐富的選擇。</li></ul><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0915/153904_iXi8_2720166.png" referrerpolicy="no-referrer"></p><p>Vercel 近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fannouncing-v0-generative-ui" target="_blank">宣佈</a></u> v0 已從 Alpha 過渡到 Beta，向 5000 名用户開放了訪問權限，併為想要解鎖 v0 完整功能集的用户推出訂閲計劃——包含 4 檔級別：</p><ul><li><strong>Free</strong>: $0 per month includes 200 credits</li><li><strong>Basic</strong>: $10/month includes 1,500 credits</li><li><strong>Standard</strong>: $30/month includes 5,000 credits</li><li><strong>Premium</strong>: $50/month includes 10,000 credits</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 06:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263528/v0-generative-ui</guid>
            <link>https://www.oschina.net/news/263528/v0-generative-ui</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 24.04 發佈日期定為 2024 年 4 月 25 日]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">Ubuntu 的下一個長期支持 (LTS) 版本 Ubuntu 24.04 的最終發佈日期已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flaunchpad.net%2Fubuntu%2Fnoble" target="_blank">確定</a>，計劃於 2024 年 4 月 25 日發佈。</span></p><p><span style="color:#000000">除此之外，Ubuntu 24.04 的功能凍結階段定於 2024 年 2 月 29 日；Ubuntu 24.04 beta 計劃於 2024 年 4 月 4 日發佈。</span></p><p><span style="color:#000000">目前尚未知曉 Ubuntu 24.04 版本的具體代號，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F10%2Fubuntu-24-04-release-date-set-for-april-25-2024" target="_blank">OMG! Ubuntu</a> 認為，其可能會在 11 月初於拉脱維亞里加舉行的 2023 年 Ubuntu 峯會上正式宣佈。但已知的是，其代號的前半部分為「Noble」。</span></p><p><img height="303" src="https://oscimg.oschina.net/oscnet/up-3ba65917ba444a9427e968bdf7618fbc210.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Ubuntu 的 LTS 版本將獲得 5 年的安全更新、錯誤修復和精選應用程序更新。Ubuntu Pro 則會在此基礎上額外增加 5 年的安全保障，為現代的 LTS 版本提供了長達十年的支持。</span></p><p><span style="color:#000000">Ubuntu 24.04 將是 Ubuntu 自 2006 年以來的第 10 個 LTS 版本，不過迄今為止對 Ubuntu 24.04 中將包含的新功能和改進知之甚少。但 Noble 大概率會採用 GNOME 46，並且會提供一個新的 Linux 內核。此外，我們還將看到首個正式發佈的全 Snap 不可變 Ubuntu 桌面鏡像。</span></p><p><span style="color:#000000">有關 Ubuntu 24.04 LTS 的更多信息，可關注未來幾個月的後續更新。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 06:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263525/ubuntu-24-04-release-date-april-25-2024</guid>
            <link>https://www.oschina.net/news/263525/ubuntu-24-04-release-date-april-25-2024</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RISC-V 創業公司 SiFive 裁員 100 多人，大部分是工程師]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>RISC-V 創業公司 SiFive 正在大規模裁員。</p><blockquote><p>RISC-V 是開源指令集架構，SiFive 成立於 2015 年，是一家基於 RISC-V 架構的芯片設計商，致力於將開源標準引入半導體設計，使其更便宜且更容易被客户使用。 它也是少數幾家提供高性能 RISC-V 產品的公司之一。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7063d1f400258edb38c5f4f5f46f1ca80fb.png" referrerpolicy="no-referrer"></p></blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tomshardware.com%2Fnews%2Fsifive-lays-off-hundreds-of-risc-v-developers" target="_blank">報道稱</a>，該公司從 10 月中旬開始大裁員，約 700 名員工中的 100-300 多人被解僱，大部分是工程師，還有少數銷售和產品人員。</p><p>SiFive 在隨後發表給媒體的一份聲明中澄清，它裁掉了來自不同業務組的約 140 名員工，佔員工總數的五分之一。</p><p>該公司表示，「隨着 Google 將 Android 引入 RISC-V 生態系統，它在 AI 以及可穿戴設備和移動設備等消費產品領域看到了巨大的機遇。基於他們對當前機遇的判斷和投入，SiFive 正在對全球團隊進行戰略性重組，以最大限度地滿足客户快速變化的需求。不幸的是，在這次調整中，約 20% 的員工受到了影響，涉及不同的業務組和級別。這些員工將獲得遣散費和安置協助。」</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 06:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263350/sifive-lays-off-hundreds-of-risc-v-developers</guid>
            <link>https://www.oschina.net/news/263350/sifive-lays-off-hundreds-of-risc-v-developers</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | POSIX 真的不適合對象存儲嗎？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p>最近，留意到 MinIO 官方博客的一篇題為「<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.min.io%2Ffilesystem-on-object-store-is-a-bad-idea%2F" target="_blank">在對象存儲上實現 POSIX 訪問接口是壞主意</a>」的文章，作者以 S3FS-FUSE 為例分享了通過 POSIX 方式訪問 MinIO 中的數據時碰到了性能方面的困難，性能遠不如直接訪問 MinIO。在對結果進行分析時，作者認為是 POSIX 本身存在的缺陷導致的性能問題。這個結論與我們既有經驗有一定出入。</p><p>我們知道 POSIX 是一個有用而且廣泛應用的標準，遵循它而開發的程序可以保證不同操作系統之間的兼容性和可移植性。各行各業中常用的業務系統和應用程序，大多遵循 POSIX 標準。</p><p>隨着雲計算、大數據、人工智能等技術的發展和數據存儲量的攀升，本地化應用也逐漸產生對對象存儲等彈性存儲的需求，MinIO 等對象存儲雖然提供了各種語言的 SDK，但許多傳統應用很難甚至無法修改代碼去適配對象存儲的訪問接口，這促使很多存儲產品在對象存儲的基礎上去實現 POSIX 接口來滿足這樣的剛性需求。</p><p>業內在對象存儲上實現 POSIX 接口的產品有很多，比如 Ceph、JuiceFS、Weka 等，它們都有廣泛的用户羣和大量的成功案例，在性能方面也都有不錯的表現。</p><p>誠然，我們認可 POSIX 存在較大的複雜性，需要付出很大的努力才能解決好相關的問題，但這些問題並不是無法解決。抱着尊重和求證的態度，我搭建了測試環境，採用相同的樣本和測試方法，進行了一番驗證。</p><h2>測試項目</h2><p>為了得到更為全面的測試結果，我將 JuiceFS 引入了對比。</p><p>JuiceFS 是開源的雲原生分佈式文件系統，它採用對象存儲作為數據存儲層，採用獨立的數據庫存儲元數據。提供了包括 POSIX API、S3 API、CSI Driver、HDFS API、WebDAV 在內的多種訪問方式，具有獨特的數據分塊、緩存和併發讀寫機制。JuiceFS 是文件系統，與 s3fs-fuse 等只提供簡單的從對象存儲到 POSIX 協議轉換的工具有着本質的不同。</p><p>通過將 JuiceFS 引入對比，可以更為客觀地求證以對象存儲為底層實現 POSIX 等協議的利弊。</p><p>在本文中，我會對 MinIO、JuiceFS 和 s3fs-fuse 進行以下兩項測試：</p><ol><li><p>10GB 大文件的寫入測試</p></li><li><p>Pandas 小文件覆蓋寫測試</p></li></ol><p>在底層存儲方面，它們均使用部署在獨立服務器上的 MinIO 實例；在測試樣本方面，10GB 文件會採用那篇文章中使用的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdata.cityofnewyork.us%2Fapi%2Fviews%2Ft29m-gskq%2Frows.csv%3FaccessType%3DDOWNLOAD" target="_blank">csv</a> 文件。</p><blockquote><p>本文所提及的環境、軟件、腳本、樣本數據等均提供完整的代碼和説明，確保讀者可以復現環境和測試結果。</p></blockquote><h2>服務器及測試環境準備</h2><p>兩台配置相同的雲服務器：</p><ul><li>System: Ubuntu 22.04 x64</li><li>CPU: 8 cores</li><li>RAM: 16GB</li><li>SSD: 500GB</li><li>Network: VPC</li></ul><p>每台服務器的信息如下：</p><table><thead><tr><th align="left">Server</th><th>IP</th><th>For</th></tr></thead><tbody><tr><td align="left">Server A</td><td>172.16.254.18</td><td>MinIO Instance</td></tr><tr><td align="left">Server B</td><td>172.16.254.19</td><td>Test Environment</td></tr></tbody></table><h3>Server A 的準備工作</h3><p>1.我在 Server A 上通過 Docker 部署了 MinIO，命令如下：</p><pre><code class="language-bash"># 創建並進入專用目錄
mkdir minio &amp;&amp; cd minio

# 創建配置文件
mkdir config
touch config/minio
</code></pre><p><code>config/minio</code> 文件中寫入以下信息：</p><pre><code class="language-bash">MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=abc123abc
MINIO_VOLUMES="/mnt/data"
</code></pre><p>2.創建 MinIO 容器：</p><pre><code class="language-bahs">sudo docker run -d --name minio \
  -p 9000:9000 \
  -p 9090:9090 \
  -v /mnt/minio-data:/mnt/data \
  -v ./config/minio:/etc/config.env \
  -e "MINIO_CONFIG_ENV_FILE=/etc/config.env" \
  --restart unless-stopped \
  minio/minio server --console-address ":9090"
</code></pre><p>3.在 MinIO 的 Web Console 中預先創建三個 buckets：</p><table><thead><tr><th align="left">Bucket Name</th><th align="left">目的</th></tr></thead><tbody><tr><td align="left">test-minio</td><td align="left">用於測試 MinIO</td></tr><tr><td align="left">test-juicefs</td><td align="left">用於測試 JuiceFS</td></tr><tr><td align="left">test-s3fs</td><td align="left">用於測試 s3fs-fuse</td></tr></tbody></table><h3>Server B 的準備工作</h3><p>下載 10GB 測試樣本文件</p><pre><code class="language-bash">curl -LO https://data.cityofnewyork.us/api/views/t29m-gskq/rows.csv?accessType=DOWNLOAD
</code></pre><p>2.安裝 mc 客户端</p><p>mc 是 MinIO 項目開發的命令行文件管理器，可以在 Linux 命令行讀寫本地以及 S3 兼容的對象存儲。mc 的 cp 命令可以實時顯示數據拷貝的進度和速度，便於觀察各項測試。</p><blockquote><p>注：為了保持測試的公平性，三種方案均採用 mc 進行寫測試。</p></blockquote><pre><code class="language-bash"># 下載 mc
wget https://dl.min.io/client/mc/release/linux-amd64/mc

# 檢查版本
mc -v
mc version RELEASE.2023-09-20T15-22-31Z (commit-id=38b8665e9e8649f98e6162bdb5163172e6ecc187)
Runtime: go1.21.1 linux/amd64

# 安裝 mc
sudo install mc /usr/bin

# 為 MinIO 添加別名
mc alias set my http://172.16.254.18:9000 admin abc123abc
</code></pre><p>3.安裝 s3fs-fuse</p><pre><code class="language-bash">sudo apt install s3fs

# 檢查版本
s3fs --version
Amazon Simple Storage Service File System V1.93 (commit:unknown) with OpenSSL

# 設置對象存儲訪問密鑰
echo admin:abc123abc &gt;  ~/.passwd-s3fs

# 修改密鑰文件權限
chmod 600  ~/.passwd-s3fs

# 創建掛載目錄
mkdir mnt-s3fs

# 掛載對象存儲
s3fs test-s3fs:/ /root/mnt-s3fs -o url=http://172.16.254.18:9000 -o use_path_request_style
</code></pre><p>4.安裝 JuiceFS</p><p>這裏使用官方提供的腳本安裝最新的 JuiceFS 社區版</p><pre><code class="language-bash"># 一鍵安裝腳本
curl -sSL https://d.juicefs.com/install | sh -

# 檢查版本
juicefs version
juicefs version 1.1.0+2023-09-04.08c4ae6
</code></pre><p>JuiceFS 是文件系統，需要先創建才能使用。除了對象存儲，還需要一個數據庫作為元數據引擎，支持多種數據庫，這裏使用較常用的 Redis 作為元數據引擎。</p><blockquote><p>注：我在這裏將 Redis 安裝在 Server A，通過 172.16.254.18:6379 進行訪問，無密碼，安裝過程略，詳情參考 Redis 官方文檔。</p></blockquote><pre><code class="language-bash"># 創建文件系統
juicefs format --storage minio \
--bucket http://172.16.254.18:9000/test-juicefs \
--access-key admin \
--secret-key abc123abc \
--trash-days 0 \
redis://172.16.254.18/1 \
myjfs
</code></pre><p>5.另外，我會同時以較為常用的 POSIX 和 S3 API 兩種方式訪問 JuiceFS 並分別測試它們的性能。</p><pre><code class="language-bash"># 創建掛載目錄
mkdir ~/mnt-juicefs

# 以 POSIX 方式掛載文件系統
juicefs mount redis://172.16.254.18/1 /root/mnt-juicefs

# 以 S3 API 方式訪問文件系統
export MINIO_ROOT_USER=admin
export MINIO_ROOT_PASSWORD=abc123abc
juicefs gateway redis://172.16.254.18/1 0.0.0.0:9000

# 在 mc 中為 JuiceFS S3 API 添加別名
mc alias set juicefs http://172.16.254.18:9000 admin abc123abc
</code></pre><blockquote><p>注：JuiceFS Gateway 也可以部署在 Server A 或其他任何可聯網服務器上，因為它開放的是基於網絡訪問的 S3 API。</p></blockquote><h2>測試及結果</h2><h3>測試一：10GB 文件寫入測試</h3><p>這項測試用來評估寫大文件的性能，耗時越短性能越好。這裏會使用 time 命令統計寫入耗時，結果會包含三個指標：</p><ul><li><p><strong>real</strong>：從命令開始到結束的實際時間。它包括了所有的等待時間，例如等待 I/O 操作完成、等待進程切換、等待資源等。</p></li><li><p><strong>user</strong>：在用户態（用户模式）執行的時間，也就是 CPU 用於執行用户代碼的時間。它通常表示命令的計算工作量。</p></li><li><p><strong>sys</strong>：在內核態（系統模式）執行的時間，也就是 CPU 用於執行內核代碼的時間。它通常表示命令與系統調用（如文件 I/O、進程管理等）相關的工作量。</p></li></ul><h4>MinIO</h4><pre><code class="language-bash"># 執行拷貝測試
time mc cp ./2018_Yellow_Taxi_Trip_Data.csv  my/test-minio/
</code></pre><p>MinIO 直寫 10 GB 文件的測試結果：</p><pre><code class="language-bahs">
real 0m27.651s
user 0m10.767s
sys 0m5.439s
</code></pre><h4>s3fs-fuse</h4><pre><code class="language-bash"># 執行拷貝測試
time mc cp ./2018_Yellow_Taxi_Trip_Data.csv /root/mnt-s3fs/
</code></pre><p>s3fs-fuse 寫 10 GB 文件的測試結果：</p><pre><code class="language-bash">
real 3m6.380s
user 0m0.012s
sys 0m5.459s
</code></pre><blockquote><p>注：雖然寫入耗時 3 分零 6 秒，但並沒有出現那篇文章所謂寫入失敗的情況。</p></blockquote><h4>JuiceFS POSIX 和 S3 API</h4><p>分別測試 JuiceFS 的 POSIX 和 S3 API 的大文件寫性能：</p><pre><code class="language-bash"># POSIX 寫測試
time mc cp ./2018_Yellow_Taxi_Trip_Data.csv /root/mnt-juicefs/

# S3 API 寫測試
time mc cp ./2018_Yellow_Taxi_Trip_Data.csv  juicefs/myjfs/

</code></pre><p>JuiceFS POSIX 寫 10 GB 文件的測試結果：</p><pre><code class="language-bash">
real 0m28.107s
user 0m0.292s
sys 0m6.930s
</code></pre><p>JuiceFS S3 API 寫 10GB 文件的測試結果：</p><pre><code class="language-bash">real 0m28.091s
user 0m13.643s
sys 0m4.142s
</code></pre><h4>大文件寫結果總結</h4><p><img src="https://oscimg.oschina.net/oscnet/up-173c5df31eb67e8ef11190f6d753f102a5e.png" alt="" referrerpolicy="no-referrer"></p><p>從測試結果來看，直接寫 MinIO 和 JuiceFS 的性能相當，均可在 30s 內完成，而 s3fs-fuse 寫入 10GB 文件耗時 3 分鐘以上，平均比前兩者慢了 6 倍左右。</p><p>在寫入大文件時，mc 會使用 Multipart API 來將文件分塊上傳到 S3 接口，而只能單線程寫入到 POSIX。JuiceFS 在大文件的順序寫也會自動將文件分塊並併發寫入到 MinIO 中，因此與直接寫 MinIO 性能相當。而 S3FS 默認先是單線程寫入到緩存盤，然後再分塊寫入到 MinIO 中，這會耗費更多寫入時間。</p><p>按照寫 10GB 文件耗時 30 秒計算，平均速度為 333 MB/s，這是雲服務器 SSD 的帶寬限制，測試結果表明，MinIO 和 JuiceFS 都能打滿本地 SSD 的帶寬，它們的性能會隨着服務器雲盤和網絡帶寬的提升而提升。</p><h3>測試二：Pandas 小文件覆蓋寫</h3><p>這項測試主要用來評估對象存儲在小文件覆蓋寫方面的性能，各個軟件的測試腳本略有不同，你可以在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fyuhr123%2F7acb7e6bb42fb0ff12f3ba64d2cdd7da" target="_blank">這裏</a>找到所有腳本代碼。</p><pre><code class="language-bash">
# 獲取測試腳本
curl -LO https://gist.githubusercontent.com/yuhr123/7acb7e6bb42fb0ff12f3ba64d2cdd7da/raw/30c748e20b56dec642a58f9cccd7ea6e213dab3c/pandas-minio.py

# 執行測試
python3 pandas-minio.py
</code></pre><p>測試結果：</p><pre><code class="language-bash">
Execution time: 0.83 seconds
</code></pre><h4>s3fs-fuse</h4><pre><code class="language-bash">
# 獲取測試腳本
curl -LO gist.githubusercontent.com/yuhr123/7acb7e6bb42fb0ff12f3ba64d2cdd7da/raw/30c748e20b56dec642a58f9cccd7ea6e213dab3c/pandas-s3fs.py

# 執行測試
python3 pandas-s3fs.py
</code></pre><p>測試結果：</p><pre><code class="language-bash">Execution time: 0.78 seconds
</code></pre><h4>JuiceFS POSIX</h4><pre><code class="language-bash"># 獲取測試腳本
curl -LO gist.githubusercontent.com/yuhr123/7acb7e6bb42fb0ff12f3ba64d2cdd7da/raw/30c748e20b56dec642a58f9cccd7ea6e213dab3c/pandas-juicefs-posix.py

# 執行測試
python3 pandas-juicefs-posix.py
</code></pre><p>測試結果：</p><pre><code class="language-bash">Execution time: 0.43 seconds
</code></pre><h4>JuiceFS S3 API</h4><pre><code class="language-bash"># 獲取測試腳本
curl -LO https://gist.githubusercontent.com/yuhr123/7acb7e6bb42fb0ff12f3ba64d2cdd7da/raw/30c748e20b56dec642a58f9cccd7ea6e213dab3c/pandas-juicefs-s3api.py

# 執行測試
python3 pandas-juicefs-s3api.py
</code></pre><p>測試結果：</p><pre><code class="language-bash">Execution time: 0.86 seconds
</code></pre><h4>Pandas 小文件覆蓋寫結果總結</h4><p><img src="https://oscimg.oschina.net/oscnet/up-5b3aa52d25367600d2ed77d28758cccf647.png" alt="" referrerpolicy="no-referrer"></p><p>在這項測試中，JuiceFS FUSE-POSIX 的速度最快，幾乎是其他方案的 2 倍。MinIO、s3fs-fuse、JuiceFS S3 Gateway 的速度相當。從小文件覆蓋寫的角度來看，POSIX 接口效率更高，比對象存儲接口有更好的性能表現。</p><h3>測試結果</h3><table><thead><tr><th align="left"></th><th align="right">MinIO</th><th align="right">S3FS-FUSE</th><th align="right">JuiceFS (FUSE)</th><th align="right">JuiceFS (s3 gateway)</th></tr></thead><tbody><tr><td align="left">10GB 大文件寫</td><td align="right">0m27.651s</td><td align="right">3m6.380s</td><td align="right">0m28.107s</td><td align="right">0m28.091s</td></tr><tr><td align="left">Pandas 小文件覆蓋寫</td><td align="right">0.83s</td><td align="right">0.78s</td><td align="right">0.46s</td><td align="right">0.96s</td></tr></tbody></table><h2>分析和總結</h2><p><strong>問題一：S3FS 為什麼這麼慢？</strong></p><p>從測試數據可以清楚地看到，寫入同樣的 10GB 大文件，S3FS 需要 3 分鐘，而 MinIO 和 JuiceFS 只需要 30 秒左右，速度相差近 6 倍，這主要是由於不同的技術實現導致的。</p><p>s3fs-fuse 在寫入文件時，會優先寫入本地臨時文件，然後以分片方式上傳對象存儲。如果本地磁盤空間不足，則會以同步的方式上傳。因為它需要在本地磁盤和 S3 存儲之間進行數據複製，在處理大文件或大量文件時就會導致性能下降。</p><p>再者，S3FS 依賴底層對象存儲的元數據管理能力，當需要讀寫大量文件時，頻繁地與對象存儲交互獲取元數據也會對性能產生很大的影響。</p><p>簡單來説，寫入 S3FS 的文件體積和總量越大，相應的性能開銷也會成比例地放大。</p><p><strong>問題二：JuiceFS 為什麼更快？</strong></p><p>同樣是通過 FUSE 進行讀寫，為什麼 JuiceFS 可以與 MinIO 一樣打滿磁盤帶寬，而沒有像 S3FS 那樣出現性能問題呢？這同樣也是由技術架構決定的。</p><p>在寫入文件時，數據雖然也經由 FUSE 層處理，但 JuiceFS 通過高併發、緩存、數據分塊等技術降低了與底層對象存儲之間的通信開銷，一次性處理更多文件的讀寫請求，從而減少了等待時間和傳輸延遲。</p><p>另外，JuiceFS 採用獨立的數據庫（在本文中使用了 Redis）管理元數據，當文件量特別大時，獨立的元數據引擎能有效釋放壓力，可以更快地定位文件位置。</p><h3>結論</h3><p>以上數據表明，把對象存儲作為底層，在其上實現 POSIX 接口不一定會損失性能，不論是寫大文件還是小文件，JuiceFS 的性能與直接寫 MinIO 是相當的，並沒有因為訪問 POSIX 而損失底層對象存儲的性能。而在 Pandas 表格覆蓋寫方面，JuiceFS FUSE-POSIX 的性能不降反升，超過 MinIO 近兩倍。</p><p>從測試結果不難發現，某些軟件（例如 s3fs-fuse）將 S3 API 與 POSIX 接口相互轉換可能會導致對象存儲的性能損失，但它不失為一款還算方便的臨時訪問 S3 的小工具，但要想長期穩定的高性能使用，需要通過更為審慎的調研和驗證來選擇其他更適的方案。</p><p>簡單的非結構化文件歸檔存儲，直接使用 MinIO 或雲上對象存儲是不錯的選擇。而對於需要進行大規模數據存儲和處理，如 AI 模型訓練、大數據分析和 Kubernetes 數據持久化等頻繁讀寫的場景，JuiceFS 的獨立元數據管理、併發讀寫和緩存機制會帶來更好的性能表現，是更值得嘗試的高性能文件系統解決方案。</p><p>希望這篇內容能夠對你有一些幫助，如果有其他疑問歡迎加入 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2F" target="_blank">JuiceFS 社區</a>與大家共同交流。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 06:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5389802/blog/10123104</guid>
            <link>https://my.oschina.net/u/5389802/blog/10123104</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[香橙派 Orange Pi OS (OH) 即將發佈，開源鴻蒙 PC 端]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>香橙派官方<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhcrF9uYR8yHQX6bpM1K0qg" target="_blank">發文稱</a></u>，基於 OpenHarmony 定製研發的 Orange Pi OS（OH）即將發佈！</p><p>日前，迅龍開源鴻蒙的工程師團隊已經在搭載 RK3566 的開發板 Orange Pi 3B 上完成了 Orange Pi OS(OH) 對 PC 的初步適配，<strong>這是國內首次將開源鴻蒙操作系統運行在 PC 設備上</strong>，意味着迅龍軟件將領先於華為、深開鴻等，在業內率先推出 PC 端的開源鴻蒙系統。</p><h3><strong><strong><strong>完成</strong></strong>OpenHarmony<strong><strong>對</strong></strong>PC 的適配</strong></h3><p>Orange Pi OS(OH) 已經完成了 HDMI 適配、5 寸 LCD 顯示屏適配、觸摸功能適配、定製化的系統應用、開機動畫、主題、壁紙、設置、文件管理器等，支持十幾種 hap 應用。</p><p>從相關演示可見，此次適配已經支持設備的正常開關機，原創應用包括任務欄、控制中心、設置、文件管理器、輸入法、瀏覽器、播放器、應用商城等，具備運行熱門 App 等基礎功能，可以滿足基本的辦公、娛樂需求。</p><ul><li>控制中心</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ad5a2e133c95acf0ea0b468fead31a679ac.png" referrerpolicy="no-referrer"></p><ul><li>文件管理器</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e48dc6012686d69b04cca4c32efd239067.png" referrerpolicy="no-referrer"></p><ul><li>應用展示</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3f71537b302f1b7b495b56a2fd8c2c36bd1.png" referrerpolicy="no-referrer"></p><ul><li>應用市場</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a872248edc51ee489418d3878731c181e91.png" referrerpolicy="no-referrer"></p><h3><strong>首先適配<strong><strong>Orange Pi 3B</strong></strong>、Orange Pi</strong><strong>5/5 Plus</strong></h3><p>按照計劃，Orange Pi OS(OH) 將首先適配三款設備：</p><ul><li>搭載 RK3566 的開發板 Orange Pi 3B</li><li>搭載 RK3588S 的開發板 Orange Pi 5</li><li>搭載 RK3588 的開發板 Orange Pi 5 Plus</li></ul><p>三款設備均採用 ARM 架構的 CPU。</p><p>而最先適配的是 Orange Pi 3B。Orange Pi 3B 採用了瑞芯微 RK3566 四核 64 位處理器，22nm 先進工藝，主頻最高可達 1.8GHz，集成 ARM Mali G52 2EE 圖形處理器，內置 0.8Tops 算力的 AI 加速器 NPU，擁有 2GB/4GB/8GB（LPDDR4/4X），支持 16GB /32GB/ 64GB/128GB /256GB 的 eMMC 模塊、支持 16MB/32MB SPI Flash，具有 Wi-Fi5、BT5.0，支持 BLE。</p><p>Orange Pi 3B 引用了相當豐富的接口，包括 HDMI 輸出、M.2 M-KEY（可選）、TF 卡槽、千兆網口、USB2.0、USB3.0、3.5mm 耳機插孔、MIPI DSI 接口、eDP 接口、MIPI CSI 攝像頭接口、多功能 40 Pin 擴展接口等，可廣泛適用於電視盒子、高端平板、邊緣計算、人臉識別、智能安防、智能家居等領域，賦能豐富的 AI 應用和物聯網場景。</p><p>在操作系統上，Orange Pi 3B 支持 Android11、Ubuntu22.04、Ubuntu20.04、Debian11、Debian12、開源鴻蒙 4.0 Beta1、Orange Pi OS（Arch）、基於開源鴻蒙的 Orange Pi OS（OH）等操作系統。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3037395f6b7e5a710e08660d7d5b340aa29.png" referrerpolicy="no-referrer"></p><h3><strong>下一步將適配 X86 架構的 PC</strong></h3><p>鴻蒙系統已經應用在了手機、汽車、手錶、電視、物聯網等設備上，但在個人電腦領域，由於適配的技術難度較高，鴻蒙尚未實現全面適配。但迅龍軟件一直在積極推進開源鴻蒙操作系統在 PC 領域的發展。</p><p>開發一個全新的電腦操作系統，難度非常之大，不但要基於新內核打造一個新系統，還要召集無數的開發者為其做應用方面的適配。為此，迅龍軟件成立了一個專注於開源鴻蒙的研發和商業化落地的團隊。</p><p>Orange Pi OS(OH) 目前只適配支持 ARM 架構的 PC，而迅龍的下一步計劃是適配 X86 架構的 PC。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 06:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263519</guid>
            <link>https://www.oschina.net/news/263519</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[deepin WSL 正式上架微軟商店]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="background-color:#ffffff; color:#333333">deepin 社區<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdeepin-wsl%2F" target="_blank">宣佈</a>&nbsp;</span>deepin WSL 已正式上架微軟商店。</p><p>WSL 是 Windows Subsystem for Linux 的縮寫，它是一種可以讓用户在 Windows 上運行 Linux 的技術。使用 WSL，可以輕鬆地在 Windows 和 Linux 之間切換和集成，使用開源的工具和環境來開發或測試 Linux 相關的項目，利用 Windows 的硬件支持和性能優化來運行 Linux 的應用程序，以及體驗不同的 Linux 發行版。</p><p><img height="213" src="https://oscimg.oschina.net/oscnet/up-187f0fca4a326d487fbb7a73117e9f48061.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start"><strong>使用 deepin WSL</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">1.確認系統支持：WSL 最低要求為 Windows 10 版本 1709（內部版本號 16299）或更高版本。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">2.啓用 WSL 功能：打開 Windows PowerShell(管理員權限)，運行以下命令：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><em>wsl --install​</em></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">這將啓用 WSL 和虛擬機平台功能，並下載安裝 WSL 2 引擎。或者在菜單欄中找到控制面板找到程序，選擇啓用和關閉 Windows 功能，找到「適用於 Linux 的 Windows 子系統」和 「虛擬機平台」進行勾選，會自動下載安裝需要的組件，重啓後即可。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">3.打開微軟商店，搜索 deepin wsl，找到並點擊獲取會進行安裝。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">4.初次運行時，會提示設置用户名和密碼，按照指示完成配置即可。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><img alt="" height="399" src="https://oscimg.oschina.net/oscnet/up-96917b26a11a13e6f9cfff8349e5783cb7a.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start"><strong>相關項目</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">如果想自定義 WSL 可以參考以下項目。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">1.<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepin-community%2Fdeepin-rootfs" target="_blank">deepin-rootfs</a>&nbsp;這是製作 deepin v23 的根文件系統的項目，該項目為 WSL 提供根文件系統。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">2.<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2FWSL-DistroLauncher" target="_blank">WSL-DistroLauncher</a>&nbsp;這是微軟官方官方的 WSL 啓動器。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">3.<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepin-community%2Fdeepin-wsl" target="_blank">deepin-WSL</a>&nbsp;這是基於 WSL-DistroLauncher 項目進行修改的。上架應用商店的 deepin WSL 也依賴該項目。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">4.<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyuk7%2Fwsldl" target="_blank">wsldl</a>&nbsp;這是個第三方的 WSL 啓動器。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">wsldl 為第三方提供的啓動器，新安裝一個 WSL 只需要對應的根文件系統，以及重命名一個可執行文件，使用通用工具來運行一個實例。需要自己使用命令導入根文件系統，另外默認使用 root 用户，需要自己手動配置其他用户來使用。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">WSL-DistroLauncher 官方提供的啓動器，需要將根文件系統一起打包成 Windows 下的可執行程序，另外用來上架應用商店也需要依賴該程序。需要安裝 cer 證書，雙擊運行可執行程序，安裝成功後根據提示創建一個用户。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">deepin-WSL 項目下同時提供了兩種啓動器的可執行文件。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 06:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263348</guid>
            <link>https://www.oschina.net/news/263348</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Jina AI 發佈全球首個開源 8K 文本嵌入模型，超越 OpenAI]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">人工智能公司 Jina AI 宣佈<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjina.ai%2Fnews%2Fjina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai%2F" target="_blank">推出其第二代文本嵌入模型</a>：&nbsp;<code>jina-embeddings-v2</code>&nbsp;。這款模型現在是唯一支持 8K（8192 個 token）上下文長度的開源產品。在能力和性能上與 OpenAI 的&nbsp;<code>text-embedding-ada-002</code>&nbsp;相當。</span></p><p><span style="color:#000000">與 OpenAI 的 8K 模型&nbsp;<code>text-embedding-ada-002</code>&nbsp;進行比較，</span><code>jina-embedding-v2</code><span style="color:#000000">&nbsp;在分類平均值、重排平均值、檢索平均值和摘要平均值方面超越了 OpenAI 的 <code>text-embedding-ada-002</code>。</span></p><table style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-attachment:scroll, scroll; background-color:#1e1e1e; background-repeat:no-repeat; background-size:10px 100%, 10px 100%; border-radius:8px; border-spacing:1px; box-sizing:inherit; color:#c0c4cc; display:block; font-family:poppins; font-size:clamp(0.7em, 0.7vw, 1em); font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:300; letter-spacing:normal; margin:max(3.2vmin, 24px) auto 0px; max-width:100%; orphans:2; overflow-x:scroll; text-align:left; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; vertical-align:top; white-space:nowrap; widows:2; width:auto; word-spacing:0px"><thead><tr><th style="background-color:var(--color-primary)"><span style="color:#000000">Rank</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Model</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Model Size (GB)</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Embedding Dimensions</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Sequence Length</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Average (56 datasets)</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Classification Average (12 datasets)</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Reranking Average (4 datasets)</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Retrieval Average (15 datasets)</span></th><th style="background-color:var(--color-primary)"><span style="color:#000000">Summarization Average (1 dataset)</span></th></tr></thead><tbody><tr><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">15</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">text-embedding-ada-002</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">Unknown</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">1536</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">8191</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">60.99</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">70.93</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">84.89</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">56.32</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">30.8</span></td></tr><tr><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">17</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">jina-embeddings-v2-base-en</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">0.27</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">768</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">8192</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">60.38</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">73.45</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">85.38</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">56.98</span></td><td style="background-color:rgba(255, 255, 255, 0.2)"><span style="color:#000000">31.6</span></td></tr></tbody></table><p><span style="color:#000000; font-family:-apple-system,BlinkMacSystemFont,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Segoe UI&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei&quot;,&quot;Helvetica Neue&quot;,Helvetica,Arial,sans-serif">&nbsp;</span></p><p><span style="color:#000000"><code>text-embedding-ada-002&nbsp;</code></span>的特點：</p><ul><li><span style="color:#000000">從零到卓越：這個&nbsp;<code>jina-embeddings-v2</code>&nbsp;是從頭開始構建的。在過去的三個月裏，Jina AI 的團隊進行了密集的研發、數據收集和調整。</span></li><li><span style="color:#000000">利用 8K 解鎖擴展上下文潛力：&nbsp;<code>jina-embeddings-v2</code>&nbsp;8K 的上下文長度為新的行業應用開啓了大門：</span><ul><li><span style="color:#000000">法律文件分析：確保對大量法律文本中的每一個細節進行捕捉和分析。</span></li><li><span style="color:#000000">醫學研究：為了進行高級分析和發現，全面地嵌入科學論文。</span></li><li><span style="color:#000000">文學分析：深入研究長篇內容，捕捉微妙的主題元素。</span></li><li><span style="color:#000000">財務預測：通過詳細的財務報告獲得卓越的洞察力。</span></li><li><span style="color:#000000">會話式 AI：提升聊天機器人對複雜用户查詢的響應能力。</span></li></ul></li></ul><p>同時，基準測試顯示，在多個數據集中，這種 8K 上下文長度的擴展使得 jina-embeddings-v2 超越了其它領先的嵌入模型：</p><p><img height="1026" src="https://static.oschina.net/uploads/space/2023/1026/122725_U99l_3820517.png" width="3186" referrerpolicy="no-referrer"></p><p>接下來，Jina 將會有一篇相關的學術洞察文章發表。同時團隊正在開發類似 OpenAI 的嵌入式 API 平台的產品；語言方面，正在進入多語種嵌入領域，目標是推出德英模型。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 05:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263517/jina-ai-launches-worlds-first-open-source-8k-text-embedding</guid>
            <link>https://www.oschina.net/news/263517/jina-ai-launches-worlds-first-open-source-8k-text-embedding</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[SuperCLUE 10 月榜單：vivo 自研大模型位列國內第一]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">SuperCLUE <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVEqF1RriFpP2pOO_cvHo8Q" target="_blank">發佈</a>了中文大模型 10 月榜單。其中，vivo 自研大模型以 70.74 的總分位列總排行榜第四，在國內大模型中排行第一；排在其後的分別是 Moonshot、文心一言 4.0 和 SenseChat 3.0。</span></p><p><span style="color:#000000">SuperCLUE 是中文通用大模型多層次的綜合性測評基準，包括多輪開放問題測評 SuperCLUE-OPEN 和三大能力客觀題測評 SuperCLUE-OPT。主要考察模型在中文能力上的表現，包括專業知識技能、語言理解與生成、AI 智能體和安全四大能力維度的上百個任務。</span></p><p><span style="color:#000000">本次評測選取了目前國內外最具代表性的 20 個通用大語言模型。與 9 月相比，新增了月之暗面的 Moonshot、百度的文心一言 4.0、科大訊飛的星火 V3.0、vivo 的 vivoLM 和阿里雲的 Qwen-14B。</span></p><p><span style="color:#000000"><img alt="" height="387" src="https://oscimg.oschina.net/oscnet/up-888da32dd07eb885b7523790e04c2ba5d59.png" width="400" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">評測發現，國內第一梯隊大模型格局已基本形成，在過去 11 個月的成績令人振奮，頭部幾個中文大模型已經與 GPT3.5 極為接近。但與 GPT4 的距離依然遙遠，尚未發現有對標和媲美 GPT4 的跡象。</span></p><p><span style="color:#000000"><img alt="" height="330" src="https://oscimg.oschina.net/oscnet/up-de85cfac6d99f493822220d7125e5f6a072.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">10 月評測數據集為全新的 3754 道測試題，其中包括 606 道多輪簡答題和 3148 道客觀選擇題。</span></p><p><span style="color:#000000"><strong>總排行榜</strong></span></p><p><span style="color:#000000"><strong><img alt="" height="384" src="https://oscimg.oschina.net/oscnet/up-6f6d739e88a023ebf8dd36f8dcffa0f3232.png" width="300" referrerpolicy="no-referrer"></strong></span></p><p><span style="color:#000000">注：本次評測的 GPT3.5 版本為 gpt-3.5-turbo-16k；文心一言 4.0 和 SenseChat3.0 由於分數非常接近（在 0.05 分以內）認定為並列。</span></p><p><strong><span style="color:#000000">多輪開放問題 OPEN 排行榜</span></strong></p><p><img alt="" height="317" src="https://oscimg.oschina.net/oscnet/up-b88628f6ee5e93fd8b0b14a9424c200f852.png" width="300" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">三大能力客觀題 OPT 排行榜</span></strong></p><p><img alt="" height="322" src="https://oscimg.oschina.net/oscnet/up-92174a429ffc75918fd5fafe5a2a88ca814.png" width="300" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">十大基礎能力榜單</span></strong></p><p><img alt="" height="417" src="https://oscimg.oschina.net/oscnet/up-6a0c7eaab5ab0b4da9dcf89c3784747dbdf.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">開源模型排行榜</span></strong></p><p><strong><span style="color:#000000"><img alt="" height="318" src="https://oscimg.oschina.net/oscnet/up-f39e0e579251fd4416fc3703af0fc769c61.png" width="500" referrerpolicy="no-referrer"></span></strong></p><p><strong><span style="color:#000000">SuperCLUE 觀點</span></strong></p><ul><li><span style="color:#000000">國內第一梯隊大模型經過 11 個月的努力，已經與 GPT3.5 極為接近。但與 GPT4 的距離依然巨大，尚未發現有對標和媲美 GPT4 的跡象。</span></li><li><span style="color:#000000">國內大模型多數擅長做選擇題，在三大能力客觀題 OPT 分數上有不少已經超過 GPT3.5。SuperCLUE 認為，客觀題相對主觀題更容易通過題庫形式進行訓練和提升；同時也由於客觀題中包含中文特性問題，中文模型自然有一定的優勢。</span></li><li><span style="color:#000000">國內大模型廠商從算力、數據、人才層面上做了很多努力，SuperCLUE 預計在接下來一個季度內將會出現全面超越 GPT3.5 的通用大模型。但如何趕超 GPT4，又會成為擺在所有中文模型研發機構面前新的難題。</span></li><li><span style="color:#000000">SuperCLUE 國內大模型能力成熟度：在語言理解與生成能力、大模型安全性防護能力上，國內一線模型已經相對成熟、表現優異；在專業技能與知識上，已能滿足一些應用需求；在 Agent 智能體能力上，還相對落後、成熟度低。</span></li></ul><p><strong><span style="color:#000000"><span style="background-color:#ffffff">榜單地址：</span></span></strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.superclueai.com%2F" target="_blank">https://www.superclueai.com/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 03:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263504</guid>
            <link>https://www.oschina.net/news/263504</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟 CEO 納德拉：放棄 Windows Phone 和移動業務是錯誤決策]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>微軟 CEO 納德拉 (Satya Nadella) 近日在接受媒體訪問時<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2F2023%2F10%2F24%2F23930478%2Fmicrosoft-ceo-satya-nadella-mobile-windows-phone" target="_blank">表示</a></u>，<strong>微軟放棄 Windows Phone 和移動業務是錯誤決策</strong>。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1026/104708_aov4_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>納德拉在 2014 年接替鮑爾默 (Steve Ballmer) 擔任 CEO，僅僅一年之後就宣佈裁撤了鮑爾默任內斥資 76 億美元收購的諾基亞手機業務。此後 Windows Phone 事實上就退出了移動市場。</p><p>在接受 Business Insider 採訪時，納德拉坦言微軟在「退出」手機業務上處理得不夠恰當。在被問及他可能後悔的戰略錯誤或錯誤決定時，納德拉回答道：</p><blockquote><p>「這項決定（退出手機業務）時常被人拿出來討論，也是我出任首席執行官之後做出的最困難決定——退出「當時定義下的手機」。</p><p>現在回想起來，我認為我們可以通過重新發明個人電腦、平板電腦和手機之間的計算類別，來重振手機業務。」</p></blockquote><p>在諾基亞手機業務被放棄多年後，微軟才最終確認 Windows Phone 已經消亡。此後，微軟推出了基於 Android 的 Surface Duo 和 Surface Duo 2 手機，但由於沒有後續產品，也缺乏軟件更新，因此 Surface Duo 手機品牌的未來懸而未決。</p><p>納德拉是微軟歷史上第三位對移動領域的巨大失誤進行反思的首席執行官。至於前兩位，相信大家都不會陌生——</p><p>第一位比爾・蓋茨：未收購安卓</p><p>微軟聯合創始人兼前首席執行官比爾・蓋茨表示，他「有史以來最大的錯誤」是微軟輸給了 Android。</p><p>谷歌於 2005 年以 5000 萬美元收購了 Android，前首席執行官埃裏克・施密特 (Eric Schmidt) 在 2012 年承認，谷歌最初的重點是擊敗微軟早期的 Windows Mobile 努力。</p><p>第二位鮑爾默：對 Android 和 iOS 威脅反應遲緩</p><p>微軟前首席執行官史蒂夫・鮑爾默（Steve Ballmer）對 Android 和 iPhone 的威脅也反應遲緩，他將公司的精力集中在 Windows Mobile 上，同時還嘲笑 iPhone，稱其為「世界上最昂貴的手機，對商業客户沒有吸引力」。因為它沒有鍵盤。」</p><p>鮑爾默在 2013 年承認，他後悔沒有早點關注手機。「我很遺憾在 2000 年代初的一段時期，我們過於專注於 Windows [Vista] 周圍的工作，以至於無法將人才重新部署到稱為手機的新設備上」，鮑爾默解釋道，「這是我最後悔的事情。」</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263488/ms-ceo-satya-nadella-mobile-windows-phone</guid>
            <link>https://www.oschina.net/news/263488/ms-ceo-satya-nadella-mobile-windows-phone</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openKylin 在 2023 CCF 中國開源大會發布「開明軟件包格式」!]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span>10 月 21-22 日，以「開源聯合，聚力共贏」為主題的 2023 CCF 中國開源大會在長沙北辰國際會議中心隆重召開。<strong>openKylin（開放麒麟）社區與麒麟軟件作為本屆 CCF 中國開源大會的重要合作伙伴，受邀參與本屆大會，共見中國開源新徵程，共築中國開源新未來。</strong></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-2c25e685ce2bb8b679685fd86c5ea089d96.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong>10 月 21 日上午，大會主會場「發佈儀式」環節，openKylin 社區技術委員會副主任、麒麟軟件有限公司高級副總經理魏立峯帶來 openKylin 開源社區「開明軟件包格式」發佈。</strong>與傳統軟件包管理方式相比，開明軟件包使應用隔離更兼容，支持一次打包，多處發佈；支持 Linux 存量應用、AppImage 和 Flatpak 等多種格式應用的導入，統一管理；支持應用間隔離和更細粒度的權限管控，提高安全性，保護用户在每個應用中的隱私。</span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f236e9c826fcd669bc5761c98de95e68807.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong>10 月 22 日上午，麒麟軟件有限公司高級副總經理蘭雨晴受邀出席中國電子開源高峯論壇</strong>，與飛騰信息技術有限公司首席科學家竇強，華為首席開源聯絡官、CNCF 基金會董事任旭東，阿里雲數據庫產品事業部負責人李飛飛，中國科學院計算技術研究所副所長、研究員包雲崗和中國長城科技集團高級副總裁兼長城研究院院長李璇等眾專家，結合自身實踐與洞察，對計算產業的開源發展之路進行多維度的探討與交流。</span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-1d79775d24cc7c41e1361a3c5541a43b7ba.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong>10 月 22 日下午，openKylin 社區技術委員會委員、麒麟軟件有限公司版本平台部副經理毛周受邀出席開源供應鏈安全技術分論壇</strong>，以<strong>《openKylin 開源社區安全體系建設》</strong>為題，介紹了開源安全風險現狀以及 openKylin 社區為應對開源安全風險採取的舉措。當前，開源安全風險已成為全球化挑戰，openKylin 社區為更好的開展安全體系建設，組建了社區安全治理 SIG 組，引入 SDL 安全開發流程，並建設維護了 OKSRC（ 開放麒麟安全應急響應中心）、openKylin 漏洞感知大腦項目、openKylin 漏洞動態檢測框架等一系列安全漏洞響應處理平台項目，為社區開發的全鏈路保駕護航。</span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ab7e93745984ad2cbca48239d13d3de289f.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong>10 月 22 日下午，麒麟軟件雲事業部研發總監，銀河麒麟雲原生操作系統技術負責人李俊良受邀出席開源社區建設與技術發展分論壇，</strong>以<strong>《操作系統與雲原生開源技術體系的融合探索》</strong>為題，回顧雲原生開源技術體系發展歷程，前瞻雲原生操作系統未來的發展趨勢，為大家講解介紹了銀河麒麟雲原生操作系統架構方案。</span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-0783ca15b4303ee1de5879aa6efa6ea469e.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span>同時，大會期間，openKylin 社區在二樓北辰廳南側序廳設置展台，眾多與會來賓圍聚展台前進行交流，打造一場身臨其境的沉浸式開源互動體驗。</span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e28f266aeb2be6485d5aa850758b9b8148c.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span>聚開源各界羣智，於湘江之濱論道。2023 CCF 中國開源大會已結束！openKylin 作為我國桌面操作系統根社區，未來，也將持續在開源生態、人才培養、核心技術研究等領域努力，攜手社區合作伙伴和開發者，為中國開源建設做出貢獻，共同推動我國開源技術創新和生態完善，共創開源美好未來！</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 24 Oct 2023 01:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263472</guid>
            <link>https://www.oschina.net/news/263472</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[mysqlstat - MySQL 命令行監控工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="project_detail_above_text_link_1" data-tracepid="project_detail_above_text_link"><a style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代 <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p style="margin-left:0px; margin-right:0px; text-align:start">mysqlstat 是一個命令行工具，用於實時監控和分析 MySQL 服務器的性能指標和相關信息。</p><p style="text-align:start">它可以幫助 DBA（數據庫管理員）和開發人員定位和解決數據庫性能問題。</p><p style="text-align:start">以下是 mysqlstat 工具的主要功能：</p><ul><li>實時監控：mysqlstat 可以實時監控 MySQL 服務器的 QPS（每秒查詢數）、TPS（每秒事務數）以及網絡帶寬使用情況等指標。</li><li>查詢分析：它可以展示執行次數最頻繁的前 N 條 SQL 語句，幫助定位查詢效率低下的問題，以便進行優化。</li><li>表文件分析：mysqlstat 可以列出訪問次數最頻繁的前 N 張表文件（.ibd），這有助於查找熱點表和磁盤使用情況。</li><li>鎖阻塞：工具可以顯示當前被鎖阻塞的 SQL 語句，幫助識別並解決鎖相關的問題。</li><li>死鎖信息：mysqlstat 可以提供關於死鎖的信息，幫助 DBA 瞭解並解決死鎖問題。</li><li>索引分析：它可以查找重複或冗餘的索引，幫助優化索引使用和減少存儲空間的佔用。</li><li>連接數統計：工具可以統計應用端 IP 的連接數總和，有助於瞭解數據庫的連接負載情況。</li><li>表大小統計：mysqlstat 可以提供庫中每個表的大小統計信息，有助於瞭解表的存儲佔用情況。</li><li>Binlog 分析：它可以在高峯期分析哪些表的 TPS 較高，幫助定位性能瓶頸或優化熱點表。</li><li>查看主從複製信息：工具可以提供主從複製狀態和延遲情況，方便監控和管理主從複製環境。</li></ul><pre><code class="language-bash">MySQL 命令行監控工具 - mysqlstat

options:
  -h, --help            show this help message and exit
  -H MYSQL_IP, --mysql_ip MYSQL_IP
                        Mysql IP
  -P MYSQL_PORT, --mysql_port MYSQL_PORT
                        Mysql Port
  -u MYSQL_USER, --mysql_user MYSQL_USER
                        Mysql User
  -p MYSQL_PASSWORD, --mysql_password MYSQL_PASSWORD
                        Mysql Password
  --top  N              需要提供一個整數類型的參數值，該參數值表示執行次數最頻繁的前 N 條 SQL 語句
  --io  N               需要提供一個整數類型的參數值，該參數值表示訪問次數最頻繁的前 N 張表文件 ibd
  --lock                查看當前鎖阻塞的 SQL
  --dead                查看死鎖信息
  --index               查看重複或冗餘的索引
  --conn                查看應用端 IP 連接數總和
  --tinfo               統計庫裏每個表的大小
  --binlog              Binlog 分析-高峯期排查哪些表 TPS 比較高
  --repl                查看主從複製信息
  -v, --version         show program's version number and exit</code></pre><h1 style="margin-left:0; margin-right:0; text-align:start">使用</h1><ul><li>實時監控 mysql 服務器的 QPS、TPS、網絡帶寬指標（默認不加參數選項）</li></ul><div style="text-align:start"><pre><code>shell&gt; chmod 755 mysqlstat  
shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang'
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/274128415-a35ca689-3cc0-4ec9-8b5f-6682a1986511.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/274128415-a35ca689-3cc0-4ec9-8b5f-6682a1986511.png" referrerpolicy="no-referrer"></a></p><ul><li>執行次數最頻繁的前 10 條 SQL 語句</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --top 10
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/273813598-11437da2-40c2-4ccf-8f9f-79d9d6f52d3d.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/273813598-11437da2-40c2-4ccf-8f9f-79d9d6f52d3d.png" referrerpolicy="no-referrer"></a></p><ul><li>訪問次數最頻繁的前 10 張表文件 ibd</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --io 10
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/273924296-025cc1d2-0548-464b-8e1a-1011ae06b6f2.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/273924296-025cc1d2-0548-464b-8e1a-1011ae06b6f2.png" referrerpolicy="no-referrer"></a></p><ul><li>查看當前鎖阻塞的 SQL</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --lock
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/274178002-2482a30a-84e9-4b04-b811-6cef5f14e196.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/274178002-2482a30a-84e9-4b04-b811-6cef5f14e196.png" referrerpolicy="no-referrer"></a></p><ul><li>查看重複或冗餘的索引</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --index
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/274191153-aebb781f-fcf0-4d41-8364-d381795913df.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/274191153-aebb781f-fcf0-4d41-8364-d381795913df.png" referrerpolicy="no-referrer"></a></p><ul><li>查看應用端 IP 連接數總和</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --conn
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/273929855-cf0c1e44-7ab9-4aa0-9461-e4e927a51da7.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/273929855-cf0c1e44-7ab9-4aa0-9461-e4e927a51da7.png" referrerpolicy="no-referrer"></a></p><ul><li>統計庫裏每個表的大小</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --tinfo
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/273930586-9b500c54-2db0-4f43-8d42-ca24f7a12223.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/273930586-9b500c54-2db0-4f43-8d42-ca24f7a12223.png" referrerpolicy="no-referrer"></a></p><ul><li>查看死鎖信息</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --dead
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/273931418-2fb154d3-9d44-4eb1-9580-e43a22173dc0.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/273931418-2fb154d3-9d44-4eb1-9580-e43a22173dc0.png" referrerpolicy="no-referrer"></a></p><ul><li>Binlog 分析-高峯期排查哪些表 TPS 比較高</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --binlog mysql-bin.000003
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/274125842-14ec7453-c5f1-4964-abef-69e04015abf8.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/274125842-14ec7453-c5f1-4964-abef-69e04015abf8.png" referrerpolicy="no-referrer"></a></p><ul><li>查看主從複製信息</li></ul><div style="text-align:start"><pre><code>shell&gt; ./mysqlstat -H 192.168.198.239 -P 6666 -u admin -p 'hechunyang' --repl
</code></pre></div><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/274172613-367617bd-983c-4625-970c-ef5f59f9dec0.png" target="_blank"><img alt="image" src="https://user-images.githubusercontent.com/19261879/274172613-367617bd-983c-4625-970c-ef5f59f9dec0.png" referrerpolicy="no-referrer"></a></p><p style="text-align:start">支持 MySQL5.7/8.0，工具適用於 Centos7 系統。</p><p style="text-align:start">8.0 默認是 caching_sha2_password 用户認證，需要更改為 mysql_native_password</p><div style="text-align:start"><pre><code>mysql&gt; CREATE USER 'rd'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
Query OK, 0 rows affected (0.00 sec)</code></pre></div></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 23 Oct 2023 09:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/mysqlstat</guid>
            <link>https://www.oschina.net/p/mysqlstat</link>
        </item>
        <item>
            <title>
                <![CDATA[InfoWorld 公佈 2023 年最佳開源軟件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">InfoWorld 公佈了 2023 年最佳開源軟件榜單，<span style="background-color:#ffffff">旨在表彰年度領先的軟件開發、數據管理、分析、人工智能和機器學習開源工具。</span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">InfoWorld 是致力於引領 IT 決策者走在科技前沿的國際科技媒體品牌，每年 InfoWorld 都會根據軟件對開源界的貢獻，以及在業界的影響力評選出當年的 「最佳開源軟件」 (InfoWorld's Best of Open Source Software Awards, Bossies)，該獎項評選已經延續了十多年。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="328" src="https://oscimg.oschina.net/oscnet/up-7bcc961f98e1b6cd416e92f9b7a4def7253.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">此次上榜的 25 個軟件涵蓋<span style="background-color:#ffffff">編程語言、運行時、應用程序框架、數據庫、分析引擎、機器學習庫、大型語言模型 (LLM)、用於部署 LLM 的工具等領域，具體如下</span><span style="background-color:#ffffff">（點擊每個項目名可跳轉進入項目介紹頁面）：</span></span></p><h4><span style="color:#000000"><a href="https://www.oschina.net/p/hudi"><strong>Apache Hudi</strong></a></span></h4><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">在構建開放式數據湖或<span style="background-color:#ffffff">湖倉一體</span>時，許多行業都需要一個更可發展和可變化的平台。以出版商、廣告商和媒體買家的廣告平台為例，僅有快速分析是不夠的。<span style="background-color:#ffffff">InfoWorld 認為，</span>Apache Hudi 不僅提供了快速的數據格式、表格和 SQL，還使它們能夠進行低延遲的實時分析。它與 Apache Spark、Apache Flink 以及 Presto、StarRocks 和 Amazon Athena 等工具集成。簡而言之，如果你想在數據湖上進行實時分析，Hudi 是一個非常不錯的選擇。</span></p><h4><a href="https://www.oschina.net/p/iceberg"><span style="color:#2980b9"><strong>Apache Iceberg</strong></span></a></h4><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">「<span style="background-color:#ffffff">HDFS 和 Hive 太慢了</span>」<span style="background-color:#ffffff">。Apache Iceberg 不僅能與 Hive 協同工作，還能直接與 Apache Spark 和 Apache Flink 以及 ClickHouse、Dremio 和 StarRocks 等其他系統協同工作。Iceberg 可為所有這些系統提供高性能的表格式，同時支持完整的模式演進、數據壓縮和版本回滾。Iceberg 是許多現代開放數據湖的關鍵組成部分。</span></span></p><h4><a href="https://www.oschina.net/p/caravel"><span style="color:#2980b9"><strong><span style="background-color:#ffffff">Apache Superset</span></strong></span></a></h4><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><span style="background-color:#ffffff">多年來，Apache Superset 一直是數據可視化領域的佼佼者。對於想要大規模部署自助服務、面向客户或面向用户的分析工具的人來説，Superset 幾乎是唯一的選擇。Superset 幾乎可以為任何分析場景提供可視化功能，包括從餅狀圖到複雜的地理空間圖表。它適用於大多數 SQL 數據庫，並提供 drag-and-drop builder&nbsp; 和 SQL IDE。如果你要對數據進行可視化，Superset 值得一試。</span></span></p><h4><span style="color:#000000"><a href="https://www.oschina.net/p/bun"><strong><span style="background-color:#ffffff">Bun</span></strong></a></span></h4><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Bun&nbsp;是採用&nbsp;Zig 語言編寫的高性能 「全家桶」 JavaScript 運行時，官方稱其為 "<strong>all-in-one</strong>&nbsp;JavaScript runtime"。<span style="background-color:#ffffff">Bun 提供了打包、轉譯、安裝和運行 JavaScript &amp; TypeScript 項目的功能，內置原生打包器 (native bundler)、轉譯器、task runner、npm 客户端，以及&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2Ffetch" target="_blank"><span style="color:#000000"><code>fetch</code></span></a><span style="color:#000000"><span style="background-color:#ffffff">、</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWebSocket" target="_blank"><span style="color:#000000"><code>WebSocket</code></span></a><span style="color:#000000"><span style="background-color:#ffffff">等 Web API。</span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><span style="background-color:#ffffff">InfoWorld </span>評價稱，當你以為 JavaScript 已經進入可預見的 routine 時，Bun 出現了。這個「輕佻」的名字掩蓋了它嚴肅的目標：將服務器端 JS--運行時、捆綁程序、包管理器--所需的一切都集成到一個工具中。讓它成為 Node.js 和 NPM 的直接替代品，但速度要快得多。這個簡單的主張似乎讓 Bun 成為了自 Node 顛覆 applecart 以來最具顛覆性的 JavaScript 工具。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">Bun 的速度部分歸功於 Zig，其餘則歸功於創始人 Jared Sumner 對性能的執着追求。除了性能之外，將所有工具集成在一個軟件包中，也讓 Bun 成為 Node 和 Deno 的有力替代品。</span></p><h4><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Findex%2Fclaude-2" target="_blank"><span style="color:#2980b9"><strong>Claude 2</strong></span></a></h4><p><span style="color:#000000">Anthropic 的 Claude 2 在單個提示中最多可接受 100K tokens（約 7 萬字），並可生成多達數千個 tokens 的故事。Claude 可以編輯、改寫、總結、分類、提取結構化數據、根據內容進行問答等。它在英語方面的訓練最多，但在其他一系列常用語言方面也表現出色。Claude 還掌握了大量常用編程語言的知識。</span></p><p><span style="color:#000000">Claude 從一開始就被訓練成&nbsp;<span style="background-color:#ffffff">helpful、honest 以及 harmless&nbsp;</span>的機器人，並經過廣泛的重新訓練，變得更加無害，更難產生攻擊性或危險的輸出。它不會根據你的數據進行訓練，也不會在互聯網上查詢答案。</span></p><h4><a href="https://www.oschina.net/p/cockroach"><span style="color:#2980b9"><strong>CockroachDB</strong></span></a></h4><p><span style="color:#000000">CockroachDB 是一種分佈式 SQL 數據庫，可實現強一致性 ACID 事務，通過實現數據庫讀寫的水平擴展性，解決了高性能、事務繁重型應用程序的關鍵擴展性問題。CockroachDB 還支持多區域和多雲部署，以減少延遲並遵守數據法規。部署實例包括 Netflix 的數據平台，該平台擁有 100 多個 CockroachDB 生產集羣，支持媒體應用和設備管理。主要客户包括 Hard Rock Sportsbook、摩根大通、桑坦德銀行和 DoorDash。</span></p><h4><a href="https://www.oschina.net/p/cpython"><strong>CPython</strong></a></h4><p><span style="color:#000000">在 Python 3.11 和 Python 3.12 這兩個版本中，Python 核心開發團隊對 Python 解釋器的參考實現 CPython 進行了一系列變革性升級。其結果是，Python 運行時性能對所有人來説都實現了大幅提升，而不僅限於那些選擇使用新庫或 cutting-edge 語法的少數人。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">InfoWorld 認為，</span>全局解釋器鎖（Global Interpreter Lock）是阻礙 Python 真正實現多線程並行的一個長期障礙。</span></p><h4><a href="https://www.oschina.net/p/duckdb"><strong>DuckDB</strong></a></h4><p><span style="color:#000000">DuckDB 是一種分析數據庫，它秉承了 SQLite 等小型但功能強大的項目的精神。DuckDB 提供所有熟悉的 RDBMS 功能--SQL 查詢、ACID 事務、二級索引--但增加了分析功能，如大型數據集的連接和聚合。它還可以攝取和直接查詢常見的大數據格式，如 Parquet。</span></p><h4><span style="color:#000000"><strong><a href="https://www.oschina.net/p/htmx">HTMX</a> 和 </strong></span><a href="https://www.oschina.net/p/hyperscript"><strong>Hyperscript</strong><span>&nbsp;</span></a></h4><p><span style="color:#000000">HTMX 採用了大眾所熟悉和喜愛的 HTML，並通過增強功能對其進行了擴展，使編寫現代網絡應用程序變得更加容易。HTMX 消除了用於連接網絡前端和後端的大量模板 JavaScript。相反，它使用直觀的 HTML 屬性來執行任務，如發出 AJAX 請求和用數據填充元素。</span></p><p><span style="color:#000000">同類項目 Hyperscript 引入了類似於 HyperCard 的語法，簡化了許多 JavaScript 任務，包括異步操作和 DOM 操作。總之，HTMX 和 Hyperscript 為當前的反應式框架趨勢提供了一個大膽的替代方案。</span></p><h4><a href="https://www.oschina.net/p/istio"><strong>Istio</strong></a></h4><p><span style="color:#000000">Istio 是一個服務網格，可為基於容器的微服務簡化網絡和通信，提供流量路由、監控、日誌記錄和可觀測性，同時通過加密、身份驗證和授權功能增強安全性。</span></p><p><span style="color:#000000">Istio 將通信及其安全功能與應用程序和基礎架構分離開來，從而實現了更安全、更一致的配置。該架構由部署在 Kubernetes 集羣中的控制平面和用於控制通信策略的數據平面組成。2023 年，Istio 從 CNCF 孵化項目中畢業，在雲原生社區中獲得包括谷歌、IBM、紅帽、Solo.io 等公司在內的支持和貢獻。</span></p><h4><a href="https://www.oschina.net/p/kata-containers"><strong>Kata Containers</strong></a></h4><p><span style="color:#000000">Kata Containers 結合了容器的速度和虛擬機的隔離性，是一種安全的容器運行時，使用了英特爾 Clear Containers 和 Hyper.sh runV。Kata Containers 可與 Kubernetes 和 Docker 協同工作，同時支持多種硬件架構，包括 x86_64、AMD64、Arm、IBM p 系列和 IBM z 系列。</span></p><p><span style="color:#000000">獲得了谷歌雲、微軟、AWS、阿里雲、思科、戴爾、英特爾、紅帽、SUSE 和 Ubuntu 等企業的贊助。</span></p><h4><a href="https://www.oschina.net/p/langchain"><strong>LangChain</strong></a></h4><p><span style="color:#000000">LangChain 是一個模塊化框架，可簡化由語言模型驅動的應用程序的開發。LangChain 使語言模型能夠連接到數據源並與其環境交互。LangChain 組件是模塊化抽象和抽象實現的集合。</span></p><p><span style="color:#000000">LangChain off-the-shelf chains 是組件的結構化組合，用於完成特定的高級任務。你可以使用組件定製現有的鏈，也可以構建新的鏈。LangChain 目前有三個版本： 一個是 Python 版本，一個是 TypeScript/JavaScript 版本，還有一個是 Go 版本。截至目前，已有大約 160 個 LangChain 集成。</span></p><h4><span style="color:#000000"><strong>Language Model Evaluation Harness</strong></span></h4><p><span style="color:#000000">當一個新的大語言模型（LLM）發佈時，通常都會被進行評估，將該模型與 ChatGPT 在某個基準上進行比較，很多公司可能會使用 lm-eval-harness 來生成評估分數。lm-eval-harness 由分佈式人工智能研究所 EleutherAI 創建，包含 200 多個基準，而且很容易擴展。該工具甚至被用來發現現有基準中的不足，以及為 Hugging Face 的開放式 LLM 排行榜提供支持。</span></p><h4><span style="color:#000000"><a href="https://www.oschina.net/p/llama"><strong>Llama 2</strong></a></span></h4><p><span style="color:#000000">Llama 2 是 Meta AI 的下一代大型語言模型，與 Llama 1 相比，其訓練數據量增加了 40%（來自公開來源的 2 萬億個 tokens），上下文長度增加了一倍（4096）。</span></p><p><span style="color:#000000">Llama 2 是一個<span style="background-color:#ffffff">使用優化的 Transformer 架構的</span> auto-regressive 語言模型。調整後的版本使用了監督微調（SFT）和人類反饋強化學習（RLHF），以符合人類對有用性和安全性的偏好。Code Llama 是通過在代碼特定數據集上對 Llama 2 進行微調而訓練出來的，它可以根據代碼或自然語言提示生成代碼和有關代碼的自然語言。</span></p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/p/ollama"><strong>Ollama</strong></a></h4><p><span style="color:#000000">Ollama 是一款命令行工具，可在 macOS 和 Linux 上本地運行 Llama 2、Code Llama 和其他模型，並計劃支持 Windows。Ollama 目前支持近二十多個語言模型系列，每個模型系列都有許多可用的"tags"。Tags&nbsp;是模型的變體，這些模型使用不同的微調方法以不同的規模進行訓練，並以不同的級別進行量化，以便在本地良好運行。量化級別越高，模型越精確，但運行速度越慢，所需的內存也越大。</span></p><h4><a href="https://www.oschina.net/p/polars"><strong>Polars</strong></a></h4><p><span style="color:#000000">Pandas 能做到的 Polars 不一定能做到，但它能做到的事情都能以極快的速度完成--比 Pandas 快 10 倍，使用的內存只有 Pandas 的一半。來自 PySpark 的開發人員會覺得 Polars API 比 Pandas 中的更易上手。如果你正在處理大量數據，Polars 會讓你的工作速度更快。</span></p><h4><a href="https://www.oschina.net/p/postgresql"><strong>PostgreSQL</strong></a></h4><p><span style="color:#000000">PostgreSQL 已經有 35 年的歷史，有 700 多位貢獻者參與其中，在關係數據庫管理系統中估計佔有 16.4% 的市場份額。最近的一項調查顯示，在 9 萬名開發人員中，45% 的人首選 PostgreSQL。</span></p><p><span style="color:#000000">9 月份發佈的 PostgreSQL 16 提升了聚合和選擇不同查詢的性能，增加了查詢並行性，帶來了新的 I/O 監控功能，並增加了更細粒度的安全訪問控制。同樣在 2023 年，Amazon Aurora PostgreSQL 增加了 pgvector，以支持生成式 AI 嵌入，谷歌雲也為 AlloyDB PostgreSQL 發佈了類似的功能。</span></p><h4><a href="https://www.oschina.net/p/qlora"><strong>QLoRA</strong></a></h4><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">QLoRA 是華盛頓大學提出的一種有效的微調方法，可以減少內存使用量，足以在單個 48GB GPU 上微調 65B 參數模型，同時保留完整的 16 位微調任務性能。QLoRA 通過凍結的 4 位量化預訓練語言模型將梯度反向傳播到低階適配器 (LoRA)。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">使用 QLoRA 意味着你可以在台式機上微調 30B 以上的龐大參數模型，與在多個 GPU 上進行全面調整相比，精度損失很小。事實上，QLoRA 有時甚至做得更好。InfoWorld 評價稱，「低位推理和訓練意味着更多的人可以使用 LLM--這不正是開源的意義所在嗎？」</span></p><h4><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frapids.ai%2F" target="_blank"><span style="color:#2980b9"><strong>RAPIDS</strong></span></a></h4><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">RAPIDS&nbsp;是用於常見數據科學和分析任務的 GPU 加速庫的集合。每個庫處理特定的任務，例如用於數據幀處理的 cuDF、用於圖形分析的 cuGraph 和用於機器學習的 cuML 。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">其他庫涵蓋圖像處理、信號處理和空間分析，而集成則將 RAPIDS 引入 Apache Spark、SQL 和其他工作負載。如果現有的庫都不符合要求，RAPIDS 還包括 RAFT，這是用於構建自己的解決方案的 GPU-accelerated primitives 的集合。RRAPIDS 還可與 Dask 攜手跨多個節點進行擴展，並與 Slurm 一起在高性能計算環境中運行。</span></span></p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/p/spark-nlp"><strong>Spark NLP</strong></a></h4><p><span style="color:#000000"><span style="background-color:#ffffff">Spark NLP 是一個自然語言處理庫，可在 Apache Spark 上運行，支持 Python、Scala 和 Java。該庫可幫助開發人員和數據科學家嘗試使用大型語言模型，</span><span style="background-color:#ffffff">包括來自 Google、Meta、OpenAI 等的 Transformer 模型。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Spark NLP 的模型中心有 2 萬多個模型和管道可供下載，用於語言翻譯、命名實體識別、文本分類、問題解答、情感分析和其他用例。2023 年，Spark NLP 發佈了許多 LLM 集成、新的圖像到文本註釋器、對所有主要公共雲存儲系統的支持以及對 ONNX（開放神經網絡交換）的支持。</span></span></p><h4><a href="https://www.oschina.net/p/starrocks"><strong>StarRocks</strong></a></h4><p><span style="color:#000000">分析技術已經發生了變化。如今的公司經常要向數百萬併發用户實時提供複雜的數據，即使是 PB 級的查詢也必須在數秒內完成。StarRocks 是一個查詢引擎，它結合了 native code（C++）、高效的基於成本的優化器、使用 SIMD 指令集的矢量處理、緩存和物化視圖，可高效處理大規模連接。</span></p><p><span style="color:#000000">StarRocks 甚至能在直接查詢數據湖和湖倉一體（包括 Apache Hudi 和 Apache Iceberg）時提供接近原生的性能。InfoWorld 認為，無論你是在追求實時分析、提供面向客户的分析服務，還是隻是想在不移動數據的情況下查詢數據湖，StarRocks 都值得一試。</span></p><h4><a href="https://www.oschina.net/p/tensorflow-js"><strong>TensorFlow.js</strong></a></h4><p><span style="color:#000000">TensorFlow.js 將谷歌 TensorFlow 機器學習框架的強大功能打包到 JavaScript 軟件包中，以最低的學習成本為 JavaScript 開發人員帶來非凡的功能。你可以在瀏覽器、帶有 WebGL 加速功能的純 JavaScript 棧或服務器上的 tfjs-node 庫中運行 TensorFlow.js。Node 庫為你提供了相同的 JavaScript API，但運行於 C 二進製程序之上，可最大限度地提高速度和 CPU/GPU 使用率。</span></p><p><span style="color:#000000">「就對機器學習感興趣的 JS 開發人員而言，TensorFlow.js 顯然是是一個不錯的選擇。它為 JS 生態系統做出了值得歡迎的貢獻，讓廣大開發者更容易接觸到人工智能。」</span></p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/p/vllm"><strong>vLLM</strong></a></h4><p><span style="color:#000000">由於急於在生產中部署大語言模型，導致出現了大量專注於盡可能快地進行推理的框架。vLLM 是最有前途的框架之一，它支持 Hugging Face 模型、兼容 OpenAI 的 API 和 PagedAttention 算法。</span></p><p><span style="color:#000000">目前，它是在生產中為 LLM 提供服務的不二之選，並且 FlashAttention 2 支持等新功能也在快速添加中。</span></p><h4 style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/p/weaviate"><strong>Weaviate</strong></a></h4><p><span style="color:#000000">生成式 AI 的蓬勃發展激發了對新型數據庫的需求，這種數據庫可以支持海量複雜的非結構化數據。向量數據庫應運而生。</span></p><p><span style="color:#000000">Weaviate 在部署模式、生態系統集成和數據隱私方面為開發人員提供了大量靈活性。Weaviate 將關鍵詞搜索與向量搜索相結合，可快速、可擴展地發現多模態數據（文本、圖像、音頻、視頻）。它還有用於檢索增強生成（RAG）的開箱即用模塊，可為聊天機器人和其他生成式 AI 應用程序提供特定領域的數據，使其更加有用。</span></p><h4><a href="https://www.oschina.net/p/zig"><strong>Zig</strong></a></h4><p><span style="color:#000000">InfoWorld 稱，Zig 可能是當今所有的開源項目中最重要的一個。</span></p><p><span style="color:#000000">Zig 致力於創建一種具有程序級內存控制功能的通用編程語言，其性能優於 C 語言，同時提供更強大、更不易出錯的語法。其目標是取代 C 語言，成為編程生態系統中的基準語言。由於 C 語言無處不在（即系統和設備中最常見的組件），Zig 的成功可能意味着性能和穩定性的廣泛提升。</span></p><p><span style="color:#000000">「這是我們都應該期待的。另外，Zig 是一個優秀的、老式的草根項目，擁有着巨大的抱負和開源精神。」</span></p><hr><p><span style="color:#000000"><span style="background-color:#ffffff">以上就是 2023 年度&nbsp;InfoWorld Bossie Awards 項目，關於每個項目具體的入選評語等詳細信息，可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3709196%2Fthe-best-open-source-software-of-2023.html" target="_blank">查看網站原文</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 23 Oct 2023 08:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263384/2023-infoworld-bossie-awards</guid>
            <link>https://www.oschina.net/news/263384/2023-infoworld-bossie-awards</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[前三季度我國軟件業務收入 87610 億元，同比增長 13.5%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>2023 年前三季度軟件業經濟運行情況已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3BssaWqag8KSIDrsqTMn1A" target="_blank">發佈</a>。前三季度，我國軟件和信息技術服務業（以下簡稱「軟件業」）運行態勢平穩，軟件業務收入兩位數增長，利潤總額保持較快增長，軟件業務出口降幅收窄。</p><h4><strong>一、總體運行情況</strong></h4><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong><span>軟件業務收入兩位數增長。</span></strong><span>前三季度，我國軟件業務收入 87610 億元，同比增長 13.5%。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="245" src="https://oscimg.oschina.net/oscnet/up-712e70a3953fc0c2cfa1aa152a13d323821.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>利潤總額保持較快增長</strong>。前三季度，軟件業利潤總額 10090 億元，同比增長 18.3%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="243" src="https://oscimg.oschina.net/oscnet/up-b79b774cb8b76c5ec4ddb7c143ff73da71e.png" width="500" referrerpolicy="no-referrer"></p><p><strong>軟件業務出口降幅收窄。</strong>前三季度，軟件業務出口 364 億美元，同比下降 4.4%。</p><p><img height="242" src="https://oscimg.oschina.net/oscnet/up-3f2b6b02eec4d9fa46d8b7dea207795ab3c.png" width="500" referrerpolicy="no-referrer"></p><h4 style="margin-left:0px; margin-right:0px"><strong><span>二、分領域運行情況</span></strong></h4><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>軟件產品收入平穩增長。</strong>前三季度，軟件產品收入 20465 億元，同比增長 10.3%，佔全行業收入的比重為 23.4%。其中，工業軟件產品收入 1976 億元，同比增長 11.8%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>信息技術服務收入較快增長</strong>。前三季度，信息技術服務收入 58335 億元，同比增長 15%，佔全行業收入的比重為 66.6%。其中，雲計算、大數據服務共實現收入 8750 億元，同比增長 15.8%，佔信息技術服務收入的比重為 15%；集成電路設計收入 2236 億元，同比增長 6.8%；電子商務平台技術服務收入 7990 億元，同比增長 9.4%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>信息安全收入增速穩步增長</strong>。前三季度，信息安全產品和服務收入 1421 億元，同比增長 9.3%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>嵌入式系統軟件收入增速較快增長</strong>。前三季度，嵌入式系統軟件收入 7389 億元，同比增長 12%。<span>&nbsp;</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="244" src="https://oscimg.oschina.net/oscnet/up-dbd4d30fbf582bc5c9ff7620d57956be56e.png" width="500" referrerpolicy="no-referrer"></p><h4 style="margin-left:0px; margin-right:0px"><strong><span>三、分地區運行情況</span></strong></h4><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>中、西部地區軟件業務收入小幅回落，東部地區增勢突出</strong>。前三季度，東部地區完成軟件業務收入 72555 億元，同比增長 14.1%，增速較 1—8 月份提高 0.1 個百分點；中部地區完成軟件業務收入 4317 億元，同比增長 12.1%，增速較 1—8 月份回落 1 個百分點；西部地區完成軟件業務收入 8816 億元，同比增長 9.9%，增速較 1—8 月份回落 0.2 個百分點；東北地區完成軟件業務收入 1922 億元，同比增長 13.6%，增速較 1—8 月份提高 0.3 個百分點。四個地區軟件業務收入佔全國比重分別為 82.8%、4.9%、10.1% 和 2.2%。</p><p><img height="246" src="https://oscimg.oschina.net/oscnet/up-fd5b0b7172cab689c7ca7da5f680b18a7c4.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>京津冀地區增勢突出，長三角地區穩中有升</strong>。前三季度，京津冀地區完成軟件業務收入 21577 億元，同比增長 17.4%，增速較 1—8 月份回落 0.4 個百分點；長三角地區完成軟件業務收入 25446 億元，同比增長 10.8%，增速較 1—8 月份提高 0.5 個百分點。兩個地區軟件業務收入佔全國比重分別為 24.6%、29.0%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>主要軟件大省收入佔比持續提升</strong>。前三季度，軟件業務收入居前 5 名的省份中，北京市、廣東省、江蘇省、山東省、上海市軟件收入分別為 18962 億元、14887 億元、10182 億元、9425 億元和 8104 億元，分別增長 17.6%、14.2%、8.7%、16.6% 和 19.1%，五省（市）合計軟件業務收入 61560 億元，佔全國比重為 70.3%，佔比較去年同期提高 1.1 個百分點。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="241" src="https://oscimg.oschina.net/oscnet/up-c03d086cb65a0cc5fff1393298364228ff1.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>中心城市軟件業務收入平穩增長</strong>。前三季度，全國 15 個副省級中心城市實現軟件業務收入 42538 億元，同比增長 11%，增速較 1—8 月份提高 0.2 個百分點，佔全國比重為 48.6%，佔比較去年同期回落 1 個百分點。其中，大連、濟南、青島、深圳、廈門、瀋陽和成都軟件業務收入增速超過全行業整體增速。<span>&nbsp;</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="244" src="https://oscimg.oschina.net/oscnet/up-fd2d211fdebc504db32988a98ecc224dc98.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 23 Oct 2023 08:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263380</guid>
            <link>https://www.oschina.net/news/263380</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
