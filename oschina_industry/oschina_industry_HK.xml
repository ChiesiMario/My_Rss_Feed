<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 20 Mar 2024 10:05:07 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[✍🏻測評報告 | 2023 中文大模型全景及國內外大模型測評]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span style="background-color:#ffffff; color:#060607">《中文大模型基準測評 2023 年度報告》，由 SuperCLUE 團隊發佈，報告提供了 2023 年中文大模型發展的全面回顧，包括關鍵進展、測評體系、綜合測評結果以及優秀模型案例，為瞭解該領域的最新動態提供了寶貴的信息。</span></p><p><span style="background-color:#ffffff; color:#060607">以下為主要內容：</span></p><p style="text-align:start"><strong>1. 國內大模型關鍵進展</strong></p><ul><li><p><strong>時間線</strong>：報告按照時間線劃分了 AI 大模型發展的三個階段：準備期、成長期和爆發期。</p></li><li><p><strong>關鍵事件</strong>：從 ChatGPT 發佈引發全球 AI 浪潮，到國內大模型的迅速發展和多樣化，包括多個重要時間節點和相關模型的發佈。</p></li></ul><p style="text-align:start"><strong>2. 大模型全景圖</strong></p><p style="text-align:start"><img height="702" src="https://static.oschina.net/uploads/space/2024/0320/164821_iSdC_4700705.png" width="1481" referrerpolicy="no-referrer"></p><ul><li><p><strong>模型分類</strong>：介紹了通用大模型和行業大模型，包括閉源和開源模型。</p></li><li><p><strong>代表性模型</strong>：列舉了多個代表性的中文大模型，如字節跳動的 AndesGPT、百度的文心一言、阿里雲的通義千問等。</p></li></ul><p style="text-align:start"><strong>3. 測評體系和方法</strong></p><ul><li><p><strong>SuperCLUE 介紹</strong>：詳細説明瞭 SuperCLUE 測評基準的中立性和客觀性，以及其多層次、多維度的綜合性測評體系。</p></li><li><p><strong>測評層級和體系</strong>：介紹了 SuperCLUE 的多個測評層級，包括專業與技能、語言與知識、安全性等。</p></li><li><p><strong>測評方法</strong>：解釋瞭如何通過自動化方式進行客觀評估，包括多輪對話場景和主觀題+客觀題的結合。</p></li></ul><p style="text-align:start"><strong>4. 大模型綜合測評結果</strong></p><ul><li><p><strong>模型象限</strong>：使用 SuperCLUE 模型象限展示了不同模型在基礎能力和應用能力上的定位。</p></li><li><p><strong>國內外大模型表現</strong>：分析了國內外大模型的總體表現，特別是 GPT4-Turbo 的領先情況。</p></li><li><p><strong>國內大模型競爭格局</strong>：討論了國內大模型的競爭態勢，包括創業公司與大廠的對比。</p></li></ul><p style="text-align:start"><strong>5. SuperCLUE 2.0 升級</strong></p><ul><li><p><strong>行業及專項測評基準</strong>：介紹了 SuperCLUE 2.0 在行業和專項測評方面的升級，如汽車行業、金融行業、安全測評等。</p></li></ul><p style="text-align:start"><strong>6. 四大維度測評分析及示例介紹</strong></p><ul><li><p><strong>語言與知識</strong>：分析了模型在生成與創作、語言理解、上下文對話等方面的表現。</p></li><li><p><strong>專業與技能</strong>：討論了模型在計算、邏輯推理、代碼等方面的表現。</p></li><li><p><strong>工具使用</strong>：評估了模型在檢索 API、調用 API、規劃 API 等方面的能力。</p></li><li><p><strong>傳統安全</strong>：考察了模型在財產隱私、違法犯罪、偏見歧視等方面的安全能力。</p></li></ul><p style="text-align:start"><strong>7. 優秀模型案例介紹</strong></p><ul><li><p><strong>文心一言 4.0</strong>：百度推出的模型，表現均衡，尤其在計算、邏輯推理等方面。</p></li><li><p><strong>通義千問 2.0</strong>：阿里雲的模型，擅長代碼、上下文對話等。</p></li><li><p><strong>AndesGPT</strong>：OPPO 的模型，具有對話增強、個性專屬等特點。</p></li><li><p><strong>Baichuan2-13B-Chat</strong>：百川智能的開源模型，邏輯推理和生成與創作能力突出。</p></li><li><p><strong>智譜清言</strong>：清華&amp;智譜 AI 推出的模型，工具使用能力排名第一。</p></li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">報告通過這些詳細的分析和案例介紹，為讀者提供了對 2023 年中文大模型發展的深入理解，同時也為未來的研究方向和應用場景提供了指導。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">報告詳情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「開源中國 APP - 報告模塊」</span></span></strong><span style="color:#333333">下載</span>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下載地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前僅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 09:07:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283942</guid>
            <link>https://www.oschina.net/news/283942</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開放籤開源電子簽章產品白皮書（簡版）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>開放籤開源電子簽章產品白皮書（簡版）</h1><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>一、</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#000000"><strong>摘要：</strong></span></span></span></span></strong></strong></span></span></span></span></h1><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>開放籤電子簽章團隊源自於電子合同 SaaS 公司，立志於通過開源、開放的模式，結合團隊十多年的行業經驗，將電子簽章產品更簡單、更低門檻的推廣到各行各業中。讓電子簽章應用更簡單，讓電子簽章應用更普及。我們相信秉承開源、開放的價值觀，能夠為產品和用户之間帶來更多的信任，讓用户使用起來更放心。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>本白皮書概述了開放籤電子簽章的設計理念、關鍵技術、功能特點、應用場景以及參與貢獻的方法。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>二、背景與價值主張</strong></span></span></span></span></strong></strong></span></span></span></span></h1><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>隨着全球信息化的快速發展，企業組織和個人越來越依賴於線上操作和遠程協作。數字化辦公、電子商務和移動互聯技術的普及使得傳統紙質文件簽署方式在效率、成本以及環保等方面日益顯得滯後。在此背景下，電子簽章作為一種替代傳統物理印章的有效手段，其需求呈現出以下特點：</span></span></span></span></span><span><span><span><span style="color:#000000"><span>提升業務效率</span></span></span></span></span><span><span><span><span style="color:#000000"><span>【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>電子簽章能夠實現文檔的在線實時簽署，不受地域限制</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】；【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>合規要求</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】</span></span></span></span></span><span><span><span><span style="color:#000000"><span>各地</span></span></span></span></span><span><span><span><span style="color:#000000"><span>政府紛紛出台相應的法律法規</span></span></span></span></span><span><span><span><span style="color:#000000"><span>，</span></span></span></span></span><span><span><span><span style="color:#000000"><span>確保電子簽章具有與傳統簽名相同的法律效力</span></span></span></span></span><span><span><span><span style="color:#000000"><span>；【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>降低運營成本</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】</span></span></span></span></span><span><span><span><span style="color:#000000"><span>減少紙張消耗、快遞費用、人工處理成本</span></span></span></span></span><span><span><span><span style="color:#000000"><span>；</span></span></span></span></span><span><span><span><span style="color:#000000"><span>業務場景融合</span></span></span></span></span><span><span><span><span style="color:#000000"><span>【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>電子簽章可無縫嵌入各類業務流程，如 ERP、CRM、OA 系統中</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】</span></span></span></span></span><span><span><span><span style="color:#000000"><span>；</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>價值主張</span></span></span></span></span><span><span><span><span style="color:#000000"><span>：我們相信秉承開源、開放的價值觀，打造透明、安全、可信賴的電子簽名生態系統。能夠為產品和用户之間帶來更多的信任，讓電子簽章更簡單，讓用户使用起來更放心。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>三、系統架構與核心技術</strong></span></span></span></span></strong></strong></span></span></span></span></h1><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>1、系統總體設計</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p><img height="720" src="https://oscimg.oschina.net/oscnet/up-e52e5683b2a878110dac08c5b5d52564a78.png" width="1220" referrerpolicy="no-referrer"></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>2、</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#000000"><strong>技術開發架構</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>前端技術： Ant-design-vue + Vue + vite+ ts。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>後端技術：Springboot、mybatis-plus、shiro、drools、jwt、websocket、freemarker、hutool、pdfbox 等。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>其他技術： Druid（數據庫連接池）、Logback（日誌工具）、PowerJob（定時任務）、lombok（簡化代碼）。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>加密算法與數字簽名技術:（如 RSA、SHA-256 等）。</span></span></span></span></span></span></span></span></span></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#333333"><strong>3</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#333333"><strong>、產品説明</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>開放籤電子簽章系統為企業構建安全、可信、可控、靈活的一站式電子簽章全服務體系產品鏈，產品類型如下：</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>（1）開源工具版（開源免費版）：</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>將電子簽章的核心技術代碼和工具進行開源，開源版採用更加寬鬆的 MIT 開源協議，且不受商業限制。產品功能包括：電子印章製作，手寫簽名生成，數字證書生成，PDF 文件轉圖片，電子簽章（關鍵字簽署、指定位置簽署），文件驗籤等。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>（2）企業版（商業版本）：</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>為企業或機構在業務層面提供電子簽章完整服務能力。支持私有化部署、多租户、SaaS 化等多種服務模式，提供個人和企業用户註冊、實名，組織管理，權限管理，數字證書下發，印章管理，簽名管理，電子文件的發起、接收、簽署，簽署場景支持企業內部文件籤批流轉、B2B 電子合同簽署和 B2C 電子合同簽署等業務場景。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>三、應用場景</strong></span></span></span></span></strong></strong></span></span></span></span></h1><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>1、</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#000000"><strong>工具版系統集成</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>開放籤電子簽章系統開源工具適合有技術能力的個人/團隊學習或自建電子簽章\電子合同功能或應用，避免研發同仁在工作過程中重複造輪子，降低電子簽章技術研發要求，讓電子簽章相關的技術可以更低門檻的應用在各個業務系統中。</span></span></span></span></span></span></span></span></span></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>2、企業版業務應用場景</strong></span></span></span></span></strong></strong></span></span></span></span></h2><h3><span><span><span><span style="color:#000000"><strong><span><span><span><span style="color:#000000"><span>（1）企業內部文件審批流轉</span></span></span></span></span></strong></span></span></span></span></h3><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>企業通過集成電子簽章功能的辦公自動化系統（如 OA 系統、ERP 系統等），實現各類內部文件的電子化創建、分發和簽署。</span></span></span></span></span></span></span></span></span></p><h3><span><span><span><span style="color:#000000"><strong><span><span><span><span style="color:#000000"><span>（2）跨組織商務合同簽署</span></span></span></span></span></strong></span></span></span></span></h3><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>跨地域合作時，通過電子簽章技術，無需面對面或郵寄紙質文件，各方當事人可以在任何地點通過網絡完成合同的簽署，解決異地簽署難題，提升業務效率。</span></span></span></span></span></span></span></span></span></p><h3><span><span><span><span style="color:#000000"><strong><span><span><span><span style="color:#000000"><span>（3）公共服務領域在線辦理</span></span></span></span></span></strong></span></span></span></span></h3><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>在線提交行政審批申請時，申請人、審批單位及相關業務部門可以使用電子簽章確認文件的真實性和有效性，如工商註冊、税務申報、資質許可等業務中，無需線下蓋章即可完成流程。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>四、社區共建與開源策略</strong></span></span></span></span></strong></strong></span></span></span></span></h1><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>1、開源許可證選擇與版權説明</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>開放籤開源工具版遵循 MIT 開源協議，適用於有技術能力的個人或團隊學習或自建電子簽章系統，且不受商業限制。如商業使用產生的任何問題及糾紛與我司無任何關係。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>企業版是收費版本，在尚未購買產品技術服務或商業授權之前，我們不承諾對免費用户提供任何形式的技術支持、使用擔保，也不承擔任何因使用本軟件而產生問題的相關責任。</span></span></span></span></span></span></span></span></span></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>2、開發者指南與代碼貢獻路徑</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（1）開放籤電子簽章官方網站：</span></span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kaifangqian.com" target="_blank"><span><span><span><span style="color:#0000ff"><span>https://www.kaifangqian.com</span></span></span></span></span></a></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（2）開源工具版體驗地址：</span></span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdemo.kaifangqian.com" target="_blank"><span><span><span><span style="color:#0000ff"><span>https://demo.kaifangqian.com</span></span></span></span></span></a></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（3）開源工具版 gitee 源碼：</span></span></span></span></span><a href="https://gitee.com/kaifangqian/kaifangqian-base"><span><span><span><span style="color:#0000ff"><span>https://gitee.com/kaifangqian/kaifangqian-base</span></span></span></span></span></a></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（4）開源工具版 github 源碼：</span></span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkaifangqian%2Fkaifangqian-base" target="_blank"><span><span><span><span style="color:#0000ff"><span>https://github.com/kaifangqian/kaifangqian-bas</span></span></span></span></span></a></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:53:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283940</guid>
            <link>https://www.oschina.net/news/283940</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[.NET 9 PreView2 + .AOT ILC 的重大變化]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h2_1"></span><h2><strong>前言</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">.NET9 PreView2 發佈了，它的 CLR 方面主要有兩個重磅功能</p><ul><li>RyuJIT 增強功能</li><li>Arm64 矢量化</li></ul><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">原文：</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486290%2526idx%253D1%2526sn%253D726ec65a0956e4de5840f27d8e6b2004%2526chksm%253Dc01c46c9f76bcfdf6170e771d067f8d669ac02775332bc466c0f9a1276982e315c1e7ef430c9%2526token%253D1776199625%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">.NET9 PreView2 的重磅功能</a></u></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486298%2526idx%253D1%2526sn%253D5aab48e01251c3bb6dbf100050fcc707%2526chksm%253Dc01c46c1f76bcfd7d9cb8a264c71bdeb327cd52a35f030f10dc4379b14d460eceb574b49e14e%2526token%253D1776199625%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">.NET9 AOT ILC 的重大變化</a></u></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><u><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486254%2526idx%253D1%2526sn%253Da0050659da6ee8b0696f1c758d8046d5%2526chksm%253Dc01c46b5f76bcfa3524abeb373258f10b2909ca8ac490c1eb8ed5c4a2c30c98a6712f6a8a099%2526token%253D1776199625%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">歡迎加入.NET9 技術交流羣</a></strong></u></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">下面分別看下</p><span id="OSC_h2_2"></span><h2><strong>RyuJIT 增強功能</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>1.環路優化 (循環優化)</strong></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">這種優化實際上是一種 for 循環疊加態的優化，for 循環疊加計算的過程中，會對其中部分變量進行感應。比如循環中放置 0 擴展 (第一個索引為 0)，這種優化靈感來源於 LLVM 標量演化。下面看例子，説明下這個優化：</p><div><pre><code class="language-text">[MethodImpl(MethodImplOptions.NoInlining)]
static int Foo(int[] arr)
{
    int sum = 0;
    for (int i = 0; i &lt; arr.Length; i++)
    {
        sum += arr[i];
    }

    return sum;
}</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">未優化前:</p><div><pre><code class="language-text">G_M8112_IG01:
       sub      rsp, 40
            ;; size=4 bbWeight=1 PerfScore 0.25
G_M8112_IG02:
       xor      eax, eax
       xor      edx, edx
       mov      r8d, dword ptr [rcx+0x08]
       test     r8d, r8d
       jle      SHORT G_M8112_IG04
       align    [0 bytes for IG03]
            ;; size=13 bbWeight=1 PerfScore 3.75
G_M8112_IG03:
       mov      r10d, edx
       add      eax, dword ptr [rcx+4*r10+0x10]
       inc      edx
       cmp      r8d, edx
       jg       SHORT G_M8112_IG03
            ;; size=15 bbWeight=4 PerfScore 19.00
G_M8112_IG04:
       add      rsp, 40
       ret      
            ;; size=5 bbWeight=1 PerfScore 1.25

; Total bytes of code 37, prolog size 4, PerfScore 24.25,
 instruction count 14, allocated bytes for code 37 
 (MethodHash=d1cce04f) for method ConsoleApp34.Program:Foo(int[])
 :int (FullOpts)
; ============================================================</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">未優化前 37 字節，優化後：</p><div><pre><code class="language-text">G_M8112_IG01:  ;; offset=0x0000
       sub      rsp, 40
            ;; size=4 bbWeight=1 PerfScore 0.25
G_M8112_IG02:  ;; offset=0x0004
       xor      eax, eax
       mov      edx, dword ptr [rcx+0x08]
       test     edx, edx
       jle      SHORT G_M8112_IG04
       xor      r8d, r8d
       align    [0 bytes for IG03]
            ;; size=12 bbWeight=1 PerfScore 3.75
G_M8112_IG03:  ;; offset=0x0010
       add      eax, dword ptr [rcx+4*r8+0x10]
       inc      r8d
       cmp      edx, r8d
       jg       SHORT G_M8112_IG03
            ;; size=13 bbWeight=4 PerfScore 18.00
G_M8112_IG04:  ;; offset=0x001D
       add      rsp, 40
       ret      
            ;; size=5 bbWeight=1 PerfScore 1.25

; Total bytes of code 34, prolog size 4, PerfScore 23.25, 
instruction count 13, allocated bytes for code 34
 (MethodHash=d1cce04f) for method ConsoleApp34.Program:Foo(int[])
 :int (FullOpts)</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">優化後 34 字節，減少了 3 字節，優化的指令如下，剛好三字節。這裏的優化點是減卻寄存器置零或者賦值 (稱之為放置 0 擴展)，進行共用。</p><div><pre><code class="language-text">mov   41 89 d2  r10d, edx</code></pre></div><span id="OSC_h2_3"></span><h2><strong>2.NativeAOT 改進：內聯+TLS</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">這種優化，需要了解一些知識點。假如一個類成員被多個線程訪問，一般的訪問的時候會設置鎖，以避免數據幹擾。但是，這同時也產生性能問題。為了提高性能，可以把這個類成員放到線程本地存儲 (TLS) 當中，訪問的時候直接去線程本地存儲獲取，這樣極大提高了性能。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">但是這還不夠，我們需要把訪問類成員的代碼進行內聯。進一步提高性能，不然怎麼能叫極致性能優化呢？</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">代碼：</p><div><pre><code class="language-text">:  90000000   adrp  x0, 0 &lt;System_Console_System_ConsoleKeyInfo____GetFieldHelper&gt;
      5a2f0: R_AARCH64_TLSDESC_ADR_PAGE21  tls_InlinedThreadStatics
   5a2f4:  91000000   add  x0, x0, #0x0
      5a2f4: R_AARCH64_TLSDESC_ADD_LO12  tls_InlinedThreadStatics
   5a2f8:  d53bd041   mrs  x1, tpidr_el0
   5a2fc:  f9400002   ldr  x2, [x0]
      5a2fc: R_AARCH64_TLSDESC_LD64_LO12  tls_InlinedThreadStatics
   5a300:  d63f0040   blr  x2
      5a300: R_AARCH64_TLSDESC_CALL  tls_InlinedThreadStatics
   5a304:  8b000020   add  x0, x1, x0
   5a308:  f9400013   ldr  x19, [x0]</code></pre></div><span id="OSC_h2_4"></span><h2><strong>2.PGO 的改進:類型檢查</strong></h2><span id="OSC_h2_5"></span><h2>PGO 是.NET8 的一大亮點，啓用了動態配置文件引導優化 (PGO)。.NET9 Pre2 擴展了 PGO，以便分析更多的代碼模式。啓用分層編譯後，RyuJIT 已經將檢測插入到程序中以分析其行為;在使用優化重新編譯時，RyuJIT 利用它在運行時構建的配置文件來做出特定於程序當前運行的決策。在預覽版 2 中，RyuJIT 現在默認使用 PGO 數據來提高類型檢查的性能。</h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">一般來説，確定對象的類型需要調用運行時。這會帶來一些性能上的損失，也就是説當進行類型檢查的時候，運行時為了確保類型正確性，必須進行檢查。通過.NET8 裏面啓用的 PGO，如果在 PGO 裏面能夠確定對象是某個類型，JIT 就會用一個快速路徑編碼，以比較快速的方式進行類型檢查。並且在必要的時候退回到慢速路徑 (常規檢查)</p><div><pre><code class="language-text">bool IsList&lt;T&gt;(IEnumerable&lt;T&gt; source) =&gt; source is IList&lt;T&gt;;</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">如果 PGO 檢測到 source 總是數組，則會快速路徑返回 true，否則慢速路徑進行檢測</p><div><pre><code class="language-text">if (source is int[])
{
    return true;
}
else
{
    return slow_path(); // Let the runtime figure it out
}</code></pre></div><span id="OSC_h2_6"></span><h2><strong>ARM64 矢量化</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">.NET9 Pre2 支持了一種新的實現，利用 JIT 在 Arm64 上操作寄存器的加載和存儲的能力。簡單點來説，就是用 SEE，YMM 等一次性操控 32 字節或者 64 字節的寄存器處理更大量的數據，提升性能。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><span id="OSC_h2_7"></span><h2><strong>.NET9 AOT ILC</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">AOT 編譯分成兩個階段，其一是生成 Obj 目標文件，其二則是通過鏈接器鏈接目標文件生成可執行二進制文件。這裏的目標文件和可執行二進制文件都是分別對於相應的平台，比如 MacOS/Linux/Win 等等平台。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">第一步生成 Obj 目標文件，因為多平台生成。所以.NET9 之前，微軟採用了 LLVM 後端生成了目標文件。因為 LLVM 後端近乎絕對的統治力，它有一百多個指令集級別的後端生成，所以採用 LLVM 更符合開源特徵。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">但這一情況到了.NET9 發生了變化，.NET9 裏面微軟首次引入了 C#代碼生成目標文件，取代了 LLVM 默認的生成。但是 LLVM 並沒有刪除，而是同時存在。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">這部分代碼可以參考：</p><div><pre><code class="language-text">public static void EmitObject(string objectFilePath, IReadOnlyCollection&lt;DependencyNode&gt; nodes, NodeFactory factory, ObjectWritingOptions options, IObjectDumper dumper, Logger logger)
 {
     var stopwatch = new Stopwatch();
     stopwatch.Start();

     if (Environment.GetEnvironmentVariable("DOTNET_USE_LLVM_OBJWRITER") == "1")
     {
         LegacyObjectWriter.EmitObject(objectFilePath, nodes, factory, options, dumper, logger);
     }
     else
     {
         ObjectWriter objectWriter =
             factory.Target.IsApplePlatform ? new MachObjectWriter(factory, options) :
             factory.Target.OperatingSystem == TargetOS.Windows ? new CoffObjectWriter(factory, options) :
             new ElfObjectWriter(factory, options);
         objectWriter.EmitObject(objectFilePath, nodes, dumper, logger);
     }

     stopwatch.Stop();
     if (logger.IsVerbose)
         logger.LogMessage($"Done writing object file in {stopwatch.Elapsed}");
 }</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">如果你不作任何設置，.NET9 默認的目標文件生成即是 C#自舉的代碼。但是你如果習慣了 LLVM 的生成，也可以通過設置環境變量來開啓之前的 LLVM 後端。具體如下：</p><div><pre><code class="language-text">CMD:          set    DOTNET_USE_LLVM_OBJWRITER=1
Powershell:   $env:  DOTNET_USE_LLVM_OBJWRITER=1
Unix/Linux:   export DOTNET_USE_LLVM_OBJWRITER=1

dotnet xxx.dll</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">先設置環境變量，然後通過 dotnet 命令行運行託管 DLL 即可復現之前的 LLVM 後端生成。以上是各個平台的設置。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><span id="OSC_h2_8"></span><h2><strong>作者：jianghupt(公眾號同名，歡迎關注)</strong></h2></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:46:52 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5407571/blog/11048017</guid>
            <link>https://my.oschina.net/u/5407571/blog/11048017</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟開源遠程緩存存儲系統 Garnet：基於 .NET 技術棧、支持接入 Redis 客户端]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微軟研究院<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fgarnet" target="_blank">開源</a></u>了名為&nbsp;Garnet 的遠程緩存存儲系統，據稱擁有強大的性能（高吞吐量和低延遲）、可擴展性、存儲、恢復、集羣分片、密鑰遷移和複製功能，並支持接入現有的 Redis 客户端。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f2cd6285bd80798dd9b494864d5d4642356.png" referrerpolicy="no-referrer"></p><p><strong>Garnet 核心優勢</strong></p><ul><li><p>Garnet 採用流行的 RESP 線路協議，因此大多數用户可以不作任何修改、就直接通過大多數編程語言編寫的 Redis 客户端直接接入 Garnet。</p></li><li><p>Garnet 通過多條客户端連接與小批量形式提供更好的可擴展性與吞吐量，幫助大型應用程序和服務節約運行成本。</p></li><li><p>Garnet 在第 99 及第 99.9 百分位上表現出更好的客户端延遲水平，更高比例的穩定性表現對於現實場景而言至關重要。</p></li><li><p>Garnet 基於最新.NET 技術，具有跨平台、可擴展和現代化等特點。它在設計上易於開發與調整，且不致犧牲常見場景下的性能水平。通過利用.NET 豐富的庫生態來擴展其 API，並提供開放的優化機會。憑藉對.NET 的充分發掘，Garnet 在 Linux 和 Windows 平台上均表現出頂尖性能。</p></li></ul><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e0455c41a00404e05790ec05decb67ca6ff.png" referrerpolicy="no-referrer"></p></blockquote><p>可以看到，Garnet 的核心優勢在於優異的可擴展性和吞吐量，以及對客户端會話數增加情況下的低延遲表現。經過基準測試，Garnet 與其他幾種領先的開源緩存存儲方案對比，顯示出了它在處理大量客户端連接和大數據量時更加高效穩定。</p><p>此外，Garnet 支持多種 API 功能，如原始字符串的讀寫、複雜數據類型的處理等，滿足了不同場景下的應用需求。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dc5ebce821d503d82b69ab11afe89fcb1c1.png" referrerpolicy="no-referrer"></p><p>△ Garnet 整體架構</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmicrosoft.github.io%2Fgarnet%2Fblog%2Fbrief-history" target="_blank">據介紹</a></u>，Garnet 是微軟研究院多年工作的成果。它從 2018 年完成的名為 FASTER 的初步工作發展而來的，FASTER 是一個嵌入式鍵值數據庫，旨在證明可以獲得比現有系統更好的性能。</p><p>在 2021 年大流行期間，微軟研究院決定根據微軟在現實世界中的需求，在這項技術的基礎上進行改進，最終形成了 Garnet。微軟表示，它已經在多個地方部署了 Garnet，包括 Windows 與 Web 體驗平台、Azure 資源管理器和 Azure 資源圖。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:38:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283934/ms-research-garnet-cache-store</guid>
            <link>https://www.oschina.net/news/283934/ms-research-garnet-cache-store</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[360 發佈安全大模型 3.0，安全領域效果超 GPT4]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 20 日，360 集團正式推出 360 安全大模型 3.0，並通過智能體框架，賦能企業已有的探針、平台，提煉專家知識賦能增強 360 安全雲，幫助企業數字安全體系提質增效。</p><p>360 集團首席科學家兼 360 數字安全集團 CTO 潘劍鋒提到，「我們參考了人類大腦的運行邏輯，構建 360 安全大模型 3.0 框架。實際應用中，在多個專業任務效果上超過 GPT4。」</p><p><img alt="" height="334" src="https://oscimg.oschina.net/oscnet/up-59ec68e7705b3845b8f343feb0b33fce212.webp" width="500" referrerpolicy="no-referrer"></p><p>據潘劍鋒介紹，360 從數據、場景、大模型和智能體四個方面研究方法論，總結了新一代安全大模型的核心戰法：數據制勝、小切口大縱深、類腦分區協同（CoE）和工具增強（TAG）。</p><p>展開來説，其一數據制勝，為訓練出高水平的安全大模型，需要有高質量的安全專業數據和事件數據作為語料，並配合專業的技術手段進行訓練；其二小切口大縱深，是指在場景上，立足小切口、大縱深方法論，以安全難點小場景做切入，做深做透，進而深度融合大模型與安全的能力；其三類腦協同分區，即在大模型設計上，採用類腦分區協同（CoE）設計，以多個類腦分區協同工作，解決高難度安全問題；其四工具增強（TAG），是指以安全智能體為基礎，通過調度各種安全產品與工具，為大模型提供糾錯反饋機制，持續增強大模型安全能力。</p><p>潘劍鋒指出，基於新戰法打造的 360 安全大模型 3.0，不僅僅實現安全基礎知識問答、初級腳本分析等基礎能力，而是真正錨定安全行業痛點、革新安全能力體系、引領未來安全實戰。</p><p>360 安全大模型 3.0 框架，在構建時充分參考人類大腦的運行邏輯，基於數據、知識、算力優勢，訓練語言、規劃、判別、道德、記憶五大功能中樞。其中，語言中樞實現語言翻譯、文本摘要、意圖識別能力；規劃中樞實現程序生成、方案規劃、目標拆解能力；判別中樞實現信息抽取、邏輯推理、是非判斷、研判檢測能力；道德中樞實現情感分析、道德法律能力；記憶中樞實現信息記憶能力。</p><p>基於類腦分區協同設計的安全大模型框架，不僅可以解決任務衝突問題，達到多任務最優性能，而且實現了能力突破，在多個專業任務效果上超過了 GPT4。此外，360 以安全大模型為「大腦」，構建智能體框架，通過任務編排、指令調度、記憶存儲等能力，調用安全知識、工具，模仿人類「慢思考」的過程，對安全大模型的結果進行糾錯和能力增強，實現更強大的安全專家能力。</p><p>潘劍鋒以海蓮花 APT 攻擊為例，展示了 360 安全大模型如何在實戰中智能化獵殺 APT。他表示，360 安全大模型的最終目標是幫助企業數字安全體系提質增效，是 360 安全雲體系中的重要一環。</p><p>隨後，360 數字安全集團副總裁張錦章介紹了 360 圍繞安全和 AI 兩條戰略主線的實踐。他表示，360 安全大模型已賦能 360 全線產品矩陣。而 360 安全雲在安全大模型加持下，形成公有云和私有化兩大場景。在公有云場景下，打造安全雲服務，充分利用 AI 提升運營效率；在私有化場景下，深度優化安全大腦+安全大模型+探針的能力落地。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:35:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283932</guid>
            <link>https://www.oschina.net/news/283932</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024 年 AIGC 發展趨勢報告：AIGC 驅動下的生產力變革、實踐與展望]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">愛設計 &amp; AiPPT &amp; AIGC 內容中台近期聯合發佈了《2024 年 AIGC 發展趨勢報告：AIGC 驅動下的生產力變革、實踐與展望》報告，主要探討了 AIGC 技術如何推動生產力變革、在不同行業的應用實踐以及對未來的展望。</p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><img alt="" height="391" src="https://static.oschina.net/uploads/space/2024/0320/162019_7pYi_4700705.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">以下是報告的核心內容概述：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>AIGC 的生產力變革</strong>：</p><ul><li>AI 工具的發展極大提升了工作效率，對人類生產和服務產業鏈、價值鏈進行了賦能和重構。</li><li>2023 年見證了文本和圖像生成的進步，而視頻生成領域則相對較慢。OpenAI 發佈的 Sora 模型預示着視覺敍事新時代的到來，能夠將想象力轉化為動態畫面。</li><li>AIGC 的友好性、大模型開源、API 價格降低等因素使得 AI 技術可能成為像水、電、網絡一樣的基礎設施。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AIGC 的應用實踐</strong>：</p><ul><li>AIGC 技術在文字、代碼、音樂、圖片、視頻等多種媒介形態的生產中逐步深度融入。</li><li>AI 繪圖技術可以快速生成創意設計，如廣告、海報、產品包裝等，提高營銷效率和效果。</li><li>AI 視頻技術可以高效完成視頻錄製與剪輯，創造獨特的虛擬人物和場景，提高視頻的創意和吸引力。</li><li>AI 寫作工具可以快速生成文案，支持多種場景需求，如社交媒體文案、新聞稿、產品評測等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AIGC 的未來展望</strong>：</p><ul><li>AIGC 應用層創新將成為產業發展的核心方向，預計到 2024 年將深度融入企業業務並催生新場景。</li><li>AIGC 正在工具化，從「趕時髦」變為「真有用」，企業更看重其帶來的實際效益。</li><li>中大型企業將率先湧現專屬、自建模型的需求，以獲得更理想的綜合效益。</li><li>AIGC 生態將逐步普惠化，推動新的商業模式和數字經濟產業的繁榮。</li><li>智能湧現是雙刃劍，需要與之匹配的安全措施，如隱私保護、數據泄露防範等。</li></ul></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">報告還提到了 AIGC 技術可能帶來的社會影響，包括工作替代、財富分配、倫理道德等問題，並強調了技術發展與社會整體福利水平提升之間的關係。最後，報告呼籲積極主動地擁抱 AIGC 技術，以打造更美好的未來。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">報告詳情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「開源中國 APP - 報告模塊」</span></span></strong><span style="color:#333333">下載</span>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下載地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前僅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:22:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283927</guid>
            <link>https://www.oschina.net/news/283927</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[深圳成立鴻蒙生態創新中心]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 19 日，鴻蒙生態創新中心揭幕儀式在深圳灣科技生態園舉行。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0672f9510f1b29f65734bca978a3aae242e.jpg" referrerpolicy="no-referrer"></p><p><img alt="WPS 圖片 (1).jpeg" src="https://upload.ikanchai.com/2024/0320/1710898823311.jpeg" referrerpolicy="no-referrer"></p><p>現場，深圳市南山區人民政府副區長李志娜發佈《2024 年南山區支持鴻蒙原生應用發展首批政策措施清單》，從加強鴻蒙原生應用供給能力、推動鴻蒙原生應用產業集聚、完善鴻蒙原生應用生態體系等三大方面，<strong>出台八條具體措施，全方位支持鴻蒙原生應用發展</strong>。</p><p>分別為：</p><ul><li><p>支持開發鴻蒙原生應用軟件；</p></li><li><p>推動區政務服務軟件上線鴻蒙原生應用軟件，推動國有企事業單位在教育、醫療、文旅、體育等各類垂直領域開放應用場景；</p></li><li><p>定期組織各行各業與鴻蒙生態進行對接，召開供需對接會；</p></li><li><p>爭取培育 30 萬以上開發者，吸引鴻蒙原生應用開發運營企業落户南山；</p></li><li><p>在高新區片區打造鴻蒙原生應用特色產業園，對符合條件的鴻蒙原生應用入駐企業，給予最高 40% 的租金補貼；</p></li><li><p>成立鴻蒙產業專項基金，重點投資鴻蒙原生應用相關領域；</p></li><li><p>加強鴻蒙原生應用開發人才保障，對掛牌人才實訓基地的鴻蒙原生應用企業給予補貼，建設「2048 人才社區」；</p></li><li><p>支持鴻蒙生態創新中心穩健運營等。</p></li></ul><p><span>據介紹，鴻蒙生態創新中心的建立是為構建先進完整、自主研發的鴻蒙生態體系，將深圳打造為鴻蒙生態策源地、集聚區的具體舉措，也是推動我國關鍵核心技術高水平自立自強、數字經濟高質量發展、保障國家安全、提升國際競爭力的重要舉措。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 07:47:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283921</guid>
            <link>https://www.oschina.net/news/283921</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國產數據庫 OceanBase 實現代碼、社區、生態 100% 「根自研」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 20 日消息，OceanBase 城市行首站落地深圳。會上，OceanBase CEO 楊冰表示，目前 OceanBase 已經做到了 100%「根自研」，包括從 0 到 1 自研三百萬行代碼、自研代碼開源主導產品和社區發展方向、構建自研技術生態。</p><p><img src="https://oscimg.oschina.net/oscnet/up-72edb6534ef024342601bc9acda33591568.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.doit.com.cn%2Fp%2F509890.html" target="_blank">據介紹</a></u>，OceanBase 將「根自研」解釋為<strong>代碼、社區、生態</strong>三個層面的自研。</p><ul><li>在代碼層面，由於不基於開源數據庫二次開發、自建研發環境和流程，使得 OceanBase 具備對內核代碼的完全掌控力和掌控權，避免了開源數據庫可能遭遇的協議風險。</li><li>在社區層面，2021 年開源後，OceanBase 同樣引領產品發展和社區方向，除了開源最核心的數據庫內核代碼、分佈式組件和接口驅動外，還逐步將產品工具開源。截止目前，社區擁有超 300 位貢獻者，超 500 家客户將 OceanBase 社區版應用於實際的業務生產系統。</li><li>技術生態方面，OceanBase 持續構建以「合作伙伴」為中心的產品技術文化，廣泛與多基礎設施、數據集成、數據治理、應用集成服務商圍繞 OceanBase 進行產品適配和對接，有超過 750 個主流產品已加入 OceanBase 自研技術生態。</li></ul><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-45acbfc8fd014a1cc51b03843d779e8750b.png" referrerpolicy="no-referrer"></p></blockquote><p>OceanBase 始創於 2010 年，是螞蟻集團完全自主研發的國產數據庫。2020 年 OceanBase 成立北京奧星貝斯科技有限公司並開始獨立商業化運作。2021 年，OceanBase <u><a href="https://www.oschina.net/news/144034">正式開源</a></u>(<a href="https://gitee.com/oceanbase" target="_blank">https://gitee.com/oceanbase</a>)，300 萬行核心代碼向社區開放。2024 年 3 月 19 日，螞蟻集團宣佈，旗下的螞蟻國際、OceanBase 和螞蟻數科已成立董事會，獨立面向市場。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 07:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283917</guid>
            <link>https://www.oschina.net/news/283917</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 24.04 LTS 官方壁紙揭曉]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在成立 20 週年紀念日前夕，Canonical <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Fthe-coronation-of-a-new-mascot-noble-numbat" target="_blank">宣佈</a>推出了 Ubuntu 24.04 LTS (代號 Noble Numbat) 的默認壁紙。Ubuntu 24.04 LTS 計劃於 4 月 25 日正式發佈，Beta 版將於 4 月 4 日發佈，新壁紙也將在 Beta 版中同步提供。</span></p><p><span style="color:#000000">Ubuntu 24.04 將是 Ubuntu 自 2006 年以來的第 10 個 LTS 版本。Ubuntu 的 LTS 版本將獲得 5 年的安全更新、錯誤修復和精選應用程序更新。Ubuntu Pro 則會在此基礎上額外增加 5 年的安全保障，為現代的 LTS 版本提供了長達十年的支持。</span></p><p><span style="color:#000000">Numbat（袋食蟻獸）是分佈於澳大利亞西南部的一種小型有袋動物，幾乎只以白蟻為食，每天可以吃約 20000 只白蟻。</span></p><blockquote><p><span style="color:#000000">「在大家討論高貴一詞時，可能不會首先聯想到這種動物。然而，外表是會騙人的。這些令人難以置信的瀕危物種實際上是袖珍食蟻獸，它們純粹以螞蟻為生，用三分之一長的舌頭捕捉螞蟻。它們背部的黑白條紋很像國王的長袍，因此被選為西澳大利亞州的州徽動物。袋食蟻獸證明瞭出身卑微的人也能在世界上留下自己的印記。」</span></p></blockquote><p><span style="color:#000000"><img alt="" height="229" src="https://oscimg.oschina.net/oscnet/up-9f6dfdb88767a65e4cdb5024d1854309f77.webp" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-cae0f36c1be4386da9f49bbc47d2e563e08.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-e55523fe69ae7e2b8481a53a44a0d51b9b0.webp" width="500" referrerpolicy="no-referrer"></span></p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-baee4b4f945463e758c7001ab8dc9db413b.webp" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-dc007e2e9c359e502ccf5f6056acf519da2.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">官方提供了各種格式和尺寸的壁紙下載：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdrive.google.com%2Fdrive%2Ffolders%2F1hzlUuCOCORWyTvIWqDN_d9W4gFDqetvZ" target="_blank">https://drive.google.com/drive/folders/1hzlUuCOCORWyTvIWqDN_d9W4gFDqetvZ</a></p><p>更多詳情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Fthe-coronation-of-a-new-mascot-noble-numbat" target="_blank">公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 06:23:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283905/ubuntu-24-04-wallpaper</guid>
            <link>https://www.oschina.net/news/283905/ubuntu-24-04-wallpaper</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Spring 也愛用！Antora 3.1 中文指南發佈：輕鬆打造現代化技術網站]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3><strong>簡介</strong></h3><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Antora 3.1 中文指南全新上線，助力您輕鬆打造現代化網站！指南涵蓋所有核心功能和特性，並結閤中文示例和最佳實踐，幫助您快速上手 Antora 開發。<strong>Spring 等知名開源組織也選擇使用 Antora！</strong></span></p><h3><strong>Antora 魅力所在</strong></h3><ul><li><strong>Spring 等開源組織力薦</strong></li><li><strong>構建技術網站的利器</strong></li><li><strong>基於更易上手的 AsciiDoc</strong></li></ul><h3><strong>Antora 助您</strong></h3><ul><li>自動化構建網站</li><li>模塊化開發，輕鬆重用內容</li><li>高度可擴展，滿足各種需求</li><li>支持多語言內容創作</li></ul><h3><strong>獲取指南</strong></h3><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Antora 3.1 中文指南現已上線，您可以通過以下方式獲取：</span></p><ul><li><strong>在線閲讀：</strong><span>&nbsp;</span>在 Antora 中文文檔: [<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在碼</a>] 網站上閲讀在線版本。</li></ul><h3><strong>結語</strong></h3><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Antora 3.1 中文指南的發佈，將進一步降低中國開發者學習 Antora 的門檻，助力更多開發者加入 Antora 生態，共同打造更加繁榮的現代化網站開發環境。</span></p><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>選擇 Antora，基於更易上手的 AsciiDoc，構建高效、可維護、多語言的技術網站，盡享開源組織的信賴和支持！</strong></span></p><p><img height="400" src="https://cunzaima.cn/logo.jpg" width="400" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 06:01:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283894</guid>
            <link>https://www.oschina.net/news/283894</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[KCL 3 月社區活動和最新動態速遞！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkcl-lang" target="_blank">KCL</a> 是一個 CNCF 基金會託管的基於約束的記錄及函數語言，期望通過成熟的編程語言技術和實踐來改進對大量繁雜配置比如雲原生 Kubernetes 配置場景的編寫，致力於構建圍繞配置的更好的模塊化、擴展性和穩定性，更簡單的邏輯編寫，以及更簡單的自動化和生態工具集成。</p><p>本欄目將會雙週更新 KCL 語言社區最新動態，包括功能、官網更新和最新的社區動態等，幫助大家更好地瞭解 KCL 社區！</p><p><strong><em>KCL 官網：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkcl-lang.io" target="_blank">https://kcl-lang.io</a></em></strong></p><h2><span>內容概述</span></h2><p>感謝所有貢獻者過去一段時間 (2024 03.06 - 2024.03.20) 的傑出工作，以下是重點內容概述</p><p><strong>📦 模型更新</strong></p><ul><li><p>新增 kubeadm 配置模型</p></li><li><p>更新 Knative Operator 模型，對齊上游 Knative CRD 定義</p></li></ul><p><strong>🏄 語言更新</strong></p><p><strong>KCL 發佈 0.8.1 和 0.8.2 版本</strong>，主要包含如下更新</p><ul><li><p>體驗簡化增強二元表達式類型不匹配時的錯誤信息提示</p></li><li><p>修復高階 lambda 函數對局部作用域閉包變量捕獲不正常的錯誤</p></li><li><p>去除不常用的列表數據類型的不等式比較操作</p></li></ul><p><strong>🔧 工具鏈更新</strong></p><ul><li><p><code>kcl import</code> 工具修復當輸入的 Kubernetes CRD 存在 regex 屬性與 KCL regex 系統庫衝突的錯誤</p></li><li><p><code>kcl import</code> 工具修復當輸入的 Kubernetes CRD 屬性存在複雜的默認值時輸出的 KCL 文件語法錯誤</p></li><li><p><code>kcl mod init</code> 支持 <code>--version</code> 標籤設置 KCL 新建模塊的版本</p></li><li><p><code>kcl run</code>, <code>kcl mod add</code> 和 <code>kcl mod pull</code> 等命令支持對私有 Git 倉庫的訪問</p></li><li><p>修復在 Windows 上執行對本地 OCI Registry 執行 <code>kcl run</code> 命令時遇到的路徑錯誤</p></li></ul><p><strong>🔥 SDK 更新</strong></p><ul><li><p>KCL Rust, Go 和 Java SDK 發佈 0.8 主要版本，同步 KCL 語法語義更新</p></li><li><p>KCL Python SDK 發佈 0.8.0.2 和 0.7.6 版本，修復 <code>protobuf</code>, <code>pyyaml</code> 等依賴版本過於低的問題</p></li></ul><p><strong>💻 IDE 更新</strong></p><ul><li><p>支持多個 Quick Fix 修復選項</p></li></ul><p><img alt="" src="https://files.mdnice.com/user/44450/4d37d5b6-e481-4345-a9c5-b3531dc1f1e1.png" referrerpolicy="no-referrer"></p><p><strong>🎁 API 更新</strong></p><ul><li><p>新增 <code>ListOptions</code> API，可以讀取 KCL 工程中所有 <code>option</code> 函數調用信息。</p></li></ul><p><strong>🚢 集成更新</strong></p><ul><li><p>Crossplane KCL Function 發佈 v0.3.2 版本，支持非 https 協議 OCI Registry 訪問和本地調試</p></li></ul><p><strong>🌐 網站更新</strong></p><ul><li><p>啓用 <code>kcl-lang.dev</code> 域名，現在可以同時通過 <code>kcl-lang.io</code> 和 <code>kcl-lang.dev</code> 訪問 KCL 網站</p></li><li><p>KCL 網站加載速度優化，提升文檔體驗</p></li></ul><h2><span>特別鳴謝</span></h2><p>感謝過去兩週所有的社區參與者，以下排名不分先後</p><ul><li><p>感謝 @bozaro 對 KCL Go SDK 帶 Go 語言插件的 API 的貢獻 🙌</p></li><li><p>感謝 @shashank-iitbhu 對 KCL IDE 快速修復功能的增強，支持多個修復選項 🙌</p></li><li><p>感謝 @octonawish-akcodes 對 KCL IDE 自動監聽 kcl.mod 依賴變更並自動更新依賴功能的持續貢獻 🙌</p></li><li><p>感謝 @liangyuanpeng 對 CLA Bot CI 自動鎖定 PR 的修正，kubeadm 模型的貢獻以及 kcl mod init 支持版本設置功能的支持 🙌</p></li><li><p>感謝 @Stefano Borrelli, @sfshumaker, @eshepelyuk, @vtomilov, @ricochet1k, @yjsnly, @markphillips100, @userxiaosi, @wilsonwang371, @steeling, @bozaro, @nizq, @reckless-huang, @folliehiyuki, @samuel-deal-tisseo, @MrGuoRanDuo, 和 @MattHodge 等在近段時間使用 KCL 過程中提供的寶貴建議與反饋 🙌</p></li></ul><p>https://meeting.tencent.com/dm/CCEDaHbwXD6w</p><h2><span>其他資源</span></h2><p>❤️ 查看 KCL 社區，加入我們: https://github.com/kcl-lang/community</p><p>更多其他資源請參考：</p><ul><li><p>KCL 網站: https://kcl-lang.io/</p></li><li><p>KusionStack 網站: https://kusionstack.io/</p></li><li><p>KCL v0.9.0 Milestone: https://github.com/kcl-lang/kcl/milestone/9</p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 05:51:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283891</guid>
            <link>https://www.oschina.net/news/283891</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[官宣｜Apache Flink 1.19 發佈公告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" height="383" src="https://oscimg.oschina.net/oscnet/up-bc82a0da21bbbd289ae7fd13732c07d337d.png" width="685" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>Apache Flink PMC（項目管理委員）很高興地宣佈發佈 Apache Flink 1.19.0。與往常一樣，這是一個充實的版本，包含了廣泛的改進和新功能。總共有 162 人為此版本做出了貢獻，完成了 33 個 FLIPs、解決了 600 多個問題。感謝各位貢獻者的支持！</span></p><span id="OSC_h2_1"></span><h2><span>一、Flink SQL 提升</span></h2><span id="OSC_h3_2"></span><h3><span>源表自定義並行度</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在，在 Flink 1.19 中，您可以通過選 scan.parallelism 設置自定義並行度，以調整性能。第一個可用的連接器是 DataGen（ Kafka 連接器即將推出）。下面是一個使用 SQL Client 的示例：</span></p><pre><span>-- set parallelism within the ddl</span><span>CREATE TABLE Orders (</span><span> &nbsp;  order_number BIGINT,</span><span> &nbsp;  price &nbsp; &nbsp; &nbsp;  DECIMAL(32,2),</span><span> &nbsp;  buyer &nbsp; &nbsp; &nbsp;  ROW&lt;first_name STRING, last_name STRING&gt;,</span><span> &nbsp;  order_time &nbsp; TIMESTAMP(3)</span><span>) WITH (</span><span> &nbsp;  'connector' = 'datagen',</span><span> &nbsp;  'scan.parallelism' = '4'</span><span>);</span><span><span>​</span></span><span>-- or set parallelism via dynamic table option</span><span>SELECT * FROM Orders /*+ OPTIONS('scan.parallelism'='4') */;</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsourcessinks%2F%23scan-table-source" rel="nofollow" target="_blank"><span>文檔</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fpages%2Fviewpage.action%3FpageId%3D263429150" rel="nofollow" target="_blank"><span>FLIP-367: Support Setting Parallelism for Table/SQL Sources</span></a></span></p></li></ul><span id="OSC_h3_3"></span><h3><span>可配置的 SQL Gateway Java 選項</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>一個用於指定 Java 選項的新選項 env.java.opts.sql-gateway ，這樣你就可以微調內存設置、垃圾回收行為和其他相關 Java 參數。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-33203" rel="nofollow" target="_blank"><span>FLINK-33203</span></a></span></p></li></ul><span id="OSC_h3_4"></span><h3><span>使用 SQL 提示配置不同的狀態 TTL</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>從 Flink 1.18 開始，Table API 和 SQL 用户可以通過 SQL 編譯計劃為有狀態操作符單獨設置狀態存續時間 ( TTL )。在 Flink 1.19 中，用户可以</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fhints%2F%23state-ttl-hints" rel="nofollow" target="_blank"><span>使用 STATE_TTL 提示</span></a></span><span>，以更靈活的方式直接在查詢中為常規連接和分組聚合指定自定義 TTL 值。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>這一改進意味着您不再需要修改編譯後的計劃，就能為這些常用操作符設置特定的 TTL。引入 STATE_TTL 提示後，您可以簡化工作流程，並根據操作要求動態調整 TTL。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>下面是一個例子：</span></p><pre><span>-- set state ttl for join</span><span>SELECT /*+ STATE_TTL('Orders'= '1d', 'Customers' = '20d') */ *</span><span>FROM Orders LEFT OUTER JOIN Customers</span><span> &nbsp;  ON Orders.o_custkey = Customers.c_custkey;</span><span><span>​</span></span><span>-- set state ttl for aggregation</span><span>SELECT /*+ STATE_TTL('o' = '1d') */ o_orderkey, SUM(o_totalprice) AS revenue</span><span>FROM Orders AS o</span><span>GROUP BY o_orderkey;</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fhints%2F%23state-ttl-hints" rel="nofollow" target="_blank"><span>文檔</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-373%253A%2BSupport%2BConfiguring%2BDifferent%2BState%2BTTLs%2Busing%2BSQL%2BHint" rel="nofollow" target="_blank"><span>FLIP-373: Support Configuring Different State TTLs using SQL Hint</span></a></span></p></li></ul><span id="OSC_h3_5"></span><h3><span>函數和存儲過程支持命名參數</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在，在調用函數或存儲過程時可以使用命名參數。使用命名參數時，用户無需嚴格指定參數位置，只需指定參數名稱及其相應值即可。同時，如果沒有指定非必要參數，這些參數將默認為空值。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>下面是一個使用命名參數定義帶有一個必選參數和兩個可選參數的函數的示例：</span></p><pre><span>public static class NamedArgumentsTableFunction extends TableFunction&lt;Object&gt; {</span><span><span>​</span></span><span><span></span>@FunctionHint(</span><span><span></span><span></span><span></span>output = @DataTypeHint("STRING"),</span><span><span></span><span></span><span></span>arguments = {</span><span><span></span><span></span><span></span><span></span><span></span>@ArgumentHint(name = "in1", isOptional = false, type = @DataTypeHint("STRING")),</span><span><span></span><span></span><span></span><span></span><span></span>@ArgumentHint(name = "in2", isOptional = true, type = @DataTypeHint("STRING")),</span><span><span></span><span></span><span></span><span></span><span></span>@ArgumentHint(name = "in3", isOptional = true, type = @DataTypeHint("STRING"))})</span><span><span></span>public void eval(String arg1, String arg2, String arg3) {</span><span><span></span><span></span>collect(arg1 + ", " + arg2 + "," + arg3);</span><span><span></span>}</span><span><span>​</span></span><span>}</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 SQL 中調用函數時，可以通過名稱指定參數，例如：</span></p><pre><span>SELECT * FROM TABLE(myFunction(in1 =&gt; 'v1', in3 =&gt; 'v3', in2 =&gt; 'v2'))</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>可選參數也可以省略：</span></p><pre><span>SELECT * FROM TABLE(myFunction(in1 =&gt; 'v1'))</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Ffunctions%2Fudfs%2F%23named-parameters" rel="nofollow" target="_blank"><span>文檔</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-387%253A%2BSupport%2Bnamed%2Bparameters%2Bfor%2Bfunctions%2Band%2Bcall%2Bprocedures" rel="nofollow" target="_blank"><span>FLIP-387: Support named parameters for functions and call procedures</span></a></span></p></li></ul><span id="OSC_h3_6"></span><h3><span>Window TVF 聚合功能</span></h3><ul><li><p style="margin-left:.5rem; margin-right:0"><span>支持流模式下的 SESSION Window TVF</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在，用户可以在流模式下使用 SESSION Window TVF。下面是一個簡單的示例：</span></p><pre><span>-- session window with partition keys</span><span>SELECT * FROM TABLE(</span><span> &nbsp; SESSION(TABLE Bid PARTITION BY item, DESCRIPTOR(bidtime), INTERVAL '5' MINUTES));</span><span><span>​</span></span><span>-- apply aggregation on the session windowed table with partition keys</span><span>SELECT window_start, window_end, item, SUM(price) AS total_price</span><span>FROM TABLE(</span><span> &nbsp;  SESSION(TABLE Bid PARTITION BY item, DESCRIPTOR(bidtime), INTERVAL '5' MINUTES))</span><span>GROUP BY item, window_start, window_end;</span></pre><ul><li><p style="margin-left:.5rem; margin-right:0"><span>Window TVF 聚合支持處理更新流</span></p><p style="margin-left:.5rem; margin-right:.5rem"><span>窗口聚合運算符（基於窗口 TVF 函數生成）現在可以順利處理更新流（如 CDC 數據源等）。建議用户從傳統的，窗口聚合遷移到新語法，以獲得更全面的功能支持。</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fwindow-tvf%2F%23session" rel="nofollow" target="_blank"><span>文檔</span></a></span></p></li></ul><span id="OSC_h3_7"></span><h3><span>新的 UDF 類型：AsyncScalarFunction</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>常見的 UDF 類型 ScalarFunction 可以很好地處理 CPU 密集型操作，但對於 IO 密集型或其他長時間運行的計算則效果不佳。在 Flink 1.19 中，我們新增了 AsyncScalarFunction ，它是一種用户定義的異步 ScalarFunction ，允許異步發出併發函數調用。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-400%253A%2BAsyncScalarFunction%2Bfor%2Basynchronous%2Bscalar%2Bfunction%2Bsupport" rel="nofollow" target="_blank"><span>FLIP-400: AsyncScalarFunction for asynchronous scalar function support</span></a></span></p></li></ul><span id="OSC_h3_8"></span><h3><span>Regular Join 支持 MiniBatch 優化 </span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>消息放大是 Flink 中執行級聯連接時的一個痛點，現在在 Flink 1.19 中得到了解決，新的 MiniBatch 優化可用於 Regular Join，以減少此類級聯連接場景中的中間結果。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><img src="https://img.alicdn.com/imgextra/i1/O1CN01mIzhev22B9TWiUK3v_!!6000000007081-0-tps-2098-892.jpg" referrerpolicy="no-referrer"></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Ftuning%2F%23minibatch-regular-joins" rel="nofollow" target="_blank"><span>minibatch-regular-joins 文檔</span></a></span><span>.</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-415%253A%2BIntroduce%2Ba%2Bnew%2Bjoin%2Boperator%2Bto%2Bsupport%2Bminibatch" rel="nofollow" target="_blank"><span>FLIP-415: Introduce a new join operator to support minibatch</span></a></span></p></li></ul><span id="OSC_h2_9"></span><h2><span>二、Runtime &amp; Coordination 提升</span></h2><span id="OSC_h3_10"></span><h3><span>批作業支持源表動態並行度推導</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 Flink 1.19 中，我們支持批作業的源表動態並行度推導，允許源連接器根據實際消耗的數據量動態推斷並行度。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>與以前的版本相比，這一功能有了重大改進，以前的版本只能為源節點分配固定的默認並行度。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>源連接器需要實現推理接口，以啓用動態並行度推理。目前，FileSource 連接器已經開發出了這一功能。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>此外，配置 execution.batch.adaptive.auto-parallelism.default-source-parallelism 將被用作源並行度推理的上限。現在，它不會默認為 1。取而代之的是，如果沒有設置，將使用通過配置 execution.batch.adaptive.auto-parallelism.max-parallelism 設置的允許並行度上限。如果該配置也未設置，則將使用默認的並行度設置 parallelism.default 或 StreamExecutionEnvironment#setParallelism() 。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdeployment%2Felastic_scaling%2F%23enable-dynamic-parallelism-inference-support-for-sources" rel="nofollow" target="_blank"><span>文檔</span></a></span><span>.</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-379%253A%2BDynamic%2Bsource%2Bparallelism%2Binference%2Bfor%2Bbatch%2Bjobs" rel="nofollow" target="_blank"><span>FLIP-379: Support dynamic source parallelism inference for batch jobs</span></a></span></p></li></ul><span id="OSC_h3_11"></span><h3><span>Flink Configuration 支持標準 YAML 格式</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>從 Flink 1.19 開始，Flink 正式全面支持標準 YAML 1.2 語法。默認配置文件已改為 config.yaml ，放置在 conf/directory 中。如果用户想使用傳統的配置文件 flink-conf.yaml ，只需將該文件複製到 conf/directory 中即可。一旦檢測到傳統配置文件 flink-conf.yml ，Flink 就會優先使用它作為配置文件。而在即將推出的 Flink 2.0 中， flink-conf.yaml 配置文件將不再起作用。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdeployment%2Fconfig%2F%23flink-configuration-file" rel="nofollow" target="_blank"><span>flink-configuration-file 文檔</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-366%253A%2BSupport%2Bstandard%2BYAML%2Bfor%2BFLINK%2Bconfiguration%3Fsrc%3Dcontextnavpagetreemode" rel="nofollow" target="_blank"><span>FLIP-366: Support standard YAML for Flink configuration</span></a></span></p></li></ul><span id="OSC_h3_12"></span><h3><span>在 Flink Web 上 Profiling JobManager/TaskManager</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 Flink 1.19 中，我們支持在 JobManager/TaskManager 級別觸發 Profile，允許用户創建具有任意時間間隔和事件模式（由 async-profiler 支持）的 Profile 實例。用户可以在 Flink Web UI 中輕鬆提交剖析並導出結果。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>例如，用户只需在確定存在性能瓶頸的候選任 JobManager/TaskManager 後，通過 "Create Profiling Instance" 提交一個具有指定週期和模式的 Profile 實例：</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><img src="https://img.alicdn.com/imgextra/i4/O1CN01ytIK8C1uBavsxnY5B_!!6000000005999-0-tps-3582-1264.jpg" referrerpolicy="no-referrer"></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>Profile 結果：</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><img src="https://img.alicdn.com/imgextra/i1/O1CN015wZxI11T8OXVIHnj3_!!6000000002337-0-tps-2852-258.jpg" referrerpolicy="no-referrer"></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fops%2Fdebugging%2Fprofiler%2F" rel="nofollow" target="_blank"><span>文檔</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fx%2F64lEE" rel="nofollow" target="_blank"><span>FLIP-375: Built-in cross-platform powerful java profiler</span></a></span></p></li></ul><span id="OSC_h3_13"></span><h3><span>新增管理員 JVM 選項配置選項</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>有一組管理員 JVM 選項可供使用，它們是用户設置的額外 JVM 選項的前綴，用於全平台範圍的 JVM 調整。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdeployment%2Fconfig%2F%23jvm-and-logging-options" rel="nofollow" target="_blank"><span>文檔</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-397%253A%2BAdd%2Bconfig%2Boptions%2Bfor%2Badministrator%2BJVM%2Boptions%3Fsrc%3Djira" rel="nofollow" target="_blank"><span>FLIP-397: Add config options for administrator JVM options</span></a></span></p></li></ul><span id="OSC_h2_14"></span><h2><span>三、Checkpoints 提升</span></h2><span id="OSC_h3_15"></span><h3><span>Source 反壓時支持使用更大的 Checkpointing 間隔</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>引入 ProcessingBacklog 的目的是為了説明處理記錄時應採用低延遲還是高吞吐量。ProcessingBacklog 可由 Source 算子設置，並可用於在運行時更改作業的檢查點間隔。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-32514" rel="nofollow" target="_blank"><span>FLINK-32514</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-309%253A%2BSupport%2Busing%2Blarger%2Bcheckpointing%2Binterval%2Bwhen%2Bsource%2Bis%2Bprocessing%2Bbacklog" rel="nofollow" target="_blank"><span>[FLIP-309: Support using larger checkpointing interval when source is processing backlog]</span></a></span></p></li></ul><span id="OSC_h3_16"></span><h3><span>CheckpointsCleaner 並行清理單個檢查點狀態</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>現在，在處置不再需要的檢查點時，ioExecutor 會並行處置每個狀態句柄/狀態文件，從而大大提高了處置單個檢查點的速度（對於大型檢查點，處置時間可從 10 分鐘縮短至 &lt; 1 分鐘）。可以通過設置為 false 恢復舊版本的行為。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-33090" rel="nofollow" target="_blank"><span>FLINK-33090</span></a></span></p></li></ul><span id="OSC_h3_17"></span><h3><span>通過命令行客户端觸發 </span><span><strong><span>Checkpoints</span></strong></span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>命令行界面支持手動觸發檢查點。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用方法：</span></p><pre><span>./bin/flink checkpoint $JOB_ID [-full]</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>如果指定"-full "選項，就會觸發完全檢查點。否則，如果作業配置為定期進行增量檢查點，則會觸發增量檢查點。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-6755" rel="nofollow" target="_blank"><span>FLINK-6755</span></a></span></p></li></ul><span id="OSC_h2_18"></span><h2><span>四、Connector API 提升</span></h2><span id="OSC_h3_19"></span><h3><span>與 Source API 一致的 SinkV2 新接口</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 Flink 1.19 中，SinkV2 API 做了一些修改，以便與 Source API 保持一致。以下接口已被棄用： TwoPhaseCommittingSink、StatefulSink 、WithPreWriteTopology、WithPreCommitTopology、WithPostCommitTopology 。引入了以下新接口 CommitterInitContext 、CommittingSinkWriter 、 WriterInitContext 、StatefulSinkWrite。更改了以下接口方法的參數： Sink#createWriter 。 在 1.19 版本發佈期間，原有接口仍將可用，但會在後續版本中移除。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-33973" rel="nofollow" target="_blank"><span>FLINK-33973</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-372%253A%2BEnhance%2Band%2Bsynchronize%2BSink%2BAPI%2Bto%2Bmatch%2Bthe%2BSource%2BAPI" rel="nofollow" target="_blank"><span>FLIP-372: Enhance and synchronize Sink API to match the Source API</span></a></span></p></li></ul><span id="OSC_h3_20"></span><h3><span>用於跟蹤 Committables 狀態的新 Committer 指標</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>修改了 TwoPhaseCommittingSink#createCommitter 方法的參數化，新增了 CommitterInitContext 參數。原來的方法在 1.19 版本發佈期間仍然可用，但會在後續版本中移除。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-25857" rel="nofollow" target="_blank"><span>FLINK-25857</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-371%253A%2BProvide%2Binitialization%2Bcontext%2Bfor%2BCommitter%2Bcreation%2Bin%2BTwoPhaseCommittingSink" rel="nofollow" target="_blank"><span>FLIP-371: Provide initialization context for Committer creation in TwoPhaseCommittingSink</span></a></span></p></li></ul><span id="OSC_h2_21"></span><h2><span>五、重要 API 棄用</span></h2><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>為了給 Flink 2.0 版本做準備，社區決定正式廢棄多個已接近生命週期終點的 API。</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>Flink's </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ftime%2FTime.java" rel="nofollow" target="_blank"><span>org.apache.flink.api.common.time.Time</span></a></span><span> 現已被正式棄用，並將在 Flink 2.0 中刪除。引入了支持 Duration 類的方法，以取代已廢棄的基於 Time 的方法。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-runtime%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fruntime%2Fjobgraph%2FRestoreMode.java%23L40" rel="nofollow" target="_blank"><span>org.apache.flink.runtime.jobgraph.RestoreMode#LEGACY </span></a></span><span> 已被棄用。請使用 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-runtime%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fruntime%2Fjobgraph%2FRestoreMode.java%23L31" rel="nofollow" target="_blank"><span>RestoreMode#CLAIM</span></a></span><span> 或 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-runtime%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fruntime%2Fjobgraph%2FRestoreMode.java%23L34" rel="nofollow" target="_blank"><span>RestoreMode#NO_CLAIM</span></a></span><span> 模式，以在還原時獲得清晰的狀態文件所有權。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>舊的解決模式兼容性的方法已被棄用，請參考遷移説明遷移至新方法： </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Fdatastream%2Ffault-tolerance%2Fserialization%2Fcustom_serialization%2F%23migrating-from-deprecated-typeserializersnapshotresolveschemacompatibility" rel="nofollow" target="_blank"><span>Migrating from deprecated TypeSerializerSnapshot#resolveSchemaCompatibility(TypeSerializer newSerializer) before Flink 1.19</span></a></span><span>.</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>通過硬代碼配置序列化行為已被棄用，例如 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2FExecutionConfig.java%23L643" rel="nofollow" target="_blank"><span>ExecutionConfig#enableForceKryo</span></a></span><span>。請使用選 pipeline.serialization-config 、pipeline.force-avr 、pipeline.force-kryo 和 pipeline.generic-types。實例級序列化器的註冊已被棄用，請使用類級序列化器。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>除了 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FConfiguration.java%23L176" rel="nofollow" target="_blank"><span>getString(String key, String defaultValue) </span></a></span><span>和 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FConfiguration.java%23L220" rel="nofollow" target="_blank"><span>setString(String key, String value)</span></a></span><span>，我們已廢棄所有 setXxx 和 getXxx 方法，如：setInteger 、setLong 、getInteger 和 getLong 等。 建議用户和開發人員使用以 ConfigOption 代替字符串作為鍵的 get 和 set 方法。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>StreamExecutionEnvironment 、CheckpointConfig 和 ExecutionConfig 中的非 ConfigOption 對象及其相應的 getter/setter 接口現已廢棄。這些對象和方法計劃在 Flink 2.0 中刪除。已廢棄的接口包括重啓策略（ RestartStrategy ）、檢查點存儲（ CheckpointStorage ）和狀態後端（ StateBackend ）的 getter 和 setter 方法。 </span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRuntimeContext.java%23L191" rel="nofollow" target="_blank"><span>org.apache.flink.api.common.functions.RuntimeContext#getExecutionConfig</span></a></span><span> 現已被正式棄用，並將在 Flink 2.0 中刪除。請使用 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRuntimeContext.java%23L208" rel="nofollow" target="_blank"><span>getGlobalJobParameters()</span></a></span><span> 或 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRuntimeContext.java%23L216" rel="nofollow" target="_blank"><span>isObjectReuseEnabled()</span></a></span><span>。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRichFunction.java%23L76" rel="nofollow" target="_blank"><span>org.apache.flink.api.common.functions.RichFunction#open(Configuration parameters)</span></a></span><span> 方法已被棄用，並將在未來版本中刪除。我們鼓勵用户遷移到新的</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRichFunction.java%23L118" rel="nofollow" target="_blank"><span>RichFunction#open(OpenContext openContext)</span></a></span><span>。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FAkkaOptions.java" rel="nofollow" target="_blank"><span>org.apache.flink.configuration.AkkaOptions </span></a></span><span> 已被棄用，取而代之的是 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FRpcOptions.java" rel="nofollow" target="_blank"><span> RpcOptions </span></a></span><span>。</span></p></li></ul><span id="OSC_h2_22"></span><h2><span>六、升級説明</span></h2><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>Apache Flink 社區努力確保升級過程儘可能平穩, 但是升級到 1.19 版本可能需要用户對現有應用程序做出一些調整。請參考 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Frelease-notes%2Fflink-1.19%2F" rel="nofollow" target="_blank"><span>Release Notes</span></a></span><span> 獲取更多的升級時需要的改動與可能的問題列表細節。</span></p><span id="OSC_h2_23"></span><h2><span>貢獻者列表</span></h2><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><img alt="" height="1208" src="https://oscimg.oschina.net/oscnet/up-3b5104e2ecbe3e23ee1f72b104fd572d9c2.png" width="1550" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><hr><span id="OSC_h2_24"></span><h2>Flink Forward Asia 2023</h2><p>本屆 Flink Forward Asia 更多精彩內容，可微信掃描圖片二維碼觀看全部議題的視頻回放及 FFA 2023 峯會資料！</p><p><img alt="" src="https://ucc.alicdn.com/gfbp4bwpctdbo_20231225_14aea0210006473091eeaad86fb840a2.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8374c4af52676c9e8e31915ba3a7c4ec22c.png" referrerpolicy="no-referrer"></p><hr><span id="OSC_h2_25"></span><h2>更多內容</h2><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fba668f04d5a3f206c6530c940b5973aa44.png" referrerpolicy="no-referrer"></p><hr><span id="OSC_h2_26"></span><h2>活動推薦</h2><p>阿里雲基於 Apache Flink 構建的企業級產品-實時計算 Flink 版現開啓活動：<br> 59 元試用&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3FpipCode%3Dsc" rel="nofollow" target="_blank">實時計算 Flink 版</a>（3000CU*小時，3 個月內）<br> 瞭解活動詳情：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3FpipCode%3Dsc" rel="nofollow" target="_blank">https://free.aliyun.com/?pipCode=sc</a></p><p><img alt="" src="https://ucc.alicdn.com/pic/developer-ecology/gfbp4bwpctdbo_b2c1ad1f1c94438ba3d2f6eb2f40a795.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-140340868927cb8aa03b4b96e643c9112cb.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 05:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/2828172/blog/11047986</guid>
            <link>https://my.oschina.net/u/2828172/blog/11047986</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Node.js 新版官網正式上線]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Node.js 新版官網已正式上線：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnodejs.org%2Fen" target="_blank">https://nodejs.org/en</a></u>。</p><ul><li><strong>Node.js 新版官網首頁</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d7f75fbfacc0c0f7aa4bd49a44845da9c0e.png" referrerpolicy="no-referrer"></p><ul><li><strong>舊版官網首頁</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d7fdf3a71b012fa030e0d8da045acd8a078.png" referrerpolicy="no-referrer"></p><p>可以看到，新版官網的視覺效果、頁面佈局、展現內容都有了很大的提升，整體上更大氣、更現代化。而且首頁關於 Node.js 的介紹也變得更突出、描述更全面。</p><p>此外，新版官網最大的交互變化是在首頁添加了「全局搜索」入口，方便用户隨時檢索文檔、博客、下載等信息。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9984afc8c57cf2cc9b031519ad713980ba.png" referrerpolicy="no-referrer"></p><p>其他子頁面一覽：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5219eed54c5df5855bb21a3c939725e914b.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-82a9406af23007a8c812f31fd7c8bdce52f.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c626de0d15afa528c4f04eb59658c79635e.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f4190b429a1060ceb08600f74698605af6.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-432b101ae6fdf83b85ce42d68b8f7ca2b68.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 04:23:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283883/node-js-org-new-ui</guid>
            <link>https://www.oschina.net/news/283883/node-js-org-new-ui</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[iLogtail 2.0 來了；通義靈碼下載量破百萬]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>雲原生月度動態</strong></p><p>雲原生是企業數字創新的最短路徑。</p><p>《阿里云云原生每月動態》，從趨勢熱點、產品新功能、服務客户、開源與開發者動態等方面，為企業提供數字化的路徑與指南。</p><h2>趨勢熱點</h2><h3>🥇&nbsp;雲原生可觀測團隊獲選「InfoQ 年度技術內容貢獻獎」</h3><p>近期，知名技術媒體 InfoQ 結合廣大開發者和技術社羣的實際反饋，評選出「InfoQ 年度技術內容貢獻獎」，以表彰推動業界知識分享的卓越貢獻者。其中，「阿里云云原生可觀測團隊」成功獲選，以此表彰阿里云云原生可觀測團隊在技術研發與產品創新同時，積極參與技術內容輸出、社區建設、知識分享等活動，努力推進雲原生、可觀測的落地實踐。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247561870%26idx%3D1%26sn%3Dd8f2919d37b32eb46aa973032ada64eb%26chksm%3Dfae7f941cd907057abc8ce4be579cc7ba83f6e674c3a989145b6c35b320ff53b0f35f3167c3e%26scene%3D21%23wechat_redirect" target="_blank">相關文章：「雲原生可觀測團隊」獲選「InfoQ 年度技術內容貢獻獎」</a></p><h3>🥈&nbsp;國內唯一！通義靈碼入選全球智能編碼助手使用率 TOP 榜單</h3><p>近日，在國內知名科技媒體 InfoQ 研究中心發佈的《中國軟件技術發展洞察和趨勢預測報告 2024》中提到，隨着 AI 和大模型技術的普及，開發者智能編碼助手的使用習慣已經養成，其中，開發者使用的智能編碼助手產品使用率超過 10% 的產品共計 8 款，唯一一款國內企業研發的產品為阿里旗下的通義靈碼，使用率佔比 12.9% 排名第五。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247561987%26idx%3D1%26sn%3D094e6ffb1ecd9268194cd912401dc09d%26chksm%3Dfae7f8cccd9071daf348db0f1a9f8f65179589da0d3f9cf065adedf604b1ab8fa01222750367%26scene%3D21%23wechat_redirect" target="_blank">相關文章：國內唯一！通義靈碼入選全球智能編碼助手使用率 TOP 榜單<br></a></p><h3>🥉&nbsp;iLogtail 2.0 來了！</h3><p>隨着可觀測數據採集需求的不斷推陳出新，現有的 iLogtail 架構和採集配置結構逐漸成為制約 iLogtail 繼續快速演進的瓶頸。基於此，團隊決定對 iLogtail 進行全面升級，全面提升 iLogtail 的易用性、可擴展性和性能。經過半年多的重構與優化，iLogtail 2.0 已經呼之欲出，有以下新特性：【商業版】採集配置全面升級流水線結構、處理插件組合更加靈活、新增 SPL 處理模式、日誌解析控制更加精細、【商業版】日誌時間解析支持納秒級精度、【商業版】狀態觀測更加清晰、運行更快更安全。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247562109%26idx%3D1%26sn%3D997036af93cc31ff68faab565d6f5022%26chksm%3Dfae7f8b2cd9071a4e7822493c921cec17d273ec25e4621d35caeda0445b8a08ba2d1da940356%26scene%3D21%23wechat_redirect" target="_blank">相關文章：你好，iLogtail 2.0！<br></a></p><h2>產品新功能</h2><h3>微服務引擎 MSE</h3><ul><li>MSE 註冊配置中心支持在控制枱進行網絡變配</li><li>雲原生網關核心鏈路優化</li></ul><h3>雲效項目協作 Projex</h3><ul><li>項目管理權限細化：將成員管理、基本信息設置、通知等單獨拆分權限點</li><li>支持項目模板角色權限同步</li></ul><h3>日誌服務 SLS</h3><ul><li>SLS Lens 支持 SQL 質量報告功能</li><li>logtail 2.0.1 版本支持 SPL 數據處理語言處理數據</li><li>SLS 支持接入 NLB 產品 4 層指標數據，支持短信服務（國際站）日誌</li><li>SLS 日誌審計應用支持以張家口作為中心化存儲地域</li></ul><h3>應用實時監控服務 ARMS</h3><p><strong>應用監控</strong></p><ul><li>新版控制枱調用鏈分析支持錯慢 Trace 分析功能</li><li>持續剖析配置支持根據應用部署環境自動填充網段地址</li></ul><p><strong>智能告警</strong></p><ul><li>應用監控告警事件詳情支持傳遞自定義的應用標籤</li><li>告警屏蔽操作支持填寫屏蔽原因</li></ul><p><strong>用户體驗監控</strong></p><ul><li>會話追蹤詳情面板</li><li>資源加載趨勢分析</li><li>App 監控能力</li></ul><p>雲撥測證書過期時間檢測和告警</p><h3>可觀測鏈路 OpenTelemetry 版</h3><p>可觀測鏈路 OpenTelemetry 版重磅發佈 2.0 版本</p><h3>可觀測監控 Prometheus 版</h3><ul><li>數據投遞服務支持將阿里雲 Prometheus 數據通過 &nbsp;RemoteWrite 協議投遞到自建 &nbsp;Prometheus</li><li>接入管理支持配置廢棄指標</li><li>RDS-PG 增加監控指標</li><li>新版接入中心海外區域全面上線</li><li>新版接入中心海外區域全面上線 ack-sysom-monitor 監控限時免費（2024/2/21-2024/5/21 ）</li></ul><h3>通義靈碼</h3><ul><li>支持自定義配置不觸發行間生成的編程語言</li><li>VS Code 兼容 Windows 7 操作系統，擴展 IDE 版本兼容到 1.70.0 以上</li><li>優化 Java、Python 生成單元測試效果及新建文件命名規則</li><li>優化登錄後身份選擇的提示</li></ul><h2>優秀實戰案例</h2><h3>青團社：億級靈活用工平台的雲原生架構實踐</h3><p>青團社是國內領先的一站式靈活用工招聘服務企業，在發展初期技術架構比較薄弱，存在較多問題。面對這些問題，青團社開始了架構演進，選擇了進行微服務架構和業務容器化改造，同時，在可觀測性和應用性的架構上，用阿里雲應用實時監控服務 ARMS 的應用監控能力和 MSE 產品來對應用服務進行性能觀測與流量治理，使應用實現了高可用和彈性調度，能快速瞭解系統運行狀態，運維成本也大幅降低。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247562153%26idx%3D1%26sn%3Df6f5fb5931dac455ce6fe296c0a41375%26chksm%3Dfae7f866cd90717038e7f848d1e6f7d2d90fd1d2a14e115f714564b7ecdf55cc92200e3ecd38%26scene%3D21%23wechat_redirect" target="_blank">相關文章：青團社：億級靈活用工平台的雲原生架構實踐<br></a></p><h2>開源與開發者動態</h2><h3>有獎討論丨你能看出來哪些是 AI 寫的代碼麼？</h3><p>隨着 AI 智能浪潮到來，AI 智能編碼助手成為越來越多開發者的必備工具，本期話題我們就來聊聊備受關注的「AI 編碼助手」，體驗「通義靈碼」，分享使用感受。</p><p>相關文章：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247561935%26idx%3D2%26sn%3D8ee55dc8ed4ad3694ee4efc1ad38ff87%26chksm%3Dfae7f900cd907016e273eb3dd3d884797ba6662301a95d0580e98c34484701ca06b5288094a6%26scene%3D21%23wechat_redirect" target="_blank">有獎討論丨你能看出來哪些是 AI 寫的代碼麼？</a></p><h3>參與通義靈碼體驗活動贏全球架構師峯會門票</h3><p>通義靈碼，是阿里雲出品的一款基於通義大模型的智能編碼輔助工具，提供行級/函數級實時續寫、自然語言生成代碼、單元測試生成、代碼優化、註釋生成、代碼解釋、研發智能問答、異常報錯排查等能力，並針對阿里雲的雲服務使用場景調優，助力開發者高效、流暢的編碼。本次 ArchSummit 架構師峯會期間，通義靈碼聯合 InfoQ 策劃發起 AI 編程體驗活動，參與通義靈碼體驗抽獎活動，有機會贏全球架構師峯會專屬免費門票。（票價 5440 元）</p><p>相關文章：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247562169%26idx%3D1%26sn%3Dc084e24cd2efbc65e21f1cc5e220f179%26chksm%3Dfae7f876cd90716067905c024e3d4ed2a86b75129f302453a520938a26a48382c641f43bea54%26scene%3D21%23wechat_redirect" target="_blank">AI 編程如何顛覆生產力 | 參與體驗免費領取 ArchSummit 架構師峯會專屬門票</a></p><p>點擊<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftongyi.aliyun.com%2Flingma" target="_blank">此處</a>，進入通義靈碼官網快速體驗。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:51:17 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/11048168</guid>
            <link>https://my.oschina.net/u/3874284/blog/11048168</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 22 正式發佈，一文了解全部新特性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在昨晚，Java 22 正式發佈！該版本提供了 12 項功能增強，其中包括 7 項預覽功能和 1 項孵化器功能。它們涵蓋了對 Java 語言、API、性能以及 JDK 中包含的工具的改進。</p><p>下面就來一起學習一下該版本都更新了哪些新特性！</p><h2>Unnamed Variables &amp; Patterns - JEP 456</h2><p>JEP 456 - 未命名變量和模式：當需要但未使用變量聲明或嵌套模式時，提高了可讀性。兩者都由下劃線字符表示。</p><p><strong>價值</strong></p><ul><li>捕獲開發人員的意圖，即未使用給定的綁定或 lambda 參數，並強制執行該屬性以澄清程序並減少出錯的機會。</li><li>通過識別必須聲明（例如，在 catch 子句中）但未使用的變量，提高所有代碼的可維護性。</li><li>允許多個模式出現在單個 case 標籤中，如果它們都沒有聲明任何模式變量。</li><li>通過消除不必要的嵌套類型模式來提高記錄模式的可讀性。</li></ul><h2>Statements before super (…) [Preview] - JEP 447</h2><p>在構造函數中，允許不引用正在創建的實例的語句出現在顯式構造函數調用之前。</p><p><strong>價值</strong></p><ul><li>為開發人員提供了更大的自由來表達構造函數的行為，從而可以更自然地放置目前必須納入輔助靜態方法、輔助中間構造函數或構造函數參數中的邏輯。</li><li>保留構造函數在類實例化期間按自上而下順序運行的現有保證，確保子類構造函數中的代碼不會干擾超類實例化。</li><li>不需要對 Java 虛擬機進行任何更改。此 Java 語言功能僅依賴於 JVM 驗證和執行構造函數中顯式構造函數調用之前出現的代碼的當前能力。</li></ul><h2>String Templates (2nd Preview) - JEP 459</h2><p>字符串模版的第 2 個預覽版，關於該功能之前 DD 給大家介紹過，更多細節可以看看之前的這篇文章<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2Fjava21%2Fjep430-string-templates.html" target="_blank">String Templates（字符串模版）</a></p><p><strong>價值</strong></p><ul><li>通過輕鬆表達包含運行時計算值的字符串，簡化了 Java 程序的編寫。</li><li>增強混合文本和表達式的表達式的可讀性，無論文本適合單個源行（如字符串文字）還是跨越多個源行（如文本塊）。</li><li>通過支持模板及其嵌入表達式的值的驗證和轉換，提高 Java 程序的安全性，這些程序從用户提供的值組成字符串並將其傳遞到其他系統（例如，構建數據庫查詢）。</li><li>通過允許 Java 庫定義字符串模板中使用的格式化語法來保留靈活性。</li><li>簡化了接受非 Java 語言（例如 SQL、XML 和 JSON）編寫的字符串的 API 的使用。</li><li>允許創建根據文字文本和嵌入表達式計算的非字符串值，而無需通過中間字符串表示形式進行傳輸。</li></ul><h2>Implicitly Declared Classes and Instance Main Methods (2nd Preview) - JEP 463</h2><p>隱式聲明的類和實例主要方法（2nd 預覽）- JEP 463</p><p>學生可以編寫他們的第一個 Java 程序，而無需瞭解為大型程序設計的語言功能。學生無需使用單獨的語言方言，而是可以為單類程序編寫簡化的聲明，然後隨着技能的增長無縫擴展他們的程序以使用更高級的功能。關於該特性，之前 DD 也介紹過，更多細節可見這篇文章<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2Fjava21%2Fjep445-Unnamed-Classes-and-Instance-Main-Methods.html" target="_blank">未命名類和實例的 Main 方法</a></p><p><strong>價值</strong></p><ul><li>加速 Java 學習</li><li>為 Java 編程提供了一個平滑的入門通道，以便教師可以循序漸進地介紹概念。</li><li>幫助學生以簡潔的方式編寫基本程序，並隨着他們的技能增長而優雅地擴展他們的代碼。</li><li>減少編寫簡單程序（例如：腳本和命令行實用程序）的方式。</li><li>不引入單獨的初學者工具鏈；學生程序應該使用與編譯和運行任何 Java 程序相同的工具來編譯和運行。</li></ul><h2>Foreign Function &amp; Memory API - JEP 454</h2><p>外部函數和內存 API - JEP 454</p><p>允許 Java 程序與 Java 運行時之外的代碼和數據進行互操作。通過有效地調用外部函數（即 JVM 外部的代碼），並安全地訪問外部內存（即不受 JVM 管理的內存），API 使 Java 程序能夠調用本機庫並處理本機數據，而不會出現脆弱性和危險。 JNI。</p><p><strong>價值</strong></p><ul><li>生產力：用簡潔、可讀且純 Java API 取代脆弱的本機方法和 Java 本機接口 (JNI)。</li><li>性能：提供對外部函數和內存的訪問，其開銷與 JNI 和 sun.misc.Unsafe 相當（如果不是更好的話）。</li><li>廣泛的平台支持：允許在 JVM 運行的每個平台上發現和調用本機庫。</li><li>一致性：提供在多種內存（例如本機內存、持久內存和託管堆內存）中操作無限大小的結構化和非結構化數據的方法。</li><li>健全性：保證沒有釋放後使用錯誤，即使在多個線程之間分配和釋放內存時也是如此。</li><li>完整性：允許程序使用本機代碼和數據執行不安全的操作，但默認警告用户此類操作。</li></ul><h2>Class-File API (Preview) - JEP 457</h2><p>類文件 API（預覽版）- JEP 457，提供用於解析、生成和轉換 Java 類文件的標準 API。</p><p><strong>價值</strong></p><ul><li>該 API 允許依賴它的框架和程序自動支持最新 JDK 中的最新類文件，以便可以快速、輕鬆地採用以類文件表示的新語言和 VM 功能。</li></ul><h2>Stream Gatherers (Preview) - JEP 461</h2><p>Stream Gatherers（預覽版）- JEP 461，增強了 Stream API 以支持自定義中間操作。這將允許流管道以現有內置中間操作不易實現的方式轉換數據。</p><p><strong>價值</strong></p><ul><li>通過使流中的常見自定義操作更加靈活和富有表現力，提高開發人員的工作效率和代碼可讀性。儘可能允許中間操作操作無限大小的流。</li></ul><h2>Structured Concurrency (2nd Preview) - JEP 462</h2><p>結構化併發（2nd 預覽版）- JEP 462，簡化併發編程。結構化併發將在不同線程中運行的相關任務組視為單個工作單元，從而簡化錯誤處理和取消、提高可靠性並增強可觀察性。</p><p><strong>價值</strong></p><ul><li>通過推廣一種編程風格來簡化併發代碼的開發，這種編程風格可以消除因取消和關閉而產生的常見風險（例如線程泄漏和取消延遲），並提高併發代碼的可觀察性。</li></ul><h2>Scoped Values (2nd Preview) - JEP 464</h2><p>範圍值（2nd 預覽）- JEP 464，實現線程內和線程間不可變數據的高效共享。</p><p><strong>價值</strong></p><ul><li>易於使用 - 提供一個編程模型來在線程內以及與子線程共享數據，以簡化有關數據流的推理。</li><li>可理解性——使共享數據的生命週期從代碼的語法結構中可見。</li><li>魯棒性——確保調用者共享的數據只能由合法的被調用者檢索。</li><li>性能——將共享數據視為不可變，以允許大量線程共享，並實現運行時優化。</li></ul><h2>Vector API (7th Incubator) - JEP 460</h2><p>矢量 API（7th 孵化器）- JEP 460，一個用於表達向量計算的 API，可在運行時可靠地在支持的 CPU 架構上編譯為最佳向量指令，從而實現優於等效標量計算的性能。此 JEP 建議在 JDK 22 中重新孵化該 API，相對於 JDK 21。該實現包括錯誤修復和性能增強。我們包括以下顯着變化：</p><ul><li>支持使用任何原始元素類型的數組支持的堆 MemorySegments 進行向量訪問。以前的訪問僅限於由字節數組支持的堆 MemorySegment。</li></ul><p><strong>價值</strong></p><ul><li>提供清晰簡潔的 API，能夠清晰簡潔地表達各種向量計算，這些向量計算由循環內組成的向量運算序列組成，並且可能還包含控制流。</li><li>該 API 設計為與 CPU 架構無關，可在支持向量指令的多種架構上實現。</li><li>在 x64 和 AArch64 架構上提供可靠的運行時編譯和性能。</li></ul><h2>Regional Pinning for G1 - JEP 423</h2><p>G1 的區域固定 - JEP 423，通過在 G1 中實現區域固定來減少延遲，以便在 Java 本機接口 (JNI) 關鍵區域期間無需禁用垃圾收集。</p><p><strong>價值</strong></p><ul><li>使用 JNI 時，Java 線程無需在 G1 GC 操作完成之前等待，從而提高開發人員的工作效率。</li></ul><h2>Launch Multi-File Source-Code Programs - JEP 458</h2><p>啓動多文件源代碼程序 - JEP 458，允許用户運行作為多個 Java 源代碼文件提供的程序，而無需先進行編譯。</p><p><strong>價值</strong></p><ul><li>通過使從小程序到大型程序的過渡更加漸進，提高開發人員的工作效率，使開發人員能夠選擇是否以及何時配置構建工具。</li><li>請注意，預覽功能已完全指定並完全實現了 Java SE 平台的語言或 VM 功能，但它們是暫時的。它們在 JDK 功能版本中提供，以便開發人員根據實際使用情況提供反饋，然後再在未來版本中永久保留。這也為工具供應商提供了在最終確定為 Java SE 標準之前致力於支持功能的機會。</li><li>孵化器模塊中的 API 將非最終 API 和非最終工具交給開發人員和用户，以收集反饋，最終提高 Java 平台的質量。</li><li>除了 JEP 中描述的更改之外，發行説明中還列出了許多較小的更新，許多應用程序開發人員和系統管理員都會對此感興趣。其中包括棄用過時的 API 和刪除以前棄用的 API。</li></ul><h2>其他更新</h2><p>Java 22 發行説明中還有​​一些其他關鍵更新：</p><ul><li>向 keytool 和 jarsigner 添加附加算法。</li><li>垃圾收集器吞吐量的提高，尤其是與「年輕」垃圾相關的情況。</li><li>更好的系統模塊描述符版本報告。</li><li>改進了本機代碼的「wait」處理選項。</li><li>Unicode 通用區域設置數據存儲庫已更新至版本 44。</li><li>類型註釋支持從字節碼加載的類型。</li><li>ForkJoinPool 和 ForJoinTasks 現在可以更好地處理不間斷任務。</li><li>配置客户端與服務器 TLS 連接屬性的額外靈活性。</li><li>改進了本機內存跟蹤，包括報告峯值使用情況的能力</li></ul><p>最後注意：JDK 22 是通過六個月的發佈節奏按時交付的 13th 功能版本。由於預期改進源源不斷，這種程度的可預測性使開發人員能夠輕鬆管理創新的採用。Oracle 不會為 JDK 22 提供長期支持，在 2023 年 9 月之前提供更新，之後它將被 Oracle JDK 23 取代。最近的長期維護版本是 Java 21，更多關於 Java 新特性的解讀和學習歡迎關注<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2F" target="_blank">《Java 新特性解讀》</a>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8dea4b48eb8ffca981a1a54d4079789b777.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>歡迎關注我的公眾號：程序猿 DD。第一時間瞭解前沿行業消息、分享深度技術乾貨、獲取優質學習資源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:50:17 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/didispace/blog/11048218</guid>
            <link>https://my.oschina.net/didispace/blog/11048218</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | Grok 使用體驗完全夠不上第一梯隊，Surface Duo 在開源社區扶持下煥發新生]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#e67e22"><strong># 2024.3.19</strong></span></h3><h2 style="margin-left:0; margin-right:0; text-align:left"><strong><span style="color:#16a085">今日要點</span></strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>OpenSource Daily</strong></p><h3 style="margin-left:0; margin-right:0; text-align:left"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1aEpUETGY14C9nAJU-v9dw" target="_blank">英偉達全新 GPU 架構 Blackwell<span>——</span>「全球最強」、第二代 Transformer 引擎、計算性能提升 1000 倍</a></strong></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">按照每兩年更新一次 GPU 架構的傳統，今年黃仁勳如期公佈了英偉達新一代 AI 芯片架構 Blackwell，以及基於該架構的 B200、GB200 系列芯片。他在演講台上表示，這是目前為止功能最強大的 AI 芯片家族。8 年，從 Pascal 架構到 Blackwell 架構，英偉達將 AI 計算性能提升了 1000 倍！黃仁勳表示：「Hopper 固然已經非常出色了，但我們需要更強大的 GPU」。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="375" src="https://oscimg.oschina.net/oscnet/up-c8c1a36924f6258786a38abcdf84c1220f4.png" width="500" referrerpolicy="no-referrer"></p><h3 style="margin-left:0; margin-right:0; text-align:start"><strong><a href="https://www.oschina.net/news/283757" target="_blank">微信 Linux 原生版正式支持龍架構</a></strong></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">龍芯中科<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2gzVb4cvnVSOP_qgi3A0Bg" target="_blank">宣佈</a>，在騰訊微信團隊、龍芯中科與國產操作系統廠商的共同努力下，微信 Linux 原生版在龍架構平台終端已於近日成功啓動運行，並在操作系統廠商應用商店上架分發，為用户帶來全新的龍架構平台使用體驗。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">本次微信（Universal）是基於原生跨平台方案進行的一次大型版本重構與更新，旨在逐步實現微信 Windows/Mac/Linux 版本在功能與更新節奏上保持一致，大幅提高軟件功能的開發與迭代速度。同時，新版本功能也更加豐富，支持大文件收發、羣管理、雙人視頻通話、一鍵開啓視頻號、小程序、搜一搜等實用功能。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="281" src="https://oscimg.oschina.net/oscnet/up-8af6d64640c735fa2e0b0e82057264aa298.jpg" width="500" referrerpolicy="no-referrer"></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><strong><span style="color:#16a085">今日觀察</span></strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="97" src="https://oscimg.oschina.net/oscnet/up-22ef22ee0a115b4cc31c8e2d7df84d742f1.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">-<span>&nbsp;</span></span>微博 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2337975403%2FO5z5a0Ij2" target="_blank"><em>詹俊全</em></a></u></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="122" src="https://oscimg.oschina.net/oscnet/up-1fedf59d99708d718ae00a49e1527ffc328.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">-&nbsp;微博<span>&nbsp;</span></span><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1560906700%2FO5HOTACxA%3Frefer_flag%3D1001030103_" target="_blank">闌夕</a></u></em></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="120" src="https://oscimg.oschina.net/oscnet/up-18ae674bface2fa54ccf5013b070a987524.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">- <em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2F2024-03-19%2Fdetail-inanviqu4644393.d.html" target="_blank">每日經濟新聞</a></u></em></span></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="409" src="https://oscimg.oschina.net/oscnet/up-2a95c498beb1bd4a0f02da6d0f975cf6235.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmanticoresoftware%2Fmanticoresearch" target="_blank">https://github.com/manticoresoftware/manticoresearch</a></u></em></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#16a085"><strong>事件點評</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="470" src="https://oscimg.oschina.net/oscnet/up-b4b468388bab83bb920db154ed8a6269d4a.png" width="500" referrerpolicy="no-referrer"></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong><span style="background-color:#e67e22">每日 GitHub 精選</span></strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="637" src="https://oscimg.oschina.net/oscnet/up-75a419043367ba895f86d3d58d171950867.png" width="500" referrerpolicy="no-referrer"></p><blockquote><h4 style="margin-left:0; margin-right:0"><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/aud8p7bvfbui2z3/032_nvidia_ai_blackwell_surface_duo_MfoMo6bqlE.pdf" target="_blank">開源日報第 032 期：Grok 使用體驗完全夠不上第一梯隊，Surface Duo 在開源社區扶持下煥發新生</a></u></em></h4></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>往期回顧</strong></p><ul style="list-style-type:disc; margin-left:0; margin-right:0"><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/maajc6fkxn2b8la/031_microsoft_autodev_grok_os_vvdrJAOBEq.pdf" target="_blank">開源日報第 031 期：微軟 AI 程序員登場，馬斯克開源 Grok</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/bkpgqfjrsg02gbc/30_i9_14900_ks_hip_rt_PUJjodKP2j.pdf" target="_blank">開源日報第 030 期：RISC-V 正在發生質變？離職後可以刪除自己所寫的軟件嗎</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/71npja41p7l4ojy/29_risc_v_ai_smart_B3RnKR88Kl.pdf" target="_blank">開源日報第 029 期：英特爾獲準繼續向華為出售芯片；明年 AI 將比任何人都聰明</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/q35lx4s6qq9ls4r/28_cognition_labs_devin_Epbxne3xzN.pdf" target="_blank">開源日報第 028 期：全球首位 AI 軟件工程師 Devin；谷歌承認 「竊取」 OpenAI 模型關鍵信息</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/hh291xp9mxksc9i/27_ai_google_50_gpt_4_KfagjDXXfZ.pdf" target="_blank">開源日報第 027 期：AI 接連翻車的 Google 要變天了；互聯網大廠 50 款大模型及應用，能否全面超越 GPT-4？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/uwsizmmsnhq8zdk/26_git_hub_22_web_os_22_vue_rolldown_FpVykoR7rJ.pdf" target="_blank">開源日報第 026 期：大模型替代程序員根本就是一個偽命題；GitHub 頂流 "Web OS"</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6ho57sxydzsh9jh/25_ai_5_ax1LWz5GP5.pdf" target="_blank">開源日報第 025 期：買手機送大模型；「釣魚式維權」 須遏制；「AI 原生」 騙局江湖</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7xd6teyhekcvamw/24_risc_v_x86_arm_5LsjoStPUn.pdf" target="_blank">開源日報第 024 期：RISC-V 能否和 x86、Arm 一起成為三大主流架構；給閻王開發地府管理系統</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">開源日報第 023 期：Google = 開源，好評；Microsoft = 閉源收入還低，差評</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">開源日報第 022 期：輕鬆復現 Sora 模型；事關 CUDA 兼容，英偉達禁止了；百度還差一個 「遙遙領先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">開源日報第 021 期：閉源模型就是比開源安全；起訴 OpenAI 不能更贊同</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">開源日報第 020 期：為什麼王炸都來自 OpenAI；Pingora 最好不要用 YAML 當配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">開源日報第 019 期：我讓 AI 用 C 語言寫一個算法；微軟三進制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">開源日報第 018 期：蘋果十年造車夢碎；這個開源項目有點...「大膽」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">開源日報第 017 期：MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有 「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:47:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283875</guid>
            <link>https://www.oschina.net/news/283875</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英偉達和高通加入開源機器人聯盟支持 ROS 開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">開源機器人基金會 (OSRF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fosralliance.org%2Fopen-robotics-launches-the-open-source-robotics-alliance-2%2F" target="_blank">宣佈</a>成立開源機器人聯盟 (OSRA)，旨在維持開源機器人項目的開發和維護，特別關注 OSRF 自己的機器人操作系統 (ROS) 的健康發展。</span></p><p><span style="color:#000000">公告指出，OSRA 將效仿 Linux 基金會和 Eclipse 基金會等其他成功的開源項目基金會，採用混合會員制和精英管理模式。公開邀請所有社區利益相關者參與 OSRF 開源項目（ROS、Gazebo、Open-RMF 及其基礎設施）的技術監督、指導、開發和支持。「整個機器人生態系統的參與對這項計劃至關重要。」</span></p><p><span style="color:#000000">OSRA 的中心是技術治理委員會 (TGC)，該委員會將監督各個項目管理委員會、技術委員會、特別興趣組和工作組的活動。作為 OSRF 的一項慈善計劃，OSRA 的總體責任仍由 OSRF 董事會承擔。</span></p><p><img height="241" src="https://oscimg.oschina.net/oscnet/up-41f7c0a537fff8636e3a87932da3a46430c.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">為了表示支持，英偉達、高通以及由 Alphabet 成立的衍生機器人公司 Intrinsic 均已簽約成為新聯盟的「白金」成員 。</span></p><p><span style="color:#000000">英偉達機器人軟件副總裁 Gordon Grigor 表示：「英偉達利用 ROS 2 進行開發，為開發人員、研究人員和商業應用帶來加速計算和人工智能。作為 OSRA 的首屆白金會員，我們將通過協助開發工作、提供治理和連續性來合作推進整個生態系統的開源機器人技術。」</span></p><p><span style="color:#000000">其他成員還包括金牌成員 </span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FApex.ai" target="_blank"><span style="color:#000000">Apex.ai</span></a><span style="color:#000000"> 和 Zettascale，銀牌成員 Clearpath Robotics、Ekumen、eProsima 和 PickNik，以及準成員 Silicon Valley Robotics。首批支持組織包括 Canonical 和 Open Navigation。即將加入的成員包括 Bosch 和 ROS-Industrial，後續還計劃進一步公佈其他成員名單。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283872/nvidia-qualcomm-open-source-robotics-alliance</guid>
            <link>https://www.oschina.net/news/283872/nvidia-qualcomm-open-source-robotics-alliance</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[三星宣佈「AI for All」企業發展願景]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 三星家電新品發佈會 3 月 17 日舉行，發佈了全新的 MICRO LED、Neo QLED 8K/4K 系列、OLED 系列、Lifestyle 藝術電視及 BESPOKE 繽色鉑格系列等全系生態產品。</p><p>此外，三星宣佈「AI for All」的企業發展願景，三星電子大中華區總裁崔勝植表示，「三星正在將 AI 融入到我們的互聯技術，從移動設備上的 Galaxy AI，到顛覆性的顯示技術，再到通過智能家電改善的智能家居，致力於為用户帶來切實利益。」</p><p><img height="334" src="https://oscimg.oschina.net/oscnet/up-3ddacc315c81554f395aa1ff93439e7ec09.png" width="500" referrerpolicy="no-referrer"></p><p>多年來，三星一直在 AI 領域進行戰略投資，NQ8 AI Gen3 芯片就是成果之一，其神經處理單元（NPU）的速度是其前代產品的兩倍，神經網絡的數量也由 64 個增至 512 個。在該款 AI 芯片的加持下，三星 Neo QLED 8K 系列開啓了三星 AI 電視新紀元。</p><p>該公司預計 2024 年的銷量將恢復到 2022 年的水平，在未來 2-3 年內重新奪回全球芯片領先的位置，將在所有設備中採用人工智能，並積極開拓新業務。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 02:39:46 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283862</guid>
            <link>https://www.oschina.net/news/283862</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[走近 AI Infra 架構師：在高速飛馳的大模型 「賽車」 上 「換輪子」 的人]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>如果把大模型訓練比作 F1 比賽，長凡所在的團隊就是造車的人，也是在比賽現場給賽車換輪子的人。1% 的訓練提速，或者幾秒之差的故障恢復時間，累積起來，都能影響到幾百萬的成本。長凡説：「大模型起來的時候，我們非常興奮，因為 DLRover 天生就是為大模型訓練的場景設計的。」</p><p>目前業界普遍認為數據、算力、算法是大模型訓練的三大核心要素，AI 工程的價值似乎還沒有得到足夠的重視，我們和螞蟻 DLRover 開源負責人長凡深入聊了聊，聊到了他為何在大模型出現前就選擇了 AI Infra 的賽道，他參與開源的經歷，也聊了 DLRover 誕生背後的故事。</p><h1>AI Infra+開源， 一個通信畢業生的非主流選擇</h1><p>畢業於盛產程序員的北京郵電大學，雖然本科和研究生專業都是通信相關的，但長凡還是機緣巧合邁入了 AI 的大門，如果你也走在職業發展的路口，或許長凡的故事也能給你帶來啓發。</p><p><strong>Q：首先請介紹下自己，為什麼會選擇在螞蟻做 AI Infra 方面的工作？</strong></p><p><strong>長凡：</strong> 我本科在北交大的理科實驗班，研究生在北郵做 5G 移動通信的研究。大四的時候，我去了中國移動研究院實習，做機器學習在醫療領域的應用探索，算是入門了大數據和機器學習。我自己對概率統計和編程也比較感興趣，發現自己所學的知識可以解決真實問題了。後來在研究生期間，課餘時間會打打 Kaggle 比賽，邊實踐邊學習。</p><p>畢業之前我來螞蟻做暑期實習，做 ML Infra 相關的項目。相比打 Kaggle 用算法解決具體業務問題，Infra 的工作能幫助更多的同學來用 ML 解決更多的問題。再加上螞蟻在大力發展 AI，我所在的螞蟻人工智能部有很多 AI 方向的資深技術大拿，所以我畢業後選擇了留在螞蟻。</p><p>ChatGPT 出來後，大模型一下子火了，大模型相比之前的 AI 訓練對 Infra 的需求要高得多，對我們做 Infra 的是一個非常大的機遇。大模型訓練和推理的成本非常高，Infra 在提升效率和降低成本上大有可為。</p><p><strong>Q：是什麼契機讓你開始參與開源的？參與開源對你的職業道路產生了哪些影響？</strong></p><p><strong>長凡：</strong> 在螞蟻工作一年後，我加入到 ElasticDL 團隊，跟着王益老師（原百度 <a href="https://www.oschina.net/action/visit/ad?id=1185" title="PaddlePaddle">PaddlePaddle</a> 技術負責人）一起做開源項目。在開發 ElasticDL 過程中，王益老師教會了我很多開源思想、開源工作方式和開發習慣。比如新功能需要先寫設計文檔，然後拆解成 issue，最後是開發測試；PR 要儘量小，小 PR 可以降低 Review 成本；代碼質量需要有工具來保障等等。</p><p>這段經歷對我現在做 DLRover 幫助很大。在 DLRover 項目剛啓動時，我就在代碼倉庫了設置了很多代碼質量相關的檢測，比如 DLRover 的代碼 CI 覆蓋率約 80%。後來，張科老師接手帶領 ElasticDL，一直給我們強調開放合作。這也使得我在主導 DLRover 的開源過程中對架構設計更加開放。這裏説的開放不僅僅指使開源的開放代碼，更多的是指我們的架構和接口設計的開放，以便讓更多的人能進來擴展相關功能滿足各自的業務需求。比如，我們的故障機檢測功能當前支持 NVIDIA GPU 和 Ascend NPU，如果用户在其他的芯片上訓練，可以自定義檢測腳本。</p><p><strong>Q：隨着大模型的興起，許多技術人也感受到了前所未有的挑戰。作為</strong><strong>AI Infra 領域的架構師</strong><strong>，你如何評估大型模型或 AI 對傳統技術架構師的影響？針對當前的技術趨勢，你對於這些架構師有哪些建議？</strong></p><p><strong>長凡：</strong> 大模型或者 AI 將會改變我們的產品形態和業務模式，而且很多創新可能都是當前看不到或者很難預料的。作為技術架構師，我們的目標其實很簡單，利用技術幫助業務發展。我覺得最好的方式就是從業務中來，到業務中去。比如我們做 AI Infra 的，經常和訓練算法同學一起盯着訓練作業，review 訓練代碼並分析訓練性能，這樣從中發現很多訓練對 Infra 的實際需求。然後將這些需求抽象出來，利用自己的技術經驗來設計項目解決業務問題。</p><p>隨着大模型技術的發展，不管是對計算、存儲等硬件領域，還是對訓練框架、分佈式系統等軟件領域，對於 AI Infra 的架構師都有非常大的需求。如果想從事 AI Infra 領域，可以結合自前的經驗深入到 AI 應用中去，一定能做出成果。</p><h1>DLRover：發展靠機遇，持續發展靠技術判斷力</h1><p>時間拉回到 2022 年 9 月，DLRover 剛剛開源，那時深度學習的訓練基本都是在單機多卡上完成的，作為一個分佈式訓練的智能調度系統，DLRover 的功能似乎有些過於強大，就好像開了一輛百米加速的超跑來上下班。</p><p>DLRover 的容錯和彈性擴縮容在單機多卡的訓練上幾乎沒有用武之地，團隊也很迷茫是否要針對 GPU 訓練做優化，所以當 2022 年底，ChatGPT 在全球引起廣泛關注的的時候，大規模分佈式訓練是大模型訓練的剛需，長凡一下子就興奮了。</p><p><strong>Q：DLRover 是如何誕生的？發展歷程中有哪些關鍵的轉折點或者故事？</strong></p><p><strong>長凡：</strong> DLRover 脱胎於螞蟻內部的一個項目，主要利用容錯和彈性擴縮容來提升搜推廣訓練的速度和資源利用率。2022 年 7 月，該功能上線後，集羣資源利用率提升了快一倍，訓練時間也縮短了約 20%。基於自動擴縮容，我們就想讓用户只寫模型代碼，系統能自動地將模型在集羣上高效、穩定地和經濟地訓練出來，從而大幅降低分佈式訓練的門檻和運維成本。基於這個願景，我們在 2023 年 3 月開源了項目，並取名 DLRover，Rover 代表火星車，我們把 DL 訓練作為火星車的乘客，DLRover 這個火星車的目的就是快速、穩定、節能地將 DL 訓練這位乘客送到目的地，即訓練出模型。</p><p>DLRover 剛開源的時候，發佈了 CPU 集羣上 TensorFlow 異步分佈式訓練的自動資源配置與自動擴縮容，該功能可以將算法工程師從作業資源調優上解脱出來。但是發佈後社區反響一般，主要原因是搜推廣的訓練已經比較成熟了，業界也主要在關注 GPU 訓練。為此，我們內部也在討論要不要在 GPU 訓練上做點東西。但那時 GPU 訓練主要還是 CV 和 NLP 領域，以單機多卡為主，DLRover 的容錯和彈性擴縮容好像在單機多卡 GPU 訓練上沒有用武之地。</p><p>正在我們迷茫時，2023 年初大模型火了。因為 GPU 本身的故障率較高，大規模訓練經常因為故障而中斷，嚴重影響了大模型訓練的進度和集羣的利用率。所以 DLRover 在 2023 年的重點方向就是降低故障對訓練的影響。後來，DLRover 針對大規模分佈式訓練的場景，發佈了故障自愈功能，該功能吸引了很多大模型訓練的同學，也吸引了很多國產 AI 芯片的公司的關注。</p><p><strong>Q：DLRover 為什麼選擇開源？</strong></p><p><strong>長凡：</strong> DLRover 面向的用户主要使用的是開源技術，比如 TensorFlow 和 PyTorch 等訓練框架，Kubernetes 和 Ray 等分佈式集羣調度系統。開源可以讓我們接觸到領域裏更多的同行，擴寬我們的視野。當前很多公司都在做 AI 訓練，大家面臨的場景和問題可能都不一樣。通過開源交流，我們可以對 AI 訓練所面臨的問題與挑戰有更全面的瞭解，社區提出來的問題，未來我們也可能會遇到。我們希望 DLRover 不僅能滿足螞蟻內部大模型訓練的需求，也能滿足整個社區的普遍需求。</p><p><strong>Q：如果內部需求和社區需求不一致怎麼辦？</strong></p><p><strong>長凡：</strong> 這其實是開源項目經常會遇到的問題，我覺得首先要有技術判斷力，判斷這個需求是不是一個普遍需求，公司未來是不是也可能用得到。比如，以前我們認為跑大模型訓練大多都用英偉達的 GPU 卡，但現在社區開始提出希望我們適配國產芯片的需求，很多國產芯片的公司也來找我們交流，也就是很多人已經開始在國產芯片上去跑訓練了，這就是對我認知的一個刷新。如果我們未來買不到 GPU 了，或者國產芯片能達到更好的效果了，我們已經提前做了國產芯片的支持，那這個需求就可以直接上了。</p><p>現在很多流行的開源項目，以前 Star 數可能是線性增長，在大模型出來之後是指數增長。就是因為他們兩年前就覺得這個事情是一個正確的方向，堅持在做，然後機遇一來，他們就起來了。</p><hr><p><strong>Q：開源社區在 DLRover 的發展過程中扮演着怎樣的角色？有沒有一些特別令你印象深刻的社區貢獻者或者故事？</strong></p><p><strong>長凡：</strong> 開源社區給 DLRover 貢獻了很多非常好的思路和有價值的需求。比如 DLRover 的 Flash Checkpoint 功能發佈後，社區同學的試用幫我們發現了一些沒有測試的 corner case，這幫助我們提高了 DLRover 的產品質量。還有，我們最近吸引了很多國產 AI 芯片公司的關注，社區也提出將我們的訓練故障自愈擴展到國產芯片的意願，這些都是來自一線從業同學的真實聲音，是我們發展 DLRover 的寶貴源泉和動力。</p><h1>未來展望：幫助用户高效、穩定地訓練模型</h1><p>提到對項目未來的規劃時，長凡説：「我們希望 DLRover 能幫助用户解決問題，高效、穩定地訓練模型。」也希望有更多對 AI 工程感興趣的開發者能加入到 DLRover 項目，一起推進 AI Infra 領域的發展。</p><p><strong>Q：目前還有哪些項目也在做類似的事情嗎？和 DLRover 相比有什麼不同？</strong></p><p><strong>長凡：</strong> 分佈式訓練的彈性容錯一直是開源社區在探索的，比如 TorchElastic 和 Elastic Horovod 解決了訓練框架的彈性與容錯。大模型出來之前，大家訓練 NLP 或者 CV 模型主要還是單機或者小規模的集羣。小規模訓練因為使用的節點少，故障率較低，對彈性容錯需求不大。大模型訓練一下將訓練規模擴大到幾百上千卡，故障率就高了很多。同時實際訓練中，訓練容錯和故障自愈需要集羣調度、節點管理和訓練框架一起協作。所以 DLRover 是將現有的彈性訓練框架與節點管理、集羣調度相結合來實現快速的訓練故障自愈。</p><p>訓練自愈這塊其實很多雲廠商也在做，但是都是和自己的雲平台耦合的。最近幾個月也有好幾篇定會文章介紹相關工作。DLRover 是和雲平台解耦的，用户只要是在 kubernetes 集羣上做分佈式訓練，就可以使用 DLRover 的訓練故障自愈功能。除此之外，由於我們之前在這塊有過探索和積累，所以訓練穩定性這塊的功能開源得比較快。</p><hr><p><strong>Q：在 AI Infra 領域，海外有哪些做得比較好的開源項目，對於我們有哪些借鑑意義？</strong></p><p><strong>長凡：</strong> Flash Attention 和 vllm，這兩個框架大幅提升了大模型訓練和推理的性能，更重要的是，用户只需要安裝 Python 包即可使用。他們的特點就是利用創新解決了一個很難且很有價值的問題，但是又非常簡單易用，這對我們有很大啓發。比如，我們在設計 DLRover 訓練自愈的 Flash Checkpoint 的 API 時，也是儘量讓 API 簡單易用，用户儘量少改代碼就能使用 DLRover。</p><p><strong>Q：對於 DLRover 未來的規劃，你有什麼願景或目標？</strong></p><p><strong>長凡：</strong> 我們希望 DLRover 在大模型時代能讓更多的用户高效地訓練大模型，降低 AI 訓練門檻。當前 AI 訓練有 2 個趨勢，一方面大家根據 Scaling law 來使用更大規模的集羣，來訓練越來越大的模型；另一方面很多工作在探索如何在小規模或者單機上微調模型。</p><p>不管是大規模預訓練還是微調，高效、穩定地訓練模型都有困難，需要根據經驗反覆調試。我們希望 DLRover 能幫助用户解決這方面的問題，也希望能支持到國內的 AI 發展。DLRover 未來在功能和接口設計上會做得更加開放，讓用户能在國產芯片上使用 DLRover 高效、穩定地訓練模型。當然，我們也非常歡迎更多的同學加入到 DLRover 社區，一起推進 AI Infra 的前進。</p><p><strong>Q：最後，給我們預告下你在 GDC 上會分享哪些內容吧</strong></p><p><strong>長凡：</strong> GDC 上我將分享 DLRover 如何通過訓練故障自愈，來降低大規模 AI 訓練的成本，幫訓練省錢的。以及大家如何來使用 DLRover 來提升訓練的效率。</p><hr><p>看完長凡的經歷和 DLRover 的故事，你是不是對 AI Infra 有了更多興趣呢？3 月 23 日下午，長凡將在 2024 全球開發者先鋒大會 (GDC) 分享《DLRover 訓練故障自愈：大幅提升大規模 AI 訓練的算力效率》，歡迎到現場和講師近距離交流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dc4d134f36c97587b51d09fd3639c34817e.png" alt="" referrerpolicy="no-referrer"></p><p>關於 DLRover</p><p>DLRover（Distributed Deep Learning System）是螞蟻集團 AI Infra 團隊維護的開源社區，是基於雲原生技術打造的智能分佈式深度學習系統。DLRover 使得開發人員能夠專注於模型架構的設計，而無需處理任何工程方面的細節，例如硬件加速和分佈式運行等；開發深度學習訓練的相關算法，讓訓練更高效、智能，例如優化器。目前，DLRover 支持使用 K8s、Ray 進行自動化操作和維護深度學習訓練任務。更多 AI Infra 技術請關注 DLRover 項目。</p><p>加入 DLRover 釘釘技術交流羣：31525020959</p><p>DLRover Star 一下：<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintelligent-machine-learning%2Fdlrover" target="_blank">https://github.com/intelligent-machine-learning/dlrover</a></em></p><p>在&nbsp;GitHub&nbsp;關注&nbsp;DLRover：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintelligent-machine-learning%2Fdlrover" target="_blank">https://github.com/intelligent-machine-learning/dlrover</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 02:28:21 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/7032067/blog/11048088</guid>
            <link>https://my.oschina.net/u/7032067/blog/11048088</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[20 年編程，AI 編程 6 個月，關於 Copliot 輔助編碼工具，你想知道的都在這裏]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>AI 代碼輔助工具</span></span></span></h1><p><span><span><strong><span>嘗試各種輔助編程的 AI 工具</span></strong></span></span></p><p><span><span><span>筆者是一個後端 Coder~，開發工具使用 Idea 和 VsCode。在過去我一直嘗試找到一款適合自己的智能代碼輔助工具，來告別繁瑣的重複性編碼，好提高開發效率。直到 AIGC 和 AI Agent 的迅速發展，越來越多的 AI 編碼輔助工具百花齊放。宣告天下-生成式編碼新賽道的來臨。於是開始使用</span></span></span><span><span><strong><span>Github Coplilot、Bito、</span></strong></span></span><span><span><strong><span>Duet AI、CodeWhisperer、</span></strong></span></span><span><span><strong><span>通義靈碼/螞蟻百靈、</span></strong></span></span><span><span><strong><span>Comate、CodeGeeX2 </span></strong></span></span><span><span><span>等不下 10 種的工具。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>AI 生成工具總結：</span></strong></span></span></p><div><table style="width:auto"><tbody><tr><th><span><span><span>產品</span></span></span></th><th><span><span><span>版本</span></span></span></th><th><span><span><span>功能</span></span></span></th><th><span><span><span style="background-color:#ffffff; color:#000000">費用</span></span></span></th><th><span><span><span>鏈接</span></span></span></th><th><span><span><span>總結</span></span></span></th></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（微軟) GitHub Copilot</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">個人/企業</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.代碼補全 2.根據註釋生成代碼 3.創建 SQL 查詢 3.代碼優化 4.問答 5.單元測試</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">個人版每月$10 企業版每月$19</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.github.com%2Fzh%2Fcopilot%2Fusing-github-copilot%2Fgetting-started-with-github-copilot" target="_blank" rel="nofollow"><span><span><span>官網</span></span></span></a></td><td><span><span><span style="background-color:#ffffff; color:#000000">業界排名第一，最新版代碼補全能力遙遙領先，使用</span></span></span><span><span><strong><span>Open AI 的大模型用 Github 庫來訓練。新版 chat 是 GPT-3.5</span></strong></span></span><span><span><span style="background-color:#ffffff; color:#000000">。只要網絡允許絕對首選。 根據 github 統計，96% 的人研發認為可以快速完成重複工作，80% 的研發認為可以提高工作效率。</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（google）Duet AI</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">企業版</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.生成代碼 2.生成單測 3.</span></span></span><span><span><span>回答有關 Google Cloud 產品的問題。</span></span></span><span><span><span style="background-color:#ffffff; color:#000000"> 4.代碼優化 5.對錯誤消息進行問題排查</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">每月 $19</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fduet-ai%3F_gl%3D1*keo78j*_up*MQ..%26gclid%3DCjwKCAiA_OetBhAtEiwAPTeQZ_hhyKrqF62wIqOXFSYhnVozDRPiAsvCrE0v66hAeB798nyj9B7VNhoCQ0wQAvD_BwE%26gclsrc%3Daw.ds%26hl%3Dzh-cn%23pricing" target="_blank" rel="nofollow"><span><span><span>官網</span></span></span></a></td><td><span><span><span style="background-color:#ffffff; color:#000000">UE 和響應速度很好，內置的 chat 是 gemini pro。免費用 30 次。 集成了 Google Cloud 和 k8 還有熱部署。 bug 的提示修復很厲害。 支持 AI SQL（BigQuery 收費）。有自己的日誌中心和 CI/CD。 最厲害的是推出的</span></span></span><span><span><strong><span>AI 告警，和 AI 日誌分析</span></strong></span></span><span><span><span style="background-color:#ffffff; color:#000000">。幫助定位和發現生產環境出現的問題。傳説內部的 Goose 已經學會 google 技術架構。</span></span></span></td></tr><tr><td><span><span><span>Bito</span></span></span></td><td><span><span><span>免費/收費</span></span></span></td><td><span><span><span>1.生成代碼 2.生成單測 3.問答 4.代碼優化 5.代碼解釋 6.代碼檢查</span></span></span></td><td><span><span><span>收費$15</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbito.ai%2F" target="_blank" rel="nofollow"><span><span><span>官網</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span>號稱提高 10 倍開發效率。體感生成速度確實快。 Bito 利用來自 </span></span></span><span><span><strong><span>Open AI、Anthropic </span></strong></span></span><span><span><span>等公司的大模型。（可以理解他用了 GPT 和 Claude 大模型） 亮點是 CodeView 功能。利用 AI agent 實現的。 免費版是 GPT-3.5 Turbo 或谷歌</span></span></span><span><span><span style="background-color:#ffffff; color:#121926">Chat-bison</span></span></span><span><span><span>，chat 和代碼補全有限制。付費是 GPT-4 每月 400 個請求。 </span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（AWS）CodeWhisperer</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">個人/企業</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.生成代碼 2.生成單測 3.代碼安全檢查 4.問答</span></span></span></td><td><span><span><span>個人免費，企業版每月$19</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fcodewhisperer%2F" target="_blank" rel="nofollow"><span><span><span>官網</span></span></span></a></td><td><span><span><span style="background-color:#ffffff; color:#000000">UE 工具欄在左側，內置了 chat，不支持中文。 號稱提高</span></span></span><span><span><span>開發</span></span></span><span><span><span style="background-color:#ffffff; color:#000000">速度 28% 代碼補全精準度很好，沒有廢代碼。 可以根據中文註釋生成，聯繫上下文寫出定義方法。 最 nb 的功能</span></span></span><span><span><strong><span>代碼安全檢查</span></strong></span></span><span><span><span style="background-color:#ffffff; color:#000000">，免費版每月 50 次，企業版每月 500 次</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（阿里）CodeFuse(螞蟻百靈) 和通義靈碼</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">個人</span></span></span></td><td><span><span><span>1.生成代碼 2.生成單測 3.問答 4.代碼優化 5.代碼解釋 6.代碼檢查</span></span></span></td><td><span><span><span>免費</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftongyi.aliyun.com%2F" target="_blank" rel="nofollow"><span><span><span>通義靈碼</span></span></span></a><span><span><span> / </span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodefuse.alipay.com%2F" target="_blank" rel="nofollow"><span><span><span>螞蟻百靈</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">阿里通義大模型套件。通義靈碼來自阿里雲，Codefuse 來自螞蟻集團。 通義靈碼基於通義大模型提供行級/函數級實時續寫、自然語言生成代碼。 Codefuse 基於開源的 DeepSeek 的 33b 模型二開的產品。目前內測中。 通義靈碼的配置比較豐富，可以根據使用習慣來定製，補全長度、方式輔助功能等。 現階段使用上通義靈碼優於 Codefuse</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（百度）Comate</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">個人</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.生成代碼 2.代碼解釋 3.問答 4.代碼優化 5.生成單測</span></span></span></td><td><span><span><span>每月 60</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcomate.baidu.com%2F" target="_blank" rel="nofollow"><span><span><span>官網</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">代碼生成：代碼模塊存在缺失和不完善，如數據預處理未按要求處理。損失函數可視化部分缺失；代碼分段輸出、註釋清晰，首次執行結果： 按提示修改數據集文件地址後，執行第一步數據預處理報錯，順利執行 10% 場景能力：在單次對話中，上下文關聯差，多輪對話過程，未能很好結合上下文，後續提問回答，更像是單次提問的百科搜索回答。 其他：提問字數超出限制之後，胡亂輸出了我本地 ide 中的代碼文件</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（清華智譜）CodeGeeX2</span></span></span></td><td><span><span><span>開源</span></span></span></td><td><span><span><span>1.生成代碼 2.代碼解釋 3.問答 4.代碼優化</span></span></span></td><td><span><span><span>免費</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTHUDM%2FCodeGeeX2" target="_blank" rel="nofollow"><span><span><span>官網</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1、交互較差，補全代碼的時候經常補到一半 (到行甚至單詞的一部分就停了) 2、理解能力較差，代碼不正確 3、代碼轉換 (不同語言) 能力還可以 4、生成代碼接受率低，需要刪減</span></span></span></td></tr></tbody></table></div><p><span><span><span>最初我認為不會有太多地方用得上它們。因為大廠都有一套自己的技術體系和技術架構。外部的工具不可能學會，也不會讓他們去訓練自家的技術。所以我的定位是解決重複性編碼的工作。經過六個月的使用後，發現我使用 AI 的方式隨着時間的推移在不斷變化和改進。</span></span></span></p><p><span><span><span>首先在選擇工具時我有一個要求，那就是必須是基於</span></span></span><span><span><strong><span>GPT</span></strong></span></span><span><span><span>。因為在</span></span></span><span><span><span style="color:#333333">代碼生成基準測試中，</span></span></span><span><span><span>GPT</span></span></span><span><span><span style="color:#333333">絕對是搖搖領先。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-03-16-286A4dAOifUAQ27tVb.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><div><span><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-21-109DAAKkBqe6JnEij.png" referrerpolicy="no-referrer"></span></div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>當下和</span></span></span><span><span><strong><span>Open AI</span></strong></span></span><span><span><span>合作的名氣最大的是</span></span></span><span><span><strong><span>GitHub Copliot</span></strong></span></span><span><span><span>。GitHub Copliot 一直是業界的標杆！在代碼補全領域一直是行業第一。新版本也增加了 chat 功能，作為插件在 UE 上也下足了工服，生成單側，代碼優化，代碼解釋等主流功能一應俱全。一月 10$的價格也是可以接受。</span></span></span></p><p><span><span><span>同時對持學生證或者在 github 活躍項目的維護者提供永久免費。主打一個沉浸式編碼！最近也發佈了企業版。唯獨一點就是要科學上網才能有好的體驗。否則生成真的會很慢。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-03-16-38DtUyeZhqExFv09h.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>每每看到 Thinking...就會抓狂！那有沒有同樣是和 Open AI 合作，且沒有網絡限制的平替產品呢？ 答案是</span></span></span><span><span><strong><span>Bito</span></strong></span></span><span><span><span>。一個號稱提高 10 倍生產力！每天節約 1 小時的產品...</span></span></span></p><p><span><span><span>Bito 在用户本地部署矢量數據庫。該數據庫會嵌入了 1 萬個索引作。該矢量庫使用</span></span></span><span><span><span style="background-color:#ffffff; color:#191b1f">embedding（</span></span></span><span><span><span> 超過 1 萬個維度的向量</span></span></span><span><span><span style="background-color:#ffffff; color:#191b1f">）</span></span></span><span><span><span>。將代碼庫中檢索文本、函數名稱、對象等，轉換為多維向量空間存儲。</span></span></span></p><p><span><span><span>最後，Bito 利用來自 Open AI、Anthropic 的大模型，也就是説他可以用 GPT 或 Claude 模型。免費版的 chat 使用的 GPT-3.5 Turbo、或者 Google 的 chat-bison、Claude Instant。</span></span></span></p><p><span><span><span>如何安裝就不多説了，支持 Jetbrains 和 VsCode 平台。直接看他的功能吧！</span></span></span></p><p><span><span><span>﻿</span></span></span></p><span id="OSC_h1_2"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>Bito</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>1.代碼補全：</span></strong></span></span><span><span><span>被動觸發，默認快捷鍵是</span></span></span><span><span><strong><span></span></strong></span></span></p><p><span><span><span>macOS：Option + Shift + K</span></span></span></p><p><span><span><span>Windows：Alt + Shift + K</span></span></span></p><p><span><span><strong><span>2.解釋代碼：</span></strong></span></span><span><span><span>對於陌生語言很有用</span></span></span></p><p><span><span><span>macOS：Option + Shift + E</span></span></span></p><p><span><span><span>Windows：Alt + Shift + E</span></span></span></p><p><span><span><strong><span>3.生成註釋：</span></strong></span></span><span><span><span>生成的方法註釋，用的少</span></span></span></p><p><span><span><span>macOS：Option + Shift + V</span></span></span></p><p><span><span><span>Windows：Alt + Shift + V</span></span></span></p><p><span><span><strong><span>4.優化代碼：一般沒什麼用。</span></strong></span></span></p><p><span><span><span>macOS：Option + Shift + Q</span></span></span></p><p><span><span><span>Windows：Alt + Shift + Q</span></span></span></p><p><span><span><strong><span>5.安全檢查：</span></strong></span></span><span><span><span>這裏主要是找代碼漏洞</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-18-083rVVSsHSL3uAerO.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>快捷鍵 macOS：Option + Shift + Z</span></span></span></p><p><span><span><span>Windows：Alt + Shift + Z</span></span></span></p><p><span><span><strong><span>6.style 檢查：</span></strong></span></span><span><span><span>這裏的 style 是指代碼規範</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-18-07gxMX446tY0IFYnYp.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>快捷鍵 macOS：Option + Shift + U</span></span></span></p><p><span><span><span>Windows：Alt + Shift + U</span></span></span></p><p><span><span><strong><span>7.是生成單測</span></strong></span></span><span><span><span>。只能單個文件生成。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><span>我用的最多的是 chat，太絲滑了！其次才是代碼補全，</span></span></span><span><span><strong><span>看下代碼補全的使用場景</span></strong></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>重複性代碼補全：</span></strong></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-18-37hPLnRnb9pFelsJk.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><strong><span>正則表達式</span></strong></span></span><span><span><span>：</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://503886607-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FYgNBTrPKG0DuVdAyDvSa%2Fuploads%2FuSybqpcFilyfxEoxOA4e%2Fregex_2.gif?alt=media&amp;token=fee783fc-3729-4bf7-81dc-6f9abcfd4141" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>編寫 SQL：</span></strong></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://503886607-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FYgNBTrPKG0DuVdAyDvSa%2Fuploads%2FrDSpxXqZchp9wZDhgsm6%2Fsql_1.gif?alt=media&amp;token=39542188-bed6-4966-92c9-5d413c06ce98" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>﻿</span></span></span></p><p><span><span><span>在 mapper 可以自動補全 sql 的查詢條還能，還一種用法在 chat 裏面輸入表結構。讓 Bito 生成複雜 sql。</span></span></span></p><p><span><span><strong><span>生成實體：</span></strong></span></span><span><span><span>這裏不是生成 getter/setter 方法，而是實體賦值或者轉換。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-05-15-50bPtsgjBni0HrMyz.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span> 生成代碼場景</span></span></span></p><p><span><span><span>Bito 有個很好用的功能，可以自定義 Prompt 模版。我們可以把設計好的提示詞添加到模版裏用來生成想要的結果。比如定義</span></span></span><span><span><strong><span>sql 生成實體的 Prompt</span></strong></span></span><span><span><span>，定義</span></span></span><span><span><strong><span>生成 Web、RPC 接口的 Prompt</span></strong></span></span><span><span><span>等。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-06-19-42lZmVoelFDM7pKRu.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><div><span><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-06-19-4747s4735C6R47FqNGhRR.png" referrerpolicy="no-referrer"></span></div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><span id="OSC_h1_4"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span> 心流</span></span></span></p><p><span><span><strong><span>打造心流領域</span></strong></span></span></p><p><span><span><span style="color:#333333">我們用 AI 代碼輔助工具是為了提高我們的</span></span></span><span><span><strong><span>工作效率</span></strong></span></span><span><span><span style="color:#333333">，而不是靠他來生成業務代碼。生成業務代碼屬於「</span></span></span><span><span><span>實時的軟件生成」領域的</span></span></span><span><span><span style="color:#333333">（Prompt 編程+低代碼）。即使谷歌的 Goose 已經學會了自家的全部技術棧，也不能完全做到需求即交付。因為 AI 需要滲透到整個軟件生命週期裏，完全標準化後才能達到的預期效果。我理解的提效就是進入「心流」狀態。而 AI 輔助工具能幫我做到。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>打造個人的</span></strong></span></span><span><span><strong><span>Copliot</span></strong></span></span></p><p><span><span><span style="color:#333333">推薦組合：CodeFuse+Bito+豆包 </span></span></span></p><p><span><span><span style="color:#333333">結對編程組合：</span></span></span><span><span><span>GitHub Copliot 就很夠了！適合轉型新語言的開發者。</span></span></span></p><p><span><span><span style="color:#333333">打造沉浸式環境：JoyCoder（自家工具</span></span></span><span><span><span>）+Bito。完全輔助，可以徹底告別網絡搜索。期待自己家的 JoyCoder 的成長！</span></span></span></p><span id="OSC_h1_5"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>總結</span></span></span></p><p><span><span><span>完全可以提高 20% 的工作效率！如果對 P</span></span></span><span><span><span style="color:#333333">rompt 理解透徹、代碼模塊化思維能力夠強，</span></span></span><span><span><span>願意花時間調整工作流程的話，</span></span></span><span><span><span style="color:#333333">還會提高的更多！</span></span></span></p><p><span><span><span style="color:#333333">如果這篇文章帶給大家一些收穫，不妨點贊、收藏。下次會介紹更好玩的產品。</span></span></span></p><p><img height="396" src="https://oscimg.oschina.net/oscnet/up-1fe741836aaf93527c65cbe2a65e4ffa9ff.png" width="396" referrerpolicy="no-referrer"></p><p>&nbsp; &nbsp;掃一掃，與作者技術交流一下吧</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Mar 2024 09:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/11047919</guid>
            <link>https://my.oschina.net/u/4090830/blog/11047919</link>
            <author>
                <![CDATA[京東雲開發者]]>
            </author>
        </item>
    </channel>
</rss>
