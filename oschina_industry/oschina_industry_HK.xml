<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 27 Oct 2023 10:31:59 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[扎克伯克：Meta 明年投入更多工程和計算資源到 AI 領域]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>當地時間 10 月 25 日，在 2023 財年第三季度財報電話會上，Meta CEO 扎克伯格強調，相信生成式 AI 的相關技術將讓人們使用各種應用程序的方式變得更有意義。在未來，Meta 甚至有可能會利用 AI 來根據用户的興趣為他們直接生成內容。</p><p>扎克伯格表示，AI 將幫助使用 Meta 各大應用的創作者提升內容質量和生產效率，而隨着時間的推移，AI 參與生成的內容在用户消費內容中的佔比將會越來越大。</p><p>對於公司的後續發展，扎克伯格表示在 2024 年，<strong>就工程和計算資源而言，AI 將成為 Meta 最大的投資領域</strong>。此外，扎克伯格補充道，為了避免引入大量的新員工，<strong>公司將降低一些非 AI 項目的優先級，並將相關人員轉向從事 AI 工作</strong>。</p><p>上月曾報道過，<u><a href="https://www.oschina.net/news/257670/meta-building-llm-rival-openais-gpt4">Meta 正在構建</a></u>新開源大模型，據稱性能超越 Llama 2、比肩 GPT-4，最終目標是加速開發下一代生成式人工智能模型，使其能夠生成更多類似人類的表達。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0911/152426_g2gp_2720166.png" referrerpolicy="no-referrer"></p><p>長期以來，Meta 一直在採用開源方法公開其大模型產品，是業內眾所周知的最大貢獻者之一。僅今年它就向人工智能社區發佈了大量人工智能模型和訓練數據集。其中包括針對編程任務優化的 Code Llama 大語言模型； 可實現數百種語言通用按需翻譯的 SeamlessM4T 模型； 用於創作音樂和聲音的生成式人工智能模型 AudioCraft；語音生成人工智能模型 Voicebox。它還推出了 I-JEPA（一種可以像人類一樣學習的計算機視覺模型）和 FACET（一種基準數據集，旨在幫助研究人員審核計算機視覺模型的偏差）。</p><hr><p>延伸閲讀</p><ul><li><a href="https://www.oschina.net/news/256830/meta-ai-belebele">Meta AI 多語言閲讀理解數據集 Belebele，涵蓋 122 種語言變體</a></li><li><a href="https://www.oschina.net/news/255350/meta-code-llama">Meta 開源基於 Llama 2 的 AI 代碼生成大模型：Code Llama</a></li><li><a href="https://www.oschina.net/news/255168/meta-seamless-m4t">Meta 推出&nbsp;SeamlessM4T，可轉錄和翻譯近 100 種語言</a></li><li><a href="https://www.oschina.net/news/252174/audiocraft-generative-ai-for-music-and-audio">Meta 發佈開源 AI 工具 AudioCraft，文本自動生成音樂</a></li><li><a href="https://www.oschina.net/news/249944/meta-llama-2">Meta 放大招：發佈開源大語言模型 Llama 2，可免費商用</a></li><li><a href="https://www.oschina.net/news/245895/meta-voicebox-generative-ai-model-speech">Meta 發佈語音生成 AI 模型：Voicebox</a></li><li><a href="https://www.oschina.net/news/245705/meta-musicgen">Meta 開源音樂生成模型 MusicGen</a></li><li><a href="https://www.oschina.net/news/242331/mate-multilingual-model-speech">Meta 開源大模型：支持 4000+ 語言識別，1100+ 種語音文本轉換</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 09:36:23 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263757</guid>
            <link>https://www.oschina.net/news/263757</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 24.04 進入開發階段，代號 Noble Numbat]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">Canonical 的 Utkarsh Gupta 在一封發送給 Ubuntu 開發郵件列表的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.ubuntu.com%2Farchives%2Fubuntu-devel%2F2023-October%2F042835.html" target="_blank">電子郵件中宣佈</a>，Ubuntu 24.04 現已開放供開發，並透露了該版本的代號為「Noble Numbat」。</span></p><blockquote><p><span style="color:#000000">我們很高興地宣佈，Noble Numbat 現已開放開發。自動同步已啓用，並將很快運行。和往常一樣，我們預計在初始階段會有大量的構建和自動測試湧入，這將導致一些延遲現象的出現。請協助修復出現的任何故障。</span></p></blockquote><p><span style="color:#000000">根據百度百科，Numbat（袋食蟻獸）是分佈於澳大利亞西南部的一種小型有袋動物，幾乎只以白蟻為食，每天可以吃約 20000 只白蟻。目前僅在少數地區存活，屬於瀕危物種，已被列入《世界自然保護聯盟瀕危物種紅色名錄》。袋食蟻獸的體型小而吻長，牙齒多達 52 枚，超過任何陸生哺乳動物的齒數，齒細，排成長列，長而能伸的舌（長約 10 釐米），用以捕捉白蟻。</span></p><p><span style="color:#000000"><img alt="" height="286" src="https://oscimg.oschina.net/oscnet/up-050f5f99cc77c3757686112b409fb2558f7.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Ubuntu 24.04 將是 Ubuntu 自 2006 年以來的第 10 個 LTS 版本。Ubuntu 的 LTS 版本將獲得 5 年的安全更新、錯誤修復和精選應用程序更新。Ubuntu Pro 則會在此基礎上額外增加 5 年的安全保障，為現代的 LTS 版本提供了長達十年的支持。</span></p><p><span style="color:#000000">目前對於 Ubuntu 24.04 中將包含的新功能和改進仍然知之甚少。但 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F10%2Fubuntu-24-04-development-open" target="_blank">OMG! Ubuntu</a> 指出，對於長期支持版本而言，Ubuntu 在主要新功能、用户界面的巨大變化等方面往往會比較保守，主要會更加專注于堅實、穩定的體驗。</span></p><p><span style="color:#000000">可以確定的是，24.04 肯定會配備新的 Linux 內核（6.7 或 6.8，視時間而定）、GNOME 46（預計將在三月份發佈）。Canonical 的 Oliver Grawert 還透露，一個不可變的、snap-based Ubuntu 24.04 鏡像將於 4 月份提供下載（但不會是默認推薦下載）。</span></p><p><span style="color:#000000">Ubuntu 24.04 計劃於 2024 年 4 月 25 日正式發佈。其功能凍結階段定於 2024 年 2 月 29 日，beta 版本計劃於 2024 年 4 月 4 日發佈。</span></p><p><img height="501" src="https://oscimg.oschina.net/oscnet/up-78523d04d02ccf21bda56aa13e0dcd0b317.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">可在此查看具體的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fnoble-numbat-release-schedule%2F35649" target="_blank">發佈時間表</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 09:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263754/ubuntu-24-04-noble-numbat</guid>
            <link>https://www.oschina.net/news/263754/ubuntu-24-04-noble-numbat</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[3202 年了，為啥 SSR 並沒有預想中的流行？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div><p style="text-align:left">有研究發現，網站加載時間每增加一秒，用户便會流失 10%。為提高頁面的秒開率，各路人馬不斷探索着優化策略，僅僅在瀏覽器領域下的優化已經滿足不了極致的要求了，大家開始往服務端方向不斷探索，並一度讓【服務端渲染】這一古早的概念「翻紅」，且炒得火熱。</p><p>服務端渲染簡稱 SSR，全稱 Server Side Rendering，顧名思義是將渲染的工作放在 Server 端進行。這種辦法不僅有利於首屏渲染，提高 SPA 應用的首屏響應速度，還方便搜索引擎抓取，有利於 SEO 優化。不過，到 2023 年了，SSR 並沒有預想中的流行。</p><p>有評論認為，大部分用 SSR 的原因是為了服務 SEO，但現在搜索引擎已經跟上發展步伐了，對於用框架寫成的 SPA 支持也不錯，所以 SSR 必要性沒那麼大了。還有人覺得 SSR 就是偽需求，業務邏輯和控制器分離好了加載一樣快。</p><p>但也有評論認為，現在仍然有大量的用户因為網絡環境或設備情況，在訪問 Web 頁面的時候無法達到很好的體驗，如果要提升這部分用户的體驗，那麼 SSR 就是一種不可或缺的方式。</p><p style="text-align:left">對此，真實的情況是怎樣的？實際應用中，阻礙 SSR 成為 Web 主流開發模式的原因是什麼？這種方法放到今天的環境下過時了嗎？什麼樣的業務場景更適合 SSR 呢？對此，開源中國邀請了兩位前端大佬，來聽聽他們的看法。</p><ul><li><p><span style="color:#245bdb">劉奎，社區暱稱 kuitos 。支付寶體驗技術部前端工程師，開源微前端方案 qiankun 作者，目前在螞蟻負責 Web 基建研發相關工作。</span></p></li><li><p><span style="color:#245bdb">劉勇，社區暱稱天豬，某大廠 Node.js </span><span style="color:#245bdb">Infra</span><span style="color:#245bdb"> 負責人，EggJS / CNPM 核心開發者。</span></p></li></ul><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>一、SSR，並不是偽需求</h1><p><span style="color:#245bdb"><strong>Q1：以你的經驗，什麼類型的項目和場景更常用 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> ？能舉些例子嗎？</strong></span></p><p><strong>劉奎：</strong>對首屏性能非常敏感，或者對 SEO 有強訴求的這類網站會更常用 SSR，如：</p><ul><li><p>電商平台：更快的首屏渲染可以讓用户更快的看到商品信息，提升購買轉化率</p></li><li><p>營銷活動頁：秒開能有效提升營銷活動的業務效果</p></li><li><p>門户網站：內容型站點通常對 SEO 有着比較強的訴求</p></li></ul><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q2：從你的實際體驗出發，你覺得 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 相比於 </strong></span><span style="color:#245bdb"><strong>CSR</strong></span><span style="color:#245bdb"><strong>（</strong></span><span style="color:#245bdb"><strong>Client-side rendering</strong></span><span style="color:#245bdb"><strong>）模式，優勢在哪？</strong></span></p><p><strong>劉奎：</strong>從我個人體驗來看，最大的優勢還是在首屏體驗上，SSR 模式下 HTML 加載過程中用户就能看到有效的頁面內容，這個基本是 CSR 很難做到的。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q3：如今</strong></span><span style="color:#245bdb"><strong>搜索引擎</strong></span><span style="color:#245bdb"><strong>已經支持渲染了，你認為還有必要因為 </strong></span><span style="color:#245bdb"><strong>SEO</strong></span><span style="color:#245bdb"><strong> 的原因使用 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 嗎？</strong></span></p><p><strong>劉奎：</strong>由於眾所周知的原因，國內的搜索引擎對 SPA 類型的應用支持的並不好，如果希望自己的網站能更好的被爬蟲索引到，基本上還是需要使用 SSR（或者 SSR 的變種）方案了。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q4：有人認為 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 是偽需求，要改善首屏渲染性能的話，後端服務的業務邏輯和控制器分離，控制器分視圖控制器和接口控制器，調用相同的業務邏輯。第一次打開頁面，前端 </strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong> 加載頁面渲染的數據，用户交互時再請求接口獲取數據。這個方案比性能着急的 SSR 強多了。你怎麼評價？</strong></span></p><p><strong>劉奎：</strong>這個方案本質還是 CSR，無法解決 CSR 方案原生的問題：即用户必須等到 JS 下載完成 -&gt; 發起接口請求 -&gt; JS 獲取數據渲染頁面之後，才能看到有效內容的問題。在越苛刻的網絡環境及用户設備條件下，這個問題會越明顯。</p><p><strong>劉勇：</strong>根據團隊的基建成熟度和業務場景做技術選型，這 2 個方案沒有絕對的優劣，也不是絕對的割裂，它們是可以通過前端工程化結合成一個方案的。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>二、SSR，想紅有點難</h1><p><span style="color:#245bdb"><strong>Q5：以當前的形勢來看，</strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 並沒能成為 Web 主流的開發模式，你覺得這其中的阻礙有哪些？</strong></span></p><p><strong>劉奎：</strong>我覺得主要有這幾類原因：</p><ul><li><p><strong>技術複雜度：</strong>SSR 需要在服務器端進行渲染，並與前端框架進行集成，對開發人員來説需要掌握更多的技術知識。</p></li><li><p><strong>SSR</strong><strong> 帶來的額外的開發及維護成本：</strong>相對於 CSR，SSR 方案需要前端額外去關注服務端相關的開發及運維，比如如何寫出更高性能的服務端渲染邏輯，如何處理潛在的內存泄露、變量污染等隔離問題，如何做 SSR 的容災（在 SSR 失敗時 fallback 到 CSR）等，這些都需要團隊有額外的資源及時間投入。</p></li><li><p><strong>場景匹配度：</strong>國內大量的服務是通過小程序、APP 這類載體進行分發的，純 Web 技術棧的產品相對較少，這點與國外的場景有着非常大的不同。</p></li></ul><p><strong>劉勇：</strong>首先，SSR 是需要服務器資源成本的，在降本提效的大背景下，會需要結合 Serverless 或邊緣計算等一些基建才能找到平衡點。同時既然是服務端，就有一定的運維能力要求，對前端團隊的技術積累有一定的要求。</p><p>其次，框架的封裝和維護如果做的不好的話，業務同學寫 SSR 很容易弄出內存泄露問題，這是非常常見的。而且目前的前端框架還沒有針對 SSR 場景進行優化，如果只是首屏展示快，但緊接着要下載超大的 Bundle 文件，從而用户可交互時間太慢，就得不償失了。</p><p>最後，演進路徑問題，譬如螞蟻那邊，他們當年就已經跟把離線包的上下游基建都做的很完善了，APP 側、網絡側都有兄弟團隊配合一起打磨。這種模式會有一些缺陷，如離線包太多時的業務競爭問題，但就首屏性能這一點上，SSR 不一定比它好多少，這時候讓他們切換到 SSR 就會有不小的阻力。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q6：有評論認為 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 開發和維護成本太高了，轉而投向了 </strong></span><span style="color:#245bdb"><strong>CSR</strong></span><span style="color:#245bdb"><strong> 的懷抱。CSR 能否取得跟 SSR 一樣的效果呢？有什麼具體的操作方案嗎？</strong></span></p><p><strong>劉勇：</strong>從首屏性能的關鍵點看，CSR 如果不做一定的優化的話，至少 3 次串行的 HTTP 請求，首屏時間肯定比不過 SSR（互操作時間就不一定）。</p><p>不過相應的解決方案也挺多的，如 ServiceWorker、離線包等等方式。</p><p><strong>劉奎：</strong>單從首屏渲染速度這一點來看，CSR 想取得 SSR 類似的效果，可以採取以下方案優化：</p><ol><li><p><strong>首屏頁面靜態資源優化：</strong>通過代碼切割 &amp; 懶加載等手段，確保首屏需要的 JS/CSS 是最小化的版本，並通過內聯等方式直接打到 HTML 中，減少首屏渲染需要的網絡請求；</p></li><li><p><strong>緩存和</strong><strong>預加載</strong><strong>：</strong>利用客户端的緩存及預加載等機制，提升二次訪問速度；</p></li><li><p><strong>使用更輕量的框架：</strong>選擇更輕量的前端框架，從而減少首屏的 JS 體積，提升加載速度；</p></li><li><p><strong>優化關鍵接口響應速度：</strong>優化首屏需要的關鍵內容的接口響應速度，確保前端能更快的呈現頁面。</p></li></ol><p>但如果還有額外的 SEO 訴求，單純的 CSR 可能很難達到一樣的效果。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q7：如果將原有的應用直接切換到 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 一體化應用中來，成本會有多大？對開發團隊會有哪些挑戰呢？</strong></span></p><p><strong>劉奎：</strong>成本及挑戰有以下幾點：</p><ol><li><p><strong>應用改造成本：</strong>大部分應用都是無法直接在服務端環境運行的，基本都需要做一定程度的改造，比如消除首屏渲染代碼中對 window、location 等瀏覽器特有 API 的依賴，構建出用於服務端運行的 JS 等。</p></li><li><p><strong>SSR</strong><strong> 函數研發及運維挑戰：</strong>同時具備豐富的前端及服務端開發經驗的團隊在大部分公司都是非常少見的，如前面提到的，SSR 帶來的額外的服務端的開發及運維挑戰，這個也是需要前端團隊考慮的。</p></li></ol><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>三、也許，SSR + CSR 會是未來新方向？</h1><p><span style="color:#245bdb"><strong>Q8：現在一些網站採用了</strong></span><span style="color:#245bdb"><strong>首屏服務器端</strong></span><span style="color:#245bdb"><strong>渲染，即對於用户最開始打開的那個頁面採用的是服務器端渲染，這樣就保證了渲染速度，而其他的頁面採用</strong></span><span style="color:#245bdb"><strong>客户端渲染</strong></span><span style="color:#245bdb"><strong>，這樣就完成了前後端分離。你覺得這會是融合了兩者優勢的更完美的方案嗎？</strong></span></p><p><strong>劉奎：</strong>是的，這也是目前社區內的最佳實踐，能很好的保留 SSR 及 SPA 應用的優點。</p><p><strong>劉勇：</strong>這其實很多年前就有相關實踐了，譬如當年雲龍在 UC 的 Scrat Pagelet 就是類似的實踐，甚至當時做的是後續頁面也通過服務端局部渲染，按需更新前端頁面的階段。</p><p>這種方式在業界也有看到一些更近一步的實踐：開發者很自然的去寫邏輯，不用管什麼分離不分離的事，在前端工程化那一層自動拆分，SSG + SSR + CSR，一些可以靜態構建的直接在構建階段處理了，一些可以在服務端渲染的服務端，剩下的非剛需的組件直接前端渲染掉。這些都能做，前提是前端工程化這塊的基建是否足夠完善，研發模式是否足夠收斂。</p><p>最後提醒下，我所瞭解大部份 SSR 實踐，一般也會在前面再擋一個短時效的 CDN，然後通過 CSR 做千人千面的修飾和後續業務邏輯。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q9：你如何看待 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 的未來發展？是會隨着硬件的升級逐步淘汰，還是會隨着技術的更新越發流行？</strong></span></p><p><strong>劉勇：</strong>優化思路是不會過時的，也許某一天我們現在熟悉的 SSR 的編程界面變了，譬如當年的 SSR 是用 nunjucks、ejs 之類的模版，現在是 react、vue。未來也會有新的技術出現，但它很有可能也屬於 SSR 的一種實踐模式。</p><p><strong>劉奎：</strong>按照我的經驗來看，很多時候新的技術方案大都會嘗試更多的壓榨硬件機能，從而獲得更好的交互體驗，所以任何時期都會存在相對「低端」的設備，這個應該是解決不掉的（笑</p><p>在我看來，SSR 最主要的落地成本還是在服務端的研發及運維上，這個對於大部分公司的前端團隊都是較大的負擔，進而因為 ROI 不高導致 SSR 落地困難。但是，隨着 Serverless 的發展，出現了許多幾乎「零運維」的 Serverless 方案，可以極大地降低前端團隊的運維成本。同時，從社區的趨勢來看，近年來流行的各種前端框架都在擁抱 Edge 和 SSR，例如 Next.js、remix-run、Qwik、Astro、Fresh 等。同時，React 等庫也推出了性能表現更佳的流式 SSR 能力。通過這些框架技術的集成和迭代，不僅可以顯著降低前端工程師開發 SSR 應用的研發成本，還能進一步提升傳統 SSR 的性能效果。</p><p>從目前的趨勢來看，我覺得 SSR 會隨着研發及運維成本的降低，變得越發的流行。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q10：結合你的項目經驗，你會如何評價 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 這一模式呢？</strong></span></p><p><strong>劉勇：</strong>從前端的歷史演進看，是 SSR → CSR → SSR，粗一看似乎是在開歷史倒車，但實際不然。</p><p>舉個例子，當年前端的 HTML + CSS + JS 都是 all-in-one 的單文件方式，因為那時候前端沒有編譯能力只能寫在一起；隨着前端工程化的演進，開發期拆成多文件方式進行組織，構建時自動處理成為了主流；再進一步又出現了類似 Vue SFC 這樣的單文件方式，這是開倒車麼？其實不是，而是隨着基建的完善，用户編程界面是可以更貼近直覺的，性能和部署之類的事交給工具去做即可。</p><p>因此，我認為 SSR 模式是有真實場景的，但在目前這個階段，我覺得它還有很多切實的性能問題和工程化問題需要解決才能更好的落地。</p><p><strong>劉奎：</strong>CSR 雖然也能獲得比較好的首屏體驗，但受限於用户設備的機能，存在着明顯的性能天花板。而 SSR 則能更好的藉助邊緣計算（ESR）、流式渲染等服務端能力，有效的提升性能天花板，在大部分時候會是 Web 應用提升首屏性能的一個有效武器。</p><p>當然每個項目和團隊都有不同的特點和目標，在選擇開發模式時需要綜合考慮各種因素。</p><p>&nbsp;</p><p style="text-align:left">對此，你怎麼看？你的項目採取了 SSR 還是 CSR 呢？快來評論區説説你的體驗吧~</p></div></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 09:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10136979</guid>
            <link>https://my.oschina.net/u/6852546/blog/10136979</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[推特年度工程總結，數據感人，什麼代碼減少 60 萬行、節省 1 億美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>推特官方帳號發佈了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FXEng%2Fstatus%2F1717754398410240018" target="_blank">一年的工程總結</a>，亮點數據包括：</p><ul><li><p><span style="color:#000000"><span style="background-color:#ffffff">徹底重構 For you 服務和排名系統，代碼行數從 700K 減少到 70K，減少了 90%，計算佔用量減少了 50%，帖子吞吐量增加了 80%。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">重構了技術棧的 API 中間件層，並簡化了架構</span></span>，<span style="color:#000000"><span style="background-color:#ffffff">刪除超過 10 萬行代碼和數千個未使用的內部端，消除未採用的客户端服務。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">關閉薩克拉門託數據中心並重新配置 5,200 個機架和 148,000 台服務器，每年節省超過 1 億美元。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">元數據獲取後延遲減少了 50%，全局 API 超時錯誤減少了 90%。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">優化了對雲服務提供商的使用，在本地進行更多工作，每月雲成本降低了 60%。具體是將所有媒體/blob 工件移出雲，使得整體雲數據存儲大小減少了 60%。同時，雲數據處理成本降低了 75%。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">構建本地 GPU 超級計算集羣，並設計、開發和交付 43.2Tbps 的新網絡結構架構以支持集羣。 </span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">擴展網絡主幹容量和冗餘，每年節省 1,390 萬美元。 </span></span></p></li></ul><hr><p><img src="https://static.oschina.net/uploads/space/2023/1027/161455_YSrE_2720166.png" referrerpolicy="no-referrer"></p><hr><p><strong>推薦閲讀</strong></p><ul><li><a href="https://www.oschina.net/news/231624/a-single-engineer-brought-down-twitter" target="_blank">一名工程師修改配置導致推特宕機，馬斯克迴應：要徹底重寫這堆 "ShitCode"</a></li><li><a href="https://www.oschina.net/news/259436/elon-musk-moved-twitter-servers-himself" target="news">馬斯克硬核遷移推特服務器</a></li><li><a href="https://www.oschina.net/news/247743/twitter-rate-limit" target="news">馬斯克稱 Twitter 數據被極端抓取，緊急上線「限流」機制</a></li><li><a href="https://www.oschina.net/news/228687/musk-twitter-recommend-algorithm" target="news">馬斯克連夜命令推特工程師修改算法</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263723/x-engineering-report</guid>
            <link>https://www.oschina.net/news/263723/x-engineering-report</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟已擁有超過 100 萬付費 Copilot 用户]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">微軟 CEO 薩提亞·納德拉 (Satya Nadella) 日前透露，該公司 GitHub Copilot 軟件的付費用户已超過 100 萬。</span></p><p><span style="color:#000000">「藉助 GitHub Copilot，我們將開發人員的工作效率提高了 55%，我們擁有超過 100 萬付費 Copilot 用户。此外，已有超過 37,000 個組織訂閲了 Copilot for Business，環比增長 40%。本季度，我們通過 GitHub Copilot Chat 添加了新功能，Shopify 等數字原生企業以及馬士基和普華永道等領先企業已在使用這些功能，以提高其軟件開發人員的生產力。」</span></p><p><img height="264" src="https://oscimg.oschina.net/oscnet/up-1fbc03d629d9cf27183ca8ebfb858414029.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">納德拉表示，Copilot 是其在公司產品線中推廣 AI 的眾多方式之一。該公司的必應搜索引擎已經與 OpenAI 的 ChatGPT 集成，迄今為止用户參與的聊天數量已「超過 19 億次」。</span></p><p><span style="color:#000000">他指出，Microsoft Edge 瀏覽器的市場份額現已連續 10 個季度增長。「本季度，我們推出了新的個性化答案以及對 DALL-E 3 的支持，幫助人們獲得更相關的答案並創建極其逼真的圖像。迄今為止，我們已創建了超過 18 億張圖像。藉助 Copilot 在購物方面的應用，大家可以獲取更多量身定製的推薦以及達成更好的交易。」</span></p><p><span style="color:#000000">目前，微軟已經向初創公司 OpenAI 投資超過 100 億美元；華爾街預計微軟將從與 OpenAI 的合作中獲得巨大的財務回報。一些華爾街分析師估計，這種合作關係有一天可能會給微軟帶來 1000 億美元的價值。</span></p><p><span style="color:#000000">儘管納德拉沒有量化 GitHub Copilot 的收入，但微軟 CFO Amy Hood 表示，「高於預期的 AI 消費推動了 Azure 的收入增長」。</span></p><p><span style="color:#000000">該公司智能雲計算業務本季度的總收入超出了分析師的預期 (234 億美元)，同比增長 19%，達到 243 億美元。Hood 表示，其中 Azure 業務增長了 29%，有 3 個百分點來自「AI 服務」。</span></p><p><span style="color:#000000">此外，微軟方面還將 Copilot 引入了 Power Platform，使任何人都可以使用自然語言來創建應用程序，構建虛擬代理和分析數據。納德拉表示：「包括 3M、Equinor、Lumen Technologies、Nationwide、PG&amp;E 和豐田在內的超過 126,000 家組織都使用了 Copilot 和 Power Platform。」</span></p><p><span style="color:#000000">該公司還正在將生成式 AI 添加到其 LinkedIn 業務中。「我們發現本季度在 LinkedIn 上觀看 AI 相關學習課程的會員數量增加了近 80%」。以及將 Copilot 擴展到醫療保健等各行各業。目前，該公司正在將臨牀工具集成到 Azure 上的 Fabric 數據服務中。</span></p><p><span style="color:#000000">納德拉稱，GitHub Copilot 和其他產品的推出還處於早期階段。「我們正處於非常非常早期的階段，因此我們期待看到這些產品在未來的發展。Copilot 的早期發展給了我們很大的信心，更重要的是，讓我們的客户對這些產品所代表的價值充滿了信心。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 07:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263710</guid>
            <link>https://www.oschina.net/news/263710</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國家安全部：警惕一些境外 SDK 背後的「數據間諜」竊密]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><blockquote><p>本文轉載自 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fxq_0nAxzuZ4t0HLXLy8BEg" target="_blank"><strong>國家安全部微信公眾號</strong></a></u></p></blockquote><p>你知道 SDK 是什麼嗎？SDK 是英文 Software Development Kit 的縮寫，即軟件開發工具包，它的類型多種多樣。如果把開發一個軟件系統比作蓋一所「三室一廳」的房子，那麼不同的 SDK 就是這套房子的「客廳」「卧室」「衞生間」「廚房」等功能模塊。蓋好這套房子，我們只需要從不同的供應商那裏選擇這個功能模塊拼裝即可，而不再需要從「砌磚」「壘牆」做起，從而極大提高了軟件開發的效率。</p><p>近年來，國家安全機關工作發現，境外一些別有用心的組織和人員，正在通過 SDK 蒐集我用户數據和個人信息，給我國家安全造成了一定風險隱患。</p><h4><span style="color:#ffffff"><strong><span style="background-color:#2980b9">SDK 帶來哪些數據安全問題？</span></strong></span></h4><p>當前，SDK 以其多樣化、易用性和靈活性等優勢成為移動供應產業鏈中最重要的一項服務，與此同時也帶來諸多數據安全問題。</p><ul><li><strong>過度收集用户數據</strong></li></ul><p>有些 SDK 會收集與提供服務無關的個人信息，或強制申請非必要的使用權限，比如獲取地理位置、通話記錄、相冊照片等信息以及拍照、錄音等功能。當 SDK 的用户覆蓋量達到一定規模時，可以通過蒐集的大量數據，對不同用户羣體進行畫像側寫，從而分析出潛在的有用信息，比如同事關係、單位位置、行為習慣等。</p><p>一些境外 SDK 服務商，通過向開發者提供免費服務，甚至向開發者付費等方式來獲取數據。據相關網站披露，一款在美國擁有 5 萬日活躍用户的應用程序，其開發者通過使用某 SDK，每月可以獲得 1500 美元的收入。作為回報，該 SDK 服務商可以從這款應用程序中收集用户的位置數據。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28cd143918cb6491c1493e0dcedaa1e2bd3.png" referrerpolicy="no-referrer"></p><p><em>SDK 蒐集個人信息類型</em></p><ul><li><strong>境外情報機構將 SDK 作為蒐集數據的重要渠道</strong></li></ul><p>據報道，美國特種作戰司令部曾向美國 SDK 服務商 Anomaly Six 購置了「商業遙測數據源」的訪問服務，而該服務商曾自稱將 SDK 軟件植入全球超過 500 款應用中，可以監控全球大約 30 億部手機的位置信息。</p><p>2022 年 4 月，有關媒體曝光巴拿馬一家公司通過向世界各地的應用程序開發人員付費的方式，將其 SDK 代碼整合到應用程序中，秘密地從數百萬台移動設備上收集數據，而該公司與為美國情報機構提供網絡情報蒐集等服務的國防承包商關係密切。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b4bc6599b4e81d3e9a7883925c9f4c2c397.png" referrerpolicy="no-referrer"></p><p><em>《華爾街日報》：美國政府承包商在多個手機 APP 中嵌入跟蹤軟件</em></p><h4><span style="color:#ffffff"><strong><span style="background-color:#2980b9">消除 SDK 背後的數據風險</span></strong><strong><span style="background-color:#2980b9">我們應該怎麼做？</span></strong></span></h4><p>據國內權威機構掌握，截至 2022 年 12 月，我國 10 萬個頭部應用中，共檢測出 2.3 萬餘例樣本使用境外 SDK，使用境外 SDK 應用的境內終端約有 3.8 億台。對此，我們又應該做些什麼呢？</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-85cdd9629fe616749844499bf44f168c4aa.png" referrerpolicy="no-referrer"></p><p><em>SDK 申請收集用户信息佔比</em></p><ul><li><strong>應用程序開發企業</strong>：應儘量選擇接入經過備案認證的 SDK，引入境外 SDK 前應做好安全檢測和風險評估，深入瞭解 SDK 的隱私政策，並利用 SDK demo 以及 APP 測試環境對 SDK 聲明內容進行一致性比對，並持續監測 SDK 是否有異常行為。</li><li><strong>個人用户</strong>：個人用户在使用手機應用程序時，要增強個人信息保護意識及安全使用技能，要選擇安全可靠的渠道下載使用應用程序，不安裝來路不明的應用，不盲目通過敏感權限的申請。特別是發現 SDK 申請與應用功能無關的權限時，需要保持高度警惕。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 07:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263704</guid>
            <link>https://www.oschina.net/news/263704</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows CE 徹底退役]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>誕生於 1996 年的 Windows 嵌入式操作系統 —— Windows CE (Windows Embedded Compact) 本月迎來了它的生命週期終點。</p><p>Windows CE 最初是 Windows 的精簡版本，之後逐漸發展成為全新的操作系統，它有自己的 CE 內核，而不是傳統 Windows 操作系統使用的 NT 內核。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8f640a89f188c88148ea17ea44e6c74b915.png" referrerpolicy="no-referrer"></p><p>它的最後一個版本是 2013 年 8 月 11 日發佈的 Windows Embedded Compact 2013（或者叫 Windows CE 8.0），該版本於 2018 年 10 月結束主流支持 (Mainstream Support)，<strong>2023 年 10 月結束延長支持 (Extended Support)</strong>，成為不受支持的退役產品。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bea6f86fc521c769ddd160731ae640284b0.png" referrerpolicy="no-referrer"></p><p>然而很少有人注意到 Windows CE 的生命週期已結束。作為一個產品，CE 8.0 的發佈未能獲得太多關注或宣傳。即使在 Windows CE 社區中，大多數人也認為 Windows Embedded Compact 2013 完全不適合使用。與之前的 Windows CE 7.0 一樣，基於 CE 8.0 平台發佈的設備很少，因此大多數人甚至從未見過 CE 8 的實體設備。</p><p>CE 8 唯一值得注意的特性是首次加入了 IPv6 支持，但更重要的是刪除了默認示例用户界面，它規定任何 OEM 都必須發佈帶有完全自定義編碼界面的設備，然而很少有供應商願意這樣做，此舉事實上真正結束了廉價 Windows CE 上網本設備的時代。</p><blockquote><p>事實上微軟並未介紹過 CE 縮寫的由來，一般解釋則有 Compact Edition、Customer Embedded、Consumer Electronics 等等。</p><p>在 2008 年 4 月 15 日舉行的嵌入式系統大會上，微軟宣佈將 Windows CE 更名為 Windows Embedded Compact，與 Windows Embedded Enterprise、Windows Embedded Standard 和 Windows Embedded POSReady 組成 Windows Embedded 系列產品。</p></blockquote><p>===彩蛋分割線===</p><p>曾被稱為「國產機皇」的魅族 M8，其運行的操作系統正是基於 Windows CE 開發。</p><p><img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-786c41866ad15ca06fc5d0a683e8366c459.png" width="400" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 06:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263685/end-of-an-era-windows-ces-final-day</guid>
            <link>https://www.oschina.net/news/263685/end-of-an-era-windows-ces-final-day</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.10.0 - 支持更靈活的變更發佈人]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><h2>🚀 新功能</h2><ul><li>發佈策略支持制定更靈活的變更發佈人：可以指定任意角色集合，也可以指定自定義審批流的最後一個審批人。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-232e6912ae4dfccc575951fdcfb6182eaae.png" alt="file" referrerpolicy="no-referrer"></p><ul><li>支持在項目中創建分支保護規則。</li><li>支持給數據庫設置標籤。</li><li>支持給字段設置標籤。</li><li>支持給表設置分類分級。</li></ul><h2>🎄 改進</h2><ul><li><p>支持 PostgreSQL 16。</p></li><li><p>SQL Editor：支持自定義數據庫樹的視圖。</p></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-07ab1d1c2b98175941d8e28433fe617b896.png" alt="file" referrerpolicy="no-referrer"></p><ul><li>SQL Editor：允許提前終止查詢。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-80f111990561ce0c665fe4cce51db4fcb3a.png" alt="file" referrerpolicy="no-referrer"></p><ul><li>支持從指定分支中創建子分支。</li><li>支持在分支合併時選擇其他目標分支。</li><li>支持在工單中使用 SQL Server 局部變量。</li><li>基於 Parser 為 Postgres, MySQL, Oracle, SQL Server, Snowflake 查詢語句增加 LIMIT 子句。</li><li>表詳情頁展示「類型」的最大長度（如有）。</li></ul><h2>🐞 Bug 修復</h2><ul><li>修復分支和變更 Schema 中的列默認值問題。</li></ul><h2>📕 安裝及升級</h2><p>參考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升級指南</a>。如果從之前版本升級，獲取新版本後，重新啓動升級即可。</p><hr><p>💡 更多資訊，請關注 Bytebase 公號：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 06:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10136864</guid>
            <link>https://my.oschina.net/u/6148470/blog/10136864</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[騰訊混元大模型正式開放「文生圖」功能、代碼能力提升 20%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.75)">今天上午，騰訊混元大模型迎來全新升級，<strong>並正式對外開放「文生圖」功能</strong>。</span></p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1026/153337_LfTH_2720166.jpg" referrerpolicy="no-referrer"></p></blockquote><p>進入「騰訊混元助手」小程序即可使用騰訊混元大模型：</p><p><img height="754" src="https://static.oschina.net/uploads/space/2023/1026/165557_Bc0Q_2720166.png" width="400" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.75)"><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fu0AGtpwm_LmgnDY7OQhKGg" target="_blank">官方公告稱</a></u>，升級後的騰訊混元中文效果整體超過 GPT-3.5，<strong>代碼能力大幅提升 20%</strong>，達到業界領先水平。</span></p><p>據介紹，經過對 32 種主流語言代碼文件、各類計算機書籍和博客的學習增訓，騰訊混元代碼處理水平提升超過 20%，代碼處理效果勝出 ChatGPT 6.34%，在 HumanEval 公開測試集指標上全面超過 Starcoder、Codellama 等業界頭部開源代碼大模型。</p><p>只需輸入簡單的指令如「幫我用前端語言實現一個貪吃蛇」，騰訊混元便能自動生成可運行的代碼，快速製作出一個貪吃蛇小遊戲。此外，騰訊混元還支持 Python、C++、Java、JavaScript 等多種語言的指令生成，比如輸入「用 Python 畫紅色的心形線」，騰訊混元會提供代碼庫選擇、安裝命令、繪製代碼等具體操作步驟的指引。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-74216bf9be5ab9c4baadcbe9551410b8953.png" referrerpolicy="no-referrer"></p><p>對於大模型文生圖功能，騰訊稱其難點體現在<strong>對提示詞的語義理解，生成內容的合理性以及生成圖片的效果</strong>。針對這三個技術難點，騰訊進行了專項的技術研究，提出了一系列原創算法，來保證生成圖片的可用性和畫質。</p><p>1、<strong>在語義理解方面，騰訊混元採用了中英文雙語細粒度的模型</strong>，模型同時建模中英文實現雙語理解，而不是通過翻譯，通過優化算法提升了模型對細節的感知能力與生成效果，有效避免多文化差異下的理解錯誤。</p><p>2、<strong>在內容合理性方面</strong>，AI 生成人體結構和手部經常容易變形。<strong>混元文生圖通過增強算法模型的圖像二維空間位置感知能力</strong>，並講人體骨架和人手結構等先驗信息引入到生成過程中，讓生成的圖像結構更合理，減少錯誤率。</p><p>3、<strong>在畫面質感方面，混元文生圖基於多模型融合的方法，提升生成質感</strong>。經過模型算法的優化之後，混元文生圖的人像模型，包含髮絲、皺紋等細節的效果提升了 30%，場景模型，包含草木、波紋等細節的效果提升了 25%。</p><hr><p>下面是官方提供的「騰訊混元文生圖」使用案例。</p><ul><li>生成一幅照片：亞洲女子，魅力，中短髮，戴墨鏡，站在長城上，背景有紅葉</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-68d0953d2980101a5d24fe95c964a701946.png" referrerpolicy="no-referrer"></p><ul><li>生成一張長城的照片，攝影風，真實感</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3d745e8069507f0664da26f405ccddc4bc5.png" referrerpolicy="no-referrer"></p><ul><li>幫我畫一個拿着奶茶的甄嬛，扁平插畫，可愛 Q 版</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b61d22330c53d477f4669f355753becd266.png" referrerpolicy="no-referrer"></p><ul><li>生成 3D 遊戲軍事場景動漫，城市戰區，廢墟瓦礫，焦黑的建築，空氣中瀰漫硝煙</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f900d701ddb927a9b2fdb40caa870f9d736.png" referrerpolicy="no-referrer"></p><ul><li>畫一幅漁舟唱晚的畫</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-58f36165a591c6630cd605fb7afb63f5e47.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 07:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263543</guid>
            <link>https://www.oschina.net/news/263543</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[全新的分佈式鎖，功能簡單且強大]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><blockquote><p>來源：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftlnet.top%2Farticle%2F22425101" target="_blank">《全新的分佈式鎖，功能簡單且強大》</a></p><p>前言：分佈式鎖是分佈式系統中一個極為重要的工具。目前有多種分佈式鎖的設計方案，比如藉助 redis，mq，數據庫，zookeeper 等第三方服務系統來設計分佈式鎖。tldb 提供的分佈式鎖，主要是要簡化這個設計的過程，提供一個簡潔可靠，類似使用程序中對象鎖的方式來獲取分佈式鎖。</p></blockquote><p><strong>tldb 提供分佈式鎖使用方法：</strong></p><ol><li><p>lock 阻塞式請求鎖</p></li><li><p>trylock 嘗試加鎖，若鎖已被佔用，則失敗返回，反之，則獲取該鎖</p></li><li><p>unlock 釋放已經獲取的鎖</p><p>tldb 提供的分佈式鎖功能主要在 MQ 模塊中實現，調用的方法在 MQ 客户端實現，客户端的實現實際非常簡單，除了目前已經實現的幾種語言 java，golang，python，javaScript 寫的 simpleClient，其實其他開發者有興趣也可以實現其他語言的 MQ 客户端，完全沒有技術門檻。分佈式鎖由 tldb 服務器控制，所以它相對客户端來説，也是跨語言的，如，用 java 客户端上鎖的對象，其他語言同樣無法獲取該對象鎖。</p></li></ol><hr><h4><strong>Lock(string,int) 方法的使用</strong></h4><p>tldb 提供的是以字符串為鎖對象的獨佔鎖， 如，lock("abc",3) 必須提供兩個參數：</p><ol><li>第一個參數為鎖對象，即服務器對「abc」對象分配一個鎖，所有對"abc"對象請求加鎖的線程爭用一個獨佔鎖，該方法為一個阻塞方法，請求到鎖則返回，如果鎖被其他線程佔用，則一直阻塞直至獲取到鎖。</li><li>第二個參數為持有該分佈式鎖的最長時間，單位為秒，例如 lock("abc",3)，意思是，如果超過 3 秒還沒有調用 unlock 釋放該鎖，服務器將強制釋放該鎖，繼續將鎖分配給其他請求的線程。</li></ol><hr><h4><strong>UnLock(string) 方法的使用</strong></h4><ul><li>UnLock 為釋放分佈式鎖時調用的方法。客户端在成功獲取分佈式鎖後，服務器會返回一個該鎖的 key，客户端執行完邏輯代碼的最後，必須顯式調用 UnLock(key) 來釋放該分佈式鎖。如果沒有調用 unlock 釋放鎖，tldb 將等待鎖釋放的超時時間直至超時後強制釋放該鎖。</li></ul><hr><h4><strong>TryLock(string,int) 方法的使用</strong></h4><ul><li>trylock 與 lock 相似，但是 lock 方法阻塞的，調用 lock 方法請求分佈式鎖時，如果該鎖已經被佔用，那麼 lock 方法將一直等待直至 tldb 服務器將鎖分配給它，這與程序中獲取獨佔鎖的方式一致。而 trylock 時非阻塞的，調用 trylock 後會立即返回，如果獲取到鎖，tldb 會將標識該鎖的 key 一併返回，如何該鎖已經被佔用，服務器將返回空數據。</li></ul><hr><p><strong>以下以 go 為例使用分佈式鎖</strong></p><p>因為 tldb 分佈式的實現是在 MQ 模塊，所以 go 程序必須使用 tlmq-go, tldb 的 mq 客户端進行調用鎖方法。</p><pre><code>   import  "github.com/donnie4w/tlmq-go/cli"
</code></pre><p>調用 lock 的程序：lock 方法是阻塞的</p><pre><code>sc := cli.NewMqClient("ws://127.0.0.1:5001", "mymq=123")
sc.Connect()
//以上為，客户端連接 MQ 服務器
key, err := sc.Lock("testlock", 3)
//lock 中兩個參數，第一個參數為字符串，即 tldb 服務器為「testlock」分配一個全局的分佈式鎖
//第二個參數 3 為客户端持有該鎖的最長時間，表示超過 3 秒沒有釋放鎖時，tldb 服務器將在服務端強制釋放該鎖，並分配給其他請求鎖的線程
if err!=nil{
    //獲取鎖失敗，需查看 tldb 能正常訪問
}else{
    defer sc.UnLock(key) //獲取鎖成功後，必須在程序最後調用 Unlock
    //執行業務邏輯程序
}
</code></pre><p><strong>調用 tryLock 的程序，trylock 是非阻塞的</strong></p><pre><code>sc := cli.NewMqClient("ws://127.0.0.1:5001", "mymq=123")
sc.Connect()

if key, ok := sc.TryLock("testlock2", 3); ok {
    //ok 為 true，表示已經成功獲取到分佈式鎖
    defer sc.UnLock(key) //在程序最後釋放鎖對象
    ...        
}
</code></pre><p><strong>go 用自旋的方式使用 trylock 獲取分佈式鎖，實現程序的阻塞等待</strong></p><pre><code>sc := cli.NewMqClient("ws://127.0.0.1:5001", "mymq=123")
sc.Connect()
var key string
for {
if  v, ok := sc.TryLock("testlock", 3); ok {
    key = v
break
} else {
&lt;-time.After(100* time.Millisecond)
}
}
defer sc.UnLock(key)
...//業務邏輯代碼
</code></pre><p>這段程序應該比較易於理解，就是每隔 100 毫秒，循環獲取字符串「testlock」的分佈式鎖直至成功。</p><hr><p><strong>以下以 java 為例</strong> java 客户端為 tlmq-j ：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdonnie4w%2Ftlmq-j" target="_blank">https://github.com/donnie4w/tlmq-j</a></p><p>maven 配置</p><pre><code>&lt;dependency&gt;        
   &lt;groupId&gt;io.github.donnie4w&lt;/groupId&gt;      
   &lt;artifactId&gt;tlmq-j&lt;/artifactId&gt;     
   &lt;version&gt;0.0.2&lt;/version&gt;   
&lt;/dependency&gt;
</code></pre><p>調用 lock 方法</p><pre><code>MqClient mc = new SimpleClient("ws://127.0.0.1:5001", "mymq=123");
mc.connect();
//java 連接服務器
String key = null;
try{
      key = mc.lock("testlock", 3); //獲取分佈式
      ... //執行業務邏輯程序
}finally {
     if (key!=null){
         mc.unLock(key); //釋放分佈式鎖
     }
}
</code></pre><p>調用 trylock 方法</p><pre><code>MqClient mc = new SimpleClient("ws://127.0.0.1:5001", "mymq=123");
mc.connect();
String key = null;
try{
      key = mc.tryLock("testlock", 3); //獲取分佈式
      ... //執行業務邏輯程序
} finally {
     if (key!=null){
         mc.unLock(key); //釋放分佈式鎖
     }               
}
</code></pre><p><strong>以下是 tldb 分佈式鎖的功能測試數據：</strong><strong>多線程併發，調用 lock 獲取同一個對象鎖後，程序的運行數據：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-09276d085e420b382074c69dade4cd6372b.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>多線程併發使用自旋的方式調用 trylock 與 lock 獲取同一個對象鎖：</strong><img src="https://oscimg.oschina.net/oscnet/up-cb14a249e167dfb0eca3c06850a6017f182.jpg" alt="" referrerpolicy="no-referrer"></p><hr><p><a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%9C%89%E4%BB%BB%E4%BD%95%E9%97%AE%E9%A2%98%E6%88%96%E5%BB%BA%E8%AE%AE%E8%AF%B7Email%EF%BC%9Adonnie4w%40gmail.com%E6%88%96" target="_blank">有任何問題或建議請 Email：donnie4w@gmail.com 或</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftlnet.top%2Fcontact" target="_blank">https://tlnet.top/contact</a> 發信給我，謝謝！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 07:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/donnie4w/blog/10114233</guid>
            <link>https://my.oschina.net/donnie4w/blog/10114233</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 更新「知識」數據，截至 2023 年 4 月]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>ChatGPT 剛剛宣佈，其「知識」數據已進行更新，當前的知識截止日期是 2023 年 4 月。</p><p><img height="786" src="https://static.oschina.net/uploads/space/2023/1026/143656_e72e_2720166.png" width="1651" referrerpolicy="no-referrer"></p><p>注意，此次知識數據更新僅面向 GPT-4 版本提供。</p><p>ChatGPT 官方提供瞭如下示例。</p><p>提問：<strong>請列出最近發生的 10 次災難，以及在您的知識截止日期前的傷亡人數。災難至少應始於 2022 年之後。</strong></p><blockquote><p>Here are 10 significant catastrophes that occurred after 2022, up to my knowledge cutoff in April 2023, along with their associated casualties:</p><ol><li><p><strong>Earthquake in Turkey and Syria (February 6, 2023):</strong> This devastating earthquake, with a magnitude of 7.8, struck southeastern Turkey and northern Syria, leading to widespread destruction. The death toll exceeded 47,000 people, making it one of the deadliest earthquakes in recent history.</p></li><li><p><strong>Floods in Brazil (January 2023):</strong> Severe floods and landslides hit the state of São Paulo in Brazil, resulting in over 50 deaths. Several cities, including São Sebastião and Ubatuba, were significantly impacted.</p></li><li><p><strong>Train Derailment in Greece (March 1, 2023):</strong> A passenger train and a freight train collided in central Greece, near the city of Larissa, causing the death of at least 57 people.</p></li><li><p><strong>Earthquake in Afghanistan (June 22, 2022):</strong> A powerful earthquake with a magnitude of 5.9 struck eastern Afghanistan, particularly affecting the Paktika and Khost provinces. The catastrophe resulted in the death of over 1,000 people.</p></li><li><p><strong>Floods in Pakistan (Mid-2022):</strong> Monsoon floods in Pakistan, particularly severe in the Sindh and Balochistan provinces, led to the deaths of over 1,000 people and displaced millions.</p></li><li><p><strong>Tornado Outbreak in the United States (March 2023):</strong> A series of tornadoes swept across several states in the U.S., including Mississippi, Alabama, and Georgia. The outbreak caused at least 25 fatalities.</p></li><li><p><strong>Ferry Fire in the Philippines (March 28, 2023):</strong> A fire broke out on a ferry in the Philippines, leading to at least 31 deaths. The incident occurred near the island of Basilan.</p></li><li><p><strong>Typhoon Noru in the Philippines (September 2022):</strong> This powerful typhoon, also known as Karding, caused widespread destruction in the Philippines, resulting in the deaths of at least 8 people.</p></li><li><p><strong>Landslides in Peru (January 2023):</strong> Heavy rains triggered landslides in the Cusco region of Peru, leading to at least 36 deaths. The town of Santa Teresa, near the tourist attraction Machu Picchu, was particularly affected.</p></li><li><p><strong>Cyclone Gabrielle in New Zealand (February 2023):</strong> This powerful cyclone caused significant flooding and landslides in New Zealand's North Island, leading to at least 11 deaths.</p></li></ol><p>Please note that the number of casualties and the impact of these catastrophes might have changed after my last update in April 2023.</p></blockquote><p>via <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.openai.com%2Fshare%2F3b088460-86f8-4fa6-afd1-802b7f9a5e9f" target="_blank">https://chat.openai.com/share/3b088460-86f8-4fa6-afd1-802b7f9a5e9f</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 06:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263533</guid>
            <link>https://www.oschina.net/news/263533</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[《2023 年三季度互聯網投融資運行情況》研究報告發布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">中國信息通信研究院政策與經濟研究所互聯網運行分析團隊於日前，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FxZbTT8DZ0Q79-2RGTXhFbg" target="_blank">發佈</a>了《2023 年三季度互聯網投融資運行情況》報告。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">報告構建了互聯網行業投融資研究框架，藉助 CB Insights 數據庫，深入挖掘我國和全球行業投融資整體態勢及重點領域情況，為行業趨勢預測、熱點問題預判提供重要參考。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">本季要點：</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>1.&nbsp;</strong><strong>我國互聯網投融資略有反彈。</strong>2023Q3，我國互聯網投融資規模企穩，案例數環比下跌 5.8%，同比下跌 54%；披露的金額環比上漲 34.7%，同比下跌 36.4%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>2.<span>&nbsp;</span></strong><strong>全球互聯網投融資繼續下探。</strong>2023Q3，全球互聯網投融資案例數環比下跌 5.1%，同比下跌 23.4%；披露的金額環比下跌 15.5%，同比下跌 28.8%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>3.</strong><strong>企業服務融資佔比保持領先。</strong>2023Q3，我國企業服務領域融資案例數佔比 25.7%，融資金額佔比 26%；全球企業服務領域融資案例數佔比 21.3%，融資金額佔比 19.8%。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>報告全文：</span></p><p><img height="3587" src="https://oscimg.oschina.net/oscnet/up-ee666d0691d7989a2ff66c9cfbe80f422d2.png" width="500" referrerpolicy="no-referrer"></p><p><img height="2012" src="https://oscimg.oschina.net/oscnet/up-2d7d99c36f9f1ebf6569235631c9a3771cd.png" width="500" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.caict.ac.cn%2Fkxyj%2Fqwfb%2Fqwsj%2F202310%2FP020231027488865727077.pdf" target="_blank">報告全文下載</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 06:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263690</guid>
            <link>https://www.oschina.net/news/263690</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[崑崙萬維 Q3 報告：實現經營性現金流 7.6 億]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">崑崙萬維發佈了 2023 年第三季度報告。據報告披露，崑崙萬維第三季度<strong>全面加速推進</strong>「All in」 AGI 與 AIGC 的戰略佈局，在多個方向均取得了突破性進展。截至本報告期末，崑崙萬維實現營業收入<strong>36.8 億</strong>元，同比增長 8%。實現經營性現金流<strong>7.6 億</strong>元，同比增長<strong>33%</strong>。</span></p><p><span style="color:#000000">今年前三季度，崑崙萬維海外業務收入佔比進一步提升至 84%，同比增加近 9 個百分點；整體毛利率達 80%，繼續保持在較高水平；實現歸屬於上市公司股東的淨利潤 3.3 億元，<strong>穩居行業第一梯隊</strong>。崑崙萬維第三季度實現經營性淨利潤 1.0 億元，環比增長 29%。</span></p><p><span style="color:#000000">為全面落實「All in」AGI 與 AIGC 的戰略佈局，崑崙萬維前三季度研發費用提升至 6.2 億元，加速推進相關業務發展。此外，9 月 21 日，崑崙萬維發佈公告，公司控股股東、實際控制人周亞輝先生及一致行動人盈瑞世紀承諾未來三年（從 2023 年 9 月 22 日到 2026 年 9 月 21 日）不以任何形式減持所持有的公司股票，包括承諾期間該部分股份因資本公積轉增、派送股票紅利、配股、增發等事項產生的新增股份，長期助力崑崙萬維成為一家全球領先的人工智能科技企業。</span></p><p><img height="282" src="https://static.oschina.net/uploads/space/2023/1027/113236_MDTf_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">報告稱，在國內 AGI 與 AIGC 領域，其「天工」大模型在邏輯推理、文本理解、多模態能力等多個方面均取得了顯著突破。基於大模型核心能力的提升，「天工」APP 進行了全面迭代升級，整合了 AI 搜索、AI 閲讀、AI 創作等核心功能，覆蓋了<strong>工作、學習和生活</strong>等多個應用場景。</span></p><p><span style="color:#000000">AI 搜索功能經過升級，提高了信息獲取的精準度和效率。AI 閲讀功能高效分析文章鏈接或文檔文件，生成 AI 摘要並提煉要點，幫助用户快速瞭解文章內容。同時，支持問答式交互，使用户能夠更便捷地查詢文檔信息。AI 創作提供輕鬆高效的創作體驗，滿足<strong>學術教育、職場文檔、創意寫作、廣告營銷</strong>等不同場景需求。</span></p><p><span style="color:#000000">作為崑崙萬維 AI 業務矩陣之一的 AI 遊戲也取得了重要進展。崑崙萬維旗下 Play for Fun 遊戲工作室自研的首款 AI 遊戲《Club Koala》於 8 月 25 日在德國科隆國際遊戲展亮相。Club Koala 引入了 AI NPC，並通過 Atom 系統控制 NPC 行為，使 AI NPC 擁有自我意識及記憶能力，為玩家提供更真實、更具沉浸感的遊戲體驗。</span></p><p><span style="color:#000000">海外佈局方面，崑崙萬維依託旗下信息分發及元宇宙業務 Opera 原生瀏覽器 AI 助手 Aria，推出了一系列前沿 AI 功能。</span></p><p><span style="color:#000000"><img alt="" height="236" src="https://oscimg.oschina.net/oscnet/up-b99565529a38b20bc30538e26fb9fe3d15d.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><em>Aria「重用」與「改述」功能</em></span></p><p><span style="color:#000000"><em><img alt="" height="238" src="https://oscimg.oschina.net/oscnet/up-00dfeb44b4d900099bac85a6a6d12e867cc.png" width="500" referrerpolicy="no-referrer"></em></span></p><p><span style="color:#000000"><em>Aria「Compose」與「My Style」功能</em></span></p><p><span style="color:#000000">Aria 已在包括歐盟在內的<strong>180</strong>多個國家和地區上線，用户突破<strong>百萬</strong>。此外，Aria 已覆蓋 Mac、Windows、Linux、Android 和 iOS 等所有主要平台，以及公司元宇宙入口 Opera GX。</span></p><p><span style="color:#000000">截至本季度末，崑崙萬維此前採購及租賃芯片已到貨<strong>約 6000 張</strong>，另外還有約<strong>3000 張</strong>芯片待交付。目前崑崙萬維已有算力預計能夠滿足未來 1~2 年除視頻 AIGC 之外的大模型算力需求。</span></p><p><span style="color:#000000">報告期內，崑崙萬維宣佈通過增資方式控股 AI 算力芯片企業北京艾捷科芯科技有限公司（簡稱「艾捷科芯」），完成「算力基礎設施—大模型算法—AI 應用」全產業鏈佈局。艾捷科芯旨在開發一款可編程的、具有高性能的 NPU 產品，同時應用於模型訓練及推理。</span></p><p><span style="color:#000000">此外，崑崙萬維在「華為全聯接大會 2023」舉辦期間，發佈「天工大模型端雲一體化方案」。該方案具備開箱即用、定製調優、服務保障三大優勢，企業可以自主地訓練模型，也可以<strong>基於天工模型定製</strong>，實現從應用場景真實需求出發，賦能業務發展並提升競爭力。</span></p><p><span style="color:#000000">「崑崙萬維 2023 年第三季度報告展示了公司在 AGI 及 AIGC 領域的突飛猛進。隨着技術的不斷創新和業務的持續擴張，以及在全產業鏈佈局的驅動下，崑崙萬維有望加速成為全球領先的人工智能龍頭企業。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263657</guid>
            <link>https://www.oschina.net/news/263657</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 基於 React 技術棧的工作流高階組件 Antd-bpmn]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-antd-bpmn" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#antd-bpmn"></a>Antd-bpmn</h1><p>一個基於 React + Ant.design + bpmn.js 編寫的工作流高階組件。</p><p><img src="https://gitee.com/antdadmin/antd-bpmn/raw/main/docs/assets/images/01.png" alt="" referrerpolicy="no-referrer"></p><h3><a id="user-content-已完成功能" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#%E5%B7%B2%E5%AE%8C%E6%88%90%E5%8A%9F%E8%83%BD"></a>已完成功能</h3><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 基於 bpmn.js 的基礎畫圖功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> XML 預覽</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> XML 保存</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 對齊方式：向右對齊，左右居中，向左對齊，向上對齊，上下居中，向下對齊</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 放大、縮小</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 撤銷、重做</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 小地圖、快捷鍵</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 重寫工具欄（更符合國人習慣）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 重寫元素菜單（更符合國人習慣）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 屬性面板的設置</li></ul><h3><a id="user-content-如何使用" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8"></a>如何使用</h3><p>安裝：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm i @codeflex/antd-bpmn</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>示例代碼：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">function</span><span class="nx">App</span><span class="p">()</span><span class="p">{</span></span><span id="LC2" class="line"><span class="kd">const</span><span class="nx">config</span><span class="p">:</span><span class="nx">AntdBpmnConfig</span><span class="o">=</span><span class="p">{</span></span><span id="LC3" class="line"><span class="na">deptDataUrl</span><span class="p">:</span><span class="dl">"</span><span class="s2">/xxxx</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">xmlDataUrl</span><span class="p">:</span><span class="dl">"</span><span class="s2">bpmn.demo.xml</span><span class="dl">"</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">onLoad</span><span class="p">:</span><span class="p">(</span><span class="nx">url</span><span class="p">,</span><span class="kd">set</span><span class="p">)</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC6" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">onLoad</span><span class="dl">"</span><span class="p">,</span><span class="nx">url</span><span class="p">)</span></span><span id="LC7" class="line"><span class="c1">// 加載 xml 數據</span></span><span id="LC8" class="line"><span class="k">if</span><span class="p">(</span><span class="nx">url</span><span class="o">===</span><span class="dl">"</span><span class="s2">bpmn.demo.xml</span><span class="dl">"</span><span class="p">)</span><span class="p">{</span></span><span id="LC9" class="line"><span class="nx">fetch</span><span class="p">(</span><span class="nx">url</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="nx">response</span><span class="o">=&gt;</span><span class="kd">set</span><span class="p">(</span><span class="nx">response</span><span class="p">.</span><span class="nx">text</span><span class="p">()))</span></span><span id="LC10" class="line"><span class="p">.</span><span class="k">catch</span><span class="p">(</span><span class="nx">err</span><span class="o">=&gt;</span><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">err</span><span class="p">));</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="c1">// 加載部門數據</span></span><span id="LC13" class="line"><span class="k">else</span><span class="p">{</span></span><span id="LC14" class="line"><span class="kd">set</span><span class="p">([</span></span><span id="LC15" class="line"><span class="p">{</span><span class="na">value</span><span class="p">:</span><span class="dl">'</span><span class="s1">dept1</span><span class="dl">'</span><span class="p">,</span><span class="na">label</span><span class="p">:</span><span class="dl">'</span><span class="s1">北京分公司</span><span class="dl">'</span><span class="p">},</span></span><span id="LC16" class="line"><span class="p">{</span><span class="na">value</span><span class="p">:</span><span class="dl">'</span><span class="s1">dept2</span><span class="dl">'</span><span class="p">,</span><span class="na">label</span><span class="p">:</span><span class="dl">'</span><span class="s1">上海分公司</span><span class="dl">'</span><span class="p">},</span></span><span id="LC17" class="line"><span class="p">{</span><span class="na">value</span><span class="p">:</span><span class="dl">'</span><span class="s1">dept3</span><span class="dl">'</span><span class="p">,</span><span class="na">label</span><span class="p">:</span><span class="dl">'</span><span class="s1">-- 上海研發部</span><span class="dl">'</span><span class="p">},</span></span><span id="LC18" class="line"><span class="p">])</span></span><span id="LC19" class="line"><span class="p">}</span></span><span id="LC20" class="line"><span class="p">},</span></span><span id="LC21" class="line"></span><span id="LC22" class="line"><span class="na">onChooseAssignee</span><span class="p">:</span><span class="p">(</span><span class="kd">set</span><span class="p">)</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC23" class="line"><span class="kd">set</span><span class="p">(</span><span class="nb">Math</span><span class="p">.</span><span class="nx">random</span><span class="p">(),</span><span class="dl">"</span><span class="s2">Michael</span><span class="dl">"</span><span class="p">);</span></span><span id="LC24" class="line"><span class="p">},</span></span><span id="LC25" class="line"><span class="p">};</span></span><span id="LC26" class="line"><span class="k">return</span><span class="p">&lt;</span><span class="nc">AntdBpmn</span><span class="na">config</span><span class="p">=</span><span class="si">{</span><span class="nx">config</span><span class="si">}</span><span class="p">/&gt;;</span></span><span id="LC27" class="line"><span class="p">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>AntdBpmnConfig</strong> 説明：</p><ul><li>xmlDataUrl: 獲取 bpmn xml 數據的 URL</li><li>deptDataUrl: 獲取部門數據的 URL</li><li>onLoad: 監聽加載網絡數據，數據加載完畢後通過第二個參數 <code>set</code> 方法來設置</li><li>onChooseAssignee: 監聽選擇用户操作，選擇用户後通過第二個參數 <code>set</code> 方法來設置</li></ul><h3><a id="user-content-運行測試" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#%E8%BF%90%E8%A1%8C%E6%B5%8B%E8%AF%95"></a>運行測試</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://gitee.com/antdadmin/antd-bpmn.git</span><span id="LC2" class="line"></span><span id="LC3" class="line">npm <span class="nb">install</span></span><span id="LC4" class="line">npm run dev</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-antdadmin-技術交流羣" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#antdadmin-%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>AntdAdmin 技術交流羣</h3><p>QQ 羣：560291578</p><h3><a id="user-content-antdadmin-簡介" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#antdadmin-%E7%AE%80%E4%BB%8B"></a>AntdAdmin 簡介</h3><p>AntdAdmin 是一個致力於 <strong>中國信創</strong> 產業的前端開源框架，其底層技術棧主要以 React + Ant.design 為主。AntdAdmin 開源（或者計劃開源）的產品主要如下：</p><ul><li><strong>antd-admin</strong>：一個基於 React + Ant.Design 的中（後）台 UI 框架（準備中...）。</li><li><strong>antd-crud</strong>：一個基於 React + Ant.Design 的增刪改查高級組件（已開源：<a href="https://gitee.com/antdadmin/antd-crud">https://gitee.com/antdadmin/antd-crud</a> ）。</li><li><strong>antd-bpmn</strong>：一個基於 React + Ant.Design 的工作流設計組件（已開源：<a href="https://gitee.com/antdadmin/antd-bpmn">https://gitee.com/antdadmin/antd-bpmn</a> ）。</li><li><strong>antd-builder</strong>：一個基於 React + Ant.Design 的表單拖拽設計組件（準備中...）。</li></ul>]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/antdadmin/antd-bpmn</guid>
            <link>https://gitee.com/antdadmin/antd-bpmn</link>
        </item>
        <item>
            <title>
                <![CDATA[WxAutoExIm - 微信聊天圖片自動備份工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="project_detail_above_text_link_1" data-tracepid="project_detail_above_text_link"><a style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代 <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p>WxAutoExIm 是一款免費開源微信聊天圖片自動備份工具，自動備份微信聊天圖片到指定位置，即開即用。該工具能夠掃描 dat 加密圖片並且解密，把微信微信圖片自動備份為普通圖片。</p><p>WxAutoExIm 使用 Rust 和 C++ 開發，工具開源、解密算法不開源。</p><p><strong>運行截圖</strong></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0f7f60097376c7df3344aacf35adaba6e2e.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-1f4f2464b4440e7cadd1f23e748210200cc.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-b544656edd46ba309b4ed2b8a8b1f2f7b8c.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/wxautoexim</guid>
            <link>https://www.oschina.net/p/wxautoexim</link>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu LTS 堅持 10 年更新不動搖]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>Linux 內核開發者 Jonathan Corbet 此前在歐洲開源峯會上宣佈，LTS 內核的支持時間將<u><a href="https://www.oschina.net/news/258970/linux-gives-up-on-6-year-lts" target="_blank">從六年縮短至兩年</a></u>，原因在於缺乏使用和缺乏支持。穩定版內核維護者 Greg Kroah-Hartman 也表示「<u><a href="https://www.oschina.net/news/261164/greg-says-lf-strongly-supports-kernel-developers" target="_blank">沒人用 LTS 內核</a></u>」。</p><p>近日，Ubuntu 開發商 Canonical <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Flinux-kernel-lts" target="_blank">發表博客稱</a></u>，他們會堅持為 Ubuntu LTS 版本提供 10 年的更新支持。</p><blockquote><p><img height="718" src="https://static.oschina.net/uploads/space/2023/1027/105620_6hYU_2720166.png" width="1527" referrerpolicy="no-referrer"></p></blockquote><p>Canonical 在博客寫道：</p><blockquote><p><strong>Ubuntu 為您提供 10 年的穩定性</strong></p><p>近二十年來，Canonical 一直是 Ubuntu Linux 內核最重要的 LTS 提供商。 我們每兩年發佈一個新的 LTS 內核，並總共維護 10 年。我們為 LTS 內核提供為期五年的安全更新，並可以選擇通過擴展安全維護 (ESM) 將維護窗口延長至 10 年。</p><p>Canonical 的專門工程團隊負責維護所有 Ubuntu 內核、管理 Linux 內核 CVE，並針對關鍵缺陷應用提供相關補丁。 內核高可靠性是我們設計和工程決策的核心，並且由於 Ubuntu 在生產環境中的廣泛使用，我們處於不斷提高可靠性的有利位置。</p><p>Ubuntu 內核經過嚴格的測試、完善和改進，使其成為計算領域中經過最嚴格生產測試的內核之一。</p><p>Canonical 的維護和支持工作完全獨立於上游 LTS，並將像以前一樣繼續進行。 儘管上游 LTS 支持發生了變化，Canonical 仍然致力於為 Ubuntu 內核提供可靠的支持，確保 Linux 社區和企業可以繼續依賴穩定和安全的軟件。</p></blockquote><p>鑑於 Linux 內核維護週期即將發生的變化，Canonical 這番對長期支持的承諾顯得更加重要。畢竟維護 Linux 內核需要大量的專業知識，這在處理設計為長壽命的產品時變得尤其具有挑戰性，意味着組織可能會在維護和核心業務目標之間進行權衡。</p><p>Canonical 提供了生產級軟件分發機制，以及一致的可靠安全更新流。該方法已經在生產環境中經過嚴格測試，從基本操作系統和關鍵軟件包的安全更新擴展到基礎設施組件和應用程序。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263647/ubuntu-linux-kernel-lts-10yr</guid>
            <link>https://www.oschina.net/news/263647/ubuntu-linux-kernel-lts-10yr</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米澎湃 OS 正式發佈，Xiaomi Vela 將開源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">在小米澎湃 OS 暨小米 14 系列新品發佈會上，雷軍<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FyVatKNDYaEPabwTyVN-1wQ" target="_blank">宣佈</a>正式發佈全新操作系統小米澎湃 OS（Xiaomi HyperOS），並表示計劃開源其</span><span style="background-color:#ffffff; color:#222222">自研的 Xiaomi Vela 系統內核。</span></p><p><span style="color:#000000">雷軍介紹稱，小米集團的全新戰略是：從「手機 × AIoT」，升級「人車家全生態」；而承接新戰略的關鍵就是小米澎湃 OS。小米澎湃 OS 是一套完整的跨端系統，歷經 13 年探索，歷時 7 年研發而成。定位為：以人為中心，打造「人車家全生態」操作系統，「這是一次史無前例的系統底層重構，工作量非常大。」</span></p><p><span style="color:#000000">小米在其中投入了 5000 名工程師，並在設計之初提出了五大設計目標：</span></p><p><span style="color:#000000"><img alt="" height="214" src="https://oscimg.oschina.net/oscnet/up-d67d41e84ecbf23996764d026e5488dca64.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">有關小米澎湃 OS 的具體介紹如下：</span></p><h4><span style="color:#000000"><strong>底層重構，全面發揮設備性能</strong></span></h4><p><span style="color:#000000">在最底層的系統內核層，該團隊將自研的 Xiaomi Vela 系統內核與深度修改的 Linux 系統內核進行融合，重構了性能調度、任務管理、內存管理、文件管理等各個基礎模塊，實現了性能、效率的大幅提升。</span></p><p><img height="286" src="https://oscimg.oschina.net/oscnet/up-d6f930b8ab8ba527d90f18c59826a999496.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">核心系統</span></strong></p><p><span style="color:#000000">小米澎湃 OS 核心系統有幾大特性：</span></p><ul><li><span style="color:#000000">第一擁有強大的異構硬件兼容性，支持 200+處理器平台，20+文件系統，200+硬件品類。</span></li><li><span style="color:#000000">第二靈活性極高，運行空間支持從 64KB 到 24GB。</span></li><li><span style="color:#000000">第三能基於不同硬件為其配置必需資源，加上底層 IO 技術棧的文件去重和壓縮，極大幅度精簡固件。</span></li></ul><p><img height="222" src="https://oscimg.oschina.net/oscnet/up-25826e7e57ee3d5a04ba79dba779d18aae1.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">調度</span></strong></p><p><span style="color:#000000">小米澎湃 OS 最重要的能力之一，就是調度發揮卓越的硬件性能，在高算力設備上，比安卓原生內核更快；在輕量設備上，比行業頭部的輕量商用 OS 內核更快。</span></p><p><img height="216" src="https://oscimg.oschina.net/oscnet/up-a882b1b6dda5967319c78b674b3f2f79ddb.png" width="500" referrerpolicy="no-referrer"></p><p><img height="213" src="https://oscimg.oschina.net/oscnet/up-c387fd4b4d70612b9a77ab035899d5ec0c2.png" width="500" referrerpolicy="no-referrer"></p><p><img height="218" src="https://oscimg.oschina.net/oscnet/up-53fa103f3764054071491e3007e71a0e68f.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">當然快是不夠的，最重要的是精準。一部手機上可能同時運行着上萬個線程，原生 OS 一般把線程分為兩類，優先與普通，以一個相對固定的週期評估負載，但在複雜場景下，系統評估是趕不上負載變化速度的。而小米澎湃 OS 分類則更為細緻，系統評估週期會跟根據任務執行時間動態變化。</span></p><p><img height="221" src="https://oscimg.oschina.net/oscnet/up-29854cac511f0e6b6c4decdd6946869cdff.png" width="500" referrerpolicy="no-referrer"></p><p><img height="216" src="https://oscimg.oschina.net/oscnet/up-64a77dd556ef86efd43c9523eeeee73df0e.png" width="500" referrerpolicy="no-referrer"></p><p><img height="213" src="https://oscimg.oschina.net/oscnet/up-d28c5e7c0d63a43eee257cfe399b1711a68.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">此外，系統會進一步分析線程間的依賴關係來進行染色，根據染色關聯關鍵任務，對 CPU 進行精準負載評估。在算力有限的輕量設備上，系統還可以把任務拆分到多個運算單元上協同計算，最大化發揮硬件性能。精準的調度能力，保障流暢體驗的同時，也會帶來優異的功耗表現。</span></p><p><img height="200" src="https://oscimg.oschina.net/oscnet/up-0f7813b86fdcabef979795c3c11eb192399.png" width="354" referrerpolicy="no-referrer">&nbsp;<img height="200" src="https://oscimg.oschina.net/oscnet/up-6b034e2a0fa168a6eebcea06c617aa8e125.png" width="356" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">重構內存管理</span></strong></p><p><span style="color:#000000">小米澎湃 OS 獨特的內存管理機制，通過精準化一體評估、提前分配、及時回收與分級加速，帶來了超強性能和駐留表現。連續啓動 30 個應用，耗時最短，連續啓動 30 個應用兩輪，駐留數量最多。</span></p><p><img height="218" src="https://oscimg.oschina.net/oscnet/up-e19c1e0d7f4b89bd0b55de98c35e1381549.png" width="500" referrerpolicy="no-referrer">&nbsp;<img height="217" src="https://oscimg.oschina.net/oscnet/up-ac82a08de7db5d164f1df951790c87ed110.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">重構文件管理</span></strong></p><p><span style="color:#000000">重構了文件系統，軟硬結合，小米澎湃 OS 可達到 50 個月性能衰減幾乎為零，徹底告別手機越用越卡的情況。</span></p><p><img height="217" src="https://oscimg.oschina.net/oscnet/up-af646f4e4505f07e67c5bad89fb2e01bbd4.png" width="500" referrerpolicy="no-referrer">&nbsp;<img height="216" src="https://oscimg.oschina.net/oscnet/up-ef2debedf7f852355407e67349f6663921b.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">重構網絡系統</span></strong></p><p><span style="color:#000000">小米澎湃 OS 重構了網絡系統，在高鐵、微信語音、遊戲平均時延、WLAN 峯值帶寬方面也有着卓越的表現。</span></p><p><img height="218" src="https://oscimg.oschina.net/oscnet/up-de377c6d0687460d25cebb0f4d397263998.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">重構圖形子系統</span></strong></p><p><span style="color:#000000">小米澎湃 OS 重構了圖形子系統，能輕鬆實現高質量的渲染效果。在系統中實現複雜模糊混色的多級渲染，支持非常獨特的「動態玻璃」效果，實時模擬玻璃的光影變幻，還能實現柔和的空間投影、實時渲染光照效果。</span></p><p><img height="200" src="https://oscimg.oschina.net/oscnet/up-8de2aaf1f3314363bacc2a90071d2dcb2df.jpg" width="467" referrerpolicy="no-referrer">&nbsp;<img alt="" height="200" src="https://oscimg.oschina.net/oscnet/up-1fb227a7f81ab447db52e79ee4ffacc5730.jpg" width="467" referrerpolicy="no-referrer"></p><p><img alt="" height="200" src="https://oscimg.oschina.net/oscnet/up-a1937dee1d1a9d003589816b3e84675384d.jpg" width="467" referrerpolicy="no-referrer">&nbsp;<img alt="" height="200" src="https://oscimg.oschina.net/oscnet/up-87292ec26024ee0889ce096559f59d4f4a8.jpg" width="467" referrerpolicy="no-referrer"></p><p><img alt="" height="200" src="https://oscimg.oschina.net/oscnet/up-071784a287dd7ddbb9f252d0444b9454d04.jpg" width="467" referrerpolicy="no-referrer"></p><h4><span style="color:#000000"><strong>跨端智聯，助力設備高效連接</strong></span></h4><p><strong><span style="color:#000000">Xiaomi HyperConnect 跨端互聯框架</span></strong></p><p><span style="color:#000000">小米自研了澎湃跨互聯框架「Xiaomi HyperConnect」。在小米澎湃 OS 下，設備能動態實時組網。</span></p><p><img height="286" src="https://oscimg.oschina.net/oscnet/up-c0b728fbf2a5bd496b5eeef31cfa86f25cf.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#000000">融合設備中心</span></strong></p><p><span style="color:#000000">以及設計了融合設備中心，使得用户可以隨時看到設備的聯網情況。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-c376c4267d44901e1491ef37d3c40289773.gif" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">不僅是手機、PAD 等個人設備，這個能力也開放給了智能家居領域。比如，空調能自動根據人數調温度、家裏的監控能自動幫你找寵物在哪。</span></p><p><span style="color:#000000"><img alt="" src="https://oscimg.oschina.net/oscnet/up-119e9537e04527326e487b7f4af48e1e9a0.gif" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">還可以根據自己的喜好進行編排、比如打個響指屋裏的燈都亮了、家裏的燈能隨着音箱的律動變化等。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-19bafac7985dccdca8a4b0761a51c2fc1f5.gif" width="500" referrerpolicy="no-referrer"></span></p><h4><span style="color:#000000"><strong>主動智能，迎接前沿 AI 技術落地</strong></span></h4><p><span style="color:#000000">雷軍認為，主動智能是未來操作系統的一個重要特質。所以，他們推出了「Xiaomi HyperMind」，一個跨越多端的智能思考中樞，可以感知你的日常習慣，為你提供自動化建議。</span></p><p><img height="218" src="https://oscimg.oschina.net/oscnet/up-265b627d96de3081670ac0c519e29d66921.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">此外，整個系統也使用了非常多基於 AI 大模型的功能，支持實時字幕、小愛輸入助手、AI 寫真、AI 妙畫、AI 搜圖等功能。</span></p><p><img height="216" src="https://oscimg.oschina.net/oscnet/up-591fa655eb5152842eb5e1c0ebc0ae913ca.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">大模型對算力和技術架構都有着極高的要求，一般都是在雲端使用的。小米澎湃 OS 的 AI 子系統支持最新的大模型 NPU 部署技術，很快就能在手機端側直接運行。</span></p><p><img height="216" src="https://oscimg.oschina.net/oscnet/up-6145795b903e6a2c89f657bc77d56c4b07f.png" width="500" referrerpolicy="no-referrer">&nbsp;</p><p><img height="217" src="https://oscimg.oschina.net/oscnet/up-06ce6ce252c420d24be08fb754b4fa113e2.png" width="500" referrerpolicy="no-referrer"></p><p><img height="218" src="https://oscimg.oschina.net/oscnet/up-e909ed213e586f1d7d9574b125b44647f24.png" width="500" referrerpolicy="no-referrer"></p><h4><span style="color:#000000"><strong>全端安全隱私，單設備、跨設備都安全</strong></span></h4><p><span style="color:#000000">安全隱私框架的基礎，是小米自主研發的底層安全系統 TEE，它擁有獨立的內核，在使用 CPU、內存等資源時，在硬件層面完全隔離。TEE 系統通過形式化方法進行嚴格的數學邏輯推導和證明，保障系統達到」數學意義"上的嚴格安全。</span></p><p><img height="223" src="https://oscimg.oschina.net/oscnet/up-aed7af72b22cc55003730454c86363a8683.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">開發團隊同時加持了跨端安全隱私體系，每台設備是否安全，不是由設備自己判斷，而是設備間基於安全子系統相互判斷，保障整個設備網絡更加安全；同時在數據傳輸的鏈路使用硬件級 TEE 端到端加密，達到互聯網的全面安全。 並將隱私保護從單端擴充到了多設備，支持互聯權限管理、互聯行為提醒和記錄</span></p><h4><span style="color:#000000"><strong>開發生態，與全球開發者共建共創</strong></span></h4><p><span style="color:#000000">Xiaomi HyperConnect 將向 APP 開發者、智能硬件開發者開放。包括了應用開發者和智能硬件開發者，目前已有超過 9000 家智能硬件設備廠商接入，全面覆蓋 200 餘個品類。</span></p><p>「<span style="color:#000000">Xiaomi Vela 也將開源，為全球開發者貢獻力量。</span>」</p><p><span style="color:#000000">小米澎湃 OS 的首批發布計劃如下：</span></p><p><span style="color:#000000"><img alt="" height="667" src="https://oscimg.oschina.net/oscnet/up-bc51697f057c9f360a911c06e73d039ea6b.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">有關此次發佈會的更多詳情，可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FyVatKNDYaEPabwTyVN-1wQ" target="_blank">此處</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263645</guid>
            <link>https://www.oschina.net/news/263645</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[no-GIL Python，啓動！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>CPython 核心開發者 Thomas Wouters 代表 Python 指導委員會宣佈：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.python.org%2Ft%2Fpep-703-making-the-global-interpreter-lock-optional-in-cpython-acceptance%2F37075" target="_blank"><strong>正式接受 PEP 703 提案</strong></a></u>。</p><blockquote><p>PEP 703（Making the Global Interpreter Lock Optional，讓全局解釋器鎖成為可選），簡稱<strong> no-GIL</strong>，也被稱為自由線程 (free-threaded)。</p></blockquote><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-c596a475dbbae0dd91e3f3072a9b309f794.png" referrerpolicy="no-referrer"></p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">根據提案的描述，CPython 的全局解釋器鎖 (GIL) 阻止了同時多線程執行代碼，成為了在多核 CPU 上提高 Python 代碼運行效率的一大障礙。PEP 703 提案建議向 CPython 添加構建配置 (<code>--disable-gil</code>)，使其在沒有全局解釋器鎖的情況下運行 Python 代碼，並進行必要的更改以保證解釋器線程安全。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Thomas Wouters 表示，Python 指導委員會當然很清楚 no-GIL 意味着什麼，社區普遍也是秉承支持的態度，畢竟它為 Python 帶來巨大好處。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">但與此同時，<span><span><span>委員會擔心移除 GIL 會破壞目前的所有擴展模塊，或者顯着降低 CPython 的性能或可維護性。</span></span></span><span><span><span>此外，</span></span><span><span>第三方 PyPI 軟件包生態系是 Python 的一大優勢，與 C 語言庫的緊密、高效集成則是 CPython 的優勢之一。</span></span><span><span>它們使得存在多種軟件包選擇成為可能，這是 Python 的獨特賣點。</span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span><span>因此他們需要謹慎實現 no-GIL，避免破壞這些優勢，或者導致其他開發者放棄數十年的軟件包開發。</span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span><span>由於還沒有實現 no-GIL，評估實際影響以及讓第三方軟件包適應新的自由線程的實用性是很困難的。尤其是</span></span><span><span>與線程相關的問題的不可預測性更是讓難度升級，</span></span></span><span><span><span>因為有些問題只有在顯着負載下才會暴露。</span></span></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span><span><span>目前</span></span></span> Python 指導委員針對 no-GIL 的實現計劃分成三個階段：</p><ol><li style="text-align:left"><strong>實驗階段</strong>。通過提供 build-time 選項，讓開發者在構建時選擇啓用自由線程 (free-threaded)。在此階段對外明確告知<span><span><span>是實驗性的，不支持用於生產環境。</span></span></span></li><li style="text-align:left"><strong>支持但不默認階段</strong>。<span><span><span>該階段將在 API 和 ABI 變更充分解決，並且有足夠的社區支持時開始啓動。</span></span></span></li><li style="text-align:left"><strong>默認階段</strong>。此時默認啓用自由線程（初期仍支持禁用），但此階段確切的標準很難確定，目標是使開發者儘可能無縫且無痛地進行升級和兼容。</li></ol><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.python.org%2Ft%2Fpep-703-making-the-global-interpreter-lock-optional-in-cpython-acceptance%2F37075" target="_blank">點此查看詳情</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 25 Oct 2023 10:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263570/pep-703-acceptance</guid>
            <link>https://www.oschina.net/news/263570/pep-703-acceptance</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI、谷歌微軟等設立 1000 萬美元 AI 安全基金]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">谷歌、微軟、OpenAI 和 Anthropic <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Ffrontier-model-forum-updates" target="_blank">發佈聯合聲明</a>，任命美國智庫學會高管 Chris Meserole 為前沿模型論壇 (Frontier Model Forum) 首任執行董事。並宣佈設立 1000 萬美元的 AI 安全基金，「以推動正在進行的工具開發研究，幫助社會能夠有效地測試和評估最有能力的 AI 模型。」</span></p><p><span style="color:#000000">前沿模型論壇由微軟、OpenAI、谷歌和 Anthropic 在今年 7 月聯合創立而成，是一個專注於確保安全和負責任地開發前沿人工智能模型的行業機構。該論壇旨在幫助：</span></p><ul><li><span style="color:#000000">推動人工智能安全研究，促進負責任地開發前沿模型並最大限度地降低潛在風險；</span></li><li><span style="color:#000000">確定前沿模型的安全最佳實踐；</span></li><li><span style="color:#000000">與政策制定者、學術界、民間社會和其他方面分享知識，推動負責任的人工智能發展；</span></li><li><span style="color:#000000">以及<span style="background-color:#ffffff">大力支持開發有助於應對社會挑戰的 AI 應用程序</span>。</span></li></ul><p><img height="243" src="https://oscimg.oschina.net/oscnet/up-08b8848cddef1c10504a853bad39c129725.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">公告指出，AI 安全基金<span style="background-color:#ffffff">將支持來自世界各地附屬於學術機構、研究機構和初創公司的獨立研究人員。初始資金來自 Anthropic、谷歌、微軟和 OpenAI，以及其他慈善合作伙伴。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">基金的主要重點將在於，</span><span style="background-color:#ffffff">支持開發新的模型評估技術，以幫助開發和測試前沿系統潛在危險能力的評估技術。「我們相信，增加該領域的資金將有助於提高安全標準，併為行業、政府和民間社會應對 AI 系統帶來的挑戰所需的緩解和控制提供見解。&nbsp;」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">該基金將在未來幾個月內徵集提案。</span>前沿模型論壇還計劃<span style="background-color:#ffffff">成立一個顧問委員會，以幫助指導其戰略和優先事項。</span></span></p><hr><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">1000 萬美元不算小數目，但在 AI 安全研究的背景下以及與前沿模式論壇成員在商業活動上的花費相比，這一數目就「顯得相當保守了」。科技媒體&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F25%2Fai-titans-throw-a-tiny-bone-to-ai-safety-researchers%2F" target="_blank">TechCrunch</a> 指出，僅今年一年，Anthropic 就從亞馬遜籌集了數十億美元，用於開發下一代 AI 助手，此前谷歌也向其投資了 300 美元。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">且與其他 AI 安全基金相比，該基金的規模也很小。根據博客 Less Wrong 的</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGpFFJo2uFe5ssgEb%2Fan-overview-of-the-ai-safety-funding-situation" target="_blank">分析</a><span style="color:#000000">，由 Facebook 創始人 (Dustin Moskovitz 聯合創辦的資助和研究基金會 Open Philanthropy 已為 AI 安全捐贈了約 3.07 億美元。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">公益公司「The Survival and Flourishing Fund」也已向 AI 安全項目捐贈了約 3000 萬美元。美國國家科學基金會表示，未來兩年將斥資 2000 萬美元用於 AI 安全研究，部分資金由 Open Philanthropy 資助。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「</span><span style="color:#000000">前沿模型論壇暗示下一步將成立一個規模更大的基金。如果這一目標實現，它可能有機會推動 AI 安全研究 —— 前提是我們相信該基金的明確營利性支持者不會對研究施加不當影響。但無論你如何劃分，<strong>首批資金似乎都過於有限，無法取得多大成就。</strong></span><span style="color:#000000">」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 25 Oct 2023 08:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263552/frontier-model-forum-ai-safety</guid>
            <link>https://www.oschina.net/news/263552/frontier-model-forum-ai-safety</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 11 和 Java 17 使用率均超 Java 8]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 請你來轟趴啦！1028 蘇州源創會，一起尋寶 AI 時代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">Java 軟件供應商&nbsp;Azul <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.azul.com%2Fnewsroom%2Fazul-state-of-java-survey-report-2023-businesses-exploring-java-alternatives%2F" target="_blank">發佈</a>了首份年度 Java 現狀調查報告，基於對全球 2062 名 Java 專業人士和基於 Java 的應用程序用户進行的調查。調查探討的領域包括 Java 採用趨勢、Oracle 最新 Java 定價變化的影響、Java 應用程序向雲的遷移以及公司如何優化雲成本，以及常見漏洞和暴露 (CVE) 的安全注意事項。</span></p><p><span style="color:#000000"><img alt="" height="340" src="https://oscimg.oschina.net/oscnet/up-ae384b843fd1f2008ed4e7affed0c1bd24a.png" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">結果表明，<strong>Java 的採用依然強勁</strong>，98% 的受訪者表示在他們的軟件應用程序或基礎架構中使用了 Java。其中 57% 的受訪者表示，他們至少 60% 的應用程序是基於 Java 的；有&nbsp;<span style="background-color:#ffffff">66% 的公司為 Java 支持付費。</span></span></p><p><span style="color:#000000">2018 年 9 月發佈的 Java 11 和 2020 年 9 月發佈的 Java 17 是使用最廣泛的 Java 版本，使用率分別為 48% 和 45%。其次是 2014 年 3 月發佈的 Java&nbsp;8，使用率為 40%。<span style="background-color:#ffffff">85% 的受訪者使用的是 LTS 版本的 Java，64% 的受訪者使用了多個 Java 版本。</span></span></p><p><span style="color:#000000"><strong>Oracle 的 Java 市場份額正在下降</strong>。在使用 Oracle Java 的受訪者中，82% 的人表示對 1 月份推出的新 Java SE 通用訂閲定價模式感到擔憂。受 Oracle 最新的定價政策影響，72% 的受訪者表示他們正在考慮使用 OpenJDK 等開源替代品；而在沒有考慮採用開源替代方案的受訪者中，有 14% 的人表示，是因為他們沒有想到可以這樣做。</span></p><p><span style="color:#000000">但僅管如此，Oracle 仍然是 Java 市場的強大參與者。42% 的受訪者表示他們仍然使用至少一個 Oracle Java 實例，不過其中 74% 的組織表示他們還使用至少一個 OpenJDK 供應商的 JDK。大約 60% 的公司選擇了 OpenJDK 發行版而不是 Oracle Java SE。</span></p><p><span style="color:#000000"><strong>90% 的受訪者在雲環境中使用 Java</strong>：公有 (48%)、私有 (47%) 或混合 (40%)。雲格局正在迅速轉變，組織不斷向雲邁進，以實現可擴展性、靈活性、生產力和敏捷性，但成本和安全性仍然是兩個主要挑戰。</span></p><p><span style="color:#000000">近 70% 的公司表示，他們正在為至少 20% 的未使用雲容量付費，「這是過度配置雲資源的明顯跡象」。<span style="background-color:#ffffff">95% 的公司在過去一年中採取了降低雲成本的措施</span>，46% 的企業正在利用高性能 Java 平台更有效地使用雲資源。</span></p><p><span style="color:#000000"><strong>Log4Shell 漏洞對組織產生了廣泛的安全影響。</strong>近 80% 的受訪者表示受到了 2021 年 Log4J 庫漏洞的影響。近一半的公司在該漏洞出現後不得不分配額外的工程時間，30% 的公司受到嘗試利用此漏洞的影響。</span></p><p><span style="color:#000000">近三分之二的調查受訪者明確表示，第三方和開源應用程序及庫是最令人擔憂的 CVE 來源。其中 57% 的受訪者將開源庫和應用程序列為最令人擔憂的 CVE 來源，51% 的受訪者認為第三方庫和應用程序是最令人擔憂的 CVE 來源。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.azul.com%2Freport%2F2023-state-of-java%2F" target="_blank">查看完整報告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 25 Oct 2023 07:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263544/azul-state-of-java-survey-report-2023</guid>
            <link>https://www.oschina.net/news/263544/azul-state-of-java-survey-report-2023</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
