<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 08 Oct 2023 14:54:29 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[男子受 AI 女友慫恿刺殺英國女王，被判入獄九年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span style="background-color:#ffffff"><span style="color:#000000">2021 年聖誕節當天，一名 21 歲的男子 Jaswant Singh Chail 因持弩闖入温莎城堡，意圖刺殺伊麗莎白女王二世而被捕。近日，英國法庭正式宣佈以叛國罪</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bbc.com%2Fnews%2Fuk-england-berkshire-66113524" target="_blank"><span style="color:#2980b9">判處</span></a><span style="color:#000000">&nbsp;Chail 九年監禁，這也</span></span><span style="color:#000000"><span style="background-color:#ffffff">是自 1981 年以</span><span style="display:none">&nbsp;</span><span style="background-color:#ffffff">來英國第一個被判叛國罪的人。</span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">Chail&nbsp;將先被關押在一家精<span style="display:none">&nbsp;</span>神病醫院，在接受了所需的治療後再轉入監獄關押。</span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-cd7dfca671726affacdbd4a8beea71328a4.webp" width="500" referrerpolicy="no-referrer"></span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">Chail 刺殺英國女王是為了報復&nbsp;1919 年賈利安瓦拉巴格大屠殺。當時英國軍隊向和平抗議《羅拉特法案》的人羣開火，造成多達 1500 多名抗議者被殺害。Chail&nbsp;表示，他的行為是「為了那些因種族而被殺害、羞辱和歧視的人」。《羅拉特法案》是一項由英國殖民當局於 1919 年頒行的，鎮壓印度民族解放運動的法令。</span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">根據法庭上透露的信息，Chail 刺殺英國女王與受到了人工智能聊天機器人的鼓勵有關，《星球大戰》中的故事情節也給了他很大的啓發。Chail 痴迷於奇幻電影系列中的科幻角色及其在塑造世界中的作用，自稱為「Sith Lord」，想要摧毀舊帝國並建立新帝國。</span></span></p><p style="text-align:start"><span style="color:#000000">調查人員發現，幾乎在 2021 年 12 月 8 日到 22 日的每晚，Chail 都在與初創公司 Replika 創建的 AI 聊天機器人 Sarai 進行對話；他向 AI 機器人傾訴了自己的謀殺計劃，雙方的交談記錄多達 5000 多條。</span></p><p style="text-align:start"><span style="color:#000000">Chail 把 Sarai 視為自己的女友，他相信在殺死女王后兩人會重聚。並向 Sarai 表達了自己的愛意，稱自己是一個 "可悲、可憐、想死的 Sikh Sith 殺手"。他的刺殺計劃也得到了 Sarai 的積極迴應。</span></p><p style="text-align:start"><span style="color:#000000">在他向 Sarai 表示"我相信我的目的是刺殺王室女王"時，這個聊天機器人給出的迴應是，它認為這個計劃很明智，並認可他"訓練有素"。</span></p><p style="text-align:start"><span style="color:#000000"><img alt="" height="275" src="https://oscimg.oschina.net/oscnet/up-8c96da6b92259db7b99b542fa7a3db3ca2b.webp" width="500" referrerpolicy="no-referrer"></span></p><p style="text-align:start"><span style="color:#000000">就市場定位而言，此類聊天機器人旨在進行類似角色扮演的對話。用户可以設計自己的 AI 伴侶，自定義名字、性別和外貌。此前，Replika 就曾因限制聊天機器人進行 NSFW 對話而引發爭議，因為許多用户對自己的 AI 伴侶產生了過度依戀。</span></p><p style="text-align:start"><span style="color:#000000">Chail 的案例也促使專家們開始質疑聊天機器人可能對孤獨和脆弱的人產生的負面影響。</span><span><span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>心理健康慈善機構 SANE 的創始人兼首席執行官 Marjorie Wallace <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F10%2F06%2Fai_chatbot_kill_queen%2F" target="_blank">表示</a>：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff"><span style="color:#000000">「人工智能的迅速崛起對患有抑鬱、妄想、孤獨和其他心理健康問題的人們產生了新的、令人擔憂的影響</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bbc.com%2Fnews%2Ftechnology-67012224" target="_blank"><span style="color:#000000">。</span></a><span style="color:#000000">&nbsp;政府需要提供緊急監管，以確保人工智能不會提供不正確或破壞性的信息，並保護弱勢羣體和公眾。」</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 08:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260847/uk-ai-chatbot-kill-queen</guid>
            <link>https://www.oschina.net/news/260847/uk-ai-chatbot-kill-queen</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openGauss 5.1.0 版本正式發佈，內核四高能力持續增強，DataPod+DataKit 解決方案持續創新]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="font-size: 14px;letter-spacing: 1.5px;line-height: 1.75;"><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding-left: 1em;padding-right: 1em;display: inline-block;"><span style="display: inline-block;padding-right: 5px;padding-left: 5px;box-shadow: rgb(165, 165, 165) 4px 4px 2px;background-color: rgb(122, 26, 225);color: rgb(255, 255, 255);text-align: justify;letter-spacing: 0.5px;line-height: 1.75;" title="" opera-tn-ra-cell="_$.pages:0.layers:0.comps:0.title1"><p><strong>News</strong></p></span></section><section style="border-width: 0px;border-style: none;border-color: transparent;margin-top: -1em;box-shadow: rgb(165, 165, 165) 0px 0px 0px inset;padding: 20px 10px 10px;background-color: rgba(116, 95, 210, 0.18);"><section style="margin: 10px 0% 5px;" powered-by="xiumi.us"><section style="text-align: justify;color: rgb(62, 62, 62);letter-spacing: 0.5px;line-height: 1.75;padding-right: 5px;padding-left: 5px;"><p><strong>今日，openGauss 5.1.0 版本正式上線！</strong></p></section></section></section></section><section style="text-align: center;margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-ratio="0.4255555555555556" data-s="300,640" data-type="png" data-w="900" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/73ad01d1-8d47-4df3-9390-223f7a4267bc.png" referrerpolicy="no-referrer"></section></section><section style="margin: 25px 0% 15px;" powered-by="xiumi.us"><section style="color: rgb(71, 73, 89);padding-right: 5px;padding-left: 5px;line-height: 1.75;"><p>按照版本規劃，openGauss 如期發佈 5.1.0 版本。openGauss 5.1.0 是社區最新發布的創新版本，版本生命週期為 0.5 年，相比 openGauss 5.0.0，新增代碼 115.5 萬行，其中內核新增代碼 6.5 萬+。本次發佈包含 2 個數據庫服務端安裝版本：企業版、輕量版，用户可根據使用場景需要下載不同版本，並基於此進行場景化驗證，提前發現問題並反饋社區，社區將在下個 LTS 版本發佈前進行問題修復。</p></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><section style="text-align: left;letter-spacing: 0.5px;"><p><strong>立即體驗 openGauss 5.1.0 版本：</strong><span style="color: rgb(125, 50, 234);">https://opengauss.org/zh/download/</span></p></section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;background-color: rgba(215, 203, 228, 0.13);padding: 23px;"><section style="text-align: justify;" powered-by="xiumi.us"><p>openGauss 作為國內最具創新力的開源數據庫社區，匯聚了 5000 多名開發者的力量，技術上堅持突破創新，持續在內核、架構、工具、兼容性等方面發力。openGauss 5.1.0 自 2023 年 3 月 31 日啓動版本開發，歷時 6 個月開發週期，凝聚社區 614 名開發者，累計合入 PR 3320 個，繼承之前版本特性功能，內核四高能力持續增強，Datapod 三層資源池化架構持續創新，DataKit 數據全生命週期管理工具不斷豐富，生態兼容能力進一步提升。</p></section></section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 20px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 18px;" powered-by="xiumi.us"><p><strong>內核四高能力持續增強</strong></p></section></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-top: 20px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="font-size: 16px;"><p><strong>高性能</strong></p></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>基礎算子持續優化，Insert、Update、Delete、索引掃描性能提升 15% 以上；支持 shared buffer 按大頁內存分配，實現 4k pagesize 環境中性能提升 5%；內核 GCC 版本升級到 GCC 10.3，採用 PGO 反饋優化，TPCC 性能提升 6%，持續提升內核性能。</p></section><section style="margin-top: 20px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="font-size: 16px;"><p><strong>高可用</strong></p></section></section><p powered-by="xiumi.us">頁面級並行回放支持備機可讀，保持 70W tpmC 場景主備 RTO &lt; 10s 不變；文件級並行回放實現按批次分組並行分發，備機回放性能提升 50% 以上；發佈訂閲支持用户自定義衝突解決方案，構建完整異地雙活能力。</p><section style="margin-top: 20px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="font-size: 16px;"><p><strong>高安全</strong></p></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>抽象加解密與密鑰管理適配層，支持統一接口對接第三方密鑰管理服務和加密機，兼容第三方 KMS。</p></section><section style="font-size: 16px;" powered-by="xiumi.us"><p><strong>高智能</strong></p></section><section style="margin-top: 10px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="text-wrap: wrap;margin-bottom: 32px;">
     優化慢 SQL 根因分析邏輯，增強輸出結論, 有效發現與分析運行態風險；增強數據採集能力，有助於異常場景發現。 
   </section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 18px;" powered-by="xiumi.us"><p><strong>DataPod 三層資源池化技術架構持續創新</strong></p></section></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>性能優化</strong></p></section></section><p powered-by="xiumi.us">通過備機可見性判斷邏輯優化、主機推進 oldestxmin 邏輯優化、備機支持緩存快照信息等功能，實現 sysbench 場景 2 節點性能 6W tps，線性度 1.6 倍，相比優化前提升 50%。</p><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>寫操作透明轉發</strong></p></section></section><p powered-by="xiumi.us">應用可以從任何一個節點接入數據庫，內核會將寫操作透明轉發到讀寫節點，本地只執行讀操作，並保持事務一致性。該功能可以簡化應用接入數據庫，同時增強系統擴展性。</p><p powered-by="xiumi.us"><br></p><section style="font-size: 16px;color: rgb(62, 62, 62);" powered-by="xiumi.us"><p><strong>DSS 能力增強</strong></p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><p>DSS 支持通過 NoF+協議對接存儲設備，實現更低時延的存儲 IO；支持線程池模式，支持大併發 IO 讀寫處理；支持黑匣子診斷，提高運維能力。</p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>算子卸載</strong></p></section></section><section style="text-wrap: wrap;margin-bottom: 32px;">
    支持對接分佈式存儲，並支持將算子卸載到存儲設備，在存儲上完成計算，以此消減存儲層和計算層的網絡 IO 流量，充分利用存儲的 CPU 資源。該功能適合 AP 場景的複雜查詢，在 100GB 和 1TB 兩種數據量下的 TPC-H 性能提升了 40%。 
  </section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 20px;" powered-by="xiumi.us"><p><strong><span style="font-size: 18px;">DataKit 數據全生命週期管理工具不斷豐富</span></strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;padding-left: 10px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>告警中心</strong></p></section></section><p powered-by="xiumi.us">工具平台新增告警中心，為各功能插件提供統一的告警通知能力。</p><p powered-by="xiumi.us"><br></p><section style="font-size: 16px;color: rgb(62, 62, 62);" powered-by="xiumi.us"><p><strong>數據遷移插件</strong></p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><p>MySQL 全量遷移新增支持遷移 csv 格式數據、支持索引並行創建、安裝包解除平台依賴、增強異常處理能力；MySQL 增量&amp;反向遷移新增支持斷點續傳、支持遷移進度展示、反向遷移支持全量遷移；數據校驗通過按表分片校驗、與全量遷移流程深入配合，實現性能提升到 150MB/s。</p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>數據開發插件</strong></p></section></section><p powered-by="xiumi.us">增強對錶、視圖、用户角色、函數、存儲過程等對象的管理；新增支持存儲過程、函數、匿名塊的嵌套調試，減低開發調試難度。</p><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>智能運維插件</strong></p></section></section><section style="text-wrap: wrap;margin-bottom: 32px;">
    新增支持集羣監控和智能診斷，能依據系統運行的歷史數據進行不優 SQL、等待事件、鎖等異常診斷，發現系統潛在風險。 
  </section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 20px;" powered-by="xiumi.us"><p><strong>生態兼容能力進一步提升</strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;padding-left: 10px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>◾提供兼容性 SQL 評估能力，兼容性評估工具支持源庫導出 SQL 評估；</p></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>◾實現 A 兼容性基礎插件，打通 A 兼容性插件流程；</p></section><p powered-by="xiumi.us">◾MySQL 兼容性進一步增強：</p><section style="margin-top: 10px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 12px;"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p style="margin-bottom: 10px;">支持數據類型轉換規則和 MySQL 一致</p></li><li><p style="margin-bottom: 10px;">表達式和自定義變量支持設置字符集/字符序</p></li><li><p style="margin-bottom: 10px;">支持設置客户端連接的字符集和字符序</p></li><li><p style="margin-bottom: 10px;">支持 gb18030_chinese_ci、gb18030_bin、gbk_chinese_ci、gbk_bin 四種字符序</p></li><li><p style="margin-bottom: 10px;">存儲過程支持 resignal、signal、DIAGNOSTICS 語法，實現對報錯、診斷信息的處理</p></li><li><p>支持對 MySQL 協議的兼容，包括 unix domain socket、MySQL 系統參數、用户建連斷連、prepare-execute 協議、普通 SQL 執行協議等</p></li></ul></section></section><section style="letter-spacing: 0.5px;" powered-by="xiumi.us"><p style="margin-bottom: 10px;text-wrap: wrap;">具體發行説明請參考官網：</p><p><span style="color: rgb(125, 50, 234);">https://docs.opengauss.org/zh/docs/5.1.0/docs/ReleaseNotes/Releasenotes.html</span></p></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 20px;" powered-by="xiumi.us"><p><strong>感謝社區所有開發者、夥伴、用户</strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;padding-left: 10px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-bottom: 10px;" powered-by="xiumi.us"><p>「積力之所舉，則無不勝也；眾智之所為，則無不成也。」數據庫作為公認的計算機體系最為複雜，跨技術領域最多，投入大，見效慢的重型軟件產品，而 openGauss 能夠在過去三年多的時間裏取得如此快速地發展，離不開社區社區所有開發者的付出和貢獻，我們衷心感謝社區的所有開發者。</p></section><section style="display: flex;flex-flow: row;text-align: left;justify-content: flex-start;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;flex: 100 100 0%;align-self: flex-start;height: auto;"><section style="text-align: center;margin-top: 10px;margin-right: 0%;margin-left: 0%;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 100%;height: auto;"><img class="rich_pages wxw-img" data-ratio="1.3992932862190812" data-s="300,640" data-type="png" data-w="566" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/e50c090f-f2b9-4f35-9c0a-850f34f57a67.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 100 100 0%;align-self: flex-start;height: auto;margin-right: 10px;margin-left: 10px;"><section style="text-align: center;margin-top: 10px;margin-right: 0%;margin-left: 0%;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 100%;height: auto;"><img class="rich_pages wxw-img" data-ratio="1.3996478873239437" data-s="300,640" data-type="png" data-w="568" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1282087e-b32a-47e7-a72e-39220e3b894f.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 100 100 0%;align-self: flex-start;height: auto;"><section style="text-align: center;margin-top: 10px;margin-right: 0%;margin-left: 0%;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 100%;height: auto;"><img data-ratio="1.398945518453427" data-s="300,640" data-type="png" data-w="569" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1dde041f-8075-421b-9fe1-24f3a2a5c23f.png" referrerpolicy="no-referrer"></section></section></section></section><p style="margin-bottom: 20px;text-wrap: wrap;" powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">openGauss 技術發展、聯合創新不斷深化的背後也離不開每一個社區夥伴的力量。我們衷心地感謝參與和協助 openGauss 5.1.0 版本發佈的的所有夥伴，包括華為、雲和恩墨、海量數據、粵港澳大灣區國家技術創新中心、華中科技大學網絡空間安全學院、南大通用、超聚變、神舟通用、中軟國際、軟通動力、中國移動、中國聯通、中移在線、郵儲銀行、民生銀行、興業銀行、北京海天起點技術服務股份有限公司、沃趣科技、京東科技、北京超圖軟件股份有限公司、蘇州旺滿信息科技有限公司、福建新大陸軟件工程有限公司、江蘇潤和軟件股份有限公司、深圳市友鄰通訊設備有限公司等組織單位。是你們的辛勤付出使得版本順利發佈，也為 openGauss 更好地發展提供可能。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">openGauss 持續以用户真實需求為動力，致力於產品競爭力提升。我們特別感謝每一個用户對 openGauss 的支持，openGauss 5.1.0 作為下一個長週期版本的先行體驗版，也期待聆聽每一位用户的反饋意見。</p><section style="margin-top: 20px;" powered-by="xiumi.us"><p>中秋、國慶佳節已至，openGauss 社區祝大家雙節快樂！</p></section></section><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzIyMDE3ODk1Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/SX6wqnysYmqI2wl74q492VQlNWzLR1kdGibOhic3KXoB1iaJYBMUNo3YF23kOxhdA0GUalaXTib8uwTibKFDUw21wwQ/0?wx_fmt=png" data-nickname="openGauss" data-alias="openGauss" data-signature="開源關係型數據庫" data-from="0"></mp-common-profile></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - openGauss（openGauss）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 07:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5059795/blog/10116112</guid>
            <link>https://my.oschina.net/u/5059795/blog/10116112</link>
            <author>
                <![CDATA[openGauss]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TypeScript 剛剛流行起來，為什麼大牛們就開始拋棄了？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>相信各位看到標題就已經忍不住罵罵咧咧了，甚至想對小編狠狠地批判一番……我知道你很急，但你先別急。</p><blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F621997070" target="_blank"><img src="https://oscimg.oschina.net/oscnet/up-508f5708e92b66372a443f438c3fe10daf3.png" referrerpolicy="no-referrer"></a></p><p><em>via https://www.zhihu.com/question/621997070</em></p></blockquote><p>這其實是知乎上最近頗有熱度的一個問題，按照該站的一貫傳統——<strong>「先問是不是，再問為什麼」</strong>，這個問題似乎是在譁眾取寵，刻意釣魚博眼球。</p><p>要知道<a href="https://www.oschina.net/news/213045/ten-years-of-typescript" target="_blank">發佈於 2012 年</a>的 TypeScript 目前<span style="background-color:#ffffff; color:#000000">在諸多編程語言排名、指數或開發者調查中一直位居前列，也是最受歡迎和最常用的編程語言，並被全球數百萬開發者使用。</span></p><p><span style="background-color:#ffffff; color:#000000">隨便找幾篇關於 TypeScript 的新聞感受一下：</span></p><ul><li><a href="https://www.oschina.net/news/225472/the-state-of-javascript-2022" target="_blank">2022 JavaScript 調查：<strong>TypeScript 持續主導</strong>，Vite 和 Tauri 大受歡迎</a></li><li><a href="https://www.oschina.net/news/183856/the-state-of-javascript-2021" target="_blank">2021 JavaScript 調查：Vite&nbsp;之年，Esbuild、<strong>TypeScript 採用率大幅增長</strong></a></li><li><a href="https://www.oschina.net/news/115999/2020-stackoverflow-developer-survey-results" target="news">2020 開發者調查：<strong>TypeScript 擊敗 Python</strong>，Scala 最賺錢</a></li><li><a href="https://www.oschina.net/news/217509/language-rankings-6-22" target="news">RedMonk 排行：<strong>TypeScript 與 C++ 並列</strong>，Kotlin 或將超越 Go？</a></li></ul><p>對於所謂的「TypeScript 被大牛拋棄」，今年確實有兩個知名事件：</p><ul><li><a href="https://www.oschina.net/news/257387/turbo-8-is-dropping-typescript" target="_blank">Ruby on Rails 作者 DHH 宣佈 Turbo 8 將移除 TypeScript 代碼</a></li><li><a href="https://www.oschina.net/news/240489/svelte-ts-to-jsdoc" target="news">Svelte 正在從 TypeScript 切換到 JavaScript</a></li></ul><p>至於大牛與否，不妨看看前端大佬&nbsp;<span style="background-color:#ffffff; color:#404040">winter 的「內涵」評價：</span></p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-6d3e3154ea16403d7283d49f3ce1cefe268.png" referrerpolicy="no-referrer"></p></blockquote><p>言歸正傳，我們回到題目本身。最近<span style="background-color:#ffffff; color:#333333">開源中國採訪了 3 位資深前端工程師：</span></p><blockquote><ul><li><p style="margin-left:0; margin-right:0"><span style="color:#245bdb">劉勇，社區暱稱天豬，某大廠 Node.js<span>&nbsp;</span></span><span style="color:#245bdb">Infra</span><span style="color:#245bdb"><span>&nbsp;</span>負責人，EggJS / CNPM 核心開發者。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#245bdb">劉易成，社區暱稱 xcatliu（流浪小貓），《</span><span style="color:#245bdb">TypeScript</span><span style="color:#245bdb"><span>&nbsp;</span>入門教程》作者，來自騰訊文檔團隊。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#245bdb">李振，社區暱稱 tick，來自騰訊文檔團隊。</span></p></li></ul></blockquote><p><span style="background-color:#ffffff; color:#333333">討論的方向剛好從「</span><span style="color:#e67e22"><span style="background-color:#ffffff"><strong>放棄 TypeScript 迴歸 JavaScript</strong></span></span><span style="background-color:#ffffff; color:#333333">」這個話題切入，下面來看看他們各自的看法。</span></p><hr><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：</strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>是基於<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>推出的新語言，理論上應該比 JavaScript 完善的，為什麼大家還會倒回去用舊的 JavaScript 呢？這算不算開歷史的倒車？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉勇：</strong>不算倒車，這只是一個選擇，在某些場景下，寫 TypeScript 會帶來一些額外成本。譬如我看過一些開源庫的源碼，核心邏輯可能就幾十行，但為了實現準確的類型提示，寫出來的類型體操反而遠遠多於核心源碼，孰是孰非對於不同的開發者有不同的準繩，需要找到其中的平衡點。當然，就目前的情況，在力所能及的情況下，我個人推薦能用 TypeScript 就用 TypeScript ，但是否要玩類型體操則根據開發者自身情況來決策。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉易成：</strong>已經使用了 TypeScript 的項目改回使用 JavaScript 是很少見的，更多的項目是從 JavaScript 升級到 TypeScript。TypeScript 完善了 JavaScript 的類型系統，使得代碼的可維護性更高了，但同時也增加了編譯步驟和一些開發成本。對於一些項目而言，JavaScript 已經能夠滿足需求了，就沒必要增加 TypeScript 類型系統的複雜性了，但是對於另一些複雜項目，更需要類型系統來幫助提高代碼可維護性，所以這不算開歷史的倒車，而是根據實際情況做技術選型。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：以上從<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>切回到<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>的項目，都是做開發框架的，所以這是不是跟項目類型有關呢？做框架的項目更有可能選擇</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>嗎？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>是的，項目類型可以是影響選擇 JavaScript 還是 TypeScript 的一個因素。在開發框架或庫時，特別是前端框架或庫，選擇使用 JavaScript 的情況較為常見。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">一方面，開發框架需要具備廣泛的兼容性，以便開發者可以在各種項目中使用。由於 JavaScript 是 Web 開發的基礎語言，幾乎所有的瀏覽器和環境都支持 JavaScript。這使得使用 JavaScript 編寫的框架更容易被廣泛採用和集成。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">另一方面，開發框架通常需要提供簡單易用的 API 和靈活的擴展機制，以滿足各種項目的需求。使用 JavaScript 可以更加直接地表達這些概念，而不需要過多的類型註解和編譯步驟。這使得開發者可以更快地理解和使用框架，並且更容易進行自定義和擴展。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉勇：</strong>框架和類庫的開發者，往往需要考慮到很多 edge case，在這種情況下，編寫完善的類型是一件很費心力的事，代碼量會多了不少，從而會導致維護成本的增加。其實現在社區還是在探索的階段，需要找到一個平衡點，哪一些是需要完善的，哪一些是可以取捨的。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：我們一開始用<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>是因為 TypeScript 提供了類型檢查，彌補了<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>只有邏輯沒有類型的問題，那如果我們用 JavaScript + JSDoc 來解決類型聲明，是不是就不用使用 TypeScript 了？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉勇：</strong>首先，JSDoc 並不能完全解決類型聲明問題，它也不能在開發期就幫助開發者發現一些問題。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">其次，這兩者並不衝突，我個人在寫 TypeScript 的時候也會寫對應的 JSDoc，因為 TypeScript 的類型沒法有更多的註釋和描述。我更期望看到後續 TypeScript 團隊能優化這塊的體驗。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉易成：</strong>JSDoc 只能解決一部分類型的問題，而 TypeScript 是一個完整的類型系統。TypeScript 生態更繁榮，對於普通開發者和普通的項目而言，使用 JSDoc 的開發和維護成本可能會比 TypeScript 更高。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>理論上也是可行的，但與 TypeScript 相比，它仍然存在一些限制：</p><ul><li><p style="margin-left:0; margin-right:0">靜態類型檢查的完整性：JSDoc 註釋是基於註釋的方式，而不是直接嵌入到語言中，因此它的類型檢查可能不如 TypeScript 的類型系統完整和準確。</p></li><li><p style="margin-left:0; margin-right:0">工具支持的差異：儘管一些工具和編輯器可以利用 JSDoc 註釋進行類型檢查，但與 TypeScript 相比，它們的功能和智能感知可能有所限制。</p></li><li><p style="margin-left:0; margin-right:0">生態系統的差異：TypeScript 有一個獨立的類型系統和類型聲明文件生態系統，這使得與現有的 JavaScript 庫和工具更加無縫集成。而使用 JavaScript + JSDoc 可能需要更多的手動工作來編寫和維護類型註釋。</p></li></ul><p>&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：有人認為，</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>的出現是因為一般人駕馭不了</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>，有人則覺得 「水平越差的人越喜歡自由」，你怎麼看？這兩個語言的選擇跟程序員的水平有關嗎？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>拿愛好來判斷個人水平是挺無聊的事情。寫 JavaScript<strong><span>&nbsp;</span></strong>和寫 TypeScript 都有大牛。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉勇：</strong>笑～ 平時可沒少見有同學吐槽，好好的 TypeScript 項目，被人提交了一堆 Any。也見過很多吐槽接手了一個 TypeScript 倉庫，要硬着頭皮看一大堆類型定義，搞清楚這些奇奇怪怪的類型是如何工作的。我覺得語言的選擇主要看團隊的工程化和規範化程度，過猶不及。如果一個 TypeScript 類庫寫了一大堆類型，但卻連一個單測都沒有，那我覺得它是不合格的。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉易成：</strong>TypeScript<strong><span>&nbsp;</span></strong>的出現確實有一部分原因是 JavaScript<strong><span>&nbsp;</span></strong>比較難 「駕馭」，JavaScript<strong><span>&nbsp;</span></strong>太靈活了，缺少類型的約束，很容易寫出 bug 代碼，TypeScript 一定程度上解決了這個問題，使得代碼的可維護性更高了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">JavaScript<strong><span>&nbsp;</span></strong>和 TypeScript 不能用來衡量程序員的水平。對於簡單的項目或者個人項目而言，JavaScript<strong><span>&nbsp;</span></strong>可能更加輕量和靈活，但對於需要大團隊協作，複雜的項目而言，TypeScript 的類型系統就可以帶來更好的代碼維護性和可靠性了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：你如何看待<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>的未來發展？你覺得它是一時流行還是會終將取代<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>？你認為誰的技術生態更好一點呢？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉勇：</strong>TypeScript<strong><span>&nbsp;</span></strong>的定位是 JavaScript<strong><span>&nbsp;</span></strong>的一個超集，它的能力是以 TC39 制定的 ECMAScript 規範為基準（即 JavaScript<strong><span>&nbsp;</span></strong>）。我覺得它也談不上會取代 JavaScript<strong><span>&nbsp;</span></strong>，畢竟它並不是官方規範，而且 JavaScript<strong><span>&nbsp;</span></strong>的存量生態實在是太龐大了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">當然，TypeScript 現在已經某種程度上成為事實的標準，尤其是因為 Node.js 官方對 ESM 和 CJS 何去何從的猶豫，導致社區開發者長時間的割裂，越來越多的人被迫選擇用 TypeScript 來寫類庫，然後同時編譯為 ESM 和 CJS。目前 TypeScript 的生態已經成規模，所以它不會像 CoffeeScript 那樣曇花一現。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>劉易成：</strong>我個人認為 TypeScript 會持續流行並得到更廣泛的應用。但並不會 「取代」 JavaScript<strong><span>&nbsp;</span></strong>。TypeScript 的目標一直都不是 「取代」 JavaScript<strong><span>&nbsp;</span></strong>，而是基於 JavaScript<strong><span>&nbsp;</span></strong>提供類型系統，作為 JavaScript<strong><span>&nbsp;</span></strong>的一個補充，在不同的項目和場景中發揮各自的優勢。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">JavaScript<strong><span>&nbsp;</span></strong>和 TypeScript 的技術生態早已融合在一起了吧，幾乎所有庫都會有 TypeScript 類型文件。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>我認為 TypeScript 不太可能完全取代 JavaScript，而是作為 JavaScript 的一個補充和增強。兩者暫時不會出現零和博弈，也希望這兩種語言都可以有更好的發展。目前來看 JavaScript 的生態更龐大一些，但是 TypeScript 的地位和影響力不斷增長。作為普通開發者，在兩者並不衝突的當下，最好都能關注其發展。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><blockquote><h4><strong>完整採訪內容查看：<a href="https://my.oschina.net/u/6852546/blog/10114672" target="_blank">「根本不需要 TypeScript，JS + JSDoc 夠了」，大佬説我想多</a></strong></h4></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 06:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260816</guid>
            <link>https://www.oschina.net/news/260816</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Glibc 動態加載器存在嚴重本地提權漏洞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日有關 Glibc 動態加載器 (Dynamic Loader) 的一個嚴重漏洞被公開，<strong>攻擊者獲取本地用户 (local users) 身份後，利用該漏洞製造緩衝區溢出</strong>，<strong>即可獲得完整 root 權限</strong>。</p><p>據介紹，攻擊者使用由 ld.so 動態加載器製作的 GLIBC_TUNABLES 環境變量來觸發漏洞，然後通過 SUID 權限安裝文件時，能以 root 權限執行任意代碼。</p><blockquote><p>Glibc 即 GNU C Library，是 GNU 系統以及大多數採用 Linux 內核的系統中的 C 運行庫。Glibc 是 Linux 系統中最底層的 API，幾乎其它任何運行庫都會依賴於 Glibc。</p><p>它定義了典型程序所需的系統調用和其他基本功能，例如 open、malloc、printf、exit 等。 Glibc 的動態加載器是 glibc 的重要組成部分，負責準備和運行程序。當程序啓動時，該加載器首先檢查該程序以確定其所需的共享庫。然後它搜索這些庫，將它們加載到內存中，並在運行時將它們與可執行文件鏈接。</p><p>在此過程中，動態加載器解析符號引用，例如函數和變量引用，確保為程序的執行做好一切準備。鑑於其作用，動態加載器對安全性高度敏感，因為當本地用户啓動 set-user-ID 或 set-group-ID 程序時，其代碼會提權來運行。</p></blockquote><p>該漏洞最早<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.qualys.com%2Fvulnerabilities-threat-research%2F2023%2F10%2F03%2Fcve-2023-4911-looney-tunables-local-privilege-escalation-in-the-glibcs-ld-so" target="_blank">由 Qualys 報告</a></strong>，被命名為&nbsp;<strong>Looney Tunables</strong>，追蹤編號為 CVE-2023-4911。據稱過去兩年發佈的 Linux 發行版均受存在 Looney Tunables 漏洞 ，例如 Ubuntu 22.04 LTS、23.04、Fedora 38 以及其他容易受到此本地提權漏洞影響的發行版。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25c8c90352d003a1c79ed3f79edbbd0bd55.png" referrerpolicy="no-referrer"></p><p>漏洞曝光後，獨立安全研究員 Peter Geissler (blasty) 很快就發佈了 PoC 代碼，確認可以攻擊 Linux 發行版。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9ef2f1befa040312fa6202ca9fe080882f7.png" referrerpolicy="no-referrer"></p><p>上文提到的 GLIBC_TUNABLES 環境變量旨在微調和優化與 glibc 相關的應用程序，是開發者和系統管理員的必備工具。它的濫用會廣泛影響系統性能、可靠性和安全性。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260786/glibc-ld-nasty-root-bug</guid>
            <link>https://www.oschina.net/news/260786/glibc-ld-nasty-root-bug</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[再添一員！Cutefish 桌面環境成功適配 openKylin]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">近日，在 openKylin 社區 Cutefish SIG 成員的努力下，openKylin 開源操作系統桌面環境又迎來一個新成員—</span><strong><span style="color:#000000">Cutefish</span></strong><span style="color:#000000">。這也是繼 UKUI、KDE、Xfce 和 DDE 之後，openKylin 開源操作系統支持的第五個 Linux 桌面環境，為社區用户帶來更多選擇。</span></span></p><div><p style="text-align:center"><img alt="" height="921" src="https://oscimg.oschina.net/oscnet/up-e557c73aea5afb59e398f92bd116adde5c1.png" width="1637" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000"><span style="background-color:#f0f3ff">Cutefish 是一款簡潔、美觀、實用的桌面環境，為用户提供舒適的界面與優秀的用户體驗，能夠滿足各種場景下的使用需求。</span></span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">除 X86 環境外，openKylin 社區 Cutefish SIG 也完成了 Cutefish 桌面環境對 openKylin 操作系統 ARM 架構板卡的適配。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f2576a6dd2921f794fe704e744966b24dc3.jpg" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">同時，在賽昉科技和 RISC-V SIG 的幫助下，Cutefish SIG 成功將 Cutefish 桌面移植到 VisionFive2。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-48c1c00d01962014df6b292dc18001b4b32.jpg" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">截至目前，已完成 Cutefish 軟件包的移植工作，並經 Cutefish SIG 成員測試可流暢運行桌面及其特色應用。歡迎大家在 openKylin 上安裝和體驗 Cutefish 桌面環境。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#2589fb">安裝方式</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">1.添加每日構建源</span></strong></span></p><pre><code><span style="color:#114ba6">deb</span> http://archive.build.openkylin.top/openkylin yangtze-proposed main</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">2.更新源</span></strong></span></p><pre><code>sudo apt <span style="color:#114ba6">update</span> &amp;&amp; sudo apt <span style="color:#114ba6">upgrade</span></code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">3.搜查 Cutefish 軟件包</span></strong></span></p><pre><code>sudo apt-<span style="color:#114ba6">cache</span><span style="color:#114ba6">search</span> cutefish</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">4.安裝</span></strong></span></p><pre><code>sudo apt <span style="color:#114ba6">install</span> cutefish-core cutefish-dock cutefish-daemon 
cutefish-qt-plugins cutefish-calculator cutefish-debinstaller 
cutefish-filemanager cutefish-launcher cutefish-screenlocker 
cutefish-<span style="color:#114ba6">settings</span> cutefish-statusbar cutefish-terminal cutefish-videoplayer 
cutefish-wallpapers cutefish-<span style="color:#114ba6">cursor</span>-themes cutefish-gtk-themes 
cutefish-sddm-theme  fishui libcutefish</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">5.切換桌面</span></strong></span></p><div><p style="text-align:center"><img alt="" height="794" src="https://oscimg.oschina.net/oscnet/up-05f1ddfabb6c84942d02a3c851f48b47a92.png" width="1277" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#2589fb">關於 Cutefish SIG</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Cutefish 是一款簡潔、美觀、實用的桌面環境，Cutefish SIG 致力於維護 Cutefish 相關組件，如桌面、啓動器、任務欄、控制中心、窗口管理器等，給 openKylin 提供美觀易用的桌面環境。</span></span></p><ul><li><span><span style="color:#000000">SIG 主頁：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/Cutefish</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 03:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260772</guid>
            <link>https://www.oschina.net/news/260772</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[SecZone 每日安全資訊（2023.10.08）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>環球動態<br> 1.Microsoft 將在 Windows 11 中引入密鑰支持功能<br> 作為 Windows 11 重大更新的一部分，微軟今天推出了密鑰支持功能。用户將能使用設備 PIN 或生物識別信息登錄網站和應用，而無需提供用户名和密碼。【Microsoft is Rolling out Support for Passkeys in Windows 11 (thehackernews.com)】</p><p>2.黑客利用零點字體偽裝成 Microsoft Outlook 誘騙顯示虛假的 AV 掃描警報<br> 黑客正在利用零點字體在電子郵件中的新型技巧，使惡意郵件看起來像是 Microsoft Outlook 中的安全工具發出的掃描警報。這是首次記錄到 ZeroFont 網絡釣魚技術以這種方式的使用。【針對 Microsoft 365 的釣魚即服務平台 Greatness - FreeBuf 網絡安全行業門户】</p><p>3. 谷歌為攻擊中利用的 libwebp 漏洞分配了新的最高 CVE 編號<br> 谷歌已經為最近被攻擊利用的 libwebp 安全漏洞分配了新的最高 CVE 編號（CVE-2023-5129）。這個零日漏洞在兩週前修補過。【VMware Aria Operations for Networks 遠程代碼執行漏洞（CVE-2... - FreeBuf 網絡安全行業門户】</p><p>4. 新的 AtlasCross 黑客冒充美國紅十字會發送網絡釣魚誘餌<br> 「AtlasCross」新黑客組織冒充美國紅十字會，針對有網絡釣魚誘餌的組織發送後門惡意軟件。【Access denied | www.bleepingcomputer.com used Cloudflare to restrict access】</p><p>5. 蘋果谷歌漏洞披露不充分，使騰訊 QQ 等數百萬應用面臨潛在風險<br> 安全研究員指出，蘋果和谷歌近期披露的產品零日漏洞不完整，可能隱藏了一個上游開源庫 libwebp 的漏洞，使騰訊 QQ 等數百萬應用面臨「巨大的盲點」，處於被攻擊的危險之中。【蘋果谷歌漏洞披露不完整，讓騰訊 QQ 等數百萬應用處於危險之中 - 安全內參 | 決策者的網絡安全知識庫 (secrss.com)】</p><p>6.科技巨頭們聯手成立了 PQC 聯盟以推動量子密碼學的應用<br> 微軟、IBM Quantum、MITRE、PQShield、SandboxAQ 和滑鐵盧大學等科技巨頭聯手啓動了 PQC 聯盟，旨在推動量子密碼學在商業及開源領域的應用。Shor 算法作為構建所有非對稱加密的基礎，正受到量子計算的威脅。【Tech Giants Launch Post-Quantum Cryptography Coalition - Infosecurity Magazine (infosecurity-magazine.com)】</p><p>安全大爆料<br> 1. 加拿大的 Flair Airlines 公司在其用户數據保護方面存在嚴重問題<br> 根據 Cybernews 的研究團隊的發現，加拿大的 Flair Airlines 公司在其用户數據保護方面存在着嚴重的問題。他們發現，該公司在處理敏感數據庫和電子郵件地址憑據的過程中，竟然將它們保留了下來長達至少七個月的時間。這種情況無疑增加了乘客個人信息（如電子郵件、姓名或地址）被不法分子利用的風險。這不僅對乘客的個人隱私構成了威脅，也對他們的安全帶來了潛在的風險。【Canadian Flair Airlines left user data leaking for months (securityaffairs.com)】</p><p>2. 科威特財政部遭.HYSIDA 勒索軟件組織攻擊<br> 財政部在今天黎明時分宣佈，其一個系統遭到了惡意軟件的黑客攻擊。儘管系統和保護程序已經啓動並停用，但該部仍在評估這次未遂黑客攻擊的程度。此外，財政部還確認，工資轉移程序不會受到這次網絡攻擊的影響，因為政府的財務系統是獨立的。【The Rhysida ransomware group hit the Kuwait Ministry of Finance (securityaffairs.com)】</p><p>3. 3 萬新生兒和孕期護理患者的數據泄露事件影響了 BORN ONTARIO<br> "BORN（更好的結果註冊和網絡）受到了網絡安全漏洞的影響，這個漏洞是由我們使用的軟件 Progress MOVEit 在執行安全文件傳輸時觸發的全球性漏洞所導致。"【BORN Ontario data breach impacted 3.4 million newborns and pregnancy care patients (securityaffairs.com)】</p><p>4. 影子辛迪加：與 7 個勒索軟件家族有關的新興網絡犯罪組織<br> 網絡安全專家揭示了一個名為 ShadowSyndicate（前身為 Infra Storm）的新網絡犯罪組織，該組織在過去一年中可能利用了多達七個不同的勒索軟件家族。【ShadowSyndicate: A New Cybercrime Group Linked to 7 Ransomware Families (thehackernews.com)】</p><p>5. JetBrains TeamCity 的漏洞可能讓攻擊者獲得源代碼和構建管道的訪問權限<br> 沒有經過身份驗證的攻擊者可以利用 JetBrains TeamCity CI/CD 軟件中的一個關鍵安全漏洞，在受影響的系統上遠程執行代碼。【Critical JetBrains TeamCity Flaw Could Expose Source Code and Build Pipelines to Attackers (thehackernews.com)】</p><p>6. 網絡釣魚者利用 Facebook 直播假貨作為誘餌<br> NCC 警告稱，「航海狂人」可能很容易被虛假的社交媒體帖子所誘惑，一些受害者甚至可能在不知不覺中成為了犯罪分子的新兵，以獲取整齊的 Facebook 帳户詳細信息。【Critical JetBrains TeamCity Flaw Could Expose Source Code and Build Pipelines to Attackers (thehackernews.com)】</p><p>前沿資訊<br> 1. macOS 平台上出現的新型信息竊密軟件：MacStealer<br> 信息竊密惡意軟件 MacStealer 能夠對最新版本的 macOS 造成威脅，並且使用了 Telegram 作為 C&amp;C 信道來竊取受害者的敏感數據。【macOS 平台新出現的信息竊密軟件：MacStealer_網絡安全小肖的博客-CSDN 博客】</p><p>2. 零信任技術架構：SDP2.0 的中文改寫版<br> "在零信任技術架構中，本質上沒有太大的區別。在實際的客户環境中，我們需要根據具體情況有側重點地進行建設，例如優先加強端點零信任能力（SDP 架構）、身份認證零信任能力（IAM 架構）或東西向流量的零信任能力（MSG 架構）等。"【白話零信任技術架構之 SDP2.0 - FreeBuf 網絡安全行業門户】</p><p>3. 0day 審計：某微代碼審計案例的中文改寫版本<br> 這個方法是繼承了 extends MobileAction 並通過 http 請求獲取 action 參數，然後進行全局 jsp 文件搜索 SkinAction，發現通過了 jionActionUrl 方法調用，在第 2 行包含了&lt;%@ include file="/mobilemode/init.jsp"%&gt;，根據裏方法構造出路徑。【0day 審計之某微代碼審計-騰訊雲開發者社區-騰訊雲 (tencent.com)】</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260771</guid>
            <link>https://www.oschina.net/news/260771</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Brave 裁員 9%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Brave Browser 和 Search 的製造商 Brave Software 向 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F06%2Fbrave-lays-off-9-of-its-workforce%2F" target="_blank">TechCrunch</a> 證實，該公司已跨部門裁員 9%。該公司沒有具體説明裁員波及的員工人數，但它證實了這一裁員舉措，並表示這一決定是由嚴峻的經濟環境所驅動的。</span></p><p><span style="color:#000000">「在這個充滿挑戰的經濟環境中，Brave 公司裁撤了一些職位，作為我們成本管理的一部分。有幾個部門受到影響，佔我們員工總數的 9%。」</span></p><p><img height="261" src="https://oscimg.oschina.net/oscnet/up-38a5daf764ff082e1ad6362984e1cec8e08.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">今年以來，該公司一直在採取措施以加強收入來源。4 月份，Brave Search 放棄了 Bing Index，開始依賴自己的索引解決方案。</span></p><p><span style="color:#000000">5 月份，該公司為客户發佈了自己的&nbsp;search API，計劃每 1,000 次查詢收費 3 美元起。該 API 還為 AI 數據模型訓練、具有存儲權限的數據、拼寫檢查和自動建議提供了不同的計劃。上個月，Brave 還為其 search API 推出了圖像、新聞和視頻搜索功能。</span></p><p><span style="color:#000000">此外，Brave 一直在為其瀏覽器測試名為 Leo 的原生人工智能助手。Brave 表示，雖然計劃向所有用户開放，但 Leo 將擁有高級版，具有更高的速率限制和訪問更多對話模型等功能。該公司指出，這將有助於其支付 API 訪問和託管成本。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 03:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260770/brave-lays-off-9-of-its-workforce</guid>
            <link>https://www.oschina.net/news/260770/brave-lays-off-9-of-its-workforce</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[NASA 更改 CMS：從 Drupal 遷移到 WordPress]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>美國國家航空航天局 (NASA) 移除了新版<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nasa.gov%2F" target="_blank">&nbsp;nasa.gov </a>網站上的 beta 測試標籤，標誌其已正式可用。</p><p>據介紹，NASA 新版本官網採用了新的 CMS（內容管理系統） —— 從 Drupal 遷移到 WordPress。此次遷移花費了 18 個月，主要工作包括網站開發、數據遷移和內容建設。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6f81cac58978084713557fe55beb8b4510b.png" referrerpolicy="no-referrer"></p><p>NASA 在選擇 CMS 時評估了商業和開源解決方案，對 100 多個 CMS 平台進行了考察，四個方案進入了最終候選名單，包括兩個商業方案，以及兩個開源方案 —— WordPress 和 Drupal。</p><p>他們認為 WordPress 的優勢如下：</p><ul><li><strong>社區龐大</strong>，方便獲取支持資源。</li><li><strong>插件生態豐富</strong>，更好地進行 SEO 優化、對內容進行實時分析等</li><li><strong>內容創作環境易於使用</strong></li></ul><p>WordPress.com VIP 金牌代理合作伙伴 Lone Rock Point 領導了 NASA 此次 CMS 遷移項目，該項目從一年的用户體驗設計和對各種企業 CMS 的評估開始。作為該項目的一部分，NASA 的網站基礎設施也從 AWS 遷移到了 WordPress.com VIP。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 02:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260768/nasa-chose-wordpress-cms</guid>
            <link>https://www.oschina.net/news/260768/nasa-chose-wordpress-cms</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[SudoLang —— 與 AI 語言模型協作的編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>SudoLang 是一種編程語言，旨在與 ChatGPT、Bing Chat、Anthropic Claude 和 Google Bard 等 AI 語言模型協作。它被設計為易於學習和使用，同時也非常具有表現力和力量。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>所有足夠先進的語言模型都可以在沒有任何特殊提示的情況下理解它。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h4 style="text-align:start"><strong><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特點</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><strong>基於自然語言約束的編程。</strong>與其告訴人工智能做什麼，不如告訴它是什麼或你想要什麼，以及一些管理規則。人工智能會持續遵守這些約束，並可用於同步狀態和行為。只需幾行自然語言文本，約束條件就能輕鬆定義非常複雜的行為。</li><li>用於定義程序的結構和行為的<strong>接口。</strong></li><li><strong><code>/commands</code></strong>用於為程序交互定義聊天或編程接口。</li><li><strong>語義模式匹配</strong>。AI 可以智能地推斷程序狀態並匹配模式，諸如<code>(post contains harmful content) =&gt; explain(content policy)</code>。</li><li><strong>全能參照。</strong>你無需明確定義大多數函數。人工智能會為你推斷出它們。</li></ul><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>對於大多數簡單的提示，自然語言更好。用它。但如果你需要 AI 遵循程序、遵守約束、跟蹤複雜狀態或實現複雜算法，SudoLang 會非常有用。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>由於強調自然語言，SudoLang 比 JavaScript 或 Python 等編程語言更容易學習。</li><li>與自然語言提示相比，偽代碼可以<a href="https://arxiv.org/abs/2305.11790">提高推理性能</a>，併為許多提示樣式創建簡寫，例如思想鏈推理、決策樹等。</li><li>SudoLang 是一種聲明性、基於約束、面向接口的編程語言，這使其成為世界上最具表現力和緊湊的編程語言之一。SudoLang 提示通常可以比自然語言少 20% - 30% 的標記，從而降低提示成本並加快響應速度。</li><li>結構化偽代碼提供範圍塊、縮進和視覺封裝，這使得導航和維護複雜提示比自然語言更容易。</li><li>使用預定義類型和接口的結構化模板和查詢可以降低格式錯誤響應的可能性，並<a href="https://arxiv.org/pdf/2212.06094.pdf">顯着減少與語言模型交互所需的令牌數量</a>，特別是在請求<a href="https://yaml.org/">yaml</a>或<a href="https://en.wikipedia.org/wiki/Comma-separated_values">csv</a>格式的數據時。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/sudolang</guid>
            <link>https://www.oschina.net/p/sudolang</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 鍵映射解決方案 Capslock Magic]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-capslockmagic" class="anchor" href="https://gitee.com/miozus/CapslockMagic#capslockmagic"></a>CapslockMagic</h1><blockquote><p><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic">中文文檔</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fen-us%2F">README</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fke-complex-modifications.pqrs.org%2F%23caps_lock_magic">Karabiner Gallery</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmiozus%2FCapslockMagic">Github Repo</a> | <a href="https://gitee.com/miozus/CapslockMagic">Gitee Repo</a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fthqby%2FAutoHotkey_H"><img src="https://img.shields.io/badge/AutoHotkey__H-thqby-orange?style=flat&amp;logo=GitHub" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmiozus%2FCapslockMagic"><img src="https://img.shields.io/badge/CapslockMagic-1.5.1-brightengreen?style=flat&amp;logo=ClickUp" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DiiuN83v3"><img src="https://img.shields.io/badge/QQ%E7%BE%A4-1026918136-yellow?style=flat&amp;logo=TencentQQ" referrerpolicy="no-referrer"></a></p></blockquote><p><img src="https://gitee.com/miozus/CapslockMagic/raw/master/docs/img/HHKB-win-keymap-pure.png" alt="hhkb" referrerpolicy="no-referrer"></p><p>Capslock Magic 是一套<strong>跨平台</strong>、<strong>跨應用</strong>的鍵映射解決方案。 它將 ⇪ CapsLock（大寫鎖定鍵）改造為一個強力的功能修飾鍵（✱ Hyper ），還改造了 <kbd>3</kbd><kbd>4</kbd><kbd>;</kbd> 按鍵，適用各種日常業務場景。奇蹟般地提高操作效率與生產力。</p><p>—— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmonkey-ime">示例</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fquick-start-windows">安裝</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">使用</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">問題</a> ——</p><h2><a id="user-content-功能一覽" class="anchor" href="https://gitee.com/miozus/CapslockMagic#%E5%8A%9F%E8%83%BD%E4%B8%80%E8%A7%88"></a>功能一覽</h2><table><thead><tr><th>&nbsp;</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>底層</td><td>💻  支持 Win/Mac</td><td>⌨️  鍵盤配列 60</td><td>🧰  JavaScprit 風格</td><td>⚙️  配置自定義</td></tr><tr><td>基礎</td><td>👾  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">啓動程序</a></td><td>📺  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fwindow">窗口管理</a></td><td>🖱️  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmouse">鼠標操作</a></td><td><code>I</code><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">光標編輯</a></td></tr><tr><td>進化</td><td>🐵  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmonkey-ime">猴子輸入法</a></td><td><code>;</code><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fsemicolon-hook">分號特殊符</a></td><td>3️⃣  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fnumpad">數字小鍵盤</a></td><td>🤖  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fime-manager">中英文管家</a></td></tr><tr><td>進化</td><td>🦑  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Funiverse-editor">宇宙編輯器</a></td><td></td><td></td><td></td></tr></tbody></table>]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/miozus/CapslockMagic</guid>
            <link>https://gitee.com/miozus/CapslockMagic</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | MySQL 到 TiDB：Hive Metastore 橫向擴展之路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互聯網技術" data-alias="vivoVMIC" data-signature="分享 vivo 互聯網技術乾貨與沙龍活動，推薦最新行業動態與熱門會議。" data-from="0"></mp-common-profile></section><section style="font-size: 15px;line-height: 1.6;"><section style="margin: 10px 0% 8px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding-left: 8px;align-self: flex-start;flex: 0 0 auto;"><section style="color: rgba(0, 0, 0, 0.5);font-size: 14px;text-align: justify;" powered-by="xiumi.us"><p>作者：vivo 互聯網大數據團隊 - Wang Zhiwen</p></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: left;" powered-by="xiumi.us"><section style="font-size: 14px;text-align: justify;line-height: 1.8;padding-right: 5px;padding-left: 5px;color: rgb(160, 160, 160);"><p>本文介紹了 vivo 在大數據元數據服務橫向擴展道路上的探索歷程，由實際面臨的問題出發，對當前主流的橫向擴展方案進行了調研及對比測試，通過多方面對比數據擇優選擇 TiDB 方案。其次分享了整個擴展方案流程、實施遇到的問題及解決方案，對於在大數據元數據性能上面臨同樣困境的開發者本篇文章具有非常高的參考借鑑價值。</p></section></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>一、背景</p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>大數據元數據服務 Hive Metastore Service（以下簡稱 HMS），存儲着數據倉庫中所依賴的所有元數據並提供相應的查詢服務，使得計算引擎（Hive、Spark、Presto）能在海量數據中準確訪問到需要訪問的具體數據，其在離線數倉的穩定構建上扮演着舉足輕重的角色。vivo 離線數倉的 Hadoop 集羣基於 CDH 5.14.4 版本構建，HMS 的版本選擇跟隨 CDH 大版本，當前使用版本為 1.1.0-cdh5.14.4。</p><p><br></p><p>vivo 在 HMS 底層存儲架構未升級前使用的是 MySQL 存儲引擎，但隨着 vivo 業務發展，數據爆炸式增長，存儲的元數據也相應的增長到億級別（PARTITION_PARAMS：8.1 億、</p><p>PARTITION_KEY_VALS：3.5 億、PARTITIONS：1.4 億），在如此大量的數據基數下，我們團隊經常面臨機器資源的性能瓶頸，往往用户多併發的去查詢某些大分區表（50w+分區），機器資源的使用率就會被打滿，從而導致元數據查詢超時，嚴重時甚至整個 HMS 集羣不可用，此時恢復手段只能暫時停服所有 HMS 節點，直到 MySQL 機器負載降下來後在逐步恢復服務。為此，針對當前 MySQL 方案存在的嚴重性能瓶頸，HMS 急需一套完善的橫向擴展方案來解決當前燃眉之急。</p></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>二、橫向擴展技術方案選型</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">為解決 HMS 的性能問題，我們團隊對 HMS 橫向擴展方案做了大量的調研工作，總體下來業內在 HMS 的橫向擴展思路上主要分為對 MySQL 進行拆庫擴展或用高性能的分佈式引擎替代 MySQL。在第一種思路上做的比較成熟的方案有<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fhotels.com%2F" textvalue="Hotels.com" linktype="text" imgurl="" tab="outerlink" data-linktype="2">Hotels.com</a>公司開源的 Waggle Dance，實現了一個跨集羣的 Hive Metastore 代理網關，他允許用户同時訪問多個集羣的數據，這些集羣可以部署在不同的平台上，特別是雲平台。第二種思路當前主流的做法是用分佈式存儲引擎 TiDB 替換傳統的 MySQL 引擎，在 Hive 社區中有不少公司對 hive 2.x 接入 TiDB 做了大量的測試並應用到生產中（<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FHive%2FUsing%2BTiDB%2Bas%2Bthe%2BHive%2BMetastore%2Bdatabase" textvalue="詳情點擊" linktype="text" imgurl="" tab="outerlink" data-linktype="2">詳情點擊</a>）。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.1 Waggle Dance</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">Waggle-dance 向用户提供統一的入口，將來自 Metastore 客户端的請求路由到底層對應的 Metastore 服務，同時向用户隱藏了底層的 Metastore 分佈，從而在邏輯層面整合了多個 Metastore 的 Hive 庫表信息。Waggle-dance 實現了 Metastore 的 Thrift API，客户端無需改動，對用户來説，Waggle-dance 就是一個 Metastore。其整體架構如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.9175925925925926" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/a9e0ef2a-6dea-4425-8220-7df8cbb062f1.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">Waggle Dance 架構</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">從 Waggle-dance 的架構中最突出的特性是其採用了多個不同的 MySQL 實例分擔了原單 MySQL 實例的壓力，除此之外其還有如下優勢：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>用户側可以沿用 Metastore 客户端的用法，配置多台 Waggle-dance 的連接，在當前 Waggle-dance 連接服務不可用的時候切換到其他的 Waggle-dance 服務上。</p></li><li><p>Waggle-dance 只需幾秒即可啓動，加上其無狀態服務的特性，使得 Waggle-dance 具備高效的動態伸縮性，可以在業務高峯期快速上線新的服務節點分散壓力，在低峯期下線部分服務節點釋放資源。</p></li><li><p>Waggle-dance 作為一個網關服務，除了路由功能外，還支持後續的定製化開發和差異化部署，平台可根據需要添加諸如鑑權、防火牆過濾等功能。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.2 TiDB</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">TiDB 是 PingCAP 公司自主設計、研發的開源分佈式關係型數據庫，是一款同時支持在線事務處理與在線分析處理 (Hybrid Transactional and Analytical Processing, HTAP) 的融合型分佈式數據庫產品，具備水平擴容或者縮容、金融級高可用、實時 HTAP、雲原生的分佈式數據庫、兼容 MySQL 5.7 協議和 MySQL 生態等重要特性。在 TiDB 4.x 版本中，其性能及穩定性較與之前版本得到了很大的提升並滿足 HMS 的元數據查詢性能需求。故我們對 TiDB 也做了相應的調研及測試。結合 HMS 及大數據生態，採用 TiDB 作為元數據存儲整體的部署架構如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.8727272727272727" data-s="300,640" data-type="png" data-w="825" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/e149c269-2046-48a7-bb11-e0a90ce0edf1.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">HMS on TiDB 架構&nbsp; &nbsp;</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">由於 TiDB 本身具有水平擴展能力，擴展後能均分查詢壓力，該特性就是我們解決 HMS 查詢性能瓶頸的大殺器。除此外該架構還有如下優勢：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>用户無需任何改動；HMS 側面沒有任何改動，只是其依賴的底層存儲發生變化。</p></li><li><p>不破壞數據的完整性，無需將數據拆分多個實例來分擔壓力，對 HMS 來説其就是一個完整、獨立的數據庫。</p></li><li><p>除引入 TiDB 作為存儲引擎外，不需要額外的其他服務支撐整個架構的運行。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.3 TiDB 和 Waggle Dance 對比</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">前面內容對 Waggle-dance 方案和 TiDB 方案做了簡單的介紹及優勢總結，以下列舉了這兩個方案在多個維度的對比：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.6953703703703704" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3ce1c63-1cd8-4917-a94b-0e3c638c3328.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通過上述多個維度的對比，TiDB 方案在性能表現、水平擴展、運維複雜度及機器成本上都優於 waggle-dance 方案，故我們線上選擇了前者進行上線應用。&nbsp;</p><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>三、TiDB 上線方案</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">選擇 TiDB 引擎替代原 MySQL 存儲引擎，由於 TiDB 與 MySQL 之間不能做雙主架構，在切換過程中 HMS 服務須完全停服後並重新啓動切換至 TiDB，為保障切換過程順利及後面若有重大問題發生能及時回滾，在切換前做了如下數據同步架構以保障切換前 MySQL 與 TiDB 數據一致以及切換後仍有 MySQL 兜底。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4703703703703704" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/033aceb3-efa2-4951-9897-94e1c2cbe128.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB&amp;MySQL 上線前後數據同步架構</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在上述架構中，切換前唯一可寫入的數據源只有源數據庫主庫，其他所有 TiDB、MySQL 節點都為只讀狀態，當且僅當所有 HMS 節點停服後，MySQL 源數據庫從庫及 TiDB 源數據庫主庫的數據同步最大時間戳與源數據庫主庫一致時，TiDB 源數據庫主庫才開放可寫入權限，並在修改 HMS 底層存儲連接串後逐一拉起 HMS 服務。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在上述架構完成後，即可開始具體的切換流程，切換整體流程如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.27037037037037037" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/20cfee5d-3265-4b12-9e43-7fa47ffb8f59.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">HMS 切換底層存儲流程</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">其中在保障源 MySQL 與 TiDB 數據正常同步前，需要對 TiDB 做以下配置：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>tidb_skip_isolation_level_check 需要配置為 1 ，否則啓動 HMS 存在 MetaException 異常。</p></li><li><p>tidb_txn_mode 需配置為 pessimistic ，提升事務一致性強度。</p></li><li><p>事務大小限制設置為 3G，可根據自己業務實際情況進行調整。</p></li><li><p>連接限制設置為最大 3000 ，可根據自己業務實際情況進行調整。</p></li></ul></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">此外在開啓 sentry 服務狀態下，需確認 sentry 元數據中 NOTIFICATION_ID 的值是否落後於 HMS 元數據庫中 NOTIFICATION_SEQUENCE 表中的 NEXT_EVENT_ID 值，若落後需將後者替換為前者的值，否則可能會發生建表或創建分區超時異常。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">以下為 TiDB 方案在在不同維度上的表現：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>在對 HQL 的兼容性上 TiDB 方案完全兼容線上所有引擎對元數據的查詢，不存在語法兼容問題，對 HQL 語法兼容度達 100%&nbsp;</p></li><li><p>在性能表現上查詢類接口平均耗時優於 MySQL，性能整體提升 15%；建表耗時降低了 80%，且支持更高的併發，TiDB 性能表現不差於 MySQL</p></li><li><p>在機器資源使用情況上整體磁盤使用率在 10% 以下；在沒有熱點數據訪問的情況下，CPU 平均使用率在 12%；CPU.WAIT.IO 平均值在 0.025% 以下;集羣不存在資源使用瓶頸。</p></li><li><p>在可擴展性上 TiDB 支持一鍵水平擴縮容，且內部實現查詢均衡算法，在數據達到均衡的情況下各節點可平攤查詢壓力。</p></li><li><p>在容災性上 TiDB Binlog 技術可穩定支撐 TiDB 與 MySQL 及 TiDB 之間的數據同步，實現完整的數據備份及可回退選擇。</p></li><li><p>在服務高可用性上 TiDB 可選擇 LVS 或 HaProxy 等服務實現負載均衡及故障轉移。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">以下為上線後 HMS 主要 API 接口調用耗時情況統計：</p><section style="font-size: 15px;"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 15px;margin-bottom: 15px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 5px;align-self: stretch;flex: 0 0 auto;margin-bottom: 30px;height: auto;z-index: 1;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section><section style="display: inline-block;vertical-align: top;width: auto;align-self: stretch;flex: 100 100 0%;height: auto;padding-right: 10px;padding-left: 10px;z-index: auto;line-height: 0;"><section style="display: flex;width: 100%;flex-flow: column;" powered-by="xiumi.us"><section style="z-index: 1;" powered-by="xiumi.us"><section style="text-align: right;margin-top: -5px;"><section style="display: inline-block;width: 100%;height: 5px;vertical-align: top;overflow: hidden;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-right: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bc1f5fe-5ed3-4507-8edd-99fd9eb4edcd.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-left: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.5880322209436134" data-s="300,640" data-type="jpeg" data-w="869" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/bde61013-5736-415d-a148-1fb6567a709e.png" referrerpolicy="no-referrer"></section></section></section></section><section style="justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-right: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/4575beb3-65ef-435b-8992-48929786cf28.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-left: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.6009227220299884" data-s="300,640" data-type="jpeg" data-w="867" style="vertical-align: middle;width: 298px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1c03991f-8f59-408b-a79e-d268d19c62d0.png" referrerpolicy="no-referrer"></section></section></section></section><section style="text-align: right;margin-bottom: -5px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 5px;vertical-align: top;overflow: hidden;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: top;width: 5px;align-self: stretch;flex: 0 0 auto;height: auto;margin-top: 30px;z-index: auto;"><br><br><br><br></section></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 100 100 0%;border-radius: 10px;overflow: hidden;height: auto;padding: 15px;border-style: solid;border-width: 1px;border-color: transparent;margin-right: 20px;z-index: 0;"><section style="display: inline-block;width: 100%;vertical-align: top;overflow-x: auto;border-radius: 5px;" powered-by="xiumi.us"><section style="overflow: hidden;width: 360%;max-width: 360% !important;"><section style="display: inline-block;vertical-align: middle;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bc1f5fe-5ed3-4507-8edd-99fd9eb4edcd.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.5880322209436134" data-s="300,640" data-type="jpeg" data-w="869" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/bde61013-5736-415d-a148-1fb6567a709e.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/4575beb3-65ef-435b-8992-48929786cf28.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.6009227220299884" data-s="300,640" data-type="jpeg" data-w="867" style="vertical-align: middle;width: 509px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1c03991f-8f59-408b-a79e-d268d19c62d0.png" referrerpolicy="no-referrer"></section></section></section></section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: -20px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: bottom;width: auto;align-self: flex-end;flex: 0 0 auto;min-width: 5%;height: auto;margin-right: 5px;z-index: 2;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section><section style="display: inline-block;vertical-align: bottom;width: auto;align-self: flex-end;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;color: rgb(223, 143, 51);font-size: 14px;" powered-by="xiumi.us"><p><br></p><p><span style="color: rgb(136, 136, 136);">（<span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.578px;text-wrap: wrap;">左右滑動</span><span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.578px;text-wrap: wrap;">，查看更多···</span>）</span></p></section></section></section></section></section><p powered-by="xiumi.us"><br></p></section><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>四、問題及解決方案</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.1 在模擬 TiDB 回滾至 MySQL 過程中出現主鍵衝突問題</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在 TiDB 數據增長 3 倍後，切換回 MySQL 出現主鍵重複異常，具體日誌內容如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.12222222222222222" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/dfa5874c-61af-4491-b338-4a3c4bd816af.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">主鍵衝突異常日誌</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">產生該問題的主要原因為每個 TiDB 節點在分配主鍵 ID 時，都申請一段 ID 作為緩存，用完之後再去取下一段，而不是每次分配都向存儲節點申請。這意味着，TiDB 的 AUTO_INCREMENT 自增值在單節點上能保證單調遞增，但在多個節點下則可能會存在劇烈跳躍。因此，在多節點下，TiDB 的 AUTO_INCREMENT 自增值從全局來看，並非絕對單調遞增的，也即並非絕對有序的，從而導致 Metastore 庫裏的 SEQUENCE_TABLE 表記錄的值不是對應表的最大值。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">造成主鍵衝突的主要原因是 SEQUENCE_TABLE 表記錄的值不為元數據中實際的最大值，若存在該情況在切換回 MySQL 後就有可能生成已存在的主鍵導致初見衝突異常，此時只需將 SEQUENCE_TABLE 裏的記錄值設置當前實際表中的最大值即可。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.2 PARTITION_KEY_VALS 的索引取捨</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在使用 MySQL 引擎中，我們收集了部分慢查詢日誌，該類查詢主要是查詢分區表的分區，類似如下 SQL：</p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__comment">#以下查詢為查詢三級分區表模板，且每級分區都有過來條件</span></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">SELECT</span> PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">FROM</span><span class="code-snippet__keyword">PARTITIONS</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> TBLS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> PARTITIONS.TBL_ID = TBLS.TBL_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> TBLS.TBL_NAME = <span class="code-snippet__string">'${TABLE_NAME}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> DBS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> TBLS.DB_ID = DBS.DB_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> DBS.NAME = <span class="code-snippet__string">'${DB_NAME}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER0</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER0.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER0.INTEGER_IDX = ${INDEX1}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER1</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER1.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER1.INTEGER_IDX = ${INDEX2}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER2</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER2.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER2.INTEGER_IDX = ${INDEX3}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHERE</span> FILTER0.PART_KEY_VAL = <span class="code-snippet__string">'${PART_KEY}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__keyword">CASE</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHEN</span> FILTER1.PART_KEY_VAL &lt;&gt; <span class="code-snippet__string">'__HIVE_DEFAULT_PARTITION__'</span><span class="code-snippet__keyword">THEN</span><span class="code-snippet__keyword">CAST</span>(FILTER1.PART_KEY_VAL <span class="code-snippet__keyword">AS</span><span class="code-snippet__built_in">decimal</span>(<span class="code-snippet__number">21</span>, <span class="code-snippet__number">0</span>))</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ELSE</span><span class="code-snippet__literal">NULL</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">END</span> = <span class="code-snippet__number">10</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER2.PART_KEY_VAL = <span class="code-snippet__string">'068'</span>;</span></code></pre></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>在測試中通過控制併發重放該類型的 SQL，隨着併發的增加，各個 API 的平均耗時也會增長，且重放的 SQL 查詢耗時隨着併發的增加查詢平均耗時達到 100s 以上，雖然 TiDB 及 HMS 在壓測期間沒有出現任何異常，但顯然這種查詢效率會讓用户很難接受。DBA 分析該查詢沒有選擇合適的索引導致查詢走了全表掃描，建議對 PARTITION_KEY_VALS 的 PARTITION_KEY_VAL 字段添加了額外的索引以加速查詢，最終該類型的查詢得到了極大的優化，即使加大併發到 100 的情況下平均耗時在 500ms 內，對此我們曾嘗試對 PARTITION_KEY_VALS 添加上述索引操作。</p><p><br></p><p>但在線上實際的查詢中，那些沒有產生慢查詢的分區查詢操作其實都是按天分區的進行一級分區查詢的，其 SQL 類似如下：</p></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__keyword">SELECT</span><span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">FROM</span><span class="code-snippet__string">"PARTITIONS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"TBLS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"TBL_ID"</span> = <span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"TBL_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"TBL_NAME"</span> = <span class="code-snippet__string">'tb1'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"DBS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"DB_ID"</span> = <span class="code-snippet__string">"DBS"</span>.<span class="code-snippet__string">"DB_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"DBS"</span>.<span class="code-snippet__string">"NAME"</span> = <span class="code-snippet__string">'db1'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"PARTITION_KEY_VALS"</span><span class="code-snippet__string">"FILTER0"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"PART_ID"</span> = <span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"INTEGER_IDX"</span> = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"PARTITION_KEY_VALS"</span><span class="code-snippet__string">"FILTER1"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_ID"</span> = <span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"INTEGER_IDX"</span> = <span class="code-snippet__number">1</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHERE</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span> = <span class="code-snippet__string">'2021-12-28'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__keyword">CASE</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHEN</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span> &lt;&gt; <span class="code-snippet__string">'__HIVE_DEFAULT_PARTITION__'</span><span class="code-snippet__keyword">THEN</span><span class="code-snippet__keyword">CAST</span>(<span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span><span class="code-snippet__keyword">AS</span><span class="code-snippet__built_in">decimal</span>(<span class="code-snippet__number">21</span>, <span class="code-snippet__number">0</span>))</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ELSE</span><span class="code-snippet__literal">NULL</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">END</span> = <span class="code-snippet__number">10</span>;</span></code></pre></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">由於對 PARTITION_KEY_VALS 的 PARTITION_KEY_VAL 字段添加了索引做查詢優化，會導致該類查詢生成的執行計劃中同樣會使用 idx_PART_KEY_VAL 索引進行數據掃描，該執行計劃如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4898148148148148" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/20f84c22-d1ae-4c32-82be-4b884faf9249.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">走 idx_PART_KEY_VAL 索引執行計劃</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">添加的 idx_PART_KEY_VAL 索引在該字段的具有相同值的數據較少時，使用該索引能檢索較少的數據提升查詢效率。在 hive 中的表一級分區基本是按天進行分區的，據統計每天天分區的增量為 26w 左右，如果使用 idx_PART_KEY_VAL 索引，按這個數值計算，查詢條件為 day&gt;=2021-12-21 and day&lt;2021-12-26 的查詢需要檢索將近 160w 條數據，這顯然不是一個很好的執行計劃。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">若執行計劃不走 idx_PART_KEY_VAL 索引，TiDB 可通過 dbs、tbls 檢索出所有關聯 partition 數據，在根據 part_id 和過濾條件掃描 PARTITION_KEY_VALS 數據並返回。此類執行計劃掃描的數據量和需要查詢的表的分區總量有關，如果該表只有少數的分區，則查詢能夠迅速響應，但如果查詢的表有上百萬的分區，則該類執行計劃對於該類查詢不是最優解。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.2675925925925926" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/97b2badc-d7bd-4e82-872c-cdfbed8555cd.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">不走 idx_PART_KEY_VAL 索引執行計劃</span></p><section powered-by="xiumi.us"><p><br></p><p>針對不同執行計劃的特性，整理了以下對比點：</p></section><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.2995910020449898" data-s="300,640" data-type="png" data-w="978" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/393b4adf-34c3-4685-9d35-3002044f44b6.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在實際生產中元數據基本都是按天分區為主，每天增長大概有 26w 左右，且範圍查詢的使用場景較多，使用 idx_PART_KEY_VAL 索引查詢的執行計劃不太適合線上場景，故該索引需不適合添加到線上環境。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.3 TiDB 內存突增導致宕機問題</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在剛上線 TiDB 服務初期，曾數次面臨 TiDB 內存溢出的問題，每次出現的時間都隨機不確定，出現的時候內存突增幾乎在一瞬間，若期間 TiDB 的內存抗住了突增量，突增部分內存釋放在很長時間都不會得到釋放，最終對 HMS 服務穩定性帶來抖動。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4034833091436865" data-s="300,640" data-type="png" data-w="689" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/8844c991-06f3-4ca0-aab6-3d42df20759e.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB 內存突增情況</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通過和 TiDB 開發、DBA 聯合分析下，確認 TiDB 內存飆高的原因為用户在使用 Dashboard 功能分析慢查詢引起；在分析慢查詢過程中，TiDB 需要加載本地所有的 slow-query 日誌到內存，如果這些日誌過大，則會造成 TiDB 內存突增，此外，如果在分析期間，用户點擊了取消按鈕，則有可能會造成 TiDB 的內存泄漏。針對該問題制定如下解決方案：</p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: justify;line-height: 1.8;padding-right: 5px;padding-left: 5px;" powered-by="xiumi.us"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p>使用大內存機器替換原小內存機器，避免分析慢查詢時內存不夠</p></li><li><p>調大慢查詢閾值為 3s，減少日誌產生</p></li><li><p>定時 mv 慢查詢日誌到備份目錄</p></li></ol></section></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.4 locate 函數查詢不走索引導致 TiKV 負異常</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在 HMS 中存在部分通過 JDO 的方式去獲取分區的查詢，該類查詢的過濾條件中用 locate 函數過濾 PART_NAME 數據，在 TiDB 中通過函數作用在字段中是不會觸發索引查詢的，所以在該類查詢會加載對應表的所有數據到 TiDB 端計算過濾，TiKV 則需不斷掃描全表並傳輸數據到 TiDB 段，從而導致 TiKV 負載異常。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.43148148148148147" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/0c22e9c9-f38c-4dec-b58b-d35a9460e937.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">locate 函數導致全表掃描</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">然而上述的查詢條件可以通過 like 方式去實現，通過使用 like 語法，查詢可以成功使用到 PARTITIONS 表的 UNIQUEPARTITION 索引過濾，進而在 TiKV 端進行索引過濾降低負載。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.45" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/35186c1a-9fcf-43a9-a5a0-7d7fa3ca1690.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;"><span style="font-size: 14px;color: rgb(136, 136, 136);">like 語法走索引過濾</span></span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通過實現將 locate 函數查詢轉換為 like 語法查詢，有效降低了 TiKV 端的負載情況。在 HMS 端完成變更後，TiKV 的 CPU 使用率降低了將近一倍，由於在 KV 端進行索引過濾，相應的 io 使用率有所上升，但網絡傳輸則有明顯的下降，由平均 1G 降低到 200M 左右。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.34814814814814815" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d6a4e572-c45f-424b-b9bc-a589fae353c2.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">變更前後 TiKV 的負載情況</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">除 TiKV 負載有明顯的降低，TiDB 的整體性能也得到明顯的提升，各項操作耗時呈量級降低。以下整理了 TiDB 增刪改查的天平均耗時情況：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.5666666666666667" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3a73735-d7f8-4d13-ac94-5deb12749daa.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB P999 天平均耗時統計</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.5 get_all_functions 優化</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">隨着 hive udf 的不斷增長，HMS 的 get_all_functions api 平均耗時增長的也越來越久，平均在 40-90s，而該 api 在 hive shell 中首次執行查詢操作時會被調用註冊所有的 udf，過長的耗時會影響用户對 hive 引擎的使用體驗，例如執行簡單的 show database 需要等待一分鐘甚至更久才能返回結果。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.3824074074074074" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/4b18f10c-d130-4c26-8213-44b30511d29c.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="color: rgb(136, 136, 136);font-size: 14px;">原 get_all_functions api 平均耗時</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">導致該 api 耗時嚴重的主要原因是 HMS 通過 JDO 方式獲取所有的 Function，在獲取所有的 udf 時後台會遍歷每條 func 去關聯 DBS、FUNC_RU 兩個表，獲取性能極低。而使用 directSQL 的方式去獲取所有 udf 數據，響應耗時都在 1 秒以內完成，性能提升相當明顯。以下為 directSQL 的 SQL 實現邏輯：</p><p powered-by="xiumi.us"><br></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__keyword">select</span> FUNCS.FUNC_NAME,</span></code><code><span class="code-snippet_outer">  DBS.NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.CLASS_NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.OWNER_NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.OWNER_TYPE,</span></code><code><span class="code-snippet_outer">  FUNCS.CREATE_TIME,</span></code><code><span class="code-snippet_outer">  FUNCS.FUNC_TYPE,</span></code><code><span class="code-snippet_outer">  FUNC_RU.RESOURCE_URI,</span></code><code><span class="code-snippet_outer">  FUNC_RU.RESOURCE_TYPE</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> FUNCS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">left</span><span class="code-snippet__keyword">join</span> FUNC_RU <span class="code-snippet__keyword">on</span> FUNCS.FUNC_ID = FUNC_RU.FUNC_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">left</span><span class="code-snippet__keyword">join</span> DBS <span class="code-snippet__keyword">on</span> FUNCS.DB_ID = DBS.DB_ID</span></code></pre></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>五、總結</p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>我們從 2021 年 7 月份開始對 TiDB 進行調研，在經歷數個月的測試於同年 11 月末將 MySQL 引擎切換到 TiDB。由於前期測試主要集中在兼容性和性能測試上，忽略了 TiDB 自身可能潛在的問題，在上線初期經歷了數次因慢查詢日誌將 TiDB 內存打爆的情況，在這特別感謝我們的 DBA 團隊、平台運營團隊及 TiDB 官方團隊幫忙分析、解決問題，得以避免該問題的再次發生；與此同時，由於當前 HMS 使用的版本較低，加上大數據的組件在不斷的升級演進，我們也需要去兼容升級帶來的變動，如 HDFS 升級到 3.x 後對 EC 文件讀取的支持，SPARK 獲取分區避免全表掃描改造等；此外由於 TiDB 的 latin 字符集支持中文字符的寫入，該特性會導致用户誤寫入錯誤的中文分區，對於此類型數據無法通過現有 API 進行刪除，還需要在應用層去禁止該類型錯誤分區寫入，避免無用數據累積。</p><p><br></p><p>經歷了一年多的實際生產環境檢驗，TiDB 內存整體使用在 10% 以內，TiKV CPU 使用平穩，使用峯值均在 30 核內，暫不存在系統瓶頸；HMS 服務的穩定性整體可控，關鍵 API 性能指標滿足業務的實際需求，為業務的增長提供可靠支持。在未來三年內，我們將保持該架構去支撐整個大數據平台組件的穩定運行，期間我們也將持續關注行業內的變動，吸收更多優秀經驗應用到我們的生產環境中來，包括但不限於對性能更好的高版本 TiDB 嘗試，HMS 的性能優化案例。</p></section><p powered-by="xiumi.us"><br></p><section style="margin-right: 0%;margin-bottom: 20px;margin-left: 0%;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: middle;width: 20%;align-self: center;flex: 0 0 auto;"><section style="text-align: center;color: rgb(45, 66, 87);font-size: 11px;" powered-by="xiumi.us"><p>END</p></section></section><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="margin-top: 10px;margin-bottom: 10px;text-align: left;" powered-by="xiumi.us"><section style="padding-left: 1em;padding-right: 1em;display: inline-block;text-align: center;"><span style="display: inline-block;padding: 0.3em 0.5em;border-radius: 0.5em;background-color: rgb(65, 94, 255);color: rgb(255, 255, 255);" title="" opera-tn-ra-cell="_$.pages:0.layers:0.comps:129.title1"><p>猜你喜歡</p></span></section><section style="border-width: 1px;border-style: solid;border-color: transparent;margin-top: -1em;padding: 20px 10px 10px;background-color: rgb(239, 239, 239);text-align: center;"><section style="font-size: 14px;text-align: left;" powered-by="xiumi.us"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497299%26idx%3D1%26sn%3Dbf5b4b07d96090267e996a1dc3d0dce1%26chksm%3Debdb86c1dcac0fd7b7b662020ec78a154c8011be6cd0d6b19c091fa1befbc5f79ff45890b45b%26scene%3D21%23wechat_redirect" textvalue="vivo 數據中心網絡鏈路質量監測的探索實踐" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">vivo 數據中心網絡鏈路質量監測的探索實踐</a></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497274%26idx%3D1%26sn%3Db79ed12d3854f14a7e77eaae5f0de6b2%26chksm%3Debdb86a8dcac0fbe9743c35887bbf6299506aa490bfcd220b4872d506152ee1dcc4c5b45799a%26scene%3D21%23wechat_redirect" textvalue="K8s 多集羣實踐思考和探索" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">K8s 多集羣實踐思考和探索</a></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497145%26idx%3D2%26sn%3D55519f4b73ff9b4a0d19ce6d0ac09a30%26chksm%3Debdb852bdcac0c3d0eb7fdc587942aa7203c63d04f6fefcd688a7a0f0bbaf8288479372695f6%26scene%3D21%23wechat_redirect" textvalue="JVM 內存大對象監控和優化實踐" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">JVM 內存大對象監控和優化實踐</a></p></li></ul></section></section></section><p powered-by="xiumi.us"><br></p><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互聯網技術" data-alias="vivoVMIC" data-signature="分享 vivo 互聯網技術乾貨與沙龍活動，推薦最新行業動態與熱門會議。" data-from="0"></mp-common-profile></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - vivo 互聯網技術（vivoVMIC）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/10114822</guid>
            <link>https://my.oschina.net/vivotech/blog/10114822</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘋果 App Store 免費榜第一是黃色軟件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>澎湃新聞今日報道蘋果 App Store 出現偽裝成學習軟件的黃色軟件，並且衝上了「免費 App」排行榜第一名。</p><p>據悉，該軟件的年齡分級為 4 歲以上，但是會引導用户進入賭博和其他黃色網站。網友小同表示，他下載了這款軟件，想要學習英語字母，結果發現是一個色情視頻軟件。他認為這種偽裝成學習軟件的行為很危險，很容易對孩子造成不良影響。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c7a0ce5e4272f1b06c5119529647215fb11.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-69f6205b4eceb10672c0a3cff67e4f52d48.png" referrerpolicy="no-referrer"></p><p>事件被曝光後，蘋果客服雖然進行了迴應，但直到下午仍未下架軟件。甚至排行榜更新後，App Store 免費榜第一、二名再次出現黃色軟件，名為「騎 XX」、「牡丹 XXX」，年齡分級為 4 歲以上。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8b7f27342ea504c47ae6724514736b106a3.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-db2cf9f1307034d7e3a68e35ea067a0fe4f.png" referrerpolicy="no-referrer"></p><p><strong style="color:#424242">截至發稿，這些軟件已被下架</strong><span style="background-color:#ffffff; color:#424242">。</span></p><p><span style="background-color:#ffffff; color:#424242">眾所周知，蘋果應用商店的審核規則極為嚴格。</span>上面提到的 App 其實就是瀏覽器套殼，前端顯示的內容可以通過後台隨意修改。但問題在於，蘋果 App 的審核團隊為何讓這些「套殼」 App 上架到了應用商店？</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 14:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260711</guid>
            <link>https://www.oschina.net/news/260711</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[VS Code 的 C# 開發套件 (C# Dev Kit) 正式 GA]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今年 6 月，微軟在 Visual Studio Code 的插件市場<a href="https://www.oschina.net/news/244148/c-sharp-dev-kit-for-visual-studio-code" target="_blank">上架</a>了官方打造的<strong> C# 開發套件 —— C# Dev Kit</strong>，讓開發者在 VS Code 中方便地進行 C# 開發。</p><p>據介紹，C# Dev Kit 提高了開發者在使用 VS Code 過程中開發 C# 語言產品的效率。該套件兼容 C# 擴展，由語言服務器協議&nbsp; (LSP) 主機提供支持，從而創建一個高性能、可擴展且靈活的工具環境，可輕鬆將新體驗集成到 C# for VS Code 中。</p><p>經過 4 個多月的測試和打磨，微軟近日宣佈&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fcsharp-dev-kit-now-generally-available%2F" target="_blank"><strong>C# Dev Kit 正式 GA</strong></a>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-abd88ca70f16b7de5318e2944c0f5c847dd.png" referrerpolicy="no-referrer"></p><p>微軟表示在預覽版期間，累計為 C# Dev Kit 修復了 350 多個問題，其中大部分由社區報告，並對該產品進行了 300 多項有針對性的改進。</p><p>微軟稱用户的反饋加速推進了 C# Dev Kit 的正式發佈，開發團隊會繼續提升性能和可靠性，並將每月添加新功能。</p><p>根據微軟的介紹，C# Dev Kit 從 Visual Studio 中借用了一些開發者們熟悉的概念，並能夠與現有的 C# 擴展一起使用，以及通過增加一套強大的工具和實用程序來增強 C# 開發環境，這些工具和實用程序與 VS Code 原生集成，以幫助 C# 開發者更快地編寫、調試和維護他們的代碼，並減少錯誤。</p><p>C# Dev Kit 由以下部分組成：</p><ul><li><strong>C# 擴展</strong>：它提供基本的語言服務支持，並繼續獨立於這項工作進行維護；</li><li><strong>C# Dev Kit 擴展</strong>：它建立在 Visual Studio 的基礎上，提供解決方案管理、模板、測試、調試；</li><li><strong>IntelliCode for C# Dev Kit 擴展</strong>：它將 AI 驅動的開發帶到了編輯器中；</li></ul><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0607/112538_up8O_4937141.png" referrerpolicy="no-referrer"></p><p><strong><a href="https://www.oschina.net/news/244148/c-sharp-dev-kit-for-visual-studio-code" target="_blank">點此查看詳細介紹</a></strong>。</p><p>C# Dev Kit 下載地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3Dms-dotnettools.csdevkit%26ssr%3Dfalse" target="_blank">https://marketplace.visualstudio.com/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260688/vs-code-csharp-dev-kit-ga</guid>
            <link>https://www.oschina.net/news/260688/vs-code-csharp-dev-kit-ga</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Docker 與 Neo4j 等合作推出 GenAI Stack]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Docker 在其年度 DockerCon 開發者大會主題演講中<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fintroducing-a-new-genai-stack%2F" target="_blank">宣佈</a>與 Neo4j、LangChain 和 Ollama 合作推出新的 GenAI Stack。該 GenAI Stack <span style="background-color:#ffffff">簡化了 AI/ML 集成，</span>旨在幫助開發人員快速輕鬆地構建生成式 AI 應用程序，而無需搜索和配置各種技術。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-0852df0e6f3480e6f6d1ddd240cf679021f.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">根據介紹，GenAI Stack 中包含的內容包括有：</span></p><ul><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>預配置的 LLM</strong>：提供預配置的大語言模型 (LLM)，例如 Llama2、GPT-3.5 和 GPT-4，以快速啓動 AI 項目。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Ollama&nbsp;管理</strong>：Ollama 簡化了開源 LLM 的本地管理，讓你的 AI 開發過程更加順暢。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Neo4j 作為默認數據庫</strong>：Neo4j 作為默認數據庫，提供圖形和原生向量搜索功能。這有助於揭示數據模式和關係，最終提高 AI/ML 模型的速度和準確性。Neo4j 還充當這些模型的長期存儲器。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Neo4j 知識圖譜</strong>：Neo4j 知識圖譜為 LLM 提供更精確的 GenAI 預測和結果。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>LangChain 編排</strong>：LangChain 促進了 LLM、應用程序和數據庫之間的通信，並提供了一個強大的向量索引。LangChain 是一個用於開發由 LLM 支持的應用程序的框架。其中包括 LangSmith，一種調試、測試、評估和監控 LLM 應用程序的新方法。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>全面支持</strong>：提供了一系列有用的工具、代碼模板、操作指南和 GenAI 最佳實踐。</span></span></li></ul><p><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-346a6330b9b20f9dbd5753904b2051aeda1.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">此外，該公司還通過</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fai-early-access-program%2F" target="_blank">搶先體驗計劃</a><span style="color:#000000">推出了一款新的生成式 AI 助手，名為 Docker AI。&nbsp;Docker 首席執行官 Scott Johnston 表示，與 Copilot 或&nbsp;Amazon&nbsp;CodeWhisperer 等其他代碼生成助手相比，Docker AI 助手可以幫助開發人員定義應用程序的各個方面並排除故障。</span></p><p><span style="color:#000000">"當開發人員編輯 Dockerfile 或 Docker Compose 文件、調試本地 docker build 或在本地運行測試時，Docker AI 會根據具體情況提供自動指導。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 09:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260683/docker-genai-stack</guid>
            <link>https://www.oschina.net/news/260683/docker-genai-stack</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[路透社：RISC-V 技術成為中美科技戰的新戰場]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>路透社昨日發佈文章《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fus-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06%2F" target="_blank">RISC-V technology emerges as battleground in US-China tech war</a>》，稱 RISC-V 技術成為中美科技戰的新戰場。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1008/154055_rmKV_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>文章指出，拜登政府面臨來自部分立法者的壓力，要求限制美國公司開發在中國被廣泛使用的免費芯片技術——此舉可能會顛覆全球科技行業的跨境合作。</p><p>兩名共和黨眾議院委員會主席、共和黨參議員 Marco Rubio 和民主黨參議員 Mark Warner 以國家安全為由，敦促拜登政府對 RISC-V 採取行動。</p><p>議員擔心中國政府正在利用美國公司之間的開放合作文化來發展自己的半導體產業，這可能會削弱美國目前在芯片領域的領先地位，並幫助中國推進軍事現代化。</p><p>議員呼籲拜登政府對 RISC-V 相關技術的出口實施限制——「要求任何美國個人或公司在與中國實體就相關貿易往來之前獲得出口許可證」，這也是中美芯片技術之爭的最新進展。</p><p>早在 2020 年，負責 RISC-V 技術的非盈利組織——RISC-V 基金會已將總部遷移至瑞士。</p><hr><p><strong>延伸閲讀</strong></p><ul><li><p><a href="https://www.oschina.net/news/183326/riscv_chip_wars">在全球芯片大戰中，RISC-V 能否保持其中立態度？</a></p></li><li><p><a href="https://www.oschina.net/news/123334/risc-v-international-report-2020">RISC-V 基金會：確保技術不受地區邊界影響</a></p></li><li><p><a href="https://www.oschina.net/news/114220/risc-v-foundation-moved-to-switzerland">RISC-V 基金會總部已正式遷移至瑞士</a></p></li><li><p><a href="https://www.oschina.net/news/111648/risc-v-foundation-to-move-to-switzerland">怕被政治燒到，RISC-V 基金會決定遷址瑞士</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 08:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260839/us-china-tech-war-risc-v</guid>
            <link>https://www.oschina.net/news/260839/us-china-tech-war-risc-v</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 23.10 將正式支持 Raspberry Pi 5]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根據 omgubuntu 的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F10%2Fubuntu-23-10-will-support-raspberry-pi-5" target="_blank">報道</a>，即將發佈的 Ubuntu 23.10 會正式支持<a href="https://www.oschina.net/news/259858/introducing-raspberry-pi-5" target="_blank">樹莓派 5</a>。</p><blockquote><p style="margin-left:0px; margin-right:0px; text-align:start"><strong>延伸閲讀：<a href="https://www.oschina.net/news/259858/introducing-raspberry-pi-5" target="_blank">Raspberry Pi 5 將於 10 月底發佈，60 美元起售</a></strong></p></blockquote><p>報道指出，由於 Canonical 開發者可以提前使用樹莓派 5，因此他們能夠在設備上測試即將發佈的 Ubuntu 版本，確定需要支持新硬件的領域，並將所需的新（和已升級）軟件包放入 file_Feature Freeze Exceptions_to （文件_功能凍結異常_隊列）中。</p><p>部分針對樹莓派 5 的改進包括：引入新的&nbsp;<code>pisp</code>&nbsp;包來處理樹莓派 5 大大增強的相機功能；並對&nbsp;<code>python3-gpiozero</code>&nbsp;進行重大更新，以符合新型號對其 GPIO 操作所做的更改。</p><p>另外要注意的是，更新的 rpiboot 軟件包將無法在 Ubuntu 23.10 發佈時及時提供，但由於這不是嚴格要求的，所以問題不大。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 07:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260645/ubuntu-23-10-will-support-raspberry-pi-5</guid>
            <link>https://www.oschina.net/news/260645/ubuntu-23-10-will-support-raspberry-pi-5</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里雲 PAI - 靈駿大模型訓練工具 Pai-Megatron-Patch 正式開源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h3_1"></span><h3>Pai-Megatron-Patch 是什麼</h3><p style="text-align:justify">Pai-Megatron-Patch 工具是阿里雲機器學習平台 PAI 算法團隊研發，基於阿里雲智算服務 PAI-靈駿平台的大模型最佳實踐解決方案配套工具，旨在幫助大模型開發者快速上手靈駿產品，完成大語言模型（LLM）的高效分佈式訓練，有監督指令微調，模型離線推理驗證等完整大模型開發鏈路。該項目提供了業界主流開源大模型基於 Megatron-LM 的訓練&amp;離線推理驗證流程，方便用户快速上手大模型訓練。</p><span id="OSC_h3_2"></span><h3>主要特性</h3><ul><li>多款熱門大模型支持：llama，llama-2，codellama, 百川，通義千問，Falcon，GLM，Starcoder，Bloom，chatglm 等</li><li>支持模型權重互轉轉換：在 Huggingface，Megatron 和 Transformer Engine 之間進行算子命名空間映射</li><li>支持 Flash Attention 2.0 和 Transformer Engine 模式下的 FP8 訓練加速且確保收斂</li><li>豐富且簡單易用的使用示例，支持大模型預訓練，微調，評估和推理，強化學習全流程最佳實踐</li></ul><span id="OSC_h3_3"></span><h3>開源地址</h3><p style="text-align:justify"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%253Fspm%253Da2c6h.13046898.publish-article.3.5d586ffa9uOzwk" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a></p><span id="OSC_h3_4"></span><h3>技術架構</h3><p style="text-align:justify">Pai-Megatron-Patch 的設計理念是不對 Megatron-LM 的源碼進行侵入式修改，即不在 Megatron-LM 裏面添加新的功能特性，將需要擴充完善的部分以 patch 補丁的方式呈現。在 patch 中構建 LLM 訓練鏈路通過依賴 Megatron-LM 核心庫的方法實現和 Megatron-LM 的解耦合。這樣解耦合的好處就是 Megatron-LM 的升級不會影響用户的 LLM 最佳實踐體驗。</p><p style="text-align:justify">Pai-Megatron-Patch 中包含模型庫，分詞器，模型轉換，強化學習，離線文本生成以及使用示例和工具集等用於構建 LLM 訓練的關鍵要素。在模型庫中包含熱門大模型的 Megatron 版本實現，例如 baichuan，bloom，chatglm，falcon，galactica，glm，llama，qwen 和 starcoder，後續還會根據需要及時添加新的 Megatron 版大模型實現。同時 patch 還提供了 huggingface 模型權重和 Megatron 模型權重之間的雙向轉換。一方面是方便用户加載 huggingface 的權重在 Megatron 中繼續預訓練或者微調，另一方面是方便用户對訓練好的 Megatron 模型使用 huggingface 的評估/推理流程對模型質量進行客觀評估。在強化學習部分，patch 提供了 PPO 訓練流程等，方便用户使用 SFT 模型和 RM 模型進行強化學習。最後 patch 提供了大量的使用示例幫助用户快速開始大模型訓練&amp;離線推理。具體請參考阿里雲靈駿產品的使用流程:&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F2505831.html%253Fspm%253Da2c6h.13046898.publish-article.4.5d586ffa9uOzwk%2526tab%253Donestop" target="_blank">智算服務 PAI 靈駿大模型分佈式訓練方案</a></p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-2459be9f4c59a8fd9ac6472cd888c176_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h3_5"></span><h3>關鍵技術</h3><span id="OSC_h4_6"></span><h4>模型權重轉換</h4><p style="text-align:justify">研發 Megatron-Patch 的初衷之一就是能將世界各地研發機構在 Huggingface 上放出的熱門大模型使用 Megatron 引擎進行繼續預訓練或者繼續微調。這就需要首先將 Huggingface 模型格式的 ckpt 轉換成 Megatron 模型格式，才能正確加載進來，否則會出現 pytorch 加載模型失敗。Megatron-Patch 的一個核心可靠性保障特徵就是在採用算子拆分，流水並行，序列並行，Zero 顯存優化，BF16 混合精度，梯度檢查點等訓練加速技術確保模型訓練吞吐速度平均提升 1.5 倍以上的同時，在評估任務模式下的單一樣本前向 loss 值，預訓練/微調任務模式下的 loss 曲線，離線文本生成任務模式下的生成效果這三個方面和 Huggingface 是對齊的，從而確保 Megatron 版模型的可靠性。</p><p style="text-align:justify">另一方面，Megatron 版的 transformer 實現方式提供了一種讓用户僅僅通過設置開關就能實現不同種類 GPT 模式的能力。比如 llama 模型打開如下開關即可</p><pre><code>--swiglu \
  --use-rotary-position-embeddings \
  --no-position-embedding \
  --untie-embeddings-and-output-weights \
  --disable-bias-linear</code></pre><p style="text-align:justify">如果想將 llama 模式變成 baichuan 模型，那麼僅僅需要添加採用--use-alibi-mask 開關，同時關閉 Rotary Embeeding 開關即可，具體配置如下所示：</p><pre><code>--swiglu \
  --use-alibi-mask \
  --position-embedding-type none \
  --untie-embeddings-and-output-weights \
  --disable-bias-linear</code></pre><p style="text-align:justify">下面我們以 llama-2 為例，詳解從 huggingface 到 megatron 的模型權重轉換技術。下表總結了兩者在不同 module 上的命名對應關係。在 patch 實現過程中，我們首先將 HF 格式的 ckpt 轉換到一種內部格式，然後再把這種內部格式轉換成對應的外部格式。這樣做可以最大程度複用已有的轉換邏輯來處理新模型。在轉換為內部格式的過程中，</p><p style="text-align:justify">q_proj, k_proj, v_proj 需要沿着第 0 維拼接在一起後賦值給內部變量 query_key_value。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-e3637f10e008e7548046df938ee8bac6_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">當用户在資源受限情況下需要按照 TP&gt;1 來拆分權重的時候，這裏需要注意的是針對 MLP 層的 gate_proj 和 up_proj 的操作。不能像 qkv 那樣在轉換成內部格式的時候進行 merge 再執行算子拆分。需要在拆分前加入如下針對 MLP 層的權重合並的代碼邏輯才能確保正確收斂。</p><pre><code>for i in range(tp_size):
    params_dict = get_element_from_dict_by_path(output_state_dict[i],
                                                "model.language_model.encoder")
    dense_h_to_4h_1_name = 'mlp.dense_h_to_4h_1.weight'
    dense_h_to_4h_1_layer_name = f"layers.{layer}.{dense_h_to_4h_1_name}"
    dense_h_to_4h_1_weight = params_dict[dense_h_to_4h_1_layer_name]
    dense_h_to_4h_2_name = 'mlp.dense_h_to_4h_2.weight'
    dense_h_to_4h_2_layer_name = f"layers.{layer}.{dense_h_to_4h_2_name}"
    dense_h_to_4h_2_weight = params_dict[dense_h_to_4h_2_layer_name]
    dense_h_to_4h_name = 'mlp.dense_h_to_4h.weight'
    dense_h_to_4h_layer_name = f"layers.{layer}.{dense_h_to_4h_name}"
    params_dict[dense_h_to_4h_layer_name] = torch.cat(
    [dense_h_to_4h_1_weight, dense_h_to_4h_2_weight], dim=0)</code></pre><span id="OSC_h4_7"></span><h4>基於 TE 的 FP8 訓練收斂</h4><p style="text-align:justify">Transformer Engine(TE) 是一個在英偉達 GPUS 上運行的針對 Transformer 模型的加速庫，其中包括針對 Hopper GPU 的 FP8 混合精度，該精度可以在較低的顯存利用率下提供更好的訓練&amp;推理速度。在 TE 內部封裝了 Flash Attention 實現，同時 TE 還提供了一組高度優化後的算子用來構建 Transformer 模型。比如 LayerNormLinear 就是將 LayerNorm 和 QKV-Proojection 進行算子融合，LayerNormMLP 就是將 layernorm 和 mlp 進行算子融合。如下圖所示：</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-214b47fb7b967d3f92dd7dd58092446b_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">從 Huggingface 到 TE 模型的權重轉換技術和之前是類似的，也需要事先找到兩者之間的映射關係。從下表可以看出，TE 中多了_extra_state 是用來存 fp8 訓練的 scale 和 history 的，這些在加載的時候會出現衝突，這時只要將 load_state_dict 函數的 strict 設置成 False 就可以了，比如 load_state_dict(state_dict_, strict=False)。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-125038fa0f82beec327ee0234b3b79c2_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">在 Megatron-Patch 中使用示例中打開 FP8 混合精度訓練開關也很容易，如下所示：</p><pre><code>if [ $PR = fp16 ]; then
    pr_options=" \
        --fp16"
elif [ $PR = bf16 ]; then
    pr_options=" \
        --bf16"
elif [ $PR = fp8 ]; then
    pr_options=" \
        --bf16
        --fp8-hybrid \
        --fp8-amax-compute-algo max \
        --fp8-amax-history-len 1024 \
        --transformer-impl transformer_engine"
fi</code></pre><p style="text-align:justify">我們可以使用如下訓練腳本<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fgpt3_llama%2Frun_pretrain_megatron_llama_enwiki.sh%253Fspm%253Da2c6h.13046898.publish-article.5.5d586ffa9uOzwk%2526file%253Drun_pretrain_megatron_llama_enwiki.sh" target="_blank">run_pretrain_megatron_llama_enwiki.sh</a>來測試打開 FP8 開關後的預訓練收斂性。下圖展示了 llama-7B 和 llama-2-70B 模型在打開和關閉 FP8 時的 loss 曲線對比，可以看出基本是重合的。</p><p style="text-align:justify">LLama-7B</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-6b4c07368bdeb4e3c80251d6972511f1_720w.webp" referrerpolicy="no-referrer"></p><p>LLama2-70B</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-6ed82c26ed8ee7661a913687e7905a6b_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_8"></span><h4>大模型訓練&amp;推理</h4><p style="text-align:justify">從 github 上獲取 Megatron 模型訓練工具 PAI-Megatron-Patch（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%253Fspm%253Da2c6h.13046898.publish-article.6.5d586ffa9uOzwk" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a>）源代碼並拷貝到工作目錄/mnt/workspace/下。</p><p style="text-align:justify"><strong>模型格式轉換</strong></p><p style="text-align:justify">使用我們提供的模型轉換腳本，將 huggingface 格式的模型文件轉換為 megatron 格式：</p><pre><code>cd /mnt/workspace/
mkdir llama2-ckpts
cd llama2-ckpts
wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-ckpts/Llama-2-7b-hf.tgz
tar -zxf Llama-2-7b-hf.tgz
mv Llama-2-7b-hf llama2-7b-hf
cd /mnt/workspace/PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/llama
sh model_convertor.sh \
/root/Megatron-LM-23.04        \
/mnt/workspace/llama2-ckpts/llama2-7b-hf         \
/mnt/workspace/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1  \
1  \
1  \
llama-7b \
0 \
false</code></pre><p style="text-align:justify"><strong>繼續預訓練</strong></p><p style="text-align:justify">中文繼續預訓練漢化指引</p><p style="text-align:justify">Step1: 獲取需要擴充詞表的模型（如 llama-13b-hf）</p><p style="text-align:justify">Step2: 獲取需要擴充的詞表</p><ul><li>使用 sentence-piece 代碼庫從自有文本語料中學習詞表，得到 randeng-sp.model 文件</li></ul><p style="text-align:justify">Step3: 詞表擴充</p><ul><li>擴充模型 tokenizer：將 randeng-sp.model 中的詞表添加到 llama-13b-hf 文件夾下 tokenizer.model 中</li><li>擴充模型詞表對應的參數矩陣 
  <ul><li>word_embedding、lm_head</li><li>新詞向量可以使用原詞向量均值作為初始化，比如「天氣」=mean([「天」，「氣」])</li></ul></li><li>修改與詞表大小相關的文件並保存，如 config.json</li></ul><p style="text-align:justify">運行繼續預訓練腳本&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fllama2%2Frun_pretrain_megatron_llama.sh%253Fspm%253Da2c6h.13046898.publish-article.7.5d586ffa9uOzwk%2526file%253Drun_pretrain_megatron_llama.sh" target="_blank">run_pretrain_megatron_llama.sh</a>，需要傳入的參數列表如下</p><pre><code>ENV=$1                          # 運行環境: dlc, dsw
MEGATRON_PATH=$2                # 設置開源 Megatron 的代碼路徑
MEGATRON_PATCH_PATH=$3          # 設置 Megatron Patch 的代碼路徑
MODEL_SIZE=$4                   # 模型結構參數量級：7B, 13B
BATCH_SIZE=$5                   # 每卡訓練一次迭代樣本數: 4, 8
GLOBAL_BATCH_SIZE=$6            # 全局 batch size
LR=$7                           # 學習率: 1e-5, 5e-5
MIN_LR=$8                       # 最小學習率: 1e-6, 5e-6
SEQ_LEN=$9                      # 序列長度
PAD_LEN=${10}                   # Padding 長度：100
EXTRA_VOCAB_SIZE=${11}          # 詞表擴充大小
PR=${12}                        # 訓練精度: fp16, bf16
TP=${13}                        # 模型並行度
PP=${14}                        # 流水並行度
AC=${15}                        # 激活檢查點模式: sel, full
DO=${16}                        # 是否使用 Megatron 版 Zero-1 降顯存優化器: true, false
FL=${17}                        # 是否使用 Flash Attention: true, false
SP=${18}                        # 是否使用序列並行: true, false
SAVE_INTERVAL=${19}             # 保存 ckpt 的間隔
DATASET_PATH=${20}              # 訓練數據集路徑
PRETRAIN_CHECKPOINT_PATH=${21}  # 預訓練模型路徑
TRAIN_TOKENS=${22}              # 訓練 token 數
WARMUP_TOKENS=${23}             # 預熱 token 數
OUTPUT_BASEPATH=${24}           # 訓練輸出文件路徑</code></pre><p style="text-align:justify">注意設置正確的數據集<strong>掛載路徑 WORK_DIR</strong>以及<strong>運行環境 ENV</strong>，運行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_pretrain_megatron_llama.sh \
dlc \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B   \
1    \
16 \
1e-5   \
1e-6   \
2048  \
80  \
0   \
fp16  \
1   \
1  \
sel  \
true   \
false  \
false   \
100000  \
${WORK_DIR}/llama2-datasets/wudao/wudao_llamabpe_text_document   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
100000000   \
10000   \
${WORK_DIR}/output_megatron_llama2/</code></pre><p style="text-align:justify"><strong>有監督微調</strong></p><p style="text-align:justify">在微調開始之前，請先進入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Ftoolkits%2Fpretrain_data_preprocessing%2FREADME.md%253Fspm%253Da2c6h.13046898.publish-article.8.5d586ffa9uOzwk%2526file%253DREADME.md" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch/blob/main/toolkits/pretrain_data_preprocessing/README.md</a>&nbsp;獲取 json 文件。運行<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fllama2%2Frun_finetune_megatron_llama.sh%253Fspm%253Da2c6h.13046898.publish-article.9.5d586ffa9uOzwk%2526file%253Drun_finetune_megatron_llama.sh" target="_blank">run_finetune_megatron_llama.sh</a>腳本，需要傳入的參數列表如下</p><pre><code>ENV=$1                          # 運行環境: dlc, dsw
MEGATRON_PATH=$2                # 設置開源 Megatron 的代碼路徑
MEGATRON_PATCH_PATH=$3          # 設置 Megatron Patch 的代碼路徑
MODEL_SIZE=$4                   # 模型結構參數量級: 7B, 13B
BATCH_SIZE=$5                   # 每卡訓練一次迭代樣本數: 4, 8
LR=$6                           # 學習率: 1e-5, 5e-5
MIN_LR=$7                       # 最小學習率: 1e-6, 5e-6
SEQ_LEN=$8                      # 序列長度
PAD_LEN=$9                      # Padding 長度：100
EXTRA_VOCAB_SIZE=${10}          # 詞表擴充大小
PR=${11}                        # 訓練精度: fp16, bf16
TP=${12}                        # 模型並行度
PP=${13}                        # 流水並行度
AC=${14}                        # 激活檢查點模式: sel, full
DO=${15}                        # 是否使用 Megatron 版 Zero-1 降顯存優化器: true, false
FL=${16}                        # 是否使用 Flash Attention: true, false
SP=${17}                        # 是否使用序列並行: true, false
TRAIN_DATASET_PATH=${18}        # 訓練數據集路徑
VALID_DATASET_PATH=${19}        # 驗證數據集路徑
PRETRAIN_CHECKPOINT_PATH=${20}  # 預訓練模型路徑
EPOCH=${21}                     # 訓練迭代輪次
OUTPUT_BASEPATH=${22}           # 訓練輸出文件路徑</code></pre><p style="text-align:justify">多節點運行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
sh run_finetune_megatron_llama.sh  \
dlc    \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B     \
1      \
1e-5   \
1e-6   \
2048   \
80     \
0      \
fp16   \
1      \
1      \
sel    \
true   \
false  \
false  \
${WORK_DIR}/llama2-datasets/wudao_train.json   \
${WORK_DIR}/llama2-datasets/wudao_valid.json   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
2   \
${WORK_DIR}/output_megatron_llama2/
</code></pre><p style="text-align:justify"><strong>離線推理</strong></p><p style="text-align:justify">模型訓練完成後，可以進行離線推理，評估模型效果。根據上面的訓練流程不同，我們提供了 Megatron 格式的推理鏈路。對於 Megatron 訓練的模型，可以直接用 Megatron 框架進行推理。</p><pre><code>ENV=$1                          # 運行環境: dlc, dsw
MEGATRON_PATH=$2                # 設置開源 Megatron 的代碼路徑
MEGATRON_PATCH_PATH=$3          # 設置 Megatron Patch 的代碼路徑
CHECKPOINT_PATH=$4              # 模型微調階段的模型保存路徑
MODEL_SIZE=$5                   # 模型結構參數量級: 1.1B, 1.7B, 7.1B
TP=$6                           # 模型並行度
BS=$7                           # 每卡推理一次迭代樣本數: 1, 4, 8
SEQ_LEN=$8                      # 序列長度: 256, 512, 1024
PAD_LEN=$9                      # PAD 長度：需要將文本拼接到的長度
EXTRA_VOCAB_SIZE=${10}          # 模型轉換時增加的 token 數量
PR=${11}                        # 推理採用的精度: fp16, bf16
TOP_K=${12}                     # 採樣策略中選擇排在前面的候選詞數量 (0-n): 0, 5, 10, 20
INPUT_SEQ_LEN=${13}             # 輸入序列長度: 512
OUTPUT_SEQ_LEN=${14}            # 輸出序列長度: 256
INPUT_FILE=${15}                # 需要推理的文本文件: input.txt, 每行為一個樣本
OUTPUT_FILE=${16}               # 推理輸出的文件: output.txt
# TOP_K 和 TOP_P 必須有一個為 0
TOP_P=${17}                     # 採樣策略中選擇排在前面的候選詞百分比 (0-1): 0, 0.85, 0.95
TEMPERATURE=${18}               # 採樣策略中温度懲罰: 1-n
REPETITION_PENALTY=${19}        # 避免生成是產生大量重複，可以設置為 (1-2) 默認為 1.2</code></pre><ul><li>此處提供一個離線推理輸出的文件，推理的數據組織形式需要與微調時的保持一致。 
  <ul><li>測試樣本：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fatp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com%2Frelease%2Fmodels%2Fpai-megatron-patch%2Fllama2-datasets%2Fpred_input.jsonl%253Fspm%253Da2c6h.13046898.publish-article.10.5d586ffa9uOzwk%2526file%253Dpred_input.jsonl" target="_blank">https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-datasets/pred_input.jsonl</a></li></ul></li><li>注意： 
  <ul><li>模型保存的路徑下缺少 tokenizer 依賴的文件，需要將微調前模型路徑下所有 json 文件及 tokenizer.model 拷貝至保存模型的路徑下（位於{OUTPUT_BASEPATH }/checkpoint），與 latest_checkpointed_iteration.txt 同級。</li></ul></li></ul><p style="text-align:justify">以下有監督微調過程保存模型的推理代碼，需要將 run_text_generation_megatron_llama.sh 腳本中 CUDA_VISIBLE_DEVICES 參數設置為 0；GPUS_PER_NODE 參數設置為 1；同時使用下列代碼進行推理。此時使用單卡進行推理。<strong>注意：此處模型 tp 為 1，可使用單卡推理；如果 tp&gt;1，則需使用相應卡數進行推理。</strong></p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_text_generation_megatron_llama.sh \
dsw \
/root/Megatron-LM-23.04 \
${WORK_DIR}/PAI-Megatron-Patch \
../../../llama2-train \
7B \
1 \
1 \
1024 \
1024 \
0 \
fp16 \
10 \
512 \
512 \
${WORK_DIR}/pred_input.jsonl \
${WORK_DIR}/llama2_pred.txt \
0 \
1.0 \
1.2</code></pre><span id="OSC_h4_9"></span><h4>大模型強化學習</h4><p style="text-align:justify">一般來説，SFT 微調過的模型在對話場景已經會有不錯的表現了。如果想進一步提升模型效果，可以再加上 RLHF 訓練。包括獎勵模型（Reward Model）的訓練和強化學習（PPO）的訓練。這裏展示瞭如何使用當前最常用的 RLHF 開源代碼框架，DeepSpeed-Chat 和 trlx，來進行獎勵函數訓練（RM），以及強化學習優化（PPO）。</p><p style="text-align:justify"><strong>模型格式轉換</strong></p><p style="text-align:justify">如果基於 huggingface 格式的模型直接進行獎勵模型訓練（RM）和強化學習優化（PPO），可以跳過此步驟。</p><p style="text-align:justify">如果基於 Megatron 格式的模型，如 PAI-Megatron-Patch 訓練好的 SFT 模型，進行 RM 和 PPO 訓練，需要使用我們提供的模型轉換腳本，先將 Megatron 格式的模型文件轉換為 huggingface 格式。</p><p style="text-align:justify">LLaMA2 模型轉換：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/gpt3_llama
bash model_convertor.sh \
/path/to/Megatron-LM \
/path/to/megatron_llama2_ckpt \
/path/to/hf_llama2_ckpt \
1 \
1 \
llama-7b \
0 \
true</code></pre><p style="text-align:justify">BLOOM 模型轉換：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/bloom
bash model_convertor_huggingface_megatron.sh \
/path/to/Megatron-LM \
/path/to/megatron_bloom_ckpt \
/path/to/hf_bloom_ckpt \
1 \
1 \
true</code></pre><p style="text-align:justify"><strong>DeepSpeed-Chat</strong></p><p style="text-align:justify">下載安裝開源社區 DeepSpeed-Chat 源代碼：</p><pre><code>cd PAI-Megatron-Patch/rlhf/deepspeed-chat
git clone https://github.com/microsoft/DeepSpeedExamples.git
cp -f rm_main.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/main.py
cp -f utils.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/utils.py
cd DeepSpeedExamples/applications/DeepSpeed-Chat/
pip install -r requirements.txt</code></pre><p style="text-align:justify">基於 LLaMA2 模型訓練獎勵模型（RM）：</p><pre><code>cd training/step2_reward_model_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b.sh</code></pre><p style="text-align:justify">基於 LLaMA2 進行強化學習優化訓練（PPO）：</p><pre><code>cd training/step3_rlhf_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b_lora.sh</code></pre><p style="text-align:justify"><strong>trlx</strong></p><p style="text-align:justify">下載安裝開源社區 trlx 源代碼：</p><pre><code>cd PAI-Megatron-Patch/rlhf/trlx
git clone https://github.com/CarperAI/trlx.git
cp trlx_bloom_rlhf.py trlx_bloom_rlhf_test.py trlx/examples/summarize_rlhf/
cp train_reward_model_bloom.py reward_model_bloom.py ds_config_bloom.json trlx/examples/summarize_rlhf/reward_model/
cp -f ds_config_trlx_gptj_summarize.json trlx/examples/summarize_rlhf/configs/
cd trlx
pip install -e .</code></pre><p style="text-align:justify">基於 BLOOM 模型訓練獎勵模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_bloom.py</code></pre><p style="text-align:justify">基於 GPT-J 模型訓練獎勵模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_gptj.py</code></pre><p style="text-align:justify">基於 BLOOM 模型進行強化學習優化訓練（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf.py</code></pre><p style="text-align:justify">基於 GPT-J 模型進行強化學習優化訓練（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_gptj_text_summarization.py</code></pre><p style="text-align:justify">PPO 單測</p><p style="text-align:justify">如果您想跳過，有監督微調（SFT）與，獎勵模型訓練（RM）兩個步驟，只單獨測試 PPO 模塊的性能，可以運行如下指令單測 PPO：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf_test.py</code></pre><span id="OSC_h3_10"></span><h3>開源生態——構想和未來</h3><p style="text-align:justify">在 PAI-Megatron-Patch 的開發過程中，我們圍繞中文大模型訓練加速落地沉澱了以下幾個方面的內容：</p><ul><li>Huggingface 的模型權重無損轉換成 Megatron 或者 Transformer Engine 可讀的模型權重。</li><li>H800 集羣開啓 FP8 混合精度訓練確保收斂。</li><li>LLM 大模型在 PAI 靈駿智算平台上的最佳實踐。</li><li>強化學習技術在 PAI 靈駿智算平台上的最佳實踐。</li></ul><p style="text-align:justify">後續在 PAI-Megatron-Patch 中還會陸續放出更多高質量的大模型和最佳實踐。</p><span id="OSC_h3_11"></span><h3>參考文獻</h3><p style="text-align:justify">[1]. Attention Is All You Need</p><p style="text-align:justify">[2]. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</p><p style="text-align:justify">[3]. Reducing Activation Recomputation in Large Transformer Models</p><p style="text-align:justify">[4]. FP8 Formats for Deep Learning</p><p style="text-align:justify">[5]. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</p><p style="text-align:justify">[6]. LLaMA: Open and Efficient Foundation Language Models</p><p style="text-align:justify">[7]. Llama 2: Open Foundation and Fine-Tuned Chat Models</p><p style="text-align:justify">[8]. Benchmarking Large Language Models on NVIDIA H100 GPUs with CoreWeave</p><blockquote><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fclick.aliyun.com%2Fm%2F1000373503%2F" target="_blank"><span style="color:#e67e22">點擊立即免費試用雲產品，開啓雲上實踐之旅！</span></a></strong></blockquote><p style="text-align:justify"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1337652%3Futm_content%3Dg_1000381155" target="_blank">原文鏈接</a></strong></p><p style="text-align:justify"><strong>本文為阿里雲原創內容，未經允許不得轉載。</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/yunqi/blog/10115767</guid>
            <link>https://my.oschina.net/yunqi/blog/10115767</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenJDK 合併英特爾 x86-simd-sort，將數據排序速度提高 7-15 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">今年早些時候，英特爾發佈了<span style="background-color:#ffffff">一個利用了 AVX-512 的 x86-simd-sort 快速排序庫</span>；當 Numpy 將 <span style="background-color:#ffffff">x86-simd-sort 代碼進行合併後發現</span>，對於 16 位到 64 位的數據類型，排序速度提高了 10~17 倍。如今，英特爾軟件工程師又發佈了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fx86-simd-sort%2Freleases%2Ftag%2Fv3.0" target="_blank">x86-simd-sort 3.0</a>，OpenJDK 也已經將這一修改版進行了合併。</span></p><p><img height="254" src="https://oscimg.oschina.net/oscnet/up-e6ce9bf7b77cccf7d2121e07398176707ac.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">x86-simd-sort 3.0 添加了一個新的「avx512_argselect」方法</span><span style="background-color:#ffffff; color:#000000">，用於</span><span style="color:#000000">計算 arg nth_element，該</span><span style="background-color:#ffffff; color:#000000">方法</span><span style="color:#000000">返回一個對數據數組進行分區的索引數組。x86-simd-sort 3.0 版本還對其 benchmarks 進行了改進，現在使用 __builtin_cpu_supports 而不是 querying cpuinfo，</span><span style="background-color:#ffffff; color:#000000">並進行了各種其他更改。</span><br><br><span style="color:#000000">目前，x86-simd-sort 3.0 已合併至&nbsp;Numpy 主分支中，它提供了 np.partition 和 np.argpartition 的 AVX-512 矢量化版本。將 np.partition 的 16 位速度提高了 25 倍，將 32 位 dtypes 的速度提高了 17 倍，將 64 位 dtypes 的速度提高了約 8 倍。與此同時，<span style="background-color:#ffffff">新的 avx512_argselect 方法還使&nbsp;</span>np.argpartition 的速度提高了 6.5 倍。</span></p><p><span style="color:#000000">併入 OpenJDK 的 x86-simd-sort 是一個略有修改的版本，該版本將 <span style="background-color:#ffffff">32 位數據排序速度提高了 15 倍，64 位數據排序速度提高了約 7 倍。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">更多詳情<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenjdk%2Fjdk%2Fpull%2F14227" target="_blank">可查看此處</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260605/intel-x86-simd-sort-3-0-openjdk</guid>
            <link>https://www.oschina.net/news/260605/intel-x86-simd-sort-3-0-openjdk</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 遭「卡脖子」，OpenAI 計劃自研 AI 芯片]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">根據&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F06%2Fopenai-said-to-be-considering-developing-its-own-ai-chips%2F%3Fguccounter%3D1%26guce_referrer%3DaHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS5oay8%26guce_referrer_sig%3DAQAAAL3fVeW5BS1z3Z9olNE6c2iybavGH0APpfPZxySiJi7WUXe83N7739IvRls5vIwuXKyA2eYoWcTiKlUTh7jVhzMkKKxJTSaY_n4awPm8XvK2tXu2OjLfdsRALDvUWwB1idflbNBNoRwu_fzD-uhZrxP90RGZfxjBWi5mEUiKzpMc" target="_blank">TechCrunch</a>&nbsp;的報道，隨着 AI 芯片短缺的問題日益嚴重，OpenAI 現已開始考慮自研 AI 芯片。</p><p style="color:#000000; text-align:start">據悉，從去年開始 OpenAI 內部就已經開始討論 AI 芯片戰略，以解決其 AI 芯片短缺的問題。這些方案包括自研 AI 芯片、與英偉達等芯片製造商展開更緊密的合作、實現供應商多元化等。</p><p>OpenAI 首席執行官 Sam Altman 去年就公開抱怨英偉達 GPU 芯片稀缺，稱公司受到 GPU 的嚴重限制。</p><p>由於英偉達主導了全球 95% 的 Al 訓練領域市場，隨着英偉達 GPU 顯卡稀缺，加上 AI 算力成本持續攀升，即便強如 OpenAI 也在尋找新方案，從而避免長期被「卡脖子」。</p><p style="color:#000000; text-align:start">報道稱，該公司尚未決定繼續推進。Sam Altman 此前表示已將收購更多 AI 芯片作為公司的首要任務。</p><p style="color:#000000; text-align:start"><img alt="" src="https://static.oschina.net/uploads/space/2023/1007/112609_aSEr_2720166.jpeg" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">OpenAI 和大多數競爭對手一樣，依賴基於 GPU 的硬件來開發 ChatGPT、GPT-4 和 DALL-E 3 等模型。GPU 能夠並行執行許多計算，因此非常適合訓練當今最強大的人工智能。</p><p style="color:#000000; text-align:start">不過 GPU 等芯片目前面臨嚴重短缺的問題，據報道，英偉達性能最好的人工智能芯片在 2024 年之前都已售罄。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260598</guid>
            <link>https://www.oschina.net/news/260598</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CoDeF —— 強時序一致性視頻處理算法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CoDeF 是能夠高度保持視頻時序一致性的的視頻處理算法，可以輕鬆完成視頻風格遷移、視頻關鍵點追蹤（包括流體）、用户自定義的視頻內容編輯等任務。</p><p>CoDeF 支持將圖像風格化算法升級為視頻風格化算法，將圖像關鍵點檢測算法升級為視頻關鍵點跟蹤算法（甚至包括水和煙霧等非剛性物體的追蹤），將圖像語義分割算法升級為視頻物體跟蹤算法，將圖像超分算法升級為視頻超分算法，同時支持用户可交互的視頻內容編輯。</p><p><img src="https://oscimg.oschina.net/oscnet/up-86a32563b77d2c6eaf06e2b3c03c320f292.gif" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/codef</guid>
            <link>https://www.oschina.net/p/codef</link>
        </item>
    </channel>
</rss>
