<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 06 Oct 2023 21:41:43 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[1/8 的開源下載包含已知漏洞，開源項目的積極維護減少]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">Sonatype&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.sonatype.com%2Fintroducing-our-9th-annual-state-of-the-software-supply-chain-report" target="_blank">發佈</a>了最新的一份</span>《軟件供應鏈狀況》報告，深入探討瞭如何在充滿選擇的世界中定義更好的軟件，並探討人工智能 (AI) 對軟件開發的深遠影響；還研究了開源供應、需求和安全之間錯綜複雜的相互作用。</p><p>報告跟蹤了 Java (Maven)、JavaScript (npm)、Python (PyPI)、.NET (NuGet Gallery) 四大開源生態系統的開源應用增長情況。2022 年至 2023 年間，可用開源項目的數量平均增長了 29%。2023 年，開源項目平均發佈了 15 個可供使用的版本，不同開源註冊中心的特定生態系統平均有 10 到 22 個版本。這意味着每個月都會發布 1-2 個新版本，在觀察到的生態系統中總共發佈了 6000 萬個新版本。</p><p><img height="293" src="https://oscimg.oschina.net/oscnet/up-a3af85a689f0adbcfb8236b4dac77b7f235.png" width="500" referrerpolicy="no-referrer"></p><p>每個受檢測的生態系統都表現出一致的項目增長率，平均同比增長率高達 29%。</p><p><img height="295" src="https://oscimg.oschina.net/oscnet/up-9ab7acc5786b753b241922eeaa519953a3d.png" width="500" referrerpolicy="no-referrer"></p><p>但隨着開源組件供應量的持續增長，其需求卻未能與之同步。在過去兩年中，下載量的增長率逐漸下降。2023 年的平均增長率為 33%，與 2021 年 73% 的增長率相比大幅下降。</p><p><span style="color:#000000">與此同時，開源軟件安全問題沒有放緩的跡象。截至 2023 年 9 月，研究團隊共發現了&nbsp;245,032 個惡意軟件包，是往年總和的 2 倍。八分之一的開源下載存在已知風險，且仍有 23% 的 Log4j 下載存在嚴重漏洞。</span></p><p><img height="304" src="https://oscimg.oschina.net/oscnet/up-b8b946760f70163d67ebbf53b91a14930fd.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">開源項目的主動維護也變得越來越少。研究表明，去年有近五分之一（18.6%）的項目停止維護，影響了 Java 和 JavaScript 生態系統。<span style="background-color:#ffffff">只有 11% 的開源項目實際上得到了積極維護。</span>儘管存在這些缺陷，但 Sonatype 仍然表示，近 96% 存在已知漏洞的組件下載可以通過選擇無漏洞版本來避免。</span></p><p><span style="color:#000000">就軟件開發中的人工智能而言，97% 的受訪 DevOps 和 SecOps 領導者表示，他們目前在工作流程中某種程度上使用了人工智能，大多數人每天使用兩個或更多工具。</span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>去年，企業環境中 AI 和 ML 組件的採用率增加了 135%。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">研究還發現，企業自認為的安全程度與實際情況之間存在脱節。67% 的公司表示，他們確信自己的系統中沒有來自漏洞庫的代碼，但今年有 10% 的公司因漏洞組件而遭遇安全漏洞。39% 的公司可以在</span><span style="background-color:#ffffff">&nbsp;1 到 7 天的時間內發現漏洞，29% 的公司需要一週以上的時間，28% 的公司只需要不到一天的時間。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sonatype.com%2Fstate-of-the-software-supply-chain%2Fintroduction" target="_blank">查看完整報告</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 04:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260454/9th-annual-state-of-the-software-supply-chain-report</guid>
            <link>https://www.oschina.net/news/260454/9th-annual-state-of-the-software-supply-chain-report</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AgentVerse —— 多 LLM 環境模擬框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>AgentVerse 提供了一個多功能框架，可簡化為大型語言模型（LLM）創建定製多代理環境的過程。框架旨在以最小的投入促進快速開發和定製，從而使研究人員能夠專注於他們的研究，而不是被實施細節所困擾。</p><p><img alt="" height="333" src="https://static.oschina.net/uploads/space/2023/0915/161848_BpYH_4252687.png" width="500" referrerpolicy="no-referrer"></p><h4 style="text-align:start"><strong><span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特點</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><p><span><span><strong>高效的環境構建：</strong>我們的框架提供了一系列基本構建塊，可以輕鬆創建多代理環境。只需要配置文件中的幾行，就可以輕鬆構建 LLM 聊天室等基本環境。此過程需要為 LLM 士定義環境設置和提示，使研究人員能夠專注於實驗和分析。</span></span></p></li><li><p><span><span><strong>可定製組件</strong>：AgentVerse 通過將多代理環境劃分為五個功能模塊並定義各自的接口來簡化多代理環境。對於使用 AgentVerse 提供的基礎模塊無法直接構建的複雜環境，你可以自定義這五個功能模塊中的一個或多個接口，根據你的需求高效地創建你自己的多 Agent 環境。</span></span></p></li><li><p><span><span><strong>工具（插件）利用</strong>：AgentVerse 通過工具支持多代理環境。目前，AgentVerse 支持<a href="https://github.com/OpenBMB/BMTools">BMTools</a>中提供的工具。</span></span></p></li></ul><p><img height="287" src="https://static.oschina.net/uploads/space/2023/0915/161814_aa6e_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/agentverse</guid>
            <link>https://www.oschina.net/p/agentverse</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | Rocky Linux 系統安全加固工具 narsil]]>
            </title>
            <description>
                <![CDATA[<p>English | <a href="https://gitee.com/seatonjiang/narsil/blob/main/README.zh-CN.md">簡體中文</a></p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%23gh-light-mode-only"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/narsil-light.png#gh-light-mode-only" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%23gh-dark-mode-only"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/narsil-dark.png#gh-dark-mode-only" referrerpolicy="no-referrer"></a></p><p align="center"><img src="https://img.shields.io/static/v1?style=flat-square&amp;message=Rocky%20Linux&amp;color=15B076&amp;logo=rockylinux&amp;logoColor=FFFFFF&amp;label=" referrerpolicy="no-referrer"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fissues"><img src="https://img.shields.io/github/issues/seatonjiang/narsil?style=flat-square&amp;color=blue" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fpulls"><img src="https://img.shields.io/github/issues-pr/seatonjiang/narsil?style=flat-square&amp;color=brightgreen" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fblob%2Fmain%2FLICENSE"><img src="https://img.shields.io/github/license/seatonjiang/narsil?&amp;style=flat-square" referrerpolicy="no-referrer"></a></p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fissues">Report Bug</a>
    ·
    <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fissues">Request Feature</a></p><p align="center">System security hardening tool for Rocky Linux</p><h2><a id="user-content--screenshot" class="anchor" href="https://gitee.com/seatonjiang/narsil#-screenshot"></a>💻 Screenshot</h2><h3><a id="user-content-script-execution" class="anchor" href="https://gitee.com/seatonjiang/narsil#script-execution"></a>Script Execution</h3><p align="center"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/script-execution.png" referrerpolicy="no-referrer"></p><h3><a id="user-content-login-information" class="anchor" href="https://gitee.com/seatonjiang/narsil#login-information"></a>Login Information</h3><p align="center"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/login-information.png" referrerpolicy="no-referrer"></p><h3><a id="user-content-mount-disk" class="anchor" href="https://gitee.com/seatonjiang/narsil#mount-disk"></a>Mount disk</h3><p align="center"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/mount-disk.png" referrerpolicy="no-referrer"></p><h2><a id="user-content--features" class="anchor" href="https://gitee.com/seatonjiang/narsil#-features"></a>✨ Features</h2><ul><li>Password can be used for a maximum of 30 days.</li><li>After 30 days of password expiration, the account will be disabled.</li><li>The interval between two password changes is 1 day.</li><li>Warning 7 days before password expiration.</li><li>Set the system default encryption algorithm to SHA512.</li><li>Set a session timeout policy of 180 seconds.</li><li>Each created user will be given their own group.</li><li>The newly created user home directory permissions are changed to 0750.</li><li>Modify the permissions of the home directory of the stock user to 0750.</li><li>Hardened OpenSSH config (Some configs need to be done manually).</li><li>Disable login for users without home directory.</li><li>Disable login by default for new users.</li><li>Disable apport and popular-contest statistics for uploading user information.</li><li>Disable synchronous deletion of user groups when deleting users.</li></ul><p>There are many more settings that are not listed, and you can refer to the files in the <code>scripts</code> directory for more information.</p><h2><a id="user-content--quick-start" class="anchor" href="https://gitee.com/seatonjiang/narsil#-quick-start"></a>🚀 Quick start</h2><h3><a id="user-content-step-1-clone-repo" class="anchor" href="https://gitee.com/seatonjiang/narsil#step-1-clone-repo"></a>Step 1: Clone Repo</h3><p>Make sure the server has git first, otherwise you need to install it using <code>sudo dnf install -y git</code>.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://github.com/seatonjiang/narsil.git</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-step-2-edit-config-file" class="anchor" href="https://gitee.com/seatonjiang/narsil#step-2-edit-config-file"></a>Step 2: Edit Config File</h3><p>Go to project directory.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">cd </span>narsil</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Be sure to authenticate the contents of the config file.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">vi narsil.conf</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-step-3-running-script" class="anchor" href="https://gitee.com/seatonjiang/narsil#step-3-running-script"></a>Step 3: Running Script</h3><p>If you are root, you can run it directly, if you are a normal user please use <code>sudo</code> and you must run the script with <code>bash</code>.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--config-options" class="anchor" href="https://gitee.com/seatonjiang/narsil#-config-options"></a>📝 Config Options</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c"># Verify Operation</span></span><span id="LC2" class="line"><span class="py">VERIFY</span><span class="p">=</span><span class="s">'Y'</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c"># Cloud Server Metadata Overlay (DNS Server/NTP Server/Hostname)</span></span><span id="LC5" class="line"><span class="py">METADATA</span><span class="p">=</span><span class="s">'Y'</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="c"># Production Environment Reminder</span></span><span id="LC8" class="line"><span class="py">PROD_TIPS</span><span class="p">=</span><span class="s">'Y'</span></span><span id="LC9" class="line"></span><span id="LC10" class="line"><span class="c"># SSH Port Config</span></span><span id="LC11" class="line"><span class="py">SSH_PORT</span><span class="p">=</span><span class="s">'22'</span></span><span id="LC12" class="line"></span><span id="LC13" class="line"><span class="c"># Time Zone Config</span></span><span id="LC14" class="line"><span class="py">TIME_ZONE</span><span class="p">=</span><span class="s">'Asia/Shanghai'</span></span><span id="LC15" class="line"></span><span id="LC16" class="line"><span class="c"># Hostname Config (not valid if METADATA is Y)</span></span><span id="LC17" class="line"><span class="py">HOSTNAME</span><span class="p">=</span><span class="s">'rockylinux'</span></span><span id="LC18" class="line"></span><span id="LC19" class="line"><span class="c"># DNS Server Config (not valid if METADATA is Y)</span></span><span id="LC20" class="line"><span class="py">DNS_SERVER</span><span class="p">=</span><span class="s">'119.29.29.29 223.5.5.5'</span></span><span id="LC21" class="line"></span><span id="LC22" class="line"><span class="c"># NTP Server Config (not valid if METADATA is Y)</span></span><span id="LC23" class="line"><span class="py">NTP_SERVER</span><span class="p">=</span><span class="s">'ntp.tencent.com'</span></span><span id="LC24" class="line"></span><span id="LC25" class="line"><span class="c"># Docker Config</span></span><span id="LC26" class="line"><span class="py">DOCKER_CE_REPO</span><span class="p">=</span><span class="s">'http://mirrors.tencent.com/docker-ce/linux/centos/docker-ce.repo'</span></span><span id="LC27" class="line"><span class="py">DOCKER_CE_MIRROR</span><span class="p">=</span><span class="s">'mirrors.tencent.com'</span></span><span id="LC28" class="line"><span class="py">DOCKER_HUB_MIRRORS</span><span class="p">=</span><span class="s">'https://hub-mirror.c.163.com'</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--modular" class="anchor" href="https://gitee.com/seatonjiang/narsil#-modular"></a>🔨 Modular</h2><p>Narsil contains a number of standalone functions that are not in the auto-executed script and need to be used separately using parameters, which can be viewed using the <code>bash narsil.sh --help</code> for all standalone functions.</p><h3><a id="user-content-clear-log-files" class="anchor" href="https://gitee.com/seatonjiang/narsil#clear-log-files"></a>Clear Log Files</h3><p>Clear all syslog files.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-c</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-install-docker" class="anchor" href="https://gitee.com/seatonjiang/narsil#install-docker"></a>Install Docker</h3><p>Install docker service and set registry mirrors.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-d</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-mount-disk-1" class="anchor" href="https://gitee.com/seatonjiang/narsil#mount-disk-1"></a>Mount Disk</h3><p>Interactively mount the data disk. Data is priceless, remember to be careful during the operation!</p><blockquote><p>If the selected hard disk is already mounted, you will be prompted to unmount and format the operation.</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-f</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-change-system-hostname" class="anchor" href="https://gitee.com/seatonjiang/narsil#change-system-hostname"></a>Change system hostname</h3><p>If the parameters of the configuration file have not changed, prioritize getting the metadata.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-h</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-change-ssh-port" class="anchor" href="https://gitee.com/seatonjiang/narsil#change-ssh-port"></a>Change SSH Port</h3><p>Interactively modify the SSH port.</p><blockquote><p>The port range is recommended to be between 10000 and 65535.</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-p</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-uninstall-monitoring-component" class="anchor" href="https://gitee.com/seatonjiang/narsil#uninstall-monitoring-component"></a>Uninstall Monitoring Component</h3><p>Remove the various monitoring components installed into the server by the cloud vendor.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-r</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-add-swap-space" class="anchor" href="https://gitee.com/seatonjiang/narsil#add-swap-space"></a>Add swap space</h3><p>If physical memory is too small, it is recommended to add the swap space.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-s</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--structure" class="anchor" href="https://gitee.com/seatonjiang/narsil#-structure"></a>📂 Structure</h2><p>A quick look at the folder structure of this project.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">narsil</span><span id="LC2" class="line">├── narsil.sh</span><span id="LC3" class="line">├── narsil.conf</span><span id="LC4" class="line">├── config</span><span id="LC5" class="line">│   └── <span class="o">(</span>some config files<span class="o">)</span></span><span id="LC6" class="line">└── scripts</span><span id="LC7" class="line">    └── <span class="o">(</span>some script files<span class="o">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--contributing" class="anchor" href="https://gitee.com/seatonjiang/narsil#-contributing"></a>🤝 Contributing</h2><p>We welcome all contributions. You can submit any ideas as Pull Requests or as Issues, have a good time! :)</p><h2><a id="user-content--license" class="anchor" href="https://gitee.com/seatonjiang/narsil#-license"></a>📃 License</h2><p>The project is released under the GNU General Public License v3.0, see the <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fblob%2Fmain%2FLICENSE">LICENCE</a> file for details.</p>]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/seatonjiang/narsil</guid>
            <link>https://gitee.com/seatonjiang/narsil</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 使用 FHE 實現加密大語言模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 編輯器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">近來，大語言模型 (LLM) 已被證明是提高編程、內容生成、文本分析、網絡搜索及遠程學習等諸多領域生產力的可靠工具。</p><span id="OSC_h2_1"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">大語言模型對用户隱私的影響</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">儘管 LLM 很有吸引力，但如何保護好 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">輸入給這些模型的用户查詢中的隱私</code> 這一問題仍然存在。一方面，我們想充分利用 LLM 的力量，但另一方面，存在向 LLM 服務提供商泄露敏感信息的風險。在某些領域，例如醫療保健、金融或法律，這種隱私風險甚至有一票否決權。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">一種備選解決方案是本地化部署，LLM 所有者將其模型部署在客户的計算機上。然而，這不是最佳解決方案，因為構建 LLM 可能需要花費數百萬美元 (GPT3 為 460 萬美元)，而本地部署有泄露模型知識產權 (intellectual property, IP) 的風險。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Zama 相信有兩全其美之法: 我們的目標是同時保護用户的隱私和模型的 IP。通過本文，你將瞭解如何利用 Hugging Face transformers 庫並讓這些模型的某些部分在加密數據上運行。完整代碼見，此處。</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">全同態加密 (Fully Homomorphic Encryption，FHE) 可以解決 LLM 隱私挑戰</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">針對 LLM 部署的隱私挑戰，Zama 的解決方案是使用全同態加密 (FHE)，在加密數據上執行函數。這種做法可以實現兩難自解，既可以保護模型所有者知識產權，同時又能維護用户的數據隱私。我們的演示表明，在 FHE 中實現的 LLM 模型保持了原始模型的預測質量。為此，我們需要調整 Hugging Face transformers 庫，中的 GPT2 實現，使用 Concrete-Python 對推理部分進行改造，這樣就可以將 Python 函數轉換為其 FHE 等效函數。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-ratio="1.2027809965237544" data-type="png" data-w="863" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/338741ab-aa57-4681-b21f-eeeabcd24fce.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     圖 1. GPT2 架構; 圖源: https://en.wikipedia.org/wiki/GPT-2 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">圖 1 展示了由多個 transformer block 堆疊而成的 GPT2 架構: 其中最主要的是多頭注意力 (multi-head attention，MHA) 層。每個 MHA 層使用模型權重來對輸入進行投影，然後各自計算注意力，並將注意力的輸出重新投影到新的張量中。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 TFHE 中，模型權重和激活均用整數表示。非線性函數必須通過可編程自舉 (Programmable Bootstrapping，PBS) 操作來實現。PBS 對加密數據實施查表 (table lookup，TLU) 操作，同時刷新密文以支持，任意計算。不好的一面是，此時 PBS 的計算時間在線性運算中佔主導地位。利用這兩種類型的運算，你可以在 FHE 中表達任何子模型的計算，甚至完整的 LLM 計算。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">使用 FHE 實現 LLM 的一層</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">接下來，你將瞭解如何加密多頭注意力 (MHA) 中的一個注意力頭。你可以在，此處，找到完整的 MHA 實現代碼。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-ratio="1.0334538878842676" data-type="svg" data-w="1106" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/72fc90eb-872e-4a86-9f18-c949824b4c7d.svg" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     圖 2. 在 FHE 中運行 LLM 模型的某些部分 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">圖 2 概述了一個簡化的底層實現。在這個方案中，模型權重會被分成兩個部分，分別存儲在客户端和服務端。首先，客户端在本地開始推理，直至遇到已第一個不在本地的層。用户將中間結果加密併發送給服務端。服務端對其執行相應的注意力機制計算，然後將結果返回給客户端，客户端對結果進行解密並繼續在本地推理。</p><span id="OSC_h3_4"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">量化</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先，為了對加密值進行模型推理，模型的權重和激活必須被量化並轉換為整數。理想情況是使用，訓練後量化，這樣就不需要重新訓練模型了。這裏，我們使用整數和 PBS 來實現 FHE 兼容的注意力機制，並檢查其對 LLM 準確率的影響。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">要評估量化的影響，我們運行完整的 GPT2 模型，並讓其中的一個 LLM 頭進行密態計算。然後我們基於此評估權重和激活的量化比特數對準確率的影響。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-ratio="0.8024691358024691" data-type="png" data-w="567" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/e0260d01-fa3c-414c-a6d7-a0c0025b9e4b.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     單注意力頭量化的平均 top-k 準確率 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">上圖表明 4 比特量化保持了原始精度的 96%。該實驗基於含有約 80 個句子的數據集，並通過將原始模型的 logits 預測與帶有量化注意力頭的模型的 logits 預測進行比較來計算最終指標。</p><span id="OSC_h3_5"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">在 Hugging Face GPT2 模型中使用 FHE</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我們需要在 Hugging Face 的 transformers 庫的基礎上重寫加密模塊的前向傳播，以使其包含量化算子。首先通過加載 GPT2LMHeadModel 構建一個 SingleHeadQGPT2Model 實例，然後手動使用 QGPT2SingleHeadAttention 替換第一個多頭注意力模塊，代碼如下。你可以在，這裏，找到模型的完整實現。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">self.transformer.h[<span style="color: #008080;line-height: 26px;">0</span>].attn&nbsp;=&nbsp;QGPT2SingleHeadAttention(config,&nbsp;n_bits=n_bits)<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">至此，前向傳播已被重載成用 FHE 算子去執行多頭注意力的第一個頭，包括構建查詢、鍵和值矩陣的投影。以下代碼中的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">QGPT2</code> 模塊的代碼見，此處。</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="line-height: 26px;"><span style="font-weight: bold;line-height: 26px;">class</span>&nbsp;<span style="color: #458;font-weight: bold;line-height: 26px;">SingleHeadAttention</span><span style="line-height: 26px;">(QGPT2)</span>:</span><br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #d14;line-height: 26px;">"""Class&nbsp;representing&nbsp;a&nbsp;single&nbsp;attention&nbsp;head&nbsp;implemented&nbsp;with&nbsp;quantization&nbsp;methods."""</span><br><br><br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="line-height: 26px;"><span style="font-weight: bold;line-height: 26px;">def</span>&nbsp;<span style="color: #900;font-weight: bold;line-height: 26px;">run_numpy</span><span style="line-height: 26px;">(self,&nbsp;q_hidden_states:&nbsp;np.ndarray)</span>:</span><br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Convert&nbsp;the&nbsp;input&nbsp;to&nbsp;a&nbsp;DualArray&nbsp;instance</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_x&nbsp;=&nbsp;DualArray(<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;float_array=self.x_calib,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int_array=q_hidden_states,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;quantizer=self.quantizer<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Extract&nbsp;the&nbsp;attention&nbsp;base&nbsp;module&nbsp;name</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mha_weights_name&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">f"transformer.h.<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>.attn."</span><br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Extract&nbsp;the&nbsp;query,&nbsp;key&nbsp;and&nbsp;value&nbsp;weight&nbsp;and&nbsp;bias&nbsp;values&nbsp;using&nbsp;the&nbsp;proper&nbsp;indices</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;head_0_indices&nbsp;=&nbsp;[<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list(range(i&nbsp;*&nbsp;self.n_embd,&nbsp;i&nbsp;*&nbsp;self.n_embd&nbsp;+&nbsp;self.head_dim))<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;i&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;range(<span style="color: #008080;line-height: 26px;">3</span>)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv_weights&nbsp;=&nbsp;...<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv_bias&nbsp;=&nbsp;...<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Apply&nbsp;the&nbsp;first&nbsp;projection&nbsp;in&nbsp;order&nbsp;to&nbsp;extract&nbsp;Q,&nbsp;K&nbsp;and&nbsp;V&nbsp;as&nbsp;a&nbsp;single&nbsp;array</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv&nbsp;=&nbsp;q_x.linear(<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight=q_qkv_weights,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias=q_qkv_bias,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key=<span style="color: #d14;line-height: 26px;">f"attention_qkv_proj_layer_<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>"</span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Extract&nbsp;the&nbsp;queries,&nbsp;keys&nbsp;and&nbsp;vales</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv&nbsp;=&nbsp;q_qkv.expand_dims(axis=<span style="color: #008080;line-height: 26px;">1</span>,&nbsp;key=<span style="color: #d14;line-height: 26px;">f"unsqueeze_<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>"</span>)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_q,&nbsp;q_k,&nbsp;q_v&nbsp;=&nbsp;q_qkv.enc_split(<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #008080;line-height: 26px;">3</span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis=<span style="color: #008080;line-height: 26px;">-1</span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key=<span style="color: #d14;line-height: 26px;">f"qkv_split_layer_<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>"</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Compute&nbsp;attention&nbsp;mechanism</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_y&nbsp;=&nbsp;self.attention(q_q,&nbsp;q_k,&nbsp;q_v)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-weight: bold;line-height: 26px;">return</span>&nbsp;self.finalize(q_y)<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">模型中的其他計算仍以浮點形式進行，未加密，並由客户端在本地執行。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">將預訓練的權重加載到修改後的 GPT2 模型中，然後調用 <em style="color: black;">generate</em> 方法:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">qgpt2_model&nbsp;=&nbsp;SingleHeadQGPT2Model.from_pretrained(<br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #d14;line-height: 26px;">"gpt2_model"</span>,&nbsp;n_bits=<span style="color: #008080;line-height: 26px;">4</span>,&nbsp;use_cache=<span style="color: #008080;line-height: 26px;">False</span><br>)<br><br>output_ids&nbsp;=&nbsp;qgpt2_model.generate(input_ids)<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">舉個例子，你可以要求量化模型補全短語 「Cryptography is a」 。在 FHE 中運行模型時，如果量化精度足夠，生成的輸出為:</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">「Cryptography is a very important part of the security of your computer」</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">當量化精度太低時，您會得到:</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">「Cryptography is a great way to learn about the world around you」</p><span id="OSC_h3_6"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">編譯為 FHE</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">現在，你可以使用以下 Concrete-ML 代碼編譯註意力頭:</p><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">circuit_head&nbsp;=&nbsp;qgpt2_model.compile(input_ids)<br></code></pre><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">運行此代碼，你將看到以下打印輸出: 「Circuit compiled with 8 bit-width」。該配置與 FHE 兼容，顯示了在 FHE 中執行的操作所需的最大位寬。</p><span id="OSC_h3_7"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">複雜度</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 transformer 模型中，計算量最大的操作是注意力機制，它將查詢、鍵和值相乘。在 FHE 中，加密域中乘法的特殊性加劇了成本。此外，隨着序列長度的增加，這些乘法的數量還會呈二次方增長。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">而就加密注意力頭而言，長度為 6 的序列需要 11622 次 PBS 操作。我們目前的實驗還很初步，尚未對性能進行優化。雖然可以在幾秒鐘內運行，但不可否認它需要相當多的計算能力。幸運的是，我們預期，幾年後，硬件會將延遲提高 1000 倍到 10000 倍，使原來在 CPU 上需要幾分鐘的操作縮短到 ASIC 上的低於 100 毫秒。有關這些估算的更多信息，請參閲，此博文。</p><span id="OSC_h2_8"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">總結</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">大語言模型有望使能大量應用場景，但其實現引發了用户隱私的重大關切。在本文中，我們朝着密態 LLM 邁出了第一步，我們的最終願景是讓整個模型完全在雲上運行，同時用户的隱私還能得到充分尊重。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">當前的做法包括將 GPT2 等模型中的特定部分轉換至 FHE 域。我們的實現利用了 transformers 庫，用户還能評估模型的一部分在加密數據上運行時對準確率的影響。除了保護用户隱私之外，這種方法還允許模型所有者對其模型的主要部分保密。你可在，此處，找到完整代碼。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Zama 庫 Concrete 和 Concrete-ML (別忘了給我們的 github 代碼庫點個星星 ⭐️💛) 允許直接構建 ML 模型並將其轉換至等價的 FHE 域，從而使之能夠對加密數據進行計算和預測。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">希望你喜歡這篇文章。請隨時分享你的想法/反饋！</p><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/encrypted-llm</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Roman Bredehoft，Jordan Frery</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">譯者: Matrix Yao (姚偉峯)，英特爾深度學習工程師，工作方向為 transformer-family 模型在各模態數據上的應用及大規模模型的訓練推理。</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">審校/排版: zhongdongy (阿東)</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10112832</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10112832</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大模型在無損壓縮方面超越 PNG 和 FLAC]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">Google DeepMind 和 Meta 的研究人員發表論文《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2309.10668" target="_blank">Language Modeling Is Compression</a>》，他們發現 DeepMind 的大語言模型 Chinchilla 70B 在圖像和音頻的無損壓縮上超過了 PNG 和 FLAC。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:start">論文提到，Chinchilla 70B 能將 ImageNet 圖像數據庫中的圖像無損壓縮到原始大小 43.4%，超過了 PNG 算法的 58.5%。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:start">Chinchilla 能將 LibriSpeech 音頻數據集中的樣本無損壓縮到原始大小 16.4%，超過 FLAC 算法的 30.3%。</p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ca6b2c476913b6a89c88077731175c6b63b.png" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farstechnica.com%2Finformation-technology%2F2023%2F09%2Fai-language-models-can-exceed-png-and-flac-in-lossless-compression-says-study%2F" target="_blank">據介紹</a>，Chinchilla 70B 主要是訓練用於處理文本，但它在壓縮其它類型的數據集上的效果也表現優異，甚至優於專門的算法。</p><p style="color:#000000; text-align:start">下面的例子比較了 gzip 和 Chinchilla 在示例文本上的生成效果。可以看到，gzip 的輸出沒有可讀性。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/1005/191209_GfKh_2720166.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 05 Oct 2023 11:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260407/llm-can-exceed-png-and-flac-in-lossless-compression</guid>
            <link>https://www.oschina.net/news/260407/llm-can-exceed-png-and-flac-in-lossless-compression</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RMS 談 AI、Red Hat 和道德軟件許可]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">在瑞士 Biel 舉行的慶祝 GNU 誕生 40 週年的活動上，GNU 和 FSF 創始人 Richard Stallman (RMS) 發表了 25 分鐘的演講，除了披露身患癌症外，他還談論了 Red Hat、AI 和道德軟件許可。</p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-d7dc3b154962c7667a46bffdb69807efc99.png" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><em>RMS 在瑞士 Biel 參加慶祝 GNU 40 歲生日的活動</em></p><p style="color:#000000; text-align:start">RMS 表示目前正在接受濾泡性淋巴瘤的治療，他稱之為「生長緩慢和可控的」。</p><p style="color:#000000; text-align:start"><strong>Red Hat&nbsp;<strong><strong>和&nbsp;</strong></strong>GPL</strong></p><p style="color:#000000; text-align:start">Red Hat 的支持合同禁止客户重新分發該公司的開源軟件，RMS 認為此舉可能沒有違反 GPL 許可，但其做法是「反社會的」。</p><p style="color:#000000; text-align:start">他認為 Red Hat 應該停止這一做法，或者社區能通過施加影響力讓 Red Hat 做出改變。</p><p style="color:#000000; text-align:start"><strong>生成式&nbsp;<strong><strong>AI&nbsp;</strong></strong>不具備理解能力</strong></p><p style="color:#000000; text-align:start">對於 AI 或生成式聊天機器人 ChatGPT，RMS 認為危險主要來自於 AI 營銷人員所編織的敍事。</p><p style="color:#000000; text-align:start">他認為今天的 AI 尚未真正具有理解能力，但人們正使用 AI 這一術語來誇大其詞，他説 ChatGPT 生成的內容都是廢話，不過是流暢的廢話。</p><p style="color:#000000; text-align:start">因此他認為，相信 ChatGPT 這類產品生成的內容的人都很愚蠢。</p><p style="color:#000000; text-align:start">RMS 説道：「在我看來，‘intelligence’ 意味着需要具備瞭解或理解某個領域的能力。如果某些東西不能真正理解事情，我們不應該説它是智能的，甚至是一點智能都沒有，但人們正在用人工智能一詞來描述廢話生成器。」</p><p style="color:#000000; text-align:start">所以他沒有把那些產品稱作「人工智能」或任何帶有 ‘intelligence’ 一詞的東西，因為這會鼓勵大眾認為它們（生成式人工智能程序）所説的不是胡説八道。它鼓勵大眾相信它們，這給了他們造成巨大傷害的機會。</p><p style="color:#000000; text-align:start">然而，這並不意味着 RMS 認為真正的人工智能並不存在。</p><p style="color:#000000; text-align:start">他説：「有些程序可以查看一些放大細胞的照片並告訴你診斷結果，無論是否患有癌症，比任何人類醫生都更有可能正確。另外，有一些人工智能系統可以非常有效地找出什麼會吸引人們的注意力。這些被反社交媒體平台使用，可悲的是，它們效果很好。他們非常擅長這些工作，但他們所做的是讓用户上癮。」</p><p style="color:#000000; text-align:start"><strong>道德軟件許可證</strong></p><p style="color:#000000; text-align:start">RMS 似乎不是所謂的「道德」軟件許可證的支持者，試圖監管誰可以使用軟件。</p><p style="color:#000000; text-align:start">這不足為奇，因為他倡導的自由軟件哲學的四項基本自由中的第一項是用户具有出於任何目的運行軟件的自由。</p><p style="color:#000000; text-align:start">演講最後，RMS 拋出了一個問題——「我們如何讓年輕人對自由軟件感興趣？」</p><p style="color:#000000; text-align:start">他稱這個問題是「我們在社區中面臨的難題之一」。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 05 Oct 2023 04:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260374/rms-talks-red-hat-ai-and-ethical-software-licenses</guid>
            <link>https://www.oschina.net/news/260374/rms-talks-red-hat-ai-and-ethical-software-licenses</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龍芯為 Linux 6.7 支持 LoongArch 架構 KVM 虛擬機]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在已發佈的多個 Linux 內核版本中，龍芯工程師都致力於為 LoongArch 架構實現更多內核功能。到目前為止，LoongArch CPU 的性能雖然無法與 x86_64 或 Arm 硬件相比，但正在慢慢變得更加實用，此外架構支持方面已經越來越成熟。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Fchenhuacai%2Flinux-loongson.git%2Flog%2F%3Fh%3Dloongarch-next" target="_blank">根據龍芯工程師最新提交的代碼</a>，Linux 內核的龍芯 Git 分支已將其所有初始 KVM 支持 (Kernel-based Virtual Machine) 代碼提交到 loongarch-next 排隊，迎接大約一個月後 Linux 6.7 合併窗口，即將迎來對基於內核的虛擬機支持。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-da5409cd652b9af9cb94b9dd19283a665d1.png" referrerpolicy="no-referrer"></p><p>這組補丁為龍芯 CPU 提供了所有基礎的 KVM 支持代碼。這種 KVM 支持依賴於 LoongArch 的虛擬化擴展，是 LoongArch 支持的首個虛擬化方式。</p><p>雖然考慮到目前 LoongArch CPU 性能水平，KVM 虛擬化支持在目前可能不太實用，但隨着性能的提高，以及龍芯未來在雲 / 虛擬化服務器領域的擴展，KVM 虛擬化支持將變得十分重要，因此提早做準備是有必要的。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 04 Oct 2023 04:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260296/loongarch-kvm-for-linux-6-7</guid>
            <link>https://www.oschina.net/news/260296/loongarch-kvm-for-linux-6-7</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GCC 安全策略文檔已合併到倉庫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">最近幾周在 GCC 郵件列表進行討論後，開發團隊為 GCC 代碼庫添加了 GCC 安全策略，以概述編譯器項目的安全流程。</p><p style="color:#000000; text-align:start"><img alt="" src="https://static.oschina.net/uploads/space/2023/1006/113615_PVqj_2720166.jpeg" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">該文檔概述了 GCC 安全漏洞處理建議、GCC 語言運行庫的安全注意事項、在 GCC 中實現的安全功能，以及私下報告安全漏洞的最佳方式。</p><p style="color:#000000; text-align:start">GCC 安全政策文檔於週三<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgcc.gnu.org%2Fgit%2F%3Fp%3Dgcc.git%3Ba%3Dcommit%3Bh%3D4cac1d2eec5549927fe0caee179f80007e8d729b" target="_blank">提交</a>到代碼庫。如果希望瞭解更多關於 GCC 安全策略的內容，可以在&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgcc.gnu.org%2Fgit%2F%3Fp%3Dgcc.git%3Ba%3Dblob%3Bf%3DSECURITY.txt" target="_blank">SECURITY.txt</a>&nbsp;中閲讀。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 04 Oct 2023 03:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260447/gcc-security-policy</guid>
            <link>https://www.oschina.net/news/260447/gcc-security-policy</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[呼喚國內 Java 開發者共建 Solon]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>Solon 是什麼？</h3><p style="color:#24292e; text-align:start"><strong>Java 生態級應用開發框架</strong>。從零開始構建，有自己的標準規範與開放生態（歷時五年，具備全球第二級別的生態規模）。更多內容詳見：<a href="https://www.oschina.net/news/258633">《中國這麼多 Java 開發者，應該誕生出生態級應用開發框架》</a></p><h3>有什麼特點？</h3><ul><li>啓動快 5 ～ 10 倍。<span>&nbsp;</span><strong>（更快）</strong></li><li>qps 高 2～ 3 倍。<span>&nbsp;</span><strong>（更高）</strong></li><li>運行時內存節省 1/3 ~ 1/2。<span>&nbsp;</span><strong>（更少）</strong></li><li>打包可以縮小到 1/2 ~ 1/10；比如，300Mb 的變成了 23Mb。<span>&nbsp;</span><strong>（更小）</strong></li><li>同時支持 jdk8, jdk11, jdk17, jdk21,<span>&nbsp;</span><strong>graalvm native image</strong></li></ul><h3>呼喚？</h3><p style="color:#24292e; text-align:start">如果您開源感興趣且願意學習和貢獻，歡迎您共建 Solon 生態。</p><h3>項目倉庫地址？</h3><ul><li>gitee：<a href="https://gitee.com/noear/solon">https://gitee.com/noear/solon</a></li><li>github：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnoear%2Fsolon" target="_blank">https://github.com/noear/solon</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 03 Oct 2023 13:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260414</guid>
            <link>https://www.oschina.net/news/260414</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[特斯拉：FSD 不使用高清地圖，只依賴神經網絡和海量數據]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>特斯拉最近解釋了其全自動駕駛 (FSD) 軟件是如何運作的，以及其作出決策背後的依據。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1003/180701_AefK_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>特斯拉的官方推特賬號<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTesla%2Fstatus%2F1707858812424606039" target="_blank">轉發</a>了特斯拉硅谷車主俱樂部發布的一段短視頻，視頻內容展示了 FSD 如何在沒有任何導航的情況下在湖邊的一條土路上行駛。該俱樂部<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FteslaownersSV%2Fstatus%2F1706123024037269568" target="_blank">寫道</a>：「世界還沒有意識到正在發生什麼。」</p><p><img height="823" src="https://static.oschina.net/uploads/space/2023/1003/180844_X59r_2720166.png" width="725" referrerpolicy="no-referrer"></p><p>特斯拉在轉發的推文中説道：</p><blockquote><p>特斯拉 FSD 不依賴高清地圖，這意味着 Autopilot 可以在汽車以前從未見過的地方啓用。 雖然它會考慮導航以到達正確的目的地，但如果沒有路線或地圖可用，它會選擇最可能的路徑。<strong>這條路徑是由大多數人在任何給定場景下所做的事情決定的，並由我們全球數百萬輛汽車的學習提供動力。</strong>車道的概念也只是鬆散地嵌入到我們的系統中，使汽車能夠自信地在沒有標記的道路上行駛。</p></blockquote><p>特斯拉利用其車隊的視頻來訓練 FSD 的能力。馬斯克此前曾表示：「道路是為生物神經網絡和眼睛設計的，因此數字神經網絡和攝像頭將發揮最佳作用。」</p><p>今年 7 月初，在 2023 年世界人工智能大會上，馬斯克還表示，特斯拉「非常接近」實現全自動駕駛能力。他説：「過去我對這個預測一直是錯誤的，但我覺得我們比以往任何時候都更接近這個預測。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-adf92c911bcb0d3d528ae1aac0dca386027.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 03 Oct 2023 10:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260260</guid>
            <link>https://www.oschina.net/news/260260</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Stability AI 發佈最新語言模型：Stable LM 3B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Stability AI 昨日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fblog%2Fstable-lm-3b-sustainable-high-performance-language-models-smart-devices" target="_blank">發佈</a>最新語言模型：Stable LM 3B，可在筆記本和手機等智能設備上運行。</p><p><img src="https://static.oschina.net/uploads/space/2023/1003/123230_hJQt_2720166.png" referrerpolicy="no-referrer"></p><p>公告寫道，Stable LM 3B 包含 30 億個參數，相比於行業通常使用的 70 億參數，它更小、更高效。主要功能如下：&nbsp;</p><ul><li>文本生成：可以用於生成文本</li><li>自迴歸：基於變換器解碼器架構</li><li>多樣性的訓練數據：使用了多個開源大規模數據集</li></ul><p>Stable LM 3B 主要特點：</p><ol><li>高性能：儘管只有 30 億個參數，但性能與更大的模型相當，甚至有時超過它們。</li><li>低功耗：設計為在便攜式設備上高效運行，因此電力需求較低。</li><li>多平台兼容：可以在邊緣設備、家用電腦以及其他便攜式數字設備上運行。</li><li>可微調：模型可以根據特定需求進行微調，如編程輔助或其他專用應用。</li><li>開源：該模型已在 Hugging Face 平台上開源 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fstabilityai%2Fstablelm-3b-4e1t" target="_blank">https://huggingface.co/stabilityai/stablelm-3b-4e1t</a>)，方便開發者使用和改進。</li><li>訓練細節：該模型在 Stability AI 的集羣上進行了訓練，使用了 256 個 NVIDIA A100 40GB GPU（AWS P4d 實例）。</li></ol><p>詳情：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fblog%2Fstable-lm-3b-sustainable-high-performance-language-models-smart-devices" target="_blank">https://stability.ai/blog/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 03 Oct 2023 04:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260235/stable-lm-3b</guid>
            <link>https://www.oschina.net/news/260235/stable-lm-3b</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[適用於 Box 的 ONLYOFFICE 文檔集成應用程序現已可用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">適用於 Box 的 ONLYOFFICE 集成應用程序可直接在 Box 前端中處理文件。 請繼續閲讀瞭解詳情。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="New integration available: ONLYOFFICE &amp; Box" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/09/27103552/ONLYOFFICE-Box-integration.jpg" referrerpolicy="no-referrer"></p><h2>ONLYOFFICE 文檔是什麼</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite.aspx" target="_blank">ONLYOFFICE 文檔</a>是一個功能強大的在線編輯器，用於文本文檔、電子表格、演示文稿、表單和 PDF 閲讀器，可以與任何平台集成。跨平台並與微軟格式高度兼容，ONLYOFFICE 為初創公司提供了優秀的辦公套件。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">在 ONLYOFFICE 文檔中，您能夠以實時和段落鎖定模式安全地協作處理文檔。共享權限包括可編輯、可查看、可審閲、可填寫表單、可留評論等。其他協作功能包括追蹤更改、版本歷史記錄、文檔比較和恢復。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">由於自定義選項和靈活性，ONLYOFFICE 文檔幾乎可以適應任何屏幕。默認功能可通過第三方插件進行擴展，例如 <a href="https://www.oschina.net/news/259993/onlyoffice-ai">AI 助手</a>、縮放、谷歌翻譯、文本識別、語音輸入等。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 也可以與其他平台集成，允許您在&nbsp;<span style="background-color:#ffffff; color:#333333">Odoo、Pipedrive、Confluence、Moodle、Nextcloud、Seafile 等平台上使用文檔協作編輯功能。</span></p><h2><strong>ONLYOFFICE 應用程序及其功能</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 新的集成應用程序可以讓用户在流行的雲內容管理平台 Box 中輕鬆打開和編輯現有文檔、電子表格和演示文稿。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">為此，請單擊 3 點圖標啓動文件上下文菜單，找到<strong>集成</strong>，然後選擇<strong>用 ONLYOFFICE 打</strong><strong>開</strong>，相應的 ONLYOFFICE 編輯器將以全屏模式在新選項卡中打開。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">如果您與其他 Box 用户有共享文件，還可以協作處理文檔。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="New integration available: ONLYOFFICE &amp; Box" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/09/27103850/Box-onlyoffice-edit-files.png" referrerpolicy="no-referrer"></p><h2><strong>如何安裝應用程序</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 應用程序可在<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapp.box.com%2Fapp-center%2Fonlyoffice_personal%2Fapp" target="_blank">Box App Center</a>（應用程序中心）完全免費使用。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faccount.box.com%2Flogin" target="_blank">登錄您的 Box 帳户</a>並按「<strong>安裝</strong>」按鈕即可。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>請注意</strong>：該應用程序使用 ONLYOFFICE 文檔雲的預配置租户，不需要任何額外配置。</p><h2><strong>支持的文件格式</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">適用於 Box 的 ONLYOFFICE 應用程序支持處理多種文件格式：</p><ul><li>OOXML 文件，包括 DOCX、XLSX、PPTX，可直接打開進行編輯。</li><li>DOCXF 和 OFORM，用於處理數字表單。</li><li>ODT、ODP、ODS、TXT、CSV、RTF、EPUB、FB2 只能打開查看，也可以直接進行編輯，但由於格式限制可能會導致數據丟失，或者轉換為 OOXML 進行進一步編輯。</li><li>DOC、XLS、PPT、DOT、ET、FODP、HTM、POT 等可以打開僅供查看，也可以轉換為 OOXML 進行編輯。</li><li>PDF、DJVU、OXPS 只能打開查看。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 02 Oct 2023 11:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260197</guid>
            <link>https://www.oschina.net/news/260197</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「開源 Windows」ReactOS 改進 GUI 設置/安裝]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，ReactOS Deutschlande.V.&nbsp;宣佈聘請了該項目的長期貢獻者，在接下來的五個月內致力於開發 ReactOS GUI 設置模式 (ReactOS GUI setup mode)，該特性將替代之前基於文本的設置方案，以降低使用門檻。</p><p>目前 ReactOS 正在向 Hermès Bélusca-Maïto 支付費用，讓他在接下來的五個月內開發 ReactOS GUI 設置模式，以完成安裝 ReactOS 過程中第一階段的目標。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bf70d29b68f97316bc35adb689b7fa33baf.png" referrerpolicy="no-referrer"></p><p>據介紹，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Freactos.org%2Fwiki%2FInstalling_ReactOS" target="_blank">安裝 ReactOS 會經歷三個階段</a>。前兩個階段需要處理系統的安裝，而第三階段是用户的第一個可用引導界面。</p><ul><li>第一階段 – 文本模式設置，從 ReactOS CD-ROM 啓動。</li><li>第二階段 – 引導至 GUI 安裝程序。用户信息的輸入和文件的註冊。</li><li>第三階段 – 引導至桌面，用户配置。</li></ul><p><strong>目前安裝 ReactOS 第一步的唯一選擇是通過文本模式安裝</strong>，其餘的安裝將在第二階段安裝後處理。自該項目啓動以來，這一直是在虛擬機或裸機上安裝 ReactOS 的標準方法，因此需要一些門檻，也勸退了不少用户。</p><p>ReactOS GUI 設置模式的開發路線圖如下：</p><ul><li>完成有關 CAB 文件提取的 setupapi.dll 的部分 Winesync；</li><li>將 FreeLdr 引導加載程序安裝選擇步驟移至 ROS 磁盤 / 分區選擇步驟之後，並放在實際安裝之前；</li><li>集成註冊表設置回調（目前 GUI 設置中不存在）；</li><li>添加對 GUI 設置的 GPT 支持；</li><li>雜項（進一步清理、一些重構等）。</li></ul><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Freactos.org%2Fproject-news%2Fhermes-belusca-hired-full-time%2F" target="_blank">詳情</a></p><blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">ReactOS 項目的主要目標就是提供一個與 Windows 環境二進制兼容的操作系統。它能讓你的 Windows 應用程序和驅動程序如同在 Windows 上一樣運行。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">此外，由於應用了 Windows 操作系統的外觀特性，已經熟悉 Windows 用户界面的用户在使用 ReactOS 時將駕輕就熟。ReactOS 的終極目標是使你能夠在感覺不到最終用户體驗變化的前提下，使用 ReactOS 來替代 Windows。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://static.oschina.net/uploads/space/2019/0306/073550_CIxD_2720166.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 02 Oct 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260162/reactos-gui-setup-project</guid>
            <link>https://www.oschina.net/news/260162/reactos-gui-setup-project</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蘋果中國 App Store 將不允許未備案應用上架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>蘋果更新了「App 信息」中「<strong>在中國大陸的供應情況</strong>」，要求 App 有備案號才能在中國大陸的 App Store 中上架。這意味着大部分外國應用將無法通過 App Store 在中國區提供下載。</p><p><img src="https://static.oschina.net/uploads/space/2023/1002/112310_WnrJ_2720166.jpg" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1002/112502_k0Xd_2720166.jpg" referrerpolicy="no-referrer"></p><p>蘋果稱：</p><blockquote><p>中國工業和信息化部（MIIT）要求 App 必須具備有效的互聯網信息服務提供者（ICP）備案號。此外，遊戲 App 必須取得網絡遊戲出版物號。圖書和報刊雜誌 App 必須持有中國國家新聞出版署（NPPA）頒發的《網絡出版服務許可證》。包含宗教內容的 App 必須持有中國國家宗教事務局（NRAA）頒發的《互聯網宗教信息服務許可證》。新聞 App 必須持有中國國家互聯網信息辦公室（CAC）頒發的《互聯網新聞信息服務許可證》。如果你已經或計劃在中國大陸的 App Store 中提供上述類型的 App，則必須提供相關信息和證明文件。如果 App 符合上述情況，請在「App 信息」頁面的相應位置填寫 ICP 備案信息。為方便 Apple 驗證你的網絡遊戲出版物號，請上傳遊戲的 ISBN（國際標準書號）核發單或批覆文件，以及最新營業執照的副本。此外，你還可以上傳相應運營單位的授權協議。為方便 Apple 驗證你的出版許可，請上傳《網絡出版服務許可證》或中國國家新聞出版署頒發的其他相關許可、授權方提供的出版許可授權書、營業執照、ICP 許可證或類似的證明文件。為方便 Apple 驗證你的互聯網宗教信息服務許可，請上傳《互聯網宗教信息服務許可證》、授權方提供的許可授權書、營業執照、ICP 許可證或類似的證明文件。為方便 Apple 驗證你的互聯網新聞信息服務許可，請上傳《互聯網新聞信息服務許可證》、授權方提供的許可授權書、營業執照、ICP 許可證或類似的證明文件。</p></blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fcn%2Fhelp%2Fapp-store-connect%2Freference%2Fapp-information%2F" target="_blank">https://developer.apple.com/cn/help/app-store-connect/reference/app-information/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 02 Oct 2023 03:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260160</guid>
            <link>https://www.oschina.net/news/260160</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Snap 商店遭受惡意應用攻擊，臨時新增人工審核]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">Canonical 的 Snap Store&nbsp;團隊發佈<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.snapcraft.io%2Ft%2Ftemporary-suspension-of-automatic-snap-registration-following-security-incident%2F37077" target="_blank">公告稱</a>，他們於近日收到了一些用户所報告的安全隱患事件。即，幾個最近新發布的 Snap 可能存在惡意</span><span style="background-color:#ffffff">，可以</span><span style="background-color:#ffffff">竊取用户的加密資金。</span></span></p><p><span style="color:#000000">目前，Snap Store 已經刪除了所報告的 Snap。新的 Snap 註冊實施了臨時人工審核要求，立即生效。此人工審查旨在阻止惡意行為者註冊合法應用程序的名稱（或至少聽起來合法的名稱），並將其用作向用户推送惡意 Snap 的途徑。</span></p><p><img height="270" src="https://oscimg.oschina.net/oscnet/up-88656dc09868a0f56e324642884ef0b8f38.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">當用户嘗試註冊新的&nbsp;Snap 時，系統將提示「請求保留名稱」。Snap Store 工作人員手動審核成功後，該名稱將被註冊。上傳和發佈現有 Snap 的修訂版則不會受到影響。</span></p><blockquote><p style="text-align:start"><span style="color:#000000">對於這可能給我們的 snap 發佈者和開發者帶來的任何不便，我們深表歉意。然而，我們認為這是目前最謹慎的行動。</span></p><p style="text-align:start"><span style="color:#000000">我們希望徹底調查這一事件，而不會給系統帶來任何干擾，更重要的是，我們希望確保我們的用户在 Snap Store 中獲得安全且值得信賴的體驗。</span></p><p style="text-align:start"><span style="color:#000000">請耐心等待我們進行調查。我們將在未來幾天提供更詳細的更新。</span></p></blockquote><p><span style="color:#000000">如果你最近從 Snap Store 安裝了任何新上架的<span style="background-color:#ffffff">加密賬本應用程序</span>，不妨檢查一下應用程序是否還在列表中。如果沒有，這可能意味着它已因為被懷疑是惡意程序而撤下。&nbsp;</span></p><p><span style="color:#000000">更多詳情可查看&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.snapcraft.io%2Ft%2Ftemporary-suspension-of-automatic-snap-registration-following-security-incident%2F37077" target="_blank">Snapcraft 論壇</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260114/snap-store-security-incident</guid>
            <link>https://www.oschina.net/news/260114/snap-store-security-incident</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美國國家安全局將開設人工智能安全中心]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美國國家安全局 (NSA) 宣佈正在創建人工智能安全中心，以「監督美國國家安全系統內人工智能功能的開發和集成」。</span></p><p><span style="color:#000000">新中心將幫助促進與在國家安全中使用人工智能相關的最佳實踐、評估方法和風險框架的發展。美國國家安全局將整合所有與人工智能和安全相關的活動，並在人工智能安全中心進行。</span></p><p><span style="color:#000000">美國國家安全局將與商業公司、國家實驗室、學術界、國防部和選定的外國合作伙伴就這一計劃密切合作。</span></p><p><span style="color:#000000">美國國家安全局局長、陸軍上將 Paul Nakasone 表示：</span></p><blockquote><p><span style="color:#000000">「人工智能將對我們國家以及我們的盟友和合作夥伴的外交、技術和經濟事務中的國家安全產生越來越重要的影響。今天，美國在這個關鍵領域處於領先地位，但這種領先不應被視為理所當然。幾十年來，我們的對手一直利用盜竊和利用我們的知識產權來促進他們的利益，他們將尋求利用我們在人工智能方面的進步，並破壞我們對其的應用。」</span></p></blockquote><p><span style="color:#000000">這一公告是美國政府一系列人工智能相關舉措中的又一項。例如，1 月份，美國國防部更新了 2012 年關於負責任地開發自主武器系統的指南，以反映人工智能的最新進展。2020 年，他們還發布了《負責任的人工智能戰略和實施路徑》。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260112/nsa-open-ai-security-center</guid>
            <link>https://www.oschina.net/news/260112/nsa-open-ai-security-center</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Yazi —— 極速終端文件管理器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Yazi（中文「鴨子」）是一個用 Rust 編寫的終端文件管理器，基於非阻塞異步 I/O。它旨在提供高效、用户友好且可定製的文件管理體驗。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span style="background-color:#ffffff; color:#1f2328">注意：Yazi 目前正在積極開發中，可能不穩定。</span></p><h4 style="text-align:start"><strong><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特性</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><strong>完全異步支持</strong>：所有 I/O 操作都是異步的，CPU 任務分佈在多個線程上，充分利用可用資源。</li><li><strong>強大的異步任務調度和管理</strong>：提供實時進度更新、任務取消和內部任務優先級分配。</li><li><strong>內置支持多種圖像協議</strong>：還與Überzug++集成，覆蓋幾乎所有終端。</li><li><strong>內置代碼高亮和圖像編碼</strong>：結合預緩存機制，大大加速圖像和普通文件的加載。</li><li>與 fd、rg、fzf、zicide 集成</li><li>類似 Vim 的輸入組件和選擇組件</li><li>多選項卡支持，可滾動預覽（適用於視頻、PDF、檔案、目錄、代碼等）</li><li>批量重命名、可視模式、文件選擇器</li><li>題系統、自定義佈局、垃圾桶、CSI u</li><li>...&nbsp;</li></ul><p><img height="353" src="https://static.oschina.net/uploads/space/2023/0918/162924_SnRz_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/yazi</guid>
            <link>https://www.oschina.net/p/yazi</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 一站式開源數據可觀測性平台 Datavines]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-datavines" class="anchor" href="https://gitee.com/datavane/datavines#datavines"></a>Datavines</h1><p><a href="https://gitee.com/datavane/datavines/blob/dev/README.md"><img src="https://img.shields.io/badge/document-English-blue.svg" alt="EN doc" referrerpolicy="no-referrer"></a><a href="https://gitee.com/datavane/datavines/blob/dev/README.zh-CN.md"><img src="https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%E4%B8%AD%E6%96%87%E7%89%88-blue.svg" alt="CN doc" referrerpolicy="no-referrer"></a></p><hr><p>Datavines 是一站式開源數據可觀測性平台，提供元數據管理、數據概覽報告、數據質量管理，數據分佈查詢、數據趨勢洞察等核心能力，致力於幫助用户全面地瞭解和掌管數據，讓您做到心中有數。</p><h2><a id="user-content-架構設計" class="anchor" href="https://gitee.com/datavane/datavines#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1"></a>架構設計</h2><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/architecture.jpg" alt="DataVinesArchitecture" referrerpolicy="no-referrer"></p><h2><a id="user-content-安裝" class="anchor" href="https://gitee.com/datavane/datavines#%E5%AE%89%E8%A3%85"></a>安裝</h2><p>使用<code>Maven3.6.1</code>以及以上版本</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>mvn clean package <span class="nt">-Prelease</span><span class="nt">-DskipTests</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-特性" class="anchor" href="https://gitee.com/datavane/datavines#%E7%89%B9%E6%80%A7"></a>特性</h2><h3><a id="user-content-數據目錄" class="anchor" href="https://gitee.com/datavane/datavines#%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95"></a>數據目錄</h3><ul><li>定時獲取<strong>數據源元數據</strong>，構造數據目錄</li><li>定時監聽<strong>元數據變更</strong>情況</li><li>支持元數據的<strong>標籤管理</strong></li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-catalog.jpg" alt="數據目錄" referrerpolicy="no-referrer"></p><h3><a id="user-content-數據質量監控" class="anchor" href="https://gitee.com/datavane/datavines#%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E7%9B%91%E6%8E%A7"></a>數據質量監控</h3><ul><li>內置 <strong>27</strong> 個數據質量檢查規則，開箱即用</li><li>支持 <strong>4</strong> 種數據質量檢查規則類型
<ul><li>單表單列檢查類型</li><li>單表自定義<code>SQL</code>檢查類型</li><li>跨表準確性檢查類型</li><li>兩表值比對檢查類型</li></ul></li><li>支持配置定時任務進行<strong>定時檢查</strong></li><li>支持配置 <code>SLA </code>用於<strong>檢查結果告警</strong></li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-quality.jpg" alt="數據質量檢查" referrerpolicy="no-referrer"></p><h3><a id="user-content-數據概覽" class="anchor" href="https://gitee.com/datavane/datavines#%E6%95%B0%E6%8D%AE%E6%A6%82%E8%A7%88"></a>數據概覽</h3><ul><li>支持定時執行數據探測，輸出<strong>數據概覽報告</strong></li><li>支持<strong>自動識別</strong>列的類型自動匹配合適的數據概況指標</li><li>支持<strong>錶行數趨勢</strong>監控</li><li>支持列的<strong>數據分佈</strong>情況查看</li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-profile.jpg" alt="數據目錄" referrerpolicy="no-referrer"></p><h3><a id="user-content-插件化設計" class="anchor" href="https://gitee.com/datavane/datavines#%E6%8F%92%E4%BB%B6%E5%8C%96%E8%AE%BE%E8%AE%A1"></a>插件化設計</h3><p>平台以插件化設計為核心，以下模塊都支持用户<code>自定義插件</code>進行擴展</p><ul><li><strong>數據源</strong>：已支持 <code>MySQL</code>、<code>Impala</code>、<code>Starocks</code>、<code>Doris</code>、<code>Presto</code>、<code>Trino</code>、<code>ClickHouse</code>、<code>PostgreSQL</code></li><li><strong>檢查規則</strong>：內置空值檢查、非空檢查、枚舉檢查等 27 個檢查規則</li><li><strong>作業執行引擎</strong>：已支持<code>Spark</code>和<code>Local</code>兩種執行引擎。<code>Spark </code>引擎目前僅支持<code>Spark2.4</code>版本，<code>Local</code> 引擎則是基於<code>JDBC</code>開發的本地執行引擎，無需依賴其他執行引擎。</li><li><strong>告警通道</strong>：已支持<strong>郵件</strong></li><li><strong>錯誤數據存儲</strong>：已支持 <code>MySQL</code> 和 <strong>本地文件</strong>（僅支持<code>Local</code>執行引擎）</li><li><strong>註冊中心</strong>：已支持 <code>MySQL</code>、<code>PostgreSQL</code> 和 <code>ZooKeeper</code></li></ul><h3><a id="user-content-多種運行模式" class="anchor" href="https://gitee.com/datavane/datavines#%E5%A4%9A%E7%A7%8D%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"></a>多種運行模式</h3><ul><li>提供<strong>Web 頁面</strong>配置檢查作業、運行作業、查看作業執行日誌、查看錯誤數據和檢查結果</li><li>支持<strong>在線生成</strong>作業運行腳本，通過 <code>datavines-submit.sh</code> 來提交作業，可與調度系統配合使用</li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-job-script.jpg" alt="作業腳本" referrerpolicy="no-referrer"></p><h3><a id="user-content-容易部署高可用" class="anchor" href="https://gitee.com/datavane/datavines#%E5%AE%B9%E6%98%93%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8"></a>容易部署&amp;高可用</h3><ul><li>平台依賴少，容易部署</li><li>最小僅依賴 <code>MySQL</code> 既可啓動項目，完成數據質量作業的檢查</li><li>支持水平擴容，自動容錯</li><li><strong>無中心化設計</strong>，<code>Server</code> 節點支持水平擴展提高性能</li><li>作業<strong>自動容錯</strong>，保證作業不丟失和不重複執行</li></ul><h2><a id="user-content-環境依賴" class="anchor" href="https://gitee.com/datavane/datavines#%E7%8E%AF%E5%A2%83%E4%BE%9D%E8%B5%96"></a>環境依賴</h2><ol><li><code>Java</code> 運行環境:<code>Jdk8</code></li><li><code>Datavines</code> 支持 <code>JDBC</code> 引擎，如果你的數據量較小或者只是想做功能驗證，可以使用 <code>JDBC</code> 引擎</li><li>如果您要想要基於 <code>Spark</code> 來運行 <code>Datavines</code> ，那麼需要保證你的服務器具有運行 <code>Spark</code> 應用程序的條件</li></ol><h2><a id="user-content-快速入門" class="anchor" href="https://gitee.com/datavane/datavines#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"></a>快速入門</h2><p>請參考官方文檔：<a href="https://gitee.com/link?target=https%3A%2F%2Fdatavane.github.io%2Fdatavines-website%2Fzh-CN%2Fdocs%2Fuser-guide%2Fquick-start%2F">快速入門指南</a></p><h2><a id="user-content-開發指南" class="anchor" href="https://gitee.com/datavane/datavines#%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97"></a>開發指南</h2><p>請參考官方文檔：<a href="https://gitee.com/link?target=https%3A%2F%2Fdatavane.github.io%2Fdatavines-website%2Fzh-CN%2Fdocs%2Fdevelopment%2Fenvironment-preparation%2F">開發指南</a></p><h2><a id="user-content-貢獻指南" class="anchor" href="https://gitee.com/datavane/datavines#%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97"></a>貢獻指南</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fpulls"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" referrerpolicy="no-referrer"></a></p><p>你可以提交 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fpulls">pull requests</a> 或者 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fissues%2Fnew%2Fchoose">GitHub issues</a>.</p><blockquote><p>如果您是發佈問題的新手，我們要求您閲讀 <a href="https://gitee.com/link?target=http%3A%2F%2Fwww.catb.org%2F~esr%2Ffaqs%2Fsmart-questions.html"><em>How To Ask Questions The Smart Way</em></a> (<strong>本指南不提供此項目的實際支持服務！</strong>) 和<a href="https://gitee.com/link?target=http%3A%2F%2Fwww.chiark.greenend.org.uk%2F~sgtatham%2Fbugs.html">How to Report Bugs Effectively</a> 。好的錯誤報告可以讓我們更好地幫助您！</p></blockquote><p>感謝所有已經為 Datavines 做出貢獻的人！</p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fgraphs%2Fcontributors"><img src="https://contrib.rocks/image?repo=datavane/datavines" alt="contrib graph" referrerpolicy="no-referrer"></a></p><h2><a id="user-content-license" class="anchor" href="https://gitee.com/datavane/datavines#license"></a>License</h2><p><code>Datavines</code> 基於 <a href="https://gitee.com/datavane/datavines/blob/dev/LICENSE">Apache License 2.0</a> 協議。<code>Datavines</code> 依賴了一些第三方組件，它們的開源協議也為 <code>Apache License 2.0</code> 或者兼容 <code>Apache License 2.0</code>， 此外 <code>Datavines</code> 也直接引用或者修改了 <code>Apache DolphinScheduler</code>、<code>SeaTunnel</code> 以及 <code>Dubbo</code> 中的一些代碼，均為 <code>Apache License 2.0</code> 協議的，感謝這些項目的貢獻。</p><h2><a id="user-content-社交媒體" class="anchor" href="https://gitee.com/datavane/datavines#%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93"></a>社交媒體</h2><ul><li>微信公眾號（中文，掃描二維碼關注）</li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/wechat-qrcode.jpg" alt="微信二維碼" referrerpolicy="no-referrer"></p>]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/datavane/datavines</guid>
            <link>https://gitee.com/datavane/datavines</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 語言大模型的進化軌跡]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><section style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;"><img class="rich_pages wxw-img" data-ratio="0.6001955034213099" src="https://oscimg.oschina.net/oscnet/c4090c6e-9047-4acf-8026-4ee2c0bd5701.jpg" data-w="1023" referrerpolicy="no-referrer"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"></span></section><section style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;outline: 0px;background-color: rgb(25, 25, 25);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-style="max-width: 100%; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important; color: rgb(163, 163, 163) !important;" class="js_darkmode__0" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;background-color: rgb(255, 255, 255);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section style="margin-right: 8px;margin-left: 8px;outline: 0px;visibility: visible;line-height: 1.75em;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-style="padding: 10px; max-width: 100%; background-color: rgb(239, 239, 239); color: rgb(62, 62, 62); line-height: 25.6px; display: inline-block; width: 670px; border-width: 2px; border-style: dashed; border-color: transparent; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important;" class="js_darkmode__1" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="padding: 10px;outline: 0px;background-color: rgb(239, 239, 239);line-height: 25.6px;display: inline-block;width: 670px;border-width: 2px;border-style: dashed;border-color: transparent;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 的發佈是語言大模型（LLM）發展史的轉折點，它讓人們意識到 LLM 的潛力，並引發了「AI 競賽」，世界上主要人工智能實驗室和初創公司都參與其中。在這之後，基於 LLM 的聊天機器人層出不窮。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 及相關 LLM 模型讓我們共同見證了 AI 的歷史性變革，很多人好奇，LLM 和它們的運作方式究竟是怎樣的？它們是如何被構建的？未來又將走向何方？本文對此進行了深入探討。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">本文作者 Etienne Bernard 是人工智能和機器學習專家，NuMind 的聯合創始人兼 CEO，該企業創建由 LLM 提供支持的自定義 NLP 模型。Etienne 曾在 Wolfram Research 工作八年，主要擔任機器學習負責人，並領導了自動學習工具、用户友好的深度學習框架以及各種機器學習應用程序的開發。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></em></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">&nbsp;（以下內容經授權後由 OneFlow 編譯，轉載請聯繫 OneFlow 獲得授權。來源：https://www.numind.ai/blog/what-are-large-language-models）</span></em></p></section></section></section></section></section></section></section></section></section></section></section></section></section><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><section style="line-height: 1.6em;margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);"><strong><span style="letter-spacing: 2px;font-size: 16px;">作者 |&nbsp;Etienne Bernard</span></strong></span></section><section style="line-height: 1.6em;margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);"><strong><span style="letter-spacing: 2px;font-size: 16px;">OneFlow 編譯</span></strong></span></section><section style="line-height: 1.6em;margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);"><strong><span style="letter-spacing: 2px;font-size: 16px;">翻譯 | 宛子琳、賈川、楊婷</span></strong></span></section><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><span id="OSC_h2_1"></span><h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">1</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">語言模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">簡單來説，<strong>語言模型能夠以某種方式生成文本</strong>。它的應用十分廣泛，例如，可以用語言模型進行情感分析、標記有害內容、回答問題、概述文檔等等。但理論上，語言模型的潛力遠超以上常見任務。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">想象你有一個完備的語言模型，可生成任意類型的文本，並且人們還無法辨別這些內容是否由計算機生成，那麼我們就可以使其完成很多事，例如生成具有代表性的內容，如電子郵件、新聞稿、書籍和電影劇本等。再進一步來看，<strong>還可以用其生成計算機程序，甚至構建整個軟件。只要願意，我們還可以讓它生成科學論文</strong>。如果語言模型真正「完備」，那麼它們生成的論文將能夠以假亂真，與真實論文沒有區別，這意味着必須對語言模型展開實質性研究！</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">當然，就目前而言，完備的語言模型還無法實現，不過也展示出了這些系統的潛力。<strong>語言模型不僅僅能「預測文本」，它們的潛力可能遠超想象。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">現在我們回顧一下語言模型的發展歷程，從最初的樸素語言模型到目前基於 Transformer 的 LLM（語言大模型）。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">2</span></strong></p><span id="OSC_h2_2"></span><h2 style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">樸素語言模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">語言模型是機器學習模型，因此它們會學習如何生成文本。教授它們的方法（即訓練階段）是<strong>提供一個大規模文本語料庫，它們將從中學習如何模仿生成這些文本的過程。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">也許這聽起來有些抽象，但創建一個樸素語言模型實際上非常簡單。你可以將文本語料庫分成一定大小的字符串塊，並測量它們的頻率。下面是我使用大小為 2 的字符串得到的結果：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5605858854860186" src="https://oscimg.oschina.net/oscnet/ef013e46-5762-483f-b482-421a3f071c50.png" data-type="png" data-w="751" height="auto" width="751" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">圖源：《機器學習導論》</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這些字符串塊被稱為 n-gram（其中 n 表示字符串的大小，因此此處 n=2）。通過這些 n-gram，你可以像玩多米諾骨牌一樣生成文本。從一個初始的 n-gram 開始，例如「th」，然後根據測量的頻率隨機選擇一個以初始 n-gram 結尾的 n-gram 。在這個例子中，如果選擇「hi」，就會形成「th」 + 「hi」 = 「thi」。然後再繼續添加以「i」開頭的 n-gram，以此類推，生成整段文本。不過正如你所想，這些 n-gram 模型並不能生成足夠連貫的文本。以下是我繼續執行這一過程時得到的結果：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">説實話，這一結果並不太理想！但也説得通，因為該模型的記憶能力很有限，只通過前一個字符來預測下一個字符。如果我們使用 n=4 的字符串，結果會稍微好一些：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">「complaine building thing Lakers inter blous of try sure camp Fican chips always and to New Semested and the to have being severy undiscussion to can you better is early shoot on」</span></em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">現在出現了一些拼寫正確的單詞，但結果仍不夠理想！理論上，進一步增加 n 的值，輸出結果會得到改善，但在實踐中，<strong>我們無法顯著增加 n 值，因為這需要一個龐大的數據集來訓練模型</strong>。最後，我們可以嘗試將單詞而不是字符作為基本單位（在自然語言處理術語中稱為「詞元（token）」）。這會改善輸出結果，但因為 n&lt;6，生成的文本仍然缺乏連貫性。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這些樸素語言模型的記憶能力始終有限，因此無法生成超過一定長度的連貫文本</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">。儘管如此，它們仍具備一定用途。幾年前，樸素語言模型被廣泛用於文本分類和語音識別，且如今仍被用於語言識別等任務。<strong>然而，對於更高級的文本理解和文本生成任務來説，樸素語言模型就捉襟見肘了。因此需要神經網絡。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">3</span></strong></p><span id="OSC_h2_3"></span><h2 style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">基於神經網絡的語言模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">現代語言模型基於（人工）神經網絡。<strong>神經網絡是受人腦啓發開發出的計算機，能夠通過任務示例學習如何執行任務</strong>。這種機器學習形式也被稱為深度學習，因為其中的網絡由多個計算層組成（因此被稱為「深度」網絡）。<strong>在神經網絡中，通過遍歷任務示例並迭代修改網絡參數以優化任務目標，從而實現學習。你可以將這些參數想象成一組旋鈕（knob），通過左右旋動以改進目標</strong>，但區別是計算機為你進行改進，並且知道如何同時正確地朝着改進方向進行調整（得益於著名的反向傳播算法）。因此，網絡會遍歷任務示例（通常以幾百個示例為一批），並在這一過程中優化目標。以下是一個正在被優化的目標示例（稱為成本函數，數值越小越好）：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.607565011820331" src="https://oscimg.oschina.net/oscnet/ebf3e1ab-0914-4c47-ad3b-09f58569f6f6.png" data-type="png" data-w="423" height="auto" width="423" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">成本函數隨訓練迭代次數的變化。圖源：《機器學習導論》</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">隨着模型的訓練，成本函數值會逐漸下降，意味着模型在任務處理上變得更加優秀。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在該案例中，我們想要生成文本。<strong>目前，標準的方法是訓練一個模型，通過前面的單詞預測後面的單詞</strong>。由於下一個單詞有多種可能性，模型會學習為每個可能的單詞關聯一個概率。以下是對「the cat sat on the」之後可能出現單詞的概率分佈可視化圖像：<br><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5652173913043478" src="https://oscimg.oschina.net/oscnet/c028e4da-8de4-406c-adde-4643579804a5.png" data-type="png" data-w="529" height="auto" width="529" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">改編自《機器學習導論》</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">一旦擁有這樣的預測模型，就可以從預測概率中抽樣來生成下一個單詞，然後將該單詞重新輸入到網絡，再抽樣一個新的單詞，以此類推，從而生成文本</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">。這一生成過程被稱為自迴歸，因為網絡利用自己的預測結果來生成新的預測。雖然有人對此提出了異議，認為這並非最佳方法，但目前而言，這就是最實際的操作方式，且效果也出奇地好！</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">曾經用於建模語言的第一類神經網絡是 RNN（循環神經網絡），尤其是 LSTM（長短期記憶網絡）架構。<strong>RNN 就像一個逐個閲讀單詞的小型機器，在這一過程中，它會更新思維狀態（mental state）</strong>。這種思維狀態如同記憶，使它們在生成文本時能大概記住一段時間的信息。<strong>相比 n-gram 模型，RNN 模型能夠獲得更為優越的性能。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">RNN 創建之初，神經對話模型（Neural Conversational Model）給我留下了深刻印象。該模型是 Google 於 2015 年基於電影字幕訓練的一個特殊 LSTM 模型，當時這個模型已經算得上是 LLM 了（也可能是首個 LLM）：擁有 3 億參數，並在約 10 億詞的數據上進行訓練。由於電影字幕是對話形式，因此可直接將該模型用作聊天機器人。以下是不同人類輸入對應的回答示例：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類：你叫什麼名字？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">機器：我叫朱莉婭。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類：你是什麼時候出生的？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">機器：7 月 20 日。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類：我的名字是大衞。我的名字是什麼？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">機器：大衞。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類：天行者是誰？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">機器：他是一個英雄。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類：天空是什麼顏色？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">機器：藍色。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人類：血液是什麼顏色？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">機器：和黑眼圈的顏色相同。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">如你所見，該模型能夠閒聊，同時也對世界有一定了解，這些知識完全是通過學習如何預測文本獲得的！我記得自己曾對這一事實很感興趣：<strong>學習預測文本迫使你理解世界</strong>（但並不意味着這個過程很容易）。然而，該模型也有一些明顯的短板：它經常出錯，並且與類似基於 LSTM 的模型一樣，無法生成長篇連貫的文本。理論上，循環神經網絡可以長時間記憶事物，<strong>但在實踐中，它們卻往往很快就忘記了：經過幾十到一百個詞之後，它們就會開始偏離主題，不再連貫。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">2017 年，人們針對短期記憶問題提出一種解決方案——Transformer</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">。Transformer 是一種基於注意力機制的新型神經網絡架構（本質上是一種選擇操作），下圖來自介紹 Transformer 的論文，用以説明其在翻譯任務中的工作原理：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="1.4446640316205535" src="https://oscimg.oschina.net/oscnet/535ec695-4411-41cb-90ef-59154234fded.png" data-type="png" data-w="1012" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">Transformer 架構。來源：https://arxiv.org/abs/1706.03762</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">Transformer 在各個方面都可圈可點，但最值得一提的是，<strong>該架構在文本建模方面表現非常出色，並且很適合在 GPU 上運行，從而處理（和學習）大量數據。正是有了 Transformer 這種架構，才使得現代 LLM 得以興起（或至少起到了很強的促進作用）。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="color:#3f3f3f;"><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">4</span></span></strong></p><span id="OSC_h2_4"></span><h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;color: rgb(30, 35, 128);font-size: 17px;">現代語言大模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">Transformer 的發明標誌着現代 LLM 時代的開始。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">自 2018 年以來，AI 實驗室開始訓練規模越來越大的模型。令眾人驚訝的是，這些模型的質量也在不斷提高！下圖對這些模型進行了可視化，我們將重點介紹其中值得關注的模型：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><img class="rich_pages wxw-img" data-ratio="0.7972222222222223" src="https://oscimg.oschina.net/oscnet/d63f0ce4-11ec-418a-b09c-9a910e495283.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">LLM 進化樹。來源：https://github.com/Mooler0410/LLMsPracticalGuide</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這些語言模型主要分為三類。一是「僅編碼器（encoder-only）」組（上圖中的粉色部分），該類語言模型擅長文本理解，因為它們允許信息在文本的兩個方向上流動。二是「僅解碼器（decoder-only）」組（上圖中的藍色部分），該類語言模型擅長文本生成，因為信息只能從文本的左側向右側流動，以自迴歸方式有效生成新詞彙。三是「編碼器-解碼器（encoder-decoder）」組（上圖中的綠色部分），該類語言模型對上述兩種模型進行了結合，用於完成需要理解輸入並生成輸出的任務，例如翻譯。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這一切都主要始於文本理解類模型。最初是使用 RNN 的 ELMo，之後是谷歌著名的 BERT 模型及其派生模型（如 RoBERTa），它們都基於 Transformer。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這些模型通常具有幾億個參數（相當於約 1GB 的計算機內存），在大約 10GB 到 100GB 的文本上進行訓練（通常為幾十億個單詞），並且可以在現代筆記本電腦上以約 0.1 秒的速度處理一段文本。<strong>這些模型極大地提升了文本理解任務的性能，如文本分類、實體檢測和問題回答等。</strong>這已然是 NLP（自然語言處理）領域的一場革命，不過才剛剛拉開序幕……</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在文本理解類語言模型發展的同時，<strong>OpenAI 開始基於 Transformer 創建文本生成類語言模型</strong>。首先是 2018 年的 GPT-1，有 1 億個參數；<strong>然後是 2019 年的 GPT-2，擁有高達 15 億個參數，並在 40GB 的文本上進行了訓練</strong><strong>。至少對我來説，GPT-2 的創建是一個至關重要的時刻。</strong>以下是 GPT-2 可以生成的文本示例，從一個由人類撰寫的段落開始：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5203703703703704" src="https://oscimg.oschina.net/oscnet/6cc3b7d0-9aa6-4f4f-a9b6-95e215a32d2d.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">來源：https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">生成的英語文本質量很不錯，而且具有連貫性。例如，科學家的名字沒有改變，而這在基於 RNN 的模型中是個經典問題。<strong>由於 GPT-2 在所生成文本的質量上取得了巨大突破，</strong><strong>為避免濫用，OpenAI 最初決定不向公眾發佈。</strong>可以説 GPT-2 標誌着 LLM 正朝着正確的方向發展。<strong>需要注意的是：使用這類語言模型需要先提供一個起始文本，這個起始文本被稱為提示（prompt）。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">一年後（2020 年），OpenAI 創建了 GPT-3。<strong>GPT-3 是一個具有 1750 億個參數的模型</strong>（需要 700GB 的計算機內存來存儲模型！），<strong>該模型不僅規模顯著擴大，文本生成質量也有重大改進。除了性能的提升外，GPT-3 還讓人們對未來如何使用 LLM 大開眼界。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">首先，<strong>GPT-3 能夠編寫代碼</strong>。例如，你可以使用 GPT-3 來生成（非常）簡單的網站，只需在提示中描述網站的外觀即可。以下是一個示例，讓 GPT-3 使用 HTML 創建一個按鈕：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.3148148148148148" src="https://oscimg.oschina.net/oscnet/891ad7cc-c694-4283-ba93-4a711bc8b6b3.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這些基本的編碼能力在當時並不十分實用，<strong>但它們的出現意味着軟件開發在未來可能會發生根本性轉變。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">GPT-3 另一令人矚目的能力是能夠進行上下文學習，它可以通過提示中所展示的示例來學習如何執行任務。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這意味着你可以通過編寫提示來定製 LLM，而無需更改它們的權重。這一能力開闢了一種全新的、完全基於提示的自然語言處理方式，如今十分受歡迎。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">總而言之，GPT-3 展示了「提示」作為一種新方式的潛力，可以讓機器通過自然語言按照我們的意願執行任務。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">注意：GPT-3 比 GPT-2 要大得多。<strong>自 2018 年以來，模型的規模急劇增加。</strong>以下是一些值得關注的 LLM 及其規模：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.84" src="https://oscimg.oschina.net/oscnet/7399dbde-b740-42d5-97e7-367afd2035ec.png" data-type="png" data-w="600" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在兩年時間裏，模型參數的數量增加了 1000 倍，目前最大的模型（如 GPT-4）已接近 1 萬億個參數，</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這是因為模型規模的增加與性能的改善密切相關，並且目前還未達到性能瓶頸。這些模型規模十分龐大，與人腦相比，人腦約有 1000 億個神經元，每個神經元平均與其他 1000 個神經元相連接，總共約有 100 萬億個連接。從某種意義上説，最大的 LLM 仍然比人腦小 100 倍。當然，這只是一個非常寬泛的比較，因為人腦和當前 LLM 使用的架構和學習方法都截然不同。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">另一個有趣的指標是這些模型在訓練階段所「閲讀（read）」的單詞數量。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.7116666666666667" src="https://oscimg.oschina.net/oscnet/fce3c3d5-5632-40a4-92df-0de3b10de8d2.png" data-type="png" data-w="600" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">如你所見，數量十分龐大。<strong>這些模型在訓練過程中會接觸超 1000 億個單詞，是一個人在一生中聽到或閲讀單詞數量的 100 倍以上！</strong>這顯示出神經網絡與人腦的不同之處：<strong>神經網絡的學習速度比人類慢得多，但可以獲得比人類接觸的多得多的數據。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">需要注意的是，LLM 在訓練過程中所接觸到的單詞數量並未像參數數量那樣迅速增長（從 GPT-1 到 GPT-3 只增長了 3 倍）。這是因為優先考慮模型規模，不過結果證明這是一個小小的失誤。最新的模型並沒有比 GPT-3 大很多，但通過處理更多單詞來進行訓練。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">這種對數據的渴求導致了一個問題，即可用文本的總量存在硬性限制，約為數萬億個單詞，而模型正在接近這一限制。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">雖然仍有可能循環遍歷所有文本，但這會導致模型性能的回報遞減。總而言之，可得出結論：網絡在訓練階段處理的有效限制是幾十萬億個單詞，比 GPT-4 的數量約多出 10 倍。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">另一個問題是，通過用更多的數據訓練更大的模型，計算成本也在增加。以下是訓練上述模型的預估計算成本：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.7116666666666667" src="https://oscimg.oschina.net/oscnet/d828b020-6cac-4651-b22c-97d85f9b7678.png" data-type="png" data-w="600" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">為顯著超越當前模型的性能，下一代模型需要耗費數億美元的計算資源。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">雖然考慮到這些模型能帶來的好處，這一成本是合理的，但如此巨大的花費仍然是一個問題。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">模型的擴展變得越來越困難。幸運的是，擴大規模並不是改進 LLM 的唯一途徑。2022 年末，一項創新開啓了另一場革命，這次的影響遠遠超出了 NLP 領域。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">5</span></strong></p><span id="OSC_h2_5"></span><h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;color: rgb(30, 35, 128);font-size: 17px;">指令調優和聊天機器人 LLM</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">GPT-3 揭示了提示的潛力，但撰寫提示並不容易。事實上，傳統語言模型經訓練可以模仿其在網絡上看到的內容。因此，要想創建一個好的提示，你必須清楚網絡上哪種起始文本可能會引導模型生成你所期望的結果。這是一種奇怪的遊戲，也是一種找到正確表述的藝術，<strong>你需要改變措辭，假裝自己是專家，展示如何逐步思考的示例等等。這一過程叫做提示工程，這使得使用這些 LLM 變得困難。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">為解決這個問題，研究人員一直在探索如何修改基礎 LLM，以讓其更好地遵循人類指令。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">現主要有兩種方法：一是使用人類編寫的指令-回答對（instruction-answer pairs），並在此數據集上對基礎 LLM 進行微調（即繼續訓練）。二是讓 LLM 生成幾個可能的答案，然後由人類對答案評分，並使用強化學習在此數據集上對 LLM 微調。這就是著名的 RLHF（人類反饋的強化學習）的過程。此外，我們還可以將兩種方法相結合，OpenAI 在 InstructGPT 和 ChatGPT 中就對這兩者進行了結合。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5685185185185185" src="https://oscimg.oschina.net/oscnet/2fbcb686-6afb-4f7f-9b9c-684b8b26350c.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">InstructGPT 和 ChatGPT 的指令調整步驟。來源：https://openai.com/blog/chatgpt（修改自 https://arxiv.org/abs/2203.02155）</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">將這兩種技術結合在一起可以得到一個經過指令調整的 LLM。調整後的 LLM 比基礎模型更擅長遵循人類指令，使用起來更加容易。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">經過指令調整的 LLM 已經非常出色了，但還有最後一步才能將這些 LLM 真正轉化為每個人都可以使用的東西——聊天機器人。<strong>OpenAI 在 2022 年 12 月發佈了 ChatGPT，一個基於 GPT-3.5 的聊天機器人。</strong>它的創建方式與 InstructGPT 相同，但這次使用的是整個對話而不僅僅是指令-回答對。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 發佈後，基於 LLM 的新型聊天機器人開始層出不窮。OpenAI 使用 GPT-4 來代替 GPT-3.5，對 ChatGPT 進行了改進，Anthropic 發佈了 Claude，Google 推出 Bard，Meta 也研發出了 LLaMA，還有幾個開源 LLM 正在發佈過程中。<strong>這是一次真正的模型大爆炸，將會帶來許多令人興奮的應用，NuMind 也會為此出一份力。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 發佈兩個月後，迅速擁有了上億用户，成為有史以來用户增長最快的產品。人們用 ChatGPT 來根據要點編寫電子郵件、重新組織文本、總結文本、編寫代碼，或學習東西（在此之前，搜索引擎一直壟斷着這項任務）。<strong>ChatGPT 的發佈是 LLM 發展史的轉折點，它讓人們意識到了 LLM 的潛力，引發了「AI 競賽」，世界上主要人工智能實驗室和初創公司都參與其中。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">值得注意的是，LLM 的突然普及也引發了人們的擔憂。人們擔心 LLM 被有心人利用，做一些有害的事情，所以創建開放式 LLM 聊天機器人必須確保它們的「安全」性（或「與人類價值觀保持一致」），也就是説它們不能幫助製造炸彈等。目前有一些方法可以繞過聊天機器人的安全防禦措施，但隨着時間推移，這些安全措施會逐漸完善，想繞過它們將變得十分困難。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">6</span></strong></p><span id="OSC_h2_6"></span><h2 style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;color: rgb(30, 35, 128);font-size: 17px;">語言大模型的未來</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">近年來，LLM 取得了很大進步，人們對它的熱情達到了空前高度，在這一領域投入了大量精力。那麼，LLM 的未來將如何發展？雖然預測未來很難，但我們也有一些看法：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">模型大小和訓練規模將繼續擴大。擴展在過去取得了非常好的效果，且仍有提升空間</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">，但問題是，模型的訓練成本急劇增長，逐漸讓人望而卻步（&gt;1 億美元）。更好的 GPU 和新的專用硬件有助於擴展模型規模，但它們的開發和生產需要時間。此外，最大的模型已經迭代了所有書籍和整個網絡，這意味着我們正在達到可用訓練數據的極限（即「詞元危機」）。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">因此，可以肯定的是，在未來幾年內，參數數量不會像過去那樣出現爆發式增長。<strong>最大的模型今年應該會穩定在 1 萬億參數以下規模，然後以每年 50% 的速度增長。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">LLM 將超越純語言模型，<strong>將圖像和視頻納入訓練數據</strong>，成為多模態模型。從圖像和視頻中學習可能有助於模型更好地理解世界。GPT-4 就是在圖像和文本上進行訓練的，且取得了少許性能提升。<strong>利用視頻數據訓練 LLM 可能給這一領域帶來質的改變，但這需要大量計算。預計還需兩年多的時間才能真正實現利用視頻訓練「語言」大模型。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">擴大規模、實現語言模型向多模態模型的轉變需要大量算力。為緩解這一問題，我們可以採用更好的神經架構和訓練程序，這些架構和訓練程序要麼計算強度較低，要麼可以用更少的數據進行學習（人類大腦證明這是可能的）。然而更可能的是類似於 RNN 的內存會捲土重來，因為這種內存運行時的效率非常高（例如最近的 RWKV 架構）。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><strong>此外，還可能有一些更大的變化，例如 LLM 不以自迴歸的方式生成，而是以自上而下的方式生成</strong>（例如在生成單詞之前做出（隨機）決定），這種做法可能更合乎邏輯（這就是神經網絡目前生成圖像的方式）。到底何時會開發出這樣的新架構/方法還很難説，但我們預計應該就在未來幾年，一旦開發出來，LLM 模型的性能將得到大幅提升。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">另一個改進方向是繼續進行指令調優，讓更多人蔘與到「教育」LLM（即與 AI 對齊）的過程中。這可以由私人 AI 實驗室來實現，也可以是一個更像維基百科的眾包項目，以改進和對齊開放模型的 LLM 能力。在這個問題上，我們還是希望偏離傳統的 RLHF，而是讓人們與模型對話來進行教導，就像我們對待孩子一樣。我不確定這種項目的具體時間線，但我已經思考了一段時間，非常希望看到它的實現。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">上文我們只討論了改進實際模型的方法，但實際上有一些方法可以在不改變模型的情況下改進 LLM。<strong>方法之一就是為 LLM 提供工具</strong>。這種工具可以是用於查找準確信息的搜索引擎，或者是用於進行基本數學計算的計算器。此外，它還可以是一個結合了推理引擎（符號人工智能的經典組件）的知識庫，如 Wolfram Alpha，用於查找事實、進行邏輯推理或其他神經網絡不擅長的計算。當然，這個工具還可以是一個用於編寫和運行代碼的完整編程環境。LLM 可以通過生成觸發 API 調用的特殊詞元（單詞）來使用這些工具，然後將 API 的輸出插入到生成的文本中。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.6586270871985158" src="https://oscimg.oschina.net/oscnet/49d3e79a-4b8d-42f1-b679-51c70d2b0c32.png" data-type="png" data-w="1078" height="auto" width="auto" referrerpolicy="no-referrer"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">LLM 使用工具示例。來源：https://arxiv.org/abs/2302.04761</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">上述趨勢實際上已經開始了（例如，ChatGPT 插件、LangChain 庫和 Toolformer 論文），我相信這些工具將成為 LLM 的核心。</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">改進 LLM 的另一個方法是以更智能的方式使用它們，讓它們更好地完成任務。這可以通過巧妙的提示或更高級的程序來實現。<strong>比如説我們可以讓 LLM 按步驟進行思考（即思想鏈提示（ chain-of-thoughts prompting）），並提高 LLM 在邏輯任務上的表現。</strong>以下是提示 LLM 按步驟思考的示例：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.4842592592592593" src="https://oscimg.oschina.net/oscnet/ae908068-436d-4861-9e91-105957832a7b.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">思維鏈提示示例。來源：https://arxiv.org/abs/2201.11903</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">同樣地，我們可以要求 LLM 反思、批判自己的輸出，並對其進行迭代修改。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">通過迭代，我們可以顯著提高 LLM 性能，尤其是生成代碼方面的性能。<strong>我們還可以更進一步，創建完全自主的智能體，這些智能體可以管理任務列表並迭代任務，直到達到主要目標（請參考 AutoGPT 和 BabyAGI）。</strong><strong>目前，這些自動化智能體的運行效果並不理想，但它們的效果會逐步提升，很難説這些自動化智能體會發展到何種程度，對 LLM 產生何種影響。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">由於 LLM 可以通過這些程序（思想鏈、迭代批評等）改進答案，因此，我們可以使用這些程序創建指令-答案對，然後在指令-答案對上按順序對 LLM 微調以提高其性能。這種自我完善是可能的（參見</span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(136, 136, 136);"><em>https://arxiv.org/abs/2210.11610</em></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">），我相信它具有很大的潛力。<strong>例如，我們可以想象模型為了變得更加自洽而與自身進行討論，這是一種自我反思過程。</strong>可能會進一步提升 LLM 的表現。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">LLM 可能還有其他改進方向，總的來説，我們無法確定 LLM 的未來，但顯然它們將繼續發展下去。<strong>理解和生成文本的能力使 LLM 成為了一項基本技術。即使在目前的發展情況下，LLM 也將解鎖大量應用程序，日常工作中的數字助理就是一個很好的例子，更瘋狂的是，LLM 甚至可能引導我們創造某種超級智能。</strong></span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><section style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;white-space: normal;outline: 0px;caret-color: rgba(0, 0, 0, 0.9);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-size-adjust: auto;line-height: 1.75em;text-align: left;"><span style="background-color: rgb(255, 255, 255);color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 1px;">其他人都在看</span><br></section><span id="OSC_h3_7"></span><h3 style="letter-spacing: 0.578px;white-space: normal;"><ul class="list-paddingleft-1" style="width: 577.422px;"><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491796%26idx%3D1%26sn%3D41f16bd562cebfeb5fbb06a8b8758ebb%26chksm%3Dfe426ee2c935e7f449d0cc74c9a1faeb23489ee06d6f02554c103459b01fb3ae8b1e1baa7e93%26scene%3D21%23wechat_redirect" textvalue="關於語言大模型的八大論斷" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">關於語言大模型的八大論斷</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491796%26idx%3D1%26sn%3D41f16bd562cebfeb5fbb06a8b8758ebb%26chksm%3Dfe426ee2c935e7f449d0cc74c9a1faeb23489ee06d6f02554c103459b01fb3ae8b1e1baa7e93%26scene%3D21%23wechat_redirect" textvalue="關於語言大模型的八大論斷" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491801%26idx%3D1%26sn%3D9cc37240451fa684825ad82a3133e12a%26chksm%3Dfe426eefc935e7f9c31a21752e898004461180b0176f38ee7b390110610e99fff1d664450729%26scene%3D21%23wechat_redirect" textvalue="NCCL 源碼解析④：建圖過程" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">NCCL 源碼解析④：建圖過程</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491741%26idx%3D1%26sn%3D125132a0c895fbaf0606f0097cf95998%26chksm%3Dfe426eabc935e7bd81c3403dcc85eed4404f32f713862217c526596d86d728e1d94346cbbe43%26scene%3D21%23wechat_redirect" textvalue="揭示 GPT Tokenizer 的工作原理" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">揭示 GPT Tokenizer 的工作原理</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491741%26idx%3D1%26sn%3D125132a0c895fbaf0606f0097cf95998%26chksm%3Dfe426eabc935e7bd81c3403dcc85eed4404f32f713862217c526596d86d728e1d94346cbbe43%26scene%3D21%23wechat_redirect" textvalue="揭示 GPT Tokenizer 的工作原理" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491783%26idx%3D1%26sn%3Db3ebb8a7d4441aaceb62db59992db61b%26chksm%3Dfe426ef1c935e7e7a1ddfba5412a98ee8c091c4304724e73b202a0e127b533f8d039a3ed9703%26scene%3D21%23wechat_redirect" textvalue="語言大模型 100K 上下文窗口的秘訣" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">語言大模型 100K 上下文窗口的秘訣</a><br></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491721%26idx%3D1%26sn%3D71fd215ca3625f276913db5f62d6791e%26chksm%3Dfe426ebfc935e7a96d0437566485a5774b6e3063ba4c768093eaffc25f054730e0f7f836be3f%26scene%3D21%23wechat_redirect" textvalue="GPT 總設計師：大型語言模型的未來" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">GPT 總設計師：大型語言模型的未來</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><section style="outline: 0px;line-height: 1.75em;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" textvalue="一塊 GPU 訓練 TB 級推薦模型不是夢，OneEmbedding 性能一騎絕塵" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="outline: 0px;cursor: pointer;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">OneEmbedding:單卡</a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" textvalue="一塊 GPU 訓練 TB 級推薦模型不是夢，OneEmbedding 性能一騎絕塵" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="outline: 0px;cursor: pointer;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">訓練 TB 級推薦模型不是夢</a></section></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><section style="outline: 0px;line-height: 1.75em;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247490555%26idx%3D1%26sn%3D280c4ac043a31170236a9d8fba5fc2d2%26chksm%3Dfe4195cdc9361cdb6db1cb3b77c66b45c353b2fb65c4d082fbae9b72fe0b3a441ab9101cb147%26scene%3D21%23wechat_redirect" textvalue="GLM 國產大模型訓練加速：性能最高提升 3 倍，顯存節省 1/3，低成本上手" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">GLM 訓練加速：性能最高提升 3 倍，顯存節省 1/3</a></section></li></ul><section style="outline: 0px;line-height: 1.75em;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;outline: 0px;background-color: rgb(255, 255, 255);letter-spacing: 1px;font-size: 14px;color: rgb(63, 63, 63);">試用 OneFlow: github.com/Oneflow-Inc/oneflow/</span></section></h3><h2 style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;"><hr style="border-style: solid;border-right-width: 0px;border-bottom-width: 0px;border-left-width: 0px;border-color: rgba(0, 0, 0, 0.1);transform-origin: 0px 0px;transform: scale(1, 0.5);"></h2><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: center;"><img class="rich_pages wxw-img" data-backh="162" data-backw="578" data-galleryid="" data-ratio="0.2802690582959641" data-s="300,640" src="https://oscimg.oschina.net/oscnet/de5775ed-8e8f-4ce5-8a22-887be523b2a7.png" data-type="png" data-w="892" style="width: 100%;display: inline;height: auto;" referrerpolicy="no-referrer"></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10086766</guid>
            <link>https://my.oschina.net/oneflow/blog/10086766</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國慶中秋特別漫畫：小哪吒貓助力大平台工程]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-d91588328d298da006ea97d4e2408fbd16c.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">現代 IT 和 DevOps 面臨着業務增長、微服務數量激增、開發者工具分散、複雜流程和多雲部署等諸多挑戰，導致業務滿意度下降和開發者體驗受損。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-ddd1050d3f1669e0d201ad4b2a33c5d6070.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">而「平台工程」是一種軟件工程方法，旨在簡化交付流程、提高開發者生產力，更是被 Gartner 列為 2023 年十大戰略技術趨勢。ZadigX 新版本發佈在即，它整合了企業現有資源和工具鏈，避免了從零開始的平台工程建設。ZadigX 通過強大的自定義流程引擎，升級企業低效的碎片化協作流程，輕鬆應對複雜的場景挑戰，並利用 Kubernetes 雲原生技術底座管理各種複雜異構環境。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-72413f6e0050d0bcce96663b06308814696.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">ZadigX 國慶特別版帶來了一系列強大的能力矩陣，包括深度集成企業現有工具和系統，企業無需從頭開始構建平台，使業務治理更加輕鬆高效，開發者體驗更為順滑。這一版本還加強了 DevOps/Xops 工作流編排和質量工程解決方案，通過高度可擴展且低配置負擔的自定義流程引擎，解決企業複雜流程和碎片化的挑戰。同時，ZadigX 與眾多合作伙伴緊密合作，推動平台工程的升級，為開發者提供了更多鏈接一切的機會。Enjoy～</p><span id="OSC_h3_1"></span><h3><strong>01、深度集成企業現有能力和工具鏈，只為開發者體驗更絲滑</strong></h3><p><img src="https://oscimg.oschina.net/oscnet/up-b6f9875b650dc4ebfa1eb60c310e122e3e5.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#ff2968">自動化項目協同：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>發佈計劃統籌項目迭代規劃，從需求到發佈一站式完成。支持 Jira 項目、飛書 Meego 項目管理編排，實現自動化任務狀態同步。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-54e1c98c02ac79da6d85f9efbaae785dd03.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-063c0ebf4dbe2972d06d743e2488d802e13.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-159cfb76a5b41b1e14912e183800b461347.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#ff2968">配置變更與數據變更協同：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>支持 Nacos、Apollo 等配置變更、 DMS/Flyway/MySQL 等數據變更編排，實現配置變更和數據變更的自動化晉級。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-db9a95b28c2e5ebaaaaee0aecaf55f084eb.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c635493645f6f3a64018816f86800201fd2.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a51568b8fb835c9ec3088ec54a2c41a7e84.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-43f879afbcedf20a7cac5d3963780c54fe1.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-58c7a50c777142c9e14daaa9e8ad5974687.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#ff2968">開放擴展外部系統協同：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>支持全流程 OpenAPI 開放，自定義任務擴展，可接入任何外部系統。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bbd7129f4b81adfb60d163d08e72714dd40.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-dceca93bf7594c74c78bcbc7f9a72a7ecc9.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_2"></span><h3><strong>02、企業無需從零搭建，業務治理更輕鬆高效</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-3adab7831272ed9b40f791d2325ecaf118f.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">零運維負擔接入：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">實施平台工程的難度大幅降低，可通過一鍵接入托管項目實現同時治理和推廣。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e45016a56eb684b33c51f440492bc897c17.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-50919c16f1b290e77b4922045a5f5b13d11.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">企業無需修改現有流程：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">能夠支持大規模、快速安全的批量項目接入，數千項服務遷移僅需 2 周。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-676ecce9bcbb61f1caed817d6b3dfa81aba.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3c0440b6bcaed7a50a2add4ef29f496a0c6.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">個性化配置管理：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>支持企業自定義 logo、主題、權限與用户組配置，提高業務管理效率。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-12bbc58cff1be661a11340fada277e8befb.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a1b75d264c539f975ab0531e0163475e7ff.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-1543dda576a5860182acbbc38759639a757.png" referrerpolicy="no-referrer"></p><span id="OSC_h3_3"></span><h3><strong>03、DevOps/Xops 工作流編排 ，質量工程解決方案</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-ab2e5ff67abc4443a039194940f67e015b5.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">支持全流程 DevOps 集成和交付：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">實現需求到發佈的全流程協同，無縫整合開發、測試、預發佈驗證和生產發佈流程。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6ea843be2aea86430a5b4a1ae9ed2ace72c.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f82f932ae93e50fc36088aa420a5aa7ede5.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-70e3c889b78a2e74364cd7d2d4ebad95eff.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">支持多類型資源平面和變更觀測：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>集羣管理支持指定訪問權限和工作流任務執行，支持 Severless 集羣 /GPU 調度/靈活調度策略確保資源合理安全分配；擴展支持 Kubernetes 資源對象 CronJob、CRD、CloneSet 等變更管理。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5968e2b07cca00089b6f6d68d27216bf1bf.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a1378c60b4045a36d2945b57845825fbd58.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">生產服務和生產環境管理：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>隔離生產服務和生產環境資源管理和變更通道，同時支持自動化更新全局變量、環境配置、自助上下線服務、Helm Chart 生產部署等。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a6d2054efd73946af6e81527d7f90377fc2.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bfaf96b6c418a91b0e6a0ac914a4d4fe5e9.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e7613a48fda6753cdd34021ccec28df29c2.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">質量內建與安全防護：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">強調代碼質量掃描、迴歸測試、質量門等質量工程建設，提高質量水平。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f3a80ad0fdd0182bafb4b7b7a5d51898e8f.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">個性化管理運營：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">提供內置數學模型，可定製的 DevOps 數據看板，助力企業有效實施研發管理理念。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6582e0c266d75c5c9404b39cf69c0248363.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-0ec43f3dd3b15b560a8d79a8990eb0cbe89.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_4"></span><h3><strong>04、高擴展、低配置負擔的自定義流程引擎，應對企業複雜流程挑戰</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-8301a82372e5e33ba654fa882ef48959037.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">超低配置負擔：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">支持 YAML/GUI 兩種模式配置，內置 DevOps 最佳實踐模板推動架構的標準化和治理。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ea42a5b8fcddf7b75e636b47c8589dcf6f4.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-0de22a4098f55bdd4a4079bcb4731e6c77f.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-cbd296208334ce881a5930355ea8d864543.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">無限併發與擴展性：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">利用強大的雲原生底層能力，支持工作流參數傳遞、共享存儲、任務併發配置。支持服務級別測試任務編排和藍綠髮布策略。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5a9882684eb859bdc97830cb6e9915148d5.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-85718bec21612698223f79bdd49b7ec7617.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5b85fb26407a6018d9ecf7a48df91ce76e9.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ba6b1663852b874171c131c497984de61d9.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">自定義管控配置：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">強化任務步驟執行，支持集中管理、飛書、釘釘，OA 接入等審批流程。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6f0b2de0ee135fc440f95061c98b954926d.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3599d09f48e80895f1a45c89bdb5754977d.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5d8fdb33fd92b58e83db1201fe1be35bc61.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">用户友好與靈活性：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">鏡像分發任務支持配置目標鏡像生成規則，任務列表可自定義展示字段。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8ed3791587e9cb0c723958c6e2785a9e569.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-47200e5cc0905f11e73d76efe3e64bb95fb.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_5"></span><h3><strong>05、與眾多合作伙伴聯手共建平台工程升級方案，為開發者鏈接一切</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-47c27768bb61da18942141692c7acd82fa2.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">全鏈路灰度能力：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">融合阿里雲 MSE 全鏈路灰度能力，開發者可輕鬆驗證自助上線。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-46bcc5d51cf746d91687ecb79e48cf32981.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">可觀測全鏈路：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">融合觀測雲檢測服務，實現從變更到可觀測全鏈路打通，一鍵發佈。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-979e7bc7d790a3c3b0d9a880006b206bb21.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#ff2968">安全策略內建：</span>支持清源 SCA、Fortify、Sonar 集成，全流程編排安全策略，每次變更都得到安全防護。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-66b182b75cbb3c998db1a6715bf3438cea5.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f478751e724c25bb9f36a717927132d8e25.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">AI 助力效能提升：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">支持基於 Azure OpenAI 技術，提升 DevOps 診斷和運營效率，首次推出 AI 環境巡檢和 AI 效能診斷模塊。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6c1e94b1ed2ff2b756730b38b6692cc9a45.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-4c09032ee8c8df89a48e7f3fcc75f473657.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">官方已開通免費 30 天試用</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">立即體驗 ZadigX 最新版本，開啓全新平台工程</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">創新之旅！🚀</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">&nbsp;<span style="background-color:#ffffff; color:#ff2968">ZadigX，開放，鏈接，專業</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px"><img src="https://oscimg.oschina.net/oscnet/up-737521b788156c5c0d8468b2e564baa99a6.png" referrerpolicy="no-referrer"></p><blockquote><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px"><strong>閲讀原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNLnTwZQ-kEhEk7hw6ZRM_w" target="_blank">https://mp.weixin.qq.com/s/NLnTwZQ-kEhEk7hw6ZRM_w</a></strong></p></blockquote><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 02:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/10115118</guid>
            <link>https://my.oschina.net/koderover/blog/10115118</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
    </channel>
</rss>
