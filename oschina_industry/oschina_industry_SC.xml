<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 29 Oct 2023 07:38:31 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Next.js 支持在前端代码中写 SQL，开倒车还是遥遥领先？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>下面这张图来自近日举办的&nbsp;Next.js Conf 2023，里面的代码使用了名为<strong>「Server Actions」</strong>的特性——在前端代码中使用 SQL 语句直接操作数据库。</p><p><img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-e254f1c847ae20e8c530b34f9021da3a4d0.png" width="400" referrerpolicy="no-referrer"></p><p>在最新发布的 Next.js 14 中，Server Actions 已到达稳定阶段。其团队表示，Server Actions 改进了开发者在编写数据变更方面的体验。</p><p>Server Actions 允许开发者定义异步服务器函数，他们可以使用 Server Actions 重新验证缓存数据、重定向到不同的路由、设置和读取 cookie 等等。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-77eb78e36979830a06c1f44ed2476bb4db1.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0ad921306554c0716b4b4b0a8bedb71b8ba.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-badb8152ef443eb8272d03c220e0450c723.png" referrerpolicy="no-referrer"></p><p>不过目前看来，大多数人对它的评价似乎并不太好 ——</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1029/122449_wEe4_2720166.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 04:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263921</guid>
            <link>https://www.oschina.net/news/263921</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux Mint]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>Linux Mint 团队在最新月度报告中<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.linuxmint.com%2F%3Fp%3D4591" target="_blank">提到</a></u>，他们已经开始着手开发对 Wayland 的支持。</p><p>团队称这项工作是他们在很长一段时间内必须面对的主要挑战之一，虽然他们不期待 Wayland 能很快取代 Xorg 作为默认值，无论是在 21.3 中，还是在 22.x 中，但仍然希望做好准备。</p><p>按照计划，Cinnamon 6.0 计划在今年的 Mint 21.3 中推出，<strong>并将提供实验性的 Wayland 支持</strong>。用户可以从登录界面在默认 Cinnamon 会话（在 Xorg 上运行）和 Cinnamon on Wayland 之间进行选择。</p><p>下图是 Cinnamon on Wayland 的运行截图：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-21b9daccab538fe5909df6cef6b172695f5.png" referrerpolicy="no-referrer"></p><p>Linux Mint 团队表示，他们可能在 2026 年实现对 Wayland 的稳定支持/默认支持。鉴于 Linux Mint 坚持以 Ubuntu LTS 为基础，因此并不指望在 Ubuntu 24.04 LTS 之前就能支持 Wayland。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 28 Oct 2023 04:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263917/linux-mint-wayland-progress</guid>
            <link>https://www.oschina.net/news/263917/linux-mint-wayland-progress</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国外物价高，6 美元只能买 50 个 GitHub stars]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>《Wired》杂志发表文章<em>"<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wired.com%2Fstory%2Fgithub-stars-black-market-coders-cheat%2F" target="_blank">The GitHub Black Market That Helps Coders Cheat the Popularity Contest</a></u>"</em>，介绍了交易 GitHub Stars 的地下黑市。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1028/161939_TSqR_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>GitHub 平台托管项目的受欢迎程度能够为部分程序员和创业公司打开一扇大门，他们通过 Stars 获得关注度、影响力和声誉。然而地下黑市出售的 Stars 提供了」以假乱真「的方式来让他们进行作弊。这些虚假 Stars 在某种程度上能帮助程序员和创业公司在联络投资人或找工作时留下好印象。</p><p>据介绍，在交易 GitHub Stars 的平台上，支付价值&nbsp;6 美元的以太币即可购买 50 个 Stars。除了 Stars，其他可量化的指标——如 Forks、Watchers 和 Follower 也可单独或组合购买。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://static.oschina.net/uploads/space/2023/1024/174616_4UDX_2720166.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em>via<span>&nbsp;</span><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaddhi.shop%2Fproduct%2Fbuy-github-followers%2F" target="_blank">https://baddhi.shop/product/buy-github-followers/</a></u></em></p><p>文章写道，此前初创公司、程序员和投资者在决定雇用谁、为谁工作或投资谁时，会使用这些指标来筛选有潜力的程序员和初创公司。</p><p>但真正决定成功的不仅是这些指标，投资者开始意识到这种评估方式并不可靠，正在改变对 GitHub Stars 等指标的依赖，GitHub 平台也在打击这些专门用于刷数据的虚假账号。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 10:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263862/github-stars-black-market-coders-cheat</guid>
            <link>https://www.oschina.net/news/263862/github-stars-black-market-coders-cheat</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[《2023 年三季度互联网投融资运行情况》研究报告发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">中国信息通信研究院政策与经济研究所互联网运行分析团队于日前，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FxZbTT8DZ0Q79-2RGTXhFbg" target="_blank">发布</a>了《2023 年三季度互联网投融资运行情况》报告。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">报告构建了互联网行业投融资研究框架，借助 CB Insights 数据库，深入挖掘我国和全球行业投融资整体态势及重点领域情况，为行业趋势预测、热点问题预判提供重要参考。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">本季要点：</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>1.&nbsp;</strong><strong>我国互联网投融资略有反弹。</strong>2023Q3，我国互联网投融资规模企稳，案例数环比下跌 5.8%，同比下跌 54%；披露的金额环比上涨 34.7%，同比下跌 36.4%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>2.<span>&nbsp;</span></strong><strong>全球互联网投融资继续下探。</strong>2023Q3，全球互联网投融资案例数环比下跌 5.1%，同比下跌 23.4%；披露的金额环比下跌 15.5%，同比下跌 28.8%。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>3.</strong><strong>企业服务融资占比保持领先。</strong>2023Q3，我国企业服务领域融资案例数占比 25.7%，融资金额占比 26%；全球企业服务领域融资案例数占比 21.3%，融资金额占比 19.8%。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>报告全文：</span></p><p><img height="3587" src="https://oscimg.oschina.net/oscnet/up-ee666d0691d7989a2ff66c9cfbe80f422d2.png" width="500" referrerpolicy="no-referrer"></p><p><img height="2012" src="https://oscimg.oschina.net/oscnet/up-2d7d99c36f9f1ebf6569235631c9a3771cd.png" width="500" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.caict.ac.cn%2Fkxyj%2Fqwfb%2Fqwsj%2F202310%2FP020231027488865727077.pdf" target="_blank">报告全文下载</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 06:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263690</guid>
            <link>https://www.oschina.net/news/263690</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米 14 开机动画显示澎湃 OS 基于 Android]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>小米 14、澎湃 OS 等一大波新品已经正式登场<strong>。澎湃 OS 发布前，不少人都争论，它不是小米自研的系统，对此雷军还特意表示，确实不是。</strong></p><p>小米的澎湃 OS 由两部分组成：一部分是基于安卓系统进行深度进化的，这使得澎湃 OS 可以与安卓系统保持同步，并且能够使用安卓软件。</p><p>另一部分则是小米自研发的 Vela 系统，主要用于实现小米产品之间的互联互通。</p><p>这种系统架构使得澎湃 OS 能够兼顾兼容性和自主性，既满足了用户对丰富应用的需求，又能够提供更好的硬件软件一体化体验。</p><p><strong>发布会后，有网友从现场展示的新机看到，小米澎湃 OS 开机页面动画还是和以前一样，也有显示 "Powered by android"，这也算是证实了雷军之前的说法。</strong></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4b428f25973338129e02686c3a80ff9faf1.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 05:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263829</guid>
            <link>https://www.oschina.net/news/263829</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 CCF 中国开源大会开源商业化分论坛顺利召开]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p>10 月 21 日至 22 日，由中国计算机学会（CCF）、开放原子开源基金会主办的 2023 CCF 中国开源大会在长沙顺利举行。其中，开源商业化分论坛由开源中国承办，开源中国董事长马越担任主席。来自开源原生商业公司的诸多专家就开源项目商业化最佳实践展开分享，为更多开发者和企业提供可借鉴的经验，共同推动开源生态建设，助力开源生态发展。</p><p><strong>开源中国董事长马越</strong>以《中国开源商业发展的现状及思考》为题发表主旨演讲。他指出，当前开源创业公司有「七大恨」：没有品牌、没有流量、没有销售能力、没有资质、没有交付能力、没有现金流、没有资本渠道。这些都严重阻碍了创业公司进一步发展壮大。而解决开源创业公司「七大恨」的关键就在于开源创业联合体。所谓开源创业联合体，就是提供通用服务模型的价值流平台，实现集成和自动化 IT 价值链的插件开放平台，融合市场各类开源或商业生态能力，落地客户场景服务。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-729f0faa336b257003127266ac12c4b722d.png" width="800" referrerpolicy="no-referrer"></p><p>最后马越提议，希望能够集众多开源力量共建这样的插件开放平台，繁荣开源商业生态，互通有无。开源中国已积累了十几年的商业化经验以及商业化能力，旗下 Gitee 平台也已经入驻了 27 万多家中小团队，服务中国 600 多家 100 亿元估值以上的大企业。未来，开源中国将通过该插件平台将这些经验和能力赋能更多开源企业。</p><p><strong>CCF 开源发展委员会常委谭中意</strong>就 「AI to B 的开源和商业化」这两大方向展开探讨。谭中意认为，当前 LLM to B 业务的难点在于，需要找到一个 Killer 场景——有足够的商业回报，能覆盖大模型 Finetune 和 Serving 以及 LLM 应用开发和运维的成本。但是 LLM 技术存在先天上的约束：一是无法避免幻觉的问题，To C 业务需要满足网信办规定，合规成本很高；二是无法避免概率的问题，To B 的严肃场景可能不太适合。因此，突破口可能在于：一是企业内部，对生成内容更讲究创意或者实时 Check 的场景，比如内部研发代码生成工具、游戏行业的场景；二是电商领域，比如促销、广告投放等，因为这是离钱最近的潜力市场，且容易形成数据闭环。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-cf8531b4308c6c6399ab200699cb0ef9b7d.png" width="800" referrerpolicy="no-referrer"></p><p>至于开源在 LLM 产业的关键作用，主要有两个：一是降低成本，开源是降低整个产业创新成本的关键，即 AI 民主化。这需要整个学术界和产业界一起努力，来把成本降下来，而且开源底座模型是整个大生态最重要部分；二是建立信任，人工智能要让人信任，它必须公开透明。一旦这个问题解决了，一个十万亿规模的市场可能起飞。</p><p><strong>PingCAP 副总裁刘松</strong>分享了 TiDB 从开源到 Serverless 的商业化演进逻辑。据其介绍，PingCAP 的商业化之路可以总结为「四部曲」：创建一个满足时代刚需的开源项目，开源产品获得规模化的用户部署与反馈，打造一个全球化的商业化模式，持续创造满足极致用户需求的产品形态。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-c12ba68303c5e846f95912614c315de728c.png" width="800" referrerpolicy="no-referrer"></p><p>刘松表示，面对「开源 + 云」互相推动和演进的新技术环境，TiDB 演进方向从技术领先走向了「技术+体验」领先。当前，PingCAP 围绕 TiDB 构建了三大产品形态：TiDB 企业版、TiDB Cloud（全托管）、TiDB Cloud Serverless。其中，TiDB Cloud 提供全托管的 DBaaS （Database-as-a-Service）服务，极大地降低了云数据库的使用门槛；TiDB Cloud Serverless 基于云原生/多云的设计，采用 AI-Ready 的架构，实现极致低成本、极致弹性，拥有自动化的资源调度能力以及灵活集成 AI 能力等特性。</p><p><strong>统信软件解决方案中心专家任紫东</strong>以《中国开源操作系统商业发展探索》为题展开分享。任紫东认为，2020 年是国产 Linux 里程碑之年。2019 年前，我国有 10 多家国产操作系统企业，随着政策引导和市场竞争战略的选择，国产操作系统厂商进行了全新的业态整合，2020 年起，初步形成两家主流国产操作系统企业，统信就是其中之一。及至 2022 年，产业链的商业形态形成。头部操作系统公司规模也呈现「干百十」特征：千人以上的操作系统开发队伍，百人以上的内核研发团队，十人以上的开源合规律师团队。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-d9d35f21d4f87673628b2337118d6fb42dc.png" width="800" referrerpolicy="no-referrer"></p><p>当前，统信 UOS 生态是国内最大的自主操作系统生态圈之一。统信己基于服务器操作系统完成诸多主流国外商业软件的适配，涵盖了 Oracle、IBM、SAP、微软等厂商的主流数据库产品，Google、FaceBook、百度、华为等厂商的主流 AI 人工智能类产品，以及 Oracle、IBM 等厂商的主流中间件产品。</p><p>开源社区做得好，怎么变成钱？在以《白鲸 DataOps 开源矩阵商业化之路》为题的演讲中，<strong>白鲸开源 CEO 郭炜</strong>提到，白鲸花了 8 个月时间，摸索了一套开源商业转化流程，积累数千万的商业 Pipeline 以及上百个线索，而投入资源不过是一名销售人员，没有任何市场费用。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-c3550e7f84e4a38252e13b77a70f32bcd94.png" width="800" referrerpolicy="no-referrer"></p><p>郭炜把这些成果归结于几大原则：「别人做中石油，我做中石化」，即做所有人的朋友；开源项目定位要清晰，商业功能痛点要明确，因此白鲸开源采取了「开源矩阵+OpenCore」的路线；开源商业软件要重视「行业属性」，分行业洞察痛点，口碑营销；不忘初心，牢记使命，不断升级开源版，商业版才有机会；勇于探索，拥抱新技术，将大模型融入软件，等等。</p><p>最后他提到，开源风口并没有过去，而且温度刚刚好。面对经济下行周期、资本趋于冷静以及收入体量要求更高等挑战，也应看到行业展现出来更多的机会，比如恶性竞争减少，互联网公司开始付费买工具，订阅制更容易被接受，海外市场逐步增长等等。</p><p><strong>TDengine 联合创始人&amp; 商业化 VP 李广</strong>分享了 TDengine 是如何从开源时序数据库到工业大数据处理平台的。他表示，一款软件开源，就意味着可信、可控。TDengine 的商业逻辑就是重塑 2B 销售模式，以开源建社区与品牌，以开源建 GTM 路径。通过开源扩大影响力，树立品牌，形成开发者社区，构建竞争壁垒，快速获得市场反馈，快速迭代，快速打造生态，获得用户信任。另一方面，将传统的 2B 销售演变为 2C 的模式，将传统的登门拜访演变为线上销售，将资源型销售转化为技术和产品型销售。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-a48a9ecbd7606788031401fba0b8a83267d.png" width="800" referrerpolicy="no-referrer"></p><p>当前，TDengine 提供三种产品与服务，一是开源社区版——TDengine OSS，主要是为了建立开发者社区，建立生态；二是企业版——TDengine Enterprise，支持独立部署并按照 TBL（Term Based License）年度服务订阅或者永久 Licenese 模式销售；三是云服务版——TDengine Cloud，在阿里云、AWS、华为云等云平台上直接提供 SaaS 服务，根据数据量和时长计费。</p><p>最后他表示，开源软件的商业化逻辑已经发生了变化，从关注增长转向强调利润。2B 软件群龙纷争的时代结束，只有深入行业黑土地才能生存。</p><p><strong>筑栈（KodeRover / Zadig）创始人 &amp; CEO 李倩</strong>分析了公司为什么选择深耕中国而不是出海。据悉，在商业化过程中，KodeRover 也面临过不少问题，比如花了时间打磨产品，但用户付费意愿不强烈；有需求有预算的大客户找上门，却因为自身团队规模过小无法为其提供大型服务等等，不过 KodeRover 最终也地制定了相应策略。李倩将公司的商业化思路总结为：技术上用开源铸造好基建，打造产品力、品牌力；商业上，中国场景助力「新 IT」 （比如硬科技创新、旧行业升级重整）升级，创造客户价值；可持续创造价值，广泛链接，为客户提供最优质的解决方案。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-e0510f159c4ed52d504290463b06b22c059.png" width="800" referrerpolicy="no-referrer"></p><p>李倩提到，Zadig 是生产软件的软件，目的是交付数字业务。 Zadig 开源两年，企业安装总量近 3 万，目前是国内云原生 DevOps 领域落地最广泛的平台，成为包括字节飞书、极氪、路特斯、小鹏、七牛云、WiFi 万能钥匙、易快报、iMile、TT 语音、锅圈、药师帮、大参林、老百姓大药房、 益丰大药房、小天才等标杆企业的数千家企业研发工程师每日深度、高频使用的软件交付平台。</p><p><strong>EMQ 映云科技联合创始人兼 CPO 金发华</strong>以《EMQ —— 开源数实融合基础软件的商业化》为题发表演进。据了解，作为全球领先的物联网基础软件提供商，EMQ 创立并主导 LF Edge eKuiper、NanoMQ、Neuron 等多个全球知名边缘软件开源项目。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-086857ea6bb66926b0c38eb9fb66172ceae.png" width="800" referrerpolicy="no-referrer"></p><p>金发华表示，Hosting(Cloud) 模式是未来产品的一个方向。当前，EMQ Cloud 商业服务有三种。一是 Serverless，轻松几步即可获得一个安全可伸缩的 ServerlessMQTT 服务。全托管特性让用户无需关心基础设施和资源管理，特别适用于个人开发者、中小型项目、开发测试环境以及技术框架的评估。二是专有版，独立部署的全托管 MQTT 服务，具有更高的性能保障和可定制能力，尤其适用于对性能、稳定性要求较高的企业级项目。三是 BYOC (Bring Your Own Cloud)，用户在自己的云上部署 EMQX 集群,并交由 EMQX 团队托管，适用于有严格数据安全和合规性要求的企业级项目，最大限度地利用现有的云资源。</p><p><strong>天际科技投资副总裁江志桐</strong>阐述了开源与 AI 时代下的投资逻辑。她表示，在 AI 2.0 时代，从全球市场来看，基于大模型未来增长预期，资本给予显著溢价。当前通用模型格局明确，出现了微软、谷歌双龙头企业，工具层、应用层、垂直领域涌现大量独角兽。全球市场都在关注大模型商业化的落地，围绕效率、创意、情感陪伴 2C/2B 的应用生态繁荣。</p><p style="text-align:center"><img height="533" src="https://oscimg.oschina.net/oscnet/up-d423c2f9a083841554cb3cea84bb20c4056.png" width="800" referrerpolicy="no-referrer"></p><p>与此同时，开源正在加速 AI 2.0 落地，加速 AI 生态繁荣。开源是大模型基础设施必然选择，延伸出的服务、应用具有巨大商业机会。AI 开源时代的投资策略以核心人物为中心，布局早期，发挥产业资源优势，关键人物、网络效应、稀缺数据，以及软硬一体都有可能成为企业护城河的因素，也是 AI 开源时代投资重点。</p><p>那么中国市场的机会在哪里呢？江志桐认为，主要在于两方面，一是基础设施，二是垂直行业。国内大模型的应用还在快速成长，基于开源加速模型落地后，整个 AI 生态里面也会出现能够对标全球市场的公司。总之，国内 AI 市场还处于巨头形成的阶段。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10136947</guid>
            <link>https://my.oschina.net/u/3859945/blog/10136947</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[智谱 AI 推出第三代基座大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>2023 年 10 月 27 日，智谱 AI 于 2023 中国计算机大会（CNCC）上，推出了<strong>全自研的第三代基座大模型 ChatGLM3</strong>及相关系列产品。</p><p><img height="281" src="https://static.oschina.net/uploads/space/2023/1028/102320_GQzP_2720166.jpg" width="500" referrerpolicy="no-referrer"></p><p>以下汇总摘录自官方公告：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSVq458IhrR2GGezA9goumw" target="_blank">https://mp.weixin.qq.com/s/SVq458IhrR2GGezA9goumw</a></u></p><hr><h4><strong>全新技术升级</strong></h4><p><strong>1. 更强大的性能：</strong></p><p>今年以来，这是我们第三次对 ChatGLM 基座模型进行了深度优化。我们采用了独创的多阶段增强预训练方法，更丰富的训练数据和更优的训练方案，使训练更为充分。</p><p>评测显示，与 ChatGLM 二代模型相比，在 44 个中英文公开数据集测试中，ChatGLM3 在国内同尺寸模型中排名首位。其中，MMLU 提升 36%、CEval 提升 33%、GSM8K 提升 179% 、BBH 提升 126%。</p><p><strong>2. 瞄向 GPT-4V 的技术升级：</strong></p><p>瞄向 GPT-4V，ChatGLM3 本次实现了若干全新功能的迭代升级，包括：</p><p><strong>多模态理解</strong>能力的 CogVLM，看图识语义，在 10 余个国际标准图文评测数据集上取得 SOTA；</p><p><strong>代码增强</strong>模块 Code Interpreter 根据用户需求生成代码并执行，自动完成数据分析、文件处理等复杂任务；</p><p><strong>网络搜索增强</strong>WebGLM，接入搜索增强，能自动根据问题在互联网上查找相关资料并在回答时提供参考相关文献或文章链接。</p><p>ChatGLM3 的<strong>语义能力与逻辑能力</strong>大大增强。</p><p><strong>3. 全新的 Agent 智能体能力：</strong></p><p>ChatGLM3 本次集成了自研的 AgentTuning 技术，激活了模型智能体能力，尤其在智能规划和执行方面，相比于 ChatGLM 二代提升 1000%；开启国产大模型原生支持工具调用、代码执行、游戏、数据库操作、知识图谱搜索与推理、操作系统等复杂场景。</p><p><strong>4. Edge 端侧模型：</strong></p><p>ChatGLM3 本次推出可手机部署的端测模型 ChatGLM3-1.5B 和 ChatGLM3-3B，支持包括 Vivo、小米、三星在内的多种手机以及车载平台，甚至支持移动平台上 CPU 芯片的推理，速度可达 20 tokens/s。</p><p>精度方面 ChatGLM3-1.5B 和 ChatGLM3-3B 在公开 Benchmark 上与 ChatGLM2-6B 模型性能接近。</p><p><strong>5. 更高效推理/降本增效：</strong></p><p>基于最新的高效动态推理和显存优化技术，我们当前的推理框架在相同硬件、模型条件下，相较于目前最佳的开源实现，包括伯克利大学推出的 vLLM 以及 Hugging Face TGI 的最新版本，推理速度提升了 2-3 倍，推理成本降低一倍，每千 tokens 仅 0.5 分，成本最低。</p><h4><strong>新一代「智谱清言」上线</strong></h4><p>在全新升级的 ChatGLM3 赋能下，生成式 AI 助手智谱清言已成为国内首个具备代码交互能力的大模型产品（Code Interpreter）。</p><p>传送门：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchatglm.cn%2Fmain%2Fcode" target="_blank">https://chatglm.cn/main/code</a></u></p><p><img src="https://static.oschina.net/uploads/space/2023/1028/102833_nbbu_2720166.png" referrerpolicy="no-referrer"></p><p>在这一能力的加持下，ChatGLM3 可支持图像处理、数学计算、数据分析等使用场景。以下分别为：</p><p><strong>处理数据生成图表</strong></p><p><img src="https://static.oschina.net/uploads/space/2023/1028/102853_C5gK_2720166.png" referrerpolicy="no-referrer"></p><p><strong>画图</strong></p><p><img src="https://static.oschina.net/uploads/space/2023/1028/102920_iPm4_2720166.png" referrerpolicy="no-referrer"></p><p><strong>上传 SQL 代码分析</strong></p><p><img src="https://static.oschina.net/uploads/space/2023/1028/102938_Bkdu_2720166.png" referrerpolicy="no-referrer"></p><p>随着 WebGLM 大模型能力的加入，智谱清言现具有搜索增强能力。智谱清言可以帮助用户整理出相关问题的网上文献或文章链接，并整理出答案。</p><p><img src="https://static.oschina.net/uploads/space/2023/1028/102955_TE2Q_2720166.jpg" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1028/103014_ein5_2720166.png" referrerpolicy="no-referrer"></p><p>CogVLM 模型则提高了智谱清言的中文图文理解能力，取得了接近 GPT-4V 的图片理解能力。它可以回答各种类型的视觉问题，并且可以完成复杂的目标检测，并打上标签，完成自动数据标注。</p><p><img src="https://static.oschina.net/uploads/space/2023/1028/103030_N8vg_2720166.png" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1028/103042_fWLm_2720166.jpg" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1028/103052_suIU_2720166.jpg" referrerpolicy="no-referrer"></p><hr><p>据介绍，自 2022 年初，智谱 GLM 系列模型已支持在升腾、神威超算、海光 DCU 架构上进行大规模预训练和推理，当前已支持 10 余种国产硬件生态，包括升腾、神威超算、海光 DCU、海飞科、沐曦曦云、算能科技、天数智芯、寒武纪、摩尔线程、百度昆仑芯、灵汐科技、长城超云等。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 27 Oct 2023 02:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263818</guid>
            <link>https://www.oschina.net/news/263818</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[扎克伯克：Meta 明年投入更多工程和计算资源到 AI 领域]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>当地时间 10 月 25 日，在 2023 财年第三季度财报电话会上，Meta CEO 扎克伯格强调，相信生成式 AI 的相关技术将让人们使用各种应用程序的方式变得更有意义。在未来，Meta 甚至有可能会利用 AI 来根据用户的兴趣为他们直接生成内容。</p><p>扎克伯格表示，AI 将帮助使用 Meta 各大应用的创作者提升内容质量和生产效率，而随着时间的推移，AI 参与生成的内容在用户消费内容中的占比将会越来越大。</p><p>对于公司的后续发展，扎克伯格表示在 2024 年，<strong>就工程和计算资源而言，AI 将成为 Meta 最大的投资领域</strong>。此外，扎克伯格补充道，为了避免引入大量的新员工，<strong>公司将降低一些非 AI 项目的优先级，并将相关人员转向从事 AI 工作</strong>。</p><p>上月曾报道过，<u><a href="https://www.oschina.net/news/257670/meta-building-llm-rival-openais-gpt4">Meta 正在构建</a></u>新开源大模型，据称性能超越 Llama 2、比肩 GPT-4，最终目标是加速开发下一代生成式人工智能模型，使其能够生成更多类似人类的表达。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0911/152426_g2gp_2720166.png" referrerpolicy="no-referrer"></p><p>长期以来，Meta 一直在采用开源方法公开其大模型产品，是业内众所周知的最大贡献者之一。仅今年它就向人工智能社区发布了大量人工智能模型和训练数据集。其中包括针对编程任务优化的 Code Llama 大语言模型； 可实现数百种语言通用按需翻译的 SeamlessM4T 模型； 用于创作音乐和声音的生成式人工智能模型 AudioCraft；语音生成人工智能模型 Voicebox。它还推出了 I-JEPA（一种可以像人类一样学习的计算机视觉模型）和 FACET（一种基准数据集，旨在帮助研究人员审核计算机视觉模型的偏差）。</p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/256830/meta-ai-belebele">Meta AI 多语言阅读理解数据集 Belebele，涵盖 122 种语言变体</a></li><li><a href="https://www.oschina.net/news/255350/meta-code-llama">Meta 开源基于 Llama 2 的 AI 代码生成大模型：Code Llama</a></li><li><a href="https://www.oschina.net/news/255168/meta-seamless-m4t">Meta 推出&nbsp;SeamlessM4T，可转录和翻译近 100 种语言</a></li><li><a href="https://www.oschina.net/news/252174/audiocraft-generative-ai-for-music-and-audio">Meta 发布开源 AI 工具 AudioCraft，文本自动生成音乐</a></li><li><a href="https://www.oschina.net/news/249944/meta-llama-2">Meta 放大招：发布开源大语言模型 Llama 2，可免费商用</a></li><li><a href="https://www.oschina.net/news/245895/meta-voicebox-generative-ai-model-speech">Meta 发布语音生成 AI 模型：Voicebox</a></li><li><a href="https://www.oschina.net/news/245705/meta-musicgen">Meta 开源音乐生成模型 MusicGen</a></li><li><a href="https://www.oschina.net/news/242331/mate-multilingual-model-speech">Meta 开源大模型：支持 4000+ 语言识别，1100+ 种语音文本转换</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 09:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263757</guid>
            <link>https://www.oschina.net/news/263757</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 24.04 进入开发阶段，代号 Noble Numbat]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">Canonical 的 Utkarsh Gupta 在一封发送给 Ubuntu 开发邮件列表的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.ubuntu.com%2Farchives%2Fubuntu-devel%2F2023-October%2F042835.html" target="_blank">电子邮件中宣布</a>，Ubuntu 24.04 现已开放供开发，并透露了该版本的代号为「Noble Numbat」。</span></p><blockquote><p><span style="color:#000000">我们很高兴地宣布，Noble Numbat 现已开放开发。自动同步已启用，并将很快运行。和往常一样，我们预计在初始阶段会有大量的构建和自动测试涌入，这将导致一些延迟现象的出现。请协助修复出现的任何故障。</span></p></blockquote><p><span style="color:#000000">根据百度百科，Numbat（袋食蚁兽）是分布于澳大利亚西南部的一种小型有袋动物，几乎只以白蚁为食，每天可以吃约 20000 只白蚁。目前仅在少数地区存活，属于濒危物种，已被列入《世界自然保护联盟濒危物种红色名录》。袋食蚁兽的体型小而吻长，牙齿多达 52 枚，超过任何陆生哺乳动物的齿数，齿细，排成长列，长而能伸的舌（长约 10 厘米），用以捕捉白蚁。</span></p><p><span style="color:#000000"><img alt="" height="286" src="https://oscimg.oschina.net/oscnet/up-050f5f99cc77c3757686112b409fb2558f7.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Ubuntu 24.04 将是 Ubuntu 自 2006 年以来的第 10 个 LTS 版本。Ubuntu 的 LTS 版本将获得 5 年的安全更新、错误修复和精选应用程序更新。Ubuntu Pro 则会在此基础上额外增加 5 年的安全保障，为现代的 LTS 版本提供了长达十年的支持。</span></p><p><span style="color:#000000">目前对于 Ubuntu 24.04 中将包含的新功能和改进仍然知之甚少。但 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F10%2Fubuntu-24-04-development-open" target="_blank">OMG! Ubuntu</a> 指出，对于长期支持版本而言，Ubuntu 在主要新功能、用户界面的巨大变化等方面往往会比较保守，主要会更加专注于坚实、稳定的体验。</span></p><p><span style="color:#000000">可以确定的是，24.04 肯定会配备新的 Linux 内核（6.7 或 6.8，视时间而定）、GNOME 46（预计将在三月份发布）。Canonical 的 Oliver Grawert 还透露，一个不可变的、snap-based Ubuntu 24.04 镜像将于 4 月份提供下载（但不会是默认推荐下载）。</span></p><p><span style="color:#000000">Ubuntu 24.04 计划于 2024 年 4 月 25 日正式发布。其功能冻结阶段定于 2024 年 2 月 29 日，beta 版本计划于 2024 年 4 月 4 日发布。</span></p><p><img height="501" src="https://oscimg.oschina.net/oscnet/up-78523d04d02ccf21bda56aa13e0dcd0b317.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">可在此查看具体的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fnoble-numbat-release-schedule%2F35649" target="_blank">发布时间表</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 09:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263754/ubuntu-24-04-noble-numbat</guid>
            <link>https://www.oschina.net/news/263754/ubuntu-24-04-noble-numbat</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[3202 年了，为啥 SSR 并没有预想中的流行？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div><p style="text-align:left">有研究发现，网站加载时间每增加一秒，用户便会流失 10%。为提高页面的秒开率，各路人马不断探索着优化策略，仅仅在浏览器领域下的优化已经满足不了极致的要求了，大家开始往服务端方向不断探索，并一度让【服务端渲染】这一古早的概念「翻红」，且炒得火热。</p><p>服务端渲染简称 SSR，全称 Server Side Rendering，顾名思义是将渲染的工作放在 Server 端进行。这种办法不仅有利于首屏渲染，提高 SPA 应用的首屏响应速度，还方便搜索引擎抓取，有利于 SEO 优化。不过，到 2023 年了，SSR 并没有预想中的流行。</p><p>有评论认为，大部分用 SSR 的原因是为了服务 SEO，但现在搜索引擎已经跟上发展步伐了，对于用框架写成的 SPA 支持也不错，所以 SSR 必要性没那么大了。还有人觉得 SSR 就是伪需求，业务逻辑和控制器分离好了加载一样快。</p><p>但也有评论认为，现在仍然有大量的用户因为网络环境或设备情况，在访问 Web 页面的时候无法达到很好的体验，如果要提升这部分用户的体验，那么 SSR 就是一种不可或缺的方式。</p><p style="text-align:left">对此，真实的情况是怎样的？实际应用中，阻碍 SSR 成为 Web 主流开发模式的原因是什么？这种方法放到今天的环境下过时了吗？什么样的业务场景更适合 SSR 呢？对此，开源中国邀请了两位前端大佬，来听听他们的看法。</p><ul><li><p><span style="color:#245bdb">刘奎，社区暱称 kuitos 。支付宝体验技术部前端工程师，开源微前端方案 qiankun 作者，目前在蚂蚁负责 Web 基建研发相关工作。</span></p></li><li><p><span style="color:#245bdb">刘勇，社区暱称天猪，某大厂 Node.js </span><span style="color:#245bdb">Infra</span><span style="color:#245bdb"> 负责人，EggJS / CNPM 核心开发者。</span></p></li></ul><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>一、SSR，并不是伪需求</h1><p><span style="color:#245bdb"><strong>Q1：以你的经验，什么类型的项目和场景更常用 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> ？能举些例子吗？</strong></span></p><p><strong>刘奎：</strong>对首屏性能非常敏感，或者对 SEO 有强诉求的这类网站会更常用 SSR，如：</p><ul><li><p>电商平台：更快的首屏渲染可以让用户更快的看到商品信息，提升购买转化率</p></li><li><p>营销活动页：秒开能有效提升营销活动的业务效果</p></li><li><p>门户网站：内容型站点通常对 SEO 有着比较强的诉求</p></li></ul><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q2：从你的实际体验出发，你觉得 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 相比于 </strong></span><span style="color:#245bdb"><strong>CSR</strong></span><span style="color:#245bdb"><strong>（</strong></span><span style="color:#245bdb"><strong>Client-side rendering</strong></span><span style="color:#245bdb"><strong>）模式，优势在哪？</strong></span></p><p><strong>刘奎：</strong>从我个人体验来看，最大的优势还是在首屏体验上，SSR 模式下 HTML 加载过程中用户就能看到有效的页面内容，这个基本是 CSR 很难做到的。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q3：如今</strong></span><span style="color:#245bdb"><strong>搜索引擎</strong></span><span style="color:#245bdb"><strong>已经支持渲染了，你认为还有必要因为 </strong></span><span style="color:#245bdb"><strong>SEO</strong></span><span style="color:#245bdb"><strong> 的原因使用 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 吗？</strong></span></p><p><strong>刘奎：</strong>由于众所周知的原因，国内的搜索引擎对 SPA 类型的应用支持的并不好，如果希望自己的网站能更好的被爬虫索引到，基本上还是需要使用 SSR（或者 SSR 的变种）方案了。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q4：有人认为 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 是伪需求，要改善首屏渲染性能的话，后端服务的业务逻辑和控制器分离，控制器分视图控制器和接口控制器，调用相同的业务逻辑。第一次打开页面，前端 </strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong> 加载页面渲染的数据，用户交互时再请求接口获取数据。这个方案比性能着急的 SSR 强多了。你怎么评价？</strong></span></p><p><strong>刘奎：</strong>这个方案本质还是 CSR，无法解决 CSR 方案原生的问题：即用户必须等到 JS 下载完成 -&gt; 发起接口请求 -&gt; JS 获取数据渲染页面之后，才能看到有效内容的问题。在越苛刻的网络环境及用户设备条件下，这个问题会越明显。</p><p><strong>刘勇：</strong>根据团队的基建成熟度和业务场景做技术选型，这 2 个方案没有绝对的优劣，也不是绝对的割裂，它们是可以通过前端工程化结合成一个方案的。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>二、SSR，想红有点难</h1><p><span style="color:#245bdb"><strong>Q5：以当前的形势来看，</strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 并没能成为 Web 主流的开发模式，你觉得这其中的阻碍有哪些？</strong></span></p><p><strong>刘奎：</strong>我觉得主要有这几类原因：</p><ul><li><p><strong>技术复杂度：</strong>SSR 需要在服务器端进行渲染，并与前端框架进行集成，对开发人员来说需要掌握更多的技术知识。</p></li><li><p><strong>SSR</strong><strong> 带来的额外的开发及维护成本：</strong>相对于 CSR，SSR 方案需要前端额外去关注服务端相关的开发及运维，比如如何写出更高性能的服务端渲染逻辑，如何处理潜在的内存泄露、变量污染等隔离问题，如何做 SSR 的容灾（在 SSR 失败时 fallback 到 CSR）等，这些都需要团队有额外的资源及时间投入。</p></li><li><p><strong>场景匹配度：</strong>国内大量的服务是通过小程序、APP 这类载体进行分发的，纯 Web 技术栈的产品相对较少，这点与国外的场景有着非常大的不同。</p></li></ul><p><strong>刘勇：</strong>首先，SSR 是需要服务器资源成本的，在降本提效的大背景下，会需要结合 Serverless 或边缘计算等一些基建才能找到平衡点。同时既然是服务端，就有一定的运维能力要求，对前端团队的技术积累有一定的要求。</p><p>其次，框架的封装和维护如果做的不好的话，业务同学写 SSR 很容易弄出内存泄露问题，这是非常常见的。而且目前的前端框架还没有针对 SSR 场景进行优化，如果只是首屏展示快，但紧接着要下载超大的 Bundle 文件，从而用户可交互时间太慢，就得不偿失了。</p><p>最后，演进路径问题，譬如蚂蚁那边，他们当年就已经跟把离线包的上下游基建都做的很完善了，APP 侧、网络侧都有兄弟团队配合一起打磨。这种模式会有一些缺陷，如离线包太多时的业务竞争问题，但就首屏性能这一点上，SSR 不一定比它好多少，这时候让他们切换到 SSR 就会有不小的阻力。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q6：有评论认为 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 开发和维护成本太高了，转而投向了 </strong></span><span style="color:#245bdb"><strong>CSR</strong></span><span style="color:#245bdb"><strong> 的怀抱。CSR 能否取得跟 SSR 一样的效果呢？有什么具体的操作方案吗？</strong></span></p><p><strong>刘勇：</strong>从首屏性能的关键点看，CSR 如果不做一定的优化的话，至少 3 次串行的 HTTP 请求，首屏时间肯定比不过 SSR（互操作时间就不一定）。</p><p>不过相应的解决方案也挺多的，如 ServiceWorker、离线包等等方式。</p><p><strong>刘奎：</strong>单从首屏渲染速度这一点来看，CSR 想取得 SSR 类似的效果，可以采取以下方案优化：</p><ol><li><p><strong>首屏页面静态资源优化：</strong>通过代码切割 &amp; 懒加载等手段，确保首屏需要的 JS/CSS 是最小化的版本，并通过内联等方式直接打到 HTML 中，减少首屏渲染需要的网络请求；</p></li><li><p><strong>缓存和</strong><strong>预加载</strong><strong>：</strong>利用客户端的缓存及预加载等机制，提升二次访问速度；</p></li><li><p><strong>使用更轻量的框架：</strong>选择更轻量的前端框架，从而减少首屏的 JS 体积，提升加载速度；</p></li><li><p><strong>优化关键接口响应速度：</strong>优化首屏需要的关键内容的接口响应速度，确保前端能更快的呈现页面。</p></li></ol><p>但如果还有额外的 SEO 诉求，单纯的 CSR 可能很难达到一样的效果。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q7：如果将原有的应用直接切换到 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 一体化应用中来，成本会有多大？对开发团队会有哪些挑战呢？</strong></span></p><p><strong>刘奎：</strong>成本及挑战有以下几点：</p><ol><li><p><strong>应用改造成本：</strong>大部分应用都是无法直接在服务端环境运行的，基本都需要做一定程度的改造，比如消除首屏渲染代码中对 window、location 等浏览器特有 API 的依赖，构建出用于服务端运行的 JS 等。</p></li><li><p><strong>SSR</strong><strong> 函数研发及运维挑战：</strong>同时具备丰富的前端及服务端开发经验的团队在大部分公司都是非常少见的，如前面提到的，SSR 带来的额外的服务端的开发及运维挑战，这个也是需要前端团队考虑的。</p></li></ol><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>三、也许，SSR + CSR 会是未来新方向？</h1><p><span style="color:#245bdb"><strong>Q8：现在一些网站采用了</strong></span><span style="color:#245bdb"><strong>首屏服务器端</strong></span><span style="color:#245bdb"><strong>渲染，即对于用户最开始打开的那个页面采用的是服务器端渲染，这样就保证了渲染速度，而其他的页面采用</strong></span><span style="color:#245bdb"><strong>客户端渲染</strong></span><span style="color:#245bdb"><strong>，这样就完成了前后端分离。你觉得这会是融合了两者优势的更完美的方案吗？</strong></span></p><p><strong>刘奎：</strong>是的，这也是目前社区内的最佳实践，能很好的保留 SSR 及 SPA 应用的优点。</p><p><strong>刘勇：</strong>这其实很多年前就有相关实践了，譬如当年云龙在 UC 的 Scrat Pagelet 就是类似的实践，甚至当时做的是后续页面也通过服务端局部渲染，按需更新前端页面的阶段。</p><p>这种方式在业界也有看到一些更近一步的实践：开发者很自然的去写逻辑，不用管什么分离不分离的事，在前端工程化那一层自动拆分，SSG + SSR + CSR，一些可以静态构建的直接在构建阶段处理了，一些可以在服务端渲染的服务端，剩下的非刚需的组件直接前端渲染掉。这些都能做，前提是前端工程化这块的基建是否足够完善，研发模式是否足够收敛。</p><p>最后提醒下，我所了解大部份 SSR 实践，一般也会在前面再挡一个短时效的 CDN，然后通过 CSR 做千人千面的修饰和后续业务逻辑。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q9：你如何看待 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 的未来发展？是会随着硬件的升级逐步淘汰，还是会随着技术的更新越发流行？</strong></span></p><p><strong>刘勇：</strong>优化思路是不会过时的，也许某一天我们现在熟悉的 SSR 的编程界面变了，譬如当年的 SSR 是用 nunjucks、ejs 之类的模版，现在是 react、vue。未来也会有新的技术出现，但它很有可能也属于 SSR 的一种实践模式。</p><p><strong>刘奎：</strong>按照我的经验来看，很多时候新的技术方案大都会尝试更多的压榨硬件机能，从而获得更好的交互体验，所以任何时期都会存在相对「低端」的设备，这个应该是解决不掉的（笑</p><p>在我看来，SSR 最主要的落地成本还是在服务端的研发及运维上，这个对于大部分公司的前端团队都是较大的负担，进而因为 ROI 不高导致 SSR 落地困难。但是，随着 Serverless 的发展，出现了许多几乎「零运维」的 Serverless 方案，可以极大地降低前端团队的运维成本。同时，从社区的趋势来看，近年来流行的各种前端框架都在拥抱 Edge 和 SSR，例如 Next.js、remix-run、Qwik、Astro、Fresh 等。同时，React 等库也推出了性能表现更佳的流式 SSR 能力。通过这些框架技术的集成和迭代，不仅可以显著降低前端工程师开发 SSR 应用的研发成本，还能进一步提升传统 SSR 的性能效果。</p><p>从目前的趋势来看，我觉得 SSR 会随着研发及运维成本的降低，变得越发的流行。</p><p>&nbsp;</p><p><span style="color:#245bdb"><strong>Q10：结合你的项目经验，你会如何评价 </strong></span><span style="color:#245bdb"><strong>SSR</strong></span><span style="color:#245bdb"><strong> 这一模式呢？</strong></span></p><p><strong>刘勇：</strong>从前端的历史演进看，是 SSR → CSR → SSR，粗一看似乎是在开历史倒车，但实际不然。</p><p>举个例子，当年前端的 HTML + CSS + JS 都是 all-in-one 的单文件方式，因为那时候前端没有编译能力只能写在一起；随着前端工程化的演进，开发期拆成多文件方式进行组织，构建时自动处理成为了主流；再进一步又出现了类似 Vue SFC 这样的单文件方式，这是开倒车么？其实不是，而是随着基建的完善，用户编程界面是可以更贴近直觉的，性能和部署之类的事交给工具去做即可。</p><p>因此，我认为 SSR 模式是有真实场景的，但在目前这个阶段，我觉得它还有很多切实的性能问题和工程化问题需要解决才能更好的落地。</p><p><strong>刘奎：</strong>CSR 虽然也能获得比较好的首屏体验，但受限于用户设备的机能，存在着明显的性能天花板。而 SSR 则能更好的借助边缘计算（ESR）、流式渲染等服务端能力，有效的提升性能天花板，在大部分时候会是 Web 应用提升首屏性能的一个有效武器。</p><p>当然每个项目和团队都有不同的特点和目标，在选择开发模式时需要综合考虑各种因素。</p><p>&nbsp;</p><p style="text-align:left">对此，你怎么看？你的项目采取了 SSR 还是 CSR 呢？快来评论区说说你的体验吧~</p></div></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 09:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10136979</guid>
            <link>https://my.oschina.net/u/6852546/blog/10136979</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[推特年度工程总结，数据感人，什么代码减少 60 万行、节省 1 亿美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>推特官方帐号发布了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FXEng%2Fstatus%2F1717754398410240018" target="_blank">一年的工程总结</a>，亮点数据包括：</p><ul><li><p><span style="color:#000000"><span style="background-color:#ffffff">彻底重构 For you 服务和排名系统，代码行数从 700K 减少到 70K，减少了 90%，计算占用量减少了 50%，帖子吞吐量增加了 80%。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">重构了技术栈的 API 中间件层，并简化了架构</span></span>，<span style="color:#000000"><span style="background-color:#ffffff">删除超过 10 万行代码和数千个未使用的内部端，消除未采用的客户端服务。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">关闭萨克拉门托数据中心并重新配置 5,200 个机架和 148,000 台服务器，每年节省超过 1 亿美元。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">元数据获取后延迟减少了 50%，全局 API 超时错误减少了 90%。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">优化了对云服务提供商的使用，在本地进行更多工作，每月云成本降低了 60%。具体是将所有媒体/blob 工件移出云，使得整体云数据存储大小减少了 60%。同时，云数据处理成本降低了 75%。</span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">构建本地 GPU 超级计算集群，并设计、开发和交付 43.2Tbps 的新网络结构架构以支持集群。 </span></span></p></li><li><p><span style="color:#000000"><span style="background-color:#ffffff">扩展网络主干容量和冗余，每年节省 1,390 万美元。 </span></span></p></li></ul><hr><p><img src="https://static.oschina.net/uploads/space/2023/1027/161455_YSrE_2720166.png" referrerpolicy="no-referrer"></p><hr><p><strong>推荐阅读</strong></p><ul><li><a href="https://www.oschina.net/news/231624/a-single-engineer-brought-down-twitter" target="_blank">一名工程师修改配置导致推特宕机，马斯克回应：要彻底重写这堆 "ShitCode"</a></li><li><a href="https://www.oschina.net/news/259436/elon-musk-moved-twitter-servers-himself" target="news">马斯克硬核迁移推特服务器</a></li><li><a href="https://www.oschina.net/news/247743/twitter-rate-limit" target="news">马斯克称 Twitter 数据被极端抓取，紧急上线「限流」机制</a></li><li><a href="https://www.oschina.net/news/228687/musk-twitter-recommend-algorithm" target="news">马斯克连夜命令推特工程师修改算法</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263723/x-engineering-report</guid>
            <link>https://www.oschina.net/news/263723/x-engineering-report</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[全新的分布式锁，功能简单且强大]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><blockquote><p>来源：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftlnet.top%2Farticle%2F22425101" target="_blank">《全新的分布式锁，功能简单且强大》</a></p><p>前言：分布式锁是分布式系统中一个极为重要的工具。目前有多种分布式锁的设计方案，比如借助 redis，mq，数据库，zookeeper 等第三方服务系统来设计分布式锁。tldb 提供的分布式锁，主要是要简化这个设计的过程，提供一个简洁可靠，类似使用程序中对象锁的方式来获取分布式锁。</p></blockquote><p><strong>tldb 提供分布式锁使用方法：</strong></p><ol><li><p>lock 阻塞式请求锁</p></li><li><p>trylock 尝试加锁，若锁已被占用，则失败返回，反之，则获取该锁</p></li><li><p>unlock 释放已经获取的锁</p><p>tldb 提供的分布式锁功能主要在 MQ 模块中实现，调用的方法在 MQ 客户端实现，客户端的实现实际非常简单，除了目前已经实现的几种语言 java，golang，python，javaScript 写的 simpleClient，其实其他开发者有兴趣也可以实现其他语言的 MQ 客户端，完全没有技术门槛。分布式锁由 tldb 服务器控制，所以它相对客户端来说，也是跨语言的，如，用 java 客户端上锁的对象，其他语言同样无法获取该对象锁。</p></li></ol><hr><h4><strong>Lock(string,int) 方法的使用</strong></h4><p>tldb 提供的是以字符串为锁对象的独占锁， 如，lock("abc",3) 必须提供两个参数：</p><ol><li>第一个参数为锁对象，即服务器对「abc」对象分配一个锁，所有对"abc"对象请求加锁的线程争用一个独占锁，该方法为一个阻塞方法，请求到锁则返回，如果锁被其他线程占用，则一直阻塞直至获取到锁。</li><li>第二个参数为持有该分布式锁的最长时间，单位为秒，例如 lock("abc",3)，意思是，如果超过 3 秒还没有调用 unlock 释放该锁，服务器将强制释放该锁，继续将锁分配给其他请求的线程。</li></ol><hr><h4><strong>UnLock(string) 方法的使用</strong></h4><ul><li>UnLock 为释放分布式锁时调用的方法。客户端在成功获取分布式锁后，服务器会返回一个该锁的 key，客户端执行完逻辑代码的最后，必须显式调用 UnLock(key) 来释放该分布式锁。如果没有调用 unlock 释放锁，tldb 将等待锁释放的超时时间直至超时后强制释放该锁。</li></ul><hr><h4><strong>TryLock(string,int) 方法的使用</strong></h4><ul><li>trylock 与 lock 相似，但是 lock 方法阻塞的，调用 lock 方法请求分布式锁时，如果该锁已经被占用，那么 lock 方法将一直等待直至 tldb 服务器将锁分配给它，这与程序中获取独占锁的方式一致。而 trylock 时非阻塞的，调用 trylock 后会立即返回，如果获取到锁，tldb 会将标识该锁的 key 一并返回，如何该锁已经被占用，服务器将返回空数据。</li></ul><hr><p><strong>以下以 go 为例使用分布式锁</strong></p><p>因为 tldb 分布式的实现是在 MQ 模块，所以 go 程序必须使用 tlmq-go, tldb 的 mq 客户端进行调用锁方法。</p><pre><code>   import  "github.com/donnie4w/tlmq-go/cli"
</code></pre><p>调用 lock 的程序：lock 方法是阻塞的</p><pre><code>sc := cli.NewMqClient("ws://127.0.0.1:5001", "mymq=123")
sc.Connect()
//以上为，客户端连接 MQ 服务器
key, err := sc.Lock("testlock", 3)
//lock 中两个参数，第一个参数为字符串，即 tldb 服务器为「testlock」分配一个全局的分布式锁
//第二个参数 3 为客户端持有该锁的最长时间，表示超过 3 秒没有释放锁时，tldb 服务器将在服务端强制释放该锁，并分配给其他请求锁的线程
if err!=nil{
    //获取锁失败，需查看 tldb 能正常访问
}else{
    defer sc.UnLock(key) //获取锁成功后，必须在程序最后调用 Unlock
    //执行业务逻辑程序
}
</code></pre><p><strong>调用 tryLock 的程序，trylock 是非阻塞的</strong></p><pre><code>sc := cli.NewMqClient("ws://127.0.0.1:5001", "mymq=123")
sc.Connect()

if key, ok := sc.TryLock("testlock2", 3); ok {
    //ok 为 true，表示已经成功获取到分布式锁
    defer sc.UnLock(key) //在程序最后释放锁对象
    ...        
}
</code></pre><p><strong>go 用自旋的方式使用 trylock 获取分布式锁，实现程序的阻塞等待</strong></p><pre><code>sc := cli.NewMqClient("ws://127.0.0.1:5001", "mymq=123")
sc.Connect()
var key string
for {
if  v, ok := sc.TryLock("testlock", 3); ok {
    key = v
break
} else {
&lt;-time.After(100* time.Millisecond)
}
}
defer sc.UnLock(key)
...//业务逻辑代码
</code></pre><p>这段程序应该比较易于理解，就是每隔 100 毫秒，循环获取字符串「testlock」的分布式锁直至成功。</p><hr><p><strong>以下以 java 为例</strong> java 客户端为 tlmq-j ：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdonnie4w%2Ftlmq-j" target="_blank">https://github.com/donnie4w/tlmq-j</a></p><p>maven 配置</p><pre><code>&lt;dependency&gt;        
   &lt;groupId&gt;io.github.donnie4w&lt;/groupId&gt;      
   &lt;artifactId&gt;tlmq-j&lt;/artifactId&gt;     
   &lt;version&gt;0.0.2&lt;/version&gt;   
&lt;/dependency&gt;
</code></pre><p>调用 lock 方法</p><pre><code>MqClient mc = new SimpleClient("ws://127.0.0.1:5001", "mymq=123");
mc.connect();
//java 连接服务器
String key = null;
try{
      key = mc.lock("testlock", 3); //获取分布式
      ... //执行业务逻辑程序
}finally {
     if (key!=null){
         mc.unLock(key); //释放分布式锁
     }
}
</code></pre><p>调用 trylock 方法</p><pre><code>MqClient mc = new SimpleClient("ws://127.0.0.1:5001", "mymq=123");
mc.connect();
String key = null;
try{
      key = mc.tryLock("testlock", 3); //获取分布式
      ... //执行业务逻辑程序
} finally {
     if (key!=null){
         mc.unLock(key); //释放分布式锁
     }               
}
</code></pre><p><strong>以下是 tldb 分布式锁的功能测试数据：</strong><strong>多线程并发，调用 lock 获取同一个对象锁后，程序的运行数据：</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-09276d085e420b382074c69dade4cd6372b.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>多线程并发使用自旋的方式调用 trylock 与 lock 获取同一个对象锁：</strong><img src="https://oscimg.oschina.net/oscnet/up-cb14a249e167dfb0eca3c06850a6017f182.jpg" alt="" referrerpolicy="no-referrer"></p><hr><p><a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%9C%89%E4%BB%BB%E4%BD%95%E9%97%AE%E9%A2%98%E6%88%96%E5%BB%BA%E8%AE%AE%E8%AF%B7Email%EF%BC%9Adonnie4w%40gmail.com%E6%88%96" target="_blank">有任何问题或建议请 Email：donnie4w@gmail.com 或</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftlnet.top%2Fcontact" target="_blank">https://tlnet.top/contact</a> 发信给我，谢谢！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 07:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/donnie4w/blog/10114233</guid>
            <link>https://my.oschina.net/donnie4w/blog/10114233</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软已拥有超过 100 万付费 Copilot 用户]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">微软 CEO 萨提亚·纳德拉 (Satya Nadella) 日前透露，该公司 GitHub Copilot 软件的付费用户已超过 100 万。</span></p><p><span style="color:#000000">「借助 GitHub Copilot，我们将开发人员的工作效率提高了 55%，我们拥有超过 100 万付费 Copilot 用户。此外，已有超过 37,000 个组织订阅了 Copilot for Business，环比增长 40%。本季度，我们通过 GitHub Copilot Chat 添加了新功能，Shopify 等数字原生企业以及马士基和普华永道等领先企业已在使用这些功能，以提高其软件开发人员的生产力。」</span></p><p><img height="264" src="https://oscimg.oschina.net/oscnet/up-1fbc03d629d9cf27183ca8ebfb858414029.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">纳德拉表示，Copilot 是其在公司产品线中推广 AI 的众多方式之一。该公司的必应搜索引擎已经与 OpenAI 的 ChatGPT 集成，迄今为止用户参与的聊天数量已「超过 19 亿次」。</span></p><p><span style="color:#000000">他指出，Microsoft Edge 浏览器的市场份额现已连续 10 个季度增长。「本季度，我们推出了新的个性化答案以及对 DALL-E 3 的支持，帮助人们获得更相关的答案并创建极其逼真的图像。迄今为止，我们已创建了超过 18 亿张图像。借助 Copilot 在购物方面的应用，大家可以获取更多量身定制的推荐以及达成更好的交易。」</span></p><p><span style="color:#000000">目前，微软已经向初创公司 OpenAI 投资超过 100 亿美元；华尔街预计微软将从与 OpenAI 的合作中获得巨大的财务回报。一些华尔街分析师估计，这种合作关系有一天可能会给微软带来 1000 亿美元的价值。</span></p><p><span style="color:#000000">尽管纳德拉没有量化 GitHub Copilot 的收入，但微软 CFO Amy Hood 表示，「高于预期的 AI 消费推动了 Azure 的收入增长」。</span></p><p><span style="color:#000000">该公司智能云计算业务本季度的总收入超出了分析师的预期 (234 亿美元)，同比增长 19%，达到 243 亿美元。Hood 表示，其中 Azure 业务增长了 29%，有 3 个百分点来自「AI 服务」。</span></p><p><span style="color:#000000">此外，微软方面还将 Copilot 引入了 Power Platform，使任何人都可以使用自然语言来创建应用程序，构建虚拟代理和分析数据。纳德拉表示：「包括 3M、Equinor、Lumen Technologies、Nationwide、PG&amp;E 和丰田在内的超过 126,000 家组织都使用了 Copilot 和 Power Platform。」</span></p><p><span style="color:#000000">该公司还正在将生成式 AI 添加到其 LinkedIn 业务中。「我们发现本季度在 LinkedIn 上观看 AI 相关学习课程的会员数量增加了近 80%」。以及将 Copilot 扩展到医疗保健等各行各业。目前，该公司正在将临床工具集成到 Azure 上的 Fabric 数据服务中。</span></p><p><span style="color:#000000">纳德拉称，GitHub Copilot 和其他产品的推出还处于早期阶段。「我们正处于非常非常早期的阶段，因此我们期待看到这些产品在未来的发展。Copilot 的早期发展给了我们很大的信心，更重要的是，让我们的客户对这些产品所代表的价值充满了信心。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 07:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263710</guid>
            <link>https://www.oschina.net/news/263710</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国家安全部：警惕一些境外 SDK 背后的「数据间谍」窃密]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><blockquote><p>本文转载自 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fxq_0nAxzuZ4t0HLXLy8BEg" target="_blank"><strong>国家安全部微信公众号</strong></a></u></p></blockquote><p>你知道 SDK 是什么吗？SDK 是英文 Software Development Kit 的缩写，即软件开发工具包，它的类型多种多样。如果把开发一个软件系统比作盖一所「三室一厅」的房子，那么不同的 SDK 就是这套房子的「客厅」「卧室」「衞生间」「厨房」等功能模块。盖好这套房子，我们只需要从不同的供应商那里选择这个功能模块拼装即可，而不再需要从「砌砖」「垒墙」做起，从而极大提高了软件开发的效率。</p><p>近年来，国家安全机关工作发现，境外一些别有用心的组织和人员，正在通过 SDK 搜集我用户数据和个人信息，给我国家安全造成了一定风险隐患。</p><h4><span style="color:#ffffff"><strong><span style="background-color:#2980b9">SDK 带来哪些数据安全问题？</span></strong></span></h4><p>当前，SDK 以其多样化、易用性和灵活性等优势成为移动供应产业链中最重要的一项服务，与此同时也带来诸多数据安全问题。</p><ul><li><strong>过度收集用户数据</strong></li></ul><p>有些 SDK 会收集与提供服务无关的个人信息，或强制申请非必要的使用权限，比如获取地理位置、通话记录、相册照片等信息以及拍照、录音等功能。当 SDK 的用户覆盖量达到一定规模时，可以通过搜集的大量数据，对不同用户群体进行画像侧写，从而分析出潜在的有用信息，比如同事关系、单位位置、行为习惯等。</p><p>一些境外 SDK 服务商，通过向开发者提供免费服务，甚至向开发者付费等方式来获取数据。据相关网站披露，一款在美国拥有 5 万日活跃用户的应用程序，其开发者通过使用某 SDK，每月可以获得 1500 美元的收入。作为回报，该 SDK 服务商可以从这款应用程序中收集用户的位置数据。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28cd143918cb6491c1493e0dcedaa1e2bd3.png" referrerpolicy="no-referrer"></p><p><em>SDK 搜集个人信息类型</em></p><ul><li><strong>境外情报机构将 SDK 作为搜集数据的重要渠道</strong></li></ul><p>据报道，美国特种作战司令部曾向美国 SDK 服务商 Anomaly Six 购置了「商业遥测数据源」的访问服务，而该服务商曾自称将 SDK 软件植入全球超过 500 款应用中，可以监控全球大约 30 亿部手机的位置信息。</p><p>2022 年 4 月，有关媒体曝光巴拿马一家公司通过向世界各地的应用程序开发人员付费的方式，将其 SDK 代码整合到应用程序中，秘密地从数百万台移动设备上收集数据，而该公司与为美国情报机构提供网络情报搜集等服务的国防承包商关系密切。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b4bc6599b4e81d3e9a7883925c9f4c2c397.png" referrerpolicy="no-referrer"></p><p><em>《华尔街日报》：美国政府承包商在多个手机 APP 中嵌入跟踪软件</em></p><h4><span style="color:#ffffff"><strong><span style="background-color:#2980b9">消除 SDK 背后的数据风险</span></strong><strong><span style="background-color:#2980b9">我们应该怎么做？</span></strong></span></h4><p>据国内权威机构掌握，截至 2022 年 12 月，我国 10 万个头部应用中，共检测出 2.3 万余例样本使用境外 SDK，使用境外 SDK 应用的境内终端约有 3.8 亿台。对此，我们又应该做些什么呢？</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-85cdd9629fe616749844499bf44f168c4aa.png" referrerpolicy="no-referrer"></p><p><em>SDK 申请收集用户信息占比</em></p><ul><li><strong>应用程序开发企业</strong>：应尽量选择接入经过备案认证的 SDK，引入境外 SDK 前应做好安全检测和风险评估，深入了解 SDK 的隐私政策，并利用 SDK demo 以及 APP 测试环境对 SDK 声明内容进行一致性比对，并持续监测 SDK 是否有异常行为。</li><li><strong>个人用户</strong>：个人用户在使用手机应用程序时，要增强个人信息保护意识及安全使用技能，要选择安全可靠的渠道下载使用应用程序，不安装来路不明的应用，不盲目通过敏感权限的申请。特别是发现 SDK 申请与应用功能无关的权限时，需要保持高度警惕。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 07:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263704</guid>
            <link>https://www.oschina.net/news/263704</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows CE 彻底退役]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>诞生于 1996 年的 Windows 嵌入式操作系统 —— Windows CE (Windows Embedded Compact) 本月迎来了它的生命周期终点。</p><p>Windows CE 最初是 Windows 的精简版本，之后逐渐发展成为全新的操作系统，它有自己的 CE 内核，而不是传统 Windows 操作系统使用的 NT 内核。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8f640a89f188c88148ea17ea44e6c74b915.png" referrerpolicy="no-referrer"></p><p>它的最后一个版本是 2013 年 8 月 11 日发布的 Windows Embedded Compact 2013（或者叫 Windows CE 8.0），该版本于 2018 年 10 月结束主流支持 (Mainstream Support)，<strong>2023 年 10 月结束延长支持 (Extended Support)</strong>，成为不受支持的退役产品。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bea6f86fc521c769ddd160731ae640284b0.png" referrerpolicy="no-referrer"></p><p>然而很少有人注意到 Windows CE 的生命周期已结束。作为一个产品，CE 8.0 的发布未能获得太多关注或宣传。即使在 Windows CE 社区中，大多数人也认为 Windows Embedded Compact 2013 完全不适合使用。与之前的 Windows CE 7.0 一样，基于 CE 8.0 平台发布的设备很少，因此大多数人甚至从未见过 CE 8 的实体设备。</p><p>CE 8 唯一值得注意的特性是首次加入了 IPv6 支持，但更重要的是删除了默认示例用户界面，它规定任何 OEM 都必须发布带有完全自定义编码界面的设备，然而很少有供应商愿意这样做，此举事实上真正结束了廉价 Windows CE 上网本设备的时代。</p><blockquote><p>事实上微软并未介绍过 CE 缩写的由来，一般解释则有 Compact Edition、Customer Embedded、Consumer Electronics 等等。</p><p>在 2008 年 4 月 15 日举行的嵌入式系统大会上，微软宣布将 Windows CE 更名为 Windows Embedded Compact，与 Windows Embedded Enterprise、Windows Embedded Standard 和 Windows Embedded POSReady 组成 Windows Embedded 系列产品。</p></blockquote><p>===彩蛋分割线===</p><p>曾被称为「国产机皇」的魅族 M8，其运行的操作系统正是基于 Windows CE 开发。</p><p><img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-786c41866ad15ca06fc5d0a683e8366c459.png" width="400" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 06:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263685/end-of-an-era-windows-ces-final-day</guid>
            <link>https://www.oschina.net/news/263685/end-of-an-era-windows-ces-final-day</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.10.0 - 支持更灵活的变更发布人]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><h2>🚀 新功能</h2><ul><li>发布策略支持制定更灵活的变更发布人：可以指定任意角色集合，也可以指定自定义审批流的最后一个审批人。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-232e6912ae4dfccc575951fdcfb6182eaae.png" alt="file" referrerpolicy="no-referrer"></p><ul><li>支持在项目中创建分支保护规则。</li><li>支持给数据库设置标签。</li><li>支持给字段设置标签。</li><li>支持给表设置分类分级。</li></ul><h2>🎄 改进</h2><ul><li><p>支持 PostgreSQL 16。</p></li><li><p>SQL Editor：支持自定义数据库树的视图。</p></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-07ab1d1c2b98175941d8e28433fe617b896.png" alt="file" referrerpolicy="no-referrer"></p><ul><li>SQL Editor：允许提前终止查询。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-80f111990561ce0c665fe4cce51db4fcb3a.png" alt="file" referrerpolicy="no-referrer"></p><ul><li>支持从指定分支中创建子分支。</li><li>支持在分支合并时选择其他目标分支。</li><li>支持在工单中使用 SQL Server 局部变量。</li><li>基于 Parser 为 Postgres, MySQL, Oracle, SQL Server, Snowflake 查询语句增加 LIMIT 子句。</li><li>表详情页展示「类型」的最大长度（如有）。</li></ul><h2>🐞 Bug 修复</h2><ul><li>修复分支和变更 Schema 中的列默认值问题。</li></ul><h2>📕 安装及升级</h2><p>参考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升级指南</a>。如果从之前版本升级，获取新版本后，重新启动升级即可。</p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 06:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10136864</guid>
            <link>https://my.oschina.net/u/6148470/blog/10136864</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维 Q3 报告：实现经营性现金流 7.6 亿]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">昆仑万维发布了 2023 年第三季度报告。据报告披露，昆仑万维第三季度<strong>全面加速推进</strong>「All in」 AGI 与 AIGC 的战略布局，在多个方向均取得了突破性进展。截至本报告期末，昆仑万维实现营业收入<strong>36.8 亿</strong>元，同比增长 8%。实现经营性现金流<strong>7.6 亿</strong>元，同比增长<strong>33%</strong>。</span></p><p><span style="color:#000000">今年前三季度，昆仑万维海外业务收入占比进一步提升至 84%，同比增加近 9 个百分点；整体毛利率达 80%，继续保持在较高水平；实现归属于上市公司股东的净利润 3.3 亿元，<strong>稳居行业第一梯队</strong>。昆仑万维第三季度实现经营性净利润 1.0 亿元，环比增长 29%。</span></p><p><span style="color:#000000">为全面落实「All in」AGI 与 AIGC 的战略布局，昆仑万维前三季度研发费用提升至 6.2 亿元，加速推进相关业务发展。此外，9 月 21 日，昆仑万维发布公告，公司控股股东、实际控制人周亚辉先生及一致行动人盈瑞世纪承诺未来三年（从 2023 年 9 月 22 日到 2026 年 9 月 21 日）不以任何形式减持所持有的公司股票，包括承诺期间该部分股份因资本公积转增、派送股票红利、配股、增发等事项产生的新增股份，长期助力昆仑万维成为一家全球领先的人工智能科技企业。</span></p><p><img height="282" src="https://static.oschina.net/uploads/space/2023/1027/113236_MDTf_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">报告称，在国内 AGI 与 AIGC 领域，其「天工」大模型在逻辑推理、文本理解、多模态能力等多个方面均取得了显著突破。基于大模型核心能力的提升，「天工」APP 进行了全面迭代升级，整合了 AI 搜索、AI 阅读、AI 创作等核心功能，覆盖了<strong>工作、学习和生活</strong>等多个应用场景。</span></p><p><span style="color:#000000">AI 搜索功能经过升级，提高了信息获取的精准度和效率。AI 阅读功能高效分析文章链接或文档文件，生成 AI 摘要并提炼要点，帮助用户快速了解文章内容。同时，支持问答式交互，使用户能够更便捷地查询文档信息。AI 创作提供轻松高效的创作体验，满足<strong>学术教育、职场文档、创意写作、广告营销</strong>等不同场景需求。</span></p><p><span style="color:#000000">作为昆仑万维 AI 业务矩阵之一的 AI 游戏也取得了重要进展。昆仑万维旗下 Play for Fun 游戏工作室自研的首款 AI 游戏《Club Koala》于 8 月 25 日在德国科隆国际游戏展亮相。Club Koala 引入了 AI NPC，并通过 Atom 系统控制 NPC 行为，使 AI NPC 拥有自我意识及记忆能力，为玩家提供更真实、更具沉浸感的游戏体验。</span></p><p><span style="color:#000000">海外布局方面，昆仑万维依托旗下信息分发及元宇宙业务 Opera 原生浏览器 AI 助手 Aria，推出了一系列前沿 AI 功能。</span></p><p><span style="color:#000000"><img alt="" height="236" src="https://oscimg.oschina.net/oscnet/up-b99565529a38b20bc30538e26fb9fe3d15d.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><em>Aria「重用」与「改述」功能</em></span></p><p><span style="color:#000000"><em><img alt="" height="238" src="https://oscimg.oschina.net/oscnet/up-00dfeb44b4d900099bac85a6a6d12e867cc.png" width="500" referrerpolicy="no-referrer"></em></span></p><p><span style="color:#000000"><em>Aria「Compose」与「My Style」功能</em></span></p><p><span style="color:#000000">Aria 已在包括欧盟在内的<strong>180</strong>多个国家和地区上线，用户突破<strong>百万</strong>。此外，Aria 已覆盖 Mac、Windows、Linux、Android 和 iOS 等所有主要平台，以及公司元宇宙入口 Opera GX。</span></p><p><span style="color:#000000">截至本季度末，昆仑万维此前采购及租赁芯片已到货<strong>约 6000 张</strong>，另外还有约<strong>3000 张</strong>芯片待交付。目前昆仑万维已有算力预计能够满足未来 1~2 年除视频 AIGC 之外的大模型算力需求。</span></p><p><span style="color:#000000">报告期内，昆仑万维宣布通过增资方式控股 AI 算力芯片企业北京艾捷科芯科技有限公司（简称「艾捷科芯」），完成「算力基础设施—大模型算法—AI 应用」全产业链布局。艾捷科芯旨在开发一款可编程的、具有高性能的 NPU 产品，同时应用于模型训练及推理。</span></p><p><span style="color:#000000">此外，昆仑万维在「华为全联接大会 2023」举办期间，发布「天工大模型端云一体化方案」。该方案具备开箱即用、定制调优、服务保障三大优势，企业可以自主地训练模型，也可以<strong>基于天工模型定制</strong>，实现从应用场景真实需求出发，赋能业务发展并提升竞争力。</span></p><p><span style="color:#000000">「昆仑万维 2023 年第三季度报告展示了公司在 AGI 及 AIGC 领域的突飞猛进。随着技术的不断创新和业务的持续扩张，以及在全产业链布局的驱动下，昆仑万维有望加速成为全球领先的人工智能龙头企业。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263657</guid>
            <link>https://www.oschina.net/news/263657</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 基于 React 技术栈的工作流高阶组件 Antd-bpmn]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-antd-bpmn" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#antd-bpmn"></a>Antd-bpmn</h1><p>一个基于 React + Ant.design + bpmn.js 编写的工作流高阶组件。</p><p><img src="https://gitee.com/antdadmin/antd-bpmn/raw/main/docs/assets/images/01.png" alt="" referrerpolicy="no-referrer"></p><h3><a id="user-content-已完成功能" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#%E5%B7%B2%E5%AE%8C%E6%88%90%E5%8A%9F%E8%83%BD"></a>已完成功能</h3><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 基于 bpmn.js 的基础画图功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> XML 预览</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> XML 保存</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 对齐方式：向右对齐，左右居中，向左对齐，向上对齐，上下居中，向下对齐</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 放大、缩小</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 撤销、重做</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 小地图、快捷键</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 重写工具栏（更符合国人习惯）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 重写元素菜单（更符合国人习惯）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 属性面板的设置</li></ul><h3><a id="user-content-如何使用" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8"></a>如何使用</h3><p>安装：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm i @codeflex/antd-bpmn</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>示例代码：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">function</span><span class="nx">App</span><span class="p">()</span><span class="p">{</span></span><span id="LC2" class="line"><span class="kd">const</span><span class="nx">config</span><span class="p">:</span><span class="nx">AntdBpmnConfig</span><span class="o">=</span><span class="p">{</span></span><span id="LC3" class="line"><span class="na">deptDataUrl</span><span class="p">:</span><span class="dl">"</span><span class="s2">/xxxx</span><span class="dl">"</span><span class="p">,</span></span><span id="LC4" class="line"><span class="na">xmlDataUrl</span><span class="p">:</span><span class="dl">"</span><span class="s2">bpmn.demo.xml</span><span class="dl">"</span><span class="p">,</span></span><span id="LC5" class="line"><span class="na">onLoad</span><span class="p">:</span><span class="p">(</span><span class="nx">url</span><span class="p">,</span><span class="kd">set</span><span class="p">)</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC6" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">onLoad</span><span class="dl">"</span><span class="p">,</span><span class="nx">url</span><span class="p">)</span></span><span id="LC7" class="line"><span class="c1">// 加载 xml 数据</span></span><span id="LC8" class="line"><span class="k">if</span><span class="p">(</span><span class="nx">url</span><span class="o">===</span><span class="dl">"</span><span class="s2">bpmn.demo.xml</span><span class="dl">"</span><span class="p">)</span><span class="p">{</span></span><span id="LC9" class="line"><span class="nx">fetch</span><span class="p">(</span><span class="nx">url</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="nx">response</span><span class="o">=&gt;</span><span class="kd">set</span><span class="p">(</span><span class="nx">response</span><span class="p">.</span><span class="nx">text</span><span class="p">()))</span></span><span id="LC10" class="line"><span class="p">.</span><span class="k">catch</span><span class="p">(</span><span class="nx">err</span><span class="o">=&gt;</span><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">err</span><span class="p">));</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="c1">// 加载部门数据</span></span><span id="LC13" class="line"><span class="k">else</span><span class="p">{</span></span><span id="LC14" class="line"><span class="kd">set</span><span class="p">([</span></span><span id="LC15" class="line"><span class="p">{</span><span class="na">value</span><span class="p">:</span><span class="dl">'</span><span class="s1">dept1</span><span class="dl">'</span><span class="p">,</span><span class="na">label</span><span class="p">:</span><span class="dl">'</span><span class="s1">北京分公司</span><span class="dl">'</span><span class="p">},</span></span><span id="LC16" class="line"><span class="p">{</span><span class="na">value</span><span class="p">:</span><span class="dl">'</span><span class="s1">dept2</span><span class="dl">'</span><span class="p">,</span><span class="na">label</span><span class="p">:</span><span class="dl">'</span><span class="s1">上海分公司</span><span class="dl">'</span><span class="p">},</span></span><span id="LC17" class="line"><span class="p">{</span><span class="na">value</span><span class="p">:</span><span class="dl">'</span><span class="s1">dept3</span><span class="dl">'</span><span class="p">,</span><span class="na">label</span><span class="p">:</span><span class="dl">'</span><span class="s1">-- 上海研发部</span><span class="dl">'</span><span class="p">},</span></span><span id="LC18" class="line"><span class="p">])</span></span><span id="LC19" class="line"><span class="p">}</span></span><span id="LC20" class="line"><span class="p">},</span></span><span id="LC21" class="line"></span><span id="LC22" class="line"><span class="na">onChooseAssignee</span><span class="p">:</span><span class="p">(</span><span class="kd">set</span><span class="p">)</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC23" class="line"><span class="kd">set</span><span class="p">(</span><span class="nb">Math</span><span class="p">.</span><span class="nx">random</span><span class="p">(),</span><span class="dl">"</span><span class="s2">Michael</span><span class="dl">"</span><span class="p">);</span></span><span id="LC24" class="line"><span class="p">},</span></span><span id="LC25" class="line"><span class="p">};</span></span><span id="LC26" class="line"><span class="k">return</span><span class="p">&lt;</span><span class="nc">AntdBpmn</span><span class="na">config</span><span class="p">=</span><span class="si">{</span><span class="nx">config</span><span class="si">}</span><span class="p">/&gt;;</span></span><span id="LC27" class="line"><span class="p">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>AntdBpmnConfig</strong> 说明：</p><ul><li>xmlDataUrl: 获取 bpmn xml 数据的 URL</li><li>deptDataUrl: 获取部门数据的 URL</li><li>onLoad: 监听加载网络数据，数据加载完毕后通过第二个参数 <code>set</code> 方法来设置</li><li>onChooseAssignee: 监听选择用户操作，选择用户后通过第二个参数 <code>set</code> 方法来设置</li></ul><h3><a id="user-content-运行测试" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#%E8%BF%90%E8%A1%8C%E6%B5%8B%E8%AF%95"></a>运行测试</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://gitee.com/antdadmin/antd-bpmn.git</span><span id="LC2" class="line"></span><span id="LC3" class="line">npm <span class="nb">install</span></span><span id="LC4" class="line">npm run dev</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-antdadmin-技术交流群" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#antdadmin-%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>AntdAdmin 技术交流群</h3><p>QQ 群：560291578</p><h3><a id="user-content-antdadmin-简介" class="anchor" href="https://gitee.com/antdadmin/antd-bpmn#antdadmin-%E7%AE%80%E4%BB%8B"></a>AntdAdmin 简介</h3><p>AntdAdmin 是一个致力于 <strong>中国信创</strong> 产业的前端开源框架，其底层技术栈主要以 React + Ant.design 为主。AntdAdmin 开源（或者计划开源）的产品主要如下：</p><ul><li><strong>antd-admin</strong>：一个基于 React + Ant.Design 的中（后）台 UI 框架（准备中...）。</li><li><strong>antd-crud</strong>：一个基于 React + Ant.Design 的增删改查高级组件（已开源：<a href="https://gitee.com/antdadmin/antd-crud">https://gitee.com/antdadmin/antd-crud</a> ）。</li><li><strong>antd-bpmn</strong>：一个基于 React + Ant.Design 的工作流设计组件（已开源：<a href="https://gitee.com/antdadmin/antd-bpmn">https://gitee.com/antdadmin/antd-bpmn</a> ）。</li><li><strong>antd-builder</strong>：一个基于 React + Ant.Design 的表单拖拽设计组件（准备中...）。</li></ul>]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/antdadmin/antd-bpmn</guid>
            <link>https://gitee.com/antdadmin/antd-bpmn</link>
        </item>
        <item>
            <title>
                <![CDATA[WxAutoExIm - 微信聊天图片自动备份工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="project_detail_above_text_link_1" data-tracepid="project_detail_above_text_link"><a style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" target="_blank">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代 <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p>WxAutoExIm 是一款免费开源微信聊天图片自动备份工具，自动备份微信聊天图片到指定位置，即开即用。该工具能够扫描 dat 加密图片并且解密，把微信微信图片自动备份为普通图片。</p><p>WxAutoExIm 使用 Rust 和 C++ 开发，工具开源、解密算法不开源。</p><p><strong>运行截图</strong></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0f7f60097376c7df3344aacf35adaba6e2e.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-1f4f2464b4440e7cadd1f23e748210200cc.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-b544656edd46ba309b4ed2b8a8b1f2f7b8c.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/wxautoexim</guid>
            <link>https://www.oschina.net/p/wxautoexim</link>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu LTS 坚持 10 年更新不动摇]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/event/2331193" _blank"="">OSC 请你来轰趴啦！1028 苏州源创会，一起寻宝 AI 时代<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>Linux 内核开发者 Jonathan Corbet 此前在欧洲开源峰会上宣布，LTS 内核的支持时间将<u><a href="https://www.oschina.net/news/258970/linux-gives-up-on-6-year-lts" target="_blank">从六年缩短至两年</a></u>，原因在于缺乏使用和缺乏支持。稳定版内核维护者 Greg Kroah-Hartman 也表示「<u><a href="https://www.oschina.net/news/261164/greg-says-lf-strongly-supports-kernel-developers" target="_blank">没人用 LTS 内核</a></u>」。</p><p>近日，Ubuntu 开发商 Canonical <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Flinux-kernel-lts" target="_blank">发表博客称</a></u>，他们会坚持为 Ubuntu LTS 版本提供 10 年的更新支持。</p><blockquote><p><img height="718" src="https://static.oschina.net/uploads/space/2023/1027/105620_6hYU_2720166.png" width="1527" referrerpolicy="no-referrer"></p></blockquote><p>Canonical 在博客写道：</p><blockquote><p><strong>Ubuntu 为您提供 10 年的稳定性</strong></p><p>近二十年来，Canonical 一直是 Ubuntu Linux 内核最重要的 LTS 提供商。 我们每两年发布一个新的 LTS 内核，并总共维护 10 年。我们为 LTS 内核提供为期五年的安全更新，并可以选择通过扩展安全维护 (ESM) 将维护窗口延长至 10 年。</p><p>Canonical 的专门工程团队负责维护所有 Ubuntu 内核、管理 Linux 内核 CVE，并针对关键缺陷应用提供相关补丁。 内核高可靠性是我们设计和工程决策的核心，并且由于 Ubuntu 在生产环境中的广泛使用，我们处于不断提高可靠性的有利位置。</p><p>Ubuntu 内核经过严格的测试、完善和改进，使其成为计算领域中经过最严格生产测试的内核之一。</p><p>Canonical 的维护和支持工作完全独立于上游 LTS，并将像以前一样继续进行。 尽管上游 LTS 支持发生了变化，Canonical 仍然致力于为 Ubuntu 内核提供可靠的支持，确保 Linux 社区和企业可以继续依赖稳定和安全的软件。</p></blockquote><p>鉴于 Linux 内核维护周期即将发生的变化，Canonical 这番对长期支持的承诺显得更加重要。毕竟维护 Linux 内核需要大量的专业知识，这在处理设计为长寿命的产品时变得尤其具有挑战性，意味着组织可能会在维护和核心业务目标之间进行权衡。</p><p>Canonical 提供了生产级软件分发机制，以及一致的可靠安全更新流。该方法已经在生产环境中经过严格测试，从基本操作系统和关键软件包的安全更新扩展到基础设施组件和应用程序。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 26 Oct 2023 03:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/263647/ubuntu-linux-kernel-lts-10yr</guid>
            <link>https://www.oschina.net/news/263647/ubuntu-linux-kernel-lts-10yr</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
