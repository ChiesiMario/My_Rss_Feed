<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 03 Jan 2024 02:56:01 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[数据损毁！250 亿美金的 Pinterest，在数据库选型上的翻车经历]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>原文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fread.engineerscodex.com%2Fp%2Fhow-pinterest-scaled-to-11-million" target="_blank">链接</a></p></blockquote><p>Pinterest 是一个以图片为主的社交网络，用户可以将图片保存或 "钉 / pin" 在自己的图板上。Pinterest 在 2019 年上市，目前市值 250 亿美金。本文内容主要根据 <a href="https://my.oschina.net/u/6148470/blog/www.infoq.com/presentations/Pinterest/">2012 年 Scaling Pinterest 的分享</a>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b6732ec7ea8c34bc808a4107b2716fd055b.png" alt="file" referrerpolicy="no-referrer"></p><p>2012 年 1 月，Pinterest 的月独立用户数量达到 1170 万，而当时只有 6 名工程师。 Pinterest 于 2010 年 3 月推出，<strong>是当时月活用户突破 1000 万最快的公司</strong>。</p><h2>扩展 Pinterest 的经验教训</h2><ul><li>**使用已知的成熟技术。**Pinterest 当时涉足较新的技术，导致了数据损坏等问题。</li><li><strong>保持简单。</strong>(反复出现的主题！）</li><li>**不要太有创意。**团队采用的架构可以增加更多相同的节点来扩大规模。</li><li>限制选项。</li><li>**数据库分片 &gt; 集群。**这减少了跨节点的数据传输，是件好事。</li><li>**享受乐趣！**新工程师能够在第一周内贡献代码。</li></ul><h2>2010 年 3 月：Closed beta 发布，1 名工程师</h2><p>Pinterest 于 2010 年 3 月推出，当时只有一个小型 MySQL 数据库、一个小型 web server 和一名工程师（还有两位联合创始人）。</p><p><img src="https://oscimg.oschina.net/oscnet/up-987c831e14abcda14e64d79afb5cb06f8ae.png" alt="file" referrerpolicy="no-referrer"></p><h2>2011 年 1 月：10,000 名用户，2 名工程师</h2><p>九个月后的 2011 年 1 月，Pinterest 的架构已经发展到可以处理更多用户。当时他们仍然只接受邀请，只有两名工程师。</p><p>他们拥有：</p><ul><li>基本的 web server 技术栈（亚马逊 EC2、S3 和 CloudFront）</li><li>用于后端的 Django（Python）</li><li>4 台 web server 作为冗余</li><li>NGINX 作为反向代理和负载均衡。</li><li>1 个 MySQL 主数据库 + 1 个只读数据库</li><li>用于计数的 MongoDB</li><li>1 个任务队列和 2 个任务处理器，用于异步任务</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-0196d02cb17d2d0bcaaa97c0bd92dc910d7.png" alt="file" referrerpolicy="no-referrer"></p><h2>2011 年 10 月：320 万用户，3 名工程师</h2><p>从 2011 年 1 月到 2011 年 10 月，Pinterest 的增长速度极快，用户数量每隔一个半月就翻一番。</p><p>他们在 2011 年 3 月推出的 iPhone 应用程序是推动这一增长的因素之一。</p><p>当事物快速发展时，技术出现问题的频率会超出你的预期。</p><p>这时 Pinterest 犯了一个错误：<strong>他们把架构弄得过于复杂了</strong>。</p><p>他们只有 3 名工程师，但却采用了 5 种不同的数据库技术来存放数据。</p><p>他们既要手动对 MySQL 数据库进行分片，又要使用 Cassandra 和 Membase（现在的 Couchbase）对数据进行集群。</p><p>他们「过于复杂的技术栈」：</p><ul><li>Web server 栈（EC2 + S3 + CloudFront）</li><li>Pinterest 开始使用 Flask（Python）作为后端服务器</li><li>16 台 web server</li><li>2 个 API 引擎</li><li>2 个 NGINX 代理服务器</li><li>5 个手动分片的 MySQL DB + 9 个只读</li><li>4 个 Cassandra 节点</li><li>15 个 Membase 节点（3 个独立集群）</li><li>8 个 Memcache 节点</li><li>10 个 Redis 节点</li><li>3 个任务路由器 + 4 个任务处理器</li><li>4 个 Elastic Search 节点</li><li>3 个 Mongo 集群</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-5f2fb558a7729ae71bf2c0a861f5aa90efe.png" alt="file" referrerpolicy="no-referrer"></p><h3>⚠️ 集群崩了</h3><blockquote><p>数据库集群 (Database Clustering) 是将多个数据库服务器连接起来作为一个系统共同工作的过程。</p></blockquote><p>从理论上讲，集群可以自动扩展数据存储、提供高可用性、自由负载平衡，并且不会出现单点故障。</p><p>遗憾的是，在实践中，集群过于复杂，升级机制困难，而且存在一个大的单点故障 （SPOF）。</p><p><img src="https://oscimg.oschina.net/oscnet/up-179c5fa53414a11501ceb25bdab51593892.png" alt="file" referrerpolicy="no-referrer"></p><p>每个 DB 都有一个集群管理算法，在 DB 之间进行路由。</p><p>当一个数据库出现问题时，就会添加一个新的数据库来替代它。</p><p>理论上，集群管理算法应该可以很好地处理这个问题。</p><p>但实际上，Pinterest 的集群管理算法中存在<strong>一个 bug，破坏了所有节点上的数据，破坏了数据该如何重新平衡，并产生了一些无法修复的问题</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d2e5d632b64dd8c742675e658c610f1a084.png" alt="file" referrerpolicy="no-referrer"></p><p>Pinterest 的解决方案是什么？</p><p>从系统中移除所有集群技术（Cassandra、Membase）。全面采用 MySQL + Memcached（更成熟）。</p><p>MySQL 和 Memcached 都是久经考验的技术。Facebook 利用这两种技术创建了世界上最大的 Memcached 系统，每秒轻松处理数十亿次请求。</p><h2>2012 年 1 月：1100 万用户，6 名工程师</h2><p>2012 年 1 月，Pinterest 的月活跃用户约为 1100 万，日活跃用户在 1200 万到 2100 万之间。</p><p>此时，Pinterest 已经花时间简化了他们的架构。</p><p>他们删除了当时不太成熟的方案，如集群和 Cassandra，取而代之的是成熟的方案，如 MySQL、Memcache 和分片。</p><p>他们简化后的技术栈：</p><ul><li>亚马逊 EC2 + S3 + Akamai（取代 CloudFront）</li><li>AWS ELB（弹性负载平衡）</li><li>90 个 web servers + 50 个 API 引擎（使用 Flask）</li><li>66 个 MySQL DB + 66 个只读</li><li>59 个 Redis 实例</li><li>51 个 Memcache 实例</li><li>1 个 Redis 任务管理器 + 25 个任务处理器</li><li>分片式 Apache Solr（取代 Elasticsearch）</li><li><strong>移除 Cassanda、Membase、Elasticsearch、MongoDB、NGINX</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-120c963bf32049f24ff2571b3b8c73cc066.png" alt="file" referrerpolicy="no-referrer"></p><h3>Pinterest 如何手动分片数据库</h3><blockquote><p>数据库分片 (Database Sharding) 是一种将单个数据集分割成多个数据库的方法。 优点：高可用性、负载平衡、数据放置算法简单、易于拆分数据库以增加容量、易于定位数据</p></blockquote><p>Pinterest 首次对数据库进行分片时，需要冻结新功能发布。在几个月的时间里，他们以渐进和手动的方式对数据库进行了分片：</p><p><img src="https://oscimg.oschina.net/oscnet/up-c7987776a9c9a98ea53f138c0972aac17c8.png" alt="file" referrerpolicy="no-referrer"></p><p>团队删除了数据库层中的表 Join 和复杂查询。他们添加了大量缓存。</p><p>由于跨数据库维护唯一约束需要额外的工作，他们将用户名和电子邮件等数据保存在一个巨大的、未分片的数据库中。</p><p>这个数据库下的所有表都存在于所有分片中。</p><h3>手动分片的一个小例子</h3><p>由于他们有数十亿个 "pin"，他们的数据库索引会耗尽内存。</p><p>他们会将数据库中最大的表转移到自己的数据库中。</p><p>然后，当数据库空间耗尽时，他们就会将其分片。</p><h2>2012 年 10 月：2200 万用户，40 名工程师</h2><p>2012 年 10 月，Pinterest 的月度用户约为 2200 万，但他们的工程团队却翻了两番，达到了 40 名工程师。</p><p><strong>架构是一样的</strong>。他们只是增加了更多相同的系统。</p><ul><li>亚马逊 EC2 + S3 + CDN（EdgeCast、Akamai、Level 3）</li><li>180 台 web servers + 240 个 API 引擎（使用 Flask）</li><li>88 个 MySQL DB + 88 个只读</li><li>110 个 Redis 实例</li><li>200 个 Memcache 实例</li><li>4 个 Redis 任务管理器 + 80 个任务处理器</li><li>分片式 Apache Solr</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-7ae083a97f3b96301ba7b7466676e28147f.png" alt="file" referrerpolicy="no-referrer"></p><p>他们开始从 HDD 转向固态硬盘 SSD。</p><p>一个重要的教训是：<strong>有限的、经过验证的选择是件好事</strong>。</p><p>坚持使用 EC2 和 S3 意味着他们只有有限的配置可供选择，从而减少了麻烦，提高了简便性。</p><p>与此同时，<strong>新实例可以在几秒钟内准备就绪</strong>。这意味着他们可以在几分钟内添加 10 个 Memcache 实例。</p><h3>Pinterest 的数据库结构 ID</h3><p>和 Instagram 一样，Pinterest 也有一个独特的 ID 结构，因为他们有分片数据库。</p><p>他们的 64 位 ID 看起来像</p><p><img src="https://oscimg.oschina.net/oscnet/up-d15359a11c9a670227bfdd39c3eadd5271a.png" alt="file" referrerpolicy="no-referrer"></p><blockquote><p>分区 ID：哪个分区（16 位） 类型：对象类型，如针（10 位） 本地 ID：在表中的位置（38 位）</p></blockquote><p>这些 ID 的查找结构是一个简单的 Python 字典。</p><h3>数据库表</h3><p>它们有对象表和映射表。</p><p>对象表适用于 pin、板块、评论、用户等。它们有一个映射到 MySQL blob（如 JSON）的本地 ID。</p><p>映射表用于对象之间的关系数据，如将板块映射到用户或将赞映射到 pin。它们有一个映射到完整 ID 和一个时间戳的完整 ID。</p><p>为了提高效率，所有查询都使用 PK（主键）或索引查找。他们删除了所有 JOIN。</p><blockquote><p>译者语，Pinterest 高速发展的时期正好也出现了各种新数据库系统。尤其是 NoSQL 这块，除了 Pinterest 提到过的这些，还有 Riak, Tokyo Cabinet, Voldemort 等。 还是那句话，我们应该采用无聊的技术去构建创新的产品，而不是倒过来。</p></blockquote><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 03 Jan 2024 02:45:54 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10568091</guid>
            <link>https://my.oschina.net/u/6148470/blog/10568091</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[DB-Engines 公布 2023 年度数据库：PostgreSQL]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>DB-Engines<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdb-engines.com%2Fen%2Fblog_post%2F106" target="_blank"> 宣布 </a></u>PostgreSQL 获得 「2023 年度数据库」 称号。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-f3e1b0d42eced287cdf5fe896947622f295.png" referrerpolicy="no-referrer"></p><p>DB-Engines 是全球知名的数据库流行度排行榜网站，其评选年度数据库的标准为：计算数据库当前最新流行度分数（2024 年 1 月）的同比增长量，分数增长最多的即为年度数据库。</p></blockquote><p>颁奖词：</p><h3>年度数据库：PostgreSQL</h3><p><strong>PostgreSQL</strong>&nbsp;已经第四次成为我们的年度数据库了，前三次是在&nbsp;<strong>2017，2018，2020</strong>。Postgres 大约在 35 年前首次发布，从那时起已经发生了翻天覆地的变化，这也是 PostgreSQL 的成功原因 ——&nbsp;<strong>高速进行的稳定改进</strong>，让这种数据库既能站在数据库技术最前沿，同时又能提供一个可靠而稳定的平台。在 2023 年 9 月发布的 PostgreSQL 16 带来了更进一步的性能提升，提供了相比其他数据库更丰富的复制选项。所有这些都使得&nbsp;<strong>PostgreSQL 成为有史以来最成功的开源项目之一</strong>。</p><h3>亚军：Databricks</h3><p>Databricks&nbsp;是一个云上大数据分析/机器学习平台，由 Apache Spark 的创始人们所创立。Databricks 运营着一个围绕着开源工具的生态系统：包括由其所创建或支持的 Apache Spark，以及 Delta Lake（一个开源存储框架）、Delta Sharing（一种用于安全共享数据的开放协议）和 MLflow（一个开源的机器学习平台）。</p><p>Databricks 在我们的排名中保持在第&nbsp;<strong>17&nbsp;</strong>位，比一年前的第&nbsp;<strong>19&nbsp;</strong>位有所上升。</p><h3>季军：Google BigQuery</h3><p>BigQuery&nbsp;是谷歌的全托管云数仓/分析平台，可以使用 SQL 查询处理和分析大型数据集。除了 Serverless 计算的常见优点外，它还内置了机器学习与 BI 功能。BigQuery 是谷歌云平台（GCP）云计算服务套件的一部分。</p><p>BigQuery 在我们的排名中保持在第 19 位，比一年前的第 21 位有所上升。</p><p>让我们祝贺&nbsp;<strong>PostgreSQL</strong>、<strong>Databricks&nbsp;</strong>和谷歌&nbsp;<strong>BigQuery&nbsp;</strong>在 2023 年取得的成功。</p><hr><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>历年 DB-Engines 年度数据库：</strong></p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:1px; border:none; box-sizing:border-box; color:#444444; display:block; font-family:-apple-system,BlinkMacSystemFont,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Segoe UI&quot;,&quot;PingFang SC&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei&quot;,&quot;Helvetica Neue&quot;,Helvetica,Arial,sans-serif; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; line-height:inherit; margin:0px 0px 20px; max-width:100%; orphans:2; overflow:auto; text-align:left; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:776px; word-break:keep-all; word-spacing:0px"><tbody><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">PostgreSQL</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2023</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">Snowflake</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2022</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">Snowflake</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2021</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">PostgreSQL</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2020</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">MySQL</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2019</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">PostgreSQL</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2018</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">PostgreSQL</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2017</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">Microsoft SQL Server</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2016</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">Oracle</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2015</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">MongoDB</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2014</td></tr><tr><td style="border-color:#dddddd; border-style:solid; border-width:1px">MongoDB</td><td style="border-color:#dddddd; border-style:solid; border-width:1px">2013</td></tr></tbody></table></div>
                                    ]]>
            </description>
            <pubDate>Wed, 03 Jan 2024 02:17:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273923/pgsql-is-the-dbms-of-the-year-2023</guid>
            <link>https://www.oschina.net/news/273923/pgsql-is-the-dbms-of-the-year-2023</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[聊聊优化慢 SQL 那些事]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4700705_2331574">高手问答第 312 期 —— 聊聊优化慢 SQL 那些事</a><div class="ui red label horizontal" data-tooltip="置顶">顶</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4700705" class="__user"><span>小白兔爱吃大灰狼</span></a> 发布于，昨天 11:47
                    </div><div class="item">阅读 471</div><div class="item collect-btn " data-id="2331574" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331574" data-obj-type="2">0</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4700705_2331574#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">3</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手问答</a></div><div class="content" id="articleContent"><p><span><span><span>公司在业务发展初期，为了将产品快速投入市场验证商业模式或适应市场需要业务快速迭代，对系统架构设计要求较低。随着业务的不断发展系统和数据量也逐渐庞大，对系统性能和稳定性要求却越来越高，但此时系统性能逐渐开始显露瓶颈，没错～ 这是前期埋下的技术债开始浮出水面。</span></span></span></p><p><span><span><span>那我们如何解决性能瓶颈问题呢？ 老程序员们都知道 70% 以上的性能瓶颈在数据库，因为慢 SQL 导致了性能瓶颈。</span></span></span></p><p><span><span><span>那么如何优化慢 SQL 呢？如何避免慢 SQL 呢？</span></span></span></p><p><strong><span><span>OSCHINA 本期高手问答（1 月 3 日 - 1 月 9 日）我们请来了嘉宾<a href="https://my.oschina.net/u/4090830" rel="nofollow">高峰老师</a>和大家一起聊聊优化慢 SQL 那些事。</span></span></strong></p><p><strong><span><span>可讨论的问题包括但不限于</span></span></strong><strong><span><span>：</span></span></strong></p><ul><li><span><span><span>慢 SQL 发生的场景</span></span></span></li><li><span><span><span>慢 SQL 优化思路</span></span></span></li><li><span><span><span>慢 SQL 优化案例</span></span></span></li><li><span><span><span>如何避免慢 SQL</span></span></span></li><li><span><span><span>分库分表的架构设计</span></span></span></li></ul><p><span><span><span>其他相关的问题，也欢迎提问！</span></span></span></p><h2><span><span><strong><span>嘉宾介绍</span></strong></span></span></h2><p><span><span><span>高峰，京东物流架构师，10 年以上架构设计和性能优化经验，支持京东物流集团国际技术部商家平台订单异步化的架构设计和落地，分布式文件存储系统的架构设计，慢 SQL 性能优化解决方案和优化工作推进等。</span></span></span></p><p><span><span><span>2022</span><span>年获得《京东物流最佳贡献奖》</span></span></span></p><p><span><span><span>2023</span><span>年获得《京东物流年度最佳设计奖》</span></span></span></p><p><img alt="" height="416" src="https://oscimg.oschina.net/oscnet/up-6e65e12d03c100efd3e72f8301428aa0f9d.png" width="300" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">🎁</span><span style="background-color:#ffffff; color:#333333"><span>&nbsp;</span>为了鼓励踊跃提问，问答结束后我们将从提问者中抽取 5 名幸运会员，赠予京东 joy 公仔一个。</span></p><p><img alt="" height="387" src="https://oscimg.oschina.net/oscnet/up-90b2b5aff2ebecc2f6ab155367519f07e00.png" width="350" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手问答一贯的风格，不欢迎任何与主题无关的讨论和喷子。</span></p><p>下面欢迎大家就 「优化慢 SQL 」<span><span>&nbsp;</span>相关</span>问题向<span>&nbsp;<a href="https://my.oschina.net/u/4090830" rel="nofollow">高峰老师</a></span><a href="https://my.oschina.net/klblog" rel="nofollow"><strong><span style="color:#000000">&nbsp;</span></strong></a>提问，直接回帖提问既可。</p></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331574" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331574" data-obj-type="2">0</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331574" data-obj-type="2" data-url="https://www.oschina.net/question/4700705_2331574"><i class="flag red icon"></i>举报</a></div></div>
            ]]>
            </description>
            <pubDate>Wed, 03 Jan 2024 01:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4700705_2331574</guid>
            <link>https://www.oschina.net/question/4700705_2331574</link>
        </item>
        <item>
            <title>
                <![CDATA[高性能 Python 解释器 PyPy 已从 Mercurial 迁移到 Git]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>PyPy 已将其官方仓库和问题跟踪器从 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffoss.heptapod.net%2Fpypy%2Fpypy" target="_blank">https://foss.heptapod.net/pypy/pypy</a> 迁移到 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffoss.heptapod.net%2Fpypy%2Fpypy%E8%BF%81%E7%A7%BB%E5%88%B0https%3A%2F%2Fgithub.com%2Fpypy%2Fpypy%EF%BC%8C%E4%B9%9F%E6%AD%A3%E5%BC%8F%E4%BB%8E" target="_blank">https://github.com/pypy/pypy</a>，也正式从 Mercurial 转移到 Git。</p><p>官方团队仍然认为 Mercurial 是更好的版本控制系统，命名分支模型和用户界面都优于其它选择，但<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffoss.heptapod.net" target="_blank">foss.heptapod.net</a>在 google/bing/duckduckgo 搜索中的索引并不完善，所以人们很难搜索到项目中的 issue。除此之外，还有其它一些迁移原因：</p><ul><li><p>自从 Heptapod 加强了垃圾邮件控制后，经常会收到报告说用户创建的 issue 会被标记为垃圾邮件。</p></li><li><p>开源已经成为 GitHub 的代名词。</p></li><li><p>当前大部分开发都是在修复 issue，如果所有代码都在同一个平台上，那么跟踪交错 issue 就更容易了。</p></li><li><p>社区虽然提出了两个反对迁移的论点。但事实证明没有迁移到 GitHub 会阻碍贡献和报告 issue。</p></li><li><p>希望继续使用 Mercurial 的人可以使用相同的方法在 GitHub 上操作。</p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FGitHub%E6%AF%94foss.heptapod.net" target="_blank">GitHub</a>比<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FGitHub%E6%AF%94foss.heptapod.net" target="_blank">foss.heptapod.net</a>资源更丰富，可以添加 CI 作业来替换一些老化的 buildbot 基础设施。</p></li></ul><p><span style="background-color:#ffffff; color:#333333">PyPy 是一个兼容性强大的&nbsp;Python 解释器，几乎是 CPython 2.7 与 3.6 的直接替代品。</span></p><p>此次变更，具体影响开发操作等信息，可以查看官方通告：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pypy.org%2Fposts%2F2023%2F12%2Fpypy-moved-to-git-github.html" target="_blank">https://www.pypy.org/posts/2023/12/pypy-moved-to-git-github.html</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 11:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273863/pypy-moved-to-git-github</guid>
            <link>https://www.oschina.net/news/273863/pypy-moved-to-git-github</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[适用于 WebAssembly 的 Kotlin 进入 Alpha 阶段]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><section style="line-height: 1.6;letter-spacing: 0px;padding-right: 5px;font-size: 15px;color: rgb(0, 0, 0);margin-bottom: 24px;" data-mpa-powered-by="yiban.io"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section style="justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section style="margin: 30px 0% 10px;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;background-color: rgb(237, 238, 242);align-self: flex-start;flex: 0 0 auto;"><section style="display: flex;width: 100%;flex-flow: column;" powered-by="xiumi.us"><section style="z-index: auto;" powered-by="xiumi.us"><section style="display: flex;flex-flow: row;justify-content: flex-start;transform: translate3d(18px, 0px, 0px);margin-top: -16px;margin-right: 0%;margin-left: 0%;"><section style="display: inline-block;vertical-align: top;width: 15%;flex: 0 0 auto;height: auto;align-self: flex-start;"><section style="text-align: center;margin-top: -16px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021388" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/579d942e-3813-439a-be37-eb53b5387a74.png" data-type="png" data-w="707" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 auto;align-self: flex-start;min-width: 10%;height: auto;"><section style="transform: translate3d(5px, 0px, 0px);" powered-by="xiumi.us"><section style="text-align: justify;color: rgb(115, 119, 173);padding-right: 7px;padding-left: 7px;line-height: 1.2;"><p style="text-wrap: wrap;"><strong>记得加关注， Kotlin 之路不迷路！</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section style="text-align: justify;font-size: 12px;color: rgb(221, 18, 101);line-height: 1.2;"><p style="text-wrap: wrap;">&nbsp; &nbsp; Kotlinlang.org</p></section><grazie-editor-wrapper></grazie-editor-wrapper></section></section></section></section></section></section></section></section></section></section></section><section style="" powered-by="xiumi.us"><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;"><span style="color: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: inherit;letter-spacing: 0px;">Kotlin/Wasm 是新推出的 Kotlin Multiplatform 目标平台，现已达到 Alpha 状态！</span><span style="color: inherit;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: inherit;letter-spacing: 0px;">以下是值得注意的更改：</span></p></section></section><section style="font-size: 15px;color: rgb(33, 33, 33);line-height: 1.6;letter-spacing: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;margin-bottom: 24px;"><ul style="font-size: inherit;color: inherit;line-height: inherit;padding-left: 32px;" class="list-paddingleft-1"><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p>JetBrains 已将 Kotlin/Wasm 提升到<strong><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.org%2Fdocs%2Fcomponents-stability.html%23stability-levels-explained" textvalue="Alpha" linktype="text" imgurl="" tab="outerlink" data-linktype="2">Alpha</a></strong>&nbsp;版本，让您可以亲自上手尝试。您的反馈将影响使用 Kotlin 构建 Web 应用程序的未来！</p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">作为 Alpha 版本，Kotlin/Wasm 已经可以在预生产场景中使用，但许多方面仍待完善。我们需要社区的帮助来确定 Kotlin/Wasm 的相关决策并确定其优先级。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">Compose for Web（目前处于实验阶段）由 Kotlin/Wasm 提供支持。两种技术互相配合，让您完全使用 Kotlin 为 Web 应用程序创建声明式用户界面。</span><span style="color: rgb(70, 120, 178);font-size: 14px;letter-spacing: 0px;text-align: left;"></span></p></li></ul><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021386" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ef2cad5e-409f-400d-8c7e-ec6679c67f45.png" data-type="png" data-w="500" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding-left: 10px;"><section style="text-align: left;margin-top: 10px;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;"><p><strong>WebAssembly：</strong></p><p><strong>最新的 Kotlin Multiplatform 目标</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="margin-top: 2px;margin-bottom: 8px;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">对于以浏览器为目标的语言，<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwebassembly.org%2F" textvalue="WebAssembly" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>WebAssembly</strong></a>&nbsp;正在成为其标准编译目标。借助 Kotlin/Wasm，您能够通过 Kotlin Multiplatform 使用这个新目标。我们最初在<strong><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.org%2Fdocs%2Fwhatsnew1820.html%23new-kotlin-wasm-target" textvalue="Kotlin 1.8.20" linktype="text" imgurl="" tab="outerlink" data-linktype="2">Kotlin 1.8.20</a></strong>&nbsp;中作为实验性技术引入 Kotlin/Wasm，此后对其进行了改进和完善。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">Kotlin 是一种自动内存管理语言，建立在最近达到<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FWebAssembly%2Fmeetings%2Fblob%2Fmain%2Fprocess%2Fphases.md%234-standardize-the-feature-working-group" textvalue="第 4 阶段（标准化）" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>第 4 阶段（标准化）</strong></a>的<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FWebAssembly%2Fgc%2Fblob%2Fmain%2Fproposals%2Fgc%2FOverview.md" textvalue="垃圾回收提案" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>垃圾回收提案</strong></a>的基础上， 已在许多主流浏览器中默认启用。例如，最新版本的 Chrome 和 Firefox 都可以运行 Kotlin/Wasm 应用程序，无需任何调整。虽然 Safari 尚未支持 Wasm 垃圾回收，但 JavaScriptCore 中必需功能的实现已在推进。</p><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021385" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ef2cad5e-409f-400d-8c7e-ec6679c67f45.png" data-type="png" data-w="500" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding-left: 10px;"><section style="text-align: left;margin-top: 10px;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;"><p><strong>Kotlin/Wasm 使用入门</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="margin-top: 2px;margin-bottom: 8px;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><p style="text-align: justify;font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="color: inherit;font-size: inherit;letter-spacing: 0px;text-align: justify;">开始使用 Kotlin/Wasm 的便捷方式是查看</span><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.org%2Fdocs%2Fwasm-overview.html" textvalue="使用入门页面" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong style="color: inherit;font-size: inherit;letter-spacing: 0px;text-align: justify;">使用入门页面</strong></a><span style="color: inherit;font-size: inherit;letter-spacing: 0px;text-align: justify;">。</span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;text-align: justify;">该页面提供了技术概览以及设置 Kotlin/Wasm 应用程序的说明。</span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;text-align: justify;">您还会看到项目和展示 Kotlin/Wasm 不同方面的示例项目链接，其中的一些项目阐释了如何在浏览器中使用以及配合 Compose Multiplatform 等。</span></p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-imgfileid="100021389" data-ratio="0.4685185185185185" src="https://oscimg.oschina.net/oscnet/1cb76a75-b0f2-49e1-bf55-5947993b76fa.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;" title="Kotlin/Wasm 进入 Alpha 阶段：详细探索技术和查看示例项目" referrerpolicy="no-referrer"></figure></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplay.kotl.in%2Fwasm" textvalue="Kotlin Playground" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>Kotlin Playground</strong></a>&nbsp;现在也支持 Kotlin/Wasm，您可以直接在浏览器中编写第一个 WebAssembly 代码段并探索 Kotlin/Wasm 的功能。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">为了帮助您超越初学 WebAssembly 时的「Hello World」示例，我们还将 `kotlinx` 库套件引入 Kotlin/Wasm， 包括<strong><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlinx-atomicfu" textvalue="kotlinx-atomicfu" linktype="text" imgurl="" tab="outerlink" data-linktype="2">kotlinx-atomicfu</a>、<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlinx.coroutines" textvalue="kotlinx.coroutines" linktype="text" imgurl="" tab="outerlink" data-linktype="2">kotlinx.coroutines</a>、<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlinx.serialization" textvalue="kotlinx.serialization" linktype="text" imgurl="" tab="outerlink" data-linktype="2">kotlinx.serialization</a>、<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlinx-datetime" textvalue="kotlinx-datetime" linktype="text" imgurl="" tab="outerlink" data-linktype="2">kotlinx-datetime</a> 和 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlinx-io" textvalue="kotlinx-io" linktype="text" imgurl="" tab="outerlink" data-linktype="2">kotlinx-io</a></strong>。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">用于构建网络应用程序的 JetBrains 框架<strong><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fktor.io%2F" textvalue="Ktor" linktype="text" imgurl="" tab="outerlink" data-linktype="2">Ktor</a></strong>&nbsp;也即将登陆 WebAssembly。在下一个版本中，您将能够使用 Ktor 的 HTTP 客户端直接从 Kotlin/Wasm 代码发起网络请求。</p><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021387" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ef2cad5e-409f-400d-8c7e-ec6679c67f45.png" data-type="png" data-w="500" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding-left: 10px;"><section style="text-align: left;margin-top: 10px;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;"><p><strong>Compose Multiplatform：</strong></p><p><strong>由 Kotlin/Wasm 提供支持</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="margin-top: 2px;margin-bottom: 8px;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">Kotlin/Wasm 未绑定到任何特定 UI 框架， 是在浏览器中运行 Kotlin 代码的通用方式。不过，它是 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fzh-cn%2Flp%2Fcompose-multiplatform%2F" textvalue="Compose Multiplatform" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>Compose Multiplatform</strong></a><span style="font-size: inherit;color: inherit;letter-spacing: 0px;">&nbsp;实验性 Web 目标的底层技术，Compose Multiplatform 是 JetBrains 基于 Google 的 Jetpack Compose 打造的声明式多平台 UI 工具包。Compose Multiplatform for Web 使用基于画布的渲染，您可以使用与其他平台上相同的布局和组件。它直接配备了 Material 和 Material 3 设计组件。</span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;"></span></p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">借助 Compose Multiplatform，您可以构建以最重要平台为目标的共享应用：Android 和 iOS、桌面，以及浏览器（得益于 Kotlin/Wasm 的强大功能）。要开始构建您自己的共享 UI，您可以使用 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkmp.jetbrains.com%2F" textvalue=" Kotlin Multiplatform Web 向导" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>Kotlin Multiplatform Web 向导</strong></a><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">生成项目，向导现在也实验性地支持 Kotlin/Wasm 目标。</span></p><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021393" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ef2cad5e-409f-400d-8c7e-ec6679c67f45.png" data-type="png" data-w="500" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding-left: 10px;"><section style="text-align: left;margin-top: 10px;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;"><p><strong>性能</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="margin-top: 2px;margin-bottom: 8px;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">WebAssembly 从一开始就被设计为语言的编译目标，这意味着 Kotlin 编译器可以将源代码转换为高性能 WebAssembly 字节码。我们定期在 Kotlin/Wasm 上运行<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlin-wasm-benchmarks" textvalue="基准测试" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>基准测试</strong></a><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">，确保其运行时性能。由于 Kotlin/Wasm 仍处于 Alpha 阶段，团队将继续推动性能改进，但 Kotlin/Wasm 在几乎所有宏基准测试中都已经优于 Kotlin/JS：</span></p><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="" powered-by="xiumi.us"><p style="text-wrap: wrap;"><span style="color: inherit;font-size: inherit;letter-spacing: 0px;"></span></p></section></section><figure style="font-size: inherit;color: inherit;line-height: inherit;"><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-imgfileid="100021392" data-ratio="0.5814814814814815" src="https://oscimg.oschina.net/oscnet/26c868c4-e143-46ea-8131-f9dc660cd81d.png" data-type="png" data-w="1080" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;" title="" referrerpolicy="no-referrer"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"></figcaption></figure></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">同样，在 Kotlin/Wasm 上运行的 Compose Multiplatform 已经表现出良好的性能特征，执行速度与在 JVM 上运行的相同应用程序相当：</p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-imgfileid="100021390" data-ratio="0.36666666666666664" src="https://oscimg.oschina.net/oscnet/2c06ec2e-0aa6-4140-b3ea-888e6e1806ab.png" data-type="png" data-w="1080" height="564" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;" width="1538" referrerpolicy="no-referrer"></figure><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">这些基准测试结果来自我们在最新版本 Google Chrome 中的测试，但我们在测试的其他浏览器中也观察到相似结果。</p><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021391" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ef2cad5e-409f-400d-8c7e-ec6679c67f45.png" data-type="png" data-w="500" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding-left: 10px;"><section style="text-align: left;margin-top: 10px;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;"><p><strong>正在推进的工作</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="margin-top: 2px;margin-bottom: 8px;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">作为一项处于 Alpha 阶段的技术，Kotlin/Wasm 正迅速发展，团队正在全力开发改进和增强。因此，仍有许多领域尚待完善。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">目前，Kotlin/Wasm 中的调试支持有限，我们正在努力改进其功能。我们也意识到，在以 Web 为目标时，捆绑包大小是一个重要因素，我们希望进一步优化编译器生成的输出，特别是对于 Compose Multiplatform 项目。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">随着 WebAssembly 持续发展，我们希望在新提案到来时加以利用 – 无论是<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FWebAssembly%2Fstack-switching%2Fblob%2Fmain%2Fproposals%2Fstack-switching%2FOverview.md" textvalue="堆栈切换" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>堆栈切换</strong></a><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">、<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FWebAssembly%2Fthreads%2Fblob%2Fmain%2Fproposals%2Fthreads%2FOverview.md" textvalue="线程" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>线程</strong></a></span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">，还是其他。我们还在向 Kotlin 引入对 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcomponent-model.bytecodealliance.org%2F" textvalue="WebAssembly Component Model" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>WebAssembly Component Model</strong></a><strong>&nbsp;</strong></span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">的支持，这将用于构建可互操作的 Wasm 库和应用程序。我们还在努力使 Kotlin/Wasm 成为浏览器之外开发的良好目标，包括对 WASI (WebAssembly System Interface) 的支持。作为 WebAssembly Community Group 的一部分，通过与 WebAssembly VM 的供应商积极合作，我们希望确保 Kotlin/Wasm 无论在何处都能提供出色的体验。</span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;"></span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;"></span></p><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="" powered-by="xiumi.us"><p style="text-wrap: wrap;"><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">我们的目标是为您提供卓越的开发者体验，并确保其在性能和捆绑包大小方面满足您的要求。</span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">随着我们取得进展，我们将为您提供动态并分享更多信息！</span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;"></span></p></section></section><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021394" data-ratio="1" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ef2cad5e-409f-400d-8c7e-ec6679c67f45.png" data-type="png" data-w="500" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding-left: 10px;"><section style="text-align: left;margin-top: 10px;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;"><p><strong>加入社区以获取动态并分享反馈！</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="margin-top: 2px;margin-bottom: 8px;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><p style="text-align: justify;font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="color: inherit;font-size: inherit;letter-spacing: 0px;text-align: justify;">如果您想与其他对 Kotlin/Wasm 感兴趣的团队和开发者交流，我们邀请您加入 Kotlin Slack 上的讨论（在<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsurveys.jetbrains.com%2Fs3%2Fkotlin-slack-sign-up" textvalue="此处" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>此处</strong></a></span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">获取邀请）。在 </span><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fslack-chats.kotlinlang.org%2Fc%2Fwebassembly" textvalue="#webassembly" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">#webassembly</span></strong></a><strong><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">&nbsp;</span></strong><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">频道中，您可以找到有关 Kotlin 和 WebAssembly 的讨论。</span></p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">Kotlin/Wasm 处于 Alpha 阶段，我们希望确保根据用户的需求继续发展这项技术。报告问题、告诉我们您认为缺少的 API，以及请求您希望看到的功能，帮助我们为您做出改进。您可以向 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutrack.jetbrains.com%2Fissues%2FKT" textvalue=" Kotlin YouTrack 项目" linktype="text" imgurl="" tab="outerlink" data-linktype="2"><strong>Kotlin YouTrack 项目</strong></a><span style="color: inherit;font-size: inherit;letter-spacing: 0px;">添加问题。</span><span style="color: inherit;font-size: inherit;letter-spacing: 0px;"></span></p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">我们很高兴与 Kotlin 共同迈出下一步，也期待看到您使用 Kotlin/Wasm 的开发成果！</p><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;"><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 48px;align-self: center;flex: 0 0 auto;height: auto;"><section style="margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-imgfileid="100021396" data-ratio="1" data-s="300,640" data-type="png" data-w="500" style="vertical-align: middle;width: 100%;" src="https://oscimg.oschina.net/oscnet/ef2cad5e-409f-400d-8c7e-ec6679c67f45.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 100 100 0%;height: auto;padding-left: 10px;"><section style="text-align: left;margin-top: 10px;" powered-by="xiumi.us"><section style="color: rgb(42, 8, 69);font-size: 24px;line-height: 1.2;"><p><strong>另请参阅</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="margin-top: 2px;margin-bottom: 8px;" powered-by="xiumi.us"><section style="background-color: rgb(120, 85, 245);height: 1px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section></section><ul style="font-size: inherit;color: inherit;line-height: inherit;padding-left: 32px;" class="list-paddingleft-1"><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p>关于 Kotlin/Wasm 的讲座和视频：</p><p><span style="font-size: 14px;color: rgb(70, 120, 178);">https://kotl.in/wasm-pl</span><br></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p>Kotlin 1.8.20 最新变化：新的 Kotlin/Wasm 目标：</p><p style="font-size: 15px;color: rgb(33, 33, 33);line-height: 1.6;letter-spacing: 0px;font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;"><span style="font-size: 14px;color: rgb(70, 120, 178);">https://kotlinlang.org/docs/whatsnew1820.html#new-kotlin-wasm-target</span><br></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MzkxMzg3MQ%3D%3D%26mid%3D2247483831%26idx%3D1%26sn%3D9041056a4ee0fbdbee39532d9e239c20%26chksm%3Dcf416457f836ed419074f8f8f3feec4ab9aa834a134f4087f67316d587697d25c2a060066973%26scene%3D21%23wechat_redirect" textvalue="Compose Multiplatform for iOS 现已进入 Alpha 阶段 | Kotlin 博客" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">Compose Multiplatform for iOS 现已进入 Alpha 阶段 | Kotlin 博客</a></p></li></ul></section><section style="font-size: 15px;color: rgb(0, 0, 0);padding-right: 5px;margin-bottom: 24px;"><section style="margin: 10px 0% 8px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding-left: 8px;align-self: flex-start;flex: 0 0 auto;"><section style="" powered-by="xiumi.us"><section style="color: rgba(0, 0, 0, 0.5);text-align: justify;font-size: 12px;"><p style="text-wrap: wrap;"><strong>本博文英文原作者：</strong></p><p style="text-wrap: wrap;"><strong>Sebastian Aigner</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section></section></section><section style="margin-top: 10px;margin-right: 0%;margin-left: 0%;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;background-position: 97.529% 66.6681%;background-repeat: repeat;background-size: 171.01%;background-attachment: scroll;align-self: flex-start;flex: 0 0 auto;height: auto;background-image: url(&quot;https://oscimg.oschina.net/oscnet/dd16b9d3-a2a8-458d-9145-8d5f564b01ea.png&quot;);"><section style="text-align: justify;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;padding: 26px;align-self: flex-start;flex: 0 0 auto;"><section style="margin-top: -9px;margin-bottom: 7px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(248, 248, 248);"><p style="text-wrap: wrap;"><strong>这就是 Kotlin 编程语言</strong></p><p style="text-wrap: wrap;"><strong>简洁、跨平台、且有趣！</strong></p></section><grazie-editor-wrapper></grazie-editor-wrapper></section><section style="" powered-by="xiumi.us"><section class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-id="Mzg4MzkxMzg3MQ==" data-pluginname="mpprofile" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/y4ibuu6gd7d4NyzPduLLqtqddBasicL77gAgbLQD89CyYm1n7icODFhBr3xMoloOA7yicfjR8Bv0oaRP3CJuRLIO4Q/0?wx_fmt=png" data-nickname="Kotlin 开发者" data-alias="" data-signature="现代、简洁、安全的编程语言，由 JetBrains 打造。面向服务器、Android、Web 和原生平台，提供多种在平台间重用代码的方式以实现高效编程。官网：kotlinlang.org" data-from="2" data-is_biz_ban="0"></mp-common-profile></section></section><section style="text-align: center;margin-top: 7px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 45%;height: auto;"><img class="rich_pages wxw-img" data-imgfileid="100021395" data-ratio="0.4119760479041916" data-s="300,640" src="https://oscimg.oschina.net/oscnet/e47e85fb-81ac-4f8a-888a-51ef56d0a2bd.png" data-type="png" data-w="835" style="vertical-align: middle;width: 100%;" referrerpolicy="no-referrer"></section></section></section></section></section></section></section><p style="display: none;margin-bottom: 24px;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - JetBrains（JetBrainsChina）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 10:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5494143/blog/10398400</guid>
            <link>https://my.oschina.net/u/5494143/blog/10398400</link>
            <author>
                <![CDATA[JetBrains 中国]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[出售破解无人机「限高、限飞」程序被判刑]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日南昌法院介绍了一起「全省首例破解无人机系统禁飞限飞限高程序案」。</p><blockquote><p><img height="1224" src="https://oscimg.oschina.net/oscnet/up-4faa1c12e0cd8f028545311b02c55fdda4f.png" width="1472" referrerpolicy="no-referrer"></p></blockquote><p>据介绍，犯罪嫌疑人张某曾花费 40 欧元，在外国一网站购买了飞行解禁证书程序。随后，他通过二手交易平台，<strong>向国内消费者出售解除「无人机限飞、限高、禁飞」等服务，每台收取 400-1000 元服务费。</strong>在被抓获前，张某已解禁了 21 台（次）无人机，违法收入 15060 元。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6646f384a74184ff3010579aed13c3c1978.png" referrerpolicy="no-referrer"></p><p>经审理，张某犯「提供侵入、非法控制计算机信息系统程序罪」，<strong>判处有期徒刑六个月，缓刑一年，处罚金人民币 5000 元，并没收作案工具及违法所得 15060 元。</strong></p><p>据悉，我国无人机禁飞高度限制制度规定，轻型无人机的飞行高度限制为 120 米，与机场、公共建筑的距离为 500 米。针对特定区域，如机场、火车站、政府机关、敏感单位等重点场所，实行更严格的禁飞措施。</p><p>此外，新版《无人驾驶航空器飞行管理暂行条例》于 2024 年 1 月 1 日起施行，要求个人非经营性活动，<strong>无人机均需实名登记</strong>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 10:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273856</guid>
            <link>https://www.oschina.net/news/273856</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MegEngine 版本最新发布！新增支持寒武纪思元系列 AI 芯片训练和推理]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，MegEngine 在 v1.13.3 正式完成了与国内 AI 芯片独角兽寒武纪旗下云端人工智能处理器芯片的兼容性适配。MegEngine 与，寒武纪目前完成了常见 cv 模型的算子适配，这也标志着寒武纪端云一体的人工智能芯片，与 MegEngine 深度学习框架的成功融合。</p><h2>如何在寒武纪上运行 MegEngine</h2><h3>MegEngine 寒武纪安装说明</h3><ul><li>安装的前置条件： 
  <ul><li>安装寒武纪 MLU 驱动，sdk-1.13.0-driver</li><li>安装 cntoolkit, cnnl, cnnl_extra, cncl, cnlight</li><li>安装 MagicMind</li></ul></li><li>安装方式：通过源码编译安装 
  <ul><li>下载源码&amp;编译</li></ul></li></ul><pre><code class="language-Python">git clone https://github.com/MegEngine/MegEngine.git megengine
cd megengine
# 构建用于编译并打包的 docker 镜像
./scripts/whl/manylinux2014/build_image.sh
# 下载 mkl 依赖
./third_party/install-mkl.sh
# 编译并打包
export ALL_PYTHON="39"  # 指定编译的 python 版本，可选 36m 37m 38 39 310
export NEUWARE_HOME=/usr/local/neuware # 指定寒武纪 sdk 安装路径
./scripts/whl/manylinux2014/build_wheel_common.sh -sdk neuware113
</code></pre><ul><li>安装与验证生成的 whl 包 
  <ul><li>安装生成的 whl 包，并进行测试</li></ul></li></ul><pre><code class="language-Python">cd megngine
pip3 install ./scripts/whl/manylinux2014/output/wheelhouse/neuware113/MegEngine-1.9999.0+neuware113-cp39-cp39-manylinux2014_x86_64.whl
# 验证是否编译成功
python3 -c "import megengine as mge; print(mge.is_cambricon_available()); print(mge.Tensor([1.]))"
</code></pre><ul><li><ul><li>输出类似以下内容，表示安装成功</li></ul></li></ul><pre><code class="language-Python">True
06 14:03:06[mgb] cambricon: card0: name=`MLU370' dyn_mem_reserve=0.00MiB alignment=0x100
Tensor([1.], device=xpux:0)
</code></pre><ul><li>MegEngine 寒武纪训练示例见 cambircon_train</li></ul><h2>关于寒武纪</h2><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cambricon.com%2Findex.php%3Fm%3Dcontent%26c%3Dindex%26a%3Dlists%26catid%3D7%23nav2" target="_blank">寒武纪</a>成立于 2016 年，专注于人工智能芯片产品的研发与技术创新，致力于打造人工智能领域的核心处理器芯片，让机器更好地理解和服务人类。寒武纪提供云边端一体、软硬件协同、训练推理融合、具备统一生态的系列化智能芯片产品和平台化基础系统软件。寒武纪产品广泛应用于服务器厂商和产业公司，面向互联网、金融、交通、能源、电力和制造等领域的复杂 AI 应用场景提供充裕算力，推动人工智能赋能产业升级。</p><h2>关于 MegEngine</h2><p>开源深度学习框架旷视天元（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMegEngine" target="_blank">MegEngine</a>）是旷视自主研发的国产工业级深度学习框架 ，是旷视新一代 AI 生产力平台 Brain++ 的最核心组件，在 2020 年 3 月正式向全球开发者开源 。MegEngine 凭借其训练推理一体、超低硬件门槛和全平台高效推理 3 大核心优势，能够帮助企业与开发者大幅节省产品从实验室原型到工业部署的流程，真正实现小时级的转化能力。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 09:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5265910/blog/10560224</guid>
            <link>https://my.oschina.net/u/5265910/blog/10560224</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openKylin 全方位赋能算能 RISC-V 产品！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span>近日，在 openKylin 社区 RISC-V SIG 组的推动下，<strong>openKylin 实现了对算能 RISC-V 产品的全方位支持</strong>，涵盖了<strong>桌面环境、软件生态、容器化部署</strong>和<strong>人工智能</strong>等关键领域。</span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span>在桌面环境方面，openKylin 成功适配算能开发板 Milk-V Pioneer，并搭载 UKUI 桌面环境，保证系统运行的稳定性和流畅性，用户友好性高。Milk-V Pioneer 是算能公司推出的创新性产品，以 SOPHON SG2042 高性能处理器为核心，采用标准的 mATX 外形设计，提供了类似 PC 的丰富接口，确保了良好的兼容性和可扩展性，该产品是开发者体验 RISC-V 前沿技术的理想选择。</span></p><div><p style="text-align:center"><img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-45e936cfd0aef30557ee6198e8a7d9883f1.png" width="1920" referrerpolicy="no-referrer"></p><p style="color:#999999; margin-left:0; margin-right:0; text-align:center">图 1 风格现代化的桌面</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span>在软件生态方面，openKylin RISC-V 版本从日常使用、办公需求、影音娱乐等多个角度提供支持，全方位满足用户需求。</span></p><ul><li><span>集成当前主流操作系统中的日常应用和工具，如压缩包管理工具、文件管理器、多语言管理器、电脑管家、设置等，使用户可以方便地定制、使用和管理自己的操作系统。</span></li><li><span>集成和适配当前主流的开源办公工具和应用，包括浏览器 Firefox、文本编辑器、文档查看器、输入法管理工具 fcitx5、图片查看器、截图工具等，可以覆盖用户日常轻度办公的大部分场景。</span></li><li><span>集成音乐播放器、视频播放器，以便满足用户基本的影音娱乐需求。</span></li></ul><div><p style="text-align:center"><img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-148c7c327046e55257badcb57aea0aa7a45.png" width="1920" referrerpolicy="no-referrer"></p><p style="color:#999999; margin-left:0; margin-right:0; text-align:center">图 2 内置麒麟管家</p></div><div><p style="text-align:center"><img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-5901bd6b4fc9bc18fed85fbe4dd8e553c41.png" width="1920" referrerpolicy="no-referrer"></p><p style="color:#999999; margin-left:0; margin-right:0; text-align:center">图 3 简洁易用的文件系统</p></div><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e572d5b19e0cdc36ca9ba03b2dbe3a7e7d.png" referrerpolicy="no-referrer"></p><p style="color:#999999; margin-left:0; margin-right:0; text-align:center">图 4 文档查看器</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span>在容器化方面，RISC-V SIG 组在 openKylin RISC-V 平台桌面操作系统镜像的基础上，构建了 openKylin RISC-V 版本 docker 镜像。该镜像已在算能 RISC-V 通用云开发空间中安装运行，并在 docker hub 平台提供下载页面。</span></p><div><p style="text-align:center"><img alt="" height="591" src="https://oscimg.oschina.net/oscnet/up-6aa9bc1661804477c58f46d995226c32511.jpg" width="1291" referrerpolicy="no-referrer"></p><p style="color:#999999; margin-left:0; margin-right:0; text-align:center">图 5 openKylin RISC-V 版本 docker 镜像下载页面</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span>在人工智能方面，RISC-V SIG 组积极进行相关软件适配工作，目前已完成 Google 编译工具 bazel 在 openKylin RISC-V 平台的适配工作，并正在推动主流 AI 软件，如 TensorFlow、PyTorch 等的适配工作，为用户提供 AI 方面的支持。</span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span>经过全面测试，openKylin 在算能 RISC-V 产品上运行稳定，功能及稳定性良好。未来，随着 RISC-V 生态的不断扩展和算能 RISC-V 产品的不断迭代，我们将持续对 openKylin RISC-V 版本进行维护、扩展和适配，以确保用户始终能够体验到最先进的技术和功能。</span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><strong><span style="color:#ffffff"><span style="background-color:#0060e8">关于 RISC-V SIG</span></span></strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span>openKylin RISC-V SIG 主要负责 RISC-V 架构开源软件包的维护，发布 openKylin 的 RISC-V 版本，进行软件包构建、系统构建等，欢迎所有对 RISC-V 开发平台技术方向感兴趣的爱好者加入到 RISC-V SIG！</span></p><ul><li><span>SIG 主页：</span></li><li><span><span style="color:#0060e8">https://gitee.com/openkylin/community/tree/master/sig/RISC-V</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 09:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273849</guid>
            <link>https://www.oschina.net/news/273849</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「北大-智元机器人联合实验室」正式成立]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京大学计算机学院官网<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcs.pku.edu.cn%2Finfo%2F1263%2F2856.htm" target="_blank">公告称</a>，「北大-智元机器人联合实验室」现已正式成立。</p><p><img alt="" height="334" src="https://oscimg.oschina.net/oscnet/up-e05329fa21e140b58847f470224b04c6f50.jpg" width="500" referrerpolicy="no-referrer"></p><p>智元机器人由「华为天才少年」彭志辉（稚晖君）等来自多家大厂的科技人才联合创立，于 2023 年 12 月完成新一轮融资。</p><p>公告指出，「北大-智元机器人联合实验室」的成立对校企合作与协同创新具有重要意义，并将在着力解决关键具身智能技术问题的同时，培养领域内的国际顶尖技术人才。北京大学将与智元机器人协同共进、持续探索，推动前沿技术创新与产业化的链接，为国家具身智能及通用人形机器人的产业发展贡献力量。</p><p>稚晖君在联合实验室的揭牌仪式上介绍了智元机器人的发展历程，强调了通用人形机器人、具身智能技术对国家科技创新和经济发展的重要意义。</p><p>并表示，作为一家 2023 年上半年成立的新兴科技企业，智元已经在决策模型、任务规划、环境感知、通用抓取等环节具备了领先的技术积累。智元非常看重校企合作的发展模式，将与北京大学紧密配合，实现研发成果落地，推动具身智能和通用机器人产业的发展和迭代。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 09:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273848</guid>
            <link>https://www.oschina.net/news/273848</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024 的开源世界：或有更多企业转向商业许可]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>未来一年，可能会有更多公司将其开源许可证变更为商业许可证、出现新一轮的监管浪潮以及 GenAI 的持续发展。</p></blockquote><p>开源世界在 2023 年伊始就充满了不确定性，科技界大面积裁员、经济动荡不安。生成式 AI 在过去的一年里取得了突飞猛进的发展，而 HashiCorp 许可证的变更则表明，风投公司认为开源模式的前景并不乐观。</p><p>在此背景下，Rust 基金会执行董事兼 CEO Rebecca Rumbul 在接受 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthenewstack.io%2Fopen-source-in-2024-more-volatility-more-risk-more-ai%2F" target="_blank">The New Stack</a> 的采访时，就 2024 年的市场发展发表了一些看法。她认为，目前市场上的乐观情绪已经日渐浓厚。在大幅削减开发人员关系职位之后，出现了一些空缺需要填补；削减职位可能是一种虚假经济。Rumbul 指出，「与开源社区保持良好的关系可以带来巨大的商业回报」。</p><p>不过企业还可以通过一些更直接的方式确保商业回报。譬如今年 8 月，HashiCorp 决定将包括 Terraform 在内的整个产品线转为商业源码许可，这一决定在业界引起了轩然大波；同时也引出了一个获得了 Linux 基金会的支持的 OpenTofu 分叉。</p><p>HashiCorp CEO David McJannet 在其客户会议上曾对整个基金会模式提出质疑，并表示 Linux 基金会对 OpenTofu 的支持是开源创新的悲剧。这最终可能意味着"硅谷将不再有开源公司"。</p><p>Linux 基金会欧洲区总经理 Gabriele Columbro 则评论称，今后可能会出现更多的许可证转换--以及随之而来的分叉：「市场上由风投支持的开源初创公司越多，就越会有一部分公司在某一时刻决定转换许可证，因为这样做对公司最有利。」</p><p>他认为，HashiCorp 完全有权利转换许可。但这一事件可能会鼓励用户更多地考虑开源和项目开放治理之间的区别，从而可能会加强基金会的作用。「当你选择依赖某个开源项目时，你可能会问自己这个问题。它是否只是开源，任何一家专有公司都可以随时打我个猝不及防？」</p><p>Columbro 指出，使用 Terraform 等产品的大公司可能会面临数十万美元的账单，仅仅是为了弄清许可证变更对公司的影响。"我可以想象，摩根大通或谷歌必须花多少钱才能弄清楚他们在 Terraform 上的立场并进行影响评估"。鉴于大企业（特别是在金融领域）对开源的接受程度越来越高，这些计算也变得越来越重要。</p><p>"我认为，我们正处于金融服务和金融科技完全意识到自己是一个以技术为中心的行业的风口浪尖上，因此也会像大型科技公司那样拥抱开源，将其作为数字化转型的核心支柱，同时也是行业结构的核心支柱。"</p><p>Percona 社区负责人 Joe Brockmeier 表示，许多执行团队已经在考虑，是否要冒着更大的风险和弊端转而采用闭源模式。</p><p>但 OpenUK CEO Amanda Brock 认为，这些并不意味着行业不应该重新审视许可和相关问题。现在正是在持有不同观点的不同派别之间进行更开放的对话的时机，让用户、贡献者和社区之间产生更多的了解。</p><p><strong>开源和 GenAI</strong></p><p>AI（尤其是生成式 AI）正在给整个科技界和社会带来巨大冲击，「统一战线可以说比以往任何时候都更加重要」。</p><p>DataStax 开发者关系副总裁 Patrick McFadin 认为，大众对于 GenAI 的隐私问题已经"严重恐慌"，这一情绪将导致对 OpenAI 和超级计算机的反抗。「监管开源几乎是不可能的。一旦事情被公开，你就无法对其进行监管。开源[大语言模型]已经存在，它们正在接受训练，而且它们开始变得比 GPT-4 更好，这使得监管它们变得更加困难。」</p><p>Brock 没有 McFadin 这么末世论，但也同样严肃。「当我们看到人工智能正常化，人们开始更好地理解它是什么并不再被炒作所影响时，我们将更好地讨论开源的含义以及开源如何融入人工智能」。这将导致「与开源社区及其代表的参与，而不仅仅是公司的参与，这是目前全球的一个趋势。」</p><p>她认为，中国参加了在英国布莱切利公园举行的人工智能安全会议是一个非常重要的节点，表明监管对话正在从主权转移到关注跨界合作。这将产生更广泛的影响，促进国际开源技术行业的发展，其中包括强大的本地生态系统和在全球范围内开展合作的熟练劳动力。</p><p><strong>开源监管的前景如何？</strong></p><p>目前，美国和欧盟都已经围绕人工智能制定了立法和监管，但具体的成效还需等到 2024 落地以后才能凸显。欧盟的《网络弹性法案》也将于 2024 年生效，其最近宣布的修订版貌似降低了对开源的限制，不过最终文本尚未公布。</p><p>但要加强科技领域的国际合作还存在很多障碍，美国的制裁已经导致了一些对开源项目的贡献被拒。Rumbul 称，「如果开源只是以美国为中心，或者与美国的外交政策保持一致，那将是非常糟糕的。这不是开源的精神。」</p><p>针对开源在 2024 年的可持续性问题，Rumbul 也同样表达了担忧。「开源社区创造了一些精美的东西，但再精美的东西也会被人从桌子上打下来，摔得粉碎。 」。不过她也认为，虽然"风险"可能比以前更高，但风险并不总是一个坏词，它总是和机遇并存。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 09:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273844/open-source-in-2024</guid>
            <link>https://www.oschina.net/news/273844/open-source-in-2024</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MySQL 5.7、魔趣、李跳跳……盘点 2023「停更」的（开源）项目和网站]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年，许多陪伴我们很久的网站和（开源）项目纷纷挥手道别，或退役、或停更、或 EOL、或倒闭……</p><hr><h4><a href="https://www.oschina.net/news/224302/mokee-eol">开源 ROM 魔趣 (Mokee) 创始人宣布项目结束</a></h4><p>国内最大的非营利性开源 ROM 项目魔趣 (Mokee) 在 2023 年 1 月 7 日正式宣布关闭。魔趣下载页面所有固件已备份到 SourceForge。项目作者马丁龙猪发文称，「刷机的时代其实早已落幕，迟迟下不定决心只是希望能让魔趣多存续一些时间，但该来的终究会来。」</p><p><img src="https://oscimg.oschina.net/oscnet/up-a03702d6043769216aed5f1c60b250af639.png" referrerpolicy="no-referrer"></p><p>魔趣开源项目 20121212 ~ 20230107</p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/225416/afnetworking-officially-deprecated">网络框架 AFNetworking 停止维护</a></h4><p>在停更近 3 年后，适用于苹果旗下多个操作系统 (iOS、macOS、watchOS 和 tvOS) 的网络框架 AFNetworking 在 2023 年 1 月 17 日正式发布公告宣布弃用，停止维护。原始仓库将作为一个归档库永久保留。</p><p>AFNetworking 建议开发者可以迁移到同样由 Alamofire 软件基金会所开发的 Alamofire —— 一个 100% 使用 Swift 编写的网络框架。</p><p><img src="https://static.oschina.net/uploads/space/2023/0118/153745_fT17_4937141.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/223913/aethersx2-end">开发者遭死亡威胁，项目停止开发</a></h4><p>因遭受过多的骚扰甚至于死亡威胁，AetherSX2 软件的开发者 Tahlreth 于 2023 年 1 月宣布无限期停止该项目的开发。</p><p>「AetherSX2 对我来说一直是一个有趣的爱好，而不是为了盈利。继续开发一个不再有趣的项目是没有任何意义的。」</p><p>AetherSX2 是 Android 平台上最好用的 PlayStation 2 模拟器（没有之一）。用户还可以继续下载和使用 AetherSX2，但该应用程序已经不再有进一步的开发计划。</p><p><img src="https://oscimg.oschina.net/oscnet/up-93a2a42d4210b16856fc57cda8138b21c0e.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/232215/peek-discontinued">问题堆积如山，GIF 录屏工具 Peek 停止开发</a></h4><p>GIF 屏幕录制工具 Peek 的开发者在 2023 年 1 月正式宣布项目停止开发，主要原因在于 Wayland 上运行时所面临的一些技术挑战。而解决问题的唯一途径就是以不同的方式、不同的 UI 完全重写应用程序，但「现在的 Peek 几乎没有什么资源可以重用」。</p><p>开发者表示自己并没有兴趣再开发一个全新的项目，所以做出了放弃该项目的决定。</p><p><img src="https://oscimg.oschina.net/oscnet/up-10c040add5089c3b13095d5f4ee74d1685a.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/230777">aardio 编程语言作者：因妻子患癌，再无精力维护项目</a></h4><p>aardio 编程语言作者发文表示，因妻子患癌，再无精力维护项目。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aardio.com%2F">aardio</a> 是一门专注于桌面软件开发的编程语言，特点是小、轻、快，体积仅 6.5MB，学习和使用成本极低。aardio 虽然小，但提供了惊人数量的开源标准库、扩展库 —— 这些库基本都是由纯 aardio 代码实现。</p><p>aardio 的所有库基本都是由作者一个人编写，并且 17 年来一直保持非常活跃的更新。</p><p><img src="https://static.oschina.net/uploads/space/2023/0302/174216_nFqa_2720166.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/235303/touca-shutting-down">开源项目 Touca 开发商倒闭</a></h4><p>开源测试工具 Touca 的创始人 Pejman Ghorbanzade 于 2023 年 3 月宣布其公司正式倒闭，不景气的市场大环境是 Touca 倒闭的一个主要原因。</p><p>Pejman Ghorbanzade 于 2021 年创立了 Touca，并于 2022 年 5 在 Apache-2.0 许可下开源。Touca 可以帮助工程团队发现日常代码修改所导致的意外副作用。它将软件的行为和性能与之前的可信版本进行比较，并以近乎实时的方式将差异可视化。</p><p>Touca 公司倒闭后，Touca 这个开源项目还将继续存在，并保持开源，Pejman Ghorbanzade 表示自己会持续维护这个项目，并开始寻找新的机会。</p><p><img src="https://static.oschina.net/uploads/space/2023/0404/083735_MqQM_4937141.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/242988/qt-5-15-lts-support-ends">Qt 5.15 LTS 已结束标准支持</a></h4><p>Qt 5 系列的最后一个次要版本 Qt 5.15 LTS 于 2023 年 5 月 26 日正式结束标准支持。</p><p>Qt 5.15 LTS 是一个长期支持版本，有三年的标准支持期。最后一个补丁版本是 Qt 2023 年 5 月 25 日发布的 5.15.14，适用于具有旧许可证的商业客户的标准支持条款。</p><p><img src="https://static.oschina.net/uploads/space/2023/0530/072839_iyUd_2720166.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/243315/rarbg-shut-down">战争、疫情、通货膨胀，资源网站 RARBG 宣布关闭</a></h4><p>受战争、疫情、通货膨胀等因素影响，资源网站 RARBG 于 2023 年年中宣布关站。</p><p>RARBG 是一个著名的 BitTorrent 网站，提供了许多高质量的电影、电视剧、音乐、游戏和软件等种子资源。它成立于 2008 年，总部位于保加利亚，已经成为了 BitTorrent 社区中备受喜爱的网站之一。</p><p><img src="https://static.oschina.net/uploads/space/2023/0601/090415_Crb3_4937141.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/247891/libjpeg-turbo-fund">资金严重短缺，又一流行开源项目宣布停止功能开发</a></h4><p>libjpeg-turbo 的首席开发人员 DRC 在完成该项目的 3.0.0 版本发布后表示，由于资金短缺，其未来的功能开发或将受到限制，可能永远不会有 libjpeg-turbo 3.1 版本。</p><p>他将继续修复 libjpeg-turbo 中的错误，并在 3.0.x 发行版系列中发布错误修复版本；但不会再有 libjpeg-turbo 3.1 发行版系列，除非该项目可以获得更多的通用资金。</p><p>libjpeg-turbo 是一个 JPEG 图像编解码器，它使用 SIMD 指令（MMX、SSE2、AVX2、Neon、AltiVec）来加速 x86、x86-64、Arm 和 PowerPC 系统上的基线 JPEG 压缩和解压缩，以及 x86、x86-64 和 Arm 系统的渐进式 JPEG 压缩。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5009145e786948703fca4d615949b2aa180.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/255159">自动跳过开屏广告应用「李跳跳」无限期停止更新</a></h4><p>「李跳跳」 作者于 2023 年 8 月在公众号宣布无限期停止更新，原因是收到了某集团律师函，对方称 「李跳跳」 APP 涉嫌不正当竞争，对旗下的浏览器产生影响，并要求四十八小时内全网下架 「李跳跳」。</p><p>「李跳跳」 是一款利用无障碍权限进行跳过 APP 开屏广告的 Android 辅助应用，无需联网，免费使用。除了 「李跳跳」，其他同类开屏广告应用也都在同一时期收到了律师函，比如 「大圣净化」、「一指禅」 和 「叮小跳」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f76f9db79d31ec9572ff7a63c83b254b314.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/256175/visual-studio-for-mac-retirement">微软官宣：Visual Studio for Mac 退役</a></h4><p>微软于 2023 年 8 月发布了 Visual Studio for Mac 的退役公告。未来，开发团队将专注于增强 Visual Studio 和 VS Code，优化它们以进行跨平台开发。</p><p>自 2024 年 8 月 31 日起，Visual Studio for Mac 将不会再获得任何支持。届时，Visual Studio for Mac 将只能通过 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmy.visualstudio.com" target="_blank">my.visualstudio.com</a>，为已订阅 Visual Studio 的用户提供旧版安装，但不再提供服务或维护。</p><p>Visual Studio for Mac 退役后，微软方面仍会为 Mac 开发者提供替代方案，例如 C# Dev Kit for VS Code 和其他扩展。</p><p><img src="https://static.oschina.net/uploads/space/2023/0831/111644_7KuF_2720166.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/257320/wangeditor-suspend-maintained">开源富文本编辑器 wangEditor 暂停维护</a></h4><p>开源 Web 富文本编辑器 wangEditor 作者王福朋于 2023 年 8 月发布宣布暂停项目维护。主要原因在于作者暂无精力维护 wangEditor ，且 「最近行业形势也不太好，先努力搞钱吧」。</p><p>他也欢迎有人接手 wangEditor 的维护，不过需要通过初步考核：在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwangeditor-team%2FwangEditor%2Fissues">issues</a> 列表中，回答 10 个 issue。</p><p><img src="https://static.oschina.net/uploads/space/2023/0908/105123_MDIq_2720166.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/256530/microsoft-deprecated-wordpad-in-windows">时隔 28 年，微软计划在 Windows 中淘汰写字板</a></h4><p>微软在 2023 年 9 月宣布计划在未来的 Windows 更新中弃用写字板。对于 .doc 和 .rtf 等富文本文档，该公司建议使用 Microsoft Word 作为替代品；对于 .txt 等纯文本文档，则建议使用 Windows 记事本。</p><p>写字板是一种基本的文本编辑应用程序，允许用户创建和编辑带有格式化文本的文档，幷包含图像和其他文件的链接。自 1995 年 Windows 95 发布以来就附带在 Windows 系统上，为用户提供集成到操作系统中的基本文字处理器和文档编辑器。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9eb98bd9630dd96807298f16da6fd2ec37f.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/224251/linux-4-9-eol">Linux 4.9 正式 EOL ，结束持续 6 年的 LTS 周期</a></h4><p>在长达 6 年多的长期支持后，Linux 4.9 内核系列在 Linux 4.9.337 更新中，结束了生命周期。</p><p>Linux 内核 4.9 于 2016 年 12 月 11 日发布，它带来了对 XFS 文件系统的共，享范围和写时复制支持、用于检测固件引起的延迟的硬件延迟跟踪器、对，来自 Project Ara 的 Greybus 总线的支持、更高效的 BPF 分析器、新的可选 BBR TCP 拥塞控制算法、虚拟映射内核堆栈等特性。</p><p>由于是 LTS 版本，Linux 4.被广泛用于生产环境，比如基于 Linux 4.9 操作，系统驱动的大规模生产设备/硬件。</p><p><img alt="082401_IvCl_5430600.png" src="https://static.oschina.net/uploads/space/2023/0109/082401_IvCl_5430600.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://my.oschina.net/GreatSQL/blog/10117424">MySQL 5.7 于 2023.10.21 正式 EOL</a></h4><p>MySQL 目前已经成为中国用户使用最广泛的开源数据库，其中 5.7 版本用户的比重又是最高的。根据报告中的统计数字，MySQL 5.7 用户占比在国内高达 47%。届时这些用户将会面临选择，如何应对 EOL 事件。</p><p>实际上 2020 年的时候就有一些机构提醒用户，MySQL 5.7 按照生命周期将于 2023 年到达服务期限，当时这件事还在 MySQL 社区和 DBA 圈子里引发过一些关于开源项目安全性的讨论。3 年后，这个狼来了的问题，终于正式要面对我们了。</p><p><img src="https://oscimg.oschina.net/oscnet/up-38ac7bf161ea28943b1db6cc2ac7b40b41d.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/258425">JS 工具库 lodash 关闭所有 issue 和公开 PR</a></h4><p>老牌 JS 工具库 lodash 关闭了所有 issue 并统一打上 "issue bankruptcy" 的 tag，此外还关闭了所有公开 PR，表示无力处理，一关了之。</p><p><img src="https://static.oschina.net/uploads/space/2023/0917/112931_OgKg_2720166.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h4><a href="https://www.oschina.net/news/265128">承载微软跨平台生态之梦的 UWP，正在消亡</a></h4><p>开发者发现，微软最新的 Windows 11 Canary Build 25987 预览版已经开始提供两个版本的 XAML Shell 服务，新的版本直接基于 Win32 + XAML，曾经被寄予厚望的 UWP 在新版本里已经不见踪影。</p><p><img src="https://static.oschina.net/uploads/space/2023/1106/113836_8gF1_2720166.png" referrerpolicy="no-referrer"></p><hr><p>更多年度重磅事件回顾，<strong><span style="background-color:#e67e22">查看</span><em><u><a href="https://talk.gitee.com/report/china-open-source-2023-annual-report.pdf?fr=eol_news0102"><span style="background-color:#e67e22">《2023 中国开源开发者报告》</span></a></u></em></strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-31c655bad093b73b284c51a422e90e89f0a.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-5199a6522e6176e753c99bda331326df1ff.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-de7179752ad55a2a635cd9f1ec18ce587ee.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 09:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273843</guid>
            <link>https://www.oschina.net/news/273843</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[把 DevOps 带进数据库 - Bytebase 的 2023]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>前情提要：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMjI2MDY5OQ%3D%3D%26mid%3D2247501714%26idx%3D1%26sn%3De042aa907bc5eb45bdcad8d4cd56cfd3%26chksm%3Dc25cf9a6f52b70b0ef011150790edb7f6864cc9dbfc94959d358b12506119eefb248d44faa36%26scene%3D21%23wechat_redirect" target="_blank">Bytebase 的 2022｜埋头苦干，孕育希望</a></p></blockquote><h2>产品迭代</h2><ul><li><p>2023 年共发布了 25 个版本。这个数字和 2022 年一样，除开春节和一次全员疫情，做到了两周一次的更新。</p></li><li><p>版本号从 1.11.0 升级到了 2.13.0。其中在 5 月份，我们发布了 Bytebase 2.0 版，明确了做 Database DevOps 的产品主张。 <img src="https://oscimg.oschina.net/oscnet/up-68868615564cc83e1c5c26bc6160165fd16.png" alt="file" referrerpolicy="no-referrer"></p></li><li><p>PR 数超过 10000，成为了 GitHub 上最繁忙的开源项目之一。 <img src="https://oscimg.oschina.net/oscnet/up-f94e6c186bd68ccd2a105ae853db7e9f04e.png" alt="file" referrerpolicy="no-referrer"></p></li><li><p>GitHub Star 数也从 4.7 k 增加到 8.7 k，不仅继续保持同领域内最快的增速，而且还先后超越了国外的 Flyway 和国内的 Yearning，成为了同领域内，全球 Star 最多的开源项目。 <img src="https://oscimg.oschina.net/oscnet/up-2622bb405457359ff36b66daad3d244cc6d.png" alt="file" referrerpolicy="no-referrer"></p></li></ul><h2>企业级，可依赖</h2><p><img src="https://oscimg.oschina.net/oscnet/up-3c1a784de5a150efbfc8e71fe8cd4d2d3da.png" alt="file" referrerpolicy="no-referrer"></p><p>今年 Bytebase 成为了唯一被 CNCF Landscape 和 Platform Engineering (平台工程组织) 同时收录的数据库管理工具。</p><p><img src="https://oscimg.oschina.net/oscnet/up-72f780b2eedaf1328244e667365722b33e3.png" alt="file" referrerpolicy="no-referrer"></p><p>目前 Bytebase 已经支持市面上 17 种主流数据库系统。提供了一套覆盖变更，查询，安全，治理的数据库开发全生命周期的解决方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9ebeef3b72d5ba1d510aea61c971e5be01d.png" alt="file" referrerpolicy="no-referrer"></p><p>今年 Bytebase 全面增强了企业级功能，SSO，多因素认证，动态脱敏，批量变更，自定义审批流，审计日志等。并且还通过开放 API 的方式让 Bytebase 能被集成到了企业已有的研发平台中。</p><h2>旧雨新知</h2><p>Bytebase 在 2022 年年中开始商业化，今年则是全面商业化的第一年。我们完成了所有老客户的续约，并且在国内又收获了电信，制造业，造车新势力等行业的标杆。同时我们还把产品卖到了全球，北美，欧洲，东南亚，中东，非洲也都有了我们的客户。</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMjI2MDY5OQ%3D%3D%26mid%3D2247502348%26idx%3D1%26sn%3D6d1056e2dcc09a35b327ab981a4b4d49%26chksm%3Dc25cf438f52b7d2ee6fb3e56dfa9917abaf470e014d2d04148bb726fcbe0b59295a3bef452cc%26token%3D1617600613%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank">1:1000，新能源车企如何将数据库管理效能发挥到极致</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMjI2MDY5OQ%3D%3D%26mid%3D2247506285%26idx%3D1%26sn%3D37498d417a3c4b024504e590f89f39a4%26chksm%3Dc25ce759f52b6e4f8d884466b7d155635c031a864df18d3cd6b2d50cfacf2d3670da8a6fae37%26token%3D2062945217%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank">来自电子制造行业视源科技 (CVTE) 的数据库变更管理实践</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMjI2MDY5OQ%3D%3D%26mid%3D2247505728%26idx%3D1%26sn%3D6fa17fe88d8ba6d8f2635ab05ac3639f%26chksm%3Dc25ce974f52b6062a0d8a03d9669b4b5da3dba081e3f838a9a69b094bee5da0e5b873e40b535%26token%3D1617600613%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank">中东 Shopify 如何使用 Bytebase 构建一站式数据库开发工作流</a></li></ul><h2>良师益友</h2><p>作为一款面向开发者和 DBA 的数据库工具，Bytebase 今年也积极和上下游数据库和开发者工具建立合作关系，先后成为了 PingCAP, Snowflake, GitHub, GitLab 的全球技术合作伙伴。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8689af380e45d36553f6e3e3b79cf3a2c26.png" alt="file" referrerpolicy="no-referrer"></p><p>受邀在 OceanBase 的年度开发者大会进行了专题分享，并且基于一同服务的客户案例，推出了「数据库变更全生命周期管理」的联合解决方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-87dc34a29f68218802d3b0e281a320767ef.png" alt="file" referrerpolicy="no-referrer"></p><p>此外我们还支持了 RisingWave, StarRocks 这些冉冉升起的数据库新星。</p><h2>守正出奇，穿越周期</h2><p>不可否认，中国的企业服务正在经历低谷，面向 toB 市场的 Bytebase 自然也是受到了冲击。2023 以及即将迎来的 2024，我们依旧会开拓并且专注于「数据库开发」这一个工作流。当年 Bytebase 最早推出的 GitOps 方案现在已经出现在了 Snowflake 的产品中。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4189a487badbc0cf4ea8ebf2dd74463f905.png" alt="file" referrerpolicy="no-referrer"></p><p>今年我们继续在产品上创新，比如第一次在数据库工具里引入了分支工作流 (Branching)。</p><p><img src="https://oscimg.oschina.net/oscnet/up-56b1418f8c2a0f29dbccd0cb17e9358b656.png" alt="file" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-17c7adc49e0b01b7c804bcfbb1f7a204b22.png" alt="file" referrerpolicy="no-referrer"></p><p>总之，Bytebase 既要满足客户的需求，又要交付出一个面向未来的方案。</p><p>最后感谢我们所有的企业客户，社区用户，感谢你们信任一家起步不到三年的初创公司。大家有时也会操心公司的命运 (代码是完全开源的，结构清晰，部署简单，如果公司倒闭了，就可以任意使用/二开)。感谢大家的关心，我们的现金流即将转正，届时等我们的好消息吧。</p><p>好啦，明年再见 👋</p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10560159</guid>
            <link>https://my.oschina.net/u/6148470/blog/10560159</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[米老鼠原始版本进入公有领域 (Public Domain)]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在近一个世纪之后，米老鼠终于摆脱了迪斯尼的版权束缚。</p><p>这个标志性卡通人物的原始版本最早出现在《威利号汽船》(Steamboat Willie) 和无声版《疯狂飞机》(Plane Crazy) 动画电影，<strong>现在已于&nbsp;2024 年 1 月 1 日进入公有领域</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-2bff5b6c08ba6360efda331dccd547351f6.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-034cd0975e2f207388bfd20852a4bd6fcd3.png" referrerpolicy="no-referrer"></p><blockquote><p><strong>公有领域 (Public Domain) </strong>是人类的一部分作品与一部分知识的总汇，可以包括文章、艺术品、音乐、科学、发明等等。对于领域内的知识财产，任何个人或团体都不具所有权益（所有权益通常由版权或专利体现）。</p><p>这些知识发明属于公有文化遗产，任何人可以不受限制地使用和加工它们（此处不考虑有关安全、出口等的法律）。创立版权制度的初衷是借由给予创作者一段时期的专有权利作为（经济）刺激以鼓励作者从事创作。当专有权利期间届止，作品便进入公有领域。<strong>公有领域的作品由于没有专属权利人，因此公众有权自由使用它们</strong>。</p><p>许多国家将每年 1 月 1 日定为「<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpublicdomainreview.org%2Fblog%2F2024%2F01%2Fpublic-domain-day-2024%2F" target="_blank"><strong>公有领域日 (Public Domain Day)</strong></a></u>」。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-36bc427e8958111f8b21613b93880334f6a.png" referrerpolicy="no-referrer"></p></blockquote><p>进入公有领域的版本是 1928 年上映的动画片《威利号汽船》中刻画的米老鼠，米老鼠有多个版本，后续版本仍然受到了版权保护，仍然掌握在迪士尼手中。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-de4c25d0fcf3d14b5ec5b3b34339bb8e27d.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-03bacd2e7b78ab39a3544d5785e9f2f8e2d.jpg" referrerpolicy="no-referrer"></p><p>事实上，围绕米老鼠的版权极为复杂。公有领域版本的角色并不包括后来作品中的重大设计改动，比如 1940 年《幻想曲》中的巫师学徒米奇。此外，任何人也不能制作虚假的作品，把自己说成是迪斯尼的作品或官方商品，因为米老鼠同时也是迪斯尼的注册商标。也正因此，即使最原始的米老鼠版权到期，其他人在使用时也不能将其作为商标或 Logo，否则会构成侵权。</p><p>杜克大学公有领域研究中心主任詹妮弗-詹金斯 (Jennifer Jenkins) 在杜克大学的博客上对法律做了更为全面的解释：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweb.law.duke.edu%2Fcspd%2Fmickey%2F" target="_blank">https://web.law.duke.edu/cspd/mickey/</a></u></em>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-96469a26f95c5f39881aadfbddd806baa49.png" referrerpolicy="no-referrer"></p><p>米老鼠对于版权法的影响力和意义极为深远。美国将版权保护期限延长到 95 年，一个重要原因是迪士尼等公司的游说，因此该法律被笑称为「米老鼠保护法」。如此长的版权保护期限制了进入公有领域的作品，但另一方面迪士尼其实受益于公有领域作品，而且米老鼠本身的形象也是借鉴了卓别林等早期电影明星的风格。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 07:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273808/mickey-public-domain</guid>
            <link>https://www.oschina.net/news/273808/mickey-public-domain</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[mybatis-mp - 亮点二：支持不同数据库 ID 自增配置]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>亮点二：支持不同数据库 ID 自增配置</p><div><pre><span style="color:#9e880d">@Table
</span><span style="color:#0033b3">public class </span><span style="color:#000000">IdTest </span>{

 
    <span style="color:#9e880d">@TableId
</span><span style="color:#9e880d">    @TableId</span>(dbType = <span style="color:#000000">DbType</span>.<em>SQL_SERVER</em>,value = <span style="color:#000000">IdAutoType</span>.<em>AUTO</em>)
    <span style="color:#9e880d">@TableId</span>(dbType = <span style="color:#000000">DbType</span>.<em>PGSQL</em>,value = <span style="color:#000000">IdAutoType</span>.<em>SQL</em>, sql = <span style="color:#067d17">"select nextval('seq1')"</span>)
    <span style="color:#0033b3">private </span><span style="color:#000000">Long </span><span style="color:#871094">id</span>;

    <span style="color:#0033b3">private </span><span style="color:#000000">LocalDateTime </span><span style="color:#871094">createTime</span>;

}</pre></div><p><span style="color:#9e880d">@TableId 是默认配置（默认数据库自增）</span></p><p><span style="color:#9e880d">@TableId</span>(dbType = <span style="color:#000000">DbType</span>.<em>SQL_SERVER</em>,value = <span style="color:#000000">IdAutoType</span>.<em>AUTO</em>) 则是在<em>SQL_SERVER 下</em>生效，方式，数据库自增</p><p><span style="color:#9e880d">@TableId</span>(dbType = <span style="color:#000000">DbType</span>.<em>PGSQL</em>,value = <span style="color:#000000">IdAutoType</span>.<em>SQL</em>, sql = <span style="color:#067d17">"select nextval('seq1')"</span>)&nbsp;则是在<em>PGSQL</em><em>数据库下</em>生效，方式，为 sql，使用序列！</p><p>非常适合需要支持不同数据库场景下的开发</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 07:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273800</guid>
            <link>https://www.oschina.net/news/273800</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[@所有人 2023 IT 行业项目管理调查问卷，邀您参与！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年，行业飞速发展，在这一年里，新技术、新趋势带来了一波又一波创新浪潮，人工智能、物联网、云计算等技术正也在重塑我们的生活、工作方式。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>作为项目管理工具厂商，禅道深知项目管理过程的困难与不易，也紧跟管理方式的迭代与更新。为共同探索行业趋势，推动项目管理的进步与创新，我们联合多方合作伙伴，发起了 2023 年 IT 行业项目管理调查问卷，现诚挚地邀请您参与填写本问卷。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>我们希望通过这次调查，了解不同公司和个人在项目管理中面临的现状与挑战，为行业提供宝贵的数据、经验，推动行业发展。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>您的参与、转发就是对行业的支持~问卷所填内容仅用于报告分析及礼品发放，不会对外披露或对第三方提供。问卷将于 2024 年 2 月 20 日截止，届时我们将基于问卷数据生成调查报告，与您共享。</span></span></span></span>、</p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>认真完成问卷填写，即可参与中奖率百分百的抽奖，超多惊喜好礼在等您！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>点击填写问卷：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zentao.net%2Fredirect-index-23598.html" target="_blank">https://www.zentao.net/redirect-index-23598.html</a></strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img alt="" height="533" src="https://static.oschina.net/uploads/space/2024/0102/141727_mORd_4252687.png" width="300" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img alt="" height="147" src="https://static.oschina.net/uploads/space/2024/0102/141752_M92b_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 06:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273789</guid>
            <link>https://www.oschina.net/news/273789</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Hugging Face 年度回顾：2023，开源大模型之年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 编辑器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;"><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">查看本文完整链接，请点击文末阅读原文</p></blockquote><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 2023 年，大型语言模型（Large Language Models，简称 LLMs）受到了公众的广泛关注，许多人对这些模型的本质及其功能有了基本的了解。是否开源的议题同样引起了广泛的讨论。在 Hugging Face，我们对开源模型抱有极大热情。开源模型的优势在于，它们不仅促进了研究的可复制性，还鼓励社区参与到人工智能模型的开发中来，这样做有助于我们更容易地审视模型中可能存在的偏差和局限性。此外，通过重复利用已有的检查点，我们还能够减少整个领域的碳足迹（这只是，众多优点，中的一部分）。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">让我们一起回顾开源 LLMs 在过去一年的发展历程吧！</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><span style="color: rgb(136, 136, 136);">为了确保本文篇幅适中，我们将不涉及代码模型的相关内容。</span></p><span id="OSC_h2_1"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">🍜 预训练大型语言模型的配方</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先，如何获得一个大型语言模型呢？（如果你对此已有所了解，可以跳过这部分内容。）</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">模型的 <strong style="color: black;">架构</strong>（即其代码表示）定义了它的具体实现和数学结构：这包括所有的相关参数，以及这些参数如何与输入数据进行交互。目前，大多数高性能的大型语言模型（LLMs）都是基于 「仅解码器」（decoder-only）的 Transformer 架构的衍生版本，有关原始 Transformer 的详细信息可以参考其，发表的论文。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">训练数据集</strong> 是模型训练过程中（即参数被学习时）所依赖的全部样本和信息的集合，它使模型能够学习到特定的数据模式。这些数据通常包括多样的文本材料，既可以是各种自然语言文本，如法语、英语、汉语等，也可以是各类编程语言代码，比如 Python、C 语言等，或者是任何能够以文本形式表现的结构化信息，例如 Markdown 或 LaTeX 中的表格、公式等。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">分词器</strong> 是定义如何将训练数据集中的文本转化为数字的工具（因为模型是一个数学函数，因此需要数字作为输入）。分词是通过将文本转换为称为 「词元」 的子单元（可以是单词、子词或字符，具体取决于分词方法）来完成的。分词器的词汇量大小决定了其能够将文本分割成的不同词元的种类数目，这个数字通常介于 32,000 到 200,000 之间。数据集的规模常常用它包含的 <strong style="color: black;">词元数量</strong> 来衡量。经过分词后，如今的数据集范围从几千亿词元到几万亿词元不等，这些词元是构成数据集的基本单元。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">训练超参数</strong> 定义了模型训练的方法。这些参数决定了模型应如何调整自身以适应新的数据样本，以及模型参数更新的速度应该是多快。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">一旦确定了这些超参数，接下来需要的就是 1）充足的计算资源来进行模型训练；2）具备专业技能的人员来执行和监督训练过程。训练过程本身包括在训练所用的硬件上初始化模型架构，以及依据前述超参数在训练数据集上应用训练算法。训练的成果是一系列模型权重 —— 这些就是经过学习的 <strong style="color: black;">模型参数</strong>，也正是人们通常所说的开放获取的预训练模型。这些权重可以用于后续的 <strong style="color: black;">推理过程</strong>，即对新的输入数据进行预测，例如生成文本。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">预训练的大型语言模型（LLM）在完成初始训练后，还可以根据具体任务进行定制化或进一步调整。特别是当这些模型的参数被开放共享时，它们可以作为不同用例和应用的基础，经过一种称为 「微调」 的过程进行优化。微调包括在与原始预训练数据集不同的、通常更小且更专业化的数据集上，对模型执行额外的训练步骤，目的是为了针对特定应用场景优化模型性能。尽管微调步骤在计算资源消耗上有一定成本，但这一成本通常远低于从零开始训练一个全新模型所需的财务投入和环境代价。这也是高品质开源预训练模型极具吸引力的一个原因，它们使得即便是计算预算有限的从业者也能够自由地使用和改进这些模型。</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">🗝️ 2022 年，从规模竞赛转向数据竞赛</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 2023 年之前，社区有哪些开源模型可用？</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">直至 2022 年初，机器学习界普遍认为，模型的规模越大（即拥有的参数越多），其性能也越出色。特别是，模型一旦超过某个特定的规模阈值，其能力似乎会实现质的飞跃，这两种现象分别被称为 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">突现能力</code> 和 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">规模定律</code>。2022 年推出的多个预训练开源模型家族大多遵循这种范例。</p><ol data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><p style="margin-top: 5px;line-height: 26px;color: rgb(58, 58, 58);margin-bottom: 16px;"><strong>BLOOM (BigScience Large Open-science Open-access Multilingual Language Model)<br></strong>BLOOM 是由 BigScience 研究团队推出的，一系列模型。BigScience 是一个由 Hugging Face 协调，联合法国的 GENCI 和 IDRIS 组织共同参与的国际合作项目，涵盖了来自 60 个国家、250 个研究机构的 1000 名科研人员。这些模型采用了仅包含解码器的 transformer 架构，并进行了细微调整，比如引入了嵌入后归一化和 ALiBi 位置嵌入技术。在这一系列模型中，最大的一个拥有 1760 亿个参数，它接受了 46 种人类语言和 13 种编程语言的 3500 亿个多语言数据词元的训练。大量的训练数据已经向公众开放，包括数据的来源、策划和处理过程的详细信息。它是目前为止发布的最大的开源多语言模型。</p></li><li><p style="margin-top: 5px;line-height: 26px;color: rgb(58, 58, 58);margin-bottom: 16px;"><strong>OPT (Open Pre-trained Transformer)<br></strong>Meta 发布的 OPT 模型，系列采用了仅包含解码器的 Transformer 架构。这些模型借鉴了 GPT-3 论文中的技术，如特定的权重初始化和预归一化策略，并对注意力机制进行了改进，比如引入了交替的密集型与局部带状注意力层。系列中最大的模型拥有 1750 亿个参数，其训练数据涵盖了来自公共领域的 1800 亿个数据词元，包括书籍、Reddit 社交平台数据、新闻、维基百科以及其他多种互联网来源。这一系列模型在性能上与 GPT-3 不相上下，并且通过编码优化减少了计算资源的消耗。</p></li><li><p style="margin-top: 5px;line-height: 26px;color: rgb(58, 58, 58);margin-bottom: 16px;"><strong>GLM-130B (General Language Model)<br></strong>清华大学联合智谱 AI 共同发布了 GLM-130B 模型。该模型基于完整的 Transformer 架构，并引入了一些创新（如采用 DeepNorm 进行层后归一化、使用旋转式位置嵌入）。GLM-130B 拥有 1300 亿参数，是在包含英文和中文的互联网数据集上训练的，这些数据集包括 The Pile、WuDao 语料库以及其他中文语料库，共计 4000 亿个词元。在性能上，GLM-130B 与 GPT-3 模型不相上下。</p></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong>较小或更专业的开源大语言模型<br></strong>近期，一些较小型的开源模型也相继发布，这些模型主要服务于科研领域：Meta 推出了 Galactica 系列的大型语言模型（LLM），其中规模最大的模型拥有高达 120B 参数，这些模型是在科学文献中的 1060 亿个词元基础上进行预训练的。EleutherAI 则发布了 GPT-NeoX-20B 模型，这是一个完全开源的仅解码器式 Transformer 模型（包括模型架构、权重和数据），在 5000 亿词元上经过训练，并采用了 RoPE 以及对注意力机制和初始化过程的若干改进，为科学研究提供了一个完整的工具集。 
    </section></li></ol><section style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);margin-top: 16px;">
    这些巨大的模型令人振奋，然而，它们的运行成本也高得惊人！在进行推理计算（即从模型中得出预测结果）时，模型必须被加载到内存中，而一个具有一千亿参数的模型往往需要占用高达 220GB 的内存空间（这个过程我们将在后文中详细阐述），这样的内存需求对于大多数机构和专业人士来说都是难以承担的！ 
  </section><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">然而，2022 年 3 月，DeepMind 发表了一篇，论文，探讨了在固定计算预算条件下，模型参数与数据量的最优配比。简而言之，如果你的模型训练预算有限，应该如何平衡模型大小和数据规模？研究者们发现，在平均计算预算下，对于大型语言模型（LLMs），更高效的策略是维持一个相对较小的模型，并在更广泛的数据集上进行训练。他们开发的模型 Chinchilla（未公开）拥有 700 亿个参数，仅为某些大型模型参数总数的三分之一，却在高达 1.4 万亿个词元的数据集上进行了训练，是其他模型所使用数据量的三到四倍。结果显示，Chinchilla 在性能上不仅媲美甚至超越了其他更大的同类型模型，无论是开源还是非开源的。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这种范式的变化，尽管可能已在封闭的实验室环境中为人所知，但它却让整个开放的科学界感到措手不及。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">🌊 2023, 开放发布之年</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><span id="OSC_h3_4"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);"><em style="color: black;">小型</em> 大语言模型的崛起</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">2023 年，仅解码器（decoder-only）式的 Transformer 模型迎来了爆发式增长。几乎每月都有新的预训练模型问世，发展速度之快以至于渐渐演变为每周甚至每日都有新模型的推出。Meta 在 2 月推出了 LLaMA 模型；Eleuther AI 在 4 月带来了 Pythia 模型；MosaicML 在 5 月推出了 MPT 模型；Salesforce 和 TIIUAE 则在 6 月分别发布了 X-GEN 和 Falcon 模型。Meta 紧随其后，在 7 月发布了 LLaMA 的升级版本 LLaMA 2。进入下半年，9 月阿里巴巴发布了 Qwen 模型；Mistral.AI 推出了同名 Mistral 模型；01-ai 在 11 月发布了 Yi 模型；Deci 推出了 DeciLM 模型；而 Upstage 则在 12 月带来了 Phi-2 和 SOLAR 模型。这一系列的模型发布，不仅展示了人工智能领域的快速进步，也预示着技术的不断迭代与革新。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这些发布包括了：a) 模型权重（在不同程度的开源许可下）；b) 对于较小规模的模型（介于 30 亿至 700 亿参数之间），它们的性能都相当出色，因此立刻被社区采用。这些模型几乎都采用仅解码器的 Transformer 架构，并且进行了各种调整（比如 ALiBi 或 RoPE、RMS 预归一化、SwiGLU），以及对注意力函数的一些改变（如 Flash-Attention、GQA、滑动窗口注意力），并且在不同的代码库实现中进行了优化，以提高训练或推理速度。这些调整很可能在一定程度上影响模型的性能和训练速度；然而，由于所有架构都已经连同权重一起公开发布，剩下的核心差异主要在于训练数据和模型的许可方式。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Meta AI 发布的 LLaMA 系列是该系列中的首款模型。研究团队的目标是在既定的计算预算内训练不同规模的模型，以求达到最优性能。他们首次明确将训练预算与推理成本（即在满足特定性能目标时，模型推理所需的成本）并重考虑。基于这样的考量，他们选择在更大量的数据和更多的训练步骤上，训练规模较小的模型，以期在较小的模型尺度上获得更高的性能（这是对训练计算效率的一种权衡）。在 LLaMA 系列中，最大的模型拥有 650 亿参数，经过了 1.4 万亿的词元训练，而规模较小的模型 —— 分别具有 60 亿和 130 亿参数 —— 则在 1 万亿词元训练后完成。在大多数基准测试中，130 亿参数的 LLaMA 小型模型的表现超过了 GPT-3，而 650 亿参数的 LLaMA 大模型在发布时则代表了最先进的技术水平。然而，这些模型的权重是以非商业许可的形式发布的，这限制了它们在社区中的应用范围。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Eleuther AI 是一个开源的非营利实验室，它发布了一系列名为 Pythia 的大型语言模型（LLMs）。这些模型有不同的规模，全部采用公开数据进行训练，目的是为了帮助研究人员理解大型语言模型训练的不同阶段。有关 Pythia 模型的更多信息，可以通过它们在 Hugging Face 上的，系列合集，查看。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">MosaicML 公司在两个月后推出了 MPT 模型，该模型的性能优越，并且支持商业用途，同时公司还公开了其训练的具体细节。MPT 的首个版本是一个 7B 的模型，紧接着在 6 月份，公司发布了一个更大的 30B 版本。这两个模型都是基于 1 万亿个英语和编程语言的词元训练而成，训练数据包括了 C4、CommonCrawl、The Stack、S2ORC 等数据集。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">MPT 模型推出后不久，TIIUAE 团队便发布了 Falcon 系列模型，中的 7B 和 30B 版本。这些模型在 1 至 1.5 万亿个英文和代码词元上进行了训练，训练数据包括来自 RefinedWeb、Project Gutenberg、Reddit、StackOverflow、GitHub、arXiv、Wikipedia 等多个来源。同年晚些时候，TIIUAE 还发布了一款更为庞大的 180B 模型。Falcon 模型的细节、所用数据以及训练过程均在一份技术报告及随后发表的，研究论文，中有详尽的描述。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">先前的模型在公开时通常会公开其数据集，但随后推出的模型很少公布其训练过程中使用的具体信息，这使得重现它们的成果变得困难。尽管如此，这些模型通过发布它们的权重参数，为研究社区提供了一个研究和进一步开发的起点。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Salesforce 在夏初推出了 X-Gen 模型，这是一款拥有 70 亿参数的模型，训练数据包括了 15 万亿个 「自然语言和代码」 词元，训练过程分为多个步骤，并采用了数据调度系统（并非所有数据同时输入模型）。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">X-Gen 在 Meta 推出的更为引人注目的新的 LLaMA-2 家族的阴影下显得有些黯然失色。LLaMA-2 是 Meta 推出的一个新的模型系列，规模从 7B 到 70B 不等，这些模型是在 2 万亿个 「来自公开来源的词元」 上训练而成的，采用了宽松的社区许可证，并经过了人类偏好的精细调整（RLHF），即所谓的对齐过程。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">随后，新兴初创企业 Mistral 推出了其首款模型 ——Mistral-7B，该模型，是基于互联网公开数据集的大量数据训练而成，具体数据量尚未公布。随着 2023 年末的临近，模型发布活动日益频繁。Mistral 紧接着发布了更为庞大的第二款模型 Mixtral 8x7B。与此同时，Deci.AI 公司也带来了其令人瞩目的首款模型 DeciLM，upstage 公司也不甘落后，推出了规模更大的 SOLAR 模型。这些模型均采用了来源和数量未公开的数据进行训练。在各大排行榜和公开基准测试中，这些模型均展现出稳步的进步。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 2023 年年底，值得关注的一大事件是中国训练并公开发布了多个性能显著提升的模型。其中，阿里巴巴推出了其双语（英汉）模型 Qwen 系列，其参数规模从 70 亿，至 700 亿不等，经过了 240 亿词元数据的训练。与此同时，01-AI 公司也发布了 Yi 系列模型，其参数规模介于 60 亿至 340 亿之间，训练数据量达到了 300 亿词元。这些模型在公开排行榜（如 Open LLM leaderboard）以及一些极具挑战性的基准测试（例如 Skill-Mix）中的表现，均超过了之前的模型。2023 年底的另一强有力的新竞争者是 DeepSeek AI，他们推出了 「DeepSeek-Coder」，该模型从零开始训练了 200 亿词元数据，其中包含 87% 的代码和 13% 的英汉混合自然语言。</p><span id="OSC_h3_5"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">随处可见的对话模型</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">2023 年，与前一年相比，几乎所有新发布的预训练模型都配备了预训练版本和对话微调版本，这些版本采纳了多种现有的调整方法。尽管适用于聊天环境的模型调整技术在 2022 年及以前已有所开发，但这些技术在 2023 年得到了广泛应用并迅速兴起，这突显了聊天模型在普罗大众中使用的快速增长，以及通过与模型的互动对其进行的人工评估（即 「氛围检查」 评估）。本文将详细介绍几种著名的训练调整预训练模型以进行聊天的方法，实际上，相关的变体还有很多！</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">基于对话的微调</strong> 是一种特殊形式的监督式微调。在这种方法中，我们使用的标注数据是对话形式的，类似于社交媒体上的多轮对话记录。通过这种方式，可以对模型进行特定的微调。在这个过程中，我们可以采用与模型训练阶段相同的技术。例如，在处理仅解码器 Transformer 模型时，可以训练模型通过自回归方法，即逐一预测接下来的词元。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">指令微调</strong>（Instruction-based Fine-Tuning，IFT）采用相同的方法，但使用指令数据集，该数据集包含一系列类似查询的提示以及答案（如果需要，还可以包含可选的附加输入）。这些数据集教导模型如何遵循指示，并且可以是人类生成的，也可以是大型语言模型生成的。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">利用大规模模型输出的合成数据集（由模型生成的数据集，例如来自 GPT-4 的生成，可以是来自指示或用户与模型之间的交互）是实现指导微调和聊天微调的一种方式。这通常被称为 「蒸馏」，因为它涉及从性能较高的模型中获取知识，以训练或微调较小的模型。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这两种方法都相对容易执行：你只需找到或创建相应的数据集，然后采用与训练时相同的技术对模型进行调整即可。去年，发布了众多指导性数据集，它们有效提升了模型在对话场景中的表现。想要了解更多关于此主题的信息，可以参阅这篇介绍性博文的，链接。然而，尽管模型的性能有了显著提升，但它们仍未能完全达到人类的预期水平。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">从人类反馈中强化学习</strong>（Reinforcement Learning from Human Feedback，RLHF）是一项旨在使模型输出与人类偏好（基于特定标准）相一致的特定方法。具体操作流程如下：模型根据给定的提示生成多个潜在答案；人类评估者对这些答案进行排序；然后，这些排序结果用于训练一个偏好模型（该模型学习如何给出反映人类对答案偏好程度的评分）；最后，利用偏好模型通过强化学习对语言模型进行进一步的微调。更详细的信息，请参阅这篇，博客文章，原始 RLHF 论文，或者 Anthropic 关于 RLHF 的论文。需要注意的是，这是一种成本较高的方法（注释 / 排名 + 训练新模型 + 微调的整个过程成本很高），主要用于确保模型的输出与安全目标相符。为了降低成本，人们开发了一种低成本的变体方法，即利用高质量的语言模型来对模型输出进行评分，而不是完全依赖人类评价，这种方法称为从 <strong style="color: black;">人工智能反馈中学习的强化学习</strong>（Reinforcement Learning from AI Feedback, RLAIF）。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">直接偏好优化</strong>（Direct Preference Optimization, DPO）是 RLHF 的另一种变体，其核心优势在于无需训练和运用独立的偏好模型。这一方法同样需要人类或人工智能生成的排序数据集，但它通过直接利用这些数据来更新模型，即通过对比模型现有的策略（即预测行为）与理想的策略（即能够预测出最优排序答案的行为）。换言之，模型本身即扮演了对齐和偏好模型的双重角色，这不仅简化了优化流程，而且根据报告，还能够实现与其他方法相媲美的性能水平。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">回到来自（大多数）私企的小型开放权重模型的浪潮，其中很多模型都发布了经过精细调整的对应版本：MPT-7B 还配备了一个指令微调和一个对话版本，Falcon 和 XGen 模型的指令微调版本在年底发布，Llama-2、Qwen 和 Yi 发布了对话版本，DeciLM 则发布了一个指令微调版本。Llama-2 的发布尤其引人注目，因为它在预训练和指令微调模型中都特别注重安全性。</p><span id="OSC_h3_6"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">社区的进展如何？</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">虽然随着新模型的发布，聊天模型和指令微调模型通常会立即推出，但社区成员和研究人员并没有把这看作是理所应当的。在这些基础模型提供的沃土上，涌现出了一个庞大而活跃的微调爱好者社区。这些微调专家经常会构建新的数据集，并对模型进行细致的微调，以此来展现新发布模型的出色性能。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 2023 年伊始，一些专为指令交互和对话微调设计的数据集已经被发布。例如，代表人类偏好的数据集包括 OpenAI 的 WebGPT 数据集、Anthropic 的 HH-RLHF 数据集以及 OpenAI 的，摘要，数据集，它们在这一领域是开拓者。指令数据集的例子包括 BigScience 的，公共提示池、Google 的 FLAN 1 和 2（FLAN 数据集）、AllenAI 的，自然指令，数据集、由不同机构的研究人员开发的自动生成指令框架，自我指令、由专家创建的指令基准，超自然指令（有时用作微调数据），以及由特拉维夫大学和 Meta 合作生成的自动指令数据集，非自然指令，等。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">❄️ 冬 2022/2023: 一月，来自中国多个研究机构的研究人员共同发布了，人类 ChatGPT 指令语料库（HC3），其中包含了人类与模型对各种问题的回答。3 月份，发布活动接连不断：斯坦福大学推出了 Alpaca 模型，这是首个遵循指令的 LLaMA 模型（7B），以及相关的数据集，包括用大型语言模型生成的 52K 条指令。非营利开源实验室 LAION 发布了，开放指令通用数据集（OIG），包含 4300 万条指令，这些指令既有通过数据增强创建的，也有编译自其他现有数据源的。同月，位于加州大学伯克利分校的 LMSYS 组织发布了 Vicuna，这也是一个基于 ChatGPT 聊天数据的 LLaMA 精调模型（13B），这些聊天数据是用户与 ChatGPT 之间的对话，由用户自己公开分享在 ShareGPT 上。还发布了 Guanaco 数据集，它是 Alpaca 数据集的扩展版（增加了 50 万条多语言条目），以及相关的 LLaMA-7B 精调模型。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">🌱 春：四月，伯克利人工智能研究实验室（Berkeley AI Research lab，BAIR）发布了 Koala，这是一个经过聊天调优的 LLaMA 模型，它使用了多个先前的数据集（包括 Alpaca、HH-RLHF、WebGPT、ShareGPT），而 DataBricks 则发布了 Dolly 数据集，这是一个由 15K 条人工生成的指令组成的数据集，以及相关的 Pythia 微调模型。五月，清华大学发布了 UltraChat，这是一个包含 1.5M 对话指令的数据集，以及在该数据集上进行微调的 UltraLLaMA 模型。随后，微软发布了 GPT4-LLM 数据集 / 框架，用于生成 GPT4 的指令。六月，微软研究院分享了一种新方法 Orca，通过使用大型模型的推理轨迹（逐步解释其推理过程）来构建指令数据集，该方法很快被社区（尤其是 Alignementlab.ai）复现，他们创建了 Open Orca 数据集，包含数百万条条目，随后用于微调多个模型（如 Llama、Mistral 等）。五月和六月期间，Camel-AI 发布了多个关于不同话题（物理、生物、化学等）的指令或聊天数据集，每个领域都有超过 20K 的示例。同样在六月，发布了 Airoboros 框架，用于使用模型生成的数据微调模型（遵循自我指导方法），以及一系列的，指令数据集。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">🌻 夏：八月，由中国的非营利组织 OpenBMB 发布了 UltraLM（一种基于 LLaMA 的高性能聊天模型微调版本），随后在九月，他们又发布了相关的偏好数据集 UltraFeedback，这是一个包含与 GPT4 对比的输入反馈数据集，并附有注释。在整个夏天，一个名为 NousResearch 的集体发布了多个基于私有和公开指导数据集的微调版本（特别是 Hermes 和 Capybara 系列）。九月，清华大学的一个学生团队发布了 OpenChat，这是一个应用了新的强化学习微调策略的 LLaMA 微调版本。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">🍂 秋：十月，Hugging Face 发布了 Zephyr 模型，这是一个在 UltraChat 和 UltraFeedback 上使用 DPO 和 AIF 技术对 Mistral 模型进行微调的产物。同时，社区成员发布了 OpenHermes 2，这是一个在来自网络或使用 Axolotl 生成的 900K 条目上对 Mistral-7B 模型进行微调的版本。Lmsys 发布了 LMSYS-Chat-1M，包含了与 25 个大型语言模型（LLMs）的真实用户对话。十一月，OpenBuddy 发布了 OpenBuddy-Zephyr，这是一个对 Zephyr 模型进行微调的多轮对话模型。同月，NVIDIA 发布了 HelpSteer 数据集，这是一个对齐微调数据集，提供了提示、相关模型回应以及基于几个标准对这些回答的评分，而微软研究院则发布了 Orca-2 模型，这是一个在新的合成推理数据集上对 Llama 2 模型进行微调的版本。十二月，伯克利大学发布了 Starling 模型，这是一个对 Open-Chat 模型进行 RLAIF 微调的版本，以及相关的数据集 Nectar，包含了 20 万条比较数据。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">正如我们看到的，今年整个领域的发展既依赖于通过使用高质量的预训练大型语言模型（LLMs）创建新数据集，也依赖于社区发布的各种开源模型，这使得该领域进步飞速！如果你现在在模型名称中看到这些名字中的任何一个，你就能够大概了解它的来源了🤗。</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      还有一些更专业的数据集，例如用于数学问题微调的 MetaMath 和 MathInstruct，以及涉及数学和代码指令的 Evol-Instruct，还有 CodeAlpaca 与 CodeCapybara 等代码指令相关的数据集也已发布。虽然这些数据集同样被用于提升模型在特定任务上的表现，但我们在此不会详细介绍它们。你还可以访问，令人心动的指令数据集，来查看其他相关数据集的集合。 
    </section></li></ul><span id="OSC_h2_7"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">开启定制模型的大门</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><span id="OSC_h3_8"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">模型融合：极致的定制化</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在开源社区的典范实践中，一个重要的里程碑是模型与数据的融合。随着每一次代码合并或提交，追溯所使用数据的来源变得愈发复杂 —— 许多公开的数据集本身就是其他数据集的汇编。同样，由于卓越性能的模型往往是在相似模型的基础上经过层层微调得来的（可参考 Mistral 的，衍生模型树），模型的发展历史也变得难以梳理。在这篇摘要中，我们尚未有足够的篇幅深入探讨这一引人入胜的技术领域，但在最后，我们将简要介绍一下它的概念。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">然而，「模型融合」 究竟是什么意思呢？</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">模型融合</strong> 是一种将不同模型的权重融合到一个单一模型中的方法，其理想目标是将每个模型的各自优势结合在一个统一的模型中。目前已有一些技术实现了这一目标，这些技术大多在社区论坛中得到扩展和发布，这是一个全球范围内的去中心化研究的典型案例，涵盖了从业者、研究人员到业余爱好者的广泛社区。其中一种最简单的公开方法是平均一组具有共同架构的模型的参数（示例 1，示例 2），但还存在更复杂的参数组合方法，例如确定每个模型中对特定任务最有影响力的参数（加权平均），或者在合并前考虑模型间参数的相互干扰，从而选择保留哪些参数（关联融合）。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这些技术使任何人都能轻松地生成模型的组合，而且由于大多数现代模型都是基于同一架构的变体，这一过程变得尤为简便。这也是 Open LLM leaderboard 上一些模型名称如 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">llama2-zephyr-orca-ultra</code> 的原因。这个特定的例子很可能是将 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">llama2</code> 和 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">zephyr</code> 模型合并后，再在 orca 和 ultra 数据集上进行微调的结果。通常，更多的细节可以在 Hugging Face 中心的相应模型卡片上找到。</p><span id="OSC_h3_9"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">参数高效微调：触手可及的个性化体验</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">有时候，你可能需要进行更为细致的个性化调整，但受限于硬件显存大小，无法加载完整模型进行微调。其实，你知道吗？微调时并不必须要用到模型的全部。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">你或许想尝试一种叫做 <strong style="color: black;">参数高效微调</strong>（Parameter-Efficient Fine-Tuning，PEFT）的方法。这项技术首先会冻结你所关注的预训练模型中的参数，然后在其基础上附加一些新的参数层，也就是我们所说的 「适配器」。接下来，你只需对这些专为你的任务设计的轻量级适配器权重进行微调，这些权重远小于原始模型的规模。这样，你仅需分享你的小型适配器权重（以及底层模型）即可！你可以在，这里，探索一系列引人入胜的 PEFT 技术。</p><span id="OSC_h3_10"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">量化：模型普及于各处</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我们已经看到，性能出色的模型现在形态各异…… 但即便如此，并不意味着它们对所有人都是触手可及的！一个拥有 300 亿参数的模型仅仅加载到内存中（还未开始使用）就可能需要超过 66GB 的 RAM，而并非社区中的每个人都有能力配备这样的硬件。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">这就是量化技术的用武之地！量化是一种特殊的技术，它通过改变模型参数的精度来减少模型的大小。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">量化是什么意思呢？</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在计算机中，数字是以一定的精度存储的，例如 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">float32</code>、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">float16</code>、<code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">int8</code> 等。精度不仅指明了数字类型（是浮点数还是整数），同时也指出了数字存储所占用的内存大小：例如 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">float32</code> 是在计算机上以 32 位存储的浮点数。要了解更深入的解释，请参见这个，链接。因此，数据的精度越高，它所占用的物理内存就越多，这是因为需要更多的位来存储这些数据。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">因此，如果你降低精度，就会减少模型参数在存储上占用的内存，进而减小模型的大小！这也意味着你降低了计算的实际精度，可能会降低模型的性能。然而，我们发现，在较大的模型上，这种性能下降实际上是，非常有限，的。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">回到我们之前的例子中，一个含有 300 亿参数的模型，在使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">float16</code> 格式时需要不到 66GB 的内存。如果采用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">8bit</code>，内存需求将减半至 33GB；若使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">4bit</code> 编码，则只需大约 16GB，进一步降低了内存的要求，使得模型更易于部署和使用。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">精度转换有多种方法，涉及不同的 「转换」 策略，每种策略都有其独特的优势和局限。目前流行的转换方法包括 bitsandbytes、GPTQ, 和 AWQ 等。有些开发者，例如 TheBloke，甚至正在将所有流行的模型进行转换，以便更容易地被社区使用。所有这些方法都是相对较新并且仍在不断发展之中，我们期待随着时间的推移，这些技术能够取得更多的进步。</p><span id="OSC_h2_11"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">接下来呢？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">年尾尚未到来！在这最后时刻，已经迎来了一些惊喜：新的架构是否终将超越简单高效的 Transformer 模型呢？</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">最新发布包括：</p><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      混合专家模型： 
    </section></li><ul style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;color: black;list-style-type: square;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
       Mixtral，该模型由 8 个子模型（仅解码器的 Transformer 模型）组成，对于每个输入，一个路由器会选择两个最佳子模型并将它们的输出求和。 
     </section></li></ul><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      几种状态空间模型（通过潜在空间将输入映射到输出的模型，可以根据任务需求表达为 RNN 或 CNN）： 
    </section></li><ul style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;color: black;list-style-type: square;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
       Mamba，增加了选择机制的状态空间模型 
     </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
       Striped Hyena，具有快速卷积核的状态空间模型 
     </section></li></ul></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">目前来说，这些新方法是否会取代 Transformer 模型还为时尚早，但状态空间模型确实非常有前景！</p><span id="OSC_h2_12"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">要点回顾</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><ul data-tool="mdnice 编辑器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      今年，从大型企业到初创公司，再到研究实验室，各种主体纷纷开放发布模型，这极大地赋能了社区，使其以前所未有的速度开始进行实验和探索。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      模型公告的开放性呈现出起伏变化，从年初的公开发布（数据集组合、权重、架构）到年末对训练数据守口如瓶，导致无法复现。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      开源模型出现在包括中国在内许多新的地方，有几个新的参与者将自己定位为语言模型竞争中的强劲竞争者。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      个性化定制的可能性达到了前所未有的高度，新策略的出现（如强化学习优化的微调、适配器、合并技术），虽然这仅仅是个开始。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      更小的模型尺寸和量化升级使得大型语言模型对更多人来说变得真正唾手可得！ 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      新的架构也随之出现 —— 它们是否最终会取代 Transformer 架构，仍是一个值得关注的问题。 
    </section></li></ul><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">各位朋友们，就是这样了！</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">希望你喜欢我们今年的回顾，从中学到了一些知识，并且和我一样，对于人工智能进步现在如此依赖开源和社区努力感到无比热情！🤗</p><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);"><span style="font-size: 14px;">英文原文:</span><url style="font-size: 14px;color: rgb(136, 136, 136);visibility: visible;display: block;"><span style="font-size: 14px;">https://huggingface.co/blog/2023-in-llms</span></url><span style="font-size: 14px;">原文作者：Clémentine Fourrier<br>译者: Xinyu Yang (杨新宇)，字节跳动算法工程师，工作方向为通过 SFT、RL 提升大模型 Math、Reasoning 能力。</span></p></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Hugging Face（gh_504339124f0f）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 04:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10555492</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10555492</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TinyEngine 服务端正式开源啦]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>背景介绍</h1><h2>TinyEngine 低代码引擎介绍</h2><p>随着企业对于低代码开发平台的需求日益增长，急需一个通用的解决方案来满足各种低代码平台的开发需求。正是在这种情况下，低代码引擎应运而生。它是一种通用的开发框架，通过对低代码平台系统常用的功能进行解构，将其划分为多个功能模块，并为每个模块定义了相应的协议和开发范式，使得开发者可以根据自身的业务需求，轻松定制开发出自己的低代码开发平台。</p><p>TinyEngine 提供了低代码底层能力，并集成了人工智能，从而使用户能够高效开发。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-engine%23%2Fhome" target="_blank">TinyEngine</a> 具有强大的拖拽功能，无论是图元还是复杂组件，都能在画布上带来流畅的体验。它适用于多场景的低代码平台开发，包括资源编排、流程编排、服务端渲染、模型驱动、移动端、大屏端以及页面编排等低代码平台。</p><p>TinyEngine 官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-engine" target="_blank">https://opentiny.design/tiny-engine</a><br> TinyEngine 源码：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank">https://github.com/opentiny/tiny-engine</a> （欢迎 star）</p><p><img src="https://oscimg.oschina.net/oscnet/up-fa7423149eca45391380663a32b595b208f.png" alt="" referrerpolicy="no-referrer"></p><h2>服务端开源介绍</h2><p>2023 年 9 月 21 日，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-engine%23%2Fhome" target="_blank">TinyEngine</a> 在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7280926568854667299" target="_blank">华为全联接大会正式宣布开源</a>，引发了广泛的关注，3 个月时间收获了 960 个 Star，组建了 4 个用户交流社群，成员数 772 名。</p><p>很多企业和个人开发者尝试基于 TinyEngine 搭建自己的低代码平台，为搭建企业 Web 应用提效，在使用过程中，大家也遇到了很多问题，比较常见的包括：如何对接服务端、如何导入第三方组件库、如何使用插槽、如何生成代码、如何开发自定义插件等，为此我们在 10 月 27 日策划了一次<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7298642242116452402" target="_blank">线上直播答疑活动</a>，邀请了团队技术专家为大家答疑解惑。</p><p>其中如何对接服务端是众多开发者非常关注的问题，为了帮助开发者打通低代码平台搭建的前后端整体流程，本次 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-engine%23%2Fhome" target="_blank">TinyEngine</a> 低代码引擎服务端配套代码的开源，让开发者能够深入了解 TinyEngine 低代码引擎的前后端运行机制，更能够让更多的小伙伴以更深的层次参与到产品共建，共同探讨并改进系统，推动其不断优化，带来更高的创新潜力，使得更多的人能够从中受益。</p><p>同时服务端的开源为自由定制和扩展提供了可能，开发者可以参考 TinyEngine 的代码，根据自身需求对服务端进行改造创新，从而使得产品更具灵活性，能够满足各种复杂的业务需求，构建一个强大而健壮的 TinyEngine 生态系统。</p><h1>核心特性</h1><p>当今互联网应用的复杂性和用户需求的多样性要求我们搭建一套灵活的、便于扩展的系统架构，以满足不断变化的业务需求。 因此我们引入了微服务的概念，将系统拆分为小而独立的服务单元，使得每个服务单元都可以独立开发、测试和部署。这种架构不仅提高了团队的协作效率，还使得系统更容易扩展和维护。</p><ul><li>TinyEngine 设计器微服务选择了<strong>基于 Node.js 的技术栈</strong>，为前端开发者提供了一致的开发体验，无需学习额外的语言即可全栈开发，降低了开发难度和学习曲线，避免了学习新语言的困扰。更能够从服务端的角度去理解 TinyEngine 设计器的运行原理与设计思想。</li><li>在我们的架构设计中，我们<strong>采用了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.eggjs.org%2Fzh-CN" target="_blank">Egg.js</a> 作为业务接口微服务的框架</strong>。Egg.js 优秀的设计和丰富的插件生态系统，使得我们能够迅速构建可维护、可扩展的微服务，从而确保系统的稳定性和可维护性。</li><li>为了降低服务耦合，我们还单独封装了<strong>提供数据库操作接口的数据中心微服务</strong>，在框架选型上我们选择了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.strapi.io%2F" target="_blank">Strapi</a>，Strapi 是一个开源数据管理框架。不仅提供了强大的数据管理和查询功能，还支持自定义内容类型和灵活的 API 构建，为我们的微服务提供了丰富的数据支持。Strapi 的易用性和可扩展性使得我们能够高效地管理和发布数据，确保前端业务接口始终能够获得及时、准确的数据支持。</li></ul><p>综上所述，我们的技术架构旨在提供高效、可维护、可扩展的系统，充分利用 Node.js 和现代化的开源工具，使我们能够更好地满足不断变化的业务需求。这种架构不仅提高了开发效率，还为未来的扩展和创新提供了坚实的基础。</p><h1>服务端架构</h1><p>根据上面的介绍，开发者可以根据微服务这一特性，轻松扩展并实现自己的 TinyEngine 服务端架构。</p><ul><li>业务接口微服务（webService）：构建业务的引擎， 汇总连接其他微服务为前端提供接口。</li><li>数据中心 (data-center)： 作为数据基座，统一进行数据管理，为其他微服务提供一致性的数据支持。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-f120981dacaac81db69e9a2f113ef113e3b.png" alt="" referrerpolicy="no-referrer"></p><p>根据上述架构特点，我们可以在此基础上，通过核心的 webService (业务接口微服务) 搭配任务队列服务 (RabbitMq、 Kafka、 RocketMq 等等) 连接其他功能微服务， 从而拓展整体系统的功能，例如：</p><ul><li>构建服务：由 webService 收集用户请求触发任务队列执行耗费机器资源的构建设计器、区块、物料的相关服务。</li><li>爬虫服务：单独封装，安装了 puppeteer 服务器的微服务，由 webService 触发去执行一些爬取数据、代理登录等等操作。</li><li>AI 大模型相关服务：连接自己内部 AI 大模型， 进行设计器智能化相关的 AI 代码生成、指令操作等等功能的。</li><li>发布服务：封装自己的 CI/CD 流水线微服务，结合设计器代码产出，使代码生产-构建-部署一条龙式运作。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-4558b19a5a930a638d800a5208bcb821d59.png" alt="" referrerpolicy="no-referrer"></p><h1>硬件配置</h1><h2>本地开发</h2><p>推荐使用 <code>windows</code> 操作系统， 推荐配置如下：</p><ul><li>64 位操作系统</li><li>12 核 CPU</li><li>32G 内存</li></ul><h2>服务容器化部署</h2><p>以下信息为支撑 50 qps 并发量的配置参考， 开发者可根据实际情况进行具体问题具体分析，配置信息仅供参考.</p><p>配置单位：</p><ul><li>U: cpu 核数</li><li>G: 内存单位</li></ul><p>在配置负载均衡的情况下推荐：</p><table><thead><tr><th>服务</th><th>配置</th><th>工作负载数量</th></tr></thead><tbody><tr><td>webService</td><td>1U+3G</td><td>4</td></tr><tr><td>data-center</td><td>1U+2G</td><td>4</td></tr></tbody></table><h1>FAQ</h1><p><strong>1、服务端开源之后，如果不想启动 webservice 和 datacenter 两个后端服务器，是否还能沿用原来 mockServer？</strong><br> 答：可以正常使用 mockServer，启动方式和原先一致，直接在项目里执行 <code>pnpm dev</code> 即可</p><p><strong>2、如果本地启动了 webservice 和 datacenter，那么前端本地工程是否还需要更改配置？如果需要，如何更改配置？</strong><br> 答：需要更改配置，更改流程如下： 启动 <code>tinyengine</code></p><p>修改 <code>packages/design-core/vite.config.js</code> 中 origin 的值为自己本地 webService 项目的地址端口（webService 端口默认为 7011）</p><p>运行如下脚本并启动</p><pre><code class="language-sh">pnpm install  # 第一次启动项目需要
pnpm serve:frontend
</code></pre><p>启动成功后浏览器会自动打开设计器页面</p><p><img src="https://oscimg.oschina.net/oscnet/up-a0f5b0133144d2b27013c73bacbf232675f.png" alt="" referrerpolicy="no-referrer"></p><p>具体搭建流程可参考官网本地化部署文档：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-engine%23%2Fhelp-center%2Fcourse%2Fbackend%2F51" target="_blank">TinyEngine 服务端开源部署 </a></p><h1>未来规划</h1><p>1，人工智能：计划将低代码平台与 AIGC（人工智能生成内容）技术相结合，为用户提供更加智能、高效的应用开发体验。后续我们考虑将低代码平台的开发流程与 AIGC 技术相结合，通过自然语言处理、机器学习和深度学习等技术，实现应用界面的自动生成、功能模块的智能推荐和代码的自动化生成等功能。</p><p>2，模型驱动：我们将致力于将低代码平台与模型驱动能力相结合，为用户提供更加高效、智能的开发体验。深入研究各种业务模型，包括数据模型、业务流程模型等，以了解其特性和需求。后续，我们将低代码平台的开发流程与模型驱动能力相结合，通过可视化建模工具和自动化技术，实现业务模型的快速构建和部署。通过这一创新性的接入方式，用户将能够更加高效地构建和调整业务模型，降低开发难度和成本。</p><h2><strong>关于 OpenTiny</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-1c661a9c0916f9dabf9cf1c4aeba473fb68.png" alt="" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">OpenTiny</a> 是一套企业级 Web 前端开发解决方案，提供跨端、跨框架、跨版本的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-vue%2Fzh-CN%2Foverview" target="_blank">TinyVue 组件库</a>，包含基于 Angular+TypeScript 的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-ng%2Foverview" target="_blank">TinyNG 组件库</a>，拥有灵活扩展的低代码引擎 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-engine%23%2Fhome" target="_blank">TinyEngine</a>，具备主题配置系统<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Fdesigntheme%2Fhome" target="_blank">TinyTheme</a> / 中后台模板<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Fpro%2Fhome" target="_blank"> TinyPro</a>/ <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-cli%2Fhome" target="_blank">TinyCLI </a>命令行等丰富的效率提升工具，可帮助开发者高效开发 Web 应用。</p><hr><p>欢迎加入 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2F" target="_blank">OpenTiny 开源社区</a>。添加微信小助手：opentiny-official 一起参与交流前端技术～更多视频内容也可关注<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F15284299%3Fspm_id_from%3D333.1007.0.0" target="_blank">B 站</a>、抖音、小红书、视频号</p><p>OpenTiny&nbsp;也在持续招募贡献者，欢迎一起共建</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">OpenTiny 官网</a>：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">https://opentiny.design/</a></strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2F" target="_blank">OpenTiny 代码仓库</a>：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2F" target="_blank">https://github.com/opentiny/</a></strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-vue" target="_blank">TinyVue 源码</a>：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-vue" target="_blank">https://github.com/opentiny/tiny-vue</a></strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank">TinyEngine 源码</a>： <strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank">https://github.com/opentiny/tiny-engine</a></strong></p><p>欢迎进入代码仓库 Star🌟<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank">TinyEngine</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-vue" target="_blank">TinyVue</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Fng" target="_blank">TinyNG</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-cli" target="_blank">TinyCLI</a>~</p><p>如果你也想要共建，可以进入代码仓库，找到&nbsp;good first issue 标签，一起参与开源贡献~</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 03:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6769809/blog/10555626</guid>
            <link>https://my.oschina.net/u/6769809/blog/10555626</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 年化收入超 16 亿美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fopenais-annualized-revenue-tops-1-6-billion-as-customers-shrug-off-ceo-drama" target="_blank">The Information</a> 援引知情人士消息称，受益于 ChatGPT 产品的强劲增长，OpenAI 最近的年化收入已经从 10 月中旬的 13 亿美元增至 16 亿美元。</span></p><p><span style="color:#000000">这一增长表明，「即便该公司因为 11 月份的领导层危机为竞争对手提供了抢夺客户的机会，但其仍能保持向企业销售人工智能产品的业务势头。」</span></p><p><img height="307" src="https://oscimg.oschina.net/oscnet/up-bc1feecce3c765f974f328d2a2ace13b9a6.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenAI 于 2023 年 2 月推出 ChatGPT 服务的付费版本 ChatGPT Plus 后，销售额开始快速增长。此前，该公司主要通过应用程序接口向开发者提供 AI 模型来进行创收。数据显示，该公司 2022 年亏损 5.4 亿美元，营收仅为 2800 万美元。</span></p><p><span style="color:#000000">路透社报道称，OpenAI 最初预计在 2023 年完成 2 亿美元的销售额。但事实证明，ChatGPT Plus 比预期的要更受欢迎：在 8 月份，OpenAI 的营收就突破了 10 亿美元，10 月达到了 13 亿美元。该公司的销售势头预计将持续到 2024 年。OpenAI 的一些高管认为，截至年底，其年化经常性收入将增长近四倍，达到 50 亿美元。</span></p><p><span style="color:#000000">「这种乐观的前景表明，该公司可能不会仅仅依靠现有产品的需求来维持其销售增长。特别是，它可能计划推出新的 AI 服务，从而创造额外的收入来源。」</span></p><p><span style="color:#000000">OpenAI 收入的快速增长也可能有助于其在来年获得投资者更高的估值。日前曾有<a href="https://www.oschina.net/news/272549/openai-valuation-100-billion-funding-round">消息称</a>，OpenAI 正在以 1000 亿美元或以上的估值筹集新一轮融资。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 03:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273759/openais-annualized-revenue-tops-1-6b</guid>
            <link>https://www.oschina.net/news/273759/openais-annualized-revenue-tops-1-6b</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[vivo 正式加入 CNCF 云原生计算基金会]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><strong style="outline: 0px;visibility: visible;">vivo 近期完成了新会员的 Onboarding 流程， 已正式加入 CNCF 云原生计算基金会</strong>（<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io" textvalue="https://www.cncf.io" linktype="text" imgurl="" tab="outerlink" data-linktype="2">https://www.cncf.io</a>）。<strong style="letter-spacing: 0.544px;outline: 0px;visibility: visible;"></strong></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><span style="text-align: center;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><br></span></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><span style="text-align: center;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014267" data-ratio="0.5613346418056918" data-s="300,640" src="https://oscimg.oschina.net/oscnet/d2d6894b-bacd-42d9-b2d8-05a6782d0354.png" data-type="png" data-w="1019" style="letter-spacing: 0.578px;text-align: center;text-wrap: wrap;" referrerpolicy="no-referrer"></span></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><span style="text-align: center;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"></span></p><p><span style="background-color: rgb(255, 255, 255);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;">C</span><span style="background-color: rgb(255, 255, 255);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;">NCF 云原生计算基金会 （Cloud Native Computing Foundation）是 Linux 基金会的一部分，是开源、供应商中立的云原生计算生态组织，致力于云原生应用推广和普及。我们希望通过加入 CNCF 基金会</span><strong style="font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;">，推动云原生技术在 vivo 内部的应用和发展，助力自身业务高效交付；同时进一步加强与全球云原生开源社区的交流沟通和知识分享，共同推动行业云原生技术生态的可持续发展</strong><span style="background-color: rgb(255, 255, 255);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;">。</span></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;">在正式加入 CNCF 云原生计算基金会之前，vivo 内部研发团队积极探索与实践云原生技术，在多个业务场景下应用云原生项目，助力业务发展。</p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><br></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014268" data-ratio="0.43425925925925923" data-s="300,640" src="https://oscimg.oschina.net/oscnet/695497a4-859d-487c-b98b-7537cebc2053.jpg" data-type="jpeg" data-w="1080" style="" referrerpolicy="no-referrer"><span style="font-size: var(--articleFontsize);letter-spacing: 0.034em;text-align: justify;"></span></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;text-align: center;"><span style="color: rgb(136, 136, 136);font-size: 14px;">vivo 在云原生领域的项目采纳现状</span></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;text-align: center;"><span style="color: rgb(136, 136, 136);font-size: 14px;">截止 2023 年 12 月</span></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;text-align: left;"><br></p><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: right;visibility: visible;"><section style="padding: 10px;outline: 0px;display: inline-block;width: 677px;border-width: 1px;border-style: solid;border-color: transparent;background-color: rgb(239, 239, 239);height: auto;visibility: visible;"><section powered-by="xiumi.us" style="outline: 0px;font-size: 14px;text-align: justify;visibility: visible;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><strong style="font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(239, 239, 239);outline: 0px;visibility: visible;">应用方面：</strong><br></p><p style="outline: 0px;visibility: visible;"><span style="font-size: 15px;">在云原生领域的应用主要包括基于 Kubernetes 的容器编排、服务发现和负载均衡、容器镜像管理、日志收集和分析等场景。通过使用 Openkruise、Helm、Harbor、Containerd、Dragonfly、Fluentd 等开源项目与工具，vivo 实现了基于容器平台的应用发布和管理，提高了业务交付效率和系统可靠性。</span></p></li></ul><p style="outline: 0px;visibility: visible;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="outline: 0px;visibility: visible;"><strong><span style="font-size: 15px;">容器平台能力建设方面：</span></strong></p><p style="outline: 0px;visibility: visible;"><strong><span style="font-size: 15px;"></span></strong><span style="font-size: 15px;letter-spacing: 0.544px;">主要包括基础设施建设、平台架构设计和运维管理等方面。通过使用 Kubernetes 等容器编排技术，vivo 构建了一套完整的容器平台，包括容器集群运维、容器网络、存储管理、应用发布、安全管理等模块，为企业内部多个业务线提供了稳定、可靠的容</span><span style="font-size: 15px;letter-spacing: 0.544px;">器平台。</span></p></li></ul><p style="outline: 0px;visibility: visible;"><span style="font-size: 15px;"><br></span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 15px;"><strong>敢于探索实践方面：</strong></span></p><p><span style="font-size: 15px;"></span><span style="font-size: 15px;letter-spacing: 0.544px;">vivo 在云原生领域勇于探索和实践，积极参与开源社区和代码贡献，持续探索并推广新技术及其应用场景。</span><span style="font-size: 15px;letter-spacing: 0.544px;">同时有积极参与 CNCF 应用交付 TAG 旗下相关工作组的贡献，推广和传播平台工程相关的白皮书、成熟度模型等相关实践和标准。</span></p></li></ul></section></section></section><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><br style="outline: 0px;visibility: visible;"></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;">此外，vivo 持续保持与行业交流及合作，共同探索云原生时代的软件工程之道。2023 年 9 月由 Linux 基金会、云原生计算基金会（CNCF）主办的 <a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lfasiallc.com%2Fkubecon-cloudnativecon-open-source-summit-china%2F" textvalue="KubeCon + CloudNativeCon + Open Source Summit China" linktype="text" imgurl="" tab="outerlink" data-linktype="2">KubeCon + CloudNativeCon + Open Source Summit China</a> 在上海举行，vivo 在平台工程专题做了 2 个主题分享。同时，我们也积极支持并参与 KCD 等区域性 Meetup 活动。</p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014269" data-ratio="1.0716981132075472" data-s="300,640" src="https://oscimg.oschina.net/oscnet/8a9a6912-227d-44eb-ac54-faf41d593727.jpg" data-type="jpeg" data-w="1060" style="" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;">未来，vivo 将持续探索与实践云原生技术，在 CNCF 云原生基金会积极参与和贡献，并与各成员持续加强交流合作。</p><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: right;visibility: visible;"><section style="padding: 10px;outline: 0px;display: inline-block;width: 677px;border-width: 1px;border-style: solid;border-color: transparent;background-color: rgb(239, 239, 239);height: auto;visibility: visible;"><section powered-by="xiumi.us" style="outline: 0px;font-size: 14px;text-align: justify;visibility: visible;"><ul class="list-paddingleft-1" style="width: 555.438px;"><li><p><strong style="font-size: 15px;letter-spacing: 0.544px;outline: 0px;visibility: visible;">生产实践方面：</strong><br></p><p style="outline: 0px;visibility: visible;"><span style="font-size: 15px;">将继续推进云原生技术在企业中的应用和发展，加强容器化和微服务能力，探索和实践最新的容器化和微服务技术，基于此实践积极向上游提供反馈，最终提高我们自身的业务交付效率和用户体验。</span></p></li></ul><p style="outline: 0px;visibility: visible;"><br></p><ul class="list-paddingleft-1" style="width: 555.438px;"><li><p style="outline: 0px;visibility: visible;"><strong><span style="font-size: 15px;">社区贡献方面：</span></strong></p><p style="outline: 0px;visibility: visible;"><span style="font-size: 15px;">以企业中应用云原生技术遇到的实际问题为推动力，加强与 CNCF 组织和其他企业的技术交流与合作，积极参与 CNCF 项目开发和相关工作组的贡献并传播云原生技术<span style="font-size: 15px;letter-spacing: 0.544px;">。</span></span><span style="font-size: 15px;letter-spacing: 0.544px;"></span></p></li></ul></section></section></section><p powered-by="xiumi.us" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);visibility: visible;"><br></p><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;visibility: visible;"><section style="padding-bottom: 3px;outline: 0px;display: inline-block;vertical-align: middle;border-bottom: 1px solid rgb(65, 95, 255);border-top-color: rgb(65, 95, 255);border-right-color: rgb(65, 95, 255);border-left-color: rgb(65, 95, 255);visibility: visible;"><section style="outline: 0px;border-bottom: 3px solid rgb(65, 95, 255);border-top-color: rgb(65, 95, 255);border-right-color: rgb(65, 95, 255);border-left-color: rgb(65, 95, 255);font-size: 16px;color: rgb(65, 95, 255);visibility: visible;"><p style="outline: 0px;visibility: visible;">关于 CNCF</p></section></section></section><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><br style="outline: 0px;letter-spacing: 0.578px;visibility: visible;"></p><section style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.5;visibility: visible;"><p style="outline: 0px;text-align: left;visibility: visible;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="200" data-cropsely1="0" data-cropsely2="77" data-imgfileid="100014263" data-ratio="0.16574074074074074" data-s="300,640" src="https://oscimg.oschina.net/oscnet/55ece88a-d979-4dbb-941c-1ed46907bd24.jpg" data-type="png" data-w="1080" style="outline: 0px;visibility: visible !important;width: 465px;height: 77px;" referrerpolicy="no-referrer"></p></section><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;justify-content: flex-start;display: flex;flex-flow: row;visibility: visible;"><section style="padding-left: 8px;outline: 0px;display: inline-block;width: 578px;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;align-self: flex-start;flex: 0 0 auto;visibility: visible;"><section powered-by="xiumi.us" style="outline: 0px;color: rgba(0, 0, 0, 0.5);text-align: justify;visibility: visible;"><p style="outline: 0px;visibility: visible;">使命：让云原生无处不在</p></section></section></section><p powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);visibility: visible;"><br style="outline: 0px;visibility: visible;"></p><section powered-by="xiumi.us" style="margin-bottom: 0px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);"><p style="outline: 0px;">CNCF 云原生计算基金会 (Cloud Native Computing Foundation, https://www.cncf.io/）成立于 2015 年 12 月，是非营利性 Linux 基金会（https://www.linuxfoundation.org/）的一部分，其使命是「让云原生技术无处不在」（参考 CNCF 章程 ）。</p><p style="outline: 0px;"><br style="outline: 0px;"></p><p style="outline: 0px;">CNCF 致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术，托管全球技术基础设施的关键组件。通过将最前沿的模式民主化，让这些创新为大众所用。CNCF 汇集了世界顶级的开发者、最终用户和供应商，并举办了最大的开源开发者大会。</p><p style="outline: 0px;"><br></p><p style="outline: 0px;"><span style="letter-spacing: 0.544px;text-align: center;">相关资料：</span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p>Linux 基金会</p><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2F" textvalue="https://www.linuxfoundation.org/" linktype="text" imgurl="" tab="outerlink" data-linktype="2">https://www.linuxfoundation.org/</a></p></li><li><p>CNCF 云原生计算基金会</p><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2F" textvalue="https://www.cncf.io/" linktype="text" imgurl="" tab="outerlink" data-linktype="2">https://www.cncf.io/</a></p></li><li><p>CNCF 章程</p></li></ul><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcncf%2Ffoundation%2Fblob%2Fmain%2Fcharter.md" textvalue="https://github.com/cncf/foundation/blob/main/charter.md" linktype="text" imgurl="" tab="outerlink" data-linktype="2">https://github.com/cncf/foundation/blob/main/charter.md</a></p><p><br></p></section><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;"><section style="padding: 3px;outline: 0px;display: inline-block;border-bottom: 1px solid rgb(65, 95, 255);color: rgb(65, 95, 255);"><p style="outline: 0px;">关注我们</p></section></section><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);text-align: left;justify-content: flex-start;display: flex;flex-flow: row;"><section style="padding: 22px;outline: 0px;display: inline-block;width: 677px;vertical-align: top;align-self: flex-start;flex: 0 0 auto;background-color: rgb(247, 247, 247);"><section powered-by="xiumi.us" style="outline: 0px;text-align: justify;"><ul class="list-paddingleft-1" style="padding-left: 40px;outline: 0px;list-style-position: outside;"><li style="outline: 0px;"><p style="outline: 0px;">【移动 OSS】</p><p style="outline: 0px;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.vivo.com%2F" textvalue="https://opensource.vivo.com" linktype="text" imgurl="" tab="outerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">https://opensource.vivo.com</a></p></li><li style="outline: 0px;"><p style="outline: 0px;">【互联网 OSS】</p><p style="outline: 0px;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvivo" textvalue="https://github.com/vivo&nbsp;" linktype="text" imgurl="" tab="outerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">https://github.com/vivo&nbsp;</a></p></li><li style="outline: 0px;"><p style="outline: 0px;">【<span style="outline: 0px;letter-spacing: 0.578px;">开源频道</span>】@vivo 互联网技术&nbsp;&nbsp;<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26action%3Dgetalbum%26album_id%3D2951473838086422533%23wechat_redirect" textvalue="#开源&nbsp;" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2" style="outline: 0px;color: var(--weui-LINK);-webkit-user-drag: none;cursor: pointer;">#开源&nbsp;</a></p></li></ul></section></section></section><p><br></p><section class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互联网技术" data-alias="vivoVMIC" data-signature="分享 vivo 互联网技术干货与沙龙活动，推荐最新行业动态与热门会议。" data-from="0" data-is_biz_ban="0"></mp-common-profile></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - vivo 互联网技术（vivoVMIC）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 03:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/10448921</guid>
            <link>https://my.oschina.net/vivotech/blog/10448921</link>
            <author>
                <![CDATA[vivo 互联网技术]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[飞致云开源社区月度动态报告（2023 年 12 月）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start"><span><span style="color:#000000">自 2023 年 6 月起，中国领先的开源软件公司 FIT2CLOUD 飞致云以月度为单位发布《飞致云开源社区月度动态报告》，旨在向广大社区用户同步飞致云旗下系列开源软件的发展情况，以及当月主要的产品新版本发布、社区运营成果等相关信息。</span></span></p><p style="color:#000000; text-align:start"><span><strong><span style="color:#00355d">飞致云开源大屏（2023 年 12 月）</span></strong></span></p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ce20816fb99437841e5fd716dc8614c9a48.png" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><span>▲图 1 飞致云开源大屏（2023.12.29 12:00）</span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">2023 年 12 月飞致云开源软件运营数据概览（统计时间为 2023.12.1～2023.12.29）</span></span></p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-7f1d375b645d195bf7e8b90007275b91588.png" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:center"><strong><span style="color:#3370ff">2023 年 12 月产品发布事件</span></strong></p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ Halo 开源建站工具</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 1 日，强大易用的开源建站工具 Halo 正式发布 2.11.0 版本。在这一版本中，Halo 新增个人中心功能，将所有和用户自身相关的功能移动到个人中心。同时，Halo 进行了 50 多项功能优化和问题修复。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ DataEase 开源数据可视化分析工具</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 11 日，DataEase 开源数据可视化分析平台正式发布 v2.1.0 版本。</p><p style="color:#000000; text-align:start">这一版本的功能升级包括：新增模板中心，用户可以通过模板中心的模板快速创建仪表板和数据大屏；新增「系统设置」功能模块，该模块包含系统参数、认证设置、嵌入式管理、平台对接四个子模块。在「系统参数」子模块中，用户可以对常用的系统设置项进行管理，「认证设置」子模块支持 CAS（中央认证服务）、LDAP（轻量级目录访问协议）、OIDC（开放 ID 连接）等常用认证协议的对接，在「嵌入式管理」子模块中用户可以创建嵌入式应用，通过嵌入式应用将 DataEase 嵌入到第三方平台中，「平台对接」子模块目前已支持飞书平台的接入，用户可以通过飞书扫码的方式快速登录到 DataEase 平台；数据准备方面，新版 DataEase 支持数据集和数据源的复制功能，方便用户快速创建类似的数据资源。</p><p style="color:#000000; text-align:start">此外，DataEase 开源项目组还对其他一些常用的功能进行了功能优化和问题修复。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ 1Panel 开源面板</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 18 日，现代化、开源的 Linux 服务器运维管理面板 1Panel 正式发布 v1.9.0 版本。</p><p style="color:#000000; text-align:start">在这一版本中，1Panel 引入了新的工具箱管理功能，包含 Swap 分区管理、Fail2Ban 管理等功能。此外，1Panel 针对网站证书管理功能进行了全面重构，现在支持添加 ZeroSSL、BuyPass 和 Google Cloud 等 ACME 账户，还新增了 GoDaddy、Name.com、NameCheap、NameSilo 等 DNS 账户。在申请证书时，系统支持多种加密算法，能够创建自签名证书，并且提供证书的上传、下载功能，用户还可以批量删除证书，将证书推送至本地目录。容器配置页面也新增了与 IPv6 相关的配置选项。</p><p style="color:#000000; text-align:start">此外，1Panel 开源项目组还进行了 70 多项功能更新和问题修复。1Panel 应用商店新增了 10 款应用，并且更新了 20 款应用。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ JumpServer 开源堡垒机</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 25 日，JumpServer 开源堡垒机正式发布 v3.10 LTS（Long Term Support）版本。JumpServer 开源项目组将对 v3.10 LTS 版本提供长期支持，定期迭代发布小版本，持续进行问题修复更新并针对部分功能进行优化。欢迎广大用户升级使用 v3.10 LTS 版本。</p><p style="color:#000000; text-align:start">在这一版本中，JumpServer 重构了「标签」功能，支持全局标签管理，赋予了「标签」更为灵活、更为强大的功能。从 JumpServer v3.10.0 版本开始，「标签」不仅能绑定到资产上，还能够绑定到其他资源上，让其他资源通过「标签」功能拥有额外的功能属性。同时，JumpServer 新增 Chat AI 小助手功能，支持对接 ChatGPT，实现了多个用户可以在 JumpServer 浏览器功能界面直接与 ChatGPT 进行对话的能力，极大地提高了用户的使用率及工作效率。</p><p style="color:#000000; text-align:start">另外，「账号收集」功能支持将远程服务器中不存在的账户进行同步删除；「文件管理」功能支持批量传输文件，将批量命令和批量传输文件集中到工作台界面。这样一来，管理员可以让资产功能以更加方便的方式直接暴露给用户使用。</p><p style="color:#000000; text-align:start">X-Pack 增强包方面，JumpServer 支持第三方客户端直连 SQL Server 数据库，支持 Slack 平台的用户认证及消息通知功能。同时，新版本 JumpServer 还支持配置备案信息至登录页面，支持使用 Linux 系统作为远程应用发布机。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ MeterSphere 开源持续测试平台</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 28 日，MeterSphere 开源持续测试平台发布 v2.10.10 LTS 版本。</p><p style="color:#000000; text-align:start">在这一版本中，UI 测试方面，新增文件上传限制、添加关联文件时过滤已存在关联关系的文件；测试跟踪方面，在用例评审时支持左侧模块树功能、表头默认不显示所属模块字段、本地附件转存文件库时排除第三方存储库模块；接口测试方面，去除接口定义路径结尾的空格、接口自动化表头增加所属模块字段。此外，MeterSphere 项目组还进行了 8 项功能优化和 22 项漏洞修复工作。</p><p style="color:#000000; text-align:center"><strong><span style="color:#3370ff">其他重要事件</span></strong></p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ 飞致云与上海吉谛达成战略合作，获得 Gitea 企业版中国大陆地区独家代理权</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 13 日，FIT2CLOUD 飞致云宣布与上海吉谛达成战略合作，FIT2CLOUD 飞致云获得上海吉谛旗下代码托管平台 Gitea 企业版中国大陆地区独家代理权。</p><p style="color:#000000; text-align:start">在 Gitea 社区版的基础之上，Gitea 企业版提供面向企业级应用场景的 X-Pack 增强包及企业级支持服务，有效助力企业快速构建并运营自托管的新一代代码托管平台。</p><p style="color:#000000; text-align:start">Gitea v1.21 版本的企业版软件已经于 2023 年 11 月正式发布，首批开放的 X-Pack 增强包功能包括：企业微信/钉钉/飞书对接集成、供应链安全扫描、数据安全备份、分布式部署架构和国产化信创适配等。</p><p style="color:#000000; text-align:start"><img alt="" height="608" src="https://oscimg.oschina.net/oscnet/up-d57c9939ebd603754752cc23d2f9e9aca95.jpg" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><span>▲ 图 2 飞致云与上海吉谛达成战略合作</span></p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ FIT2CLOUD 飞致云荣膺「2023 年度 OSCHINA 优秀开源技术团队」奖项</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 8 日，知名开源技术社区 OSCHINA（开源中国）公布了「2023 年度 OSCHINA 优秀开源技术团队」入选名单。凭借在开源软件研发和开源社区运营方面的年度优异表现，FIT2CLOUD 飞致云再次收获「优秀开源技术团队」奖项。这也是继 2021 年和 2022 年之后，FIT2CLOUD 飞致云连续第三年荣膺该项荣誉。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ JumpServer 开源堡垒机 V2 社区版即将停止维护的通知</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 1 日，JumpServer 开源项目组发布重要通知。如《关于 JumpServer 开源堡垒机 V2 版本产品生命周期的相关说明》所示，JumpServer 开源堡垒机 V2 版本（社区版）将于 2023 年 12 月 31 日停止维护支持。</p><p style="color:#000000; text-align:start">出于产品自身迭代和用户需求升级的要求，2023 年 2 月 27 日，JumpServer 开源堡垒机正式发布 v3.0 版本，目前已更新至 v3.10 LTS 版本。JumpServer 开源项目组建议社区版和企业版用户更新至 JumpServe v3.x 版本，以使用更多的新增功能并获取更好的软件使用体验。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ Halo 推出 AI 助手插件</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 15 日，Halo AI 助手插件上线。AI 助手插件通过扩展编辑器功能，为 Halo 默认编辑器带来了丰富的 AI 辅助功能。用户可以通过选中文字或者使用/命令的方式快速呼出 AI 对话框。AI 助手插件目前使用 OpenAI 的接口来提供 AI 能力支持，用户可以自定义 OpenAI 接口地址，选择切换不同的模型或者在网络不通的情况下配置代理使用。用户访问 Halo 应用市场，即可下载体验 Halo AI 助手插件。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ DataEase 漏洞通知及修复方案（DE-2023.12.19）</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 19 日，DataEase 项目组发布了编号为「DE-2023.12.19」的漏洞通知及修复方案，请用户尽快将 DataEase 升级至 v1.18.11 及以后的版本。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">■ Halo 1.x 停止维护公告</span></strong></p><p style="color:#000000; text-align:start">2023 年 12 月 21 日，Halo 开源项目组发布《Halo 1.x 停止维护公告》。为了集中资源和精力去持续改进和维护 Halo 的最新版本，Halo 1.x 版本将于 2023 年 12 月 31 日停止维护。Halo 开源项目组提供了详细的从 1.x 版本迁移到 2.x 版本的升级指南，您可以访问官方文档：《从 Halo 1.x 迁移》<span style="color:#172b4d">（</span>https://docs.halo.run/getting-started/migrate-from-1.x/<span style="color:#172b4d"><span>&nbsp;</span>）</span>来了解详情。</p><p style="color:#000000; text-align:start"><strong><span style="color:#00355d">关于飞致云开源大屏</span></strong></p><p style="color:#000000; text-align:start">飞致云开源大屏（https://bi.fit2cloud.com/link/6CgpMHrT）是 FIT2CLOUD 飞致云为展示其旗下开源软件的社区运营情况制作的数据仪表板。该大屏使用 DataEase 开源数据可视化分析平台制作，实时呈现飞致云开源社区近 30 日内的动态信息。</p><p style="color:#000000; text-align:start">广大社区用户可以通过该大屏了解飞致云旗下开源项目的 GitHub Star、Fork、Issue、贡献者等指标的数量信息，以及近 30 日内新增的 Star、Fork、下载、Issue、PR 数量等，同时该大屏还展示了飞致云旗下开源项目的 Issue 趋势、Commit 趋势、PR 趋势、Issue 生命周期等。</p><p style="color:#000000; text-align:start">除了展示所有项目的汇总信息外，该大屏还支持用户分类别查看 JumpServer、DataEase、MeterSphere、Halo、1Panel、CloudExplorer Lite 六个开源项目的独立运营数据。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 02 Jan 2024 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/10469745</guid>
            <link>https://my.oschina.net/u/4736111/blog/10469745</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
