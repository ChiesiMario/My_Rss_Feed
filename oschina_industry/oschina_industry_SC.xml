<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 14 Dec 2023 02:31:52 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[cprobe —— All-in-One 的探针采集器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start">cprobe 是一个缝合怪，整合 Prometheus 服务发现的能力以及各类 Exporter 的能力，预期是做一个 All-in-One 的探针采集器。为何有此想法呢？主要是社区里各类 Exporter 存在以下问题：</p><ul><li>良莠不齐：有的 Exporter 写的非常棒，有的则并不完善，有些监控类别甚至有多个 Exporter，选择困难</li><li>写法各异：Exporter 所用的日志库、配置文件管理方式、命令行传参方式各异</li><li>倚重边车模式：有些 Exporter 和采集目标之间是一对一的关系，有几个采集目标就需要部署几个 Exporter，在 Kubernetes 环境下相对容易管理，在物理机虚拟机环境下管理起来就比较复杂了，而且多个 Exporter 还会带来资源成本的提升</li><li>配置文件切分：对于非边车模式的 Exporter，即一个 Exporter 对应多个采集目标的，通常很难做到不同的采集目标不同的配置，期望能有一种配置文件切分 INCLUDE 机制，不同的采集目标采用不同的配置</li><li>缺乏监控目标服务发现：对于支持 /probe 模式的 Exporter，服务发现就通过 Prometheus + relabel 模式来实现了，如果不支持 /probe 模式的 Exporter 则缺乏监控目标的服务发现机制</li></ul><p>要是能有一个统一的采集器把这些能力集成起来，统一规范化设计就好了，cprobe 应运而生。</p><h2 style="text-align:start">对比</h2><p style="color:#1f2328; text-align:start">社区有一些其他采集器，比如 grafana-agent，也是一个缝合怪，也是把各类 Exporter 的能力整合在一起，但是整合的非常生硬，缺少统一化设计，对目标实例的服务发现支持较弱；telegraf 和 categraf 则自成一派，指标体系没有拥抱 Prometheus exporter 生态，相关仪表盘、告警规则资源匮乏，另外服务发现机制做的也不好。datadog-agent 确实比较完备，但是生态上也是自成一派，服务于自身的 SaaS 服务，较少有开源用户采用。</p><p style="color:#1f2328; text-align:start">以我当前的认知，监控数据的采集大抵需要三个角色，一个是部署在所有的目标机器上的，比如使用 categraf，中心端需要两个采集器，一个用于采集 Prometheus 协议的端点数据，可以使用 vmagent 或 Prometheus agent mode，另外一个用于采集所有非 Prometheus 协议的端点数据，计划就是 cprobe。</p><h2 style="text-align:start">当前进展</h2><p style="color:#1f2328; text-align:start">cprobe 刚刚起步，目前主要是在完善基础框架，框架层面已经达到 GA 的水平，插件已经整合进来了 mysql_exporter、redis_exporter、kafka_exporter、blackbox_exporter。这个时候的代码是最为简单清晰的最小功能集，如果大家想要参与，建议阅读此时的代码。</p><p style="color:#1f2328; text-align:start">代码仓库：<a href="https://github.com/cprobe/cprobe">https://github.com/cprobe/cprobe</a></p><h2 style="text-align:start">安装</h2><p style="color:#1f2328; text-align:start">到 cprobe 的 releases 页面<span>&nbsp;</span><a href="https://github.com/cprobe/cprobe/releases">https://github.com/cprobe/cprobe/releases</a><span>&nbsp;</span>下载发布包。解包之后核心就是那个二进制 cprobe，通过如下命令安装：</p><div style="text-align:start"><pre>./cprobe --install
./cprobe --start
</pre></div><p style="color:#1f2328; text-align:start">如果是支持 systemd 的 OS，上面的安装过程实际就是自动创建了 service 文件，你可以通过下面的命令查看：</p><div style="text-align:start"><pre>systemctl status cprobe
</pre></div><p style="color:#1f2328; text-align:start">如果不是 systemd 的 OS，会采用其他进程管理方式，比如 Windows，会创建 cprobe 服务。</p><h2 style="text-align:start">配置</h2><p style="color:#1f2328; text-align:start">解压缩之后应该可以看到 conf.d 目录，这是配置文件所在目录，未来的规划是 writer.yaml + 一堆插件目录，当然项目起步阶段，所以只有 writer.yaml + mysql，因为只有 mysql 一个插件得到支持。</p><p style="color:#1f2328; text-align:start">writer.yaml 是配置 remote write 地址（不知道什么是 remote write 地址，请自行 Google：Prometheus remote write），可以配置多个，默认配置如下：</p><div style="text-align:start"><pre><span style="color:var(--color-prettylights-syntax-entity-tag)">global</span>:
  <span style="color:var(--color-prettylights-syntax-entity-tag)">extra_labels</span>:
    <span style="color:var(--color-prettylights-syntax-entity-tag)">colld</span>: <span style="color:var(--color-prettylights-syntax-string)">cprobe</span><span style="color:var(--color-prettylights-syntax-entity-tag)">writers</span>:
- <span style="color:var(--color-prettylights-syntax-entity-tag)">url</span>: <span style="color:var(--color-prettylights-syntax-string)">http://127.0.0.1:9090/api/v1/write</span></pre></div><p style="color:#1f2328; text-align:start">这是一个极简配置，也基本够用，实际 writer.yaml 中还可以配置不同时序库后端的认证信息以及 relabel 的配置，同级目录下有个 backup.yaml 可以看到一些配置样例。</p><p style="color:#1f2328; text-align:start">不同的插件的配置会散落在各个插件目录里，以 mysql 插件举例，相关配置在<span>&nbsp;</span><code>conf.d/mysql</code><span>&nbsp;</span>下面，入口文件是 main.yaml，用于定义需要采集的 mysql target，计划至少提供三种 service discovery 机制：static_configs、http_sd_configs、file_sd_configs，这个配置和 Prometheus 的 scrape 配置基本保持一致。</p><p style="color:#1f2328; text-align:start">在 cprobe 场景下，cprobe 会直连监控目标，比如 mysql 的监控，Prometheus 是从 mysqld_exporter 获取监控数据，而 cprobe 是直连 mysql，所以 main.yaml 中要配置一些采集规则，即 scrape_rule_files。scrape_rule_files 是个数组，即可以把配置文件切分管理，这提供了极大的管理灵活性，各位自行发挥了。</p><p style="color:#1f2328; text-align:start">mysql 的采集插件 fork 自 mysqld_exporter，所以相关指标体系、仪表盘都可以复用。当然，也做了一些改造，原来 mysqld_exporter 是一套采集规则应用到所有的 target，在 cprobe 这里，不同的 target 可以采用不同的 scrape_rules，修改了原来通过命令行传参的机制以支持并发。另外就是扩展了自定义 SQL 能力，通过自定义 SQL 来抓取更多监控指标。更多信息可以参考：<a href="https://github.com/cprobe/cprobe/tree/main/conf.d/mysql/doc">mysql 插件文档</a>。</p><h2 style="text-align:start">后续规划</h2><p style="color:#1f2328; text-align:start">最核心的是增加更多插件，不同的插件要整理仪表盘、告警规则。框架层面，希望增加更多自埋点数据，通过 HTTP 的方式暴露更多调试信息。另外就是完善中英文文档。当然，大家如有建议也欢迎留言给我们。</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 02:00:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/cprobe</guid>
            <link>https://www.oschina.net/p/cprobe</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 自主开发的网络协议栈 onps]]>
            </title>
            <description>
                <![CDATA[<h1><a id="onps 网络协议栈" class="anchor" href="https://gitee.com/Neo-T/open-npstack#onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88"></a>onps 网络协议栈</h1><h4><a id="背景" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%83%8C%E6%99%AF"></a>背景</h4><p>大约是 06 年，因项目之需我开始接触应用於单片机系统的国外开源 tcp/ip 协议栈——LwIP，并借此顺势创作了我的第一本印成铅字的书——《嵌入式网络系统设计——基于 Atmel ARM7 系列》。这本书的反响还不错，好多人给我发 msn（可惜这么好的一个即时通讯工具就这么被微软放弃了，好多联系人就此失联， <img class="emoji" alt=":persevere:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/persevere-1f8fa05847efd349c0f2c62b1cee5bd1.png" width="14" height="14" referrerpolicy="no-referrer"> ）或邮件咨询相关问题。在我原来的写作计划中，这本书的出版只是一个开始，接下来还要写第二本——系统介绍 LwIP 包含的 ppp 协议栈的移植、应用及设计实现等相关内容。但，事与愿违，这本书跳票了，且这一跳就是十二年……</p><p>细细想来，当初跳票的主因有二：其一，因家庭、工作等致可支配时间太少；其二，缺乏足够的 ppp 协议相关知识及技术储备致信心不足，畏首畏尾，裹足不前。但，这件事始终是我的一个遗憾。十二年的时间，不长亦不短，但足够让心底的遗憾变成一粒小小的种子并茁壮成长为一棵梦想的参天大树。</p><p>如今，世界来到了疫情肆虐的二零年代。我的可支配时间多了起来，技术能力亦远非当年可比。梦想之树到了开花结果的时候了。遥想当初，入行还没几年，技术能力有限，我只能站在大神的肩膀上研究如何移植、使用 LwIP，ppp 栈碰都没敢碰。现在，如果还只是延续十几年前的工作，那这件事做起来就无甚意义。基于对自身技术实力的准确认识，我决定自己从零开始搭建一个完整的网络协议栈。终，历 6 个月余，onps 协议栈（onps，open net protocol stack）完成初版开发，并内部测试通过。十余年的遗憾今日得偿。另，从业 20 余年，内心终有一个做核心基础软件的梦。今，这二之梦想亦借此得偿。</p><p>新莺初啼，总免不了会有诸多不尽如人意的地方。开源，则可与志趣相投者共享、共用、共研，历诸位严苛手段使之快速迭代，快速成熟，比肩 LwIP 可期 <img class="emoji" alt=":blush:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/blush-85d11d8b7459d18f70eab0659c19a266.png" width="14" height="14" referrerpolicy="no-referrer"> 。</p><h4><a id="简介" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%AE%80%E4%BB%8B"></a>简介</h4><p>onps 是一个开源且完全自主开发的国产网络协议栈，适用于资源受限的单片机系统，提供完整地 ethernet/ppp/tcp/ip 协议族实现，同时提供 sntp、dns、ping 等网络工具，支持以太网环境下 dhcp 动态 ip 地址申请，也支持动态及静态路由表。协议栈还封装实现了一个伯克利套接字（Berkeley sockets）层。该层并没有完全按照 Berkeley sockets 标准设计实现，而是我根据以往 socket 编程经验，以方便用户使用、简化用户编码为设计目标，重新声明并定义了一组常见 socket 接口函数：</p><ul><li>socket：创建一个 socket，目前仅支持 udp 和 tcp 两种类型</li><li>close：关闭一个 socket，释放当前占用的协议栈资源</li><li>connect：与目标 tcp 服务器建立连接（阻塞型）或绑定一个固定的 udp 服务器地址</li><li>connect_nb：与目标 tcp 服务器建立连接（非阻塞型）</li><li>is_tcp_connected：获取当前 tcp 链路的连接状态</li><li>send：数据发送函数，tcp 链路下为阻塞型</li><li>send_nb：数据发送函数，非阻塞型</li><li>is_tcp_send_ok：数据是否已成功送达 tcp 链路的对端（收到 tcp ack 报文）</li><li>sendto：udp 数据发送函数，发送数据到指定目标地址</li><li>recv：数据接收函数，udp/tcp 链路通用</li><li>recvfrom：数据接收函数，用于 udp 链路，接收数据的同时函数会返回数据源的地址信息</li><li>socket_set_rcv_timeout：设定 recv() 函数接收等待的时长，单位：秒</li><li>bind：绑定一个固定端口、地址</li><li>listen：tcp 服务器进入监听状态</li><li>accept：接受一个到达的 tcp 连接请求</li><li>tcpsrv_recv_poll：tcp 服务器专用函数，等待任意一个或多个 tcp 客户端数据到达信号</li><li>socket_get_last_error：获取 socket 最近一次发生的错误信息</li><li>socket_get_last_error_code：获取 socket 最近一次发生的错误编码</li></ul><p>协议栈简化了传统 BSD socket 编程需要的一些繁琐操作，将一些不必要的操作细节改为底层实现，比如 select/poll 模型、阻塞及非阻塞读写操作等。简化并不意味着推翻，socket 接口函数的基本定义、主要参数、使用方法并没有改变，你完全可以根据以往经验及编程习惯快速上手并熟练使用 onps 栈 sockets。 <strong>无须过多关注协议栈底层，利用 socket api 编程即可完全满足复杂通讯应用的需求，而不像 LwIp 一样需要使用它自定义的一组接口函数才能达成同样的目标。</strong></p><p>为了适应单片机系统对内存使用极度变态的苛刻要求，onps 协议栈在设计之初即考虑采用写时零复制（zero copy）技术。用户层数据在向下层协议传递过程中，协议栈采用 buf list 链表技术将它们链接到一起，直至将其发送出去，均无须任何内存复制操作。另外，协议栈采用 buddy 算法提供安全、可靠的动态内存管理功能，以期最大限度地提高协议栈运行过程中的内存利用率并尽可能地减少内存碎片。</p><p>不同于本世纪 00 到 10 年代初，单片机的应用场景中 ucosii 等 rtos 尚未大规模普及，前后台系统还大行其道的时代，现如今大部分的应用场景下开发人员选择使用 rtos 已成为主流。因此，协议栈在设计之初即不支持前后台模式，其架构设计建立在时下流行的 rtos（RT-Thread、ucosii/iii 等）之上。协议栈移植的主要工作也就自然是针对不同 rtos 编写相关 os 适配层功能函数了。当然，如果你有着极其特定的应用场景，需要将 onps 栈移植到采用前后台模式的单片机上，我的建议是保留 tcp/udp 之下协议层的通讯处理逻辑，调整上层的系统架构使其适应目标系统运行模式。</p><h4><a id="软件架构" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84"></a>软件架构</h4><p>onps 栈设计实现了一套完整的 tcp/ip 协议模型。从数据链路层到 ip 层，再到 tcp/udp 层以及之上的伯克利 socket 层，最后是用户自己的通讯应用层，onps 栈实现了全栈覆盖，能够满足绝大部分的网络编程需求。其架构如下：
<img src="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="onps 栈架构" referrerpolicy="no-referrer"></p><p>可以看出，其与传统的网络编程模型并没有什么不同，用户仍然是继续利用 socket api 编写常见的 tcp 及 udp 网络应用。同时你还可以利用协议栈提供的几个网络工具进行网络校时、dns 查询等操作。</p><h4><a id="目录结构" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"></a>目录结构</h4><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td>bsd</td><td>伯克利 sockets 层的相关接口函数实现源文件</td></tr><tr><td>ethernet</td><td>以太网协议族如 ethernet-ii/arp 及 emac 层、dhcp 客户端等的相关实现源文件</td></tr><tr><td>include</td><td>协议栈的头文件</td></tr><tr><td>ip</td><td>ip 及其上层 icmp/tcp/udp 协议族的相关实现源文件</td></tr><tr><td>mmu</td><td>协议栈内存管理模块的相关实现源文件</td></tr><tr><td>net_tools</td><td>网络工具实现源文件，如 dns 查询、网络校时、ping、telnet 等</td></tr><tr><td>netif</td><td>网卡及路由管理等相关接口实现源文件</td></tr><tr><td>port</td><td>协议栈移植相关的源文件</td></tr><tr><td>ppp</td><td>ppp 链路层相关实现源文件，包括 lcp/ipcp/chap/pap 等协议族的实现源文件</td></tr><tr><td>TcpServerForStackTesting</td><td>用于协议栈测试的 tcp 服务器，IDE 为 vs2015 开发，目标系统为 win7 及以上</td></tr><tr><td>test_code</td><td>linux 下的 ppp 拨号原理验证文件</td></tr></tbody></table><h4><a id="移植及使用说明" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A7%BB%E6%A4%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"></a>移植及使用说明</h4><p>协议栈支持主流的 ARM Cortex 系列 MCU，支持 Keil MDK、IAR 等常见 IDE。移植的核心工作就是完成 RTOS 模拟层的编写及适配，详细的移植说明请参考《onps 网络协议栈移植及使用说明 v1.0》一文，点此<a href="https://gitee.com/Neo-T/open-npstack/releases/download/v1.0.0.221017/onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E7%A7%BB%E6%A4%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8Ev1.0.7z">下载</a>。本说明提供了 STM32F103RCT6 及 STM32F407VET6 两种硬件平台的移植样例，每种样例分别针对 RT-Thread 和 ucosii 两种 RTOS。样例工程经过了严格的内部测试，可以直接使用。</p><p>如果你没有太多时间，或者样例工程与你的目标平台并不匹配，你可以直接参考协议栈移植的一般性指导文件<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E7%A7%BB%E6%A4%8D%E6%89%8B%E5%86%8C.pdf">《onps 栈移植手册》</a>。</p><p>协议栈开发的一般性指导文件请参考<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88API%E6%8E%A5%E5%8F%A3%E6%89%8B%E5%86%8C.pdf">《onps 栈 API 接口手册》</a>及<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.pdf">《onps 栈用户使用手册》</a>。</p><h4><a id="移植样例" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A7%BB%E6%A4%8D%E6%A0%B7%E4%BE%8B"></a>移植样例</h4><p><strong>STM32F407VET6 平台</strong> ：
<a href="https://gitee.com/Neo-T/onps-rtthread">RT-Thread 移植样例</a><a href="https://gitee.com/Neo-T/onps-ucosii">ucos-ii 移植样例</a></p><p><strong><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307">沁恒 CH32V307 平台</a></strong> ：
<a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/HarmonyOS/LiteOS_m">鸿蒙 LiteOS-M 移植样例</a><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/FreeRTOS">Free-rtos 移植样例</a><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/rt-thread">RT-Thread 移植样例</a></p><h4><a id="社区支持" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A4%BE%E5%8C%BA%E6%94%AF%E6%8C%81"></a>社区支持</h4><p>您可以随时访问<a href="https://gitee.com/link?target=http%3A%2F%2Fwww.onps.org.cn"><strong>onps 栈官方网站</strong></a>，获取协议栈研发进度、后续计划、最新版本等相关信息。<br>如您在使用过程中遇到任何问题或建议，您可以到 <strong><a href="https://gitee.com/link?target=http%3A%2F%2Fneo.onps.org.cn">onps 栈交流社区</a></strong> 提出您的建议或问题，新版本发布也会在交流社区第一时间通知。<br>您也可以加入 QQ 群进行在线技术交流：<br><img src="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81%E7%BE%A4%E7%BE%A4%E4%BA%8C%E7%BB%B4%E7%A0%81.png" alt="qq 交流群" referrerpolicy="no-referrer"></p><h4><a id="许可协议" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE"></a>许可协议</h4><p>Apache License 2.0 开源许可协议</p><h4><a id="通过 oscs 安全认证" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E9%80%9A%E8%BF%87oscs%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81"></a>通过 OSCS 安全认证</h4><p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.murphysec.com%2Faccept%3Fcode%3D64bea0edfe145ac454cc464b23659406%26type%3D1%26from%3D2%26t%3D2"><img src="https://www.murphysec.com/platform3/v3/badge/1615596818625232896.svg?t=1" alt="Security Status" referrerpolicy="no-referrer"></a></p><h4><a id="后续计划" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E5%90%8E%E7%BB%AD%E8%AE%A1%E5%88%92"></a>后续计划</h4><ul><li>更多目标平台的适配工作， 提供相应移植样例</li><li>重构部分代码， 进一步降低代码尺寸及内存消耗</li><li>支持 ftp 客户端/服务器</li><li>支持 http 客户端/服务器</li></ul><h4><a id="捐赠" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E6%8D%90%E8%B5%A0"></a>捐赠</h4><p>为了项目能够持续下去，期望得到您的支持，您可以扫描下面的二维码通过支付宝/微信向本项目捐款：</p><p><img src="https://gitee.com/Neo-T/open-npstack/raw/master/alipayn.jpg" alt="支付宝" referrerpolicy="no-referrer"><img src="https://gitee.com/Neo-T/open-npstack/raw/master/tencentpay.jpg" alt="微信" referrerpolicy="no-referrer"></p>]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:51:47 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/Neo-T/open-npstack</guid>
            <link>https://gitee.com/Neo-T/open-npstack</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 深度解读 Cascades 查询优化器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>数据库中查询优化器是数据库的核心组件，其决定着 SQL 查询的性能。Cascades 优化器是 Goetz 在 volcano optimizer generator 的基础上优化之后诞生的一个搜索框架。</p><p>本期技术贴将带大家了解 Cascades 查询优化器。首先介绍 SQL 查询优化器，接着分析查询优化基本原理，最后对 Cascades 查询优化器进行重点介绍。</p><span id="OSC_h1_1"></span><h1>一、SQL 查询优化器</h1><p>用户与数据库交互时只需要输入声明式 SQL 语句，数据库优化器则负责将用户输入的 SQL 语句进行各种规则优化，生成最优的执行计划，并交由执行器执行。优化器对于 SQL 查询具有十分重要的意义。</p><p>如图 1 所示，SQL 语句经过语法和词法解析生成抽象语法树 (AST)，经过**基于规则的查询优化（Rule-Based Optimizer）<strong>和</strong>基于代价的查询优化（Cost-Based Optimizer）**生成可执行计划。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-2f53e715e5e2dc13da2ae7593b5a622c7a2.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 1</p><ul><li><p><strong>基于规则的优化算法</strong>:&nbsp;基于规则的优化方法的要点在于结构匹配和替换。应用规则的算法一般需要先在关系代数结构上匹配一部分局部的结构，再根据结构的特点进行变换乃至替换操作。</p></li><li><p><strong>基于成本的优化算法</strong>:&nbsp;现阶段主流的方法都是基于成本（Cost）估算的方法。给定某一关系代数代表的执行方案，对这一方案的执行成本进行估算，最终选择估算成本最低的方案。尽管被称为基于成本的方法，这类算法仍然往往要结合规则进行方案的探索。基于成本的方法其实是通过不断的应用规则进行变换得到新的执行方案，然后对比方案的成本优劣进行最终选择。</p></li></ul><span id="OSC_h1_2"></span><h1>二、查询优化的基本原理</h1><p>优化器一般由三个组件组成：<strong>统计信息收集</strong>、<strong>开销模型</strong>、<strong>计划列举</strong>。</p><p>如图 2 所示，开销模型使用收集到的统计信息以及构造的不同开销公式，估计某个特定查询计划的成本，帮助优化器从众多备选方案中找到开销最低的计划。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-74c10d3f0e3e2443c51805fe0a0d7742ec4.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 2</p><p><strong>SQL 语句查询优化基于关系代数这一模型：</strong></p><ul><li><p>SQL 查询可以转化为关系代数；</p></li><li><p>关系代数可以进行局部的等价变换，变换前后返回的结果不变但是执行成本不同；</p></li><li><p>通过寻找执行成本最低的关系代数表示，我们就可以将一个 SQL 查询优化成更为高效的方案。</p></li></ul><p>寻找执行成本最低的关系代数表示，可以分为<strong>基于动态规划的自底向上</strong>和<strong>基于 Cascades/Volcano 的自顶向下</strong>两个流派。</p><ul><li><p><strong>自底向上搜索</strong>：从叶子节点开始计算最低成本，并利用已经计算好的子树成本计算出母树的成本，就可以得到最优方案；</p></li><li><p><strong>自顶向下搜索</strong>：先从关系算子树的顶层开始，以深度优先的方式来向下遍历，遍历过程中进行剪枝。</p></li></ul><p>自底向上的优化器从零开始构建最优计划，这类方法通常采用动态规划策略进行优化，采用这类方法的优化器包括&nbsp;IBMSystem R。自顶向下的优化策略的优化器包括基于 Volcano 和 Cascades 框架的优化器。</p><span id="OSC_h1_3"></span><h1>三、Cascades 查询优化器</h1><p>Cascades 查询优化器采用自顶向下的搜索策略，并在搜索过程中利用 Memo 结构保存搜索的状态。</p><p><strong>Cascades 关键组件构成：</strong></p><ul><li><p><strong>Expression</strong>：Expression 表示一个逻辑算子或物理算子。如 Scan、Join 算子；</p></li><li><p><strong>Group</strong>：表示等价 Expression 的集合，即同一个 Group 中的 Expression 在逻辑上等价。Expression 的每个子节点都是以一个 Group 表示的。一个逻辑算子可能对应多个物理算子，例如一个逻辑算子 Join(a,b)，它对应的物理算子包括{HJ(a, b), HJ(b, a), MJ(a, b), MJ(b, a), NLJ(a, b), NLJ(b, a)}。我们将这些逻辑上等价的物理算子称为一个 Group（组）。注：HJ 表示 HashJoin 算子，MJ 表示 MergeJoin 算子，NLJ 表示 NestLoopJoin 算子；</p></li><li><p><strong>Memo</strong>：由于 Cascades 框架采用自顶向下的方式进行枚举，因此，枚举过程中可能产生大量的重复计划。为了防止出现重复枚举，Cascades 框架采用 Memo 数据结构。Memo 采用一个类似树状（实际是一个图状）的数据结构，它的每个节点对应一个组，每个组的成员通过链表组织起来；</p></li><li><p><strong>Transformation Rule</strong>：是作用于 Expression 和 Group 上的等价变化规则，用来扩大优化器搜索空间。</p></li></ul><p>Cascades 首先将整个 Operator Tree 按节点拷贝到一个 Memo 的数据结构中，Memo 由一系列的 Group 构成，每个算子放在一个 Group，对于有子节点的算子来说，将原本对算子的直接引用，变成对 Group 的引用。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8f15c28ea323e3c6c3812cb4345b2668089.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 3</p><p>如图 3 所示，生成该语法树的 Memo 初始结构。Memo 结构中一个圆角框代表一个算子，圆角框右下角是对其 Children’s Groups 的引用，左下角是唯一标识符。生成初始的 Memo 结构后，可以采用 transform rule 进行逻辑等价转换，规则如下：</p><ul><li><p>对于一个逻辑算子，其所有基于关系代数的等价表达式保存在同一个 Group 内，例如 join(A,B) -&gt; join(B,A)；</p></li><li><p>在一个 Group 内，对于一个逻辑算子，会生成一个或多个物理算子，例如 join -&gt; hash join,merge join，NestLoop join；</p></li><li><p>一个 Group 内，一个算子，其输入（也可以理解为 subplan）可以来自多个 Group 的表达式。</p></li></ul><p>在图 4 中，描述了一个部分扩展的 Memo&nbsp;结构，与图 1 中的初始 Memo 相比，在同一个 Group 内，增加了等价的逻辑算子，以及对应的物理算子。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-be8b645c303e9167ab3ab1936afe751448f.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 4</p><p>在探索的过程中，优化器就会通过开销模型 Coster 借助统计信息来计算子步骤的开销，遍历完每个 Memo Group 之后，归总得到每个完整计划的总开销，最终选择 Memo 中开销最低的计划。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-11ec37fc83f5aeeb91f0464308b62d14ecb.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图&nbsp;5</p><p>图 5 中有三个 Group，分别对应三个逻辑算子：Join(a, b), GET(a) 和 GET(b)。Group 1（Group 2）中包含了所有对应 GET(a) （GET(b)）的物理算子，我们可以估算每个物理算子的代价，选取其中最优的算子保留下来。</p><p>为了防止枚举过程出现重复枚举某个表达式，Memo 结构体中还包含一个哈希表（exprHT），它以表达式为哈希表的键，用来快速查找某个表达式是否已经存在于 Memo 结构体中。</p><p>Cascades 采用自顶向下的方式来进行优化，以计划树的根节点为输入，递归地优化每个节点或表达式组。如图所示，整个优化过程从 Group 0 开始，实际上要先递归地完成两个子节点（Group 1 和 Group 2）的优化。</p><p>因此，实际的优化完成次序是 Group 1 -&gt; Group2 -&gt; Group 0。在优化每个 Group 时，依次优化每个组员；在优化每个组员时，依次递归地优化每个子节点。依次估算当前组里每个表达式 e 的代价 cost(e)，选择最低得代价结果保存在 bestHT 中。优化结束时，查询 Join(a,b) 对应的 Memo 结构体，获取最低的执行计划。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:46:47 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5148943/blog/10320570</guid>
            <link>https://my.oschina.net/u/5148943/blog/10320570</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Soul 上线自研语言大模型 SoulX]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>社交平台 Soul 正式上线自研语言大模型 SoulX。作为生成式人工智能最基础、最核心的工具，SoulX 将作为 Soul 「AIGC+社交」布局的重要基建，垂直应用于平台上多元社交互动场景，例如智能对话机器人「AI 苟蛋」、AI 辅助聊天、虚拟陪伴等诸多工具和创新功能，进一步丰富平台用户的社交体验。</p><p>根据介绍，该模型基于海量数据训练，具备 prompt 驱动、条件可控生成、上下文理解、多模态理解等能力。在保证对话流畅、自然、具备情感温度的同时，SoulX 覆盖百种细粒度风险类别，通过训练数据安全筛选、安全 SFT 数据构造、RLHF 安全对齐、推理拦截等策略来构建安全体系，保证了大模型的内容生产质量和安全性。</p><p><img height="444" src="https://oscimg.oschina.net/oscnet/up-83bee0805ad5819554ad5c4bf7d1885d136.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 10:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270889</guid>
            <link>https://www.oschina.net/news/270889</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MegEngine 正式支持 XLA 啦！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>XLA（Accelerated Linear Algebra）是 Google 提出的一个神经网络编译器，可以用于加速 AI 模型的训练和推理。MegEngine 1.13.1 中也已经支持了 XLA，在训练模型时可以选择开启此项功能，不同的模型可以获得 10%~80% 不等的速度提升。</p><h2>主要的目标场景</h2><p>MegEngine 现在是动态执行的，即 python 中每一个 mge.functional 的调用都对应着底层 gpu 上的一次 kernel 执行。这种模式的好处在于实际的执行方式与代码逻辑一致，所见即所得，非常的灵活；不过其问题是难以优化，性能可能不是最优。</p><p>而 XLA 采取静态执行的方式，会将模型计算过程表达成一张静态计算图，称为 「HLO」 （High-Level Optimized）。HLO 中包含计算图的相关操作，张量的数据流程和形状等信息。XLA 随后会对 HLO 进行一系列的优化，并最终生成一个更优的计算图，从而更快的完成计算。而 XLA 的局限性就在于不够灵活，对于 Tensor Shape 改变或者控制流等信息无法很好的表达。</p><p>现在 MegEngine 中已经支持了 XLA，模型训练中一些比较静态的场景，我们可以使用 XLA 来进行加速，从而缩短整个训练过程的时间。</p><h2>使用方法与效果</h2><p>在使用 MegEngine 进行训练时，可以通过对原来的训练函数增加 xla_trace/partial_trace 装饰器来启用 XLA 编译优化。</p><p>当整个模型是完全静态时，我们可以使用 xla_trace 将整张网络表达成一张静态图，然后交由 XLA 做后续的优化编译，后续的执行过程将执行这张优化后的计算图提升速度。</p><p>而如果我们模型中有一些动态性，比如训练过程中一些 Tensor Shape 会发生变化，亦或者是存在控制流，我们可以使用 partial_trace，将网络中静态的部分 trace 成一些子图并分别交给 XLA 进行编译优化，而网络中其他部分仍然保持动态执行，同时保证性能与灵活性。</p><p>下面展示了在 MegEngine 中，XLA 功能开启前后，主流的神经网络模型性能变化。其中蓝色为 XLA 开启之前的训练速度，橙色为 XLA 开启之后的训练速度。在开启 XLA 后，大部分模型的性能可以获得 10%~40% 的提升，最多可以超过 80%。 <img src="https://data.megengine.org.cn/engine-website/assets/images/38f415d8-9963-11ee-a7f5-8272bed56fd1.png" alt="1.png" referrerpolicy="no-referrer"></p><p>关于 XLA 的更多信息及具体的使用方法可以参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.megengine.org.cn%2Fdoc%2Fstable%2Fzh%2Fuser-guide%2Fmodel-development%2Fjit%2Fxla.html" target="_blank">https://www.megengine.org.cn/doc/stable/zh/user-guide/model-development/jit/xla.html</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 10:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5265910/blog/10321024</guid>
            <link>https://my.oschina.net/u/5265910/blog/10321024</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[麟卓发布多平台软件安装包构建系统，支持 Windows 和 Linux]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京麟卓<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9I8Xo7H_LLHPmSy_HMY24A" target="_blank">宣布推出</a></u>「多平台软件安装包构建系统」，用于解决 Windows 和 Linux 系统中传统软件封装、安装过程繁琐、平台差异严重等诸多问题。</p><p>据介绍，该工具提供「一站式构建、安装」功能，让用户能够轻松制作软件安装包程序，提升工作效率，简化软件封装、安装以及卸载流程。</p><blockquote><strong>下载地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linzhuotech.com%2FProduct%2FDownLoadWindows" target="_blank">https://www.linzhuotech.com/Product/DownLoadWindows</a></u></em></strong></blockquote><p>「多平台软件安装包构建系统」是利用统一交互界面和配置机制生成多平台软件安装包的系统，支持在 Windows、Linux 平台上进行目标软件的多层级模块化封装以及安装功能，主要具备以下优势：</p><ul><li>软件安装便捷：简化传统软件安装流程中的解压、拷贝以及配置环境等繁琐操作。</li><li>人机交互统一：在不同的操作系统平台上，具备统一人机交互，方便用户进行多平台封装。</li><li>功能操作简单：具备多层级可选控制、安装信息配置、自定义安装脚本、环境配置等丰富功能的同时保证软件操作简洁，易学易用。</li></ul><p><img height="779" src="https://oscimg.oschina.net/oscnet/up-346f799048871759324d7ded950e159fa0d.png" width="1280" referrerpolicy="no-referrer"><img src="https://static.oschina.net/uploads/space/2023/1213/174623_Cjur_2720166.png" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-401cdffba4679c3bdb8ae9bb0feea96f222.png" referrerpolicy="no-referrer"></p><ul></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 09:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270878</guid>
            <link>https://www.oschina.net/news/270878</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软推出小模型 Phi-2，性能优于 Llama 2/Mistral 7B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">微软<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fphi-2-the-surprising-power-of-small-language-models%2F" target="_blank">宣布</a>推出一个 27 亿参数的语言模型 Phi-2，并声称其性能可与大 25 倍的模型相匹配或优于。「展示了出色的推理和语言理解能力，展示了参数少于 130 亿的基础语言模型中最先进的性能。」</span></p><p><span style="color:#000000">其基准测试结果表明，只需 27 亿个参数，Phi-2 就能在各种综合基准测试中超越 Mistral 和 Llama-2 模型在 7B 和 13B 参数下的性能。与大 25 倍的 Llama-2-70B 模型相比，Phi-2 在多步推理任务（即编码和数学）上实现了更好的性能。</span></p><p><span style="color:#000000">此外，Phi-2 的性能与最近发布的 Google Gemini Nano 2 不相上下，甚至更胜一筹。</span></p><p><img height="179" src="https://oscimg.oschina.net/oscnet/up-195920a0bfb4c87cd5ca00cc5d3edd0c25d.png" width="500" referrerpolicy="no-referrer"></p><p><img height="101" src="https://oscimg.oschina.net/oscnet/up-00457009ea9fb83c5e5802e175d784bd463.png" width="500" referrerpolicy="no-referrer"></p><p>且<span style="background-color:#ffffff; color:#000000">与经过调整的现有开源模型相比，</span><span style="color:#000000">Phi-2 </span><span style="color:#1a202c">响应中的「毒性」和偏差也要更少。</span></p><p><span style="color:#1a202c"><img alt="" height="243" src="https://oscimg.oschina.net/oscnet/up-36ec3b182b6104dcd29d01e7b450d2cb42c.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">此前，谷歌发布的 Gemini 演示视频曾展示了其解决复杂物理问题，以及对学生进行纠错的能力。微软研究人员也将&nbsp;Phi-2 进行了同样的测试，并表示它同样能够正确回答问题，和使用相同的提示纠错。</span></p><p><img height="282" src="https://oscimg.oschina.net/oscnet/up-11a57788ae91ebd7277cc00ee2b3ab55339.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Phi-2 是微软「小语言模型（SLM）」系列中的最新版本。第一个版本是拥有 13 亿参数的 Phi-1，针对基本的 Python 编码任务进行了微调。9 月，该公司将重点扩展到常识推理和语言理解，推出了一个新的 13 亿参数模型 Phi-1.5，性能可与大 5 倍的模型相媲美。</span></p><p><span style="color:#000000">微软表示，Phi-2 的效率使其成为想要探索增强人工智能安全性、可解释性和语言模型道德发展等领域的研究人员的理想平台。目前，</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fml.azure.com%2Fregistries%2Fazureml-msr%2Fmodels%2Fmicrosoft-phi-2%2Fversion%2F3%3Ftid%3D72f988bf-86f1-41af-91ab-2d7cd011db47%23overview" target="_blank">Phi-2</a><span style="color:#000000"> 现已通过 Microsoft Azure AI Studio 的模型目录发布。</span></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fphi-2-the-surprising-power-of-small-language-models%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270831/microsoft-phi-2-small-language-model</guid>
            <link>https://www.oschina.net/news/270831/microsoft-phi-2-small-language-model</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Wi-Fi 7 将于 2024 年初全面登场，速度比 Wi-Fi 6 提升 5 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#262626">WiFi 联盟<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wi-fi.org%2Fdiscover-wi-fi%2Fwi-fi-certified-7" target="_blank">宣布</a></u>将在明年 1 月 9 日至 12 日参加 CES 2024，并确认基于 IEEE 802.11be 的 Wi-Fi CERTIFIED 7 认证标准将于第一季度末之前正式推出。</span>与目前的 Wi-Fi 6 标准相比，该标准有望提供千兆位速度和其他改进。</p><p><img src="https://oscimg.oschina.net/oscnet/up-bf8bb1d4062d6abcdd5bde367ecbe4cc108.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0cc0e98c02c1b0b058bc6ac02b0b37ea771.png" referrerpolicy="no-referrer"></p><p>英特尔（Intel）和博通（Broadcom）去年展示的 Wi-Fi 7（也称 802.11be）速度高达 5 Gbps，大大超过了 Wi-Fi 6 的典型最高速度约 1.7 Gbps。<strong>Wi-Fi 7 允许在 2.4GHz、5GHz 和 6GHz 频率之间无缝切换</strong>，兼容设备可同时使用这些频率，从而实现了这一目标。</p><p>此外，6GHz 频谱可提供 320MHz 的超宽信道，吞吐量比 Wi-Fi 6 翻了一番，这是速度提升的关键因素。通过从 1024 QAM 升级到 4K QAM，新标准还将传输速率提高了 20%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-68acdc34185024028d7aabf4f9b688fd47e.png" referrerpolicy="no-referrer"></p><p>Wi-Fi 7 连接也有望比以前的规格更加稳定。多链路操作可智能平衡流量，使网络能有效容纳更多设备。联盟表示，新标准将非常适合增强现实和虚拟现实应用。美国联邦通信委员会（FCC）最近初步批准了 6GHz 频谱上的超高速 Wi-Fi 关联，这是使 VR 和 AR 设备能够利用 Wi-Fi 7 的重要一步。</p><p>2024 年的推出日期与英特尔 2022 年的预测基本吻合。该公司计划从明年开始推出支持 Wi-Fi 7 的个人电脑，并于 2025 年在市场上普及。高通公司也对 Wi-Fi 7 持乐观态度，并将其与 5G 一起纳入了 FastConnect 计划。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 05:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270823/wi-fi-certified-7</guid>
            <link>https://www.oschina.net/news/270823/wi-fi-certified-7</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Log4Shell 两周年，仍有不少项目使用包含漏洞的版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Log4Shell 是 Log4j 2.0（Log4J2）的一个 0day 远程代码执行漏洞，被定性为「过去十年来最大、最关键的漏洞」，最早由阿里巴巴集团于 2021 年 11 月 24 日发现并报告给 Apache 软件基金会。</p><p>尽管已经过去了两年，<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.veracode.com%2Fblog%2Fresearch%2Fstate-log4j-vulnerabilities-how-much-did-log4shell-change" target="_blank">但根据安全公司 Veracode 的报告</a></u></strong>，该漏洞的影响仍然存在。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-73861b3642e119baf3ccca3f3a037679b4f.png" referrerpolicy="no-referrer"></p><p>Veracode 分析了 2023 年 8 月 15 日至 11 月 15 日期间 90 天内的软件扫描数据，针对 3,866 个组织运行 Log4j 版本 1.1 至 3.0.0-alpha1 的 38,278 个独特应用程序。</p><p>在 Log4j 1.1 到 3.0.0-alpha1 版本中，有超过三分之一的应用程序使用了存在漏洞的 Log4j 版本。具体来说：</p><ul><li>2.8% 的应用程序仍在使用 Log4j2 2.0-beta9 到 2.15.0 之间的版本，这些版本存在 Log4Shell 漏洞。</li><li>另外 3.8% 的应用程序使用的是 Log4j2 2.17.0 版本，虽然该版本已修复了 Log4Shell 漏洞，但仍然存在 CVE-2021-44832 漏洞，这是一个高危的远程代码执行漏洞。</li><li>还有 32% 的应用程序使用的是 Log4j2 1.2.x 版本，这个版本在 2015 年 8 月已经停止维护，但在 2022 年 1 月 ASF 宣布了三个影响该版本的关键漏洞。</li></ul><p>这些数据表明，尽管各方对 Log4Shell 漏洞进行了大规模的修复工作，但仍然存在许多应用程序使用了存在漏洞的 Log4j 版本。</p><p>Veracode 的研究还发现，许多开发者在将第三方库引入到代码后从未更新过这些库。这也解释了为什么有如此大比例的应用程序在运行已经停止维护的 Log4j 版本。</p><p>此外，研究还发现，一旦开发者通过扫描发现了漏洞，他们通常会相对迅速地进行修复。但是，一些外部因素会拖慢开发人员的修复速度，例如缺乏信息或资源。</p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/173273/log4j-maintainer-response" target="_blank">Log4j 维护者：为向后兼容没移除导致漏洞的旧功能</a></li><li><a href="https://www.oschina.net/news/174752/impact-of-apache-log4j" target="_blank">Apache Log4j 漏洞的影响规模</a></li><li><a href="https://www.oschina.net/news/203874/log4j-the-pain-just-keeps-going-and-going" target="_blank">「核弹级」 Log4j 漏洞仍普遍存在，并造成持续影响</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270803/state-log4j-vulnerabilities-2023</guid>
            <link>https://www.oschina.net/news/270803/state-log4j-vulnerabilities-2023</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 11 记事本的底部状态栏将显示「字符数统计」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Windows 11 内置的文本编辑器「记事本」添加了一项重要功能：在底部状态栏显示<strong>字符数统计</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-876aae8d39e39c30417766c1912f6ab4e65.png" referrerpolicy="no-referrer"></p><p>该功能会显示使用者输入的<strong>字符总数</strong>，包括字母、数字、符号、空格、标点符号等。「字符统计」与「字数统计」不一样，字数统计仅计算文档中的单词总数，有人会觉得它比字符数统计更有用。</p><p>根据微软的<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ghacks.net%2F2023%2F12%2F08%2Fwindows-11s-notepad-is-getting-a-character-count-on-the-status-bar%2F" target="_blank">公告</a></u>，记事本中的字符数统计有两种工作方式。默认情况下，文本编辑器将在窗口底部的状态栏上显示文档的字符数。如果使用者在文档中选择了文本，记事本将分别显示所选文本的字符数和文档的总计数。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270799/windows-11s-notepad-character-count-on-the-status-bar</guid>
            <link>https://www.oschina.net/news/270799/windows-11s-notepad-character-count-on-the-status-bar</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国产数据库的出现和消失，都不是技术问题]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><blockquote><p>最近，关于数据库国产化替代的话题甚是热门。OSCHINA 开源中国特别邀请了<strong>欧冶云商股份有限公司数据库首席薛晓刚</strong>就这一话题发表看法。</p></blockquote><span id="OSC_h2_1"></span><h2><span style="color:#2980b9">为什么要替代 Oracle?</span></h2><p>去 IOE 的背景，要从阿里巴巴去 IOE 谈起，I 是 IBM 小型机大型机，O 是 Oracle 数据库，E 是 EMC 存储。这几个搭配起来使得阿里轻松走过了最初的技术发展阶段。这个配置组合也是当年这条街最靓的仔。这个穿搭在大型银行和运营商中也很常见。这种组合的好处是就稳定，而且非常稳定。<strong>缺点可能只有一个，就是贵。</strong></p><p>随着阿里业务的增加，阿里人考虑继续这样使用的成本很高。再加上阿里开始了云计算的规划，所以提出了去 IOE 的口号。这个在其他互联网公司是不可能有的。因为其他互联网公司一开始就没有 IOE 所以不需要去。只有阿里一开始的架构是这样的。所以只有阿里提出了。</p><p>阿里做阿里云，希望用户上云。上云的核心就是数据上云。数据上云后存在哪里？自然是数据库中，如果用的数据库是 Oracle 的，那么可能要分给 Oracle 利润（要采购许可）。所以阿里打算用 MySQL 以及后来自研替代 Oracle。</p><p>从最开始的去 IOE，直到现在还经常看到各种大会上提到去 O，这用了十几年，去掉了 I 和 E。有些企业完成了去 O，而有些企业还在使用 O。</p><p><strong>那么为什么只提去 O，那不用去 DB2 和 SQLServer 吗？本质上也要去的。</strong>只是其他的数据库不如 Oracle 的使用广泛，例如现在使用和维护 DB2 的人是很少了。之所以没人提去 DB2，是因为从总体来说 DB2，已经被去掉了。所以狭义去 O 是去掉 Oracle 数据库，而广义的去 O 其实可以扩大为去 M（美国化）。</p><p>在今天不少人观点认为用 MySQL 去替代 Oracle 是无意义的。因为 MySQL 和 Oracle 同属于甲骨文公司。甚至在有的场合中还会提到要去掉 MySQL。</p><span id="OSC_h2_2"></span><h2><span style="color:#2980b9">当前数据库国产化进程情况如何?</span></h2><p>当前在信创和安可这些趋势下，国产数据库如雨后春笋般出现。在国内某权威数据库排行榜上，已经有 280 多个数据库了。实际上的数字可能比这个还要多一点。</p><p>在一些政府、金融、运营商行业都有一些国产化替换。这些替换其实不仅仅是数据库了，还包括服务器、CPU、操作系统等等。从宣传上看有些是全栈替换，有些是部分替换。也还有一些公司或者企业没有替换。然而这些都是国产厂商的宣传，至于实际的替换情况只有用户自己知道。而即使替换的用户也没有进行相关的宣传，这就使得整个情况非常的模糊。不过这个过程还在继续，还是会有一些系统从 Oracle、DB2、SQLServer 等数据库切换到国产化上来的。只是现在不确定因素太多了。</p><p>今年年初，TiDB、TDengine、TDSQL、OceanBase 四位数据库界掌门人在一场直播中大致达成一致，三年后在中国健康运营的数据库不超过 20 家。所谓健康运营是，企业能有正常营收，员工发薪正常。目前国产数据库有 280 多个产品，有的一个公司有几个产品。即使这样也是有绝大部分产品或者公司会因为无法盈利而退出舞台。用户现在也意识到了这一点，也在等情况明朗后再去选择。没有企业愿意看到花了很大代价切换的数据库无人维护了，不得不继续再次替换。</p><p>国产数据库有完全自研的，例如达梦、OceanBase 等，也有一些是基于 MySQL 做改造的，还有一些事基于 PostgreSQL 改造的，还有购买外国源码然后进行修改的。</p><span id="OSC_h2_3"></span><h2><span style="color:#2980b9">替代 Oracle 的难点在哪里?</span></h2><p>技术上，Oracle 确实领先，在数据库领域是一个标杆一样的存在。即使我们国产数据库的头部企业都认为自己和 Oracle 有较大的差距，作为学习者不断地在向 Oracle 学习。</p><p>Oracle 领先的其实不仅仅是技术，还有设计理念和前瞻性。2020 年信通院发布的白皮书中写了数据库的未来几大趋势，而在那时候这几个趋势当时 Oracle 已经部分实现和深度实现了。其实 Oracle 产品线很多，不仅仅是数据库。其中间件、硬件、操作系统等等是全方面的输出。</p><p><strong>具体到几个方面：</strong></p><p><strong>兼容性</strong><strong>。</strong>对于替换国产数据库，兼容性是一件绕不开的话题，特别是对于存量系统来说，大多数重要系统是运行在 Oracle 数据库上的，那么对于 Oracle 的<strong>基本</strong><strong>SQL</strong><strong>语法、</strong><strong>PL</strong><strong>/SQL、存储过程、触发器等</strong>的兼容性肯定是十分重要的，毕竟这涉及代码变更的问题。如果在国产数据库替换过程中出现业务适配新数据库代码变更量太大、数据库功能缺失需要业务侧代码补充、适配分布式数据库过程中对数据库设计和业务逻辑变更等现象的话，开发层面对国产数据库的抵触会非常大。</p><p><strong>性能。</strong>性能和硬件以及优化器都有很大的关系。优化器这方面目前没有能超过 Oracle 优化器的。因为这些底层都是数学算法。2021 年信通院发布的数据库发展白皮书显示，我国数据库企业针对数据库领域的平均专利数量（含国内外专利）为 38 个，最高为 500 个左右规模，数量为 0 的企业个数是 19 个，占比 24%。拥有专利数 0-4 个的企业占比最高为 51%，专利数 5-10 个的企业次之，占比 14%，专利数 21-50 个的企业数量排名第三，占比 12%。从企业专利数量上看，Oracle 以 1.4 万个全球领先，SAP 居次席。</p><p><strong>稳定性。</strong>Oracle 的稳定性还是毋庸置疑的，这也就是为什么在过去那么多年中，其一直占据着领导地位，以及使用如此广泛。企业负责人都不希望看到自己的数据库经常出问题，每次数据库的问题都可能导致故障，从而影响到在线业务。不仅仅要面对直接和间接的经济损失，还有问责的压力。</p><p>Oracle 等国外数据库有足够的全球市场，专心在技术上投入做数据库，而国产数据库厂商只能在国内有限的数据库市场内卷，需要投入大量的内卷、恶性竞争和关系处理上，无法专心把全部精力放在做数据库上。甚至还是为了如何生存而谋划。</p><p>国产数据库的出现并不是技术问题，而是其他因素。</p><p>数据库领域的人都知道，在信创活动结束之后就没有替换动力了。而最终国内市场无法容得下几百家供应商，所以大部分国产数据库的消失也不是技术问题。</p><span id="OSC_h2_4"></span><h2><span style="color:#2980b9"><strong>有哪些能够替代 Oracle 的国产数据库？</strong></span></h2><p>这个替代要讲清楚是怎么替代？如果说就是把系统关停，然后把数据导过来，然后再修改数据库的连接字符串就可以和之前一样正常使用而且稳定的。目前没见过也没听说过。</p><p>如果说换了一个国产数据库，然后把链接这个数据库的所有业务系统的软件代码进行修改（这个修改可能是 30-100%），即软件重写适配数据库或者部分需求和功能放弃，那么这样的替换还是有一些的。OceanBase、TiDB、TDSQL 等都有在不同程度上有，具体的都是应实际情况而定。</p><p>这些替换的优势，可能在于满足了政治要求。</p><p><strong>这些替换的劣势，有多方面：</strong></p><p>由于同等硬件下不如 Oracle 的性能，所以增加硬件导致成本的上升。或者分布式数据库的硬件就是比集中式硬件的多导致的硬件成本上升。</p><p>由于数据库特性和功能的缺失，所以应用程序需要改造的成本上升。这部分可能占替换总成本的 60%-80%。因为这是调动大量应用开发人员重写适配的过程。</p><p>由于稳定性上不如 Oracle，所以需要增加大量运维人员，导致运维的成本上升。</p><p>由于部分国产数据库需要许可才可以运行，所以增加了大量的许可费用。相比较之前很少采购 Oracle 许可或者甚至不采购许可来说，这部分采购费用占比很大。</p><p>以上这些成本可能会是使用 Oracle 数据库的数倍甚至几十倍甚至上百倍。而很多计算中都忽略了第二和第三项的成本。</p><span id="OSC_h2_5"></span><h2><span style="color:#2980b9">现有国产数据库跟 Oracle 相比，有多大的差距?</span></h2><p>从技术上来说，我们和 Oracle 相比有代差。</p><p>可能不同的人有不同的见解。我个人感觉有以下多方面的差距（但是不限于此）：</p><p><strong>数据库的</strong><strong>优化器</strong><strong>上：</strong>有人说为什么 Oracle 快，你可能不知道多少满头白发的数学教授在那里研究着这些。有人说：你别逼我，逼急了我什么都做的出来。」 「是吗？，那你把这道数学题给做做？」 人被逼急了还真不是什么都做的出来，起码数学就不是。各种复杂查询的核心是优化器和统计信息。而这全部都是数学问题。没有在数学上的基础投入是无法在这个领域攻坚克难的。</p><p><strong>体系架构上：</strong>如今越来越多的国产数据库考虑 RAC 架构。在经历了互联网的分布式数据库的洗礼后，越来越多的用户觉得集中式更加适合自己。所以才有了各种国产数据库厂商开始实现 RAC 的计划，达梦、优炫等。即使分布式数据库厂商在研发过程中发现 Oracle 的各种体系设计，没有一个是多余的，都是设计极其精妙的。而这些很多设计都是 30 年前甚至更早就已经设计到位的。</p><p><strong>与</strong><strong>操作系统</strong><strong>的融合上：</strong>数据库是运行在操作系统之上的，如何与 CPU 打交道？SQL 调用指令集的多少都是有讲究的。甚至有些操作是绕过操作系统直接操作的。这些都是需要深耕操作系统才能解决的。</p><p><strong>与硬件的融合上：</strong>数据库必然要和存储设备打交道。数据库的优化几乎等同于 IO 优化。所以 Oracle 直接做出来自己的存储。这些存储上都是带有 CPU 的，更好的存储和读取数据上发挥了很大的作用。做数据库是从上至下的深入解决。</p><p><strong>趋势把握上：</strong>数据库的多模和超融合这些都是 Oracle 在引领着数据库技术的前进方向。我们定义为趋势的，Oracle 基本都是已经实现的。而很多理念从设计到实现需要 8-10 年的过程。</p><span id="OSC_h2_6"></span><h2><span style="color:#2980b9"><strong>国产数据库未来要怎么走?</strong></span></h2><p>我个人角度认为，应该静下心来踏实的做技术。</p><p>最好是没有政治因素的干扰去市场上竞争，避免大跃进式的百家齐放，而是规范市场，让国内外数据库厂商同台竞争。用户结合自己的预算进行抉择，是选择廉价的还是性价比高的，让一切回归到技术本身来。而不能用政策限制其他产品进入，只能强制使用国产。这样会导致自我封闭和外部的排斥。既然我们用政策限制其他人，那么对等的就会出现别人限制我们。从而更加无法走出去。</p><p>如果真正能走出去，在国外用得起来，那么就是国产数据库的成功。中国的高铁就是因为走出去了才成为了中国的一张名片。</p><blockquote><p><strong>作者简介：</strong></p><p>薛晓刚，现任欧冶云商股份有限公司数据库首席。曾服务于政府、公安、交通、安防行业，从事过大型项目管理，设计和运维多个单表 100 亿，单机 100TB 的数据库。目前负责高可用、业务连续性和高并发数据架构设计和运维管理。</p><p>Oracle ACE-Pro（Oracle 和 MySQL 方向），Oracle OCP/MySQL OCP 及 OCP 讲师。PostgreSQL 的 PGCE 和 PCP 认证，PostgreSQL ACE Partner。墨天轮 MVP，TiDB MVA，ITPUB 论坛内存数据库版主、核心专家、金牌顾问，墨天轮社区特聘金牌讲师，机械工业出版社专家委员会委员。</p><p><img height="483" src="https://oscimg.oschina.net/oscnet/up-db67ea17186e0146cd30e998dbd09b31b55.png" width="500" referrerpolicy="no-referrer"></p><p><strong>联系作者：</strong></p><p><img height="249" src="https://oscimg.oschina.net/oscnet/up-783ed80bb94f3f8e33fb256e9e56a3413e6.png" width="500" referrerpolicy="no-referrer"></p></blockquote><p>&nbsp;</p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10321019</guid>
            <link>https://my.oschina.net/u/3859945/blog/10321019</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FFmpeg CLI 支持多线程 —— 数十年来「最复杂的重构」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>FFmpeg CLI 近日迎来重大改进 —— 合并了<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fffmpeg.org%2Fpipermail%2Fffmpeg-devel%2F2023-November%2F316552.html" target="_blank">多线程转码管道</a></u>&nbsp;</strong>(multi-threaded transcoding pipelines)，预计在明年发布的&nbsp;FFmpeg 7.0 中提供。</p><p><img src="https://oscimg.oschina.net/oscnet/up-69e8f13ce3a5ed36727e8f9c13a6d4cf9a0.png" referrerpolicy="no-referrer"></p><p>来源：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fffmpeg.org%2Findex.html%23cli_threading" target="_blank">https://ffmpeg.org/index.html#cli_threading</a></em></u></p><p>其开发团队表示，这项工作是「数十年来 FFmpeg CLI 最复杂的重构之一」，主要内容包括添加了线程感知的转码调度基础设施、将编码任务移动到独立线程，以及各种其他底层更改。这意味着 FFmpeg 现在可以实现并行处理任务，这将提高吞吐量和 CPU 利用率，降低延迟。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0f082465774090329fe668d4160939f9c33.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fup.khirnov.net%2F7m.pdf" target="_blank">https://up.khirnov.net/7m.pdf</a></u></em></p><p>据介绍，这次更新并不是针对编解码器本身进行多线程处理，因为现代编解码器通常已经支持多线程处理。相反，FFmpeg 决定并行化的是 ffmpeg 本身，包括过滤器等。这意味着 FFmpeg CLI 现在可以更高效地处理视频转码任务。</p><p>Hacker News 上有开发者提出了一些关于视频编码的<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D38613219" target="_blank">想法</a></u>，例如将关键帧分段独立处理，以实现更好的多核性能。这种方法可以在一定程度上提高编码效率，但也需要考虑内存和编码逻辑的复杂性。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 02:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270790/ffmpeg-cli-multi-threading-merged</guid>
            <link>https://www.oschina.net/news/270790/ffmpeg-cli-multi-threading-merged</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源之夏 2023 圆满落幕，共同点亮开源新星]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:#494949">1</span></span></span><span><span><span style="color:#494949">2</span></span></span><span><span><span style="color:#494949">月</span></span></span><span><span><span style="color:#494949">8</span></span></span><span><span><span style="color:#494949">日，随着年度优秀学生名单的公示，开源之夏 2</span></span></span><span><span><span style="color:#494949">023</span></span></span><span><span><span style="color:#494949">圆满落幕。从 3 月到 1</span></span></span><span><span><span style="color:#494949">2</span></span></span><span><span><span style="color:#494949">月，伴随着四季推进，开源之夏 2</span></span></span><span><span><span style="color:#494949">023</span></span></span><span><span><span style="color:#494949">见证了数百位高校开发者如星星之火闪烁在众多开源项目中以及他们在漫长开源之旅中留下的足迹，也见证了更多优秀的开源贡献者和开源项目的应运而生。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:#494949">开源之夏&nbsp;2023&nbsp;由中国科学院软件研究所与&nbsp;openEuler&nbsp;社区联合主办，</span></span></span><span><span><span style="color:#494949">中科南京软件技术研究院承办，旨在</span></span></span><span><span><span style="color:#494949">鼓励在校学生积极参与开源软件的开发维护，促进优秀开源软件社区的蓬勃发展，助力开源软件供应链建设，让开源的力量薪火相传</span></span></span><span><span><span style="color:#494949">，是中国科学院软件研究所「开源软件供应链点亮计划」指导下的重点年度活动。</span></span></span><span><span><span style="color:#494949">本届</span></span></span><span><span><span style="color:#494949">开源之夏</span></span></span><span><span><span style="color:#494949">联合</span></span></span><span><span><span style="color:#494949">1</span></span></span><span><span><span style="color:#494949">33</span></span></span><span><span><span style="color:#494949">家国内外活跃的开源社区，</span></span></span><span><span><span style="color:#494949">针对其重要开源软件的开发与维护任务，面向全球高校学生发布项目 593 个</span></span></span><span><span><span style="color:#494949">，</span></span></span><span><span><span style="color:#494949">覆盖操作系统、人工智能、大数据、web、内核与编译器、分布式、云原生、RISC-V 等热门技术方向。</span></span></span><span><span><span style="color:#494949">时至第四届，</span></span></span><span><span><span style="color:#494949">开源之夏吸引了</span></span></span><span><span><span style="color:#494949">越来越多遍布国内外</span></span></span><span><span><span style="color:#494949">的年轻开发者参与开源社区、贡献开源。2023</span></span></span><span><span><span style="color:#494949">年，来自海内外 5</span></span></span><span><span><span style="color:#494949">92</span></span></span><span><span><span style="color:#494949">所高校的 3</span></span></span><span><span><span style="color:#494949">000</span></span></span><span><span><span style="color:#494949">多位学生参与开源之夏，</span></span></span><span><span><span style="color:#494949">504&nbsp;名学生</span></span></span><span><span><span style="color:#494949">成功</span></span></span><span><span><span style="color:#494949">中选，开启开源之旅。历经&nbsp;3&nbsp;个月的项目开发时间，最终，418&nbsp;份项目成果通过结项考核，累计产出并合并 1236 个 PR，成果陆续纳入社区主线并上线发布</span></span></span><span><span><span style="color:#494949">，随着版本更新在华为、阿里、字节、京东、腾讯、网易等企业落地应用。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:#494949">为了鼓励同学们，</span></span></span><span><span><span style="color:#494949">经开源社区和导师推荐，本年度</span></span></span><span><span><span style="color:#494949">组委会</span></span></span><span><span><span style="color:#494949">继续</span></span></span><span><span><span style="color:#494949">从&nbsp;4&nbsp;个方向评选出具有代表性的&nbsp;20&nbsp;位优秀学生。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><p><strong><span><span><span style="color:#494949">最佳质量奖为项目角度的评选奖项，侧重项目完成质量、代码的可读性、文档的完整度使得项目具有可延续性。</span></span></span></strong></p></li><li><p><strong><span><span><span style="color:#494949">突出贡献奖为社区角度的评选奖项，侧重学生对社区的贡献度、完成项目对社区的重要性等。</span></span></span></strong></p></li><li><p><strong><span><span><span style="color:#494949">最快进步奖为学生角度的评选奖项，侧重学生参与活动的进步程度和快速学习能力。</span></span></span></strong></p></li><li><p><strong><span><span><span style="color:#494949">最具潜力奖为开源角度的评选奖项，侧重学生展现出未来持续贡献开源的潜力和意愿。</span></span></span></strong></p></li></ul><p>&nbsp;</p><p><img alt="" height="539" src="https://oscimg.oschina.net/oscnet/up-76644ac7087ce5b6c9b434dfb2567ba28a3.png" width="1252" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><img alt="" height="517" src="https://oscimg.oschina.net/oscnet/up-53e663e573fe0f8ad1bd9fae6d3e99e51f5.png" width="1216" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><img alt="" height="496" src="https://oscimg.oschina.net/oscnet/up-5f9ee24a1414766db22103aff87af28ef7b.png" width="1235" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:#494949">一年活动的结束并不意味着开源参与的结束</span></span></span><span><span><span style="color:#494949">，大批新生的开源力量</span></span></span><span><span><span style="color:#494949">不断涌现并持续贡献</span></span></span><span><span><span style="color:#494949">。</span></span></span><span><span><span style="color:#494949">开源之夏 2</span></span></span><span><span><span style="color:#494949">023 调研结果显示，结项后继续留在开源社区参与开发贡献的学生</span></span></span><span><span><span style="color:#494949">高达 8</span></span></span><span><span><span style="color:#494949">0%</span></span></span><span><span><span style="color:#494949">。</span></span></span><span><span><span style="color:#494949">这些高校开发者在已有项目成果的基础上不断扩展贡献范围，有效保证</span></span></span><span><span><span style="color:#494949">了</span></span></span><span><span><span style="color:#494949">相关成果的连续性与维护性，并</span></span></span><span><span><span style="color:#494949">逐渐</span></span></span><span><span><span style="color:#494949">成长为开源项目的核心开发者。</span></span></span><span><span><span style="color:#494949">学生在开源之夏参与高质量工业化的开源项目实践，了解最前沿的技术趋势，与社区导师、资深开发者建立联系，获取更多的实践经验，为自己的职业发展打下坚实基础。同时开源社区也在活动中发掘、培养优秀开发者，完善社区建设，助力开源生态繁荣发展。让我们共同期待未来星光熠熠的开源之天空！</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 02:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270788</guid>
            <link>https://www.oschina.net/news/270788</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[院士领衔，Linux 操作系统多语言支撑技术研讨会在成都成功举行！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>2023 年 12 月 10 日，由西藏大学、内蒙古大学、青海师范大学、四川大学、电子科技大学、国防科技大学、麒麟软件有限公司、成都联图科技有限公司等单位联合举办，openKylin 社区承办的《Linux 操作系统多语言支撑技术研讨会》在成都召开！本次会议由中国工程院院士、openKylin 社区咨询委员会委员尼玛扎西教授担任主席，openKylin 社区秘书长余杰研究员担任主持。参会专家围绕 Linux 操作系统的多语言支持现状、不足和未来规划等进行深入探讨，并研讨操作系统如何助力国家更好地实现一带一路战略。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="517" src="https://oscimg.oschina.net/oscnet/up-7d7650099c002fecddf0ea48dc0d0aeae2f.jpg" width="853" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>首先，openKylin 社区技术委员会委员李剑峰就 openKylin 操作系统多语言版本情况向与会专家进行汇报，介绍了多语言操作系统的发布情况、版本特性、平台架构以及未来规划。未来，openKylin 操作系统将继续扩展多语言支持，包括外语拓展、少数民族语言扩展，进一步优化多语言框架，研制国内领先、国际先进的多语言支撑平台，提升我国信息领域技术核心竞争力。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>随后，参会专家围绕当前 Linux 操作系统多语言版本进行了发言。他们主要表示了要完善操作系统生态的必要性，包括办公软件的完善，集成当前主流的智能 AI 框架和大语言模型，以掌握 AI 操作系统的话语权。此外，他们还提出了进一步优化翻译平台和翻译机制的建议，并强调加强推广多语言操作系统版本的重要性。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>最后，尼玛扎西院士就本次会议进行总结发言。他强调，提高我国基础软件竞争力需采取有效策略，充分利用丰富的语言文字资源，积极响应国家需求，开发实用、好用的多语言操作系统，推动我国科技创新和发展。</span><span>我国 Linux 操作系统要扎根中国、</span><span>扬帆出海！</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="855" src="https://oscimg.oschina.net/oscnet/up-b67751709c8cc8e9f16b3e4e388f03eaff0.jpg" width="1280" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 02:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270783</guid>
            <link>https://www.oschina.net/news/270783</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[HyperDX —— 开发者友好的 Datadog 替代品]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>HyperDX&nbsp;是<span style="background-color:#ffffff; color:#1f2328">一个</span>基于云的生产监控和调试工具<span style="background-color:#ffffff; color:#1f2328">，统一会话重放、日志、指标、跟踪和错误。</span>通过将日志、指标、跟踪、异常和会话重播集中并关联到一处，帮助工程师更快地找出生产中断的原因。Datadog 和 New Relic 的开源且开发人员友好的替代方案。</p><ul><li>端到端关联，只需点击几下即可从浏览器会话重放到日志和跟踪</li><li>由 Clickhouse 提供支持的极快性能</li><li>直观的全文搜索和属性搜索语法（例如<code>level:err</code>）</li><li>自动对数十亿个事件中的事件模式进行聚类</li><li>仪表板高基数事件，无需复杂的查询语言</li><li>只需点击几下即可设置警报</li><li>自动解析 JSON/结构化日志</li><li>OpenTelemetry native</li></ul><p><img height="702" src="https://static.oschina.net/uploads/space/2023/0920/163847_4VuB_4252687.png" width="1220" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/hyperdx</guid>
            <link>https://www.oschina.net/p/hyperdx</link>
        </item>
        <item>
            <title>
                <![CDATA[小米回应余承东「龙骨转轴」抄袭华为言论]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>「小米公司发言人」官方微博近日发布声明，就余承东所述「龙骨转轴」抄袭华为言论做出澄清称：</p><blockquote><p>近日，余承东先生无端针对我司龙骨转轴技术发布不实言论，与事实严重不符。我们请余承东先生遵循「科学与严谨」的基本规则，请勿再抹黑同行、误导公众。</p></blockquote><p>声明指出，无论是设计思路还是机械结构，小米自研的龙骨转轴与余承东所宣称的所谓双旋水滴较链都完全不同。</p><p>且龙骨转轴于 2020 年 9 月 18 日申请专利，并于 2021 年 1 月 5 日获得专利授权，在 2023 年 8 月于 XiaomiMIXFold 了上首发应用。双旋水滴较链则于 2019 年 12 月 13 日申请的专利，2021 年 6 月 18 日才公开。「由此可知，余承东先生的言论，完全不符合事实。」</p><p><img alt="" height="1349" src="https://oscimg.oschina.net/oscnet/up-31b05e591ed808bedd4150f1214bc51f38d.jpg" width="500" referrerpolicy="no-referrer"></p><p>专利图：</p><p><img alt="" height="368" src="https://static.oschina.net/uploads/space/2023/1213/100457_fh3o_4252687.jpg" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 02:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270776</guid>
            <link>https://www.oschina.net/news/270776</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 物联网智能网关系统，物联大师]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-物联大师" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E7%89%A9%E8%81%94%E5%A4%A7%E5%B8%88"></a>物联大师</h1><p><strong>注意，[V3.0]版本与<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fzgwit%2Fiot-master%2Ftree%2Fv2">V2.0</a>
和<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fzgwit%2Fiot-master%2Ftree%2Fv1">V1.0</a>有较大差异，不可以直接升级！！！</strong></p><h3><a id="user-content-说明文档--演示 demo-账号密码-admin-123456" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3--%E6%BC%94%E7%A4%BAdemo-%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81-admin-123456"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fiot-master.com%2Fmanual">说明文档</a><a href="https://gitee.com/link?target=http%3A%2F%2Fdemo.iot-master.com%3A8080%2F">演示 demo</a> 账号密码 admin 123456</h3><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fzgwit%2Fiot-master%2Factions%2Fworkflows%2Fgo.yml"><img src="https://github.com/zgwit/iot-master/actions/workflows/go.yml/badge.svg" alt="Go" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fzgwit%2Fiot-master%2Factions%2Fworkflows%2Fcodeql-analysis.yml"><img src="https://github.com/zgwit/iot-master/actions/workflows/codeql-analysis.yml/badge.svg" alt="Go" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fcodecov.io%2Fgh%2Fzgwit%2Fiot-master"><img src="https://codecov.io/gh/zgwit/iot-master/branch/main/graph/badge.svg?token=AK5TD8KQ5C" alt="codecov" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fpkg.go.dev%2Fgithub.com%2Fzgwit%2Fiot-master"><img src="https://pkg.go.dev/badge/github.com/zgwit/iot-master.svg" alt="Go Reference" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2Fzgwit%2Fiot-master"><img src="https://goreportcard.com/badge/github.com/zgwit/iot-master" alt="Go Report Card" referrerpolicy="no-referrer"></a></p><p>物联大师是<a href="https://gitee.com/link?target=https%3A%2F%2Flabs.zgwit.com">无锡真格智能科技有限公司</a>
推出的开源且免费的物联网操作系统，内置 MQTT、TCP Server/Client、UDP Server/Client、串口等接入服务，
系统集成标准 Modbus，水务（SL651、SZY206），电力（DL/T645、IEC101、102、103、104、61850）以及一些主流 PLC 协议，
系统可以通过插件支持数据采集、公式计算、定时控制、异常报警、自动控制策略、流量监控、远程调试、Web 组态等功能，
适用于大部分物联网或工业互联网应用场景。
系统采用 Golang 编程实现，支持多种操作系统和 CPU 架构，可以运行在智能网关上，也可以安装在现场的电脑或工控机上，还能部署到云端服务器。</p><p>项目摒弃复杂的平台架构思维，远离微服务，从真实需求出发，注重用户体验，做到简捷而不简单，真正解决物联网缺乏灵魂的问题。</p><p>我们的宗旨是：<strong>让物联网实施变成一件简单的事情!!!</strong></p><h2><a id="user-content-项目的优势" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E9%A1%B9%E7%9B%AE%E7%9A%84%E4%BC%98%E5%8A%BF"></a>项目的优势</h2><ul><li>开源免费，商业应用也不限制</li><li>单一程序文件，不需要配置运行环境，不依赖第三方服务，放服务器上就能跑</li><li>极小内存占用，对于一百节点以内的物联网项目，只需要几十兆内存足够了，<del>比起隔壁 Java 动辄大几百兆内存简直太省了</del></li><li>支持工控机和智能网关，边缘计算也没问题</li><li>支持大屏展示，Web 组态，3D 数据孪生 <del>毕竟很多物联网项目都是面子工程</del></li><li>在线产品库、模板库、组件库，小白也能分分钟搞得有模有样【还在努力建设中】</li></ul><h2><a id="user-content-项目示例" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E9%A1%B9%E7%9B%AE%E7%A4%BA%E4%BE%8B"></a>项目示例</h2><p><img src="https://iot-master.com/web1.jpg" alt="web" referrerpolicy="no-referrer"><img src="https://iot-master.com/hmi-editor.png" alt="scada" referrerpolicy="no-referrer"></p><h2><a id="user-content-咨询服务" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E5%92%A8%E8%AF%A2%E6%9C%8D%E5%8A%A1"></a>咨询服务</h2><p><strong>本公司目前提供免费的物联网方案咨询服务，结合我们十多年的行业经验，给您提供最好的建议，请联系 15161515197（微信同号）</strong></p><blockquote><p>PS. 提供此服务的主要目的是让用户少走弯路，为物联网行业的健康发展尽绵薄之力。
总结一下常见的弯路：</p><ol><li>前期使用某个物联网云平台，后期没办法继续，二次开发受限</li><li>花了几千元买了工业网关，用着一百元 DTU 的功能</li><li>找多个外包公司，低价拿单，结果做出屎一样的东西</li><li>盲目使用开源项目，最终被开源项目所累</li><li>硬件选型失败，效果差强人意</li><li>自身技术人员能力有限，架构设计有问题</li><li>不支持高并发量，市场爆发了，平台反而跟不上</li><li>等等</li></ol></blockquote><h2><a id="user-content-联系方式" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F"></a>联系方式</h2><ul><li>邮箱：<a href="mailto:jason@zgwit.com">jason@zgwit.com</a></li><li>手机：<a>15161515197</a>(微信同号)</li></ul><table><thead><tr><th>技术交流群</th><th>微信</th></tr></thead><tbody><tr><td><img src="https://iot-master.com/tech.png" alt="微信群" referrerpolicy="no-referrer"></td><td><img src="https://iot-master.com/jason.jpg" alt="微信" referrerpolicy="no-referrer"></td></tr></tbody></table><h2><a id="user-content-开源协议" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE"></a>开源协议</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fzgwit%2Fiot-master%2Fblob%2Fmain%2FLICENSE">GPL v3</a></p><p>补充：任何组织或个人都可以免费使用或做二次开发，但不得用于商业售卖，如有需求请联系我们。</p><h3><a id="user-content-官方插件" class="anchor" href="https://gitee.com/zgwit_labs/iot-master#%E5%AE%98%E6%96%B9%E6%8F%92%E4%BB%B6"></a>官方插件</h3><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Forgs%2Fiot-master-contrib%2Frepositories">插件库</a></p><table><thead><tr><th>插件</th><th>完成</th><th>正式版</th></tr></thead><tbody><tr><td>历史统计【内置】</td><td>✅</td><td>⬜</td></tr><tr><td>异常报警【内置】</td><td>✅</td><td>⬜</td></tr><tr><td>Influxdb 时序数据库</td><td>✅</td><td>⬜</td></tr><tr><td>Modbus 通讯协议</td><td>✅</td><td>⬜</td></tr><tr><td>WebRTC 接入摄像头</td><td>✅</td><td>⬜</td></tr><tr><td>Web 组态</td><td>✅</td><td>⬜</td></tr><tr><td>3D 数据孪生</td><td>⬜</td><td>⬜</td></tr><tr><td>阿里云通知</td><td>✅</td><td>⬜</td></tr><tr><td>DLT645-2007，电力规约</td><td>⬜</td><td>⬜</td></tr><tr><td>西门子 PLC，S7 系统，PPI，MPI，FetchWrite</td><td>✅</td><td>⬜</td></tr><tr><td>三菱 PLC</td><td>✅</td><td>⬜</td></tr><tr><td>欧姆龙 PLC，Hostlink，Fins</td><td>✅</td><td>⬜</td></tr><tr><td>TDEngine</td><td>⬜</td><td>⬜</td></tr><tr><td>OpenTSDB</td><td>⬜</td><td>⬜</td></tr><tr><td>流式计算</td><td>⬜</td><td>⬜</td></tr><tr><td>报表引擎</td><td>⬜</td><td>⬜</td></tr></tbody></table>]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 01:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/zgwit_labs/iot-master</guid>
            <link>https://gitee.com/zgwit_labs/iot-master</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 双十一弹性能力支撑 - ECI 稳定性建设]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h3_1"></span><h3>一、关于 ECI</h3><p style="text-align:justify">背景从 2018 年正式发布，<strong>ECI 已经打磨了整整 4 个年头</strong>，如今也已经快速成长为了阿里云 serverless 容器的基础设施，服务着阿里内外众多的公有云客户与云产品，每天承接着数百万的弹性容器创建。</p><p style="text-align:justify">然而，ECI 这些年却未参与到集团双十一大促，双十一可以说是阿里技术人的阅兵，能不能承接住双十一的流量成为了检验一个产品是否稳定可靠的重要标准。但一切都是水到渠成，就在今年，ASI 开始与 ECI 对接，尝试让 ECI 承接双十一大促的弹性的 30W 核算力，我们都知道双十一大促对于整个阿里集团的意义，使命将至，我们必将全身心地投入到对接、压测、护航的工作中。经过长达两个多月的业务适配、压测、备战，最终完成了双十一大促的弹性容器的圆满交付。这背后，离不开 ASI、ECI 以及参与到其中的每一位脚踏实地、用心钻研、保驾护航的同学的努力。ECI 今年首次作为集团大促弹性基础设施，根据线上数据统计，大促期间 ECI 弹性资源使用共计约 400W 核，从资源的瞬时弹性、保有规模、系统稳定性等多方面对云原生系统都是一次巨大的考验。作为底层的计算单元，ECI 此次也成功顶住了双十一弹性流量洪峰的考验，在感叹 serverless、容器这些技术发展迅猛的同时，对于全新的系统架构稳定性的考验也不小。</p><p style="text-align:justify">如今再回过头来看 ECI 的第一次双十一，我们有必要做一次全面的总结，我们为集团弹性保障做了哪些工作，哪些是将来可以复用的工作，哪些是可以给其他的团队作为借鉴的技术和经验，以及哪些地方还可以做的更好，为下一次大促做准备。</p><p style="text-align:justify">本文我们将为大家介绍，<strong>ECI 这些年在稳定性方面做了哪些工作，以及是如何来为集团双十一保驾护航的。</strong></p><span id="OSC_h3_2"></span><h3>二、遇到的挑战</h3><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-484afd33bc5b8c5f4774ab7fddf53a98_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">大规模并发带来的稳定性挑战遇到的最大挑战首先是大规模并发带来的。容器保有量增多之后，从容器实例生产方面来看对于云管控系统是不小的考验，尤其是对于弹性场景来讲，需要在极短的时间进行实例的生产，镜像的大规模拉取，进而保障容器的成功启动。</p><p style="text-align:justify"><strong>如何能保障实例的大规模成功生产</strong>，如何先于线上发现问题，以及即使出现了问题如何第一时间止血并进行故障恢复，这对于集团双十一期间的业务重保都是尤为重要的。除此之外，对于公有云环境来讲，不能影响到其他的公有云客户也是需要重点关注的，因此需要具备一套完整的稳定性保障体系以及故障应对方案以确保双十一期间的业务能够顺利进行。实例生产系统稳定性 ECI 和 ECS 共用一套资源调度系统，相对于 ECS 容忍度为分钟级别的应用来讲，ECI 实例频繁的创建删除对调度系统的要求更为苛刻，对系统容量以及稳定性保障方面提了更高的要求。服务可用性保障 ECI 安全沙箱由于某种原因异常（OOM/物理机宕机/kernel panic），导致不健康情况。这种情况下，k8s 层面如果不从 endpoint 上摘除这个 ECI Pod，会导致请求通过负载均衡依然可以路由到这台不健康的 ECI 上，会导致业务请求成功率下降，因此对于集团业务服务可用性保障也是尤为重要的。</p><span id="OSC_h3_3"></span><h3>三、ECI 稳定性技术建设</h3><p style="text-align:justify">稳定性保障从需求收集准备阶段开始，双十一大促持续两个月之久，为了配合集团全链路验收，ECI 自身的稳定性保障工作也随之紧锣密鼓地进行。</p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-353460c616617e11f187c76359272f10_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">稳定性的保障贯穿了整个大促过程，大促前慎重/减少系统变更以排除人为因素的干扰，敬畏发布，多次压测演预案确保系统稳定性，不断提升系统抵抗力稳定性和系统恢复力稳定性，以保障大促的顺利进行，最后通过问题覆盘沉淀出可复制的大客户重保策略，这对于未经过双十一实战演练具有积极的意义。</p><p style="text-align:justify">因此我们梳理出了整个大促期间围绕稳定性方面做的主要工作，主要包括风险控制、关键业务依赖梳理、技术保障、压测预案、运行时保障、故障运维能力、以及最后的覆盘优化，希望以此能对今后的大促工作作为指导，并沉淀出稳定性治理的经验。接下来我们对此次大促涉及到的主要稳定性保障方法以及如何应用进行介绍。</p><p style="text-align:justify">实例生产保障 VM 复用技术实例生产行为的保障是集团弹性使用 ECI 的重中之重。一个典型的实例生产过程如图所示，<strong>ECS 和 ECI 在控制面共用一套管控系统，</strong>ECI 管控侧调用资源调度系统之后会分配计算资源之后会调用 pync（阿里云单机管控组件），进而调用 avs(阿里云单机网络组件) 和 tdc(阿里云单机存储组件) 分别生产网卡与磁盘。在此过程中，对于调用 ECS 依赖的 open api 接口较重，在大规模创建删除场景很快成为系统瓶颈，此前我们专门针对容器实例高频创建删除场景开发了 VM 复用功能，对于高频场景删除容器实例的场景，延迟 vm 的回收，并复用容器实例的网卡、镜像、计算资源，降低对管控系统整体的冲击，以此来保障实例生产系统的稳定性，从此次双十一的实战演练效果来看，vm 复用取得了很好的效果，管控系统容量整体处于正常水位，保障了集团双十一实例稳定的弹性能力。</p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-dcd697c3f23312c91e09c0272f34fbd8_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">重调度机制对于库存不足或者远程服务调用超时等情况，为了保障实例生产的最终一致性，对于 ECI 实例生产我们设计了相应的故障处理策略策略，取值如下：fail-back：失败自动恢复。即 Pod 创建失败后自动尝试重新创建 fail-over：失败转移。效果等同于 fail-backfail-fast：快速失败。即 Pod 创建失败后直接报错故障处理策略本质上是一种重调度的策略。原生的 k8s 调度支持重调度，即调度失败后会将 pod 重新放入调度队列等待下次调度，类比 k8s 的重调度行为，当 eci 管控系统收到创建请求的时候，首先会进入一个队列，然后有个异步定时任务会将创建从队列中捞起，提交到异步工作流进行实际的资源生产、以及容器的启动等。即便是结合了多可用区和多规格的优化，异步工作流依然有可能失败的，比如资源的争抢、内网 ip 不足、启动失败等，这时候就需要将创建请求再次重回队列，等待被重新调度生产。</p><p style="text-align:justify">我们目前对于<strong>故障处理策略</strong>：</p><p style="text-align:justify">1、失败的任务会一直重试，但是我们会计算每个任务的执行周期，重试次数越多，执行周期越长，以达到退避效果。</p><p style="text-align:justify">2、优先级策略会考虑用户级别、任务类型、任务上次失败的原因等因素，优先级高的任务优先提交执行。</p><p style="text-align:justify">3、每次调度失败的原因都会以标准事件的方式通知到 k8s 集群。队列里的任务的整个执行流程的状态机如下：</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-e09200aea1a82cf515617f061a7bb54a_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">所有执行失败的任务都会重新进入队列，等待被再次调度。由于任务会在任何一步失败，所以所有生产出来的资源都会回滚，回滚结束后，进入初始状态。初始状态的任务会被拉起执行，然后提交到异步生产。如果生产失败，就会再次回到等待调度的状态。如果生产成功，任务就结束，到达终态。基于我们的重调度机制，可以极大的减少由于生产系统抖动造成实例生产失败的情况，对于容器启动成功率要求高的场景可以保障实例生产的最终一致性，对于容器启动成功率要求不那么严格的场景可以快速失败，由上层业务进行处理。</p><p style="text-align:justify">服务容错降级对于故障场景，系统依赖服务的降级也是十分重要的。大多数进行限流降级的方案主要关注点在服务的稳定性，当调用链路中某个资源依赖出现异常，例如，表现为 timeout，异常比例升高的时候，则对这个资源的调用进行限制，并让请求快速失败或返回预设静态值，避免影响到其它的资源，最终产生雪崩的效果。ECI 目前实现了基于历史日志自学习进行无损降级、本地 cache 降级、流控降级 3 级降级机制框架，ECS/ECI openapi 全面接入，内部依赖 200+接口接入，根据每个接口的调用频率、RT 分布、超时时间设置来单独分析，选择合适的降级策略，设置合理的阀值，能让系统出问题时，智能降级从而进行系统保护。<strong>一个典型的降级机制实现过程如图：</strong></p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-1239ddaa0f4eab60e7996e6fec9fe364_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify"><strong>当有非资源类核心 API 新请求进入</strong>，如果历史缓存数据未过期则直接返回缓存数据，结束业务逻辑反之则请求远程接口。如果请求成功，返回数据，对数据进行缓存，同时将缓存数据以日志方式存入 sls cache log 日志用于未来降级，结束业务逻辑当远程请求失败时触发降级策略：如果失败指标（例如指定时间内异常比例）在预设时间窗口内未达到配置的降级策略阈值，则直接抛出相应业务异常，结束业务逻辑如达到降级策略阈值则按以下顺序实行降级策略：从 sls 缓存日志查找历史日志数据作为降级返回值，同时将返回值重新写入缓存，结束业务逻辑如果 sls 缓存日志没有相应日志则返回：预设静态值或空值，结束业务逻辑对于一些跟用户资源无关，更新少，属于全局参数的服务/接口，以上通用降级策略和方案可能因为降级规则阈值难以界定而无法有效执行。</p><p style="text-align:justify">针对这些接口采用 dubbo 异常直接降级的策略涉及到降级或熔断的条件：自动降级 (可选利用 Sentinal 进行自动降级)： 超时，异常，限流手动开关支持核心非资源 api 直接进行 openapi 本地降级 cache 对于严重的系统故障，可以将核心几个 describe api 进行 openapi 本地 cache，发生故障，或有雪崩出现时，全部切到 openapi 本地 cache，在降级影响面的同时，也能减轻对下层服务的调用压力来赢取恢复时间。</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-0ce94b0355dad7e7cbc7463c70e8ad87_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">依赖服务非创建链路 dubbo 或 http 请求进行本地 moc 对于几乎不会频繁变化的依赖服务，通过每日 sls 分析进行 kv 的存储，当故障发生时，降级为备用，让降级影响面趋向于 0。其他服务降级机制大分页流控 cache 创建类 api 进行依赖 dubbo 或 http 服务降级，<strong>异步补偿操作类 api 进行链路降级，</strong>取消非必需依赖数据库降级 ro 库流量降级隔离，用户级别流量切到灰度 api 级别流量切到灰度/独立线程池日志 debug 及调用链路跟踪使用 apicontext 实现详细日志 debug 及调用全链路跟踪能力核心 api debug 日志建设，支持按用户开启 debug 日志打印 requestId 贯穿到 dao，支持随时采样，及时发现 dao 异常调用服务依赖降级容错机制可以在保障服务稳定性的前提上，利用相关接口的历史缓存数据，基于 SLS 日志无损降级，当 SLS 无数据的时候也可以采用本地静态数据兜底，构建有效返回值，在服务触发流控降级熔断后，大部分用户不会感知到服务异常。</p><p style="text-align:justify">在内部的多次故障演练中，服务降级机制可以有效保护系统由于发生故障带来的系统瘫痪。服务可用性保障在传统的 Kubernetes 集群中，如果 Node 变得不可用且达到时间阈值，那么会将 Node 上的 Pod 进行驱逐，重新在其他 Node 上拉起新的 Pod。而在 Serverless 场景下，ECI 管控会通过异步检测机制检测不健康 ECI，修改状态为不可用，同时增加导致不可用的事件，告知 ECI 用户，之后 ECI 会通过主动运维的手段治愈不健康 ECI，之后触发控制面将 ECI 恢复为 Ready 状态，<strong>主要过程如图所示：</strong></p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-790b2ccc925edb4964dede90b43256af_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify"><strong>处理不健康 ECI 的流程：</strong></p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-4e6eaa3bddc8488957271e480923d34a_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify"><strong>恢复 Ready ECI 流程预案&amp;压测除了技术方面的保障，故障注入、应急预案、压测演练在稳定性建设中也尤为重要。</strong>在双十一活动期间我们内部进行了多次压测演练，对系统中常见的性能瓶颈进行故障注入，用以模拟故障的发生，同时制定应急预案，以此应对故障已经发生时的场景。通过多次的压测摸高，一方面可以评估系统容量的承载上限，另一方面可以借此机会进行大规模压测演练，验证系统降级方案并对系统稳定性进行评估。预警&amp;监控大促进行时，预警和监控是保证系统运行时稳定性的重要措施。通过监控和预警可以及时发现系统故障，进而快速进行恢复。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-bfb30f596763e9976d35e307e15d74a2_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-c27bfedd2fd094067dc495bbdab8340a_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h3_4"></span><h3>四、系统的健壮性</h3><p style="text-align:justify">思考沉淀一个健壮的系统不仅需要减少问题的发生，同时要具备故障发现以及故障快速恢复的能力。除了预警和监控，运维能力建设也十分重要。</p><p style="text-align:justify"><strong>一个系统的健壮性体现在系统的容量，</strong>系统的容错能力以及系统依赖的各个资源的 sla，尤其是在云上覆杂的资源环境下，由于「木桶效应」，某一项依赖资源的很可能造成整个系统的直接不可用。因此，随着系统不断完善，我们需要通过混沌工程等方法来找出当前系统的「弱点」进而对其进行专项优化，进而提升整个系统的健壮性；其二对于系统的故障恢复以及降级能力也很重要，历史上 ECS/ECI 管控多次由於单用户或系统某个环节变慢，导致系统全链路雪崩，最终导致 P1P2 故障，ECS/ECI 管控是阿里云最复杂的管控系统，复杂的业务逻辑，内部系统依赖，非常多的环节出问题都有可能导致全链路某个应用雪崩进而全局不可用，因此，对于故障已经来临时，依赖降级能力能非常有效的保护我们的系统，这也是稳定性建设的一个十分重要的方向。</p><span id="OSC_h3_5"></span><h3>五、总结</h3><p style="text-align:justify">未来展望随着双十一最后一波流量高峰结束，ECI 顺利通过了对阿里人最严苛的技术考验--双十一，本文围绕此次参与双十一活动的经历做出总结，希望可以为今后 ECI 稳定性方面的建设积累经验，当然，这对 ECI 来说也仅仅是一步试金石，作为云原生时代的基础设施，ECI 任重而道远，共勉！</p><p style="text-align:justify">本文出品及鸣谢： 柳密、羽云、景奇、存诚、 煜枫、景止、皓瑜、月悬、佐井、尚哲、涌泉、十刀、 木名、秉辰、易观、冬岛、不物、潇洛、 怀欢、 尝君、寒亭、伯琰。</p><p style="text-align:justify"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1389034%3Futm_content%3Dg_1000385342" target="_blank">原文链接</a></strong></p><p style="text-align:justify"><strong>本文为阿里云原创内容，未经允许不得转载。</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 01:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/yunqi/blog/10319647</guid>
            <link>https://my.oschina.net/yunqi/blog/10319647</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AutoMQ 社区双周精选第二期（11.20-12.01）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>本期概要</h2><p>在开源的第二个双周里，作为一个成长中的开源项目，AutoMQ 做了很多的优化和重构，以下是相关重点动态的总结。<br> AutoMQ Kafka：写链路耗时优化、快慢读隔离、Spot 实例强制回收容灾。<br> AutoMQ RocketMQ：历史数据冷读优化、LogCache 读写耗时优化、发布 v0.0.3-alpha 版本、发布 Helm Chart、发布文档站。</p><h2>AutoMQ Kafka 精选动态</h2><h3>写链路耗时优化</h3><p>原来所有的写入和回调都会放到一个单线程线程池去进行处理来确保数据安全，该方式存在线程上下文切换通信、单线程处理排队两个问题。本次优化将写入流程中的数据结构改造成线程并发安全模式，使得不同 stream 之间可以并发进行写入，AutoMQ Kafka 客户端平均写入耗时<strong>下降 0.3ms</strong>。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fpull%2F728" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/pull/728</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fpull%2F729" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/pull/729</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fpull%2F743" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/pull/743</a></p><h3>快慢读隔离</h3><p>隔离从 Cache 读取的快读和从 S3 的读取的慢读，避免慢读占满快读的线程池影响快读。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-kafka%2Fpull%2F472" target="_blank">https://github.com/AutoMQ/automq-for-kafka/pull/472</a></p><p><strong>Spot 实例强制回收容灾</strong></p><p>在上期精选中提及进度的 Spot 实例强制回收容灾已经完成。Spot（竞价实例）相比按需实例可以便宜至多 90 %，但问题是它可能不经通知就强制回收。该特性支持 Spot 实例强制回收的情况下，仍旧可以将数据卷挂载到存活的机器，进行<strong>秒级容灾恢复</strong>。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-kafka%2Fissues%2F447" target="_blank">https://github.com/AutoMQ/automq-for-kafka/issues/447</a></p><h2>AutoMQ RocketMQ 精选动态</h2><h3>Stream 模块性能优化</h3><h4>历史数据冷读优化</h4><p>历史数据追赶读优化，Fetch 请求（50MB &amp; 50 stream）冷读穿透到 S3 场景，单次 Fetch 耗时从 4s 优化到 100ms。即使是完全穿透冷读，S3 读取吞吐效率也是很高的。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fpull%2F766" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/pull/766</a></p><h4>LogCache 读写耗时优化</h4><p>增加上次 Cache 读取位点记录，避免每次从 LogCache 读取数据都需要二分查找定位，10W 个消息下 10W 次查询时间从 71s 优化到 86ms。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fpull%2F731" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/pull/731</a> 通过读写锁，将 LogCache 升级成线程并发安全的数据结构，提升 LogCache 读取并发效率。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fpull%2F701" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/pull/701</a></p><h3>发布 v0.0.3-alpha 版本</h3><p>这个版本包含了以下功能和优化： 1）稳定性与性能提升：修复了潜在的 OOM 问题以及提升 stream 模块性能，详见 Changelog：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fcompare%2Fv0.0.2-alpha...v0.0.3-alpha" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/compare/v0.0.2-alpha...v0.0.3-alpha</a> 2）工程化建设：引入 Nightly build 和&nbsp;E2E test CI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhub.docker.com%2Fr%2Fautomqinc%2Fautomq-for-rocketmq%2Ftags" target="_blank">https://hub.docker.com/r/automqinc/automq-for-rocketmq/tags</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Factions%2Fworkflows%2Fbuild-ci.yml" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/actions/workflows/build-ci.yml</a> 3）可观测性提升：为 stream 模块引入 Metrics；为 Proxy、Store 模块引入 Trace <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-rocketmq%2Fpull%2F766" target="_blank">https://github.com/AutoMQ/automq-for-rocketmq/pull/766</a></p><h3>发布 Helm Chart</h3><p>现在可以使用 Helm Chart 快速在 Kubernetes 中创建 AutoMQ RocketMQ 集群。</p><pre><code class="language-cs">$ helm repo add automq https://charts.automq.com
$ helm search repo automq                                                                                                                                                            
NAME                            CHART VERSION   APP VERSION     DESCRIPTION                                                                                                           
automq/automq-for-rocketmq      0.0.4           v0.0.3-alpha    A Helm chart for automq-for-rocketmq
</code></pre><p>部署该 Chart 会创建一个 AutoMQ RocketMQ Broker 以及依赖的 MySQL 与 Minio 组件。后续会陆续加入可选的可观测性依赖组件。</p><h3>发布文档站</h3><p>介绍了 AutoMQ RocketMQ 基本使用方式，包含：本地构建、使用 docker compose 部署、在 Kubernetes 上部署。以及使用 CLI 运维集群模式，管理 Topic 等资源。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.automq.com%2Fzh%2Fdocs%2Fautomq-rocketmq%2FRmuXwhb5Xi9zjCkrInRcCz0UnTe" target="_blank">https://docs.automq.com/zh/docs/automq-rocketmq/RmuXwhb5Xi9zjCkrInRcCz0UnTe</a></p><h2>More Things</h2><p>与小红书的同学共创对象存储跨地域容灾方案 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ%2Fautomq-for-kafka%2Fissues%2F477" target="_blank">https://github.com/AutoMQ/automq-for-kafka/issues/477</a></p><p>以上是第二期《双周精选》的内容，欢迎关注我们的公众号，我们会定期更新 AutoMQ 社区的进展。同时，也诚邀各位开源爱好者持续关注我们社区，跟我们一起构建云原生消息中间件！</p><p><strong>END</strong></p><h3>关于我们</h3><p>AutoMQ 是一家专业的消息队列和流存储软件服务供应商。AutoMQ 开源的 AutoMQ Kafka 和 AutoMQ RocketMQ 基于云对 Apache Kafka、Apache RocketMQ 消息引擎进行重新设计与实现，在充分利用云上的竞价实例、对象存储等服务的基础上，兑现了云设施的规模化红利，带来了下一代更稳定、高效的消息引擎。此外，AutoMQ 推出的 RocketMQ Copilot 专家系统也重新定义了 RocketMQ 消息运维的新范式，赋能消息运维人员更好的管理消息集群。&nbsp;</p><p>🌟&nbsp;GitHub 地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAutoMQ" target="_blank">https://github.com/AutoMQ</a></p><p>💻&nbsp;官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.automq.com" target="_blank">https://www.automq.com</a></p><p>👀&nbsp;B 站：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546572478482870" target="_blank">AutoMQ 官方账号</a></p><p>🔍&nbsp;视频号：AutoMQ&nbsp;</p><p><strong>👉 扫二维码</strong>加入我们的社区群</p><p><img src="https://oscimg.oschina.net/oscnet/up-c4c6b2be9441c750e268dd2d48294131af7.png" alt="" referrerpolicy="no-referrer"></p><p>关注我们，一起学习更多云原生干货</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 01:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6990971/blog/10320900</guid>
            <link>https://my.oschina.net/u/6990971/blog/10320900</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云原生周刊：Kubernetes v1.29 新特性一览]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwerf%2Fkubedog" title="kubedog" target="_blank">kubedog</a></h3><p>Kubedog 是一个用于在 CI/CD 部署管道中监视和跟踪 Kubernetes 资源的库。</p><p>这个库被用于 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwerf%2Fwerf" title="werf CI/CD" target="_blank">werf CI/CD</a> 工具中，在部署过程中跟踪资源。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frunwhen-contrib%2Frunwhen-local" title="RunWhen Local" target="_blank">RunWhen Local</a></h3><p>runwhen-local 是一个工具，用于在本地环境中运行 runwhen 脚本。runwhen 是一个灵活的任务调度工具，可以根据条件和时间表来执行任务。通过 runwhen-local，开发者可以在本地测试和调试 runwhen 脚本，以确保其正确运行。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewharf%2Fkubegateway" title="KubeGateway" target="_blank">KubeGateway</a></h3><p>kube-gateway 是字节跳动内部管理海量 kubernetes 集群的最佳实践。 它是为 kube-apiserver 的 HTTP2 流量专门设计并定制的七层负载均衡代理。 目标是为海量的大规模 kubernetes 集群（千级 node 以上）提供灵活的稳定的流量治理方案。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fflannel-io%2Fflannel" title="flannel" target="_blank">flannel</a></h3><p>Flannel 是为 Kubernetes 设计的一种简单且易于配置的第三层网络结构的解决方案。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmoelove.info%2F2023%2F12%2F10%2FKubernetes-v1.29-%25E6%2596%25B0%25E7%2589%25B9%25E6%2580%25A7%25E4%25B8%2580%25E8%25A7%2588%2F" target="_blank">Kubernetes v1.29 新特性一览</a></h3><p>这篇文章介绍了 Kubernetes v1.29 版本的新特性。该版本包含了 49 个主要的更新，其中有 19 个增强功能进入 Alpha 阶段，19 个升级到 Beta 阶段，还有 11 个升级到稳定版。</p><p>文章重点介绍了两个重要的特性：基于 CEL 的 CRD 规则校验和为动态和静态分配预留 NodePort 端口范围。基于 CEL 的 CRD 规则校验是一种在 CRD 声明中编写校验规则的方式，简化了开发和维护成本。而为动态和静态分配预留 NodePort 端口范围的特性解决了在创建 NodePort 时可能产生的端口冲突问题。总体而言，Kubernetes v1.29 版本的新特性为用户提供了更好的功能扩展和更可靠的输入校验。</p><h3>[Kubernetes：Pod 和 WorkerNodes – 控制 Pod 在节点上的放置</h3><p>](<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frtfm.co.ua%2Fen%2Fkubernetes-pods-and-workernodes-control-the-placement-of-the-pods-on-the-nodes%2F" target="_blank">https://rtfm.co.ua/en/kubernetes-pods-and-workernodes-control-the-placement-of-the-pods-on-the-nodes/</a>)</p><p>这篇文章介绍了在 Kubernetes 中如何控制 Pods 在 WorkerNodes 上的部署位置。它提供了四种主要的方法来实现这种控制：</p><ul><li>配置节点</li><li>Taints 和 Tolerations</li><li>配置 Pod 本身</li><li>Pod 亲和性和反亲和性</li></ul><p>此外，文章还提到了 Pod 拓扑分布约束（Pod Topology Spread Constraints），即根据失败域（regions、可用区或节点）的规则来放置 Pod。</p><p>文章还提供了一些使用 kubectl explain 命令来查看相关参数和资源文档的技巧。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40geoffrey.muselli%2Fargocd-multi-tenancy-strategy-94d72183c94" title="ArgoCD：多租户策略" target="_blank">ArgoCD：多租户策略</a></h3><p>这篇文章介绍了使用 ArgoCD 实现多租户策略的方法。在使用 ArgoCD 时，通常会允许所有用户自由操作，直到进入生产环境后才意识到某个人通过删除应用程序而删除了命名空间或 CRD。为了解决这个问题，需要使用访问控制和多租户策略。文章详细介绍了如何利用 ArgoCD 的原生功能实现多租户策略，并提供了一个示例来演示如何在大型组织中使用企业敏捷框架（例如 SAFe）来实施。文章还讨论了 ArgoCD 中的 AppProject、RBAC 和命名空间等概念，以及如何配置和使用它们来实现多租户策略。最后，文章提供了一个具体的示例，展示了如何根据团队和项目的需求来配置 AppProject 和 RBAC。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F05%2Fkyverno-completes-third-party-security-audit%2F" title="Kyverno 完成第三方安全审计" target="_blank">Kyverno 完成第三方安全审计</a></h3><p>Kyverno 项目宣布完成了第三方安全审计。该审计是由 Ada Logics 与 Kyverno 维护人员、开源技术改进基金合作进行，由 CNCF 资助。</p><p>该安全审计是一个全面的安全审计，有以下四个目标：</p><ul><li>为 Kyverno 定义一个正式的威胁模型。</li><li>对代码进行手动安全漏洞审计。</li><li>根据威胁模型评估 Kyverno 的模糊测试套件。</li><li>针对 SLSA 评估 Kyverno 的供应链风险。</li></ul><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Dec 2023 11:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10320847</guid>
            <link>https://my.oschina.net/u/4197945/blog/10320847</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
