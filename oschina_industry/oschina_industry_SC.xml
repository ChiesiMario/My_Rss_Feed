<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 06 Mar 2024 12:57:10 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Linux 基金会推出「反诈」开源项目 Tazama，获盖茨基金会资助]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gatesfoundation.org%2F" target="_blank">比尔及梅琳达•盖茨基金会</a>（Bill &amp; Melinda GatesFoundation）的支持下，Linux 基金会慈善机构（LF Charities）<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-launches-tazama-for-real-time-fraud-management" target="_blank">宣布</a></u>推出<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">Tazama</a>，这是一套用于实时欺诈预防的开源软件解决方案。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-935f8d1d736dc3d5b53baa4a2e1caebd24b.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gasa.org%2Fglobal-anti-scam-summit-2023" target="_blank">全球反诈骗联盟 (Global Anti-Scam Alliance)</a>报告称，2022 年因在线欺诈损失了近万亿美元。</p><p>Tazama 标志着全球金融监管和合规方式的重大转变。迄今为止，金融业一直在使用专有的、往往成本高昂的解决方案，这些解决方案限制了许多人（尤其是发展中经济体）的使用和适应性。</p><p>Tazama 提供了一种强大、可扩展且成本效益高的开源反欺诈替代解决方案，实现了先进金融监控工具的平民化，有助于打击欺诈行为，从而挑战了这一现状。</p><p>Tazama 解决了政府、民间社会、最终用户、行业机构和金融服务业的主要问题，包括欺诈检测、反洗钱合规性和数字金融交易的成本效益监控。该解决方案的架构强调数据主权、隐私和透明度，与世界各国政府的优先事项保持一致。Tazama 由 LF 慈善基金会主办，该基金会将为项目的运行和功能提供支持，Tazama 展示了开源解决方案的可扩展性和稳健性，尤其是在国家支付交换机等关键基础设施方面。</p><p>一些组织正在探索与 Tazama 的协同作用，包括 BankservAfrica、IPSL、JoPACC 和 BCEAO。协同作用包括评估 Tazama 解决方案在实际应用场景中的有效性、可扩展性和适应性，确保其满足并超越各行业数字金融服务提供商（DFSP）的不同需求。</p><p>Tazama 欢迎各国中央银行、监管机构、移动支付提供商、系统集成商、组织和个人参与其中。欲了解更多有关 Tazama 及其使命、社区和倡议的信息，请访问 Tazama<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftazama.org%2F" target="_blank">网站</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffrmscoe" target="_blank">GitHub</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 10:03:40 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</guid>
            <link>https://www.oschina.net/news/281816/lf-tazama-for-real-time-fraud-management</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 和 Elon Musk【译】]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>OpenAI 今天在官网<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">发布新闻稿</a></u>，回应</span><span>埃隆·马斯克</span><span>起诉一事。</span></p><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>该文章由 Sam Altman、Greg Brockman、Ilya Sutskever 等人共同署名。文章表示，OpenAI 打算</span><span>驳回</span><span>埃隆·马斯克</span><span>的所有诉讼请求，</span><span>并公布了一些高层和</span><span>埃隆·马斯克</span><span>的历史往来邮件作为证据。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-49bfb7cdaf49904c3a735c17f2ac5c4887e.png" referrerpolicy="no-referrer"></p></blockquote><p>以下为新闻稿原文翻译：</p><p>&nbsp;</p><p>OpenAI 的使命是确保 AGI 造福全人类，这意味着既要构建安全有益的 AGI，又要帮助人类创造收益。现在，我们将与大家分享我们在完成使命方面的心得，以及我们与埃隆之间关系的一些事实情况。</p><p>我们正打算驳回埃隆的所有诉讼请求。</p><h3><strong>我们意识到，构建 AGI 所需的资源远远超出我们最初的想象</strong></h3><hr><p>埃隆说，我们应该布向 OpenAI 提供 10 亿美元的初始资金承诺。实际上，这家非营利组织总共从埃隆那里筹集了不到 4500 万美元，从其他捐赠者那里筹集了 9000 多万美元。</p><p>在 2015 年底创办 OpenAI 时，格雷格和萨姆最初计划筹集 1 亿美元。但是埃隆在一封电子邮件中表示&nbsp;「我们需要一个比 1 亿美元大得多的数字，以免让人听起来觉得毫无希望……我认为我们应该从 10 亿美元的资金承诺开始.如果其他人不提供的，我会承担。「 [1]</p><p>我们花了很多时间来设想通往 AGI 的合理路径。2017 年初，我们意识到构建 AGI 需要大量的计算。我们开始计算 AGI 可能需要多少计算量。我们都明白，要想成功完成使命，我们将需要更多的资金--这将达到每年数十亿美元，远远超出了我们任何人的想象，尤其是埃隆，他认为我们作为非营利组织无法筹集到这么多资金。</p><h3><strong>我们和埃隆都认识到，要获得这些资源，就必须建立一个营利实体。</strong></h3><hr><p>在我们讨论营利性结构以推进使命时，埃隆希望我们与特斯拉合并，否则他需要获得全部的控制权。这之后埃隆离开了 OpenAI，他说需要有一个与谷歌/DeepMind 相对应的竞争对手，而他打算自己来做这件事。他同事表示，他会支持我们找到自己的道路。</p><p>2017 年底，我们和埃隆决定下一步的任务是创建一个营利实体。埃隆希望获得多数股权以及最初的董事会控制权，并担任首席执行官。在这些讨论中，他扣留了资金。Reid Hoffman 填补了资金缺口，为我们支付了工资和运营费用。</p><p>我们无法就营利性公司的条款与埃隆达成一致，因为我们认为任何个人对 OpenAI 拥有绝对控制权都有悖于公司的使命。于是，他建议将 OpenAI 并入特斯拉。2018 年 2 月初，埃隆给我们转发了一封邮件，建议 OpenAI 「依附于特斯拉，将其作为自己的资金来源「，并评论说 「完全正确……特斯拉是唯一一条甚至有望与谷歌相提并论的道路。即便如此，与谷歌抗衡的可能性也很小。但并不是零」。[2]</p><p>埃隆很快选择离开 OpenAI，他说我们的成功概率为 0，他计划在特斯拉内部建立一个 AGI 团队与我们竞争。他在 2018 年 2 月底离开时告诉我们，他支持我们自己寻找筹集数十亿美元的道路。2018 年 12 月，埃隆给我们发邮件说：「即使筹集到几亿美元也不够。这需要每年筹集数十亿美元，否则就算了。「 [3]</p><h3><strong>我们通过构建可广泛使用的有益工具来推进我们的使命</strong></h3><hr><p>我们通过开源等方式，使我们的技术能够广泛使用，从而提高人们的效率，改善他们的日常生活。</p><p>我们向大众提供了当今最强大的人工智能，包括每天有数亿人使用的免费版本。举个例子，阿尔巴尼亚正在使用 OpenAI 的工具将其加入欧盟的时间加快了 5.5 年；数字绿色公司正在帮助肯尼亚和印度提高农民收入，通过在 OpenAI 的基础上将农业推广服务的成本降低 100 倍；罗德岛州最大的医疗保健提供商 Lifespan 使用 GPT-4 将其手术同意书从大学阅读水平简化到六年级水平；而冰岛正在使用 GPT-4 保护越来越少人使用的冰岛语。</p><p>埃隆明白，这些工作并不意味着开源 AGI。正如伊利亚告诉埃隆的那样 「随着我们越来越接近 AGI，开始降低开放程度是有意义的。OpenAI 中的 「开放 「是指人工智能建成后，每个人都应从人工智能的成果中受益，但不分享科学成果也完全没问题……"，埃隆回答道： 「是的」。[4]</p><p>对于埃隆的起诉，我们倍感遗憾。我们深深钦佩的一个人走到了这一步。他曾激励我们向更高的目标迈进，然后告诉我们会失败，建立了一个竞争对手团队，而当我们开始在没有他的情况下朝着 OpenAI 的使命取得有意义的进展时，他又将我们告上法庭。</p><p>我们专注于推进自己的使命，这还有很长的路要走。我们相信随着我们的产品越来越好，他们将更好地为每个人赋权。</p><p>&nbsp;</p><p><strong>以下为往来邮件翻译：</strong></p><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173736_2J68.png" referrerpolicy="no-referrer"></p><p>[1]</p><p>发件人 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;格雷格-布罗克曼</p><p>抄送： Sam Altman</p><p>Date： Sun, Nov 22, 2015 at 7:48 PM</p><p>主题： 通话后续</p><p>博客听起来不错，但要考虑到中立性和以青委会为中心。</p><p>我更倾向于将博客定位为更吸引普通大众－－让大众支持我们取得成功有很大的价值－－然后为招聘工作准备一个更长、更详细、更有内幕的版本，并在普通大众版本的末尾提供链接。</p><p>我们需要一个比 1 亿美元大得多的数字，以避免与谷歌或 Facebook 的支出相比显得毫无希望。我认为我们应该说，我们将从 10 亿美元的资金承诺开始。这是真的。其他人不提供的，我都会提供。</p><p>模板看起来还不错，除了默认转为归属现金红利外，还可以选择将其转为 YC 或 SpaceX（需要了解具体数额）的股票。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_l1GG.png" referrerpolicy="no-referrer"></p><p>[2]</p><p>发件人 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>Date： 2018 年 2 月 1 日，星期四，凌晨 3:52</p><p>主题 Fwd： 今天的顶级人工智能机构</p><p>说得一点没错。我们或许希望如此，但在我看来，特斯拉是唯一能与谷歌抗衡的公司。即便如此，与谷歌抗衡的可能性也很小，但也不是零。</p><p>开始转发信息：</p><p>发件人： &nbsp;&nbsp;&lt;&gt;</p><p>致 &nbsp;埃隆-马斯克 &lt;&gt;</p><p>日期，太平洋标准时间 2018 年 1 月 31 日下午 11:54:30</p><p>主题 Re： 当今顶尖的人工智能机构</p><p>不幸的是，在人工智能的最前沿工作是昂贵的。除了 DeepMind，谷歌还有 Google Brain、Research 和 Cloud。还有 TensorFlow、TPU，它们拥有大约三分之一的研究成果（事实上，它们还举办自己的人工智能会议）。</p><p>我还强烈怀疑，要实现 AGI，计算能力将是必要的。如果历史趋势能够说明问题，那么人工智能的进步主要是由系统－－计算、数据、基础设施－－驱动的。我们今天使用的核心算法与上世纪 90 年代相比基本没有变化。不仅如此，任何发表在论文中的算法进展几乎都可以立即被重新实现和整合。反过来说，如果没有一定的规模，单靠算法的进步是没有生命力的。</p><p>在我看来，如今的 OpenAI 正在烧钱，其融资模式无法达到与谷歌（一家 8000 亿美元的公司）认真竞争的规模。如果你无法与谷歌认真竞争，却继续在开放环境中进行研究，那么你可能会让事情变得更糟，并 「免费 「帮助他们，因为他们很容易复制任何进步，并立即将其规模化。</p><p>以营利为目的的转型可能会随着时间的推移创造出更稳定的收入来源，而就目前的团队而言，很可能会带来大量投资。然而，从零开始打造产品会抢走人工智能研究的重点，而且需要很长时间，目前还不清楚一家公司能否 「赶上 「谷歌的规模，投资者也可能会在错误的方向上施加过多压力。我所能想到的最有希望的方案，正如我之前提到的，就是让 OpenAI 附属于特斯拉，将其作为自己的资金来源。我认为，依附于其他大型公司（如苹果、亚马逊），会因公司基因不兼容而失败。打个比方，特斯拉已经建造了火箭的 「第一级「，包括 Model 3 的整个供应链、车载电脑和持续的互联网连接。第二阶段 「将是基于大规模神经网络训练的完全自动驾驶解决方案，OpenAI 的专业技术可以大大帮助加快这一进程。在大约 2-3 年的时间里，我们就能推出功能完善的完全自动驾驶解决方案，销售大量汽车/卡车。如果我们真的做得很好，运输行业的规模足够大，我们可以将特斯拉的市值提高到 O（约 10 万美金），并利用这笔收入为适当规模的人工智能工作提供资金。</p><p>我看不到有任何其他公司有潜力在十年内达到可持续的谷歌规模资本。</p><hr><p><img alt="" src="https://static.oschina.net/uploads/img/202403/06173737_gNCb.png" referrerpolicy="no-referrer"></p><p>[3]</p><p>发件人 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;Ilya Sutskever 、Greg Brockman</p><p>抄送： Sam Altman</p><p>Date： Wed, Dec 26, 2018 at 12:07 PM</p><p>主题： 我觉得我应该重申</p><p>在执行和资源没有发生巨大变化的情况下，我对 OpenAI 与 DeepMind/Google 相关性的概率评估是 0%。而不是 1%。我希望不是这样。</p><p>即使筹集到几亿美元也不够。这需要每年立即筹集数十亿美元，否则就算了。</p><p>不幸的是，人类的未来掌握在【未透露名称】手中。</p><p>他们所做的远不止这些。</p><p>我真希望我错了。</p><p>埃隆</p><hr><p><img src="https://oscimg.oschina.net/oscnet/up-9103940e18f26f6ed78e7c0e58a9b0be1dc.png" referrerpolicy="no-referrer"></p><p>【4】</p><p>Fwd: 恭喜猎鹰 9</p><p>包含 3 条信息</p><p>发件人 &nbsp;Elon Musk</p><p>收件人 &nbsp;Sam Altman、Ilya Sutskever、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 8:18 AM</p><p>主题，收件人： 恭喜猎鹰 9 号</p><p>开始转发消息：</p><p>From：&nbsp;未透露姓名</p><p>To： &nbsp;埃隆-马斯克</p><p>日期： 美国中部时间 2016 年 1 月 2 日上午 10:12:32</p><p>主题： 恭喜猎鹰 9 号</p><p>嗨，埃隆</p><p>祝你新年快乐，</p><p>首先祝贺猎鹰 9 号着陆，这是一项了不起的成就。现在是时候组建舰队了！</p><p>我看到你（还有萨姆和其他 OpenAI 人士）最近接受了很多采访，大肆宣扬人工智能开源的优点，但我想你应该意识到，这并不是某种能神奇地解决安全问题的灵丹妙药吧？有很多很好的论据可以说明，为什么你所采取的方法实际上是非常危险的，事实上可能会增加世界的风险。在这篇博文中，一些比较明显的观点得到了很好地阐述，我相信你已经看到了，但还有其他一些重要的考虑因素：</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fslatestarcodex.com%2F2015%2F12%2F17%2Fshould-ai-be-open%2F" target="_blank">http://slatestarcodex.com/2015/12/17/should-ai-be-open/</a></p><p>我很想听听你对这些观点的反驳。</p><p>发件人 &nbsp;Ilya Sutskever</p><p>致 &nbsp;Elon Musk 、Sam Altman、 Greg Brockman</p><p>日期 Sat, Jan 2, 2016 at 9:06 AM</p><p>主题 Fwd: 恭喜猎鹰 9 号</p><p>这篇文章关注的是 「硬起飞 「</p><p>如果发生 「硬起飞「，而安全的人工智能比不安全的人工智能更难构建，那么通过开放一切，我们就会让那些能够获得大量硬件的不法分子轻而易举地构建出不安全的人工智能，从而遭遇 「硬起飞」。</p><p>当我们越来越接近构建人工智能时，开始降低开放程度将变得更有意义。openAI 中的 「开放 「意味着，在人工智能建成后，每个人都应从人工智能的成果中获益，但不分享科学知识也是完全可以的（尽管在短期和中期内，为了招聘的目的，分享一切绝对是正确的策略）。</p><p>来自 &nbsp;埃隆-马斯克</p><p>收件人 &nbsp;Ilya Sutskever</p><p>日期 Sat, Jan 2, 2016 at 9:11 AM</p><p>主题 Fwd: 恭喜猎鹰 9 号</p><p>是的</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:37:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281801/openai-elon-musk</guid>
            <link>https://www.oschina.net/news/281801/openai-elon-musk</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌在其搜索排名系统中对垃圾邮件和人工智能进行降级]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2F2024%2F3%2F5%2F24091099%2Fgoogle-search-high-quality-results-spam-ai-content" target="_blank">据 The Verge 报道</a></u>，谷歌正在对其搜索排名系统进行一些新的更改，这些更改旨在帮助在结果中显示好的内容，并隐藏网络上一些最糟糕和最愤世嫉俗的内容。</p><p>该公司表示，它在降级内容方面做得更好，这些内容只是为了总结其他内容——有时可能是正常的搜索引擎优化内容，但也越来越多地成为生成人工智能工具的工作——并打击人们用来欺骗的一些技巧它的排名系统。</p><p>谷歌搜索副总裁潘杜·纳亚克 (Pandu Nayak) 列举了谷歌现在认为是垃圾邮件行为并打算降低排名的三个例子。</p><p>第一个是大规模内容：这些网站每天通过低薪承包商或人工智能生成器创建数千篇低质量文章，并将这些内容定位在搜索结果中。</p><p>第二种垃圾邮件行为是 Nayak 所说的「网站声誉滥用」。这是指一个原本受人尊敬的网站出租其部分网站来传播垃圾邮件。</p><p>第三就是人工智能，人工智能生成的内容应该如何排名的问题才刚刚开始，因为它既试图将人工智能带给每个人，又试图拯救网络免于被淘汰。甚至谷歌自己的搜索引擎也成为人工智能机器。而且总会有新的方法来让它在搜索结果中名列前茅。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 09:03:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281786/google-search-high-quality-results-spam-ai-content</guid>
            <link>https://www.oschina.net/news/281786/google-search-high-quality-results-spam-ai-content</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CSIS：2023 年全球人工智能发展回顾及 2024 年人工智能政策预测]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">2024 年 1 月 30 日，战略与国际问题研究中心 CSIS 发布报告《2024 年人工智能政策预测》，回顾了 2023 年全球人工智能的发展，提出了 2024 年在 AI 政策方面需要关注的 10 个重点，以及 AI 领域关键技术术语。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" height="301" src="https://static.oschina.net/uploads/space/2024/0306/162236_PCSo_4700705.png" width="360" referrerpolicy="no-referrer"></span></p><p>以下是报告主要内容：</p><div><div><ol><li><p style="margin-left:0; margin-right:0"><strong>2023 年 AI 发展回顾</strong>：</p><ul><li>中国实施了管理深度伪造的新法律。</li><li>微软对 OpenAI 进行了巨额投资。</li><li>美国国防部更新了关于武器系统中自主性的指令。</li><li>NIST 发布了 AI 风险管理框架。</li><li>美国与欧盟宣布加速联合 AI 研究。</li><li>荷兰和日本加入美国限制对中国半导体制造设备出口的努力。</li><li>OpenAI 的 ChatGPT 成为历史上增长最快的应用。</li><li>美国和欧盟签署了关于 AI 治理的协议。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AI 技术影响</strong>：</p><ul><li>AI 聊天机器人用户数量激增，尤其是 OpenAI 的 ChatGPT。</li><li>大型语言模型（LLM）如 GPT-4 和 Meta 的 LLaMA 不断推出，模型规模和参数不断增大。</li><li>AI 在多个科学领域取得突破，如材料科学和气象学。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AI 治理与监管</strong>：</p><ul><li>美国、欧盟和中国等地区采取了 AI 监管措施。</li><li>美国商务部发布了 AI 风险管理框架，旨在增强 AI 的透明度和安全性。</li><li>欧盟通过了 AI 法案，这是迄今为止最全面的 AI 监管法规。</li><li>中国发布了关于生成性 AI 服务的监管措施，包括确保数据训练的合法性。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>国际合作与治理</strong>：</p><ul><li>英国举办了全球 AI 安全峰会，签署了 Bletchley 宣言，旨在促进 AI 的透明度和问责制。</li><li>G7 和联合国等国际组织在 AI 治理方面进行了讨论，强调了国际合作的重要性。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>私营部门的角色</strong>：</p><ul><li>私营部门在 AI 治理中扮演了重要角色，与政府合作管理 AI 技术。</li><li>AI 相关诉讼数量增加，涉及数据隐私、版权和专利法等问题。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>军事应用</strong>：</p><ul><li>美国国防部更新了关于武器系统中自主性的指令，并推出了 Replicator 计划，旨在加速 AI 启用的自主系统的部署。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>企业投资与市场动态</strong>：</p><ul><li>AI 成为企业投资的热点，尤其是「Magnificent Seven」（Meta、亚马逊、苹果、微软、谷歌、特斯拉和英伟达）等科技巨头在股市中表现突出。</li><li>私人投资在生成性 AI 领域达到历史新高。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>2024 年展望</strong>：</p><ul><li>报告提出了 2024 年值得关注的 AI 发展，包括全球 AI 治理的实质性影响、第三方红队测试的实践、国会是否能通过全面的 AI 立法等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>术语定义</strong>：</p><ul><li>报告最后提供了 2024 年关键 AI 术语的定义，如智能体、生成性 AI、大型语言模型（LLM）、自然语言处理（NLP）等。</li></ul></li></ol><p style="margin-left:0; margin-right:0">报告强调了 AI 技术的快速发展和其在各个领域的广泛应用，同时也指出了随之而来的监管挑战和国际合作的重要性。报告还提到了 AI 在军事应用、企业投资以及国际政策制定中的作用，以及对未来一年 AI 发展的预测和展望。</p></div><div><div><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本</em>）</strong></p></div></div></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 08:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281773</guid>
            <link>https://www.oschina.net/news/281773</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Open-Sora：开源 Sora 复现方案，成本降低 46%，序列扩充至近百万]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Colossal-AI 开源了完整的 Sora 复现架构方案 Open-Sora，声称可降低 46% 复现成本，并将模型训练输入序列长度扩充至 819K patches。</p><h2><strong>Sora 算法复现方案</strong></h2><p>在 Sora 的技术报告中，Sora 使用了一个视频压缩网络将各种尺寸的视频压缩成一个隐空间 (latent space) 的时空块序列 (a sequence of patial temporal patch)，然后使用了 Diffusion Transformer 进行去噪，最后进行解码生成视频。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f00afc0ec2f11a40cd894bf027b8730d85.png" referrerpolicy="no-referrer"></p><p>Open-Sora 将 Sora 可能使用的训练 pipeline 归纳为下图。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e8f00fbfc988a866c34ebecf3e2bf47c561.png" referrerpolicy="no-referrer"></p><p>目前 Open-Sora 已涵盖：</p><ul><li><p>提供<strong>完整的 Sora 复现架构方案</strong>，包含从数据处理到训练推理全流程。</p></li><li><p>支持<strong>动态分辨率</strong>，训练时可直接训练任意分辨率的视频，无需进行缩放。</p></li><li><p>支持<strong>多种模型结构</strong>。由于 Sora 实际模型结构未知，我们实现了 adaLN-zero、cross attention、in-context conditioning(token concat) 等三种常见的多模态模型结构。</p></li><li><p>支持<strong>多种视频压缩方法</strong>。用户可自行选择使用原始视频、VQVAE（视频原生的模型）、SD-VAE（图像原生的模型）进行训练。</p></li><li><p>支持<strong>多种<strong><strong>并行</strong></strong>训练优化</strong>。包括结合 Colossal-AI 的 AI 大模型系统优化能力，及 Ulysses 和 FastSeq 的混合序列并行。</p></li></ul><h2>性能</h2><p>以在单台 H800 SXM 8*80GB GPU 上使用 DiT-XL/2 模型的性能测试为例。在 600K 的序列长度时，Open-Sora 的方案比基线方案有<strong>40%<strong><strong>以上</strong></strong>的性能提升和成本降低</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25ab5d8374c10bc5678d1da4ec093be7aa4.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-da251590ba84c47683092b37c9ad6f1896c.png" referrerpolicy="no-referrer"></p><p>Open-Sora 开源地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FOpen-Sora" target="_blank">https://github.com/hpcaitech/Open-Sora</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 06:14:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281739</guid>
            <link>https://www.oschina.net/news/281739</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软将 CBL-Mariner Linux 重命名为 Azure Linux]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">微软内部用于各种用途的 Linux 发行版曾被称为 CBL-Mariner，意为"Common Base Linux"，而现在似乎正在向 Azure Linux 过渡。</span></p><p><span style="color:#000000">Azure Linux 是从 CBL-Mariner 演化而来的，但注意不要将其与微软基于 Linux 的 Azure Sphere 操作系统混淆，后者是物联网/微控制器的使用平台。</span></p><p><span style="color:#000000"><img alt="" height="333" src="https://oscimg.oschina.net/oscnet/up-bcba0fe512236d7141e4845b2311f73e148.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">随着 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazurelinux%2Freleases%2Ftag%2F2.0.20240301-2.0" target="_blank">CBL-Mariner 2.0.20240301</a> 的发布，该项目现在已重定向到 GitHub 上的 Microsoft/AzureLinux 项目。CBL-Mariner 存储库已更名为"AzureLinux"，其他对 CBL-Mariner 的引用也已过渡到 Azure Linux 品牌，但仍保留了一些 CBL-Mariner 标记。</span></p><p><span style="color:#000000">在新发布的 v2.0.20240301 版本中，还有一些源代码更新<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazurelinux%2Fpull%2F7664%2Ffiles" target="_blank">开始重命名工件</a>，例如 Azure Linux 从"MARINER_VERSION"更名为"AZL_VERSION"。</span></p><p><span style="color:#000000">微软是否会更好地公开定位其内部 Linux 平台，或者 Azure Linux 还会有哪些其他变化，值得进一步的探究。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 06:13:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281738/microsoft-cbl-mariner-azure-linux</guid>
            <link>https://www.oschina.net/news/281738/microsoft-cbl-mariner-azure-linux</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[mybatis-mp - 亮点七：枚举的良好支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>mybatis-mp gitee 地址：<a href="https://gitee.com/mybatis-mp">https://gitee.com/mybatis-mp</a></h1><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">日常开发中，枚举的存储一般以 name 或，自定义 code，存放到数据库；一般的框架都不支持直接以枚举作为直接参数，需要开发者自行处理</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">mybatis-mp 为你提供了方便：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">1：普通枚举（以 name 作为存储）：直接继承&nbsp;<span style="color:#000000">Serializable 类型即可</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">2：自定义 code 的枚举，继承&nbsp;EnumSupport 类；如下：</span></p><div><pre><span style="color:#0033b3">public enum </span><span style="color:#000000">TestEnum </span><span style="color:#0033b3">implements </span><span style="color:#000000">EnumSupport</span>&lt;<span style="color:#000000">String</span>&gt; {

    <em>X1</em>(<span style="color:#067d17">"a1"</span>),<em>X2</em>(<span style="color:#067d17">"a2"</span>);

    <span style="color:#00627a">TestEnum</span>(<span style="color:#000000">String code</span>){
        <span style="color:#0033b3">this</span>.<span style="color:#871094">code</span>=<span style="color:#000000">code</span>;
    }

    <span style="color:#0033b3">private final </span><span style="color:#000000">String </span><span style="color:#871094">code</span>;

    <span style="color:#9e880d">@Override
</span><span style="color:#9e880d"></span><span style="color:#0033b3">public </span><span style="color:#000000">String </span><span style="color:#00627a">getCode</span>() {
        <span style="color:#0033b3">return this</span>.<span style="color:#871094">code</span>;
    }
}</pre></div><p>3：如何在 mybatis-mp 中直接使用枚举进行 CRUD</p><p>&nbsp;&nbsp;&nbsp;&nbsp;3.1：实体类中：列字段可直接是枚举</p><p>&nbsp; &nbsp; 3.2：CRUD 参数中，直接可用枚举，和普通 string int long 类型无差别使用;如下：</p><div><pre><span style="color:#000000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;QueryChain</span>.<em>of</em>(<span style="color:#000000">mapper</span>)
      &nbsp;&nbsp;&nbsp;&nbsp;.in(<span style="color:#000000">Student</span>::getType,<span style="color:#000000">Arrays</span>.<em>asList</em>(<span style="color:#000000">TestEnum</span>.<em>X1</em>,<span style="color:#000000">TestEnum</span>.<em>X2</em>)).list();
</pre></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 06:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281737</guid>
            <link>https://www.oschina.net/news/281737</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[有道 QAnything 背后的故事 --- 关于 RAG 的一点经验分享]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，我们开源了有道自研的 RAG（Retrieval Augmented Generation) 引擎 QAnything。该引擎允许用户上传 PDF、图片、Word、Excel、PowerPoint 等多种格式的文档，并实现类似于 ChatGPT 的互动问答功能，其中每个答案都能精确追溯到相应的文档段落来源。QAnything 支持纯本地部署，上传文档数量无上限，问答准确率高。</p><p>QAnything 自开源以来，迅速吸引了开发者社区的广泛关注，并很快登上了 GitHub trending 榜单。短短一个月内，下载次数已达数万次，其中，我们的语义嵌入排序模型 BCEmbedding 更是达到了惊人的 60 万次下载。根据社区的热情反馈，我们决定分享 QAnything 背后的研发故事、技术路线选择以及我们的经验，希望能够为社区带来启发。</p><p><strong>QAnything 的起源</strong></p><p>与市场上的其他 Retrieval Augmented Generation (RAG) 产品相比，QAnything 引擎的研发轨迹略显不同。它不是一开始就被设定为一个具体的项目目标，而是在项目进展中，通过不断的探索和实践，逐步成形的。这个过程虽然经历了一些波折，但正是这些经历，让我们在 RAG 领域积累了丰富的实践经验。</p><p><strong>从文档翻译到文档问答</strong></p><p>QAnything 的研发团队最初专注于文档翻译。2022 年我们启动了一个为期一年的文档翻译的升级的项目，到 2023 年 3 月份上线，效果提升显著。正好那时候 ChatGPT 和类似技术正在兴起，我们意识到这正是将我们现有技术扩展至文档问答的绝佳时机。因此，我们毫不犹豫地为我们的文档翻译服务增添了问答功能，该功能能够根据文档内容自动推荐问题并提供答案，于 5 月份正式推出。</p><p><img alt="" height="381" src="https://oscimg.oschina.net/oscnet/up-f997fd94e09af0d0e75e09aa1f1778b3dd5.png" width="676" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#303030">(视频链接：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fwww.bilibili.com%252Fvideo%252FBV1fw4m1Z7QX%252F" rel="nofollow" target="_blank"><span style="color:#3db24b !important">https://www.bilibili.com/video/BV1fw4m1Z7QX/</span></a><span style="background-color:#ffffff; color:#303030">）</span></p><p>之所以能够轻松地扩展到文档问答，是因为有道在文档翻译领域的深厚积累。我们的文档翻译服务因其卓越的性能而闻名，这主要得益于两大核心技术：先进的翻译引擎和精准的文档解析/OCR 技术。多年来，在翻译和 OCR 领域的持续探索和创新，为我们构建 Retrieval Augmented Generation (RAG) 系统提供了坚实的基础。</p><p>首先，核心技术方面，我们的翻译模型基于 Transformer 架构，这与当前研究领域的大型语言模型（LLM）紧密相连，实质上并无显著区别。所谓 LLM，就是很大的 Transformer 模型，就是我们天天在研究的东西。ChatGPT 出来后，我们之所以能迅速掌握并扩展我们的模型，例如开发了针对教育场景的「子曰」大模型，这一切都得益于我们对 Transformer 模型的深入理解和应用。</p><p>接着，关于 RAG 系统，它不仅仅是外部数据和 LLM 的简单叠加。鉴于用户文档的多样性，特别是 PDF 文件中复杂的图文混排，仅仅提取文本往往会带来信息的失真。例如，将具有逻辑连贯性的文本分割成多个片段，或者将图表数据错误地融入文本，这些都会严重影响信息的准确性。正因如此，我们长期致力于文档解析技术的研发，能够精确地识别和分析文档中的每一部分，无论是段落、图表、公式还是其他元素，确保将用户的查询以最适合机器处理的方式进行组织和检索。</p><p>借助有道翻译庞大的用户基础，我们得以在实际应用中不断完善和优化我们的系统。日均活跃用户数达百万级别的大数据反馈，为我们提供了宝贵的实践经验，使我们能够持续提升系统性能，满足用户对高质量翻译和问答服务的需求。</p><p><br><strong>从文档问答到速读</strong></p><p>有道速读 ([https://read.youdao.com](https://read.youdao.com/)) 是我们算法研究员从自己的需求出发做的产品。有道翻译桌面端虽然已经上线了文档问答，但是它主要是面向大众设计的，适合通用的文档。我们经常读论文，希望有一些论文相关的更个性一点的功能。而有道翻译用户量太大了，不方便随意改动。</p><p><br> 我们做有道速读，一开始主要是面向论文阅读做的。这也是我们新技术的试验田，迭代快一点。我们看到了 wordtune 出了个段落摘要和对照的功能，用着特别爽，但是很贵，我们就把那个功能与 RAG 整合在一起，又能摘要读段落，又能问答，方便溯源。论文一般都会讲自己方法多好，我们就把其他人对这篇论文的评价信息也给整合起来了，做了论文口碑，把一篇论文的优势和局限更客观的展示出来。在内部做研发的过程中，有个研究人员希望能自动写综述，我们就在速读上加上了自动综述的功能，对每一篇论文，把前后引用的论文全部抓来，自动做问答，然后整理成报告。</p><p>有道速读可以看作是 RAG 在某个垂直领域的应用。因为里面的口碑、综述、文章解读等功能，都可以认为是先设置一个模版，有一堆问题（或者自动生成的），然后通过自问自答的方式，生成关键信息，最后再总结润色成文，这一切过程都是全自动的。</p><p>速读给了我们一个训练场，让我们调试应用新技术，这个过程也学到了很多，团队进步很大。当然，速读现在也不只局限于论文阅读了。</p><p><img alt="" height="801" src="https://oscimg.oschina.net/oscnet/up-6f955fec46dcbc86a2e0a7cca2c0797fac3.png" width="1280" referrerpolicy="no-referrer"></p><p><strong>从速读到 Qanything</strong></p><p>速读主要是单篇问答（6 月份刚上线时候只支持单篇，现在也支持多篇问答了，和 QAnything 主要区别是速读更偏重阅读的场景，QAnything 偏重问答的场景，底层引擎是一样的），且只支持 pdf 的格式。QAnything 是支持多文档问答的，不限文档格式。</p><p>做 Qanything 有个契机。去年 7 月份的时候，网易的 IT 集团想升级他们的客服系统，找到我们，问能否基于他们的 IT 文档做一个自动问答机器人，因为他们看到了我们的文档问答效果，觉得做的不错。于是我们就拿着他们的文档和历史的问答数据快速实验了一下，发现经过我们的系统后，70% 的转人工的次数都可以被省下来，由 AI 来回答。</p><p>客服这个场景，用户的文档格式非常多样，回答问题需要综合各种文档的内容。于是我们在这个场景需求的推动下，做了多文档问答。我们给这个多文档问答系统取了一个大气的名字，叫 Qanything，中文名字叫「万物皆可问」。</p><p>QAnything，也是我们的愿景。QAnything 的前两个字母是 Q 和 A，也是问答的意思，后面是 anything，希望什么都可以放进去，什么东西都可以提问。</p><p>在去年 8 月份的时候，除了内部客户要，有道智云的外部 B 端客户也需要这样的多文档问答系统，还需要私有化。于是我们就做了大模型的小型化适配，做了私有化的版本，可以直接跑在游戏本上的。整个系统是完整的，可直接使用，也可以通过 API 调用。给了客户，卖了点钱。</p><p><img alt="" height="379" src="https://oscimg.oschina.net/oscnet/up-db8c48d9e609a5a09c0233eef0aeced2c29.png" width="676" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#303030">（视频链接：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fwww.bilibili.com%252Fvideo%252FBV1FC411s7gQ%252F" rel="nofollow" target="_blank">https://www.bilibili.com/video/BV1FC411s7gQ/</a><span style="background-color:#ffffff; color:#303030">）</span></p><p><strong>从 QAanyhing 到升学咨询</strong><br> &nbsp;<br> 我们一直将 qanything 的体验页挂在网上，主要是为了做，有道智云 toB 生意的时候给外部用户体验的，也没怎么宣传。去年 9 月份的时候，突然有一天，我们的精品课事业部（有道领世）的人找上门来，说希望合作 QAnything。原来，他们不知道通过哪里的渠道知道了我们的 QAnything，去体验了下，发现效果很好。比他们自己用 langchain/lamma index+chatgpt 搭建了很久的系统，效果要好很多。</p><p>有道领世在高中升学领域深耕多年，积累了海量的升学数据资料，有几万份的文档，还有大量的数据存储在数据库里。我们的任务是通过 QAnything，结合这样的积累的数据，打造出一个私人 AI 规划师，针对每个家长和学生，提供个性化、更加全面、专业、及时的升学规划服务。</p><p>一开始，我们把全部数据直接塞入我们 QAnything 系统，升学百科问答只有 45% 的准确率。经过一段时间的反复迭代优化，我们把确确率提升到了 95%。目前系统可以解答用户关于高考政策、升学路径、学习生活以及职业规划等各种问题。未来随着不断地数据补充和更新，准确率会一直上涨。</p><p>有道 AI 升学规划师产品做出来后，我们都为它的体验感到惊艳。</p><p><img alt="" height="505" src="https://oscimg.oschina.net/oscnet/up-f77f7ac44e748438e8d3638886acd511458.png" width="674" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#303030">（视频链接：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fwww.bilibili.com%252Fvideo%252FBV1Bt421b7am%252F" rel="nofollow" target="_blank">https://www.bilibili.com/video/BV1Bt421b7am/</a><span style="background-color:#ffffff; color:#303030">）</span></p><p><br><strong>Qanything 开源</strong></p><p>今年 1 月份，我们整理了下我们的 QAnything 的代码和模型，将适合开源的部分开放出来了。我们做这事，希望能和社区一起，共同推动 RAG 技术应用的发展。最近这个月，社区给了我们很对反馈，也让我们受益良多。</p><p>QAnything 架构解析</p><p>这次开源包括了模型和系统等所有必要的模块。模型方面包括 ocr 解析、embedding/rerank，以及大模型。系统方面包括向量数据库、mysql 数据库、前端、后端等必要的模块。整个引擎的功能完整，用户可以直接下载，不需要再搭配其他的模块即可使用。系统可扩展性也非常好，只要硬盘内存足够，就可以一直建库，支持无上限的文档。<br><img alt="" height="1016" src="https://oscimg.oschina.net/oscnet/up-e97bf7c2bc4e2b7c629959740e9a816df26.png" width="1146" referrerpolicy="no-referrer"></p><p>系统的工作流程主要包含三个环节：</p><p>- &nbsp; 索引（indexing）：文本索引的构建包括以下步骤：文档解析、文本分块、Embedding 向量化和创建索引。先将不同格式的原始文件解析转换为纯文本，再把文本切分成较小的文本块。通过 Embedding 为每一个文本块生成一个向量表示，用于计算文本向量和问题向量之间的相似度。创建索引将原始文本块和 Embedding 向量以键值对的形式存储，以便将来进行快速和频繁的搜索。<br> - &nbsp; 检索（Retrieval）：使用 Embedding 模型将用户输入问题转换为向量，计算问题的 Embedding 向量和语料库中文本块 Embedding 向量之间的相似度，选择相似度最高的前 K 个文档块作为当前问题的增强上下文信息。<br> - &nbsp; 生成（Generation）：将检索得到的前 K 个文本块和用户问题一起送进大模型，让大模型基于给定的文本块来回答用户的问题。</p><p><br><strong>Bcembedding 模型</strong></p><p>Embedding 是 RAG 系统里面最关键的模块。为啥要自己训练 embedding 模型？一开始我们也是直接去尝试 openai 的 ada embedding 以及开源的 embedding 模型。但是我们很快发现，这样做有很大弊端。首先，在我们的业务场景下，外部的 embedding 效果并不如宣传的那么好。openai 的 embedding 接口除了效果不好外，还很慢。我们后来自研了 embedding，因为是放在自己服务器上，调用起来比 openai 接口快一百倍。其次，很多开源的 embedding 模型在 mteb 等地方刷傍刷的很高，但是那些刷榜的分值并不完全能反映真实的效果。第三，我们业务场景有很多混合语言的情况，比如库里面放的是英文的文档，用户用中文去问答。这种跨语种的能力，现有模型支持不好。第四，单纯的 embedding 在检索排序上天花板比较低，所以我们在 embedding 的基础上又做了 rerank，共享同样的底座，head 不一样。</p><p>为啥我们自己训练的模型会比 openai 的效果好？我们认为可能是通才和专才的区别。openai 是通才，但是它的效果远未达到万能的地步，大家不必迷信。在我们的场景下 (客服问答以及一些 toB 客户的场景），openai 的 ada2 embedding 的检索准确率只有 60%，而经过训练的 bcembedding 检索准确率可以达到 95%。</p><p>我们自研的[BCEmbedding](https://github.com/netease-youdao/BCEmbedding)，总的来讲有两个特色：</p><p>- &nbsp; 中英双语和跨语种能力</p><p>我们收集开源数据集（包括摘要、翻译、语义改写、问答等），来实现模型通用的基础语义表征能力。为了实现一个模型就可以实现中英双语、跨语种的检索任务，我们依赖网易有道多年积累的强大的翻译引擎，对数据进行处理，获得中英双语和跨语种数据集。实现一个模型就可以完成双语和跨语种任务。</p><p>- &nbsp; 多领域覆盖</p><p>我们分析现有市面上常见或可能的应用场景，收集了包括：教育、医疗、法律、金融、百科、科研论文、客服 (faq)、通用 QA 等场景的语料，使得模型可以覆盖尽可能多的应用场景。同样的依靠网易有道翻译引擎，获得多领域覆盖的中英双语和跨语种数据集。实现一个模型就可以支持多业务场景，用户可以开箱即用。 &nbsp;<br> 我们在训练的过程中，发现一个有意思的现象，数据标签的构建对模型的效果影响非常大。相信大家一定听过「难例挖掘」的概念，在机器学习中模型性能上不去时候，经常是因为一些例子比较难，模型训练时候见的比较少，多挖掘一些难例给模型，就能够提升模型的性能。但是在 embedding 训练的时候，我们发现难例挖掘反而会降低模型的性能。我们猜测原因是 embedding 模型本身的能力有限，不应该给过难的任务。我们想要让模型做多领域覆盖，多语种、跨语种覆盖（还要覆盖代码检索和工具检索），这已经给 Embedding 增加很多负担了，应该想想怎么给 Embedding「减负」。</p><p>因为 Embedding 模型是 dual-encoder，query 和 passage 在「离线」地语义向量提取时没有信息交互，全靠模型将 query 和 passages「硬」编码到语义空间中，再去语义检索。而 rerank 的阶段，cross-encoder 可以充分交互 query 和 passage 信息，潜力大的多。所以我们定了目标，embedding 尽可能提高召回，rerank 尽可能提高精度。</p><p>我们在 Embedding 模型训练中，不使用难负样例挖掘，只在 Reranker 中使用。以下是我们的几点看法，供参考。</p><p>1. &nbsp;我们在训练 Embedding 模型时发现，过难的负样本对模型训练有损害，训练过程中会使模型「困惑」，影响模型最终性能[19]。Embedding 模型算法本身性能上限有限，很多难负样本只有细微差异，「相似」程度很高。就像让一个小学生强行去学习微积分，这种数据对 Embedding 训练是「有毒」的。<br> 1. &nbsp;在大量的语料库中，没有人工校验的自动化难负样例挖掘，难免会「挖到正例」。语料库很大，里面经常会混有正例，利用已有 Embedding 模型去挖掘正例，经常会挖到正例，毒害模型训练。应该有不少调参工程师有这种惨痛经历。<br> 1. &nbsp;其实所谓的「正例」和「难负样例」应该是根据你业务的定义来的。RAG 场景下，之前人们认为的难负样例可能就成为了正例。比如要回答「小明喜欢吃苹果吗？」，RAG 场景下召回「小明喜欢吃苹果」和「小明不喜欢吃苹果」都是符合目标的，而学术定义的语义相似这两句话又是难负样例。</p><p>所以回归我们业务目标和好检索器的「评判标准」，Embedding 模型应该能尽量召回相关片段，不要将精排 Reranker 要干的事强压在 Embedding 身上，「越俎代庖」终究会害了它。</p><p>检索排序效果**评测方式**LlamaIndex（https://github.com/run-llama/llama_index）是一个著名的大模型应用的开源框架，在 RAG 社区中很受欢迎。最近，LlamaIndex 博客（https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83）对市面上常用的 embedding 和 reranker 模型进行 RAG 流程的评测，吸引广泛关注。</p><p>为了公平起见，我们复刻 LlamaIndex 博客评测流程，将 bce-embedding-base_v1 和 bce-reranker-base_v1 与其他 Embedding 和 Reranker 模型进行对比分析。在此，我们先明确一些情况，LlamaIndex 博客（https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83）的评测只使用了 llama v2（https://arxiv.org/abs/2307.09288）这一篇英文论文来进行评测的，所以该评测是在纯英文、限定语种（英文）、限定领域（人工智能）场景下进行的。<br><img alt="" height="832" src="https://oscimg.oschina.net/oscnet/up-5f9db64da828a15a1df04e374a64f33307f.png" width="1280" referrerpolicy="no-referrer"></p><p>如上表所示，</p><p>- &nbsp; 在没有 Reranker 模块的设置下，bce-embedding-base_v1 显著优于其他常见的开源和闭源英文 embedding 模型。<br> - &nbsp; 在相同 reranker 配置下（竖排对比），bce-embedding-base_v1 也都是优于其他开源、闭源 embedding 模型。<br> - &nbsp; 在相同的 embedding 配置下（横排对比），利用 reranker 模型可以显著提升检索效果，印证前面所述二阶段检索的优势。bce-reranker-base_v1 比其他常见的开源、闭源 reranker 模型具备更好的精排能力。<br> - &nbsp; 综上，bce-embedding-base_v1 和 bce-reranker-base_v1 的组合可以实现最好的效果。</p><p>多领域、多语种和跨语种 RAG 效果正如上所述的 LlamaIndex 博客（https://huggingface.co/datasets/maidalun1020/CrosslingualMultiDomainsDataset）评测有些局限，为了兼容更真实更广的用户使用场景，评测算法模型的，领域泛化性，双语和跨语种能力，我们按照该博客的方法构建了一个多领域（计算机科学，物理学，生物学，经济学，数学，量化金融等领域）的中英双语种和中英跨语种评测数据，CrosslingualMultiDomainsDataset（https://huggingface.co/datasets/maidalun1020/CrosslingualMultiDomainsDataset）。</p><p>为了使我们这个数据集质量尽可能高，我们采用 OpenAI 的 gpt-4-1106-preview 用于数据生成。为了防止数据泄漏，评测用的英文数据我们选择了 ArXiv 上 2023 年 12 月 30 日最新的各领域英文文章；中文数据选择 Semantic Scholar 相应领域高质量的尽可能新的中文文章。<br><img alt="" height="661" src="https://oscimg.oschina.net/oscnet/up-10bf37226f5b2453ffbbe931fa45b495af1.jpg" width="1280" referrerpolicy="no-referrer"><br> 我们针对市面上最强的常用开源、闭源 embedding 和 reranker 模型，进行系统性评测分析，结果如上图所示。</p><p>- &nbsp; 竖排对比，bce-embedding-base_v1 的表现和之前一样，具备很好的效果，语种支持和领域覆盖都很不错。最新的 openai-embed-3 和 bge-m3 表现出顽强的性能，具备良好的多语种和跨语种能力，具备良好的领域泛化性。Cohere 和 e5 的多语种 embedding 模型同样表现出不错的效果。而其他单语种 embedding 模型表现却不尽如人意（JinaAI-v2-Base-zh 和 bge-large-zh-v1.5 稍好一些）。</p><p>- &nbsp; 横排对比，reranker 模块可以显著改善检索效果。其中 CohereRerank 和 bge-reranker-large 效果相当，bce-reranker-base_v1 具备比前二者更好的精排能力。</p><p>- &nbsp; 综上，bce-embedding-base_v1 和 bce-reranker-base_v1 的组合可以实现最好的检索效果（93.46/77.02），比其他开源闭源最好组合（bge-m3-large+bge-reranker-large， 89.94/70.17），hit rate 提升 3.53%，mrr 提升 6.85%。</p><p><br><strong>Rerank 的必要性</strong></p><p>为啥需要 rerank，上面数字可能还不直观。我们在开源的 github 上放了一张图，意思是 QAnything 在知识库的数据越多，准确率越高。而一般搭建的 RAG，如果没有 rerank 这一环节，在数据输入多了以后，效果反而下降了。<br><img alt="" height="776" src="https://oscimg.oschina.net/oscnet/up-72860571cf331d8baaf1fe6c6d6a32aff62.jpg" width="1235" referrerpolicy="no-referrer"><br> 我们在做升学问答的时候，遇到一个有趣的现象：我们分批往 RAG 知识库中灌入数据，每加一批数据都做一次评测，观察随着数据量变大，问答效果的变化情况：</p><p>- &nbsp; baseline：第一批数据加入后问答正确率有 42.6%，此时有一些问题没回答上来是因为确实缺少相关资料。我们继续加数据…<br> - &nbsp; 迎来上涨：第二批加了更多数据，覆盖知识范围更广。准确率提升到了 60.2%，提升非常明显，看来加数据确实还是挺有用的。<br> - &nbsp; 坏消息：当加入第三批数据的时候，我们最担心的事情还是发生了。正确率急剧下降，跌了将近 8 个百分点。</p><p><img alt="" height="591" src="https://oscimg.oschina.net/oscnet/up-8319017eaecc4989a5540acd83a2c9bbc3c.png" width="1280" referrerpolicy="no-referrer"></p><p>不是所的 RAG 系统都能保证：数据越多，效果越好。随着数据的增多，数据之间可能会有相互干扰，导致检索退化的问题，影响问答的质量。</p><p>这个现象在最近的一篇论文：The Power of Noise: Redefining Retrieval for RAG Systems （arXiv:2401.14887v2）也有一些解释，对于 RAG 系统，如果喂给大模型的输入是相近容易混淆的话，对正确性的影响是最大的。</p><p>&nbsp;以我们遇到的一个 case 为例，大连医科大学怎么样？这个问题在 v2 版本（加入第三批数据前）是能回答对的，v3 版本（加入第三批数据后）回答错了。看了一下送到 LLM 的文本片段，居然全部都是大连理工大学相关的信息。<br><img alt="" height="750" src="https://oscimg.oschina.net/oscnet/up-bf69d543bfb43367e7dda1a555252c893fe.png" width="952" referrerpolicy="no-referrer"></p><p>主要原因是第三批加入的某些文档中恰好有 "大连理工大学 xxx 怎么样？" 的句子，和 query "大连医科大学怎么样？" 表面上看起来确实非常像，Embedding 给它打了比较高的分。</p><p>而类似大连医科大学师资介绍这样的片段相关性就稍微低了些。LLM 输入 token 有限制，前面两个最相关但是实际并不能回答 query 问题的片段就已经占满了 token 的窗口，只能把他俩送进 LLM 里。结果可想而知，啥都不知道。</p><p>文本片段与 query 的相似性和文本片段是否包含 query 的答案（相关性）是两回事。RAG 中一个非常重要的矛盾点在于检索召回的片段比较多，但是 LLM 输入 token 是有限制，所以必须把能回答 query 问题的片段（和问题最相关）给 LLM。 Embedding 可以给出一个得分，但是这个得分描述的更多的是相似性。Embedding 本质上是一个双编码器，两个文本在模型内部没有任何信息交互。只在最后计算两个向量的余弦相似度时才进行唯一一次交互。所以 Embedding 检索只能把最相似的文本片段给你，没有能力来判断候选文本和 query 之间的相关性。但是相似又不等于相关。&nbsp;</p><p>如下图所示，从某种程度上，Embedding 其实就是在算两个文本块中相似字符的个数占比，它分不清 query 中的重点是大连医科大学，在它看来每个字符的重要性都是一样的。感兴趣的话可以计算一下下图中红字部分的占比，和最后余弦相似度的得分基本是吻合的。<br><img alt="" height="662" src="https://oscimg.oschina.net/oscnet/up-e03af7dedb9142ae03fae273c1f835b55e1.png" width="1240" referrerpolicy="no-referrer"><br> Rerank 本质是一个 Cross-Encoder 的模型。Cross-Encoder 能让两个文本片段一开始就在 BERT 模型各层中通过 self-attention 进行交互。它能够用 self-attention 判断出来这 query 中的重点在于大连医科大学，而不是怎么样？所以，如下图所示，大连医科大学怎么样？这个 query 和大连医科大学创建于 1947 年…更相关。<br><img alt="" height="517" src="https://oscimg.oschina.net/oscnet/up-d1e3389e4d05a523535c92a8547bd1b39da.png" width="1240" referrerpolicy="no-referrer"></p><p>加上两阶段检索后，重新跑一下实验：<br><img alt="" height="488" src="https://oscimg.oschina.net/oscnet/up-5ed99ad8f15fe754f53ea8b2d3672258b98.png" width="1280" referrerpolicy="no-referrer"><br> 在数据不变的情况，两阶段检索问答准确率从 52.8% 提升到 65.9%，这个结果再次证明了一阶段检索中存在数据互相干扰的情况。两阶段检索可以最大化的挖掘出数据的潜力，我们继续加数据，效果能够稳定提升。如下图所示，两阶段检索最大的意义不是在某一个实验上面提升了 10 个点。它最大的意义在于让「数据越多，效果越好」变成了现实。 在实际使用中，因为 rerank 比 embedding 慢得多，所以一般用两阶段检索。速度慢不是 cross-encoder 的模型比 bi-encoder 的模型速度慢。关键在于，bi-encoder 可以离线计算海量文本块的向量化表示，把它们暂存在向量数据库中，在问答检索的时候只需要计算一个 query 的向量化表示就可以了。拿着 query 的向量表示去库里找最相似的文本即可。但是 cross-encoder 需要实时计算两个文本块的相关度，如果候选文本有几万条，每一条都需要和 query 一起送进 BERT 模型中算一遍，需要实时算几万次。这个成本是非常巨大的。所以，我们可以把检索过程分为两个阶段：召回（粗排）和重排:</p><p>- &nbsp; 第一个阶段的目标是尽可能多的召回相似的文本片段，这个阶段的文本得分排序不是特别靠谱，所以候选的 topK 可以设置大一些，比如 topK=100；<br> - &nbsp; 第二个阶段的目标是对 100 个粗排的候选文本片段进行重新排序，用 cross-encoder 计算 100 个候选文本和 query 的相关度得分；<br> 两阶段检索结合可以兼顾效果和效率。</p><p><br><strong>LLM 模型微调</strong></p><p>我们的开源项目 QAnything 引入了一款 7B 参数规模的大型语言模型 Qwen-7B-QAnything，该模型是在 Qwen-7B 基础上，通过使用我们团队精心构建的中英文高质量指令数据进行微调得到的。随着开源大型语言模型（LLM）基座模型的能力不断增强，我们通过在这些优秀的基座模型上进行后续训练，包括继续预训练、指令微调（SFT）和偏好对齐等工作，以更有效地满足 RAG 应用对大模型的特定需求，从而实现高性价比的模型优化。</p><p>为什么要微调？</p><p>RAG 技术结合了知识检索与生成模型，通过从外部知识源检索信息，并将这些信息与用户问题整合成完整的 Prompt 输入到大模型中，以便根据这些参考信息回答问题。然而，当面对含有专业术语或通俗缩写的开放性问题时，**直接使用开源 Chat 模型可能会导致模型回答不准确。** 此外，为了最大化利用大模型的上下文窗口，RAG 应用倾向于保留尽可能多的检索信息，这可能会使得模型的注意力分散，降低其遵循指令的能力，进而引发回答中的重复内容、关键信息丢失等问题。为了提高大模型在参考信息不足时的诚实度，加入与用户问题关联度低的负样本进行微调训练变得必要。</p><p>在选择基座模型时，我们寻找能够支持中英文、至少具备 4K 上下文窗口的模型，且能在单块 GPU 上部署，优先考虑 7B 以下参数规模的模型以便于未来在消费级硬件上部署。Qwen-7B，一个阿里云研发的 70 亿参数的通用大模型，以其在多个基准测试中的卓越表现成为我们的选择。该模型通过在超过 2.4 万亿 tokens 的数据上预训练，包含了丰富的中英文、多语言、编程、数学等领域数据，确保了广泛的覆盖面。考虑到 7B 参数规模的限制，我们在指令微调时采用了结构化指令模板，以增强模型在实际应用中的指令遵循能力。<br><img alt="" height="522" src="https://oscimg.oschina.net/oscnet/up-2d3d3662175b7c878cee7ead4d0fbfabf5d.png" width="1280" referrerpolicy="no-referrer"></p><p>如何微调？&nbsp;</p><p><strong>1. 指令微调数据构造</strong></p><p>我们为 Qwen-7B-QAnything 模型构造了丰富的指令微调数据集，涵盖了多种类型的数据，包括基于参考信息的结构化问答数据（单文档/多文档的事实问答、多文档的归纳总结/推理类问答、信息抽取）、多轮对话查询重写、段落摘要、开放域问答、中英文翻译以及跨学科问答等。<br> &nbsp;<br><strong>2. 指令微调模型训练</strong></p><p>尽管与大模型的预训练相比，指令微调成本较低，但在微调数据不完整或比例不平衡的初期探索阶段，采用全参数微调的代价依然较高。为了尽可能降低实验成本并快速验证微调效果，我们首先采用 LoRA 方法进行微调探索，待实验条件稳定后，再转向全参数微调。我们的 LoRA 微调配置如下：使用 8 张 A40 显卡的单机环境，初始学习率设为 3e-5，每张卡的批量大小为 2，采用 16 步的梯度累积，同时利用 bfloat16 精度训练以避免溢出并增强稳定性。此外，我们采用 QLoRA + DeepSpeed Zero2 + FlashAttention 配置以节约训练所需的显存。QLoRA 通过 4 比特量化技术压缩预训练语言模型，使用 NormalFloat4 数据类型存储基模型权重，冻结基模型参数，并以低秩适配器（LoRA 参数）形式添加少量可训练参数。在微调阶段，QLoRA 将权重从 NormalFloat4 数据类型反量化为 bfloat16 进行前向和后向传播，仅更新 bfloat16 格式的 LoRA 参数权重梯度。与 LoRA 原论文不同，针对指令微调数据规模达到百万级别的情况，我们在所有线性层添加低秩适配器，并发现增加 lora_rank 和 lora_alpha 参数能显著提升微调效果。因此，我们为 Qwen-7B 模型微调采取了特定的 LoRA 参数配置，以实现最佳效果。<br><img alt="" height="208" src="https://oscimg.oschina.net/oscnet/up-c858a0c049064dc4013ed8f4baa1752ba72.png" width="1280" referrerpolicy="no-referrer"><br> 3. 指令微调模型问答效果评估</p><p>我们参考了这篇文章：Benchmarking Large Language Models in Retrieval-Augmented Generation，使用开源 Benchmark 的事实型文档问答测试集，对微调过后的 LLM 做质量评估。中、英文测试集分别包含 300 条，Context Noise Ratio （0～0.8）表示 LLM 输入 Context 中不相关噪声片段的比例。回答准确率指标结果说明：Qwen-7B-Chat (QwenLM 2023) 表示论文中的结果，[Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat) 表示使用开源 Chat 模型和结构化指令模版的结果，Qwen-7B-QAnything 表示 QAnything 开源项目微调模型的结果。模型评估时使用了 top_p 采样。结果表明 Qwen-7B-QAnything 对检索外部知识源包含不相关信息的鲁棒性更好。<br><img alt="" height="354" src="https://oscimg.oschina.net/oscnet/up-ed9e217a1a740f3ce947701f20f6d010c7e.png" width="1080" referrerpolicy="no-referrer"></p><p><img alt="" height="386" src="https://oscimg.oschina.net/oscnet/up-843d77dce42bf3ef921d246f501de5dd78e.png" width="1280" referrerpolicy="no-referrer"><br> 公开数据集的 benchmark 的评测结果</p><p>此外，团队内部针对业务场景构造 700 条问答对作为评测集，覆盖多种文档类型和问题，其中相关参考信息由 BCE Embedding 和 Rerank 模型检索重排序得到，参考答案由 GPT4 生成，结合人工修正得到。结合 Ragas 评测框架实现对 LLM 的自动化评测。评测指标采用 [answer_correctness],通过计算 LLM 回答内容 answer 和参考答案的 factual correctness 和 semantic similarity 加权和得到，其中 factual correctness（权重系数 0.75）利用 GPT4 根据 answer 和参考答案生成 TP/FN/FP 表述计算得分，semantic similarity（权重系数 0.25）利用 BCE Embedding 计算 answer 和参考答案的语义相似度。以下是评测结果及部分示例。<br><img alt="" height="260" src="https://oscimg.oschina.net/oscnet/up-5361f664da82c8a631079da21799447d774.png" width="820" referrerpolicy="no-referrer"></p><p><strong>本地部署</strong></p><p>QAnything 开源项目为本地部署的大型语言模型（LLM）提供了三种推理框架后端选项：FasterTransformer、vLLM 和 Huggingface Transformers。这些选项满足了不同用户对于部署 LLM 的需求，实现了在高性能与通用性之间的平衡。</p><p>FasterTransformer (&lt;https://github.com/NVIDIA/FasterTransformer&gt;) 是由 NVIDIA 开源的一个高性能 LLM 推理框架，专为 NVIDIA GPU 优化。它的优点在于支持大型模型的 INT8-Weight-Only 推理，能在保持模型精度的同时减少推理延时和 GPU 显存使用，提高了在相同 GPU 配置下的多并发吞吐性能。FasterTransformer 的模型权重转换与具体 GPU 型号无关，提供了一定的部署灵活性，但需要 GPU 具备一定的计算能力（FP16 推理支持计算能力 7.0 及以上，INT8-Weight-Only 支持 7.5 及以上）。此外，FasterTransformer 作为 Triton Inference Server 的后端 (&lt;https://github.com/triton-inference-server/fastertransformer_backend&gt;) 实施 LLM 推理，支持 Linux/Windows 11 WSL2 部署。NVIDIA 还基于 FasterTransformer 和 TensorRT 开发了新的推理框架 TensorRT-LLM (&lt;https://github.com/NVIDIA/TensorRT-LLM&gt;)，进一步提高了推理性能，但这也意味着与 NVIDIA GPU 的绑定更紧密，牺牲了一定的灵活性和通用性。</p><p>vLLM (&lt;https://github.com/vllm-project/vllm&gt;) 是由 UC Berkeley LMSYS 团队开发的另一款高性能 LLM 推理框架，其利用 PagedAttention 技术优化 KV Cache 管理，并结合并行采样和连续批处理请求调度管理，支持 NVIDIA 和 AMD GPU，提高了系统吞吐性能。通过 Huggingface Transformers 训练的模型可以轻松部署为 Python 服务，展现出良好的系统灵活性。vLLM 通过 AWQ 和 GPTQ 等算法支持 INT4-Weight-Only 推理，节省显存同时减少推理延时，但可能会轻微影响模型精度和生成质量。QAnything 利用 FastChat (&lt;https://github.com/lm-sys/FastChat&gt;) 提供的接口使用 vLLM 后端，提供了兼容 OpenAI API 的调用接口，默认采用 bfloat16 推理，对 GPU 和算力有一定要求。</p><p>Huggingface Transformers (&lt;https://github.com/huggingface/transformers&gt;) 是由 Huggingface 团队开发的一个通用性强、灵活性高的 Transformer 模型库，与 PyTorch 等深度学习框架配合，支持模型训练和 Python 服务部署。虽然在多数情况下，其推理性能可能不及 FasterTransformer 和 vLLM，但它兼容不同算力等级的 GPU。QAnything 通过复用 FastChat(&lt;https://github.com/lm-sys/FastChat&gt;) 提供的接口使用 Huggingface Transformers 后端，实现了兼容 OpenAI API 的调用，采用 load_in_8bit 配置加载模型以节省显存，同时使用 bfloat16 进行推理。</p><p><strong>关于开源</strong></p><p>自从「QAnything」项目开放源代码以来，受到了开发社区的热烈欢迎和广泛认可。截至 2024 年 2 月 29 日，项目在 GitHub 上已经积累近 5000 个星标，这反映出了其流行度和用户对其价值的高度评价。</p><p>欢迎点击下面的链接下载试用：</p><p>QAnything github: &nbsp;&lt;https://github.com/netease-youdao/QAnything&gt;<br> QAnything gitee: &nbsp;&lt;https://gitee.com/netease-youdao/QAnything&gt;<br> 欢迎大家在 GitHub 上为[「QAnything」](https://github.com/netease-youdao/QAnything) 加星助力，方便收到新版本更新的通知！<br> &nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 06:02:56 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/youdaotech/blog/11045422</guid>
            <link>https://my.oschina.net/youdaotech/blog/11045422</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | 轻松复现 Sora 模型；事关 CUDA 兼容，英伟达禁止了；百度还差一个「遥遥领先」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.5</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/281597/bitwarden-mobile-native" target="_blank">密码管理工具 Bitwarden 宣布淘汰 Xamarin 框架，转向原生开发</a></h3><p>密码管理工具 Bitwarden 开发者在 Reddit 发布消息，称当下自家应用的 iOS 和 Android 客户端采用微软 Xamarin 框架，不仅早已过时且消耗资源较多。开发者表示他们正在使用 Kotlin 开发 Android 客户端、使用 Swift 来开发 iOS 客户端，正式上线还需要再等待几个月的时间。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8fbf5f9731de815a67f0b226b6125d4495b.png" referrerpolicy="no-referrer"></p><h3><a href="https://www.oschina.net/news/281566" target="_blank">Linux 桌面操作系统的市场份额超过 4%</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">截至 2024 年 2 月，<strong>Linux 在全球桌面操作系统市场份额的占比已超过 4%</strong>。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-32e040790feadfaa2ba3b7c7366a87eec23.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-1123ac30b2d25f778d2d273a031471c592c.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2082348875%2FO3BAkjZCu" target="_blank">伯克利_尤洋</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-dd51dcd7c7b84633a9e7f39d113d7df4d01.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fuser.guancha.cn%2Fmain%2Fcontent%3Fid%3D1191772" target="_blank">科技新知</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-3c72fbaae4c6f2b4a0a86043e9b60a28a3f.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.36kr.com%2Fp%2F2675982080800514" target="_blank">半导体行业观察</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-6097a7d202474dee1620add69e8449b7a6b.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FPrefectHQ%2Fprefect" target="_blank">https://github.com/PrefectHQ/prefect</a></u></em></p><hr><h2><span style="color:#16a085"><strong>开源之声</strong></span></h2><p>&nbsp;<img src="https://oscimg.oschina.net/oscnet/up-a696a9aacc9990b2b0ebdf6bb5ccd9d77d1.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c809c148077fe0b9ca74b2150495cad2c73.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精选</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-98fdfe8bf3d3dee3bbfe35b4feba428f637.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">开源日报第 22 期：轻松复现 Sora 模型；事关 CUDA 兼容，英伟达禁止了；百度还差一个「遥遥领先」</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">开源日报第 021 期：闭源模型就是比开源安全；起诉 OpenAI 不能更赞同；中国算力产业出现五个真问题</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">开源日报第 020 期：为什么王炸都来自 OpenAI；Pingora 最好不要用 YAML 当配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">开源日报第 019 期：我让 AI 用 C 语言写一个算法；微软三进制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">开源日报第 018 期：苹果十年造车梦碎；这个开源项目有点...「大胆」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">开源日报第 017 期：MariaDB 消亡史；写代码我有三不沾；V 神建议马斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 04:04:35 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281719</guid>
            <link>https://www.oschina.net/news/281719</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 回应被起诉：马斯克曾意图获得公司「绝对控制权」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">针对被联合创始人和前赞助人埃隆·马斯克<a href="https://www.oschina.net/news/281047/elon-musk-sues-openai-over-ai-threat">起诉</a>一事，OpenAI 在其网站上发布博文作出了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">回应</a>，称马斯克曾一度希望通过与特斯拉合并来「绝对控制」该公司，包括「多数股权、初始董事会控制权以及担任首席执行官」。</span></p><blockquote><p><span style="color:#000000">「在我们讨论营利性结构以推进使命时，Elon 希望我们与特斯拉合并，否则他就想要完全控制权。埃隆离开了 OpenAI，他说需要有一个能与 Google/DeepMind 相抗衡的竞争对手，而且他打算自己来做这件事。他说，他会支持我们找到自己的道路。」</span></p></blockquote><p><span style="color:#000000">OpenAI 表示，他们无法与马斯克就营利性条款达成一致，因为他们认为任何个人对 OpenAI 拥有绝对控制权都是违背使命的。在相关事项讨论期间，马斯克还扣留了资金，是 Reid Hoffman 弥补了工资和运营方面的缺口。</span></p><p><span style="color:#000000">而马斯克在试图将该公司纳入特斯拉但未能成功后，对公司大加挞伐。「我们很遗憾，和一位我们一直深感钦佩的人走到这一步。他曾激励我们志存高远，然后告诉我们会失败，进而创立了一个竞争对手，终至于在我们开始朝着 OpenAI 的使命取得有意义的进展时把我们告上公堂。」</span></p><p><span style="color:#000000">另一方面，OpenAI 还为其不开源的举措进行了辩解。「我们正在通过开源贡献等方式，使我们的技术能够广泛应用，从而增强人们的能力，改善他们的日常生活。我们提供对当今最强大人工智能的广泛访问，包括每天有数亿人使用的免费版本。」</span></p><p><span style="color:#000000">「Elon 明白这一使命并不意味着开源 AGI」。该公司在博文中指出，OpenAI 首席科学家曾在与马斯克的沟通中提到，"随着我们越来越接近 building AI，开始降低开放程度是有意义的。openAI 中的 Open 是指 AI 建成后，每个人都应从 AI 的成果中受益，但不分享科学成果也完全没问题......"。而对于这番言论，马斯克彼时也表明了赞同的态度。</span></p><p><img height="342" src="https://oscimg.oschina.net/oscnet/up-0683231baadda6cd1bbc78a08aa3f0b3340.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fopenai-elon-musk" target="_blank">查看官方博客</a>。</span></p><p><strong><span style="color:#000000">相关阅读：</span></strong></p><ul><li><p style="margin-left:0px; margin-right:0px; text-align:start"><a href="https://www.oschina.net/news/281047/elon-musk-sues-openai-over-ai-threat" target="_blank">马斯克起诉 OpenAI 及其 CEO 奥特曼，要求公司恢复开源状态</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 03:41:35 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281710/openai-response-elon-musk-lawsuit</guid>
            <link>https://www.oschina.net/news/281710/openai-response-elon-musk-lawsuit</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软将终止对 WSA 的支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fwindows%2Fandroid%2Fwsa%2F" target="_blank">宣布</a>将逐步停止对适用于 Android 的 Windows 子系统 (Windows Subsystem for Android，WSA) 的支持，截止时间为 2025 年 3 月 5 日。</p><p><img height="335" src="https://oscimg.oschina.net/oscnet/up-39b6577bcae20f6f2829c6ca55936d9cae2.png" width="500" referrerpolicy="no-referrer"></p><p>WSA 类似于 Windows Subsystem for Linux（WSL），但其目的是在 Windows 11 上运行 Amazon Appstore 中的 Android 应用程序。公告写道：</p><blockquote><p>微软将终止对 Windows Subsystem for Android (WSA) 的支持。因此，从 2025 年 3 月 5 日开始，Windows 上的 Amazon Appstore 以及依赖于 WSA 的所有应用程序和游戏将不再受到支持。在此之前，客户仍可获得技术支持。</p><p>在 2024 年 3 月 5 日之前安装了 Amazon Appstore 或 Android 应用程序的客户，在 2025 年 3 月 5 日停用日期之前仍可继续访问这些应用程序。如有其他问题，请通过<span style="color:#161616">&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.microsoft.com%2F" target="_blank">support.microsoft.com</a>&nbsp;联系我们的支持团队。</p></blockquote><p>这一更改仅针对 Windows Subsystem for Android，对 Windows Subsystem for Linux 并无明显影响。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 02:34:37 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281692/microsoft-dropping-wsa</guid>
            <link>https://www.oschina.net/news/281692/microsoft-dropping-wsa</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[倒了一个 Yuzu，还有千千万万个「转世」开源模拟器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>开源 Switch 模拟器 Yuzu 昨天突然的「滑跪」着实让人大跌眼镜——<u><a href="https://www.oschina.net/news/281570/switch-emulator-yuzu-shut-down-pay-24-million-to-settle-lawsuit">宣布项目关闭</a></u>、删除托管在 GitHub 的代码仓库，并向任天堂支付 240 万美元和解诉讼。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a754bb26a7ca77ccb496a39c5eecc8de82.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-f9ab7fe69c73d0aa85fe5a02118cb044ead.png" referrerpolicy="no-referrer"></p><p>然而这并不意味「开源模拟器」就此销声匿迹——号称是 Yuzu 转世的 "Suyu" 直接在 GitHub 挑衅任天堂：</p><blockquote><p>致任天堂法律团队：</p><p>你无法击败我们，即使你们把我打倒，也会有更多的人来。即使你把它们都下架，还会有更多人前仆后继。你输了这场战役。</p><p>这个项目不支持盗版，你需要自己提供游戏和 key，我们不从这个项目中赚钱（主要是为了让任天堂不起诉我们，哈哈）。</p><p>这个分支版本是确保任天堂无法干掉 Yuzu，模拟器长存！</p><p>此 repo 基于 Yuzu EA 4176 创建，欢迎贡献。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a4166af65954610888a3fc09d77a754eaf9.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCrimson-Hawk%2Fsuyu" target="_blank">https://github.com/Crimson-Hawk/suyu</a></u></em></p></blockquote><p>可以看到，Suyu 是基于 Yuzu 模拟器最新版本的开源项目，并声明自己不以任何方式支持盗版，目前正在寻找开发者。</p><p><img alt="" height="333" src="https://oscimg.oschina.net/oscnet/up-3d744fffcfd16f042f26222c57fcc388a01.png" width="300" referrerpolicy="no-referrer"></p><p>目前该项目已迁移至 GitLab：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.com%2Fsuyu-emu%2Fsuyu" target="_blank">https://gitlab.com/suyu-emu/suyu</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 02:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281690/yuzu-fork-suyu</guid>
            <link>https://www.oschina.net/news/281690/yuzu-fork-suyu</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 新增朗读功能，支持 37 种语言、5 种声音]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">OpenAI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FOpenAI%2Fstatus%2F1764712432939995549" target="_blank">宣布</a>为 ChatGPT 推出了名为「朗读」（ ReadAloud）的新功能。</span><span style="background-color:#ffffff; color:#222222">不仅支持 37 种语言，还可以自动检测文本语言并进行朗读。</span></p><p><span style="color:#000000">与"朗读"同时推出的还有一个新的设置菜单选项，让你可以对播报的语音进行选择。该功能可以让 ChatGPT 用五种不同的声音朗读其回复，旨在为用户提供更加便捷的交互体验。目前，「朗读」功能已上线 ChatGPT 的网页端、iOS 和安卓应用。该功能同时适用于 GPT-4 和 GPT-3.5 版本的 ChatGPT。</span></p><p><img height="280" src="https://oscimg.oschina.net/oscnet/up-4e53e10a9fbe9117ef7dac4953b4ab2da25.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">该功能可通过消息下方的一个新的扬声器图标进行访问，它采用了与移动应用程序上的 ChatGPT Voice 背后相同的技术。即使离开 ChatGPT 页面，语音播报也会继续，因此用户可以在处理其他事情时保持收听状态。</span></p><p><span style="color:#000000">OpenAI 表示，"朗读"功能适用于那些"需要免提的时刻，或者大声朗读信息有助于更好地理解信息的情况"。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 02:05:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281682/chatgpt-readaloud</guid>
            <link>https://www.oschina.net/news/281682/chatgpt-readaloud</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苏州科达加入 openKylin，为社区提供领先的视讯系统解决方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>近日，苏州科达科技股份有限公司（以下简称「苏州科达」）签署了 openKylin 社区 CLA(Contributor License Agreement 贡献者许可协议)，正式加入 openKylin 开源社区。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-60b7982651cc2dbe678ab7f58ddaca6ff8f.png" width="829" referrerpolicy="no-referrer"></p><p><span><span><span style="color:var(--weui-LINK)">苏州科达</span><span>成立于 1995 年，是领先的视讯与安防产品及解决方案提供商，致力于以视频会议、视频监控以及丰富的视频应用解决方案帮助各类政府及企业客户解决可视化沟通与管理难题。</span></span></span></p><p><span>在视频会议领域，<span>苏州科达</span>可提供全场景会议解决方案，覆盖高端会议厅、大中小型会议室、桌面、移动等不同场景，满足视频会议、指挥调度、会商协作、移动办公等多样化需求。在视频监控领域，<span><span>苏州</span></span>科达拥有前端、平台、存储等近千款产品，以及针对不同领域的视频信息解决方案。同时基于视频会议与视频监控两大领域的技术积累，苏州科达公司产品及解决方案已覆盖 200 多个行业，并在国内外获得了广泛应用。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-22a96ab807cbe2a9524d906354710cea835.png" width="940" referrerpolicy="no-referrer"></p><p><span><span>加入 openKylin 社区后，苏州科达将利用自身在视频会议、视频监控两大领域的技术积累以及在专业解决方案上的经验沉淀，结合 openKylin 社区版本，一方面为行业客户提供安全可信的系统解决方案；另一方面，解决会议和监控专用硬件终端与</span><span style="color:var(--weui-LINK)">主流 CPU</span><span>、操作系统进行成功集成后的持续迭代更新问题，推动社区在行业解决方案、软件生态建设方面的持续进步。</span></span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 01:25:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281670</guid>
            <link>https://www.oschina.net/news/281670</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[App Store 与 Spotify 撕逼，苹果表示约 86% 开发者从未需要向其支付费用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欧盟委员会最近的一项决定，指责 App Store 对数字音乐市场的竞争构成了阻碍，这一决定似乎为 Spotify 的立场提供了支持。然而，Apple 并不认同这一观点，他们认为这一市场是繁荣的，并且竞争是充分的。</p><p>Spotify，这个总部位于瑞典的音乐流媒体巨头，是这一决定的主要推动者。尽管 Spotify 在欧洲市场上占据了主导地位，拥有超过 50% 的市场份额，但它从未为在 App Store 上的成功支付过任何费用。Spotify 的成功，部分归功于 App Store 提供的平台和技术支持，这些帮助它构建和更新应用，以及与全球 Apple 用户分享其服务。</p><p>Apple 对此表示自豪，他们认为<strong> App Store 为开发者提供了一个公平的竞争环境，并且为用户创造了一个安全可靠的市场。App Store 的规则旨在保护用户安全，并且让开发者能够触达全球超过 10 亿台设备。大多数开发者（约 86%）实际上从未需要向 Apple 支付费用。</strong></p><p>Spotify 的成功故事是 App Store 成功的缩影。然而，Spotify 并不满足于现状，他们试图改变 App Store 的规则，以获取更多的利益。<strong>Spotify 希望在不使用 App Store 的内购系统的情况下，直接在应用内嵌入订阅价格。这与 Apple 的政策相冲突，因为 Apple 不会对通过 App Store 进行的交易收取佣金。</strong></p><p>这场争议的核心是 Spotify 与欧盟委员会的合作。自 2015 年以来，Spotify 一直在推动对 Apple 的调查，声称 Apple 在限制竞争对手的发展。尽管 Spotify 自身在 App Store 的帮助下取得了显著增长，但欧盟委员会在数字市场法案（DMA）即将生效之际，公布了这一决定。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com.cn%2Fnewsroom%2F2024%2F03%2Fthe-app-store-spotify-and-europes-thriving-digital-music-market%2F" target="_blank">Apple 对此表示不满，并计划提起上诉</a>。</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 12:01:04 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281630/the-app-store-spotify-and-europes-thriving-digital-music-market</guid>
            <link>https://www.oschina.net/news/281630/the-app-store-spotify-and-europes-thriving-digital-music-market</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🎁有奖问答|如何高效处理电子表格办公文档]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4700705_2331750">高手问答第 313 期 —— 如何高效处理电子表格办公文档</a><div class="ui red label horizontal" data-tooltip="置顶">顶</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4700705" class="__user"><span>小白兔爱吃大灰狼</span></a> 发布于，今天 14:24
                    </div><div class="item">阅读 29</div><div class="item collect-btn " data-id="2331750" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331750" data-obj-type="2">0</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4700705_2331750#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">0</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手问答</a></div><div class="content" id="articleContent"><p>以 Excel 为代表的电子表格应用已广泛应用于各行各业，随着企业数智化进程的加速，开发者通过编程的方式对办公文档的自动化处理场景越来越多。</p><p><strong><span><span>OSCHINA 本期高手问答（3 月 6 日 - 3 月 12 日）我们请来了嘉宾</span></span></strong><a href="https://my.oschina.net/xuri" rel="nofollow"><strong>续日</strong></a><strong><span><span>和大家一起聊聊，高效处理电子表格办公文档，那些事。</span></span></strong></p><p><strong>可讨论的问题包括但不限于：</strong></p><ul><li>带有高阶复杂功能工作表的自动化处理方法</li><li>遇到包含大规模数据工作簿时如何优化读写性能</li><li>Excelize 适合的应用场景</li><li>如何借助 WebAssembly 在浏览器中使用 Excelize</li><li>............</li></ul><p>其他相关的问题，也欢迎提问！</p><h2>嘉宾介绍：</h2><p><img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-0d2b62bc6b36ebd12c11a32d3f77ec4d739.jpg" width="300" referrerpolicy="no-referrer"></p><p>续日（GitHub: @xuri），软件工程师，阿里巴巴技术专家，曾就职于百度、360 等公司从事网络服务框架与基础软件研发，在办公文档软件研发领域有着丰富的经验。他是知名开源电子表格基础库 Excelize 的作者。</p><blockquote><p>Excelize 是一款用于操作 Office Excel 文档的开源基础库，遵循 BSD 3-clause 开源协议，基于 ISO/IEC 29500 国际标准。可以使用它来读取、写入由 Excel 、WPS 、OpenOffice 等办公软件创建的电子表格文档。支持 XLAM / XLSM / XLSX / XLTM / XLTX 等多种文档格式，高度兼容带有样式、图片 (表)、切片器等复杂组件的文档。可应用于各类报表平台、云计算、边缘计算等系统。正在被广泛应用于大型互联网公司、中小企业客户和初创公司。</p><p>项目地址：<br> https://github.com/xuri/excelize<br> https://gitee.com/xurime/excelize<br> https://www.oschina.net/p/excelize</p></blockquote><p><span style="background-color:#ffffff; color:#333333">🎁</span><span style="background-color:#ffffff; color:#333333"><span>&nbsp;</span>为了鼓励踊跃提问，问答结束后我们将从提问者中抽取 3 名幸运会员，赠予开源魔方一个。</span></p><p><span style="background-color:#ffffff; color:#333333"><img alt="" height="267" src="https://oscimg.oschina.net/oscnet/up-1afbf8f3e292f5abf1de816cca143b906b8.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手问答一贯的风格，不欢迎任何与主题无关的讨论和喷子。</span></p><p>下面欢迎大家就 「高效处理电子表格办公文档」<span><span>&nbsp;</span>相关</span>问题向<strong><a href="https://my.oschina.net/xuri" rel="nofollow">续日</a></strong>老师提问，直接回帖提问既可。</p></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331750" data-user-id="4700705" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331750" data-obj-type="2">0</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331750" data-obj-type="2" data-url="https://www.oschina.net/question/4700705_2331750"><i class="flag red icon"></i>举报</a></div></div>
            ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 11:08:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4700705_2331750</guid>
            <link>https://www.oschina.net/question/4700705_2331750</link>
        </item>
        <item>
            <title>
                <![CDATA[科大讯飞董事长刘庆峰：建议制定国家《通用人工智能发展规划》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 全国「两会」期间，全国人大代表、科大讯飞董事长刘庆峰建议，在 2017 年《新一代人工智能发展规划》的基础上，瞄准我国通用人工智能发展中需要重点补上的短板进行设计，围绕自主可控算力生态构建、高质量数据开放共享、科学的评测标准制定、源头技术前瞻研发、人才培养、法律制定和伦理人文等维度，系统性制定国家《通用人工智能发展规划》，由国家高位推动规划的制定和落地，不断缩小中美通用人工智能产业在通用底座平台方面的差距，并在行业应用和价值创造上打造我国的比较优势。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fa6b56a2cceac0c35759f54de9f877e3b82.png" referrerpolicy="no-referrer"></p><p>刘庆峰表示，国家在制定《规划》的同时，应该加快推动通用人工智能的相关工作，他提出 9 点建议：</p><p><strong>第一，建议发挥举国体制优势，加大并保持对通用大模型底座「主战场」的持续投入。</strong></p><p>建议以专项的形式从算力、数据、算法上在未来 5 年内持续支持我国通用大模型的研发攻关；建议支持有条件的地方政府，以专项债的形式支持通用和行业大模型研发以及应用生态发展所需的算力基础设施建设；建议制订相关政策，推动工业和民生等领域的大模型应用，从而让「底座大模型+行业应用」形成相互促进的良好局面；建议鼓励国资央企优先应用国产大模型，在关键敏感领域和核心战略领域只能用自主可控的大模型；建议面向「一带一路」设立专项，支持多语种大模型技术研发，以及在主要产业链合作国家、地区的落地应用。</p><p><strong>第二，建议加快形成围绕国产大模型的自主可控产业生态。</strong></p><p>大模型是典型的平台赋能性技术，要加快我国大模型开发者生态体系建设和运营，支持国产大模型向开发者开放，开展大模型评测体系和开源社区建设，降低研发和使用成本。支持工业大模型在工业互联网领域的赋能，支持软件大模型对软件行业的赋能，支持行业大模型对汽车、家电、服务机器人等行业领域的应用，以「人工智能+」推动我国自主可控的大模型产业生态蓬勃发展。</p><p><strong>第三，建议推动国家级高质量训练数据开放和共享。</strong></p><p>推动国家层面高质量数据平台的设立和资源共享，加大政府和市场协同，合理解决知识产权问题，构建包括国家公共数据资源、高质量电子图书、高质量音视频、多渠道行业应用数据及互联网开源数据资源等多源多模态的国家级数据资源汇聚平台，支持国家实验室、全国重点实验室、国家人工智能开放创新平台、行业领军企业等国家战略科技力量以揭榜挂帅形式优先、低成本使用。</p><p><strong>第四，建议出台更加客观、公正、可信的评测方法，加快大模型在行业领域的应用落地。</strong></p><p>联合国家级权威机构和行业龙头企业等组织，共同发布具有公信力的大模型评测标准和应用指南，并定期组织系统全面的科学评测，指导各行业甄别和选型大模型，避免各家大模型刻意刷榜和各种不权威的商业评测扰乱正常市场秩序。在行业应用方面，建议首批可以加快开发面向金融、工业、汽车、文旅、政务、教育、医疗等关键行业的应用场景，加快打造标杆示范，在成效验证后向全国规模化推广。</p><p><strong>第五，建议坚持源头核心技术系统性创新，在战略性、前瞻性的基础研究领域做好布局。</strong></p><p>布局投入大模型的宽基础研究，在大模型能力涌现机理、大模型可信训练推理、强化学习技术、自主学习技术等方面形成突破。建议加快脑科学与类脑智能、量子计算等领域与人工智能关键研究的协同攻关，形成交叉学科的突破，助力我国通用人工智能弯道超车。建议推动大模型与科学研究的深度结合，打造 AI for Science 的科研新范式，研究基于科学数据的 AI 建模和科学知识提取技术，助力科研人员更高效地进行科学研究和探索。在生命科学、化学、制药、物理、材料等多个科研领域，引入人工智能通识课，培养一批具备专业科研能力以及高水平通用人工智能理解能力的人才，为可能涌现的交叉学科重大突破做储备。</p><p><strong>第六，建议加快推广大模型赋能全学段，以全新机制加快探索我国人工智能拔尖创新人才培养。</strong></p><p>建议加快运用大模型的现有能力打造教师和学生的助手，赋能从中小学到职业教育和大学的教育教学提质增效。设立国家人工智能学院，以「核心+基地」的组织形式和全新机制推动我国面对中美竞争的拔尖人工智能人才培养。加强人工智能一级学科建设，联合头部企业打造一批人工智能人才产教融合培养基地，打造优秀人才专项遴选机制和通道等。</p><p><strong>第七，建议研究通用人工智能时代人才能力素质模型和培养方案，加快应用型人才培养。</strong></p><p>针对未来可能被人工智能大量替代的行业和岗位，对劳动力培养及再就业做专项研究，并且提前、主动做好应对。关注通用人工智能对社会各行业带来的冲击，加快建设新的人才能力素质模型和课程培养体系，特别是加快用通用人工智能赋能软件代码、语言学习、艺术创意等应用型人才的培养，助力我国软件行业和数字经济发展。</p><p><strong>第八，建议加速通用人工智能技术相关的法律法规制定与审议。</strong></p><p>建议围绕大模型的数据安全、隐私泄露、可靠性、知识产权等几大关键方面制定法律法规，提升通用人工智能技术可靠性与规范性。同时，完善向社会开放的大模型的准入和运行规则，明确责任分配与问责机制，并明确大模型知识产权与保护方式。</p><p><strong>第九，建议设立软课题进行通用人工智能相关的伦理人文研究。</strong></p><p>坚持科学、独立原则，针对通用人工智能技术可能带来的社会风险、伦理挑战和人类文明变化进行开放式课题研究。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 10:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281604</guid>
            <link>https://www.oschina.net/news/281604</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[知乎创始人兼 CEO 周源：中国大模型面临中文语料资源短缺的挑战]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 2024 年全国两会上，全国政协委员、知乎创始人兼 CEO 周源提交多份提案，重点关注补齐优质中文语料数据短板、激发互联网平台企业创新热情、以高质量技能人才供给推动新质生产力快速发展等内容。</p><p><img alt="" height="322" src="https://oscimg.oschina.net/oscnet/up-7f20232feea611c54f6dff70e0d906765cd.png" width="400" referrerpolicy="no-referrer"></p><p><strong>▍补齐优质中文语料数据短板</strong></p><p>截至 2023 年年底，我国累计发布了 200 多个人工智能大模型，其中有 20 多个大模型产品获批向公众提供服务。尽管我国在大模型领域取得了一定的成就，但仍面临着一些挑战，其中最显著的问题之一是高质量中文语料资源的短缺。</p><p>2021-2026 年中国数据量规模将由 18.51ZB 增长至 56.16ZB，年均复合增长率达到 24.9%，高于全球平均水平。虽然国内存量数据资源丰富，但目前中文优质数据仍然稀缺，如 ChatGPT 训练数据中文资料比重不足千分之一，而英文资料占比超过 92.6%。</p><p>对此，周源建议，建立数据合规的监管机制，推动完善 AIGC 监管立法，保护和规范人工智能领域的数据合规。对大模型的数据采集来源、处理方法、合规性等进行监督和审查。此外，应加强对大模型的社会影响和风险评估，及时发现和解决可能存在的问题。此外，要加强数据安全和知识产权的保护措施，并加快高质量中文数据集的开发与利用，数据作为新型生产要素已经成为驱动全球数字经济的动力引擎，国内数据要素市场起步较晚，标准、权属、交易、商业模式、监管等相关环节还有待完善。</p><p><strong>▍激发互联网平台企业创新活力</strong></p><p>2024 年将迎来中国全功能接入互联网 30 周年的重要里程碑。历经近三十载的发展，互联网不仅重塑了人们的工作模式、生活形态，甚至改变了思维方式，是我国科技创新体系的核心力量，为推动创新驱动发展战略提供了强大动力。</p><p>对此，周源建议，加强政策法规保障，提振互联网平台企业发展信心 。要加快促进民营经济发展立法进程。要科学设置监管政策。完善市场准入负面清单制度，明确禁止和限制进入的领域。对于尚未纳入监管范围的产业，应遵循「法无禁止即可为」的原则，支持互联网平台企业探索未知领域，为培育未来产业奠定坚实基础。</p><p>要完善科技创新机制，激发互联网平台企业创新热情。优化产业和科技扶持资金和项目的组织方式，更大比例吸收科技创新型互联网平台企业及其产业科学家、企业家深度参与。提供税收优惠和政府引导基金支持，降低互联网企业研发成本，激发其持续投入研发的热情。</p><p><strong>▍以高质量技能人才供给，推动新质生产力快速发展</strong></p><p>新质生产力的源头在科技创新，落脚点在产业升级，关键因素在人才支撑。加快形成新质生产力，不仅需要「高精尖缺」科技人才，还要有一大批高素质技术技能人才、大国工匠、能工巧匠等。</p><p>周源表示，人工智能技术为技能培训行业带来了更多的创新机会，促进了技能培训行业更加丰富的应用场景落地。通过人工智能技术的运用，职业技能培训行业可以实现更加个性、灵活、高效的教学模式，为学生提供更精准的学习体验。同时，教师也能借助 AI 工具提升教学效果，更好地满足学生的学习需求，促进技能培训向更高水平发展。</p><p>他建议，应鼓励并引导培训机构和教师更加积极主动地适应和掌握 AI 技术，提升自身的专业能力和教育素养，借助人工智能技术和 AI 大模型的发展，不断探索创新，赋能技能培训行业实现变革式发展，可促进高质量技能人才培养效率和有效供给。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 09:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281602</guid>
            <link>https://www.oschina.net/news/281602</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[密码管理工具 Bitwarden 宣布淘汰 Xamarin 框架，转向原生开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>密码管理工具 Bitwarden 开发者在 Reddit 发布消息，称当下自家应用的 iOS 和 Android 客户端采用微软 Xamarin 框架，不仅早已过时且消耗资源较多。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-90c67634cb3551e151a824faa9c8080b7c2.png" referrerpolicy="no-referrer"></p><p><em>via&nbsp;<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2FBitwarden%2Fcomments%2F1b32bbz%2Fgoing_native_the_future_of_the_bitwarden_mobile%2F" target="_blank">https://www.reddit.com</a></u></em></p></blockquote><p>虽然看上去通过 Xamarin 可以降低开发成本，但由于需要等待 Xamarin 更新适配新版 iOS 以及 Android 系统，因此客户端将无法在第一时间完成对新系统的支持。</p><p>开发者表示他们正在使用 Kotlin 开发 Android 客户端、使用 Swift 来开发 iOS 客户端，正式上线还需要再等待几个月的时间。</p><p>下面是官方提供的原生客户端截图：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8fbf5f9731de815a67f0b226b6125d4495b.png" referrerpolicy="no-referrer"></p><p>作为过渡期，目前 Bitwarden 还未彻底放弃 Xamarin 框架，为了能够支持 Passkey 即通行密钥，Bitwarden 将 Xamarin 升级到了 MAUI 框架，虽然这个过程并不顺利，但总算是实现了需求。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 09:22:06 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281597/bitwarden-mobile-native</guid>
            <link>https://www.oschina.net/news/281597/bitwarden-mobile-native</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[北大×腾讯联合发布报告，研究泛在操作系统开源生态体系]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#060607">北京大学和腾讯研究院联合发布了《泛在操作系统开源生态体系研究报告》，这是</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">双方共同发布《泛在操作系统实践与展望研究报告》之后，进一步聚焦于泛在操作系统开源生态的业界首个研究成果。</span></p><p><img alt="" height="410" src="https://static.oschina.net/uploads/space/2024/0305/151812_Os45_4700705.jpg" width="300" referrerpolicy="no-referrer"></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">报告主要内容包括：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>泛在操作系统的定义与框架</strong>：泛在操作系统（Ubiquitous Operating System, UOS）是在人机物融合的泛在计算模式下支持泛在应用开发和运行的操作系统平台。它不仅管理传统的计算资源，还包括传感器、数据等泛在资源。</p></li><li><p style="margin-left:0; margin-right:0"><strong>开源生态体系的重要性</strong>：开源模式被认为是促进软件技术创新的有效方式，能够激发群体智慧，实现快速迭代和技术创新。报告强调了开源在 IT 产业发展中的重要作用，以及开源与商业化如何相辅相成。</p></li><li><p style="margin-left:0; margin-right:0"><strong>国内外开源项目现状</strong>：报告梳理了国内外在泛在操作系统领域的开源项目，如 openKylin、deepin、Loongnix、OpenCloudOS、OpenEuler 等，并指出这些项目在推动软件产业链发展中的作用。</p></li><li><p style="margin-left:0; margin-right:0"><strong>开源生态体系框架</strong>：提出了泛在操作系统开源生态体系框架，包括泛在操作系统在软件供应链中的定位、开源社区的营造与治理、软件供应链的构建与运维，以及开源标准的联动制定。</p></li><li><p style="margin-left:0; margin-right:0"><strong>挑战与建议</strong>：报告分析了泛在操作系统开源生态体系建设面临的挑战，如核心技术推进、社区建设、生态链形成、产品应用与演化、知识产权保护和人才培养等，并提出了相应的建议。</p></li><li><p style="margin-left:0; margin-right:0"><strong>人才培养</strong>：强调了开源人才培养的重要性，提出了加强开源技能、意识和文化教育的建议，并建议通过产学研合作培养泛在操作系统相关的开源人才。</p></li><li><p style="margin-left:0; margin-right:0"><strong>开源社区与供应链建设</strong>：报告建议加快泛在操作系统开源社区及其软件供应链的建设，以营造良好的开源生态环境，并促进开源与商业的有机融合。</p></li><li><p style="margin-left:0; margin-right:0"><strong>标准制定</strong>：提出了加快泛在操作系统相关标准研制的建议，并探索开源标准联动模式，以推动泛在操作系统的研发与应用。</p></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">报告最后强调了开源生态体系对于泛在操作系统发展的重要性，并呼吁产学研用各界共同参与，共同构建和维护一个健康、可持续发展的开源生态体系。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本</em>）</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 05 Mar 2024 07:39:43 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281582</guid>
            <link>https://www.oschina.net/news/281582</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
