<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 06 Nov 2023 08:03:14 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[🔥 周热点 | VS Code 史上呼声最高的特性终于实现；vivo 发布自研操作系统蓝河 (BlueOS)....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2023.10.31-2023.11.05]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 07:13:11 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[龙芯 3A6000 国产桌面处理器本月底发布，对标英特尔 10 代酷睿]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日的龙芯中科 2023 年第三季度业绩说明会上，龙芯中科宣布&nbsp;3A6000 国产桌面处理器初步定于<strong>11 月 28 日发布</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-033f0723def37a98686c0268285f4fe7284.png" referrerpolicy="no-referrer"></p><p>龙芯 3A6000 是基于龙架构的新一代四核处理器，于今年 8 月流片成功。综合相关测试结果，<strong>龙芯 3A6000 处理器总体性能与英特尔公司 2020 年上市的第 10 代酷睿四核处理器相当</strong>，因此也是不少国内用户期待的一款高性能国产处理器。</p><p>龙芯中科在业绩说明会上透露，龙芯 3A6000 将于 11 月底正式发布（初步定于 11 月 28 日），<strong>十几家整机 / ODM 企业将发布其整机产品</strong>。</p><p>在谈到后续产品龙芯 3B6000 时，龙芯中科董事长、总经理胡伟武表示：「龙芯走的是提高效率路线，争取每 GHz 性能接近或达到苹果 CPU 的水平。<strong>3B6000 争取每 GHz 的性能再提高 20%-30%</strong>，在此基础上再用先进工艺提高主频，这时候龙芯 CPU 性能就处于世界领先行列了。当然，我们也会努力提高 3B6000 的主频。」</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 06:48:46 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265161</guid>
            <link>https://www.oschina.net/news/265161</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[李开复旗下 AI 公司发布 Yi 系列开源大模型，估值超 10 亿美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>创新工场董事长兼 CEO 李开复于今年创办了 AI 大模型创业公司「<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.01.ai%2F" target="_blank">零一万物</a></u>」。<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2506227176630145" target="_blank">根据 36 氪的独家报道</a></u>，零一万物已完成新一轮融资，由阿里云领投。目前，<strong>零一万物估值已超 10 亿美元，跻身独角兽行列</strong>。</p><p><strong>该公司已推出&nbsp;Yi-34B 和&nbsp;Yi-6B 两个开源大模型</strong>，号称对学术研究完全开放，同步开放免费商用申请。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4ab5886e43554fd3233305e7c8264217507.png" referrerpolicy="no-referrer"></p><blockquote><p>Hugging Face：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B" target="_blank">https://huggingface.co/01-ai/Yi-34B</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-6B" target="_blank">https://huggingface.co/01-ai/Yi-6B</a></p><p>ModelScope：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-34B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-34B/summary</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-6B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-6B/summary</a></p><p>GitHub：<br><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F01-ai%2FYi" target="_blank">https://github.com/01-ai/Yi</a></p></blockquote><p><span>据介绍，Yi 目前拥有 200K 上下文窗口，可处理约 40 万字的文本——这也是目前全球大模型中最长的上下文窗口。其中 Yi-34B 在 Hugging Face 英文测试榜单中位列第一，在 C-Eval 中文能力排行榜中超越所有开源模型。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e1c843e9962b9e9aecc13487da3270520c.png" referrerpolicy="no-referrer"><br><em>Hugging Face Open LLM Leaderboard (pretrained) 大模型排行榜，Yi-34B 高居榜首 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-03d63eae8034e7ca5d0e28148b2fb94dc3f.png" referrerpolicy="no-referrer"><br><em>C-Eval 排行榜:公开访问的模型，Yi-34B 全球第一 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e5919449029e62b8bf111322f96af0dcb3.png" referrerpolicy="no-referrer"></p><p>Yi-34B 和 Yi-6B 的表现：</p><ul><li><strong>C-Eval 中文能力排行榜</strong>：Yi-34B 在 C-Eval 中文能力排行榜上超越了所有开源模型，这意味着在中文语言理解和生成方面，Yi-34B 的性能优于其他所有开源的大模型。</li><li><strong>中文综合能力</strong>：在 CMMLU、E-Eval、Gaokao 等中文评测指标上，Yi-34B 明显领先于 GPT-4，展现了其在中文语境下的强大理解和应用能力。</li><li><strong>中文问答能力</strong>：在 BooIQ、OBQA 两个中文问答指标上，Yi-6B 和 Yi-34B 与 GPT-4 的表现水平相当，这表明它们在理解中文问题和提供准确答案方面具有很高的能力。</li><li><strong>超长文本处理</strong>：200K 上下文窗口，Yi-34B 能够处理大约 40 万汉字的超长文本输入，这在处理长篇中文文档、书籍或报告时尤为重要，能够理解和生成连贯、准确的中文文本。</li><li><strong>技术创新</strong>：零一万物自研规模化训练实验平台和智能数据处理管线。强大的 AI 基础设施支持，提高了训练效率和降低了成本。</li></ul><p>「零一万物」在官网写道，他们深信「以大语言模型为突破的 AI 2.0 正在掀起技术、平台到应用多个层面的革命」。根据他们的判断，AI 2.0 时代将诞生「比移动互联网大十倍的平台机会」，将把既有的软件、使用界面和应用重写一次，改写用户的交互和入口。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 05:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</guid>
            <link>https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[承载微软跨平台生态之梦的 UWP，正在消亡]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>开发者发现，微软最新的 Windows&nbsp;11&nbsp;Canary Build 25987 预览版已经开始提供两个版本的 XAML Shell 服务，<strong>新的版本直接基于 Win32 + XAML</strong>，曾经被寄予厚望的 UWP 在新版本里已经不见踪影。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1106/113836_8gF1_2720166.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fthebookisclosed%2Fstatus%2F1720108362275213594" target="_blank">https://twitter.com/thebookisclosed/status/1720108362275213594</a></em></u></p></blockquote><p>据介绍，新增的 dll 名为 ControlCenter.dll，这是控制中心的文件，目前已经同时提供旧版本和新的基于 Win32+XAML 的版本，即用户可以通过 ViveTool 启用这种新变体。</p><p>一般来说能被发现已经可以通过 ViveTool 启用，那么这个新变化基本已经开发完毕，后续就会分别面向不同的用户进行测试，收集运行数据。</p><p>延伸阅读</p><ul><li><strong><a href="https://www.oschina.net/news/165300/ms-officially-deprecates-uwp">微软正式弃用 UWP</a></strong></li><li><strong><a href="https://www.oschina.net/news/149997/winui-3-uwp-win32-apps-windows11">WinUI 3 仍专注于 Win32 应用，暂无面向 UWP 的计划</a></strong></li><li><strong><a href="https://www.oschina.net/news/107123/microsofts-uwp-app-dream-is-dead">Win32 应用进入微软应用商店，UWP 怎么办？</a></strong></li><li><strong><a href="https://www.oschina.net/news/149797/ms-store-xmal">Microsoft Store 完全使用 XAML 以替代 HTML，Visual Studio 预计年底上架商店</a></strong></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265128</guid>
            <link>https://www.oschina.net/news/265128</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国内最大开源模型发布，650 亿参数无条件免费商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">元象 XVERSE 公司宣布开源 650 亿参数高性能通用大模型 XVERSE-65B，无条件免费商用。</span></p><p><span style="color:#000000">XVERSE-65B 采用了 Transformer 网络结构，模型通过训练了 2.6 万亿个令牌的高质量多样化数据，包含了 40 多种语言。具有 16K 的上下文长度，适用于多轮对话、知识问答和摘要等任务。</span></p><p><span style="color:#000000">主要特点如下:</span></p><ul><li><span style="color:#000000"><strong>模型结构</strong>：XVERSE-65B 使用主流 Decoder-only 的标准 Transformer 网络结构，支持 16K 的上下文长度（Context Length），能满足更长的多轮对话、知识问答与摘要等需求，模型应用场景更广泛。</span></li><li><span style="color:#000000"><strong>训练数据</strong>：构建了 2.6 万亿 token 的高质量、多样化的数据对模型进行充分训练，包含中、英、俄、西等 40 多种语言，通过精细化设置不同类型数据的采样比例，使得中英两种语言表现优异，也能兼顾其他语言效果。</span></li><li><span style="color:#000000"><strong>分词</strong>：基于 BPE（Byte-Pair Encoding）算法，使用上百 GB 语料训练了一个词表大小为 100,534 的分词器，能够同时支持多语言，而无需额外扩展词表。</span></li><li><span style="color:#000000"><strong>训练框架</strong>：训练中采用 FlashAttention2 加速计算，3D 并行基础上采用虚拟流水线（virtual pipeline）技术，降低较长流水线和 16k 上下文窗口产生的过高气泡率，在千卡集群的峰值算力利用率达到业界前列。同时通过集群基础设施运营、资源调度、训练框架和调度平台协同等持续优化，打造出高稳定、低中断、强容错的训练系统，将每周有效训练率提升至 98.6%。</span></li></ul><p><span style="color:#000000"><strong>评测结果</strong></span></p><p><span style="color:#000000"><img height="454" src="https://oscimg.oschina.net/oscnet/up-2cd1eb2bb0579c1ae7d9b7cdba455e38df6.png" width="500" referrerpolicy="no-referrer">&nbsp;</span></p><blockquote><p><span style="color:#000000">元象 XVERSE 于 2021 年初在深圳成立，主营 AI 与 3D 技术，创始人姚星是前腾讯副总裁和腾讯 AI Lab 创始人。该公司目前累计融资金额超过 2 亿美元，投资机构包括腾讯、高榕资本、五源资本、高瓴创投、红杉中国、淡马锡和 CPE 源峰等。</span></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265120</guid>
            <link>https://www.oschina.net/news/265120</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蚂蚁集团百灵大模型通过备案，采用 Transfromer 架构]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 6 日，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jiemian.com%2Farticle%2F10342101_sina.html" target="_blank">界面新闻从蚂蚁集团获悉</a></u>，根据国家七部委联合公布的《生成式人工智能服务管理暂行办法》指导要求，蚂蚁百灵大模型已完成备案，基于百灵大模型的多款产品已陆续完成内测，将向公众开放。</p><p>本次通过备案的是<strong>蚂蚁百灵语言大模型，该大模型采用 Transfromer 架构</strong>，基于万亿级 Token 语料训练而成，支持窗口长度达 32K。</p><p>目前，蚂蚁大模型已形成包括大模型底层基础设施、基础大模型、行业大模型、应用产品在内的完整技术链条。</p><p>在基础大模型层面，除了本次通过备案的百灵语言大模型，蚂蚁集团也在研发百灵多模态大模型，并已内测。</p><blockquote><p><a href="https://www.oschina.net/news/257409/codefuse-ai" target="_blank">蚂蚁集团正式开源 CodeFuse 代码大模型</a><br><a href="https://www.oschina.net/news/246241" target="_blank">蚂蚁集团证实正研发语言和多模态大模型，命名「贞仪」</a></p></blockquote><p>国内第二批通过备案的 AI 大模型包括 11 家公司，部分已面向全社会开放服务。加上首批的 10&nbsp;余个大模型，目前已有超过 20&nbsp;个大模型获得备案。</p><p>新一批备案名单包括：网易有道（「子曰」大模型）、蚂蚁集团（百灵大模型）、面壁智能（「面壁露卡 Luca」）、出门问问（「序列猴子」）、昆仑万维（「天工」大模型）、美团（模型）、知乎（「知海图 AI」模型）、月之暗面（moonshot）、金山办公（WPS AI）、好未来（MathGPT 大模型）等。</p><p>8 月 31 日首批通过备案的 AI&nbsp;大模型包括百度文心一言、百川智能、商汤商量 SenseChat、抖音（云雀大模型）、智谱 AI（GLM 大模型）、中科院（紫东太初大模型）、上海 MiniMax（ABAB 大模型）、上海人工智能实验室（书生通用大模型）、「360 智脑」等等。</p><blockquote><p><a href="https://www.oschina.net/news/256949" target="_blank">挑战 ChatGPT，国产有这 8 款 AI 大模型产品</a></p></blockquote><p>据悉，今年 8 月 15 日正式施行的《生成式人工智能服务管理暂行办法》 ，提供具有舆论属性或者社会动员能力的生成式人工智能服务的，应当按照国家有关规定开展安全评估，并按照《互联网信息服务算法推荐管理规定》履行算法备案和变更、注销备案手续。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265114</guid>
            <link>https://www.oschina.net/news/265114</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[DHorse 即将支持更多的登录方式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>现状</h2><p>在 v1.4.0 版本之前，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F512team%2Fdhorse" target="_blank">DHorse</a>支持的登录方式有：DHorse 系统本身、Ldap 两种；但是，既然作为企业级服务，只支持以上两种方式是不够的。当下，越来越多的企业使用钉钉和企业微信进行沟通和办公，支持这两种登录方式也势在必行，此外，还有传统的 SSO 登录，在未来的 v1.5.0 的版本里即将支持以上登录方式。</p><p>下面，简单介绍一下即将支持的这三种登录方式。</p><h3>钉钉登录</h3><p>开启钉钉登录，需要具备以下几个条件：</p><ul><li>需要拥有钉钉后台的管理权限；</li><li>需要创建钉钉应用；</li><li>需要进行 DHorse 的钉钉配置；</li></ul><h3>企业微信登录</h3><p>开启企业微信登录，需要具备以下几个条件：</p><ul><li>需要拥有企业微信的后台管理权限；</li><li>需要创建企业微信的应用；</li><li>需要配置 DHorse 的企业微信；</li></ul><h3>SSO 登录</h3><p>CAS 是 SSO 登录的主流实现者，DHorse 也使用 CAS 登录来实现 SSO 登录的功能；</p><p>开启 SSO 登录，需要具备以下几个条件：</p><ul><li>需要企业提供自己的 CAS 服务；</li><li>需要配置 DHorse 的 CAS 登录；</li></ul><h2>结论</h2><p>为了更好的与企业管理员工方式的多样性相结合，简化企业管理，支持尽可能多的登录方式势在必行。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265154</guid>
            <link>https://www.oschina.net/news/265154</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenELA 公开发布 Enterprise Linux 源代码]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000">Open Enterprise Linux Association (OpenELA)</span><span style="color:#000000"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenela.org%2Fnews%2F2023.11.02-governance_and_code_availability%2F" target="_blank">宣布</a>公开发布 Enterprise Linux (EL) 源代码并成立技术指导委员会。</span></p><blockquote><p><span style="color:#000000">「OpenELA 很高兴地宣布，现在所有人都可以获取构建衍生&nbsp;Enterprise Linux 操作系统所需的全部源代码包。初步侧重点在于 EL8 和 EL9，EL7 的软件包也即将推出。该项目致力于确保向社区无限期提供 EL 源代码。」</span></p></blockquote><p><img alt="" height="381" src="https://oscimg.oschina.net/oscnet/up-08878f094d1e8bcafadeca1ea19e8f93ccc.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenELA 是在今年 8 月份，由甲骨文、SUSE 和 CIQ (Rocky Linux 背后的商业实体) 联合组建的一个开源企业 Linux 发行版开发商的行业协会；旨在通过提供开放和免费的 Enterprise Linux 源代码，鼓励<span style="background-color:#ffffff">与 Red Hat Enterprise Linux (RHEL) 兼容的发行版的开发和协作</span>。</span><span style="background-color:#ffffff; color:#000000">OpenELA 的形成源于红帽</span><a href="https://www.oschina.net/news/246331/red-hat-centos-stream-sources">对 RHEL 源代码可用性的更改</a><span style="background-color:#ffffff; color:#000000">。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Oracle、SUSE 和 CIQ&nbsp;方面都表达了对这一进展的喜悦之情。CIQ 首席执行官兼 Rocky Linux 创始人 Gregory Kurtzer 发言称：</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「几十年来，各组织都在 CentOS 上进行标准化，因为它是免费的，遵循 Enterprise Linux 标准，并且得到许多供应商的大力支持。CentOS 停产后，不仅在生态系统中留下了一个巨大的漏洞，而且也清楚地表明了社区需要团结起来才能做得更好。OpenELA 正是这样的一个社区答案，它将确保所有专业 IT 部门和企业用例拥有一个协作和稳定的未来。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">AlmaLinux 尚未加入该协会。AlmaLinux 操作系统基金会主席 benny Vasquez 评论表示，「</span></span><span style="background-color:#ffffff; color:#000000">我总是很乐于看到一个新的非营利组织站稳脚跟并开始</span><span style="color:#000000"><span style="background-color:#ffffff">运作。不过我们目前还不会使用他们发布的代码，因为我们已经建立了自己的工作流程，不需要使用这些代码。」</span></span></p><p><span style="color:#000000">OpenELA&nbsp;已经<span style="background-color:#ffffff">完成了在美国特拉华州的非营利性非股份公司的注册，正在向美国国税局申请 501(c)(6) 免税资格。该公司表示，将为有兴趣支持开源企业 Linux 发行版开发目标和利益的利益相关者提供一个论坛。「创始公司认为，法律实体是对开源工作产生积极影响的基础性工具，可以统一开源工作的价值观，并确保与开源社区的适当接触。」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>相关阅读：</strong></span></p><ul><li style="text-align:start"><a href="https://www.oschina.net/news/253319/oracle-suse-ciq-openela" target="_blank">SUSE、甲骨文和 CIQ 组建 OpenELA：企业 Linux 源代码的社区存储库</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 04:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264995/openela-enterprise-linux-source</guid>
            <link>https://www.oschina.net/news/264995/openela-enterprise-linux-source</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenHarmony 4.0 开发数据：华为贡献者 1800 名、增删改代码 8849882 行]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenHarmony <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW9H8Yyq6-jK-35FnIsafSQ" target="_blank">公布</a></u>了关于 4.0 Release 版本的开发数据。</p><p>据介绍，<u><a href="https://www.oschina.net/news/264989/openharmony-4-0-released">OpenAtom OpenHarmony 4.0 Release 版本</a></u>于 10 月 27 日发布，经过了 32 周的开发周期。</p><p>在此期间，有 65499 个 Committs 进入了版本。共有 2220 位贡献者为 4.0 Release 版本做出了贡献。其中，华为贡献者 1800 名，累计 2000+名，共增删改代码 8849882 行，占比 80.03%。</p><p>华为的 5 名顶级贡献者和华为以外的 15 名顶级贡献者如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb921b7f488f8d9d32c10bfb308ed11d6fe.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">以下的单位参与了 OpenHarmony 4.0 Release 版本的工作，较活跃的如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-baa6184ec3c30845abf2d57faddb063630b.png" referrerpolicy="no-referrer"></p><p>不同单位在不同子系统的贡献比例：</p><p>华为的贡献覆盖 30 多个核心子系统，其他顶级共建单位在各领域的贡献情况如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9045d86ad3cdc74208e832cc5a7cc327d37.png" referrerpolicy="no-referrer"></p><p>这些单位对 OpenHarmony 4.0 Release 版本的工作主要集中在以下领域：</p><p>• 深开鸿的工作主要集中在短距，驱动，XTS，开发工具，ArkUI 子系统中，包括蓝牙&amp;wifi 增强，ArkUI 运行时，ArkUI 组件增强，NAPI 框架生成工具，ALSA 驱动 HDI 插件平台解耦，codec 驱动 HDI 接口，ArkUI XTS 套件支持，RK3568 开发板等特性。</p><p>• 开鸿智谷的工作主要集中在开发样例，开发板，轻内核子系统中，包括轻内核 queue 读写增强，ArkUI 组件集合样例，场景化仿应用开发（设备管理，通信，数据库，相机，语音）和 Niobe 开发板等特性。</p><p>• 软通动力的工作主要集中在 ArkUI，XTS，开发板子系统中，包括 ArkUI 组件（TextInput，TextTimer，边框）增强，wpt 套件 Reftest 自动化测试，ArkUI 布局 XTS 套件，UnionPi Tiger 开发板,扬帆致远开发板等特性。</p><p>• 九联科技的工作主要集中在开发样例，芯片内核驱动，HDF 驱动子系统中，包括温湿度传感器驱动，开发样例（通知，分布式账号管理，资源授权访问，一多交互等场景），A311D 芯片适配，UnionPi Tiger 开发板适配等特性。</p><p>• 润开鸿的工作主要集中在芯片开发板，ArkUI，驱动子系统中，包括 arkcompiler 中 arraybuffer 功能增强，启动流程优化，DAYU210 开发板，Neptune100 开发板适配等特性。</p><p>• 诚迈的工作主要在多模输入子系统中。</p><p>据称华为、深开鸿、软通动力、开鸿智谷分别建设超过 5 万+行代码并持续贡献中，成为 2023 年《百人代码贡献单位》。九联开鸿、润开鸿、京东、诚迈科技、中科院软件所、中软国际持续贡献中，计划今年 12 月 31 日前贡献 5 万+行功能特性代码。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 04:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265135</guid>
            <link>https://www.oschina.net/news/265135</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[马斯克旗下 xAI 发布首个 AI 大模型产品 Grok]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">马斯克旗下 xAI 团队发布其首个 AI 大模型产品 —— <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.ai%2F" target="_blank">Grok</a>；目前只训练了 2 个月左右的时间，因此尚处于非常早期的测试阶段。</span></p><blockquote><p><span style="color:#000000">Grok 是一款仿照《银河系漫游指南》设计的人工智能，可以回答几乎任何问题，更难能可贵的是，它甚至可以建议你要问什么问题！</span></p><p><span style="color:#000000">Grok 在回答问题时略带诙谐和反叛，因此如果你讨厌幽默，请不要使用它！</span></p><p><span style="color:#000000">Grok 的一个独特且根本的优势是它可以通过 𝕏 平台实时了解世界。它还能回答被大多数其他人工智能系统拒绝的尖锐问题。</span></p></blockquote><p><img height="316" src="https://oscimg.oschina.net/oscnet/up-95e999fb26b9fab921735913d2139b7577d.jpg" width="300" referrerpolicy="no-referrer"></p><p><img height="388" src="https://oscimg.oschina.net/oscnet/up-c1e26f5d404c988b2332dcab2ffaa7becdc.jpg" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Grok 基于&nbsp;xAI 团队于 11 月发布的自研大语言模型&nbsp;Grok-1。在&nbsp;xAI 宣布成立后，项目团队就用 330 亿个参数训练了一个 LLM 原型（Grok-0），这一<span style="background-color:#ffffff">早期模型</span>自称与 LLaMA 2 (70B) 能力相当，但只使用了一半的训练资源。</span></p><p><span style="color:#000000">Grok-1 则在此基础上改进了推理和编码能力。Grok-1 是一个基于 Transformer 的自回归模型，经过预先训练以执行 next-token 预测。然后利用人类和早期 Grok-0 模型的广泛反馈对该模型进行微调，初始 Grok-1 的上下文长度为 8192 个 token。</span></p><p><span style="color:#000000">一些评测结果如下所示：</span></p><p><span style="color:#000000"><img height="238" src="https://oscimg.oschina.net/oscnet/up-78c5896454178aea96eb296a0a2beeb7faf.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img height="96" src="https://oscimg.oschina.net/oscnet/up-ff9e8be5f7abf6322719c422a60352348a7.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Grok-1 也存在一些局限性，该语言模型不具备独立搜索网络的能力，官方建议在 Grok 中部署搜索工具和数据库可以增强模型的能力和真实性。并警告称，尽管可以访问外部信息源，但该模型仍会产生幻觉。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">为了创建 Grok，</span>xAI 团队还<span style="background-color:#ffffff">构建了一个基于 Kubernetes、Rust 和 JAX 的自定义训练和推理堆栈。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「</span>Rust 已被证明是构建可扩展、可靠且可维护的基础架构的理想选择。它提供高性能、丰富的生态系统，并防止分布式系统中通常会发现的大多数错误。鉴于我们的团队规模较小，基础架构的可靠性至关重要，否则维护就会缺乏创新。Rust 让我们充满信心，任何代码修改或重构都可能产生可以在最少监督的情况下运行数月的工作程序。<span style="background-color:#ffffff">」</span></span></p><p><span style="color:#000000">目前&nbsp;<span style="background-color:#ffffff">Grok 仅面向少数美国用户<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrok.x.ai%2F" target="_blank">开放测试</a>。</span></span></p><p><strong><span style="color:#000000">相关阅读：</span></strong></p><ul><li><a href="https://www.oschina.net/news/249159/elonmusk-announced-xai" target="_blank">马斯克宣布成立 xAI 公司</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265129/xai-grok</guid>
            <link>https://www.oschina.net/news/265129/xai-grok</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维「天工」大模型正式向全社会开放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 11 月 3 日，昆仑万维「天工」大模型通过《生成式人工智能服务管理暂行办法》备案，面向全社会开放服务！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>用户在应用商店下载「天工</span></span><span><span>APP」或登陆「天工官网」（www.tiangong.cn）均可直接注册使用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>「天工」是国内首个对标</span></span><span><span>ChatGPT 的双千亿级大语言模型，也是一个 AI 搜索引擎，一个对话式 AI 助手。「天工」拥有强大的自然语言处理和智能交互能力，能够实现个性化 AI 搜索、智能问答、聊天互动、文本生成、编写代码、语言翻译等多种应用场景，并且具有丰富的知识储备，涵盖科学、技术、文化、艺术、历史等领域。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span>&nbsp;<img alt="" height="589" src="https://oscimg.oschina.net/oscnet/up-d32a56bf391efe8f4eb7543b06215352058.png" width="1265" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2022 年 12 月 15 日，昆仑万维在北京举行 AIGC 技术发布会，发布自研 AIGC 全系列算法与模型，覆盖了图像、音乐、文本、编程等多模态的 AI 内容生成能力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 4 月 17 日，昆仑万维正式发布自研千亿级大语言模型「天工」，同时宣布启动邀请测试。「天工」用过通过自然语言与用户进行问答式交互，AI 生成能力可满足文案创作、知识问答、代码编程、逻辑推演、数理推算等多元化需求。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 5 月 19 日，北京市经济和信息化局公布第一批《北京市通用人工智能产业创新伙伴计划成员名单》。昆仑万维凭借在 AIGC 领域的前沿探索和投资布局，成为第一批模型伙伴和投资伙伴。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 8 月 23 日，昆仑万维推出国内第一款 AI 搜索产品——「天工 AI 搜索」，并开启内测申请。「天工 AI 搜索」深度融合 AI 大模型能力，通过人性化、智能化的方式全面提升用户的搜索体验，为用户提供快速、可靠的交互式搜索服务，并集成 AI 对话、AI 写作等常用功能，帮助用户提升工作效率，全面重塑中文搜索体验。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月，昆仑万维多模态大模型 Skywork-MM 在腾讯优图实验室联合厦门大学开展的多模态大语言模型测评 MME 中，综合得分排名第一。该评测首次对全球范围内 MLLM 模型进行了全面定量评测并公布了 16 个排行榜，包含感知、认知两个总榜单以及 14 个子榜单。Skywork-MM 模型位列综合榜单第一，其中，感知榜单排名第一、认知榜单排名第二。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 16 日，在权威推理榜单 Benchmark GSM8K 测试中，昆仑万维「天工」大模型以 80% 的正确率脱颖而出，大幅领先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%），这标志着天工的推理能力达到全球领先，接近 GPT-4。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 17 日，昆仑万维通过信通院「可信 AI」评估，并被评选为人工智能实验室副组长单位。经中国信通院评估，昆仑万维天工大模型符合 AIIA/PG 0071-2023、AIIA/PG 0072-2023 评估标准，模型开发、以及模型能力均达到了「4+级」。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>10 月 30 日，昆仑万维开源百亿级大语言模型「天工」Skywork-13B 系列，并配套开源了 600GB、150B Tokens 的超大高质量开源中文数据集。「天工」Skywork-13B 系列目前包括 130 亿参数的两大模型，Skywork-13B-Base 模型、Skywork-13B-Math 模型，它们在 CEVAL、GSM8K 等多个权威评测与基准测试上都展现了同等规模模型的最佳效果，其中文能力尤为出色，在中文科技、金融、政务等领域表现均高于其他开源模型。同时，昆仑万维「天工」Skywork-13B 系列大模型全面开</span></span><span><span>放商用——开发者无需申请，即可商用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>一直以来，昆仑万维致力于在</span></span><span><span>AIGC 模型算法方面的技术创新和开拓，致力于降低 AIGC 技术在各行各业的使用和学习门槛。通过《生成式人工智能服务管理暂行办法》备案后，昆仑万维将面向全社会开放 AI 服务，持续推动天工大模型及 AIGC 业务迈向新高度，提高多款生成式 AI 产品的用户体验，探索未知世界、创造美好未来。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265122</guid>
            <link>https://www.oschina.net/news/265122</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[从科幻走向现实，LLM Agent 做到哪一步了？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LLM 洪流滚滚，AI 浪潮席卷全球，在这不断冲击行业认知的一年中，Agent 以冉冉新星之态引起开发者侧目。OpenAI 科学家 Andrej Karpathy 曾言「OpenAI 在大模型领域快人一步，但在 Agent 领域，却是和大家处在同一起跑线上。」</p><p>在此背景下，AI 从业者坚信：基于 LLM 的 Agent 会是一个崭新并且充满着机会的蓝海领域。</p><p>那么，究竟什么是 Agent？它的框架工作方式是什么？现阶段存在哪些问题？未来有着怎样的可能性？本文将分享一些思考。</p><h2>01.什么是 Agent？</h2><p><img src="https://oscimg.oschina.net/oscnet/up-1f337817172f1c53b43dbdb7e958d8fe1a8.png" alt="" referrerpolicy="no-referrer"></p><p>根据 OpenAI 科学家 Lilian Weng 的一张 Agent 示意图 [1] 我们可以了解 Agent 由一些组件来组成。</p><h3>规划模块</h3><ul><li><p>子目标分解：Agent 将目标分为更小的、易于管理的子目标，从而更高效地处理复杂的任务。</p></li><li><p>反省和调整：Agent 可以对过去的行为进行自我批评和自我反思，从错误中吸取教训，并针对未来的步骤进行完善，从而提高最终结果的质量。</p></li></ul><h3>记忆模块</h3><ul><li><p>短期记忆：在这里通常是指 in-context learning，即利用提示工程来让模型进行一定的学习。</p></li><li><p>长期记忆：这为 Agent 提供了长时间保留和召回信息的能力，通常是通过利用外部向量存储和快速检索。</p></li></ul><h3>工具使用模块</h3><p>代理学习调用外部 API 来获取模型权重中缺失的额外信息（通常在预训练后很难更改），包括当前信息、代码执行能力、对专有信息源的访问等。</p><p>所以当 Agent 接收到一个处理复杂任务的目标时，它会首先进行任务的拆解，并去执行子任务，每次大模型调用之间通过短期记忆连接，使得大模型能理解当前任务处理的状态。接下来 Agent 需要根据任务的状态来获取能够帮助模型处理任务的信息，这些信息可以是历史信息以及与任务有关的额外信息。</p><p>由于大模型拥有一定的认知能力，所以在无法精准定义所需信息的情况下，我们可以将与当前状态有相关性的信息组织起来，让大模型自主地去摘取它需要的内容。所以，比起基于关键字精准的匹配的搜索方法，向量数据库所拥有的根据语义相关性的模糊搜索在这一点上受到了 Agent 框架的广泛青睐。通过将长期记忆存放在一个数据库（向量数据库或传统数据库），并且在执行过程中根据需要进行检索，模型能够在任务的执行中获取执行经验以及认识到总体的状态。</p><h2>02.Agent 框架工作方式</h2><p>我们以 AutoGPT 为例，看看一个 Agent 框架具体是如何工作的：</p><p><img src="https://oscimg.oschina.net/oscnet/up-0eb6a67673ebe44e8085f325471e525612a.png" alt="" referrerpolicy="no-referrer"></p><p>AutoGPT[2] 使用 GPT-4 来生成任务、确定优先级并执行任务，同时使用插件进行互联网浏览和其他访问。AutoGPT 使用外部记忆来跟踪它正在做什么并提供上下文，使其能够评估其情况，生成新任务或自我纠正，并将新任务添加到队列中，然后对其进行优先级排序。</p><p>另一个著名的项目 babyagi[3] 也是采取类似工作的方式。Agent 与一般的 LLM 最大的不同点在于，LLM Agent 通常根据任务的总体目标来去指定以及编排子目标，而 LLM 通常是作为一个被调用的工具，在一个工作流中担任一个具体任务的执行者。</p><h2>03.LLM Agent 现阶段出现的问题</h2><p>由于一些 LLM（GPT-4）带来了惊人的自然语言理解和生成能力，并且能处理非常复杂的任务，一度让 LLM Agent 成为满足人们对科幻电影所有憧憬的最终答案。但是在实际使用过程中，大家逐渐发现了通往通用人工智能的道路并不是一蹴而就的，目前 Agent 很容易在一些情况下失败：</p><ul><li><p>Agent 会在处理某一个任务上陷入一个循环</p></li><li><p>prompt 越来越长，最终甚至超出最大内容长度</p></li><li><p>记忆模块的策略没有给 LLM 某些关键的信息而导致执行失败</p></li><li><p>LLM 由于幻觉问题错误使用工具，或者让事情半途而废</p></li></ul><p>上述问题随着大家对于 Agent 的了解开始浮出水面，这些问题一部分需要 LLM 自身来解决，另一部分也需要 Agent 框架来进行解决，通用的 Agent 仍需进一步打磨。</p><h2>04.Agent 的展望</h2><p>目前，LLM Agent 大多是处于实验和概念验证的阶段，持续提升 Agent 的能力才能让它真正从科幻走向现实。当然，我们也可以看到，围绕 LLM Agent 的生态也已经开始逐渐丰富，大部分工作都可以归类到以下三个方面进行探索：</p><h3>Agent 模型</h3><p>AgentBench[4] 指出了不同的 LLM 对于 Agent 的处理能力有很大区别，当前的 gpt-4（0613）版本以极大的优势领先于同类竞品，LLM 本身的逻辑推理能力以及更长的 prompt 处理能力都会是 Agent 中极其重要的因素。</p><p>sToolLLM[5] 则使用轻量级的 LLaMA 向更加复杂的大模型学习理解 API 和使用 API 的能力，希望能够将这种能力运用在更轻量的模型上。</p><h3>Agent 框架</h3><p>由 Lilian Weng 列出来的每一个组件都有探索的空间，目前学术探索较多的是利用框架提升 LLM 推理的能力，从 COT[6]、ReAct[7]、Reflexion[8] 等一系列方法，都是在不改变大模型的方法下，利用 prompt 去提升大模型的理性。关于记忆和搜索，目前普遍是将内容存储在数据库和搜索引擎中，Refexion 认为可以将执行过程中的观察以轨迹的形式存储在短期记忆中，而将接受反馈后的评估和自我反省总结的经验放在长期记忆中。在其他方向，AutoGen[9] 也在探索多智能体之间的通信与协作。</p><h3>Agent 应用</h3><p>实现真正意义上的 Agent 道阻且长，因为现实世界具有太多不确定性。在特定、具体的可控环境下，Agent 便可以如工厂中实现一道道供需的机器人一般，针对更多的场景特点进行针对性的设计，从而更好的去完成一些特定的任务，达到预期的效果。</p><p>MetaGPT[10] 是一个针对软件开发场景的 Agent，针对这一具体场景设计了各种具有不同技能的角色协作完成这一任务。Voyager[11] 是一个可以在 Minecraft 中可以进行自主探索、学习技能，并且会合成道具的 Agent。VoxPoser 结合了 RGB-D 信息以及 LLM 的推理能力后，可以完成更多复杂的机器人抓取操作。当下，Agent 尚不能做到完全可靠，针对更多场景的设计可以保障 Agent 不会在大部分简单场景下失败。</p><p>我们置身于一个充满无限可能性的时刻，人工智能的进步将继续塑造我们的未来，而 LLM Agent 无疑是这一演进过程中的亮点之一。人们探索人工智能，最终还是希望能够让人工智帮助人类完成自己无法做到的复杂任务，而 Agent 恰恰是从自动化走向智能化的一个关键的里程碑……</p><h3>参考链接</h3><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flilianweng.github.io%2F" target="_blank">https://lilianweng.github.io/</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSignificant-Gravitas%2FAuto-GPT" target="_blank">https://github.com/Significant-Gravitas/Auto-GPT</a></p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyoheinakajima%2Fbabyagi" target="_blank">https://github.com/yoheinakajima/babyagi</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.03688" target="_blank">https://arxiv.org/abs/2308.03688</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.16789" target="_blank">https://arxiv.org/abs/2307.16789</a></p><p>[6]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2201.11903" target="_blank">https://arxiv.org/abs/2201.11903</a></p><p>[7]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a></p><p>[8]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2303.11366" target="_blank">https://arxiv.org/abs/2303.11366</a></p><p>[9]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.08155" target="_blank">https://arxiv.org/abs/2308.08155</a></p><p>[10]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.00352" target="_blank">https://arxiv.org/abs/2308.00352</a></p><p>[11]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.16291" target="_blank">https://arxiv.org/abs/2305.16291</a></p><p>[12]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.05973" target="_blank">https://arxiv.org/abs/2307.05973</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10140821</guid>
            <link>https://my.oschina.net/u/4209276/blog/10140821</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🎁有奖问答 | 程序员如何入门大数据]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4855753_2331281">高手问答第 308 期 —— 程序员如何入门大数据？</a><div class="ui red label horizontal" data-tooltip="置顶">顶</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4855753" class="__user"><span>OSC 哒哒</span></a><span class="org-label org-label--simple primary" data-tooltip="认证官方账号"><i class="oicon oicon-org"></i></span> 发布于 10/31 12:14
                    </div><div class="item">阅读 2K+</div><div class="item collect-btn " data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331281" data-obj-type="2">6</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4855753_2331281#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">5</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手问答</a></div><div class="content" id="articleContent"><div><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>市面上不少公司都在做用户画像的相关工作，无论是电商行业、金融行业、视频行业等等，都有这样的产品。那到底怎么去定义用户画像呢？</span></span></span></span></span></span></span></span></span></span></span></div><div>
  &nbsp; 
</div><div><strong>OSCHINA 本期高手问答 (10 月 31 日 - 11 月 6 日) 我们请来</strong><strong>了嘉宾&nbsp;</strong><strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">诸葛子房</a>老师&nbsp;</span></strong><strong>来和大家一起探讨关于从 0 到 1 入门用户画像掌握大数据技术的问题。</strong></div><div>
  &nbsp; 
</div><div><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>可讨论的问题包括但不限于：</span></span></span></span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>想入门用户画像需要掌握哪些技术栈？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>没有企业的大量用户或者行为数据，普通用户该如何真实地模拟企业级的画像项目？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>程序员如何入门大数据？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大数据</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>行业都有哪些职位，以及在公司中发挥的作用如何</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大数据行业未来的发展如何，以 ChatGPT&nbsp;为代表的 AI 浪潮是否会让大数据行业走向</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>没落</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li></ul><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>有其他相关问题，也欢迎大家积极提问！</span></span></span></span></span></span></span></span></span></span></span></p><hr><h2>嘉宾介绍</h2><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>段小秋，网名：诸葛子房，先后就职于京东和 BAT，在大数据领域有多年工作经验，也是多个 Apache&nbsp;项目的贡献者。蓝桥杯蓝桥云课《用户画像案例精讲》专栏作者，也是开源项目 DataCompare&nbsp;作者。</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>微信</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>：zhugezifang001，欢迎交流沟通。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>个人</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>主页：</span></span></span></span></span></span></span></span><a href="https://gitee.com/ZhuGeZiFang" rel="nofollow"><span><span><span><u><span style="color:#1e6fff"><span><span>https://gitee.com/ZhuGeZiFang</span></span></span></u></span></span></span></a></span></span></span></p><p><img height="639" src="https://oscimg.oschina.net/oscnet/up-5e58f5cf142af8e6ec1a3b8c3dc1cef16ec.png" width="500" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>为了鼓励踊跃提问，会在问答结束后从提问者中抽取 2 名幸运会员赠予《</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户画像案例精讲》专栏电子版！</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="516" src="https://oscimg.oschina.net/oscnet/up-71771b786f7cc1bd0161793b6af70daf066.png" width="310" referrerpolicy="no-referrer"></p><p><img height="574" src="https://oscimg.oschina.net/oscnet/up-c2d9d9ce8dd66a412d3ef791ee45548dc45.png" width="311" referrerpolicy="no-referrer"></p></div><div><div><hr><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户</span></span></span></span></strong></span></span></span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>画像概念</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户画像，即：用标签的方式去描述一个人或者一台手机、一台电脑，有些公司称之为」用户画像「，有一些公司称之为」用户特征「，其实是一个意思。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>举个简单的例子：</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>袁小青，性别：女，年龄：22 岁，职业：时尚编辑，爱好：音乐、拍照，居住地：北京，消费情况：年薪 10w，喜欢的 app：抖音</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="310" src="https://oscimg.oschina.net/oscnet/up-d3e2ad6f2150ece5dd0882380562cb797a7.png" width="488" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>因此我们概念中描述的用户画像，其实是用标签的方式对于一个用户、一个账号、一部手机进行描述。</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="368" src="https://oscimg.oschina.net/oscnet/up-adc4c1c21829279233af14e8d74631dfab4.png" width="400" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户画像常见标签</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>既然上面讲到了对于用户进行标签化，那究竟要给用户打哪些标签呢？如何对标签进行分类呢？</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>画像核心标签以及其分类：</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="589" src="https://oscimg.oschina.net/oscnet/up-9efa6c4c17cb0bd2647c8d303db9def85cc.png" width="868" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户画像的作用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>1. 个性化推荐</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>在使用一些社区产品、电商产品、短视频 app、音乐 app 的时候，经常会遇到推荐的场景，根据不同的人推荐不同的内容或者商品。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>这其实是用户画像其中的一个应用，根据用户查询用户的标签数据，来进行推荐用户感兴趣的内容</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>2. 营销圈选 (短信营销、PUSH 营销)</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>相信不少用户收到过类似的营销短信，或者一些 app&nbsp;弹窗，这个也是用户画像常见的应用场景</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>3. 策略引擎</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>根据用户的标签展示不同页面，比如说：北京地区的用户能才能领取北京的优惠券，以及只有高消费值的用户才有淘宝上奢侈品 Luxury 入口的界面。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>4. 算法模型</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>算法模型的训练，比如说：推荐模型、广告模型，需要用到画像数据来优化推荐模型。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>5. 画像报告</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>不少商业公司会出一些行业报告，比如说下图的小红书、锁屏 app&nbsp;的行业画像报告；还有我们经常看到的一些个人年度榜单。</span></span></span></span></span></span></span></span></span></span></span></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>大数据技术在用户画像中的实际应用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>由于</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>画像涉及到的一些行为数据，包括用户购物行为、观影行为，一些较为大型一些的公司数据日均都涉及 PB，因此需要处理的数据量非常大。在其中就会用到一些大数据的处理和存储技术，比如说：Hadoop、Spark、Hbase&nbsp;等等。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>同时随着业务发展，一些广告和推荐场景对于实时需求也更加明显，所以实时数据处理领域，Flink、Kafka 等实时相关技术领域也越来越重要了。</span></span></span></span></span></span></span></span></span></span></span></p><hr><div><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手问答一贯的风格，不欢迎任何与主题无关的讨论和喷子。</span></p><p>下面欢迎大家就<span>用户画像和大数据技术相关</span>问题向&nbsp;<strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">诸葛子房</a></span></strong><span style="color:#000000">老师</span><strong><span style="color:#000000">&nbsp;</span></strong>提问，直接回帖提问既可。</p></div></div></div></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331281" data-obj-type="2">6</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331281" data-obj-type="2" data-url="https://www.oschina.net/question/4855753_2331281"><i class="flag red icon"></i>举报</a></div></div>
            ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4855753_2331281</guid>
            <link>https://www.oschina.net/question/4855753_2331281</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 基于连接的可扩展消息传输协议 SocketD]]>
            </title>
            <description>
                <![CDATA[<h1 align="center"><a id="user-content---socketd" class="anchor" href="https://gitee.com/noear/socketd#--socketd"></a>
  SocketD
</h1><p align="center"><strong>基于连接的可扩展消息传输协议</strong></p><p align="center"><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fsearch.maven.org%2Fartifact%2Forg.noear%2Fsocketd"><img src="https://img.shields.io/maven-central/v/org.noear/socketd.svg?label=Maven%20Central" alt="Maven" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.apache.org%2Flicenses%2FLICENSE-2.0.txt"><img src="https://img.shields.io/:license-Apache2-blue.svg" alt="Apache 2" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjavase-jdk8-downloads.html"><img src="https://img.shields.io/badge/JDK-8-green.svg" alt="jdk-8" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk11-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-11-green.svg" alt="jdk-11" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk17-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-17-green.svg" alt="jdk-17" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk21-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-21-green.svg" alt="jdk-21" referrerpolicy="no-referrer"></a><br><a target="_blank" href="https://gitee.com/noear/socketd/stargazers"><img src="https://gitee.com/noear/socketd/badge/star.svg" alt="gitee star" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fnoear%2Fsocketd%2Fstargazers"><img src="https://img.shields.io/github/stars/noear/socketd.svg?logo=github" alt="github star" referrerpolicy="no-referrer"></a></p><br><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DkjB5JNiC"><img src="https://img.shields.io/badge/QQ%E4%BA%A4%E6%B5%81%E7%BE%A4-870505482-orange" referrerpolicy="no-referrer"></a></p><hr><p>SocketD 是一个基于连接的、可扩展的、主题消息驱动的传输协议。主要特性有：</p><ul><li>异步通讯，非阻塞，由主题消息驱动</li><li>语言无关，二进制通信协议（支持 tcp, ws, udp）。支持多语言、多平台</li><li>背压流控，请求时不让你把服务端发死了</li><li>断线重连，自动连接恢复</li><li>双向通讯，单链接双向互发双向互听</li><li>多路复用</li><li>自动分片，数据超出 16Mb，会自动分片、自动重组（udp 除外）</li><li>扩展定制，可以为数据添加 meta 标注（就像 http header）</li><li>接口简单</li></ul><h3><a id="user-content-快速入门与学习" class="anchor" href="https://gitee.com/noear/socketd#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AD%A6%E4%B9%A0"></a>快速入门与学习</h3><p>请点击：<a href="https://gitee.com/noear/socketd/blob/main/_docs">《快速入门与学习》</a>。Java 之外的语言与平台会尽快跟进（欢迎有兴趣的同学加入社区）</p><h3><a id="user-content-适用场景" class="anchor" href="https://gitee.com/noear/socketd#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"></a>适用场景</h3><p>可用于 MSG、RPC、IM、MQ 等一些的场景开发，可替代 Http, Websocket, gRpc 等一些协议。比如移动设备与服务器的连接，比如一些微服务场景等等。</p><h3><a id="user-content-简单的协议" class="anchor" href="https://gitee.com/noear/socketd#%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%8F%E8%AE%AE"></a>简单的协议</h3><ul><li>link (url style)</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">tcp://19.10.2.3:9812/path?u=noear&amp;t=1234</span><span id="LC2" class="line">udp://19.10.2.3:9812/path?u=noear&amp;t=1234</span><span id="LC3" class="line">ws://19.10.2.3:1023/path?u=noear&amp;t=1234</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>codec</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">//udp only &lt;2k, and no auto fragments</span><span id="LC2" class="line">[len:int][flag:int][sid:str(&lt;64)][\n][topic:str(&lt;512)][\n][metaString:str(&lt;4k)][\n][data:byte(&lt;16m)]</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>flag &amp; flow</li></ul><table><thead><tr><th>Flag</th><th>Server</th><th>Client</th><th>备注</th></tr></thead><tbody><tr><td>Unknown</td><td>::close()</td><td>::close()</td><td></td></tr><tr><td>Connect</td><td>/</td><td>c(Connect)-&gt;s(Connack)-&gt;c::onOpen()</td><td></td></tr><tr><td>Connack</td><td>s(Connack)-&gt;c,s::onOpen()</td><td>/</td><td></td></tr><tr><td>Ping</td><td>/</td><td>c(Ping)-&gt;s(Pong)-&gt;c</td><td></td></tr><tr><td>Pong</td><td>s(Pong)-&gt;c</td><td>/</td><td></td></tr><tr><td>Close</td><td>s(Close)-&gt;c::onClose()</td><td>c(Close)-&gt;s::onClose()</td><td>用于特殊场景（如：udp）</td></tr><tr><td>Message</td><td>s(Message)-&gt;c</td><td>c(Message)-&gt;s</td><td></td></tr><tr><td>Request</td><td>s(Request)-&gt;c(Reply or ReplyEnd)-&gt;s</td><td>c(Request)-&gt;s(Reply or ReplyEnd)-&gt;c</td><td></td></tr><tr><td>Subscribe</td><td>s(Subscribe)-&gt;c(Reply...ReplyEnd)-&gt;s</td><td>c(Subscribe)-&gt;s(Reply...ReplyEnd)-&gt;c</td><td></td></tr><tr><td>Reply</td><td>-&gt;s(Reply)-&gt;c</td><td>-&gt;c(Reply)-&gt;s</td><td></td></tr><tr><td>ReplyEnd</td><td>-&gt;s(ReplyEnd)-&gt;c</td><td>-&gt;c(ReplyEnd)-&gt;s</td><td>结束答复</td></tr></tbody></table><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">//The reply acceptor registration in the channel is removed after the reply is completed</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-加入到交流群" class="anchor" href="https://gitee.com/noear/socketd#%E5%8A%A0%E5%85%A5%E5%88%B0%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>加入到交流群：</h3><table><thead><tr><th>QQ 交流群：870505482</th><th>微信交流群（申请时输入：SocketD）</th></tr></thead><tbody><tr><td></td><td><img src="https://gitee.com/noear/socketd/raw/main/group_wx.png" width="120" referrerpolicy="no-referrer"></td></tr></tbody></table><p>交流群里，会提供 "保姆级" 支持和帮助。如有需要，也可提供技术培训和顾问服务</p><h3><a id="user-content-第一个程序你好世界" class="anchor" href="https://gitee.com/noear/socketd#%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E4%BD%A0%E5%A5%BD%E4%B8%96%E7%95%8C"></a>第一个程序：你好世界！</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">public</span><span class="kd">class</span><span class="nc">Demo</span><span class="o">{</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kd">static</span><span class="kt">void</span><span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span><span class="n">args</span><span class="o">)</span><span class="kd">throws</span><span class="nc">Throwable</span><span class="o">{</span></span><span id="LC3" class="line"><span class="c1">//::启动服务端</span></span><span id="LC4" class="line"><span class="nc">SocketD</span><span class="o">.</span><span class="na">createServer</span><span class="o">(</span><span class="k">new</span><span class="nc">ServerConfig</span><span class="o">(</span><span class="s">"tcp"</span><span class="o">).</span><span class="na">port</span><span class="o">(</span><span class="mi">8602</span><span class="o">))</span></span><span id="LC5" class="line"><span class="o">.</span><span class="na">listen</span><span class="o">(</span><span class="k">new</span><span class="nc">SimpleListener</span><span class="o">(){</span></span><span id="LC6" class="line"><span class="nd">@Override</span></span><span id="LC7" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">onMessage</span><span class="o">(</span><span class="nc">Session</span><span class="n">session</span><span class="o">,</span><span class="nc">Message</span><span class="n">message</span><span class="o">)</span><span class="kd">throws</span><span class="nc">IOException</span><span class="o">{</span></span><span id="LC8" class="line"><span class="k">if</span><span class="o">(</span><span class="n">message</span><span class="o">.</span><span class="na">isRequest</span><span class="o">()){</span></span><span id="LC9" class="line"><span class="n">session</span><span class="o">.</span><span class="na">replyEnd</span><span class="o">(</span><span class="n">message</span><span class="o">,</span><span class="k">new</span><span class="nc">StringEntity</span><span class="o">(</span><span class="s">"And you too."</span><span class="o">));</span></span><span id="LC10" class="line"><span class="o">}</span></span><span id="LC11" class="line"><span class="o">}</span></span><span id="LC12" class="line"><span class="o">})</span></span><span id="LC13" class="line"><span class="o">.</span><span class="na">start</span><span class="o">();</span></span><span id="LC14" class="line"></span><span id="LC15" class="line"><span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span><span class="c1">//等会儿，确保服务端启动完成</span></span><span id="LC16" class="line"></span><span id="LC17" class="line"><span class="c1">//::打开客户端会话</span></span><span id="LC18" class="line"><span class="nc">Session</span><span class="n">session</span><span class="o">=</span><span class="nc">SocketD</span><span class="o">.</span><span class="na">createClient</span><span class="o">(</span><span class="s">"tcp://127.0.0.1:8602/hello?token=1b0VsGusEkddgr3d"</span><span class="o">)</span></span><span id="LC19" class="line"><span class="o">.</span><span class="na">open</span><span class="o">();</span></span><span id="LC20" class="line"></span><span id="LC21" class="line"><span class="c1">//发送并请求（且，收回答复）</span></span><span id="LC22" class="line"><span class="nc">Entity</span><span class="n">reply</span><span class="o">=</span><span class="n">session</span><span class="o">.</span><span class="na">sendAndRequest</span><span class="o">(</span><span class="s">"/demo"</span><span class="o">,</span><span class="k">new</span><span class="nc">StringEntity</span><span class="o">(</span><span class="s">"Hello wrold!"</span><span class="o">).</span><span class="na">meta</span><span class="o">(</span><span class="s">"user"</span><span class="o">,</span><span class="s">"noear"</span><span class="o">));</span></span><span id="LC23" class="line"><span class="o">}</span></span><span id="LC24" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/noear/socketd</guid>
            <link>https://gitee.com/noear/socketd</link>
        </item>
        <item>
            <title>
                <![CDATA[云几何内核开源平台 —— OpenGeometry 开源社区正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 5 日，由广东省工业和信息化厅、广东省科学技术厅、广东省教育厅、深圳市人民政府主办，工业和信息化部第五研究所、广东省数字化学会承办，深圳市工业和信息化局、深圳市龙岗区人民政府、深圳市福田区人民政府协办的 2023 工业软件生态大会在广东省深圳市召开。</p><p>在大会主论坛上，国内备受关注的云几何内核开源平台——OpenGeometry 开源社区正式发布。</p><p><img src="https://static.oschina.net/uploads/space/2023/1106/104536_bRwO_2720166.png" referrerpolicy="no-referrer"></p><p>据介绍，OpenGeometry Group（简称 OGG）是由数字化工业软件联盟孵化，并由开元几何（深圳）科技有限公司作为服务公司运营的开源项目。OpenGeometry 开源社区将通过搭建云几何内核的开源软件开发平台，构建新一代工业软件的核心「根」技术，为工业软件的产品研发提供支持，并带动上下游厂商、服务商等合作伙伴共同参与，最终形成产业链协同发展的良性循环。</p><p>OpenGeometry 开源社区表示，未来将积极与科研院校、工业软件厂商、工业软件应用企业、开发者等合作伙伴进行广泛的技术交流和合作，引进国内外最先进的技术、吸引顶尖的人才，引入数字化工业软件联盟的生态资源，深入电子、汽车、装备制造等行业应用中进行场景化联合研发，真正做到以高质量的技术更好地服务产业实体经济。</p><div>
 北师大港浸大的单肖文教授代在会上表示，OpenGeometry 开源社区对中国工业软件界意义很大，是构筑工业软件的「根」，只有「根」扎得深，工业软件的树才能枝繁叶茂。
</div></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265108</guid>
            <link>https://www.oschina.net/news/265108</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[轻松理解 Transformers (3): Feed-Forward Layer 部分]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>编者按：随着人工智能技术的不断发展 Transformer 架构已经成为了当今最为热门的话题之一。前馈层作为 Transformer 架构中的重要组成部分，其作用和特点备受关注。本文通过浅显易懂的语言和生活中的例子，帮助读者逐步理解 Transformers 中的前馈层。</p><p>本文是 Transformers 系列的第三篇。作者的观点是：前馈层在 Transformer 架构中扮演着至关重要的角色，它能够有效地提高计算效率，同时也是集体智慧的体现。</p><p>文章作者首先介绍了前馈层的基本结构，它由全连接层组成，进行线性变换和线性计算。但也存在局限性，不能进行复杂的非线性变换。所以前馈层需要激活函数（如 ReLU）进行非线性转换，增强网络的表达能力。为防止模型仅记忆数据特征而不具备推理能力，需要使用正则化技术如 dropout。相信通过本文的阅读，读者将对 Transformer 中的前馈层有更深入的理解。</p><p>随着深度学习在语音、图像、自然语言处理等领域取得突破，人工智能或许正向着真正的通用人工智能迈进。但要培养通用人工智能，我们还需不断深入理解其中的原理和相关机制。</p><p>以下是译文，enjoy！</p></blockquote><p><strong>作者 | Chen Margalit</strong></p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fchen-margalit%2F" target="_blank">https://www.linkedin.com/in/chen-margalit/</a></strong></p><p><strong>编译 | 岳扬</strong></p><p><em><strong>本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。</strong></em></p><p><em>原文链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftowardsdatascience.com%2Fsimplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9" target="_blank">https://towardsdatascience.com/simplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9</a></em></p><p>本节将介绍前馈层（Feed-Forward layer），这是大多数深度学习架构中的基础元素。在有关深度学习的常见话题交流时，一般都会强调它们在构造 Transformer 架构中的重要作用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a856aacefd53ae8070b810c099e0da6711.png" alt="" referrerpolicy="no-referrer"><em>原论文中的图片[1]</em></p><p>前馈全连接层（feed-forward linear layer）基本上就是一堆神经元，每个神经元都与其他神经元相连接。请看下图，其中 a、b、c 和 d 是神经元。这些神经元包含了一些 input（即一些我们想要理解的数据（像素值（pixels）、词嵌入（word embeddings）等））。它们与编号为 1 的神经元相连。每两个神经元之间的连接都有不同的连接权重值（connection strength）。例如，a-1 是 0.12，b-1 是-0.3，等等。实际上，左列中的所有神经元都与右列中的所有神经元相连。但是为了清晰起见，我没有在图像中展示全部的连接，你需要了解这一情况。就像图中有 a-1 一样，还应该有 a-2、b-2、c-2、d-3 等。两个神经元之间的每个连接都有不同的「连接权重」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f139aa760b0e5733e14a61f50803820e023.png" alt="" referrerpolicy="no-referrer"></p><p><em>该图由原文作者绘制</em></p><p>该架构有两点值得注意：</p><ol><li>如前所述，每个节点（神经元）都与其他节点相连。所有的 a、b、c、d 都与其他神经元（1、2、3）相连。可以将这幅图像看作是一条军队指挥链。1、2、3 是指挥官。他们从士兵 a、b、c、d 那里得到情报。a 知道某件事情的一些细节，但它的情报不够全面。1 知道的就更多了，因为它能够从 a、b、c 和 d 那里同时得到情报。2 和 3 也是指挥官，同样从 a、b、c、d 那里获取情报。这些指挥官（1、2、3）也会向更高级的指挥官传递报告。在他们之后的指挥官既从 a、b、c、d 那里得到情报，也从 1、2、3 那里得到情报，因为下一层（每列神经元为一层）也是以完全相同的方式进行全连接的。因此，首先要明白的是， 1 的情报比 a 更全面，而下一层指挥官的情报也比 1 更全面。</li><li>第二点需要注意的是，每个节点与下一层的每个其他节点之间的连接权重是不同的。a-1 是 0.12，b-1 是-0.3。我在这里给出的数字显然是虚构的，但它们也是在合理的范围内，并且它们都是自动学习调整的参数（learned parameters）（例如，它们在训练过程中会发生变化）。把这些数字看作是 1 对 a、b 等的影响程度。从 1 号指挥官的角度来看，a 的情报有一定的可信度。但不应该想当然地相信他说的每一句话，可以选择性地相信他说的某些话。b 则截然不同。这个节点通常会低估它接收到的输入（情报）的重要性，就像一个悠闲的人一样。「这是一只 tiger 吗？不，只是一只 big cat。」 这是对发生的事情的过度简化，但重要的是要注意这一点：<strong>每个神经元都掌握着一些 input（无论是原始输入还是经过处理的 input）并进行处理后将其传递下去。</strong></li></ol><p>你知道「传话游戏」吗？你和其他 10 个人坐成一排，然后你向下一个人耳语一个词，比如说「Pizza」。第 2 个人听成了类似「Pazza」的词，于是他们把「Pazza」传给了第 3 个人。第 3 个人听成了 「Lassa」（毕竟是耳语），于是他把 「Lassa」传给了第 4 个人。第 4 个人听成了 「Batata」，于是他又转述了 「Batata」，以此类推。当你问第 10 个人他听到了什么？结果他回答「Shambala」，我们是怎么从「Pizza」到「Shambala」的？这个游戏与神经网络的区别在于，每个人都会对信息进行处理。第二个人不会说 「Pazza」，他会说「Pazza 是意大利菜，很好吃」。第三个人会说：「Lassa 是一道意大利菜，在全世界都很常见」，等等。每个人（层）都会补充一些他们希望有用的东西。</p><p>基本情况就是这样。<strong>每个神经元获得输入，处理输入，然后继续传递。</strong> 为了与全连接层（fully connected layer）相匹配，我建议对这个游戏进行升级：从现在开始，在游戏中引入多行人，每个人都可以对每一行中的其他人说悄悄话。从每一行的第 2 位开始，每个人都会收到很多人的悄悄话，他们需要了解每个人说的话语的「权重」（重要性），这就是前馈层（Feed Forward Layer）。</p><p><strong>为什么我们要使用前馈层？因为它们使我们的计算能够更加有效，可以将其类比为集体智慧的体现。</strong> 讲一个关于「猜测一头牛重量」的故事吧！1906 年，在英国的某个地方，有人把一头牛带到一个展览会上。主持人随机挑选了 787 名观览者，请他们猜测这头牛的重量。你认为他们猜测的结果会是多少？这头牛的实际体重是多少呢？</p><p>他们猜测的平均值是 1197 磅（542 公斤）。这些都是随机抽取的群众对牛体重的估计。这个平均猜测值离真实重量相差多远呢？只有 1 磅差距，也就是 450 克。这头牛的重量是 1198 磅。这个故事来自这里[2]，我不确定细节是否准确，但回到本文的主题，我们可以把线性层 <em>（译者</em><em>注：此处即本文所说的前馈层）</em> 看作是在做类似的事情。通过增加更多的参数、更多的计算（更多的猜测），就可以得到更准确的结果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1dd0ad28fe0fffea90238839fce31188c1e.png" alt="" referrerpolicy="no-referrer"></p><p><em>照片由 Larry Costales[3] 在 Unsplash[4] 上发布</em></p><p>让我们试着想象一个真实的使用场景。给神经网络输入一张图片，让它判断图片里的是苹果还是橙子。这种架构基于卷积神经网络（CNN）层，本文不会深入讨论这个知识点，因为其超出了本系列文章的范围。但该层是一个能够学习和识别图像中特定模式（specific patterns）的计算层。 <em>（译者注：这些特定模式的识别有助于网络进行更准确的分类和判断，例如判断图像中是苹果还是橙子。）</em> 每一层都能识别更复杂的模式。例如，第一层几乎不能识别出任何东西，该层只是传递原始像素，第二层就能够识别出垂直线条。如果下一层同时接收到有垂直线条的信息，并从其他神经元那里听说还有非常接近的垂直线条。它会将两者综合起来进行计算、分析，然后思考：不错！这是一个角落。这就是从多个来源获取输入信息的好处。</p><p>我们可能会认为，进行计算的次数越多，得到的结果就越好。但事实上，并非完全是这样，但确实有一定的道理。如果我们做更多的计算，咨询更多人（神经元）的意见，通常就能得出更好的结果。</p><h1><strong>01 激活函数 Activation Function</strong></h1><p>接下来将介绍深度学习中另一个非常重要的基本概念的关键组成部分——激活函数，并探讨它与 Transformer 的关系，以便更好地理解两者之间的关联。</p><p>尽管全连接层（Fully connected layers）的使用非常广泛，但也存在一个很大的缺点——<strong>它们是线性层（linear layers），只能进行线性变换和线性计算。全连接层可以进行加法和乘法运算，但无法以「创造性」的方式转换输入（input）。有时候，仅仅增加计算量是不够的，需要以完全不同的思考方式来解决问题。</strong></p><p>如果我每天工作 10 个小时，每天赚 10 美元，如果我想更快地存下 1 万美元，我可以每周工作更多天，或者每天工作更多小时。但是肯定还有其他解决方案，对吧？有很多人不需要他们拥有的钱（我可以更好地利用它），或者我可以找到更高薪的工作等等。解决办法并不总是千篇一律。</p><p>同理，在本文的情况下，激活函数可以来提供帮助。激活函数能够帮助我们进行非线性变换（non-linear transformation）。例如，将一个数字列表[1, 4, -3, 5.6]转换为概率分布，就是 Softmax 激活函数的作用。该激活函数能够将这些数字转换为[8.29268754e-03, 1.66563082e-01, 1.51885870e-04, 8.24992345e-01]这样的输出。这 5 个数字相加等于 1。虽然这些数字看起来有些混乱，但 e-03 表示第一个数字（8）在小数点后 3 个零开始（例如 0.00，然后是 82926。实际上该数字是 0.00829268754）。<strong>这个 Softmax 激活函数将整数转换为 0 到 1 之间的浮点数，转换后的浮点数仍然保持了原始整数之间的相对大小关系。这种保持相对大小关系的特性在统计学中非常有用。</strong></p><p>还有其他类型的激活函数，其中最常用的之一是 ReLU（修正线性单元）。这是一种非常简单（同时也非常有用）的激活函数，它能够将任何负数转化为 0，而非负数保持不变。非常简单且实用。如果我将列表[1, -3, 2]输入 ReLU 函数，会得到[1, 0, 2]。</p><p>在介绍完复杂的 Softmax 之后，你可能会期望一些更复杂的东西，但有人曾经告诉我「Luck is useful」。有了激活函数后，我们就走运了。</p><p>我们之所以需要这些激活函数，是因为非线性关系（nonlinear relationship）无法通过线性计算（全连接层）来表示。如果我每工作一小时就能得到 10 美元，那么收入就是线性关系。如果我每连续工作 5 个小时，接下来的 5 个小时就能增加 10%，那么这种关系就不再是线性的了。我的工资不再是工作小时数乘以固定的小时工资。<strong>在文本生成等更复杂的任务中使用深度学习，就是因为我们要建模的关系高度非线性。</strong> 在「我喜欢」之后能出现的词并不是固定的。</p><p>ReLU 的一大优势，也许可以解释它为何被广泛使用，就是<strong>对大量数据进行计算的成本非常低。</strong> 当神经元数量较少时（比方说几万个），计算量并不重要。但是当像大语言模型那样使用数千亿个神经元时，一种更高效的计算方式会带来巨大差异。</p><h1><strong>02 正则化 Regularization</strong></h1><p>在解释 Transformer 中如何实现正则化（非常简单）之前，我们将介绍最后一个概念——dropout，这是一种正则化技术。由于算法是基于数据的，并且它们的任务是尽可能逼近训练目标，所以对于一个大脑聪明的人来说，有时仅仅记住一点点东西就足够了。正如我们在学校中所受到的教育，学习复杂的逻辑并不总是有用的，我们有时只需记住我们所见过的，或者记住与之接近的东西。第二次世界大战是什么时候发生的？嗯...它受到了第一次世界大战、经济危机、人民愤怒等等因素的影响...大约是 1917 年左右...所以我们就说是 1928 年吧。记住确切的日期可能更好。</p><p>可以想象，这对机器学习来说并不是好事。如果我们需要的是已经有答案的问题的答案，我们就不需要这些复杂的技术了。我们需要一个聪明的算法，因为我们无法记住所有的东西。我们需要它进行实时推理，进行思考。<strong>正则化（Regularization）是让算法仅学习不记忆的一系列技术的总称。在这些正则化技术中，一种常用的技术就是 dropout。</strong></p><h1><strong>03 Dropout</strong></h1><p>dropout 可以说是一种相当简单的技术。还记得我们说过全连接层（fully connected layers）是完全连接的吗？dropout 打破了这种逻辑。dropout 技术将「连接权重（connection strength）」设置为 0，这意味着该连接不会产生任何影响。对于 1 号指挥官来说，连接到士兵「a」的输入变为 0 时，「a」传递的情报会变得完全无用。不回答，不肯定，也不否定。<strong>我们在每一层中使用 dropout 技术时，会随机选择一定数量的神经元（由开发者配置），并将它们与其他神经元的连接权重设为 0。</strong> 每次指挥官会被迫忽略不同的士兵，因此无法记住其中任何一个士兵，因为下次可能不会再遇到它们传递情报。</p><h1><strong>04 回到 Transformer！</strong></h1><p>现在我们已经掌握了理解 Transformer 中前馈层工作原理所需的所有基础知识。接下来解释实现过程就会非常简单了。It will now be very simple.</p><p><img src="https://oscimg.oschina.net/oscnet/up-d58c4da377e46953ddd77cd2bcb9c4fdd64.png" alt="" referrerpolicy="no-referrer"></p><p><em>图片来自 Vaswani, A. 等人的论文[5]</em></p><p>在原论文中的架构图中，前馈线性层只做了四件事情：</p><ul><li><strong>对文本中的每个位置 (用向量表示)，进行逐位置的线性计算。</strong></li><li><strong>对线性运算的输出应用 ReLU 函数。</strong></li><li><strong>对上一步骤 ReLU 运算的输出进行再一次线性运算。</strong></li><li><strong>最后，将其添加到第 3 层的输出中。</strong></li></ul><p>就是这样。如果你有深度学习领域的相关经验，那么理解这一部分对你来说可能很容易。如果你没有经验，可能稍显吃力，但你已经理解了深度学习中一个极为重要的组成部分。</p><p>在下一部分,我们将介绍 Transformer 中的解码器 (Decoder) 部分相关知识！</p><p><strong>END</strong></p><h1><strong>参考资料</strong></h1><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wondriumdaily.com%2Fthe-wisdom-of-crowds%2F%23%3A%7E%3Atext%3DAn%2520Astonishing%2520Example%2520of%2520the%2520Wisdom%2520of%2520Crowds%26text%3DThe%2520actual%2520weight%2520of%2520the%2Cthat%2520weight%2520was%25201%252C197%2520pounds" target="_blank">https://www.wondriumdaily.com/the-wisdom-of-crowds/#:~:text=An%20Astonishing%20Example%20of%20the%20Wisdom%20of%20Crowds&amp;text=The%20actual%20weight%20of%20the,that%20weight%20was%201%2C197%20pounds</a>.</p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2F%40larry3%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/@larry3?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2Fphotos%2FAhf1ZmcKzgE%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/photos/Ahf1ZmcKzgE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/10141048</guid>
            <link>https://my.oschina.net/IDP/blog/10141048</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维「天工」大模型正式向全社会开放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 11 月 3 日，昆仑万维「天工」大模型宣布通过《生成式人工智能服务管理暂行办法》备案，面向全社会开放服务！</p><p>用户在应用商店下载「天工 APP」或登陆「天工官网」（<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.tiangong.cn" target="_blank">www.tiangong.cn</a>）均可直接注册使用。</p><p>官方介绍称，「天工」是国内首个对标 ChatGPT 的双千亿级大语言模型，也是一个 AI 搜索引擎，一个对话式 AI 助手。「天工」拥有强大的自然语言处理和智能交互能力，能够实现个性化 AI 搜索、智能问答、聊天互动、文本生成、编写代码、语言翻译等多种应用场景，并且具有丰富的知识储备，涵盖科学、技术、文化、艺术、历史等领域。</p><p><img height="232" src="https://oscimg.oschina.net/oscnet/up-4220721cc203df8b9704c1aa7e7fb303f00.png" width="500" referrerpolicy="no-referrer"></p><p>2022 年 12 月 15 日，昆仑万维在北京举行 AIGC 技术发布会，发布自研 AIGC 全系列算法与模型，覆盖了图像、音乐、文本、编程等多模态的 AI 内容生成能力。</p><p>2023 年 4 月 17 日，昆仑万维正式发布自研千亿级大语言模型「天工」，同时宣布启动邀请测试。「天工」用过通过自然语言与用户进行问答式交互，AI 生成能力可满足文案创作、知识问答、代码编程、逻辑推演、数理推算等多元化需求。</p><p>2023 年 5 月 19 日，北京市经济和信息化局公布第一批《北京市通用人工智能产业创新伙伴计划成员名单》。昆仑万维成为第一批模型伙伴和投资伙伴。</p><p>2023 年 8 月 23 日，昆仑万维推出国内第一款 AI 搜索产品——「天工 AI 搜索」，并开启内测申请。「天工 AI 搜索」深度融合 AI 大模型能力，通过人性化、智能化的方式全面提升用户的搜索体验，为用户提供快速、可靠的交互式搜索服务，并集成 AI 对话、AI 写作等常用功能，帮助用户提升工作效率，全面重塑中文搜索体验。</p><p>2023 年 9 月，昆仑万维多模态大模型 Skywork-MM 在腾讯优图实验室联合厦门大学开展的多模态大语言模型测评 MME 中，综合得分排名第一。该评测首次对全球范围内 MLLM 模型进行了全面定量评测并公布了 16 个排行榜，包含感知、认知两个总榜单以及 14 个子榜单。Skywork-MM 模型位列综合榜单第一，其中，感知榜单排名第一、认知榜单排名第二。</p><p>2023 年 9 月 16 日，在权威推理榜单 Benchmark GSM8K 测试中，昆仑万维「天工」大模型以 80% 的正确率脱颖而出，大幅领先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%）。</p><p>2023 年 9 月 17 日，昆仑万维通过信通院「可信 AI」评估，并被评选为人工智能实验室副组长单位。经中国信通院评估，昆仑万维天工大模型符合 AIIA/PG 0071-2023、AIIA/PG 0072-2023 评估标准，模型开发、以及模型能力均达到了「4+级」。</p><p>10 月 30 日，昆仑万维开源百亿级大语言模型「天工」Skywork-13B 系列，并配套开源了 600GB、150B Tokens 的超大高质量开源中文数据集。「天工」Skywork-13B 系列目前包括 130 亿参数的两大模型，Skywork-13B-Base 模型、Skywork-13B-Math 模型，它们在 CEVAL、GSM8K 等多个权威评测与基准测试上都展现了同等规模模型的最佳效果，其中文能力尤为出色，在中文科技、金融、政务等领域表现均高于其他开源模型。同时，昆仑万维「天工」Skywork-13B 系列大模型全面开放商用——开发者无需申请，即可商用。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 03 Nov 2023 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264987</guid>
            <link>https://www.oschina.net/news/264987</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[WinterJS —— Rust 编写的 Service Worker]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>WinterJS 是用 Rust 编写的 JavaScript Service Worker。</p><p>WinterJS 使用 SpiderMonkey 运行时执行 JavaScript（与 Firefox 使用的运行时相同），并遵循 WinterCG 规范，目的是最大限度地兼容 Cloudflare Workers、Deno Deploy 和 Vercel 等其他服务（因此命名为 WinterJS）。</p><p>WinterJS 除了速度极快，还能通过 WASIX&nbsp;<strong>编译成 WebAssembly</strong>，因此完全支持在 Wasmer 上运行。</p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 03 Nov 2023 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/winterjs</guid>
            <link>https://www.oschina.net/p/winterjs</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 复用性风控：软件复用成本的量化管理]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:justify">复用性（Reusability）是软件工程中一个被频频使用的术语，它一般作为产品的卖点被宣传，或者出现在技术设计文档之中。大部分看到这个概念的的受众只是将其作为一个积极的软件非功能属性去理解，但却忽略了其背后隐藏的风险。本文从另一个角度出发，去分析「复用性」这一概念背后的风险及成因，借助笔者在业务安全和基础安全的一点经验，提出了一个在软件研发流程中，管理「复用性成本风险」的风险管理模型。从模型出发，我们可以认识到实现复用时面临的各项挑战、开发认知谬误、复用成本的形式化定义方法等，希望这些输入能为读者在后续的技术决策和软件研发流程提供些许帮助。</p><p style="text-align:justify">本文主要分为三个部分：第一部分介绍复用性的定义以及不合理复用引入的主要技术债，第二部分分析复用性失效的原因；第三部分为复用性软件资产的构建方和使用方提供一个形式化的度量工具，该工具将奠定后续风险管理模型评估阶段定量分析的基础；第四部分提出一个用于管理「复用性风险」的模型，覆盖软件研发生命周期的全流程，通过事前评估、事中缓释和事后迭代三个环节最大程度地降低由于软件复用带来的软件开发和维护成本。</p><span id="OSC_h3_1"></span><h3>一、复用性的理想与现实</h3><span id="OSC_h4_2"></span><h4><strong>1.1 复用定义：从代码到系统</strong></h4><p style="text-align:justify">软件复用是解决软件质量和生产力问题的一种方法，它指的是在软件开发过程中重复使用相同或相似的软件元素。通过合理利用软件复用技术，我们可以提高开发效率，并且降低开发过程中的错误率。同时，软件复用还可以促进团队协作和知识共享，使得开发者们能够更好地利用彼此的经验和资源。因此，在当今快节奏的开发环境中，软件复用已经成为提高生产力和质量的关键策略之一。在过去几十年的时间里，很多编程语言的成功（Python、Java 等）和开源文化的蓬勃发展，都与复用密不可分。软件复用可以在不同粒度上进行，包括代码和设计拷贝、源代码复用、设计和软件体系结构复用以及领域特定的软件体系结构复用等。早期的软件复用主要集中在代码级别，例如共享方法、抽象类、库、微服务和 Docker 镜像等。随着时间推移，其外延拓展至领域知识、开发经验、设计文档、需求分析和测试用例及数据等在不同阶段所产生的各种软件产品。<strong>在本文中，除非特别说明，复用性主要指的就是聚焦代码的复用，下文中的「组件复用」，不仅限于通常我们认知中的公共库，还包括代码方法、公共类、软件框架、可集成系统等软件开发中的可复用元素。</strong></p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-963651fba23c39dc34c4a58a1a6eaacb_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_3"></span><h4><strong>1.2 复用风险：复杂度和成本</strong></h4><p style="text-align:justify">诚然，通过组件的复用可以提高软件开发效率和质量，但复用不是银弹，复用也会有一些副作用：</p><p style="text-align:justify">1.兼容性/安全性/性能；</p><p style="text-align:justify">2.增加了系统间的依赖；</p><p style="text-align:justify">3.增加了开发和维护成本。</p><p style="text-align:justify"><strong>首先，兼容性/安全性/性能</strong>等这几类问题，是针对可复用组件的使用方来说的，一般来说，在决策是否复用之前就可以评估，其指标和过程也比较清晰，这里就不具体展开了。</p><p style="text-align:justify"><strong>其次，复用会增加系统依赖。</strong>依赖关系是软件的基本组成部分，无法消除，但软件设计的目标之一是尽可能消除依赖关系，并使依赖关系尽可能简单和明显。当我们引入外部组件进行复用时，软件组件之间的依赖关系会导致组件变更范围的扩大以及组件认知负荷的增加，前者是针对组件维护方而言的，即看似简单的变更需要在许多不同的地方修改代码，<strong>随着消费者数量的增长，在不同需求之间进行平衡变得越来越困难；</strong>后者是对于组件使用方而言的，即开发人员需要了解大量组件领域知识才能实现有效的组件复用。比如，需要了解待使用接口中若干入参的设计意图、是否存在隐式依赖传递从而导致依赖冲突等。依赖的增加会为系统引入更多的复杂性，而我们知道，构建软件系统的核心挑战就是管理复杂性，复用组件只会在一定程度上转移复杂性，但并不能消除复杂性。因此，我们需要在「复用组件降低成本」和「复用组件引入依赖（复杂性）」之间取得平衡。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-3612b21399b66c7600b9f27155d86f92_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify"><strong>最后，复用会增加各项成本。</strong>包括开发的成本、变更的成本、集成的成本、领域知识迁移的成本。对于一个面向复用设计的组件来说，实现正确抽象和通用框架的设计和开发成本，比一次性的解决方案高得多，对于组件的后续维护者来说，这样的可复用框架和库通常也会带来陡峭的学习曲线（因为文档一般是缺失的），组件会逐渐走向腐化，最后不得不推倒重来。此外，对于可复用组件的使用方来说，其理解和集成组件的成本通常也是被忽略的，一些强推的业务层的「伪复用框架」给前台集成的同学带来了巨大的集成、学习和维护成本。</p><p style="text-align:justify">上述复用带来问题，有一些是可以规避的，如兼容性、性能、容量等的匹配度，有一些是无法避免的，如设计通用化组件的开发成本、不合理的抽象导致的代码腐化、不合理的复用导致的维护成本等。事实上，无论我们在技术上做多么精妙的设计，技术的创新永远滞后于系统的腐化速度。</p><p style="text-align:justify">为了最大程度的降低复用带来的风险，本文提出一套从类比于安全风险管理的「复用性风险」应对模型，从事前评估、事中缓释、事后迭代三个阶段出发，最大程度地降低我们在开发可复用组件、使用可复用组件中遇到的各类风险。需要说明的是，<strong>上面以及后面指的「复用性风险」，定义为「由于不合理的复用决策，导致依赖和复杂度膨胀过快，从而导致软件维护成本过高」的问题，</strong>除了成本风险外，由于复用组件的不合理使用或存在的缺陷而导致的兼容性、安全性、性能等方面的风险，其风险更为显著和易于治理，因此不是本文论述的重点。此外，复用开发过程中的开发目标偏移、迭代和发布计划的延期、人员短缺等风险，限于篇幅也不在这里展开。</p><p style="text-align:justify">第二部分首先会介绍导致「复用提升软件开发效率」这一原则失效的几类主要原因，第三部分会重点介绍用于评估复用性的若干工具，有了对复用性本质的认识后，再第四部分我们会简要介绍复用性风险管理模型。</p><span id="OSC_h3_4"></span><h3>二、复用性风险根因分析</h3><span id="OSC_h4_5"></span><h4><strong>2.1 现实挑战：正确和错误的抽象</strong></h4><p style="text-align:justify">我们复用组件的一个初衷，除了是为了提升研发效率之外，也是希望可复用组件可以将领域的复杂性隔离在一个我们永远看不到的地方，从而整体降低组件使用方的系统复杂度。因此，一个可复用的组件，无论其规模大小，其设计过程就是对某个领域高度抽象的过程。在设计组件时，向上面对当前或潜在的需求，需要我们做一定的前向通用设计，向下尽可能屏蔽掉组件的实现细节，抽象的结果直接决定了后续该组件可复用性程度的高低（可复用性的度量将在下一个章节详述）。但遗憾的是，良好的抽象能力对于大部分开发者来说是一个稀缺的产物，它需要对问题进行清晰的定义、简化和分解，同时识别和利用通用模式，将子问题的解法组合起来形成一个整体解决方案，依赖对设计模式、开源的库和框架、数据结构和算法以及大量生产项目的长期实践和思考。</p><p style="text-align:justify">在日常的代码中，我们不乏抽象，但大部分都是不合理的抽象。错误的抽象造成的危害甚于不抽象，比如常见的一个现象：对设计模式的适用范围知之甚少，仅仅为了炫技而滥用设计模式，导致代码的可读性和可维护性下降。</p><p style="text-align:justify">除了对抽象能力的要求外，很多时候需求紧迫度、开发资源、责任心以及组件所在领域职责的变更等因素，都会导致可复用组件从出生就带着「高成本」的原罪，其后续的使用成本和维护成本会急剧上升，这里就不一一展开了。</p><span id="OSC_h4_6"></span><h4><strong>2.2 认知谬误：复用不是设计目标</strong></h4><p style="text-align:justify">一个对于复用性的认知谬误就是，把「不重复」等效为「复用」，这两个概念之间有相似之处，但还是有一些微妙的差别。「不重复」即我们所熟知的 DRY 原则（Don’t Repeat Yourself），其目标是通过减少重复建设从而避免承担副本不一致的维护成本，而 Reusability 是从所有代码中找到重复的部分，然后在复杂度可控的前提下，努力抽象出可复用的东西。一堆不重复的代码，并不代表存在可复用的组件。</p><p style="text-align:justify"><strong>复用只是实现不重复目标的一种手段，「不重复」才是我们设计软件系统时的目标，单纯追逐「复用性」很多时候会出现一些本末倒置的现象。</strong>如出现了一些接入成本非常高的自动测试框架、业务中台框架，一味追逐「（我）一次开发，（你）随处使用」，殊不知在使用方需要消耗大量的精力去内化框架设计者的设计初衷，面对十几个接入参数或配置文件一筹莫展。</p><p style="text-align:justify">举个例子，偶尔会看到我们在业务层代码中，部分同学会把简单的新增和修改逻辑抽象为一个方法，美其名曰「提供给接入层复用」，如下面的 insertOrUpdate 方法中，初看是复用了领域对象转换和用户对象是否存在的代码，符合 DRY 原则，但实际上却是混用了两个不同的业务语义，会给后续的维护带来较高的成本，如变更用户信息时，需要做更个性化的用户属性处理，这时候调整领域对象转换处的代码，将会影响新增逻辑。</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-3c8e7289db213680d7aa473520b964c9_720w.webp" referrerpolicy="no-referrer"></p><p>更合理的实现是，将明显不同语义的代码进行拆分，虽然看上去存在一定程度上的代码重复，但其设计会更利于后续的功能迭代，也更符合代码的「单一职责」设计原则。</p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-5f8500b6ba012049c89989be0edced10_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_7"></span><h4><strong>2.3 决策偏差：复用的决策权在哪</strong></h4><p style="text-align:justify">代码的复用更多的时候是软件开发者自发完成的，但我们无法忽视的一点是，如何集成、是否复用、如何复用、是否是同一个功能、使用什么粒度的复用，很多时候是由业务架构决定的，「康威定律」还是无法回避的。</p><p style="text-align:justify">比如，在一个新的场景里，产品要求把「PPT 上与其名字相同的一个功能」进行复用，以快速上线，虽然他们除了名字相同，其产品形态、业务流程、环境依赖等都不一样。最终强行「复用」的结果就是代码逻辑里出现了大量的分支判断，底层技术架构变得臃肿。由于对于领域的理解不同，出现这种情况在所难免。虽然很多时候软件复用的决策权并不在开发者这里，但出于技术情怀也好，责任心也罢，开发者有义务去做这种纠偏，最大程度地消除这种差异性。但需要认识到技术的作用在这里并不是决定性的，卓越的技术是复用成功的必要非充分条件。</p><span id="OSC_h4_8"></span><h4><strong>2.4 工具缺失：如何计算复用成本</strong></h4><p style="text-align:justify">复用性度量，主要分为两个部分：</p><p style="text-align:justify">1.复用度：决定一个组件复用性高低水平的因素有哪些？</p><p style="text-align:justify">2.复用成本：组件集成方、组件所在的组织，决定实行复用策略后的 ROI 如何计算？</p><p style="text-align:justify">通过复用度和复用成本两个指标，我们可以进行一定程度上的复用性定量分析，做出更为长远的技术决策。比如，可以了解到一个复用性高的组件，其特征有哪些？引入一个新的第三方组件时，除了基础的功能性组件外，我还需要考虑哪些？相较于使用已经存在的组件，是否考虑重新造一个轮子？「复用」和「造轮子」间成本有多大？关于复用性的度量工具，第三部分将重点论述。</p><span id="OSC_h3_9"></span><h3>三、复用性的形式化度量</h3><span id="OSC_h4_10"></span><h4><strong>3.1 组件度量：可复用水平的评估</strong></h4><p style="text-align:justify">我们在设计一段代码/一个类/一个模块等可复用的组件时，一些可衡量的软件指标共同决定了组件的可复用性水平的高低。这些指标包括：可靠性（Reliability）、可读性（Understandability）、可维护性（Maintainability）、通用性（Generality）与可迁移性（Portability），如下图所示。每一个指标可由各类代码度量属性决定，如组件的可迁移性由「组件的独立性」和「耦合性」两个属性决定，大部分的度量属性都是可以通过形式化定义并计算出来。不同指标的决定因子及度量值（括号中）如下：</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-ae30c926a96772aa3e71efcc921e9e0e_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">1.<strong>可靠性：</strong>性能（响应时间）、容错程度（恢复时间）；</p><p style="text-align:justify">2.<strong>通用性：</strong>类泛化水平（子类实例个数或接口实现类个数）；</p><p style="text-align:justify">3.<strong>可读性：</strong>内聚性（类之间耦合度）、复杂度（圈复杂度）、规模（代码行数）、文档水平（数量+完整度）；</p><p style="text-align:justify">4.<strong>可维护性：</strong>易于修改、单测和回归测试（测试覆盖度）、组件的独立性（依赖数）、耦合性（类间耦合度）；</p><p style="text-align:justify">5.<strong>可迁移性：</strong>组件的独立性（依赖数）、耦合性（类间耦合度）。</p><p style="text-align:justify">为了度量整个组件的的可复用性，有必要定义一个可复用性计算模型。该模型基于上图所示的复用性属性模型。主要的可复用性属性、影响这些属性的因素以及度量这些因素的量度之间的关系显示在这个模型中。理论上，软件组件的可复用性 (用&nbsp;<em>Reusability</em>&nbsp;表示) 可以用表达式来计算：</p><p style="text-align:justify"><em>Reusability = w1*M + w2*R + w3*P + w4*U + w5*G</em></p><p style="text-align:justify">其中&nbsp;<em>w1 ~ w5</em>&nbsp;为不同指标的权重值，指标&nbsp;<em>M（Maintainability）、R（Reliability）、P（Portability）、U（Understandability）、G（Generality）</em>&nbsp;值进行归一化（0 ... 1）后，乘以每个指标不同的权重值，通过计算得到最终的组件的可复用度。</p><p style="text-align:justify">在上面的分析过程中，存在部分度量无法进行定量分析的情况，但不同因子组合计算还是有意义的，我们可以拿这些指标去评估我们目前的系统，存在的问题的严重程度。当下次别人问我们为什么要复用组件 A 而不是组件 B 时，我们可以给出更令人信服的理由，而不仅仅是「我觉得」、「A 比 B 好很多」等论述。</p><span id="OSC_h4_11"></span><h4><strong>3.2 组织度量：复用的投入产出比</strong></h4><p style="text-align:justify">对组件的复用性有了一个感性认知后，更加一步地，让我们从经济的角度去思考复用性背后的成本问题。首先，我们先定义几个变量&nbsp;<strong>RL、NUC、RCR、RCWR</strong>。</p><ul><li><strong>RL（Reuse Level）</strong>：可复用组件在应用中的比例，即 RL=复用的组件中代码行数/应用总的代码行数；</li><li><strong>NUC（Not Use Cost）</strong>：应用开发过程中完全不使用可复用组件的成本，注意不包括后续的维护成本；</li><li><strong>RCR（Relative Cost of Reuse）</strong>：复用既有的组件与重新造一个相似的轮子，这两者之间工作量的比值，一般在 0.03~0.4 之间，经验值为 20%，即这意味着复用所花费的成本大约是编写新组件所投入的 20%；</li><li><strong>RCWR（Relative Cost of Writing for Reuse）</strong>：开发可复用的组件与开发一次性使用的模块，这两者之间工作量的比值，一般在 1.0~2.2 之间，经验值为 1.5，即这意味着编写可复用软件需要大约 50% 的额外成本。</li></ul><p style="text-align:justify">对于集成方而言，可以计算因复用节省的成本（DCA，Development Cost Avoidance）以及复用后的成本节省比占比（ DCAR，Development Cost Avoidance Ratio）：</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-ac493599b0c28acc0e45e8e36f988186_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">举例，如果复用度 RL = 40%， RCR = 0.2，则软件集成方节约成本占比 = 0.64，即节省了 64% 的成本。同时我们可以得到一个简单的结论，对于组件的集成方来说，如果想要提升成本占比，则需要：<strong>可复用组件在项目中的复用度越高越好，同时可复用组件的 RCR 应较低。</strong>这意味着可复用组件拓展性、可读性需要保持在一个较高的水平，这样集成方在集成时的二次开发和适配成本会较低，这个结论也是契合我们研发时的直觉的。</p><p style="text-align:justify">对于组织而言，假如某可复用组件的 N 个场景被使用了，则组织复用收益 OROI 可计算如下：</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-6d2fc9255a7e8362245fea5bbc0424ab_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">举例：如果复用度 RL = 40%，RCR = 0.2，RCWR = 1.5，复用次数为 5 次，则，组织收益 OROI = 167%，这意味着开发一个可复用的组件，同时在多个场景进行复用，是有超额回报的。但是不是只要复用了就会有收益呢？另 OROI = (N*(1-RCR) - RCWR)/RCWR &gt; 0 可以得到 N &gt; RCWR/(1-RCR)，带入上面预设的 RCR = 0.2，RCWR = 1.5 这两个值，得到 N &gt; 2，这意味着需要两个或两个以上的场景复用了此组件，我们此次研发活动才会取得正向的收益。与此同时，我们可以从上面的公式得到以下几个关于提升组织复用 ROI 的结论：<strong>可复用组件在项目中复用度越高越好，开发可复用组件时，RCWR 和 RCR 越低越好。</strong>RCWR 低意味着不要去过度设计，组件的泛化性需要在领域内得到一定的控制，RCR 低意味着可复用组件可读性好、拓展性高，集成时的成本不高。</p><p style="text-align:justify">马丁·福勒（Martin Fowler）在《重构》一书提出了一条代码重构经验法则「Rule of Three 」，即我们可以复制和粘贴一次代码，但是当复制相同的代码三次时，应将其提取到新过程中进行抽象以便于复用，法则里面的最小重复次数 3，其值亦符合上述 N &gt; RCWR/(1-RCR) 的结论。</p><span id="OSC_h4_12"></span><h4><strong>3.3 重复度量：复用和复制的边界</strong></h4><p style="text-align:justify">回到我们第二节中所提到的问题：为什么说 DRY 原则不等价于复用？假设以下场景：1. 项目中设计了全局的字符串常量类，所有的公共常量都放在此处，其他模块中的类都引用此常量，这是一个好的实践吗，是不是定义模块内的常量类或类中的常量字段会更好？2. 我需要进行字符串判重逻辑，是自己重写一个字符串工具类，还是直接使用如 commons-lang 或 guava 包中的代码呢？上面的场景都没有绝对的答案，但就我目前看到的情况来看，在很多开发者的编码习惯中，因为过度去追逐「复用性」，出现了一些没有必要的依赖负担，如使用全局常量类，出现没必要的类加载，第三方包的随意使用，造成应用包膨胀或者集成时的包冲突问题。<strong>有时候，复制一些类似的代码比尝试泛化再实例要好得多，过度使用抽象只会模糊真正关键的问题。</strong></p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-0ce4791fa1d8b3d3c325d20da80465f7_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">那什么时候可以复制，什么时候不建议呢？除了 2.2 中提到的语义不一致时的适度复制（就不是复用），当我们真实使用的代码占可复用组件整体代码逻辑的比例较低时（譬如只使用了 commons-lang 包中的 StringUitls 类），可以考虑重写一份，进行适度的复制粘贴，实现该处逻辑和集成方「自治」。对应前面的结论，这种情况下意味着 RL 较低，同时&nbsp;<strong>RCR 较高，比如 RL = 0.01，RCR = 0.8，则，软件集成方节约成本占比只有 RL*(1-RCR) = 0.2%</strong>，这一点收益同后续可能潜在的风险（包膨胀和包冲突）相比，复制可能是一个更好的选择。</p><span id="OSC_h3_13"></span><h3>四、复用性风险管理模型</h3><p style="text-align:justify">有了前面两个部分的铺垫，我们再回头去审视因为复用引入的成本风险，应该采取哪些措施能使得风险最小化呢？在业务风控和数据安全等泛信息安全的业务中，我们对风险管理的抽象，都会强调事前、事中、事后的风险控制流程。相似地，我们可以在代码研发过程中，<strong>通过建立事前评估、事中缓释及事后迭代的复用性风险管控手段</strong>，降低风险发生的可能性及其造成的影响，并根据业务架构和技术架构的发展趋势采取规避、降低和转移风险的措施，将风险控制到团队可承受的水平之内，最大程度地避免或延缓因为复用导致的维护成本高、系统快速腐化等问题。</p><p style="text-align:justify">事前评估、事中缓释、事后迭代形成的全生命周期复用性风险管理模型如下图所示：</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-68fe36560c29dea37111fa27bd2310e9_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_14"></span><h4><strong>4.1 事前评估：成本与启发式决策</strong></h4><p style="text-align:justify">风控的事前阶段（评估+分析），一般基于某些黑样本出发，挖掘出适用于后续风险对抗阶段的某些风险行为特征或模型，并基于历史样本计算出准确率和召回率。在复用性风险的事前阶段，我们也可以通过定性和定量的评估手段，尽早发现各种复用时的「坏味道」，立即予以纠正或防范，把风险消灭在萌芽状态，避免因为错误的复用引入过多技术债。评估的流程主要分为：可复用组件评估、复用成本和收益的度量、启发式决策这三个阶段，具体地：</p><p style="text-align:justify">1.如果待复用的组件是已存在的，则可以计算或估算出已复用组件的可复用水平，考量的指标即上面提到的可靠性、可读性、可维护性、通用性和可迁移性，不同场景的指标权重不一，可以结合具体场景进行判断；</p><p style="text-align:justify">2.如果待复用的组件是需要新建的，则可以计算出后续集成节约的人力成本，以及中长期的时间里组织通过复用组件获取的整体收益，通过结合复用成本、复用收益、当前组织人力现状、后续业务进行最终的决策；</p><p style="text-align:justify">3.如果步骤 1 和 2 都得不到一个最终的结论，下面还有一些启发式的经验帮助我们决定是否真的需要复用。</p><p style="text-align:justify"><strong>可能需要复用的场景</strong>（抽象组件或复用既有组件）：</p><p style="text-align:justify">1.待复用的业务逻辑非常专业，如 Json 序列化、加解密；</p><p style="text-align:justify">2.相同或相似业务语义的代码已经存在多（3）处，需要重构；</p><p style="text-align:justify">3.待选的可复用组件文档非常全面，易于接入、拓展、替换或移除；</p><p style="text-align:justify">4.业务逻辑变更频繁，每次变更需要同时变更多个系统或模块以保持同步；</p><p style="text-align:justify">5.需要即时共享且对不一致性容忍度较低的一些业务逻辑单元，如表的元信息。</p><p style="text-align:justify"><strong>可能无需复用的场景</strong>（那就再造一个轮子吧）：</p><p style="text-align:justify">1.没有文档，或文档质量较差；</p><p style="text-align:justify">2.重复造一个不太难，同时维护成本较低；</p><p style="text-align:justify">3.只使用了可复用组件所有功能里的很少一点逻辑；</p><p style="text-align:justify">4.要花费大量的时间去了解可复用组件的设计思路；</p><p style="text-align:justify">5.可复用组件在拓展新功能时，需要投入大量的精力去协同推进；</p><p style="text-align:justify">6.可复用组件集成时的适配或拓展代码，比单独重写该组件的代码还要多；</p><p style="text-align:justify">7.可复用的组件是整个应用的核心，且后续业务发展迅速有较多的定制需求；</p><p style="text-align:justify">8.可复用组件的产品文档或系统设计中承诺了太多的功能（饼），过于「雄心勃勃」；</p><p style="text-align:justify">9.最后一点：如果决策时觉得可用可不用，那大概率也是不需要复用的，相信自己的第一判断。</p><p style="text-align:justify">通过成本和收益估算，以及若干启发式的决策经验，大多数的场景我们都可以评估得到一个清晰的是否复用的答案。软件复用可能会在短期内提高生产力，但它可能会产生长期后果，所以这一步需要慎之又慎。</p><span id="OSC_h4_15"></span><h4><strong>4.2 事中缓释：HCLC&amp;测试&amp;文档</strong></h4><p style="text-align:justify">事中缓释阶段是控制复用性风险的核心环节，它主要聚焦在可复用组件的开发阶段，通过一系列的关键步骤将复用风险在开发或正式使用前尽可能地降低，主要包括下面几个要点：</p><ul><li>高内聚低耦合</li><li>单元测试和回归测试</li><li>完整且有效的文档化</li></ul><p style="text-align:justify"><strong>高内聚低耦合（HCLC）。</strong>这是一个老生常谈的事情了，内聚和耦合会影响可复用水平中的多个指标，如是否内聚会影响可读性和可迁移性，耦合会影响可维护性、可迁移性和可读性。软件工程中已经有很多设计原则或模式供我们选择了，如在代码开发阶段，优先组合、依赖倒置、里式替换、接口隔离、单一职责、开放封闭、23 种设计模式等，在架构设计阶段，也有若干的架构设计模式或方法论，如分层、CQRS、异步事件驱动、领域驱动设计等。</p><p style="text-align:justify"><strong>完整且有效的文档。</strong>「好的代码是自解释性的」，这句话不完全对。首先，无论是我们的架构设计抑或是代码设计，很多东西是无法在代码中体系出来的，如对于领域抽象的取舍、决策的思考过程等，即便是我们的的接口、成员变量、实现，其命名和设计过程已经到了一个非常高的水平，代码中「隐藏信息」还是会损失，而注释可以尽可能去弥补这部分损失。其次，需要认识到：人类的感知与沟通速度是很慢且低效的，需要通过文档去填补双方沟通时的这一道鸿沟。当然，这里讨论的是一般情况，依托「无文档化」构建核心「竞争力」的行为模式不应归入此类。最后，一个正常的组织，人员是会流失的，大部分人最终都会离开这个组织，可复用组件的关键设计者如果不在组织里了，这种知识性的损失将是永久性的，文档（注释、设计）起到了一个备份领域知识的作用。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-865f007635a00f99fa6fbed28bc1075e_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify"><strong>单元测试和回归测试。</strong>复用理论之所以成立，出发点是我们希望使用已经存在的、成熟的软件资产来提升研发效率，同时降低系统缺陷，一套全面的自动化回归测试，不仅有利于集成方，也会让后续和此可复用组件相关的每一个人受益。如果我们开发的可复用组件没有自动化的回归测试，那这样的组件是不合格的，是不应该发布公共仓库的。缺少自动化测试或核心流程自动化测试覆盖度较低的组件，对于集成方和组件后续的维护者来说是一场灾难，它给系统引入的巨大的技术债甚于完全没有配套文档的可复用组件。</p><span id="OSC_h4_16"></span><h4><strong>4.3 事后迭代：捕捉领域变化&amp;组织</strong></h4><p style="text-align:justify">在开发可复用组件时，如果一开始就大刀阔斧地投入研发资源，最终可能会创建与直接需求无关的软件资产，并由于设计、开发和测试时间的增加而产生重大的进度风险，相反，通过多次迭代改进可复用组件来降低这些风险，<strong>一个良好的组件、框架和软件架构需要时间来设计、实现、优化、验证、应用、维护和增强。</strong>与此同时，第一阶段的开发和集成结束后，在迭代的过程中进行持续性的风险管理，可以使得可复用组件的风险保持在一个较低的水位，尽可能地延长组件的生命力，需要做的主要事项包括：持续捕捉领域变化以及相应的组织支持。</p><p style="text-align:justify"><strong>捕捉领域变化。</strong>上面提到了，代码中有部分内隐的知识，事实上，<strong>一个可复用的组件就是开发者对于某个领域思考的结果</strong>，无论它是以类文件、模块还是系统的方式呈现。而领域都是会变化的，变化包括：领域的边界会拓展、领域内部分实体内涵会变化、不同领域之间的边界会重叠或者融合等。领域变化后，如果在这其中的可复用组件没有进行适当的调整，就会出现技术和业务配速失效的问题。可复用组件在封装了领域知识的同时，也一定程度上屏蔽了复杂度，当组件不足以承担起领域的实体或功能出现偏差时，就会出现「复杂度泄漏」的问题。</p><p style="text-align:justify">捕捉域变化的两个关键动作：统一领域上下文以及关注上游需求池。统一领域上下文重要性不言而喻，<strong>很多时候各方意见出现偏差的根本原因是大家没有形成统一沟通的语言，无法简单、准确且清晰地描述各自的诉求。</strong>我在进行某风险域架构治理时，做的第一件事情就是拉上了业产研三方，统一大家对「规则」和「策略」两个概念的内涵和边界的认知。其次，开发人员和架构师需紧密关注需求池，从需求本身出发，区分领域中可变性和通用性的关键来源。识别出问题域中的所有变化是不现实的，我们可以关注一些关键问题，如面对一个新的需求，可以考虑：</p><p style="text-align:justify">1.我们讨论的概念是否一致？</p><p style="text-align:justify">2.该需求涉及哪些领域实体？</p><p style="text-align:justify">3.该需求是否需要有我们新增实体？</p><p style="text-align:justify">4.新增实体是否会与既有实体产生二义性？</p><p style="text-align:justify">5.之前是否存在类似的需求？有什么不同？</p><p style="text-align:justify">6.新增的需求是否可以和既有的逻辑进行隔离？</p><p style="text-align:justify">7.......</p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-b4a6ff6154f2348778fd424cd86b6cfc_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">是否有一种指导原则，可以让我们在跟踪这些域变化的时候，进行更合理的设计与取舍呢？熵增原理告诉我们：一个孤立的热力学系统的熵不减。对于系统的可逆过程熵不变，不可逆过程熵增加。因此，类比软件工程领域，在组件的事后迭代阶段，<strong>一个尽可能消除代码设计/软件架构中熵增的设计原则：在既有组件中新增的功能点需要存在逆向的删除机制</strong>，这样就可以尽可能让可复用组件跳出逐渐混乱无法维护的宿命。功能可逆的具体操作具体可以表现为：SPI 机制（Service Provider Interface ）、面向接口的编程、通过模块隔离随机的或一次性的需求等。</p><p style="text-align:justify"><strong>组织和配套的文化。首先，组织是业务架构的投射</strong>，当复用组件内的领域实体和组织负责的领域实体出现偏差时，就会出现因错位产生的技术债，结果无非是两种：一种是之前的可复用组件直接被抛弃，任由其自生自灭；另一种缺少破釜沉舟进行重构勇气与担当，既然不是我负责的，那就改一改重新用，原先统一均衡的结构会快速打破。<strong>其次，可复用组件和框架的好坏取决于构建和使用它们的人</strong>，我们需要能评估风险和机遇的管理者，需要能识别领域本质复杂度和偶然复杂度、同时能很好掌握设计模式和架构模式的架构师，以及，在开发原则、模式和实践上经验丰富的开发人员，组件是否可复用、可以复用多久，很大程度上是具备良好设计和经验丰富的开发人员的副产品。<strong>再者，在事后迭代阶段，我们需要专门的团队或负责人为此可复用资产负责</strong>，不断监控平台代码库的健康，跟踪和修复错误，坚持正确抽象，不断完善文档。当然上述只是理想情况，更多的时候，这样的人或团队是不存在的，或者即便存在，相应的组织激励也是缺失的，在一个没有复用的文化土壤中，组件腐化只是时间问题。最后，有了正确的组织和优秀的人，长期的<strong>信心、热情、激励以及管理层的支持与响应</strong>，也都是成功的复用必不可少的条件。</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-2228938440622697c56b0d0ace934f73_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h3_17"></span><h3>五、关于复用的一点感想</h3><p style="text-align:justify">本文想重点去表达的几个观点：不要过度去追逐「复用」、可复用的水平以及复用投入产出比是可量化的、可复用资产是内隐的领域知识、适度的重复也是可接受的、文档可以弥补领域知识的损失、架构演进中新增功能需可逆。</p><p style="text-align:justify">撰写此篇文章的初衷，一方面源于近几年来在指导新同学时，发现出现较多的「伪复用」现象，例如为了减少代码，将共享的方法签名放在接口中，形成「过程式接口」，另一方面，自己也写过一些「为了复用」而设计的组件或模块，从中间件到业务组件大概有十几个了。但最近逐渐开始意识到，很多时候为了后续的可迁移性，一些架构或代码层的的前向防御性设计作用并不大，过度抽象反而是给使用方造成了一些理解上的困难。到底哪些真的需要复用，哪些可以妥协，梳理完这篇文章后，坚定了一部分想法（例如全程文档化），也给一些既有观念做了纠偏。</p><p style="text-align:justify">上面也一直在传递一个观点，好的软件资产是一个优秀团队的副产品。当把复用的目光从软件聚焦到人，我们自己身上，哪些是可以复用的，哪些又是平台或组织赋予我们的？去除掉那些光怪陆离的虚幻部分，不可变的部分又有哪些？授权后的高价值专利算一种，其有效期为二十年。思考过程中沉淀可能算另一种，它们或多或少且阶段性地概述了当时的所思所想，无论内容是否全面、正确，也涂抹上了时光的颜色，这也是这篇文章产生的另一个动机。</p><p style="text-align:justify">作者｜齐光</p><blockquote><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fclick.aliyun.com%2Fm%2F1000373503%2F" target="_blank"><span style="color:#ff9900">点击立即免费试用云产品，开启云上实践之旅！</span></a></strong></blockquote><p style="text-align:justify"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1364680%3Futm_content%3Dg_1000382902" target="_blank">原文链接</a></strong></p><p style="text-align:justify"><strong>本文为阿里云原创内容，未经允许不得转载</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 03 Nov 2023 02:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/yunqi/blog/10140476</guid>
            <link>https://my.oschina.net/yunqi/blog/10140476</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌放弃 Web Environment Integrity API 提案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fincreasing-trust-for-embedded-media.html" target="_blank">宣布</a>放弃其备受争议的&nbsp;<span style="background-color:#ffffff">Web Environment Integrity API 提案，转而开发&nbsp;</span><span style="background-color:#ffffff">Android WebView Media Integrity API。</span></span></p><p><span style="color:#000000">今年 5 月份，谷歌在开发者邮件列表中宣布了其&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity%2Fblob%2Fmain%2Fexplainer.md%23goals" target="_blank">Web Environment Integrity API</a><span style="color:#000000">，旨在作为一种限制在线欺诈和滥用的方法，同时不会引发跨站点跟踪或浏览器指纹识别等隐私问题。但却遭受了公众的强烈反对，认为其更类似于一种网站的数字版权管理（DRM）功能，担心谷歌借此限制网络自由。</span></p><p><span style="color:#000000">因此在收到众多反馈后，谷歌表示其&nbsp;<span style="background-color:#ffffff">Chrome 团队不再考虑&nbsp;Web Environment Integrity API；并将重点转向范围更窄的解决方案 Android WebView Media Integrity API，仅针对应用程序中嵌入的 WebView。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">根据介绍，这个新的 API 只扩展了具有 Google 移动服务 (GMS) 的 Android 设备上的现有功能，并且没有计划提供超出嵌入式媒体（例如流媒体视频和音频）或 Android WebView 之外的功能。</span></span></p><p><span style="color:#000000"><img height="248" src="https://oscimg.oschina.net/oscnet/up-79bb6dbdddd857c0a5caad36bd7b735e59e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Android WebView API 允许应用程序开发人员显示嵌入媒体的网页，并增强对 UI 的控制和高级配置选项，以允许在应用程序中无缝集成。这为移动应用开发带来了很大的灵活性，但同时也为欺诈和滥用提供了途径；因为它允许应用程序开发人员访问网页内容，拦截或修改用户与网页的交互。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">新的 Android WebView Media Integrity API 旨在使嵌入式媒体提供商能够访问定制的完整性响应，其中包含设备和应用程序的完整性判定，以便他们能够确保他们的流媒体在安全、可信的环境中运行，无论嵌入式应用程序是从哪个应用程序商店安装的。</span></span></p><p><span style="color:#000000">谷歌方面计划<span style="background-color:#ffffff">在明年初，与选定的嵌入式媒体供应商一起试点实验性 Android WebView Media Integrity API。</span></span></p><p><span style="color:#000000">详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fincreasing-trust-for-embedded-media.html" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 02 Nov 2023 04:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264883/google-abandons-web-environment-integrity-api</guid>
            <link>https://www.oschina.net/news/264883/google-abandons-web-environment-integrity-api</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
