<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 21 Nov 2023 02:38:26 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Zadig 推出环境睡眠，平均节省一半测试资源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:center"><img alt="" height="386" src="https://oscimg.oschina.net/oscnet/up-27ced375dc5b1beb469bf36b2afaa8b1994.png" width="902" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247491064%26idx%3D1%26sn%3D4bbe7bfe944feaa8b44a08e6156e04e2%26chksm%3Dcfb45158f8c3d84e40d44d2dd9228a844b9bcdeea1fe32a7b0ae41b9af982c11319a38f6675e%26token%3D481744823%26lang%3Dzh_CN%23rd" target="_blank">阅读原文</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig" target="_blank">Zadig 在 Github</a>&nbsp;/&nbsp;<a href="https://gitee.com/koderover/zadig">Zadig 在 Gitee</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><strong>推荐阅读：</strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490415%26idx%3D1%26sn%3D1914c7fd25aac5d33b98663571bbb744%26chksm%3Dcfb457cff8c3ded9c02809aad88012fa802eac55222eebe70b8c637ca2c86a101045aa81e73a%26scene%3D21%23wechat_redirect" target="_blank">是时候和 Jenkins 说再见了</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490637%26idx%3D1%26sn%3D6e0498b37fb15f8b8903c4997e5611d8%26chksm%3Dcfb450edf8c3d9fb758d691081f09fd85d91dbb17534ba9c18c2300725462d3806581efbd237%26scene%3D21%23wechat_redirect" target="_blank">Zadig vs. Jenkins 详细比对：时代的选择与开发者之选</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247489682%26idx%3D1%26sn%3Df4ac5ceb38547542061477a45d8dc86d%26chksm%3Dcfb45432f8c3dd24b727e0fb6db276b2d63b2751933e63a25b00b9d9fac2dd68efbd2cbd3863%26scene%3D21%23wechat_redirect" target="_blank">平台工程和 AI 时代的新 10 亿开发者</a></p><p style="margin-left:0; margin-right:0">Zadig 起源于环境管理工具，逐渐演变成了全面的云原生 CI/CD 平台，最终成为了综合性的 DevOps 解决方案。社区小伙伴一致赞誉它为「中小型企业的得力助手，大型企业的利器」，它有众多独特优势：</p><p style="margin-left:0; margin-right:0"><span><strong>· 现有服务接入<span style="color:#ff2968">姿势多</span>：</strong></span>无论你的服务定义是 K8s YAML、Helm Chart 还是传统的主机服务，Zadig 都提供了一键接入，实现高效统一的环境治理。</p><p style="margin-left:0; margin-right:0"><span><strong>· 运行时管理<span style="color:#ff2968">能力强</span>：</strong></span>不仅支持环境配置管理，还包括了服务的重启、更新和配置管理功能，同时还为开发者提供了便捷的实时日志查看和容器内调试工具。</p><p style="margin-left:0; margin-right:0"><strong><span>· 多环境管理<span style="color:#ff2968">负担轻</span>：</span></strong>基于一份环境配置，Zadig 能够秒级内创建多套完整的环境，一键复制已有环境到新环境，快速回溯到特定版本的环境，并且利用服务变量功能实现不同环境的个性化配置。</p><p style="margin-left:0; margin-right:0"><strong><span>· 环境更新<span style="color:#ff2968">效率高</span>：</span></strong>支持多服务多环境的并行更新，智能选择空闲环境，避免资源浪费和低效堵塞。</p><p style="margin-left:0; margin-right:0"><strong><span>· 环境<span style="color:#ff2968">资源占用少</span>：</span></strong>自测模式可快速创建仅包含部分服务的子环境，支持开发者快速开发和修改目标服务，从而显著降低团队协作时的多环境使用成本。</p><p style="margin-left:0; margin-right:0"><span>......</span></p><p style="margin-left:0; margin-right:0">过往社区也沉淀了大量的最佳实践供大家参考：</p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247486322%26idx%3D1%26sn%3Dbf80ef6f666a9f4d3baa1d1c43382004%26chksm%3Dcfb447d2f8c3cec4606c0370a2f4f885fbf51b97f1407e38a551a0128163c38dff4818cabe84%23rd" target="_blank">简单极了：Zadig 托管项目支持上千开发者、多业务线、多环境协作</a></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487967%26idx%3D1%26sn%3Dc50e4a2d2543ee5f771c139c85503abd%26chksm%3Dcfb45d7ff8c3d4690690b800f1f5640fac8d92e06465c9e99d7516960ff3d949a3d308c83ba9%23rd" target="_blank">多套环境的数据库隔离，域名访问，差异化配置，香！快解锁！</a></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487915%26idx%3D1%26sn%3D4719546f8f109733324124bd87c908f9%26chksm%3Dcfb45d0bf8c3d41d581db5e3d957feef9a3a121726bbf66b85eb3a82ded4a88fc98836f247da%23rd" target="_blank">写代码 5 分钟，上线 2 小时？就离谱！来用用 Zadig 环境负载均衡</a></span></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487124%26idx%3D1%26sn%3D062f9a269f16ff91e5e578a9f8456c15%26chksm%3Dcfb44234f8c3cb22d68b608c51327c91fcc06e2bb88d1da5d3f4e5237c9dffa1af9f668ee98e%23rd" target="_blank">在星云科技，我们使用 Zadig 实现多环境并行发布，上千次周部署</a></span></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487033%26idx%3D1%26sn%3D645702bbe3e58b957ea960c4b231d819%26chksm%3Dcfb44299f8c3cb8fc664bb7de920eec0d3e587615b04d49cb59ed1b23fe40b83977068626f88%23rd" target="_blank">谁说 Zadig 只能复制环境？数百微服务一套环境实现高效协作</a></span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c1b0440b31e72d76997ee520ad4540be287.png" referrerpolicy="no-referrer"></p><span id="OSC_h2_1"></span><h2><span style="color:#ff2968"><strong>一、降本增效：推出环境睡眠和唤醒功能</strong></span></h2><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">随着越来越多的企业深度采用 Zadig，我们关注着环境的易用性、变更效率以及维护负担等基础能力，同时积极努力降低环境资源成本。我们明白工程师并非 24 小时都需要使用环境，因此时刻在线的环境会导致资源浪费和企业成本增加。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">在 Zadig 的新版本中，我们引入了环境睡眠/唤醒功能，使环境管理更具智能性。这一功能能够自动缩减应用程序的大小以节省云资源成本。环境睡眠/唤醒适用于多种场景，包括但不限于：</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>1. 日常开发和测试：</strong></span><span>&nbsp;</span>工程师进行自测、联调和集成验收时，根据使用频率，可以轻松设置环境的睡眠和唤醒，以合理利用资源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>2. 不经常迭代的项目：</strong></span><span>&nbsp;</span>对于不经常迭代但仍提供在线服务的项目，需要保留多套完整可验证的开发、测试和预发布环境。通过定期设置睡眠，唤起使用时，可以及时释放资源到公共资源池。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>3. 定时按需控制：</strong></span><span>&nbsp;</span>您可以设置环境的定时睡眠和唤醒，尤其适用于弹性节点资源。例如每天晚上自动睡眠，早上自动唤醒，或者在节假日休息时自动睡眠，工作日自动唤醒，以避免无人使用时仍然占用资源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">这一新功能将使您能够更智能地管理环境，更有效地利用资源，从而降低成本。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-059a61e53b3cb2a2033421b525584d8db96.png" referrerpolicy="no-referrer"></p><span id="OSC_h2_2"></span><h2><span style="color:#ff2968"><strong>二、关于环境使用的成本优化测算</strong></span></h2><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.5)">实际资源取决于应用本身的占用及环境使用频率，Zadig 环境睡眠主张从源头减少浪费。</span></p><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">以一个典型的微服务项目为例，该项目由 5 名前后端工程师协同，包含 10 个 Java 服务，平均资源 Request 1C2G；1 个 vue 前端服务，资源 Request 1C0.5G；项目迭代过程共包含开发环境 2 套，测试环境 1 套，预发环境 1 套。平均每个服务每人每天构建 2 次；构建时长 6 分钟。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>· 正常使用资源消耗：</strong>研发阶段大致需要消耗资源<span>&nbsp;</span><span style="color:#ff2968"><strong>44C82G</strong></span><span>&nbsp;</span>(前端 4C2G，后端 40C80G)。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>· 配置环境睡眠策略后：</strong>该项目在不同迭代频率下，平均节约<span>&nbsp;</span><strong><span style="color:#ff2968">22C41G</span></strong><span>&nbsp;</span>约一半资源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-99d72eb1139570e2b7bf667fd8ddd2d855b.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8452cd8960943c012f669980244501130a7.png" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img height="1278" src="https://oscimg.oschina.net/oscnet/up-54779359f43a9840cdac2ba5ac23b7e5af5.png" width="2346" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">下面将展开介绍如何配置环境睡眠及效果的展示。</span></p><span id="OSC_h3_3"></span><h3><span style="color:#ff2968">01-</span><span style="color:#ff2968">如何启用环境睡眠能力</span></h3><p>&nbsp;</p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span style="color:rgba(0, 0, 0, 0.5)">前提条件：安装 Zadig v1.7.0 版本，系统中存在正在使用的环境。</span></p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span><strong>•<span>&nbsp;</span></strong></span>安装 Zadig v2.0.0</p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span><strong>•<span>&nbsp;</span></strong></span>Zadig 环境管理</p><span id="OSC_h3_4"></span><h3><span style="color:#ff2968">02-配置一键睡眠/唤醒</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">进入环境，点击睡眠与唤醒 -&gt; 立即睡眠即可将环境一键睡眠。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a23a8cfb642b3eec757e317f8bf162ebd9d.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9dfbdcb488595269fcafbfe331e1bc7e44.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">需要使用环境时，进入睡眠的环境，点击睡眠与唤醒 -&gt; 立即唤醒即可将环境唤醒恢复可用。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-2ebf5b3eb9aca3d21beba63bb63497d7e17.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_5"></span><h3><span style="color:#ff2968">03-配置定时睡眠/唤醒</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">进入环境，点击睡眠与唤醒 -&gt; 配置定时睡眠和唤醒 Cron 表达式即可。比如，下图示例中每天 22:00 定时睡眠环境，每天 8:00 环境将定时唤醒恢复可用。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-db2e0c10ffc9d063b4a59de5fe8a9d09b0c.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-4f4226bd32cc075241b7d87451ab3fb23be.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_6"></span><h3><span style="color:#ff2968">04-使用效果一览</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">睡眠后，环境中所有服务实例副本数将会自动调整为 0，CronJob 会被挂起，节省环境所使用云资源成本。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-45cb0a823997e3471d8dfe59e755369a6aa.png" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p style="margin-left:0; margin-right:0">唤醒后，环境中的所有服务会根据服务编排顺序恢复到睡眠之前的状态。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-d899a41dcd4f828dbfc32a19cfa534dd94c.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_7"></span><h4><strong>参考资料</strong></h4><p style="margin-left:0; margin-right:0; text-align:left"><span>[1] 安装 Zadig v2.0.0</span></p><p style="margin-left:0; margin-right:0; text-align:left">https://docs.koderover.com/zadig/Zadig%20v2.0.0/stable/quick-install</p><p style="margin-left:0; margin-right:0; text-align:left"><span>[2] Zadig 环境管理</span>https://docs.koderover.com/zadig/Zadig%20v2.0.0/project/env/k8s</p><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-187186c2b990f912cf841796017d7e8ce6f.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0px; margin-right:0px"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247491064%26idx%3D1%26sn%3D4bbe7bfe944feaa8b44a08e6156e04e2%26chksm%3Dcfb45158f8c3d84e40d44d2dd9228a844b9bcdeea1fe32a7b0ae41b9af982c11319a38f6675e%26token%3D481744823%26lang%3Dzh_CN%23rd" target="_blank">阅读原文</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig" target="_blank">Zadig 在 Github</a>&nbsp;/&nbsp;<a href="https://gitee.com/koderover/zadig">Zadig 在 Gitee</a></p><p style="color:#333333; margin-left:0px; margin-right:0px"><strong>推荐阅读：</strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490415%26idx%3D1%26sn%3D1914c7fd25aac5d33b98663571bbb744%26chksm%3Dcfb457cff8c3ded9c02809aad88012fa802eac55222eebe70b8c637ca2c86a101045aa81e73a%26scene%3D21%23wechat_redirect" target="_blank">是时候和 Jenkins 说再见了</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490637%26idx%3D1%26sn%3D6e0498b37fb15f8b8903c4997e5611d8%26chksm%3Dcfb450edf8c3d9fb758d691081f09fd85d91dbb17534ba9c18c2300725462d3806581efbd237%26scene%3D21%23wechat_redirect" target="_blank">Zadig vs. Jenkins 详细比对：时代的选择与开发者之选</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247489682%26idx%3D1%26sn%3Df4ac5ceb38547542061477a45d8dc86d%26chksm%3Dcfb45432f8c3dd24b727e0fb6db276b2d63b2751933e63a25b00b9d9fac2dd68efbd2cbd3863%26scene%3D21%23wechat_redirect" target="_blank">平台工程和 AI 时代的新 10 亿开发者</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 02:34:22 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/10149325</guid>
            <link>https://my.oschina.net/koderover/blog/10149325</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 超 700 名员工签署联名信，要求董事会集体辞职]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据纽约时报等媒体统计数据，目前 OpenAI 至少有 743 名员工已签署联名信逼迫董事会集体辞职，同时恢复 Sam Altman 和 Greg Brockman 在董事会的职位。<strong>否则所有签名者集体跳槽微软</strong>，而且这一人数正在持续增加中（昨晚还只有&nbsp;500 人左右）。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3b5ce54499e3d9390d7173b0cacee47dfbc.png" referrerpolicy="no-referrer"></p><p>出乎意料的是，被认为是 OpenAI&nbsp;此次「政变」组织者的首席科学家 Ilya Sutskever 也签署了这一联名信。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-08e0a2b4d71953d511d7c02b0bc333b91bf.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-65a525945aa136b1379d133093172eaa368.png" referrerpolicy="no-referrer"></p><p>同时，多位消息人士告诉 The Verge，<strong>如果解雇他的其余董事会成员下台，Sam Altman&nbsp;和联合创始人&nbsp;Greg Brockman&nbsp;仍然愿意重返 OpenAI。</strong></p><p>公开资料显示&nbsp;OpenAI 员工人数为 770 名，这批「逼宫」的人占据了员工总数超 96% 之多。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 02:18:22 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267364</guid>
            <link>https://www.oschina.net/news/267364</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[修完这个 Bug 后，MySQL 性能提升了 300%]]>
            </title>
            <description>
                <![CDATA[这个 bug 是由 Mark Callaghan 发现的。Mark 早年在 Google MySQL 团队，后来去了 Meta MySQL，也主导了 RocksDB 的开发。]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 02:09:22 GMT</pubDate>
            <guid isPermaLink="false">修完这个 Bug 后，MySQL 性能提升了 300%</guid>
            <link></link>
        </item>
        <item>
            <title>
                <![CDATA[目标导向主义失效了？前 OpenAI 科学家现身说法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div>
  「目标感很强」常常被我们用来夸赞一个职场人，并被当作是成功的一大原因。然而，两位前 OpenAI 科学家——Kenneth Stanley、Joel Lehman 在多年的 AI 研究中发现，目标导向论对于成就伟大的事情并无助益，反而抱着探索的心态去尝试做有趣的事情更能带来意想不到的成果。 
</div><div>
  &nbsp; 
</div><div>
  尤其是在人工智能的算法研究中，比如让机器人通过一条走廊，最终从走廊尽头的大门中出去。最终实验证明，在不设定「出门」目标的情况，机器人可以纯粹尝试一些与以往不同的事情，反而最终能找到出门的方法。类似原理的还有 Kenneth Stanley 曾参与的图片繁育网站的工作，在这个图片繁育网站上，用户可以从一个简单的圆点图形，叠加其他图形图片，最终生成出类似汽车、动物等「有用」的图片，但如果用户开局就抱着」我要生成一张汽车图片「的目标，反而很难成功。 
</div><div>
  &nbsp; 
</div><div>
  由于认知理念上的转变，在 ChatGPT 发布前几个月，Kenneth 离开 OpenAI 去创业，研究新产品——开放式、偶然性社交网络 Maven，Joel 离开后到了 Stability，领导 Carper 开放性研究团队，同时他也在研究机器之爱。Kenneth 和 Joel 也合作创作了一本书《为什么伟大无法被计划》，书中认为，许多时候，哪怕我们的探索漫无目的，在前方位置的道路上依然埋藏着无数宝藏。从「目标」中解放出来，或许能成为发现意外之喜的「寻宝者」。 
</div><div>
  &nbsp; 
</div><div>
  「 
 <strong>在我看来，研究工作最重要、最实用的方面之一是开发对于可能性的直觉。」</strong>&nbsp;正如 Joel 现在去研究机器之爱的历程，在接触心理学之后，他将对心理学和机器学习的兴趣结合起来，找到了更加热爱的事情，「 
 <strong>我们的生活没有统一的目标，我们的兴趣和心理发展往往是偶然进行的——于是，一个新的研究方向为我打开了。」</strong>在他看来，在机器时代，我们越来越需要人类代理的提醒，技术的目的是为人类的利益服务，而人类是构建和设计这项技术的人。 
</div><div>
  &nbsp; 
</div><div>
  同样，对于人工智能的看法，Ken 也从人文的角度给出观点：「一种哲学见解认为，好的人工智能实验不仅应该带来强大的系统，还应该带来对我们人类自身的洞察。毕竟，对智能的任何伟大洞察实际上都是对人类的洞察，因为智能是我们的决定性特征。」 
</div><div>
  &nbsp; 
</div><div>
  Kenneth 和 Joel 提出的哲学态度与常规认知相反，或许能给我们在这个混乱时刻一些新的启示，因此，OSCHINA 特别邀请 Kenneth 和 Joel 聊了聊他们理念、观点和故事。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Ken 可以详细介绍下偶然性社交网络 Maver 的玩法、原理、以及目前的成长状态吗？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  Maven 是一种新奇的社交网络，我创办了一家新公司来开发它。它基于我们《为什么伟大不能被计划》一书中的原则，专注于将人们与个性化的偶然发现联系起来，而不是增强病毒式传播。我们从 2023 年开始开发它，所以它还很新。 
</div><div><img height="373" src="https://oscimg.oschina.net/oscnet/up-ea180ad51144df638c6a6b631f4e68e7054.jpg" width="700" referrerpolicy="no-referrer"></div><div><span style="background-color:#ffffff; color:#888888">Kenneth Stanley</span></div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Stability 现在在全球市场也备受关注，但很多人都不太了解开放性研究，能否请 Joel 介绍下正在做的开放性研究是指什么？</strong></span></p><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  创建生成式 AI 大模型的公司之间的一个主要理念分歧是专有模型与开源模型。 
</div><div>
  &nbsp; 
</div><div>
  例如，现在 OpenAI 和 Anthropic 没有公开他们最大的模型，以便其他人可以修改或在其基础上构建 (尤其是对他们来说有商业价值的模型)，而是只提供一个 API，用户可以在有限范围内使用模型。支持这种模式的理由通常是：如果大模型被滥用可能造成危险，而 API 可以实现更好的监控，并且训练大模型成本很高，公司需要一种赚钱的方法。 
</div><div>
  &nbsp; 
</div><div>
  相比之下，由 Stability 和 HuggingFace 等公司采用开源的方式训练模型、发布代码和模型 (通常比闭源模型的模型小)，这样其他公司和研究人员可以直接在其基础上进行构建，并根据自己的目的灵活调整。这些公司通常不太关心模型被滥用的危险，而是更关心创建一个蓬勃发展的研究和模型生态系统。但由于他们免费发布模型，其他人现在可以运行他们的模型，而无需向训练模型的公司付费，因此他们需要一种不同的商业模式来保持财务上的可行性。 
</div><div>
  &nbsp; 
</div><div>
  这两种理念都有蓬勃发展的空间，尽管未来存在关键的不确定性。例如，如果开源模型在未来变得非常强大，并且不良行为者最终利用这些模型造成了社会问题，则可能会产生负面影响。反之，如果专有大模型的 API 对于大多数希望使用生成式 AI 的公司来说限制过多或是成本过高，也许也导致更多人选择开源路径。 
</div><div>
  &nbsp; 
</div><div>
  当然，随着开源运动模式与方法的日益多样化，开源似乎更符合 Ken 和我的书中所传递的理念。我可以想象，许多有趣的发现将由此产生。但我担心，如何在开源社群中加入安全约束和规范引入，使得这些模型在造福社会的同时，也能尽量避免可能的负面影响？以及如何在鼓励这些规范和约束的同时不必放慢创新速度？这是一个有趣而微妙的问题。 
</div><div><img height="592" src="https://oscimg.oschina.net/oscnet/up-f738a9b408fbacdee21e45d537991e8c562.png" width="700" referrerpolicy="no-referrer"></div><div><span style="background-color:#ffffff; color:#888888">Joel Lehman</span></div><span id="OSC_h3_1"></span><h3>从「繁育」到「提示」，我们该如何对话机器</h3><p><span style="color:#2ea121"><strong>OSCHINA：当年「繁育图片」的孵化器网站后面的故事是怎样的？是否还在运行？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  你指的是 Picbreeder。它是在我在中佛罗里达大学 (University of Central Florida) 的实验室开发的 (该实验室名为 EPlex-Evolutionary Complexity Research Group)。Jimmy Secretan(当时是一名博士生) 领导了这项工作。这是一个允许互联网用户培育图像的网站，就像你培育狗或马一样。更深层次地说，其实这是一次开放性实验。它使我们能够观察到在人工环境中发生的大规模开放式搜索过程 (让人联想到自然进化)。看到这一过程的展开，我们得到了许多深刻的教训，其中包括新奇性搜索算法背后的理念，以及《为什么伟大无法被计划》一书中的见解。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：「繁育」原理和现在火爆的「输入 prompt 生成图片」这类网站可以做比较吗，二者背后的运行原理有什么相似得地方，有什么不同的地方？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  它们都是生成艺术的一种形式，但工作方式截然不同。基于提示的现代图像生成技术之所以有效，是因为生成图像的模型已经过数百万或数十亿个示例图像的训练。所以当它生成图像时汲取了丰富的经验。在协议中，Picbreeder 没有任何训练数据，用户只是简单地开始随机繁育圆点，经过几代的繁育，就能产生进化，产生更多我们更熟悉的图像，比如如汽车和蝴蝶。一个一开始并不明显的巨大差异是，繁育远没有那么密集：像 Picbreeder 头骨这样的繁育图像只需要几十次迭代搜索，而现代图像模型已经经过数百万或数十亿次迭代进行优化。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  抽象地说，繁育原理是指人们以发散和协作的方式探索思想空间，是取得新发现和有用发现的关键。「输入提示生成图片」的方法，在某种意义上与繁育原则是正交关系，因为你可以发散地与他人写作探索提示空间，也可以自己探索。 
</div><div>
  &nbsp; 
</div><div>
  换句话说，许多人确实分享了他们的提示技巧，展示如何让模型生成图像获得有趣成果。例如，在一些模型中，添加「Trending on Artstation」这一文本将有助于提高质量。所以，人们越能看到他人制作的图片和提示，就越能从图片和他人的提示中得到启发，制作自己的图像，从而更全面地用拥抱繁育原则。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Prompt 背后的原理，是更接近目标函数原理，还是无目标探索</strong></span><span style="color:#2ea121"><strong>系统理论</strong></span><span style="color:#2ea121"><strong>？如何解释？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  因为 prompt 可以传达任何想法，所以它可以用来表达客观或非客观的过程。大多数人可能会客观地使用它们，因为这是我们大多数人被教导的思考方式，但仍然有可能有人非客观地使用它们。例如，如果我让它为我解决一个问题，这是一个客观使用。但如果我让它想给出一些有趣的东西，那就更接近于非客观。然而，重要的是要注意，你可以向 LLM 表达一个非客观的概念并不意味着它能表现得很好，或像人类一样。我认为现在的 LLM 通常无法很好地独立实现非客观的表达。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  Prompt 原则既可以兼容目标函数原则，又可以兼容探索系统理论。有时，人们会 prompt 进行大量优化，试图在特定任务中获得最佳性能。还有一些时候，人们以一种更不定向的方式利用 prompt 进行探索，以找到不同寻常的有趣方法来产生新的输出——探索特定语言模型或图像生成模型的边界。 
</div><div>
  &nbsp; 
</div><div>
  以「思维链」提示的惊人发现为例，只需要给模型举几个例子，说明如何推理一个问题，最终就能帮助模型更好地完成任务 (即告诉模型「一步步思考」)。模型本身有意想不到的优势，需要研究人员去发现，而发现方法往往是遵循他们的直觉，并以其他人发现和其他共享出来的 prompt 为基础。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：现在很多培训教学，教大家如何使用 Prompt，如果遵循用无目标探索</strong></span><span style="color:#2ea121"><strong>系统理论</strong></span><span style="color:#2ea121"><strong>，采用寻宝原则，我们该如何学习使用 prompt 和机器对话？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我认为以这种方式探索 prompt 是一个好主意。当你和 LLM 交谈时，尝试去做一些没有目标的事情，看看当你尝试一些有趣的事情时会发生什么。当你发现它以一种有趣的方式响应时，请进一步探索这条路径。这种方法可能会带来对模型的更深入的理解，而不是简单地尝试实现特定的目标。就像对待一个人一样，与系统一起探索，以更好地了解它是很有价值的。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一个原则是花一些时间玩这个系统，做你认为有趣的探索。也许你想看看模型有多善于讽刺，或者扮演你最喜欢的名人。你可以通过修改 prompt，或者尝试他人创建的 prompt 来开发直觉。你可以对意外发现持开放态度，注意到模型以一种本身有趣的方式作出响应——也许你试图让语言模型进行讽刺，但它却以巧妙的双关语做出了反应。那么，也许你可以探索它擅长哪种双关语，以及它何时会犯奇怪的错误。很有可能，当你尝试将模型应用到实际事物中时，你在亲手操作模型的过程中形成的直觉最终会对你有用，或者你可能会发现一种新的提示方法，或者至少你可能会在学习提示的过程中获得乐趣。 
</div><div>
  &nbsp; 
</div><span id="OSC_h3_2"></span><h3>哲学与技术，开发对于可能性的直觉</h3><p><span style="color:#2ea121"><strong>OSCHINA：在开发者群体中，roadmap、里程碑文化非常盛行，这是典型的目标导向。事实上，我们能看到很多知名软件都早已偏离最初的预设目标，但很多时候，时候软件标准、里程碑也能很好地指引开发团队做事。这个现象可以怎么理解？对于开发者该如何选择自己的「开发哲学」，你们有什么建议？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  目标并不总是坏的。当通往目标的路径是已知的，设定目标就会有成效。在软件开发中，完成项目的步骤通常是已知的，所以遵循目标是有意义的。然而，如果项目的目标是创新、发现或创造力，那么目标就有问题了。这样的项目可能会被目标扼杀，最终只做了很少有创造性的事情。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  首先我要说明的是，我在大型软件工程方面没有太多的个人经验。但一般来说，里程碑和标准可能非常适合在已知如何做的范围内进行的工作。距离成功可能只是一步之遥，不需要广泛探索。将软件从版本 1 升级到版本 1.1，修复一些现有的 bug 或添加一些有限的功能，可能是非常适合目标的思维的地方。但是从更长远的角度来看，如果目标是完全重新构想一个软件，或者创建一个软件来实现其他软件从未实现过的功能，那么就需要更多的探索和垫脚石思维。 
</div><div>
  &nbsp; 
</div><div>
  有时，垫脚石现象发生在更高的层面上。例如，当一个团队开发并发布一个开源库时，一个对他们的目的有用的库，一个构建在以前存在的库上的库，并且将使其他人能够创建他们自己的新库——这就是在玩寻宝游戏。因此，开发人员的哲学中，与寻宝有关的方式是，了解目前有哪些软件垫脚石，这些垫脚石可能使哪些以前没有的东西成为可能，并向世界推出新的软件，让别人能够以你无法预料的方式去使用的新软件。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：哲学思想可以如何作用于 IT 领域的研究，可以结合实际的事情来聊一聊吗？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我不确定这里指的是一般哲学还是这本书的哲学。当然，这本书的哲学也可以应用于其中。因为它只是赞同有时走一些有趣的路，即使你不知道它们通向何方。这在信息技术领域是绝对可行的。 关于一般哲学能否应用于 IT 的问题，我认为是可以的。 我认为哲学是对世界可能存在的方式的研究（与研究世界存在方式的科学相对）。 
 <strong>对「可能是什么 」的理解可以帮助你在做出选择之前看到眼前的各种可能性。</strong></div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  这很有趣——有些人把哲学和实用性对立起来。我能理解这种观点，因为我们接触到的哲学往往是抽象的、象牙塔式的。但在我看来，最重要的哲学是非常实用的。在进行包括 IT 在内的任何领域研究时，掌握一些关于如何进行发现的哲学是非常重要的。你可以通过自己的经验和观察发展出自己的个人哲学，但我们这本书的一个贡献就是强调了雄心勃勃的发现通常是如何发生的。 
</div><div>
  &nbsp; 
</div><div><strong>在我看来，研究工作最重要、最实用的方面之一是开发对于可能性的直觉。</strong>我的意思是，去理解什么样的事情是容易完成的，哪些事情是在可能性的边缘，哪些事情你不清楚你是否能够解决它们。当一个人刚进入一个领域时，当涉及到可能性时，他们的直觉通常会很差。但是，当你对可能性的直觉很好 (你大致知道一个问题有多难)，并且你的探索哲学也很合理 (如果一个问题很容易，就可以直接攻克；如果一个问题非常困难，可能无法解决，或者至少需要大量耐心的发散性探索)，那么你成功的机会就会大得多。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：无目标，新奇性搜索等哲学思想对你们的日常生活产生了哪些影响？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  这对我的日常生活很有帮助，因为我对仅仅因为有趣而去做某事的疑虑减少了。我知道它可能会成为一个有趣的垫脚石，即使我还不知道它最终将如何有用。我还把它来对待我的孩子。例如，我 9 岁的儿子有时会选择一些没有明显好处的事情，但我鼓励他去做，因为我看到他对这些项目很感兴趣，所以我相信这些项目可以引导他发现自我。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  写这本书，以及多年来对新奇性搜索的研究，这种理念不可避免地渗透到一个人的生活中。我比大多数人更乐于改变职业方向 (我目前正处于改变职业方向的过程中)，我努力保持求知欲，乐于看到意想不到的新机会，并努力在生活的不同方面之间找到广泛的联系。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：多年前你们因为图片产品的启示，开始研究「无目标」相关的哲学，这些年有没有一些实践体验带来新的哲学感悟？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span><strong>一种哲学见解认为，好的人工智能实验不仅应该带来强大的系统，还应该带来对我们人类自身的洞察。毕竟，对智能的任何伟大洞察实际上都是对人类的洞察，因为智能是我们的决定性特征。</strong></div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  这些年来，我有很多顿悟的时刻，事情以一种意想不到的方式突然发生。这些经历往往发生在阅读与我正在研究的课题有着抽象联系的有趣内容时，一种新的联系突然出现，或者当我的两个看似独立的兴趣突然联系在一起时，就达到更深层次的统一。 
</div><div>
  例如，我最近关于「机器之爱」的研究就是将我对心理学和机器学习的兴趣结合在一起。起初，这些兴趣似乎是完全分开的。但后来，随着我不断深入研究心理学， 
 <strong>我开始意识到，人类个体的生活在某种程度上是开放式的，就像生物进化一样——我们的生活没有统一的目标，我们的兴趣和心理发展往往是偶然进行的——于是，一个新的研究方向为我打开了。 </strong></div><div>
  &nbsp; 
</div><span id="OSC_h3_3"></span><h3><strong>ChatGPT</strong><strong>：或许是目标与非目标导向的产物</strong></h3><p><span style="color:#2ea121"><strong>OSCHINA：当下火热的 </strong></span><span style="color:#2ea121"><strong>ChatGPT</strong></span><span style="color:#2ea121"><strong>，或者其他</strong></span><span style="color:#2ea121"><strong>人机互动</strong></span><span style="color:#2ea121"><strong>问答产品，其背后的搜索符合新奇性搜索原则吗？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  这取决于这里所说的「搜索」是什么意思。假设是研究人员，确实有一个搜索的组成部分反映了新奇性搜索的各个方面，即使它不是明确的新奇性搜索算法。尤其是，没有人知道 ChatGPT 会成为一个世界性的现象——相反，他们决定研究它，是因为它既有趣又新奇。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  如果我们回顾一下 OpenAI 的研究历程，就会发现 ChatGPT 并不是该公司的长期目标。他们一开始就做了很多不同类型的研究，与 ChatGPT 似乎没有什么联系 (例如，机器人实验，以及教 AI 玩电子游戏的实验)。因此，创建一个功能非常强大的问答系统的道路是出乎意料的，没有计划，它取决于并建立在许多其他人铺设的垫脚石的上。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：</strong></span><span style="color:#2ea121"><strong>OpenAI</strong></span><span style="color:#2ea121"><strong> 或者 </strong></span><span style="color:#2ea121"><strong>ChatGPT</strong></span><span style="color:#2ea121"><strong> 可以称得上是一项伟大的实验 OpenAI 现在在做的事情是符合「目标导向」还是「自由探索」路径？如何解释？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  因为我已经不在 OpenAI 工作了，所以很难说他们现在正在遵循什么样的流程。但我想说的是，这很可能是一个混合体，既要努力优化以获得更好的性能（这是以目标为导向的），又要尝试其他有趣的想法（这是以新奇为导向的）。这种混合反映出，他们既需要改进现有的东西，也需要寻找下一个新事物。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  我不代表 OpenAI 发言，也不太了解他们目前的计划 (我一年前离开那里)。但我认为这两者兼而有之——既有「自由探索」，也有「目标导向」。这家公司已经不像刚成立时那样进行纯粹的原始探索，但他们仍在继续做许多有趣的研究。 
</div><div>
  &nbsp; 
</div><span id="OSC_h3_4"></span><h3>关于探索尝试、关于机器之爱</h3><p><span style="color:#2ea121"><strong>OSCHINA：你们提到一句话：「如果你想在有远见的人身上投资，就看看那些在附近的不确定性领域中徘徊和探索的人。」这句话里「附近的不确定性领域」是容易被发现的吗？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  不，我觉得这不容易发现。这就是为什么发现这些变革性机会的人如此罕见。我们经常假设世界运行的方式，这让我们对仍然存在的问题视而不见。然而，一旦有人指出了其中的一点，那么其他人就很容易看到了。但首先看到它就是一件不平凡的事情。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一开始不容易发现，但这是一种可以培养的技能。这是一种识别当前存在哪些垫脚石以及这些垫脚石可能带来什么的技能。通过一些专业领域知识，更容易识别「邻近的不确定性区域」。例如，我对量子物理知之甚少，我很难理解什么是已知的，什么是未知的，或者当前的垫脚石是什么样的。但在我工作多年的人工智能领域，我确实对该领域中有趣的不确定性有丰富的直觉。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：现在的 </strong></span><span style="color:#2ea121"><strong>AI</strong></span><span style="color:#2ea121"><strong> 世界，有哪些很酷的尝试？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我认为计算机辅助创作很有趣，多模态 (如文本与图像) 以及新型音乐的可能性也很有趣。比这些更酷的是幻觉的解决方案或产生真正开创性想法的能力。然而，据我所知，这些问题的解决方案还不存在。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一个很酷的现象是，大模型正在重塑、重新想象旧算法。例如，一个大语言模型可以通过指令来创建一个计算机程序或一段文本的新变体，这将不仅仅是随机变体，而是智能变体——因为大模型是在大量计算机程序和文本中训练出来的。因此，你可以使用语言模型作为智能变化的引擎，从而使新型进化算法成为可能。通常，进化算法使用随机变化——但使用语言模型的进化算法更接近人类发明新想法的方式，即对其进行智能的探索性修改。 
</div><div>
  &nbsp; 
</div><div>
  这只是大模型如何重新发明算法的一个例子，但总的来说，它们是有趣的新工具——令人兴奋的新跳板——并为构建以前不可能构建的东西开辟了许多新的有趣的可能性。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：机器之爱真的能实现吗？个性化推荐、信息茧房、偏见、制度、思想、等等各种有形或事无形的阻碍充斥在各个地方，目之所及似乎都是困难。如果把「美好的人与机器的世界」做为目标，我们大概率会踩到错误的垫脚石上。如果用「寻宝原则」做导向，放任当下的机器研究自由发展，会不会使得情况更为糟糕？而现在要做的事情又是什么呢？</strong></span></p><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  我相信，机器之爱的某些方面是可以实现的——这似乎是一个简单的事实，语言模型确实可以使机器开始处理定性和心理方面的工作，这可以让我们设计出关系自身成长和发展的算法，而这正是机器之爱的核心理念。在我看来，这是一块值得关注的有趣垫脚石，尽管目前还不清楚它会通向哪里——我们有理由怀疑，机器之爱的完整愿景是否会实现，它想要改变我们的世界确实还有很多障碍。但它可能会带来其他的垫脚石，以及应对这些障碍的方法——我们还不知道。 
</div><div>
  &nbsp; 
</div><div><strong>除了「机器之爱」（这只是改善机器对我们的影响的一个想法）之外，我们应该大胆地探索机器如何帮助我们人类过上更好的生活的许多不同愿景，也许这些愿景中的一个可以实现。我们永远不可能完全知道一块垫脚石会把我们带到哪里，但我们会尽最大努力，在不确定性和希望解决世界难题之间取得平衡。</strong></div><div>
  &nbsp; 
</div><div>
  我坚信， 
 <strong>在开发新技术时，寻宝原则不是我们应该遵循的唯一原则，让当前的机器学习不受阻碍地发展，可能会给社会带来许多负面的外部影响。</strong>一种观点认为，对社会安全的搜索也是一个开放式的搜索过程，就像对更强大的技术 (如大模型) 的探索一样。在寻找安全的过程中，就像在寻找技术一样，垫脚石的结构是不明确的，因此我们需要广泛而好奇地探索可能的干预空间 (例如，政府政策、新算法、公共教育、文化运动)，同时要知道，安全无法得到完全保证。在鼓励创新的同时，我们仍应尽最大努力维护社会，这可能需要智慧、克制和创造力。 
</div><div>
  &nbsp; 
</div><div>
  更具体地说， 
 <strong>在机器时代，我们越来越需要人类代理的提醒。技术的目的是为人类的利益服务，而人类是构建和设计这项技术的人。除了我们自己，还有什么能让我们保持谨慎呢?</strong></div><div>
  &nbsp; 
</div><div><hr></div><div>
  👍 为什么伟大不能被计划：OpenAI 科学家跨界撰写的思维奇书，源自人工智能研究的意外发现，找到人类伟大发明的真正入口，颠覆传统目标理论，重塑认知与思维模型，向普通人描绘一幅不同的成功图景 。 
</div><div><hr></div><div>
  【💰售价】39.50 元 
</div><div>
  👉购买链接：https://j.youzan.com/TTuo6A 
</div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 01:55:22 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/10149295</guid>
            <link>https://my.oschina.net/u/4489239/blog/10149295</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Intel SIG 成立！携手打造 openKylin-Intel 技术生态]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">2023 年 11 月，经 openKylin 社区技术委员会审议通过，</span><strong><span style="color:#000000">Intel SIG</span></strong><span style="color:#000000">正式成立。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 由</span><strong><span style="color:#000000">英特尔中国</span></strong><span style="color:#000000">发起成立，负责 openKylin 社区中桌面操作系统上 Intel 最新平台支持、适配与优化等技术相关的开发工作。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">01&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 目标</span></strong></span></p><ul><li><span>创建并维护 openKylin Intel 新平台的规划和升级，建设更完善的 openKylin-Intel 技术生态；</span></li><li><span>充分利用 openKylin 提供的平台，把最新的 Intel 技术基础软件栈融入 openKylin 操作系统，为未来社区的创新和发展提供更广阔的空间，为推动 Intel 产品的落地提供生态支撑。</span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">02&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 职责</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">1、Intel 新平台</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根据 openKylin 社区的规划，并且结合上游内核的开发，Intel SIG 会对 Intel 最新的平台在下游社区进行全面支持。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">2、Intel 新技术</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根据客户的需求，引入 Intel 优势技术，更好的提供可行性方案；拓展更广的技术和商业合作空间。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">3、OEM 的支持</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根据桌面平台的生产商 (OEM)，Intel 可以根据 OEM 的需求以及 openKylin 的要求，合作支持 OEM。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">4、与 openKylin 共赢</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 愿意与 openKylin 各方合作，共同构建面向未来的良性合作生态环境，为 openKylin 开源桌面操作系统的发展提质提速。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">03&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">欢迎加入 SIG</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 负责 openKylin 社区中 Intel 技术相关的开发和信息交流，本小组拥有国内外顶尖的 Intel 平台研究技术团队，为拓展 openKylin 的生态提供有力支撑，期待各位感兴趣的小伙伴们的加入！</span></span></p><ul><li><span>邮件列表：</span></li><li><span><span style="color:#0052ff">intel@lists.openkylin.top</span></span></li><li><span>SIG 主页：</span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/Intel-SIG</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 01:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267352</guid>
            <link>https://www.oschina.net/news/267352</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云原生周刊：Istio 1.20.0 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Floft-sh%2Fdevpod" target="_blank">DevPod</a></h3><p>DevPod 是一款纯客户端工具，可在任何后端基于 devcontainer.json 创建可重现的开发人员环境。每个开发者环境都在一个容器中运行，并通过 devcontainer.json 进行指定。通过 DevPod 提供商，这些环境可以在任何后端创建，如本地计算机、Kubernetes 集群、任何可访问的远程机器或云中的虚拟机。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFairwindsOps%2Fgemini" target="_blank">Gemini</a></h3><p>Gemini 是用于管理卷快照的 Kubernetes CRD 和 operator。可以定期为 PersistentVolumes 上的数据创建快照，清空旧快照，并以最少的停机时间恢复快照。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fr0binak%2FMTKPI" target="_blank">MTKPI</a></h3><p>MTKPI - 多工具 Kubernetes 渗透测试镜像。该 docker 映像包含 Kubernetes 渗透测试所需的所有最常用工具。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-alert-and-monitoring-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 个最佳告警和监控工具</a></h3><p>这篇文章介绍了针对 Kubernetes 的前五个告警和监控工具。文章指出，Kubernetes 作为容器运行应用程序的首选选择，具有可伸缩性、灵活性和弹性等优势。然而，管理和监控 Kubernetes 可能会相当困难。因此，对于保证应用程序平稳可靠运行的关键是监控和告警。监控和告警是有效运营 Kubernetes 集群的实践方法，它们使您能够收集集群、节点、Pod、容器、服务和应用程序的指标、日志和跟踪数据，并使用仪表板、图表和表格对数据进行可视化和分析。通过规则、阈值和通知对异常、错误、故障和 SLA 违规进行告警，并通过调查根本原因、解决问题或升级到适当的团队来采取行动。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-machine-learning-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 大机器学习工具</a></h3><p>这篇文章介绍了在 Kubernetes 上进行机器学习的五个顶级工具。文章介绍了每个工具的特点、优势和使用案例，以及选择这些工具的标准，如功能性、易用性、流行度和创新性。通过使用这些工具，用户可以更轻松地在 Kubernetes 上进行机器学习任务，并提高其工作流程的效率和可靠性。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspacelift.io%2Fblog%2Fkubernetes-deployment-strategies" target="_blank">8 种不同类型的 Kubernetes 部署策略</a></h3><p>这篇文章介绍了 Kubernetes 的八种不同部署策略，包括 Recreating、Rolling、Blue/Green、Canary、A/B、Ramped Slow Rollout、Best-Effort Controlled Rollout 和 Shadow Deployment。它解释了每种策略的优点和用途，帮助读者在应用程序部署和升级时做出明智的选择。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubescape.io%2Fblog%2F2023%2F09%2F19%2Fintroducing-kubescape-3%2F" target="_blank">Kubescape 3.0 发布</a></h3><p>Kubescape 是 CNCF Kubernetes 安全姿态管理工具的下一代，日前发布了 v3.0。</p><p>Kubescape 3.0 新增以下功能：</p><ul><li>将合规性和容器扫描结果存储为 Kubernetes 集群内的资源</li><li>通过命令行界面扫描容器镜像的漏洞</li><li>报告集群中所有镜像的漏洞情况</li><li>全新的概览安全扫描，帮助你为集群安全设置基线</li><li>突出显示高风险工作负载：那些如果受到损害可能造成最大危害的工作负载</li><li>改进的显示输出</li><li>新的基于能力的 Helm chart</li><li>每个工作负载、命名空间和集群的 Prometheus 指标</li><li>通过 Prometheus Alertmanager 进行告警</li><li>将数据发送到集群外的托管服务</li></ul><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.opencost.io%2Fblog%2Faks-cost-analysis" target="_blank">OpenCost 宣布与 Microsoft AKS 成本分析工具集成</a></h3><p>OpenCost 正在与 Microsoft 的新 Azure Kubernetes Service（AKS）成本分析工具集成，以实现使用度量收集。Microsoft Azure 的客户现在可以根据 Kubernetes 特定的结构，原生地了解成本分配的可见性。</p><p>AKS 成本分析是针对标准和高级 AKS 群集的附加组件，向客户提供免费的服务。它直接在 Azure 门户中提供成本分配报告。AKS 客户现在可以轻松地可视化其 Kubernetes 成本分配，作为进一步优化和异常检测的基础。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fistio.io%2Flatest%2Fnews%2Freleases%2F1.20.x%2Fannouncing-1.20%2F" target="_blank">Istio 1.20.0 发布</a></h3><p>Istio 1.20.0 发布，这是 2023 年最后一个 Istio 版本，以下是该版本主要变化：</p><ul><li>网关 API</li><li>改进的外部名称服务支持</li><li>一致的 Envoy 过滤器排序</li><li>对网络 WasmPlugin 的扩展支持</li><li>TCP 元数据交换增强</li><li>插入根证书轮换</li><li>流量镜像现在支持多个目标</li><li>...</li></ul><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 10:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10149219</guid>
            <link>https://my.oschina.net/u/4197945/blog/10149219</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[运营商神操作：后台断网、停用宽带账号，强迫用户更换光猫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，河南电视台都市频道节目报道称，河南周口联通为了强迫用户更换光猫，<strong>公司在后台停掉用户的宽带账号，导致用户无法上网，然后让工程师上门「维修」，谎称光猫损坏，需要花 299 元换新</strong>。<strong>更换完后，联通再在后台恢复用户的网络</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6bca55961849d5db6bafd2b8cf31a04abc6.png" referrerpolicy="no-referrer"></p><p>联通公司不仅对老用户进行这种强制更换光猫的行为，还会在给新用户装机的时候，故意使用破旧光猫，也就是之前强迫用户换新留下的，而再过一段时间之后，又会告诉用户使用的是旧光猫无法匹配，必须换新。联通公司还会故意关掉用户的短信服务，在后台增加增值业务，之后再把短信功能打开，以此牟利。</p><p><img height="826" src="https://static.oschina.net/uploads/space/2023/1120/163843_Utox_2720166.png" width="1518" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1120/164043_bGMp_2720166.png" referrerpolicy="no-referrer"></p><p>周口联通回应称，全力配合省公司调查组进行调查核实。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5af067ca7f5336640898e328da5adc6109b.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.sina.com.cn%2Fs%2F2023-11-20%2Fdoc-imzvfrzw9582625.shtml" target="_blank">https://news.sina.com.cn/s/2023-11-20/doc-imzvfrzw9582625.shtml</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267276</guid>
            <link>https://www.oschina.net/news/267276</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里云开源大数据产品年度发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文根据 2023 云栖大会演讲实录整理而成，演讲信息如下：</p><p><strong>演讲人</strong>：陈守元 | 阿里云计算平台事业部开源大数据产品总监</p><p><strong>演讲主题</strong>：阿里云开源大数据产品年度发布</p><p>随着云计算的不断发展，未来数据处理和应用的趋势将围绕 Cloud Native、Severless 和 Data+AI 展开。其中，云原生架构已成为主流趋势，因为它可以提高数据处理和应用程序的可伸缩性和灵活性，支持大规模部署和更快的响应时间。同时，Serverless 作为一种新型计算模式，可以提高处理效率、降低运营成本并减少资源浪费，其独特的特点使得其成为处理大规模数据的理想选择。此外，Data 与 AI 融合正在快速发展，不断提高智能化和自动化程度，同时需要高质量的数据来支撑算法的准确性和有效性。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a48d65a7b7035e480f3276674b7f31f68a3.png" alt="" referrerpolicy="no-referrer"></p><h2>EMR：面向下一代湖仓和全面 Serverless 化</h2><p>下面进入产品发布环节，我们将围绕上面三个点&nbsp;做哪些事情、有哪些发布更好地服务用户上云&nbsp;来讲述我们产品的重点发布。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4026c36c77d94f189e70fb9fe1cb0464515.png" alt="" referrerpolicy="no-referrer"></p><p>首先，我们来看 EMR。EMR 是一个云原生开源大数据平台系统。对于 EMR 而言，线下 IDC 大量基于开源 Hadoop 生态构建的线下用户搬站上云第一站就会选择 EMR，因为改造代价特别地小，几乎可以无缝平迁上云。这对用户来说是具有巨大的人力资本和机器资本的节省。&nbsp;我们将阿里云 EMR 定位为&nbsp;用户搬站上云的第一站。</p><p>今年我们的产品矩阵做了升级，我们希望在云上基于更多样化的 IaaS 提供多样化的 EMR 产品形态。EMR 通用版，核心解决的用户问题就是帮助用户的大数据系统平迁上云，这也是和用户线下部署兼容度最高的方案。第二个是 EMR 容器版，即 EMR ACK 版。现在 IT 基础设施的云原生容器化基本上都深入人心，我们大量客户在云上基于 IT 系统的构建都会选择容器化的平台，例如阿里云的 ACK。用户自然而然会联想到如何把 Data 和 AI 的 workload 迁移到 IT 基础设施的同一个集群里，完成 Data&amp;AI 的负载&nbsp;与 IT 设施负载混用，EMR 容器版，或者说 EMR onACK 就是帮用户解决这类问题的产品。</p><p>最后也是我们今天想强调的重点就是 EMR Serverless 版。对于 EMR Serverless 子产品线而言，内部有些 feature 或者功能&nbsp;在之前云栖中已做了发布。今天对于 EMR Serverless 产品线是一个更加完整的矩阵呈现，今天会重点讲一下 Serverless Spark、Serverless StrarRocks 两大主流 EMR 计算引擎的 Serverless 化，今天也是我们正式对外提出一个完整的 EMR Serverless 化的产品线矩阵。</p><p>EMR Serverless 版是 EMR 产品线形态中诞生最晚、发布最新的一代产品和技术，其实 EMR 围绕 Serverless 的布局在一年前、两年前都在紧锣密鼓地进行。前面 OSS-HDFS、Serverless HDFS 这一块其实在去年、前年已有发布，但是今年我们做了更多的尝试努力，我们希望把 EMR 上面主流的大数据计算引擎、存储引擎、开发平台、元数据管理全都 Serverless 化，只有这样方才能够更好地满足云原生用户更好地利用大数据。Serverless Spark，更好地解决了湖仓场景下 Data ETL 的处理能力，Serverless StrarRocks 更好地解决了湖仓场景下 Data analytic 能力，Serverless HDFS 更好解决了湖仓场景下数据存储能力，最后 EMR Stutio 帮助用户线下可以平迁体验上云，让用户能够更好使用云上大数据基础设施，同时还能免运维。所以 EMR 今年从计算，到存储，到开发环境&nbsp;几乎全部实现了 EMR 主力引擎和平台都能够做到 Serverless 化，我们希望能够把整个大数据开发运维闭环，从而进一步帮助云原生上的开发者更好地把大数据用起来。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e0e494088f0e316e87a203fb7a7b147a1c7.png" alt="" referrerpolicy="no-referrer"></p><p>下面仍然回到 EMR 主力场景， EMR 通用版，围绕湖仓场景做了大量更新。EMR 主力场景仍然围绕着湖仓处理，围绕在湖仓计算、存储、运维、开发做了大量的更新。在计算层面，我们核心还是降本提效，IaaS 层适配了新的倚天 CPU，PaaS 层做了 Native Spark RunTime，这些都是从 IaaS 层和 PaaS 层更好地帮助用户降本提效。存储部分，Serverless HDFS (同时也称之为 OSS-HDFS)&nbsp;很早已有发布，但是在这一年希望让 Serverless HDFS 和&nbsp;本地 HDFS 在使用层面给用户体验完全一致，包括&nbsp;在&nbsp;文件性能、数据访问、源数据获取等方案&nbsp;做到几乎完全一致。为上述目标，我们因此做了大量有关系统性能优化&nbsp;以及&nbsp;系统安全性优化。我们的 Open 文件性能的提升、DU 访问源数据的提升，这些都是今年的成果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-00bfea3732092d7e26b3743ad341b1f080a.png" alt="" referrerpolicy="no-referrer"></p><p>EMR 运维，这主要体现在两个方面。在云上来说 EMR 能结合到云原生上面给用户创造比较大的平台价值就在于弹性，今年我们做到大量的弹性优化。我们大量客户给我们反馈说 EMR 的平台弹性越来越稳定；另外一个运维重点，即 EMR Doctor，我们希望通过 AI 的方式、自动化、智能化的运维平台方式帮助用户去解决开源大数据运维的问题。从社区开源大数据用户反馈来看，开源大数据使用最大的、最痛的点就是系统运维。如何长期有效地保证我们的业务在云上健康地运行，这是很多用户上云和云下使用开源大数据非常大的痛点，EMR Doctor 就是解决这个问题。EMR 开发，即 EMR Studio，我们希望云原生 Serverless 化托管了我们的开发平台、调度平台，帮助用户从线下的体验完全平迁到云上的一套体验。以上均是 EMR 围绕湖仓场景的重大更新。</p><p>最后仍然回到 EMR For AI，我们每个产品都在拥抱积极的变化，这里分为三部分：EMR DataScience、EMR Doctor、EMR+DataWorks 的 Code Pilot。EMR DataScience 是在 EMR 的容器版里面，我们提供了一个新的集群叫 EMR DataScience，里面内置了不少 AI 最流行的组件，包括 Pytorch、TF。我们希望用户在一个平台上既能够处理大数据，同时还能够云原生地处理 AI 的工具，这是 EMR DataScience 帮助用户做的相关工作。EMR Doctor，这个工作前面提到希望用 AI 化、智能化的方式帮助用户实现 AIOps，能够用自动化的手段定位问题、诊断问题、及早发现问题。EMR+Dataworks，今年 DataWorks 重磅的发布就是 code pilot 的发布，但是那上面作为一个平台实际上底下也对接了 EMR 等等，正好实际上 code pilot 也是平台引擎无关的 Feature，可以生成 EMR 里面的 HIVE 代码，用户就可以用 DataWorks 上面开发平台能够通过自然语言生成 MaxCompute 的 SQL，能够操作业务，这样能够极大地减少用户开发代码的成本，这在 DataWorks 对外提供公测的时候欢迎去试用一下。</p><h2>Flink Streaming Lakehouse：新一代的流式湖仓新方案</h2><p>下面我们看一下 Flink Streaming Lakehouse。Lakehouse 这个概念其实在前几年很火，原因就是对于一个 Lakehouse 的系统来说，既兼具了 Data Warehouse 的严谨，包括 ACID、版本的管理、数据格式的校验等等；同时它还有 Data Lake 的灵活性，能够放很多大量非结构化的文本，包括图片、视频、音频、图像等等。而 Lakehouse 同时能够承载结构化的数据和非结构化的数据，这对用户来说是非常好的 AI 和大数据融合的底层存储方案。但是我们看 Lakehouse 的过程中发现 Lakehouse 在时效性方面有非常大的问题，Flink 核心使命和价值就在帮助我们的客户解决大数据实时化转型和升级。所以 Flink 社区&nbsp;和&nbsp;我们&nbsp;一起发布了 Streaming Lakehouse 方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-37eae0cedf4dbaf6356c5188b319f6e8a02.png" alt="" referrerpolicy="no-referrer"></p><p>回到 Streaming Lakehouse 我主要从产品方向&nbsp;讲三个场景要点。前面已经提到 Lakehouse 在 AI 时代下 Lakehouse 的方案会越来越重要，因为它既能存储结构化的数据又能存储非阶段的数据，这个是大数据和 AI 一体化存储的重要承载点。但是 Lakehouse 在实践的过程中仍然遇到时效性的问题，整个 Lakehouse 的 Data Pipeline 串联起来可能达到小时级别的延迟，从最开始的数据进入到数据价值的发挥，比如 BI、AI，能够看到整个数据链路到小时级别，这其实对于用户来说要构建一个实时湖仓面临很大的延迟。所以 Flink 希望一起帮助用户做到 Lakehouse 的实时化，通过流式、实时帮助用户做很大的提升。</p><p>最后是 Unified，其实 Flink 社区在前几年一直主打 Unified Batch &amp; Streaming。我们希望在计算层面做到融合，就是流批一体。我们在开源社区推广流批一体的方案时，发现如果用户只是计算层面的融合对于用户只能解决一半的问题。还有一半问题在于存储，存储仍然是两套的存储方案，两套存储和两套数据因此会导致的离线和实时的数据不一致性对于用户来说是非常大的问题，所以 Flink 团队和社区一起构建了 Paimon。Paimon 基于底层的分布式文件系统，比如说 OSS 会构建一个 Unified 的 storage，既可以做流，也可以做批，我们称之为批流一体的存储。所以 Flink+Paimon 构成 Lakehouse 的方案，既具备 Unified 的 process，也可以具备 Unified 的 Storage，这一层合并在一起能够真正完整地帮助用户实现流批一体的解决方案。这是我们 Streaming Lakehouse 的价值点，最终我们希望帮助用户在 Data+AI 时代下提供实时化、流式化和 Serverless 化的湖仓方案。</p><p>回到 Flink 主线，我们一直以来的使命就是希望帮助用户做到大数据的升级和转型，所以追求实时场景下的性价比一直是 Flink 团队一直以来努力的方向。追求实时化的性价比今年有两个重要的点，一个是 Flink 全面拥抱了倚天，结合到倚天&nbsp;整个实时计算 Flink 综合的性价比有 50% 的提升，这是 Flink 团队结合 IaaS 层面做了大量优化。同时在 PaaS 层 Flink 企业级内核&nbsp;我们仍然在做大量优化，这其中包括算子的优化，以及未来我们会公布 native runtime 的优化。这部分优化相比于开源 Flink 引擎，我们实时计算 Flink 版&nbsp;会有两倍的提升，特别是在吞吐部分可以解决很多用户高吞吐量或者大流量的实时计算场景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-93711ed92a4488a619f2f0cfa9e51e70d03.png" alt="" referrerpolicy="no-referrer"></p><h2>Elasticsearch:Serverless 和 Search for Data &amp; AI</h2><p>接下来讲一下 Elasticsearch，这也是开源大数据很重要的组成部分。说到 Elasticsearch 可能大家更多仍然停留在比较早期 for data 的 search，就是全文的检索，类似于搜索引擎要做全文的检索。但今天我想告诉大家这个思想需要刷新一下，Elasticsearch 不仅是 for data 的 search，也是 for AI 的 search。我今天给大家重点会讲一下 ES 如何从 Data 转变成 Data+AI 的 search 系统。</p><p>第一个是我们的 Elasticsearch 的版本发布。坦白地说，当前产品形态，即 ES on PaaS 的独立集群版本已经非常好地满足我们中国公有云和专有云客户很多的市场需求，不少中大型公司都非常认可阿里云的 ES 产品形态，产品客户受众无论在基数以及未来增长都很不错。但实际上随着最近这一两年客户在降本提效上提上了日程之后，发现有一批非常大的潜在客户以及中长尾的客户其实仍然对云上的独立集群版本所带来的成本仍然认为是比较大的上云入门门槛。他们非常希望以低门槛甚至零门槛的方式开启云上的 ES，这就是我们 ES Serverless 要做的初衷，我们希望以一个零门槛的方式能够帮助用户开启云上 Elasticsearch 的使用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dda1df3c99a6593d14261aabceb742084c0.png" alt="" referrerpolicy="no-referrer"></p><p>同时 Elasticsearch Serverless 也是我们国内首家支持通用场景的 ES 版本。去年我们也发布了一个 Elasticsearch Serverless 版本，但更多解决日志 ELK 场景的需求。但是该版本在数据一致性上会存在问题，所以今年我们进行大量的产品技术架构重构。本次 ES Serverless 的发布是一个面向通用场景的升级发布，这里面不仅支持包括日志场景，还支持订单、金融等等场景，这里面的数据一致性都可以得到很好的保障。这是我们今年发布相比于去年发布升级很不一样的点。针对 ES Serverless 可以真正按量付费、秒级弹性、简单运维，同时可以完全兼容开源的 ES，这是很多其他的厂商不一定能做到的。</p><p>下面重点强调 ES for AI 和 Data 的部分，标志着 ES 真正从 Data 面向 Data&amp;AI 的搜索引擎。云栖会场外面有很大的广告栏，主打的是 ESRE 的发布，这是 ES 公司重大的发布。发布的核心简单跟大家说一下，就是支持 AI 相关检索，包括向量检索，包括多路并规的查询优化，这些东西都是在 ES 内核重点打的点，帮助用户做 AI 检索。阿里云 ES 围绕着 ES 最新的 AI 能力进行了大量方案集成，就是右边的增强方案。我们跟达摩院 AI 方案做联合，和 PAI—EAS 方案联合，甚至会和社区一起做更多的联合方案，这些方案能够帮助我们的用户更好地在云上用上阿里云、达摩院 AI 的技术，和社区的 ES 更好地结合起来。所以我们希望通过 ES8.9 这个版本能够帮助用户构建下一代面向 Data+AI 的检索系统。</p><p><img src="https://oscimg.oschina.net/oscnet/up-47305474e3702aae7f01185fc4b3c7a7d65.png" alt="" referrerpolicy="no-referrer"></p><p>围绕 ES 自研能力的升级，阿里云 ES 是和 ES 公司一起合作，也是基于开源的 ES 做更多的优化孵化，其实是完全基于开源，也是完全兼容开源的，我们做了大量的增强。而这里面做了三个升级，包括场景的升级，也就是日志场景向通用场景的升级和改造。去年 ES 更多是做日志场景、ELK 场景，今年的 ES Serverless 面向通用场景进行完全开放。另外就是有关搜索内核引擎的优化，包括读写分离、存算分离，这些更好地解决集群稳定性问题、成本流控问题、资源弹性的问题。最后我们在购买链路和相关控制枱上做了比较大的体验升级，我们非常推荐大家去用一用阿里云 ES Serverless 版本，感受一下完全 Serverless 化的 ES。</p><h2>Milvus：AI 时代的搜索引擎</h2><p>今天最后一个，也是今年完全新的产品。前面全部是我们现有的功能、现有产品线的叠加，Milvus 这部分是我们今年要发布的 AI 时代新的搜索引擎。目前，在向量检索部分 Milvus 几乎是全球最火、最亮眼的技术。我们会在 12 月份开启向量检索 Milvus 版本对外测试，相比于开源的 Milvus 来说会做相应产品企业级的增强。同时在兼容开源的 Milvus 之上，我们还会去结合达摩院的技术能够提供更好的企业级向量检索能力。同时在云上肯定会做大量的产品联合工作，包括和我们的存储上有大量非结构化的数据可供用户检索查询。同时我们会跟 PAI 平台、达摩院 AI 模型做更多的深度集成，做 AI 向量检索能力、做大模型向量支撑，这些方案未来都会在我们的产品之上构建。所以我们最终是希望能够帮助云上使用 Milvus 的用户更快、更方便、更低门槛构建 AI 时代下的搜索系统。</p><p><img src="https://oscimg.oschina.net/oscnet/up-684d85b432854ecd04eafd9cad2a5a50df8.png" alt="" referrerpolicy="no-referrer"></p><p>回顾一下我们讲了大数据的三个趋势。Cloud Native，整个 IT 投资都在往云上加速转型。Serverless 化，我们认为未来的 PaaS 平台最终全部都会归到 Serverless 化，所有 AI 产品、大数据产品和其他 PaaS 产品都会归到 Serverless 化。最后是 Data+AI，未来 AI 和大数据会做彻底的融合打通，这也是我们整个开源大数据一直以来在积极围绕这三个点做布局。</p><p>最后希望大家多多关注阿里云，关注阿里云的开源大数据，谢谢大家！</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/10149103</guid>
            <link>https://my.oschina.net/u/5583868/blog/10149103</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 前 CEO 和总裁 Sam Altman & Greg Brockman 加入微软]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软 CEO Satya Nadella 刚刚<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsatyanadella%2Fstatus%2F1726509045803336122" target="_blank">发布推特称</a></u>，OpenAI 前 CEO 和总裁 Sam Altman &amp; Greg Brockman 将加入微软，他们负责领导新的 AI 研究团队。</p><p><img height="1176" src="https://static.oschina.net/uploads/space/2023/1120/155839_imd2_2720166.png" width="1264" referrerpolicy="no-referrer"></p><p>Sam Altman 转发了这条推文，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1726510261509779876" target="_blank">并说道</a></u>：不忘使命，砥砺前行。</p><p><img height="678" src="https://static.oschina.net/uploads/space/2023/1120/161424_UZuO_2720166.png" width="1272" referrerpolicy="no-referrer"></p><p>Satya Nadella <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsatyanadella%2Fstatus%2F1726516824597258569" target="_blank">评论了 Sam 的推文</a>：</p><blockquote><p>Sam，我对你以首席执行官身份加入新团队感到无比激动，你将为我们的创新工作开辟新的道路。</p><p>多年来，我们学会了如何为创始人和创新者提供空间，让他们在微软内部发展独立的身份和文化，这一点从 GitHub、Mojang Studios 到 LinkedIn 的发展中可见一斑。我迫不及待想看到你也能做到。</p></blockquote><p><img height="1372" src="https://static.oschina.net/uploads/space/2023/1120/164746_aILD_2720166.png" width="1286" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267272</guid>
            <link>https://www.oschina.net/news/267272</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 回归失败，OpenAI 董事会聘请 Twitch 前高管担任 CEO]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">据</span>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fbreaking-sam-altman-will-not-return-as-ceo-of-openai" target="_blank">The Information</a>&nbsp;<span style="color:#000000">和</span>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-20%2Fopenai-s-board-hires-former-twitch-executive-shear-as-ceo" target="_blank">Bloomberg</a>&nbsp;<span style="color:#000000">消息称，经过一个周末的谈判，OpenAI 董事会决定不顾投资者要求 Sam Altman 复职的呼声，聘请前 Twitch 首席执行官 Emmett Shear 来担任该公司的临时首席执行官。</span></p><p><span style="color:#000000">OpenAI 联合创始人兼董事会董事 Ilya Sutskever 向员工表示，公司高管有尝试努力挽回 Sam Altman，但没有成功，Altman</span>&nbsp;<span style="color:#000000">将不会回到 OpenAI。</span></p><p><img alt="" height="300" src="https://static.oschina.net/uploads/space/2023/1120/153143_G4mc_4252687.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Emmett Shear 将从 Mira Murati 手中接过这一职位，这也意味着 OpenAI 在三天内迎来了第三任首席执行官。此前，在 Sam Altman 被突然解雇后，曾有大批 OpenAI 员工开始在社交媒体上表达了对 Altman 的支持，Mira Murati 也在此列。</span></p><p><span style="color:#000000">Shear 在 2006 年帮助推出了游戏流媒体网站 Twitch，并于 2014 年以近 10 亿美元的价格将其出售给亚马逊。今年早些时候，Shear 辞去了 Twitch 的首席执行官一职。</span></p><p><span style="color:#000000">有知情人士表示，Shear 之所以能赢得 OpenAI 董事会的青睐，是因为他能意识到人工智能所带来的生存威胁。此外，<span style="background-color:#ffffff">Open AI 的董事会已经至少联系了两名科技行业的知名高管，希望其中一位可以担任公司董事长的职位。</span></span></p><p><span style="color:#000000">OpenAI 及其最大投资者微软的发言人目前暂未回应相关置评请求。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 07:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267256/openai-twitch-ceo-shear</guid>
            <link>https://www.oschina.net/news/267256/openai-twitch-ceo-shear</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周热点 | OpenAI 内讧，奥特曼被驱逐；俄罗斯操作系统 Aurora OS 5.0 全新 UI 亮相；.NET 8 正式 GA.....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2023.11.13-2023.11.19]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 03:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093971&#38;idx=1&#38;sn=3f2a763dda28e1c46c3aeca3f287766e&#38;chksm=880c4c40bf7bc556325bae39dd086d3b0d3cea17b35ad8c141b34669fc8c632bc161023a587a&#38;token=584579097&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093971&#38;idx=1&#38;sn=3f2a763dda28e1c46c3aeca3f287766e&#38;chksm=880c4c40bf7bc556325bae39dd086d3b0d3cea17b35ad8c141b34669fc8c632bc161023a587a&#38;token=584579097&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[Linux Kernel 6.6 确认成为 LTS 版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Greg Kroah-Hartman 已经宣布 Linux Kernel 6.6 版本为长期支持 (LTS) 版本；支持期限到 2026 年 12 月。</span></p><p><span style="color:#000000">Linux Kernel 6.6 于 10 月 29 日正式发布，是一次包含了新功能、硬件支持、安全增强和性能改进的重大更新。具体包括有：引入了 EEVDF scheduler，最终实现了对 Intel Shadow Stack 的支持，为 Nouveau DRM 驱动程序添加了 Mesa NVK Vulkan 驱动程序所需的&nbsp;user-space API，继续支持即将到来的 Intel 和 AMD 平台，以及大量的其他驱动程序改进和一些不错的性能优化等。</span></p><p><img height="254" src="https://oscimg.oschina.net/oscnet/up-40bae094eb2126579af39e14031fa92878c.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">一般来说，年度 LTS 内核往往是该日历年的最后一个稳定内核版本。Linux 6.6 于十月底发布，Linux 6.7 预计可能会在 2023 年的最后几天或者 2024 年年初达到稳定。但考虑到 6.7 版本规模较大，且年末的假期往往会放慢测试和 bug 修复的速度，导致相关周期拖长，因此 6.7 版本大概率还是可能在 2024 年初登陆。</span></p><p><span style="color:#000000">目前，Kernel.org 已更新相关版本信息。Linux 6.6 生命周期将将截止 2026 年 12 月；与此同时，Linux 6.1、5.15 和 5.10 也将于 2026 年 12 月结束生命周期。因此根据当下的政策，Linux 6.6 LTS 将在未来三年内得到维护，不过也有消息称内核开发人员一直在讨论将 LTS 支持期缩短为 2 年。</span></p><p><span style="color:#000000">更多详情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kernel.org%2Fcategory%2Freleases.html" target="_blank">此处</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 03:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267220/linux-6-6-lts</guid>
            <link>https://www.oschina.net/news/267220/linux-6-6-lts</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 以访客身份回到 OpenAI，和公司高管会面谈判]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据 The Information 报道，OpenAI 首席战略官 Jason Kwon 在员工备忘录中表示，<strong>上周五离职的 Sam Altman 等高管或将会回到公司</strong>。</p><p>而 Altman 本人也在周一<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1726345564059832609" target="_blank">推文</a></u>写道「这是我第一次也是最后一次带这玩意」，配图是他手持 OpenAI 访客工牌的自拍，表示他持访客证明造访了 OpenAI 总部，与公司董事会讨论某事。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-01348c9bedfa830267784f185d7e8e2dbeb.png" referrerpolicy="no-referrer"></p><p>有消息称，包括微软在内的投资者正在向 OpenAI 董事会施压，要求他们同意 Sam Altman 等离职高管回归 OpenAI 工作。</p><p>目前尚不能确定 Altman 等人是否会回到 OpenAI 继续工作。有消息称，Altman 正计划同前 OpenAI 总裁 Greg Brockman 一起成立一间新的 AI 公司。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 02:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267200</guid>
            <link>https://www.oschina.net/news/267200</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中国科学院软件所在分组加密算法差分密码分析方面取得进展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">中国科学院软件研究所可信智能系统研究团队在分组加密算法的差分密码分析方面取得<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbrkeBtNVsRP27RgnXZLnVg" target="_blank">进展</a>。该工作设计了一个面向分组加密算法的领域编程语言 EasyBC，在此基础上提出了通用、可扩展的差分密码分析方法，研制了全自动分析工具平台 EasyBC （如图 1）。</span></p><p><span style="color:#000000">该研究成果以_EasyBC: A Cryptography-Specific Language for Security Analysis of Block Ciphers against Differential Cryptanalysis_为题被编程语言国际顶级会议 POPL 2024 录用，通讯作者是软件所计算机科学国家重点实验室宋富研究员。</span></p><p><span style="color:#000000"><img alt="" height="122" src="https://oscimg.oschina.net/oscnet/up-3680dde4b4183fc67c37f117d71002e2e79.png" width="500" referrerpolicy="no-referrer"></span></p><p><em><span style="color:#000000">图 1. EasyBC 平台流程图</span></em></p><p><span style="color:#000000">分组加密算法（block cipher）是将明文分成多个等长的模块（block），使用对称密钥对每组分别加密或解密，广泛应用于电子邮件加密、银行交易转帐等多个领域。作为极其重要的加密协议组成，主流分组加密算法有中国国家密码管理局颁布的 SM1、SM4 和 SM7，美国政府核定的标准算法 AES 和 3DES。而差分密码分析在评估分组加密算法的安全性方面发挥着核心作用，是分组加密算法标准化不可或缺的安全性分析手段。当前已有的差分密码分析方法在通用性、自动化程度方面存在一定不足，同时建模过程复杂导致用户需要熟悉大量的建模方法及底层分析工具的应用。</span></p><p><span style="color:#000000">为解决上述不足，研究团队设计了一种分组加密算法的密码学专用高级编程语言 EasyBC，提供了完整的语法、类型和语义的形式定义，为分组加密算法安全性自动分析奠定了良好基础；提出了三种不同分析精度和性能的差分密码分析方法，不仅统一和优化了已有的各类加密操作的建模方法，并提出了多种新的建模方法。</span></p><p><span style="color:#000000">研究团队实现了 23 个加密原语，包括美国国家标准与技术研究院（National Institute of Standards and Technology，NIST）认证加密方案的底层置换算法以及多种常用分组加密算法（如图 2）；并对其中的分组密码原语进行了安全性分析（如图 3），进而验证了 EasyBC 语言的表达能力以及 EasyBC 工具平台安全性自动分析的有效性。</span></p><p><span style="color:#000000"><img alt="" height="184" src="https://oscimg.oschina.net/oscnet/up-6c84d792455028442affb5312288fbac624.png" width="500" referrerpolicy="no-referrer"></span></p><p><em><span style="color:#000000">图 2.EasyBC 语言实现的 23 个加密原语</span></em></p><p><em><span style="color:#000000"><img alt="" height="171" src="https://oscimg.oschina.net/oscnet/up-55a59db5baf9240d59fc4e82c667f38b199.png" width="500" referrerpolicy="no-referrer"></span></em></p><p><em><span style="color:#000000">图 3.Word-wise 实现的加密原语差分密码安全性分析结果</span></em></p><p><span style="color:#000000">该研究对分组加密算法的差分密码分析研究具有重要意义，为后续密码学相关研究者们进行分组加密算法的安全性全自动分析和各类运算操作建模方法性能评估提供了良好的研究基础和平台支撑。</span></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><strong>论文信息：</strong></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><em>EasyBC: A Cryptography-Specific Language for Security Analysis of Block Ciphers against Differential Cryptanalysis</em>. Pu Sun (ShanghaiTech University), Fu Song* (Institute of Software Chinese Academy of Sciences, and University of Chinese Academy of Sciences), Yuqi Chen (ShanghaiTech University), Taolue Chen (Birkbeck, University of London). Proc. ACM Program. Lang. 8, POPL, Article 29 (January 2024), 33 pages.<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoi.org%2F10.1145%2F3632871" target="_blank">https://doi.org/10.1145/3632871</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 04:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267024</guid>
            <link>https://www.oschina.net/news/267024</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Kotlin Multiplatform 公布 2024 年开发路线图]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">继几周前宣布推出</span><a href="https://www.oschina.net/news/265360/kotlin-multiplatform-stable">第一个稳定版本</a><span style="color:#000000">后，JetBrains <span style="background-color:#ffffff">发布了 2024 年 </span>Kotlin Multiplatform&nbsp;<span style="background-color:#ffffff">的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2023%2F11%2Fkotlin-multiplatform-development-roadmap-for-2024%2F" target="_blank">开发路线图</a>。 其</span></span><span style="background-color:#ffffff; color:#19191c">目标是在 2024 年对 Kotlin Multiplatform 核心技术、Compose Multiplatform、KMP 工具和 KMP 库进行一系列改进。</span></p><p><span style="color:#000000">「我们致力于使 Compose Multiplatform 成为一个框架，允许创建在所有受支持的平台上看起来都同样美观且高性能的应用程序。」</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-8af6c9da66280ab985d71d05df036c402a9.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">目前，该公司对&nbsp;<span style="background-color:#ffffff">Compose Multiplatform 的主要关注点是将 iOS 版 Compose 升级到 Beta 版。同时还计划：</span></span></p><ul style="margin-left:0; margin-right:0"><li>使所有 Jetpack Compose core API 和组件实现多平台。</li><li>提高 iOS 上的渲染性能。</li><li>使 Compose for iOS 应用程序中的滚动和文本编辑行为与 iOS 原生应用程序中的行为相同。</li><li>实现通用 API 以共享所有类型的资源。</li><li>与 iOS 和&nbsp;Desktop accessibility API 集成。</li><li>提供多平台导航解决方案。</li></ul><p><span style="color:#000000">以及致力于改进 Compose for Web，尤其<span style="background-color:#ffffff">是 Wasm</span>。例如：</span></p><ul><li><span style="color:#000000">允许你移植现有代码；</span></li><li><span style="color:#000000">支持不同的屏幕尺寸、方向和密度；</span></li><li><span style="color:#000000">支持通过鼠标、触摸屏、物理键盘或屏幕键盘进行输入；</span></li><li><span style="color:#000000">改善性能和 binary size。</span></li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">JetBrains 还将对 IDE 进行多项改进，</span>包括：增强对 Compose Multiplatform 的支持，包括常见代码的实时预览和可视化调试工具；<span style="background-color:#ffffff">项目配置帮助；</span>多平台项目所有部分的统一和增强的调试体验。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="display:none">&nbsp;</span><span style="color:#000000"><span style="background-color:#ffffff">为了支持想要与 iOS target&nbsp;共享代码的开发人员，项目团队将致力于直接从 Kotlin 导出到 Swift。「流行的 Kotlin Multiplatform 应用场景之一是与 iOS target&nbsp;共享代码。我们希望关注在代码库中使用 Kotlin Multiplatform 框架的 iOS 开发人员的开发体验......它将消除 Objective-C 瓶颈，从而提供更广泛的 Swift 语言支持和更自然的 API 导出。」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">还在专门为 Kotlin 库作者创建工具，旨在提高 Kotlin API 导出到 Swift 时的兼容性和用户友好性。一些其他举措包括，<span style="background-color:#ffffff">提高 Kotlin/Native 编译的性能、改进 CocoaPods 集成以及添加对使用 SwiftPM 导出框架的支持。&nbsp;</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">此外，随着 Kotlin <span style="background-color:#ffffff">Multiplatform&nbsp;</span>生态系统的快速发展，库的向后兼容性变得至关重要。<span style="background-color:#ffffff">JetBrains 将重点关注改进 klib 格式，以允许库创建者利用他们的 JVM 库构建技能；</span><span style="background-color:#ffffff">在 Kotlin Multiplatform&nbsp;</span><span style="background-color:#ffffff">库中实现与 JVM 相同的代码内联行为；以及提供一个工具来确认库的公共 API 没有以不兼容的方式进行了更改。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2023%2F11%2Fkotlin-multiplatform-development-roadmap-for-2024%2F" target="_blank">查看官方博客</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 04:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267112/kotlin-multiplatform-development-roadmap-2024</guid>
            <link>https://www.oschina.net/news/267112/kotlin-multiplatform-development-roadmap-2024</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GROMACS —— 分子动力学模拟工具包]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GROMACS（全称：GROningen MAchine for Chemical Simulations，格罗宁根化学模拟体系），是用于研究生物分子体系的分子动力学模拟工具包，主要用来模拟研究蛋白质、脂质、核酸等生物分子的性质。</p><p>它可以用分子动力学、随机动力学或者路径积分方法模拟溶液或晶体中的任意分子，进行分子能量的最小化，分析构象等。</p><p>它的模拟程序包包含 GROMACS 力场 (蛋白质、核苷酸、糖等)，研究的范围可以包括玻璃和液晶、到聚合物、晶体和生物分子溶液。</p><p>GROMACS 是一个功能强大的分子动力学的模拟软件，其在模拟大量分子系统的牛顿运动方面具有极大的优势。</p><blockquote><p>分子动力学模拟是分子模拟中最接近实验条件的模拟方法。它能够从原子层面给出体系的微观演变过程，直观的展示实验现象发生的机理与规律。</p><p>因此，分子动力学模拟在生物，药学，化学以及材料科学的研究中发挥着越来越重要的作用。</p></blockquote><p>GROMACS 起初由荷兰格罗宁根大学生物化学系开发，目前由来自世界各地的大学和研究机构维护。</p><p><strong>主要功能</strong></p><ul><li><p>支持基本动力学相关算法，包括牛顿力学及随机动力学积分器、能量最小化、正则模式分析等。</p></li><li><p>支持温度及压强控制，支持基于 SHAKE 和 P-LINCS 的完全约束算法，支持多种几何约束。</p></li><li><p>支持 AMBER、CHARMM 及 OPLS 等常见经典力场。</p></li><li><p>支持 QM/MM 混合动力学，可对接 GAMESS、Orca 等量化软件。</p></li></ul><p>它可以用于上百万个粒子体系的分子动力学模拟研究，尤其是生物体系，如磷脂双分子层生物膜、蛋白质、药物分子等。</p><p><img src="https://static.oschina.net/uploads/space/2023/1102/194131_DK4t_2720166.png" referrerpolicy="no-referrer"></p><p>此外，GROMACS 能够非常快速地计算非键作用，因此也可用于非生物体系，如聚合物、一些有机物、无机物等。</p><p><img src="https://static.oschina.net/uploads/space/2023/1102/194200_MtCm_2720166.png" referrerpolicy="no-referrer"></p><p><strong>核心优势</strong></p><ul><li><p>开源软件、可免费使用</p></li><li><p>力场较全面且容易扩充</p></li><li><p>操作方便，相关教程也多</p></li><li><p>算法性能好，计算效率高</p></li></ul><p>GROMACS 最突出的特色和优势是高效，无论串行还是并行版本。</p><p><img src="https://static.oschina.net/uploads/space/2023/1102/194219_S3QX_2720166.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/gromacs</guid>
            <link>https://www.oschina.net/p/gromacs</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 网络自动化领域解决方案框架 NetAxe]]>
            </title>
            <description>
                <![CDATA[<p align="center"><img src="https://gitee.com/iflytek/NetAxe/raw/master/readme/logo.png" alt="netaxe" referrerpolicy="no-referrer"></p><p align="center"><img src="https://img.shields.io/badge/Python-brightgreen.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Django-orange.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/FastAPI-brightgreen.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Vue3-blue.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Vite-orange.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/NaiveUI-blue.svg" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/license-Apache-green.svg" referrerpolicy="no-referrer"><a href="https://gitee.com/NetAxeClub" target="_blank"><img src="https://img.shields.io/badge/Author-NetAxeClub-orange.svg" referrerpolicy="no-referrer"></a></p><p align="center"><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io">Netaxe 官方文档</a> |  <a target="_blank" href="https://gitee.com/link?target=http%3A%2F%2F47.99.86.164%3A9980">在线预览</a></p><h2><a id="user-content-项目介绍" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D"></a>项目介绍</h2><p><strong>专注网络自动化领域的整体架构解决方案</strong></p><p>[ NetAxe ]是一个网络自动化领域解决方案框架，通过微服务和微前端的方式构建的应用集合，主要有资源管理、配置管理、自动化、网络拓扑、地址定位、地址管理等等功能集合，同时各个微应用支持插件形式的能力集成，方便用户自行扩展。</p><h2><a id="user-content-组织地址" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E7%BB%84%E7%BB%87%E5%9C%B0%E5%9D%80"></a>组织地址</h2><p><a href="https://gitee.com/NetAxeClub">NetAxeClub</a></p><p>致力于网络自动化工具和平台开发</p><p>联系邮箱:<a href="mailto:netaxe@qun.mail.163.com">netaxe@qun.mail.163.com</a></p><h2><a id="user-content-文档说明" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E6%96%87%E6%A1%A3%E8%AF%B4%E6%98%8E"></a>文档说明</h2><p>👇👇👇👇👇👇👇👇👇👇👇</p><p>📚 <a href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io%2F">NetAxe 文档教程使用说明</a> : <a href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io%2F">https://netaxe.github.io/</a></p><p>👆👆👆👆👆👆👆👆👆👆👆</p><h2><a id="user-content-项目预览" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E9%A1%B9%E7%9B%AE%E9%A2%84%E8%A7%88"></a>项目预览</h2><p>👇👇👇👇👇👇👇👇👇👇👇</p><p><a href="https://gitee.com/link?target=http%3A%2F%2F47.99.86.164%3A9980">体验环境</a> 账号密码：admin/123456</p><p>仅在工作时间开启 (9:30-18:00)</p><p>👆👆👆👆👆👆👆👆👆👆👆</p><h2><a id="user-content-平台架构图" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84%E5%9B%BE"></a>平台架构图</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/%E6%9E%B6%E6%9E%84%E5%9B%BE.3vrmin46me00.webp" alt="平台架构图" referrerpolicy="no-referrer"></p><h2><a id="user-content-1 平台登录页" class="anchor" href="https://gitee.com/iflytek/NetAxe#1%E5%B9%B3%E5%8F%B0%E7%99%BB%E5%BD%95%E9%A1%B5"></a>1.平台登录页</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-login.78afwmigsc00.webp" alt="登录页面" referrerpolicy="no-referrer"></p><h2><a id="user-content-2 资产管理" class="anchor" href="https://gitee.com/iflytek/NetAxe#2%E8%B5%84%E4%BA%A7%E7%AE%A1%E7%90%86"></a>2.资产管理</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/golang.63zo8r1zsjs0.webp" alt="资产管理" referrerpolicy="no-referrer"></p><h2><a id="user-content-3 配置差异比较" class="anchor" href="https://gitee.com/iflytek/NetAxe#3%E9%85%8D%E7%BD%AE%E5%B7%AE%E5%BC%82%E6%AF%94%E8%BE%83"></a>3.配置差异比较</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-git-diff.60gnker70dk0.webp" alt="配置差异比较" referrerpolicy="no-referrer"></p><h2><a id="user-content-4webssh" class="anchor" href="https://gitee.com/iflytek/NetAxe#4webssh"></a>4.Webssh</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-webssh.3rs5vtioxe80.webp" alt="Webssh" referrerpolicy="no-referrer"></p><h2><a id="user-content-5 接口清单" class="anchor" href="https://gitee.com/iflytek/NetAxe#5%E6%8E%A5%E5%8F%A3%E6%B8%85%E5%8D%95"></a>5.接口清单</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-interface.5pje0o1za4w0.webp" alt="接口清单" referrerpolicy="no-referrer"></p><h2><a id="user-content-6 采集方案" class="anchor" href="https://gitee.com/iflytek/NetAxe#6%E9%87%87%E9%9B%86%E6%96%B9%E6%A1%88"></a>6.采集方案</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netzxe-collect.4yf0qcxemhk0.webp" alt="采集方案" referrerpolicy="no-referrer"></p><h2><a id="user-content-7 任务列表" class="anchor" href="https://gitee.com/iflytek/NetAxe#7%E4%BB%BB%E5%8A%A1%E5%88%97%E8%A1%A8"></a>7.任务列表</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-task.58uns0zatss0.webp" alt="任务列表" referrerpolicy="no-referrer"></p><h2><a id="user-content-8 任务调度管理" class="anchor" href="https://gitee.com/iflytek/NetAxe#8%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%AE%A1%E7%90%86"></a>8.任务调度管理</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/netaxe-dispatch.3x68huinuzi0.webp" alt="任务调度管理" referrerpolicy="no-referrer"></p><h2><a id="user-content-9-地址管理" class="anchor" href="https://gitee.com/iflytek/NetAxe#9-%E5%9C%B0%E5%9D%80%E7%AE%A1%E7%90%86"></a>9. 地址管理</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/ipam.3vspimj3jf20.webp" alt="地址管理" referrerpolicy="no-referrer"></p><h2><a id="user-content-10-权限中心" class="anchor" href="https://gitee.com/iflytek/NetAxe#10-%E6%9D%83%E9%99%90%E4%B8%AD%E5%BF%83"></a>10. 权限中心</h2><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/rbac.6k2qnc2yqxk0.webp" alt="权限中心" referrerpolicy="no-referrer"></p><h2><a id="user-content-交流群" class="anchor" href="https://gitee.com/iflytek/NetAxe#%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>交流群</h2><blockquote><p>扫码添加好友，提交入群申请。</p></blockquote><p><img src="https://cdn.staticaly.com/gh/xuehaoweng/netaxe-image@master/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20230106172200.240x6tqonx9c.webp" alt="NetAxe 开源社区" referrerpolicy="no-referrer"></p><h2><a id="user-content--参与贡献" class="anchor" href="https://gitee.com/iflytek/NetAxe#-%E5%8F%82%E4%B8%8E%E8%B4%A1%E7%8C%AE"></a>🤝 参与贡献</h2><p>欢迎你参与到 NetAxe 项目的建设中来！🎉</p><p>我们可以一起：</p><ul><li>🎁 设计和开发功能模块</li><li>⭐ 讨论实际运维场景和自动化的落地实践</li><li>🎊 结识一群热爱学习、热爱开源的朋友</li></ul><h2><a id="user-content--维护者" class="anchor" href="https://gitee.com/iflytek/NetAxe#-%E7%BB%B4%E6%8A%A4%E8%80%85"></a>✨ 维护者</h2><p>维护者是做出杰出贡献且在社区长期活跃的 NetAxe 社区成员。</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FM87NET">jamlee</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fxuehaoweng">xuehaoweng</a></li></ul><h2><a id="user-content--贡献者" class="anchor" href="https://gitee.com/iflytek/NetAxe#-%E8%B4%A1%E7%8C%AE%E8%80%85"></a>✨ 贡献者</h2><p>贡献者是在 NetAxe 社区中合并了 1 个或多个 PR 的社区成员。
虚位以待。。。</p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsP2dC0txvBhExYxbjq94UA">PR 提交指南</a></p><p>github:&nbsp;<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fiflytek%2FNetAxe">https://github.com/iflytek/NetAxe</a><br>
gitee:&nbsp;<a href="https://gitee.com/iflytek/NetAxe">https://gitee.com/iflytek/NetAxe</a><br>
NetAxe 官网文档:<a href="https://gitee.com/link?target=https%3A%2F%2Fnetaxe.github.io%2F">https://netaxe.github.io/</a></p>]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/iflytek/NetAxe</guid>
            <link>https://gitee.com/iflytek/NetAxe</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 彩虹桥架构演进之路 - 性能篇]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一、前言</h1><p>一年前的《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247488943%26idx%3D1%26sn%3D867041a53c801b5f83457fa622bb4909%26scene%3D21%23wechat_redirect" target="_blank">彩虹桥架构演进之路</a>》侧重探讨了稳定性和功能性两个方向。在过去一年中，尽管业务需求不断增长且流量激增了数倍，彩虹桥仍保持着零故障的一个状态，算是不错的阶段性成果。而这次的架构演进，主要分享一下近期针对性能层面做的一些架构调整和优化。其中最大的调整就是 Proxy-DB 层的线程模式从 BIO 改造成了性能更好的 NIO。下面会详细介绍一下具体的改造细节以及做了哪些优化。</p><blockquote><p>阅读本文预计需要 20～30 分钟，整体内容会有些枯燥难懂，建议阅读前先看一下上一篇彩虹桥架构演进的文章（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247488943%26idx%3D1%26sn%3D867041a53c801b5f83457fa622bb4909%26scene%3D21%23wechat_redirect" target="_blank">彩虹桥架构演进之路</a>）以及 MySQL 协议相关基础知识。</p></blockquote><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>二、改造前的架构</h1><p>先来复习一下彩虹桥的全景架构图： <img src="https://oscimg.oschina.net/oscnet/up-a99befe24a3c3d97eae3a3fd156ae4e23bd.jpg" alt="" referrerpolicy="no-referrer"></p><h2>Proxy 三层模块</h2><p>针对 Proxy 这一层，可以大致分成 Frontend、Core、Backend 三层：</p><ul><li><strong>Frontend-服务暴露层</strong>：使用 Netty 作为服务器，按照 MySQL 协议对接收&amp;返回的数据进行编解码。</li><li><strong>Core-功能&amp;内核层</strong>：通过解析、改写、路由等内核能力实现数据分片、读写分离、影子库路由等核心功能。</li><li><strong>Backend-底层 DB 交互层</strong>：通过 JDBC 实现与数据库交互、对结果集改列、归并等操作。</li></ul><h2>BIO 模式下的问题</h2><p>这里 Core 层为纯计算操作，而 Frontend、Backend 都涉及 IO 操作，Frontend 层使用 Netty 暴露服务为 NIO 模式，但是 Backend 使用了数据库厂商提供的传统 JDBC 驱动，为 BIO 模式。所以 Proxy 的整体架构还是 BIO 模式。在 BIO 模型中，每个连接都需要一个独立的线程来处理。这种模型有一些明显的缺点：</p><ul><li><strong>高资源消耗</strong>：每个请求创建独立线程，伴随大量线程开销。线程切换与调度额外消耗 CPU。</li><li><strong>扩展性受限</strong>：受系统线程上限影响，处理大量并发连接时，性能急剧下降。</li><li><strong>I/O 阻塞</strong>：BIO 模型中，读/写操作均为阻塞型，导致线程无法执行其他任务，造成资源浪费。</li><li><strong>复杂的线程管理</strong>：线程管理和同步问题增加开发和维护难度。</li></ul><p>我们看最简单的一个场景：在 JDBC 在发起请求后，当前线程会一直阻塞直到数据库返回数据，当出现大量慢查或者数据库出现故障时，会导致大量线程阻塞，最终雪崩。在上一篇彩虹桥架构演进文章中，我们做了一些改进来避免了 BIO 模型下的一些问题，比如使用线程池隔离来解决单库阻塞导致全局雪崩的问题。 <img src="https://oscimg.oschina.net/oscnet/up-5dad3dc23bdca9a239bdf3253b4a7f9b319.jpg" alt="" referrerpolicy="no-referrer"></p><p>但是随着逻辑库数量的增多，最终导致 Proxy 的线程数膨胀。系统的可伸缩性和吞吐量都受到了挑战。因此有必要将现有的基于 JDBC 驱动的阻塞式连接升级为采用 NIO（非阻塞 I/O）方式连接数据库。</p><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>三、改造后的架构</h1><ul><li><strong>BIO-&gt;NIO</strong></li></ul><p>想把 Proxy 整体架构从 BIO-&gt;NIO，最简单的方式就是把传统的 BIO 数据库驱动 JDBC 换成 NIO 的数据库驱动，但是在调研过后发现开源的 NIO 驱动并不多，而且基本上没有什么最佳实践。最后在参考 ShardingSphere 社区之前做的调研后（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fshardingsphere%2Fissues%2F13957" target="_blank">https://github.com/apache/shardingsphere/issues/13957</a> ） ，决定使用 Vertx 来替换 JDBC。最开始使用 Vert.x 的原因，第一是 Vertx 的异步编码方式更友好，编码复杂度相对较低，第二是因为它实现了主流数据库的驱动。但最终的结果不尽人意，由于 Vertx 相关抽象化的架构，导致链路较长时，整个调用栈深非常夸张。最终压测出来的吞吐量提升只有 5% 不到，而且存在很多兼容性问题。于是推倒重来，决定自研数据库驱动和连接池。</p><ul><li><strong>跳过不必要的编解码阶段</strong></li></ul><p>由于 JDBC 驱动会自动把 MySQL 的字节数据编解码成 Java 对象，然后 Proxy 再把这些结果集经过一些加工（元信息修正、结果集归并）后再进行编码返回给上游。如果自研驱动的话，就可以把编解码流程控制的更细致一些，把 Proxy 不需要加工的数据直接转发给上游，跳过无意义的编解码。后面会介绍一下哪些场景是不需要 Proxy 对结果集进行加工的。</p><h2>自研 NIO 数据库驱动</h2><p>数据库驱动主要是封装了与 DB 层交互协议，封装成高级 API。下面 2 张图是 java.sql 包中的 Connection 和 Statement 的一些核心接口。 <img src="https://oscimg.oschina.net/oscnet/up-517ee2a0bafe29e2a2e648762ed31d87bb9.jpg" alt="" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-3e947c153f1f81f011a177b66d7b2036cee.jpg" alt="" referrerpolicy="no-referrer"></p><p>所以首先我们需要了解一下，如何与数据库进行数据交互，以 MySQL 为例，使用 Netty 连接 MySQL，简单的交互流程如下。 <img src="https://oscimg.oschina.net/oscnet/up-99ac2f8e643ce9a4d7c1db6f7db7a20a81e.jpg" alt="" referrerpolicy="no-referrer"></p><p>使用 Netty 与 MySQL 连接建立后，我们要做的就是按照 MySQL 协议规定的数据格式，先鉴权后再发送具体的命令包即可。下面是 MySQL 官方文档中鉴权流程和命令执行流程：</p><ul><li><strong>鉴权流程</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Fdev%2Fmysql-server%2Flatest%2Fpage_protocol_connection_phase.html" target="_blank">https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_connection_phase.html</a></li><li><strong>执行命令流程</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Fdev%2Fmysql-server%2Flatest%2Fpage_protocol_command_phase.html" target="_blank">https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_command_phase.html</a></li></ul><p>下面就是按照 MySQL 的文档，去实现编解码 Handle，我们简单看一下实现的代码。 <img src="https://oscimg.oschina.net/oscnet/up-93dbe9735b43149a35e21ca060fb870ed92.jpg" alt="" referrerpolicy="no-referrer"></p><ul><li>decode 解码</li></ul><p>就是针对 MySQL 返回的数据包解码，根据长度解析出 Palyload 封装成 MySQLPacketPayload 传给对应的 Handle 处理。</p><ul><li>encode 编码</li></ul><p>把具体的命令类转换成具体的 MySQL 数据包，这里的 MySQLPacket 有多个实现类，跟 MySQL 的 Command 类型一一对应。</p><p>现在还需要一个类似 java.sql.Connection 的实现类，来组装 MySQLPacket 并写入到 Netty 通道中，并且解析编码后的 MySQLPacketPayload 转换成 ResultSet。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5cf9d17b87a550d191bd089eef9e41f28fd.jpg" alt="" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-2c4b743cde5a7c667d2a2d04881afaf237a.jpg" alt="" referrerpolicy="no-referrer"> 看起来比较简单，交互流程和传统的 JDBC 几乎一样，但是由于现在是异步化流程，所有的 Response 都是通过回调返回，所以这里有 2 个难点：</p><ul><li>由于 MySQL 在上一条命令没结束前无法接受新的命令，所以如何控制单个连接的命令串行化？</li><li>如何将 MySQL 返回的数据包和发起命令的 Request 一一绑定？</li></ul><p>首先 NettyDbConnection 引入了一个无锁化非阻塞队列 ConcurrentLinkedQueue。 <img src="https://oscimg.oschina.net/oscnet/up-95d916682b2dd973e5096a9c7889a398b1c.jpg" alt="" referrerpolicy="no-referrer"></p><p>在发送 Command 时，如何没有正在进行中的 Command，则直接发送，如果有正在进行中的 Command，直接扔到队列中，等待上一条 Command 处理完成后推动下一条命令的执行。保证了单个连接命令串行化。</p><p>其次，NettyDbConnection 在执行命令时，传入一个 Promise，在 MySQL 数据包全部返回后，这个 Promise 将会被设置完成，即可于发起命令的 Request 一一绑定。 <img src="https://oscimg.oschina.net/oscnet/up-fbcb7f0a0133a4cb43712626f4fbfed08a3.jpg" alt="" referrerpolicy="no-referrer"></p><h2>自研 NIO 数据库连接池</h2><p>前面介绍了 NettyDbConnection 这个类，实现了与 MySQL 的交互，并且提供了执行 SQL 的高级 API，但实际使用过程中，不可能每次都创建一个连接执行完 SQL 就关闭。所以需要对 NettyDbConnection 进行池化，统一管理连接的生命周期。其功能类似于传统连接池 HikariCP，在完成基本能力的基础上，做了很多性能优化。</p><ul><li>连接生命周期管控</li><li>连接池动态伸缩</li><li>完善的监控</li><li>连接异步保活</li><li>超时控制</li><li>EventLoop 亲和性</li></ul><p>这里除了 EventLoop 亲和性，其他几个功能只要用过传统的数据库连接池应该都比较熟悉，这里不做过多展开。这里主要针对 EventLoop 亲和性展开介绍一下。</p><p>在文章开头我们说到 Proxy 的三层模块，Frontend、Core、Backend，如果现在我们把 Backend 层于数据库交互的组件换成了我们自研的驱动，那么 Proxy 就即是 Netty Server，也是 Netty Client，所以 Frontend 和 Backend 可以共用一个 EventLoopGroup。为了降低线程上下文切换，在单个请求从 Frontend 接收、经过 Core 层计算后转发到 MySQL ，再到接收 MySQL 服务响应，以及最终的回写给 Client 端，这一些列操作尽量放在一个 EventLoop 线程中处理。 <img src="https://oscimg.oschina.net/oscnet/up-e04581647d274a5cc64fded2d2f26bff551.jpg" alt="" referrerpolicy="no-referrer"></p><p>具体的做法就是 Backend 在选择与数据库连接时，优先选择与当前 EventLoop 绑定的连接。也就是前面提到的 EventLoop 亲和性，这样就能保证大部分场景下一次请求从头到尾都由同一个 EventLoop 处理，下面我们看一下具体的代码实现。</p><p>在 NettyDbConnectionPool 类中使用一个 Map 存储连接池中的空闲连接，Key 为 EventLoop，Value 为当前 EventLoop 绑定的空闲连接队列。 <img src="https://oscimg.oschina.net/oscnet/up-3099eb3f9c96d39f72551fa8442ebdce261.jpg" alt="" referrerpolicy="no-referrer"></p><p>在获取时，优先获取当前 EventLoop 绑定的连接，如果当前 EventLoop 未绑定连接，则会借用其他 EventLoop 的连接。 <img src="https://oscimg.oschina.net/oscnet/up-830d6a25ed63767ae092d9eaa272e7624b5.jpg" alt="" referrerpolicy="no-referrer"></p><p>为了提高&nbsp;EventLoop 命中率，需要注意几点配置：</p><ul><li>EventLoop 线程数量尽量与 CPU 核心数保持一致。</li><li>连接池最大连接数超过&nbsp;EventLoop 线程数越多，EventLoop 命中率越高。</li></ul><p>下面放一张压测环境（8C16G、连接池最大连接数 10~30）的命中率监控，大部分保持在 75% 左右。 <img src="https://oscimg.oschina.net/oscnet/up-2164ed7abbf169379e215ff14861f04d876.jpg" alt="" referrerpolicy="no-referrer"></p><h2>跳过不必要的编解码</h2><p>前面说到，有部分 SQL 的结果集是不需要 Proxy 进行加工的，也就是可以直接把 MySQL 返回的数据流原封不动转发给上游，直接省去编解码操作。那什么 SQL 是不需要 Proxy 进行加工的呢，我们举个例子说明一下。</p><p>假设逻辑库 A 里面有一张表 User 做了分库，分了 2 个库 DB1 和 DB2，分片算法是 user_id%2。</p><ul><li>SQL 1</li></ul><blockquote><p>‍SELECT id, name FROM user WHERE user_id in (1, 2)</p></blockquote><ul><li>SQL 2</li></ul><blockquote><p>‍SELECT id, name FROM user WHERE user_id in (1)</p></blockquote><p>很显然 SQL 1 由于有 2 个分片 Value，最终匹配到了 2 个节点，SQL 2 只会匹配到 1 个节点。 <img src="https://oscimg.oschina.net/oscnet/up-f6637b742c35d1af023f60cf01309006bc9.jpg" alt="" referrerpolicy="no-referrer"></p><p>SQL 1 由于需要对结果集进行归并，所以无法跳过编解码，SQL 2 不需要对结果集归并，只需要把结果集中的列定义数据做修正后，真正的 Row 数据无需处理，这种情况就可以把 Row 数据直接转发至上游。</p><h2>全链路异步化</h2><p>Backend 层用自研连接池+驱动替换原先的 HikariCP+JDBC 后，从 Frontend-Core-Backend 全链路涉及到阻塞的操作需要全部替换成异步化编码，也就是通过 Netty 的 Promise 和 Future 来实现。 <img src="https://oscimg.oschina.net/oscnet/up-3eb5da9b30f76427c3cddf2847919af3b71.jpg" alt="" referrerpolicy="no-referrer"></p><p>由于部分场景拿到 Future 时，可能当前 Future 已经完成了，如果每次都是无脑的加 Listener 会让调用栈加长，所以我们定义了一个通用的工具类来处理 Future，即 future.isDone() 时直接执行，反之才会 addListener，最大化降低整个调用栈的深度。 <img src="https://oscimg.oschina.net/oscnet/up-d36312a5a58e232274aa174dea7ccd9551a.jpg" alt="" referrerpolicy="no-referrer"></p><h2>兼容性</h2><p>除了以上基本代码的改造外，还需要做大量的兼容工作：</p><ul><li>特殊数据库字段类型处理</li><li>JDBC URL 参数兼容</li><li>ThreadLocal 相关数据全部需要迁移至 ChannelHandlerContext 中</li><li>日志 MDC、TraceContext 相关数据传递</li><li>……</li></ul><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>四、性能表现</h1><p>经过几轮性能压测后，NIO 架构相较于 BIO 架构性能有较大提升：</p><ul><li>整体最大吞吐量提升 67%</li><li>LOAD 下降 37% 左右</li><li>高负载情况下 BIO 多次出现进程夯住现象，NIO 相对较稳定</li><li>线程数减少 98% 左右</li></ul><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><h1>‍五、总结</h1><p>NIO 架构的改造工作量相当巨大，中间也经历了一些曲折，但是最终的结果令人满意。得益于 ShardingShpere 本身内核层面的高性能加上本次 NIO 改造后，彩虹桥在 DAL 中间件性能层面基本上可以算是第一梯队了。</p><h1>‍<img src="" alt="" referrerpolicy="no-referrer"></h1><p>*文 / 新一</p><p>本文属得物技术原创，更多精彩文章请看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com" target="_blank">得物技术官网</a></p><p>未经得物技术许可严禁转载，否则依法追究法律责任！</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10143389</guid>
            <link>https://my.oschina.net/u/5783135/blog/10143389</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 董事会与 Sam Altman 讨论重返 CEO 岗位事宜]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">The Verge 援引多位知情人士消息称，OpenAI 董事会正在与 Sam Altman 讨论重返公司担任首席执行官的事宜。</span></p><p><span style="color:#000000">其中一位知情人士表示，在经历了没有任何通知就突然被董事会解雇的 Altman 对回归一事"态度暧昧"，并希望对公司的治理模式进行重大变革。</span></p><p><img height="358" src="https://oscimg.oschina.net/oscnet/up-7c44d0d4980461dc3b0cab2147edf5763c7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">事实上，在 OpenAI 董事会宣布解雇了 Altman 几小时后；被免去董事会主席职务的 Greg Brockman 就公开宣布辞职，后续还有多位 OpenAI 高管也陆续辞职。一些风险投资家也公开声明表示支持 Altman，红杉资本普通合伙人 Alfred Lin 在推特上发文称，期待着 Altman 和 Brockman 建立下一个改变世界的公司。OpenAI 最大的投资者微软则在 Altman 被解雇后不久发表声明称，该公司「将继续致力于」与 OpenAI 的合作关系。</span></p><p><span style="color:#000000">事件后续的进展是，Altman 和董事会约定了一个时间点 —— 在当地时间下午 5 点之前达成停战协议，即董事会辞职，他和 Brockman 回归。然后董事会的摇摆不定导致他们错过了这一时间期限。</span></p><p><span style="color:#000000">如果不能尽快达成协议，Altman 和 Brockman 的离开势必会带走更多 OpenAI 员工。两人一直在与朋友和投资者讨论创办另一家公司的事宜，如果 Altman 决定离开并创办一家新公司，肯定会有大批员工追随。目前 OpenAI 的发言人仍未回应有关 Altman 与董事会讨论回归事宜的置评请求。微软发言人则拒绝发表评论。</span></p><p><span style="color:#000000">OpenAI 当下的董事会成员包括首席科学家 Ilya Sutskever、Quora 首席执行官 Adam D'Angelo、前 GeoSim Systems 首席执行官 Tasha McCauley 以及乔治城安全与新兴技术中心战略总监 Helen Toner 组成。</span></p><p><span style="color:#000000">多位消息人士透露，Sutskever 也是 OpenAI 的联合创始人之一并领导着 OpenAI 的研究团队，他在罢免 Altman 的过程中发挥了重要作用。而他在这次政变中的角色也表明，公司的研发部门和产品部门之间存在权力斗争。</span></p><p><strong><span style="color:#000000">相关阅读：</span></strong></p><ul><li><a href="https://www.oschina.net/news/267006/openai-ceo-sam-altman-fired" target="_blank">OpenAI 董事会内讧，CEO 兼创始人 Sam Altman 被逐出公司</a></li><li><a href="https://www.oschina.net/news/267013/openai-greg-brockman-quit" target="_blank">OpenAI 总裁 Greg Brockman 辞职</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267101/openai-board-discussions-with-sam-altman-return-as-ceo</guid>
            <link>https://www.oschina.net/news/267101/openai-board-discussions-with-sam-altman-return-as-ceo</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OneTable —— Lakehouse 表格式间全方位互操作]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#1f2328">OneTable 是一种表格式的全方位转换器，可促进数据处理系统和查询引擎之间的互操作性</span><span style="color:#000000">。Apache Hudi、Delta Lake 和 Apache Iceberg 之间无缝互操作。</span></p><p>OneTable 不是一种新的或独立的格式，OneTable 提供了用于转换 Lakehouse 表格式元数据的抽象和工具</p><p><span><span>OneTable 通过利用表表示的通用模型来简化数据湖操作。这允许用户以一种格式写入数据，同时仍然受益于其他格式的集成和功能。例如，OneTable 使现有的 Hudi 用户能够无缝地使用 Databricks 的 Photon Engine 或使用 Snowflake 查询 Iceberg 表。创建从一种格式到另一种格式的转换非常简单，只需要实现一些接口，项目团队认为，这将有助于将来支持的源格式和目标格式的扩展。</span></span></p><p style="margin-left:0px; margin-right:0px"><img alt="" height="414" src="https://static.oschina.net/uploads/space/2023/1116/163549_inUl_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 18 Nov 2023 03:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/onetable</guid>
            <link>https://www.oschina.net/p/onetable</link>
        </item>
    </channel>
</rss>
