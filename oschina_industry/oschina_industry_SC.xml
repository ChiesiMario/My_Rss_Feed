<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 27 Feb 2024 08:00:25 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[0201-0225 开放签团队工作日记]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span><span><span><span>2022 年底</span></span></span><span><span><span>团队决定</span></span></span><span><span><span>以全新的产品运营和设计思路重回电子签章行业，重新做</span></span></span><span><span><span>电子签章</span></span></span><span><span><span>产品。至于当时如何离开电子签章，又是如何回来的，具体原因等后面再敍。在这么多年的创业的过程中，我们团队经历了从迷茫无助到方向坚定（我们认为的），从一点点构建基础技术架构到基本成熟，有太多的不容易，每一个不容易都可以是个故事，具体的也在将来一一再敍，这次单说最近的一些工作感受和工作概况。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>经过努力</span></span></span><span><span><span>，23 年底（12 月 15 日）</span></span></span><span><span><span>产品</span></span></span><span><span><span>上线</span></span></span><span><span><span>后</span></span></span><span><span><span>，我们深知自己在</span></span></span><span><span><span>市场竞争中与头部企业仍存在功能层面的差距</span></span></span><span><span><span>，不敢妄想有什么好的反馈和成果。但是首</span></span></span><span><span><span>月</span></span></span><span><span><span>便</span></span></span><span><span><span>迎来了</span></span></span><span><span><span>付费用户</span></span></span><span><span><span>（企业版）和近</span></span></span><span><span><span>百</span></span></span><span><span><span>个开源用户</span></span></span><span><span><span>，</span></span></span><span><span><span>这完全出乎我和同事的意料</span></span></span><span><span><span>。刚开始我们以为这些用户至少要在 3-5 个月内才能积累到。事实证明我们错了，我们保守了，但是方向貌似对了（还需要更多的付出和积累）。在与客户沟通过程中，很快就收集到</span></span></span><span><span><span>首批客户集中提出</span></span></span><span><span><span>的众多需求，主要体现在</span></span></span><span><span><span>移动端签署、API 集成、</span></span></span><span><span><span>国产化</span></span></span><span><span><span>及优化交互体验</span></span></span><span><span><span>四大方面。也有很多我们在设计过程中没有考虑到的，没有考虑到的方面对我们来说尤其珍贵，价值巨大。</span></span></span><span><span><span>所以</span></span></span><span><span><span>我们在年前</span></span></span><span><span><span>加快工作节奏，</span></span></span><span><span><span>年后规划新年一季度目标。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>首要任务是</span></span></span><span><span><span>移动端开发，并承诺于春节后第一周交付新功能。</span></span></span><span><span><span>这段时间的工作节奏是这样的：</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>1、</span></span></span><span><span><span>临近春节</span></span></span><span><span><span>（</span></span></span><span><span><span>农历 28 日</span></span></span><span><span><span>）</span></span></span><span><span><span>我们完成了功能开</span></span></span><span><span><span>发，勉强通过冒烟测试</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>2、</span></span></span><span><span><span>年后进行系统和功能测试时，</span></span></span><span><span><span>出乎意料的事情接踵而至</span></span></span><span><span><span>，</span></span></span><span><span><span>出现了</span></span></span><span><span><span>移动端链接逻辑</span></span></span><span><span><span>跳转混乱</span></span></span><span><span><span>、文件签署内存异常、</span></span></span><span><span><span>签署</span></span></span><span><span><span>图片丢失、签署控件重复等</span></span></span><span><span><span>问题</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>3、</span></span></span><span><span><span>测试同学「大壮」在群里</span></span></span><span><span><span>发飙了，</span></span></span><span><span><span>讲述上线风险和延期上线的请求</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>4、不动声色的产品负责人老胡看到</span></span></span><span><span><span>请求</span></span></span><span><span><span>后</span></span></span><span><span><span>一直未回复（他的性格很刚强，表面不说，内心很要强）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>5、老胡</span></span></span><span><span><span>开始</span></span></span><span><span><span>着手</span></span></span><span><span><span>理清工作任务，</span></span></span><span><span><span>逐条分析 BUG，确定优先级。</span></span></span><span><span><span>···········（结果：原定计划</span></span></span><span><span><span>（2 月 25 日）</span></span></span><span><span><span>未完成上线）只好协调大家</span></span></span><span><span><span>周六日</span></span></span><span><span><span>继续</span></span></span><span><span><span>通宵奋战</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>6、</span></span></span><span><span><span>直至</span></span></span><span><span><span>2 月 26 日</span></span></span><span><span><span>凌晨五点成功修复所有问题并上线新版本</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>这个过程真是酸爽，自从决定做开放签以来，首先内心是非常欣慰的，工作状态也超好，整个团队也是热情澎湃的，甚至自然而然的解决了一些团队管理问题。</span></span></span><span><span><span>同样的产品不同的公司，都是为了服务客户</span></span></span><span><span><span>和理想在</span></span></span><span><span><span>奋斗</span></span></span><span><span><span>、在</span></span></span><span><span><span>熬夜，感谢</span></span></span><span><span><span>团</span></span></span><span><span><span>队成员的努力付出</span></span></span><span><span><span>！加油！（会想尽一切办法和努力给大家加鸡腿，让我们</span></span></span><span><span><span>的</span></span></span><span><span><span>产品更好</span></span></span><span><span><span>，</span></span></span><span><span><span>团队更顽强</span></span></span><span><span><span>，客户更放心</span></span></span><span><span><span>........）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>值得欣喜的是，按照约定我们成功完成版本更新</span></span></span><span><span><span>，</span></span></span><span><span><span>并与两家新客户签约。接下来，我们将采取敏捷迭代策略，小步快跑地满足需求</span></span></span><span><span><span>。</span></span></span><span><span><span>同时大胆创新签约场景模式，使更多企业在真实场景下实现高效合规</span></span></span><span><span><span>签署，让电子签更简单不是说说而已</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:right"><span><span><span><span><span><span><span>2024 年 02 月 27 日</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 07:32:21 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280492</guid>
            <link>https://www.oschina.net/news/280492</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Spring Boot 拒绝用 AI 为仓库自动生成注释]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">一名开发者近日在 Spring Boot 提交了一项 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-boot%2Fpull%2F39754%2F" target="_blank">PR</a>，旨在使用 AI 模型为整个 Spring Boot 代码库添加注释：</span></p><blockquote><p><span style="color:#000000">此代码变更为整个 Spring Boot 代码库添加了注释。本 PR 的内容完全由自定义微调 AI 模型创建。</span></p><p><span style="color:#000000">我们正在对我们的工具进行大规模实验，在数百万行代码上运行该工具，以识别任何 bug 或错误。在此代码库中运行时，该工具的编译成功率高达 99.9%。</span></p><p><span style="color:#000000">我们可以选择放弃这些代码，或者将其发布并作为一项贡献。我们选择了后者，并决定打开此 Pull Request。</span></p></blockquote><p><img height="280" src="https://oscimg.oschina.net/oscnet/up-c694ca89e5d80a24accaf670c4f099452bc.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">但 Spring Boot 项目负责人 Phil Webb 对此进行了婉拒。并表示，相较自动生成，团队成员更喜欢人工手动的方式；且自动生成这种无差别的方式，很可能给整个仓库增添许多不必要的麻烦。</span></p><p><span style="color:#000000">「我认为您的工具对于正在学习代码库或需要某些部分的额外帮助的人来说可能非常有用。」</span></p><p>Reddit 上的一些讨论也表达了对这一提议的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F1b0n9kx%2Fai_added_comments_for_the_entire_code_base_of%2F" target="_blank">不看好</a>：</p><blockquote><p>「哇，这太可怕了。我真希望这只是个玩笑，提出要求的人只是在嘲笑这个想法。」</p><p>「如果这不是纯粹为了吸引眼球，那么我想公关背后的开发人员可以说是真的缺乏开发技能。」</p></blockquote><p>目前，相关 PR 已被关闭。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 06:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280473/ai-comments-spring-boot</guid>
            <link>https://www.oschina.net/news/280473/ai-comments-spring-boot</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | 鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.26</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/280197/warp-for-linux" target="_blank">基于 Rust 开发的终端应用 Warp 发布 Linux 版本</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Warp 是一个基于 Rust 开发的现代化终端应用，内置 AI 功能，支持 CPU 加速。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">此前 Warp 仅面向 Mac 平台提供，近日其开发团队终于<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.warp.dev%2Fblog%2Fwarp-for-linux" target="_blank">发布</a></u>了 Linux 版本，用户可在大多数主流 Linux 发行版上安装 Warp，包括 Ubuntu、Fedora、Arch Linux 或 Red Hat。</p><h3><a href="https://www.oschina.net/news/280083/wubuntu-windows-ubuntu" target="_blank">Wubuntu：披着 Windows 11 外衣的 Ubuntu</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Wubuntu，又称 "Windows Ubuntu"</strong>，是基于 Ubuntu 开发的操作系统，其最具特色之处在于<strong>完全复刻了 Windows 的所有外观和功能</strong>，而且运行时不需要具备 TPM、安全启动或任何其他硬件要求。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span>此外，Wubuntu</span>&nbsp;通过集成 Wine 提供了与 Windows 应用的兼容性，开发者称 Wubuntu 支持运行 Windows 的 .exe 和 .msi&nbsp;程序，以及支持 Android 应用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b78011bce450db4cf20d1bb7cc559cd4cb6.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-a5cb30243de8b0b91be1d481043c473ad9e.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tmtpost.com%2F6949344.html" target="_blank">钛媒体</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-dd0b05ccdc75b8e461bccd191d8b02a887a.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>开源之声</strong></span></h2><p><img height="376" src="https://oscimg.oschina.net/oscnet/up-61ab492b02eb694af46583aa700ca993ddd.png" width="1104" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-393f28205ac4c95982b1545e5541957f5f9.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 Gitee 精选</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-f0e8ff0ed6f05f1864bb5c951acca5d3893.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 04:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280457</guid>
            <link>https://www.oschina.net/news/280457</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OSI 发布报告，研究 BSL 这样的「延迟开源发布」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff">Open Source Initiative（OSI）近期发布了一个报告《Delayed Open Source Publication:&nbsp;</span>A Survey of Historical and Current Practices<span style="background-color:#ffffff; color:#060607">》（</span>延迟开源发布：历史与当前实践调研<span style="background-color:#ffffff; color:#060607">），作者是 Seth Schoen、James Vasile 和 Karl Fogel。</span></p><p>&nbsp;</p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">Delayed Open Source Publication，简称 DOSP，延迟开源发布的意思，这份报告研究了它的历史和现状。报告核心要点：</p><p style="margin-left:0; margin-right:0"><strong>延迟开源发布（DOSP）定义</strong>：DOSP 是指软件最初在专有许可下发布，然后计划性地在某个时间点将源代码以开源许可的形式公开。</p><p style="margin-left:0; margin-right:0"><strong>历史背景</strong>：DOSP 的做法可以追溯到 GNU 项目，并且一直延续至今。公司尝试各种商业模式，以在有限时间内保持独家权利，然后过渡到 OSI（开放源代码倡议）批准的许可。</p><p style="margin-left:0; margin-right:0"><strong>策略类型</strong>：DOSP 分为三种类型：无条件计划性重新许可、事件驱动的重新许可和有条件的重新许可。</p><p style="margin-left:0; margin-right:0"><strong>商业源许可（BUSL）</strong>：BUSL 是一种新兴的 DOSP 许可方式，它要求在特定的「变更日期」后，软件的许可将变为开源许可。这种做法在数据库系统中尤为常见。（以往也叫 BSL）</p><p style="margin-left:0; margin-right:0">以下是当前知名的 16 个使用 BUSL 的项目，都是延迟几年后转型成开源协议：</p><p style="margin-left:0; margin-right:0"><img height="1588" src="https://static.oschina.net/uploads/space/2024/0227/115012_ybIG_3820517.png" width="1434" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>反竞争条款</strong>：一些 DOSP 许可中包含反竞争条款，旨在防止许可证持有者使用软件提供与许可方直接竞争的服务。</p><p style="margin-left:0; margin-right:0"><strong>后果和影响</strong>：从开源许可转变为 DOSP 许可的项目可能会受到批评，有时会导致用户转向其他项目或维护竞争性的分支。</p><p style="margin-left:0; margin-right:0"><strong>未来研究问题</strong>：报告提出了一些未来研究的问题，包括 AGPL 与 DOSP 许可的比较、DOSP 对外部贡献的影响、BUSL 额外使用授权的分类、以及在初始开源发布后重新许可的策略。</p><p style="margin-left:0; margin-right:0"><strong>结论</strong>：DOSP 自开源运动早期以来一直在使用，公司通常利用它来保持商业优势，同时尽可能保留开源的优势。报告强调，DOSP 的实验性和多样性比预期的要多，且这种趋势可能会继续。</p><p>详情可以查看<a href="https://apiv1.oschina.net/api/files/jhim80u9qm1ofsw/27nfbrttho0ynu9/delayed_open_source_publication_2FzjpHTElG.pdf?token=">报告原文</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:57:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280456/osi-delayed-open-source-publication-report</guid>
            <link>https://www.oschina.net/news/280456/osi-delayed-open-source-publication-report</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[终于，我们拿下了硅谷的那个 Linear]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-0963fd788787982101b5435a54ca146c2ab.png" alt="file" referrerpolicy="no-referrer"></p><p>就像设计领域的 Figma，文档领域的 Notion，Linear 同样在软件开发管理领域推出了革命性的工具。而且以其名字 Linear Style 命名的设计风格，也成为了一股软件设计潮流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-19feb8c039e4eb58e00760e5e8abaeba7f9.png" alt="file" referrerpolicy="no-referrer"></p><p>Linear 于 2019 年在美国 🇺🇸 旧金山创立。目前服务的对象涵盖了从新兴初创到知名上市公司的广泛范围，其中包括 Vercel、Arc、Runway，Supercell 和 OpenSea 等知名企业。其产品因能显著提升团队生产力和协作效率而成为近几年硅谷新兴公司的首选。</p><p><img src="https://oscimg.oschina.net/oscnet/up-29fa5d140ca7408dad14b59ffc2cef3023a.png" alt="file" referrerpolicy="no-referrer"></p><p><strong>Linear 使用 Bytebase 管理其数据库的全开发生命周期。收口员工查询数据库操作，通过 Bytebase API 将数据库变更集成进现有 CI/CD 工作流。</strong></p><p>Linear 的员工统一在 SQL 编辑器查询数据，通过权限管控、数据脱敏及行为审计，限制查询范围、监控行为并满足合规需求。</p><p>通过 Bytebase API 将数据库变更的审核部署集成进现有的代码提交部署工作流中，触发在 Bytebase 中建立工单，自动进行 SQL 预审核以减少人力降低错误可能性；根据变更的风险等级，通过自定义审批流确保相应的审批管理；并且，通过变更记录的查询功能，便于锁定特定的变更，以利于后续的审计。此外，单点登录 (SSO)，双因子身份验证 (2FA) 等功能进一步为账户管理带来了便利性和安全性保障。</p><p>未来 Linear 还将利用 Bytebase 的批量变更能力管理部署在不同地域的同构数据库。</p><p><img src="https://oscimg.oschina.net/oscnet/up-07cce1911ea9af359d0b945ffb3b6a4eca4.png" alt="file" referrerpolicy="no-referrer"></p><p>对开发者工具极其挑剔的 Linear 最终选择了 Bytebase。正如我们在 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMjI2MDY5OQ%3D%3D%26mid%3D2247483664%26idx%3D1%26sn%3Dbd6be60909c156c2d54687ad90ba4825%26chksm%3Dc25f3f24f528b63261d5d86fb9ddcad8f36826bdaa16fdb43da555d5457313c5036aa1665b78%26scene%3D21%23wechat_redirect" target="_blank">2021 年发布 Bytebase</a> 时设想的那样，<strong>Bytebase 会站上世界最高的舞台，成为现代软件研发工具链上的核心一环</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-551f266a1ef72674d8516e4795c1c18b9b4.png" alt="file" referrerpolicy="no-referrer"></p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:52:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/11044874</guid>
            <link>https://my.oschina.net/u/6148470/blog/11044874</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 工程师使用 Rust 为 Linux 开发内核调度程序]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Ubuntu 内核团队工程师 Andrea Righi 使用&nbsp;Rust 编写了一个 Linux 内核调度程序，并利用 eBPF 在运行时动态加载。Ubuntu 还没有承诺将其作为发行版的一部分，Righi 也在博客表示这是一个实验性内核项目，用于探索 Rust 在 Ubuntu 的应用，并谈到了未来<strong>利用 Rust 和 eBPF 进行「微内核设计」</strong>的可能性。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c0d741c436f514bc20978b2df98eb1e23a1.png" referrerpolicy="no-referrer"></p><p>Righi 在博客介绍称，用 Rust 开发的内核调度程序 sched-ext 不仅为开发者提供了便利，还能让用户也受益，比如可以根据用户的工作负载和其他特殊情况加载优化的调度程序。</p><p>博客文章最后写道：</p><blockquote><p>「我们正朝着一种微内核设计迈进，它有可能为 Linux 认证铺平道路：在上述情况下，如果用户空间调度程序崩溃，任务将无缝过渡到默认的内核调度程序，确保系统的持续可用性，而不会出现任何停机时间。</p><p>这表明，类似的方法也可用于其他子系统，从而使 Linux 内核能够提供完全冗余和崩溃安全的系统。」</p></blockquote><p>相关链接</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsched-ext%2Fscx%2Fpull%2F161" target="_blank">https://github.com/sched-ext/scx/pull/161</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2F%2Fblog%2Fcrafting-new-linux-schedulers-with-sched-ext-rust-and-ubuntu" target="_blank">https://ubuntu.com//blog/crafting-new-linux-schedulers-with-sched-ext-rust-and-ubuntu</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:25:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280450/ubuntu-rust-scheduler-micro</guid>
            <link>https://www.oschina.net/news/280450/ubuntu-rust-scheduler-micro</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Rebebuca —— 桌面端 ffmpeg 管理器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>Rebebuca（发音：瑞贝不卡） 是一个使用 Rust 开发的桌面端 ffmpeg 管理器，在不卡系列中处于推流端的生态位（Monibuca 为服务端，Jessibuca 为播放端）。</p></li><li><p>Rebebuca 在不久的将来会支持管理 Monibuca&nbsp;进程。</p></li><li><p><strong style="color:black"><span style="color:#010101">Rebebuca&nbsp;</span>可以在 30 秒内完成创建、运行、管理你的 ffmpeg 命令</strong></p><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div class="ckeditor-html5-video" style="text-align:center"><video controls="controls" src="https://rebebuca.com/quick.mp4">&nbsp;</video></div></div><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0">&nbsp;</div><div style="margin-left:0; margin-right:0">&nbsp;</div></div></div></div></div></div></div></div></div></div></li><li><p>帮助我们更好的管理繁多复杂的 ffmpeg 参数和 ffmpeg 命令运行状态</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>功能特性</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>ffmpeg 命令全周期管理</p><ul style="list-style-type:circle; margin-left:0; margin-right:0"><li style="list-style-type:circle"><p>支持 ffmpeg 命令运行、停止、重启等操作</p></li><li style="list-style-type:circle"><p>支持 ffmpeg 命令参数可视化配置、导入终端命令</p></li><li style="list-style-type:circle"><p>支持，按项目维度管理各种 ffmpeg 命令</p></li><li style="list-style-type:circle"><p>支持，数据导出</p></li></ul></li><li><p>列表+详情交互模式</p></li><li><p>支持 ffmpeg 源切换、中英语言、深色浅色主题切换、窗口关闭方式选择</p><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0">&nbsp;</div><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0; text-align:center"><div class="ckeditor-html5-video" style="text-align:center"><video controls="controls" src="https://rebebuca.com/quick.mp4">&nbsp;</video></div></div><div style="margin-left:0; margin-right:0">&nbsp;</div></div></div></div></div></div></div></div></div></div></li><li><p>支持软件自动更新</p></li><li><p>支持 mac 和 window 平台</p></li><li><p>简单好用、能力丰富、长期维护</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>下载安装</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>Windows：https://download.m7s.live/rb/Rebebuca_0.1.0_x64_en-US.msi</p></li><li><p>Mac：https://download.m7s.live/rb/Rebebuca_0.1.0_x64.dmg</p></li><li><p>Mac(arm64) ：https://download.m7s.live/rb/Rebebuca_0.1.0_aarch64.dmg</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>官方地址</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>官方网站：https://rebebuca.com</p></li><li><p>github：https://github.com/rebebuca/rebebuca</p></li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/rebebuca</guid>
            <link>https://www.oschina.net/p/rebebuca</link>
        </item>
        <item>
            <title>
                <![CDATA[华为发布首个 5.5G 智能核心网：计划 2024 年商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 MWC24 巴塞罗那期间，华为云核心网产品线总裁高治国发布 5.5G 智能核心网解决方案。</p><p>据悉，2023 年新通话已在中国 31 省部署，可支撑 5000 万用户，同时在欧洲、拉美、中东、亚太等多个区域得到了广泛验证，计划 2024 年商用。高治国表示：「华为发布的业界首个新通话-A 通过智能能力和 DC（Data Channel）交互能力升级，正式迈入多模态通信时代。」</p><p><img height="333" src="https://oscimg.oschina.net/oscnet/up-b019072789c268abb1883dc58f6487ea5eb.png" width="500" referrerpolicy="no-referrer"></p><p>5.5G 也就是 5G-A，全称为 5G-Advanced，是 5G 的技术演进，具备更大带宽、更广连接、确定性时延等能力。作为 5G-A 的重要技术之一，三载波聚合（3CC）是 5G-A 的基础体验网，5G-A 三载波聚合可以通过三载波组网方案，结合确定性体验保障等技术，进一步提升网络质量与体验。</p><p>华为倡导的 5.5G 时代，是包含 5.5G、F5.5G、Net5.5G 等全面演进升级的端到端解决方案，会带来 10 倍的网络性能提升，可实现下行万兆、上行千兆的峰值能力。同时在时延、定位、可靠性方面也有了 10 倍的提升，还能实现毫秒级时延和低成本千亿物联。</p><p>在 2023 MWC 上海展会上， 华为董事、ICT 产品与解决方案总裁杨超斌曾宣布，华为 2024 年将会推出面向商用的 5.5G 全套网络设备。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280433</guid>
            <link>https://www.oschina.net/news/280433</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | Web 端弹幕库 Fly Barrage]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content--fly-barrage" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-fly-barrage"></a>✨ Fly Barrage</h1><p>Fully functional and powerful web-based barrage library</p><p>功能完善，强大的 web 端弹幕库</p><h2><a id="user-content--rendering-effects" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-rendering-effects"></a>🎥 Rendering effects</h2><p><img src="https://gitee.com/fei_fei27/fly-barrage/raw/master/public/imgs/0001.png" alt="渲染效果" referrerpolicy="no-referrer"></p><h2><a id="user-content--official-website" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-official-website"></a>📝 Official Website</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Ffly-barrage.netlify.app%2F">https://fly-barrage.netlify.app/</a></p><h2><a id="user-content--install" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-install"></a>📥 Install</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm <span class="nb">install </span>fly-barrage</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--usage" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-usage"></a>🌍 Usage</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c">&lt;!-- Taking Vue framework as an example, this library is not limited to specific frameworks. --&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;</span><span class="k">template</span><span class="nt">&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;div</span><span class="na">id=</span><span class="s">"container"</span><span class="nt">&gt;</span></span><span id="LC4" class="line"><span class="nt">&lt;video</span></span><span id="LC5" class="line"><span class="na">ref=</span><span class="s">"video"</span></span><span id="LC6" class="line"><span class="na">id=</span><span class="s">"video"</span></span><span id="LC7" class="line"><span class="na">controls</span></span><span id="LC8" class="line"><span class="na">autoplay</span></span><span id="LC9" class="line"><span class="na">src=</span><span class="s">"../src/assets/demo1.mp4"</span></span><span id="LC10" class="line"><span class="err">@</span><span class="na">play=</span><span class="s">"videoPlay"</span></span><span id="LC11" class="line"><span class="err">@</span><span class="na">pause=</span><span class="s">"videoPause"</span></span><span id="LC12" class="line"><span class="nt">&gt;&lt;/video&gt;</span></span><span id="LC13" class="line"><span class="nt">&lt;/div&gt;</span></span><span id="LC14" class="line"><span class="nt">&lt;/</span><span class="k">template</span><span class="nt">&gt;</span></span><span id="LC15" class="line"></span><span id="LC16" class="line"><span class="nt">&lt;</span><span class="k">script</span><span class="na">setup</span><span class="na">lang=</span><span class="s">"ts"</span><span class="nt">&gt;</span></span><span id="LC17" class="line"><span class="k">import</span><span class="nx">BarrageRenderer</span><span class="p">,</span><span class="p">{</span><span class="nx">BarrageOptions</span><span class="p">}</span><span class="k">from</span><span class="dl">'</span><span class="s1">fly-barrage</span><span class="dl">'</span><span class="p">;</span></span><span id="LC18" class="line"><span class="k">import</span><span class="p">{</span><span class="nx">onMounted</span><span class="p">,</span><span class="nx">ref</span><span class="p">}</span><span class="k">from</span><span class="dl">'</span><span class="s1">vue</span><span class="dl">'</span><span class="p">;</span></span><span id="LC19" class="line"></span><span id="LC20" class="line"><span class="kd">const</span><span class="nx">barrages</span><span class="p">:</span><span class="nx">BarrageOptions</span><span class="p">[]</span><span class="o">=</span><span class="p">[</span></span><span id="LC21" class="line"><span class="p">{</span></span><span id="LC22" class="line"><span class="dl">"</span><span class="s2">id</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">e55b45c9-7f9e-48c9-9bba-4d3b53441976</span><span class="dl">"</span><span class="p">,</span></span><span id="LC23" class="line"><span class="dl">"</span><span class="s2">barrageType</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">scroll</span><span class="dl">"</span><span class="p">,</span></span><span id="LC24" class="line"><span class="dl">"</span><span class="s2">time</span><span class="dl">"</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span></span><span id="LC25" class="line"><span class="dl">"</span><span class="s2">text</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">残灯无焰影幢幢，此夕闻君谪九江。</span><span class="dl">"</span><span class="p">,</span></span><span id="LC26" class="line"><span class="dl">"</span><span class="s2">fontSize</span><span class="dl">"</span><span class="p">:</span><span class="mi">34</span><span class="p">,</span></span><span id="LC27" class="line"><span class="dl">"</span><span class="s2">lineHeight</span><span class="dl">"</span><span class="p">:</span><span class="mf">1.2</span><span class="p">,</span></span><span id="LC28" class="line"><span class="dl">"</span><span class="s2">color</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">#FFFF00</span><span class="dl">"</span><span class="p">,</span></span><span id="LC29" class="line"><span class="p">},</span></span><span id="LC30" class="line"><span class="p">];</span></span><span id="LC31" class="line"></span><span id="LC32" class="line"><span class="kd">const</span><span class="nx">barrageRenderer</span><span class="o">=</span><span class="nx">ref</span><span class="o">&lt;</span><span class="nx">BarrageRenderer</span><span class="o">&gt;</span><span class="p">();</span></span><span id="LC33" class="line"><span class="kd">const</span><span class="nx">video</span><span class="o">=</span><span class="nx">ref</span><span class="p">();</span></span><span id="LC34" class="line"></span><span id="LC35" class="line"><span class="nx">onMounted</span><span class="p">(()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC36" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="o">=</span><span class="k">new</span><span class="nx">BarrageRenderer</span><span class="p">({</span></span><span id="LC37" class="line"><span class="na">container</span><span class="p">:</span><span class="dl">'</span><span class="s1">container</span><span class="dl">'</span><span class="p">,</span></span><span id="LC38" class="line"><span class="na">video</span><span class="p">:</span><span class="nx">video</span><span class="p">.</span><span class="nx">value</span><span class="p">,</span></span><span id="LC39" class="line"><span class="nx">barrages</span><span class="p">,</span></span><span id="LC40" class="line"><span class="p">});</span></span><span id="LC41" class="line"><span class="p">})</span></span><span id="LC42" class="line"></span><span id="LC43" class="line"><span class="kd">const</span><span class="nx">videoPlay</span><span class="o">=</span><span class="p">()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC44" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="p">?.</span><span class="nx">play</span><span class="p">();</span></span><span id="LC45" class="line"><span class="p">};</span></span><span id="LC46" class="line"></span><span id="LC47" class="line"><span class="kd">const</span><span class="nx">videoPause</span><span class="o">=</span><span class="p">()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC48" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="p">?.</span><span class="nx">pause</span><span class="p">();</span></span><span id="LC49" class="line"><span class="p">};</span></span><span id="LC50" class="line"><span class="nt">&lt;/</span><span class="k">script</span><span class="nt">&gt;</span></span><span id="LC51" class="line"></span><span id="LC52" class="line"><span class="nt">&lt;</span><span class="k">style</span><span class="nt">&gt;</span></span><span id="LC53" class="line"><span class="o">*</span><span class="p">{</span></span><span id="LC54" class="line"><span class="nl">padding</span><span class="p">:</span><span class="m">0</span><span class="p">;</span></span><span id="LC55" class="line"><span class="nl">margin</span><span class="p">:</span><span class="m">0</span><span class="p">;</span></span><span id="LC56" class="line"><span class="p">}</span></span><span id="LC57" class="line"></span><span id="LC58" class="line"><span class="nf">#container</span><span class="p">{</span></span><span id="LC59" class="line"><span class="nl">width</span><span class="p">:</span><span class="m">1000px</span><span class="p">;</span></span><span id="LC60" class="line"><span class="nl">height</span><span class="p">:</span><span class="m">700px</span><span class="p">;</span></span><span id="LC61" class="line"><span class="nl">margin</span><span class="p">:</span><span class="m">20px</span><span class="nb">auto</span><span class="m">0</span><span class="p">;</span></span><span id="LC62" class="line"><span class="p">}</span></span><span id="LC63" class="line"></span><span id="LC64" class="line"><span class="nf">#video</span><span class="p">{</span></span><span id="LC65" class="line"><span class="nl">width</span><span class="p">:</span><span class="m">100%</span><span class="p">;</span></span><span id="LC66" class="line"><span class="nl">height</span><span class="p">:</span><span class="m">100%</span><span class="p">;</span></span><span id="LC67" class="line"><span class="nl">background</span><span class="p">:</span><span class="no">black</span><span class="p">;</span></span><span id="LC68" class="line"><span class="p">}</span></span><span id="LC69" class="line"><span class="nt">&lt;/</span><span class="k">style</span><span class="nt">&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>For complete usage, please clone the project directly, install the dependencies, and then execute npm run dev to view the complete usage</p><p>Try to use a higher version of the node version, my local version is v18.19.0</p><h2><a id="user-content--license" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-license"></a>🌲 License</h2><p><a href="https://gitee.com/fei_fei27/fly-barrage/blob/master/LICENSE">MIT License</a></p>]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/fei_fei27/fly-barrage</guid>
            <link>https://gitee.com/fei_fei27/fly-barrage</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 得物自研 API 网关实践之路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>一、业务背景</h1><p style="color:#24292f; text-align:start">老网关使用 Spring Cloud Gateway （下称 SCG）技术框架搭建，SCG 基于 webflux 编程范式，webflux 是一种响应式编程理念，响应式编程对于提升系统吞吐率和性能有很大帮助; webflux 的底层构建在 netty 之上性能表现优秀；SCG 属于 spring 生态的产物，具备开箱即用的特点，以较低的使用成本助力得物早期的业务快速发展；但是随着公司业务的快速发展，流量越来越大，网关迭代的业务逻辑越来越多，以及安全审计需求的不断升级和稳定性需求的提高，SCG 在以下几个方面逐步暴露了一系列的问题。</p><span id="OSC_h2_2"></span><h2>网络安全</h2><p style="color:#24292f; text-align:start">从网络安全角度来讲，对公网暴露接口无疑是一件风险极高的事情，网关是对外网络流量的重要桥梁，早期的接口暴露采用泛化路由的模式，即通过正则形式（ /api/v1/app/order/** ）的路由规则开放接口，单个应用服务往往只配置一个泛化路由，后续上线新接口时外部可以直接访问；这带来了极大的安全风险，很多时候业务开发的接口可能仅仅是内部调用，但是一不小心就被泛化路由开放到了公网，甚至很多时候没人讲得清楚某个服务具体有多少接口属于对外，多少对内；另一方面从监控数据来看，黑产势力也在不断对我们的接口做渗透试探。</p><span id="OSC_h2_3"></span><h2>协同效率</h2><p style="color:#24292f; text-align:start">引入了接口注册机制，所有对外暴露接口逐一注册到网关，未注册接口不可访问，安全的问题得到了解决但同时带来了性能问题，SCG 采用遍历方式匹配路由规则，接口注册模式推广后路由接口注册数量迅速提升到 3W+，路由匹配性能出现严重问题；泛化路由的时代，一个服务只有一个路由配置，变动频率很低，配置工作由网关关开发人员负责，效率尚可，接口注册模式将路由工作转移到了业务开发同学的身上，这就得引入一套完整的路由审核流程，以提升协同效率；由于路由信息早期都存在配置中心，同时这么大的数据量给配置中心也带来极大的压力和稳定性风险。</p><span id="OSC_h2_4"></span><h2>性能与维护成本</h2><p style="color:#24292f; text-align:start">业务迭代的不断增多，也使得 API 网关堆积了很多的业务逻辑，这些业务逻辑分散在不同的 filter 中，为了降低开发成本，网关只有一套主线分支，不同集群部署的代码完全相同，但是不同集群的业务属性不同，所需要的 filter 逻辑是不一样的；如内网网关集群几乎没什么业务逻辑，但是 App 集群可能需要几十个 filter 的逻辑协同工作；这样的一套代码对内网网关而言，存在着大量的性能浪费；如何平衡维护成本和运行效率是个需要思考的问题。</p><span id="OSC_h2_5"></span><h2>稳定性风险</h2><p style="color:#24292f; text-align:start">API 网关作为基础服务，承载全站的流量出入，稳定性无疑是第一优先级，但其定位决定了绝不可能是一个简单的代理层，在稳定运行的同时依然需要承接大量业务需求，例如 C 端用户登录下线能力，App 强升能力，B 端场景下的鉴权能力等；很难想象较长一段时间以来，网关都保持着双周一次的发版频率；频繁的发版也带来了一些问题，实例启动初期有很多资源需要初始化，此时承接的流量处理时间较长，存在着明显的接口超时现象；早期的每次发版几乎都会导致下游服务的接口短时间内超时率大幅提高，而且往往涉及多个服务一起出现类似情况；为此甚至拉了一个网关发版公告群，提前置顶发版公告，让业务同学和 NOC 有一个心里预期；在发布升级期间尽可能让业务服务无感知这是个刚需。</p><span id="OSC_h2_6"></span><h2>定制能力</h2><p style="color:#24292f; text-align:start">流量灰度是网关最常见的功能之一，对于新版本迭代，业务服务的某个节点发布新版本后希望引入少部分流量试跑观察，但很遗憾 SCG 原生并不支持，需要对负载均衡算法进行手动改写才可以，此外基于流量特征的定向节点路由也需要手动开发，在 SCG 中整个负载均衡算法属于比较核心的模块，不对外直接暴露，存在较高的改造成本。</p><p style="color:#24292f; text-align:start">B 端业务和 C 端业务存在着很大的不同，例如对接口的响应时间的忍受度是不一样的，B 端场景下下载一个报表用户可以接受等待 10s 或者 1 分钟，但是 C 端用户现在没有这个耐心。作为代理层针对以上的场景，我们需要针对不同接口定制不同的超时时间，原生的 SCG 显然也不支持。</p><p style="color:#24292f; text-align:start">诸如此类的定制需求还有很多，我们并不寄希望于开源产品能够开箱即用满足全部需求，但至少定制性拓展性足够好。上手改造成本低。</p><span id="OSC_h1_7"></span><h1>二、技术痛点</h1><p style="color:#24292f; text-align:start">SCG 主要使用了 webflux 技术，webflux 的底层构建在 reactor-netty 之上，而 reactor-netty 构建于 netty 之上；SCG 能够和 spring cloud 的技术栈的各组件，完美适配，做到开箱即用，以较低的使用成本助力得物早期的业务快速发展；但是使用 webflux 也是需要付出一定成本，首先它会额外增加编码人员的心智负担，需要理解流的概念和常用的操作函数，诸如 map, flatmap, defer 等等；其次异步非阻塞的编码形式，充斥着大量的回调函数，会导致顺序性业务逻辑被割裂开来，增加代码阅读理理解成本；此外经过多方面评估我们发现 SCG 存在以下缺点：</p><span id="OSC_h2_8"></span><h2>内存泄露问题</h2><p style="color:#24292f">SCG 存在较多的内存泄漏问题，排查困难，且官方迟迟未能修复，长期运行会导致服务触发 OOM 并宕机；以下为 github 上 SCG 官方开源仓库的待解决的内存泄漏问题，大约有 16 个之多。</p><p style="color:#24292f; text-align:center"><img alt="80.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/80.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 内存泄漏 BUG</p><p style="color:#24292f">下图可以看到 SCG 在长期运行的过程中内存使用一直在增长，<strong>当增长到机器内存上限时当前节点将不可用，联系到网关单节点所承接的 QPS 在几千，可想而知节点宕机带来的危害有多大</strong>；一段时间以来我们需要对 SCG 网关做定期重启。</p><p style="color:#24292f; text-align:center"><img alt="078.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/078.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 生产实例内存增长趋势</p><span id="OSC_h2_9"></span><h2>响应式编程范式复杂</h2><p style="color:#24292f">基于 webflux 中的 flux 和 mono ，在对 request 和 response 信息读取修改时，编码复杂度高，代码理解困难，下图是对 body 信息进行修改时的代码逻辑。</p><p style="color:#24292f; text-align:center"><img alt="607.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/607.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">对 requestBody 进行修改的方式</p><span id="OSC_h2_10"></span><h2>多层抽象的性能损耗</h2><p style="color:#24292f; text-align:start">尽管相比于传统的阻塞式网关，SCG 的性能已经足够优秀，但相比原生的 netty 仍然比较低下，SCG 依赖于 webflux 编程范式，webflux 构建于 reactor-netty 之上，reactor-netty 构建于 netty 之上，多层抽象存在较大的性能损耗。<span>&nbsp;</span></p><p style="color:#24292f; text-align:start"><img alt="106.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/106.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 依赖层级</p><p style="color:#24292f">一般认为程序调用栈越深性能越差；下图为只有一个 filter 的情况下的调用栈，可以看到存在大量的 webflux 中的 subscribe() 和 onNext() 方法调用,这些方法的执行不关联任何业务逻辑，属于纯粹的框架运行层代码，粗略估算下没有引入任何逻辑的情况下 SCG 的调用栈深度在 90+ ，如果引入多个 filter 处理不同的业务逻辑，线程栈将进一步加深，<strong>当前网关的业务复杂度实际栈深度会达到 120 左右，也就是差不多有四分之三的非业务栈损耗，这个比例是有点夸张的。</strong></p><p style="color:#24292f; text-align:center"><img alt="205.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/205.png" referrerpolicy="no-referrer"><img alt="200.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/200.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG filter 调用栈深度</p><span id="OSC_h2_11"></span><h2>路由能力不完善</h2><p style="color:#24292f">原生的的 SCG 并不支持动态路由管理，路由的配置信息通过大量的 KV 配置来做，平均一个路由配置需要三到四条 KV 配置信息来支撑，这些配置数据一般放在诸如 Apollo 或者 ark 这样的配置中心，即使是添加了新的配置 SCG 并不能动态识别，需要引入动态刷新路由配置的能力。另一方面路由匹配算法通过遍历所有的路由信息逐一匹配的模式，当接口级别的路由数量急剧膨胀时，性能是个严重问题。</p><p style="color:#24292f; text-align:center"><img alt="017.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/017.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 路由匹配算法为 On 时间复杂度</p><span id="OSC_h2_12"></span><h2>预热时间长，冷启动 RT 尖刺大</h2><p style="color:#24292f">SCG 中 LoadBalancerClient 会调用 choose 方法来选择合适的 endpoint 作为本次 RPC 发起调用的真实地址，由于是懒加载，只有在有真实流量触发时才会加载创建相关资源；在触发底层的 NamedContextFactory#getContext 方法时存在一个全局锁导致，woker 线程在该锁上大量等待。</p><p style="color:#24292f; text-align:center"><img alt="769.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/769.png" referrerpolicy="no-referrer">NamedContextFactory#getContext 方法存在全局锁</p><p style="color:#24292f; text-align:center"><img alt="209.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/209.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 发布时超时报错增多</p><span id="OSC_h2_13"></span><h2>定制性差，数据流控制耦合</h2><p style="color:#24292f">SCG 在开发运维过程中已经出现了较多的针对源码改造的场景，如动态路由，路由匹配性能优化等；其设计理念老旧，控制流和数据流混合使用，架构不清晰，如对路由管理操作仍然耦合在 filter 中，即使引入 spring mvc 方式管理，依然绑定使用 webflux 编程范式，同时也无法做到控制流端口独立，存在一定安全风险。</p><p style="color:#24292f; text-align:center"><img alt="9007.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9007.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">filter 中对路由进行管理</p><span id="OSC_h1_14"></span><h1>三、方案调研</h1><span id="OSC_h2_15"></span><h2>理想中的网关</h2><p style="color:#24292f; text-align:start">综合业务需求和技术痛点，我们发现<strong>理想型的网关</strong>应该是这个样子的：</p><ul><li><p>支持海量接口注册，并能够在运行时支持动态添加修改路由信息，具备出色路由匹配性能</p></li><li><p>编程范式尽可能简单，降低开发人员心智负担，同时最好是开发人员较为熟悉的语言</p></li><li><p>性能足够好，至少要等同于目前 SCG 的性能，RT99 线和 ART 较低</p></li><li><p>稳定性好，无内存泄漏，能够长时间持续稳定运行，发布升级期间要尽可能下游无感</p></li><li><p>拓展能力强，支持超时定制，多网络协议支持，http，Dubbo 等，生态完善</p></li><li><p>架构设计清晰，数据流与控制流分离，集成 UI 控制面</p></li></ul><span id="OSC_h2_16"></span><h2>开源网关对比</h2><p style="color:#24292f; text-align:start">基于以上需求，我们对市面上的常见网关进行了调研，以下几个开源方案对比。</p><p style="color:#24292f; text-align:start"><img alt="6078.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6078.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">结合当前团队的技术栈，我们倾向于选择 Java 技术栈的开源产品，唯一可选的只有 zuul2 ，但是 zuul2 路由注册和稳定性方面也不能够满足我们的需求，也没有实现数控分离的架构设计。因此唯有走上自研之路。</p><span id="OSC_h1_17"></span><h1>四、自研架构</h1><p style="color:#24292f; text-align:start">通常而言代理网关分为透明代理与非透明代理，其主要区别在于对于流量是否存在侵入性，这里的侵入性主要是指对请求和响应数据的修改；显然 API Gateway 的定位决定了必然会对流量进行数据调整，常见的调整主要有，添加或者修改 head 信息，加密或者解密 query params head ,以及 requestbody 或者 responseBody，可以说 http 请求的每一个部分数据都存在修改的可能性，这要求代理层必须要完全解析数据包信息，而非简单的做一个路由器转发功能。</p><p style="color:#24292f; text-align:start">传统的服务器架构，以 reactor 架构为主。boss 线程和 worker 线程的明确分工，boss 线程负责连接建立创建；worker 线程负责已经建立的连接的读写事件监听处理，同时会将部分复杂业务的处理放到独立的线程池中，进而避免 worker 线程的执行时间过长影响对网络事件处理的及时性；由于网关是 IO 密集型服务，相对来说计算内容较少，可以不必引入这样的业务线程池；直接基于 netty 原生 reactor 架构实现。</p><span id="OSC_h2_18"></span><h2>Reactor 多线程架构</h2><p style="color:#24292f; text-align:start"><img alt="1009.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1009.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">为了只求极致性能和降低多线程编码的数据竞争，单个请求从接收到转发后端，再到接收后端服务响应，以及最终的回写给 client 端，这一系列操作被设计为完全闭合在一个 workerEventLoop 线程中处理；这需要 worker 线程中执行的 IO 类型操作全部实现异步非阻塞化，确保 worker 线程的高速运转；这样的架构和 NGINX 很类似；我们称之为 thread-per-core 模式。<img alt="1008.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1008.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_19"></span><h2>API 网关组件架构</h2><p style="color:#24292f; text-align:start"><img alt="7008.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/7008.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_20"></span><h2>数据流控制流分离</h2><p style="color:#24292f; text-align:start">数据面板专注于流量代理，不处理任何 admin 类请求，控制流监听独立的端口，接收管理指令。</p><p style="color:#24292f; text-align:start"><img alt="6009.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6009.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h1_21"></span><h1>五、核心设计</h1><span id="OSC_h2_22"></span><h2>请求上下文封装</h2><p style="color:#24292f; text-align:start">新的 API 网关底层仍然基于 Netty，其自带的 http 协议解析 handler 可以直接使用。基于 netty 框架的编程范式，需要在初始化时逐一注册用到的 Handler。<span>&nbsp;</span></p><p style="color:#24292f; text-align:start"><img alt="10035.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/10035.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">Client 到 Proxy 链路 Handler 执行顺序</p><p style="color:#24292f; text-align:start">HttpServerCodec 负责 HTTP 请求的解析；对于体积较大的 Http 请求，客户端可能会拆成多个小的数据包进行发送，因此在服务端需要适当的封装拼接，避免收到不完整的 http 请求；HttpObjectAggregator 负责整个请求的拼装组合。</p><p style="color:#24292f; text-align:start">拿到 HTTP 请求的全部信息后在业务 handler 中进行处理；如果请求体积过大直接抛弃；使用 ServerWebExchange 对象封装请求上下文信息，其中包含了 client2Proxy 的 channel, 以及负责处理该 channel 的 eventLoop 线程等信息，考虑到整个请求的处理过程中可能在不同阶段传递一些拓展信息，引入了 getAttributes 方法，用于存储需要传递的数据；此外 ServerWebExchange 接口的基本遵循了 SCG 的设计规范，保证了在迁移业务逻辑时的最小化改动；具体到实现类，可以参考如下代码：</p><pre><code>@Getter
  public class DefaultServerWebExchange implements ServerWebExchange {
    private final Channel client2ProxyChannel;
    private final Channel proxy2ClientChannel;
    private final EventLoop executor;
    private ServerHttpRequest request;
    private ServerHttpResponse response;
    private final Map&lt;String, Object&gt; attributes;
 }
</code></pre><p style="text-align:center">DefaultServerWebExchange</p><p style="color:#24292f; text-align:start">Client2ProxyHttpHandler 作为核心的入口 handler 负责将接收到的 FullHttpRequest 进行封装和构建 ServerWebExchange 对象，其核心逻辑如下。可以看到对于数据读取封装的逻辑较为简单，并没有植入常见的业务逻辑，封装完对象后随即调用 Request filter chain。</p><pre><code>@Override
protected void channelRead0(ChannelHandlerContext ctx, FullHttpRequest fullHttpRequest) {
    try {
        Channel client2ProxyChannel = ctx.channel();
        DefaultServerHttpRequest serverHttpRequest = new DefaultServerHttpRequest(fullHttpRequest, client2ProxyChannel);
        ServerWebExchange serverWebExchange = new DefaultServerWebExchange(client2ProxyChannel,(EventLoop) ctx.executor(), serverHttpRequest, null);
        // request filter chain
        this.requestFilterChain.filter(serverWebExchange);
    }catch (Throwable t){
        log.error("Exception caused before filters!\n {}",ExceptionUtils.getStackTrace(t));
        ByteBufHelper.safeRelease(fullHttpRequest);
        throw t;
    }
}
</code></pre><p style="text-align:center">Client2ProxyHttpHandler 精简后的代码</p><span id="OSC_h2_23"></span><h2>FilterChain 设计</h2><p style="color:#24292f; text-align:start">FilterChain 可以解决异步请求发送出去后，还没收到响应，但是顺序逻辑已经执行完成的尴尬；例如当我们在上文的。</p><p style="color:#24292f; text-align:start">channelRead0 方法中发起某个鉴权 RPC 调用时，出于性能考虑只能使用非阻塞的方式，按照 netty 的非阻塞编码 API 最终要引入类似如下的 callback 机制，++在业务逻辑上在没有收到 RPC 的响应之前该请求的处理应该「暂停」，等待收到响应时才能继续后续的逻辑执行++; 也就是下面代码中的下一步执行逻辑并不能执行，正确的做法是将 nextBiz() 方法包裹在 callBack() 方法内，由 callBack() 触发后续逻辑的执行；这只是发起一次 RPC 调用的情况，在实际的的日常研发过程中存在着鉴权，风控，集群限流（Redis）等多次 RPC 调用，这就导致这样的非阻塞代码编写将异常复杂。</p><pre><code>ChannelFuture writeFuture = channel.writeAndFlush(asyncRequest.httpRequest);
    writeFuture.addListener(future -&gt; {
                if(future.isSuccess()) {
                   callBack();
                }
            }
    );
    nextBiz()；
</code></pre><p style="text-align:center">非阻塞调用下的业务逻辑编排</p><p style="color:#24292f; text-align:start">对于这样的复杂场景，采用 filterChain 模式可以很好的解决；首先 RequestFilterChain().filter(serverWebExchange); 后不存在任何逻辑；发起请求时 ，当前 filter 执行结束，由于此时没有调用 chain.filter(exchange); 所以不会继续执行下一个 filter，发送请求到下游的逻辑也不会执行；当前请求的处理流程暂时中止，<strong>eventloop 线程将切换到其他请求的处理过程上；当收到 RPC 响应时，chain.filter(exchange) 被执行，之前中断的流程被重新拉起。</strong></p><pre><code>public void filter(ServerWebExchange exchange) {
    if (this.index &lt; filters.size()) {
        GatewayFilter filter = filters.get(this.index);
        DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1);
        try {
            filter.filter(exchange, chain);
        }catch (Throwable e){
            log.error("Filter chain unhandle backward exception! Request path {}, FilterClass: {}, exception: {}", exchange.getRequest().getPath(),   filter.getClass(), ExceptionUtils.getFullStackTrace(e));
            ResponseDecorator.failResponse(exchange,500, "网关内部错误！filter chain exception！");
        }
    }
}
</code></pre><p style="text-align:center">基于 filterChain 的调用模式</p><p style="color:#24292f; text-align:start">对于 filter 的执行需要定义先后顺序，这里参考了 SCG 的方案，每个 filter 返回一个 order 值。不同的地方在于 DAG 的设计不允许 order 值重复，因为在 order 重复的情况下，很难界定到底哪个 Filter 先执行，存在模糊地带，这不是我们期望看到的；DAG 中的 Filter 执行顺序为 order 值从小到大，且不允许 order 值重复。为了易于理解，<strong>这里将 Filter 拆分为了 requestFilter，和 responseFilter；分别代表请求的处理阶段，和拿到下游响应阶段，responseFilter 遵循同样的逻辑执行顺序与不可重复性。</strong></p><pre><code>public interface GatewayFilter extends Ordered {
    void filter(ServerWebExchange exchange, GatewayFilterChain chain);
}

public interface ResponseFilter extends GatewayFilter { }

public interface RequestFilter extends GatewayFilter { }
</code></pre><p style="text-align:center">filter 接口设计</p><span id="OSC_h2_24"></span><h2>路由管理与匹配</h2><p style="color:#24292f; text-align:start">以 SCG 网关注册的路由数量为基准，网关节点的需要支撑的路由规则数量是上万级别的，按照得物目前的业务量，上限不超过 5W，为了保证匹配性能，路由规则放在分布式缓存中显然是不合适的，需要保存在节点的内存中。类似于在 nginx 上配置上万条 location 规则，手动维护难度可想而知，即使在配置中心管理起来也很麻烦，所以需要引入独立路由管理模块。<img alt="1090.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1090.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">在匹配的效率上也需要进一步优化，SCG 的路由匹配策略为普通的循环迭代逐一匹配，时间效率为 On，在路由规则膨胀到万级别后，性能急剧拉胯，结合得物的接口规范，新网关采用 Hash 匹配模式，将匹配效率提升到 O1；hash 的 key 为接口的 path, 需要强调的是在同一个网关集群中，path 是唯一的，这里的 path 并不等价于业务服务的接口 path, 绝大多数时候存在一些剪裁，例如在业务服务的编写的/order/detail 接口，在网关实际注册的接口可能为/api/v1/app/order/detail；由于使用了 path 作为 key 进行 hash 匹配。常见的 restful 接口显然是不支持的，确切的讲基于 path 传参数模式的接口均不支持；出于某些历史原因，网关保留了类似 nginx 的前缀匹配的支持，但是这部分功能不对外开放。</p><pre><code>public class Route implements Ordered {
    private final String id;
    private final int skipCount;
    private final URI uri;
 }
</code></pre><p style="text-align:center">route 类设计</p><p style="color:#24292f; text-align:start">route 的 URI 字段中包含了，需要路由到的具体服务名，这里也可以称之为 host ，route 信息会暂存在 exchange 对象的 attributes 属性中, 在后续的 loadbalance 阶段 host 信息会被进一步替换为真实的 endpoint。</p><pre><code>private Route lookupRoute(ServerWebExchange exchange) {
    String path = exchange.getRequest().getPath();
    CachingRouteLocator locator = (CachingRouteLocator) routeLocator;
    Route exactRoute = pathRouteMap.getOrDefault(path, null);
    if (exactRoute != null) {
        exchange.getAttributes().put(DAGApplicationConfig.GATEWAY_ROUTE_CACHE, route);
        return exactRoute;
    }
}
</code></pre><p style="text-align:center">路由匹配逻辑</p><span id="OSC_h2_25"></span><h2>单线程闭环</h2><p style="color:#24292f; text-align:start">为了更好地利用 CPU，以及减少不必要的数据竞争，++将单个请求的处理全部闭合在一个线程当中++；这意味着这个请求的业务逻辑处理，RPC 调用，权限验证，限流 token 获取都将始终由某个固定线程处理。netty 中，网络连接被抽象为 channel，channel 与 eventloop 线程的对应关系为 N 对 1，一个 channel 仅能被一个 eventloop 线程所处理，这在处理用户请求时没有问题，但是在接收请求完毕向下游转发请求时，我们碰到了一些挑战，下游的连接往往是连接池在管理，连接池的管理是另一组 eventLoop 线程在负责，++为了保持闭环需要将连接池的线程设定为处理当前请求的线程++，并且只能是这一个线程；这样一来，默认状态下启动的 N 个线程（N 与机器核心数相同），分别需要管理一个连接池；thread-per-core 模式的性能已经在 nginx 开源组件上得到验证。<img alt="659.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/659.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_26"></span><h2>连接管理优化</h2><p style="color:#24292f; text-align:start">为了满足单线程闭环，需要将连接池的管理线程设置为当前的 eventloop 线程，最终我们通过 threadlocal 进行线程与连接池的绑定；通常情况下 netty 自带的连接池 FixedChannelPool 可以满足我们大部分场景下的需求，这样的连接池也是适用于多线程的场景；由于新网关使用 thread-per-core 模式并将请求处理的全生命周期闭合在单个线程中，所有为了线程安全的额外操作不再必要且存在性能浪费；为此需要对原生连接池做一些优化, 连接的获取和释放简化为对链表结构的简单 getFirst , addLast。</p><p style="color:#24292f; text-align:start">对于 RPC 而言，无论是 HTTP，还是 Dubbo，Redis 等最终底层都需要用到 TCP 连接，将构建在 TCP 连接上的数据解析协议与连接剥离后，我们发现这种纯粹的连接管理是可以复用的，对于连接池而言不需要知道具体连接的用途，只需要维持到特定 endpoint 的连接稳定即可，那么这里的 RPC 服务的连接仍然可以放入连接池中进行托管；最终的连接池设计架构图。<img alt="1300.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1300.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_27"></span><h2>AsyncClient 设计</h2><p style="color:#24292f; text-align:start">对于七层流量而言基本全部都是 Http 请求，同样在 RPC 请求中 http 协议也占了大多数，考虑到还会存在少量的 dubbo, Redis 等协议通信的场景。因此需要抽象出一套异步调用框架来支撑；这样的框架需要具备超时管理，回调执行，错误输出等功能，更重要的是具备协议无关性质， 为了更方便使用需要支持链式调用。</p><p style="color:#24292f; text-align:start">发起一次 RPC 调用通常可以分为以下几步：</p><ol><li>获取目标地址和使用的协议, 目标服务为集群部署时，需要使用 loadbalance 模块</li><li>封装发送的请求，这样的请求在应用层可以具体化为某个 Request 类，网络层序列化为二进制数据流</li><li>出于性能考虑选择非阻塞式发送，发送动作完成后开始计算超时</li><li>接收数据响应，由于采用非阻塞模式，这里的发送线程并不会以 block 的方式等待数据</li><li>在超时时间内完成数据处理，或者触发超时导致连接取消或者关闭<img alt="9006.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9006.jpeg" referrerpolicy="no-referrer"></li></ol><p style="color:#24292f">AsyncClient 模块内容并不复杂，AsyncClient 为抽象类不区分使用的网络协议；ConnectionPool 作为连接的管理者被 client 所引用，<strong>获取连接的 key 使用 protocol+ip+port 再适合不过</strong>；通常在某个具体的连接初始化阶段就已经确定了该 channel 所使用的协议，因此初始化时会直接绑定协议 Handler；当协议为 HTTP 请求时，HttpClientCodec 为 HTTP 请求的编解码 handler；也可以是构建在 TCP 协议上的 Dubbo, Mysql ,Redis 等协议的 handler。</p><p style="color:#24292f; text-align:start">首先对于一个请求的不同执行阶段需要引入状态定位，这里引入了 STATE 枚举：</p><pre><code>enum STATE{
        INIT,SENDING,SEND,SEND_SUCCESS,FAILED,TIMEOUT,RECEIVED
}
</code></pre><p style="color:#24292f; text-align:start">其次在执行过程中设计了 AsyncContext 作为信息存储的载体，内部包含 request 和 response 信息，作用类似于上文提到的 ServerWebExchange；channel 资源从连接池中获取，使用完成后需要自动放回。</p><pre><code>public class AsyncContext&lt;Req, Resp&gt; implements Cloneable{
    STATE state = STATE.INIT;
    final Channel usedChannel;
    final ChannelPool usedChannelPool;
    final EventExecutor executor;
    final AsyncClient&lt;Req, Resp&gt; agent;
    
    Req request;
    Resp response;
    
    ResponseCallback&lt;Resp&gt; responseCallback;
    ExceptionCallback exceptionCallback;
    
    int timeout;
    long deadline;
    long sendTimestamp;

    Promise&lt;Resp&gt; responsePromise;
}
</code></pre><p style="text-align:center">AsyncContext</p><p style="color:#24292f; text-align:start">AsyncClient 封装了基本的网络通信能力，不拘泥于某个固定的协议，可以是 Redis, http，Dubbo 等。当将数据写出去之后，该 channel 的非阻塞调用立即结束，在没有收到响应之前无法对 AsyncContext 封装的数据做进一步处理，如何在收到数据时将接收到的响应和之前的请求管理起来这是需要面对的问题，channel 对象，的 attr 方法可以用于临时绑定一些信息，以便于上下文切换时传递数据，可以在发送数据时将 AsyncContext 对象绑定到该 channel 的某个固定 key 上。当 channel 收到响应信息时，在相关的 AsyncClientHandler 里面取出 AsyncContext。</p><pre><code>public abstract class AsyncClient&lt;Req, Resp&gt; implements Client {
    private static final int defaultTimeout = 5000;
    private final boolean doTryAgain = false;
    private final ChannelPoolManager channelPoolManager = ChannelPoolManager.getChannelPoolManager();
    protected static AttributeKey&lt;AsyncRequest&gt; ASYNC_REQUEST_KEY = AttributeKey.valueOf("ASYNC_REQUEST");

    public abstract ApplicationProtocol getProtocol();
    
    public AsyncContext&lt;Req, Resp&gt; newRequest(EventExecutor executor, String endpoint, Req request) {
        final ChannelPoolKey poolKey = genPoolKey(endpoint);
        ChannelPool usedChannelPool = channelPoolManager.acquireChannelPool(executor, poolKey);
        return new AsyncContext&lt;&gt;(this,executor,usedChannelPool,request, defaultTimeout, executor.newPromise());
    }

    public void submitSend(AsyncContext&lt;Req, Resp&gt; asyncContext){
        asyncContext.state = AsyncContext.STATE.SENDING;
        asyncContext.deadline = asyncContext.timeout + System.currentTimeMillis();   
        ReferenceCountUtil.retain(asyncContext.request);
        Future&lt;Resp&gt; responseFuture = trySend(asyncContext);
        responseFuture.addListener((GenericFutureListener&lt;Future&lt;Resp&gt;&gt;) future -&gt; {
            if(future.isSuccess()){
                ReferenceCountUtil.release(asyncContext.request);
                Resp response = future.getNow();
                asyncContext.responseCallback.callback(response);
            }
        });
    }
    /**
     * 尝试从连接池中获取连接并发送请求，若失败返回错误
     */
    private Promise&lt;Resp&gt; trySend(AsyncContext&lt;Req, Resp&gt; asyncContext){
        Future&lt;Channel&gt; acquireFuture = asyncContext.usedChannelPool.acquire();
        asyncContext.responsePromise = asyncContext.executor.newPromise();
        acquireFuture.addListener(new GenericFutureListener&lt;Future&lt;Channel&gt;&gt;() {
                @Override
                public void operationComplete(Future&lt;Channel&gt; channelFuture) throws Exception {
                    sendNow(asyncContext,channelFuture);
                }
        });
        return asyncContext.responsePromise;
    }

    private void sendNow(AsyncContext&lt;Req, Resp&gt; asyncContext, Future&lt;Channel&gt; acquireFuture){
        boolean released = false;
        try {
            if (acquireFuture.isSuccess()) {
                NioSocketChannel channel = (NioSocketChannel) acquireFuture.getNow();
                released = true;
                assert channel.attr(ASYNC_REQUEST_KEY).get() == null;
                asyncContext.usedChannel = channel;
                asyncContext.state = AsyncContext.STATE.SEND;
                asyncContext.sendTimestamp = System.currentTimeMillis();
                channel.attr(ASYNC_REQUEST_KEY).set(asyncContext);
                ChannelFuture writeFuture = channel.writeAndFlush(asyncContext.request);
                channel.eventLoop().schedule(()-&gt; doTimeout(asyncContext), asyncContext.timeout, TimeUnit.MILLISECONDS);
            } else {
                asyncContext.responsePromise.setFailure(acquireFuture.cause());
            }
        } catch (Exception e){
            throw new Error("Unexpected Exception.............!");
        }finally {
            if(!released) {
                ReferenceCountUtil.safeRelease(asyncContext.request);
            }
        }
    }
}
</code></pre><p style="text-align:center">AsyncClient 核心源码</p><pre><code>public class AsyncClientHandler extends SimpleChannelInboundHandler {
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception {
        AsyncContext asyncContext = ctx.attr(AsyncClient.ASYNC_REQUEST_KEY).get();
        try {
            asyncContext.state = AsyncContext.STATE.RECEIVED;
            asyncContext.releaseChannel();
            asyncContext.responsePromise.setSuccess(msg);
        }catch (Throwable t){
            log.error("Exception raised when set Success callback. Exception \n: {}", ExceptionUtils.getFullStackTrace(t));
            ByteBufHelper.safeRelease(msg);
            throw t;
        }
    }
}
</code></pre><p style="text-align:center">AsyncClientHandler</p><p style="color:#24292f; text-align:start">通过上面几个类的封装得到了一个易用使用的 AsyncClient，下面的代码为调用权限系统的案例：</p><pre><code>final FullHttpRequest httpRequest = HttpRequestUtil.getDefaultFullHttpRequest(newAuthReq, serviceInstance, "/auth/newCheckSls");
asyncClient.newRequest(exchange.getExecutor(), endPoint,httpRequest)
        .timeout(timeout)
        .onComplete(response -&gt; {
            String checkResultJson = response.content().toString(CharsetUtil.UTF_8);
            response.release();
            NewAuthResult result = Jsons.parse(checkResultJson,NewAuthResult.class);
            TokenResult tokenResult = this.buildTokenResult(result);
            String body = exchange.getAttribute(DAGApplicationConfig.REQUEST_BODY);

            if (tokenResult.getUserInfoResp() != null) {
                UserInfoResp userInfo = tokenResult.getUserInfoResp();
                headers.set("userid", userInfo.getUserid() == null ? "" : String.valueOf(userInfo.getUserid()));
                headers.set("username", StringUtils.isEmpty(userInfo.getUsername()) ? "" : userInfo.getUsername());
                headers.set("name", StringUtils.isEmpty(userInfo.getName()) ? "" : userInfo.getName());
                chain.filter(exchange);
            } else {
                log.error("{},heads: {},response: {}", path, headers, tokenResult);
                int code = tokenResult.getCode() != null ? tokenResult.getCode().intValue() : ResultCode.UNAUTHO.code;
                ResponseDecorator.failResponse(exchange, code, tokenResult.getMsg());
            }
        })
        .onError(throwable -&gt; {
            log.error("Request service {},occur an exception {}",endPoint, throwable);
            ResponseDecorator.failResponseWithStatus(exchange,HttpResponseStatus.INTERNAL_SERVER_ERROR,"AuthFilter 验证失败");
        })
        .sendRequest();
</code></pre><p style="text-align:center">asyncClient 的使用</p><span id="OSC_h2_28"></span><h2>请求超时管理</h2><p style="color:#24292f; text-align:start">一个请求的处理时间不能无限期拉长， 超过某个阈值的情况下 App 的页面会被取消 ，长时间的加载卡顿不如快速报错带来的体验良好；显然网关需要针对接口做超时处理，尤其是在向后端服务发起请求的过程，通常我们会设置一个默认值，例如 3 秒钟，超过这个时间网关会向请求端回写 timeout 的失败信息，由于网关下游接入的服务五花八门，可能是 RT 敏感型的 C 端业务，也可能是逻辑较重 B 端服务接口，甚至是存在大量计算的监控大盘接口。这就导致不同接口对超时时间的诉求不一样，因此针对每个接口的超时时间设定应该被独立出来，而不是统一配置成一个值。</p><pre><code>asyncClient.newRequest(exchange.getExecutor(), endPoint,httpRequest)
        .timeout(timeout)
        .onComplete(response -&gt; {
            String checkResultJson = response.content().toString(CharsetUtil.UTF_8);
            //..........
        })
        .onError(throwable -&gt; {
            log.error("Request service {},occur an exception {}",endPoint, throwable);
            ResponseDecorator.failResponseWithStatus(exchange,HttpResponseStatus.INTERNAL_SERVER_ERROR,"AuthFilter 验证失败");
        })
        .sendRequest();
</code></pre><p style="color:#24292f; text-align:start">asyncClient 的链式调用设计了 timeout 方法，用于传递超时时间，我们可以通过一个全局 Map 来配置这样的信息。</p><p style="color:#24292f; text-align:start">Map&lt;String,Integer&gt; 其 key 为全路径的 path 信息，V 为设定的超时时间，单位为 ms, 至于 Map 的信息在实际配置过程中如何承载，使用 ARK 配置或者 Mysql 都很容易实现。处于并发安全和性能的极致追求，超时事件的设定和调度最好能够在与当前 channel 绑定的线程中执行，庆幸的是 EventLoop 线程自带 schedule 方法。具体来看上文的 AsyncClient 的 56 行。schedule 方法内部以堆结构的方式实现了对超时时间进行管理，整体性能尚可。</p><span id="OSC_h2_29"></span><h2>堆外内存管理优化</h2><p style="color:#24292f; text-align:start">常见的堆外内存手动管理方式无非是引用计数，不同处理逻辑可能针对 RC (引用计数) 的值做调整，到某个环节的业务逻辑处理后已经不记得当前的引用计数值是多少了，甚至是前面的 RC 增加了，后面的 RC 忘记减少了；但换个思路，在数据回写给客户端后我们肯定要把这个请求整个生命周期所申请的堆外内存全部释放掉，堆外内存在回收的时候条件只有一个，就是 RC 值为 0 ，那么在最终的 release 的时候，我们引入一个 safeRelase 的思路 , 如果当前的 RC&gt;0 就不停的 release ，直至为 0；因此只要把这样的逻辑放在 netty 的最后一个 Handler 中即可保证内存得到有效释放。</p><pre><code>public static void safeRelease(Object msg){
    if(msg instanceof ReferenceCounted){
        ReferenceCounted ref = (ReferenceCounted) msg;
        int refCount = ref.refCnt();
        for(int i=0; i&lt;refCount; i++){
            ref.release();
        }
    }
}
</code></pre><p style="text-align:center">safeRelease</p><span id="OSC_h2_30"></span><h2>响应时间尖刺优化</h2><p style="color:#24292f; text-align:start">由于 DAG 选择了复用 spring 的 loadbalance 模块，但这样一来就会和 SCG 一样存在启动初期的响应时间尖刺问题；为此我们进一步分析 RibbonLoadBalancerClient 的构建过程，发现其用到了 NamedContextFactory，该类的 contexts 变量保存了每一个 serviceName 对应的一个独立 context，这种使用模式带来大量的性能浪费。</p><pre><code>public abstract class NamedContextFactory&lt;C extends NamedContextFactory.Specification&gt;implements DisposableBean, ApplicationContextAware {
    //1. contexts 保存 key -&gt; ApplicationContext 的 map
    private Map&lt;String, AnnotationConfigApplicationContext&gt; contexts = new ConcurrentHashMap&lt;&gt;();
    //........
}
</code></pre><p style="color:#24292f; text-align:start">在实际运行中 RibbonLoadBalancerClient 会调用 choose 方法来选择合适的 endpoint 作为本次 RPC 发起调用的真实地址；choose 方法执行过程中会触发 getLoadBalancer() 方法执行，可以看到该方法的可以按照传入的 serviceId 获取专属于这个服务的 LoadBalancer，事实上这样的设计有点多此一举。大部分情况下，每个服务的负载均衡算法都一致的，完全可以复用一个 LoadBalancer 对象；该方法最终是从 spring 容器中获取 LoadBalancer。</p><pre><code>class  RibbonLoadBalancerClient{
    //..........
    private SpringClientFactory clientFactory;
    
    @Override
    public ServiceInstance choose(String serviceId) {
       return choose(serviceId, null);
    }
    
    public ServiceInstance choose(String serviceId, Object hint) {
       Server server = getServer(getLoadBalancer(serviceId), hint);
       if (server == null) {
          return null;
       }
       return new RibbonServer(serviceId, server, isSecure(server, serviceId),
             serverIntrospector(serviceId).getMetadata(server));
    }
    
    protected ILoadBalancer getLoadBalancer(String serviceId) {
       return this.clientFactory.getLoadBalancer(serviceId);
    }
    //.........
}
</code></pre><p style="text-align:center">RibbonLoadBalancerClient</p><p style="color:#24292f; text-align:start"><strong>由于是懒加载，实际流量触发下才会执行，因此第一次执行时，RibbonLoadBalancerClient 对象并不存在，需要初始化创建，创建时大量线程并发调用 SpringClientFactory#getContext 方法，锁在同一个对象上，出现大量的 RT 尖刺。这也解释了为什么 SCG 网关在发布期间会出现响应时间大幅度抖动的现象。</strong></p><pre><code>public class SpringClientFactory extends NamedContextFactory&lt;RibbonClientSpecification&gt;{
    //............    
    protected AnnotationConfigApplicationContext getContext(String name) {
       if (!this.contexts.containsKey(name)) {
          synchronized (this.contexts) {
             if (!this.contexts.containsKey(name)) {
                this.contexts.put(name, createContext(name));
             }
          }
       }
       return this.contexts.get(name);
    }
    //.........
}
</code></pre><p style="text-align:center">SpringClientFactory</p><p style="color:#24292f; text-align:start">在后期的压测过程中，发现 DAG 的线程数量远超预期，基于 thread-per-core 的架构模式下，过多的线程对性能损害比较大，尤其是当负载上升到较高水位时。上文提到<strong>默认情况下，每个服务都会创建独立 loadBalanceClient , 而在其内部又会启动独立的线程去同步当前关联的 serviceName 对应的可用 serverList</strong>,网关的特殊性导致需要接入的服务数量极为庞大，进而导致运行一段时间后 DAG 的线程数量急剧膨胀，对于同步 serverList 这样的动作而言，完全可以采用非阻塞的方式从注册中心拉取相关的 serverList , 这种模式下单线程足以满足性能要求。</p><p style="color:#24292f; text-align:start"><img alt="1078.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1078.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">serverList 的更新前后架构对比</p><p style="color:#24292f; text-align:start">通过预先初始化的方式以及全局只使用 1 个 context 的方式，可以将这里冷启动尖刺消除，改造后的测试结果符合预期。<img alt="6034.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6034.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">通过进一步修改优化 spring loadbalance serverList 同步机制，降低 90% 线程数量的使用。</p><p style="color:#24292f; text-align:start"><img alt="879.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/879.png" referrerpolicy="no-referrer"></p><p style="text-align:center">优化前线程数量（725）</p><p style="color:#24292f; text-align:start"><img alt="779.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/779.png" referrerpolicy="no-referrer"></p><p style="text-align:center">优化后线程数量（72）</p><span id="OSC_h2_31"></span><h2>集群限流改造优化</h2><p style="color:#24292f; text-align:start">首先来看 DAG 启动后 sentinel 相关线程，类似的问题，线程数量非常多，需要针对性优化。<img alt="234.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/234.png" referrerpolicy="no-referrer"></p><p style="text-align:center">Sentinel 线程数</p><p style="color:#24292f; text-align:start">sentinel 线程分析优化：</p><p style="color:#24292f; text-align:start"><img alt="120.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/120.jpeg" referrerpolicy="no-referrer"><img alt="220.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/220.png" referrerpolicy="no-referrer"></p><p style="text-align:center">最终优化后的线程数量为 4 个</p><p style="color:#24292f; text-align:start">sentinel 原生限流源码分析如下，进一步分析 SphU#entry 方法发现其底调用 FlowRuleCheck#passClusterCheck；<strong>在 passClusterCheck 方法中发现底层网络 IO 调用为阻塞式</strong>，由于该方法的执行线程为 workerEventLoop，因此需要使用上文提到的 AsyncClient 进行优化。</p><pre><code>private void doSentinelFlowControl(ServerWebExchange exchange, GatewayFilterChain chain, String resource){
    Entry urlEntry = null;
    try {
        if (!StringUtil.isEmpty(resource)) {
            //1. 检测是否限流
            urlEntry = SphU.entry(resource, ResourceTypeConstants.COMMON_WEB, EntryType.IN);
        }
       //2. 通过，走业务逻辑
        chain.filter(exchange);
    } catch (BlockException e) {
        //3. 拦截，直接返回 503
        ResponseDecorator.failResponseWithStatus(exchange, HttpResponseStatus.SERVICE_UNAVAILABLE, ResultCode.SERVICE_UNAVAILABLE.message);
    } catch (RuntimeException e2) {
        Tracer.traceEntry(e2, urlEntry);
        log.error(ExceptionUtils.getFullStackTrace(e2));
        ResponseDecorator.failResponseWithStatus(exchange, HttpResponseStatus.INTERNAL_SERVER_ERROR,HttpResponseStatus.INTERNAL_SERVER_ERROR.reasonPhrase());
    } finally {
        if (urlEntry != null) {
            urlEntry.exit();
        }
        ContextUtil.exit();
    }
}
</code></pre><p style="text-align:center">SentinelGatewayFilter（sentinel 适配 SCG 的逻辑）</p><pre><code>public class RedisTokenService implements InitializingBean {
    private final RedisAsyncClient client = new RedisAsyncClient();
    private final RedisChannelPoolKey connectionKey;
    
    public RedisTokenService(String host, int port, String password, int database, boolean ssl){
        connectionKey = new RedisChannelPoolKey(String host, int port, String password, int database, boolean ssl);
    }
    //请求 token
    public Future&lt;TokenResult&gt; asyncRequestToken(ClusterFlowRule rule){
        ....
        sendMessage(redisReqMsg,this.connectionKey)
    }
    
    private Future&lt;TokenResult&gt; sendMessage(RedisMessage requestMessage, EventExecutor executor, RedisChannelPoolKey poolKey){
        AsyncRequest&lt;RedisMessage,RedisMessage&gt; request = client.newRequest(executor, poolKey,requestMessage);
        DefaultPromise&lt;TokenResult&gt; tokenResultFuture = new DefaultPromise&lt;&gt;(request.getExecutor());

        request.timeout(timeout)
                .onComplete(response -&gt; {
                    ...
                    tokenResultFuture.setSuccess(response);
                })
                .onError(throwable -&gt; {
                    ...
                    tokenResultFuture.setFailure(throwable);
                }).sendRequest();

        return tokenResultFuture;
    }
}
</code></pre><p style="text-align:center">RedisTokenService</p><p style="color:#24292f; text-align:start">最终的限流 Filter 代码如下：</p><pre><code>public class SentinelGatewayFilter implements RequestFilter {
    @Resource
    RedisTokenService tokenService;\
    
    @Override
    public void filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //当前为 netty NioEventloop 线程
        ServerHttpRequest request = exchange.getRequest();
        String resource = request.getPath() != null ? request.getPath() : "";
  
        //判断是否有集群限流规则
        ClusterFlowRule rule = ClusterFlowManager.getClusterFlowRule(resource);
        if (rule != null) {
           //异步非阻塞请求 token
            tokenService.asyncRequestToken(rule,exchange.getExecutor())
                    .addListener(future -&gt; {
                        TokenResult tokenResult;
                        if (future.isSuccess()) {
                            tokenResult = (TokenResult) future.getNow();
                        } else {
                            tokenResult = RedisTokenService.FAIL;
                        }
                        if(tokenResult == RedisTokenService.FAIL || tokenResult == RedisTokenService.ERROR){
                            log.error("Request cluster token failed, will back to local flowRule check");
                        }
                        ClusterFlowManager.setTokenResult(rule.getRuleId(), tokenResult);
                        doSentinelFlowControl(exchange, chain, resource);
                    });
        } else {
            doSentinelFlowControl(exchange, chain, resource);
        }
    }
}
</code></pre><p style="text-align:center">改造后适配 DAG 的 SentinelGatewayFilter</p><span id="OSC_h1_32"></span><h1>六、压测性能</h1><span id="OSC_h2_33"></span><h2>DAG 高压表现</h2><p style="color:#24292f; text-align:start">wrk -t32 -c1000 -d60s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">DAG 网关的 QPS、实时 RT、错误率、CPU、内存监控图；<strong>在 CPU 占用 80% 情况下，能够支撑的 QPS 在 4.5W。</strong><img alt="657.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/657.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 网关的 QPS、RT 折线图</p><p style="color:#24292f; text-align:start"><img alt="645.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/645.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>DAG 在 CPU 占用 80% 情况下，能够支撑的 QPS 在 4.5W，ART 19ms</strong></p><span id="OSC_h2_34"></span><h2>SCG 高压表现</h2><p style="color:#24292f; text-align:start">wrk -t32 -c1000 -d60s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">SCG 网关的 QPS、实时 RT、错误率、CPU、内存监控图：<img alt="3410.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/3410.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">SCG 网关的 QPS、RT 折线图：<img alt="1670.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1670.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>SCG 在 CPU 占用 95% 情况下，能够支撑的 QPS 在 1.1W，ART 54.1ms</strong></p><span id="OSC_h2_35"></span><h2>DAG 低压表现</h2><p style="color:#24292f; text-align:start">wrk -t5 -c20 -d120s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">DAG 网关的 QPS、实时 RT、错误率、CPU、内存：<img alt="1354.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1354.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 网关的 QPS、RT 折线图：</p><p style="color:#24292f; text-align:start"><img alt="1·.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1%C2%B7.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>DAG 在 QPS 1.1W 情况下，CPU 占用 30%，ART 1.56ms</strong></p><span id="OSC_h2_36"></span><h2>数据对比</h2><p style="color:#24292f; text-align:start"><img alt="00.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/-00.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>结论</strong></p><p style="color:#24292f; text-align:start">满负载情况下，DAG 要比 SCG 的吞吐量高很多，QPS 几乎是 4 倍，RT 反而消耗更低，SCG 在 CPU 被打满后，RT 表现出现严重性能劣化。DAG 的吞吐控制和 SCG 一样情况下，CPU 和 RT 损耗下降了更多。DAG 在最大压力下，内存消耗比较高，达到了 75% 左右，不过到峰值后，就不再会有大幅变动了。对比压测结果，结论令人欣喜，<strong>SCG 作为 Java 生态当前使用最广泛的网关，其性能属于一线水准，DAG 的性能达到其 4 倍以上也是远超意料，这样的结果给与研发同学极大的鼓舞。</strong></p><span id="OSC_h1_37"></span><h1>七、投产收益</h1><span id="OSC_h2_38"></span><h2>安全性提升</h2><p style="color:#24292f; text-align:start"><strong>完善的接口级路由管理</strong></p><p style="color:#24292f; text-align:start">基于接口注册模式的全新路由上线，包含了接口注册的申请人，申请时间，接口场景备注信息等，接口管理更加严谨规范；结合路由组功能可以方便的查询当前服务的所有对外接口信息，某种程度上具备一定的 API 查询管理能力；同时为了缓解用户需要检索的接口太多的尴尬，引入了一键收藏功能，大部分时候用户只需要切换到已关注列表即可。</p><p style="color:#24292f; text-align:start"><img alt="·01.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/%C2%B701.png" referrerpolicy="no-referrer"></p><p style="text-align:center">注册接口列表</p><p style="color:#24292f; text-align:start"><img alt="=0.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/=0.png" referrerpolicy="no-referrer"></p><p style="text-align:center">接口收藏</p><p style="color:#24292f; text-align:start"><strong>防渗透能力极大增强</strong></p><p style="color:#24292f; text-align:start">早期的泛化路由，给黑产的渗透带来了极大的想象空间和安全隐患，甚至可以在外网直接访问某些业务的配置信息。<img alt="701.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/701.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">黑产接口渗透</p><p style="color:#24292f; text-align:start">接口注册模式启用后，所有未注册的接口均无法访问，防渗透能力提升一个台阶，同时自动推送异常接口访问信息。</p><p style="color:#24292f; text-align:start"><img alt="81.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/8-1.png" referrerpolicy="no-referrer"></p><p style="text-align:center">404 接口访问异常推送</p><span id="OSC_h2_39"></span><h2>稳定性增强</h2><p style="color:#24292f; text-align:start"><strong>内存泄漏问题解决</strong></p><p style="color:#24292f; text-align:start">通过一系列手段改进优化和严格的测试，新网关的内存使用更加稳健，内存增长曲线直接拉平，彻底解决了泄漏问题。</p><p style="color:#24292f; text-align:start"><img alt="2300.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/2300.png" referrerpolicy="no-referrer"></p><p style="text-align:center">老网关内存增长趋势</p><p style="color:#24292f; text-align:start"><img alt="789=.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/789=.png" referrerpolicy="no-referrer"></p><p style="text-align:center">新网关内存增长趋势</p><p style="color:#24292f; text-align:start"><strong>响应时间尖刺消除</strong></p><p style="color:#24292f; text-align:start">通过预先初始化 &amp; context 共用等手段，去除了运行时并发创建多个 context 抢占全局锁的开销，冷启动 RT 尖刺降低 99% ；关于 spring load balance 模块的更多优化细节可以参考这篇博客：Spring LoadBalance 存在问题与优化。</p><p style="color:#24292f; text-align:start"><strong>压测数据对比</strong><img alt="1=.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1-=.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>实际生产监控</strong></p><p style="color:#24292f; text-align:start">趋势图上略有差异，但是从非 200 请求的绝对值上看，这种差异可以忽略, <strong>对比发布期间和非发布期间异常请求的数量，发现基本没有区别，这代表着以往的发布期间的响应时间尖刺基本消除，做到了发布期间业务服务彻底无感知。</strong></p><p style="color:#24292f; text-align:start"><img alt="01.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-1.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 4 日发布期间各节点流量变化</p><p style="color:#24292f; text-align:start"><img alt="02.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-2.png" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 4 日异常请求状态数量监控 (发布期间)</p><p style="color:#24292f; text-align:start"><img alt="03.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-3.png" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 5 日异常请求状态数量监控（无发布）</p><span id="OSC_h2_40"></span><h2>降本增效</h2><p style="color:#24292f; text-align:start"><strong>资源占用下降 50% +</strong></p><p style="color:#24292f; text-align:start"><img alt="04.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-4.png" referrerpolicy="no-referrer"></p><p style="text-align:center">SCG 平均 CPU 占用</p><p style="color:#24292f; text-align:start"><img alt="05.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-5.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 资源占用</p><p style="color:#24292f; text-align:start"><strong>JDK17 升级收益</strong></p><p style="color:#24292f">得益于 ZGC 的优秀算法，JVM17 在 GC 暂停时间上取得了出色的成果，网关作为延迟敏感型应用对 GC 的暂停时间尤为看重，为此我们组织升级了 JDK17 版本；下面为同等流量压力情况下的配置不同 GC 的效果对比，<strong>可以看到 GC 的暂停时间从平均 70ms 降低到 1ms 内，RT99 线得到大幅度提升；吞吐量不再受流量波动而大幅度变化，性能表现更加稳定；同时网关的平均响应时间损耗降低 5%。</strong></p><p style="color:#24292f"><img alt="08.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-8.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK8-G1 暂停时间表现</p><p style="color:#24292f; text-align:start"><img alt="09.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/09-.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17-ZGC 暂停时间表现</p><p style="color:#24292f; text-align:start">吞吐量方面，G1 伴随流量的变化呈现出一定的波动趋势，均线在 99.3% 左右。ZGC 的吞吐量则比较稳定，维持在无限接近 100% 的水平。</p><p style="color:#24292f; text-align:start"><img alt="9.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9--.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK8-G1 吞吐量</p><p style="color:#24292f; text-align:start"><img alt="1.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/--1.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17-ZGC 吞吐量</p><p style="color:#24292f; text-align:start">对于实际业务接口的影响，从下图中可以看到平均响应时间有所下降，这里的 RT 差值表示接口经过网关层的损耗时间；不同接口的 RT 差值损耗是不同的，这可能和请求响应体的大小，是否经过登录验证，风控验证等业务逻辑有关。</p><p style="color:#24292f; text-align:start"><img alt="80.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/8-0.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17 与 JDK8 ART 对比</p><p style="color:#24292f; text-align:start">需要指出的是 ZGC 对于一般的 RT 敏感型应用有很大提升， 服务的 RT 99 线得到显著改善。但是如果当前应用大量使用了堆外内存的方式，则提升相对较弱，如大量使用 netty 框架的应用, 因为这些应用的大部分数据都是通过手动释放的方式进行管理。</p><span id="OSC_h1_41"></span><h1>八、思考总结</h1><span id="OSC_h2_42"></span><h2>架构演进</h2><p style="color:#24292f; text-align:start">API 网关的自研并非一蹴而就，而是经历了多次业务迭代循序渐进的过程；从早期的泛化路由引发的安全问题处理，到后面的大量路由注册，带来的匹配性能下降 ，以及最终压垮老网关最后一根稻草的内存泄漏问题；在不同阶段需要使用不同的应对策略，早期业务快速迭代，大量的需求堆积，最快的时候一个功能点的改动需要三四天内上线 ，我们很难有足够的精力去做一些深层次的改造，这个时候需求导向为优先，功能性建设完善优先，是一个快速奔跑的建设期；伴随体量的增长安全和稳定性的重视程度逐步拔高，继而推进了这些方面的大量建设；从拓展 SCG 的原有功能到改进框架源码，以及最终的自研重写，可以说新的 API 网关是一个业务推进而演化出来的产物，也只有这样 」生长「 出来的架构产品才能更好的契合业务发展的需要。</p><span id="OSC_h2_43"></span><h2>技术思考</h2><p style="color:#24292f; text-align:start">开源的 API 网关有很多，但是自研的案例并不多，我们能够参考的方案也很有限。除了几个业界知名的产品外，很多开源的项目参考的价值并不大；从自研的目标来看，我们最基本的要求是性能和稳定性要优于现有的开源产品，至少 Java 的生态是这样；这就要求架构设计和代码质量上必须比现有的开源产品更加优秀，才有可能；为此我们深度借鉴了流量代理界的常青树 Nginx，发现基于 Linux 多进程模型下的 OS，如果要发挥出最大效能，单 CPU 核心支撑单进程（线程）是效率最高的模式。可以将 OS 的进程调度开销最小化同时将高速缓存 miss 降到最低，此外还要尽可能减少或者消除数据竞争，避免锁等待和自旋带来的性能浪费；DAG 的整个技术架构可以简化的理解为引入了独立控制流的多线程版的 Nginx。</p><p style="color:#24292f; text-align:start">中间件的研发创新存在着较高的难度和复杂性，更何况是在业务不断推进中换引擎。在整个研发过程中，为了尽可能适配老的业务逻辑，对原有的业务逻辑的改动最小化，新网关对老网关的架构层接口做了全面适配；换句话说新引擎的对外暴露的核心接口与老网关保持一致，让老的业务逻辑在 0 改动或者仅改动少量几行代码后就能在新网关上直接跑，能够极大幅度降低我们的测试回归成本，因为这些代码本身的逻辑正确性，已经在生产环境得到了大量验证。这样的适配器模式同样适用于其他组件和业务开发。</p><p style="color:#24292f; text-align:start">作为底层基础组件的开发人员，要对自己写下的每一行代码都有清晰的认识，不了解的地方一定要多翻资料，多读源码，模棱两可的理解是绝对不够的；常见的开源组件虽然说大部分代码都是资深开发人员写出来的，但是有程序员的地方就有 bug ，要带着审慎眼光去看到这些组件，而不是一味地使用盲从，所谓尽信书不如无书；很多中间件的基本原理都是相通的，如常见 Raft 协议，基于 epoll 的 reactor 网络架构，存储领域的零拷贝技术，预写日志，常见的索引技术，hash 结构，B+树，LSM 树等等。一个成熟的中间件往往会涉及多个方向的技术内容。研发人员并不需要每一个组件都涉猎极深，也不现实，掌握常见的架构思路和技巧以及一些基本的技术点，做到对一两个组件做到熟稔于心。思考和理解到位了，很容易触类旁通。</p><span id="OSC_h2_44"></span><h2>稳定性把控</h2><p style="color:#24292f; text-align:start">自研基础组件是一项浩大的工程，可以预见代码量会极为庞大，如何有效管理新项目的代码质量是个棘手的问题; 原有业务逻辑的改造也需要回归测试；现实的情况是中间件团队没有专职的测试，质量保证完全依赖开发人员；这就对开发人员的代码质量提出了极高的要求，一方面我们通过与老网关适配相同的代理引擎接口，降低迁移成本和业务逻辑出现 bug 的概率；另一方面还对编码质量提出了高标准，平均每周两到三次的 CodeReview；80% 的单元测试行覆盖率要求。</p><p style="color:#24292f; text-align:start">网关作为流量入口，承接全司最高流量，对稳定性的要求极为苛刻。最理想的状态是在业务服务没有任何感知的情况下，我们将新网关逐步替换上去；为此我们对新网关上线的过程做了充分的准备，严格控制上线过程；具体来看整个上线流程分为以下几个阶段：</p><p style="color:#24292f; text-align:start"><strong>第一阶段</strong></p><p style="color:#24292f; text-align:start">我们在压测环境长时间高负载压测，持续运行时间 24 小时以上，以检测内存泄漏等稳定性问题。同时利用性能检测工具抓取热点火焰图，做针对性优化。</p><p style="color:#24292f; text-align:start"><strong>第二阶段</strong></p><p style="color:#24292f; text-align:start">发布测试环境试跑，采用并行试跑的方式，新老网关同时对外提供服务（流量比例 1 ：1，初期新网关承接流量可能只有十分之一），一旦用户反馈的问题可能跟新网关有关，或者发现异常 case，立即关停新网关的流量。待查明原因并确认修复后，重新引流。</p><p style="color:#24292f; text-align:start"><strong>第三阶段</strong></p><p style="color:#24292f; text-align:start">上线预发，小得物环境试跑，由于这些环境流量不大，依然可以并行长时间试跑，发现问题解决问题。</p><p style="color:#24292f; text-align:start"><strong>第四阶段</strong></p><p style="color:#24292f; text-align:start">生产引流，单节点从万分之一比例开始灰度，逐步引流放大，每个阶段停留 24 小时以上，观察修正后再放大，循环此过程；基於单节点承担正常比例流量后，再次抓取火焰图，基于真实流量场景下的性能热点做针对性优化。</p><span id="OSC_h2_45"></span><h2>团队成长</h2><p style="color:#24292f; text-align:start">回顾整个研发历程我们在不间断新业务承接的情况下，几个月时间内完成开发和上线，从节奏上来讲不可谓不快，研发同学的心态也经历了一些变化。从一开始的质疑，认为大家以前从没有做过的东西现在就这点人能搞的出来吗？到中期的这个组件写起来蛮有挑战也很有意思！直到后期初版压测数据出来后的惊讶。就项目结果而言，可以说收获感满满，从后续的针对研发同学的 one one 沟通反馈来看，对于整个项目感触最大的是技术上的提升很大，对高并发网络编程领域的认知提升了一个档次, 尤其是异步编程方面，技术信心增强很多；内部也组织了分享会，大家普遍很感兴趣，收获了较大的技术红利。</p><p style="color:#24292f; text-align:start">*<strong>文/簌语</strong></p><p>本文属得物技术原创，更多精彩文章请看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com" target="_blank">得物技术官网</a></p><p>未经得物技术许可严禁转载，否则依法追究法律责任！</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/11033092</guid>
            <link>https://my.oschina.net/u/5783135/blog/11033092</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软投资「欧洲版 OpenAI」 Mistral]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软公司周一宣布与法国大模型创业公司&nbsp;Mistral AI 建立新的合作伙伴关系，后者有 「欧洲版 OpenAI」 之称。</p><p>微软在一份声明中表示将投资 20 亿欧元帮助 Mistral AI 开启「新的商业机会」，并向全球市场扩张，但没有提供进一步的财务细节。</p><p>根据协议，Mistral 宣布其最先进的大模型 Mistral Large 首次通过微软的云服务 Azure 提供——成为继 OpenAI 之后第二家在微软 Azure 云计算平台上提供商业语言模型的公司。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-24b13d1f5c37e4bc325eac6c3bbdf3ab204.png" referrerpolicy="no-referrer"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmistral-large%2F" target="_blank">https://mistral.ai/news/mistral-large/</a></em></u></p><p>微软还将帮助这家初创公司获得新客户，后者将推出其 ChatGpt 风格的多语言对话助手「Le Chat」（猫）。微软总裁布拉德·史密斯（Brad Smith）周一表示，这笔交易是该公司支持欧洲技术的「重要」信号。</p><p>与此同时，有人发现 Mistral AI 修改了其网站内容，删除了所有提及对开源社区义务的内容，所以有网友推测他们未来不太可能再发布任何开源模型。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c96c457e5fd400acfcd37ead7a44f8b1528.png" referrerpolicy="no-referrer"></p><p>一位 X 用户发帖称：「我不想说谎；我很遗憾 Mistral 没有开源他们的任何模型。我以为他们是 OSS 团队的。」另一位用户转发了微软 CEO 纳德拉宣布与 Mistral AI 合作的消息，并评论称：「这可能是原因。」马斯克则<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Felonmusk%2Fstatus%2F1762217391633952953" target="_blank">评论道</a>：「是微软让他们闭源的？」</p><p><img height="2051" src="https://oscimg.oschina.net/oscnet/up-6027c2509b672051b14eb678783045ad0e9.png" width="1287" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280426</guid>
            <link>https://www.oschina.net/news/280426</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中文 JDK21 API 网站上线，为 Java 开发者提供全新体验！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">Java Development Kit (JDK) 21 是 Java 平台的最新版本，为 Java 开发者提供了许多新特性和改进。为了更好地支持中文开发者，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在码官网</a>在此自豪地宣布推出最新的中文 JDK21 API 网站。</p><p>这个<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在码</a>网站将成为中文 Java 开发者的首选资源，提供以下内容：</p><ol><li>中文 Java 教程：提供系统的 Java 编程教程，从 Java 基础到高级特性，全面介绍 Java 编程的最佳实践。</li><li>JavaFX 教程：提供 JavaFX 编程的详细教程，介绍 JavaFX 的视图和控制器、图形和动画、媒体和图像等多个方面。</li><li>Orekit 教程：提供 Orekit 库的详细教程，介绍 Orekit 的轨道运动学和控制、姿态和姿态动力学、导航和定位等多个方面。</li><li>JDK21 API 文档：提供 JDK21 中所有类和方法的详细 API 文档，包括类描述、方法签名、参数和返回值等。</li><li>JDK21 工具的中文文档：提供 JDK21 中所有工具的中文文档，包括<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjava.cunzaima.cn%2Fjdk21%2Fdoc-zh%2Fspecs%2Fman%2Fjpackage.html" target="_blank">j</a>package、jwebserver、jlink、jmap 等。</li></ol><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">我们相信，这个新的中文 JDK21 API 将会成为中文 Java 开发者的不可或缺的工具，为他们提供更加便捷和高效的 Java 开发体验。欢迎访问<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn%2F" target="_blank">https://cunzaima.cn/</a>，并在评论区留下您的反馈和建议。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">感谢您的支持和关注！</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn%2F" target="_blank"><img height="100" src="https://oscimg.oschina.net/oscnet/up-3f77e9064178316e9c9acacd55ae6b89c0f.jpg" width="100" referrerpolicy="no-referrer"></a></p><p>网站内容截图：</p><p><img height="887" src="https://oscimg.oschina.net/oscnet/up-b439f6c336100368058aa097a0cc2cc8b44.png" width="1166" referrerpolicy="no-referrer"></p><p><img height="887" src="https://oscimg.oschina.net/oscnet/up-e5afd9a524f3a61fbd854899739c3a190fb.png" width="1166" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 14:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280393</guid>
            <link>https://www.oschina.net/news/280393</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ONLYOFFICE 文档获得达梦数据兼容认证：如何将数据库连接到编辑器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite.aspx" target="_blank">ONLYOFFICE 文档</a>获得了与达梦数据库的兼容证书。阅读本文，了解如何将数据库连接到 ONLYOFFICE 开源文档编辑器。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="ONLYOFFICE 文档获得达梦数据兼容认证：如何将数据库连接到编辑器" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/22105702/onlyoffice-and-dameng-db.png" referrerpolicy="no-referrer"></p><h2><strong>关于达</strong><strong>梦</strong><strong>数据</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">随着数字经济的快速发展，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.dameng.com%2F" target="_blank"><u>达梦</u></a>在数字化转型解决方案方面积累了丰富的经验，为客户提供各类数据库软件及集群软件、云计算与大数据等一系列产品及服务。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">目前的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.dameng.com%2Fview%2F16.html" target="_blank"><u>DM8</u></a><span>&nbsp;</span>是新一代大型通用关系数据库，完全支持 ANSI SQL 标准和主流编程语言接口/开发框架。该数据库拥有行列融合存储技术，兼容 OLAP 和 OLTP 系统，满足 HTAP 混合应用场景。</p><h2><strong>兼容性</strong><strong>认证</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 与武汉达蒙数据库股份有限公司一起通过了相互测试。因此，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocs-enterprise.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddameng" target="_blank"><u>ONLYOFFICE<span>&nbsp;</span></u><u>文档</u></a>被认证为与 DM8 兼容的稳定解决方案。</p><p style="text-align:center"><img alt="ONLYOFFICE Docs certified by Dameng: How to connect DB to the editors" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/22105811/dameng-certificate-714x1024.jpg" referrerpolicy="no-referrer"></p><h2><strong>如何将</strong><strong>达梦数据库</strong><strong>连接到 ONLYOFFICE 文档</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">本指南建议先在一个单独的分支里开发实现一个测试 bench：<code>feature/damengdb-compose</code></p><pre><code class="language-javascript"><span>BUILD=&lt;build-number-</span><strong>from</strong><span>-develop&gt; docker compose up -d</span></code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">使用 Docker 安装 ONLYOFFICE 文档时，可以指定可用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%3Ftab%3Dreadme-ov-file%23available-configuration-parameters" target="_blank"><u>变量</u></a><em>（DB_TYPE</em>、<em>DB_NAME</em>、<em>DB_HOST、DB_USER</em>、<em>DB_PWD、DB_PORT）</em><em>，</em>允许自定义数据库连接。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">要连接达梦数据库，需要将连接条件和参数添加到 ONLYOFFICE 文档（文件服务器）映像的初始化入口点脚本中。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%2Fpull%2F712%2Ffiles%23diff-8303d91c24ab115773c468f37319449463b1e1ff312b4e560d14a7c16a1e4b25R377" target="_blank"><u>添加新的数据库类型</u></a>：</p><pre><code class="language-javascript"><span style="color:#880000">"dameng"</span><span>)
</span><span>      DB_PORT=${</span><span>DB_PORT</span><span>:-</span><span style="color:#880000">"5236"</span><span>}
</span>      ;;</code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%2Fpull%2F712%2Ffiles%23diff-8303d91c24ab115773c468f37319449463b1e1ff312b4e560d14a7c16a1e4b25R423" target="_blank"><u>添加</u><u>远程数据库创建功能</u></a>：</p><pre><code class="language-javascript"><strong>create_dameng_tbl</strong><span>(</span><span>)</span><span> {
</span>  DM8_USER=SYSDBA
  DM8_PASS=SYSDBA001

<span>  (cd /opt/dmdbms/bin/ &amp;&amp; ./disql $DM8_USER/$DM8_PASS@$DB_HOST:$DB_PORT -e </span><span style="color:#880000">"create user "</span><span>onlyoffice</span><span style="color:#880000">" identified by "</span><span>onlyoffice</span><span style="color:#880000">" password_policy 0;"</span><span>)
</span>  # Create db on remote server
<span>  echo </span><span style="color:#880000">"EXIT"</span><span> | tee -a $APP_DIR/server/schema/dameng/createdb.sql
</span><span>  (cd /opt/dmdbms/bin/ &amp;&amp; ./disql $DM8_USER/$DM8_PASS@$DB_HOST:$DB_PORT \</span><span style="color:#880000">`$APP_DIR/server/schema/dameng/createdb.sql)
</span><span style="color:#880000">}</span></code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">将这些更改添加到入口脚本后，文档服务器就可以初始化与数据库的连接了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">创建一个简单的&nbsp;compose 文件，您可以在其中指定文档服务器所需的变量：</p><ul><li><strong>DB_TYPE：</strong>&nbsp;达梦数据库</li><li><strong>DB_HOST：</strong>compose 文件中数据库服务的名称（DNS 名称）</li><li><strong>DB_NAME：</strong>要使用的数据库的名称。应在容器启动时出现。</li><li><strong>DB_USER：</strong>用户名</li><li><strong>DB_PWD：</strong>用户密码</li><li><strong>DB_PORT：</strong>带数据库的服务端口</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">从<code>damengdb</code><span>&nbsp;</span>容器装入二进制目录，以便文件服务器容器可以访问<code>disql</code><span>&nbsp;</span>实用程序。请参阅<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%2Fpull%2F712%2Ffiles%23diff-bc48fb274f9199eed1a1a0dabb00738c2c5dd87ab1c85fdb1feb15d22c83f66b" target="_blank"><u>docker-compose.yml</u></a>以了解更多信息。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>运行<span>&nbsp;</span></strong><strong>stand</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">要启动这个 stand，请执行以下命令：</p><pre><code class="language-javascript"><span>git clone -b feature/damentdb-compose https:</span><span style="color:#888888">//github.com/ONLYOFFICE/Docker-DocumentServer.git</span><span></span>cd Docker-DocumentServer/tests/damengdb/
docker compose up –d</code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">注意：数据库映像可在&nbsp;hub.docker 上获得。为方便起见，我们上传了&nbsp;v8.1.2.128&nbsp;映像：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhub.docker.com%2Fr%2Fdanilaworker%2Fdamengdb" target="_blank"><u>点击此处查看</u></a>。</p><div><h3><strong>相关链接</strong></h3><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.dameng.com%2F" target="_blank"><u>达</u><u>梦官方网站</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fcertificates.aspx" target="_blank"><u>ONLYOFFICE 证书</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload-docs.aspx" target="_blank"><u>获取 ONLYOFFICE 文档</u></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 12:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280385</guid>
            <link>https://www.oschina.net/news/280385</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[鸿蒙程序员平均月薪超 1 万 8]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据智联招聘数据显示，春招鸿蒙岗位需求是去年近 3 倍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-47729617a06471ca213c42bdadb7fd974ad.png" referrerpolicy="no-referrer"></p><p>本月初，华为 HarmonyOS 在新年贺词中提到，基于开源鸿蒙开发的 HarmonyOS NEXT 鸿蒙星河版将在今年秋天正式和消费者见面，这也促使大量企业急需鸿蒙人才。</p><p>春节后开工第一周，鸿蒙相关职位数同比增长 163%，投递人数同比增长 349%，同时，鸿蒙开发岗的招聘薪资，达到 18191 元/月，比总体开发岗的平均薪资（16617 元/月）高出 9%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bb038ad20fec544a0619fbde6c5f4049059.png" referrerpolicy="no-referrer"></p><p>来自：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1656737654%2FO2miyxjc4" target="_blank">现代快报</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 10:49:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280369</guid>
            <link>https://www.oschina.net/news/280369</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云原生周刊：Docker 推出 Docker Build Cloud]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkube-vip%2Fkube-vip" target="_blank">Kube-Vip</a></h3><p>Kube-Vip 旨在为 Kubernetes 集群提供高可用性和负载均衡功能。它提供了一个可插拔的 VIP（虚拟 IP）管理器，可以为集群中的服务分配一个虚拟 IP 地址，并自动将流量路由到正确的节点。该项目提供了多种配置选项，可以根据需要选择适合的负载均衡算法和 IP 模式。Kube-Vip 还支持一些高级功能，如自定义健康检查和故障转移。通过使用 Kube-Vip，用户可以轻松地实现 Kubernetes 集群的高可用性和可靠性，提供稳定的服务和无缝的故障恢复能力。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fselefra%2Fselefra" target="_blank">Selefra</a></h3><p>Selefra 的意思是「从基础设施中选择*」。它是一款开源策略即代码软件，可为多云和 SaaS 环境提供分析，包括 AWS、GCP、Azure、阿里云、Kubernetes、Github、Cloudflare 和 Slack 等 30 多种服务。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmarvasgit%2Fkubernetes-statemonitor" target="_blank">KubeStateWatch</a></h3><p>KubeStateWatch 是 Kubernetes 的状态监视器，用于向多个通道发送通知，告知更改的时间和内容。</p><p>它可以独立使用，也可以部署在 Kubernetes 中。但它的主要目的是部署在 Kubernetes 中。</p><p>KubeStateWatch 是 kubewatch 的扩展和简化版本。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fweaveworks%2Ftf-controller" target="_blank">Weave GitOps' Terraform Controller</a></h3><p>Weave GitOps 的 Terraform 控制器（又名 Weave TF-Controller）是 Flux 的控制器，用于以 GitOps 方式协调 Terraform 资源。借助 Flux 与 Terraform 的强大功能，TF-controller 允许您按照自己的节奏在 Kubernetes 和 Terraform 领域中对基础设施和应用程序资源进行 GitOps 化。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40deepaksharma2494%2Funderstanding-kubernetes-and-docker-easiest-explanation-9505638107e3" target="_blank">了解 Docker 和 Kubernetes：一个简单的解释</a></h3><p>这篇文章以简单易懂的方式解释了 Kubernetes 和 Docker 的概念。文章首先介绍了 Docker 的作用，将应用程序和其依赖项打包成容器，实现跨平台的可移植性。然后，文章详细解释了 Kubernetes 的作用，它是一个容器编排和管理工具，用于自动化应用程序的部署、扩展和管理。文章强调了 Kubernetes 的重要性，它可以帮助解决容器化应用程序的挑战，如负载均衡、服务发现和自动容错。通过理解这两个概念，读者可以更好地了解如何使用 Docker 打包应用程序，并如何使用 Kubernetes 管理和运行这些容器化应用程序。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fovercast.blog%2Fzero-downtime-deployments-with-kubernetes-a-full-guide-71019397b924" target="_blank">使用 Kubernetes 进行零停机部署：完整指南</a></h3><p>这篇文章提供了关于使用 Kubernetes 实现零停机时间部署的全面指南。它介绍了零停机时间部署的基本原理和重要性，并详细解释了 Kubernetes 支持的各种部署策略，如滚动更新、蓝绿部署和金丝雀发布。文章还深入探讨了如何通过 Kubernetes 的服务和 Ingress 来优化流量管理，确保应用程序的高可用性和用户体验。此外，文章还介绍了一些高级的零停机时间技术，如特性标志和 A/B 测试，以进一步提升部署的弹性和可靠性。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoq.com%2Fnews%2F2024%2F02%2Fdocker-build-cloud%2F%3FtopicPageSponsorship%3Defb5f5b6-1e14-4b4f-8fdb-fd15c9d625f9" target="_blank">Docker 推出 Docker Build Cloud</a></h3><p>Docker 最近宣布了他们基于云的容器镜像构建工具 Docker Build Cloud 的正式推出。Docker Build Cloud 提供远程共享缓存和针对 AMD64 和 ARM64 CPU 架构的本地构建器，旨在"改善协作"并减少镜像构建时间。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloudnativenow.com%2Ffeatures%2Fcrossplane-maintainers-add-python-support-to-control-plane%2F" target="_blank">Crossplane 增加对 Python 的支持</a></h3><p>用于管理混合 IT 环境的开源 Crossplane 平台的维护者除了现有的 Go 支持之外，还增加了对 Python 编程语言的支持。</p><p>此外，除了现在将项目托管在 xpkg.upbound.io 上之外，命令行界面 (CLI) 还通过其他子命令进行了扩展，以简化 DevOps 工作流程，xpkg.upbound.io 是唯一符合开放容器计划 (OCI) 规范的注册中心了解 Crossplane 包的内部结构。</p><p>Crossplane 最初由 Upbound 开发，是 Kubernetes 控制平面的扩展，它使用复合资源定义 (XRD) 和 Kubernetes 自定义资源定义 (CRD) 将该控制平面的覆盖范围扩展到旧平台。该功能使得跨多个云和本地 IT 环境集中管理控制平面成为可能。随着 Crossplane 1.15 版本的发布，IT 团队现在还可以使用 Kubernetes 应用程序编程接口 (API) 服务器中的验证库根据其模式离线验证资源。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoq.com%2Fnews%2F2024%2F02%2Fgrab-kafka-kubernetes-aws-nth%2F%3FtopicPageSponsorship%3Defb5f5b6-1e14-4b4f-8fdb-fd15c9d625f9" target="_blank">Grab 改进 K8s 上的 Kafka 容错能力</a></h3><p>Grab 更新了 Kubernetes 上的 Kafka 设置，以提高容错能力，并完全消除 Kafka 代理意外终止时的人为干预。为了解决初始设计的缺点，团队集成了 AWS Node Termination Handler (NTH)，使用负载均衡器控制器进行目标组映射，并切换到 ELB 卷进行存储。</p><p>两年来，Grab 一直在生产环境中使用 Strimzi 在 Kubernetes ( EKS ) 上运行 Apache Kafka，作为其 Coban 实时数据平台的一部分。该团队之前利用 Strimzi（现在是 CNCF 孵化项目），通过将经过验证的身份验证、授权和机密性机制应用于所有服务器-服务器和客户端-服务器集成来增强 Kafka 集群安全性。</p><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 09:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/11044789</guid>
            <link>https://my.oschina.net/u/4197945/blog/11044789</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024 年 Apache DolphinScheduler RoadMap：引领开源调度系统的未来]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>非常欢迎大家来到 Apache DolphinScheduler 社区！随着开源技术在全球范围内的快速发展，社区的贡献者 <strong>「同仁」</strong> 一直致力于构建一个强大而活跃的开源调度系统社区，为用户提供高效、可靠的任务调度和工作流管理解决方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6e52878282cac3d28604d1cbd49899728c9.png" alt="file" referrerpolicy="no-referrer"></p><p>在过去的一段时间里，我们取得了一些重要的成就，但我们的愿景远未实现。为了更好地满足用户需求和推动项目的发展，我们在 2024 新春伊始，制定了以下 Roadmap，将在未来的版本中实现一系列激动人心的功能和改进。</p><h2>当前社区状态</h2><p>2024 年 roadmap 有两个来源，部分是来自 2023 年发起但是没有开始实施，或者实施了部分的议题，另一部分是最新新增的议题。2024 年 roadmap 可以分成如下几个部分</p><p><strong>云原生相关</strong>： 我们希望增加 K8S executor 复用 K8S 提供的能力做弹性资源管理、监控和失败重试等</p><p><strong>任务插件增强</strong>： 我们收到了用户关于任务插件的诉求，将会进一步支持 streaming 类型的任务、trigger 类型插件等，除此之外，我们还希望统一在 worker 和 master 中运行的任务、以及为任务插件增加生命周期的接口。于此同时我们会持续关注动态任务组件的功能，希望以后可以对任务组件单独发版保证迭代频率</p><p><strong>DataOps 相关</strong>：希望引入 data ops 相关功能，通过集成 git 供应商来实现 git ops，最终实现工作流 CICD&nbsp;</p><p><strong>测试</strong>： 我们会继续完善和增加项目单元测试覆盖率，并且逐步补充 API 部分的测试</p><p><strong>其他优化</strong>：引入工作流事件触发功能；优化审计日志</p><h3>云原生相关</h3><p>我们希望引入 K8S executor 作为 dispatcher 将 dolphinscheduler 的任务分发到 K8S 中，K8S executor 的好处是我们可以有更高的资源利用率；沿用 K8S 的监控机制，实现 pod level 的监控；沿用 pod 容错做任务容错。</p><p>这个设计的核心是将 executor 的抽象出来变成可配置的， 用户可以选择 K8S 或者非 K8S 的 executor，如果选择 K8S executor ，dolphinscheduler 会将任务提交到 K8S API server ，每个任务启动一个 worker，运行一个 pod。这一点的好处是 worker 不是一个长期运行的资源，而是仅当有任务的时候才需要启动。当业务低谷的时候，我们有空运行的 worker 来等待任务运行。</p><p>详情请看链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F13316" target="_blank">https://github.com/apache/dolphinscheduler/issues/13316</a></p><p><img src="https://oscimg.oschina.net/oscnet/up-bcabca103a55182159cc091dd62f7578835.png" alt="file" referrerpolicy="no-referrer"></p><h3>任务插件增强</h3><p><strong>streaming 任务类型增强</strong></p><p>2023 年 dolphinscheduler 社区增加了 streaming 任务类型的支持，但是是使用 shell 提交 flink 任务，一经推出收获了不少用户。当时实现的是一个简单版本，想看看用户反馈，开发者在开发过程，以及用户的使用中发现了部分可优化项。这部分优化项目我们希望能在 2024 年有部分进展，其中包括</p><ul><li>使用 flink sdk 去创建和提交任务，目前的 shell 方式提交不能很好的监控和处理运行中的任务，使用 sdk 可以有更多功能的支持，详情请看链接：&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F11440" target="_blank">https://github.com/apache/dolphinscheduler/issues/11440</a></li><li>支持 flink sql</li><li>增加 flink 的指标</li><li>增加 checkpoints savepoint 管理，保证任务失败重试等异常情况能继续执行</li></ul><p>详情请查看 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F11352" target="_blank">https://github.com/apache/dolphinscheduler/issues/11352</a></p><p><strong>动态任务组件 &amp; 任务单独发版</strong></p><p>这个任务是引入动态任务组件的概念，将任务组件的参数通过后端定义，然后在前端渲染，希望通过这样方法化简任务组件的开发流程，在参数的输入类型没有新增的情况下，可以不修改或者少修改前端代码而实现任务组件的新增和修改。</p><p>详情请看链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F12526" target="_blank">https://github.com/apache/dolphinscheduler/issues/12526</a></p><p>同时这个任务也是我们将任务插件单独发版的前置任务，任务插件单独发版也是非常重要的功能，实现了这个功能后，我们可以加快任务插件的发版频率，保证用户使用的是功能丰富、最新的任务插件。例如我们有一个新的任务插件 A ，这个插件在昨天被 merge 到 dev 分支，那么我们今天就能安排这个插件的发版。又例如我们发现了已经发版的任务插件 B 有比较严重的 bug，在，这个 bug 被 fix 后，我们就能安排插件的 bugfix 版本发版。</p><p>这个任务已经实现了已经简单的 demo，详情请看链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F12526" target="_blank">https://github.com/apache/dolphinscheduler/issues/12526</a></p><p><strong>任务插件生命周期管理</strong></p><p>为任务插件增加 close 方法从而更好的管理任务插件，特别是需要关闭资源的的任务组件，如数据库、云计算资源任务等。我们目前为任务插件定义了 init、handle、cancel 等方法，对于关闭资源的方法都是在任务中单独实现的，所以希望抽象一个 close 方法统一处理需要关闭资源的任务。</p><p>详情请看链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F14877" target="_blank">https://github.com/apache/dolphinscheduler/issues/14877</a></p><p><strong>统一 worker 和逻辑任务</strong></p><p>dolphinscheduler 现在有两个类型的任务 spi，分别是 worker 任务和逻辑任务，这两种任务类型分别是运行在 worker 上的，以及运行在 master 上的。不同的 spi 导致两种任务有不同的生命周期管理，并且不利于后面动态任务组件的实现，所以需要将两种任务尽可能弄成统一 spi。</p><p>详情请看链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F14823" target="_blank">https://github.com/apache/dolphinscheduler/issues/14823</a></p><h3>Git Ops</h3><p>dolphinscheduler 在处理生产和开发环境的时候，只能通过 json 导入导出来实现，社区部分伙伴建议我们可以使用 gitops 方法论来实现开发到生产环境的部署。GitOps 是一种基于版本控制系统的持续交付和基础设施管理的方法。它的核心理念是将整个系统的状态和配置存储在版本控制库中，通过 Git 的特性实现对系统的自动化管理和持续交付。</p><p><strong>gitops 支持</strong></p><p>希望将工作流相关资源的校验、工作流部署到生产环境的功能集成到 dolphinscheduler 中，集成之后只需要在 dolphinscheduler 配置 git 供应商的 url 和鉴权信息，就能在远程仓库中有新的 push 事件后，立马触发工作流的更新操作，从而保证生产中的工作流和远端 git 供应商的定义是一样的，实现客户的 cicd ，保证流程简单便捷</p><p><strong>测试</strong></p><p>测试对于开源软件至关重要，它不仅确保软件质量和稳定性，还提高了用户体验。通过全面的测试，可以及时发现和修复潜在的问题，增强软件的可靠性。测试也是保证新功能引入不破坏现有功能的关键，为开源项目的可持续发展提供了坚实的基础。dolphinscheduler 社区从 2023 年一直在努力提高测试覆盖度、并做了优化让贡献者更加方便的写测试，但是测试的增强是一个长期的工作，2024 年我们会坚持这部分内容</p><p><strong>API 测试</strong></p><p>在 api 层面的测试，确保我们核心的 api 接口能正常运行。当被 api 测试覆盖的接口，可以确保每次提交新代码时，API 接口逻辑和依赖关系都正确，不会破坏之前已有的功能。补充缺失的单元测试，确保接口与接口之间的连接性。dolphinscheduler 社区在 2023 年已经启动 api 测试的补充，目前部分核心接口已经覆盖，希望在 2024 年将尽可能多的 api 接口进行覆盖。</p><p>详情请看链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F10411" target="_blank">https://github.com/apache/dolphinscheduler/issues/10411</a></p><p><strong>UT 增强</strong></p><p>单元测试对比 API 测试是粒度更加小的，他能保证部分代码块如预期般工作，在此之前我们升级到了 junit5，并且增加了 worker 部分的测试覆盖率，与 api 测试一样的是，这是一个长期的工作，同时需要更多有激情的贡献者参与到该功能的建设中。</p><p>详情请看链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F10573" target="_blank">https://github.com/apache/dolphinscheduler/issues/10573</a></p><h3>其他优化</h3><p><strong>工作流 trigger 支持</strong></p><p>引入 trigger 插件实现事件触发，目前我们工作流的启动方式有两种，用户手动触发；定时触发。事件触发是希望增加其中的范围，让工作流可以被更多的事件触发。目前打算支持的事件包括</p><ul><li>定时触发： 目前已经有的触发方式</li><li>消息队列触发：通过消息监听消息队列的方式触发工作流</li><li>HTTP、TCP、SMTP 触发：通过监听 HTTP、TCP、SMTP 特定事件触发工作流</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-b839753a55a744119a2477182268d00ef2f.png" alt="file" referrerpolicy="no-referrer"></p><p>详情请看链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F15330" target="_blank">https://github.com/apache/dolphinscheduler/issues/15330</a></p><p><strong>审计日志增强</strong></p><p>Apache Dolphinscheduler 会在 2024 年增加更多的审计日志相关的功能，保证将用户对资源的操作能记录下来，这里的资源包括项目、工作流、任务、资源中心文件、udf、数据源等在 dolphinscheduler 中会被创建、修改、删除、更新的资源。</p><p>我们目前打算通过 AOP 的方式实现这个功能，<strong>实现了审计日志后</strong>，用户可以更好的查看资源创建情况，当出现意外情况时及时通过审计日志发现历史操作。</p><p>目前有一个 PR 初步实现了这个功能，详情请看链接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F15423" target="_blank">https://github.com/apache/dolphinscheduler/issues/15423</a></p><p>随着这份路线图的实施，Apache DolphinScheduler 社区将持续优化和扩展我们的调度系统，为用户提供更加强大、灵活和高效的解决方案。</p><p>我们相信，通过社区成员的共同努力和用户的积极反馈，Apache DolphinScheduler 将继续领跑开源调度和工作流管理领域，为企业和开发者带来更多的价值和可能性。让我们携手并进，共同见证 Apache DolphinScheduler 的蓬勃发展和创新旅程。</p><p>&nbsp;</p><blockquote><p>本文由 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.whaleops.com" target="_blank">白鲸开源科技</a> 提供发布支持！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 09:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/dailidong/blog/11044801</guid>
            <link>https://my.oschina.net/dailidong/blog/11044801</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[基于 Qt5 的 Windows 截图工具，可代替微信和搜狗截图]]>
            </title>
            <description>
                <![CDATA[<p><img src="https://gitee.com/tujiaw/ntscreenshot/raw/master/ntscreenshot_demo.png" alt="ntscreenshot" referrerpolicy="no-referrer"><img src="https://gitee.com/tujiaw/ntscreenshot/raw/master/ntscreenshot_demo2.png" alt="ntscreenshot" referrerpolicy="no-referrer"></p><p><a href="https://gitee.com/tujiaw/ntscreenshot/tree/master/release">已编译好的绿色包下载</a></p><h1><a id="user-content-ntscreenshot" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#ntscreenshot"></a>ntscreenshot</h1><p>Windows 截图工具，基本功能都实现了，陆陆续续也花了不少时间，<a href="https://gitee.com/tujiaw/ntscreenshot">源码地址</a>有兴趣的 Star 一下吧。</p><h1><a id="user-content-功能列表" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E5%8A%9F%E8%83%BD%E5%88%97%E8%A1%A8"></a>功能列表</h1><h2><a id="user-content-基本的截图功能" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%88%AA%E5%9B%BE%E5%8A%9F%E8%83%BD"></a>基本的截图功能</h2><ul><li>托盘菜单</li><li>全局快捷键设置，默认 F5 截图，F6 贴图</li><li>开机自启动设置</li><li>移动鼠标自动感知选区</li><li>放大器，放大当前鼠标所在像素点周围区域</li><li>显示选区大小，鼠标光标座标，光标所在位置像素的颜色</li><li>c 键复制当前颜色</li><li>移动鼠标选择选区</li><li>方向键进行像素级移动</li><li>截图背景透明度设置</li><li>保存截图到剪切板</li><li>保存截图到文件目录</li></ul><h2><a id="user-content-贴图" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E8%B4%B4%E5%9B%BE"></a>贴图</h2><ul><li>贴图管理</li><li>贴图边框</li></ul><h2><a id="user-content-标注" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E6%A0%87%E6%B3%A8"></a>标注</h2><ul><li>基本图形文字标注</li><li>支持改颜色，画笔、字体大小</li><li>支持马赛克</li><li>支持撤销</li></ul><h2><a id="user-content-上传图床" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E4%B8%8A%E4%BC%A0%E5%9B%BE%E5%BA%8A"></a>上传图床</h2><p>需要配置服务器</p><h2><a id="user-content-设置" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E8%AE%BE%E7%BD%AE"></a>设置</h2><p>托盘右键菜单打开设置窗口</p>]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 09:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/tujiaw/ntscreenshot</guid>
            <link>https://gitee.com/tujiaw/ntscreenshot</link>
        </item>
        <item>
            <title>
                <![CDATA[GitHub Copilot 会扩大代码的不安全性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>开发者安全公司 Snyk 发文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsnyk.io%2Fblog%2Fcopilot-amplifies-insecure-codebases-by-replicating-vulnerabilities%2F" target="_blank">指出</a>，GitHub Copilot 可以复制代码中现有的安全问题。即当用户现有的代码库存在安全问题时，GitHub Copilot 可能会基于此提供一些不安全的代码建议；「这意味着，项目中现有的安全债务会让使用 Copilot 的不安全开发变得更不安全。」</p><p>另一方面，如果代码库已经高度安全，则 Copilot 生成存在安全问题的代码的可能性就会较小，因为它可以利用的不安全代码上下文较少。这也极大地激励了人们投入时间来减少现有代码库中的漏洞，从而减少未来通过生成式 AI 编码助手引入的问题。</p><p>Snyk 表示， GitHub Copilot、Amazon CodeWhisperer 和 ChatGPT 等生成式 AI 编码助手在生产力和代码效率方面实现了重大飞跃。但这些工具不理解代码语义，因此无法对其进行判断。</p><p>GitHub Copilot 根据从大量现有代码存储库中学到的模式和结构生成代码片段。虽然这种方法有优点，但在安全方面也存在明显的缺点。Copilot 的代码建议可能会无意中复制邻接文件中存在的现有安全漏洞和不良做法，导致不安全的编码实践，并为一系列安全漏洞打开大门。</p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-af08dd68db7fed4ac1bc73918bf7af185e2.png" width="500" referrerpolicy="no-referrer"></p><p>为了减少 AI 助手生成的代码中重复出现现有的安全问题，Snyk 建议采取以下措施：</p><ul><li>开发人员应该对代码进行手动审查。</li><li>安全团队应该建立 SAST（security application security testing）护栏，包括策略。</li><li>开发人员应遵守安全编码指南。</li><li>安全团队应该为开发团队提供培训和意识，并对每个团队积压的问题进行优先级和分类。</li><li>执行团队应强制要求设置安全护栏。</li></ul><p>更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsnyk.io%2Fblog%2Fcopilot-amplifies-insecure-codebases-by-replicating-vulnerabilities%2F" target="_blank">查看官方博客</a>。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 08:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280334/github-copilot-amplifies-insecure-codebases</guid>
            <link>https://www.oschina.net/news/280334/github-copilot-amplifies-insecure-codebases</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周热点 | Warp 正式发布 Linux 版本；披着 Windows 11 外衣的 Ubuntu：能跑 exe 程序、支持 Android 应用.....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2024.02.19-2024.02.25]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 07:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094405&#38;idx=1&#38;sn=76fa95b2d568a613ee5903f8d3976d4a&#38;chksm=880c4216bf7bcb00d586ffe8ded38f9c3b4426ec5ddfc0f8617a965327c402a814e03533dd08&#38;token=1383836775&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094405&#38;idx=1&#38;sn=76fa95b2d568a613ee5903f8d3976d4a&#38;chksm=880c4216bf7bcb00d586ffe8ded38f9c3b4426ec5ddfc0f8617a965327c402a814e03533dd08&#38;token=1383836775&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[1024 分辨率下最快模型，字节跳动文生图开放模型 SDXL-Lightning 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-73d9ffe00a0d63e36ff98fa923e79b6bf92.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>文章来源｜字节跳动智能创作团队</p></blockquote><p>很高兴跟大家分享我们最新的文生图模型 —— SDXL-Lightning，它实现了前所未有的速度和质量，并且已经向社区开放。</p><p>模型：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FByteDance%2FSDXL-Lightning" target="_blank">https://huggingface.co/ByteDance/SDXL-Lightning</a></p><p>论文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.13929" target="_blank">https://arxiv.org/abs/2402.13929</a></p><p><img src="https://oscimg.oschina.net/oscnet/up-dbb8391e5301fe0818c07c5007701e0819d.png" alt="" referrerpolicy="no-referrer"></p><h2>闪电般的图像生成</h2><p>生成式 AI 正凭借其根据文本提示（text prompts）创造出惊艳图像乃至视频的能力，赢得全球的瞩目。然而，当前最先进的生成模型依赖于扩散过程（diffusion），这是一个将噪声逐步转化为图像样本的迭代过程。这个过程需要耗费巨大的计算资源并且速度较慢，在生成高质量图像样本的过程中，单张图像的处理时间约为 5 秒，其中通常需要多次（20 到 40 次）调用庞大的神经网络。这样的速度限制了有快速、实时生成需求的应用场景。如何在提升生成质量的同时加快速度，是当前研究的热点领域，也是我们工作的核心目标。</p><p>SDXL-Lightning 通过一种创新技术——<strong>渐进式对抗蒸馏（Progressive Adversarial Distillation）</strong>——突破了这一障碍，实现了前所未有的生成速度。该模型能够在短短 2 步或 4 步内生成极高质量和分辨率的图像，将计算成本和时间降低十倍。我们的方法甚至可以在 1 步内为超时敏感的应用生成图像，虽然可能会稍微牺牲一些质量。</p><p>除了速度优势，SDXL-Lightning 在图像质量上也有显著表现，并在评估中超越了以往的加速技术。在实现更高分辨率和更佳细节的同时保持良好的多样性和图文匹配度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6b51a9297b11683e92da115b696de953036.gif" alt="" referrerpolicy="no-referrer"> 速度对比示意</p><p>原始模型（20 步），我们的模型（2 步）</p><h2>模型效果</h2><p>我们的模型可以通过 1 步、2 步、4 步和 8 步来生成图像。推理步骤越多，图像质量越好。</p><p>以下是我们的 4 步生成结果： <img src="https://oscimg.oschina.net/oscnet/up-015feba9e22188c5c0903fb75dce3e8b13f.png" alt="" referrerpolicy="no-referrer"></p><p>以下是我们的 2 步生成结果： <img src="https://oscimg.oschina.net/oscnet/up-4943949b28735497159ae73bd6222f0c97a.png" alt="" referrerpolicy="no-referrer"></p><p>与以前的方法（Turbo 和 LCM）相比，我们的方法生成的图像在细节上有显著改进，并且更忠实于原始生成模型的风格和布局。</p><p><img src="https://oscimg.oschina.net/oscnet/up-99a60575458ab118c0706dcfb0fcd00f199.png" alt="" referrerpolicy="no-referrer"></p><h2>回馈社区，开放模型</h2><p>开源开放的浪潮已经成为推动人工智能迅猛发展的关键力量，字节跳动也自豪地成为这股浪潮的一部分。我们的模型基于目前最流行的文字生成图像开放模型 SDXL，该模型已经拥有一个繁荣的生态系统。现在，我们决定将 SDXL-Lightning 开放给全球的开发者、研究人员和创意从业者，以便他们能访问并运用这一模型，进一步推动整个行业的创新和协作。</p><p>在设计 SDXL-Lightning 时，我们就考虑到与开放模型社区的兼容。社区中已有众多艺术家和开发者创建了各种各样的风格化图像生成模型，例如卡通和动漫风格等。为了支持这些模型，我们提供 SDXL-Lightning 作为一个增速插件，它可以无缝地整合到这些多样风格的 SDXL 模型中，为各种不同模型加快图像生成的速度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9b1d4811ae28daa9f18b7dc72848ab191b5.png" alt="" referrerpolicy="no-referrer"> 我们的模型也可以和目前非常流行的控制插件 ControlNet 相结合，实现极速可控的图片生成。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9215316be3b78c2af2c84a7df0cc9760b1f.png" alt="" referrerpolicy="no-referrer"> 我们的模型也支持开源社区里目前最流行的生成软件 ComfyUI，模型可以被直接加载来使用： <img src="https://oscimg.oschina.net/oscnet/up-db434e5743cd4966699ba28133c7606abfe.png" alt="" referrerpolicy="no-referrer"></p><h2>关于技术细节</h2><p>从理论上来说，图像生成是一个由噪声到清晰图像的逐步转化过程。在这一过程中，神经网络学习在这个转化流（flow）中各个位置上的梯度。</p><p>生成图像的具体步骤是这样的：首先，我们在流的起点，随机采样一个噪声样本，接着用神经网络计算出梯度。根据当前位置上的梯度，我们对样本进行微小的调整，然后不断重复这一过程。每一次迭代，样本都会更接近最终的图像分布，直至获得一张清晰的图像。</p><p><img src="https://oscimg.oschina.net/oscnet/up-586c0cfa75fa7c3308fa9421e66f6bb352d.png" alt="" referrerpolicy="no-referrer"><em>图：生成流程</em><em>（</em><em>图片来自</em><em>：</em><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2011.13456" target="_blank">https://arxiv.org/abs/2011.13456</a></em><em>）</em></p><p>由于生成流复杂且非直线，生成过程必须一次只走一小步以减少梯度误差累积，所以需要神经网络的频繁计算，这就是计算量大的原因。</p><p><img src="https://oscimg.oschina.net/oscnet/up-13ed5521422c15757fe99d8e1c85130cdc0.png" alt="" referrerpolicy="no-referrer"><em>图：曲线流程</em><em>（</em><em>图片来自</em><em>：</em><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2210.05475" target="_blank">https://arxiv.org/abs/2210.05475</a></em><em>）</em></p><p>为了减少生成图像所需的步骤数量，许多研究致力于寻找解决方案。一些研究提出了能减少误差的采样方法，而其他研究则试图使生成流更加直线化。尽管这些方法有所进展，但它们仍然需要超过 10 个推理步骤来生成图像。</p><p>另一种方法是模型蒸馏，它能够在少于 10 个推理步骤的情况下生成高质量图像。不同于计算当前流位置下的梯度，模型蒸馏改变模型预测的目标，直接让其预测下一个更远的流位置。具体来说，我们训练一个学生网络直接预测老师网络完成了多步推理的后的结果。这样的策略可以大幅减少所需的推理步骤数量。通过反复应用这个过程，我们可以进一步降低推理步骤的数量。这种方法被先前的研究称之为渐进式蒸馏。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6d96b685339c4b2a6d8f5b95cf6be348912.png" alt="" referrerpolicy="no-referrer"><em>图：渐进式蒸馏</em><em>，学生网络预测老师网络多步后的结果</em></p><p>在实际操作中，学生网络往往难以精确预测未来的流位置。误差随着每一步的累积而放大，导致在少于 8 步推理的情况下，模型产生的图像开始变得模糊不清。</p><p>为了解决这个问题，我们的策略是不强求学生网络精确匹配教师网络的预测，而是让学生网络在概率分布上与教师网络保持一致。换言之，学生网络被训练来预测一个概率上可能的位置，即使这个位置并不完全准确，我们也不会对它进行惩罚。这个目标是通过对抗训练来实现的，引入了一个额外的判别网络来帮助实现学生网络和教师网络输出的分布匹配。</p><p>这是我们研究方法的简要概述。在我们的技术论文（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.13929" target="_blank">https://arxiv.org/abs/2402.13929</a>）中，我们提供了更深入的理论分析、训练策略以及模型的具体公式化细节。</p><h2>SDXL-Lightning 之外</h2><p>尽管本研究主要探讨了如何利用 SDXL-Lightning 技术进行图像生成，但我们所提出的渐进式对抗蒸馏方法的应用潜力不局限于静态图像的范畴。这一创新技术也可以被运用于快速且高质量生成视频、音频以及其他多模态内容。我们诚挚邀请您在 HuggingFace 平台上体验 SDXL-Lightning，并期待您宝贵的意见和反馈。</p><p>模型：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FByteDance%2FSDXL-Lightning" target="_blank">https://huggingface.co/ByteDance/SDXL-Lightning</a></p><p>论文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.13929" target="_blank">https://arxiv.org/abs/2402.13929</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 07:36:47 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6210722/blog/11044777</guid>
            <link>https://my.oschina.net/u/6210722/blog/11044777</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
