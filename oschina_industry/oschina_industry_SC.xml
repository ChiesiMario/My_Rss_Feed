<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 30 Jan 2024 17:58:06 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[爆了！Sealos 三天支持 1000 个帕鲁私服]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhzh.sealos.run%2F%3Fopenapp%3Dsystem-template%253FtemplateName%253Dpalworld%2526uid%3Dkc811077" target="_blank">Sealos 的帕鲁私服模板</a>从第一天发布之后就起了 100 多个私服，第二天直接上到 500 多个，第三天直接上千，还在加速增长中。来讲讲我们只用一个晚上怎么做到上线一个专属可用区的，还有一些帕鲁实践让我对云有的一些新的思考。</p><p><img src="https://oscimg.oschina.net/oscnet/up-490ea01e164188b5dfed8d0ca052a6ac442.jpg" alt="" referrerpolicy="no-referrer"></p><h2>Sealos 凭啥杀出一条血路</h2><p>这次各大云厂商都出了私服教程。</p><p>原因很简单，别的厂商都只是虚拟机上搭建的教程，有的甚至是长长的一篇文档，不过后来都搞一件部署了。</p><p>而 Sealos 直接做成了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsealos.run%2Fdocs%2Fguides%2Ftemplates%2F" target="_blank">应用模版</a>，<strong>点点鼠标，有手就会，对此菜市场大妈表示体验很好，边买菜都可以边部署起来</strong>。论速度我们吊打一切，只需要 30 秒起服，而其他我大部分测试了都要三分钟，原因很简单：<strong>我们抛弃了虚拟机</strong>。</p><p><strong>玩游戏的很多人并非开发者，或者没那么懂技术的，虚拟机，控制枱这些概念都不能让他们知道，就更别劝玩家去用了</strong>。Sealos 就是一个链接：</p><ul><li><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhzh.sealos.run%2F%3Fopenapp%3Dsystem-template%253FtemplateName%253Dpalworld%2526uid%3Dkc811077" target="_blank">https://hzh.sealos.run/?openapp=system-template%3FtemplateName%3Dpalworld%26uid=kc811077</a></strong></li></ul><p>看，有手就能部署，脑子都不用带。</p><p>我们的视频教程在 B 站获得了非常高的热度：</p><p><img src="https://oscimg.oschina.net/oscnet/up-e1ff512810d70062569e7e07974a64a1010.jpg" alt="" referrerpolicy="no-referrer"></p><p>视频传送门：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1Tw41177n3" target="_blank">【幻兽帕鲁】零门槛服务器搭建配置存档教程免费体验</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1Ab4y1P7Es" target="_blank">【幻兽帕鲁】最小白的服务器搭建教程 32 人低延迟免费体验</a></li></ul><p><strong>Sealos 还可以先体验后付钱，付费转化率夸张的高！</strong></p><p>相比较包年包月，Sealos 采用完全按量计费的方式，玩家睡觉时就可以关了，收一点点磁盘的费用。容器还有个好处就是内存炸了很快就可以自动重启，几乎不影响用户体验，而虚拟机重启下不得分钟级。</p><p>还有就是调配置，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsealos.run%2Fdocs%2Fguides%2Fapplaunchpad%2Fautoscale" target="_blank">Sealos 随便伸缩</a>，虚拟机包年包月伸缩就很尴尬。</p><p>最后是一些细节体验，比如导入存档，配置管理，死亡不掉落等等。</p><p>还有一个要点，就是运营的同学要去玩游戏，为什么？如果我们不玩我们就无法体会死亡不掉落的重要性，无法体会孵蛋时间是个啥，无法理解用户在什么时间点会上头，这直接决定需要赠送多少额度，需要提供什么样的配置，需要新增什么样的痛点特性。</p><h2>事情经过</h2><p>有两个朋友给我发了这个游戏的文章，瞬间我就找到了我们 「奇技淫巧奖」 获得者的米开朗基杨同学，当天就把模版做出来了，上架到了我们的两个集群。随后文章一发，瞬间集群资源就满了。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e8607737eb52990918b33443b1aae7332a4.jpg" alt="" referrerpolicy="no-referrer"></p><p>周四晚上我们立马决定建设一个新的专属可用区，这个可用区选择在阿里云上，原因很简单：需要快速扩容，而且以后可能热度下降要考虑释放问题。<strong>所以大家就不要随便黑公有云了，这是成本最低的打法</strong>，下文细讲。</p><p>我们一半人写代码，一半人买服务器起集群，把 Sealos 中玩家不需要的东西通通裁剪掉，应用市场也就只放一个模版，用 Laf 花了五分钟写一个游戏配置管理的程序并上线到 Sealos 上做默认应用。剩下的时间就在不断优化游戏的模版，包括缓存游戏的镜像让启动速度达到极致。</p><p>晚上就火爆了，不是在加服务器就是在加服务器的路上，我们每个节点可以跑 70 个私服。<strong>第二天团建，全员揹着电脑，几乎一半人在烧烤一半人在支撑。</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-a3be78a611bf5d875e6a6ac46c8b5a66546.jpg" alt="" referrerpolicy="no-referrer"></p><p>到目前为止单集群已经启动上千个。</p><h2>帕鲁事件对云的思考</h2><p>这个事只是一个影子，他映射出未来的云应该是什么样子。</p><h3>第一：应用是一等公民，忘掉云原生，忘掉容器，更要忘掉虚拟机</h3><p>你看安卓/iOS/Windows/macOS 以及各种 Linux 发行版，大部分用户用的是具体的应用，每个应用都有不同的用户画像，而很少有用户关心系统本身，更不会去关心内核。</p><p>把用户的最终需求直接给到用户才是云发展的终极目标，像帕鲁，<strong>用户需要的肯定不是容器，也不是虚拟机</strong>，那让用户进入到一个虚拟机的操作控制枱显然就违揹人性了。</p><p>当然会有很多开发者直接需要的就是虚拟机，那提供一个虚拟的应用也可以，核心逻辑解耦合，尽量不要让用户关心他需求以外的东西。随着应用的丰富，大众市场对更底层的需求就会越来越少，比如有了 RDS 之后，很多人要用数据库的人就不想去折腾虚拟机了，这里务必理解用户最终想要的是什么，直接给。</p><p>所以这必然会衍生出一种更合理的架构，其实这个架构已经有答案了，单机操作系统就是答案，有很好的标准，一堆人开发应用，另外一堆人使用应用，云为什么不这样？</p><p>今天的公有云很多都被框死在了控制枱，这样应用很难有自己的发挥空间，比如帕鲁的用户去登录公有云一通操作，VPC 快照对象存储几个标签就能把他看晕乎，这不是一种极致的产品体验。而手机上 LOL 游戏就不会外面套个微信的聊天框，不同的应用需要有自己不同的风格。markteplace 就更不用说了，缺乏标准，一锅大杂烩而已。</p><h3>第二：云是连接应用的生产者与使用者</h3><p>一旦云足够成熟的时候就会有非常好的灵活性，可以让大量开发者开发云上应用，使用者来使用，而今天云厂商大部分是厂商自己开发云产品，虽然也有第三方上架什么的，但是味道不对，怎么样算对，参考手机生态。</p><p>Docker Hub 就有点这个味道了，什么味道？标准的形成，很好的链接了镜像的制作者和使用者，但是提供的是零件，不是完整的分布式应用。</p><p>K8s 生态提供了很好的标准，是个非常优秀的云内核，一旦发行版盛行，此生态大成！那个时候很多人会忘掉 K8s，我可以给一个非常让人吃惊的数字，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsealos.run" target="_blank">Sealos</a> 云上的用户 80% 没接触过容器，20% 完全不是专业的开发者，他们就只想直接起应用。</p><p>所以先进的云需要给应用非常高的自由度，需要让用户用它的时候完全沉浸在应用本身的使用中，Sealos 就是这样，打开一个应用之后你就看不到 Sealos 的任何东西了，<strong>而目前云厂商都有个大大的 Header 和侧边栏</strong>，所以就出现了这种怪物：</p><p><img src="https://oscimg.oschina.net/oscnet/up-dff4b1c0b72679e2c0f1003dacad4c7f038.png" alt="" referrerpolicy="no-referrer"></p><p>我想写代码，可是嵌套一层又一层。</p><p>云 IDE 应当是一个独立的应用，可能是第三方提供，然后别人来使用。即便是官方自研也应当是这样的架构。</p><h3>第三：云是连接资源的提供者与消费者</h3><p>现在的云厂商基本硬件资源都是自己提供，而 Sealos 的做法比较有意思，未来我们的很多 Region 算力本身也可以由第三方提供，接入到我们平台中，真正成为一个算力平台，从算力视角连接双方。有点像直营和加盟的意思，或者京东和淘宝。若无云操作系统，这种想法也无法落地，而我们 24 年就会提供。</p><h3>第五：Sealos 公有云服务坚定选择云厂商，抛弃自托管硬件方向</h3><p>自建还是选择公有云确实要看场景，Sealos 云服务的业务未来只考虑用公有云。不要只看到价格的贵而忽略效率成本，还有很多其它隐性成本不可不查。</p><p>帕鲁这个场景毫无疑问首选公有云，快速扩容这一个需求就决定了没法在自己的机房跑。而且热点过去了是要缩回来了。</p><p>即便不是帕鲁这个场景，Sealos 还是坚定不移用公有云，我曾经一直在摇摆自建还是上云，我们本身就是做云的，绝对有托管硬件自建的能力，物理机的性能也更好，单纯计算算力价格也低太多。</p><p>但是，最终发现需要花好多倍成本就解决那剩下 10% 的问题，比如高可用要备份，你的备份程序和磁盘都需要额外成本，对应人力成本也来了，最要命的是响应速度，换块盘也需要时间，需要沟通成本等等。这些公有云上一个快照就都可以解决。</p><p>还有个恶心的备案问题，几乎只能人肉迁移备案，开白名单这些。而且机房的带宽费用并不便宜。</p><p>买多少硬件资源也是一个很费事的问题，预留不够上架可就慢了。</p><p>综合下来如果你把云的弹性用好，是可以节省大量成本的。特别有状态和无状态分开运行，夜间释放，根据不同的 SLA 等级划分可用区，举个例子，我们可以针对开发测试场景专门做一个对接竞价实例的集群，把所有无状态全部用竞价去跑。</p><p>使用公有云还可以让我们自己保持轻资产运营，天下武功唯快不破，迭代速度是创业公司最为追求的。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 11:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4148359/blog/10992796</guid>
            <link>https://my.oschina.net/u/4148359/blog/10992796</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeFuse 新开源模型荣登 Big Code 评测榜首！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="jahb.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1706606628857-bd1dbf7f-50d0-4b4e-a704-2f26ae5a3814.png?x-oss-process=image%2Fresize%2Cw_900%2Climit_0" width="900" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong><span>使用多任务高效微调框架 MFTCoder，以 DeepSeek-Coder-33b 模型为底座，微调获得的 CodeFuse-DeepSeek-33b 模型在</span></strong><strong><span style="color:#1f2937">Big<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Code</span></strong><strong><span style="color:#1f2937"><span>&nbsp;</span>Models<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Leaderboard</span></strong><strong><span>代码大模型榜单上以 43.58% WinRate 成为新晋榜首，同时模型在 NLP 任务上也取得了很好的表现。本文我们将介绍该模型的得来和使用，包括训练数据、训练超参设置、模型评测效果以及如何获取该模型和基于它继续微调。我们已经在 HuggingFace 和 ModelScope 开放了模型下载（下载地址在文末），并同步提供了 4bit 量化版本供大家直接部署到生产环境。</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1706581702847-565b14ab-7236-4bab-b74f-b8ce640e2eb9.png" width="1734" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>图 1: Big Code Models LeaderBoard 榜单截图（截取时间 2024-01-30）。</span></strong><strong><span style="color:#1f2937">Big<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Code</span></strong><strong><span style="color:#1f2937"><span>&nbsp;</span>Models<span>&nbsp;</span></span></strong><strong><span style="color:#e6b800">Leaderboard</span></strong><strong><span>（</span></strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fbigcode%2Fbigcode-models-leaderboard" target="_blank"><strong><span>https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard</span></strong></a><strong><span>）是由 HuggingFace BigCode 团队维护的代码大模型榜单，是代码大模型领域比较权威的评测榜单。</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_1"></span><h1><span>多任务微调 MFT</span></h1><p style="margin-left:0; margin-right:0"><span>我们选择以 DeepSeek-Coder-33b 模型为底座，使用多任务微调框架 MFTCoder 对 5 个下游任务数据进行微调，得到 CodeFuse-DeepSeek-33b 模型。以下将更为详细地进行介绍。</span></p><span id="OSC_h2_2"></span><h2><span>训练数据</span></h2><p style="margin-left:0; margin-right:0"><span>本次训练我们设置了 5 个下游任务，如下表 1 所示，包括代码补全任务、文本生成代码任务、单测生成任务、自然语言表述对齐任务和代码练习题任务，共约 168 万样本数据。得益于我们开源的多任务微调框架 MFTCoder，这些下游任务能一定程度上相互促进，比直接将所有任务数据混合为一后微调表现更优。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 1: 下游任务训练数据统计</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:700px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span><strong><span>序号</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span><strong><span>MFT 下游任务</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>任务能力</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span><strong><span>#Samples<span>&nbsp;</span></span></strong></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>1</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>单测用例生成</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>给定函数级代码生成单元测试用例</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>390,393</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>2</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>代码补全</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>根据前文补全代码（方法级）</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>192,547</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>3</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>文本生成代码</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>基于文本描述生成功能代码</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>66,862</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>4</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>NLP 表述对齐</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>增强 NLP 理解能力</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>951,278</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>5</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>代码练习题 (JAVA/CPP/GO)</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>基于文本描述生成基础功能代码</span></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span>82,603</span></span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px">&nbsp;</td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><strong><span>#Total</span></strong></span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span><span style="color:#000000">1,683,683</span></span></p></td></tr></tbody></table><span id="OSC_h2_3"></span><h2><span>关键超参设置</span></h2><p style="margin-left:0; margin-right:0"><span>本次微调使用的是我们已经开源的多任务微调框架 MFTCoder</span><strong><span>(</span></strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fmain%2Fmftcoder_accelerate" target="_blank"><strong><span>https://github.com/codefuse-ai/MFTCoder/tree/main/mftcoder_accelerate</span></strong></a><strong><span>)</span></strong><span>，MFTCoder 支持多模型适配（包括 Llama 1/2、CodeLlama、Qwen、Baichuan 2、ChatGLM 2/3、CodeGeex 2、GPT-NEOX、Mistral、DeepSeek 等）、多任务并行、多种均衡 Loss 设计、PEFT（Lora 和 QLora）高效微调，此前已被采纳为 Qwen Code AI 竞赛初赛推荐微调框架（</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftianchi.aliyun.com%2Fcompetition%2Fentrance%2F532169%2Finformation" target="_blank"><span>https://tianchi.aliyun.com/competition/entrance/532169/information</span></a><span>）。本次训练使用的关键超参设置如下表 2 所示，更多详细的参数说明可参考</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fmain%2Fmft_peft_hf%2332-loraqlora" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder/tree/main/mft_peft_hf#32-loraqlora</span></a></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 2： MFTCoder 微调关键超参设置及解释</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:734px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>参数名称</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>参数值</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><strong><span>简要解释</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>data_split</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>"98,2,0"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>98% 数据用于训练，2% 用于验证</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>padding_mode</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>"padding"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>使用动态填充模式，即每张卡每个 batch 大小是由每次其中的最长者动态决定而不是固定大小。另一种可选数据模式是"pack"。</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:48px"><p style="margin-left:0; margin-right:0"><span>dynamic_padding</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:48px"><p style="margin-left:0; margin-right:0"><span>True</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>weighted_loss_mode</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>"case3"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>使用数据均衡 Loss 函数，更多细节可见论文</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2311.02303" target="_blank"><span>https://arxiv.org/abs/2311.02303</span></a></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>peft_type</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>"qlora"</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>采取 QLora 4bit 量化微调模式</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>quantization</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>"4bit"</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>lora_rank</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>192</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>决定可训练参数比例</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>lora_alpha</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>32</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>per_device_train_batch_size</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>4</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>训练时单卡 batch 大小</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>per_device_eval_batch_size</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>4</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>验证时单卡 batch 大小</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>learning_rate</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>5e-5</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>初始学习率</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>min_lr</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>1e-6</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>最小学习率</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>gradient_accumulation_steps</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>1</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>梯度累积步数，如果为 2，则每累积 2 步再更新参数，资源不足是一种间接增加 global batch size 的方式</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>world_size</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>64</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>GPU 卡数，使用 64 张 A100/A100 卡</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>evalation_steps</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>500</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>每 500 步验证一次</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>checkpointing_steps</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>500</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>每 500 步保存一次检查点</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>num_train_epochs</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>10</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>最大训练轮数，最大 10 轮</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>early_stopping</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>True</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>开启 early-stopping 机制，即当连续 3 个检查点的 eval loss 均比倒数第 4 个检查点的 eval loss 大时终止训练</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>early_stopping_stall_num</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>3</span></p></td></tr></tbody></table><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>使用前述训练数据和配置，经过 156.5 小时，模型在完成 5.09 Epochs 训练后触发 Early-Stopping 策略后终止。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_4"></span><h1><span>模型效果</span></h1><p style="margin-left:0; margin-right:0"><span>我们从代码能力和 NLP 能力两个方面对训练获得的 CodeFuse-DeepSeek-33b 进行了测试，pass@1 测试均采用 greedy 解码模式（即</span><span style="background-color:#d8dad9">doSample=False, num_beams=1, num_return_sequences=1</span><span>）。</span></p><span id="OSC_h2_5"></span><h2><span>代码能力</span></h2><p style="margin-left:0; margin-right:0"><span>我们选取了常用的代码评测集对模型进行评测，首先我们使用自己的 CodeFuse-Evaluation 评测框架（</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-evaluation" target="_blank"><span>https://github.com/codefuse-ai/codefuse-evaluation</span></a><span>）对模型在 HumanEval-X（含 HumanEval）和 MBPP 测试集上的表现进行了测试并与 CodeFus 此前微调过的模型进行了比较，如下表 3 和表 4 所示。</span></p><p style="margin-left:0; margin-right:0"><strong><span>CodeFuse-DeepSeek-33b 在 HumanEval 上 pass@1 指标值为 78.65%、在 MBPP 上为 71%（zero-shot），两项平均为 74.83%，略高于 DeepSeek-Coder-Instruct-33B</span></strong><span>。</span></p><p style="margin-left:0; margin-right:0"><strong><span>CodeFuse-DeepSeek-33b 在多语言评测集 HumanEval-X 上 pass@1 指标值平均为 67.07%，比此前我们开放的 CodeFuse-CodeLlama-34b 模型高 6.69%，在具体各种语言上高出 3.48%~12.19% 不等</span></strong><span>。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 3: CodeFuse-DeepSeek-33b 模型与其他开源底座模型及微调模型在 HumanEval 和 MBPP 上的对比</span></strong></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1704200172671-e3b1411a-19eb-4305-878d-99f7f95945e5.png" width="636" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 4: CodeFuse-DeepSeek-33b 模型与其他开源底座模型及 MFT 微调模型在 HumanEval-X 上的对比</span></strong></p><p style="margin-left:0; margin-right:0; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1704200193212-a4061f95-d847-46d6-853b-2f0848c16050.png" width="719" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>由于不同评测框架在代码后处理和生成终止条件（Stop Words）等方面常存在差异，除了用我们自己的 CodeFuse-Evaluation 评测框架，我们也用代码大模型榜单 Big Code Models LeaderBoard 所用的开源评测框架 bigcode-evaluation-harness (</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbigcode-project%2Fbigcode-evaluation-harness" target="_blank"><span>https://github.com/bigcode-project/bigcode-evaluation-harness</span></a><span>) 进行了评测，并与榜单上的模型进行了比较。榜单会测试模型在 Python 代码补全测试集 HumenEval 和多语言代码补全测试集 MultiPL-E 共 12 种语言上的表现，并根据各语言表现进行 WinRate 排序。（结果复现代码地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftwelveand0%2Fbigcode-evaluation-harness" target="_blank"><span>https://github.com/twelveand0/bigcode-evaluation-harness</span></a><span>）</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 5： 采用 bigcode-evaluation-harness 评测 CodeFuse-DeepSeek-33b 模型后的新榜单</span></strong><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1706582301694-43665f48-da68-422d-ad5a-86454c8f627f.png" width="1400" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>如表 5 所示，</span><strong><span>CodeFuse-DeepSeek-33b 模型的 WinRate 为 43.58%，超过原榜首 DeepSeek-Coder-33b-instruct。在 HumanEval 评测集上，CodeFuse-DeepSeek-33b 表现不如 DeepSeek-Coder-33b-instruct，但在其他 8 种语言（包括 Java 和 JS 等）上超过后者，均值（Average Score）亦超过后者 1.7%</span></strong><span>。</span></p><span id="OSC_h2_6"></span><h2><span>NLP 通用能力</span></h2><p style="margin-left:0; margin-right:0"><span>对于 NLP 通用能力测试，我们参照 OpenCompass 选择了 18 个评测集，包括语言能力（AFQMC、CHID、Wic、WSC）、推理能力（COPA、CMNLI、OCNLI、Ax-b、Ax-g、RTE）、理解能力（CSL、C3、EPRSTMT）、学科综合能力（MMLU、C-Eval、ARC-c）、代码能力（HumanEval、MBPP）。对于每个模型，我们会使用生成式和 PPL 方式计算每个指标，并在每个维度上选取两种方式中较高的值作为指标值。</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/347737/1704260089384-cb664a24-5d58-4a7d-9081-a61159a469e3.png" width="1230" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>图 2: CodeFuse-DeepSeek-33b NLP 通用能力雷达图</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b 模型的评测结果如图 3 雷达图所示，我们将其与底座模型 DeepSeek-Coder-33b 和 DeepSeek 通用模型 DeepSeek-67b-Chat 进行了对比。</span><strong><span>从图中可以看出，相较于底座模型 DeepSeek-Coder-33b，CodeFuse-DeepSeek-33b 在所有维度上均有正向提升；相较于我们此前开源的 CodeFuse-CodeLlama-34b，CodeFuse-DeepSeek-33b 在绝大多数维度上表现更优；相较于通用模型 DeepSeek-67b-Chat，CodeFuse-DeepSeek-33b 在语言能力、代码能力和理解能力上整体表现更优，在推理能力上表现稍差，在学科综合能力上差距较大。考虑到模型参数规模差距和底座目标功能类型差异，我们认为 CodeFuse-DeepSeek-33b 已经表现很好。</span></strong></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_7"></span><h1><span>模型 INT4 量化</span></h1><p style="margin-left:0; margin-right:0"><span>为了便于直接部署投入生产，我们同步提供了 CodeFuse-DeepSeek-33b-INT4 量化版本。对于量化后的模型，我们测试了它的代码能力，如表 5 所示，量化后模型在代码补全任务上只有微弱降幅。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 5：模型量化前后在 HumanEval-X 和 MBPP 上的指标对比</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:749px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Model</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>HumanEval-X</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>MBPP</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Python</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Java</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>C++</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>JS</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Go</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>78.65%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>67.68%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>65.85%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>67.07%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>56.10%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0"><span>71.0%</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b-INT4</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>78.05%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>68.29%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>62.19%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>64.63%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>55.49%</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px">&nbsp;</td></tr></tbody></table><p style="margin-left:0; margin-right:0"><span>此外，我们测试了该模型实际部署后的性能。测试环境为单张 A10（24G 显存）、部署框架为 NVIDIA 开源的 tensorRT。测试结果具体如表 6 所示：</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>表 6: CodeFuse-DeepSeek-33b-INT4 在单张 A10 的推理性能</span></strong></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:640px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>模型版本</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>CodeFuse-DeepSeek-33b</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>推理速度指标</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>Tokens/s</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>模型并行/gpu 型号</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center">&nbsp;</p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>单卡 A10</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>量化格式</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center">&nbsp;</p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><span>int4 &nbsp;</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>输入/输出长度</span><br><span>(batch_size=1)</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>16/8</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:37px"><p style="margin-left:0; margin-right:0; text-align:center"><span>21.7</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:40px"><p style="margin-left:0; margin-right:0; text-align:center"><span>64/32</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:40px"><p style="margin-left:0; margin-right:0; text-align:center"><span>21.5</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:38px"><p style="margin-left:0; margin-right:0; text-align:center"><span>256/128</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:38px"><p style="margin-left:0; margin-right:0; text-align:center"><span>21.1</span></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:36px"><p style="margin-left:0; margin-right:0; text-align:center"><span>1024/512</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:36px"><p style="margin-left:0; margin-right:0; text-align:center"><span>20.5</span></p></td></tr></tbody></table><span id="OSC_h1_8"></span><h1>&nbsp;</h1><span id="OSC_h1_9"></span><h1><span>模型下载试用</span></h1><p style="margin-left:0; margin-right:0"><span>我们开放了量化前后 2 个模型的下载，提供了推理格式和推理示例，并说明了如何在此基础上继续微调。</span></p><span id="OSC_h2_10"></span><h2><span>下载</span></h2><p style="margin-left:0; margin-right:0"><span>我们已经将 2 个模型（CodeFuse-DeepSeek-33b 和 CodeFuse-DeepSeek-33b-INT4）发布到 HuggingFace 和 ModelScope 社区，大家可以选择通过以下链接下载：</span></p><table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #d9d9d9; table-layout:fixed; width:726px"><tbody><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>Model</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>HuggingFace</span></strong></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>ModelScope</span></strong></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B" target="_blank"><span>https://huggingface.co/codefuse-ai/CodeFuse-DeepSeek-33B</span></a></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B%2Fsummary" target="_blank"><span>https://modelscope.cn/models/codefuse-ai/CodeFuse-DeepSeek-33B/summary</span></a></p></td></tr><tr><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b-4bits</span></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B-4bits" target="_blank"><span>https://huggingface.co/codefuse-ai/CodeFuse-DeepSeek-33B-4bits</span></a></p></td><td style="border-color:#d9d9d9; border-style:solid; border-width:1px; height:33px"><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fcodefuse-ai%2FCodeFuse-DeepSeek-33B-4bits%2Fsummary" target="_blank"><span>https://modelscope.cn/models/codefuse-ai/CodeFuse-DeepSeek-33B-4bits/summary</span></a></p></td></tr></tbody></table><span id="OSC_h2_11"></span><h2><span>推理格式与代码</span></h2><p style="margin-left:0; margin-right:0"><span>CodeFuse-DeepSeek-33b 使用的推理格式如下：</span></p><pre><code>&lt;s&gt;system
{THIS IS YOUR SYSTEM PROMPT}
&lt;s&gt;human
{THIS IS YOUR PROMPT of ROUND 1}
&lt;s&gt;bot
{THIS IS MODEL's RESPONSE of ROUND 1}
&lt;s&gt;human
{THIS IS YOUR PROMPT of ROUND 2}
&lt;s&gt;bot</code></pre><p style="margin-left:0; margin-right:0"><span>在这个格式中，sysem 部分是可选的，对话轮数可以是多轮的也可以是单轮的。下面是一些具体的案例展示：</span></p><pre><code>&lt;s&gt;human
请写一个快排程序
#Python
&lt;s&gt;bot
</code></pre><pre><code>&lt;s&gt;system
你是 CodeFuse，你会被给定一个任务，你必须按照用户的要求完成任务。
&lt;s&gt;human
请写一个快排程序
#Python
&lt;s&gt;bot
下面是一个使用 Python 编写的快速排序算法的示例代码：
```python
def quick_sort(arr):
    if len(arr) &lt;= 1:
        return arr
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x &lt; pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x &gt; pivot]
    return quick_sort(left) + middle + quick_sort(right)
# 测试快速排序算法
arr = [3, 6, 8, 10, 1, 2, 1]
print(quick_sort(arr))
```
这段代码定义了一个`quick_sort`函数，它接受一个列表作为参数，并返回排序后的列表。在函数内部，首先判断列表的长度是否小于等于 1，如果是，则直接返回列表本身。否则，选择列表中间的元素作为基准值，并将列表分成三个部分：小于基准值的部分、等于基准值的部分和大于基准值的部分。然后，对这三个部分分别递归调用`quick_sort`函数进行排序，最后将排序后的三个部分合并并返回。
通过这个示例，你可以了解到如何使用 Python 编写快速排序算法，并对其进行测试。
&lt;s&gt;human
请为以上代码生成单测用例
&lt;s&gt;bot
</code></pre><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>下面是一段示例的推理代码：</span></p><pre><code>import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig

model_dir = "codefuse-ai/CodeFuse-DeepSeek-33B"

def load_model_tokenizer(model_path):
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    tokenizer.eos_token = "&lt;｜end▁of▁sentence｜&gt;"
    tokenizer.pad_token = "&lt;｜end▁of▁sentence｜&gt;"
    tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)
    tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)
    tokenizer.padding_side = "left"
    
    model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto',torch_dtype=torch.bfloat16, trust_remote_code=True)
    return model, tokenizer


HUMAN_ROLE_START_TAG = "&lt;s&gt;human\n"
BOT_ROLE_START_TAG = "&lt;s&gt;bot\n"

text_list = [f'{HUMAN_ROLE_START_TAG}Write a QuickSort program\n#Python\n{BOT_ROLE_START_TAG}']

model, tokenizer = load_model_tokenizer(model_dir)
inputs = tokenizer(text_list, return_tensors='pt', padding=True, add_special_tokens=False).to('cuda')
input_ids = inputs["input_ids"]
attention_mask = inputs["attention_mask"]
generation_config = GenerationConfig(
        eos_token_id=tokenizer.eos_token_id,
        pad_token_id=tokenizer.pad_token_id,
        temperature=0.1,
        max_new_tokens=512,
        num_return_sequences=1,
        num_beams=1,
        top_p=0.95,
        do_sample=False
)
outputs = model.generate(
        inputs= input_ids,
        attention_mask=attention_mask,
        **generation_config.to_dict()
)
gen_text = tokenizer.batch_decode(outputs[:, input_ids.shape[1]:], skip_special_tokens=True)
print(gen_text[0])</code></pre><span id="OSC_h2_12"></span><h2><span>继续微调</span></h2><p style="margin-left:0; margin-right:0"><span>如果你想在这两个模型基础上继续微调，欢迎使用我们开源的多任务高效微调框架 MFTCoder（</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fmain%2Fmftcoder_accelerate" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder/tree/main/mftcoder_accelerate</span></a><span>）。要继续微调，你需要准备好训练数据集（CodeFuse-ChatML 格式）、设置训练配置文件、设置运行配置文件并启动训练。这里提供一个对 Qwen-1.8 模型用 MFTCoder 进行微调的案例供参考：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder%2Ftree%2Fcodeqwen_competition%2Fmft_peft_hf" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder/tree/codeqwen_competition/mft_peft_hf</span></a><span>。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h1_13"></span><h1><span>联系我们</span></h1><p style="margin-left:0; margin-right:0"><span>MFTCoder 已经开源，本文中提到的模型和数据集也在陆续开源中，如果您喜欢我们的工作，欢迎试用、指正错误和贡献代码，可以的话请给我们的项目增加 Star 以支持我们。</span></p><ul><li><span>GitHub 项目主页：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder" target="_blank"><span>https://github.com/codefuse-ai/MFTCoder</span></a></li><li><span>HuggingFace 主页：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodefuse-ai" target="_blank"><span>https://huggingface.co/codefuse-ai</span></a></li><li><span>魔搭社区主页：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Forganization%2Fcodefuse-ai" target="_blank"><span>https://modelscope.cn/organization/codefuse-ai</span></a></li></ul></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 11:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/10992906</guid>
            <link>https://my.oschina.net/u/6942768/blog/10992906</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[重磅！AutoMQ 品牌全新升级]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年伊始，</p><p>AutoMQ 作为一家专业的消息队列和流存储软件服务供应商，</p><p>正式发布全新的 logo 和官网与大家见面！</p><p>一直以来，</p><p>我们致力于引领消息和流存储走向云原生时代！</p><p>希望通过这次品牌升级，</p><p>不断创新，为大家提供更先进的产品和服务！</p><p><strong>LOGO 升级</strong></p><p><img alt="" src="https://image.automq.com/%E5%AE%98%E7%BD%91/20231214-171408.png" referrerpolicy="no-referrer"></p><p>新 logo 以"M"字母为核心设计元素，融合"A"字母，不仅象征着 AutoMQ 的名字，更代表了我们对核心业务和理念的坚持。AutoMQ 正是以云原生技术理念，对消息队列和流存储领域进行深刻创新，致力于通过自动伸缩、自动运维和自动优化的技术，为客户兑现云的普惠价值。</p><p>我们的品牌形象以流畅的线条和波浪效果为特征，象征着 AutoMQ 助力企业驾驭规模日益庞大的数据流，确保数据传输的高效和稳定。在视觉上，全新品牌选择了充满未来感的科技紫作为主题色彩，它不仅代表了我们追求技术卓越的决心，也反映了我们以产品为驱动，不断前行的发展理念。</p><p><strong>官网升级</strong></p><p><img alt="" src="https://image.automq.com/%E5%AE%98%E7%BD%91/%E5%AE%98%E7%BD%91%E6%88%AA%E5%9B%BE.jpeg" referrerpolicy="no-referrer"></p><p>新官网链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.automq.com" target="_blank">https://www.automq.com</a></p><p>新官网坚持技术开发者友好的设计理念，以可量化的数字结论，从<strong>成本、稳定性、弹性和兼容性</strong>等方面阐述了 AutoMQ 带来的技术优势和客户价值。<br> 新官网全新设计了<strong>博客、文档中心、产品、定价详情页面</strong>，帮助开发者快速了解 AutoMQ 的产品功能和参考资料。<br> 最后，值得一提的是官网的构建过程也使用了 Webflow 低代码设计开发平台。整个开发过程无需前端工程师介入，由设计师直接完成设计上线，并且可以做到随时快速迭代。</p><p>欢迎关注我们，学习更多技术干货！同时，也诚邀各位开源爱好者持续关注我们社区，点亮小星星🌟，跟我们一起构建云原生消息中间件！</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 07:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276906</guid>
            <link>https://www.oschina.net/news/276906</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Wok-Server —— 轻量级 Nodejs 后端框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:left">Wok-Server 是一个简洁易用的 Nodejs 后端框架，使用 Typescript 开发，有完整的类型约束和定义，注释详细，文档齐全，支持国际化。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">主要功能：配置，日志，国际化，校验，缓存，MVC，mysql，mongodb ，周期任务 。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><a href="https://gitee.com/tai/wok-server/blob/master/documentation/zh-cn/index.md">查看文档</a></p><h2 style="margin-left:0; margin-right:0; text-align:left">优点</h2><ul><li>学习成本较低，函数式为主，少量面向对象，未使用代理和装饰器等增强技术</li><li>功能简单，使用方便，保持克制，不引入太多特性</li><li>轻量封装，最大限度兼容已有生态，支持集成第三方 http 相关的库来处理请求</li><li>支持国际化，自带多种语言的支持，国际化内容支持扩展</li><li>有完整的类型约束和定义，结合 IDE 的代码补全功能，开发效率高</li><li>注释详细，文档就在代码中，方法和参数都有详细说明，可在 IDE 的辅助下方便查看</li></ul><h2 style="margin-left:0; margin-right:0; text-align:left">Hello world</h2><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">安装：</p><div style="text-align:left"><div><pre><span>npm i wok-server --save</span></pre><div style="text-align:center">&nbsp;</div></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">入口文件：</p><div style="text-align:left"><div><pre><span><strong style="color:#000000">import</strong><span>{</span><span>startWebServer</span><span>}</span><strong style="color:#000000">from</strong><span>'</span><span style="color:#dd1144">wok-server</span><span>'</span></span><span><span>startWebServer</span><span>({</span></span><span><span style="color:#008080">routers</span><span>:</span><span>{</span></span><span><span>'</span><span style="color:#dd1144">/</span><span>'</span><span>:</span><strong style="color:#000000">async</strong><span>exchange</span><span>=&gt;</span><span>exchange</span><span>.</span><span>respondText</span><span>(</span><span>'</span><span style="color:#dd1144">Hello world !</span><span>'</span><span>)</span></span><span><span>}</span></span><span><span>}).</span><strong style="color:#000000">catch</strong><span>(</span><span>e</span><span>=&gt;</span><span>{</span></span><span><span>console</span><span>.</span><span>error</span><span>(</span><span>'</span><span style="color:#dd1144">Start server failed</span><span>'</span><span>,</span><span>e</span><span>)</span></span><span><span>})</span></span></pre><div style="text-align:center">&nbsp;</div></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">上面的代码启动了 web 服务，访问路径<span>&nbsp;</span><code>http://localhost:8080</code><span>&nbsp;</span>将输出文本 「Hello world !」。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">相关的设置可以通过环境变量来修改，查看<a href="https://gitee.com/tai/wok-server/blob/master/documentation/zh-cn/index.md">完整文档</a>了解细节。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 06:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/wok-server</guid>
            <link>https://www.oschina.net/p/wok-server</link>
        </item>
        <item>
            <title>
                <![CDATA[Jina AI 开源中英和英德双语 8K 向量模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在 Jina Embeddings 英语向量模型突破百万下载后，Jina AI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FT-2EB1LfZKhueidIGW1x0w" target="_blank">宣布</a>又正式开源了两款双语向量模型：中英双语（Chinese-English）和英德双语（English-German）向量模型，这也是全球首次推出支持 8K 双语文本的开源向量模型。</span></p><h4><span style="color:#000000"><strong>技术亮点</strong></span></h4><p><span style="color:#000000"><strong>8K 输入：长文本处理更得心应手</strong></span></p><p><span style="color:#000000">在 RAG 应用里，文本就像被切成了多个块，通过 Embedding 模型变成向量，然后存进数据库。当你搜索时，系统会把这些文本块的向量和你的搜索词比对，找到最匹配的文本。</span></p><p><span style="color:#000000">传统模型最多只能处理 512 Token 的文本，面对更长文本时，就力不从心，尤其是预测的时候。</span></p><p><span style="color:#000000">但 Jina Embeddings v2 能处理高达 8k 的输入，能够实现从实体、句子、段落到整个篇章的多粒度向量表示。实际应用的时候，可以将这些不同层次的向量结合起来，实现更为精准的匹配。此外，也支持按语义切割，获得更佳的搜索效果。</span></p><blockquote><p><span style="color:#000000">8K token，也就是说一整版人民日报的内容可以压缩成一个向量！</span></p></blockquote><p><span style="color:#000000"><strong>技术创新：JinaBert 架构</strong></span></p><p><span style="color:#000000">Jina Embeddings 系列模型均基于 Jina AI 自研的 JinaBert 架构，这是首次将 ALiBi 应用到编码器上，该架构专为长文本任务优化，直接在 Attention 层处理位置信息，让模型更准确地捕捉词语间的关系。就算是超长文本，也能轻松应对。</span></p><p><span style="color:#000000">这一技术创新让模型在处理长文本时更加强大，也为 RAG 应用带来了更多可能性。无论是解读法律文件、研究医学文献、还是文学分析，Jina Embeddings 系列模型都表现出色，任务的准确率和效率都大大提升。</span></p><p><span style="color:#000000"><strong>双语支持：无缝跨语言交互</strong></span></p><p><span style="color:#000000">双语模型能把中文（或德文）和英文映射到同一个向量空间。即使是不同语言，只要含义相近，它们在向量空间里就很接近。</span></p><p><span style="color:#000000">尽管很多模型也声称支持多种语言，但由于英语在互联网上的主导地位，以及训练阶段大量使用机器翻译文本，这些模型往往对某些人群、主题或话题存在偏见，其影响会在下游任务中进一步放大。Jina AI 则专注于优化 2 种语言的向量表征，严格把关训练数据，力求把偏见降到最低，并确保性能超越那些支持多语言的大型模型。</span></p><p><span style="color:#000000">用 Jina Embeddings，不管是在 RAG 聊天机器人里，还是给文本分类、做摘要、分析情感，都能把不同语言的文本当作同一种语言来处理，让多语言应用的构建变得无比丝滑。用中文搜中文资料，或者中文搜英文、英文搜中文，都能得到又准又顺的结果。Jina Embeddings 助力您打造和全球用户无障碍沟通的新时代！</span></p><p><span style="color:#000000"><strong>MTEB 排行榜：性能领先</strong></span></p><p><span style="color:#000000">Jina Embeddings v2 系列模型在 MTEB 排行榜上，在文本分类、检索、重排、摘要等任务上均有优势。并且输出和 OpenAI 完全一致，是 OpenAI ada 002 模型的理想替代开源解决方案。</span></p><p><span style="color:#000000">jina-embeddings-v2 的双语模型以 322MB 的轻巧体积（包含 1.61 亿参数），输出维度为 768，能够在普通计算机硬件上高效运行，无需依赖 GPU，极大地提升了其实用性和便捷性。</span></p><p><span style="color:#000000">最近，在 Standford HAI 发布的 LoCo 性能测试中，Jina Embeddings 同样名列前茅。</span></p><p><img height="221" src="https://oscimg.oschina.net/oscnet/up-5db7acf49ccda5e5a0aba0d4098ee18b6b6.png" width="500" referrerpolicy="no-referrer"></p><p><img height="135" src="https://oscimg.oschina.net/oscnet/up-789c9393a0fb12fa9b322e8af83f1b0e6c0.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000"><span style="background-color:#ffffff">Jina</span> AI 方面表示，未来将持续扩展多语言 8k 向量模型家族，支持更多语言。</span></p><ul><li><span style="color:#000000">中英双语向量模型：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fjinaai%2Fchinese-english-embeddings" target="_blank">https://huggingface.co/jinaai/chinese-english-embeddings</a></li><li><span style="color:#000000">英德双语向量模型：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fjinaai%2Fenglish-german-embeddings" target="_blank">https://huggingface.co/jinaai/english-german-embeddings</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276902</guid>
            <link>https://www.oschina.net/news/276902</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Milk-V Vega: 全球首款 RISC-V 万兆开源交换机正式发售]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>MilkV 于去年 8 月亮相了「全球首款开源万兆 RISC-V 网络交换机 Milk-V Vega」。时隔数月，该产品现已上架官方淘宝店开售，定价 799 元。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dc8f8d1b6ca91d1342e4484e8e267513a9c.jpg" referrerpolicy="no-referrer"></p><p>据介绍，Milk-V Vega 是 Milk-V 面向新一代网络架构开发的一款小体积、高密度盒式开源万兆网络交换机，为用户提供宽带、语音、视频、监控等多业务统一承载平台，多网融合覆盖全业务；搭载国产 RISC-V 高可靠网络交换芯片，帮助企业与用户大幅简化网络架构，降低能耗成本与运维成本；可广泛应用于数据中心、园区、大中型企业网络、酒店、科研教学等场景。 &nbsp;</p><p>Milk-V Vega 支持完备的二层网络协议处理功能，包括 L2 桥接，L2 组播和风暴抑制等；支持基于流、端口、协议、子网的 VLAN 功能；支持 STP，RSTP 和 QinQ 功能；支持防 DOS 攻击，黑白名单和协议包滤除功能；支持滤镜，链路聚合，OAM 报文发送和端口保护功能；支持入口及出口的 ACL 功能，还支持同步以太网，1588 功能。</p><p>同时 Milk-V Vega 作为全球首款 RISC-V 开源万兆交换机，为开发者提供了以下特性：</p><ul><li>基于开源 Linux 系统，方便二次开发及 DIY</li><li>开放 openSBI，u-boot，Linux kernel 源码，提供交叉编译工具链</li><li>提供 JTAG 接口，方便底层开发</li><li>提供 RS232 及 I2C 接口，方便外接其他传感器</li><li>支持 1U 标准机柜，每一层机柜可安装 2 台 Milk-V Vega</li><li>双万兆光口 + 4 千兆光口 + 8 千兆电口，满足家用 Homelab 需求</li><li>支持远程配置，提供 WEB 和 SSH 访问</li><li>提供命令行业务配置，实现 VLAN 配置，端口镜像，MAC 地址学习，流量控制等功能</li><li>提供接口 SDK 和 API，灵活实现业务配置</li></ul><p><img height="1922" src="https://oscimg.oschina.net/oscnet/up-18941523fbbd18a8e49875ecd1672e1a1a8.jpg" width="1080" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-553d000aeabc9e13f63432542706d102e13.jpg" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c56ea9be1224ad7658d518aedd13b7c0dea.jpg" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-dd5e9f39bbba69c1b283082faf3484443da.jpg" referrerpolicy="no-referrer"></p><p><strong><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsFzKJKkRKq3q9DYPtpm2_Q" target="_blank">https://mp.weixin.qq.com/s/sFzKJKkRKq3q9DYPtpm2_Q</a></u></em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 06:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276901</guid>
            <link>https://www.oschina.net/news/276901</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[npm 被滥用 —— 有人上传了 700 多个武林外传切片视频]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Sonatype 安全研究团队近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.sonatype.com%2Fnpm-flooded-with-748-packages-that-store-movies" target="_blank">介绍</a></u>了一起滥用 npm 的案例——他们发现托管在 npm 的 748 个软件包实际上是视频文件。</p><p>据介绍，这些软件包每个大小约为 54.5MB，包名以 「wlwz」 作为前缀，并附带了应该是代表日期的数字。时间戳显示，这些包至少自 2023 年 12 月 4 日起就一直存在于 npm，但 GitHub 上周已经开始删除。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4206ec7f1e46a5d3841a266e37293bd8f7b.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bccdf9a35b4ae1bd8a8920c57f87e5ceeb7.png" referrerpolicy="no-referrer"></p><p>每个包中都有以「.ts」扩展名结尾的视频剪辑，这表明这些视频剪辑是从 DVD 和蓝光光盘中翻录的。</p><blockquote><p>这里的 ts 不是 TypeScript 文件，而是 transport stream 的缩写，全称为 「MPEG2-TS」：</p><p>MPEG2-TS 传输流（MPEG-2 Transport Stream；又称 MPEG-TS、MTS、TS）是一种标准数字封装格式,用来传输和存储视频、音频与频道、节目信息，应用于数字电视广播系统，如 DVB、ATSC、ISDB[3]:118、IPTV 等。</p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dd32d5c3ad016f5c5ba20f9ec67e9f04a3f.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-85ee088f5f36f3c27c4bb43e72b3c6271ec.png" referrerpolicy="no-referrer"></p><p>此外，某些包（例如「wlwz-2312」）在 JSON 文件中包含普通话字幕。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-37361519bbcf2b7a95d47a0a2451c0e42aa.png" referrerpolicy="no-referrer"></p><p>虽然这些视频不会像挖矿程序、垃圾邮件包和依赖性恶意软件那样毒害社区，但这种把开源基础设施当 CDN 的操作无疑是破坏了规则，也违反了供应商的服务条款，各位耗子尾汁吧。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 03:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276893/npm-flooded-with-748-packages-wlwz</guid>
            <link>https://www.oschina.net/news/276893/npm-flooded-with-748-packages-wlwz</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源小谈，赠现代卧龙、凤雏；创造三赢的方案！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3><span>前言</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 </span><span><a href="https://www.oschina.net/comment/news/276508"><span>ioGame17 文档或将强制收费</span></a></span><span>文中引起了一些讨论，这些讨论更多的是理念上的分歧。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>文中内容简要如下</span></p><blockquote><p style="margin-left:.8em; margin-right:0"><span>近期 ioGame 将要升级到 21 版本，提醒开发者保存好 ioGame17 的文档。</span></p><p style="margin-left:.8em; margin-right:.8em">&nbsp;</p><p style="margin-left:0; margin-right:.8em"><span>开发者如果不打算升级到 ioGame21 的，请提前私下保存好 ioGame17 相关文档。ioGame21 发布后，在线文档的内容则与新版本对应。而旧的文档（ioGame17）将从自愿付费模式转为强制付费文档。如果不打算支付这部分文档费用，请私下保存一份自留使用，但不得以任何形式传播及公开。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>整体内容并不多，意外的是在讨论区中惊现各种现代化的卧龙、凤雏、五星评论员、如果哥、指点江山哥、慷他人之慨...等，之流。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>由于精力有限，将不对之前的文档、旧的版本进行维护。旧的文档如有需要，可付费获取；如不想付费，请私下保存一份自留使用，但不得以任何形式传播及公开。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>之所以不提供旧文档的阅读及旧版本的维护，是因为 ioGame 开源作者将精力放到了最新的 ioGame 版本上，并提供了与之对应版本的在线文档阅读（不需要登录，没有辣眼的广告，可阅读所有文档）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>但似乎现代化的卧龙、凤雏、五星评论员、如果哥、指点江山哥、慷他人之慨...等，之流，想让开源作者继续免费提供旧文档，并无条件的维护旧版本。（不知道让 spring 团队维护 1.x 版本的，会得到什么样的回复）</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 开源作者在阅读 </span><span><a href="https://www.oschina.net/comment/news/276508"><span>ioGame17 文档或将强制收费</span></a></span><span>讨论区相关的内容后，找到了能够完美的解决这些矛盾的三赢方案。本篇内容不多，大体如下</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>理念冲突（不同）</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>可持续性发展</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>当前开源环境</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>开源策略</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>用户流失？不，这是三赢！</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>比较优势</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>理念不同</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><img height="398" src="https://oscimg.oschina.net/oscnet/up-336b076ff70f355b497e0040cf1b8a333cb.png" width="700" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>当今，在制度理念上可大致分为两种，GC 主义和资本主义。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 源码使用的是 AGPL 协议，之所以选择该协议是因为，就目前来说其更符合 GC 主义；GC 主义的经济制度类型为</span><span><strong><span>生产资料公有制</span></strong></span><span>，而资本主义则是</span><span><strong><span>生产资料私有制</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；同时，ioGame 是允许私有的，前提是支付闭源授权费。所以，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。</span></p><blockquote><p style="margin-left:0; margin-right:0"><span>ioGame 使用的开源策略是：两开一免一自主。即源码完全开放、最新文档阅读完全开放、使用完全免费、开发者可自主选择按需付费。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>为什么需要闭源授权费</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，这里仅指闭源授权，也就是你的产品不需要对外开源（可将生产资料私有制）；除此之外，并不会提供更多的其他服务。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>之所以需要授权费，是因为我们为产品附加了价值。《资本论》中著名的公式：商品价值 = c+v+m，即商品价值 = 不变资本+可变资本+剩余价值。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>c+v+m 可以表示社会总产值，也可以表示某个商品的价值，或某一单位时间内生产的商品的总价值。简单的说 c 表示的是生产资料价值，v 表示的是劳动力的价值，m 表示的是剩余价值</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>为了易懂，这里举个不恰当，但意思差不多的公式。商品价值 = 你为产品迭代的劳动力 + 你的日常开销（自身教育及小孩教育的支出、维持动者本人及家属生存所必需的生活资料、房租房贷...等）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在，关于闭源授权费这部分也说清楚了；之所以有闭源授权费，是因为我们为产品附加了价值。这里再重复一次，使用 ioGame 是免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；同时，ioGame 是允许私有的，前提是支付闭源授权费。所以，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>资本主义理念的小算盘是，即希望免费使用你的产品，又希望你免费维护，同时又不想将自身的产品成果公开出来（只想生产资料私有制）。换句话说就是，又想马儿跑，又不给马吃草，因为这一行为很符合资本主义。这里称其为</span><span><strong><span>自以为聪明的资本家</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>自以为聪明的资本家</span></strong></span><span>的基本特征是：你这产品不错、你这框架不错、你这项目不错，应该免费；同时，这群家伙还擅长慷他人之慨，真让他们参与付出时，结局是</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一头牛</span></a></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>可持续性发展</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>经济基础是一切可持续性发展的前提，开源亦是如此。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>如大家所熟悉的 apache 组织、srping 等...各开源巨头，都是有基金会或其他经济支持的；也有一些半开源的产品会寻求一些资本的注入，其目的也是为了得到经济支持。所以，经济基础是一切可持续发展的前提。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>大部分开发者认为开源软件是完全免费的，也应当完全免费。造成这些错觉是因为常年使用开源巨头所提供的软件，但又忽略了背后基金或类似基金的支持。注意，这里说的类似基金指的是间接或直接所获得的收入。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>资本家是恐怖的，国外的资本家们取得收益后，或多或少的会向基金会捐赠，以保持相互的良性循环。而</span><span><strong><span>自以为聪明的资本家</span></strong></span><span>们可不这么想，因为他们并懂可持续性发展的重要性。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>这群</span><span><strong><span>自以为聪明的资本家们</span></strong></span><span>秉持着希望免费使用你的产品，又希望你免费维护，同时又不想将自身的成果公开出来（只想生产资料私有制）。现在，我们知道使用 ioGame 是免费的了，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；当</span><span><strong><span>自以为聪明的资本家们</span></strong></span><span>知道要他们把私有资料公开时，他们就会给你上演</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一头牛</span></a></span><span>的故事。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>到这，已经说清楚了经济基础是一切可持续发展的前提。同时，也区分了真正的资本家与</span><span><strong><span>自以为聪明的资本家</span></strong></span><span>。真正的资本家是恐怖的，他们懂得可持续性发展的重要性，并壮大着这些开源组织；而</span><span><strong><span>自以为聪明的资本家们</span></strong></span><span>并不懂得这些，</span><span><strong><span>滑稽</span></strong></span><span>的是他们还喜欢充当所谓的网络侠客（并不具备事物分析能力的人，大部分的发言是臆测主观性的）；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>开源环境</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>经济是发展的核心，任何强大的开源组织（开源巨头）都离不开经济基础。注意，这里说的开源组织并不是指你在 github 随意创建一个 organization 后，放入几个项目的那种组织。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在，国内有很多人想要往这方面发力，建立国产开源组织；但目前在国内很难实现，具体原因这里就不细说了，因为这部分没有十数万字也讲不清楚，而且大部开发者对这部分也没啥兴趣。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>目前国产开源组织也有一些，但大部分都是几个项目勉强凑合到一起所形成的组织。若想要建立一个可持续性发展的开源组织，就目前的环境来说是不可能的。建立一个可持续性发展的开源组织的基本条件，是需要有基金会或类似基金会的支持。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在没有得到外部资金的支持时，任何一个开源框架想要有长远的发展，首先需要考虑的是如何盈利。如果没有持续资金的支持，通常很难坚持下去。你可以在 GitHub 上找到很多长时间未更新的开源项目，通常是因为最初的热情慢慢消退，导致不再维护。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>国产项目的开源策略大部分都是采用社区版本和商业版本的方式，其本质目的也只有一个，即维持自身的可持续性发展。同时，这也是开源维护者与开源使用者的矛盾点之一，但这些是符合马克思主义哲学三大规律的。（将来，如非洲、东南亚、西亚、中东 ...等地区的多数国家也会经历这一阶段的发展过程，但还需要数十年。）</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现阶段，国内开源土壤与环境并不理想，并且还有一群擅长慷他人之慨的网络侠客在添堵。但并无大碍，因为这些小卡拉并不能阻碍，也阻碍不了国产开源的发展。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 的开源策略</span></h3><blockquote><p style="margin-left:0; margin-right:0"><span>ioGame 使用的开源策略是：两开一免一自主。即源码完全开放、最新文档阅读完全开放、使用完全免费、开发者可自主选择按需付费。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>源码：源码完全开放，没有社区版、商业版本之说。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>文档：最新文档阅读完全开放，并采用自愿付费原则（不强制付费）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；同时，ioGame 是允许私有的，前提是支付闭源授权费；所以，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。费用采用年付费制，且费用低（不会超过当年全国最低工资标准的 2 倍，并且可申请盈利后支付）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或许有开发者会问，国产开源项目大部分都是社区版本（免费）和商业版本（强制收费）的策略。但 ioGame 为什么会采用源码完全开放、文档完全开放、使用完全免费的策略呢？</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>源码完全开放的原因</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 推崇</span><span><strong><span>生产资料公有制。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>源码完全开放可以让更好地服务使用者，让使用者更快、更好地完成业务并出产品；同时，这对使用者学习框架源码也比较友好。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>通常（中、小、新）这类公司、团队、独立开发者，在前期是比较缺资金的。我们知道，只有让游戏开发者先盈利，之后想支付费用时才无压力（闭源自身的游戏产品）。（注意，使用 ioGame 是完全免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来）</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>最新文档阅读完全开放，并采用自愿付费的原因</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在你阅读 ioGame 的在线文档时，不会有辣眼的广告，没有登录限制。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 致力于提供高质量的使用文档，在 ioGame21 中，大概有三十多万字（不要认为文档内容多，学习框架成本是困难的，这两者不是对等关系；如果文档只保留一个字，你会认为这是简单的吗？）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>不夸张的说，文档的编写比代码还要困难。如果文档只服务于少部分人，那就有点可惜了。只有完全开放了文档，才能帮助更多的游戏团队、独立开发者及想进入游戏行业的开发者。因为我们知道，只有让开发者先盈利了，他们才更愿意支付费用。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>另一个文档阅读完全开放的原因是，ioGame 推崇</span><span><strong><span>生产资料公有制</span></strong></span><span>（不要理解为版权免费赠送）。需要注意的是，ioGame 的文档不是开源的，以后也不会开源。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或许有开发者会问到，如果以后你的文档不公开了，又或者说强制收费了怎么办。首先，我们的目标很明确，帮助开发者提升、快速地学习整体框架、加快游戏产品的研发并上线盈利。其次，对基础使用文档收费并无兴趣。再次，我们推崇</span><span><strong><span>生产资料公有制</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>此时开发者又会说到，xxx 一开始文档也是公开的，等开发者开始用了，就开始收费割韭菜了，大家都被假开源骗怕了...等之类的话。这里借用凤凰传奇曾毅的一句玩笑话，歌土跟我有什么关系，我才几个词；同样的，你被骗跟我有什么关系，又不是我骗的你。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>另外，要是 ioGame 对基础使用文档有收费的兴趣，也就不会请提前让开发者私下保存一份自留使用了。所以与其他案例是有本质区别的。</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>首先，已经发文提前通知了。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>其次，允许开发者私下保存一份自留使用，但不得以任何形式传播及公开（ioGame 的文档没有开源，以后也不会开源，著作权归作者所有）。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>再次，在 ioGame21 发布后，在线文档对应的是当前最新版本；新的在线文档依旧采用自愿付费模式策略，与之前一样，文档是完全开放的（开发者可阅读所有文档，没有任何限制）。</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>使用 ioGame 免费的原因</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 推崇</span><span><strong><span>生产资料公有制。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是完全免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；同时，ioGame 是允许私有的，前提是支付闭源授权费（</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv" target="_blank"><span>为什么采用授权许可申请？</span></a></span><span>）；所以，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>用户流失？不，这是三赢！</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或许会有开发者问，为什么使用闭源授权的方式，这样不是会流失用户吗？</span></p><blockquote><p style="margin-left:0; margin-right:0"><span>提示：开源 != 免费。即使是做慈善的组织，组织内工作的人也得吃饭。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>纯白嫖的用户流失是一定的，但同时也会吸引更多的新用户，因为 ioGame 有了更长远的规划。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGama 是海纳百川的，在文档中我们推荐了很多同行业的游戏服务器框架。因为我们知道，流失的用户与 ioGame 的矛盾点是必然存在的，但 ioGame 对待流失用户是友好的，我们会积极的把这部分流失的用户推荐给竞品框架。这样</span><span><strong><span>既解决了矛盾，又创造了三赢的局面，真是太棒了</span></strong></span><span>！</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>对于用户群体，ioGame 自身有明确的规划，而且也没打算说服所有的开发者来使用 ioGame；所以，我们首先要做的就是排除对自身不适合或者说理念不相同的开发者，只有这样才能抽出更多的时间来服务真实有效使用者；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，这里的真实有效使用者指的是在项目中使用了 ioGame 的团队、个人、公司...等，并不是特指购买了闭源授权的；因为使用 ioGame 是完全免费的，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>最后，闭源授权的目的是为了社区的长期发展建设，通过闭源授权来营收，后将营收继续投入到社区中，将社区壮大。规划长久的发展，可使双方互利，ioGame 就像一台水果采摘机器，你可以使用这台机器来采摘任何水果，在你取得收获时，希望你能为这台机器加些能量。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>完全开源不怕被参考吗</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 完全开源，就不怕其他开发者参考吗？</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>不怕的，在</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23le5sm" target="_blank"><span>自研框架的成本分析及面临的问题</span></a></span><span>这一小节中，已经列举了很多案例了，这些案例都是与成本相关的。这些问题大致如下</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>如果负责研发框架的开发人员离职后，公司如何安排？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>如果负责研发框架的开发人员，或其他开发人员离职后，将框架带到下个公司使用，是否等于用公司的资源帮其他公司做嫁衣？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>或将现有公司的框架带到下个公司去使用，会给新公司带来风险吗？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>如果员工的框架是上个公司的，你如何确定没有法律风险？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>有完整的使用文档吗？如果将你当前使用的框架给到其他团队，在没有你的帮助下，该团队能顺利完成开发吗？</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>打算新招一个编写业务逻辑的人员，可以做到零学习成本吗？</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>参考者在制作自己的框架时，也只敢参考部分，而且后续的维护成本也是恐怖的（需要付出巨大的劳动力）。看似参考的策略可以节省成本，但实际上的成本更高了。实际当中，也有很多开发者在开展这一策略，即参考 ioGame 来制作自己的框架，但其生命周期都是短暂的，最终是不了了之；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h4><span>有趣的小故事</span></h4><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>这里说个有趣的小故事。现在，有两个开发者分别想要研发一款游戏，游戏类型也大致相同，这里将开发者称为 A、B。 A 和 B 的目标很明确，就是快速的将游戏开发出来并上线。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>技术选型的过程中，他们知道了 ioGame；A 、B 知道 ioGame 的源码完全开放、最新文档阅读完全开放、使用完全免费；只是想将游戏产品闭源时，则需要支付闭源授权费，但可以申请盈利后支付闭源授权费。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在，A 直接开始使用 ioGame 来研发游戏产品了；而 B 则是在想，如何规避这部分闭源授权费。于是 B 就开始阅读、参考 ioGame 相关源码，并开始自制框架。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>数月后，B 依然把劳动力分配在自制的框架上；而 A 则早已将游戏开发了出来。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或许 B 早已忘记了最开始的主要目标了，这也是大多数开发者存在的行为；为了达成次要目标，而放弃或拖延主要目标。这种行为的危害是巨大的，从而导致主要目标无法完成，甚至到最后有可能自制框架都没能完成。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>这种真实的案例每天都在上演，你会发现很多想接触游戏行业的开发者，即使过了数年也没有研发出一个游戏。因为他们忘记了最初的主要目标，如果最开始就把劳动力分配在游戏产品上，或许早已经完成主要目标了。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>而 A 的目标与执行力更加的明确，直接使用 ioGame 来研发产品。这样就能把所有的劳动力分配到自身游戏产品的业务上，从而能快速的开发出游戏。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在这个小故事中，B 最开始只是为了规避闭源授权费，导致自身付出了更多的成本。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h4><span>比较优势</span></h4><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>上面讲了一个有趣的小故事，这里还有一些</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23aSk5x" target="_blank"><span>关于成本分析的其他案例</span></a></span><span>（点击我）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>大衞·李嘉图在其代表作《政治经济学及赋税原理》中提出了比较成本贸易理论（后人称为「</span><span><strong><span>比较优势</span></strong></span><span>贸易理论」）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>比较优势可以表述为：在两国之间，劳动生产率的差距并不是在任何产品上都是相等的。每个国家都应集中生产并出口具有比较优势的产品，进口具有比较劣势的产品（即「两优相权取其重，两劣相衡取其轻」），双方均可节省劳动力，获得专业化分工提高劳动生产率的好处。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在小故事及</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23aSk5x" target="_blank"><span>关于成本分析的其他案例</span></a></span><span>中，本质上也是在描述成本的比较优势。即两个个体、两个团队、两个公司 ... 等，之间的比较。两者之间的分配策略，基本决定了后续的谁的生存几率更大；把有趣小故事中的 A、B 替换成两个公司、团队之间的博弈亦是如此。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在有趣小故事中，之所以 A 比 B 更有几率出游戏产品，是因为 A 把劳动力放在游戏产品的研发上，而 B 除了需要研发产品外，还需要兼顾自研框架。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>小结</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在我们知道了，ioGame 源码完全开放，没有社区版、商业版本之说，让使用者用得开心，用得放心。ioGame 新版在线文档阅读完全开放，与之前一样，依旧采用自愿付费原则的策略（不强制付费）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；同时，ioGame 是允许私有的，前提是支付闭源授权费；所以，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><blockquote><p style="margin-left:0; margin-right:0"><span>ioGame 使用的开源策略是：两开一免一自主。即源码完全开放、最新文档阅读完全开放、使用完全免费、开发者可自主选择按需付费。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>当其他开发者、团队还有纠结及时，我们的真实有效用户早已将产品上线并运营了。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 是无私的，能容得下所有竞品框架；甚至我们还在文档中介绍了其他的竞品框架。如果 ioGame 不能很好的满足你的需要，请别担心，这里还有</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fwwvg7z%23EH8Oc" target="_blank"><span>更多的 java 游戏服务器框架推荐</span></a></span><span>给你。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>为什么不在之前的讨论区回应</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>因为讨论区大部分是各种现代化的卧龙、凤雏。滑稽的是他们还喜欢充当所谓的网络侠客（一些不具备事物分析能力的人，大部分的发言是臆测主观性的）；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，这里不是指讨论区内的所有人，只是部分人符合我心中现代化卧龙、凤雏的形象。所以，个人并不会把时间浪费在现代化卧龙、凤雏身上；因为他们的目的不是辩，而是摆弄。不信？后续在其他版块中，你还会看见这群家伙在不同的讨论区中，周而复始的操弄着带有臆测主观性的庸俗观点来发言。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>现代化的卧龙、凤雏，或者说自以为聪明的资本家</span></strong></span><span>的基本特征是：你这产品不错、你这框架不错、你这项目不错，应该免费；同时，这群家伙还擅长慷他人之慨，真让他们参与付出时，结局是</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一头牛</span></a></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>我们只会把时间投入到真实有效使用者的身上，加强文档的质量，耐心回答与 ioGame 相关的 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgame-town%2FioGame%2Fissues" target="_blank"><span>issues</span></a></span><span> 。注意，这里的真实有效使用者指的是在项目中使用了 ioGame 的团队、个人、公司...等，并不是特指购买了闭源授权的；因为使用 ioGame 是完全免费的，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>规避与防范 ioGame</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv%23a7jj5" target="_blank"><span>如何规避闭源授权费用？</span></a></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>通常来讲你要防范的并不是 ioGame，因为 ioGame 每年需要支付的闭源授权的费用很少，而且可以申请盈利后支付。在成本分析中已经说明，如果你选择自研框架，自研一个月的成本够使用 ioGame 几十年了（而且需要自己编写、维护文档）。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>更多的时候，取得授权是为了保护自身产品源代码泄露时可以得到法律的保护，所以如果你不担心这点，我想你应该知道如何做了。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 的使命</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>改变行业现状，降低使用难度。让游戏开发领域的</span><span><strong><span>生产资料公有制</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 是什么？</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 学习成本非常低，可以说是</span><span><strong><span>零学习成本</span></strong></span><span>，即使没有游戏编程（网络编程）经验，也能轻松上手。开发者只需掌握普通的 java 方法或 webMVC 相关知识，就能用框架开发业务，通常在 10 分钟内就能掌握。框架不要求开发者改变编码习惯，而是自身适应开发者的需求。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>同时，ioGame 也</span><span><strong><span>适用于网络游戏服务器、物联网、内部系统及各种需要长连接的场景</span></strong></span><span>；框架采用无锁异步化、事件驱动的架构设计；轻量级，无需依赖任何第三方中间件或数据库就能支持集群、分布式。通过 ioGame 可以很容易的搭建出一个集群无中心节点、集群自动化、多进程的分布式游戏服务器。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 是一个非常适合网络游戏开发的框架。可以让你轻松地创建高性能、低延迟、易扩展的游戏服务器，并且节省时间和资源。如果你想要快速地开发出令人惊艳的网络游戏，请不要犹豫，立即选择 ioGame 吧！框架屏蔽了很多复杂且重复性的工作，并可为项目中的功能模块结构、开发流程等进行</span><span><strong><span>清晰的组织定义</span></strong></span><span>，减少了后续的项目维护成本。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 的使用趋势</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>关注 ioGame 的游戏服务器开发者持续增多，</span><span><strong><span>2022-09 ~ 至今</span></strong></span><span>各月的统计数据；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>这里的统计信息是关于开发者关注 ioGame 框架相关的，从统计数据中可以看出，由于 ioGame 上手简单，功能强大等优点，得到了众多开发者的关注。如果你想知道 ioGame 有没有人在使用，可以先到这里看下统计数据、开发者的评价与讨论。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgpxk93%23TwVa8" target="_blank">https://www.yuque.com/iohao/game/gpxk93#TwVa8</a></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>这里展示了每月的统计数据，统计数据来源于语雀后台，这些数据都是</span><span><strong><span>真实的、客观存在的、活的</span></strong></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>因为成本的原因，某宝某多还没有出现能提供这种服务的商家，所以这样的统计数据也更具真实性。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>通过统计数据，我们可以看到每天会有很多开发者在访问 ioGame 的在线文档，并且这些统计数据不是来源于口嗨的，也不是主观创造的。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>所以，还在犹豫要不要使用 ioGame 的开发者们，更应该讨论的是「为什么这些开发者会选择使用 ioGame」，而不是 ioGame 有没有人在使用的问题。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao" target="_blank"><span>点击我，到语雀后台查看 ioGame 的数据</span></a></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>ioGame 版本命名规则</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>从发布到中央仓库开始，ioGame 就有定义了自身的</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fwsgmba%23zagb5" target="_blank"><span>版本规则</span></a></span><span>。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>ioGame17 版本命名规则 x.y.z</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>x 表示当前使用的 JDK 版本</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>y 表示 ioGame API 变更版本 （但基本上不会变动，常规下是变动 x 才会变动 API）</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>z 表示 ioGame 新特性、新功能、新模块、bugfix 相关</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 的 x 会跟着最新的 JDK LTS 版本来走的，目的是确保 ioGame 的 API 不会发生很大的变化。为了保持新活力与接受新鲜事物， ioGame 基本会用上最新的 JDK LTS; 也就是说，下一个 x 将会是 21;</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>x 一般延后 1~2 个季度，给开发者一个缓冲。即下一个 JDK LTS 出来后，那么 ioGame 的 x 会在 1~2 个季度后跟上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>从 ioGame21 开始，版本命名规则将使用 x.y 的格式，其他照旧</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>x 表示当前使用的 JDK LTS 版本</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>y 表示 ioGame 新特性、新功能、新模块、bugfix 相关</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><h3><span>最后</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>由于整篇内容较长，阅读到最后难免会忘记前面的。所以，在最后这里，来个二次小结与介绍。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 推崇</span><span><strong><span>生产资料公有制。</span></strong></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGame 使用的开源策略是：两开一免一自主。即源码完全开放、最新文档阅读完全开放、使用完全免费、开发者可自主选择按需付费。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用 ioGame 是完全免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；同时，ioGame 是允许私有的，前提是支付闭源授权费（</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fiohao%2Fgame%2Fgd5l3b0y0h027kcv" target="_blank"><span>为什么采用授权许可申请？</span></a></span><span>）；所以，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><div><hr></div><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>或许会有开发者问，为什么使用闭源授权的方式，这样不是会流失用户吗？</span></p><blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>提示：开源 != 免费。即使是做慈善的组织，组织内工作的人也得吃饭。</span></p></blockquote><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>纯白嫖的用户流失是一定的，但同时也会吸引更多的新用户，因为 ioGame 有了更长远的规划。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>ioGama 是海纳百川的，在文档中我们推荐了很多同行业的游戏服务器框架。因为我们知道，流失的用户与 ioGame 的矛盾点是必然存在的，但 ioGame 对待流失用户是友好的，我们会积极的把这部分流失的用户推荐给竞品框架。这样</span><span><strong><span>既解决了矛盾，又创造了三赢的局面，真是太棒了</span></strong></span><span>！</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>对于用户群体，ioGame 自身有明确的规划，而且也没打算说服所有的开发者来使用 ioGame；所以，我们首先要做的就是排除对自身不适合或者说理念不相同的开发者，只有这样才能抽出更多的时间来服务真实有效使用者；</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>注意，这里的真实有效使用者指的是在项目中使用了 ioGame 的团队、个人、公司...等，并不是特指购买了闭源授权的；因为使用 ioGame 是完全免费的，</span><span><strong><span>付费不是必须的，也不是强制性的</span></strong></span><span>，选择权在使用者手上。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><div><hr></div><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>真正的资本家是恐怖的，国外的资本家们取得收益后，或多或少的会向基金会捐赠，以保持相互的良性循环。而</span><span><strong><span>自以为聪明的资本家</span></strong></span><span>们可不这么想，因为他们并懂可持续性发展的重要性。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>这群</span><span><strong><span>自以为聪明的资本家们</span></strong></span><span>秉持着希望免费使用你的产品，又希望你免费维护，同时又不想将自身的成果公开出来（只想生产资料私有制）。现在，我们知道使用 ioGame 是免费的了，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来；当</span><span><strong><span>自以为聪明的资本家们</span></strong></span><span>知道要他们把私有资料公开时，他们就会给你上演</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一头牛</span></a></span><span>的故事。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>现代化的卧龙、凤雏，或者说自以为聪明的资本家</span></strong></span><span>的基本特征是：你这产品不错、你这框架不错、你这项目不错，应该免费；同时，这群家伙还擅长慷他人之慨，真让他们参与付出时，结局是</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.bing.com%2Fsearch%3Fq%3D%25E7%259C%259F%25E6%259C%2589%25E4%25B8%2580%25E5%25A4%25B4%25E7%2589%259B%26qs%3Dn%26form%3DQBRE%26sp%3D-1%26lq%3D0%26pq%3D%26sc%3D0-0%26sk%3D%26cvid%3D9BE3D9C25BDF45FA8341F1641F100333%26ghsh%3D0%26ghacc%3D0%26ghpl%3D" target="_blank"><span>真有一头牛</span></a></span><span>。</span></p><p>&nbsp;</p><div><hr></div><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>最后，我们的目的是为了帮助（中、小、新）这类公司、团队、独立开发者，通过双方的比较优势来互补。我们知道，只有让游戏开发者先盈利，之后想支付费用时才无压力（闭源自身的游戏产品）。（注意，使用 ioGame 是完全免费的，前提是要认同</span><span><strong><span>生产资料公有制</span></strong></span><span>，就是把你的产品也完全的开源出来）</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 03:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276890</guid>
            <link>https://www.oschina.net/news/276890</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RHEL 源码访问限制影响 CentOS SIG]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">去年 6 月，红帽发布公告<a href="https://www.oschina.net/news/246331/red-hat-centos-stream-sources">宣布</a>了一个限制 Red Hat Enterprise Linux (RHEL)&nbsp; 源代码访问性的政策。时至今日，这一变更似乎无意中给 CentOS Integration&nbsp;Special&nbsp;Interest&nbsp;Group (&nbsp;(SIG) 小组带来了一些麻烦。</span></p><p><span style="color:#000000">Kmods SIG 旨在为 CentOS Stream 和 Red Hat Enterprise Linux 维护额外内核模块。CentOS 博客上周<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.centos.org%2F2024%2F01%2Fjanuary-2024-news%2F" target="_blank">发布</a>了 Kmods SIG 的最新状态，其中一项值得注意的内容是：</span></p><blockquote><p>由于 Red Hat 发布 Red Hat Enterprise Linux 源代码的方式发生了变化，Kmods SIG 目前由于法律原因无法为 Red Hat Enterprise Linux 制作软件包。我们正与 Red Hat 合作解决这一问题，并希望能尽快再次为企业 Linux 提供软件包。</p></blockquote><p><img height="304" src="https://oscimg.oschina.net/oscnet/up-05fcfbc3e8c1312848b6f99d2e074ce2339.png" width="500" referrerpolicy="no-referrer"></p><p>此外，CentOS Hyperscale SIG 在 2023 年第四季度报告中<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.centos.org%2F2024%2F01%2Fcentos-hyperscale-sig-quarterly-report-for-2023q4%2F" target="_blank">表示</a>：</p><blockquote><p><span style="color:#020008">Hyperscale SIG 的最新版本是 CentOS Stream 9 的内核 6.7.1-0.hs1。这个新内核现在基于上游 Fedora 版本内核，而不是 CentOS/RHEL 内核树。在可预见的未来，Hyperscale SIG 将跟踪 Fedora 内核以构建并发布到 CentOS 中。内核仍然采用类似 RHEL 的配置构建，专门针对 CentOS Hyperscale 进行 modulo 更改。</span></p><p><span style="color:#020008">随着&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.centos.org%2F2023%2F04%2Fend-dates-are-coming-for-centos-stream-8-and-centos-linux-7%2F" target="_blank">EOL</a>&nbsp;<span style="color:#020008">的临近，CentOS Stream 8 的内核已停止使用，并且没有计划围绕 CentOS Stream 8 进行进一步的工作。</span></p></blockquote><p><span style="background-color:#ffffff; color:#333333">Hyperscalers SIG 由 Facebook 和 Twitter 等科技公司倡议<a href="https://www.oschina.net/news/126467/centos-hyperscale-sig">成立</a>，致力于在大型基础架构上（如 Facebook、Twitter 和云服务提供商等其他 "hyperscaler" 组织）启用 CentOS Stream 部署，并促进软件包和工具上的协作。&nbsp;</span>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 03:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276886/centos-rhel-kmods-sig</guid>
            <link>https://www.oschina.net/news/276886/centos-rhel-kmods-sig</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeIgniter 社区 2023 年终总结]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>随着我们步入 2024 年，我想借此机会总结过去一年 CodeIgniter 社区所取得的成果，并对所有贡献者的努力表示感谢。CodeIgniter 作为一个社区驱动的项目，每一位贡献者都在促进着我们的发展。</p><p>因为所有工作都是由志愿者完成的，所以贡献者的参与度会因他们的空余时间、工作以及其他生活琐事而有所变动。今年，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.codeigniter.com%2Fmember.php%3Faction%3Dprofile%26uid%3D90" target="_blank">@kenjis</a> 的突出贡献让人印象深刻，他们在主要的代码仓库和论坛上的辛勤耕耘让整个项目有了质的飞跃。</p><p>以下是一些数据，以侧面展示了我们在 2023 年的活跃程度：</p><ul><li>我们发布了 15 个核心框架版本</li><li>我们的身份验证系统 Shield 发布了 6 个测试版，并在年底前推出了 1.0 的正式版</li><li>推出了两个新的库 - Tasks 和 Queue，虽然还处于 Alpha 阶段，但正朝着第一个正式版稳步前进。他们本身是 CodeIgniter 构建出色软件所需的最后几个关键模块，所以我对他们极其期待。</li><li>我们为 Settings、Shield、Tasks 和 Queue 库新建了文档站点</li></ul><p>如果只看我们的核心框架，我们在过去一年内取得的成果包括：</p><ul><li>每月平均新增两名贡献者</li><li>全年共新增了 26 名新贡献者</li><li>每月平均有 11 名活跃的贡献者</li><li>新贡献者占提交者的 18%</li><li>每月平均有 203 次代码提交</li><li>平均每名提交者每月提交代码 18.45 次</li><li>提交者总数增加了 26 人（从 350 增加到 376）</li><li>平均每月合并 54 个 PR 请求</li></ul><p>这是一份令人印象深刻的成绩单。除此之外，我们还在进行持续的翻译工作，修复了一些严重的安全漏洞，以及将代码质量管理工作做得更加精细，确保无论贡献者数量如何增长，我们都能保持高质量的代码输出。</p><p>我要向今年所有做出贡献的人表示感谢，无论是贡献代码、编写文档还是在论坛上帮助他人。正是你们让这个项目保持了活力。</p><p><strong>那么，CodeIgniter 未来会有什么新变化呢？</strong></p><p>我们正在开发一款全新的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonnieezell%2Fforum-example" target="_blank">论坛软件</a>，这款软件完全基于 CodeIgniter 构建。这款软件的目标是提供一种符合现代审美，而又为这个社区定制的论坛体验，展示 CodeIgniter 的可能性。它将使用 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftailwindcss.com%2F" target="_blank">TailwindCSS</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falpinejs.dev%2F" target="_blank">AlpineJS</a> 和 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhtmx.org%2F" target="_blank">HTMX</a>，以提供快速、现代的用户体验。目前我们的团队还在积极开发阶段，如果你愿意加入，我们会很欢迎。</p><p>虽然我不能代表所有团队成员的观点，但是在我看来，我想尝试让 CodeIgniter 的使用更加简化。这是一个宏大主题，但我相信我们很快能就此取得一些进展。</p><p>首先，我们打算简化代码库的贡献过程，让任何有意愿的人都能从自己的电脑开始更便捷地参与进来。虽然现在还没有确定的消息可以公布，但我们希望这样，更多的开发者会愿意加入我们。</p><p>接下来，我们关注用户指南。我们在尝试不丢失任何内容的情况下，将其<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodeigniter4%2Fdocs-update" target="_blank">转换为 Markdown 格式</a>，并取得了非常好的进展。我们希望 Markdown 语言的易用性，能让更多的贡献者参与其中。这样，我们的文档就能保持统一的格式和风格，让项目页面显得更加整齐一致。实际上，我们的库已经实现了这一点，核心框架是最后一个待处理的问题。</p><p>我还有其它的一些想法，比如关于 API 和本地化的问题，但是这需要在我完成其它项目后，看我能投入多少时间来做。</p><p>所以，我要再次感谢我们的核心团队、论坛的版主和所有为这个社区做出贡献的你们。期待今年我们能有更好的发展！</p><hr><p>原文作者: kilishan<br> 原文链接: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.codeigniter.com%2Fshowthread.php%3Ftid%3D89075" target="_blank">https://forum.codeigniter.com/showthread.php?tid=89075</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276880/codeigniter-2023</guid>
            <link>https://www.oschina.net/news/276880/codeigniter-2023</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[上海 AI 实验室发布新一代书生·视觉大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>上海人工智能实验室（上海 AI 实验室）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbdfAJRqOF9tUk8Vy9KC_XQ" target="_blank">宣布</a>联合清华大学、香港中文大学、商汤科技等机构开源新一代书生·视觉大模型（InternVL）。</p><p>新一代「书生·视觉基础」模型的视觉编码器参数量达 60 亿 (InternVL-6B)，首次提出了对比-生成融合的渐进式对齐技术，实现了在互联网级别数据上视觉大模型与语言大模型的精细对齐。</p><p>InternVL-6B 不仅能处理复杂图片中细微的视觉信息并完成图生文任务，还可以识别和解读复杂页面中的信息，甚至解决其中的数理问题。</p><p>目前，InternVL 全系列模型、代码均已开源，并提供 Demo 试用。</p><ul><li>开源链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenGVLab%2FInternVL" target="_blank">https://github.com/OpenGVLab/InternVL</a></li><li>论文链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.14238" target="_blank">https://arxiv.org/abs/2312.14238</a></li><li>试用 Demo：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finternvl.opengvlab.com" target="_blank">https://internvl.opengvlab.com</a></li></ul><p>InternVL-6B 具备纯视觉感知、图文检索、图文生成、图文多模态生成和对话等关键能力。谷歌 ViT-22B 是目前被公认为最强大的专注视觉的基础模型（非开源）。InternVL 开源模型以不到 1/3 的参数量，在纯视觉任务（如 ImageNet、ADE20K 等）和图生文任务（如 NoCaps、MS COCO 等）上逼近或超过谷歌 ViT-22B。</p><p><img alt="" height="435" src="https://oscimg.oschina.net/oscnet/up-f94fea8f6165e351f12396a1f5f9a393f7c.png" width="500" referrerpolicy="no-referrer"></p><p>在视觉感知、图文检索、图文多模态生成和对话等 30 余个视觉基准测试上，InternVL-6B 取得了开源社区的最优性能，超过了 Meta、谷歌、微软、LAION 等机构的同类开源模型。</p><p><img alt="" height="669" src="https://oscimg.oschina.net/oscnet/up-5d454993d286bc955eddcb7f961048b6440.png" width="300" referrerpolicy="no-referrer"></p><p>在 TinyLVLM 、MMBench 等多模态大模型评测上，InternVL-6B 取得了优秀的性能。其中，在 MMBench-dev 上，InternVL-6B 达到 76.6，虽然综合能力仍有待提高，但个别性能超越了 GPT-4V（75.1）和 Gemini（75.2）。</p><p>InternVL-6B 具备强大的视觉表征和理解能力，尤其表现在面对信息复杂的图片时，模型仍可对细节进行精准捕捉，不仅可在图片或实际场景的复杂画面中捕捉细微的视觉信息，还可从复杂排版的图文页面中整合、解读信息，或辨别伪装外观的物体。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:35:50 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276879</guid>
            <link>https://www.oschina.net/news/276879</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Meta 发布全新代码生成大模型 Code Llama 70B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Meta 今天发布了全新的代码生成大模型 Code Llama 70B。据称其 HumanEval 评分达到 67.8，达到 GPT-4 水准，是目前评分最高的开源大模型。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aa28c3b26f59dc762db43f6ffcd3091ca27.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FAIatMeta%2Fstatus%2F1752013879532782075" target="_blank">https://twitter.com/AIatMeta/status/1752013879532782075</a></u></em></p></blockquote><p>Code Llama 70B 是此前 <strong><u><a href="https://www.oschina.net/news/255350/meta-code-llama">Code Llama </a></u></strong>的升级版本，包括三个模型：</p><ul><li>CodeLlama-70B</li><li>CodeLlama-70B-Python</li><li>CodeLlama-70B-Instruct</li></ul><p><strong>开源地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodellama%2FCodeLlama-70b-hf" target="_blank">https://huggingface.co/codellama/CodeLlama-70b-hf</a></u></em></strong></p><p>Code Llama 以 Llama 2 为基础，可以帮助开发者根据提示创建代码，并调试人工编写的代码。</p><p>Meta 表示，Code Llama 70B 性能更高，可以处理更多的内容，更好地帮助开发者处理编程时遇到的问题。此外，Code Llama 70B 采用了与 Llama 2 和 Code Llama 相同的 License，可用于研究和商业用途。</p><p>扎克伯格<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.facebook.com%2Fzuck%2Fposts%2Fpfbid0KccyDFLszKeHkWVssrcSJYnigb1VYfsLuExTjxVPKWzDpXgmd9FYMfZ1hcWpyf3Zl" target="_blank">表示</a></u>：「编写代码能力对于 AI 模型更严谨、更合理地处理其他领域的信息也非常重要。我为这里取得的进展感到自豪，并期待着将这些进展纳入 Llama 3 和未来的模型中。」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-02e72478e15d47689552ffc6fd15bb220af.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276877/meta-code-llama-70b</guid>
            <link>https://www.oschina.net/news/276877/meta-code-llama-70b</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RWKV-5-World 7B 模型开源——最环保、最节能的 AI 模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年 1 月 28 日，RWKV 开源基金会<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4hTFA2CMcInhGLZTqa_H4g" target="_blank">宣布</a></u></strong>开源 RWKV-5-World 7B 模型。</p><p>据介绍，「RWKV-5-World 7B」是 RWKV 第五代架构 7B 参数大模型，也是 RWKV 迄今为止多语言性能最强的开源大模型。根据性能评测数据显示，在 100% attention-free 和只训练 1.1T tokens 的前提下，RWKV-5 7B 模型的多语言性能超过 Mistral，英文性能看齐 LlaMa2。</p><h3><strong>RWKV 模型介绍</strong></h3><p>RWKV 是一种创新的深度学习网络架构，它将 Transformer 与 RNN 各自的优点相结合，同时实现高度并行化训练与高效推理，时间复杂度为线性复杂度，在长序列推理场景下具有优于 Transformer 的性能潜力。</p><p>RWKV-v5 架构模型能力指标接近 Llama2，但推理成本降低 2~10 倍，训练成本降低 2~3 倍。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8b124ce111f66fc29349dc3550fae0e963d.png" referrerpolicy="no-referrer"></p><p>如上图所示，对比 RWKV-v4 架构，在使用相同训练数据集的情况下，RWKV-v5 的多语言能力大幅提升，整体提升约 4%。而对比其他同为 7B 参数的模型，RWKV-5 7B 的多语言表现亦处于领先地位。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b4a1c53e39044930c57fdeb0099eda5ea3d.png" referrerpolicy="no-referrer"></p><p>官方介绍称，在相同参数大小（7B）的模型独立基准测试中，RWKV 是世界上最环保、最节能的人工智能模型/架构（以每个 token 输出为基础）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3d734a934d678a080b7392fed400e7c9c3a.png" referrerpolicy="no-referrer"><br> 测试地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fml.energy%2Fleaderboard%2F" target="_blank">https://ml.energy/leaderboard/</a></u></em></p><p>RWKV 架构的能源效率源自线性 Transformer 架构的 2~10 倍计算效率与 Transformer 架构的二次缩放。随着模型规模的扩大，RWKV 架构的节能特性会越发明显。</p><p><img src="https://oscimg.oschina.net/oscnet/up-38b5e2a74f34b88918058aa8e911bf3c62b.png" referrerpolicy="no-referrer"></p><h3><strong>下载&amp;试玩 RWKV-5-World 7B</strong></h3><p><strong>RWKV-5-World 7B 模型在线 Demo：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2" target="_blank">https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2</a></p><p><strong>RWKV-5-World 7B 模型下载地址：</strong></p><ul><li><p><strong>Hugging Face</strong>:<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-5-world%2Fblob%2Fmain%2FRWKV-5-World-7B-v2-20240128-ctx4096.pth" target="_blank">https://huggingface.co/BlinkDL/rwkv-5-world/blob/main/RWKV-5-World-7B-v2-20240128-ctx4096.pth</a></p></li><li><p><strong>wisemodel</strong>:<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-5-World-7B-v2%2Ffile" target="_blank">https://wisemodel.cn/models/rwkv4fun/RWKV-5-World-7B-v2/file</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:08:50 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276876/rwkv-5-world-7b-opensource</guid>
            <link>https://www.oschina.net/news/276876/rwkv-5-world-7b-opensource</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[腾讯 APIJSON 插件 apijson-mongodb 开源，支持文档数据库 MongoDB]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img height="1570" src="https://oscimg.oschina.net/oscnet/up-bdaf900bde612e78f2a7ac5ec7f7dda180c.png" width="2202" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">腾讯 APIJSON 是一种专为 API 而生的 JSON 网络传输协议，以及，基于这套协议实现的 ORM 库。<br><strong>为各种增删改查提供了完全自动化的万能 API，零代码实时满足千变万化的各种新增和变更需求。</strong><br> 能大幅降低开发和沟通成本，简化开发流程，缩短开发周期。适合中小型前后端分离的项目。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>自 2016 年开源 7 年来发展迅速，目前 16K+ Star 位居 400W Java 开源项目前 100。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>国内，腾讯、华为、阿里巴巴、字节跳动、美团、拼多多、百度、京东、网易、快手、圆通，等 和<br> 国外 Google, Apple, Microsoft, Amazon, Tesla, Meta(FB), Paypal 等数百个知名大厂员工 Star，<br> 也有，腾讯、华为、字节跳动、Microsoft、Zoom、知乎，等 工程师/专家/架构师，提了 PR/Issue，<br> 还被，腾讯、华为、百度、SHEIN、快手、中兴、传音、圆通、美图，等各大知名厂商用于各类项目。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="1352" src="https://oscimg.oschina.net/oscnet/up-05507add1ab73979181e2a721832b2ef017.png" width="1850" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="1344" src="https://oscimg.oschina.net/oscnet/up-b0118180bc641918130cef0f4dee2bf1ca1.png" width="1634" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h1>apijson-mongodb<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjitpack.io%2F%23APIJSON%2Fapijson-mongodb" target="_blank"><img alt="" src="https://camo.githubusercontent.com/f9608d575b9afc54743bb783cab0dd73e97b3b37a696f11e0494caa137b72f24/68747470733a2f2f6a69747061636b2e696f2f762f4150494a534f4e2f6170696a736f6e2d6d6f6e676f64622e737667" referrerpolicy="no-referrer"></a></h1><p style="color:#1f2328; text-align:start">腾讯<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent%2FAPIJSON" target="_blank">APIJSON</a><span>&nbsp;</span>的 MongoDB 数据库插件，可通过 Maven, Gradle 等远程依赖。</p><p style="color:#1f2328; text-align:start"><img height="709" src="https://oscimg.oschina.net/oscnet/up-7e4aaaf91ea988480d31e94d5def25b75de.png" width="1280" referrerpolicy="no-referrer"></p><h2>添加依赖</h2><h4>1. 在 pom.xml 中添加 JitPack 仓库</h4><div><pre>&lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">repositories</span>&gt;
&lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">repository</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">id</span>&gt;jitpack.io&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">id</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">url</span>&gt;https://jitpack.io&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">url</span>&gt;
&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">repository</span>&gt;
&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">repositories</span>&gt;
</pre></div><h4>2. 在 pom.xml 中添加 apijson-mongodb 依赖</h4><div><pre>&lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">dependency</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">groupId</span>&gt;com.github.APIJSON&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">groupId</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">artifactId</span>&gt;apijson-mongodb&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">artifactId</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">version</span>&gt;LATEST&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">version</span>&gt;
&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">dependency</span>&gt;

</pre></div><h3>使用</h3><p style="color:#1f2328; text-align:start">在你项目继承 AbstractSQLExecutor 的子类重写方法 getValue<br> Override getValue in your SQLExecutor extends AbstractSQLExecutor</p><div><pre><span style="color:var(--color-prettylights-syntax-constant)">@</span><span style="color:var(--color-prettylights-syntax-constant)">Override</span><span style="color:var(--color-prettylights-syntax-keyword)">protected</span><span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Object</span><span>getValue</span>(<span style="color:var(--color-prettylights-syntax-storage-modifier-import)">SQLConfig</span>&lt;<span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Long</span>&gt; <span>config</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">ResultSet</span><span>rs</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">ResultSetMetaData</span><span>rsmd</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">int</span><span>tablePosition</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">JSONObject</span><span>table</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">int</span><span>columnIndex</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">String</span><span>lable</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Map</span>&lt;<span style="color:var(--color-prettylights-syntax-storage-modifier-import)">String</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">JSONObject</span>&gt; <span>childMap</span>) <span style="color:var(--color-prettylights-syntax-keyword)">throws</span><span>Exception</span> {
            <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Object</span><span>v</span> = <span style="color:var(--color-prettylights-syntax-entity)">super</span>.<span style="color:var(--color-prettylights-syntax-entity)">getValue</span>(<span>config</span>, <span>rs</span>, <span>rsmd</span>, <span>tablePosition</span>, <span>table</span>, <span>columnIndex</span>, <span>lable</span>, <span>childMap</span>);
            <span style="color:var(--color-prettylights-syntax-keyword)">return</span><span style="color:var(--color-prettylights-syntax-storage-modifier-import)">MongoUtil</span>.<span style="color:var(--color-prettylights-syntax-entity)">getValue</span>(<span>v</span>);
        }</pre><div><br> &nbsp;
 </div></div><p style="color:#1f2328; text-align:start">有问题可以去 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent%2FAPIJSON" target="_blank">Tencent/APIJSON</a> 提 issue<br> &nbsp;</p><h4>创作不易，右上角点亮 ⭐Star 支持/收藏下吧，谢谢 ^_^</h4><p style="color:#1f2328; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAPIJSON%2Fapijson-mongodb" target="_blank">https://github.com/APIJSON/apijson-mongodb</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 01:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276875</guid>
            <link>https://www.oschina.net/news/276875</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openKylin 2.0 揭秘 | 新一代不可变系统的设计与实现]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">在<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg2MDc5MDU1OQ%3D%3D%26mid%3D2247494992%26idx%3D1%26sn%3D996588c684d59a85aea52eb371570323%26chksm%3Dce23a720f9542e36dbaba5c747475834862a800a0843c5ab55f562b1ff15f8d0364ad4690f5b%26scene%3D21%23wechat_redirect" target="_blank">之前文章</a>中，我们向大家揭秘了什么是不可变系统以及不可变系统相较于传统操作系统具有哪些优势。今天我们继续向大家深入揭秘 openKylin 不可变系统的特性具体是如何设计和实现的！</span></p><p style="text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-ba9965c58fe2a7a291437acb42d33cd74c1.png" width="940" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff"><span>UpdateManager SIG 基于 OSTree 技术为原生 openKylin 操作系统设计并实现了不可变操作系统特性，同时，为尽可能保障在安装、启动、UI 界面和用户操作等方面与传统操作系统保持一致，还在</span>文件系统结构<span>、安装方式、启动流程、版本控制方式和版本存储库等特性方面进行了针对 OSTree 技术特点的设计改造。具体如下：</span></span></p><p>&nbsp;</p><p>0<span>1</span><strong>文件系统结构</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">openKylin 不可变系统的目录结构与传统 Linux 发行版相比有一些不同，主要体现在采用 OSTree 管理文件系统版本、强调不可变系统的特性以及将用户程序和数据都视为不可变的。这些设计使得其在系统稳定性和可靠性方面有所提升。具体实现如下：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/usr</span></strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">&nbsp;/usr 及其下面的所有内容都是只读的。</span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/usr</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/bin&nbsp;→&nbsp;/usr/bin</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/lib&nbsp;→&nbsp;/usr/lib</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/lib64&nbsp;→&nbsp;/usr/lib64</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/sbin&nbsp;→&nbsp;/usr/sbin</span></p></li></ul><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/var</span></strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff"><span>系统运行时状态的存储位置。/var 目录是用于存储</span>可变数据<span>的位置，包括各种应用程序的文件、日志、缓存和运行时数据。同时将/home 和/root 目录，存放至 data 分区 /media -&gt; var/run/media。</span></span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/mnt&nbsp;-&gt;&nbsp;var/mnt</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/opt&nbsp;-&gt;&nbsp;var/opt</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/root&nbsp;-&gt;&nbsp;data/root&nbsp;</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/home-&gt;data/home</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/srv&nbsp;-&gt;&nbsp;var/srv</span></p></li></ul><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/sysroot</span></strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">文件系统根目录，类似于传统 Linux 中的/目录，使用/sysroot 作为其文件系统的根目录，与传统 Linux 发行版中的/目录有所不同。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/ostree</span></strong></p><p><span style="background-color:#ffffff">sysroot/ostree 目录是基于 OSTree 技术的系统根文件系统的存储位置，其中的 repo 目录存储了 OSTree 的版本控制数据库，deploy 目录存储了不同版本的系统根文件系统部署。这种机制使得系统可以进行整体的不可变性管理和更新。</span></p><p>&nbsp;</p><p>0<span>2</span><strong>系统安装</strong></p><p><span style="background-color:#ffffff">openKylin 不可变系统的安装过程与传统操作系统相似，在安装时，用户可在安装界面勾选不可变系统安装，即可实现不可变系统的安装。在安装完成后，安装器调用 OStree CLI 实现不可变系统的初始化、&nbsp;仓库创建、分支提交等动作。</span></p><p>&nbsp;</p><p>0<span>3</span><strong>系统启动</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff"><span>OSTree 在/ostree 目录下安装部署，但最终还是要控制系统的/boot 目录。这种方式是通过</span>Boot Loader<span>来实现的。当部署一个分支时，会生成/boot/loader/entries/ostree-1-</span></span></p><p><span style="background-color:#ffffff"><span>openkylin.conf 的配置文件，该配置文件中将包含一个内核参数和一个</span><span>initrd</span><span><span>参数，允许 initramfs 找到指定的部署。最后 OStree 会更新/boot/grub/grub.</span>cfg 文件<span>，引导系统启动。</span></span></span></p><p>&nbsp;</p><p>0<span>4</span><strong>版本控制</strong></p><p><span style="background-color:#ffffff">OSTree 使用版本控制技术来管理系统的文件系统。它将文件系统的每个版本都存储为一个只读快照（snapshot），并通过分支（branch）的方式跟踪和管理不同的版本。这样，系统的每个更新都是事务性的，可以轻松进行回滚操作。</span></p><p>&nbsp;</p><p>0<span>5</span><strong>存储库管理</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">OSTree 使用存储库来存储系统的版本控制数据，存储库中包含了系统的不同分支和快照，以及与版本控制相关的元数据。通过存储库，系统管理员可以方便地管理和维护系统的版本。</span></p><p><span style="background-color:#ffffff">通过上述改造和设计，OSTree 实现了不可变系统的特性，提供了一种可靠、稳定的系统更新和管理机制。它改变了传统系统的文件系统结构、启动、版本管理和更新方式，为系统提供了更好的可信度、可靠性和维护性。</span></p><p>&nbsp;</p><p>0<span>6</span><strong>关于 UpdateManager SIG</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">openKylin 社区 UpdateManager SIG 小组，致力于新一代操作系统不可变系统相关技术研发，包括系统架构、OStree、系统更新组件等，提供不可变系统相关的技术规划、设计、开发、维护和系统升级等服务。openKylin 基于 OStree 的不可变系统将成为数字化未来的重要引领者，为用户带来更加稳定、安全和高效的数字化体验。</span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">SIG 主页：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#0b43d1">https://gitee.com/openkylin/community/tree/master/sig/UpdateManager</span></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 01:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276872</guid>
            <link>https://www.oschina.net/news/276872</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百度搜索结果被 Microsoft Edge 浏览器封禁，搜索结果页「全红」警示]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong><span style="background-color:#e67e22">更新：</span></strong>1 月 29 日 18 时许，网友通过 Microsoft Edge 浏览器使用百度搜索，发现相关问题已不存在，目前可正常使用。</p><p>至于此次问题的原因，有网友透露：「这是百度今天给网站加了重定向，点进去之后就会发现广告都是先进百度的网站，然后跳转一次，之前是直接跳转的，没有中间这个先进去百度的网站，这种重定向操作本就是诈骗和广告网站常用的，所以直接被列为高危了很正常。」</p><hr><p>1 月 29 日下午消息，今日，# Edge#话题登上热搜，据多位网友反馈，浏览器提示百度搜索结果不安全， Edge 浏览器将百度的搜索结果显示为「此网站已被人举报不安全」的警告语，需要展开详细，然后选择「继续访问此不安全站点（不推荐）」才能访问相关页面。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fdd5e488d1f44785059f7a586d3696390e8.png" referrerpolicy="no-referrer"></p><p>截至目前，相关问题仍未修复，在 Microsoft Edge 浏览器上点击百度相关链接，全部页面显示「红色」警示。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2Fchanjing%2Fgsxw%2F2024-01-29%2Fdetail-inafeqqm7979703.d.html" target="_blank">新浪科技称</a></u>已向百度以及微软中国方面进行求证，但双方均回应称暂不清楚情况，正向业务问询了解情况。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 09:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276851</guid>
            <link>https://www.oschina.net/news/276851</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 版权第一案：我用 AI 做的图，版权归我吗？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近，一个跟 AI 相关的案子引起了全国同行的围观，原因是一个百家号作者在网上写文章时，用了一张网上的 AI 图片当配图，结果被图片的生产者告侵权。这不禁让人紧张：以后 AI 产的图片，还能随便用吗？会不会侵权？</p><p>事情是这样的——</p><p style="text-align:left">2023 年 2 月，李昀锴使用 Stable Diffusion 模型，通过在模型上输入数十个提示词，设置相关迭代步数、图片高度、提示词引导系数以及随机数种子等，生成了数张人像图片。随后，李昀锴以 「春风送来了温柔」 为名发布在社交平台小红书上。2023 年 3 月 2 日，百家号一自媒体账号发布的名为《三月的爱情，在桃花里》的文章使用了李昀锴制作的图片。</p><p style="text-align:center"><img height="768" src="https://oscimg.oschina.net/oscnet/up-f6cf6dc908fcf7b1c685805400c6c984609.png" width="512" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#999999"><em>李昀锴用 Stable Diffusion 模型生成的图片</em></span></p><p style="text-align:left">李昀锴认为，对方未获得他的许可就截掉了他在小红书平台的署名水印进行发布，侵犯了署名权及信息网络传播权，应当承担法律责任。</p><p style="text-align:left">2023 年 5 月，李昀锴起诉被告刘某侵害作品署名权、信息网络传播权纠纷一案在北京互联网法院立案。</p><p><strong>这里最关键的争议在于，李昀锴基于自己设定的提示词和参数，使用 Stable Diffusion 模型制作的图片 「春风送来了温柔」 是否构成作品？以及构成哪一种类型的作品？</strong></p><p style="text-align:left"><strong>法院认为，原告李昀锴使用</strong><strong>开源软件</strong><strong> Stable Diffusion 创作的图片由其独立完成，体现了他的个性化表达，因此涉案图片具备 「独创性」 要件。涉案图片符合作品的定义，属于美术作品，受到著作权法的保护。最终判决李昀锴胜诉，被告需在百家号平台公开道歉，并向原告赔偿 500 元</strong>。</p><p style="text-align:left">这个案件，也成为了 AI 生成图片相关领域著作权第一案，让 AI 领域的从业者和使用者都提高了警惕：</p><p>原来 AI 创作的图片也是有著作权的，那以后使用 AI 图片还得注意授权问题了？</p><p>AI 图片很多都是用别人的图片「溶」出来的，相当于「二创」。这种做法放在文艺领域早被当成抄袭了，为啥它还能享有著作权呢？这是不是合理的？</p><p>我用 AI 创作的图，总共有哪些权利和风险？权责如何划分？</p><p>对此，我们邀请了知识产权领域的专业律师邓超进行对谈，一起聊聊究竟怎么回事。</p><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>01 AI 作品，版权并不明晰</h1><p><span style="color:#245bdb">开源中国：首先我们捋清一下概念，版权和著作权是一回事吗？</span></p><p>&nbsp;</p><p>邓超：是的，著作权和版权没有区别。根据相关法律规定，著作权是指作品的作者等相关人员，依法对其已经完成的作品所享有的发表权、署名权、复制权、保护作品完整性权等。<strong>且著作权即版权。</strong></p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：OK，那在现行法律当中，个人或单位使用 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 生产的图片，拥有版权吗？</span></p><p>&nbsp;</p><p>邓超：<strong>在现行法律当中，这块还没有明确规定，行业意见也不统一，需要进行个案分析。</strong></p><p>前年北京互联网法院有一个「菲林诉百度案」，当时法院认为，机器生成的内容是没有版权的。</p><p style="text-align:center"><img height="625" src="https://oscimg.oschina.net/oscnet/up-d4964bffd09758af1e3dbb525b78e0b065e.png" width="1421" referrerpolicy="no-referrer"></p><p>但是在深圳的「腾讯新闻案」，法院则认为，机器生成的内容有版权。</p><p style="text-align:center"><img height="687" src="https://oscimg.oschina.net/oscnet/up-9672009ee8539049d0417268a64ca6f9a30.png" width="1437" referrerpolicy="no-referrer"></p><p>一南一北，对这个问题给出了不同的答案，但是这些案子都没有上诉，所以说现在还没有一个统一的意见。今天这个案子里，北京互联网法院就认为，AI 生成的图片是有版权的。但是，北京互联网法院它是个基层法院，判决的效力有限，不好说能不能全国推广。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：那 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 生成的图片所拥有的权利很模糊啊？</span></p><p>&nbsp;</p><p>邓超：也不能说很模糊，它有一个判断的过程。判决也强调了，<strong>利用人工智能生成的内容是否构成作品，需要视个案情况而定，不能一概而论。</strong>在这个案子里，这张图片的生成涉及了上百个提示词和参数的调整，在这种情况下，法院会认可这个创作者是付出了一定的创造性劳动的。相反，假设只是跟 AI 说「画一幅秋天的风景画」，那这个在我看来就不能有版权了，因为没付出什么符合著作权法要求的创作。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：可是，这些为创作而输出的参数和设定，多少算多，又多少算少呢？</span></p><p>&nbsp;</p><p>邓超：是的，这里恰恰就是判断的难点，可能在每个案子里，每个法官的判断都会不一样。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：有律师认为，</span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 作图跟传统的美术创作有很大的区别，原告只输出了提示词，并没有动笔去画具体的线条，也没有百分之百地告知 Stable Diffusion 模型怎样去画出具体的线条和色彩，就通过人工智能生成了图片。</span><span style="color:#245bdb"><strong>根据《著作权法》的传统理论，人创作的作品才受版权保护，原告李昀锴的行为并不构成创作。</strong></span><span style="color:#245bdb">你怎么看？</span></p><p>&nbsp;</p><p>邓超：是的，这种反对的观点还挺普遍。做个类比，我让一位画家画一幅秋天的风景画，但我不能在画家画完了之后说「我是这幅画的作者」。这是不合理的。</p><p>还有一种反对观点，它的逻辑是：即使我说了「画一幅秋天的风景画」这句话，不同的人他会画出不一样的东西，不能因为我说了这句指令，我就拥有了画的著作权，这是很奇怪的。像秋天的风景这种东西，本来就是一千个人一千种画法，即使是 AI ，不同的 AI 画出来的也不一样。甚至相同的 AI ，你让它再画一遍，都不一定画得出来。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：即使是相同的参数，它也不一定会生成同样的图。</span></p><p>&nbsp;</p><p>邓超：是的，没错。但是这个类比，只能放在人身上，放在 AI 身上就不太一样，因为 AI 它是一个机器，不是具体的人，是没有权利的。如果这幅图是我让一个人来画的话，那著作权肯定就属于画画的那个人了。但 AI 它不是人，它没法成为作者。<strong>现阶段，生成式人工智能模型不具备自由意志，无论是国内还是国外，都不支持 AI 成为法律上的主体。</strong></p><p>这也是法院在这个判决中做出的考量。目前来讲，无论是认为 AI 作品应该有版权还是不应该有版权，其实都能解释得通，因为 AI 这东西是新兴的，法律比较落后，现在还没有达成一致说这种情况应该怎么办？所以，法院现在判决的时候，更多是从产业或者立法目的的角度，去解释说：这 AI 是把它保护起来比较好，还是不保护更好？</p><p>在这个案子里面，原告为了生成这张图片，输入了大量的指令，调整了上百个参数，如此正向反向的一系列约束下来，才得到这张图。这个过程，在法院看来，是有一定的独创性的。咱们国家法律规定的独创性很低。比如说摄影作品，摄影师等了一天安排了特定角度拍出来的图，大家会认为有独创性；但咱们普通人随便拍的图，一般来讲也是有独创性的，即使你没调参数，也没啥构思。所以说，<strong>独创性，这东西的门槛就很低，不需要达到什么专业高度就能拥有。</strong></p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：可是拍照这事儿是我们自己动手拍的，不是别人告诉我怎么拍的。</span><span style="color:#245bdb"><strong>而且用 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 的话，即使描述得再具体，它也只是文字创作，不是美术创作，</strong></span><span style="color:#245bdb">它对于创作结果是不能预见也无法控制的，这与人们之前使用画笔、绘图软件去作图有很大的不同。</span><span style="color:#245bdb"><strong>它是「文生图」，不是「手作图」。</strong></span></p><p>&nbsp;</p><p>邓超：所以说，这里其实是一个价值取向的问题，给不给版权保护都说得通。</p><p>有一种反对观点认为，比如说「画一幅秋天的风景」这个指令，可以拥有文字性的版权，但这个文字性的版权，不能延伸到它生成的图片，不然以后所有的秋天风景画都侵犯了我的版权了，因为我最先说了这句指令。</p><p><strong>不过，从历史的角度来看，各种形式的创作，要获得版权保护都是一个时间问题。</strong>比如说摄影技术刚诞生的时候，大家觉得摄影也不应该给版权，因为摄影出现之前，大家都是用油画，可能得花几十年学习，才能把风景画得很像。结果摄影技术出来之后，不需要任何绘画功底、也不用学几十年，只需按一下快门，就能得到一幅比你学了十几年画画还要接近真实的画，所以大家都认为它不是艺术，不应该给版权。可是后来你看，随着技术的发展，摄影慢慢地也成为一门艺术了。</p><p>从历史的视角来看，每当有新的事物出现，它总会面临一些争议，比方说要不要给版权？但是我们可以想办法把版权保护做得更好，在保障权利的同时适应新事物的出现。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>02 新情况可以参照现有法律吗？</h1><p><span style="color:#245bdb">开源中国：现在有一种想法是将 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 创作类比成互联网产品。比方说程序员在后台输入代码，通过计算机生成了一个 APP，生成了它的各种功能。但是代码不属于美术作品，谁来写都一样，能实现就行，同一个功能背后的代码可能是一模一样的。在 AI 创作中，提示词就相当于创作的「代码」，生成的图片就类似于前台的 APP，那这个提示词是不是也是谁来写都一样呢？还应该有版权吗？</span></p><p>&nbsp;</p><p>邓超：在智力创作这一块，法律要求的门槛很低，毕加索的画有版权，小学生的画也一样有，并不以智力贡献的高低来衡量，只要是你写的就能有版权。</p><p>所以，代码也是可以享有版权的，像软件著作权登记，它登记的就是这个代码。如果你写了一个代码，别人抄袭你的代码，那也是构成著作权侵权的。只不过代码的著作权仅限于这个文字代码本身。</p><p>最开始，把代码当成文学小说来保护，也是有争议的。毕竟文字它没有任何实用的功能，但是代码，它唯一的目的就是实现功能。但是版权法不保护功能，要想保护功能可以用专利。所以最开始把代码视为文学小说就有这么一个不自洽的地方。那么法律后来就规定了，<strong>实现某个功能的唯一或者非常有限的代码，它是不能受版权保护的。</strong>比如说，单独写一个「弹出提示框」，仅仅这么一点东西，是没法被版权保护的。<strong>但要是整个程序，比如像微信，作为一个整体来讲，它就受到版权保护。</strong></p><p>要是拿音乐来类比的话，单个音节，像 do、rei、mi、fa、so 本身是没法保护的，但是你把它编成一首曲子，那这首曲子就能受到版权保护。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：意思就是它得作为整体的一个作品来呈现才能算。</span></p><p>&nbsp;</p><p>邓超：对。但是要说得呈现到啥程度，这其实并没有一个清晰的线。比方说一首歌算，那其中一段算不算呢？这就得到具体案件里面，进行具体分析了。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：人工智能的软件是可以大规模复制的，只要</span><span style="color:#245bdb">算力</span><span style="color:#245bdb">足够，短时间生成海量的图片完全没有问题。如果这都可以获得著作权保护，对整个社会而言，会不会起不到鼓励创新的效果？</span></p><p>&nbsp;</p><p>邓超：是这样，现在从实践来讲，很多图片没法判断是不是 AI 生成的，除了那些手画不好的之外，其实很难分辨。在这种情况下，<strong>咱们默认所有图片都是有版权的就行了，不要在意它是不是 AI 生产的，这跟 AI 没关系。</strong>咱们在用图的时候，就两个原则：你独创的，或者是合法购买许可的，那就用；如果不是，那就别随便用。不能在网上看到一个图片就随手拿过来，这无论是不是 AI 生产的，风险都很大。</p><p>如果说我用 AI 大模型生成的图，跟别人生成的一样，比方说一样的提示词下 AI 给我们都出了一样的图，那也没关系，因为这是你独立创作的，就可以避免法律风险，哪怕对方来起诉也不怕。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：就是说</span><span style="color:#245bdb"><strong>我们用同一个 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 同一套提示词生成的两张图，我们各自分别都有著作权，哪怕这两张图一模一样？</strong></span></p><p>&nbsp;</p><p>邓超：是的，因为咱们讲的是独创性，只要这是你独立完成的，那就没有问题。比如说，两个人同时拍天安门广场升旗的图片，可能俩人的角度非常像，拍出来的图片几乎一样，在这种情况下，各自都有著作权，没有任何人侵权。但如果真到了法庭那个阶段，你就得拿出证据证明这图确实是我拍的，不是我扒的。像这个案子里，被告把原告图片水印都截掉了，那肯定是在网络上扒的，肯定侵权。但如果被告的时候，能把原图或提示词都拿出来，证明确实能生成这图，那被告侵权就不成立了。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：但如果要重现的话，万一输入同样的提示词，</span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 生成的图不一样，那不就没法自证了？</span></p><p>&nbsp;</p><p>邓超：理论上是这样，但另一方面来看，这些图片侵权的案子，判赔额都很低，这个案子判赔 500，其他案子更少，一般就几十块钱，风险很小。如果是自创图片的话，虽然不一定保留有创作过程，但肯定会留痕，实在不行还能找证人出庭作证，总之肯定能查清，所以对现状不会有什么颠覆性的影响。</p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>03 AI 创作，风险大大的有</h1><p><span style="color:#245bdb">开源中国：说到独创性，</span><span style="color:#245bdb"><strong>目前很多的 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 图片，都是用别人现有的图片「溶」出来的，这样也能算独创性吗？这不算抄袭吗？</strong></span></p><p>&nbsp;</p><p>邓超：当前刚好有一个案子：2023 年 12 月 27 日，《纽约时报》起诉微软和 OpenAI，宣称报社数百万篇文章被用作 AI 的训练数据，这些数据的投喂到底是属于合理使用还是版权侵权，现在也没有定论，可以密切关注一下。</p><blockquote><p>「合理使用原则」是指，虽然你的行为严格来说算侵权，但你的行为是一种可以接受的借用，用来促进创造性的表达。例如，学者可以在自己的作品中引用摘录他人内容；作者可以出版改编图书；普通人可以截取电影片段做影评。换句话说，如果对版权限制过死，文明的创造力将可能停滞。</p><p>科技公司长期利用这一原则来规避版权争议。2013 年，谷歌因为复制数百万册图书并在线上传书里的片段，遭到作家协会的起诉，法官基于合理使用原则，裁决谷歌这一行为合法，因为它为公众创建了可搜索的索引，创造了公共价值。在大模型时代，合理使用原则仍可能发挥关键作用。支持 AI 不侵权的人认为，<strong>大模型生成内容的过程，跟人类创作相差无几——当你尝试画一幅画或拍一支视频，你的脑海里也会有你看过的画或电影。人类的创作在前人的基础上进步，大模型也是如此。</strong></p></blockquote><p><strong>现实总是领先法律一步：现实里出现问题了，法律再进行回应，现在刚好卡在了没达成一致意见的时候。</strong></p><p><strong>从本质上来讲，著作权法、</strong><strong>知识产权</strong><strong>法的目的都是为了促进社会的繁荣。</strong>像远古时代，没有什么知识产品，宋代印刷术出现之前，大家都是用手抄本，但大家都认为这是好事，可以防止文献失传。印刷术出现之后，才慢慢有了著作权。立法者认为，对作品作者给予一定保护，可以激发其他人创作出更多的作品来。现实也的确是这样，发达国家都有着非常完善的知识沉淀。所以本质来讲，还是看怎么选择更能促进产业和整个社会的发展。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：说到促进创作，这里我要讲一下，</span><span style="color:#245bdb"><strong>在美术界，相似度达到 10% 就属于抄袭了，但是 </strong></span><span style="color:#245bdb"><strong>AI</strong></span><span style="color:#245bdb"><strong> 现在是在不声明的情况下抄袭，并且不以任何代价使用，这不就跟促进创作的初衷刚好相反了？</strong></span><span style="color:#245bdb">如果一做出来就会被抄袭，那不正好打击了人们创作的积极性，挤压人的创作空间吗？</span></p><p>&nbsp;</p><p>邓超：对，是这样。<strong>任何一个东西，政策的影响都是两方面的，</strong>你说的是负面的一方。但从正面来讲，以前创作图片，需要美工先学十年美术，美工画一幅图要画一天。但现在，任何一个没有学过美术的人，也可以创作出一幅画了。从这方面来讲，生产力肯定是大大提高了，AI 一天生成的图就能顶 100 个美工的创作。当然，最后肯定还需要微调，但这生产率已经翻倍了。</p><p>假设现在一个公司需要 100 张图，如果找美工，成本是十万块钱；但找一个 AI 的话，可能就 1000 块钱，加上后期人工修改可能只需一万。从公司的角度来讲，它的成本就降低了，变得更有竞争力了，但背后可能就有十个美工失业了。可是从另外一个角度来讲，可能又会有十个 AI 相关的就业岗位增加。</p><p>所以 AI 这个东西，它就像蝴蝶效应一样，一个因素改变带来的社会变化非常复杂，有人受益，就会有人受损，所以这里很难预测，也不是我一个人能想明白的事。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：在风险这块，举个例子：假设我用 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 做图的时候，只输了文字</span><span style="color:#245bdb">指令</span><span style="color:#245bdb">，但 AI 在训练的时候被喂了有版权的图片，所以</span><span style="color:#245bdb"><strong>产出给我的图片也侵权了，那是我负责还是 AI 公司负责？</strong></span></p><p>&nbsp;</p><p>邓超：按照咱们讨论的这个案子来讲，肯定是你负责，因为 <strong>AI</strong><strong> 它只是一个工具，就跟画笔或者照相机一样，最后出问题可能还是得人来负责。</strong>除了我们刚才说的「纽约时报诉 OpenAI 案」，因为 OpenAI 是在训练的时候使用了纽约时报的内容，所以要 OpenAI 负责。但是现在 OpenAI 已经把产品软件提供出来了，你用这个 AI 软件生成的图片，如果侵权的话，（虽然现在还没有案例），AI 工具它大概率是没有责任的，责任在你。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：可是我本意没有想要侵权任何人，也不是我让这个 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 去抄袭别人的，甚至我都不知道别人作品的存在，是 AI 公司训练的时候喂了有版权的图导致的生成作品侵权，这种情况我是没法控制的，也需要我来负责吗？</span></p><p>&nbsp;</p><p>邓超：确实，你问的这三个问题，是 AI 时代最棘手的三个问题，现在都没有人有答案：</p><p><strong>第一，</strong><strong>大模型</strong><strong>使用海量数据来进行训练，这种行为到底是侵权还是合理使用？</strong></p><p><strong>第二，</strong><strong>AI</strong><strong> 生成的作品到底有没有版权？（今天讨论的这个案子里北京互联网法院已经初步给出了意见）</strong></p><p><strong>第三，用 </strong><strong>AI</strong><strong> 生成的作品侵权了究竟谁来承担责任？</strong></p><p>这三个问题现在没人能有答案，我刚才说的，只是我个人的观点。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：那意思就是说，有好处的话，是使用者获得，如果是风险的话，也是使用者承担。那 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 公司它岂不是只负责赚钱不承担风险？</span></p><p>&nbsp;</p><p>邓超：简单来说是这样，但具体的还得结合具体案情来讲。</p><p>企业的风险就是我们说的第一个问题：用别人的内容来训练 AI 模型，属不属于合理使用？这时候的政策是很敏感的。假设这算合理使用，企业风险很小，那一定程度上会促进 AI 产业的发展，因为企业没啥后顾之忧了；但如果让企业承担很大的责任，那一些刚发展起来的小公司搞不好会因为法律诉讼破产，这样就阻碍了行业发展。法律也好，判决也好，肯定都是要考虑产业发展的。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：但是也不能光揽好处，把风险甩给用户去跟原作者扯皮吧？</span></p><p>&nbsp;</p><p>邓超：对，但是有人受益，肯定就有人受损，这个不太可能双赢，就看你价值取向更偏向谁。比如产业早期的时候，可能倾向于促进产业发展；等产业发展成熟了，公司壮大了，还一点责任都不承担就不太好了。不同阶段，产业政策不一样，法律方面的话，至少在我看来，裁判者也好，立法者也好，都是需要平衡的。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：伴随着人工智能、大语言模型的发展，</span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 创作这种生产方式，还可能会触及哪些法律问题？</span></p><p>&nbsp;</p><p>邓超：除了上面讲到的三点，还有就是<strong>可能会侵犯别人的肖像权</strong>，比方说生成的人像跟别人长得一样，可能就会侵犯肖像权，这也属于第三点中侵权的一种形式吧。</p><p>&nbsp;</p><p><span style="color:#245bdb">开源中国：法律届是怎么看待 </span><span style="color:#245bdb">AI</span><span style="color:#245bdb"> 创作这一新的生产模式的？接下来会不会出台相关的法律法规呢？</span></p><p>&nbsp;</p><p>邓超：按照过往的历史经验来看，不会这么早出台法律。以往像互联网之类的新事物，法律界都会先让子弹飞一会儿，先观察一阵，等到时机成熟了，再出台相关法律法规。另外，咱们现在的知识产权法的框架，足以解决目前跟 AI 相关的一些问题，还没有必要单独针对 AI 立一个法。可能等时机成熟了，会完善法律下面的一些解释或规定吧。</p><hr><p>对此，各位怎么看？你认为 AI 作品应该有版权吗？我们评论区见吧~</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>本期嘉宾：</strong>邓超 | 律师（微信号：dengchao）</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="560" src="https://oscimg.oschina.net/oscnet/up-0fa35e5b407c4ce45828bd4c6e0c8078989.png" width="400" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">具有理学学士和法学博士学位，有着深厚的法学理论基础；在知识产权行业从业十余年，有着丰富的实践经验。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">长期专注于科技和媒体领域的知识产权前沿问题的研究和实践，代表客户处理相关的诉讼和非诉法律事务。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">在进入律师事务所之前，曾就职于世界 500 强公司的法务部以及国内顶尖的知识产权事务所，为众多跨国公司、国内上市公司等提供知识产权法律服务。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10992795</guid>
            <link>https://my.oschina.net/u/6852546/blog/10992795</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[工信部等七部门联合发文：发展下一代操作系统、推广开源技术、构建开源生态体系]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>工业和信息化部、教育部、科技部、交通运输部、文化和旅游部、国务院国资委、中国科学院等七部门近日联合印发<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gov.cn%2Fzhengce%2Fzhengceku%2F202401%2Fcontent_6929021.htm" target="_blank">《<u>关于推动未来产业创新发展的实施意见</u>》</a></em>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-77dbe7b14ccd70bf436e9b444bcb994dcdd.png" referrerpolicy="no-referrer"></p><p>其中提到的重点任务包括：</p><ul><li><strong>（一）全面布局未来产业</strong></li><li><strong>（二）加快技术创新和产业化</strong></li><li><strong>（三）打造标志性产品</strong></li><li><strong>（四）壮大产业主体</strong></li><li><strong>（五）丰富应用场景</strong></li><li><strong>（六）优化产业支撑体系</strong></li></ul><p>在「打造标志性产品」章节，意见提出要<strong>做优信息服务产品</strong>：</p><p><strong>发展下一代操作系统，构筑安全可靠的数字底座。推广开源技术，建设开源社区，构建开源生态体系</strong>。探索以区块链为核心技术、以数据为关键要素，构建下一代互联网创新应用和数字化生态。面向新一代移动信息网络、类脑智能等加快软件产品研发，鼓励新产品示范应用，激发信息服务潜能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d3c823b6016f70ba58bb95c2ae81c353cce.png" referrerpolicy="no-referrer"></p><p>原文：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FN9YYFWtcrNfAX1TYqY7G1A" target="_blank">https://mp.weixin.qq.com/s/N9YYFWtcrNfAX1TYqY7G1A</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 03:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276882</guid>
            <link>https://www.oschina.net/news/276882</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥🔥 mac 中使用 rz sz 新姿势 🔥🔥]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>macOS 使用 zmodem ( rz / sz ) 的新方法，支持 iTerm2 等任意有本地 shell 的终端</h2><h3><strong>1、本地安装<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">trzsz-ssh ( tssh )</a></strong></h3><ul><li>开源地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">https://<span>github.com/trzsz/trzsz-ssh</span></a></li><li><span>Gitee 地址：</span><a href="https://gitee.com/trzsz/tssh">https://gitee.com/trzsz/tssh</a></li></ul><div><pre><code class="language-text">brew install trzsz-ssh</code></pre></div><h3>2、本地安装 lrzsz</h3><div><pre><code class="language-text">brew install lrzsz</code></pre></div><h3>3、配置 ~/.ssh/config</h3><div><pre><code class="language-text">Host *
    #!! EnableZmodem Yes</code></pre></div><h3>4、使用<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">trzsz-ssh ( tssh )</a><span>&nbsp;</span>登录服务器，用法与 ssh 完全一致：</h3><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">trzsz-ssh ( tssh )</a><span>&nbsp;</span>额外支持的功能详见文档：<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftrzsz.github.io%2Fcn%2Fssh" target="_blank">https://<span>trzsz.github.io/cn/ssh</span></a></li></ul><div><pre><code class="language-text">tssh xxx</code></pre></div><h3>5、服务器上安装有 lrzsz ，就可以正常使用 rz / sz 了，不再赘述：</h3><div><pre><code class="language-text">rz # 上传文件
sz xxx # 下载文件</code></pre></div><h3>6、如果服务器可以安装 trzsz ( trz / tsz )，则可以解锁更多功能：</h3><ul><li>详见文档：<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftrzsz.github.io%2Fcn%2F" target="_blank">https://<span>trzsz.github.io/cn/</span></a></li></ul><div><pre><code class="language-text">trz # 等价于 rz
tsz xxx # 等价于 sz xxx</code></pre></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276878</guid>
            <link>https://www.oschina.net/news/276878</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><p><strong># 2024.1.29&nbsp;</strong></p><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要点</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/276738/search-with-lepton-opensource" target="news">贾扬清最新开源项目 —— 500 行代码构建的 AI 搜索工具</a></u></h3><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#595959">贾扬清前几天在社交平台介绍了自己开发的 AI 应用 Lepton Search —— 一个用 500 行 Python 代码构建的对话式 AI 搜索工具</span></span></span><span><span><span style="color:#595959">。</span></span></span><span><span><span style="color:#595959">Lepton Search 的后端是 Mixtral-8x7b 模型，托管在 LeptonAI，输出速度能达到每秒大约 200 个 token，搜索引擎采用了 Bing 的搜索 API。</span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span style="color:#595959">目前 Lepton Search 已正式开源，包含完整前后端源代码，采用 Apache License，可商用。</span></span></span></span></span></p><p><img src="https://oscimg.oschina.net/oscnet/up-653f2a2bd37324fb0d75d8ceb45ba2c5187.png" referrerpolicy="no-referrer"></p><h3><u><a href="https://www.oschina.net/news/276824/16-bit-cpu-built-and-runs-in-excel" target="news">大神只用 Excel 就构建了一颗 CPU：具有 128kb RAM、配备汇编语言</a></u></h3><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#595959">YouTube 科技博主「Inkbox」近日发布视频介绍如何在 Microsoft Excel 的限制下构建功能齐全 CPU。Inkbox 称没有使用任何 Visual Basic 脚本或插件 —— 完全用 Excel 实现。</span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#595959">据介绍，这是一颗 16 位 CPU，在 Excel 中构建并以 3Hz 时钟频率运行，具有 128KB RAM、16 色 128x128 像素显示屏和自定义汇编语言，所有这些都在 Excel 中运行</span></span></span><span><span><span style="color:#595959">。</span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-05bafb20ee50b854fae8d35fd3dd39d81d6.png" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="color:#595959">这个 Excel CPU 项目最令人印象深刻的壮举之一是 Inkbox 为其创建了功能完整的汇编语言 Excel-ASM16，它包含 23 种不同的指令，并支持变量、标签，甚至二进制文件。虽然这些是汇编语言的基本功能，但对于在 Microsoft Excel 下运行的 16 位 CPU 的限制来说已经足够了。</span></span></span></span></span></p><h3><u><a href="https://www.oschina.net/news/276779/ubuntu-24-04-will-use-linux-6-8" target="_blank">Ubuntu 24.04 LTS 默认内核将采用 Linux 6.8</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Canonical 公布了 Ubuntu 24.04 LTS 的内核计划，并表示将正在开发的 Linux 6.8 作为下一个长期支持 Ubuntu 桌面 / 服务器发行版的默认内核。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">此前许多人在讨论&nbsp;Ubuntu 24.04 LTS 会采用哪个内核版本，有人觉得是 Linux 6.6 LTS，因为它在 2023 年成为了长期支持版本。也有人认为是最新的稳定内核 Linux 6.7，该版本有很多有用的新特性。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">现在 Canonical 工程师 Andrea Righi 宣布了在 Ubuntu 24.04 中采用 Linux 6.8 作为默认内核的暂定计划。目前实验性内核构建已经可以通过 PPA 获得。</p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">用户观点</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-9f8ec1ffe5a4c0214de25d655fcee74a996.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">媒体观点</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-dabde0b7612b466a0720487e9cba9a008de.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日项目榜</span></span></span></span></span></span></strong></h2><p>GitHub 榜单：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9c14f4f693a1964be35334f161b0b67f9eb.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6ca82877deafa256f357e48b095ec561b11.png" referrerpolicy="no-referrer"></p><blockquote><h4>在线阅读完整日报内容，访问：<strong><em><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC004%E6%9C%9F%EF%BC%9A%E5%A4%A7%E7%A5%9E%E5%8F%AA%E7%94%A8%20Excel%20%E5%B0%B1%E6%9E%84%E5%BB%BA%E4%BA%86%E4%B8%80%E9%A2%97%20CPU.pdf" target="_blank">开源日报第 004 期：大神只用 Excel 就构建了一颗 CPU</a></u></em></strong></h4></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 28 Jan 2024 14:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276864</guid>
            <link>https://www.oschina.net/news/276864</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
