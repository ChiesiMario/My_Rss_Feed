<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 08 Jan 2024 17:54:31 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[年度盘点｜深圳工信十件大事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>「i 深圳」官微<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_8-u5N6_fIBUYJZGu1fGYg" target="_blank">发文</a>盘点了 2023 年深圳工信十大事件，具体如下：</p><p><span style="color:#007aaa"><strong>一、企业创新主体地位不断强化，「深圳制造」爆款迭出</strong></span></p><p><span style="color:#595959">企业研发投入达 1784.6 亿元，约占全社会研发投入比重 94.9%，位居全国第一。华为推出全球首款支持衞星通话和应用星闪技术的 Mate 60 系列手机产品，引发线上线下抢购热潮；荣耀推出全球最轻薄大内折高端机 Magic V2，引领折叠屏厚度进入「毫米时代」；仰望 U8、问界 M9 等高端车型先后发布，搭载业内领先的自研车身控制系统和智能科技配置，代表了全球高端新能源汽车前沿水平。</span></p><p><img height="383" src="https://oscimg.oschina.net/oscnet/up-c427126861041278cce2734057b420f8024.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#007aaa"><strong>二、「新一代世界一流汽车城」建设全面提速，比亚迪勇夺全球新能源汽车销冠</strong></span></p><p><span style="color:#595959">高标准规划建设「新一代世界一流汽车城」，全市全年新能源汽车产量继续实现翻倍增长。汽车出口屡创新高，全市新车电动化渗透率、充电基础设施密度全国领先，新能源汽车保有量超 96 万辆，入围国家首批公共领域全面电动化一类试点城市。全力支持深汕特别合作区建设世界级汽车制造城，深汕比亚迪汽车工业园二期建成投产，东风李尔、壁虎科技、佛吉亚等一批新能源汽车产业链上下游明星企业集聚深汕。比亚迪累计下线超 600 万辆新能源汽车，2023 年全年销售汽车 302.44 万辆，同比增长 61.9%，一举夺得全国汽车年度销冠、全球新能源汽车销冠，创下中国汽车年销量最高纪录，新能源汽车行业迈向规模化、全球化高质量发展之路。</span></p><p><img height="395" src="https://oscimg.oschina.net/oscnet/up-37f0d216108702b10da9071d67a72e94422.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>三、优质通用大模型接连推出，人工智能全域全时场景应用加快拓展</strong></span></p><p><span style="color:#595959">印发实施《深圳市加快推动人工智能高质量发展高水平应用行动方案（2023-2024 年）》，构建「一条例、一方案、一清单、一基金群」的政策体系。华为云盘古 3.0。腾讯混元、云天励飞天书等一批高水平通用大模型陆续推出。升腾系列芯片成为国内具备全栈技术的最高水平的人工智能算力芯片。累计发布人工智能清扫等 41 个「城市+AI」场景，举办人工智能专场产学研对接系列活动，人工智能全域全时场景应用加快拓展。</span></p><p><img height="323" src="https://oscimg.oschina.net/oscnet/up-09bda6383445c51b8c4c7c3c38d87601298.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>四、开源鸿蒙欧拉产业高地建设再上台阶，「软件名城」获评「三星级」</strong></span></p><p><span style="color:#595959">印发实施《深圳市推动开源鸿蒙欧拉产业创新发展行动计划（2023—2025 年）》，全体系增强操作系统技术能力，开源鸿蒙装机量已超过 7 亿台，开源欧拉装机量占据国内服务器市场份额近 4 成。落地全球智慧物联网联盟等国际组织，建设鸿蒙生态创新中心，加快推动我国操作系统技术创新和高水平自立自强。在全国「软件名城」考核中名列前茅，获评最高等次「三星级」。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="275" src="https://oscimg.oschina.net/oscnet/up-45f99849e79a7af19baff203be73c45bcee.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>五、75 个「工业上楼」项目开工建设，高标准谋划共建产业园区</strong></span></p><p><span style="color:#595959">持续加大产业用地用房供应，积极稳妥推进「工业上楼」，为制造业高质量发展提供强有力空间保障。2023 年开工建设 75 个「工业上楼」项目，预计可提供总建筑面积超 2000 万㎡。龙岗宝龙专精特新产业园正式开园，全国首个全装配式智能产业园坪山区新能源汽车产业园交付使用，推广实现「上下游就是上下楼，产业园就是产业链」。与汕头、潮州等地加大产业合作力度，高标准谋划共建产业园区，努力实现优势互补、合作共赢。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="351" src="https://oscimg.oschina.net/oscnet/up-0e185217af6add18c0a3dc295242507811b.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#007aaa"><strong>六、中小企业发展环境综合排名全国第一，专精特新「小巨人」增量全国第一</strong></span></p><p><span style="color:#595959">《2022 年度中小企业发展环境评估报告》发布，深圳中小企业发展环境综合排名全国第一。「深 i 企」平台用户数突破 300 万。创新开展「我帮企业找市场」等系列行动，线上打造供需对接平台，线下开展上百场各类主题的「链上配对」精准对接服务，帮助企业拿订单、拓市场，打通上下游合作「最后一公里」。2023 年新增专精特新「小巨人」企业 309 家，新增数量居全国大中城市第一，总数达 742 家、位列全国第二。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="350" src="https://oscimg.oschina.net/oscnet/up-bb68fd01669b2204acf6e1a401f88b4d831.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>七、千兆城市建设水平领跑全国，率先迈入 5G-A 时代</strong></span></p><p><span style="color:#595959">启动「极速宽带先锋城市」建设行动，全年新增 5G 基站超 1 万个、累计建成超 7.5 万个，重点场所 5G 网络通达率 100%，多项千兆城市指标位居全国大中城市首位。启动数字家庭 3T 跃升行动试点，深圳市公共场所 WIFI 管理平台累计服务近 3 亿人次，为市民节省约 1.7 亿元流量费，市民生活数字化服务水平得到大幅提升。出台《深圳市算力基础设施高质量发展行动计划（2024-2025）》，力争将算力打造成像水、电「一点接入、即取即用」的基础设施，夯实数字经济发展「底座」。全面加速 5G-A 行业应用创新与产业融合发展，成为全球首个迈入 5G-A 时代的城市。</span></p><p><span style="color:#007aaa"><strong>八、一批重大先进制造业项目落地，工业投资实现高速增长</strong></span></p><p><span style="color:#595959">市区协同、部门联动，赴法国、德国、马来西亚、沙特等 25 个国家和北京、上海等 30 多个城市精准招商，招引西门子、椭圆星池、京西重工、壁虎科技等一批国内外知名企业重点项目成功落地。推动与中国一汽、中国化学、中汽中心等一批央企签署合作协议，打造央地产业合作新典范。全年先进制造业领域成功招引落地百亿以上项目 8 个，10 亿以上项目超 80 个，投资金额合计超 4000 亿元。2023 年工业投资规模再创历史新高，实现增长超 30%。出台《深圳市关于新形势下加快工业企业技术改造升级的若干措施》，将重大项目支持金额上限提高至 1 亿元，推动 1200 余家企业开展技术改造。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="318" src="https://oscimg.oschina.net/oscnet/up-d1e0659e29ba6df8968fad30a54240bfb54.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#007aaa"><strong>九、国际星闪无线短距通信联盟落户河套，高水平产业创新平台加快打造</strong></span></p><p><span style="color:#595959">国际星闪无线短距通信联盟正式落户河套深港科技创新合作区，成为第二个注册地设立在深圳的国际性产业与标准组织。联盟已发布星闪芯片、测试仪表等产品，加快在智能汽车、智能家居、智能终端等领域推进产业化和国际化进程。新增 1 家国家级「双跨」平台、总数占全国十分之一，电子元器件和集成电路国际交易中心交易规模突破 500 亿元。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><img height="357" src="https://oscimg.oschina.net/oscnet/up-56ac4a5cdf50607b2958f21ad8d17cac815.png" width="500" referrerpolicy="no-referrer"></p><p><strong><span style="color:#007aaa">十、中国—东盟新兴产业论坛成功举办，国际产业交流合作成效斐然</span></strong></p><p><span style="color:#595959">成功举办中国-东盟新兴产业论坛，来自东盟各国的 9 位部长、29 位东盟国家驻华使领馆代表以及相关国际组织、商协会、智库、企业共计 180 余位外方嘉宾参加盛会，共话新兴产业发展。发布《新兴产业合作倡议（深圳倡议）》，举办中国-东盟产业对接会（深圳），达成 20 项战略合作框架协议，意向合作金额超 50 亿元。延伸举办中国（深圳、香港）-东盟（吉隆坡）新兴产业对接会，深港携手「并船出海」，达成 22 项合作协议，签约金额超 100 亿元。</span></p><p><img height="640" src="https://oscimg.oschina.net/oscnet/up-3b53abdd29e47790a9ca14a4c7ddea89cdd.png" width="936" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 09:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274769</guid>
            <link>https://www.oschina.net/news/274769</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[祝贺！openKylin 社区再次入选「科创中国」开源创新榜]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">近日，由中国科协科学技术传播中心、中国计算机学会、中国通信学会和中国科学院软件研究所联合主办，CSDN 承办的</span><strong><span style="color:#333333">2023 年开源创新榜专家评审会</span></strong><span style="color:#333333">圆满落幕。</span><span style="color:#0060e8"><strong><span>openKylin 社区荣获「2023 开源创新榜」优秀开源社区奖，这也是 openKylin 社区<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg2MDc5MDU1OQ%3D%3D%26mid%3D2247488006%26idx%3D1%26sn%3D9829fb8b7f075f1239b239d4be35d36b%26chksm%3Dce205876f957d160ca609fd7c95b3f6698bd2fddacb2697724ae7a20292e6780bd3b7ba44906%26scene%3D21%23wechat_redirect" target="_blank">连续两年</a>入选该榜单。</span></strong></span></p><p style="text-align:center"><img alt="" height="1654" src="https://oscimg.oschina.net/oscnet/up-5a2d6ec6c333def9c35daa719508157beef.png" width="2339" referrerpolicy="no-referrer"></p><p><span style="color:#333333">2023 开源创新榜面向中国开源行业领域，评选具有创新性、贡献度和影响力的开源项目、社区、人物。突出「与时俱进、鼓励创新」的原则，旨在挖掘和推广我国在开源技术领域的优秀成果和先进经验。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">相较于往年，2023 年开源创新榜在</span><strong><span style="color:#333333">权威性、公信力和专业度</span></strong><span style="color:#333333">方面均有显著提升。</span></p><ul><li><p style="margin-left:0; margin-right:0">权威性。主办单位新加入中国计算机学会、中国通信学会、中国科学院软件研究所，四家主办单位优势互补，共同推动榜单策划、征集申报、专家评审等工作重点。</p></li><li><p style="margin-left:0; margin-right:0">公信力。由王怀民院士担任评委会主任，指导组建了结构更加科学、领域更加全面的评审专家库，从中提名形成最终评审专家。</p></li><li><p style="margin-left:0; margin-right:0">专业度。围绕项目、社区、人物三大类别，四家主办单位打磨了更加客观、严谨、贴合实际的评审标准和更加开放、公平、科学的评审办法，在征集过程中公开标准细节，接受社会的意见反馈，形成良性循环。</p></li></ul><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">作为中国领先的开源操作系统根社区，openKylin 社区自成立以来便积极推动开源生态建设。截至目前，openKylin 社区已累计发布 6 个社区版本，下载量达 100 万+；聚合 400+家单位会员，涵盖操作系统、数据库、办公软件、CPU、GPU、整机、人工智能优势企业及高等院校；拥有 5700+位开发者，并累计成立 95 个 SIG 组开展技术研究与创新。广泛的产、学、研、用各领域力量加入社区共建之中，为操作系统根技术创新奠定智囊基础。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#333333">此次入选科创中国「开源创新榜」是对 openKylin 社区开源创新能力和行业影响力的高度肯定。未来，openKylin 也将保持初心，聚焦开源创新生态建设、为营造良好开源生态持续努力。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 09:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274766</guid>
            <link>https://www.oschina.net/news/274766</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeFuse 开源这半年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="hjfgjkf.png" src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/98756342/1704681398439-ec399b89-4898-4a2c-94e5-3981b90ed95d.png?x-oss-process=image%2Fresize%2Cw_900%2Climit_0" width="900" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>2023 年可以称得上是大模型元年，在过去的这一年里，大模型领域飞速发展，新的大模型纷纷涌现，基于大模型的新产品也吸引着大家的眼球，未来，这个领域又会给大家带来多少惊喜？</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>蚂蚁也推出了自己的百灵代码大模型 CodeFuse，经历近半年内部打磨后，在 9 月正式对外开源。下面就让我们来看一下，在过去的半年里，CodeFuse 在开源方面取得了哪些进展？</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_1"></span><h2><span>一、让研发变得更简单</span></h2><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>在大模型落地到多个场景的过程中，代码自动生成，成为技术实现的必要环节。在这一趋势下，蚂蚁集团基于百灵大模型，推出了蚂蚁百灵研发助手，帮助开发者自动生成代码、注释、测试用例等，提高研发效率。</span></p><p style="margin-left:0; margin-right:0"><br><span>CodeFuse 源于蚂蚁自身的开发场景及代码库沉淀，基于海量高质量代码数据和代码领域特色词表，和多任务微调技术 MFT，在蚂蚁一万多内部研发人员的日常编码、测试、运维等场景中，经过反复验证与迭代。当前，CodeFuse 从研发效能、DevOps 衍生到了企业 IT 智能化场景智能体的探索。同时，基于 CodeFuse，蚂蚁集团打造了代码大模型的完整工具链，包括：模型服务、风险防护、数据质量、平台工程。</span></p><p style="margin-left:0; margin-right:0"><br><span>2023 年中，CodeFuse 及其必要的工具链，面向技术社区开源开放，帮助社区开发人员在此之上作研究、评价和二次开发和训练。</span></p><p style="margin-left:0; margin-right:0"><br><span>目前，CodeFuse 在蚂蚁各部门落地支持 40 多种编程语言，10 多个主流 IDE 平台。整体采纳率 30%，代码通过 AI 占比 20%。比如，CodeFuse 在蚂蚁数字科技的 SOFAStack 云原生应用智能商业产品线全面融合，涵盖设计、研发、测试、运维等领域，形成从领域建模到智能运维端到端 Copilot 产品解决方案，提升了企业级应用的交付效率和质量，加速行业数字化降本增效。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_2"></span><h2><span>二、丰富的开源内容</span></h2><p style="margin-left:0; margin-right:0"><span>CodeFuse 的使命是开发专门设计用于支持整个软件开发生命周期的大型代码语言模型（Code LLMs），当前内容涵盖代码、运维、分析、测试、推理、评价六大方向。截止 2023.12.31，CodeFuse 已累计开源了 11 个代码仓库、4 个数据集、11 个大模型参数文件，总计关注/点赞数超过 3000、下载量超过 2.4 万，并有 1 篇论文已被接收，2 篇预影印在 Arxiv 上。</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/276193/1704259197296-b8ea3135-7387-4a92-a84f-d02643811793.png" width="739" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_3"></span><h4><strong>1、代码 - MFTCoder 系列：</strong></h4><p>国际首个高精度、高效率、多任务、多模型支持、多训练算法，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FMFTCoder" target="_blank" rel="nofollow"><span>大模型代码能力微调框架</span></a><span>；多任务微调的技术细节已在 Arxiv 公布，可参考</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2311.02303" target="_blank" rel="nofollow"><span>MFTCoder 论文</span></a><span>，以及</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484188%26idx%3D1%26sn%3D27c9fe0e849f9f27eac588fda76574be%26chksm%3Dc139d02df64e593b2fcb9101cea55c4b78af5a6b4dd0f6518d7993bc864a36150ae438abc902%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前发布的文章</span></a></p><div><p style="margin-left:0; margin-right:0"><span>预训练语言模型可以在大量的文本数据上学习通用的语言模式和结构。通过运用无监督学习技术，模型可以基于前面的词序列来预测句子中的下一个词。然而，仅仅进行预训练并不能在特定的自然语言处理任务上取得高性能。因此，需要在特定任务的小型数据集上对预训练模型进行微调，以学习任务特定的特征并提高性能。微调过程使用监督学习技术将预训练模型适应到特定的任务上。将训练过程分为预训练和微调两个阶段，可以使自然语言处理模型充分发挥无监督学习和有监督学习的优势。</span></p><p style="margin-left:0; margin-right:0"><span>但是，需要注意的是，当模型的参数量巨大时，为每一个下游任务独立进行微调并部署将需要大量的资源。然而，是否存在一种方法可以让一个模型同时支持所有的下游任务呢？答案是肯定的，多任务微调（multitask fine-tuning，MFT）为解决这个问题提供了一种有效的途径。</span></p><p style="margin-left:0; margin-right:0"><span>多任务微调不仅能够节省资源，还能够带来其他优势。通过联合训练，模型可以学习到多个任务之间的特征和规律。相比于针对每一个任务单独进行微调，多任务微调能够更好地完成各种任务。同时，由于学习到的特征和规律是相互联系的，模型的泛化能力也会得到提高。这意味着，即使在面对未见过的任务时，模型也能够表现出色，因为它已经学习到了许多相关任务的特征和规律。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_4"></span><h4>2、运维 - DevOps 系列：</h4><p>业界首个开源的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-DevOps-Model" target="_blank" rel="nofollow"><span>中文开发运维大模型</span></a><span>，能够帮助工程师回答在 DevOps 生命周期中遇到的问题，并提供通过检索增强生成、工具学习和沙盒环境来构建软件开发全生命周期的<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-chatbot" target="_blank" rel="nofollow"><span>AI 智能助手</span></a><span>；详细介绍可以参看此前文章<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484045%26idx%3D1%26sn%3D838d9de49922b0d04bcffb3efbeec4df%26chksm%3Dc139d1bcf64e58aa0c92696d74ccebc64281a9ed287f88333bdd139e34ee5e8d46726ef9cd6e%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>DevOps-Eval</span></a><span>、</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484350%26idx%3D1%26sn%3Dc9875496ec1b2c75f47db73986007a05%26chksm%3Dc139d08ff64e5999b5c55f727d1b98475cc50a328662b5c84d921fe8c45a477f452effc2c41f%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>DevOps-Model</span></a><span>、</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484642%26idx%3D1%26sn%3De7dde520532b0868d267cff5ff4bc449%26chksm%3Dc139d7d3f64e5ec53f110495dbefc8e1903c9f09e13c909b2d236b1808bb9683d034b065e007%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>DevOps-Chatbot</span></a></p><div><p style="margin-left:0; margin-right:0"><span>我们希望用户逐渐从各处资料查询、独立分散平台操作的传统开发运维模式转变到大模型问答的智能化开发运维模式，改变人们的开发运维习惯。</span></p><p style="margin-left:0; margin-right:0"><span>核心差异技术、功能点：</span></p><ul><li><span>智能调度核心： 构建了体系链路完善的调度核心，支持多模式一键配置，简化操作流程。</span></li><li><span>代码整库分析： 实现了仓库级的代码深入理解，以及项目文件级的代码编写与生成，提升了开发效率。</span></li><li><span>文档分析增强： 融合了文档知识库与知识图谱，通过检索和推理增强，为文档分析提供了更深层次的支持。</span></li><li><span>垂类专属知识： 为 DevOps 领域定制的专属知识库，支持垂类知识库的自助一键构建，便捷实用。</span></li><li><span>垂类模型兼容： 针对 DevOps 领域的小型模型，保证了与 DevOps 相关平台的兼容性，促进了技术生态的整合。</span></li></ul><p style="margin-left:0; margin-right:0"><span>依托于开源的 LLM 与 Embedding 模型，可实现基于开源模型的离线私有部署，此外，也支持 OpenAI API 的调用。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_5"></span><h4><span>3、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-Query" target="_blank" rel="nofollow">分析 - CodeFuse-Query</a></span><span>：</span></h4><p><span style="color:#000000">基于查询的代码分析引擎，适合大规模、复杂的代码库分析场景。可参考论文<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.01571" target="_blank" rel="nofollow"><span>https://arxiv.org/abs/2401.01571</span></a><span>；详细介绍可以参看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484536%26idx%3D1%26sn%3D2e985b431ff9bd219c93b97ce4f4f444%26chksm%3Dc139d749f64e5e5f96f248f99d18bc55a5cd75fcb58c7726f52cfd6cd131f640d09e7d0e122a%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a></p><div><p style="margin-left:0; margin-right:0"><span>CodeFuse-Query 的特点和优势可以概括为以下几点：</span></p><ul><li><span>高度可扩展：CodeQuery 可以处理大规模的代码库，且能够适应不同的分析需求。这种高度的可扩展性使得 CodeQuery 可以在大型组织中发挥重要作用。</span></li><li><span>以数据为中心：CodeQuery 将源代码和分析结果视作数据，这种以数据为中心的方法使其在处理大数据环境中的代码分析问题时具有独特优势。</span></li><li><span>高度集成：CodeQuery 能够无缝地融入大型组织的各种系统中，包括数据仓库、数据计算设施、对象存储和灵活计算资源等。这种高度的集成性使得 CodeQuery 在大型组织中的使用变得更加方便和高效。</span></li><li><span>支持多元化的需求：CodeQuery 不仅可以处理大规模的代码库，还可以应对各种复杂的分析需求，包括服务质量分析需求、跨编程语言分析需求、算法需求和性能需求等。</span><br> &nbsp;</li></ul></div><span id="OSC_h4_6"></span><h4><span>4、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FTest-Agent" target="_blank" rel="nofollow">测试 - Test-Agent</a></span><span>：</span></h4><p><span>测试领域的「智能体」，打造创新的测试领域解决方案，构建 24 小时在线的测试助理服务；详细介绍可以参看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247483884%26idx%3D3%26sn%3Db92d3cbbe82c9487777f63ad6a38851b%26chksm%3Dc139d2ddf64e5bcb2246335bf6ee327900c789dbfead77bfc3c325a8a4854f5d50bd839eb8ad%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a></p><div><p style="margin-left:0; margin-right:0"><span>大模型的号角已经吹响，测试领域大模型也在不断进化中，通过预训练过程中积累的丰富世界知识，在复杂交互环境中展现出了非凡的推理与决策能力。</span></p><p style="margin-left:0; margin-right:0"><span>尽管在测试领域中，基础模型取得了显著的成果，但仍然存在一些局限性，特定领域的测试任务通常需要专业化的工具或领域知识来解决。例如，基础模型可以通过预训练知识完成单次测试代码生成和测试文本生成等任务，但处理复杂的集成用例生成、特定领域用例生成和测试流程 pipeline 交互等问题时，需要更专业的工具和领域知识。</span></p><p style="margin-left:0; margin-right:0"><span>因此将专用工具与基础模型整合在一起，可以充分发挥它们各自的优势。专用工具可以解决模型时效性不足、增强专业知识、提高可解释性和鲁棒性的问题。而基础模型则具备类人的推理规划能力，可以理解复杂的数据和场景，并与现实世界进行交互。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_7"></span><h4><span>5、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FCodeFuse-ModelCache%2Fblob%2Fmain%2FREADME_CN.md" target="_blank" rel="nofollow">推理 - ModelCache</a></span><span>：</span></h4><p><span>大模型语义缓存系统，通过缓存已生成的模型结果，降低类似请求的响应时间，提升用户体验；详细介绍可以参看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484139%26idx%3D1%26sn%3Df6b0fbe4d4dc7b47759146de60a1c820%26chksm%3Dc139d1daf64e58ccd522435f3769c2dd5b1953b7974c5efbb53ef0f9247ae3c037428a1770bf%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a><span>。</span></p><div><p style="margin-left:0; margin-right:0"><span>当前大模型服务面临以下三个挑战：</span></p><ul><li><span>成本高：大模型参数量千亿级别，单实例就需要多张 A10 卡，规模化部署成本高昂。因此，当前大模型服务基本按照处理的 token 数量计费，导致用户侧使用成本也居高不下。</span></li><li><span>速度慢：大型模型的推理速度也是一个关键问题。在许多实时应用中，如对话系统、业务助手，响应时间要求非常高，通常在毫秒级别。然而，大型模型的推理速度往往较慢，在秒级，导致无法实时返回结果，用户体验下降。</span></li><li><span>稳定性无保障：由於单实例部署成本高昂，当前大模型服务接受到大流量请求时，通过限流的方式，防止服务不可用。</span></li></ul><p style="margin-left:0; margin-right:0"><span>针对上述挑战，引入大模型缓存可以解决当前问题：通过引入 Cache 机制，缓存已计算的结果，当接收到类似请求，可以直接从缓存获取结果，避免重复计算，节约计算资源，显著提升响应时间，提升用户体验；同时，缓存可以起到分流的作用，降低透传到后端的请求量，降低后端压力，提升服务稳定性。因此，Cache 作为一种重要的大模型服务部署解决方案，在资源有限和对实时性要求较高的场景下，可以帮助企业和研究机构更好地应用大型语言模型，提升模型性能和效率。未来，随着大型模型在各个领域的广泛应用，Cache 的重要性将不断凸显。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h4_8"></span><h4><span>6、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2Fcodefuse-evaluation%2Fblob%2Fmaster%2FREADME_CN.md" target="_blank" rel="nofollow">评测 - CodeFuse-Evaluation</a></span><span>：</span></h4><p><span>在 HumanEval-x、MBPP 的基准上开发的编程领域多任务的评测基准， 可用于评估大模型在代码补全，自然语言生成代码，测试用例生成、跨语言代码翻译、中文指令生成代码等多类任务的性能；详细介绍可以参看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkwOTU3NTc3NA%3D%3D%26mid%3D2247484436%26idx%3D1%26sn%3D55ad2d46c2d6b8e9ef0d3e94201945b0%26chksm%3Dc139d725f64e5e331deb25933742bc70e9b608756059458bfa3700e16974711000ad20a32a86%26token%3D1529034469%26lang%3Dzh_CN%23rd" target="_blank" rel="nofollow"><span>此前文章</span></a><span>。</span></p><div><p style="margin-left:0; margin-right:0"><span>目前对于大语言模型评估的按照生成的结果是否可定量衡量比如数学计算和文章生成分为客观评测和主观评测。客观评测：基于业界影响力较高评测基准对生成内容进行各维度评估；主观评测：组织多位有专业背景知识的专家进行相关维度评估。</span></p><p style="margin-left:0; margin-right:0"><span>按照评测执行方式可分为自动化评测，人工评测和模型评测三类。</span></p><p style="margin-left:0; margin-right:0"><span>模型训练完成后，基于评估基准跑出评分，这个过程可以完全工程化的执行因此成为自动化评测。人工评测特别是领域知识需要着急各领域专家进行测评，此种方式评估成本较高但是评估结果更具有说服力。模型（如 PandaLM）评测模型即通过训练大模型学习到人类对不同生成文本的总体偏好，并作出基于习得的人类偏好的相对评价，这种评价方式相比人工更稳定、高效。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div><span id="OSC_h2_9"></span><h2><span>三、精彩的社区活动</span></h2><p style="margin-left:0; margin-right:0"><span>我们深知，开源不只是开放代码，还包括在社区的分享与交流。在开源内容上干货满满，社区活动定也不落下风，让我们看看都有哪些吧！！</span></p><p style="margin-left:0; margin-right:0"><span>8 月，我们在 AI+ 软件研发数字峰会上进行了专场分享《基于 AIGC 的测试生成》；</span></p><p style="margin-left:0; margin-right:0"><span>9 月，外滩大会上正式对外宣布 CodeFuse 开源；</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420417098-5d63a0fa-ef73-4abe-8569-db04857eddef.png" width="540" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>10 月，在 MLSummit 2023 上，对外分享了 CodeFuse 研发经验；</span></p><p style="margin-left:0; margin-right:0"><span>11 月初，在云栖大会上进行 CodeFuse 专题演讲；</span></p><p style="margin-left:0; margin-right:0"><span>11 月，和始智 AI 等联合举办了「代码大模型技术与应用发展」论坛；</span></p><p style="margin-left:0; margin-right:0"><span>12 月初，在 CCF 中国软件大会上，与参会者现场体验、互动交流；</span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420830670-62d284f9-b89c-4c3f-9f10-1bc174d4154e.png" width="480" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span>12 月末，在全球软件开发者大会 QCon 上经验分享《基于 CodeFuse 的下一代研发探索》。</span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h2_10"></span><h2><span>四、获得业界认可</span></h2><p style="margin-left:0; margin-right:0"><span>今年，CodeFuse 还获得了多个奖项，感谢业界的认可：</span></p><ul><li><span>荣获开源中国 2023 年度优秀开源技术团队</span></li></ul><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420476632-42355276-1d79-46dd-bcb6-eb0c29a62311.png" width="540" referrerpolicy="no-referrer"></p><ul><li><span>入选极客公园 2023 大模型先锋案例 TOP10</span></li></ul><p style="margin-left:0px; margin-right:0px; text-align:center"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2024/png/217410/1704420452319-a2eabbe9-21a1-47e2-a54f-84d5fce1b04b.png" width="540" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:center">&nbsp;</p><span id="OSC_h2_11"></span><h2><span>五、2024 新的期待</span></h2><p style="margin-left:0; margin-right:0"><br><span>2023 年以来，大模型在代码领域落地不断深入。经过一年的实践，我们对相关的技术也有了更深层次的理解与认识。也看到了很多有趣的方向与落地实践。在 2024 新的一年里，我们还会继续深耕开源：</span></p><ul><li><span>更多创新功能发布，例如近期 1 月份将发布支持 MoE 的 MFTCoder v0.2; 2 月份将发布支持前端设计到代码的训练框架和模型；</span></li><li><span>更多的线下活动，会组织多次 CodeFuse 线下 meetup，欢饮感兴趣的同行多多参与；也会积极参与国内和国际行业会议/论坛更多分享 CodeFuse 的实践经验；</span></li><li><span>更多的社区参与和互动，会社区调研，让大家能够参与到项目中来；包括不限于发起社区一起捉虫、一起贡献新特性，推动相关体系的标准化，甚至组织相关比赛活动等。</span></li></ul><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span>非常欢迎大家能够跟我们一起交流探索，一起来定义下一代基于大模型的全生命周期研发解决方案。欢迎大家参与到我们社区中，一起探讨、交流。 2024，一起向未来！</span></p><p style="margin-left:0; margin-right:0"><span style="color:rgba(0, 0, 0, 0.9)">CodeFuse 官网：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodefuse.alipay.com" rel="nofollow" target="_blank"><span style="color:#0080ff">https://codefuse.alipay.com</span></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 07:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6942768/blog/10678192</guid>
            <link>https://my.oschina.net/u/6942768/blog/10678192</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[商汤科技：前海深港人工智能算力中心正式启动]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>商汤科技发文宣布，前海深港人工智能算力中心正式点亮启动；目标打造粤港澳大湾区大规模、领先算力的智算中心。</p><p>一期建设算力将达 500 Petaflops（FP16），AI 算力规模每秒 50 亿亿次，相当于一小时可完成 16 亿张图像处理、190 万小时语音翻译、0.7 万公里自动驾驶 AI 数据处理；</p><p>该算力中心坐落于深圳市前海信息枢纽大厦，由深圳前海管理局、商汤科技、香港科技园公司三方共同推进，前海科技创新集团与商汤科技联合投资建设。</p><p>商汤科技董事长兼 CEO 徐立表示：</p><blockquote><p>「人工智能在 2023 年实现了跨越式发展，进入以大模型为基础的 AI 2.0 时代，先进智能算力作为当前最具活力的新型生产力，已成为重要的战略资源。前海加大科技基础设施建设和科技领域投入，又一次走在了全国新旧发展动能转换的前列。基于建成亚洲最大 AIDC 智算中心之一的成功经验，商汤愿意充分发挥在人工智能行业的优势，在深港合作、算法大模型、人工智能产业与投资等领域加强产业带动与应用示范，协同香港与前海融合发展做出贡献。」</p></blockquote><p>活动现场<span style="background-color:#ffffff; color:#4c4c4c">还举行了智算中心意向客户签约仪式，并与前海大数据资源管理中心有限公司签订了委托运营协议。</span></p><p><img height="292" src="https://oscimg.oschina.net/oscnet/up-f2e6b62e914595ab3929261a6cb9b2e07c8.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 07:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274742</guid>
            <link>https://www.oschina.net/news/274742</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[R 语言社区知名开发者「谢益辉」被 RStudio/Posit 解雇]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>R Markdown、knitr、blogdown 和 bookdown 等 R 软件包的创建者<span style="background-color:#ffffff; color:#191b1f">谢益辉</span>于日前<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyihui.org%2Fen%2F2024%2F01%2Fbye-rstudio%2F" target="_blank">发布博客表示</a>，自己已于 2023 年底被 Posit (原 Rstudio) 公司解雇，并于 2024 年 1 月 1 日正式离开该公司。</p><blockquote><p><span style="color:#000000">在写了这么多年的 「*down」 packages 后，我在这里宣布「Yihui-down」。</span></p><p>谁倒下了？我。在 RStudio/Posit 工作了 10 多年之后，<span style="color:#000000">现在是我探索其他机会的时候了</span>。两个多星期前，我被告知被裁员了，最后一天是 2023-12-31。坦率地说，我感到非常惊讶，但只是短暂的惊讶。我完全尊重 Posit 的决定，并很快接受了我的贡献不再配得上这里的全职工作这一结论。一段关系的结束往往并不意味着任何一方做错了什么或失败了什么。相反，它可能只是表明双方不匹配，这很正常。人就是会变。<span style="color:#000000">回想起这些美好的岁月，我离开时大多怀着感激之情。</span></p></blockquote><p><span style="background-color:#ffffff; color:#191b1f">谢益辉表示，</span><span style="background-color:#ffffff; color:#000000">Posit 同时</span><span style="background-color:#ffffff; color:#111111">为他提供了一个合同工方案；因此这一离开并不意味着诀别，他后续将继续维护 R Markdown 系列包（暂定一年）。现有的 R 软件包仍将得到维护。但 DT 软件包是唯一的例外，因为它不在合同之列，Posit 计划为它寻找新的维护者。</span></p><p><span style="background-color:#ffffff; color:#111111">但这一合同工并不足以维生，</span><span style="background-color:#ffffff; color:#191b1f">谢益辉也在需找新的工作机会，希望同时能够满足可以自由灵活地继续为 R 生态系统和开源做出贡献。</span></p><p><span style="background-color:#ffffff; color:#191b1f">考虑到被突然解雇后所面临的经济压力，谢益辉还发布了一个众筹的赞助页面，以寻求大家的帮助：</span><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsponsors%2Fyihui" target="_blank">https://github.com/sponsors/yihui</a></strong></p><p>「我以前从未向社区请求过经济支持，因为我从来没有感觉到有必要（感谢 Posit）。现在情况变得不一样了......如果有人能在我过渡到下一个稳定的生活阶段之前支持我几个月，我将非常感激。当我不再需要赞助时，我会通知大家，如果你们是月度赞助，可以取消赞助。我很乐意提供一些临时性的帮助作为回报。」</p><p><img height="250" src="https://oscimg.oschina.net/oscnet/up-53f457f44cfc3d2e70079cb04b2ef93e18a.png" width="500" referrerpolicy="no-referrer"></p><p>一些 R 用户对于<span style="background-color:#ffffff; color:#191b1f">谢益辉的离开</span>表达了震惊，研究软件工程师 Zhian N. Kamvar 在 Mastodon 上<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhachyderm.io%2F%40zkamvar%2F111699279163834211" target="_blank">发帖称</a>，「这绝对是毁灭性的消息。如果没有<span style="background-color:#ffffff; color:#191b1f">益</span>辉在 knitr 上的工作，我不可能取得过去十年的成就。如果你最近有使用过 RStats 构建的网站、报告或书籍，你都要感谢<span style="background-color:#ffffff; color:#191b1f">益</span>辉。」</p><p>外媒&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3712061%2Fposit-lays-off-r-markdown-knitr-creator-yihui-xie.html" target="_blank">InfoWorld</a> 认为，<span style="background-color:#ffffff; color:#191b1f">谢益辉的离开再次表明了一个信号，即&nbsp;Posit&nbsp;</span>正在专注于提供 R 和 Python 之间互操作性的产品。一个相关的佐证就是 2022 年发布的 Quarto 开源技术发布平台，该平台不区分语言，同样支持 R 和 Python，以及 Julia 和 Observable JavaScript。该公司当时表示，Quarto 将是下一代 R Markdown。</p><p>在<span style="background-color:#ffffff; color:#191b1f">谢益辉</span>被解雇的前一个月，Python pandas 创建者 Wes McKinney 也加入了 Posit，这也表明该公司正在认真地将其业务重点扩大到 R 之外。McKinney 当时表示，他将「在 Posit 的工作中倡导 PyData 生态系统的需求，并继续推进重要的开源计划。」</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274729/posit-lays-off-yihui-xie</guid>
            <link>https://www.oschina.net/news/274729/posit-lays-off-yihui-xie</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周热点 | 「后开源」 时代已来；Redis 之父 「锐评」 LLM 编程；2024 前端圈「开年之战」上演....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2024.01.01-2024.01.07]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 06:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094095&#38;idx=1&#38;sn=ef33510eefe489ba79639ee09ff10152&#38;chksm=880c4cdcbf7bc5ca1ab8725a741382ed6cce96c7493e27dbb87e559dde82be3bbeb14def9960&#38;token=1679093283&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094095&#38;idx=1&#38;sn=ef33510eefe489ba79639ee09ff10152&#38;chksm=880c4cdcbf7bc5ca1ab8725a741382ed6cce96c7493e27dbb87e559dde82be3bbeb14def9960&#38;token=1679093283&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[App 跨平台框架 VS 原生开发深度评测之 2023 版]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>App 跨平台框架历史悠久，从<code>cordova</code>、<code>react native</code>、<code>flutter</code>，直到最近的<code>uni-app x</code>。江山代有才人出，每个都试图颠覆原生，但过去却一直未成功。</p><p>过去的问题到底在哪里？</p><p>我们先捋一捋各种技术路线，分析这些跨平台开发框架和原生应用的差别具体在哪里。</p><table><thead><tr><th>逻辑层</th><th>渲染层</th><th>类型</th><th>代表作</th></tr></thead><tbody><tr><td>webview</td><td>webview</td><td>弱类型</td><td>5+App、cordova</td></tr><tr><td>js 引擎</td><td>webview</td><td>弱类型</td><td>uni-app 之<code>app-vue</code> 、小程序（dount）</td></tr><tr><td>js 引擎</td><td>原生渲染</td><td>弱类型</td><td>react native、uni-app 之<code>app-nvue</code>、weex</td></tr><tr><td>dart 引擎</td><td>flutter 渲染引擎</td><td>强类型</td><td>flutter</td></tr><tr><td>js 引擎</td><td>flutter 渲染引擎</td><td>弱类型</td><td>微信 skyline、webF、ArkUI-x</td></tr><tr><td>kotlin</td><td>原生渲染</td><td>强类型</td><td>uni-app x</td></tr><tr><td>kotlin</td><td>原生渲染</td><td>强类型</td><td>原生应用</td></tr></tbody></table><p>上面的表格，除了行尾的原生应用外，各个跨平台框架按出现时间排序，可以看到跨平台框架是如何演进的。</p><p>上表中，<code>uni-app x</code>和原生应用是一样的，逻辑层和渲染层都是原生，都是强类型；而其他跨平台框架或者在逻辑层、或者在渲染层与原生不一致。</p><p><code>webview</code>不行已经是业内常识了，启动慢、渲染慢、内存占用高。这块本文不再详述。</p><p>但那些非 web-view 的框架到底哪里不如原生？</p><h2>1. js 逻辑+ 原生渲染</h2><p><code>react native</code>、<code>weex</code>等抛弃<code>webview</code>，改由原生渲染的跨平台方案，2014 年就推出了。 如今手机硬件也越来越好了，为什么性能还达不到原生？</p><p>js+原生渲染的方案主要有 2 点缺陷：</p><ul><li>JS 引擎自身的性能问题</li><li>JS 和原生之间的通信延迟</li></ul><h3>1.1 js 引擎慢，启动速度和运行速度都弱于原生</h3><p>所以很多开发者即便使用这类方案，首页也还是原生来写。</p><p>React Native 的<code>Hermes</code>引擎和华为的<code>arkUI</code>，提供了 js 编译为字节码的方案，这是一种空间换时间的方案，启动速度有了一定优化，但仍然比不过原生。</p><p>弱类型在编译期可优化的幅度有限，还是需要一个运行时来跑，无法像强类型那样直接深入底层。</p><p>以数字运算为例，js 的<code>number</code>运算确实比强类型的<code>int</code>慢，内存开销也更大。</p><h3>1.2 js 语言与原生之间通信卡顿</h3><p>每个语言有自己的内存空间，跨语言通信都有折损，每次通信几十到几百毫秒不等，视手机当时的状态。一旦频繁通信，就会明显卡顿。</p><p>逻辑层的 js，即要和原生渲染层通信，还要和原生 API 通信：</p><h4>1.2.1 js 与原生 ui 通信</h4><p>举个简单的场景例子，在 js 里监听滚动，根据滚动变化实时调整界面上某些元素的高度变化。这个问题能难倒一大批跨平台开发框架。</p><p>如果全部在 webview 里，js 操作 ui 还好一些，所以 uni-app 的 app-vue 里的 renderjs 操作 UI 性能高，就是这个道理。同理还有微信小程序的<code>wsx</code>。</p><p>虽然小程序和 uni-app 都是 js，但实际上逻辑层在独立 js 引擎里，通过原生桥来控制 web-view，通信成本很高。</p><p>weex 提供了<code>bindingx</code>技术，这是一种弱编程，渲染层预先定义了一些操作 UI 的方式，调用时全部在渲染层运行，不会来回与逻辑层通信。但这种预定义方式的适应面有限，无法做到在 js 里高性能、自由的操作所有 UI。</p><h4>1.2.2 js 操作原生 api</h4><p>操作系统和三方 SDK 的 API 都是原生的，js 调用这些能力也需要跨语言通信。比如 js 调用原生的 Storage 或 IO，数据较多时遍历的性能非常差。</p><p>当然在 js API 的封装上可以做些优化，比如微信的 storage 提供了<code>wx.batchGetStorageSync</code>这种批量读取的 API，既然遍历性能差，那干脆一次性从原生读出来再传给 js。</p><p>这也只能是无奈的方案，如果在遍历时想用 js 做什么判断就实现不了了，而且一次性读出很大的数据后传给 js 这一下，也需要通信时间。</p><h2>2. flutter 方案</h2><p>flutter 在 2018 年发布，第一次统一了逻辑层和渲染层，而且使用了强类型。</p><p>它没有使用原生渲染，而是使用由<code>dart</code>驱动的渲染引擎，这样逻辑层的 dart 代码操作 UI 时，再也没有延时了！bindingx、wxs 这种补丁方案再也不需要了。</p><p>并且 dart 作为强类型，编译优化很好做，启动速度和运行速度都胜过 js。</p><p>在这个开源项目下<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_flutter_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_flutter_slider_100</a>，提供了一个 flutter 编写的 100 个 slider 同时滑动的示例， 项目下有源码也有打包好 apk，可以直接安装体验。</p><p>100 个 slider 同时滑动，非常考验逻辑和 UI 的通信。如果在 webview 内部，html 和 js 写 100 个这样的 slider，在新的手机上表现也还 ok。但在小程序和 react native 这种逻辑和 UI 分离的模式下，100 个 slider 是灾难。</p><p>下载安装 apk 后可以看到 dart 操作 flutter 的 UI 真的没有通信折损，100 个 slider 的拖动非常流畅。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317188140437864502%3FlogTag%3Dfd9af6e9d0d98f40568e" target="_blank">点击查看视频</a></p><p>flutter 看起来很完美。但为什么也没有成为主流呢？很多大厂兴奋的引入后为何又不再扩大使用范围呢？</p><h3>2.1 dart 与原生 API 的通信</h3><p>别忘了上面 1.2.2 提到的原生 API 通信。flutter 虽然在逻辑层和渲染层都是 dart，但要调用原生 API 时，还是要通信。</p><p>操作系统和三方 SDK 的 API 是原生的，让 dart 调用需要做一层封装，又落到了跨语言通信的坑里。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest_flutter_message_channel" target="_blank">https://gitcode.net/dcloud/test_flutter_message_channel</a>这是一个开源测试项目，来测试原生的 claas 数据与 dart 的通信耗时。</p><p>项目里面有源码，大家可自行编译；根目录有打包好的 apk，也可以直接安装体验。</p><p>这个项目首先在 kotlin 中构建了包含不同数据量的 class，传递到 dart 然后渲染在界面上，并且再写回到原生层。</p><p>有 0.1k 和 1k 两种数据量（点击界面上的 1k 数字可切换），有读和读并写 2 个按钮，各自循环 1000 次。</p><p>以下截图的测试环境是华为 mate 30 5G，麒麟 990。手机上所有进程杀掉。如下图：</p><ul><li>1k 数据从原生读到 dart 并渲染</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-b6da22344a6d16c9d69b06e7e643d8693c1.jpg" alt="flutter_1k_read.jpeg" referrerpolicy="no-referrer"></p><ul><li>1k 数据从原生读到 dart 并渲染再写回</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-bf956b25b963ff74a653cb15558cad78f00.jpg" alt="flutter_1k_readwrite.jpeg" referrerpolicy="no-referrer"></p><ul><li>0.1k 数据从原生读到 dart 并渲染</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-eec96c5ae67f8c3db0137dc2f84f5c757c3.jpg" alt="flutter_0.1k_read.jpeg" referrerpolicy="no-referrer"></p><ul><li>0.1k 数据从原生读到 dart 并渲染再写回</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-6df9c0934af2fed44809afdcad596493c1e.jpg" alt="flutter_0.1k_readwrite.jpeg" referrerpolicy="no-referrer"></p><p>通信损耗非常明显。并且数据量从 1k 降低到 0.1k 时，通信时间并没有减少 10 倍，这是因为通信耗时有一个基础线，数据再小也降不下去。</p><p>为什么会这样？因为<code>dart</code>和<code>kotlin</code>不是一种编程语言，不能直接调用<code>kotlin</code>的<code>class</code>，只能先序列化成字符串，把字符串数据从原生传到 dart，然后在 dart 层再重新构造。</p><p>当然也可以在原生层为 dart 封装 API 时提供 wx.batchGetStorageSync 这类批处理 API，把数据一次读好再给 dart，但这种又会遇到灵活性问题。</p><p>而在<code>uni-app x</code>中，这种跨语言通信是不存在的，不需要序列化，因为 uni-app x 使用的编程语言 uts，在 android 上就编译为了 kotlin，它可以直接调用 kotlin 的 class 而无需通信和封装。示例如下，具体 uni-app x 的原理后续章节会专题介绍。</p><pre><code>&lt;template&gt;
&lt;/template&gt;
&lt;script lang="uts"&gt;
import Build from 'android.os.Build';
export default {
onLoad() {
console.log(Build.MODEL); //uts 可以直接导入并使用原生对象，不需要封装，没有跨语言通信折损
}
}
&lt;/script&gt;
</code></pre><p>再分享一个知识：</p><p>很多人都知道 iPhone 上跨平台框架的应用，表现比 android 好。但大多数人只知道是因为 iPhone 的硬件好。</p><p>其实还有一个重要原因，iOS 的 jscore 是 c 写的，OS 的 API 及渲染层也都是 ObjectC，js 调用原生时，某些类型可以做共享内存的优化。但复杂对象也还是无法直接丢一个指针过去共享使用内存。</p><p>而 android，不管 java 还是 kotlin，他们和 v8、dart 通信仍然需要跨语言通信。</p><h3>2.2 flutter 渲染和原生渲染的并存问题</h3><p>flutter 的自渲染引擎，在技术上是不错的。但在生态兼容上有问题。</p><p>很多三方软件和 SDK 是原生的，原生渲染和 flutter 自渲染并存时，问题很多。</p><p>flutter 开发者都知道的一个常见坑是输入法，因为输入法是典型的原生 UI，它和 flutter 自绘 UI 并存时各种兼容问题，输入框被遮挡、窗体 resize 适应，输入法有很多种，很难适配。</p><p>混合渲染，还有信息流广告、map、图表、动画等很多三方 sdk 涉及。这个时候内存占用高、渲染帧率下降、不同渲染方式字体不一致、暗黑主题不一致、国际化、无障碍、UI 自动化测试，各种不一致。。。</p><p>这里没有提供开源示例，因为 flutter 官方是承认这个问题的，它提供了 2 种方式：混合集成模式和虚拟显示模式模式。</p><p>但在渲染速度、内存占用、版本兼容、键盘交互上都各自有各自的问题。详见 flutter 官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.flutter.dev%2Fplatform-integration%2Fandroid%2Fplatform-views%23performance" target="_blank">https://docs.flutter.dev/platform-integration/android/platform-views#performance</a>。这个是中文翻译：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fflutter.cn%2Fdocs%2Fplatform-integration%2Fandroid%2Fplatform-views%23performance" target="_blank">https://flutter.cn/docs/platform-integration/android/platform-views#performance</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fflutter.cn%2Fdocs%2Fplatform-integration%2Fandroid%2Fplatform-views%23performance" target="_blank"></a></p><p>在各大 App 中，微信的小程序首页是为数不多的使用 flutter UI 的界面，已经上线 1 年以上。</p><p>下面是微信 8.0.44（此刻最新版），从微信的发现页面进入小程序首页。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317194438416007206%3FlogTag%3D8165f43a009f28425f24" target="_blank">点击查看视频</a></p><p>视频中手机切换暗黑主题后，这个 UI 却还是白的，而且 flutter 的父容器原生 view 已经变黑了，它又在黑底上绘制了一个白色界面，体验非常差。</p><p>这个小程序首页界面很简单，没有输入框，规避了混合渲染，点击搜索图标后又跳转到了黑色的原生渲染的界面里。</p><p>假使这个界面再内嵌一个原生的信息流 SDK，那会看到白色 UI 中的信息流广告是黑底的，更无法接受。</p><p>当然这不是说 flutter 没法做暗黑主题，重启微信后这个界面会变黑。这里只是说明渲染引擎不一致带来的各种问题。</p><blockquote><p>注：如何识别一个界面是不是用 flutter 开发的？在手机设置的开发者选项里，有一个 GPU 呈现模式分析，flutter 的 UI 不触发这个分析。且无法审查布局边界。</p></blockquote><p>flutter 的混合渲染的问题，在所有使用原生渲染的跨平台开发框架中都不存在，比如 react native、weex、uni-app x。</p><p>总结下 flutter：逻辑层和 UI 层交互没有通信折损，但逻辑层 dart 和原生 api 有通信成本，自绘 UI 和原生 ui 的混合渲染问题很多。</p><h2>3. js+flutter 渲染</h2><p>flutter 除了上述提到的原生通信和混合渲染，还有 3 个问题：dart 生态、热更新、以及比较难用的嵌套写法。</p><p>一些厂商把 flutter 的 dart 引擎换成了 js 引擎，来解决上述 3 个问题。比如微信 skyline、webF、ArkUI-x。</p><p>其实这是让人困惑的行为。因为这又回到了 react native 和 weex 的老路了，只是把原生渲染换成了 flutter 渲染。</p><p>flutter 最大的优势是 dart 操作 UI 不需要通信，以及强类型，而改成 js，操作 UI 再次需要通信，又需要 js 运行时引擎。</p><p>为了解决 js 和 flutter 渲染层的通信问题，微信的 skyline 又推出了补丁技术 worklet 动画，让这部分代码运行在 UI 层。（当然微信的通信，除了跨语言，还有跨进程通信，会更明显）</p><p>这个项目<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_arkuix_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_arkuix_slider_100</a>， 使用 ArkUI-x 做了 100 个 slider，大家可以看源码，下载 apk 体验，明显能看到由于逻辑层和 UI 层通信导致的卡顿。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317196064589627411%3FlogTag%3D368ecfd6c36a3f4fe41a" target="_blank">点击查看视频</a></p><p>上述视频中，注意看手指按下的那 1 个 slider，和其他 99 个通过数据通讯指挥跟随一起行动的 slider，无法同步，并且界面掉帧。</p><p>不过自渲染由于无法通过 Android 的开发者工具查看 GPU 呈现模式，所以无法从条状图直观反映出掉帧。</p><blockquote><p>注意 ArkUI-x 不支持<code>Android8.0</code>以下的手机，不要找太老的手机测试。</p></blockquote><p>很多人以为自渲染是王道，但其实自渲染是坑。因为 flutter 的 UI 还会带来混合渲染问题。</p><p>也就是说，js+flutter 渲染，和 js+原生渲染，这 2 个方案相比，都是 js 弱类型、都有逻辑层和渲染层的通信问题、都有原生 API 通信问题，而 js+flutter 还多了一个混合渲染问题。</p><p>可能有的同学会说，原生渲染很难在 iOS、Android 双端一致，自渲染没有这个问题。</p><p>但其实完全可以双端一致，如果你使用某个原生渲染框架遇到不一致问题，那只是这个框架厂商做的不好而已。</p><p>是的，很遗憾 react native 在跨端组件方面投入不足，官方连 slider 组件都没有，导致本次评测中未提供 react native 下 slider-100 的示例和视频。</p><h2>4. uni-app x</h2><p>2022 年，uts 语言发布。2023 年，uni-app x 发布。</p><p>uts 语言是基于 typescript 修改而来的强类型语言，编译到不同平台时有不同的输出：</p><ul><li>编译到 web，输出 js</li><li>编译到 Android，输出 kotlin</li><li>编译到 iOS，输出 swift</li></ul><p>而 uni-app x，是基于 uts 语言重新开发了一遍 uni-app 的组件、API 以及 vue 框架。</p><p>如下这段示例，前端的同学都很熟悉，但它在编译为 Android App 时，变成了一个纯的 kotlin app，里面没有 js 引擎、没有 flutter、没有 webview，从逻辑层到 UI 层都是原生的。</p><pre><code>&lt;template&gt;
&lt;view class="content"&gt;
&lt;button @click="buttonClick"&gt;{{title}}&lt;/button&gt;
&lt;/view&gt;
&lt;/template&gt;

&lt;script&gt; //这里只能写 uts
export default {
data() {
return {
title: "Hello world"
}
},
onLoad() {
console.log('onLoad')
},
methods: {
buttonClick: function () {
uni.showModal({
"showCancel": false,
"content": "点了按钮"
})
}
}
}
&lt;/script&gt;

&lt;style&gt;
.content {
width: 750rpx;
background-color: white;
}
&lt;/style&gt;
</code></pre><p>这听起来有点天方夜谭，很多人不信。DCloud 不得不反复告诉大家，可以使用如下方式验证：</p><ul><li><p>在编译 uni-app x 项目时，在项目的 unpackage 目录下看看编译后生成的 kt 文件</p></li><li><p>解压打包后的 apk，看看里面有没有 js 引擎或 flutter 引擎</p></li><li><p>手机端审查布局边界，看看渲染是不是原生的（flutter 和 webview 都无法审查布局边界）</p></li></ul><p>但是开发者也不要误解之前的 uni-app 代码可以无缝迁移。</p><ul><li><p>之前的 js 要改成 uts。uts 是强类型语言，上面的示例恰好类型都可以自动推导，不能推导的时候，需要用<code>:</code>和<code>as</code>声明和转换类型。</p></li><li><p>uni-app x 支持 css，但是 css 的子集，不影响开发者排版出所需的界面，但并非 web 的 css 全都兼容。</p></li></ul><p>了解了 uni-app x 的基本原理，我们来看下 uni-app x 下的 100 个 slider 效果怎么样。</p><p>项目<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_uniappx_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_uniappx_slider_100</a>下有源码工程和编译好的 apk。</p><p>如下视频，打开了 GPU 呈现模式，可以看到没有一条竖线突破那条红色的掉帧安全横线，也就是没有一帧掉帧。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317198768934715433%3FlogTag%3D89299d3c416b4e9e6de7" target="_blank">点击查看视频</a></p><p>uni-app x 在 app 端，不管逻辑层、渲染层，都是 kotlin，没有通信问题、没有混合渲染问题。不是达到了原生的性能，而是它本身就是原生应用，它和原生应用的性能没差别。</p><p>这也是其他跨平台开发框架做不到的。</p><p>uni-app x 是一次大胆的技术突破，分享下 DCloud 选择这条技术路线的思路：</p><p>DCloud 做了很多年跨平台开发，uni-app 在 web 和小程序平台取得了很大的成功，不管规模大小的开发者都在使用；但在 app 平台，大开发者只使用 uni 小程序 sdk，中小开发者的 app 会整体使用。</p><p>究其原因，uni-app 在 web 和小程序上，没有性能问题，直接编译为了 js 或 wxml，uni-app 只是换了一种跨平台的写法，不存在用 uni-app 开发比原生 js 或原生 wxml 性能差的说法。</p><p>但过去基于小程序架构的 app 端，性能确实不及原生开发。</p><p>那么 App 平台，为什么不能像 web 和小程序那样，直接编译为 App 平台的原生语言呢？</p><p>uni-app x，目标不是改进跨平台框架的性能，而是给原生应用提供一个跨平台的写法。</p><p>这个思路的转换使得 uni-app x 超越了其他跨平台开发框架。</p><p>在 web 端编译为 js，在小程序端编译为 wxml 等，在 app 端编译为 kotlin。每个平台都只是帮开发者换种一致的写法而已，运行的代码都是该平台原生的代码。</p><p>然而在 2 年前，这条路线有 2 个巨大的风险：</p><ol><li><p>从来没有人走通过</p></li><li><p>即便能走通，工作量巨大</p></li></ol><p>没有人确定这个产品可以做出来，DCloud 内部争议也很多。</p><p>还好，经历了无数的困难和挑战，这个产品终于面世了。</p><p>换个写法写原生应用，还带来另一个好处。</p><p>同样业务功能的 app，使用 vue 的写法，比手写纯原生快多了。也就是 uni-app x 对开发效率的提升不只是因为跨平台，单平台它的开发效率也更高。</p><p>其实 google 自己也知道原生开发写法太复杂，关于换种更高效的写法来写原生应用，他们的做法是推出了 compose UI。</p><p>不过遗憾的是这个方案引入了性能问题。我们专门测试使用 compose UI 做 100 个 slider 滑动的例子，流畅度也掉帧。</p><p>源码见：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Ftest-cross%2F-%2Ftree%2Fmaster%2Ftest_compose_ui_slider_100" target="_blank">https://gitcode.net/dcloud/test-cross/-/tree/master/test_compose_ui_slider_100</a>， 项目下有打包后的 apk 可以直接安装体验。</p><p>打开 GPU 呈现模式，可以看到 compose ui 的 100 个 slider 拖动时，大多数竖线都突破那条红色的掉帧安全横线，也就是掉帧严重。 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ixigua.com%2F7317199270568787978%3FlogTag%3D198750168701d834e8ac" target="_blank">点击查看视频</a></p><p>既然已经把不同开发框架的 slider-100 应用打包出来了，我们顺便也比较了不同框架下的包体积大小、内存占用：</p><table><thead><tr><th></th><th>包体积（单位:M）</th><th>内存占用（单位:Kb）</th></tr></thead><tbody><tr><td>flutter</td><td>18</td><td>141324.8</td></tr><tr><td>ArtUI-x</td><td>45.7</td><td>133091.2</td></tr><tr><td>uni-app x</td><td>8.5</td><td>105451.2</td></tr><tr><td>compose ui</td><td>4.5</td><td>97683.2</td></tr></tbody></table><p><strong>包体积数据说明：</strong></p><ul><li><p>包含 3 个 CPU 架构：arm64、arm32、x86_64。</p></li><li><p>flutter 的代码都是编译为 so 文件，支持的 cpu 类型和包体积是等比关系，1 个 cpu 最小需要 6M 体积，业务代码越多，cpu 翻倍起来越多。</p></li><li><p>ArtUI-x 的业务代码虽然写在 js 里，但除了引用了 flutter 外还引用了 js 引擎，这些 so 库体积都不小且按 cpu 分类型翻倍。</p></li><li><p>uni-app x 里主业务都在 kotlin 里，kotlin 和 Android x 的兼容库占据了不少体积。局部如图片引用了 so 库，1 个 cpu 最小需要 7M 体积。但由于 so 库小，增加了 2 个 cpu 类型只增加了不到 1M。</p></li><li><p>compose ui 没有使用 so 库，体积裁剪也更彻底。</p></li><li><p>uni-app x 的常用模块并没有裁剪出去，比如 slider100 的例子其实没有用到图片，但图片使用的 fesco 的 so 库还是被打进去了。实际业务中不可能不用图片，所以实际业务中 uni-app x 并不会比 compose ui 体积大多少。</p></li></ul><p><strong>内存占用数据说明：</strong></p><ul><li>在页面中操作 slider 数次后停止，获取应用内存使用信息 VmRSS: 进程当前占用物理内存的大小</li><li>表格中的内存数据是运行 5 次获取的值取平均值</li><li>自渲染会占据更多内存，如果还涉及混合渲染那内存占用更高</li></ul><h2>5. 后记</h2><p>跨语言通信、弱类型、混合渲染、包体积、内存占用，这些都是过去跨平台框架不如原生的地方。</p><p>这些问题在<code>uni-app x</code>都不存在，它只是换了一种写法的原生应用。</p><table><thead><tr><th>各种框架</th><th>类型</th><th>逻辑层与 UI 通信折损</th><th>逻辑层与 OS API 通信折损</th><th>混合渲染</th></tr></thead><tbody><tr><td>react native、nvue、weex</td><td>弱</td><td>有</td><td>有</td><td>无</td></tr><tr><td>flutter</td><td>强</td><td>无</td><td>有</td><td>有</td></tr><tr><td>微信 skyline、webF、ArkUI-x</td><td>弱</td><td>有</td><td>有</td><td>有</td></tr><tr><td>uni-app x</td><td>强</td><td>无</td><td>无</td><td>无</td></tr><tr><td>原生应用</td><td>强</td><td>无</td><td>无</td><td>无</td></tr></tbody></table><p>当然，作为一个客观的分析，这里需要强调<code>uni-app x</code>刚刚面世，还有很多不成熟的地方。比如前文 diss 微信的暗黑模式，其实截止到目前 uni-app x 还不支持暗黑模式。甚至 iOS 版现在只能开发 uts 插件，还不能做完整 iOS 应用。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvote.dcloud.net.cn%2F%23%2F%3Fname%3Duni-app%2520x" target="_blank">需求墙</a>里都是 uni-app x 该做还未做的。也欢迎大家投票。</p><p>另外，原生 Android 中一个界面不能有太多元素，否则性能会拉胯。flutter 的自渲染和 compose ui 解决了这个问题。而原生中解决这个问题需要引入自绘机制来降低元素数量，这个在<code>uni-app x</code>里对应的是 draw 自绘 API。</p><p>uni-app x 这个技术路线是产业真正需要的东西，随着产品的迭代完善，它能真正帮助开发者即提升开发效率又不牺牲性能。</p><p>让跨平台开发不如原生，成为历史。</p><p>欢迎体验 uni-app x 的示例应用，感受它的启动速度，渲染流畅度。</p><p>源码在：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.net%2Fdcloud%2Fhello-uni-app-x%2F" target="_blank">https://gitcode.net/dcloud/hello-uni-app-x/</a>； 或者扫描下方二维码下载打包后的 apk 文件：</p><p><img src="https://oscimg.oschina.net/oscnet/up-832ea9b51d5b53048d6ab133b791cc54ecb.png" alt="uts-01.png" referrerpolicy="no-referrer"></p><p>这个示例里有几个例子非常考验通信性能，除了也内置了 slider-100 外，另一个是「模版-scroll-view 自定义滚动吸顶」，在滚动时实时修改元素 top 值始终为一个固定值，一点都不抖动。</p><p>我们不游说您使用任何开发技术，但您应该知道它们的原理和差别。</p><p>欢迎指正和讨论。</p><h2>橄榄枝</h2><p><a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%AC%A2%E8%BF%8E%E5%AF%B9uni-app%E5%9B%A2%E9%98%9F%E6%84%9F%E5%85%B4%E8%B6%A3%E7%9A%84%E5%90%84%E4%BD%8D%E5%90%8C%E5%AD%A6%EF%BC%8C%E6%8A%95%E7%AE%80%E5%8E%86%E5%88%B0hr2013%40dcloud.io%E3%80%82" target="_blank">欢迎对 uni-app 团队感兴趣的各位同学，投简历到 hr2013@dcloud.io。</a></p><p>DCloud 是一个纯粹的工程师团队，公司 90% 的职员都是写代码的工程师，无需见客户、写方案，大部分都有原始股权，欢迎有好奇心、追求卓越的极客加盟。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 06:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/hbcui/blog/10590182</guid>
            <link>https://my.oschina.net/hbcui/blog/10590182</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Pulsar3.0 新功能介绍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://s2.loli.net/2024/01/03/1QuX3wI6P8hefLa.png" alt="Pulsar3.0-NewFeature.png" referrerpolicy="no-referrer"></p><p>在上一篇文章 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrossoverjie.top%2F2023%2F12%2F24%2Fob%2FPulsar3.0-upgrade%2F" target="_blank">Pulsar3.0 升级指北</a>讲了关于升级 Pulsar 集群的关键步骤与灾难恢复，本次主要分享一些 <code>Pulsar3.0</code> 的新功能与可能带来的一些问题。</p><h1>升级后所遇到的问题</h1><p>先来个欲扬先抑，聊聊升级后所碰到的问题吧。</p><p>其中有两个问题我们感知比较明显，特别是第一个。</p><h2>topic 被删除</h2><p>我们在上个月某天凌晨从 <code>2.11.2</code> 升级到 <code>3.0.1</code> 之后，进行了上一篇文章中所提到的功能性测试，发现没什么问题，觉得一切都还挺顺利的，半个小时搞定后就下班了。</p><p>结果哪知道第二天是被电话叫醒的，有部分业务反馈业务重启之后就无法连接到 Pulsar 了。</p><p><img src="https://s2.loli.net/2024/01/02/KUAnZ8W65jO3x7d.png" alt="image.png" referrerpolicy="no-referrer"> 最终定位是 topic 被删除了。</p><blockquote><p>其中的细节还蛮多的，修复过程也是一波三折，后面我会单独写一篇文章来详细梳理这个过程。</p></blockquote><p>在这个 issue 和 PR 中有详细的描述： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F21653" target="_blank">https://github.com/apache/pulsar/issues/21653</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fpull%2F21704" target="_blank">https://github.com/apache/pulsar/pull/21704</a></p><p>感兴趣的朋友也可以先看看。</p><h2>监控指标丢失</h2><p>第二个问题不是那么严重，是升级后发现 bookkeeper 的一些监控指标丢失了，比如这里的写入延迟： <img src="https://s2.loli.net/2024/01/02/9c7qs4CX1lejOIn.png" alt="image.png" referrerpolicy="no-referrer"> 我也定位了蛮久，但不管是官方的 docker 镜像还是源码编译都无法复现这个问题。</p><p>最终丢失的指标有这些：</p><ul><li>bookkeeper_server_ADD_ENTRY_REQUEST</li><li>bookkeeper_server_ADD_ENTRY_BLOCKED</li><li>bookkeeper_server_READ_ENTRY_BLOCKED</li><li>bookie_journal_JOURNAL_CB_QUEUE_SIZE</li><li>bookie_read_cache_hits_count</li><li>bookie_read_cache_misses_count</li><li>bookie_DELETED_LEDGER_COUNT</li><li>bookie_MAJOR_COMPACTION_COUNT</li></ul><p>详细内容可以参考这个 issue： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F21766" target="_blank">https://github.com/apache/pulsar/issues/21766</a></p><h1>新特性</h1><p>讲完了遇到的 bug，再来看看带来的新特性，重点介绍我们用得上的特性。</p><h2>支持低负载均衡</h2><p><img src="https://s2.loli.net/2024/01/02/KVpW4DyNimlMhqH.png" alt="image.png" referrerpolicy="no-referrer"></p><p>当我们升级或者是重启 broker 的时候，全部重启成功后其实会发现最后重启的那个 broker 是没有流量的。</p><p>这个原理和优化在之前写过的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrossoverjie.top%2F2023%2F02%2F07%2Fpulsar%2Fpulsar-load-banance%2F%23Pulsar-%25E8%25B4%259F%25E8%25BD%25BD%25E5%259D%2587%25E8%25A1%25A1%25E5%258E%259F%25E7%2590%2586" target="_blank">Pulsar 负载均衡原理及优化</a> 其实有详细介绍。</p><p>本次 3.0 终于将那个优化发版了，之后只要我们配置 <code>lowerBoundarySheddingEnabled: true</code> 就能开启这个低负载均衡的一个特性，使得低负载的 broker 依然有流量进入。</p><h2>跳过空洞消息</h2><p><img src="https://s2.loli.net/2024/01/02/nj2IyteVUQ79SBZ.png" alt="image.png" referrerpolicy="no-referrer"> Pulsar 可能会因为消息消费异常导致游标出现空洞，从而导致磁盘得不到释放；</p><p>所以我们有一个定时任务，会定期扫描积压消息的 topic 判断是否存在空洞消息，如果存在便可以在管理台使用 skipMessage API 跳过空洞消息，从而释放磁盘。</p><p>但在 3.0 之前这个跳过 API 存在 bug，只要跳过的数量超过 8 时，实际跳过的数量就会小于 8.</p><p>具体 issue 和修复过程在这里： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F20262" target="_blank">https://github.com/apache/pulsar/issues/20262</a><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fpull%2F20326" target="_blank">https://github.com/apache/pulsar/pull/20326</a></p><p>总之这个问题在 3.0 之后也是修复了，有类似需求的朋友也可以使用。</p><h2>新的负载均衡器</h2><p>同时也支持了一个新的负载均衡器，解决了以下问题：</p><ul><li>以前的负载均衡大量依赖 zk，当 topic 数量增多时对扩展性带来问题。 
  <ul><li>新的负载均衡器使用 <code>non-persistent</code> 来存储负载信息，就不再依赖 zk 。</li></ul></li><li>以前的负载均衡器需要依赖 <code>leader broker</code> 进行重定向到具体的 broker，其实这些重定向并无意义，徒增了系统开销。 
  <ul><li>新的负载均衡器使用了 SystemTopic 来存放 topic 的所有权信息，这样每个 broker 都可以拿到数据，从而不再需要从 leader broker 重定向了。</li></ul></li></ul><p>更多完整信息可以参考这个 PIP: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fissues%2F16691" target="_blank">PIP-192: New Pulsar Broker Load Balancer</a></p><h2>支持大规模延迟消息</h2><p>第二个重大特性是支持大规模延迟消息，相信是有不少企业选择 Pulsar 也是因为他原生就支持延迟消息。</p><p>我们也是大量在业务中使用延迟消息，以往的延迟消息有着以下一些问题：</p><ul><li>内存开销过大，延迟消息的索引都是保存在内存中，即便是可以分布在多个 broker 中分散存储，但消耗依然较大 
  <ul><li>重点优化了索引的内存占有量。</li></ul></li><li>重启 broker 时会消耗大量时候重建索引 
  <ul><li>支持了索引快照，最大限度的降低了构建索引的资源消耗。</li></ul></li></ul><h1>待优化功能</h1><h2>监控面板优化</h2><p>最后即便是升级到了 3.0 依然还有一些待优化的功能，在之前的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrossoverjie.top%2F2023%2F08%2F03%2Fob%2FPulsar-Client%2F" target="_blank">从 Pulsar Client 的原理到它的监控面板</a>中有提到给客户端加了一些监控埋点信息。</p><p>最终使用下来发现还缺一个 ack 耗时的一个面板，其实日常碰到最多的问题就是突然不能消费了（或者消费过慢）。</p><p>这时如果有这样的耗时面板，首先就可以定位出是否是消费者本身的问题。</p><p><img src="https://s2.loli.net/2024/01/03/YFoy4PfnRbz72qX.png" alt="image.png" referrerpolicy="no-referrer"> 目前还在开发中，大概类似于这样的数据。</p><h1>总结</h1><p>Pulsar3.0 是 Pulsar 的第一个 LTS 版本，推荐尽快升级可以获得长期支持。 但只要是软件就会有 bug，即便是 LTS 版本，所以大家日常使用碰到 Bug 建议多向社区反馈，一起推动 Pulsar 的进步。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 04:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/crossoverjie/blog/10678357</guid>
            <link>https://my.oschina.net/crossoverjie/blog/10678357</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 大模型首次牵手国民级综艺，昆仑万维天工 AI 联合《最强大脑》加速大模型落地]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>1 月 5 日周五晚 21:20，由昆仑万维「天工 APP」特约赞助的《最强大脑》第 11 季正式播出。</span></span></span></span></span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>这是 AI 大模型技术与国民级综艺 IP 的首度深度合作</span></span></span></span></strong><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>，在节目中，「天工 APP」将发挥其能搜、能聊、能写的多项超级 AI 大模型能力，与嘉宾选手深度互动，参与趣味脑力竞技环节，从而进一步推动大模型技术的普适应用，降低技术门槛，让越来越多的用户能够轻松、便捷地拥抱大模型。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-0d6fccfb6752359be7a21bfe88595876a12.png" width="1267" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>作为一档国内影响力最广、最具代表性的国民级的大型科学竞技综艺节目，《最强大脑》在过去十年间已成功举办了 10 期，在 372 个挑战项目中</span></span></span></span></span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>，</span></span></span></span></span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>近 600 位中外选手齐聚舞台，参与脑力竞技、传播科学知识，鼓励越来越多的观众们不断突破能力边界，开拓大脑潜能。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:justify"><img alt="" height="713" src="https://oscimg.oschina.net/oscnet/up-b1a63ff1d5fe64826bead3eefd0c56b6bad.png" width="1267" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>本次「天工 APP」与《最强大脑》第 11 季的深度合作，既是《最强大脑》在科学科普、赛制创新上的又一次尝试，</span></span></span></span></span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>也是以「天工 APP」为代表的 AI 大模型技术在用户更多日常使用场景中的推广与落地。</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img alt="" height="976" src="https://oscimg.oschina.net/oscnet/up-9741a5d12eccfbcf9dc28df09dd2ede734a.png" width="720" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>比如，在节目第一期的「天工开悟」环节中，用户可以通过在「天工 APP」中实时搜索「大位数速算法」，与台上的选手们同步学习运用心算技巧，挑战最强大脑。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img alt="" height="751" src="https://oscimg.oschina.net/oscnet/up-ea25660c5d5c9745295d24537388f01df14.png" width="661" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:center">&nbsp;</p><p style="margin-left:0; margin-right:0; text-align:center"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>与此同时，「天工 APP」还与《最强大脑》联合发起了</span></span></span></span></span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>脑力挑战赛</span></span></span></span></strong><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>，用户可进入「天工 APP」最强大脑专区，通过 15 道逻辑、计算、观察、记忆、空间、创造题目的作答，分析出用户专属的「脑力潜能六维图」，识别个人脑力潜能所在，从而有针对性地开发锻炼。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:left"><span><span><span><span><span style="color:#222222"><span>用户还可以在「天工 APP」里为喜欢的选手投票助威，并赢得亲临现场的机会，共同见证本季脑王夺冠时刻。</span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><span><span style="background-color:#ffffff"><span><span style="color:#222222"><span>随着后续节目的播出，还将有更多来自「天工 APP」的「惊喜彩蛋」，全方位地展现 AI 大模型技术在不同场景中如何为用户学习生活带来便利，降低技术门槛，推动大模型技术走入千家万户，让 AI 触手可及。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span><span><span><span><strong><span style="background-color:#ffffff"><span><span style="color:#222222"><span>每周五晚 21:20 锁定江苏衞视，昆仑万维天工 APP 携手《最强大脑》第 11 季，天赋回归，脑力封神。</span></span></span></span></strong></span></span></span></span></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 04:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274703</guid>
            <link>https://www.oschina.net/news/274703</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[某中学采购「智能互动宣泄仪」——实则为任天堂 Wii 的套壳]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近，广州某中学的学生在网上发帖称，该校采购了「智能互动宣泄仪」帮助学生们释放压力，该设备功能特征包括：人机互动、体感训练、体能检测、力学感知、身心平衡训练、虚拟运动训练、建立宣泄档案。</p><p>根据学生在微博上发布的视频，所谓「智能互动宣泄仪」<strong>其实是一台任天堂 Wii 游戏机连接了一个显示屏</strong>，但其采购价高达 46000 元。而在电商平台上，任天堂 Wii 游戏机价格为 600 元左右。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1c72c99904de625f4332ee6f95291e7b59c.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-10711ecb9c79de2a4a684bd2258d3c2b699.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ff968abd3c6c2bc39a5823ed41712f0c0ce.png" referrerpolicy="no-referrer"></p><p>参见下图，这确实是物理意义上的「套壳」：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-58cd5cf8c2ac60c565c31e8513b12e1ec64.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 03:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274693</guid>
            <link>https://www.oschina.net/news/274693</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TIOBE 2023 年度编程语言：C#]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TIOBE&nbsp;宣布&nbsp;2023 年度编程语言花落&nbsp;C#，这是&nbsp;C# 在 TIOBE 指数历史上首次荣获年度编程语言的奖项。</p><p><img height="64" src="https://oscimg.oschina.net/oscnet/up-db2c2ac24b28289dd46cdbf4bea8067aa28.png" width="700" referrerpolicy="no-referrer"></p><p>一直以来，C# 都稳居榜单前十名，去年则成为了年度涨幅最大的语言（+1.43%）。紧随其后的是 Scratch（+0.83%）和 Fortran（+0.64%）</p><p><span style="color:#000000">TIOBE CEO&nbsp;Paul Jansen 认为，</span>C# 正在追赶四大语言的步伐，蚕食 Java 的市场份额，并在<span style="color:#24292e">Web 应用程序后端和游戏</span>（得益于 Unity）等领域越来越受欢迎。「C# 可以免费使用，而且发展速度稳定，每次发布新版本都会使语言更具表现力。C# 将继续存在，甚至可能很快超过 Java。」</p><p>除此之外，去年的 TIOBE 指数还发生了一些其他的有趣变化。Fortran 和 Kotlin 取代了 R 和 Perl，常驻榜单 Top 20。一个有趣的问题是：2024 年，哪些语言将进入 TIOBE 指数前 20 名？</p><p><span style="color:#000000">Paul 的观点是：</span>很难预测。2023 年，Julia 曾短暂进入 TIOBE 指数，但未能保持这一位置；要想获得第二次机会，则需要 Julia 语言和社区的成熟。「我会把赌注押在 Dart（with&nbsp;Flutter）和 TypeScript 上。后者已经在业界得到了广泛应用，但由于某些原因，它还没有在 TIOBE 指数中取得突破。让我们拭目以待 2024 年的发展。」</p><p><strong style="color:#333333">TIOBE 1 月 TOP 20 编程语言</strong></p><p><img height="413" src="https://oscimg.oschina.net/oscnet/up-51cde871f2fcdc7b05035d73cd44695f53c.png" width="500" referrerpolicy="no-referrer"></p><p>Scratch 相较上月上升一位&nbsp;<span style="background-color:#ffffff; color:#000000">(11→10)</span>，进入&nbsp;Top 10 榜单；Assembly language 被挤落，从第 10 位跌至 15。<span style="background-color:#ffffff; color:#000000">其他语言的一些波动还包括：</span></p><ul><li><span style="background-color:#ffffff; color:#333333">Go<span>&nbsp;</span></span><span style="background-color:#ffffff; color:#000000">的排名从 13 又回升至 11</span></li><li><span style="background-color:#ffffff; color:#000000">Delphi/Object Pascal&nbsp;</span><span style="background-color:#ffffff; color:#000000">的排名从 16 升至 13</span></li><li><span style="color:#000000">Swift&nbsp;<span style="background-color:#ffffff">的排名从 </span></span><span style="background-color:#ffffff; color:#000000">17 升至 16</span></li><li><span style="color:#000000">Kotlin&nbsp;<span style="background-color:#ffffff">的排名从 15&nbsp;跌至 17</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Ruby 的排名从 19 升至 18</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">Rust 的排名从 18 跌至 19</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">COBOL&nbsp;的排名从 23 升至 20</span></span></li><li><span style="background-color:#ffffff; color:#000000">Fortran、MATLAB 则分别保持第 12、14 位不变；上月榜单中第 20 位的 R 语言，在本月榜单中跌至了第 23 位，与&nbsp;</span><span style="color:#000000"><span style="background-color:#ffffff">COBOL 排名进行了互换。</span></span></li></ul><p><strong style="color:#333333">TOP 10 编程语言 TIOBE 指数走势（2002-2024）</strong></p><p><img height="222" src="https://oscimg.oschina.net/oscnet/up-dc9e870242c6d049337fb838adea09a3236.png" width="700" referrerpolicy="no-referrer"></p><p><strong style="color:#333333">第 21-50 名编程语言排行</strong></p><p><img height="439" src="https://oscimg.oschina.net/oscnet/up-a98ae6f64844c6dc2d91b93487afbf1725d.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#000000">第 51-100 名如下，由于它们之间的数值差异较小，仅以文本形式列出（按字母排序）：</span></p><blockquote><p>Algol, AutoLISP, Avenue, Bash, bc, Boo, CIL, CL (OS/400), CLIPS, Clojure, CLU, Curl, DiBOL, Erlang, Forth, Hack, Icon, Io, J, J#, JScript, LabVIEW, Ladder Logic, Lingo, LiveCode, M4, Maple, MQL5, NATURAL, Nim, OpenEdge ABL, PL/I, PostScript, PowerShell, Pure Data, Q, Racket, REXX, Ring, RPG, Scheme, Snap!, Solidity, SPARK, SPSS, Squirrel, Stata, Wolfram, Xojo, XQuery</p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">TIOBE 编程社区指数（The TIOBE Programming Community index）是一个衡量编程语言受欢迎程度的指标，该指数每月更新一次。评判的依据来自世界范围内的工程师、课程和第三方供应商，包括流行的搜索引擎，如 Google、必应、雅虎、维基百科、亚马逊、YouTube 和百度都被用于指数计算。值得注意的是，TIOBE 指数并不代表编程语言的好坏或编写代码的多少。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#000000">该指数可以用来检查你的编程技能是否还能跟上时代的步伐，或者在开始建立一个新的软件系统时，基于指数对采用何种编程语言做出决策。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F" target="_blank">TIOBE 指数</a><span style="color:#000000">的定义方式，以及详细榜单信息<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F" target="_blank">均可查看官网</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 03:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274691/tiobe-index-202401</guid>
            <link>https://www.oschina.net/news/274691/tiobe-index-202401</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[欢迎 Tianai-Captcha 加入 Dromara 开源社区，可能是开源界最好用的行为验证码工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>作者介绍</h2><blockquote><p>95 后大龄程序员，一名野生的民间技术爱好者，15 年学习编程技术，迫于生计于 17 年就职于某电商公司， 在从业生涯中，本项目 2020 年发布后，后续也是改改停停，自古闲人出金货，也许有一天笔者自由了，会好好的完善这套框架。</p></blockquote><h2>引言:</h2><blockquote><p>譬如在今之网络世界，为保障资讯之安全，凡入网之人或事，多须经由验证之法以证实己身之真实性。是以，验证码乃必不可少之一环也。其重要性备矣，具诚信者无不体知。</p><p>朕观网络之变幻，验证码多以随机字母构成者为众所周知。然而，此类验证码对于一般用户而言，尤其易于应用。盖因滑动、点选等高级验证码，虽能提供更加友好之体验，然然不易于普通用户之应用。</p><p>吾观察于平民百姓，多未涉猎于技术深处，对于复杂之滑动、点选类验证码而言，或存不解其所在。且诸多普通用户或使用传统设备，或因技术限制而难以适用此等新颖验证码。是以，此类验证码对于普罗百姓而言，未免难以为继。</p><p>嗟乎！有智者闻我国民之难，乃发明滑动及点选验证码以应民需，其善心可嘉。彼将此等验证码开源，使广大百姓得以轻松接纳，实属可喜可贺。</p><p>滑动及点选验证码之开源，如一泓清泉，涤荡网络之隐忧。于此，一般百姓不复为验证码所困，得以轻松、便利之享用。其操作简便，贴近生活，解民忧而广受欢迎，实为普及网络安全之一良策。</p><p>开源此等验证码者，其举措实乃有益于民众。不仅促进了网络安全，亦鼓舞了普罗百姓参与其中之热情。愿诸般良好之举措，皆能为社会大众所接纳，盛行于世。</p></blockquote><hr><h2>关于 TIANAI-CAPTCHA</h2><p><code>tianai-captcha</code>简称<code>tac</code>，是一款集成滑动类、点选类的一款行为验证码，以使用简单、安全性强、界面美观、接入方便而，是为集好看、功能多、安全性强的一款开源行为验证码工具。</p><hr><p><img alt="" src="https://files.mdnice.com/user/29321/f7dbe307-c5c2-4ee4-b3ec-1434a22b5b28.jpg" referrerpolicy="no-referrer"></p><p><img alt="" src="https://files.mdnice.com/user/29321/98590d8c-b83d-40d1-a136-028372f94236.jpg" referrerpolicy="no-referrer"></p><h2>在线体验</h2><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcaptcha.tianai.cloud" target="_blank">http://captcha.tianai.cloud</a></p><h2>使用方式</h2><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fdoc.captcha.tianai.cloud" target="_blank">http://doc.captcha.tianai.cloud</a></p><h2>源码地址</h2><p><a href="https://gitee.com/dromara/tianai-captcha">https://gitee.com/dromara/tianai-captcha</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdromara%2Ftianai-captcha" target="_blank">https://github.com/dromara/tianai-captcha</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274680</guid>
            <link>https://www.oschina.net/news/274680</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[马化腾回应早期微信「偷窥」用户相册：图片缓存加速造成的误会]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据 CSDN 报道，针对早前有软件工程师爆料称包括微信等在内的多款国民级 App 在后台反复读取用户相册一事，1 月 5 日，马化腾独家回应：「应该是 21 年 10 月的事了，图片缓存加速造成的误会，后面应该用 iOS 新的解决卡顿的 API 解决了」。并特别表示，「可以帮忙辟谣」。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-61301141026d7bfed6e78fc18961393ff36.png" referrerpolicy="no-referrer"></p><p>事情的前因还要追溯到 2021 年 10 月 8 日，当时苹果 iOS 15 刚刚推出隐私新特性 「记录 App 活动」，对所有 App 的隐私读取行为进行了 7 天的监控，并使用 App Privacy Insights 对记录进行读取。 &nbsp;数码博主、软件开发工程师 @Hackl0us 发现微信在用户未主动激活 App 的情况下，在后台数次读取用户相册，每次读取时间长达 40 秒，至 1 分钟不等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5c44695ad62718318a0289820dd5dc8bb89.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274667</guid>
            <link>https://www.oschina.net/news/274667</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ParadeDB —— 基于 Postgres 的 ElasticSearch 替代方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">ParadeDB 是</span>基于 Postgres 构建的开源 ElasticSearch 替代方案<span style="color:#000000">。开发团队正在构建 ElasticSearch 产品套件的功能，首先是搜索。</span></p><p><span style="color:#000000">ParadeDB 提供所有 Postgres 数据库中最全面的 Postgres 原生搜索功能。</span></p><ul><li><strong>全文搜索</strong>。使用可配置的分词器、17 种语言的词干以及基于 SQL 的可扩展查询语言按关键字或短语进行搜索。</li><li><strong>相似性搜索</strong>。使用预安装的 pgvector 扩展和工作流程按语义进行搜索，逐步保持向量同步。</li><li><strong>混合搜索</strong>。通过混合搜索提供更高精确度和召回率的结果，该搜索结合了全文搜索和相似性搜索的优势。</li><li><strong>BM25 Scoring</strong>。全文搜索结果按 BM25 排序，BM25 是 ElasticSearch 使用的基于术语的排名算法。</li><li><strong>分面搜索</strong>。通过分面搜索存储和收集搜索结果的统计指标。</li><li><strong>分布式搜索</strong>。ParadeDB 自动对索引进行分片，使开发人员的搜索速度比单节点 Postgres 快数百倍。</li></ul><p>ParadeDB 的搜索引擎基于 Tantivy 开发，Tantivy 是 Apache Lucene 的基于 Rust 的实现。</p></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/paradedb</guid>
            <link>https://www.oschina.net/p/paradedb</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 轻量级隐私计算任务编排框架 Kuscia]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-kuscia" class="anchor" href="https://gitee.com/secretflow/kuscia#kuscia"></a>Kuscia</h1><p><a href="https://gitee.com/link?target=https%3A%2F%2Fdl.circleci.com%2Fstatus-badge%2Fredirect%2Fgh%2Fsecretflow%2Fkuscia%2Ftree%2Fmain"><img src="https://dl.circleci.com/status-badge/img/gh/secretflow/kuscia/tree/main.svg?style=svg" alt="CircleCI" referrerpolicy="no-referrer"></a></p><p align="center"><a href="https://gitee.com/secretflow/kuscia/blob/main/README.zh-CN.md">简体中文</a>｜<a href="https://gitee.com/secretflow/kuscia/blob/main/README.md">English</a></p><p>Kuscia（Kubernetes-based Secure Collaborative InfrA）是一款基于 K3s 的轻量级隐私计算任务编排框架，旨在屏蔽异构基础设施和协议，并提供统一的隐私计算底座。通过 Kuscia：</p><ul><li>你可以快速体验隐私计算功能。</li><li>你可以获得完整的隐私计算生产能力。</li><li>你可以与行业内多种隐私计算系统进行互联互通。</li><li>你可以使用不同的中心化或点对点业务组网模式。</li></ul><p><img src="https://gitee.com/secretflow/kuscia/raw/main/docs/imgs/kuscia_architecture.png" alt="Kuscia" referrerpolicy="no-referrer"></p><h2><a id="user-content-文档" class="anchor" href="https://gitee.com/secretflow/kuscia#%E6%96%87%E6%A1%A3"></a>文档</h2><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2F">Kuscia</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Fgetting_started%2Findex.html">准备开始</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Freference%2Findex.html">参考手册</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Ftutorial%2Findex.html">教程</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.secretflow.org.cn%2Fdocs%2Fkuscia%2Flatest%2Fzh-Hans%2Fdevelopment%2Findex.html">开发</a></li></ul><h2><a id="user-content-贡献代码" class="anchor" href="https://gitee.com/secretflow/kuscia#%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81"></a>贡献代码</h2><p>请查阅 <a href="https://gitee.com/secretflow/kuscia/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></p><h2><a id="user-content-声明" class="anchor" href="https://gitee.com/secretflow/kuscia#%E5%A3%B0%E6%98%8E"></a>声明</h2><p>非正式发布的 Kusica 版本仅用于演示，请勿在生产环境中使用。尽管此版本已涵盖 Kuscia 的基础功能，但由于项目存在功能不足和待完善项，可能存在部分安全问题和功能缺陷。因此，我们欢迎你积极提出建议，并期待正式版本的发布。</p>]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 02:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/secretflow/kuscia</guid>
            <link>https://gitee.com/secretflow/kuscia</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 米哈游大数据云原生实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><em>作者：米哈游大数据开发</em></p><p>近年来，容器、微服务、Kubernetes 等各项云原生技术的日渐成熟，越来越多的公司开始选择拥抱云原生，并开始将 AI、大数据等类型的企业应用部署运行在云原生之上。以 Spark 为例，在云上运行 Spark 可以充分享有公共云的弹性资源、运维管控和存储服务等，并且业界也涌现了不少 Spark on Kubernetes 的优秀实践。</p><p>在刚刚结束的 2023 云栖大会上，米哈游数据平台组大数据技术专家杜安明分享了米哈游大数据架构向云原生化升级过程中的目标、探索和实践，以及如何通过以阿里云容器服务 ACK 为底座的 Spark on K8s 架构，获得在弹性计算、成本节约以及存算分离方面的价值。</p><h2>背景简介</h2><p>随着米哈游业务的高速发展，大数据离线数据存储量和计算任务量增长迅速，早期的大数据离线架构已不再满足新场景和需求。</p><p>为了解决原有架构缺乏弹性、运维复杂、资源利用率低等问题，2022 年下半年，我们着手调研将大数据基础架构云原生化，并最终在阿里云上落地了 Spark on K8s + OSS-HDFS 方案，目前在生产环境上已稳定运行了一年左右的时间，并获得了弹性计算、成本节约以及存算分离这三大收益。</p><p><strong>1. 弹性计算</strong></p><p>由于游戏业务会进行周期版本更新、开启活动以及新游戏的上线等，对离线计算资源的需求与消耗波动巨大，可能是平时水位的几十上百倍。利用 K8s 集群天然的弹性能力，将 Spark 计算任务调度到 K8s 上运行，可以比较轻松的解决这类场景下资源消耗洪峰问题。</p><p><strong>2. 成本节约</strong></p><p>依托阿里云容器服务 Kubernetes 版 ACK 集群自身强大的弹性能力，所有计算资源按量申请、用完释放，再加上我们对 Spark 组件的定制改造，以及充分利用 ECI Spot 实例，在承载同等计算任务和资源消耗下，成本节约达 50%。</p><p><strong>3. 存算分离</strong></p><p>Spark 运行在 K8s 之上，完全使用 K8s 集群的计算资源，而访问的则数据也由 HDFS、OSS 逐步切换到 OSS-HDFS 上，中间 Shuffle 数据的读写采用 Celeborn，整套架构实现了计算和存储的解耦，易于维护和扩展。</p><h2>Spark on K8s&nbsp;架构演进</h2><p>众所周知，Spark 引擎可以支持并运行在多种资源管理器之上，比如 Yarn、K8s、Mesos 等。在大数据场景下，目前国内大多公司的 Spark 任务还是运行在 Yarn 集群之上的，Spark 在 2.3 版本首次支持 K8s，并于 2021 年 3 月发布的 Spark3.1 版本才正式 GA。</p><p>相较于 Yarn，Spark 在 K8s 上起步较晚，尽管在成熟度、稳定性等方面还存在一定的欠缺，但是 Spark on K8s 能够实现弹性计算以及成本节约等非常突出的收益，所以各大公司也都在不断进行尝试和探索，在此过程中，Spark on K8s 的运行架构也在不断的向前迭代演进。</p><p><img src="https://oscimg.oschina.net/oscnet/up-91f57f93e692da3c3bc6738e3cbe09d8dce.png" alt="" referrerpolicy="no-referrer"></p><h3>1. 在离线混部</h3><p>目前，将 Spark 任务运行在 K8s 上，大多公司采用的方案依旧是在线与离线混合部署的方式。架构设计依据的原理是，不同的业务系统会有不同的业务高峰时间。大数据离线业务系统典型任务高峰期间会是凌晨的&nbsp;0&nbsp;点到 9 点钟，而像是各种应用微服务、Web 提供的 BI 系统等，常见的业务高峰期是白天时间，在这个时间以外的其它时间中，可以将业务系统的机器 Node 加入到 Spark 所使用的 K8s NameSpace &nbsp;中。如下图所示，将 Spark 与其他在线应用服务等都部署在一套 K8s 集群之上。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c37f20f1df91812d5e7c562815e3b9f0ed4.png" alt="" referrerpolicy="no-referrer"></p><p>该架构的优点是可以通过在离线业务的混合部署和错峰运行，来提升机器资源利用率并降低成本，但是缺点也比较明显，即架构实施起来复杂，维护成本比较高，而且难以做到严格的资源隔离，尤其是网络层面的隔离，业务之间不可避免的会产生一定的相互影响，此外，我们认为该方式也不符合云原生的理念和未来发展趋势。</p><h3>2. Spark&nbsp;on&nbsp;K8s&nbsp;+&nbsp;OSS-HDFS</h3><p>考虑到在离线混合部署的弊端，我们设计采用了一种新的、也更加符合云原生的实现架构：底层存储采用 OSS-HDFS(JindoFs)，计算集群采用阿里云的容器服务 ACK，Spark 选择功能相对丰富且比较稳定的 3.2.3 版本。</p><p>OSS-HDFS 完全兼容了 HDFS 协议，除了具备 OSS 无限容量、支持数据冷热存储等优点以外，还支持了目录原子性、毫秒级 rename 操作，非常适用于离线数仓，可以很好的平替现有 HDFS 和 OSS。</p><p>阿里云 ACK 集群提供了高性能、可伸缩的容器应用管理服务，可以支持企业级 Kubernetes 容器化应用的生命周期管理，ECS 是大家所熟知的阿里云服务器，而弹性容器实例 ECI 是一种 Serverless 容器运行服务，可以按量秒级申请与释放。</p><p>该架构简单易维护，底层利用 ECI 的弹性能力，Spark 任务可以较为轻松的应对高峰流量，将 Spark 的 Executor 调度在 ECI 节点上运行，可最大程度的实现计算任务弹性与最佳的降本效果，整体架构的示意图如下所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-02cd50d97a62975f921948f5fa16139e6dc.png" alt="" referrerpolicy="no-referrer"></p><h2>云原生架构设计与实现</h2><h3>1. 基本原理</h3><p>在阐述具体实现之前，先简要介绍一下 Spark 在 K8s 上运行的基本原理。Pod 在 K8s 中是最小的调度单元，Spark 任务的 Driver 和 Executor 都是一个单独 Pod，每个 Pod 都分配了唯一的 IP 地址，Pod 可以包含一个或多个 Container，无论是 Driver 还是 Executor 的 JVM 进程，都是在 Container 中进行启动、运行与销毁的。</p><p>一个 Spark 任务被提交到 K8s 集群之后，首先启动的是 Driver Pod，而后 Driver 会向 Apiserver 按需申请 Executor，并由 Executor 去执行具体的 Task，作业完成之后由 Driver 负责清理所有的 Executor Pod，以下是这几者关系的简要示意图。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f76c245cf83130f4a99cf98056228951683.png" alt="" referrerpolicy="no-referrer"></p><h3>2. 执行流程</h3><p>下图展示了完整的作业执行流程，用户在完成 Spark 作业开发后，会将任务发布到调度系统上并进行相关运行参数的配置，调度系统定时将任务提交到自研的 Launcher 中间件，并由中间件来调用 spark-k8s-cli，最终由 Cli 将任务提交至 K8s 集群上。任务提交成功之后，Spark Driver Pod 最先启动，并向集群申请分配 Executor Pod，Executor 在运行具体的 Task 时，会与外部 Hive、Iceberg、OLAP 数据库、OSS-HDFS 等诸多大数据组件进行数据的访问与交互，而 Spark Executor 之间的数据 Shuffle 则由 CeleBorn 来实现。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f5d39e0da69d013c767af359682cf71fc2a.png" alt="" referrerpolicy="no-referrer"></p><h3>3. 任务提交</h3><p>关于如何将 Spark 任务提交到 K8s 集群上，各个公司的做法不尽相同，下面先简要描述下目前比较常规的做法，然后再介绍目前我们线上所使用的任务提交和管理方式。</p><h4>3.1 使用原生 spark-submit</h4><p>通过 spark-submit 命令直接提交，Spark 原生就支持这种方式，集成起来比较简单，也符合用户的习惯，但是不方便进行作业状态跟踪和管理，无法自动配置 Spark UI 的 Service 和 Ingress，任务结束后也无法自动清理资源等，在生产环境中并不适合。</p><h4>3.2 使用 spark-on-k8s-operator</h4><p>这是目前较常用的一种提交作业方式，K8s 集群需要事先安装 spark-operator，客户端通过 kubectl 提交 yaml 文件来运行 Spark 作业。本质上这是对原生方式的扩展，最终提交作业依然是使用 spark-submit 方式，扩展的功能包括：作业管理，Service/Ingress 创建与清理，任务监控，Pod 增强等。此种方式可在生产环境中使用，但与大数据调度平台集成性不太好，对于不熟悉 K8s 的用户来说，使用起来复杂度和上手门槛相对较高。</p><h4>3.3 使用 spark-k8s-cli</h4><p>在生产环境上，我们采用 spark-k8s-cli 的方式进行任务的提交。spark-k8s-cli 本质上是一个可执行的文件，基于阿里云 emr-spark-ack 提交工具我们进行了重构、功能增强和深度的定制。</p><p>spark-k8s-cli 融合 spark-submit 和 spark-operator 两种作业提交方式的优点，使得所有作业都能通过 spark-operator 管理，支持运行交互式 spark-shell 和本地依赖的提交，并且在使用方式上与原生 spark-submit 语法完全一致。</p><p>在上线使用初期，我们所有任务的 Spark Submit JVM 进程都启动在 Gateway Pod 中，在使用一段时间后，发现该方式稳定性不足，一旦 Gateway Pod 异常，其上的所有正在 Spark 任务都将失败，另外 Spark 任务的日志输出也不好管理。鉴于此种情况，我们将 spark-k8s-cli 改成了每个任务使用单独一个 Submit Pod 的方式，由 Submit Pod 来申请启动任务的 Driver，Submit Pod 和 Driver Pod 一样都运行在固定的 ECS 节点之上，Submit Pod 之间完全独立，任务结束后 Submit Pod 也会自动释放。spark-k8s-cli 的提交和运行原理如下图所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-727f4fc057aedcd02fbc83b3b98bce9db35.png" alt="" referrerpolicy="no-referrer"></p><p>关于 spark-k8s-cli，除了上述基本的任务提交以外，我们还做了其他一些增强和定制化的功能。</p><ul><li>支持提交任务到同地域多个不同的 K8s 集群上，实现集群之间的负载均衡和故障转移切换</li><li>实现类似 Yarn 资源不足时的自动排队等待功能&nbsp;（K8s 如果设置了资源 Quota，当 Quota 达到上限后，任务会直接失败）</li><li>增加与 K8s 网络通信等异常处理、创建或启动失败重试等，对偶发的集群抖动、网络异常进行容错</li><li>支持按照不同部门或业务线，对大规模补数任务进行限流和管控功能</li><li>内嵌任务提交失败、容器创建或启动失败以及运行超时等告警功能</li></ul><h3>4. 日志采集与展示</h3><p>K8s 集群本身并没有像 Yarn 那样提供日志自动聚合和展示的功能，Driver 和 Executor 的日志收集需要用户自己来完成。目前比较常见的方案是在各个 K8s Node 上部署 Agent，通过 Agent 把日志采集并落在第三方存储上，比如 ES、SLS 等，但这些方式对于习惯了在 Yarn 页面上点击查看日志的用户和开发者来说，使用起来很不方便，用户不得不跳转到第三方系统上捞取查看日志。</p><p>为实现 K8s Spark 任务日志的便捷查看，我们对 Spark 代码进行了改造，使 Driver 和 Executor 日志最终都输出到 OSS 上，用户可以在 Spark UI 和 Spark Jobhistory 上，直接点击查看日志文件。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0eace11cc08cce9ab78ba861cb398c35717.png" alt="" referrerpolicy="no-referrer"></p><p>上图所示为日志的收集和展示原理，Spark 任务在启动时，Driver 和 Executor 都会首先注册一个 Shutdown Hook，当任务结束 JVM 退出时，调用 Hook 方法把完整的日志上传到 OSS 上。此外，想要完整查看日志，还需要对 Spark 的 Job History 相关代码做下改造，需要在 History 页面显示 stdout 和 stderr，并在点击日志时，从 OSS 上拉取对应 Driver 或 Executor 的日志文件，最终由浏览器渲染查看。另外，对于正在运行中的任务，我们会提供一个 Spark Running Web UI 给用户，任务提交成功后，spark-operator&nbsp;会自动生成的 Service 和 Ingress 供用户查看运行详情，此时日志的获取通过访问 K8s 的 api 拉取对应 Pod 的运行日志即可。</p><h3>5. 弹性与降本</h3><p>基于 ACK 集群提供的弹性伸缩能力，再加上对 ECI 的充分利用，同等规模量级下的 Spark 任务，运行在 K8s 的总成本要明显低于在 Yarn 固定集群上，同时也大大提高了资源利用率。</p><p>弹性容器实例 ECI 是一种 Serverless 容器运行服务，ECI 和 ECS 最大的不同就在于 ECI 是按量秒级计费的，申请与释放速度也是秒级的，所以 ECI 很适合 Spark 这一类负载峰谷明显的计算场景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-265d37ec5e9ec1a64b70219ca89169e35bc.png" alt="" referrerpolicy="no-referrer"></p><p>上图示意了 Spark 任务在 ACK 集群上如何申请和使用 ECI，使用前提是在集群中安装 ack-virtual-node 组件，并配置好 Vswitch 等信息，在任务运行时，Executor 被调度到虚拟节点上，并由虚拟节点申请创建和管理 ECI。</p><p>ECI 分为普通实例和抢占式实例，抢占式实例是一种低成本竞价型实例，默认有 1 小时的保护期，适用于大部分 Spark 批处理场景，超出保护期后，抢占式实例可能被强制回收。为进一步提升降本效果，充分利用抢占式实例的价格优势，我们对 Spark 进行改造，实现了 ECI 实例类型自动转换的功能。Spark 任务的 Executor Pod 都优先运行在抢占式 ECI 实例上，当发生库存不足或其他原因无法申请创建抢占式实例，则自动切换为使用普通 ECI 实例，保证任务的正常运行。&nbsp;具体实现原理和转换逻辑如下图所示。</p><p><img src="https://oscimg.oschina.net/oscnet/up-47f719ef69ab5b6992ea95f746548cc8ab4.png" alt="" referrerpolicy="no-referrer"></p><h3>6. Celeborn</h3><p>由于 K8s 节点的磁盘容量很小，而且节点都是用时申请、用完释放的，无法保存大量的 Spark Shuffle 数据。如果对 Executor Pod 挂载云盘，挂载盘的大小难以确定，考虑到数据倾斜等因素，磁盘的使用率也会比较低，使用起来比较复杂。此外，虽然 Spark 社区在 3.2 提供了 Reuse PVC 等功能，但是调研下来觉得功能尚不完备且稳定性不足。</p><p>为解决 Spark 在 K8s 上数据 Shuffle 的问题，在充分调研和对比多家开源产品后，最终采用了阿里开源的 Celeborn 方案。Celeborn 是一个独立的服务，专门用于保存 Spark 的中间 Shuffle 数据，让 Executor 不再依赖本地盘，该服务 K8s 和 Yarn 均可以使用。Celeborn 采用了 Push Shuffle 的模式，Shuffle 过程为追加写、顺序读，提升数据读写性能和效率。</p><p>基于开源的 Celeborn 项目，我们内部也做了一些数据网络传输方面的功能增强、Metrics 丰富、监控告警完善、Bug 修复等工作，目前已形成了内部稳定版本。</p><p><img src="https://oscimg.oschina.net/oscnet/up-08142d767f6df474b0c291a38b188840ab2.png" alt="" referrerpolicy="no-referrer"></p><h3>7. Kyuubi&nbsp;on&nbsp;K8s</h3><p>Kyuubi 是一个分布式和多租户的网关，可以为 Spark、Flink 或 Trino 等提供 SQL 等查询服务。在早期，我们的 Spark Adhoc 查询是发送到 Kyuubi 上执行的。为了解决 Yarn 队列资源不足，用户的查询 SQL 无法提交和运行的问题，在 K8s 上我们也支持了 Kyuubi Server 的部署运行，当 Yarn 资源不足时，Spark 查询自动切换到 K8s 上运行。鉴于 Yarn 集群规模逐渐缩减，查询资源无法保证，以及保障相同的用户查询体验，目前我们已将所有的 SparkSQL Adhoc 查询提交到 K8s 上执行。</p><p>为了让用户的 Adhoc 查询也能在 K8s 上畅快运行，我们对 Kyuubi 也做了一些源码改造，包括对 Kyuubi 项目中 docker-image-tool.sh、Deployment.yaml、Dockfile 文件的改写，重定向 Log 到 OSS 上，Spark Operator 管理支持、权限控制、便捷查看任务运行 UI 等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a97f1245c24b11a2c25c62b1bf824f0c0eb.png" alt="" referrerpolicy="no-referrer"></p><h3>8. K8s&nbsp;Manager</h3><p>在 Spark on K8s 场景下，尽管 K8s 有集群层面的监控告警，但是还不能完全满足我们的需求。在生产环境中，我们更加关注的是在集群上的 Spark 任务、Pod 状态、资源消耗以及 ECI 等运行情况。利用 K8s 的 Watch 机制，我们实现了自己的监控告警服务 K8s Manager，下图所示为该服务的示意图。</p><p><img src="https://oscimg.oschina.net/oscnet/up-530ec8ff85f98c8ff44efed2349011ef832.png" alt="" referrerpolicy="no-referrer"></p><p>K8sManager 是内部实现的一个比较轻量的 Spring Boot 服务，实现的功能就是对各个 K8s 集群上的 Pod、Quota、Service、ConfigMap、Ingress、Role 等各类资源信息监听和汇总处理，从而生成自定义的 Metrics 指标，并对指标进行展示和异常告警，其中包括集群 CPU 与 Memory 总使用量、当前运行的 Spark 任务数、Spark 任务内存资源消耗与运行时长 Top 统计、单日 Spark 任务量汇总、集群 Pod 总数、Pod 状态统计、ECI 机器型号与可用区分布统计、过期资源监控等等，这里就不一一列举了。</p><h3>9. 其他工作</h3><h4>9.1 调度任务自动切换</h4><p>在我们的调度系统中，Spark 任务支持配置 Yarn、K8s、Auto 三种执行策略。如果用户任务指明了需要运行使用的资源管理器，则任务只会在 Yarn 或 K8s 上运行，若用户选择了 Auto，则任务具体在哪里执行，取决于当前 Yarn 队列的资源使用率，如下图所示。由于总任务量较大，且 Hive 任务也在不断迁移至 Spark，目前仍然有部分任务运行在 Yarn 集群上，但最终的形态所有任务将由 K8s 来托管。</p><p><img src="https://oscimg.oschina.net/oscnet/up-35f4cbad3736b91872ac6f9bd97d486d940.png" alt="" referrerpolicy="no-referrer"></p><h4>9.2 多可用区、多交换机支持</h4><p>Spark 任务运行过程中大量使用 ECI，ECI 创建成功有两个前提条件: 1、能够申请到 IP 地址；2、当前可用区有库存。&nbsp;实际上，单个交换机提供的可用 IP 数量有限，单个可用区拥有的抢占式实例的总个数也是有限的，因此在实际生产环境中，无论是使用普通 ECI 还是 Spot 类型的 ECI，比较好的实践方式是配置支持多可用区、多交换机。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f08f0ecc5c0e2ea97499e52e5fd1a5f60c4.png" alt="" referrerpolicy="no-referrer"></p><h4>9.3 成本计算</h4><p>由于在 Spark 任务提交时，都已明确指定了每个 Executor 的 Cpu、Memory 等型号信息，在任务结束 SparkContxt 关闭之前，我们可以从任务的中拿到每个 Executor 的实际运行时长，再结合单价，即可计算出 Spark 任务的大致花费。由于 ECI Spot 实例是随着市场和库存量随时变动的，该方式计算出来的单任务成本是一个上限值，主要用于反映趋势。</p><h4>9.4 优化 Spark&nbsp;Operator</h4><p>在上线初期任务量较少时，Spark Operator 服务运行良好，但随着任务不断增多，Operator 处理各类 Event 事件的速度越来越慢，甚至集群出现大量的 ConfigMap、Ingress、Service 等任务运行过程中产生的资源无法及时清理导致堆积的情况，新提交 Spark 任务的 Web UI 也无法打开访问。发现问题后，我们调整了 Operator 的协程数量，并实现对 Pod Event 的批量处理、无关事件的过滤、TTL 删除等功能，解决了 Spark Operator 性能不足的问题。</p><h4>9.5 升级 Spark&nbsp;K8s&nbsp;Client</h4><p>Spark3.2.2 采用 fabric8(Kubernetes Java Client) 来访问和操作 K8s 集群中的资源，默认客户端版本为 5.4.1，在此版本中，当任务结束 Executor 集中释放时，Driver 会大量发送 Delete Pod 的 Api 请求到 K8s Apiserver 上，对集群 Apiserver 和 ETCD 造成较大的压力，Apiserver 的 cpu 会瞬间飙高。</p><p>目前我们的内部 Spark 版本，已将 kubernetes-client 升级到 6.2.0，支持 pod 的批量删除，解决 Spark 任务集中释放时，由大量的删除 Api 请求操作的集群抖动。</p><h2>问题与解决方案</h2><p>在整个 Spark on K8s 的方案设计以及实施过程中，我们也遇到了各种各样的问题、瓶颈和挑战，这里做下简单的介绍，并给出我们的解决方案。</p><h3>1.&nbsp;弹性网卡释放慢</h3><p>弹性网卡释放速度慢的问题，属于 ECI 大规模应用场景下的性能瓶颈，该问题会导致交换机上 IP 的剧烈消耗，最终导致 Spark 任务卡住或提交失败，具体触发原因如下图所示。目前阿里云团队已通过技术升级改造解决，并大幅提升了释放速度和整体性能。</p><p><img src="https://oscimg.oschina.net/oscnet/up-24660bc811456fd79a7853a00ff0a09a121.png" alt="" referrerpolicy="no-referrer"></p><h3>2.&nbsp;Watcher 失效</h3><p>Spark 任务在启动 Driver 时，会创建对 Executor 的事件监听器，用于实时获取所有 Executor 的运行状态，对于一些长时运行的 Spark 任务，这个监听器往往会由于资源过期、网络异常等情况而失效，因此在此情况下，需要对 Watcher 进行重置，否则任务可能会跑飞。该问题属于 Spark 的一个 Bug，当前我们内部版本已修复，并将 PR 提供到了 Spark 社区。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fe6ab9a8837a6d715aa3dbadb128573dc1d.png" alt="" referrerpolicy="no-referrer"></p><h3>3.&nbsp;任务卡死</h3><p>如上图所示，Driver 通过 List 和 Watch 两种方式来获取 Executor 的运行状况。Watch 采用被动监听机制，但是由于网络等问题可能会发生事件漏接收或漏处理，但这种概率比较低。List 采用主动请求的方式，比如每隔 3 分钟，Driver 可向 Apiserver 请求一次自己任务当前全量 Executor 的信息。</p><p>由于 List 请求任务所有 Pod 信息，当任务较多时，频繁 List 对 K8s 的 Apiserver 和 ETCD 造成较大压力，早期我们关闭了定时 List，只使用 Watch。当 Spark 任务运行异常，比如有很多 Executor OOM 了，有一定概率会导致 Driver Watch 的信息错误，尽管 Task 还没有运行完，但是 Driver 却不再申请 Executor 去执行任务，发生任务卡死。对此我们的解决方案如下:</p><ul><li>在开启 Watch 机制的同时，也开启 List 机制，并将 List 时间间隔拉长，设置每 5 分钟请求一次</li><li>修改 ExecutorPodsPollingSnapshotSource 相关代码，允许 Apiserver 服务端缓存，从缓存中获取全量 Pod 信息，降低 List 对集群的压力</li></ul><h3>4. Celeborn 读写超时、失败</h3><p>ApacheCeleborn 是阿里开源的一款产品，前身为 RSS(Remote Shuffle Service)。在早期成熟度上还略有欠缺，在对网络延迟、丢包异常处理等方面处理的不够完善，导致线上出现一些有大量 Shuffle 数据的 Spark 任务运行时间很长、甚至任务失败，以下三点是我们针对此问题的解决办法。</p><ul><li>优化 Celeborn，形成内部版本，完善网络包传输方面的代码</li><li>调优 Celeborn&nbsp;Master 和 Worker 相关参数，提升 Shuffle 数据的读写性能</li><li>升级 ECI 底层镜像版本，修复 ECI&nbsp;Linux 内核 Bug</li></ul><h3>5. 批量提交任务时，Quota 锁冲突</h3><p>为了防止资源被无限使用，我们对每个 K8s 集群都设置了 Quota 上限。在 K8s 中，Quota 也是一种资源，每一个 Pod 的申请与释放都会修改 Quota 的内容 (Cpu/Memory 值)，当很多任务并发提交时，可能会发生 Quota 锁冲突，从而影响任务 Driver 的创建，任务启动失败。</p><p>应对这种情况导致的任务启动失败，我们修改 Spark Driver Pod 的创建逻辑，增加可配置的重试参数，当检测到 Driver Pod 创建是由于 Quota 锁冲突引起时，进行重试创建。Executor Pod 的创建也可能会由于 Quota 锁冲突而失败，这种情况可以不用处理，Executor 创建失败 Driver 会自动申请创建新的，相当于是自动重试了。</p><h3>6.&nbsp;批量提交任务时，UnknownHost 报错</h3><p>当瞬时批量提交大量任务到集群时，多个 Submit Pod 会同时启动，并向 Terway 组件申请 IP 同时绑定弹性网卡，存在一定概率出现以下情况，即 Pod 已经启动了，弹性网卡也绑定成功但是实际并没有完全就绪，此时该 Pod 的网络通信功能实际还无法正常使用，任务访问 Core DNS 时，请求无法发出去，Spark 任务报错 UnknownHost 并运行失败。该问题我们通过下面这两个措施进行规避和解决：</p><ul><li>为每台 ECS 节点，都分配一个 Terway&nbsp;Pod</li><li>开启 Terway 的缓存功能，提前分配好 IP 和弹性网卡，新 Pod 来的直接从缓存池中获取，用完之后归还到缓存池中</li></ul><h3>7. 可用区之间网络丢包</h3><p>为保障库存的充足，各 K8s 集群都配置了多可用区，但跨可用区的网络通信要比同可用区之间通信的稳定性略差，即可用区之间就存在一定概率的丢包，表现为任务运行时长不稳定。</p><p>对于跨可用区存在网络丢包的现象，可尝试将 ECI 的调度策略设定为 VSwitchOrdered，这样一个任务的所有 Executor 基本都在一个可用区，避免了不同可以区 Executor 之间的通信异常，导致的任务运行时间不稳定的问题。</p><h2>总结与展望</h2><p>最后，非常感谢阿里云容器、ECI、EMR 等相关团队的同学，在我们整个技术方案的落地与实际迁移过程中，给予了非常多的宝贵建议和专业的技术支持。</p><p>目前新的云原生架构已在生产环境上稳定运行了近一年左右的时间，在未来，我们将持续对整体架构进行优化和提升，主要围绕以下几个方面:</p><ol><li><p>持续优化云原生的整体方案，进一步提升系统承载与容灾能力</p></li><li><p>云原生架构升级，更多大数据组件容器化，让整体架构更加彻底的云原生化</p></li><li><p>更加细粒度的资源管理和精准的成本控制</p></li></ol></div>
                                    ]]>
            </description>
            <pubDate>Mon, 08 Jan 2024 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/10404597</guid>
            <link>https://my.oschina.net/u/3874284/blog/10404597</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微信团队确认私密朋友圈存在 bug，现已修复]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微信团队今日上午通过微博回应了「<strong>私密朋友圈存在 bug</strong>」的问题。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-34320da0579bfc83ad3cb597de2fb3f1a80.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1930378853%2FNAIzytG5Y%23comment" target="_blank">https://weibo.com/1930378853/NAIzytG5Y</a></u></em></p></blockquote><p>从网友的反馈来看，许多微信用户最近在发布私密朋友圈时，好友会在入口看到提醒朋友圈更新的「小红点头像」。但点进去却发现对方并没有发布新内容。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-b0fe2ae650294a4d3684dc3e1ef41cb7cc6.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-30399efe2ea7df75517428697b41ed60bf4.png" referrerpolicy="no-referrer"></p><p><img height="1168" src="https://oscimg.oschina.net/oscnet/up-03c6871c585c1eec034fbf03e988cee454d.png" width="994" referrerpolicy="no-referrer"></p></blockquote><p>根据微信团队的回应，「私密朋友圈显示提醒」的 bug 仅在 1 月 1 日当天出现，并且是极小部分用户受影响。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 06:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274592</guid>
            <link>https://www.oschina.net/news/274592</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源之旅，.NET 流行框架 Furion 2023 年终总结]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一年又一年，已是物是人非</h1><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><img height="383" src="https://oscimg.oschina.net/oscnet/up-2cb38aa868c8eb4fa8ae6cfd1adb53f6921.png" width="900" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>开源之旅，曲折而又意义非凡。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">回想三年前，我初次迈出 Furion 开源项目的步伐，面对着一片质疑和嘲笑的声音。虽然这些声音刺痛了我的内心，但我并没有放弃。我选择专注于用户需求，持之以恒地改进代码质量和文档。艰辛与困难并没有打败我，相反，它们让我变得更坚定，更成熟。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>开源世界从来不是一个人的舞台，它需要众多开发者和用户的支持和参与。我深知，无论我怎样努力和完善我的项目，总会有人不喜欢，不认同。</strong>&nbsp;然而，这并不是我成长的障碍，反而是我成长的催化剂。<strong>我逐渐明白，不追求所有人的赞同，而是专注于为那些真正认可和喜欢我的工作的人提供更好的服务，才是更重要的。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">在这段开源之路上，我亦流连于困境和挫折中。<strong>磨难并不使人成长，但它们教会了我成熟和坚韧。我深知，每个人都会有自己的独特感受和看法，只有接受这个事实，并用成熟的心态去面对，才能不断发展自己，走向更高的成就。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">同时，我对国内开源人的不易有着深切的感受。在商业导向的社会中，选择投身开源事业需要巨大的勇气和决心。开源项目的作者们需要面对各种挑战和批评，但正是因为他们对开源事业的执着，社区才得以繁荣。我向每一位国内的开源爱好者致以崇高的敬意，你们是开源事业中不可或缺的一环。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">回首三周年的开源项目，我的内心充满了感慨。这段经历锤炼了我的意志和技术能力，让我从一个技术懵懂的新手成长为一个在领域中有所建树的人。虽然这个过程中并非一帆风顺，但我感激每一个困难和挑战，它们让我更加坚定地走在开源之路上。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>最后，我要衷心感谢所有支持和鼓励我的人。感谢那些相信我能够创造出有价值的开源项目的人，感谢那些给予我反馈和建议的人。</strong>&nbsp;同时，我也要向所有国内开源人表达我的敬意和感激之情。正因为有你们的努力和奉献，才有了开源事业的繁荣和进步。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>愿每一个开源爱好者都能坚守初心，用心对待用户需求，不断提升自己的技术水平。我们的开源项目不仅仅是一个代码库，更是我们对技术和自由精神的执着追求。</strong>&nbsp;相信自己，相信开源的力量，让我们继续前行，创造出更美好的明天！</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>开源 Furion 本是 ⌈无心之举⌋，未成想它成为我人生 ⌈志心之源⌋</strong></p><hr><h1>避不开的话题：开源与商业</h1><p><img height="1322" src="https://oscimg.oschina.net/oscnet/up-5ab9cc31a4279de753c445b4e2937ee94af.png" width="1710" referrerpolicy="no-referrer"></p><h2>自身价值</h2><p><span style="background-color:#ffffff; color:#3f3f3f">在面对外界的评价和期待时，我要保持内心的宁静和坚定。我的价值和能力不应该被别人的意见所影响，而应该建立在我对自己的自信和对用户需求的关注之上。通过坚持初衷和不断进步，我相信我可以为用户创造出更优秀的产品和服务。</span></p><p><strong><span style="background-color:#ffffff; color:#3f3f3f">知不足而奋进，望远山而前行。感谢一路同行</span></strong></p><h2>市场选择</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Furion 于 2020 年 09 月 01 日开源，在质疑和不被看好的环境中逐渐成长起来。<strong>与其说它的流行归结于自身的努力，不如说是市场的选择。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>任何东西都有其生命周期，适者生存。如果它哪天不 「适」 了，自然会消失；如果它一直 「适」 着，也就会一直存在着。</strong><span>&nbsp;</span>主要还是看它的特性有没有持续生命力。如果大家一直反馈，一直使用，那么它也将一直维护，一直更新，一直存在。</p><h2>开源商业</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">开源很困难，盈利也很困难，将开源与盈利结合更是难上加难。这个难题不在于技术，而在于思维的转变。困难的不是坚持，而是放下那种深藏心底的帮助他人并受到感激的情感。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>很多开源项目之所以未能实现商业化，主要原因是创作者对自己产品的价值持怀疑态度，他们质疑别人是否真的愿意为自己的产品付费。同时，他们在为自己的产品收费时会感到羞愧和愧疚。这也是许多开源项目无法实现商业化的主要原因。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">孔子虽满怀救国救民的良策，但深知天道不可违、人力有限，故一生颠簸坎坷。若想成就一番大事，不仅需要实力和经济支持，还要有不被现实所裹挟的决心。我们必须时刻保持警惕，不断磨砺自己，才能迎接未来的挑战。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>世俗的成功给人自由，你可以不屠龙，但是不能不磨剑。</strong></p><h2>命运之门</h2><p>网络中流行的一句热词是"命运的齿轮开始转动"，它源于日本动漫《命运石之门》。<strong>这句话传达了我们每一次的选择都有可能引发巨大的命运变化，从而导致完全不同的人生轨迹</strong>。</p><p><strong>此刻，命运的齿轮再次缓慢地转动......</strong></p><p><img height="450" src="https://oscimg.oschina.net/oscnet/up-c7eee0cfc9b9a6acaf5859d843f608145ed.png" width="720" referrerpolicy="no-referrer"></p><hr><h1>发展事记</h1><h2>2020 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232020-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2020 年 06 月 22 日</strong>，<code>Fur</code><span>&nbsp;</span>在 Gitee 平台创建空仓库<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/commit/25de190d83027fab58e72714ca7c044206607127" target="_blank">25de190</a>。</li><li><strong>2020 年 09 月 01 日</strong>，<code>Fur</code><span>&nbsp;</span>正式写下第一行代码。</li><li><strong>2020 年 10 月 01 日</strong>，<strong><code>Fur</code><span>&nbsp;</span>获得 Gitee 最有价值开源项目<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fimg%2Fgvp.png" target="_blank">GVP</a><span>&nbsp;</span>证书</strong>。</li><li><strong>2020 年 10 月 22 日</strong>，<code>Fur</code><span>&nbsp;</span>在 Gitee 平台获得 1000 stars.</li><li><strong>2020 年 11 月 11 日</strong>，<code>Fur</code><span>&nbsp;</span>单身节当天发布了<span>&nbsp;</span><code>1.0.0</code><span>&nbsp;</span>正式版。</li><li><strong>2020 年 11 月 18 日</strong>，<strong><code>Fur</code><span>&nbsp;</span>改名为<span>&nbsp;</span><code>Furion</code></strong>。<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/commit/a24acd44a70bac94d2af8ab290197478aa10ef51" target="_blank">a24acd4</a><span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/commit/97011efab563d88b3d369d4a6a8c9e7ac324123f" target="_blank">97011ef</a></li><li><strong>2020 年 11 月 23 日</strong>，<code>Furion</code><span>&nbsp;</span>Logo 由之前的<span>&nbsp;</span><code>奶牛</code><span>&nbsp;</span>更换为<span>&nbsp;</span><code>袋鼠</code>。</li><li><strong>2020 年 12 月 22 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 2000 stars。</li></ul><h2>2021 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232021-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2021 年 03 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>捐赠项目到<span>&nbsp;</span><a href="https://gitee.com/dotnetchina" target="_blank">dotNET China</a><span>&nbsp;</span>组织。</li><li><strong>2021 年 03 月 05 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 3000 stars。</li><li><strong>2021 年 04 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>所在群<span>&nbsp;</span><code>dotNET China</code><span>&nbsp;</span>突破 5000 人。</li><li><strong>2021 年 04 月 06 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 4000 stars。</li><li><strong>2021 年 04 月 19 日</strong>，<code>Furion</code><span>&nbsp;</span>正式发布<span>&nbsp;</span><code>2.0.0</code><span>&nbsp;</span>版本，并支持控制枱应用开发。</li><li><strong>2021 年 04 月 29 日</strong>，<code>Furion</code><span>&nbsp;</span>所在群<span>&nbsp;</span><code>dotNET China</code><span>&nbsp;</span>突破 6000 人。</li><li><strong>2021 年 05 月 13 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 5000 stars。</li><li><strong>2021 年 06 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>所在群<span>&nbsp;</span><code>dotNET China</code><span>&nbsp;</span>突破 7000 人。</li><li><strong>2021 年 06 月 22 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 6000 stars。</li><li><strong>2021 年 07 月 04 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>登顶 Gitee 平台<span>&nbsp;</span><code>C#</code><span>&nbsp;</span>语言板块第一名。</strong></li><li><strong>2021 年 07 月 16 日</strong>，<code>Furion</code><span>&nbsp;</span>采用<span>&nbsp;</span><code>百小僧</code><span>&nbsp;</span>头像作为<span>&nbsp;</span><code>Logo</code>。</li><li><strong>2021 年 07 月 20 日</strong>，<code>Furion</code><span>&nbsp;</span>将<span>&nbsp;</span><code>Apache 2.0</code><span>&nbsp;</span>开源协议修改为<span>&nbsp;</span><code>MulanPSL-2.0</code><span>&nbsp;</span>（木兰宽松许可证）</li><li><strong>2021 年 07 月 27 日</strong>，<code>Furion</code><span>&nbsp;</span>正式支持全平台、<code>.NET</code><span>&nbsp;</span>全平台项目开发。</li><li><strong>2021 年 08 月 11 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>加入<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fportal.mulanos.cn%2F" target="_blank">木兰开源社区</a><span>&nbsp;</span>重点孵化。</strong></li><li><strong>2021 年 08 月 21 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>100 万</code><span>&nbsp;</span>下载量。</strong></li><li><strong>2021 年 08 月 30 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 7000 stars。</li><li><strong>2021 年 09 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>诞生一周年。</li><li><strong>2021 年 11 月 09 日</strong>，<code>Furion</code><span>&nbsp;</span>正式发布<span>&nbsp;</span><code>3.0.0</code><span>&nbsp;</span>版本，全新的<span>&nbsp;</span><code>.NET6</code><span>&nbsp;</span>架构。</li><li><strong>2021 年 11 月 22 日</strong>，<code>Furion</code><span>&nbsp;</span>迎来了第一个赞助商。</li></ul><h2>2022 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232022-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2022 年 05 月 20 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 8000 Stars。</li><li><strong>2022 年 05 月 28 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>200 万</code><span>&nbsp;</span>下载量。</li><li><strong>2022 年 06 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>有了自己的入口函数<span>&nbsp;</span><code>Serve.Run()</code><span>&nbsp;</span>和错误页。</li><li><strong>2022 年 06 月 20 日</strong>，<code>Furion</code><span>&nbsp;</span>项目贡献者突破 200 人。</li><li><strong>2022 年 07 月 25 日</strong>，<code>Furion</code><span>&nbsp;</span>正式发布<span>&nbsp;</span><code>4.0.0</code><span>&nbsp;</span>版本，彻底实现大一统（<code>.NET5</code>-<code>.NET N</code>）都可以升级。</li><li><strong>2022 年 08 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>将<span>&nbsp;</span><code>MulanPSL-2.0</code><span>&nbsp;</span>开源协议修改为<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Furion/blob/v4/LICENSE" target="_blank">MIT</a>。</li><li><strong>2022 年 08 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>300 万</code><span>&nbsp;</span>下载量。</li><li><strong>2022 年 09 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>诞生两周年。</li><li><strong>2022 年 09 月 18 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>解散<span>&nbsp;</span><code>QQ</code><span>&nbsp;</span>群，回归最初的开源协作模式，<a href="https://gitee.com/dotnetchina/Furion/issues/I5RWYL" target="_blank">了解更多</a></strong>。</li><li><strong>2022 年 10 月 29 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>400 万</code><span>&nbsp;</span>下载量。</li><li><strong>2022 年 11 月 08 日</strong>，<code>Furion</code><span>&nbsp;</span>正式适配<span>&nbsp;</span><code>.NET7</code><span>&nbsp;</span>架构。</li><li><strong>2022 年 11 月 24 日</strong>，<code>Furion</code><span>&nbsp;</span>发布了全新的分布式定时任务模块<span>&nbsp;</span><a href="https://gitee.com/dotnetchina/Sundial" target="_blank">Sundial</a>。</li><li><strong>2022 年 12 月 07 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>500 万</code><span>&nbsp;</span>下载量。</li><li><strong>2022 年 12 月 29 日</strong>，<code>Furion</code><span>&nbsp;</span>获得开源云联盟优秀开源项目奖项：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2zW-WnBbzs8rOdQ8AfwVag" target="_blank">查看获奖</a>。</li></ul><h2>2023 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232023-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2023 年 02 月 04 日</strong>，<code>Furion</code><span>&nbsp;</span>获得《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkaiyuanshe.feishu.cn%2Fwiki%2FwikcnnJ8b90pOoDRFzXngfRslkd" target="_blank">2022 年中国开源年度报告</a>》<span>&nbsp;</span><code>Gitee</code><span>&nbsp;</span>指数<span>&nbsp;</span><code>Top 10</code><span>&nbsp;</span>项目：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkaiyuanshe.feishu.cn%2Fwiki%2FwikcnnJ8b90pOoDRFzXngfRslkd" target="_blank">查看报告</a>。</li><li><strong>2023 年 02 月 06 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>600 万</code><span>&nbsp;</span>下载量。</li><li><strong>2023 年 03 月 15 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>700 万</code><span>&nbsp;</span>下载量。</li><li><strong>2023 年 04 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 9000 Stars。</li><li><strong>2023 年 04 月 18 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>800 万</code><span>&nbsp;</span>下载量。</li><li><strong>2023 年 06 月 07 日</strong>，<code>Furion</code><span>&nbsp;</span>正式开通微信公众号<span>&nbsp;</span><code>Furion</code>。</li><li><strong>2023 年 06 月 08 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>成功购买下<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffurion.net%2F" target="_blank">furion.net</a><span>&nbsp;</span>域名：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4OTI0ODg3MA%3D%3D%26mid%3D2247483653%26idx%3D1%26sn%3D36d046a0369beb24a60aa9bd0499ea2e%26chksm%3Dcfef8c0cf898051a6637c1bb2643249b0b3d08017cc5ea5d0901a3d3fd127a1cc3fad1e06ace%26token%3D162131388%26lang%3Dzh_CN%23rd" target="_blank">查看官宣</a>。</strong></li><li><strong>2023 年 06 月 14 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>900 万</code><span>&nbsp;</span>下载量。</li><li><strong>2023 年 08 月 22 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>1000 万</code><span>&nbsp;</span>下载量。</strong></li><li><strong>2023 年 09 月 01 日</strong>，<code>Furion</code><span>&nbsp;</span>诞生三周年。</li><li><strong>2023 年 09 月 05 日</strong>，<code>Furion</code><span>&nbsp;</span>申请从<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fportal.mulanos.cn%2F" target="_blank">木兰开源社区</a><span>&nbsp;</span>毕业。</li><li><strong>2023 年 10 月 19 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>1100 万</code><span>&nbsp;</span>下载量。</li><li><strong>2023 年 11 月 03 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>推出官方<span>&nbsp;</span><code>VIP</code><span>&nbsp;</span>服务。</strong></li><li><strong>2023 年 11 月 15 日</strong>，<code>Furion</code><span>&nbsp;</span>正式适配<span>&nbsp;</span><code>.NET8</code><span>&nbsp;</span>架构。</li><li><strong>2023 年 11 月 17 日</strong>，<code>Furion</code><span>&nbsp;</span>通过<span>&nbsp;</span><a href="https://www.oschina.net/news/267981/furion-4-9-1-7-released" target="_blank">⌈中国电子技术标准化研究院⌋</a><span>&nbsp;</span>成熟度评估。</li><li><strong>2023 年 11 月 26 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>推出文档付费浏览服务。</strong></li><li><strong>2023 年 12 月 13 日</strong>，<strong><code>Furion</code><span>&nbsp;</span>上线新官网<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffurion.net%2F" target="_blank">furion.net</a>。</strong></li><li><strong>2023 年 12 月 19 日</strong>，<code>Furion</code><span>&nbsp;</span>在<span>&nbsp;</span><code>NuGet</code><span>&nbsp;</span>平台突破<span>&nbsp;</span><code>1200 万</code><span>&nbsp;</span>下载量。</li><li><strong>2023 年 12 月 28 日</strong>，<code>Furion</code><span>&nbsp;</span>在 Gitee 平台获得 10000 Stars。</li></ul><h2>2024 年<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ffurion.net%2Fdocs%2Fcourse%232024-%25E5%25B9%25B4" target="_blank">​</a></h2><ul><li><strong>2024 年 ?? 月 ?? 日</strong>，<code>Furion</code><span>&nbsp;</span>正式发布<span>&nbsp;</span><code>5.0.0</code><span>&nbsp;</span>版本，一次彻底的革新。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 04:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274711/furion-2023</guid>
            <link>https://www.oschina.net/news/274711/furion-2023</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME 支持 RDP 协议，可通过图形界面进行远程登录]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FGNOME-RDP-Remote-Login" target="_blank">根据 Phoronix 的报道</a></u>，GNOME 桌面环境<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.gnome.org%2FGNOME%2Fgnome-remote-desktop%2F-%2Fmerge_requests%2F139" target="_blank">最近合并的 PR</a></u>&nbsp;实现了对远程桌面协议 (RDP) 支持的重要部分。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f8bcbc9835268555ad0adf16dcf7ea5a915.png" referrerpolicy="no-referrer"></p><p>正如 PR 所述，这项功能用于提供图形化远程登录支持。该 PR 自 2022 年 8 月以来一直处于开启状态，直到 2024 年 1 月才被合并。该功能的实现依赖于 GNOME Session、GDM 和 GNOME Settings Daemon 等方面的变化，这些变化在过去一年内已经合并。这意味着在&nbsp;3 月发布的 GNOME 46 版本中，这项功能将会正式上线。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-066aac4e76b43f37a7382fdcadcbfa32300.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c76d08a2fa57ee735cdd5820ccbdc09d20f.png" referrerpolicy="no-referrer"></p><p>这个功能的具体实现细节包括对标准守护进程的抽象，以及实现了两种新的行为。第一种是作为系统服务运行，它会在新的 RDP 连接时请求 GDM 启动一个无 header GDM 登录会话。第二种是在无 header 用户会话中运行（又名 daemon-handover），它会告诉系统服务使用 handover dbus 接口启动交接过程。这两种行为的实现使得 GNOME 桌面环境可以处理图形远程登录的需求。</p><p>此外，这项功能还支持 Wayland。这意味着它不仅可以在 X11 上运行，还可以在 Wayland 上运行。这对于用户来说是一个好消息，因为他们可以在不同的显示服务器上使用这项功能。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 03:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274575/gnome-rdp-remote-login</guid>
            <link>https://www.oschina.net/news/274575/gnome-rdp-remote-login</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[用 Socket.D 替代原生 WebSocket 做前端开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start">socket.d.js 是基于 websocket 包装的 socket.d 协议的实现。就是用 ws 传输数据，但功能更强大。</p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&quot;system-ui&quot;,&quot;Segoe UI&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"><tbody><tr><th>功能</th><th>原生 websocket</th><th>socket.d</th><th>说明</th></tr></tbody><tbody><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">listen</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">监听消息</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">send</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发消息</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndRequest</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">无</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发消息并接收一个响应（类似于 http）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndSubscribe</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">无</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发消息并接收多个响应（也叫订阅）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">event(or path)</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">无</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消息有事件或路径（可对消息，进行业务路由）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">meta(or header)</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">无</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">有</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消息有元信息或头信息（可为数据，标注业务语义）</td></tr></tbody></table><p style="color:#24292e; text-align:start">下面感受下开发方面的差异！</p><h3>1、客户端示例代码</h3><p style="color:#24292e; text-align:start">使用时，可以根据自己的业务对原生接口包装，进一步简化使用。</p><pre><code class="language-html language-xml"><span>&lt;<span style="color:#e45649">script</span><span style="color:#986801">src</span>=<span style="color:#50a14f">"js/socket.d.js"</span>&gt;</span><span>&lt;/<span style="color:#e45649">script</span>&gt;</span><span>&lt;<span style="color:#e45649">script</span>&gt;
<span style="color:#a626a4">async</span><span style="color:#a626a4">function</span><span style="color:#4078f2">init</span>(){
    <em>//构建事件监听</em><span style="color:#a626a4">const</span> eventListener = <span style="color:#a626a4">await</span><span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">newEventListener</span>().<span style="color:#4078f2">doOnMessage</span>(<span>(<span>s,m</span>)=&gt;</span>{
       <em>//监听所有消息（可能不需要）</em>
    }).<span style="color:#4078f2">doOn</span>(<span style="color:#50a14f">"/im/user.upline"</span>, <span>(<span>s,m</span>)=&gt;</span>{ <em>//事件的应用</em><em>//监听用户上线</em><span style="color:#a626a4">let</span> user_id = m.<span style="color:#4078f2">meta</span>(<span style="color:#50a14f">"user_id"</span>);
    }).<span style="color:#4078f2">doOn</span>(<span style="color:#50a14f">"/im/user.downline"</span>, <span>(<span>s,m</span>)=&gt;</span>{
        <em>//监听用户下线</em><span style="color:#a626a4">let</span> user_id = m.<span style="color:#4078f2">meta</span>(<span style="color:#50a14f">"user_id"</span>); <em>//元信息的应用</em>
    });

    <em>//创建单例</em><span style="color:#986801">window</span>.<span>clientSession</span> = <span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">createClient</span>(<span style="color:#50a14f">"sd:</span></span><span style="color:#50a14f">ws://127.0.0.1:8602/?u=a&amp;p=2"</span>)</code><code class="language-html language-xml"><span>            .<span style="color:#4078f2">listen</span>(eventListener)
            .<span style="color:#4078f2">open</span>();
}

<span style="color:#a626a4">function</span><span style="color:#4078f2">join</span>(){
    clientSession.<span style="color:#4078f2">sendAndRequest</span>(<span style="color:#50a14f">"/user/join"</span>, <span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">newEntity</span>()).<span style="color:#4078f2">thenReply</span>(r-&gt;{
        <em>//加入成功</em>
    });
}

<span style="color:#4078f2">init</span>();
</span><span>&lt;/<span style="color:#e45649">script</span>&gt;</span></code></pre><p style="color:#24292e; text-align:start">Socket.D 有三个发消息的接口：</p><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&quot;system-ui&quot;,&quot;Segoe UI&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"><tbody><tr><th>接口</th><th>说明</th></tr></tbody><tbody><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">send</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">像 websocket。多了事件与元信息属性</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndRequest</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">像 http</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">sendAndSubscribe</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">像 reactive stream 。多了事件与元信息属性</td></tr></tbody></table><h3>2、服务端示例代码（用 java 演示）</h3><pre><code class="language-java"><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">Demo</span> {
    <span style="color:#a626a4">public</span><span style="color:#a626a4">static</span><span style="color:#a626a4">void</span><span style="color:#4078f2">main</span><span>(String[] args)</span><span style="color:#a626a4">throws</span> Throwable {
        List&lt;Session&gt; userSessions = <span style="color:#a626a4">new</span><span style="color:#c18401">ArrayList</span>&lt;Session&gt;();
        <em>//创建监听器</em><span style="color:#986801">Listener</span><span style="color:#986801">listener</span><span>=</span><span style="color:#a626a4">new</span><span style="color:#c18401">EventListener</span>().doOnOpen(s-&gt;{
            <em>//鉴权</em><span style="color:#a626a4">if</span>(<span style="color:#50a14f">"a"</span>.equals(s.param(<span style="color:#50a14f">"u"</span>)) == <span style="color:#0184bb">false</span>){
                s.close();
            }<span style="color:#a626a4">else</span>{
                <em>//加入用户表</em>
                s.attrPut(<span style="color:#50a14f">"user_id"</span>, s.param(<span style="color:#50a14f">"u"</span>));
                userSessions.add(s);
            }
        }).doOn(<span style="color:#50a14f">"/user/join"</span>, (s,m)-&gt;{
            <span style="color:#a626a4">if</span>(m.isRequest()){
                s.reply(m, <span style="color:#a626a4">new</span><span style="color:#c18401">StringEntity</span>());
            }
            
            <span style="color:#a626a4">for</span>(Session s1: userSessions){
                <em>//告诉所有用户，有人上线</em>
                s1.send(<span style="color:#50a14f">"/im/user.upline"</span>, <span style="color:#a626a4">new</span><span style="color:#c18401">StringEntity</span>().metaPut(<span style="color:#50a14f">"user_id"</span>), s.attr(<span style="color:#50a14f">"userId"</span>));
            }
        });
        
        <em>//启动服务</em>
        SocketD.createServer(<span style="color:#50a14f">"sd:ws"</span>)
                .config(c -&gt; c.port(<span style="color:#986801">8602</span>))
                .listen(listener)
                .start();
    }
}
</code></pre><h3>3、Socket.D 是什么东东？</h3><p style="color:#24292e; text-align:start">Socket.D 是一个基于「事件」和「语义消息」「流」的网络应用层协议（听起来好像很 ao 口）。支持 tcp, udp, ws, kcp 传输。有用户说，「Socket.D 之于 Socket，尤如 Vue 之于 Js、Mvc 之于 Http」。</p><p style="color:#24292e; text-align:start">协议之所有强大，有三个关键基础因素：</p><ul><li>事件</li><li>语义消息</li><li>流</li></ul><p style="color:#24292e; text-align:start">它的帧码结构：</p><pre><code class="language-css"><span style="color:#986801">[len:int]</span><span style="color:#986801">[flag:int]</span><span style="color:#986801">[sid:str(&lt;64)]</span><span style="color:#986801">[\n]</span><span style="color:#986801">[event:str(&lt;512)]</span><span style="color:#986801">[\n]</span><span style="color:#986801">[metaString:str(&lt;4k)]</span><span style="color:#986801">[\n]</span><span style="color:#986801">[data:byte(&lt;16m)]</span></code></pre><p style="color:#24292e; text-align:start">因为是应用层协议，所以可以建立在任意传输层协议之上。比如 websocket。</p><h3>4、开源仓库</h3><ul><li>github:<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnoear%2Fsocket.d" target="_blank">https://github.com/noear/socket.d</a></li><li>gitee:<span>&nbsp;</span><a href="https://gitee.com/noear/socket.d">https://gitee.com/noear/socket.d</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 07 Jan 2024 02:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/274678</guid>
            <link>https://www.oschina.net/news/274678</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
