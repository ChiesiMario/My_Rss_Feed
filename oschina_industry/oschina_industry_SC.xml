<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 10 Nov 2023 05:13:25 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[GitHub 发布开源编程字体家族 Monaspace]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>GitHub 推出了名为「Monaspace」的开源等宽编程字体家族。</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/120711_f6hb_2720166.png" referrerpolicy="no-referrer"></p><p>地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmonaspace.githubnext.com%2F" target="_blank">https://monaspace.githubnext.com/</a></u></em></p><blockquote>
 「字体家族」（typeface / font family）和 「单款字体」（font）是不同的概念，虽然通常习惯将两者都称作 「字体」，但一个字体家族通常包含多个单款字体，字型之间以字重（粗细）、风格（正斜体）等设置区分开来。
 <br><br> 简而言之，「字体家族」 是一整套的设计，其中包含若干款 「字体」，即单独的字体文件。
</blockquote><p>根据介绍，「Monaspace」作为字体家族，可分为「静态」和「可变」两种字体风格。</p><ul><li><code>Monaspace _____</code>代表<strong>静态</strong></li><li><code>Monaspace _____ Var</code>或<code>VF</code>代表<strong>可变</strong></li></ul><p>GitHub Monaspace 总共包含 5 种字体，由于它们的属性相互兼容，因此可以混搭使用。</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/121225_m9Kc_2720166.png" referrerpolicy="no-referrer"></p><p>下面是单独使用 Xe 字体的效果：</p><p><img height="1228" src="https://static.oschina.net/uploads/space/2023/1110/121353_QrHp_2720166.png" width="1716" referrerpolicy="no-referrer"></p><p>开发者可基于上述 5 种字体任意搭配组合使用，如下：</p><p><img src="https://static.oschina.net/uploads/space/2023/1110/121517_ONNu_2720166.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 04:15:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265861</guid>
            <link>https://www.oschina.net/news/265861</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[亚马逊开发基于 Linux 的操作系统，以摆脱 Android 依赖]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Lowpass 记者 Janko Roettgers 从多方消息来源<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.lowpass.cc%2Fp%2Famazon-vega-os-fire-tv-android" target="_blank">得知</a>，亚马逊一直在开发一种新的操作系统 —— 内部代号为「Vega」，以便在 Fire TV、智能显示器和其他联网设备上取代 Android 系统。</span></p><p><span style="color:#000000">一直以来，亚马逊的一些智能家居设备都使用了名为 Fire OS 的 Android 分叉版本。但也正是因为依赖 Android 开源项目来构建 Fire OS，导致该公司操作系统的开发落后于谷歌多年。</span></p><p><span style="color:#000000">而 Vega 并不是一个新的 Android 分叉，也不是基于 AOSP，「是一种基于 Linux 的风格，并采用了一种更加面向网络的应用模式。应用程序开发人员被告知使用 React Native 作为应用程序框架，这样他们就可以使用 Javascript 驱动的界面来构建本地应用程序。」</span></p><p><img height="333" src="https://static.oschina.net/uploads/space/2023/1110/120051_g6gS_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">目前，亚马逊设备操作系统部门已有"数百人"在致力于新操作系统的开发，其中就包括前 Mozilla 工程师和 Javascript 专家 Zibi Braniecki。Branieck 于 2022 年初加入亚马逊从事 Alexa 工作，然后在 2023 年初过渡到设备操作系统团队。他当时曾在 LinkedIn 上透露，自己正在「为智能家居、汽车和其他亚马逊设备产品线开发下一代操作系统」。</span></p><p><span style="color:#000000">Roettgers 指出，Vega 开发进度似乎相当快。该系统已经在 Fire TV 流媒体适配器上进行了测试，且亚马逊已向部分合作伙伴透露了在不久的将来过渡到新应用框架的计划。</span></p><p><span style="color:#000000">一位了解该公司计划的消息人士表示，亚马逊最早可能会在明年开始在部分 Fire TV 设备上搭载 Vega。SDK 也正在准备发布，以便开发人员在 Vega 上市前将他们的应用程序移植到 Vega 上。</span></p><p><span style="color:#000000">此外，消息称亚马逊的<strong>最终目标是在其所有的新设备上摆脱对 Android 的依赖</strong>。Vega 不仅可以在 Fire TV 和智能显示器上运行，还可以在车载娱乐系统和其他未来的硬件产品上运行。亚马逊发布的多份招聘信息显示，Vega 将成为其汽车业务的关键。</span></p><p><span style="color:#000000">Vega 的出现，也帮助亚马逊避免了与谷歌的进一步冲突。Roettgers 称，两家公司长期以来一直为亚马逊使用 Android 系统的问题争吵不休，谷歌曾一度向硬件制造商施压，要求他们不要生产搭载亚马逊系统的智能电视。直到后来两家公司达成协议，允许亚马逊与海信和 TCL 等电视机制造商合作」，但亚马逊放弃 Android 系统后，应该能更好地掌控自己的命运。「</span></p><p><span style="color:#000000">不过一些业内人士认为，<span style="background-color:#ffffff">竞争压力可能并不是亚马逊转向 Vega 的主要原因。亚马逊真正关心的是如何在各种廉价设备上吸引数亿眼球，然后通过广告和服务将其货币化--而内置定制操作系统可能正是实现这一目标的最佳途径。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 04:00:32 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265858/amazon-vega-linux-based-os</guid>
            <link>https://www.oschina.net/news/265858/amazon-vega-linux-based-os</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[文心一言用户规模已达 7000 万]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在前沿数字技术创新与安全论坛和人工智能赋能产业发展论坛上，百度 CTO 王海峰</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbH6zON1itJDh9bwCAeLfWw" target="_blank"><span style="color:#2980b9">披露</span></a><span style="color:#000000">，文心一言自 8 月 31 日面向全社会开放至今，用户规模现已达到 7000 万，场景 4300 个，应用 2492 个。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://static.oschina.net/uploads/space/2023/1110/115002_eScQ_4252687.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">王海峰表示，人工智能是新一轮科技革命和产业变革的重要驱动力量，深度学习作为人工智能的核心技术，具有很强的通用性，并具备标准化、自动化和模块化的工业大生产特征，而大模型的兴起，使得人工智能应用的深度和广度进一步拓展。人工智能已进入工业大生产阶段。</span></p><p><span style="color:#000000">例如，标准化方面，框架和模型联合优化，多硬件统一适配，应用模式简洁高效，大幅降低人工智能应用门槛；自动化方面，从训练、适配，到推理部署，提升人工智能研发全流程效率；模块化方面，丰富的产业级模型库，支撑人工智能在广泛场景的便捷应用。</span></p><p><span style="color:#000000">王海峰认为，人工智能具有多种典型能力，理解、生成、逻辑、记忆是其中的基础能力，这四项能力越强，越接近通用人工智能，而大语言模型具备了这四项能力，且越来越强，为通用人工智能带来了曙光。</span></p><p><span style="color:#000000">面对大模型产业化的挑战，王海峰表示，类似芯片代工厂模式，可以采用「集约化生产，平台化应用」的模式，即具有算法、算力和数据综合优势的企业将模型生产的复杂过程封装起来，通过低门槛、高效率的生产平台，为千行百业提供大模型服务。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 02:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265847</guid>
            <link>https://www.oschina.net/news/265847</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GNOME 获 100 万欧元投资]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">GNOME 基金会<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffoundation.gnome.org%2F2023%2F11%2F09%2Fgnome-recognized-as-public-interest-infrastructure%2F" target="_blank">宣布</a></u>收到了来自「<span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund</span>」的 100 万欧元投资，并表示这笔资金将用于实现平台现代化、改进工具和可访问性，并支持符合公共利益的功能。</p><p>具体包括：</p><ul><li>改进当前的可访问性状态</li><li>设计新的辅助功能堆栈并制作原型</li><li>支持单独加密 user 主目录</li><li>实现现代化的秘密存储</li><li>扩大硬件支持的范围和质量</li><li>为质量保证和开发者体验投入资源</li><li>扩展和拓宽 freedesktop API</li><li>整合和改进平台组件</li></ul><p><span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund 是</span>德国政府资助的一项计划，由 Adriana Groh 和 Fiona Krakenbürg 运营，他们在国家和国际层面拥有「多年推广开源技术的经验」。目标是支持「开源数字基础设施的开发、改进和维护」，这与 GNOME 项目的协同作用是显而易见的。</p><p>他们在官方网站写道：「.....开源生态虽然非常成功，但也越来越脆弱。因为使用开源软件的人永远比为该软件做出贡献的人多。现在是投资数字共享、志愿者社区和开源来建设我们希望看到的数字世界的时候了。」</p><p><span style="background-color:#ffffff; color:#000000">Sovereign Tech Fund 投资过的项目</span>包括 curl、Fortran、WireGuard、OpenSSH、Yocto，以及与 OpenJS 基金会合作「改进 Javascript 生态基础设施和安全性」。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 10 Nov 2023 02:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265839/gnome-sovereign-tech-fund</guid>
            <link>https://www.oschina.net/news/265839/gnome-sovereign-tech-fund</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[正在被代码折磨到深夜的你，何不请 AI 帮帮你]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在生成式 AI 工具规模化应用仍被质疑和观望的时候，由其生成的内容、视觉、代码程序已经高速涌入大众视野。AI 技术一日千里，拥抱 AI 开发工具或将成为向未来工程师的进化的必经之路。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/204756_bv5c_2720166.gif" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="text-align:center"><strong>「半天时间就能梳理 20000 行代码」</strong></p><p>大星是某电商业务的后端核心研发，入行 3 年，成长很快，已经是项目 owner 独当一面。但是大星也自有烦恼，电商促销活动频繁，且因为需求方复杂，经常需要处理突发状况，还有一个「重灾区」就是频繁修复历史技术债，不断打补丁，使得系统的可维护性越来越差，重构迫在眉睫。</p><p>今年提前两个月，双十一大促进入筹备期。大星发现，如果不尽快重构系统，不仅很难继续补丁式的开发新活动，甚至稳定性也存在风险。但是重构系统又与新的开发工作存在矛盾，人力有限，极容易顾此失彼。这时，大星想到了近期在试用的百度 Comate 研发插件，在理解老代码、生成注释方面都有不错的表现，于是大星和小伙伴，迅速梳理了遗留的老代码，制定了新优惠逻辑的实现融合方案，快速融合了新旧优惠逻辑，2 名研发只用了半天时间完成了 20000 多行代码的梳理。</p><p>后来，大星多次分享了这次经历：「这不仅等于增派了研发人力，更重要的是百度 Comate 理解更准确，注释生成更规范。这次成功救场，启发我作为工程师，更应该超前使用新工具，这样才能跑得更快。」</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/204929_EoB7_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><strong>「不被语言所困，我就是研发 E 人！」</strong></p><p>去年毕业的小韩，作为优秀校招生入职大厂，工作一年有余，由于好学爱折腾，已经接了不少项目。最近，小韩接手了一个新项目，该项目的实现语言是 Go，但是小韩不太擅长，另外，由于对项目的已有代码不熟悉，让他接手项目和快速修改其中的内容有了不少阻碍。</p><p>他想到平时使用的百度 Comate，利用其代码解释和使用其它语言实现的能力，快速理解了项目已有的代码，高质量实现了快速接手任务，得到了团队内其他成员的一致好评。</p><p>「我属于程序员 E 人，平时喜欢多交流，百度 Comate 就是小伙伴推荐的，我发现，面对短板，找到方法其实就能快速弯道超车，这对研发新人很重要。」小韩直言不讳。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205015_NLab_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><strong>「用好工具，重组生产要素，提升研发生产力」</strong></p><p>作为研发团队管理者，大刚最近痛失两名 QA，新的 QA 迟迟招不到，团队的 bug 数直线上升，质量危机迫在眉睫，将近年底，眼看质量指标达成就要灰飞烟灭。多年的经验告诉大刚要沉下心来，仔细分析找到解法，在角色、人力、环节、工时、质量几个维度上设计出最优解。</p><p>通过分析，大刚逐步梳理出了解法：既然人力缺失，是否尽可能利用自动化能力来减少人工的投入，如在每次回归测试中释放 QA 的人力。再推导一步：如果对现有代码批量生成单元测试，对于缓解 QA 人力紧缺也将有非常大的帮助。</p><p>最后，大刚决定使用百度 Comate 插件来解决这些问题。大刚和团队研发成员一起，针对遗留代码和新增的代码，使用百度 Comate 的单测生成能力，快速的生成了满足业务要求的单元测试代码，通过自动化的方式实现回归验证，保证代码在变更后的运行结果符合预期情况，将测试环节左移，更早发现问题，减少后续环节的人力投入。</p><p>大刚团队的案例，是通过百度 Comate 生成了主要流程的单元测试用例，虽然在研发过程中看上去对单个功能的开发时间加长了，但是方案保证了核心流程的正确性，提高验证效率，最大化的缓解了人员紧缺的情况。</p><p>后来大刚在覆盘中，这样总结：「研发是一个系统性工程，不仅有人人协同，还有人机协同，用好工具提升人机协同能力，重组生产要素，用技术的力量提升研发生产力。」</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205101_OWD9_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205125_R8fr_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><h3 style="text-align:center"><strong>⭐ 百度 Comate SaaS 有哪些优势？</strong></h3><p>依托文心大模型，百度 Comate SaaS 支持单行推荐、多行推荐、多条推荐、代码知识的问答、代码生成、注释生成、注释文档生成、代码解释、生成行间注释、函数拆分、优化和重构等一系列编码相关的能力，在编程现场实现帮你想、帮你写、帮你改代码的效果。</p><p>此外，经过测试，百度 Comate 在易用性、速度、安全性、使用体验上具有明显优势。功能完备，开箱即用，后续支持私域数据索引，推理结果更精准。在使用体验上，支持全中文交互，交互速度更快，体验更好；领先的安全机制保证代码数据的安全，同时成本和部署方式上也更灵活、更具高性价比。</p><h3 style="text-align:center"><strong>🌈 限时福利！</strong></h3><p><span style="color:#2980b9"><strong>福利一：限时免费试用</strong></span>（活动时间：即日起- 11 月 20 日）</p><ul><li><p>扫描或长按下图二维码，即装即用，<span style="color:#c0392b"><strong>限时领取免费试用 1 个月！</strong></span></p></li><li><p>邀请其他人注册，<span style="color:#c0392b"><strong>每分享 1 人注册成功，即可获得+1 个月免费试用期，总计最高获得 6 个月免费试用</strong>。</span></p></li></ul><p><span style="color:#2980b9"><strong>福利二：限时特价</strong></span>（活动时间：即日起- 11 月 20 日）</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205713_POpJ_2720166.png" referrerpolicy="no-referrer"></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><span style="color:#c0392b"><strong>以上福利扫码立即获得！</strong></span></p><p>下载下面图片➡️转发小伙伴，成功推荐其他新用户，即可延长免费试用时间，最高得 6 个月免费试用～</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1109/205507_xM4u_2720166.jpg" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 12:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265796</guid>
            <link>https://www.oschina.net/news/265796</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软计划为 Windows 10 提供 AI 助手 Copilot]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fwindows-10%2Fexclusive-microsoft-plans-to-bring-its-ai-copilot-to-1-billion-windows-10-users" target="_blank">根据 Windows Central 的报道</a></u>，微软计划将 Copilot 引入 Windows 10。该公司做出这一决定的主要原因是希望为 Copilot 增加更多用户。</p><p>Windows 11 最近发布的重大更新 v23H2 包含了 AI 助手 Copilot，它直接添加到了桌面的工具栏上。但 Windows 11 的用户数目前还远不及上一代的 Windows 10，而微软致力于让每个用户都能使用 Copilot，它正计划向有 10 亿用户的 Windows 10 提供 Copilot。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7b7b3e6ab4e1286eb6e8ecd2789040a2a53.png" referrerpolicy="no-referrer"></p><p>Windows 10 的 Copilot 和 Windows 11 基本一致，Copilot 按钮放置在工具栏上，点击该按钮会显示一个可用于对话的侧边栏。</p><p>报道还指出，Windows 10 和 Windows 11 的 Copilot 体验将是相同的，包括插件的兼容性。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265760</guid>
            <link>https://www.oschina.net/news/265760</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[reverse_sql —— MySQL 数据闪回恢复工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">reverse_sql 是一个用于解析和转换 MySQL 二进制日志（binlog）的工具。它可以将二进制日志文件中记录的数据库更改操作（如插入、更新、删除）转换为反向的 SQL 语句，以便进行数据恢复。其运行模式需二进制日志设置为 ROW 格式。</p><p style="color:#1f2328; text-align:start">该工具的主要功能和特点包括：</p><p style="color:#1f2328; text-align:start">1、解析二进制日志：reverse_sql 能够解析 MySQL 的二进制日志文件，并还原出其中的 SQL 语句。</p><p style="color:#1f2328; text-align:start">2、生成可读的 SQL：生成原始 SQL 和反向 SQL。</p><p style="color:#1f2328; text-align:start">3、支持过滤和筛选：可以根据时间范围、表、DML 操作等条件来过滤出具体的误操作 SQL 语句。</p><p style="color:#1f2328; text-align:start">4、支持多线程并发解析 binlog 事件。</p><h3 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#%E4%BD%BF%E7%94%A8">使用</a></h3><div style="text-align:start"><pre><code>shell&gt; chmod 755 reverse_sql
shell&gt; ./reverse_sql --help
usage: reverse_sql [-h] [-ot ONLY_TABLES [ONLY_TABLES ...]] [-op ONLY_OPERATION] -H MYSQL_HOST
                   -P MYSQL_PORT -u MYSQL_USER -p MYSQL_PASSWD -d MYSQL_DATABASE
                   [-c MYSQL_CHARSET] --binlog-file BINLOG_FILE [--binlog-pos BINLOG_POS]
                   --start-time ST --end-time ET [--max-workers MAX_WORKERS] [--print]

Binlog 数据恢复，生成反向 SQL 语句。

options:
  -h, --help            show this help message and exit
  -ot ONLY_TABLES [ONLY_TABLES ...], --only-tables ONLY_TABLES [ONLY_TABLES ...]
                        设置要恢复的表，多张表用,逗号分隔
  -op ONLY_OPERATION, --only-operation ONLY_OPERATION
                        设置误操作时的命令（insert/update/delete）
  -H MYSQL_HOST, --mysql-host MYSQL_HOST
                        MySQL 主机名
  -P MYSQL_PORT, --mysql-port MYSQL_PORT
                        MySQL 端口号
  -u MYSQL_USER, --mysql-user MYSQL_USER
                        MySQL 用户名
  -p MYSQL_PASSWD, --mysql-passwd MYSQL_PASSWD
                        MySQL 密码
  -d MYSQL_DATABASE, --mysql-database MYSQL_DATABASE
                        MySQL 数据库名
  -c MYSQL_CHARSET, --mysql-charset MYSQL_CHARSET
                        MySQL 字符集，默认 utf8
  --binlog-file BINLOG_FILE
                        Binlog 文件
  --binlog-pos BINLOG_POS
                        Binlog 位置，默认 4
  --start-time ST       起始时间
  --end-time ET         结束时间
  --max-workers MAX_WORKERS
                        线程数，默认 4（并发越高，锁的开销就越大，适当调整并发数）
  --print               将解析后的 SQL 输出到终端
  --replace             将 update 转换为 replace 操作

Example usage:
    shell&gt; ./reverse_sql -ot table1 -op delete -H 192.168.198.239 -P 3336 -u admin -p hechunyang -d hcy \
            --binlog-file mysql-bin.000124 --start-time "2023-07-06 10:00:00" --end-time "2023-07-06 22:00:00" 
</code></pre><div>&nbsp;</div></div><p><a href="https://github.com/hcymysql/reverse_sql#%E5%BD%93%E5%87%BA%E7%8E%B0%E8%AF%AF%E6%93%8D%E4%BD%9C%E6%97%B6%E5%8F%AA%E9%9C%80%E6%8C%87%E5%AE%9A%E8%AF%AF%E6%93%8D%E4%BD%9C%E7%9A%84%E6%97%B6%E9%97%B4%E6%AE%B5%E5%85%B6%E5%AF%B9%E5%BA%94%E7%9A%84binlog%E6%96%87%E4%BB%B6%E9%80%9A%E5%B8%B8%E4%BD%A0%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87show-master-status%E5%BE%97%E5%88%B0%E5%BD%93%E5%89%8D%E7%9A%84binlog%E6%96%87%E4%BB%B6%E5%90%8D%E4%BB%A5%E5%8F%8A%E5%88%9A%E6%89%8D%E8%AF%AF%E6%93%8D%E4%BD%9C%E7%9A%84%E8%A1%A8%E5%92%8C%E5%85%B7%E4%BD%93%E7%9A%84dml%E5%91%BD%E4%BB%A4%E6%AF%94%E5%A6%82update%E6%88%96%E8%80%85delete">当出现误操作时，只需指定误操作的时间段，其对应的 binlog 文件（通常你可以通过 show master status 得到当前的 binlog 文件名）以及刚才误操作的表，和具体的 DML 命令，比如 update 或者 delete。</a></p><p style="color:#1f2328; text-align:start">工具运行时，首先会进行 MySQL 的环境检测（if binlog_format != 'ROW' and binlog_row_image != 'FULL'），如果不同时满足这两个条件，程序直接退出。</p><p style="color:#1f2328; text-align:start">工具运行后，会在当前目录下生成一个{db}_{table}_recover.sql 文件，保存着原生 SQL（原生 SQL 会加注释） 和，反向 SQL，如果想将结果输出到前台终端，可以指定--print 选项。</p><p style="color:#1f2328; text-align:start">如果你想把 update 操作转换为 replace，指定--replace 选项即可，同时会在当前目录下生成一个{db}_{table}_recover_replace.sql 文件。</p><p style="color:#1f2328; text-align:start"><a href="https://user-images.githubusercontent.com/19261879/251670057-b06528a6-fbff-4e00-8adf-0cba19737d66.png" target="_blank"><img alt="图片" src="https://static.oschina.net/uploads/img/202311/08114920_eBdc.png" referrerpolicy="no-referrer"></a></p><p style="color:#1f2328; text-align:start">MySQL 最小化用户权限：</p><div style="text-align:start"><pre><code>&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO `yourname`@`%`;

&gt; GRANT SELECT ON `test`.* TO `yourname`@`%`;
</code></pre></div><h3 style="text-align:start"><br><a href="https://github.com/hcymysql/reverse_sql#%E6%81%A2%E5%A4%8D">恢复</a></h3><p style="color:#1f2328; text-align:start">在{db}_{table}_recover.sql 文件中找到你刚才误操作的 DML 语句，然后在 MySQL 数据库中执行逆向工程后的 SQL 以恢复数据。</p><p style="color:#1f2328; text-align:start">如果{db}_{table}_recover.sql 文件的内容过多，也可以通过 awk 命令进行分割，以便更容易进行排查。</p><div style="text-align:start"><pre><code>shell&gt; awk '/^-- SQL 执行时间/{filename = "output" ++count ".sql"; print &gt; filename; next} {print &gt; filename}' test_t1_recover.sql
</code></pre><div>&nbsp;</div></div><p style="color:#1f2328; text-align:start">不支持 drop 和 truncate 操作，因为这两个操作属于物理性删除，需要通过历史备份进行恢复。</p><h4 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#%E6%B3%A8reverse_sql-%E6%94%AF%E6%8C%81mysql-5780-%E5%92%8C-mariadb%E9%80%82%E7%94%A8%E4%BA%8Ecentos-7%E7%B3%BB%E7%BB%9F">注：reverse_sql 支持 MySQL 5.7/8.0 和 MariaDB，适用于 CentOS 7 系统。</a></h4><hr><h3 style="text-align:start"><a href="https://github.com/hcymysql/reverse_sql#docker%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8">Docker 部署使用</a></h3><p style="color:#1f2328; text-align:start">shell&gt; wget<span>&nbsp;</span><a href="https://github.com/hcymysql/reverse_sql/archive/refs/heads/reverse_sql_progress.zip">https://github.com/hcymysql/reverse_sql/archive/refs/heads/reverse_sql_progress.zip</a></p><p style="color:#1f2328; text-align:start">shell&gt; unzip reverse_sql_progress.zip</p><p style="color:#1f2328; text-align:start">shell&gt; cd reverse_sql_progress</p><p style="color:#1f2328; text-align:start">shell&gt; vim Dockerfile</p><div style="text-align:start"><pre><code>FROM centos:7

COPY reverse_sql /root/
RUN chmod 755 /root/reverse_sql
</code></pre></div><p style="color:#1f2328; text-align:start">shell&gt; docker build -t reverse_sql .</p><p style="color:#1f2328; text-align:start">shell&gt; docker run -itd --name reverse_sql reverse_sql /bin/bash</p><p style="color:#1f2328; text-align:start">shell&gt; docker exec -it reverse_sql /root/reverse_sql --help</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/reverse-sql</guid>
            <link>https://www.oschina.net/p/reverse-sql</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | Android 发热监控实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一、背景</h1><p>相信移动端高度普及的现在，大家或多或少都会存在电量焦虑，拥有过手机发热发烫的糟糕体验。而发热问题是一个长时间、多场景的指标存在，且涉及到端侧应用层、手机 ROM 厂商系统、外界环境等多方面的影响。如何有效衡量发热场景、定位发热现场、以及归因发热问题成为了端侧应用层发热监控的面前的三座大山。本文通过得物 Android 端侧现有的一些监控实践，不深入功耗计算场景无法自拔，优先聚焦于发热场景本身，希望能给大家一些参考。</p><h1>二、发热定义</h1><p>温度是最直观能反映发热问题的指标，当前 Android 侧，我们以体感温度 37° 以上作为分界线，向上每 3° 作为一个发热温度区间，区间细分上限温度 49° ，即划分出 37-40，40-43，43-46，46-49，49+ 五个等级。</p><p>以手机温度、CPU 使用率作为第一、第二要素来判断用户是否发热的同时，获取其他参数来支撑发热现场情况。</p><p><strong>具体指标如下:</strong></p><p>手机温度 CPU 使用率、GPU 使用率；</p><p>线程堆栈；</p><p>系统服务使用频次；</p><p>设备前后台、亮灭屏时长；</p><p>电量、充电情况；</p><p>热缓解发热等级；</p><p>系统机型、版本；</p><p>....</p><h1>三、指标获取</h1><h2>温度</h2><ul><li><strong>电池温度</strong></li></ul><p>系统 BatteryManger 已经提供了一系列自带的接口和粘性广播获取电池信息。</p><p>BatteryManager.EXTRA_TEMPERATURE 广播，获取的温度值是摄氏度为单位的 10 倍数值。</p><pre><code>//获取电池温度 BatteryManager.EXTRA_TEMPERATURE，华氏温度需要除以 10
fun getBatteryTempImmediately(context: Context): Float {
    return try {
        val batIntent = getBatteryStickyIntent(context) ?: return 0f
        batIntent.getIntExtra(BatteryManager.EXTRA_TEMPERATURE, 0) / 10F
    } catch (e: Exception) {
        0f
    }
}

private fun getBatteryStickyIntent(context: Context): Intent? {
    return try {
        context.registerReceiver(null, IntentFilter(Intent.ACTION_BATTERY_CHANGED))
    } catch (e: Exception) {
        null
    }
}
</code></pre><p>BatteryManager 除支持电池温度的系统广播外，也包含电量、充电状态等额外信息的读取，均定义在其源码中。</p><pre><code>以下罗列几个值得关注的:
//BATTERY_PROPERTY_CHARGE_COUNTER 剩余电池容量，单位为微安时
//BATTERY_PROPERTY_CURRENT_NOW 瞬时电池电流，单位为微安
//BATTERY_PROPERTY_CURRENT_AVERAGE 平均电池电流，单位为微安
//BATTERY_PROPERTY_CAPACITY 剩余电池容量，显示为整数百分比
//BATTERY_PROPERTY_ENERGY_COUNTER 剩余能量，单位为纳瓦时
// EXTRA_BATTERY_LOW  是否认为电量低
// EXTRA_HEALTH  电量健康常量的常数
// EXTRA_LEVEL  电量值
// EXTRA_VOLTAGE 电压
// ACTION_CHARGING   进入充电状态
// ACTION_DISCHARGING  进入放电状态
</code></pre><ul><li><strong>传感器温度</strong></li></ul><p>Android 是基于 Linux 基础上修改的开源操作系统，同样的在手机系统 sys/class/thermal/ 目录下存在以 thermal_zoneX 为代表各传感器的温度分区，以及 cooling_deviceX 为代表风扇或散热器等冷却设备。</p><p>以一加 9 为例，共存在 105 个温度传感器 or 温度分区，以及 48 个冷却设备。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b5cf3938151953ff43b21f0a681ce4c9b65.jpg" alt="" referrerpolicy="no-referrer"></p><p>每个温度分区下记录下具体的参数类型，我们重点关注的是 type 文件和&nbsp;temp 文件，分别记录了该传感器设备的名称，以及当前的传感器温度。以 thermal_zone29 为例，代表了 CPU 第一核心的，第五处理单元的温度值为 33.2 摄氏度。而对单一设备来说分区对应的名称是固定的，从而我们可以通过读取 thermal_zone 文件的方式来记录当前第一个 type 文件名称包含&nbsp;CPU&nbsp;的传感器作为&nbsp;CPU&nbsp;温度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f2279774ca9ce74031e6897a9db4a7ea9dc.jpg" alt="" referrerpolicy="no-referrer"></p><ul><li><strong>壳温</strong></li></ul><p>Android 10 Google 官方推出了热缓解框架，通过 HAL2.0 框架监听底层硬件传感器（主要为 USB 传感器、Skin 传感器）提供 USB、壳温的热信号等级变更监听， 系统 PowerManager 源码提供了对应发热等级变更的回调和发热等级的获取，共 7 个等级，提供给开发者主动或被动获取。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1110179d6d33bc1f87ed57c99e6797dc931.jpg" alt="" referrerpolicy="no-referrer"></p><pre><code>final PowerManager powerManager = (PowerManager) mContext.getSystemService(Context.POWER_SERVICE);
powerManager.addThermalStatusListener(new PowerManager.OnThermalStatusChangedListener() {
    @Override
    public void onThermalStatusChanged(int status) {
       //返回对应的热状态
    }
});
</code></pre><p>但对于发热等级来说，壳温无疑是最为能够反应手机的发热情况的。可以看到 Android 系统的 API 实际上是提供了 AIDL 接口，可以直接注册 Thermal 变更事件的监听，获取到 Temperature 对象。但由于标识了 Hide API 。常规应用层是无法获取到的，在考虑好 Android 版本兼容性前提下，通过反射代理 ThermalManagerService 方式进行读取。</p><p><img src="https://oscimg.oschina.net/oscnet/up-50f7b8b0252859eb185129ba23e59b367cb.jpg" alt="" referrerpolicy="no-referrer"></p><p>但事与愿违，国内厂商并没有完全适配官方热缓解框架，热状态回调时常不够准确，而是需要单独接入每个厂商的热缓解 SDK 去直接获取到壳温，具体 API 则以各应用厂商的内部接入文档为准。</p><h2>CPU 使用率</h2><p>CPU 使用率的采集通过读取解析 Proc stat 文件的方式进行计算。</p><p>在系统 proc/[pid]/stat&nbsp; 和&nbsp; /proc/[pid]/task/[tid]/stat &nbsp;分别记录了对应进程 ID、进程 ID 下的线程 ID 的 CPU 信息。具体的字段描述在此不进行赘述，详见：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fman7.org%2Flinux%2Fman-pages%2Fman5%2Fprocfs.5.html" target="_blank">https://man7.org/linux/man-pages/man5/procfs.5.html</a> 。</p><p><img src="https://oscimg.oschina.net/oscnet/up-49d2512961ec5d6361ee15326af3c2c5885.jpg" alt="" referrerpolicy="no-referrer"></p><p>我们重点关注 14.15 位的信息，分别代表进程/线程的用户态运行的时间和内核态运行的时间。 <img src="https://oscimg.oschina.net/oscnet/up-30cbd118f0cbd9df3ddf67043cc22b050ea.jpg" alt="" referrerpolicy="no-referrer"></p><p>通过解析当前进程的 Stat 文件，以及 Task 目录下所有线程的 Stat 文件，在两次采样周期内 (当前设置为 1s) 的 utime+stime 之和的差值/采样间隔，即可认为是进线程的 CPU 的使用率。即，进线程 CPU 使用率 = ((utime+stime)-(lastutime+laststime)) / period</p><h2>GPU 使用率</h2><p>高通芯片的设备，我们可以参考&nbsp;/sys/class/kgsl/kgsl-3d0/gpubusy&nbsp;下文件内容，参考高通官网的说明。</p><p>GPU 的使用率 = (下图) 数值 1 / 数值 2 * 100，经过验证与 SnapDragonProfiler 信息采集获取的数值基本一致。 <img src="https://oscimg.oschina.net/oscnet/up-0be7cfc4a8df3b97c0a5600c5512c4e415e.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-9496bbec4a96755eb7d59997c3ac6fd12bc.jpg" alt="" referrerpolicy="no-referrer"></p><p>联发科芯片的设备，我们可以直接通过读取&nbsp;<strong>/d/ged/hal/gpu_utilization</strong> 下的使用率数值。</p><p>同样的通过指定周期 (每秒 1 次) 的采样间隔，即可获取到每秒的当前 GPU 使用率。</p><h2>系统服务使用</h2><p>Android 系统服务包括 Warelock、Alarm、Sensor、Wifi、Net、Location、Bluetooth、Camera 等。</p><p>与市面上常规的监控手段差异不大，都是通过系统 Hook ServiceManager 的方式，监听系统服务的 Binder 通信，匹配对应的调用方法名，做对应中间层监控的回调记录处理。</p><p>熟悉 Android 开发的同学知道 Android 的 Zygote 进程是 Android 系统启动时的第一个进程。在 Zygote Fork 进程中会孵化出系统服务相关的进程 SystemServer，在其核心的 RUN 方法中，会注册启动大量的系统服务，并通过 ServiceManager 进行管理。 <img src="https://oscimg.oschina.net/oscnet/up-f43504f6a7801c8edffd8a299338158a10c.jpg" alt="" referrerpolicy="no-referrer"></p><p>故我们可以通过反射代理 ServiceManager 的方式，以 LocationManager 为例进行监听，拦截对应 LocationManager 内对应的方法，记录我们期望获取的数据。</p><pre><code>// 获取 ServiceManager 的 Class 对象
Class&lt;?&gt; serviceManagerClass = Class.forName("android.os.ServiceManager");
// 获取 getService 方法
Method getServiceMethod = serviceManagerClass.getDeclaredMethod("getService", String.class);
// 通过反射调用 getService 方法获取原始的 IBinder 对象
IBinder originalBinder = (IBinder) getServiceMethod.invoke(null, "location");
// 创建一个代理对象 Proxy
Class&lt;?&gt; iLocationManagerStubClass = Class.forName("android.location.ILocationManager$Stub");
Method asInterfaceMethod = iLocationManagerStubClass.getDeclaredMethod("asInterface", IBinder.class);
final Object originalLocationManager = asInterfaceMethod.invoke(null, originalBinder);
Object proxyLocationManager = Proxy.newProxyInstance(context.getClassLoader(),
        new Class[]{Class.forName("android.location.ILocationManager")},
        new InvocationHandler() {
            @Override
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                // 在这里进行方法的拦截和处理
                Log.d("LocationManagerProxy", "Intercepted method: " + method.getName());
                // 执行原始的方法
                return method.invoke(originalLocationManager, args);
            }
        });
// 替换原始的 IBinder 对象
getServiceMethod.invoke(null, "location", proxyLocationManager);
</code></pre><p>同理，我们获取在固定采样周期内，各系统服务对应，申请次数、计算间隔时长等进行记录。</p><p>源码&nbsp;Power_profile&nbsp;文件中定义了每个系统服务状态下的电流量定义。</p><p>我们在需要记录每个元器件在不同状态的工作时间之后，通过以下计算方式，可以得出元器件的发热贡献排行，即：</p><p>元器件，电量消耗（发热贡献） &nbsp;~~ &nbsp;电流量 * 运行时长 * 电压（一般为固定值，可忽略）</p><p><img src="https://oscimg.oschina.net/oscnet/up-95b4814576aef6a67210588b65b259c9abf.jpg" alt="" referrerpolicy="no-referrer"></p><h2>线程堆栈</h2><p>由于发热问题是一个综合性的问题，并不像 Crash 问题一样，在发生现场我们就可以知道是哪个线程触发的。如果将所有线程的堆栈都进行 Dump 记录的话，得物当前运行时的子线程数量在 200+，全部进行存储的话无疑是不合理的。问题就转变为，如何较为准确的找到发热代码的线程堆栈？</p><p>上文说到，在计算 CPU 使用率的时读取进程下所有线程的 Stat 文件，我们可以获取到子线程的 CPU 使用率，对其使用率进行倒排，筛选超过阈值（当前定义 50% ) 或，占用 Top N 的线程进行存储。由于堆栈频繁采集时机上是有性能折损的，故牺牲了部分的堆栈采样精度和准确性，在温度、CPU 使用率等指标超过阈值定义后，才开始采集，指定下发时间的堆栈信息。</p><p>我们还要明确一个概念，线程 Stat 文件的文件名即为线程标识名，Thread.id 是指线程 ID。</p><p>其两者并不等价，但 Native 方法中给我们提供了对应的方式去建立两者的映射关系。</p><p>在 Art &nbsp;Thread.cc 方法中，将 Java 中的 Thread 对象转换成 C++ 中的 Thread 对象，调用 ShortDump 打印线程的相关信息，我们通过字符串匹配到核心的 Tid= 的信息，即可获取到线程的 Tid。 <img src="https://oscimg.oschina.net/oscnet/up-6e69839410035c1793072333c26c962790c.jpg" alt="" referrerpolicy="no-referrer"></p><p>核心代码逻辑如下:</p><pre><code>//获取队列中最近一次 cpu 采样的数据
 val threadCpuUsageData = cpuProfileStoreQueue.last().threadUsageDataList
       val hotStacks = mutableListOf&lt;HotStack&gt;()
        if (threadCpuUsageData != null) {
            val dataCount = if (threadCpuUsageData.size &lt;= TOP_THREAD_COUNT) {
                threadCpuUsageData.size
            } else {
                TOP_THREAD_COUNT
            }
            val traces: MutableMap&lt;Thread, Array&lt;StackTraceElement&gt;&gt; = Thread.getAllStackTraces()
            //定义 tid 和 thread 的映射关系 map
            val tidMap: MutableMap&lt;String, Thread&gt; = mutableMapOf()
            traces.keys.forEach { thread -&gt;
                //调用 native 方法获取到 tid 信息
                val tidInfo = hotMonitorListener?.findTidInfoByThread(thread)
                tidInfo?.let {
                    findTidByTidInfo(tidInfo).let { tid -&gt;
                        if (tid.isNotEmpty()) {
                            tidMap[tid] = thread
                        }
                    }
                }
            }
            //采集 topN 的发热堆栈
            for (index in 1..dataCount) {
                val singleThreadData = threadCpuUsageData[index - 1]
                val isMainThread = singleThreadData.pid == singleThreadData.tid
                val thread = tidMap[singleThreadData.tid.toString()]
                thread?.let { findThread -&gt;
                    traces[findThread]?.let { findStackTrace -&gt;
                        //获取当前的线程堆栈
                        val sb = StringBuilder()
                        for (element in findStackTrace) {
                            sb.append(element.toString()).append("\n")
                        }
                        sb.append("\n")
                        if (findStackTrace.isNotEmpty()) {
                            //是否为主线程
                            //组装 hotStack
                            val hotStack = HotStack(
                                //进程 id
                                singleThreadData.pid,
                                singleThreadData.tid,
                                singleThreadData.name,
                                singleThreadData.cpuUseRate,
                                sb.toString(),
                                thread.state
                                isMainThread
                            )
//                        Log.d("HotMonitor", sb.toString())
                            hotStacks.add(hotStack)
                        }
                    }
                }

            }
        }
</code></pre><h1>四、监控方案</h1><p>了解核心指标数据是如何获取的前提下，其实监控方案的核心思路无非就是通过远端 APM 配置中心下发的采样阈值、采样周期、各模块数据开关等限定采样配置，子线程 Handler 定时发消息，采集各个模块的数据进行组装，在合适的时机进行数据上报即可，具体的数据拆解、分析工作则由发热平台进一步处理。</p><p><strong>模块整体架构</strong><img src="https://oscimg.oschina.net/oscnet/up-b5030680856c30aab1b0a1b2d301fbbeea8.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>上报时机</strong><img src="https://oscimg.oschina.net/oscnet/up-0cbaca499275d7a3292d7a5990c26ced860.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>核心采集流程</strong><img src="https://oscimg.oschina.net/oscnet/up-81a16007734e761fbece449580c494a4ccb.jpg" alt="" referrerpolicy="no-referrer"></p><p><strong>线上线下区分</strong></p><p>由于所有子线程的 CPU 采集、堆栈采集实际上是会对性能有折损的，200+ 的线程的读取耗时整体在 200ms 左右，采样子线程的 CPU 使用率在 10%，考虑到线上用户体验问题，并不能全量开启高频率采样。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b83fd9a6c760d788fb151f04d854e8c40eb.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-2e9a9a66b142535b29d5dc9793467e73fdf.jpg" alt="" referrerpolicy="no-referrer"></p><p>故整体方案来说: 线下场景以重点侧重发现、排查、治理全量问题，上报全量日志，以 CPU、GPU 使用率为第一衡量指标；</p><p>线上场景以重点侧重观察整体发热大盘趋势、分析潜在问题场景，上报核心日志，以电池温度为第一衡量指标。</p><p><strong>发热平台</strong></p><p>在平台侧同学的支持下，发热现场数据经过平台侧进行消费，将核心的发热堆栈经过 Android 堆栈反混淆服务进行聚合，补齐充电状态、主线程 CPU 使用率、问题类型、电池温度等基础字段，平台侧就具备发现、分析、解决的流程化监控推进的能力。</p><p>具体的堆栈信息 &amp; 发热信息平台展示如下:</p><p><img src="https://oscimg.oschina.net/oscnet/up-3251d963a881ef9e7f09fcc6d73d9b2925d.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-04b122e8d11a65f06b2ed4f71062b718945.jpg" alt="" referrerpolicy="no-referrer"></p><p>由于电池温度、CPU 使用率是针对运行时发热场景最直观的指标，且我们一期重点关注发热场景的治理，不针对元器件 Hook 等耗电场景进行持续深入分析，故当前得物侧是以电池温度、CPU 使用率为第一第二指标 &nbsp;建立核心的发热问题四象限，优先关注高温、高 CPU 的问题场景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5a65d936a2e2676307b5562a55eb4fca2e7.jpg" alt="" referrerpolicy="no-referrer"></p><p>在数据分析过程中，我们遇到了数据上的效率排查效率不够高、问题精度不够准的情况。</p><ul><li>如何定位是高温场景是发生在 App 内部，且在使用过程中明显上升的？ 通过过滤从启动开始即高温、后台切换回来即高温的场景，重点关注在 App 内部温度上升的场景。</li><li>线上的采样后仍旧单日有 6w+ 数据的上报，我们如何筛选出更为核心的数据？当前的做法是定义了温度跨度的概念，优先看在 App 内部温度跨度较大的 Case。</li><li>线程存在调用 Wait 等方法阻塞的堆栈，消耗内核态的时间分配，但实际不消耗整体 CPU 的误报数据。 补充了线程的运行状态和 Proc 文件中记录的 State，方便优先处理 RUNNABLE 线程的 CPU 高温高占用问题。</li><li>手机温度上升作为渐进式的场景，如何实现温度上升场景下的页面精确归因？增加温度采样频率的同时，汇总 CPU 使用率和实时堆栈等瞬时数据作为数据支撑，但考虑到数据体量的情况，数据上报聚合裁剪方式仍在逐步探索更为合理的方式，力求在两者之间找到一个平衡点。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-838ac3d056faa216013c5cf2b87b08cbf57.jpg" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-abcc4634539696d10682e28632c278d9415.jpg" alt="" referrerpolicy="no-referrer"></p><h1>五、收益</h1><p>Android 端侧发热监控自上线以来，背靠平台侧的支撑，陆续发现了一些问题并联合开发同学做了对应场景的治理优化工作，如：</p><p>耗时独立线程任务，接入统一线程池调度管理；</p><p>动画执行死循环监测修复；</p><p>高 IO 场景的文件读写策略优化；</p><p>高并发任务锁粒度优化；</p><p>日志库等 Json 解析频繁场景，采用效率更高的序列化方；</p><p>系统相机等系统功率过高的采集参数设备分级尝试；</p><p>基于 Webgl 的游戏场景，帧率降低和资源及时回收优化运行时内存；</p><p>....</p><p>这无疑给未来体验工作的场景技术选型、技术实现沉淀了一些有价值的经验，符合对 App 体验追求极致的高标准、高要求。</p><h1>六、未来展望</h1><p>手机发热作为渐进式的体验场景，涉及手机硬件、系统服务、软件使用、外界环境多方位因素。对于端侧的排查上来说，当前优先级聚焦于应用层的不合理使用上，对于排查工具链路增强、问题业务归因、低电量、低功耗模式下的动态策略降低、自动化诊断报告等环节仍旧有很多值得深入挖掘的点，例如：</p><p><strong>监控/工具增强</strong></p><ul><li>App 浮层分析工具 (CPU\GPU/频率/温度/功耗等信息)</li><li>借鉴 BatteryHistorian、SnapdragonProfiler、Systrace 等工具，实现自研 TeslaLab 能力增强。</li></ul><p><strong>业务归因</strong></p><ul><li>发热堆栈自动分配</li><li>调用溯源归因精细化</li></ul><p><strong>场景策略、降级</strong></p><ul><li>CPU 调频、动态帧率、分辨率降级</li><li>端内低功耗模式探索</li></ul><p><strong>自动化诊断报告</strong></p><ul><li>单用户定向自动化分析输出诊断报告</li></ul><p>‍</p><h1>七、总结</h1><p>在此也只是粗略介绍当前已经做的针对发热治理的一些初步工作，以及对未来发热功耗相关开展的思路，希望能让 App 带来更好的体验，给用户带来更对美好事物的向往的感受。</p><p>*文 / GavinX</p><p>本文属得物技术原创，更多精彩文章请看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2F" target="_blank">得物技术官网</a></p><p>未经得物技术许可严禁转载，否则依法追究法律责任！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 09:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10141675</guid>
            <link>https://my.oschina.net/u/5783135/blog/10141675</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英伟达或将推出针对中国区的最新改良版 AI 芯片]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chinastarmarket.cn%2Fdetail%2F1512299" target="_blank">据<span style="background-color:#ffffff">《科创板日报》</span>报道</a></u>，产业链人士称英伟达现已开发出针对中国区的最新改良版 AI 芯片：HGX H20、L20 PCle 和 L2 PCle。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-edecf0f4b0f979b064fa454bfd31a0ec4e3.png" referrerpolicy="no-referrer"></p><p>知情人士称，最新三款芯片是由 H100 改良而来，英伟达最快或将于本月 16 号之后公布，国内厂商最快将在这几天拿到产品。</p><p>NVIDIA H100 Tensor Core GPU&nbsp;采用全新 Hopper 架构，基于台积电 N4 工艺，集成了 800 亿个晶体管。与上一代产品相比，可为多专家 (MoE) 模型提供高 9 倍的训练速度。</p><p>它配备第四代 Tensor Core 和 Transformer 引擎（FP8 精度），还具有高度可扩展的 NVLink 互连技术（最多可连接达 256 个 H100 GPU，相较于上一代采用 HDR&nbsp;Quantum&nbsp;InfiniBand 网络，带宽高出 9 倍，带宽速度为 900GB/s）等功能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-acc6975ca53f0be377caf78b3f05ea055f8.png" referrerpolicy="no-referrer"></p><p>记者向英伟达求证该消息的真实性，但截至发稿，英伟达方面暂无回应。</p><hr><p>2023 年 10 月 17 日，CNBC 报道称，美国商务部计划在未来几周内限制向中国出售更先进的人工智能芯片。高级政府官员表示，<strong>新政策将限制 NVIDIA A800 和 H800 芯片的出口</strong>。详情：<em><u><a href="https://www.oschina.net/news/262251/us-bans-export-of-more-ai-chips-including-nvidia-h800-to-china">美国政府限制向中国出口 NVIDIA H800 GPU</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 07:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265728</guid>
            <link>https://www.oschina.net/news/265728</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美团招兵买马，拟开发鸿蒙系统 App]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美团招聘官网近日更新了多个鸿蒙相关的社招开发岗位，为鸿蒙原生应用开发招兵买马。主要开发美团鸿蒙 App、大众点评鸿蒙 App。</span></p><p><span style="color:#000000">其中的一个「鸿蒙高级工程师（C++）」职位就是面向美团鸿蒙 App 研发团队。根据介绍，具体的岗位职责为：</span></p><ol><li><span style="color:#000000">参与鸿蒙端动态化容器的架构设计，确保项目研发质量和代码的可维护性；</span></li><li><span style="color:#000000">负责鸿蒙端动态化容器的模块设计与实现，实现高性能、高质量的容器模块；</span></li><li><span style="color:#000000">对项目中的技术难点和重点进行深入研究和总结，积累可复用的经验。</span></li><li><span style="color:#000000">能够主动解决和推动项目前鸿蒙端动态化容器技术领域的阻塞点和难点；</span></li><li><span style="color:#000000">结合美团的业务需求，探索行业前沿技术，规划容器技术路线。</span></li></ol><p><span style="color:#000000">且满足「熟悉 ArkTS 和鸿蒙上的主流开发框架（例如 ArkUI）；作为主要贡献者参与过有影响力的开源产品的开发；了解 Web 开发，熟悉浏览器内核的运行机制；了解动态化容器原理，熟悉 Hybrid、React Native、Flutter 等前沿技术之一；乐于分享和沟通，活跃于 GitHub 和各大技术社区，或有自己的高质量原创博客」等条件的将优先考虑。</span></p><p><span style="color:#000000"><img alt="" height="267" src="https://oscimg.oschina.net/oscnet/up-ae63f8c42eec2e0095d1026cb5f531df31b.png" width="500" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 07:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265725</guid>
            <link>https://www.oschina.net/news/265725</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[vivo 公布蓝心大模型 BlueLM-7B 开源地址]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>vivo 已在&nbsp;Hugging Face 上正式开源蓝心大模型 BlueLM-7B。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7b7b72160940bf13dc85103adc480ff135f.png" referrerpolicy="no-referrer"></p><p>地址：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fvivo-ai" target="_blank">https://huggingface.co/vivo-ai</a></u></p><p>BlueLM-7B 开源大模型包括&nbsp;<strong>7B 基础模型和 7B 对话模型</strong>，vivo 还开源了支持&nbsp;32K&nbsp;的长文本基础模型和对话模型。</p><p>据介绍，BlueLM 采用高质量语料库进行训练，<strong>规模达到了&nbsp;2.6 万亿&nbsp;的 token 数，该语料库包含中文、英文以及少量日韩数据</strong>。其中 BlueLM-7B-Chat 在&nbsp;C-Eval&nbsp;和&nbsp;CMMLU&nbsp;上均取得领先结果。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-032d6f2119d13af32e2019c475fa5b87681.png" referrerpolicy="no-referrer"></p><p>BlueLM-7B-Base-32K 和 BlueLM-7B-Chat-32K 均支持&nbsp;32K&nbsp;长文本，在保持基础能力相当情况下，能够支持更长上下文理解。</p><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/264455" target="_blank">vivo 开源蓝心大模型-7B：70 亿参数、适合中国开发者</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 06:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265715</guid>
            <link>https://www.oschina.net/news/265715</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 服务中断近 2 小时，CEO 奥特曼道歉：流量远超预期]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京时间 11 月 8 日晚 22 点左右，OpenAI 旗下 ChatGPT 以及相关 API 出现中断故障，导致面向用户和开发者的服务近 2 小时无法正常使用。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/114753_pknp_2720166.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstatus.openai.com%2F" target="_blank">随后 OpenAl 更新事故报告称</a></u>，已确定了一个导致 API 和 ChatGPT 错误率高的问题，正在努力修复。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/114923_hRcd_2720166.png" referrerpolicy="no-referrer"></p><p>与此同时，OpenAI CEO 山姆・奥特曼<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1722315204242149788">公开致歉称</a></u>，本周发布的新功能遇到远超预期的使用量。公司原计划在周一为所有订阅者启用 GPTs 服务，但目前还无法实现。由于负载的原因，短期内可能会出现服务不稳定的情况，对此情况向用户道歉。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/1109/113902_kyvS_2720166.png" referrerpolicy="no-referrer"></p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/265330">OpenAI 开发者大会：GPT-4 Turbo、GPTs 商店、128k 上下文窗口、大降价</a></li><li><a href="https://www.oschina.net/news/265331/openai-custom-versions-chatgpt">OpenAI 推出用户自定义版 ChatGPT</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265693</guid>
            <link>https://www.oschina.net/news/265693</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果正在利用 LLM 彻底改造 Siri，将成为杀手级 AI 应用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>爆料者 Tech_Reve 发表推文<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTech_Reve%2Fstatus%2F1722418466647625999" target="_blank">表示</a></u>，苹果公司正在使用大语言模型 (LLM) 将 Siri 彻底改造成「终极虚拟助理」，并准备将其开发为「最强大的杀手级 AI 应用」。</p><p>目前苹果正在积极推进这项开发工作，首款产品预计将在 WWDC 2024 上亮相。改进后的 Siri 将成为 iPhone 16 及后续机型的标配功能。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/111614_rFyz_2720166.png" referrerpolicy="no-referrer"></p><p>Tech_Reve 还说道，苹果和三星一样<strong>，整体思路都是专注于在设备侧运行，同时配合云端实现相关 AI 服务</strong>，这是因为 AI 在本地运行响应时间更快、不需要网络连接，且更具隐私性。</p><p>上个月<u><a href="https://www.oschina.net/news/263067">彭博社的报道</a></u>也提到了苹果公司内部对如何部署生成式 AI 的争论：<strong>完全在设备上运行、基于云运行或介于两者之间</strong>。</p><p><span style="background-color:#ffffff; color:#333333">部署在设备上会运行得更快，并有助于保护隐私，但通过云部署大模型将允许更高级的操作。部署在设备端的策略也会让苹果更难更新其技术并适应快速变化的行业。考虑到这一点，该公司很可能采用组合方法：<strong>使用设备上的部署处理某些功能，使用云来处理更高级的任务</strong>。</span></p><p>彭博社还提到，今年 7 月，苹果公司构建了自己的大型语言模型，<a href="https://www.oschina.net/news/250184/apple-gpt"><strong>称为 Ajax</strong></a>，并推出了一个名为 「Apple GPT」 的内部聊天机器人来测试其功能。下一步的关键是确定该技术是否能够应对竞争对手，以及苹果如何将其实际应用到产品中。</p><p>分别负责人工智能和软件工程的高级副总裁 John Giannandrea 以及 Craig Federighi 正在带头开展这项工作，服务主管 Eddy Cue 也参与其中。目前，3 人计划每年在该项目上花费约 10 亿美元。</p><p>据介绍，John Giannandrea 主要负责全新 AI 系统的底层技术，他的团队目前正在改进 Siri，这个更智能的 Siri 最早可能会在明年准备就绪。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265689</guid>
            <link>https://www.oschina.net/news/265689</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 工程师年薪中位数高达 92.5 万美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">来自美国薪资跟踪网站 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.levels.fyi%2Fcompanies%2Fopenai%2Fsalaries%2Fsoftware-engineer" target="_blank">Levels.fyi</a> 的数据显示，OpenAI 软件工程师的年薪中位数高达 92.5 万美元，其中包括基本工资以及潜在的股票报酬和奖金。</span></p><p><span style="color:#000000">目前 OpenAI 薪酬最低的工程师底薪为 21 万美元，拥有约 2 至 4 年的行业从业经验。L5 软件工程师（拥有 10 年以上工作经验的软件工程师）的底薪为 30 万美元，另外还可以获得 62.5 万美元的股票薪酬。此外，该公司的一些高级软件工程师的薪酬甚至更高，年薪最高达到 140 万美元。</span></p><p><img height="139" src="https://oscimg.oschina.net/oscnet/up-540ee3f9087289680579b5a9f2e340b6bf7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenAI 提供的高薪不仅对公司本身，而且对整个行业都具有深远影响。根据 Levels.fyi 的数据，以科技中心和人才库著称的旧金山，为 AI 软件开发人员提供的薪酬中位数一般约为 30 万美元。「通过提供近三倍的薪酬，OpenAI 为该地区的薪酬设定了新的基准，并表明其致力于吸引和留住顶尖 AI 人才的承诺。」</span></p><p><span style="color:#000000">OpenAI 的员工薪资由「基本工资」和「Profit Participation Units(PPU)」两个部分组成。PPU 是 OpenAI 独创的分润机制，该公司以 PPU 的形式提供股票薪酬，让员工分享公司的利润。</span></p><p><img height="291" src="https://oscimg.oschina.net/oscnet/up-9f5f514ce43285fd98946d201453956b368.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">而 PPU 的价值取决于公司未来的表现或被收购时的估值。9 月份有消息称，<span style="background-color:#ffffff">OpenAI&nbsp;</span><span style="background-color:#ffffff">正在与投资者讨论股票出售事宜</span><span style="background-color:#ffffff">，其</span><span style="background-color:#ffffff">估值大概在 800 亿至 900 亿美元之间，约是今年早些时候水平的三倍。今年 4 月，OpenAI 曾从红杉资本、Andreessen Horowitz、Thrive 和 K2 Global 等支持者那里获得了略高于 3 亿美元的融资，估值为 290 亿美元。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265688/openai-software-engineer-pay</guid>
            <link>https://www.oschina.net/news/265688/openai-software-engineer-pay</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[魅族为 Flyme 征集中文名，入选者将获赠「华小魅」手机组合包]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>魅族科技今日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2683843043%2FNrJHikCZG%3Fpagetype%3Dprofilefeed" target="_blank">发布公告称</a></u>，集魅友力量，<strong>为 Flyme 征集中文 OS 名称</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-75abc601083ca8c26ecda32cafc7d8aac84.png" referrerpolicy="no-referrer"></p><p>魅族在公告写道：「再一次，华为、小米、魅族奔跑在了同一条道路上，一条由中国企业定义、引领的手机、汽车、AR 等多终端全场景生态融合发展的道路。」</p><p>在这样一个奔涌的时代，<strong>Flyme 也需要拥有像鸿蒙、澎湃一样响亮的中文名</strong>。和用户共创是魅族的传统，魅族科技将 Flyme 的中文 OS 命名权交给魅友。</p><p>该公司将选取三个意向名称，创作者可获赠「华小魅」手机组合一份（<strong>包含华为 Mate 60 Pro、小米 14 Pro、魅族 20 PRO 各一部</strong>）。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 02:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265679</guid>
            <link>https://www.oschina.net/news/265679</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 11 原生支持 7z 和 .tar 压缩文件格式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>推特用户 @PhantomOfEarth <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FPhantomOfEarth%2Fstatus%2F1722334216199766161" target="_blank">发现</a></u>，最新的 Windows 11 Canary 版本支持将文件压缩为另外两种存档格式：.<strong>7z 和 .tar</strong>。虽然 RAR 格式仍然缺失，但至少不再局限于 zip。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bac57f48d11859af0d2e31f42856329e753.png" referrerpolicy="no-referrer"></p><p>微软没有在第 25992 版的发布说明中提及这一变更。此外，它已在默认情况下启用，因此无需执行特殊命令即可让 Windows 11 将文件打包为 7z 和 TAR 格式。将系统更新至版本 25992 后，选择要存档的文件，然后从右键菜单中选择"压缩至"即可实现。</p><p><img src="https://static.oschina.net/uploads/space/2023/1109/101016_c73D_2720166.png" referrerpolicy="no-referrer"></p><p>除了可以处理更多的归档类型，Windows 11 版本 25992 还提高了处理大型 ZIP 文件时的性能。发布说明中提到了这一点：</p><blockquote><p>做了一些工作，应有助于明显改善在文件资源管理器中打开大型 .zip 文件的性能。</p></blockquote><p>Windows 11 build 25992 中的其他更改包括 SMB 升级、已知问题修复和剪切工具中的 HDR 支持改进。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265668</guid>
            <link>https://www.oschina.net/news/265668</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[以浏览器为开端，海泰方圆联合 openKylin 持续开展安全创新]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，北京海泰方圆科技股份有限公司（以下简称「海泰方圆」）签署 openKylin 社区 CLA（Contributor License Agreement 贡献者许可协议），正式加入 openKylin 开源社区</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-30204f1812a28ab7bf8a53b135c586e329b.png" width="829" referrerpolicy="no-referrer"></p><p><span>海泰方圆是一家以密码全能力和可信数据管理为核心，全面服务网信大时代的领军安全企业。公司拥有国家保密局颁发的多项甲级资质、军工三证，并具备各类档案、载体的数字化加工资质和能力。海泰方圆成立于 2003 年，作为一家密码基因深厚的技术型企业，公司以「让信息世界充满信任」为使命，聚焦密码、数据治理、数据安全、国密浏览器、移动安全、物联及工控安全等多个领域，为党政、金融和大型企事业等客户提供全方位的专业安全解决方案及服务，以云化、智能化、平台化的密码服务和保障，护航数字中国，建设网络强国。</span></p><p style="text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-0bb93bbd9a72f5673030aaf3710c92897b7.png" width="940" referrerpolicy="no-referrer"></p><p><span>海泰方圆作为 openKylin（开放麒麟）社区共建伙伴，在加入社区后便积极开展双方产品的适配认证工作，于近期<strong>正式完成 openKylin 开源操作系统 V1.0 与红莲花安全浏览器 V5.0 的适配测试工作，并上架应用商店</strong>。测试结果表明，<strong>红莲花浏览器在 openKylin 操作系统上运行稳定，使用流畅。</strong></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a6d035f42cfa9089f7d758b91dc0fc6016c.png" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888">适配证书</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-27a21c058492459d08169c4b606e5cbd3a8.png" width="1920" referrerpolicy="no-referrer"></span></p><p style="text-align:center"><span style="color:#888888">红莲花安全浏览器已上架 openKylin 应用商店</span></p><p><span>浏览器作为操作系统必不可少的基础软件和业务应用的承载容器，在 IT 环境中，发挥着举足轻重的作用。海泰方圆红莲花安全浏览器，融入我国国产密码算法和一系列安全功能，打造了更安全的架构，支持自主网络信任体系。全面兼容龙芯（MIPS)、龙芯（LoongArch)、飞腾、兆芯、鲲鹏、海光、申威等国产处理器；全面兼容麒麟操作系统；全面兼容金山 WPS、数科、书生、点聚等电子公文、电子签章、电子文档、中间件以及数据库等基础软硬件产品。</span></p><p><span>未来，海泰方圆将持续与 openKylin 社区开展深入合作，共同开展面向安全和密码领域的合作，共建桌面操作系统根社区创新技术生态。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 09 Nov 2023 01:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265665</guid>
            <link>https://www.oschina.net/news/265665</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[目标智能体社会，MetaGPT 携手 Jürgen Schmidhuber 团队]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6a26cdfc68540cd8ce50fd07f1d06aa~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=530&amp;s=59164&amp;e=webp&amp;b=fcfbfb" referrerpolicy="no-referrer"><img alt="" height="335" src="https://oscimg.oschina.net/oscnet/up-35f95b18cb984ecd9e8659b66778355d901.jpg" width="800" referrerpolicy="no-referrer"></p><p>过去数月，MetaGPT [1] 的智能体（Agents）软件公司实例让人印象深刻，它迅速在 GitHub 获得了 30k star，也获得了数十个全球专业媒体与大 V 报道。但智能体软件公司只是智能体社会（Agent Society）的一个缩影。智能体社会或许会有软件公司、电商公司、游戏公司，也会拥有大量的独立智能体提供生产力。现代人工智能之父 Jürgen Schmidhuber 也非常认可智能体社会的理念，他与其团队对 MetaGPT 做出了显著贡献，列入了 MetaGPT 作者名单。</p><p>早在 1986 年，马文·明斯基以《心智社会》（Society of Mind, SOM）[2] 之作引领了人工智能领域的一场思想革命。他提出了一个极具创见的理论：心智不需由具有智能的单独部件构成，反而是由一系列简单部件的相互作用集结而成的复杂系统，正是这种集结，催生了我们所认识的智能和意识。这一理念对于构建自主智能体以及其后续发展，产生了不可估量的深远影响。</p><p>随着人工智能技术至 2023 年的飞跃，我们现在可以设想，如果每个微小部件本身都拥有一定程度的智能，它们将如何相互作用，产生何种层次的集体智能。2023 年上半年关于自然语言心智社会（NLSOM, Language Agent Society）的研究论文 [3] 中，来自阿卜杜拉国王科技大学、瑞士人工智能实验室、牛津大学以及苏黎世联邦理工学院等知名研究机构的科学家们共同探讨了智能体社群的可能性。</p><p>他们提出，构建成由语言驱动的智能体社区，能够协同完成单一智能体无法或难以独立完成的任务。研究中提出了一系列实验构想，这些实验构想不仅仅是概念验证，它们被视作迈向一个包含万亿级智能体社会的先导，这个社会可能也会包括人类成员。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/21644b3cc3a84c2db0d0da75652a0cb0~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=981&amp;h=1280&amp;s=170610&amp;e=webp&amp;b=fcfbfb" referrerpolicy="no-referrer"><img alt="" height="1044" src="https://oscimg.oschina.net/oscnet/up-2ee6f8c420b35e61bc71e31c9228d6fcd13.png" width="800" referrerpolicy="no-referrer"></p><p>在 2023 年的 CogX Festival 上，Jürgen 向听众展示了他对于大型语言模型（LLMs）的深刻见解。他在讨论智能体（Agents）相关的话题时，提到了构建自我改进系统的多种途径，包括通用图灵机（Universal Turing Machine）[4] 和哥德尔机（Gödel machines）[5]。他指出，目前的大语言模型为我们提供了一种全新的思维模式 — 通过使用通用符号语言（例如：自然语言或编程代码）作为接口，来串联不同的模型。这些模型能够与其他语言模型进行交流，共同构建起一个自然语言心智社会（NLSOM）的范例。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/51d8e153f5514d13820c1d67539ede46~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1920&amp;h=1080&amp;s=66142&amp;e=webp&amp;b=7d5c3e" referrerpolicy="no-referrer"><img alt="" height="450" src="https://oscimg.oschina.net/oscnet/up-f4af29afe3864c3625875a198b225f27628.jpg" width="800" referrerpolicy="no-referrer"></p><p>Jürgen Schmidhuber 教授是瑞士人工智能实验室 (IDSIA) 的科学主任，以及阿卜杜拉国王科技大学人工智能中心 (AI Initiative, KAUST) 的主任。他的工作对强化学习（Reinforcement Learning），元学习（Meta Learning），以及神经网络（Neural Network）等重要人工智能方向有着深刻的影响。</p><p>截止目前，Schmidhuber 教授的谷歌学术引用为 21 万，其中作为共同发明人的长短时记忆（LSTM）论文单篇引用过 9 万。他在 15 岁就希望能开发一种比它聪明并且能够自我完善的人工智能，然后他就可以退休了。DeepMind 创始初期四人中的两人以及他们招募的第一个人工智能博士都来自 Jürgen Schmidhuber 的实验室。</p><p>在 Jürgen 构想的这一社会中，所有的交流都是透明且易于解释的。他提到了一个被称作「Mindstorm」的概念，即当给定一个问题时，这个自然语言心智社会能够协同合作进行解答。</p><p>在这个过程中，社会中的每个成员可能会有不同的想法和视角，它们将收集并整合这些不同的思路，从而做出集体决策。</p><p>这种方式特别适合于解决那些单个智能体无法有效解决的问题。Jürgen 进一步举例说明，这种问题可以是编程性质的，如使用 Python 语言解决一个具体的编程难题。通过这种协同作用，智能体社会的智能集结，将能够实现超越个体能力的解决方案。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5cc7dc94e9a64bebb63187c960442abd~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1269&amp;h=635&amp;s=49620&amp;e=webp&amp;b=fdfaf9" referrerpolicy="no-referrer"><img alt="" height="401" src="https://oscimg.oschina.net/oscnet/up-0a2e1cb3557ba4e33b63ccceca6b4647eb2.png" width="800" referrerpolicy="no-referrer"></p><p>此次 MetaGPT 项目的迭代获得了 Jürgen 直接指导，其团队也在代码、写作、工程上做了大量支持。</p><p>接下来，本文将详细解析 MetaGPT 论文的更新内容，以便让读者能够更加深入地理解其细节。</p><p><strong>1、论文与框架更新</strong></p><p>论文 3.1 节更新：阐述了 MetaGPT 框架中的角色专业化设计和角色分工概念，说明了单个智能体在 MetaGPT 中的行为模式和 SOPs 下的组织方式。</p><p>论文 3.2 节更新：介绍 MetaGPT 框架中的通信机制，包括结构化通信接口设计和发布-订阅机制。</p><p>论文 3.3 节更新：引入了可执行反馈机制，它是一种在代码执行过程中进行持续迭代和自我纠正的机制。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/52272b7b6df4434589d9071492e7d736~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=636&amp;s=82808&amp;e=webp&amp;b=fdfcfc" referrerpolicy="no-referrer"><img alt="" height="401" src="https://oscimg.oschina.net/oscnet/up-47bacc68b62b046bdc40b461241d7a1ab26.jpg" width="800" referrerpolicy="no-referrer"></p><p>Fig.2. 通信协议示例（左）和运行中可执行反馈的迭代编程示例（右）。左图：Agents 使用共享消息池发布结构化消息。它们还可以根据自己的配置订阅相关消息。右图：生成初始代码后，工程师 Agent 可执行代码并检查运行中是否报错。如果出现报错，Agent 会检查执行结果，并将它们与 PRD、系统设计和代码文件进行比较，进行代码的重写和优化。</p><p><strong>1.1、智能体通信协议</strong></p><p>目前大部分多智能体都是通过以自然语言为主的对话形式来完成协作，但这对于解决具体特定任务而言并不是最优的方式。</p><p>没有约束和特定要求的自然语言输出，可能会导致信息内容的失真或者语义焦点的偏移。</p><p>因此，结构化的通信内容和接口形式有助于智能体之间进行快速准确的任务要求理解，也有利于信息内容的最大化保留。参考人类 SOPs 中对不同岗位的角色要求，我们给每个角色设定了符合人类对应岗位专家的输出规范，要求智能体将原始自然语言信息转换为更结构化的表达（如下图所示），如数据结构、API 设计和时序图。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39c4bc32ea9644b9b0f383b5b9810d81~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=1235&amp;s=146554&amp;e=webp&amp;b=ddecfb" referrerpolicy="no-referrer"><img alt="" height="779" src="https://oscimg.oschina.net/oscnet/up-3cb7baa9146b4b2f65471d6d5f4e2f4f4a7.jpg" width="800" referrerpolicy="no-referrer"></p><p>Fig.3 MetaGPT 软件开发流程示意图，表明结构化的 SOPs 可以带来较好的效果 。更详细的演示见附录 B</p><p>在后续的实验中，我们对比了 MetaGPT 和 ChatDev（使用聊天形式的沟通协作机制）来进行软件开发的这一复杂任务的实际解决效果，结果说明结构化的通信接口设计对于智能体协作能带来显著效果。</p><p><strong>发布-订阅机制</strong></p><p>在多智能体的通信过程中，仅仅依赖 1v1 的单点通信方式不仅会加剧通信拓扑的复杂度，导致协作的效率低下，也会急剧增加开发成本。因此，我们通过【发布-订阅】的消息机制，在框架内实现了共享消息池和基于兴趣的订阅方式。</p><p>具体来说，环境提供共享的消息池，智能体可以从中直接获取信息，无需逐一询问其他智能体。与此同时，智能体可根据自己兴趣/关注的行为来进行消息的过滤和筛选，从而减少消息/记忆的过载。如图 3 所示，架构师主要关注产品经理的 PRD 文档输出，而对测试工程师的文档则关注较少。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f4cb736da0047778cb331c48db14fb9~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1266&amp;h=705&amp;s=29794&amp;e=webp&amp;b=f9fbfe" referrerpolicy="no-referrer"><img alt="" height="445" src="https://oscimg.oschina.net/oscnet/up-fa141e11ff2fb59723d29e9be1259680890.jpg" width="800" referrerpolicy="no-referrer"></p><p><strong>1.2、可执行迭代反馈设计</strong></p><p>调试和执行反馈在日常编程任务中发挥着重要作用。然而，现有方法往往缺乏自我纠正机制，仅通过代码审查和评审机制进行代码可行性评估。为了进一步减少 LLM 在生成代码上的幻觉问题，我们引入了可执行反馈机制，对代码进行迭代改进。通过自动的代码执行测试结果反馈，进行代码可行性评估和判断，促进 LLM 进行自我的迭代和优化。如图 2 所示，工程师可根据代码执行结果持续更新代码，迭代测试，直到测试通过或者最大 N 次重试退出。</p><p><strong>2、实验更新</strong></p><p>在实验部分，我们增加了对 SOPs 引入多智能体框架效果的探索实验，和可执行迭代反馈带来的代码质量的提升实验。在数据集上：</p><ol><li>针对代码质量的效果评估：我们使用了两个公共基准数据集：HumanEval 和 MBPP。<br> 1）HumanEval 包括 164 个手写编程任务。这些任务包括功能说明、描述、参考代码和测试。<br> 2）MBPP 包含 427 个 Python 任务。这些任务涵盖核心概念和标准库功能，幷包括说明、参考代码和自动测试。</li><li>我们提出了更具有挑战性的软件开发任务的基准数据集 SoftwareDev：我们的 SoftwareDev 数据集收集了 70 个具有代表性的软件开发任务实例，每个实例都有自己的任务提示（见论文表 5）。这些任务的范围多种多样（见论文图 5），如迷你游戏、图像处理算法、数据可视化等。它们为真实的开发任务提供了一个强大的测试平台。与之前的数据集不同，SoftwareDev 侧重于工程方面。在比较中，我们随机选择了七个具有代表性的任务进行评估。</li></ol><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a63997ca887a49a1a619d93e208c164d~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=703&amp;h=727&amp;s=87524&amp;e=webp&amp;b=fbfafa" referrerpolicy="no-referrer"><img alt="" height="620" src="https://oscimg.oschina.net/oscnet/up-762eec7feede0d100b7ae1c5039f8331f71.jpg" width="600" referrerpolicy="no-referrer"></p><p><strong>2.1、可执行迭代反馈设计</strong></p><p>图 4 表明，MetaGPT 在 HumanEval 和 MBPP 基准测试中均优于之前的所有方法。当 MetaGPT（使用 GPT-4 作为基础模型），与 GPT-4 相比，它在 HumanEval 基准测试中的 Pass @1 显著提高。它在这两个公共基准测试中达到了 85.9% 和 87.7%（考虑到实验成本，部分模型的数值结果直接使用的 Dong et al. (2023). 所提供的结果 [6]）。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6749bae368dd4f4d86ac44a57ace9c82~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1280&amp;h=382&amp;s=31468&amp;e=webp&amp;b=fdfdfd" referrerpolicy="no-referrer"><img alt="" height="239" src="https://oscimg.oschina.net/oscnet/up-55fc3e480ea87fb5c5872f15472848bf135.jpg" width="800" referrerpolicy="no-referrer"></p><p>Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.</p><p><strong>2.2、软件开发任务数据集 &amp; 评价指标</strong></p><p>对于 SoftwareDev，我们优先考虑生成项目的实际可用性，并通过人工评估（A、E）或统计分析（B、C、D）来评估性能，我们通过可视化示例展示了 MetaGPT 的自主软件生成能力（论文图 5）。有关其他实验和分析，可参阅论文附录 C：</p><p>（A）可执行性：该指标将生成代码从 1（失败/无功能）到 4（无缺陷）进行评级。1 代表无功能，2 代表可运行但不完美，3 代表接近完美，4 代表无缺陷。</p><p>（B）成本：这里的成本评估包括（1）项目运行时间（2）Token 消耗量和（3）实际费用。</p><p>（C）代码统计信息：包括（1）代码文件数量（2）每个文件的平均代码行数，以及（3）总代码行数。</p><p>（D）生产效率：基本定义为 Token 使用量除以代码行数，即每行代码消耗的 Token，该数值越小说明代码生产效率越高。</p><p>（E）人工修订成本：以确保代码顺利运行所需的修订轮数来量化，这表示人工干预的频率，如调试或导入依赖等修订。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7cce3f4c622541ea856eb3dc0e1fd9b8~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1266&amp;h=761&amp;s=58372&amp;e=webp&amp;b=f8f7f7" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-58d8c9338be9e954eee491611053ad8b451.png" width="800" referrerpolicy="no-referrer"></p><p><strong>2.3、SOPs vs ChatChain</strong></p><p>在解决特定任务的场景中，为了探索 SOPs 对多智能体协作的效果，我们选择了开源工作中支持软件开发任务的智能体框架 ChatDev 作为实验比较对象。ChatDev 是基于 ChatChain 和软件开发瀑布流的角色分工进行智能体组织和协作的框架。我们从 SoftwareDev 选择了 7 个任务进行对比，并比较了上述的相关指标来说明差异。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2c3560be06bd46feab9b37a51b03e6aa~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=741&amp;s=67220&amp;e=webp&amp;b=ffffff" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-06aa7e7223004b9c3b2ca38b88efa69b92d.png" width="800" referrerpolicy="no-referrer"></p><p>如论文表 1 所示，在具有挑战性的 SoftwareDev 数据集上，MetaGPT 几乎在所有指标上都优于 ChatDev。</p><p>例如：在可执行性方面，MetaGPT 得到了 3.75 分，非常接近 4 分（完美无缺）。此外，它花费的时间（503 秒）也明显少于 ChatDev。</p><p>在代码统计和人工修改的成本上也明显优于 ChatDev。虽然 MetaGPT 需要更多的 Token（24,613 或 31,255，而 ChatDev 为 19,292 ），但它只需要 126.5/124.3 个 Tokens 就能生成一行代码。相比之下，ChatDev 使用了 248.9 个 Tokens。</p><p>这些结果凸显了 SOPs 在多智能体协作中的优势。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2c8b076075554df5a425342a9c1940e7~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=817&amp;h=263&amp;s=24046&amp;e=webp&amp;b=f4f4f4" referrerpolicy="no-referrer"><img alt="" height="258" src="https://oscimg.oschina.net/oscnet/up-b7e033a3dab2d9dbc88391df2712d572478.jpg" width="800" referrerpolicy="no-referrer"></p><p><strong>3、致谢</strong></p><p>感谢来自 KAUST AI 中心的执行秘书 Sarah Salhi，博士后王宇辉，以及博士生王文一对于此论文提供的建议以及帮助。</p><p>[1] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fpdf%252F2308.00352.pdf" target="_blank">arxiv.org/pdf/2308.00…</a></p><p>[2] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FSociety_of_Mind" target="_blank">en.wikipedia.org/wiki/Societ…</a></p><p>[3] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fpdf%252F2305.17066.pdf" target="_blank">arxiv.org/pdf/2305.17…</a></p><p>[4] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FUniversal_Turing_machine" target="_blank">en.wikipedia.org/wiki/Univer…</a></p><p>[5] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FG%2525C3%2525B6del_machine" target="_blank">en.wikipedia.org/wiki/Gödel_…</a></p><p>[6] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fabs%252F2304.07590" target="_blank">arxiv.org/abs/2304.07…</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 08 Nov 2023 10:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265625</guid>
            <link>https://www.oschina.net/news/265625</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[华为与西工大合作，发布首款流体力学大模型「秦岭・翱翔」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>华为近日宣布，与西北工业大学联合研发的首个面向飞行器的流体力学大模型「秦岭・翱翔」现已正式发布。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ff4d245868c9104fe5ffe5ca0fd9c6111a1.png" referrerpolicy="no-referrer"></p><p>秦岭・翱翔大模型是西工大流体力学智能化国际联合研究所携手华为 AI4Sci Lab 在国产开源流体计算软件风雷的基础上，依托升腾 AI 澎湃算力及升思 MindSpore AI 框架共同研发的面向飞行器流体仿真的智能化模型。</p><p>大模型通过打造智能通用的流体力学软件平台与流体工业全场景应用底座，旨在实现全场景流场准确预测。同时结合业界领先的数据同化、AI 湍流模型、流场快速预测等技术，支撑流体力学大模型的基础构架。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d498c2db0add1f15cf241f0aff43d998bfb.png" referrerpolicy="no-referrer"></p><p>具体来说，大模型采用自研多级分布式并行自适应框架，多层级融合流体力学经典理论和人工智能方法，构造数学物理关联特征、开展多范式一体化建模、搭建不变性可实现性多模态统一框架。同时，在模型算法设计、混合精度加速，以及数值求解耦合并行优化等方面进行了创新与验证，实现了高置信度流场重构、全速域湍流场求解和复杂流场近实时预测。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 08 Nov 2023 08:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265612</guid>
            <link>https://www.oschina.net/news/265612</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[著名硬件黑客黄欣国：美国限制 RISC-V 只会适得其反]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美国立法者继续施压限制中国使用 RISC-V 的举措已经引起质疑。著名硬件黑客黄欣国近日就针对此事，写了一封至白宫、<span style="background-color:#ffffff">美国商务部和国会议员</span>的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bunniestudios.com%2Fblog%2F%3Fp%3D6862" target="_blank">公开信</a>，敦促不要对 RISC-V 技术的共享施加任何限制。</span></p><p><span style="color:#000000">他认为，增添限制只会减少美国对一项重要新兴技术的参与，同时巩固 ARM 作为嵌入式 CPU 近乎垄断的现有供应商的地位。</span></p><blockquote><p><span style="color:#000000">我是一名出生于密歇根州的美国人，拥有麻省理工学院电子工程博士学位。我还是一个设计和制造电子产品的小企业主。我写信敦促你们不要对 RISC-V 技术的共享施加任何限制。</span></p><p><span style="color:#000000">我的产品 CPU 基于开源的 RISC-V 标准。RISC-V 的开放性特别有利于像我这样的小企业。我从开源社区获得工具和设计，并将自己的改进回馈给社区。无障碍地参与这个充满活力的开源生态系统可以降低开销，使我能够在残酷的硬件行业中保持竞争力。</span></p></blockquote><p><span style="color:#000000">作为一个全球性项目，RISC-V 并不是美国的单独所有，其很多贡献都来自欧盟、印度、中国等地。黄欣国指出，譬如他所使用的&nbsp;VexRiscv，就是由欧盟开发的一个 RISC-V 实现。「<strong>对美国人的参与设置任何障碍都只会延缓美国在开发和采用该技术方面的进展。其效果将与立法者的初衷背道而驰</strong>」。另一个微妙之处在于，RISC-V 只是一种标准，对既定标准的使用进行监管也不切实际。</span></p><p><img height="318" src="https://oscimg.oschina.net/oscnet/up-211d8f4d387a1aadc108064451b71db8e29.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">黄欣国认为，美国立法者和政策制定者普遍对开源缺乏了解。并<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F11%2F07%2Fproposed_restrictions_riscv" target="_blank">表示</a>他最大的担忧在于，美国的这一限制可能会造成寒蝉效应，迫使企业和组织决定不采用或停止为 RISC-V 做贡献，暂停 RISC-V 生态系统的参与。因为所面临的违反美国出口管制的风险太大 —— 包括最高 25 万美元的民事处罚、20 年监禁的刑事处罚和最高 100 万美元的罚款。</span></p><p><span style="color:#000000">「这将使 RISC-V 世界变得更加匮乏：至少来自美国人的创新和贡献会减少，其他人使用它的动力以及开发它的理由也会减少......这将使美国失去强有力的第三选择 ISA。」</span></p><p><span style="color:#000000">此外，黄欣国还认为，美国的这一限制很大程度上将促使中国结束对西方技术的依赖，转而把钱花在自研芯片上。他在信中总结称：</span></p><blockquote><p><span style="color:#000000">总之，对美国人共享 RISC-V 技术施加任何限制都只会削弱美国作为技术领导者的作用。过于宽泛的限制可能会剥夺教育工作者在美国校园向学生传授计算机知识时使用的流行工具，因为他们担心也会意外地向被禁运的实体传授知识。即使是对 RISC-V 的狭义限制，也会使那些有可能进入中国市场的美国科技公司失去获得高性价比、高性能 CPU 技术的机会，迫使它们向近乎垄断的现有供应商 ARM Holdings plc 支付专利费，而 ARM Holdings plc 并非美国公司。这削弱了美国的竞争力，最终损害了美国的最佳利益。</span></p><p><span style="color:#000000">如果政府认为 RISC-V 是一项对美国经济和军事利益至关重要的技术，值得特别关注，那么它就不应该试图通过联邦强制许可制度来限制 RISC-V 的表达，而应该投资于开发更多美国本土 RISC-V 芯片制造商成功案例的项目。在美国现有的法律框架和 RISC-V 合同框架内，公司可以选择开发 RISC-V CPU 的专有实施方案。在美国，有许多公司在开放标准的界限内游刃有余，并有在不需要联邦指导的情况下取得成功的先例： Intel 和 AMD 都是美国工业巨头，它们都是通过专有技术实现原本公开的"x86"计算机标准而建立起来的。美国需要的是对 ARM Holdings plc 的垄断做出回应，而这一回应来自于对接受 RISC-V 的美国公司的投资。</span></p><p><span style="color:#000000">拜登总统，我恳请您：对美国的创新充满信心。相信美国的价值观。不要对共享 RISC-V 技术施加任何限制。我们可以共同努力，创造更多美国芯片制造商的成功案例，同时拥抱言论自由的美国价值观！</span></p></blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bunniestudios.com%2Fblog%2F%3Fp%3D6862" target="_blank"><strong>公开信地址&nbsp;</strong></a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 08 Nov 2023 08:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265608/bunnie-restrictions-riscv</guid>
            <link>https://www.oschina.net/news/265608/bunnie-restrictions-riscv</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
