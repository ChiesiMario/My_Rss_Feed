<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 28 Nov 2023 19:47:45 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Furion 文档收费？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今天访问 Furion 官网发现它的文档居然要付费才能看：</p><p><img height="1392" src="https://static.oschina.net/uploads/space/2023/1128/173151_D1kJ_2720166.png" width="2338" referrerpolicy="no-referrer"></p><p>http://furion.baiqian.ltd/docs/saas</p><p>而且还搞了个 499 的 VIP 技术支持服务……</p><p><img height="1858" src="https://static.oschina.net/uploads/space/2023/1128/173121_ZrVP_2720166.png" width="3360" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 09:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268540</guid>
            <link>https://www.oschina.net/news/268540</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenUK：扶持开源将有效遏制人才流向美国]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">英国开源非营利组织 OpenUK&nbsp;最新发布了 「</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenuk.uk%2Fstate-of-open-the-uk-in-2023-phase-three-skills-or-bust%2F" target="_blank">State of Open: The UK in 2023: Phase 3 Skills or Bust</a><span style="background-color:#ffffff">」 报告，此部分内容主要聚焦于英国开源软件的贡献者和维护者。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「开源软件是数字经济的潜水艇。无论是互联网、云计算、人工智能、ML 还是区块链，它都是我们所有技术生态系统的基础。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff"><img alt="" height="420" src="https://oscimg.oschina.net/oscnet/up-a2e7775cd5fe8e3981df48a726e8410b676.jpg" width="300" referrerpolicy="no-referrer"></span></span></p><p><span style="color:#000000">Skills or Bust 重点分析了英国开源社区的数据，发现英国共有 320 万个 GitHub 帐户（占英国人口的 4.5%）和 31800 个开源项目贡献者。过去 12 个月里，开源项目的贡献者达 8200 人；开源项目新增了 1700 名贡献者，实现了 20.7% 的增长。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">报告作者明确指出，英国政府有机会支持开源人才，并在英国建立一个更强大的技术部门。远程工作是开源技术的一种常态，这意味着许多国际公司是根据技能而非地理位置来招聘人才的。随着英国各地互联互通的改善，无论是在城市还是农村地区，这都为掌握紧缺技能的人才提供了就业机会。这只会推动英国科技经济的增长，并确保其未来成为"下一个硅谷"。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">报告还揭示了 OpenUK 对英国技术和开源技能需求的调查见解：</span></p><ul><li><span style="color:#000000"><strong>77% </strong>的英国公司正在寻求编程技能</span></li><li><span style="color:#000000"><strong>后端开发人员是最受欢迎的职位</strong>（招聘比例为 51%），其次是云工程师（36%）和开发运维工程师（32%）</span></li><li><span style="color:#000000"><strong>后端开发人员仍然是未来招聘的重点</strong>（28%），另外还有云工程师（23%）和开发运维工程师（16%）</span></li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><img alt="" height="500" src="https://oscimg.oschina.net/oscnet/up-7eec672f4d5ab2c1eec10c4fc10e98ebe5c.jpg" width="500" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">以及确定了支持英国科技行业增长至关重要的三个关键政策领域：</span></p><ul><li><span style="color:#000000"><strong>填补英国人才库商业技能的空白&nbsp;</strong>—— 因收购而留下的空白，目前英国缺乏将其创新商业化所需的商业技能。</span></li><li><span style="color:#000000"><strong>留住经常逃往美国的人才&nbsp;</strong>—— 通过支持这些技能在英国的发展来阻止移民，并鼓励技术工人移民。</span></li><li><span style="color:#000000"><strong>培训人员掌握正确的工程和开发技能&nbsp;</strong>—— 英国目前还没有，而且团队缺乏实践经验。</span></li></ul><p><span style="color:#000000">OpenUK 首席执行官 Amanda Brock 称，这十年以来，开源软件的重要性一直被英国政府所忽视。而为此做出贡献的开源工作者，是全球科技行业中受人尊敬和有影响力的一部分。</span></p><p><span style="color:#000000">「他们中的许多人都是 homeworkers，掌握着紧缺的技能，在这艘'全球潜艇'上工作并成长为领导者，将湾区的薪资带入英国。现在是时候让潜艇浮出水面了......」</span></p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenuk.uk%2Fstateofopen" target="_blank"><span style="color:#2980b9">查看完整报告</span></a></strong></p><hr><p><strong><span style="color:#000000">相关阅读</span></strong></p><ul><li><a href="https://www.oschina.net/news/249841/openuk-report-benefits-of-open-source" target="_blank">英国科技总增值 27% 来自开源，价值达 135.9 亿英镑</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 08:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268523/state-of-open-the-uk-in-2023</guid>
            <link>https://www.oschina.net/news/268523/state-of-open-the-uk-in-2023</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大语言模型的前世今生]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自华为云社区《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F416109%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">大语言模型的前世今生</a>》，作者： 码上开花_Lancer 。</p><p><strong>大规模语言模型（Large Language Models，LLM）</strong>，也称大规模语言模型或大型语言模型，是一种由包含数百亿以上参数的深度神经网络构建的语言模型，使用自监督学习方法通过大量无标注文本进行训练。自 2018 年以来，Google、OpenAI、Meta、百度、华为等公司和研究机构都相继发布了包括 BERT，GPT 等在内多种模型，并在几乎所有自然语言处理任务中都表现出色。2019 年大模型呈现爆发式的增长，特别是 2022 年 11 月 ChatGPT（Chat Generative Pre-trained Transformer）发布后，更是引起了全世界的广泛关注。用户可以使用自然语言与系统交互，从而实现包括问答、分类、摘要、翻译、聊天等从理解到生成的各种任务。大型语言模型展现出了强大的对世界知识掌握和对语言的理解。</p><span id="OSC_h1_1"></span><h1>一、大规模语言模型基本概念</h1><p>语言是人类与其他动物最重要的区别，而人类的多种智能也与此密切相关。逻辑思维以语言的形式表达，大量的知识也以文字的形式记录和传播。如今，互联网上已经拥有数万亿以上的网页资源，其中大部分信息都是以自然语言描述。因此，如果人工智能算法想要获取知识，就必须懂得如何理解人类使用的不太精确、可能有歧义、混乱的语言。语言模型（Language Model，LM）目标就是建模自然语言的概率分布。词汇表 V 上的语言模型，由函数 P(w1w2...wm) 表示，可以形式化地构建为词序列 w1w2...wm 的概率分布，表示词序列 w1w2...wm 作为一个句子出现的可能性大小。由于联合概率 P(w1w2...wm) 的参数量十分巨大，直接计算 P(w1w2...wm) 非常困难。按照《现代汉语词典（第七版）》包含 7 万单词，句子长度按照 20 个词计算，模型参数量达到 7.9792×1096 的天文数字。中文的书面语中超过 100 个单词的句子也并不罕见，如果要将所有可能都纳入考虑，模型的复杂度还会进一步急剧增加，无法进行存储和计算。为了减少 P(w1w2...wm) 模型的参数空间，可以利用句子序列通常情况下从左至右的生成过程进行分解，使用链式法则得到：</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700874836405431196.png" referrerpolicy="no-referrer"></p><p>由此，w1w2...wm 的生成过程可以看作单词逐个生成的过程。首先生成 w1，之后根据 w1 生成 w2，再根据 w1 和 w2 生成 w3，以此类推，根据前 m− 1 个单词生成最后一个单词 wm。例如：对于句子「把努力变成一种习惯」的概率计算，使用上述公式可以转化为：</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700874878791508245.png" referrerpolicy="no-referrer"></p><p>通过上述过程将联合概率 P(w1w2...wm) 转换为了多个条件概率的乘积。但是，仅通过上述过程模型的参数空间依然没有下降，P(wm|w1w2...wm.1) 的参数空间依然是天文数字。为了解决上述问题，可以进一步假设任意单词 wi 出现的概率只与过去 n − 1 个词相关，即：</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700874915077390823.png" referrerpolicy="no-referrer"></p><p>满足上述条件的模型被称为 n 元语法或 n 元文法 (n-gram) 模型。其中 n-gram 表示由 n 个连续单词构成的单元，也被称为 n 元语法单元。尽管 n 元语言模型能缓解句子概率为 0 的问题，但语言是由人和时代创造的，具备无穷的可<br> 能性，再庞大的训练语料也无法覆盖所有的 n-gram，而训练语料中的零频率并不代表零概率。因此，需要使用平滑技术（Smoothing）来解决这一问题，对所有可能出现的字符串都分配一个非零的概率值，从而避免零概率问题。平滑是指为了产生更合理的概率，对最大似然估计进行调整的一类方法，也称为数据平滑（Data Smoothing）。平滑处理的基本思想是提高低概率，降低高概率，使整体的概率分布趋于均匀。这类方法通常称为统计语言模型（Statistical Language models，SLM）。n 语法模型整体上来看与训练语料规模和模型的阶数有较大的关系，不同的平滑算法在不同情况下的表现有较大的差距。平滑算法虽然较好的解决了零概率问题，但是基于稀疏表示的 n 元语言模型仍然有三个较为明显的缺点：（1）无法建模长度超过 n 的上下文；（2）依赖人工设计规则的平滑技术；（3）当 n 增大时，数据的稀疏性随之增大，模型的参数量更是指数级增加，并且模型受到数据稀疏问题的影响，其参数难以被准确的学习。此外，n 语法中单词的离散表示也忽略了词之间的相似性。</p><p>因此，基于分布式表示和神经网络的语言模型逐渐成为了研究热点。Bengio 等人在 2000 年提出了使用前馈神经网络对 P(wi|wi−n+1...wi−1) 进行估计的语言模型。词的独热编码被映射为一个低维稠密的实数向量，称为词向量（Word Embedding）。此后，循环神经网络、卷积神经网络、端到端记忆网络等神经网络方法都成功应用于语言模型建模。相较于 n 元语言模型，神经网络方法可以在一定程度上避免数据稀疏问题，有些模型还可以避免对历史长度的限制，从而更好的建模长距离依赖关系。这类方法通常称为神经语言模型（Neural Language Models，NLM）。深度神经网络需要采用有监督方法，使用标注数据进行训练，因此，语言模型的训练过程也不可避免需要构造训练语料。但是由于训练目标可以通过无标注文本直接获得，从而使得模型的训练仅需要大规模无标注文本即可语言模型也成为了典型的自监督学习（Self-supervised Learning）任务。互联网的发展，使得大规模文本非常容易获取，因此训练超大规模的基于神经网络的语言模型也成为了可能。受到计算机视觉领域采用 ImageNet 对模型进行一次预训练，使得模型可以通过海量图像充分学习如何提取特征，然后再根据任务目标进行模型精调的范式影响，自然语言处理领域基于预训练语言模型的方法也逐渐成为主流。以 ELMo 为代表的动态词向量模型开启了语言模型预训练的大门，此后以 GPT 和 BERT 为代表的基于 Transformer 模型的大规模预训练语言模型的出现，使得自然语言处理全面进入了预训练微调范式新时代。将预训练模型应用于下游任务时，不需要了解太多的任务细节，不需要设计特定的神经网络结构，只需要「微调」预训练模型，即使用具体任务的标注数据在预训练语言模型上进行监督训练，就可以取得显著的性能提升。这类方法通常称为预训练语言模型（Pre-trained Language Models，PLM）。2020 年 Open AI 发布了包含 1750 亿参数的生成式大规模预训练语言模型 GPT-3（GenerativePre-trained Transformer 3）。开启了大规模语言模型的时代。由于大规模语言模型的参数量巨大，如果在不同任务上都进行微调需要消耗大量的计算资源，因此预训练微调范式不再适用于大规模语言模型。但是研究人员发现，通过语境学习（Incontext Learning，ICL）等方法，直接使用大规模语言模型就可以在很多任务的少样本场景下取得了很好的效果。此后，研究人员们提出了面向大规模语言模型的提示词（Prompt）学习方法、模型即服务范式（Model as a Service，MaaS）、指令微调（Instruction Tuning）等方法，在不同任务上都取得了很好的效果。与此同时，Google、Meta、百度、华为等公司和研究机构都纷纷发布了包括 PaLM、LaMDA、T0 等为代表的不同大型语言模型。</p><p>2022 年底 ChatGPT 的出现，将大规模语言模型的能力进行了充分的展现，也引发了大规模语言模型研究的热潮。Kaplan 等人在文献中提出了缩放法则（Scaling Laws），指出模型的性能依赖于模型的规模，包括：参数数量、数据集大小和计算量，模型的效果会随着三者的指数增加而线性提高。如图 1.1 所示，模型的损失（Loss）值随着模型规模的指数增大而线性降低。这意味着模型的能力是可以根据这三个变量估计的，提高模型参数量，扩大数据集规模都可以使得模型的性能可预测地提高。这为继续提升大模型的规模给出了定量分析依据。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231125/1700875112804923222.png" referrerpolicy="no-referrer"></p><p>图 1.1 大规模语言模型的缩放法则（Scaling Laws）</p><span id="OSC_h1_2"></span><h1>二、大规模语言模型发展历程</h1><p>大规模语言模型的发展历程虽然只有短短不到五年的时间，但是发展速度相当惊人，截止 2023 年 6 月，国内外有超过百种大模型相继发布。中国人民大学赵鑫教授团队在文献按照时间线给出 2019 年至 2023 年 5 月比较有影响力并且模型参数量超过 100 亿的大规模语言模型，如图 2.1 所示。大规模语言模型的发展可以粗略的分为如下三个阶段：基础模型、能力探索、突破发展。</p><p><strong>基础模型阶段</strong>主要集中于 2018 年至 2021 年，2017 年 Vaswani 等人提出了 Transformer[ 架构，在机器翻译任务上取得了突破性进展。2018 年 Google 和 Open AI 分别提出了 BERT[1] 和 GPT-1 模型，开启了预训练语言模型时代。BERT-Base 版本参数量为 1.1 亿，BERT-Large 的参数量为 3.4 亿，GPT-1 的参数量 1.17 亿。这在当时，相比其它深度神经网络的参数量已经是有数量级上提升。2019 年 Open AI 又发布了 GPT-2，其参数量达到了 15 亿。此后，Google 也发布了参数规模为 110 亿的 T5 模型。2020 年 Open AI 进一步将语言模型参数量扩展到 1750 亿，发布了 GPT-3。此后，国内也相继推出了一系列的大规模语言模型，包括清华大学<a href="https://www.oschina.net/action/visit/ad?id=1191">ERNIE</a>(THU)、百度<a href="https://www.oschina.net/action/visit/ad?id=1191">ERNIE</a>(Baidu)、华为盘古-α 等。这个阶段研究主要集中语言模型本身，包括仅编码器（Encoder Only）、编码器-解码器（Encoder-Decoder）、仅解码器（Decoder Only）等各种类型的模型结构都有相应的研究。模型大小与 BERT 相类似的算法，通常采用预训练微调范式，针对不同下游任务进行微调。但是模型参数量在 10 亿以上时，由于微调的计算量很高，这类模型的影响力在当时相较 BERT 类模型有不小的差距。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819499486261627.png" referrerpolicy="no-referrer"></p><p>图 2.1 大规模语言模型发展时间线</p><p><strong>能力探索阶段</strong>集中于 2019 年至 2022 年，由于大规模语言模型很难针对特定任务进行微调，研究人员们开始探索在不针对单一任务进行微调的情况下如何能够发挥大规模语言模型的能力。2019 年 Radford 等人，就使用 GPT-2 模型研究了大规模语言模型在零样本情况下的任务处理能力。在此基础上，Brown 等人在 GPT-3 模型上研究了通过语境学习（In-Context Learning）进行少样本学习的方法。将不同任务的少量有标注的实例拼接到待分析的样本之前输入语言模型，用语言模型根据实例理解任务并给出正确结果。在包括 TriviaQA、WebQS、CoQA 等评测集合都展示出了非常强的能力，在有些任务中甚至超过了此前的有监督方法。上述方法不需要修改语言模型的参数，模型在处理不同任务时无需花费的大量计算资源进行模型微调。但是仅依赖基于语言模型本身，其性能在很多任务上仍然很难达到有监督学习效果，因此研究人员们提出了指令微调（Instruction Tuning）方案，将大量各类型任务，统一为生成式自然语言理解框架，并构造训练语料进行微调。</p><p><strong>突破发展阶段</strong>以 2022 年 11 月 ChatGPT 的发布为起点。ChatGPT 通过一个简单的对话框，利用一个大规模语言模型就可以实现问题回答、文稿撰写、代码生成、数学解题等过去自然语言处理系统需要大量小模型订制开发才能分别实现的能力。它在开放领域问答、各类自然语言生成式任务以及对话上文理解上所展现出来的能力远超大多数人的想象。2023 年 3 月 GPT-4 发布，相较于 ChatGPT 又有了非常明显的进步，并具备了多模态理解能力。GPT-4 在多种基准考试测试上的得分高于 88% 的应试者，包括美国律师资格考试（Uniform Bar Exam）、法学院入学考试（Law School Admission Test）、学术能力评估（Scholastic Assessment Test，SAT）等。它展现了近乎「通用人工智能（AGI）」的能力。各大公司和研究机构也相继发布了此类系统，包括 Google 推出的 Bard、百度的文心一言、科大讯飞的星火大模型、智谱 ChatGLM、复旦大学 MOSS 等。表 1.1 给出了截止 2023 年 6 月典型开源和未开源大规模语言模型的基本情况。可以看到从 2022 年开始大模型呈现爆发式的增长，各大公司和研究机构都在发布各种不同类型的大模型。</p><span id="OSC_h1_3"></span><h1>三、 大规模语言模型构建流程</h1><p>根据 OpenAI 联合创始人 Andrej Karpathy 在微软 Build 2023 大会上所公开的信息，OpenAI 所使用的大规模语言模型构建流程如图 2.2 所示。主要包含四个阶段：预训练、有监督微调、奖励建模、强化学习。这四个阶段都需要不同规模数据集合、不同类型的算法，产出不同类型的模型，所需要的资源也有非常大的差别。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819526965391967.png" referrerpolicy="no-referrer"></p><p>图 2.2 OpenAI 使用的大规模语言模型构建流程</p><p><strong>预训练</strong><strong>（</strong><strong>Pretraining</strong><strong>）阶段</strong>需要利用海量的训练数据，包括互联网网页、维基百科、书籍、GitHub、论文、问答网站等，构建包含数千亿甚至数万亿单词的具有多样性的内容。利用由数千块高性能 GPU 和高速网络组成超级计算机，花费数十天完成深度神经网络参数训练，构建基础语言模型（Base Model）。基础大模型构建了长文本的建模能力，使得模型具有语言生成能力，根据输入的提示词（Prompt），模型可以生成文本补全句子。也有部分研究人员认为，语言模型建模过程中也隐含的构建了包括事实性知识（Factual Knowledge）和常识知识（Commonsense）在内的世界知识（World Knowledge）。根据他们的文献介绍，GPT-3 完成一次训练的总计算量是 3640PFlops，按照 NVIDIA A100 80G 和平均利用率达到 50% 计算，需要花费近一个月时间使用 1000 块 GPU 完成。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819546103132882.png" referrerpolicy="no-referrer"></p><p>表 1.1 典型开源大规模语言模型汇总</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819565269758033.png" referrerpolicy="no-referrer"></p><p>表 1.2 典型闭源大规模语言模型汇总</p><p><strong>有监督微调</strong>（Supervised Finetuning），也称为指令微调（Instruction Tuning），利用少量高质量数据集合，包含用户输入的提示词（Prompt）和对应的理想输出结果。用户输入包括问题、闲聊对话、任务指令等多种形式和任务。</p><p><strong>例如</strong>：提示词（Prompt）：复旦大学有几个校区？</p><p>理想输出：复旦大学现有 4 个校区，分别是邯郸校区、新江湾校区、枫林校区和张江校区。其中邯郸校区是复旦大学的主校区，邯郸校区与新江湾校区都位于杨浦区，枫林校区位于徐汇区，张江校区位于浦东新区。</p><p>利用这些有监督数据，使用与预训练阶段相同的语言模型训练算法，在基础语言模型基础上再进行训练，从而得到有监督微调模型（SFT 模型）。经过训练的 SFT 模型具备了初步的指令理解能力和上下文理解能力，能够完成开放领域问题、阅读理解、翻译、生成代码等能力，也具备了一定的对未知任务的泛化能力。由于有监督微调阶段的所需的训练语料数量较少，SFT 模型的训练过程并不需要消耗非常大量的计算。根据模型的大小和训练数据量，通常需要数十块 GPU，花费数天时间完成训练。SFT 模型具备了初步的任务完成能力，可以开放给用户使用，很多类 ChatGPT 的模型都属于该类型，包括：Alpaca、Vicuna、MOSS、ChatGLM-6B 等。很多这类模型效果也非常好，甚至在一些评测中达到了 ChatGPT 的 90% 的效果。当前的一些研究表明有监督微调阶段数据选择对 SFT 模型效果有非常大的影响，因此如何构造少量并且高质量的训练数据是本阶段有监督微调阶段的研究重点。</p><p>目标是构建一个文本质量对比模型，对于同一个提示词，SFT 模型给出的多个不同输出结果的质量进行排序。奖励模型（RM 模型）可以通过二分类模型，对输入的两个结果之间的优劣进行判断。RM 模型与基础语言模型和 SFT 模型不同，RM 模型本身并不能单独提供给用户使用。奖励模型的训练通常和 SFT 模型一样，使用数十块 GPU，通过几天时间完成训练。由于 RM 模型的准确率对于强化学习阶段的效果有着至关重要的影响，因此对于该模型的训练通常需要大规模的训练数据。Andrej Karpathy 在报告中指出，该部分需要百万量级的对比数据标注，而且其中很多标注需要花费非常长的时间才能完成。图 2.3 给出了 InstructGPT 系统中奖励模型训练样本标注示例。可以看到，示例中文本表达都较为流畅，标注其质量排序需要制定非常详细的规范，标注人员也需要非常认真的对标规范内容进行标注，需要消耗大量的人力，同时如何保持众包标注人员之间的一致性，也是奖励建模阶段需要解决的难点问题之一。此外奖励模型的泛化能力边界也在本阶段需要重点研究的另一个问题。如果 RM 模型的目标是针对所有提示词系统所生成输出都能够高质量的进行判断，该问题所面临的难度在某种程度上与文本生成等价，因此如何限定 RM 模型应用的泛化边界也是本阶段难点问题。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/20231124/1700819609846149973.png" referrerpolicy="no-referrer"></p><p>图 2.3 InstructGPT 系统中奖励模型训练样本标注示例</p><p><strong>强化学习</strong><strong>（</strong><strong>Reinforcement Learning</strong><strong>）阶段</strong>根据数十万用户给出的提示词，利用在前一阶段训练的 RM 模型，给出 SFT 模型对用户提示词补全结果的质量评估，并与语言模型建模目标综合得到更好的效果。该阶段所使用的提示词数量与有监督微调阶段类似，数量在十万量级，并且不需要人工提前给出该提示词所对应的理想回复。使用强化学习，在 SFT 模型基础上调整参数，使得最终生成的文本可以获得更高的奖励（Reward）。该阶段所需要的计算量相较预训练阶段也少很多，通常也仅需要数十块 GPU，经过数天时间的即可完成训练。文献[给出了强化学习和有监督微调的对比，在模型参数量相同的情况下，强化学习可以得到相较于有监督微调好得多的效果。关于为什么强化学习相比有监督微调可以得到更好结果的问题，截止到 2023 年 9 月也还没有完整和得到普遍共识的解释。此外，Andrej Karpathy 也指出强化学习也并不是没有问题的，它会使得基础模型的熵降低，从而减少了模型输出的多样性。在经过强化学习方法训练完成后的 RL 模型，就是最终提供给用户使用具有理解用户指令和上下文的类 ChatGPT 系统。由于强化学习方法稳定性不高，并且超参数众多，使得模型收敛难度大，再叠加 RM 模型的准确率问题，使得在大规模语言模型如何能够有效应用强化学习非常困难。</p><p>大语言模型研究进展之快，让在自然语言处理领域开展了近三十年工作的我们也难以适从。其研究之火爆程度令人咋舌，自然语言处理领域重要国际会议 EMNLP，2022 年语言模型相关论文投稿占比只有不到 5%。然而，2023 年语言模型相关投稿则超过了 EMNLP 整体投稿的 20%。如何能够兼顾大语言模型的基础理论，又能够在快速发展的各种研究中选择最具有代表性的工作介绍给大家，是写作中面临的最大挑战之一，受限于我们的认知水平和所从事的研究工作的局限，对其中一些任务和工作的细节理解可能存在不少错误，也恳请专家、读者批评指正！</p><p>&nbsp;</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>点击关注，第一时间了解华为云新鲜技术~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 05:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10278002</guid>
            <link>https://my.oschina.net/u/4526289/blog/10278002</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[滴滴昨晚系统服务故障，技术团队连夜修复]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 28 日凌晨，「滴滴崩了」相关话题登上微博热搜，多个用户表示滴滴 App 无法正常使用。对此滴滴紧急回应称「由于系统故障，今天晚间滴滴 App 服务出现异常，经技术同学紧急修复，目前正陆续恢复中。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-795f1525cfa56ab2e93c3007ac4f10118a3.png" referrerpolicy="no-referrer"></p><p>从用户反馈看，11 月 27 日晚间 10 点多起，陆续有用户反馈无法使用滴滴旗下相关 App，滴滴抢修超过了 9 小时。</p><p>对此，在 11 月 28 日早间，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2838754010%2FNuBQfuzij" target="_blank">滴滴发布微博更新了恢复情况</a></u>，滴滴称「经技术团队连夜修复，滴滴网约车等服务已恢复，用户可下载滴滴 App 使用打车服务。骑车等服务还在陆续修复中，所有可开锁或未关锁的青桔车辆均可免费骑行，希望能为缓解早高峰压力努力多做一点点。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e973f0017d2a44b92e63ec57b2224d9ef6.png" referrerpolicy="no-referrer"></p><p>虽然滴滴表示网约车服务已恢复，但是不少用户早间在微博反馈仍然无法打车，只能选择其他平台出行。</p><p>从司机反馈看，此次滴滴平台在接单、定位、计费等环节上都出现了问题。有网约车司机表示，昨晚 App 崩溃时刚好在接单，「从晚上 10 点 20 分开始什么都做不了，客服电话也进不了线。目前恢复了少部分功能，但不能正常使用，很多错单乱单，还出现了多位司机接同一单的现象。」</p><p>有业内人士表示，出问题的应该是滴滴自己的 IDC，这种事故也会加速滴滴全部上云的步伐。从过往情况看，滴滴崩溃多是因为机房网络故障等原因，不过故障当天都能修好，本次故障维修时长或是滴滴历次故障之最。</p><p>目前滴滴由滴滴云提供服务。滴滴云官网显示，滴滴出行的云计算服务基于滴滴出行的业务技术和经验积累，采用领先的云计算架构、高规格服务器集群搭建、高性能资源配置机制、精细化运营模式，致力于为开发者提供简单快捷、高效稳定、高性价比、安全可靠的 IT 基础设施云服务。</p><p>在今年 2 月，滴滴云发布公告，由于产品线调整，滴滴云在 2023 年 3 月 31 日起将不再对外提供公有云服务。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 04:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268480</guid>
            <link>https://www.oschina.net/news/268480</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龙芯宣布兼容 IE 的龙芯浏览器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start">在今日上午举办的 2023 龙芯产品发布暨用户大会上，龙芯中科介绍了龙芯平台当前的生态发展，称其已可运行绝大多数 X86 / Linux 应用，并争取 1-2 年后流畅运行绝大多数 X86 / Windows 应用。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a41459afcde42a92f9ad416d6fca4d8f732.png" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px; text-align:start">龙芯平台已支持多个国产操作系统和基础应用，后续将通过二进制翻译运行 X86 应用，兼容 Windows 和安卓应用。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-86b36d9e89683e59c00caa945cf2aab9fef.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9c91a07b40ce827b5d10883b6fe1138abc2.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-55e8d68de37d96583e2acb6ba8d53dba16b.png" referrerpolicy="no-referrer"></p><p>大会上，龙芯中科宣布了与 IE 浏览器兼容的<strong>「龙芯浏览器」</strong>。从官方公开的 PPT 可以看到，龙芯浏览器之所以在 2023 年还兼容 IE，是因为我国信息系统主要基于 IE 构建。</p><p style="margin-left:0px; margin-right:0px; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-b7fb745bc3039ea3eb00357a2cc36dd5d5d.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 04:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268477</guid>
            <link>https://www.oschina.net/news/268477</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Reddit 再次试水 IPO]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">彭博社</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-27%2Freddit-leads-class-of-2024-us-ipo-candidates-testing-the-water%3Fsref%3Dgni836kR" target="_blank"><span style="color:#2980b9">报道</span></a><span style="color:#000000">称，Reddit「正在与潜在投资者就首次公开募股进行谈判。」&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Reddit 总部位于旧金山，由&nbsp;Steve Huffman&nbsp;、Aaron Swartz 和 Alexis Ohanian 于 2005 年联合创立。消息人士透露，该公司正在考虑最早在明年第一季度上市。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><img height="331" src="https://oscimg.oschina.net/oscnet/up-2b1b4904c5ce1731bc1a4743a3619d6d07d.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">2021 年 12 月，Reddit 秘密向美国证券交易委员会提交了一份上市注册声明草案，但相关计划并未成功实现。此举发生在 Reddit 获得由富达（Fidelity）领投的 4.1 亿美元巨额融资、估值达到 100 亿美元的几个月之后。当时，Reddit 计划以 7 亿美元完成 F 轮融资。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">然后，在 2022 年 1 月，Reddit 甚至邀请摩根士丹利和高盛参与上市工作。当时，该公司考虑的估值高达 150 亿美元。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">目前尚不清楚如果该公司真的上市，明年的估值将会达到多少。Reddit 发言人向外媒 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F11%2F27%2Freddit-might-once-again-be-flirting-with-an-ipo%2F" target="_blank">TechCrunch</a> 表示，该公司正处于静默期，无法发表评论。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268471/reddit-might-once-again-flirting-ipo</guid>
            <link>https://www.oschina.net/news/268471/reddit-might-once-again-flirting-ipo</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[周热点 | 微软开源 Terminal Chat；Fish Shell 采用 Rust 重写会导致性能下降；程序员篡改 ETC 余额......]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2023.11.20-2023.11.27]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094007&#38;idx=1&#38;sn=c31a714cf204a2b39bc6c24fc06671d9&#38;chksm=880c4c64bf7bc57274d01421a2877a746fb9f7fbeaaada17eb65b684a5f45c287aa67387684a&#38;token=958250931&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094007&#38;idx=1&#38;sn=c31a714cf204a2b39bc6c24fc06671d9&#38;chksm=880c4c64bf7bc57274d01421a2877a746fb9f7fbeaaada17eb65b684a5f45c287aa67387684a&#38;token=958250931&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[龙芯 3A6000 桌面处理器正式发布，国产之光！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日上午举办的&nbsp;2023 龙芯产品发布暨用户大会上，龙芯 3A6000 国产桌面通用处理器正式发布。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e6662d2058f428348499738edb731d2f88.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2bf0856cd3fa1f2a6bae9ce059cc87ace7f.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-064f9db667224d22c42556b43acac5bafe7.png" referrerpolicy="no-referrer"></p><blockquote><p>此处引用一下<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWgrMt3RO7w0a1kNyydptog" target="_blank">央视新闻的报道原文</a></u></em>：<br><br><strong>龙芯 3A6000 采用我国自主设计的指令系统和架构，无需依赖任何国外授权技术，是我国自主研发、自主可控的新一代通用处理器，可运行多种类的跨平台应用，满足各类大型复杂桌面应用场景。</strong></p><p><strong>它的推出，标志着我国自主研发的 CPU 在自主可控程度和产品性能方面达到新高度，性能达到国际主流产品水平。</strong></p></blockquote><p>据介绍，<strong>龙芯 3A6000 </strong>拥有四个物理核 / 八个逻辑核，主频 2.0-2.5GHz，<strong>采用第四代 64 位微架构 LA664，实现 SMT2 技术</strong>，支持双通道 DDR4-3200 内存，片内集成安全可信模块，支持安全启动和国密算法（SM2、SM3、SM4）等。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f13f4b4df7a318d97e95b08500fbdf966c5.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b28daeabb9b929cefa3541d62533899f8cd.png" referrerpolicy="no-referrer"></p><p>龙芯 3A6000 突破了同时多线程 (SMT, Simultaneous Multi-Threading) 技术，支持 CPU 核心在同一时刻运行多个线程，<strong>相比上一代龙芯 3A5000 的单线程性能提升 60%，多线程性能提升 100%</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-59bdeef2ea7f1bf45930f2862938198ffc6.png" referrerpolicy="no-referrer"></p><p>根据龙芯官方实测，<strong>2.5GHz 龙芯 3A6000 性能可达英特尔 10 代酷睿 3.6GHz&nbsp;i3-10100 的水平</strong>，下一步争取使用成熟工艺达到英特尔、AMD 先进工艺 CPU 的性能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f0c409ce43a2e7c78d093de804acbc7ce2f.png" referrerpolicy="no-referrer"></p><p>此外，<strong>龙芯后续将推 3B6000、3B7000 等桌面端产品</strong>，而在服务端已完成龙芯 3C6000 设计，笔记本端已完成 2K3000 前端设计。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-202643b33452a1f49b4f60821a77e9010eb.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e19da8aac185fc7beffd93031306d623c92.png" referrerpolicy="no-referrer"></p><hr><p>华硕电脑开放平台中国区总经理俞元麟昨晚在其 B 站账号（@普普通通 Tony 大叔）更新的视频介绍了龙芯 3A6000 CPU 的性能表现：：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV15u4y1A7aK%2F">《国产最强！龙芯中科 3A6000 台式机 CPU 性能测试》</a></em></u>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2f786c32b8e5bec71a427021176790a2fdb.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268459/loongson-3a6000</guid>
            <link>https://www.oschina.net/news/268459/loongson-3a6000</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mitosis —— 前端编译时框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Mitosis 是一个编译时框架，可以让开发者使用 JSX 编写组件，并将其编译为原生 JavaScript、Angular、React、Vue 等多种框架的代码。</p><p>Mitosis 使用了受 Solid 启发的静态 JSX 子集，可以将其解析为简单的 JSON 结构，然后轻松构建针对不同框架和实现的序列化器。</p><p>与其他编译时框架相比，Mitosis 类似于 Svelte 和 SolidJS，它们都是编译时框架，非常快速。但与它们的不同之处在于，Mitosis 允许你生成多个框架的代码，从而提供了最大的灵活性。</p><p>与 SolidJS 类似，Mitosis 使用一种将组件编译为 JSON 的 JSX 版本。插件可以将组件编译为不同的目标，使你可以创建双向工具：</p><ol><li>可以转换为 Mitosis JSON 的代码</li><li>将 JSON 编译或序列化为目标框架的插件</li></ol><p>Mitosis 得到了 <a href="http://builder.io/">Builder.io</a> 的支持，因为 Mitosis 还支持无代码工具。通过将其序列化为 <a href="http://builder.io/">Builder.io</a> 的 JSON 格式，Mitosis 可以与无代码工具无缝集成。</p></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/mitosis</guid>
            <link>https://www.oschina.net/p/mitosis</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 数据同步中间件 MyDataHarbor]]>
            </title>
            <description>
                <![CDATA[<p align="center"><br><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.mydataharbor.com" target="_blank"><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/mydataharbor.png" alt="logo" referrerpolicy="no-referrer"></a></p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fmydataharbor.com"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Factions%2Fworkflows%2Fmaven.yml" target="_blank"><img src="https://img.shields.io/github/actions/workflow/status/mydataharbor/mydataharbor/maven.yml?branch=main" alt="GitHub-CI" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Freleases" target="_blank"><img src="https://img.shields.io/github/v/release/mydataharbor/mydataharbor" alt="查看发行的版本" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fsearch.maven.org%2Fsearch%3Fq%3Dcom.mydataharbor" target="_blank"><img src="https://img.shields.io/maven-central/v/com.mydataharbor/mydataharbor" alt="maven 仓库" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Freleases" target="_blank"><img src="https://img.shields.io/github/downloads/mydataharbor/mydataharbor/total" alt="下载数量" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Fblob%2Fmain%2FLICENSE" target="_blank"><img src="https://img.shields.io/github/license/mydataharbor/mydataharbor" alt="开源协议" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fmydataharbor.yuque.com%2Fbooks%2Fshare%2Fd5b1360e-d316-4be0-85de-b0958ac64267%2Fpckin3" target="_blank"><img src="https://img.shields.io/badge/plugins-%E6%B8%85%E5%8D%95-blue" alt="插件列表" referrerpolicy="no-referrer"></a></p><p>欢迎前端、插件开发人员前来贡献代码，感兴趣的请联系我：<a href="mailto:1053618636@qq.com">1053618636@qq.com</a></p><h2><a id="user-content-简介定位" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E7%AE%80%E4%BB%8B%E5%AE%9A%E4%BD%8D"></a>简介/定位</h2><p><img class="emoji" alt=":cn:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/cn-8adc9b40bd67529ae9a9135ebbc60809.png" width="14" height="14" referrerpolicy="no-referrer"> 🚢 MyDataHarbor 是一个致力于解决异构数据源之间的分布式、高扩展性、高性能、微事务（至少一次保证）、准实时的数据同步中间件。</p><p>它可以帮助用户可靠、快速、稳定的对海量数据进行准实时增量同步或者定时全量同步，主要定位是为实时交易系统服务，亦可用于大数据的数据同步（ETL 领域）。</p><h2><a id="user-content-背景" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%83%8C%E6%99%AF"></a>背景</h2><p>在微服务的大背景下，实时交易系统的数据的分散存储已经成为常态，然而有时候我们需要对这些数据进行实时或者定时全量的同步到另外一个地方。</p><p>比如，一个公司的 C 部门的系统，需要用到 A、B 部门产生的数据，这时候避免不了进行全量或者增量的数据同步。再比如，数据库中的数据我要实时同步到 elasticsearch、redis 等等中进行搜索。</p><p>数据同步的应用场景在日常的分布式系统开发中非常常见，而且非常重要，一旦数据同步出现问题，将会导致数据不一致，引起其他严重的异常。</p><p>目前小公司的做法是在业务程序系统里修改代码，往目标数据源中写入数据，上点规模的公司的做法是，各个部门开发一套自己的同步小程序，没有管理，更可能没有监控，来一个需求开发一个、非常浪费资源，稳定性也得不到保障，而大公司则是有一套数据迁移平台（如阿里的精衞）。</p><p>MyDataHarbor 在这种场景需求下应用而生！</p><h2><a id="user-content-特性" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E7%89%B9%E6%80%A7"></a>特性</h2><h3><a id="user-content-分布式设计" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%BE%E8%AE%A1"></a>🚩分布式设计</h3><p>MyDataHarbor 是一个在 zookeeper 上构建的分布式中间件，支持水平扩展，对节点进行分组，各分组下的机器形成一个子集群，任务在子集群隔离范围内进行负载均衡，防止单点故障。</p><h3><a id="user-content-插件式设计" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%8F%92%E4%BB%B6%E5%BC%8F%E8%AE%BE%E8%AE%A1"></a>🚩插件式设计</h3><p>高度合理的抽象、插件化的设计使得 MyDataHarbor 拥有很高扩展性，任何数据迁移的需求都可以通过开发插件完成。</p><h3><a id="user-content-事务支持" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E4%BA%8B%E5%8A%A1%E6%94%AF%E6%8C%81"></a>🚩事务支持</h3><p>MyDataHarbor 设计之初就考虑到数据丢失问题，引入事务的支持保障数据不丢失！</p><h3><a id="user-content-插件自描述" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%8F%92%E4%BB%B6%E8%87%AA%E6%8F%8F%E8%BF%B0"></a>🚩插件自描述</h3><p>安装插件后中间件会自动识别这个插件的能力，并且生成用户 UI 友好的任务创建界面，不需要用户直接编写复杂的 json 配置。</p><h3><a id="user-content-自由组合" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%87%AA%E7%94%B1%E7%BB%84%E5%90%88"></a>🚩自由组合</h3><p>MyDataHarbor 支持从不同的插件中复用各种组件，形一个新的 pipeline 管道，并且这些都是可以通过可视化的方式进行。</p><h3><a id="user-content-任务监控" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E4%BB%BB%E5%8A%A1%E7%9B%91%E6%8E%A7"></a>🚩任务监控</h3><p>对接 java 的 jmx，每个任务都有详细的监控，实时查看任务的运行状态。</p><h3><a id="user-content-批量支持" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%89%B9%E9%87%8F%E6%94%AF%E6%8C%81"></a>🚩批量支持</h3><p>为可以批量进行提交的写入源预留批量接口通道，有效提升数据迁移速度，摩托变汽车。</p><h3><a id="user-content-forkjoin" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#forkjoin"></a>🚩ForkJoin</h3><p>对于 DataSource 无法多线程并发拉取的情况下（如 jdbc 游标取数据），内部引入 forkjoin 并发处理模型开启多线程处理，并且灵活的事务控制，让速度飞快的同时保证数据迁移的稳定、不丢失，汽车变高铁。</p><h2><a id="user-content-设计" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%AE%BE%E8%AE%A1"></a>设计</h2><p>MyDataHarbor 唯一依赖的中间件是 zookeeper，共有两个组件：mydataharbor-console、mydataharbor-server
<img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/cluster-design.png" alt="集群设计" referrerpolicy="no-referrer"><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/node-design.png" alt="节点任务设计" referrerpolicy="no-referrer"></p><h2><a id="user-content-支持的插件" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%94%AF%E6%8C%81%E7%9A%84%E6%8F%92%E4%BB%B6"></a>支持的插件</h2><p>详见  <a href="https://gitee.com/link?target=https%3A%2F%2Fmydataharbor.yuque.com%2Fstaff-tzwgrd%2Fuqew9p%2Fpckin3">https://mydataharbor.yuque.com/staff-tzwgrd/uqew9p/pckin3</a></p><h2><a id="user-content-快速开始" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"></a>快速开始</h2><p>MyDataHarbor 的安装非常简单（启动前请先准备好 zookeeper 集群）：</p><h3><a id="user-content-下载二进制包" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E4%B8%8B%E8%BD%BD%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85"></a>下载二进制包</h3><p>下载地址：<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmydataharbor%2Fmydataharbor%2Freleases">https://github.com/mydataharbor/mydataharbor/releases</a>
下载列表：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">  mydataharbor-console-xxx-bin.tar.gz</span><span id="LC2" class="line">  mydataharbor-server-xxx-bin.tar.gz</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><blockquote><p>xxx 是发行的版本号</p></blockquote><h3><a id="user-content-mydataharbor-console" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#mydataharbor-console"></a>mydataharbor-console</h3><h4><a id="user-content-解压" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%A7%A3%E5%8E%8B"></a>解压</h4><p><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/image-20210812143819918.png" alt="image-20210812143819918" referrerpolicy="no-referrer"></p><h4><a id="user-content-配置" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E9%85%8D%E7%BD%AE"></a>配置</h4><p>进入 config 目录，修改 application.yml，主要修改如下配置</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="na">server</span><span class="pi">:</span></span><span id="LC2" class="line"><span class="na">port</span><span class="pi">:</span><span class="m">8080</span><span class="c1">#console 服务启动端口</span></span><span id="LC3" class="line"><span class="na">zk</span><span class="pi">:</span><span class="s">127.0.0.1:2181</span><span class="c1">#zk 地址</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-运行" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%BF%90%E8%A1%8C"></a>运行</h4><p>Windows 系统下运行 start.bat<br>
Linux 系统下运行 start.sh &nbsp;关闭 stop.sh</p><blockquote><p>start.sh 脚本支持 jmx、debug、status 参数，如：<br>
start.sh jmx   启动远程 jmx 支持 <br>
start.sh debug 开启远程 debug 方式启动 <br>
start.sh status 查看当前程序状态</p></blockquote><h3><a id="user-content-mydataharbor-server" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#mydataharbor-server"></a>mydataharbor-server</h3><h4><a id="user-content-解压-1" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%A7%A3%E5%8E%8B-1"></a>解压</h4><p><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/image-20210812144430744.png" alt="image-20210812144430744" referrerpolicy="no-referrer"></p><h4><a id="user-content-配置-1" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E9%85%8D%E7%BD%AE-1"></a>配置</h4><p>修改 config 目录下的 system.yml</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="na">zk</span><span class="pi">:</span><span class="pi">[</span><span class="s2">"</span><span class="s">127.0.0.1:2181"</span><span class="pi">]</span><span class="c1">#zk 地址</span></span><span id="LC2" class="line"><span class="na">port</span><span class="pi">:</span><span class="m">1299</span><span class="c1">#server 服务启动端口</span></span><span id="LC3" class="line"><span class="na">group</span><span class="pi">:</span><span class="s">biz001</span><span class="c1">#该节点所属组</span></span><span id="LC4" class="line"><span class="na">pluginRepository</span><span class="pi">:</span><span class="s">http://127.0.0.1:8080</span><span class="c1">#插件仓库地址</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-运行-1" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E8%BF%90%E8%A1%8C-1"></a>运行</h4><p>Windows 系统下运行 start.bat<br>
Linux 系统下运行 start.sh &nbsp;关闭 stop.sh</p><blockquote><p>start.sh 脚本支持 jmx、debug、status 参数，如：<br>
start.sh jmx   启动远程 jmx 支持 <br>
start.sh debug 开启远程 debug 方式启动 <br>
start.sh status 查看当前程序状态</p></blockquote><h4><a id="user-content-验证" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E9%AA%8C%E8%AF%81"></a>验证</h4><p>访问：mydataharbor-console &nbsp;<a href="https://gitee.com/link?target=http%3A%2F%2F127.0.0.1%3A8080">http://127.0.0.1:8080</a>
是否可以看到刚刚启动的节点
<img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/demo.png" alt="image-20210812143819918" referrerpolicy="no-referrer"></p><h2><a id="user-content-其它" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E5%85%B6%E5%AE%83"></a>其它</h2><p>demo 运行实例：<a href="https://gitee.com/link?target=http%3A%2F%2Fdemo.mydataharbor.com">http://demo.mydataharbor.com</a></p><p>插件市场：<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.mydataharbor.com%2Fuser%2Finfo.html">https://www.mydataharbor.com/user/info.html</a></p><p>文档 (语雀)：<a href="https://gitee.com/link?target=http%3A%2F%2Fdoc.mydataharbor.com">http://doc.mydataharbor.com</a></p><h4><a id="user-content-qq 群加群时需要验证项目 star 数请 star 一下然后记下 star 数告诉管理员" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#qq%E7%BE%A4%E5%8A%A0%E7%BE%A4%E6%97%B6%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E9%A1%B9%E7%9B%AEstar%E6%95%B0%E8%AF%B7star%E4%B8%80%E4%B8%8B%E7%84%B6%E5%90%8E%E8%AE%B0%E4%B8%8Bstar%E6%95%B0%E5%91%8A%E8%AF%89%E7%AE%A1%E7%90%86%E5%91%98"></a>QQ 群（<strong><em>加群时需要验证项目 star 数，请 star 一下然后记下 star 数告诉管理员</em></strong>）</h4><p><img src="https://gitee.com/mydataharbor/mydataharbor/raw/main/doc/image/qq-discuz.png" alt="QQ 群" referrerpolicy="no-referrer"></p><h2><a id="user-content-更新日志" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"></a>更新日志</h2><h3><a id="user-content-200 版本" class="anchor" href="https://gitee.com/mydataharbor/mydataharbor#200%E7%89%88%E6%9C%AC"></a>2.0.0 版本</h3><p>1、新增 mydataharbor.ITaskStorage 接口，允许各组件在运行期持久化记录数据，并提供一个 zookeeper 的默认实现，每秒 1 次准实时同步，不影响性能。</p><p>2、默认将任务的监控信息通过持久化接口近乎实时的展示在管理台</p><p>3、任务修改重建功能</p><p>4、调整 rebalance 算法，新机器加入，将转移当前管道数大于任务分配节点数的任务</p><p>5、鉴于 1.x 使用用户可能较少，由于修复了一些拼写错误，接口名称变了，不再向 1.x 兼容，建议大家把任务移到 2.x 上，请谅解</p>]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/mydataharbor/mydataharbor</guid>
            <link>https://gitee.com/mydataharbor/mydataharbor</link>
        </item>
        <item>
            <title>
                <![CDATA[华硕发布龙芯 3A6000 消费级主板]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日上午的&nbsp;2023 龙芯产品发布暨用户大会上，华硕宣布推出支持龙芯 3A6000 处理器的消费级主板 ——<strong>XC-LS3A6M 主板</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-61f3a35d39534e4fb1085f11406b047d65b.png" referrerpolicy="no-referrer"></p><p>华硕电脑开放平台中国区总经理俞元麟在大会现场展示了龙芯 3A6000 的测试成绩，在多核定点 / 浮点成绩上强于英特尔 i3-10100 处理器。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c6d03bcc64cbfa182ffe0874a92b73a9ad8.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4ba65ea3f7d7737f377147c043f38186a81.png" referrerpolicy="no-referrer"></p><p>此外，<strong>龙芯 3A6000 可以超频到 2.63GHz，而在液氮下保守可跑到 3GHz（BIOS 限制）</strong>，后续还能继续提升。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fffb0755e8808aa87c3bb539474c7452802.png" referrerpolicy="no-referrer"></p><hr><p>俞元麟昨晚在其 B 站账号（@普普通通 Tony 大叔）更新的视频介绍了龙芯 3A6000 CPU 的性能表现：：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV15u4y1A7aK%2F" target="_blank">《国产最强！龙芯中科 3A6000 台式机 CPU 性能测试》</a></em></u>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2f786c32b8e5bec71a427021176790a2fdb.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-87828dce58a34545dcb0a71096f24938a30.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268453</guid>
            <link>https://www.oschina.net/news/268453</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 时间复杂度为 O (nlogn) 的排序算法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>归并排序</h1><p>归并排序遵循<strong>分治</strong>的思想：将原问题分解为几个规模较小但类似于原问题的子问题，递归地求解这些子问题，然后合并这些子问题的解来建立原问题的解，归并排序的步骤如下：</p><ul><li><p><strong>划分</strong>：分解待排序的 n 个元素的序列成各具 n/2 个元素的两个子序列，将长数组的排序问题转换为短数组的排序问题，当待排序的序列长度为 1 时，递归划分结束</p></li><li><p><strong>合并</strong>：合并两个已排序的子序列得出已排序的最终结果</p></li></ul><p>归并排序的代码实现如下：</p><pre><code>    private void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 划分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid);
        sort(nums, mid + 1, right);
        // 合并
        merge(nums, left, mid, right);
    }

    private void merge(int[] nums, int left, int mid, int right) {
        // 辅助数组
        int[] temp = Arrays.copyOfRange(nums, left, right + 1);

        int leftBegin = 0, leftEnd = mid - left;
        int rightBegin = leftEnd + 1, rightEnd = right - left;
        for (int i = left; i &lt;= right; i++) {
            if (leftBegin &gt; leftEnd) {
                nums[i] = temp[rightBegin++];
            } else if (rightBegin &gt; rightEnd || temp[leftBegin] &lt; temp[rightBegin]) {
                nums[i] = temp[leftBegin++];
            } else {
                nums[i] = temp[rightBegin++];
            }
        }
    }

</code></pre><p>归并排序最吸引人的性质是它能保证将长度为 n 的数组排序所需的时间和 nlogn 成正比；它的主要缺点是所需的额外空间和 n 成正比。</p><p>算法特性：</p><ul><li><p><strong>空间复杂度</strong>：借助辅助数组实现合并，使用 O(n) 的额外空间；递归深度为 logn，使用 O(logn) 大小的栈帧空间。忽略低阶部分，所以空间复杂度为 O(n)</p></li><li><p><strong>非原地排序</strong></p></li><li><p><strong>稳定排序</strong></p></li><li><p><strong>非自适应排序</strong></p></li></ul><p>以上代码是归并排序常见的实现，下面我们来一起看看归并排序的优化策略：</p><span id="OSC_h3_2"></span><h3>将多次创建小数组的开销转换为只创建一次大数组</h3><p>在上文实现中，我们在每次合并两个有序数组时，即使是很小的数组，我们都会创建一个新的 temp[] 数组，这部分耗时是归并排序运行时间的主要部分。更好的解决方案是将 temp[] 数组定义成 sort() 方法的局部变量，并将它作为参数传递给 merge() 方法，实现如下：</p><pre><code>    private void sort(int[] nums, int left, int right, int[] temp) {
        if (left &gt;= right) {
            return;
        }

        // 划分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid, temp);
        sort(nums, mid + 1, right, temp);
        // 合并
        merge(nums, left, mid, right, temp);
    }

    private void merge(int[] nums, int left, int mid, int right, int[] temp) {
        System.arraycopy(nums, left, temp, left, right - left + 1);
        int l = left, r = mid + 1;
        for (int i = left; i &lt;= right; i++) {
            if (l &gt; mid) {
                nums[i] = temp[r++];
            } else if (r &gt; right || temp[l] &lt; temp[r]) {
                nums[i] = temp[l++];
            } else {
                nums[i] = temp[r++];
            }
        }
    }

</code></pre><span id="OSC_h3_3"></span><h3>当数组有序时，跳过 merge() 方法</h3><p>我们可以在执行合并前添加判断条件：如果<code>nums[mid] &lt;= nums[mid + 1]</code>时我们认为数组已经是有序的了，那么我们就跳过 merge() 方法。它不影响排序的递归调用，但是对任意有序的子数组算法的运行时间就变成线性的了，代码实现如下：</p><pre><code>    private void sort(int[] nums, int left, int right, int[] temp) {
        if (left &gt;= right) {
            return;
        }

        // 划分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid, temp);
        sort(nums, mid + 1, right, temp);
        // 合并
        if (nums[mid] &gt; nums[mid + 1]) {
            merge(nums, left, mid, right, temp);
        }
    }

    private void merge(int[] nums, int left, int mid, int right, int[] temp) {
        System.arraycopy(nums, left, temp, left, right - left + 1);
        int l = left, r = mid + 1;
        for (int i = left; i &lt;= right; i++) {
            if (l &gt; mid) {
                nums[i] = temp[r++];
            } else if (r &gt; right || temp[l] &lt; temp[r]) {
                nums[i] = temp[l++];
            } else {
                nums[i] = temp[r++];
            }
        }
    }

</code></pre><span id="OSC_h3_4"></span><h3>对小规模子数组使用插入排序</h3><p>对小规模数组进行排序会使递归调用过于频繁，而使用插入排序处理小规模子数组一般可以将归并排序的运行时间缩短 10% ~ 15%，代码实现如下：</p><pre><code>    /**
     * M 取值在 5 ~ 15 之间大多数情况下都能令人满意
     */
    private final int M = 9;

    private void sort(int[] nums, int left, int right) {
        if (left + M &gt;= right) {
            // 插入排序
            insertSort(nums);
            return;
        }

        // 划分
        int mid = left + right &gt;&gt; 1;
        sort(nums, left, mid);
        sort(nums, mid + 1, right);
        // 合并
        merge(nums, left, mid, right);
    }

    /**
     * 插入排序
     */
    private void insertSort(int[] nums) {
        for (int i = 1; i &lt; nums.length; i++) {
            int base = nums[i];

            int j = i - 1;
            while (j &gt;= 0 &amp;&amp; nums[j] &gt; base) {
                nums[j + 1] = nums[j--];
            }
            nums[j + 1] = base;
        }
    }

    private void merge(int[] nums, int left, int mid, int right) {
        // 辅助数组
        int[] temp = Arrays.copyOfRange(nums, left, right + 1);

        int leftBegin = 0, leftEnd = mid - left;
        int rightBegin = leftEnd + 1, rightEnd = right - left;
        for (int i = left; i &lt;= right; i++) {
            if (leftBegin &gt; leftEnd) {
                nums[i] = temp[rightBegin++];
            } else if (rightBegin &gt; rightEnd || temp[leftBegin] &lt; temp[rightBegin]) {
                nums[i] = temp[leftBegin++];
            } else {
                nums[i] = temp[rightBegin++];
            }
        }
    }

</code></pre><hr><span id="OSC_h1_5"></span><h1>快速排序</h1><p>快速排序也遵循<strong>分治</strong>的思想，它与归并排序不同的是，快速排序是<strong>原地排序</strong>，而且快速排序会先排序当前数组，再对子数组进行排序，它的算法步骤如下：</p><ul><li><p><strong>哨兵划分</strong>：选取数组中最左端元素为基准数，将小于基准数的元素放在基准数左边，将大于基准数的元素放在基准数右边</p></li><li><p><strong>排序子数组</strong>：将哨兵划分的索引作为划分左右子数组的分界，分别对左右子数组进行哨兵划分和排序</p></li></ul><p>快速排序的代码实现如下：</p><pre><code>    private void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 哨兵划分
        int partition = partition(nums, left, right);

        // 分别排序两个子数组
        sort(nums, left, partition - 1);
        sort(nums, partition + 1, right);
    }

    /**
     * 哨兵划分
     */
    private int partition(int[] nums, int left, int right) {
        // 以 nums[left] 作为基准数，并记录基准数索引
        int originIndex = left;
        int base = nums[left];

        while (left &lt; right) {
            // 从右向左找小于基准数的元素
            while (left &lt; right &amp;&amp; nums[right] &gt;= base) {
                right--;
            }
            // 从左向右找大于基准数的元素
            while (left &lt; right &amp;&amp; nums[left] &lt;= base) {
                left++;
            }
            swap(nums, left, right);
        }
        // 将基准数交换到两子数组的分界线
        swap(nums, originIndex, left);

        return left;
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><p>算法特性：</p><ul><li><p><strong>时间复杂度</strong>：平均时间复杂度为 O(nlogn)，最差时间复杂度为 O(n2)</p></li><li><p><strong>空间复杂度</strong>：最差情况下，递归深度为 n，所以空间复杂度为 O(n)</p></li><li><p><strong>原地排序</strong></p></li><li><p><strong>非稳定排序</strong></p></li><li><p><strong>自适应排序</strong></p></li></ul><blockquote><p>归并排序的时间复杂度一直是 O(nlogn)，而快速排序在最坏的情况下时间复杂度为 O(n2)，为什么归并排序没有快速排序应用广泛呢？</p><p>答：因为归并排序是非原地排序，在合并阶段需要借助非常量级的额外空间</p></blockquote><p>快速排序有很多优点，但是在哨兵划分不平衡的情况下，算法的效率会比较低效。下面是对快速排序排序优化的一些方法：</p><span id="OSC_h3_6"></span><h3>切换到插入排序</h3><p>对于小数组，快速排序比插入排序慢，快速排序的 sort() 方法在长度为 1 的子数组中也会调用一次，所以，在排序小数组时切换到插入排序排序的效率会更高，如下：</p><pre><code>    /**
     * M 取值在 5 ~ 15 之间大多数情况下都能令人满意
     */
    private final int M = 9;

    public void sort(int[] nums, int left, int right) {
        // 小数组采用插入排序
        if (left + M &gt;= right) {
            insertSort(nums);
            return;
        }

        int partition = partition(nums, left, right);
        sort(nums, left, partition - 1);
        sort(nums, partition + 1, right);
    }

    /**
     * 插入排序
     */
    private void insertSort(int[] nums) {
        for (int i = 1; i &lt; nums.length; i++) {
            int base = nums[i];

            int j = i - 1;
            while (j &gt;= 0 &amp;&amp; nums[j] &gt; base) {
                nums[j + 1] = nums[j--];
            }
            nums[j + 1] = base;
        }
    }

    private int partition(int[] nums, int left, int right) {
        int originIndex = left;
        int base = nums[left];

        while (left &lt; right) {
            while (left &lt; right &amp;&amp; nums[right] &gt;= base) {
                right--;
            }
            while (left &lt; right &amp;&amp; nums[left] &lt;= base) {
                left++;
            }
            swap(nums, left, right);
        }
        swap(nums, left, originIndex);

        return left;
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><span id="OSC_h3_7"></span><h3>基准数优化</h3><p>如果数组为倒序的情况下，选择最左端元素为基准数，那么每次哨兵划分会导致右数组长度为 0，进而使快速排序的时间复杂度为 O(n2)，为了尽可能避免这种情况，我们可以对基准数的选择进行优化，采用<strong>三取样切分</strong>的方法：选取数组最左端、中间和最右端这三个值的中位数为基准数，这样选择的基准数大概率不是区间的极值，时间复杂度为 O(n2) 的概率大大降低，代码实现如下：</p><pre><code>    public void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 基准数优化
        betterBase(nums, left, right);

        int partition = partition(nums, left, right);

        sort(nums, left, partition - 1);
        sort(nums, partition + 1, right);
    }

    /**
     * 基准数优化，将 left, mid, right 这几个值中的中位数换到 left 的位置
     * 注意其中使用了异或运算进行条件判断
     */
    private void betterBase(int[] nums, int left, int right) {
        int mid = left + right &gt;&gt; 1;

        if ((nums[mid] &lt; nums[right]) ^ (nums[mid] &lt; nums[left])) {
            swap(nums, left, mid);
        } else if ((nums[right] &lt; nums[left]) ^ (nums[right] &lt; nums[mid])) {
            swap(nums, left, right);
        }
    }

    private int partition(int[] nums, int left, int right) {
        int originIndex = left;
        int base = nums[left];

        while (left &lt; right) {
            while (left &lt; right &amp;&amp; nums[right] &gt;= base) {
                right--;
            }
            while (left &lt; right &amp;&amp; nums[left] &lt;= base) {
                left++;
            }
            swap(nums, left, right);
        }
        swap(nums, originIndex, left);

        return left;
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><span id="OSC_h3_8"></span><h3>三向切分</h3><p>在数组有大量重复元素的情况下，快速排序的递归性会使元素全部重复的子数组经常出现，而对这些数组进行快速排序是没有必要的，我们可以对它进行优化。</p><p>一个简单的想法是将数组切分为三部分，分别对应小于、等于和大于基准数的数组，每次将其中「小于」和「大于」的数组进行排序，那么最终也能得到排序的结果，这种策略下我们不会对等于基准数的子数组进行排序，提高了排序算法的效率，它的算法流程如下：</p><p>从左到右遍历数组，维护指针 l 使得 [left, l - 1] 中的元素都小于基准数，维护指针 r 使得 [r + 1, right] 中的元素都大于基准数，维护指针 mid 使得 [l, mid - 1] 中的元素都等于基准数，其中 [mid, r] 区间中的元素还未确定大小关系，图示如下：</p><p><img alt="快速排序-荷兰国旗.jpg" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-30-09-24mWidH7TKov10iOQb.jpg" referrerpolicy="no-referrer"></p><p>它的代码实现如下：</p><pre><code>    public void sort(int[] nums, int left, int right) {
        if (left &gt;= right) {
            return;
        }

        // 三向切分
        int l = left, mid = left + 1, r = right;
        int base = nums[l];
        while (mid &lt;= r) {
            if (nums[mid] &lt; base) {
                swap(nums, l++, mid++);
            } else if (nums[mid] &gt; base) {
                swap(nums, mid, r--);
            } else {
                mid++;
            }
        }

        sort(nums, left, l - 1);
        sort(nums, r + 1, right);
    }

    private void swap(int[] nums, int left, int right) {
        int temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }

</code></pre><blockquote><p>这也是经典的荷兰国旗问题，因为这就好像用三种可能的主键值将数组排序一样，这三种主键值对应着荷兰国旗上的三种颜色</p></blockquote><hr><span id="OSC_h3_9"></span><h3>巨人的肩膀</h3><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.hello-algo.com%2F" rel="nofollow" target="_blank">《Hello 算法》：11.5 和 11.6 小节</a></p></li><li><p>《算法，第四版》：2.3 节，快速排序</p></li><li><p>《算法导论，第三版》：第 2.2、2.3、7 章</p></li></ul><blockquote><p>作者：京东物流，王奕龙</p><p>来源：京东云开发者社区，自猿其说 Tech 转载请注明来源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10277308</guid>
            <link>https://my.oschina.net/u/4090830/blog/10277308</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国家广播电视总局发布三项广播电视和网络视听行业标准]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 27 日，国家广播电视总局发布通知，通知表示已组织审查了《有线电视业务技术要求》《IPTV 业务技术要求》《互联网电视业务技术要求》等三项标准文件，并批准为我国广播电视和网络视听推荐性行业标准。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-03c93c0f85c6c7cb4cd79deda8d4acfa63f.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nrta.gov.cn%2Fart%2F2023%2F11%2F27%2Fart_113_66209.html" target="_blank">https://www.nrta.gov.cn/art/2023/11/27/art_113_66209.html</a></u></em></p></blockquote><p>《有线电视业务技术要求》《IPTV 业务技术要求》中说明，有线电视终端与 IPTV 终端端应提供<strong>「开机进入全屏直播」和「开机进入突出直播频道的交互主页」</strong>两种「开机模式」选项，<strong>系统默认设置应为「开机进入全屏直播」</strong>。</p><p>选择进入交互主页开机模式的，开机后默认焦点应停留在直播窗口，且如果用户在 20s 内无操作，应自动进入全屏直播；包括开机广告等特定内容在内的冷启动开机时间应不大于 35s，且宜具备待机快速唤醒功能；遥控器应具备快捷看直播频道的「看电视」按键。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-979f3921987d751af13a1ef1f85b0df4424.png" referrerpolicy="no-referrer"></p><p>《互联网电视业务技术要求》中说明，互联网电视应用<strong>启动时间宜小于 3s</strong>，<strong>应不大于 5s</strong>，应用的启动广告时间应包含在互联网电视应用启动时间内，如展现了广告，启动时间仍应符合该要求。</p><p>交互主页应设置显著、便捷的免费业务专区入口，从交互主页默认焦点至免费业务专区入口的操作次数不宜超过 3 次；交互主页不应设置弹窗广告；业务的订购或退订等相关操作，均应在用户界面上提供明确的提示说明和流程操作说明，且应提供确认付费或取消付费的明确操作步骤，<strong>不应设置「一键付费」相关操作</strong>。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268448</guid>
            <link>https://www.oschina.net/news/268448</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[B 站正式启动鸿蒙原生应用开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>哔哩哔哩（B 站）与华为宣布达成鸿蒙领域全面合作，并正式启动鸿蒙原生应用开发工作。</p><p>数据显示，今年上半年，B 站的日活用户同比增长 17% 至超过 9500 万，而月活用户达 3.19 亿；总日均视频播放量同比增长 34% 至 41 亿。截至今年 8 月，鸿蒙生态设备数量已超过 7 亿，超过 220 万开发者投入到鸿蒙生态开发中，且近期日新增注册量已过万。</p><p><img alt="" height="331" src="https://oscimg.oschina.net/oscnet/up-25a150372aecd554f4a31c934afbf6af3f8.webp" width="500" referrerpolicy="no-referrer"></p><p>目前，已宣布启动鸿蒙原生应用开发的 App 包括但不限于：同程旅行、开心消消乐、美团、去哪儿、钉钉、飞常准、小红书、B 站。</p><p>哔哩哔哩方面表示，鸿蒙原生版本的哔哩哔哩将充分利用 HarmonyOS 独特的全场景分布式体验、原生智能、纯净安全、大模型 AI 交互等能力，提供更多创新体验。华为则表示，将提供端到端的鸿蒙开发和赋能套件，使得鸿蒙应用适配成本降低。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268446</guid>
            <link>https://www.oschina.net/news/268446</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google Drive 出现数据丢失问题]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>有 Google Drive 用户称自己存储在云端的文件<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F11%2F27%2Fgoogle_drive_files_disappearing%2F" target="_blank">无端丢失</a></u>，他表示登录 Google Drive 后发现自己的文件<strong>回到了 2023 年 5 月的状态</strong>。由于他没有手动删除过文件，所以回收站也没有任何丢失文件的记录。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1128/102059_Ynyc_2720166.png" referrerpolicy="no-referrer"></p><p>来源：<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fdrive%2Fthread%2F245055606%2Fgoogle-drive-files-suddenly-disappeared-the-drive-literally-went-back-to-condition-in-may-2023%3Fhl%3Den" target="_blank">https://support.google.com/drive/thread/245055606/google-drive-files-suddenly-disappeared-the-drive-literally-went-back-to-condition-in-may-2023?hl=en</a></em></p></blockquote><p>其他用户也<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fdrive%2Fthread%2F245055606%3Fhl%3Den%26msgid%3D245207929" target="_blank">报告了类似的经历</a></u>，有人声称丢失了六个月的业务数据。另外有一些用户报告称同步功能停止工作，导致云存储中的文件不再是最新的版本。</p><p>一些用户通过调整缓存文件成功恢复了部分信息，<strong>但受影响用户的建议是在工程师找到解决方案之前不要进行任何更改</strong>。</p><p>Google 支持团队发布的一条消息也建议在工程师调查问题期间不要对根/数据文件夹进行更改。一些用户猜测可能与账户被意外删除有关。</p><p>这一状况通常会波及多达数月的云文件，且无法用恢复工具还原。有部分用户在缓存文件中找到部分数据。目前 Google 官方人员在其中一条反馈中表示该问题已在排查中，但未能给出具体修复时间，也无法确定在修复后是否能找回全部文件。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 02:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268442/google-drive-files-suddenly-disappeared</guid>
            <link>https://www.oschina.net/news/268442/google-drive-files-suddenly-disappeared</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[研易科技加入 openKylin，共推社区 ARM 生态繁荣！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">近日，深圳市研易科技有限公司（以下简称」研易科技「）签署了 openKylin 社区 CLA（Contributor License Agreement 贡献者许可协议），正式加入 openKylin 开源社区。</span></span></p><div><p style="text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-0f2a91ac2d8ef1357d5dd4e6294f78f07a8.png" width="829" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">研易科技依托资深研发销售队伍，集行业专用嵌入式计算机产品研发、生产、销售及服务于一体，产品涉及嵌入式计算机板卡、嵌入式准系统、工业整机、工业平板电脑等，可广泛应用于智慧医疗、人工智能、智慧零售、仓储物流、智慧城市、轨道交通、灯光工程、网络安全、智慧电网、国产化、工业自动化等行业领域。公司旗下 Coolpi 系列开源模块产品，可提供高性能计算能力，方便广大开发者评估项目与应用落地。</span></span></p><div><p style="text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-ec10d5d2b359fddbaf627cab3d3c3505685.png" width="940" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">加入 opeKylin 社区后，研易科技完成了 Cool Pi 与社区操作系统 1.0 版本的兼容适配。后续，双方将持续在技术和生态上展开合作，包括硬件升级和版本适配等。研易科技也将持续对 openKylin 社区进行投入，共同推动社区 ARM 生态繁荣。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 27 Nov 2023 01:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268435</guid>
            <link>https://www.oschina.net/news/268435</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[浪潮发布基础大模型「源 2.0」，千亿参数全面开源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>浪潮信息<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrjnsUS83TT7aEN3r2i0IPQ" target="_blank">发布</a></u>「源 2.0」基础大模型，并宣布全面开源</strong>。</p><p>据介绍，源 2.0 基础大模型包括 1026 亿、518 亿、21 亿等三种参数规模的模型，在编程、推理、逻辑等方面展示出了先进的能力。</p><p><strong>算法方面</strong>，源 2.0 提出并采用了一种新型的注意力算法结构：局部注意力过滤增强机制 (LFA：Localized Filtering-based Attention)。LFA 通过先学习相邻词之间的关联性，然后再计算全局关联性的方法，能够更好地学习到自然语言的局部和全局的语言特征，对于自然语言的关联语义理解更准确、更人性，提升了模型的自然语言表达能力，进而提升了模型精度。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184848_muAm_2720166.png" referrerpolicy="no-referrer"></p><p><strong>数据方面</strong>，源 2.0 通过使用中英文书籍、百科、论文等高质量中英文资料，降低了互联网语料内容占比，结合高效的数据清洗流程，为大模型训练提供了高质量的专业数据集和逻辑推理数据集。</p><p>据称，为了更高效地获得相对匮乏的高质量中文数学及代码数据集，源 2.0 采用了基于大模型的数据生产及过滤方法，在保证数据的多样性的同时也在每一个类别上提升数据质量，获取了一批高质量的数学与代码预训练数据。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184918_iLAq_2720166.png" referrerpolicy="no-referrer"></p><p><strong>算力方面</strong>，源 2.0 采用了非均匀流水并行的方法，综合运用流水线并行+优化器参数并行+数据并行的策略，让模型在流水并行各阶段的显存占用量分布更均衡，避免出现显存瓶颈导致的训练效率降低的问题，该方法显著降低了大模型对芯片间 P2P 带宽的需求，为硬件差异较大训练环境提供了一种高性能的训练方法。</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184932_0UiQ_2720166.png" referrerpolicy="no-referrer"></p><p>源 2.0 在业界公开的评测上进行了代码生成、数学问题求解、事实问答方面的能力测试，下面是测试结果：</p><p><img src="https://static.oschina.net/uploads/space/2023/1127/184945_PzyP_2720166.png" referrerpolicy="no-referrer"></p><p><strong>源 2.0 采用全面开源策略，全系列模型参数和代码均可免费下载使用</strong>。</p><ul><li>代码开源链接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0</a></em></u></li><li>论文链接：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FIEIT-Yuan%2FYuan-2.0%2Fblob%2Fmain%2Fdocs%2FYuan2.0_paper.pdf" target="_blank">https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/Yuan2.0_paper.pdf</a></em></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268384</guid>
            <link>https://www.oschina.net/news/268384</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[字节跳动成立新部门 Flow，发力 AI 应用层]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">36 氪报道称，</span><span style="background-color:#ffffff; color:#222222">字节跳动近期成立了一个新 AI 部门 Flow，技术负责人为字节跳动技术副总裁洪定坤。</span></p><p><span style="background-color:#ffffff; color:#222222">一位知情人士表示，这一新部门的业务带头人，为字节大模型团队的负责人朱文佳。Flow 主要聚焦在 AI 应用层。在字节圈内，Flow 近期发布了活水招聘帖，社会招聘也已经开始一段时间。</span></p><p><span style="background-color:#ffffff; color:#222222">在帖中，其表示是字节跳动旗下 AI 创新业务团队，「目前已经在国内和海外分别上线豆包和 Cici 两款产品，有多个 AI 相关创新产品孵化中」。截止发稿前，字节跳动尚无回应。</span></p><p style="color:#262626; margin-left:0; margin-right:0; text-align:justify">在 11 月初，字节各个事业部都进行了不少业务和架构调整，这些调整仍在进行中，当前 Flow 的架构和汇报线未完全确定。且多位知情人士透露，在此次调整中，字节也从飞书、抖音等各个 BU 抽调人选，到这一部门做一款新的 C 端产品。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/268383</guid>
            <link>https://www.oschina.net/news/268383</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云原生周刊：Kubernetes 1.29 中的删除、弃用和主要更改]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyonahd%2Forphaned-configmaps" target="_blank">Orphaned ConfigMaps</a></h3><p>该版本库包含一个脚本，用于识别 Kubernetes 命名空间中的孤立的配置映射。孤立的配置映射是指那些未被命名空间中的任何活动 Pod 或容器引用的配置映射。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmarvasgit%2Fkubernetes-multicooker" target="_blank">Kubernetes Multi Cooker</a></h3><p>该项目包含一个小型 Kubernetes 控制器，用于监视每个节点的 CPU 压力；当超过某个阈值时，节点将被污染（这样就不会在已经超载的节点上调度额外的工作负载），最后控制器将开始从该节点驱逐 Pod。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Femberstack%2Fkubernetes-reflector" target="_blank">Reflector</a></h3><p>Reflector 是一个 Kubernetes 插件，旨在监视资源（秘密和配置映射）的更改并反映相同或其他命名空间中镜像资源的更改。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubernetes.io%2Fblog%2F2023%2F11%2F16%2Fkubernetes-1-29-upcoming-changes%2F" target="_blank">Kubernetes 1.29 中的删除、弃用和主要更改</a></h3><p>和其他每次发布一样，Kubernetes v1.29 将弃用和移除一些特性。一贯以来生成高质量发布版本的能力是开发周期稳健和社区健康的证明。本文列举即将发布的 Kubernetes 1.29 中的一些弃用和移除事项。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-storage-provider-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 大存储提供商工具</a></h3><p>这篇文章介绍了 Kubernetes 的五个存储提供者工具：SeaweedFS、Vitess、TiKV、Rook 和 OpenEBS。这些工具帮助管理 Kubernetes 上的数据工作负载，包括卷供应、复制、备份、加密、压缩和性能调优等功能。它们与 Kubernetes API 和概念无缝集成，并支持持久卷（PV）、持久卷声明（PVC）和存储类（Storage Class）。这篇文章详细介绍了每个工具的工作机制、优势以及在实际使用中的案例和成功故事。通过阅读这篇文章，读者可以了解 Kubernetes 上可用的存储提供者选项，并根据自己的需求选择最合适的工具。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.atatus.com%2Fblog%2Ftroubleshooting-kubernetes-deployment%2F" target="_blank">对各个级别的 Kubernetes 部署进行故障排除</a></h3><p>这篇文章是关于在各个层面上解决 Kubernetes 部署问题的指南。文章首先介绍了 Kubernetes 作为容器编排的事实标准，并提到了它自动化部署、扩展和管理容器化应用程序的能力。然而，即使遵循最佳实践并具备专业知识，Kubernetes 部署有时也是一个复杂而具有挑战性的过程。文章探讨了从应用代码到基础设施和 Kubernetes 组件的各个层面上的部署故障排除过程，并介绍了一些常见问题和挑战，如容器镜像拉取错误、Pod 调度问题、网络连接问题和存储问题。文章还讨论了一些诊断和解决这些问题的最佳实践和工具。通过阅读这篇文章，读者将更好地了解如何在 Kubernetes 部署的每个层面上进行故障排除，并更好地管理其应用程序。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F11%2F20%2Fannouncing-the-platform-engineering-maturity-model%2F" target="_blank">CNCF 平台工程成熟度模型出炉</a></h3><p>CNCF（Cloud Native Computing Foundation）的平台工程成熟度模型首次发布。该模型提供了对平台工程成熟度的具体应用，是今年 4 月份发布的备受欢迎的白皮书的延伸。该模型将平台工程定义为通过在构建平台和其能力的各个方面（包括人员、流程、策略和技术）进行投资，提供内部平台作为产品的实践，从而推动业务结果。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloudnativenow.com%2Ftopics%2Fcloudnativedevelopment%2Fmicrosoft-expands-scope-of-azure-kubernetes-services%2F" target="_blank">微软扩大 Azure Kubernetes 服务范围</a></h3><p>Microsoft 已普遍推出 Azure Kubernetes Fleet Manager，以便更轻松地集中管理多个集群，并可与一组用于优化成本的工具一起分阶段进行。</p><p>与此同时，除了预览 Azure 容器应用程序平台的扩展以增加对事件的支持之外，微软还使用 Kubernetes AI 工具链运算符简化在 Azure Kubernetes 服务 (AKS) 上部署大型语言模型 (LLM) 的过程用于训练 AI 模型的驱动框架，同时支持开源 Qdrant、Milvus 和 Weaviate 矢量数据库。</p><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10293895</guid>
            <link>https://my.oschina.net/u/4197945/blog/10293895</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[What's new in dubbo-go-pixiu v1.0.0]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>dubbo 原生网关 dubbo-go-pixiu v1.0 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Freleases%2Ftag%2Fv1.0.0-rc2" target="_blank">https://github.com/apache/dubbo-go-pixiu/releases/tag/v1.0.0-rc2</a> 正式发版了，项目从 2019 年一路走来，四年磨剑，感谢从，铁城、张天，到 吕梦超，三位负责人。</p><p>目前，dubbo-go-pixiu 可作为 dubbo/dubbogo 服务网关，也可作为 dubbo/dubbogo 服务的 sidecar，还额外基于 Istio v1.14.3 实现了 dubbo 的控制面。</p><p>dubbo-go 和 dubbo-go-pixiu 在 2023 年初被蚂蚁集团采用内部容器 PAAS HCS(Hyper Container Service) 超级容器平台的微服务技术底座， v1.0.0 集成了蚂蚁集团使用过程中的提交的很多改进和优化。感谢本次版本的主要贡献者，胡潇晗、樊凡、龚娜、张国强、【阿里】远云、【蚂蚁】多航、王虓雄、望哥、于雨，等社区同学。</p><h1>1 New Features In v1.0.0</h1><h2>1.1 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F548" target="_blank">Triple 支持传递 Header 和引入 PB 定义</a></h2><p>Triple 代理现在可以正确传递 header 到 Triple 服务，且支持通过引入 protoset 文件来支持未开启 Proto 反射或不支持反射的特定 proto，例如使用旧版本编译的或 gogoproto 编译的服务。</p><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftriple" target="_blank">https://github.com/apache/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/triple</a></p><h2>1.2 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F554" target="_blank">负载均衡 Maglev hashing</a></h2><p>负载均衡支持新算法：Maglev hashing。Maglev 是 Google 开发的基于 kernal bypass 技术实现的 4 层负载均衡，它具有非常强大的负载性能，承载了 Google 绝大部分接入流量。Maglev 在负载均衡算法上采用自行开发的一致性哈希算法被称为 Maglev Hashing，该哈希算法在节点变化时能够尽量少的影响其他几点，且尽可能的保证负载的均衡，是一个非常优秀的一致性哈希算法。</p><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshawnh2%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftraffic" target="_blank">https://github.com/shawnh2/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/traffic</a></p><h2>1.3 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F565" target="_blank">Router 支持 Header 路由</a></h2><p>Router 支持通过 header 路由，可以更方便的管理流量。</p><pre><code class="language-yaml">              http_filters:
                  - name: dgp.filter.http.traffic
                    config:
                      traffics:
                        - name: "user-v1"
                          router: "/user"
                          canary-by-header: v1
                          canary-weight: 0
                        - name: "user-v2"
                          router: "/user"
                          canary-by-header: v2
                          canary-weight: 100
</code></pre><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshawnh2%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fdubbogo%2Fsimple%2Ftraffic" target="_blank">https://github.com/shawnh2/dubbo-go-pixiu-samples/tree/main/dubbogo/simple/traffic</a></p><h2>1.4 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F571" target="_blank">错误注入</a></h2><p>支持对特定 API 做错误注入，例如返回固定的响应，施加随机性的延时/错误等。</p><pre><code class="language-yaml">                http_filters:
                  - name: dgp.filter.http.faultinjection
                    config:
                      fail_inject_rules:
                        "/UserService/com.dubbogo.pixiu.UserService/GetUserByCode":
                          type: delay
                          trigger_type: random
                          status_code: 500
                          body: 'error'
                          delay: 5s
                          odds: 30
</code></pre><p>samples： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fblob%2Fdevelop%2Fdocs%2Fsample%2Fothers%2Ffail-inject.md" target="_blank">https://github.com/apache/dubbo-go-pixiu/blob/develop/docs/sample/others/fail-inject.md</a></p><h2>1.5 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F522" target="_blank">Add GracefulShutdown Signal For Windows</a></h2><p>支持 Windows 优雅下线，Pixiu 关闭时避免流量损失。</p><pre><code class="language-yaml">static_resources:
.......
.......
  shutdown_config:
    timeout: "60s"
    step_timeout: "10s"
    reject_policy: "immediacy"
</code></pre><p>配置方式参考： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu-samples%2Ftree%2Fmain%2Fshutdown" target="_blank">https://github.com/apache/dubbo-go-pixiu-samples/tree/main/shutdown</a></p><h1>2 Enhancement in v1.0.0</h1><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F573" target="_blank">优化 Prometheus 指标上报</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F530" target="_blank">修复一致性 Hash 数组越界</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F521" target="_blank">优化 Timeout 时的 http status code</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F528" target="_blank">优化 Metric 推拉模式</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F524" target="_blank">优化 Nacos 客户端启动时的参数配置</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F517" target="_blank">修复特定 Filter 配置为空时的 NPE 问题</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F515" target="_blank">升级 wasmer-go v1.0.4 以支持 Mac ARM 版本</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F506" target="_blank">fix sample url using github.com/apache/dubbo-go-pixiu-samples</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F507" target="_blank">修复流量管理路由权重计算错误的问题</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F513" target="_blank">修复负载均衡在特定情况下无法正常工作的问题</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F574" target="_blank">移除无用的 imports</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F575" target="_blank">chore: unnecessary use of fmt.Sprintf</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F567" target="_blank">chore:use wasm filter build tags add wasm</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F556" target="_blank">修复无法错误的 samples 链接等</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F557" target="_blank">revert gatewayCmd to Run dubbo go pixiu</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdubbo-go-pixiu%2Fpull%2F516" target="_blank">升级 hessian2 依赖到 v1.11.3</a></li></ul><h1>3 参考文档</h1><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRwIA7TitRfUMU8rTI4JsBg" target="_blank">What's new in dubbo-go-pixiu v0.6.0</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5syzT64koPV77aRh04Izsw" target="_blank">What's new in dubbo-go-pixiu 0.5.1</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fdok42ssPJqazjeSRYaifVw" target="_blank">What's new in dubbo-go-pixiu 0.4.0</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC7TxU0Zbee7EZ_6SJOLK8w" target="_blank">Dubbo 跨语言调用神兽：dubbo-go-pixiu</a></li></ul><h1>4 社区</h1><p>欢迎钉钉扫码加入 dubbogo 社区钉钉群【钉钉群号 23331795】进行交流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ff09984b6821a6da40dcdb6db415fcca4b8.png" alt="" referrerpolicy="no-referrer"></p><p>以及 dubbogo 社区微信公众号：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8feb2024cbf754333e9d7564cd0316dbb71.jpg" alt="" referrerpolicy="no-referrer"></p><p>从今年开始，除了以往负责的 dubbogo 社区项目外，于雨还负责了 pika 项目 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenAtomFoundation%2Fpika" target="_blank">https://github.com/OpenAtomFoundation/pika</a>)，如果对该项目感兴趣，请扫码：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3e900aa69386ac2190edb8035f4abb68415.png" alt="" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 26 Nov 2023 09:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/dubbogo/blog/10294380</guid>
            <link>https://my.oschina.net/dubbogo/blog/10294380</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
