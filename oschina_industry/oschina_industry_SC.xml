<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Thu, 14 Dec 2023 06:41:07 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[中国法院做出全球首个 5G 费率判决]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">日前，重庆市第一中级人民法院就 OPPO 诉诺基亚标准必要专利使用费纠纷一案作出判决，判决确认了诺基亚 2G-5G 标准必要专利的全球性的公平、合理和无歧视（FRAND）费率：针对 5G 多模手机，在全球第一区的单台许可费为 1.151 美元/台，在第二区（中国大陆地区）及第三区的单台许可费为 0.707 美元/台。针对 4G 多模手机，在第一区的单台许可费为 0.777 美元/台，在第二区及第三区的单台许可费为 0.477 美元/台。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">本次判决是中国法院首次对标准必要专利诉讼作出全球费率判决。2021 年，最高人民法院首次在「OPPO 夏普标准必要专利许可纠纷案」中终审裁定中国法院对标准专利具备全球费率管辖权。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">此外，判决首次确定了手机行业 5G 标准累积费率为 4.341%-5.273%。按照本次裁决，不考虑多模制式占比，一部 200 美元的纯 5G 手机，整机收取 5G 专利费的上限为 10.55 美元。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 06:20:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271007</guid>
            <link>https://www.oschina.net/news/271007</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【直播预告】上云 vs 下云：降本增笑？割韭菜？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本月，滴滴崩溃事件闹得轰轰烈烈，各种离谱派单层出不穷，而造成这一混乱的，则是底层出故障的阿里云。尴尬的是，这已经不是它第一次崩溃了，距离上一次，还不到一个月。</p><p>一时之间，各种有关「云」的讨论纷纷扬扬：有人眼馋马斯克的 X 下云省钱，觉得反正都有风险，还不如自己弄，这样更可掌控，也更清楚；有人则认为上云才是未来的趋势，想要发挥出软件的最大优势，上云更合适。</p><p>那么，你怎么看呢——</p><p><strong>公有云崩溃，到底是必然事件，还是事出偶然？</strong></p><p><strong>X 的案例参考性有多大？想省钱是该上云 or 下云呢？</strong></p><p><strong>到底是自建云更安全，还是公有云更有保障？</strong></p><p><strong>对普通的厂商而言，该怎么选择呢？</strong></p><p>本期，OSCHINA【开源漫谈】特地邀请了 5 位业内具有代表性的专家，直播探讨一下，接下来，我们该上云还是下云？</p><p>&nbsp;</p><p><strong>直播主题：</strong>上云 vs 下云：降本增笑？割韭菜？</p><p><strong>直播时间：</strong>12 月 20 日 19:00 - 20:30</p><p><strong>直播平台：</strong>「OSC 开源社区」视频号</p><p><strong>主办方：</strong>开源中国</p><p>&nbsp;</p><div><div><p><strong>直播嘉宾：</strong></p><div><div><p>&nbsp;&nbsp;<strong>主持人：</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;李鹤，kinitiras、kluster-capacity 作者，kubernetes、karmada 社区贡献者，前滴滴软件开发工程师。16 年起一直从事容器相关工作，公众号云原生散修，个人 blog https://www.likakuli.com，目前在虾皮北京，做资源利用率优化相关工作。</p><p>&nbsp;</p></div><div><p>&nbsp;&nbsp;<strong>正方：</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;周新宇，AutoMQ 联合创始人 &amp; CTO，是 Apache 软件基金会成员，Apache RocketMQ 联合创始人 &amp; PMC 成员。有近十年的云计算从业经历，完整经历了阿里云中间件上云历程，是云原生上云理念的倡导者。</p><p>&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp;蒋明，前淘宝 DBA。</p><p>&nbsp;</p></div><div><p>&nbsp;&nbsp;<strong>反方：</strong></p><p style="text-align:left">&nbsp;&nbsp;&nbsp;&nbsp;冯若航，磐吉云数 CEO / 创始人，Pigsty 作者，PostgreSQL 中文社区开源技术委员。公众号《非法加冯》主理人，下云倡导者。</p><p>&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp;马工，在北欧从事 Infra 工程师，公众号《瑞典马工》主理人。主张云计算是新的操作系统，其用户是软件开发者，简单的搬迁上云没有意义。他认为目前云计算厂商有太多的草台班子，80% 的乙方员工都不会用自家的云。</p></div></div></div></div><p>&nbsp;</p><p>公有云崩溃屡屡出现，我们仍该坚持上云还是掉头选择下云？你怎么看呢？快扫码预约直播，一起讨论吧~还可以进我们的 OSC 技术交流群，分享你的想法哦~</p><p style="text-align:center"><img height="2895" src="https://oscimg.oschina.net/oscnet/up-b9c174de1a7a4b314f3ff751d6e6e2ad5e0.png" width="750" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="text-align:left"><strong>直播福利</strong></p><ul><li><p>互动抽奖：在直播评论区提问，被直播嘉宾回复的用户可获 OSC 魔方一个，名额不限。</p></li><li><p>福袋抽奖：直播中将有多轮抽奖，参与就有机会获得 OSC T 恤、魔方等。</p></li></ul><p style="text-align:center"><img height="2160" src="https://oscimg.oschina.net/oscnet/up-555ffa0866e12bdebcbbab1295b7fef43bc.png" width="3840" referrerpolicy="no-referrer"></p><p>我们直播间见吧~</p><p>&nbsp;</p><p><strong>特别鸣谢本次合作社区：</strong></p><ul><li><p><strong>PostgreSQL</strong><strong>中文社区</strong></p></li></ul><p>PostgreSQL 中文社区是一个非盈利的民间组织，目前成员都以志愿者身份加入，成立的目的在于构建 PG 数据库技术生态圈子 (内核、用户培训机构、厂商、服务商、软件开发商、高校形成 「业务与利益双向驱动」 的良性发展生态圈); 帮助企业解决人才培养和企业商用数据库成本问题，社区会在各运营平台发布 PostgreSQL 最新信息和 PostgreSQL 相关技术文章，推动 PG 技术在中国的发展。 官网链接：http://www.postgres.cn/index.php/v2/home</p><p>&nbsp;</p><ul><li><p><strong>Pigsty</strong></p></li></ul><p style="text-align:left">Pigsty 是本地优先的 RDS 开源替代，开箱即用的 PostgreSQL 发行版，自带高可用、监控系统，PITR，IaC 与部署方案。</p><p style="text-align:left">官网链接：https://pigsty.cc</p><p>&nbsp;</p><ul><li><p><strong>AutoMQ 开源社区</strong></p></li></ul><p>AutoMQ 社区聚集了一群热衷于云原生技术的开源爱好者，他们曾经见证并应对了消息队列基础设施在大型互联网公司和云计算公司面临的种种挑战，希望与广大开发者共同探索，以云原生技术为基础，重新塑造这一关键领域，探索云原生消息队列的更多可能性。目前，AutoMQ 社区以 Apache 协议开源了云原生版本的 Kafka 和 RocketMQ 实现，致力于用云原生的技术栈，大幅度降低企业的云资源成本，以及提高运维效率。</p><p>社区地址：https://github.com/AutoMQ</p><p>&nbsp;</p><ul><li><p><strong>TiDB</strong></p></li></ul><p>由 TiDB 生态中的开发者、用户、合作伙伴一起建立的分享、学习平台。TiDB 线上社区汇聚了 33448 位 TiDB 资深用户（注册用户数），所有成员都可以在这里自由发声，互相协助解决问题。社区线上论坛 asktug.com 已经积累 23,000+ 个问题帖（主题帖数），90 % 的问题都得到了解决，累计总回复 243,000+ 个（主题帖回复数）。</p><p>社区地址：asktug.com</p><p>&nbsp;</p><ul><li><p><strong>Apache</strong><strong> IoTDB </strong></p></li></ul><p>Apache IoTDB 是一款低成本、高可用的物联网原生时序数据库，采用端边云协同的轻量化结构，支持一体化的物联网时序数据收集、存储、管理与分析，具有多协议兼容、超高压缩比、高通量读写、工业级稳定、极简运维等特点。IoTDB 自研完整的存储引擎、查询引擎、计算引擎，并支持权限管理、集群管理、系统监控、可视化呈现等多项功能，可实现物联网时序数据全生命周期，也就是涵盖写入、存储、处理、查询、分析、展示等多个维度的时序数据高效管理，助力企业构建时序数据高可用、高稳定解决方案。</p><p>作为全球性开源项目，Apache IoTDB 已成为 Apache 基金会顶级项目，并建成全球认可的国际开源社区。目前，Apache IoTDB 社区拥有超过 260 名代码提交者，完成 9000 余次提交，收获 4100 余次 stars，代码活跃度于 Apache 350 余个项目中排名第三。</p><p>社区地址：https://iotdb.apache.org</p><p>&nbsp;</p><ul><li><p><strong>StarRocks</strong></p></li></ul><p>Linux 基金会项目 StarRocks 是数据分析新范式的开创者、新标准的领导者。面世三年来，StarRocks 一直专注打造世界顶级的新一代极速全场景 MPP 数据库，帮助企业构建极速统一的湖仓分析新范式，是实现数字化转型和降本增效的关键基础设施。</p><p>社区地址：https://www.starrocks.io/</p><p>项目链接：https://github.com/StarRocks/starrocks</p><p>&nbsp;</p><ul><li><p><strong>Gitee</strong></p></li></ul><p>Gitee（码云）是开源中国于 2013 年推出的基于 Git 的代码托管平台、企业级研发效能平台，提供中国本土化的代码托管服务。</p><p>截止 2023 年 7 月，Gitee 已经有 1000 万名注册用户和 2500 万个代码仓库，是中国境内规模最大的代码托管平台。同时，旗下企业级 DevOps 研发效能管理平台 Gitee 企业版已服务超过 26 万家企业。</p><p>网址：https://gitee.com/</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10321438</guid>
            <link>https://my.oschina.net/u/6852546/blog/10321438</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mate 60 Pro 的 5G 调制解调器和射频技术遥遥领先]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>TechInsights 对华为 Mate 60 Pro 的持续分析显示，中国在绕过技术封锁方面取得了重大进展。<strong>这种进步不仅体现在应用处理器片上系统 (SoC) 上，还体现在 5G 基带处理器和移动射频技术上</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-fb55239889638f62fda03f236e44ce5e085.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ftechinsightsinc%2Fstatus%2F1734034686689661432" target="_blank">https://twitter.com/techinsightsinc/status/1734034686689661432</a></u></em></p><p>搭载于 Mate 60 Pro 的麒麟 9000S 证明，华为和中芯国际可以在没有美国公司和其他被禁止与这两家中国实体合作的实体的帮助下，继续大规模生产移动芯片。</p><p>不止麒麟 9000S，最近的一项分析显示，除了芯片组外，<strong>旗舰产品中使用的先进 5G 调制解调器和射频技术也使华为可以与其他高端智能手机和芯片制造商相媲美</strong>。</p><p>TechInsights 分析称：「中国在开发先进的（2D）系统级封装（SiP）模块和射频滤波器方面也取得了飞跃，采用了声波滤波器的改进技术以及基于薄膜集成无源器件（IPD）和低温共烧陶瓷（LTCC）的混合技术。与 2015 年和 2016 年之前的射频 FE 5G 架构相比，这是一个重大进步。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c43c2606127ed23640e66b732ba55f6a808.png" referrerpolicy="no-referrer"></p><p>该公司凭借其 5G 调制解调器和射频技术跨越了这些令人生畏的障碍，使华为成为其他巨头中的佼佼者。鉴于苹果公司已经投资数十亿美元努力制造自己的基带芯片，其中包括收购英特尔的 5G 调制解调器业务，但仍然遇到了无数的开发问题，这证明制造这些芯片是多么困难，但华为已经想出了办法。</p><p>不仅如此，华为和中芯国际还悄然发布了一款 5 纳米芯片，虽然是用于笔记本电脑，但突破 7 纳米大关足以证明，明年我们可能会看到新的麒麟芯片与新的 5G 调制解调器一起出现在 P70 系列上。尽管如此，中国的芯片技术仍比美国落后几年，但以目前的速度，这一差距可能会持续缩小。</p><p>原文：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techinsights.com%2Fblog%2Fmate-60-pro-mobile-rf-architecture-proves-huawei-can-compete-top-tier-smartphone-oems" target="_blank">https://www.techinsights.com/</a></u></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270978</guid>
            <link>https://www.oschina.net/news/270978</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CNCF 首个云原生多云容器编排项目 Karmada 正式晋级孵化]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>文分享自华为云社区《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F417774%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">CNCF 首个云原生多云容器编排项目 Karmada 正式晋级孵化】</a>》，作者：云容器大未来。</p><p>近日，云原生计算基金会（CNCF）宣布，CNCF 技术监督委员会（TOC）已投票通过 Karmada 为正式孵化项目。Karmada 是华为云捐赠的云计算开源技术，是业界首个多云多集群容器编排项目。 正式晋升 CNCF 孵化级，也意味着 Karmada 的技术生态受到全球业界广泛认可，在分布式云原生技术领域进入了成熟新阶段。</p><p>作为 CNCF 首个跨云跨集群容器编排引擎，Karmada 由华为云、工商银行、小红书、中国一汽等八家企业联合发起。项目于 2021 年 4 月正式开源，2021 年 9 月加入 CNCF 成为沙箱项目。Karmada 的贡献者来自世界各地，覆盖全球 22 个国家和地区的 60 多家组织，包括华为、DaoCloud、浙江大学、滴滴、腾讯、小红书、新浪、Intel、IBM、Red Hat、Comcast 等公司。截至目前，项目在开源软件项目托管平台 GitHub 已收获超过 3600 Star。</p><p><img alt="cncf.png" src="https://bbs-img.huaweicloud.com/blogs/img/20231213/1702453150429804713.png" referrerpolicy="no-referrer"></p><p><strong>华为云</strong><strong>CTO 张宇昕表示</strong>，华为云长期致力于云原生技术、产业和生态的建设。Karmada 源于社区和华为云在多云管理领域的深厚沉淀，为企业提供了从单集群到分布式云架构的平滑演进方案。「作为 Karmada 项目的发起者和主要贡献者之一，华为云将继续与 CNCF 和社区合作，释放无处不在的云原生价值。」</p><p>「Karmada 开源以来受到了广泛的关注和支持，并帮助越来越多的最终用户在多云环境中高效管理 Kubernetes 集群和分布式应用。」<strong>Karmada 社区创始人兼维护者王泽锋表示</strong>，「我们很高兴 Karmada 已达到 CNCF 孵化状态，并将继续致力于将其发展成更为完善的国际化社区。」</p><p><strong>CNCF 技术监督委员会（TOC）Nikhita Raghunath 表示</strong>，Karmada 填补了 Kubernetes 多云和多集群环境中的调度和编排方面的空白，可以为分布式组织提供更好的性能并降低成本。「自从加入 CNCF Sandbox 以来，项目团队一直不懈地努力添加新特性和功能，以融入更广阔的云原生生态。我们期待看到该项目的持续成长。」</p><p>目前，项目已在华为云、兴业数金、中国移动云、中国联通、携程、vivo、飓风引擎、VIPKID、有赞、网易、快手、之江实验室等 20 多家企业和单位落地应用，以开源创新促进云原生产业发展，项目全球生态发展迅速。Karmada 的创新优势，也得到了企业用户的高度认可。</p><p>「Karmada 使我们能够为 Zendesk 的内部工程团队提供多集群架构，同时保持身份验证、配置交付和服务管理的单点访问。」<strong>Zendesk 计算团队工程经理 Adam Minasian</strong>说到，「随着 Karmada 项目进入 CNCF 孵化阶段，我们很高兴能够继续与该项目合作。」</p><p>「Karmada 为企业落地多云战略提供了便捷的基础设施。它基于中立、厂商无关的设计，让用户在极小代价情况下，灵活接入和切换多云和混合云；同时它为客户在微服务跨集群编排、跨集群弹性伸缩，多云化的访问、容灾等场景带来了便利性。」<strong>DaoCloud 联合创始人兼首席架构师颜开</strong>表示。</p><p>基于对可持续供应的考虑，以及对业务快速扩展的需求，混合云多云已成为携程集团的技术优选。「Karmada 以其标准的 K8s API 兼容性、关注点分离的原则、活跃的社区，帮助我们构建了混合多云的控制面，降低了架构迁移成本和异构环境的管理复杂性。」<strong>携程集团容器与混合云团队总监乐鸿辉</strong>表示，携程借助于 Karmada 实现的故障隔离架构和多集群 HPA，也帮助公司成功应对旅游业的强劲复苏。</p><p>「Karmada 简化了多集群环境中的集群与应用的交付和管理，实现跨集群的资源协调，以增强应用程序的可用性和弹性。它确保稳定、高效、可控的应用程序部署和更新。」<strong>Shopee 专家工程师李鹤</strong>表示。</p><p>「Karmada 作为开源的多云容器编排平台，为云原生中间件提供了灵活性和可靠的跨平台、跨区域、跨云的资源管理，为中间件同城跨机房高可用提供了基石。」<strong>网易资深开发工程师孟祥勇</strong>表示。</p><p>目前，Karmada 社区已累计更新 67 个版本。晋级 CNCF 孵化项目后，项目进一步规划了社区发展路标，并正在积极添加新功能和特性，如多集群安全、大规模场景应用、多集群可观测性、多集群应用分发、生态融合发展等。</p><p>作为 CNCF 亚洲唯一创始成员、白金会员，华为云在 CNCF 贡献量、Kubernetes 社区和 Istio 社区的代码贡献量持续多年稳居亚洲第一，已向 CNCF 贡献了业界首个云原生边缘计算项目 KubeEdge、首个云原生批量算力项目 Volcano 等多个重量级云原生开源项目，并持续开源 Kurator、Kappital、Kuasar 等创新项目，与全球云原生社区共同发展。华为云 UCS 作为业界首发的分布式云原生服务，基于 Karmada 项目构建全新的应用算力供给模式，覆盖中心 Region、专有 Region、边缘云、客户数据中心和第三方云场景，提供无处不在的云原生能力，为云原生服务提供跨云跨地域一致性体验。</p><p>Karmada 正式晋级 CNCF 孵化项目，进一步展现了华为云持续践行开源、拥抱开源，与全球开发者共创先进技术的理念，持续助力云上开源创新生态发展。未来，Karmada 将持续探索云原生多云多集群领域技术创新，让基于 Karmada 的多云方案融入更广泛的云原生技术生态。</p><p>Karmada 官网：<u>https://karmada.io/</u></p><p>项目地址：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkarmada-io%2Fkarmada" rel="nofollow" target="_blank">https://github.com/karmada-io/karmada</a></u></p><p>Slack 地址：https://slack.cncf.io/</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>点击关注，第一时间了解华为云新鲜技术~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10321412</guid>
            <link>https://my.oschina.net/u/4526289/blog/10321412</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年，PHP 停滞不前]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>热心开发者分析了一波 GitHub 的数据后发现，<strong>编程语言为 PHP 的 PR 数量逐年下降</strong>。</p><p><strong>GitHut&nbsp;</strong>是通过 GitHub 数据专门分析编程语言的项目。它基于各种编程语言在 GitHub 中的使用情况，挖掘编程语言在开发者中的受欢迎程度，并发现每种语言的独特之处。</p><p>GitHub 本身提供了公开的 API，支持与其庞大的事件数据集与托管仓库进行交互。GitHub Archive 则更进一步，汇总并存储了 API 的长期数据。</p><p>GitHut 2.0 使用的定量数据通过 Google BigQuery 从 GitHub Archive 数据集进行收集。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmadnight.github.io%2Fgithut%2F%23%2Fpull_requests%2F2023%2F3" target="_blank">从 GitHut 最新公布的数据来看</a></u>，<strong>开发者在 GitHub 提交的 PR 中，所使用语言为 PHP 的数量逐年下降</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8f21cb80016974c4473515841593e0a1dbd.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-48434852dee054fa4d246d1387188cac51e.png" referrerpolicy="no-referrer"></p><p>因此，有人直言：「<strong>2023 年，PHP 停滞不前</strong>」：</p><p><img src="https://oscimg.oschina.net/oscnet/up-8ebd5b97a696dcedfeafd1c2b1a5e6a9bbb.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F18hgduc%2Fgithub_says_php_is_the_most_stagnating_language%2F" target="_blank">https://www.reddit.com/</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270973</guid>
            <link>https://www.oschina.net/news/270973</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[数据库圈的夜郎自大，危！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>作者：尹海文，Oracle ACE，OCM 11g/12c/19c，MySQL 8.0 OCP，墨天轮 MVP、技术专家，ITPUB 核心专家，OCM 讲师，网思科技 DBA 总监。</p><p>微信公众号：<span style="color:#576b95">胖头鱼的鱼缸</span></p><p><img height="200" src="https://oscimg.oschina.net/oscnet/up-2246bd76f586b377330839cc13eda5af742.jpg" width="200" referrerpolicy="no-referrer"></p></blockquote><p>今天看到薛首席在 OSCHINA 邀稿的一篇文章<a href="https://my.oschina.net/u/3859945/blog/10321019">《国产数据库的出现和消失，都不是技术问题》</a>及其评论，感触颇多，忍不住得写一篇文章。</p><span id="OSC_h2_1"></span><h2>0 和 1 的艺术</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">现在计算机，归根结底是二极管的使用艺术，即开与合，0 和 1，运行在硬件之上无论是操作系统、软件还是其他什么的，都是对二进制的使用，本质还是和数学打交道。以数据库为例，其中的各项算法都得和这最基础的数学打交道，涉及基本的二进制、硬件固件、硬件指令集、硬件驱动等等与软件运行之间的结合。我一直没搞懂总有人在说，近几十年来很多涉及数据库数学层面的东西没有进步，我们随随便便就能赶超？！</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">我是一个高中文科大学园林设计专业的 DBA，我无法从深层次的数学层面来解释一些东西，但是我可以通过一些方法来展现结果：安安分分用相同的配置在 Oracle 11g vs 19c、MySQL 5.6 vs 8.0、PG 9 vs 16 跑跑完全相同的东西，抹平所谓的硬件带来的进步，看看性能有没有提升（别说难搞，大不了一台 4C16GB 虚拟机轮流测试）。</p><span id="OSC_h2_2"></span><h2>带宽的瓶颈</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">说起带宽瓶颈以前一直说是磁盘 IO 瓶颈，传统的 HDD 顶多 300MB/s 和几百几千 IOPS 的性能确实不够看。但现在的传输带宽，还是存在一个比较尴尬的情况，大多数网络都是以万兆为主，之前我的文章也讲过，现在主流的 PCIe4.0 x4 NVMe SSD 单盘极限带宽能来到 4000MB/s，即是一块 SSD 即可占满万兆网络（1250MB/s），而主流的 32GBps 的 HBA 卡也可以一块 SSD 占满，40GBps 的 IB 交换机勉强支撑一块 SSD，100GBps 的 RoCE 交换机 3 块 SSD 即超越，再往上多路的话依次类推，总之在 NVMe SSD 越来越廉价的今天，即使考虑<span>随机读写</span>的性能衰减问题，数量不多的 SSD 也能占满单机的带宽。</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">在磁盘性能&gt;传输性能的当下，我仍然能听到，就对比 Oracle Exadata 的基于 X86 服务器的分布式存储来说，专用存储设备更好。Oracle Exadata 存储层做了啥，Exadata Storage Software 充分利用了硬件特性与软件结合，在存储内部就实现数据的过滤筛选，<span style="background-color:#fbfbfb; color:#24292e">减少网络传输层面的带宽需求，</span>让 NVMe SSD、PMEM 这些高性能磁盘设备发挥真正的作用而不是去撑爆网络。就专用存储而言，无法突破使用服务器的传输瓶颈，即使 IO 再强劲，出口带宽再大，也只能突增使用存储设备的服务器数量；而对於单机服务器配置大量高性能磁盘来说，特别是用于分布式数据库中的跨分片操作，只要数据量稍微大一些，网络就很难扛得住（不一定是磁盘引起的也可以是内存），这也是为啥分布式数据库建议把关联数据放在一个分片内（这得从数据库层面干掉多少需求或者说是一些需求就不能用分布式数据库实现）。</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">回头看看本节一开始，为啥当年有分布式，我个人认为单机性能不足需要更多机器来堆，但是现在一块小小的 SSD 比曾经几十上百台集群整体 IO 性能还好的情况下，分布式是不是又成为了一个伪需求。再看 Exadata 的解决方案，充分利用硬件的存储分布式+数据库集中式，是不是更合理呢。</p><p style="margin-left:0px; margin-right:0px; text-align:center"><img height="541" src="https://oscimg.oschina.net/oscnet/up-96f480f7817145b83bf512d2552cbc09163.png" width="1080" referrerpolicy="no-referrer"></p><span id="OSC_h2_3"></span><h2>「遥遥领先」</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">不知何时开始，估摸着是电影《西红柿首富》的「卧龙凤雏」开始，很多曾经的赞美之词，现在也蒙上了贬义词的阴影，其中就有来自某大厂某大嘴的「遥遥领先」。我已经不止一次在国产数据库沟通、宣传材料（包含潜台词）、行业形势宣传中看到，<span>咱们的很多产品已经遥遥领先于 Oracle、DB2、SQLServer、MySQL、PostgreSQL</span>这些国外数据库产品（我也不知道后两个那么多套壳的好意思说出口）。</p><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">回到之前写过的，数据库是一个需要长期时间去磨砺的基础系统工程，不是把一大堆所谓的「先进理念、先进架构、先进算法（特别是只会拿来用不知道到底怎么实现的算法）」缝合在一起，倒腾出数据库产品就能很牛逼的？！这样带来的只能是所谓的快速追赶进度，真要追得上，以这种忽略地基的方式是不可能实现的。</p><span id="OSC_h2_4"></span><h2>总结</h2><p style="color:#24292e; margin-left:0; margin-right:0; text-align:left">数据库圈，正视差距不丢人，夜郎自大才丢人，所谓的「遥遥领先」最终带来的是系统的危险。&nbsp;&nbsp;&nbsp;&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10321420</guid>
            <link>https://my.oschina.net/u/3859945/blog/10321420</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[VMware 产品全面改为订阅制]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Broadcom 发布新闻稿称，公司已大幅简化了 VMware 的产品线，<strong>并完成了所有 VMware 产品从买断制向订阅制的转变</strong>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-8022b562fee7c21769f54eba21a0318e820.png" referrerpolicy="no-referrer"></p><p>来源：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.vmware.com%2Fcompany%2Fvmware-by-broadcom-business-transformation" target="_blank">https://news.vmware.com/company/vmware-by-broadcom-business-transformation</a></u></p></blockquote><p><strong>从 12 月 11 日开始，VMware 停止永久许可证的销售</strong>，此前购买过永久授权的用户可以获得订阅购买计划的积分 (trade in)，以便将永久许可证产品换到新订阅产品。永久许可证以及支持和订阅续订结束后，产品将仅以订阅或定期许可证的形式提供。此外，已拥有永久许可证的用户还能够继续获得使用许可和产品支持。</p><p>VMware 称，其旗舰企业级混合云解决方案 VMware Cloud Foundation 订阅价降低一半，并推出新的面向中小企业的产品 VMware vSphere Foundation。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270967/vmware-by-broadcom-business-transformation</guid>
            <link>https://www.oschina.net/news/270967/vmware-by-broadcom-business-transformation</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[删库并嘲讽同事，云工程师被判处两年监禁、赔款 52.9 万美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">disgruntled-cloud-engineer-sentenced-two-years-prison</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">美国司法部 (DoJ) 发布了一则公告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.justice.gov%2Fusao-ndca%2Fpr%2Fdisgruntled-cloud-engineer-sentenced-two-years-prison-intentionally-damaging-his" target="_blank">宣布</a>，因入侵网络和向政府机构作虚假陈述，判处 38 岁的云工程师 Miklos Daniel Brody 两年监禁，并支付 529266.37 美元的赔偿金。&nbsp;</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Brody 曾在旧金山第一共和银行 (FRB) 担任云工程师，直到 2020 年 3 月 11 日因为违反公司政策被解雇。原因是他将包含色情内容的 USB 驱动器连接到公司计算机，因此被终止了雇佣关系。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">被解雇后，Brody 拒绝归还他的工作笔记本电脑，并在被解雇当晚继续使用他仍然有效的账户访问银行的计算机网络，展开一系列报复。在量刑听证会上，法官判定因 Brody 所造成的银行系统损坏的总成本至少为 220,621.22 美元。</span></span></p><blockquote><p><span style="color:#000000">「Brody 删除了银行的代码库，运行恶意脚本删除日志，在银行代码中留下对前同事的嘲讽，并冒充银行的其他员工以他们的名义打开会话。他还通过电子邮件向自己发送了他作为员工时编写的银行专有代码，价值超过 5000 美元。」</span></p></blockquote><p style="margin-left:0; margin-right:0; text-align:start"><img height="307" src="https://oscimg.oschina.net/oscnet/up-388d14f405275a3f7c1595c9aff84cc89a7.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">总的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Fcloud-engineer-gets-2-years-for-wiping-ex-employers-code-repos%2F" target="_blank">来说</a>，在 2020 年 3 月 12 日最终终止对 FRB 网络的访问之前，Brody 共执行了以下操作：</span></span></p><ul><li><span style="color:#000000">运行名为「dar.sh」的恶意脚本来清除 FRB 的服务器</span></li><li><span style="color:#000000">删除了特定脚本的 git 日志和 git 提交历史记录</span></li><li><span style="color:#000000">访问 FRB 的 GitHub 存储库并删除所托管的代码</span></li><li><span style="color:#000000">在代码中插入「嘲讽」语句，包括对「grok」的引用</span></li><li><span style="color:#000000">冒充 FRB 的另一位云工程师访问该公司的网络并进行配置更改</span></li></ul><p><span style="color:#000000">之后为了逃避责任，<span style="background-color:#ffffff">Brody 向警局谎称&nbsp;</span>FRB <span style="background-color:#ffffff">配发的笔记本电脑被人偷走。且在&nbsp;2021 年 3 月被捕后，在向美国国家安全局特工发表的声明中进一步强调了这一虚假指控。最终在 2023 年 4 月，Brody 承认了自己在笔记本电脑问题上进行了虚假陈述，并承认两项有关违反《计算机欺诈和滥用法》的指控：</span></span></p><ul><li><span style="color:#000000"><span style="background-color:#ffffff">从受保护的计算机获取信息，违反了 18 USC § 1030(a)(2)(C) (c)(2)(B)</span></span></li><li><span style="color:#000000"><span style="background-color:#ffffff">以及故意损坏受保护的计算机，违反 18 USC § 1030(a)(5)(A) 和 (c)(4)(B)(i) </span></span></li></ul><p><span style="color:#000000">还有<span style="background-color:#ffffff">一项向政府机构做出虚假陈述的指控，违反了 18 USC § 1001(a)(2)</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 03:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270966/disgruntled-cloud-engineer-sentenced-two-years-prison</guid>
            <link>https://www.oschina.net/news/270966/disgruntled-cloud-engineer-sentenced-two-years-prison</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 内核删除「高龄」驱动补丁，但它支持的设备似乎从未存在过？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>英特尔多年来一直为其硬件产品提供非常及时的 Linux 上游支持。通常来说，他们会在产品计划公开发布很早之前就启动相关工作。</p><p>在许多情况下，这就意味着英特尔在 Linux 内核中添加了某些硬件支持补丁——<strong>但这些硬件最终不会面向消费者发布</strong>。比如最近的 Thunder Bay 支持，在明确 SoC 永远不会发布后，内核就删除了对该硬件的支持。</p><p>但现在出现了一个更极端的情况，<strong>一个驱动程序在主线内核中存在了 15 年，却是为了支持从未发布的硬件</strong>。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20231208224703.1603264-1-willy%40infradead.org%2F" target="_blank">根据 Linux 内核最近的提交</a></u>，维护者准备删除支持英特尔"Carillo Ranch"硬件产品的&nbsp;<span>2000 多行驱动程序代码（</span>fbdev 驱动，和 backlight 驱动）<span>，删除的原因是</span>"Carillo Ranch"<span>似乎根本就不存在。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-5fcc2aa84734ff67c32a2166c1742c636e4.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FLinux-Drop-Intel-Carillo-Ranch" target="_blank">据了解</a></u>，Carillo Ranch 是一款 90 纳米的 32 位单核处理器，主频为 1.2GHz，热设计功耗为 19 瓦，适用于嵌入式设备。</p><blockquote><p>「据任何人所知，这款产品从未发布。即使发布了，它也是在 2007 年推出的，再也没有人能够使用它了。」</p></blockquote><p>早在 2007 年，英特尔就资助了 Tungsten Graphics（该公司在被 VMware 收购之前推动了 Mesa 的开发），为 Carillo Ranch 开发<strong>帧缓冲区 (FBDEV) 驱动程序</strong>。还有一个<strong> MTD Carillo Ranch 驱动程序</strong>，英特尔在 2006 年资助 MontaVista 开发该驱动程序。</p><p>如果在谷歌搜索"Intel Carillo Range"以寻找出处，会被重定向至「Intel Carrillo Range」(注意多了个字母 r)，而唯一的搜索结果会跳转到 MontaVista 的一份联系方式表格。表格里有一句话：「<em>我们希望听到关于这款主板的更多信息：兼容英特尔 Carrillo Ranch 奔腾 M，集成 Vermillion Range</em>」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-f1e624bba0ef26989427fb903aea4efe72c.png" referrerpolicy="no-referrer"></p><p>来源&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mvista.com%2Fcontactus%2FBoard%3A%2520Intel%2520Carrillo%2520Ranch%2520Pentium%2520M%2520compatible%2520Vermillion%2520Range%2FICH7%2520based%2520dev%2520platform" target="_blank">https://www.mvista.com</a></em></u></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 02:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270960/linux-drop-intel-carillo-ranch</guid>
            <link>https://www.oschina.net/news/270960/linux-drop-intel-carillo-ranch</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[cprobe —— All-in-One 的探针采集器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start">cprobe 是一个缝合怪，整合 Prometheus 服务发现的能力以及各类 Exporter 的能力，预期是做一个 All-in-One 的探针采集器。为何有此想法呢？主要是社区里各类 Exporter 存在以下问题：</p><ul><li>良莠不齐：有的 Exporter 写的非常棒，有的则并不完善，有些监控类别甚至有多个 Exporter，选择困难</li><li>写法各异：Exporter 所用的日志库、配置文件管理方式、命令行传参方式各异</li><li>倚重边车模式：有些 Exporter 和采集目标之间是一对一的关系，有几个采集目标就需要部署几个 Exporter，在 Kubernetes 环境下相对容易管理，在物理机虚拟机环境下管理起来就比较复杂了，而且多个 Exporter 还会带来资源成本的提升</li><li>配置文件切分：对于非边车模式的 Exporter，即一个 Exporter 对应多个采集目标的，通常很难做到不同的采集目标不同的配置，期望能有一种配置文件切分 INCLUDE 机制，不同的采集目标采用不同的配置</li><li>缺乏监控目标服务发现：对于支持 /probe 模式的 Exporter，服务发现就通过 Prometheus + relabel 模式来实现了，如果不支持 /probe 模式的 Exporter 则缺乏监控目标的服务发现机制</li></ul><p>要是能有一个统一的采集器把这些能力集成起来，统一规范化设计就好了，cprobe 应运而生。</p><h2 style="text-align:start">对比</h2><p style="color:#1f2328; text-align:start">社区有一些其他采集器，比如 grafana-agent，也是一个缝合怪，也是把各类 Exporter 的能力整合在一起，但是整合的非常生硬，缺少统一化设计，对目标实例的服务发现支持较弱；telegraf 和 categraf 则自成一派，指标体系没有拥抱 Prometheus exporter 生态，相关仪表盘、告警规则资源匮乏，另外服务发现机制做的也不好。datadog-agent 确实比较完备，但是生态上也是自成一派，服务于自身的 SaaS 服务，较少有开源用户采用。</p><p style="color:#1f2328; text-align:start">以我当前的认知，监控数据的采集大抵需要三个角色，一个是部署在所有的目标机器上的，比如使用 categraf，中心端需要两个采集器，一个用于采集 Prometheus 协议的端点数据，可以使用 vmagent 或 Prometheus agent mode，另外一个用于采集所有非 Prometheus 协议的端点数据，计划就是 cprobe。</p><h2 style="text-align:start">当前进展</h2><p style="color:#1f2328; text-align:start">cprobe 刚刚起步，目前主要是在完善基础框架，框架层面已经达到 GA 的水平，插件已经整合进来了 mysql_exporter、redis_exporter、kafka_exporter、blackbox_exporter。这个时候的代码是最为简单清晰的最小功能集，如果大家想要参与，建议阅读此时的代码。</p><p style="color:#1f2328; text-align:start">代码仓库：<a href="https://github.com/cprobe/cprobe">https://github.com/cprobe/cprobe</a></p><h2 style="text-align:start">安装</h2><p style="color:#1f2328; text-align:start">到 cprobe 的 releases 页面<span>&nbsp;</span><a href="https://github.com/cprobe/cprobe/releases">https://github.com/cprobe/cprobe/releases</a><span>&nbsp;</span>下载发布包。解包之后核心就是那个二进制 cprobe，通过如下命令安装：</p><div style="text-align:start"><pre>./cprobe --install
./cprobe --start
</pre></div><p style="color:#1f2328; text-align:start">如果是支持 systemd 的 OS，上面的安装过程实际就是自动创建了 service 文件，你可以通过下面的命令查看：</p><div style="text-align:start"><pre>systemctl status cprobe
</pre></div><p style="color:#1f2328; text-align:start">如果不是 systemd 的 OS，会采用其他进程管理方式，比如 Windows，会创建 cprobe 服务。</p><h2 style="text-align:start">配置</h2><p style="color:#1f2328; text-align:start">解压缩之后应该可以看到 conf.d 目录，这是配置文件所在目录，未来的规划是 writer.yaml + 一堆插件目录，当然项目起步阶段，所以只有 writer.yaml + mysql，因为只有 mysql 一个插件得到支持。</p><p style="color:#1f2328; text-align:start">writer.yaml 是配置 remote write 地址（不知道什么是 remote write 地址，请自行 Google：Prometheus remote write），可以配置多个，默认配置如下：</p><div style="text-align:start"><pre><span style="color:var(--color-prettylights-syntax-entity-tag)">global</span>:
  <span style="color:var(--color-prettylights-syntax-entity-tag)">extra_labels</span>:
    <span style="color:var(--color-prettylights-syntax-entity-tag)">colld</span>: <span style="color:var(--color-prettylights-syntax-string)">cprobe</span><span style="color:var(--color-prettylights-syntax-entity-tag)">writers</span>:
- <span style="color:var(--color-prettylights-syntax-entity-tag)">url</span>: <span style="color:var(--color-prettylights-syntax-string)">http://127.0.0.1:9090/api/v1/write</span></pre></div><p style="color:#1f2328; text-align:start">这是一个极简配置，也基本够用，实际 writer.yaml 中还可以配置不同时序库后端的认证信息以及 relabel 的配置，同级目录下有个 backup.yaml 可以看到一些配置样例。</p><p style="color:#1f2328; text-align:start">不同的插件的配置会散落在各个插件目录里，以 mysql 插件举例，相关配置在<span>&nbsp;</span><code>conf.d/mysql</code><span>&nbsp;</span>下面，入口文件是 main.yaml，用于定义需要采集的 mysql target，计划至少提供三种 service discovery 机制：static_configs、http_sd_configs、file_sd_configs，这个配置和 Prometheus 的 scrape 配置基本保持一致。</p><p style="color:#1f2328; text-align:start">在 cprobe 场景下，cprobe 会直连监控目标，比如 mysql 的监控，Prometheus 是从 mysqld_exporter 获取监控数据，而 cprobe 是直连 mysql，所以 main.yaml 中要配置一些采集规则，即 scrape_rule_files。scrape_rule_files 是个数组，即可以把配置文件切分管理，这提供了极大的管理灵活性，各位自行发挥了。</p><p style="color:#1f2328; text-align:start">mysql 的采集插件 fork 自 mysqld_exporter，所以相关指标体系、仪表盘都可以复用。当然，也做了一些改造，原来 mysqld_exporter 是一套采集规则应用到所有的 target，在 cprobe 这里，不同的 target 可以采用不同的 scrape_rules，修改了原来通过命令行传参的机制以支持并发。另外就是扩展了自定义 SQL 能力，通过自定义 SQL 来抓取更多监控指标。更多信息可以参考：<a href="https://github.com/cprobe/cprobe/tree/main/conf.d/mysql/doc">mysql 插件文档</a>。</p><h2 style="text-align:start">后续规划</h2><p style="color:#1f2328; text-align:start">最核心的是增加更多插件，不同的插件要整理仪表盘、告警规则。框架层面，希望增加更多自埋点数据，通过 HTTP 的方式暴露更多调试信息。另外就是完善中英文文档。当然，大家如有建议也欢迎留言给我们。</p></div>
                                                                ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/cprobe</guid>
            <link>https://www.oschina.net/p/cprobe</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 自主开发的网络协议栈 onps]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-onps 网络协议栈" class="anchor" href="https://gitee.com/Neo-T/open-npstack#onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88"></a>onps 网络协议栈</h1><h4><a id="user-content-背景" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%83%8C%E6%99%AF"></a>背景</h4><p>大约是 06 年，因项目之需我开始接触应用於单片机系统的国外开源 tcp/ip 协议栈——LwIP，并借此顺势创作了我的第一本印成铅字的书——《嵌入式网络系统设计——基于 Atmel ARM7 系列》。这本书的反响还不错，好多人给我发 msn（可惜这么好的一个即时通讯工具就这么被微软放弃了，好多联系人就此失联， <img class="emoji" alt=":persevere:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/persevere-1f8fa05847efd349c0f2c62b1cee5bd1.png" width="14" height="14" referrerpolicy="no-referrer"> ）或邮件咨询相关问题。在我原来的写作计划中，这本书的出版只是一个开始，接下来还要写第二本——系统介绍 LwIP 包含的 ppp 协议栈的移植、应用及设计实现等相关内容。但，事与愿违，这本书跳票了，且这一跳就是十二年……</p><p>细细想来，当初跳票的主因有二：其一，因家庭、工作等致可支配时间太少；其二，缺乏足够的 ppp 协议相关知识及技术储备致信心不足，畏首畏尾，裹足不前。但，这件事始终是我的一个遗憾。十二年的时间，不长亦不短，但足够让心底的遗憾变成一粒小小的种子并茁壮成长为一棵梦想的参天大树。</p><p>如今，世界来到了疫情肆虐的二零年代。我的可支配时间多了起来，技术能力亦远非当年可比。梦想之树到了开花结果的时候了。遥想当初，入行还没几年，技术能力有限，我只能站在大神的肩膀上研究如何移植、使用 LwIP，ppp 栈碰都没敢碰。现在，如果还只是延续十几年前的工作，那这件事做起来就无甚意义。基于对自身技术实力的准确认识，我决定自己从零开始搭建一个完整的网络协议栈。终，历 6 个月余，onps 协议栈（onps，open net protocol stack）完成初版开发，并内部测试通过。十余年的遗憾今日得偿。另，从业 20 余年，内心终有一个做核心基础软件的梦。今，这二之梦想亦借此得偿。</p><p>新莺初啼，总免不了会有诸多不尽如人意的地方。开源，则可与志趣相投者共享、共用、共研，历诸位严苛手段使之快速迭代，快速成熟，比肩 LwIP 可期 <img class="emoji" alt=":blush:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/blush-85d11d8b7459d18f70eab0659c19a266.png" width="14" height="14" referrerpolicy="no-referrer"> 。</p><h4><a id="user-content-简介" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%AE%80%E4%BB%8B"></a>简介</h4><p>onps 是一个开源且完全自主开发的国产网络协议栈，适用于资源受限的单片机系统，提供完整地 ethernet/ppp/tcp/ip 协议族实现，同时提供 sntp、dns、ping 等网络工具，支持以太网环境下 dhcp 动态 ip 地址申请，也支持动态及静态路由表。协议栈还封装实现了一个伯克利套接字（Berkeley sockets）层。该层并没有完全按照 Berkeley sockets 标准设计实现，而是我根据以往 socket 编程经验，以方便用户使用、简化用户编码为设计目标，重新声明并定义了一组常见 socket 接口函数：</p><ul><li>socket：创建一个 socket，目前仅支持 udp 和 tcp 两种类型</li><li>close：关闭一个 socket，释放当前占用的协议栈资源</li><li>connect：与目标 tcp 服务器建立连接（阻塞型）或绑定一个固定的 udp 服务器地址</li><li>connect_nb：与目标 tcp 服务器建立连接（非阻塞型）</li><li>is_tcp_connected：获取当前 tcp 链路的连接状态</li><li>send：数据发送函数，tcp 链路下为阻塞型</li><li>send_nb：数据发送函数，非阻塞型</li><li>is_tcp_send_ok：数据是否已成功送达 tcp 链路的对端（收到 tcp ack 报文）</li><li>sendto：udp 数据发送函数，发送数据到指定目标地址</li><li>recv：数据接收函数，udp/tcp 链路通用</li><li>recvfrom：数据接收函数，用于 udp 链路，接收数据的同时函数会返回数据源的地址信息</li><li>socket_set_rcv_timeout：设定 recv() 函数接收等待的时长，单位：秒</li><li>bind：绑定一个固定端口、地址</li><li>listen：tcp 服务器进入监听状态</li><li>accept：接受一个到达的 tcp 连接请求</li><li>tcpsrv_recv_poll：tcp 服务器专用函数，等待任意一个或多个 tcp 客户端数据到达信号</li><li>socket_get_last_error：获取 socket 最近一次发生的错误信息</li><li>socket_get_last_error_code：获取 socket 最近一次发生的错误编码</li></ul><p>协议栈简化了传统 BSD socket 编程需要的一些繁琐操作，将一些不必要的操作细节改为底层实现，比如 select/poll 模型、阻塞及非阻塞读写操作等。简化并不意味着推翻，socket 接口函数的基本定义、主要参数、使用方法并没有改变，你完全可以根据以往经验及编程习惯快速上手并熟练使用 onps 栈 sockets。 <strong>无须过多关注协议栈底层，利用 socket api 编程即可完全满足复杂通讯应用的需求，而不像 LwIp 一样需要使用它自定义的一组接口函数才能达成同样的目标。</strong></p><p>为了适应单片机系统对内存使用极度变态的苛刻要求，onps 协议栈在设计之初即考虑采用写时零复制（zero copy）技术。用户层数据在向下层协议传递过程中，协议栈采用 buf list 链表技术将它们链接到一起，直至将其发送出去，均无须任何内存复制操作。另外，协议栈采用 buddy 算法提供安全、可靠的动态内存管理功能，以期最大限度地提高协议栈运行过程中的内存利用率并尽可能地减少内存碎片。</p><p>不同于本世纪 00 到 10 年代初，单片机的应用场景中 ucosii 等 rtos 尚未大规模普及，前后台系统还大行其道的时代，现如今大部分的应用场景下开发人员选择使用 rtos 已成为主流。因此，协议栈在设计之初即不支持前后台模式，其架构设计建立在时下流行的 rtos（RT-Thread、ucosii/iii 等）之上。协议栈移植的主要工作也就自然是针对不同 rtos 编写相关 os 适配层功能函数了。当然，如果你有着极其特定的应用场景，需要将 onps 栈移植到采用前后台模式的单片机上，我的建议是保留 tcp/udp 之下协议层的通讯处理逻辑，调整上层的系统架构使其适应目标系统运行模式。</p><h4><a id="user-content-软件架构" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84"></a>软件架构</h4><p>onps 栈设计实现了一套完整的 tcp/ip 协议模型。从数据链路层到 ip 层，再到 tcp/udp 层以及之上的伯克利 socket 层，最后是用户自己的通讯应用层，onps 栈实现了全栈覆盖，能够满足绝大部分的网络编程需求。其架构如下：
<img src="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="onps 栈架构" referrerpolicy="no-referrer"></p><p>可以看出，其与传统的网络编程模型并没有什么不同，用户仍然是继续利用 socket api 编写常见的 tcp 及 udp 网络应用。同时你还可以利用协议栈提供的几个网络工具进行网络校时、dns 查询等操作。</p><h4><a id="user-content-目录结构" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"></a>目录结构</h4><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td>bsd</td><td>伯克利 sockets 层的相关接口函数实现源文件</td></tr><tr><td>ethernet</td><td>以太网协议族如 ethernet-ii/arp 及 emac 层、dhcp 客户端等的相关实现源文件</td></tr><tr><td>include</td><td>协议栈的头文件</td></tr><tr><td>ip</td><td>ip 及其上层 icmp/tcp/udp 协议族的相关实现源文件</td></tr><tr><td>mmu</td><td>协议栈内存管理模块的相关实现源文件</td></tr><tr><td>net_tools</td><td>网络工具实现源文件，如 dns 查询、网络校时、ping、telnet 等</td></tr><tr><td>netif</td><td>网卡及路由管理等相关接口实现源文件</td></tr><tr><td>port</td><td>协议栈移植相关的源文件</td></tr><tr><td>ppp</td><td>ppp 链路层相关实现源文件，包括 lcp/ipcp/chap/pap 等协议族的实现源文件</td></tr><tr><td>TcpServerForStackTesting</td><td>用于协议栈测试的 tcp 服务器，IDE 为 vs2015 开发，目标系统为 win7 及以上</td></tr><tr><td>test_code</td><td>linux 下的 ppp 拨号原理验证文件</td></tr></tbody></table><h4><a id="user-content-移植及使用说明" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A7%BB%E6%A4%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"></a>移植及使用说明</h4><p>协议栈支持主流的 ARM Cortex 系列 MCU，支持 Keil MDK、IAR 等常见 IDE。移植的核心工作就是完成 RTOS 模拟层的编写及适配，详细的移植说明请参考《onps 网络协议栈移植及使用说明 v1.0》一文，点此<a href="https://gitee.com/Neo-T/open-npstack/releases/download/v1.0.0.221017/onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E7%A7%BB%E6%A4%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8Ev1.0.7z">下载</a>。本说明提供了 STM32F103RCT6 及 STM32F407VET6 两种硬件平台的移植样例，每种样例分别针对 RT-Thread 和 ucosii 两种 RTOS。样例工程经过了严格的内部测试，可以直接使用。</p><p>如果你没有太多时间，或者样例工程与你的目标平台并不匹配，你可以直接参考协议栈移植的一般性指导文件<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E7%A7%BB%E6%A4%8D%E6%89%8B%E5%86%8C.pdf">《onps 栈移植手册》</a>。</p><p>协议栈开发的一般性指导文件请参考<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88API%E6%8E%A5%E5%8F%A3%E6%89%8B%E5%86%8C.pdf">《onps 栈 API 接口手册》</a>及<a href="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E6%A0%88%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.pdf">《onps 栈用户使用手册》</a>。</p><h4><a id="user-content-移植样例" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A7%BB%E6%A4%8D%E6%A0%B7%E4%BE%8B"></a>移植样例</h4><p><strong>STM32F407VET6 平台</strong> ：
<a href="https://gitee.com/Neo-T/onps-rtthread">RT-Thread 移植样例</a><a href="https://gitee.com/Neo-T/onps-ucosii">ucos-ii 移植样例</a></p><p><strong><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307">沁恒 CH32V307 平台</a></strong> ：
<a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/HarmonyOS/LiteOS_m">鸿蒙 LiteOS-M 移植样例</a><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/FreeRTOS">Free-rtos 移植样例</a><a href="https://gitee.com/Neo-T/Onps-WCH-CH32V307/tree/master/rt-thread">RT-Thread 移植样例</a></p><h4><a id="user-content-社区支持" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E7%A4%BE%E5%8C%BA%E6%94%AF%E6%8C%81"></a>社区支持</h4><p>您可以随时访问<a href="https://gitee.com/link?target=http%3A%2F%2Fwww.onps.org.cn"><strong>onps 栈官方网站</strong></a>，获取协议栈研发进度、后续计划、最新版本等相关信息。<br>如您在使用过程中遇到任何问题或建议，您可以到 <strong><a href="https://gitee.com/link?target=http%3A%2F%2Fneo.onps.org.cn">onps 栈交流社区</a></strong> 提出您的建议或问题，新版本发布也会在交流社区第一时间通知。<br>您也可以加入 QQ 群进行在线技术交流：<br><img src="https://gitee.com/Neo-T/open-npstack/raw/master/onps%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%8A%80%E6%9C%AF%E4%BA%A4%E6%B5%81%E7%BE%A4%E7%BE%A4%E4%BA%8C%E7%BB%B4%E7%A0%81.png" alt="qq 交流群" referrerpolicy="no-referrer"></p><h4><a id="user-content-许可协议" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE"></a>许可协议</h4><p>Apache License 2.0 开源许可协议</p><h4><a id="user-content-通过 oscs 安全认证" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E9%80%9A%E8%BF%87oscs%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81"></a>通过 OSCS 安全认证</h4><p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.murphysec.com%2Faccept%3Fcode%3D64bea0edfe145ac454cc464b23659406%26type%3D1%26from%3D2%26t%3D2"><img src="https://www.murphysec.com/platform3/v3/badge/1615596818625232896.svg?t=1" alt="Security Status" referrerpolicy="no-referrer"></a></p><h4><a id="user-content-后续计划" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E5%90%8E%E7%BB%AD%E8%AE%A1%E5%88%92"></a>后续计划</h4><ul><li>更多目标平台的适配工作， 提供相应移植样例</li><li>重构部分代码， 进一步降低代码尺寸及内存消耗</li><li>支持 ftp 客户端/服务器</li><li>支持 http 客户端/服务器</li></ul><h4><a id="user-content-捐赠" class="anchor" href="https://gitee.com/Neo-T/open-npstack#%E6%8D%90%E8%B5%A0"></a>捐赠</h4><p>为了项目能够持续下去，期望得到您的支持，您可以扫描下面的二维码通过支付宝/微信向本项目捐款：</p><p><img src="https://gitee.com/Neo-T/open-npstack/raw/master/alipayn.jpg" alt="支付宝" referrerpolicy="no-referrer"><img src="https://gitee.com/Neo-T/open-npstack/raw/master/tencentpay.jpg" alt="微信" referrerpolicy="no-referrer"></p>]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/Neo-T/open-npstack</guid>
            <link>https://gitee.com/Neo-T/open-npstack</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 深度解读 Cascades 查询优化器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>数据库中查询优化器是数据库的核心组件，其决定着 SQL 查询的性能。Cascades 优化器是 Goetz 在 volcano optimizer generator 的基础上优化之后诞生的一个搜索框架。</p><p>本期技术贴将带大家了解 Cascades 查询优化器。首先介绍 SQL 查询优化器，接着分析查询优化基本原理，最后对 Cascades 查询优化器进行重点介绍。</p><span id="OSC_h1_1"></span><h1>一、SQL 查询优化器</h1><p>用户与数据库交互时只需要输入声明式 SQL 语句，数据库优化器则负责将用户输入的 SQL 语句进行各种规则优化，生成最优的执行计划，并交由执行器执行。优化器对于 SQL 查询具有十分重要的意义。</p><p>如图 1 所示，SQL 语句经过语法和词法解析生成抽象语法树 (AST)，经过**基于规则的查询优化（Rule-Based Optimizer）<strong>和</strong>基于代价的查询优化（Cost-Based Optimizer）**生成可执行计划。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-2f53e715e5e2dc13da2ae7593b5a622c7a2.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 1</p><ul><li><p><strong>基于规则的优化算法</strong>:&nbsp;基于规则的优化方法的要点在于结构匹配和替换。应用规则的算法一般需要先在关系代数结构上匹配一部分局部的结构，再根据结构的特点进行变换乃至替换操作。</p></li><li><p><strong>基于成本的优化算法</strong>:&nbsp;现阶段主流的方法都是基于成本（Cost）估算的方法。给定某一关系代数代表的执行方案，对这一方案的执行成本进行估算，最终选择估算成本最低的方案。尽管被称为基于成本的方法，这类算法仍然往往要结合规则进行方案的探索。基于成本的方法其实是通过不断的应用规则进行变换得到新的执行方案，然后对比方案的成本优劣进行最终选择。</p></li></ul><span id="OSC_h1_2"></span><h1>二、查询优化的基本原理</h1><p>优化器一般由三个组件组成：<strong>统计信息收集</strong>、<strong>开销模型</strong>、<strong>计划列举</strong>。</p><p>如图 2 所示，开销模型使用收集到的统计信息以及构造的不同开销公式，估计某个特定查询计划的成本，帮助优化器从众多备选方案中找到开销最低的计划。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-74c10d3f0e3e2443c51805fe0a0d7742ec4.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 2</p><p><strong>SQL 语句查询优化基于关系代数这一模型：</strong></p><ul><li><p>SQL 查询可以转化为关系代数；</p></li><li><p>关系代数可以进行局部的等价变换，变换前后返回的结果不变但是执行成本不同；</p></li><li><p>通过寻找执行成本最低的关系代数表示，我们就可以将一个 SQL 查询优化成更为高效的方案。</p></li></ul><p>寻找执行成本最低的关系代数表示，可以分为<strong>基于动态规划的自底向上</strong>和<strong>基于 Cascades/Volcano 的自顶向下</strong>两个流派。</p><ul><li><p><strong>自底向上搜索</strong>：从叶子节点开始计算最低成本，并利用已经计算好的子树成本计算出母树的成本，就可以得到最优方案；</p></li><li><p><strong>自顶向下搜索</strong>：先从关系算子树的顶层开始，以深度优先的方式来向下遍历，遍历过程中进行剪枝。</p></li></ul><p>自底向上的优化器从零开始构建最优计划，这类方法通常采用动态规划策略进行优化，采用这类方法的优化器包括&nbsp;IBMSystem R。自顶向下的优化策略的优化器包括基于 Volcano 和 Cascades 框架的优化器。</p><span id="OSC_h1_3"></span><h1>三、Cascades 查询优化器</h1><p>Cascades 查询优化器采用自顶向下的搜索策略，并在搜索过程中利用 Memo 结构保存搜索的状态。</p><p><strong>Cascades 关键组件构成：</strong></p><ul><li><p><strong>Expression</strong>：Expression 表示一个逻辑算子或物理算子。如 Scan、Join 算子；</p></li><li><p><strong>Group</strong>：表示等价 Expression 的集合，即同一个 Group 中的 Expression 在逻辑上等价。Expression 的每个子节点都是以一个 Group 表示的。一个逻辑算子可能对应多个物理算子，例如一个逻辑算子 Join(a,b)，它对应的物理算子包括{HJ(a, b), HJ(b, a), MJ(a, b), MJ(b, a), NLJ(a, b), NLJ(b, a)}。我们将这些逻辑上等价的物理算子称为一个 Group（组）。注：HJ 表示 HashJoin 算子，MJ 表示 MergeJoin 算子，NLJ 表示 NestLoopJoin 算子；</p></li><li><p><strong>Memo</strong>：由于 Cascades 框架采用自顶向下的方式进行枚举，因此，枚举过程中可能产生大量的重复计划。为了防止出现重复枚举，Cascades 框架采用 Memo 数据结构。Memo 采用一个类似树状（实际是一个图状）的数据结构，它的每个节点对应一个组，每个组的成员通过链表组织起来；</p></li><li><p><strong>Transformation Rule</strong>：是作用于 Expression 和 Group 上的等价变化规则，用来扩大优化器搜索空间。</p></li></ul><p>Cascades 首先将整个 Operator Tree 按节点拷贝到一个 Memo 的数据结构中，Memo 由一系列的 Group 构成，每个算子放在一个 Group，对于有子节点的算子来说，将原本对算子的直接引用，变成对 Group 的引用。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8f15c28ea323e3c6c3812cb4345b2668089.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 3</p><p>如图 3 所示，生成该语法树的 Memo 初始结构。Memo 结构中一个圆角框代表一个算子，圆角框右下角是对其 Children’s Groups 的引用，左下角是唯一标识符。生成初始的 Memo 结构后，可以采用 transform rule 进行逻辑等价转换，规则如下：</p><ul><li><p>对于一个逻辑算子，其所有基于关系代数的等价表达式保存在同一个 Group 内，例如 join(A,B) -&gt; join(B,A)；</p></li><li><p>在一个 Group 内，对于一个逻辑算子，会生成一个或多个物理算子，例如 join -&gt; hash join,merge join，NestLoop join；</p></li><li><p>一个 Group 内，一个算子，其输入（也可以理解为 subplan）可以来自多个 Group 的表达式。</p></li></ul><p>在图 4 中，描述了一个部分扩展的 Memo&nbsp;结构，与图 1 中的初始 Memo 相比，在同一个 Group 内，增加了等价的逻辑算子，以及对应的物理算子。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-be8b645c303e9167ab3ab1936afe751448f.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图 4</p><p>在探索的过程中，优化器就会通过开销模型 Coster 借助统计信息来计算子步骤的开销，遍历完每个 Memo Group 之后，归总得到每个完整计划的总开销，最终选择 Memo 中开销最低的计划。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-11ec37fc83f5aeeb91f0464308b62d14ecb.png" referrerpolicy="no-referrer"></p><p style="text-align:center">图&nbsp;5</p><p>图 5 中有三个 Group，分别对应三个逻辑算子：Join(a, b), GET(a) 和 GET(b)。Group 1（Group 2）中包含了所有对应 GET(a) （GET(b)）的物理算子，我们可以估算每个物理算子的代价，选取其中最优的算子保留下来。</p><p>为了防止枚举过程出现重复枚举某个表达式，Memo 结构体中还包含一个哈希表（exprHT），它以表达式为哈希表的键，用来快速查找某个表达式是否已经存在于 Memo 结构体中。</p><p>Cascades 采用自顶向下的方式来进行优化，以计划树的根节点为输入，递归地优化每个节点或表达式组。如图所示，整个优化过程从 Group 0 开始，实际上要先递归地完成两个子节点（Group 1 和 Group 2）的优化。</p><p>因此，实际的优化完成次序是 Group 1 -&gt; Group2 -&gt; Group 0。在优化每个 Group 时，依次优化每个组员；在优化每个组员时，依次递归地优化每个子节点。依次估算当前组里每个表达式 e 的代价 cost(e)，选择最低得代价结果保存在 bestHT 中。优化结束时，查询 Join(a,b) 对应的 Memo 结构体，获取最低的执行计划。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 14 Dec 2023 01:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5148943/blog/10320570</guid>
            <link>https://my.oschina.net/u/5148943/blog/10320570</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Soul 上线自研语言大模型 SoulX]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>社交平台 Soul 正式上线自研语言大模型 SoulX。作为生成式人工智能最基础、最核心的工具，SoulX 将作为 Soul 「AIGC+社交」布局的重要基建，垂直应用于平台上多元社交互动场景，例如智能对话机器人「AI 苟蛋」、AI 辅助聊天、虚拟陪伴等诸多工具和创新功能，进一步丰富平台用户的社交体验。</p><p>根据介绍，该模型基于海量数据训练，具备 prompt 驱动、条件可控生成、上下文理解、多模态理解等能力。在保证对话流畅、自然、具备情感温度的同时，SoulX 覆盖百种细粒度风险类别，通过训练数据安全筛选、安全 SFT 数据构造、RLHF 安全对齐、推理拦截等策略来构建安全体系，保证了大模型的内容生产质量和安全性。</p><p><img height="444" src="https://oscimg.oschina.net/oscnet/up-83bee0805ad5819554ad5c4bf7d1885d136.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 10:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270889</guid>
            <link>https://www.oschina.net/news/270889</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MegEngine 正式支持 XLA 啦！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>XLA（Accelerated Linear Algebra）是 Google 提出的一个神经网络编译器，可以用于加速 AI 模型的训练和推理。MegEngine 1.13.1 中也已经支持了 XLA，在训练模型时可以选择开启此项功能，不同的模型可以获得 10%~80% 不等的速度提升。</p><h2>主要的目标场景</h2><p>MegEngine 现在是动态执行的，即 python 中每一个 mge.functional 的调用都对应着底层 gpu 上的一次 kernel 执行。这种模式的好处在于实际的执行方式与代码逻辑一致，所见即所得，非常的灵活；不过其问题是难以优化，性能可能不是最优。</p><p>而 XLA 采取静态执行的方式，会将模型计算过程表达成一张静态计算图，称为 「HLO」 （High-Level Optimized）。HLO 中包含计算图的相关操作，张量的数据流程和形状等信息。XLA 随后会对 HLO 进行一系列的优化，并最终生成一个更优的计算图，从而更快的完成计算。而 XLA 的局限性就在于不够灵活，对于 Tensor Shape 改变或者控制流等信息无法很好的表达。</p><p>现在 MegEngine 中已经支持了 XLA，模型训练中一些比较静态的场景，我们可以使用 XLA 来进行加速，从而缩短整个训练过程的时间。</p><h2>使用方法与效果</h2><p>在使用 MegEngine 进行训练时，可以通过对原来的训练函数增加 xla_trace/partial_trace 装饰器来启用 XLA 编译优化。</p><p>当整个模型是完全静态时，我们可以使用 xla_trace 将整张网络表达成一张静态图，然后交由 XLA 做后续的优化编译，后续的执行过程将执行这张优化后的计算图提升速度。</p><p>而如果我们模型中有一些动态性，比如训练过程中一些 Tensor Shape 会发生变化，亦或者是存在控制流，我们可以使用 partial_trace，将网络中静态的部分 trace 成一些子图并分别交给 XLA 进行编译优化，而网络中其他部分仍然保持动态执行，同时保证性能与灵活性。</p><p>下面展示了在 MegEngine 中，XLA 功能开启前后，主流的神经网络模型性能变化。其中蓝色为 XLA 开启之前的训练速度，橙色为 XLA 开启之后的训练速度。在开启 XLA 后，大部分模型的性能可以获得 10%~40% 的提升，最多可以超过 80%。 <img src="https://data.megengine.org.cn/engine-website/assets/images/38f415d8-9963-11ee-a7f5-8272bed56fd1.png" alt="1.png" referrerpolicy="no-referrer"></p><p>关于 XLA 的更多信息及具体的使用方法可以参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.megengine.org.cn%2Fdoc%2Fstable%2Fzh%2Fuser-guide%2Fmodel-development%2Fjit%2Fxla.html" target="_blank">https://www.megengine.org.cn/doc/stable/zh/user-guide/model-development/jit/xla.html</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 10:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5265910/blog/10321024</guid>
            <link>https://my.oschina.net/u/5265910/blog/10321024</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[麟卓发布多平台软件安装包构建系统，支持 Windows 和 Linux]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京麟卓<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9I8Xo7H_LLHPmSy_HMY24A" target="_blank">宣布推出</a></u>「多平台软件安装包构建系统」，用于解决 Windows 和 Linux 系统中传统软件封装、安装过程繁琐、平台差异严重等诸多问题。</p><p>据介绍，该工具提供「一站式构建、安装」功能，让用户能够轻松制作软件安装包程序，提升工作效率，简化软件封装、安装以及卸载流程。</p><blockquote><strong>下载地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linzhuotech.com%2FProduct%2FDownLoadWindows" target="_blank">https://www.linzhuotech.com/Product/DownLoadWindows</a></u></em></strong></blockquote><p>「多平台软件安装包构建系统」是利用统一交互界面和配置机制生成多平台软件安装包的系统，支持在 Windows、Linux 平台上进行目标软件的多层级模块化封装以及安装功能，主要具备以下优势：</p><ul><li>软件安装便捷：简化传统软件安装流程中的解压、拷贝以及配置环境等繁琐操作。</li><li>人机交互统一：在不同的操作系统平台上，具备统一人机交互，方便用户进行多平台封装。</li><li>功能操作简单：具备多层级可选控制、安装信息配置、自定义安装脚本、环境配置等丰富功能的同时保证软件操作简洁，易学易用。</li></ul><p><img height="779" src="https://oscimg.oschina.net/oscnet/up-346f799048871759324d7ded950e159fa0d.png" width="1280" referrerpolicy="no-referrer"><img src="https://static.oschina.net/uploads/space/2023/1213/174623_Cjur_2720166.png" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-401cdffba4679c3bdb8ae9bb0feea96f222.png" referrerpolicy="no-referrer"></p><ul></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 09:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270878</guid>
            <link>https://www.oschina.net/news/270878</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软推出小模型 Phi-2，性能优于 Llama 2/Mistral 7B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">微软<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fphi-2-the-surprising-power-of-small-language-models%2F" target="_blank">宣布</a>推出一个 27 亿参数的语言模型 Phi-2，并声称其性能可与大 25 倍的模型相匹配或优于。「展示了出色的推理和语言理解能力，展示了参数少于 130 亿的基础语言模型中最先进的性能。」</span></p><p><span style="color:#000000">其基准测试结果表明，只需 27 亿个参数，Phi-2 就能在各种综合基准测试中超越 Mistral 和 Llama-2 模型在 7B 和 13B 参数下的性能。与大 25 倍的 Llama-2-70B 模型相比，Phi-2 在多步推理任务（即编码和数学）上实现了更好的性能。</span></p><p><span style="color:#000000">此外，Phi-2 的性能与最近发布的 Google Gemini Nano 2 不相上下，甚至更胜一筹。</span></p><p><img height="179" src="https://oscimg.oschina.net/oscnet/up-195920a0bfb4c87cd5ca00cc5d3edd0c25d.png" width="500" referrerpolicy="no-referrer"></p><p><img height="101" src="https://oscimg.oschina.net/oscnet/up-00457009ea9fb83c5e5802e175d784bd463.png" width="500" referrerpolicy="no-referrer"></p><p>且<span style="background-color:#ffffff; color:#000000">与经过调整的现有开源模型相比，</span><span style="color:#000000">Phi-2 </span><span style="color:#1a202c">响应中的「毒性」和偏差也要更少。</span></p><p><span style="color:#1a202c"><img alt="" height="243" src="https://oscimg.oschina.net/oscnet/up-36ec3b182b6104dcd29d01e7b450d2cb42c.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">此前，谷歌发布的 Gemini 演示视频曾展示了其解决复杂物理问题，以及对学生进行纠错的能力。微软研究人员也将&nbsp;Phi-2 进行了同样的测试，并表示它同样能够正确回答问题，和使用相同的提示纠错。</span></p><p><img height="282" src="https://oscimg.oschina.net/oscnet/up-11a57788ae91ebd7277cc00ee2b3ab55339.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Phi-2 是微软「小语言模型（SLM）」系列中的最新版本。第一个版本是拥有 13 亿参数的 Phi-1，针对基本的 Python 编码任务进行了微调。9 月，该公司将重点扩展到常识推理和语言理解，推出了一个新的 13 亿参数模型 Phi-1.5，性能可与大 5 倍的模型相媲美。</span></p><p><span style="color:#000000">微软表示，Phi-2 的效率使其成为想要探索增强人工智能安全性、可解释性和语言模型道德发展等领域的研究人员的理想平台。目前，</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fml.azure.com%2Fregistries%2Fazureml-msr%2Fmodels%2Fmicrosoft-phi-2%2Fversion%2F3%3Ftid%3D72f988bf-86f1-41af-91ab-2d7cd011db47%23overview" target="_blank">Phi-2</a><span style="color:#000000"> 现已通过 Microsoft Azure AI Studio 的模型目录发布。</span></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fphi-2-the-surprising-power-of-small-language-models%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270831/microsoft-phi-2-small-language-model</guid>
            <link>https://www.oschina.net/news/270831/microsoft-phi-2-small-language-model</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Wi-Fi 7 将于 2024 年初全面登场，速度比 Wi-Fi 6 提升 5 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#262626">WiFi 联盟<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wi-fi.org%2Fdiscover-wi-fi%2Fwi-fi-certified-7" target="_blank">宣布</a></u>将在明年 1 月 9 日至 12 日参加 CES 2024，并确认基于 IEEE 802.11be 的 Wi-Fi CERTIFIED 7 认证标准将于第一季度末之前正式推出。</span>与目前的 Wi-Fi 6 标准相比，该标准有望提供千兆位速度和其他改进。</p><p><img src="https://oscimg.oschina.net/oscnet/up-bf8bb1d4062d6abcdd5bde367ecbe4cc108.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0cc0e98c02c1b0b058bc6ac02b0b37ea771.png" referrerpolicy="no-referrer"></p><p>英特尔（Intel）和博通（Broadcom）去年展示的 Wi-Fi 7（也称 802.11be）速度高达 5 Gbps，大大超过了 Wi-Fi 6 的典型最高速度约 1.7 Gbps。<strong>Wi-Fi 7 允许在 2.4GHz、5GHz 和 6GHz 频率之间无缝切换</strong>，兼容设备可同时使用这些频率，从而实现了这一目标。</p><p>此外，6GHz 频谱可提供 320MHz 的超宽信道，吞吐量比 Wi-Fi 6 翻了一番，这是速度提升的关键因素。通过从 1024 QAM 升级到 4K QAM，新标准还将传输速率提高了 20%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-68acdc34185024028d7aabf4f9b688fd47e.png" referrerpolicy="no-referrer"></p><p>Wi-Fi 7 连接也有望比以前的规格更加稳定。多链路操作可智能平衡流量，使网络能有效容纳更多设备。联盟表示，新标准将非常适合增强现实和虚拟现实应用。美国联邦通信委员会（FCC）最近初步批准了 6GHz 频谱上的超高速 Wi-Fi 关联，这是使 VR 和 AR 设备能够利用 Wi-Fi 7 的重要一步。</p><p>2024 年的推出日期与英特尔 2022 年的预测基本吻合。该公司计划从明年开始推出支持 Wi-Fi 7 的个人电脑，并于 2025 年在市场上普及。高通公司也对 Wi-Fi 7 持乐观态度，并将其与 5G 一起纳入了 FastConnect 计划。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 05:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270823/wi-fi-certified-7</guid>
            <link>https://www.oschina.net/news/270823/wi-fi-certified-7</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Log4Shell 两周年，仍有不少项目使用包含漏洞的版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Log4Shell 是 Log4j 2.0（Log4J2）的一个 0day 远程代码执行漏洞，被定性为「过去十年来最大、最关键的漏洞」，最早由阿里巴巴集团于 2021 年 11 月 24 日发现并报告给 Apache 软件基金会。</p><p>尽管已经过去了两年，<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.veracode.com%2Fblog%2Fresearch%2Fstate-log4j-vulnerabilities-how-much-did-log4shell-change" target="_blank">但根据安全公司 Veracode 的报告</a></u></strong>，该漏洞的影响仍然存在。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-73861b3642e119baf3ccca3f3a037679b4f.png" referrerpolicy="no-referrer"></p><p>Veracode 分析了 2023 年 8 月 15 日至 11 月 15 日期间 90 天内的软件扫描数据，针对 3,866 个组织运行 Log4j 版本 1.1 至 3.0.0-alpha1 的 38,278 个独特应用程序。</p><p>在 Log4j 1.1 到 3.0.0-alpha1 版本中，有超过三分之一的应用程序使用了存在漏洞的 Log4j 版本。具体来说：</p><ul><li>2.8% 的应用程序仍在使用 Log4j2 2.0-beta9 到 2.15.0 之间的版本，这些版本存在 Log4Shell 漏洞。</li><li>另外 3.8% 的应用程序使用的是 Log4j2 2.17.0 版本，虽然该版本已修复了 Log4Shell 漏洞，但仍然存在 CVE-2021-44832 漏洞，这是一个高危的远程代码执行漏洞。</li><li>还有 32% 的应用程序使用的是 Log4j2 1.2.x 版本，这个版本在 2015 年 8 月已经停止维护，但在 2022 年 1 月 ASF 宣布了三个影响该版本的关键漏洞。</li></ul><p>这些数据表明，尽管各方对 Log4Shell 漏洞进行了大规模的修复工作，但仍然存在许多应用程序使用了存在漏洞的 Log4j 版本。</p><p>Veracode 的研究还发现，许多开发者在将第三方库引入到代码后从未更新过这些库。这也解释了为什么有如此大比例的应用程序在运行已经停止维护的 Log4j 版本。</p><p>此外，研究还发现，一旦开发者通过扫描发现了漏洞，他们通常会相对迅速地进行修复。但是，一些外部因素会拖慢开发人员的修复速度，例如缺乏信息或资源。</p><hr><p>延伸阅读</p><ul><li><a href="https://www.oschina.net/news/173273/log4j-maintainer-response" target="_blank">Log4j 维护者：为向后兼容没移除导致漏洞的旧功能</a></li><li><a href="https://www.oschina.net/news/174752/impact-of-apache-log4j" target="_blank">Apache Log4j 漏洞的影响规模</a></li><li><a href="https://www.oschina.net/news/203874/log4j-the-pain-just-keeps-going-and-going" target="_blank">「核弹级」 Log4j 漏洞仍普遍存在，并造成持续影响</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270803/state-log4j-vulnerabilities-2023</guid>
            <link>https://www.oschina.net/news/270803/state-log4j-vulnerabilities-2023</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 11 记事本的底部状态栏将显示「字符数统计」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Windows 11 内置的文本编辑器「记事本」添加了一项重要功能：在底部状态栏显示<strong>字符数统计</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-876aae8d39e39c30417766c1912f6ab4e65.png" referrerpolicy="no-referrer"></p><p>该功能会显示使用者输入的<strong>字符总数</strong>，包括字母、数字、符号、空格、标点符号等。「字符统计」与「字数统计」不一样，字数统计仅计算文档中的单词总数，有人会觉得它比字符数统计更有用。</p><p>根据微软的<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ghacks.net%2F2023%2F12%2F08%2Fwindows-11s-notepad-is-getting-a-character-count-on-the-status-bar%2F" target="_blank">公告</a></u>，记事本中的字符数统计有两种工作方式。默认情况下，文本编辑器将在窗口底部的状态栏上显示文档的字符数。如果使用者在文档中选择了文本，记事本将分别显示所选文本的字符数和文档的总计数。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/270799/windows-11s-notepad-character-count-on-the-status-bar</guid>
            <link>https://www.oschina.net/news/270799/windows-11s-notepad-character-count-on-the-status-bar</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国产数据库的出现和消失，都不是技术问题]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><blockquote><p>最近，关于数据库国产化替代的话题甚是热门。OSCHINA 开源中国特别邀请了<strong>欧冶云商股份有限公司数据库首席薛晓刚</strong>就这一话题发表看法。</p></blockquote><span id="OSC_h2_1"></span><h2><span style="color:#2980b9">为什么要替代 Oracle?</span></h2><p>去 IOE 的背景，要从阿里巴巴去 IOE 谈起，I 是 IBM 小型机大型机，O 是 Oracle 数据库，E 是 EMC 存储。这几个搭配起来使得阿里轻松走过了最初的技术发展阶段。这个配置组合也是当年这条街最靓的仔。这个穿搭在大型银行和运营商中也很常见。这种组合的好处是就稳定，而且非常稳定。<strong>缺点可能只有一个，就是贵。</strong></p><p>随着阿里业务的增加，阿里人考虑继续这样使用的成本很高。再加上阿里开始了云计算的规划，所以提出了去 IOE 的口号。这个在其他互联网公司是不可能有的。因为其他互联网公司一开始就没有 IOE 所以不需要去。只有阿里一开始的架构是这样的。所以只有阿里提出了。</p><p>阿里做阿里云，希望用户上云。上云的核心就是数据上云。数据上云后存在哪里？自然是数据库中，如果用的数据库是 Oracle 的，那么可能要分给 Oracle 利润（要采购许可）。所以阿里打算用 MySQL 以及后来自研替代 Oracle。</p><p>从最开始的去 IOE，直到现在还经常看到各种大会上提到去 O，这用了十几年，去掉了 I 和 E。有些企业完成了去 O，而有些企业还在使用 O。</p><p><strong>那么为什么只提去 O，那不用去 DB2 和 SQLServer 吗？本质上也要去的。</strong>只是其他的数据库不如 Oracle 的使用广泛，例如现在使用和维护 DB2 的人是很少了。之所以没人提去 DB2，是因为从总体来说 DB2，已经被去掉了。所以狭义去 O 是去掉 Oracle 数据库，而广义的去 O 其实可以扩大为去 M（美国化）。</p><p>在今天不少人观点认为用 MySQL 去替代 Oracle 是无意义的。因为 MySQL 和 Oracle 同属于甲骨文公司。甚至在有的场合中还会提到要去掉 MySQL。</p><span id="OSC_h2_2"></span><h2><span style="color:#2980b9">当前数据库国产化进程情况如何?</span></h2><p>当前在信创和安可这些趋势下，国产数据库如雨后春笋般出现。在国内某权威数据库排行榜上，已经有 280 多个数据库了。实际上的数字可能比这个还要多一点。</p><p>在一些政府、金融、运营商行业都有一些国产化替换。这些替换其实不仅仅是数据库了，还包括服务器、CPU、操作系统等等。从宣传上看有些是全栈替换，有些是部分替换。也还有一些公司或者企业没有替换。然而这些都是国产厂商的宣传，至于实际的替换情况只有用户自己知道。而即使替换的用户也没有进行相关的宣传，这就使得整个情况非常的模糊。不过这个过程还在继续，还是会有一些系统从 Oracle、DB2、SQLServer 等数据库切换到国产化上来的。只是现在不确定因素太多了。</p><p>今年年初，TiDB、TDengine、TDSQL、OceanBase 四位数据库界掌门人在一场直播中大致达成一致，三年后在中国健康运营的数据库不超过 20 家。所谓健康运营是，企业能有正常营收，员工发薪正常。目前国产数据库有 280 多个产品，有的一个公司有几个产品。即使这样也是有绝大部分产品或者公司会因为无法盈利而退出舞台。用户现在也意识到了这一点，也在等情况明朗后再去选择。没有企业愿意看到花了很大代价切换的数据库无人维护了，不得不继续再次替换。</p><p>国产数据库有完全自研的，例如达梦、OceanBase 等，也有一些是基于 MySQL 做改造的，还有一些事基于 PostgreSQL 改造的，还有购买外国源码然后进行修改的。</p><span id="OSC_h2_3"></span><h2><span style="color:#2980b9">替代 Oracle 的难点在哪里?</span></h2><p>技术上，Oracle 确实领先，在数据库领域是一个标杆一样的存在。即使我们国产数据库的头部企业都认为自己和 Oracle 有较大的差距，作为学习者不断地在向 Oracle 学习。</p><p>Oracle 领先的其实不仅仅是技术，还有设计理念和前瞻性。2020 年信通院发布的白皮书中写了数据库的未来几大趋势，而在那时候这几个趋势当时 Oracle 已经部分实现和深度实现了。其实 Oracle 产品线很多，不仅仅是数据库。其中间件、硬件、操作系统等等是全方面的输出。</p><p><strong>具体到几个方面：</strong></p><p><strong>兼容性</strong><strong>。</strong>对于替换国产数据库，兼容性是一件绕不开的话题，特别是对于存量系统来说，大多数重要系统是运行在 Oracle 数据库上的，那么对于 Oracle 的<strong>基本</strong><strong>SQL</strong><strong>语法、</strong><strong>PL</strong><strong>/SQL、存储过程、触发器等</strong>的兼容性肯定是十分重要的，毕竟这涉及代码变更的问题。如果在国产数据库替换过程中出现业务适配新数据库代码变更量太大、数据库功能缺失需要业务侧代码补充、适配分布式数据库过程中对数据库设计和业务逻辑变更等现象的话，开发层面对国产数据库的抵触会非常大。</p><p><strong>性能。</strong>性能和硬件以及优化器都有很大的关系。优化器这方面目前没有能超过 Oracle 优化器的。因为这些底层都是数学算法。2021 年信通院发布的数据库发展白皮书显示，我国数据库企业针对数据库领域的平均专利数量（含国内外专利）为 38 个，最高为 500 个左右规模，数量为 0 的企业个数是 19 个，占比 24%。拥有专利数 0-4 个的企业占比最高为 51%，专利数 5-10 个的企业次之，占比 14%，专利数 21-50 个的企业数量排名第三，占比 12%。从企业专利数量上看，Oracle 以 1.4 万个全球领先，SAP 居次席。</p><p><strong>稳定性。</strong>Oracle 的稳定性还是毋庸置疑的，这也就是为什么在过去那么多年中，其一直占据着领导地位，以及使用如此广泛。企业负责人都不希望看到自己的数据库经常出问题，每次数据库的问题都可能导致故障，从而影响到在线业务。不仅仅要面对直接和间接的经济损失，还有问责的压力。</p><p>Oracle 等国外数据库有足够的全球市场，专心在技术上投入做数据库，而国产数据库厂商只能在国内有限的数据库市场内卷，需要投入大量的内卷、恶性竞争和关系处理上，无法专心把全部精力放在做数据库上。甚至还是为了如何生存而谋划。</p><p>国产数据库的出现并不是技术问题，而是其他因素。</p><p>数据库领域的人都知道，在信创活动结束之后就没有替换动力了。而最终国内市场无法容得下几百家供应商，所以大部分国产数据库的消失也不是技术问题。</p><span id="OSC_h2_4"></span><h2><span style="color:#2980b9"><strong>有哪些能够替代 Oracle 的国产数据库？</strong></span></h2><p>这个替代要讲清楚是怎么替代？如果说就是把系统关停，然后把数据导过来，然后再修改数据库的连接字符串就可以和之前一样正常使用而且稳定的。目前没见过也没听说过。</p><p>如果说换了一个国产数据库，然后把链接这个数据库的所有业务系统的软件代码进行修改（这个修改可能是 30-100%），即软件重写适配数据库或者部分需求和功能放弃，那么这样的替换还是有一些的。OceanBase、TiDB、TDSQL 等都有在不同程度上有，具体的都是应实际情况而定。</p><p>这些替换的优势，可能在于满足了政治要求。</p><p><strong>这些替换的劣势，有多方面：</strong></p><p>由于同等硬件下不如 Oracle 的性能，所以增加硬件导致成本的上升。或者分布式数据库的硬件就是比集中式硬件的多导致的硬件成本上升。</p><p>由于数据库特性和功能的缺失，所以应用程序需要改造的成本上升。这部分可能占替换总成本的 60%-80%。因为这是调动大量应用开发人员重写适配的过程。</p><p>由于稳定性上不如 Oracle，所以需要增加大量运维人员，导致运维的成本上升。</p><p>由于部分国产数据库需要许可才可以运行，所以增加了大量的许可费用。相比较之前很少采购 Oracle 许可或者甚至不采购许可来说，这部分采购费用占比很大。</p><p>以上这些成本可能会是使用 Oracle 数据库的数倍甚至几十倍甚至上百倍。而很多计算中都忽略了第二和第三项的成本。</p><span id="OSC_h2_5"></span><h2><span style="color:#2980b9">现有国产数据库跟 Oracle 相比，有多大的差距?</span></h2><p>从技术上来说，我们和 Oracle 相比有代差。</p><p>可能不同的人有不同的见解。我个人感觉有以下多方面的差距（但是不限于此）：</p><p><strong>数据库的</strong><strong>优化器</strong><strong>上：</strong>有人说为什么 Oracle 快，你可能不知道多少满头白发的数学教授在那里研究着这些。有人说：你别逼我，逼急了我什么都做的出来。」 「是吗？，那你把这道数学题给做做？」 人被逼急了还真不是什么都做的出来，起码数学就不是。各种复杂查询的核心是优化器和统计信息。而这全部都是数学问题。没有在数学上的基础投入是无法在这个领域攻坚克难的。</p><p><strong>体系架构上：</strong>如今越来越多的国产数据库考虑 RAC 架构。在经历了互联网的分布式数据库的洗礼后，越来越多的用户觉得集中式更加适合自己。所以才有了各种国产数据库厂商开始实现 RAC 的计划，达梦、优炫等。即使分布式数据库厂商在研发过程中发现 Oracle 的各种体系设计，没有一个是多余的，都是设计极其精妙的。而这些很多设计都是 30 年前甚至更早就已经设计到位的。</p><p><strong>与</strong><strong>操作系统</strong><strong>的融合上：</strong>数据库是运行在操作系统之上的，如何与 CPU 打交道？SQL 调用指令集的多少都是有讲究的。甚至有些操作是绕过操作系统直接操作的。这些都是需要深耕操作系统才能解决的。</p><p><strong>与硬件的融合上：</strong>数据库必然要和存储设备打交道。数据库的优化几乎等同于 IO 优化。所以 Oracle 直接做出来自己的存储。这些存储上都是带有 CPU 的，更好的存储和读取数据上发挥了很大的作用。做数据库是从上至下的深入解决。</p><p><strong>趋势把握上：</strong>数据库的多模和超融合这些都是 Oracle 在引领着数据库技术的前进方向。我们定义为趋势的，Oracle 基本都是已经实现的。而很多理念从设计到实现需要 8-10 年的过程。</p><span id="OSC_h2_6"></span><h2><span style="color:#2980b9"><strong>国产数据库未来要怎么走?</strong></span></h2><p>我个人角度认为，应该静下心来踏实的做技术。</p><p>最好是没有政治因素的干扰去市场上竞争，避免大跃进式的百家齐放，而是规范市场，让国内外数据库厂商同台竞争。用户结合自己的预算进行抉择，是选择廉价的还是性价比高的，让一切回归到技术本身来。而不能用政策限制其他产品进入，只能强制使用国产。这样会导致自我封闭和外部的排斥。既然我们用政策限制其他人，那么对等的就会出现别人限制我们。从而更加无法走出去。</p><p>如果真正能走出去，在国外用得起来，那么就是国产数据库的成功。中国的高铁就是因为走出去了才成为了中国的一张名片。</p><blockquote><p><strong>作者简介：</strong></p><p>薛晓刚，现任欧冶云商股份有限公司数据库首席。曾服务于政府、公安、交通、安防行业，从事过大型项目管理，设计和运维多个单表 100 亿，单机 100TB 的数据库。目前负责高可用、业务连续性和高并发数据架构设计和运维管理。</p><p>Oracle ACE-Pro（Oracle 和 MySQL 方向），Oracle OCP/MySQL OCP 及 OCP 讲师。PostgreSQL 的 PGCE 和 PCP 认证，PostgreSQL ACE Partner。墨天轮 MVP，TiDB MVA，ITPUB 论坛内存数据库版主、核心专家、金牌顾问，墨天轮社区特聘金牌讲师，机械工业出版社专家委员会委员。</p><p><img height="483" src="https://oscimg.oschina.net/oscnet/up-db67ea17186e0146cd30e998dbd09b31b55.png" width="500" referrerpolicy="no-referrer"></p><p><strong>联系作者：</strong></p><p><img height="249" src="https://oscimg.oschina.net/oscnet/up-783ed80bb94f3f8e33fb256e9e56a3413e6.png" width="500" referrerpolicy="no-referrer"></p></blockquote><p>&nbsp;</p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Dec 2023 03:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10321019</guid>
            <link>https://my.oschina.net/u/3859945/blog/10321019</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
