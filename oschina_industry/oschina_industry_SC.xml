<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 16 Dec 2023 18:36:17 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[商汤科技创始人汤晓鸥离世，享年 55 岁]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 16 日，腾讯新闻报道称，商汤科技董事长、人工智能科学家汤晓鸥于 12 月 15 日在睡梦中不幸离世，享年 55 岁。</p><p>汤晓鸥主要从事计算机视觉相关领域的研究，包括多媒体、计算机视觉、模式识别及视频处理，是全球人脸识别技术的「开拓者」和「探路者」。</p><blockquote><p><img height="1272" src="https://static.oschina.net/uploads/space/2023/1216/153402_su2B_2720166.png" width="1442" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fview.inews.qq.com%2Fa%2F20231216A051VT00" target="_blank"><span style="background-color:rgba(0, 0, 0, 0); color:inherit">https://</span>view.inews.qq.com/a/20231216A051<span style="background-color:rgba(0, 0, 0, 0); color:inherit">VT00</span></a></u></em></p></blockquote><p>最早的网传消息：</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1216/153606_97lp_2720166.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1644054135%2FNxokl6vOQ%3Fpagetype%3Dprofilefeed" target="_blank">https://weibo.com/1644054135/Nxokl6vOQ</a></u></em></p></blockquote><p>公开信息显示，汤晓鸥 1968 年出生于辽宁鞍山，香港中文大学信息工程学系教授、工程学院杰出学人。汤晓鸥于 1990 年从中国科学技术大学毕业；1991 年获得美国罗切斯特大学硕士学位；1996 年获得麻省理工学院博士学位，之后进入香港中文大学工作；2001 年创立了香港中文大学多媒体实验室；2005 年至 2007 年在微软亚洲研究院工作，担任视觉计算组主任；2008 年在深圳先进技术研究院多媒体集成技术研究室工作，担任主任和研究员。</p><p><img height="457" src="https://oscimg.oschina.net/oscnet/up-a417892a92b7c38cf49b69a36526d033f48.png" width="300" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">汤晓鸥指导的博士生何恺明是深度残差网络 (ResNets) 的主要开发者。深度残差网络</span>使神经网络能够达到前所未有的深度，获得以前难以实现的能力，促成了多个突破性的成果——包括 AlphaGo、AlphaFold 和 ChatGPT，为人工智能做出了基础性贡献。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 07:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271336</guid>
            <link>https://www.oschina.net/news/271336</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 设立 1000 万美元基金，支持超人类 AI 风险研究]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">OpenAI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fsuperalignment-fast-grants" target="_blank">宣布</a>与 Eric Schmidt 合作，启动了一项 1000 万美元的新资助计划，以支持技术研究，确保超人类人工智能（superhuman AI）系统的一致性和安全性。</span></p><p><span style="color:#000000">「<span style="background-color:#ffffff">我们相信超级智能可能在未来十年内到来。这些人工智能系统将拥有巨大的能力 —— 它们可能带来巨大的好处，但也可能带来巨大的风险。</span>」</span></p><p><img height="249" src="https://oscimg.oschina.net/oscnet/up-76bbf42b019b3dacb6d1b9184ea8dcc692a.png" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">该公司表示，当前确保 AI 系统安全的手段主要是依赖于人工监督的对齐技术（例如 RLHF）。但超</span>人类&nbsp;AI&nbsp;<span style="background-color:#ffffff">系统将能够执行人类无法完全理解的复杂且富有创造性的行为。例如，如果一个超人模型生成一百万行极其复杂的代码，人类将无法可靠地评估这些代码执行起来是安全还是危险，现有的技术可能不再够用。&nbsp;</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「这就引出了一个根本性的挑战：人类如何引导和信任比自己聪明得多的人工智能系统？这是世界上尚未解决的最重要的技术问题之一。但我们认为，只要齐心协力，这个问题是可以解决的。现存<span style="background-color:#ffffff">许多有希望的方法和令人兴奋的方向，以及许多唾手可得的成果。</span>」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">作为其 Superalignment 项目的一部分，OpenAI 推出的这一资助计划旨在：</span></p><ul><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">向学术实验室、非营利组织和个人研究人员捐赠 10 万至 200 万美元</span></span></li><li style="text-align:start"><span style="color:#000000">并<span style="background-color:#ffffff">为研究生推出为期一年的 15 万美元奖学金（一半将用于研究经费，另一半将作为津贴）</span></span></li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">根据 OpenAI 的说法，申请这一资助资金的研究人员不要求有对齐工作的经验，他们已准备好为尚未在这方面做过任何工作的研究人员提供支持。</span></span><span><span><span><span style="color:#585858"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fairtable.com%2FappnIXmOlWAJBzrJp%2FpaghnoKL6EHiKmKbf%2Fform" target="_blank"><span><span><span>申请</span></span></span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="color:#000000"><span style="background-color:#ffffff">将持续开放至 2 月 18 日，申请人将在申请截止日期后四个星期内收到回复。&nbsp;</span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fairtable.com%2FappnIXmOlWAJBzrJp%2FpaghnoKL6EHiKmKbf%2Fform" target="_blank">申请表单</a></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 03:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271307/openai-superalignment-grant-fund</guid>
            <link>https://www.oschina.net/news/271307/openai-superalignment-grant-fund</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[今年我国语言大模型市场增长率将超 100%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">据央视新闻报道，工业和信息化部赛迪研究院数据显示，2023 年我国语言大模型市场规模实现较快提升，应用场景不断丰富，增长率有望突破 100%。</span></p><p><span style="background-color:#ffffff; color:#222222">工业和信息化部赛迪研究院数据显示，目前，我国已有超过 19 个语言大模型研发厂商，其中，15 家厂商的模型产品已经通过备案，预计今年我国语言大模型市场规模将达到 132.3 亿元，增长率将达到 110%。</span></p><p><span style="background-color:#ffffff; color:#222222">语言大模型能够模仿人类的对话和决策能力，是率先实现技术突破和应用落地的大模型，是当下人工智能的主赛道，在金融、医疗、教育、工业、游戏、法律等多个行业应用广泛。专家预测，到 2027 年，我国语言大模型市场规模有望达到 600 亿元。</span></p><p><img height="273" src="https://oscimg.oschina.net/oscnet/up-256c6498333f3d9198b73f867a58b33c90d.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 03:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271303</guid>
            <link>https://www.oschina.net/news/271303</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Prompt flow —— 构建高质量的 LLM 应用程序]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><strong>Prompt flow&nbsp;</strong>是一套开发工具，旨在简化基于 LLM 的人工智能应用程序的端到端开发周期，从构思、原型设计、测试、评估到生产部署和监控。它使即时工程变得更加容易，并使你能够构建具有生产质量的 LLM 应用程序。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>通过该项目，你将能够：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>创建将 LLM、提示、Python 代码和其他工具链接在一起的可执行工作流程。</li><li>轻松调试和迭代你的流程，尤其是与 LLM 的交互。</li><li>使用更大的数据集评估流程的质量和性能。</li><li>将测试和评估集成到你的 CI/CD 系统中，以确保流程的质量。</li><li>将你的流程部署到你选择的服务平台或轻松集成到应用程序的代码库中。</li><li>（可选，官方强烈推荐）利用 Azure AI 中 Prompt flow 的云版本与团队协作。
<p>&nbsp;</p></li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 03:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/promptflow</guid>
            <link>https://www.oschina.net/p/promptflow</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 分布式块存储系统 fastblock]]>
            </title>
            <description>
                <![CDATA[<h1><a id="fastblock 简介" class="anchor" href="https://gitee.com/openeuler/fastblock#fastblock%E7%AE%80%E4%BB%8B"></a>fastblock 简介</h1><p>目前使用的分布式块存储系统 (ceph) 存在的问题已经不能适应对性能、延迟、成本和稳定性的需求，主要体现在:</p><ul><li>CPU 经济性: 目前需要消耗大量的 CPU，CPU 在 nvme ssd 集群中成为瓶颈</li><li>可用性差: 采用主从强同步复制策略, 集群抖动时有 IO 会被 hang 住</li><li>单卷性能不足: 对接 qemu 时性能更差，做压测时需要多个卷才能跑满整个集群的性能</li><li>单卷延迟过大: 不能充分利用 nvme 设备的低延迟特性，rbd 块设备通常延迟都在毫秒级别</li><li>并发总性能不足: iops 和吞吐相对硬件能够提供的水平相差较大</li></ul><p>fastblock 是为解决性能和延迟问题而生的，它的特点是:</p><ul><li>使用 spdk 编程框架编写，利用用户态 nvme 驱动、无锁队列等特性降低 IO 路径延迟</li><li>引入 RDMA 网卡进行零拷贝、内核旁路、无需 CPU 干预的网络通信</li><li>使用 multi-raft 进行数据复制，保证数据可靠性</li><li>简单、可靠、易定制的集群元数据管理</li></ul><h1><a id="fastblock 设计及架构" class="anchor" href="https://gitee.com/openeuler/fastblock#fastblock%E8%AE%BE%E8%AE%A1%E5%8F%8A%E6%9E%B6%E6%9E%84"></a>fastblock 设计及架构</h1><p>fastblock 的架构跟 ceph 非常类似，且 monitor、osd、pg 等众多概念都跟 ceph 一样以便于快速理解，架构如下图所示:<br><img src="https://gitee.com/openeuler/fastblock/raw/master/docs/architecture.png" alt="arch" referrerpolicy="no-referrer">
其中:</p><ul><li>Compute 表示计算服务</li><li>Monitor cluster 负责维护集群元数据（包括 osdMap、pgMap、pool 信息和 image 信息），以及 pool 和 pg 的管理。</li><li>storage cluster 对应存储集群，每个存储集群包含多个 Storage Node，每个 Storage Node 上运行多个 osd(Object Storage Daemon)。</li><li>Control rpc 用于传输元数据，使用 tcp socket；Data rpc 用于在客户端和 osd 之间传输数据请求；raft rpc 用于在 osd 之间传输 raft 论文中定义的 RPC 消息。其中 Data rpc 和 raft rpc 使用 protobuf 和 RDMA。</li><li>Monitor Client 是 monitor 客户端模块，用于跟 monitor 通信。</li><li>Command Dispatcher 是消息处理模块，用于接收处理客户端的数据请求。</li><li>raft Protocol Processer 用于处理 raft RPC 消息、选举、成员变更等 raft 协议规定的内容。</li><li>raft Log Manager 负责管理和持久化 raft Log，持久化 raft Log 使用了 spdk blob。</li><li>Data State Machine 存储用户数据，使用了 spdk blobstore。</li><li>raft Log Entry Cache 用于缓存 raft Log，提高性能。</li><li>KV System 则提供 kv api，持久化时使用了 spdk blob。</li></ul><h1><a id="fastblock 组件及交互逻辑" class="anchor" href="https://gitee.com/openeuler/fastblock#fastblock%E7%BB%84%E4%BB%B6%E5%8F%8A%E4%BA%A4%E4%BA%92%E9%80%BB%E8%BE%91"></a>fastblock 组件及交互逻辑</h1><h2><a id="monitor" class="anchor" href="https://gitee.com/openeuler/fastblock#monitor"></a>monitor</h2><p>monitor 服务负责维护存储节点状态和节点加入删除、存储卷的元数据、维护集群的拓扑结构、响应用户创建 pool 等操作、根据当前的拓扑结构在 osd 上均匀创建 raft group 等。monitor 作为集群管理工具，并不需要存储数据，也不需要追求极致性能，所以使用 golang 进行实现, monitor 使用 etcd 进行多副本存储。<br>
monitor 集群是一致性的重要保证，因为客户端、osd 看到的都是相同的视图。对于所有客户端的 io 操作都只能看到 pg 这一层，而 osd 和客户端都会在启动时开启一个定时器定时去向 monitor 获取 osdmap 和 pgmap 信息，所以所有的 osd 和客户端都能够看到相同的 pg 状态变化并作出相同的相应，针对特定 pg 的写入操作也不会写到错误的地方。<br>
详情可参考<a href="https://gitee.com/openeuler/fastblock/blob/master/monitor/README.md" title="monitor 简介">monitor 简介</a></p><h2><a id="osd-rpc 子系统" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-rpc%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd rpc 子系统</h2><p>rpc 子系统是连接各模块的重要系统，出于异构网络的要求，rpc 子系统的实现了两种方式，即基于 socket（Control rpc）的和基于 rdma（Data Rpc 和 Raft Rpc）的，基于 socket 的就是经典的 linux socket 应用场景，而基于 rdma 的 rpc 则是使用异步 rdma(即 rdma write) 语义实现的。<br><img src="https://gitee.com/openeuler/fastblock/raw/master/docs/rpc_subsystem.png" alt="rpc 子系统" referrerpolicy="no-referrer">
上图是 fastblock 中各个模块之间的联系，由图中可以看出使用了三种类型的 rpc，分别为 Control Rpc、Data Rpc 和 Raft Rpc:
Control rpc： 用于在客户端与 monitor 之间，osd 与 monitor 之间传递 osdmap、pgmap 和 image 信息等数据，这些数据量不大，频率不高，因此可以使用基于 socket 的实现;
Data rpc：用于在客户端与 osd 之间传输对象数据操作和结果，这些数据量比较大，频率会很高，因此需要基于 rdma 的方法;
Raft rpc： 用于在 osd 之间传输 raft rpc 协议内容，里面会保护对象数据，这些数据量比较大，频率会很高，因此需要基于 rdma 的方法。
Data rpc 和 Raft rpc 使用 protobuf 的 RPC 框架，网络交互部分代码使用 RDMA,rpc 传输数据的序列号都使用 protobuf。</p><h2><a id="osd-raft 子系统" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-raft%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd raft 子系统</h2><p>raft 通过选举一个领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目（log entries），把日志条目复制到其他服务器上，并告诉其他的服务器什么时候可以安全地将日志条目应用到他们的状态机中。 raft 在已经有很多开源实现，我们参考<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fwillemt%2Fraft" title="raft 的 C 语言实现">willemt</a>的 C 语言 raft 实现，并额外实现了 multi-raft，这个模块主要包括了:</p><ul><li>raft groups 的管理，包括 raft 的创建、修改和删除;</li><li>raft 选举以及选举超时处理;</li><li>raft log 处理，包括 log 缓存、log 落盘和 log 复制到 follower 节点;</li><li>数据 state machine 处理，既数据落盘;</li><li>raft 快照管理和 raft log recovery;</li><li>raft 成员变更管理 (暂未实现);</li><li>raft 心跳合并。</li></ul><p>实现 multi-group raft,意味着有多个 raft 并存，每个 raft 的 leader 需要给它的 follower 发送心跳包，因此就会有多个心跳包，如果 raft 过多就会导致心跳包过多，占用大量的带宽和 cpu 资源。解决方法也很简单，每个 osd 可能属于多个 raft，因此可以对相同 leader、相同 flower 的 raft 进行心跳的合并，这样就可以减少心跳包数量。如下图所示，有两个 pg（raft）分别为 pg1 和 pg2，pg1 和 pg2 中都包含 osd1、osd2 和 osd3，osd1 是 leader，osd1 需要给 osd2 和 osd3 分别发送 heartbeat (pg1)，pg2 中 osd1 需要给 osd2 和 osd3 分别发送 heartbeat (pg2)。心跳合并后，只需要 osd1 给 osd2 和 osd3 分别发送 heartbeat (pg1, pg2)。
<img src="https://gitee.com/openeuler/fastblock/raw/master/docs/heartbeat_merge.png" alt="心跳合并" referrerpolicy="no-referrer"></p><h2><a id="osd-kv 子系统" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-kv%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd kv 子系统</h2><p>kv 子系统用于存储 raft 的元数据、存储系统本身的数据，由于数据量不大，就自己设计了一套。因为数据量不大，内存中的 hash map 就可以存储所有数据，提供 put、remove 和 get 接口，每隔 10ms 把 hash map 中修改的数据写到磁盘中。</p><h2><a id="osd-localstore 子系统" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-localstore%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd localstore 子系统</h2><p>本地存储基于 spdk blobstrore 进行存储，包含 3 个存储功能模块：</p><ul><li>disk_log: 存储 raft log，一个 pg(对应一个 raft 组) 对应一个 spdk blob。</li><li>object_store: 存储对象数据，一个对象对应一个 spdk blob。</li><li>kv_store: 每个 cpu 核拥有一个 spdk blob。保存当前 cpu 核上的需要保存的所有 kv 数据，包括 raft 的元数据、存储系统本身的数据。
如下图所示，假设我们运行了两个 raft，localstore 为这两个 raft 提供了 log、object 和 kv 这 3 部分存储功能。
<img src="https://gitee.com/openeuler/fastblock/raw/master/docs/osd_localstore.png" alt="本地存储引擎" referrerpolicy="no-referrer"></li></ul><h2><a id="客户端" class="anchor" href="https://gitee.com/openeuler/fastblock#%E5%AE%A2%E6%88%B7%E7%AB%AF"></a>客户端</h2><p>客户端用于创建、修改和删除 image，把用户对 image 的数据操作转换为对 object（osd 处理的基本数据单元）的操作，然后封装为 Data Rpc 消息发送给 pg 的 leader osd，并接收处理 leader osd 返回的响应，结果返回给用户。 客户端有多种模式：使用 spdk vhost 提供给虚拟机使用；使用 NBD 提供给裸金属使用；使用 CSI 提供给虚拟机使用。这三种模式最终都会调用 libfastblock 库进行 image 到 object 的转换，并和 osd 通信。 下面主要介绍使用 spdk vhost 提供给虚拟机使用的模式:<br>
调用 spdk 库创建一个 vhost app，spdk 资源初始化后，需要开启一个定时器去向 monitor 获取 osdmap、pgmap 和 image 信息。
使用 spdk 的 rpc.py 脚本向 vhost app 发送创建 bdev（bdev_fastblock_create）的请求，vhost app 收到请求后创建 image，把 image 信息发送给 monitor，创建 bdev 设备，然后注册此设备的操作接口（此接口会调用 libfastblock 库）。
使用 spdk 的 rpc.py 脚本向 vhost app 发送创建 bdev 的 vhost-blk controller（vhost_create_blk_controller）的请求，vhost app 收到请求后打开 bdev 设备，注册一个 vhost 驱动去处理 vhost 消息（创建一个可供客户端 (如 qemu) 连接的 socket，并遵循 vhost 协议实现连接服务，这是 DPDK 中已实现的功能）。
libfastblock 把用户对 image 的数据操作转换为对 object（osd 处理的基本数据单元）的操作，然后封装为 Data Rpc 消息发送给 pg 的 leader osd，并接收处理 leader osd 返回的响应。</p><h1><a id="代码结构及编译" class="anchor" href="https://gitee.com/openeuler/fastblock#%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84%E5%8F%8A%E7%BC%96%E8%AF%91"></a>代码结构及编译</h1><p>fastblock 代码主要位于 src、monitor 和 spdk 目录中:</p><ul><li>src 目录主要包含 raft 实现、rdma 通信、底层存储引擎、块层 API 封装等功能, 详情见<a href="https://gitee.com/openeuler/fastblock/blob/master/src/README.md" title="src 代码简介">src 目录简介</a></li><li>monitor 目录则包含了集群元数据存储管理、monitor 选举、pg 分配、clustermap 分发等功能, 详情见<a href="https://gitee.com/openeuler/fastblock/blob/master/monitor/README.md" title="monitor 代码简介">monitor 目录简介</a></li><li>spdk 目录是通过复用 spdk 的 rdma 通信模块以支撑低延迟的 rpc 通信, 详情见<a href="https://gitee.com/openeuler/fastblock/blob/master/spdk/README.md" title="spdk 目录简介">spdk 目录简介</a>
编译之前需要先安装依赖，目前已进行了 ubuntu 21.10 和 openEuler 22.03 版本的验证，其他操作系统可酌情更改.</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./install-deps.sh</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>首次编译时，需要获取 spdk 和 abseil-cpp 等依赖，可通过运行以下命令分别编译 Release 版本的 montior 和 osd:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./build.sh -t Release -c monitor</span><span id="LC2" class="line">./build.sh -t Release -c osd</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>编译完成后，<code>fastblock-mon</code>和<code>fastblock-client</code>二进制位于<code>mon/</code>目录下，而<code>fastblock-osd</code>和<code>fastblock-vhost</code>二进制位于<code>build/src/osd/</code>目录和<code>build/src/bdev</code>目录下。
后续 osd、vhost 有代码改动，则可仅在<code>build/</code>目录下编译，而 monitor 有改动则可仅在<code>mon/</code>目录下<code>make</code>即可。</p><h1><a id="部署及性能测试" class="anchor" href="https://gitee.com/openeuler/fastblock#%E9%83%A8%E7%BD%B2%E5%8F%8A%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95"></a>部署及性能测试</h1><p>参考<a href="https://gitee.com/openeuler/fastblock/blob/master/docs/performance_test_1012.md" title="性能测试报告">部署及测试报告</a>, 在我们的测试环境中，在每个 osd 仅适用一个核的情况下，获得了 4k 随机写单线程 100us 以下的延迟以及并发 41 万 iops 的性能。</p><h1><a id="future-works" class="anchor" href="https://gitee.com/openeuler/fastblock#future-works"></a>future works</h1><ul><li>实现卷快照、快照组等功能</li><li>实现卷 QoS</li><li>osd 和 client 多核性能优化</li><li>实现本地存储引擎的可恢复性，以及本地存储引擎优化</li><li>添加测试系统，进行单元测试、集成测试，特别是 raft 层和本地存储引擎的故障测试</li><li>接入 CI 系统</li><li>实现可定制的 monitor 的 pg 分配插件</li><li>实现 raft 成员变更及与 monitor 的 pg 分配整体联调</li><li>优化 osd client 的 rdma 连接管理</li><li>重写 rdma 传输层以替换 spdk nvmf 版的 rdma 传输层</li><li>支持 DPU 卸载 vhost</li><li>监控数据导出及集群运行时数据展示</li><li>部署工具开发及系统配置文件简化</li><li>支持卷加解密功能</li><li>支持卷共享</li></ul>]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 02:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/openeuler/fastblock</guid>
            <link>https://gitee.com/openeuler/fastblock</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 如何做到人均告警减少 90%？B 站新一代告警平台的设计与实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一分钟精华速览</h1><p>B 站的业务规模和用户群体不断扩大，对于服务的稳定性和可用性的要求也日益增高。这就需要 B 站的监控告警系统能够及时、准确地发现和定位问题，以便尽快解决，维护好用户的使用体验。</p><p>本文是对 B 站在告警监控系统上的一次重要迭代和优化的详细记录。文章详细阐述了 B 站对告警平台设计思路和优化迭代，以及在实现过程中遇到的问题和解决方法。特别是对于告警定位的精准性和定位效率的提升，文章给出了新的设计方案和实践方法。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1c59a16c99cd6269dbb40c664c5cf2055c4.png" alt="file" referrerpolicy="no-referrer"></p><h1>作者介绍</h1><p><img src="https://oscimg.oschina.net/oscnet/up-a440bfaf0e2d837fc556f9759e77fe1f9e6.png" alt="file" referrerpolicy="no-referrer"></p><p>哔哩哔哩资深开发工程师——王程田</p><p>TakinTalks 稳定性社区专家团成员，哔哩哔哩资深开发工程师。2020 年加入 B 站先后负责事件平台，链路追踪，AIOps 及告警平台方向技术演进 &amp;平台迭代。完成了新一代告警平台落地，达成了 99 分位一分钟内的异常端到端发现，实现了人均告警从每周 1000+条/人到 70+条/人告警治理上的突破。</p><p>温馨提醒：本文约 6000 字，预计花费 8 分钟阅读。</p><p>TakinTalks 稳定性社区后台回复 「交流」 进入读者交流群；回复「1130」获取课件；</p><h1>背景</h1><p>在 B 站的多元化业务中，告警平台起着至关重要的作用。无论是视频播放、弹幕发送、用户评论、直播间管理，还是后台的内容审核、数据统计等，都离不开系统的稳定运行。告警平台可以实时监控这些业务系统的运行状态，一旦出现异常，就会及时发出告警示，使运维人员能够迅速定位问题，及时进行处理。</p><p>然而，维护这些业务的稳定运行并非易事。从告警发生的前、中、后三个阶段，即生产端、传输端和消费端来看，B 站的告警平台设计都面临着不小的挑战和复杂性。 <img src="https://oscimg.oschina.net/oscnet/up-1dd0249404eb178d97848101b0fd3492b8f.png" alt="file" referrerpolicy="no-referrer"></p><p>考虑到这些业务需求和复杂度，我们着手对 B 站新一代告警平台进行了全面升级，结果达成了人均告警减少 90%，根因分析准确率高达 87.9% 的突破。在本文中，我将概述新一代告警平台的设计理念，并重点分享该平台在告警降噪和告警智能化分析方面的实施策略。</p><h1>一、告警平台做了哪些重点设计？</h1><h2>1.1 业务核心诉求</h2><p>在告警平台的设计和迭代过程中，我们不断收到各类业务需求。总体上，这些需求的核心都集中在「以质量为中心，及时发现并处理异常，确保业务稳定性」。具体来说，需求场景可划分为风险场景和故障场景。在风险场景中，需要提前感知并有效应对潜在问题；而在故障场景中，需要迅速发现线上问题，及时响应，以实现快速恢复。</p><p>在满足这些业务需求的过程中，我们提炼出三个核心诉求和目标：</p><p>有效性：我们期望所有收到的告警都是有效的，即每次接收到告警时，都确实存在异常，而且这条告警对当前的接收者是具有意义的。</p><p>及时性：对于高优先级的异常，我们希望能在第一时间触达并被用户感知，以便他们能够及时采取行动进行处理。</p><p>覆盖性与跟进：我们期望实现告警的全面覆盖和跟进。从用户的角度来看，他们希望所有自己负责的业务或应用的场景都能被告警覆盖，同时，他们也希望能了解不同场景的告警覆盖情况。当规则产生异常后，用户需要有一个便捷的方式去快速处理并跟进解决问题。</p><h2>1.2 告警平台详细设计</h2><h3>1.2.1 闭环模型</h3><p>在告警平台的详细设计中，我们基于前述的目标和业务需求，构建了一个闭环模型。这个模型旨在保证各关联方的积极参与，从而推动目标的持续改善。特别的，告警定义和告警治理是模型中的两个关键环节，因为它们决定了告警降噪和召回效果的优劣。 <img src="https://oscimg.oschina.net/oscnet/up-412a40c1cfbb39cb0c17812de113d3f3d26.png" alt="file" referrerpolicy="no-referrer"></p><p>接下来将详细介绍 B 站告警定义、检测、通道侧功能的设计。重点是告警处理、根因分析以及告警治理侧的实践内容。</p><h3>1.2.2 告警接入</h3><p>在告警接入环节，主要区分了三个场景，这些场景的设计可以覆盖业务对于告警接入的大部分需求。</p><p>1）面向平台的场景</p><p>我们为平台覆盖的告警场景提供告警规则和模板的开放接口能力，支持多租户规则集成。不同租户可以基于预定义的模板进行配置，可以在业务申请或者注册资源时，快速完成告警的定义和覆盖，整个过程成本低，便捷性高。</p><p>2）面向自定义场景</p><p>我们为业务直接开放告警规则定义，包括规则的触发条件配置、表达式及通知策略的配置。</p><p>3）面向第三方事件</p><p>我们开放事件集成能力，用户可以通过注册事件完成准入，主动触发方式发送到告警平台，告警平台完成后续闭环的处理。</p><h3>1.2.3 告警计算</h3><p>我们设计了一个分布式的告警计算引擎，实现了多级的调度。基于线上全量生效的规则，进行全局调度，将告警的场景、可用区调度到不同的可用区和计算集群下。在同一个计算集群下，进行本地调度，将任务调度到不同的计算节点，实现负载均衡。计算节点会周期性地检测数据判断告警是否触发，触发后将投递到告警通道。 <img src="https://oscimg.oschina.net/oscnet/up-6dd8eb1e13f1625434405ab2a73c51430a1.png" alt="file" referrerpolicy="no-referrer"></p><h3>1.2.4 告警通道</h3><p>主要做降噪、渲染、分发，以实现准确的投递和快速的触达。对于引擎侧产生的告警事件，在通道会生成告警消息，然后先经过降噪模块，依次完成通知窗口拦截、通知频率拦截、接警拦截、静默拦截、抑制拦截、告警聚合等。接下来，经过告警渲染分发模块，完成渲染接收人、渲染通知通道、渲染通知模板，最终触达到用户并更新告警的投递状态。 <img src="https://oscimg.oschina.net/oscnet/up-9ceb09b7a6a29d8ed6874d76ba957d1e1c1.png" alt="file" referrerpolicy="no-referrer"></p><h1>二、告警治理有哪些实践心得？</h1><p>下面我将主要阐述 B 站在告警治理的实践过程中，如何推行告警治理策略，降低告警噪声，以及提高告警的有效性。</p><h2>2.1 告警治理背景</h2><p>过去一段时间里，B 站的告警通知泛滥问题，对技术团队和平台来说，这已经成为一个多年的困扰，也是一个较大的痛点。一方面，随着稳定性问题的出现以及新平台的接入，告警规则和配置不断增加；另一方面，又缺乏有效的告警治理和运营分析机制。这导致告警数量越来越多，很多用户也不会去主动治理告警，反而选择设定免打扰。最后，真实的风险和异常往往被淹没在众多告警中，无法第一时间被感知到。</p><p>用一句话来概括，就是「太多的告警就相当于没有告警」。</p><h2>2.2 问题分析</h2><p>我们认为，这主要由以下四部分原因导致：</p><p>告警定义不合理：很多规则缺乏有效的维护，大量的规则在触发后，并不代表有异常发生，业务也不会去处理。此外，有些告警的粒度太细，导致同一异常触发后产生大量的告警，放大了整个通知的影响。</p><p>通知人数放大：由于历史组织架构的变更或临时排查问题，定位权限相耦合，导致服务树长期缺乏治理，造成告警通知人数的大幅度放大，经常发给一些无关的人员。</p><p>缺少分析治理工具：虽然大家都知道告警太多了，需要治理，但是却没有头绪，也没有合适的平台能力帮助他们分析告警主要集中的部分，从而进行有针对性的治理。</p><p>缺乏有效的运营机制：大家对治理告警的动力不足，同时也缺乏有效的机制和规范约束。在历史上可能经过一些短期治理后，告警又出现反弹，治理效果就不复存在。</p><h2>2.3 告警治理的三个阶段</h2><p>在分析了告警泛滥的原因后，我们开始了告警治理，这个过程主要分为三个阶段。 <img src="https://oscimg.oschina.net/oscnet/up-88282d9da6f4baae2fd9486d47eae1f9705.png" alt="file" referrerpolicy="no-referrer"></p><p>第一阶段：目标设定</p><p>经过多轮的会议和讨论，我们确定了告警数的指标，将原先每周超过 1000 条的告警数量降低到每周 80 条。这个目标在初始阶段看起来几乎是不可能完成的。然而，我们认为这 80 条告警是一个业务人员能够逐条响应处理的合理范围。于是，我们坚持以这个目标去执行，并尽力去达成。</p><p>第二阶段：数据分析</p><p>我们将告警数据集成到数据仓库中，提供了多维度的分析视图，为告警治理提供了数据支持。通过计算公式来确定影响因子，公式基于告警通知数量，即：告警通知数量=告警数<em>每次触发通知的人数</em>降噪系数。这个公式帮助我们明确了治理的方向和重点。</p><p>第三阶段：治理动作</p><p>在这个阶段，我们开始执行一系列治理动作。</p><p>首先，优化了告警项，与 SRE 和平台同事一起评估了默认告警项的合理性，对无效的告警项进行了关闭处理。对于一些不合理的告警项，我们评估并优化了其表达式和默认阈值等条件，以降低告警噪声并提高告警的有效性。</p><p>其次，为了解决通知人数放大的问题，优化了告警接收人的设置。我们深度参与并推动了服务树研发和负责人角色的校准，并推出了值班，升级等能力，以缩小告警的通知范围，有效地降低了通知人数放大的噪声。</p><p>最后，丰富了通道的告警降噪策略，支持了规则组的微调拦截能力，以及多维度下的告警汇总和聚合能力，从而更高效降低了告警噪声。</p><h2>2.4 告警治理过程经验总结</h2><p>在进行了一系列的告警治理行动后，我们对治理过程进行了总结和思考。主要从以下三个方面进行分享：</p><p>1）异常召回是底线</p><p>在整个治理过程中，集中处理的主要是无效的噪声告警，然而，绝不能忽视真实且有效的告警。在治理中，我们始终坚守一个原则，即不能牺牲异常的召回率。因此，我们将注意力集中在那些持续触发、重复触发以及异常放大等不合理的规则上，以及 Top 级别的规则上，并对这些问题进行专项治理。</p><p>2）运营推进不可少</p><p>实际上，治理过程就是一个运营推进的过程。在这个过程中，创建了数十个群组，制定了无数的治理、推进和跟进文档，以确保整个密集且强制性的告警治理工作的落实。同时，也与各个场景平台以及 SRE 进行了紧密合作，共同推动了告警治理工作。</p><p>3）分层分级抓重点是方向</p><p>我们借鉴了毛剑老师的理念，强调分层分级，抓住重点，尤其是保证业务可用性的核心告警。对于事件类的告警，建议记录并可查询，以避免淹没其他重要的告警通知。对于一些不适合直接通知业务侧的依赖告警，建议通过关联的方式来呈现，这样可以有效地降低告警的噪声。</p><h2>2.5 告警治理效果</h2><p>近半年地推式的告警治理，告警数据得到显著改善：</p><p>中位数告警 1000 次/周减少到 74 次/周，减少到原来的 7.4%；</p><p>整体告警通知数从治理前 300w+减少到 22w+，减少到原来的 7%；</p><p>人均告警通知数从 1600+减少到 140，减少到原来的 8.8%； <img src="https://oscimg.oschina.net/oscnet/up-4aaba5026a5563dc1f202fb6d8ec6184710.png" alt="file" referrerpolicy="no-referrer"></p><h2>2.6 建立长效治理机制</h2><p>为了确保告警治理所取得的成果能够持续稳定，我们构建了一套长效治理机制，具体包含以下三个方面：</p><p>1）便捷治理分析工具</p><p>包含了一个告警治理分析大盘，它被集成在告警平台上。这个大盘支持从业务、个人和公司等多个视角，通过多个维度对告警的分布和趋势进行分析。此外，我们还利用了一些治理工具，为快速治理提供了必要的能力。</p><p>2）数据报表订阅</p><p>我们与 SRE 各个组件平台达成了共识，制定了共同的目标，并生成了各类数据报表的订阅。持续跟进这些报表，以防止告警的恶化，并持续进行告警治理。 <img src="https://oscimg.oschina.net/oscnet/up-c3811ee980a3d066894a0537c26b3846b35.png" alt="file" referrerpolicy="no-referrer"></p><p>3）接入管控</p><p>针对新接入的规则和平台场景，增加了一些告警数据接入的人工校验，以及平台侧的校验和噪声监控。对于一些不合理的规则，我们会建议对应的接入方进行优化，以保持告警治理成果。</p><h1>三、告警根因分析是如何设计和应用的？</h1><p>结合当下业界广泛运用的前沿技术，例如异常检测、智能降噪、智能合并策略以及根因分析等，我将重点分享 B 站在根因分析方面的实践和实战经验。</p><h2>3.1 根因分析背景</h2><p>随着 SLO 体系的日益完善，更多的业务被接入到 SLO 体系中。这使得我们有了明确的异常定义和触发对象，能够更精确地实施根因分析。</p><p>此外，B 站已经设定了 「1-5-10」 的目标。目前，已经通过优化告警计算采集和通道，实现了 99 分位端到端一分钟内的问题发现。然而，对于 5 分钟的定位，仍存在一些瓶颈。定位过程过于依赖人工经验，存在一定的不确定性。人工专家经验因人而异，同时受场景影响，导致定位效率也不一致。另外，由于平台能力的建设和交互，以及一些极端情况下的响应延时，如凌晨故障或者出差等场景，都会影响定位效率。</p><p>最后，用户需求的积累也在不断增加。随着业务和基础设施的增长，人们越来越关注告警定位的效率，并积累了大量定位告警的经验。因此，对于根因分析的需求日益迫切，同时，根因分析的实施条件也逐渐成熟。</p><h2>3.2 根因分析设计</h2><h3>3.2.1 根因分析设计 1.0 版</h3><p>首先，我们采用了以 SLO 告警为基础的设计方案，对微服务架构下的黄金指标进行定位能力的设计，这就是 1.0 版根因分析设计。整个设计方案主要包含三个阶段。 <img src="https://oscimg.oschina.net/oscnet/up-9bd92ad17719b87e37ee6ac443eaf813c83.png" alt="file" referrerpolicy="no-referrer"></p><p>首阶段，我们监听 SLO 的告警触发，关联错误的范围和数据，然后基于这些数据分析日志指标，挖掘出异常的维度。例如，错误可能集中在特定集群的某个实例下，或者某个上游请求的某个接口。</p><p>第二阶段，我们根据这些错误维度，对应用侧的链路调用进行关联，找出异常期间的异常链路。通过聚合分析，能区分出耗时和错误的场景，通过关键路径分析和剪枝下钻的方式，定位到异常链路下的异常节点。</p><p>最后一阶段，将定位到的异常节点映射到知识图谱中，通过数据图谱关联到相关的数据库、缓存、消息队列、容器、机器、交换机、机柜、机房等信息。然后，结合异常、告警、变更等信息，通过关联分析模型进行打分推荐，最终推荐出可能的 Top 根因排序。</p><p>尽管这个 1.0 版的根因分析设计在某些场景下的准确率可以接受，但是它仍然存在一些瓶颈。</p><p><img src="https://oscimg.oschina.net/oscnet/up-54c493835c8d5726c828410f1bc25b115b6.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.2.2 根因分析设计 2.0 版</h3><p>在设计 2.0 版的根因分析时，我们进行了全面的调研，深入了解了业界资深的 SRE 和业务同事们在定位问题时的过程。</p><p>总结下来，这个过程主要是：在告警触发后，根据专家的经验，关联到具体的异常事件；然后再根据这些经验，分析这个异常可能由哪些原因导致，并找出这些原因的相关指标和日志等观测数据；最后，通过观察这些数据，判断出导致异常的根源。</p><p>在设计 2.0 版的过程中，我们力求将这个过程普遍化，并构建一个异常知识图谱，将专家的经验沉淀下来。同时，也开放了根因分析的集成和知识目录的功能，提供通用的根因分析能力。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e5caf92711bcb72bd249bb36169653cf1be.png" alt="file" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-f219736ec60c443fe1e4c5ee319640d9a75.png" alt="file" referrerpolicy="no-referrer"></p><p>根因分析的实现主要围绕知识的定义。这里的知识主要是基于异常节点定义。每个异常都会定义在具体的某个实体节点下，例如某个应用或某个数据库的集群实例。每个异常都会关联到具体的数据节点，比如日志、指标、告警等，通过这些数据我们可以检测和判断异常的发生。同时，异常之间也存在传导关系，一个异常可能由哪些异常导致，这些异常之间的传导链路和关联关系是怎样的。这就是我们在知识工程中定义的整个知识结构。</p><p>这种基于知识图谱的根因分析方式，很好地解决了 1.0 版中遇到的问题。使我们能够更深入地理解异常发生的原因，更准确地定位到问题的根源。通过将专家的经验进行系统化的沉淀，不仅提高了问题定位的效率，也使得知识的传承和积累成为可能。</p><h3>3.2.3 AIOps 算法支持</h3><p>根因分析的能力建设，离不开 AIOps 算法的支撑。目前，我们已经构建了一个全面的算法体系，设计了指标、日志、事件、链路等多个场景。同时，也根据不同类型的数据，支持了时序预测、异常检测、指标分类以及日志聚类、多维下钻，和事件聚类、链路分析等多个场景的算法能力。 <img src="https://oscimg.oschina.net/oscnet/up-59882e82b01a1f6dfdd569508b48de9e812.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.2.4 关联分析模型升级</h3><p>在关联分析的过程中，我们将异常图通过特征构建、模型加载，基于模型推理预测并打分，最终推荐出异常的根因和传导路径。特征设计包括：时间依赖特征、图关系/距离特征、因果特征、路径相似特征、事件类别特征。</p><p>模型构建方面，在初期主要是基于冷启动的方式，预定义了一些异常之间的传播系数。随着样本标注数据的增多，开始进行模型的训练，并基于模型进行推理和推荐。此外，我们也支持 GBDT 模型，以进一步提升关联分析能力。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d6b0445d907edbb174e1774270aaad5e9fe.png" alt="file" referrerpolicy="no-referrer"></p><h2>3.3 难点和重点</h2><p>在根因分析的过程中，我们面临着一些难点和重点。难点主要在于，如何有效评价推荐的根因，以及如何获取用户的准确率和评价数据。这对于评估不同版本，以及根因分析的准确率和有效性，以及帮助模型进行迭代至关重要。为了解决这个难题，我们进行了以下四部分工作：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5420196edcfd8b93bbbd8b23c00f71ee132.png" alt="file" referrerpolicy="no-referrer"></p><p>在整个过程中，一个重点是围绕专家经验的收集和构建。我们会与不同业务和 SRE 同学深度沟通，梳理相关的异常知识和专家经验，完成这部分知识的定义。</p><p>对于组件方面，我们会与相关同学持续完善这部分知识的定义和构建能力。针对一些特殊场景，也会提供外部专家经验的集成方案，提供根因分析的集成能力和接口，让外部的根因也可以通过分析能力完成，实现人工告警的推荐、展示和评价。</p><h2>3.4 案例分析</h2><h3>3.4.1 上游流量突增导致服务限流，可用率下降</h3><p>在这种情况下，可以基于告警关联到具体服务的 SLO 异常，并且下钻得到具体的异常接口和错误。同时，通过异常关联分析可以检测到上游的流量突增，明确具体哪一个入口的流量突增。有了这些信息，业务侧可以对上游的服务进行一些限流的配置并进行修复。</p><p><img src="https://oscimg.oschina.net/oscnet/up-447ee94180d00bc126ef72c16b89a733600.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.4.2 下游变更导致服务异常影响网关接口可用率</h3><p>可以通过根因分析关联到具体的链路，并关联到具体下游的异常和变更。最终，可以推荐出 AI 服务的变更是影响网关接口的主要原因。业务同学可以快速找到对应的变更人，然后进行排查和回滚等止损操作。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d0179cd8afb98967fa016c6b5edc192f2ce.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.4.3 下游 Redis 请求异常影响服务接口</h3><p>可以通过内部分析以及异常关联到具体的服务，并构建起异常的传导路径。同时，可以推荐出具体的异常请求耗时和日志。此外，业务侧也可以与相关组件的同学一起进行更深入的定位。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5ffa4fd875968133050d7a1cdeac23233f3.png" alt="file" referrerpolicy="no-referrer"></p><h2>3.5 效果评估</h2><p>根因分析已经落地，并取得了一些成效——</p><p>根因分析次数：20652/天</p><p>准确率：87.9%</p><p>召回率：77.5%</p><p>分析耗时 95 分位：10s</p><p>平均分析耗时：4s 内（这意味着，在告警发出后，平均仅需 4 秒钟就可以推荐出根因，业务人员打开告警卡片就可以直接看到对应的异常根因。）</p><p><img src="https://oscimg.oschina.net/oscnet/up-c32a5ed1c13a8e5e899857ff7a6633ab6ae.png" alt="file" referrerpolicy="no-referrer"></p><h1>四、总结与展望</h1><p>设计告警平台时，需要考虑到多种多样的业务需求和不同的应用场景。理解这些需求的本质，然后基于这个本质来构建平台的能力以及关键功能模型，并设计出闭环逻辑，以此来设计出更贴近业务需求的告警平台。其次，告警治理过程是必不可少的。无论告警的数量多少，只有通过完善的告警治理机制，才能使整个系统的闭环优化规则的定义，持续提升告警的有效性，发挥告警的价值。最后，告警与人工智能的结合是未来的发展趋势。通过深度结合的一些能力，可以提升故障发现的准确率，减少定位和恢复止损的时间，为质量管理和系统稳定性提供保障。（全文完）</p><h1>Q&amp;A：</h1><p>1、这个告警治理是否主要靠人力筛选减少规则？</p><p>2、业务侧的告警关联降噪可以举个例子吗？是在监控侧关联还是在告警侧关联？业务告警可以和基础告警关联吗？</p><p>3、告警后有进一步的自动分析场景吗？</p><p>4、监控告警通知的发送状态和效果怎么管理？怎么处理通知失败或异常的情况？</p><p>5、在告警合并方面，高优告警怎么不被淹没？同时保证低优告警的质量巡检？</p><p>6、怎么优化根因分析的效率和准确性，来支持实时分析和批量处理呢？根因分析过程中，大量的数据和日志信息怎么管理和存储？有哪些最佳实践和经验可以分享？</p><p>以上问题答案，欢迎点击「<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.shulie.io%2F%3Fp%3D7721" target="_blank">阅读全文</a>」，观看完整版解答！</p><p>声明：本文由公众号「TakinTalks 稳定性社区」联合社区专家共同原创撰写，如需转载，请后台回复「转载」获得授权。</p><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 02:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/5129714/blog/10321815</guid>
            <link>https://my.oschina.net/5129714/blog/10321815</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Oxlint 正式面市，JavaScript 开发者的新选择？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 12 月 12 日，JavaScript 和 TypeScript 开发者们迎来了一个新工具的诞生——Oxlint。这个被设计用来快速捕捉错误或无用代码的 JavaScript linter，以其显著的性能优势和易用性宣告了自己的市场入场。据报道，Oxlint 能够在仅需几秒钟的时间内完成原本 ESLint 需要 75 分钟才能完成的任务，这对于那些在持续集成环境中追求高效的大型项目来说，无疑是一种极具吸引力的改变。</p><p>然而，在技术社区，特别是在 HackerNews 上，对于 Oxlint 的讨论并非全然积极。一部分人担忧，尽管 Oxlint 在速度上有显著提升，但这种优势对于日常的开发工作可能并不那么重要。毕竟，ESLint 的执行速度问题在多数情况下并不明显，它只在大规模运行 lint 任务时才可能成为瓶颈。此外，Oxlint 的出现意味着可能需要重新实现 ESLint 的许多规则，这不仅降低了与现有生态的兼容性，也给未来的规则和语法更新带来了同步维护的压力。</p><p>另一方面，对于大型项目，优化 ESLint 的配置，比如仅扫描修改过的文件，可能就足以解决速度问题，而无需转向全新的工具。这引发了一个更深层次的问题：开发和维护一个全新的工具是否真的值得，特别是对于商业项目而言，这种成本与收益的权衡需要更加审慎。</p><p>而且，不可忽视的是，Oxlint 在初期可能无法与 ESLint 的规则集完全兼容，功能上可能不如 ESLint 丰富。这对于那些依赖 ESLint 深厚生态的项目来说，可能是一个不小的挑战。此外，关于 Oxlint 的性能提升，有观点认为应该深入分析 ESLint 存在的性能瓶颈，并进行针对性优化，而不是简单地通过更换工具来解决问题。</p><p>在这样的背景下，Oxlint 的出现无疑给 JavaScript 和 TypeScript 的开发者们提供了一个新的选择。它的高效性和易用性对于一些特定场景下的需求来说，可能是一个不错的解决方案。但同时，它也带来了一系列的考量，包括对现有生态的兼容性、功能的完备性，以及长期维护的可持续性等。</p><p>那么，面对这样一个新兴工具，开发者们又该如何选择？是否应该追求速度和效率，还是应该更加重视生态的完整性和成熟度？Oxlint 是否能够在未来的技术演进中找到自己的定位，或者说，它能否引领一种新的开发工具趋势？这些问题，可能还需要时间和更多的实践来回答。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 01:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271287</guid>
            <link>https://www.oschina.net/news/271287</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[生成式 AI 的落地焦虑，如何破？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span>自 ChatGPT 火爆出圈以来，各式大模型与生成式 AI 技术喷涌而出，医疗、金融、出行、消费零售、互联网等各个行业都在寻找利用生成式</span></span><span><span> AI 技术赋能业务</span></span><span><span>创新</span></span><span><span>的方法。然而，</span></span><span><span>从摸索到落地，</span></span><span><span>企业</span></span><span><span>在应用</span></span><span><span>用生成式 AI 技术尚存在门槛，使用现成的技术服务又会产生安全等方面的顾虑，比如业务数据泄漏等问题。一时间，许多企业陷入进退两难的境地。本篇就来说道说道企业在落地生成生式 AI 应用过程中的那些事。</span></span></span></span></p><ul><li><h2 style="text-align:left"><span><span><strong><strong><span><span><strong>从模型选择到业务安全，生成式 AI 应用诞生的曲折</strong></span></span></strong></strong></span></span></h2></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>实际上，生成式 AI 市场经过一年多快速的发展，一方面市场上涌现出很多</span></span><span><span>大模型与配套服务，另一方面，企业面临的难题也在与日俱增。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>首先，从模型的选择开始，眼花缭乱的大模型就已经够厂家喝上一壶。5 月 28 日，由中国科学技术信息研究所、科技部新一代人工智能发展研究中心联合相关研究机构编写的《中国人工智能大模型地图研究报告》正式发布，报告显示，我国 10 亿参数规模以上大模型已发布近 80 个。再到 10 月中国新一代人工智能发展战略研究院发布的《2023 中国新一代人工智能科技产业发展报告》显示，目前国内大模型总数达 238 个。而据北京经信局数据，截至 10 月初，北京发布大模型数量达 115 个，其中通用大模型 12 个，垂类大模型 103 个。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>按照这个发展趋势，「百模大战」或许很快就会升级为「千模大战」。而企业如何选择大模型便会难上加难。在具体应用场景中，企业需要在准确性和性能平衡间作出衡量，有效地比较模型并根据其首选指标找到最佳选择，这就需要深厚的数据科学专业知识，也会耗费大量的人力时间成本。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>而模型的选择只是开始，确定模型之后，还需要结合自身业务，做模型的精调、训练等工作。在这一步，公司的业务数据类型与大模型输入所要求的数据类型需要做一定适配，同时输入的数据需要具有代表性、多样性、一致性和可靠性，这样才能实现效果更佳的输出，这便要求企业需要有既懂业务，又懂大模型技术的工程师对数据进行整理。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>此外，大模型的精调也需要大量的算力，需要投入大量的资金和时间来购买和维护硬件设备，或者租用云服务，同时基础设施也需要长时间的维护。而大模型技术作为新兴技术，许多公司并没有相应的人才储备与经验，这对企业来说也是不小的压力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>模型本身的问题解决了之后，企业还要面临安全隐患。比如很多使用方会担心，用了某个大模型，那么自己的数据会不会都被模型方看到甚至泄露？会不会导致敏感信息泄漏，或是生成违规内容等等？那么，企业就需要确保数据在传输、存储和处理的过程中不会被泄露或者滥用，以免给业务和声誉带来损失。</span></span></span></span></p><ul><li><h2 style="text-align:left"><span><span><strong><strong><span><span><strong>亚马逊云科技助力企业安全构建生成式 AI 应用</strong></span></span></strong></strong></span></span></h2></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>面对种种挑战，对于许企业来说，最佳选择可以是给自己找一个 AI 助手，全方面辅助完成 AI 能力的嵌入，最常见的便是云上大模型平台和服务。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>2023 年 11 月 28 日，2023 亚马逊云科技 re:Invent 在美国拉斯维加斯盛大开启，并于 12 月 2 日圆满落下帷幕。2023 年 12 月 12 日起，2023 亚马逊云科技 re:Invent 中国行城市巡展活动将在 10 大城市开启，覆盖北京、上海、广州、深圳、成都、青岛、南京、西安、杭州、长沙 10 个城市！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><img alt="" height="1068" src="https://oscimg.oschina.net/oscnet/up-2aec5379c01dccaa8d1cb0c81c83e824ec0.png" width="1600" referrerpolicy="no-referrer"></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>作为全球云计算领域的年度风向标，2023 亚马逊云科技 re:Invent 为全球云计算爱好者和构建者带来了最新的产品和技术发布、最前沿的领导者洞察和全球云计算的最佳实践。在今年 re:Invent 中，一系列重磅发布成为大会焦点，从 Serverless、生成式 AI 时代的数据战略、芯片与云底座创新，到 Amazon Bedrock 的重磅更新、企业级生成式 AI 应用 (Amazon Q</span></span><span><span>) 的全新发布等等，系列组合拳为企业落地生成式 AI 应用全方位护航。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="1067" src="https://oscimg.oschina.net/oscnet/up-c52755aef19a7aa20abb1e9cd7e8662d7ab.png" width="1600" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>在多个新发布的动作中，一项全面托管服务的重磅更新引人注目——Amazon Bedrock 发布更多模型选择和全新强大功能。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>首先，Amazon Bedrock 上集成了 AI21 Labs、Anthropic、Cohere、Meta、Stability AI 和亚马逊的多种行业领先大语言模型和其他模型，用户可轻松访问。不仅如此，为了帮助客户在纷繁的模型中选择更适合自己的，Amazon Bedrock 新功能可帮助客户高效评估、比较和选择最适合其应用场景和业务需求的模型。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>确定模型之后，企业往往需要针对模型做适配，或者说是扩展调优，最大程度地释放数据价值。针对这些部分，Amazon Bedrock 知识库功能使用上下文和相关公司数据定制模型响应：组织希望使用专有数据补充现有模型，以获得更相关和更准确的响应。针对模型调优，Amazon Bedrock 中的 Cohere Command、Meta Llama 2 和 Amazon Titan 模型支持调优，为客户的模型定制提供更多选项，Anthropic Claude 也即将支持调优。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>此外，Amazon Bedrock 也兼备代理功能，可以自动执行，使用公司系统和数据源执行多步骤任务。虽然模型能够有效地进行对话和创建新内容，但如果能够执行复杂的操作，例如解决问题以及与公司系统交互以完成任务（例如，旅行预定或订购替换零件），它们可以提供更多价值。然而，这需要定制化地将模型与公司数据源、API 以及内部和外部系统集成起来。开发人员必须编写代码来协调模型、系统和用户之间的交互，以便应用程序可以按逻辑顺序执行一系列 API 调用。为了将模型与数据源连接起来，开发人员必须部署 RAG，以便模型可以根据任务调整其响应。最后，开发人员必须配置和管理必要的基础设施，并制定数据安全和隐私策略。这些步骤非常耗时且需要专业知识，从而减慢了生成式 AI 应用程序的开发速度。现在正式可用、完全托管的 Amazon Bedrock 代理功能使生成式 AI 应用程序能够跨公司系统和数据源执行多步骤任务。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>最后，在交互安全层面。虽然许多模型使用内置控件来过滤不良和有害内容，但企业希望进一步定制交互，以保证话题始终与业务相关，符合公司政策，并遵守「负责任的 AI」的原则。例如，银行可能希望这样设置其在线助手：避免查询竞争对手、避免提供投资建议、以及限制有害内容。此外，应用户要求，可能要变换或隐去用户的个人身份信息（PII）以保证安全。企业希望以一种简化的方式在生成 AI 应用程序中强化关键策略和规则，以提供所答即所问的用户体验并支持更安全地使用该技术。Amazon Bedrock 的 Guardrails 功能现已推出预览版，使客户能够为生成式 AI 应用程序实施保护措施。借助 Amazon Bedrock 的 Guardrails 功能，客户可以根据应用程序要求和负责任的 AI 策略跨模型实施保护措施。这些应用程序根据客户应用场景和「负责任的 AI」原则进行定制，因此这一功能可以增强用户交互的安全性和隐私性。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="1067" src="https://oscimg.oschina.net/oscnet/up-28a6f412bca7e88f6847ddd2341600b1962.png" width="1600" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>目前，亚马逊云科技已经推出多款产品助力企业构建生成式 AI 应用，缓解 AI「焦虑」其中也不乏许多科技界合作伙伴。MongoDB 首席产品官 Sahir Azam 表示：「各行各业越来越多的客户希望利用生成式 AI 来构建下一代应用程序，但许多人担心数据隐私以及人工智能驱动的系统输出的准确性。为了满足客户的需求，我们将 MongoDB Atlas 作为 Amazon Bedrock 的知识库，以便我们的共同客户可以利用其运营数据安全地构建生成式 AI 应用程序，以符合最终用户期望的信任度和准确性来创建个性化体验。通过这种集成，客户可以访问行业领先的基础模型，并使用 MongoDB Atlas Vector Search 处理过的数据来创建应用程序，在正确的上下文中提供更多相关的输出。利用 Amazon Bedrock 知识库中内置的数据隐私最佳实践，客户可以节省在生成式 AI 运营上花费的时间，从而更专注于技术部署，以在，亚马逊云科技上提供更有吸引力的最终用户体验。」</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>当然，除了 Amazon Bedrock，2023 亚马逊云科技 re:Inven 还有许多重磅发布，并且在接下来的 2023 亚马逊云科技 re:Invent 中国活动中，亚马逊云科技也将对各个新产品新功能做深入解读。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="1067" src="https://oscimg.oschina.net/oscnet/up-c47b8d38d09f54435ff17dbe0dd4b647787.png" width="1601" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fhttps%3A%2F%2Faws.amazon.com%2Fcn%2Fproducts%2F%3Faws-products-all.sort-by%3Ditem.additionalFields.productNameLowercase%26aws-products-all.sort-order%3Dasc%26awsf.re%253AInvent%3Devent-year%2523aws-reinvent-2023%26awsf.Free%2BTier%2BType%3D*all%26awsf.tech-category%3D*all%26trk%3D6ffebce9-f4cb-4ff0-910e-6b6ee3c74dc8%26sc_channel%3Del" target="_blank"><strong><span>点击此处，一链速看亚马逊云科技 re:Invent 2023 的所有热门发布</span></strong></a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fhttps%3A%2F%2Faws.amazon.com%2Fcn%2Fproducts%2F%3Faws-products-all.sort-by%3Ditem.additionalFields.productNameLowercase%26aws-products-all.sort-order%3Dasc%26awsf.re%253AInvent%3Devent-year%2523aws-reinvent-2023%26awsf.Free%2BTier%2BType%3D*all%26awsf.tech-category%3D*all%26trk%3D6ffebce9-f4cb-4ff0-910e-6b6ee3c74dc8%26sc_channel%3Del" target="_blank"><strong>。</strong></a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 10:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271239</guid>
            <link>https://www.oschina.net/news/271239</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[稚晖君创业公司再融资，金额超 6 亿元，投前估值 35 亿元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2560285742488705" target="_blank">据报道</a>，稚晖君创业公司智元机器人近日完成新一轮 A3 融资。</p><p>本轮融资由蓝驰创投、中科创星、鼎晖投资、长飞基金、C 资本、高瓴创投、立景创新、三花控股集团、基石资本、临港新片区基金和银杏谷资本投资。 据了解，本轮投前估值为 35 亿元，融资金额超 6 亿元人民币。</p><p>目前，该公司正在进行新一轮融资，投前 70 亿元估值。截止发稿，官方并未给到回复。</p><p>智元机器人因创始人「稚晖君」彭志辉而出名，公司希望对标特斯拉的擎天柱，产品方向为人形机器人。今年 8 月，智元推出了<em><u><a href="https://www.oschina.net/news/254290">远征 A1 人形机器人</a></u></em>，并发布了其自研的 PowerFlow 关节电机，反关节的设计和灵巧手 SkillHand。</p><p><img src="https://static.oschina.net/uploads/space/2023/0818/134556_I0Zb_2720166.jpg" referrerpolicy="no-referrer"></p><p>智元机器人在 8 月发布会时表示，他们已经和多家头部制造业服务企业对接，并面向 3C 电子、汽车装备等不同场景，训练了很多如拧螺丝的动作，公司预计 2024 年产品会推向商业化落地。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 08:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271228</guid>
            <link>https://www.oschina.net/news/271228</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MariaDB 拆分 SkySQL，作为独立公司成立]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">MariaDB<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmariadb.com%2Fnewsroom%2Fpress-releases%2Fmariadb-finalizes-spinoff-of-skysql%2F" target="_blank"> 宣布</a>已将其 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fskysql.com%2F" target="_blank">SkySQL</a> 业务拆分为一家独立的云数据库公司，以负责构建和支持 SkySQL 产品。</span></p><p><span style="color:#000000">「我们相信，此次分拆将促进依赖 SkySQL 的客户顺利过渡。我们很高兴 SkySQL 产品将在一家新公司的领导下继续发展，同时让我们能够集中精力开发核心的 MariaDB 企业服务器产品。」</span></p><p><span style="color:#000000">未来，新公司 SkySQL Inc. 将承担 SkySQL 数据库即服务 (DBaaS) 的开发、销售和支持工作。MariaDB 将持有 SkySQL 的股权，以强调两家公司之间的长期合作关系。</span></p><p><span style="color:#000000">SkySQL DBaaS 产品是 MariaDB 数据库的云托管和生产级版本。SkySQL 表示，通过作为一个独立实体推出，它将能够加快向平台提供新功能的步伐。其主要优先事项之一是在 Microsoft Azure 上启动该服务。目前，客户可以通过 Amazon Web Services 和 Google Cloud 进行访问。</span></p><p><span style="color:#000000"><img alt="" height="294" src="https://oscimg.oschina.net/oscnet/up-a1e38eab7fc4e80eb5d8322843767666f63.webp" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">MariaDB 于 2020 年推出了 SkySQL，称它是流行的 MariaDB 数据库的云原生版本，是 MySQL 数据库的替代品。由于 SkySQL 是基于 Kubernetes 构建，因此它可以与任何类型的云基础设施相融合。</span></p><p><span style="color:#000000">SkySQL 的云原生特性意味着客户可以更轻松地管理其数据库部署。与 Oracle 等其他公司的数据库产品相比，它的许可和管理也更容易。此外，SkySQL 是首批支持行、列式以及组合行和列式存储的 DBaaS 服务之一，这是一种可以在同一个数据集上在一个位置处理事务和分析的技术。</span></p><p><span style="color:#000000">由于采用了 MariaDB 专有的 MaxScale 和 Xpand 技术，SkySQL 还声称比其他类型的数据库具有更高的可用性和更大的可扩展性。</span></p><p><span style="color:#000000">作为一个独立的实体，SkySQL 的领导团队包括：首席执行官 Nithin Rao、联合创始人 Jags Ramnarayan（首席技术官）和 Saravana Krishnamurthy (CPO)。曾在 MariaDB 中负责开发和运营 SkySQL 的核心技术团队也已加入该公司。</span></p><p><span style="color:#000000">Rao <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsiliconangle.com%2F2023%2F12%2F14%2Fmariadb-spins-skysql-independent-database-service-company%2F" target="_blank">表示</a>，通过分拆 SkySQL，新公司将确保 SkySQL 继续成为那些希望在云中获得最佳 MariaDB 体验的客户的「不二之选」。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 07:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271211/mariadb-spins-skysql-independent-company</guid>
            <link>https://www.oschina.net/news/271211/mariadb-spins-skysql-independent-company</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FolkMQ 「多中心」集群部署方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start">FolkMQ 是一个新起的内存型消息中间件。</p><h3>简介</h3><ul><li>采用 「多路复用」 + "内存运行" + "快照持久化" + "Broker 集群模式"（可选）+</li><li>基于<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsocketd.noear.org%2F" target="_blank">Socket.D 网络应用协议</a><span>&nbsp;</span>开发。全新设计，自主架构！</li></ul><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&quot;system-ui&quot;,&quot;Segoe UI&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"><tbody><tr><th>角色</th><th>功能</th></tr></tbody><tbody><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">生产端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发布消息（Qos0、Qos1）、发布定时消息（Qos0、Qos1）、发布重试</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消费端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">订阅、取消订阅</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消费端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消费-ACK（自动、手动）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">服务端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">发布-Confirm、订阅-Confirm、取消订阅-Confirm、派发-Retry、派发-Delayed</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">服务端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">内存运行、快照持久化（自动、停机、手动）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">服务端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">集群热扩展</td></tr></tbody></table><h3>特点</h3><ul><li>高吞吐量、低延迟（单机版，180K TPS）</li><li>扩展性（集群可」热扩展「服务节点）</li><li>持久性、可靠性</li><li>高可用（只要有」一个「同类节点在即可）</li></ul><h3>多中心集群部署演示：</h3><p><iframe frameborder="0" height="400" scrolling="no" src="https://player.bilibili.com/player.html?aid=409798174&amp;bvid=BV1vG411a7Q7&amp;cid=1367060964&amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &quot;system-ui&quot;, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"></iframe></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 04:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271182</guid>
            <link>https://www.oschina.net/news/271182</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 「泄露」 GPT-4.5，价格是 GPT-4 的 6 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 官网的产品价格订阅页面似乎意外地「泄露」了 GPT-4.5。按照页面的信息，GPT-4.5 的价格是目前 GPT-4 的 6 倍。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-31d1ece739917eff1f166c5dbe37cdaf3cd.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2FOpenAI%2Fcomments%2F18i5n29%2Fanyone_hear_of_gpt45_drop_today%2F" target="_blank">https://www.reddit.com/r/OpenAI/comments/18i5n29/anyone_hear_of_gpt45_drop_today/</a></u></em></p></blockquote><p>根据描述，最先进的模型带来了<strong>跨语言、音频、视觉、视频和 3D 的多模态功能，以及复杂的推理和跨模态理解</strong>，以及 3 个新型号：</p><ul><li>GPT-4.5</li><li>GPT-4.5-64k</li><li>GPT-4.5-audio-and-speech</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271170/openai-leak-gpt45</guid>
            <link>https://www.oschina.net/news/271170/openai-leak-gpt45</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[夸克浏览器 PC 版开启内测]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff"><span style="color:#555555">夸克浏览器今天正式开启 PC 版本的内测，安装包大小 165 MB，基于 Chromium&nbsp;112 内核版本打造，目前内测版本功能相对简单，主打夸克小工具和夸克网盘。</span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-7d2b1e9f052bd1f16e693666b844526c384.png" width="500" referrerpolicy="no-referrer"></span></span></p><p><span style="color:#555555"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-c1abc7d9868a44f006af303db9fc34bc1f2.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff"><span style="color:#555555"><img alt="" height="319" src="https://oscimg.oschina.net/oscnet/up-1a021e823d1e28e62da4d57b8883ec880ef.png" width="300" referrerpolicy="no-referrer"></span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555">安装完成，需要使用夸克浏览器手机版扫码登录，登录后的界面</span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555"><img alt="" height="338" src="https://oscimg.oschina.net/oscnet/up-118ef3c22895713a51398d5edfc8ff9bde0.png" width="500" referrerpolicy="no-referrer"></span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555">文件工具中心</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271168</guid>
            <link>https://www.oschina.net/news/271168</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.12.0 - 改进自动补全和布局导航]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>🚀 新功能</h2><ul><li>支持 MySQL 高级自动补全。</li><li>支持从 UI 上导入分类分级配置。 <img src="https://oscimg.oschina.net/oscnet/up-0268af7aad60dafccd3d2d9f573a25e45b2.png" alt="file" referrerpolicy="no-referrer"></li></ul><h2>🔔 重大变更</h2><ul><li>作废已有企业版试用证书。之后可以通过提交申请获取新的试用证书。</li></ul><h2>🎄 改进</h2><ul><li><p>改进整体布局和导航。</p></li><li><p>支持在 SQL 编辑器里显示以及查询 PostgreSQL 数据库分区表。</p></li><li><p>优化对数据库/实例/慢查询的过滤体验。 <img src="https://oscimg.oschina.net/oscnet/up-0e38c7ab958fb392f60f9f749b38a5a5e48.png" alt="file" referrerpolicy="no-referrer"></p></li><li><p>Schema 编辑器性能优化。</p></li><li><p>支持 TiDB 7.5。</p></li><li><p>提升 MySQL SQL 审核，的兼容性。</p></li></ul><h2>🐞 Bug 修复</h2><ul><li>修复了当结果太大无法查询 MongoDB 的问题。</li><li>修复了在 SQL Editor 中无法查询 PostgreSQL 视图的问题。</li></ul><h2>🎠 社区</h2><ul><li>感谢 @jinrenjie 提交 fix(smtp): fix host name error in smtp authentication #9674</li></ul><h2>📕 安装及升级</h2><p>参考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升级指南</a>。如果从之前版本升级，获取新版本后，重新启动升级即可。</p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10321743</guid>
            <link>https://my.oschina.net/u/6148470/blog/10321743</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[互联网大厂月薪分布：字节跳动超 5% 员工月薪高于 5 万]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>某统计机构公开了一份国内互联网大厂的月薪分布。从统计来看，贝壳、阿里、滴滴、拼多多、快手和腾讯有超过 60% 的员工，月薪都在 3-5 万区间。而拼多多和字节跳动，还有 5% 以上的员工月薪超过了 5 万。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6dee49384f61d67489bea92afa25362f142.png" referrerpolicy="no-referrer"></p><p>大家熟悉的华为，有 51% 的员工月薪在 3-5 万区间（3.4% 员工月薪超过 5 万），而小米这个数字为 47.5%。</p><p>事实上，不少互联网公司内部都有等级评定，而像华为、阿里、腾讯内部，级别高的员工甚至年薪+分红都轻松过百万。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271163</guid>
            <link>https://www.oschina.net/news/271163</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[赠书 + 5 折购书，作者线上亲解《MLOps 工程实践》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>如何实现 </strong><strong>AI</strong><strong> 规模化落地？</strong></p><p><strong>如何跨越 </strong><strong>AI</strong><strong> 工程化鸿沟？</strong></p><p><strong>如何解决 </strong><strong>AI</strong><strong> 落地的效果与效率难题？</strong></p><p>这三大问题，都可以在《MLOps 工程实践：工具、技术与企业级应用》这本书中找到答案。</p><p>《MLOps 工程实践》由第四范式创始人领衔撰写，腾讯、小米、百度等分享经验，涵盖生产级机器学习项目相关技术理论、工具和大厂案例，构建可靠、高效、可复用、可扩展机器学习模型。</p><p>12 月 18 日晚 19:00，《MLOps 工程实践》的三名作者陈庆、颜丙政、赵喜生将直播分享本书内容，并讲述写书背后的故事，一起探讨 MLOps 的过去、现在和未来。</p><p><img height="600" src="https://oscimg.oschina.net/oscnet/up-60cbe740936b6e154b981698fc29b5ca488.png" width="600" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p>此外，直播期间，我们还将对外<strong><span style="color:#2980b9">赠送 10 本《MLOps 工程实践》</span></strong>，在直播评论区互动或参与直播抽奖即有机会获得！</p><p>同时，在 12 月 18 日当天，定价 109 元的<span style="color:#2980b9"><strong>《MLOps 工程实践》将打五折！</strong></span>扫码入群，即可获取购书链接！</p><p><img height="401" src="https://oscimg.oschina.net/oscnet/up-c1ed9b7c34eb99c03694baa402a428eb7bd.png" width="414" referrerpolicy="no-referrer"></p><p><strong>直播主题：</strong>三大作者亲解 MLOps ——《MLOps 工程实践》读书分享会</p><p><strong>直播时间：</strong>12 月 18 日（周一） 19:00-20:30</p><p><strong>直播平台：</strong>「OSC 开源社区」 视频号</p><p><strong>主办方：</strong>开源中国、机械工业出版社</p><div><div><p><strong>直播嘉宾：</strong></p><div><p>&nbsp;&nbsp; <strong>主持人：</strong></p><p>&nbsp;&nbsp;孙越，星策社区产品经理</p><p>&nbsp;&nbsp; <strong>分享嘉宾：</strong></p><p>&nbsp;&nbsp;陈庆，第四范式大语言模型式说解决方案产品负责人</p><p>&nbsp;&nbsp;颜丙政，第四范式架构师</p><p>&nbsp;&nbsp;赵喜生，腾讯机器学习平台架构师</p><p><img height="1422" src="https://oscimg.oschina.net/oscnet/up-96816a36a647d5cac6e6102f7c1ece4591d.png" width="800" referrerpolicy="no-referrer"></p><p><strong>除了赠书之外，我们还有更多直播福利：</strong></p></div></div></div><ul><li><p>互动抽奖：在直播评论区提问，被直播嘉宾回复的用户可获 OSC T 恤 1 件，名额不限。</p></li><li><p>福袋抽奖：直播中将有多轮抽奖，参与就有机会获得 OSC T 恤、笔记本、马克杯 、前沿技术书籍等。</p></li></ul><p><img height="281" src="https://oscimg.oschina.net/oscnet/up-5107f5e07c513d574174e5301fed5a6be4c.png" width="500" referrerpolicy="no-referrer"></p><p>小伙伴们，我们直播间见～</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10321745</guid>
            <link>https://my.oschina.net/u/3859945/blog/10321745</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JavaScript 引擎 V8 年度回顾：新编译器、修改基础架构、改进 GC……]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>V8 官方博客<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv8.dev%2Fblog%2Fholiday-season-2023" target="_blank">回顾了</a></u> 2023 年的重要变化：通过创新的性能优化，V8 不断突破 Web 领域的可能性界限。比如引入新的中间层编译器，对顶层编译器基础架构、运行时和垃圾回收进行多项改进，从而全面提升速度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-bf9e793830df03255fd7b3a067d1fec862c.png" referrerpolicy="no-referrer"></p><p>除了性能改进之外，V8 团队还为 JavaScript 和 WebAssembly 添加了许多新功能。比如通过 WasmGC 将支持垃圾回收的编程语言用于 Web 开发（<u><em><a href="https://www.oschina.net/news/264807/wasmgc-chrome" target="_blank">Chrome 支持运行 Kotlin、Java 等 GC 编程语言</a></em></u>）。</p><p>此外还改进了沙箱基础设施，并为 V8 引入了控制流完整性 (CFI)，为用户提供了更安全的环境。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3394d169661bc1f898bec9fe7ebe5286e7a.png" referrerpolicy="no-referrer"></p><p><strong>V8 2023 重磅新特性回顾</strong></p><ol><li><p><strong>新的中间层编译器 Maglev</strong>：Maglev 是 V8 引擎的新中间层编译器，它的推出使得代码的优化速度大大提高。相比于现有的编译器，Maglev 的编译速度快了 10 到 100 倍，并且在 JetStream 和 Speedometer 等性能测试中取得了 8.2% 和 6% 的性能提升。</p></li><li><p><strong>新的顶层优化编译器架构 Turboshaft</strong>：V8 引擎还引入了 Turboshaft，这是一个用于顶层优化编译器的新内部架构。使用 Turboshaft 后，编译速度提高了一倍，这有助于节约能源并为未来的性能提升奠定基础。</p></li><li><p><strong>更快的 HTML 解析器</strong>：V8 团队对 HTML 解析器进行了优化，这导致 Speedometer 测试分数提高了 3.4%。这些变化也被 WebKit 项目采纳，从而对 Chrome 浏览器的性能产生了积极影响。</p></li><li><p><strong>更快的 DOM 分配</strong>：V8 团队还对 DOM 对象的内存分配策略进行了优化，这使得 DOM 对象的分配速度提高了 3 倍，并在 DOM 密集型测试中取得了显著的改进。</p></li><li><p><strong>新的 JavaScript 特性</strong>：V8 引擎还推出了一系列新的 JavaScript 特性，包括可调整大小的 ArrayBuffers、ArrayBuffer 传输、String isWellFormed 和 toWellFormed 等。</p></li><li><p><strong>WebAssembly 更新</strong>：V8 引擎为 WebAssembly 引入了多个新特性和性能优化，包括对多内存的支持、尾调用、放松的 SIMD 等。</p></li><li><p><strong>WebAssembly 垃圾回收</strong>：V8 引擎最终实现了 WebAssembly 垃圾回收（WasmGC），这使得可以将使用 Java、Kotlin、Dart 等垃圾回收语言编写的应用程序编译为 WebAssembly，从而提高了其运行速度。</p></li><li><p><strong>安全增强</strong>：V8 引擎还在安全方面进行了改进，包括改进了沙箱基础设施、引入了控制流完整性（CFI）等。</p></li></ol><p>原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv8.dev%2Fblog%2Fholiday-season-2023" target="_blank">https://v8.dev/blog</a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271159/v8-2023-recap</guid>
            <link>https://www.oschina.net/news/271159/v8-2023-recap</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox 为 Android 用户提供 450 多个新扩展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Mozilla 正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Fen%2Fmozilla%2Fnew-extensions-youll-love-now-available-on-firefox-for-android%2F" target="_blank">宣布</a>在 Addons.mozilla.org (AMO) Android 页面上，面向用户提供 450 多个新的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fzh-CN%2Fandroid%2F%3F_gl%3D1*72qen9*_ga*MTM5NzQ4MDI5My4xNzAwNjE4OTgx*_ga_X4N05QV93S*MTcwMjYwNzA0MC4xLjAuMTcwMjYwNzA0MC4wLjAuMA.." target="_blank">Firefox Android 版扩展</a>。</span></p><p><span style="color:#000000">「这一里程碑标志着一个新的开放式移动扩展生态系统的启动，开发者现在可以自由创建和发布扩展，用户也可以轻松访问并在 Firefox for Android 上安装这些扩展。」</span></p><p><img height="303" src="https://oscimg.oschina.net/oscnet/up-7126e1593955faa3278ba5deb2d5c413912.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Firefox 工程副总裁 Vicky Chin 称，扩展最初的意义就是人们用来定制自己的互联网体验的一种方式。Firefox&nbsp;是当下唯一一个支持开放扩展生态系统的主要 Android 浏览器。他们计划在未来几个月启用更多扩展，供用户选择并定制自己的移动互联网体验。</span></p><p><span style="color:#000000">现在的人在<span style="background-color:#ffffff">很多事情上都依赖于移动设备 — 快速信息搜索、阅读文章、听音乐、寻找食谱等。</span>目前一些可用的相关扩展程序有：</span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fen-US%2Fandroid%2Faddon%2Fmidnight-lizard-quantum%2F%3Futm_source%3Daddons.mozilla.org%26utm%2520_medium%3Dreferral%26utm_content%3Dsearch" target="_blank"><strong>Midnight Lizard</strong></a><strong style="color:#000000"><span>&nbsp;</span>– 阅读更轻松&nbsp;</strong></li></ul><p><span style="color:#000000">Midnight Lizard 扩展可以调节手机界面颜色，增加或减少亮度和对比度；还能添加蓝光滤镜、屏幕着色器，以及夜间模式。从而减轻眼睛疲劳，保持良好状态。</span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fen-US%2Fandroid%2Faddon%2Fdark-background-light-text%2F%3Futm_source%3Daddons.mozilla.org%26utm_medium%3Dreferral%26utm_content%3Dsearch" target="_blank"><strong>深色背景和浅色文本</strong></a><strong>&nbsp;– 保持简洁</strong></li></ul><p><span style="color:#000000">用户可以自由定制，让所有网页都以深色背景和浅色文本的方式呈现，或者也可只选择部分网页。</span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fen-US%2Fandroid%2Faddon%2Fworldwide-radio%2F" target="_blank"><strong>全球电台</strong></a><strong>&nbsp;– 尽情享受</strong></li></ul><p><span style="color:#000000">可直接从 Android 版 Firefox 浏览器访问来自世界各地的 50,000 多个广播电台。</span></p><p><span style="background-color:#ffffff; color:#000000">公告称，随着越来越多的开发者创建针对移动设备优化的内容，预计未来几个月还将出现一波新的 Firefox for Android 扩展浪潮。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 02:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271154/new-extensions-available-firefox-for-android</guid>
            <link>https://www.oschina.net/news/271154/new-extensions-available-firefox-for-android</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 代码助手盛行，编程语言排行榜都没法做了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>RedMonk 编程语言排行榜通过追踪编程语言在 GitHub 和 Stack Overflow 上的代码使用情况与讨论数量，统计分析后进行排序，其旨在深入了解潜在的语言采用趋势。因此在众多编程语言榜单中，RedMonk 编程语言排行榜在专业度和认可度方面称得上是业内天花板了。</p><blockquote><p>RedMonk 榜单的数据收集方式包含两部分：<br> -使用 GitHub Archive 作为数据源对 GitHub 数据进行分析；<br> -Stack Overflow 部分则直接使用其提供的实用工具&nbsp;data explorer，具体排序算法见<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2019%2F07%2F18%2Flanguage-rankings-6-19%2F">官方介绍</a>。</p></blockquote><p>该榜单一年发布两次，上次更新是 5 月（<u><a href="https://www.oschina.net/news/241358/redmonk-language-rankings-1-23" target="news">RedMonk 排行：Objective-C 日渐衰落</a></u>）。按照惯例，第 2 次更新是 11 月，但直到现在也没有任何动静。</p><p>昨日，官方<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Frstephens%2F2023%2F12%2F14%2Flanguage-rankings-update%2F" target="_blank">解释</a></u>了为何迟迟不发布新的编程语言榜单——原因是他们按照以往的方式获取数据后发现，收集到的数据量跟往年比较相差巨大。</p><p>自 ChatGPT 发布以来，各种 AI 代码助手大行其道，因此问答社区的整体提问数量大幅下降。而在 GitHub 中，根据 GitHub Archive 的数据，与 2022 年 2 月的 PR 相比，2023 年 1 月的 PR 量下降了约 25%，完全出乎意料。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fd179e77353ed33816985ce76dfca218f56.png" referrerpolicy="no-referrer"></p><p>RedMonk 称虽然早已知晓 Stack Overflow 的流量已出现显著下滑（<em><u><a href="https://www.oschina.net/news/251072/the-fall-of-stack-overflow" target="news">Stack Overflow 访问量大幅下降</a></u></em>），但没有预料到 GitHub 上的数据会出现如此重大的「异常」。</p><p>因此 RedMonk 指出，基于人工智能的代码助手的出现和兴起已经影响了 RedMonk 语言排名的数据。随着问题和知识共享从公共论坛转移到私人工具，他们从公开数据中确定有意义趋势的能力将无限期地改变。</p><p>RedMonk 称会继续跟踪这些趋势，<strong>并确定样本量的变化将如何影响他们进行排名</strong>，同时预告&nbsp;2024 年 1 月，发布新榜单。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 02:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271153/redmonk-language-rankings-update</guid>
            <link>https://www.oschina.net/news/271153/redmonk-language-rankings-update</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google Groups 停止支持 Usenet]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌宣布从&nbsp;2024 年 2 月 22 日开始，用户无法再使用 Google Groups（网址为 groups.google.com）向 Usenet 群组发布内容、订阅 Usenet 群组，或查看新的 Usenet 内容。但可以继续查看和搜索 2024 年 2 月 22 日之前在 Google Groups 上发布的历史 Usenet 内容。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3d4af7d4780a6e633853c6fc3460057d75c.png" referrerpolicy="no-referrer"></p><p>来源：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgroups%2Fanswer%2F11036538%3Fhl%3Den" target="_blank">https://support.google.com/groups/answer/11036538?hl=en</a></em></u></p><p>谷歌表示，在过去几年里，基于文本的 Usenet 群组中的合规活跃已显著下降，因为用户已转向更现代的技术和格式，例如社交媒体和基于 Web 的论坛。目前通过 Usenet 传播的大部分内容都是<strong>二进制（非文本）文件共享</strong>（Google Groups 不支持该项功能），以及垃圾邮件。</p><p>Usenet（/ˈjuːznɛt/）是一种在计算机上可用的全球分布式讨论系统。它是从通用的 Unix 到 Unix 复制（UUCP） 拨号网络架构中发展出来的。</p><p>杜克大学研究生汤姆·特拉斯科特与吉姆·埃利斯在 1979 年设计了 Usenet，并于 1980 年发布。用户阅读和发布消息到一个或多个主题类别，称为「新闻组」。Usenet 在许多方面类似于公告板系统（BBS），并且是现在广泛使用的 Internet 论坛的前身。</p><p>Linux 内核的命运齿轮启动正是由 Usenet 见证——1991 年 8 月 26 日，芬兰大学生 Linus Benedict Torvalds 向 comp.os.minix 新闻组的成员透露了出于 「业余爱好」 而正在研究操作系统，当时 Linus 在邮件中表示自己捣鼓的操作系统只是一个业余性质项目，不会像 GNU 那样庞大和专业。</p><blockquote><p>我正在研究一款（自由的）操作系统（就是个兴趣爱好，我不会搞得像 GNU 那么大那么专业），打算让它工作在 386 (486) AT 平台上。它从四月就开始酝酿了，马上就快好了。我希望那些喜欢或不喜欢 minix 的人能够反馈意见，因为我的系统和它有点类似（同样的文件系统的物理布局 —— 由于实际原因，还有些其他的东西）。</p><p>我现在已经移植了&nbsp;bash (1.08) 和&nbsp;gcc (1.40)， 而且看起来奏效了。这意味着我会在几个月内得到一些实用的东西。我想了解大多数人想要的特性是什么，欢迎各位积极提出建议，不过我不保证能实现 :-)</p><p><img alt="" src="https://static.oschina.net/uploads/space/2019/0826/211817_vyJK_2720166.jpg" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 02:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271146</guid>
            <link>https://www.oschina.net/news/271146</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
