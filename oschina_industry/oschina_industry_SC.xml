<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 23 Jan 2024 09:56:12 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[开放签电子签章企业版，业务线功能正确使用方法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>一、业务线功能说明</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>业务线全称为「开放签电子签章业务线管理」，顾名思义业务线功能主要是围绕用户不同业务场景下使用电子签章的业务管理。用户可根据不同的业务场景（人力资源合同签署、内部证明文件签署、企业对企业签署、企业对个人签署等），通过业务线功能配置不同的电子签署功能，从而更加便捷、安全的管理电子签章的应用。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>用户可通过业务线配置电子文件签署的业务流程，通过对业务线进行配置来确定和规范签署文件、签署方、签署过程，同时也极大的简化了签署发起的操作。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>二、功能特点</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>灵活规范：</strong></span></span></span></strong><span><span><span>通过业务线可快速构建出企业的各类签约场景，并进行标准化管理。例如，人事合同签署、内部文件审批签字、销售合同签署、对外报告盖章等场景；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>操作标准：</strong></span></span></span></strong><span><span><span>通过标准化的流程，确保各方按照一致的规范和要求进行文件签署；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>风险控制：</strong></span></span></span></strong><span><span><span>通过业务线控制，降低签署过程中因操作不当等带来的风险；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>提高效率：</strong></span></span></span></strong><span><span><span>自动化和简化发起流程，提高文件签署的效率和速度；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>合规性：</strong></span></span></span></strong><span><span><span>确保文件签署符合法律法规和企业内部政策；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>权限可控：</strong></span></span></span></strong><span><span><span>业务线设置各类权限，包括业务线本身的管理权、使用权，同时包括通过业务线发起的签署业务的数据查看权限、文件下载权限；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>三、业务线功能说明</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>1、视频讲解</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>（1）业务线介绍：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1oc411x7zu%2F%3Fspm_id_from%3D888.80997.embed_other.whitelist%26t%3D43" target="_blank">视频功能讲解</a></strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>（2）业务线配置介绍：</strong></span></span></span></strong></span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1Z94y1T7gB%2F%3Fspm_id_from%3D888.80997.embed_other.whitelist%26t%3D45" target="_blank"><span><span><span><span><strong><span><span><span><strong>视频功能讲解</strong></span></span></span></strong></span></span></span></span></a></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>2、文字说明</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>（1）基本信息设置</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>编号：</strong></span></span></span></strong><span><span><span>发起签署时，可根据预设的规则自动生成文档编号，统一一类签署场景的编号规范，减少发起人输入操作，编号规则支持文本、日期、流水号、时间戳，示例：KFQ-renshi-20230101-000001;</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>主题：</strong></span></span></span></strong><span><span><span>发起签署时，可根据预设的规则自动生成文档主题，统一一类签署场景的主题规范，减少发起人输入操作，主题规则支持文本、业务线名称、日期、流水号、时间戳、发起人姓名、接收方姓名，示例：KFQ-入职相关合同（2023 版本）-20230101-000001-李四;</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>签署方：</strong></span></span></span></strong><span><span><span>支持经办人发起时自行设置和经办人发起时，按照预设流程发起并签署两种方式。可设置签署顺序、发起方内部签署人和外部接收方；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>抄送：</strong></span></span></span></strong><span><span><span>是否允许抄送，为该业务线设置抄送时机、抄送的用户类型、指定抄送人；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>签约文件：</strong></span></span></span></strong><span><span><span>支持上传本地文件和选择在线模板，减少经办人发起时重复上传签约文件。同时，可限制经办人是否可删除或新增签约文件；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>附件：</strong></span></span></span></strong><span><span><span>限制经办人发起签署时是否可以上传附件；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>签署方式：</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>a、使用 CA 数字证书（符合电子签名法）：签署文件时，需要使用 CA 机构颁发的数字证书；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>b、使用平台防篡改证书（保护文件）（无法律效力）：签署文件时，使用平台下发的防篡改证书，该证书非 CA 机构颁发，仅用于文件保护，避免文件被篡改，签署后的文件不具备法律效力；</span></span></span></span></span></span></span></p><p><img height="709" src="https://oscimg.oschina.net/oscnet/up-3b855599317328959d0b6e8d2dbd23ef0d2.png" width="1280" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><span><span><span><span><span><span><span>图一、基本信息设置</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>（2）权限管理</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>业务线管理权限：业务线的管理权限和使用权限配置；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>签约文件权限设置：签约数据查看权限和签署文件下载权限配置.</span></span></span></span></span></span></span></p><p><img height="630" src="https://oscimg.oschina.net/oscnet/up-94a4f4e4dde46ddd76822def13d63575dbd.png" width="1280" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><span><span><span><span><span><span><span><span>图二、权限管理</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>（3）签署位置及参数设置</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>指定各签署方的签署位置；</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>如果签约文件中包含在线模板，可为模板中的各个参数指定对应的填写方，在签署环节时，各签署人可根据设置完成待签署文件的信息完善。</span></span></span></span></span></span></span></p><p><img height="708" src="https://oscimg.oschina.net/oscnet/up-921b6aa7ff79c0c801f4d5782b3d069f2a2.png" width="1280" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><span><span><span><span><span><span><span><span>图三、位置及参数设置</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><strong><span><span><span><strong>​四、总结</strong></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>开放签业务线具有灵活、便捷、安全的电子签署业务配置能力。接下来业务线将持续更新，添加更多配置功能，使开放签电子签章系统可以满足更多电子签业务场景。</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 07:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276436</guid>
            <link>https://www.oschina.net/news/276436</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Fedora 40 计划采用 Bpfman 作为默认 eBPF 程序管理器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:left">Fedora 40 正在考虑采用 bpfman 作为默认 eBPF 程序管理器，以简化 eBPF 程序的部署和管理。</p><p style="margin-left:0px; margin-right:0px; text-align:left"><img alt="" src="https://oscimg.oschina.net/oscnet/up-20aea944299992e9369a9cfe05627bf7e4d.png" referrerpolicy="no-referrer"></p><p>开发者在提案写道：「<em>bpfman 作为 eBPF 管理器，专注于简化 eBPF 程序的部署和管理。bpfman 是一个软件栈，旨在使加载、卸载、修改和监控 eBPF 程序变得更加容易，无论是在单个主机还是在 Kubernetes 集群中。我们的目标是在 Fedora 引入 bpfman，让系统能方便地加载 eBPF 程序。</em>」</p><blockquote><p style="margin-left:0px; margin-right:0px; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-a8b461fd85c4a7a0cfae3bf419d5b9e7681.png" referrerpolicy="no-referrer"><br><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffedoraproject.org%2Fwiki%2FChanges%2FDefaultBpfman" target="_blank">https://fedoraproject.org/wiki/Changes/DefaultBpfman</a></em></u></p></blockquote><p style="margin-left:0px; margin-right:0px; text-align:left">该提案目前正在等待 Fedora 工程和指导委员会 (FESCo) 的批准，很可能会在 4 月份出现在 Fedora 40 中。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 06:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276433/fedora-40-bpfman-ebpf-manager</guid>
            <link>https://www.oschina.net/news/276433/fedora-40-bpfman-ebpf-manager</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu Pro 包更新无法禁用引用户不满]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">一名 Ubuntu 用户在 Launchpad 上提交了一份针对 update-manager 的错误报告，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugs.launchpad.net%2Fubuntu%2F%2Bsource%2Fupdate-manager%2F%2Bbug%2F2047778" target="_blank">表达</a>了自己对 Ubuntu LTS 版本的软件更新工具 (Software Updater tool) 无法禁止显示 Ubuntu Pro 软件包更新的不满。</span></p><blockquote><p><span style="color:#000000">每次调用软件更新程序时，我都会看到一个 Ubuntu Pro 安全更新列表，底部还有一条信息，告诉我需要启用 Ubuntu Pro 才能更新，只有一个按钮可供选择，那就是"Remind Me Later"。我搜索了一下 Ubuntu Pro，想知道它到底是什么，最后得出的结论是我不需要它；但似乎没有任何方法可以永久拒绝安装它。每次重启电脑，我都会再次看到同样的文件，唯一的选择又是启用 Pro 或稍后提醒，而这两个选项都不能反映我的意愿和愿望。这究竟是一个选项，还是必须升级？作为用户，我对此感到很困惑。</span></p></blockquote><p><img height="263" src="https://static.oschina.net/uploads/space/2024/0123/140949_wfD7_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">他表示，也许这只是一个非常拙劣且引导性的营销伎俩，而不是软件本身存在 bug；但无论如何，有关 Ubuntu Pro 的这一困扰表明软件更新程序存在缺陷，官方应该提供一种能让用户拒绝升级的方法。</span></p><p><span style="color:#000000">Canonical 于去年更新了 update-manager（又称 Software Updater tool），无论用户系统是否启用 Ubuntu Pro，它都会显示可用的 Ubuntu Pro 软件包更新列表（如果未启用，则无法安装）。</span></p><p><span style="color:#000000">还有人反映称，对于一些不太懂行的人而言，此举更加迷惑。「我接到一些客户的电话，他们不知道自己的系统出了什么问题，在进行更新时会看到一个更新管理器窗口，里面有一些灰色的软件包，你无法删除，除非你启用 ubuntu pro。」</span></p><p><span style="color:#000000">Canonical 的 Oliver Grawert 对此进行了<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugs.launchpad.net%2Fubuntu%2F%2Bsource%2Fupdate-manager%2F%2Bbug%2F2047778%2Fcomments%2F7" target="_blank">回复</a>：</span></p><blockquote><p><span style="color:#000000">Pro 是一项完全免费的服务，适合个人和小型企业使用，它为用户提供了 2.5 多个附加软件包的安全修复......为了维护这一点，canonical 安全团队必须扩展规范的安全团队。维护这 2.5 万个软件包是有成本的，canonical 在这里所做的就是让企业为这些额外的工作付费，然后再免费提供给社区...</span></p><p><span style="color:#000000">为了确保这些企业不会免费攫取，需要建立一个控制机制，这也是为什么需要注册才能获得。</span></p></blockquote><p><span style="color:#000000">并反问用户，是更愿意安全漏洞被知而不报从而被恶意行为者利用，还是更愿意在更新时获得可用修复程序的列表。此外，他还邀请有想法的用户提出解决问题的方案，项目团队将进行考量：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fubuntu-pro-faq%2F34042" target="_blank">https://discourse.ubuntu.com/t/ubuntu-pro-faq/34042</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 06:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276430/ubuntu-pro-software-updater-issue</guid>
            <link>https://www.oschina.net/news/276430/ubuntu-pro-software-updater-issue</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FreeBSD 也要「锈化」？团队称考虑在基础系统采用 Rust]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>FreeBSD 开发者正在考虑允许在 FreeBSD 基础系统中使用 Rust 编程语言的好处和成本。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-a49c5ed65580e1dd715c12f8604797093fb.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.freebsd.org%2Farchives%2Ffreebsd-hackers%2F2024-January%2F002823.html" target="_blank">https://lists.freebsd.org/archives/freebsd-hackers/2024-January/002823.html</a></u></em></p></blockquote><p>邮件写道，在 FreeBSD 基础系统使用 Rust 的<strong>主要缺点是构建时间加倍。</strong>这是因为需要编译基于 LLVM 的 Rustc 编译器和 Rust 的所有附加功能，这些操作使得基础系统的构建时间大约是当前的两倍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a7d460b865a7215d966af4b4b1bd8a09b6e.png" referrerpolicy="no-referrer"></p><p>如果 FreeBSD 基础系统采用了 Rust，开发者可以重新 Rust 重写许多组件——而不是使用 C++，例如 ZFS 守护进程 (zfsd)、重写 devd、WiFi 用户空间代码也可以受益于用 Rust 编写，等等。列举部分如下：</p><blockquote><p>* ctl-exporter (I started this, but discovered that the CTL stats API is<br> &nbsp; unstable, so it can't live in ports. &nbsp;Instead, I had to do it in C).<br> &nbsp; https://github.com/freebsd/freebsd-src/commit/1a7f22d9c211f504f6c48a86401469181a67ec34</p><p>* fusefs tests. &nbsp;Absolutely impossible to do in C. &nbsp;I considered Rust, but went<br> &nbsp; with C++ so they could live in base. &nbsp;They are too closely coupled to<br> &nbsp; fusefs(5) to live out-of-tree.<br> &nbsp; https://github.com/freebsd/freebsd-src/tree/main/tests/sys/fs/fusefs</p><p>* devd. &nbsp;Currently C++, but imp suggested a rewrite.<br> &nbsp; https://github.com/freebsd/freebsd-src/tree/main/sbin/devd</p><p>* zfsd. &nbsp;Currently C++, but I've long pondered a rewrite. &nbsp;Using Rust would<br> &nbsp; make it more testable.<br> &nbsp; https://github.com/freebsd/freebsd-src/tree/main/cddl/usr.sbin/zfsd</p><p>* nscd. &nbsp;Currently C, but confusing and with no test coverage. &nbsp;I've<br> &nbsp; contemplated a rewrite myself, but I don't want to do it in C.<br> &nbsp; https://github.com/freebsd/freebsd-src/tree/main/usr.sbin/nscd</p><p>* The userland portion of the 802.11ac and Lightning stacks. &nbsp;scottl suggested<br> &nbsp; that these were good candidates for Rust.</p><p>* freebsd-kpi-r14-0 . &nbsp;https://crates.io/crates/freebsd-kpi-r14-0</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 05:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276426/freebsd-considers-rust-base</guid>
            <link>https://www.oschina.net/news/276426/freebsd-considers-rust-base</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[有道开源 RAG 引擎 QAnything 版本更新啦]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="208" src="https://oscimg.oschina.net/oscnet/up-67e056e24f60398bb7bf271d9d54549517a.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FQAnything" target="_blank" rel="nofollow">https://github.com/netease-youdao/QAnything</a></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><strong><span><span>近日，我们将我们的</span>RAG<span>（基于检索增强的生成，Retrieval Augmented Generation）</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA3NDgxOTk0Nw%3D%3D%26mid%3D2247487167%26idx%3D1%26sn%3D37b169a72c023534bca4e855fb74d384%26scene%3D21%23wechat_redirect" target="_blank" rel="nofollow">引擎 QAnything 开源了</a></strong></span><strong><span><span>，用户可以传入 doc, pdf, 图片，ppt, excel 等各种类型的文档，就可以基于这些文档问答，像 "</span>chatgpt<span>" 一样的体验。本次开源包括了 embedding, rerank, LLM，</span></span>向量数据库<span>等所有必要的模型和系统模块，用户可以一键下载，纯本地搭建大模型问答系统，马上开始使用。</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="957" src="https://oscimg.oschina.net/oscnet/up-7e9ee4cc9ff72de7100d208ace2888f68ab.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center">（QAnything 引擎系统架构图）</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><strong>QAnything 受到广大开发者的密切关注，<strong>开源近两周，</strong>star 迅速涨到接近 2000，昨日 QAnything 进入到了 github 的 trending 版。</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-9edabedec54be4f3aece687806112a66d1d.png" width="800" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span>&nbsp; &nbsp;</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="823" src="https://oscimg.oschina.net/oscnet/up-b90732602b9da060344c0372ed724bcc120.jpg" width="1026" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><strong>QAnything 开源后，广大用户给我们提了很多的意见。我们研发人员日夜不停的回答用户问题，并紧锣密鼓的改代码。昨日，我们发布了一个 Release 更新：</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="color:#000000"><strong>QAnything 版本 V1.1.0</strong></span><strong>，让安装过程更简单，体验更流畅。</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FQAnything%2Freleases%2Ftag%2Fv1.1.0" target="_blank" rel="nofollow"><span>https://github.com/netease-youdao/QAnything/releases/tag/v1.1.0</span></a></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span><strong>Features:</strong></span></p><p><span><strong>- 安装过程更简单</strong></span></p><p><span><strong>&nbsp; -&nbsp;</strong>优化启动流程，支持一键启动：执行 bash run.sh 即可</span></p><p><span>&nbsp; -&nbsp;优化安装过程的交互，提示信息更友好</span></p><p><span><strong>- 体验更流畅</strong></span></p><p><span>&nbsp; -&nbsp;优化前端启动速度，秒打开。感谢网友@jsoncode 的贡献！</span></p><p><span><strong>- 部署选择更多</strong></span></p><p><span>&nbsp; -&nbsp;优化显存占用，支持多 GPU 部署，目前支持单卡或双卡部署，双卡两张卡显存占用分别为 11G，5G</span></p><p><span><strong>- 其他优化</strong></span></p><p><span><strong>&nbsp;</strong><span>&nbsp;</span>-&nbsp;向量库占用空间减少到原来的 1/3&nbsp;</span></p><p><span>&nbsp; -&nbsp;优化 xlsx，html 切分 chunk 时 size 过大导致的解析失败</span></p><p><span>&nbsp; -&nbsp;优化知识库内只有单文档时回答的效果</span></p><p><span>&nbsp; -&nbsp;优化 pdf 解析效果，pdf 解析速度</span></p><p><span>&nbsp; -&nbsp;提供原始未修改 DockerFile</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"><strong>QAnything 还在不断迭代升级中，欢迎大家下载使用并提供宝贵反馈！</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 04:20:12 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/youdaotech/blog/10894309</guid>
            <link>https://my.oschina.net/youdaotech/blog/10894309</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[飞致云旗下开源项目 GitHub Star 数量突破 100,000 个！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start"><span><span style="color:#000000">2024 年 1 月 19 日，</span><strong><span style="color:#00355d">中国领先的开源软件提供商 FIT2CLOUD 飞致云宣布，其旗下开源项目在代码托管平台 GitHub 上所获得的 Star 数量已经超过 100,000 个。</span></strong>与此同时，飞致云旗下开源项目的月度新增软件下载次数也超过 100,000 次。</span></p><p style="color:#000000; text-align:start"><img alt="" height="1080" src="https://oscimg.oschina.net/oscnet/up-e9826cd18696f364c38f706941565519335.jpg" width="1920" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">飞致云的开源之旅起步于 2017 年 11 月对 JumpServer 开源堡垒机项目（</span></span><em><span><span style="color:#000000">https://github.com/jumpserver</span></span></em><span><span style="color:#000000">）的收购。此后基于长期的开源企业战略和持续完善的社区生态，飞致云相继创立 MeterSphere 开源持续测试平台项目（</span></span><em><span><span style="color:#000000">https://github.com/metersphere</span></span></em><span><span style="color:#000000">）、DataEase 开源数据可视化分析平台项目（</span></span><em><span><span style="color:#000000">https://github.com/dataease</span></span></em><span><span style="color:#000000">）和 1Panel 开源面板项目（</span></span><em><span><span style="color:#000000">https://github.com/1Panel-dev</span></span></em><span><span style="color:#000000">），并且于 2021 年 1 月收购 Halo 开源建站工具项目（</span></span><em><span><span style="color:#3e3e3e"><span style="background-color:#feffff">https://github.com/halo-de</span></span><span style="color:#3e3e3e">v</span></span></em><span><span style="color:#3e3e3e"><span style="background-color:#feffff">）。</span></span></span></p><p style="color:#000000; text-align:start"><img alt="" height="574" src="https://oscimg.oschina.net/oscnet/up-a1bf6c4efe509ab85e280ab4441fdccdbc9.png" width="1396" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">在创新与并购的双轮驱动下，飞致云以「为数字经济时代创造好软件」为使命的开源生态体系不断发展壮大。目前，飞致云旗下开源项目的贡献者超过 1,700 位，有超过 7,000 位社区用户提交 Issue，Fork 总数量超过 24,000 次，PR（(Pull Request）数量超过 43,000 次。另据不完全统计，飞致云开源社区交流总人数已经超过 30,000 人。</p><p style="color:#000000; text-align:start">飞致云旗下五大核心开源项目的产研体系高速迭代又彼此联动，并且通过开源社区运营持续收集用户反馈，与广大社区用户保持高频的良性互动，基于用户反馈不断优化开源软件产品。与此同时，飞致云的开源增值服务模式也在过去的六年间不断发展和优化。目前在中国市场，飞致云的开源付费用户已经超过 2,500 家，广泛覆盖金融、制造、能源、交通、医疗、教育、通信、传媒、房地产、互联网等行业。</p><p style="color:#000000; text-align:start">软件是支撑数字经济时代发展的重要基石。《「十四五」软件和信息技术服务业发展规划》指出，「开放、平等、协作、共享的开源模式，加速软件迭代升级，促进产用协同创新，推动产业生态完善，成为全球软件技术和产业创新的主导模式。当前，开源已覆盖软件开发的全域场景，正在构建新的软件技术创新体系，引领新一代信息技术创新发展，全球 97% 的软件开发者和 99% 的企业使用开源软件，基础软件、工业软件、新兴平台软件大多基于开源，开源软件已经成为软件产业创新源泉和‘标准件库’。同时，开源开辟了产业竞争新赛道，基于全球开发者众研众用众创的开源生态正加速形成。」</p><p style="color:#000000; text-align:start">FIT2CLOUD 飞致云 CEO 阮志敏表示：<strong><span style="color:#00355d">秉持「软件用起来才有价值，才有改进的机会」的核心价值观，飞致云正在向着「成为中国数字化团队首选的通用工具软件提供商」的愿景目标不断前行。在开源的道路上，我们与用户、与客户共成长。</span></strong></p><p style="color:#000000; text-align:start"><img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-2505ad47bc0e6df4ad47aa0868c55b792d0.png" width="1619" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><span>▲ 图 1 飞致云开源大屏（2024 年 1 月 18 日 14:00）</span></p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-74c6a47084bfb41b02f7e7ccb612faf1db8.png" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><span>▲ 图 2 飞致云公司概览大屏（2024 年 1 月 18 日）</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 04:18:12 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/10919084</guid>
            <link>https://my.oschina.net/u/4736111/blog/10919084</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Nacos 2.3.0 正式版发布，Nacos Controller 项目开源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者：杨翊</p><h2>新版本发布</h2><p>Nacos 2.3.0-BETA 版本经过 1 个多月的社区测试，修复了部分的问题并对部分新功能的使用进行了少量优化后，于 2023 年 12 月 7 日正式发布。</p><p>Nacos 2.3.0 版本基于&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247559032%26idx%3D1%26sn%3Dd9396e3bddc180e2bbeaea08c3286670%26chksm%3Dfae7ecb7cd9065a13b2aac2de154be3b682544b531c54fe3371fa8e78eef5953e05d6298010e%26scene%3D21%23wechat_redirect" target="_blank">2.3.0-BETA</a>&nbsp;版本为基础，主要进行了如下更新：</p><ul><li>基于能力协商机制，支持通过 Grpc 的方式进行持久化服务实例的注册及删除。</li><li>Console UI 中显示更多内容，例如部署模式等。</li><li>对参数校验功能的实现方式进行优化。</li><li>对 TopN 指标的实现进行重构，优化准确性和内存消耗。</li></ul><p>详细的更新日志请查看：</p><pre><code>## Feature
[#11393] Support register or deregister persistent instance by grpc.

## Enhancement&amp;Refactor
[#11275] Enhance console ui deploy, show more information like `mode`.
[#11298] Strip groupNamePrefix of instance serviceName at register or deregister.
[#11310] Simplify the validate method for serviceinfo.
[#11342] Simplify BatchDeregister instances conditions to ip and port.
[#11343] Simplified parameters checker control logic.
[#11352] Refactor topN logic to enhance memory usage and accuracy.

## BugFix
[#10353] Handling DataIntegrityViolationException and DuplicateKeyException together.
[#11299] Fix console ui auth pagination failure.
[#11382] Fix console ui listening query pagination failure.
[#11384] Fix console ui comparing configuration failure.
[#11390] Fix Config EncryptionPluginService order problem.
[#11442] Fix listen configuration check failed without namespace.

## Dependency
[#11216] Declare httpcore as direct dependency to fix avoid conflict.
[#11396] Upgrade jackson same with spring boot dependency.
[#11439] Upgrade some UI component to solve security problem.
</code></pre><h2>Nacos Controller 项目开源</h2><p>在云原生下，应用代码与运行环境可以通过 Helm 或 Kustomize 等软件进行交付、维护、CICD，但应用的 Nacos 配置依然需要手工地迁移、或使用控制枱修改发布配置。借助于&nbsp;Nacos Controller <strong>[</strong><strong>1]</strong> 项目，我们可以将 Nacos 配置管理下移到 Kubernetes 集群中，又或是可以将 Kubernetes 中 ConfigMap 配置上移到 Nacos 控制枱中，从而实现统一管理能力。</p><h3>Nacos 配置下移到 Kubernetes 集群中</h3><h4>工作机制</h4><p>Nacos Controller 监听集群内的 DC 资源，当 DC 资源发生变化时，Nacos Controller 将其中的配置内容同步到 Nacos Server 中。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d13902a108e460eea74465f3e4c110b0598.png" alt="" referrerpolicy="no-referrer"></p><h4>简易 Demo</h4><p>在 Nacos Controller 中，我们定义了一份 CRD：DynamicConfiguration（简称 DC），我们将 Nacos 配置保存在 ConfigMap 中，对配置的任何修改都通过 DC 将其中的配置同步到对应的 Nacos 服务端中。在后续的配置维护中，直接修改对应的 ConfigMap 即可。以下是一份简易的 Demo 示例：</p><pre><code>apiVersion: nacos.io/v1
kind: DynamicConfiguration
metadata:
    name: dc-demo-cluster2server
spec:
  dataIds:
  - data-id1.properties
  - data-id2.yml
  nacosServer:
    endpoint: &lt;your-nacos-server-endpoint&gt;
    namespace: &lt;your-nacos-namespace-id&gt;
    group: &lt;your-nacos-group&gt;
    authRef:
      apiVersion: v1
      kind: Secret
      name: nacos-auth
  strategy:
    syncPolicy: Always
    syncDirection: cluster2server
    syncDeletion: true
  objectRef:
    apiVersion: v1
    kind: ConfigMap
    name: nacos-config-cm

---
apiVersion: v1
kind: ConfigMap
metadata:
    name: nacos-config-cm
    namespace: default
data:
    data-id1.properties: |
      key=value
      key2=value2
    data-id2.yml: |
      app:
        name: test

---
apiVersion: v1
kind: Secret
metadata:
    name: nacos-auth
data:
    ak: &lt;base64 ak&gt;
    sk: &lt;base64 sk&gt;
</code></pre><h3>Kubernetes 配置上移到 Nacos 控制枱</h3><h4>工作机制</h4><p>首先需要用户创建 DC 资源指定需要同步哪些 DataId，Nacos Controller 根据读取到的 DC 配置，选择性监听 Nacos Server 中的相关配置并将配置改动同步到 Kubernetes 集群中。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d736813e431613b6413591d077040fda436.png" alt="" referrerpolicy="no-referrer"></p><h4>简易 Demo</h4><p>云原生下，应用除了需要加载 Nacos 配置外，还可能依赖一些环境变量，比如 JVM 参数通过环境变量注入。做得比较好的方式是通过 ConfigMap 等 Kubernetes 原生方式管理配置，通过引用的方式传递给应用 Pod。在 Nacos Controller 中，我们可以定义一份 DC，将 Nacos 服务端中的某些 DataId 同步到 Kubernetes 集群中的 ConfigMap 中，从而实现配置的统一管理。以下是一份示例 Demo：</p><pre><code>apiVersion: nacos.io/v1
kind: DynamicConfiguration
metadata:
    name: dc-demo-server2cluster
spec:
  dataIds:
  - APP1_JVM_PARAMS
  - APP2_JVM_PARAMS
  nacosServer:
    endpoint: &lt;your-nacos-server-endpoint&gt;
    namespace: &lt;your-nacos-namespace-id&gt;
    group: &lt;your-nacos-group&gt;
    authRef:
      apiVersion: v1
      kind: Secret
      name: nacos-auth
  strategy:
    syncPolicy: Always
    syncDirection: server2cluster
    syncDeletion: true
---
apiVersion: v1
kind: Secret
metadata:
    name: nacos-auth
data:
    ak: &lt;base64 ak&gt;
    sk: &lt;base64 sk&gt;
</code></pre><h3>云原生下的配置管理最佳实践</h3><p>在使用 Kubernetes 的场景下，一个微服务应用的配置被分割成两部份，一部分存放管理在 Kubernetes 集群中的 Secret 或 ConfigMap 中，另一部份存放管理与 Nacos 配置中心。对于运维人员，我们需要知道哪些配置是存放在何处且同时需要对两个平台的配置管理操作均有所了解，一来是增加了运维人员的知识门槛，二来是增加了应用配置运维的操作成本。通过 Nacos Controller 项目，我们将应用的所有配置集中于一处管理，降低应用配置运维的门槛与复杂性。</p><p><img src="https://oscimg.oschina.net/oscnet/up-15236dda6a0b791d16c3d87a0ff0ebbd209.png" alt="" referrerpolicy="no-referrer"></p><h4>面向 Kubernetes 运维偏好的用户</h4><p>通过 Nacos Controller 项目，我们将应用与应用配置的交付和维护集中在 Kubernetes 集群中。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ab4b6aba57a492717aa28a51934ed9fdddc.png" alt="" referrerpolicy="no-referrer"></p><p>以下通过一份 Helm 应用 Chart 包说明如何集中管理。</p><pre><code>.
├── Chart.yaml
├── charts
├── conf
│   ├── application-dev.properties
│   ├── application.properties
│   ├── consumer-app.properties
│   └── provider-app.yaml
├── templates
│   ├── consumer.yaml
│   ├── dc.yaml
│   └── provider.yaml
└── values.yaml
</code></pre><p>以上是一份 Chart 包目录结构，其中 conf 目录存放的是 Nacos 配置，文件名即 DataId，文件内容即对应的 Content。在 templates/dc.yaml 中，我们定义一份 ConfigMap 来组装这些配置。templates 目录中的 consumer.yaml 与 provider.yaml 分别是应用定义。</p><pre><code>apiVersion: v1
kind: ConfigMap
metadata:
  name: nacos-config
  namespace: {{ .Release.Namespace }}
data:
  {{- range $path, $_ := .Files.Glob "conf/**" }}
  {{ $path | base }}: |-
{{ $.Files.Get $path | indent 4}}
  {{- end }}
</code></pre><p><strong>使用上述方式定义好应用与配置后，可以借助 git 实现应用、配置的版本管理。当需要发布应用或配置时，修改对应文件后，执行 helm upgrade 命令即可。</strong></p><h4>面向 Nacos 运维偏好的用户</h4><p>Nacos 配置管理能力使得应用可以动态调整运行配置，但对于一些特殊的参数，如 JVM 参数、特殊环境变量、特殊目录文件等内容，Nacos 配置管理依然无法涵盖。在 Kubernetes 集群中，我们一般将环境变量或一些特殊文件配置写入 ConfigMap 中，通过 envFrom 能力将内容引用到环境变量中或者 volumeMount 挂载到文件系统中。这样的配置管理能力与 Nacos 配置管理能力是散开的，不利于统一管理。借助于 Nacos Controller，我们将这些配置上移到 Nacos 控制枱中，进行统一管理。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7f674fb17e9b9797cbd3b76836c621c638b.png" alt="" referrerpolicy="no-referrer"></p><p>以下是一份 Demo 应用，通过 Nacos 控制枱管理 JVM 启动参数：</p><pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: demo-app
  template:
    metadata:
      labels:
        app: demo-app
    spec:
      containers:
      - name: demo-app
        image: openjdk:8 #替换为你的应用镜像
        command: ["/bin/sh", "-c", "java -jar ${JVM_PARAMS} /app.jar"]
        env:
        - name: JVM_PARAMS # 从 ConfigMap 中载入 JVM 参数到环境变量中
          valueFrom:
            configMapKeyRef:
              name: nacos-config
              key: APP1_JVM_PARAMS

---
apiVersion: nacos.io/v1
kind: DynamicConfiguration
metadata:
    name: nacos-config
spec:
  dataIds:
  - APP1_JVM_PARAMS
  - APP2_JVM_PARAMS
  nacosServer:
    endpoint: &lt;your-nacos-server-endpoint&gt;
    namespace: &lt;your-nacos-namespace-id&gt;
    group: &lt;your-nacos-group&gt;
    authRef:
      apiVersion: v1
      kind: Secret
      name: nacos-auth
  strategy:
    syncPolicy: Always
    syncDirection: server2cluster
    syncDeletion: true
---
apiVersion: v1
kind: Secret
metadata:
    name: nacos-auth
data:
    ak: &lt;base64 ak&gt;
    sk: &lt;base64 sk&gt;
</code></pre><p>在 Nacos 控制枱中，修改 DataId：APP1_JVM_PARAMS 后，配置将自动同步到集群的 ConfigMap 中。只需重启相关应用，则对应的 JVM 参数将自动变化。<strong>成功实现将应用的所有配置集中管理在 Nacos 上。</strong></p><h2>Nacos 社区新晋&nbsp;Committer</h2><p>社区中新增了 2 位 Committer&nbsp;Karsonto <strong>[</strong><strong>2]</strong> 和&nbsp;Daydreamer-ia <strong>[</strong><strong>3]</strong> 。同时，Nacos 社区又迎来了一位来自开源之夏的 Committer 同学&nbsp;Daydreamer-ia&nbsp;。</p><p><img src="https://oscimg.oschina.net/oscnet/up-cff13fc011b530801a7a7de4e3fe2b1e895.png" alt="" referrerpolicy="no-referrer"></p><h2>展望</h2><h3>2.X 后续计划</h3><p>从 2021 年 3 月 2.0.0 正式版发布至今，2.X 版本已经走了接近 2 年时间，如今 2.3.0 版本发布，完成了大部分功能的插件化提炼，在之后的 2.3.X 版本中，会主要对当前版本的问题进行修复，并做出小范围的功能优化。同时对于 2.4.0 版本，会作为一个 Nacos3.0 的过度版本，对大量代码进行优化重构，在提升稳定性、健壮性的同时，提升易用性和可观测性，向 Nacos3.0 版本平稳过度。</p><h3>3.0 计划</h3><p>Nacos 社区同时也开启了关于&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU4NzU0MDIzOQ%3D%3D%26mid%3D2247511397%26idx%3D3%26sn%3D3ed3ef95e5ce1e396554ba4f370a0254%26scene%3D21%23wechat_redirect" target="_blank">Nacos3.0</a>&nbsp;的畅想和规划，Nacos 将会从统一控制面、支持国产化、存储计算分离等方向进一步演进 Nacos 的功能和架构，欢迎社区积极参与到新版本的建设中。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ae6e82384f221721d25cb6bc6624f7117ac.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-1fba0033910e46bee9c0a01b2d4172ae33e.png" alt="" referrerpolicy="no-referrer"></p><h2>About Nacos</h2><p>Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。Nacos 是构建以「服务」为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。</p><p>最后欢迎大家使用钉钉搜索群号加入 Nacos 社区群，钉钉群号：12810027056</p><p><strong>相关链接：</strong></p><p>[1]&nbsp;Nacos Controller</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnacos-group%2Fnacos-controller" target="_blank">https://github.com/nacos-group/nacos-controller</a></em></p><p>[2]&nbsp;Karsonto</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkarsonto" target="_blank">https://github.com/karsonto</a></em></p><p>[3]&nbsp;Daydreamer-ia</p><p><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FDaydreamer-ia" target="_blank">https://github.com/Daydreamer-ia</a></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 04:17:12 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/10918936</guid>
            <link>https://my.oschina.net/u/3874284/blog/10918936</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「回看 Milvus 的 2023」：AI 热潮中的非典型向量数据库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年是 AI 应用开发领域的一个重要转折点。</p><p>在这一年里，大语言模型（LLMs）因其卓越的自然语言处理能力而广受赞誉，极大地拓宽了机器学习应用的场景。开发者们逐渐意识到，有了 LLMs，他们可以设计出更智能、更容易互动的应用程序。与此同时，「向量数据库」已成为业界的热门话题，其作为大型模型长期记忆的角色得到了认可。像 RAG（检索增强生成）模型、智能代理和多模态检索等应用的兴起生动地展示了向量数据库在实现高效多模态数据检索、减少大型模型的幻觉以及补充领域知识方面的巨大潜力。</p><p>此外，2023 年大模型技术的发展也带来了另一个重要变化——嵌入提取能力的显著提升。根据 Huggingface 上的 MTEB 排行榜数据，像 UAE、VoyageAI、CohereV3 和 bge 这样的性能领先嵌入模型都在 2023 年发布。它们的迅速发展进一步增强了向量检索的有效性，为各种 AI 应用提供了更精确、更高效的数据处理能力。</p><p>当然，在这一年中，得益于应用场景的演变、资本投资和媒体炒作，向量数据库已成为一个广为人知的技术术语。数十家初创公司进入向量数据库领域，许多传统数据库开始将向量作为一个重要的数据类型对待。然而，随着知名度的提升，争议也随之而来，激起了关于专门向量数据库必要性的辩论。无论是关系数据库、NoSQL 还是搜索引擎，在许多情况下似乎都能替代向量数据库。</p><p>回顾完热闹的 2023 年，我们来谈谈 2024 年。在我看来，2024 年伊始是个审视向量数据库行业的好时机，包括在这一领域中独树一帜的 Milvus。</p><p>以下报告最初是为我们的 Milvus 社区内部反思而制作的，通过大模型重新整理，旨在提供对过去一年内向量数据库领域真正进步和趋势的清晰而详细的视角。这将帮助 AIGC 应用开发者在技术选择上做出更有教育意义和战略性的决策。</p><h2>01.数据不会说谎</h2><p>Milvus 是全球第一款向量数据库，首次开源是在 2019 年，以其高可靠性、可扩展性、搜索质量和性能而闻名。2023 年，我们见证了 AIGC 应用场景的演变所驱动一个向量数据库重要的转变，以下是一些最能代表 Milvus 在 2023 年进展的关键数据：</p><h3>0 - 滚动升级期间零停机时间</h3><p>对于许多向量数据库的新手来说，他们选型的关注点往往更多地在功能上而非运营维护。应用开发者通常对他们的向量数据库的稳定性的关注比对事务性数据库的需求要低得多，因为他们的应用程序通常处于非常早期阶段。然而，在 AIGC 应用领域，如果你想在生产环境中部署你的应用程序并实现最佳用户体验，稳定性和可维护性就变得不可或缺。意识到这一点，Milvus 从 2.2.3 版本开始引入了滚动升级，通过在多个版本中持续改进，逐渐变得更加稳定，并最终实现了零停机时间的滚动升级。</p><h3>3X - 生产环境中的性能提升</h3><p>向量检索的性能一直是向量数据库的关注焦点。Zilliz 发布了 VectorDB bench，以帮助测试不同场景下的向量检索性能。与过去的方法不同，VectorDB bench 现在专注于真实世界的数据，包括更接近实际嵌入模型的数据集（如最新的 OpenAI 嵌入和 Clip 数据集）、更广泛的测试场景（包括过滤、实时更新,删除）和更大的测试数据集（大多数当前的测试框架针对的是小而固定的数据点，如果某些 vectordb 在数据集上作弊可能会误导）。</p><p>目前，大多数向量检索供应商提供的解决方案都围绕开源 HNSW 算法的调整，这在各种生产部署中遇到显著的性能挑战，尤其是在涉及高过滤（超过 90%）和频繁删除的场景中。Milvus 在 2023 年不仅专注于最大化实验室性能，而且转向解决用户生产环境中的这些真实世界性能问题，在过滤、流式插入查询等实际生产场景实现了 3 倍以上的性能提升。</p><h3>5% - Beir 数据集上的召回率提升</h3><p>Dense Embedding 虽然有效，但在某些场景中依然存在局限性，如搜索特定名称、对象、某些缩写和短查询上下文。Sparse Embeding 在这些情况下可以与 Dense Embedding 互补，结合 ReRanking，在一些数据集上实现了 5% 的 NDCG<a href="https://my.oschina.net/u/3333828">@10</a> 提升。除了搜索质量之外，Milvus 还引入了一种基于图的 Sparse Embedding 检索解决方案，显著超过 WAND 等传统搜索方法。在 NeurIPS BigANN 竞赛中，Zilliz 员工王子豪提出的名为 Pyanns 的解决方案，并获得了全球第一的成绩，这个解决方案也是我们生产 Sparse Sembedding 方案的前身。随着稀疏嵌入提取模型和 Reranker 的不断发展，向量数据库中混合查询的重要性将越来越大。（事实上，尽管 Splade 目前是最佳的稀疏向量提取模型，效果大大超过了 BM25 的检索结果，根据我们的测试结果它可能不久后就不再是最佳的稀疏嵌入模型了。）</p><h3>10 倍 - 内存节省</h3><p>在 2023 年，检索增强生成（RAG）模型被广泛认为是向量数据库的最主要应用之一。我们发现，在文档被分割成块之后，一个含有 500 个 Token 的 Chunk（通常 1000 字节）会转换成一个 1536 维的 float32 向量（通常 3000 字节），这意味着向量数据的体积可能会超过原始文档的大小，给成本带来了重大挑战。</p><p>作为第一个支持基于磁盘索引的开源向量数据库，Milvus 通过磁盘混合存储实现了五倍的内存节省。2023 年末的 Milvus 新版本允许通过内存映射文件（MMap）将标量和向量数据/索引加载到磁盘，与传统的内存索引相比，这可以实现超过 10 倍的内存节省。特别值得注意的是，RAG 应用常展现出对冷热数据不同的使用模式，这使得 MMap 数据缓存能力对于 RAG 应用尤其有益。</p><h3>20 次 - 版本迭代</h3><p>2023 年对 Milvus 而言是一个转折性的年份。随着应用场景的显著演变，Milvus 的设计理念也相应地发生了改变。在 2.2.9 版本中引入的动态 Schema，标志着 Milvus 从优先追求绝对性能向更强调用户友好性的转变。我们在 2.3 版本中加入了诸如 Upsert、范围搜索以及余弦相似度等关键特性，均来自于用户的呼声。整个年度的 20 次版本更新不仅体现了超过 300 名社区开发者的心血，也足以证明了社区以用户为中心的开发模式所带来的积极成果。</p><h3>100 万 - 单个集群支持的租户数量</h3><p>在构建大模型应用时，多租户支持是关键特性，特别是在 RAG 和代理应用场景中，用户对数据隔离的要求越来越高。在面向消费者（ToC）的环境下，租户数量可能高达数百万，这使得物理数据隔离变得不实际（在关系数据库中创建数百万个表是不可行的）。为应对这一挑战，Milvus 引入了 PartitionKey 功能，使得基于 PartitionKey 的逻辑隔离和高效数据过滤成为可能。</p><p>在面向企业（ToB）的场景中，租户数量通常在数万级别，实施物理资源隔离策略更加可行和可控。因此，在 2.3.4 版本中，Milvus 对内存管理、协程处理和 CPU 优化进行了显著改进。这些改进使得在单个集群中创建数万个 Collection 变得可行，从而可以使用一个 Collection 一个租户的方式支持多租户。</p><h3>1000 万次 - Docker 镜像拉取</h3><p>在 2023 年的最后一天，Milvus 庆祝了一个引人注目的里程碑：达到 1000 万次 Docker 镜像下载。这一成就不仅凸显了全球开发者对 Milvus 的兴趣在与日俱增，也强调了 Milvus 在向量数据库领域中日益增长的重要性。作为世界上第一个云原生向量数据库，Milvus 一直与 Kubernetes 和容器生态系统紧密结合。那么未来呢？很多开发者都会好奇，向量数据库领域的下一个热点会是什么？可能是无服务器架构（Serverless）吗？这里先卖个关子。</p><h3>100 亿 - 单个 Collection 中的实体数量</h3><p>尽管在当前的 AI 热潮中，可扩展性可能不是最吸引眼球的部分，但它仍然对业务的成功至关重要。</p><p>以一个实例来说明，我们就曾用 Milvus 帮助一个大型模型供应商从一个庞大的 100 亿数据点集合中提取出深层价值。当然，并非所有用户的数据量都如此庞大，但 Milvus 以强大的可扩展性轻松适配不同数据体量的用户。</p><p>例如，在面对 1000 万个数据点时，Milvus 的处理速度堪称「如手指滑过丝绸般顺滑」，为相应用户业务的持续发展打下坚实的基础。在面对 1 亿个数据点时，Milvus 可能是唯一一个能够有序、灵活处理该规模的向量数据库。当数据点高达 10 亿时，用户往往面临成本与性能的双重挑战，Milvus 则可以通过多种优化方式帮助用户解决这一困境。最后，如果大家有谁正面临着处理 100 亿数据实体的挑战——请毫不犹豫地联系我们！我们可以共同探索如何支持和管理上述海量数据。</p><h2>02.向量数据库的新认知</h2><p>除了数字上的里程碑，2023 年业务模式的改变也带来了很多定性的认知。这些认知帮助我们深化了对向量这种数据类型的理解，也引导了我们思考向量数据库未来的发展方向。</p><h3>大模型应用仍处于初期阶段：避免重蹈智能手机时代「手电筒应用」的覆辙</h3><p>回顾移动互联网早期，许多开发者创建了如手电筒或天气预报等简单应用，这些应用最终被整合到智能手机操作系统中。如今，大多数 AI 原生应用，例如迅速在 GitHub 上获得 100,000 星的 AutoGPT，并未提供实际的业务价值，只是一些有价值的尝试。这意味着 AIGC 场景对大模型和向量数据库的应用都处于早期阶段，对今年的向量数据库使用场景可能只是 AI 原生转型的第一波浪潮，期待真正的杀手级应用出现。</p><h3>向量数据库持续分化</h3><p>就像数据库发展为 OLTP、OLAP 和 NoSQL 等不同类型一样，2023 年的向量数据库开始显示出多样化的趋势。超越传统的在线服务范围，离线分析领域变得更为重要，已经有专门的向量数据库系统面向数据准备和分析领域。GPTCache 是我们在 2023 年开源的项目，旨在利用向量检索 Cache 大模型输出，这也为向量数据库开拓了缓存这一全新的赛道。未来，我们满怀希望并期待来年见证向量数据库在更多样化的应用场景和设计。</p><h3>向量语意的复杂性日增</h3><p>ANN 并非向量数据库的唯一特性。许多人认为，支持最近邻搜索就足以称之为向量或 AI 原生数据库。然而，向量所需的操作比想象中更为复杂。除了标量过滤和混合查询外，为 AI 原生应用量身定制的数据库应支持更复杂的语义能力，如 NN 过滤、KNN 联接和集群查询。</p><p>对于 AI 原生应用而言，高弹性至关重要，但向量数据库可能成为瓶颈</p><p>像 ChatGPT 这样的 AI 应用，仅用两个月时间月活跃用户就超过 1 亿，其增长速度远超以往任何业务。一旦业务开始加速增长，从 100 万到 10 亿数据点的快速扩展至关重要。AI 应用开发者受益于大型模型提供商提供的按需付费服务模式，显著降低了运营成本。同样，以符合这一模式的方式存储向量数据对开发者有利，使他们能够更专注于核心业务逻辑。与大型模型和其他依赖项不同，向量数据库本质上维护状态，这在可扩展性和弹性方面带来了更大的挑战。因此，在选择向量数据库时，弹性和可扩展性必须被视为关键因素。</p><h3>将机器学习应用于向量数据库可以带来惊人的高回报</h3><p>2023 年，我们大力投资 AI4DB，并取得了显著的回报。与传统数据库相比，向量数据库的固有不精确性使其更易于使用机器学习算法进行优化。我们引入了两个关键能力：基于机器学习的自动参数调整索引 AutoIndex、基于数据聚类的数据分区策略，这两者都显著提高了 Milvus 企业版在云上的搜索性能。</p><h3>开源与闭源</h3><p>在大型语言模型（LLM）领域，OpenAI 和 Claude 的闭源模型目前领先，而开源社区在没有相当的计算资源和数据的情况下依然在苦苦挣扎。对于向量数据库，我坚信开源最终将成为用户的首选。开源意味着更丰富的应用场景、更快的迭代和更强大的生态系统。更重要的是，数据库是复杂的系统，不能像大型模型那样不透明，用户必须充分理解数据库本身才能找到最合理的使用的方式，开源的透明度对于用户来讲不仅意味着自由更意味着可控。</p><h3>新的开始</h3><p>2023 年在大模型的变革中迅速流逝，而向量数据库的故事似乎才刚刚开始。对于被认为是非典型向量数据库的 Milvus 而言，我们的旅程并不是迷失在人工智能生成内容（AIGC）的热潮中。</p><p>相反，我们专注于精心打造我们的产品，识别并培育最适合我们的应用场景，并致力于服务我们理想的用户群体。我们希望对开源的承诺能够弥合我们与用户之间的距离，让他们即使在世界的任意一个角度都能感知到我们善意和工匠精神。</p><p>2023 年也见证了大量人工智能初创企业的成立和首轮融资。看到这些开发者的创新令人激动，这让我想起了我最初为何投身于向量数据库这一赛道。2024 年将是所有这些创新应用开始真正获得关注的一年，不仅吸引融资，还会吸引真正的付费客户。这将为这些开发者带来一系列全新的要求，因为构建一个几乎不间断、完全可扩展的解决方案至关重要……新的一年，我们顶峰相见！</p><p>本文作者系 Zilliz 合伙人、研发 VP 栾小凡</p><p>「你眼中的 Zilliz·2023」调研已开启！欢迎各位在 Zilliz 微信后台私信我们，谈谈「过去一年你对 Zilliz 印象最深刻的一件事情是什么？」范围不限于 Zilliz 的单个产品，也可以谈谈对 Zilliz 的商业动态、线下活动、内容平台的文章等印象，字数不限，入选用户将收获神秘礼物盲盒，欢迎来私～</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 03:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10920789</guid>
            <link>https://my.oschina.net/u/4209276/blog/10920789</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[网易云音乐第三方开源 API 因侵权被要求删除]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>NeteaseCloudMusicApi 是 Node.js 编写的非官方网易云音乐 API，可用于获取网易云音乐平台的歌曲信息。该项目完全开源，在 GitHub 上的 star 数超过 3 万。</p><p>根据公开的信息，NeteaseCloudMusicApi 主要是整理了网易云音乐公开的网页接口，在此基础上进行聚合后以便其他项目进行调用。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-5f0e449d6b5d2d7cbab05d8f27824a30533.png" referrerpolicy="no-referrer"></p></blockquote><p>近日，NeteaseCloudMusicApi 的开源仓库清空了所有代码，以及 commit 记录等信息，并在 README 写道：「<u><em>保护版权,此仓库不再维护</em></u>」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a5fab4ac6b5a85c43ff9e4d4b90647baf96.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.landiannews.com%2Farchives%2F101953.html" target="_blank">据称</a>原因是网易云音乐发送法律通知给 NeteaseCloudMusicApi 开发者，声明该项目侵犯网易公司的相关版权，要求开发者立即下线该项目中<strong>盗链网易云音乐的方法及内容</strong>。</p><blockquote><p>网易云音乐由杭州网易云音乐有限公司独立开发运营，网易云音乐作为国内知名的在线音乐平台，致力于为用户提供优质的音乐内容服务，我司以高额的成本采购了海量音乐作品的内容，在未我司合法授权的任何第三方均没有权利播放由我司享有版权的音乐作品，我司有权以自己的名义或授权第三方进行维权。</p><p>我司收到用户的举报，您开发的 NeteaseCloudMusicApi 或存在涉嫌通过非法破解网易云音乐内容接口的方式获取网易云音乐享有版权的歌曲内容。</p><p>贵司未经我司授权，通过技术手段破解绕开限制直接提供网易云音乐享有版权的音乐作品内容，该行为不仅侵犯了我司享有的音乐作品版权，亦非法攫取了网易云音乐的用户流量构成不正当竞争，损害了我司作为权利人的合法权益。</p><p>同时贵方通过非法技术手段破解网站获取大量歌曲内容的行为，涉嫌构成侵犯著作权罪，破坏 / 非法入侵计算机信息系统罪及 / 或提供破坏 / 非法入侵计算机信息系统工具罪。</p><p>针对上述侵权行为，根据中华人民共和国《著作权法》、《刑法》等相关法律法规规定，我司现郑重致函：</p><p>1、立即，下线 NeteaseCloudMusicApi 上盗链网易云音乐的方法及内容；</p><p>2、在未获得我方授权的前提下，停止一切侵犯我司合法权益的行为。</p><p>请贵方充分认识到该行为的违法性和严重性，按照本函要求立即处理侵权行为，并将处理结果及时告知我方。若贵方怠于履行该项义务，为维护自身合法权益，我司将采取包括诉讼、投诉、举报等在内的一切必要的法律措施确保合法权利得到有效保护。</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 03:21:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276411</guid>
            <link>https://www.oschina.net/news/276411</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[惊讶！史上最年轻的 Apache Committer 诞生！！！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-b74c559a04078fb6182d6af9815c351d338.png" referrerpolicy="no-referrer"></p><p>在 Apache StreamPark 被数以千计的星星和诸多荣誉的眷顾下，用户越来越多，遍布各个行业。这一切的背后都是因为有一帮热爱开源，愿意投身开源项目建设的贡献者。这其中有一批 「00 后」 的新星正悄然在社区崭露头角，他们正用自己的实际行动书写着自己的开源故事。Apache StreamPark 社区近日迎来了两位 「00」 后 Committer，下面让我们一睹两位 Committer 的风采。</p><span id="OSC_h1_1"></span><h1><strong>新晋 Committer&nbsp;之张超篇</strong></h1><hr><p><img height="648" src="https://oscimg.oschina.net/oscnet/up-63b75bc7d4a38c12ff48b29d44c7cf3bbe6.png" width="1216" referrerpolicy="no-referrer"></p><p><br><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">很开心能够被提名为 Apache StreamPark 的 Committer！非常感谢支持社区的每一位小伙伴！也感谢参与项目时社区的各位技术大拿们给予的指导和帮助！</span></p><p><iframe frameborder="no" height="400px" scrolling="no" src="https://player.bilibili.com/player.html?aid=666424225&amp;bvid=BV1Ra4y1C7EE&amp;cid=1411725695&amp;p=1" width="720px" referrerpolicy="no-referrer"></iframe></p><span id="OSC_h4_2"></span><h4>&nbsp;</h4><span id="OSC_h4_3"></span><h4><strong><strong><strong><strong><strong>主要贡献</strong></strong></strong></strong></strong></h4><ol><li><p>Apache StreamPark 进入 Apache 孵化器期间参与从 MySQL 到 H2 数据库的适配</p></li><li><p>变更 Mybatis-Plus 配置方式，简化配置文件配置项</p></li><li><p>完善用户模块删除功能，部分前后端功能开发与适配，并追踪后续讨论、改进</p></li><li><p>参与整理、完成代码风格和质量指南文档，并参与相关代码规范的推进工作</p></li><li><p>参与官网文档的改进，完成中英文文档编写各 2 篇、翻译 15&nbsp;篇以及其他文档完善</p></li></ol><span id="OSC_h4_4"></span><h4><strong><strong><strong><strong><strong>结缘社区</strong></strong></strong></strong></strong></h4><p>对我来说，Apache 不仅仅是一个技术社区，它更像是一种信仰。在我还是个初学者的时候，提起 Apache Tomcat、Apache Maven 这样的顶级项目，它们在我的心中就好像是编程世界的神话传说。对于热爱编程的我而言，Apache 代表着技术的极致、创新的精神，激励着我不断前行。想到有一天可能成为这个信仰的一份子，和全球的技术大牛们肩并肩，这种感觉，就像是梦想变成现实。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7e1ecdc00c6b91bb4bab730f471cf204ac8.png" referrerpolicy="no-referrer"></p><p>我参与 Apache StreamPark 提交的第一个 PR 是处理客户端发起 GET 请求时携带了 「    」问题，是在 2022 年 8 月 28 日提交的，只用了一行箭头函数的代码就解决！持续贡献到现在也已经一年多了。</p><p>在我印象中，那时 Apache&nbsp;StreamPark 还叫 StreamX，整个团队都在为加入 Apache 孵化器做准备，这时项目急需对 H2 数据库进行适配，而我正好是 Mybatis-Plus 的开发者。PMC 成员华杰哥[1]邀请我一同参与，我立马答应了下来，然后开始从零了解 Apache StreamPark。即刻怀揣着兴奋的心情，连夜肝代码。第一个挑战是 Windows 下的开发环境配置，消耗九牛二虎之力，总算终于跑通了代码！等我抬头一看发现天都亮了——时间真会玩，就这么偷偷溜走了: )。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-270fbabed9d20e29eabf0f3261a698241f2.jpg" referrerpolicy="no-referrer"></p><p>后面我在陆陆续续参与开发中也遇到很多问题，记得印象很深的一次是有一天晚上在进行 Apache StreamPark 前端开发时，遇到一个前端组件的 BUG，处理了半天无果，最后求助社区的 PPMC 成员思柱哥[2]。思柱哥不仅帮我解决了问题，还手把手教我原理，真的很感谢思柱哥！这也是我切身感受到参与开源的乐趣之一，有很多技术大拿愿意带着你成长。</p><p>今年八月，我有幸去北京参加了 Apache Community Over Code 2023[3]。跟 Apache 社区的大佬们近距离接触，真是开眼界了。Apache Way 最让我印象深刻的就是 「社区大于代码」 这个理念。特别是听了 Apache Pulsar PMC 成员小狐狸小姐姐的演讲后，我就豁然开朗：开源项目不仅仅是代码，也需要一个文档来告诉你它怎么运作。因此我主动请缨参与文档的完善工作，帮助社区文档更友好！</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-02f03dc61579e20ce426bef16ae9accec92.png" referrerpolicy="no-referrer"></p><p>我每天都会坚持写一篇博客，哪怕没什么可写的技术题材，我也会坚持随便积累一点。顺带一提我在任何地方都可以打开电脑写代码，譬如咖啡厅、飞机上、地铁上等，甚至我去韩国旅游时也在随便找的一家咖啡厅处理 issue。</p><span id="OSC_h4_5"></span><h4><strong>社区印象</strong></h4><p>社区的大佬们真的各显神通，在 Apache&nbsp;StreamPark 社区里经常有热心技术大拿愿意提供帮助。并且也进一步地学习到不少开发规范和实用技巧，就比如让代码 「一尘不染」 的工具 Spotless、以及 Vue3 的知识点掌握等！在 Apache&nbsp;StreamPark 有一个使用登记收集的 Issue，其中有一条特别引起了我的注意：来自 「袁隆平农业高科技股份有限公司」 的使用登记。这家公司的名字源于杂交水稻之父袁隆平老先生，我为身处的社区能服务于这样一家公司感到超级自豪。参与开源真的是一件很酷的事情！</p><span id="OSC_h4_6"></span><h4><strong>寄，语</strong></h4><p>从 Apache&nbsp;StreamPark 进入 Apache 孵化器，到现在一周年已经过去啦，期间让人感动的瞬间数不胜数！期待更多小伙伴的加入和陪伴，咱们一同见证其从孵化器毕业，进一步为实时领域发展作出贡献！</p><span id="OSC_h1_7"></span><h1><strong>新晋 Committer&nbsp;之蔡灿材篇</strong></h1><hr><p><img height="648" src="https://oscimg.oschina.net/oscnet/up-8120852d62a802a07553d710655b8046808.png" width="1216" referrerpolicy="no-referrer"></p><p>非常荣幸被提名为 Apache&nbsp;StreamPark 的 Committer！感谢社区的信任和肯定！感谢历次讨论、设计、协作和 review 过程中社区开发者给予的指导和帮助！</p><span id="OSC_h4_8"></span><h4><strong><strong><strong><strong><strong>主要贡献</strong></strong></strong></strong></strong></h4><ol><li><p>参与 Kubernetes V2 Operator 重构 streampark-flink-kubernetes 模块</p></li><li><p>测试、修复 streamp-flink-kubernetes 模块并补充单元测试</p></li><li><p>积极参与方案讨论、规范制定和代码 Review</p></li><li><p>修复并完善官网文档</p></li></ol><span id="OSC_h4_9"></span><h4><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>结缘社区</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></h4><p>Apache&nbsp;StreamPark 算是我第一个正式参与的开源项目,与社区结缘主要是因为 StremaPark PPMC 成员余林颖哥[4](Al-assad)。那时候我想加入开源社区，但又觉得自己实力太菜，所以一直没付诸行动。后面 Al-assad 就问我要不要参与 Apache&nbsp;StreamPark 社区，说有很多工作可以做，那时候我还有点怕自己会拖后腿，但大佬说有他兜底。我也就抱着试一试态度去参加了。</p><p>刚进社区，我就接下了三个 feature（真是初生牛犊不怕虎)，真实情况是因为那三个 feature 是很类似的需求，我就想一个是做，两个也是做，那就一起接过来算了。一开始环境搭建在社区的各位大佬的帮助下，也是花了一星期时间成功搭建好了，后面就开始漫长的 debug 之旅。</p><p>在 debug 过程中，我也发现 Apache&nbsp;StreamPark 的一些问题，提了一些 PR 进行修复。令我比较惊讶的是，我的每个 PR 社区都回复的很快，并提了很多改进的意见、让我学到了很多，也让我更有动力。印象比较深的是：在完成第一个 feature 时，我写的代码其实很丑陋，几个 PMC 成员们非凡不嫌弃还提了很多修改意见、鼓励我慢慢改进，最后还是林颖哥出手才让我第一个 feature 成功完成，那时候感觉自己帮了倒忙，感觉很不好意思。但 Al-assad 鼓励我说是新人是这样的啦，多进行尝试就好了。在对第一个 feature 进行认真 review 代码后，我后面两个 feature 也顺利完成了（虽然也是磕磕绊绊）。还记得最后一个 feature 合并的时候，我的心情都激动得快哭了，原来我也能做到自己曾经大学可望而可不及的事情（开源之夏）。记得之前有人看某个开源项目的时候，跟我说，你看这个人和你和你差不多大已经完成了三个 feature 了，我那时候在想什么时候我也能这么牛叉就好了，没想到过了没多久我也成为了 「这样的人」，哈哈。</p><p>一开始，我打算搞完这三个 feature 就不参与社区了，后面认识了社区很多优秀的开发者让我改变了这个想法，Apache&nbsp;StreamPark 社区开发者们非常的团结友善，核心贡献者们更是牺牲休息时间投入到项目中，知道这一点的时候我十分吃惊。所以在这里你能认识一群真正热爱代码的人，我十分感谢在 Apache&nbsp;StreamPark 社区遇到每一位开发者，他们教会了我很多。在这个社区，我仿佛意识到开源精神的某种含义。</p><span id="OSC_h4_10"></span><h4><strong>寄，语</strong></h4><p>当然是希望 Apache&nbsp;StreamPark 社区越来越好啦，毕竟是我参加开源以来第一个加入的社区，期待新的小伙伴能加入进来，一起建设社区。如果是新手也不用害怕，我也是新手不也成功加入进来了吗。祝 Apache StreamPark 能够早日孵化成功, 祝各位 Apache&nbsp;StreamPark 社区的小伙伴都玩得开心，have fun！</p><span id="OSC_h1_11"></span><h1>**&nbsp;加，入 我，们&nbsp;**</h1><p>Apache&nbsp;StreamPark 是一个流处理应用程序开发管理框架。初衷是让流处理更简单，旨在轻松构建和管理流处理应用程序，提供使用 Apache Flink 和 Apache Spark 编写流处理应用程序的开发框架，未来将支持更多其他引擎。同时，Apache&nbsp;StreamPark 提供了一个流处理应用管理平台，核心能力包括但不限于应用开发、调试、交互查询、部署、运维、实时数仓等，于 2022 年 9 月通过投票正式成为 Apache 开源软件基金会的孵化项目。</p><p>Apache&nbsp;StreamPark 社区一直以来都以用心做好一个项目为原则，高度关注项目质量，努力建设发展社区。我们时刻保持开发者谦逊朴素的本质，认真学习和遵循「The Apache Way」，秉承更加兼容幷包的心态，迎接更多的机遇与挑战。诚挚欢迎更多的贡献者参与到社区建设中来，和我们一道携手共建。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb1f818f6981c4a0f1366a2ec6f60a7252e.png" referrerpolicy="no-referrer"></p><p>💻 项目地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark" target="_blank">https://github.com/apache/streampark</a><br> 🧐 提交问题和建议：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fissues" target="_blank">https://github.com/apache/streampark/issues</a><br> 🥁 贡献代码：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fstreampark%2Fpulls" target="_blank">https://github.com/apache/streampark/pulls</a><br> 📮 Proposal：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FINCUBATOR%2FStreamPark%2BProposal" target="_blank">https://cwiki.apache.org/confluence/display/INCUBATOR/StreamPark+Proposal</a><br> 📧 订阅社区开发邮件列表：**dev@streampark.apache.org&nbsp;<br> 💁‍♀️&nbsp;<strong>社区沟通：</strong><br><img alt="" src="https://oscimg.oschina.net/oscnet/up-d2fb1e3ea10be8a185704b27e79d83d2ad4.png" referrerpolicy="no-referrer"></p><p><strong>参考资料</strong><br> [1]&nbsp;<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwolfboys" target="_blank">https://github.com/wolfboys</a></em><br> [2]&nbsp;<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwangsizhu0504" target="_blank">https://github.com/wangsizhu0504</a></em><br> [3]&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunityovercode.org" target="_blank">https://communityovercode.org</a><br> [4]&nbsp;<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAl-assad" target="_blank">https://github.com/Al-assad</a></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 02:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/streampark/blog/10890500</guid>
            <link>https://my.oschina.net/streampark/blog/10890500</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[《互联网法律白皮书（2023 年）》发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年 1 月 19 日，中国信息通信研究院（简称「中国信通院」）互联网法律研究中心举办第七届互联网法律研讨会，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSfy0OltG0u4n1YKNDSXmqg" target="_blank">发布</a>《互联网法律白皮书（2023 年）》。系统梳理过去一年国内外重要互联网立法活动，深入分析我国互联网立法的最新成果和国际互联网立法进展，对未来互联网立法工作进行了展望，希望能为社会各界了解互联网领域立法情况提供有价值的参考。</p><p><strong>白皮书核心观点</strong></p><ol><li><p>我国网络空间法治化迈向新阶段。我国加快推进互联网立法进程，在网络安全、数据安全、个人信息保护、互联网平台等方面明确管理要求，为构建网络综合治理体系提供了法治保障。2023 年，我国互联网法治建设继续顺应全球信息化发展大势，立足我国互联网发展实践，不断深化对依法治网的规律性认识，在保安全的基础上向促发展迈进，查漏补缺、完善制度、细化规则。</p></li><li><p>我国互联网法律体系日趋健全完善。我国深入贯彻落实党中央关于网络强国、数字中国的决策部署，积极推进互联网立法工作，不断完善相关法律制度规范，基本形成了具有中国特色的互联网法律体系。网络设施安全防护进一步加强，保障数据安全和促进数据价值释放法律制度同步推进，互联网平台发展的法治环境日益优化，新技术新模式发展逐步规范。</p></li><li><p>全球互联网立法展现新趋势新动向。2023 年，全球网络安全立法持续推进，数据跨境流动和数据共享流通成为新的立法关注点，互联网平台对网络信息内容的管理义务进一步强化，全球加快对人工智能等新技术新应用的立法应对，各国加快推进互联网立法进程为保障其国内发展、强化国际竞争提供制度保障。</p></li><li><p>构建适应数字经济和实体经济融合发展的互联网法律体系。在习近平新时代中国特色社会主义思想指引下，我国需适应数字经济发展要求，构建完善互联网法律体系，补齐法制短板，通过分类分级制度实现精准施策。应对人工智能等新技术发展趋势，为新技术的规范发展提供法治支撑。深入布局研究互联网立法前沿问题，探索构建数据基础法律制度。进一步健全互联网法律法规，提高我国数字经济治理体系和治理能力现代化水平，以法治护航数字经济行稳致远。</p></li></ol><p><img height="280" src="https://oscimg.oschina.net/oscnet/up-2e6e5be1f936754aa5edce38c01aada886b.png" width="500" referrerpolicy="no-referrer"></p><p><img height="275" src="https://oscimg.oschina.net/oscnet/up-559d5e7fe744cce93a4ae209e492aee5880.png" width="500" referrerpolicy="no-referrer"></p><p><img height="272" src="https://oscimg.oschina.net/oscnet/up-7ae8f0a460439255c90efe36af5171f1195.png" width="500" referrerpolicy="no-referrer"></p><p><img height="271" src="https://oscimg.oschina.net/oscnet/up-ab6fa6ae131b9d94129e631761e1ee414c9.png" width="500" referrerpolicy="no-referrer"></p><p><img height="278" src="https://oscimg.oschina.net/oscnet/up-9998e54e517d56fe321f2268e243548c9f8.png" width="500" referrerpolicy="no-referrer"></p><p><img height="279" src="https://oscimg.oschina.net/oscnet/up-60418af84fcfa23ba48a3f631cff64713c5.png" width="500" referrerpolicy="no-referrer"></p><p><img height="277" src="https://oscimg.oschina.net/oscnet/up-6f1f74832bb661a34b0429d057d5aca4d93.png" width="500" referrerpolicy="no-referrer"></p><p><img height="275" src="https://oscimg.oschina.net/oscnet/up-e099e03ebfcf5a5101d332999447594f51a.png" width="500" referrerpolicy="no-referrer"></p><p><img height="285" src="https://oscimg.oschina.net/oscnet/up-ef189c3cccb8a9ec7d7e5540ddac9d9026d.png" width="500" referrerpolicy="no-referrer"></p><p><img height="284" src="https://oscimg.oschina.net/oscnet/up-9a859a2d1c378f75b300162a287fa4ffd38.png" width="500" referrerpolicy="no-referrer"></p><p><img height="284" src="https://oscimg.oschina.net/oscnet/up-39b8a71bbc15699a837a443f84672b1781c.png" width="500" referrerpolicy="no-referrer">&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 02:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276402</guid>
            <link>https://www.oschina.net/news/276402</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024-1 月 | WHLUG（武汉 Linux 用户组）活动回顾，这是没有过的全新版本]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><div><p style="margin-left:0; margin-right:0">内容来源：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Findex%2Fzh" target="_blank">deepin 社区</a></p><hr><p style="margin-left:0; margin-right:0">2024 年 1 月 20 日下午，由 deepin（深度）社区联合 Linux 中国、龙蜥社区（OpenAnolis）、华中科技大学网络空间安全学院开源俱乐部一起举办的 Linux 爱好者线下沙龙活动（WHLUG）在武汉未来科技城成功举办。</p></div></div><p style="margin-left:0; margin-right:0">本次活动聚集了近 40 名来自武汉地区的 Linux 爱好者线下参与，大家共同探讨技术话题，分享技术经验和见解，现场气氛热烈。现在就让我们一起来回顾本次活动的精彩瞬间吧！</p></div><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" height="611" src="https://storage.deepin.org/thread/202401220819117663_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059112961557.png" width="825" referrerpolicy="no-referrer"></p><div><div>
  来自 deepin 团队的研发工程师 Black desk 在会议上与参会者分享了一些 Linux 内核提供的容器相关特性的用户态接口使用方法、非 root 用户使用 Linux 容器的限制，和其他有趣的 Linux 容器技术细节，同时也深入介绍了玲珑方案产生的背景、希望去解决的问题，以及玲珑的优势和目前存在的问题。
 </div></div><div>
 &nbsp;
</div><div><img alt="" height="603" src="https://storage.deepin.org/thread/202401220820237378_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059113054411.png" width="827" referrerpolicy="no-referrer"></div><div>
 &nbsp;
</div><div><div><div>
   开源已经迈入了「新生代」，我们需要资深的开发者，也需要更张扬的年轻人。在本次分享中，来自华中科技大学开放原子开源俱乐部的慕冬亮老师，便从「领路人」的视角，为大家分享了他是如何带领学生走进 Linux 内核的世界，一同挖掘、修复 Linux 内核漏洞，并通过内部审核机制保障内核补丁正确性的故事。
  </div></div></div><div>
 &nbsp;
</div><div>
 &nbsp;
</div><div><img alt="" height="617" src="https://storage.deepin.org/thread/202401220820504191_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059113182099.png" width="825" referrerpolicy="no-referrer"></div><div>
 &nbsp;
</div><div><div><div>
   那从学生的视角来看，开源参与又会有哪些不一样呢？来自华中科技大学的朱俊星同学结合自身从 0-1 参与开源的经历，为大家介绍了他是如何从「发布项目无人问津、参与项目无从下手」的小白，逐步深入探索、找到组织，并进阶成为开源项目的核心贡献者的。他强调，「开源不仅仅是开放源代码，更是一种分享合作、共同进步的精神」，希望大家能够抛开顾虑，勇敢尝试。
  </div></div></div><div>
 &nbsp;
</div><div><img alt="" height="461" src="https://storage.deepin.org/thread/202401220821331561_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059113277879.png" width="826" referrerpolicy="no-referrer"></div><div>
 &nbsp;
</div><div><div><div>
   虚拟网卡是云计算重要组成部分，目前正面临着性能和功能的双重挑战。在本次活动中，来自龙蜥社区高性能网络 SIG 的成员衡琪，向大家分享了 Anolis OS 是如何通过优化 Virtio 协议来增强网络性能，从而解决这一挑战。衡琪在分享中提到了一些具体的优化措施，如制定新的 Virtio 标准，包括 Inner Hash、Virtio Checksum 修复、NetDIM、Device Stats 等技术。
  </div></div><div>
  &nbsp;
 </div></div><div><img alt="" height="615" src="https://storage.deepin.org/thread/202401220822105140_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059113375653.png" width="827" referrerpolicy="no-referrer"></div><div>
 &nbsp;
</div><div><div><div><p style="margin-left:0; margin-right:0">除了主题演讲之外，来自现场爱好者的闪电演讲的分享，也赢得了满堂喝彩。</p><p style="margin-left:0; margin-right:0">钟同学为大家分享了自己在 Treeland 及窗管调优方面的经验与探索，向大家展示了他是如何基于 Treeland 进行窗管深度客制化，以及在三个月内打造的台前调度。这个分享引发了现场观众的兴趣和探讨，大家对于钟同学的经验和成果表示赞赏，并积极参与了与之相关的交流和讨论。</p></div></div></div><div><img alt="" height="463" src="https://storage.deepin.org/thread/202401220822396312_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059113493557.png" width="828" referrerpolicy="no-referrer"></div><div>
 &nbsp;
</div><div>
 &nbsp;
</div><div><div><div><p style="margin-left:0; margin-right:0">桑同学结合自己的工作和大家分享了有关路由器和无线网卡的相关知识，并讲述了在工作中遇到的一些有趣的事情。其中，当提到客户经常将需求误认为 BUG 并直接反馈给技术同学时，更是引发了现场从事 B 端业务的研发同学们的共鸣，并引发了一系列讨论和交流。</p><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" height="608" src="https://storage.deepin.org/thread/202401220823104278_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059113564231.png" width="822" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p></div></div></div><div><div><div><h1><strong>网上相会，何如线下相见</strong></h1><p style="margin-left:0; margin-right:0">WHLUG 的创办希望帮助大家在武汉遇到同为 Linux 爱好者的小伙伴，一起在某个周末，交流技术，学习技术。基本的形式如下：</p></div></div></div><div><img alt="" height="217" src="https://storage.deepin.org/thread/202401220823526444_%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17059114451088.png" width="807" referrerpolicy="no-referrer"></div><div><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">我们热切的希望能够有更多武汉当地的学校、企业、开源爱好者加入我们，共同参与到 WHLUG 活动的策划和组织中。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>所以，我们会面向核心成员招募组织人，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwj.qq.com%2Fs2%2F13816139%2F8b53%2F" target="_blank">如果您感兴趣，请报名。</a>期待与您一起共建！</strong></p><p style="text-align:center"><img height="271" src="https://oscimg.oschina.net/oscnet/up-07d49751e8486d624c7c08f7166f237fa1c.png" width="276" referrerpolicy="no-referrer"></p><hr><p><strong>内容来源：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2F2024-01-whlug%2F" target="_blank">deepin 社区</a></strong></p><p><strong>了解 WHLUG（武汉 Linux 用户组）：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fwelcome-to-whlug%2F" target="_blank">https://www.deepin.org/zh/welcome-to-whlug/</a></strong></p><p><strong>往期 WHLUG 活动回顾：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fcategory%2Fwhlug-news%2F" target="_blank">https://www.deepin.org/zh/category/whlug-news/</a></strong></p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 02:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276400</guid>
            <link>https://www.oschina.net/news/276400</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Agents-Flex —— 大语言模型应用开发框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:left">Agents-Flex 是一个优雅的 LLM（大语言模型） 应用开发框架。其使用 Java 开发，对标 LangChain。</p><h2 style="margin-left:0; margin-right:0; text-align:left">基础能力</h2><ul><li>LLM 的访问能力</li><li>Prompt、Prompt Template 定义加载的能力</li><li>Function Calling 定义、调用和执行等能力</li><li>Embedding</li><li>Vector Storage</li><li>丰富的内容加载器</li><li>丰富的文本分割器</li><li>LLM Chain</li><li>Agents Chain</li></ul><h2 style="margin-left:0; margin-right:0; text-align:left">简单对话</h2><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">使用 OpenAi 大语言模型:</p><div style="text-align:left"><div><pre><span><strong>public</strong><strong>static</strong><strong style="color:#445588">void</strong><strong style="color:#990000">main</strong><span>(</span><strong style="color:#445588">String</strong><span>[]</span><span>args</span><span>)</span><strong>throws</strong><strong style="color:#445588">InterruptedException</strong><span>{</span></span><span><strong style="color:#445588">OpenAiConfig</strong><span>config</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">OpenAiConfig</strong><span>();</span></span><span><span>config</span><span>.</span><span style="color:#008080">setApiKey</span><span>(</span><span style="color:#dd2200">"sk-rts5NF6n*******"</span><span>);</span></span><span><strong style="color:#445588">Llm</strong><span>llm</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">OpenAiLlm</strong><span>(</span><span>config</span><span>);</span></span><span><strong style="color:#445588">Prompt</strong><span>prompt</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">SimplePrompt</strong><span>(</span><span style="color:#dd2200">"请写一个关于小兔子战胜大灰狼的故事。"</span><span>);</span></span><span><span>llm</span><span>.</span><span style="color:#008080">chat</span><span>(</span><span>prompt</span><span>,</span><span>(</span><span>llmInstance</span><span>,</span><span>message</span><span>)</span><span>-&gt;</span><span>{</span></span><span><strong style="color:#445588">System</strong><span>.</span><span style="color:#008080">out</span><span>.</span><span style="color:#008080">println</span><span>(</span><span style="color:#dd2200">"---&gt;"</span><span>+</span><span>message</span><span>.</span><span style="color:#008080">getContent</span><span>());</span></span><span><span>});</span></span><span><strong style="color:#445588">Thread</strong><span>.</span><span style="color:#008080">sleep</span><span>(</span><span style="color:#009999">10000</span><span>);</span></span><span><span>}</span></span></pre><div style="text-align:center">&nbsp;</div></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">使用 「通义千问」 大语言模型:</p><div style="text-align:left"><div><pre><span><strong>public</strong><strong>static</strong><strong style="color:#445588">void</strong><strong style="color:#990000">main</strong><span>(</span><strong style="color:#445588">String</strong><span>[]</span><span>args</span><span>)</span><strong>throws</strong><strong style="color:#445588">InterruptedException</strong><span>{</span></span><span><strong style="color:#445588">QwenLlmConfig</strong><span>config</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">QwenLlmConfig</strong><span>();</span></span><span><span>config</span><span>.</span><span style="color:#008080">setApiKey</span><span>(</span><span style="color:#dd2200">"sk-28a6be3236****"</span><span>);</span></span><span><span>config</span><span>.</span><span style="color:#008080">setModel</span><span>(</span><span style="color:#dd2200">"qwen-turbo"</span><span>);</span></span><span><strong style="color:#445588">Llm</strong><span>llm</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">QwenLlm</strong><span>(</span><span>config</span><span>);</span></span><span><strong style="color:#445588">Prompt</strong><span>prompt</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">SimplePrompt</strong><span>(</span><span style="color:#dd2200">"请写一个关于小兔子战胜大灰狼的故事。"</span><span>);</span></span><span><span>llm</span><span>.</span><span style="color:#008080">chat</span><span>(</span><span>prompt</span><span>,</span><span>(</span><span>llmInstance</span><span>,</span><span>message</span><span>)</span><span>-&gt;</span><span>{</span></span><span><strong style="color:#445588">System</strong><span>.</span><span style="color:#008080">out</span><span>.</span><span style="color:#008080">println</span><span>(</span><span style="color:#dd2200">"---&gt;"</span><span>+</span><span>message</span><span>.</span><span style="color:#008080">getContent</span><span>());</span></span><span><span>});</span></span><span><strong style="color:#445588">Thread</strong><span>.</span><span style="color:#008080">sleep</span><span>(</span><span style="color:#009999">10000</span><span>);</span></span><span><span>}</span></span></pre><div style="text-align:center">&nbsp;</div></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">使用 「讯飞星火」 大语言模型:</p><div style="text-align:left"><div><pre><span><strong>public</strong><strong>static</strong><strong style="color:#445588">void</strong><strong style="color:#990000">main</strong><span>(</span><strong style="color:#445588">String</strong><span>[]</span><span>args</span><span>)</span><strong>throws</strong><strong style="color:#445588">InterruptedException</strong><span>{</span></span><span><strong style="color:#445588">SparkLlmConfig</strong><span>config</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">SparkLlmConfig</strong><span>();</span></span><span><span>config</span><span>.</span><span style="color:#008080">setAppId</span><span>(</span><span style="color:#dd2200">"****"</span><span>);</span></span><span><span>config</span><span>.</span><span style="color:#008080">setApiKey</span><span>(</span><span style="color:#dd2200">"****"</span><span>);</span></span><span><span>config</span><span>.</span><span style="color:#008080">setApiSecret</span><span>(</span><span style="color:#dd2200">"****"</span><span>);</span></span><span><strong style="color:#445588">Llm</strong><span>llm</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">SparkLlm</strong><span>(</span><span>config</span><span>);</span></span><span><strong style="color:#445588">Prompt</strong><span>prompt</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">SimplePrompt</strong><span>(</span><span style="color:#dd2200">"请写一个关于小兔子战胜大灰狼的故事。"</span><span>);</span></span><span><span>llm</span><span>.</span><span style="color:#008080">chat</span><span>(</span><span>prompt</span><span>,</span><span>(</span><span>llmInstance</span><span>,</span><span>message</span><span>)</span><span>-&gt;</span><span>{</span></span><span><strong style="color:#445588">System</strong><span>.</span><span style="color:#008080">out</span><span>.</span><span style="color:#008080">println</span><span>(</span><span style="color:#dd2200">"---&gt;"</span><span>+</span><span>message</span><span>.</span><span style="color:#008080">getContent</span><span>());</span></span><span><span>});</span></span><span><strong style="color:#445588">Thread</strong><span>.</span><span style="color:#008080">sleep</span><span>(</span><span style="color:#009999">10000</span><span>);</span></span><span><span>}</span></span></pre><div style="text-align:center">&nbsp;</div></div></div><h2 style="margin-left:0; margin-right:0; text-align:left">历史对话示例</h2><div style="text-align:left"><div><pre><span><strong>public</strong><strong>static</strong><strong style="color:#445588">void</strong><strong style="color:#990000">main</strong><span>(</span><strong style="color:#445588">String</strong><span>[]</span><span>args</span><span>)</span><strong>throws</strong><strong style="color:#445588">InterruptedException</strong><span>{</span></span><span><strong style="color:#445588">SparkLlmConfig</strong><span>config</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">SparkLlmConfig</strong><span>();</span></span><span><span>config</span><span>.</span><span style="color:#008080">setAppId</span><span>(</span><span style="color:#dd2200">"****"</span><span>);</span></span><span><span>config</span><span>.</span><span style="color:#008080">setApiKey</span><span>(</span><span style="color:#dd2200">"****"</span><span>);</span></span><span><span>config</span><span>.</span><span style="color:#008080">setApiSecret</span><span>(</span><span style="color:#dd2200">"****"</span><span>);</span></span><span><span style="color:#888888">// 创建一个大模型</span></span><span><strong style="color:#445588">Llm</strong><span>llm</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">SparkLlm</strong><span>(</span><span>config</span><span>);</span></span><span><span style="color:#888888">//创建一个历史对话的 prompt</span></span><span><strong style="color:#445588">HistoriesPrompt</strong><span>prompt</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">HistoriesPrompt</strong><span>();</span></span><span><strong style="color:#445588">System</strong><span>.</span><span style="color:#008080">out</span><span>.</span><span style="color:#008080">println</span><span>(</span><span style="color:#dd2200">"您想问什么？"</span><span>);</span></span><span><strong style="color:#445588">Scanner</strong><span>scanner</span><span>=</span><strong style="color:#000000">new</strong><strong style="color:#445588">Scanner</strong><span>(</span><strong style="color:#445588">System</strong><span>.</span><span style="color:#008080">in</span><span>);</span></span><span><span style="color:#888888">//等待用户从控制枱输入问题</span></span><span><strong style="color:#445588">String</strong><span>userInput</span><span>=</span><span>scanner</span><span>.</span><span style="color:#008080">nextLine</span><span>();</span></span><span><strong style="color:#000000">while</strong><span>(</span><span>userInput</span><span>!=</span><strong>null</strong><span>){</span></span><span><span>prompt</span><span>.</span><span style="color:#008080">addMessage</span><span>(</span><strong style="color:#000000">new</strong><strong style="color:#445588">HumanMessage</strong><span>(</span><span>userInput</span><span>));</span></span><span><span style="color:#888888">//向大模型提问</span></span><span><span>llm</span><span>.</span><span style="color:#008080">chat</span><span>(</span><span>prompt</span><span>,</span><span>(</span><span>instance</span><span>,</span><span>message</span><span>)</span><span>-&gt;</span><span>{</span></span><span><strong style="color:#445588">System</strong><span>.</span><span style="color:#008080">out</span><span>.</span><span style="color:#008080">println</span><span>(</span><span style="color:#dd2200">"&gt;&gt;&gt;&gt; "</span><span>+</span><span>message</span><span>.</span><span style="color:#008080">getContent</span><span>());</span></span><span><span>});</span></span><span><span style="color:#888888">//继续等待用户从控制枱输入内容</span></span><span><span>userInput</span><span>=</span><span>scanner</span><span>.</span><span style="color:#008080">nextLine</span><span>();</span></span><span><span>}</span></span><span><span>}</span></span></pre></div></div></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 02:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/agents-flex</guid>
            <link>https://www.oschina.net/p/agents-flex</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 云原生量子计算平台，量易伏]]>
            </title>
            <description>
                <![CDATA[<p>简体中文 | <a href="https://gitee.com/baidu/qcompute/blob/master/README.md">English</a></p><h1><a id="user-content-量易伏---qcomputesdk" class="anchor" href="https://gitee.com/baidu/qcompute#%E9%87%8F%E6%98%93%E4%BC%8F---qcomputesdk"></a>量易伏 - QComputeSDK</h1><ul><li><a href="https://gitee.com/baidu/qcompute#%E7%89%B9%E8%89%B2">特色</a></li><li><a href="https://gitee.com/baidu/qcompute#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4">安装步骤</a><ul><li><a href="https://gitee.com/baidu/qcompute#%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE">环境设置</a></li><li><a href="https://gitee.com/baidu/qcompute#%E5%AE%89%E8%A3%85-QComputeSDK">安装 QComputeSDK</a></li><li><a href="https://gitee.com/baidu/qcompute#%E8%BF%90%E8%A1%8C">运行</a></li><li><a href="https://gitee.com/baidu/qcompute#%E9%87%8D%E5%A4%A7%E6%9B%B4%E6%96%B0">重大更新</a></li></ul></li><li><a href="https://gitee.com/baidu/qcompute#%E5%85%A5%E9%97%A8%E4%B8%8E%E5%BC%80%E5%8F%91">入门与开发</a><ul><li><a href="https://gitee.com/baidu/qcompute#%E6%A1%88%E4%BE%8B%E5%85%A5%E9%97%A8">案例入门</a></li><li><a href="https://gitee.com/baidu/qcompute#API-%E6%96%87%E6%A1%A3">API 文档</a></li><li><a href="https://gitee.com/baidu/qcompute#%E5%BC%80%E5%8F%91">开发</a></li></ul></li><li><a href="https://gitee.com/baidu/qcompute#%E4%BA%A4%E6%B5%81%E4%B8%8E%E5%8F%8D%E9%A6%88">交流与反馈</a></li><li><a href="https://gitee.com/baidu/qcompute#%E4%BD%BF%E7%94%A8-qcomputesdk-%E7%9A%84%E5%B7%A5%E4%BD%9C">使用 QComputeSDK 的工作</a></li><li><a href="https://gitee.com/baidu/qcompute#faq">FAQ</a></li><li><a href="https://gitee.com/baidu/qcompute#copyright-and-license">Copyright and License</a></li></ul><p><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2F">Quantum Leaf (量易伏)</a> 是<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum.baidu.com%2F">百度量子计算研究所</a>旗下全球首个云原生量子计算平台。用户可以使用量易伏进行量子编程，量子模拟和运行真实量子计算机。量易伏旨在为量子基础设施即服务 (Quantum infrastructure as a Service, QaaS) 提供量子基础开发环境。</p><p><img src="https://release-data.cdn.bcebos.com/github-qleaf%2F%E9%87%8F%E6%98%93%E4%BC%8F%E5%9B%BE%E6%A0%87.png" alt="" referrerpolicy="no-referrer"></p><p><a href="https://gitee.com/baidu/qcompute/blob/master/LICENSE"><img src="https://img.shields.io/badge/license-Apache%202.0-green" alt="" referrerpolicy="no-referrer"></a><img src="https://img.shields.io/badge/build-passing-green" alt="" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Python-3.9--3.11-blue" alt="" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/release-v3.3.0-blue" alt="" referrerpolicy="no-referrer"></p><p><img src="https://img.shields.io/badge/OS-MacOS%20%7C%20Windows%20%7C%20Linux-lightgrey.svg?style=flat-square" alt="" referrerpolicy="no-referrer"></p><p>本安装包是 QComputeSDK 的 Python 语言实现的全量量子开源计算框架。它采用经典量子混合的编程模式并预制多种先进模块，用户不仅可以在量子环境对象 (QEnv) 下快速搭建电路，也可以将它用于各类复杂量子算法的研发。QComputeSDK 内置多类本地高性能模拟器和云端模拟器/真机调用接口，用户可以将电路在本地模拟器快速模拟验证也可以将电路任务进一步提交至云端真实量子硬件（超导、离子阱）以及高性能模拟器执行。</p><h2><a id="user-content-特色" class="anchor" href="https://gitee.com/baidu/qcompute#%E7%89%B9%E8%89%B2"></a>特色</h2><ul><li>轻松上手
<ul><li>近 50 篇教程案例，还在不断地增加</li><li>量子电路本地可视化</li><li>全自动调用相关计算模块，完成预订流程</li></ul></li><li>功能丰富
<ul><li>支持电路嵌套的量子子程序功能</li><li>本地高性能模拟器支持 32 量子比特的模拟运算</li><li>云端高性能异构模拟器支持更大规模量子模拟</li><li>支持多种噪声模型的模拟</li><li>基于英伟达 cuQuantum 的本地 GPU 模拟器</li><li>基于 Gaussian/Fork 态的本地光量子模拟器</li></ul></li><li>真实量子算力
<ul><li>接入百度自研超导量子计算机 QPUQian</li><li>接入中科院精密测量院离子阱量子计算机 IonAPM</li><li>接入中科院物理所超导量子计算机 IoPCAS</li></ul></li></ul><h2><a id="user-content-安装步骤" class="anchor" href="https://gitee.com/baidu/qcompute#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"></a>安装步骤</h2><h3><a id="user-content-环境设置" class="anchor" href="https://gitee.com/baidu/qcompute#%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE"></a>环境设置</h3><p>推荐使用 Anaconda 创建虚拟环境，</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">conda create <span class="nt">-n</span> qcompute_env <span class="nv">python</span><span class="o">=</span>3.10</span><span id="LC2" class="line">conda activate qcompute_env</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><blockquote><p>Anaconda 请从<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.anaconda.com%2Fdownload%23downloads">官网下载</a></p></blockquote><blockquote><p>注意： 无论使用 Anaconda 还是原生 Python ，Python 版本都应 &gt;= 3.9</p></blockquote><h3><a id="user-content-安装-qcomputesdk" class="anchor" href="https://gitee.com/baidu/qcompute#%E5%AE%89%E8%A3%85-qcomputesdk"></a>安装 QComputeSDK</h3><p>通过 <code>pip</code> 完成安装，</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">pip <span class="nb">install </span>qcompute</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>用户也可以选择下载全部文件后进行本地安装。我们推荐此种方式安装以及二次 SDK 开发，可以方便的形成本地开发闭环，更方便调试等动作。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://github.com/baidu/QCompute.git</span><span id="LC2" class="line"><span class="nb">cd </span>QCompute</span><span id="LC3" class="line">pip <span class="nb">install</span><span class="nt">-e</span><span class="nb">.</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-运行" class="anchor" href="https://gitee.com/baidu/qcompute#%E8%BF%90%E8%A1%8C"></a>运行</h3><p>如果用户选择下载全部文件，现在可以试着运行一段程序来验证是否安装成功。这里我们运行 QComputeSDK 提供的测试脚本，</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">python <span class="nt">-m</span> Test.PostInstall.PostInstall_test</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>该脚本中包括执行本地与云端任务测试，云端测试前需要在命令行输入用户 Token ，Token 可登陆<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Ftoken">量易伏官网</a>查看。如不需要做云端测试可运行 <code>Ctrl+c</code> 结束。</p><blockquote><p>注意：通过 pip 安装请跳过此步。</p></blockquote><h3><a id="user-content-重大更新" class="anchor" href="https://gitee.com/baidu/qcompute#%E9%87%8D%E5%A4%A7%E6%9B%B4%E6%96%B0"></a>重大更新</h3><p>从 QComputeSDK 3.0.0 版本开始，开发者可以通过 QComputeSDK 运行百度自研超导量子计算机干始。设备定期对外提供服务，可以从<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fservices">量易伏真机详情页</a>查看真机开放时间。该设备在 QComputeSDK 中的后端名为<code>CloudBaiduQPUQian</code>.</p><h2><a id="user-content-入门与开发" class="anchor" href="https://gitee.com/baidu/qcompute#%E5%85%A5%E9%97%A8%E4%B8%8E%E5%BC%80%E5%8F%91"></a>入门与开发</h2><h3><a id="user-content-案例入门" class="anchor" href="https://gitee.com/baidu/qcompute#%E6%A1%88%E4%BE%8B%E5%85%A5%E9%97%A8"></a>案例入门</h3><p>QComputeSDK 是一个实现后台接入真实量子硬件的量子计算开发框架。建立起了量子计算与量子硬件的桥梁，为量子算法和应用的研发落地提供强有力的支撑，也提供了丰富的案例供开发者学习。</p><p>在这里，我们提供了初级、中级、高级案例供大家学习。初级案例中展示了使用 QComputeSDK 可以快速上手的简单示例，包括量子态制备、经典量子混合编程、以及将电路任务提交到量子计算机上执行等。中级案例中是 QComputeSDK 的进阶用法，包括模块的使用、内置转换器的使用等。高级案例中则是进阶量子算法在 QComputeSDK 上的实现示例，我们为这些算法都配套了详细的教程文档。建议用户下载 QComputeSDK 全部文件安装，本地运行进行实践。</p><ul><li><p><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1">初级案例</a></p><ol><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/GHZ_Local.py">GHZ 态制备（本地）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/GHZ_Cloud.py">GHZ 态制备（云端）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/HCNOT_Local.py">贝尔态制备（本地）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/HCNOT_Cloud.py">贝尔态制备（云端）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Hybrid_Local.py">经典量子混合语言示例（本地）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Hybrid_Cloud.py">经典量子混合语言示例（云端）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Interact_Local.py">经典量子信息交互示例（本地）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Interact_Cloud.py">经典量子信息交互示例（云端）</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/QPUCase_BaiduQPUQian.py">百度量子自研超导真机运行示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/QPUCase_IonAPM.py">中科院精密测量院离子阱运行示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/QPUCase_IoPCAS.py">中科院物理所超导真机运行示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/PhotonicFookCase_local.py">基于 Fock 态的光量子线路模拟</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/PhotonicGaussianCase_local.py">基于 Gaussian 态的光量子线路模拟</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/SimulatorCase_CuQuantum_Local.py">基于 cuQuantum 的 GPU 模拟器</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Ubqc.py">盲量子计算示例</a></li></ol><ul><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Noise">量子噪声模拟</a><ol><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Noise/AddNoise.py">对电路添加噪声示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Noise/CompressNoiseTest.py">量子噪声压缩模块示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Noise/OneQubitNoiseTest.py">一量子位电路含噪模拟</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Noise/ParallelNoiseSimulationTest.py">多进程并行的噪声模拟</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/Noise/TwoQubitNoiseTest.py">两量子位电路含噪模拟</a></li></ol></li></ul></li><li><p><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2">中级案例</a></p><ul><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/0_OutputFormatControl">输出信息设置</a><ol><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/0_OutputFormatControl/Turorials/OutputFormatControl_ZH.md">教程</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/tutorials/machine_learning/QClassifier_CN.ipynb">结果打印信息设置示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/tutorials/machine_learning/VSQL_CN.ipynb">输出文件自动清理示例</a></li></ol></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules">通用模块</a><ol><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules/Tutorials/OpenModules_ZH.md">教程</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules/0_OpenModules.py">模块使用示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules/1_InverseCircuitModule.py">量子电路逆操作模块</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules/2_ReverseCircuitModule.py">量子电路反操作模块</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules/3_UnrollProcedureModule.py">子程序展开模块</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules/4_UnrollCircuitModule.py">量子门分解模块</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/1_OpenModules/5_CompressGateModule.py">量子门压缩模块</a></li></ol></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors">转换器</a><ol><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/Tutorials/OpenConvertors_ZH.md">教程</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/0_Circuit.py">电路序列化示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/1_DrawConsole.py">终端绘图示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/2_InternalStruct.py">电路序列和反序列示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/3_JSON.py">电路转 JSON 示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/4_QASM.py">电路转 QASM 示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/5_Qobj.py">电路转 QOBJ 示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/6_IonQ.py">电路转 IonQ 示例</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_2/2_OpenConvertors/7_XanaduSF.py">电路转 Xanadu 示例</a></li></ol></li></ul></li><li><p><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3">高级案例</a></p><ol><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3/0_SuperdenseCoding/Tutorial-Superdense/Superdense_CN.md">量子超密编码</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3/1_Deutsch-Jozsa/Tutorial-DJ/Deutsch-Jozsa_CN.md">Deutsch-Jozsa 算法</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3/2_PhaseEstimation/Tutorial-phase/Phase_CN.md">量子相位估计 (QPE)</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3/3_Grover/Tutorial-Grover/Grover_CN.md">格罗弗搜索算法</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3/4_ShorAlgorithm/tutorial/Shor_CN.md">Shor 算法</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3/5_VQE/Tutorial-VQE/VQE_CN.md">变分量子基态求解器 (VQE)</a></li><li><a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_3/6_VQSD/Tutorial-VQSD/VQSD_CN.md">变分量子态对角化 (VQSD)</a></li></ol></li></ul><p>在最近的更新中，QComputeSDK 加入了本地光量子计算模拟器 (LocalBaiduSimPhotonic) 。与传统的量子电路模型不同，光量子计算具有其独特的运行方式。QComputeSDK 在架构上支撑起光学体系，也成为了首个集成通用量子计算与光量子计算双体系的量子开发套件。感兴趣的读者请参见<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fpqs%2Ftutorial-introduction">光量子计算模拟器教程</a>。</p><h3><a id="user-content-api-文档" class="anchor" href="https://gitee.com/baidu/qcompute#api-%E6%96%87%E6%A1%A3"></a>API 文档</h3><p>了解更多 QComputeSDK 使用方法，请参考 <a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fdocs%2Fqcompute%2Flatest%2F">API 文档</a>，包含了供用户使用的所有函数和类的详细说明与用法。</p><h3><a id="user-content-开发" class="anchor" href="https://gitee.com/baidu/qcompute#%E5%BC%80%E5%8F%91"></a>开发</h3><p>QComputeSDK 中包括量子计算架构、量子模拟器、量子案例以及扩展功能等。对于需要涉及架构或模拟器源码的开发者，建议下载全部文件并本地安装调试。对于使用 QComputeSDK 研发算法应用的开发者或科研工作者，建议以 <a href="https://gitee.com/baidu/qcompute/blob/master/Example/Level_1/GHZ_Cloud.py">GHZ_Cloud.py</a> 作为代码框架，修改和使用这个文件可以有效帮助熟悉本量子开发套件的语法。建议开发者熟悉 QComputeSDK 的电路模型构造，注意量子位输出顺序为高位。</p><h2><a id="user-content-交流与反馈" class="anchor" href="https://gitee.com/baidu/qcompute#%E4%BA%A4%E6%B5%81%E4%B8%8E%E5%8F%8D%E9%A6%88"></a>交流与反馈</h2><ul><li>我们非常欢迎您提交问题、报告与建议，您可以通过以下渠道反馈
<ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fbaidu%2FQCompute%2Fissues">GitHub Issues</a> / <a href="https://gitee.com/baidu/qcompute/issues">Gitee Issues</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Ffeedback">量易伏官网-意见反馈</a></li><li>量易伏官方邮箱 <a href="mailto:quantum@baidu.com">quantum@baidu.com</a></li></ul></li><li>技术交流 QQ 群：1147781135，欢迎扫码进群</li></ul><p><img src="https://release-data.cdn.bcebos.com/github-qleaf%2Fqrcode.png" alt="" referrerpolicy="no-referrer"></p><h2><a id="user-content-使用-qcomputesdk-的工作" class="anchor" href="https://gitee.com/baidu/qcompute#%E4%BD%BF%E7%94%A8-qcomputesdk-%E7%9A%84%E5%B7%A5%E4%BD%9C"></a>使用 QComputeSDK 的工作</h2><p>我们非常欢迎开发者使用 QComputeSDK 进行量子应用研发，如果您的工作有使用 QComputeSDK，也非常欢迎联系我们。以下为基于 QComputeSDK 开发的量子应用：</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fqep%2Ftutorial-overview">量噪 (QEP, Quantum Error Processing)</a>，百度量子计算研究所研发的量子噪声处理工具集，主要功能包括量子性能评估、量子噪声刻画、量子噪声缓释和量子纠错。</li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fbqc%2Ftutorial-bqc">盲量子计算 (UBQC, Universal Blind Quantum Computation)</a>，百度量子计算研究所研发的基于 UBQC 协议的盲计算代理服务。</li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fqapp%2Ftutorial-overview">QAPP</a> 是基于 QComputeSDK 开发的量子计算解决方案工具集，提供包括量子化学、组合优化、机器学习在内的诸多领域问题的量子计算求解服务。</li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fqsvt%2Ftutorial-overview">量子奇异值变换 (QSVT, Quantum Singular Value Transformation)</a>，百度量子计算研究所研发的量子奇异值变换工具集，主要功能包括量子奇异值变换，对称量子信号处理，以及哈密顿量模拟。</li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fqfinance%2Ftutorial-option-pricing">量子金融 QFinance</a> ，百度量子计算研究所研发的量子金融库，提供用于期权定价的量子蒙特卡罗方法。</li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fpqs%2Ftutorial-introduction">光量子计算模拟器 (PQS, Photonic Quantum Simulator)</a>，百度研究院量子计算研究所研发的光量子计算模拟器，支持基于 Gaussian 态和 Fock 态的光量子线路模拟。</li></ul><h2><a id="user-content-faq" class="anchor" href="https://gitee.com/baidu/qcompute#faq"></a>FAQ</h2><ol><li><p>问：<strong>使用 QComputeSDK 可以做什么？它有哪些应用场景？</strong></p><p>答：QComputeSDK 是一个基于 Python 的量子计算开发框架，可以用于构建、运行和优化量子算法。我们在 QComputeSDK 建设了全面且完善的基础设施用于支持各类量子算法的实现，因此在量子应用的研发上它具有广泛的应用场景。具体工作可以参考但不限于 QComputeSDK 中的<a href="https://gitee.com/baidu/qcompute/blob/master/Extensions">扩展功能</a>。</p></li><li><p>问：<strong>想用 QComputeSDK 做量子编程，但对量子计算不是很了解，该如何入门？</strong></p><p>答：Nielsen 和 Chuang 所著的《量子计算与量子信息》是量子计算领域公认的经典入门教材。建议读者首先学习这本书的第一、二、四章，介绍了量子计算中的基本概念、数学和物理基础、以及量子电路模型。读者也可以在<a href="https://gitee.com/link?target=https%3A%2F%2Fqulearn.baidu.com%2F">量易简</a>上学习，这是一个在线量子学习知识库，不仅包含量子计算教程，还有丰富的视频课程。读者还可以下载<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fqmobile">量易伏 APP</a>，APP 上的量子小调包含丰富有趣的量子样例，帮助读者随时随地的学习。</p></li><li><p>问：<strong>QComputeSDK 是否免费？</strong></p><p>答：QComputeSDK 是免费的。QComputeSDK 是开源 SDK 并携带多类本地模拟器，用户执行本地模拟任务是免费的。当用户通过 QComputeSDK 将任务提交给云端模拟器或真机运行时，会扣除一定点数。详细的扣点规则可以参考<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2FquickGuide%2Faccount">用户指南</a>。用户在创建账户时我们会赠送点数，点数余额可以在<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fprofile">个人中心</a>查看。</p></li><li><p>问：<strong>点数不足怎么办？</strong></p><p>答：点数目前仅用于资源控制。点数不足时可以从量易伏官网的<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Ffeedback">意见反馈</a>或<a href="https://gitee.com/link?target=https%3A%2F%2Fquantum-hub.baidu.com%2Fqmobile">量易伏 APP</a>的用户反馈提交点数申请。我们会在三个工作日内处理您的请求。</p></li></ol><h2><a id="user-content-copyright-and-license" class="anchor" href="https://gitee.com/baidu/qcompute#copyright-and-license"></a>Copyright and License</h2><p>QComputeSDK 使用 <a href="https://gitee.com/baidu/qcompute/blob/master/LICENSE">Apache-2.0 license</a> 许可证。</p><h2><a id="user-content-作者" class="anchor" href="https://gitee.com/baidu/qcompute#%E4%BD%9C%E8%80%85"></a>作者</h2><ul><li>刘树森</li><li>贺旸</li><li>江云帆</li><li>张文学</li><li>孙文赟</li><li>付永凡</li><li>陈建萧</li><li>沈豪杰</li><li>吕申进</li><li>王友琪</li></ul>]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 02:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/baidu/qcompute</guid>
            <link>https://gitee.com/baidu/qcompute</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | ElasticSearch 集群灾难：别放弃，也许能再抢救一下]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>1 前言</h1><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">Elasticsearch 作为一个分布式搜索引擎，自身是高可用的；但也架不住一些特殊情况的发生，如：</p><ul><li><p style="color:#222222; margin-left:0; margin-right:0">集群超过半数的 master 节点丢失，ES 的节点无法形成一个集群，进而导致集群不可用；</p></li><li><p style="color:#222222; margin-left:0; margin-right:0">索引 shard 的文件损坏，分片无法被正常恢复，进而导致索引无法正常提供服务</p></li><li><p style="color:#222222; margin-left:0; margin-right:0">本地盘节点，多数据节点故障，旧节点无法再次加入集群，数据丢失</p></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">针对上述的情况，今天来聊一聊相关的解决方案。</p><span id="OSC_h1_2"></span><h1>2 基础知识</h1><span id="OSC_h2_3"></span><h2>2.1 集群经典架构</h2><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">在聊解决方案之前，首先来看一看 ES 集群层面的基本知识，es 的集群组成通常如图 1-1 所示<img alt="es 集群角色.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-01-06-15-270pb9YSxO96kLhga.png" referrerpolicy="no-referrer"></p><div><p>图 1-1 es 常用集群架构</p> 如图 1-1 所示，为生产环境 es 集群的经典架构，主要由专有主节点、专有协调节点和数据节点组成： 
</div><ul><li><p style="color:#222222; margin-left:0; margin-right:0"><strong>专有主节点 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fmodules-node.html%23master-node" rel="nofollow" target="_blank">Master-eligible node</a>)</strong>: 具有 master 角色的节点，这使其有资格被选为主节点，只存储集群元信息包含 cluster、index、shard 级别的元数据；该种角色节点被选举为 master 之后，将作为整个 ES 集群的大脑，负责维护集群层面的元信息，创建删除索引等工作。该种节点的个数必须为奇数，通常我们固定为 3 个，如果该类节点丢失半数，es 集群将无法维持 es 节点形成一个集群。</p></li><li><p style="color:#222222; margin-left:0; margin-right:0"><strong>专有协调节点 (网关节点)</strong>: 该种节点不具有任何角色，仅仅用来处理 es 请求；比如（1）将写请求的数据归类转发到数据所属的节点（2）查询请求的二次聚合计算。通常我们也会给该类节点保留<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fmodules-node.html%23node-ingest-node" rel="nofollow" target="_blank">ingest 角色</a><span>&nbsp;</span>，ingest 的主要作用是对数据进行预处理；比如：字段重命名、给数据文档打上指纹和清洗数据等功能主要通过<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fpipeline.html" rel="nofollow" target="_blank">pipeline 能力</a>进行处理</p></li><li><p style="color:#222222; margin-left:0; margin-right:0"><strong>数据节点 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fmodules-node.html%23data-node" rel="nofollow" target="_blank">Data node</a>)</strong>: 存储数据和集群元信息，执行与数据相关的操作，如 CRUD、搜索和聚合。在数据节点上打上不同的属性，可以使其成为 hot、warm、cold 数据节点，在 es7.9 版本之后配置略有不同，但是原理基本不变。</p></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">如果没有显示设置节点角色，es 的每个节点都会含有以上三种角色。除此之后还有<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fmodules-node.html%23remote-node" rel="nofollow" target="_blank">Remote-eligible node</a><span>&nbsp;</span>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fmodules-node.html%23ml-node" rel="nofollow" target="_blank">ml-node</a>和<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fmodules-node.html%23transform-node" rel="nofollow" target="_blank">Transform nodes</a>等角色需要显示的配置，节点才会有该角色。</p><span id="OSC_h2_4"></span><h2>2.2 集群元信息</h2><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">集群完全启动主要包含选举主节点、元信息、主分片、数据恢复等重要阶段；如图 2-1 所示[1]。</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start"><img alt="5211704611687_.pic.jpg" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-01-07-15-22jRx48QjPfQUT8WnF.jpg" referrerpolicy="no-referrer"></p><div><p>图 2-1 es 集群启动流程</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">主节点选举的过程，不是本文的重点，而是集群元信息的选举。被选举出的 master 和集群元信息新旧程度没有关系；master 节点被选举出来之后，它所要完成的第一个任务，即是选举集群元信息。</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">（1）Master 选举成功之后，判断其持有的集群状态中是否存在 STATE_NOT_RECOVERED_BLOCK，如果不存在，则说明元数据已<br> 经恢复，跳过 gateway 恢复过程，否则等待。<code>org.elasticsearch.gateway.GatewayService#clusterChanged</code></p><pre><code>//跳过元数据恢复
if (state.blocks().hasGlobalBlock(STATE_NOT_RECOVERED_BLOCK) == false) {
            // already recovered
            return;
 }
 //此处省略部分代码。
 //进入 gateway 恢复过程   
performStateRecovery(enforceRecoverAfterTime, reason); 
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">（2）Master 从各个节点主动获取元数据信息。<code>org.elasticsearch.gateway.Gateway#performStateRecovery</code></p><pre><code># 获取元信息核心代码
 final String[] nodesIds = clusterService.state().nodes().getMasterNodes().keys().toArray(String.class);
        logger.trace("performing state recovery from {}", Arrays.toString(nodesIds));
        final TransportNodesListGatewayMetaState.NodesGatewayMetaState nodesState = listGatewayMetaState.list(nodesIds, null).actionGet();
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">（3）从获取的元数据信息中选择版本号最大的作为最新元数据;元信息包括集群级、索引级。</p><pre><code>## org.elasticsearch.gateway.Gateway#performStateRecovery

    public void performStateRecovery(final GatewayStateRecoveredListener listener) throws GatewayException {
# 省略若干行代码

## 进入 allocation 阶段；
## final Gateway.GatewayStateRecoveredListener recoveryListener = new GatewayRecoveryListener();
## listener 为 GatewayStateRecoveredListener   
 listener.onSuccess(builder.build());    
}
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">（4）两者确定之后，调用 allocation 模块的 reroute，对未分配，的分片执行分配，主分片分配过程中会异步获取各个 shard 级别元数据。</p><pre><code>#主要实现方法为如下方法   
#org.elasticsearch.gateway.GatewayService.GatewayRecoveryListener#onSuccess
## 主要工作是构建集群状态（ClusterState），其中的内容路由表，依赖 allocation 模块协助完成，调用 allocationService.reroute 进，入下一阶段：异步执行分片层元数据的恢复，以及分片分配。updateTask 线程结束.
   
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start"><strong>ES 中存储的数据</strong>：（1）state 元数据信息；（2）index Lucene 生成的索引文件；（3）translog 事务日志。<br><strong>元数据信息</strong>：</p><ol><li><p style="color:#222222; margin-left:0; margin-right:0">nodes/0/_state/*.st，集群层面元信息 MetaData（clusterUUID 、 settings 、templates 等）；</p></li><li><p style="color:#222222; margin-left:0; margin-right:0">nodes/0/indices/{index_uuid}/_state/*.st，索引层面元信息 IndexMetaData（ numberOfShards 、mappings 等）；</p></li><li><p style="color:#222222; margin-left:0; margin-right:0">nodes/0/indices/{index_uuid}/0/_state/*.st，分片层面元信息 ShardStateMetaData（version 、indexUUID、primary 等）。</p></li></ol><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">上述信息被持久化到磁盘：持久化的 state 不包括某个分片存在于哪个节点这种内容路由信息，集群完全重启时，依靠 gateway 的 recovery 过程重建 RoutingTable 和 RoutingNode。当读取某个文档时， 根据路由算法确定目的分片后，再从 RoutingTable 中查找分片位于哪个节点，然后将请求转发到目的节点[1]。</p><blockquote><p style="color:#999999; margin-left:0; margin-right:0">⚠️ 注意：在 es7.0.0 之后 es 的元信息存储方式发生变化；<br> es7.0.0 之后元信息存储改使用 lucene 的方式存储，见<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F50928" rel="nofollow" target="_blank">pr50928 Move metadata storage to Lucene</a>)</p></blockquote><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">7.10.2 专有主节点，集群元数据</p><pre><code>./
|-- _state
|   |-- _39h.cfe
|   |-- _39h.cfs
|   |-- _39h.si
|   |-- node-0.st
|   |-- segments_50d
|   `-- write.lock
`-- node.lock
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">6.8.13 专有主节点，集群元数据</p><pre><code>./
|-- _state
|   |-- global-230.st
|   `-- node-2.st
|-- indices
|   |-- -hiy4JnoRfqUJHTJoNUt4Q
|   |   `-- _state
|   |       `-- state-4.st
|   `-- ylJKVlqISGOi8EkpxHE_2A
|       `-- _state
|           `-- state-6.st
`-- node.lock
</code></pre><span id="OSC_h1_5"></span><h1>3 灾难场景与处理方法</h1><span id="OSC_h2_6"></span><h2>3.1 master 节点丢失</h2><blockquote><p style="color:#999999; margin-left:0; margin-right:0">⚠️ 注意本文所述的 master 节点个数，假设前提均为 3 个</p></blockquote><span id="OSC_h3_7"></span><h3>场景 1 master 节点丢失过半</h3><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">master 节点是控制整个集群；当该种节点角色丢失过半，由于集群中投票节点永远不可能达到 quorum 无法选主，将无法维持 es 节点形成一个集群；虽然集群无法形成一个集群，但所仍幸 master-eligible 节点存活,我们可以使用如下手段进行处理。</p><span id="OSC_h4_8"></span><h4>es7.0.0 版本之前</h4><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">1 修改剩余节点的 elasticsearch.yaml 配置如下,修改 quorum 的个数，然后启动剩余的节点，形成一个新的集群；</p><pre><code>discovery.zen.minimum_master_nodes: 1
discovery.zen.ping.unicast.hosts:
- masters-0
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">2 重建补充之前丢失的 master-eligible 节点，加入集群之后.<br> 3 将集群配置修改为旧的配置，再逐一重启下集群中的节点，先从 master-eligible 开始.</p><span id="OSC_h4_9"></span><h4>es7.0.0（包含）版本之后.</h4><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">在 es7.0.0 版本之后,由于 es 修改集群的启动配置,新增配置<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.0%2Fdiscovery-settings.html%23unicast.hosts" rel="nofollow" target="_blank">discovery.seed_hosts</a><span>&nbsp;</span>和<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.0%2Fdiscovery-settings.html%23initial_master_nodes" rel="nofollow" target="_blank">cluster.initial_master_nodes</a>；es 集群第一次启动时称为 bootstrap，该过程将配置文件中的 cluster.initial_master_node 作为初始的投票节点<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.9%2Fmodules-discovery-voting.html" rel="nofollow" target="_blank">Voting configurations</a>，投票节点具有选举 master 和 commit cluster state 的权利，超过半数以上同意即投票成功。如果在集群健康的场景下，我们需要下线超过半数的 master-eligible；则必须首先使用投票配置排除 API 从投票配置中排除受影响的节点。</p><pre><code>POST _cluster/voting_config_exclusions?node_names={node_names}
POST _cluster/voting_config_exclusions?node_ids={node_ids}
DELETE _cluster/voting_config_exclusions
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">但是如果丢失的 master 节点超过半数，则可以使用新的集群处理工具 elasticsearch-node unsafe-bootstrap<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F37696" rel="nofollow" target="_blank">pr37696</a><span>&nbsp;</span>和 elasticsearch-node detach-cluster<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F37979" rel="nofollow" target="_blank">pr37979</a></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">面对丢失半数 master-eligible，es7.0.0（包含）版本之后的处理步骤如下：<br> 1 使用<code>bin/elasticsearch-node unsafe-bootstrap</code>命令让唯一主节点以不安全的方式改写投票节点，就像重新进行 bootstrap 一样，自己使用持久化的 cluster state 形成一个新集群<br> 2 其他数据节点无法加入新集群因为 UUID 不同 (es 使用 UUID 作为节点和集群的唯一表示，每个节点都会持久化当前集群的 UUID)，使用<code>bin/elasticsearch-node detach-cluster</code>命令让节点离开之前的集群<br> 3 启动数据节点和新的 master-eligible 节点 (如下补充两个新的 master-eligible)，他会加入新集群中</p><pre><code>cluster.initial_master_nodes:
- {master-0}
- {new-master-1}
- {new-master-2}
discovery.seed_hosts:
- {master-ip-0}
- {new-master-ip-1}
- {new-master-ip-2}
</code></pre><span id="OSC_h3_10"></span><h3>场景 2 master 节点全部丢失</h3><span id="OSC_h4_11"></span><h4>es7.0.0 版本之前</h4><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">1 关闭 security 功能 (如果开启了, 最好先关闭 security 插件功能)：<br> 1.1 因为新启动的 master 节点, 没有数据节点 (如果只配置了一个 master 的角色), security 插件的初始化无法完成, 各类接口不好调用<br> 1.2 如果给新启动的 master 节点, 配置了 master and data 角色, 则 security 插件会初始化成功. 会插入 index, 但是这个 index 会和原来的 data 节点上保存的冲突. 不知道怎么解.<br> elastic 官方<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fconfiguring-security.html" rel="nofollow" target="_blank">xpack-security</a>;关闭鉴权：<code>xpack.security.enabled:false</code><br> 2 启动足够的新 master-eligible 节点形成一个新集群.</p><pre><code>discovery.zen.minimum_master_nodes: 2
discovery.zen.ping.unicast.hosts:
- {new-masters-1}
- {new-masters-2}
- {new-masters-3}
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">3 修改数据节点的为新 master 的地址,并且删除掉节点上的_state(因为新集群的 cluster UUID 不一致)，同上<br> 4 启动数据节点，数据被恢复加入到集群</p><span id="OSC_h4_12"></span><h4>es7.0.0（包含）版本之后</h4><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">已经没有 cluster state 了，唯一的希望是数据节点上的 index 数据；恢复方式借助<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fnode-tool.html" rel="nofollow" target="_blank">elasticsearch-node</a><span>&nbsp;</span>工具</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">1 关闭 security 功能 (如果开启了, 最好先关闭 security 插件功能),原因同上<br> 2 启动足够的新 master-eligible 节点形成一个新集群</p><pre><code>cluster.initial_master_nodes:
- {new-master-0}
- {new-master-1}
- {new-master-2}
discovery.seed_hosts:
- {new-master-ip-0}
- {new-master-ip-1}
- {new-master-ip-2}
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">3<span>&nbsp;</span><code>bin/elasticsearch-node detach-cluster</code>命令让数据节点离开之前的集群</p><pre><code>./bin/elasticsearch-node detach-cluster
------------------------------------------------------------------------

    WARNING: Elasticsearch MUST be stopped before running this tool.

------------------------------------------------------------------------

You should only run this tool if you have permanently lost all of the
master-eligible nodes in this cluster and you cannot restore the cluster
from a snapshot, or you have already unsafely bootstrapped a new cluster
by running `elasticsearch-node unsafe-bootstrap` on a master-eligible
node that belonged to the same cluster as this node. This tool can cause
arbitrary data loss and its use should be your last resort.

Do you want to proceed?

Confirm [y/N] y
Node was successfully detached from the cluster
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">4<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.9%2Fdangling-indices-list.html" rel="nofollow" target="_blank">查询 dangling 索引</a>,<code>GET /_dangling</code>, 改 api 引入 es7.9 版本于<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F58176" rel="nofollow" target="_blank">pr58176</a><br> 5 启动数据节点并使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.9%2Fdangling-index-import.html" rel="nofollow" target="_blank">Import dangling indexAPI</a>将 index 数据 import 到 cluster state 中 (官方推荐，es7.9 版本之后). 或者，配置<code>gateway.auto_import_dangling_indices: true</code>引入于 es7.6 版本<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F49174" rel="nofollow" target="_blank">pr49174</a>（es7.6.0-7.9.0 可用该配置，在 7.6 版本之前不需要配置默认加载 dangling 索引）并启动数据节点</p><pre><code>POST /_dangling/{index-uuid}?accept_data_loss=true
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">6 导入完成之后，索引 recovery 之后即可进行读写</p><blockquote><blockquote><p style="color:#999999; margin-left:0; margin-right:0">注意</p></blockquote><p style="color:#999999; margin-left:0; margin-right:0"><strong>Q1</strong>: 为什么 7.6.0 之后需要配置,才能处理悬空索引（dangling index）才能让数据加入新集群，7.6.0 之后没有悬空索引吗？<br><strong>A1</strong>: 其实也是有的，只不过在 es2 版本将配置移除（对应<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F10016" rel="nofollow" target="_blank">pr10016</a>）,默认自动加载 dangling index（es2.0-es7.6）; 具体实现于<code>org.elasticsearch.gateway.DanglingIndicesState#processDanglingIndices</code><span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F49174" rel="nofollow" target="_blank">es7.6 再次引入 dangling 配置</a>，es7.9 引入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.9%2Fdangling-index-import.html" rel="nofollow" target="_blank">dangling index rest api</a></p></blockquote><blockquote><p style="color:#999999; margin-left:0; margin-right:0"><strong>Q2</strong>: 什么是 dangling 索引？<br><strong>A2</strong>: 当一个节点加入集群时，如果发现存储在其本地数据目录中的任何分片（shard）不存在于集群中，将认为这些分片属于「悬空」索引。悬空索引产生的场景（1）在 Elasticsearch 节点离线时删除了多个<code>cluster.indices.tombstones.size</code><span>&nbsp;</span>索引，节点再次加入集群集群 （2）master 节点丢失，数据节点重新加入新的集群等</p></blockquote><span id="OSC_h2_13"></span><h2>3.2 数据节点故障</h2><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">数据节点灾难故障之后，无法恢复加入集群；可将数据物理复制到新的节点，然后按照 master 节点丢失的方式，将数据节点加入集群即可。</p><span id="OSC_h2_14"></span><h2>3.3 分片不能够自动分配</h2><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">查看索引分片为什么无法分配，<code>POST _cluster/allocation/explain</code></p><span id="OSC_h3_15"></span><h3>3.3.1 分片正常</h3><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">如果分片数据正常，那么我们可以尝试重试分配分片任务;<code>POST _cluster/reroute?retry_failed</code></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">获取索引的 shard 在那些节点上，使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.0%2Findices-shards-stores.html" rel="nofollow" target="_blank">_shard_stores api</a></p><pre><code>GET indexName1/_shard_stores
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fcluster-reroute.html" rel="nofollow" target="_blank">cluster reroute</a>重新分配</p><pre><code># 尝试分配副本 
POST /_cluster/reroute
{
  "commands": [
    {
      "allocate_replica": {
        "index": "{indexName1}",
        "shard": {shardId},
        "node": "{nodes-9}"
      }
    }
  ]
}
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">如果是主分片无法分配，可以尝试如下命令进行分配</p><pre><code>POST /_cluster/reroute
{
  "commands": [
    {
      "allocate_stale_primary": {
        "index": "{indexName1}",
        "shard": {shardId},
        "node": {nodes-9},
        "accept_data_loss": true
      }
    }
  ]
}
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">如果主分片确实是无法分配，只能选择丢失该分片的数据，分配一个空的主分片</p><pre><code>POST /_cluster/reroute
{
  "commands": [
    {
      "allocate_empty_primary": {
        "index": "{indexName1}",
        "shard": {shardId},
        "node": "{nodes-9}",
        "accept_data_loss": true
      }
    }
  ]
}
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">es5.0 版本之前参考; https://www.elastic.co/guide/en/elasticsearch/reference/2.4/cluster-reroute.html</p><span id="OSC_h3_16"></span><h3>3.3.2 分片数据损坏</h3><span id="OSC_h4_17"></span><h4>shard corrupted</h4><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">错误参考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.elastic.co%2Ft%2Fcorrupted-elastic-index%2F135932" rel="nofollow" target="_blank">Corrupted elastic index</a></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F6.5%2Fshard-tool.html" rel="nofollow" target="_blank">shard-tool</a><span>&nbsp;</span>es6.5 版本引入，该操作需要 stop 节点<br> elasticsearch-shard 工具 es6.5 版本引入<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F33848" rel="nofollow" target="_blank">pr33848</a><br> elasticsearch-shard remove-corrupted-data 的 es7.0.0 引入<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F32281" rel="nofollow" target="_blank">pr32281</a></p><pre><code>bin/elasticsearch-shard remove-corrupted-data --index {indexName} --shard-id {shardId}
## 示列：修复索引 twitter 的 0 号分片
bin/elasticsearch-shard remove-corrupted-data --index twitter --shard-id 0

## 如果--index 和--shard-id 换成索引分片目录参数--dir，则直接修复 data 和 translog
bin/elasticsearch-shard remove-corrupted-data --dir /var/lib/elasticsearchdata/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">修复完成之后，启动节点，如果分片不能够自动分配,使用 reroute 命令进行 shard 分片</p><pre><code>POST /_cluster/reroute{
  "commands":[
    {
      "allocate_stale_primary":{
        "index":"index42",
        "shard":0,
        "node":"node-1",
        "accept_data_loss":false
      }
    }
  ]}
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">5 版本之前可以通过索引级别配置，进行修复<br> index.shard.check_on_startup: fix ，该配置在 es6.5 版本移除<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F32279" rel="nofollow" target="_blank">pr32279</a></p><span id="OSC_h4_18"></span><h4>translog 损坏</h4><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">修复 translog 操作，需要 stop 节点。</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">修复工具 elasticsearch-translog es5.0.0 引入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F19342" rel="nofollow" target="_blank">pr19342</a><br> elasticsearch-shard remove-corrupted-data translog 的 es7.4.1 开始引入，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F47866" rel="nofollow" target="_blank">pr47866</a>elasticsearch-shard 可以直接清除 translog，也可以像上文中指定--dir 那样进行修复 translog</p><pre><code>bin/elasticsearch-shard remove-corrupted-data --index  --shard-id   --truncate-clean-translog
## 示列：修复索引 twitter 的 0 号分片
bin/elasticsearch-shard remove-corrupted-data --index twitter --shard-id 0 --truncate-clean-translog
</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">清除完成之后使用 cluster reroute 进行恢复</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">5 版本之前可以通过索引级别配置，进行修复<br> index.shard.check_on_startup: fix ，该配置在 es6.5 版本移除<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Fpull%2F32279" rel="nofollow" target="_blank">pr32279</a></p><span id="OSC_h4_19"></span><h4><code>segments_N 文件丢失</code></h4><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">该种场景的文件损坏是最难修复的；官方还未提供工具，我们正在自己调研中</p><span id="OSC_h1_20"></span><h1>4 参考</h1><p style="color:#222222; margin-left:0; margin-right:0; text-align:start">[1]<span>&nbsp;</span>elasticsearch 集群启动流程<br> [2]https://www.elastic.co/guide/en/elasticsearch/reference/7.9/dangling-indices-list.html<br> [3]https://www.elastic.co/guide/en/elasticsearch/reference/7.10/node-tool.html</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">作者：京东科技，杨松柏</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">来源：京东云开发者社区，转载请注明来源</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 23 Jan 2024 02:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10920402</guid>
            <link>https://my.oschina.net/u/4090830/blog/10920402</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[德国程序员因报告漏洞被判罚 2.4 万元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">德国于利希地方法院近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.heise.de%2Fnews%2FWarum-ein-Sicherheitsforscher-im-Fall-Modern-Solution-verurteilt-wurde-9601392.html" target="_blank">宣布</a>了一项最新判决结果，认定一名程序员因未经授权访问第三方计算机系统和刺探数据，违反《德国刑法典》（StGB）中所谓的黑客条款 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gesetze-im-internet.de%2Fstgb%2F__202a.html" target="_blank">202a</a> 而处以 3000 欧元的罚款（约 2.35 万元），同时承担所有的诉讼费用。</span></p><p><img height="203" src="https://oscimg.oschina.net/oscnet/up-1685fc08f7024fc47d741af2e54fc872cf5.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">2021 年 6 月，这位名为 Hendrik H. 的研究人员在为 IT 服务公司 Modern Solution GmbH 的一位客户排除软件故障时发现，Modern Solution 的代码通过 MySQL 连接至一台 MariaDB 数据库服务器。而访问远程服务器的密码则以纯文本形式存储在程序文件 MSConnect.exe 中，任何人使用简单的文本编辑器就能打开该文件查看内容，并找到未加密的硬编码密码。</span></p><p><span style="color:#000000">也正是因为这个唾手可得的密码，导致任何人都可以登录远程服务器访问 Modern Solution 的客户的数据，同时还可以访问存储在该数据库服务器上的供应商所有客户的数据。总的来说，这个数据库漏洞暴露了近 70 万条客户记录，包括姓名、电子邮件地址、电话号码、银行信息、密码以及对话和通话记录等。</span></p><p><span style="color:#000000">在发现这一漏洞后，该程序员在一名技术博客作者 Mark Steier 的帮助下联系了相关公司，后者随后修复了安全漏洞，并报警追究这名程序员的责任。2021 年 9 月，德国警方扣押了 Hendrik H. 的电脑，因为 Modern Solution 指控他是通过内部信息获得的密码，并声称他是竞争对手。</span></p><p><span style="color:#000000">2023 年 6 月，德国于利希地方法院以 Modern Solution 软件保护不力为由，支持了 Hendrik H 的诉讼请求。但亚琛地区法院指令于利希地方法院再次审理此案，原先的裁定被推翻。2024 年 1 月 17 日，于利希地方法院最终宣判对 Hendrik H. 处以罚款，并责令其支付诉讼费用。</span></p><p><span style="color:#000000">这一判决不可避免的在广大网络安全专家和研究人员当中引起了争议。Steier 发帖<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwortfilter.de%2Fentdecker-des-datenlecks-modern-solution-heute-vor-gericht%2F" target="_blank">表示</a>，这一判决从根本上就是错误的。「几乎以纯文本形式保存的密码并不构成第 202 条所要求的'special security'。法官无法对此作出判断是可以理解的，但这样一来就必须就这个问题听取专家的意见。遗憾的是，这并没有发生。」</span></p><p><span style="color:#000000">不过，该判决尚未具有法律约束力。</span><span style="background-color:#ffffff; color:#323232">被告的辩护律师辩称，即使法院判定他有罪，他的当事人的行为也是为了公众利益。</span><span style="color:#000000">被指控的程序员已于 1 月 19 日宣布，正在对判决提出上诉。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 22 Jan 2024 09:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276369/germany-programmer-fined-security</guid>
            <link>https://www.oschina.net/news/276369/germany-programmer-fined-security</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[北京获准向公众开放的生成式 AI 大模型产品占全国近半]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>北京市第十六届人民代表大会第二次会议于日前召开，会上透露，2023,年，北京获准向公众开放的生成式人工智能大模型产品占全国近一半。今年，北京将推动人工智能模型对标国际先进水平，加快在政务、医疗、工业、生活服务等领域应用。</p><p>北京市市长殷勇作政府工作报告时指出，2023 年，北京加快建设国际科技创新中心，加强科技领军人才尤其是青年人才培养引进，实施基础研究领先行动和关键核心技术攻坚战行动，推动在京国家实验室高质量运行，支持新型研发机构开展有组织科研，加快构建以企业为主导的产学研深度融合新范式。</p><p>北京巩固提升高精尖产业发展优势，出台通用人工智能、人形机器人等 30 余项细分产业支持政策，新设 4 支政府高精尖产业基金，一批创新药品、医疗器械获批上市，小米智能手机工厂、理想汽车旗舰工厂提前投产。</p><p>北京精心打造全球数字经济标杆城市，率先建成全球性能领先的区块链基础设施，新增 5G 基站 3 万个，获准向公众开放的生成式人工智能大模型产品占全国近一半，「京通」「京办」「京智」三个智慧城市应用终端快速升级拓展，高级别自动驾驶示范区实现 160 平方公里连片运行，全国首个数据基础制度先行区启动建设，数字经济增加值占地区生产总值比重达 42.9%。</p><p>殷勇说，今年，北京将加快发展新质生产力。实施制造业重点产业链高质量发展行动，提升产业链供应链韧性和安全水平。加强原创新药和高端医疗器械研发，培育生物制造等医药健康产业新增长点。推动新能源汽车产业高质量发展，积极布局电机、电池、电控等关键零部件产业链。推进超高清视频全产业链优化升级。促进新能源、新材料、商业航天、低空经济等战略性新兴产业发展，开辟量子、生命科学等未来产业新赛道。优化专精特新企业梯队培育体系，助力更多企业发展壮大。</p><p>殷勇指出，今年，北京将促进平台经济有序竞争、创新发展，推动先进数字技术向中小企业深度普及，构建开放共享、充满活力的创新生态。提升人工智能底层技术和基础底座自主可控能力，推动人工智能模型对标国际先进水平，加快在政务、医疗、工业、生活服务等领域应用，保持人工智能研发应用领先水平。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 22 Jan 2024 05:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276347</guid>
            <link>https://www.oschina.net/news/276347</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RustDesk 新增 2FA 双重认证功能，增强远程桌面访问安全性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>RustDesk <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frustdesk%2Frustdesk%2Freleases%2Ftag%2Fnightly" target="_blank">nightly</a>&nbsp;新增 2FA 双重认证功能，增强远程桌面访问安全性，欢迎大家试用反馈。</p><p><img height="1246" src="https://oscimg.oschina.net/oscnet/up-0de6626da796bb7195b23fc861ee98e2f12.jpg" width="1708" referrerpolicy="no-referrer"></p><p><img height="623" src="https://oscimg.oschina.net/oscnet/up-eef5d3bce35b2b05039bb7678d9ebbea95b.jpg" width="854" referrerpolicy="no-referrer"></p><p><img height="1270" src="https://oscimg.oschina.net/oscnet/up-d4017aeb3ba844b73de27c16d258a40944d.jpg" width="1780" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 22 Jan 2024 04:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276342/rustdesk-2fa</guid>
            <link>https://www.oschina.net/news/276342/rustdesk-2fa</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[到底什么样的 Java 项目用 Solon 好？？？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; margin-left:0; margin-right:0; text-align:start">就像华为讲的，不要因为爱国而特意买华为手机。Solon 也是，<strong>有需要就用不需要就跳过</strong>（按正常的需求选择）：</p><ul><li>信创需要国产化，应该用 Solon 或者 Solon Cloud（有案例）</li><li>军工项目要国产化，应该用 Solon 或者 Solon Cloud（有案例）</li><li>嵌入式设备，内存有限，算力差，可以用 Solon 或者 Solon Native（有案例）</li><li>客户的希望你内存更少，可以用 Solon （有案例）</li><li>别的框架用腻了，可以用 Solon （有案例）</li><li>有新系统开发想尝新的框架，可以用 Solon （有案例）</li><li>老系统要轻量化改造，可以用 Solon（有案例）</li></ul><p style="color:#24292e; margin-left:0; margin-right:0; text-align:start">作为后来者，大家的疑或是会多一些。有问题，可以去交流群里多交流。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 22 Jan 2024 04:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276341</guid>
            <link>https://www.oschina.net/news/276341</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[如何写好大模型提示词？来自大赛冠军的经验分享（进阶篇）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p><strong>编者按</strong>：近期，如何通过 Prompt Engineering 最大程度发挥大模型的潜力已成为一个热点话题。人们越来越关注如何通过 Prompt Engineering 技术低成本地用好大模型。</p><p>今天我们推荐的这篇文章，作者认为 Prompt Engineering 需要结合艺术与科学，需要在理解技术背景的同时，发挥创造力和战略思维。</p><p>本系列文章详细介绍了作者在新加坡首届 GPT-4 Prompt Engineering 大赛中使用的策略技巧，包括：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMTI3MTg5MQ%3D%3D%26mid%3D2247484732%26idx%3D1%26sn%3Dbb155ad71f69a8b6aefe7f8557192620%26chksm%3Dc26cc080f51b4996fbb197d6a1fbdce5a45aad000747178e06abea12c89a5601101309012e68%26scene%3D21%23wechat_redirect" target="_blank">使用 CO-STAR 框架构建提示语、使用分隔符明确语义单元</a>、利用 system prompts 添加行为约束、仅依靠 GPT-4 对数据集进行分析等。这些技巧都得到了实例验证，证明了 Prompt Engineering 的重要作用。</p><p>本文属于该系列文章的第二部分，详细介绍适合进阶使用的 Prompt Engineering 高级策略。</p></blockquote><p><strong>作者 |&nbsp;Sheila Teo</strong></p><p><strong>编译&nbsp;|&nbsp;岳扬</strong></p><p><strong>🚢🚢🚢欢迎小伙伴们加入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaihai-idp.yuque.com%2Fmwvla8%2Fdoc%3F%23" target="_blank">AI 技术软件及技术交流群</a>，追踪前沿热点，共探技术难题~</strong></p><p>上个月，我有幸获得新加坡首届 GPT-4 提示工程（Prompt Engineering）大赛相关奖项，该比赛由新加坡政府科技署（GovTech）组织，汇聚了超过 400&nbsp;位优秀的参与者。</p><p><strong>提示工程（Prompt Engineering）是一门融合了艺术和科学的学科——这门学科不仅需要理解技术，还需要一定的创造力和战略思维。</strong> 以下是我在学习过程中学到的提示工程（Prompt Engineering）策略汇编，这些策略可以驱动任何大语言模型（LLM）精准执行需求，甚至超常发挥！</p><blockquote><p>作者注：</p><p>在撰写本文时，我力图摒弃已在网上广泛讨论和记录的传统提示工程（Prompt Engineering）技术。相反，撰写本文的目的是给大家介绍我在实验中学到的新见解，以及对某些技术的不同理解。希望你会喜欢阅读这篇文章！</p></blockquote><p>本系列文章包括以下内容，其中🔵指的是适合初学者的提示语（prompt）技巧（<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMTI3MTg5MQ%3D%3D%26mid%3D2247484732%26idx%3D1%26sn%3Dbb155ad71f69a8b6aefe7f8557192620%26chksm%3Dc26cc080f51b4996fbb197d6a1fbdce5a45aad000747178e06abea12c89a5601101309012e68%26scene%3D21%23wechat_redirect" target="_blank">见基础篇</a>），而🔴指的是高级策略（本文的重点）：</p><p>1.[🔵] 使用&nbsp;CO-STAR&nbsp;框架构建提示语</p><p>2.[🔵]&nbsp;使用分隔符（delimiters）将提示语分段</p><p><strong>3.[🔴]&nbsp;使用&nbsp;LLM guardrails&nbsp;创建&nbsp;system prompts</strong>（译者注："guardrails"&nbsp;指的是一种保护机制或限制，用于确保大语言模型生成的内容符合特定标准或要求，防止产生不准确、不合适或有害的信息。）</p><p><strong>4.[🔴]&nbsp;仅使用&nbsp;LLM（无需插件或代码）分析数据集——将介绍一个使用&nbsp;GPT-4&nbsp;分析真实&nbsp;Kaggle&nbsp;数据集的实践示例</strong></p><h1><strong>01 [🔴]&nbsp;使用&nbsp;LLM guardrails&nbsp;创建&nbsp;system prompts</strong></h1><p>在进入正题之前，需要注意的是本节只适用于具有 System Prompt 功能的 LLM，而不像基础篇和本文的其他章节那样适用于任何 LLM。最著名的 LLM 当然是&nbsp;ChatGPT ，因此在本节中我们将以 ChatGPT 作为示例。</p><h2><strong>1.1 围绕&nbsp;System Prompt&nbsp;的术语</strong></h2><p>首先，让我们来理清术语，特别是关于 ChatGPT 的三种术语的使用：这三种术语在 ChatGPT 几乎可以互换使用：&nbsp;"System Prompts"、"System Messages "和&nbsp;"Custom Instructions"。这让很多人（包括我在内！）感到困惑，以至于&nbsp;OpenAI&nbsp;特意发布了一篇文章来解释这些术语。以下是其摘要：</p><ul><li><strong>"System Prompts"和"System Messages"是通过 Chat Completions API 以编程方式与 ChatGPT 进行交互时使用的术语。</strong></li><li><strong>另一方面，"Custom Instructions"是通过 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.openai.com%2F" target="_blank">https://chat.openai.com/</a>&nbsp; 用户界面与 ChatGPT 交互时使用的术语。</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-121921e25f98c551f3af8e6f70943254843.png" alt="" referrerpolicy="no-referrer"></p><p>Image from Enterprise DNA Blog</p><p>不过总的来说，这三个术语指的是同一件事，所以不要被这些术语混淆了！后续部分，本文将使用&nbsp;"System Prompts"一词。现在，让我们进入正题！</p><h2><strong>1.2 什么是 System Prompts ？</strong></h2><p>System Prompts 是一种额外的提示语（prompt），我们可以在其中提供有关 LLM 行为方式的 instructions。它被认为是额外的提示语（prompt），因为它不属于您给 LLM 的&nbsp;"正常"&nbsp;提示语（即 User Prompts）。</p><p>在聊天中，每当您给 LLM 发送新的提示语（prompt）时，System Prompts 都会像过滤器一样，LLM 会在回答您的新提示语（prompt）之前自动应用这些提示语（prompt）。这意味着 System Prompts 在 LLM 做出回答时都会被考虑进去。</p><h2><strong>1.3 何时使用 System Prompt ？</strong></h2><p>您心中可能会想到的第一个问题是：为什么我应该在 System Prompts 中提供 instruction，而不是在我向与 LLM 的新对话的第一个提示语（prompt）中提供 instruction，然后再与 LLM 进行更多的对话呢？</p><p>答案是，因为 LLM 的对话记忆是有限的。在后一种情况下，随着对话的继续，LLM 很可能会"忘记"您在聊天中提供的第一条提示语（prompt），从而使这些 instruction （指令）过时。</p><p>另一方面，如果在 System Prompts 中提供了 instruction （指令），那么这些 System Prompts &nbsp;会与聊天中提供的每个新提示语一起发送。这可以确保 LLM 在聊天过程中继续接收这些 instruction，无论聊天过程变得多长。</p><p>总结：</p><p>在整个聊天过程中，使用 System Prompts 提供您希望 LLM 在回答时记住的 instruction 。</p><h2><strong>1.4 System Prompt 应包括哪些内容？</strong></h2><p>System Prompt 通常应包括以下类别的 instruction ：</p><ul><li><strong>目标任务的定义（Task definition）</strong> ，这样 LLM 在整个对话过程中都会记住它必须做什么。</li><li><strong>输出格式（Output format）</strong> ，这样 LLM 在整个对话过程中都会记住它应该如何做出回答。</li><li><strong>防范措施（Guardrails）</strong> ，这样 LLM 在整个对话过程中都会记住它不应该如何做出回答。Guardrails 是 LLM governance 中的新兴领域，指的是 LLM 被允许操作的行为边界。</li></ul><p>例如，System Prompt 可能是这样的：</p><blockquote><p>You will answer questions using this text:&nbsp;[insert text].</p><p>You will respond with a JSON object in this format:&nbsp;{「Question」:&nbsp;「Answer」}.</p><p>If the text does not contain sufficient information to answer the question,&nbsp;do not make up information and give the answer as&nbsp;「NA」.</p><p>You are only allowed to answer questions related to&nbsp;[insert scope].&nbsp;Never answer any questions related to demographic information such as age,&nbsp;gender,&nbsp;and religion.</p></blockquote><p>各部分内容涉及的类别如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-cab48977b545bba61bf371683a3bdc105af.png" alt="" referrerpolicy="no-referrer"></p><p>Breaking down a System Prompt&nbsp;—&nbsp;Image by author</p><h2><strong>1.5 但是，"正常"的聊天提示语又是什么呢？</strong></h2><p>现在你可能会想：听起来 System Prompt 中已经提供了很多信息。那我应该在聊天的"正常"提示语（即 User Prompts）中写些什么呢？</p><p>System Prompt 概述了当前的一般任务。在上面的 System Prompt 示例中，任务已被定义为只使用一段特定的文本来回答问题，并且 LLM 被指示以{"Question":&nbsp;"Answer"}的格式进行回答。</p><blockquote><p>You will answer questions using this text:&nbsp;[insert text].</p><p>You will respond with a JSON object in this format:&nbsp;{「Question」:&nbsp;「Answer」}.</p></blockquote><p>在这种情况下，聊天过程中的每个 User Prompt 都将简化为你希望 LLM 用文本回答的问题。例如，某个用户的提问可能是「这段文本是关于什么的？（What is the text about?）」然后 LLM 会回答说&nbsp;{"这段文本是关于什么的？（What is the text about?）":&nbsp;"这段文本是关于……（The text is about..）"}。</p><p>但是，让我们进一步概括这个任务示例。在这种情况下，我们可以将上述 System Prompt &nbsp;的第一行从：</p><blockquote><p>You will answer questions using this text:&nbsp;[insert text].</p></blockquote><p>编辑为：</p><blockquote><p>You will answer questions using the provided text.</p></blockquote><p>现在，每个用户在聊天时的提示语（prompt）将包括进行问题回答的文本和要回答的问题，例如：</p><blockquote><p>&lt;text&gt;</p><p>[insert text]</p><p>&lt;/text&gt;</p><p>&lt;question&gt;</p><p>[insert question]</p><p>&lt;/question&gt;</p></blockquote><p>在这里，还将使用 XML 标签作为分隔符，以便以结构化的方式向 LLM 提供所需的两个信息片段。<strong>XML 标签中使用的名词「text」和「question」与 System Prompt 中使用的名词相对应，这样 LLM 就能理解标签与 System Prompt instructions 之间的关系。</strong></p><p>总之， System Prompt 应给出总体任务 instructions，而每个 User Prompt 应提供任务执行的具体细节。例如，在本例中，这些具体的细节是 text 和 question。</p><h2><strong>1.6 LLM guardrails&nbsp;动态化</strong></h2><p>上面通过 System Prompt 中的几句话添加了 guardrails 。这些 guardrails 会被固定下来，在整个聊天过程中都不会改变。但是如果您希望在对话的不同阶段设置不同的 guardrails ，该怎么办？</p><p>对于使用 ChatGPT Web 界面的用户来说，目前还没有直接的方法来做到这一点。不过，如果您正在通过编程方式与 ChatGPT 进行交互，那你就走运了！随着人们对构建有效的 LLM guardrail 的关注度越来越高，一些开源软件包也应运而生，它们可以让你以编程方式设置更详细、更动态的 guardrail。</p><p>其中值得注意的是英伟达团队开发的&nbsp;NeMo Guardrails[1]，它允许您配置用户和 LLM 之间预期的对话流程，从而在聊天的不同时间点设置不同的 guardrail ，实现随着聊天进展而不断演变的动态 guardrails 。我强烈推荐您去了解一下！</p><h1><strong>02 [🔴]&nbsp;仅使用&nbsp;LLM（无需插件或代码）分析数据集</strong></h1><p>您可能已经听说过 OpenAI 在 ChatGPT 的 GPT-4 中推出的高级数据分析插件，该插件仅高级（付费）账户可以使用。它允许用户将数据集上传到 ChatGPT，并直接在数据集上运行代码，从而进行精确的数据分析。</p><p>但你知道吗，使用 LLM 分析数据集并不一定需要这样的插件？让我们先来了解一下单纯使用 LLMs 分析数据集的优势和局限性。</p><h2><strong>2.1 大语言模型不擅长的数据集分析类型</strong></h2><p>正如您可能已经知道的那样，LLM 在进行精确数学计算方面的能力有限，因此它们不适合完成需要对数据集进行精确定量分析的任务，比如：</p><ul><li><strong>描述性统计（Descriptive Statistics）</strong> ：通过诸如均值或方差的测量来定量总结数值列。</li><li><strong>相关性分析（Correlation Analysis）</strong> ：获取列之间精确的相关系数。</li><li><strong>统计分析（Statistical Analysis）</strong> ：比如假设检验（hypothesis testing），以确定各组数据点之间是否存在统计意义上的显著差异。</li><li><strong>机器学习（Machine Learning）</strong> ：在数据集上执行预测建模，比如使用线性回归（linear regressions）、梯度提升树（gradient boosted trees）或神经网络（neural networks）。</li></ul><p>方便在数据集上执行这些定量任务正是 OpenAI 推出高级数据分析插件的原因，这样编程语言就可以在数据集上运行代码来执行此类任务。</p><p>那么，为什么有人只想使用 LLM 而不使用此类插件来分析数据集呢？</p><h2><strong>2.2 大语言模型擅长的数据集分析类型</strong></h2><p>LLM 非常擅长识别模式和趋势（patterns and trends）。这种能力源自它们在多样化和海量数据上的广泛训练，使它们能够识别那些可能无法立即察觉的复杂模式。</p><p>这使它们非常适合执行基于数据集进行模式识别的任务，例如：</p><ul><li><strong>异常检测（Anomaly detection）</strong> ：基于一列或多列的数值，识别偏离常规的异常数据点。</li><li><strong>聚类（Clustering）</strong> ：将具有相似特征的数据点分组。</li><li><strong>跨列关系（Cross-Column Relationships）</strong> ：通过分析不同列之间的关系，可以揭示数据中的复杂模式和趋势。</li><li><strong>文本分析（Textual Analysis）（针对基于文本的列）</strong> ：基于主题或情感进行分类。</li><li><strong>趋势分析（Trend Analysis）（针对具有时间特征的数据集）</strong> ：识别列中跨时间的模式、季节性变化或趋势。</li></ul><p>对于这类基于模式的任务，单独使用 LLM 可能会比使用代码在更短的时间内获得更好的结果！让我们用一个例子来充分说明这一点。</p><h2><strong>2.3 仅使用&nbsp;LLM&nbsp;分析&nbsp;Kaggle&nbsp;数据集</strong></h2><p>我们将使用一个广受欢迎的真实&nbsp;Kaggle&nbsp;数据集[2]，该数据集专为进行客户人格分析而准备，其中一家公司试图对其客户群体进行细分，以便更好地了解其客户。</p><p>为了便于之后验证 LLM 的分析结果，我们取该数据集的 50&nbsp;行为一个子集，并只保留最相关的列。之后，用于分析的数据集将如下所示，其中每一行代表一位客户，每一列描述客户信息：</p><p><img src="https://oscimg.oschina.net/oscnet/up-7c8caf80c5954ae73d0746053b0109b7737.png" alt="" referrerpolicy="no-referrer"></p><p>First 3 rows of dataset&nbsp;—&nbsp;Image by author</p><p>假设你在公司的营销团队工作。你的任务是利用这些客户信息数据集来指导营销工作。这是一项分两步走的任务：首先，利用数据集划分多个具有实际意义的客户细分群体。接下来，提出如何最好地针对每个客户群体进行创意营销。现在，这是一个实际的商业问题，LLM 的模式发现（pattern-finding，对于步骤 1 ）能力在这个问题上确实可以大显身手。</p><p>让我们按照以下方式为这个任务制定提示语（prompt），将使用&nbsp;4&nbsp;种&nbsp;prompt engineering&nbsp;技术（后续会详细介绍[3]）：</p><p><strong>1. 将复杂的任务分解为简单的步骤</strong></p><p><strong>2. 参考每个步骤的中间输出</strong></p><p><strong>3. 格式化 LLM 的回答</strong></p><p><strong>4. 将&nbsp;instructions&nbsp;与数据集分开</strong></p><blockquote><p>System Prompt:</p><p>I want you to act as a data scientist to analyze datasets.&nbsp;Do not make up information that is not in the dataset.&nbsp;For each analysis I ask for,&nbsp;provide me with the exact and definitive answer and do not provide me with code or instructions to do the analysis on other platforms.</p><p>Prompt:</p><p>#&nbsp;CONTEXT&nbsp;#</p><p>I sell wine.&nbsp;I have a dataset of information on my customers:&nbsp;[year of birth,&nbsp;marital status,&nbsp;income,&nbsp;number of children,&nbsp;days since last purchase,&nbsp;amount spent].</p><p>#############</p><p>#&nbsp;OBJECTIVE&nbsp;#</p><p>I want you use the dataset to cluster my customers into groups and then give me ideas on how to target my marketing efforts towards each group.&nbsp;Use this step-by-step process and do not use code:</p><p>1.&nbsp;CLUSTERS:&nbsp;Use the columns of the dataset to cluster the rows of the dataset,&nbsp;such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values.&nbsp;Ensure that each row only belongs to 1 cluster.</p><p>For each cluster found,</p><p>2.&nbsp;CLUSTER_INFORMATION:&nbsp;Describe the cluster in terms of the dataset columns.</p><p>3.&nbsp;CLUSTER_NAME:&nbsp;Interpret&nbsp;[CLUSTER_INFORMATION]&nbsp;to obtain a short name for the customer group in this cluster.</p><p>4.&nbsp;MARKETING_IDEAS:&nbsp;Generate ideas to market my product to this customer group.</p><p>5.&nbsp;RATIONALE:&nbsp;Explain why&nbsp;[MARKETING_IDEAS]&nbsp;is relevant and effective for this customer group.</p><p>#############</p><p>#&nbsp;STYLE&nbsp;#</p><p>Business analytics report</p><p>#############</p><p>#&nbsp;TONE&nbsp;#</p><p>Professional,&nbsp;technical</p><p>#############</p><p>#&nbsp;AUDIENCE&nbsp;#</p><p>My business partners.&nbsp;Convince them that your marketing strategy is well thought-out and fully backed by data.</p><p>#############</p><p>#&nbsp;RESPONSE:&nbsp;MARKDOWN REPORT&nbsp;#</p><p>&lt;For each cluster in&nbsp;[CLUSTERS]&gt;</p><p>—&nbsp;Customer Group:&nbsp;[CLUSTER_NAME]</p><p>—&nbsp;Profile:&nbsp;[CLUSTER_INFORMATION]</p><p>—&nbsp;Marketing Ideas:&nbsp;[MARKETING_IDEAS]</p><p>—&nbsp;Rationale:&nbsp;[RATIONALE]</p><p>&lt;Annex&gt;</p><p>Give a table of the list of row numbers belonging to each cluster,&nbsp;in order to back up your analysis.&nbsp;Use these table headers:&nbsp;[[CLUSTER_NAME],&nbsp;List of Rows].</p><p>#############</p><p>#&nbsp;START ANALYSIS&nbsp;#</p><p>If you understand,&nbsp;ask me for my dataset.</p></blockquote><p>GPT-4 的回答如下，接下来我们将数据集以 CSV 字符串的形式传递给它。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e81a5f6ea27da5b058438541aa821009931.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-4's response&nbsp;—&nbsp;Image by author</p><p>随后，GPT-4 将按照我们要求的 markdown 格式回复分析结果：</p><p><img src="https://oscimg.oschina.net/oscnet/up-72040eca14932d7eb9289119eb13af4d0a8.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-4's response&nbsp;—&nbsp;Image by author</p><p><img src="https://oscimg.oschina.net/oscnet/up-03f08b1a6bfadee91b96716822f50f0c4a4.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-4's response&nbsp;—&nbsp;Image by author</p><p><img src="https://oscimg.oschina.net/oscnet/up-f81c09e878806d7f71c9773c8291d3611d5.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-4's response&nbsp;—&nbsp;Image by author</p><h2><strong>2.4 验证&nbsp;LLM&nbsp;的分析结果</strong></h2><p>为了简洁起见，我们将挑选 LLM 生成的 2 个客户群体进行验证，比如 Young Families 和 Discerning Enthusiasts。</p><h3><strong>2.4.1 Young Families</strong></h3><ul><li>LLM 总结的该人群特征：1980 年后出生，已婚或同居，收入中等偏低，有孩子，经常进行小额购买。</li><li>LLM 将数据集中的这些行聚类到了 Young Families 这个群体中：3、4、7、10、16、20</li></ul><p>深入数据集，这些行的完整数据如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-01030fc251ada675444cc2b84f87f861ce5.png" alt="" referrerpolicy="no-referrer"></p><p>Full data for Young Families&nbsp;—&nbsp;Image by author</p><p>LLM 识别出的这部分客户资料，确实对应于所识别的客户群体。甚至能够在我们事先未经过预处理的情况下对具有空值的资料进行聚类！</p><h3><strong>2.4.2 Discerning Enthusiasts</strong></h3><ul><li>LLM 总结的该人群特征：年龄跨度广，可能是任何婚姻状况，高收入，子女状况各异，购买支出高。</li><li>LLM 认为该人群对应的数据行：2、5、18、29、34、36</li></ul><p>深入数据集，这些行的完整数据如下：</p><p><img src="https://oscimg.oschina.net/oscnet/up-2844275d166caf555082adb378ad4e1e7b6.png" alt="" referrerpolicy="no-referrer"></p><p>Full data for Discerning Enthusiasts&nbsp;—&nbsp;Image by author</p><p>再次与 LLM 识别出的人群资料非常吻合！</p><p>这个例子展示了 LLM 在发现模式、解释和提炼多维数据集，并将其提炼为有意义的见解方面的能力，同时确保其分析深深扎根于数据集的事实。</p><h2><strong>2.5 如果我们使用 ChatGPT 的高级数据分析插件会怎样呢？</strong></h2><p>为了保证分析的完整性，我尝试使用相同的提示语（prompt），并请求 ChatGPT 使用代码执行相同的分析，这就激活了它的高级数据分析插件。这个想法是让插件直接在数据集上运行 K-Means 等聚类算法的代码，以获得各个用户群体的特征，然后综合每个群体的数据来提供营销策略。</p><p>然而，尽管数据集只有 50&nbsp;行，进行了多次尝试都导致出现以下错误信息而没有任何输出：</p><p><img src="https://oscimg.oschina.net/oscnet/up-10c7526d7a4b7d296cef8b48699d37762a9.png" alt="" referrerpolicy="no-referrer"></p><p>Error and no output from Attempt 1&nbsp;—&nbsp;Image by author</p><p><img src="https://oscimg.oschina.net/oscnet/up-fa3318a26ba4ab2800121fb5ab4295345f5.png" alt="" referrerpolicy="no-referrer"></p><p>Error and no output from Attempt 2&nbsp;—&nbsp;Image by author</p><p>现在使用高级数据分析插件，在数据集上执行较简单的任务（如计算描述性统计数据或创建图表）似乎很容易实现，但需要某些计算算法的较高级任务有时可能会由于计算限制或其他原因导致错误或无输出。</p><h2><strong>2.6 那么......何时使用 LLM 分析数据集？</strong></h2><p>答案是取决于分析的数据类型。</p><p>对于需要精确数学计算或复杂的、基于规则处理的任务，传统的编程方法仍然更胜一筹。</p><p>对于基于模式识别（pattern-recognition）的任务，使用传统的编程或算法方式可能比较具有挑战性或更耗时。然而，LLM 擅长此类任务，甚至可以提供额外的内容输出，比如用来支持其分析的附件和 Markdown 格式的完整分析报告。</p><blockquote><p><strong>归根结底，是否使用 LLM 取决于手头任务的性质，要在 LLM 在模式识别方面的优势与传统编程技术提供的精确性和特异性之间取得平衡。</strong></p></blockquote><h2><strong>2.7 现在回到提示工程（prompt engineering）！</strong></h2><p><strong>在本节结束之前，让我们回顾一下用于生成此数据集分析的提示语（prompt），并分解所使用的 prompt engineering 关键技术。</strong></p><blockquote><p>Prompt:</p><p>#&nbsp;CONTEXT&nbsp;#</p><p>I sell wine.&nbsp;I have a dataset of information on my customers:&nbsp;[year of birth,&nbsp;marital status,&nbsp;income,&nbsp;number of children,&nbsp;days since last purchase,&nbsp;amount spent].</p><p>#############</p><p>#&nbsp;OBJECTIVE&nbsp;#</p><p>I want you use the dataset to cluster my customers into groups and then give me ideas on how to target my marketing efforts towards each group.&nbsp;Use this step-by-step process and do not use code:</p><p>1.&nbsp;CLUSTERS:&nbsp;Use the columns of the dataset to cluster the rows of the dataset,&nbsp;such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values.&nbsp;Ensure that each row only belongs to 1 cluster.</p><p>For each cluster found,</p><p>2.&nbsp;CLUSTER_INFORMATION:&nbsp;Describe the cluster in terms of the dataset columns.</p><p>3.&nbsp;CLUSTER_NAME:&nbsp;Interpret&nbsp;[CLUSTER_INFORMATION]&nbsp;to obtain a short name for the customer group in this cluster.</p><p>4.&nbsp;MARKETING_IDEAS:&nbsp;Generate ideas to market my product to this customer group.</p><p>5.&nbsp;RATIONALE:&nbsp;Explain why&nbsp;[MARKETING_IDEAS]&nbsp;is relevant and effective for this customer group.</p><p>#############</p><p>#&nbsp;STYLE&nbsp;#</p><p>Business analytics report</p><p>#############</p><p>#&nbsp;TONE&nbsp;#</p><p>Professional,&nbsp;technical</p><p>#############</p><p>#&nbsp;AUDIENCE&nbsp;#</p><p>My business partners.&nbsp;Convince them that your marketing strategy is well thought-out and fully backed by data.</p><p>#############</p><p>#&nbsp;RESPONSE:&nbsp;MARKDOWN REPORT&nbsp;#</p><p>&lt;For each cluster in&nbsp;[CLUSTERS]&gt;</p><p>—&nbsp;Customer Group:&nbsp;[CLUSTER_NAME]</p><p>—&nbsp;Profile:&nbsp;[CLUSTER_INFORMATION]</p><p>—&nbsp;Marketing Ideas:&nbsp;[MARKETING_IDEAS]</p><p>—&nbsp;Rationale:&nbsp;[RATIONALE]</p><p>&lt;Annex&gt;</p><p>Give a table of the list of row numbers belonging to each cluster,&nbsp;in order to back up your analysis.&nbsp;Use these table headers:&nbsp;[[CLUSTER_NAME],&nbsp;List of Rows].</p><p>#############</p><p>#&nbsp;START ANALYSIS&nbsp;#</p><p>If you understand,&nbsp;ask me for my dataset.</p></blockquote><p><strong>技巧 1：将复杂任务分解为简单步骤</strong></p><p>LLM 擅长执行简单任务，但在复杂任务上表现一般。因此，<strong>对于像这样的复杂任务，重要的是要把任务分解成简单的步骤说明，让 LLM 遵循。</strong> 这样做的目的是向 LLM 提供你自己执行任务时会采取的步骤。</p><p>在本例中，步骤如下：</p><blockquote><p><strong>Use this step-by-step process and do not use code:</strong></p><p><strong>1.&nbsp;CLUSTERS:&nbsp;Use the columns of the dataset to cluster the rows of the dataset,&nbsp;such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values.&nbsp;Ensure that each row only belongs to 1 cluster.</strong></p><p><strong>For each cluster found,</strong></p><p><strong>2.&nbsp;CLUSTER_INFORMATION:&nbsp;Describe the cluster in terms of the dataset columns.</strong></p><p><strong>3.&nbsp;CLUSTER_NAME:&nbsp;Interpret&nbsp;[CLUSTER_INFORMATION]&nbsp;to obtain a short name for the customer group in this cluster.</strong></p><p><strong>4.&nbsp;MARKETING_IDEAS:&nbsp;Generate ideas to market my product to this customer group.</strong></p><p><strong>5.&nbsp;RATIONALE:&nbsp;Explain why&nbsp;[MARKETING_IDEAS]&nbsp;is relevant and effective for this customer group.</strong></p></blockquote><p>与简单地将整体任务交给 LLM 相比，例如「将客户分组，然后提出针对每个群体的营销策略」。通过逐步说明，LLM 更有可能提供正确的结果。</p><p><strong>技巧 2：引用每个步骤的中间输出</strong></p><p>在向 LLM 提供逐步说明时，可将每个步骤的中间输出命名为大写的变量名，例如 CLUSTERS、CLUSTER_INFORMATION、CLUSTER_NAME、MARKETING_IDEAS 和 RATIONALE。</p><p><strong>使用大写字母是为了将这些变量名与给出的 instructions 内容区分开。稍后可以使用方括号引用这些中间输出，如[VARIABLE_NAME]。</strong></p><p><strong>技巧 3：规范大模型回答的格式</strong></p><p>在这里，要求使用 Markdown 报告格式，以美化 LLM 的回答。在这里，中间输出中的变量名又派上了用场，可以决定报告的结构。</p><blockquote><p>#&nbsp;RESPONSE:&nbsp;MARKDOWN REPORT&nbsp;#</p><p>&lt;For each cluster in&nbsp;[CLUSTERS]&gt;</p><p>—&nbsp;Customer Group:&nbsp;[CLUSTER_NAME]</p><p>—&nbsp;Profile:&nbsp;[CLUSTER_INFORMATION]</p><p>—&nbsp;Marketing Ideas:&nbsp;[MARKETING_IDEAS]</p><p>—&nbsp;Rationale:&nbsp;[RATIONALE]</p><p>&lt;Annex&gt;<br><strong>Give a table of the list of row numbers belonging to each cluster,&nbsp;in order to back up your analysis.&nbsp;Use these table headers:&nbsp;[[CLUSTER_NAME],&nbsp;List of Rows].</strong></p></blockquote><p>事实上，您甚至可以随后要求 ChatGPT 将报告提供为可下载文件，这样您就可以根据其回答来撰写最终的报告文档。</p><p><img src="https://oscimg.oschina.net/oscnet/up-792771629e0046fa10609d608023fce4df5.png" alt="" referrerpolicy="no-referrer"></p><p>Saving GPT-4's response as a file&nbsp;—&nbsp;Image by author</p><p><strong>技巧 4：将任务说明与数据集分开</strong></p><p>您会注意到我们在第一个提示语中并没有将数据集提供给 LLM。相反，提示语只包含了数据集分析的任务说明，并在最后加上了以下内容：</p><blockquote><p>#&nbsp;START ANALYSIS&nbsp;#</p><p>If you understand,&nbsp;ask me for my dataset.</p></blockquote><p>ChatGPT 随后回复说它理解了，我们将在下一个提示语中将数据集作为 CSV 字符串传递给它：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3b139d01a6cf26df1f930d6e67dc5b8be24.png" alt="" referrerpolicy="no-referrer"></p><p>GPT-4's response&nbsp;—&nbsp;Image by author</p><p><strong>但为什么要将 instructions 与数据集分开呢？</strong></p><p>简单明了的答案是，LLM 的上下文窗口存在限制，即在一句提示语中可以输入的 tokens 数量存在限制。同时包含 instructions 和数据的长提示语（long prompt）可能会超过这个限制，从而导致截断（truncation）和信息丢失（loss of information）。</p><p>更复杂的答案是，<strong>将 instructions 和数据集分开可以帮助 LLM 保持清晰的理解，降低遗漏信息的可能性。</strong> 你可能遇到过这样的情况，即 LLM "不小心忘记了"&nbsp;你发送的较长提示语给出的某个 instruction ——例如，如果你要求给出 100&nbsp;字的回答，而 LLM 却给了您一个较长的段落。通过先接收 instructions ，再接收 instructions 所针对的数据集，LLM 可以先消化它应该执行的任务，然后再对接下来提供的数据集执行 instructions 。</p><p>不过请注意，只有聊天型&nbsp;LLM&nbsp;才能实现&nbsp;instruction&nbsp;和数据集的分离，因为它们会保留对话记忆，而&nbsp;completion LLM&nbsp;则不会（译者注：completion LLM 指的是一种能够根据给定的提示语来生成完整文本或完成特定任务的语言模型。这种模型通常不具备对话记忆，而是专注于根据提示语生成连贯的文本）。</p><p><strong>Thanks for reading!</strong></p><p><strong>END</strong></p><p><strong>🚢🚢🚢欢迎小伙伴们加入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaihai-idp.yuque.com%2Fmwvla8%2Fdoc%3F%23" target="_blank">AI 技术软件及技术交流群</a>，追踪前沿热点，共探技术难题~</strong></p><p><strong>参考资料</strong></p><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FNVIDIA%2FNeMo-Guardrails" target="_blank">https://github.com/NVIDIA/NeMo-Guardrails</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fimakash3011%2Fcustomer-personality-analysis" target="_blank">https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis</a></p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41%23544b" target="_blank">https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41#544b</a></p><p><strong>本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。</strong></p><p><strong>原文链接：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41" target="_blank">https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 22 Jan 2024 03:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/10920438</guid>
            <link>https://my.oschina.net/IDP/blog/10920438</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
