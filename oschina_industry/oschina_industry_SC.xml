<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 21 Nov 2023 23:00:25 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[「X」Embedding in NLP｜初识自然语言处理（NLP）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>从情感分析到信息提取，再到机器翻译、问答系统、聊天机器人……自然语言处理（Natural Language Processing，NLP）的应用可谓复杂多样。向量数据库的加入，则为 NLP 注入了更多的可能性。</p><p>为了方便大家能够深入了解向量数据库与 NLP 的关系及应用，我们上线了「X」Embedding in NLP 系列专题，分为初阶和进阶两部分。本文为初阶第一篇，将详细介绍 NLP 以及以 Zilliz Cloud、Milvus 为代表的向量数据库是如何为 NLP 赋能的。</p><h2>01.什么是 NLP ？</h2><p>自然语言处理（NLP）是跨学科的机器学习技术，结合了人工智能和计算语言学。其主要目标是让计算机能够以有意义和有价值的方式理解和响应人类语言。</p><p>当然，我们可以构建一个包含所有句子的词典来实现这一目标，但这有些不切实际，因为人类语言中用于构成句子的单词组合无穷无尽。不仅如此，口音、多样的同义词汇、错误发音或句中省略单词等情况，进一步加深了人类语言的复杂性。</p><p>NLP 运用各种技术和算法处理自然语言数据。本质上，NLP 用于处理非结构化数据，特别是非结构化文本，并通过自然语言理解（NLU），使用文本和语音的句法和语义分析来确定句子的含义，并生成计算机可以使用的结构化文本。相反，自然语言生成（NLG）是指计算机根据一些数据输入生成人类语言文本的响应。</p><p>通过利用 NLP 技术，开发人员可以从文本数据中提取信息和洞见，使机器能够理解和响应人类查询，并将所有涉及语言处理的任务自动化。可以说，NLP 使人机交互过程更直观、高效和流畅。NLP 在现实世界中有众多应用，如虚拟助手、聊天机器人、信息检索系统、语言翻译服务、情感分析工具和自动化内容生成等。而向量数据库，尤其是其高效的 embedding 向量存储和检索能力能够为 NLP 领域带来革新，简化相似文档或短语的搜索过程。</p><h2>02.NLP 用例</h2><p>开发人员可以使用 NLP 构建多种应用，包括：</p><h3>情感分析</h3><p>情感分析是指确定文本中表达的情感或情绪。情感分析涉及将文本分类为正面、负面或中性。情感分析技术可能使用机器学习算法在标记数据集上训练模型，或利用预训练模型捕捉单词和短语的情感。情感分析常见的场景之一是电影评论分类，可以统计出正负面的影评占的比例。</p><h3>信息提取</h3><p>信息提取是指从文本中识别特定信息，例如提取名称、日期或数值。信息提取使用命名实体识别（NER）和关系提取从非结构化文本中提取结构化数据。</p><h3>机器翻译</h3><p>NLP 通过利用统计或神经网络机器翻译模型实现机器翻译。这些模型从大量平行文本数据中学习语言之间的模式和关系，允许它们适当借助上下文将文本从一种语言翻译成另一种语言。</p><h3>问答系统</h3><p>问答系统使用 NLP 技术理解用户问题并从给定的文本语料库中检索相关信息。问答系统包含文本理解、文档检索和信息提取等步骤，为用户提供准确和相关的查询答案。</p><h3>虚拟助手或聊天机器人</h3><p>虚拟助手是诸如 Alexa 或 Siri 这样的产品，它们接收人类的话语并从人类语言中推导出命令从而触发动作。（例如：嘿，Alexa，打开灯！）。聊天机器人使用书面语言与人类互动，从而协助用户处理账户或账单问题或其他一般问题。在完成文本处理后，聊天机器人就可以遍历决策树从而做出正确的操作。</p><h3>文本生成</h3><p>NLP 模型可以基于给定的提示或输入生成文本。这包括语言建模、文本摘要和使用诸如循环神经网络（RNN）或 Transformer 模型等技术的文本生成等任务。</p><h3>垃圾邮件检测</h3><p>自然语言处理可以辅助垃圾邮件检测。例如，通过查看过度使用的单词、错误的语法或不适当的紧急声明，检查电子邮件的内容以确定它是否是垃圾邮件。</p><h2>03.NLP 原理</h2><p>NLP 是指通过一系列技术和算法，使计算机能够处理、理解和生成人类语言。以下是 NLP 工作流程：</p><p>文本预处理—— NLP 的初始步骤通常是文本数据的预处理。预处理涉及诸如分段（将句子分解为组成词）、token 化（将文本分割为单个单词或 token）、停用词（去除像停用词和普通词如「the」或「is」这样不携带太多含义的标点）以及应用词干提取（为给定标记推导词干）或词形还原（从字典中获取标记的含义以得到根源）以将单词还原为其基本形式的任务。</p><p>语言理解—— NLP 算法使用各种技术来理解文本的含义和结构。这些技术包括：词性标注（通过为每个单词分配语法标签进行语法分析）、句法解析（分析句子结构）和命名实体识别（识别和分类命名实体，如人物、组织、地点或流行文化参考）等任务。</p><p><em>「观其伴而知其意（You shall know a word by the company it keeps）」</em></p><p>-- 英国语言学家 J. R. Firth</p><h2>04.NLP 模型</h2><p>在大型数据集上接受训练以执行特定 NLP 任务的深度学习模型被称为 NLP 的预训练模型（PTM），它们可以通过避免从头开始训练新模型来帮助下游 NLP 任务。以下是一些著名的自然语言处理模型，以便模型更准确地执行：</p><ul><li><p>BERT（Bidirectional Encoder Representations from Transformer） 是由 Google 开发的自然语言处理模型，可学习文本的双向表示。</p></li><li><p>XLNet 是 CMU 和 Google Brain 团队在 2019 年 6 月份于论文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1906.08237" target="_blank">《XLNet: Generalized Autoregressive Pretraining for Language Understanding》</a>发布的模型。</p></li><li><p>RoBERTa 是 2019 年在论文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1907.11692" target="_blank">《RoBERTa: A Robustly Optimized BERT Pretraining Approach》</a>中被提出的。</p></li><li><p>ALBERT 模型来自 Google 2019 年公布的论文《ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS》。</p></li><li><p>StructBERT 是阿里对 BERT 的一个改进，于 2019 年在论文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1908.04577" target="_blank">《StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding》</a>中提出。</p></li><li><p>PaLM 2 是下一代大语言模型，已经过大量数据训练，能够预测人类输入后的下一个单词。</p></li><li><p>GPT-4 是 OpenAI 开发的多模态大语言模型。它是 GPT 系列中的第四个模型，以其强大的自然语言生成能力而闻名。</p></li><li><p>SentenceTransformers 是一个用于句子、文本和图像 Embedding 的 Python 框架，最初于论文《Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks》中提出。</p></li></ul><h2>05.Zilliz 如何赋能 NLP？</h2><p>开发者正在使用向量数据库革新 NLP 领域。向量数据库能够有效存储和检索 NLP 模型生成的 Embedding <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fglossary%2Fembedding-%25E5%2590%2591%25E9%2587%258F" target="_blank">向量</a>，简化了基于语义相似性寻找相似文档、短语或甚至单个词的过程。此外，使用向量数据库后，开发者可以快速总结 Collection 文档。使用 NLP 算法可以从文本语料库中提取最重要的句子，然后借助 Milvus 便可找到与提取的短语语义上最相似的短语。</p><p>另一个广泛的向量数据库 + NLP 用例就是检索增强生成（Retrieval Augmented Generation，RAG）。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fuse-cases%2Fllm-retrieval-augmented-generation" target="_blank">RAG</a> 通常以聊天机器人的形式出现。大语言模型仅基于公开可用的数据进行训练。因此，它们可能缺乏特定领域知识或者私有信息。开发者可以在 LLM 之外的向量数据库中存储特定领域的数据，进行相似性搜索以返回与用户提问相关的 top-K 结果。最终将这些结果合并发送至 LLM，使其生成准确的答案。</p><h2>06.总结</h2><p>使用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fblog%2Fvectordatabase-introduction-milvus" target="_blank">向量数据库</a>，尤其是其高效的 embedding 向量存储和检索能力能够为 NLP 领域带来革新，简化相似文档或短语的搜索过程。NLP 结合了人工智能和计算语言学，帮助计算机理解并响应人类语言，其应用场景广泛，包括虚拟助手、聊天机器人、翻译服务和情感分析等。诸如 BERT、XLNet、RoBERTa、ALBERT 和 GPT-4 之类的 NLP 模型和 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzilliz.com.cn%2Fcloud" target="_blank">Zilliz Cloud</a> 之类的向量数据库能够进一步增强 NLP，简化基于语义相似性检索相似文档或短语的过程。</p><hr><ul><li><p>如果在使用 Milvus 或 Zilliz 产品有任何问题，可添加小助手微信 「zilliz-tech」 加入交流群。</p></li><li><p>欢迎关注微信公众号「Zilliz」，了解最新资讯。</p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 11:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10149535</guid>
            <link>https://my.oschina.net/u/4209276/blog/10149535</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AWebSocket - 基于 OkHttp 封装的 WebSocket]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:left">AWebSocket for Android 一个基于 okhttp 封装的<span>&nbsp;</span><strong>WebSocket</strong>，简洁易用。</p><h2 style="margin-left:0; margin-right:0; text-align:left">Gif 展示</h2><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><img alt="" height="581" src="https://oscimg.oschina.net/oscnet/up-ecbee904460eb28c99bfb586b530b5bbefd.gif" width="300" referrerpolicy="no-referrer"></p><blockquote>&nbsp;</blockquote><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">你也可以直接下载<span>&nbsp;</span><a href="https://gitee.com/link?target=https%3A%2F%2Fraw.githubusercontent.com%2Fjenly1314%2FAWebSocket%2Fmaster%2Fapp%2Frelease%2Fapp-release.apk">演示 App</a><span>&nbsp;</span>体验效果</p><h2 style="margin-left:0; margin-right:0; text-align:left">引入</h2><h3 style="margin-left:0; margin-right:0; text-align:left">Gradle:</h3><ol><li><p style="margin-left:0; margin-right:0">在 Project 的<span>&nbsp;</span><strong>build.gradle</strong><span>&nbsp;</span>或<span>&nbsp;</span><strong>setting.gradle</strong><span>&nbsp;</span>中添加远程仓库</p><div><div><pre><span><strong style="color:#000000">repositories</strong><span>{</span></span><span><span style="color:#888888">//...</span></span><span><span>mavenCentral</span><span>()</span></span><span><span>}</span></span></pre><div style="text-align:center">&nbsp;</div></div></div></li><li><p style="margin-left:0; margin-right:0">在 Module 的<span>&nbsp;</span><strong>build.gradle</strong><span>&nbsp;</span>里面添加引入依赖项</p><div><div><pre><span><span>implementation</span><span style="color:#dd1144">'com.github.jenly1314:awebsocket:1.0.0'</span></span></pre></div></div></li></ol><h2 style="margin-left:0; margin-right:0; text-align:left">使用</h2><h3 style="margin-left:0; margin-right:0; text-align:left">主要使用示例</h3><div style="text-align:left"><div><pre><span><span style="color:#888888">//初始化 AWebSocket</span></span><span><strong>val</strong><strong style="color:#336699">aWebSocket</strong><span>=</span><strong style="color:#445588">AWebSocket</strong><span>(</span><span>url</span><span>)</span></span><span><span style="color:#888888">// 设置监听</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">setWebSocketListener</strong><span>(</span><strong>object</strong><span style="background-color:#ffadad; color:#a61717">: </span><strong style="color:#445588">WebSocketListener</strong><span>()</span><span>{</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onOpen</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>response</span><span>:</span><strong style="color:#445588">Response</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onOpen</strong><span>(</span><span>webSocket</span><span>,</span><span>response</span><span>)</span></span><span><span style="color:#888888">// TODO 连接成功，可以进⾏通信了</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>text</span><span>:</span><strong style="color:#445588">String</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>,</span><span>text</span><span>)</span></span><span><span style="color:#888888">// TODO 接收消息</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>bytes</span><span>:</span><strong style="color:#445588">ByteString</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onMessage</strong><span>(</span><span>webSocket</span><span>,</span><span>bytes</span><span>)</span></span><span><span style="color:#888888">// TODO 接收消息</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onClosing</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>code</span><span>:</span><strong style="color:#445588">Int</strong><span>,</span><span>reason</span><span>:</span><strong style="color:#445588">String</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onClosing</strong><span>(</span><span>webSocket</span><span>,</span><span>code</span><span>,</span><span>reason</span><span>)</span></span><span><span style="color:#888888">// TODO 连接关闭中</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onClosed</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>code</span><span>:</span><strong style="color:#445588">Int</strong><span>,</span><span>reason</span><span>:</span><strong style="color:#445588">String</strong><span>)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onClosed</strong><span>(</span><span>webSocket</span><span>,</span><span>code</span><span>,</span><span>reason</span><span>)</span></span><span><span style="color:#888888">// TODO 连接已关闭</span></span><span><span>}</span></span><span><strong style="color:#000000">override</strong><strong style="color:#000000">fun</strong><strong style="color:#990000">onFailure</strong><span>(</span><span>webSocket</span><span>:</span><strong style="color:#445588">IWebSocket</strong><span>,</span><span>t</span><span>:</span><strong style="color:#445588">Throwable</strong><span>,</span><span>response</span><span>:</span><strong style="color:#445588">Response</strong><span>?)</span><span>{</span></span><span><strong style="color:#000000">super</strong><span>.</span><strong style="color:#990000">onFailure</strong><span>(</span><span>webSocket</span><span>,</span><span>t</span><span>,</span><span>response</span><span>)</span></span><span><span style="color:#888888">// TODO 连接出错</span></span><span><span>}</span></span><span><span>})</span></span><span><span style="color:#888888">// 连接</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">connect</strong><span>()</span></span><span><span style="color:#888888">//---------------------------</span></span><span><span style="color:#888888">//...</span></span><span><span style="color:#888888">// 发送消息</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">send</strong><span>(</span><span>data</span><span>)</span></span><span><span style="color:#888888">//---------------------------</span></span><span><span style="color:#888888">//...</span></span><span><span style="color:#888888">// 关闭连接</span></span><span><span>aWebSocket</span><span>.</span><strong style="color:#990000">close</strong><span>()</span></span></pre></div></div><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">更多使用详情，请查看<a href="https://gitee.com/jenly1314/AWebSocket/blob/master/app">Demo</a>中的源码使用示例或直接查看<a href="https://gitee.com/link?target=https%3A%2F%2Fjitpack.io%2Fcom%2Fgithub%2Fjenly1314%2FAWebSocket%2Flatest%2Fjavadoc%2F">API 帮助文档</a></p><h3 style="margin-left:0; margin-right:0; text-align:left">相关推荐</h3><p style="margin-left:0px; margin-right:0px; text-align:left"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fjenly1314%2FANetty">ANetty</a><span>&nbsp;</span>基于 Netty 封装的 Android 链路通讯库，用以快速开发高性能，高可靠性的网络交互。在保证易于开发的同时还保证其应用的性能，稳定性和伸缩性。</p><p style="margin-left:0px; margin-right:0px; text-align:left"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fjenly1314%2FASocket">ASocket</a><span>&nbsp;</span>一个 TCP/UDP 协议的封装库，方便快速实现 TCP 的长连接与 UDP 的单播、组播、广播等相关通信。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 10:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/awebsocket</guid>
            <link>https://www.oschina.net/p/awebsocket</link>
        </item>
        <item>
            <title>
                <![CDATA[假如你是开源项目维护者，遇到这种回复能忍到哪步？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>背景：</p><p>Vant 是一个轻量、可定制的移动端组件库，由有赞团队开源。近日，一名开发者在 Vant 的 GitHub 仓库提交了一个 issue：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyouzan%2Fvant%2Fissues%2F12453" target="_blank">https://github.com/youzan/vant/issues/12453</a></u></em>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d12cf1220dd6a3686fc370d6999fa3ad16f.png" referrerpolicy="no-referrer"></p><hr><p>直奔主题，请阅读这名开发者与维护者的问答互动：</p><p>Vant 维护者对该 issue 先是进行了如下回复：</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-9b703d704225830325c310edc6473fdd774.png" referrerpolicy="no-referrer"></p></blockquote><p>提问者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-e6c785757085efeac52ec4017730e405587.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-6b53e369e0f7047d703165ef2353d69ef98.png" referrerpolicy="no-referrer"></p><p>提问者（询问项目维护者这到底是不是 bug）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a454d0c5ff658f495c0a716bfa806fea64.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img height="296" src="https://oscimg.oschina.net/oscnet/up-2d3f37ca3537caa4910f618b2ac40813283.png" width="1684" referrerpolicy="no-referrer"></p><p>提问者（没得到自己想要的答案，开始阴阳怪气）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-7548ef7e9f27dbe02d902b21a805d3c2b83.png" referrerpolicy="no-referrer"></p><p>项目维护者（准备到此为止）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-cfa1f12f75fcdcc6f4445236b19400921df.png" referrerpolicy="no-referrer"></p><p>提问者继续追问：</p><p><img src="https://oscimg.oschina.net/oscnet/up-2ac7c06681f933d411c766346ba126c3860.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-717a1ca2200a63fe14ace932a3754887966.png" referrerpolicy="no-referrer"></p><p>提问者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-30cdb4ece4857089a0c6033e18b4d439231.png" referrerpolicy="no-referrer"></p><p>项目维护者：</p><p><img src="https://oscimg.oschina.net/oscnet/up-945eaa18e070e9c15264da20b49d0cd9978.png" referrerpolicy="no-referrer"></p><p>最后一个来回：</p><p><img src="https://oscimg.oschina.net/oscnet/up-7617f52c138888233e08e5aedb53a49a012.png" referrerpolicy="no-referrer"></p><p>然后，这名提问者去社区发帖分享了「一次 github 跟开源大佬的抬杠经历」。</p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv2ex.com%2Ft%2F993100" target="_blank">https://v2ex.com/t/993100</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 07:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267411</guid>
            <link>https://www.oschina.net/news/267411</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LineageOS 全球安装量达 150 万台]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LineageOS 团队日前在知名数码 UP 主 MKBHD 播客中回顾了 LineageOS 的历史，<strong>并介绍称目前全球有 150 万台 Android 设备采用 LineageOS</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-45aadd76321a77a1392775596a7127e39cd.png" referrerpolicy="no-referrer"></p><p>LineageOS 是一个面向智能手机和平板电脑的自由、免费、开源的 Android 系统分支。它是深受欢迎的定制 ROM CyanogenMod 的继任者，在 2016 年首次推出，至今仍在积极更新。</p><p>LineageOS 可在不同 Android 品牌的各种不同设备上使用，包括谷歌、HMD Global、三星、索尼、一加、小米等，这款&nbsp;ROM&nbsp;也让一些久远的品牌继续前行，例如早期的 Essential Phone、LG 等。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 07:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267410</guid>
            <link>https://www.oschina.net/news/267410</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[基于 Triple 实现 Web 移动端后端全面打通]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><h1 style="line-height: 1.75em;margin-bottom: 8px;" data-mpa-powered-by="yiban.io"><img class="rich_pages wxw-img" data-backh="81" data-backw="578" data-ratio="0.14106583072100312" src="https://oscimg.oschina.net/oscnet/c03fcfd2-fd29-4f40-8a8b-fbc8acf7f63e.gif" data-w="638" style="outline: 0px;display: initial;visibility: visible !important;width: 677px !important;" referrerpolicy="no-referrer"></h1><section style="margin-bottom: 40px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 14px;">作者：陈有为，陌陌研发工程师、Apache Dubbo PMC</span></em></span></section><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">01</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">RPC 协议开发微服务</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Aliware</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/11f88a4a-39b5-4f5e-9496-4101a228839b.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">在我们正常开发微服务的时候，传统 RPC 服务可能在最底层。上层可能是浏览器、移动端、外界的服务器、自己的测试、curl 等等。我们可能会通过 Tomcat 这种外部服务器去组装我们的 RPC 层，也就是 BFF。或者我们没有 BFF，我们的 RPC 就是对外提供服务。但因为浏览器要访问，所以我们需要有一个网关，比如说 APISIX 或者 ShenYu 等 HTTP 网关。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/79eae4dd-4c7e-45d4-b382-3b7e0fbd8e7a.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">上图展示的是我们的流程，但是存在一些问题。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">如果我们的服务是非常轻的，我们只需要一个转发层，无论是配网关还是起一个 webserver 去转发，怎么做都很麻烦。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">此外，RPC 服务大部分都是基于二进制的，而二进制正常在本地是没法测试的。因此我们的公司内都可能就会开发一种后台或者中间的 Proxy 代理让我们去测试。但这个的前提是你至少得把它部署到测试环境，所以还是没法在本地测试。</span><o:p></o:p></section><p style="line-height: 1.75em;margin-bottom: 40px;"><span style="font-size: 15px;">总体来说，这两个问题会导致易用性比较低，且开发成本相对较高，因为要做一些与业务无关的重复劳动。</span></p><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">02</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">全新升级的 Triple 协议</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Apache Dubbo</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;"></span><o:p></o:p></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/601481f3-b469-46d3-a9e5-6bd230a68166.png" data-type="png" data-w="832" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;" referrerpolicy="no-referrer"><br></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">基于上边的两个问题，我们来介绍一下 Triple 协议。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">先来说一下上一代协议，它产出的原因是什么。我们应该都知道 Dubbo 原来是 Dubbo 协议，它是基于 tcp 的，它只有一个包。因为它的包的设计，导致了网关无法做一些特殊规则判断、过滤等操作。但也不是绝对的，如果你愿意牺牲性能把包完全解出来，组装回去再透传还是可以做到的，但一般大家都不太能接受。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">所以我们就在想能不能把原数据和真正的包分开。现在我们有现成的 HTTP，又有一个业界主流的 gRPC，所以我们的目标就是兼容 gRPC。因为 gRPC 目前都是用 IDL，而 IDL 有一个问题，尤其在 Java 侧。因为大家都是写一些接口，定义一些包去实现，这样就会非常麻烦。Go 侧就还好，因为大家已经习惯了这种开发模式。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">所以我们开发了 Triple 协议，<strong>首先它兼容了 gRPC，</strong>所以我们能实现和 gRPC 的完全互通。<strong>其次，我们兼容了自己定义接口的方法。</strong>虽然会损失一定的性能，但提升了一些易用性。而且 RPC 一般不是业务的瓶颈，大多数瓶颈还是在 DB。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">但还有个问题，虽然我们兼容了 gRPC，但 gRPC 是基于 TPC 的，所以如果前端或者其他第三方系统只有 HTTP，它还是接受不了我们的系统。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/979f4ac2-7a4e-423f-9b1b-b4073e2170ac.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;text-align: left;margin-bottom: 24px;"><span style="font-size: 15px;">基于此，我们想推出一个全新的 Triple 协议。为了解决上述的所有问题，我们参考了 gRPC、gRPC Web、通用 HTTP 等多种协议，做到浏览器访问，支持&nbsp; Streaming，还支持同时运行在 HTTP/1、HTTP/2 协议上。因为目前 HTTP/3 还没有大规模推广，未来也会支持 HTTP/3。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><strong><span style="font-size: 15px;">最终的设计实现是完全基于 HTTP 的，且对人类、开发调试友好。</span></strong><span style="font-size: 15px;">我们可以通过简单的浏览器访问或者 curl 访问，尤其是对 unary RPC。此外，我们和 gRPC 是完全互通的，用 HTTP 的业务不用担心兼容性的问题，也不用担心签协议的问题。为了稳定性，我们只会采用业界流行的网络库，比如 Java 的 native、Go 的基础的 net 包。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/2096d161-0996-43b9-a7ae-13dc12461acf.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;text-align: left;margin-bottom: 24px;"><span style="font-size: 15px;">虽然 Triple 协议和 gRPC 协议都基于 HTTP，但 gRPC 是基于 HTTP/2 的，而 Triple 是基于 HTTP/1 和 HTTP/2 的。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">我们在兼容 gRPC 的同时，我们为了易用性也扩展了一些功能。比如请求里我们支持 Application/Json 的请求格式，支持使用 curl 访问；</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">此外上一版的协议，为了支持传统定义接口的方式，我们有一个二次序列化的过程。我们想在这里通过一个特殊的 content type 来决定我们的 body 的结构，解决二次序列化的问题。同时这个东西是可以扩展的，理论上 HTTP 的所有功能我们在 Triple 协议上都可以实现，也可以拓展。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/df1f6c58-13f2-46f7-be3b-a518882ec9b4.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">用了 Triple 协议之后，我们的开发流程也发生了改变。如果你不需要进行组装，或者没有外层的代理，可能你的接入流程就是从外部的请求浏览器、对方的服务器、curl、自己测试等直接到了 server。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">和其他的 gRPC 的通信也是没有问题的，流程就相当于少了一层。对于大多数用户，如果你不需要这个场景，其实是有很大的好处。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/fbad75ed-0049-4471-83cb-525e33e0e7d0.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;text-align: left;margin-bottom: 24px;"><span style="font-size: 15px;">Triple 协议因为最开始兼容 gRPC，那个时候只基于 HTTP/2，HTTP/2 有 Streaming 的能力，所以它天然支持 Streaming。但这里比较特殊的是，我们新版的协议在 HTTP/1 也支持了 Stream，但因为 HTTP/1 的限制只能支持到 Server Streaming。依赖 HTTP/1 的 Server Push 实现。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/3fc79407-e890-4793-a290-6b9f3bc67dd8.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><p style="line-height: 1.75em;margin-bottom: 40px;"><span style="font-size: 15px;">Client Stream 和 Bi Stream 就没什么可说的了。但有一个特别的是，在 Java 侧没有 Bi Stream，从编码上就没有，但从实现上是有的。</span><o:p></o:p></p><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">03</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">Triple 协议开发微服务</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Apache Dubbo</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/e6931bb8-79f4-4cee-91b6-d5d690516fc9.png" data-type="png" data-w="832" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;" referrerpolicy="no-referrer"><br></section><section style="line-height: 1.75em;margin-bottom: 24px;"><strong><span style="font-size: 15px;">目前 Triple 协议比较灵活的支持两种定义方式，分别是 IDL 定义和直接定义。</span></strong><span style="font-size: 15px;">直接定义支持同步、异步、手写。还有比较极端一点的，比如在自己定义接口的时候使用 IDL 生成 protobuf 的类，我们不定义它的 service，只用它的生成的 request 和&nbsp; response 类也是没问题的，Triple 协议会自动识别接口使用 protobuf 还是不使用 protobuf 进行传输。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/5ff5bab2-f311-4755-830d-b20806c7cf14.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Server 就是把它的务实现一下。上图是一个例子，我就直接拿了 API 的组装方式，真正的业务上可能是注解或者 XML 的方式。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/ce5be064-8661-47b0-a30b-78efa617ab67.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">因为我们支持了 HTTP 这个标准的协议，理论上我们的测试就会变得很简单。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">因为我们支持 gRPC，所以我们可以用 gRPC curl 去调用我们的服务。但前提是你得有反射服务，然后手动开启一下，它不是默认开启的。然后它就可以通过反射拿到接口的源数据，通过 Json 转成 protobuf 格式发过去。或者我们直接用 Application/Json 的方式直接调过去。这里有一点比较特别的是在 HTTP/1 下我们也可以用 Sreaming。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">另外，因为我们支持 HTTP，理论上所有第三方的 HTTP 客户端都是可以调用的。然后使用 Dubbo 的 Admin 也可以进行测试，前提是你得把它注册上。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/59b1ddfb-d5b9-492f-b5be-19d98ac1becb.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">调用端不管是 POJO 还是 IDL，它们都没有本质的区别。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/7915eb90-8133-4eac-a8a9-d6ed2e3e85c5.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><p style="line-height: 1.75em;margin-bottom: 40px;"><span style="font-size: 15px;">现在我们有了 Triple 协议，但如果这个协议没有承载方也是行不通的。<strong>因此我们还得有一个框架，有一些服务治理才是我们的微服务。</strong>所以服务治理也是微服务中不可或缺的一部分。</span><o:p></o:p></p><section data-role="title" data-tools="135 编辑器" data-id="106625" mpa-from-tpl="t" style="margin-bottom: 0px;outline: 0px;"><section mpa-from-tpl="t" style="margin: 10px auto;outline: 0px;text-align: center;"><section mpa-from-tpl="t" style="outline: 0px;display: inline-block;"><section mpa-from-tpl="t" style="padding-right: 7px;padding-left: 7px;outline: 0px;display: flex;justify-content: center;align-items: flex-end;"><section mpa-from-tpl="t" style="outline: 0px;font-size: 28px;letter-spacing: 1.5px;color: rgb(255, 255, 255);font-style: italic;text-shadow: rgb(255, 85, 50) 1px 1px 0px;line-height: 25px;"><strong mpa-from-tpl="t" style="outline: 0px;">04</strong></section><section data-brushtype="text" hm_fix="343:395" mpa-from-tpl="t" style="margin-left: 15px;outline: 0px;font-size: 16px;letter-spacing: 1.5px;color: rgb(242, 98, 46);"><p style="outline: 0px;vertical-align: inherit;line-height: normal;"><em style="caret-color: red;"><strong style="outline-style: initial;">Dubbo 为 Triple 协议带来治理能力</strong></em></p></section></section><section data-width="100%" data-role="list" mpa-from-tpl="t" style="margin-top: 6px;outline: 0px;width: 100%;height: 6px;background-color: rgba(245, 224, 179, 0.8);opacity: 0.51;"><p style="outline: 0px;vertical-align: inherit;"><span style="outline: 0px;font-size: 14px;"><em style="outline: 0px;"><span style="outline: 0px;color: rgb(165, 165, 165);">Apache Dubbo</span></em></span></p></section></section></section></section><section style="line-height: 1.75em;margin-top: 40px;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/31ad4bc8-c9e8-44c6-be77-ee023944fbba.png" data-type="png" data-w="832" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;" referrerpolicy="no-referrer"><br></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Triple 的定位只是 Dubbo 里的其中一个协议，当然你也可以为了兼容性，用原来的 Dubbo 协议或者其他的协议。而且我们支持在同一个端口上开启多个协议，可以按需选择。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/72e291fc-3bce-4ba4-9b31-bd339eca8655.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">同时 Dubbo 为 Triple 提供了多语言的实现。目前会在 Rust、Go、Java、JS、node、Python 这几部分实现官方的实现。这样用户就不用自己根据实验协议的 spec 去实现了。如果你有一些定制需求，比如内部的一些框架，你根据 spec 实现也是可以的。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/f151c36d-888d-4ca4-b78d-c84b36bae333.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Dubbo 和服务框架集成的很好，理论上在开发流程中，尤其是在 Java 侧服务定义、服务治理、服务注册发现等都不用客户来操心，<strong>是开箱即用的。</strong></span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/e615a1a8-d7bb-4f79-b638-1d3b1fc109d6.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">Dubbo 提供了丰富的生态，第三方的生态包括 Nacos、Zookeeper 等等，我们不用创新，直接引入相应的包即可。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/08125323-87f5-4957-bf1f-d44ba434892c.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">这是我们使用 Triple 协议服务注册的例子。上面你可以选 Nacos、Zookeeper、K8s，左边是一个 Client 和一个 Server，这么调用。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/67f6ea46-946c-46a0-a6e4-64776c71c3a6.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 24px;"><span style="font-size: 15px;">我们在 admin 上看一下实现。这里提一句，我们的 admin 也在新版重构，是用 Go 实现的，大家可以期待一下。</span><o:p></o:p></section><section style="line-height: 1.75em;margin-bottom: 24px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.5625" data-s="300,640" src="https://oscimg.oschina.net/oscnet/8bbb56ce-98c2-42b0-91d9-54c1b7a18255.png" data-type="png" data-w="832" style="" referrerpolicy="no-referrer"></section><section style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">我们经常会遇到灰度发布或者流量染色的需求。我们可以从 admin 上发一个 tag 治理规则下去，然后把一些实例打上 tag，然后这个携带 tag 的流量就从入口就会挨个传递下去，从而实现全链路的流量染色。</span><o:p></o:p></section><p style="display: none;margin-bottom: 24px;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Apache Dubbo（ApacheDubbo）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 04:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6214966/blog/10116068</guid>
            <link>https://my.oschina.net/u/6214966/blog/10116068</link>
            <author>
                <![CDATA[ApacheDubbo]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中国操作系统调研]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" height="566" src="https://static.oschina.net/uploads/space/2023/1121/112104_Mhtw_3820517.jpg" width="400" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.qq.com%2Fsheet%2FDQ2hmWHpJdk1WYUl3%3Ftab%3DBB08J2" target="_blank">https://docs.qq.com/sheet/DQ2hmWHpJdk1WYUl3?tab=BB08J2</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 03:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267381</guid>
            <link>https://www.oschina.net/news/267381</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[小米 2023Q3 财报：总收入 709 亿，研发支出 50 亿]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">小米 2023 Q3 财报现已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FopJuLdveNeZPOCiYcNAHkw" target="_blank">公布</a>：总收入 709 亿元，本季重回正增长。经调整净利润 60 亿元，同比增 182.9%。智能电动汽车等创新业务投入 17 亿元。小米持续大规模投入底层核心技术，Q3 研发支出 50 亿元，同比增长 22.0%，研发人员占比已超过 53%。</span></p><p><span style="color:#000000">雷军表示：「作为一家科技公司，小米始终将'技术为本'列为铁律，我们下定决心大规模研发底层核心技术，坚定不移投入其中。我们有充足的现金储备来支持持续创新，本季度末，小米现金总储备达人民币 1276 亿元，又一次创下新高。」</span></p><p><span style="color:#000000">公告指出，本季度小米研发支出人民币 50 亿元，同比增长 22.0%。该公司还计划五年之内（2022-2026）将投入研发 1000 亿元人民币。人才梯队方面，截至第三季度末，小米的工程师人数占比已经超过了 53%。小米的新十年目标（2020-2030）为：大规模投入底层核心技术，致力成为全球新一代硬核科技引领者。</span></p><p><span style="color:#000000">小米智能手机业务在本季度重回增长，全球市占率达 14.1%，连续 3 个季度环比提升。全球智能手机出货量为 4180 万台，同比增长 4.0%，环比增长 27.0%。IoT 业务实现了收入和毛利率的同步增长。Q3 IoT 与生活消费产品收入达到人民币 207 亿元，同比增长 8.5%，毛利率则创下历史新高，达到 17.8%，同比提升 4.3 个百分点。</span></p><p><span style="color:#000000">互联网业务总收入达人民币 78 亿元，创历史新高，毛利率为 74.4%，同比提升 2.3 个百分点。广告收入创下历史新高，达人民币 54 亿元；游戏业务连续 9 个季度实现收入同比增长，达人民币 11 亿元。境外互联网业务本季度收入达到人民币 23 亿元，同比增长 35.8%，占整体互联网收入的比例为 30.0%，同比提升 5.8 个百分点。</span></p><p><span style="color:#000000">本季度，小米全球 MIUI 月活用户达 6.23 亿，同比增长 10.5%；中国大陆 MIUI 月活用户达 1.52 亿，同比增长 7.4%。</span></p><p><span style="color:#000000"><img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-84bfe07342c57c14fda453f243618d607d5.jpg" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="400" src="https://oscimg.oschina.net/oscnet/up-24b5b3d9caa05b951e0825aed1626215466.png" width="300" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267376</guid>
            <link>https://www.oschina.net/news/267376</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Zadig 推出环境睡眠，平均节省一半测试资源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:center"><img alt="" height="386" src="https://oscimg.oschina.net/oscnet/up-27ced375dc5b1beb469bf36b2afaa8b1994.png" width="902" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247491064%26idx%3D1%26sn%3D4bbe7bfe944feaa8b44a08e6156e04e2%26chksm%3Dcfb45158f8c3d84e40d44d2dd9228a844b9bcdeea1fe32a7b0ae41b9af982c11319a38f6675e%26token%3D481744823%26lang%3Dzh_CN%23rd" target="_blank">阅读原文</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig" target="_blank">Zadig 在 Github</a>&nbsp;/&nbsp;<a href="https://gitee.com/koderover/zadig">Zadig 在 Gitee</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><strong>推荐阅读：</strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490415%26idx%3D1%26sn%3D1914c7fd25aac5d33b98663571bbb744%26chksm%3Dcfb457cff8c3ded9c02809aad88012fa802eac55222eebe70b8c637ca2c86a101045aa81e73a%26scene%3D21%23wechat_redirect" target="_blank">是时候和 Jenkins 说再见了</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490637%26idx%3D1%26sn%3D6e0498b37fb15f8b8903c4997e5611d8%26chksm%3Dcfb450edf8c3d9fb758d691081f09fd85d91dbb17534ba9c18c2300725462d3806581efbd237%26scene%3D21%23wechat_redirect" target="_blank">Zadig vs. Jenkins 详细比对：时代的选择与开发者之选</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247489682%26idx%3D1%26sn%3Df4ac5ceb38547542061477a45d8dc86d%26chksm%3Dcfb45432f8c3dd24b727e0fb6db276b2d63b2751933e63a25b00b9d9fac2dd68efbd2cbd3863%26scene%3D21%23wechat_redirect" target="_blank">平台工程和 AI 时代的新 10 亿开发者</a></p><p style="margin-left:0; margin-right:0">Zadig 起源于环境管理工具，逐渐演变成了全面的云原生 CI/CD 平台，最终成为了综合性的 DevOps 解决方案。社区小伙伴一致赞誉它为「中小型企业的得力助手，大型企业的利器」，它有众多独特优势：</p><p style="margin-left:0; margin-right:0"><span><strong>· 现有服务接入<span style="color:#ff2968">姿势多</span>：</strong></span>无论你的服务定义是 K8s YAML、Helm Chart 还是传统的主机服务，Zadig 都提供了一键接入，实现高效统一的环境治理。</p><p style="margin-left:0; margin-right:0"><span><strong>· 运行时管理<span style="color:#ff2968">能力强</span>：</strong></span>不仅支持环境配置管理，还包括了服务的重启、更新和配置管理功能，同时还为开发者提供了便捷的实时日志查看和容器内调试工具。</p><p style="margin-left:0; margin-right:0"><strong><span>· 多环境管理<span style="color:#ff2968">负担轻</span>：</span></strong>基于一份环境配置，Zadig 能够秒级内创建多套完整的环境，一键复制已有环境到新环境，快速回溯到特定版本的环境，并且利用服务变量功能实现不同环境的个性化配置。</p><p style="margin-left:0; margin-right:0"><strong><span>· 环境更新<span style="color:#ff2968">效率高</span>：</span></strong>支持多服务多环境的并行更新，智能选择空闲环境，避免资源浪费和低效堵塞。</p><p style="margin-left:0; margin-right:0"><strong><span>· 环境<span style="color:#ff2968">资源占用少</span>：</span></strong>自测模式可快速创建仅包含部分服务的子环境，支持开发者快速开发和修改目标服务，从而显著降低团队协作时的多环境使用成本。</p><p style="margin-left:0; margin-right:0"><span>......</span></p><p style="margin-left:0; margin-right:0">过往社区也沉淀了大量的最佳实践供大家参考：</p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247486322%26idx%3D1%26sn%3Dbf80ef6f666a9f4d3baa1d1c43382004%26chksm%3Dcfb447d2f8c3cec4606c0370a2f4f885fbf51b97f1407e38a551a0128163c38dff4818cabe84%23rd" target="_blank">简单极了：Zadig 托管项目支持上千开发者、多业务线、多环境协作</a></p><p style="margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487967%26idx%3D1%26sn%3Dc50e4a2d2543ee5f771c139c85503abd%26chksm%3Dcfb45d7ff8c3d4690690b800f1f5640fac8d92e06465c9e99d7516960ff3d949a3d308c83ba9%23rd" target="_blank">多套环境的数据库隔离，域名访问，差异化配置，香！快解锁！</a></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487915%26idx%3D1%26sn%3D4719546f8f109733324124bd87c908f9%26chksm%3Dcfb45d0bf8c3d41d581db5e3d957feef9a3a121726bbf66b85eb3a82ded4a88fc98836f247da%23rd" target="_blank">写代码 5 分钟，上线 2 小时？就离谱！来用用 Zadig 环境负载均衡</a></span></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487124%26idx%3D1%26sn%3D062f9a269f16ff91e5e578a9f8456c15%26chksm%3Dcfb44234f8c3cb22d68b608c51327c91fcc06e2bb88d1da5d3f4e5237c9dffa1af9f668ee98e%23rd" target="_blank">在星云科技，我们使用 Zadig 实现多环境并行发布，上千次周部署</a></span></p><p style="margin-left:0; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247487033%26idx%3D1%26sn%3D645702bbe3e58b957ea960c4b231d819%26chksm%3Dcfb44299f8c3cb8fc664bb7de920eec0d3e587615b04d49cb59ed1b23fe40b83977068626f88%23rd" target="_blank">谁说 Zadig 只能复制环境？数百微服务一套环境实现高效协作</a></span></p><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c1b0440b31e72d76997ee520ad4540be287.png" referrerpolicy="no-referrer"></p><span id="OSC_h2_1"></span><h2><span style="color:#ff2968"><strong>一、降本增效：推出环境睡眠和唤醒功能</strong></span></h2><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">随着越来越多的企业深度采用 Zadig，我们关注着环境的易用性、变更效率以及维护负担等基础能力，同时积极努力降低环境资源成本。我们明白工程师并非 24 小时都需要使用环境，因此时刻在线的环境会导致资源浪费和企业成本增加。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">在 Zadig 的新版本中，我们引入了环境睡眠/唤醒功能，使环境管理更具智能性。这一功能能够自动缩减应用程序的大小以节省云资源成本。环境睡眠/唤醒适用于多种场景，包括但不限于：</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>1. 日常开发和测试：</strong></span><span>&nbsp;</span>工程师进行自测、联调和集成验收时，根据使用频率，可以轻松设置环境的睡眠和唤醒，以合理利用资源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>2. 不经常迭代的项目：</strong></span><span>&nbsp;</span>对于不经常迭代但仍提供在线服务的项目，需要保留多套完整可验证的开发、测试和预发布环境。通过定期设置睡眠，唤起使用时，可以及时释放资源到公共资源池。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><strong>3. 定时按需控制：</strong></span><span>&nbsp;</span>您可以设置环境的定时睡眠和唤醒，尤其适用于弹性节点资源。例如每天晚上自动睡眠，早上自动唤醒，或者在节假日休息时自动睡眠，工作日自动唤醒，以避免无人使用时仍然占用资源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">这一新功能将使您能够更智能地管理环境，更有效地利用资源，从而降低成本。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-059a61e53b3cb2a2033421b525584d8db96.png" referrerpolicy="no-referrer"></p><span id="OSC_h2_2"></span><h2><span style="color:#ff2968"><strong>二、关于环境使用的成本优化测算</strong></span></h2><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.5)">实际资源取决于应用本身的占用及环境使用频率，Zadig 环境睡眠主张从源头减少浪费。</span></p><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">以一个典型的微服务项目为例，该项目由 5 名前后端工程师协同，包含 10 个 Java 服务，平均资源 Request 1C2G；1 个 vue 前端服务，资源 Request 1C0.5G；项目迭代过程共包含开发环境 2 套，测试环境 1 套，预发环境 1 套。平均每个服务每人每天构建 2 次；构建时长 6 分钟。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>· 正常使用资源消耗：</strong>研发阶段大致需要消耗资源<span>&nbsp;</span><span style="color:#ff2968"><strong>44C82G</strong></span><span>&nbsp;</span>(前端 4C2G，后端 40C80G)。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong>· 配置环境睡眠策略后：</strong>该项目在不同迭代频率下，平均节约<span>&nbsp;</span><strong><span style="color:#ff2968">22C41G</span></strong><span>&nbsp;</span>约一半资源。</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-99d72eb1139570e2b7bf667fd8ddd2d855b.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8452cd8960943c012f669980244501130a7.png" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><img height="1278" src="https://oscimg.oschina.net/oscnet/up-54779359f43a9840cdac2ba5ac23b7e5af5.png" width="2346" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">下面将展开介绍如何配置环境睡眠及效果的展示。</span></p><span id="OSC_h3_3"></span><h3><span style="color:#ff2968">01-</span><span style="color:#ff2968">如何启用环境睡眠能力</span></h3><p>&nbsp;</p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span style="color:rgba(0, 0, 0, 0.5)">前提条件：安装 Zadig v1.7.0 版本，系统中存在正在使用的环境。</span></p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span><strong>•<span>&nbsp;</span></strong></span>安装 Zadig v2.0.0</p><p style="color:#ff7faa; margin-left:0; margin-right:0; text-align:justify"><span><strong>•<span>&nbsp;</span></strong></span>Zadig 环境管理</p><span id="OSC_h3_4"></span><h3><span style="color:#ff2968">02-配置一键睡眠/唤醒</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">进入环境，点击睡眠与唤醒 -&gt; 立即睡眠即可将环境一键睡眠。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a23a8cfb642b3eec757e317f8bf162ebd9d.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9dfbdcb488595269fcafbfe331e1bc7e44.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">需要使用环境时，进入睡眠的环境，点击睡眠与唤醒 -&gt; 立即唤醒即可将环境唤醒恢复可用。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-2ebf5b3eb9aca3d21beba63bb63497d7e17.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_5"></span><h3><span style="color:#ff2968">03-配置定时睡眠/唤醒</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">进入环境，点击睡眠与唤醒 -&gt; 配置定时睡眠和唤醒 Cron 表达式即可。比如，下图示例中每天 22:00 定时睡眠环境，每天 8:00 环境将定时唤醒恢复可用。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-db2e0c10ffc9d063b4a59de5fe8a9d09b0c.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-4f4226bd32cc075241b7d87451ab3fb23be.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_6"></span><h3><span style="color:#ff2968">04-使用效果一览</span></h3><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">睡眠后，环境中所有服务实例副本数将会自动调整为 0，CronJob 会被挂起，节省环境所使用云资源成本。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-45cb0a823997e3471d8dfe59e755369a6aa.png" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p style="margin-left:0; margin-right:0">唤醒后，环境中的所有服务会根据服务编排顺序恢复到睡眠之前的状态。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-d899a41dcd4f828dbfc32a19cfa534dd94c.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h4_7"></span><h4><strong>参考资料</strong></h4><p style="margin-left:0; margin-right:0; text-align:left"><span>[1] 安装 Zadig v2.0.0</span></p><p style="margin-left:0; margin-right:0; text-align:left">https://docs.koderover.com/zadig/Zadig%20v2.0.0/stable/quick-install</p><p style="margin-left:0; margin-right:0; text-align:left"><span>[2] Zadig 环境管理</span>https://docs.koderover.com/zadig/Zadig%20v2.0.0/project/env/k8s</p><p style="margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-187186c2b990f912cf841796017d7e8ce6f.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0px; margin-right:0px"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247491064%26idx%3D1%26sn%3D4bbe7bfe944feaa8b44a08e6156e04e2%26chksm%3Dcfb45158f8c3d84e40d44d2dd9228a844b9bcdeea1fe32a7b0ae41b9af982c11319a38f6675e%26token%3D481744823%26lang%3Dzh_CN%23rd" target="_blank">阅读原文</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig" target="_blank">Zadig 在 Github</a>&nbsp;/&nbsp;<a href="https://gitee.com/koderover/zadig">Zadig 在 Gitee</a></p><p style="color:#333333; margin-left:0px; margin-right:0px"><strong>推荐阅读：</strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490415%26idx%3D1%26sn%3D1914c7fd25aac5d33b98663571bbb744%26chksm%3Dcfb457cff8c3ded9c02809aad88012fa802eac55222eebe70b8c637ca2c86a101045aa81e73a%26scene%3D21%23wechat_redirect" target="_blank">是时候和 Jenkins 说再见了</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247490637%26idx%3D1%26sn%3D6e0498b37fb15f8b8903c4997e5611d8%26chksm%3Dcfb450edf8c3d9fb758d691081f09fd85d91dbb17534ba9c18c2300725462d3806581efbd237%26scene%3D21%23wechat_redirect" target="_blank">Zadig vs. Jenkins 详细比对：时代的选择与开发者之选</a>&nbsp;/&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4NDY0NTMyNw%3D%3D%26mid%3D2247489682%26idx%3D1%26sn%3Df4ac5ceb38547542061477a45d8dc86d%26chksm%3Dcfb45432f8c3dd24b727e0fb6db276b2d63b2751933e63a25b00b9d9fac2dd68efbd2cbd3863%26scene%3D21%23wechat_redirect" target="_blank">平台工程和 AI 时代的新 10 亿开发者</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 21 Nov 2023 02:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/10149325</guid>
            <link>https://my.oschina.net/koderover/blog/10149325</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云原生周刊：Istio 1.20.0 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Floft-sh%2Fdevpod" target="_blank">DevPod</a></h3><p>DevPod 是一款纯客户端工具，可在任何后端基于 devcontainer.json 创建可重现的开发人员环境。每个开发者环境都在一个容器中运行，并通过 devcontainer.json 进行指定。通过 DevPod 提供商，这些环境可以在任何后端创建，如本地计算机、Kubernetes 集群、任何可访问的远程机器或云中的虚拟机。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFairwindsOps%2Fgemini" target="_blank">Gemini</a></h3><p>Gemini 是用于管理卷快照的 Kubernetes CRD 和 operator。可以定期为 PersistentVolumes 上的数据创建快照，清空旧快照，并以最少的停机时间恢复快照。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fr0binak%2FMTKPI" target="_blank">MTKPI</a></h3><p>MTKPI - 多工具 Kubernetes 渗透测试镜像。该 docker 映像包含 Kubernetes 渗透测试所需的所有最常用工具。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-alert-and-monitoring-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 个最佳告警和监控工具</a></h3><p>这篇文章介绍了针对 Kubernetes 的前五个告警和监控工具。文章指出，Kubernetes 作为容器运行应用程序的首选选择，具有可伸缩性、灵活性和弹性等优势。然而，管理和监控 Kubernetes 可能会相当困难。因此，对于保证应用程序平稳可靠运行的关键是监控和告警。监控和告警是有效运营 Kubernetes 集群的实践方法，它们使您能够收集集群、节点、Pod、容器、服务和应用程序的指标、日志和跟踪数据，并使用仪表板、图表和表格对数据进行可视化和分析。通过规则、阈值和通知对异常、错误、故障和 SLA 违规进行告警，并通过调查根本原因、解决问题或升级到适当的团队来采取行动。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcollabnix.com%2Ftop-5-machine-learning-tools-for-kubernetes%2F" target="_blank">Kubernetes 的 5 大机器学习工具</a></h3><p>这篇文章介绍了在 Kubernetes 上进行机器学习的五个顶级工具。文章介绍了每个工具的特点、优势和使用案例，以及选择这些工具的标准，如功能性、易用性、流行度和创新性。通过使用这些工具，用户可以更轻松地在 Kubernetes 上进行机器学习任务，并提高其工作流程的效率和可靠性。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspacelift.io%2Fblog%2Fkubernetes-deployment-strategies" target="_blank">8 种不同类型的 Kubernetes 部署策略</a></h3><p>这篇文章介绍了 Kubernetes 的八种不同部署策略，包括 Recreating、Rolling、Blue/Green、Canary、A/B、Ramped Slow Rollout、Best-Effort Controlled Rollout 和 Shadow Deployment。它解释了每种策略的优点和用途，帮助读者在应用程序部署和升级时做出明智的选择。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubescape.io%2Fblog%2F2023%2F09%2F19%2Fintroducing-kubescape-3%2F" target="_blank">Kubescape 3.0 发布</a></h3><p>Kubescape 是 CNCF Kubernetes 安全姿态管理工具的下一代，日前发布了 v3.0。</p><p>Kubescape 3.0 新增以下功能：</p><ul><li>将合规性和容器扫描结果存储为 Kubernetes 集群内的资源</li><li>通过命令行界面扫描容器镜像的漏洞</li><li>报告集群中所有镜像的漏洞情况</li><li>全新的概览安全扫描，帮助你为集群安全设置基线</li><li>突出显示高风险工作负载：那些如果受到损害可能造成最大危害的工作负载</li><li>改进的显示输出</li><li>新的基于能力的 Helm chart</li><li>每个工作负载、命名空间和集群的 Prometheus 指标</li><li>通过 Prometheus Alertmanager 进行告警</li><li>将数据发送到集群外的托管服务</li></ul><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.opencost.io%2Fblog%2Faks-cost-analysis" target="_blank">OpenCost 宣布与 Microsoft AKS 成本分析工具集成</a></h3><p>OpenCost 正在与 Microsoft 的新 Azure Kubernetes Service（AKS）成本分析工具集成，以实现使用度量收集。Microsoft Azure 的客户现在可以根据 Kubernetes 特定的结构，原生地了解成本分配的可见性。</p><p>AKS 成本分析是针对标准和高级 AKS 群集的附加组件，向客户提供免费的服务。它直接在 Azure 门户中提供成本分配报告。AKS 客户现在可以轻松地可视化其 Kubernetes 成本分配，作为进一步优化和异常检测的基础。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fistio.io%2Flatest%2Fnews%2Freleases%2F1.20.x%2Fannouncing-1.20%2F" target="_blank">Istio 1.20.0 发布</a></h3><p>Istio 1.20.0 发布，这是 2023 年最后一个 Istio 版本，以下是该版本主要变化：</p><ul><li>网关 API</li><li>改进的外部名称服务支持</li><li>一致的 Envoy 过滤器排序</li><li>对网络 WasmPlugin 的扩展支持</li><li>TCP 元数据交换增强</li><li>插入根证书轮换</li><li>流量镜像现在支持多个目标</li><li>...</li></ul><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 10:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10149219</guid>
            <link>https://my.oschina.net/u/4197945/blog/10149219</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软开源 Terminal Chat]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fcommandline%2Fterminal-chat-in-windows-terminal-canary%2F" target="_blank">宣布</a>开源其 AI 聊天功能 Terminal Chat 的工作，邀请开发人员尝试体验并参与构建。「Windows Terminal 团队致力于提高透明度，我们希望让开源社区有机会帮助我们定义 terminal 应用程序中的人工智能。」</p><p><span style="color:#000000">Terminal Chat 是 Windows Terminal Canary 中的一项功能，允许用户保持在 terminal 上下文中的同时，与 AI 服务聊天以获得智能建议（例如查找命令或解释错误消息）。</span></p><p><img alt="" height="323" src="https://oscimg.oschina.net/oscnet/up-7d85ccd13aaf667d1c3ebcd092187c83cf8.png" width="500" referrerpolicy="no-referrer"></p><p>值得注意的是，Windows Terminal Canary 不提供默认模型或内置 AI 模型。因此要使用 Terminal Chat，用户必须手动在 Windows Terminal Canary 的 Terminal Chat 设置中添加 AI 服务端点和密钥。</p><p>目前，Terminal Chat 仅支持 Azure OpenAI 服务。要获取必要的 Azure OpenAI 服务端点和密钥，用户需要创建和部署 Azure OpenAI 服务资源。</p><p><img alt="" height="337" src="https://oscimg.oschina.net/oscnet/up-3418831b63a1cef6ad618521d5e8e233d0f.png" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="319" src="https://oscimg.oschina.net/oscnet/up-2698239a8126cd25a2f1bab83a5f1c0f605.png" width="500" referrerpolicy="no-referrer"></p><p style="text-align:left"><span><span><span><span><span style="color:#333333"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Windows Terminal Canary 仅在用户发送消息时与 AI 服务进行通信，聊天记录和用户活动 shell 的名称也会附加到发送给 AI 服务的信息中。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>Terminal Chat&nbsp;<span><span><span><span><span style="color:#333333"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>结束后，Windows Terminal Canary 不会保存聊天历史记录。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:left"><span style="color:#000000"><span style="background-color:#ffffff">微软方面表示，他们知道「AI in a terminal」听起来令人生畏，因此他们将致力于提高透明度并积极听取用户反馈。「我们坚信，开源社区的加入将帮助我们确定人工智能路线图，并帮助我们确定可用于核心产品 Windows Terminal 的最基本的 AI 功能集。」</span></span></p><p style="text-align:left"><span style="color:#000000">Terminal Chat&nbsp;<span style="background-color:#ffffff">功能目前仅在 Windows Terminal Canary 中提供，不会包含在 WindowsTerminal 预览版或 Windows Terminal 稳定版的构建中。</span></span></p><p style="text-align:left"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fterminal%23installing-windows-terminal-canary" target="_blank"><span style="color:#2980b9"><span style="background-color:#ffffff">下载地址</span></span></a></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 09:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267428/terminal-chat-in-windows-terminal-canary</guid>
            <link>https://www.oschina.net/news/267428/terminal-chat-in-windows-terminal-canary</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软 CEO：Sam Altman 可能会重返 OpenAI]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Sam Altman 在被 OpenAI 公司解雇后宣布转投微软，但这一决定并非板上钉钉。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2F2023%2F11%2F20%2F23969586%2Fsam-altman-plotting-return-open-ai-microsoft" target="_blank">The Verge</a> 援引多位知情人士消息称，如果解雇 Altman 的其余董事会成员下台，他和联合创始人 Greg Brockman 仍愿意重返 OpenAI。</span></p><p><span style="color:#000000">与此同时，微软首席执行官 Satya Nadella 在接受</span><span style="color:#333333"></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Falexeheath%2Fstatus%2F1726741601278681400" target="_blank">CNBC</a><span style="color:#333333"><span>&nbsp;</span>和<span>&nbsp;</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ftechnology%2Fstatus%2F1726751929475150226" target="_blank">Bloomberg TV</a><span style="color:#333333"><span>&nbsp;</span></span><span style="color:#000000">采访时也明确表示，</span>Altman 可能会以某种身份重返 OpenAI。</p><p>他在被问及&nbsp;<span style="color:#000000">Altman 以及 700 名 OpenAI 员工是否会加入微软时回答道，「这取决于 OpenAI 董事会、管理层和员工的选择」。并表示，无论他们是去是留，他都对这两种选择持开放态度。「显然，如果 Sam 和 Greg 不打算留在 OpenAI，我们希望他们有一个美好的归宿。」</span></p><p><img height="281" src="https://oscimg.oschina.net/oscnet/up-dc4fe464c1a2cd2a935cf44d7d8bd62f0c8.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">关于「明天谁会是 OpenAI 的 CEO」的直白提问，Nadella 也依旧是同样的回答："我会把这个问题留给 OpenAI 和它的董事会"。</span></p><p><span style="color:#000000">此外，当被问及微软是否需要在 OpenAI 董事会中占有一席之地时，他则表示，OpenAI 的治理方面必须做出一些改革，微软方面将就此与其董事会进行对话，并随着事态的发展而逐步推进解决这个问题。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">目前，被认为是此次 「政变」 组织者的 OpenAI 首席科学家 Ilya Sutskever 已经改变了主意，签署联名信要求 </span>Altman 回归。因此，<span style="background-color:#ffffff">OpenAI 剩下的三名董事会成员中只需要有两人反转就能让 Altman 回归。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267384/microsoft-ceo-sam-altman-plotting-return-open-ai</guid>
            <link>https://www.oschina.net/news/267384/microsoft-ceo-sam-altman-plotting-return-open-ai</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[发动 OpenAI 「政变」幕后黑手浮出水面：Quora 联合创始人 Adam]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据报道，随着局势日渐明朗，此次宫斗大剧的幕后黑手指向了 OpenAI 董事会成员、问答网站 Quora 联合创始人亚当·德安格洛（Adam D'Angelo），是他煽动并拉拢了公司首席科学家伊尔亚·苏茨克维（Ilya Sutskever）一起驱逐山姆·奥尔特曼（Sam Altman）。</p><p><strong>OpenAI 董事会背景</strong></p><p><img src="https://static.oschina.net/uploads/space/2023/1121/111403_8DJZ_2720166.png" referrerpolicy="no-referrer"></p><p>有人指出，德安格洛不满原因奥尔特曼的原因与 11 月初 OpenAI 开发者大会宣布的 GPTs 有关，德安格洛认为自己创办的 AI 机器人产品 Poe 将会被 GPTs 所淘汰，<strong>他对身为董事会成员却没有提前得知 GPTs 的存在而感到不满</strong>，觉得奥尔特曼不该对自己保密。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-d6576cd6d0b5a4521931becb8dedd5bf47b.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fwilliamlegate%2Fstatus%2F1726715671487156554" target="_blank">https://twitter.com/williamlegate/status/1726715671487156554</a></u></em></p></blockquote><p>据说德安格洛现在正忙着和律师商量应对方案。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ebba8bbe70d3d6091986c34281eacfde3b8.png" referrerpolicy="no-referrer"></p><p>公开资料显示，德安格洛出生于 1984 年，他被《财富》杂志誉为「科技界最聪明的人之一」，大学去了被誉为"天才"摇篮的加州理工，毕业后成为 Facebook 的第一任 CTO，后创办全球领先问答网站 Quora。他 2016 年上了《福布斯》杂志 40 岁以下最富有企业家排行榜。</p><p>此外，在纳德拉宣布 OpenAI 创始人奥尔特曼和格雷格・布罗克曼将<u><a href="https://www.oschina.net/news/267272">加入</a></u>微软领导新的 AI 研究团队后，微软股价盘前大涨 57%。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 03:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267375</guid>
            <link>https://www.oschina.net/news/267375</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 超 700 名员工签署联名信，要求董事会集体辞职]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据纽约时报等媒体统计数据，目前 OpenAI 至少有 743 名员工已签署联名信逼迫董事会集体辞职，同时恢复 Sam Altman 和 Greg Brockman 在董事会的职位。<strong>否则所有签名者集体跳槽微软</strong>，而且这一人数正在持续增加中（昨晚还只有&nbsp;500 人左右）。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3b5ce54499e3d9390d7173b0cacee47dfbc.png" referrerpolicy="no-referrer"></p><p>出乎意料的是，被认为是 OpenAI&nbsp;此次「政变」组织者的首席科学家 Ilya Sutskever 也签署了这一联名信。在这之前，Ilya Sutskever <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Filyasut%2Fstatus%2F1726590052392956028" target="_blank">发表推文称</a></u>：</p><blockquote><p>「我对自己参与董事会的行动深感遗憾。我从来没有想过要伤害 OpenAI。我热爱我们共同建立的一切，我将尽一切努力让公司重新团结起来。」</p><p><img src="https://oscimg.oschina.net/oscnet/up-498cd7551f25f7cc120902eb390081941de.png" referrerpolicy="no-referrer"></p></blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-08e0a2b4d71953d511d7c02b0bc333b91bf.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-65a525945aa136b1379d133093172eaa368.png" referrerpolicy="no-referrer"></p><p>同时，多位消息人士告诉 The Verge，<strong>如果解雇他的其余董事会成员下台，Sam Altman&nbsp;和联合创始人&nbsp;Greg Brockman&nbsp;仍然愿意重返 OpenAI。</strong></p><p>公开资料显示&nbsp;OpenAI 员工人数为 770 名，这批「逼宫」的人占据了员工总数超 96% 之多。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 02:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267364</guid>
            <link>https://www.oschina.net/news/267364</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[修完这个 Bug 后，MySQL 性能提升了 300%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>最近 MySQL 官方在 8.0.35 上修复了一个 bug：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3d378f6a5fb5f8dff83d14e5ff72cab3b1b.png" alt="file" referrerpolicy="no-referrer"></p><p>这个 bug 是由 Mark Callaghan 发现的。Mark 早年在 Google MySQL 团队，后来去了 Meta MySQL，也主导了 RocksDB 的开发。</p><p><img src="https://oscimg.oschina.net/oscnet/up-378864937e5b51e7e3eccce11e141140199.png" alt="file" referrerpolicy="no-referrer"></p><p>Mark 在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugs.mysql.com%2Fbug.php%3Fid%3D109595" target="_blank">#109595</a> 的 bug report 给出了非常详细的复现步骤</p><p><img src="https://oscimg.oschina.net/oscnet/up-8b85b0e3e90e67e4818aa415877ce952032.png" alt="file" referrerpolicy="no-referrer"></p><p>在官方修复后，Mark 在他的读写 benchmark 上验证有 300% 的提升 (4x)。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b04bfe95f38c366667868bb63f5182862a1.png" alt="file" referrerpolicy="no-referrer"></p><p>这样的性能提升在 Hacker News 上也引起了讨论，评论区也呈现了 HN 一贯的嘲讽风格。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0dbfce2e26833c161f1e3a3441c51d78a92.png" alt="file" referrerpolicy="no-referrer"></p><p>其实 infra 层这种性能提升的空间并不少。业界缺少的是像 Mark 这样躬身入局，抽丝剥茧的钻研态度。之前 Jeff Dean 在 Google 内部也做过一个分享，讲了通过优化一小段代码，就给 Google 一年省了十几万核。</p><p>画根线很容易，难的永远是知道在哪儿画。</p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 02:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10143821</guid>
            <link>https://my.oschina.net/u/6148470/blog/10143821</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[目标导向主义失效了？前 OpenAI 科学家现身说法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div>
  「目标感很强」常常被我们用来夸赞一个职场人，并被当作是成功的一大原因。然而，两位前 OpenAI 科学家——Kenneth Stanley、Joel Lehman 在多年的 AI 研究中发现，目标导向论对于成就伟大的事情并无助益，反而抱着探索的心态去尝试做有趣的事情更能带来意想不到的成果。 
</div><div>
  &nbsp; 
</div><div>
  尤其是在人工智能的算法研究中，比如让机器人通过一条走廊，最终从走廊尽头的大门中出去。最终实验证明，在不设定「出门」目标的情况，机器人可以纯粹尝试一些与以往不同的事情，反而最终能找到出门的方法。类似原理的还有 Kenneth Stanley 曾参与的图片繁育网站的工作，在这个图片繁育网站上，用户可以从一个简单的圆点图形，叠加其他图形图片，最终生成出类似汽车、动物等「有用」的图片，但如果用户开局就抱着」我要生成一张汽车图片「的目标，反而很难成功。 
</div><div>
  &nbsp; 
</div><div>
  由于认知理念上的转变，在 ChatGPT 发布前几个月，Kenneth 离开 OpenAI 去创业，研究新产品——开放式、偶然性社交网络 Maven，Joel 离开后到了 Stability，领导 Carper 开放性研究团队，同时他也在研究机器之爱。Kenneth 和 Joel 也合作创作了一本书《为什么伟大无法被计划》，书中认为，许多时候，哪怕我们的探索漫无目的，在前方位置的道路上依然埋藏着无数宝藏。从「目标」中解放出来，或许能成为发现意外之喜的「寻宝者」。 
</div><div>
  &nbsp; 
</div><div>
  「 
 <strong>在我看来，研究工作最重要、最实用的方面之一是开发对于可能性的直觉。」</strong>&nbsp;正如 Joel 现在去研究机器之爱的历程，在接触心理学之后，他将对心理学和机器学习的兴趣结合起来，找到了更加热爱的事情，「 
 <strong>我们的生活没有统一的目标，我们的兴趣和心理发展往往是偶然进行的——于是，一个新的研究方向为我打开了。」</strong>在他看来，在机器时代，我们越来越需要人类代理的提醒，技术的目的是为人类的利益服务，而人类是构建和设计这项技术的人。 
</div><div>
  &nbsp; 
</div><div>
  同样，对于人工智能的看法，Ken 也从人文的角度给出观点：「一种哲学见解认为，好的人工智能实验不仅应该带来强大的系统，还应该带来对我们人类自身的洞察。毕竟，对智能的任何伟大洞察实际上都是对人类的洞察，因为智能是我们的决定性特征。」 
</div><div>
  &nbsp; 
</div><div>
  Kenneth 和 Joel 提出的哲学态度与常规认知相反，或许能给我们在这个混乱时刻一些新的启示，因此，OSCHINA 特别邀请 Kenneth 和 Joel 聊了聊他们理念、观点和故事。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Ken 可以详细介绍下偶然性社交网络 Maver 的玩法、原理、以及目前的成长状态吗？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  Maven 是一种新奇的社交网络，我创办了一家新公司来开发它。它基于我们《为什么伟大不能被计划》一书中的原则，专注于将人们与个性化的偶然发现联系起来，而不是增强病毒式传播。我们从 2023 年开始开发它，所以它还很新。 
</div><div><img height="373" src="https://oscimg.oschina.net/oscnet/up-ea180ad51144df638c6a6b631f4e68e7054.jpg" width="700" referrerpolicy="no-referrer"></div><div><span style="background-color:#ffffff; color:#888888">Kenneth Stanley</span></div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Stability 现在在全球市场也备受关注，但很多人都不太了解开放性研究，能否请 Joel 介绍下正在做的开放性研究是指什么？</strong></span></p><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  创建生成式 AI 大模型的公司之间的一个主要理念分歧是专有模型与开源模型。 
</div><div>
  &nbsp; 
</div><div>
  例如，现在 OpenAI 和 Anthropic 没有公开他们最大的模型，以便其他人可以修改或在其基础上构建 (尤其是对他们来说有商业价值的模型)，而是只提供一个 API，用户可以在有限范围内使用模型。支持这种模式的理由通常是：如果大模型被滥用可能造成危险，而 API 可以实现更好的监控，并且训练大模型成本很高，公司需要一种赚钱的方法。 
</div><div>
  &nbsp; 
</div><div>
  相比之下，由 Stability 和 HuggingFace 等公司采用开源的方式训练模型、发布代码和模型 (通常比闭源模型的模型小)，这样其他公司和研究人员可以直接在其基础上进行构建，并根据自己的目的灵活调整。这些公司通常不太关心模型被滥用的危险，而是更关心创建一个蓬勃发展的研究和模型生态系统。但由于他们免费发布模型，其他人现在可以运行他们的模型，而无需向训练模型的公司付费，因此他们需要一种不同的商业模式来保持财务上的可行性。 
</div><div>
  &nbsp; 
</div><div>
  这两种理念都有蓬勃发展的空间，尽管未来存在关键的不确定性。例如，如果开源模型在未来变得非常强大，并且不良行为者最终利用这些模型造成了社会问题，则可能会产生负面影响。反之，如果专有大模型的 API 对于大多数希望使用生成式 AI 的公司来说限制过多或是成本过高，也许也导致更多人选择开源路径。 
</div><div>
  &nbsp; 
</div><div>
  当然，随着开源运动模式与方法的日益多样化，开源似乎更符合 Ken 和我的书中所传递的理念。我可以想象，许多有趣的发现将由此产生。但我担心，如何在开源社群中加入安全约束和规范引入，使得这些模型在造福社会的同时，也能尽量避免可能的负面影响？以及如何在鼓励这些规范和约束的同时不必放慢创新速度？这是一个有趣而微妙的问题。 
</div><div><img height="592" src="https://oscimg.oschina.net/oscnet/up-f738a9b408fbacdee21e45d537991e8c562.png" width="700" referrerpolicy="no-referrer"></div><div><span style="background-color:#ffffff; color:#888888">Joel Lehman</span></div><span id="OSC_h3_1"></span><h3>从「繁育」到「提示」，我们该如何对话机器</h3><p><span style="color:#2ea121"><strong>OSCHINA：当年「繁育图片」的孵化器网站后面的故事是怎样的？是否还在运行？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  你指的是 Picbreeder。它是在我在中佛罗里达大学 (University of Central Florida) 的实验室开发的 (该实验室名为 EPlex-Evolutionary Complexity Research Group)。Jimmy Secretan(当时是一名博士生) 领导了这项工作。这是一个允许互联网用户培育图像的网站，就像你培育狗或马一样。更深层次地说，其实这是一次开放性实验。它使我们能够观察到在人工环境中发生的大规模开放式搜索过程 (让人联想到自然进化)。看到这一过程的展开，我们得到了许多深刻的教训，其中包括新奇性搜索算法背后的理念，以及《为什么伟大无法被计划》一书中的见解。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：「繁育」原理和现在火爆的「输入 prompt 生成图片」这类网站可以做比较吗，二者背后的运行原理有什么相似得地方，有什么不同的地方？</strong></span></p><div><span style="color:#245bdb"><strong>ken：</strong></span></div><div>
  它们都是生成艺术的一种形式，但工作方式截然不同。基于提示的现代图像生成技术之所以有效，是因为生成图像的模型已经过数百万或数十亿个示例图像的训练。所以当它生成图像时汲取了丰富的经验。在协议中，Picbreeder 没有任何训练数据，用户只是简单地开始随机繁育圆点，经过几代的繁育，就能产生进化，产生更多我们更熟悉的图像，比如如汽车和蝴蝶。一个一开始并不明显的巨大差异是，繁育远没有那么密集：像 Picbreeder 头骨这样的繁育图像只需要几十次迭代搜索，而现代图像模型已经经过数百万或数十亿次迭代进行优化。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  抽象地说，繁育原理是指人们以发散和协作的方式探索思想空间，是取得新发现和有用发现的关键。「输入提示生成图片」的方法，在某种意义上与繁育原则是正交关系，因为你可以发散地与他人写作探索提示空间，也可以自己探索。 
</div><div>
  &nbsp; 
</div><div>
  换句话说，许多人确实分享了他们的提示技巧，展示如何让模型生成图像获得有趣成果。例如，在一些模型中，添加「Trending on Artstation」这一文本将有助于提高质量。所以，人们越能看到他人制作的图片和提示，就越能从图片和他人的提示中得到启发，制作自己的图像，从而更全面地用拥抱繁育原则。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：Prompt 背后的原理，是更接近目标函数原理，还是无目标探索</strong></span><span style="color:#2ea121"><strong>系统理论</strong></span><span style="color:#2ea121"><strong>？如何解释？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  因为 prompt 可以传达任何想法，所以它可以用来表达客观或非客观的过程。大多数人可能会客观地使用它们，因为这是我们大多数人被教导的思考方式，但仍然有可能有人非客观地使用它们。例如，如果我让它为我解决一个问题，这是一个客观使用。但如果我让它想给出一些有趣的东西，那就更接近于非客观。然而，重要的是要注意，你可以向 LLM 表达一个非客观的概念并不意味着它能表现得很好，或像人类一样。我认为现在的 LLM 通常无法很好地独立实现非客观的表达。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  Prompt 原则既可以兼容目标函数原则，又可以兼容探索系统理论。有时，人们会 prompt 进行大量优化，试图在特定任务中获得最佳性能。还有一些时候，人们以一种更不定向的方式利用 prompt 进行探索，以找到不同寻常的有趣方法来产生新的输出——探索特定语言模型或图像生成模型的边界。 
</div><div>
  &nbsp; 
</div><div>
  以「思维链」提示的惊人发现为例，只需要给模型举几个例子，说明如何推理一个问题，最终就能帮助模型更好地完成任务 (即告诉模型「一步步思考」)。模型本身有意想不到的优势，需要研究人员去发现，而发现方法往往是遵循他们的直觉，并以其他人发现和其他共享出来的 prompt 为基础。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：现在很多培训教学，教大家如何使用 Prompt，如果遵循用无目标探索</strong></span><span style="color:#2ea121"><strong>系统理论</strong></span><span style="color:#2ea121"><strong>，采用寻宝原则，我们该如何学习使用 prompt 和机器对话？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我认为以这种方式探索 prompt 是一个好主意。当你和 LLM 交谈时，尝试去做一些没有目标的事情，看看当你尝试一些有趣的事情时会发生什么。当你发现它以一种有趣的方式响应时，请进一步探索这条路径。这种方法可能会带来对模型的更深入的理解，而不是简单地尝试实现特定的目标。就像对待一个人一样，与系统一起探索，以更好地了解它是很有价值的。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一个原则是花一些时间玩这个系统，做你认为有趣的探索。也许你想看看模型有多善于讽刺，或者扮演你最喜欢的名人。你可以通过修改 prompt，或者尝试他人创建的 prompt 来开发直觉。你可以对意外发现持开放态度，注意到模型以一种本身有趣的方式作出响应——也许你试图让语言模型进行讽刺，但它却以巧妙的双关语做出了反应。那么，也许你可以探索它擅长哪种双关语，以及它何时会犯奇怪的错误。很有可能，当你尝试将模型应用到实际事物中时，你在亲手操作模型的过程中形成的直觉最终会对你有用，或者你可能会发现一种新的提示方法，或者至少你可能会在学习提示的过程中获得乐趣。 
</div><div>
  &nbsp; 
</div><span id="OSC_h3_2"></span><h3>哲学与技术，开发对于可能性的直觉</h3><p><span style="color:#2ea121"><strong>OSCHINA：在开发者群体中，roadmap、里程碑文化非常盛行，这是典型的目标导向。事实上，我们能看到很多知名软件都早已偏离最初的预设目标，但很多时候，时候软件标准、里程碑也能很好地指引开发团队做事。这个现象可以怎么理解？对于开发者该如何选择自己的「开发哲学」，你们有什么建议？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  目标并不总是坏的。当通往目标的路径是已知的，设定目标就会有成效。在软件开发中，完成项目的步骤通常是已知的，所以遵循目标是有意义的。然而，如果项目的目标是创新、发现或创造力，那么目标就有问题了。这样的项目可能会被目标扼杀，最终只做了很少有创造性的事情。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  首先我要说明的是，我在大型软件工程方面没有太多的个人经验。但一般来说，里程碑和标准可能非常适合在已知如何做的范围内进行的工作。距离成功可能只是一步之遥，不需要广泛探索。将软件从版本 1 升级到版本 1.1，修复一些现有的 bug 或添加一些有限的功能，可能是非常适合目标的思维的地方。但是从更长远的角度来看，如果目标是完全重新构想一个软件，或者创建一个软件来实现其他软件从未实现过的功能，那么就需要更多的探索和垫脚石思维。 
</div><div>
  &nbsp; 
</div><div>
  有时，垫脚石现象发生在更高的层面上。例如，当一个团队开发并发布一个开源库时，一个对他们的目的有用的库，一个构建在以前存在的库上的库，并且将使其他人能够创建他们自己的新库——这就是在玩寻宝游戏。因此，开发人员的哲学中，与寻宝有关的方式是，了解目前有哪些软件垫脚石，这些垫脚石可能使哪些以前没有的东西成为可能，并向世界推出新的软件，让别人能够以你无法预料的方式去使用的新软件。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：哲学思想可以如何作用于 IT 领域的研究，可以结合实际的事情来聊一聊吗？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我不确定这里指的是一般哲学还是这本书的哲学。当然，这本书的哲学也可以应用于其中。因为它只是赞同有时走一些有趣的路，即使你不知道它们通向何方。这在信息技术领域是绝对可行的。 关于一般哲学能否应用于 IT 的问题，我认为是可以的。 我认为哲学是对世界可能存在的方式的研究（与研究世界存在方式的科学相对）。 
 <strong>对「可能是什么 」的理解可以帮助你在做出选择之前看到眼前的各种可能性。</strong></div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  这很有趣——有些人把哲学和实用性对立起来。我能理解这种观点，因为我们接触到的哲学往往是抽象的、象牙塔式的。但在我看来，最重要的哲学是非常实用的。在进行包括 IT 在内的任何领域研究时，掌握一些关于如何进行发现的哲学是非常重要的。你可以通过自己的经验和观察发展出自己的个人哲学，但我们这本书的一个贡献就是强调了雄心勃勃的发现通常是如何发生的。 
</div><div>
  &nbsp; 
</div><div><strong>在我看来，研究工作最重要、最实用的方面之一是开发对于可能性的直觉。</strong>我的意思是，去理解什么样的事情是容易完成的，哪些事情是在可能性的边缘，哪些事情你不清楚你是否能够解决它们。当一个人刚进入一个领域时，当涉及到可能性时，他们的直觉通常会很差。但是，当你对可能性的直觉很好 (你大致知道一个问题有多难)，并且你的探索哲学也很合理 (如果一个问题很容易，就可以直接攻克；如果一个问题非常困难，可能无法解决，或者至少需要大量耐心的发散性探索)，那么你成功的机会就会大得多。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：无目标，新奇性搜索等哲学思想对你们的日常生活产生了哪些影响？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  这对我的日常生活很有帮助，因为我对仅仅因为有趣而去做某事的疑虑减少了。我知道它可能会成为一个有趣的垫脚石，即使我还不知道它最终将如何有用。我还把它来对待我的孩子。例如，我 9 岁的儿子有时会选择一些没有明显好处的事情，但我鼓励他去做，因为我看到他对这些项目很感兴趣，所以我相信这些项目可以引导他发现自我。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  写这本书，以及多年来对新奇性搜索的研究，这种理念不可避免地渗透到一个人的生活中。我比大多数人更乐于改变职业方向 (我目前正处于改变职业方向的过程中)，我努力保持求知欲，乐于看到意想不到的新机会，并努力在生活的不同方面之间找到广泛的联系。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：多年前你们因为图片产品的启示，开始研究「无目标」相关的哲学，这些年有没有一些实践体验带来新的哲学感悟？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span><strong>一种哲学见解认为，好的人工智能实验不仅应该带来强大的系统，还应该带来对我们人类自身的洞察。毕竟，对智能的任何伟大洞察实际上都是对人类的洞察，因为智能是我们的决定性特征。</strong></div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  这些年来，我有很多顿悟的时刻，事情以一种意想不到的方式突然发生。这些经历往往发生在阅读与我正在研究的课题有着抽象联系的有趣内容时，一种新的联系突然出现，或者当我的两个看似独立的兴趣突然联系在一起时，就达到更深层次的统一。 
</div><div>
  例如，我最近关于「机器之爱」的研究就是将我对心理学和机器学习的兴趣结合在一起。起初，这些兴趣似乎是完全分开的。但后来，随着我不断深入研究心理学， 
 <strong>我开始意识到，人类个体的生活在某种程度上是开放式的，就像生物进化一样——我们的生活没有统一的目标，我们的兴趣和心理发展往往是偶然进行的——于是，一个新的研究方向为我打开了。 </strong></div><div>
  &nbsp; 
</div><span id="OSC_h3_3"></span><h3><strong>ChatGPT</strong><strong>：或许是目标与非目标导向的产物</strong></h3><p><span style="color:#2ea121"><strong>OSCHINA：当下火热的 </strong></span><span style="color:#2ea121"><strong>ChatGPT</strong></span><span style="color:#2ea121"><strong>，或者其他</strong></span><span style="color:#2ea121"><strong>人机互动</strong></span><span style="color:#2ea121"><strong>问答产品，其背后的搜索符合新奇性搜索原则吗？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  这取决于这里所说的「搜索」是什么意思。假设是研究人员，确实有一个搜索的组成部分反映了新奇性搜索的各个方面，即使它不是明确的新奇性搜索算法。尤其是，没有人知道 ChatGPT 会成为一个世界性的现象——相反，他们决定研究它，是因为它既有趣又新奇。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  如果我们回顾一下 OpenAI 的研究历程，就会发现 ChatGPT 并不是该公司的长期目标。他们一开始就做了很多不同类型的研究，与 ChatGPT 似乎没有什么联系 (例如，机器人实验，以及教 AI 玩电子游戏的实验)。因此，创建一个功能非常强大的问答系统的道路是出乎意料的，没有计划，它取决于并建立在许多其他人铺设的垫脚石的上。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：</strong></span><span style="color:#2ea121"><strong>OpenAI</strong></span><span style="color:#2ea121"><strong> 或者 </strong></span><span style="color:#2ea121"><strong>ChatGPT</strong></span><span style="color:#2ea121"><strong> 可以称得上是一项伟大的实验 OpenAI 现在在做的事情是符合「目标导向」还是「自由探索」路径？如何解释？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  因为我已经不在 OpenAI 工作了，所以很难说他们现在正在遵循什么样的流程。但我想说的是，这很可能是一个混合体，既要努力优化以获得更好的性能（这是以目标为导向的），又要尝试其他有趣的想法（这是以新奇为导向的）。这种混合反映出，他们既需要改进现有的东西，也需要寻找下一个新事物。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  我不代表 OpenAI 发言，也不太了解他们目前的计划 (我一年前离开那里)。但我认为这两者兼而有之——既有「自由探索」，也有「目标导向」。这家公司已经不像刚成立时那样进行纯粹的原始探索，但他们仍在继续做许多有趣的研究。 
</div><div>
  &nbsp; 
</div><span id="OSC_h3_4"></span><h3>关于探索尝试、关于机器之爱</h3><p><span style="color:#2ea121"><strong>OSCHINA：你们提到一句话：「如果你想在有远见的人身上投资，就看看那些在附近的不确定性领域中徘徊和探索的人。」这句话里「附近的不确定性领域」是容易被发现的吗？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  不，我觉得这不容易发现。这就是为什么发现这些变革性机会的人如此罕见。我们经常假设世界运行的方式，这让我们对仍然存在的问题视而不见。然而，一旦有人指出了其中的一点，那么其他人就很容易看到了。但首先看到它就是一件不平凡的事情。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一开始不容易发现，但这是一种可以培养的技能。这是一种识别当前存在哪些垫脚石以及这些垫脚石可能带来什么的技能。通过一些专业领域知识，更容易识别「邻近的不确定性区域」。例如，我对量子物理知之甚少，我很难理解什么是已知的，什么是未知的，或者当前的垫脚石是什么样的。但在我工作多年的人工智能领域，我确实对该领域中有趣的不确定性有丰富的直觉。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：现在的 </strong></span><span style="color:#2ea121"><strong>AI</strong></span><span style="color:#2ea121"><strong> 世界，有哪些很酷的尝试？</strong></span></p><div><span style="color:#245bdb"><strong>Ken：</strong></span></div><div>
  我认为计算机辅助创作很有趣，多模态 (如文本与图像) 以及新型音乐的可能性也很有趣。比这些更酷的是幻觉的解决方案或产生真正开创性想法的能力。然而，据我所知，这些问题的解决方案还不存在。 
</div><div>
  &nbsp; 
</div><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  一个很酷的现象是，大模型正在重塑、重新想象旧算法。例如，一个大语言模型可以通过指令来创建一个计算机程序或一段文本的新变体，这将不仅仅是随机变体，而是智能变体——因为大模型是在大量计算机程序和文本中训练出来的。因此，你可以使用语言模型作为智能变化的引擎，从而使新型进化算法成为可能。通常，进化算法使用随机变化——但使用语言模型的进化算法更接近人类发明新想法的方式，即对其进行智能的探索性修改。 
</div><div>
  &nbsp; 
</div><div>
  这只是大模型如何重新发明算法的一个例子，但总的来说，它们是有趣的新工具——令人兴奋的新跳板——并为构建以前不可能构建的东西开辟了许多新的有趣的可能性。 
</div><div>
  &nbsp; 
</div><p><span style="color:#2ea121"><strong>OSCHINA：机器之爱真的能实现吗？个性化推荐、信息茧房、偏见、制度、思想、等等各种有形或事无形的阻碍充斥在各个地方，目之所及似乎都是困难。如果把「美好的人与机器的世界」做为目标，我们大概率会踩到错误的垫脚石上。如果用「寻宝原则」做导向，放任当下的机器研究自由发展，会不会使得情况更为糟糕？而现在要做的事情又是什么呢？</strong></span></p><div><span style="color:#245bdb"><strong>Joel：</strong></span></div><div>
  我相信，机器之爱的某些方面是可以实现的——这似乎是一个简单的事实，语言模型确实可以使机器开始处理定性和心理方面的工作，这可以让我们设计出关系自身成长和发展的算法，而这正是机器之爱的核心理念。在我看来，这是一块值得关注的有趣垫脚石，尽管目前还不清楚它会通向哪里——我们有理由怀疑，机器之爱的完整愿景是否会实现，它想要改变我们的世界确实还有很多障碍。但它可能会带来其他的垫脚石，以及应对这些障碍的方法——我们还不知道。 
</div><div>
  &nbsp; 
</div><div><strong>除了「机器之爱」（这只是改善机器对我们的影响的一个想法）之外，我们应该大胆地探索机器如何帮助我们人类过上更好的生活的许多不同愿景，也许这些愿景中的一个可以实现。我们永远不可能完全知道一块垫脚石会把我们带到哪里，但我们会尽最大努力，在不确定性和希望解决世界难题之间取得平衡。</strong></div><div>
  &nbsp; 
</div><div>
  我坚信， 
 <strong>在开发新技术时，寻宝原则不是我们应该遵循的唯一原则，让当前的机器学习不受阻碍地发展，可能会给社会带来许多负面的外部影响。</strong>一种观点认为，对社会安全的搜索也是一个开放式的搜索过程，就像对更强大的技术 (如大模型) 的探索一样。在寻找安全的过程中，就像在寻找技术一样，垫脚石的结构是不明确的，因此我们需要广泛而好奇地探索可能的干预空间 (例如，政府政策、新算法、公共教育、文化运动)，同时要知道，安全无法得到完全保证。在鼓励创新的同时，我们仍应尽最大努力维护社会，这可能需要智慧、克制和创造力。 
</div><div>
  &nbsp; 
</div><div>
  更具体地说， 
 <strong>在机器时代，我们越来越需要人类代理的提醒。技术的目的是为人类的利益服务，而人类是构建和设计这项技术的人。除了我们自己，还有什么能让我们保持谨慎呢?</strong></div><div>
  &nbsp; 
</div><div><hr></div><div>
  👍 为什么伟大不能被计划：OpenAI 科学家跨界撰写的思维奇书，源自人工智能研究的意外发现，找到人类伟大发明的真正入口，颠覆传统目标理论，重塑认知与思维模型，向普通人描绘一幅不同的成功图景 。 
</div><div><hr></div><div>
  【💰售价】39.50 元 
</div><div>
  👉购买链接：https://j.youzan.com/TTuo6A 
</div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 01:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/10149295</guid>
            <link>https://my.oschina.net/u/4489239/blog/10149295</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Intel SIG 成立！携手打造 openKylin-Intel 技术生态]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">2023 年 11 月，经 openKylin 社区技术委员会审议通过，</span><strong><span style="color:#000000">Intel SIG</span></strong><span style="color:#000000">正式成立。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 由</span><strong><span style="color:#000000">英特尔中国</span></strong><span style="color:#000000">发起成立，负责 openKylin 社区中桌面操作系统上 Intel 最新平台支持、适配与优化等技术相关的开发工作。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">01&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 目标</span></strong></span></p><ul><li><span>创建并维护 openKylin Intel 新平台的规划和升级，建设更完善的 openKylin-Intel 技术生态；</span></li><li><span>充分利用 openKylin 提供的平台，把最新的 Intel 技术基础软件栈融入 openKylin 操作系统，为未来社区的创新和发展提供更广阔的空间，为推动 Intel 产品的落地提供生态支撑。</span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">02&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">SIG 职责</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">1、Intel 新平台</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根据 openKylin 社区的规划，并且结合上游内核的开发，Intel SIG 会对 Intel 最新的平台在下游社区进行全面支持。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">2、Intel 新技术</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根据客户的需求，引入 Intel 优势技术，更好的提供可行性方案；拓展更广的技术和商业合作空间。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">3、OEM 的支持</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">根据桌面平台的生产商 (OEM)，Intel 可以根据 OEM 的需求以及 openKylin 的要求，合作支持 OEM。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><strong><span style="color:#0052ff">4、与 openKylin 共赢</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 愿意与 openKylin 各方合作，共同构建面向未来的良性合作生态环境，为 openKylin 开源桌面操作系统的发展提质提速。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><em><span><strong><span style="color:#ffae28">03&nbsp;</span></strong></span></em><span><strong><span style="color:#0b43d1">欢迎加入 SIG</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Intel SIG 负责 openKylin 社区中 Intel 技术相关的开发和信息交流，本小组拥有国内外顶尖的 Intel 平台研究技术团队，为拓展 openKylin 的生态提供有力支撑，期待各位感兴趣的小伙伴们的加入！</span></span></p><ul><li><span>邮件列表：</span></li><li><span><span style="color:#0052ff">intel@lists.openkylin.top</span></span></li><li><span>SIG 主页：</span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/Intel-SIG</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 20 Nov 2023 01:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267352</guid>
            <link>https://www.oschina.net/news/267352</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[运营商神操作：后台断网、停用宽带账号，强迫用户更换光猫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，河南电视台都市频道节目报道称，河南周口联通为了强迫用户更换光猫，<strong>公司在后台停掉用户的宽带账号，导致用户无法上网，然后让工程师上门「维修」，谎称光猫损坏，需要花 299 元换新</strong>。<strong>更换完后，联通再在后台恢复用户的网络</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6bca55961849d5db6bafd2b8cf31a04abc6.png" referrerpolicy="no-referrer"></p><p>联通公司不仅对老用户进行这种强制更换光猫的行为，还会在给新用户装机的时候，故意使用破旧光猫，也就是之前强迫用户换新留下的，而再过一段时间之后，又会告诉用户使用的是旧光猫无法匹配，必须换新。联通公司还会故意关掉用户的短信服务，在后台增加增值业务，之后再把短信功能打开，以此牟利。</p><p><img height="826" src="https://static.oschina.net/uploads/space/2023/1120/163843_Utox_2720166.png" width="1518" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1120/164043_bGMp_2720166.png" referrerpolicy="no-referrer"></p><p>周口联通回应称，全力配合省公司调查组进行调查核实。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5af067ca7f5336640898e328da5adc6109b.png" referrerpolicy="no-referrer"></p><p>来源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.sina.com.cn%2Fs%2F2023-11-20%2Fdoc-imzvfrzw9582625.shtml" target="_blank">https://news.sina.com.cn/s/2023-11-20/doc-imzvfrzw9582625.shtml</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267276</guid>
            <link>https://www.oschina.net/news/267276</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里云开源大数据产品年度发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文根据 2023 云栖大会演讲实录整理而成，演讲信息如下：</p><p><strong>演讲人</strong>：陈守元 | 阿里云计算平台事业部开源大数据产品总监</p><p><strong>演讲主题</strong>：阿里云开源大数据产品年度发布</p><p>随着云计算的不断发展，未来数据处理和应用的趋势将围绕 Cloud Native、Severless 和 Data+AI 展开。其中，云原生架构已成为主流趋势，因为它可以提高数据处理和应用程序的可伸缩性和灵活性，支持大规模部署和更快的响应时间。同时，Serverless 作为一种新型计算模式，可以提高处理效率、降低运营成本并减少资源浪费，其独特的特点使得其成为处理大规模数据的理想选择。此外，Data 与 AI 融合正在快速发展，不断提高智能化和自动化程度，同时需要高质量的数据来支撑算法的准确性和有效性。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a48d65a7b7035e480f3276674b7f31f68a3.png" alt="" referrerpolicy="no-referrer"></p><h2>EMR：面向下一代湖仓和全面 Serverless 化</h2><p>下面进入产品发布环节，我们将围绕上面三个点&nbsp;做哪些事情、有哪些发布更好地服务用户上云&nbsp;来讲述我们产品的重点发布。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4026c36c77d94f189e70fb9fe1cb0464515.png" alt="" referrerpolicy="no-referrer"></p><p>首先，我们来看 EMR。EMR 是一个云原生开源大数据平台系统。对于 EMR 而言，线下 IDC 大量基于开源 Hadoop 生态构建的线下用户搬站上云第一站就会选择 EMR，因为改造代价特别地小，几乎可以无缝平迁上云。这对用户来说是具有巨大的人力资本和机器资本的节省。&nbsp;我们将阿里云 EMR 定位为&nbsp;用户搬站上云的第一站。</p><p>今年我们的产品矩阵做了升级，我们希望在云上基于更多样化的 IaaS 提供多样化的 EMR 产品形态。EMR 通用版，核心解决的用户问题就是帮助用户的大数据系统平迁上云，这也是和用户线下部署兼容度最高的方案。第二个是 EMR 容器版，即 EMR ACK 版。现在 IT 基础设施的云原生容器化基本上都深入人心，我们大量客户在云上基于 IT 系统的构建都会选择容器化的平台，例如阿里云的 ACK。用户自然而然会联想到如何把 Data 和 AI 的 workload 迁移到 IT 基础设施的同一个集群里，完成 Data&amp;AI 的负载&nbsp;与 IT 设施负载混用，EMR 容器版，或者说 EMR onACK 就是帮用户解决这类问题的产品。</p><p>最后也是我们今天想强调的重点就是 EMR Serverless 版。对于 EMR Serverless 子产品线而言，内部有些 feature 或者功能&nbsp;在之前云栖中已做了发布。今天对于 EMR Serverless 产品线是一个更加完整的矩阵呈现，今天会重点讲一下 Serverless Spark、Serverless StrarRocks 两大主流 EMR 计算引擎的 Serverless 化，今天也是我们正式对外提出一个完整的 EMR Serverless 化的产品线矩阵。</p><p>EMR Serverless 版是 EMR 产品线形态中诞生最晚、发布最新的一代产品和技术，其实 EMR 围绕 Serverless 的布局在一年前、两年前都在紧锣密鼓地进行。前面 OSS-HDFS、Serverless HDFS 这一块其实在去年、前年已有发布，但是今年我们做了更多的尝试努力，我们希望把 EMR 上面主流的大数据计算引擎、存储引擎、开发平台、元数据管理全都 Serverless 化，只有这样方才能够更好地满足云原生用户更好地利用大数据。Serverless Spark，更好地解决了湖仓场景下 Data ETL 的处理能力，Serverless StrarRocks 更好地解决了湖仓场景下 Data analytic 能力，Serverless HDFS 更好解决了湖仓场景下数据存储能力，最后 EMR Stutio 帮助用户线下可以平迁体验上云，让用户能够更好使用云上大数据基础设施，同时还能免运维。所以 EMR 今年从计算，到存储，到开发环境&nbsp;几乎全部实现了 EMR 主力引擎和平台都能够做到 Serverless 化，我们希望能够把整个大数据开发运维闭环，从而进一步帮助云原生上的开发者更好地把大数据用起来。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e0e494088f0e316e87a203fb7a7b147a1c7.png" alt="" referrerpolicy="no-referrer"></p><p>下面仍然回到 EMR 主力场景， EMR 通用版，围绕湖仓场景做了大量更新。EMR 主力场景仍然围绕着湖仓处理，围绕在湖仓计算、存储、运维、开发做了大量的更新。在计算层面，我们核心还是降本提效，IaaS 层适配了新的倚天 CPU，PaaS 层做了 Native Spark RunTime，这些都是从 IaaS 层和 PaaS 层更好地帮助用户降本提效。存储部分，Serverless HDFS (同时也称之为 OSS-HDFS)&nbsp;很早已有发布，但是在这一年希望让 Serverless HDFS 和&nbsp;本地 HDFS 在使用层面给用户体验完全一致，包括&nbsp;在&nbsp;文件性能、数据访问、源数据获取等方案&nbsp;做到几乎完全一致。为上述目标，我们因此做了大量有关系统性能优化&nbsp;以及&nbsp;系统安全性优化。我们的 Open 文件性能的提升、DU 访问源数据的提升，这些都是今年的成果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-00bfea3732092d7e26b3743ad341b1f080a.png" alt="" referrerpolicy="no-referrer"></p><p>EMR 运维，这主要体现在两个方面。在云上来说 EMR 能结合到云原生上面给用户创造比较大的平台价值就在于弹性，今年我们做到大量的弹性优化。我们大量客户给我们反馈说 EMR 的平台弹性越来越稳定；另外一个运维重点，即 EMR Doctor，我们希望通过 AI 的方式、自动化、智能化的运维平台方式帮助用户去解决开源大数据运维的问题。从社区开源大数据用户反馈来看，开源大数据使用最大的、最痛的点就是系统运维。如何长期有效地保证我们的业务在云上健康地运行，这是很多用户上云和云下使用开源大数据非常大的痛点，EMR Doctor 就是解决这个问题。EMR 开发，即 EMR Studio，我们希望云原生 Serverless 化托管了我们的开发平台、调度平台，帮助用户从线下的体验完全平迁到云上的一套体验。以上均是 EMR 围绕湖仓场景的重大更新。</p><p>最后仍然回到 EMR For AI，我们每个产品都在拥抱积极的变化，这里分为三部分：EMR DataScience、EMR Doctor、EMR+DataWorks 的 Code Pilot。EMR DataScience 是在 EMR 的容器版里面，我们提供了一个新的集群叫 EMR DataScience，里面内置了不少 AI 最流行的组件，包括 Pytorch、TF。我们希望用户在一个平台上既能够处理大数据，同时还能够云原生地处理 AI 的工具，这是 EMR DataScience 帮助用户做的相关工作。EMR Doctor，这个工作前面提到希望用 AI 化、智能化的方式帮助用户实现 AIOps，能够用自动化的手段定位问题、诊断问题、及早发现问题。EMR+Dataworks，今年 DataWorks 重磅的发布就是 code pilot 的发布，但是那上面作为一个平台实际上底下也对接了 EMR 等等，正好实际上 code pilot 也是平台引擎无关的 Feature，可以生成 EMR 里面的 HIVE 代码，用户就可以用 DataWorks 上面开发平台能够通过自然语言生成 MaxCompute 的 SQL，能够操作业务，这样能够极大地减少用户开发代码的成本，这在 DataWorks 对外提供公测的时候欢迎去试用一下。</p><h2>Flink Streaming Lakehouse：新一代的流式湖仓新方案</h2><p>下面我们看一下 Flink Streaming Lakehouse。Lakehouse 这个概念其实在前几年很火，原因就是对于一个 Lakehouse 的系统来说，既兼具了 Data Warehouse 的严谨，包括 ACID、版本的管理、数据格式的校验等等；同时它还有 Data Lake 的灵活性，能够放很多大量非结构化的文本，包括图片、视频、音频、图像等等。而 Lakehouse 同时能够承载结构化的数据和非结构化的数据，这对用户来说是非常好的 AI 和大数据融合的底层存储方案。但是我们看 Lakehouse 的过程中发现 Lakehouse 在时效性方面有非常大的问题，Flink 核心使命和价值就在帮助我们的客户解决大数据实时化转型和升级。所以 Flink 社区&nbsp;和&nbsp;我们&nbsp;一起发布了 Streaming Lakehouse 方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-37eae0cedf4dbaf6356c5188b319f6e8a02.png" alt="" referrerpolicy="no-referrer"></p><p>回到 Streaming Lakehouse 我主要从产品方向&nbsp;讲三个场景要点。前面已经提到 Lakehouse 在 AI 时代下 Lakehouse 的方案会越来越重要，因为它既能存储结构化的数据又能存储非阶段的数据，这个是大数据和 AI 一体化存储的重要承载点。但是 Lakehouse 在实践的过程中仍然遇到时效性的问题，整个 Lakehouse 的 Data Pipeline 串联起来可能达到小时级别的延迟，从最开始的数据进入到数据价值的发挥，比如 BI、AI，能够看到整个数据链路到小时级别，这其实对于用户来说要构建一个实时湖仓面临很大的延迟。所以 Flink 希望一起帮助用户做到 Lakehouse 的实时化，通过流式、实时帮助用户做很大的提升。</p><p>最后是 Unified，其实 Flink 社区在前几年一直主打 Unified Batch &amp; Streaming。我们希望在计算层面做到融合，就是流批一体。我们在开源社区推广流批一体的方案时，发现如果用户只是计算层面的融合对于用户只能解决一半的问题。还有一半问题在于存储，存储仍然是两套的存储方案，两套存储和两套数据因此会导致的离线和实时的数据不一致性对于用户来说是非常大的问题，所以 Flink 团队和社区一起构建了 Paimon。Paimon 基于底层的分布式文件系统，比如说 OSS 会构建一个 Unified 的 storage，既可以做流，也可以做批，我们称之为批流一体的存储。所以 Flink+Paimon 构成 Lakehouse 的方案，既具备 Unified 的 process，也可以具备 Unified 的 Storage，这一层合并在一起能够真正完整地帮助用户实现流批一体的解决方案。这是我们 Streaming Lakehouse 的价值点，最终我们希望帮助用户在 Data+AI 时代下提供实时化、流式化和 Serverless 化的湖仓方案。</p><p>回到 Flink 主线，我们一直以来的使命就是希望帮助用户做到大数据的升级和转型，所以追求实时场景下的性价比一直是 Flink 团队一直以来努力的方向。追求实时化的性价比今年有两个重要的点，一个是 Flink 全面拥抱了倚天，结合到倚天&nbsp;整个实时计算 Flink 综合的性价比有 50% 的提升，这是 Flink 团队结合 IaaS 层面做了大量优化。同时在 PaaS 层 Flink 企业级内核&nbsp;我们仍然在做大量优化，这其中包括算子的优化，以及未来我们会公布 native runtime 的优化。这部分优化相比于开源 Flink 引擎，我们实时计算 Flink 版&nbsp;会有两倍的提升，特别是在吞吐部分可以解决很多用户高吞吐量或者大流量的实时计算场景。</p><p><img src="https://oscimg.oschina.net/oscnet/up-93711ed92a4488a619f2f0cfa9e51e70d03.png" alt="" referrerpolicy="no-referrer"></p><h2>Elasticsearch:Serverless 和 Search for Data &amp; AI</h2><p>接下来讲一下 Elasticsearch，这也是开源大数据很重要的组成部分。说到 Elasticsearch 可能大家更多仍然停留在比较早期 for data 的 search，就是全文的检索，类似于搜索引擎要做全文的检索。但今天我想告诉大家这个思想需要刷新一下，Elasticsearch 不仅是 for data 的 search，也是 for AI 的 search。我今天给大家重点会讲一下 ES 如何从 Data 转变成 Data+AI 的 search 系统。</p><p>第一个是我们的 Elasticsearch 的版本发布。坦白地说，当前产品形态，即 ES on PaaS 的独立集群版本已经非常好地满足我们中国公有云和专有云客户很多的市场需求，不少中大型公司都非常认可阿里云的 ES 产品形态，产品客户受众无论在基数以及未来增长都很不错。但实际上随着最近这一两年客户在降本提效上提上了日程之后，发现有一批非常大的潜在客户以及中长尾的客户其实仍然对云上的独立集群版本所带来的成本仍然认为是比较大的上云入门门槛。他们非常希望以低门槛甚至零门槛的方式开启云上的 ES，这就是我们 ES Serverless 要做的初衷，我们希望以一个零门槛的方式能够帮助用户开启云上 Elasticsearch 的使用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dda1df3c99a6593d14261aabceb742084c0.png" alt="" referrerpolicy="no-referrer"></p><p>同时 Elasticsearch Serverless 也是我们国内首家支持通用场景的 ES 版本。去年我们也发布了一个 Elasticsearch Serverless 版本，但更多解决日志 ELK 场景的需求。但是该版本在数据一致性上会存在问题，所以今年我们进行大量的产品技术架构重构。本次 ES Serverless 的发布是一个面向通用场景的升级发布，这里面不仅支持包括日志场景，还支持订单、金融等等场景，这里面的数据一致性都可以得到很好的保障。这是我们今年发布相比于去年发布升级很不一样的点。针对 ES Serverless 可以真正按量付费、秒级弹性、简单运维，同时可以完全兼容开源的 ES，这是很多其他的厂商不一定能做到的。</p><p>下面重点强调 ES for AI 和 Data 的部分，标志着 ES 真正从 Data 面向 Data&amp;AI 的搜索引擎。云栖会场外面有很大的广告栏，主打的是 ESRE 的发布，这是 ES 公司重大的发布。发布的核心简单跟大家说一下，就是支持 AI 相关检索，包括向量检索，包括多路并规的查询优化，这些东西都是在 ES 内核重点打的点，帮助用户做 AI 检索。阿里云 ES 围绕着 ES 最新的 AI 能力进行了大量方案集成，就是右边的增强方案。我们跟达摩院 AI 方案做联合，和 PAI—EAS 方案联合，甚至会和社区一起做更多的联合方案，这些方案能够帮助我们的用户更好地在云上用上阿里云、达摩院 AI 的技术，和社区的 ES 更好地结合起来。所以我们希望通过 ES8.9 这个版本能够帮助用户构建下一代面向 Data+AI 的检索系统。</p><p><img src="https://oscimg.oschina.net/oscnet/up-47305474e3702aae7f01185fc4b3c7a7d65.png" alt="" referrerpolicy="no-referrer"></p><p>围绕 ES 自研能力的升级，阿里云 ES 是和 ES 公司一起合作，也是基于开源的 ES 做更多的优化孵化，其实是完全基于开源，也是完全兼容开源的，我们做了大量的增强。而这里面做了三个升级，包括场景的升级，也就是日志场景向通用场景的升级和改造。去年 ES 更多是做日志场景、ELK 场景，今年的 ES Serverless 面向通用场景进行完全开放。另外就是有关搜索内核引擎的优化，包括读写分离、存算分离，这些更好地解决集群稳定性问题、成本流控问题、资源弹性的问题。最后我们在购买链路和相关控制枱上做了比较大的体验升级，我们非常推荐大家去用一用阿里云 ES Serverless 版本，感受一下完全 Serverless 化的 ES。</p><h2>Milvus：AI 时代的搜索引擎</h2><p>今天最后一个，也是今年完全新的产品。前面全部是我们现有的功能、现有产品线的叠加，Milvus 这部分是我们今年要发布的 AI 时代新的搜索引擎。目前，在向量检索部分 Milvus 几乎是全球最火、最亮眼的技术。我们会在 12 月份开启向量检索 Milvus 版本对外测试，相比于开源的 Milvus 来说会做相应产品企业级的增强。同时在兼容开源的 Milvus 之上，我们还会去结合达摩院的技术能够提供更好的企业级向量检索能力。同时在云上肯定会做大量的产品联合工作，包括和我们的存储上有大量非结构化的数据可供用户检索查询。同时我们会跟 PAI 平台、达摩院 AI 模型做更多的深度集成，做 AI 向量检索能力、做大模型向量支撑，这些方案未来都会在我们的产品之上构建。所以我们最终是希望能够帮助云上使用 Milvus 的用户更快、更方便、更低门槛构建 AI 时代下的搜索系统。</p><p><img src="https://oscimg.oschina.net/oscnet/up-684d85b432854ecd04eafd9cad2a5a50df8.png" alt="" referrerpolicy="no-referrer"></p><p>回顾一下我们讲了大数据的三个趋势。Cloud Native，整个 IT 投资都在往云上加速转型。Serverless 化，我们认为未来的 PaaS 平台最终全部都会归到 Serverless 化，所有 AI 产品、大数据产品和其他 PaaS 产品都会归到 Serverless 化。最后是 Data+AI，未来 AI 和大数据会做彻底的融合打通，这也是我们整个开源大数据一直以来在积极围绕这三个点做布局。</p><p>最后希望大家多多关注阿里云，关注阿里云的开源大数据，谢谢大家！</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/10149103</guid>
            <link>https://my.oschina.net/u/5583868/blog/10149103</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 前 CEO 和总裁 Sam Altman & Greg Brockman 加入微软]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软 CEO Satya Nadella 刚刚<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsatyanadella%2Fstatus%2F1726509045803336122" target="_blank">发布推特称</a></u>，OpenAI 前 CEO 和总裁 Sam Altman &amp; Greg Brockman 将加入微软，他们负责领导新的 AI 研究团队。</p><p><img height="1176" src="https://static.oschina.net/uploads/space/2023/1120/155839_imd2_2720166.png" width="1264" referrerpolicy="no-referrer"></p><p>Sam Altman 转发了这条推文，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1726510261509779876" target="_blank">并说道</a></u>：不忘使命，砥砺前行。</p><p><img height="678" src="https://static.oschina.net/uploads/space/2023/1120/161424_UZuO_2720166.png" width="1272" referrerpolicy="no-referrer"></p><p>Satya Nadella <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsatyanadella%2Fstatus%2F1726516824597258569" target="_blank">评论了 Sam 的推文</a>：</p><blockquote><p>Sam，我对你以首席执行官身份加入新团队感到无比激动，你将为我们的创新工作开辟新的道路。</p><p>多年来，我们学会了如何为创始人和创新者提供空间，让他们在微软内部发展独立的身份和文化，这一点从 GitHub、Mojang Studios 到 LinkedIn 的发展中可见一斑。我迫不及待想看到你也能做到。</p></blockquote><p><img height="1372" src="https://static.oschina.net/uploads/space/2023/1120/164746_aILD_2720166.png" width="1286" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 08:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267272</guid>
            <link>https://www.oschina.net/news/267272</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Altman 回归失败，OpenAI 董事会聘请 Twitch 前高管担任 CEO]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">据</span>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fbreaking-sam-altman-will-not-return-as-ceo-of-openai" target="_blank">The Information</a>&nbsp;<span style="color:#000000">和</span>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-20%2Fopenai-s-board-hires-former-twitch-executive-shear-as-ceo" target="_blank">Bloomberg</a>&nbsp;<span style="color:#000000">消息称，经过一个周末的谈判，OpenAI 董事会决定不顾投资者要求 Sam Altman 复职的呼声，聘请前 Twitch 首席执行官 Emmett Shear 来担任该公司的临时首席执行官。</span></p><p><span style="color:#000000">OpenAI 联合创始人兼董事会董事 Ilya Sutskever 向员工表示，公司高管有尝试努力挽回 Sam Altman，但没有成功，Altman</span>&nbsp;<span style="color:#000000">将不会回到 OpenAI。</span></p><p><img alt="" height="300" src="https://static.oschina.net/uploads/space/2023/1120/153143_G4mc_4252687.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Emmett Shear 将从 Mira Murati 手中接过这一职位，这也意味着 OpenAI 在三天内迎来了第三任首席执行官。此前，在 Sam Altman 被突然解雇后，曾有大批 OpenAI 员工开始在社交媒体上表达了对 Altman 的支持，Mira Murati 也在此列。</span></p><p><span style="color:#000000">Shear 在 2006 年帮助推出了游戏流媒体网站 Twitch，并于 2014 年以近 10 亿美元的价格将其出售给亚马逊。今年早些时候，Shear 辞去了 Twitch 的首席执行官一职。</span></p><p><span style="color:#000000">有知情人士表示，Shear 之所以能赢得 OpenAI 董事会的青睐，是因为他能意识到人工智能所带来的生存威胁。此外，<span style="background-color:#ffffff">Open AI 的董事会已经至少联系了两名科技行业的知名高管，希望其中一位可以担任公司董事长的职位。</span></span></p><p><span style="color:#000000">OpenAI 及其最大投资者微软的发言人目前暂未回应相关置评请求。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 19 Nov 2023 07:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/267256/openai-twitch-ceo-shear</guid>
            <link>https://www.oschina.net/news/267256/openai-twitch-ceo-shear</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
