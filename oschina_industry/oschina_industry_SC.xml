<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 19 Sep 2023 19:00:22 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[微软 AI 研究人员意外泄露 38TB 内部数据]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">云安全初创公司 Wiz 的研究人员<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wiz.io%2Fblog%2F38-terabytes-of-private-data-accidentally-exposed-by-microsoft-ai-researchers%23security-risks-in-the-ai-pipeline-53" target="_blank">报告</a>了一起发生在微软 AI GitHub 存储库上的数据泄露事件，其中包括 3 万多条内部 Microsoft Teams 消息的泄露；而这一切都是由一个配置错误的 SAS 令牌所引起。</span></p><p><span style="color:#000000">Wiz 指出，<span style="background-color:#ffffff">数据泄露源于微软人工智能研究小组</span>下的一个名为<code>robust-models-transfer</code>的仓库<span style="background-color:#ffffff">；该存储库包含可用于构建新神经网络的图像识别模型和训练数据集。此次泄露是由其中一个训练数据文件引起的，该文件托管在 Azure 存储帐户中。微软方面原本打算仅公开共享 AI 训练数据集，但意外地开放了对包含该数据集的整个 Azure 存储帐户的访问权限。</span></span></p><p><span style="color:#000000">研究人员在扫描后发现，<span style="background-color:#ffffff">配置错误的帐户导致了 38 TB 的微软内部文件泄露，其中包括两名员工工作站的</span><span style="background-color:#ffffff">磁盘</span><span style="background-color:#ffffff">备份。</span>这些备份包含敏感的个人数据，涵盖 Microsoft services 的密码、密钥以及来自 359 名微软员工的 30,000 多条内部 Microsoft Teams 消息。</span></p><p><img height="418" src="https://oscimg.oschina.net/oscnet/up-88f8ade4d873149ff786e4d451232457b72.png" width="500" referrerpolicy="no-referrer"></p><p><img height="367" src="https://oscimg.oschina.net/oscnet/up-149c6bcfd37adc22e051de3892ba542104e.png" width="500" referrerpolicy="no-referrer"></p><p><img height="486" src="https://oscimg.oschina.net/oscnet/up-9d5cc6df05d4c596395a22515834cbc75a1.png" width="500" referrerpolicy="no-referrer"></p><p>且除了过于宽松的访问范围之外，令牌还被错误配置为允许「完全控制」权限而不是只读权限。这意味着，攻击者不仅可以查看存储帐户中的所有文件，还可以删除和覆盖现有文件。</p><p>不过研究人员指出，此存储帐户并未直接向公众公开，而是一个私有存储帐户。「微软的开发人员使用了一种名为 SAS tokens 的 Azure 机制，该机制允许创建一个可共享的链接，授予对 Azure 存储账户数据的访问权限--而经过检查，该存储账户看起来仍然是完全私有的。」</p><p><img height="286" src="https://oscimg.oschina.net/oscnet/up-c51fde2b8a33a7092286ee6cf33280d7771.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Wiz 最初于 6 月 22 日发现了该问题，并在不久后向微软报告。6 月 24 日，微软宣布撤销 SAS 令牌，并于 8 月 16 日完成了潜在影响的内部调查。</span></p><p><span style="color:#000000">报告总结称，共享人工智能数据集这一简单步骤却导致了重大数据泄露，根本原因在于使用了账户 SAS 令牌作为共享机制。由于缺乏监控和管理，SAS 令牌存在安全风险，应尽可能限制其使用。「这些令牌很难跟踪，因为微软没有在 Azure 门户中提供集中管理这些令牌的方法。此外，这些令牌可以配置为永久有效，没有过期时间上限。因此，将账户 SAS 令牌用于外部共享是不安全的，应避免使用。」</span></p><p><span style="color:#000000">并建议组织提高人工智能开发过程的相关安全风险意识，确保安全团队与数据科学和研究团队密切合作，以确保定义适当的防护栏。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 19 Sep 2023 09:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258688/microsoft-38tb-internal-data</guid>
            <link>https://www.oschina.net/news/258688/microsoft-38tb-internal-data</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[议题征集｜Flink Forward Asia 2023 正式启动]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0px; margin-right:0px; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><img alt="1" src="https://oscimg.oschina.net/oscnet/up-4db90028a890acd5c61100f4f31eae97aca.png" referrerpolicy="no-referrer"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:FF6a00"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsurvey.aliyun.com%2Fapps%2Fzhiliao%2F081fLSOu4" rel="nofollow" target="_blank">点击投递议题</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>作为最受 Apache Flink 社区开发者期盼的年度峰会之一，<strong>Flink Forward Asia 2023</strong>&nbsp;已正式启动！本届 Flink Forward Asia（以下简称 FFA ） 重新回归线下，预计将于 12 月 8 - 9 日在北京举办。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>延续 FFA 惯例，峰会所有议题均为开放征集而来，并由专业的议题评选委员会评分筛选，确保内容代表行业领先水平。今年，议题组委会将持续集结全球多行业一线厂商，围绕 Flink 核心技术、行业实践、平台建设、实时湖仓、数据集成等多个热门方向，以及 Flink 社区孵化出的 Flink CDC、Apache Paimon、Flink ML 等优质项目，为开发者奉上实时计算领域的技术盛宴。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FFA 2023 官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fflink-forward.org.cn%2F" rel="nofollow" target="_blank">https://flink-forward.org.cn/</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><span id="OSC_h2_1"></span><h2><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>议题投递方式</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h2><span id="OSC_h3_2"></span><h3><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>PC 端：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h3><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>打开 FFA 2023 官网，点击<strong>「议题投递」</strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>FFA 2023 官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fflink-forward.org.cn%2F" rel="nofollow" target="_blank">https://flink-forward.org.cn/</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><img alt="" src="https://ucc.alicdn.com/gfbp4bwpctdbo_20230912_8481bebde87041b8ab38bb125e5e3929.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-811e1576263083b10a09316dc51017ade6a.png" referrerpolicy="no-referrer"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><span id="OSC_h3_3"></span><h3><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>移动端：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h3><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>扫描下方二维码 ⬇️</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><img alt="" src="https://ucc.alicdn.com/gfbp4bwpctdbo_20230912_63220172f6924aeca6a4b16a23560323.png" referrerpolicy="no-referrer"><img alt="" height="383" src="https://oscimg.oschina.net/oscnet/up-4feeffa69a2698c22802f8adb90cbfed232.png" width="685" referrerpolicy="no-referrer"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><span id="OSC_h2_4"></span><h2><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>议题方向</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h2><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Flink Forward Asia 2023 将采用议题标签的形式呈现所有大会精彩内容，围绕 Flink 横跨多行业，新场景。每个议题最多选择 3 个标签。主要标签划分如下：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>Keynote</li><li>核心技术</li><li>平台建设</li><li>行业案例</li><li>流批一体</li><li>实时数仓</li><li>Lakehouse</li><li>数据集成</li><li>OLAP</li><li>AI &amp; 特征工程</li><li>其他</li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>作为国内规模最大的开源顶级项目技术峰会之一，Flink Forward Asia 致力于集结领先的行业实践与技术动态，参与者多为业界资深从业者。参与 Flink Forward Asia 议题分享，不仅可以同各技术领域顶级专家面对面交流，探索数字化技术下的未来趋势，同时还能结交到一批志同道合的朋友，学习业内最富价值的一线内容，不容错过。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><strong>如果您对以上任意技术方向有积累与洞察，欢迎投递议题！</strong>每位嘉宾最多可以投递三个 Topic，投递日期截止至 10 月 14 日。过程中如有问题，可以添加下方微信沟通咨询。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:FF6a00"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsurvey.aliyun.com%2Fapps%2Fzhiliao%2F081fLSOu4" rel="nofollow" target="_blank">点击投递议题</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img height="816" src="https://oscimg.oschina.net/oscnet/up-02e8e2191265ae6a5f0ccc455b7643eae79.png" width="799" referrerpolicy="no-referrer"></p><span id="OSC_h2_5"></span><h2><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>赞助与合作</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h2><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>本届会议赞助商与合作伙伴招募中，如有合作意向可添加工作人员微信详询👇</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img height="816" src="https://oscimg.oschina.net/oscnet/up-f1dd4ea0ea65232857cc461e6e212498bff.png" width="799" referrerpolicy="no-referrer"></p><span id="OSC_h2_6"></span><h2><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>更多推荐：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h2><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU3Mzg4OTMyNQ%3D%3D%26mid%3D2247501266%26idx%3D2%26sn%3De6b05a7e43a6dbaaa7cb71a4a8b5a7cc%26chksm%3Dfd384b90ca4fc286f4a02877adad726e13a201f76b8dabe7f27e98acb71c252e3fcdf3d88441%26scene%3D21%23wechat_redirect" rel="nofollow" target="_blank">投入上百人、经历多次双 11，Flink 已经足够强大了吗？</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU3Mzg4OTMyNQ%3D%3D%26mid%3D2247500740%26idx%3D1%26sn%3De902b00fc01bec346012d50ab86c2b33%26chksm%3Dfd384d86ca4fc490db02dd2464fa6d778811bfd5af63d88645bc3f8a1c32ca4491c75e808fd9%26cur_album_id%3D1929705819747467266%26scene%3D189%23wechat_redirect" rel="nofollow" target="_blank">FFA 议程上线！实时化浪潮下，Apache Flink 还将在大数据领域掀起怎样的变革？</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU3Mzg4OTMyNQ%3D%3D%26mid%3D2247494243%26idx%3D1%26sn%3D6c254c281c247b21275fdab043d449f0%26chksm%3Dfd386421ca4fed37a8fef4ca1b6776e1c5f15de32596f692b23f770240a371d48731633dfba6%26cur_album_id%3D1929705819747467266%26scene%3D189%23wechat_redirect" rel="nofollow" target="_blank">实时即未来！Flink Forward Asia 2021 议程正式上线！</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU3Mzg4OTMyNQ%3D%3D%26mid%3D2247489706%26idx%3D1%26sn%3D65afb0e5b1f46743c2b8792553a9f9c4%26chksm%3Dfd3b96e8ca4c1ffe1485276efaa24344232c249904e52c241d7e6b252ef1214a150c16c15509%26cur_album_id%3D1929705819747467266%26scene%3D189%23wechat_redirect" rel="nofollow" target="_blank">重磅发布！Flink Forward Asia 2020 在线峰会预约开启！</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><hr><span id="OSC_h2_7"></span><h2><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>更多内容</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h2><p style="margin-left:0; margin-right:0; text-align:start"><img height="692" src="https://oscimg.oschina.net/oscnet/up-932b84d0cda4d97e3a606851bb6ff2da0b0.png" width="1992" referrerpolicy="no-referrer"></p><span id="OSC_h3_8"></span><h3><span><span><span><span><span style="color:#181818 !important"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>活动推荐</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></h3><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span><span style="color:#24292e"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>阿里云基于 Apache Flink 构建的企业级产品-实时计算 Flink 版现开启活动：<br> 首购 99 元包月试用，有机会赢取定制周边礼品！<br> 产品官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aliyun.com%2Fproduct%2Fbigdata%2Fsc" rel="nofollow" target="_blank">https://www.aliyun.com/product/bigdata/sc</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0px; margin-right:0px; text-align:start"><img height="1096" src="https://oscimg.oschina.net/oscnet/up-1584ed402396b0e870a64f15854ee703619.png" width="1990" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 19 Sep 2023 07:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/2828172/blog/10109980</guid>
            <link>https://my.oschina.net/u/2828172/blog/10109980</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[马斯克考虑向所有推特用户收费]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvariety.com%2F2023%2Fdigital%2Fnews%2Felon-musk-charge-all-x-twitter-users-fee-1235726693%2F" target="_blank">据外媒报道</a>，当地时间周一，在与以色列总理本雅明·内塔尼亚胡（Benjamin Netanyahu）就人工智能展开的广泛对话中，<strong>马斯克提出了向 X/Twitter 的所有用户收费的想法，以解决社交媒体机器人的问题</strong>。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/0919/125604_Xwg2_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>马斯克表示，将开始每月向 X/Twitter 用户收取少量费用。他提到 X 有 5.5 亿月活跃用户，每天在该社交网络上发布 1 亿至 2 亿条帖子。</p><p>马斯克没有提到向 X/Twitter 用户收费的时间，也没有说费用是多少。他声称，这是消除机器人问题的唯一方法。</p><p>马斯克去年 10 月 27 日以 440 亿美元的价格收购 Twitter。收购推特后，一些广告客户因对马斯克的内容审核计划感到担忧纷纷撤出，导致推特的广告收入大幅下降。</p><p>自 2022 年 10 月收购 Twitter 以来，马斯克一直在对该平台进行改革，比如，将员工人数缩减约 80%，推出三层 API 收费制度以及每月 8 美元的 Twitter Blue 付费认证服务。</p><p>此外，马斯克还为该公司任命了新的首席执行官琳达·亚卡里诺（Linda Yaccarino），试图赢回广告商。</p><p>今年 7 月 1 日，马斯克宣布将对用户每天可以浏览的推文数量进行临时限制。他声称，这是为了解决极端的数据抓取和系统操纵问题，这些问题可能被用来传播错误信息和操纵公众舆论。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 19 Sep 2023 04:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258652/elon-musk-charge-all-x-twitter-users-fee</guid>
            <link>https://www.oschina.net/news/258652/elon-musk-charge-all-x-twitter-users-fee</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[工信部：优先开展「元宇宙+工业制造」等行业应用标准研制]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">工信部科技司就《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fkjs%2Fjscx%2Fbzgf%2Fart%2F2023%2Fart_115c3d913ff44ca2976df4894374f348.html" target="_blank">工业和信息化部元宇宙标准化工作组筹建方案（征求意见稿）</a>》公开征求意见，截止日期 2023 年 10 月 18 日。</span></p><p><span style="color:#000000">工信部表示，加快开展元宇宙领域标准化工作，统筹推进元宇宙行业标准需求研究和重点标准研制，是深入贯彻落实《国家标准化发展纲要》《新产业标准化领航工程实施方案 (2023－2035 年)》《元宇宙产业创新发展三年行动计划 (2023－2025 年)》的重要举措。</span></p><p><span style="color:#000000">当前，元宇宙正处于快速发展阶段，面临认识不统一、应用不规范、伦理问题突出等挑战，亟须通过标准规范和引导元宇宙行业健康有序发展。而国内企业近期紧跟元宇宙国际发展形势，纷纷加大研发投入，积极布局元宇宙应用，已具备开展标准化工作的基础条件。我国需尽快组织国内重点企业、科研院所等优势资源，加强元宇宙行业标准化工作，并推动我国优秀实践方案成为国际标准，提升产业综合竞争力。</span></p><p><img height="245" src="https://oscimg.oschina.net/oscnet/up-9b6ff160913aa37ee2a89f09ee20ab45c06.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">根据《征求意见稿》，工信部元宇宙标准化工作组工作范围包括：</span></p><p><span style="color:#000000">（一）研究分析元宇宙领域标准化需求方向，建设和维护元宇宙行业标准体系，提出元宇宙领域行业标准制修订项目建议；</span></p><p><span style="color:#000000">（二）开展元宇宙领域行业标准的制修订工作；</span></p><p><span style="color:#000000">（三）预研元宇宙在工业制造、通信等领域应用标准，以及数字身份、虚拟数字人等相关领域关键技术标准；</span></p><p><span style="color:#000000">（四）开展元宇宙领域的标准宣贯、应用推广以及人才培训等工作；</span></p><p><span style="color:#000000">（五）积极对接元宇宙国际标准化组织，适时提出、参与元宇宙国际标准的制修订工作。</span></p><p><span style="color:#000000"><img height="238" src="https://oscimg.oschina.net/oscnet/up-98b0f959e9024bd923f9f071adde962e028.png" width="500" referrerpolicy="no-referrer"></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span style="color:#000000">成立后工作计划包括：</span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span style="color:#000000"><strong><strong>（一）</strong></strong><strong><strong>加强标准顶层设计，</strong></strong><strong><strong>梳理标准化路线图</strong></strong><strong><strong>。</strong></strong>结合前期研究基础，组织国内元宇宙产学研用各方，加强体现元宇宙典型特征的标准体系研究和完善，编制元宇宙标准化路线图，明确标准化重点方向和研制顺序，成套成体系开展元宇宙标准制定。</span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span style="color:#000000"><strong><strong>（二</strong></strong><strong><strong>）</strong></strong><strong><strong>聚焦</strong></strong><strong><strong>行业</strong></strong><strong><strong>发展需求，加快重点标准研制。</strong></strong>按照急用先行的原则，重点加快研制元宇宙术语、参考架构等基础通用标准，元宇宙身份体系、数字内容生成、跨域互操作等关键技术标准，优先开展「元宇宙+工业制造」等行业应用标准研制。</span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span style="color:#000000"><strong><strong>（三</strong></strong><strong><strong>）</strong></strong><strong><strong>强化前沿技术融合</strong></strong><strong><strong>，</strong></strong><strong><strong>推动行业标准预研。</strong></strong>面向隐私保护、内容监管、数据安全等元宇宙领域中新技术、新产品、新业态、新模式，加快开展关键技术和产业发展研究，加强与脑机接口、生成式人工智能、量子信息等领域技术融合创新。</span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span style="color:#000000"><strong><strong>（四</strong></strong><strong><strong>）</strong></strong><strong><strong>开展</strong></strong><strong><strong>标准</strong></strong><strong><strong>贯标推广</strong></strong><strong><strong>，</strong></strong><strong><strong>促进</strong></strong><strong><strong>标准应用实施。</strong></strong>开展工业元宇宙、城市元宇宙、虚拟数字人等应用标准研究，指导行业协会、标准化专业机构和技术组织，面向元宇宙产业的生产方、使用方开展标准宣贯，引导企业在研发、生产、管理等环节对标达标，提升标准应用的有效性。</span></p><p style="text-align:justify"><span style="color:#000000"><strong><strong>（五</strong></strong><strong><strong>）</strong></strong><strong><strong>加快</strong></strong><strong><strong>国际标准</strong></strong><strong><strong>布局</strong></strong><strong><strong>，提升</strong></strong><strong><strong>未来</strong></strong><strong><strong>产业竞争。</strong></strong>鼓励国内企事业单位深度参与国际标准化活动，基于我国优势技术和丰富的应用场景，适时提出国际标准提案。依托国内元宇宙行业标准化工作基础，积极推动在 ISO、IEC、ITU 等国际标准化组织成立元宇宙标准化相关组织，提升我国元宇宙产业综合竞争力。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 19 Sep 2023 03:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258645</guid>
            <link>https://www.oschina.net/news/258645</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google 上线网页版 Emoji Kitchen —— Emoji 表情合成]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Google 上线了网页版「Emoji Kitchen」。该功能允许用户选取两个 emoji，由此生成一个新 emoji。</p><p>Emoji Kitchen 此前只在 Gboard Android 版提供。目前可以在 Google 搜索栏搜索 Emoji Kitchen 开始使用。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e37339a80b692e4416f0ec2ddafed13766d.png" referrerpolicy="no-referrer"></p><p>Emoji Kitchen 是谷歌 Gboard 键盘于 2020 年新增加的一个表情创意功能。该功能允许 Android 用户将两个 emoji 表情符号合成制作出表情包后，发送出去。</p><p>现在无论是 Google Chrome 或者 Safari，移动端还是桌面端，只要在 Google 搜索栏输入「Emoji Kitchen」即可体验这款合成 emoji 的产品。</p><p><img height="851" src="https://static.oschina.net/uploads/space/2023/0919/104120_pPak_2720166.png" width="1096" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 19 Sep 2023 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258637</guid>
            <link>https://www.oschina.net/news/258637</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中国这么多 Java 开发者，应该诞生出生态级应用开发框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>1、必须要有，不然就永远不会有</h3><p style="color:#24292e; text-align:start">应用开发框架，虽然没有芯片、操作系统、数据库、编程语言这些重要。但是最终呈现在用户面前的，总是有软件部分。而软件系统开发，一般都需要应用开发框架，它是软件系统的基础性部件之一。</p><p style="color:#24292e; text-align:start">很多很多软件系统都会有 Java 开发的部分，尤其是<strong>政府部门的软件系统</strong>大量的使用了 Java。市场非常的大，我们有很多的 Java 程序员，更有很多技术大能，也为很多全球级的项目供献过力量。理所应该当也要有自己的「生态级」应用开发框架，不是说卡不卡脖子的问题，而是不好意思没有啊！外面可是隔三差五的出语言。</p><p style="color:#24292e; text-align:start">国内现在有很多好的「功能性能开发框架」，也有很多好的「快速开发框架」，还有很多好的「后台脚手架」。但是没有像 Spring 这样生态级的框架出现。个人觉得，这应该是有问题的、是可惜的、是遗憾的。</p><p style="color:#24292e; text-align:start">想要搞个 Java 生态级的应用开发框架。一般是以年为开发时间单位的（需要漫长的时间打磨），一般是不赚钱的。还有 Spring 生态这个巨人存在。但，真的有很多人是期待的：一个轻量的，更现代感的，最好还是国产的。</p><p style="color:#24292e; text-align:start">刚开始的确会很难；刚开始可能不如人家的完善；刚开始会有很多人质疑和漫骂。再难能有芯片难？？？不是说非要替换代别人，<span style="background-color:#f1c40f">而是必须要有，不然就永远不会有</span>。</p><h3>2、一个美好的「生态级」应用开发框架</h3><p style="color:#24292e; text-align:start">应该是所有「功能型」框架的好朋友，就像水、土、空气一样<span style="background-color:#f1c40f">串起万物生长</span>；应该是<span style="background-color:#f1c40f">接地气</span>些，方便所有技术员快速学习和使用。比如：</p><ul><li>应该能自动装配扩展能力（方便做第三方扩展）</li><li>应该有很多的第三方合作与便利适配（生态嘛）</li><li>应该有 IOC 和 AOP（确实更便利）</li><li>应该启动很快（必须要远超它的前辈）</li><li>应该内存更少，尤其是在启动时和静默时的内存（休息时，不该吃那么多内存）</li><li>应该很少量的代码（不然学习太幸苦了）</li><li>应该有自己的思考方式和性格特性（抄过来的不好）</li></ul><p style="color:#24292e; text-align:start">其实要求也不高，只要道心稳，慢慢打怪升级。最近有位技术大牛说：国外有 spring 和 apache，<strong>国内有 solon 和 dromara</strong>。</p><h3>3、论 Solon 框架的意义</h3><p style="color:#24292e; text-align:start">是一个国产的生态级 Java 应用开发框架（已发具备全球第二级别的生态）。开玩笑，两三百个生态扩展呢。</p><ul><li>国内第一个</li></ul><p style="color:#24292e; text-align:start">从零开始构建，有自己的标准规范与开放生态。尤其没有使用 javaee 的接口规范（它改包名了，可麻烦）。会借鉴与善用前人的成果，但绝对是原创。</p><ul><li>为什么说是生态呢</li></ul><p style="color:#24292e; text-align:start">没有功能，没有集成。都是基于标准与规范的扩展与适配。同一个需求，可以有很多不同的方案选择。这是架构的美感。当然别人家的生态框架也会是这样。</p><ul><li>提供不同的选择</li></ul><p style="color:#24292e; text-align:start">以前只有包子，没得选，不管什么场景只有包子吃。而且很多人都习惯了这样。<span style="background-color:#f1c40f">现在是还有面条和米饭，你可以按需选择</span>。</p><ul><li>助力信创国产化</li></ul><p style="color:#24292e; text-align:start">信创，讲国产可控。但是很多软件系统用了 spring 开发。之前是没得选。现在可以用 solon 了。</p><ul><li>助力国产语言的成长</li></ul><p style="color:#24292e; text-align:start">当有适合的国产语言出现时，可以快速实现副本迁移。因为 solon 是原创，有自己的标准规范与开放生态，迁移起来很方便。开发语言，有好的生态框架，能优化用户体验，加速成长。</p><ul><li>助力部训机构使用国产框架进行 Java 教学</li></ul><p style="color:#24292e; text-align:start">一个生态级的应用开发框架。无形之中，会有很多模式，有很多术语。应用于教学，对国产开发环境是好事。</p><ul><li>助力高校使用国产框架进行 Java 教学</li></ul><p style="color:#24292e; text-align:start">Solon 的愿景里，会有很多相关书出现。以 Solon 的视角去展现 Java。 以前是没得选，以后可以选 Solon 相关的书，进行教学。</p><ul><li>助力 Java 开源项目成长</li></ul><p style="color:#24292e; text-align:start">以前嘛，我们的 Java 开源项目很多是「面向 Spring 编程的」。现在可以回归本源，「面向 Java 编程」（同时也适配下 Solon）。Java 的世界很大，有很多的不同的生态框架。</p><ul><li>助力 Java 程序员的成长</li></ul><p style="color:#24292e; text-align:start">有些 Java 程序员，如果没有 Spring 是不能编程的。其实 Java 的世界很大，Java 之外的世界更大。见识不同的生态应用开发框架，见识不同的编程语言，可以看见更大的世界。</p><h3>4、Solon 生态框架是应运而生的</h3><p style="color:#24292e; text-align:start">这不是吹牛，之前真的是没有，<span style="background-color:#f1c40f">这是第一个生态级的</span>。打磨五六年了。暂时，它还真是中国人的 Java 生态框架（没别的啦）。</p><p style="color:#24292e; text-align:start">特性：</p><ul><li>启动快 5 ～ 10 倍。<span>&nbsp;</span><strong>（更快）</strong></li><li>qps 高 2～ 3 倍。<span>&nbsp;</span><strong>（更高）</strong></li><li>运行时内存节省 1/3 ~ 1/2。<span>&nbsp;</span><strong>（更少）</strong></li><li>打包可以缩小到 1/2 ~ 1/10；比如，300Mb 的变成了 23Mb。<span>&nbsp;</span><strong>（更小）</strong></li><li>同时支持 jdk8, jdk11, jdk17, jdk21,<span>&nbsp;</span><strong>graalvm native image</strong></li></ul><p style="color:#24292e; text-align:start">简介：</p><ul><li><strong>克制、简洁、高效、开放、生态</strong></li><li>支持 JDK8、JDK11、JDK17、JDK20（是同时支持）</li><li>Http、WebSocket、Socket 三种信号统一的开发体验（俗称：三源合一）</li><li>支持「注解」与「手动」两种模式，按需自由操控</li><li>Not Servlet，可以适配任何基础通讯框架（最小 0.3m 运行 rpc 架构）</li><li>独特的 IOC/AOP 容器设计。不会因为插件变多而启动变很慢</li><li>支持 Web、Data、Job、Remoting、Cloud 等任何开发场景</li><li>兼顾 Handler + Context 和 Listener + Message 两种架构模式</li><li>强调插件式扩展，可扩展可切换；适应不同的应用场景</li><li>支持 GraalVm Native Image 打包</li><li>允许业务插件「热插」、「热拔」、「热管理」</li></ul><p style="color:#24292e; text-align:start">预览：</p><pre><code class="language-java"><span style="color:#4078f2">@Controller</span><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">App</span> {
    <span style="color:#a626a4">public</span><span style="color:#a626a4">static</span><span style="color:#a626a4">void</span><span style="color:#4078f2">main</span><span>(String[] args)</span> {
        Solon.start(App.class, args, app -&gt; {
            <em>//手写模式</em>
            app.get(<span style="color:#50a14f">"/hello1"</span>, ctx -&gt; ctx.output(<span style="color:#50a14f">"Hello world!"</span>));
        });
    }

    <em>//注解模式</em><span style="color:#4078f2">@Get</span><span style="color:#4078f2">@Socket</span><span style="color:#4078f2">@Mapping("/hello2")</span><span style="color:#a626a4">public</span> String <span style="color:#4078f2">hello2</span><span>(String name)</span> {
        <span style="color:#a626a4">return</span> String.format(<span style="color:#50a14f">"Hello %s!"</span>, name);
    }
}
</code></pre><h3>5、什么样的 Java 项目用 Solon 好</h3><p style="color:#24292e; text-align:start">就像华为讲的，不要因为爱国而特意买华为手机。Solon 也是，有需要就用不需要就跳过（<span style="background-color:#f1c40f">按正常的需求选择</span>）：</p><ul><li>信创需要国产化，应该用 Solon 或者 Solon Cloud（有案例）</li><li>军工项目要国产化，应该用 Solon 或者 Solon Cloud（有案例）</li><li>嵌入式设备，内存有限，算力差，可以用 Solon 或者 Solon Native（有案例）</li><li>客户的希望你内存更少，可以用 Solon （有案例）</li><li>别的框架用腻了，可以用 Solon （有案例）</li><li>有新系统开发想尝新的框架，可以用 Solon （有案例）</li><li>老系统要轻量化改造，可以用 Solon（有案例）</li></ul><p style="color:#24292e; text-align:start">作为后来者，大家的疑或是会多一些。有问题，可以去交流群里多交流。</p><h3>6、Solon 的代码仓库</h3><p style="color:#24292e; text-align:start">喜欢 Solon 的，可以帮助宣传。喜欢但觉得不够好的，可以助其成长。不方便切换框架的，也可支持：</p><ul><li><a href="https://gitee.com/noear/solon">https://gitee.com/noear/solon</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnoear%2Fsolon" target="_blank">https://github.com/noear/solon</a></li></ul><p style="color:#24292e; text-align:start">「<span style="background-color:#f1c40f">众人拾柴火焰高</span>」，支持它、使用它、传播它、一起供献代码：）</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 19 Sep 2023 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258633</guid>
            <link>https://www.oschina.net/news/258633</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微调语言模型前，需要考虑这三个关键方面]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>编者按：随着大语言模型 (LLM) 的迅速发展，越来越多团队希望针对特定领域进行模型微调。但是实践运用中总是存在一些困难，直接应用并不总是能达到理想效果。</p><p>本文着重探讨了三个关键问题:</p><ul><li>利用强大模型 (如 ChatGPT) 的输出结果来微调较弱模型是否有效？</li><li>如何选择是采用低成本的上下文学习还是对模型进行微调？</li><li>如何处理超过模型上下文限制的长文本，让模型理解并回答关于长文本的复杂问题？</li></ul><p>此篇文章探讨了构建特定垂直领域语言模型时需要考虑的关键因素，能够帮助读者在微调大语言模型时做出明智的决策。我们衷心期望本次内容分享能帮助更多团队高效地获得所需的垂直领域大模型。</p><p>以下是译文，enjoy！</p></blockquote><p><strong>🚢🚢🚢欢迎小伙伴们加入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaihai-idp.yuque.com%2Fmwvla8%2Fdoc%3F%23" target="_blank">AI 技术软件及技术交流群</a>，追踪前沿热点，共探技术难题~</strong></p><p><strong>作者 | Sean Smith</strong></p><p><strong>编译 | 岳扬</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-1f811a62864704138c6ffe1633ea11b66e6.png" alt="" referrerpolicy="no-referrer"></p><p><em>Photo by Brett Jordan on Unsplash</em></p><p>目前，市场正处于 LLMs（大语言模型）和生成式人工智能的风口上。IBM 的一项数据显示，将近三分之二的企业高管感受到了来自投资者的压力——要求他们加快使用生成式人工智能。自然而然，这种压力也传导到了数据科学和机器学习团队，他们肩负着抓住机遇、成功应用生成式 AI 的重任。</p><p>随着形势的发展，LLMs 的生态系统迅速分化为开源和商业化两种模式，「护城河」正被迅速填平。这一前所未有的局面促使许多团队思考一个问题：我们如何使 LLM 更贴近我们的具体需求？</p><p>在本文中，我们细致探讨了构建一款特定垂直领域的 LLM 所需考虑的一些关键因素，包括投入时间和工程周期等，这些因素我们应该牢记在心。在这一过程中，必须了解最新的相关研究，特别是针对微调大语言模型的潜在局限性和最佳实践方面的研究。阅读完本文后，您将掌握更多的决策思路，从而引导公司做出正确的决定：训练还是不训练，以及如何训练。</p><h1>01 <strong>可能无法通过开源模型来模仿 GPT</strong></h1><p>众所周知，OpenAI 凭借其最新版本的 GPT 在 LLM 领域处于领先地位。因此，出于各种原因（速率限制、数据隐私、成本等），许多利益相关方可能会要求开发团队开发部署比 GPT 效果更好的模型。这自然而然地使开发人员产生疑问：我们能否从 GPT 中生成输出结果，并利用它们对模型进行微调？</p><p>对于这个问题的答案仍不确定，因为其似乎取决于多个因素。这项特殊的任务被称为模仿学习（imitation learning），其涉及到使用来自更高级模型（如 GPT）的响应结果来微调、训练一个全新的语言模型。虽然这看起来是一种从下游模型（downstream model）中提取良好性能的好方法，但这种方法也存在一些不明显的问题。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d8980c9e83809a46c9e9162febbceda9048.png" alt="" referrerpolicy="no-referrer"><em>图表摘自参考文献 [1]，Gudibande 等人</em></p><p>最近一篇题为《The False Promise of Imitating Proprietary LLMs》[1] 的论文揭示了使用这种方法可能会存在的一些隐患。作者通过进行实验证明，增加许多「模仿」数据可能会导致模型性能下降。观察上图，我们可以在中间的图表中发现：随着 tokens 数量的增加，基准任务的准确性确实在下降。但是，为什么会出现这种情况呢？</p><p>作者认为这是因为模仿模型（imitation models）学习的是其所模仿的模型的内容风格，而不是学习和理解模型输出的内容。从上图左侧的图表可以看出，人类评审员更喜欢模仿模型的输出结果，而非 ChatGPT。经过探讨可以发现，评审员明显更喜欢模仿模型（imitation models）的内容风格，但并没有仔细审查输出内容。值得注意的是，模仿模型产生的内容往往缺乏事实依据，导致作者总结道： <strong>「模仿模型实际上体现的是 AI 助手最糟糕的一些方面：它们的回答听起来很自信，但比 ChatGPT 的回答更缺乏事实依据。」</strong></p><p>值得注意的是，在某些情况下，模仿模型（imitation models）可以取得出色的表现。作者指出，在本地任务或者复制教师模型（teacher model）的特定行为的任务上，模仿模型可以取得良好的性能。在一项名为 "NQ-Synthetic "的研究任务中，作者要求大语言模型根据给定的语境生成 10 个相关问题和答案。令人惊讶的是，模仿模型的得分接近于 GPT 的得分。这表明，在尝试模仿教师模型的行为时，更加专注于特定领域的模型可能会取得更好的表现。</p><p>文章中提到的一个有趣的推论，使用教师模型对模型进行微调实际上有助于降低模仿模型的 toxic（内容毒性）分数。这对于那些希望快速推出一款开源 LLM（大语言模型），而不想费力围绕输出构建内容过滤器的公司来说非常有用。相较于手动构建内容过滤器，公司可以选择使用经过精心处理的数据集，通过从教师模型获取的输出进行训练，以获得一个可靠的基座。</p><p>值得一提的是微软研究院最近发布的 Orca 模型，它将来自 GPT 的信息或指导（signals）作为训练数据的一部分。两者的区别在于模型所使用的训练数据的大小。Orca 模型在 500 万个示例的基础上进行微调，而全面的模仿模型仅在大约 15.1 万个可观测数据上进行了调优。由于我推测大多数读者不会花费 16000 美元来进行一个随意的 LLM 实验，所以我更倾向于参考构建模仿模型相关的论文而非 Orca 模型进行陈述。然而，我们仍需等待更多研究结果，以明确确定模仿学习作为用于更全面任务的可行方案所需的最少示例数量。</p><p><strong>总结：由于任务的复杂程度不一，尝试用一个性能较弱的模型去模仿 GPT 或其他高级模型的输出可能导致模型性能不佳。</strong></p><h1>02 <strong>仅凭上下文学习就足够了吗?</strong></h1><p>上下文学习 (In-context learning)，也称为少样本学习，是一种在 prompt 中加入需要完成的特定任务示例的过程。这种方法主要适用于复杂的大语言模型，因为大部分小型开源模型尚未具备所需的灵活性（flexibility）来完成上下文学习。通常情况下，通过这种方法可以取得很好的效果，但是你是否曾想过为什么会这样呢？</p><p>Dai 等人[3]的论文探讨了这个问题的答案，他们在论文中研究了在 prompt 中加载示例和使用相同示例对大模型进行微调之间的数学联系。作者证明，prompt 示例会产生元梯度（meta-gradients），这些元梯度会在推理时的前向传播过程（forward propagation）中得到反映。而在微调时，这些示例产生了用于更新权重的真实梯度（real gradients）。因此，似乎上下文学习可以实现与微调类似的效果。如果想要更深入地了解这些内容，我建议阅读这篇论文，其中详细介绍了这些数学联系的具体细节。</p><p>虽然上下文学习的方法很好，但确实存在微调所不具备的局限性。在我们拥有大量训练数据时，微调后的模型会在训练过程中使用真实梯度更新模型，从而利用所有数据。而在上下文学习过程中，我们只能提供有限数量的可观测数据。于是，一个新问题便出现了：在给定大量训练数据的情况下，我们如何才能利用与我们的输入最相关的示例来获得最佳模型响应？</p><p>解决该问题的一种有效方法是使用启发式算法来选择示例，目前 LangChain 提供了对此算法的支持。LangChain 是一个 Python 模块，基本上包含了预构建的提示（pre-built prompts），可以简化语言模型的工作。我们现在需要重点关注的 LangChain 工具是 ExampleSelector（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpython.langchain.com%2Fdocs%2Fmodules%2Fmodel_io%2Fprompts%2Fexample_selectors%2F%EF%BC%89%E3%80%82" target="_blank">https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/）。</a></p><pre><code class="language-python">def get_similarity(seq_a: str, seq_b: str) -&gt; Union[float, int]:
 """ 
    Make a similarity heuristic,
    here we use Jaccard similarity or IOU
 
    seq_a: First sequence to compare
    seq_b: Second sequence to compare
 
    Returns:
    Similarity score (float or int)
    """
 # Tokenize
    set_a = set(seq_a.split(' '))
    set_b = set(seq_b.split(' ')) 
 
 # Calculate IOU/Jaccard similarity
 return len(set_a.intersection(set_b)) / len(set_a.union(set_b))

def example_selector(examples: List[str], input: str, examples2use: int) -&gt; List[str]:
 """ 
    Pseudo code for an example selector
 
    examples: List of training corpus
    input: Target sequence to translate
    examples2use: Number of examples to use
 
    Returns:
    List of selected examples
    """
    scores = [get_similarity(example, input) for example in examples]
    sorted_idx = [i for i, _ in sorted(enumerate(scores), key=lambda x: x[1], reverse=True)]
 return examples[sorted_idx[:examples2use]]
</code></pre><p>ExampleSelectors 是一种 prompt 操作器，该工具允许我们在推理时动态地改变使用的示例。有许多启发式算法可以使用。上面我给出了一些伪代码，是想要告诉大家 LangChain 的选择器本质上是如何工作的。我在输入序列和示例序列之间使用了 Jaccard 相似度。（译者注：Jaccard 相似度是衡量两个集合的相似度一种指标，本质上是集合的交集与集合的并集的比例）</p><p>采用该种方法有两个主要优点。首先，可以根据给定的输入，有选择性地选择最相关的示例，从而使 LLM 更高效的利用数据。这有别于为所有可观测结果（observations）静态加载几个示例的做法。如果通过托管服务进行调整，另二个优点是可以节约成本。截至目前，使用经过微调的 Davinci 模型的成本为每 1000 个 token 0.12 美元。相比之下，使用 instruct Davinci 的价格为 0.02 美元，前者价格为后者的 500%！还不包括模型训练费用。</p><p>需要注意的是，正如一篇现已删除的博文[5]所透露的那样，由于 OpenAI 尚未使用 LoRa 或 Adapters，这些价格后续可能会发生变化。尽管如此，由于必须为每个用户维护自定义的权重，微调模型的价格可能仍然会更高。此外，这还没有考虑到上下文中示例的成本。您的团队需要从成本和准确性等角度，去评估是上下文学习（ICL）还是微调（fine-tuning）对完成目标任务更有意义。</p><p><strong>Takeaway：使用动态示例加载的上下文学习在某些场景下可以达到与微调相同的效果，相对成本会更低。</strong></p><h1>03 <strong>在进行最终的推理步骤之前，执行目标任务是否需要一个或多个中间步骤？</strong></h1><p>比方说，要求模型尝试回答关于长文档的复杂问题。这种任务一般都要求大语言模型具备良好的语言掌握能力和理解能力。这样又会引出一个问题：<strong>如果我们帮助语言模型将推理过程分解为多个子任务执行，类似于人类分析文档并按顺序执行任务，会怎么样呢？</strong><img src="https://oscimg.oschina.net/oscnet/up-6c47120688c52ada730c45b129476e8ae9e.png" alt="" referrerpolicy="no-referrer"><em>图摘自 Sun 等人的文章[4]</em></p><p>这正是微软公司的研究人员想要实现的目标，他们解决这一问题的方案是 PEARL[4]。PEARL 是 Planning and Executing Actions for Reasoning over Long documents 的缩写，意为 "长文档推理的规划和操作执行"。这个通用框架主要分为三个步骤：</p><ul><li><strong>行为挖掘（Action Mining）</strong> ：首先，通过 prompt 让语言模型阅读文档，并提取可用于回答特定领域问题的可行行为。为了提取这些行为，语言模型通常会给出一些示例的行为方式。后续我将给出关于「行为 action」的示例。</li><li><strong>规划生成（Plan Generation）</strong> ：在生成一组用于目标任务的操作方案之后，需要要求 LLM 根据问题和上下文生成一系列需要按顺序执行的操作流程。LLM 会提供一些其他目标任务的规划样例，以帮助构建高质量的操作流程规划。更多技术细节可以在论文中找到。</li><li><strong>执行规划（Plan Execution）</strong> ：模型有了操作流程规划之后，将用户输入提供给模型并执行操作流程规划。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-aabd017db2791fdb2c2e927ff693c01c8e3.png" alt="" referrerpolicy="no-referrer"><em>行为示例，摘自 Sun 等人的文章[4]</em></p><p>在上述各个阶段之间，还有一些中间步骤被用来确保目标任务的执行效果质量。作者们设置了一个自纠正步骤（self-correction step），确保计划符合所需的格式。还有一个自完善步骤（self-refinement），用于确定此操作流程规划是否可以作为后续用于【规划生成】流程的小样本示例使用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-cfdea2ed47fc6e79d42be2a08ac03431893.png" alt="" referrerpolicy="no-referrer"><em>摘自 Sun 等人的文章[4]的表格</em></p><p>在进行评估时，发现 PEARL 相较于其他 GPT 模型拥有明显的性能改进。于是可以得出结论，在某些情况下，将目标任务的解决方案划分为多个步骤可以较明显地帮助模型提升性能。</p><p>还有另一个情况，<strong>当上下文中的文档数量超过语言模型所支持的数量时，设置一些中间步骤也被证明是有利的。</strong> 目前，OpenAI 使用的注意力机制的计算复杂度为 O(n²)，暂时还没有解决这一问题的具体方案[5]。因此，大家都对如何将上下文减少到尽可能最小的形式十分感兴趣。</p><p>对于不同的目标任务，有不同的处理方法。例如，如果目标任务完全围绕实体展开，就有机会提取相关实体及其相关属性。（译者注：在处理文本时，可以识别出文本中的特定实体（如人名、地点、组织等），并提取这些实体的相关属性（如年龄、地址、职位等）。通过这种方式，可以将文本中的信息转化为结构化的形式，使得对实体和属性的理解更加明确和系统化。这样可以为后续的任务提供更准确和有用的信息。）可以将这种方法看作是一种有损压缩，这种方法允许用户将更多上下文输入到 LLM 中。这一中间步骤的另一个好处是，可以将非结构化数据转换为结构化格式，这使得用户可以在不使用 LLM 的情况下也能进行明智的决策。下面是 Fei 等人的论文中展示的一个示例任务图表[6]。 <img src="https://oscimg.oschina.net/oscnet/up-314fc02a50eaadda5d463d83c4626b8dc31.png" alt="" referrerpolicy="no-referrer"><em>图摘自 Fei 等人发表的论文[6]</em></p><p><strong>Takeaway：将目标任务分解成较小的子任务，有助于将较复杂的问题简化为更易管理的部分，还可以利用这些较小的任务来解决与模型限制相关的性能瓶颈问题。</strong></p><h1>04 <strong>结束语</strong></h1><p>以上是研究人员在 LLM 性能和效率这一新领域探索的一些总体思路。这并非微调模型时需要考虑的所有事项，却是一个很好的起点，可以给我们提供一些参考。</p><p>如需进一步了解，Hugging Face 发表的这篇有关 LLM 训练的文章[7]非常有趣，对于在特定领域的问题上探索模仿模型来说是一个很好的开始。</p><p>再次概括本文要点：</p><ul><li>由于任务的复杂程度不一，尝试用一个性能较弱的模型去模仿 GPT 或其他高级模型的输出可能导致模型性能不佳。</li><li>使用动态示例加载的上下文学习在某些场景下可以达到与微调相同的效果，且成本较低。</li><li>将目标任务分解成较小的子任务，有助于将较复杂的问题简化为更易管理的部分，还可以利用这些较小的任务来解决与模型 Token 限制相关的性能瓶颈问题。</li></ul><p><strong>END</strong></p><h1><strong>参考资料</strong></h1><p>[1] Arnav Gudibande, Eric Wallace, Charlie Snell, Xinyang Geng, Hao Liu, Pieter Abbeel, Sergey Levine, &amp; Dawn Song. (2023). The False Promise of Imitating Proprietary LLMs.</p><p>[2] Mukherjee, S., Mitra, A., Jawahar, G., Agarwal, S., Palangi, H., &amp; Awadallah, A. (2023). Orca: Progressive Learning from Complex Explanation Traces of GPT-4. arXiv: Computation and Language.</p><p>[3] Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Shuming Ma, Zhifang Sui, &amp; Furu Wei. (2023). Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers.</p><p>[4]Simeng Sun, Yang Liu, Shuohang Wang, Chenguang Zhu, &amp; Mohit Iyyer. (2023). PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents.</p><p>[5] Habib, R.. (2023). OpenAI’s plans according to Sam Altman.</p><p>[6] Hao Fei , Fei Li , Chenliang Li , Shengqiong Wu , Jingye Li and Donghong Ji, (2022). Inheriting the Wisdom of Predecessors: A Multiplex Cascade Framework for Unifed Aspect-based Sentiment Analysis</p><p>[7] Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU (huggingface.co)</p><p><strong>本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。</strong></p><p><strong>原文链接</strong>：</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293" target="_blank">https://towardsdatascience.com/thinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293</a></p><p><strong>🚢🚢🚢欢迎小伙伴们加入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaihai-idp.yuque.com%2Fmwvla8%2Fdoc%3F%23" target="_blank">AI 技术软件及技术交流群</a>，追踪前沿热点，共探技术难题~</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 19 Sep 2023 02:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/10111244</guid>
            <link>https://my.oschina.net/IDP/blog/10111244</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Rust 团队前成员深感后悔，要求取消挂名，昨日完成移除]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>这事还要从 2023 年 9 月 8 日说起。</p><p>这一天，Rust 发布团队（Release Team）的成员 Jonas Schievink 在 Github 的 Rust 语言管理项目提了个 Pull Request，要求<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frust-lang%2Fteam%2Fpull%2F1071" target="_blank">把自己的名字从各项目中删除</a>，还在正文中要求把自己的名字从 Rust 语言官网撤下，明确表示自己退出 Rust 团队后不该继续挂名。</p><p>在这个 Pull Request 当中，Jonas Schievink 表示后悔自己参与了 Rust 项目。</p><p>翻译如下：</p><blockquote><p>我在今年稍早的时候就已经离开了 Rust 团队。这个 Pull Request 用来进一步地把我从「校友录」中移除，与我有关联的文件一并删除。</p><p>我也想请求 Rust 团从 rust-lang 组织各项目中，删掉我各个 commit 中的所有作者信息。</p><p>我不再希望以任何方式与 Rust 项目有关联，对曾经参与其中深感后悔。</p><p>Rust 项目一再辜负了自己的志愿者，破坏了社区项目，压制了公开讨论，而其领导层却总是在「关切」的虚名掩护下逃避责任。</p><p>最近 RustConf 主题演讲事件的懦夫式处理手法只是其中最新的例子，并且不太可能会是最后一个，即使领导架构改成了新的领导委员会。永久解决这些问题的唯一办法是，把那些需要对此负责的人，或者为之辩护的人，彻底驱逐出 Rust 项目。</p><p>我强烈建议 Rust 团队的所有志愿者重新认真考虑，你们是否值得自愿为这个组织付出。</p><p>此外，我敦促所有了解 Rust 项目的失败细节、但未公开表达的人问问自己：难道你们不觉得，对于那些想要置身参与 Rust 的人，应该告诉他们接下来会遇到什么事，免得他们陷入其中并把相同的经历重新体验一次？</p></blockquote><p>值得注意的是，这条 Pull Request 有 6 条讨论被删。</p><p>昨天（2023 年 9 月 18 日），也就是在 Pull Request 提交后的十天，Merge 操作终于完成，移除了这位前成员的名字。</p><p>根据「网站时光机」的存档对比，5 月份时 Jonas Schievink 的名字仍在列表上，现在已经从<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rust-lang.org%2Fgovernance%2Fteams%2Falumni" target="_blank">Rust 语言官网的「校友录」</a>的名单中消失。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 17:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258618</guid>
            <link>https://www.oschina.net/news/258618</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[BoringDB —— 基于 SQLite 的高性能键值数据库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>BoringDB 是基于 SQLite 采用 Rust 编写的高性能键值数据库。</p><p>BoringDB 有一个相当奇特的设计——它是功能非常齐全的 SQLite，提供了一个简单的键值 API。处理索引、ACID 事务等所有繁重工作。</p><p>SQLite 具有极高的可靠性，BoringDB 添加了一个缓存层和写入批处理，使得每秒操作数较高的键值任务（例如处理稀疏 Merkle 树分支）相当快。</p></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 10:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/boringdb</guid>
            <link>https://www.oschina.net/p/boringdb</link>
        </item>
        <item>
            <title>
                <![CDATA[任正非：我们即将进入第四次工业革命、苹果是华为的老师]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，ICPC 基金会主席及教练和世界计算机竞赛的金牌获得者前往华为考察。在此期间，华为创始人任正非表示，华为一直坚持开放和拥抱全球人才的原则，愿意与学术界共同培养信息领域的优秀人才。华为希望通过赞助竞赛和组织交流活动，促进全球信息产业的发展和各国信息领域人才的培养。</p><p>任正非强调，除了 ICPC 竞赛，华为也愿意赞助其他学科的竞赛，以此推动基础科学的人才培养。华为欢迎 ICPC 在华为园区举办比赛，并将对年轻人开放研发区，让他们体验华为的工作环境。同时，华为愿意面向全球优秀青少年开放技术难题和实习机会，帮助他们接触到华为的前沿技术，从而促进他们的成长和发展。</p><p>任正非表示，未知就叫科学，当今世界，科学和技术的边界越来越接近，科学转化为技术的时间越来越短，如果等到大学把理论完全研究明白再去进行技术开发，就已经没有先发优势，没有竞争力了，所以华为每年大约投入 30-50 亿美金用于基础理论研究，与大学一起共同研究看似无用的科学。</p><p>任正非表示，<strong>我们即将进入第四次工业革命，基础就是大算力</strong>，第四次工业革命波澜壮阔，其规模之大不可想象，今天的年青人是未来大算力时代的领袖，二三十年之内的人工智能革命，一定会看到年青人星光闪耀。</p><p>他还说道，华为一直坚持开放和拥抱全球人才的原则，愿意与学术界共同培养信息领域的优秀人才。华为希望通过赞助竞赛和组织交流活动，促进全球信息产业的发展和各国信息领域人才的培养。</p><p>此外，任正非与 ICPC（国际大学生程序设计竞赛）基金会及教练和金牌获得者的学生的谈话纪要也已公开。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a1c508c2ce7831689f3da34cc08ddee6dcb.png" referrerpolicy="no-referrer"></p><p>▲<u><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Ficpc.pku.edu.cn%2Fxwdt%2F152848.htm" target="_blank">http://icpc.pku.edu.cn/xwdt/152848.htm</a></u></p><hr><p>本次谈话纪要全文：</p><p>感谢 ICPC 基金会主席及十几位教练带了 58 位各国世界计算机竞赛的金牌获得者，来我们公司考察与竞赛。我们会继续支持你们的全球活动，也希望通过你们将全球大学生数学、物理、生物…… 竞赛引进来，我们同样给予赞助与支持。</p><p><strong>一、我们即将进入第四次工业革命，基础就是大算力，今天的年青人，明天有可能就是第四次工业革命的领袖。我们支持竞赛的目的是要为年青人搭建一个绽放生命火花的舞台。</strong></p><p>团队协作既是竞赛致胜的基础，也是维持生存的基础，更是人类更加繁荣的需要。我们需要彼此紧密合作，大家互相聚在一起，相互激发和挤压，就会有新的科学技术爆发出来。这次，来自 25 个国家的精英们欢聚一堂，我们认识了，就有了共同交流的平台。教练与学生、学生与学生、赛队与赛队之间可以互相激发，可能就留下了火种，擦出了火花，年青人们把火种带回祖国，去点燃了自己国家的大火。新的科学技术一定能创造更多的社会财富，消除贫困，使人类的生活能够改善，走共同富裕的道路。</p><p>第四次工业革命波澜壮阔，其规模之大不可想象。今天的年青人是未来大算力时代的领袖，人类社会对你们具有很大的期望，二三十年之内的人工智能革命，一定会看到你们星光闪耀。</p><p><strong>二、华为一贯秉持发现、发展人才，但绝不垄断人才的原则。坚持开放，拥抱全世界人才。</strong></p><p>世界的发展离不开技术的进步与人才的交流，更快的速度和更好的人才是国家繁荣的基础。华为愿意与学术界共同培养信息领域的优秀人才，但绝不垄断人才。这些人才在华为锻炼、学习、成长之后，将来各自回归他们的祖国，也有利于各国信息产业的振兴。</p><p><strong>三、对于竞赛，我们会长期稳定地支持发展，赞助全球和各区域大赛的组织。华为愿意赞助 ICPC 教练、参赛人员等来中国交流。华为资助竞赛不以华为为目的。我们不仅要坚持，还要加大对这类活动的赞助。</strong></p><p>支持未来 ICPC 全球赛在中国的举办，并邀请优秀选手和教练来中国多走走、多看看。比如北京、深圳、杭州、上海、贵州……，也可以去新疆、西藏等边疆省份感受一下，还有一些小县城也非常漂亮，值得去看看，了解中国的产业发展与城市建设；坐坐高铁，体会中国的发展速度；喝喝咖啡，吃吃烧烤，感受中国的美食和文化氛围。</p><p>除了支持或协办全球软件大赛，我们也要支持其他学科的竞赛，例如信息、数学、物理、化学、生物学、神经网络…… 等，对这些学科的青少年逐步开始支持，激发对科学研究的兴趣，从而促进基础科学的人才培养。</p><p><strong>四、我们会开放全球的园区，支持 ICPC 在华为园区举办的比赛，同时也会对大家开放研发区，邀请年轻人才来体验华为的工作环境。</strong></p><p>华为愿意面向全球优秀青少年开放信息领域的技术难题、开放实习与研究机会，帮助接触华为的端边管云平台、参与攀登珠峰的基础和前沿探索；也可以通过多种渠道，比如组织难题挑战赛事、黄大年茶思屋的开放研讨等，让青少年了解产业现实的挑战，在做题突破中能够得奖，这样就节省了勤工俭学的时间用于更好地学习，通过这个过程，也能让年轻人更好地成长。</p><hr><h3>现场问答环节：</h3><p>俄罗斯 ICPC 教练：我作为 ICPC 冠军队教练已经 10 年了。很多公司支持人才发展，但可能因为与业务没有直接的关系，他们就不太愿意支持大规模竞赛如 ICPC。自从华为在本地建立起了资源中心，支持竞赛，一切都发生了很大变化。我发现华为不仅是为了招聘人才，更多的是帮助本地社区去发展人才。我们获得了竞赛部门的大力支持，我的冠军团队也有 25 人加入了华为各个部门。我想问，华为为什么觉得支持竞赛对业务发展这么重要，或者是必须要做的事情呢？</p><p><strong>任正非：</strong>俄罗斯是一个伟大的国家。叶卡捷琳娜引进了西方的绘画、音乐、哲学……，同一个时代，中国清朝走的是闭关锁国的道路，因此俄罗斯早于中国实现了工业化。在此基础上，基础理论研究得到前苏联的重视，也取得了很大的成就，例如茹可夫斯基、门捷列夫、罗蒙诺索夫、波波夫……。近期比如，前苏联六十年代有位科学家彼得・乌菲姆契夫，最先发现钻石切面有无线电反射功能，但前苏联研究了半天觉得这个东西没用，为什么？因为做不到，没有意义，所以批准了数学家的论文公开发表。但美国人看了以后，如获至宝，花 20 年时间把 F22 隐形飞机做出来了。</p><p>华为公司虽然是一个商业公司，但是并不是唯利是图的公司。比如说我们资助竞赛是真心诚意的，并非是要获得人才，以后我们还加大竞赛活动的赞助。刚才跟 Bill 主席喝咖啡，我们讲了希望通过你们把信息、数学、物理、化学、生物学、神经网络…… 的竞赛都可以引到中国来。跟我们有关无关，我们都可以给予支持。就像 Bill 主席讲的，科学技术要用于创造更多的社会财富，消除贫困，走共同富裕的道路。</p><p>Sun Teck（新加坡国立大学副教授、IOI 成员，新加坡信息奥赛主席，前 ICPC 赛队教练）：首先，感谢华为大力支持我们训练学生并参加竞赛。其次我想介绍一下另外两个竞赛组织：一是 IOI（国际信息学奥赛），是 ICPC 的下游合作伙伴，主要是去发现、培养人才。IOI 遇到一些问题，90 多个国家加入，仍有柬埔寨、老挝、文莱、缅甸等很多国家没有加入，这些国家需要我们的支持，这和华为传播信息技术、连接世界的愿景也是一致的。已经加入 IOI 的国家也面临一些问题，比如没有足够资源去培训学生因而很少赢得奖项，从而没有机会参与到 ICPC，希望华为能够帮助 IOI 的发展。另外一个是 EGOI（欧洲女生信息学奥赛），是专门为女子办的，这是一个很好的趋势。今天的 58 人里只有一位女生，占不到 2%，关于如何实现竞赛中的性别平衡，希望华为能够支持。</p><p><strong>任正非：</strong>新加坡立国时，李光耀定了两个最重要的政策，第一确定了国家语言为英文，连接了一个非常大的世界；另一语言是汉语，准确来说说是普通话和简体字，这样就把两个大世界都连起来了。今天我们进行计算机竞赛，就要统一计算机的语言，统一大算力时代的标准，通过我们喝咖啡，通过我们交流，消除我们之间的障碍和隔阂。</p><p>这次我们把参加的 25 个国家连接起来了，星星之火可以燎原，点燃你们国家的大火。欢迎教练和年轻人，随时到中国来，你们已经加了我们很多同事、朋友的通信方式了，可以保持沟通和联系。今天你们这些年青人就是我们永久的伙伴。除了 ICPC，我们也要支持 IOI, 以及数学、物理、化学、生物学、神经网络等学科的竞赛，一起促进基础科学的人才培养。</p><p>Meza（智利圣玛利亚理工大学计算机科学教授、ICPC 拉美地区主管）：我感到很骄傲，因为一位拉美选手获得了本次冠军，当然我们还有很多优秀学生。或许是因为美洲有相关限制，在拉美，华为的工作机会不多，华为是否欢迎拉美人才来实习，比如来中国会不会有一些系统化的支持？</p><p><strong>任正非：</strong>无论是拉美还是其他国家的优秀人才，我们都欢迎到华为来。我们有个网络平台叫「黄大年茶思屋」，学生可以在上面联系相关专家沟通，如果专家觉得你应该到中国来面对面地一起实习，都是可以的。举一个简单的例子，美国倾举国之力打击的 5G 是谁发明的？其中的 Polar 码是谁发明的？是土耳其的 Arikan 教授。他十几年前发表了一篇数学论文，发表两周以后我们发现了这篇文章，就组织了数千科学家和专家研究解析并工程化，才做出了今天领先世界的 5G。所以，天涯何处无芳草？到处都有优秀人才，当然大概率是在美国。天才从哪个地方冒出来，谁都不知道，欢迎在网络上和我们的专家沟通。</p><p>北京大学教授、ICPC 亚洲东部区域竞赛总监：过去的十几年中都是美国公司在赞助，但从几年前华为开始赞助全球性的活动，终于中国公司也能站出来赞助全球的教育活动，我们感到非常自豪。我想请问您对高等教育有什么样的期望？</p><p><strong>任正非：</strong>我们不仅要继续资助活动，而且我认为资助力度还不够，要继续加强。</p><p>高等教育应该因材施教，不要老强调统一的教材；中小学教育，「不要输在起跑线上」这个口号，我认为是不正确的，不能让优秀的学生等跑。中国教育一定要振兴起来，华为公司这些年由 7000 多位高鼻子的外国科学家、专家，13800 多位留学生，大多数是博士，再加上十多万咱们中国的优秀学生，组成研发队伍，才扭转了困难。如果美国将来关闭一些学科，不允许中国留学生去留学的话，那我们就只能从中国大学获得人才，大学不能同质化。</p><p>法国选手：有一种科学研究叫无用研究，说它无用其实是短期还不知道它应用到哪里，这种研究可能主要是由大学而不是公司完成，但其实这种研究长期来看是非常重要的。华为对这种这类无用研究的是什么看法？华为会不会投资这类研究？</p><p><strong>任正非：</strong>什么叫科学？未知就叫科学。现在大家都知道，美国在科学研究上自由化程度是比较高的。在二战前，美国基础研究是很薄弱的，基本上是依赖欧洲的理论来支撑其工业、航空、航天……，如同今天中国对西方的依赖，大量的定理定律、公式、发明…… 都来自欧洲。二战结束后，美国发现自己是跟在欧洲后面跑，因为美国基本上没多少基础理论积淀。美国科学家范内瓦尔・布什，写了一本书叫《科学：无尽的前沿》，提出美国要研究看起来没有用的、遥远的东西，就是研究了很多「无用」的科学，美国在二战以后基础科学就蓬勃发展。到 90 年代以后美国普林斯顿大学一个教授叫司托克斯写了一本书《基础科学与技术创新: 巴斯德象限》，关于如何通过应用牵引科学的探索，把「无用」的科学聚集起来变成有用的。在这个数字时代，美国称雄了世界，我们就是搭上了时代的数字列车发展起来的。</p><p>当今时代，科学和技术的边界越来越接近，科学转化为技术的时间越来越短，如果等到大学把理论完全研究明白，我们再去进行技术开发，就已经没有先发优势，没有竞争力了。所以我们自己也开始重视基础理论研究，每年大约投入 30-50 亿美金用于基础理论研究。我们和大学一起并驾齐驱、互相嵌入式地共同研究这些看似无用的科学。</p><p>巴西选手：因为美国制裁，近年华为遇到了不少的困难，我想知道华为是如何应对，是否已经做好了准备，能够在国际市场上可持续发展？以及是否要恢复和美国的关系，还是说不用跟美国恢复关系仍然能够持续发展？</p><p><strong>任正非：</strong>美国制裁对我们来说确实是压力，但是压力也是动力。打压之前，我们把基础平台建在美国。美国打压以后，我们被迫把平台切换到另一个平台，这是艰难的。经过这四年的攻坚，20 万员工的拼搏奋斗，我们基本上建立了自己的平台了，将来和美国的平台不一定在同一个基础上运行，但互联互通是一定的。</p><p>孟加拉国选手：这次 ICPC 参赛者有没有机会加入华为？未来职业发展机会是什么？</p><p><strong>任正非：</strong>我们的竞赛活动完全是学术性的，与加入华为没有直接关系。如果你有意愿加入华为，可以向我们当地的人力资源部门去申请，我们欢迎全世界优秀人才加入华为。孟加拉有将近 2 亿人口，西方曾判断孟加拉会是下一个新兴的工业国家。现在孟加拉有你这样的优秀人才，慢慢地会引导国家走向更快的发展。但更快发展的基础是什么？是速度。希望你能够带头，把所学所获带回孟加拉，把国家发展提高到一个新的速度。</p><p>ICPC 墨西哥 &amp; 中美地区主管：一些科技公司如甲骨文、思科在墨西哥设置了研发中心。我想请问未来华为是否有计划在墨西哥或者是在拉美设置研发机构？</p><p><strong>任正非：</strong>海外研发的布局，需要问我们 2012 实验室的主任，我们把您的意见带回去。墨西哥有很灿烂的文明，玛雅文化现代人到今天也还没有完全搞明白。墨西哥文明起源很早，我们相信这种文明在世界各国都会有。我们也可能会考虑到那里，但还是要根据 2012 实验室的具体部署来。以前我们的部署是以美国为中心、分布全世界，后来美国打击我们，我们就以欧洲为中心，逐渐以欧亚为中心，拉美就去的少了。拉美还受美国的管制，我们还要进一步评估一下管制的状况。</p><p>俄罗斯选手：华为公司有这么多人，通过怎样的管理实现高效运作？</p><p><strong>任正非：</strong>在创立公司之初我访问了美国，以 IBM 为主体去理解他们的管理。第一，IBM 的企业目标管理，就是为客户服务，一切都要以客户为中心，这样企业就有了一个整体方向感，这个方向感把员工凝聚起来了。第二，学习 IBM 推行 IPD，就是在研发中怎么加入市场、服务代表，IPD 是一个前瞻性的领导组织来引导研发前进。接下来又向 IBM 学习 IFS、ISC 财务和供应链管理。这样，流程体系就清楚了。最重要的是分配问题，我们就研究华为财富在哪儿，财富怎么分配。我们认为财富在员工的脑袋里面，把脑袋拿来称一称到底有多重，就给你分多少。我们的分配方式，劳动分三，资本分一。</p><p>冰岛选手：不知道是真的假的，我之前听说您本人是果粉？</p><p><strong>任正非：</strong>因为我女儿在美国读书，如果不用苹果，她上课就很不方便。我们不要排外，我们也经常探究苹果的产品为什么做得好，也能看到我们与苹果之间的差距。有一个老师是很幸福的，可以有学习机会，有做比较的机会。如果从这些角度来说我是果粉呢，也不为过。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 10:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258695</guid>
            <link>https://www.oschina.net/news/258695</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌以 9300 万美元和解加州 Android 追踪诉讼案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">美国加利福尼亚州总检察长<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FAGRobBonta%2Fstatus%2F1702460406713946115" target="_blank">宣布</a>，谷歌将支付 9300 万美元，以了结一项指控其违反美国消费者保护法的隐私诉讼。</span></span></p><blockquote><p><span style="color:#000000">「谷歌告诉用户，一旦他们选择退出，谷歌就不会追踪他们的位置；但它却阳奉阴违，继续使用位置数据追踪、存储和销售广告。这是不可接受的。我们要求他们承担 9,300 万美元的责任。」</span></p></blockquote><p style="margin-left:0; margin-right:0; text-align:start"><img alt="" height="375" src="https://oscimg.oschina.net/oscnet/up-b863c625adb303970bf98289230190288f8.webp" width="300" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">具体表现为，加州司法部的一项调查<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fgoogle%2Fgoogle-pays-93m-to-settle-android-tracking-lawsuit-in-california%2F" target="_blank">发现</a>，谷歌在收集、保留和利用 Android 用户的位置数据用于消费者分析和广告等目的方面存在欺骗行为。该公司所有这些数据收集行为，都是在没有获得用户知情同意的情况下进行的。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">指控的重点内容在于谷歌对用户位置的跟踪。在用户所了解的角度，在设备设置中关闭"位置历史记录"意味着可以完全禁用位置跟踪。但事实却是，存在一个名为"Web &amp; App Activity"的账户设置被默认启用，允许谷歌收集、保留和使用客户的个人身份位置数据。</span></span></p><p><span style="color:#000000">根据此项和解协议，谷歌同意将实施<span style="background-color:#ffffff">更加用户友好的帐户控制</span>，同时限制特定位置数据类别的使用和保留。还必须提高其位置数据跟踪和收集行为的透明度，在启用与位置相关的账户设置时向用户提供更多信息；且必须就其收集的数据类型和使用方式提供更详细的信息。</span></p><p><span style="color:#000000">值得一提的是，谷歌已经因为此类诉讼被处以多次罚款，包括：</span></p><ul><li><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>2021 年 11 月因激进的数据收集行为而被意大利机构处以 1130 万美元的罚款。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>2022 年 1 月被法国国家信息学和自由委员会 (CNIL) 处以 1.7 亿美元的罚款，理由是谷歌侵犯了互联网用户的同意权，这使得选择退出隐藏在多次点击背后的网站跟踪 cookie 变得困难。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>2022 年 8 月，澳大利亚竞争与消费者委员会 (ACCC) 对谷歌处以 6000 万美元罚款，原因是谷歌在近两年内欺骗和收集澳大利亚 Android 用户的位置数据。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>2022 年 11 月，谷歌还支付了 3.915 亿美元，以了结美国 40 个州总检察长联盟针对同样侵犯隐私行为提起的隐私诉讼。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li></ul><p><span style="color:#000000">有关此次诉讼的更多信息可</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Foag.ca.gov%2Fsystem%2Ffiles%2Fattachments%2Fpress-docs%2FGoogle%2520Proposed%2520Order%2520FINAL%2520%25283%2529.pdf" target="_blank">查看官方文件</a>。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 09:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258591/google-93m-settle-android-tracking-lawsuit-california</guid>
            <link>https://www.oschina.net/news/258591/google-93m-settle-android-tracking-lawsuit-california</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中国计算产业规模达 2.6 万亿元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根据工信微报的公众号消息，2022 年，我国计算产业规模达 2.6 万亿元，近六年累计出货超过 2091 万台通用服务器、82 万台 AI 服务器。</p><p>下一步，相关部门将加强技术创新，聚焦计算产业链，设立专项任务，支持新形态、新产品研发。深入实施各类计算产业政策，加大对计算重点领域和薄弱环节支持力度，增强核心竞争力。</p><p>工信部总工程师赵志国当天表示，以异构计算、智能计算、量子计算等为代表的先进计算已演进到质变的关键阶段，计算产业展现出强大的活力和不可估量的潜力。</p><p>据中国信通院发布的《中国算力发展指数白皮书（2023 年）》显示，算力多元化发展持续推进。以 AIGC 为代表的人工智能应用、大模型训练等新应用、新需求快速崛起都对算力提出更高要求。预计到 2025 年全球算力规模超过 3ZFlops（ZFlops：每秒十万亿亿次浮点数运算），至 2030 年超过 20ZFlops。</p><p>面对技术和产业发展的新趋势，工信部将围绕加强技术创新、加快企业培育、深化行业应用、强化政策保障等方面，持续推动我国计算产业高质量发展。</p><p>赵志国表示，将聚焦计算产业链，设立专项任务，支持智能服务器、集群服务器、存算一体服务器等新形态、新产品研发。围绕重点需求场景，加强产品生态建设和软硬生态适配，培育一批计算产业链优质企业，促进各地区计算产业集聚化发展，形成区域布局合理、辐射带动效能大的计算产业体系。</p><p>他同时表示，将进一步推动计算产业与实体经济深度融合，加速向制造、交通、金融、教育、医疗等行业渗透，推进先进计算规模化应用，带动产业数字化转型升级，促进生产和服务效率提升。深化全方位部省合作，深入实施各类计算产业政策，加大对计算重点领域和薄弱环节支持力度，建设完善计算标准和测评体系，加强知识产权布局，增强核心竞争力。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 09:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258585</guid>
            <link>https://www.oschina.net/news/258585</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龙芯国产化全固态桌面存储一体机正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>龙芯国产化全固态桌面存储一体机正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fd2EGcDvhxEQ9LF6r_uDQAQ" target="_blank">发布</a>。该产品由龙芯中科 (武汉) 技术有限公司牵头，联合龙众创芯、嘉合劲威、熊猫电子、可道云等多家国产存储厂商共同推出。产品主要针对个人、家庭、团体和小微企业市场，提供国产化的桌面网络存储方案。目前预订活动已正式开启。</p><p><img alt="" height="225" src="https://oscimg.oschina.net/oscnet/up-7329bc5e0d17b2a9823a2a3266be4f11d79.jpg" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#9f9fa0">龙芯国产化全固态桌面存储一体机（8 盘位）</span></p><p><span style="background-color:#ffffff; color:#9f9fa0"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-cabe84089afd95264d8a165b221917cf243.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#9f9fa0">一体机在线演示中心</span></p><p><span style="background-color:#ffffff; color:#9f9fa0"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-9b04c234092306db284338e23f1fef3b46c.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#9f9fa0">插件扩展</span></p><p><span style="background-color:#ffffff; color:#9f9fa0"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-ddeb9d2c2bee1998a3a4fd2df9c8afc2f75.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#9f9fa0">在线 PS</span></p><p><span style="background-color:#ffffff; color:#9f9fa0"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-023ca83835e58b3301e2cf1f88c83a434de.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#9f9fa0">网盘界面</span></p><h4 style="margin-left:0px; margin-right:0px"><strong>产品 | 配置</strong></h4><p style="margin-left:0; margin-right:0"><strong>处理器</strong></p><p style="margin-left:0; margin-right:0">该产品采用龙芯 3A5000 处理器，主频 2.5G。主流桌面 8 盘位 NAS 产品采用的处理器多为 4 核 2.2G，因此该产品可完全满足桌面网络存储应用的需求。</p><p style="margin-left:0; margin-right:0"><strong>内存</strong></p><p style="margin-left:0; margin-right:0">产品采用长鑫颗粒的嘉合劲威（神可）、力积存储（力存）、紫光等国产品牌产品，企业版方案专门配备带 ECC 的服务器内存型号，可靠性更高。</p><p style="margin-left:0; margin-right:0"><strong>硬盘配置</strong></p><p style="margin-left:0; margin-right:0">产品与大唐存储、嘉合劲威和泽石等国产存储品牌厂商合作，为本产品定制硬盘，默认系统盘和存储盘采用全固态方案，主控芯片采用国产主控，存储颗粒采用长江存储颗粒，有效防止数据远程泄密和人为窃取硬件可能。</p><p style="margin-left:0; margin-right:0"><strong>机箱外观</strong></p><p style="margin-left:0; margin-right:0">产品提供标准和定制机箱，包括迷你主机、NAS 主机等方案，以及入门型、社区型、门锁型、企业型等多种款式，满足各类用户的需求。</p><p style="margin-left:0; margin-right:0"><strong>操作系统</strong></p><p style="margin-left:0; margin-right:0">产品支持 loongnix、统信 UOS、银河麒麟、龙蜥 Anolis、openEuler 等国产操作系统，本次采用最新发布的 Anolis OS8.8。该版本新增了龙芯 3D5000 处理器、龙芯 2K0500 BMC 驱动，以及虚拟化二进制翻译支持，功能完善，运行稳定，满足用户企业级需求。</p><p style="margin-left:0; margin-right:0"><strong>存储管理软件</strong></p><p style="margin-left:0; margin-right:0">上海七朵信息基于 loongnixserver 8.4、可道云基于 Anolis OS 8.8 分别移植了 NAS 系统和私有云网盘系统，可为个人、团体、企业提供专业的网络存储应用服务。基于 Anolis OS 的可道云企业私有云存储操作系统 8.8 LoongArch64（龙芯定制版）是专门支持龙芯的 Anolis OS 商业发行版，将在龙芯俱乐部社区和龙蜥社区推广。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 08:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258583</guid>
            <link>https://www.oschina.net/news/258583</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周热点 | JetBrains 发布独立 Rust IDE；PHP 市场份额超 7 成.....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2023.09.11-2023.09.17]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 06:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093858&#38;idx=1&#38;sn=4c65dae56e5b41c3d5863cd74a70aa7d&#38;chksm=880c4df1bf7bc4e78d0d90ab8ed8b4ddfb3d4064b4f52cca7a2f8e44adee410c044f15e32024&#38;token=938160620&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093858&#38;idx=1&#38;sn=4c65dae56e5b41c3d5863cd74a70aa7d&#38;chksm=880c4df1bf7bc4e78d0d90ab8ed8b4ddfb3d4064b4f52cca7a2f8e44adee410c044f15e32024&#38;token=938160620&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[阿里云 PAI - 灵骏大模型训练工具 Pai-Megatron-Patch 正式开源！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>作者：</strong> 李鹏，王明，施晨，黄俊</p><h2>导读</h2><p>随着深度学习大语言模型的不断发展，其模型结构和量级在快速演化，依托大模型技术的应用更是层出不穷。对于广大开发者来说不仅要考虑如何在复杂多变的场景下有效的将大模型消耗的算力发挥出来，还要应对大模型的持续迭代。开发简单易用的大模型训练工具就成了应对以上问题广受关注的技术方向，让开发者专注于大模型解决方案的开发，降低大模型训练加速性能优化和训练/推理全流程搭建的人力开发成本。阿里云机器学习平台 PAI 开源了业内较早投入业务应用的大模型训练工具 Pai-Megatron-Patch，本文将详解 Pai-Megatron-Patch 的设计原理和应用。</p><h2><strong>Pai-Megatron-Patch 是什么</strong></h2><p>Pai-Megatron-Patch 工具是阿里云机器学习平台 PAI 算法团队研发，基于阿里云智算服务 PAI-灵骏平台的大模型最佳实践解决方案配套工具，旨在帮助大模型开发者快速上手灵骏产品，完成大语言模型（LLM）的高效分布式训练，有监督指令微调，模型离线推理验证等完整大模型开发链路。该项目提供了业界主流开源大模型基于 Megatron-LM 的训练&amp;离线推理验证流程，方便用户快速上手大模型训练。</p><h3>主要特性</h3><ul><li>多款热门大模型支持：llama，llama-2，codellama, 百川，通义千问，Falcon，GLM，Starcoder，Bloom，chatglm 等</li><li>支持模型权重互转转换：在 Huggingface，Megatron 和 Transformer Engine 之间进行算子命名空间映射</li><li>支持 Flash Attention 2.0 和 Transformer Engine 模式下的 FP8 训练加速且确保收敛</li><li>丰富且简单易用的使用示例，支持大模型预训练，微调，评估和推理，强化学习全流程最佳实践</li></ul><h3>开源地址</h3><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a></p><h3><strong>技术架构</strong></h3><p>Pai-Megatron-Patch 的设计理念是不对 Megatron-LM 的源码进行侵入式修改，即不在 Megatron-LM 里面添加新的功能特性，将需要扩充完善的部分以 patch 补丁的方式呈现。在 patch 中构建 LLM 训练链路通过依赖 Megatron-LM 核心库的方法实现和 Megatron-LM 的解耦合。这样解耦合的好处就是 Megatron-LM 的升级不会影响用户的 LLM 最佳实践体验。</p><p>Pai-Megatron-Patch 中包含模型库，分词器，模型转换，强化学习，离线文本生成以及使用示例和工具集等用于构建 LLM 训练的关键要素。在模型库中包含热门大模型的 Megatron 版本实现，例如 baichuan，bloom，chatglm，falcon，galactica，glm，llama，qwen 和 starcoder，后续还会根据需要及时添加新的 Megatron 版大模型实现。同时 patch 还提供了 huggingface 模型权重和 Megatron 模型权重之间的双向转换。一方面是方便用户加载 huggingface 的权重在 Megatron 中继续预训练或者微调，另一方面是方便用户对训练好的 Megatron 模型使用 huggingface 的评估/推理流程对模型质量进行客观评估。在强化学习部分，patch 提供了 PPO 训练流程等，方便用户使用 SFT 模型和 RM 模型进行强化学习。最后 patch 提供了大量的使用示例帮助用户快速开始大模型训练&amp;离线推理。具体请参考阿里云灵骏产品的使用流程: 智算服务 PAI 灵骏大模型分布式训练方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ab36e41130c172c6004c2a2f2d7bbef90cd.png" alt="" referrerpolicy="no-referrer"></p><h3>关键技术</h3><p><strong>1. 模型权重转换</strong></p><p>研发 Megatron-Patch 的初衷之一就是能将世界各地研发机构在 Huggingface 上放出的热门大模型使用 Megatron 引擎进行继续预训练或者继续微调。这就需要首先将 Huggingface 模型格式的 ckpt 转换成 Megatron 模型格式，才能正确加载进来，否则会出现 pytorch 加载模型失败。Megatron-Patch 的一个核心可靠性保障特征就是在采用算子拆分，流水并行，序列并行，Zero 显存优化，BF16 混合精度，梯度检查点等训练加速技术确保模型训练吞吐速度平均提升 1.5 倍以上的同时，在评估任务模式下的单一样本前向 loss 值，预训练/微调任务模式下的 loss 曲线，离线文本生成任务模式下的生成效果这三个方面和 Huggingface 是对齐的，从而确保 Megatron 版模型的可靠性。</p><p>另一方面，Megatron 版的 transformer 实现方式提供了一种让用户仅仅通过设置开关就能实现不同种类 GPT 模式的能力。比如 llama 模型打开如下开关即可</p><pre><code> --swiglu \
 --use-rotary-position-embeddings \
 --no-position-embedding \
 --untie-embeddings-and-output-weights \
 --disable-bias-linear
</code></pre><p>如果想将 llama 模式变成 baichuan 模型，那么仅仅需要添加采用--use-alibi-mask 开关，同时关闭 Rotary Embeeding 开关即可，具体配置如下所示：</p><pre><code> --swiglu \
  --use-alibi-mask \
  --position-embedding-type none \
  --untie-embeddings-and-output-weights \
  --disable-bias-linear
</code></pre><p>下面我们以 llama-2 为例，详解从 huggingface 到 megatron 的模型权重转换技术。下表总结了两者在不同 module 上的命名对应关系。在 patch 实现过程中，我们首先将 HF 格式的 ckpt 转换到一种内部格式，然后再把这种内部格式转换成对应的外部格式。这样做可以最大程度复用已有的转换逻辑来处理新模型。在转换为内部格式的过程中，q_proj, k_proj, v_proj 需要沿着第 0 维拼接在一起后赋值给内部变量 query_key_value。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d673e56a66d863151ffbdef09e6bbe815df.png" alt="" referrerpolicy="no-referrer"></p><p>当用户在资源受限情况下需要按照 TP&gt;1 来拆分权重的时候，这里需要注意的是针对 MLP 层的 gate_proj 和 up_proj 的操作。不能像 qkv 那样在转换成内部格式的时候进行 merge 再执行算子拆分。需要在拆分前加入如下针对 MLP 层的权重合并的代码逻辑才能确保正确收敛。</p><pre><code>for i in range(tp_size):
    params_dict = get_element_from_dict_by_path(output_state_dict[i],
                                                "model.language_model.encoder")

    dense_h_to_4h_1_name = 'mlp.dense_h_to_4h_1.weight'
    dense_h_to_4h_1_layer_name = f"layers.{layer}.{dense_h_to_4h_1_name}"
    dense_h_to_4h_1_weight = params_dict[dense_h_to_4h_1_layer_name]

    dense_h_to_4h_2_name = 'mlp.dense_h_to_4h_2.weight'
    dense_h_to_4h_2_layer_name = f"layers.{layer}.{dense_h_to_4h_2_name}"
    dense_h_to_4h_2_weight = params_dict[dense_h_to_4h_2_layer_name]

    dense_h_to_4h_name = 'mlp.dense_h_to_4h.weight'
    dense_h_to_4h_layer_name = f"layers.{layer}.{dense_h_to_4h_name}"

    params_dict[dense_h_to_4h_layer_name] = torch.cat(
    [dense_h_to_4h_1_weight, dense_h_to_4h_2_weight], dim=0)
</code></pre><p><strong>2. 基于 TE 的 FP8 训练收敛</strong></p><p>Transformer Engine(TE) 是一个在英伟达 GPUS 上运行的针对 Transformer 模型的加速库，其中包括针对 Hopper GPU 的 FP8 混合精度，该精度可以在较低的显存利用率下提供更好的训练&amp;推理速度。在 TE 内部封装了 Flash Attention 实现，同时 TE 还提供了一组高度优化后的算子用来构建 Transformer 模型。比如 LayerNormLinear 就是将 LayerNorm 和 QKV-Proojection 进行算子融合，LayerNormMLP 就是将 layernorm 和 mlp 进行算子融合。如下图所示：</p><p><img src="https://oscimg.oschina.net/oscnet/up-53a950508a61f0ccc5924b654c44bc1da4b.png" alt="" referrerpolicy="no-referrer"></p><p>从 Huggingface 到 TE 模型的权重转换技术和之前是类似的，也需要事先找到两者之间的映射关系。从下表可以看出，TE 中多了_extra_state 是用来存 fp8 训练的 scale 和 history 的，这些在加载的时候会出现冲突，这时只要将 load_state_dict 函数的 strict 设置成 False 就可以了，比如 load_state_dict(state_dict_, strict=False)。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4b5da490d5168d58505bf16cedf157a6560.png" alt="" referrerpolicy="no-referrer"></p><p>在 Megatron-Patch 中使用示例中打开 FP8 混合精度训练开关也很容易，如下所示：</p><pre><code>if [ $PR = fp16 ]; then
    pr_options=" \
        --fp16"
elif [ $PR = bf16 ]; then
    pr_options=" \
        --bf16"
elif [ $PR = fp8 ]; then
    pr_options=" \
        --bf16
        --fp8-hybrid \
        --fp8-amax-compute-algo max \
        --fp8-amax-history-len 1024 \
        --transformer-impl transformer_engine"
fi
</code></pre><p>我们可以使用如下训练脚本 run_pretrain_megatron_llama_enwiki.sh 来测试打开 FP8 开关后的预训练收敛性。下图展示了 llama-7B 和 llama-2-70B 模型在打开和关闭 FP8 时的 loss 曲线对比，可以看出基本是重合的。</p><p>LLama-7B</p><p><img src="https://oscimg.oschina.net/oscnet/up-c749406c18a5e391c380313b99dabd8d83f.png" alt="" referrerpolicy="no-referrer"></p><p>LLama2-70B</p><p><img src="https://oscimg.oschina.net/oscnet/up-62bdf429cd9619a79272dec35d3a737c4ff.png" alt="" referrerpolicy="no-referrer"></p><p><strong>3. 大模型训练&amp;推理</strong></p><p>从 github 上获取 Megatron 模型训练工具 PAI-Megatron-Patch（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a>）源代码并拷贝到工作目录/mnt/workspace/下。</p><p><strong>1）模型格式转换</strong></p><p>使用我们提供的模型转换脚本，将 huggingface 格式的模型文件转换为 megatron 格式：</p><pre><code>cd /mnt/workspace/
mkdir llama2-ckpts
cd llama2-ckpts
wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-ckpts/Llama-2-7b-hf.tgz
tar -zxf Llama-2-7b-hf.tgz
mv Llama-2-7b-hf llama2-7b-hf

cd /mnt/workspace/PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/llama
sh model_convertor.sh \
/root/Megatron-LM-23.04        \
/mnt/workspace/llama2-ckpts/llama2-7b-hf         \
/mnt/workspace/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1  \
1  \
1  \
llama-7b \
0 \
false
</code></pre><p><strong>2）继续预训练</strong></p><p>中文继续预训练汉化指引</p><p>Step1: 获取需要扩充词表的模型（如 llama-13b-hf）</p><p>Step2: 获取需要扩充的词表</p><ul><li>使用 sentence-piece 代码库从自有文本语料中学习词表，得到 randeng-sp.model 文件</li></ul><p>Step3: 词表扩充</p><ul><li>扩充模型 tokenizer：将 randeng-sp.model 中的词表添加到 llama-13b-hf 文件夹下 tokenizer.model 中</li><li>扩充模型词表对应的参数矩阵</li></ul><ol><li>word_embedding、lm_head</li><li>新词向量可以使用原词向量均值作为初始化，比如「天气」=mean([「天」，「气」])</li></ol><ul><li>修改与词表大小相关的文件并保存，如 config.json</li></ul><p>运行继续预训练脚本 run_pretrain_megatron_llama.sh，需要传入的参数列表如下：</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
MODEL_SIZE=$4                   # 模型结构参数量级：7B, 13B
BATCH_SIZE=$5                   # 每卡训练一次迭代样本数: 4, 8
GLOBAL_BATCH_SIZE=$6            # 全局 batch size
LR=$7                           # 学习率: 1e-5, 5e-5
MIN_LR=$8                       # 最小学习率: 1e-6, 5e-6
SEQ_LEN=$9                      # 序列长度
PAD_LEN=${10}                   # Padding 长度：100
EXTRA_VOCAB_SIZE=${11}          # 词表扩充大小
PR=${12}                        # 训练精度: fp16, bf16
TP=${13}                        # 模型并行度
PP=${14}                        # 流水并行度
AC=${15}                        # 激活检查点模式: sel, full
DO=${16}                        # 是否使用 Megatron 版 Zero-1 降显存优化器: true, false
FL=${17}                        # 是否使用 Flash Attention: true, false
SP=${18}                        # 是否使用序列并行: true, false
SAVE_INTERVAL=${19}             # 保存 ckpt 的间隔
DATASET_PATH=${20}              # 训练数据集路径
PRETRAIN_CHECKPOINT_PATH=${21}  # 预训练模型路径
TRAIN_TOKENS=${22}              # 训练 token 数
WARMUP_TOKENS=${23}             # 预热 token 数
OUTPUT_BASEPATH=${24}           # 训练输出文件路径
</code></pre><p>注意设置正确的数据集<strong>挂载路径 WORK_DIR</strong>以及<strong>运行环境 ENV</strong>，运行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_pretrain_megatron_llama.sh \
dlc \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B   \
1    \
16 \
1e-5   \
1e-6   \
2048  \
80  \
0   \
fp16  \
1   \
1  \
sel  \
true   \
false  \
false   \
100000  \
${WORK_DIR}/llama2-datasets/wudao/wudao_llamabpe_text_document   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
100000000   \
10000   \
${WORK_DIR}/output_megatron_llama2/ 
</code></pre><p><strong>3）有监督微调</strong></p><p>在微调开始之前，请先进入</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Ftoolkits%2Fpretrain_data_preprocessing%2FREADME.md" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch/blob/main/toolkits/pretrain_data_preprocessing/README.md</a></p><p>获取 json 文件。运行 run_finetune_megatron_llama.sh 脚本，需要传入的参数列表如下：</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
MODEL_SIZE=$4                   # 模型结构参数量级: 7B, 13B
BATCH_SIZE=$5                   # 每卡训练一次迭代样本数: 4, 8
LR=$6                           # 学习率: 1e-5, 5e-5
MIN_LR=$7                       # 最小学习率: 1e-6, 5e-6
SEQ_LEN=$8                      # 序列长度
PAD_LEN=$9                      # Padding 长度：100
EXTRA_VOCAB_SIZE=${10}          # 词表扩充大小
PR=${11}                        # 训练精度: fp16, bf16
TP=${12}                        # 模型并行度
PP=${13}                        # 流水并行度
AC=${14}                        # 激活检查点模式: sel, full
DO=${15}                        # 是否使用 Megatron 版 Zero-1 降显存优化器: true, false
FL=${16}                        # 是否使用 Flash Attention: true, false
SP=${17}                        # 是否使用序列并行: true, false
TRAIN_DATASET_PATH=${18}        # 训练数据集路径
VALID_DATASET_PATH=${19}        # 验证数据集路径
PRETRAIN_CHECKPOINT_PATH=${20}  # 预训练模型路径
EPOCH=${21}                     # 训练迭代轮次
OUTPUT_BASEPATH=${22}           # 训练输出文件路径
</code></pre><p>多节点运行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
sh run_finetune_megatron_llama.sh  \
dlc    \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B     \
1      \
1e-5   \
1e-6   \
2048   \
80     \
0      \
fp16   \
1      \
1      \
sel    \
true   \
false  \
false  \
${WORK_DIR}/llama2-datasets/wudao_train.json   \
${WORK_DIR}/llama2-datasets/wudao_valid.json   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
2   \
${WORK_DIR}/output_megatron_llama2/   
</code></pre><p><strong>4）离线推理</strong></p><p>模型训练完成后，可以进行离线推理，评估模型效果。根据上面的训练流程不同，我们提供了 Megatron 格式的推理链路。对于 Megatron 训练的模型，可以直接用 Megatron 框架进行推理。</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
CHECKPOINT_PATH=$4              # 模型微调阶段的模型保存路径
MODEL_SIZE=$5                   # 模型结构参数量级: 1.1B, 1.7B, 7.1B
TP=$6                           # 模型并行度
BS=$7                           # 每卡推理一次迭代样本数: 1, 4, 8
SEQ_LEN=$8                      # 序列长度: 256, 512, 1024
PAD_LEN=$9                      # PAD 长度：需要将文本拼接到的长度
EXTRA_VOCAB_SIZE=${10}          # 模型转换时增加的 token 数量
PR=${11}                        # 推理采用的精度: fp16, bf16
TOP_K=${12}                     # 采样策略中选择排在前面的候选词数量 (0-n): 0, 5, 10, 20
INPUT_SEQ_LEN=${13}             # 输入序列长度: 512
OUTPUT_SEQ_LEN=${14}            # 输出序列长度: 256
INPUT_FILE=${15}                # 需要推理的文本文件: input.txt, 每行为一个样本
OUTPUT_FILE=${16}               # 推理输出的文件: output.txt
# TOP_K 和 TOP_P 必须有一个为 0
TOP_P=${17}                     # 采样策略中选择排在前面的候选词百分比 (0-1): 0, 0.85, 0.95
TEMPERATURE=${18}               # 采样策略中温度惩罚: 1-n
REPETITION_PENALTY=${19}        # 避免生成是产生大量重复，可以设置为 (1-2) 默认为 1.2
</code></pre><ul><li>此处提供一个离线推理输出的文件，推理的数据组织形式需要与微调时的保持一致。</li></ul><ol><li>测试样本：</li></ol><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fatp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com%2Frelease%2Fmodels%2Fpai-megatron-patch%2Fllama2-datasets%2Fpred_input.jsonl" target="_blank">https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-datasets/pred_input.jsonl</a></p><ul><li>注意：</li></ul><ol><li>模型保存的路径下缺少 tokenizer 依赖的文件，需要将微调前模型路径下所有 json 文件及 tokenizer.model 拷贝至保存模型的路径下（位于{OUTPUT_BASEPATH }/checkpoint），与 latest_checkpointed_iteration.txt 同级。</li></ol><p>以下有监督微调过程保存模型的推理代码，需要将 run_text_generation_megatron_llama.sh 脚本中 CUDA_VISIBLE_DEVICES 参数设置为 0；GPUS_PER_NODE 参数设置为 1；同时使用下列代码进行推理。此时使用单卡进行推理。<strong>注意：此处模型 tp 为 1，可使用单卡推理；如果 tp&gt;1，则需使用相应卡数进行推理</strong>。</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_text_generation_megatron_llama.sh \
dsw \
/root/Megatron-LM-23.04 \
${WORK_DIR}/PAI-Megatron-Patch \
../../../llama2-train \
7B \
1 \
1 \
1024 \
1024 \
0 \
fp16 \
10 \
512 \
512 \
${WORK_DIR}/pred_input.jsonl \
${WORK_DIR}/llama2_pred.txt \
0 \
1.0 \
1.2
</code></pre><p><strong>4. 大模型强化学习</strong></p><p>一般来说，SFT 微调过的模型在对话场景已经会有不错的表现了。如果想进一步提升模型效果，可以再加上 RLHF 训练。包括奖励模型（Reward Model）的训练和强化学习（PPO）的训练。这里展示了如何使用当前最常用的 RLHF 开源代码框架，DeepSpeed-Chat 和 trlx，来进行奖励函数训练（RM），以及强化学习优化（PPO）。</p><p><strong>1）模型格式转换</strong></p><p>如果基于 huggingface 格式的模型直接进行奖励模型训练（RM）和强化学习优化（PPO），可以跳过此步骤。如果基于 Megatron 格式的模型，如 PAI-Megatron-Patch 训练好的 SFT 模型，进行 RM 和 PPO 训练，需要使用我们提供的模型转换脚本，先将 Megatron 格式的模型文件转换为 huggingface 格式。</p><p>LLaMA2 模型转换：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/gpt3_llama
bash model_convertor.sh \
/path/to/Megatron-LM \
/path/to/megatron_llama2_ckpt \
/path/to/hf_llama2_ckpt \
1 \
1 \
llama-7b \
0 \
true
</code></pre><p>BLOOM 模型转换：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/bloom
bash model_convertor_huggingface_megatron.sh \
/path/to/Megatron-LM \
/path/to/megatron_bloom_ckpt \
/path/to/hf_bloom_ckpt \
1 \
1 \
true
</code></pre><p><strong>2）DeepSpeed-Chat</strong></p><p>下载安装开源社区 DeepSpeed-Chat 源代码：</p><pre><code>cd PAI-Megatron-Patch/rlhf/deepspeed-chat
git clone https://github.com/microsoft/DeepSpeedExamples.git
cp -f rm_main.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/main.py
cp -f utils.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/utils.py
cd DeepSpeedExamples/applications/DeepSpeed-Chat/
pip install -r requirements.txt
</code></pre><p>基于 LLaMA2 模型训练奖励模型（RM）：</p><pre><code>cd training/step2_reward_model_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b.sh
</code></pre><p>基于 LLaMA2 进行强化学习优化训练（PPO）：</p><pre><code>cd training/step3_rlhf_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b_lora.sh
</code></pre><p><strong>3）trlx</strong></p><p>下载安装开源社区 trlx 源代码：</p><pre><code>cd PAI-Megatron-Patch/rlhf/trlx
git clone https://github.com/CarperAI/trlx.git
cp trlx_bloom_rlhf.py trlx_bloom_rlhf_test.py trlx/examples/summarize_rlhf/
cp train_reward_model_bloom.py reward_model_bloom.py ds_config_bloom.json trlx/examples/summarize_rlhf/reward_model/
cp -f ds_config_trlx_gptj_summarize.json trlx/examples/summarize_rlhf/configs/
cd trlx
pip install -e .
</code></pre><p>基于 BLOOM 模型训练奖励模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_bloom.py
</code></pre><p>基于 GPT-J 模型训练奖励模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_gptj.py
</code></pre><p>基于 BLOOM 模型进行强化学习优化训练（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf.py
</code></pre><p>基于 GPT-J 模型进行强化学习优化训练（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_gptj_text_summarization.py
</code></pre><p>PPO 单测</p><p>如果您想跳过，有监督微调（SFT）与，奖励模型训练（RM）两个步骤，只单独测试 PPO 模块的性能，可以运行如下指令单测 PPO：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf_test.py
</code></pre><h2><strong>开源生态——构想和未来</strong></h2><p>在 PAI-Megatron-Patch 的开发过程中，我们围绕中文大模型训练加速落地沉淀了以下几个方面的内容：</p><p>在 PAI-Megatron-Patch 的开发过程中，我们围绕中文大模型训练加速落地沉淀了以下几个方面的内容：</p><ul><li>Huggingface 的模型权重无损转换成 Megatron 或者 Transformer Engine 可读的模型权重。</li><li>H800 集群开启 FP8 混合精度训练确保收敛。</li><li>LLM 大模型在 PAI 灵骏智算平台上的最佳实践。</li><li>强化学习技术在 PAI 灵骏智算平台上的最佳实践。</li></ul><p>后续在 PAI-Megatron-Patch 中还会陆续放出更多高质量的大模型和最佳实践。此外，在中长期，我们在 Megatron 版的 Lora 流程以及 Transformer Engine 方向上会持续投入精力，也欢迎各种维度的反馈和改进建议以及技术讨论，同时我们十分欢迎和期待对开源社区建设感兴趣的同行一起参与共建，<strong>钉钉群号是 29605038042</strong>。</p><p><strong>参考文献</strong></p><p>[1]. Attention Is All You Need</p><p>[2]. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</p><p>[3]. Reducing Activation Recomputation in Large Transformer Models</p><p>[4]. FP8 Formats for Deep Learning</p><p>[5]. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</p><p>[6]. LLaMA: Open and Efficient Foundation Language Models</p><p>[7]. Llama 2: Open Foundation and Fine-Tuned Chat Models</p><p>[8]. Benchmarking Large Language Models on NVIDIA H100 GPUs with CoreWeave</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 06:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/10110020</guid>
            <link>https://my.oschina.net/u/5583868/blog/10110020</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[前端新轮子 Nue JS，作者称要打造全新的 Web 生态]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Nue JS 是最近开源的 Web 前端项目，用于构建用户界面，体积非常小（压缩后 2.3kb）。Nue JS 支持服务器端渲染 (SSR)、反应式组件和「同构」组合 ("isomorphic" combinations)。</p><p>作者表示，它就像 Vue.js、React.js 或 Svelte，但没有 hooks, effects, props, portals, watchers, provides, injects, suspension 这些抽象概念，<strong>开发者只需掌握 HTML、CSS 和 JavaScript 的基础知识，就能轻松上手</strong>。</p><p><img src="https://static.oschina.net/uploads/space/2023/0918/120647_3IjB_2720166.png" referrerpolicy="no-referrer"></p><p>他还说道，Nue 最大的好处是能够用更少的代码来完成同样的事情——与使用 React 相比，Nue JS 实现同样的功能代码量只有前者的 1/10。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e8386b068aeae9430ed951780a94d1a9bee.png" referrerpolicy="no-referrer"></p><p>作者称 Nue 消除了 TCP 慢启动算法和渐进增强带来的「地狱」：</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0918/114329_NA5Q_2720166.png" referrerpolicy="no-referrer"></p><p><strong>示例代码</strong></p><p>Nue 使用基于 HTML 的模板语法：</p><pre><code class="language-html">&lt;div @name="media-object" class="{ type }"&gt;
  &lt;img src="{ img }"&gt;
  &lt;aside&gt;
    &lt;h3&gt;{ title }&lt;/h3&gt;
    &lt;p :if="desc"&gt;{ desc }&lt;/h3&gt;
    &lt;slot/&gt;
  &lt;/aside&gt;
&lt;/div&gt;
</code></pre><p>Nue JS 的作者曾开源过一款颇有名气的项目——<a href="https://www.oschina.net/p/riotjs" target="_blank">Riot.js</a>，这是一个 JavaScript 的 MVP 框架。</p><p>对于这个新轮子，Nue JS 作者称他对当前的 Web 开发生态并不满意，所以想从头开始编写一个全新的生态。在过去的 12 个月里，他一直在投入到 Nue 的开发中，最近全职参与。</p><p>当然他也使用了一些「旧」的创新概念，例如渐进增强、关注点分离 (Separation of concerns) 和语义化 Web 设计。</p><p><img src="https://static.oschina.net/uploads/space/2023/0918/120355_pfQe_2720166.png" referrerpolicy="no-referrer"></p><p>Nue JS 是这个生态的核心组件，其他部分还没完成：</p><ul><li><strong>Nue JS：</strong>使用减少 10 倍的代码构建用户界面</li><li><strong>Nue CSS：</strong>恢复级联​​样式的力量</li><li><strong>Nue MVC：</strong>构建可扩展的直观单页应用程序</li><li><strong>Nue UI：</strong>用于快速 UI 开发的可复用组件</li><li><strong>Nuemark：</strong>提供丰富互动内容的 Markdown 风味版本</li><li><strong>Nuekit：</strong>使用减少 10 倍的代码构建网站和 Web 应用程序</li></ul><p>作者表示，一旦所有子项目完成，Nue 将成为 Vite、Next.js 和 Astro 等项目的重要替代品。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 03:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258529/nue-ecosystem</guid>
            <link>https://www.oschina.net/news/258529/nue-ecosystem</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Unity 道歉：将修改]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>对于上周引发激烈争议的 <a href="https://www.oschina.net/news/257929/unity-runtime-fee" target="_blank">"runtime fee" 收费政策</a>，Unity 官方今日终于正式进行了回应。他们表示对收费政策带来的混乱和焦虑深表歉意，目前正在与团队成员、社区、客户和合作伙伴交流，听取各方意见，以及修改政策——过几天会公布。</p><p><img src="https://static.oschina.net/uploads/space/2023/0918/103856_LA5P_2720166.png" referrerpolicy="no-referrer"></p><p>前几天 Unity 高管 Marc Whitten 已针对这一争议事件<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.axios.com%2F2023%2F09%2F13%2Funity-runtime-fee-policy-marc-whitten">向外媒 Axios 进行了回复：</a></p><blockquote><p>Unity 公司实际上只会对第一次安装进行收费，但另一方面如果同一位用户在另一台不同的设备上安装游戏（例如在 PC 上安装后再在 Steam Deck 上安装），则依然会被计入收费。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0915/180359_xxCE_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>Marc Whitten 还澄清了其他几点，包括游戏试玩 Demo 下载不会被计入收取 「运行费」，除非 「Demo 是包含在完整游戏下载中的一部分」，以及抢先体验游戏将被收费，而为慈善事业提供或纳入慈善的游戏将被免费除费用。</p><p>延伸阅读：</p><ul><li><a href="https://www.oschina.net/news/257929/unity-runtime-fee">Unity 引擎明年起根据游戏安装量收费 (runtime fee)</a></li><li><a href="https://www.oschina.net/news/258280/unity-closes-offices-following-death-threats">游戏引擎开发商 Unity 收到死亡威胁</a></li><li><a href="https://www.oschina.net/news/258477/wait-is-unity-allowed-to-just-change-its-fee-structure-like-that">走近 「收费门」：互相矛盾的服务条款导致 Unity 面临被起诉的风险</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 03:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258513/unity-apologize-for-runtime-fee</guid>
            <link>https://www.oschina.net/news/258513/unity-apologize-for-runtime-fee</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维天工大模型推理能力大幅超过 GPT-3.5 和 LLaMA2]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>9 月 16 日，在权威推理榜单 Benchmark GSM8K 测试中，昆仑万维完全自研的天工大模型以 80% 的正确率脱颖而出，大幅领先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%），「这标志着天工的推理能力达到全球领先，接近 GPT-4」。</p><p>与此同时，<span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">在 MMLU 数据集测试中，天工以 65% 准确率超越了 LLaMA-65B 的 63.4%；</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">在 C-EVAL 数据集测试中，天工以 65% 准确率超越了 GPT3.5 的 54.4%。</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">在 HumanEval 数据集测试中，天工以 37.2% 的准确率超过了 PaLM-540B（26.2%）、LLaMA-65B（23.7%）、LLaMa2 -70B（30.5%）。</span></p><p><img height="229" src="https://oscimg.oschina.net/oscnet/up-2106808c877e4262f7093741a3ddbe71025.png" width="500" referrerpolicy="no-referrer"></p><p>「<span>推理能力对于判断一个基座大模型是否「聪明」至关重要。在 GSM8K、MMLU、C-EVAL、HumanEval 四项数据集测试中，天工大模型均获得较高的正确率，表明天工大模型的通用能力很强，核心性能均达到了国际领先水准。</span>」</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><span>GSM8K 英文数据集测试<span>是<span>目前</span><span>全球公认的</span>评判基座大</span><span>模型推理能力的权威标准。</span>GSM8K 包含 8500 个高质量的数学问题。这些问题被分为 7500 个训练问题和 1000 个测试问题，一般需要 2 到 8 个步骤来解决。这些问题的解决主要涉及算术运算。GSM8K 数据集的目的是用来测试推理多步数学问题的能力。研究人员通常使用 GSM8K 来评估大型语言模型在解决英文数学问题时的性能表现。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><span>除了英文数据集，天工大模型在小米的中文开源数据集 CMATH 测试中也表现良好。CMATH 数据集包括 1700 个小学水平的数学应用题和详细的注释，旨在提供一个基准工具，评估当前流行的大模型的数学能力对应小学数学哪一年级的水平，在这份测试集中天工大模型的平均准确率为 76.4% 高于 ChatGPT 的平均准确率 74.8%。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><strong><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">天工和 GPT-3.5 在 GSM8K 测试中的具体表现，示例：</span></strong></p><blockquote><p style="color:#333333; margin-left:5px; margin-right:5px; text-align:justify"><span>E<span>very day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy.&nbsp; She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed.&nbsp; In the afternoon, she gives her chickens another 25 cups of feed.&nbsp; How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi's flock is 20 chickens?</span></span></p><p style="color:#333333; margin-left:5px; margin-right:5px; text-align:left"><span>案例为英文。注释：每天，Wendi 给每只鸡喂三杯混合鸡饲料，其中包括种子、黄粉虫和蔬菜，以帮助它们保持健康。她分三餐给鸡喂食。上午，她给鸡群喂 15 杯饲料。下午，她再给鸡喂 25 杯饲料。如果 Wendi 的鸡群有 20 只鸡，那么一天的最后一餐她需要给鸡喂多少杯饲料？</span></p></blockquote><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><strong>天工<span>给出的解题思路</span>：</strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><img alt="" height="419" src="https://oscimg.oschina.net/oscnet/up-7eb47dfe04b852b49d438f0f1f15ad1f1fa.png" width="500" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><span><span>最后天工大模型给出的答案是：</span><span>Wendi<span>&nbsp;</span></span>需要在一天的最后一餐中给鸡喂<span><span>&nbsp;</span>20<span>&nbsp;</span></span>杯饲料，以确保它们一天都吃饱。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><strong><span>GPT-3.5 给出的解题思路：</span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><span><img alt="" height="688" src="https://oscimg.oschina.net/oscnet/up-26ce32130080aba37dafd59dbb3078fbf69.png" width="500" referrerpolicy="no-referrer"></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify"><span><span>GPT-3.5</span><span>给出的答案为：</span><span>Wendi<span>&nbsp;</span></span><span>需要在一天的最后一餐中给鸡喂</span><span><span>&nbsp;</span>21<span>&nbsp;</span></span><span>杯饲料，为错误的答案。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:5px; margin-right:5px; text-align:justify">目前天工大模型仍属于内测阶段，以上评测暂未整合到天工 AI 搜索和天工 AI 助手，官方<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1UkXNOZRoInoLf8SvtTWRg" target="_blank">表示</a>后续会将最好的基座部署上线，供用户体验。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 02:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258509</guid>
            <link>https://www.oschina.net/news/258509</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 基于 HBase Client API 设计的 SQL 查询器 HydraQL]]>
            </title>
            <description>
                <![CDATA[<p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fhydraql.com"><img src="http://leo-jie-pic.oss-cn-beijing.aliyuncs.com/blog/4imexl.png" width="45%" referrerpolicy="no-referrer"></a></p><p align="center"><strong>🍬 HydraQL [ˈhaɪdrəQL]，是基于 HBase 原生客户端 API 设计的一款 SQL 查询器，专为简化 HBase 的使用而打造。</strong></p><p align="center">
👉 <a href="https://gitee.com/link?target=https%3A%2F%2Fhydraql.com">https://hydraql.com/</a> 👈
</p><p align="center"><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fsearch.maven.org%2Fartifact%2Fcom.hydraql%2Fhydraql"><img src="https://img.shields.io/:maven3+-maven-blue.svg" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fopensource.org%2Flicense%2Fmit%2F"><img src="https://img.shields.io/:license-mit-blue.svg" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjavase-jdk8-downloads.html"><img src="https://img.shields.io/badge/JDK-8+-green.svg" referrerpolicy="no-referrer"></a></p><hr><p><a href="https://gitee.com/weixiaotome/hydra-ql/blob/master/README-EN.md"><strong>🌎English Documentation</strong></a></p><hr><h2><a id="user-content-简介" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E7%AE%80%E4%BB%8B"></a>📚简介</h2><p><code>HydraQL</code> 是基于 <code>hbase-clinet</code> API 设计的一款 SQL 查询器，专为简化 HBase 的使用而打造。</p><p><code>HydraQL</code>旨在提供一种更直观和易用的方式来查询和操作 HBase 数据库。通过使用 SQL 语法或更精简的 API，
用户就可以轻松读写 HBase 表中的数据，而无需深入了解和编写复杂的方法调用。</p><p>与 Phoenix 相比，<code>HydraQL</code>中的 SQL 语法更轻量，无需引入额外的组件和配置即可使用，但目前还不支持二级索引。</p><h3><a id="user-content-hydraql 的名称由来" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#hydraql%E7%9A%84%E5%90%8D%E7%A7%B0%E7%94%B1%E6%9D%A5"></a>🎁HydraQL 的名称由来</h3><p><code>HydraQL</code>由 Hydra + SQL 拼接而来，其名称<strong>Hydra</strong>引用了「九头蛇」，象征着在处理 HBase 数据时的灵活性和多功能性。
<strong>hql</strong> 是其简称，一种类 SQL 的语言，其在执行时，会被翻译成<code>hbase-client</code>的原生 API 来读写 HBase 表中的数据。</p><h3><a id="user-content-hydraql 的理念" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#hydraql%E7%9A%84%E7%90%86%E5%BF%B5"></a>🍺HydraQL 的理念</h3><p><code>HydraQL</code> 是 HBase 的衍生工具集，它融合了 hql、HBatis、hbase-shell、hbase-thrift 等 API 的功能，你可以按需引用，也可以<strong>拷贝</strong>和修改源码使用，
这并不会有什么限制，只希望能及时反馈 bug，或提供更好的建议。</p><hr><h2><a id="user-content-️模块信息" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%EF%B8%8F%E6%A8%A1%E5%9D%97%E4%BF%A1%E6%81%AF"></a>⚙️模块信息</h2><p>项目结构：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">├── LICENSE</span><span id="LC2" class="line">├── README.md</span><span id="LC3" class="line">├── antlr</span><span id="LC4" class="line">├── bin</span><span id="LC5" class="line">├── build</span><span id="LC6" class="line">├── hydraql-adapter</span><span id="LC7" class="line">│&nbsp;&nbsp; ├── hydraql-adapter-common</span><span id="LC8" class="line">│&nbsp;&nbsp; ├── hydraql-adapter_1.2</span><span id="LC9" class="line">│&nbsp;&nbsp; ├── hydraql-adapter_1.4</span><span id="LC10" class="line">│&nbsp;&nbsp; ├── hydraql-adapter_2.2</span><span id="LC11" class="line">├── hydraql-common</span><span id="LC12" class="line">├── hydraql-console</span><span id="LC13" class="line">├── hydraql-dsl</span><span id="LC14" class="line">├── hydraql-examples</span><span id="LC15" class="line">├── hydraql-tests</span><span id="LC16" class="line">│&nbsp;&nbsp; ├── hydraql-example</span><span id="LC17" class="line">│&nbsp;&nbsp; ├── hydraql-shell-example</span><span id="LC18" class="line">│&nbsp;&nbsp; └── spring-boot-starter-hydraql-example</span><span id="LC19" class="line">├── hydraql-shell</span><span id="LC20" class="line">│&nbsp;&nbsp; ├── hydraql-shell-core</span><span id="LC21" class="line">│&nbsp;&nbsp; ├── hydraql-shell_1.2</span><span id="LC22" class="line">│&nbsp;&nbsp; ├── hydraql-shell_1.4</span><span id="LC23" class="line">│&nbsp;&nbsp; ├── hydraql-shell_2.2</span><span id="LC24" class="line">├── hydraql-template</span><span id="LC25" class="line">├── hydraql-thrift</span><span id="LC26" class="line">└── spring-boot-starter-hydraql</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>核心模块介绍：</p><table><thead><tr><th>模块</th><th>介绍</th></tr></thead><tbody><tr><td>hydraql-common</td><td>对一些公共方法的封装</td></tr><tr><td>hydraql-dsl</td><td>hql 的定义，以及使用 antr4 解析 hql，并转换 hbase-client 的调用</td></tr><tr><td>hydraql-adapter</td><td>统一 HBase 数据读写的接口，并针对不同版本的<code>hbase-client</code> api 进行适配和增强，屏蔽了多版本下 hbase-client api 不兼容</td></tr><tr><td>hydraql-template</td><td>依赖 hydraql-adapter，对外统一暴露为模版类和模版方法</td></tr><tr><td>hydraql-tests</td><td>利用 HBaseMiniCluster 来做单元测试</td></tr><tr><td>spring-boot-starter-hydraql</td><td>可以利用 spring-boot-starter-hydraql 与 Spring Boot 轻松集成</td></tr><tr><td>hydraql-thrift</td><td>对 HBase thrift API 的池化和封装</td></tr><tr><td>hydraql-shell</td><td>对 HBase Shell 的封装，支持直接在 java 进程中执行 hbase-shell 的 JRuby 环境，可以利用该模块，封装 web-hbase-shell</td></tr><tr><td>hydraql-console</td><td>hql 的命令行交互程序</td></tr></tbody></table><h2><a id="user-content-️功能特性" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%EF%B8%8F%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7"></a>🛠️功能特性</h2><p>对<code>hbase-client</code>原生 API 进行了统一的接口定义，屏蔽了底层 API 的复杂调用方式，消除了跨版本升级过程中 API 不兼容的问题。
在保障原有功能的同时，额外扩展了其他优秀特性，列举如下：</p><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 定义了统一的接口规范，消除了不同版本<code>hbase-client</code>API 之间的差异</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> HQL，以类 SQL 的形式读写 HBase 的表中数据</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> HBatis, 类似 MyBatis，提供<strong>ORM</strong>的特性，支持以注解的方式快速定义表、列簇、字段的数据模型，在保存和查询数据时，底层自动做数据类型转换</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 对 HBase 的原生 thrift API 进行池化封装，提供了 HBaseThriftPool 的功能</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 利用 spring-boot-starter-hydraql 可与 SpringBoot 无缝集成</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 支持 kerberos 认证，支持 kerberos 认证的超级用户代理普通用户</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 支持类似 hdfs 的 hbase.client.hedged.read 功能，在读主集群达到超时阈值或异常时，自动降级读备集群数据，此功能要求 HBase 主备集群互相 Replication</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> hydraql-shell，把 hbase-shell 封装到一个 jar 包中，可被其他项目通过 maven 等方式依赖，这在你想开发 hbase-web-shell 的功能时非常有用</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> hydraql-console，命令行交互工具，可以同时执行 hql 和 hbase-shell 的指令，可完全替代 hbase-shell 来使用</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> HBatis，类似于 myBatis，提供配置文件管理 HQL 的功能（规划中）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> thrift 连接池中连接数的动态扩所容能力（规划中）</li></ul><hr><h2><a id="user-content-文档" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E6%96%87%E6%A1%A3"></a>📝文档</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.docs.hydraql.com">📘中文文档</a></p><p><a href="https://apidoc.gitee.com/weixiaotome/HydraQL/" rel="nofollow">📙参考 API</a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FB">🎬视频介绍</a></p><hr><h2><a id="user-content-支持 hydraql" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E6%94%AF%E6%8C%81hydraql"></a>🪙支持 HydraQL</h2><h3><a id="user-content-捐赠" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E6%8D%90%E8%B5%A0"></a>💳捐赠</h3><p>如果你觉得 HydraQL 不错，可以请维护者吃包辣条~，在此表示感谢^_^。</p><p align="center"><a target="_blank"><img alt="赞助" src="http://leo-jie-pic.oss-cn-beijing.aliyuncs.com/blog/9zbk1v.png?raw=true" referrerpolicy="no-referrer"></a></p><hr><h2><a id="user-content-使用指南" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97"></a>📦使用指南</h2><h3><a id="user-content-maven" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#maven"></a>🍊Maven</h3><p>在普通 maven 项目中使用，在项目的 pom.xml 的 dependencies 中加入以下内容:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;properties&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;hydraql.hbase.adapter.version&gt;</span>1.2<span class="nt">&lt;/hydraql.hbase.adapter.version&gt;</span></span><span id="LC3" class="line"><span class="c">&lt;!--    &lt;hydraql.hbase.adapter.version&gt;1.4&lt;/hydraql.hbase.adapter.version&gt;--&gt;</span></span><span id="LC4" class="line"><span class="c">&lt;!--    &lt;hydraql.hbase.adapter.version&gt;2.2&lt;/hydraql.hbase.adapter.version&gt;--&gt;</span></span><span id="LC5" class="line"><span class="nt">&lt;/properties&gt;</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="nt">&lt;dependency&gt;</span></span><span id="LC8" class="line"><span class="nt">&lt;groupId&gt;</span>com.hydraql<span class="nt">&lt;/groupId&gt;</span></span><span id="LC9" class="line"><span class="nt">&lt;artifactId&gt;</span>hydraql-template_${hydraql.hbase.adapter.version}<span class="nt">&lt;/artifactId&gt;</span></span><span id="LC10" class="line"><span class="nt">&lt;version&gt;</span>1.0.0<span class="nt">&lt;/version&gt;</span></span><span id="LC11" class="line"><span class="nt">&lt;/dependency&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>在 Spring Boot 项目中使用，在项目的 pom.xml 的 dependencies 中加入以下内容:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nt">&lt;properties&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;hydraql.hbase.adapter.version&gt;</span>1.2<span class="nt">&lt;/hydraql.hbase.adapter.version&gt;</span></span><span id="LC3" class="line"><span class="c">&lt;!--    &lt;hydraql.hbase.adapter.version&gt;1.4&lt;/hydraql.hbase.adapter.version&gt;--&gt;</span></span><span id="LC4" class="line"><span class="c">&lt;!--    &lt;hydraql.hbase.adapter.version&gt;2.2&lt;/hydraql.hbase.adapter.version&gt;--&gt;</span></span><span id="LC5" class="line"><span class="nt">&lt;/properties&gt;</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="nt">&lt;dependency&gt;</span></span><span id="LC8" class="line"><span class="nt">&lt;groupId&gt;</span>com.hydraql<span class="nt">&lt;/groupId&gt;</span></span><span id="LC9" class="line"><span class="nt">&lt;artifactId&gt;</span>spring-boot-starter-hydraql_${hydraql.hbase.adapter.version}<span class="nt">&lt;/artifactId&gt;</span></span><span id="LC10" class="line"><span class="nt">&lt;version&gt;</span>1.0.0<span class="nt">&lt;/version&gt;</span></span><span id="LC11" class="line"><span class="nt">&lt;/dependency&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>根据所需 hbase 的版本来指定不同的<code>hydraql.hbase.adapter.version</code>，目前支持的 hbase 版本有：1.2.x，1.4.x，2.0.x ~ 2.2.x，</p><p>更多 HBase 版本的支持还在持续构建中 ～</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Frepo1.maven.org%2Fmaven2%2Fcom%2Fhydraql%2Fhydraql%2F1.0.0%2F">Maven 中央库</a></li></ul><blockquote><p>🔔️注意
最新版本的发行包可能更新不及时，同时，hydraql 在构建发行包时，默认把 hbase--shaded-client 的依赖一起打包。
如果对 hbase 的版本要求强一致，可以选择修改 hbase-client 的版本后，自行编译安装，再在项目中引入</p></blockquote><h3><a id="user-content-gradle" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#gradle"></a>🍐Gradle</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">implementation 'com.hydraql:hydraql-template_1.2:1.0.0'</span><span id="LC2" class="line">implementation 'com.hydraql:hydraql-template_1.4:1.0.0'</span><span id="LC3" class="line">implementation 'com.hydraql:hydraql-template_2.2:1.0.0'</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-编译安装" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85"></a>🚽编译安装</h3><p>访问<code>HydraQL</code>的 GItHub 主页：<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FCCweixiao%2FHydraQL">https://github.com/CCweixiao/HydraQL</a> 下载整个项目源码（master 分支）然后进入 HydraQL 项目的根目录下执行：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">sh bin/build.sh 1.2/1.4/2.2</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>或</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c"># 默认 1.2</span></span><span id="LC2" class="line">mvn clean <span class="nb">install</span><span class="nt">-Dmaven</span>.test.skip<span class="o">=</span><span class="nb">true</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c"># 1.4</span></span><span id="LC5" class="line">mvn clean <span class="nb">install</span><span class="nt">-Dmaven</span>.test.skip<span class="o">=</span><span class="nb">true</span><span class="nt">-Dhbase</span>.profile<span class="o">=</span>1.4</span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="c"># 2.2 </span></span><span id="LC8" class="line">mvn clean <span class="nb">install</span><span class="nt">-Dmaven</span>.test.skip<span class="o">=</span><span class="nb">true</span><span class="nt">-Dhbase</span>.profile<span class="o">=</span>2.2</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>如果你想在本地进行开发，扩展额外的功能，请确保已经安装了 Java8 和 maven3.6+，同时建议在本地部署一个可连通的 HBase 开发环境。
建议使用 docker 来快速搭建一个 HBase 的单机环境，可以参考博客：<a href="https://gitee.com/link?target=https%3A%2F%2Fblog.csdn.net%2Ffeinifi%2Farticle%2Fdetails%2F121174846">https://blog.csdn.net/feinifi/article/details/121174846</a></p><h3><a id="user-content-快速入门" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"></a>快速入门</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testSaveAndGet</span><span class="o">(){</span></span><span id="LC3" class="line"><span class="nc">Configuration</span><span class="n">conf</span><span class="o">=</span><span class="nc">HBaseConfiguration</span><span class="o">.</span><span class="na">create</span><span class="o">();</span></span><span id="LC4" class="line"><span class="nc">HBaseTableTemplate</span><span class="n">tableTemplate</span><span class="o">=</span><span class="nc">HBaseTableTemplate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></span><span id="LC5" class="line"></span><span id="LC6" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Object</span><span class="o">&gt;</span><span class="n">data</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">);</span></span><span id="LC7" class="line"><span class="n">data</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"f1:name"</span><span class="o">,</span><span class="s">"leo"</span><span class="o">);</span></span><span id="LC8" class="line"><span class="n">data</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"f1:age"</span><span class="o">,</span><span class="mi">18</span><span class="o">);</span></span><span id="LC9" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="s">"test_table"</span><span class="o">,</span><span class="s">"1001"</span><span class="o">,</span><span class="n">data</span><span class="o">);</span></span><span id="LC10" class="line"><span class="nc">HBaseRowData</span><span class="n">rowData</span><span class="o">=</span><span class="n">tableTemplate</span><span class="o">.</span><span class="na">getRow</span><span class="o">(</span><span class="s">"test_table"</span><span class="o">,</span><span class="nc">GetRowParam</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="s">"1001"</span><span class="o">).</span><span class="na">build</span><span class="o">());</span></span><span id="LC11" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>更多测试用例请参考：<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FCCweixiao%2FHydraQL%2Fblob%2Fmaster%2Fhydraql-tests%2Fhydraql-template-test%2Fsrc%2Ftest%2Fjava%2Fcom%2Fhydraql%2Ftemplate%2FHBaseTableTestTemplateTest.java">更多测试用例</a></p><h2><a id="user-content-使用手册" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C"></a>使用手册</h2><h3><a id="user-content-连接配置" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E8%BF%9E%E6%8E%A5%E9%85%8D%E7%BD%AE"></a>连接配置</h3><p><strong>普通 Java 项目</strong></p><p><strong>普通认证</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 普通认证</span></span><span id="LC2" class="line"><span class="nc">Configuration</span><span class="n">conf</span><span class="o">=</span><span class="nc">HBaseConfiguration</span><span class="o">.</span><span class="na">create</span><span class="o">();</span></span><span id="LC3" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.zookeeper.quorum"</span><span class="o">,</span><span class="s">"myhbase"</span><span class="o">);</span></span><span id="LC4" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.zookeeper.property.clientPort"</span><span class="o">,</span><span class="s">"2181"</span><span class="o">);</span></span><span id="LC5" class="line"><span class="c1">// 请按需引入一些额外所需的客户端配置</span></span><span id="LC6" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.client.retries.number"</span><span class="o">,</span><span class="s">"3"</span><span class="o">);</span></span><span id="LC7" class="line"><span class="nc">HBaseTableTemplate</span><span class="n">tableTemplate</span><span class="o">=</span><span class="nc">HBaseTableTemplate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>或者在项目的 src/main/resources 目录下放入<code>hbase-site.xml</code>配置文件</p><p><strong>Kerberos 认证</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nc">Configuration</span><span class="n">conf</span><span class="o">=</span><span class="nc">HBaseConfiguration</span><span class="o">.</span><span class="na">create</span><span class="o">();</span></span><span id="LC2" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.zookeeper.quorum"</span><span class="o">,</span><span class="s">"zk1,zk2,zk3"</span><span class="o">);</span></span><span id="LC3" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.zookeeper.property.clientPort"</span><span class="o">,</span><span class="s">"2181"</span><span class="o">);</span></span><span id="LC4" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.security.authentication"</span><span class="o">,</span><span class="s">"kerberos"</span><span class="o">);</span></span><span id="LC5" class="line"></span><span id="LC6" class="line"><span class="c1">// 下面配置是 kerberos 认证方式所需</span></span><span id="LC7" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"kerberos.principal"</span><span class="o">,</span><span class="s">"hbase@HADOOP.LEO.COM"</span><span class="o">);</span></span><span id="LC8" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"keytab.file"</span><span class="o">,</span><span class="s">"/etc/hbase/conf/hbase.keytab"</span><span class="o">);</span></span><span id="LC9" class="line"><span class="c1">// 设置 kerberos 代理用户，默认为空即不进行设置，需保证 hbase 有代理其他用户的权限</span></span><span id="LC10" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"kerberos.proxy.user"</span><span class="o">,</span><span class="s">"leojie"</span><span class="o">);</span></span><span id="LC11" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.regionserver.kerberos.principal"</span><span class="o">,</span><span class="s">"hbase/_HOST@HADOOP.LEO.COM"</span><span class="o">);</span></span><span id="LC12" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.master.kerberos.principal"</span><span class="o">,</span><span class="s">"hbase/_HOST@HADOOP.LEO.COM"</span><span class="o">);</span></span><span id="LC13" class="line"><span class="c1">// 指定 kdc 服务相关的配置方式有如下两种：</span></span><span id="LC14" class="line"><span class="c1">// 方式一：指定 krb5.conf 路径</span></span><span id="LC15" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"java.security.krb5.conf"</span><span class="o">,</span><span class="s">"/etc/krb5.conf"</span><span class="o">);</span></span><span id="LC16" class="line"><span class="c1">// 方式二：指定 java.security.krb5.realm 和 java.security.krb5.kdc</span></span><span id="LC17" class="line"><span class="c1">// conf.set("java.security.krb5.realm", "HADOOP.LEO.COM");</span></span><span id="LC18" class="line"><span class="c1">// conf.set("java.security.krb5.kdc", "你自己的 kdc 服务地址");</span></span><span id="LC19" class="line"><span class="c1">// 一些额外的客户端参数</span></span><span id="LC20" class="line"><span class="n">conf</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">"hbase.client.retries.number"</span><span class="o">,</span><span class="s">"3"</span><span class="o">);</span></span><span id="LC21" class="line"><span class="nc">HBaseTableTemplate</span><span class="n">tableTemplate</span><span class="o">=</span><span class="nc">HBaseTableTemplate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>Spring Boot 项目</strong></p><p><strong>普通认证</strong></p><p>application.yaml</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="na">spring</span><span class="pi">:</span></span><span id="LC2" class="line"><span class="na">datasource</span><span class="pi">:</span></span><span id="LC3" class="line"><span class="na">hbase</span><span class="pi">:</span></span><span id="LC4" class="line"><span class="na">zk-quorum</span><span class="pi">:</span><span class="s">zk_host1,zk_host2,zk_host3</span></span><span id="LC5" class="line"><span class="na">zk-client-port</span><span class="pi">:</span><span class="m">2181</span><span class="c1"># (可选，默认 2181)</span></span><span id="LC6" class="line"><span class="na">dfs-root-dir</span><span class="pi">:</span><span class="s">/hbase</span><span class="c1"># (可选，默认/hbase)</span></span><span id="LC7" class="line"><span class="na">zk-node-parent</span><span class="pi">:</span><span class="s">/hbase</span><span class="c1"># (可选，默认/hbase)</span></span><span id="LC8" class="line"><span class="na">security-auth-way</span><span class="pi">:</span><span class="s">simple</span><span class="c1"># (可选，默认 simple)</span></span><span id="LC9" class="line"><span class="na">client-properties</span><span class="pi">:</span><span class="s">hbase.client.retries.number=3;key1=value2</span></span><span id="LC10" class="line"><span class="na">server</span><span class="pi">:</span></span><span id="LC11" class="line"><span class="na">port</span><span class="pi">:</span><span class="m">8088</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>Kerberos 认证</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="na">spring</span><span class="pi">:</span></span><span id="LC2" class="line"><span class="na">datasource</span><span class="pi">:</span></span><span id="LC3" class="line"><span class="na">hbase</span><span class="pi">:</span></span><span id="LC4" class="line"><span class="na">zk-quorum</span><span class="pi">:</span><span class="s">myhbase</span></span><span id="LC5" class="line"><span class="na">zk-client-port</span><span class="pi">:</span><span class="m">2181</span></span><span id="LC6" class="line"><span class="na">dfs-root-dir</span><span class="pi">:</span><span class="s">/hbase</span></span><span id="LC7" class="line"><span class="na">zk-node-parent</span><span class="pi">:</span><span class="s">/hbase</span></span><span id="LC8" class="line"><span class="na">security-auth-way</span><span class="pi">:</span><span class="s">kerberos</span></span><span id="LC9" class="line"><span class="na">kerberos-principal</span><span class="pi">:</span><span class="s">hbase@HADOOP.LEO.COM</span></span><span id="LC10" class="line"><span class="na">keytab-file-path</span><span class="pi">:</span><span class="s">/etc/hbase/conf/hbase.keytab</span></span><span id="LC11" class="line"><span class="na">kerberos-proxy-user</span><span class="pi">:</span><span class="s">test</span></span><span id="LC12" class="line"><span class="na">rs-kerberos-principal</span><span class="pi">:</span><span class="s">hbase/_HOST@HADOOP.LEO.COM</span></span><span id="LC13" class="line"><span class="na">master-kerberos-principal</span><span class="pi">:</span><span class="s">hbase/_HOST@HADOOP.LEO.COM</span></span><span id="LC14" class="line"><span class="na">krb5-conf-path</span><span class="pi">:</span><span class="s">/etc/krb5.conf</span></span><span id="LC15" class="line"><span class="na">krb5-realm</span><span class="pi">:</span></span><span id="LC16" class="line"><span class="na">krb5-kdc-server-addr</span><span class="pi">:</span></span><span id="LC17" class="line"><span class="na">client-properties</span><span class="pi">:</span><span class="s">hbase.client.retries.number=3</span></span><span id="LC18" class="line"><span class="na">server</span><span class="pi">:</span></span><span id="LC19" class="line"><span class="na">port</span><span class="pi">:</span><span class="m">8088</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Service</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kd">class</span><span class="nc">HBaseAdminService</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nd">@Autowired</span></span><span id="LC4" class="line"><span class="kd">private</span><span class="nc">BaseHBaseAdminTemplate</span><span class="n">adminTemplate</span><span class="o">;</span></span><span id="LC5" class="line"></span><span id="LC6" class="line"><span class="kd">public</span><span class="nc">List</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span><span class="nf">allTables</span><span class="o">()</span><span class="o">{</span></span><span id="LC7" class="line"><span class="k">return</span><span class="n">adminTemplate</span><span class="o">.</span><span class="na">listTableNames</span><span class="o">();</span></span><span id="LC8" class="line"><span class="o">}</span></span><span id="LC9" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-hydraql-template 模块介绍" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#hydraql-template%E6%A8%A1%E5%9D%97%E4%BB%8B%E7%BB%8D"></a>hydraql-template 模块介绍</h3><p><code>hydraql-template</code>模块中封装了三类模版操作类，分别是：</p><ul><li>HBaseAdminTemplate: 对 Admin 中方法的封装，比如：创建表，创建 namespace，list 表等</li><li>HBaseTableTemplate: 对 Table 中方法的封装，比如：put，get，scan，delete 等</li><li>HBaseSqlTemplate: 提供 hql 的功能</li></ul><p><img src="http://leo-jie-pic.oss-cn-beijing.aliyuncs.com/blog/r8hxhq.png" alt="UML" referrerpolicy="no-referrer"></p><p><strong>普通项目</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1">// 数据读写 API 的操作模版类</span></span><span id="LC2" class="line"><span class="nc">Configuration</span><span class="n">conf</span><span class="o">=</span><span class="nc">HBaseConfiguration</span><span class="o">.</span><span class="na">create</span><span class="o">();</span></span><span id="LC3" class="line"><span class="nc">BaseHBaseTableTemplate</span><span class="n">tableTemplate</span><span class="o">=</span><span class="nc">HBaseTableTemplate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></span><span id="LC4" class="line"></span><span id="LC5" class="line"><span class="c1">// Admin 操作模版类</span></span><span id="LC6" class="line"><span class="nc">BaseHBaseAdminTemplate</span><span class="n">adminTemplate</span><span class="o">=</span><span class="nc">HBaseAdminTemplate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></span><span id="LC7" class="line"></span><span id="LC8" class="line"><span class="c1">// HQL 操作模版类</span></span><span id="LC9" class="line"><span class="nc">BaseHBaseSqlTemplate</span><span class="n">sqlTemplate</span><span class="o">=</span><span class="nc">HBaseSqlTemplate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>SpringBoot 项目</strong></p><p>@Autowired 依赖注入</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Service</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kd">class</span><span class="nc">UserService</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nd">@Autowired</span></span><span id="LC4" class="line"><span class="kd">private</span><span class="nc">BaseHBaseTableTemplate</span><span class="n">tableTemplate</span><span class="o">;</span></span><span id="LC5" class="line"><span class="nd">@Autowired</span></span><span id="LC6" class="line"><span class="kd">private</span><span class="nc">BaseHBaseAdminTemplate</span><span class="n">adminTemplate</span><span class="o">;</span></span><span id="LC7" class="line"><span class="nd">@Autowired</span></span><span id="LC8" class="line"><span class="kd">private</span><span class="nc">BaseHBaseSqlTemplate</span><span class="n">sqlTemplate</span><span class="o">;</span></span><span id="LC9" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-basehbaseadmintemplate 使用" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#basehbaseadmintemplate%E4%BD%BF%E7%94%A8"></a>BaseHBaseAdminTemplate 使用</h3><p><code>BaseHBaseAdminTemplate</code>封装了<code>hbase-client</code>中 Admin 的常用操作，比如 namespace 的创建和删除、表的创建和删除、以及快照管理等等，后续这些 API 将会更加完整。</p><p><img src="https://leo-jie-pic.oss-cn-beijing.aliyuncs.com/leo_blog/2020-11-29-120523.jpg" alt="admin-api" referrerpolicy="no-referrer"></p><p><strong>创建 namespace</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">createNameSpace</span><span class="o">()</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">NamespaceDesc</span><span class="n">namespaceDesc</span><span class="o">=</span><span class="k">new</span><span class="nc">NamespaceDesc</span><span class="o">();</span></span><span id="LC4" class="line"><span class="n">namespaceDesc</span><span class="o">.</span><span class="na">setNamespaceName</span><span class="o">(</span><span class="s">"test_nn"</span><span class="o">);</span></span><span id="LC5" class="line"><span class="n">namespaceDesc</span><span class="o">.</span><span class="na">addNamespaceProp</span><span class="o">(</span><span class="s">"createdBy"</span><span class="o">,</span><span class="s">"leojie"</span><span class="o">);</span></span><span id="LC6" class="line"><span class="n">adminTemplate</span><span class="o">.</span><span class="na">createNamespaceAsync</span><span class="o">(</span><span class="n">namespaceDesc</span><span class="o">);</span></span><span id="LC7" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>创建表</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testCreateTable</span><span class="o">()</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">ColumnFamilyDesc</span><span class="n">f1</span><span class="o">=</span><span class="nc">ColumnFamilyDesc</span><span class="o">.</span><span class="na">newBuilder</span><span class="o">()</span></span><span id="LC4" class="line"><span class="o">.</span><span class="na">name</span><span class="o">(</span><span class="s">"f1"</span><span class="o">)</span></span><span id="LC5" class="line"><span class="o">.</span><span class="na">build</span><span class="o">();</span></span><span id="LC6" class="line"><span class="nc">ColumnFamilyDesc</span><span class="n">f2</span><span class="o">=</span><span class="nc">ColumnFamilyDesc</span><span class="o">.</span><span class="na">newBuilder</span><span class="o">()</span></span><span id="LC7" class="line"><span class="o">.</span><span class="na">name</span><span class="o">(</span><span class="s">"f2"</span><span class="o">)</span></span><span id="LC8" class="line"><span class="o">.</span><span class="na">timeToLive</span><span class="o">(</span><span class="mi">3600</span><span class="o">)</span></span><span id="LC9" class="line"><span class="o">.</span><span class="na">maxVersions</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span></span><span id="LC10" class="line"><span class="o">.</span><span class="na">build</span><span class="o">();</span></span><span id="LC11" class="line"><span class="nc">HTableDesc</span><span class="n">tableDesc</span><span class="o">=</span><span class="nc">HTableDesc</span><span class="o">.</span><span class="na">newBuilder</span><span class="o">()</span></span><span id="LC12" class="line"><span class="o">.</span><span class="na">name</span><span class="o">(</span><span class="s">"leo_test_22222"</span><span class="o">)</span></span><span id="LC13" class="line"><span class="o">.</span><span class="na">addFamilyDesc</span><span class="o">(</span><span class="n">f1</span><span class="o">)</span></span><span id="LC14" class="line"><span class="o">.</span><span class="na">addFamilyDesc</span><span class="o">(</span><span class="n">f2</span><span class="o">)</span></span><span id="LC15" class="line"><span class="o">.</span><span class="na">build</span><span class="o">();</span></span><span id="LC16" class="line"><span class="n">adminTemplate</span><span class="o">.</span><span class="na">createTable</span><span class="o">(</span><span class="n">tableDesc</span><span class="o">);</span></span><span id="LC17" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>更多测试用例请参考 <code>hydraql-tests</code>模块</p><h3><a id="user-content-basehbasetabletemplate 使用" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#basehbasetabletemplate%E4%BD%BF%E7%94%A8"></a>BaseHBaseTableTemplate 使用</h3><p><code>BaseHBaseTableTemplate</code>中封装了对 HBase 表数据的读、写、删除等操作。</p><p><strong>普通方式读写</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testSaveMap</span><span class="o">()</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Object</span><span class="o">&gt;</span><span class="n">data</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">);</span></span><span id="LC4" class="line"><span class="n">data</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"f1:name"</span><span class="o">,</span><span class="s">"leo"</span><span class="o">);</span></span><span id="LC5" class="line"><span class="n">data</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"f1:age"</span><span class="o">,</span><span class="mi">18</span><span class="o">);</span></span><span id="LC6" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="s">"1001"</span><span class="o">,</span><span class="n">data</span><span class="o">);</span></span><span id="LC7" class="line"><span class="nc">HBaseRowData</span><span class="n">rowData</span><span class="o">=</span><span class="n">tableTemplate</span><span class="o">.</span><span class="na">getRow</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="nc">GetRowParam</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="s">"1001"</span><span class="o">).</span><span class="na">build</span><span class="o">());</span></span><span id="LC8" class="line"><span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span><span class="n">rowData</span><span class="o">.</span><span class="na">getColDataContainer</span><span class="o">().</span><span class="na">size</span><span class="o">());</span></span><span id="LC9" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>ORM 特性</strong></p><ol><li>创建数据模型类</li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">public</span><span class="kd">class</span><span class="nc">CityTag</span><span class="o">{</span></span><span id="LC2" class="line"><span class="kd">private</span><span class="nc">String</span><span class="n">tagName</span><span class="o">;</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="kd">public</span><span class="nf">CityTag</span><span class="o">(</span><span class="nc">String</span><span class="n">tagName</span><span class="o">)</span><span class="o">{</span></span><span id="LC5" class="line"><span class="k">this</span><span class="o">.</span><span class="na">tagName</span><span class="o">=</span><span class="n">tagName</span><span class="o">;</span></span><span id="LC6" class="line"><span class="o">}</span></span><span id="LC7" class="line"><span class="c1">// 省略 Getter/Setter/toString</span></span><span id="LC8" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@HBaseTable</span><span class="o">(</span><span class="n">namespaceName</span><span class="o">=</span><span class="s">"default"</span><span class="o">,</span><span class="n">tableName</span><span class="o">=</span><span class="s">"test_table"</span><span class="o">,</span><span class="n">defaultFamilyName</span><span class="o">=</span><span class="s">"f1"</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kd">class</span><span class="nc">CityModel</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nd">@HBaseRowKey</span></span><span id="LC4" class="line"><span class="kd">private</span><span class="nc">String</span><span class="n">cityId</span><span class="o">;</span></span><span id="LC5" class="line"><span class="kd">private</span><span class="nc">String</span><span class="n">cityName</span><span class="o">;</span></span><span id="LC6" class="line"><span class="kd">private</span><span class="nc">String</span><span class="n">cityAddress</span><span class="o">;</span></span><span id="LC7" class="line"><span class="nd">@HBaseColumn</span><span class="o">(</span><span class="n">familyName</span><span class="o">=</span><span class="s">"detail"</span><span class="o">)</span></span><span id="LC8" class="line"><span class="kd">private</span><span class="nc">Integer</span><span class="n">cityArea</span><span class="o">;</span></span><span id="LC9" class="line"><span class="nd">@HBaseColumn</span><span class="o">(</span><span class="n">familyName</span><span class="o">=</span><span class="s">"detail"</span><span class="o">,</span><span class="n">toUpperCase</span><span class="o">=</span><span class="kc">true</span><span class="o">)</span></span><span id="LC10" class="line"><span class="kd">private</span><span class="nc">Integer</span><span class="n">totalPopulation</span><span class="o">;</span></span><span id="LC11" class="line"><span class="nd">@HBaseColumn</span><span class="o">(</span><span class="n">familyName</span><span class="o">=</span><span class="s">"detail"</span><span class="o">,</span><span class="n">columnName</span><span class="o">=</span><span class="s">"cityTagList"</span><span class="o">)</span></span><span id="LC12" class="line"><span class="kd">private</span><span class="nc">List</span><span class="o">&lt;</span><span class="nc">CityTag</span><span class="o">&gt;</span><span class="n">cityTagList</span><span class="o">;</span></span><span id="LC13" class="line"><span class="c1">// 省略 Getter/Setter/toString</span></span><span id="LC14" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><code>@HBaseTable</code>注解用于定义 HBase 的表信息</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@HBaseTable</span><span class="o">(</span><span class="n">namespaceName</span><span class="o">=</span><span class="s">"default"</span><span class="o">,</span><span class="n">tableName</span><span class="o">=</span><span class="s">"t2"</span><span class="o">,</span><span class="n">defaultFamilyName</span><span class="o">=</span><span class="s">"info"</span><span class="o">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>1）namespaceName：用于指定该表的命名空间，默认：default
2）tableName：用于指定该表的表名，如果不指定，表名则为类名的组合单词拆分转小写加'_'拼接，如：CityModel 对应的表名为：city_model。
3）defaultFamilyName：用于定义如果有字段不特配置（@HBaseRowKey 注解中的 familyName）列簇名，则使用此处配置的列簇名。</p><p><code>@HBaseRowKey</code>注解用于定义某一个属性字段是用作存储 rowKey 数据的，是必须要设置的，如：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@HBaseRowKey</span></span><span id="LC2" class="line"><span class="kd">private</span><span class="nc">String</span><span class="n">cityId</span><span class="o">;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>该注解表示 cityId 字段为 rowKey，每一个模型类必须，也只能有一个字段被标识为 rowKey。</p><p><code>@HBaseColumn</code>注解用于定义 HBase 的列簇和列名信息，如：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@HBaseColumn</span><span class="o">(</span><span class="n">familyName</span><span class="o">=</span><span class="s">"detail"</span><span class="o">,</span><span class="n">columnName</span><span class="o">=</span><span class="s">"TOTAL_POPULATION"</span><span class="o">,</span><span class="n">toUpperCase</span><span class="o">=</span><span class="kc">true</span><span class="o">)</span></span><span id="LC2" class="line"><span class="kd">private</span><span class="nc">Integer</span><span class="n">totalPopulation</span><span class="o">;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>1）familyName：指定列簇名，不指定，则使用 defaultFamilyName 配置的列簇名。
2）columnName：指定列名，不指定则默认使用字段名的组合单词拆分转小写加'_'拼接，如：isVip，对应的字段名是：is_vip
3）toUpperCase：定义字段名是否转大写，如：isVip -&gt; IS_VIP，默认值：false，不做转换。</p><ol start="2"><li>存取数据</li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testSave</span><span class="o">()</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">CityModel</span><span class="n">cityModel</span><span class="o">=</span><span class="nc">CityModelUtil</span><span class="o">.</span><span class="na">createDefaultCityModel</span><span class="o">();</span></span><span id="LC4" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">cityModel</span><span class="o">);</span></span><span id="LC5" class="line"><span class="nc">GetRowParam</span><span class="n">getRowParam</span><span class="o">=</span><span class="nc">GetRowParam</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">cityModel</span><span class="o">.</span><span class="na">getCityId</span><span class="o">()).</span><span class="na">build</span><span class="o">();</span></span><span id="LC6" class="line"><span class="nc">Optional</span><span class="o">&lt;</span><span class="nc">CityModel</span><span class="o">&gt;</span><span class="n">cityModelRes</span><span class="o">=</span><span class="n">tableTemplate</span><span class="o">.</span><span class="na">getRow</span><span class="o">(</span><span class="n">getRowParam</span><span class="o">,</span><span class="nc">CityModel</span><span class="o">.</span><span class="na">class</span><span class="o">);</span></span><span id="LC7" class="line"><span class="nc">Assert</span><span class="o">.</span><span class="na">assertNotNull</span><span class="o">(</span><span class="n">cityModelRes</span><span class="o">);</span></span><span id="LC8" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ol start="3"><li>批量存取数据</li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testSaveBatch</span><span class="o">()</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">List</span><span class="o">&lt;</span><span class="nc">CityModel</span><span class="o">&gt;</span><span class="n">cityModelList</span><span class="o">=</span><span class="nc">CityModelUtil</span><span class="o">.</span><span class="na">createDefaultCityModelList</span><span class="o">();</span></span><span id="LC4" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">saveBatch</span><span class="o">(</span><span class="n">cityModelList</span><span class="o">);</span></span><span id="LC5" class="line"><span class="nc">List</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span><span class="n">rowKeys</span><span class="o">=</span><span class="n">cityModelList</span><span class="o">.</span><span class="na">stream</span><span class="o">().</span><span class="na">map</span><span class="o">(</span><span class="nl">CityModel:</span><span class="o">:</span><span class="n">getCityId</span><span class="o">).</span><span class="na">collect</span><span class="o">(</span><span class="nc">Collectors</span><span class="o">.</span><span class="na">toList</span><span class="o">());</span></span><span id="LC6" class="line"><span class="nc">GetRowsParam</span><span class="n">getRowsParam</span><span class="o">=</span><span class="nc">GetRowsParam</span><span class="o">.</span><span class="na">of</span><span class="o">().</span><span class="na">rowKeyList</span><span class="o">(</span><span class="n">rowKeys</span><span class="o">).</span><span class="na">build</span><span class="o">();</span></span><span id="LC7" class="line"><span class="nc">List</span><span class="o">&lt;</span><span class="nc">CityModel</span><span class="o">&gt;</span><span class="n">rows</span><span class="o">=</span><span class="n">tableTemplate</span><span class="o">.</span><span class="na">getRows</span><span class="o">(</span><span class="n">getRowsParam</span><span class="o">,</span><span class="nc">CityModel</span><span class="o">.</span><span class="na">class</span><span class="o">);</span></span><span id="LC8" class="line"><span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="n">rowKeys</span><span class="o">.</span><span class="na">size</span><span class="o">(),</span><span class="n">rows</span><span class="o">.</span><span class="na">size</span><span class="o">());</span></span><span id="LC9" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ol start="4"><li>查询数据使用自定义的 RowMapper 解析字段</li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testGetByRowMapper</span><span class="o">()</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">GetRowParam</span><span class="n">getRowParam</span><span class="o">=</span><span class="nc">GetRowParam</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="s">"a10001"</span><span class="o">).</span><span class="na">build</span><span class="o">();</span></span><span id="LC4" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">String</span><span class="o">&gt;</span><span class="n">data</span><span class="o">=</span><span class="n">tableTemplate</span><span class="o">.</span><span class="na">getRow</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="n">getRowParam</span><span class="o">,</span><span class="k">new</span><span class="nc">RowMapper</span><span class="o">&lt;</span><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">String</span><span class="o">&gt;&gt;()</span><span class="o">{</span></span><span id="LC5" class="line"><span class="nd">@Override</span></span><span id="LC6" class="line"><span class="kd">public</span><span class="o">&lt;</span><span class="no">R</span><span class="o">&gt;</span><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">String</span><span class="o">&gt;</span><span class="nf">mapRow</span><span class="o">(</span><span class="no">R</span><span class="n">r</span><span class="o">,</span><span class="kt">int</span><span class="n">rowNum</span><span class="o">)</span><span class="kd">throws</span><span class="nc">Exception</span><span class="o">{</span></span><span id="LC7" class="line"><span class="nc">Result</span><span class="n">result</span><span class="o">=</span><span class="o">(</span><span class="nc">Result</span><span class="o">)</span><span class="n">r</span><span class="o">;</span></span><span id="LC8" class="line"><span class="k">if</span><span class="o">(</span><span class="n">result</span><span class="o">==</span><span class="kc">null</span><span class="o">)</span><span class="o">{</span></span><span id="LC9" class="line"><span class="k">return</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">0</span><span class="o">);</span></span><span id="LC10" class="line"><span class="o">}</span></span><span id="LC11" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">String</span><span class="o">&gt;</span><span class="n">data</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">);</span></span><span id="LC12" class="line"><span class="k">for</span><span class="o">(</span><span class="nc">Cell</span><span class="n">cell</span><span class="o">:</span><span class="n">result</span><span class="o">.</span><span class="na">listCells</span><span class="o">())</span><span class="o">{</span></span><span id="LC13" class="line"><span class="n">data</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="nc">Bytes</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="nc">CellUtil</span><span class="o">.</span><span class="na">cloneFamily</span><span class="o">(</span><span class="n">cell</span><span class="o">))</span><span class="o">+</span><span class="s">":"</span><span class="o">+</span><span class="nc">Bytes</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="nc">CellUtil</span><span class="o">.</span><span class="na">cloneQualifier</span><span class="o">(</span><span class="n">cell</span><span class="o">)),</span></span><span id="LC14" class="line"><span class="nc">Bytes</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="nc">CellUtil</span><span class="o">.</span><span class="na">cloneValue</span><span class="o">(</span><span class="n">cell</span><span class="o">)));</span></span><span id="LC15" class="line"><span class="o">}</span></span><span id="LC16" class="line"><span class="k">return</span><span class="n">data</span><span class="o">;</span></span><span id="LC17" class="line"><span class="o">}</span></span><span id="LC18" class="line"><span class="o">}).</span><span class="na">orElse</span><span class="o">(</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">0</span><span class="o">));</span></span><span id="LC19" class="line"><span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span><span class="n">data</span><span class="o">.</span><span class="na">size</span><span class="o">());</span></span><span id="LC20" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ol start="5"><li>scan 查询，自定义 Filter</li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testScanWithCustomFilter</span><span class="o">()</span><span class="o">{</span></span><span id="LC3" class="line"><span class="n">testSaveBatch</span><span class="o">();</span></span><span id="LC4" class="line"><span class="nc">ScanParams</span><span class="n">scanParams</span><span class="o">=</span><span class="nc">ScanParams</span><span class="o">.</span><span class="na">of</span><span class="o">()</span></span><span id="LC5" class="line"><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="k">new</span><span class="nc">IHBaseFilter</span><span class="o">&lt;</span><span class="nc">Filter</span><span class="o">&gt;()</span><span class="o">{</span></span><span id="LC6" class="line"><span class="nd">@Override</span></span><span id="LC7" class="line"><span class="kd">public</span><span class="nc">Filter</span><span class="nf">customFilter</span><span class="o">()</span><span class="o">{</span></span><span id="LC8" class="line"><span class="nc">List</span><span class="o">&lt;</span><span class="nc">Filter</span><span class="o">&gt;</span><span class="n">filters</span><span class="o">=</span><span class="k">new</span><span class="nc">ArrayList</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">);</span></span><span id="LC9" class="line"><span class="c1">// 筛选 row key 大于 b20001 的数据</span></span><span id="LC10" class="line"><span class="nc">Filter</span><span class="n">rowFilter</span><span class="o">=</span><span class="k">new</span><span class="nc">RowFilter</span><span class="o">(</span><span class="nc">CompareFilter</span><span class="o">.</span><span class="na">CompareOp</span><span class="o">.</span><span class="na">GREATER</span><span class="o">,</span></span><span id="LC11" class="line"><span class="k">new</span><span class="nf">BinaryComparator</span><span class="o">(</span><span class="s">"b20001"</span><span class="o">.</span><span class="na">getBytes</span><span class="o">()));</span></span><span id="LC12" class="line"><span class="c1">// 筛选列前缀 city_address 的数据</span></span><span id="LC13" class="line"><span class="nc">ColumnPrefixFilter</span><span class="n">columnPrefixFilter</span><span class="o">=</span><span class="k">new</span><span class="nc">ColumnPrefixFilter</span><span class="o">(</span><span class="nc">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="s">"city_address"</span><span class="o">));</span></span><span id="LC14" class="line"><span class="c1">// 筛选列值与深圳市相等的数据</span></span><span id="LC15" class="line"><span class="nc">ValueFilter</span><span class="n">valueFilter</span><span class="o">=</span><span class="k">new</span><span class="nc">ValueFilter</span><span class="o">(</span><span class="nc">CompareFilter</span><span class="o">.</span><span class="na">CompareOp</span><span class="o">.</span><span class="na">EQUAL</span><span class="o">,</span><span class="k">new</span><span class="nc">BinaryComparator</span><span class="o">(</span><span class="nc">Bytes</span><span class="o">.</span><span class="na">toBytes</span><span class="o">(</span><span class="s">"深圳市"</span><span class="o">)));</span></span><span id="LC16" class="line"><span class="c1">// 多过滤器，注意顺序</span></span><span id="LC17" class="line"><span class="n">filters</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">rowFilter</span><span class="o">);</span></span><span id="LC18" class="line"><span class="n">filters</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">columnPrefixFilter</span><span class="o">);</span></span><span id="LC19" class="line"><span class="n">filters</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">valueFilter</span><span class="o">);</span></span><span id="LC20" class="line"><span class="c1">// 需所有条件全部通过</span></span><span id="LC21" class="line"><span class="nc">FilterList</span><span class="n">andFilterList</span><span class="o">=</span><span class="k">new</span><span class="nc">FilterList</span><span class="o">(</span><span class="nc">FilterList</span><span class="o">.</span><span class="na">Operator</span><span class="o">.</span><span class="na">MUST_PASS_ALL</span><span class="o">,</span><span class="n">filters</span><span class="o">);</span></span><span id="LC22" class="line"><span class="c1">// 满足其中一个条件即可</span></span><span id="LC23" class="line"><span class="nc">FilterList</span><span class="n">orFilterList</span><span class="o">=</span><span class="k">new</span><span class="nc">FilterList</span><span class="o">(</span><span class="nc">FilterList</span><span class="o">.</span><span class="na">Operator</span><span class="o">.</span><span class="na">MUST_PASS_ONE</span><span class="o">,</span><span class="n">filters</span><span class="o">);</span></span><span id="LC24" class="line"><span class="k">return</span><span class="n">andFilterList</span><span class="o">;</span></span><span id="LC25" class="line"><span class="o">}</span></span><span id="LC26" class="line"><span class="o">})</span></span><span id="LC27" class="line"><span class="o">.</span><span class="na">build</span><span class="o">();</span></span><span id="LC28" class="line"><span class="nc">List</span><span class="o">&lt;</span><span class="nc">CityModel</span><span class="o">&gt;</span><span class="n">cityModels</span><span class="o">=</span><span class="n">tableTemplate</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="n">scanParams</span><span class="o">,</span><span class="nc">CityModel</span><span class="o">.</span><span class="na">class</span><span class="o">);</span></span><span id="LC29" class="line"><span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="n">cityModels</span><span class="o">.</span><span class="na">size</span><span class="o">());</span></span><span id="LC30" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ol start="6"><li>多版本查询</li></ol><p>使用 HBaseRowDataWithMultiVersions 结构来接收多版本数据</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">testGetMultiVersions</span><span class="o">()</span><span class="kd">throws</span><span class="nc">InterruptedException</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Object</span><span class="o">&gt;</span><span class="n">data1</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">3</span><span class="o">);</span></span><span id="LC4" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="s">"b1"</span><span class="o">,</span><span class="n">data1</span><span class="o">);</span></span><span id="LC5" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Object</span><span class="o">&gt;</span><span class="n">data2</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">3</span><span class="o">);</span></span><span id="LC6" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="s">"b1"</span><span class="o">,</span><span class="n">data2</span><span class="o">);</span></span><span id="LC7" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Object</span><span class="o">&gt;</span><span class="n">data3</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">3</span><span class="o">);</span></span><span id="LC8" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="s">"b1"</span><span class="o">,</span><span class="n">data3</span><span class="o">);</span></span><span id="LC9" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Object</span><span class="o">&gt;</span><span class="n">data4</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">3</span><span class="o">);</span></span><span id="LC10" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="s">"b1"</span><span class="o">,</span><span class="n">data4</span><span class="o">);</span></span><span id="LC11" class="line"><span class="nc">Map</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span><span class="nc">Object</span><span class="o">&gt;</span><span class="n">data5</span><span class="o">=</span><span class="k">new</span><span class="nc">HashMap</span><span class="o">&lt;&gt;(</span><span class="mi">3</span><span class="o">);</span></span><span id="LC12" class="line"><span class="n">tableTemplate</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="s">"b1"</span><span class="o">,</span><span class="n">data5</span><span class="o">);</span></span><span id="LC13" class="line"><span class="c1">// 省略数据构造过程</span></span><span id="LC14" class="line"><span class="nc">GetRowParam</span><span class="n">getRowParam</span><span class="o">=</span><span class="nc">GetRowParam</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="s">"b1"</span><span class="o">).</span><span class="na">versions</span><span class="o">(</span><span class="mi">5</span><span class="o">).</span><span class="na">build</span><span class="o">();</span></span><span id="LC15" class="line"><span class="nc">HBaseRowDataWithMultiVersions</span><span class="n">rowData</span><span class="o">=</span><span class="n">tableTemplate</span><span class="o">.</span><span class="na">getWithMultiVersions</span><span class="o">(</span><span class="no">TEST_TABLE</span><span class="o">,</span><span class="n">getRowParam</span><span class="o">);</span></span><span id="LC16" class="line"><span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span><span class="n">rowData</span><span class="o">.</span><span class="na">getColDataWithMultiVersions</span><span class="o">().</span><span class="na">size</span><span class="o">());</span></span><span id="LC17" class="line"><span class="nc">Assert</span><span class="o">.</span><span class="na">assertEquals</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span><span class="n">rowData</span><span class="o">.</span><span class="na">getColDataWithMultiVersions</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="s">"info:name"</span><span class="o">).</span><span class="na">size</span><span class="o">());</span></span><span id="LC18" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-hql" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#hql"></a>HQL</h3><p>使用前首先构造<code>BaseHBaseSqlTemplate</code></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nc">Configuration</span><span class="n">conf</span><span class="o">=</span><span class="nc">HBaseConfiguration</span><span class="o">.</span><span class="na">create</span><span class="o">();</span></span><span id="LC2" class="line"><span class="nc">BaseHBaseSqlTemplate</span><span class="n">sqlTemplate</span><span class="o">=</span><span class="nc">HBaseSqlTemplate</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>1. 创建表 schema</strong></p><p>使用<code>create virtual table</code>语句来创建表的 schema，如果 HBase 集群中没有表<code>HQL.META_DATA</code>，会先创建，然后把表解析出来的
表模型 HBaseTableSchema 对象，以 json 的格式存储在这张元数据表中，之后每次 select 或 insert 时，加载出表 schema 的元数据。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nd">@Test</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kt">void</span><span class="n">testCreateVirtualTable</span><span class="o">)</span><span class="o">{</span></span><span id="LC3" class="line"><span class="nc">String</span><span class="n">hql</span><span class="o">=</span><span class="s">"create virtual table test:test_sql (\n"</span><span class="o">+</span></span><span id="LC4" class="line"><span class="s">" row_key string isrowkey,\n"</span><span class="o">+</span></span><span id="LC5" class="line"><span class="s">" f1:id string nullable,\n"</span><span class="o">+</span></span><span id="LC6" class="line"><span class="s">" f1:name string nullable,\n"</span><span class="o">+</span></span><span id="LC7" class="line"><span class="s">" f1:age int nullable,\n"</span><span class="o">+</span></span><span id="LC8" class="line"><span class="s">" f1:job string nullable,\n"</span><span class="o">+</span></span><span id="LC9" class="line"><span class="s">" f1:pay double nullable,\n"</span><span class="o">+</span></span><span id="LC10" class="line"><span class="s">" f2:address string nullable,\n"</span><span class="o">+</span></span><span id="LC11" class="line"><span class="s">" f2:commuter string nullable\n"</span><span class="o">+</span></span><span id="LC12" class="line"><span class="s">" );"</span><span class="o">;</span></span><span id="LC13" class="line"><span class="n">sqlTemplate</span><span class="o">.</span><span class="na">createVirtualTable</span><span class="o">(</span><span class="n">hql1</span><span class="o">);</span><span class="err">`</span></span><span id="LC14" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>virtualTable 的名称要与 hbase 的实际表名一致，且只能存在一个。
也可以选择在执行 HQL 前调用 sqlTemplate.registerTableSchema 方法来手动注册某张表的 Schema，只有注册成功表的 Schema 之后，才能使用 hql。</p><p>打印 schema</p><p><img src="http://leo-jie-pic.oss-cn-beijing.aliyuncs.com/blog/ela83.png" alt="printSchema" referrerpolicy="no-referrer"></p><p><strong>2. 删除表的 schema</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nc">String</span><span class="n">hql</span><span class="o">=</span><span class="s">"drop virtual table test:test_sql;"</span><span class="o">;</span></span><span id="LC2" class="line"><span class="n">sqlTemplate</span><span class="o">.</span><span class="na">dropVirtualTable</span><span class="o">(</span><span class="n">hql2</span><span class="o">);</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>删除虚拟表的操作，不会对 HBase 的原表产生任何影响。</p><p><strong>3. Insert</strong></p><p>插入一条数据</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">insert</span><span class="k">into</span><span class="n">test</span><span class="p">:</span><span class="n">test_sql</span><span class="p">(</span><span class="n">row_key</span><span class="p">,</span><span class="n">f1</span><span class="p">:</span><span class="n">id</span><span class="p">,</span><span class="n">f1</span><span class="p">:</span><span class="n">name</span><span class="p">,</span><span class="n">f1</span><span class="p">:</span><span class="n">age</span><span class="p">)</span><span class="k">values</span><span class="p">(</span><span class="s1">'r1'</span><span class="p">,</span><span class="s1">'id1_v1'</span><span class="p">,</span><span class="s1">'leo1_v1'</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>插入多条数据</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">insert</span><span class="k">into</span><span class="n">test</span><span class="p">:</span><span class="n">test_sql</span><span class="p">(</span><span class="n">row_key</span><span class="p">,</span><span class="n">f1</span><span class="p">:</span><span class="n">id</span><span class="p">,</span><span class="n">f1</span><span class="p">:</span><span class="n">name</span><span class="p">,</span><span class="n">f1</span><span class="p">:</span><span class="n">age</span><span class="p">)</span></span><span id="LC2" class="line"><span class="k">values</span><span class="p">(</span><span class="s1">'r1'</span><span class="p">,</span><span class="s1">'id1_v1'</span><span class="p">,</span><span class="s1">'leo1_v1'</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span></span><span id="LC3" class="line"><span class="p">(</span><span class="s1">'r2'</span><span class="p">,</span><span class="s1">'id2_v1'</span><span class="p">,</span><span class="s1">'leo2_v1'</span><span class="p">,</span><span class="mi">21</span><span class="p">),</span></span><span id="LC4" class="line"><span class="p">(</span><span class="s1">'r3'</span><span class="p">,</span><span class="s1">'id3_v1'</span><span class="p">,</span><span class="s1">'leo3_v1'</span><span class="p">,</span><span class="mi">31</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>插入数据时，使用内置的 rowKey 自定义函数</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">insert</span><span class="k">into</span><span class="n">test</span><span class="p">:</span><span class="k">table</span><span class="p">(</span><span class="n">f</span><span class="p">:</span><span class="n">id</span><span class="p">,</span><span class="n">f</span><span class="p">:</span><span class="n">name</span><span class="p">,</span></span><span id="LC2" class="line"><span class="n">f</span><span class="p">:</span><span class="n">age</span><span class="p">,</span><span class="n">f2</span><span class="p">:</span><span class="n">pay</span><span class="p">,</span><span class="n">f3</span><span class="p">:</span><span class="n">detail</span><span class="p">)</span><span class="k">VALUES</span><span class="p">(</span><span class="n">md5</span><span class="p">(</span><span class="s1">'1001'</span><span class="p">),</span><span class="s1">'张三'</span><span class="p">,</span><span class="mi">23</span><span class="p">.</span><span class="mi">32</span><span class="p">,</span><span class="k">null</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><strong>4. Select</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">select</span><span class="o">*</span><span class="k">from</span><span class="n">test</span><span class="p">:</span><span class="n">test_sql</span><span class="k">where</span><span class="n">rowKey</span><span class="o">=</span><span class="s1">'a10001'</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><img src="http://leo-jie-pic.oss-cn-beijing.aliyuncs.com/blog/jz8pd.png" alt="select_by_row" referrerpolicy="no-referrer"></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">select</span><span class="o">*</span><span class="k">from</span><span class="n">test</span><span class="p">:</span><span class="n">test_sql</span><span class="k">where</span><span class="n">rowKey</span><span class="k">in</span><span class="p">(</span><span class="s1">'a10001'</span><span class="p">,</span><span class="s1">'a10002'</span><span class="p">,</span><span class="s1">'a10003'</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><img src="http://leo-jie-pic.oss-cn-beijing.aliyuncs.com/blog/7cnqd.png" alt="in_row_keys" referrerpolicy="no-referrer"></p><p><strong>4. Delete</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">delete</span><span class="o">*</span><span class="k">from</span><span class="n">test</span><span class="p">:</span><span class="n">test_sql</span><span class="k">where</span><span class="n">rowKey</span><span class="o">=</span><span class="s1">'b20004'</span><span class="p">;</span></span><span id="LC2" class="line"><span class="k">delete</span><span class="n">f1</span><span class="p">:</span><span class="n">age</span><span class="k">from</span><span class="n">test</span><span class="p">:</span><span class="n">test_sql</span><span class="k">where</span><span class="n">rowKey</span><span class="o">=</span><span class="s1">'b20004'</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><hr><h2><a id="user-content-️添砖加瓦" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%EF%B8%8F%E6%B7%BB%E7%A0%96%E5%8A%A0%E7%93%A6"></a>🏗️添砖加瓦</h2><h3><a id="user-content-分支说明" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E5%88%86%E6%94%AF%E8%AF%B4%E6%98%8E"></a>🎋分支说明</h3><p>HydraQL 的源码分为两个分支，功能如下：</p><table><thead><tr><th>分支</th><th>作用</th></tr></thead><tbody><tr><td>master</td><td>主分支，release 版本使用的分支，与中央库提交的 jar 一致，不接收任何 pr 或修改</td></tr><tr><td>dev</td><td>开发分支，默认为下个版本的 SNAPSHOT 版本，接受修改或 pr</td></tr></tbody></table><h3><a id="user-content-提供 bug 反馈或建议" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E6%8F%90%E4%BE%9Bbug%E5%8F%8D%E9%A6%88%E6%88%96%E5%BB%BA%E8%AE%AE"></a>🐞提供 bug 反馈或建议</h3><p>提交问题反馈时请说明正在使用的 JDK 版本、HydraQL 版本和相关依赖库的版本。</p><ul><li><a href="https://gitee.com/weixiaotome/hydra-ql/issues">Gitee issue</a></li><li><a href="https://gitee.com/weixiaotome/hydra-ql/issues">Github issue</a></li></ul><h3><a id="user-content-贡献代码的步骤" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81%E7%9A%84%E6%AD%A5%E9%AA%A4"></a>🧬贡献代码的步骤</h3><ol><li>在 Gitee 或者 Github 上 fork 项目到自己的 repo</li><li>把 fork 过去的项目也就是你的项目 clone 到你的本地</li><li>修改代码（记得一定要修改 dev 分支）</li><li>commit 后 push 到自己的库（dev 分支）</li><li>登录 Gitee 或 Github 在你首页可以看到一个 pull request 按钮，点击它，填写一些说明信息，然后提交即可。</li><li>等待维护者合并</li></ol><h3><a id="user-content-pr 遵照的原则" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#pr%E9%81%B5%E7%85%A7%E7%9A%84%E5%8E%9F%E5%88%99"></a>📐PR 遵照的原则</h3><hr><h2><a id="user-content-star-hydraql" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#star-hydraql"></a>⭐Star HydraQL</h2><h2><a id="user-content--知识星球" class="anchor" href="https://gitee.com/weixiaotome/hydra-ql#-%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83"></a>📌 知识星球</h2>]]>
            </description>
            <pubDate>Mon, 18 Sep 2023 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/weixiaotome/hydra-ql</guid>
            <link>https://gitee.com/weixiaotome/hydra-ql</link>
        </item>
        <item>
            <title>
                <![CDATA[走近「收费门」：互相矛盾的服务条款导致 Unity 面临被起诉的风险]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p><em>混淆不清、相互矛盾的服务条款为诉讼留下了隐患</em></p></blockquote><p>如果你在周一开发了一款 Unity 引擎游戏，你一般会认为除了订购 Unity 编辑器软件本身之外，你不会被收取额外的版税或其他费用。</p><p>如果你在周二开发了同一款游戏，你就会突然受到令人震惊的新条款的限制，在达到一定的单个游戏收入和安装阈值后，每次安装将收取高达 0.20 美元的费用（从明年开始）。</p><p>这一变化在游戏开发社区引发了可以理解的愤怒和指责。但也有人不禁要问，如此巨大的变化在法律上是如何实现的？Unity 是否可以单方面改变其开发者所依赖的收费结构，即使是在完全不同的法律条款下启动（甚至完成）的开发项目？</p><p>答案似乎取决于你如何理解近年来出现在各种 Unity 服务条款中的一些看似矛盾的条款。</p><h3><strong>Unity：我们想做什么就做什么</strong></h3><p>Unity 明确表示，新的收费结构不适用于在 1 月 1 日新公布的收费结构生效之前安装的任何游戏。但在常见问题解答中，<strong>该公司表示，2024 年之前发布的游戏在新规则生效后的后续安装都需要付费。</strong></p><p>"常见问题解答中写道："假设游戏符合条件并发布了 Unity 运行时，那么将收取 Runtime 费用。"我们会查看游戏的终生安装次数，以确定是否符合收取运行时费用的条件。然后，我们会根据 2024 年 1 月 1 日之后的所有新安装情况收取运行时费用。"</p><p>这可能会让在 2015 年发布 Unity 游戏的开发者感到惊讶，当时 Unity 首席执行官约翰-里奇蒂耶洛（John Riccitiello）还在公开吹捧 Unity 的 "无版税、不乱搞 "订阅计划。现在，即使是当年为 Unity 的 "永久授权 "支付了 1500 美元的开发者，理论上也可能从明年开始需要支付额外的按安装次数收费的费用（前提是他们的游戏仍有足够的收入和安装次数）。</p><p>Unity 尚未回应 Ars Technica 的置评请求，但该公司发言人在 "寻找律师 "之后，在论坛上概述了该公司的法律论据：</p><blockquote><p>我们的服务条款规定，Unity 可随时增加或更改费用。在 Unity Runtime 费用生效前，我们会提前三个多月通知您。额外费用的生效无需征得同意，而且<strong>我们条款的唯一版本是最新版本</strong>；您不能选择遵守之前的版本。此外，我们的条款受加利福尼亚州法律管辖，与客户所在国无关。</p></blockquote><h3><strong>与我一起阅读旧的法律文件</strong></h3><p>从广义上讲，所有 Unity 开发者签署的一般法律协议都支持这一立场。至少早在 2013 年，Unity EULA 就包含了一个宽泛的条款，规定公司 "可以随时修改或终止订阅期限或其他软件许可产品"。</p><p>但是，这种 "我们想怎么改就怎么改 "的直白语言在 2019 年初变得有些复杂。当时，Unity 陷入了另一场服务条款（ToS）变更的争议中，这次涉及的新条款似乎禁止了流行的基于云的多人游戏开发工具包 SpatialOS。</p><p>虽然 Unity 最终与 SpatialOS 制造商 Improbable 解决了问题，但开发社区担心未来的 ToS 变更会影响他们的项目是有道理的。为了平息事态，Unity 宣布了一项新的 "开放平台承诺"，其中包括一项重要的保护措施，防止进一步突然更改 ToS。该公司在<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.unity.com%2Fcommunity%2Fupdated-terms-of-service-and-commitment-to-being-an-open-platform" target="_blank">公告博文</a>中写道"当你获得了一个版本的 Unity，但没有升级你的项目时，我们认为你应该能够坚持使用那个版本的 ToS"。</p><p>在 Unity 为跟踪此类 ToS 变动而设立的 GitHub&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweb.archive.org%2Fweb%2F20201111183311%2Fhttps%3A%2F%2Fgithub.com%2FUnity-Technologies%2FTermsOfService%2Fblob%2Fmaster%2FUnity%2520Software%2520Additional%2520Terms.md" target="_blank">页面</a>上，该承诺被翻译成了法律术语：</p><blockquote><p>Unity 可以随时以任何理由更新这些 Unity 软件附加条款，恕不另行通知（以下简称 "更新条款"），更新条款将适用于 Unity 软件的最新当年版本，但<strong>如果更新条款对您的权利产生不利影响，您可以选择按照更新条款之前适用的条款（以下简称 "之前条款"）继续使用 Unity 软件的任何当年版本（例如 2018.x 和 2018.y 以及该当年版本的任何长期支持 (LTS) 版本）。</strong></p></blockquote><p>从表面上看，该条款似乎表明，在 Unity 新条款生效之前发布的游戏可以坚持使用游戏发布时存在的旧版免安装费 ToS。唯一可能出现的问题是，如果您想将项目更新到 Unity 的后续版本；在这种情况下，正如 ToS 所述，"您对软件任何新版本或发行版的使用将受适用于该发行版或版本的更新条款的约束"。</p><p>更重要的是，2019 版的软件使用条款明确规定了 "非独占、不可转让、免版税 "的权利，即在某些宽泛的条件下，"将 Unity Runtime 作为项目的集成部分进行发布"。这似乎不允许该公司很快计划对 Unity 游戏安装收取 "Unity Runtime 费用"--至少对于决定坚持使用旧版 ToS 的未更新旧项目来说是如此。</p><p>通过 2022 年 10 月 23 日的更新，「保留旧 ToS」和「免版税运行时间」条款继续出现在 Unity 的「编辑器软件服务条款」中，这表明在 Unity 2022.x 和 Unity 2021.x LTS（或更早版本）上制作的未更新项目可能能够保留构建它们的免费法律结构。但随后，几乎没有通知，2023 年 4 月的编辑器软件 ToS 更新完全删除了该安全阀。</p><p>4 月版本顶部的注释提到，新版本包括对「条款修改」部分的更新。实际上，该「更新」意味着 2019 年引入的「保留旧 ToS」条款只是被批量删除，而不是替换。此外，更新了「免版税运行时分发」条款，表明此类分发「需要支付适用的费用」，为本周的安装费公告悄悄奠定了法律基础。</p><p>Unity 似乎也在不遗余力地消除至少一些现存的迹象，表明其以前的「软件服务条款」有任何不同。承诺的 GitHub 页面跟踪 ToS 更改不再有效，尽管 GitHub 的相同分支仍然捕获旧语言（互联网档案馆快照表明 GitHub 删除发生在 2022 年 7 月之后的某个时间）。截至撰写本文时，Unity 网站上仍有一份较旧的「软件附加条款」文档，其中包含「保持旧 ToS」条款不变，日期为 2022 年 3 月。</p><h3><strong>第二个服务条款？</strong></h3><p>对于开发人员来说，4 月份的更新是个坏消息，他们从那时起在不知不觉中使用了最新版本的 Unity 编辑器，似乎在此过程中受制于新规则。但是在旧版本的编辑器（和服务条款）下创建的项目可能仍然受到旧的「保留您的 ToS」条款的保护，对吗？</p><p>不幸的是，事情并没有那么简单。这是因为 Unity 编辑器软件 ToS（在 Reddit 和其他地方引起了很多关注）是对更广泛的 Unity 服务条款文档的补充，该文档适用于 Unity 产品和服务的所有用户。</p><p>这些取代条款对于 Unity 「随时修改协议且无需事先通知」的权利要宽松得多。这里也没有「保留旧的 ToS」条款的迹象：</p><blockquote><p>在我们向您提供修改通知后继续访问或使用服务，即表示您同意受修改后的条款的约束。<strong>如果您不接受修改后的条款，您唯一的办法是停止使用服务。</strong></p></blockquote><p>换句话说，如果您不想受新规则的约束，这些总体 Unity 条款表明您唯一的出路是完全停止使用 Unity 的服务（这似乎包括分发安装和玩游戏所需的 Unity Runtime）。此外，这些总体条款明确允许 Unity 「通过在网站或服务面板中发布此类更改，不时增加、修改或添加新的费用和收费」，并至少提前 30 天通知。</p><p>「您在任何此类更改生效日期后继续使用此类软件和/或开发人员服务意味着您接受并同意此类更改（如适用）」，更新的 ToS 写道。</p><p>我能够找到这个通用 Unity ToS 的最旧版本，存档日期到 2022 年 1 月，因此尚不完全清楚这种取代语言的有效期。但 2013 年 EULA 中的类似语言表明，这并不是对 Unity 的全新法律保护。</p><p>有趣的是，一月份版本的总体 ToS 还包括一个句子，特别指出了允许您忽略软件 ToS 更改的不同条款。目前的通用 ToS 删除了这句话，并明确表示**「为免生疑问」，其修改规则也适用于「附加条款」（即软件 ToS）**。</p><h3><strong>我们会在法庭上见到你吗？</strong></h3><p>那么，所有这些不断变化且看似矛盾的 ToS 条款在实践中对于工作的 Unity 开发人员意味着什么？答案并不完全清楚。</p><p>「当然，在今天的合同中，[Unity]似乎被覆盖了」，游戏行业律师理查德·霍格（Richard Hoeg）在 YouTube 直播中分析了这里的法律问题。「但是存在时间和旧版本的问题，特别是对于不久前已经制作并最终确定的游戏，远在做出此更改之前。</p><p>Hoeg 说，Unity 可能会遇到一些法律风险的地方是整体 ToS（Unity 表示只要您使用其服务，您就会受到其约束）和软件 ToS（直到最近还表示，如果您不更新游戏，您可以继续使用旧版本）之间的明显冲突。「这是一种模棱两可的感觉...当我们在合法土地上写合同时，我们首先要避免，「Hoeg 说。</p><p><strong>通常，这种歧义通常会通过更通用的 ToS 覆盖「附加」编辑器软件条款来解决</strong>，这些条款在法律术语中被视为辅助条款。与此同时，Hoeg 表示，开发人员可以争辩说，他们已经合理地依赖了软件条款中的辅助语言，包括可以想象允许他们保留这些条款的条款，即使在将来发生变化的情况下也是如此。</p><p>Hoeg 说：「有人本可以看着它说，'是的，我将投入我的时间和精力'，通过在不公开的情况下改变这一点，然后在 2023 年 9 月改变这里的费用结构，你可能会提出索赔。</p><p>想要在法庭上提出这种索赔的开发商可以使用允诺禁止反言的概念进行辩论，或者像 Hoeg 所说的那样「如果其他人依赖它，你就不能改变交易的概念」。「你向一方承诺，你将给他们 Unity 工具，他们不必付钱，他们花了四年的时间进行投资，教育，学习 Unity 工具集并准备构建游戏，然后你最后改变了定价，「霍格用假设论证的方式说道。</p><p>虽然霍格说他个人可能接受这种类型的论点，但<strong>在实际法庭上提出这可能是一个艰难的技术主张</strong>。正如霍格所说，在这种论点中，你基本上「把自己投入到正义的概念上，并希望事情对你来说一切都好」。</p><p>不过，这可能是一些 Unity 开发人员准备提出的法律论点。独立开发者 Xalavier Nelson， Jr.告诉 Axios，「该领域一些使用该引擎的最重要的开发者」正在考虑对这些变化提起集体诉讼，此前周二的社交媒体<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FWritNelson%2Fstatus%2F1701720278189937099" target="_blank">帖子</a>也暗示了这一点。</p><p>「我看不出这是合法的」，Cult of the Lamb 开发商 Massive Monster&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gamesradar.com%2Fgame-devs-say-unitys-new-install-fee-is-a-threat-to-everyone-including-gamers-and-theres-no-going-back-i-dont-want-to-sell-my-house-because-my-game-was-too-popular%2F" target="_blank">告诉</a>&nbsp;PC Gamer。「他们绝对有诉讼要打」。</p><p>然而，最终，<strong>这种潜在的法律纠纷只有在商业伙伴关系的通常惯例完全崩溃时才是必要的</strong>。「很多时候，这些合同将以这样一种方式编写，即公司拥有广泛的权力来做他们将要做的事情，而你最终将处于信任的位置」，Hoeg 说。「作为律师，我们不从事'相信我'的业务。你，作为一个商人，<strong>作为客户，必须确定你是否与你的商业伙伴有足够的信任或亲密关系，相信他们会持有相对相同的东西</strong>......」</p><p>原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farstechnica.com%2Fgaming%2F2023%2F09%2Fwait-is-unity-allowed-to-just-change-its-fee-structure-like-that%2F" target="_blank">https://arstechnica.com/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 17 Sep 2023 15:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258477/wait-is-unity-allowed-to-just-change-its-fee-structure-like-that</guid>
            <link>https://www.oschina.net/news/258477/wait-is-unity-allowed-to-just-change-its-fee-structure-like-that</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
