<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 13 Mar 2024 12:23:05 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[官宣正式成为 PostgreSQL Contributor，Richard 有何秘诀？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">作为世界上最受欢迎的开源数据库之一，PostgreSQL&nbsp;国际社区于 3 月 3 日正式公布了新加入的 PostgreSQL&nbsp;Contributor&nbsp;名单，以认可为&nbsp;PostgreSQL&nbsp;开源项目做出实质性、长期贡献的人员。本次公布的名单中包括&nbsp;3&nbsp;名&nbsp;Contributor&nbsp;和&nbsp;6&nbsp;名&nbsp;Major&nbsp;Contributor。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">拓数派技术专家 Richard&nbsp;Guo&nbsp;本次荣获 PostgreSQL 官方认可，正式成为一名&nbsp;PostgreSQL&nbsp;Contributor。据统计，Richard&nbsp;是目前&nbsp;PostgreSQL&nbsp;Contributor&nbsp;名单中唯二的中国人。</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/up-25ee98ae6a7e0a55a085185dd10524643f4.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">众所周知，PostgreSQL 全球的 Committer 人数长期维持在较少的人数（约 30 人），Contributor&nbsp;名单中也罕见中国人身影。本次，Richard&nbsp;被官方认可为正式的&nbsp;Contributor，这一荣誉既归功于他所在的拓数派公司开放创新企业文化和强大的技术能力，也得益于&nbsp;Richard&nbsp;对开源技术的喜爱与坚持不懈的努力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">接下来，拓数派的吉祥物 「派派」 将对话&nbsp;Richard，为大家揭开成为 PostgreSQL&nbsp;Contributor 的秘诀。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>派派：</strong><span>&nbsp;</span><strong>您是如何开始参与开源代码贡献的？有什么特别的经历或项目激发了您对开源贡献的兴趣？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Richard：</strong><span>&nbsp;</span>我参与的第一个开源项目是早在 2012 年，当时由于工作原因，我参与了 Linux&nbsp;Kernel 的开发工作，开始对开源代码贡献产生了兴趣。2016 年，由于机缘巧合，我加入了&nbsp;Pivotal&nbsp;的开源数据库产品 Greenplum&nbsp;团队，进行 Greenplum 开源产品的开发工作。由于 Greenplum 是基于 PostgreSQL 内核研发的，于是当时也开始了对 PostgreSQL 开源社区的关注，并开始了对 PostgreSQL 的贡献。如今，加入拓数派之后，由于工作需求，也很幸运公司具有拥抱开源的文化，我也在继续参与 PostgreSQL 社区的开源工作。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>派派：</strong><span>&nbsp;</span><strong>您认为自己主要在哪些方面对 PostgreSQL 做出了贡献或改进？这些改进对于整个 PostgreSQL 社区有何影响？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Richard：</strong><span>&nbsp;</span>在 PostgreSQL 的代码贡献中，我主要专注于&nbsp;PostgreSQL&nbsp;优化器和执行器模块，这也为我后续打造拓数派产品&nbsp;PieCloudDB&nbsp;的优化器奠定了基础。在&nbsp;PostgreSQL&nbsp;社区，我对代码优化和性能调优花费了不少时间进行研究，参与了一些&nbsp;Bug&nbsp;Fix&nbsp;和&nbsp;Patch&nbsp;&nbsp;Review 工作，为用户提供更好的体验。我还努力推动新功能的实现，提交过一些新&nbsp;Feature。曾经提交的新&nbsp;Feature&nbsp;包括 "Support&nbsp;Right&nbsp;Anti&nbsp;Join"、"Support&nbsp;Memoize&nbsp;for&nbsp;UNION&nbsp;ALL&nbsp;Queries" 等。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>派派：</strong><span>&nbsp;</span><strong>您平时通过什么来提高的自己技术能力？有哪些技术或领域是您特别关注和学习的？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Richard：</strong><span>&nbsp;</span>我一直坚信 「实践出真知」，通过多阅读优秀的代码，多思考其中的逻辑和原理，然后在工作中提高对自己代码的质量要求是我认为最快打磨技术能力的一种方式。此外，所谓 「三人行，必有我师」，通过多和资深的人交流、讨论，往往能学习到很多意想不到的知识。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">除了数据库的优化器和执行模块相关的领域，我对&nbsp;AI&nbsp;也非常感兴趣，包括数据库与 AI 的结合，以及 Chatgpt，Sora 等前沿生成式&nbsp;AI&nbsp;应用，我都非常关注。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>派派：</strong><span>&nbsp;</span><strong>对于那些希望成为开源代码贡献者的人来说，您有什么建议或指导？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Richard：</strong><span>&nbsp;</span>在参与开源代码贡献前，对源码的熟悉和了解是前提条件。此外，我意识到专注是非常重要的，因此我付出了许多努力来保持专注。举例来说，我尽量减少手机使用时间，关闭聊天工具等，目前我已成功将每天使用手机的时间控制在&nbsp;1&nbsp;小时以内。同时，也建议大家注重思考和讨论，以不断迭代自己的思维和逻辑，我相信这也是非常重要的。通过积极思考和与他人交流，才能不断提升自己。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 09:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282927</guid>
            <link>https://www.oschina.net/news/282927</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[信通院发布报告，研究中国综合算力]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">《中国综合算力评价白皮书（2023 年）》由中国信息通信研究院发布，主要内容包括：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>背景介绍</strong>：随着科技革命和产业变革的加速，算力成为数字化转型的新动能。中国在算力、存力、运力方面的基础设施投入不断加大，形成了支撑数字经济发展的重要力量。</p></li><li><p style="margin-left:0; margin-right:0"><strong>算力发展现状</strong>：截至 2022 年底，中国算力核心产业规模达到 1.8 万亿元，算力总规模达到 180EFLOPS，年增长率近 30%。存力总规模超过 1000EB，网络单向时延降低到 20 毫秒以内。</p></li><li><p style="margin-left:0; margin-right:0"><strong>综合算力评价体系</strong>：白皮书构建了一个涵盖算力、存力、运力、环境等关键因素的综合算力评价指标体系，对我国综合算力的发展情况进行了多维度的客观分析，并给出了发展建议。</p></li><li><p style="margin-left:0; margin-right:0"><strong>评价结果</strong>：综合算力评价结果显示，广东省、江苏省、上海市等东部省份在算力、存力、运力方面整体处于较高水平，而内蒙古自治区、贵州省等西部省份在存力、环境等方面也展现出优势。</p></li><li><p style="margin-left:0; margin-right:0"><strong>发展建议</strong>：白皮书提出了系统布局新型基础设施、加速推动核心技术创新、加快政策标准体系建设、持续构建全产业链生态、激发算力产业创新动力等建议，以推动综合算力的技术创新与基础设施建设。</p></li><li><p style="margin-left:0; margin-right:0"><strong>数据来源和计算方法</strong>：报告的数据来源于工信部、中国信通院等官方机构和公开资料，采用极差标准化法进行指标标准化，并利用层次分析法（AHP）确定指标权重，最后形成各区域的评价结果。</p></li><li><p style="margin-left:0; margin-right:0"><strong>联系方式</strong>：文件最后提供了中国信息通信研究院的地址、邮编、电话、传真和网址信息。</p></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">整体而言，这份白皮书全面阐述了中国综合算力的发展现状、评价体系、评价结果，并对未来的发展提出了建议，旨在为我国综合算力的技术创新与基础设施建设提供参考。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:56:18 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282905</guid>
            <link>https://www.oschina.net/news/282905</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美国政府软件要求提供安全软件开发认证表]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">作为改善网络安全持续努力的一部分，拜登-哈里斯政府宣布已批准了一份</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cisa.gov%2Fresources-tools%2Fresources%2Fsecure-software-development-attestation-form" target="_blank">安全软件开发认证表</a>。</p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">该表格由 CISA 和管理和预算办公室 (OMB) 于 2024 年 3 月 11 联合发布，任何提供政府将使用的软件的公司都需要填写该表格。它将有助于确保该软件是由优先考虑安全性的公司开发的。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><img height="250" src="https://oscimg.oschina.net/oscnet/up-5f101db1d80c4331864091d96dc415eac6e.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Endor Labs 首席安全顾问兼 CISA 网络创新研究员 Chris Hughes 表示：「表格中的要求代表了一些基本的安全开发实践，希望向联邦政府出售软件的供应商如果想参与联邦监管的生态系统，就应该能够满足这些要求。」&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">表格中的要求之一是软件必须在安全的环境中开发。这包括分离生产和开发环境，最大限度地减少代码中不安全产品的使用，跨环境强制执行多因素身份验证，加密敏感数据，实施持续监控和警报等防御实践，以及定期记录、监控和审核信任关系。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「分离开发和生产环境、实施日志记录和 MFA 等做法是任何现代安全软件开发环境中都应该存在的关键安全控制措施。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">另一个要求是通过使用自动化工具监控第三方代码并维护内部代码和第三方组件的来源，真诚地努力维护可信的供应链。它还需要定期使用自动化工具来检查安全漏洞，包括制定披露和解决已知漏洞的策略。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">然而 Hughes 认为，这种形式缺少一些元素。例如，它不需要使用威胁建模或内存安全，而这正是 CISA 一直在推动的事情。他表示，它还允许首席执行官指定其他人在证明上签字，以便在出现问题或证明造假时作为潜在的替罪羊。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「一方面，我们听说网络安全需要成为董事会的议题，CISA 甚至呼吁高管层参与其有关安全设计/默认的出版物；但另一方面，这种形式允许将这一关键认证活动委托给某人组织中的其他人，并可能使其无法被最高管理层/首席执行官和执行领导团队看到。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Hughes 认为，最难满足认证要求的软件生产商是那些尚未实施安全软件开发实践的软件生产商。&nbsp;</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「他们需要评估当前的开发实践，找出缺陷并实施纠正计划。这当然需要时间和资源，而规模较小的初创公司和不成熟的组织获得这些时间和资源的机会有限，尤其是面对对上市速度、收入、投资者回报、功能速度等方面的竞争需求。」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">CISA 的在线表单提交存储库 (</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsoftwaresecurity.cisa.gov%2F" target="_blank">https://softwaresecurity.cisa.gov</a><span style="color:#000000">) 预计将于 2024 年 3 月下旬提供。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282896/secure-software-development-attestation-form</guid>
            <link>https://www.oschina.net/news/282896/secure-software-development-attestation-form</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[全球首位 AI 软件工程师 Devin：能自学新语言、开发迭代 App、自动 Debug]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>初创公司 Cognition 近日<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fcognition_labs%2Fstatus%2F1767548763134964000" target="_blank">发布公告</a></u>，宣布推出全球首个 AI 软件工程师 Devin，并号称会彻底改变人类构建软件的方式。</p><p><img height="1758" src="https://oscimg.oschina.net/oscnet/up-63fe0533116cdf85964e331427c9d8b851b.png" width="1282" referrerpolicy="no-referrer"></p><p>官方对其的描述如下：Devin 是一位不知疲倦、技术娴熟的队友，随时准备与您并肩作战，或独立完成任务供您审查。有了 Devin，工程师可以专注于更有趣的问题，工程团队可以努力实现更远大的目标。</p><p>Devin 所具备的技能如下：</p><ul><li>快速掌握新技术：只需阅读文档，Devin 就能快速掌握不熟悉的工具和框架；</li><li>开发端到端应用：构建并部署功能齐全的网络应用程序，根据用户反馈逐步增加功能；</li><li>自动化查找 BUG：Devin 擅长识别、调试和修复代码问题，同时为开源和生产级软件仓库作出贡献；</li><li>AI 培训：从研究资料库中获取指令，建立并微调大型语言模型。</li></ul><p>Devin 在 SWE-bench 编码基准测试中取得了突破性的成功，展示了其执行复杂任务的能力，甚至超越了顶尖的人类工程师。</p><p>Devin 擅长长期推理能力，可以自主规划和完成软件项目，并在此过程中做出数以千计的准确决策。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 07:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282895/cognition-labs-devin</guid>
            <link>https://www.oschina.net/news/282895/cognition-labs-devin</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果放宽欧盟 App Store 软件分发规则]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">苹果公司<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fnews%2F%3Fid%3D8c1m8hqt" target="_blank">宣布</a>计划放宽欧盟 App Store 的部分软件分发规则。「我们为在欧盟 (EU) 分发应用程序的开发者提供了更大的灵活性，包括引入一种直接从开发者网站分发应用程序的新方法。」</span></p><p><img height="189" src="https://oscimg.oschina.net/oscnet/up-aeff8c07ddcf1ab5d5c5b257662843ab247.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">据悉，此举将使该公司更容易遵守欧盟立法者于 2022 年通过的《数字服务法》和《数字市场法》这两部反垄断法，分别于上个月和上周生效。</span></p><p><span style="color:#000000">公告指出，已同意欧盟应用程序替代条款附录的开发者可以为其在欧盟的应用程序提供新选项：</span></p><ul><li><span style="color:#000000">备选应用市场（Alternative app marketplaces）。市场可以选择仅提供来自市场开发商的应用程序目录。</span></li><li><span style="color:#000000">Linking out to purchase。修订后的应用商店规则允许欧盟的开发者自定义指向外部网站的应用内链接。软件团队现在可以「选择如何设计促销、折扣和其他交易」。此前，应用程序仅限于使用 Apple 提供的一组界面模板，更新后这些模板将继续作为可选的开发人员资源提供。</span></li></ul><p><span style="color:#000000">预计今年春季晚些时候还将会推出 Web Distribution 功能，授权开发者可以直接通过开发者拥有的网站向欧盟用户分发 iOS 应用程序。Apple 将为授权开发者提供 API 访问权限，以方便他们通过网络发布应用程序、集成系统功能、备份和恢复用户的应用程序等。</span></p><p><span style="color:#000000">更多相关详情可查看&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fsupport%2Fweb-distribution-eu%2F" target="_blank">Getting ready for Web Distribution in&nbsp;the&nbsp;EU</a><span style="color:#1d1d1f">。</span></p><p><strong><span style="color:#1d1d1f">相关阅读：</span></strong></p><ul><li style="margin-left: 0px; margin-right: 0px; text-align: start;"><a href="https://www.oschina.net/news/276674" target="_blank">苹果在欧盟地区放开对浏览器和应用商店的限制</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 06:04:30 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282888/apple-app-store-software-distribution-rules-eu</guid>
            <link>https://www.oschina.net/news/282888/apple-app-store-software-distribution-rules-eu</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Tremor —— 模块化组件 React 库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p>Tremor 是一个快速构建仪表板的 React 库，完全开源，由数据科学家和软件工程师打造。</p></div><p><img height="1000" src="https://static.oschina.net/uploads/space/2023/0609/161343_Wiyn_4937141.png" width="3000" referrerpolicy="no-referrer"></p><h2>入门</h2><p>对于新项目，官方建议使用 Next.js 13.4+，要使用该库，还需要在项目中设置 Tailwind CSS。</p><h2>使用 NextJS</h2><p>在终端中，我们会创建一个新的 Next 项目，当提示 <code>Would you like to use Tailwind CSS with this project?</code>时，选择 <code>Yes</code>.</p><div><pre>npx create-next-app@latest my-project
cd my-project</pre></div><h3>使用 Tremor CLI 安装</h3><p>建议使用我们的 CLI 安装 Tremor。 为此，请运行此命令并选择 Next 作为你的框架。</p><div><pre>npx @tremor/cli@latest init</pre></div><p>现在你已经设置好了，就可以启动开发服务器了。</p><div><pre>npm run dev</pre></div><p>&nbsp;</p></div>
                                                                ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 03:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/tremor</guid>
            <link>https://www.oschina.net/p/tremor</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 自动化测试基础框架，有趣（YouQu）]]>
            </title>
            <description>
                <![CDATA[<p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Flinuxdeepin.github.io%2Fdeepin-autotest-framework%2F"><img src="https://gitee.com/deepin-community/deepin-autotest-framework/raw/master/docs/logo.png" width="520" alt="YouQu" referrerpolicy="no-referrer"></a></p><p align="center"><em>有趣，一个使用简单且功能强大的自动化测试基础框架。</em></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework%2Fissues"><img src="https://img.shields.io/github/issues/linuxdeepin/deepin-autotest-framework?color=%23F79431" alt="GitHub issues" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework%2Fpulls"><img src="https://img.shields.io/github/issues-pr/linuxdeepin/deepin-autotest-framework?color=%23F79431" alt="GitHub pull requests" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework%2Fdiscussions"><img src="https://img.shields.io/github/discussions/linuxdeepin/deepin-autotest-framework?color=%23F79431" alt="GitHub Discussions" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fpypi.org%2Fproject%2Fyouqu%2F"><img src="https://img.shields.io/pypi/v/youqu?style=flat&amp;logo=github&amp;link=https%3A%2F%2Fpypi.org%2Fproject%2Fyouqu%2F&amp;color=%23F79431" alt="PyPI" referrerpolicy="no-referrer"></a><img src="https://img.shields.io/pypi/l/youqu?color=%23F79431" alt="PyPI - License" referrerpolicy="no-referrer"><img src="https://img.shields.io/pypi/pyversions/youqu?color=%23F79431" alt="PyPI - Python Version" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/UOS%2FDeepin/Ubuntu/Debian-Platform?style=flat&amp;label=OS&amp;color=%23F79431" alt="Static Badge" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Linux-Platform?style=flat&amp;label=Platform&amp;color=%23F79431" alt="Static Badge" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?style=flat&amp;logo=MaterialForMkDocs&amp;logoColor=white&amp;color=%23F79431" alt="Built with Material for MkDocs" referrerpolicy="no-referrer"></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fpepy.tech%2Fproject%2Fyouqu"><img src="https://static.pepy.tech/badge/youqu/week" alt="Downloads" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fpepy.tech%2Fproject%2Fyouqu"><img src="https://static.pepy.tech/badge/youqu/month" alt="Downloads" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fpepy.tech%2Fproject%2Fyouqu"><img src="https://static.pepy.tech/badge/youqu" alt="Downloads" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework"><img src="https://hits.sh/github.com/linuxdeepin/deepin-autotest-framework.svg?style=flat&amp;label=Github_Hits&amp;color=blue" alt="Hits" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Flinuxdeepin.github.io%2Fdeepin-autotest-framework"><img src="https://hits.sh/linuxdeepin.github.io/deepin-autotest-framework.svg?style=flat&amp;label=YouQu_Hits&amp;color=blue" alt="Hits" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=http%3A%2F%2Fyouqu.uniontech.com%2F"><img src="https://hits.sh/youqu.uniontech.com.svg?style=flat&amp;label=YouQu%E5%86%85%E7%BD%91_Hits&amp;color=blue" alt="Hits" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fpypi.org%2Fproject%2Fyouqu%2F"><img src="https://hits.sh/pypi.org/project/youqu.svg?style=flat&amp;label=PyPI_Hits&amp;color=blue" alt="Hits" referrerpolicy="no-referrer"></a></p><hr><p><strong>文档</strong>: <a href="https://gitee.com/link?target=https%3A%2F%2Flinuxdeepin.github.io%2Fdeepin-autotest-framework" target="_blank"></a><a href="https://gitee.com/link?target=https%3A%2F%2Flinuxdeepin.github.io%2Fdeepin-autotest-framework">https://linuxdeepin.github.io/deepin-autotest-framework</a></p><p><strong>源码</strong>: <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework" target="_blank"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework">https://github.com/linuxdeepin/deepin-autotest-framework</a></p><hr><p>有趣（YouQu）是深度科技开源的一个用于 <code>Deepin/UOS</code> 操作系统（Linux）的自动化测试框架，采用结构分层的设计理念，支持多元化元素定位和断言、用例标签化管理和执行、强大的日志和报告输出等特色功能，同时完美兼容 X11、Wayland 显示协议，环境部署简单，操作易上手。</p><h3><a id="user-content-爱上-有趣-的-18-个理由" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#%E7%88%B1%E4%B8%8A-%E6%9C%89%E8%B6%A3-%E7%9A%84-18-%E4%B8%AA%E7%90%86%E7%94%B1"></a>爱上 「有趣」 的 18 个理由</h3><ol><li>核心库提供了统一的接口，编写方法时只需要导入一个包就可以使用到核心库提供的所有功能；</li><li>公共库封装了很多常用模块的相关方法，比如：任务栏的操作、桌面的操作、右键菜单的操作等等；</li><li>除了常用的属性定位、图像识别以外，我们还提供基于 <code>UI</code> 的元素定位方案，其使用简单且高效，效果一定能惊讶到你；</li><li>对属性定位的方法进行了二次封装，将编写属性定位的方法变得简单而优雅；</li><li>对图像识别定位技术进行功能升级，除了支持单个座标返回，还支持同一界面下多个相同元素返回多个座标的功能；</li><li>提供用例标签化管理、批量跳过和批量条件跳过的功能，你想不到一个 <code>csv</code> 文件原来能干这么多事情；</li><li>提供了功能强大的执行器入口，让你可以方便的在本地执行任何用例集的用例，其丰富的自定义配置项，满足你对执行器所有的幻想；</li><li>提供远程执行的功能，可以控制多台机器并行跑，或者分布式跑，这种付费功能现在免费给你用；</li><li>提供自动输出日志的功能，你再也不用为每个方法单独写输出日志的代码，一切我们给你搞定了，日志输出不仅内容丰富，颜值也绝对在线，我们还自己设计了一款终端输出主题叫《五彩斑斓的黑》；</li><li>提供一键部署自动化测试环境的功能，让你再也不用为环境部署而烦恼；</li><li>提供自动生成多种报告的功能，你想输出什么报告形式都行，而且我们在报告中还加入了失败录屏和失败截图的功能；</li><li>对断言进行了二次封装，提供更友好化的错误提示，让定位问题精准高效；</li><li>不仅支持单条用例超时控制，而且还支持动态控制用例批量执行的总时间，确保 <code>CI</code> 环境下能顺畅运行；</li><li>支持本地文件测试套执行、<code>PMS</code> 测试套执行、标签化执行方案，满足你各种场景下的执行需求；</li><li>支持基于深度学习的 <code>OCR</code> 功能，可定位可断言，中文识别的天花板；</li><li>完美兼容 <code>Wayland</code>  和 <code>X11</code>，真正做到一套代码，随处执行；</li><li>支持多种方式的数据回填功能，其中异步回填的方案，完美解决了数据回填的耗时问题；</li><li>支持重启交互场景用例的执行，使用方法优雅简洁；</li></ol><hr><p>统信公司内网还可以访问【<a href="https://gitee.com/link?target=http%3A%2F%2Fyouqu.uniontech.com%2F">内网文档</a>】，文档内容一样，访问速度更快哦~~</p><h2><a id="user-content-安装使用" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8"></a>安装使用</h2><p>从 PyPI 安装:</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span><span class="nb">sudo </span>pip3 <span class="nb">install </span>youqu</span><span id="LC2" class="line"><span class="gp">---&gt;</span><span class="w"></span>100%</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>创建项目:</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu-startproject my_project</span><span id="LC2" class="line"><span class="gp">---&gt;</span><span class="w"></span>100%</span><span id="LC3" class="line"><span class="go">The project: [my_project],has been created by youqu-x.x.x</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>如果 <code>youqu-startproject</code> 后面不加参数，默认的项目名称为：<code>youqu</code> ；</p><p>安装依赖:</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="go">// 如果你的测试机密码不是 `1` ，那你需要在全局配置文件 `globalconfig.ini` 里面将 `PASSWORD` 配置项修改为当前测试机的密码。</span></span><span id="LC2" class="line"><span class="gp">$</span><span class="w"></span><span class="nb">cd </span>my_project</span><span id="LC3" class="line"><span class="gp">$</span><span class="w"></span>bash env.sh</span><span id="LC4" class="line"><span class="gp">---&gt;</span><span class="w"></span>100%</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><hr><p><strong>【APP 工程】</strong></p><p>如果您已经有一个可用的 <code>APP</code> 工程，将应用库放到基础框架下 <code>apps</code> 目录下，像这样：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">my_project</span><span id="LC2" class="line">├── apps</span><span id="LC3" class="line">│   ├── autotest_deepin_music  <span class="c"># 应用库</span></span><span id="LC4" class="line">...</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>如果您还没有 <code>APP</code> 工程，建议使用框架提供的脚手架功能创建一个全新的 <code>APP</code> 工程。</p><h2><a id="user-content-创建工程" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B"></a>创建工程</h2><p>创建一个 APP 工程：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py startapp autotest_deepin_some</span><span id="LC2" class="line"><span class="gp">---&gt;</span><span class="w"></span>100%</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>这样在 <code>apps</code> 目录下会创建一个子项目工程 <code>autotest_deepin_some</code>，同时新建好工程模板目录和模板文件：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">apps</span><span id="LC2" class="line">└── autotest_deepin_some</span><span id="LC3" class="line"> &nbsp;&nbsp; ├── <span class="k">case</span></span><span id="LC4" class="line"> &nbsp;&nbsp; │&nbsp;&nbsp; ├── assert_res</span><span id="LC5" class="line"> &nbsp;&nbsp; │&nbsp;&nbsp; │&nbsp;&nbsp; └── readme</span><span id="LC6" class="line"> &nbsp;&nbsp; │&nbsp;&nbsp; ├── base_case.py</span><span id="LC7" class="line"> &nbsp;&nbsp; │&nbsp;&nbsp; └── __init__.py</span><span id="LC8" class="line"> &nbsp;&nbsp; ├── config.ini</span><span id="LC9" class="line"> &nbsp;&nbsp; ├── config.py</span><span id="LC10" class="line"> &nbsp;&nbsp; ├── conftest.py</span><span id="LC11" class="line"> &nbsp;&nbsp; ├── control</span><span id="LC12" class="line"> &nbsp;&nbsp; ├── deepin_some_assert.py</span><span id="LC13" class="line"> &nbsp;&nbsp; ├── deepin_some.csv</span><span id="LC14" class="line"> &nbsp;&nbsp; ├── __init__.py</span><span id="LC15" class="line"> &nbsp;&nbsp; └── widget</span><span id="LC16" class="line"> &nbsp;&nbsp;     ├── base_widget.py</span><span id="LC17" class="line"> &nbsp;&nbsp;     ├── case_res</span><span id="LC18" class="line"> &nbsp;&nbsp;     │&nbsp;&nbsp; └── readme</span><span id="LC19" class="line"> &nbsp;&nbsp;     ├── deepin_some_widget.py</span><span id="LC20" class="line"> &nbsp;&nbsp;     ├── __init__.py</span><span id="LC21" class="line"> &nbsp;&nbsp;     ├── other.ini</span><span id="LC22" class="line"> &nbsp;&nbsp;     ├── other_widget.py</span><span id="LC23" class="line"> &nbsp;&nbsp;     ├── pic_res</span><span id="LC24" class="line"> &nbsp;&nbsp;     │&nbsp;&nbsp; └── readme</span><span id="LC25" class="line"> &nbsp;&nbsp;     └── ui.ini</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><code>autotest_deepin_some</code> 是你的工程名称，比如：<code>autotest_deepin_music</code> ；</p><p>在此基础上，你可以快速的开始你的 AT 项目，更重要的是确保创建工程的规范性。</p><h2><a id="user-content-运行" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#%E8%BF%90%E8%A1%8C"></a>运行</h2><h3><a id="user-content-1-工作空间" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#1-%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4"></a>1. 工作空间</h3><p>在项目根目录下有一个 <code>manage.py</code> ，它是一个执行器入口，提供了本地执行、远程执行等的功能。</p><h3><a id="user-content-2-本地执行" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#2-%E6%9C%AC%E5%9C%B0%E6%89%A7%E8%A1%8C"></a>2. 本地执行</h3><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py run</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><h4><a id="user-content-21-命令行参数" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#21-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0"></a>2.1. 命令行参数</h4><p>通过命令行参数配置参数，使用 <code>-h</code> 或 <code>--help</code> 可以查看所有支持的命令行参数：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py run <span class="nt">-h</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>在一些 CI 环境下使用命令行参数会更加方便：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py run <span class="nt">--app</span> apps/autotest_deepin_music <span class="nt">--keywords</span><span class="s2">"xxx"</span><span class="nt">--tags</span><span class="s2">"xxx"</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>更多参数请查看【<a href="https://gitee.com/link?target=https%3A%2F%2Flinuxdeepin.github.io%2Fdeepin-autotest-framework%2F%25E6%25A1%2586%25E6%259E%25B6%25E5%258A%259F%25E8%2583%25BD%25E4%25BB%258B%25E7%25BB%258D%2F%25E6%2589%25A7%25E8%25A1%258C%25E7%25AE%25A1%25E7%2590%2586%25E5%2599%25A8%2F%2321">命令行参数</a>】</p><h4><a id="user-content-22-配置文件" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#22-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"></a>2.2. 配置文件</h4><p>通过配置文件配置参数</p><p>在配置文件 <code>setting/globalconfig.ini</code> 里面支持配置对执行的一些参数进行配置，配置完成之后，直接在命令行执行 <code>manage.py</code> 就好了。</p><p>详细配置项请查看【<a href="https://gitee.com/link?target=https%3A%2F%2Flinuxdeepin.github.io%2Fdeepin-autotest-framework%2F%25E6%25A1%2586%25E6%259E%25B6%25E5%258A%259F%25E8%2583%25BD%25E4%25BB%258B%25E7%25BB%258D%2F%25E6%2589%25A7%25E8%25A1%258C%25E7%25AE%25A1%25E7%2590%2586%25E5%2599%25A8%2F%2322">配置项</a>】</p><h3><a id="user-content-3-远程执行" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#3-%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8C"></a>3. 远程执行</h3><p>远程执行就是用本地作为服务端控制远程机器执行，远程机器执行的用例相同；</p><p>使用 <code>remote</code> 命令：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py remote</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><h4><a id="user-content-31-远程多机器分布式异步执行" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#31-%E8%BF%9C%E7%A8%8B%E5%A4%9A%E6%9C%BA%E5%99%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%BC%82%E6%AD%A5%E6%89%A7%E8%A1%8C"></a>3.1. 远程多机器分布式异步执行</h4><p><img src="https://pic.imgdb.cn/item/64f6d3c0661c6c8e549f8ca5.png" alt="" referrerpolicy="no-referrer"></p><p>多机器分布式异步执行就是由本地 YouQu 作为服务端，控制远程 N 台机器执行相同的用例，执行完之后所有测试机的测试结果会返回给服务端 report 目录下；</p><p>远程执行同样通过配置文件 <code>setting/globalconfig.ini</code> 进行用例相关配置；</p><p>需要重点说一下远程执行时的测试机信息配置，在配置文件 <code>setting/remote.ini</code>  里面配置测试机的用户名、IP、密码。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c">;=============================== CLIENT LIST =====================================</span></span><span id="LC2" class="line"><span class="c">; 测试机配置列表</span></span><span id="LC3" class="line"><span class="c">;[client{number}]     ;测试机别名，有多少台测试机就写多少个 client，别名必须包含 client 字符，且不能重复。</span></span><span id="LC4" class="line"><span class="c">;user =               ;测试机 user</span></span><span id="LC5" class="line"><span class="c">;ip =                 ;测试机 ip</span></span><span id="LC6" class="line"><span class="c">;password = 1         ;测试机的密码, 可以不配置此项，默认取 CLIENT_PASSWORD 的值；</span></span><span id="LC7" class="line"><span class="c">;如果你所有测试机密码都相同，那么只需要配置 CLIENT_PASSWORD 就可以了</span></span><span id="LC8" class="line"><span class="c">;=================================================================================</span></span><span id="LC9" class="line"></span><span id="LC10" class="line"><span class="nn">[client1]</span></span><span id="LC11" class="line"><span class="py">user</span><span class="p">=</span><span class="s">uos</span></span><span id="LC12" class="line"><span class="py">ip</span><span class="p">=</span><span class="s">10.8.15.xx</span></span><span id="LC13" class="line"></span><span id="LC14" class="line"><span class="nn">[client2]</span></span><span id="LC15" class="line"><span class="py">user</span><span class="p">=</span><span class="s">uos</span></span><span id="LC16" class="line"><span class="py">ip</span><span class="p">=</span><span class="s">10.8.15.xx</span></span><span id="LC17" class="line"></span><span id="LC18" class="line"><span class="nn">[client3]</span></span><span id="LC19" class="line"><span class="py">user</span><span class="p">=</span><span class="s">uos</span></span><span id="LC20" class="line"><span class="py">ip</span><span class="p">=</span><span class="s">10.8.11.xx</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>有多少台机器就像这样参考上面的格式写就行了。</p><p>然后在命令行：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py remote</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>这样运行是从配置文件去读取相关配置。</p><p>如果你不想通过配置文件，你仍然通过命令行参数进行传参，</p><p>以下为 <code>python3 manage.py remote</code> 提供的一些参数选项：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="o">-</span><span class="nx">h</span><span class="p">,</span><span class="o">--</span><span class="nx">help</span><span class="nx">show</span><span class="k">this</span><span class="nx">help</span><span class="nx">message</span><span class="o">and</span><span class="nx">exit</span></span><span id="LC2" class="line"><span class="o">-</span><span class="nx">c</span><span class="nx">CLIENTS</span><span class="p">,</span><span class="o">--</span><span class="nx">clients</span><span class="nx">CLIENTS</span></span><span id="LC3" class="line"><span class="err">远程机器的</span><span class="nx">user</span><span class="vi">@</span><span class="na">ip</span><span class="o">:</span><span class="nx">password</span><span class="p">,</span><span class="err">多个机器用</span><span class="s">'/'</span><span class="err">连接</span><span class="p">,</span><span class="err">如果</span><span class="nx">password</span><span class="err">不传入</span><span class="p">,</span><span class="err">默认取</span><span class="nx">sett</span></span><span id="LC4" class="line"><span class="nx">ing</span><span class="o">/</span><span class="nx">remote</span><span class="p">.</span><span class="na">ini</span><span class="err">中</span><span class="nx">CLIENT_PASSWORD</span><span class="err">的值</span><span class="p">,</span><span class="err">比如</span><span class="o">:</span><span class="nx">uos</span><span class="err">@</span><span class="mf">10.8</span><span class="p">.</span><span class="mi">13</span><span class="p">.</span><span class="na">xx</span><span class="o">:</span><span class="mi">1</span></span><span id="LC5" class="line"><span class="err">或</span><span class="nx">uos</span><span class="err">@</span><span class="mf">10.8</span><span class="p">.</span><span class="mi">13</span><span class="p">.</span><span class="na">xx</span></span><span id="LC6" class="line"><span class="o">-</span><span class="nx">s</span><span class="p">,</span><span class="o">--</span><span class="nx">send_code</span><span class="err">发送代码到测试机（不含</span><span class="nx">report</span><span class="err">目录）</span></span><span id="LC7" class="line"><span class="o">-</span><span class="nx">e</span><span class="p">,</span><span class="o">--</span><span class="nx">build_env</span><span class="err">搭建测试环境</span><span class="p">,</span><span class="err">如果为</span><span class="no">yes</span><span class="err">，不管</span><span class="nx">send_code</span><span class="err">是否为</span><span class="no">yes</span><span class="err">都会发送代码到测试机</span><span class="p">.</span></span><span id="LC8" class="line"><span class="o">-</span><span class="nx">p</span><span class="nx">CLIENT_PASSWORD</span><span class="p">,</span><span class="o">--</span><span class="nx">client_password</span><span class="nx">CLIENT_PASSWORD</span></span><span id="LC9" class="line"><span class="err">测试机密码（全局）</span></span><span id="LC10" class="line"><span class="o">-</span><span class="nx">y</span><span class="nx">PARALLEL</span><span class="p">,</span><span class="o">--</span><span class="nx">parallel</span><span class="nx">PARALLEL</span></span><span id="LC11" class="line"><span class="na">yes</span><span class="o">:</span><span class="err">表示所有测试机并行跑，执行相同的测试用例</span><span class="p">;</span><span class="na">no</span><span class="o">:</span><span class="err">表示测试机分布式执行，服务端会根据收集到的测试用例自</span></span><span id="LC12" class="line"><span class="err">动分配给各个测试机执行。</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>==除了这些特有参数以外，它同样支持本地执行的所有参数；==</p><p>在命令行这样运行：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py remote <span class="nt">-a</span> apps/autotest_deepin_music <span class="nt">-c</span> uos@10.8.13.x3/uos@10.8.13.x4 <span class="nt">-k</span><span class="s2">"xxx"</span><span class="nt">-t</span><span class="s2">"xxx"</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>所有用例执行完之后会在 <code>report</code> 目录下回收各个测试机执行的测试报告。</p><p>注意：如果远程机器没有搭建自动化测试环境，记得加上参数 <code>-e</code> ：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py remote <span class="nt">-a</span> ... <span class="nt">-e</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>执行前确保远程机器已经开启了 ssh 服务，否则会提示无法连接，如果没有开启，请手动开启：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span><span class="nb">sudo </span>systemctl restart ssh</span><span id="LC2" class="line"><span class="gp">$</span><span class="w"></span><span class="nb">sudo </span>systemctl <span class="nb">enable </span>ssh</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><p>配置文件其他相关配置项详细说明，请查看配置文件中的注释内容。</p><h4><a id="user-content-32-远程多机器分布式异步负载均衡执行" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#32-%E8%BF%9C%E7%A8%8B%E5%A4%9A%E6%9C%BA%E5%99%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%BC%82%E6%AD%A5%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%89%A7%E8%A1%8C"></a>3.2. 远程多机器分布式异步负载均衡执行</h4><p>多机器分布式异步负载均衡执行也是用本地作为服务端控制远程机器执行，但远程机器执行的用例不同，而是所有远程机器执行的用例之和，为你想要执行的用例集；</p><p>似乎有点难以理解，我用大白话举例描述下：</p><p>服务端想要执行 10 条用例，现在远程机器有 5 台，然后服务端就先拿着第 1 条用例给远程 1 号机执行，拿第 2 条用例给远程 2 号机执行...，如此循环直到所有用例执行完，这就是负载均衡执行。</p><p><img src="https://pic.imgdb.cn/item/64f6d694661c6c8e54a1025b.png" alt="" referrerpolicy="no-referrer"></p><p>使用方法和前面一样，只是需要增加一个参数 <code>--parallel</code>：</p><div><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="gp">$</span><span class="w"></span>youqu manage.py remote <span class="nt">-a</span> ... <span class="nt">--parallel</span> no</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></div><h2><a id="user-content-贡献者" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#%E8%B4%A1%E7%8C%AE%E8%80%85"></a>贡献者</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework%2Fblob%2Fmaster%2FCONTRIBUTING.md">贡献文档</a></p><p>--8&lt;-- "docs/contributors.html"</p><h2><a id="user-content-开源许可证" class="anchor" href="https://gitee.com/deepin-community/deepin-autotest-framework#%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E8%AF%81"></a>开源许可证</h2><p>有趣，在 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-autotest-framework%2Fblob%2Fmaster%2FLICENSE">GPL-2.0-only</a> 下发布。</p><hr><p><a href=""><strong>Star History</strong></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fstarchart.cc%2Flinuxdeepin%2Fdeepin-autotest-framework"><img src="https://starchart.cc/linuxdeepin/deepin-autotest-framework.svg" alt="Stargazers over time" referrerpolicy="no-referrer"></a></p>]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 03:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/deepin-community/deepin-autotest-framework</guid>
            <link>https://gitee.com/deepin-community/deepin-autotest-framework</link>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | AI 接连翻车的 Google 要变天了；中国互联网大厂 50 款大模型及应用，能否全面超越 GPT-4？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.12</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/282590/the-apple-curl-security-incident-12604" target="_blank">苹果在 macOS 中 「魔改」 cURL，作者无端背锅很生气</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">cURL&nbsp;<span>创始人兼首席开发者 Daniel Stenberg 又对苹果 「开炮」 了，上周他发表文章</span><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdaniel.haxx.se%2Fblog%2F2024%2F03%2F08%2Fthe-apple-curl-security-incident-12604%2F" target="_blank">指责</a></u><span>苹果修改了<span>&nbsp;</span></span>cURL&nbsp;<span>在 macOS 中使用某参数时的默认行为，此举会有可能引发安全问题。</span></p><blockquote><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-4f823e8378ab656ee3eb62a8499221fd1a1.png" referrerpolicy="no-referrer"></p></blockquote><h3><a href="https://www.oschina.net/news/282668/linux-6-9-dropping-old-ntfs" target="_blank">Linux 6.9 将移除旧版 NTFS 文件系统驱动程序，可减少近 3 万行代码</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">两年前，Linux 5.15 与 Paragon 软件公司开发的 "NTFS3" 驱动程序合并，该驱动程序支持读写操作，并对微软的 NTFS 文件系统驱动程序进行了其他改进。与主线内核中的原始 NTFS 只读驱动程序相比，该驱动程序有了很大改进，而且比使用 NTFS-3G FUSE 文件系统驱动程序更快。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">现在，随着时间的推移和 NTFS3 驱动程序的良好运行，旧版 NTFS 驱动程序将被移除。移除后，Linux 源代码树的行数将减少 29303 行。</p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-2ec5959cc7e12be258b495b83e169db84a1.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5872251960%2FO4IP15kbB" target="_blank">老 talk</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-e7e097a5bc9d0da217e6b474d77b6eb0a32.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1988800805%2FO4E27leQr" target="_blank">字母榜</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-deab83bc7969ebe937685bca416cdd94028.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tmtpost.com%2F6975495.html" target="_blank">钛媒体</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-735756a4f1cc258bf03fa620abaf90bc010.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2685230938725762" target="_blank">爱范儿</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-c1a21f80e8418ea5f32effa068149542d59.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fowncast%2Fowncast" target="_blank">https://github.com/owncast/owncast</a></u></em></p><hr><h2><span style="color:#16a085"><strong>事件点评</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-98c444cd0aad24468cf26a026f899de5918.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精选</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-2c23bbee2e8540138741c4373396a65427e.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/hh291xp9mxksc9i/27_ai_google_50_gpt_4_KfagjDXXfZ.pdf" target="_blank">开源日报第 027 期：AI 接连翻车的 Google 要变天了；互联网大厂 50 款大模型及应用，能否全面超越 GPT-4？</a></u></em></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/uwsizmmsnhq8zdk/26_git_hub_22_web_os_22_vue_rolldown_FpVykoR7rJ.pdf" target="_blank">开源日报第 026 期：大模型替代程序员根本就是一个伪命题；GitHub 顶流"Web OS"</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6ho57sxydzsh9jh/25_ai_5_ax1LWz5GP5.pdf" target="_blank">开源日报第 025 期：买手机送大模型；「钓鱼式维权」须遏制；「AI 原生」骗局江湖</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7xd6teyhekcvamw/24_risc_v_x86_arm_5LsjoStPUn.pdf" target="_blank">开源日报第 024 期：RISC-V 能否和 x86、Arm 一起成为三大主流架构；给阎王开发地府管理系统</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">开源日报第 023 期：Google=开源，好评；Microsoft=闭源收入还低，差评</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">开源日报第 022 期：轻松复现 Sora 模型；事关 CUDA 兼容，英伟达禁止了；百度还差一个「遥遥领先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">开源日报第 021 期：闭源模型就是比开源安全；起诉 OpenAI 不能更赞同</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">开源日报第 020 期：为什么王炸都来自 OpenAI；Pingora 最好不要用 YAML 当配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">开源日报第 019 期：我让 AI 用 C 语言写一个算法；微软三进制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">开源日报第 018 期：苹果十年造车梦碎；这个开源项目有点...「大胆」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">开源日报第 017 期：MariaDB 消亡史；写代码我有三不沾；V 神建议马斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282857</guid>
            <link>https://www.oschina.net/news/282857</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | vivo 在离线混部探索与实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="font-size: 15px;line-height: 1.6;"><section style="margin: 10px 0% 8px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding-left: 8px;align-self: flex-start;flex: 0 0 auto;"><section style="color: rgba(0, 0, 0, 0.5);font-size: 14px;text-align: justify;" powered-by="xiumi.us"><p style="text-wrap: wrap;">作者：来自 vivo 互联网服务器团队</p></section></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;background-color: rgb(234, 241, 255);border-style: solid;border-width: 0px 0px 0px 4px;border-color: rgb(48, 97, 207) rgb(48, 97, 207) rgb(48, 97, 207) rgb(21, 151, 239);padding: 10px;"><section style="text-align: justify;" powered-by="xiumi.us"><p style="text-wrap: wrap;">本文根据甘青、黄荣杰老师在「2023 vivo 开发者大会"现场演讲内容整理而成。公众号回复【2023 VDC】获取互联网技术分会场议题相关资料。</p></section></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: left;" powered-by="xiumi.us"><section style="text-align: justify;line-height: 1.8;padding-right: 5px;padding-left: 5px;color: rgb(160, 160, 160);"><p style="text-wrap: wrap;">伴随 vivo 互联网业务的高速发展，数据中心的规模不断扩大，成本问题日益突出。在离线混部技术可以在保证服务质量的同时，极大的提升数据中心资源利用率，降低成本。混部技术涉及任务调度、资源隔离、运维观测等一系列技术难题，本文将介绍 vivo 在混部技术方面的实践和探索，为读者提供借鉴和参考。</p></section></section><section style="margin-right: 0%;margin-bottom: -5px;margin-left: 0%;text-align: right;line-height: 1;font-size: 5px;transform: translate3d(5px, 0px, 0px);" powered-by="xiumi.us"><section style="width: 0px;display: inline-block;vertical-align: top;border-bottom: 0.6em solid rgb(160, 160, 160);border-right: 0.6em solid rgb(160, 160, 160);border-top: 0.6em solid transparent !important;border-left: 0.6em solid transparent !important;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>一、在离线混部技术背景</p></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">1.1 为什么混部</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014216" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/90584c50-ab1b-4c96-a93d-1a51552af9c2.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">数据中心运行的服务可以分为在线服务和离线任务两大类，它们具有不同的资源使用特征。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在线服务是指那些长时间运行、对时延非常敏感的服务，如电商、游戏等，在线服务的资源利用率存在明显的波峰波谷现象，平均利用率较低。离线任务是指那些运行周期短，有容错性，对实时性要求低的服务，如数据转换、模型训练等，离线任务在执行过程中资源利用率很高。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在混部之前，在线和离线都是分开独立部署，机器不共享，无法形成有效的资源互补，这导致数据中心整体资源利用率不高，却要不断购买新机器，造成了资源浪费。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">1.2 混部技术定义</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014217" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/d95f327e-4b95-4e53-873a-cec47b2b9123.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">通过混部技术，我们可以将在线和离线部署到同一台物理机上，形成资源互补，提升物理机的资源利用率，降低成本。混部技术最早由谷歌在 2015 年提出，经过多年的发展，混部技术已经趋于成熟，目前业内利用混部技术可以将数据中心的 CPU 利用率提升至 40% 左右 。</p><p style="text-wrap: wrap;"><br>vivo 在 2020 年开始调研混部技术，2023 年混部平台投入生产，目前我们已经将部分混部集群的 CPU 利用率提升至 25%（最新已达 30%）左右。相较业界标杆这还有一定的差距，但随着混部规模的扩大，我们将挑战更高的目标。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>二、在离线混部平台实践</p></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.1 混部平台产品能力</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014218" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/68d72481-c187-452c-82a9-2dffd5f14199.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">混部平台必须具备两个产品能力：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">第一、强大的调度、隔离能力</span></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;">第二、完善的监控、运维能力</span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">强大的调度能力解决了，我们如何将离线任务高效、合理的调度到在线服务所在的物理机上。而强大的隔离能力保障了在线服务的质量不受离线任务干扰。完善的监控和运维能力则可以让我们洞悉整个混部平台的运行情况，及时发现潜在风险，帮助运维人员更高效的完成系统和业务的运维工作，保障集群的高稳定性。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section style="font-size: 16px;color: rgb(65, 95, 255);" powered-by="xiumi.us"><p style="text-wrap: wrap;">2.2 混部差异化资源视图</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014219" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/57e41ac2-cf24-44d9-938a-fa7e2ba4fd5a.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">混部首先要解决的一个问题是离线使用哪一部分资源。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">在 vivo 混部系统中在线和离线看到的资源视图是不同的：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">在线可用资源为，整机资源</span></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;">离线可用资源为，整机资源减去，在线实际使用的资源</span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">同时为了避免整机负载太高影响系统的稳定性，我们设置一个安全水位线，用于调节离线可用资源大小。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.3 混部 QoS 等级</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014220" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/19c209cc-56e1-496e-99b3-5f97f6afcb35.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-wrap: wrap;">为了保障混部系统的 slo，我们将服务分为三个等级：<strong>高、中，低</strong>。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">不同等级的服务对物理资源如：CPU、内存，使用时有不同的优先级。高优先级服务支持绑定 CPU 模式，适用对延时非常敏感的在线服务。一般的在线服务可设置为中优先级。离线任务设置为低优先级，通过这样的等级划分，我们很好的实现在线对离线的资源压制和隔离，保障了在线服务质量。<span style="letter-spacing: 0.034em;"></span><span style="color: rgba(0, 0, 0, 0.5);letter-spacing: 0.034em;"></span></p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.4 混部核心组件架构</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014221" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/b1afd7a5-c2cd-4147-bf9c-1608efeab996.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-wrap: wrap;">我们所有的混部组件都是以插件方式独立运行，对原生 K8s 无侵入。我们实现了一个混部调度器，在线和离线统一使用这个调度器，避免了多调度器资源账本冲突的问题。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">每台物理机上都会部署一个混部 agent，它可以实时采集容器资源使用数据，并根据安全水位线对离线任务进行压制、驱逐等操作。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">内核层面我们使用了龙蜥 OS，它具备强大的资源隔离能力，可以帮助我们更好的隔离在线、离线资源使用，保障在线服务质量。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.5 混部组件功能</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014222" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/713e94c0-293b-4843-8d8c-55417c3e25fa.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">我们把混部组件分为管控组件和单机组件两大类。</p><p style="text-wrap: wrap;"><br></p></section><section powered-by="xiumi.us"><p style="text-wrap: wrap;"><strong>管控组件</strong>主要负责调度和控制，根据 vivo 业务使用场景，我们对调度器做了一些增强，提供了 numa 感知、负载感知，热点打散，批量调度等能力。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">混部控制器主要提供了一些配置管理能力：如资源画像统计、node slo 配置、node 扩展资源变更等。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.6 混部可视化监控</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014223" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/bc9d9741-bd4c-4fd6-b91f-621a91d97fdb.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-wrap: wrap;">我们为混部建立一套完整的可视化监控体系。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">针对在线服务我们提供了：容器资源使用指标，受离线干扰指标、业务混部收益指标等监控能力。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">针对离线任务，我们提供了离线可用资源、任务异常状态等监控能力。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在平台层面上我们提供了节点、内核，核心组件的监控，通过这些监控可及时发现平台潜在的风险。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.7 混部平台运维</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014224" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/caade6d0-4d75-473e-9927-322fa0fb4c1b.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">为了简化运维操作，提升运维效率，我们对混部集群搭建和节点扩缩容操作进行了白屏化改造，开发了资源池管理功能，简化了物理机接入流程，运维效率大幅提升。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在运维平台上运维人员可以快速调整混部隔离、水位线等参数，如果发现在线服务受到干扰，运维人员可以一键关闭混部，驱逐离线任务，保障在线服务质量。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.8 问题与挑战</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><strong>2.8.1 apiServer 拆分</strong></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014225" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/62a20de0-2b72-4f82-8240-53b688884216.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-wrap: wrap;">通过混部产品能力的建设，我们很好的实现了容器混部能力，但是在实践中我们还是遇到一些新的挑战：相对于普通 K8s 集群，混部集群中运行着更多的容器，而且离线任务由于生命周期短，容器创建销毁更为频繁，这对 K8s apiServer 产生了很大的压力。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">所以我们拆分了 apiServer ，离线任务使用独立的 apiServer ，保障了集群 apiServer 负载一直处于一个安全水平。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><strong>2.8.2 监控架构优化</strong></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014226" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/a141c014-152a-4858-887b-9992c38212c3.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">同样混部之后由于采集了更多的监控指标，导致 Prometheus 内存消耗过多，无法满足平台指标，采集需求。针对这个问题，我们优化了监控架构，将在线和离线监控组件分开部署，离线改用性能更好的 vmagent，通过这个优化，监控组件内存消耗减少到原来的十分之一。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.9 利用率提升</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014227" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/a78f6e6d-75d8-4552-838d-29ab9517de07.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">混部初期虽然集群 CPU 利用率有所提升，但是还是没有达到我们的预期，主要<strong>原因</strong>有：</p><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><section style="margin-right: 5px;margin-bottom: -2.25em;background-color: rgb(247, 247, 247);"><section powered-by="xiumi.us" style="margin-bottom: 5px;padding: 10px;"><section style="text-align: left;"><ul class="list-paddingleft-1" style="width: 552.438px;"><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.578px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">一、部分低配置机器资源本身较少。</span></span></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">二、J</span><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">ava 类应用堆会固定占用大量内存，导致可提供给离线使用内存资源不足。</span></span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p powered-by="xiumi.us" style="margin-bottom: 0px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 0.034em;"></span><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">针对这些问题，我们开发了定时调整安全水位线功能，在业务低峰期上调安全水位线，释放更多的资源给离线使用。通过一系列的优化手段，我们将其中一个混部集群的 CPU 利用率由 13% 提升到了 25% 左右，几乎翻倍，混部效果得到了有效的验证。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>三、Spark on K8s 弹性调度实践</p></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">3.1 方案选型</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014228" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/d3e8ac4a-32d1-4b0f-8abf-fab2aa42f043.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在大方向的技术选型上，我们选择了 Spark on K<span style="letter-spacing: 0.034em;">8s，在业内，也有一些公司采用了 YARN on K8s 的方案。</span><span style="letter-spacing: 0.034em;">我们也对这两种方案进行过对比。</span></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">从业务适用性来说，YARN on K8s 是通用的，可以兼容 Hive、Spark、Flink 这些引擎，它不需要频繁创建 Nodemanager pod，对 K8s 的压力比较小。这些都是它的优点，但另一方面，Nodemanager ESS 服务是对磁盘有容量和读写性能要求的，混部机器磁盘一般难以满足。所以我们要支持不同引擎的 remote shuffle service。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">如果计算引擎有不同的版本，那么 RSS 也要支持不同版本，比如 Spark2，Spark3。如果你有不同的引擎，不同的版本，很可能一种 RSS 还满足不了需求。另外 Nodemanager 需要根据 K8s 混部节点的剩余资源，动态调整可用的 vcore 和内存，所以还需要一个额外的组件来做这个事情，这需要较高的改造成本。在资源利用上，NM 的资源粒度相对大，自身也会占用一些资源，存在一定的浪费。在资源紧张的情况下，Nodemanager 作为整体被驱逐，会影响多个任务。<span style="letter-spacing: 0.034em;">这些是 YARN on K8s 的劣势。</span></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;"><strong>作为对比，Spark on K8s 劣势有哪些？</strong></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">首先这个特性在 Spark 3.1 以上版本才正式可用。Spark on K8s 由于会频繁的创建、查询、销毁大量的 executor pod，对 K8s 的调度能力以及 master 节点会造成比较大的压力。另一方面，它的优势在于只需要能支持 spark3.X 的 RSS，这有较多的开源产品可选择。而且改造成本比较低，不需要额外的组件。资源粒度小，更有利于充分利用集群资源。在资源紧张时，会逐个 pod 进行驱逐，任务的稳定性会更高。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">两方案各有优劣势，为什么我们选择了 Spark on K8s？一方面因为 Spark3.X 是 vivo 当前及未来 2~3 年的主流离线引擎，另一方面 vivo 内部对 K8s 研发比较深入，能有力支持我们。基于以上原因，我们最终决定使用 spark on K8s</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">3.2 三步走战略</span></p><p style="text-align: center;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014229" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/eb89e8e2-ea5e-4740-9a12-fb80622fbf88.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">确定了方案选型，那在 vivo 我们是如何推进 spark on K8s 大规模的应用落地呢？回顾总结我们走过的路，可以大致归纳为三步走的战略。<span style="text-align: left;background-color: rgb(247, 247, 247);letter-spacing: 0.034em;"></span></p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">第一，是任务跑通跑顺的初期阶段</span></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;">第二，是任务跑稳、跑稳的中期阶段</span></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;">最后，是任务跑得智能的成熟阶段</span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">接下来的内容，我们将对每个阶段展开细说。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><strong>3.2.1 任务跑通跑顺</strong></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014230" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/60083a6d-7464-47e5-acfe-80be28bd38b1.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在任务跑通、跑顺的第一阶段，我们要解决的是怎么将任务提交 K8s 集群，同时要求易用性、便利性方面能够达到与 on YARN 一致的用户体验。将我们最后采用的方案架构简化一下，就如同这张图所示。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">首先，为了降低任务提交的复杂性、避免用户改造任务的成本。我们在任务调度管理平台做到了对原有 Spark 任务的兼容，通过 vivo 内部的容器开放 API-这个代理层，我们不需要维护额外的 K8s client 环境，就可以轻松实现任务提交，提交后也能近实时获取任务的状态和日志信息。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">另外一个关键点是，我们选用了 Spark Operator 作为 Spark 任务容器化的方案。Spark Operator 是谷歌基于 K8s Operator 模式开发的一款的工具，用于通过声明式的方式向 K8s 集群提交 Spark 作业。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">Spark Operator 的方式还有其他优点：</p></section><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">Operator 方式对 K8s 更友好，支持更灵活、更全面的配置项</span></p></li><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">使用上更简单易用</span><br></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;">内置 Metrics,有利于我们做集中管理</span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">要达到阶段一的目标，让任务跑通、跑顺。我们主要克服了哪些<strong>关键问题和挑战</strong>？</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014231" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/870b19d4-186a-4594-904f-b362f3544128.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-wrap: wrap;">第一个是日志查看，因为 Spark Operator 方式并没有提供已结束作业的日志查看方式，包括 driver 和 executor 日志。在 Driver 侧，我们通过定期请求容器开放 API，能准实时地获取 Driver Pod 状态与日志。在 Executor 侧，我们参考了 on yarn 的方式，Executor Pod 结束后，日志上传 HDFS，与 YARN 日志聚合类似。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">另一方面，我们也在 Spark HistoryServer 做了二次开发工作，增加了 on K8s 方式的日志查看接口。用户查看已完成的 Executor 日志时，不再请求 JobHistory Server，而是请求 Spark HistoryServer 接口。在体验上做到了基本与 yarn 一致。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在混部 K8s 集群，我们也做了三方面能力的<strong>加强</strong>。</p><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><section style="margin-right: 5px;margin-bottom: -2.25em;background-color: rgb(247, 247, 247);"><section powered-by="xiumi.us" style="margin-bottom: 5px;padding: 10px;"><section style="text-align: left;"><ul class="list-paddingleft-1" style="width: 552.438px;"><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.578px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">一是，确保分配能力能支持离线任务频繁建删 pod 的需求，在优化后我们离线 Pod 分配能力达到数百 pod/秒。</span></span></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.578px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">二是，在 K8s 侧提升了 spark 内部的 Driver 优先级，确保了在驱逐时 Driver 稳定性高于 Executor。</span></span><br></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">最后一个是，发现并修复了 spark-operator 的一个 bug，这个 bu 是 Operator 在多副本部署时，slave 副本 webhook 处理有一点概率出现 pod 找不到的问题。</span></span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p powered-by="xiumi.us" style="margin-bottom: 0px;font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 0.034em;"></span></p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><strong>3.2.2 任务跑稳跑准</strong></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014232" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/be9e7c1f-0784-4af4-9430-927194cc675d.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">在第二阶段，我们要保障的是任务跑稳，数据跑准,因此，我们有两个<strong>关键的举措</strong>：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">大规模双跑，目的是确保 Spark 任务迁移到 K8s 集群后是兼容的，任务成功率有保障；</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">任务执行时长是稳定的，不会明显变慢；</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">数据是准确的,跟 on YARN 保持一致性。</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">为此，我们需要对任务进行 on YARN 和 on K8s 两种模式下的双跑测试，我们分批次总共进行了 7 轮双跑，覆盖了 2 万+的线上正式任务。</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">最终也取得了我们想要的结果：</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">我们双跑最终达成的任务成功率超过了 99.5%，绝大部分的任务在两种模式下的时长波动在 25% 以内，数据一致性是 100%。</span></p><p><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);"></span></p></li><li><p><span style="letter-spacing: 0.034em;">混部集群的压力联调，目的是确保混部集群的承载容量能够支撑大规模的离线任务调度，通过模拟未来 1 年的任务量来给混部集群做压力测试，充分发现和检测 K8s 集群可能存在的性能问题。</span><span style="letter-spacing: 0.034em;">最终，通过我们多轮压测和问题解决，我们在单个 K8s 集群能够支撑 150+同时运行的 Spark 任务，1 万+同时在运行的 Pod 数量。</span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014233" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/aa02646f-2993-4e8c-87df-a610f4dbc1a7.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">在<strong>第二阶段</strong>，我们主要面临三个方面的<strong>问题和挑战</strong>。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">首先是我们需要为 Spark 选择一个外部的 shuffle 服务，经过技术选型和比较，我们最终选择开源的 celeborn 作为我们的 remote shuffle service 组件。我们通过对机型和参数的测试调优，使 celeborn 的性能达到我们的预期需求。在大规模的应用场景中，我们还发现了会存在大任务会阻塞小任务，导致 shufle read 变慢的问题，我们对这种情况做了参数和代码上的优化，当前社区也针对 shuffle read 的问题有一些待优化的改进。另外 celeborn 进行了容器化部署，在提升自动化运维能力的同时，也可以为混部集群提供额外的计算资源。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">其次，在任务稳定性方面，我们也解决了一系列的问题。</p><section style="font-size: 15px;letter-spacing: 5px;"><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: justify;letter-spacing: 0px;" powered-by="xiumi.us"><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p style="margin-bottom: 10px;text-wrap: wrap;"><span style="letter-spacing: 0px;"><span style="font-size: 15px;letter-spacing: normal;text-wrap: wrap;">在双跑的时候，我们发现有不少任务在 on K8s 模式下很容易 OOM，这是因为在 on YARN 模式下申请的 container 内存大小，不止是由 Spark 任务本身的内存参数决定，还会被 YARN 的资源粒度参数所影响。所以这块要做一些适配对标工作。</span></span></p></li><li><p style="margin-bottom: 10px;text-wrap: wrap;"><span style="font-size: 15px;letter-spacing: normal;text-wrap: wrap;">在任务量比较大的情况下，Spark operator 的吞吐能力会遇到瓶颈，需要我们将并发 worker 数量、队列的相关参数调大。</span></p></li><li><p style="margin-bottom: 10px;text-wrap: wrap;"><span style="font-size: 15px;letter-spacing: normal;text-wrap: wrap;">CoreDNS 因为 Spark 任务频繁的域名解释请求，导致压力增大，甚至可能影响在线服务。这个可以通过访问 ip 而不是域名的方式来规避，比如 namenode 节点、driver 和 executor。</span></p></li><li><p style="margin-bottom: 10px;text-wrap: wrap;"><span style="font-size: 15px;letter-spacing: normal;text-wrap: wrap;">横向扩展 namespace，这样可以避免单 namespace 的瓶颈，也防止 etcd 出现问题。</span></p></li><li><p style="margin-bottom: 10px;text-wrap: wrap;"><span style="font-size: 15px;letter-spacing: normal;text-wrap: wrap;">我们 K8s apiserver 的压力随着任务量增长压力也会逐渐增大，这会影响整个集群的稳定性。我们主要通过优化 Spark driver list pod 接口、使用 hostnetwork 方式两个优化手段，有效降低了 apiserver 的压力。</span><span style="letter-spacing: 0px;"></span></p></li></ol></section></section></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="letter-spacing: 0.034em;"></span><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">最后要说的是数据一致性，关键点是要做到行级记录的 MD5 校验，发现有不一致的 Case，我们做到 100% 的分析覆盖。排除了因为时间戳随机函数等一些预期内的不一致，我们发现并修复两种 case 会偶发导致不一致的问题：<span style="text-align: left;background-color: rgb(247, 247, 247);letter-spacing: 0.034em;"></span></p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);"></span>celeborn Bug 导致不一致，具体可参考 CELEBORN-383 解决<span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);"></span></p></li><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.51px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">Java 版本不一致导致的问题</span><span style="letter-spacing: 0.034em;"></span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><strong>3.2.3 任务跑得智能</strong></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014234" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/cd569e4c-b965-4131-8030-d92568dac94d.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">在<strong>第三阶段，我们需要解决的问题是让任务跑得智能，怎么定义智能</strong>，我想用三个词来概括弹性、健壮、业务需求。这是我们弹性调度的架构图，细节我就不讲了，这里我介绍下我们的调度系统重点支持的功能。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014235" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/66a9c86a-4364-4adf-83af-94239689cfbb.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-wrap: wrap;">在弹性方面，我们需要做到实时根据混部集群资源闲忙，智能提交至混部集群或者 Hadoop 集群。在前期我们 K8s 集群的资源相对 Hadoop 是小头，通过合理的水位线控制，防止大量任务同时调度到 K8s 导致饿死。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">健壮，就是要保证任务的高可用。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">我们建设的能力包括：</p></section><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">任务双跑成功后再混部</span></span></p></li><li><p style="margin-bottom: 10px;"><span style="font-size: 15px;letter-spacing: 0.51px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">支持离线任务失败自动回滚到 Hadoop 集群执行</span><br></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;">支持用户自主决定任务是否可调度至 K8s 集群</span></p></li><li><p style="margin-bottom: 10px;"><span style="letter-spacing: 0.034em;">初期剔除重要核心任务、剔除不可重试任务</span></p></li></ul></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><section powered-by="xiumi.us"><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">目的是在用户任务迁移时做到让用户无感。</p><p style="text-wrap: wrap;"><br></p><p style="text-wrap: wrap;">在满足业务需求方面，我们支持优先调度本业务的离线任务， 优先满足业务部门的离线任务资源需求；支持只在指定时间段里调度离线任务，支持在出现异常情况下一键终止调度 K8s。这些是为了确保在线服务的高可用性，免除在线业务的后顾之忧。</p></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">3.3 混部效果</span></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014236" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/afab0f50-7f07-454b-bd55-61893c100c47.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">克服了三步走过程中的磕磕碰碰，我们终于可以将离线任务大规模混布到 K8s 混部集群了。但是我们很快发现，混部集群的整体利用率并没有达到我们的预期，主要有三方面的<strong>原因</strong>。</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><ol class="list-paddingleft-1" style="list-style-type: decimal;"><li><p><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">初期的 Spark 任务不足，这个我们通过加快双跑，迁移低版本的 Spark 任务，迁移 Hive SQL 任务来解决。</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);"></span></p><p><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);"></span></p></li><li><p><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);"><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">在混部的时候，我们也观察到，离线任务的 pod cpu 利用率其实没那么高。</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">比如我们申请一个核，通常只能利用 0.6 个核，存在浪费的情况。</span><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);">我们上线了 CPU 资源超分的能力，目前是静态的固定比例超分，通过这个措施，我们能将 pod 的实际 cpu 利用率打到 80% 以上。</span></span></p><p><span style="font-size: 15px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(247, 247, 247);"></span></p></li><li><p><span style="letter-spacing: 0.034em;">另外就是混部集群中的机器配置不均，部分机器 cpu 资源充足，但是内存不够。</span><span style="letter-spacing: 0.034em;">我们通过在调度侧控制可调度任务的资源粒度，尽量调度对内存资源需求较小的任务。</span></p></li></ol></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us">通过我们在任务调度侧，以及之前甘青提到过的其他措施。混部集群利用率得到了进一步的提升。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="100014237" data-ratio="0.562962962962963" data-s="300,640" src="https://oscimg.oschina.net/oscnet/30c40274-3532-4eeb-ba12-14839209981d.png" data-type="png" data-w="1080" style="" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p style="text-wrap: wrap;">最后，我向大家同步下，当前我们达成的<strong>混部效果</strong>。</p></section><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="margin-bottom: -2.25em;margin-right: 5px;background-color: rgb(247, 247, 247);"><section style="padding: 10px;margin-bottom: 5px;" powered-by="xiumi.us"><section style="text-align: left;"><p>我们目前可供调度的任务接近 2 万个，这些任务每天调度的次数已经超过了 4 万次。在凌晨的高峰期，我们通过混部，能为离线任务额外增加 2 万核、50TB 内存的计算资源。这个收益是相当可观的，我们也希望在未来的 2 到 3 年，将可调度的任务规模提升到 6 万个，弹性资源能够为离线计算总资源贡献 20% 的份额。</p><p><br></p><p>通过继续深度推进在离线混部技术，我们期望能够为 vivo 增效降本工作持续地贡献力量。</p></section></section></section><section style="margin-left: auto;width: 2.25em;height: 2.25em;border-right: 5px solid transparent;border-bottom: 5px solid transparent;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us">以上就是本次分享的全部内容。</p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section style="margin-right: 0%;margin-bottom: 20px;margin-left: 0%;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: middle;width: 20%;align-self: center;flex: 0 0 auto;"><section style="text-align: center;color: rgb(45, 66, 87);font-size: 11px;" powered-by="xiumi.us"><p>END</p></section></section><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="margin-top: 10px;margin-bottom: 10px;text-align: left;" powered-by="xiumi.us"><section style="padding-left: 1em;padding-right: 1em;display: inline-block;text-align: center;"><span style="display: inline-block;padding: 0.3em 0.5em;border-radius: 0.5em;background-color: rgb(65, 94, 255);color: rgb(255, 255, 255);" title="" opera-tn-ra-cell="_$.pages:0.layers:0.comps:148.title1"><p>猜你喜欢<span style="font-size: 14px;text-align: left;background-color: rgb(239, 239, 239);color: rgba(0, 0, 0, 0.9);letter-spacing: 0.034em;"></span></p></span></section><section style="border-width: 1px;border-style: solid;border-color: transparent;margin-top: -1em;padding: 20px 10px 10px;background-color: rgb(239, 239, 239);text-align: center;"><section style="font-size: 14px;text-align: left;" powered-by="xiumi.us"><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247498152%26idx%3D1%26sn%3Dedd66643831717629aad7aff83408d7b%26chksm%3Debdb893adcac002c6e3e83ce965f42a145933e65e0b6cda36b4dba5ca74b695d24c75ab1d8fb%26scene%3D21%23wechat_redirect" textvalue="vivo 海量微服务架构最新实践" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 14px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(239, 239, 239);">v</span><span style="font-size: 14px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(239, 239, 239);">ivo 海量微服务架构最新实践</span></a><span style="font-size: 14px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(239, 239, 239);"></span><br></p></li><li><p><span style="font-size: 14px;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;background-color: rgb(239, 239, 239);"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247498156%26idx%3D1%26sn%3D38a4f19cd0dd7ee722058fb93d24d9cd%26chksm%3Debdb893edcac00281d3dbdaaff9bf97849bc8c474718cc3a4897f8bc6591ac1d048d6fca32f0%26scene%3D21%23wechat_redirect" textvalue="vivo 智能活动中台-悟空系统建设之路" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">vivo 智能活动中台-悟空系统建设之路</a></span><br></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247498161%26idx%3D1%26sn%3De2b373cf68dacf452f9a72914ff5d572%26chksm%3Debdb8923dcac00350b0fc183811faca38b835da3770032ff5aac641e3c43903fb520feb2415a%26scene%3D21%23wechat_redirect" textvalue="vivo 海量基础数据计算架构应用实践" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">vivo 海量基础数据计算架构应用实践</a></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247498246%26idx%3D1%26sn%3D4de0ce8c53c4f19d8f84908a3159f449%26chksm%3Debdb8a94dcac03825ee53323d4d48266526ffc24d9bfe572d673de47e4a34aabb26125900330%26scene%3D21%23wechat_redirect" textvalue="vivo 短视频体验与成本优化实践" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">vivo 短视频体验与成本优化实践</a></p></li></ul></section></section></section><p style="text-wrap: wrap;" powered-by="xiumi.us"><br></p><section class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互联网技术" data-alias="vivoVMIC" data-signature="分享 vivo 互联网技术干货与沙龙活动，推荐最新行业动态与热门会议。" data-from="0" data-is_biz_ban="0"></mp-common-profile></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - vivo 互联网技术（vivoVMIC）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 03:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/11045485</guid>
            <link>https://my.oschina.net/vivotech/blog/11045485</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 新模型 GPT-4.5 Turbo 意外曝光]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 的最新力作 GPT-4.5 Turbo 已经在网络上意外曝光。首批发现此信息的是 Bing 和 DuckDuck Go 等搜索引擎，它们在官方发布之前就索引了这款产品的页面。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ceb1f311186a7da1ba5bb081bfbb308b554.png" referrerpolicy="no-referrer"></p><p>不过，点击这些搜索结果却会出现 404 错误页面。尽管如此，搜索引擎中的预览文本透露了一个激动人心的消息：GPT-4.5 Turbo 是 OpenAI 至今为止开发的速度最快、最准确、扩展性最强的模型，能处理高达 256,000 个 Token，是之前 GPT-4 Turbo 128K 处理能力的两倍，大约相当于 200,000 个词。</p><p>此外，预览信息还提到，GPT-4.5 Turbo 将包含直至 2024 年 6 月的最新信息，这意味着新模型预计将在 6 月份发布。这与 OpenAI 以往发布新模型后立即提供使用的做法不同，这可能是为了与近期推出的竞争对手模型，如 Anthropic 的 Claude 3 竞争，后者在多个领域的表现已经达到或超过了 GPT-4。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0fdbafcd29014f47112bb4a071d7995270b.png" referrerpolicy="no-referrer"></p><p>自去年 12 月以来，就有传闻称 GPT-4.5 Turbo 将很快推出。这些传闻中提到的新特性包括文本和图像处理之外，可能还包括视频或 3D 功能。不过，这次泄露的信息中并没有提及到这方面的能力。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 02:11:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282842/openais-gpt-4-5-turbo-leaked-on-search-engines</guid>
            <link>https://www.oschina.net/news/282842/openais-gpt-4-5-turbo-leaked-on-search-engines</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中央国家机关政府采购中心：应当将 CPU、操作系统符合安全可靠测评要求纳入采购需求]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">中央国家机关政府采购中心 3 月 11 日发布《关于更新中央国家机关台式计算机、便携式计算机批量集中采购配置标准的通知》。</span></p><p><span style="color:#000000">其中提到，明确要求，乡镇以上党政机关，以及乡镇以上党委和政府直属事业单位及部门所属为机关提供支持保障的事业单位在采购台式计算机、便携式计算机时，应当将 CPU、操作系统符合安全可靠测评要求纳入采购需求。</span></p><p><span style="color:#000000"><img height="306" src="https://oscimg.oschina.net/oscnet/up-86f7c27e9f31f3a2d12c5cfa9e70800d2fd.png" width="500" referrerpolicy="no-referrer"></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 02:05:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282840</guid>
            <link>https://www.oschina.net/news/282840</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Midjourney 禁止 Stability AI 员工使用其服务]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>据 The Verge 报道，Midjourney 宣布禁止 Stability AI 的员工使用其服务。</p><p>MidJourney 同时指责竞争对手生成式 AI 公司的员工在本月早些时候<strong>试图窃取 Midjourney 的数据时造成了系统中断</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-19fb636932e992d63ecd495889536c09fbe.png" referrerpolicy="no-referrer"></p><p>Midjourney 于 3 月 2 日在其 Discord 服务器上发布了一条更新，承认服务器长时间中断导致生成的图片无法出现在用户图库中。</p><p>在 3 月 6 日的业务更新电话会议摘要中，Midjourney 声称 "来自付费账户的僵尸网络式活动"（该公司特别将其与 Stability AI 员工联系起来）是此次故障的幕后黑手。<span style="background-color:#ffffff; color:#474747">它监测到怀疑是 Stability AI 雇员试图批量抓取提示和图像的类僵尸网络活动。</span></p><p>Stability AI CEO Emad Mostaque <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FEMostaque%2Fstatus%2F1765496173572346182" target="_blank">回应了这一报道</a></u>，表示发生的任何事情都绝非故意。他称他们的调查发现没有人在抓取图像，但一名团队成员运行了一个机器人程序，为个人项目收集提示。如果是这一行为导致了 Midjourne 宕机，他们对此表示道歉。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-18dbc114ac9f5e8bc411d1dc54f16b09afe.png" referrerpolicy="no-referrer"></p></blockquote><p>Mostaque 称 Stability AI 不需要 Midjourney 的数据，该公司最新的 Stable Diffusion 3 模型优于 Midjourne 等竞争对手的模型。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 13 Mar 2024 01:56:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282835/midjourney-bans-stability-ai-employees</guid>
            <link>https://www.oschina.net/news/282835/midjourney-bans-stability-ai-employees</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2026 年，云计算市场规模预计突破万亿美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#060607">《云计算白皮书（2023 年）》由</span><span style="background-color:#ffffff; color:#060607">中国信息通信研究院发布，以下是主要内容：</span></p><ol><li><p style="margin-left:0; margin-right:0"><strong>全球云计算发展概述</strong>：</p><ul><li><strong>战略价值提升</strong>：美国、欧洲、亚洲等国家和地区纷纷出台云计算战略，以确保在全球经济、科技和军事等领域的领先地位。</li><li><strong>市场增长</strong>：2022 年全球云计算市场规模达到 4910 亿美元，预计到 2026 年将突破万亿美元。</li><li><strong>竞争升级</strong>：全球云计算巨头调整发展重心，聚焦热点区域和领域，竞争日益激烈。</li><li><strong>技术创新</strong>：云计算技术不断进步，如应用现代化、一云多芯、平台工程等，以满足用户多样性场景需求。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>中国云计算发展概述</strong>：</p><ul><li><strong>政策指引</strong>：国家政策推动云计算与实体经济深度融合，促进云计算应用创新。</li><li><strong>市场快速增长</strong>：2022 年中国云计算市场规模达到 4550 亿元人民币，增速 40.91%，预计 2025 年市场规模将超万亿元。</li><li><strong>技术革新</strong>：云计算技术持续更新，如云原生安全、系统稳定性等，助力产业数字化升级。</li><li><strong>行业应用</strong>：云计算在政务、金融、电信等行业应用成熟，而在工业、交通、医疗等行业处于成长期。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>云计算向数字世界操作系统转变</strong>：</p><ul><li><strong>数字应用与算力变革</strong>：云计算整合海量算力资源，加速数字应用的感知、判断和执行。</li><li><strong>管理方式革新</strong>：云计算定义了算力资源使用的新方式，如纳管、编排、部署等。</li><li><strong>创新孵化效用</strong>：云计算提供了统一的数字应用创新基座，推动应用从单点创新到体系化创新。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>云计算加速催生算力服务新范式</strong>：</p><ul><li><strong>架构变革</strong>：云计算支持以数据为中心的计算体系，推动算力服务架构的创新。</li><li><strong>功能创新</strong>：云计算推动算力服务在感知接入、路由转发和融合调度等方面的创新发展。</li><li><strong>模式重构</strong>：云计算重构算力服务的供需模式，从资源交易到结果交付，实现更高效的资源利用。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>总结与展望</strong>：</p><ul><li><strong>战略深化</strong>：全球主要国家将云计算视为提升国家综合实力的关键技术，未来将更加注重云计算的战略布局。</li><li><strong>实际赋能</strong>：中国云计算发展将更加关注实际赋能水平，提升云计算的兼容能力和 SaaS 服务生态。</li><li><strong>社会发展作用</strong>：云计算作为数字经济的技术底座，将对社会发展发挥更强的作用，特别是在算力服务和数字经济高质量发展方面。</li><li><strong>算力服务融合</strong>：云计算将与算力服务深度融合，推动数字经济乘数效应的放大。</li></ul></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">这份白皮书全面分析了云计算的全球趋势、中国市场特点、技术进步、行业应用以及未来发展方向，突出了云计算在推动数字化转型和经济发展中的核心作用。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 10:38:18 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282766</guid>
            <link>https://www.oschina.net/news/282766</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[像素数据加入 openKylin，携手打造图像智能分析产品解决方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，广州像素数据技术股份有限公司（以下简称「像素数据」）签署了 openKylin 社区 CLA(Contributor License Agreement 贡献者许可协议)，正式加入 openKylin 开源社区。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-e691cef8cdc3d6bcef1b3dffc17c61f5961.png" width="829" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>像素数据创立于 1998 年，是一家专注于将先进的人工智能技术与教育行业应用相融合，构建人像采集、处理、检测、验证、识别、监控完整的产品生态链的高新技术企业。经过二十几年的探索实践，像素数据形成了系统化的教育考试和公共安全解决方案及服务模式，围绕人脸识别、人像采集与检测、物体检测和视频分析等核心人工智能技术开发产品和提供服务。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>像素数据专注于智慧教育、智慧安防及图像采集三大板块业务市场，优势产品有身份验证系列产品、理化生实验操作考试系列产品和人像检测处理系列产品等。</span></p><p style="text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-910ca663dfc388599b63ac6eaa45cba540f.png" width="940" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>加入 openKylin 社区后，像素数据将积极运用自身在智慧教育、智慧安防以及图像采集领域的专业技术和资源积淀，推动社区内资源的互补与高效融合。并通过深入交流与紧密合作，共同发掘新技术、新应用与新模式的无限潜力，汇聚社区力量，在智慧教育、智慧安防及图像采集等领域形成强大合力，为行业的创新与发展贡献源源不断的智慧与动能，共同构建一个互利共赢、共同发展的生态圈。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 09:29:11 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282746</guid>
            <link>https://www.oschina.net/news/282746</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[经济日报：谨防人工智能「风控」成风险]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近年来，人工智能技术快速渗透各行各业，金融业也不例外。不少金融机构开始尝试将人工智能技术应用于风险防控领域，用科技创新来防范金融风险。</p><p>当前，我国在「人工智能+风控」领域进行了积极的尝试与探索，与国际金融业同行相比，具有一定的先发优势。在 2023 年 7 月的世界人工智能大会上，腾讯对外发布了金融风控大模型。同年 11 月，腾讯与中国信息通信研究院、中国科学技术大学、新加坡南洋理工大学、中原消费金融、微众银行等科研院校及金融机构联合制定了全球范围内首个金融风控领域的大模型国际标准。</p><p>人工智能技术会为金融风控带来什么？理论上，人工智能赋能风控，减少了人为失误和干扰，可以提升风险识别的效率和准确性。然而，考虑到人工智能技术是尚在发展的新事物，仍不成熟，在金融风控领域贸然推广可能带来新的风险。</p><p>最令人担忧的是数据泄露的风险。目前，许多金融机构会选择与具有人工智能技术的科技公司在风控领域展开合作，这些合作往往会涉及数据共享。人工智能大模型依靠大量的样本数据进行训练，数据的规模和质量对风控的准确性有着至关重要的影响。理论上，数据越丰富，大模型精准用户画像的能力越强，在信贷审批等方面识别风险的准确度就越高。然而，随着越来越多的数据被共享，隐私能否被有效保护就成了新的风险挑战。值得强调的是，金融数据不仅具备数据的一般特性，更包含了国民账户信息、企业资金流转等重要内容，这意味着金融数据一旦泄露，可能会带来比一般数据泄露更大的风险。</p><p>除了数据泄露外，法律风险同样不容忽视。从历史上看，法律法规的修订往往滞后于新技术的应用。目前，人工智能技术还存在因数据和算法失误生成虚假内容的可能，并在一定程度上造成用户歧视。一旦大模型生成不准确的金融风控报告，将很难分清是科技公司提供的技术不可靠，还是金融机构提供的数据不可信，这使得法律层面的责任难以被界定，容易出现金融机构和科技公司相互推诿扯皮的现象。在扯皮过程中，客户贷款审批等合理诉求就可能受到拖延，风险最终由客户买单。</p><p>中央金融工作会议提出，要全面加强金融监管，有效防范化解金融风险。针对人工智能技术在金融业应用可能带来的新风险，一方面，要完善法律法规，保障人对人工智能技术生成结果合理质疑的权利，确保人工智能技术受到责任追究机制和透明、公平、安全等原则的制约；另一方面，要有效管理金融数据信息，稳健、谨慎地推动人工智能技术应用，不断提高风控技术，对风险管理和预测模型改进优化，让技术向好向善，预防人工智能技术在金融领域应用带来的潜在风险。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 08:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282738</guid>
            <link>https://www.oschina.net/news/282738</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 推理框架软件 ONNX Runtime 正式支持龙架构]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，知名 AI 推理框架开源社区 ONNX Runtime 正式发布支持龙架构的版本 1.17.0。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-315cece2b949221ece5f43ff29b6d272deb.png" referrerpolicy="no-referrer"></p></blockquote><p>今后，用户可以直接使用 ONNX Runtime 开源社区发布的版本在龙芯平台完成 AI 推理类应用的开发和部署，标志着龙架构软件生态得到进一步完善。</p><p>ONNX Runtime（ORT）是近年来兴起的 AI 推理框架软件，被大量 AI 应用作为基础 AI 推理引擎。ORT 可支持 PyTorch、Tensorflow、TFLite 等多种格式的模型输入，以及 CPU、GPU、IoT、NPU、FPGA 等多样化算力后端。</p><p>在 ONNX Runtime 社区 1.17.0 版本的研制过程中，龙芯中科技术团队与社区保持紧密合作，期间向 ONNX Runtime 社区代码仓库提交了 7697 行代码，对矩阵乘法、卷积、转置等核心算子进行深度向量优化。</p><p>在社区支持下，龙架构优化代码通过了检视、测试验证等质量保证流程，ONNX Runtime 社区自 1.17.0 版本起正式实现对龙架构的原生支持。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 08:16:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282732</guid>
            <link>https://www.oschina.net/news/282732</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google 在 MySQL 中推进矢量搜索，在 LLM 支持方面超越 Oracle]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌已将向量搜索引入其 MySQL 数据库服务，这一步领先了 MySQL 的所属公司 Oracle，迄今为止，Oracle 尚未给 MySQL 添加任何大型语言模型（LLM）方面的功能。</p><p>谷歌云数据库副总裁安迪·古特曼斯 (Andi Gutmans) 表示，在过去 12 年里，谷歌在向量方面的创新速度相当快。目前，在多个 Google Cloud 数据库中提供向量搜索预览版，包括 Cloud SQL for MySQL、Memorystore for Redis 以及 Google 的分布式数据库管理和存储服务 Spanner。</p><p>向量是 LLM 的基本元素，自 2022 年 ChatGPT 推出以来，LLM 已成为大型科技公司、政府和媒体的关注焦点。LLM 依赖於单词或语言的其他组成部分，根据其与其他语言的统计相似性将其表示为向量嵌入。Google 支持 Word2Vec，这是一种 2013 年推出的自然语言处理技术，尽管它已被法学硕士采用的转换器架构所取代。</p><p>开源数据库服务公司 Percona 的技术传播者 Dave Stokes 表示，Oracle 工程部门近期没有计划向 MySQL 支持向量类的功能。</p><p>「可悲的是，Oracle 似乎将所有资源投入到 HeatWave 中，同时为社区版做了绝对最低限度的资源」，他说。「这将使得 MySQL 进一步落后于 PostgreSQL 和新的向量数据库等。社区版普遍缺乏新特性和功能，而将 JavaScript 和向量嵌入到商业版本中，这将使社区客户寻求其他替代方案，例如 Google 提供的产品」。</p><p>不过，谷歌并不是唯一一家将向量搜索添加到 MySQL 服务的供应商。PlanetScale 是基于 MySQL/Vitesse 的分布式事务系统，于去年 10 月宣布了这一新功能。</p><p>Redis 是一种流行的内存数据库，通常用作缓存和系统代理，也已经在发布的版本中支持向量搜索。</p><p>分布式文档数据库 Couchbase 在 DBaaS Capella 和 Couchbase Enterprise Edition 中引入了向量搜索作为新功能。Couchbase 产品管理和业务运营高级副总裁 Scott Anderson 表示，向平台添加向量搜索是「使我们的客户能够构建新一波自适应应用程序」的下一步。</p><p>去年，Oracle 数据库、Cassandra、MongoDB、PostgreSQL 和 SingleStore 在其数据库系统中增加了对向量搜索的支持，而像 Pinecone 这样的专业向量数据库也如雨后春笋般涌现，以支持计算趋势。</p><p>Forrester Research 副总裁兼首席分析师 Noel Yuhanna 表示，向量搜索现在或多或少已经成为任何专业企业数据库的标准。</p><p>「那些没有它的企业可能会看到对其增长的影响。根据我们的研究，大约 35% 的企业正在考虑向量数据库，预计在未来 18 个月内将增长到 50%」，他说。</p><p>他表示，向量搜索对于生成式人工智能应用程序变得至关重要，可以帮助寻找类似的数据、图像和文档，以及客户智能、欺诈检测、聊天机器人和内容个性化等新兴应用程序。</p><p>Yuhanna 说，虽然专业向量数据库有其优势，但集成数据库为组织提供了更多背景和更丰富的数据体验。「没有哪家供应商能脱颖而出，因为向量功能仍在不断发展，而且许多供应商尚未展现出高端规模。」</p><p>然而，目前只有约 22% 的组织正在为其数据库考虑 LLM/GenAI 战略，尽管 Forrester 预计这一数字在未来两到三年内会翻一番。Yuhanna 表示：「我们看到的大部分需求是希望利用向量进行新部署的新 GenAI 应用程序；要使现有数据库转向向量，我们至少需要几年时间。」</p><p>谷歌还试图让自己的 GenAI 模型更接近其分析环境。谷歌表示，它正在通过 Vertex AI 为 BigQuery（其数据仓库系统）的用户提供 Gemini。与 AI 和 ML 平台的新集成旨在帮助数据工程师和分析师使用 Gemini 模型为其 BigQuery 数据提供多模式和高级推理功能。</p><p>Yuhanna 表示，将 Vertex AI、BigQuery 和 BigLake 更紧密地结合在一起不仅可以帮助组织避免数据移动，还可以帮助提供见解、改善数据治理和安全性、删除冗余数据，并通过最大限度地减少管理要求来降低成本。</p><p>他表示，企业将非结构化数据与结构化 BI 风格数据合并为所谓的 Lakehouse 概念是趋势的一部分，目前约有四分之一的企业采用这种概念，以降低成本并运行 BI、数据科学、AI/ML、运营单一平台上的见解和 SQL 分析。</p><p>更多技术文章，请访问：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.actionsky.com%2F" target="_blank">https://opensource.actionsky.com/</a></p><h2>关于 SQLE</h2><p>SQLE 是一款全方位的 SQL 质量管理平台，覆盖开发至生产环境的 SQL 审核和管理。支持主流的开源、商业、国产数据库，为开发和运维提供流程自动化能力，提升上线效率，提高数据质量。</p><h2>SQLE 获取</h2><table><thead><tr><th>类型</th><th>地址</th></tr></thead><tbody><tr><td>版本库</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Factiontech%2Fsqle" target="_blank">https://github.com/actiontech/sqle</a></td></tr><tr><td>文档</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Factiontech.github.io%2Fsqle-docs%2F" target="_blank">https://actiontech.github.io/sqle-docs/</a></td></tr><tr><td>发布信息</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Factiontech%2Fsqle%2Freleases" target="_blank">https://github.com/actiontech/sqle/releases</a></td></tr><tr><td>数据审核插件开发文档</td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Factiontech.github.io%2Fsqle-docs%2Fdocs%2Fdev-manual%2Fplugins%2Fhowtouse" target="_blank">https://actiontech.github.io/sqle-docs/docs/dev-manual/plugins/howtouse</a></td></tr></tbody></table></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 08:10:02 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/actiontechoss/blog/11046991</guid>
            <link>https://my.oschina.net/actiontechoss/blog/11046991</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 开源 Transformer Debugger]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">OpenAI 超级对齐负责人 Jan Leike <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fjanleike%2Fstatus%2F1767347608065106387" target="_blank">宣布</a>，推出了一个该公司内部使用的分析 Transformer 内部结构的工具 -- Transformer Debugger (TDB) 。它结合了自动可解释性和稀疏自动编码器，无需编写代码即可快速探索模型。</span></p><p><img height="477" src="https://static.oschina.net/uploads/space/2024/0312/151543_JCIR_4252687.jpg" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">目前，该项目<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Ftransformer-debugger" target="_blank">仓库</a>已在 MIT 协议下开放。Jan Leike 表示，TDB 目前仍然是一个处于早期阶段的研究工具，他们希望通过开源的方式让更多人使用，并在此基础上加以改进。</span></p><p><span style="color:#000000">根据介绍，Transformer Debugger 是 OpenAI 的 Superalignment 团队开发的一款工具，旨在支持对小语言模型的特定行为进行研究。</span></p><p><span style="color:#000000">TDB 可以在编写代码之前进行快速探索，能够干预前向传递并查看它对特定行为的影响。它可以用来回答诸如"为什么模型会输出 token A 而不是 token B"或"为什么 attention head H 会关注 token T"之类的问题。它通过识别对行为有贡献的特定组件（neurons、attention heads、autoencoder latents），显示自动生成的关于导致这些组件激活最强烈的原因的解释，以及追踪组件之间的连接以帮助发现联系。</span></p><p><span style="color:#000000">本次开源发布的内容包括：</span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Ftransformer-debugger%2Fblob%2Fmain%2Fneuron_viewer%2FREADME.md" target="_blank">Neuron viewer</a>：一个 React 应用程序，托管 TDB 以及包含有关各个模型组件（<span style="color:#1f2328">MLP&nbsp;</span>neurons、attention heads and autoencoder latents for both）信息的页面。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Ftransformer-debugger%2Fblob%2Fmain%2Fneuron_explainer%2Factivation_server%2FREADME.md" target="_blank">Activation server</a>：对主题模型进行推理，为 TDB 提供数据的后端服务器。它还从公共 Azure 存储桶读取数据并提供数据。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Ftransformer-debugger%2Fblob%2Fmain%2Fneuron_explainer%2Fmodels%2FREADME.md" target="_blank">Models</a>：一个用于 GPT-2 模型及其自动编码器的简单推理库，带有用于<span style="color:#333333">捕获激活的 hook</span>。</li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Ftransformer-debugger%2Fblob%2Fmain%2Fdatasets.md" target="_blank">Collated activation datasets</a>：MLP neurons、attention heads 和 autoencoder latents 的顶级激活数据集示例。</li></ul><p>此外， OpenAI 方面还放出了几个概述 TDB 能力的视频，<span style="color:#333333">并展示了如何使用它来研究论文「</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2211.00593" target="_blank">Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small</a><span style="color:#333333">」。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 07:10:04 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282711/openai-transformer-debugger</guid>
            <link>https://www.oschina.net/news/282711/openai-transformer-debugger</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[deepin Meetup·成都站全程回顾，干货满满，感动多多 | 附 PPT 下载]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000">内容来源：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdeepin-meetup-2024-chengdu%2F" target="_blank">deepin 社区</a></p><p style="color:#000000; text-align:center"><img alt="" height="383" src="https://storage.deepin.org/thread/202403110832526053_deepinmeetup%E6%B4%BB%E5%8A%A8%E5%9B%9E%E9%A1%BE900x383.jpg" width="900" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">2024 年 3 月 9 日，<strong>「deepin Meetup · 成都站」</strong>顺利举办！此次活动，我们聚集了业界专家与优秀的开发者，吸引了来自成都及周边地区 50 余名用户的积极参与。大家共同探讨 deepin-IDE 成长历程、Flutter 跨平台应用程序开发等热门话题，同时，更有社区资深贡献者从社区参与的角度与大家分享回顾了 deepin 发展的三个历史时期。</p><p style="color:#000000; text-align:start">接下来，就让我们一起回到精彩现场，看看此次都有哪些观点洞察和技术干货叭！</p><p style="color:#000000; text-align:start">本次活动依然由 deepin（深度）社区主办，感谢 freeCodeCamp 成都社区提供支持。</p><p style="color:#000000; text-align:center"><img alt="" height="880" src="https://storage.deepin.org/thread/202403110838247420_0.png" width="1180" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:center">&nbsp;</p><h2><strong>deepin-IDE 的成长脚步与未来道路</strong></h2><p style="color:#000000; text-align:center"><img alt="" height="879" src="https://storage.deepin.org/thread/202403110838378676_1.png" width="1179" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:center"><span style="color:#757575">卢桢（deepin-mozart） / 中国发明协会成员，系统架构师</span></p><p style="color:#000000; text-align:start">2023 年 9 月，deepin-IDE 横空出世，受到了大家的广泛关注，来自 deepin-IDE 研发团队的卢桢为大家详细讲述了 deepin-IDE 从诞生以来打怪升级的故事，以及背后所用到的调试、迁移等核心技术，并岁 deepin-IDE 的智能插件所提供的自动编码、代码注释及翻译等 AI 能力进行了现场演示。</p><p style="color:#000000; text-align:start">值得一提的是，deepin-IDE 中的智能插件现已实现了智能问答、代码翻译、添加注释、代码生成等功能。目前，deepin-IDE 已经上架 deepin 应用商店，欢迎大家可以安装体验。</p><p style="color:#000000; text-align:start"><em>仓库地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-unioncode" target="_blank">https://github.com/linuxdeepin/deepin-unioncode</a></em></p><p style="color:#000000; text-align:start"><em>开发者文档：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fusdn.uniontech.com%2F%23document" target="_blank">https://usdn.uniontech.com/#document</a></em></p><p style="color:#000000; text-align:start">&nbsp;</p><h2><strong>Flutter：桌面应用程序开发的新选择</strong></h2><div><img alt="" height="876" src="https://storage.deepin.org/thread/202403110839288916_2.png" width="1182" referrerpolicy="no-referrer"></div><p style="color:#000000; text-align:center"><span style="color:#757575">徐宝林 / Google Flutter 开源项目 Member、OPPO 软件工程师</span></p><p style="color:#000000; text-align:start">说起跨平台桌面应用开发的主流框架，Flutter 绝对是一个不可忽视的选择，作为 Google 开源的跨平台应用开发框架，Flutter 具有高性能、可移植性强、开发时间短、成本低、UI 控件丰富等优势。</p><p style="color:#000000; text-align:start">据 Google Flutter 开源项目 Member 徐宝林介绍，正是因为 Flutter 具有更低的开发成本和更短的开发周期，所以 Flutter 非常适合做原型设计开发、初创企业快速开发，开发者们可以快速上手并构建漂亮且高性能的跨平台移动应用。</p><p style="color:#000000; text-align:start">&nbsp;</p><h2><strong>我与 deepin 相伴 17 年</strong></h2><div><img alt="" height="888" src="https://storage.deepin.org/thread/202403110839399773_3.png" width="1184" referrerpolicy="no-referrer"></div><p style="color:#000000; text-align:center"><span style="color:#757575">水歌 / Web 全栈开发者、freeCodeCamp 成都社区主理人</span></p><p style="color:#000000; text-align:start">从社区参与者的角度来看，deepin 的发展经历了许多独特的变化。作为 deepin 社区的资深贡献者之一，水歌结合自己与 deepin 一同走过的 17 年岁月，带领大家一起回顾了 deepin 社区是如何从一个「草根社区」逐步发展成如今完善繁荣的模样，并分享了自己从「封装系统盘、折腾 Linux 发行版无数」到「拥抱开源生态、深入开源社区」的成长故事。</p><p style="color:#000000; text-align:center"><img alt="" height="874" src="https://storage.deepin.org/thread/202403110839481885_4.png" width="1182" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">除了主题演讲之外，现场 Linux 爱好者的闪电演讲也赢得了满堂喝彩。云原生开发工程师@chaunceyjiang 与大家分析了当前集群管理现状与痛点，并介绍了多集群生命周期管理工具 Kubean，及其所带来新的解决方案。</p><h2>下一站，西安</h2><p style="color:#000000; text-align:start">本次 deepin Meetup · 成都站活动圆满结束！感谢大家不辞远路来到现场参加活动，甚至有的同学从外地专程赶来相聚，同时感谢所有参与分享和讨论的 deepiner！</p><p style="color:#000000; text-align:start">deepin Meetup 的创办希望帮助社区当中的每一个人都可以充分的交流经验和心得，所<strong>以我们也将本次活动的演示文稿开放出来，供大家查看，大家<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdeepin-meetup-2024-chengdu%2F" target="_blank"><span style="color:#0e52d4">可点击【此处】跳转下载</span>。</a></strong></p><p style="color:#000000; text-align:start">那么，让我们准备开启下一次的 deepin Meetup 吧！月底，西安见！</p><p style="color:#000000; text-align:start">如果你感兴趣做分享，或是有更多的建议给到我们，可以扫描下方二维码，申报议题或提交建议。无论是标准的主题演讲 ，还是 5 分钟简短的闪电演讲，都期待你的报名～</p><p style="color:#000000; text-align:center"><img alt="" height="150" src="https://storage.deepin.org/thread/202403110844536352_%E8%AE%AE%E9%A2%98%E5%BE%81%E9%9B%86&amp;%E5%BB%BA%E8%AE%AE%E5%8F%8D%E9%A6%88.jpg" width="150" referrerpolicy="no-referrer"></p><hr><p><strong>内容来源：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdeepin-meetup-2024-chengdu%2F" target="_blank">deepin 社区</a></strong></strong></p><p><strong>了解 deepin ：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Findex%2Fzh" target="_blank">deepin - 基于 Linux 的开源国产操作系统</a></strong></strong></p><p><strong>了解 deepin Meetup：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdeepin-meetup%2F" target="_blank">deepin Meetup – 深度科技社区</a></strong></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 06:11:54 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282699</guid>
            <link>https://www.oschina.net/news/282699</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[30k Stars、代码每天更新 —— RSSHub 作者却称项目正在面临崩溃]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>RSSHub 是一个开源、简单易用、易于扩展的 RSS 生成器，可以给任何奇奇怪怪的内容生成 RSS 订阅源。RSSHub 借助于开源社区的力量快速发展中，目前已适配数百家网站的上千项内容。</p><p><img src="https://oscimg.oschina.net/oscnet/up-07bcaa58b6beb554c005c8bf4b60d220b89.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FDIYgod%2FRSSHub" target="_blank">https://github.com/DIYgod/RSSHub</a></u></em></p><p>RSSHub 作者今日发帖称项目正在面临崩溃：</p><blockquote><p>我有一个维护了六年的开源项目 —— RSSHub ，它正在面临崩溃</p><p>表面上，它有接近 30k Stars 、900 多 Contributors 、每月 3 亿多次请求和数不清的用户、每月几十刀的赞助、有源源不断的 issue 和 pr 、代码几乎每天更新，非常健康和充满活力，但在不可见的地方，持续数年高昂的维护时间成本、每月一千多刀的服务器费用、每天重复繁琐且逐渐积累的维护工作，都让它在崩溃的边缘反复横跳</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiygod.cc%2F6-year-of-rsshub" target="_blank">https://diygod.cc/6-year-of-rsshub</a></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 12 Mar 2024 04:26:13 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282685/6-year-of-rsshub</guid>
            <link>https://www.oschina.net/news/282685/6-year-of-rsshub</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
