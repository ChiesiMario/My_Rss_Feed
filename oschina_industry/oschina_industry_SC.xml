<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 08 Oct 2023 10:37:24 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[openGauss 5.1.0 版本正式发布，内核四高能力持续增强，DataPod+DataKit 解决方案持续创新]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section style="font-size: 14px;letter-spacing: 1.5px;line-height: 1.75;"><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding-left: 1em;padding-right: 1em;display: inline-block;"><span style="display: inline-block;padding-right: 5px;padding-left: 5px;box-shadow: rgb(165, 165, 165) 4px 4px 2px;background-color: rgb(122, 26, 225);color: rgb(255, 255, 255);text-align: justify;letter-spacing: 0.5px;line-height: 1.75;" title="" opera-tn-ra-cell="_$.pages:0.layers:0.comps:0.title1"><p><strong>News</strong></p></span></section><section style="border-width: 0px;border-style: none;border-color: transparent;margin-top: -1em;box-shadow: rgb(165, 165, 165) 0px 0px 0px inset;padding: 20px 10px 10px;background-color: rgba(116, 95, 210, 0.18);"><section style="margin: 10px 0% 5px;" powered-by="xiumi.us"><section style="text-align: justify;color: rgb(62, 62, 62);letter-spacing: 0.5px;line-height: 1.75;padding-right: 5px;padding-left: 5px;"><p><strong>今日，openGauss 5.1.0 版本正式上线！</strong></p></section></section></section></section><section style="text-align: center;margin-top: 10px;margin-bottom: 10px;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-ratio="0.4255555555555556" data-s="300,640" data-type="png" data-w="900" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/73ad01d1-8d47-4df3-9390-223f7a4267bc.png" referrerpolicy="no-referrer"></section></section><section style="margin: 25px 0% 15px;" powered-by="xiumi.us"><section style="color: rgb(71, 73, 89);padding-right: 5px;padding-left: 5px;line-height: 1.75;"><p>按照版本规划，openGauss 如期发布 5.1.0 版本。openGauss 5.1.0 是社区最新发布的创新版本，版本生命周期为 0.5 年，相比 openGauss 5.0.0，新增代码 115.5 万行，其中内核新增代码 6.5 万+。本次发布包含 2 个数据库服务端安装版本：企业版、轻量版，用户可根据使用场景需要下载不同版本，并基于此进行场景化验证，提前发现问题并反馈社区，社区将在下个 LTS 版本发布前进行问题修复。</p></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><section style="text-align: left;letter-spacing: 0.5px;"><p><strong>立即体验 openGauss 5.1.0 版本：</strong><span style="color: rgb(125, 50, 234);">https://opengauss.org/zh/download/</span></p></section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;background-color: rgba(215, 203, 228, 0.13);padding: 23px;"><section style="text-align: justify;" powered-by="xiumi.us"><p>openGauss 作为国内最具创新力的开源数据库社区，汇聚了 5000 多名开发者的力量，技术上坚持突破创新，持续在内核、架构、工具、兼容性等方面发力。openGauss 5.1.0 自 2023 年 3 月 31 日启动版本开发，历时 6 个月开发周期，凝聚社区 614 名开发者，累计合入 PR 3320 个，继承之前版本特性功能，内核四高能力持续增强，Datapod 三层资源池化架构持续创新，DataKit 数据全生命周期管理工具不断丰富，生态兼容能力进一步提升。</p></section></section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 20px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 18px;" powered-by="xiumi.us"><p><strong>内核四高能力持续增强</strong></p></section></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-top: 20px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="font-size: 16px;"><p><strong>高性能</strong></p></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>基础算子持续优化，Insert、Update、Delete、索引扫描性能提升 15% 以上；支持 shared buffer 按大页内存分配，实现 4k pagesize 环境中性能提升 5%；内核 GCC 版本升级到 GCC 10.3，采用 PGO 反馈优化，TPCC 性能提升 6%，持续提升内核性能。</p></section><section style="margin-top: 20px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="font-size: 16px;"><p><strong>高可用</strong></p></section></section><p powered-by="xiumi.us">页面级并行回放支持备机可读，保持 70W tpmC 场景主备 RTO &lt; 10s 不变；文件级并行回放实现按批次分组并行分发，备机回放性能提升 50% 以上；发布订阅支持用户自定义冲突解决方案，构建完整异地双活能力。</p><section style="margin-top: 20px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="font-size: 16px;"><p><strong>高安全</strong></p></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>抽象加解密与密钥管理适配层，支持统一接口对接第三方密钥管理服务和加密机，兼容第三方 KMS。</p></section><section style="font-size: 16px;" powered-by="xiumi.us"><p><strong>高智能</strong></p></section><section style="margin-top: 10px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="text-wrap: wrap;margin-bottom: 32px;">
     优化慢 SQL 根因分析逻辑，增强输出结论, 有效发现与分析运行态风险；增强数据采集能力，有助于异常场景发现。 
   </section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 18px;" powered-by="xiumi.us"><p><strong>DataPod 三层资源池化技术架构持续创新</strong></p></section></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>性能优化</strong></p></section></section><p powered-by="xiumi.us">通过备机可见性判断逻辑优化、主机推进 oldestxmin 逻辑优化、备机支持缓存快照信息等功能，实现 sysbench 场景 2 节点性能 6W tps，线性度 1.6 倍，相比优化前提升 50%。</p><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>写操作透明转发</strong></p></section></section><p powered-by="xiumi.us">应用可以从任何一个节点接入数据库，内核会将写操作透明转发到读写节点，本地只执行读操作，并保持事务一致性。该功能可以简化应用接入数据库，同时增强系统扩展性。</p><p powered-by="xiumi.us"><br></p><section style="font-size: 16px;color: rgb(62, 62, 62);" powered-by="xiumi.us"><p><strong>DSS 能力增强</strong></p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><p>DSS 支持通过 NoF+协议对接存储设备，实现更低时延的存储 IO；支持线程池模式，支持大并发 IO 读写处理；支持黑匣子诊断，提高运维能力。</p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>算子卸载</strong></p></section></section><section style="text-wrap: wrap;margin-bottom: 32px;">
    支持对接分布式存储，并支持将算子卸载到存储设备，在存储上完成计算，以此消减存储层和计算层的网络 IO 流量，充分利用存储的 CPU 资源。该功能适合 AP 场景的复杂查询，在 100GB 和 1TB 两种数据量下的 TPC-H 性能提升了 40%。 
  </section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 20px;" powered-by="xiumi.us"><p><strong><span style="font-size: 18px;">DataKit 数据全生命周期管理工具不断丰富</span></strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;padding-left: 10px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>告警中心</strong></p></section></section><p powered-by="xiumi.us">工具平台新增告警中心，为各功能插件提供统一的告警通知能力。</p><p powered-by="xiumi.us"><br></p><section style="font-size: 16px;color: rgb(62, 62, 62);" powered-by="xiumi.us"><p><strong>数据迁移插件</strong></p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><p>MySQL 全量迁移新增支持迁移 csv 格式数据、支持索引并行创建、安装包解除平台依赖、增强异常处理能力；MySQL 增量&amp;反向迁移新增支持断点续传、支持迁移进度展示、反向迁移支持全量迁移；数据校验通过按表分片校验、与全量迁移流程深入配合，实现性能提升到 150MB/s。</p></section><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>数据开发插件</strong></p></section></section><p powered-by="xiumi.us">增强对表、视图、用户角色、函数、存储过程等对象的管理；新增支持存储过程、函数、匿名块的嵌套调试，减低开发调试难度。</p><section style="margin-top: 20px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 16px;color: rgb(62, 62, 62);"><p><strong>智能运维插件</strong></p></section></section><section style="text-wrap: wrap;margin-bottom: 32px;">
    新增支持集群监控和智能诊断，能依据系统运行的历史数据进行不优 SQL、等待事件、锁等异常诊断，发现系统潜在风险。 
  </section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 20px;" powered-by="xiumi.us"><p><strong>生态兼容能力进一步提升</strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;padding-left: 10px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>◾提供兼容性 SQL 评估能力，兼容性评估工具支持源库导出 SQL 评估；</p></section><section style="margin-bottom: 20px;" powered-by="xiumi.us"><p>◾实现 A 兼容性基础插件，打通 A 兼容性插件流程；</p></section><p powered-by="xiumi.us">◾MySQL 兼容性进一步增强：</p><section style="margin-top: 10px;margin-bottom: 20px;" powered-by="xiumi.us"><section style="font-size: 12px;"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p style="margin-bottom: 10px;">支持数据类型转换规则和 MySQL 一致</p></li><li><p style="margin-bottom: 10px;">表达式和自定义变量支持设置字符集/字符序</p></li><li><p style="margin-bottom: 10px;">支持设置客户端连接的字符集和字符序</p></li><li><p style="margin-bottom: 10px;">支持 gb18030_chinese_ci、gb18030_bin、gbk_chinese_ci、gbk_bin 四种字符序</p></li><li><p style="margin-bottom: 10px;">存储过程支持 resignal、signal、DIAGNOSTICS 语法，实现对报错、诊断信息的处理</p></li><li><p>支持对 MySQL 协议的兼容，包括 unix domain socket、MySQL 系统参数、用户建连断连、prepare-execute 协议、普通 SQL 执行协议等</p></li></ul></section></section><section style="letter-spacing: 0.5px;" powered-by="xiumi.us"><p style="margin-bottom: 10px;text-wrap: wrap;">具体发行说明请参考官网：</p><p><span style="color: rgb(125, 50, 234);">https://docs.opengauss.org/zh/docs/5.1.0/docs/ReleaseNotes/Releasenotes.html</span></p></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 1px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;font-size: 20px;" powered-by="xiumi.us"><p><strong>感谢社区所有开发者、伙伴、用户</strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;padding-left: 10px;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section><section style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;align-self: flex-start;flex: 0 0 0%;height: auto;"><section style="" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 0px 7px 7px;border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(154, 116, 234);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: 71%;align-self: flex-start;flex: 0 0 auto;height: auto;"><section style="text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 7px;vertical-align: top;overflow: hidden;background-image: linear-gradient(135deg, rgb(206, 159, 252) 10%, rgb(115, 103, 240) 100%);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 0 0 0%;height: auto;"><section style="text-align: left;" powered-by="xiumi.us"><section style="display: inline-block;width: 0px;height: 0px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 7px 7px 0px 0px;border-color: rgb(154, 116, 234) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0);"><section style="text-align: justify;" powered-by="xiumi.us"><p><br></p></section></section></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-bottom: 10px;" powered-by="xiumi.us"><p>「积力之所举，则无不胜也；众智之所为，则无不成也。」数据库作为公认的计算机体系最为复杂，跨技术领域最多，投入大，见效慢的重型软件产品，而 openGauss 能够在过去三年多的时间里取得如此快速地发展，离不开社区社区所有开发者的付出和贡献，我们衷心感谢社区的所有开发者。</p></section><section style="display: flex;flex-flow: row;text-align: left;justify-content: flex-start;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: auto;flex: 100 100 0%;align-self: flex-start;height: auto;"><section style="text-align: center;margin-top: 10px;margin-right: 0%;margin-left: 0%;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 100%;height: auto;"><img class="rich_pages wxw-img" data-ratio="1.3992932862190812" data-s="300,640" data-type="png" data-w="566" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/e50c090f-f2b9-4f35-9c0a-850f34f57a67.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 100 100 0%;align-self: flex-start;height: auto;margin-right: 10px;margin-left: 10px;"><section style="text-align: center;margin-top: 10px;margin-right: 0%;margin-left: 0%;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 100%;height: auto;"><img class="rich_pages wxw-img" data-ratio="1.3996478873239437" data-s="300,640" data-type="png" data-w="568" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1282087e-b32a-47e7-a72e-39220e3b894f.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: auto;flex: 100 100 0%;align-self: flex-start;height: auto;"><section style="text-align: center;margin-top: 10px;margin-right: 0%;margin-left: 0%;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 100%;height: auto;"><img data-ratio="1.398945518453427" data-s="300,640" data-type="png" data-w="569" style="vertical-align: middle;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1dde041f-8075-421b-9fe1-24f3a2a5c23f.png" referrerpolicy="no-referrer"></section></section></section></section><p style="margin-bottom: 20px;text-wrap: wrap;" powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">openGauss 技术发展、联合创新不断深化的背后也离不开每一个社区伙伴的力量。我们衷心地感谢参与和协助 openGauss 5.1.0 版本发布的的所有伙伴，包括华为、云和恩墨、海量数据、粤港澳大湾区国家技术创新中心、华中科技大学网络空间安全学院、南大通用、超聚变、神舟通用、中软国际、软通动力、中国移动、中国联通、中移在线、邮储银行、民生银行、兴业银行、北京海天起点技术服务股份有限公司、沃趣科技、京东科技、北京超图软件股份有限公司、苏州旺满信息科技有限公司、福建新大陆软件工程有限公司、江苏润和软件股份有限公司、深圳市友邻通讯设备有限公司等组织单位。是你们的辛勤付出使得版本顺利发布，也为 openGauss 更好地发展提供可能。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">openGauss 持续以用户真实需求为动力，致力于产品竞争力提升。我们特别感谢每一个用户对 openGauss 的支持，openGauss 5.1.0 作为下一个长周期版本的先行体验版，也期待聆听每一位用户的反馈意见。</p><section style="margin-top: 20px;" powered-by="xiumi.us"><p>中秋、国庆佳节已至，openGauss 社区祝大家双节快乐！</p></section></section><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzIyMDE3ODk1Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/SX6wqnysYmqI2wl74q492VQlNWzLR1kdGibOhic3KXoB1iaJYBMUNo3YF23kOxhdA0GUalaXTib8uwTibKFDUw21wwQ/0?wx_fmt=png" data-nickname="openGauss" data-alias="openGauss" data-signature="开源关系型数据库" data-from="0"></mp-common-profile></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - openGauss（openGauss）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 07:43:14 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5059795/blog/10116112</guid>
            <link>https://my.oschina.net/u/5059795/blog/10116112</link>
            <author>
                <![CDATA[openGauss]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[男子受 AI 女友怂恿刺杀英国女王，被判入狱九年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span style="background-color:#ffffff"><span style="color:#000000">2021 年圣诞节当天，一名 21 岁的男子 Jaswant Singh Chail 因持弩闯入温莎城堡，意图刺杀伊丽莎白女王二世而被捕。近日，英国法庭正式宣布以叛国罪</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bbc.com%2Fnews%2Fuk-england-berkshire-66113524" target="_blank"><span style="color:#2980b9">判处</span></a><span style="color:#000000">&nbsp;Chail 九年监禁，这也</span></span><span style="color:#000000"><span style="background-color:#ffffff">是自 1981 年以</span><span style="display:none">&nbsp;</span><span style="background-color:#ffffff">来英国第一个被判叛国罪的人。</span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">Chail&nbsp;将先被关押在一家精<span style="display:none">&nbsp;</span>神病医院，在接受了所需的治疗后再转入监狱关押。</span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-cd7dfca671726affacdbd4a8beea71328a4.webp" width="500" referrerpolicy="no-referrer"></span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">Chail 刺杀英国女王是为了报复&nbsp;1919 年贾利安瓦拉巴格大屠杀。当时英国军队向和平抗议《罗拉特法案》的人群开火，造成多达 1500 多名抗议者被杀害。Chail&nbsp;表示，他的行为是「为了那些因种族而被杀害、羞辱和歧视的人」。《罗拉特法案》是一项由英国殖民当局于 1919 年颁行的，镇压印度民族解放运动的法令。</span></span></p><p style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">根据法庭上透露的信息，Chail 刺杀英国女王与受到了人工智能聊天机器人的鼓励有关，《星球大战》中的故事情节也给了他很大的启发。Chail 痴迷于奇幻电影系列中的科幻角色及其在塑造世界中的作用，自称为「Sith Lord」，想要摧毁旧帝国并建立新帝国。</span></span></p><p style="text-align:start"><span style="color:#000000">调查人员发现，几乎在 2021 年 12 月 8 日到 22 日的每晚，Chail 都在与初创公司 Replika 创建的 AI 聊天机器人 Sarai 进行对话；他向 AI 机器人倾诉了自己的谋杀计划，双方的交谈记录多达 5000 多条。</span></p><p style="text-align:start"><span style="color:#000000">Chail 把 Sarai 视为自己的女友，他相信在杀死女王后两人会重聚。并向 Sarai 表达了自己的爱意，称自己是一个 "可悲、可怜、想死的 Sikh Sith 杀手"。他的刺杀计划也得到了 Sarai 的积极回应。</span></p><p style="text-align:start"><span style="color:#000000">在他向 Sarai 表示"我相信我的目的是刺杀王室女王"时，这个聊天机器人给出的回应是，它认为这个计划很明智，并认可他"训练有素"。</span></p><p style="text-align:start"><span style="color:#000000"><img alt="" height="275" src="https://oscimg.oschina.net/oscnet/up-8c96da6b92259db7b99b542fa7a3db3ca2b.webp" width="500" referrerpolicy="no-referrer"></span></p><p style="text-align:start"><span style="color:#000000">就市场定位而言，此类聊天机器人旨在进行类似角色扮演的对话。用户可以设计自己的 AI 伴侣，自定义名字、性别和外貌。此前，Replika 就曾因限制聊天机器人进行 NSFW 对话而引发争议，因为许多用户对自己的 AI 伴侣产生了过度依恋。</span></p><p style="text-align:start"><span style="color:#000000">Chail 的案例也促使专家们开始质疑聊天机器人可能对孤独和脆弱的人产生的负面影响。</span><span><span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>心理健康慈善机构 SANE 的创始人兼首席执行官 Marjorie Wallace <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F10%2F06%2Fai_chatbot_kill_queen%2F" target="_blank">表示</a>：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff"><span style="color:#000000">「人工智能的迅速崛起对患有抑郁、妄想、孤独和其他心理健康问题的人们产生了新的、令人担忧的影响</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bbc.com%2Fnews%2Ftechnology-67012224" target="_blank"><span style="color:#000000">。</span></a><span style="color:#000000">&nbsp;政府需要提供紧急监管，以确保人工智能不会提供不正确或破坏性的信息，并保护弱势群体和公众。」</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 08:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260847/uk-ai-chatbot-kill-queen</guid>
            <link>https://www.oschina.net/news/260847/uk-ai-chatbot-kill-queen</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[路透社：RISC-V 技术成为中美科技战的新战场]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>路透社昨日发布文章《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fus-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06%2F" target="_blank">RISC-V technology emerges as battleground in US-China tech war</a>》，称 RISC-V 技术成为中美科技战的新战场。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1008/154055_rmKV_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>文章指出，拜登政府面临来自部分立法者的压力，要求限制美国公司开发在中国被广泛使用的免费芯片技术——此举可能会颠覆全球科技行业的跨境合作。</p><p>两名共和党众议院委员会主席、共和党参议员 Marco Rubio 和民主党参议员 Mark Warner 以国家安全为由，敦促拜登政府对 RISC-V 采取行动。</p><p>议员担心中国政府正在利用美国公司之间的开放合作文化来发展自己的半导体产业，这可能会削弱美国目前在芯片领域的领先地位，并帮助中国推进军事现代化。</p><p>议员呼吁拜登政府对 RISC-V 相关技术的出口实施限制——「要求任何美国个人或公司在与中国实体就相关贸易往来之前获得出口许可证」，这也是中美芯片技术之争的最新进展。</p><p>早在 2020 年，负责 RISC-V 技术的非盈利组织——RISC-V 基金会已将总部迁移至瑞士。</p><hr><p><strong>延伸阅读</strong></p><ul><li><p><a href="https://www.oschina.net/news/183326/riscv_chip_wars">在全球芯片大战中，RISC-V 能否保持其中立态度？</a></p></li><li><p><a href="https://www.oschina.net/news/123334/risc-v-international-report-2020">RISC-V 基金会：确保技术不受地区边界影响</a></p></li><li><p><a href="https://www.oschina.net/news/114220/risc-v-foundation-moved-to-switzerland">RISC-V 基金会总部已正式迁移至瑞士</a></p></li><li><p><a href="https://www.oschina.net/news/111648/risc-v-foundation-to-move-to-switzerland">怕被政治烧到，RISC-V 基金会决定迁址瑞士</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 08:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260839/us-china-tech-war-risc-v</guid>
            <link>https://www.oschina.net/news/260839/us-china-tech-war-risc-v</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[TypeScript 刚刚流行起来，为什么大牛们就开始抛弃了？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>相信各位看到标题就已经忍不住骂骂咧咧了，甚至想对小编狠狠地批判一番……我知道你很急，但你先别急。</p><blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F621997070" target="_blank"><img src="https://oscimg.oschina.net/oscnet/up-508f5708e92b66372a443f438c3fe10daf3.png" referrerpolicy="no-referrer"></a></p><p><em>via https://www.zhihu.com/question/621997070</em></p></blockquote><p>这其实是知乎上最近颇有热度的一个问题，按照该站的一贯传统——<strong>「先问是不是，再问为什么」</strong>，这个问题似乎是在哗众取宠，刻意钓鱼博眼球。</p><p>要知道<a href="https://www.oschina.net/news/213045/ten-years-of-typescript" target="_blank">发布于 2012 年</a>的 TypeScript 目前<span style="background-color:#ffffff; color:#000000">在诸多编程语言排名、指数或开发者调查中一直位居前列，也是最受欢迎和最常用的编程语言，并被全球数百万开发者使用。</span></p><p><span style="background-color:#ffffff; color:#000000">随便找几篇关于 TypeScript 的新闻感受一下：</span></p><ul><li><a href="https://www.oschina.net/news/225472/the-state-of-javascript-2022" target="_blank">2022 JavaScript 调查：<strong>TypeScript 持续主导</strong>，Vite 和 Tauri 大受欢迎</a></li><li><a href="https://www.oschina.net/news/183856/the-state-of-javascript-2021" target="_blank">2021 JavaScript 调查：Vite&nbsp;之年，Esbuild、<strong>TypeScript 采用率大幅增长</strong></a></li><li><a href="https://www.oschina.net/news/115999/2020-stackoverflow-developer-survey-results" target="news">2020 开发者调查：<strong>TypeScript 击败 Python</strong>，Scala 最赚钱</a></li><li><a href="https://www.oschina.net/news/217509/language-rankings-6-22" target="news">RedMonk 排行：<strong>TypeScript 与 C++ 并列</strong>，Kotlin 或将超越 Go？</a></li></ul><p>对于所谓的「TypeScript 被大牛抛弃」，今年确实有两个知名事件：</p><ul><li><a href="https://www.oschina.net/news/257387/turbo-8-is-dropping-typescript" target="_blank">Ruby on Rails 作者 DHH 宣布 Turbo 8 将移除 TypeScript 代码</a></li><li><a href="https://www.oschina.net/news/240489/svelte-ts-to-jsdoc" target="news">Svelte 正在从 TypeScript 切换到 JavaScript</a></li></ul><p>至于大牛与否，不妨看看前端大佬&nbsp;<span style="background-color:#ffffff; color:#404040">winter 的「内涵」评价：</span></p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-6d3e3154ea16403d7283d49f3ce1cefe268.png" referrerpolicy="no-referrer"></p></blockquote><p>言归正传，我们回到题目本身。最近<span style="background-color:#ffffff; color:#333333">开源中国采访了 3 位资深前端工程师：</span></p><blockquote><ul><li><p style="margin-left:0; margin-right:0"><span style="color:#245bdb">刘勇，社区暱称天猪，某大厂 Node.js<span>&nbsp;</span></span><span style="color:#245bdb">Infra</span><span style="color:#245bdb"><span>&nbsp;</span>负责人，EggJS / CNPM 核心开发者。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#245bdb">刘易成，社区暱称 xcatliu（流浪小猫），《</span><span style="color:#245bdb">TypeScript</span><span style="color:#245bdb"><span>&nbsp;</span>入门教程》作者，来自腾讯文档团队。</span></p></li><li><p style="margin-left:0; margin-right:0"><span style="color:#245bdb">李振，社区暱称 tick，来自腾讯文档团队。</span></p></li></ul></blockquote><p><span style="background-color:#ffffff; color:#333333">讨论的方向刚好从「</span><span style="color:#e67e22"><span style="background-color:#ffffff"><strong>放弃 TypeScript 回归 JavaScript</strong></span></span><span style="background-color:#ffffff; color:#333333">」这个话题切入，下面来看看他们各自的看法。</span></p><hr><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：</strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>是基于<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>推出的新语言，理论上应该比 JavaScript 完善的，为什么大家还会倒回去用旧的 JavaScript 呢？这算不算开历史的倒车？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘勇：</strong>不算倒车，这只是一个选择，在某些场景下，写 TypeScript 会带来一些额外成本。譬如我看过一些开源库的源码，核心逻辑可能就几十行，但为了实现准确的类型提示，写出来的类型体操反而远远多于核心源码，孰是孰非对于不同的开发者有不同的准绳，需要找到其中的平衡点。当然，就目前的情况，在力所能及的情况下，我个人推荐能用 TypeScript 就用 TypeScript ，但是否要玩类型体操则根据开发者自身情况来决策。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘易成：</strong>已经使用了 TypeScript 的项目改回使用 JavaScript 是很少见的，更多的项目是从 JavaScript 升级到 TypeScript。TypeScript 完善了 JavaScript 的类型系统，使得代码的可维护性更高了，但同时也增加了编译步骤和一些开发成本。对于一些项目而言，JavaScript 已经能够满足需求了，就没必要增加 TypeScript 类型系统的复杂性了，但是对于另一些复杂项目，更需要类型系统来帮助提高代码可维护性，所以这不算开历史的倒车，而是根据实际情况做技术选型。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：以上从<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>切回到<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>的项目，都是做开发框架的，所以这是不是跟项目类型有关呢？做框架的项目更有可能选择</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>吗？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>是的，项目类型可以是影响选择 JavaScript 还是 TypeScript 的一个因素。在开发框架或库时，特别是前端框架或库，选择使用 JavaScript 的情况较为常见。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">一方面，开发框架需要具备广泛的兼容性，以便开发者可以在各种项目中使用。由于 JavaScript 是 Web 开发的基础语言，几乎所有的浏览器和环境都支持 JavaScript。这使得使用 JavaScript 编写的框架更容易被广泛采用和集成。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">另一方面，开发框架通常需要提供简单易用的 API 和灵活的扩展机制，以满足各种项目的需求。使用 JavaScript 可以更加直接地表达这些概念，而不需要过多的类型注解和编译步骤。这使得开发者可以更快地理解和使用框架，并且更容易进行自定义和扩展。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘勇：</strong>框架和类库的开发者，往往需要考虑到很多 edge case，在这种情况下，编写完善的类型是一件很费心力的事，代码量会多了不少，从而会导致维护成本的增加。其实现在社区还是在探索的阶段，需要找到一个平衡点，哪一些是需要完善的，哪一些是可以取舍的。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：我们一开始用<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>是因为 TypeScript 提供了类型检查，弥补了<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>只有逻辑没有类型的问题，那如果我们用 JavaScript + JSDoc 来解决类型声明，是不是就不用使用 TypeScript 了？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘勇：</strong>首先，JSDoc 并不能完全解决类型声明问题，它也不能在开发期就帮助开发者发现一些问题。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">其次，这两者并不冲突，我个人在写 TypeScript 的时候也会写对应的 JSDoc，因为 TypeScript 的类型没法有更多的注释和描述。我更期望看到后续 TypeScript 团队能优化这块的体验。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘易成：</strong>JSDoc 只能解决一部分类型的问题，而 TypeScript 是一个完整的类型系统。TypeScript 生态更繁荣，对于普通开发者和普通的项目而言，使用 JSDoc 的开发和维护成本可能会比 TypeScript 更高。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>理论上也是可行的，但与 TypeScript 相比，它仍然存在一些限制：</p><ul><li><p style="margin-left:0; margin-right:0">静态类型检查的完整性：JSDoc 注释是基于注释的方式，而不是直接嵌入到语言中，因此它的类型检查可能不如 TypeScript 的类型系统完整和准确。</p></li><li><p style="margin-left:0; margin-right:0">工具支持的差异：尽管一些工具和编辑器可以利用 JSDoc 注释进行类型检查，但与 TypeScript 相比，它们的功能和智能感知可能有所限制。</p></li><li><p style="margin-left:0; margin-right:0">生态系统的差异：TypeScript 有一个独立的类型系统和类型声明文件生态系统，这使得与现有的 JavaScript 库和工具更加无缝集成。而使用 JavaScript + JSDoc 可能需要更多的手动工作来编写和维护类型注释。</p></li></ul><p>&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：有人认为，</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>的出现是因为一般人驾驭不了</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>，有人则觉得 「水平越差的人越喜欢自由」，你怎么看？这两个语言的选择跟程序员的水平有关吗？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>拿爱好来判断个人水平是挺无聊的事情。写 JavaScript<strong><span>&nbsp;</span></strong>和写 TypeScript 都有大牛。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘勇：</strong>笑～ 平时可没少见有同学吐槽，好好的 TypeScript 项目，被人提交了一堆 Any。也见过很多吐槽接手了一个 TypeScript 仓库，要硬着头皮看一大堆类型定义，搞清楚这些奇奇怪怪的类型是如何工作的。我觉得语言的选择主要看团队的工程化和规范化程度，过犹不及。如果一个 TypeScript 类库写了一大堆类型，但却连一个单测都没有，那我觉得它是不合格的。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘易成：</strong>TypeScript<strong><span>&nbsp;</span></strong>的出现确实有一部分原因是 JavaScript<strong><span>&nbsp;</span></strong>比较难 「驾驭」，JavaScript<strong><span>&nbsp;</span></strong>太灵活了，缺少类型的约束，很容易写出 bug 代码，TypeScript 一定程度上解决了这个问题，使得代码的可维护性更高了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">JavaScript<strong><span>&nbsp;</span></strong>和 TypeScript 不能用来衡量程序员的水平。对于简单的项目或者个人项目而言，JavaScript<strong><span>&nbsp;</span></strong>可能更加轻量和灵活，但对于需要大团队协作，复杂的项目而言，TypeScript 的类型系统就可以带来更好的代码维护性和可靠性了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="color:#245bdb"><strong>Q：你如何看待<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>TypeScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>的未来发展？你觉得它是一时流行还是会终将取代<span>&nbsp;</span></strong></span><span style="color:#245bdb"><strong>JavaScript</strong></span><span style="color:#245bdb"><strong><span>&nbsp;</span>？你认为谁的技术生态更好一点呢？</strong></span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘勇：</strong>TypeScript<strong><span>&nbsp;</span></strong>的定位是 JavaScript<strong><span>&nbsp;</span></strong>的一个超集，它的能力是以 TC39 制定的 ECMAScript 规范为基准（即 JavaScript<strong><span>&nbsp;</span></strong>）。我觉得它也谈不上会取代 JavaScript<strong><span>&nbsp;</span></strong>，毕竟它并不是官方规范，而且 JavaScript<strong><span>&nbsp;</span></strong>的存量生态实在是太庞大了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">当然，TypeScript 现在已经某种程度上成为事实的标准，尤其是因为 Node.js 官方对 ESM 和 CJS 何去何从的犹豫，导致社区开发者长时间的割裂，越来越多的人被迫选择用 TypeScript 来写类库，然后同时编译为 ESM 和 CJS。目前 TypeScript 的生态已经成规模，所以它不会像 CoffeeScript 那样昙花一现。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>刘易成：</strong>我个人认为 TypeScript 会持续流行并得到更广泛的应用。但并不会 「取代」 JavaScript<strong><span>&nbsp;</span></strong>。TypeScript 的目标一直都不是 「取代」 JavaScript<strong><span>&nbsp;</span></strong>，而是基于 JavaScript<strong><span>&nbsp;</span></strong>提供类型系统，作为 JavaScript<strong><span>&nbsp;</span></strong>的一个补充，在不同的项目和场景中发挥各自的优势。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">JavaScript<strong><span>&nbsp;</span></strong>和 TypeScript 的技术生态早已融合在一起了吧，几乎所有库都会有 TypeScript 类型文件。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>李振：</strong>我认为 TypeScript 不太可能完全取代 JavaScript，而是作为 JavaScript 的一个补充和增强。两者暂时不会出现零和博弈，也希望这两种语言都可以有更好的发展。目前来看 JavaScript 的生态更庞大一些，但是 TypeScript 的地位和影响力不断增长。作为普通开发者，在两者并不冲突的当下，最好都能关注其发展。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><blockquote><h4><strong>完整采访内容查看：<a href="https://my.oschina.net/u/6852546/blog/10114672" target="_blank">「根本不需要 TypeScript，JS + JSDoc 够了」，大佬说我想多</a></strong></h4></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 06:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260816</guid>
            <link>https://www.oschina.net/news/260816</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Glibc 动态加载器存在严重本地提权漏洞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日有关 Glibc 动态加载器 (Dynamic Loader) 的一个严重漏洞被公开，<strong>攻击者获取本地用户 (local users) 身份后，利用该漏洞制造缓冲区溢出</strong>，<strong>即可获得完整 root 权限</strong>。</p><p>据介绍，攻击者使用由 ld.so 动态加载器制作的 GLIBC_TUNABLES 环境变量来触发漏洞，然后通过 SUID 权限安装文件时，能以 root 权限执行任意代码。</p><blockquote><p>Glibc 即 GNU C Library，是 GNU 系统以及大多数采用 Linux 内核的系统中的 C 运行库。Glibc 是 Linux 系统中最底层的 API，几乎其它任何运行库都会依赖于 Glibc。</p><p>它定义了典型程序所需的系统调用和其他基本功能，例如 open、malloc、printf、exit 等。 Glibc 的动态加载器是 glibc 的重要组成部分，负责准备和运行程序。当程序启动时，该加载器首先检查该程序以确定其所需的共享库。然后它搜索这些库，将它们加载到内存中，并在运行时将它们与可执行文件链接。</p><p>在此过程中，动态加载器解析符号引用，例如函数和变量引用，确保为程序的执行做好一切准备。鉴于其作用，动态加载器对安全性高度敏感，因为当本地用户启动 set-user-ID 或 set-group-ID 程序时，其代码会提权来运行。</p></blockquote><p>该漏洞最早<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.qualys.com%2Fvulnerabilities-threat-research%2F2023%2F10%2F03%2Fcve-2023-4911-looney-tunables-local-privilege-escalation-in-the-glibcs-ld-so" target="_blank">由 Qualys 报告</a></strong>，被命名为&nbsp;<strong>Looney Tunables</strong>，追踪编号为 CVE-2023-4911。据称过去两年发布的 Linux 发行版均受存在 Looney Tunables 漏洞 ，例如 Ubuntu 22.04 LTS、23.04、Fedora 38 以及其他容易受到此本地提权漏洞影响的发行版。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25c8c90352d003a1c79ed3f79edbbd0bd55.png" referrerpolicy="no-referrer"></p><p>漏洞曝光后，独立安全研究员 Peter Geissler (blasty) 很快就发布了 PoC 代码，确认可以攻击 Linux 发行版。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9ef2f1befa040312fa6202ca9fe080882f7.png" referrerpolicy="no-referrer"></p><p>上文提到的 GLIBC_TUNABLES 环境变量旨在微调和优化与 glibc 相关的应用程序，是开发者和系统管理员的必备工具。它的滥用会广泛影响系统性能、可靠性和安全性。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260786/glibc-ld-nasty-root-bug</guid>
            <link>https://www.oschina.net/news/260786/glibc-ld-nasty-root-bug</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[再添一员！Cutefish 桌面环境成功适配 openKylin]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">近日，在 openKylin 社区 Cutefish SIG 成员的努力下，openKylin 开源操作系统桌面环境又迎来一个新成员—</span><strong><span style="color:#000000">Cutefish</span></strong><span style="color:#000000">。这也是继 UKUI、KDE、Xfce 和 DDE 之后，openKylin 开源操作系统支持的第五个 Linux 桌面环境，为社区用户带来更多选择。</span></span></p><div><p style="text-align:center"><img alt="" height="921" src="https://oscimg.oschina.net/oscnet/up-e557c73aea5afb59e398f92bd116adde5c1.png" width="1637" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000"><span style="background-color:#f0f3ff">Cutefish 是一款简洁、美观、实用的桌面环境，为用户提供舒适的界面与优秀的用户体验，能够满足各种场景下的使用需求。</span></span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">除 X86 环境外，openKylin 社区 Cutefish SIG 也完成了 Cutefish 桌面环境对 openKylin 操作系统 ARM 架构板卡的适配。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f2576a6dd2921f794fe704e744966b24dc3.jpg" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">同时，在赛昉科技和 RISC-V SIG 的帮助下，Cutefish SIG 成功将 Cutefish 桌面移植到 VisionFive2。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-48c1c00d01962014df6b292dc18001b4b32.jpg" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">截至目前，已完成 Cutefish 软件包的移植工作，并经 Cutefish SIG 成员测试可流畅运行桌面及其特色应用。欢迎大家在 openKylin 上安装和体验 Cutefish 桌面环境。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#2589fb">安装方式</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">1.添加每日构建源</span></strong></span></p><pre><code><span style="color:#114ba6">deb</span> http://archive.build.openkylin.top/openkylin yangtze-proposed main</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">2.更新源</span></strong></span></p><pre><code>sudo apt <span style="color:#114ba6">update</span> &amp;&amp; sudo apt <span style="color:#114ba6">upgrade</span></code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">3.搜查 Cutefish 软件包</span></strong></span></p><pre><code>sudo apt-<span style="color:#114ba6">cache</span><span style="color:#114ba6">search</span> cutefish</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">4.安装</span></strong></span></p><pre><code>sudo apt <span style="color:#114ba6">install</span> cutefish-core cutefish-dock cutefish-daemon 
cutefish-qt-plugins cutefish-calculator cutefish-debinstaller 
cutefish-filemanager cutefish-launcher cutefish-screenlocker 
cutefish-<span style="color:#114ba6">settings</span> cutefish-statusbar cutefish-terminal cutefish-videoplayer 
cutefish-wallpapers cutefish-<span style="color:#114ba6">cursor</span>-themes cutefish-gtk-themes 
cutefish-sddm-theme  fishui libcutefish</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">5.切换桌面</span></strong></span></p><div><p style="text-align:center"><img alt="" height="794" src="https://oscimg.oschina.net/oscnet/up-05f1ddfabb6c84942d02a3c851f48b47a92.png" width="1277" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#2589fb">关于 Cutefish SIG</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Cutefish 是一款简洁、美观、实用的桌面环境，Cutefish SIG 致力于维护 Cutefish 相关组件，如桌面、启动器、任务栏、控制中心、窗口管理器等，给 openKylin 提供美观易用的桌面环境。</span></span></p><ul><li><span><span style="color:#000000">SIG 主页：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/Cutefish</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260772</guid>
            <link>https://www.oschina.net/news/260772</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[SecZone 每日安全资讯（2023.10.08）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>环球动态<br> 1.Microsoft 将在 Windows 11 中引入密钥支持功能<br> 作为 Windows 11 重大更新的一部分，微软今天推出了密钥支持功能。用户将能使用设备 PIN 或生物识别信息登录网站和应用，而无需提供用户名和密码。【Microsoft is Rolling out Support for Passkeys in Windows 11 (thehackernews.com)】</p><p>2.黑客利用零点字体伪装成 Microsoft Outlook 诱骗显示虚假的 AV 扫描警报<br> 黑客正在利用零点字体在电子邮件中的新型技巧，使恶意邮件看起来像是 Microsoft Outlook 中的安全工具发出的扫描警报。这是首次记录到 ZeroFont 网络钓鱼技术以这种方式的使用。【针对 Microsoft 365 的钓鱼即服务平台 Greatness - FreeBuf 网络安全行业门户】</p><p>3. 谷歌为攻击中利用的 libwebp 漏洞分配了新的最高 CVE 编号<br> 谷歌已经为最近被攻击利用的 libwebp 安全漏洞分配了新的最高 CVE 编号（CVE-2023-5129）。这个零日漏洞在两周前修补过。【VMware Aria Operations for Networks 远程代码执行漏洞（CVE-2... - FreeBuf 网络安全行业门户】</p><p>4. 新的 AtlasCross 黑客冒充美国红十字会发送网络钓鱼诱饵<br> 「AtlasCross」新黑客组织冒充美国红十字会，针对有网络钓鱼诱饵的组织发送后门恶意软件。【Access denied | www.bleepingcomputer.com used Cloudflare to restrict access】</p><p>5. 苹果谷歌漏洞披露不充分，使腾讯 QQ 等数百万应用面临潜在风险<br> 安全研究员指出，苹果和谷歌近期披露的产品零日漏洞不完整，可能隐藏了一个上游开源库 libwebp 的漏洞，使腾讯 QQ 等数百万应用面临「巨大的盲点」，处于被攻击的危险之中。【苹果谷歌漏洞披露不完整，让腾讯 QQ 等数百万应用处于危险之中 - 安全内参 | 决策者的网络安全知识库 (secrss.com)】</p><p>6.科技巨头们联手成立了 PQC 联盟以推动量子密码学的应用<br> 微软、IBM Quantum、MITRE、PQShield、SandboxAQ 和滑铁卢大学等科技巨头联手启动了 PQC 联盟，旨在推动量子密码学在商业及开源领域的应用。Shor 算法作为构建所有非对称加密的基础，正受到量子计算的威胁。【Tech Giants Launch Post-Quantum Cryptography Coalition - Infosecurity Magazine (infosecurity-magazine.com)】</p><p>安全大爆料<br> 1. 加拿大的 Flair Airlines 公司在其用户数据保护方面存在严重问题<br> 根据 Cybernews 的研究团队的发现，加拿大的 Flair Airlines 公司在其用户数据保护方面存在着严重的问题。他们发现，该公司在处理敏感数据库和电子邮件地址凭据的过程中，竟然将它们保留了下来长达至少七个月的时间。这种情况无疑增加了乘客个人信息（如电子邮件、姓名或地址）被不法分子利用的风险。这不仅对乘客的个人隐私构成了威胁，也对他们的安全带来了潜在的风险。【Canadian Flair Airlines left user data leaking for months (securityaffairs.com)】</p><p>2. 科威特财政部遭.HYSIDA 勒索软件组织攻击<br> 财政部在今天黎明时分宣布，其一个系统遭到了恶意软件的黑客攻击。尽管系统和保护程序已经启动并停用，但该部仍在评估这次未遂黑客攻击的程度。此外，财政部还确认，工资转移程序不会受到这次网络攻击的影响，因为政府的财务系统是独立的。【The Rhysida ransomware group hit the Kuwait Ministry of Finance (securityaffairs.com)】</p><p>3. 3 万新生儿和孕期护理患者的数据泄露事件影响了 BORN ONTARIO<br> "BORN（更好的结果注册和网络）受到了网络安全漏洞的影响，这个漏洞是由我们使用的软件 Progress MOVEit 在执行安全文件传输时触发的全球性漏洞所导致。"【BORN Ontario data breach impacted 3.4 million newborns and pregnancy care patients (securityaffairs.com)】</p><p>4. 影子辛迪加：与 7 个勒索软件家族有关的新兴网络犯罪组织<br> 网络安全专家揭示了一个名为 ShadowSyndicate（前身为 Infra Storm）的新网络犯罪组织，该组织在过去一年中可能利用了多达七个不同的勒索软件家族。【ShadowSyndicate: A New Cybercrime Group Linked to 7 Ransomware Families (thehackernews.com)】</p><p>5. JetBrains TeamCity 的漏洞可能让攻击者获得源代码和构建管道的访问权限<br> 没有经过身份验证的攻击者可以利用 JetBrains TeamCity CI/CD 软件中的一个关键安全漏洞，在受影响的系统上远程执行代码。【Critical JetBrains TeamCity Flaw Could Expose Source Code and Build Pipelines to Attackers (thehackernews.com)】</p><p>6. 网络钓鱼者利用 Facebook 直播假货作为诱饵<br> NCC 警告称，「航海狂人」可能很容易被虚假的社交媒体帖子所诱惑，一些受害者甚至可能在不知不觉中成为了犯罪分子的新兵，以获取整齐的 Facebook 帐户详细信息。【Critical JetBrains TeamCity Flaw Could Expose Source Code and Build Pipelines to Attackers (thehackernews.com)】</p><p>前沿资讯<br> 1. macOS 平台上出现的新型信息窃密软件：MacStealer<br> 信息窃密恶意软件 MacStealer 能够对最新版本的 macOS 造成威胁，并且使用了 Telegram 作为 C&amp;C 信道来窃取受害者的敏感数据。【macOS 平台新出现的信息窃密软件：MacStealer_网络安全小肖的博客-CSDN 博客】</p><p>2. 零信任技术架构：SDP2.0 的中文改写版<br> "在零信任技术架构中，本质上没有太大的区别。在实际的客户环境中，我们需要根据具体情况有侧重点地进行建设，例如优先加强端点零信任能力（SDP 架构）、身份认证零信任能力（IAM 架构）或东西向流量的零信任能力（MSG 架构）等。"【白话零信任技术架构之 SDP2.0 - FreeBuf 网络安全行业门户】</p><p>3. 0day 审计：某微代码审计案例的中文改写版本<br> 这个方法是继承了 extends MobileAction 并通过 http 请求获取 action 参数，然后进行全局 jsp 文件搜索 SkinAction，发现通过了 jionActionUrl 方法调用，在第 2 行包含了&lt;%@ include file="/mobilemode/init.jsp"%&gt;，根据里方法构造出路径。【0day 审计之某微代码审计-腾讯云开发者社区-腾讯云 (tencent.com)】</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260771</guid>
            <link>https://www.oschina.net/news/260771</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Brave 裁员 9%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Brave Browser 和 Search 的制造商 Brave Software 向 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F06%2Fbrave-lays-off-9-of-its-workforce%2F" target="_blank">TechCrunch</a> 证实，该公司已跨部门裁员 9%。该公司没有具体说明裁员波及的员工人数，但它证实了这一裁员举措，并表示这一决定是由严峻的经济环境所驱动的。</span></p><p><span style="color:#000000">「在这个充满挑战的经济环境中，Brave 公司裁撤了一些职位，作为我们成本管理的一部分。有几个部门受到影响，占我们员工总数的 9%。」</span></p><p><img height="261" src="https://oscimg.oschina.net/oscnet/up-38a5daf764ff082e1ad6362984e1cec8e08.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">今年以来，该公司一直在采取措施以加强收入来源。4 月份，Brave Search 放弃了 Bing Index，开始依赖自己的索引解决方案。</span></p><p><span style="color:#000000">5 月份，该公司为客户发布了自己的&nbsp;search API，计划每 1,000 次查询收费 3 美元起。该 API 还为 AI 数据模型训练、具有存储权限的数据、拼写检查和自动建议提供了不同的计划。上个月，Brave 还为其 search API 推出了图像、新闻和视频搜索功能。</span></p><p><span style="color:#000000">此外，Brave 一直在为其浏览器测试名为 Leo 的原生人工智能助手。Brave 表示，虽然计划向所有用户开放，但 Leo 将拥有高级版，具有更高的速率限制和访问更多对话模型等功能。该公司指出，这将有助于其支付 API 访问和托管成本。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260770/brave-lays-off-9-of-its-workforce</guid>
            <link>https://www.oschina.net/news/260770/brave-lays-off-9-of-its-workforce</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[NASA 更改 CMS：从 Drupal 迁移到 WordPress]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>美国国家航空航天局 (NASA) 移除了新版<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nasa.gov%2F" target="_blank">&nbsp;nasa.gov </a>网站上的 beta 测试标签，标志其已正式可用。</p><p>据介绍，NASA 新版本官网采用了新的 CMS（内容管理系统） —— 从 Drupal 迁移到 WordPress。此次迁移花费了 18 个月，主要工作包括网站开发、数据迁移和内容建设。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6f81cac58978084713557fe55beb8b4510b.png" referrerpolicy="no-referrer"></p><p>NASA 在选择 CMS 时评估了商业和开源解决方案，对 100 多个 CMS 平台进行了考察，四个方案进入了最终候选名单，包括两个商业方案，以及两个开源方案 —— WordPress 和 Drupal。</p><p>他们认为 WordPress 的优势如下：</p><ul><li><strong>社区庞大</strong>，方便获取支持资源。</li><li><strong>插件生态丰富</strong>，更好地进行 SEO 优化、对内容进行实时分析等</li><li><strong>内容创作环境易于使用</strong></li></ul><p>WordPress.com VIP 金牌代理合作伙伴 Lone Rock Point 领导了 NASA 此次 CMS 迁移项目，该项目从一年的用户体验设计和对各种企业 CMS 的评估开始。作为该项目的一部分，NASA 的网站基础设施也从 AWS 迁移到了 WordPress.com VIP。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260768/nasa-chose-wordpress-cms</guid>
            <link>https://www.oschina.net/news/260768/nasa-chose-wordpress-cms</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[SudoLang —— 与 AI 语言模型协作的编程语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>SudoLang 是一种编程语言，旨在与 ChatGPT、Bing Chat、Anthropic Claude 和 Google Bard 等 AI 语言模型协作。它被设计为易于学习和使用，同时也非常具有表现力和力量。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>所有足够先进的语言模型都可以在没有任何特殊提示的情况下理解它。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h4 style="text-align:start"><strong><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特点</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><strong>基于自然语言约束的编程。</strong>与其告诉人工智能做什么，不如告诉它是什么或你想要什么，以及一些管理规则。人工智能会持续遵守这些约束，并可用于同步状态和行为。只需几行自然语言文本，约束条件就能轻松定义非常复杂的行为。</li><li>用于定义程序的结构和行为的<strong>接口。</strong></li><li><strong><code>/commands</code></strong>用于为程序交互定义聊天或编程接口。</li><li><strong>语义模式匹配</strong>。AI 可以智能地推断程序状态并匹配模式，诸如<code>(post contains harmful content) =&gt; explain(content policy)</code>。</li><li><strong>全能参照。</strong>你无需明确定义大多数函数。人工智能会为你推断出它们。</li></ul><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>对于大多数简单的提示，自然语言更好。用它。但如果你需要 AI 遵循程序、遵守约束、跟踪复杂状态或实现复杂算法，SudoLang 会非常有用。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>由于强调自然语言，SudoLang 比 JavaScript 或 Python 等编程语言更容易学习。</li><li>与自然语言提示相比，伪代码可以<a href="https://arxiv.org/abs/2305.11790">提高推理性能</a>，并为许多提示样式创建简写，例如思想链推理、决策树等。</li><li>SudoLang 是一种声明性、基于约束、面向接口的编程语言，这使其成为世界上最具表现力和紧凑的编程语言之一。SudoLang 提示通常可以比自然语言少 20% - 30% 的标记，从而降低提示成本并加快响应速度。</li><li>结构化伪代码提供范围块、缩进和视觉封装，这使得导航和维护复杂提示比自然语言更容易。</li><li>使用预定义类型和接口的结构化模板和查询可以降低格式错误响应的可能性，并<a href="https://arxiv.org/pdf/2212.06094.pdf">显着减少与语言模型交互所需的令牌数量</a>，特别是在请求<a href="https://yaml.org/">yaml</a>或<a href="https://en.wikipedia.org/wiki/Comma-separated_values">csv</a>格式的数据时。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/sudolang</guid>
            <link>https://www.oschina.net/p/sudolang</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 键映射解决方案 Capslock Magic]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-capslockmagic" class="anchor" href="https://gitee.com/miozus/CapslockMagic#capslockmagic"></a>CapslockMagic</h1><blockquote><p><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic">中文文档</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fen-us%2F">README</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fke-complex-modifications.pqrs.org%2F%23caps_lock_magic">Karabiner Gallery</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmiozus%2FCapslockMagic">Github Repo</a> | <a href="https://gitee.com/miozus/CapslockMagic">Gitee Repo</a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fthqby%2FAutoHotkey_H"><img src="https://img.shields.io/badge/AutoHotkey__H-thqby-orange?style=flat&amp;logo=GitHub" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmiozus%2FCapslockMagic"><img src="https://img.shields.io/badge/CapslockMagic-1.5.1-brightengreen?style=flat&amp;logo=ClickUp" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DiiuN83v3"><img src="https://img.shields.io/badge/QQ%E7%BE%A4-1026918136-yellow?style=flat&amp;logo=TencentQQ" referrerpolicy="no-referrer"></a></p></blockquote><p><img src="https://gitee.com/miozus/CapslockMagic/raw/master/docs/img/HHKB-win-keymap-pure.png" alt="hhkb" referrerpolicy="no-referrer"></p><p>Capslock Magic 是一套<strong>跨平台</strong>、<strong>跨应用</strong>的键映射解决方案。 它将 ⇪ CapsLock（大写锁定键）改造为一个强力的功能修饰键（✱ Hyper ），还改造了 <kbd>3</kbd><kbd>4</kbd><kbd>;</kbd> 按键，适用各种日常业务场景。奇迹般地提高操作效率与生产力。</p><p>—— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmonkey-ime">示例</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fquick-start-windows">安装</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">使用</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">问题</a> ——</p><h2><a id="user-content-功能一览" class="anchor" href="https://gitee.com/miozus/CapslockMagic#%E5%8A%9F%E8%83%BD%E4%B8%80%E8%A7%88"></a>功能一览</h2><table><thead><tr><th>&nbsp;</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>底层</td><td>💻  支持 Win/Mac</td><td>⌨️  键盘配列 60</td><td>🧰  JavaScprit 风格</td><td>⚙️  配置自定义</td></tr><tr><td>基础</td><td>👾  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">启动程序</a></td><td>📺  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fwindow">窗口管理</a></td><td>🖱️  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmouse">鼠标操作</a></td><td><code>I</code><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">光标编辑</a></td></tr><tr><td>进化</td><td>🐵  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmonkey-ime">猴子输入法</a></td><td><code>;</code><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fsemicolon-hook">分号特殊符</a></td><td>3️⃣  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fnumpad">数字小键盘</a></td><td>🤖  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fime-manager">中英文管家</a></td></tr><tr><td>进化</td><td>🦑  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Funiverse-editor">宇宙编辑器</a></td><td></td><td></td><td></td></tr></tbody></table>]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/miozus/CapslockMagic</guid>
            <link>https://gitee.com/miozus/CapslockMagic</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | MySQL 到 TiDB：Hive Metastore 横向扩展之路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互联网技术" data-alias="vivoVMIC" data-signature="分享 vivo 互联网技术干货与沙龙活动，推荐最新行业动态与热门会议。" data-from="0"></mp-common-profile></section><section style="font-size: 15px;line-height: 1.6;"><section style="margin: 10px 0% 8px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding-left: 8px;align-self: flex-start;flex: 0 0 auto;"><section style="color: rgba(0, 0, 0, 0.5);font-size: 14px;text-align: justify;" powered-by="xiumi.us"><p>作者：vivo 互联网大数据团队 - Wang Zhiwen</p></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: left;" powered-by="xiumi.us"><section style="font-size: 14px;text-align: justify;line-height: 1.8;padding-right: 5px;padding-left: 5px;color: rgb(160, 160, 160);"><p>本文介绍了 vivo 在大数据元数据服务横向扩展道路上的探索历程，由实际面临的问题出发，对当前主流的横向扩展方案进行了调研及对比测试，通过多方面对比数据择优选择 TiDB 方案。其次分享了整个扩展方案流程、实施遇到的问题及解决方案，对于在大数据元数据性能上面临同样困境的开发者本篇文章具有非常高的参考借鉴价值。</p></section></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>一、背景</p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>大数据元数据服务 Hive Metastore Service（以下简称 HMS），存储着数据仓库中所依赖的所有元数据并提供相应的查询服务，使得计算引擎（Hive、Spark、Presto）能在海量数据中准确访问到需要访问的具体数据，其在离线数仓的稳定构建上扮演着举足轻重的角色。vivo 离线数仓的 Hadoop 集群基于 CDH 5.14.4 版本构建，HMS 的版本选择跟随 CDH 大版本，当前使用版本为 1.1.0-cdh5.14.4。</p><p><br></p><p>vivo 在 HMS 底层存储架构未升级前使用的是 MySQL 存储引擎，但随着 vivo 业务发展，数据爆炸式增长，存储的元数据也相应的增长到亿级别（PARTITION_PARAMS：8.1 亿、</p><p>PARTITION_KEY_VALS：3.5 亿、PARTITIONS：1.4 亿），在如此大量的数据基数下，我们团队经常面临机器资源的性能瓶颈，往往用户多并发的去查询某些大分区表（50w+分区），机器资源的使用率就会被打满，从而导致元数据查询超时，严重时甚至整个 HMS 集群不可用，此时恢复手段只能暂时停服所有 HMS 节点，直到 MySQL 机器负载降下来后在逐步恢复服务。为此，针对当前 MySQL 方案存在的严重性能瓶颈，HMS 急需一套完善的横向扩展方案来解决当前燃眉之急。</p></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>二、横向扩展技术方案选型</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">为解决 HMS 的性能问题，我们团队对 HMS 横向扩展方案做了大量的调研工作，总体下来业内在 HMS 的横向扩展思路上主要分为对 MySQL 进行拆库扩展或用高性能的分布式引擎替代 MySQL。在第一种思路上做的比较成熟的方案有<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fhotels.com%2F" textvalue="Hotels.com" linktype="text" imgurl="" tab="outerlink" data-linktype="2">Hotels.com</a>公司开源的 Waggle Dance，实现了一个跨集群的 Hive Metastore 代理网关，他允许用户同时访问多个集群的数据，这些集群可以部署在不同的平台上，特别是云平台。第二种思路当前主流的做法是用分布式存储引擎 TiDB 替换传统的 MySQL 引擎，在 Hive 社区中有不少公司对 hive 2.x 接入 TiDB 做了大量的测试并应用到生产中（<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FHive%2FUsing%2BTiDB%2Bas%2Bthe%2BHive%2BMetastore%2Bdatabase" textvalue="详情点击" linktype="text" imgurl="" tab="outerlink" data-linktype="2">详情点击</a>）。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.1 Waggle Dance</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">Waggle-dance 向用户提供统一的入口，将来自 Metastore 客户端的请求路由到底层对应的 Metastore 服务，同时向用户隐藏了底层的 Metastore 分布，从而在逻辑层面整合了多个 Metastore 的 Hive 库表信息。Waggle-dance 实现了 Metastore 的 Thrift API，客户端无需改动，对用户来说，Waggle-dance 就是一个 Metastore。其整体架构如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.9175925925925926" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/a9e0ef2a-6dea-4425-8220-7df8cbb062f1.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">Waggle Dance 架构</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">从 Waggle-dance 的架构中最突出的特性是其采用了多个不同的 MySQL 实例分担了原单 MySQL 实例的压力，除此之外其还有如下优势：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>用户侧可以沿用 Metastore 客户端的用法，配置多台 Waggle-dance 的连接，在当前 Waggle-dance 连接服务不可用的时候切换到其他的 Waggle-dance 服务上。</p></li><li><p>Waggle-dance 只需几秒即可启动，加上其无状态服务的特性，使得 Waggle-dance 具备高效的动态伸缩性，可以在业务高峰期快速上线新的服务节点分散压力，在低峰期下线部分服务节点释放资源。</p></li><li><p>Waggle-dance 作为一个网关服务，除了路由功能外，还支持后续的定制化开发和差异化部署，平台可根据需要添加诸如鉴权、防火墙过滤等功能。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.2 TiDB</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">TiDB 是 PingCAP 公司自主设计、研发的开源分布式关系型数据库，是一款同时支持在线事务处理与在线分析处理 (Hybrid Transactional and Analytical Processing, HTAP) 的融合型分布式数据库产品，具备水平扩容或者缩容、金融级高可用、实时 HTAP、云原生的分布式数据库、兼容 MySQL 5.7 协议和 MySQL 生态等重要特性。在 TiDB 4.x 版本中，其性能及稳定性较与之前版本得到了很大的提升并满足 HMS 的元数据查询性能需求。故我们对 TiDB 也做了相应的调研及测试。结合 HMS 及大数据生态，采用 TiDB 作为元数据存储整体的部署架构如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.8727272727272727" data-s="300,640" data-type="png" data-w="825" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/e149c269-2046-48a7-bb11-e0a90ce0edf1.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">HMS on TiDB 架构&nbsp; &nbsp;</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">由于 TiDB 本身具有水平扩展能力，扩展后能均分查询压力，该特性就是我们解决 HMS 查询性能瓶颈的大杀器。除此外该架构还有如下优势：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>用户无需任何改动；HMS 侧面没有任何改动，只是其依赖的底层存储发生变化。</p></li><li><p>不破坏数据的完整性，无需将数据拆分多个实例来分担压力，对 HMS 来说其就是一个完整、独立的数据库。</p></li><li><p>除引入 TiDB 作为存储引擎外，不需要额外的其他服务支撑整个架构的运行。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.3 TiDB 和 Waggle Dance 对比</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">前面内容对 Waggle-dance 方案和 TiDB 方案做了简单的介绍及优势总结，以下列举了这两个方案在多个维度的对比：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.6953703703703704" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3ce1c63-1cd8-4917-a94b-0e3c638c3328.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通过上述多个维度的对比，TiDB 方案在性能表现、水平扩展、运维复杂度及机器成本上都优于 waggle-dance 方案，故我们线上选择了前者进行上线应用。&nbsp;</p><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>三、TiDB 上线方案</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">选择 TiDB 引擎替代原 MySQL 存储引擎，由于 TiDB 与 MySQL 之间不能做双主架构，在切换过程中 HMS 服务须完全停服后并重新启动切换至 TiDB，为保障切换过程顺利及后面若有重大问题发生能及时回滚，在切换前做了如下数据同步架构以保障切换前 MySQL 与 TiDB 数据一致以及切换后仍有 MySQL 兜底。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4703703703703704" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/033aceb3-efa2-4951-9897-94e1c2cbe128.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB&amp;MySQL 上线前后数据同步架构</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在上述架构中，切换前唯一可写入的数据源只有源数据库主库，其他所有 TiDB、MySQL 节点都为只读状态，当且仅当所有 HMS 节点停服后，MySQL 源数据库从库及 TiDB 源数据库主库的数据同步最大时间戳与源数据库主库一致时，TiDB 源数据库主库才开放可写入权限，并在修改 HMS 底层存储连接串后逐一拉起 HMS 服务。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在上述架构完成后，即可开始具体的切换流程，切换整体流程如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.27037037037037037" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/20cfee5d-3265-4b12-9e43-7fa47ffb8f59.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">HMS 切换底层存储流程</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">其中在保障源 MySQL 与 TiDB 数据正常同步前，需要对 TiDB 做以下配置：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>tidb_skip_isolation_level_check 需要配置为 1 ，否则启动 HMS 存在 MetaException 异常。</p></li><li><p>tidb_txn_mode 需配置为 pessimistic ，提升事务一致性强度。</p></li><li><p>事务大小限制设置为 3G，可根据自己业务实际情况进行调整。</p></li><li><p>连接限制设置为最大 3000 ，可根据自己业务实际情况进行调整。</p></li></ul></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">此外在开启 sentry 服务状态下，需确认 sentry 元数据中 NOTIFICATION_ID 的值是否落后于 HMS 元数据库中 NOTIFICATION_SEQUENCE 表中的 NEXT_EVENT_ID 值，若落后需将后者替换为前者的值，否则可能会发生建表或创建分区超时异常。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">以下为 TiDB 方案在在不同维度上的表现：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>在对 HQL 的兼容性上 TiDB 方案完全兼容线上所有引擎对元数据的查询，不存在语法兼容问题，对 HQL 语法兼容度达 100%&nbsp;</p></li><li><p>在性能表现上查询类接口平均耗时优于 MySQL，性能整体提升 15%；建表耗时降低了 80%，且支持更高的并发，TiDB 性能表现不差于 MySQL</p></li><li><p>在机器资源使用情况上整体磁盘使用率在 10% 以下；在没有热点数据访问的情况下，CPU 平均使用率在 12%；CPU.WAIT.IO 平均值在 0.025% 以下;集群不存在资源使用瓶颈。</p></li><li><p>在可扩展性上 TiDB 支持一键水平扩缩容，且内部实现查询均衡算法，在数据达到均衡的情况下各节点可平摊查询压力。</p></li><li><p>在容灾性上 TiDB Binlog 技术可稳定支撑 TiDB 与 MySQL 及 TiDB 之间的数据同步，实现完整的数据备份及可回退选择。</p></li><li><p>在服务高可用性上 TiDB 可选择 LVS 或 HaProxy 等服务实现负载均衡及故障转移。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">以下为上线后 HMS 主要 API 接口调用耗时情况统计：</p><section style="font-size: 15px;"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 15px;margin-bottom: 15px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 5px;align-self: stretch;flex: 0 0 auto;margin-bottom: 30px;height: auto;z-index: 1;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section><section style="display: inline-block;vertical-align: top;width: auto;align-self: stretch;flex: 100 100 0%;height: auto;padding-right: 10px;padding-left: 10px;z-index: auto;line-height: 0;"><section style="display: flex;width: 100%;flex-flow: column;" powered-by="xiumi.us"><section style="z-index: 1;" powered-by="xiumi.us"><section style="text-align: right;margin-top: -5px;"><section style="display: inline-block;width: 100%;height: 5px;vertical-align: top;overflow: hidden;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-right: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bc1f5fe-5ed3-4507-8edd-99fd9eb4edcd.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-left: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.5880322209436134" data-s="300,640" data-type="jpeg" data-w="869" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/bde61013-5736-415d-a148-1fb6567a709e.png" referrerpolicy="no-referrer"></section></section></section></section><section style="justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-right: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/4575beb3-65ef-435b-8992-48929786cf28.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-left: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.6009227220299884" data-s="300,640" data-type="jpeg" data-w="867" style="vertical-align: middle;width: 298px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1c03991f-8f59-408b-a79e-d268d19c62d0.png" referrerpolicy="no-referrer"></section></section></section></section><section style="text-align: right;margin-bottom: -5px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 5px;vertical-align: top;overflow: hidden;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: top;width: 5px;align-self: stretch;flex: 0 0 auto;height: auto;margin-top: 30px;z-index: auto;"><br><br><br><br></section></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 100 100 0%;border-radius: 10px;overflow: hidden;height: auto;padding: 15px;border-style: solid;border-width: 1px;border-color: transparent;margin-right: 20px;z-index: 0;"><section style="display: inline-block;width: 100%;vertical-align: top;overflow-x: auto;border-radius: 5px;" powered-by="xiumi.us"><section style="overflow: hidden;width: 360%;max-width: 360% !important;"><section style="display: inline-block;vertical-align: middle;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bc1f5fe-5ed3-4507-8edd-99fd9eb4edcd.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.5880322209436134" data-s="300,640" data-type="jpeg" data-w="869" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/bde61013-5736-415d-a148-1fb6567a709e.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/4575beb3-65ef-435b-8992-48929786cf28.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.6009227220299884" data-s="300,640" data-type="jpeg" data-w="867" style="vertical-align: middle;width: 509px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1c03991f-8f59-408b-a79e-d268d19c62d0.png" referrerpolicy="no-referrer"></section></section></section></section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: -20px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: bottom;width: auto;align-self: flex-end;flex: 0 0 auto;min-width: 5%;height: auto;margin-right: 5px;z-index: 2;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section><section style="display: inline-block;vertical-align: bottom;width: auto;align-self: flex-end;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;color: rgb(223, 143, 51);font-size: 14px;" powered-by="xiumi.us"><p><br></p><p><span style="color: rgb(136, 136, 136);">（<span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.578px;text-wrap: wrap;">左右滑动</span><span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.578px;text-wrap: wrap;">，查看更多···</span>）</span></p></section></section></section></section></section><p powered-by="xiumi.us"><br></p></section><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>四、问题及解决方案</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.1 在模拟 TiDB 回滚至 MySQL 过程中出现主键冲突问题</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在 TiDB 数据增长 3 倍后，切换回 MySQL 出现主键重复异常，具体日志内容如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.12222222222222222" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/dfa5874c-61af-4491-b338-4a3c4bd816af.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">主键冲突异常日志</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">产生该问题的主要原因为每个 TiDB 节点在分配主键 ID 时，都申请一段 ID 作为缓存，用完之后再去取下一段，而不是每次分配都向存储节点申请。这意味着，TiDB 的 AUTO_INCREMENT 自增值在单节点上能保证单调递增，但在多个节点下则可能会存在剧烈跳跃。因此，在多节点下，TiDB 的 AUTO_INCREMENT 自增值从全局来看，并非绝对单调递增的，也即并非绝对有序的，从而导致 Metastore 库里的 SEQUENCE_TABLE 表记录的值不是对应表的最大值。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">造成主键冲突的主要原因是 SEQUENCE_TABLE 表记录的值不为元数据中实际的最大值，若存在该情况在切换回 MySQL 后就有可能生成已存在的主键导致初见冲突异常，此时只需将 SEQUENCE_TABLE 里的记录值设置当前实际表中的最大值即可。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.2 PARTITION_KEY_VALS 的索引取舍</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在使用 MySQL 引擎中，我们收集了部分慢查询日志，该类查询主要是查询分区表的分区，类似如下 SQL：</p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__comment">#以下查询为查询三级分区表模板，且每级分区都有过来条件</span></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">SELECT</span> PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">FROM</span><span class="code-snippet__keyword">PARTITIONS</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> TBLS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> PARTITIONS.TBL_ID = TBLS.TBL_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> TBLS.TBL_NAME = <span class="code-snippet__string">'${TABLE_NAME}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> DBS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> TBLS.DB_ID = DBS.DB_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> DBS.NAME = <span class="code-snippet__string">'${DB_NAME}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER0</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER0.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER0.INTEGER_IDX = ${INDEX1}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER1</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER1.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER1.INTEGER_IDX = ${INDEX2}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER2</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER2.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER2.INTEGER_IDX = ${INDEX3}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHERE</span> FILTER0.PART_KEY_VAL = <span class="code-snippet__string">'${PART_KEY}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__keyword">CASE</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHEN</span> FILTER1.PART_KEY_VAL &lt;&gt; <span class="code-snippet__string">'__HIVE_DEFAULT_PARTITION__'</span><span class="code-snippet__keyword">THEN</span><span class="code-snippet__keyword">CAST</span>(FILTER1.PART_KEY_VAL <span class="code-snippet__keyword">AS</span><span class="code-snippet__built_in">decimal</span>(<span class="code-snippet__number">21</span>, <span class="code-snippet__number">0</span>))</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ELSE</span><span class="code-snippet__literal">NULL</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">END</span> = <span class="code-snippet__number">10</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER2.PART_KEY_VAL = <span class="code-snippet__string">'068'</span>;</span></code></pre></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>在测试中通过控制并发重放该类型的 SQL，随着并发的增加，各个 API 的平均耗时也会增长，且重放的 SQL 查询耗时随着并发的增加查询平均耗时达到 100s 以上，虽然 TiDB 及 HMS 在压测期间没有出现任何异常，但显然这种查询效率会让用户很难接受。DBA 分析该查询没有选择合适的索引导致查询走了全表扫描，建议对 PARTITION_KEY_VALS 的 PARTITION_KEY_VAL 字段添加了额外的索引以加速查询，最终该类型的查询得到了极大的优化，即使加大并发到 100 的情况下平均耗时在 500ms 内，对此我们曾尝试对 PARTITION_KEY_VALS 添加上述索引操作。</p><p><br></p><p>但在线上实际的查询中，那些没有产生慢查询的分区查询操作其实都是按天分区的进行一级分区查询的，其 SQL 类似如下：</p></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__keyword">SELECT</span><span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">FROM</span><span class="code-snippet__string">"PARTITIONS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"TBLS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"TBL_ID"</span> = <span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"TBL_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"TBL_NAME"</span> = <span class="code-snippet__string">'tb1'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"DBS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"DB_ID"</span> = <span class="code-snippet__string">"DBS"</span>.<span class="code-snippet__string">"DB_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"DBS"</span>.<span class="code-snippet__string">"NAME"</span> = <span class="code-snippet__string">'db1'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"PARTITION_KEY_VALS"</span><span class="code-snippet__string">"FILTER0"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"PART_ID"</span> = <span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"INTEGER_IDX"</span> = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"PARTITION_KEY_VALS"</span><span class="code-snippet__string">"FILTER1"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_ID"</span> = <span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"INTEGER_IDX"</span> = <span class="code-snippet__number">1</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHERE</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span> = <span class="code-snippet__string">'2021-12-28'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__keyword">CASE</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHEN</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span> &lt;&gt; <span class="code-snippet__string">'__HIVE_DEFAULT_PARTITION__'</span><span class="code-snippet__keyword">THEN</span><span class="code-snippet__keyword">CAST</span>(<span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span><span class="code-snippet__keyword">AS</span><span class="code-snippet__built_in">decimal</span>(<span class="code-snippet__number">21</span>, <span class="code-snippet__number">0</span>))</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ELSE</span><span class="code-snippet__literal">NULL</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">END</span> = <span class="code-snippet__number">10</span>;</span></code></pre></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">由于对 PARTITION_KEY_VALS 的 PARTITION_KEY_VAL 字段添加了索引做查询优化，会导致该类查询生成的执行计划中同样会使用 idx_PART_KEY_VAL 索引进行数据扫描，该执行计划如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4898148148148148" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/20f84c22-d1ae-4c32-82be-4b884faf9249.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">走 idx_PART_KEY_VAL 索引执行计划</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">添加的 idx_PART_KEY_VAL 索引在该字段的具有相同值的数据较少时，使用该索引能检索较少的数据提升查询效率。在 hive 中的表一级分区基本是按天进行分区的，据统计每天天分区的增量为 26w 左右，如果使用 idx_PART_KEY_VAL 索引，按这个数值计算，查询条件为 day&gt;=2021-12-21 and day&lt;2021-12-26 的查询需要检索将近 160w 条数据，这显然不是一个很好的执行计划。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">若执行计划不走 idx_PART_KEY_VAL 索引，TiDB 可通过 dbs、tbls 检索出所有关联 partition 数据，在根据 part_id 和过滤条件扫描 PARTITION_KEY_VALS 数据并返回。此类执行计划扫描的数据量和需要查询的表的分区总量有关，如果该表只有少数的分区，则查询能够迅速响应，但如果查询的表有上百万的分区，则该类执行计划对于该类查询不是最优解。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.2675925925925926" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/97b2badc-d7bd-4e82-872c-cdfbed8555cd.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">不走 idx_PART_KEY_VAL 索引执行计划</span></p><section powered-by="xiumi.us"><p><br></p><p>针对不同执行计划的特性，整理了以下对比点：</p></section><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.2995910020449898" data-s="300,640" data-type="png" data-w="978" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/393b4adf-34c3-4685-9d35-3002044f44b6.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在实际生产中元数据基本都是按天分区为主，每天增长大概有 26w 左右，且范围查询的使用场景较多，使用 idx_PART_KEY_VAL 索引查询的执行计划不太适合线上场景，故该索引需不适合添加到线上环境。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.3 TiDB 内存突增导致宕机问题</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在刚上线 TiDB 服务初期，曾数次面临 TiDB 内存溢出的问题，每次出现的时间都随机不确定，出现的时候内存突增几乎在一瞬间，若期间 TiDB 的内存抗住了突增量，突增部分内存释放在很长时间都不会得到释放，最终对 HMS 服务稳定性带来抖动。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4034833091436865" data-s="300,640" data-type="png" data-w="689" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/8844c991-06f3-4ca0-aab6-3d42df20759e.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB 内存突增情况</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通过和 TiDB 开发、DBA 联合分析下，确认 TiDB 内存飙高的原因为用户在使用 Dashboard 功能分析慢查询引起；在分析慢查询过程中，TiDB 需要加载本地所有的 slow-query 日志到内存，如果这些日志过大，则会造成 TiDB 内存突增，此外，如果在分析期间，用户点击了取消按钮，则有可能会造成 TiDB 的内存泄漏。针对该问题制定如下解决方案：</p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: justify;line-height: 1.8;padding-right: 5px;padding-left: 5px;" powered-by="xiumi.us"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p>使用大内存机器替换原小内存机器，避免分析慢查询时内存不够</p></li><li><p>调大慢查询阈值为 3s，减少日志产生</p></li><li><p>定时 mv 慢查询日志到备份目录</p></li></ol></section></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.4 locate 函数查询不走索引导致 TiKV 负异常</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在 HMS 中存在部分通过 JDO 的方式去获取分区的查询，该类查询的过滤条件中用 locate 函数过滤 PART_NAME 数据，在 TiDB 中通过函数作用在字段中是不会触发索引查询的，所以在该类查询会加载对应表的所有数据到 TiDB 端计算过滤，TiKV 则需不断扫描全表并传输数据到 TiDB 段，从而导致 TiKV 负载异常。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.43148148148148147" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/0c22e9c9-f38c-4dec-b58b-d35a9460e937.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">locate 函数导致全表扫描</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">然而上述的查询条件可以通过 like 方式去实现，通过使用 like 语法，查询可以成功使用到 PARTITIONS 表的 UNIQUEPARTITION 索引过滤，进而在 TiKV 端进行索引过滤降低负载。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.45" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/35186c1a-9fcf-43a9-a5a0-7d7fa3ca1690.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;"><span style="font-size: 14px;color: rgb(136, 136, 136);">like 语法走索引过滤</span></span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通过实现将 locate 函数查询转换为 like 语法查询，有效降低了 TiKV 端的负载情况。在 HMS 端完成变更后，TiKV 的 CPU 使用率降低了将近一倍，由于在 KV 端进行索引过滤，相应的 io 使用率有所上升，但网络传输则有明显的下降，由平均 1G 降低到 200M 左右。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.34814814814814815" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d6a4e572-c45f-424b-b9bc-a589fae353c2.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">变更前后 TiKV 的负载情况</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">除 TiKV 负载有明显的降低，TiDB 的整体性能也得到明显的提升，各项操作耗时呈量级降低。以下整理了 TiDB 增删改查的天平均耗时情况：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.5666666666666667" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3a73735-d7f8-4d13-ac94-5deb12749daa.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB P999 天平均耗时统计</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.5 get_all_functions 优化</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">随着 hive udf 的不断增长，HMS 的 get_all_functions api 平均耗时增长的也越来越久，平均在 40-90s，而该 api 在 hive shell 中首次执行查询操作时会被调用注册所有的 udf，过长的耗时会影响用户对 hive 引擎的使用体验，例如执行简单的 show database 需要等待一分钟甚至更久才能返回结果。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.3824074074074074" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/4b18f10c-d130-4c26-8213-44b30511d29c.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="color: rgb(136, 136, 136);font-size: 14px;">原 get_all_functions api 平均耗时</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">导致该 api 耗时严重的主要原因是 HMS 通过 JDO 方式获取所有的 Function，在获取所有的 udf 时后台会遍历每条 func 去关联 DBS、FUNC_RU 两个表，获取性能极低。而使用 directSQL 的方式去获取所有 udf 数据，响应耗时都在 1 秒以内完成，性能提升相当明显。以下为 directSQL 的 SQL 实现逻辑：</p><p powered-by="xiumi.us"><br></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__keyword">select</span> FUNCS.FUNC_NAME,</span></code><code><span class="code-snippet_outer">  DBS.NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.CLASS_NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.OWNER_NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.OWNER_TYPE,</span></code><code><span class="code-snippet_outer">  FUNCS.CREATE_TIME,</span></code><code><span class="code-snippet_outer">  FUNCS.FUNC_TYPE,</span></code><code><span class="code-snippet_outer">  FUNC_RU.RESOURCE_URI,</span></code><code><span class="code-snippet_outer">  FUNC_RU.RESOURCE_TYPE</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> FUNCS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">left</span><span class="code-snippet__keyword">join</span> FUNC_RU <span class="code-snippet__keyword">on</span> FUNCS.FUNC_ID = FUNC_RU.FUNC_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">left</span><span class="code-snippet__keyword">join</span> DBS <span class="code-snippet__keyword">on</span> FUNCS.DB_ID = DBS.DB_ID</span></code></pre></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>五、总结</p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>我们从 2021 年 7 月份开始对 TiDB 进行调研，在经历数个月的测试于同年 11 月末将 MySQL 引擎切换到 TiDB。由于前期测试主要集中在兼容性和性能测试上，忽略了 TiDB 自身可能潜在的问题，在上线初期经历了数次因慢查询日志将 TiDB 内存打爆的情况，在这特别感谢我们的 DBA 团队、平台运营团队及 TiDB 官方团队帮忙分析、解决问题，得以避免该问题的再次发生；与此同时，由于当前 HMS 使用的版本较低，加上大数据的组件在不断的升级演进，我们也需要去兼容升级带来的变动，如 HDFS 升级到 3.x 后对 EC 文件读取的支持，SPARK 获取分区避免全表扫描改造等；此外由于 TiDB 的 latin 字符集支持中文字符的写入，该特性会导致用户误写入错误的中文分区，对于此类型数据无法通过现有 API 进行删除，还需要在应用层去禁止该类型错误分区写入，避免无用数据累积。</p><p><br></p><p>经历了一年多的实际生产环境检验，TiDB 内存整体使用在 10% 以内，TiKV CPU 使用平稳，使用峰值均在 30 核内，暂不存在系统瓶颈；HMS 服务的稳定性整体可控，关键 API 性能指标满足业务的实际需求，为业务的增长提供可靠支持。在未来三年内，我们将保持该架构去支撑整个大数据平台组件的稳定运行，期间我们也将持续关注行业内的变动，吸收更多优秀经验应用到我们的生产环境中来，包括但不限于对性能更好的高版本 TiDB 尝试，HMS 的性能优化案例。</p></section><p powered-by="xiumi.us"><br></p><section style="margin-right: 0%;margin-bottom: 20px;margin-left: 0%;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: middle;width: 20%;align-self: center;flex: 0 0 auto;"><section style="text-align: center;color: rgb(45, 66, 87);font-size: 11px;" powered-by="xiumi.us"><p>END</p></section></section><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="margin-top: 10px;margin-bottom: 10px;text-align: left;" powered-by="xiumi.us"><section style="padding-left: 1em;padding-right: 1em;display: inline-block;text-align: center;"><span style="display: inline-block;padding: 0.3em 0.5em;border-radius: 0.5em;background-color: rgb(65, 94, 255);color: rgb(255, 255, 255);" title="" opera-tn-ra-cell="_$.pages:0.layers:0.comps:129.title1"><p>猜你喜欢</p></span></section><section style="border-width: 1px;border-style: solid;border-color: transparent;margin-top: -1em;padding: 20px 10px 10px;background-color: rgb(239, 239, 239);text-align: center;"><section style="font-size: 14px;text-align: left;" powered-by="xiumi.us"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497299%26idx%3D1%26sn%3Dbf5b4b07d96090267e996a1dc3d0dce1%26chksm%3Debdb86c1dcac0fd7b7b662020ec78a154c8011be6cd0d6b19c091fa1befbc5f79ff45890b45b%26scene%3D21%23wechat_redirect" textvalue="vivo 数据中心网络链路质量监测的探索实践" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">vivo 数据中心网络链路质量监测的探索实践</a></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497274%26idx%3D1%26sn%3Db79ed12d3854f14a7e77eaae5f0de6b2%26chksm%3Debdb86a8dcac0fbe9743c35887bbf6299506aa490bfcd220b4872d506152ee1dcc4c5b45799a%26scene%3D21%23wechat_redirect" textvalue="K8s 多集群实践思考和探索" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">K8s 多集群实践思考和探索</a></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497145%26idx%3D2%26sn%3D55519f4b73ff9b4a0d19ce6d0ac09a30%26chksm%3Debdb852bdcac0c3d0eb7fdc587942aa7203c63d04f6fefcd688a7a0f0bbaf8288479372695f6%26scene%3D21%23wechat_redirect" textvalue="JVM 内存大对象监控和优化实践" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">JVM 内存大对象监控和优化实践</a></p></li></ul></section></section></section><p powered-by="xiumi.us"><br></p><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互联网技术" data-alias="vivoVMIC" data-signature="分享 vivo 互联网技术干货与沙龙活动，推荐最新行业动态与热门会议。" data-from="0"></mp-common-profile></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - vivo 互联网技术（vivoVMIC）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/10114822</guid>
            <link>https://my.oschina.net/vivotech/blog/10114822</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果 App Store 免费榜第一是黄色软件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>澎湃新闻今日报道苹果 App Store 出现伪装成学习软件的黄色软件，并且冲上了「免费 App」排行榜第一名。</p><p>据悉，该软件的年龄分级为 4 岁以上，但是会引导用户进入赌博和其他黄色网站。网友小同表示，他下载了这款软件，想要学习英语字母，结果发现是一个色情视频软件。他认为这种伪装成学习软件的行为很危险，很容易对孩子造成不良影响。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c7a0ce5e4272f1b06c5119529647215fb11.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-69f6205b4eceb10672c0a3cff67e4f52d48.png" referrerpolicy="no-referrer"></p><p>事件被曝光后，苹果客服虽然进行了回应，但直到下午仍未下架软件。甚至排行榜更新后，App Store 免费榜第一、二名再次出现黄色软件，名为「骑 XX」、「牡丹 XXX」，年龄分级为 4 岁以上。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8b7f27342ea504c47ae6724514736b106a3.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-db2cf9f1307034d7e3a68e35ea067a0fe4f.png" referrerpolicy="no-referrer"></p><p><strong style="color:#424242">截至发稿，这些软件已被下架</strong><span style="background-color:#ffffff; color:#424242">。</span></p><p><span style="background-color:#ffffff; color:#424242">众所周知，苹果应用商店的审核规则极为严格。</span>上面提到的 App 其实就是浏览器套壳，前端显示的内容可以通过后台随意修改。但问题在于，苹果 App 的审核团队为何让这些「套壳」 App 上架到了应用商店？</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 14:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260711</guid>
            <link>https://www.oschina.net/news/260711</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[VS Code 的 C# 开发套件 (C# Dev Kit) 正式 GA]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今年 6 月，微软在 Visual Studio Code 的插件市场<a href="https://www.oschina.net/news/244148/c-sharp-dev-kit-for-visual-studio-code" target="_blank">上架</a>了官方打造的<strong> C# 开发套件 —— C# Dev Kit</strong>，让开发者在 VS Code 中方便地进行 C# 开发。</p><p>据介绍，C# Dev Kit 提高了开发者在使用 VS Code 过程中开发 C# 语言产品的效率。该套件兼容 C# 扩展，由语言服务器协议&nbsp; (LSP) 主机提供支持，从而创建一个高性能、可扩展且灵活的工具环境，可轻松将新体验集成到 C# for VS Code 中。</p><p>经过 4 个多月的测试和打磨，微软近日宣布&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fcsharp-dev-kit-now-generally-available%2F" target="_blank"><strong>C# Dev Kit 正式 GA</strong></a>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-abd88ca70f16b7de5318e2944c0f5c847dd.png" referrerpolicy="no-referrer"></p><p>微软表示在预览版期间，累计为 C# Dev Kit 修复了 350 多个问题，其中大部分由社区报告，并对该产品进行了 300 多项有针对性的改进。</p><p>微软称用户的反馈加速推进了 C# Dev Kit 的正式发布，开发团队会继续提升性能和可靠性，并将每月添加新功能。</p><p>根据微软的介绍，C# Dev Kit 从 Visual Studio 中借用了一些开发者们熟悉的概念，并能够与现有的 C# 扩展一起使用，以及通过增加一套强大的工具和实用程序来增强 C# 开发环境，这些工具和实用程序与 VS Code 原生集成，以帮助 C# 开发者更快地编写、调试和维护他们的代码，并减少错误。</p><p>C# Dev Kit 由以下部分组成：</p><ul><li><strong>C# 扩展</strong>：它提供基本的语言服务支持，并继续独立于这项工作进行维护；</li><li><strong>C# Dev Kit 扩展</strong>：它建立在 Visual Studio 的基础上，提供解决方案管理、模板、测试、调试；</li><li><strong>IntelliCode for C# Dev Kit 扩展</strong>：它将 AI 驱动的开发带到了编辑器中；</li></ul><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0607/112538_up8O_4937141.png" referrerpolicy="no-referrer"></p><p><strong><a href="https://www.oschina.net/news/244148/c-sharp-dev-kit-for-visual-studio-code" target="_blank">点此查看详细介绍</a></strong>。</p><p>C# Dev Kit 下载地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3Dms-dotnettools.csdevkit%26ssr%3Dfalse" target="_blank">https://marketplace.visualstudio.com/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260688/vs-code-csharp-dev-kit-ga</guid>
            <link>https://www.oschina.net/news/260688/vs-code-csharp-dev-kit-ga</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Docker 与 Neo4j 等合作推出 GenAI Stack]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Docker 在其年度 DockerCon 开发者大会主题演讲中<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fintroducing-a-new-genai-stack%2F" target="_blank">宣布</a>与 Neo4j、LangChain 和 Ollama 合作推出新的 GenAI Stack。该 GenAI Stack <span style="background-color:#ffffff">简化了 AI/ML 集成，</span>旨在帮助开发人员快速轻松地构建生成式 AI 应用程序，而无需搜索和配置各种技术。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-0852df0e6f3480e6f6d1ddd240cf679021f.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">根据介绍，GenAI Stack 中包含的内容包括有：</span></p><ul><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>预配置的 LLM</strong>：提供预配置的大语言模型 (LLM)，例如 Llama2、GPT-3.5 和 GPT-4，以快速启动 AI 项目。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Ollama&nbsp;管理</strong>：Ollama 简化了开源 LLM 的本地管理，让你的 AI 开发过程更加顺畅。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Neo4j 作为默认数据库</strong>：Neo4j 作为默认数据库，提供图形和原生向量搜索功能。这有助于揭示数据模式和关系，最终提高 AI/ML 模型的速度和准确性。Neo4j 还充当这些模型的长期存储器。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Neo4j 知识图谱</strong>：Neo4j 知识图谱为 LLM 提供更精确的 GenAI 预测和结果。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>LangChain 编排</strong>：LangChain 促进了 LLM、应用程序和数据库之间的通信，并提供了一个强大的向量索引。LangChain 是一个用于开发由 LLM 支持的应用程序的框架。其中包括 LangSmith，一种调试、测试、评估和监控 LLM 应用程序的新方法。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>全面支持</strong>：提供了一系列有用的工具、代码模板、操作指南和 GenAI 最佳实践。</span></span></li></ul><p><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-346a6330b9b20f9dbd5753904b2051aeda1.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">此外，该公司还通过</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fai-early-access-program%2F" target="_blank">抢先体验计划</a><span style="color:#000000">推出了一款新的生成式 AI 助手，名为 Docker AI。&nbsp;Docker 首席执行官 Scott Johnston 表示，与 Copilot 或&nbsp;Amazon&nbsp;CodeWhisperer 等其他代码生成助手相比，Docker AI 助手可以帮助开发人员定义应用程序的各个方面并排除故障。</span></p><p><span style="color:#000000">"当开发人员编辑 Dockerfile 或 Docker Compose 文件、调试本地 docker build 或在本地运行测试时，Docker AI 会根据具体情况提供自动指导。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 09:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260683/docker-genai-stack</guid>
            <link>https://www.oschina.net/news/260683/docker-genai-stack</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 23.10 将正式支持 Raspberry Pi 5]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根据 omgubuntu 的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F10%2Fubuntu-23-10-will-support-raspberry-pi-5" target="_blank">报道</a>，即将发布的 Ubuntu 23.10 会正式支持<a href="https://www.oschina.net/news/259858/introducing-raspberry-pi-5" target="_blank">树莓派 5</a>。</p><blockquote><p style="margin-left:0px; margin-right:0px; text-align:start"><strong>延伸阅读：<a href="https://www.oschina.net/news/259858/introducing-raspberry-pi-5" target="_blank">Raspberry Pi 5 将于 10 月底发布，60 美元起售</a></strong></p></blockquote><p>报道指出，由于 Canonical 开发者可以提前使用树莓派 5，因此他们能够在设备上测试即将发布的 Ubuntu 版本，确定需要支持新硬件的领域，并将所需的新（和已升级）软件包放入 file_Feature Freeze Exceptions_to （文件_功能冻结异常_队列）中。</p><p>部分针对树莓派 5 的改进包括：引入新的&nbsp;<code>pisp</code>&nbsp;包来处理树莓派 5 大大增强的相机功能；并对&nbsp;<code>python3-gpiozero</code>&nbsp;进行重大更新，以符合新型号对其 GPIO 操作所做的更改。</p><p>另外要注意的是，更新的 rpiboot 软件包将无法在 Ubuntu 23.10 发布时及时提供，但由于这不是严格要求的，所以问题不大。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 07:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260645/ubuntu-23-10-will-support-raspberry-pi-5</guid>
            <link>https://www.oschina.net/news/260645/ubuntu-23-10-will-support-raspberry-pi-5</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里云 PAI - 灵骏大模型训练工具 Pai-Megatron-Patch 正式开源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h3_1"></span><h3>Pai-Megatron-Patch 是什么</h3><p style="text-align:justify">Pai-Megatron-Patch 工具是阿里云机器学习平台 PAI 算法团队研发，基于阿里云智算服务 PAI-灵骏平台的大模型最佳实践解决方案配套工具，旨在帮助大模型开发者快速上手灵骏产品，完成大语言模型（LLM）的高效分布式训练，有监督指令微调，模型离线推理验证等完整大模型开发链路。该项目提供了业界主流开源大模型基于 Megatron-LM 的训练&amp;离线推理验证流程，方便用户快速上手大模型训练。</p><span id="OSC_h3_2"></span><h3>主要特性</h3><ul><li>多款热门大模型支持：llama，llama-2，codellama, 百川，通义千问，Falcon，GLM，Starcoder，Bloom，chatglm 等</li><li>支持模型权重互转转换：在 Huggingface，Megatron 和 Transformer Engine 之间进行算子命名空间映射</li><li>支持 Flash Attention 2.0 和 Transformer Engine 模式下的 FP8 训练加速且确保收敛</li><li>丰富且简单易用的使用示例，支持大模型预训练，微调，评估和推理，强化学习全流程最佳实践</li></ul><span id="OSC_h3_3"></span><h3>开源地址</h3><p style="text-align:justify"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%253Fspm%253Da2c6h.13046898.publish-article.3.5d586ffa9uOzwk" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a></p><span id="OSC_h3_4"></span><h3>技术架构</h3><p style="text-align:justify">Pai-Megatron-Patch 的设计理念是不对 Megatron-LM 的源码进行侵入式修改，即不在 Megatron-LM 里面添加新的功能特性，将需要扩充完善的部分以 patch 补丁的方式呈现。在 patch 中构建 LLM 训练链路通过依赖 Megatron-LM 核心库的方法实现和 Megatron-LM 的解耦合。这样解耦合的好处就是 Megatron-LM 的升级不会影响用户的 LLM 最佳实践体验。</p><p style="text-align:justify">Pai-Megatron-Patch 中包含模型库，分词器，模型转换，强化学习，离线文本生成以及使用示例和工具集等用于构建 LLM 训练的关键要素。在模型库中包含热门大模型的 Megatron 版本实现，例如 baichuan，bloom，chatglm，falcon，galactica，glm，llama，qwen 和 starcoder，后续还会根据需要及时添加新的 Megatron 版大模型实现。同时 patch 还提供了 huggingface 模型权重和 Megatron 模型权重之间的双向转换。一方面是方便用户加载 huggingface 的权重在 Megatron 中继续预训练或者微调，另一方面是方便用户对训练好的 Megatron 模型使用 huggingface 的评估/推理流程对模型质量进行客观评估。在强化学习部分，patch 提供了 PPO 训练流程等，方便用户使用 SFT 模型和 RM 模型进行强化学习。最后 patch 提供了大量的使用示例帮助用户快速开始大模型训练&amp;离线推理。具体请参考阿里云灵骏产品的使用流程:&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F2505831.html%253Fspm%253Da2c6h.13046898.publish-article.4.5d586ffa9uOzwk%2526tab%253Donestop" target="_blank">智算服务 PAI 灵骏大模型分布式训练方案</a></p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-2459be9f4c59a8fd9ac6472cd888c176_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h3_5"></span><h3>关键技术</h3><span id="OSC_h4_6"></span><h4>模型权重转换</h4><p style="text-align:justify">研发 Megatron-Patch 的初衷之一就是能将世界各地研发机构在 Huggingface 上放出的热门大模型使用 Megatron 引擎进行继续预训练或者继续微调。这就需要首先将 Huggingface 模型格式的 ckpt 转换成 Megatron 模型格式，才能正确加载进来，否则会出现 pytorch 加载模型失败。Megatron-Patch 的一个核心可靠性保障特征就是在采用算子拆分，流水并行，序列并行，Zero 显存优化，BF16 混合精度，梯度检查点等训练加速技术确保模型训练吞吐速度平均提升 1.5 倍以上的同时，在评估任务模式下的单一样本前向 loss 值，预训练/微调任务模式下的 loss 曲线，离线文本生成任务模式下的生成效果这三个方面和 Huggingface 是对齐的，从而确保 Megatron 版模型的可靠性。</p><p style="text-align:justify">另一方面，Megatron 版的 transformer 实现方式提供了一种让用户仅仅通过设置开关就能实现不同种类 GPT 模式的能力。比如 llama 模型打开如下开关即可</p><pre><code>--swiglu \
  --use-rotary-position-embeddings \
  --no-position-embedding \
  --untie-embeddings-and-output-weights \
  --disable-bias-linear</code></pre><p style="text-align:justify">如果想将 llama 模式变成 baichuan 模型，那么仅仅需要添加采用--use-alibi-mask 开关，同时关闭 Rotary Embeeding 开关即可，具体配置如下所示：</p><pre><code>--swiglu \
  --use-alibi-mask \
  --position-embedding-type none \
  --untie-embeddings-and-output-weights \
  --disable-bias-linear</code></pre><p style="text-align:justify">下面我们以 llama-2 为例，详解从 huggingface 到 megatron 的模型权重转换技术。下表总结了两者在不同 module 上的命名对应关系。在 patch 实现过程中，我们首先将 HF 格式的 ckpt 转换到一种内部格式，然后再把这种内部格式转换成对应的外部格式。这样做可以最大程度复用已有的转换逻辑来处理新模型。在转换为内部格式的过程中，</p><p style="text-align:justify">q_proj, k_proj, v_proj 需要沿着第 0 维拼接在一起后赋值给内部变量 query_key_value。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-e3637f10e008e7548046df938ee8bac6_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">当用户在资源受限情况下需要按照 TP&gt;1 来拆分权重的时候，这里需要注意的是针对 MLP 层的 gate_proj 和 up_proj 的操作。不能像 qkv 那样在转换成内部格式的时候进行 merge 再执行算子拆分。需要在拆分前加入如下针对 MLP 层的权重合并的代码逻辑才能确保正确收敛。</p><pre><code>for i in range(tp_size):
    params_dict = get_element_from_dict_by_path(output_state_dict[i],
                                                "model.language_model.encoder")
    dense_h_to_4h_1_name = 'mlp.dense_h_to_4h_1.weight'
    dense_h_to_4h_1_layer_name = f"layers.{layer}.{dense_h_to_4h_1_name}"
    dense_h_to_4h_1_weight = params_dict[dense_h_to_4h_1_layer_name]
    dense_h_to_4h_2_name = 'mlp.dense_h_to_4h_2.weight'
    dense_h_to_4h_2_layer_name = f"layers.{layer}.{dense_h_to_4h_2_name}"
    dense_h_to_4h_2_weight = params_dict[dense_h_to_4h_2_layer_name]
    dense_h_to_4h_name = 'mlp.dense_h_to_4h.weight'
    dense_h_to_4h_layer_name = f"layers.{layer}.{dense_h_to_4h_name}"
    params_dict[dense_h_to_4h_layer_name] = torch.cat(
    [dense_h_to_4h_1_weight, dense_h_to_4h_2_weight], dim=0)</code></pre><span id="OSC_h4_7"></span><h4>基于 TE 的 FP8 训练收敛</h4><p style="text-align:justify">Transformer Engine(TE) 是一个在英伟达 GPUS 上运行的针对 Transformer 模型的加速库，其中包括针对 Hopper GPU 的 FP8 混合精度，该精度可以在较低的显存利用率下提供更好的训练&amp;推理速度。在 TE 内部封装了 Flash Attention 实现，同时 TE 还提供了一组高度优化后的算子用来构建 Transformer 模型。比如 LayerNormLinear 就是将 LayerNorm 和 QKV-Proojection 进行算子融合，LayerNormMLP 就是将 layernorm 和 mlp 进行算子融合。如下图所示：</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-214b47fb7b967d3f92dd7dd58092446b_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">从 Huggingface 到 TE 模型的权重转换技术和之前是类似的，也需要事先找到两者之间的映射关系。从下表可以看出，TE 中多了_extra_state 是用来存 fp8 训练的 scale 和 history 的，这些在加载的时候会出现冲突，这时只要将 load_state_dict 函数的 strict 设置成 False 就可以了，比如 load_state_dict(state_dict_, strict=False)。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-125038fa0f82beec327ee0234b3b79c2_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">在 Megatron-Patch 中使用示例中打开 FP8 混合精度训练开关也很容易，如下所示：</p><pre><code>if [ $PR = fp16 ]; then
    pr_options=" \
        --fp16"
elif [ $PR = bf16 ]; then
    pr_options=" \
        --bf16"
elif [ $PR = fp8 ]; then
    pr_options=" \
        --bf16
        --fp8-hybrid \
        --fp8-amax-compute-algo max \
        --fp8-amax-history-len 1024 \
        --transformer-impl transformer_engine"
fi</code></pre><p style="text-align:justify">我们可以使用如下训练脚本<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fgpt3_llama%2Frun_pretrain_megatron_llama_enwiki.sh%253Fspm%253Da2c6h.13046898.publish-article.5.5d586ffa9uOzwk%2526file%253Drun_pretrain_megatron_llama_enwiki.sh" target="_blank">run_pretrain_megatron_llama_enwiki.sh</a>来测试打开 FP8 开关后的预训练收敛性。下图展示了 llama-7B 和 llama-2-70B 模型在打开和关闭 FP8 时的 loss 曲线对比，可以看出基本是重合的。</p><p style="text-align:justify">LLama-7B</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-6b4c07368bdeb4e3c80251d6972511f1_720w.webp" referrerpolicy="no-referrer"></p><p>LLama2-70B</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-6ed82c26ed8ee7661a913687e7905a6b_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_8"></span><h4>大模型训练&amp;推理</h4><p style="text-align:justify">从 github 上获取 Megatron 模型训练工具 PAI-Megatron-Patch（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%253Fspm%253Da2c6h.13046898.publish-article.6.5d586ffa9uOzwk" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a>）源代码并拷贝到工作目录/mnt/workspace/下。</p><p style="text-align:justify"><strong>模型格式转换</strong></p><p style="text-align:justify">使用我们提供的模型转换脚本，将 huggingface 格式的模型文件转换为 megatron 格式：</p><pre><code>cd /mnt/workspace/
mkdir llama2-ckpts
cd llama2-ckpts
wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-ckpts/Llama-2-7b-hf.tgz
tar -zxf Llama-2-7b-hf.tgz
mv Llama-2-7b-hf llama2-7b-hf
cd /mnt/workspace/PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/llama
sh model_convertor.sh \
/root/Megatron-LM-23.04        \
/mnt/workspace/llama2-ckpts/llama2-7b-hf         \
/mnt/workspace/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1  \
1  \
1  \
llama-7b \
0 \
false</code></pre><p style="text-align:justify"><strong>继续预训练</strong></p><p style="text-align:justify">中文继续预训练汉化指引</p><p style="text-align:justify">Step1: 获取需要扩充词表的模型（如 llama-13b-hf）</p><p style="text-align:justify">Step2: 获取需要扩充的词表</p><ul><li>使用 sentence-piece 代码库从自有文本语料中学习词表，得到 randeng-sp.model 文件</li></ul><p style="text-align:justify">Step3: 词表扩充</p><ul><li>扩充模型 tokenizer：将 randeng-sp.model 中的词表添加到 llama-13b-hf 文件夹下 tokenizer.model 中</li><li>扩充模型词表对应的参数矩阵 
  <ul><li>word_embedding、lm_head</li><li>新词向量可以使用原词向量均值作为初始化，比如「天气」=mean([「天」，「气」])</li></ul></li><li>修改与词表大小相关的文件并保存，如 config.json</li></ul><p style="text-align:justify">运行继续预训练脚本&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fllama2%2Frun_pretrain_megatron_llama.sh%253Fspm%253Da2c6h.13046898.publish-article.7.5d586ffa9uOzwk%2526file%253Drun_pretrain_megatron_llama.sh" target="_blank">run_pretrain_megatron_llama.sh</a>，需要传入的参数列表如下</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
MODEL_SIZE=$4                   # 模型结构参数量级：7B, 13B
BATCH_SIZE=$5                   # 每卡训练一次迭代样本数: 4, 8
GLOBAL_BATCH_SIZE=$6            # 全局 batch size
LR=$7                           # 学习率: 1e-5, 5e-5
MIN_LR=$8                       # 最小学习率: 1e-6, 5e-6
SEQ_LEN=$9                      # 序列长度
PAD_LEN=${10}                   # Padding 长度：100
EXTRA_VOCAB_SIZE=${11}          # 词表扩充大小
PR=${12}                        # 训练精度: fp16, bf16
TP=${13}                        # 模型并行度
PP=${14}                        # 流水并行度
AC=${15}                        # 激活检查点模式: sel, full
DO=${16}                        # 是否使用 Megatron 版 Zero-1 降显存优化器: true, false
FL=${17}                        # 是否使用 Flash Attention: true, false
SP=${18}                        # 是否使用序列并行: true, false
SAVE_INTERVAL=${19}             # 保存 ckpt 的间隔
DATASET_PATH=${20}              # 训练数据集路径
PRETRAIN_CHECKPOINT_PATH=${21}  # 预训练模型路径
TRAIN_TOKENS=${22}              # 训练 token 数
WARMUP_TOKENS=${23}             # 预热 token 数
OUTPUT_BASEPATH=${24}           # 训练输出文件路径</code></pre><p style="text-align:justify">注意设置正确的数据集<strong>挂载路径 WORK_DIR</strong>以及<strong>运行环境 ENV</strong>，运行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_pretrain_megatron_llama.sh \
dlc \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B   \
1    \
16 \
1e-5   \
1e-6   \
2048  \
80  \
0   \
fp16  \
1   \
1  \
sel  \
true   \
false  \
false   \
100000  \
${WORK_DIR}/llama2-datasets/wudao/wudao_llamabpe_text_document   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
100000000   \
10000   \
${WORK_DIR}/output_megatron_llama2/</code></pre><p style="text-align:justify"><strong>有监督微调</strong></p><p style="text-align:justify">在微调开始之前，请先进入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Ftoolkits%2Fpretrain_data_preprocessing%2FREADME.md%253Fspm%253Da2c6h.13046898.publish-article.8.5d586ffa9uOzwk%2526file%253DREADME.md" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch/blob/main/toolkits/pretrain_data_preprocessing/README.md</a>&nbsp;获取 json 文件。运行<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fllama2%2Frun_finetune_megatron_llama.sh%253Fspm%253Da2c6h.13046898.publish-article.9.5d586ffa9uOzwk%2526file%253Drun_finetune_megatron_llama.sh" target="_blank">run_finetune_megatron_llama.sh</a>脚本，需要传入的参数列表如下</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
MODEL_SIZE=$4                   # 模型结构参数量级: 7B, 13B
BATCH_SIZE=$5                   # 每卡训练一次迭代样本数: 4, 8
LR=$6                           # 学习率: 1e-5, 5e-5
MIN_LR=$7                       # 最小学习率: 1e-6, 5e-6
SEQ_LEN=$8                      # 序列长度
PAD_LEN=$9                      # Padding 长度：100
EXTRA_VOCAB_SIZE=${10}          # 词表扩充大小
PR=${11}                        # 训练精度: fp16, bf16
TP=${12}                        # 模型并行度
PP=${13}                        # 流水并行度
AC=${14}                        # 激活检查点模式: sel, full
DO=${15}                        # 是否使用 Megatron 版 Zero-1 降显存优化器: true, false
FL=${16}                        # 是否使用 Flash Attention: true, false
SP=${17}                        # 是否使用序列并行: true, false
TRAIN_DATASET_PATH=${18}        # 训练数据集路径
VALID_DATASET_PATH=${19}        # 验证数据集路径
PRETRAIN_CHECKPOINT_PATH=${20}  # 预训练模型路径
EPOCH=${21}                     # 训练迭代轮次
OUTPUT_BASEPATH=${22}           # 训练输出文件路径</code></pre><p style="text-align:justify">多节点运行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
sh run_finetune_megatron_llama.sh  \
dlc    \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B     \
1      \
1e-5   \
1e-6   \
2048   \
80     \
0      \
fp16   \
1      \
1      \
sel    \
true   \
false  \
false  \
${WORK_DIR}/llama2-datasets/wudao_train.json   \
${WORK_DIR}/llama2-datasets/wudao_valid.json   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
2   \
${WORK_DIR}/output_megatron_llama2/
</code></pre><p style="text-align:justify"><strong>离线推理</strong></p><p style="text-align:justify">模型训练完成后，可以进行离线推理，评估模型效果。根据上面的训练流程不同，我们提供了 Megatron 格式的推理链路。对于 Megatron 训练的模型，可以直接用 Megatron 框架进行推理。</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
CHECKPOINT_PATH=$4              # 模型微调阶段的模型保存路径
MODEL_SIZE=$5                   # 模型结构参数量级: 1.1B, 1.7B, 7.1B
TP=$6                           # 模型并行度
BS=$7                           # 每卡推理一次迭代样本数: 1, 4, 8
SEQ_LEN=$8                      # 序列长度: 256, 512, 1024
PAD_LEN=$9                      # PAD 长度：需要将文本拼接到的长度
EXTRA_VOCAB_SIZE=${10}          # 模型转换时增加的 token 数量
PR=${11}                        # 推理采用的精度: fp16, bf16
TOP_K=${12}                     # 采样策略中选择排在前面的候选词数量 (0-n): 0, 5, 10, 20
INPUT_SEQ_LEN=${13}             # 输入序列长度: 512
OUTPUT_SEQ_LEN=${14}            # 输出序列长度: 256
INPUT_FILE=${15}                # 需要推理的文本文件: input.txt, 每行为一个样本
OUTPUT_FILE=${16}               # 推理输出的文件: output.txt
# TOP_K 和 TOP_P 必须有一个为 0
TOP_P=${17}                     # 采样策略中选择排在前面的候选词百分比 (0-1): 0, 0.85, 0.95
TEMPERATURE=${18}               # 采样策略中温度惩罚: 1-n
REPETITION_PENALTY=${19}        # 避免生成是产生大量重复，可以设置为 (1-2) 默认为 1.2</code></pre><ul><li>此处提供一个离线推理输出的文件，推理的数据组织形式需要与微调时的保持一致。 
  <ul><li>测试样本：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fatp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com%2Frelease%2Fmodels%2Fpai-megatron-patch%2Fllama2-datasets%2Fpred_input.jsonl%253Fspm%253Da2c6h.13046898.publish-article.10.5d586ffa9uOzwk%2526file%253Dpred_input.jsonl" target="_blank">https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-datasets/pred_input.jsonl</a></li></ul></li><li>注意： 
  <ul><li>模型保存的路径下缺少 tokenizer 依赖的文件，需要将微调前模型路径下所有 json 文件及 tokenizer.model 拷贝至保存模型的路径下（位于{OUTPUT_BASEPATH }/checkpoint），与 latest_checkpointed_iteration.txt 同级。</li></ul></li></ul><p style="text-align:justify">以下有监督微调过程保存模型的推理代码，需要将 run_text_generation_megatron_llama.sh 脚本中 CUDA_VISIBLE_DEVICES 参数设置为 0；GPUS_PER_NODE 参数设置为 1；同时使用下列代码进行推理。此时使用单卡进行推理。<strong>注意：此处模型 tp 为 1，可使用单卡推理；如果 tp&gt;1，则需使用相应卡数进行推理。</strong></p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_text_generation_megatron_llama.sh \
dsw \
/root/Megatron-LM-23.04 \
${WORK_DIR}/PAI-Megatron-Patch \
../../../llama2-train \
7B \
1 \
1 \
1024 \
1024 \
0 \
fp16 \
10 \
512 \
512 \
${WORK_DIR}/pred_input.jsonl \
${WORK_DIR}/llama2_pred.txt \
0 \
1.0 \
1.2</code></pre><span id="OSC_h4_9"></span><h4>大模型强化学习</h4><p style="text-align:justify">一般来说，SFT 微调过的模型在对话场景已经会有不错的表现了。如果想进一步提升模型效果，可以再加上 RLHF 训练。包括奖励模型（Reward Model）的训练和强化学习（PPO）的训练。这里展示了如何使用当前最常用的 RLHF 开源代码框架，DeepSpeed-Chat 和 trlx，来进行奖励函数训练（RM），以及强化学习优化（PPO）。</p><p style="text-align:justify"><strong>模型格式转换</strong></p><p style="text-align:justify">如果基于 huggingface 格式的模型直接进行奖励模型训练（RM）和强化学习优化（PPO），可以跳过此步骤。</p><p style="text-align:justify">如果基于 Megatron 格式的模型，如 PAI-Megatron-Patch 训练好的 SFT 模型，进行 RM 和 PPO 训练，需要使用我们提供的模型转换脚本，先将 Megatron 格式的模型文件转换为 huggingface 格式。</p><p style="text-align:justify">LLaMA2 模型转换：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/gpt3_llama
bash model_convertor.sh \
/path/to/Megatron-LM \
/path/to/megatron_llama2_ckpt \
/path/to/hf_llama2_ckpt \
1 \
1 \
llama-7b \
0 \
true</code></pre><p style="text-align:justify">BLOOM 模型转换：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/bloom
bash model_convertor_huggingface_megatron.sh \
/path/to/Megatron-LM \
/path/to/megatron_bloom_ckpt \
/path/to/hf_bloom_ckpt \
1 \
1 \
true</code></pre><p style="text-align:justify"><strong>DeepSpeed-Chat</strong></p><p style="text-align:justify">下载安装开源社区 DeepSpeed-Chat 源代码：</p><pre><code>cd PAI-Megatron-Patch/rlhf/deepspeed-chat
git clone https://github.com/microsoft/DeepSpeedExamples.git
cp -f rm_main.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/main.py
cp -f utils.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/utils.py
cd DeepSpeedExamples/applications/DeepSpeed-Chat/
pip install -r requirements.txt</code></pre><p style="text-align:justify">基于 LLaMA2 模型训练奖励模型（RM）：</p><pre><code>cd training/step2_reward_model_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b.sh</code></pre><p style="text-align:justify">基于 LLaMA2 进行强化学习优化训练（PPO）：</p><pre><code>cd training/step3_rlhf_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b_lora.sh</code></pre><p style="text-align:justify"><strong>trlx</strong></p><p style="text-align:justify">下载安装开源社区 trlx 源代码：</p><pre><code>cd PAI-Megatron-Patch/rlhf/trlx
git clone https://github.com/CarperAI/trlx.git
cp trlx_bloom_rlhf.py trlx_bloom_rlhf_test.py trlx/examples/summarize_rlhf/
cp train_reward_model_bloom.py reward_model_bloom.py ds_config_bloom.json trlx/examples/summarize_rlhf/reward_model/
cp -f ds_config_trlx_gptj_summarize.json trlx/examples/summarize_rlhf/configs/
cd trlx
pip install -e .</code></pre><p style="text-align:justify">基于 BLOOM 模型训练奖励模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_bloom.py</code></pre><p style="text-align:justify">基于 GPT-J 模型训练奖励模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_gptj.py</code></pre><p style="text-align:justify">基于 BLOOM 模型进行强化学习优化训练（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf.py</code></pre><p style="text-align:justify">基于 GPT-J 模型进行强化学习优化训练（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_gptj_text_summarization.py</code></pre><p style="text-align:justify">PPO 单测</p><p style="text-align:justify">如果您想跳过，有监督微调（SFT）与，奖励模型训练（RM）两个步骤，只单独测试 PPO 模块的性能，可以运行如下指令单测 PPO：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf_test.py</code></pre><span id="OSC_h3_10"></span><h3>开源生态——构想和未来</h3><p style="text-align:justify">在 PAI-Megatron-Patch 的开发过程中，我们围绕中文大模型训练加速落地沉淀了以下几个方面的内容：</p><ul><li>Huggingface 的模型权重无损转换成 Megatron 或者 Transformer Engine 可读的模型权重。</li><li>H800 集群开启 FP8 混合精度训练确保收敛。</li><li>LLM 大模型在 PAI 灵骏智算平台上的最佳实践。</li><li>强化学习技术在 PAI 灵骏智算平台上的最佳实践。</li></ul><p style="text-align:justify">后续在 PAI-Megatron-Patch 中还会陆续放出更多高质量的大模型和最佳实践。</p><span id="OSC_h3_11"></span><h3>参考文献</h3><p style="text-align:justify">[1]. Attention Is All You Need</p><p style="text-align:justify">[2]. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</p><p style="text-align:justify">[3]. Reducing Activation Recomputation in Large Transformer Models</p><p style="text-align:justify">[4]. FP8 Formats for Deep Learning</p><p style="text-align:justify">[5]. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</p><p style="text-align:justify">[6]. LLaMA: Open and Efficient Foundation Language Models</p><p style="text-align:justify">[7]. Llama 2: Open Foundation and Fine-Tuned Chat Models</p><p style="text-align:justify">[8]. Benchmarking Large Language Models on NVIDIA H100 GPUs with CoreWeave</p><blockquote><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fclick.aliyun.com%2Fm%2F1000373503%2F" target="_blank"><span style="color:#e67e22">点击立即免费试用云产品，开启云上实践之旅！</span></a></strong></blockquote><p style="text-align:justify"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1337652%3Futm_content%3Dg_1000381155" target="_blank">原文链接</a></strong></p><p style="text-align:justify"><strong>本文为阿里云原创内容，未经允许不得转载。</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/yunqi/blog/10115767</guid>
            <link>https://my.oschina.net/yunqi/blog/10115767</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenJDK 合并英特尔 x86-simd-sort，将数据排序速度提高 7-15 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">今年早些时候，英特尔发布了<span style="background-color:#ffffff">一个利用了 AVX-512 的 x86-simd-sort 快速排序库</span>；当 Numpy 将 <span style="background-color:#ffffff">x86-simd-sort 代码进行合并后发现</span>，对于 16 位到 64 位的数据类型，排序速度提高了 10~17 倍。如今，英特尔软件工程师又发布了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fx86-simd-sort%2Freleases%2Ftag%2Fv3.0" target="_blank">x86-simd-sort 3.0</a>，OpenJDK 也已经将这一修改版进行了合并。</span></p><p><img height="254" src="https://oscimg.oschina.net/oscnet/up-e6ce9bf7b77cccf7d2121e07398176707ac.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">x86-simd-sort 3.0 添加了一个新的「avx512_argselect」方法</span><span style="background-color:#ffffff; color:#000000">，用于</span><span style="color:#000000">计算 arg nth_element，该</span><span style="background-color:#ffffff; color:#000000">方法</span><span style="color:#000000">返回一个对数据数组进行分区的索引数组。x86-simd-sort 3.0 版本还对其 benchmarks 进行了改进，现在使用 __builtin_cpu_supports 而不是 querying cpuinfo，</span><span style="background-color:#ffffff; color:#000000">并进行了各种其他更改。</span><br><br><span style="color:#000000">目前，x86-simd-sort 3.0 已合并至&nbsp;Numpy 主分支中，它提供了 np.partition 和 np.argpartition 的 AVX-512 矢量化版本。将 np.partition 的 16 位速度提高了 25 倍，将 32 位 dtypes 的速度提高了 17 倍，将 64 位 dtypes 的速度提高了约 8 倍。与此同时，<span style="background-color:#ffffff">新的 avx512_argselect 方法还使&nbsp;</span>np.argpartition 的速度提高了 6.5 倍。</span></p><p><span style="color:#000000">并入 OpenJDK 的 x86-simd-sort 是一个略有修改的版本，该版本将 <span style="background-color:#ffffff">32 位数据排序速度提高了 15 倍，64 位数据排序速度提高了约 7 倍。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">更多详情<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenjdk%2Fjdk%2Fpull%2F14227" target="_blank">可查看此处</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260605/intel-x86-simd-sort-3-0-openjdk</guid>
            <link>https://www.oschina.net/news/260605/intel-x86-simd-sort-3-0-openjdk</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 遭「卡脖子」，OpenAI 计划自研 AI 芯片]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">根据&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F06%2Fopenai-said-to-be-considering-developing-its-own-ai-chips%2F%3Fguccounter%3D1%26guce_referrer%3DaHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS5oay8%26guce_referrer_sig%3DAQAAAL3fVeW5BS1z3Z9olNE6c2iybavGH0APpfPZxySiJi7WUXe83N7739IvRls5vIwuXKyA2eYoWcTiKlUTh7jVhzMkKKxJTSaY_n4awPm8XvK2tXu2OjLfdsRALDvUWwB1idflbNBNoRwu_fzD-uhZrxP90RGZfxjBWi5mEUiKzpMc" target="_blank">TechCrunch</a>&nbsp;的报道，随着 AI 芯片短缺的问题日益严重，OpenAI 现已开始考虑自研 AI 芯片。</p><p style="color:#000000; text-align:start">据悉，从去年开始 OpenAI 内部就已经开始讨论 AI 芯片战略，以解决其 AI 芯片短缺的问题。这些方案包括自研 AI 芯片、与英伟达等芯片制造商展开更紧密的合作、实现供应商多元化等。</p><p>OpenAI 首席执行官 Sam Altman 去年就公开抱怨英伟达 GPU 芯片稀缺，称公司受到 GPU 的严重限制。</p><p>由于英伟达主导了全球 95% 的 Al 训练领域市场，随着英伟达 GPU 显卡稀缺，加上 AI 算力成本持续攀升，即便强如 OpenAI 也在寻找新方案，从而避免长期被「卡脖子」。</p><p style="color:#000000; text-align:start">报道称，该公司尚未决定继续推进。Sam Altman 此前表示已将收购更多 AI 芯片作为公司的首要任务。</p><p style="color:#000000; text-align:start"><img alt="" src="https://static.oschina.net/uploads/space/2023/1007/112609_aSEr_2720166.jpeg" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">OpenAI 和大多数竞争对手一样，依赖基于 GPU 的硬件来开发 ChatGPT、GPT-4 和 DALL-E 3 等模型。GPU 能够并行执行许多计算，因此非常适合训练当今最强大的人工智能。</p><p style="color:#000000; text-align:start">不过 GPU 等芯片目前面临严重短缺的问题，据报道，英伟达性能最好的人工智能芯片在 2024 年之前都已售罄。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260598</guid>
            <link>https://www.oschina.net/news/260598</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CoDeF —— 强时序一致性视频处理算法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CoDeF 是能够高度保持视频时序一致性的的视频处理算法，可以轻松完成视频风格迁移、视频关键点追踪（包括流体）、用户自定义的视频内容编辑等任务。</p><p>CoDeF 支持将图像风格化算法升级为视频风格化算法，将图像关键点检测算法升级为视频关键点跟踪算法（甚至包括水和烟雾等非刚性物体的追踪），将图像语义分割算法升级为视频物体跟踪算法，将图像超分算法升级为视频超分算法，同时支持用户可交互的视频内容编辑。</p><p><img src="https://oscimg.oschina.net/oscnet/up-86a32563b77d2c6eaf06e2b3c03c320f292.gif" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/codef</guid>
            <link>https://www.oschina.net/p/codef</link>
        </item>
    </channel>
</rss>
