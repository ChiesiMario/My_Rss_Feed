<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 08 Nov 2023 19:12:14 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[目标智能体社会，MetaGPT 携手 Jürgen Schmidhuber 团队]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6a26cdfc68540cd8ce50fd07f1d06aa~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=530&amp;s=59164&amp;e=webp&amp;b=fcfbfb" referrerpolicy="no-referrer"><img alt="" height="335" src="https://oscimg.oschina.net/oscnet/up-35f95b18cb984ecd9e8659b66778355d901.jpg" width="800" referrerpolicy="no-referrer"></p><p>过去数月，MetaGPT [1] 的智能体（Agents）软件公司实例让人印象深刻，它迅速在 GitHub 获得了 30k star，也获得了数十个全球专业媒体与大 V 报道。但智能体软件公司只是智能体社会（Agent Society）的一个缩影。智能体社会或许会有软件公司、电商公司、游戏公司，也会拥有大量的独立智能体提供生产力。现代人工智能之父 Jürgen Schmidhuber 也非常认可智能体社会的理念，他与其团队对 MetaGPT 做出了显著贡献，列入了 MetaGPT 作者名单。</p><p>早在 1986 年，马文·明斯基以《心智社会》（Society of Mind, SOM）[2] 之作引领了人工智能领域的一场思想革命。他提出了一个极具创见的理论：心智不需由具有智能的单独部件构成，反而是由一系列简单部件的相互作用集结而成的复杂系统，正是这种集结，催生了我们所认识的智能和意识。这一理念对于构建自主智能体以及其后续发展，产生了不可估量的深远影响。</p><p>随着人工智能技术至 2023 年的飞跃，我们现在可以设想，如果每个微小部件本身都拥有一定程度的智能，它们将如何相互作用，产生何种层次的集体智能。2023 年上半年关于自然语言心智社会（NLSOM, Language Agent Society）的研究论文 [3] 中，来自阿卜杜拉国王科技大学、瑞士人工智能实验室、牛津大学以及苏黎世联邦理工学院等知名研究机构的科学家们共同探讨了智能体社群的可能性。</p><p>他们提出，构建成由语言驱动的智能体社区，能够协同完成单一智能体无法或难以独立完成的任务。研究中提出了一系列实验构想，这些实验构想不仅仅是概念验证，它们被视作迈向一个包含万亿级智能体社会的先导，这个社会可能也会包括人类成员。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/21644b3cc3a84c2db0d0da75652a0cb0~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=981&amp;h=1280&amp;s=170610&amp;e=webp&amp;b=fcfbfb" referrerpolicy="no-referrer"><img alt="" height="1044" src="https://oscimg.oschina.net/oscnet/up-2ee6f8c420b35e61bc71e31c9228d6fcd13.png" width="800" referrerpolicy="no-referrer"></p><p>在 2023 年的 CogX Festival 上，Jürgen 向听众展示了他对于大型语言模型（LLMs）的深刻见解。他在讨论智能体（Agents）相关的话题时，提到了构建自我改进系统的多种途径，包括通用图灵机（Universal Turing Machine）[4] 和哥德尔机（Gödel machines）[5]。他指出，目前的大语言模型为我们提供了一种全新的思维模式 — 通过使用通用符号语言（例如：自然语言或编程代码）作为接口，来串联不同的模型。这些模型能够与其他语言模型进行交流，共同构建起一个自然语言心智社会（NLSOM）的范例。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/51d8e153f5514d13820c1d67539ede46~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1920&amp;h=1080&amp;s=66142&amp;e=webp&amp;b=7d5c3e" referrerpolicy="no-referrer"><img alt="" height="450" src="https://oscimg.oschina.net/oscnet/up-f4af29afe3864c3625875a198b225f27628.jpg" width="800" referrerpolicy="no-referrer"></p><p>Jürgen Schmidhuber 教授是瑞士人工智能实验室 (IDSIA) 的科学主任，以及阿卜杜拉国王科技大学人工智能中心 (AI Initiative, KAUST) 的主任。他的工作对强化学习（Reinforcement Learning），元学习（Meta Learning），以及神经网络（Neural Network）等重要人工智能方向有着深刻的影响。</p><p>截止目前，Schmidhuber 教授的谷歌学术引用为 21 万，其中作为共同发明人的长短时记忆（LSTM）论文单篇引用过 9 万。他在 15 岁就希望能开发一种比它聪明并且能够自我完善的人工智能，然后他就可以退休了。DeepMind 创始初期四人中的两人以及他们招募的第一个人工智能博士都来自 Jürgen Schmidhuber 的实验室。</p><p>在 Jürgen 构想的这一社会中，所有的交流都是透明且易于解释的。他提到了一个被称作「Mindstorm」的概念，即当给定一个问题时，这个自然语言心智社会能够协同合作进行解答。</p><p>在这个过程中，社会中的每个成员可能会有不同的想法和视角，它们将收集并整合这些不同的思路，从而做出集体决策。</p><p>这种方式特别适合于解决那些单个智能体无法有效解决的问题。Jürgen 进一步举例说明，这种问题可以是编程性质的，如使用 Python 语言解决一个具体的编程难题。通过这种协同作用，智能体社会的智能集结，将能够实现超越个体能力的解决方案。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5cc7dc94e9a64bebb63187c960442abd~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1269&amp;h=635&amp;s=49620&amp;e=webp&amp;b=fdfaf9" referrerpolicy="no-referrer"><img alt="" height="401" src="https://oscimg.oschina.net/oscnet/up-0a2e1cb3557ba4e33b63ccceca6b4647eb2.png" width="800" referrerpolicy="no-referrer"></p><p>此次 MetaGPT 项目的迭代获得了 Jürgen 直接指导，其团队也在代码、写作、工程上做了大量支持。</p><p>接下来，本文将详细解析 MetaGPT 论文的更新内容，以便让读者能够更加深入地理解其细节。</p><p><strong>1、论文与框架更新</strong></p><p>论文 3.1 节更新：阐述了 MetaGPT 框架中的角色专业化设计和角色分工概念，说明了单个智能体在 MetaGPT 中的行为模式和 SOPs 下的组织方式。</p><p>论文 3.2 节更新：介绍 MetaGPT 框架中的通信机制，包括结构化通信接口设计和发布-订阅机制。</p><p>论文 3.3 节更新：引入了可执行反馈机制，它是一种在代码执行过程中进行持续迭代和自我纠正的机制。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/52272b7b6df4434589d9071492e7d736~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=636&amp;s=82808&amp;e=webp&amp;b=fdfcfc" referrerpolicy="no-referrer"><img alt="" height="401" src="https://oscimg.oschina.net/oscnet/up-47bacc68b62b046bdc40b461241d7a1ab26.jpg" width="800" referrerpolicy="no-referrer"></p><p>Fig.2. 通信协议示例（左）和运行中可执行反馈的迭代编程示例（右）。左图：Agents 使用共享消息池发布结构化消息。它们还可以根据自己的配置订阅相关消息。右图：生成初始代码后，工程师 Agent 可执行代码并检查运行中是否报错。如果出现报错，Agent 会检查执行结果，并将它们与 PRD、系统设计和代码文件进行比较，进行代码的重写和优化。</p><p><strong>1.1、智能体通信协议</strong></p><p>目前大部分多智能体都是通过以自然语言为主的对话形式来完成协作，但这对于解决具体特定任务而言并不是最优的方式。</p><p>没有约束和特定要求的自然语言输出，可能会导致信息内容的失真或者语义焦点的偏移。</p><p>因此，结构化的通信内容和接口形式有助于智能体之间进行快速准确的任务要求理解，也有利于信息内容的最大化保留。参考人类 SOPs 中对不同岗位的角色要求，我们给每个角色设定了符合人类对应岗位专家的输出规范，要求智能体将原始自然语言信息转换为更结构化的表达（如下图所示），如数据结构、API 设计和时序图。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39c4bc32ea9644b9b0f383b5b9810d81~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=1235&amp;s=146554&amp;e=webp&amp;b=ddecfb" referrerpolicy="no-referrer"><img alt="" height="779" src="https://oscimg.oschina.net/oscnet/up-3cb7baa9146b4b2f65471d6d5f4e2f4f4a7.jpg" width="800" referrerpolicy="no-referrer"></p><p>Fig.3 MetaGPT 软件开发流程示意图，表明结构化的 SOPs 可以带来较好的效果 。更详细的演示见附录 B</p><p>在后续的实验中，我们对比了 MetaGPT 和 ChatDev（使用聊天形式的沟通协作机制）来进行软件开发的这一复杂任务的实际解决效果，结果说明结构化的通信接口设计对于智能体协作能带来显著效果。</p><p><strong>发布-订阅机制</strong></p><p>在多智能体的通信过程中，仅仅依赖 1v1 的单点通信方式不仅会加剧通信拓扑的复杂度，导致协作的效率低下，也会急剧增加开发成本。因此，我们通过【发布-订阅】的消息机制，在框架内实现了共享消息池和基于兴趣的订阅方式。</p><p>具体来说，环境提供共享的消息池，智能体可以从中直接获取信息，无需逐一询问其他智能体。与此同时，智能体可根据自己兴趣/关注的行为来进行消息的过滤和筛选，从而减少消息/记忆的过载。如图 3 所示，架构师主要关注产品经理的 PRD 文档输出，而对测试工程师的文档则关注较少。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f4cb736da0047778cb331c48db14fb9~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1266&amp;h=705&amp;s=29794&amp;e=webp&amp;b=f9fbfe" referrerpolicy="no-referrer"><img alt="" height="445" src="https://oscimg.oschina.net/oscnet/up-fa141e11ff2fb59723d29e9be1259680890.jpg" width="800" referrerpolicy="no-referrer"></p><p><strong>1.2、可执行迭代反馈设计</strong></p><p>调试和执行反馈在日常编程任务中发挥着重要作用。然而，现有方法往往缺乏自我纠正机制，仅通过代码审查和评审机制进行代码可行性评估。为了进一步减少 LLM 在生成代码上的幻觉问题，我们引入了可执行反馈机制，对代码进行迭代改进。通过自动的代码执行测试结果反馈，进行代码可行性评估和判断，促进 LLM 进行自我的迭代和优化。如图 2 所示，工程师可根据代码执行结果持续更新代码，迭代测试，直到测试通过或者最大 N 次重试退出。</p><p><strong>2、实验更新</strong></p><p>在实验部分，我们增加了对 SOPs 引入多智能体框架效果的探索实验，和可执行迭代反馈带来的代码质量的提升实验。在数据集上：</p><ol><li>针对代码质量的效果评估：我们使用了两个公共基准数据集：HumanEval 和 MBPP。<br> 1）HumanEval 包括 164 个手写编程任务。这些任务包括功能说明、描述、参考代码和测试。<br> 2）MBPP 包含 427 个 Python 任务。这些任务涵盖核心概念和标准库功能，幷包括说明、参考代码和自动测试。</li><li>我们提出了更具有挑战性的软件开发任务的基准数据集 SoftwareDev：我们的 SoftwareDev 数据集收集了 70 个具有代表性的软件开发任务实例，每个实例都有自己的任务提示（见论文表 5）。这些任务的范围多种多样（见论文图 5），如迷你游戏、图像处理算法、数据可视化等。它们为真实的开发任务提供了一个强大的测试平台。与之前的数据集不同，SoftwareDev 侧重于工程方面。在比较中，我们随机选择了七个具有代表性的任务进行评估。</li></ol><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a63997ca887a49a1a619d93e208c164d~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=703&amp;h=727&amp;s=87524&amp;e=webp&amp;b=fbfafa" referrerpolicy="no-referrer"><img alt="" height="620" src="https://oscimg.oschina.net/oscnet/up-762eec7feede0d100b7ae1c5039f8331f71.jpg" width="600" referrerpolicy="no-referrer"></p><p><strong>2.1、可执行迭代反馈设计</strong></p><p>图 4 表明，MetaGPT 在 HumanEval 和 MBPP 基准测试中均优于之前的所有方法。当 MetaGPT（使用 GPT-4 作为基础模型），与 GPT-4 相比，它在 HumanEval 基准测试中的 Pass @1 显著提高。它在这两个公共基准测试中达到了 85.9% 和 87.7%（考虑到实验成本，部分模型的数值结果直接使用的 Dong et al. (2023). 所提供的结果 [6]）。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6749bae368dd4f4d86ac44a57ace9c82~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1280&amp;h=382&amp;s=31468&amp;e=webp&amp;b=fdfdfd" referrerpolicy="no-referrer"><img alt="" height="239" src="https://oscimg.oschina.net/oscnet/up-55fc3e480ea87fb5c5872f15472848bf135.jpg" width="800" referrerpolicy="no-referrer"></p><p>Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.</p><p><strong>2.2、软件开发任务数据集 &amp; 评价指标</strong></p><p>对于 SoftwareDev，我们优先考虑生成项目的实际可用性，并通过人工评估（A、E）或统计分析（B、C、D）来评估性能，我们通过可视化示例展示了 MetaGPT 的自主软件生成能力（论文图 5）。有关其他实验和分析，可参阅论文附录 C：</p><p>（A）可执行性：该指标将生成代码从 1（失败/无功能）到 4（无缺陷）进行评级。1 代表无功能，2 代表可运行但不完美，3 代表接近完美，4 代表无缺陷。</p><p>（B）成本：这里的成本评估包括（1）项目运行时间（2）Token 消耗量和（3）实际费用。</p><p>（C）代码统计信息：包括（1）代码文件数量（2）每个文件的平均代码行数，以及（3）总代码行数。</p><p>（D）生产效率：基本定义为 Token 使用量除以代码行数，即每行代码消耗的 Token，该数值越小说明代码生产效率越高。</p><p>（E）人工修订成本：以确保代码顺利运行所需的修订轮数来量化，这表示人工干预的频率，如调试或导入依赖等修订。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7cce3f4c622541ea856eb3dc0e1fd9b8~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1266&amp;h=761&amp;s=58372&amp;e=webp&amp;b=f8f7f7" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-58d8c9338be9e954eee491611053ad8b451.png" width="800" referrerpolicy="no-referrer"></p><p><strong>2.3、SOPs vs ChatChain</strong></p><p>在解决特定任务的场景中，为了探索 SOPs 对多智能体协作的效果，我们选择了开源工作中支持软件开发任务的智能体框架 ChatDev 作为实验比较对象。ChatDev 是基于 ChatChain 和软件开发瀑布流的角色分工进行智能体组织和协作的框架。我们从 SoftwareDev 选择了 7 个任务进行对比，并比较了上述的相关指标来说明差异。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2c3560be06bd46feab9b37a51b03e6aa~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1267&amp;h=741&amp;s=67220&amp;e=webp&amp;b=ffffff" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-06aa7e7223004b9c3b2ca38b88efa69b92d.png" width="800" referrerpolicy="no-referrer"></p><p>如论文表 1 所示，在具有挑战性的 SoftwareDev 数据集上，MetaGPT 几乎在所有指标上都优于 ChatDev。</p><p>例如：在可执行性方面，MetaGPT 得到了 3.75 分，非常接近 4 分（完美无缺）。此外，它花费的时间（503 秒）也明显少于 ChatDev。</p><p>在代码统计和人工修改的成本上也明显优于 ChatDev。虽然 MetaGPT 需要更多的 Token（24,613 或 31,255，而 ChatDev 为 19,292 ），但它只需要 126.5/124.3 个 Tokens 就能生成一行代码。相比之下，ChatDev 使用了 248.9 个 Tokens。</p><p>这些结果凸显了 SOPs 在多智能体协作中的优势。</p><p><img alt="" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2c8b076075554df5a425342a9c1940e7~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=817&amp;h=263&amp;s=24046&amp;e=webp&amp;b=f4f4f4" referrerpolicy="no-referrer"><img alt="" height="258" src="https://oscimg.oschina.net/oscnet/up-b7e033a3dab2d9dbc88391df2712d572478.jpg" width="800" referrerpolicy="no-referrer"></p><p><strong>3、致谢</strong></p><p>感谢来自 KAUST AI 中心的执行秘书 Sarah Salhi，博士后王宇辉，以及博士生王文一对于此论文提供的建议以及帮助。</p><p>[1] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fpdf%252F2308.00352.pdf" target="_blank">arxiv.org/pdf/2308.00…</a></p><p>[2] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FSociety_of_Mind" target="_blank">en.wikipedia.org/wiki/Societ…</a></p><p>[3] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fpdf%252F2305.17066.pdf" target="_blank">arxiv.org/pdf/2305.17…</a></p><p>[4] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FUniversal_Turing_machine" target="_blank">en.wikipedia.org/wiki/Univer…</a></p><p>[5] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fen.wikipedia.org%252Fwiki%252FG%2525C3%2525B6del_machine" target="_blank">en.wikipedia.org/wiki/Gödel_…</a></p><p>[6] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fabs%252F2304.07590" target="_blank">arxiv.org/abs/2304.07…</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 10:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265625</guid>
            <link>https://www.oschina.net/news/265625</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[华为与西工大合作，发布首款流体力学大模型「秦岭・翱翔」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>华为近日宣布，与西北工业大学联合研发的首个面向飞行器的流体力学大模型「秦岭・翱翔」现已正式发布。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-ff4d245868c9104fe5ffe5ca0fd9c6111a1.png" referrerpolicy="no-referrer"></p><p>秦岭・翱翔大模型是西工大流体力学智能化国际联合研究所携手华为 AI4Sci Lab 在国产开源流体计算软件风雷的基础上，依托升腾 AI 澎湃算力及升思 MindSpore AI 框架共同研发的面向飞行器流体仿真的智能化模型。</p><p>大模型通过打造智能通用的流体力学软件平台与流体工业全场景应用底座，旨在实现全场景流场准确预测。同时结合业界领先的数据同化、AI 湍流模型、流场快速预测等技术，支撑流体力学大模型的基础构架。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d498c2db0add1f15cf241f0aff43d998bfb.png" referrerpolicy="no-referrer"></p><p>具体来说，大模型采用自研多级分布式并行自适应框架，多层级融合流体力学经典理论和人工智能方法，构造数学物理关联特征、开展多范式一体化建模、搭建不变性可实现性多模态统一框架。同时，在模型算法设计、混合精度加速，以及数值求解耦合并行优化等方面进行了创新与验证，实现了高置信度流场重构、全速域湍流场求解和复杂流场近实时预测。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 08:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265612</guid>
            <link>https://www.oschina.net/news/265612</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[著名硬件黑客黄欣国：美国限制 RISC-V 只会适得其反]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美国立法者继续施压限制中国使用 RISC-V 的举措已经引起质疑。著名硬件黑客黄欣国近日就针对此事，写了一封至白宫、<span style="background-color:#ffffff">美国商务部和国会议员</span>的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bunniestudios.com%2Fblog%2F%3Fp%3D6862" target="_blank">公开信</a>，敦促不要对 RISC-V 技术的共享施加任何限制。</span></p><p><span style="color:#000000">他认为，增添限制只会减少美国对一项重要新兴技术的参与，同时巩固 ARM 作为嵌入式 CPU 近乎垄断的现有供应商的地位。</span></p><blockquote><p><span style="color:#000000">我是一名出生于密歇根州的美国人，拥有麻省理工学院电子工程博士学位。我还是一个设计和制造电子产品的小企业主。我写信敦促你们不要对 RISC-V 技术的共享施加任何限制。</span></p><p><span style="color:#000000">我的产品 CPU 基于开源的 RISC-V 标准。RISC-V 的开放性特别有利于像我这样的小企业。我从开源社区获得工具和设计，并将自己的改进回馈给社区。无障碍地参与这个充满活力的开源生态系统可以降低开销，使我能够在残酷的硬件行业中保持竞争力。</span></p></blockquote><p><span style="color:#000000">作为一个全球性项目，RISC-V 并不是美国的单独所有，其很多贡献都来自欧盟、印度、中国等地。黄欣国指出，譬如他所使用的&nbsp;VexRiscv，就是由欧盟开发的一个 RISC-V 实现。「<strong>对美国人的参与设置任何障碍都只会延缓美国在开发和采用该技术方面的进展。其效果将与立法者的初衷背道而驰</strong>」。另一个微妙之处在于，RISC-V 只是一种标准，对既定标准的使用进行监管也不切实际。</span></p><p><img height="318" src="https://oscimg.oschina.net/oscnet/up-211d8f4d387a1aadc108064451b71db8e29.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">黄欣国认为，美国立法者和政策制定者普遍对开源缺乏了解。并<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F11%2F07%2Fproposed_restrictions_riscv" target="_blank">表示</a>他最大的担忧在于，美国的这一限制可能会造成寒蝉效应，迫使企业和组织决定不采用或停止为 RISC-V 做贡献，暂停 RISC-V 生态系统的参与。因为所面临的违反美国出口管制的风险太大 —— 包括最高 25 万美元的民事处罚、20 年监禁的刑事处罚和最高 100 万美元的罚款。</span></p><p><span style="color:#000000">「这将使 RISC-V 世界变得更加匮乏：至少来自美国人的创新和贡献会减少，其他人使用它的动力以及开发它的理由也会减少......这将使美国失去强有力的第三选择 ISA。」</span></p><p><span style="color:#000000">此外，黄欣国还认为，美国的这一限制很大程度上将促使中国结束对西方技术的依赖，转而把钱花在自研芯片上。他在信中总结称：</span></p><blockquote><p><span style="color:#000000">总之，对美国人共享 RISC-V 技术施加任何限制都只会削弱美国作为技术领导者的作用。过于宽泛的限制可能会剥夺教育工作者在美国校园向学生传授计算机知识时使用的流行工具，因为他们担心也会意外地向被禁运的实体传授知识。即使是对 RISC-V 的狭义限制，也会使那些有可能进入中国市场的美国科技公司失去获得高性价比、高性能 CPU 技术的机会，迫使它们向近乎垄断的现有供应商 ARM Holdings plc 支付专利费，而 ARM Holdings plc 并非美国公司。这削弱了美国的竞争力，最终损害了美国的最佳利益。</span></p><p><span style="color:#000000">如果政府认为 RISC-V 是一项对美国经济和军事利益至关重要的技术，值得特别关注，那么它就不应该试图通过联邦强制许可制度来限制 RISC-V 的表达，而应该投资于开发更多美国本土 RISC-V 芯片制造商成功案例的项目。在美国现有的法律框架和 RISC-V 合同框架内，公司可以选择开发 RISC-V CPU 的专有实施方案。在美国，有许多公司在开放标准的界限内游刃有余，并有在不需要联邦指导的情况下取得成功的先例： Intel 和 AMD 都是美国工业巨头，它们都是通过专有技术实现原本公开的"x86"计算机标准而建立起来的。美国需要的是对 ARM Holdings plc 的垄断做出回应，而这一回应来自于对接受 RISC-V 的美国公司的投资。</span></p><p><span style="color:#000000">拜登总统，我恳请您：对美国的创新充满信心。相信美国的价值观。不要对共享 RISC-V 技术施加任何限制。我们可以共同努力，创造更多美国芯片制造商的成功案例，同时拥抱言论自由的美国价值观！</span></p></blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bunniestudios.com%2Fblog%2F%3Fp%3D6862" target="_blank"><strong>公开信地址&nbsp;</strong></a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 08:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265608/bunnie-restrictions-riscv</guid>
            <link>https://www.oschina.net/news/265608/bunnie-restrictions-riscv</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「开源 Windows」 ReactOS 改进 UEFI 引导，支持更多硬件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>ReactOS 开发团队<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Freactos.org%2Fblogs%2Fnewsletter-103%2F" target="_blank">宣布</a></u> 64 位（AMD64 和 ARM64）UEFI 引导功能现在可以在更多设备上使用了。这些设备包括个人电脑、诺基亚的 Lumia、苹果的 iPhone 和 Valve 的 Steam Deck 等。</p><p><img src="https://static.oschina.net/uploads/space/2023/1108/144126_Cm3T_2720166.png" referrerpolicy="no-referrer"></p><p>从今年年初开始，开发团队就着手将 ReactOS 的默认引导加载程序 FreeLoader 过渡到支持 x86 和 AMD64 以及 ARM32 和 ARM64 的 UEFI。ReactOS 核心开发者 Hermès 一直在开发一个用于传递 UEFI 帧缓冲区信息的系统，使 Windows XP 可以在 UEFI 系统上运行，而 Justin Miller (TheDarkFire) 则一直在开发 UEFI FreeLoader 构建。</p><p>除了支持引导 ReactOS 外，团队还在开发其他功能，如 EFI 连锁加载和 FreeLoader 的 bootmgfw 兼容构建。这些功能将增加引导管理功能，并允许现代 Windows 系统引导用户最喜欢的引导加载器。</p><p>除此之外，ReactOS 团队还表示正在慢慢改善 NT6+ 应用程序的兼容性和支持。NT6+ 是一个术语，包括基于较新 NT 架构设计的 Vista、7、8、8.1、10 和 11 等 Windows 操作系统。</p><p>由于许多软件开发商不再支持旧版本的 Windows 系统，因此日常使用的大多数应用程序都无法在 ReactOS 上运行。不过，这种情况将会改变。</p><p>目前，ReactOS 主要局限于用户模式，内核模式的升级计划稍后进行。目前还没有预计的发布时间。</p><blockquote><p>ReactOS 项目的主要目标就是提供一个与 Windows 环境二进制兼容的操作系统。它能让你的 Windows 应用程序和驱动程序如同在 Windows 上一样运行。</p><p>此外，由于应用了 Windows 操作系统的外观特性，已经熟悉 Windows 用户界面的用户在使用 ReactOS 时将驾轻就熟。ReactOS 的终极目标是使你能够在感觉不到最终用户体验变化的前提下，使用 ReactOS 来替代 Windows。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2019/0306/073550_CIxD_2720166.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 06:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265587</guid>
            <link>https://www.oschina.net/news/265587</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[解密 deepin-IDE：如何实现简单灵活的调试技术？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p>前不久深度科技旗下 deepin 社区发布了自己的 IDE：deepin-IDE，得到了全网用户尤其是开源社区用户的广泛关注，目前在 GitHub（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flinuxdeepin%2Fdeepin-unioncode" target="_blank">https://github.com/linuxdeepin/deepin-unioncode</a>）仓库的 star 数量已经达到 600 多个，说明大家的热情还是很高涨的。</p><div><img src="https://wiki.deepin.org/05_HOW-TO/deepin-unioncode/img-20230922163311.png" referrerpolicy="no-referrer"></div><p>为了从技术层面给大家的热情做一个反馈，本文试着将 deepin-IDE 内部的一些实现方法进行分享，希望能够解答友友们的疑惑并得到积极的反馈。</p><p>本篇挑了大家关心的「调试」部分进行分享。需要说明的是，deepin-IDE 的调试功能是选用 DAP（Debug Adapter Protocol ）调试适配协议实现的，所以整体架构是围绕该协议搭建的，至于<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>具体是什么，让我们带着问号往下看。</p><h2>什么是<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>协议</h2><p><code>DAP</code><span>&nbsp;</span>即调试适配协议 ( Debug Adapter Protocol )，顾名思义，它是用来对多种调试器进行抽象统一的适配层，将原有<span>&nbsp;</span><code>IDE</code><span>&nbsp;</span>和调试工具直接交互的模式更改为和<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>进行交互。该模式可以让<span>&nbsp;</span><code>IDE</code><span>&nbsp;</span>集成多种调试器变得更简单，且灵活性更好。</p><p>在<span>&nbsp;</span><code>IDE</code><span>&nbsp;</span>中的调试功能有许多小功能组成，包括单步执行、断点、查看变量值等，常规的实现方式是在每个<span>&nbsp;</span><code>IDE</code><span>&nbsp;</span>中去实现这些逻辑，且因为调试工具的接口不同，还需要为每个调试工具做一些适配工作，这将导致大量且重复的工作，如下图所示：</p><div><img src="https://wiki.deepin.org/05_HOW-TO/deepin-unioncode/img-20230922164609.png" referrerpolicy="no-referrer"></div><p>调试适配器协议背后的想法是标准化一个抽象协议，用于开发工具如何与具体调试器通信。这个思想和<span>&nbsp;</span><code>LSP</code>(Language Server Protocol) 和<span>&nbsp;</span><code>BSP</code>(Build Server Protocol) 类似，都是通过协议去统一相同功能在不同工具之间的差异性。其所处位置如下图所示，其中左边为不同的开发工具，右边为不能同的调试器，不同于开发工具和调试器直接交互的方式，<code>DAP</code><span>&nbsp;</span>将这些交互统一了起来，让开发工具和调试工具都面向<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>编程。</p><p>上图中的交互是通过协议进行，所以不会像通过<span>&nbsp;</span><code>API</code><span>&nbsp;</span>的方式存在语言限制，可以更好的适应调试器的集成。</p><h2>DAP 如何工作</h2><p>以下部分解释了开发工具（例如<span>&nbsp;</span><code>IDE</code><span>&nbsp;</span>或编辑器）和调试适配器之间的交互，包括具体的协议格式说明、交互流程等。</p><h3>调试会话</h3><p>开发工具有两种基础的方式和调试器进行交互，分别是:</p><p>【单会话模式】</p><p>在这种模式下，开发工具启动一个调试适配器作为一个单独的进程并且通过标准的 std 接口进行通信。在调试会话的结束时调试适配器就终止，对于当前的调试会话，开发工具往往需要实现多个调试适配。</p><p>【多会话模式】</p><p>在这种模式下，开发工具不会启动调试适配器，而是假定它已经在运行并且会在特定端口上侦听连接尝试，对于每个调试会话，开发工具在特定端口上启动一个新的通信会话并在会话结束时断开连接。</p><p>在与调试适配器建立连接后，开发工具和调试适配器之间通过基础协议进行通信。</p><h3>基础协议</h3><p>基础协议由两部分组成，包括头和内容 (类似于 HTTP)，头部和内容部分通过「\r\n」进行分割：</p><p>【协议头】</p><p>协议头部分由字段组成， 每个头字段由一个键和一个值组成，用‘:’（一个冒号和一个空格）分隔， 每个头字段都以「\r\n「结尾。由于最后一个协议头字段和整个协议头本身都以 \r\n 终止，并且由于协议头是强制性的，所以消息的内容部分总是在（并唯一标识）两个 \r\n 序列之前。当前只支持一个协议头字段：</p><table style="border-spacing:0px; max-width:100%"><tbody><tr><th style="text-align:left">头字段名</th><th style="text-align:left">值类型</th><th style="text-align:left">描述</th></tr></tbody><tbody><tr><td style="border-style:double; border-width:1px; text-align:left">Content-Length</td><td style="border-style:double; border-width:1px; text-align:left">数字</td><td style="border-style:double; border-width:1px; text-align:left">这个字段是必须的，用来记录内容字段的长度，单位是字节。</td></tr></tbody></table><p>协议头部分使用的是「ASCII」编码。</p><p>【内容部分】</p><p>内容部分包含了实际要传输的数据，这些数据用<span>&nbsp;</span><code>JSON</code><span>&nbsp;</span>格式来描述请求、响应和事件。内容部分用的是<span>&nbsp;</span><code>utf-8</code><span>&nbsp;</span>编码</p><p>为了有个具体的认识，这里举个简单的例子。在调试过程中，开发人员经常会使用到下一步操作，在<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>中其协议为：</p><div><pre><code class="language-plain">Content-Length: 119\r\n
\r\n
{
 &nbsp; &nbsp;"seq": 153,
 &nbsp; &nbsp;"type": "request",
 &nbsp; &nbsp;"command": "next",
 &nbsp; &nbsp;"arguments": {
 &nbsp; &nbsp; &nbsp; &nbsp;"threadId": 3
 &nbsp;  }
}
</code></pre></div><p>类型是「请求」，命令是下一步，参数部分可以携带多个，这里是用的线程 Id。 这个协议看着挺简单的，是吧？接下来就讲讲如何使用它。</p><h3>使用方法</h3><p>详细的使用方法这里就不涉及，因为用一个时序图就可以说明：</p><div><img src="https://wiki.deepin.org/05_HOW-TO/deepin-unioncode/img-20230922164954.png" referrerpolicy="no-referrer"></div><p>可以看到，初始化、请求、响应等必要的步骤都在图中。其中调试适配器可以理解为调试器的抽象，调试功能的最终执行者是由对应语言的调试工具实现的。</p><h2>在 deepin-IDE 中的实现</h2><p>在 deepin-IDE 中，调试功能的实现是结合<span>&nbsp;</span><code>cppdap</code><span>&nbsp;</span>+<span>&nbsp;</span><code>debugmanager</code><span>&nbsp;</span>实现的。</p><p><code>cppdap</code><span>&nbsp;</span>是一款基于 C++ 开发的<span>&nbsp;</span><code>SDK</code>，基本实现了<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>的全量协议。 deepin-IDE 的客户端和服务端都是应用的该<span>&nbsp;</span><code>SDK</code><span>&nbsp;</span>进行开发，据此可以实现以下功能：</p><p>1.通信功能，包括服务端的 TCP 监听，客户端的 TCP 连接等；</p><p>2.<code>DAP</code><span>&nbsp;</span>协议的封装，并实现协议的串行化和解串行化；</p><p>3.提供注册回调功能，从而可以在回调内处理各种事件、请求等；</p><p>它的层级结构如下：</p><div><img src="https://wiki.deepin.org/05_HOW-TO/deepin-unioncode/img-20230922165226.png" referrerpolicy="no-referrer"></div><p>用<span>&nbsp;</span><code>cppdap</code><span>&nbsp;</span>可以减少客户端和服务端不少工作量，也统一了两边的协议数据。而 debugmanager 可以理解为调试器的抽象，包含所有必要的调试要素。整体结构如下：</p><div><img src="https://wiki.deepin.org/05_HOW-TO/deepin-unioncode/img-20230922165251.png" referrerpolicy="no-referrer"></div><p>左边是客户端，右边是服务端，内部实现如下：</p><h3>客户端实现</h3><p>客户端包含了两个个主要功能，一个是和<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>服务端进行交互，发送调试命令或处理返回的数据；另一个是将<code>DAP</code><span>&nbsp;</span>数据转换后显示到用户界面，并响应界面发送的事件。概括起来就包含业务模块、事件模块、<code>DAP</code><span>&nbsp;</span>模块和界面 4 个部分。</p><p>业务模块</p><ul><li><p>业务模块包含了插件类、调试参数、调试管理类等，其中插件类负责插件加载、初始化、获取上下文等，调试管理类用来组合事件、<code>DAP</code>、界面几个模块。 事件模块</p></li><li><p>事件模块包含两个子模块，分别是事件发送和事件接收，比如页面跳转事件、添加\移除断点事件等。<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>模块</p></li></ul><p><code>DAP</code><span>&nbsp;</span>模块基于<span>&nbsp;</span><code>cppdap</code><span>&nbsp;</span>开发，采用层级结构，底层是原始<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>协议封装，中间层是针对业务做的进一步封装，简化了向外提供的接口，最上层是对整个调试功能的整合，包括数据缓存、界面元素、命令收发。</p><div><img src="https://wiki.deepin.org/05_HOW-TO/deepin-unioncode/img-20230922165331.png" referrerpolicy="no-referrer"></div><ul><li>界面部分，界面模块包含堆栈界面、变量界面、断点列表、异步对话框等，用于<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>的数据展示。</li></ul><div><img src="https://wiki.deepin.org/05_HOW-TO/deepin-unioncode/img-20230922165342.png" referrerpolicy="no-referrer"></div><ul><li>如上图所示，灰色部分为<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>客户端的界面呈现。</li></ul><h3>服务端实现</h3><p>服务端的功能分为两个部分，一个是基于<span>&nbsp;</span><code>cppdap</code><span>&nbsp;</span>实现命令的收发，另一个是与<span>&nbsp;</span><code>gdb</code><span>&nbsp;</span>交互，实现调试程序的启动、暂停、退出等一系列动作。</p><p>DAP</p><ul><li><p>和客户端一样，服务端也是基于<code>cppdap</code>实现的通信和协议封装和解析。 调试工具</p></li><li><p>和调试工具的交互是通过进程调用的方式实现，接收进程输出得到返回信息。如果调试工具本身支持<span>&nbsp;</span><code>DAP</code><span>&nbsp;</span>协议，则可以直接交互。</p></li></ul><p>至此，本次的分享就到这儿啦！不知道你对<span>&nbsp;</span><code>deepin-IDE</code><span>&nbsp;</span>中的调试功能有所了解了吗？</p><p>温馨提示，deepin-IDE 还包含很多有意思的功能，如果大家感兴趣可以积极反馈，后续有机会再进行分享。</p><h2>参考文档</h2><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmicrosoft.github.io%2Fdebug-adapter-protocol%2Foverview" target="_blank">debug-adapter-protocol</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.deepin.org%2Fzh%2F05_HOW-TO%2F02_%25E5%25BC%2580%25E5%258F%2591%25E7%259B%25B8%25E5%2585%25B3%2Fdeepin-unioncode" target="_blank">deepin-IDE 使用手册</a></p><p>内容来源：deepin 社区</p><p>内容作者：deepin-mozart、toberyan</p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 06:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265585/deepin-ide-debug</guid>
            <link>https://www.oschina.net/news/265585/deepin-ide-debug</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果暂停 iPhone 和 Mac 的系统新功能开发工作，专注修复 bug]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>彭博社报道称，苹果公司罕见地暂停了明年 iPhone、iPad、Mac 和其他设备的软件更新开发工作，以便根除代码中的 bug。</p><p><img src="https://static.oschina.net/uploads/space/2023/1108/141600_8Btu_2720166.png" referrerpolicy="no-referrer"></p><p>via <em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2023-11-07%2Fapple-delays-work-on-ios-18-macos-15-watchos-11-due-to-problems-with-bugs" target="_blank">彭博社</a></u></em></p><p>苹果上周在内部向员工宣布了这一决定，<strong>公司工程师现在的主要任务不是添加新功能而是修复 bug 和改进性能</strong>。</p><p>在准备明年发布的新操作系统时，软件工程管理团队在内部测试中发现了太多的<strong>"escapes"</strong>问题（内部测试期间遗漏的错误）。由于数千名不同的苹果员工在各种操作系统和设备上工作，这些操作系统和设备需要无缝协作，因此很容易出现故障。</p><p>因此他们采取了不同寻常的做法，暂停新功能开发一周，专注于修 bug。虽然暂停一周，但发版时间仍按原计划进行。</p><p>目前还不清楚此次暂停开发一周对上述系统来说存在哪些影响，彭博社称这是苹果非常罕见的举动。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 06:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265579</guid>
            <link>https://www.oschina.net/news/265579</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 跨平台终端仿真软件 quardCRT]]>
            </title>
            <description>
                <![CDATA[<p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT%2Factions%2Fworkflows%2Fwindows.yml"><img src="https://img.shields.io/github/actions/workflow/status/qqxiaoming/quardCRT/windows.yml?branch=main&amp;logo=windows" alt="Windows ci" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT%2Factions%2Fworkflows%2Flinux.yml"><img src="https://img.shields.io/github/actions/workflow/status/qqxiaoming/quardCRT/linux.yml?branch=main&amp;logo=linux" alt="Linux ci" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT%2Factions%2Fworkflows%2Fmacos.yml"><img src="https://img.shields.io/github/actions/workflow/status/qqxiaoming/quardCRT/macos.yml?branch=main&amp;logo=apple" alt="Macos ci" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.codefactor.io%2Frepository%2Fgithub%2Fqqxiaoming%2FquardCRT"><img src="https://img.shields.io/codefactor/grade/github/qqxiaoming/quardCRT.svg?logo=codefactor" alt="CodeFactor" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT"><img src="https://img.shields.io/github/license/qqxiaoming/quardCRT.svg?colorB=f48041&amp;logo=gnu" alt="License" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT%2Freleases"><img src="https://img.shields.io/github/tag/QQxiaoming/quardCRT.svg?logo=git" alt="GitHub tag (latest SemVer)" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT%2Freleases"><img src="https://img.shields.io/github/downloads/QQxiaoming/quardCRT/total.svg?logo=pinboard" alt="GitHub All Releases" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT"><img src="https://img.shields.io/github/stars/QQxiaoming/quardCRT.svg?logo=github" alt="GitHub stars" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FQQxiaoming%2FquardCRT"><img src="https://img.shields.io/github/forks/QQxiaoming/quardCRT.svg?logo=github" alt="GitHub forks" referrerpolicy="no-referrer"></a><a href="https://gitee.com/QQxiaoming/quardCRT"><img src="https://gitee.com/QQxiaoming/quardCRT/badge/star.svg?theme=dark" alt="Gitee stars" referrerpolicy="no-referrer"></a><a href="https://gitee.com/QQxiaoming/quardCRT"><img src="https://gitee.com/QQxiaoming/quardCRT/badge/fork.svg?theme=dark" alt="Gitee forks" referrerpolicy="no-referrer"></a></p><h1><a id="user-content-quardcrt" class="anchor" href="https://gitee.com/QQxiaoming/quardCRT#quardcrt"></a>quardCRT</h1><p><a href="https://gitee.com/QQxiaoming/quardCRT/blob/main/README.md">English</a> | 简体中文</p><p>quardCRT 一款终端仿真软件，支持多种后端协议，无依赖跨平台使用，windows/linux/mac 使用体验完全一致，支持多标签页和历史记录管理。</p><table><thead><tr><th align="center"><img src="https://gitee.com/QQxiaoming/quardCRT/raw/main/docs/windows.png" alt="img2" referrerpolicy="no-referrer"></th></tr></thead><tbody><tr><td align="center">Windows</td></tr><tr><td align="center"><img src="https://gitee.com/QQxiaoming/quardCRT/raw/main/docs/macos.png" alt="img1" referrerpolicy="no-referrer"></td></tr><tr><td align="center">MacOS</td></tr><tr><td align="center"><img src="https://gitee.com/QQxiaoming/quardCRT/raw/main/docs/linux.png" alt="img3" referrerpolicy="no-referrer"></td></tr><tr><td align="center">Linux</td></tr></tbody></table><p>其他协议选择界面：</p><p><img src="https://gitee.com/QQxiaoming/quardCRT/raw/main/docs/img.png" alt="img" referrerpolicy="no-referrer"></p><h2><a id="user-content-功能描述" class="anchor" href="https://gitee.com/QQxiaoming/quardCRT#%E5%8A%9F%E8%83%BD%E6%8F%8F%E8%BF%B0"></a>功能描述</h2><ul><li><p>目前支持的终端协议包括：</p><ul><li>telnet (支持带 websocket 封装)</li><li>serial</li><li>loaclshell</li><li>rawsocket</li><li>windows:NamedPipe（linux/macos:unix domain socket）</li></ul></li><li><p>多标签页管理，标签页克隆，标签页拖拽排序</p></li><li><p>双列分屏</p></li><li><p>工作目录书签</p></li><li><p>自动化发送</p></li><li><p>HEX 显示</p></li><li><p>会话记录管理</p></li><li><p>终端样式配置（配色方案，字体）</p></li><li><p>终端背景图片配置（支持透明度设置，支持 gif 动画和视频）</p></li><li><p>终端滚动行数设置</p></li><li><p>支持深色/浅色主题</p></li><li><p>支持多语言（中文/英文/日文）</p></li></ul><h2><a id="user-content-贡献" class="anchor" href="https://gitee.com/QQxiaoming/quardCRT#%E8%B4%A1%E7%8C%AE"></a>贡献</h2><p>如果您对本项目有建议或想法，欢迎在 GitHub 或 Gitee 上提交 issue 和 pull requests。</p><p>目前项目建议使用版本 Qt6.2.0 及更高版本。</p><h2><a id="user-content-特别" class="anchor" href="https://gitee.com/QQxiaoming/quardCRT#%E7%89%B9%E5%88%AB"></a>特别</h2><p>项目目前为个人业余时间开发，为提高开发效率，本项目较为大量的使用了 GitHub Copilot 协助代码编写，部分代码的人类可读性可能不是很好，作者也会尽量在后续版本中进行优化。</p><h2><a id="user-content-感谢" class="anchor" href="https://gitee.com/QQxiaoming/quardCRT#%E6%84%9F%E8%B0%A2"></a>感谢</h2><p>本项目代码引用或部份参考或依赖了以下开源项目，项目完全尊重原项目开源协议，并在此表示感谢。</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FColinDuquesnoy%2FQDarkStyleSheet">QDarkStyleSheet</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdridk%2FQFontIcon">QFontIcon</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fsilderan%2FQTelnet">QTelnet</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flxqt%2Fqtermwidget">qtermwidget</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkafeg%2Fptyqt">ptyqt</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fbitmeal%2Fargv_split">argv_split</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmbadolato%2FiTerm2-Color-Schemes">iTerm2-Color-Schemes</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Frprichard%2Fwinpty">winpty</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FSM-nzberg%2FQtFancyTabWidget">QtFancyTabWidget</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fteknoraver%2Fqtftp">qtftp</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FJuliaStrings%2Futf8proc">utf8proc</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Ffcitx%2Ffcitx-qt5">fcitx-qt5</a></li></ul>]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 06:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/QQxiaoming/quardCRT</guid>
            <link>https://gitee.com/QQxiaoming/quardCRT</link>
        </item>
        <item>
            <title>
                <![CDATA[M3 MacBook Pro 无法从预装的 'Ventura' 系统升级至 'Sonoma']]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>配备标准 M3 芯片的新款入门级 14 英寸 MacBook Pro 已经开始发货。部分用户发现，这款新产品预装的是 macOS Ventura (13.5)，目前无法通过 OTA 升级的方式升级至 macOS Sonoma (14)。</p><p>这些用户<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Faaronp613%2Fstatus%2F1721742053170684065" target="_blank">表示</a></u>，他们尝试在「系统设置」中更新到 macOS Sonoma 时，系统提示 macOS Ventura 13.5 是可用的最新版本，而非 macOS Sonoma 14.1。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1108/115949_tV93_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>via<em><u>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FZONEofTECH%2Fstatus%2F1721868285732344224" target="_blank">https://twitter.com/ZONEofTECH/status/1721868285732344224</a></u></em></p><p>目前尚不清楚苹果何时会解决这个问题。软件研究员 Nicolás Álvarez 表示，受影响用户可以下载 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fswcdn.apple.com%2Fcontent%2Fdownloads%2F54%2F11%2F042-41700-A_6GDS7ETYNV%2Fzxpkgymp3w9bm3py7ybs9n9ud27qwnwx7u%2FInstallAssistant.pkg" target="_blank">macOS Sonoma 14.1 安装助手</a></u>（兼容 M3 版本）并手动安装更新。</p><p>据称这个问题也会<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F9to5mac.com%2F2023%2F11%2F07%2Fm3-macbook-pro-imac-sonoma-fails%2F" target="_blank">影响</a></u>搭载 M3 芯片的新款 iMac。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 04:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265559/macbook-pro-m3-macos-sonoma-update-issue</guid>
            <link>https://www.oschina.net/news/265559/macbook-pro-m3-macos-sonoma-update-issue</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[IBM 推出 5 亿美元企业 AI 风险投资基金]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">IBM&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fibm-launches-500-million-enterprise-ai-venture-fund-301979178.html" target="_blank">宣布</a>计划对专注于企业 AI 的初创公司进行更多投资，将启动一项 5 亿美元的风险投资基金。该基金将投资「一系列&nbsp;AI&nbsp;公司 —— 从早期阶段到高速增长的初创公司 —— 专注于加速企业的生成式 AI 技术和研究。」</span></p><p><span style="color:#000000">今年 8 月份，IBM&nbsp;还参与了开源 AI 平台 Hugging Face 的 2.35 亿美元 D 轮融资。并在近期参投了 AI 模型和资产安全厂商 HiddenLayer 的 5000 万美元 A 轮融资，此轮融资也是今年专注于保护 AI 的网络安全公司筹集的最大一笔 A 轮融资。</span></p><p><img height="188" src="https://oscimg.oschina.net/oscnet/up-4118d3cd5048d2cdd19ef109bc0e70b828e.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">IBM 方面表示，其企业 AI 风险基金将投资于当前和未来的&nbsp;AI&nbsp;领导者，帮助世界各地的企业实现 AI 的商业潜力。该基金由 IBM 的一支专业团队领导，为每家初创公司提供与 IBM 建立有意义的合作伙伴关系的机会，同时获得产品和工程以及上市方面的运营专业知识策略。</span></p><p><span style="color:#000000">IBM 软件高级副总裁兼首席商务官 Rob Thomas 称，</span></p><p><span style="color:#000000">「到 2030 年，&nbsp;AI&nbsp;预计将创造近 16 万亿美元的生产力。随着 IBM 企业&nbsp;AI&nbsp;风险投资基金的推出，我们正在开辟另一个渠道，利用 AI 革命的巨大潜力，为 IBM 和我们所投资的公司带来实实在在的积极成果。这笔基金是我们通过 watsonx 加倍履行我们对负责任的 AI&nbsp;创新的承诺，并帮助企业将这一变革性技术付诸实践的又一方式。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 03:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265552/ibm-500-million-enterprise-ai-venture-fund</guid>
            <link>https://www.oschina.net/news/265552/ibm-500-million-enterprise-ai-venture-fund</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果副总裁回应「黄金内存」：「统一内存架构」的 8GB 近似于其它系统的 16GB]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>B 站 up 主 @林亦 LYi 最近采访了苹果全球产品营销副总裁 Bob Borchers，期间聊到了大家关心的「祖传黄金 8GB 内存」问题。</p><p>针对苹果入门级 MacBook Pro 只给 8GB 内存的问题，Bob Borchers 表示苹果 MacBook Pro 采用了统一内存架构，所以它与其它系统的内存并不完全相同。因为苹果内存利用率更高，再加上苹果的内存压缩技术，苹果 M3 款 MacBook Pro 中&nbsp;8GB 内存和其它系统的 16GB 表现接近，所以不能只看纸面参数，要关注实际体验。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-93ec8d8aebc69057228bb55fb8b7229e485.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-a317c842c946aae94e3674f1efda6cef21e.png" referrerpolicy="no-referrer"></p><p>【8G 内存？苹果高管怎么看 M3 MacBook Pro？】<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV16M411Q7BG%2F" target="_blank">https://www.bilibili.com/video/BV16M411Q7BG/</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 03:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265547</guid>
            <link>https://www.oschina.net/news/265547</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[腾讯开源高性能轻量级跨平台 QUIC 协议库-TQUIC]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">腾讯开源了一个<span style="background-color:#ffffff">基于 RUST 语言开发的 QUIC 协议库 -&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FwRC2htPOMYevTgfxIY1uWw" target="_blank">TQUIC</a>，<span style="background-color:#ffffff">旨在打造一个稳定、快速、高性能并具有广泛技术影响力的传输协议库。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「</span>由于 QUIC 所具备的广泛性、长期性、创新性特点，我们开源了自研的 TQUIC 协议库，也希望借 TQUIC 开源的机会, 吸引更多的同学共建，一起促进传输协议的发展，提升互联网快速和安全的传输体验。<span style="background-color:#ffffff">」</span></span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">TQUIC 协议库具有如下的优势：</span></p><ul><li style="text-align:start"><span style="color:#000000"><strong>快传输：</strong>TQUIC 是业界支持拥塞控制算法最丰富的协议库，在全部场景下表现符合 RFC 预期，在弱网和部分场景下传输效果领先 2%-30%。</span></li><li style="text-align:start"><span style="color:#000000"><strong>高性能：</strong>TQUIC 在大部分测试场景下的单机处理性能优于同类开源产品 5%，部分场景下单机处理性能领先 20%。</span></li><li style="text-align:start"><span style="color:#000000"><strong>高质量<span style="background-color:#ffffff">：</span></strong>QUIC 协议栈涵盖 10+篇核心的 RFC 标准或草案，同时涉及到传输层、安全层、应用层，复杂度远大于 TCP。TQUIC 单元测试覆盖率 95% 以上，与业界四个主流 QUIC 实现的互操性测试用例通过率为 100%， 同时采用基于形式化规范 (SIGCOMM2019 论文成果）的测试方法，严格保障了协议一致性。</span></li><li style="text-align:start"><span style="color:#000000"><strong>易用性：</strong>TQUIC 易于使用，支持灵活的配置和丰富的可观察性；TQUIC 提供了 Rust/C/C++多语言接口，未来计划进一步提供 Kotlin/Swift 等语言接口。</span></li><li style="text-align:start"><span style="color:#000000"><strong>基于 RUST<span style="background-color:#ffffff">：</span></strong>TQUIC 基于内存安全语言编写，不受缓冲区溢出漏洞和其他与内存相关缺陷影响。</span></li><li style="text-align:start"><span style="color:#000000"><strong>丰富特性<span style="background-color:#ffffff">：</span></strong>TQUIC 支持所有 QUIC 和 HTTP/3 规范的重要特性。</span></li></ul><p>架构图：</p><p><img alt="" height="373" src="https://oscimg.oschina.net/oscnet/up-96c0da66ae752f38efa3109e35055f2ffe9.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">TQUIC 将跨平台兼容及多并发模型支持作为关键的设计目标。TQUIC 核心采用了网络 IO 及事件循环抽象化设计。TQUIC 核心并不依赖于套接字，而是通过用户提供的回调来实现。同时，TQUIC 核心没有强加特定的事件循环要求，它提供了帮助用户调度事件的函数。TQUIC 的灵活性使得易于在各种系统中的定制和集成。</span></p><p style="color:#353535; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">TQUIC 接口层提供了面向主流平台编程语言的高层级封装接口，支持同步、异步语义接口，兼容不同的并发模型，并简化用户的使用。</span></p><p><span style="color:#000000"><strong>后续规划：</strong></span></p><ul><li style="text-align:start"><span style="color:#000000">对接开源技术生态，扩大 TQUIC 使用场景，进一步提升 TQUIC 使用体验。</span></li><li style="text-align:start"><span style="color:#000000">发表相关论文，并逐步开源更多 TQUIC 高级特性和算法。</span></li><li style="text-align:start"><span style="color:#000000">追踪 QUIC 协议的演进和创新，并持续提升 TQUIC 核心能力。</span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 02:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265538</guid>
            <link>https://www.oschina.net/news/265538</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bun 招募运行时工程师，要求 C/C++ 或 Zig 经验，可远程]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Bun 公司正在招聘运行时工程师。Bun 是速度极快的 JavaScript 运行时，采用 Zig 编写，集打包器、转译器和包管理器于一身。</p><h4><strong>任职要求</strong></h4><ul><li><p>在系统编程语言如 Zig 或 C/C++方面有丰富的经验</p></li><li><p>对互联网技术如 JavaScript/TypeScript 和 HTTP 有深入理解</p></li><li><p>热衷于编写快速高效的代码</p></li></ul><h4><strong>加分项</strong></h4><ul><li><p>具有 Zig 的经验（大部分的 Bun 都是用 Zig 编写的）</p></li><li><p>具有 JavaScript 运行时深入层面的经验：JavaScriptCore、V8、SpiderMonkey</p></li><li><p>理解 UNIX 系统、内核、TCP/UDP 网络</p></li><li><p>理解如何构建多租户，大规模分布式系统</p></li><li><p>开源软件的维护者或频繁的贡献者</p></li></ul><h4><strong>福利</strong></h4><ul><li><p>位置：旧金山市中心有自己的办公室，并且每天提供免费午餐</p></li><li><p>远程工作 OK：如果愿意搬到旧金山，会提供额外的奖金，但可以在任何地方远程办公</p></li><li><p>薪酬：提供具有竞争力的薪酬，包括创业公司的股权，并根据贡献提供成长空间</p></li><li><p>医疗保健：提供灵活的健康计划，涵盖身体和精神健康护理</p></li><li><p>休假：每年享有四周的带薪休假，包括灵活的病假、家庭假和心理健康假</p></li><li><p>补贴：通勤到办公室，电脑硬件，办公室设置，以及健身习惯等方面提供支持</p></li></ul><p><img height="1762" src="https://static.oschina.net/uploads/space/2023/1108/103613_dUzY_3820517.png" width="1458" referrerpolicy="no-referrer"></p><p>详情查看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapply.workable.com%2Foven%2Fj%2FA7A1388873%2F" target="_blank">https://apply.workable.com/oven/j/A7A1388873</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 02:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265534/bun-hiring-runtime-engineer</guid>
            <link>https://www.oschina.net/news/265534/bun-hiring-runtime-engineer</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[HelloGitHub 社区动态，开启新的篇章！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231107191851907-206780890.png" alt="" referrerpolicy="no-referrer"></p><p>今天这篇文章是 HelloGitHub 社区动态的第一篇文章，所以我想多说两句，聊聊为啥开启这个系列。</p><p>我是 2016 年创建的 HelloGitHub，它从最初的一份分享开源项目的月刊，现如今已经成长为 7w+ Star 的开源项目、1w+ 用户的开源社区、全网 50w+ 的自媒体。</p><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231107185115225-596937695.png" alt="" referrerpolicy="no-referrer"></p><p>我本是一名普通的程序员，三流的技术水平、毫无文笔、开源门外汉，起初连 Git 都不会，也不知道什么是开源，就一个猛子扎进来做了 HelloGitHub。为了想让更多人看到 HelloGitHub 月刊，稀里糊涂地就做起了「自媒体」。我为了圆自己的站长梦，饿着肚子咬牙重构了 HelloGitHub.com 网站，从最初的 Web 1.0 的月刊展示，升级到了 Web 2.0 的开源社区。</p><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231108085617330-199475160.png" alt="" referrerpolicy="no-referrer"></p><p>聪明的人追着风口跑，很容易就赚到钱了。像我这种愚笨的人，只做「分享开源项目」这一件事情，就花了 7 年的事情，钱没赚到人还瘦了两圈😂。</p><p>有人说我不会玩流量，确实我不会，因为在我眼里每一次点击、每一个阅读、每一位粉丝背后都是我的一位朋友。说起来真是惭愧，就是我和朋友们的沟通太少了，因为<strong>我总想一个人、一台电脑、一把键盘，做出让人拍手称赞的事情</strong>。这件事我试过了，我自己搞不了！</p><p>有错就要认，挨打要立正。所以，我决定经常和朋友们说说关于 HelloGitHub 社区的事情，<strong>希望通过这个系列打开一个窗口，让社区成员了解项目的发展方向，想加入进来的人知道自己能做些什么</strong>，同时我也能多了解大家的想法，多和朋友们讨论，凝聚更多人的力量。</p><p>所以，就有了这篇「HelloGitHub 社区动态」的文章，我是这样想的：以后每个月月初写一下上个月关于 HelloGitHub 社区发生的事儿、未来要做的事儿、大家一起能做的事儿。<strong>一群人做一件值得骄傲的事情</strong>，这事儿没准能成！</p><p>我要说的就这些，下面正文开始。</p><h2>一、介绍</h2><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231107185411363-1285676789.gif" alt="" referrerpolicy="no-referrer"></p><p>HelloGitHub 是一个分享 GitHub 上有趣、入门级开源项目的开源社区，由一群热爱开源的小伙伴运营，我们<strong>因开源而相聚，为兴趣而付出</strong>，希望通过分享和讲解开源项目，帮助大家找到编程的乐趣、轻松搞定问题的技术方案、令人惊叹的开源神器，从而顺应内心的渴望，毫无保留地踏上开源之旅。</p><h2>二、社区动态</h2><p>接下来，我将和「在座」的各位汇报下 10 月份的 HelloGitHub 开源社区的项目进展、贡献者和未来计划，欢迎朋友们为社区的建设提供建议、反馈和做贡献，让我们并肩携手共创 HelloGitHub 社区。</p><ul><li>项目进展：介绍主要项目的最新进展情况，包括新增功能、修复的问题、</li><li>贡献者：表彰和赞扬过去一个月对项目做出杰出贡献的个人，欢迎新加入开源社区的贡献者，以及在做的事情和经验分享。</li><li>下一步计划：聊一聊接下来要做的事情。</li></ul><h3>2.1 项目进展</h3><p>HelloGitHub 的项目概览：</p><ol><li>月刊：这里有好玩、有趣、入门级的开源项目，每月 28 号发刊。</li><li>热点速递：每周一更新的周刊，分享和介绍 GitHub 过去一周的热点项目。</li><li>讲解系列：通过一篇文章的篇幅带你入门一款开源项目，不定期更新。</li><li>社区网站：围绕开源项目建立的社区，大家可以在这里分享、发现、评论、打分、收藏感兴趣的开源项目。</li></ol><p><strong>社区网站</strong></p><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231107185145824-1576267720.gif" alt="" referrerpolicy="no-referrer"></p><p>上个月主要做了用户反馈最多的「标签功能」的优化，入口在 PC 端访问社区的左侧「管理标签」按钮（需登录）。详情如下：</p><ol><li>为标签设置了分组，分成了编程语言、技术栈、应用类型、其它共 4 组，方便用户更快地找到自己感兴趣的标签，对于没有编程能力的朋友也可以通过桌面应用、Android、Windows、macOS 等标签找到开箱即用的应用。</li><li>支持拖拽的方式选择标签和排序。</li><li>新增 PHP、Ruby、Flutter、嵌入式、Docker、Vue 等 13 个标签。</li></ol><blockquote><p>地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhellogithub.com%2F" target="_blank">https://hellogithub.com/</a></p></blockquote><p><strong>内容</strong></p><p>HelloGitHub 自媒体 10 月份共发布了 4 篇 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzA5MzYyNzQ0MQ%3D%3D%26action%3Dgetalbum%26album_id%3D1332112026222641153%26scene%3D173%26from_msgid%3D2247516881%26from_itemidx%3D1%26count%3D3%26nolastread%3D1%23wechat_redirect" target="_blank">GitHub 热点速递</a>、1 篇<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzA5MzYyNzQ0MQ%3D%3D%26action%3Dgetalbum%26album_id%3D1332147780885856258%26scene%3D173%26from_msgid%3D2247516865%26from_itemidx%3D1%26count%3D3%26nolastread%3D1%23wechat_redirect" target="_blank">讲解开源项目的文章</a>、1 篇 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fmp%2Fappmsgalbum%3F__biz%3DMzA5MzYyNzQ0MQ%3D%3D%26action%3Dgetalbum%26album_id%3D1331197538447310849%26scene%3D173%26from_msgid%3D2247516838%26from_itemidx%3D1%26count%3D3%26nolastread%3D1%23wechat_redirect" target="_blank">HelloGitHub 月刊</a>。</p><h3>2.2 贡献者</h3><p>因为这是第一篇社区动态，所以我必须要感谢下 2023 至今的所有贡献者，他们的每个贡献对于我来说都是雪中送炭，主要集中于 HelloGitHub 社区前端代码的贡献。</p><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231107185421588-1660267532.png" alt="" referrerpolicy="no-referrer"></p><ul><li>@胤玄、@cqh：完成管理标签功能的设计和优化</li><li>@胤玄：修复月刊目录的问题、修复了弹出对话框后背景页面滚动的问题</li><li>@GJSSS：修复图片预览时没有关闭图标的问题、主题切换按钮的样式</li><li>@Maidang：修复黑暗主题下点击详情页的问题</li></ul><p><strong>如何贡献</strong></p><p>如果你会写代码可以加入到 HelloGitHub 社区的开发中，前后端都需要。</p><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231107185426160-863675536.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>需求列表：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FHelloGitHub-Team%2Fgeese%2Fissues%2F38" target="_blank">https://github.com/HelloGitHub-Team/geese/issues/38</a></p></blockquote><p>如果你喜欢写文章欢迎投稿到 HelloGitHub，可以是你上手开源项目的经过、开源项目评测对比、有趣的开源项目集合等，不用担心写得不够好，只要是用心写的内容，我会和你一同完成它。</p><p>如果你发现了优秀的开源项目，欢迎分享到 HelloGitHub 让更多人知道。</p><p><img src="https://img2023.cnblogs.com/blog/759200/202311/759200-20231107185430278-2003963940.gif" alt="" referrerpolicy="no-referrer"></p><p>希望 HelloGitHub 能成为你开源之路的第一站，让我们一同成长，一起做值得骄傲的事情。</p><h3>2.3 下一步计划</h3><p>为了能让「社区动态」持续更新，所以每个月必须做出点成绩来，才能向大家汇报。第一期我就说一下我自己下一步的打算，后面会结合朋友们的想法，来制定下一步计划：</p><ol><li>帮助新加入的贡献者为 HelloGitHub 做贡献，多沟通、提供保姆级帮助。</li><li>完成网站搜索功能的优化，打通公众号，即在公众号发消息也能得到开源项目搜索结果。</li><li>为网站加入 AIGC 的功能，比如：根据自然语言描述推荐开源项目。</li><li>我想采访一些「民间」做开源的人，讲出他们的故事。</li><li>做视频自媒体，这个事情我一直想做但始终没有走出第一步，希望有人能推我一把。</li><li>天冷了是时候吃一顿火锅了，搞一个线下的「开源人火锅局」，互认识一下聊聊开源的酸甜苦辣，看看有没有臭味相投的人。</li></ol><p>对上面的计划感兴趣的小伙伴，欢迎与我联系一起搞事情，也可以留言说出你的想法。</p><h2>三、最后</h2><p>如果把开源当成是一个爱好的话，就不会去深究为什么要花时间在上面，因为从中能得到快乐和满足感，就够了。</p><p>最后，希望有了大家的陪伴，我们彼此的开源之路不再孤单和苦闷，而是充满更多的欢声笑语。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 02:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HelloGitHub/blog/10141490</guid>
            <link>https://my.oschina.net/HelloGitHub/blog/10141490</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LME - 日志记录和保护性监控解决方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Logging Made Easy (LME) 是一个免费、开放的日志记录和保护性监控解决方案，为所有组织提供服务。</p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Logging Made Easy 最初由 NCSC 创建，现在由 CISA 维护，是一个为小型组织提供的自助安装教程，旨在为 Windows 客户端获得基本级别的集中安全日志记录并提供检测攻击的功能。它是多个免费和开放软件平台的结合，LME 帮助读者将它们集成在一起以产生端到端的日志记录功能。还提供了一些预制的配置文件和脚本。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>该项目可以：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>显示已注册设备上运行管理命令的位置</li><li>查看谁在使用哪台机器</li><li>结合威胁报告，可以以策略、技术和程序 (TTP) 的形式查询攻击者的存在</li></ul><p><img height="229" src="https://static.oschina.net/uploads/space/2023/1101/164801_RGai_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 07 Nov 2023 01:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/lme</guid>
            <link>https://www.oschina.net/p/lme</link>
        </item>
        <item>
            <title>
                <![CDATA[【店滴云】免费的茶室棋牌室管理系统，修复 phpenv 函数禁用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>店滴云介绍：</p><p><span style="background-color:#ffffff; color:#40485b">店滴云，让经营场所，更智能。围绕茶室、酒店、健身房、公寓、出租房等经营性场所进行物联网改造。同时支持多种物联网通信协议，开放智能门锁，智能开关，智能手环的 sdk 供开发者使用。</span></p><p><br><img alt="" height="600" src="https://oscimg.oschina.net/oscnet/up-db38d0aa5ae4bd6f22c7530a292b6b83c2b.png" width="1920" referrerpolicy="no-referrer"></p><p>1、大部分的伙伴安装使用我们的系统都是在宝塔安装，存在的问题就是禁用了 phpenv 函数，导致数据库和 redis 配置不能正确获取。我们在安装的过程中进行友情提示，方便不知情的伙伴快捷安装。</p><p>2、修复 setting 数据，部分数据不初始化不能正常显示后台菜单</p><p>3、<span style="color:#54b33e">/frontend/backend/pro-admin/configs/configs.js ，该文件中的域名配置安装后需要修改为自己的域名。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 14:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265466</guid>
            <link>https://www.oschina.net/news/265466</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Mozilla Firefox 开发将完全转向 Git，放弃 Mercurial]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Mozilla 负责工作流和发布管理的高级工程经理&nbsp;Glob&nbsp;在 firefox-dev 邮件列表中<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgroups.google.com%2Fa%2Fmozilla.org%2Fg%2Ffirefox-dev%2Fc%2FQnfydsDj48o%2Fm%2F8WadV0_dBQAJ" target="_blank">表示</a>，Firefox 开发正在从 Mercurial 转向 GIT，以减轻开发团队的压力。</span></p><blockquote><p><span style="color:#000000">长期以来，Firefox Desktop 开发一直同时支持 Mercurial 和 Git 用户。这种双 SCM 要求给部分已经捉襟见肘的团队带来了沉重负担。我们已经决定将 Firefox 开发转移到 Git。</span></p><ul><li><span style="color:#000000">我们将继续使用 Bugzilla、moz-phab、Phabricator 和 Lando。</span></li><li><span style="color:#000000">尽管我们将在 GitHub 上托管版本库，但我们的贡献工作流程将保持不变，而且我们目前不会接受拉取请求。</span></li></ul></blockquote><p><span style="color:#000000">目前相关事项仍在规划中，预计至少六个月后才会开始全面的 Git 过渡。过渡完成后，Mercurial 将从 Firefox 开发工作流程中完全淘汰。</span></p><p><img height="225" src="https://oscimg.oschina.net/oscnet/up-4b4cc1a8fcad1764d254f09eae44065f9c2.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">根据介绍，这项工作将分为两个部分进行：首先是面向开发人员的工作。项目团队将把主仓库从 Mercurial 切换到 Git，同时在开发人员的工作站上移除对 Mercurial 的支持。开发人员将需要在本地使用 Git，并继续使用 moz-phab 提交补丁以供审核。</span></p><p><span style="color:#000000">然后是后端基础架构的零散迁移。各个团队计划逐步将 Mercurial 上的基础架构迁移到 Git 上。在这一阶段结束时，预计可实现从基础架构中完全移除对 Mercurial 的支持。</span></p><p><span style="color:#000000">Mercurial 是一款开源的分布式源代码控制管理工具，采用 Python 语言实现，易于学习和使用，扩展性强。它可以有效地处理任何规模的项目，并提供简单直观的界面。Mercurial 由 Olivia Mackall 于 2005 年创建，作为 BitKeeper 的替代品用于管理 Linux 内核的源代码，以应对 BitKeeper 免费版的停产。</span></p><p><span style="color:#000000">更多详细信息可查看</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgroups.google.com%2Fa%2Fmozilla.org%2Fg%2Ffirefox-dev%2Fc%2FQnfydsDj48o%2Fm%2F8WadV0_dBQAJ" target="_blank">邮件列表公告</a><span style="color:#000000">。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 10:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265431/firefox-going-git</guid>
            <link>https://www.oschina.net/news/265431/firefox-going-git</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国际测试委员会 BenchCouncil 首发「开源系统杰出成果榜」 百度飞桨上榜]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，BenchCouncil（国际测试委员会）颁布首个开源系统杰出成果榜（1960s-2021），评选了开源方面具有巨大影响并对软硬件发展产生重大推动作用的顶级成果。百度飞桨深度学习框架 PaddlePaddle 成功上榜。<br><br> BenchCouncil（国际测试委员会）邀请了多位独立科学家，从 20 世纪 60 年代至 2021 年的开源或对开源产生重要影响的成果中，遴选出了 145 项代表性成果。据其官网显示，获评项目遵循以下评选标准：奠定或促进开源运动的关键里程碑工作；原创或开创性的开源工作；对软硬件发展具有重大推动作用的开源工作；被工业界或者学术界广泛使用的开源工作。<br><br><img alt="" height="786" src="https://oscimg.oschina.net/oscnet/up-a7df58c2f8bb1e56d38631e6d5b77669e52.png" width="1241" referrerpolicy="no-referrer"><br> 图：BenchCouncil 评选开源系统杰出成果（1960s-2021）<br><br> 飞桨 PaddlePaddle 自 2016 年开源，是中国最早自研开源的深度学习框架，现已发展为集核心框架、基础模型库、开发套件、工具组件和 AI Studio 星河社区于一体的产业级深度学习开源开放平台。飞桨具备四大领先技术，包括开发便捷的深度学习框架、超大规模深度学习模型训练技术、多端多平台部署的高性能推理引擎和产业级模型库。在与文心大模型的联合优化中，飞桨积累了大模型训练、适配和推理部署的领先技术优势，有力支撑人工智能技术创新和大规模产业应用。<br><br> 同时，开源生态是人工智能发展的重要基础。飞桨建设了中国最大的 AI 开发者社区 AI Studio 星河社区，联合框架开发者、算法研究者、硬件和应用开发者等共同推动人工智能技术及应用的创新。截至 2023 年 8 月，飞桨平台开发者数超过 800 万，服务 22 万家企事业单位，基于飞桨创建了 80 万个模型。<br><br> 据《2022 中国开源年度报告》数据显示，飞桨 PaddlePaddle 开源项目位列 GitHub 中国项目活跃度榜首；在 Linux 基金会公布的全球开源项目中，飞桨开源动力指数进入国际 Top30。<br><br> 现阶段，人工智能已经成为新一轮科技革命和产业变革的重要驱动力量。深度学习框架处于人工智能技术体系的关键位置，相当于智能时代的操作系统。深度学习框架加上大模型，进一步加强了人工智能的通用性，推动人工智能进入到工业大生产阶段。飞桨产业级深度学习开源开放平台加上文心大模型，为广大开发者和各行各业提供了共建共创人工智能技术和产业生态的坚实支撑。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 09:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265415</guid>
            <link>https://www.oschina.net/news/265415</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龙芯中科董事长、总经理胡伟武答网友与投资者]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>龙芯中科 2023 年第三季度业绩说明会于昨日召开，在与投资者和网友互动问答环节，<span style="background-color:#ffffff; color:#333333">龙芯中科董事长、总经理胡伟武解答了许多问题。</span></p><p><span style="background-color:#ffffff; color:#333333">下文摘录了部分问答（回答者均为龙芯中科</span>董事长、总经理，胡伟武<span style="background-color:#ffffff; color:#333333">）。</span></p><p>完整回顾：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frsc.sseinfo.com%2FroadshowIndex.do%3Fid%3D16536" target="_blank">https://rsc.sseinfo.com/roadshowIndex.do?id=16536</a></u></em></p><hr><h4><strong>开源、技术相关</strong></h4><p>您好！先前路演中，提过龙芯对于开源（个人理解为免费授权）与收费的思考，圈子里很多同学对关于「不开源」的论述有顾忌。能否借此机会明确下：龙芯法务对第三方独立完成的龙架构软硬件实现，以及善意的二次创作（如将指令集手册整理为方便查阅的网站等）持何种态度？</p><p>另外社区 Linux 发行版能否打包龙芯原创软件（如 Lbrowser、LATX、应用合作社等）？目前这些软件缺乏 EULA，保守起见是不能打包的，对这些系统的用户不太友好。</p><blockquote><p>在 11 月底的发布会上，龙芯会与使用龙芯 IP 及架构的开放授权客户签约，敬请关注。</p><p>开源与兼容是一个矛盾，Linux 没打败 Windows、OpenCL 在 Cuda 面前输得一塌糊涂，主要是参与者没有形成合力。我们正在找到一条既开源又兼容的路径，使得大量基于龙架构做芯片的人软件是兼容的。</p><p>感谢你关于 Linux 发行版的建议，我们会认真考虑。</p></blockquote><p>&nbsp;</p><p>关于生态建设方面，目前虽说龙芯 Loongnix 被官方称作「开源社区」，但它工单系统、代码仓库等不公开，协作渠道只有 service@loongnix.cn 一个邮箱，很难想像如何组织起有效的第三方参与。</p><p>作为国内为数不多的「根社区」，龙芯是否考虑将相关设施开放公开访问，为其他行业参与者树立样板？</p><blockquote><p>我们正在改进，建设统一入口的龙芯生态社区。</p></blockquote><p>&nbsp;</p><p>请问龙芯有无计划开发 ARM 的二进制翻译, 在什么契机下面向市场和社会公开?</p><blockquote><p>有。目前重点是在龙芯平台上运行 X86/Windows 应用，下一步要在龙芯平台上运行 ARM/Android 应用（已经开始部署）。</p><p>我以前说过要通过指令系统的创新消灭指令系统差异，一步步都会做到的。</p></blockquote><p>&nbsp;</p><p>龙芯的编程框架、二进制编译进展如何了？编程框架大概何时能发布？软件的可通用性在开放市场很重要。</p><blockquote><p>二进制翻译在别的问题回答过了。通用编程框架计划随龙芯 GPGPU 同步推出。</p></blockquote><p>&nbsp;</p><p>二进制翻译目前进展怎么样，什么时候可以产品化</p><blockquote><p>X86/Linux 的二进制翻译趋于稳定。X86/Windows 的打印机、IE 浏览器兼容问题基本解决，正在做通用平台，最近有很多应用可用了，而且比较流畅，但这是个大工程。</p><p>我希望，二进制翻译结合 3B6000 的推出可以到个人电脑的开放市场试试看。</p></blockquote><p>&nbsp;</p><p>胡老师好，请问：<br> 1，龙芯 3 系调频技术何时能够实现？<br> 2，龙芯系统（Loongnix）何时能够升级至新世界？<br> 3，后续是否有推动商业软件迁移至新世界的计划？ 谢谢！</p><blockquote><p>Loongnix 升级至新世界与 Debian 对龙芯的支持同步，请关注 Debian 对龙架构的支持。</p><p>我们已经基本解决了在新世界上运行老世界应用的兼容性问题，正与统信等操作系统企业合作，争取下一版操作系统支持新世界。</p></blockquote><p>&nbsp;</p><p>龙芯有无计划结合自身 JIT 方面优势做一些产品的适配和服务器或高性能领域的研发?</p><blockquote><p>感谢肯定与建议，是可以在这方面做工作，甚至未来可以做些芯片级的加速。</p></blockquote><p>&nbsp;</p><p>很期待公司的 GPGPU，能否适当吐露一些进展或者目标吗？比如是否会研发自己的神经网络框架？专门的 gpgpu 产品的计算能力大概在多少 (如 int8 或 float32)？</p><blockquote><p>在 2K3000 中 INT8 大概 8TOPS，在 9A1000 中 INT8 大概 32TOPS。同时，多个 9A1000 通过龙链互连形成更高性能。</p></blockquote><p>&nbsp;</p><p>请问可以说明一下龙链技术有哪些优势吗？</p><blockquote><p>一般高速互连包括物理、链路、协议层，像 PCIE 这样的接口协议每一层都要打包拆包，nvlink 及 CXL 这样的协议，协议层直接面向物理层设计，提高了效率。龙链跟 3A5000 的片间互联协议比，片间互联延迟成倍降低，带宽提高了好几倍，大大提高多片协同工作的性能。</p><p>龙链跟 nvlink 比，速率还低一些（目前每位速率是 16Gbps，下一步将提高到 32Gbps），但效率已经不错了。</p></blockquote><h4>&nbsp;</h4><h4>行业、政策相关</h4><p>请问胡老师，3A6000 何时正式发布？龙芯能否跳过 3B6000 直接研发 7nm 的 3A7000, 时不我待！</p><blockquote><p>3A6000 将于 11 月底正式发布，十几家整机/ODM 企业将发布其整机产品。</p><p>我感觉在目前的工艺上还应该提高性能 20%-30%。换个新工艺也就提高这么多。7nm 流片费用很高，一次得上亿元，不能用该工艺试错，用已有工艺完成结构试错后再改到更先进工艺。</p><p>另外，龙芯坚持 IP 的自主研发，在新工艺上，要研制 DDR5 PHY、PCIE PHY、各类寄存器堆、锁相环等 IP，现在已经开展对新工艺的评估，2024 年将研制这些 IP 并开展测试片研制，等这些 IP 成熟了，3B6000 也完成了对新结构的验证，时间是对得上的。</p></blockquote><p>&nbsp;</p><p>对于目前信创的主要竞争对手海光和华为各自的竞争力如何看？</p><blockquote><p>（1）商业模式不同，龙芯可以比作 Intel，华为是整机企业可以比作 IBM，海光与曙光也形成了事实上的 IBM 模式。<br> （2）龙芯做生态，他们做产品，这是主要不同。<br> （3）龙芯把信创作为走向开放市场路上的驿站，作为试错场景，最终面向开放市场和海外市场。</p></blockquote><p>&nbsp;</p><p>目前在龙芯桌面主机上还是看到一些挑内存现象，请问后续龙芯这方面有没有优化计划，尽可能做到市场主流品牌的内存插上即用。</p><blockquote><p>感谢你的问题。我们会进行持续改进。</p></blockquote><p>&nbsp;</p><p>您认为龙芯的销售是否存在不接地气的情况呢？</p><blockquote><p>理论上，龙芯主要面对整机企业，在整机企业积极性不足的情况下直接推动一些用户单位。</p><p>过去确实存在对计算机产业链不熟悉的情况，过去一年多已经有较大进步，从整机、渠道、应用单位三个环节完善产业链。</p></blockquote><p>&nbsp;</p><p>作为一个国产爱好者，请问龙芯 3a6000 对国产的电脑配件适配情况怎么样？比如长江致钛、摩尔线程、金百达等的适配情况。</p><blockquote><p>我们与自主内存、硬盘、显卡的很多合作伙伴都已经完成适配或者正在适配。</p></blockquote><p>&nbsp;</p><p>请问胡老师，龙芯与俄罗斯方面的合作是否会更深入，我个人认为龙芯应该积极与俄方合作，有利于双方打破僵局</p><blockquote><p>谢谢你的建议。 目前龙芯的营收均来自境内客户。</p><p>龙芯是一个通用 CPU 企业，会联合一带一路国家打造独立于 X86 和 ARM 体系的第三套体系。</p></blockquote><p>&nbsp;</p><p>龙芯 cpu 的性能还是不错的，但是绝大部分人对于专业软件的测试成绩是没有概念的。可否在线下设立一些龙芯电脑体验店，或者开放一些远程桌面？让有心支持国产的消费者亲身体验下是否能够满足自身需求来决定购买。</p><blockquote><p>谢谢建议。我们会认真考虑实施。</p></blockquote><p>&nbsp;</p><p>胡老师，很看好龙芯的 gpgpu 发展，相信有一天也会跟龙芯的 CPU 一样在国内一骑绝尘，请问龙芯有没有在车机或者智能芯片布局的计划，做出像高通 8155 车机芯片，地平线征程系列那样的智驾芯片计划？</p><blockquote><p>龙芯目前主要做面向推理的 AI 芯片，形成 CPU+GPGPU 的最佳解决方案。</p><p>我相信，随着应用的拓展，龙芯芯片的 AI 应用会很普遍。</p></blockquote><p>&nbsp;</p><p>胡老师您好！请问 2022/2023 年政策性市场停滞的原因主要是什么？2024/2025 年政策性市场能否像预期一样放量？</p><blockquote><p>感觉 2023Q4，政务类政策性市场部分回暖。我自己对 2024/2025 年预期不变。</p></blockquote><p>&nbsp;</p><p>龙芯以前介绍过车规级 mcu 印象说的好像是流片了，目前有没有新进展？龙芯对于新能源汽车领域有没有大的布局？感觉这块是一个大的市场，特别是当前形势下，龙芯这种有硬实力的 CPU 企业在国产替代大有可为。</p><blockquote><p>已经与部分汽车企业开展 MCU 替换工作。龙芯会把电机驱动作为重点方向。</p></blockquote><p>&nbsp;</p><p>1、可否简单介绍一下一带一路国家市场整体布局节奏和规划？<br> 2、农村包围城市的大策略是对的，不过如果整机终端有标杆性大客户是否可以更好的带动芯片销售？<br> 3、龙芯芯片整体性能不错的情况下，解决特定的某一项或两项需求痛点，形成差异化优势，也许可以脱颖而出？&nbsp;</p><blockquote><p>总体上说，龙芯要联合一带一路国家形成新型信息技术体系和产业生态，在不断探索中。</p><p>信创市场会带动龙芯技术进步，同时也有不少品牌整机客户支持龙芯，整机客户主要是看性价比。</p><p>我相信，如果龙芯性价比达到一定水平，肯定会有越来越多的品牌整机使用。同时，要做第三套生态，一定要重构产业链。 感谢你的建议，我最近多次讲的「点面结合」中的「点」与你的第三点建议是一致的。</p></blockquote><p>&nbsp;</p><p>能否加快 GPGPU 的研发，不要怕花钱，这是一个新兴市场，速度越快越好。</p><blockquote><p>待 2K3000 中得到验证后，会加速研发的。主要是自主研发需要迭代。</p></blockquote><p>&nbsp;</p><p>有企业采购和技术人员表示龙芯销售人员很不专业，没法解释龙芯的特点和优点，没法回应对手的攻击销售术语，没销售技巧，有的地区销售人员甚至已经消失了很长时间。请问龙芯销售人员是否熟悉龙芯产品，日常是否使用过龙芯自家的产品，以后怎么提高。</p><blockquote><p>龙芯公司包括办公电脑、邮件服务器、网站服务器、OA 服务器、ERP 服务器、网络安全产品，均使用龙芯 CPU。</p><p>龙芯的销售需要改进的地方挺多的，正在改进中。但我要求销售要有底线。</p><p>总体上，龙芯发展的主要矛盾还是产品能否满足市场需求的矛盾，主要体现在系统性价比和软件生态。</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 07:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265392</guid>
            <link>https://www.oschina.net/news/265392</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[马斯克旗下 AI 公司推出 PromptIDE 工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>马斯克旗下 AI 公司 xAI <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.ai%2Fprompt-ide%2F" target="_blank">宣布推出 PromptIDE 工具</a></u>，需要使用 X 账户登录。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8e71bf70af935eb153aa1cc26a973d0f5c9.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.ai%2Fprompt-ide%2F" target="_blank">https://x.ai/prompt-ide/</a></u></em></p><p>PromptIDE 是一个<strong>用于提示工程和可解释性研究的集成开发环境</strong>。它通过 SDK 加速提示工程，该 SDK 允许实现复杂的提示技术和丰富的分析功能，从而实现网络输出可视化。</p><p>IDE 的核心是一个 Python 代码编辑器，它可以与新的 SDK 结合实现复杂的提示。在 IDE 中执行提示时，用户会看到一些有用的分析和建议，例如精确标记化等等。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cabd374d49271e12b2b6a54648df587857b.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-162ef024f3eb0fff93e05bc242b6fe28ba8.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f6174ba792122df3fda5a272ff68e00d9e9.png" referrerpolicy="no-referrer"></p><p>xAI 官方表示，他们开发 PromptIDE 是为了向社区的工程师和研究人员<strong>透明地提供 Grok-1 的透明访问权限</strong>。该 IDE 旨在赋予用户权力，帮助他们快速探索大型语言模型（LLMs）的魅力。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 06:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265374</guid>
            <link>https://www.oschina.net/news/265374</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[极致性能优化：前端 SSR 渲染利器 Qwik.js | 京东云技术团队]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://my.oschina.net/u/3859945/blog/10141334" target="_blank">答开源创业 15 问：选协议、维权、公关、找钱······ <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><span id="OSC_h1_1"></span><h1><span><span><span>引言</span></span></span></h1><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>前端性能已成为网站和应用成功的关键要素之一。用户期望快速加载的页面和流畅的交互，而前端框架的选择对于实现这些目标至关重要。然而，传统的前端框架在某些情况下可能面临性能挑战且存在技术壁垒。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>在这个充满挑战的背景下，我们引入了 Qwik.js 框架。Qwik.js 不仅是一个前端框架，更是一种前端性能的终极解决方案。它不仅提供了卓越的性能，还以其独特的特点和优势脱颖而出。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>让我们一起深入探索 Qwik.js，发现它如何超越传统，成为前端性能优化的新标杆。</span></span></span></p><span id="OSC_h1_2"></span><h1><span><span><span>一、现有框架的问题</span></span></span></h1><span id="OSC_h4_3"></span><h4><span>1.</span><span><span><span><span>传统 CSR 方案</span></span></span></span></h4><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>慢加载时间：</span></strong></span></span><span><span><span> CSR 技术通常要求在浏览器中加载和渲染整个页面，这导致初始页面加载时间较长。用户必须等待页面完全加载才能进行交互。 </span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>搜索引擎优化（SEO）问题：</span></strong></span></span><span><span><span> 由于页面内容是在客户端生成的，搜索引擎爬虫可能无法正确解析和索引页面内容，这影响了网站的 SEO 效果。 </span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>不利于低带宽用户：</span></strong></span></span><span><span><span> 对于低带宽用户或网络条件较差的用户，CSR 页面加载时间更长，用户体验更差。 </span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>首屏渲染延迟：</span></strong></span></span><span><span><span> CSR 通常需要等待 JavaScript 文件的下载和执行，这导致了首屏渲染的延迟，影响了用户的第一印象。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>问题分析</span></strong></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>A. 渲染阶段耗时分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="108" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-13xZmbiiPDHyfVKHl.png" width="588" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:left"><span><span><span>B. 请求链路分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="311" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-14Jn48bC9MLjg7uj48.png" width="291" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:left"><span><span><span>C. 浏览器执行渲染分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="230" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-15HAl9koUb6m9MG98.png" width="345" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><span id="OSC_h4_4"></span><h4><span><span><span>2. 传统 SSR 方案</span></span></span></h4><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>复杂的水合过程：</span></strong></span></span><span><span><span> 涉及复杂的水合过程，包括将数据传输到客户端并在客户端重新渲染页面。这增加了页面加载时间和网络开销。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>A. 请求链路分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="366" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-27a6p7RKalKkQgqE12.png" width="275" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:left"><span><span><span>B. 浏览器执行渲染分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="236" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-23GQJadOUFvz9gVjT.png" width="387" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><span id="OSC_h4_5"></span><h4><span><span><span>什么是水合（Hydration）？</span></span></span></h4><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>"hydration"（水合）是指通过客户端 JavaScript 将静态 HTML 网页转化为动态网页的过程，以实现对 HTML 元素的事件处理。这个过程可以通过将事件处理程序附加到 HTML 元素上来完成</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="304" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F4f48568655904e4586ba34b413beb790?width=580" width="390" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p><span><span><span>深入了解水合（hydration）过程，水合的难点在于知道我们需要什么事件处理程序以及它们应该附加到哪里。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>WHAT（什么）</span></strong></span></span><span><span><span>：事件处理程序是一个封闭包，包含了事件处理程序的行为。它定义了当用户触发此事件时应该发生什么。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>WHERE（哪里）</span></strong></span></span><span><span><span>：指的是需要将 WHAT（事件处理程序）附加到的 DOM 元素的位置，这包括了事件类型。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>更复杂的部分在于，WHAT（事件处理程序）是一个封闭包，它封闭了 APP_STATE（应用程序状态）和 FRAMEWORK_STATE（框架内部状态）：</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>APP_STATE（应用程序状态）</span></strong></span></span><span><span><span>：这是应用程序的状态。APP_STATE 通常是人们所说的状态。没有 APP_STATE，您的应用程序将无法向用户展示任何动态内容。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><strong><span>FRAMEWORK_STATE（框架内部状态）</span></strong></span></span><span><span><span>：这是框架的内部状态。没有 FRAMEWORK_STATE，框架不知道应该更新哪些 DOM 节点以及何时应该更新它们。这包括组件树和对渲染函数的引用等内容。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>那么，我们如何恢复 WHAT（APP_STATE + FRAMEWORK_STATE）和 WHERE 呢？方法是通过下载并执行当前 HTML 中的组件。在 HTML 中下载和执行已渲染的组件是水合的昂贵部分。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>换句话说，水合是一种通过在浏览器中急切地执行应用程序代码来恢复 APP_STATE 和 FRAMEWORK_STATE 的方法，它涉及以下步骤：</span></span></span></p><ol><li><span><span><span><span>下载组件代码。</span></span></span></span></li><li><span><span><span><span>执行组件代码。</span></span></span></span></li><li><span><span><span><span>恢复 WHAT（事件处理程序闭包）和 WHERE（DOM 元素），以获取事件处理程序闭包。</span></span></span></span></li><li><span><span><span><span>将 WHAT（事件处理程序闭包）附加到 WHERE（DOM 元素）。</span></span></span></span></li></ol><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>这个过程的关键是将 APP_STATE 和 FRAMEWORK_STATE 从已渲染的组件中恢复，以确保应用程序在客户端获得正确的状态和行为。这对于实现前端与后端的协同工作以提供动态用户体验至关重要。</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="298" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F0e1bbc52c75747328b846dcfa76c28f2?width=905" width="660" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><span id="OSC_h1_6"></span><h1><span><span><span>二、Qwik.js 框架的特点</span></span></span></h1><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>可恢复性（Resumability）：一种无开销的水合替代方案，那么，如何设计一个没有水合且没有开销的系统呢？</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>为了消除开销，框架不仅必须避免恢复（RECOVERY），还必须避免上述所提到的第四步。第四步是将 WHAT 附加到 WHERE，这是可以避免的成本。</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>要避免这种成本，您需要三样东西：</span></span></span></p><ol><li><span><span><span><span>将所有所需的信息序列化为 HTML 的一部分。序列化的信息需要包括 WHAT、WHERE、APP_STATE 和 FRAMEWORK_STATE。</span></span></span></span></li><li><span><span><span><span>一个全局事件处理程序，依赖事件冒泡来拦截所有事件。事件处理程序需要是全局的，这样我们就不需要急切地在特定的 DOM 元素上单独注册所有事件。</span></span></span></span></li><li><span><span><span><span>一个工厂函数，可以延迟恢复事件处理程序（WHAT）。</span></span></span></span></li></ol><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>这种方法的关键是在 HTML 中序列化所有必需的信息，以及使用全局事件处理程序来拦截和处理事件，而不必显式将事件处理程序附加到特定的 DOM 元素上。这样可以避免昂贵的步骤四，从而提供无开销的可恢复性，同时仍能实现前端的互动性和性能优化。</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="304" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F04681212764f4025b2b5f5c6a258ad6e?width=905" width="675" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>A. 渲染阶段耗时分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="118" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-28K9JFlwTqhvJg8Ai.png" width="500" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:left"><span><span><span>B. 请求链路分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="383" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-28R2YSlad187SVu7u.png" width="207" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:left"><span><span><span>C. 浏览器执行渲染分析</span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" height="229" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-14-51g7EMHDw7dtR18CZV.png" width="342" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-11-19-32gB18uqO0IYVB18KxX.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><span id="OSC_h1_7"></span><h1><span><span><span>四、效果和成果</span></span></span></h1><div><img alt="" height="371" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-09-18-15-06LfwBVIHYE9RvLeU.png" width="823" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-10-11-20-00jYipo69U6Njn9Sm.gif" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><span id="OSC_h1_8"></span><h1><span><span><span>五、挑战</span></span></span></h1><p style="color:#393c5a; margin-left:0; margin-right:0; text-align:start"><span><span><span>Qwik.js 无水合方案可能会带来一些挑战，其中包括以下几个方面：</span></span></span></p><ol><li><span><span><span><strong><span>新技术的学习曲线</span></strong></span></span><span><span><span>： 采用新的前端架构或技术，如 Qwik.js，通常需要团队成员学习和适应新的工作流程和最佳实践。这可能需要一些时间和培训来确保团队熟练掌握新技术。</span></span></span></span></li><li><span><span><span><strong><span>服务器开销增加</span></strong></span></span><span><span><span>： 在无水合方案中，服务器可能需要更多的计算资源来序列化和提供所需的信息，以及处理全局事件处理程序。这可能会导致服务器开销的增加，特别是在大量并发请求的情况下。</span></span></span></span></li><li><span><span><span><strong><span>Node.js 并发挑战</span></strong></span></span><span><span><span>： 对于 Node.js 服务器，处理大量并发请求可能会带来挑战。在无水合方案中，服务器可能需要同时处理多个请求，因此需要考虑服务器的并发性能和扩展性。</span></span></span></span></li></ol><blockquote><p>作者：京东创新零售，李健</p><p>来源：京东云开发者社区，转载请注明来源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 01:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10141047</guid>
            <link>https://my.oschina.net/u/4090830/blog/10141047</link>
            <author>
                <![CDATA[京东云开发者]]>
            </author>
        </item>
    </channel>
</rss>
