<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 20 Mar 2024 10:05:07 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[✍🏻测评报告 | 2023 中文大模型全景及国内外大模型测评]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span style="background-color:#ffffff; color:#060607">《中文大模型基准测评 2023 年度报告》，由 SuperCLUE 团队发布，报告提供了 2023 年中文大模型发展的全面回顾，包括关键进展、测评体系、综合测评结果以及优秀模型案例，为了解该领域的最新动态提供了宝贵的信息。</span></p><p><span style="background-color:#ffffff; color:#060607">以下为主要内容：</span></p><p style="text-align:start"><strong>1. 国内大模型关键进展</strong></p><ul><li><p><strong>时间线</strong>：报告按照时间线划分了 AI 大模型发展的三个阶段：准备期、成长期和爆发期。</p></li><li><p><strong>关键事件</strong>：从 ChatGPT 发布引发全球 AI 浪潮，到国内大模型的迅速发展和多样化，包括多个重要时间节点和相关模型的发布。</p></li></ul><p style="text-align:start"><strong>2. 大模型全景图</strong></p><p style="text-align:start"><img height="702" src="https://static.oschina.net/uploads/space/2024/0320/164821_iSdC_4700705.png" width="1481" referrerpolicy="no-referrer"></p><ul><li><p><strong>模型分类</strong>：介绍了通用大模型和行业大模型，包括闭源和开源模型。</p></li><li><p><strong>代表性模型</strong>：列举了多个代表性的中文大模型，如字节跳动的 AndesGPT、百度的文心一言、阿里云的通义千问等。</p></li></ul><p style="text-align:start"><strong>3. 测评体系和方法</strong></p><ul><li><p><strong>SuperCLUE 介绍</strong>：详细说明了 SuperCLUE 测评基准的中立性和客观性，以及其多层次、多维度的综合性测评体系。</p></li><li><p><strong>测评层级和体系</strong>：介绍了 SuperCLUE 的多个测评层级，包括专业与技能、语言与知识、安全性等。</p></li><li><p><strong>测评方法</strong>：解释了如何通过自动化方式进行客观评估，包括多轮对话场景和主观题+客观题的结合。</p></li></ul><p style="text-align:start"><strong>4. 大模型综合测评结果</strong></p><ul><li><p><strong>模型象限</strong>：使用 SuperCLUE 模型象限展示了不同模型在基础能力和应用能力上的定位。</p></li><li><p><strong>国内外大模型表现</strong>：分析了国内外大模型的总体表现，特别是 GPT4-Turbo 的领先情况。</p></li><li><p><strong>国内大模型竞争格局</strong>：讨论了国内大模型的竞争态势，包括创业公司与大厂的对比。</p></li></ul><p style="text-align:start"><strong>5. SuperCLUE 2.0 升级</strong></p><ul><li><p><strong>行业及专项测评基准</strong>：介绍了 SuperCLUE 2.0 在行业和专项测评方面的升级，如汽车行业、金融行业、安全测评等。</p></li></ul><p style="text-align:start"><strong>6. 四大维度测评分析及示例介绍</strong></p><ul><li><p><strong>语言与知识</strong>：分析了模型在生成与创作、语言理解、上下文对话等方面的表现。</p></li><li><p><strong>专业与技能</strong>：讨论了模型在计算、逻辑推理、代码等方面的表现。</p></li><li><p><strong>工具使用</strong>：评估了模型在检索 API、调用 API、规划 API 等方面的能力。</p></li><li><p><strong>传统安全</strong>：考察了模型在财产隐私、违法犯罪、偏见歧视等方面的安全能力。</p></li></ul><p style="text-align:start"><strong>7. 优秀模型案例介绍</strong></p><ul><li><p><strong>文心一言 4.0</strong>：百度推出的模型，表现均衡，尤其在计算、逻辑推理等方面。</p></li><li><p><strong>通义千问 2.0</strong>：阿里云的模型，擅长代码、上下文对话等。</p></li><li><p><strong>AndesGPT</strong>：OPPO 的模型，具有对话增强、个性专属等特点。</p></li><li><p><strong>Baichuan2-13B-Chat</strong>：百川智能的开源模型，逻辑推理和生成与创作能力突出。</p></li><li><p><strong>智谱清言</strong>：清华&amp;智谱 AI 推出的模型，工具使用能力排名第一。</p></li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">报告通过这些详细的分析和案例介绍，为读者提供了对 2023 年中文大模型发展的深入理解，同时也为未来的研究方向和应用场景提供了指导。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong><span style="color:#333333">下载</span>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 09:07:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283942</guid>
            <link>https://www.oschina.net/news/283942</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开放签开源电子签章产品白皮书（简版）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>开放签开源电子签章产品白皮书（简版）</h1><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>一、</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#000000"><strong>摘要：</strong></span></span></span></span></strong></strong></span></span></span></span></h1><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>开放签电子签章团队源自于电子合同 SaaS 公司，立志于通过开源、开放的模式，结合团队十多年的行业经验，将电子签章产品更简单、更低门槛的推广到各行各业中。让电子签章应用更简单，让电子签章应用更普及。我们相信秉承开源、开放的价值观，能够为产品和用户之间带来更多的信任，让用户使用起来更放心。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>本白皮书概述了开放签电子签章的设计理念、关键技术、功能特点、应用场景以及参与贡献的方法。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>二、背景与价值主张</strong></span></span></span></span></strong></strong></span></span></span></span></h1><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>随着全球信息化的快速发展，企业组织和个人越来越依赖于线上操作和远程协作。数字化办公、电子商务和移动互联技术的普及使得传统纸质文件签署方式在效率、成本以及环保等方面日益显得滞后。在此背景下，电子签章作为一种替代传统物理印章的有效手段，其需求呈现出以下特点：</span></span></span></span></span><span><span><span><span style="color:#000000"><span>提升业务效率</span></span></span></span></span><span><span><span><span style="color:#000000"><span>【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>电子签章能够实现文档的在线实时签署，不受地域限制</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】；【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>合规要求</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】</span></span></span></span></span><span><span><span><span style="color:#000000"><span>各地</span></span></span></span></span><span><span><span><span style="color:#000000"><span>政府纷纷出台相应的法律法规</span></span></span></span></span><span><span><span><span style="color:#000000"><span>，</span></span></span></span></span><span><span><span><span style="color:#000000"><span>确保电子签章具有与传统签名相同的法律效力</span></span></span></span></span><span><span><span><span style="color:#000000"><span>；【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>降低运营成本</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】</span></span></span></span></span><span><span><span><span style="color:#000000"><span>减少纸张消耗、快递费用、人工处理成本</span></span></span></span></span><span><span><span><span style="color:#000000"><span>；</span></span></span></span></span><span><span><span><span style="color:#000000"><span>业务场景融合</span></span></span></span></span><span><span><span><span style="color:#000000"><span>【</span></span></span></span></span><span><span><span><span style="color:#000000"><span>电子签章可无缝嵌入各类业务流程，如 ERP、CRM、OA 系统中</span></span></span></span></span><span><span><span><span style="color:#000000"><span>】</span></span></span></span></span><span><span><span><span style="color:#000000"><span>；</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>价值主张</span></span></span></span></span><span><span><span><span style="color:#000000"><span>：我们相信秉承开源、开放的价值观，打造透明、安全、可信赖的电子签名生态系统。能够为产品和用户之间带来更多的信任，让电子签章更简单，让用户使用起来更放心。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>三、系统架构与核心技术</strong></span></span></span></span></strong></strong></span></span></span></span></h1><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>1、系统总体设计</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p><img height="720" src="https://oscimg.oschina.net/oscnet/up-e52e5683b2a878110dac08c5b5d52564a78.png" width="1220" referrerpolicy="no-referrer"></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>2、</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#000000"><strong>技术开发架构</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>前端技术： Ant-design-vue + Vue + vite+ ts。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>后端技术：Springboot、mybatis-plus、shiro、drools、jwt、websocket、freemarker、hutool、pdfbox 等。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>其他技术： Druid（数据库连接池）、Logback（日志工具）、PowerJob（定时任务）、lombok（简化代码）。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>加密算法与数字签名技术:（如 RSA、SHA-256 等）。</span></span></span></span></span></span></span></span></span></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#333333"><strong>3</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#333333"><strong>、产品说明</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>开放签电子签章系统为企业构建安全、可信、可控、灵活的一站式电子签章全服务体系产品链，产品类型如下：</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>（1）开源工具版（开源免费版）：</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>将电子签章的核心技术代码和工具进行开源，开源版采用更加宽松的 MIT 开源协议，且不受商业限制。产品功能包括：电子印章制作，手写签名生成，数字证书生成，PDF 文件转图片，电子签章（关键字签署、指定位置签署），文件验签等。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>（2）企业版（商业版本）：</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>为企业或机构在业务层面提供电子签章完整服务能力。支持私有化部署、多租户、SaaS 化等多种服务模式，提供个人和企业用户注册、实名，组织管理，权限管理，数字证书下发，印章管理，签名管理，电子文件的发起、接收、签署，签署场景支持企业内部文件签批流转、B2B 电子合同签署和 B2C 电子合同签署等业务场景。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>三、应用场景</strong></span></span></span></span></strong></strong></span></span></span></span></h1><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>1、</strong></span></span></span></span></strong><strong><span><span><span><span style="color:#000000"><strong>工具版系统集成</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>开放签电子签章系统开源工具适合有技术能力的个人/团队学习或自建电子签章\电子合同功能或应用，避免研发同仁在工作过程中重复造轮子，降低电子签章技术研发要求，让电子签章相关的技术可以更低门槛的应用在各个业务系统中。</span></span></span></span></span></span></span></span></span></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>2、企业版业务应用场景</strong></span></span></span></span></strong></strong></span></span></span></span></h2><h3><span><span><span><span style="color:#000000"><strong><span><span><span><span style="color:#000000"><span>（1）企业内部文件审批流转</span></span></span></span></span></strong></span></span></span></span></h3><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>企业通过集成电子签章功能的办公自动化系统（如 OA 系统、ERP 系统等），实现各类内部文件的电子化创建、分发和签署。</span></span></span></span></span></span></span></span></span></p><h3><span><span><span><span style="color:#000000"><strong><span><span><span><span style="color:#000000"><span>（2）跨组织商务合同签署</span></span></span></span></span></strong></span></span></span></span></h3><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>跨地域合作时，通过电子签章技术，无需面对面或邮寄纸质文件，各方当事人可以在任何地点通过网络完成合同的签署，解决异地签署难题，提升业务效率。</span></span></span></span></span></span></span></span></span></p><h3><span><span><span><span style="color:#000000"><strong><span><span><span><span style="color:#000000"><span>（3）公共服务领域在线办理</span></span></span></span></span></strong></span></span></span></span></h3><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>在线提交行政审批申请时，申请人、审批单位及相关业务部门可以使用电子签章确认文件的真实性和有效性，如工商注册、税务申报、资质许可等业务中，无需线下盖章即可完成流程。</span></span></span></span></span></span></span></span></span></p><h1><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>四、社区共建与开源策略</strong></span></span></span></span></strong></strong></span></span></span></span></h1><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>1、开源许可证选择与版权说明</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>开放签开源工具版遵循 MIT 开源协议，适用于有技术能力的个人或团队学习或自建电子签章系统，且不受商业限制。如商业使用产生的任何问题及纠纷与我司无任何关系。</span></span></span></span></span></span></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span><span style="color:#000000"><span>企业版是收费版本，在尚未购买产品技术服务或商业授权之前，我们不承诺对免费用户提供任何形式的技术支持、使用担保，也不承担任何因使用本软件而产生问题的相关责任。</span></span></span></span></span></span></span></span></span></p><h2><span><span><span><span style="color:#000000"><strong><strong><span><span><span><span style="color:#000000"><strong>2、开发者指南与代码贡献路径</strong></span></span></span></span></strong></strong></span></span></span></span></h2><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（1）开放签电子签章官方网站：</span></span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kaifangqian.com" target="_blank"><span><span><span><span style="color:#0000ff"><span>https://www.kaifangqian.com</span></span></span></span></span></a></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（2）开源工具版体验地址：</span></span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdemo.kaifangqian.com" target="_blank"><span><span><span><span style="color:#0000ff"><span>https://demo.kaifangqian.com</span></span></span></span></span></a></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（3）开源工具版 gitee 源码：</span></span></span></span></span><a href="https://gitee.com/kaifangqian/kaifangqian-base"><span><span><span><span style="color:#0000ff"><span>https://gitee.com/kaifangqian/kaifangqian-base</span></span></span></span></span></a></span></span></span></p><p style="margin-left:0.0000pt; text-align:left"><span><span><span><span><span><span><span style="color:#000000"><span>（4）开源工具版 github 源码：</span></span></span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkaifangqian%2Fkaifangqian-base" target="_blank"><span><span><span><span style="color:#0000ff"><span>https://github.com/kaifangqian/kaifangqian-bas</span></span></span></span></span></a></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:53:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283940</guid>
            <link>https://www.oschina.net/news/283940</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[.NET 9 PreView2 + .AOT ILC 的重大变化]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h2_1"></span><h2><strong>前言</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">.NET9 PreView2 发布了，它的 CLR 方面主要有两个重磅功能</p><ul><li>RyuJIT 增强功能</li><li>Arm64 矢量化</li></ul><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">原文：</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486290%2526idx%253D1%2526sn%253D726ec65a0956e4de5840f27d8e6b2004%2526chksm%253Dc01c46c9f76bcfdf6170e771d067f8d669ac02775332bc466c0f9a1276982e315c1e7ef430c9%2526token%253D1776199625%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">.NET9 PreView2 的重磅功能</a></u></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486298%2526idx%253D1%2526sn%253D5aab48e01251c3bb6dbf100050fcc707%2526chksm%253Dc01c46c1f76bcfd7d9cb8a264c71bdeb327cd52a35f030f10dc4379b14d460eceb574b49e14e%2526token%253D1776199625%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">.NET9 AOT ILC 的重大变化</a></u></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><u><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486254%2526idx%253D1%2526sn%253Da0050659da6ee8b0696f1c758d8046d5%2526chksm%253Dc01c46b5f76bcfa3524abeb373258f10b2909ca8ac490c1eb8ed5c4a2c30c98a6712f6a8a099%2526token%253D1776199625%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">欢迎加入.NET9 技术交流群</a></strong></u></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">下面分别看下</p><span id="OSC_h2_2"></span><h2><strong>RyuJIT 增强功能</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>1.环路优化 (循环优化)</strong></p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">这种优化实际上是一种 for 循环叠加态的优化，for 循环叠加计算的过程中，会对其中部分变量进行感应。比如循环中放置 0 扩展 (第一个索引为 0)，这种优化灵感来源于 LLVM 标量演化。下面看例子，说明下这个优化：</p><div><pre><code class="language-text">[MethodImpl(MethodImplOptions.NoInlining)]
static int Foo(int[] arr)
{
    int sum = 0;
    for (int i = 0; i &lt; arr.Length; i++)
    {
        sum += arr[i];
    }

    return sum;
}</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">未优化前:</p><div><pre><code class="language-text">G_M8112_IG01:
       sub      rsp, 40
            ;; size=4 bbWeight=1 PerfScore 0.25
G_M8112_IG02:
       xor      eax, eax
       xor      edx, edx
       mov      r8d, dword ptr [rcx+0x08]
       test     r8d, r8d
       jle      SHORT G_M8112_IG04
       align    [0 bytes for IG03]
            ;; size=13 bbWeight=1 PerfScore 3.75
G_M8112_IG03:
       mov      r10d, edx
       add      eax, dword ptr [rcx+4*r10+0x10]
       inc      edx
       cmp      r8d, edx
       jg       SHORT G_M8112_IG03
            ;; size=15 bbWeight=4 PerfScore 19.00
G_M8112_IG04:
       add      rsp, 40
       ret      
            ;; size=5 bbWeight=1 PerfScore 1.25

; Total bytes of code 37, prolog size 4, PerfScore 24.25,
 instruction count 14, allocated bytes for code 37 
 (MethodHash=d1cce04f) for method ConsoleApp34.Program:Foo(int[])
 :int (FullOpts)
; ============================================================</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">未优化前 37 字节，优化后：</p><div><pre><code class="language-text">G_M8112_IG01:  ;; offset=0x0000
       sub      rsp, 40
            ;; size=4 bbWeight=1 PerfScore 0.25
G_M8112_IG02:  ;; offset=0x0004
       xor      eax, eax
       mov      edx, dword ptr [rcx+0x08]
       test     edx, edx
       jle      SHORT G_M8112_IG04
       xor      r8d, r8d
       align    [0 bytes for IG03]
            ;; size=12 bbWeight=1 PerfScore 3.75
G_M8112_IG03:  ;; offset=0x0010
       add      eax, dword ptr [rcx+4*r8+0x10]
       inc      r8d
       cmp      edx, r8d
       jg       SHORT G_M8112_IG03
            ;; size=13 bbWeight=4 PerfScore 18.00
G_M8112_IG04:  ;; offset=0x001D
       add      rsp, 40
       ret      
            ;; size=5 bbWeight=1 PerfScore 1.25

; Total bytes of code 34, prolog size 4, PerfScore 23.25, 
instruction count 13, allocated bytes for code 34
 (MethodHash=d1cce04f) for method ConsoleApp34.Program:Foo(int[])
 :int (FullOpts)</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">优化后 34 字节，减少了 3 字节，优化的指令如下，刚好三字节。这里的优化点是减却寄存器置零或者赋值 (称之为放置 0 扩展)，进行共用。</p><div><pre><code class="language-text">mov   41 89 d2  r10d, edx</code></pre></div><span id="OSC_h2_3"></span><h2><strong>2.NativeAOT 改进：内联+TLS</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">这种优化，需要了解一些知识点。假如一个类成员被多个线程访问，一般的访问的时候会设置锁，以避免数据干扰。但是，这同时也产生性能问题。为了提高性能，可以把这个类成员放到线程本地存储 (TLS) 当中，访问的时候直接去线程本地存储获取，这样极大提高了性能。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">但是这还不够，我们需要把访问类成员的代码进行内联。进一步提高性能，不然怎么能叫极致性能优化呢？</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">代码：</p><div><pre><code class="language-text">:  90000000   adrp  x0, 0 &lt;System_Console_System_ConsoleKeyInfo____GetFieldHelper&gt;
      5a2f0: R_AARCH64_TLSDESC_ADR_PAGE21  tls_InlinedThreadStatics
   5a2f4:  91000000   add  x0, x0, #0x0
      5a2f4: R_AARCH64_TLSDESC_ADD_LO12  tls_InlinedThreadStatics
   5a2f8:  d53bd041   mrs  x1, tpidr_el0
   5a2fc:  f9400002   ldr  x2, [x0]
      5a2fc: R_AARCH64_TLSDESC_LD64_LO12  tls_InlinedThreadStatics
   5a300:  d63f0040   blr  x2
      5a300: R_AARCH64_TLSDESC_CALL  tls_InlinedThreadStatics
   5a304:  8b000020   add  x0, x1, x0
   5a308:  f9400013   ldr  x19, [x0]</code></pre></div><span id="OSC_h2_4"></span><h2><strong>2.PGO 的改进:类型检查</strong></h2><span id="OSC_h2_5"></span><h2>PGO 是.NET8 的一大亮点，启用了动态配置文件引导优化 (PGO)。.NET9 Pre2 扩展了 PGO，以便分析更多的代码模式。启用分层编译后，RyuJIT 已经将检测插入到程序中以分析其行为;在使用优化重新编译时，RyuJIT 利用它在运行时构建的配置文件来做出特定于程序当前运行的决策。在预览版 2 中，RyuJIT 现在默认使用 PGO 数据来提高类型检查的性能。</h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">一般来说，确定对象的类型需要调用运行时。这会带来一些性能上的损失，也就是说当进行类型检查的时候，运行时为了确保类型正确性，必须进行检查。通过.NET8 里面启用的 PGO，如果在 PGO 里面能够确定对象是某个类型，JIT 就会用一个快速路径编码，以比较快速的方式进行类型检查。并且在必要的时候退回到慢速路径 (常规检查)</p><div><pre><code class="language-text">bool IsList&lt;T&gt;(IEnumerable&lt;T&gt; source) =&gt; source is IList&lt;T&gt;;</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">如果 PGO 检测到 source 总是数组，则会快速路径返回 true，否则慢速路径进行检测</p><div><pre><code class="language-text">if (source is int[])
{
    return true;
}
else
{
    return slow_path(); // Let the runtime figure it out
}</code></pre></div><span id="OSC_h2_6"></span><h2><strong>ARM64 矢量化</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">.NET9 Pre2 支持了一种新的实现，利用 JIT 在 Arm64 上操作寄存器的加载和存储的能力。简单点来说，就是用 SEE，YMM 等一次性操控 32 字节或者 64 字节的寄存器处理更大量的数据，提升性能。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><span id="OSC_h2_7"></span><h2><strong>.NET9 AOT ILC</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">AOT 编译分成两个阶段，其一是生成 Obj 目标文件，其二则是通过链接器链接目标文件生成可执行二进制文件。这里的目标文件和可执行二进制文件都是分别对于相应的平台，比如 MacOS/Linux/Win 等等平台。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">第一步生成 Obj 目标文件，因为多平台生成。所以.NET9 之前，微软采用了 LLVM 后端生成了目标文件。因为 LLVM 后端近乎绝对的统治力，它有一百多个指令集级别的后端生成，所以采用 LLVM 更符合开源特征。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">但这一情况到了.NET9 发生了变化，.NET9 里面微软首次引入了 C#代码生成目标文件，取代了 LLVM 默认的生成。但是 LLVM 并没有删除，而是同时存在。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">这部分代码可以参考：</p><div><pre><code class="language-text">public static void EmitObject(string objectFilePath, IReadOnlyCollection&lt;DependencyNode&gt; nodes, NodeFactory factory, ObjectWritingOptions options, IObjectDumper dumper, Logger logger)
 {
     var stopwatch = new Stopwatch();
     stopwatch.Start();

     if (Environment.GetEnvironmentVariable("DOTNET_USE_LLVM_OBJWRITER") == "1")
     {
         LegacyObjectWriter.EmitObject(objectFilePath, nodes, factory, options, dumper, logger);
     }
     else
     {
         ObjectWriter objectWriter =
             factory.Target.IsApplePlatform ? new MachObjectWriter(factory, options) :
             factory.Target.OperatingSystem == TargetOS.Windows ? new CoffObjectWriter(factory, options) :
             new ElfObjectWriter(factory, options);
         objectWriter.EmitObject(objectFilePath, nodes, dumper, logger);
     }

     stopwatch.Stop();
     if (logger.IsVerbose)
         logger.LogMessage($"Done writing object file in {stopwatch.Elapsed}");
 }</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">如果你不作任何设置，.NET9 默认的目标文件生成即是 C#自举的代码。但是你如果习惯了 LLVM 的生成，也可以通过设置环境变量来开启之前的 LLVM 后端。具体如下：</p><div><pre><code class="language-text">CMD:          set    DOTNET_USE_LLVM_OBJWRITER=1
Powershell:   $env:  DOTNET_USE_LLVM_OBJWRITER=1
Unix/Linux:   export DOTNET_USE_LLVM_OBJWRITER=1

dotnet xxx.dll</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">先设置环境变量，然后通过 dotnet 命令行运行托管 DLL 即可复现之前的 LLVM 后端生成。以上是各个平台的设置。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><span id="OSC_h2_8"></span><h2><strong>作者：jianghupt(公众号同名，欢迎关注)</strong></h2></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:46:52 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5407571/blog/11048017</guid>
            <link>https://my.oschina.net/u/5407571/blog/11048017</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软开源远程缓存存储系统 Garnet：基于 .NET 技术栈、支持接入 Redis 客户端]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软研究院<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fgarnet" target="_blank">开源</a></u>了名为&nbsp;Garnet 的远程缓存存储系统，据称拥有强大的性能（高吞吐量和低延迟）、可扩展性、存储、恢复、集群分片、密钥迁移和复制功能，并支持接入现有的 Redis 客户端。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f2cd6285bd80798dd9b494864d5d4642356.png" referrerpolicy="no-referrer"></p><p><strong>Garnet 核心优势</strong></p><ul><li><p>Garnet 采用流行的 RESP 线路协议，因此大多数用户可以不作任何修改、就直接通过大多数编程语言编写的 Redis 客户端直接接入 Garnet。</p></li><li><p>Garnet 通过多条客户端连接与小批量形式提供更好的可扩展性与吞吐量，帮助大型应用程序和服务节约运行成本。</p></li><li><p>Garnet 在第 99 及第 99.9 百分位上表现出更好的客户端延迟水平，更高比例的稳定性表现对于现实场景而言至关重要。</p></li><li><p>Garnet 基于最新.NET 技术，具有跨平台、可扩展和现代化等特点。它在设计上易于开发与调整，且不致牺牲常见场景下的性能水平。通过利用.NET 丰富的库生态来扩展其 API，并提供开放的优化机会。凭借对.NET 的充分发掘，Garnet 在 Linux 和 Windows 平台上均表现出顶尖性能。</p></li></ul><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e0455c41a00404e05790ec05decb67ca6ff.png" referrerpolicy="no-referrer"></p></blockquote><p>可以看到，Garnet 的核心优势在于优异的可扩展性和吞吐量，以及对客户端会话数增加情况下的低延迟表现。经过基准测试，Garnet 与其他几种领先的开源缓存存储方案对比，显示出了它在处理大量客户端连接和大数据量时更加高效稳定。</p><p>此外，Garnet 支持多种 API 功能，如原始字符串的读写、复杂数据类型的处理等，满足了不同场景下的应用需求。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-dc5ebce821d503d82b69ab11afe89fcb1c1.png" referrerpolicy="no-referrer"></p><p>△ Garnet 整体架构</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmicrosoft.github.io%2Fgarnet%2Fblog%2Fbrief-history" target="_blank">据介绍</a></u>，Garnet 是微软研究院多年工作的成果。它从 2018 年完成的名为 FASTER 的初步工作发展而来的，FASTER 是一个嵌入式键值数据库，旨在证明可以获得比现有系统更好的性能。</p><p>在 2021 年大流行期间，微软研究院决定根据微软在现实世界中的需求，在这项技术的基础上进行改进，最终形成了 Garnet。微软表示，它已经在多个地方部署了 Garnet，包括 Windows 与 Web 体验平台、Azure 资源管理器和 Azure 资源图。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:38:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283934/ms-research-garnet-cache-store</guid>
            <link>https://www.oschina.net/news/283934/ms-research-garnet-cache-store</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[360 发布安全大模型 3.0，安全领域效果超 GPT4]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 20 日，360 集团正式推出 360 安全大模型 3.0，并通过智能体框架，赋能企业已有的探针、平台，提炼专家知识赋能增强 360 安全云，帮助企业数字安全体系提质增效。</p><p>360 集团首席科学家兼 360 数字安全集团 CTO 潘剑锋提到，「我们参考了人类大脑的运行逻辑，构建 360 安全大模型 3.0 框架。实际应用中，在多个专业任务效果上超过 GPT4。」</p><p><img alt="" height="334" src="https://oscimg.oschina.net/oscnet/up-59ec68e7705b3845b8f343feb0b33fce212.webp" width="500" referrerpolicy="no-referrer"></p><p>据潘剑锋介绍，360 从数据、场景、大模型和智能体四个方面研究方法论，总结了新一代安全大模型的核心战法：数据制胜、小切口大纵深、类脑分区协同（CoE）和工具增强（TAG）。</p><p>展开来说，其一数据制胜，为训练出高水平的安全大模型，需要有高质量的安全专业数据和事件数据作为语料，并配合专业的技术手段进行训练；其二小切口大纵深，是指在场景上，立足小切口、大纵深方法论，以安全难点小场景做切入，做深做透，进而深度融合大模型与安全的能力；其三类脑协同分区，即在大模型设计上，采用类脑分区协同（CoE）设计，以多个类脑分区协同工作，解决高难度安全问题；其四工具增强（TAG），是指以安全智能体为基础，通过调度各种安全产品与工具，为大模型提供纠错反馈机制，持续增强大模型安全能力。</p><p>潘剑锋指出，基于新战法打造的 360 安全大模型 3.0，不仅仅实现安全基础知识问答、初级脚本分析等基础能力，而是真正锚定安全行业痛点、革新安全能力体系、引领未来安全实战。</p><p>360 安全大模型 3.0 框架，在构建时充分参考人类大脑的运行逻辑，基于数据、知识、算力优势，训练语言、规划、判别、道德、记忆五大功能中枢。其中，语言中枢实现语言翻译、文本摘要、意图识别能力；规划中枢实现程序生成、方案规划、目标拆解能力；判别中枢实现信息抽取、逻辑推理、是非判断、研判检测能力；道德中枢实现情感分析、道德法律能力；记忆中枢实现信息记忆能力。</p><p>基于类脑分区协同设计的安全大模型框架，不仅可以解决任务冲突问题，达到多任务最优性能，而且实现了能力突破，在多个专业任务效果上超过了 GPT4。此外，360 以安全大模型为「大脑」，构建智能体框架，通过任务编排、指令调度、记忆存储等能力，调用安全知识、工具，模仿人类「慢思考」的过程，对安全大模型的结果进行纠错和能力增强，实现更强大的安全专家能力。</p><p>潘剑锋以海莲花 APT 攻击为例，展示了 360 安全大模型如何在实战中智能化猎杀 APT。他表示，360 安全大模型的最终目标是帮助企业数字安全体系提质增效，是 360 安全云体系中的重要一环。</p><p>随后，360 数字安全集团副总裁张锦章介绍了 360 围绕安全和 AI 两条战略主线的实践。他表示，360 安全大模型已赋能 360 全线产品矩阵。而 360 安全云在安全大模型加持下，形成公有云和私有化两大场景。在公有云场景下，打造安全云服务，充分利用 AI 提升运营效率；在私有化场景下，深度优化安全大脑+安全大模型+探针的能力落地。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:35:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283932</guid>
            <link>https://www.oschina.net/news/283932</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024 年 AIGC 发展趋势报告：AIGC 驱动下的生产力变革、实践与展望]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">爱设计 &amp; AiPPT &amp; AIGC 内容中台近期联合发布了《2024 年 AIGC 发展趋势报告：AIGC 驱动下的生产力变革、实践与展望》报告，主要探讨了 AIGC 技术如何推动生产力变革、在不同行业的应用实践以及对未来的展望。</p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><img alt="" height="391" src="https://static.oschina.net/uploads/space/2024/0320/162019_7pYi_4700705.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">以下是报告的核心内容概述：</p><ol><li><p style="margin-left:0; margin-right:0"><strong>AIGC 的生产力变革</strong>：</p><ul><li>AI 工具的发展极大提升了工作效率，对人类生产和服务产业链、价值链进行了赋能和重构。</li><li>2023 年见证了文本和图像生成的进步，而视频生成领域则相对较慢。OpenAI 发布的 Sora 模型预示着视觉敍事新时代的到来，能够将想象力转化为动态画面。</li><li>AIGC 的友好性、大模型开源、API 价格降低等因素使得 AI 技术可能成为像水、电、网络一样的基础设施。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AIGC 的应用实践</strong>：</p><ul><li>AIGC 技术在文字、代码、音乐、图片、视频等多种媒介形态的生产中逐步深度融入。</li><li>AI 绘图技术可以快速生成创意设计，如广告、海报、产品包装等，提高营销效率和效果。</li><li>AI 视频技术可以高效完成视频录制与剪辑，创造独特的虚拟人物和场景，提高视频的创意和吸引力。</li><li>AI 写作工具可以快速生成文案，支持多种场景需求，如社交媒体文案、新闻稿、产品评测等。</li></ul></li><li><p style="margin-left:0; margin-right:0"><strong>AIGC 的未来展望</strong>：</p><ul><li>AIGC 应用层创新将成为产业发展的核心方向，预计到 2024 年将深度融入企业业务并催生新场景。</li><li>AIGC 正在工具化，从「赶时髦」变为「真有用」，企业更看重其带来的实际效益。</li><li>中大型企业将率先涌现专属、自建模型的需求，以获得更理想的综合效益。</li><li>AIGC 生态将逐步普惠化，推动新的商业模式和数字经济产业的繁荣。</li><li>智能涌现是双刃剑，需要与之匹配的安全措施，如隐私保护、数据泄露防范等。</li></ul></li></ol><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">报告还提到了 AIGC 技术可能带来的社会影响，包括工作替代、财富分配、伦理道德等问题，并强调了技术发展与社会整体福利水平提升之间的关系。最后，报告呼吁积极主动地拥抱 AIGC 技术，以打造更美好的未来。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong><span style="color:#333333">下载</span>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 08:22:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283927</guid>
            <link>https://www.oschina.net/news/283927</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[深圳成立鸿蒙生态创新中心]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 19 日，鸿蒙生态创新中心揭幕仪式在深圳湾科技生态园举行。</p><p><img src="https://oscimg.oschina.net/oscnet/up-0672f9510f1b29f65734bca978a3aae242e.jpg" referrerpolicy="no-referrer"></p><p><img alt="WPS 图片 (1).jpeg" src="https://upload.ikanchai.com/2024/0320/1710898823311.jpeg" referrerpolicy="no-referrer"></p><p>现场，深圳市南山区人民政府副区长李志娜发布《2024 年南山区支持鸿蒙原生应用发展首批政策措施清单》，从加强鸿蒙原生应用供给能力、推动鸿蒙原生应用产业集聚、完善鸿蒙原生应用生态体系等三大方面，<strong>出台八条具体措施，全方位支持鸿蒙原生应用发展</strong>。</p><p>分别为：</p><ul><li><p>支持开发鸿蒙原生应用软件；</p></li><li><p>推动区政务服务软件上线鸿蒙原生应用软件，推动国有企事业单位在教育、医疗、文旅、体育等各类垂直领域开放应用场景；</p></li><li><p>定期组织各行各业与鸿蒙生态进行对接，召开供需对接会；</p></li><li><p>争取培育 30 万以上开发者，吸引鸿蒙原生应用开发运营企业落户南山；</p></li><li><p>在高新区片区打造鸿蒙原生应用特色产业园，对符合条件的鸿蒙原生应用入驻企业，给予最高 40% 的租金补贴；</p></li><li><p>成立鸿蒙产业专项基金，重点投资鸿蒙原生应用相关领域；</p></li><li><p>加强鸿蒙原生应用开发人才保障，对挂牌人才实训基地的鸿蒙原生应用企业给予补贴，建设「2048 人才社区」；</p></li><li><p>支持鸿蒙生态创新中心稳健运营等。</p></li></ul><p><span>据介绍，鸿蒙生态创新中心的建立是为构建先进完整、自主研发的鸿蒙生态体系，将深圳打造为鸿蒙生态策源地、集聚区的具体举措，也是推动我国关键核心技术高水平自立自强、数字经济高质量发展、保障国家安全、提升国际竞争力的重要举措。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 07:47:47 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283921</guid>
            <link>https://www.oschina.net/news/283921</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国产数据库 OceanBase 实现代码、社区、生态 100% 「根自研」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 20 日消息，OceanBase 城市行首站落地深圳。会上，OceanBase CEO 杨冰表示，目前 OceanBase 已经做到了 100%「根自研」，包括从 0 到 1 自研三百万行代码、自研代码开源主导产品和社区发展方向、构建自研技术生态。</p><p><img src="https://oscimg.oschina.net/oscnet/up-72edb6534ef024342601bc9acda33591568.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.doit.com.cn%2Fp%2F509890.html" target="_blank">据介绍</a></u>，OceanBase 将「根自研」解释为<strong>代码、社区、生态</strong>三个层面的自研。</p><ul><li>在代码层面，由于不基于开源数据库二次开发、自建研发环境和流程，使得 OceanBase 具备对内核代码的完全掌控力和掌控权，避免了开源数据库可能遭遇的协议风险。</li><li>在社区层面，2021 年开源后，OceanBase 同样引领产品发展和社区方向，除了开源最核心的数据库内核代码、分布式组件和接口驱动外，还逐步将产品工具开源。截止目前，社区拥有超 300 位贡献者，超 500 家客户将 OceanBase 社区版应用于实际的业务生产系统。</li><li>技术生态方面，OceanBase 持续构建以「合作伙伴」为中心的产品技术文化，广泛与多基础设施、数据集成、数据治理、应用集成服务商围绕 OceanBase 进行产品适配和对接，有超过 750 个主流产品已加入 OceanBase 自研技术生态。</li></ul><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-45acbfc8fd014a1cc51b03843d779e8750b.png" referrerpolicy="no-referrer"></p></blockquote><p>OceanBase 始创于 2010 年，是蚂蚁集团完全自主研发的国产数据库。2020 年 OceanBase 成立北京奥星贝斯科技有限公司并开始独立商业化运作。2021 年，OceanBase <u><a href="https://www.oschina.net/news/144034">正式开源</a></u>(<a href="https://gitee.com/oceanbase" target="_blank">https://gitee.com/oceanbase</a>)，300 万行核心代码向社区开放。2024 年 3 月 19 日，蚂蚁集团宣布，旗下的蚂蚁国际、OceanBase 和蚂蚁数科已成立董事会，独立面向市场。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 07:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283917</guid>
            <link>https://www.oschina.net/news/283917</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 24.04 LTS 官方壁纸揭晓]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">在成立 20 周年纪念日前夕，Canonical <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Fthe-coronation-of-a-new-mascot-noble-numbat" target="_blank">宣布</a>推出了 Ubuntu 24.04 LTS (代号 Noble Numbat) 的默认壁纸。Ubuntu 24.04 LTS 计划于 4 月 25 日正式发布，Beta 版将于 4 月 4 日发布，新壁纸也将在 Beta 版中同步提供。</span></p><p><span style="color:#000000">Ubuntu 24.04 将是 Ubuntu 自 2006 年以来的第 10 个 LTS 版本。Ubuntu 的 LTS 版本将获得 5 年的安全更新、错误修复和精选应用程序更新。Ubuntu Pro 则会在此基础上额外增加 5 年的安全保障，为现代的 LTS 版本提供了长达十年的支持。</span></p><p><span style="color:#000000">Numbat（袋食蚁兽）是分布于澳大利亚西南部的一种小型有袋动物，几乎只以白蚁为食，每天可以吃约 20000 只白蚁。</span></p><blockquote><p><span style="color:#000000">「在大家讨论高贵一词时，可能不会首先联想到这种动物。然而，外表是会骗人的。这些令人难以置信的濒危物种实际上是袖珍食蚁兽，它们纯粹以蚂蚁为生，用三分之一长的舌头捕捉蚂蚁。它们背部的黑白条纹很像国王的长袍，因此被选为西澳大利亚州的州徽动物。袋食蚁兽证明了出身卑微的人也能在世界上留下自己的印记。」</span></p></blockquote><p><span style="color:#000000"><img alt="" height="229" src="https://oscimg.oschina.net/oscnet/up-9f6dfdb88767a65e4cdb5024d1854309f77.webp" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-cae0f36c1be4386da9f49bbc47d2e563e08.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-e55523fe69ae7e2b8481a53a44a0d51b9b0.webp" width="500" referrerpolicy="no-referrer"></span></p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-baee4b4f945463e758c7001ab8dc9db413b.webp" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-dc007e2e9c359e502ccf5f6056acf519da2.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">官方提供了各种格式和尺寸的壁纸下载：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdrive.google.com%2Fdrive%2Ffolders%2F1hzlUuCOCORWyTvIWqDN_d9W4gFDqetvZ" target="_blank">https://drive.google.com/drive/folders/1hzlUuCOCORWyTvIWqDN_d9W4gFDqetvZ</a></p><p>更多详情可查看<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Fthe-coronation-of-a-new-mascot-noble-numbat" target="_blank">公告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 06:23:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283905/ubuntu-24-04-wallpaper</guid>
            <link>https://www.oschina.net/news/283905/ubuntu-24-04-wallpaper</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Spring 也爱用！Antora 3.1 中文指南发布：轻松打造现代化技术网站]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3><strong>简介</strong></h3><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Antora 3.1 中文指南全新上线，助力您轻松打造现代化网站！指南涵盖所有核心功能和特性，并结合中文示例和最佳实践，帮助您快速上手 Antora 开发。<strong>Spring 等知名开源组织也选择使用 Antora！</strong></span></p><h3><strong>Antora 魅力所在</strong></h3><ul><li><strong>Spring 等开源组织力荐</strong></li><li><strong>构建技术网站的利器</strong></li><li><strong>基于更易上手的 AsciiDoc</strong></li></ul><h3><strong>Antora 助您</strong></h3><ul><li>自动化构建网站</li><li>模块化开发，轻松重用内容</li><li>高度可扩展，满足各种需求</li><li>支持多语言内容创作</li></ul><h3><strong>获取指南</strong></h3><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Antora 3.1 中文指南现已上线，您可以通过以下方式获取：</span></p><ul><li><strong>在线阅读：</strong><span>&nbsp;</span>在 Antora 中文文档: [<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在码</a>] 网站上阅读在线版本。</li></ul><h3><strong>结语</strong></h3><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">Antora 3.1 中文指南的发布，将进一步降低中国开发者学习 Antora 的门槛，助力更多开发者加入 Antora 生态，共同打造更加繁荣的现代化网站开发环境。</span></p><p style="color:#e3e3e3; margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>选择 Antora，基于更易上手的 AsciiDoc，构建高效、可维护、多语言的技术网站，尽享开源组织的信赖和支持！</strong></span></p><p><img height="400" src="https://cunzaima.cn/logo.jpg" width="400" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 06:01:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283894</guid>
            <link>https://www.oschina.net/news/283894</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[KCL 3 月社区活动和最新动态速递！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkcl-lang" target="_blank">KCL</a> 是一个 CNCF 基金会托管的基于约束的记录及函数语言，期望通过成熟的编程语言技术和实践来改进对大量繁杂配置比如云原生 Kubernetes 配置场景的编写，致力于构建围绕配置的更好的模块化、扩展性和稳定性，更简单的逻辑编写，以及更简单的自动化和生态工具集成。</p><p>本栏目将会双周更新 KCL 语言社区最新动态，包括功能、官网更新和最新的社区动态等，帮助大家更好地了解 KCL 社区！</p><p><strong><em>KCL 官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkcl-lang.io" target="_blank">https://kcl-lang.io</a></em></strong></p><h2><span>内容概述</span></h2><p>感谢所有贡献者过去一段时间 (2024 03.06 - 2024.03.20) 的杰出工作，以下是重点内容概述</p><p><strong>📦 模型更新</strong></p><ul><li><p>新增 kubeadm 配置模型</p></li><li><p>更新 Knative Operator 模型，对齐上游 Knative CRD 定义</p></li></ul><p><strong>🏄 语言更新</strong></p><p><strong>KCL 发布 0.8.1 和 0.8.2 版本</strong>，主要包含如下更新</p><ul><li><p>体验简化增强二元表达式类型不匹配时的错误信息提示</p></li><li><p>修复高阶 lambda 函数对局部作用域闭包变量捕获不正常的错误</p></li><li><p>去除不常用的列表数据类型的不等式比较操作</p></li></ul><p><strong>🔧 工具链更新</strong></p><ul><li><p><code>kcl import</code> 工具修复当输入的 Kubernetes CRD 存在 regex 属性与 KCL regex 系统库冲突的错误</p></li><li><p><code>kcl import</code> 工具修复当输入的 Kubernetes CRD 属性存在复杂的默认值时输出的 KCL 文件语法错误</p></li><li><p><code>kcl mod init</code> 支持 <code>--version</code> 标签设置 KCL 新建模块的版本</p></li><li><p><code>kcl run</code>, <code>kcl mod add</code> 和 <code>kcl mod pull</code> 等命令支持对私有 Git 仓库的访问</p></li><li><p>修复在 Windows 上执行对本地 OCI Registry 执行 <code>kcl run</code> 命令时遇到的路径错误</p></li></ul><p><strong>🔥 SDK 更新</strong></p><ul><li><p>KCL Rust, Go 和 Java SDK 发布 0.8 主要版本，同步 KCL 语法语义更新</p></li><li><p>KCL Python SDK 发布 0.8.0.2 和 0.7.6 版本，修复 <code>protobuf</code>, <code>pyyaml</code> 等依赖版本过于低的问题</p></li></ul><p><strong>💻 IDE 更新</strong></p><ul><li><p>支持多个 Quick Fix 修复选项</p></li></ul><p><img alt="" src="https://files.mdnice.com/user/44450/4d37d5b6-e481-4345-a9c5-b3531dc1f1e1.png" referrerpolicy="no-referrer"></p><p><strong>🎁 API 更新</strong></p><ul><li><p>新增 <code>ListOptions</code> API，可以读取 KCL 工程中所有 <code>option</code> 函数调用信息。</p></li></ul><p><strong>🚢 集成更新</strong></p><ul><li><p>Crossplane KCL Function 发布 v0.3.2 版本，支持非 https 协议 OCI Registry 访问和本地调试</p></li></ul><p><strong>🌐 网站更新</strong></p><ul><li><p>启用 <code>kcl-lang.dev</code> 域名，现在可以同时通过 <code>kcl-lang.io</code> 和 <code>kcl-lang.dev</code> 访问 KCL 网站</p></li><li><p>KCL 网站加载速度优化，提升文档体验</p></li></ul><h2><span>特别鸣谢</span></h2><p>感谢过去两周所有的社区参与者，以下排名不分先后</p><ul><li><p>感谢 @bozaro 对 KCL Go SDK 带 Go 语言插件的 API 的贡献 🙌</p></li><li><p>感谢 @shashank-iitbhu 对 KCL IDE 快速修复功能的增强，支持多个修复选项 🙌</p></li><li><p>感谢 @octonawish-akcodes 对 KCL IDE 自动监听 kcl.mod 依赖变更并自动更新依赖功能的持续贡献 🙌</p></li><li><p>感谢 @liangyuanpeng 对 CLA Bot CI 自动锁定 PR 的修正，kubeadm 模型的贡献以及 kcl mod init 支持版本设置功能的支持 🙌</p></li><li><p>感谢 @Stefano Borrelli, @sfshumaker, @eshepelyuk, @vtomilov, @ricochet1k, @yjsnly, @markphillips100, @userxiaosi, @wilsonwang371, @steeling, @bozaro, @nizq, @reckless-huang, @folliehiyuki, @samuel-deal-tisseo, @MrGuoRanDuo, 和 @MattHodge 等在近段时间使用 KCL 过程中提供的宝贵建议与反馈 🙌</p></li></ul><p>https://meeting.tencent.com/dm/CCEDaHbwXD6w</p><h2><span>其他资源</span></h2><p>❤️ 查看 KCL 社区，加入我们: https://github.com/kcl-lang/community</p><p>更多其他资源请参考：</p><ul><li><p>KCL 网站: https://kcl-lang.io/</p></li><li><p>KusionStack 网站: https://kusionstack.io/</p></li><li><p>KCL v0.9.0 Milestone: https://github.com/kcl-lang/kcl/milestone/9</p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 05:51:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283891</guid>
            <link>https://www.oschina.net/news/283891</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[官宣｜Apache Flink 1.19 发布公告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img alt="" height="383" src="https://oscimg.oschina.net/oscnet/up-bc82a0da21bbbd289ae7fd13732c07d337d.png" width="685" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>Apache Flink PMC（项目管理委员）很高兴地宣布发布 Apache Flink 1.19.0。与往常一样，这是一个充实的版本，包含了广泛的改进和新功能。总共有 162 人为此版本做出了贡献，完成了 33 个 FLIPs、解决了 600 多个问题。感谢各位贡献者的支持！</span></p><span id="OSC_h2_1"></span><h2><span>一、Flink SQL 提升</span></h2><span id="OSC_h3_2"></span><h3><span>源表自定义并行度</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在，在 Flink 1.19 中，您可以通过选 scan.parallelism 设置自定义并行度，以调整性能。第一个可用的连接器是 DataGen（ Kafka 连接器即将推出）。下面是一个使用 SQL Client 的示例：</span></p><pre><span>-- set parallelism within the ddl</span><span>CREATE TABLE Orders (</span><span> &nbsp;  order_number BIGINT,</span><span> &nbsp;  price &nbsp; &nbsp; &nbsp;  DECIMAL(32,2),</span><span> &nbsp;  buyer &nbsp; &nbsp; &nbsp;  ROW&lt;first_name STRING, last_name STRING&gt;,</span><span> &nbsp;  order_time &nbsp; TIMESTAMP(3)</span><span>) WITH (</span><span> &nbsp;  'connector' = 'datagen',</span><span> &nbsp;  'scan.parallelism' = '4'</span><span>);</span><span><span>​</span></span><span>-- or set parallelism via dynamic table option</span><span>SELECT * FROM Orders /*+ OPTIONS('scan.parallelism'='4') */;</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsourcessinks%2F%23scan-table-source" rel="nofollow" target="_blank"><span>文档</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fpages%2Fviewpage.action%3FpageId%3D263429150" rel="nofollow" target="_blank"><span>FLIP-367: Support Setting Parallelism for Table/SQL Sources</span></a></span></p></li></ul><span id="OSC_h3_3"></span><h3><span>可配置的 SQL Gateway Java 选项</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>一个用于指定 Java 选项的新选项 env.java.opts.sql-gateway ，这样你就可以微调内存设置、垃圾回收行为和其他相关 Java 参数。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-33203" rel="nofollow" target="_blank"><span>FLINK-33203</span></a></span></p></li></ul><span id="OSC_h3_4"></span><h3><span>使用 SQL 提示配置不同的状态 TTL</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>从 Flink 1.18 开始，Table API 和 SQL 用户可以通过 SQL 编译计划为有状态操作符单独设置状态存续时间 ( TTL )。在 Flink 1.19 中，用户可以</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fhints%2F%23state-ttl-hints" rel="nofollow" target="_blank"><span>使用 STATE_TTL 提示</span></a></span><span>，以更灵活的方式直接在查询中为常规连接和分组聚合指定自定义 TTL 值。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>这一改进意味着您不再需要修改编译后的计划，就能为这些常用操作符设置特定的 TTL。引入 STATE_TTL 提示后，您可以简化工作流程，并根据操作要求动态调整 TTL。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>下面是一个例子：</span></p><pre><span>-- set state ttl for join</span><span>SELECT /*+ STATE_TTL('Orders'= '1d', 'Customers' = '20d') */ *</span><span>FROM Orders LEFT OUTER JOIN Customers</span><span> &nbsp;  ON Orders.o_custkey = Customers.c_custkey;</span><span><span>​</span></span><span>-- set state ttl for aggregation</span><span>SELECT /*+ STATE_TTL('o' = '1d') */ o_orderkey, SUM(o_totalprice) AS revenue</span><span>FROM Orders AS o</span><span>GROUP BY o_orderkey;</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fhints%2F%23state-ttl-hints" rel="nofollow" target="_blank"><span>文档</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-373%253A%2BSupport%2BConfiguring%2BDifferent%2BState%2BTTLs%2Busing%2BSQL%2BHint" rel="nofollow" target="_blank"><span>FLIP-373: Support Configuring Different State TTLs using SQL Hint</span></a></span></p></li></ul><span id="OSC_h3_5"></span><h3><span>函数和存储过程支持命名参数</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在，在调用函数或存储过程时可以使用命名参数。使用命名参数时，用户无需严格指定参数位置，只需指定参数名称及其相应值即可。同时，如果没有指定非必要参数，这些参数将默认为空值。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>下面是一个使用命名参数定义带有一个必选参数和两个可选参数的函数的示例：</span></p><pre><span>public static class NamedArgumentsTableFunction extends TableFunction&lt;Object&gt; {</span><span><span>​</span></span><span><span></span>@FunctionHint(</span><span><span></span><span></span><span></span>output = @DataTypeHint("STRING"),</span><span><span></span><span></span><span></span>arguments = {</span><span><span></span><span></span><span></span><span></span><span></span>@ArgumentHint(name = "in1", isOptional = false, type = @DataTypeHint("STRING")),</span><span><span></span><span></span><span></span><span></span><span></span>@ArgumentHint(name = "in2", isOptional = true, type = @DataTypeHint("STRING")),</span><span><span></span><span></span><span></span><span></span><span></span>@ArgumentHint(name = "in3", isOptional = true, type = @DataTypeHint("STRING"))})</span><span><span></span>public void eval(String arg1, String arg2, String arg3) {</span><span><span></span><span></span>collect(arg1 + ", " + arg2 + "," + arg3);</span><span><span></span>}</span><span><span>​</span></span><span>}</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 SQL 中调用函数时，可以通过名称指定参数，例如：</span></p><pre><span>SELECT * FROM TABLE(myFunction(in1 =&gt; 'v1', in3 =&gt; 'v3', in2 =&gt; 'v2'))</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>可选参数也可以省略：</span></p><pre><span>SELECT * FROM TABLE(myFunction(in1 =&gt; 'v1'))</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Ffunctions%2Fudfs%2F%23named-parameters" rel="nofollow" target="_blank"><span>文档</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-387%253A%2BSupport%2Bnamed%2Bparameters%2Bfor%2Bfunctions%2Band%2Bcall%2Bprocedures" rel="nofollow" target="_blank"><span>FLIP-387: Support named parameters for functions and call procedures</span></a></span></p></li></ul><span id="OSC_h3_6"></span><h3><span>Window TVF 聚合功能</span></h3><ul><li><p style="margin-left:.5rem; margin-right:0"><span>支持流模式下的 SESSION Window TVF</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在，用户可以在流模式下使用 SESSION Window TVF。下面是一个简单的示例：</span></p><pre><span>-- session window with partition keys</span><span>SELECT * FROM TABLE(</span><span> &nbsp; SESSION(TABLE Bid PARTITION BY item, DESCRIPTOR(bidtime), INTERVAL '5' MINUTES));</span><span><span>​</span></span><span>-- apply aggregation on the session windowed table with partition keys</span><span>SELECT window_start, window_end, item, SUM(price) AS total_price</span><span>FROM TABLE(</span><span> &nbsp;  SESSION(TABLE Bid PARTITION BY item, DESCRIPTOR(bidtime), INTERVAL '5' MINUTES))</span><span>GROUP BY item, window_start, window_end;</span></pre><ul><li><p style="margin-left:.5rem; margin-right:0"><span>Window TVF 聚合支持处理更新流</span></p><p style="margin-left:.5rem; margin-right:.5rem"><span>窗口聚合运算符（基于窗口 TVF 函数生成）现在可以顺利处理更新流（如 CDC 数据源等）。建议用户从传统的，窗口聚合迁移到新语法，以获得更全面的功能支持。</span></p></li></ul><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Fsql%2Fqueries%2Fwindow-tvf%2F%23session" rel="nofollow" target="_blank"><span>文档</span></a></span></p></li></ul><span id="OSC_h3_7"></span><h3><span>新的 UDF 类型：AsyncScalarFunction</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>常见的 UDF 类型 ScalarFunction 可以很好地处理 CPU 密集型操作，但对于 IO 密集型或其他长时间运行的计算则效果不佳。在 Flink 1.19 中，我们新增了 AsyncScalarFunction ，它是一种用户定义的异步 ScalarFunction ，允许异步发出并发函数调用。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-400%253A%2BAsyncScalarFunction%2Bfor%2Basynchronous%2Bscalar%2Bfunction%2Bsupport" rel="nofollow" target="_blank"><span>FLIP-400: AsyncScalarFunction for asynchronous scalar function support</span></a></span></p></li></ul><span id="OSC_h3_8"></span><h3><span>Regular Join 支持 MiniBatch 优化 </span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>消息放大是 Flink 中执行级联连接时的一个痛点，现在在 Flink 1.19 中得到了解决，新的 MiniBatch 优化可用于 Regular Join，以减少此类级联连接场景中的中间结果。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><img src="https://img.alicdn.com/imgextra/i1/O1CN01mIzhev22B9TWiUK3v_!!6000000007081-0-tps-2098-892.jpg" referrerpolicy="no-referrer"></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Ftable%2Ftuning%2F%23minibatch-regular-joins" rel="nofollow" target="_blank"><span>minibatch-regular-joins 文档</span></a></span><span>.</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-415%253A%2BIntroduce%2Ba%2Bnew%2Bjoin%2Boperator%2Bto%2Bsupport%2Bminibatch" rel="nofollow" target="_blank"><span>FLIP-415: Introduce a new join operator to support minibatch</span></a></span></p></li></ul><span id="OSC_h2_9"></span><h2><span>二、Runtime &amp; Coordination 提升</span></h2><span id="OSC_h3_10"></span><h3><span>批作业支持源表动态并行度推导</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 Flink 1.19 中，我们支持批作业的源表动态并行度推导，允许源连接器根据实际消耗的数据量动态推断并行度。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>与以前的版本相比，这一功能有了重大改进，以前的版本只能为源节点分配固定的默认并行度。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>源连接器需要实现推理接口，以启用动态并行度推理。目前，FileSource 连接器已经开发出了这一功能。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>此外，配置 execution.batch.adaptive.auto-parallelism.default-source-parallelism 将被用作源并行度推理的上限。现在，它不会默认为 1。取而代之的是，如果没有设置，将使用通过配置 execution.batch.adaptive.auto-parallelism.max-parallelism 设置的允许并行度上限。如果该配置也未设置，则将使用默认的并行度设置 parallelism.default 或 StreamExecutionEnvironment#setParallelism() 。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdeployment%2Felastic_scaling%2F%23enable-dynamic-parallelism-inference-support-for-sources" rel="nofollow" target="_blank"><span>文档</span></a></span><span>.</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-379%253A%2BDynamic%2Bsource%2Bparallelism%2Binference%2Bfor%2Bbatch%2Bjobs" rel="nofollow" target="_blank"><span>FLIP-379: Support dynamic source parallelism inference for batch jobs</span></a></span></p></li></ul><span id="OSC_h3_11"></span><h3><span>Flink Configuration 支持标准 YAML 格式</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>从 Flink 1.19 开始，Flink 正式全面支持标准 YAML 1.2 语法。默认配置文件已改为 config.yaml ，放置在 conf/directory 中。如果用户想使用传统的配置文件 flink-conf.yaml ，只需将该文件复制到 conf/directory 中即可。一旦检测到传统配置文件 flink-conf.yml ，Flink 就会优先使用它作为配置文件。而在即将推出的 Flink 2.0 中， flink-conf.yaml 配置文件将不再起作用。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdeployment%2Fconfig%2F%23flink-configuration-file" rel="nofollow" target="_blank"><span>flink-configuration-file 文档</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-366%253A%2BSupport%2Bstandard%2BYAML%2Bfor%2BFLINK%2Bconfiguration%3Fsrc%3Dcontextnavpagetreemode" rel="nofollow" target="_blank"><span>FLIP-366: Support standard YAML for Flink configuration</span></a></span></p></li></ul><span id="OSC_h3_12"></span><h3><span>在 Flink Web 上 Profiling JobManager/TaskManager</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 Flink 1.19 中，我们支持在 JobManager/TaskManager 级别触发 Profile，允许用户创建具有任意时间间隔和事件模式（由 async-profiler 支持）的 Profile 实例。用户可以在 Flink Web UI 中轻松提交剖析并导出结果。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>例如，用户只需在确定存在性能瓶颈的候选任 JobManager/TaskManager 后，通过 "Create Profiling Instance" 提交一个具有指定周期和模式的 Profile 实例：</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><img src="https://img.alicdn.com/imgextra/i4/O1CN01ytIK8C1uBavsxnY5B_!!6000000005999-0-tps-3582-1264.jpg" referrerpolicy="no-referrer"></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>Profile 结果：</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><img src="https://img.alicdn.com/imgextra/i1/O1CN015wZxI11T8OXVIHnj3_!!6000000002337-0-tps-2852-258.jpg" referrerpolicy="no-referrer"></span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fops%2Fdebugging%2Fprofiler%2F" rel="nofollow" target="_blank"><span>文档</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fx%2F64lEE" rel="nofollow" target="_blank"><span>FLIP-375: Built-in cross-platform powerful java profiler</span></a></span></p></li></ul><span id="OSC_h3_13"></span><h3><span>新增管理员 JVM 选项配置选项</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>有一组管理员 JVM 选项可供使用，它们是用户设置的额外 JVM 选项的前缀，用于全平台范围的 JVM 调整。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdeployment%2Fconfig%2F%23jvm-and-logging-options" rel="nofollow" target="_blank"><span>文档</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-397%253A%2BAdd%2Bconfig%2Boptions%2Bfor%2Badministrator%2BJVM%2Boptions%3Fsrc%3Djira" rel="nofollow" target="_blank"><span>FLIP-397: Add config options for administrator JVM options</span></a></span></p></li></ul><span id="OSC_h2_14"></span><h2><span>三、Checkpoints 提升</span></h2><span id="OSC_h3_15"></span><h3><span>Source 反压时支持使用更大的 Checkpointing 间隔</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>引入 ProcessingBacklog 的目的是为了说明处理记录时应采用低延迟还是高吞吐量。ProcessingBacklog 可由 Source 算子设置，并可用于在运行时更改作业的检查点间隔。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-32514" rel="nofollow" target="_blank"><span>FLINK-32514</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-309%253A%2BSupport%2Busing%2Blarger%2Bcheckpointing%2Binterval%2Bwhen%2Bsource%2Bis%2Bprocessing%2Bbacklog" rel="nofollow" target="_blank"><span>[FLIP-309: Support using larger checkpointing interval when source is processing backlog]</span></a></span></p></li></ul><span id="OSC_h3_16"></span><h3><span>CheckpointsCleaner 并行清理单个检查点状态</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>现在，在处置不再需要的检查点时，ioExecutor 会并行处置每个状态句柄/状态文件，从而大大提高了处置单个检查点的速度（对于大型检查点，处置时间可从 10 分钟缩短至 &lt; 1 分钟）。可以通过设置为 false 恢复旧版本的行为。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-33090" rel="nofollow" target="_blank"><span>FLINK-33090</span></a></span></p></li></ul><span id="OSC_h3_17"></span><h3><span>通过命令行客户端触发 </span><span><strong><span>Checkpoints</span></strong></span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>命令行界面支持手动触发检查点。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>使用方法：</span></p><pre><span>./bin/flink checkpoint $JOB_ID [-full]</span></pre><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>如果指定"-full "选项，就会触发完全检查点。否则，如果作业配置为定期进行增量检查点，则会触发增量检查点。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-6755" rel="nofollow" target="_blank"><span>FLINK-6755</span></a></span></p></li></ul><span id="OSC_h2_18"></span><h2><span>四、Connector API 提升</span></h2><span id="OSC_h3_19"></span><h3><span>与 Source API 一致的 SinkV2 新接口</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>在 Flink 1.19 中，SinkV2 API 做了一些修改，以便与 Source API 保持一致。以下接口已被弃用： TwoPhaseCommittingSink、StatefulSink 、WithPreWriteTopology、WithPreCommitTopology、WithPostCommitTopology 。引入了以下新接口 CommitterInitContext 、CommittingSinkWriter 、 WriterInitContext 、StatefulSinkWrite。更改了以下接口方法的参数： Sink#createWriter 。 在 1.19 版本发布期间，原有接口仍将可用，但会在后续版本中移除。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-33973" rel="nofollow" target="_blank"><span>FLINK-33973</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-372%253A%2BEnhance%2Band%2Bsynchronize%2BSink%2BAPI%2Bto%2Bmatch%2Bthe%2BSource%2BAPI" rel="nofollow" target="_blank"><span>FLIP-372: Enhance and synchronize Sink API to match the Source API</span></a></span></p></li></ul><span id="OSC_h3_20"></span><h3><span>用于跟踪 Committables 状态的新 Committer 指标</span></h3><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>修改了 TwoPhaseCommittingSink#createCommitter 方法的参数化，新增了 CommitterInitContext 参数。原来的方法在 1.19 版本发布期间仍然可用，但会在后续版本中移除。</span></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span><strong><span>更多信息</span></strong></span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FFLINK-25857" rel="nofollow" target="_blank"><span>FLINK-25857</span></a></span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FFLINK%2FFLIP-371%253A%2BProvide%2Binitialization%2Bcontext%2Bfor%2BCommitter%2Bcreation%2Bin%2BTwoPhaseCommittingSink" rel="nofollow" target="_blank"><span>FLIP-371: Provide initialization context for Committer creation in TwoPhaseCommittingSink</span></a></span></p></li></ul><span id="OSC_h2_21"></span><h2><span>五、重要 API 弃用</span></h2><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>为了给 Flink 2.0 版本做准备，社区决定正式废弃多个已接近生命周期终点的 API。</span></p><ul><li><p style="margin-left:.5rem; margin-right:0"><span>Flink's </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ftime%2FTime.java" rel="nofollow" target="_blank"><span>org.apache.flink.api.common.time.Time</span></a></span><span> 现已被正式弃用，并将在 Flink 2.0 中删除。引入了支持 Duration 类的方法，以取代已废弃的基于 Time 的方法。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-runtime%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fruntime%2Fjobgraph%2FRestoreMode.java%23L40" rel="nofollow" target="_blank"><span>org.apache.flink.runtime.jobgraph.RestoreMode#LEGACY </span></a></span><span> 已被弃用。请使用 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-runtime%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fruntime%2Fjobgraph%2FRestoreMode.java%23L31" rel="nofollow" target="_blank"><span>RestoreMode#CLAIM</span></a></span><span> 或 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-runtime%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fruntime%2Fjobgraph%2FRestoreMode.java%23L34" rel="nofollow" target="_blank"><span>RestoreMode#NO_CLAIM</span></a></span><span> 模式，以在还原时获得清晰的状态文件所有权。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>旧的解决模式兼容性的方法已被弃用，请参考迁移说明迁移至新方法： </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Fdocs%2Fdev%2Fdatastream%2Ffault-tolerance%2Fserialization%2Fcustom_serialization%2F%23migrating-from-deprecated-typeserializersnapshotresolveschemacompatibility" rel="nofollow" target="_blank"><span>Migrating from deprecated TypeSerializerSnapshot#resolveSchemaCompatibility(TypeSerializer newSerializer) before Flink 1.19</span></a></span><span>.</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>通过硬代码配置序列化行为已被弃用，例如 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2FExecutionConfig.java%23L643" rel="nofollow" target="_blank"><span>ExecutionConfig#enableForceKryo</span></a></span><span>。请使用选 pipeline.serialization-config 、pipeline.force-avr 、pipeline.force-kryo 和 pipeline.generic-types。实例级序列化器的注册已被弃用，请使用类级序列化器。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>除了 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FConfiguration.java%23L176" rel="nofollow" target="_blank"><span>getString(String key, String defaultValue) </span></a></span><span>和 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FConfiguration.java%23L220" rel="nofollow" target="_blank"><span>setString(String key, String value)</span></a></span><span>，我们已废弃所有 setXxx 和 getXxx 方法，如：setInteger 、setLong 、getInteger 和 getLong 等。 建议用户和开发人员使用以 ConfigOption 代替字符串作为键的 get 和 set 方法。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span>StreamExecutionEnvironment 、CheckpointConfig 和 ExecutionConfig 中的非 ConfigOption 对象及其相应的 getter/setter 接口现已废弃。这些对象和方法计划在 Flink 2.0 中删除。已废弃的接口包括重启策略（ RestartStrategy ）、检查点存储（ CheckpointStorage ）和状态后端（ StateBackend ）的 getter 和 setter 方法。 </span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRuntimeContext.java%23L191" rel="nofollow" target="_blank"><span>org.apache.flink.api.common.functions.RuntimeContext#getExecutionConfig</span></a></span><span> 现已被正式弃用，并将在 Flink 2.0 中删除。请使用 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRuntimeContext.java%23L208" rel="nofollow" target="_blank"><span>getGlobalJobParameters()</span></a></span><span> 或 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRuntimeContext.java%23L216" rel="nofollow" target="_blank"><span>isObjectReuseEnabled()</span></a></span><span>。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRichFunction.java%23L76" rel="nofollow" target="_blank"><span>org.apache.flink.api.common.functions.RichFunction#open(Configuration parameters)</span></a></span><span> 方法已被弃用，并将在未来版本中删除。我们鼓励用户迁移到新的</span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Frelease-1.19%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fapi%2Fcommon%2Ffunctions%2FRichFunction.java%23L118" rel="nofollow" target="_blank"><span>RichFunction#open(OpenContext openContext)</span></a></span><span>。</span></p></li><li><p style="margin-left:.5rem; margin-right:0"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FAkkaOptions.java" rel="nofollow" target="_blank"><span>org.apache.flink.configuration.AkkaOptions </span></a></span><span> 已被弃用，取而代之的是 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fflink%2Fblob%2Fmaster%2Fflink-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fflink%2Fconfiguration%2FRpcOptions.java" rel="nofollow" target="_blank"><span> RpcOptions </span></a></span><span>。</span></p></li></ul><span id="OSC_h2_22"></span><h2><span>六、升级说明</span></h2><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><span>Apache Flink 社区努力确保升级过程尽可能平稳, 但是升级到 1.19 版本可能需要用户对现有应用程序做出一些调整。请参考 </span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-release-1.19%2Frelease-notes%2Fflink-1.19%2F" rel="nofollow" target="_blank"><span>Release Notes</span></a></span><span> 获取更多的升级时需要的改动与可能的问题列表细节。</span></p><span id="OSC_h2_23"></span><h2><span>贡献者列表</span></h2><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start"><img alt="" height="1208" src="https://oscimg.oschina.net/oscnet/up-3b5104e2ecbe3e23ee1f72b104fd572d9c2.png" width="1550" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:.8em; margin-right:.8em; text-align:start">&nbsp;</p><hr><span id="OSC_h2_24"></span><h2>Flink Forward Asia 2023</h2><p>本届 Flink Forward Asia 更多精彩内容，可微信扫描图片二维码观看全部议题的视频回放及 FFA 2023 峰会资料！</p><p><img alt="" src="https://ucc.alicdn.com/gfbp4bwpctdbo_20231225_14aea0210006473091eeaad86fb840a2.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8374c4af52676c9e8e31915ba3a7c4ec22c.png" referrerpolicy="no-referrer"></p><hr><span id="OSC_h2_25"></span><h2>更多内容</h2><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fba668f04d5a3f206c6530c940b5973aa44.png" referrerpolicy="no-referrer"></p><hr><span id="OSC_h2_26"></span><h2>活动推荐</h2><p>阿里云基于 Apache Flink 构建的企业级产品-实时计算 Flink 版现开启活动：<br> 59 元试用&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3FpipCode%3Dsc" rel="nofollow" target="_blank">实时计算 Flink 版</a>（3000CU*小时，3 个月内）<br> 了解活动详情：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3FpipCode%3Dsc" rel="nofollow" target="_blank">https://free.aliyun.com/?pipCode=sc</a></p><p><img alt="" src="https://ucc.alicdn.com/pic/developer-ecology/gfbp4bwpctdbo_b2c1ad1f1c94438ba3d2f6eb2f40a795.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-140340868927cb8aa03b4b96e643c9112cb.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 05:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/2828172/blog/11047986</guid>
            <link>https://my.oschina.net/u/2828172/blog/11047986</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Node.js 新版官网正式上线]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Node.js 新版官网已正式上线：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnodejs.org%2Fen" target="_blank">https://nodejs.org/en</a></u>。</p><ul><li><strong>Node.js 新版官网首页</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d7f75fbfacc0c0f7aa4bd49a44845da9c0e.png" referrerpolicy="no-referrer"></p><ul><li><strong>旧版官网首页</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d7fdf3a71b012fa030e0d8da045acd8a078.png" referrerpolicy="no-referrer"></p><p>可以看到，新版官网的视觉效果、页面布局、展现内容都有了很大的提升，整体上更大气、更现代化。而且首页关于 Node.js 的介绍也变得更突出、描述更全面。</p><p>此外，新版官网最大的交互变化是在首页添加了「全局搜索」入口，方便用户随时检索文档、博客、下载等信息。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c9984afc8c57cf2cc9b031519ad713980ba.png" referrerpolicy="no-referrer"></p><p>其他子页面一览：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5219eed54c5df5855bb21a3c939725e914b.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-82a9406af23007a8c812f31fd7c8bdce52f.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c626de0d15afa528c4f04eb59658c79635e.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9f4190b429a1060ceb08600f74698605af6.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-432b101ae6fdf83b85ce42d68b8f7ca2b68.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 04:23:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283883/node-js-org-new-ui</guid>
            <link>https://www.oschina.net/news/283883/node-js-org-new-ui</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[iLogtail 2.0 来了；通义灵码下载量破百万]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>云原生月度动态</strong></p><p>云原生是企业数字创新的最短路径。</p><p>《阿里云云原生每月动态》，从趋势热点、产品新功能、服务客户、开源与开发者动态等方面，为企业提供数字化的路径与指南。</p><h2>趋势热点</h2><h3>🥇&nbsp;云原生可观测团队获选「InfoQ 年度技术内容贡献奖」</h3><p>近期，知名技术媒体 InfoQ 结合广大开发者和技术社群的实际反馈，评选出「InfoQ 年度技术内容贡献奖」，以表彰推动业界知识分享的卓越贡献者。其中，「阿里云云原生可观测团队」成功获选，以此表彰阿里云云原生可观测团队在技术研发与产品创新同时，积极参与技术内容输出、社区建设、知识分享等活动，努力推进云原生、可观测的落地实践。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247561870%26idx%3D1%26sn%3Dd8f2919d37b32eb46aa973032ada64eb%26chksm%3Dfae7f941cd907057abc8ce4be579cc7ba83f6e674c3a989145b6c35b320ff53b0f35f3167c3e%26scene%3D21%23wechat_redirect" target="_blank">相关文章：「云原生可观测团队」获选「InfoQ 年度技术内容贡献奖」</a></p><h3>🥈&nbsp;国内唯一！通义灵码入选全球智能编码助手使用率 TOP 榜单</h3><p>近日，在国内知名科技媒体 InfoQ 研究中心发布的《中国软件技术发展洞察和趋势预测报告 2024》中提到，随着 AI 和大模型技术的普及，开发者智能编码助手的使用习惯已经养成，其中，开发者使用的智能编码助手产品使用率超过 10% 的产品共计 8 款，唯一一款国内企业研发的产品为阿里旗下的通义灵码，使用率占比 12.9% 排名第五。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247561987%26idx%3D1%26sn%3D094e6ffb1ecd9268194cd912401dc09d%26chksm%3Dfae7f8cccd9071daf348db0f1a9f8f65179589da0d3f9cf065adedf604b1ab8fa01222750367%26scene%3D21%23wechat_redirect" target="_blank">相关文章：国内唯一！通义灵码入选全球智能编码助手使用率 TOP 榜单<br></a></p><h3>🥉&nbsp;iLogtail 2.0 来了！</h3><p>随着可观测数据采集需求的不断推陈出新，现有的 iLogtail 架构和采集配置结构逐渐成为制约 iLogtail 继续快速演进的瓶颈。基于此，团队决定对 iLogtail 进行全面升级，全面提升 iLogtail 的易用性、可扩展性和性能。经过半年多的重构与优化，iLogtail 2.0 已经呼之欲出，有以下新特性：【商业版】采集配置全面升级流水线结构、处理插件组合更加灵活、新增 SPL 处理模式、日志解析控制更加精细、【商业版】日志时间解析支持纳秒级精度、【商业版】状态观测更加清晰、运行更快更安全。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247562109%26idx%3D1%26sn%3D997036af93cc31ff68faab565d6f5022%26chksm%3Dfae7f8b2cd9071a4e7822493c921cec17d273ec25e4621d35caeda0445b8a08ba2d1da940356%26scene%3D21%23wechat_redirect" target="_blank">相关文章：你好，iLogtail 2.0！<br></a></p><h2>产品新功能</h2><h3>微服务引擎 MSE</h3><ul><li>MSE 注册配置中心支持在控制枱进行网络变配</li><li>云原生网关核心链路优化</li></ul><h3>云效项目协作 Projex</h3><ul><li>项目管理权限细化：将成员管理、基本信息设置、通知等单独拆分权限点</li><li>支持项目模板角色权限同步</li></ul><h3>日志服务 SLS</h3><ul><li>SLS Lens 支持 SQL 质量报告功能</li><li>logtail 2.0.1 版本支持 SPL 数据处理语言处理数据</li><li>SLS 支持接入 NLB 产品 4 层指标数据，支持短信服务（国际站）日志</li><li>SLS 日志审计应用支持以张家口作为中心化存储地域</li></ul><h3>应用实时监控服务 ARMS</h3><p><strong>应用监控</strong></p><ul><li>新版控制枱调用链分析支持错慢 Trace 分析功能</li><li>持续剖析配置支持根据应用部署环境自动填充网段地址</li></ul><p><strong>智能告警</strong></p><ul><li>应用监控告警事件详情支持传递自定义的应用标签</li><li>告警屏蔽操作支持填写屏蔽原因</li></ul><p><strong>用户体验监控</strong></p><ul><li>会话追踪详情面板</li><li>资源加载趋势分析</li><li>App 监控能力</li></ul><p>云拨测证书过期时间检测和告警</p><h3>可观测链路 OpenTelemetry 版</h3><p>可观测链路 OpenTelemetry 版重磅发布 2.0 版本</p><h3>可观测监控 Prometheus 版</h3><ul><li>数据投递服务支持将阿里云 Prometheus 数据通过 &nbsp;RemoteWrite 协议投递到自建 &nbsp;Prometheus</li><li>接入管理支持配置废弃指标</li><li>RDS-PG 增加监控指标</li><li>新版接入中心海外区域全面上线</li><li>新版接入中心海外区域全面上线 ack-sysom-monitor 监控限时免费（2024/2/21-2024/5/21 ）</li></ul><h3>通义灵码</h3><ul><li>支持自定义配置不触发行间生成的编程语言</li><li>VS Code 兼容 Windows 7 操作系统，扩展 IDE 版本兼容到 1.70.0 以上</li><li>优化 Java、Python 生成单元测试效果及新建文件命名规则</li><li>优化登录后身份选择的提示</li></ul><h2>优秀实战案例</h2><h3>青团社：亿级灵活用工平台的云原生架构实践</h3><p>青团社是国内领先的一站式灵活用工招聘服务企业，在发展初期技术架构比较薄弱，存在较多问题。面对这些问题，青团社开始了架构演进，选择了进行微服务架构和业务容器化改造，同时，在可观测性和应用性的架构上，用阿里云应用实时监控服务 ARMS 的应用监控能力和 MSE 产品来对应用服务进行性能观测与流量治理，使应用实现了高可用和弹性调度，能快速了解系统运行状态，运维成本也大幅降低。</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247562153%26idx%3D1%26sn%3Df6f5fb5931dac455ce6fe296c0a41375%26chksm%3Dfae7f866cd90717038e7f848d1e6f7d2d90fd1d2a14e115f714564b7ecdf55cc92200e3ecd38%26scene%3D21%23wechat_redirect" target="_blank">相关文章：青团社：亿级灵活用工平台的云原生架构实践<br></a></p><h2>开源与开发者动态</h2><h3>有奖讨论丨你能看出来哪些是 AI 写的代码么？</h3><p>随着 AI 智能浪潮到来，AI 智能编码助手成为越来越多开发者的必备工具，本期话题我们就来聊聊备受关注的「AI 编码助手」，体验「通义灵码」，分享使用感受。</p><p>相关文章：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247561935%26idx%3D2%26sn%3D8ee55dc8ed4ad3694ee4efc1ad38ff87%26chksm%3Dfae7f900cd907016e273eb3dd3d884797ba6662301a95d0580e98c34484701ca06b5288094a6%26scene%3D21%23wechat_redirect" target="_blank">有奖讨论丨你能看出来哪些是 AI 写的代码么？</a></p><h3>参与通义灵码体验活动赢全球架构师峰会门票</h3><p>通义灵码，是阿里云出品的一款基于通义大模型的智能编码辅助工具，提供行级/函数级实时续写、自然语言生成代码、单元测试生成、代码优化、注释生成、代码解释、研发智能问答、异常报错排查等能力，并针对阿里云的云服务使用场景调优，助力开发者高效、流畅的编码。本次 ArchSummit 架构师峰会期间，通义灵码联合 InfoQ 策划发起 AI 编程体验活动，参与通义灵码体验抽奖活动，有机会赢全球架构师峰会专属免费门票。（票价 5440 元）</p><p>相关文章：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzNzYxNjAzMg%3D%3D%26mid%3D2247562169%26idx%3D1%26sn%3Dc084e24cd2efbc65e21f1cc5e220f179%26chksm%3Dfae7f876cd90716067905c024e3d4ed2a86b75129f302453a520938a26a48382c641f43bea54%26scene%3D21%23wechat_redirect" target="_blank">AI 编程如何颠覆生产力 | 参与体验免费领取 ArchSummit 架构师峰会专属门票</a></p><p>点击<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftongyi.aliyun.com%2Flingma" target="_blank">此处</a>，进入通义灵码官网快速体验。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:51:17 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/11048168</guid>
            <link>https://my.oschina.net/u/3874284/blog/11048168</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Java 22 正式发布，一文了解全部新特性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在昨晚，Java 22 正式发布！该版本提供了 12 项功能增强，其中包括 7 项预览功能和 1 项孵化器功能。它们涵盖了对 Java 语言、API、性能以及 JDK 中包含的工具的改进。</p><p>下面就来一起学习一下该版本都更新了哪些新特性！</p><h2>Unnamed Variables &amp; Patterns - JEP 456</h2><p>JEP 456 - 未命名变量和模式：当需要但未使用变量声明或嵌套模式时，提高了可读性。两者都由下划线字符表示。</p><p><strong>价值</strong></p><ul><li>捕获开发人员的意图，即未使用给定的绑定或 lambda 参数，并强制执行该属性以澄清程序并减少出错的机会。</li><li>通过识别必须声明（例如，在 catch 子句中）但未使用的变量，提高所有代码的可维护性。</li><li>允许多个模式出现在单个 case 标签中，如果它们都没有声明任何模式变量。</li><li>通过消除不必要的嵌套类型模式来提高记录模式的可读性。</li></ul><h2>Statements before super (…) [Preview] - JEP 447</h2><p>在构造函数中，允许不引用正在创建的实例的语句出现在显式构造函数调用之前。</p><p><strong>价值</strong></p><ul><li>为开发人员提供了更大的自由来表达构造函数的行为，从而可以更自然地放置目前必须纳入辅助静态方法、辅助中间构造函数或构造函数参数中的逻辑。</li><li>保留构造函数在类实例化期间按自上而下顺序运行的现有保证，确保子类构造函数中的代码不会干扰超类实例化。</li><li>不需要对 Java 虚拟机进行任何更改。此 Java 语言功能仅依赖于 JVM 验证和执行构造函数中显式构造函数调用之前出现的代码的当前能力。</li></ul><h2>String Templates (2nd Preview) - JEP 459</h2><p>字符串模版的第 2 个预览版，关于该功能之前 DD 给大家介绍过，更多细节可以看看之前的这篇文章<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2Fjava21%2Fjep430-string-templates.html" target="_blank">String Templates（字符串模版）</a></p><p><strong>价值</strong></p><ul><li>通过轻松表达包含运行时计算值的字符串，简化了 Java 程序的编写。</li><li>增强混合文本和表达式的表达式的可读性，无论文本适合单个源行（如字符串文字）还是跨越多个源行（如文本块）。</li><li>通过支持模板及其嵌入表达式的值的验证和转换，提高 Java 程序的安全性，这些程序从用户提供的值组成字符串并将其传递到其他系统（例如，构建数据库查询）。</li><li>通过允许 Java 库定义字符串模板中使用的格式化语法来保留灵活性。</li><li>简化了接受非 Java 语言（例如 SQL、XML 和 JSON）编写的字符串的 API 的使用。</li><li>允许创建根据文字文本和嵌入表达式计算的非字符串值，而无需通过中间字符串表示形式进行传输。</li></ul><h2>Implicitly Declared Classes and Instance Main Methods (2nd Preview) - JEP 463</h2><p>隐式声明的类和实例主要方法（2nd 预览）- JEP 463</p><p>学生可以编写他们的第一个 Java 程序，而无需了解为大型程序设计的语言功能。学生无需使用单独的语言方言，而是可以为单类程序编写简化的声明，然后随着技能的增长无缝扩展他们的程序以使用更高级的功能。关于该特性，之前 DD 也介绍过，更多细节可见这篇文章<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2Fjava21%2Fjep445-Unnamed-Classes-and-Instance-Main-Methods.html" target="_blank">未命名类和实例的 Main 方法</a></p><p><strong>价值</strong></p><ul><li>加速 Java 学习</li><li>为 Java 编程提供了一个平滑的入门通道，以便教师可以循序渐进地介绍概念。</li><li>帮助学生以简洁的方式编写基本程序，并随着他们的技能增长而优雅地扩展他们的代码。</li><li>减少编写简单程序（例如：脚本和命令行实用程序）的方式。</li><li>不引入单独的初学者工具链；学生程序应该使用与编译和运行任何 Java 程序相同的工具来编译和运行。</li></ul><h2>Foreign Function &amp; Memory API - JEP 454</h2><p>外部函数和内存 API - JEP 454</p><p>允许 Java 程序与 Java 运行时之外的代码和数据进行互操作。通过有效地调用外部函数（即 JVM 外部的代码），并安全地访问外部内存（即不受 JVM 管理的内存），API 使 Java 程序能够调用本机库并处理本机数据，而不会出现脆弱性和危险。 JNI。</p><p><strong>价值</strong></p><ul><li>生产力：用简洁、可读且纯 Java API 取代脆弱的本机方法和 Java 本机接口 (JNI)。</li><li>性能：提供对外部函数和内存的访问，其开销与 JNI 和 sun.misc.Unsafe 相当（如果不是更好的话）。</li><li>广泛的平台支持：允许在 JVM 运行的每个平台上发现和调用本机库。</li><li>一致性：提供在多种内存（例如本机内存、持久内存和托管堆内存）中操作无限大小的结构化和非结构化数据的方法。</li><li>健全性：保证没有释放后使用错误，即使在多个线程之间分配和释放内存时也是如此。</li><li>完整性：允许程序使用本机代码和数据执行不安全的操作，但默认警告用户此类操作。</li></ul><h2>Class-File API (Preview) - JEP 457</h2><p>类文件 API（预览版）- JEP 457，提供用于解析、生成和转换 Java 类文件的标准 API。</p><p><strong>价值</strong></p><ul><li>该 API 允许依赖它的框架和程序自动支持最新 JDK 中的最新类文件，以便可以快速、轻松地采用以类文件表示的新语言和 VM 功能。</li></ul><h2>Stream Gatherers (Preview) - JEP 461</h2><p>Stream Gatherers（预览版）- JEP 461，增强了 Stream API 以支持自定义中间操作。这将允许流管道以现有内置中间操作不易实现的方式转换数据。</p><p><strong>价值</strong></p><ul><li>通过使流中的常见自定义操作更加灵活和富有表现力，提高开发人员的工作效率和代码可读性。尽可能允许中间操作操作无限大小的流。</li></ul><h2>Structured Concurrency (2nd Preview) - JEP 462</h2><p>结构化并发（2nd 预览版）- JEP 462，简化并发编程。结构化并发将在不同线程中运行的相关任务组视为单个工作单元，从而简化错误处理和取消、提高可靠性并增强可观察性。</p><p><strong>价值</strong></p><ul><li>通过推广一种编程风格来简化并发代码的开发，这种编程风格可以消除因取消和关闭而产生的常见风险（例如线程泄漏和取消延迟），并提高并发代码的可观察性。</li></ul><h2>Scoped Values (2nd Preview) - JEP 464</h2><p>范围值（2nd 预览）- JEP 464，实现线程内和线程间不可变数据的高效共享。</p><p><strong>价值</strong></p><ul><li>易于使用 - 提供一个编程模型来在线程内以及与子线程共享数据，以简化有关数据流的推理。</li><li>可理解性——使共享数据的生命周期从代码的语法结构中可见。</li><li>鲁棒性——确保调用者共享的数据只能由合法的被调用者检索。</li><li>性能——将共享数据视为不可变，以允许大量线程共享，并实现运行时优化。</li></ul><h2>Vector API (7th Incubator) - JEP 460</h2><p>矢量 API（7th 孵化器）- JEP 460，一个用于表达向量计算的 API，可在运行时可靠地在支持的 CPU 架构上编译为最佳向量指令，从而实现优于等效标量计算的性能。此 JEP 建议在 JDK 22 中重新孵化该 API，相对于 JDK 21。该实现包括错误修复和性能增强。我们包括以下显着变化：</p><ul><li>支持使用任何原始元素类型的数组支持的堆 MemorySegments 进行向量访问。以前的访问仅限于由字节数组支持的堆 MemorySegment。</li></ul><p><strong>价值</strong></p><ul><li>提供清晰简洁的 API，能够清晰简洁地表达各种向量计算，这些向量计算由循环内组成的向量运算序列组成，并且可能还包含控制流。</li><li>该 API 设计为与 CPU 架构无关，可在支持向量指令的多种架构上实现。</li><li>在 x64 和 AArch64 架构上提供可靠的运行时编译和性能。</li></ul><h2>Regional Pinning for G1 - JEP 423</h2><p>G1 的区域固定 - JEP 423，通过在 G1 中实现区域固定来减少延迟，以便在 Java 本机接口 (JNI) 关键区域期间无需禁用垃圾收集。</p><p><strong>价值</strong></p><ul><li>使用 JNI 时，Java 线程无需在 G1 GC 操作完成之前等待，从而提高开发人员的工作效率。</li></ul><h2>Launch Multi-File Source-Code Programs - JEP 458</h2><p>启动多文件源代码程序 - JEP 458，允许用户运行作为多个 Java 源代码文件提供的程序，而无需先进行编译。</p><p><strong>价值</strong></p><ul><li>通过使从小程序到大型程序的过渡更加渐进，提高开发人员的工作效率，使开发人员能够选择是否以及何时配置构建工具。</li><li>请注意，预览功能已完全指定并完全实现了 Java SE 平台的语言或 VM 功能，但它们是暂时的。它们在 JDK 功能版本中提供，以便开发人员根据实际使用情况提供反馈，然后再在未来版本中永久保留。这也为工具供应商提供了在最终确定为 Java SE 标准之前致力于支持功能的机会。</li><li>孵化器模块中的 API 将非最终 API 和非最终工具交给开发人员和用户，以收集反馈，最终提高 Java 平台的质量。</li><li>除了 JEP 中描述的更改之外，发行说明中还列出了许多较小的更新，许多应用程序开发人员和系统管理员都会对此感兴趣。其中包括弃用过时的 API 和删除以前弃用的 API。</li></ul><h2>其他更新</h2><p>Java 22 发行说明中还有​​一些其他关键更新：</p><ul><li>向 keytool 和 jarsigner 添加附加算法。</li><li>垃圾收集器吞吐量的提高，尤其是与「年轻」垃圾相关的情况。</li><li>更好的系统模块描述符版本报告。</li><li>改进了本机代码的「wait」处理选项。</li><li>Unicode 通用区域设置数据存储库已更新至版本 44。</li><li>类型注释支持从字节码加载的类型。</li><li>ForkJoinPool 和 ForJoinTasks 现在可以更好地处理不间断任务。</li><li>配置客户端与服务器 TLS 连接属性的额外灵活性。</li><li>改进了本机内存跟踪，包括报告峰值使用情况的能力</li></ul><p>最后注意：JDK 22 是通过六个月的发布节奏按时交付的 13th 功能版本。由于预期改进源源不断，这种程度的可预测性使开发人员能够轻松管理创新的采用。Oracle 不会为 JDK 22 提供长期支持，在 2023 年 9 月之前提供更新，之后它将被 Oracle JDK 23 取代。最近的长期维护版本是 Java 21，更多关于 Java 新特性的解读和学习欢迎关注<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.didispace.com%2Fjava-features%2F" target="_blank">《Java 新特性解读》</a>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8dea4b48eb8ffca981a1a54d4079789b777.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>欢迎关注我的公众号：程序猿 DD。第一时间了解前沿行业消息、分享深度技术干货、获取优质学习资源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:50:17 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/didispace/blog/11048218</guid>
            <link>https://my.oschina.net/didispace/blog/11048218</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | Grok 使用体验完全够不上第一梯队，Surface Duo 在开源社区扶持下焕发新生]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#e67e22"><strong># 2024.3.19</strong></span></h3><h2 style="margin-left:0; margin-right:0; text-align:left"><strong><span style="color:#16a085">今日要点</span></strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>OpenSource Daily</strong></p><h3 style="margin-left:0; margin-right:0; text-align:left"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1aEpUETGY14C9nAJU-v9dw" target="_blank">英伟达全新 GPU 架构 Blackwell<span>——</span>「全球最强」、第二代 Transformer 引擎、计算性能提升 1000 倍</a></strong></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">按照每两年更新一次 GPU 架构的传统，今年黄仁勋如期公布了英伟达新一代 AI 芯片架构 Blackwell，以及基于该架构的 B200、GB200 系列芯片。他在演讲台上表示，这是目前为止功能最强大的 AI 芯片家族。8 年，从 Pascal 架构到 Blackwell 架构，英伟达将 AI 计算性能提升了 1000 倍！黄仁勋表示：「Hopper 固然已经非常出色了，但我们需要更强大的 GPU」。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="375" src="https://oscimg.oschina.net/oscnet/up-c8c1a36924f6258786a38abcdf84c1220f4.png" width="500" referrerpolicy="no-referrer"></p><h3 style="margin-left:0; margin-right:0; text-align:start"><strong><a href="https://www.oschina.net/news/283757" target="_blank">微信 Linux 原生版正式支持龙架构</a></strong></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">龙芯中科<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2gzVb4cvnVSOP_qgi3A0Bg" target="_blank">宣布</a>，在腾讯微信团队、龙芯中科与国产操作系统厂商的共同努力下，微信 Linux 原生版在龙架构平台终端已于近日成功启动运行，并在操作系统厂商应用商店上架分发，为用户带来全新的龙架构平台使用体验。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">本次微信（Universal）是基于原生跨平台方案进行的一次大型版本重构与更新，旨在逐步实现微信 Windows/Mac/Linux 版本在功能与更新节奏上保持一致，大幅提高软件功能的开发与迭代速度。同时，新版本功能也更加丰富，支持大文件收发、群管理、双人视频通话、一键开启视频号、小程序、搜一搜等实用功能。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="281" src="https://oscimg.oschina.net/oscnet/up-8af6d64640c735fa2e0b0e82057264aa298.jpg" width="500" referrerpolicy="no-referrer"></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><strong><span style="color:#16a085">今日观察</span></strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="97" src="https://oscimg.oschina.net/oscnet/up-22ef22ee0a115b4cc31c8e2d7df84d742f1.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">-<span>&nbsp;</span></span>微博 <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2337975403%2FO5z5a0Ij2" target="_blank"><em>詹俊全</em></a></u></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="122" src="https://oscimg.oschina.net/oscnet/up-1fedf59d99708d718ae00a49e1527ffc328.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">-&nbsp;微博<span>&nbsp;</span></span><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1560906700%2FO5HOTACxA%3Frefer_flag%3D1001030103_" target="_blank">阑夕</a></u></em></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="120" src="https://oscimg.oschina.net/oscnet/up-18ae674bface2fa54ccf5013b070a987524.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#333333">- <em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2F2024-03-19%2Fdetail-inanviqu4644393.d.html" target="_blank">每日经济新闻</a></u></em></span></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="409" src="https://oscimg.oschina.net/oscnet/up-2a95c498beb1bd4a0f02da6d0f975cf6235.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmanticoresoftware%2Fmanticoresearch" target="_blank">https://github.com/manticoresoftware/manticoresearch</a></u></em></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#16a085"><strong>事件点评</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="470" src="https://oscimg.oschina.net/oscnet/up-b4b468388bab83bb920db154ed8a6269d4a.png" width="500" referrerpolicy="no-referrer"></p><hr><h2 style="margin-left:0; margin-right:0; text-align:left"><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong><span style="background-color:#e67e22">每日 GitHub 精选</span></strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="637" src="https://oscimg.oschina.net/oscnet/up-75a419043367ba895f86d3d58d171950867.png" width="500" referrerpolicy="no-referrer"></p><blockquote><h4 style="margin-left:0; margin-right:0"><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/aud8p7bvfbui2z3/032_nvidia_ai_blackwell_surface_duo_MfoMo6bqlE.pdf" target="_blank">开源日报第 032 期：Grok 使用体验完全够不上第一梯队，Surface Duo 在开源社区扶持下焕发新生</a></u></em></h4></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>往期回顾</strong></p><ul style="list-style-type:disc; margin-left:0; margin-right:0"><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/maajc6fkxn2b8la/031_microsoft_autodev_grok_os_vvdrJAOBEq.pdf" target="_blank">开源日报第 031 期：微软 AI 程序员登场，马斯克开源 Grok</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/bkpgqfjrsg02gbc/30_i9_14900_ks_hip_rt_PUJjodKP2j.pdf" target="_blank">开源日报第 030 期：RISC-V 正在发生质变？离职后可以删除自己所写的软件吗</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/71npja41p7l4ojy/29_risc_v_ai_smart_B3RnKR88Kl.pdf" target="_blank">开源日报第 029 期：英特尔获准继续向华为出售芯片；明年 AI 将比任何人都聪明</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/q35lx4s6qq9ls4r/28_cognition_labs_devin_Epbxne3xzN.pdf" target="_blank">开源日报第 028 期：全球首位 AI 软件工程师 Devin；谷歌承认 「窃取」 OpenAI 模型关键信息</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/hh291xp9mxksc9i/27_ai_google_50_gpt_4_KfagjDXXfZ.pdf" target="_blank">开源日报第 027 期：AI 接连翻车的 Google 要变天了；互联网大厂 50 款大模型及应用，能否全面超越 GPT-4？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/uwsizmmsnhq8zdk/26_git_hub_22_web_os_22_vue_rolldown_FpVykoR7rJ.pdf" target="_blank">开源日报第 026 期：大模型替代程序员根本就是一个伪命题；GitHub 顶流 "Web OS"</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6ho57sxydzsh9jh/25_ai_5_ax1LWz5GP5.pdf" target="_blank">开源日报第 025 期：买手机送大模型；「钓鱼式维权」 须遏制；「AI 原生」 骗局江湖</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7xd6teyhekcvamw/24_risc_v_x86_arm_5LsjoStPUn.pdf" target="_blank">开源日报第 024 期：RISC-V 能否和 x86、Arm 一起成为三大主流架构；给阎王开发地府管理系统</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">开源日报第 023 期：Google = 开源，好评；Microsoft = 闭源收入还低，差评</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">开源日报第 022 期：轻松复现 Sora 模型；事关 CUDA 兼容，英伟达禁止了；百度还差一个 「遥遥领先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">开源日报第 021 期：闭源模型就是比开源安全；起诉 OpenAI 不能更赞同</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">开源日报第 020 期：为什么王炸都来自 OpenAI；Pingora 最好不要用 YAML 当配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">开源日报第 019 期：我让 AI 用 C 语言写一个算法；微软三进制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">开源日报第 018 期：苹果十年造车梦碎；这个开源项目有点...「大胆」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">开源日报第 017 期：MariaDB 消亡史；写代码我有三不沾；V 神建议马斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有 「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:47:17 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283875</guid>
            <link>https://www.oschina.net/news/283875</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英伟达和高通加入开源机器人联盟支持 ROS 开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">开源机器人基金会 (OSRF) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fosralliance.org%2Fopen-robotics-launches-the-open-source-robotics-alliance-2%2F" target="_blank">宣布</a>成立开源机器人联盟 (OSRA)，旨在维持开源机器人项目的开发和维护，特别关注 OSRF 自己的机器人操作系统 (ROS) 的健康发展。</span></p><p><span style="color:#000000">公告指出，OSRA 将效仿 Linux 基金会和 Eclipse 基金会等其他成功的开源项目基金会，采用混合会员制和精英管理模式。公开邀请所有社区利益相关者参与 OSRF 开源项目（ROS、Gazebo、Open-RMF 及其基础设施）的技术监督、指导、开发和支持。「整个机器人生态系统的参与对这项计划至关重要。」</span></p><p><span style="color:#000000">OSRA 的中心是技术治理委员会 (TGC)，该委员会将监督各个项目管理委员会、技术委员会、特别兴趣组和工作组的活动。作为 OSRF 的一项慈善计划，OSRA 的总体责任仍由 OSRF 董事会承担。</span></p><p><img height="241" src="https://oscimg.oschina.net/oscnet/up-41f7c0a537fff8636e3a87932da3a46430c.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">为了表示支持，英伟达、高通以及由 Alphabet 成立的衍生机器人公司 Intrinsic 均已签约成为新联盟的「白金」成员 。</span></p><p><span style="color:#000000">英伟达机器人软件副总裁 Gordon Grigor 表示：「英伟达利用 ROS 2 进行开发，为开发人员、研究人员和商业应用带来加速计算和人工智能。作为 OSRA 的首届白金会员，我们将通过协助开发工作、提供治理和连续性来合作推进整个生态系统的开源机器人技术。」</span></p><p><span style="color:#000000">其他成员还包括金牌成员 </span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FApex.ai" target="_blank"><span style="color:#000000">Apex.ai</span></a><span style="color:#000000"> 和 Zettascale，银牌成员 Clearpath Robotics、Ekumen、eProsima 和 PickNik，以及准成员 Silicon Valley Robotics。首批支持组织包括 Canonical 和 Open Navigation。即将加入的成员包括 Bosch 和 ROS-Industrial，后续还计划进一步公布其他成员名单。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 03:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283872/nvidia-qualcomm-open-source-robotics-alliance</guid>
            <link>https://www.oschina.net/news/283872/nvidia-qualcomm-open-source-robotics-alliance</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[三星宣布「AI for All」企业发展愿景]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 三星家电新品发布会 3 月 17 日举行，发布了全新的 MICRO LED、Neo QLED 8K/4K 系列、OLED 系列、Lifestyle 艺术电视及 BESPOKE 缤色铂格系列等全系生态产品。</p><p>此外，三星宣布「AI for All」的企业发展愿景，三星电子大中华区总裁崔胜植表示，「三星正在将 AI 融入到我们的互联技术，从移动设备上的 Galaxy AI，到颠覆性的显示技术，再到通过智能家电改善的智能家居，致力于为用户带来切实利益。」</p><p><img height="334" src="https://oscimg.oschina.net/oscnet/up-3ddacc315c81554f395aa1ff93439e7ec09.png" width="500" referrerpolicy="no-referrer"></p><p>多年来，三星一直在 AI 领域进行战略投资，NQ8 AI Gen3 芯片就是成果之一，其神经处理单元（NPU）的速度是其前代产品的两倍，神经网络的数量也由 64 个增至 512 个。在该款 AI 芯片的加持下，三星 Neo QLED 8K 系列开启了三星 AI 电视新纪元。</p><p>该公司预计 2024 年的销量将恢复到 2022 年的水平，在未来 2-3 年内重新夺回全球芯片领先的位置，将在所有设备中采用人工智能，并积极开拓新业务。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 02:39:46 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/283862</guid>
            <link>https://www.oschina.net/news/283862</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[走近 AI Infra 架构师：在高速飞驰的大模型 「赛车」 上 「换轮子」 的人]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>如果把大模型训练比作 F1 比赛，长凡所在的团队就是造车的人，也是在比赛现场给赛车换轮子的人。1% 的训练提速，或者几秒之差的故障恢复时间，累积起来，都能影响到几百万的成本。长凡说：「大模型起来的时候，我们非常兴奋，因为 DLRover 天生就是为大模型训练的场景设计的。」</p><p>目前业界普遍认为数据、算力、算法是大模型训练的三大核心要素，AI 工程的价值似乎还没有得到足够的重视，我们和蚂蚁 DLRover 开源负责人长凡深入聊了聊，聊到了他为何在大模型出现前就选择了 AI Infra 的赛道，他参与开源的经历，也聊了 DLRover 诞生背后的故事。</p><h1>AI Infra+开源， 一个通信毕业生的非主流选择</h1><p>毕业于盛产程序员的北京邮电大学，虽然本科和研究生专业都是通信相关的，但长凡还是机缘巧合迈入了 AI 的大门，如果你也走在职业发展的路口，或许长凡的故事也能给你带来启发。</p><p><strong>Q：首先请介绍下自己，为什么会选择在蚂蚁做 AI Infra 方面的工作？</strong></p><p><strong>长凡：</strong> 我本科在北交大的理科实验班，研究生在北邮做 5G 移动通信的研究。大四的时候，我去了中国移动研究院实习，做机器学习在医疗领域的应用探索，算是入门了大数据和机器学习。我自己对概率统计和编程也比较感兴趣，发现自己所学的知识可以解决真实问题了。后来在研究生期间，课余时间会打打 Kaggle 比赛，边实践边学习。</p><p>毕业之前我来蚂蚁做暑期实习，做 ML Infra 相关的项目。相比打 Kaggle 用算法解决具体业务问题，Infra 的工作能帮助更多的同学来用 ML 解决更多的问题。再加上蚂蚁在大力发展 AI，我所在的蚂蚁人工智能部有很多 AI 方向的资深技术大拿，所以我毕业后选择了留在蚂蚁。</p><p>ChatGPT 出来后，大模型一下子火了，大模型相比之前的 AI 训练对 Infra 的需求要高得多，对我们做 Infra 的是一个非常大的机遇。大模型训练和推理的成本非常高，Infra 在提升效率和降低成本上大有可为。</p><p><strong>Q：是什么契机让你开始参与开源的？参与开源对你的职业道路产生了哪些影响？</strong></p><p><strong>长凡：</strong> 在蚂蚁工作一年后，我加入到 ElasticDL 团队，跟着王益老师（原百度 <a href="https://www.oschina.net/action/visit/ad?id=1185" title="PaddlePaddle">PaddlePaddle</a> 技术负责人）一起做开源项目。在开发 ElasticDL 过程中，王益老师教会了我很多开源思想、开源工作方式和开发习惯。比如新功能需要先写设计文档，然后拆解成 issue，最后是开发测试；PR 要尽量小，小 PR 可以降低 Review 成本；代码质量需要有工具来保障等等。</p><p>这段经历对我现在做 DLRover 帮助很大。在 DLRover 项目刚启动时，我就在代码仓库了设置了很多代码质量相关的检测，比如 DLRover 的代码 CI 覆盖率约 80%。后来，张科老师接手带领 ElasticDL，一直给我们强调开放合作。这也使得我在主导 DLRover 的开源过程中对架构设计更加开放。这里说的开放不仅仅指使开源的开放代码，更多的是指我们的架构和接口设计的开放，以便让更多的人能进来扩展相关功能满足各自的业务需求。比如，我们的故障机检测功能当前支持 NVIDIA GPU 和 Ascend NPU，如果用户在其他的芯片上训练，可以自定义检测脚本。</p><p><strong>Q：随着大模型的兴起，许多技术人也感受到了前所未有的挑战。作为</strong><strong>AI Infra 领域的架构师</strong><strong>，你如何评估大型模型或 AI 对传统技术架构师的影响？针对当前的技术趋势，你对于这些架构师有哪些建议？</strong></p><p><strong>长凡：</strong> 大模型或者 AI 将会改变我们的产品形态和业务模式，而且很多创新可能都是当前看不到或者很难预料的。作为技术架构师，我们的目标其实很简单，利用技术帮助业务发展。我觉得最好的方式就是从业务中来，到业务中去。比如我们做 AI Infra 的，经常和训练算法同学一起盯着训练作业，review 训练代码并分析训练性能，这样从中发现很多训练对 Infra 的实际需求。然后将这些需求抽象出来，利用自己的技术经验来设计项目解决业务问题。</p><p>随着大模型技术的发展，不管是对计算、存储等硬件领域，还是对训练框架、分布式系统等软件领域，对于 AI Infra 的架构师都有非常大的需求。如果想从事 AI Infra 领域，可以结合自前的经验深入到 AI 应用中去，一定能做出成果。</p><h1>DLRover：发展靠机遇，持续发展靠技术判断力</h1><p>时间拉回到 2022 年 9 月，DLRover 刚刚开源，那时深度学习的训练基本都是在单机多卡上完成的，作为一个分布式训练的智能调度系统，DLRover 的功能似乎有些过于强大，就好像开了一辆百米加速的超跑来上下班。</p><p>DLRover 的容错和弹性扩缩容在单机多卡的训练上几乎没有用武之地，团队也很迷茫是否要针对 GPU 训练做优化，所以当 2022 年底，ChatGPT 在全球引起广泛关注的的时候，大规模分布式训练是大模型训练的刚需，长凡一下子就兴奋了。</p><p><strong>Q：DLRover 是如何诞生的？发展历程中有哪些关键的转折点或者故事？</strong></p><p><strong>长凡：</strong> DLRover 脱胎于蚂蚁内部的一个项目，主要利用容错和弹性扩缩容来提升搜推广训练的速度和资源利用率。2022 年 7 月，该功能上线后，集群资源利用率提升了快一倍，训练时间也缩短了约 20%。基于自动扩缩容，我们就想让用户只写模型代码，系统能自动地将模型在集群上高效、稳定地和经济地训练出来，从而大幅降低分布式训练的门槛和运维成本。基于这个愿景，我们在 2023 年 3 月开源了项目，并取名 DLRover，Rover 代表火星车，我们把 DL 训练作为火星车的乘客，DLRover 这个火星车的目的就是快速、稳定、节能地将 DL 训练这位乘客送到目的地，即训练出模型。</p><p>DLRover 刚开源的时候，发布了 CPU 集群上 TensorFlow 异步分布式训练的自动资源配置与自动扩缩容，该功能可以将算法工程师从作业资源调优上解脱出来。但是发布后社区反响一般，主要原因是搜推广的训练已经比较成熟了，业界也主要在关注 GPU 训练。为此，我们内部也在讨论要不要在 GPU 训练上做点东西。但那时 GPU 训练主要还是 CV 和 NLP 领域，以单机多卡为主，DLRover 的容错和弹性扩缩容好像在单机多卡 GPU 训练上没有用武之地。</p><p>正在我们迷茫时，2023 年初大模型火了。因为 GPU 本身的故障率较高，大规模训练经常因为故障而中断，严重影响了大模型训练的进度和集群的利用率。所以 DLRover 在 2023 年的重点方向就是降低故障对训练的影响。后来，DLRover 针对大规模分布式训练的场景，发布了故障自愈功能，该功能吸引了很多大模型训练的同学，也吸引了很多国产 AI 芯片的公司的关注。</p><p><strong>Q：DLRover 为什么选择开源？</strong></p><p><strong>长凡：</strong> DLRover 面向的用户主要使用的是开源技术，比如 TensorFlow 和 PyTorch 等训练框架，Kubernetes 和 Ray 等分布式集群调度系统。开源可以让我们接触到领域里更多的同行，扩宽我们的视野。当前很多公司都在做 AI 训练，大家面临的场景和问题可能都不一样。通过开源交流，我们可以对 AI 训练所面临的问题与挑战有更全面的了解，社区提出来的问题，未来我们也可能会遇到。我们希望 DLRover 不仅能满足蚂蚁内部大模型训练的需求，也能满足整个社区的普遍需求。</p><p><strong>Q：如果内部需求和社区需求不一致怎么办？</strong></p><p><strong>长凡：</strong> 这其实是开源项目经常会遇到的问题，我觉得首先要有技术判断力，判断这个需求是不是一个普遍需求，公司未来是不是也可能用得到。比如，以前我们认为跑大模型训练大多都用英伟达的 GPU 卡，但现在社区开始提出希望我们适配国产芯片的需求，很多国产芯片的公司也来找我们交流，也就是很多人已经开始在国产芯片上去跑训练了，这就是对我认知的一个刷新。如果我们未来买不到 GPU 了，或者国产芯片能达到更好的效果了，我们已经提前做了国产芯片的支持，那这个需求就可以直接上了。</p><p>现在很多流行的开源项目，以前 Star 数可能是线性增长，在大模型出来之后是指数增长。就是因为他们两年前就觉得这个事情是一个正确的方向，坚持在做，然后机遇一来，他们就起来了。</p><hr><p><strong>Q：开源社区在 DLRover 的发展过程中扮演着怎样的角色？有没有一些特别令你印象深刻的社区贡献者或者故事？</strong></p><p><strong>长凡：</strong> 开源社区给 DLRover 贡献了很多非常好的思路和有价值的需求。比如 DLRover 的 Flash Checkpoint 功能发布后，社区同学的试用帮我们发现了一些没有测试的 corner case，这帮助我们提高了 DLRover 的产品质量。还有，我们最近吸引了很多国产 AI 芯片公司的关注，社区也提出将我们的训练故障自愈扩展到国产芯片的意愿，这些都是来自一线从业同学的真实声音，是我们发展 DLRover 的宝贵源泉和动力。</p><h1>未来展望：帮助用户高效、稳定地训练模型</h1><p>提到对项目未来的规划时，长凡说：「我们希望 DLRover 能帮助用户解决问题，高效、稳定地训练模型。」也希望有更多对 AI 工程感兴趣的开发者能加入到 DLRover 项目，一起推进 AI Infra 领域的发展。</p><p><strong>Q：目前还有哪些项目也在做类似的事情吗？和 DLRover 相比有什么不同？</strong></p><p><strong>长凡：</strong> 分布式训练的弹性容错一直是开源社区在探索的，比如 TorchElastic 和 Elastic Horovod 解决了训练框架的弹性与容错。大模型出来之前，大家训练 NLP 或者 CV 模型主要还是单机或者小规模的集群。小规模训练因为使用的节点少，故障率较低，对弹性容错需求不大。大模型训练一下将训练规模扩大到几百上千卡，故障率就高了很多。同时实际训练中，训练容错和故障自愈需要集群调度、节点管理和训练框架一起协作。所以 DLRover 是将现有的弹性训练框架与节点管理、集群调度相结合来实现快速的训练故障自愈。</p><p>训练自愈这块其实很多云厂商也在做，但是都是和自己的云平台耦合的。最近几个月也有好几篇定会文章介绍相关工作。DLRover 是和云平台解耦的，用户只要是在 kubernetes 集群上做分布式训练，就可以使用 DLRover 的训练故障自愈功能。除此之外，由于我们之前在这块有过探索和积累，所以训练稳定性这块的功能开源得比较快。</p><hr><p><strong>Q：在 AI Infra 领域，海外有哪些做得比较好的开源项目，对于我们有哪些借鉴意义？</strong></p><p><strong>长凡：</strong> Flash Attention 和 vllm，这两个框架大幅提升了大模型训练和推理的性能，更重要的是，用户只需要安装 Python 包即可使用。他们的特点就是利用创新解决了一个很难且很有价值的问题，但是又非常简单易用，这对我们有很大启发。比如，我们在设计 DLRover 训练自愈的 Flash Checkpoint 的 API 时，也是尽量让 API 简单易用，用户尽量少改代码就能使用 DLRover。</p><p><strong>Q：对于 DLRover 未来的规划，你有什么愿景或目标？</strong></p><p><strong>长凡：</strong> 我们希望 DLRover 在大模型时代能让更多的用户高效地训练大模型，降低 AI 训练门槛。当前 AI 训练有 2 个趋势，一方面大家根据 Scaling law 来使用更大规模的集群，来训练越来越大的模型；另一方面很多工作在探索如何在小规模或者单机上微调模型。</p><p>不管是大规模预训练还是微调，高效、稳定地训练模型都有困难，需要根据经验反复调试。我们希望 DLRover 能帮助用户解决这方面的问题，也希望能支持到国内的 AI 发展。DLRover 未来在功能和接口设计上会做得更加开放，让用户能在国产芯片上使用 DLRover 高效、稳定地训练模型。当然，我们也非常欢迎更多的同学加入到 DLRover 社区，一起推进 AI Infra 的前进。</p><p><strong>Q：最后，给我们预告下你在 GDC 上会分享哪些内容吧</strong></p><p><strong>长凡：</strong> GDC 上我将分享 DLRover 如何通过训练故障自愈，来降低大规模 AI 训练的成本，帮训练省钱的。以及大家如何来使用 DLRover 来提升训练的效率。</p><hr><p>看完长凡的经历和 DLRover 的故事，你是不是对 AI Infra 有了更多兴趣呢？3 月 23 日下午，长凡将在 2024 全球开发者先锋大会 (GDC) 分享《DLRover 训练故障自愈：大幅提升大规模 AI 训练的算力效率》，欢迎到现场和讲师近距离交流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dc4d134f36c97587b51d09fd3639c34817e.png" alt="" referrerpolicy="no-referrer"></p><p>关于 DLRover</p><p>DLRover（Distributed Deep Learning System）是蚂蚁集团 AI Infra 团队维护的开源社区，是基于云原生技术打造的智能分布式深度学习系统。DLRover 使得开发人员能够专注于模型架构的设计，而无需处理任何工程方面的细节，例如硬件加速和分布式运行等；开发深度学习训练的相关算法，让训练更高效、智能，例如优化器。目前，DLRover 支持使用 K8s、Ray 进行自动化操作和维护深度学习训练任务。更多 AI Infra 技术请关注 DLRover 项目。</p><p>加入 DLRover 钉钉技术交流群：31525020959</p><p>DLRover Star 一下：<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintelligent-machine-learning%2Fdlrover" target="_blank">https://github.com/intelligent-machine-learning/dlrover</a></em></p><p>在&nbsp;GitHub&nbsp;关注&nbsp;DLRover：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintelligent-machine-learning%2Fdlrover" target="_blank">https://github.com/intelligent-machine-learning/dlrover</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Mar 2024 02:28:21 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/7032067/blog/11048088</guid>
            <link>https://my.oschina.net/u/7032067/blog/11048088</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[20 年编程，AI 编程 6 个月，关于 Copliot 辅助编码工具，你想知道的都在这里]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>AI 代码辅助工具</span></span></span></h1><p><span><span><strong><span>尝试各种辅助编程的 AI 工具</span></strong></span></span></p><p><span><span><span>笔者是一个后端 Coder~，开发工具使用 Idea 和 VsCode。在过去我一直尝试找到一款适合自己的智能代码辅助工具，来告别繁琐的重复性编码，好提高开发效率。直到 AIGC 和 AI Agent 的迅速发展，越来越多的 AI 编码辅助工具百花齐放。宣告天下-生成式编码新赛道的来临。于是开始使用</span></span></span><span><span><strong><span>Github Coplilot、Bito、</span></strong></span></span><span><span><strong><span>Duet AI、CodeWhisperer、</span></strong></span></span><span><span><strong><span>通义灵码/蚂蚁百灵、</span></strong></span></span><span><span><strong><span>Comate、CodeGeeX2 </span></strong></span></span><span><span><span>等不下 10 种的工具。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>AI 生成工具总结：</span></strong></span></span></p><div><table style="width:auto"><tbody><tr><th><span><span><span>产品</span></span></span></th><th><span><span><span>版本</span></span></span></th><th><span><span><span>功能</span></span></span></th><th><span><span><span style="background-color:#ffffff; color:#000000">费用</span></span></span></th><th><span><span><span>链接</span></span></span></th><th><span><span><span>总结</span></span></span></th></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（微软) GitHub Copilot</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">个人/企业</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.代码补全 2.根据注释生成代码 3.创建 SQL 查询 3.代码优化 4.问答 5.单元测试</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">个人版每月$10 企业版每月$19</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.github.com%2Fzh%2Fcopilot%2Fusing-github-copilot%2Fgetting-started-with-github-copilot" target="_blank" rel="nofollow"><span><span><span>官网</span></span></span></a></td><td><span><span><span style="background-color:#ffffff; color:#000000">业界排名第一，最新版代码补全能力遥遥领先，使用</span></span></span><span><span><strong><span>Open AI 的大模型用 Github 库来训练。新版 chat 是 GPT-3.5</span></strong></span></span><span><span><span style="background-color:#ffffff; color:#000000">。只要网络允许绝对首选。 根据 github 统计，96% 的人研发认为可以快速完成重复工作，80% 的研发认为可以提高工作效率。</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（google）Duet AI</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">企业版</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.生成代码 2.生成单测 3.</span></span></span><span><span><span>回答有关 Google Cloud 产品的问题。</span></span></span><span><span><span style="background-color:#ffffff; color:#000000"> 4.代码优化 5.对错误消息进行问题排查</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">每月 $19</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fduet-ai%3F_gl%3D1*keo78j*_up*MQ..%26gclid%3DCjwKCAiA_OetBhAtEiwAPTeQZ_hhyKrqF62wIqOXFSYhnVozDRPiAsvCrE0v66hAeB798nyj9B7VNhoCQ0wQAvD_BwE%26gclsrc%3Daw.ds%26hl%3Dzh-cn%23pricing" target="_blank" rel="nofollow"><span><span><span>官网</span></span></span></a></td><td><span><span><span style="background-color:#ffffff; color:#000000">UE 和响应速度很好，内置的 chat 是 gemini pro。免费用 30 次。 集成了 Google Cloud 和 k8 还有热部署。 bug 的提示修复很厉害。 支持 AI SQL（BigQuery 收费）。有自己的日志中心和 CI/CD。 最厉害的是推出的</span></span></span><span><span><strong><span>AI 告警，和 AI 日志分析</span></strong></span></span><span><span><span style="background-color:#ffffff; color:#000000">。帮助定位和发现生产环境出现的问题。传说内部的 Goose 已经学会 google 技术架构。</span></span></span></td></tr><tr><td><span><span><span>Bito</span></span></span></td><td><span><span><span>免费/收费</span></span></span></td><td><span><span><span>1.生成代码 2.生成单测 3.问答 4.代码优化 5.代码解释 6.代码检查</span></span></span></td><td><span><span><span>收费$15</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbito.ai%2F" target="_blank" rel="nofollow"><span><span><span>官网</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span>号称提高 10 倍开发效率。体感生成速度确实快。 Bito 利用来自 </span></span></span><span><span><strong><span>Open AI、Anthropic </span></strong></span></span><span><span><span>等公司的大模型。（可以理解他用了 GPT 和 Claude 大模型） 亮点是 CodeView 功能。利用 AI agent 实现的。 免费版是 GPT-3.5 Turbo 或谷歌</span></span></span><span><span><span style="background-color:#ffffff; color:#121926">Chat-bison</span></span></span><span><span><span>，chat 和代码补全有限制。付费是 GPT-4 每月 400 个请求。 </span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（AWS）CodeWhisperer</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">个人/企业</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.生成代码 2.生成单测 3.代码安全检查 4.问答</span></span></span></td><td><span><span><span>个人免费，企业版每月$19</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fcodewhisperer%2F" target="_blank" rel="nofollow"><span><span><span>官网</span></span></span></a></td><td><span><span><span style="background-color:#ffffff; color:#000000">UE 工具栏在左侧，内置了 chat，不支持中文。 号称提高</span></span></span><span><span><span>开发</span></span></span><span><span><span style="background-color:#ffffff; color:#000000">速度 28% 代码补全精准度很好，没有废代码。 可以根据中文注释生成，联系上下文写出定义方法。 最 nb 的功能</span></span></span><span><span><strong><span>代码安全检查</span></strong></span></span><span><span><span style="background-color:#ffffff; color:#000000">，免费版每月 50 次，企业版每月 500 次</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（阿里）CodeFuse(蚂蚁百灵) 和通义灵码</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">个人</span></span></span></td><td><span><span><span>1.生成代码 2.生成单测 3.问答 4.代码优化 5.代码解释 6.代码检查</span></span></span></td><td><span><span><span>免费</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftongyi.aliyun.com%2F" target="_blank" rel="nofollow"><span><span><span>通义灵码</span></span></span></a><span><span><span> / </span></span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcodefuse.alipay.com%2F" target="_blank" rel="nofollow"><span><span><span>蚂蚁百灵</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">阿里通义大模型套件。通义灵码来自阿里云，Codefuse 来自蚂蚁集团。 通义灵码基于通义大模型提供行级/函数级实时续写、自然语言生成代码。 Codefuse 基于开源的 DeepSeek 的 33b 模型二开的产品。目前内测中。 通义灵码的配置比较丰富，可以根据使用习惯来定制，补全长度、方式辅助功能等。 现阶段使用上通义灵码优于 Codefuse</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（百度）Comate</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">个人</span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1.生成代码 2.代码解释 3.问答 4.代码优化 5.生成单测</span></span></span></td><td><span><span><span>每月 60</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcomate.baidu.com%2F" target="_blank" rel="nofollow"><span><span><span>官网</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">代码生成：代码模块存在缺失和不完善，如数据预处理未按要求处理。损失函数可视化部分缺失；代码分段输出、注释清晰，首次执行结果： 按提示修改数据集文件地址后，执行第一步数据预处理报错，顺利执行 10% 场景能力：在单次对话中，上下文关联差，多轮对话过程，未能很好结合上下文，后续提问回答，更像是单次提问的百科搜索回答。 其他：提问字数超出限制之后，胡乱输出了我本地 ide 中的代码文件</span></span></span></td></tr><tr><td><span><span><span style="background-color:#ffffff; color:#000000">（清华智谱）CodeGeeX2</span></span></span></td><td><span><span><span>开源</span></span></span></td><td><span><span><span>1.生成代码 2.代码解释 3.问答 4.代码优化</span></span></span></td><td><span><span><span>免费</span></span></span></td><td><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTHUDM%2FCodeGeeX2" target="_blank" rel="nofollow"><span><span><span>官网</span></span></span></a><span><span><span></span></span></span></td><td><span><span><span style="background-color:#ffffff; color:#000000">1、交互较差，补全代码的时候经常补到一半 (到行甚至单词的一部分就停了) 2、理解能力较差，代码不正确 3、代码转换 (不同语言) 能力还可以 4、生成代码接受率低，需要删减</span></span></span></td></tr></tbody></table></div><p><span><span><span>最初我认为不会有太多地方用得上它们。因为大厂都有一套自己的技术体系和技术架构。外部的工具不可能学会，也不会让他们去训练自家的技术。所以我的定位是解决重复性编码的工作。经过六个月的使用后，发现我使用 AI 的方式随着时间的推移在不断变化和改进。</span></span></span></p><p><span><span><span>首先在选择工具时我有一个要求，那就是必须是基于</span></span></span><span><span><strong><span>GPT</span></strong></span></span><span><span><span>。因为在</span></span></span><span><span><span style="color:#333333">代码生成基准测试中，</span></span></span><span><span><span>GPT</span></span></span><span><span><span style="color:#333333">绝对是摇摇领先。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-03-16-286A4dAOifUAQ27tVb.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><div><span><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-21-109DAAKkBqe6JnEij.png" referrerpolicy="no-referrer"></span></div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>当下和</span></span></span><span><span><strong><span>Open AI</span></strong></span></span><span><span><span>合作的名气最大的是</span></span></span><span><span><strong><span>GitHub Copliot</span></strong></span></span><span><span><span>。GitHub Copliot 一直是业界的标杆！在代码补全领域一直是行业第一。新版本也增加了 chat 功能，作为插件在 UE 上也下足了工服，生成单侧，代码优化，代码解释等主流功能一应俱全。一月 10$的价格也是可以接受。</span></span></span></p><p><span><span><span>同时对持学生证或者在 github 活跃项目的维护者提供永久免费。主打一个沉浸式编码！最近也发布了企业版。唯独一点就是要科学上网才能有好的体验。否则生成真的会很慢。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-03-16-38DtUyeZhqExFv09h.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>每每看到 Thinking...就会抓狂！那有没有同样是和 Open AI 合作，且没有网络限制的平替产品呢？ 答案是</span></span></span><span><span><strong><span>Bito</span></strong></span></span><span><span><span>。一个号称提高 10 倍生产力！每天节约 1 小时的产品...</span></span></span></p><p><span><span><span>Bito 在用户本地部署矢量数据库。该数据库会嵌入了 1 万个索引作。该矢量库使用</span></span></span><span><span><span style="background-color:#ffffff; color:#191b1f">embedding（</span></span></span><span><span><span> 超过 1 万个维度的向量</span></span></span><span><span><span style="background-color:#ffffff; color:#191b1f">）</span></span></span><span><span><span>。将代码库中检索文本、函数名称、对象等，转换为多维向量空间存储。</span></span></span></p><p><span><span><span>最后，Bito 利用来自 Open AI、Anthropic 的大模型，也就是说他可以用 GPT 或 Claude 模型。免费版的 chat 使用的 GPT-3.5 Turbo、或者 Google 的 chat-bison、Claude Instant。</span></span></span></p><p><span><span><span>如何安装就不多说了，支持 Jetbrains 和 VsCode 平台。直接看他的功能吧！</span></span></span></p><p><span><span><span>﻿</span></span></span></p><span id="OSC_h1_2"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>Bito</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>1.代码补全：</span></strong></span></span><span><span><span>被动触发，默认快捷键是</span></span></span><span><span><strong><span></span></strong></span></span></p><p><span><span><span>macOS：Option + Shift + K</span></span></span></p><p><span><span><span>Windows：Alt + Shift + K</span></span></span></p><p><span><span><strong><span>2.解释代码：</span></strong></span></span><span><span><span>对于陌生语言很有用</span></span></span></p><p><span><span><span>macOS：Option + Shift + E</span></span></span></p><p><span><span><span>Windows：Alt + Shift + E</span></span></span></p><p><span><span><strong><span>3.生成注释：</span></strong></span></span><span><span><span>生成的方法注释，用的少</span></span></span></p><p><span><span><span>macOS：Option + Shift + V</span></span></span></p><p><span><span><span>Windows：Alt + Shift + V</span></span></span></p><p><span><span><strong><span>4.优化代码：一般没什么用。</span></strong></span></span></p><p><span><span><span>macOS：Option + Shift + Q</span></span></span></p><p><span><span><span>Windows：Alt + Shift + Q</span></span></span></p><p><span><span><strong><span>5.安全检查：</span></strong></span></span><span><span><span>这里主要是找代码漏洞</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-18-083rVVSsHSL3uAerO.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>快捷键 macOS：Option + Shift + Z</span></span></span></p><p><span><span><span>Windows：Alt + Shift + Z</span></span></span></p><p><span><span><strong><span>6.style 检查：</span></strong></span></span><span><span><span>这里的 style 是指代码规范</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-18-07gxMX446tY0IFYnYp.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>快捷键 macOS：Option + Shift + U</span></span></span></p><p><span><span><span>Windows：Alt + Shift + U</span></span></span></p><p><span><span><strong><span>7.是生成单测</span></strong></span></span><span><span><span>。只能单个文件生成。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><span>我用的最多的是 chat，太丝滑了！其次才是代码补全，</span></span></span><span><span><strong><span>看下代码补全的使用场景</span></strong></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>重复性代码补全：</span></strong></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-04-18-37hPLnRnb9pFelsJk.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><strong><span>正则表达式</span></strong></span></span><span><span><span>：</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://503886607-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FYgNBTrPKG0DuVdAyDvSa%2Fuploads%2FuSybqpcFilyfxEoxOA4e%2Fregex_2.gif?alt=media&amp;token=fee783fc-3729-4bf7-81dc-6f9abcfd4141" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>编写 SQL：</span></strong></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://503886607-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FYgNBTrPKG0DuVdAyDvSa%2Fuploads%2FrDSpxXqZchp9wZDhgsm6%2Fsql_1.gif?alt=media&amp;token=39542188-bed6-4966-92c9-5d413c06ce98" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><p><span><span><span>﻿</span></span></span></p><p><span><span><span>在 mapper 可以自动补全 sql 的查询条还能，还一种用法在 chat 里面输入表结构。让 Bito 生成复杂 sql。</span></span></span></p><p><span><span><strong><span>生成实体：</span></strong></span></span><span><span><span>这里不是生成 getter/setter 方法，而是实体赋值或者转换。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-05-15-50bPtsgjBni0HrMyz.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span> 生成代码场景</span></span></span></p><p><span><span><span>Bito 有个很好用的功能，可以自定义 Prompt 模版。我们可以把设计好的提示词添加到模版里用来生成想要的结果。比如定义</span></span></span><span><span><strong><span>sql 生成实体的 Prompt</span></strong></span></span><span><span><span>，定义</span></span></span><span><span><strong><span>生成 Web、RPC 接口的 Prompt</span></strong></span></span><span><span><span>等。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><div><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-06-19-42lZmVoelFDM7pKRu.png" referrerpolicy="no-referrer"></div><p><span style="color:transparent"><span><span><span>﻿</span></span></span></span><span><span><span>﻿</span></span></span></p><div><span><img alt="" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2024-03-06-19-4747s4735C6R47FqNGhRR.png" referrerpolicy="no-referrer"></span></div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>﻿</span></span></span></p><p>&nbsp;</p><span id="OSC_h1_4"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span> 心流</span></span></span></p><p><span><span><strong><span>打造心流领域</span></strong></span></span></p><p><span><span><span style="color:#333333">我们用 AI 代码辅助工具是为了提高我们的</span></span></span><span><span><strong><span>工作效率</span></strong></span></span><span><span><span style="color:#333333">，而不是靠他来生成业务代码。生成业务代码属于「</span></span></span><span><span><span>实时的软件生成」领域的</span></span></span><span><span><span style="color:#333333">（Prompt 编程+低代码）。即使谷歌的 Goose 已经学会了自家的全部技术栈，也不能完全做到需求即交付。因为 AI 需要渗透到整个软件生命周期里，完全标准化后才能达到的预期效果。我理解的提效就是进入「心流」状态。而 AI 辅助工具能帮我做到。</span></span></span></p><p><span><span><span>﻿</span></span></span></p><p><span><span><strong><span>打造个人的</span></strong></span></span><span><span><strong><span>Copliot</span></strong></span></span></p><p><span><span><span style="color:#333333">推荐组合：CodeFuse+Bito+豆包 </span></span></span></p><p><span><span><span style="color:#333333">结对编程组合：</span></span></span><span><span><span>GitHub Copliot 就很够了！适合转型新语言的开发者。</span></span></span></p><p><span><span><span style="color:#333333">打造沉浸式环境：JoyCoder（自家工具</span></span></span><span><span><span>）+Bito。完全辅助，可以彻底告别网络搜索。期待自己家的 JoyCoder 的成长！</span></span></span></p><span id="OSC_h1_5"></span><h1><span><span><span>﻿</span></span></span></h1><div>
  &nbsp; 
</div><p><span><span style="color:transparent"><span><span><span>﻿</span></span></span></span></span><span><span><span>总结</span></span></span></p><p><span><span><span>完全可以提高 20% 的工作效率！如果对 P</span></span></span><span><span><span style="color:#333333">rompt 理解透彻、代码模块化思维能力够强，</span></span></span><span><span><span>愿意花时间调整工作流程的话，</span></span></span><span><span><span style="color:#333333">还会提高的更多！</span></span></span></p><p><span><span><span style="color:#333333">如果这篇文章带给大家一些收获，不妨点赞、收藏。下次会介绍更好玩的产品。</span></span></span></p><p><img height="396" src="https://oscimg.oschina.net/oscnet/up-1fe741836aaf93527c65cbe2a65e4ffa9ff.png" width="396" referrerpolicy="no-referrer"></p><p>&nbsp; &nbsp;扫一扫，与作者技术交流一下吧</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 18 Mar 2024 09:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/11047919</guid>
            <link>https://my.oschina.net/u/4090830/blog/11047919</link>
            <author>
                <![CDATA[京东云开发者]]>
            </author>
        </item>
    </channel>
</rss>
