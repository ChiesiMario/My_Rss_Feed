<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 30 Jan 2024 03:39:43 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[RHEL 源码访问限制影响 CentOS SIG]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">去年 6 月，红帽发布公告<a href="https://www.oschina.net/news/246331/red-hat-centos-stream-sources">宣布</a>了一个限制 Red Hat Enterprise Linux (RHEL)&nbsp; 源代码访问性的政策。时至今日，这一变更似乎无意中给 CentOS Integration&nbsp;Special&nbsp;Interest&nbsp;Group (&nbsp;(SIG) 小组带来了一些麻烦。</span></p><p><span style="color:#000000">Kmods SIG 旨在为 CentOS Stream 和 Red Hat Enterprise Linux 维护额外内核模块。CentOS 博客上周<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.centos.org%2F2024%2F01%2Fjanuary-2024-news%2F" target="_blank">发布</a>了 Kmods SIG 的最新状态，其中一项值得注意的内容是：</span></p><blockquote><p>由于 Red Hat 发布 Red Hat Enterprise Linux 源代码的方式发生了变化，Kmods SIG 目前由于法律原因无法为 Red Hat Enterprise Linux 制作软件包。我们正与 Red Hat 合作解决这一问题，并希望能尽快再次为企业 Linux 提供软件包。</p></blockquote><p><img height="304" src="https://oscimg.oschina.net/oscnet/up-05fcfbc3e8c1312848b6f99d2e074ce2339.png" width="500" referrerpolicy="no-referrer"></p><p>此外，CentOS Hyperscale SIG 在 2023 年第四季度报告中<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.centos.org%2F2024%2F01%2Fcentos-hyperscale-sig-quarterly-report-for-2023q4%2F" target="_blank">表示</a>：</p><blockquote><p><span style="color:#020008">Hyperscale SIG 的最新版本是 CentOS Stream 9 的内核 6.7.1-0.hs1。这个新内核现在基于上游 Fedora 版本内核，而不是 CentOS/RHEL 内核树。在可预见的未来，Hyperscale SIG 将跟踪 Fedora 内核以构建并发布到 CentOS 中。内核仍然采用类似 RHEL 的配置构建，专门针对 CentOS Hyperscale 进行 modulo 更改。</span></p><p><span style="color:#020008">随着&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.centos.org%2F2023%2F04%2Fend-dates-are-coming-for-centos-stream-8-and-centos-linux-7%2F" target="_blank">EOL</a>&nbsp;<span style="color:#020008">的临近，CentOS Stream 8 的内核已停止使用，并且没有计划围绕 CentOS Stream 8 进行进一步的工作。</span></p></blockquote><p><span style="background-color:#ffffff; color:#333333">Hyperscalers SIG 由 Facebook 和 Twitter 等科技公司倡议<a href="https://www.oschina.net/news/126467/centos-hyperscale-sig">成立</a>，致力于在大型基础架构上（如 Facebook、Twitter 和云服务提供商等其他 "hyperscaler" 组织）启用 CentOS Stream 部署，并促进软件包和工具上的协作。&nbsp;</span>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 03:24:39 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276886/centos-rhel-kmods-sig</guid>
            <link>https://www.oschina.net/news/276886/centos-rhel-kmods-sig</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[工信部等七部门联合发文：发展下一代操作系统、推广开源技术、构建开源生态体系]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>工业和信息化部、教育部、科技部、交通运输部、文化和旅游部、国务院国资委、中国科学院等七部门近日联合印发<em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gov.cn%2Fzhengce%2Fzhengceku%2F202401%2Fcontent_6929021.htm" target="_blank">《<u>关于推动未来产业创新发展的实施意见</u>》</a></em>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-77dbe7b14ccd70bf436e9b444bcb994dcdd.png" referrerpolicy="no-referrer"></p><p>其中提到的重点任务包括：</p><ul><li><strong>（一）全面布局未来产业</strong></li><li><strong>（二）加快技术创新和产业化</strong></li><li><strong>（三）打造标志性产品</strong></li><li><strong>（四）壮大产业主体</strong></li><li><strong>（五）丰富应用场景</strong></li><li><strong>（六）优化产业支撑体系</strong></li></ul><p>在「打造标志性产品」章节，意见提出要<strong>做优信息服务产品</strong>：</p><p><strong>发展下一代操作系统，构筑安全可靠的数字底座。推广开源技术，建设开源社区，构建开源生态体系</strong>。探索以区块链为核心技术、以数据为关键要素，构建下一代互联网创新应用和数字化生态。面向新一代移动信息网络、类脑智能等加快软件产品研发，鼓励新产品示范应用，激发信息服务潜能。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d3c823b6016f70ba58bb95c2ae81c353cce.png" referrerpolicy="no-referrer"></p><p>原文：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FN9YYFWtcrNfAX1TYqY7G1A" target="_blank">https://mp.weixin.qq.com/s/N9YYFWtcrNfAX1TYqY7G1A</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 03:01:50 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276882</guid>
            <link>https://www.oschina.net/news/276882</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CodeIgniter 社区 2023 年终总结]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>随着我们步入 2024 年，我想借此机会总结过去一年 CodeIgniter 社区所取得的成果，并对所有贡献者的努力表示感谢。CodeIgniter 作为一个社区驱动的项目，每一位贡献者都在促进着我们的发展。</p><p>因为所有工作都是由志愿者完成的，所以贡献者的参与度会因他们的空余时间、工作以及其他生活琐事而有所变动。今年，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.codeigniter.com%2Fmember.php%3Faction%3Dprofile%26uid%3D90" target="_blank">@kenjis</a> 的突出贡献让人印象深刻，他们在主要的代码仓库和论坛上的辛勤耕耘让整个项目有了质的飞跃。</p><p>以下是一些数据，以侧面展示了我们在 2023 年的活跃程度：</p><ul><li>我们发布了 15 个核心框架版本</li><li>我们的身份验证系统 Shield 发布了 6 个测试版，并在年底前推出了 1.0 的正式版</li><li>推出了两个新的库 - Tasks 和 Queue，虽然还处于 Alpha 阶段，但正朝着第一个正式版稳步前进。他们本身是 CodeIgniter 构建出色软件所需的最后几个关键模块，所以我对他们极其期待。</li><li>我们为 Settings、Shield、Tasks 和 Queue 库新建了文档站点</li></ul><p>如果只看我们的核心框架，我们在过去一年内取得的成果包括：</p><ul><li>每月平均新增两名贡献者</li><li>全年共新增了 26 名新贡献者</li><li>每月平均有 11 名活跃的贡献者</li><li>新贡献者占提交者的 18%</li><li>每月平均有 203 次代码提交</li><li>平均每名提交者每月提交代码 18.45 次</li><li>提交者总数增加了 26 人（从 350 增加到 376）</li><li>平均每月合并 54 个 PR 请求</li></ul><p>这是一份令人印象深刻的成绩单。除此之外，我们还在进行持续的翻译工作，修复了一些严重的安全漏洞，以及将代码质量管理工作做得更加精细，确保无论贡献者数量如何增长，我们都能保持高质量的代码输出。</p><p>我要向今年所有做出贡献的人表示感谢，无论是贡献代码、编写文档还是在论坛上帮助他人。正是你们让这个项目保持了活力。</p><p><strong>那么，CodeIgniter 未来会有什么新变化呢？</strong></p><p>我们正在开发一款全新的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flonnieezell%2Fforum-example" target="_blank">论坛软件</a>，这款软件完全基于 CodeIgniter 构建。这款软件的目标是提供一种符合现代审美，而又为这个社区定制的论坛体验，展示 CodeIgniter 的可能性。它将使用 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftailwindcss.com%2F" target="_blank">TailwindCSS</a>、<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falpinejs.dev%2F" target="_blank">AlpineJS</a> 和 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhtmx.org%2F" target="_blank">HTMX</a>，以提供快速、现代的用户体验。目前我们的团队还在积极开发阶段，如果你愿意加入，我们会很欢迎。</p><p>虽然我不能代表所有团队成员的观点，但是在我看来，我想尝试让 CodeIgniter 的使用更加简化。这是一个宏大主题，但我相信我们很快能就此取得一些进展。</p><p>首先，我们打算简化代码库的贡献过程，让任何有意愿的人都能从自己的电脑开始更便捷地参与进来。虽然现在还没有确定的消息可以公布，但我们希望这样，更多的开发者会愿意加入我们。</p><p>接下来，我们关注用户指南。我们在尝试不丢失任何内容的情况下，将其<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcodeigniter4%2Fdocs-update" target="_blank">转换为 Markdown 格式</a>，并取得了非常好的进展。我们希望 Markdown 语言的易用性，能让更多的贡献者参与其中。这样，我们的文档就能保持统一的格式和风格，让项目页面显得更加整齐一致。实际上，我们的库已经实现了这一点，核心框架是最后一个待处理的问题。</p><p>我还有其它的一些想法，比如关于 API 和本地化的问题，但是这需要在我完成其它项目后，看我能投入多少时间来做。</p><p>所以，我要再次感谢我们的核心团队、论坛的版主和所有为这个社区做出贡献的你们。期待今年我们能有更好的发展！</p><hr><p>原文作者: kilishan<br> 原文链接: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.codeigniter.com%2Fshowthread.php%3Ftid%3D89075" target="_blank">https://forum.codeigniter.com/showthread.php?tid=89075</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:44:50 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276880/codeigniter-2023</guid>
            <link>https://www.oschina.net/news/276880/codeigniter-2023</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[上海 AI 实验室发布新一代书生·视觉大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>上海人工智能实验室（上海 AI 实验室）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbdfAJRqOF9tUk8Vy9KC_XQ" target="_blank">宣布</a>联合清华大学、香港中文大学、商汤科技等机构开源新一代书生·视觉大模型（InternVL）。</p><p>新一代「书生·视觉基础」模型的视觉编码器参数量达 60 亿 (InternVL-6B)，首次提出了对比-生成融合的渐进式对齐技术，实现了在互联网级别数据上视觉大模型与语言大模型的精细对齐。</p><p>InternVL-6B 不仅能处理复杂图片中细微的视觉信息并完成图生文任务，还可以识别和解读复杂页面中的信息，甚至解决其中的数理问题。</p><p>目前，InternVL 全系列模型、代码均已开源，并提供 Demo 试用。</p><ul><li>开源链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenGVLab%2FInternVL" target="_blank">https://github.com/OpenGVLab/InternVL</a></li><li>论文链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.14238" target="_blank">https://arxiv.org/abs/2312.14238</a></li><li>试用 Demo：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finternvl.opengvlab.com" target="_blank">https://internvl.opengvlab.com</a></li></ul><p>InternVL-6B 具备纯视觉感知、图文检索、图文生成、图文多模态生成和对话等关键能力。谷歌 ViT-22B 是目前被公认为最强大的专注视觉的基础模型（非开源）。InternVL 开源模型以不到 1/3 的参数量，在纯视觉任务（如 ImageNet、ADE20K 等）和图生文任务（如 NoCaps、MS COCO 等）上逼近或超过谷歌 ViT-22B。</p><p><img alt="" height="435" src="https://oscimg.oschina.net/oscnet/up-f94fea8f6165e351f12396a1f5f9a393f7c.png" width="500" referrerpolicy="no-referrer"></p><p>在视觉感知、图文检索、图文多模态生成和对话等 30 余个视觉基准测试上，InternVL-6B 取得了开源社区的最优性能，超过了 Meta、谷歌、微软、LAION 等机构的同类开源模型。</p><p><img alt="" height="669" src="https://oscimg.oschina.net/oscnet/up-5d454993d286bc955eddcb7f961048b6440.png" width="300" referrerpolicy="no-referrer"></p><p>在 TinyLVLM 、MMBench 等多模态大模型评测上，InternVL-6B 取得了优秀的性能。其中，在 MMBench-dev 上，InternVL-6B 达到 76.6，虽然综合能力仍有待提高，但个别性能超越了 GPT-4V（75.1）和 Gemini（75.2）。</p><p>InternVL-6B 具备强大的视觉表征和理解能力，尤其表现在面对信息复杂的图片时，模型仍可对细节进行精准捕捉，不仅可在图片或实际场景的复杂画面中捕捉细微的视觉信息，还可从复杂排版的图文页面中整合、解读信息，或辨别伪装外观的物体。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:35:50 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276879</guid>
            <link>https://www.oschina.net/news/276879</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥🔥 mac 中使用 rz sz 新姿势 🔥🔥]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>macOS 使用 zmodem ( rz / sz ) 的新方法，支持 iTerm2 等任意有本地 shell 的终端</h2><h3><strong>1、本地安装<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">trzsz-ssh ( tssh )</a></strong></h3><ul><li>开源地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">https://<span>github.com/trzsz/trzsz-ssh</span></a></li><li><span>Gitee 地址：</span><a href="https://gitee.com/trzsz/tssh">https://gitee.com/trzsz/tssh</a></li></ul><div><pre><code class="language-text">brew install trzsz-ssh</code></pre></div><h3>2、本地安装 lrzsz</h3><div><pre><code class="language-text">brew install lrzsz</code></pre></div><h3>3、配置 ~/.ssh/config</h3><div><pre><code class="language-text">Host *
    #!! EnableZmodem Yes</code></pre></div><h3>4、使用<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">trzsz-ssh ( tssh )</a><span>&nbsp;</span>登录服务器，用法与 ssh 完全一致：</h3><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftrzsz%2Ftrzsz-ssh" target="_blank">trzsz-ssh ( tssh )</a><span>&nbsp;</span>额外支持的功能详见文档：<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftrzsz.github.io%2Fcn%2Fssh" target="_blank">https://<span>trzsz.github.io/cn/ssh</span></a></li></ul><div><pre><code class="language-text">tssh xxx</code></pre></div><h3>5、服务器上安装有 lrzsz ，就可以正常使用 rz / sz 了，不再赘述：</h3><div><pre><code class="language-text">rz # 上传文件
sz xxx # 下载文件</code></pre></div><h3>6、如果服务器可以安装 trzsz ( trz / tsz )，则可以解锁更多功能：</h3><ul><li>详见文档：<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftrzsz.github.io%2Fcn%2F" target="_blank">https://<span>trzsz.github.io/cn/</span></a></li></ul><div><pre><code class="language-text">trz # 等价于 rz
tsz xxx # 等价于 sz xxx</code></pre></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276878</guid>
            <link>https://www.oschina.net/news/276878</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Meta 发布全新代码生成大模型 Code Llama 70B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Meta 今天发布了全新的代码生成大模型 Code Llama 70B。据称其 HumanEval 评分达到 67.8，达到 GPT-4 水准，是目前评分最高的开源大模型。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aa28c3b26f59dc762db43f6ffcd3091ca27.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FAIatMeta%2Fstatus%2F1752013879532782075" target="_blank">https://twitter.com/AIatMeta/status/1752013879532782075</a></u></em></p></blockquote><p>Code Llama 70B 是此前 <strong><u><a href="https://www.oschina.net/news/255350/meta-code-llama">Code Llama </a></u></strong>的升级版本，包括三个模型：</p><ul><li>CodeLlama-70B</li><li>CodeLlama-70B-Python</li><li>CodeLlama-70B-Instruct</li></ul><p><strong>开源地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcodellama%2FCodeLlama-70b-hf" target="_blank">https://huggingface.co/codellama/CodeLlama-70b-hf</a></u></em></strong></p><p>Code Llama 以 Llama 2 为基础，可以帮助开发者根据提示创建代码，并调试人工编写的代码。</p><p>Meta 表示，Code Llama 70B 性能更高，可以处理更多的内容，更好地帮助开发者处理编程时遇到的问题。此外，Code Llama 70B 采用了与 Llama 2 和 Code Llama 相同的 License，可用于研究和商业用途。</p><p>扎克伯格<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.facebook.com%2Fzuck%2Fposts%2Fpfbid0KccyDFLszKeHkWVssrcSJYnigb1VYfsLuExTjxVPKWzDpXgmd9FYMfZ1hcWpyf3Zl" target="_blank">表示</a></u>：「编写代码能力对于 AI 模型更严谨、更合理地处理其他领域的信息也非常重要。我为这里取得的进展感到自豪，并期待着将这些进展纳入 Llama 3 和未来的模型中。」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-02e72478e15d47689552ffc6fd15bb220af.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:27:50 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276877/meta-code-llama-70b</guid>
            <link>https://www.oschina.net/news/276877/meta-code-llama-70b</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RWKV-5-World 7B 模型开源——最环保、最节能的 AI 模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2024 年 1 月 28 日，RWKV 开源基金会<strong><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4hTFA2CMcInhGLZTqa_H4g" target="_blank">宣布</a></u></strong>开源 RWKV-5-World 7B 模型。</p><p>据介绍，「RWKV-5-World 7B」是 RWKV 第五代架构 7B 参数大模型，也是 RWKV 迄今为止多语言性能最强的开源大模型。根据性能评测数据显示，在 100% attention-free 和只训练 1.1T tokens 的前提下，RWKV-5 7B 模型的多语言性能超过 Mistral，英文性能看齐 LlaMa2。</p><h3><strong>RWKV 模型介绍</strong></h3><p>RWKV 是一种创新的深度学习网络架构，它将 Transformer 与 RNN 各自的优点相结合，同时实现高度并行化训练与高效推理，时间复杂度为线性复杂度，在长序列推理场景下具有优于 Transformer 的性能潜力。</p><p>RWKV-v5 架构模型能力指标接近 Llama2，但推理成本降低 2~10 倍，训练成本降低 2~3 倍。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8b124ce111f66fc29349dc3550fae0e963d.png" referrerpolicy="no-referrer"></p><p>如上图所示，对比 RWKV-v4 架构，在使用相同训练数据集的情况下，RWKV-v5 的多语言能力大幅提升，整体提升约 4%。而对比其他同为 7B 参数的模型，RWKV-5 7B 的多语言表现亦处于领先地位。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b4a1c53e39044930c57fdeb0099eda5ea3d.png" referrerpolicy="no-referrer"></p><p>官方介绍称，在相同参数大小（7B）的模型独立基准测试中，RWKV 是世界上最环保、最节能的人工智能模型/架构（以每个 token 输出为基础）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-3d734a934d678a080b7392fed400e7c9c3a.png" referrerpolicy="no-referrer"><br> 测试地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fml.energy%2Fleaderboard%2F" target="_blank">https://ml.energy/leaderboard/</a></u></em></p><p>RWKV 架构的能源效率源自线性 Transformer 架构的 2~10 倍计算效率与 Transformer 架构的二次缩放。随着模型规模的扩大，RWKV 架构的节能特性会越发明显。</p><p><img src="https://oscimg.oschina.net/oscnet/up-38b5e2a74f34b88918058aa8e911bf3c62b.png" referrerpolicy="no-referrer"></p><h3><strong>下载&amp;试玩 RWKV-5-World 7B</strong></h3><p><strong>RWKV-5-World 7B 模型在线 Demo：</strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2" target="_blank">https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2</a></p><p><strong>RWKV-5-World 7B 模型下载地址：</strong></p><ul><li><p><strong>Hugging Face</strong>:<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-5-world%2Fblob%2Fmain%2FRWKV-5-World-7B-v2-20240128-ctx4096.pth" target="_blank">https://huggingface.co/BlinkDL/rwkv-5-world/blob/main/RWKV-5-World-7B-v2-20240128-ctx4096.pth</a></p></li><li><p><strong>wisemodel</strong>:<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-5-World-7B-v2%2Ffile" target="_blank">https://wisemodel.cn/models/rwkv4fun/RWKV-5-World-7B-v2/file</a></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 02:08:50 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276876/rwkv-5-world-7b-opensource</guid>
            <link>https://www.oschina.net/news/276876/rwkv-5-world-7b-opensource</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[腾讯 APIJSON 插件 apijson-mongodb 开源，支持文档数据库 MongoDB]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img height="1570" src="https://oscimg.oschina.net/oscnet/up-bdaf900bde612e78f2a7ac5ec7f7dda180c.png" width="2202" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">腾讯 APIJSON 是一种专为 API 而生的 JSON 网络传输协议，以及，基于这套协议实现的 ORM 库。<br><strong>为各种增删改查提供了完全自动化的万能 API，零代码实时满足千变万化的各种新增和变更需求。</strong><br> 能大幅降低开发和沟通成本，简化开发流程，缩短开发周期。适合中小型前后端分离的项目。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>自 2016 年开源 7 年来发展迅速，目前 16K+ Star 位居 400W Java 开源项目前 100。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>国内，腾讯、华为、阿里巴巴、字节跳动、美团、拼多多、百度、京东、网易、快手、圆通，等 和<br> 国外 Google, Apple, Microsoft, Amazon, Tesla, Meta(FB), Paypal 等数百个知名大厂员工 Star，<br> 也有，腾讯、华为、字节跳动、Microsoft、Zoom、知乎，等 工程师/专家/架构师，提了 PR/Issue，<br> 还被，腾讯、华为、百度、SHEIN、快手、中兴、传音、圆通、美图，等各大知名厂商用于各类项目。</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="1352" src="https://oscimg.oschina.net/oscnet/up-05507add1ab73979181e2a721832b2ef017.png" width="1850" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="1344" src="https://oscimg.oschina.net/oscnet/up-b0118180bc641918130cef0f4dee2bf1ca1.png" width="1634" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h1>apijson-mongodb<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjitpack.io%2F%23APIJSON%2Fapijson-mongodb" target="_blank"><img alt="" src="https://camo.githubusercontent.com/f9608d575b9afc54743bb783cab0dd73e97b3b37a696f11e0494caa137b72f24/68747470733a2f2f6a69747061636b2e696f2f762f4150494a534f4e2f6170696a736f6e2d6d6f6e676f64622e737667" referrerpolicy="no-referrer"></a></h1><p style="color:#1f2328; text-align:start">腾讯<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent%2FAPIJSON" target="_blank">APIJSON</a><span>&nbsp;</span>的 MongoDB 数据库插件，可通过 Maven, Gradle 等远程依赖。</p><p style="color:#1f2328; text-align:start"><img height="709" src="https://oscimg.oschina.net/oscnet/up-7e4aaaf91ea988480d31e94d5def25b75de.png" width="1280" referrerpolicy="no-referrer"></p><h2>添加依赖</h2><h4>1. 在 pom.xml 中添加 JitPack 仓库</h4><div><pre>&lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">repositories</span>&gt;
&lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">repository</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">id</span>&gt;jitpack.io&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">id</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">url</span>&gt;https://jitpack.io&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">url</span>&gt;
&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">repository</span>&gt;
&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">repositories</span>&gt;
</pre></div><h4>2. 在 pom.xml 中添加 apijson-mongodb 依赖</h4><div><pre>&lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">dependency</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">groupId</span>&gt;com.github.APIJSON&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">groupId</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">artifactId</span>&gt;apijson-mongodb&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">artifactId</span>&gt;
    &lt;<span style="color:var(--color-prettylights-syntax-entity-tag)">version</span>&gt;LATEST&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">version</span>&gt;
&lt;/<span style="color:var(--color-prettylights-syntax-entity-tag)">dependency</span>&gt;

</pre></div><h3>使用</h3><p style="color:#1f2328; text-align:start">在你项目继承 AbstractSQLExecutor 的子类重写方法 getValue<br> Override getValue in your SQLExecutor extends AbstractSQLExecutor</p><div><pre><span style="color:var(--color-prettylights-syntax-constant)">@</span><span style="color:var(--color-prettylights-syntax-constant)">Override</span><span style="color:var(--color-prettylights-syntax-keyword)">protected</span><span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Object</span><span>getValue</span>(<span style="color:var(--color-prettylights-syntax-storage-modifier-import)">SQLConfig</span>&lt;<span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Long</span>&gt; <span>config</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">ResultSet</span><span>rs</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">ResultSetMetaData</span><span>rsmd</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">int</span><span>tablePosition</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">JSONObject</span><span>table</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">int</span><span>columnIndex</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">String</span><span>lable</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Map</span>&lt;<span style="color:var(--color-prettylights-syntax-storage-modifier-import)">String</span>, <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">JSONObject</span>&gt; <span>childMap</span>) <span style="color:var(--color-prettylights-syntax-keyword)">throws</span><span>Exception</span> {
            <span style="color:var(--color-prettylights-syntax-storage-modifier-import)">Object</span><span>v</span> = <span style="color:var(--color-prettylights-syntax-entity)">super</span>.<span style="color:var(--color-prettylights-syntax-entity)">getValue</span>(<span>config</span>, <span>rs</span>, <span>rsmd</span>, <span>tablePosition</span>, <span>table</span>, <span>columnIndex</span>, <span>lable</span>, <span>childMap</span>);
            <span style="color:var(--color-prettylights-syntax-keyword)">return</span><span style="color:var(--color-prettylights-syntax-storage-modifier-import)">MongoUtil</span>.<span style="color:var(--color-prettylights-syntax-entity)">getValue</span>(<span>v</span>);
        }</pre><div><br> &nbsp;
 </div></div><p style="color:#1f2328; text-align:start">有问题可以去 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent%2FAPIJSON" target="_blank">Tencent/APIJSON</a> 提 issue<br> &nbsp;</p><h4>创作不易，右上角点亮 ⭐Star 支持/收藏下吧，谢谢 ^_^</h4><p style="color:#1f2328; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAPIJSON%2Fapijson-mongodb" target="_blank">https://github.com/APIJSON/apijson-mongodb</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 01:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276875</guid>
            <link>https://www.oschina.net/news/276875</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openKylin 2.0 揭秘 | 新一代不可变系统的设计与实现]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">在<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg2MDc5MDU1OQ%3D%3D%26mid%3D2247494992%26idx%3D1%26sn%3D996588c684d59a85aea52eb371570323%26chksm%3Dce23a720f9542e36dbaba5c747475834862a800a0843c5ab55f562b1ff15f8d0364ad4690f5b%26scene%3D21%23wechat_redirect" target="_blank">之前文章</a>中，我们向大家揭秘了什么是不可变系统以及不可变系统相较于传统操作系统具有哪些优势。今天我们继续向大家深入揭秘 openKylin 不可变系统的特性具体是如何设计和实现的！</span></p><p style="text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-ba9965c58fe2a7a291437acb42d33cd74c1.png" width="940" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff"><span>UpdateManager SIG 基于 OSTree 技术为原生 openKylin 操作系统设计并实现了不可变操作系统特性，同时，为尽可能保障在安装、启动、UI 界面和用户操作等方面与传统操作系统保持一致，还在</span>文件系统结构<span>、安装方式、启动流程、版本控制方式和版本存储库等特性方面进行了针对 OSTree 技术特点的设计改造。具体如下：</span></span></p><p>&nbsp;</p><p>0<span>1</span><strong>文件系统结构</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">openKylin 不可变系统的目录结构与传统 Linux 发行版相比有一些不同，主要体现在采用 OSTree 管理文件系统版本、强调不可变系统的特性以及将用户程序和数据都视为不可变的。这些设计使得其在系统稳定性和可靠性方面有所提升。具体实现如下：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/usr</span></strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">&nbsp;/usr 及其下面的所有内容都是只读的。</span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/usr</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/bin&nbsp;→&nbsp;/usr/bin</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/lib&nbsp;→&nbsp;/usr/lib</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/lib64&nbsp;→&nbsp;/usr/lib64</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/sbin&nbsp;→&nbsp;/usr/sbin</span></p></li></ul><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/var</span></strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff"><span>系统运行时状态的存储位置。/var 目录是用于存储</span>可变数据<span>的位置，包括各种应用程序的文件、日志、缓存和运行时数据。同时将/home 和/root 目录，存放至 data 分区 /media -&gt; var/run/media。</span></span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/mnt&nbsp;-&gt;&nbsp;var/mnt</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/opt&nbsp;-&gt;&nbsp;var/opt</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/root&nbsp;-&gt;&nbsp;data/root&nbsp;</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/home-&gt;data/home</span></p></li><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">/srv&nbsp;-&gt;&nbsp;var/srv</span></p></li></ul><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/sysroot</span></strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">文件系统根目录，类似于传统 Linux 中的/目录，使用/sysroot 作为其文件系统的根目录，与传统 Linux 发行版中的/目录有所不同。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><strong><span style="background-color:#ffffff">➢&nbsp;/ostree</span></strong></p><p><span style="background-color:#ffffff">sysroot/ostree 目录是基于 OSTree 技术的系统根文件系统的存储位置，其中的 repo 目录存储了 OSTree 的版本控制数据库，deploy 目录存储了不同版本的系统根文件系统部署。这种机制使得系统可以进行整体的不可变性管理和更新。</span></p><p>&nbsp;</p><p>0<span>2</span><strong>系统安装</strong></p><p><span style="background-color:#ffffff">openKylin 不可变系统的安装过程与传统操作系统相似，在安装时，用户可在安装界面勾选不可变系统安装，即可实现不可变系统的安装。在安装完成后，安装器调用 OStree CLI 实现不可变系统的初始化、&nbsp;仓库创建、分支提交等动作。</span></p><p>&nbsp;</p><p>0<span>3</span><strong>系统启动</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff"><span>OSTree 在/ostree 目录下安装部署，但最终还是要控制系统的/boot 目录。这种方式是通过</span>Boot Loader<span>来实现的。当部署一个分支时，会生成/boot/loader/entries/ostree-1-</span></span></p><p><span style="background-color:#ffffff"><span>openkylin.conf 的配置文件，该配置文件中将包含一个内核参数和一个</span><span>initrd</span><span><span>参数，允许 initramfs 找到指定的部署。最后 OStree 会更新/boot/grub/grub.</span>cfg 文件<span>，引导系统启动。</span></span></span></p><p>&nbsp;</p><p>0<span>4</span><strong>版本控制</strong></p><p><span style="background-color:#ffffff">OSTree 使用版本控制技术来管理系统的文件系统。它将文件系统的每个版本都存储为一个只读快照（snapshot），并通过分支（branch）的方式跟踪和管理不同的版本。这样，系统的每个更新都是事务性的，可以轻松进行回滚操作。</span></p><p>&nbsp;</p><p>0<span>5</span><strong>存储库管理</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">OSTree 使用存储库来存储系统的版本控制数据，存储库中包含了系统的不同分支和快照，以及与版本控制相关的元数据。通过存储库，系统管理员可以方便地管理和维护系统的版本。</span></p><p><span style="background-color:#ffffff">通过上述改造和设计，OSTree 实现了不可变系统的特性，提供了一种可靠、稳定的系统更新和管理机制。它改变了传统系统的文件系统结构、启动、版本管理和更新方式，为系统提供了更好的可信度、可靠性和维护性。</span></p><p>&nbsp;</p><p>0<span>6</span><strong>关于 UpdateManager SIG</strong></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff">openKylin 社区 UpdateManager SIG 小组，致力于新一代操作系统不可变系统相关技术研发，包括系统架构、OStree、系统更新组件等，提供不可变系统相关的技术规划、设计、开发、维护和系统升级等服务。openKylin 基于 OStree 的不可变系统将成为数字化未来的重要引领者，为用户带来更加稳定、安全和高效的数字化体验。</span></p><ul><li><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">SIG 主页：</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span style="color:#0b43d1">https://gitee.com/openkylin/community/tree/master/sig/UpdateManager</span></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 30 Jan 2024 01:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276872</guid>
            <link>https://www.oschina.net/news/276872</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><p><strong># 2024.1.29&nbsp;</strong></p><h2><span><span><span style="color:#000000"><span><span><span style="color:#00b050">今日要点</span></span></span></span></span></span></h2><p style="text-align:justify"><strong>OpenSource Daily</strong></p><h3><u><a href="https://www.oschina.net/news/276738/search-with-lepton-opensource" target="news">贾扬清最新开源项目 —— 500 行代码构建的 AI 搜索工具</a></u></h3><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#595959">贾扬清前几天在社交平台介绍了自己开发的 AI 应用 Lepton Search —— 一个用 500 行 Python 代码构建的对话式 AI 搜索工具</span></span></span><span><span><span style="color:#595959">。</span></span></span><span><span><span style="color:#595959">Lepton Search 的后端是 Mixtral-8x7b 模型，托管在 LeptonAI，输出速度能达到每秒大约 200 个 token，搜索引擎采用了 Bing 的搜索 API。</span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span style="color:#595959">目前 Lepton Search 已正式开源，包含完整前后端源代码，采用 Apache License，可商用。</span></span></span></span></span></p><p><img src="https://oscimg.oschina.net/oscnet/up-653f2a2bd37324fb0d75d8ceb45ba2c5187.png" referrerpolicy="no-referrer"></p><h3><u><a href="https://www.oschina.net/news/276824/16-bit-cpu-built-and-runs-in-excel" target="news">大神只用 Excel 就构建了一颗 CPU：具有 128kb RAM、配备汇编语言</a></u></h3><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#595959">YouTube 科技博主「Inkbox」近日发布视频介绍如何在 Microsoft Excel 的限制下构建功能齐全 CPU。Inkbox 称没有使用任何 Visual Basic 脚本或插件 —— 完全用 Excel 实现。</span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#595959">据介绍，这是一颗 16 位 CPU，在 Excel 中构建并以 3Hz 时钟频率运行，具有 128KB RAM、16 色 128x128 像素显示屏和自定义汇编语言，所有这些都在 Excel 中运行</span></span></span><span><span><span style="color:#595959">。</span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-05bafb20ee50b854fae8d35fd3dd39d81d6.png" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="color:#595959">这个 Excel CPU 项目最令人印象深刻的壮举之一是 Inkbox 为其创建了功能完整的汇编语言 Excel-ASM16，它包含 23 种不同的指令，并支持变量、标签，甚至二进制文件。虽然这些是汇编语言的基本功能，但对于在 Microsoft Excel 下运行的 16 位 CPU 的限制来说已经足够了。</span></span></span></span></span></p><h3><u><a href="https://www.oschina.net/news/276779/ubuntu-24-04-will-use-linux-6-8" target="_blank">Ubuntu 24.04 LTS 默认内核将采用 Linux 6.8</a></u></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Canonical 公布了 Ubuntu 24.04 LTS 的内核计划，并表示将正在开发的 Linux 6.8 作为下一个长期支持 Ubuntu 桌面 / 服务器发行版的默认内核。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">此前许多人在讨论&nbsp;Ubuntu 24.04 LTS 会采用哪个内核版本，有人觉得是 Linux 6.6 LTS，因为它在 2023 年成为了长期支持版本。也有人认为是最新的稳定内核 Linux 6.7，该版本有很多有用的新特性。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">现在 Canonical 工程师 Andrea Righi 宣布了在 Ubuntu 24.04 中采用 Linux 6.8 作为默认内核的暂定计划。目前实验性内核构建已经可以通过 PPA 获得。</p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">用户观点</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-9f8ec1ffe5a4c0214de25d655fcee74a996.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">媒体观点</span></span></span></span></span></span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-dabde0b7612b466a0720487e9cba9a008de.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span><span><span style="color:#000000"><span><span><span style="color:#00b050">每日项目榜</span></span></span></span></span></span></strong></h2><p>GitHub 榜单：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9c14f4f693a1964be35334f161b0b67f9eb.png" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6ca82877deafa256f357e48b095ec561b11.png" referrerpolicy="no-referrer"></p><p>在线阅读完整日报内容，访问：<strong><em><u><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC004%E6%9C%9F%EF%BC%9A%E5%A4%A7%E7%A5%9E%E5%8F%AA%E7%94%A8%20Excel%20%E5%B0%B1%E6%9E%84%E5%BB%BA%E4%BA%86%E4%B8%80%E9%A2%97%20CPU.pdf" target="_blank">开源日报第 004 期：大神只用 Excel 就构建了一颗 CPU</a></u></em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 14:16:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276864</guid>
            <link>https://www.oschina.net/news/276864</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百度搜索结果被 Microsoft Edge 浏览器封禁，搜索结果页「全红」警示]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1 月 29 日下午消息，今日，# Edge#话题登上热搜，据多位网友反馈，浏览器提示百度搜索结果不安全， Edge 浏览器将百度的搜索结果显示为「此网站已被人举报不安全」的警告语，需要展开详细，然后选择「继续访问此不安全站点（不推荐）」才能访问相关页面。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fdd5e488d1f44785059f7a586d3696390e8.png" referrerpolicy="no-referrer"></p><p>截至目前，相关问题仍未修复，在 Microsoft Edge 浏览器上点击百度相关链接，全部页面显示「红色」警示。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2Fchanjing%2Fgsxw%2F2024-01-29%2Fdetail-inafeqqm7979703.d.html" target="_blank">新浪科技称</a></u>已向百度以及微软中国方面进行求证，但双方均回应称暂不清楚情况，正向业务问询了解情况。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 09:40:28 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276851</guid>
            <link>https://www.oschina.net/news/276851</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linus 发飙，批评谷歌内核贡献者的代码是垃圾]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linus Torvalds 前两天在内核邮件列表发表了多年来措辞最激烈的一篇帖子——直接爆粗批评了一名谷歌内核贡献者关于文件系统的建议。</p><p>过去几周，「inode」一直是 Linux 内核邮件列表上争论的话题（inode 是给定文件系统中特定元数据的<strong>唯一标识符</strong>），谷歌员工 Steven Rostedt 和 Linus 就此事进行了激烈的讨论。</p><p>在标题为<em>"Have the inodes all for files and directories all be the same"</em>的邮件中，发布者指出，在使用 tar 归档文件时，inode 可能仍然发挥作用，Torvalds 则反驳称 inode 已经过时了。他认为 inode 已经不再是唯一的描述符。他表示，我们不是生活在 20 世纪 70 年代，文件系统已经发生了变化。</p><p>而 Rostedt 则建议索引节点都应该有唯一的编号。</p><p>为了回应 Rostedt 关于唯一 inode 编号的建议，Linus 指出 inode 曾经是特殊的，但现在应该尽量摆脱这种破碎的历史，<strong>不应该再让事情变得比必要的更加复杂</strong>。</p><p>不过&nbsp;Rostedt 好像没听进去 Linus 的话，提交的 PR 遭到了 Linus 的激烈批评：「你复制了一段不理解为何执行此操作的函数，这就是垃圾代码！」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-4232a4279600f5411d32e0758d98c05e345.png" referrerpolicy="no-referrer"><img src="https://oscimg.oschina.net/oscnet/up-2e9db3475e20188cc78d0693167b4e0ad0c.png" referrerpolicy="no-referrer"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flkml.iu.edu%2Fhypermail%2Flinux%2Fkernel%2F2401.3%2F04208.html" target="_blank">https://lkml.iu.edu/hypermail/linux/kernel/2401.3/04208.html</a></em></u></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 08:36:38 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276848</guid>
            <link>https://www.oschina.net/news/276848</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周热点 | Star 数超 3 万的开源仓库被清空；27 万行 Rust 代码编写的 Zed 编辑器开源；FreeBSD 「锈化」 .....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2024.01.22-2024.01.28]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 07:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094138&#38;idx=1&#38;sn=105efbbdf5bf4d0cfac0dc8ce15489b3&#38;chksm=880c4ce9bf7bc5ffb58ede3e8ea4fb28451e251396b481b6bf3e71bd7be8f174507f312d8bd5&#38;token=316000186&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094138&#38;idx=1&#38;sn=105efbbdf5bf4d0cfac0dc8ce15489b3&#38;chksm=880c4ce9bf7bc5ffb58ede3e8ea4fb28451e251396b481b6bf3e71bd7be8f174507f312d8bd5&#38;token=316000186&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[百川智能发布超千亿大模型 Baichuan 3，中文评测超越 GPT-4]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1 月 29 日，百川智能发布超千亿参数的大语言模型 Baichuan 3。</p><p>链接：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.baichuan-ai.com%2F" target="_blank">https://www.baichuan-ai.com/</a></u></em></p><p>据称在多个权威通用能力评测如 CMMLU、GAOKAO 和 AGI-Eval 中，Baichuan 3 都展现了出色的能力，<strong>尤其在中文任务上更是超越了 GPT-4</strong>。而在数学和代码专项评测如 MATH、HumanEval 和 MBPP 中同样表现出色。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4943e22112dc10bfbb4d4346b8b76cb1448.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-df748cfd41a08e601ad56b92c70ee27d974.png" referrerpolicy="no-referrer"></p><p>不仅如此，其在对逻辑推理能力及专业性要求极高的 MCMLE、MedExam、CMExam 等权威医疗评测上的中文效果同样超过了 GPT-4，是中文医疗任务表现最佳的大模型。Baichuan 3 还突破「迭代式强化学习」技术，进一步提升了语义理解和生成能力，在诗词创作的格式、韵律、表意等方面表现优异，领先于其他大模型。</p><p>在测试逻辑推理能力的 MCMLE、MedExam、CMExam 等医疗评测上，Baichuan 3 的中文效果同样号称超过了 GPT-4，是「中文医疗任务表现最佳的大模型」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c58c3189e812e73b513f6f5f311965c43f5.png" referrerpolicy="no-referrer"></p><p>据介绍，百川智能在 Baichuan 3 训练过程中提出了「动态数据选择」、「重要度保持」以及「异步 CheckPoint 存储」等多种技术手段及方案，稳定训练时间达到一个月以上，故障恢复时间不超过 10 分钟。</p><p>百川智能表示，Baichuan 3 还突破「迭代式强化学习」技术，进一步提升了语义理解和生成能力，在诗词创作的格式、韵律、表意等方面进行了提升，对于宋词这种格式多变，结构深细、韵律丰富的高难度文体，生成的内容亦能工整对仗、韵脚和谐，让每个人都能创作出咏物、寄思的五言律诗、七言绝句，写下的言志、抒情的「沁园春」、「定风波」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8959061fdec6f20cfdb40450da65be44c34.jpg" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-200b2ab4aedbbf84adc97af95557a2b8c51.jpg" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 06:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276843</guid>
            <link>https://www.oschina.net/news/276843</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Solon 框架讲的「三源合一」是怎么回事？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><h3>1、什么是「三源合一」？</h3><p>「三源合一」，是<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2F" target="_blank">Solon</a><span>&nbsp;</span>应用开发框架早期的一个架构想法。是指 Http、Socket、WebSocket 几个不同的通讯信号，进行统一架构处理......并且小巧。 对于 Socket 和 WebSocket，在原，消息+监听，的模式之外增加了 Mvc 模式（即 Handler + Context 接口处理）。</p><p>现在看来包括消息中间件的消息处理等等，都是可以转换成 Mvc 模式。怎么实现？这个太长了，这里只讲应用效果。</p><p><img src="https://teamx.noear.org/img/e6a9691c405d440dbc22541f4d0a8e5d.png" width="600" referrerpolicy="no-referrer"></p><h3>2、Http Mvc</h3><pre><code class="language-java"><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">DemoApp</span> {
    <span style="color:#a626a4">public</span><span style="color:#a626a4">static</span><span style="color:#a626a4">void</span><span style="color:#4078f2">main</span><span>(String[] args)</span> {
        Solon.start(DemoApp.class, args);
    }
}

<span style="color:#4078f2">@Controller</span><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">HelloController</span> {
    <span style="color:#4078f2">@Mapping("/mvc/hello")</span><span style="color:#a626a4">public</span> Result <span style="color:#4078f2">hello</span><span>(<span style="color:#986801">long</span> id, String name)</span> { <em>//{code:200,...}</em><span style="color:#a626a4">return</span> Result.succeed();
    }
}
</code></pre><p>Http 怎么调用？就不细讲了。</p><h3>3、Socket Mvc（使用 Socket.D 协议的请求答复接口）</h3><p>Socket.D 通讯协议，在设计之前就考虑了一个接口（sendAndRequest）用于兼容 Http 的请求模式，也称为应签模式。具体参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2F710" target="_blank">《Socket.D 协议转为 Mvc 接口》</a></p><pre><code class="language-java"><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">DemoApp</span> {
    <span style="color:#a626a4">public</span><span style="color:#a626a4">static</span><span style="color:#a626a4">void</span><span style="color:#4078f2">main</span><span>(String[] args)</span> {
        Solon.start(DemoApp.class, args, app -&gt; {
            app.enableSocketD(<span style="color:#0184bb">true</span>);
        });
    }
}

<em>//ToHandlerListene 监听器，会把 Socket.D 消息包转换成 Handler + Context 接口</em><span style="color:#4078f2">@ServerEndpoint("/mvc/")</span><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">SocketdAsMvc</span><span style="color:#a626a4">extends</span><span style="color:#c18401">ToHandlerListener</span> {
}

<span style="color:#4078f2">@Controller</span><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">HelloController</span> {
    <span style="color:#4078f2">@Mapping("/mvc/hello")</span><span style="color:#a626a4">public</span> Result <span style="color:#4078f2">hello</span><span>(<span style="color:#986801">long</span> id, String name)</span> { <em>//{code:200,...}</em><span style="color:#a626a4">return</span> Result.succeed();
    }
}
</code></pre><p>假如我们服务端启用的是<code>sd:ws</code>协议架构，客户端要怎么调用？三种方式：</p><ul><li>使用 java socket.d 原生接口调用</li></ul><pre><code class="language-java"><span style="color:#986801">let</span><span style="color:#986801">clientSession</span><span>=</span> SocketD.createClient(<span style="color:#50a14f">"sd🇼🇸//localhost:28082/mvc/?u=a"</span>).open();

<span style="color:#986801">let</span><span style="color:#986801">request</span><span>=</span><span style="color:#a626a4">new</span><span style="color:#c18401">StringEntity</span>(<span style="color:#50a14f">"{id:1,name:'noear'}"</span>).metaPut(<span style="color:#50a14f">"Content-Type"</span>,<span style="color:#50a14f">"text/json"</span>),
<span style="color:#986801">let</span><span style="color:#986801">response</span><span>=</span> clientSession.sendAndRequest(<span style="color:#50a14f">"/mvc/hello"</span>,  entity).await();
</code></pre><ul><li>使用 java rpc 代理模式调用</li></ul><pre><code class="language-java"><span style="color:#986801">HelloService</span><span style="color:#986801">rpc</span><span>=</span> SocketdProxy.create(<span style="color:#50a14f">"sd🇼🇸//localhost:28082/mvc/?u=a"</span>, HelloService.class);

System.out.println(<span style="color:#50a14f">"MVC result:: "</span> + mvc.hello(<span style="color:#50a14f">"noear"</span>));
</code></pre><ul><li>使用 js socket.d.js 调用（兼容：浏览器, uniapp(h5, android, ios), weixin, node.js）</li></ul><pre><code class="language-javascript"><span style="color:#a626a4">const</span> clientSession = <span style="color:#a626a4">await</span><span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">createClient</span>(<span style="color:#50a14f">"sd🇼🇸//127.0.0.1:28082/mvc/?u=a"</span>)
        .<span style="color:#4078f2">open</span>();

<em>//添加用户（加个内容类型，方便与 Mvc 对接）</em><span style="color:#a626a4">const</span> entity = <span style="color:#c18401">SocketD</span>.<span style="color:#4078f2">newEntity</span>(<span style="color:#50a14f">"{id:1,name:'noear'}"</span>).<span style="color:#4078f2">metaPut</span>(<span style="color:#50a14f">"Content-Type"</span>,<span style="color:#50a14f">"text/json"</span>),
clientSession.<span style="color:#4078f2">sendAndRequest</span>(<span style="color:#50a14f">"/mvc/hello"</span>,  entity, <span><span>reply</span>=&gt;</span>{
    <span style="color:#4078f2">alert</span>(reply.<span style="color:#4078f2">dataAsString</span>());
})
</code></pre><h3>4、WebSocket Mvc（使用 Socket.D 的请求答复接口）</h3><p>看起来是简单的，用起来还是要费点功夫的。具体参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2F646" target="_blank">《WebSocket 协议转换为 Socket.D》</a></p><pre><code class="language-java"><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">DemoApp</span> {
    <span style="color:#a626a4">public</span><span style="color:#a626a4">static</span><span style="color:#a626a4">void</span><span style="color:#4078f2">main</span><span>(String[] args)</span> {
        Solon.start(DemoApp.class, args, app -&gt; {
            app.enableWebSocket(<span style="color:#0184bb">true</span>);
        });
    }
}

<em>//ToSocketdWebSocketListener 监听器，会把 WebSocket 转换成 Socket.D 协议；</em><em>//ToHandlerListene 监听器，会把 Socket.D 消息包转换成 Handler + Context 接口；（一共做了两次转换）</em><span style="color:#4078f2">@ServerEndpoint("/mvc/")</span><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">WebSocketdAsMvc</span><span style="color:#a626a4">extends</span><span style="color:#c18401">ToSocketdWebSocketListener</span> {
    <span style="color:#a626a4">public</span><span style="color:#4078f2">WebSocketAsMvc</span><span>()</span> {
        <span style="color:#c18401">super</span>(<span style="color:#a626a4">new</span><span style="color:#c18401">ConfigDefault</span>(<span style="color:#0184bb">false</span>), <span style="color:#a626a4">new</span><span style="color:#c18401">ToHandlerListener</span>());
    }
}

<span style="color:#4078f2">@Controller</span><span style="color:#a626a4">public</span><span style="color:#a626a4">class</span><span style="color:#c18401">HelloController</span> {
    <span style="color:#4078f2">@Mapping("/mvc/hello")</span><span style="color:#a626a4">public</span> Result <span style="color:#4078f2">hello</span><span>(<span style="color:#986801">long</span> id, String name)</span> { <em>//{code:200,...}</em><span style="color:#a626a4">return</span> Result.succeed();
    }
}
</code></pre><p>WebSocket 转换为 Socket.D 协议，就可以使用 Socket.D 的接口去调用了：）</p></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 06:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276842</guid>
            <link>https://www.oschina.net/news/276842</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[.NET 8 动态 PGO 简析]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h2_1"></span><h2>原文：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486038%2526idx%253D1%2526sn%253D9c070c8e07acfe85269835a709cd5b6d%2526chksm%253Dc01c47cdf76bcedb8362846a829faf4c1853f4abcbe9708d6551264387f3795f7cb3e3e54828%2526token%253D1735800899%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">.NET8 动态 PGO 简析</a></u></h2><p><strong>作者：江湖评谈，公众号同名：江湖评谈 (Jianghupt）,欢迎关注。</strong></p><p>&nbsp;</p><span id="OSC_h2_2"></span><h2><strong>前言</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">.NET8 在性能方面的惊人飞跃，远超过去所取得成就，这在很大程度上归功于动态 PGO。【 I dare say the improvements in .NET 8 in the JIT are an incredible leap beyond what was achieved in the past, in large part due to dynamic PGO…官方原话】</p><span id="OSC_h2_3"></span><h2><strong>详细</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">在早期的.NET 方法只编译一次，在第一次调用该方法的时候，JIT 启动以生成该方法的代码。后续的调用以及当前的调用都会使用 JIT 生成的代码来运行程序，这是一个简单的无冲突的时代，但是也是一个原始的时代。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">简单和原始在于，方法只编译一次，再无其它可能性。无冲突在于，尤其是.NET 开源时代，分层，动态 PGO，OSR 等等都会破坏原有的代码逻辑，造成一定的复杂度，而早期的.NET 不存在这种状况。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">优化是编译器里面最耗时的操作，编译器可以花费超长的时间来优化一段代码或者一个指令集。但是程序使用者，或者软件使用者，或者软件开发者没有超长的时间去等待编译器慢慢的完成一个方法的编译。这是很致命的。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">在编译时间和代码质量上需要权衡利益得失。好的代码质量，需要更长的时间去编译，差的代码质量，则编译更快。这取决于 JIT 本身是如何工作的。大量的事实证明，在程序中大部分方法都只是调用一次或者几次，耗费很多的时间去优化这些方法。优化的时间反而超过了这些方法本身运行的时间，这完全是得不偿失的。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">为了解决这种情况，.NET Core3.0 中引入了新的 JIT 功能，称之为分层编译。通过分层一个方法可能会被编译多次，在第一次编译的时候被编译为 0 层 (tier0),在 0 层当中 JIT 优先考虑的是代码编译的速度，而不是质量。在 0 层的编译特点是，最小优化 (min opts，但是依然会保持一些优化)，之所以这样，是因为它需要更快速的编译而不是更好质量的代码。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">0 层之后，会有 1 层 (tier1)。这一层是基于 0 层的代码运行情况而来，比如 JIT 收集到 0 层的某个方法，运行的时间超过了 60ms,运行的次数超过了 2 次 (.NET8 R2R 函数进入分层编译队列的阈值，比如 Console.ReadLine 方法)，那么 JIT 就会把 0 层的这个方法放入到分层编译队列，进行编译之后该方法就会进一步优化形成了 1 层 (tier1),此后调用该方法和当前调用该方法都会调用 1 层的代码，而弃用了 0 层的代码。</p><span id="OSC_h2_4"></span><h2><strong>神来之笔</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">这里需要注意了，只有极少数的符合阈值的方法才能够进入 1 层。这样其实是 0 层和 1 层共生运行一个程序的过程，既保证了代码的质量，又保证了程序运行的速度，这是.NET8 的一个神奇点。但是它的好处远不止于此。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 1</strong>，代码从 0 层被优化到 1 层，JIT 在 0 层的时候就会收集到代码的信息，并且在编译到 1 层的时候，会进行相对应的优化。如果 JIT 直接从一开始把代码编译到 1 层，那么可能无法拥有这样的优化。举个例子，比如 0 层有个方法，它里面有个静态只读字段，0 层编译的时候它一定被初始化过了。JIT 就可以根据它收集到的初始化的内容，在生成 1 层代码的时候进行相对应的优化。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 2</strong>，有一种情况，一个方法可能只运行了寥寥几次或者只有一次。但是它里面有 for 循环这种代码，一直不停的运行。如果没有分层编译，它直接进入了 Tier1，这样很粗暴的方式明显不行。为了解决这个问题，.NET 中引入了 OSR(On-Stack Replacement)，当一个循环计数达到一定的阈值，JIT 将编译该方法的新优化版本，此后从最小代码优化版本调到新优化版本中继续执行。非常巧妙的一个方式。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 3，</strong>基于配置文件的静态优化 (PGO) 已经存在了几十年。适用于多种环境和语言，比如 C/C++,Python,Java 等等。这种原理主要是，在一些代码关键地方收集信息，下次运行根据这些信息重新构建应用程序。因为做到这些需要一些编译器或者其它一些配置，称之为静态 PGO。而通过分层，Tier0 优化到 Tier1 的基础上，所有的都是 JIT 自行收集，自行判断，自行优化，无须任何额外的开发工作，或者基础设施的配置，它就是动态 PGO。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 4，</strong>把 R2R 纳入到分层编译。R2R 是一个预编译镜像，它里面存储的 Native Header 是完全的二进制运行代码，它跟 AOT 的不同在于它运行了一定的次数之后，会被 JIT 进行重新优化编译。如果不把它纳入到分层编译，这对动态 PGO 的性能是一个很大的阻碍。</p><span id="OSC_h2_5"></span><h2><strong>编译分支和例子</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">一般的来说，即时编译分为两个分支。即源码编译和 R2R(它大量的应用在 System.Private.CoreLib.dll 里面) 预编译 (AOT 不属于即时编译，这里需要注意)。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">源码编译即所谓未 PreJIT 编译，0 层一般都是未优化 (not optimized)，未检查 (not instrumented)，在 0 层进行了检查但是未优化，此后在 1 层生成优化性代码。R2R 即所谓 PreJIT 编译，因为 R2R 可能已经被优化过了。所以 0 层它是已优化，未检查，会在 0 层进行检查。到了 1 层已优化已检查，然后会再次生成一个优化性的代码，也称之为 1 层 (但其实已经是 2 层，了)。参考如下图:</p><div><img height="629" src="https://pic2.zhimg.com/80/v2-080f882fe065fc243c87fbd61f80c1f5_720w.webp" width="1080" referrerpolicy="no-referrer"></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">下面看下 Tier0 优化的一个例子，上面说到 Tier0 是确保编译速度，而忽略代码质量。但是不代表 Tier0 不进行代码优化。下面就是 0 层代码优化的例子。</p><div><pre><code class="language-text">// dotnet run -c Release -f net8.0

MaybePrint(42.0);

static void MaybePrint&lt;T&gt;(T value)
{
    if (value is int)
        Console.WriteLine(value);
}</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">0 层 JIT 可以进行一定常量折叠 (在编译的时候评估常量而不是在运行的时候),这可以让 0 层生成更少的代码。一般的来说，0 层 JIT 大部分时间都是与虚拟机交互。如果能够减少一些永远不会使用的分支，可以大幅度提高编译的时间，也能获得更好的代码质量。将 DOTNET_JitDisasm 设置为 MaybePrint，运行</p><div><pre><code class="language-text">dotnet run -c Release -f net7.0</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">0 层代码如下：</p><div><pre><code class="language-text"> Assembly listing for method Program:&lt;&lt;Main&gt;$&gt;g__MaybePrint|0_0[double](double)
; Emitting BLENDED_CODE for X64 CPU with AVX - Windows
; Tier-0 compilation
; MinOpts code
; rbp based frame
; partially interruptible

G_M000_IG01:                ;; offset=0000H
       55                   push     rbp
       4883EC30             sub      rsp, 48
       C5F877               vzeroupper
       488D6C2430           lea      rbp, [rsp+30H]
       33C0                 xor      eax, eax
       488945F8             mov      qword ptr [rbp-08H], rax
       C5FB114510           vmovsd   qword ptr [rbp+10H], xmm0

G_M000_IG02:                ;; offset=0018H
       33C9                 xor      ecx, ecx
       85C9                 test     ecx, ecx
       742D                 je       SHORT G_M000_IG03
       48B9B877CB99F97F0000 mov      rcx, 0x7FF999CB77B8
       E813C9AE5F           call     CORINFO_HELP_NEWSFAST
       488945F8             mov      gword ptr [rbp-08H], rax
       488B4DF8             mov      rcx, gword ptr [rbp-08H]
       C5FB104510           vmovsd   xmm0, qword ptr [rbp+10H]
       C5FB114108           vmovsd   qword ptr [rcx+08H], xmm0
       488B4DF8             mov      rcx, gword ptr [rbp-08H]
       FF15BFF72000         call     [System.Console:WriteLine(System.Object)]

G_M000_IG03:                ;; offset=0049H
       90                   nop

G_M000_IG04:                ;; offset=004AH
       4883C430             add      rsp, 48
       5D                   pop      rbp
       C3                   ret

; Total bytes of code 80</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">System.Console:WriteLine 里面的代码都是可以进行优化的，但是.NET7 里面 0 层它解析出了 MaybePrint，并未意识到其根本不会执行。现在在.NET8 里面 JIT 意识到分支永远不会执行，所以生成如下：</p><div><pre><code class="language-text">; Assembly listing for method Program:&lt;&lt;Main&gt;$&gt;g__MaybePrint|0_0[double](double) (Tier0)
; Emitting BLENDED_CODE for X64 with AVX - Windows
; Tier0 code
; rbp based frame
; partially interruptible

G_M000_IG01:                ;; offset=0x0000
       push     rbp
       mov      rbp, rsp
       vmovsd   qword ptr [rbp+0x10], xmm0

G_M000_IG02:                ;; offset=0x0009

G_M000_IG03:                ;; offset=0x0009
       pop      rbp
       ret

; Total bytes of code 11</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><span id="OSC_h1_6"></span><h1>欢迎关注公众号：<strong>江湖评谈 (jianghupt）</strong></h1><h2><img alt="" height="430" src="https://oscimg.oschina.net/oscnet/up-011ec0cc18092e37225986048b70675dae9.png" width="430" referrerpolicy="no-referrer"></h2></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 06:42:22 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5407571/blog/10983721</guid>
            <link>https://my.oschina.net/u/5407571/blog/10983721</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百度输入法在候选词区域植入广告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>V2EX 用户发帖称，百度输入法最新版本在候选词区域植入了广告。</p><p>具体表现为，如果用户要打「招商银行」四个字，当输入「招商」之后，候选词的首位是「★热门加盟店排行」的链接，点击后会进入名为「加盟星榜单」的广告页面。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-0682b5080fc14f1967ebbe8ed9f2c741f2b.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1011440" target="_blank">https://www.v2ex.com/t/1011440</a></u></em></p></blockquote><p>别的不说，想出这个功能的产品经理真是个人才，因此评论区有用户感叹道：</p><blockquote><p><em>不说用户体验怎么样，不得不说这个键盘的候选词广告想法确实超前，不光超前，还实现了。</em></p><p><em>根据输入内容，直接用候选词的方式推送广告，从源头出发拿到用户的一手数据，直接甩掉了各种中间商。速度也更快，更精确的投送。</em></p><p><em>可以说是真 nb 呀</em></p></blockquote><p>知名科技博主阑夕对此评论道：「<em>你都打出招商两个字了，一定是想加盟店铺做生意吧？逻辑极其通顺智能，对不对？这真的是人类能够企及的创新吗，太牛逼了。</em>」</p><blockquote><p><img height="604" src="https://oscimg.oschina.net/oscnet/up-9c82c56b05a42376a5e053f16691428897d.png" width="1270" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 04:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276832</guid>
            <link>https://www.oschina.net/news/276832</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Katalyst v0.4.0 发布：潮汐混部与资源超分]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-35370f991af6656824cb1bdd4d587fa5449.png" alt="" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0NDMzNjkxNw%3D%3D%26mid%3D2247485561%26idx%3D1%26sn%3Dc5a10a4f5e692568a60f76fb3bab67c2%26chksm%3Dc3277103f450f815423288c62b7f66d0a86a67f3820950c77acbf241cad0e2b56f1e0461bb5f%26scene%3D21%23wechat_redirect" target="_blank">Katalyst</a> 是字节跳动开源的成本优化实践系统，致力于解决云原生场景下的资源不合理利用问题，为资源管理和成本优化提供解决方案。</p><blockquote><p>来源&nbsp;| KubeWharf 社区</p><p>项目 |&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewharf%2Fkatalyst-core" target="_blank">github.com/kubewharf/katalyst-core</a></p></blockquote><p>近日，Katalyst 社区完成了 0.4.0 版本发布。除了持续优化 QoS 能力之外，我们还在新版本中提供了可以独立在原生 Kubernetes 上使用的潮汐混部和资源超售能力。</p><p>和在离线常态混部一样，这些能力是字节跳动在不同业务场景中实现降本增效的技术手段，我们在抽象出标准化能力之后也进行了开源，期望这些能力可以帮助用户以更低的落地成本完成资源效能提升。</p><h1>潮汐混部</h1><h2>背景</h2><p>通过给应用分配差异化的 QoS 等级，Katalyst 可以基于资源隔离和动态调控能力实现在单机维度的在离线业务混部，即常态混部。这种混部模式虽然可以实现极致的资源效能提升，但是也增加了基础设施的复杂度。同时因为引入了例如 Reclaimed 资源这样的概念，要落地常态混部往往还需要做一些业务侧的适配。</p><p>为了让用户可以以更低的成本落地混部能力，在 v0.4.0 中，Katalyst 提供了潮汐混部（Tidal Colocation）功能。</p><h2>技术解读</h2><p>在潮汐混部中引入了潮汐节点池的概念，并且将集群中的节点划分为「在线」和「离线」两种类型。潮汐混部主要分为两个部分：</p><ul><li><strong>实例数管理</strong>：通过 HPA、CronHPA 等各种横向扩缩能力来管理在线业务的实例数，在夜间可以腾出资源给离线业务使用</li><li><strong>潮汐节点池管理</strong>：Tidal Controller 基于设定好的策略对潮汐节点池中的节点做 binpacking，将腾出的资源折合成整机出让给离线业务</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-20c31affd845929187609604ca5d98f5d2a.png" alt="" referrerpolicy="no-referrer"></p><h2>使用</h2><ol><li>在集群中选取加入潮汐节点池的节点，并为节点打上某个 Label</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  ...
  labels:
    beta.kubernetes.io/arch: amd64
    beta.kubernetes.io/os: linux
    # 潮汐节点标识
    tidenodes: "true"
  name: 192.168.0.11
spec:
  ...
</code></pre><ol start="2"><li>创建潮汐节点池配置</li></ol><pre><code>apiVersion: tide.katalyst.kubewharf.io/v1alpha1
kind: TideNodePool
metadata:
  name: tidenodepool-example
spec:
  nodeConfigs:
    nodeSelector:
      # 与加入潮汐节点池的节点中的标签匹配
      tidenodes: "true"
    # 配置潮汐节点池中为在线和离线节点预留的节点量
    reserve:
      offline: 25%
      online: 10%
</code></pre><ol start="3"><li>潮汐控制器为节点打上对应的标签和污点，并且会根据各个节点的负载情况动态做 Binpacking 调整节点角色</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  labels:
    beta.kubernetes.io/arch: amd64
    beta.kubernetes.io/os: linux
    tidenodes: "true"
    # 潮汐控制器为在线节点打上在线标签，离线类似
    tide.katalyst.kubewharf.io/node-pool: tidenodepool-sample
    tide.katalyst.kubewharf.io/node-type: online
    tide.katalyst.kubewharf.io/reserve: "false"
    tide.katalyst.kubewharf.io/tide: "true"
  name: 192.168.0.11
spec:
  # 潮汐控制器为在线节点打上禁止离线调度的污点，离线类似
  taints:
  - effect: NoExecute
    key: tide.katalyst.kubewharf.io/offline-not-used
    value: "true"
  ...
</code></pre><ol start="4"><li>部署在线离线业务，为应用打上相应标签和污点容忍，并配置 HPA 规则</li></ol><pre><code>kind: Deployment
apiVersion: apps/v1
metadata:
  name: tide-online
spec:
  replicas: 30
  selector:
    matchLabels:
      app: tide-online
  template:
    metadata:
      labels:
        # 标识在线
        tide.katalyst.kubewharf.io/pod-type: online
        app: tide-online
    spec:
      tolerations:
        # 容忍污点
      - key: "tide.katalyst.kubewharf.io/offline-not-used" 
        operator: "Exists"
      nodeSelector:
        # 选择在线节点，包含预留+潮汐
        tide.katalyst.kubewharf.io/node-type: online
      containers:
      - name: busybox
        image: busybox
        command: ["sleep", "36000"]
        resources:
          requests:
            cpu: "4"
            memory: "8Gi"
</code></pre><h1>在线超分</h1><h2>背景</h2><p>在线业务的资源使用量往往会随着访问数量的波动而变化，具备明显的潮汐特性。为了确保业务的稳定性，用户通常会以峰值时消耗的资源量作为申请的依据，而且往往会有过度申请资源的倾向，这些资源会被浪费。</p><p>Katalyst 提供了在离线混部的能力作为解决上述问题的方式之一，但是在一些场景下，在离线混部可能不便于落地，比如：</p><ul><li>负载类型比较单一，只有在线业务</li><li>业务方不愿意改变申请资源的协议来申请 Reclaimed 资源</li></ul><p>在新版本中，Katalyst 针对在线业务场景，提供了一种简单的、对业务方无感的资源超分方案，便于用户快速提升资源利用率。</p><h2>技术解读</h2><ul><li><strong>Over-commit Webhook</strong>：劫持 kubelet 上报心跳的请求，并对 Allocatable 资源量进行放大</li><li><strong>Over-commit Controller</strong>：超分配置管理</li><li><strong>Katalyst Agent</strong>：通过干扰检测和驱逐，保障超分后节点的性能和稳定性；根据指标数据，计算并上报动态的超分比</li><li><strong>Katalyst Scheduler</strong>：对需要绑核的 Pod 进行准入，避免超分导致实际无法绑核而启动失败</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-15d23b597098e49126aa0ae68cb1b5f0d0c.png" alt="" referrerpolicy="no-referrer"></p><h2>使用</h2><ol><li>为需要超分的节点池的节点打上 Label</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  annotations:
    # 超分节点池的标识
    katalyst.kubewharf.io/overcommit_node_pool: node-pool-1 
  name: 10.27.0.1
spec:
  ...
status:
  # 未超分时的资源量
  allocatable:
    cpu: 15900m
    memory: 32059820Ki
  capacity:
    cpu: 16
    memory: 32424364Ki
  ...
</code></pre><p>2.&nbsp;创建超分规则</p><pre><code>apiVersion: overcommit.katalyst.kubewharf.io/v1alpha1
kind: NodeOvercommitConfig
metadata:
  name: node-overcommit-config-1
spec:
  # 该规则匹配具有如下节点池 Label 的节点
  # katalyst.kubewharf.io/overcommit_node_pool=node-pool-1 
  nodeOvercommitSelectorVal: "node-pool-1"
  # 各种资源的超分比
  resourceOvercommitRatio:
    cpu: 2
status:
  # 该规则匹配的节点名称列表
  matchedNodeList: 
    - 10.27.0.1
    - 10.27.0.2
    - 10.27.0.3
</code></pre><ol start="3"><li>观察 Node 对象，发现 Katalyst 将超分比、未超分时的资源量更新到&nbsp;Annotation 中，并根据超分比对 Allocatable 和 Capacity 进行了放大</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  annotations:
    katalyst.kubewharf.io/overcommit_node_pool: node-pool-1 
    # 以下字段由 Katalyst 添加
    # CPU 超分比
    katalyst.kubewharf.io/cpu-overcommit-ratio: "2"
    # Memory 超分比
    katalyst.kubewharf.io/memory-overcommit-ratio: "1"
    # 超分前的 CPU Capacity
    katalyst.kubewharf.io/original_capacity_cpu: "16"
    # 超分前的 Memory Capacity
    katalyst.kubewharf.io/original_capacity_memory: "32424364Ki"
    # 超分前的 CPU Allocatable
    katalyst.kubewharf.io/original_allocatable_cpu: "15900m"
    # 超分前的 Memory Allocatable
    katalyst.kubewharf.io/original_allocatable_memory: "32424364Ki"
  name: 10.27.0.1
spec:
  ...
status:
  # 超分后的资源量
  allocatable:
    cpu: 31800m
    memory: 32059820Ki
  capacity:
    cpu: 32
    memory: 32424364Ki
  ...
</code></pre><h1>NUMA 粒度混部内存管控框架</h1><h2>背景</h2><p>Katalyst 当前的混部策略只考虑整体机器的可用资源，导致离线任务在 NUMA 跨度申请内存时，内存容量和带宽在各 NUMA 间分布不均匀。这种情况下，当前的混部策略往往无法精确控制内存使用量，进而引起内存压力。</p><p>针对这种情况，我们提出了一种精细化的 NUMA 粒度内存管控框架，旨在通过 sysadvisor 计算 memory provisions，并与 qrm memory plugin 交互，实现更细致的 NUMA 内存管理。这将使 qrm memory plugin 能够根据 memory provisions 进行 NUMA 细粒度内存控制。</p><h2>技术解读</h2><p>在 Sysadvisor 的 Memory Plugin 中，我们引入了名为 memoryProvisioner 的插件，负责计算每个 NUMA 的内存供应逻辑。</p><p>为增强其可扩展性，我们设计了 ProvisionPolicy 接口，包含 Update 和 GetProvision 两个方法，分别用于定期更新内存供应量和获取 provision 建议。MemoryProvisioner 插件实现了 MemoryAdvisorPlugin 接口。</p><p>此策略基于 Memory Headroom 的 PolicyNUMAAware 策略，通过遍历每个物理 NUMA 及其 pod，计算每个 NUMA 的内存供应量。具体计算逻辑包括分析 NUMA Exclusive 设置，获取每个 NUMA 节点的空闲内存，并应用公式考虑 reclaimed cores、系统 scale_factor 和 reserved 内存，以实现更均衡的 NUMA 内存分配。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5947a2be6ceb2494b055eb33148d597d250.png" alt="" referrerpolicy="no-referrer"></p><h2>使用</h2><p>katalyst-agent 添加了&nbsp;<code>memory-provision-policy</code>&nbsp;的启动参数，用于指定计算策略，默认是 canonical。用法如下：</p><pre><code>katalyst-agent --kubeconfig=/root/.kube/config \
--memory-resource-plugin-advisor=true   \
--memory-advisor-plugins=memory-provisioner \
--memory-provision-policy=memory-provisioner-canonical \
...
</code></pre><h1>支持 OOM 优先级作为 QoS 增强</h1><h2>背景</h2><p>目前，Kubernetes 中 pod 的 OOM 优先级主要受其 QoS 级别与其对内存的申请量、使用量影响。然而，当前混部场景下，kubelet 原生的 oom_score_adj 计算策略已经不能很好的满足需求，例如：</p><ul><li>需要给两个都映射到原生的 Burstable 级别的 shared_cores pods 设定 OOM 优先级</li><li>需要在两个原生都是 Guaranteed 级别的 dedicated_cores pod 和 shared_cores pod 之间设定 shared_cores pod 要早于 dedicated_cores pod OOM</li></ul><p>此外，当前 kubelet 中提供的静态 oom_score_adj 计算机制，不支持 OOM 优先级的动态调整。因此 Katalyst 提供了一个关于 OOM 优先级的 QoS Enhancement，支持更加灵活地为 pods 设置 OOM 优先级。</p><h2>技术解读</h2><p>Katalyst 通过在内核添加 ebpf 的方式实现用户自定义的 OOM 策略注入，并在上层 qrm memory plugin 中完成用户定义策略的解析以及 OOM Priority 的配置下发。</p><h2>使用</h2><p>OOM Priority 信息通过 annotaion 在 pod 上进行指定</p><pre><code>annotations:
    "katalyst.kubewharf.io/memory_enhancement":'{
    "numa_binding": "true", 
    "numa_exclusive": "true",
    "oom_priority": priorityValueInt,
    }'
</code></pre><p>priorityValueInt 的取值越大表示优先级越高，并且取值范围受 pod 所指定的 QoS level 影响。</p><h1>支持拓扑感知调度</h1><p>在搜索、广告、推荐、游戏、AI 分布式训练等业务场景下，用户对时延的敏感性较高，对容器在微拓扑级别的摆放方式存在要求。原生 K8s 的微拓扑管理能力存在一些局限，调度器不感知微拓扑，可能导致出现较多的因不满足 NUMA 亲和要求而造成的 Admit 失败。</p><p>因此，Katalyst 在 v0.4.0 实现了拓扑感知调度功能，支持两种模式：</p><ul><li>Native 策略：兼容 K8s 原生的 NUMA 亲和和绑核策略</li><li>Dynamic 策略：混部场景下增强的绑核策略，对于&nbsp;dedicated_cores&nbsp;QoS 级别，支持了 NUMA 亲和 (numa_binding) 以及 NUMA 独占 (numa_exclusive) 两种语义</li></ul><h1>其他</h1><ul><li>SysAdvisor 框架支持对接自定义业务模型，调优 rama provision policy 计算结果</li><li>QRM 支持设置整机和容器级别 TCP Memory 上限，缓解 TCP 内存满导致的丢包问题</li><li>Eviction 集成 RootFS 驱逐能力，定制排序策略和 QoS 级别驱逐阈值</li><li>KCMAS 优化存储数据结构和索引，支持多 tag 能力</li><li>ServiceProfilingDescriper (SPD) 支持服务维度的混部 baseline 和 per-pod 灰度能力</li><li>社区开发切换到基于 owner review 模式</li><li>基于超时实现死锁检测功能</li></ul><h2>新版本体验路径</h2><p>请参考社区官方文档体验 Katalyst 潮汐混部和资源超分能力:</p><ul><li>潮汐混部：gokatalyst.io/docs/user-guide/tidal-colocation/</li><li>资源超分：gokatalyst.io/docs/user-guide/resource-overcommitment/</li></ul><h2>感谢贡献者</h2><p>在本次新版本的发布过程中，社区也迎来了不少新的贡献者，在此向他们的付出表示由衷感谢：</p><p><img src="https://oscimg.oschina.net/oscnet/up-83be15e44a1ec8ffe211a81ad949b4e8982.png" alt="" referrerpolicy="no-referrer"></p><p>非常期待更多开发者和用户加入到 Katalyst 开源社区中，和我们一起交流和探讨在离线混部以及资源效能的相关话题。</p><hr><p>项目地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewharf%2Fkatalyst-core" target="_blank">github.com/kubewharf/katalyst-core</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 03:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6210722/blog/10979687</guid>
            <link>https://my.oschina.net/u/6210722/blog/10979687</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[文本检索性能提升 40 倍，Apache Doris 倒排索引深度解读]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 OLAP 领域，Apache Doris 已成为高性能、高并发以及高时效性的代名词。在面向海量数据的复杂查询需求时，除硬件配置、集群规模、网络带宽等因素外，提升性能的核心在于如何最大程度地降低 SQL 执行时的 CPU、内存和 IO 开销，而这其中数据库索引扮演着至关重要的角色。合理的索引结构设计可以跳过大量不必要的底层数据读取、快速检索定位到所需数据，并进一步提升后续计算的执行效率、降低查询 SQL 的运行时间和资源消耗。</p><p>Apache Doris 提供了丰富的索引以加速数据的读取和过滤，依据是否需要用户手工创建，索引类型大体可以分为智能内建索引和用户创建索引两类，其中智能内建索引是指在数据写入时自动生成的索引，无需用户干预，包括前缀索引和 ZoneMap 索引。用户创建索引需要用户根据业务特点手动创建，包括 Bloom Filter 索引和 2.0 版本新增的倒排索引与 NGram Bloom Filter 索引。</p><p>相较于用户比较熟悉的前缀索引、Bloom Filter 索引，2.0 版本所新增的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg3Njc2NDAwOA%3D%3D%26mid%3D2247519079%26idx%3D1%26sn%3Da232a72695ff93eea0ffe79635936dcb%26chksm%3Dcf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e%26scene%3D21%23wechat_redirecthttp%3A%2F%2F" rel="nofollow" target="_blank">倒排索引</a>和 NGram Bloom Filter 在文本检索、模糊匹配以及非主键列检索等场景有着更为明显的性能提升。本文将以 Amazon customer reviews 数据集为例，介绍 Apache Doris 在查询该数据集以及类似场景中，如何充分利用倒排索引以及 NGram Bloom Filter 索引进行查询加速，并详细解析其工作原理与最佳实践。</p><span id="OSC_h2_1"></span><h2>数据集样例</h2><p>在本文中，我们使用的数据集包含约 1.3 亿条亚马逊产品的用户评论信息。该数据集以 Snappy 压缩的 Parquet 文件形式存在，总大小约为 37GB。以下为数据集的样例：</p><p><img src="https://cdn.selectdb.com/static/_e5e3fca815.png" alt="数据集样例.png" referrerpolicy="no-referrer"></p><p>在子集中，每行包含用户 ID（<code>customer_id</code>）、评论 ID（<code>review_id</code>）、已购买产品 ID（<code>product_id</code>）、产品分类（<code>product_category</code>）、评分（<code>star_rating</code>）、评论标题（<code>review_headline</code>）、评论内容（<code>review_body</code>）等 15 列信息。 根据上述可知，列中包含了适用于索引加速的各种特征。例如，<code>customer_id</code> 是高基数的数值列，<code>product_id</code> 是低基数的定长短文本列，<code>product_title</code> 是适合文本检索的短文本列，<code>review_body</code> 则是适合文本搜索的长文本列。</p><p>通过这些列，我们可以模拟两个典型索引查询场景，具体如下：</p><ul><li>文本搜索查询：搜索 <code>review body</code> 字段中包含特定内容的产品信息。</li><li>非主键列明细查询：查询特定产品 ID（<code>product_id</code>）或者特定用户 ID（<code>customer_id</code>）的评论信息。</li></ul><p>接下来，我们将以文本搜索和非主键列明细查询为主要方向，对比在有索引和无索引的情况下查询性能的差异。同时，我们也将详细解析索引减少查询耗时、提高查询效率的原理。</p><span id="OSC_h2_2"></span><h2>环境搭建</h2><p>为了快速搭建环境，并进行集群创建和数据导入，我们使用单节点集群（1FE、1BE）并按照以下步骤进行操作：</p><ol><li><p>搭建 Apache Doris ：具体操作请参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoris.apache.org%2Fzh-CN%2Fdocs%2Fget-starting%2Fquick-start%2F" rel="nofollow" target="_blank">快速开始</a></p></li><li><p>创建数据表：按照下列建表语句进行数据表创建</p></li></ol><pre><code class="language-SQL">CREATE TABLE `amazon_reviews` (  
  `review_date` int(11) NULL,  
  `marketplace` varchar(20) NULL,  
  `customer_id` bigint(20) NULL,  
  `review_id` varchar(40) NULL,
  `product_id` varchar(10) NULL,
  `product_parent` bigint(20) NULL,
  `product_title` varchar(500) NULL,
  `product_category` varchar(50) NULL,
  `star_rating` smallint(6) NULL,
  `helpful_votes` int(11) NULL,
  `total_votes` int(11) NULL,
  `vine` boolean NULL,
  `verified_purchase` boolean NULL,
  `review_headline` varchar(500) NULL,
  `review_body` string NULL
) ENGINE=OLAP
DUPLICATE KEY(`review_date`)
COMMENT 'OLAP'
DISTRIBUTED BY HASH(`review_date`) BUCKETS 16
PROPERTIES (
"replication_allocation" = "tag.location.default: 1",
"compression" = "ZSTD"
);

</code></pre><p>3.下载数据集：从下方链接分别下载数据集，数据集为 Parque 格式，并经过 Snappy 压缩，总大小约为 37GB</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2010.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2010</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2011.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2011</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2012.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2012</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2013.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2013</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2014.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2014</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2015.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2015</a></li></ul><p>4.导入数据集：下载完成后，分别执行以下命令，导入数据集</p><pre><code class="language-Bash">curl --location-trusted -u root: -T amazon_reviews_2010.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2011.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2012.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2013.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2014.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2015.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load


</code></pre><p>5.查看与验证：完成上述步骤后，可以在 MySQL 客户端执行以下语句，来查看导入的数据行数和所占用空间。从下方代码可知：共导入 135589433 行数据，在 Doris 中占用空间 25.873GB，比压缩后的 Parquet 列式存储进一步降低了 30%。</p><pre><code class="language-SQL">mysql&gt; SELECT COUNT() FROM amazon_reviews;
+-----------+
| count(*)  |
+-----------+
| 135589433 |
+-----------+
1 row in set (0.02 sec)
mysql&gt; SHOW DATA FROM amazon_reviews;
+----------------+----------------+-----------+--------------+-----------+------------+
| TableName      | IndexName      | Size      | ReplicaCount | RowCount  | RemoteSize |
+----------------+----------------+-----------+--------------+-----------+------------+
| amazon_reviews | amazon_reviews | 25.873 GB | 16           | 135589433 | 0.000      |
|                | Total          | 25.873 GB | 16           |           | 0.000      |
+----------------+----------------+-----------+--------------+-----------+------------+
2 rows in set (0.00 sec)


</code></pre><span id="OSC_h2_3"></span><h2>文本搜索查询加速</h2><span id="OSC_h3_4"></span><h3>无索引硬匹配</h3><p>环境及数据准备就绪后，我们尝试对 <code>review_body</code> 列进行文本搜索查询。具体需求是在数据集中查出评论中包含「is super awesome」关键字的前 5 种产品，并按照评论数量降序排列，查询结果需显示每种产品的 ID、随机一个产品标题、平均星级评分以及评论总数。<code>review_body</code> 列的特征是评论内容比较长，因此进行文本搜索会有一定的性能压力。</p><p>首先我们直接进行查询，以下是查询的示例语句：</p><pre><code class="language-SQL">SELECT
    product_id,
    any(product_title),
    AVG(star_rating) AS rating,
    COUNT() AS count
FROM
    amazon_reviews
WHERE
    review_body LIKE '%is super awesome%'
GROUP BY
    product_id
ORDER BY
    count DESC,
    rating DESC,
    product_id
LIMIT 5;


</code></pre><p>执行结果如下，查询耗时为 <strong>7.6 秒</strong></p><pre><code class="language-SQL">+------------+------------------------------------------+--------------------+-------+
| product_id | any_value(product_title)                 | rating             | count |
+------------+------------------------------------------+--------------------+-------+
| B00992CF6W | Minecraft                                | 4.8235294117647056 |    17 |
| B009UX2YAC | Subway Surfers                           | 4.7777777777777777 |     9 |
| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |              4.875 |     8 |
| B0086700CM | Temple Run                               |                  5 |     6 |
| B00KWVZ750 | Angry Birds Epic RPG                     |                  5 |     6 |
+------------+------------------------------------------+--------------------+-------+
5 rows in set (7.60 sec)


</code></pre><span id="OSC_h3_5"></span><h3>利用 Ngram BloomFilter 索引加速查询</h3><p>接下来，我们尝试使用 Ngram BloomFilter 索引进行查询加速</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX review_body_ngram_idx(review_body) USING NGRAM_BF PROPERTIES("gram_size"="10", "bf_size"="10240");


</code></pre><p>添加 Ngram BloomFilter 索引之后，再次执行相同的查询。执行结果如下，<strong>查询耗时缩短至 0.93 秒，相较于未开启索引，查询效率提高了 8 倍。</strong></p><pre><code class="language-SQL">+------------+------------------------------------------+--------------------+-------+
| product_id | any_value(product_title)                 | rating             | count |
+------------+------------------------------------------+--------------------+-------+
| B00992CF6W | Minecraft                                | 4.8235294117647056 |    17 |
| B009UX2YAC | Subway Surfers                           | 4.7777777777777777 |     9 |
| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |              4.875 |     8 |
| B0086700CM | Temple Run                               |                  5 |     6 |
| B00KWVZ750 | Angry Birds Epic RPG                     |                  5 |     6 |
+------------+------------------------------------------+--------------------+-------+
5 rows in set (0.93 sec)


</code></pre><p>接下来，我们根据代码示例展开说明。使用 <code>ALTER TABLE</code> 语句为表增加 Ngram BloomFilter 索引时，<code>gram_size</code> 和 <code>bf_size</code> 参数具有特定的含义：</p><ul><li><code>gram_size</code>：表示 n-gram 中的 n 值，即连续字符的长度。在上述代码示例中，<code>"gram_size"="10"</code> 表示每个 n-gram 包含 10 个字符。这意味着文本将被切割成数个字符长度为 10 的字符串，这些字符串将用于构建索引。</li><li><code>bf_size</code>：表示 Bloom Filter 的大小，以字节（Byte）为单位。例如，<code>"bf_size"="10240"</code>表示所使用 Bloom Filter 数据大小占用空间为 10240 字节。</li></ul><p>在了解基本的参数定义后，我们来探索 <strong>Ngram BloomFilter 加速查询的原理：</strong></p><ul><li>Ngram 分词：使用 <code>gram_size</code> 对每行数据进行分词，当 <code>gram_size=5</code> 时，"hello world" 被切分为 ["hello"， "ello "， "llo w"， "lo wo"， "o wor"， " worl"， "world"]。这些子字符串经过哈希函数计算后，将被添加到相应大小（<code>bf_size</code>）的 Bloom Filter 中。由于 Doris 数据是按页面（page）组织存储，相应的 Bloom Filter 也会按页面（page）生成。</li><li>查询加速：以「hello」为例，在匹配过程中也将被切分并生成对应的 Bloom Filter，用于与各页面的 Bloom Filter 进行对比。如果 Bloom Filter 判断为包含匹配字符串（可能会出现假阳性），则加载相应的页面以进一步匹配；否则，将跳过该页面。其原理即通过跳过不需要加载的页面（page），减少需要扫描的数据量，从而显著降低了查询延时。</li></ul><p><img src="https://cdn.selectdb.com/static/Apache_Doris_c50be251fc.png" alt="Apache Doris 数据存储结构" referrerpolicy="no-referrer"></p><p>Ngram Bloom Filter 示意图</p><p>通过上述原理描述可以看出，针对不同的场景合理的配置 Ngram BloomFilter 的参数会达到更好的效果， <code>gram_size</code> 的大小直接影响匹配时效率，而 <code>bf_size</code> 的大小影响存储容量和误判率。通常情况下，较大的 <code>bf_size</code> 可以降低误判率，但这样也会占用更多的存储空间。因此，我们建议从以下两方面综合考量配置参数：</p><p><strong>数据特性：</strong> 考虑要索引的数据类型。对于文本数据，需要根据文本的平均长度和字符分布来确定。</p><ul><li>对于较短的文本（如单词或短语）：较小的 <code>gram_size</code>（例如 2-4）和较小的 <code>bf_size</code> 可能更合适。</li><li>对于较长的文本（如句子或大段描述：较大的 <code>gram_size</code>（例如 5-10）和较大的 <code>bf_size</code> 可能更有效。</li></ul><p><strong>查询模式：</strong> 考虑查询的典型模式。</p><ul><li>如果查询通常包含短语或接近完整的单词，较大的 <code>gram_size</code> 可能更好。</li><li>对于模糊匹配或包含多种变化的查询，较小的 <code>gram_size</code> 可以提供更灵活的匹配。</li></ul><span id="OSC_h3_6"></span><h3>利用倒排索引加速查询</h3><p>除了采用 Ngram BloomFilter 索引进行查询加速，还可以选择基于 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg3Njc2NDAwOA%3D%3D%26mid%3D2247519079%26idx%3D1%26sn%3Da232a72695ff93eea0ffe79635936dcb%26chksm%3Dcf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e%26token%3D533653942%26lang%3Dzh_CN%23rd" rel="nofollow" target="_blank">倒排索引</a> 进一步加速文本搜索的效率。可以通过以下步骤来构建倒排索引：</p><p>1.<strong>新增倒排索引：</strong> 对 <code>amazon_reviews</code> 表的 <code>review_body</code> 列添加倒排索引，该索引采用英文分词，并支持 Phrase 短语查询，短语查询即进行文本搜索时，分词后的词语顺序将会影响搜索结果。 2.<strong>为历史数据创建索引：</strong> 按照新增索引信息对历史数据进行索引构建，使历史数据就也可以使用倒排索引进行查询。</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX review_body_inverted_idx(`review_body`) 
    USING INVERTED PROPERTIES("parser" = "english","support_phrase" = "true"); 
BUILD INDEX review_body_inverted_idx ON amazon_reviews;

</code></pre><p>3.<strong>查看及验证：</strong> 构建完索引之后，可以通过以下方式对索引构建情况进行查看：</p><pre><code class="language-SQL">mysql&gt; show BUILD INDEX WHERE TableName="amazon_reviews";
+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+
| JobId | TableName      | PartitionName  | AlterInvertedIndexes                                                                                                              | CreateTime              | FinishTime              | TransactionId | State    | Msg  | Progress |
+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+
| 10152 | amazon_reviews | amazon_reviews | [ADD INDEX review_body_inverted_idx (
review_body
) USING INVERTED PROPERTIES("parser" = "english", "support_phrase" = "true")],  | 2024-01-23 15:42:28.658 | 2024-01-23 15:48:42.990 | 11            | FINISHED |      | NULL     |
+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+
1 row in set (0.00 sec)


</code></pre><p>如果对分词效果不确定，可以使用 TOKENIZE 函数进行分词测试。TOKENIZE 函数接收两个输入：一个是需要进行分词的文本，一个是分词的属性字段。</p><pre><code class="language-SQL">mysql&gt; SELECT TOKENIZE('I can honestly give the shipment and package 100%, it came in time that it was supposed to with no hasels, and the book was in PERFECT condition.
super awesome buy, and excellent for my college classs', '"parser" = "english","support_phrase" = "true"');
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| tokenize('I can honestly give the shipment and package 100%, it came in time that it was supposed to with no hasels, and the book was in PERFECT condition. super awesome buy, and excellent for my college classs', '"parser" = "english","support_phrase" = "true"')                                              |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ["i", "can", "honestly", "give", "the", "shipment", "and", "package", "100", "it", "came", "in", "time", "that", "it", "was", "supposed", "to", "with", "no", "hasels", "and", "the", "book", "was", "in", "perfect", "condition", "super", "awesome", "buy", "and", "excellent", "for", "my", "college", "classs"] |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
1 row in set (0.05 sec)


</code></pre><p>在倒排索引创建完成后，我们使用 <code>MATCH_PHRASE</code> 来查询包含关键词"is super awesome"的产品评论信息（具体需求可回顾前文）。</p><pre><code class="language-SQL">SELECT
    product_id,
    any(product_title),
    AVG(star_rating) AS rating,
    COUNT() AS count
FROM
    amazon_reviews
WHERE
    review_body MATCH_PHRASE 'is super awesome'
GROUP BY
    product_id

ORDER BY
    count DESC,
    rating DESC,
    product_id
LIMIT 5;


</code></pre><p>以上述代码示例进行说明，<code>review_body MATCH_PHRASE 'is super awesome'</code> 表示对 <code>review_body</code> 列进行短语匹配查询。具体而言，查询会在 <code>review_body</code> 中按照英文分词后，寻找同时包含 "is"、"super" 和 "awesome" 这三个词语的文本片段，同时要求这三个词语的顺序是 "is" 在前，"super" 在中间，"awesome" 在后，并且词语之间没有间隔（不区分大小写）。</p><p>这里需要说明的是，MATCH 与 LIKE 查询的差异在于，MATCH 查询时会忽略大小写，把句子切分成一个个词来匹配，能够更快速定位符合条件的结果，特别是在大规模数据集情况下，MATCH 的效率提升更为明显。</p><p>执行结果如下所示，<strong>开启倒排索引后查询耗时仅 0.19 秒，性能较仅开启 Ngram BloomFilter 索引时提升了 4 倍，较未开启索引时提升了近 40 倍，极大幅度提升了文本检索的效率。</strong></p><pre><code class="language-SQL">+------------+------------------------------------------+-------------------+-------+
| product_id | any_value(product_title)                 | rating            | count |
+------------+------------------------------------------+-------------------+-------+
| B00992CF6W | Minecraft                                | 4.833333333333333 |    18 |
| B009UX2YAC | Subway Surfers                           |               4.7 |    10 |
| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |                 5 |     7 |
| B0086700CM | Temple Run                               |                 5 |     6 |
| B00KWVZ750 | Angry Birds Epic RPG                     |                 5 |     6 |
+------------+------------------------------------------+-------------------+-------+
5 rows in set (0.19 sec)


</code></pre><p>究其加速原因可知，倒排索引是通过将文本分解为单词，并建立从单词到行号列表的映射。这些映射关系按照单词进行排序，并构建跳表索引。在查询特定单词时，可以通过跳表索引和二分查找等方法，在有序的映射中快速定位到对应的行号列表，进而获取行的内容。<strong>这种查询方式避免了逐行匹配，将算法复杂度从 O（n） 降低到 O（logn），在处理大规模数据时能显著提高查询性能。</strong></p><p><img src="https://cdn.selectdb.com/static/_c6e7b4f9ab.png" alt="倒排索引原理示意图" referrerpolicy="no-referrer"></p><p>为深入了解倒排索引的加速原理，需从倒排索引内部引读写逻辑说起。在 Doris 中，从逻辑角度来看，倒排索引应用于表的列级别，而从物理存储和实现角度来看，倒排索引实际是建立在数据文件级别上的。具体如下：</p><ul><li><strong>写入阶段：</strong> 数据在写入数据文件的同时，也将同步写入排索引文件中，对于每个写入数据的行号，均与倒排索引中的行号一一对应的。</li><li><strong>查询阶段：</strong> 如果查询 <code>WHERE</code> 条件中包含已建立倒排索引的列，Doris 会自动查询索引文件，返回满足条件的行号列表，再利用 Doris 通用的行号过滤机制，跳过不必要的行和页面，只读取满足条件的行，以达到查询加速的效果。</li></ul><p>总的来说，Doris 的倒排索引机制在物理层面是通过数据文件和索引文件配合工作，而在逻辑层面则通过列和行的映射来实现高效的数据检索和查询加速。</p><span id="OSC_h2_7"></span><h2>非主键列查询加速</h2><p>为了进一步验证倒排索引对非主键列查询加速的影响，我们选择对产品 ID 和用户 ID 的维度信息进行查询。</p><span id="OSC_h3_8"></span><h3>未开启倒排索引</h3><p>当查询用户 13916588 对产品 B002DMK1R0 的评论信息时，执行以下 SQL 语句进行查询时，需要对全表数据进行扫描，<strong>查询耗时为 1.81 秒。</strong></p><pre><code class="language-SQL">mysql&gt; SELECT product_title,review_headline,review_body,star_rating 
FROM amazon_reviews 
WHERE product_id='B002DMK1R0' AND customer_id=13916588;
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| product_title                                                   | review_headline      | review_body                                                                                                                 | star_rating |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| Magellan Maestro 4700 4.7-Inch Bluetooth Portable GPS Navigator | Nice Features But... | This is a great GPS. Gets you where you are going. Don't forget to buy the seperate (grr!) cord for the traffic kit though! |           4 |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
1 row in set (1.81 sec)


</code></pre><span id="OSC_h3_9"></span><h3>倒排索引查询加速</h3><p>接下来，我们为 <code>product_id</code> 和 <code>customer_id</code> 添加倒排索引。在这个场景中，倒排索引的使用与文本搜索时不同，该场景无需对 <code>product_id</code> 和 <code>customer_id</code> 进行分词，只需对这两列的 Value→RowID 的创建倒排映射表。</p><p>首先，通过执行以下 SQL 语句创建倒排索引：</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX product_id_inverted_idx(product_id) USING INVERTED ;
ALTER TABLE amazon_reviews ADD INDEX customer_id_inverted_idx(customer_id) USING INVERTED ;
BUILD INDEX product_id_inverted_idx ON amazon_reviews;
BUILD INDEX customer_id_inverted_idx ON amazon_reviews;


</code></pre><p>其次，当索引构建完成后，执行同样的查询语句，<strong>查询耗时从 1.81 秒降到了 0.06 秒</strong>，查询耗时显著降低，相比未添加索引的情况，<strong>查询效率提升了约 30 倍。</strong></p><pre><code class="language-SQL">mysql&gt; SELECT product_title,review_headline,review_body,star_rating FROM amazon_reviews WHERE product_id='B002DMK1R0' AND customer_id='13916588';
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| product_title                                                   | review_headline      | review_body                                                                                                                 | star_rating |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| Magellan Maestro 4700 4.7-Inch Bluetooth Portable GPS Navigator | Nice Features But... | This is a great GPS. Gets you where you are going. Don't forget to buy the seperate (grr!) cord for the traffic kit though! |           4 |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
1 row in set (0.06 sec)

</code></pre><p>通过观察可发现，倒排索引在于类似非主键列的维度查询中具有非常出色的加速效果。为更深入且直观的查看加速效果，可通过 Doris Profile 信息来进一步探索。</p><span id="OSC_h3_10"></span><h3>Profile 分析</h3><p>需要注意的是，在开启查询的 Profile 之前，需先在 MySQL 客户端执行 <code>SET enable_profile=true;</code> 命令。完成后再执行查询语句，并访问 http://FE_IP:FE_HTTP_PORT/QueryProfile， 来查看与本次查询相关的 Profile ID 以及详细的 Profile 信息。</p><p>本文中仅截取一个特定片段的 SegmentIterator Profile 信息来说明倒排索引查询加速原因。</p><pre><code class="language-YAML">SegmentIterator:
  - FirstReadSeekCount: 0
  - FirstReadSeekTime: 0ns
  - FirstReadTime: 13.119ms
  - IOTimer: 19.537ms
  - InvertedIndexQueryTime: 11.583ms
  - RawRowsRead: 1
  - RowsConditionsFiltered: 0
  - RowsInvertedIndexFiltered: 16.907403M (16907403)
  - RowsShortCircuitPredInput: 0
  - RowsVectorPredFiltered: 0
  - RowsVectorPredInput: 0
  - ShortPredEvalTime: 0ns
  - TotalPagesNum: 27
  - UncompressedBytesRead: 3.71 MB
  - VectorPredEvalTime: 0ns

</code></pre><p>从上述 Profile 中的 <code>RowsInvertedIndexFiltered: 16.907403M (16907403) 以及 RawRowsRead: 1</code>，我们可以观察到：倒排索引过滤了 16907403 行数据，最终只保留 1 行数据（即命中的那条数据）。根据 <code>FirstReadTime: 13.119ms</code> 可知，在读取这行数据所在的页面（page）耗时 13.119 ms，而根据<code>InvertedIndexQueryTime: 11.583ms</code> 可知，倒排索引执行时间仅耗时 11.58 ms。<strong>这意味着倒排索引仅在 11.58 ms 内过滤了 16907403 行数据，执行效率非常高。</strong></p><p>为更直接对比，接下来展示未增加倒排索引情况下 SegmentIterator 的执行情况：</p><pre><code class="language-YAML">SegmentIterator:
  - FirstReadSeekCount: 9.374K (9374)
  - FirstReadSeekTime: 400.522ms
  - FirstReadTime: 3s144ms
  - IOTimer: 2s564ms
  - InvertedIndexQueryTime: 0ns
  - RawRowsRead: 16.680706M (16680706)
  - RowsConditionsFiltered: 226.698K (226698)
  - RowsInvertedIndexFiltered: 0
  - RowsShortCircuitPredInput: 1
  - RowsVectorPredFiltered: 16.680705M (16680705)
  - RowsVectorPredInput: 16.680706M (16680706)
  - RowsZonemapFiltered: 226.698K (226698)
  - ShortPredEvalTime: 2.723ms
  - TotalPagesNum: 5.421K (5421)
  - UncompressedBytesRead: 277.05 MB
  - VectorPredEvalTime: 8.114ms


</code></pre><p>根据上述 Profile 观察可知，由于没有索引进行过滤， FirstRead 需要花费 3.14s 的时间来加载 16680706 行数据，然后使用 Predicate Evaluate 进行条件过滤，过滤掉其中 16680705 行，而条件过滤本身只消耗了不到 10ms 的时间，由此可见，大部分时间被消耗在加载原始数据上。</p><p>通过对比可知，建立倒排索引可以大大减少加载原始数据的时间，提高查询的执行效率。索引能够快速定位满足条件的行，从而减少不必要的数据加载和处理，节省时间和资源。</p><span id="OSC_h2_11"></span><h2>低基数文本列索引加速</h2><p>众所周知，倒排索引对于高基数文本列的查询来说，加速效果十分显著。然而，在低基数列的情况下，可能由于需创建过多的索引项而导致更大的开销，从而对查询性能产生负面影响。接下来，我们将以 <code>product_category</code> 作为谓词列进行过滤，来检验 Apache Doris 倒排索引在低基数文本列的加速效果如何。</p><pre><code class="language-SQL">mysql&gt; SELECT COUNT(DISTINCT product_category) FROM amazon_reviews ;
+----------------------------------+
| count(DISTINCT product_category) |
+----------------------------------+
|                               43 |
+----------------------------------+
1 row in set (0.57 sec)


</code></pre><p>通过上述操作可知，到 <code>product_category</code> 仅有 43 种分类，是一个典型的低基数文本列。接下来，我们对其增加倒排索引</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX product_category_inverted_idx(`product_category`) USING INVERTED;
BUILD INDEX product_category_inverted_idx ON amazon_reviews;

</code></pre><p>添加倒排索引之后，运行如下 SQL 查询，指查询产品分类为 Mobile_Electronics 产品中评价数量最多的前三名产品信息</p><pre><code class="language-SQL">SELECT 
    product_id,
    product_title,
    AVG(star_rating) AS rating,
    any(review_body),
    any(review_headline),
    COUNT(*) AS count 
FROM 
    amazon_reviews 
WHERE 
    product_category = 'Mobile_Electronics' 
GROUP BY 
    product_title, product_id 
ORDER BY 
    count DESC 
LIMIT 10;


</code></pre><p>从下方结果可知，增加倒排索引之后，查询耗时为 1.54s。</p><pre><code class="language-SQL">+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+
| product_id | product_title                                                                                                                                                                                          | rating             | any_value(review_body)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | any_value(review_headline)      | count |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+
| B00J46XO9U | iXCC Lightning Cable 3ft, iPhone charger, for iPhone X, 8, 8 Plus, 7, 7 Plus, 6s, 6s Plus, 6, 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](Black and White) | 4.3766233766233764 | Great cable and works well. Exact fit as Apple cable. I would recommend this to anyone who is looking to save money and for a quality cable.                                                                                                                                                                                                                                                                                                                                                             | Apple certified lightning cable |  1078 |
| B004911E9M | Wall AC Charger USB Sync Data Cable for iPhone 4, 3GS, and iPod                                                                                                                                        | 2.4281805745554035 | A total waste of money for me because I needed it for a iPhone 4.  The plug will only go in upside down and thus won't work at all.                                                                                                                                                                                                                                                                                                                                                                      | Won't work with a iPhone 4!     |   731 |
| B002D4IHYM | New Trent Easypak 7000mAh Portable Triple USB Port External Battery Charger/Power Pack for Smartphones, Tablets and more (w/built-in USB cable)                                                        | 4.5216095380029806 | I bought this product based on the reviews that i read and i am very glad that i did. I did have a problem with the product charging my itouch after i received it but i emailed the company and they corrected the problem immediately. VERY GOOD customer service, very prompt. The product itself is very good. It charges my power hungry itouch very quickly and the imax battery power lasts for a long time. All in all a very good purchase that i would recommend to anyone who owns an itouch. | Great product &amp; company         |   671 |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+
3 rows in set (1.54 sec)


</code></pre><p>接下来，我们关闭倒排索引，以观察未加倒排索引时的查询耗时。这里需要说明的是，当需要关闭索引或在增加索引后发现效果不理想，可以在 MySQL 客户端中执行 <code>set enable_inverted_index_query=false;</code>，便捷且快速地临时关闭倒排索引。我们再次运行查询 SQL，如下所示，查询耗时为 1.8s。</p><pre><code class="language-SQL">+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+
| product_id | product_title                                                                                                                                                                                          | rating             | any_value(review_body)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | any_value(review_headline)            | count |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+
| B00J46XO9U | iXCC Lightning Cable 3ft, iPhone charger, for iPhone X, 8, 8 Plus, 7, 7 Plus, 6s, 6s Plus, 6, 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](Black and White) | 4.3766233766233764 | These cables are great. They feel quality, and best of all, they work as they should. I have no issues with them whatsoever and will be buying more when needed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Just like the original from Apple     |  1078 |
| B004911E9M | Wall AC Charger USB Sync Data Cable for iPhone 4, 3GS, and iPod                                                                                                                                        | 2.4281805745554035 | I ordered two of these chargers for an Iphone 4. Then I started experiencing weird behavior from the touch screen. It would select the wrong area of the screen, or it would refuse to scroll beyond a certain point and jump back up to the top of the page. This behavior occurs whenever either of the two that I bought are attached and charging. When I remove them, it works fine once again. Needless to say, these items are being returned.                                                                                                                                                                                                                                                                                                                                                                              | Beware - these chargers are defective |   731 |
| B002D4IHYM | New Trent Easypak 7000mAh Portable Triple USB Port External Battery Charger/Power Pack for Smartphones, Tablets and more (w/built-in USB cable)                                                        | 4.5216095380029806 | I received this in the mail 4 days ago, and after charging it for 6 hours, I've been using it as the sole source for recharging my 3Gs to see how long it would work.  I use my Iphone A LOT every day and usually by the time I get home it's down to 50% or less.  After 4 days of using the IMAX to recharge my Iphone, it finally went from 3 bars to 4 this afternoon when I plugged my iphone in.  It charges the iphone very quickly, and I've been topping my phone off (stopping around 95% or so) twice a day.  This is a great product and the size is very similar to a deck of cards (not like an iphone that someone else posted) and is very easy to carry in a jacket pocket or back pack.  I bought this for a 4 day music festival I'm going to, and I have no worries at all of my iphone running out of juice! | FANTASTIC product!                    |   671 |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+
3 rows in set (1.80 sec)


</code></pre><p>综上可知，倒排索引对于低基数列场景也有 15% 的查询性能提升，虽不如高基数列场景的提升效果，但并未产生退化效果或负面影响。此外，Apache Doris 针对低基数列采用了较好的编码（如字典编码）方式和压缩技术，并且可以通过内置索引（如 zonemap）进行有效过滤。因此，即使不添加倒排索引仍能展现较好的查询效果。</p><span id="OSC_h2_12"></span><h2>总结语</h2><p>总而言之，Apache Doris 中的倒排索引显著优化了针对谓词列的过滤操作，即 SQL 查询中的 Where 子句。通过精确匹配行号，减少了存储层需要扫描的数据量，从而提高了查询性能。即使在性能提升有限的情况下，倒排索引也不会对查询效率产生负面影响。此外，倒排索引还支持轻量级的索引管理操作，如对增加或删除索引（ADD/DROP INDEX）以及构建索引（BUILD INDEX）操作进行管理。同时，还提供了在 MySQL 客户端便捷地启用或关闭索引（enable_inverted_index_query=true/false）的功能，使用户能够轻松利用倒排索引来检验查询加速效果。</p><p>倒排索引和 NGram Bloom Filter 索引为不同场景提供了查询加速方案，在选择索引类型时，数据集的特定特征和查询模式是关键考虑因素。以下是一些常见的适配场景：</p><ul><li><strong>大规模数据非主键列点查场景：</strong> 在这种场景下，往往存在大量分散的数值列在值，且查询的值命中量很低。为了加速查询，除了在建表时利用 Doris 内置的智能索引能力之外，还可以通过给对应的列增加倒排索引来加速查询。倒排索引对字符类型、数值类型、日期等标量类型支持比较完整。</li><li><strong>短文本列的文本检索场景：</strong> 如果短文本分布比较离散（即文本之间相似度低），则适合使用 Ngram Bloom Filter 索引，能够有效地处理短文本的模糊匹配查询（LIKE）。同时，在短文本场景下 Apache Doris 的向量化处理能力可以得到更加充分和高效的应用和发挥。如果短文本分布比较集中（如大量文本相似，少量文本不同），则适合使用倒排分词索引，这样可以保证词典比较小，适合快速检索获取行号列表。</li><li><strong>长文本列的文本搜索场景：</strong> 针对长文本列，倒排分词索引是更好的方案。相比于暴力字符串匹配，倒排索引提供了更高效的查询性能，避免了大量的 CPU 资源消耗。</li></ul><p>自 Apache Doris 最早引入倒排索引至今已有近一年时间，从，早期 2.0 Preview 版本至最近发布的 2.0.4，这一年间经历了大量开源用户在真实业务环境海量数据下的打磨和验证，性能与稳定性已经得到充分验证。而在后续的规划中，我们也将持续在现有基础上进行迭代和优化，包括：</p><ul><li><strong>自定义倒排索引分词能力，</strong> 针对用户在不同场景下分词效果的需求，提供用户对自定义分词器。</li><li><strong>支持更多类型的倒排索引，</strong> 后续会增加对 Array、Map 等复杂数据类型的支持，以更全面地满足各类查询需求。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 03:12:56 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5735652/blog/10946708</guid>
            <link>https://my.oschina.net/u/5735652/blog/10946708</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大神只用 Excel 就构建了一颗 CPU：具有 128kb RAM、配备汇编语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>YouTube 科技博主「Inkbox」近日发布视频介绍如何在 Microsoft Excel 的限制下构建功能齐全 CPU。Inkbox 称没有使用任何 Visual Basic 脚本或插件 —— 完全用 Excel 实现。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-b39e1a5e12f6b2b05206163af0964e75039.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D5rg7xvTJ8SU" target="_blank">https://www.youtube.com/watch?v=5rg7xvTJ8SU</a></u></em></p></blockquote><p>据介绍，这是一颗 16 位 CPU，在 Excel 中构建并以 3Hz 时钟频率运行，具有 128KB RAM、16 色 128x128 像素显示屏和自定义汇编语言，所有这些都在 Excel 中运行。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-05bafb20ee50b854fae8d35fd3dd39d81d6.png" referrerpolicy="no-referrer"></p><p>这个 Excel CPU 项目最令人印象深刻的壮举之一是 Inkbox 为其创建了功能完整的<strong>汇编语言 Excel-ASM16</strong>，它包含 23 种不同的指令，并支持变量、标签，甚至二进制文件。虽然这些是汇编语言的基本功能，但对于在 Microsoft Excel 下运行的 16 位 CPU 的限制来说已经足够了。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d48c1c2c41f8b1cdf10a21f3aeef8642108.png" referrerpolicy="no-referrer"></p><p>如果各位感兴趣，可通过作者在 GitHub 提供的文件来尝试：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FInkboxSoftware%2FexcelCPU" target="_blank">https://github.com/InkboxSoftware/excelCPU</a></u></em>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aae05a6c21c604e1ec7a527008912e357a2.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276824/16-bit-cpu-built-and-runs-in-excel</guid>
            <link>https://www.oschina.net/news/276824/16-bit-cpu-built-and-runs-in-excel</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
