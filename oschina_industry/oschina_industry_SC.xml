<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 26 Dec 2023 12:30:34 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[邀请好友使用 BaiduComate，赢取丰厚京东卡奖励！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2><span><span><strong><strong><span><span><strong>什么是 BaiduComate？</strong></span></span></strong></strong></span></span></h2><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>BaiduComate 是基于文心大模型，结合百度积累多年的编程现场大数据和外部优秀开源数据，为你生成更符合实际研发场景的优质代码的智能代码助手。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>Comate 目前可以通过自然语言及上下文，帮你生成代码，更能契合您的个人代码风格和业务需求，帮您提高编码效率，更有技术问答来帮您解答编码过程中遇到的技术难题。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>同时 Comate 能够帮您智能生成单元测试、快速生成代码注释、为您的代码内容提供优化建议，让您从繁杂零碎的工作中解放出来。</span></span></span></span></p><h2><span><span><strong><strong><span><span><strong>什么活动？</strong></span></span></strong></strong></span></span></h2><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>参与积分榜活动，邀请好友注册并使用 BaiduComate，即可轻松赢取丰厚的京东卡奖励。</span></span></span></span></p><h2><span><span><strong><strong><span><span><strong>活动怎么玩？</strong></span></span></strong></strong></span></span></h2><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>一、活动时间：</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 12 月 26 日至 2023 年 12 月 31 日。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>二、活动内容：</strong></span></span></strong></span></span></p><ol><li><span><span>登录 Comate（</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcomate.baidu.com%2F" target="_blank"><u><span><span style="color:#3f83f8"><u><span>https://comate.baidu.com/</span></u></span></span></u></a><span><span>)，进入个人中心，分享您的专属链接给好友，邀请好友注册并使用 Comate；</span></span></li><li><span><span>您可以通过分享您的专属链接或生成您的专属二维码向您的好友分享；</span></span></li></ol><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img alt="" height="166" src="https://static.oschina.net/uploads/space/2023/1226/185627_hIls_4252687.png" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img alt="" height="149" src="https://static.oschina.net/uploads/space/2023/1226/185655_vMNA_4252687.png" width="700" referrerpolicy="no-referrer"></p><p><span><span>好友通过您的链接使用 Comate 后，您和您的好友将共同获得 10 积分；</span></span></p><p><span><span>邀请的好友越多，获得的京东卡奖励越丰厚，您可在积分榜活动页查看活动详情（</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcomate.baidu.com%2F1%2Factivity" target="_blank"><u><span><span style="color:#3f83f8"><u><span>https://comate.baidu.com/1/activity</span></u></span></span></u></a><span><span>）。</span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img alt="" height="299" src="https://static.oschina.net/uploads/space/2023/1226/185733_Gean_4252687.png" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>三、活动奖励：</strong></span></span></strong></span></span></p><ol><li><span><span>积分超过 500 分且总排行榜前 20 名，可得 500 京东卡；</span></span></li><li><span><span>积分超过 200 分且总排行榜前 100 名，可得 200 京东卡；</span></span></li><li><span><span>积分超过 100 分且总排行榜前 200 名，可得 100 京东卡；</span></span></li><li><span><span>积分超过 50 分且总排行榜前 400 名，可得 50 京东卡；</span></span></li><li><span><span>其他有积分的用户，可以兑换 Baidu Comate 的使用时长，10 积分可兑换一个月的使用时长；</span></span></li><li><span><span>总排行榜前三且积分超过 500 分的用户，可额外获得神秘大奖！</span></span></li></ol><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>四、活动规则：</strong></span></span></strong></span></span></p><ol><li><span><span><span style="color:#1c1d1f">被分享人注册并使用 Comate 后，分享人和被分享人均加 10 分；</span></span></span></li><li><span><span>活动期间内，邀请的好友数量不设上限；</span></span></li><li><span><span>相同积分的用户，按照最后一名被邀请用户的使用先后顺序进行排序；</span></span></li><li><span><span>京东卡将在活动结束后 15 个工作日内发放至用户账户；</span></span></li><li><span><span><span style="color:#1c1d1f">更多规则详见 Comate 官网活动页</span></span></span><span><span>。</span></span></li></ol><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>与好友一起探索 Comate 的无限可能，让智能云技术为您的代码添色。现在，就通过您的专属链接邀请好友加入 Comate，共同开启智能新篇章！</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 10:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272829</guid>
            <link>https://www.oschina.net/news/272829</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[信通院发布《人工智能伦理治理研究报告（2023 年）》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">2023 年 12 月 26 日，中国信息通信研究院（简称「中国信通院」）在「2024 中国信通院 ICT 深度观察报告会」科技伦理治理分论坛上发布了《人工智能伦理治理研究报告（2023 年）》。</span></p><p style="margin-left:0; margin-right:0">报告在总结人工智能伦理治理有关概念和特点的基础上，对人工智能生成内容、自动驾驶、智慧医疗三个典型应用场景的伦理风险进行分析，并结合国内外人工智能伦理治理实践，提出人工智能伦理治理的四点展望，以期为更加广泛深入的讨论提供参考。</p><p style="margin-left:0; margin-right:0"><img alt="" height="424" src="https://oscimg.oschina.net/oscnet/up-c579b9404f2057e3d9c3aea95b7c78ca41e.png" width="300" referrerpolicy="no-referrer"></p><h4 style="margin-left:0px; margin-right:0px"><strong>报告核心观点</strong></h4><p style="margin-left:0; margin-right:0"><strong>1. 人工智能伦理风险挑战亟需关注</strong></p><p style="margin-left:0; margin-right:0">目前，人工智能引发的伦理挑战已从理论研讨变为现实风险。在技术研发阶段，由于人工智能技术开发主体在数据获取和使用、算法设计、模型调优等方面还存在技术能力和管理方式的不足，可能产生偏见歧视、隐私泄露、错误信息、不可解释等伦理风险。在产品研发与应用阶段，人工智能产品所面向的具体领域、人工智能系统的部署应用范围等将影响人工智能伦理风险程度，并可能产生误用滥用、过度依赖、冲击教育与就业等伦理风险。对于人工智能生成内容、自动驾驶、智慧医疗等典型应用场景，需要根据风险发生频率、影响范围、影响程度等评估主要风险。</p><p style="margin-left:0; margin-right:0"><strong>2. 人工智能伦理治理是应对人工智能风险的有效机制</strong></p><p style="margin-left:0; margin-right:0">人工智能伦理治理是人工智能治理的重要组成部分，是应对人工智能风险挑战的主要机制。人工智能伦理治理把以人为本、公平非歧视、透明可解释、人类可控制、责任可追溯、可持续发展等作为核心内容，并根据人工智能技术发展和应用情况，及时提出调整人与人工智能关系和应对人工智能风险的方法。</p><p style="margin-left:0; margin-right:0"><strong>3. 各国积极推进人工智能伦理治理</strong></p><p style="margin-left:0; margin-right:0">为应对人工智能技术应用带来的风险，世界各国积极推动人工智能伦理国际治理合作。各国政府通过出台人工智能伦理原则、发布人工智能伦理治理指引、提供技术治理工具等加强本国本地区的人工智能伦理治理监管。我国通过积极完善人工智能伦理制度规范，探索人工智能伦理治理技术化、工程化、标准化落地措施，引导行业自律，加强人工智能治理国际合作等举措推动人工智能向善发展。</p><p style="margin-left:0; margin-right:0"><strong>4. 人工智能伦理治理四点展望</strong></p><p style="margin-left:0; margin-right:0">在治理理念方面，坚持促进创新与防范风险相统一，统筹发展与安全。在治理举措方面，健全多学科多主体合作、探索分类分级治理、推动治理技术工具开发。在能力建设方面，重视科研人员、开发人员、社会公众等各主体科技伦理素养提升。在开放合作方面，积极参与全球人工智能伦理治理合作，推动人工智能技术造福人类。</p><hr><p style="margin-left:0; margin-right:0">完整报告地址：<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.caict.ac.cn%2Fkxyj%2Fqwfb%2Fztbg%2F202312%2Ft20231226_468983.htm" target="_blank">http://www.caict.ac.cn/kxyj/qwfb/ztbg/202312/t20231226_468983.htm</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 09:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272816</guid>
            <link>https://www.oschina.net/news/272816</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年各编程语言中最流行的许可证]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">OSI 所属的&nbsp;Voices of Open Source 发布了一篇「<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.opensource.org%2Fthe-most-popular-licenses-for-each-language-2023%2F" target="_blank">2023 年每种语言中最流行的许可证</a>」的文章，揭示了每种编程语言生态系统中的许可偏好，并强调了清晰和标准化许可证对开发人员、组织和整个开源社区健康的重要性。</span></p><p><span style="color:#000000">文章指出，MIT 和 Apache 2.0 许可证在不同的编程语言和包管理器中最为普遍。JavaScript 社区通常倾向于使用 MIT 许可证，Python 开发人员则偏爱 Apache 2.0。ISC 许可证以其简单性和宽容性在 JavaScript 社区中颇受欢迎。BSD 许可证（包括 3-Clause 和 2-Clause）保持稳定但相对较低的采用率。GPL 也有一定的影响力，但落后于 MIT 和 Apache 2.0。</span></p><h4><strong><span style="color:#000000">Javascript (npm)</span></strong></h4><p><span style="color:#000000">JavaScript 的 npm 软件包管理器中，大多数组件采用的是 MIT 许可（53%），其次是 Apache 2.0（14.76%）和 ISC（10.48%）。ISC 许可证由 Internet Systems Consortium 发布，虽然在 JavaScript 项目中很流行，但在其他编程语言中使用得并不多。小部分项目没有许可证（8%）或或是没有 SPDX 识别的许可证/无声明（5.49%）。</span></p><p><span style="color:#000000"><img alt="" height="275" src="https://oscimg.oschina.net/oscnet/up-6f1b2371f321720b27dc902d1b1b82de159.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong><span style="color:#000000">.NET (Nuget)</span></strong></h4><p><span style="color:#000000">而在 .NET 的包管理器 Nuget 中，最令人担忧的点在于，它的大部分组件要么没有许可证（26.76%），要么被认定为"NOASSERTION"（31.95%）。使用 MIT 或 Apache 2.0 许可的比例分别为 21.55% 和 13.37%。</span></p><p><span style="color:#000000"><img alt="" height="286" src="https://oscimg.oschina.net/oscnet/up-9a25d804c9c72bfbf419888c776e096bf8c.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong><span style="color:#000000">Java (Maven)</span></strong></h4><p><span style="color:#000000">Maven (Java 的包管理器) 中的绝大多数组件都使用 Apache 2.0 许可证（69.18%），使用 MIT 的组件仅占 7.4%。此外，被归类于 NOASSERTION 的组件占比为 14.75%。</span></p><p><span style="color:#000000"><img alt="" height="283" src="https://oscimg.oschina.net/oscnet/up-7beb2e608f1e7aed00f71e9ef72300b8bf4.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong><span style="color:#000000">Python (Pypi)</span></strong></h4><p><span style="color:#000000">在 Python 的包管理器 Pypi 中，MIT 和 Apache 2.0 许可下的组件占主导地位，分别为 29.14% 和 23.98%。BSD 2-Clause 和 GPL 3.0 下的组件分别占 6.25% 和 6.11%，还有相当一部分组件没有许可（23.69%）。</span></p><p><span style="color:#000000"><img alt="" height="282" src="https://oscimg.oschina.net/oscnet/up-8a891bd50b9f1b941ece9f07d7b367b19c3.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong><span style="color:#000000">Ruby（Gem）</span></strong></h4><p><span style="color:#000000">Gem（Ruby 的包管理器）中绝大多数组件都使用 MIT 许可证 (63.11%)。其次是 Apache 2.0 和 BSD 3-Clause 许可证，分别占 8.22% 和 6.66%。</span></p><p><span style="color:#000000"><img alt="" height="273" src="https://oscimg.oschina.net/oscnet/up-992730f13a25f44a6e27261837dd4cf2451.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong><span style="color:#000000">PHP（Composer）</span></strong></h4><p><span style="color:#000000">在 PHP 的包管理器 Composer 中，MIT 许可证非常受欢迎，占 64.37%。BSD 3-Clause 和 Apache 2.0 下的项目分别占 5.72% 和 3.92%。</span></p><p><span style="color:#000000"><img alt="" height="277" src="https://oscimg.oschina.net/oscnet/up-924aba8c7c052842a7bd363e09566d1e4cb.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong><span style="color:#000000">Go</span></strong></h4><p><span style="color:#000000">Apache 2.0 和 MIT 许可证在 Go 中占主导地位，分别为 32.49% 和 20.1%。很大一部分 Go 组件没有许可证（29.67%）。</span></p><p><span style="color:#000000"><img alt="" height="293" src="https://oscimg.oschina.net/oscnet/up-ff275f5eef822cdecae73540f0717f58d65.png" width="500" referrerpolicy="no-referrer"></span></p><h4><strong><span style="color:#000000">Rust（Crate）</span></strong></h4><p><span style="color:#000000">对于 crate（Rust 包管理器），使用 MIT 和/或 Apache 2.0 的项目占主导地位，合计占比 83.52%。</span></p><p><span style="color:#000000"><img alt="" height="275" src="https://oscimg.oschina.net/oscnet/up-e115fe1f099762a3b124de0f891eddaaae0.png" width="500" referrerpolicy="no-referrer"></span></p><hr><p><span style="color:#000000">总的来说，虽然市场上已经存在一些成熟的许可证供选择，但仍有<span style="background-color:#ffffff">许多开源组件未指定许可证或标记为 SPDX 「NOASSERTION」。文章指出， 这种模糊性致使此类组件的使用也存在很多不确定性，</span><span style="background-color:#ffffff">可能会阻碍协作、</span><span style="background-color:#ffffff">并给开发者造成法律和安全风险。</span></span></p><p><span style="color:#000000">解决<span style="background-color:#ffffff">无许可证组件的</span>问题对于开源社区的持续健康发展至关重要。开发人员、组织和整个社区都受益于清晰和标准化的许可。它不仅促进协作，还确保法律合规性并保护贡献者的知识产权。此外，它还可以帮助开发人员跟踪可能存在漏洞的组件。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 07:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272790/the-most-popular-licenses-for-each-language-2023</guid>
            <link>https://www.oschina.net/news/272790/the-most-popular-licenses-for-each-language-2023</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[如何在手机上使用 Linux＆如何培养多路径开发思维？2023 年 12 月 WHLUG 回顾]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 12 月 23 日下午，由 deepin（深度）社区主办的武汉 Linux 用户组沙龙（WHLUG）成功举行，20 余名 Linux 爱好者齐聚一堂，10 余名外地伙伴线上参与，共同度过 2023 年最后一场 WHLUG。</p><p>现在，一起来回顾本次年末收官活动的精彩瞬间吧！</p><h1>关于 Droidian 发行版的种种</h1><p>本次沙龙上，archiemeng 为大家分享了 Droidian 发行版的相关内容并进行了现场演示。Droidian 是一个基于 GNOME 的 Linux 手机端发行版，在提供基础 Linux 手机应用的同时，对桌面应用有较完整的适配，且通过 Waydroid 对 Android 应用进行了一定的支持。</p><p>更重要的是，Droidian 对于上述两种应用均能流畅运行，是一个可玩性极强的发行版。目前社区正在积极踊跃开发中，感兴趣的用户可以自行去官网获取刷机教程，也可以参与移植和开发等工作。</p><p>Droidian 官方网站：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdroidian.org%2F" target="_blank">https://droidian.org/</a></p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-1f2dc7ca1122468904def7e4bc5cc3eb82e.jpg" referrerpolicy="no-referrer"></p><h1>毕业季，引用模块化思路加载开源人生&nbsp;</h1><p>根据之前的话题收集，我们发现很多学生对于如何参与开源社区感到迷茫，所以在本次活动中，ziggy 便从实际经验及当前就业背景出发，分享了学生时期如何参与开源社区并发挥自己的价值，以及如何引用模块化思维在学业或职场中不断打怪升级成长等话题。</p><p>ziggy 通过开源生态适配中的实际案例和项目经验，生动形象地向学生们展示了掌握多领域知识的重要性。在讨论过程中更是充分发挥了社区力量，大家通过经验交流，为某历史遗留问题提供了解决方案。此次分享不仅给学生们提供了实用的指导，也激发了他们对于参与开源社区的热情和信心。</p><p style="text-align:center"><img height="615" src="https://oscimg.oschina.net/oscnet/up-e43d3f96df95ec88fcc0273bac9446650a9.png" width="1046" referrerpolicy="no-referrer"></p><p>值得一提的是，一位在 20 年前就参与 WHLUG 的资深用户也在本月来到现场，并为大家分享了经验和心得。他表示，很多人在开源社区中提问时还略显羞涩，希望大家能够放下顾虑，树立正确的社区参与心态，勇敢参与社区活动，共同推动开源社区的繁荣发展。</p><p style="text-align:center"><img height="683" src="https://oscimg.oschina.net/oscnet/up-cbb21d8467cf3f73da16231cabd999dbe48.png" width="913" referrerpolicy="no-referrer"></p><h1>小彩蛋</h1><p>WHLUG 自 1997 年创建以来，一直专注开源技术讨论和分享，我们致力于为武汉的 Linux 爱好者创建一个不受外界干扰的讨论氛围，让每一个技术爱好者回归技术本质。</p><p>我们诚挚地欢迎<strong>武汉地区的学生/开源爱好者</strong>加入，共同参与到 WHLUG 活动的策划和组织中，同时，热忱欢迎<strong>各高校社团</strong>与我们携手，为构建武汉最纯粹的 Linux 技术圈和推动本地开源发展贡献力量。</p><p>若您对参与活动共建感兴趣，<strong>请点击<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwj.qq.com%2Fs2%2F13816139%2F8b53%2F" target="_blank">「此处」</a>或扫码填写报名表</strong>，我们的工作人员将会与您取得联系，期待与您一同开启这段激动人心的开源之旅！</p><p style="text-align:center"><img height="280" src="https://oscimg.oschina.net/oscnet/up-c7b73e05cc3a7a94a2d131d1c0fea354f78.png" width="290" referrerpolicy="no-referrer"></p><div><div><p><strong>什么是 WHLUG：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fwelcome-to-whlug%2F" target="_blank">武汉 LUG – 深度科技社区</a></strong></p><p><strong>了解 deepin：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Findex%2Fzh" target="_blank">deepin - 基于 Linux 的开源国产操作系</a></strong></p></div></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 07:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272782</guid>
            <link>https://www.oschina.net/news/272782</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[WAVE SUMMIT 迎来第十届，文心一言将有最新披露！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>1</span></span><span><span>0</span></span><span><span>句话 2 分钟，挑战成功说服宿管阿姨开门，这个人群中的「显眼包」是一个接入文心大模型 4</span></span><span><span>.0</span></span><span><span>游戏里的 NPC，妥妥 「工具人」实锤～</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>尝试用</span></span><span><span>AI</span></span><span><span>一键自动识别好坏咖啡豆，看一眼便知好坏，真正「颜值即正义」，让咖啡星人狂喜～</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>借助 AI 在</span></span><span><span>任何平面上模拟</span></span><span><span>的</span></span><span><span>钢琴，</span></span><span><span>即兴「弹奏」世界名曲，开一场科技感满满的专属演奏会～</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>在虚拟世界</span></span><span><span>的</span></span><span><span>神奇办公室，输入你的创业方向，智慧打工人们将为你的项目勤劳奔走，并在过程中，把日报</span></span><span><span>、</span></span><span><span>周报写好，让你随时掌握项目进度和最终成果</span></span><span><span>……</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img height="280" src="https://static.oschina.net/uploads/space/2023/1226/134838_ASJC_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>这些听起来新奇而有趣的 A</span></span><span><span>I</span></span><span><span>应用，都将在两天后举行的 W</span></span><span><span>AVE SUMMIT+深度学习开发者大会 2023</span></span><span><span>开发者市集亮相。</span></span><span><span>作为业界影响力最大的深度学习与大模型开发者大会，WAVE SUMMIT+ 2023</span></span><span><span>定于</span></span><span><span>12 月 28 日</span></span><span><span>在</span></span><span><span>北京开启</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img height="285" src="https://static.oschina.net/uploads/space/2023/1226/134858_tJnB_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>现场大咖云集，</span></span><span><span>百度首席技术官</span></span><span><span>、</span></span><span><span>深度学习技术及应用国家工程研究中心主任王海峰</span></span><span><span>及数百位</span></span><span><span>产业大咖、知名学者、技术大牛、顶尖开源项目发起人等重磅嘉宾，从大模型技术、开源开放、产业护航、软硬一体等议题出发，</span></span><span><span>为开发者奉上大模型时代低门槛开发和创建应用的硬核干货。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>倒计时 2 天，大会的五大亮点带大家抢鲜看。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>亮点一：趋势引领，「扛把子」文心一言将曝新进展</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>今年 1</span></span><span><span>0</span></span><span><span>月 1</span></span><span><span>7</span></span><span><span>日，迄今为止综合实力最强的文心大模型 4</span></span><span><span>.0</span></span><span><span>重磅面世，</span></span><span><span>理解、生成、逻辑、记忆</span></span><span><span>四大能力得到</span></span><span><span>显著提升，大语言模型</span></span><span><span>正在</span></span><span><span>为通用人工智能带来曙光。</span></span><span><span>截至 1</span></span><span><span>1</span></span><span><span>月初，文心一言用户数达到 7</span></span><span><span>000</span></span><span><span>万，场景达</span></span><span><span>4300</span></span><span><span>个。这</span></span><span><span>得益于飞桨与文心的协同优化，</span></span><span><span>文心大模型 4</span></span><span><span>.0</span></span><span><span>的</span></span><span><span>模型周均训练有效率超过 98%，</span></span><span><span>相比于 3 月份，</span></span><span><span>训练算法效率提升</span></span><span><span>至</span></span><span><span>3.6 倍</span></span><span><span>，推理性能提升至 5</span></span><span><span>0</span></span><span><span>倍。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>本次大会，文心一言以及飞桨将披露技术和生态层面的最新进展，更关乎千万开发者的切身使用体验和权益～第十届</span></span><span><span>WAVE SUMMIT</span></span><span><span>，值得期待。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>亮点二：干货十足，硬核低门槛开发秘籍大放送</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>当今，技术圈万众瞩目的</span></span><span><span>A</span></span><span><span>gent 到底是何方神圣，应该怎么打造</span></span><span><span>A</span></span><span><span>gent？</span></span><span><span>大模型与开发工具链相结合，为开发提效提供了哪些</span></span><span><span>新</span></span><span><span>可能？</span></span><span><span>硬件-框架-模型到底怎样协同优化发挥最大效能？开发者们的「趁手利器」</span></span><span><span>C</span></span><span><span>omate 还能怎么用？你想了解的各类技术干货，前沿的科技圈热点，来</span></span><span><span>WAVE SUMMIT+2023</span></span><span><span>，不容错过！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span>亮点三：蓄势待发，大模型赋能产业正当时</span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>大会主论坛之后，聚焦前沿、产业、硬件、开发应用等主题的五大平行论坛同步举行，将</span></span><span><span>大模型前沿技术分享与产业落地的</span></span><span><span>心法一一奉上。</span></span><span><span>科学启智</span></span><span><span>、</span></span><span><span>AI 赋能</span></span><span><span>，</span></span><span><span>AI for Science 塑造多学科研究新范式</span></span><span><span>，跨界融合创新展现</span></span><span><span>巨大应用潜能</span></span><span><span>；大模型产业应用中的标杆先行者放大招：华晨宝马将带来企</span></span><span><span>业级大模型 Agent 服务平台</span></span><span><span>、东方电科新能源功率准确性提升实现能效优化……</span></span><span><span>主流硬件厂商悉数亮相：NVIDIA、Intel、中科曙光、升腾、燧原科技、太初</span></span><span><span>……</span></span><span><span>飞桨硬件生态朋友圈再扩大，生态势能贯通产业链。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span><strong>亮点四：群星闪耀，AI 产业生态星河万里</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>开源开放、众行致远</span></span><span><span>。为</span></span><span><span>持续引导探索产业 AI 关键场景，大会</span></span><span><span>还从</span></span><span><span>开源开放、产业创新等多个维度</span></span><span><span>，</span></span><span><span>评选出 「星河产业应用创新奖」，「文心 x 飞桨最具影响力开发者」</span></span><span><span>等大奖</span></span><span><span>，</span></span><span><span>并将于大会</span></span><span><span>现场颁奖，激发开源创新活力，</span></span><span><span>赋能产业繁荣生态，</span></span><span><span>助推产业智能化</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>W</span></span><span><span>AVE</span></span>&nbsp;<span><span>SUMMIT</span></span><span><span>&nbsp;五年十届，这也是中</span></span><span><span>国 AI 技术生态繁荣与崛起的关键时期。</span></span><span><span>开发者作为中坚力量，为智能世界贡献出自己的智慧；飞桨星河社区以开源开放的姿态，汇聚了开发者们最聪明的大脑。大会将设有开发者相关环节，让大家看到群像背后的一个个故事，感受一点点星光、见证科技让世界更有温度。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><strong><span><span>亮点五：</span></span></strong><strong><span><span><strong>应用繁荣，创意市集与</strong></span></span></strong><strong><span><span><strong>AI</strong></span></span></strong><strong><span><span><strong>原生</strong></span></span></strong><strong><span><span><strong>W</strong></span></span></strong><strong><span><span><strong>orkshop 尽显极客范</strong></span></span></strong></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>这次</span></span><span><span>WAVE SUMMIT+ 2023 为开发者专设多个体验互动环节，</span></span><span><span>前面</span></span><span><span>提到的开发者市集就是其中之一</span></span><span><span>。本次开发者市集上，几十款开发者打造的</span></span><span><span>AI</span></span><span><span>互动小应用，带你沉浸式感受技术的魅力，现场还有开发者亲自讲解、示范，零距离接触那些开发者大神。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><img height="265" src="https://static.oschina.net/uploads/space/2023/1226/134921_vHME_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>此外，大会还为开发者们精心准备了三场</span></span><span><span>Workshop</span></span><span><span>，</span></span><span><span>现场</span></span><span><span>手把手教你</span></span><span><span>打造自己的 AI</span></span><span><span>原生</span></span><span><span>应用</span></span><span><span>。星河探索，智能应用，志在推进高质量、高可用的</span></span><span><span>AI</span></span><span><span>原生应用落地的最后一公里，</span></span><span><span>现场</span></span><span><span>将带来星河社区</span></span><span><span>ERNIE Bot</span></span>&nbsp;<span><span>SDK</span></span><span><span>的能力讲解与实战，帮你解锁文心一言无限可能，还有更多</span></span><span><span>AI</span></span><span><span>原生应用落地和开发实战，</span></span><span><span>玩转原生应用</span></span><span><span>，感受 AI 原生应用魅力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>在经历过下午一系列酣畅的技术烧脑与极客碰撞后，晚上，开发者们可以到「</span></span><span><span>AI 开发者之夜</span></span><span><span>」好好放松一下，在这不仅可以挑战</span></span><span><span>AI 原生小游戏</span></span><span><span>，观看精彩表演，也能「以 AI 会友」，共同奔赴 AI 时代的「诗与远方」。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>随着大模型的爆发，人工智能</span></span><span><span>的风已经吹到</span></span><span><span>社会的</span></span><span><span>各个</span></span><span><span>角落。</span></span><span><span>W</span></span><span><span>AVE SUMMIT+ 2023</span></span><span><span>这场 AI 开发者的「嘉年华」，让每位参会者深入探索基于大模型的 AI 应用，了解技术发展前沿信息和应用风向，在新时代新机遇来临之际，抓住先机，创造更多可能。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 05:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272772</guid>
            <link>https://www.oschina.net/news/272772</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Kuasar 成为 CNCF 官方项目，探索容器运行时新纪元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本文分享自华为云社区《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%2F418445%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" target="_blank" rel="nofollow">Kuasar 成为 CNCF 官方项目，探索容器运行时新纪元！</a>》，作者：云容器大未来。</p><p>北京时间 12 月 20 日，云原生计算基金会（CNCF）正式接纳多沙箱容器运行时项目<span>&nbsp;</span><strong>Kuasar</strong>（https://github.com/kuasar-io/kuasar）。Kuasar 的加入，极大地推动了云原生领域容器运行时技术的探索、创新和发展。</p><p><img alt="11.png" src="https://bbs-img.huaweicloud.com/blogs/img/20231222/1703228593906841756.png" referrerpolicy="no-referrer"></p><p>作为 CNCF 首个多沙箱容器运行时项目，Kuasar 于 2023 年 4 月在 KubeCon + CloudNativeCon Europe 上由华为云、中国农业银行以及 openEuler 社区、WasmEdge 社区和 Quark Containers 社区联合发起。Kuasar 融入了各企业和社区在容器运行时领域的前沿探索、技术积累和生产实践，开源至今受到业界的广泛关注和支持，已收获 900 多个 GitHub Star 和 70 多个 Fork，数十位来自外部企业、高校的开源爱好者参与开发贡献和积极落地应用，Kuasar 正以开源创新的姿态促进云原生产业发展。</p><div><div><div><div><div><p><strong>「WebAssembly 正在快速成为云原生技术栈的一个关键部分，Kuasar 深度集成了高性能、轻量级的 WasmEdge 沙箱，Kuasar 的加入使得 WebAssembly 生态和 CNCF 生态联系更加紧密，未来 WasmEdge 和 Kuasar 将共同推动在大模型、边缘计算和函数计算等领域的发展。」</strong><strong>—— WasmEdge 项目创始人 Michael Yuan</strong></p></div></div></div></div></div><div><div><div><div><div><p><strong>「openEuler 社区在 Kuasar 项目发布之初就率先完成与 Kuasar 多沙箱生态的对接，推出基于 iSulad + Kuasar + StratoVirt 的极速轻量安全容器解决方案。未来 openEuler 社区将继续深化与 CNCF 社区项目的合作，为用户提供更轻量、更安全、更多样的容器化底座。」—— openEuler 技术委员会主席，胡欣蔚</strong></p></div></div></div></div></div><div><div><div><div><div><p><strong>「Kuasar 项目融入了华为云在容器运行时领域多年的积累，结合了社区合作伙伴的实践经验。成为 CNCF 官方项目，表明了 Kuasar 社区开放治理的决心，致力于为企业和开发者提供厂商中立、多方协作的开放环境，促进各种沙箱技术的商用成熟，为用户带来极致体验。」—— CNCF 官方大使，华为云云原生开源团队负责人，王泽锋</strong></p></div></div></div></div></div><div><div><div><div><div><p><strong>「云原生场景多样化促进了多种沙箱技术的蓬勃发展，沙箱技术接入北向生态成为普遍需求，Kuasar 推动了 Containerd 中沙箱技术标准的统一，提供了多种沙箱技术实现，为 CNCF 的容器运行时板块注入了新鲜活力。」—— CNCF 官方大使 Containerd 社区维护者，蔡威</strong></p></div></div></div></div></div><span id="OSC_h2_1"></span><h2>Kuasar 项目介绍</h2><p>为了满足企业在云原生场景下的诉求，业界出现了多种沙箱容器隔离技术。然而，应用云原生的沙箱技术仍面临挑战。一方面，各类云原生场景对沙箱提出更高要求，单一沙箱无法同时满足用户云上业务对安全隔离、极速低噪、标准通用等多个维度的要求，企业面临云原生业务场景全覆盖问题；另一方面，支持多类沙箱带来运维压力显著上升，当前业界沙箱技术对接容器运行时的实现缺乏统一开发框架，因此关键日志、重要事件、沙箱管理逻辑等均存在差异，新引入沙箱的同时运维压力陡增。</p><p>Kuasar 在保留传统容器运行时功能的基础上，与 Containerd 社区一起推动新的沙箱接口统一标准，并通过全面 Rust 化以及优化管理模型框架等手段，进一步降低管理开销，简化调用链路，灵活扩展对业界主流沙箱技术的支持。此外，通过支持多安全沙箱共节点部署，Kuasar 可以充分利用节点资源、降本增效，为用户提供更安全高效的沙箱场景解决方案。</p><p><img alt="12.png" src="https://bbs-img.huaweicloud.com/blogs/img/20231222/1703228609750179875.png" referrerpolicy="no-referrer"></p><p>▲ Kuasar 项目全景图</p><p>南向沙箱方面，Kuasar 已支持基于轻量级虚拟化技术的安全容器沙箱（Cloud Hypervisor、Qemu、StratoVirt），基于新兴的 WebAssembly 沙箱（WasmEdge、Wasmtime），基于进程级虚拟化的 App Kernel 沙箱（Quark）以及基于内核的原生普通容器沙箱（runC）；北向引擎方面，Kuasar 已与 Containerd 联合构建最新的沙箱接口标准，并共同推动该标准在 Containerd v2.0 版本的完整实现。此外，轻量级容器引擎 iSulad 项目也已经完成与 Kuasar 项目的深度集成，支持在 openEuler 23.09 创新版本上一键部署。</p><span id="OSC_h2_2"></span><h2>未来可期</h2><p>此次 CNCF 正式将 Kuasar 接纳为官方项目，将极大促进 Kuasar 上下游社区生态构建及合作。Kuasar 将持续探索云原生容器运行时领域技术创新，在企业数字化、云原生转型过程中发挥作用，让基于 Kuasar 的多沙箱容器运行时方案融入更广泛的云原生技术生态。</p><p>作为 CNCF 亚洲唯一创始成员、白金会员，华为云在 CNCF 贡献量、Kubernetes 社区和 Istio 社区的代码贡献量持续多年稳居亚洲第一，已向 CNCF 贡献了业界首个云原生边缘计算项目 KubeEdge、首个云原生批量算力项目 Volcano、首个多云容器编排项目 Karmada 等多个重量级云原生开源项目，并持续开源 Kurator、Kappital、Kmesh 等创新项目，与全球云原生社区共同发展。</p><span id="OSC_h3_3"></span><h3>Kuasar 社区技术交流地址</h3><p>Kuasar 官网：https://kuasar.io</p><p>项目地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkuasar-io%2Fkuasar" rel="nofollow" target="_blank">https://github.com/kuasar-io/kuasar</a></p><p>Twitter:<span>&nbsp;</span>https://twitter.com/Kuasar_io</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbbs.huaweicloud.com%2Fblogs%3Futm_source%3Doschina%26utm_medium%3Dbbs-ex%26utm_campaign%3Dother%26utm_content%3Dcontent" rel="nofollow" target="_blank"><strong>点击关注，第一时间了解华为云新鲜技术~</strong></a></p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4526289/blog/10412251</guid>
            <link>https://my.oschina.net/u/4526289/blog/10412251</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云原生周刊：Karmada 成为 CNCF 孵化项目]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>开源项目推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Femberstack%2Fkubernetes-reflector" target="_blank">kubernetes-reflector</a></h3><p>Reflector 是一个 Kubernetes 的插件，旨在监视资源（secrets 和 configmaps）的变化，并将这些变化反映到同一命名空间或其他命名空间中的镜像资源中。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsubstratusai%2Flingo" target="_blank">Lingo</a></h3><p>Lingo 是适用于 K8s 的 OpenAI 兼容 LLM 代理和自动缩放器。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fflanksource%2Fcanary-checker" target="_blank">canary-checker</a></h3><p>canary-checker 是一个基于 Kubernetes 的本地平台，用于通过被动和主动（合成）机制监控应用程序和基础架构的健康状况。</p><h2>文章推荐</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40elementtech.dev%2Fkubernetes-image-proxy-cache-from-minutes-to-milliseconds-fd14173e831f" target="_blank">Kubernetes Harbor 图像代理缓存 — 从几分钟到几毫秒</a></h3><p>这篇文章介绍了如何通过使用 Harbor 作为 Kubernetes 的代理缓存来提高容器镜像的拉取速度。文章首先解释了 Kubernetes 中容器镜像的拉取过程和现有的缓存机制的局限性，然后介绍了 Harbor 作为一个 CNCF 项目的作用，并详细说明了 Harbor 的 Pull Through Proxy Cache 机制。该机制可以在本地缓存中存储常用的镜像，当节点需要拉取镜像时，可以直接从本地缓存中获取，减少了网络延迟和带宽消耗。文章还介绍了如何在 Kubernetes 上安装和配置 Harbor，并提供了使用 Harbor 的示例命令。最后，文章介绍了如何通过使用 Harbor Cache Mutating Webhook 来自动让 Kubernetes 使用代理缓存。总体而言，这篇文章详细介绍了如何通过 Harbor 实现快速的镜像缓存，提高容器化环境中的部署效率。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40sushantkapare1717%2Fhelm-vs-kustomize-in-kubernetes-cc063bbb4b0e" target="_blank">Kubernetes 中的 Helm 与 Kustomize</a></h3><p>这篇文章比较了 Helm 和 Kustomize 这两个用于管理 Kubernetes 清单文件的工具。文章首先介绍了 Kubernetes 在现代 IT 基础架构中作为容器编排和管理的事实标准，并指出在规模化部署应用程序时，管理复杂配置和清单文件变得至关重要。然后详细介绍了 Helm 和 Kustomize 这两个工具的特点和优势。Helm 是一个用于简化应用程序部署和管理的 Kubernetes 包管理器，具有模板化、可重用性、版本管理和社区支持等优点。Kustomize 是另一个用于自定义 Kubernetes 清单文件的工具，采用"patch"的方法，支持声明性修改现有清单文件和配置覆盖。文章还提供了使用 Helm 和 Kustomize 的示例，并对它们进行了比较，包括模板化与补丁应用、灵活性和学习曲线等方面。最后，文章强调了根据具体需求和偏好选择适合的工具的重要性，并鼓励读者保持对最新工具和最佳实践的了解，以提高部署效率。</p><h2>云原生动态</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthenewstack.io%2Fkarmada-finally-brings-multicloud-control-to-kubernetes%2F" target="_blank">Karmada 成为 CNCF 孵化项目</a></h3><p>日前，云原生计算基金会的技术监督委员会 (TOC) 投票决定接受 Karmada 作为 CNCF 孵化项目。</p><p>Karmada 通过一组 Kubernetes 原生 API 和高级调度功能，提供了一种跨不同云提供商运行 Kubernetes 集群的方法。它不需要对应用程序本身进行任何更改。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevclass.com%2F2023%2F12%2F12%2Fdocker-buys-atomicjar-to-integrate-container-based-test-automation%2F" target="_blank">Docker 购买 AtomicJar 以集成基于容器的测试自动化</a></h3><p>Docker 购买了 AtomicJar 及其 Testcontainer 项目，为 Docker 提供了更好的测试方案，但引发了对未来许可成本和对其他容器运行时支持的担忧。</p><p>Docker 首席执行官 Scott Johnston 表示，添加 TestContainers 使 Docker 的开发人员工作流程更加完整，为涵盖构建、验证、运行、调试和共享的现有功能添加了测试。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F21%2Fciliums-2023-annual-report%2F" target="_blank">Cilium 2023 年年度报告</a></h3><p>2023 年对于 Cilium 来说是一个重要的里程碑，被称为 Cilium 毕业年。今年，我们看到 Cilium 生态系统在贡献和采用方面都取得了显着增长。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcilium%2Fcilium.io%2Fblob%2Fmain%2FAnnual-Reports%2FCilium%2520Annual%2520Report%25202023.pdf" target="_blank">2023 年 Cilium 年度报告</a>旨在强调这些进步，重点关注 Cilium 贡献者和最终用户社区的增长和活动。</p><p>该报告通过项目里程碑和承诺等数字数据以及社区领导者、最终用户和贡献者的个人见解，全面介绍了社区的健康状况。它深入探讨了几个关键领域：Cilium 毕业进度、贡献者增长、主要发布亮点、2023 年 Cilium 用户调查的反馈、Cilium 在生产环境中的使用情况、社区参与和报价、社区活动以及 2024 年项目方向。</p><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10398476</guid>
            <link>https://my.oschina.net/u/4197945/blog/10398476</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Fedora 40 计划统一 /usr/bin 和 /usr/sbin]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>早在多年前，Fedora 曾合并了 /bin 和 /usr/bin。时至今日，针对 Fedora 40&nbsp;提交的一项最新更改<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffedoraproject.org%2Fwiki%2FChanges%2FUnify_bin_and_sbin" target="_blank">提案</a>则提出，统一其&nbsp;/usr/bin&nbsp;和&nbsp;/usr/sbin&nbsp;位置；因为&nbsp;<span style="background-color:#ffffff; color:#121212">/bin 和 /sbin 之间的划分已不再有用，且无人使用。</span></p><p>提案解释称：</p><blockquote><p>/usr/sbin 目录成为 bin 的 symlink，这意味着 /usr/bin/foo 和 /usr/sbin/foo 等路径指向同一个地方。/bin 和 /sbin 已经是 /usr/bin 和 /usr/sbin 的 symlink，因此 /bin/foo 和 /sbin/foo 实际上也指向同一个地方。/usr/sbin 将从默认的 $PATH 中删除。</p></blockquote><p><img height="219" src="https://oscimg.oschina.net/oscnet/up-ed7d7efd2d93feaf5de7d017798772f87b4.png" width="700" referrerpolicy="no-referrer"></p><p>该变更提案认为这对 packagers 和 end-users 来说都是一种简化，且 Fedora 将与 Debian 等其他 Linux 发行版更加兼容。</p><p><strong><span><span><span style="color:#373a3c"><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span><span>对 Fedora 的好处：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><ul><li>Packagers&nbsp;不必考虑是将程序安装在<code>%_bindir</code>还是<code>%_sbindir</code>。</li><li>用户不必考虑程序是安装在<code>%_bindir</code>还是<code>%_sbindir</code>.</li><li>Fedora 与其他发行版变得更加兼容。「例如，我们有 /sbin/ip，而 Debian 有 /bin/ip；我们有 /bin/chmem 和 /bin/isosize，而 Debian 有 /sbin/chmem 和 /sbin/isosize、 我们还有 /sbin/{addpart,delpart,lnstat,nstat,partx,ping,rdma,resizeepart,ss,udevadm,update-alternatives}，而 Debian 的这些都在 /bin 下，等等。」</li><li>Fedora 与 Arch 更加兼容，Arch 于几年前进行了合并。</li><li><code>execvp</code>和相关函数遍历的目录更少。这对于速度可能并不重要，但在查看日志或<code>strace</code>输出时是一个很好的简化。</li></ul><p><strong><span><span><span style="color:#373a3c"><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span><span>升级/兼容性影响</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span><span style="color:#373a3c"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>对于用户来说，这种变化基本上是不可见的。在过渡过程中，两套路径都应正常工作，用户在<code>$PATH</code>中应同时拥有这两个目录。一旦过渡完成，两套路径都将正常工作，但用户在<code>$PATH</code>中只能看到<code>/usr/bin</code>。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>目前，该变更提案仍处于拟议状态，需得到 FESCo 的批准后才能应用在四月发布的 Fedora 40 中。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272754/fedora-40-unify-usr-bin-sbin</guid>
            <link>https://www.oschina.net/news/272754/fedora-40-unify-usr-bin-sbin</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年度低代码企业 TOP50 榜单公布 — JeecgBoot 连续两年荣登榜单]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p style="margin-left:0; margin-right:0">近日，中国科学院主管、科学出版社主办的国家级核心期刊《互联网周刊》联合 eNet 研究院、德本咨询评选的《2023 低代码企业 50 强》榜单正式公布。这一榜单的公布引起了业内外的广泛关注，因为其中涵盖了低代码开发领域的众多杰出企业，展现了低代码产业的发展趋势和行业格局。</p></blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">在这份备受瞩目的榜单中，知名企业钉钉、腾讯云、华为云等行业优秀厂商的产品悉数入选，充分展现了它们在低代码领域的技术实力和市场影响力。而更加令人瞩目的是，<code>JeecgBoot</code><span>&nbsp;</span>作为低代码开发领域的领军企业，连续两年荣登榜单，凭借其卓越的产品实力和市场表现，再次彰显了其在行业中的领先地位和影响力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">JeecgBoot 低代码平台作为备受认可的低代码开发平台，一直以来致力于为企业提供高效、灵活、可定制的低代码开发解决方案。其产品以简单易用、快速开发、可视化操作等特点而著称，深受广大企业用户的青睐。JeecgBoot 连续两年荣登《2023 低代码企业 50 强》榜单，再次印证了其在低代码开发领域的卓越地位和不断增长的市场影响力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">www.jeecg.com</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" height="330" src="https://oscimg.oschina.net/oscnet/up-458906dcd2cc0cb63a454761d96b1602826.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">同时在 2023 年，JeecgBoot 又推出了 「敲敲云」 零代码产品，将为低代码市场带来新的竞争对手和发展动力。这不仅丰富了 JeecgBoot 的产品线，也为企业用户提供了更多元化的选择。随着低代码和零代码市场的不断发展，我们有理由相信，这将为整个数字化转型领域带来更多的机遇和活力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">www.qiaoqiaoyun.com</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-cad61647c80a1dbdedac3adc1d490cb1917.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img alt="" height="2516" src="https://oscimg.oschina.net/oscnet/up-c3e1f9901ed0f7fbba1f83cc3cf120a9ab1.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272750</guid>
            <link>https://www.oschina.net/news/272750</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[上云？下云？降本增笑？割韭菜？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>本月，滴滴崩溃事件闹得轰轰烈烈，各种离谱派单层出不穷，而造成这一混乱的，则是底层出故障的云。尴尬的是，这已经不是第一次云崩溃事件了，距离上一次阿里云事件，还不到一个月。</p><p>一时之间，各种有关「云」的讨论纷纷扬扬：有人眼馋马斯克的 X 下云省钱，觉得反正都有风险，还不如自己弄，这样更可掌控，也更清楚；有人则认为上云才是未来的趋势，想要发挥出软件的最大优势，上云更合适。</p><p>那么，实际操作中，到底是自建云更安全，还是公有云更有保障？对普通的厂商而言，该怎么选择呢？对此，开源中国邀请了前滴滴软件开发工程师李鹤、AutoMQ 联合创始人 &amp; CTO 周新宇、前淘宝 DBA 蒋明、磐吉云数 CEO 冯若航、公众号《瑞典马工》主理人马工，一起来讨论。</p><p>&nbsp;</p><span id="OSC_h1_1"></span><h1>上云到底有没有必要？云是不是在割韭菜？</h1><p><strong>正方：周新宇 speaking ——</strong></p><p>我个人大概是在 16 年就加入阿里巴巴巴的中间件团队了，服务了很多客户。从我个人的经验来讲：</p><p><strong>第一，没有云之前，硬件出了问题，解决的门槛很高。</strong>阿里内部上云之前，因为消息中间件集群规模很大，硬件它总是在出问题，比如说因为网卡问题导致了 TCD 重视率很高，硬盘出现局部的不可写；比如服务器某个硬件温度过高，导致一些局部的节点不可用。好在阿里有专业的团队帮忙解决，但这在小企业就很难负担了。</p><p><strong>第二，公有云比专有云效率高。</strong>像我们专门做交付，交付完才是第一步，后面有很多的运维工作，这些运维工作，如果我们远程去做的话，效率比较低，如果去驻厂的话，成本又比较高。公有云的模式，通过聚集算力和统一标准，带来了很多效率上的提升。</p><p><strong>第三，云计算能加速业务的创新，提高社会运转效率。</strong>像在线教育行业，几年前，基本上都利用了公有云的优势来快速进行业务的创新。如果没有云计算，如果不上云，这些完全不可能发生。还有疫情期间的远程会议，一定程度上保障了社会各方面的正常运转。背后的钉钉这些企业软件，也都是云计算在提供算力。</p><p>过去，大部分企业还是以云托管的方式上云为主，基本上就是传统的软件架构，通过这个方式进行上云。但不管怎么样，一定程度上解决了效率和创新问题。今天在降本增效的浪潮下，企业用云，可能不能暴力地照搬以前的架构了，架构需要面向云的能力去设计、去优化，把云原生的能力发挥出来。</p><p>&nbsp;</p><p><strong>反方：冯若航 speaking ——</strong></p><p>我比较喜欢用实打实的数据来定量分析云。我的观点是：在降本增效成为主旋律的大背景下，对于有一定规模的云上企业来说，下云自建是一个非常经济务实的选项。我认为公有云它是有适用光谱的，绝对不是他们宣称的数字化万金油。不在这个光谱范围内的业务，如果选择上云，或者是留在云上，那就是被割韭菜了。</p><p><strong>我这有歪诗一首：世人常道云上好，托管服务烦恼少。我言云乃杀猪盘，溢价百倍实厚颜。赛博地主搞垄断，坐地起价剥血汗。运维外包嫖开源，租赁电脑炒概念。</strong></p><p>公有云的商业模式概括起来就是一个事儿：租——租服务器租带宽租磁盘租运维，这跟租房没有什么本质的区别，自建我们就可以类比为买房。那么租房还是买房的决定性因素是什么？我认为是租售比。房子的租售比一般在几百一个月，那大家买房可能要掂量。那么，服务器的租售比、云算力的租售比一般在半年左右使用费=购买价格。云磁盘的租售比就更离谱了，只有十几天到一个月。你用一块云盘十几天就能买下来，你用一台云服务器，六个月就能把它买下来，那么你为什么要把一个业务跑在这租的东西上，而不是直接把它买下来？如果你的业务生命周期超过六个月，你可以考虑把它买下来，而不是租。</p><p>为什么云的价格这么贵？我认为根本原因在硬件上。硬件遵循着摩尔定律在指数增长，成本在指数下降，而这个指数变化并没有在公有云的价格上反映出来，所以公有云从最开始的普惠基础设施，发展到今天变成了一个杀猪盘。它的资源租赁价格已经达到了自建单价的几十倍上百倍，堪称终极的成本刺客。</p><p>这也引发了一些新的变化，比如说马斯克的 X（Twitter）、DHH 的 37Signals，算了账单之后，明智地选择了从云上搬迁下来，节约了每年上千万甚至上亿的成本。我认为，这些案例对于整个行业，都是非常具有借鉴意义的里程碑标志。</p><p>所以，<strong>我认为云的适用光谱就是三件事——小规模，高弹性，全球化。不在这三个场景之内的业务，你选择留在云上，就是在为几倍几十倍的溢价交智商税、被割韭菜。</strong></p><p>&nbsp;</p><p><strong>正方：周新宇 speaking ——</strong></p><p>我觉得这里面有一个误区，<strong>不能拿这个硬件的成本去跟软件、甚至跟云服务对比。</strong>比如说冯总以前写过一篇文章，就是拿本地盘跟 EBS 价格做对比。实际上我认为 EBS 它本身是一个软件服务，它背后是一整套的完整的分布式系统，云服务已经提供了至少三个九的可用性。但本地盘它是硬件，它的故障概率是比较高的，不同的厂商，年化的故障率可能都有差异，有些可能甚至高达 5% 左右。任何硬件坏了都可能导致无法访问这个本地盘的数据，但在云上，ECS 也好 EBS 也好，它们都是软件，你可以理解为它们就是存算分离的。从应用角度来看，ECS、EBS 都是无状态的，EBS 还解决了一个多副本问题。</p><p>如果今天要用本地盘，肯定得主副本，那数据的复制带来的网络带宽消耗、计算资源消耗、存储空间消耗，都需要考虑到成本里面。另外，EBS 它后面是一个大规模的存储节点区域，是能够应对大量磁盘故障的，也能够解决这个数据完整性问题。如果真的要拿 EBS 跟本地盘去对比的话，我觉得至少得让用户去自建一套分布式存储系统，跟使用 EBS 做对比，还得把运维的人力成本也考虑进去。这些在自建、规模比较小的情况下，是很难算清楚的。</p><p>&nbsp;</p><p><strong>反方：冯若航 speaking ——</strong></p><p><strong>上云的成本比自建要高得多。</strong>我自己 15 年的时候在淘宝的 CNZZ，友盟+这个部门算是第一波被推上阿里云的内部 BU。在上云之前，我们有一个自己的机房，几百台服务器，一年所有成本算进去 1000 万。后来上了阿里云大数据全家桶数据库 ODPS 这些东西，每年计算 3000 万存储 4000 万。从 1000 万变成 7000 万这件事直接给了我对云的第一印象，因为阿里云是手把手出工程师加入我们团队帮我们改造业务搬上云的，从原来的每年 1000 万搬到了后来的每年 7000 万，而干的事情，本质上却还是一模一样的，都是统计和计算规模，也没有出现特别的变化。在上完云之后，我们的效能并没有出现变化，但是成本却是实打实地翻了七倍。</p><p>这是我自己亲身经历的一个案例。如果说更有共性的一件事，我觉得可以参考一下 Amazon。AWS 在 2013 年提出的公有云价值，他举了六个点：弹性、敏捷、全球化出海、将资本支出转变为运营支出，以及更低的成本、消除重复建设。</p><p>但是，<strong>这些公有云价值主张在 2023 年很多已经不成立了，</strong>甚至说很多已经没有价值了。我认为还有价值的点就是弹性、agility 和全球化出海，但是这里面覆盖的光谱其实并不多，特别是在高价值用户群体里面并没有覆盖那么多，更多是小微初创小规模业务会用到这些点。</p><p>比如这个 CAPEX 转为 OPEX，将资本支出转为运营支出。这一点，我认为除了对于那种连六个月都活不过的小业务有价值之外，凡是超过六个月，买肯定比租合算了。lower cost 是 AWS 当初相对于这些企业级解决方案来说的，它更便宜。比如说 Oracle 一盒 1 月你要付一万块钱，那么 AWS 上的 RDS 每个月只要 1000 块钱，是不是很便宜？但是那个时候，你可以说只有我这一家有云，所以我可以用这个价值定价，但现在谁家没有一个 RDS ？开源的 RDS 管控都出来了。那么这就变成了成本定价。既然是成本定价，我用云数据库加硬件，用这种开源的方案加上硬件 20 块钱一盒，1 月不比这 1000 块钱或者 400 块钱的 RDS 要香吗？lower cost 这个事儿已经完全变味儿了，现在不是 lower cost 是 higher cost。</p><p>至于消除重复建设这个事，我认为现在开源干得已经比这好了，各家都有自己的 EC2 VPS，但是 K8s 很明显一统了这些无状态服务调度天下，所以我认为在 2023 年公有云的价值就剩下了全球化合规出海，它的适用光谱已经缩小到了小规模业务和高弹性业务和出海业务这三样。以前我们业界大概有一个规模估算，你在云上的年消费在 100 到 300 万这个区间，你就应该考虑下云了。我认为，随着资源云和开源平替的出现，100 万-300 万的阈值将会被进一步拉低至 10 万-30 万或者 1 万-3 万。我认为这件事很有可能会发生，而且正在发生。</p><p>&nbsp;</p><span id="OSC_h1_2"></span><h1>如今上云还安全吗？稳定性有多强？</h1><p><strong>反方：马工 speaking ——</strong></p><p>对于安全，我有很多话说。作为一个软件工程师最基本的是，你不能把密码直接写死、hard code 就编码到你的代码里面，更不能把它提交到 Github 上，这属于初级的实习生犯的错误对不对？</p><p>但是我看了一下，国内的腾讯云阿里云和华为云什么的，全都教用户把那个 Access ID，编码到代码里面。阿里云和腾讯云去年已经改正了，因为我写文章揭露他们。但是至今为止，华为云和火山引擎上面的范例里面还是页编码，Access key，这是非常不负责任的一个做法。</p><p>我为什么说他们是一个草台班子，因为这就相当于修了一座桥，然后把桥的地基给抽掉了，或者说做了一个保险库，但是把钥匙给插在那个锁上了。就这样还谈安全？</p><p>我们可以看一下更近的例子，滴滴出了事故影响了上千万的出行，它连具体的技术原因都没提出来，只说我们会改进、我们是一个内部系统。但这个内部系统是什么？你怎么改进这个系统？基础系统是外购的，还是自研的？什么都没说，但是北京那个地铁追尾，人家就成立调查组了，调查组就会有调查结论，就会有限期改正通知书，你得覆盘，你得汇报，监管部门会过来检查，然后发通知给其他的地铁公司，让别人吸取他的教训。这才是一个真正的工程行业。</p><p>我赞同周新宇说的「云厂商的故障比自建机房的故障更令人瞩目」，但是，<strong>我的机房出故障，我可以得到最全面的信息，云厂商出故障，我得不到所有的信息，甚至他不给我信息。</strong>比如阿里云至今也没有披露技术细节。甚至有一些厂商，他是隐瞒故障，他不会跟你通知，而是想着偷偷修复了你就不知道了。这是一个非常让我们担心的问题：没有透明度。这样你也无法从业务上规避它，只能求它别出事了。这是非常危险的。</p><p>&nbsp;</p><p><strong>正方：周新宇 speaking ——</strong></p><p>今天云厂商确实做得不够好，但这也是会改进的。云厂商在安全和数据完成这块都有很大的投入，我们以前做一个架构，要经过很多层的安全架构评审，并不是说啥都不做。当然，云计算这个技术也好，云计算这种商业模式也好，它肯定是有进步空间的，不能因为当前云厂商某些地方还不够成熟，就完全否定上云的优势或者是云计算的优势。</p><p>&nbsp;</p><p><strong>正方：蒋明 speaking ——</strong></p><p>尤其是大规模的数据库用户，还是上云才能解决需求。像肯德基，阿里云出事以后，他们就把业务迁到了抖音建的云上，并没有迁到自己的机房里。</p><p>根据我的经验，自建机房的话，如果只是一两台机器托管一下的话，还是比较简单的。但是当机器达到四五千台的时候，那你就会遇到 CPU 的故障、内存的故障和磁盘的故障，这时候，你就会很依赖监控系统。我有过大概 4000 多台物理机的这种机房托管经验，当时用的是南京的管理系统，也是腾讯的开源软件，实时监控用的是阿里的监控软件 SLS，哪个磁盘出故障了，就发给线下的运维，让他去换。如果全部都是自建的话，根本就做不到。</p><p>像我们现在的政务云、水电煤背后的技术支持，全部都是在云上的，政府的政务处理系统，银行的交易系统也全部都在云上，如果云真的一无是处，那我们生活当中，支付宝就没办法扫了，钱也付不出去。</p><p>&nbsp;</p><p><strong>反方：冯若航 speaking ——</strong></p><p>我觉得你说的问题非常严峻，就是所谓的云集中的问题。Gartner 最近发布的 2023 年三季度新兴风险报告里面，<strong>云集中风险已经连续第二年进入「五大新兴风险」综合榜单，在中国排第三位。</strong>云集中说的就是云厂商已成为了新的单点，爆炸半径极大。阿里云这一挂，有多少服务宕机了？如果政务云金融云这些都跑在阿里云，那挂了怎么办？</p><p>去年阿里云香港区域故障就导致香港政府很多单位的网站和电子政务不能用。</p><p>所以，<strong>这就是一个下云的重要 argument ——为了安全性和自主可控。</strong>上云其实就是放弃了自主可控，放弃了一部分的安全性。你没有办法对机密性、完整性去进行任何的验证，甚至是追索。</p><p>我是搞信息安全的，安全里面有三个点：CIA ——机密性，数据完整性和可用性。就是不丢，不坏，不宕。但是云厂商它不给你兜机密性和完整性，它只给你兜可用性，而且是非常逊色的可用性。</p><p>比如说云 RDS for PostgreSQL，这个云数据库的基础版甚至都没有望归档，也就是说它没有数据库 PITR 时间点恢复的能力，一个数据库服务竟然没有基础的时间点恢复能力，我认为这对于一个数据库用户来说是完全不可接受的。至于机密性，那就更没法保证了，你甚至没有办法去验证发现任何数据丢失。但要是自建机房，就不会存在这样的风险。</p><p>&nbsp;</p><span id="OSC_h1_3"></span><h1>中小企业该怎么选？</h1><p><strong>正方：周新宇 speaking ——</strong></p><p>如果是一家初创企业，那肯定是毫无疑问要上云，第一天就应该把你的 IT 设施构建在云上，这样未来的业务创新或试错成本都非常低。这是，如果你的企业已经在重度用云，今天因为成本的问题在考虑是否下云，那我觉得是要慎重的，因为不管是上云还是下云，折腾一次代价是比较大的。所以说更好的方式是去分析云上的账单，这里相对于自建有很大的优势：在云上你的一切价格账单都是透明的，到底贵在哪里，可以针对性地去降本。</p><p>&nbsp;</p><p><strong>正方：蒋明 speaking ——</strong></p><p>可以用阿里云、腾讯云、AWS 的基础建设能力，比如 ECS 或 OSS，加上第三方的开源软件，比如 TiDB、AutoMQ，这些软件，它价格便宜，又能用云厂商最便宜的基础能力构建一个企业的自动化 DevOps 系统，让你用最低的成本，在云上创业。至于后面企业大了，像马斯克的 X 公司，那自建云是最佳的选择，毕竟成本会更低。</p><p>&nbsp;</p><p><strong>反方：冯若航 speaking ——</strong></p><p>从务实的角度来讲，小企业其实是适合云的，但是你也不要把所有的东西都深度依赖云。</p><p>第一，你有自建能力，这是你跟云厂商谈价格折扣的最大筹码！</p><p>第二，优先使用资源云。什么是资源云？像租用它的虚拟机，尽可能的避免使用它的专有服务、被供应商锁定。</p><p>第三，如果你在云上非要用这些服务，请避免使用 AKSKIAM 这些让你陷入供应商锁定的东西。这些不仅会让你陷入云单点故障中，更是会把你绑在一个你下不来的账单下。</p><p>&nbsp;</p><p><strong>反方：马工 speaking ——</strong></p><p>我觉得云是一个操作系统，你用云就相当于从 Windows 系统切换到 Linux，这需要非常大的努力，需要一个范式转移。这个转移路上，你必须要有人带着你走。但我目前看云自己也不知道怎么走。这有一个大胆的估测：</p><p>90% 的云厂商的员工，没有自己的云账号；</p><p>90% 的云厂商的员工，没有考过云的认证；</p><p>90% 的云厂商的员工，从来没有在云上维护过或者部署过一个生产系统。</p><p>我觉得大家还是谨慎一点，除非云厂商能够证明云计算的价值点，然后给出一个很明确的路径，不然的话你就不要那么急躁地为了云而云。另外，腾讯会议或者钉钉那不是云，跟微信一样，只是一个很普通的 Saas 系统，这个跟你要负责任的企业 IT 系统是完全不一样的。</p><p>&nbsp;</p><p>大家对此怎么看呢？快留言说说你的经验吧~</p><p>&nbsp;</p><p>直播回放如下，错过的赶紧扫码看看回放吧↓↓↓</p><p style="text-align:center"><img height="255" src="https://oscimg.oschina.net/oscnet/up-0da327351049eec05882b4fa1fb0a6df839.png" width="257" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6852546/blog/10398475</guid>
            <link>https://my.oschina.net/u/6852546/blog/10398475</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中国网络安全审查认证和市场监管大数据中心正式挂牌]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 25 日，中国网络安全审查认证和市场监管大数据中心（下称网数中心）正式挂牌成立。</p><blockquote><p>根据中央编办批覆，中国网络安全审查技术与认证中心更名为中国网络安全审查认证和市场监管大数据中心，整建制划入市场监管总局信息中心，同时划入竞争政策与大数据中心部分职能。主要职责是承担网络安全审查与认证相关标准研究和技术支撑、市场监管信息化建设、大数据分析应用、智慧监管建设等工作。</p></blockquote><p><img alt="" height="324" src="https://oscimg.oschina.net/oscnet/up-b50e4470001eac5b4504facfa10718e4195.jpg" width="500" referrerpolicy="no-referrer"></p><p>具体来说，网数中心的主要职责是：</p><p>依据《网络安全法》《数据安全法》《个人信息保护法》《网络安全审查办法》及国家有关强制性产品认证法律法规，承担网络安全审查技术与方法研究、网络安全审查技术支撑工作；在批准范围内开展与网络安全相关的产品、管理体系、服务、人员认证和培训、检验检测等工作；参与研究拟订市场监管信息化发展规划，协助指导全国市场监管系统信息化建设、管理和应用推广工作；承担市场监管业务应用系统和总局政务信息系统建设、运维及技术保障工作；承担市场监管行业标准组织协调工作，承担全国统一的市场监管信息化标准体系的建立完善工作；负责市场监管大数据中心建设、管理和运行维护工作，支撑智慧监管建设；受委托承担市场监测技术支撑工作；开展网络安全认证、市场监管信息化与大数据分析应用、智慧监管等领域的国际合作与交流。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272732</guid>
            <link>https://www.oschina.net/news/272732</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软 Bing Chat 接入 GPT-4 Turbo 模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowslatest.com%2F2023%2F12%2F25%2Fmicrosoft-bing-chat-gets-chatgpt-4-turbo-for-free-code-interpreter-big-upgrade-ahead%2F" target="_blank">根据&nbsp;Windows Latest&nbsp;的报道</a></u>，微软现已将 GPT-4 Turbo 模型接入 Bing Chat，并向部分用户免费开放。</p><p>GPT-4 Turbo 模型是 OpenAI 在 11 月的开发者大会上公布的最新模型，能力相比 GPT-4 更加强大。正常来说，该模型需要付费使用，<strong>但被选中的 Bing Chat 测试用户可以免费体验该模型的能力</strong>。微软表示，测试用户的选择完全随机，微软称之为称之为「A / B」测试。</p><p>因此能否通过必应聊天使用 GPT-4 Turbo 完全凭运气，但微软已确认计划在未来几周内扩大推广范围。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-1fe3a67b4f285f9fe3161322aa93bb4efc4.png" referrerpolicy="no-referrer"></p><p>微软还计划升级代码解释器功能，使其与 OpenAI 的功能保持一致。这意味着微软 Copilot 中的代码解释器很快就能处理更复杂的编程或数据问题。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272729/bing-chat-gets-chatgpt-4-turbo</guid>
            <link>https://www.oschina.net/news/272729/bing-chat-gets-chatgpt-4-turbo</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[openKylin 荣誉+1！荣获人民网【人民企业社会责任奖「年度案例奖」】]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>12 月 21 日，由人民日报社指导、人民网主办的 2023 人民企业社会责任荣誉盛典暨第 18 届人民企业社会责任奖颁奖活动在京顺利举办，<strong>开放麒麟（openKylin）1.0 凭借在开源创新领域的突出贡献，荣获人民企业社会责任奖年度案例奖。</strong></span></p><p style="margin-left:0; margin-right:0; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-fba19d23cce6b40aadd0f4220d261f5d981.jpg" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:justify"><span>「人民企业社会责任奖」评选活动创设于 2006 年，是中央重点新闻网站在企业社会责任领域最早发起的活动之一。本次活动以「权威性、大众化、公信力」为宗旨，以「勇毅实干&nbsp;共向未来」为主题，设置了「年度企业奖」「年度案例奖」「乡村振兴奖」「绿色发展奖」「筑梦未来奖」和「特别贡献奖」六大奖项。分别从企业履责、公益行动、乡村振兴、绿色发展、儿童事业、共建「一带一路」等维度征集企业履行社会责任的实践案例。</span></p><p style="margin-left:0; margin-right:0; text-align:justify"><span>其中，「年度案例奖」重点关注 2023 年度企业、机构策划并开展实施的具有深刻影响力的社会责任行动案例。与<span>开放麒麟（openKylin）1.0 一同入围的<span><span>获奖案例</span></span>还有：天猫黄扶手计划「观·爱」行动、安踏茁壮成长公益计划、<span><span>亚马逊云科技「AI 在未来」公益计划</span></span>等。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>今年 7 月 5 日，开放麒麟（openKylin）1.0 正式发布，标志着我国拥有了操作系统组件自主选型、操作系统独立构建的能力，填补了我国在这一领域的空白。作为国内开源操作系统根社区，开放麒麟（openKylin）社区自成立起便积极推动开源生态建设。截至目前，openKylin 已累计发布 6 个社区版本，下载量达 100 万+；汇聚 400+社区会员、5500+开发者加入社区，并累计成立 94 个 SIG 组开展技术研究与创新。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>未来，开放麒麟（openKylin）社区也将保持初心，为构建良好开源生态发展持续努力，并携手各界伙伴共筑开源生态，用持续的技术创新和更加活跃的社区运营推动我国开源产业快速发展。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272719</guid>
            <link>https://www.oschina.net/news/272719</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LobeChat —— 聊天机器人框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LobeChat 是一个开源、高性能的聊天机器人框架，支持语音合成、多模态和可扩展的功能调用插件系统。支持一键式免费部署私人 ChatGPT/LLM 网络应用程序。</p><p><img height="190" src="https://static.oschina.net/uploads/space/2023/1218/154744_PdXB_4252687.png" width="500" referrerpolicy="no-referrer"></p><p>特性一览：</p><h4 style="text-align:start">GPT 视觉认知</h4><p><img height="192" src="https://static.oschina.net/uploads/space/2023/1218/154508_TIgb_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#1f2328; text-align:start">LobeChat 已经支持 OpenAI 最新的<span>&nbsp;</span><a href="https://platform.openai.com/docs/guides/vision"><code>gpt-4-vision</code></a><span>&nbsp;</span>支持视觉识别的模型，这是一个具备视觉识别能力的多模态智能。 用户可以轻松上传图片或者拖拽图片到对话框中，助手将能够识别图片内容，并在此基础上进行智能对话，构建更智能、更多元化的聊天场景。</p><p style="color:#1f2328; text-align:start">这一特性打开了新的互动方式，使得交流不再局限于文字，而是可以涵盖丰富的视觉元素。无论是日常使用中的图片分享，还是在特定行业内的图像解读，助手都能提供出色的对话体验。</p><h4 style="text-align:start">TTS &amp; STT 语音会话</h4><p><img height="194" src="https://static.oschina.net/uploads/space/2023/1218/154539_jFKr_4252687.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#1f2328; text-align:start">LobeChat 支持文字转语音（Text-to-Speech，TTS）和语音转文字（Speech-to-Text，STT）技术，能够将文本信息转化为清晰的语音输出，用户可以像与真人交谈一样与我们的对话代理进行交流。 用户可以从多种声音中选择，给助手搭配合适的音源。 同时，对于那些倾向于听觉学习或者想要在忙碌中获取信息的用户来说，TTS 提供了一个极佳的解决方案。</p><p style="color:#1f2328; text-align:start">在 LobeChat 中，项目团队精心挑选了一系列高品质的声音选项 (OpenAI Audio, Microsoft Edge Speech)，以满足不同地域和文化背景用户的需求。用户可以根据个人喜好或者特定场景来选择合适的语音，从而获得个性化的交流体验。</p><h4 style="text-align:start">Function Calling 插件系统</h4><p style="color:#1f2328; text-align:start">LobeChat 的插件生态系统是其核心功能的重要扩展，它极大地增强了 ChatGPT 的实用性和灵活性。通过利用插件，ChatGPT 能够实现实时信息的获取和处理，例如自动获取最新新闻头条，为用户提供即时且相关的资讯。 此外，这些插件不仅局限于新闻聚合，还可以扩展到其他实用的功能，如快速检索文档、获取电商平台数据、以及其他各式各样的第三方服务。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 02:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/lobechat</guid>
            <link>https://www.oschina.net/p/lobechat</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 跨平台的截图/录屏/录音/录像软件 pear-rec]]>
            </title>
            <description>
                <![CDATA[<p align="center"><img src="https://027xiguapi.github.io/pear-rec/logo.png" height="120" referrerpolicy="no-referrer"></p><h1><a id="user-content-pear-rec" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#pear-rec"></a>pear-rec</h1><p><img src="https://img.shields.io/github/stars/027xiguapi/pear-rec" alt="stars" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/react-v18-blue" alt="react" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/electron-v26-blue" alt="react" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/express-v4-blue" alt="react" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/-TypeScript-blue?logo=typescript&amp;logoColor=white" alt="typescript" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/-Vite-646cff?logo=vite&amp;logoColor=white" alt="vite" referrerpolicy="no-referrer"></p><hr><h2><a id="user-content-readme" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#readme"></a>README</h2><p><a href="https://gitee.com/xiguapi027/pear-rec/blob/main/README.zh-CN.md">中文</a> | <a href="https://gitee.com/xiguapi027/pear-rec/blob/main/README.md">English</a> | <a href="https://gitee.com/xiguapi027/pear-rec/blob/main/README.de-DE.md">Deutsch</a></p><h2><a id="user-content-架构" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E6%9E%B6%E6%9E%84"></a>架构</h2><img src="https://027xiguapi.github.io/pear-rec/imgs/1700442414996.jpg" referrerpolicy="no-referrer"><h2><a id="user-content-简介" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E7%AE%80%E4%BB%8B"></a>简介</h2><blockquote><p>pear-rec(梨子 rec) 是一个跨平台的截图、录屏、录音、录像、录制 (动图)gif、查看图片、查看视频、查看音频和修改图片的软件。</p><p>pear-rec(pear rec) 是基于 react + electron + vite + viewerjs + plyr + aplayer + react-screenshots + tui-image-editor + gif.js 的一个项目。</p><p>更多功能和 api 可以查看<a href="https://gitee.com/link?target=https%3A%2F%2F027xiguapi.github.io%2Fpear-rec">官网 (https://027xiguapi.github.io/pear-rec)</a> 或 <a href="https://xiguapi027.gitee.io/pear-rec" rel="nofollow">https://xiguapi027.gitee.io/pear-rec</a></p></blockquote><h2><a id="user-content-例子" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E4%BE%8B%E5%AD%90"></a>例子</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fpear-rec-xiguapi.vercel.app%2F">网页</a></p><h2><a id="user-content-下载地址" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80"></a>下载地址</h2><blockquote><p>gitee: <a href="https://gitee.com/xiguapi027/pear-rec">https://gitee.com/xiguapi027/pear-rec</a></p><p>github: <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2F027xiguapi%2Fpear-rec">https://github.com/027xiguapi/pear-rec</a></p></blockquote><h2><a id="user-content-源码运行编译" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E6%BA%90%E7%A0%81%E8%BF%90%E8%A1%8C%E7%BC%96%E8%AF%91"></a>源码运行&amp;编译</h2><p>编译需要<code>nodejs</code>和<code>pnpm</code>环境</p><h3><a id="user-content-测试环境" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83"></a>测试环境</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">nodejs: 18</span><span id="LC2" class="line">pnpm: 8</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-开始" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%BC%80%E5%A7%8B"></a>开始</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c"># 拷贝代码</span></span><span id="LC2" class="line">git clone https://gitee.com/xiguapi027/pear-rec.git</span><span id="LC3" class="line"><span class="c"># 进入项目</span></span><span id="LC4" class="line"><span class="nb">cd </span>pear-rec</span><span id="LC5" class="line"><span class="c"># 安装依赖</span></span><span id="LC6" class="line">pnpm <span class="nb">install</span></span><span id="LC7" class="line"><span class="c"># 调试页面</span></span><span id="LC8" class="line">pnpm run dev:web</span><span id="LC9" class="line"><span class="c"># 调试服务</span></span><span id="LC10" class="line">pnpm run dev:server</span><span id="LC11" class="line"><span class="c"># 调试软件</span></span><span id="LC12" class="line">pnpm run dev:desktop</span><span id="LC13" class="line"><span class="c"># 运行页面</span></span><span id="LC14" class="line">pnpm run start:web</span><span id="LC15" class="line"><span class="c"># 运行软件</span></span><span id="LC16" class="line">pnpm run start:desktop</span><span id="LC17" class="line"><span class="c"># 编译软件</span></span><span id="LC18" class="line">pnpm run build:desktop</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-功能" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%8A%9F%E8%83%BD"></a>功能</h2><p>已经勾选的功能是开发过程最新功能，但可能还没发布在最新版本</p><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 截屏 (react-screenshots)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 框选裁切</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 框选大小位置可调整</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 取色器</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 放大镜</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 画笔（自由画笔）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 几何形状（边框填充支持调节）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 高级画板设置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 图像滤镜（支持局部马赛克模糊和色彩调节）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 自定义框选松开后的操作</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 以图搜图</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 扫描二维码</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 快速截取全屏到剪贴板或自定义的目录</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 截屏历史记录</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 窗口和控件选择（使用 OpenCV 边缘识别）</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 长截屏</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 多屏幕</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 录屏 (WebRTC)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 录制全屏</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 截图</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 自定义大小</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 静音</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 按键提示</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 光标位置提示</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 录制栏</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 流写入</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 录音 (WebRTC)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 录音设置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 查看录音</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 下载录音</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 编辑录音</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 录像
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 自定义比特率</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 图片预览 (viewerjs)
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 放大</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 缩小</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 拖拽</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 翻转</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 钉上层</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 查看</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 下载</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 打印</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> ocr</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 查看列表</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 以图搜图</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 扫描二维码</li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 图片编辑 (tui-image-editor)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 视频预览 (plyr)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 音频预览 (aplayer)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 动图 (gif) 编辑 (gif.js)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 基本设置
<ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 用户 uuid</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 保存地址</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 开机自启动</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 国际化 (中、英、德)</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 服务设置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 快捷键设置</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled=""> 重置设置</li></ul></li></ul><h2><a id="user-content-国际化 i18n" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%9B%BD%E9%99%85%E5%8C%96i18n"></a>国际化 (I18n)</h2><ul class="task-list"><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 简体中文</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 英语</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" checked="" disabled=""> 德语</li></ul><h2><a id="user-content-download" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#download"></a>Download</h2><table><thead><tr><th>系统</th><th>Windows</th><th>Linux</th><th>Macos</th></tr></thead><tbody><tr><td>链接</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2F027xiguapi%2Fpear-rec%2Freleases">下载</a></td><td>◯</td><td>◯</td></tr></tbody></table><p>国内可以用 <a href="https://gitee.com/link?target=https%3A%2F%2Fghproxy.com%2F">GitHub Proxy</a> 加速下载</p><h2><a id="user-content-反馈和交流" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%8F%8D%E9%A6%88%E5%92%8C%E4%BA%A4%E6%B5%81"></a>反馈和交流</h2><p>我们推荐使用 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2F027xiguapi%2Fpear-rec%2Fissues">issue</a> 列表进行最直接有效的反馈，也可以下面的方式</p><ul><li>qq 群</li></ul><p align="center"><img src="https://027xiguapi.github.io/pear-rec/imgs/pear-rec_qq_qrcode.png" referrerpolicy="no-referrer"></p><h2><a id="user-content-开源协议" class="anchor" href="https://gitee.com/xiguapi027/pear-rec#%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE"></a>开源协议</h2><p><a href="https://gitee.com/xiguapi027/pear-rec/blob/main/LICENSE">pear-rec(梨子 rec) 可在 Apache License V2 下使用。</a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FMDN%2FCommunity%2FOpen_source_etiquette">开源项目礼节</a></p>]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 01:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/xiguapi027/pear-rec</guid>
            <link>https://gitee.com/xiguapi027/pear-rec</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 揭开事件循环的神秘面纱]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-f9d098f5cee0090732c3958edc97164b6c7.png" alt="" referrerpolicy="no-referrer"></p><p>作者 |&nbsp;小萱</p><blockquote><p>导读&nbsp;</p><p>这篇文章会全方位讲解事件循环机制，从这篇文章你可以学到，「事件循环」和「浏览器渲染」的关系，浏览器 setTimeout、requestAnimationFrame（RAF）、requestIdleCallback（RIC）等 API 在事件循环的「执行时机」，导致浏览器卡顿的原因、交互指标是如何测量的以及如何提升网站的交互性能。</p></blockquote><blockquote><p><em>全文 10503 字，预计阅读时间 27 分钟。</em></p></blockquote><h1><strong>01 前言</strong></h1><p>我们常常会提到页面性能，为什么要优化长任务，又为什么 React 要做时间切片呢。这篇文章把浏览器的渲染、事件循环与页面性能串联起来。</p><p>从这篇文章你可以学到，「事件循环」和「浏览器渲染」的关系，浏览器 setTimeout、</p><p>requestAnimationFrame（RAF）、requestIdleCallback（RIC）等 API 在事件循环的「执行时机」，导致浏览器卡顿的原因、交互指标是如何测量的以及如何提升网站的交互性能。</p><p>学完这些，你可以对为什么动画要用 RAF、又何时去用 RIC、该不该选择 setTimeout、如何规避长任务之类的问题应对自如。</p><h1><strong>02 事件循环概述</strong></h1><h2><strong>2.1 为什么要了解事件循环？</strong></h2><p>深入了解事件循环是性能优化的基础。在讨论事件循环之前，我们需要先了解浏览器的多进程和多线程架构。</p><h2><strong>2.2 浏览器的架构</strong></h2><p>回顾浏览器的架构，现代浏览器都是多进程和多线程的。</p><h3><strong>2.2.1 多进程</strong></h3><p>Chrome 浏览器使用多进程架构，意味着每个标签页（在某些浏览器中也包括每个扩展程序）通常在其自己的进程中运行。这样做的好处是，一个标签页崩溃不会影响到其他标签页。</p><p>站点隔离特性，浏览器每个 tab，都是独立的渲染进程，这点的好处是假设你打开三个标签页，一个标签卡死不影响其他两个。但如果三个标签共用一个进程，一个卡死会导致全部都卡，这样体验很差。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ea0fa24c2b466fa5d6ee4b2d3f43537fb03.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△浏览器的多进程示意图</strong></strong></p><h3><strong>2.2.2 多线程</strong></h3><p>每个浏览器进程都可以包含多个线程。例如，主线程用于执行 JavaScript 代码和处理页面布局，而其他线程可能用于网络请求、渲染等任务。</p><p><strong>主线程</strong></p><p>Web 应用程序需要在此单个主线程上执行某些关键操作。当您导航到 Web 应用程序时，浏览器将创建并向您的应用程序授予该线程，以便您的代码在其上执行。</p><p>主线程指的是渲染进程下的主线程，负责解析 HTML、计算 CSS 样式、执行 JavaScript、计算布局、绘制图层等任务。</p><p><img src="https://oscimg.oschina.net/oscnet/up-835102f787ff8cc334c66e30face4316758.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△主进程即渲染进程包含的线程图</strong></strong></p><p>某些任务<strong>必须</strong> 在主线程上运行。例如，任何直接需要访问 DOM（即 DOM ﻿document﻿）的操作都必须在主线程上运行（因为 DOM 不是线程安全的）。这将包括大多数 UI 相关代码。</p><p>主线程上一次只能运行 <strong>一个任务</strong>。</p><p>此外，一个任务<strong>必须在主线程上运行完成</strong>，然后才能运行另一个任务。浏览器没有「部分」执行任务的机制，每个任务都完整地运行直至完成。</p><p>在下面的示例中，在浏览器展示界面的时候，按顺序运行下面的任务，并且每个任务都在主线程上完成：</p><p><img src="https://oscimg.oschina.net/oscnet/up-b89c629a6370f9eaf9aeae593adc5bc8d21.png" alt="图片" referrerpolicy="no-referrer"></p><h1><strong>03 事件循环的具体流程</strong></h1><p>我们这里主要讨论的是&nbsp;window event loop。也就是浏览器一个渲染进程内主线程所控制的&nbsp;Event Loop。</p><p><img src="https://oscimg.oschina.net/oscnet/up-7597949bda55e109f8b7f0eef42bde61edd.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△发生一次事件循环的具体流程</strong></strong></p><p>发生一次事件循环，也就是浏览器一帧中可以用于执行﻿JS﻿的流程如下：</p><p>从 task queue 取出一个 task(宏任务) 执行并删除 &nbsp;-&gt; 执行并清空队列中全部 job(微任务) -&gt; requestAnimationFrame -- 浏览器更新渲染 -- requestIdleCallback</p><p><strong>3.1 更新渲染的步骤</strong></p><p>前两个步骤，耳熟能详，这里不再讨论，重点讨论「更新渲染」之后的步骤。</p><p>1. Rendering opportunities: 标志是否一次事件循环后会发生渲染。在每次事件循环的结束，不一定会发生渲染。导致不渲染的可能：无法维持当前刷新率、浏览器上下文不可见、浏览器判断更新不会造成视觉改变并且 raf 的回调为空。</p><p>如果这些条件都不满足，当前文档不为空，设置 hasARenderingOpportunity 为 true。</p><p>2.如果窗口变化，执行 resize。</p><p>3.如果滚动，执行 scroll。</p><p>4.媒体查询。</p><p>5.canvas 。</p><p>6.执行 RAF 回掉，传递回掉参数 DOMHighResTimeStamp，开始执行回调的时间。</p><p>7.重新执行 Layout 等计算，渲染绘制界面。</p><p>8.如果满足，任务队列和微任务队列都为空，并且渲染时机 hasARenderingOpportunity 为 false，执行算法是否执行 requestIdleCallback 的回调函数。</p><p><strong>3.2</strong><strong>执行顺序与渲染</strong></p><p>来一道简单的题目，将创建宏任务、微任务、RIC、RAF 的代码同时定义，输出执行顺序。</p><pre><code>console.log('开始执行');
console.log('start');
setTimeout(() =&gt; {
  console.log('setTimeout');
}, 0);

requestAnimationFrame(() =&gt; {
  console.log('requestAnimationFrame');
});
new Promise((resolve, reject) =&gt; {
  console.log('Promise');
  resolve('promise resolved');
})

requestIdleCallback(() =&gt; {
  console.log('requestIdleCallback');
});

(async function asyncFunction() {
  console.log(await 'asyncFunction');
})();

console.log('执行结束');
// 开始执行
// Promise
// 执行结束
// promise resolved
// asyncFunction
// setTimeout
// requestAnimationFrame
// requestIdleCallback
</code></pre><p>你可能会疑问为什么 RAF 会在 setTimeout(fn, 0) 之前执行，setTimeout(fn, 0) 的执行时机是延迟 0-4ms，RAF 可以粗暴理解为 settimeout(fn, Math.random() * 16.6)，因此 setTimeout 会优先。但如果在 setTimeout 执行之前主线程被其他的任务跑满了，超过了一帧的耗时，setTimeout 会在 RAF 的回调之后执行（用例见下面的代码段），因此 setTimeout 的延迟时间并不稳定，RAF 的执行时机稳定，在一帧内注册的，都会在这一帧的结束，下一帧的开始之前执行。</p><pre><code>  let task = new Array(10000).fill(null).map((_, i) =&gt; () =&gt; {
    const span = document.createElement("span");
    span.innerText = i;
    console.log("==&gt;task", i);
  });
  task.forEach((i) =&gt; i());
  requestAnimationFrame(() =&gt; {
    console.log("===&gt;requestAnimationFrame");
  });
  setTimeout(() =&gt; {
    console.log("===&gt;setTimeout");
  }, 0);
  //输出：
  // ===&gt;requestAnimationFrame
  // ===&gt;setTimeout
</code></pre><p>注意，Promise.then 的回调可以保证第一轮的准确性，如果继续.then 发生的行为和浏览器版本有关，开发时不要过分依赖多.then 的回调顺序，这是不可靠的。</p><p>上面提到渲染是在一次事件循环的「最后」发生，那么对于多次「修改 dom」的操作，是会被合并取最后一次的结果作为布局渲染。</p><pre><code>    const btn = document.querySelector(".btn");
    btn.addEventListener("click", () =&gt; {
      box.style.transform = "translateX(400px)";
      box.style.transition = "transform 1s ease-in-out";
      box.style.transform = "translateX(200px)";
    });
</code></pre><p>外层父容器 400px，这段代码，表现是盒子从 0 到 200px，盒子设置 400px 的动作，被合并掉了。那如何实现盒子从 400px 呢，可以采取延迟到下一帧渲染。</p><p><img src="https://oscimg.oschina.net/oscnet/up-12acd27c0e4668c804c101feaff4900b941.gif" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△演示效果</strong></strong></p><pre><code>    btn.addEventListener("click", () =&gt; {
      box.style.transform = "translateX(400px)";
      requestAnimationFrame(() =&gt; {
        requestAnimationFrame(() =&gt; {
          box.style.transition = "transform 1s ease-in-out";
          box.style.transform = "translateX(200px)";
        });
      });
    });
</code></pre><p>「嵌套的 RAF」可以保证回调在下一帧执行。当然，此处用 setTimeout 也可以达到同样的延迟效果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-aba5e3515d83ac5a4002123ffa2fe772441.gif" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△延迟后的演示效果</strong></strong></p><h1><strong>04 任务队列与执行时机</strong></h1><p><strong>执行 JavaScript task 是在渲染之前，如果在一帧之内 JavaScript 执行时间过长就会阻塞渲染，同样会导致丢帧、卡顿</strong>，这里的 js 执行时间过长，就是长任务，下面会仔细介绍。</p><p>对长任务的定义：如果任务耗时<strong>超过 50ms</strong>，则认为该任务是长任务。</p><p>当我们谈到长任务造成页面卡顿时，通常指的是主线程（Main Thread）上的任务。主线程指的是渲染进程下的主线程，负责解析 HTML、计算 CSS 样式、执行 JavaScript、计算布局、绘制图层等任务。当主线程上的一个任务（例如一个 JavaScript 函数）运行时间过长时，它会阻塞主线程上的其他任务，包括但不限于 UI 更新和用户交互事件的处理，从而导致页面卡顿或不响应。</p><p><strong>JS 的执行和渲染的关系：</strong></p><p>JS 执行与 Paint 任务都发生在主线程，具体的绘制操作是交由合成线程完成，与主线程并不互斥，但是 JS 的执行时间过长，会导致 Paint 整理好的数据没有及时提交给合成线程，因此页面有帧没有执行绘制，也就是掉帧。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a9ff20ab17a1d01227807dc759a9caafc2e.png" alt="图片" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-45b704b84e7ef58a85990b189f3cefe42ce.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△JS 的执行和渲染的关系图</strong></strong></p><h2><strong>4.1 为什么不使用 setTimeout 做动画</strong></h2><p><strong>raf 和 setTimeout 对比:</strong></p><p><em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjsfiddle.net%2Fhixuanxuan%2Fmrw6upgs%2F3%2F__%EF%BC%89" target="_blank">https://jsfiddle.net/hixuanxuan/mrw6upgs/3/__）</a></em></p><p><strong>1.不同步与显示刷新率：</strong></p><p>浏览器通常以每秒 60 帧的速度刷新，大约每 16.67 毫秒刷新一次。如果你使用 setTimeout 来创建动画，并尝试每 16.67 毫秒运行一帧，你的代码不会完全与浏览器的刷新速率同步，导致丢帧</p><p><strong>2.延迟执行：</strong></p><p>setTimeout 的延迟时间参数只是一个最小延迟时间，而不是保证执行的精确时间。如果主线程忙于其他任务，setTimeout 的回调可能会被延迟，导致丢帧</p><p><strong>3.计时器合并：</strong></p><p>浏览器渲染有渲染时机（Rendering opportunity），也就是浏览器会根据当前的浏览上下文判断是否进行渲染，因为考虑到硬件的刷新频率限制、页面性能以及页面是否存在后台等等因素，宏任务之间不一定会伴随着浏览器绘制。如果两个 Task 距离的很近，他们可能会被合并在一次渲染任务，得到的结果是意料之外的，如果 Task 距离较大，那他跟不上浏览器的刷新频率，会导致丢帧。</p><p>RAF 的执行时机是在下一次渲染前调用，也就是说使用这个 API 允许你在下一次渲染开始之前更改 DOM，然后在本次渲染中立即体现，因此他是制作动画的绝佳选择。</p><p><strong>4.2 requestIdleCallback 的执行时机</strong></p><p>主要在浏览器的主线程空闲时执行，为了保证响应性，会计算一个截止时间，computeDeadline，它将决定何时执行&nbsp;requestIdleCallback&nbsp;中注册的回调。下面是计算截止时间算法的简要概述：</p><p><strong>1.设置初始截止时间：</strong></p><p>初始化时，将事件循环的最后闲置周期开始时间设置为当前时间。</p><p>设置一个基本的截止时间，该时间是事件循环的最后闲置周期开始时间加上 50 毫秒（为了保证对新用户输入的响应性）。为什么要加这个 50ms，是因为浏览器为了提前应对一些可能会突发的用户交互操作，比如用户输入文字。如果给的时间太长了，你的任务把主线程卡住了，那么用户的交互就得不到回应了。50ms 可以确保用户在无感知的延迟下得到回应。</p><p><strong>2.检查是否有待处理的渲染：</strong></p><p>初始化一个变量 hasPendingRenders 为 false。</p><p>遍历相同事件循环的所有窗口，检查每个窗口是否有未执行的 RAF 回调或可能的渲染更新。如果有，将 hasPendingRenders 设置为 true。</p><p><strong>3.基于 timeout 调整截止时间：</strong></p><p>如果 RIC 传入第二个参数 timeout，更新截止时间为 timeout。这会强制浏览器不管多忙，都在超过这个时间之后去执行 rIC 的回调函数。</p><p><strong>4.考虑渲染的时间：</strong></p><p>如果 hasPendingRenders 为 true，计算下一个渲染的截止时间，基于事件循环的最后渲染机会时间和当前的刷新率。</p><p>如果下一个渲染的截止时间早于当前设置的截止时间，那么更新截止时间为下一个渲染的截止时间。</p><p><strong>5.返回最终的截止时间：</strong></p><p>返回计算出的截止时间，这个时间将用于确定何时执行 requestIdleCallback 中注册的回调。</p><p><strong>6.开始空闲期：</strong></p><p>对于相同事件循环的每个窗口，执行「开始空闲期」算法，使用 computeDeadline 作为参数，确定何时执行 requestIdleCallback 中注册的回调。</p><p>也就是说，这个&nbsp;timeRemaining()&nbsp;的计算非常动态，会根据上面这些因素去决定。</p><h2><strong>4.3 React 如何实现 Time slice，没有使用 RIC、setTimeout 的原因是什么</strong></h2><p>没使用 RIC 的原因是他在部分浏览器表现不佳，比如 safari。</p><p>需要满足的条件：</p><p>1.暂停 JS 执行，将主线程去执行 style、layout、paint 等任务，让浏览器有机会更新页面。</p><p>2.在未来某个时刻可以继续调度任务，执行上次还没有完成的任务。</p><p>对于 react 的 Time Slice，他的目的是中断当前 js 的执行，让他去执行渲染相关任务，因此需要的 API 是在浏览器的 Paint 之后执行，浏览器并未提供除了 RIC 这样的 API。RAF 的执行时机是在一帧的结束，此时创建宏任务开启下一轮 Task，渲染的任务放在 RAF 里在这一帧执行。如果使用 setTimeout(fn, 0) 创建宏任务，如果 timeout 嵌套的层级超过了 5 层，最低会有 4ms 的延迟，具体定义的代码可以参考<strong>chrome 对计时器的定义</strong><em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchromium.googlesource.com%2Fchromium%2Fblink%2F%2B%2Fmaster%2FSource%2Fcore%2Fframe%2FDOMTimer.cpp%EF%BC%89" target="_blank">https://chromium.googlesource.com/chromium/blink/+/master/Source/core/frame/DOMTimer.cpp）</a></em>，因此首选的是 message channel，优先级高于 setTimeout 可以在上一帧渲染结束后立即执行，这样就实现了<strong>可以中断的 JS 执行的效果</strong>。</p><h2><strong>4.4 模拟实现 requestIdecallback</strong></h2><p>要模拟实现 requestIdecallback 的效果，定义的任务队列在浏览器完成渲染任务之后执行，扩展来说也可以用来测量浏览器渲染任务的执行时间。</p><p><strong>Background Tasks API - Web API 接口参考 | MDN</strong>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FAPI%2FBackground_Tasks_API%EF%BC%89" target="_blank">https://developer.mozilla.org/zh-CN/docs/Web/API/Background_Tasks_API）</a></p><pre><code>  // 当到时间了，立即执行的函数
  const performWorkUntilDeadline = () =&gt; {
    if (scheduledHostCallback !== null) {
      const currentTime = getCurrentTime();
      // 分配任务的剩余时间，这个可执行时间是根据 fps 动态算的
      deadline = currentTime + yieldInterval;
      const hasTimeRemaining = true;
      // 调用已计划的回调，并传递剩余时间和当前时间。
      const hasMoreWork = scheduledHostCallback(
          hasTimeRemaining,
          currentTime,
        );
        if (!hasMoreWork) {
          isMessageLoopRunning = false;
          scheduledHostCallback = null;
        } else {
          // If there's more work, schedule the next message event at the end
          // of the preceding one.
          port.postMessage(null);
        }
    } else {
      isMessageLoopRunning = false;
    }
    // 给浏览器一个绘制的机会，并重置需要绘制的标志。
    needsPaint = false;
  };
  
 
  const channel = new MessageChannel();
  const port = channel.port2;
  channel.port1.onmessage = performWorkUntilDeadline;

  requestHostCallback = function(callback) {
    scheduledHostCallback = callback;
    if (!isMessageLoopRunning) {
      isMessageLoopRunning = true;
      port.postMessage(null);
    }
  };
</code></pre><h1><strong>05 交互性能指标与优化方法</strong></h1><p>长任务对页面的影响，带来「卡顿」、「掉帧」等不好的体验，常用衡量交互性能的指标有 TTI 和 FID，这些均可使用 web-vital 库进行测量。下面展开对指标的详细介绍。</p><h2><strong>5.1 交互性能的衡量指标</strong></h2><p>衡量交互性能的指标主要关注以下几个方面：</p><h3><strong>5.1.1&nbsp;TTI （理想可交互时间）</strong></h3><p><strong>1.定义可交互：</strong></p><p>首先，需要明确什么是「可交互」。一个页面被认为是可交互的，意味着页面的主要内容已经加载完毕，用户可以进行点击、输入等交互操作，而且页面能够快速响应。</p><p><strong>2.监测首次内容绘制 (FCP) 和 DOMContentLoaded：</strong></p><p>测量 TTI 的过程通常开始于监测首次内容绘制 (FCP) 和 DOMContentLoaded 事件。这两个事件分别表示浏览器开始绘制页面内容和 DOM 结构加载完毕的时刻。</p><p><strong>3.长任务监测：</strong></p><p>长任务是指那些执行时间超过 50 毫秒的任务。长任务通常会阻塞主线程，延迟页面的交互可用性。通过监测长任务，可以了解主线程何时变得空闲。</p><p><strong>4.寻找交互窗口：</strong></p><p>为了确定 TTI，需要找到一个至少 5 秒钟主线程空闲的窗口，且该窗口应在首次内容绘制 (FCP) 之后。在这个 5 秒空闲窗口期间，没有长任务执行，意味着用户可以与页面交互。一旦找到这个空闲窗口，记录 TTI。如果未找到长任务，则 TTI 与 FCP 相同。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f839eeb20c4ce164ffb346f0ee1b8f69072.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△TTI 测量示意图（源于 web.dev）</strong></strong></p><h3><strong>5.1.2&nbsp;FID（首次输入延迟）</strong></h3><p>FID，即 First Input Delay，用于量化用户在页面加载时首次交互的响应延迟。一个低的 FID 表示页面是快速响应用户交互的，而一个高的 FID 表示页面在响应用户交互时有延迟。</p><p><strong>1.事件监听:</strong></p><p>为了计算 FID，浏览器需要监听用户的交互事件，如点击、键盘输入或者触摸事件。当用户与页面交互时，会触发这些事件。</p><p><strong>2.事件处理时间:</strong></p><p>当事件被触发时，浏览器会计算从事件触发到浏览器开始处理事件的时间。这个时间就是 FID。它包括了浏览器将事件放入事件队列、事件队列的等待时间、以及浏览器开始处理事件的时间。</p><p><strong>3.事件处理:</strong></p><p>一旦事件开始被处理，浏览器会记录下处理开始的时间。如果页面在处理事件时非常忙碌，或者有其他高优先级的任务，那么事件处理可能会被延迟，这会增加 FID。</p><h3><strong>5.1.3 INP（交互到下一次绘制）</strong></h3><p>INP，即 Interaction to Next Paint，主要关注的是用户交互（如点击、滚动或按键操作）到页面响应的时间长度，具体到页面上的某个元素的可视更新。</p><p>比起来 FID 关注的是页面加载完成后用户<strong>首次交互</strong>，INP 关注的是<strong>所有交互的最长渲染延迟</strong>，因此 INP 不仅仅代表第一印象，可以全面评估响应情况， 使 INP 比 FID 在衡量用户交互体验上更为可靠。</p><p>INP 将会在 2024 年 3 月取代 FID 成为标准性能指标。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3bf10348f63ae93f27266efad4b84531629.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△交互到绘制的时间</strong></strong></p><h2><strong>5.2 如何优化交互性能指标</strong></h2><p><strong>1、拆分任务，这是避免长任务的有效手段。</strong></p><ul><li><p>利用 performance 进行分析，找出 long task</p></li><li><p>针对 long task，进行每个步骤的任务拆分，执行优先级高的，剩下的部分利用延迟代码执行的方法进行中断。</p></li></ul><p>比如，有个 Input 框，当输入的内容发生变更，需要进行大量计算/创建 dom 等耗时操作，造成输入卡顿。因此我们需要在用户「尝试发生互动」的时候，「退让主线程」。</p><pre><code>// 通过 Promise 实现中断后继续执行，setTimeout 调用来延迟任务
function yieldToMain () {
  return new Promise(resolve =&gt; {
    setTimeout(resolve, 0);
  });
}
    async function saveSettings(tasks) {
      let deadline = performance.now() + 50;

      while (tasks.length &gt; 0) {
        // 判断当前是否有用户交互，isInputPending Chrome87+支持。
        // 可以采用判断 Expire Time 达到类似效果
        if (
          navigator.scheduling?.isInputPending() ||
          performance.now() &gt;= deadline
        ) {
         // 如果有，退让主线程，等主线程任务完成再回来继续执行。
          await yieldToMain();
          deadline = performance.now() + 50;
          continue;
        }
        const task = tasks.shift();
        task();
      }
    }

    const performLongTask = () =&gt; {
       // 创建耗时的任务
      let task = new Array(10000).fill(null).map((_, i) =&gt; () =&gt; {
        const span = document.createElement("span");
        span.innerText = i;
      });
      saveSettings(task); // 任务切片
    };
    input.addEventListener("input", (e) =&gt; {
      input.value = e.target.value;
      performLongTask();
    });
</code></pre><p>2、非关键模块，延迟执行。对于点击率不高、非核心模块等，采取 dynamic import 的方式，用到了再加载，或是延迟到一定时间后再加载，减少首次主线程所需要执行的任务。</p><p>3、对于视口内不可见的内容，延迟加载。</p><ul><li><p>图片的延迟加载。</p></li><li><p>为 img 标签 loading 设为 lazy，延迟加载资源，直到资源达到与视口的计算距离，Chrome77+支持。</p></li><li><p>利用 IntersectionObserver 监测图片是否在可视区域，再进行渲染。推荐使用<strong>lazy-load-image-component</strong><em>（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2Freact-lazy-load-image-component%EF%BC%89" target="_blank">https://www.npmjs.com/package/react-lazy-load-image-component）</a></em> 等库。</p></li><li><p>减少大量 dom 的渲染。使用 content-visibility 延迟渲染屏幕外元素，Chrome85+支持。</p></li></ul><p>4、灵活的缓存策略。</p><ul><li>用 service-worker 跨站资源共享。</li></ul><p>除了资源可以采取强缓存+协商缓存配合的方式，用 service-worker 实现更为灵活的缓存策略。比如站点 a 和站点 b 仅满足同源，技术栈渲染方式都完全不同，如何实现在访问 a 的时候可以预取 b 的资源。站点 a 空闲的时候注册 service-worker，访问站点 b 即可从 cache 里读取缓存，提升加载速度。sw 不仅在缓存方面表现优秀，也可以帮我们实现离线应用，以及无法被浏览器强缓存的文件手动添加缓存（不同浏览器对可以强缓存的文件的体积限制不同）。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6d991b243783e8ba64b09daeb68baf2d6b8.png" alt="图片" referrerpolicy="no-referrer"></p><p><strong><strong>△使用 sw 做跨站资源预取</strong></strong></p><h1><strong>06 总结</strong></h1><p>1.浏览器是多进程和多线程的，通常说主线程指的是渲染进程下的主线程。</p><p>2.主线程上一次只能运行一个任务，浏览器的绘制和主线程并不互斥，但长任务会导致延迟进入合成，甚至在这一帧不发生合成也就是掉帧。</p><p>3.在每次事件循环的结束，不一定会发生渲染。setTimeout 的执行时机并不稳定。</p><p>4.RAF 的执行时机稳定是在当前帧的最后，下一帧的开始之前，非常适合做动画。</p><p>5.RIC 的执行时机并不稳定，computeDeadline 由被多因素影响计算得出，但可以传递 timeout 控制执行的 deadline。</p><p>6.用 TTI 和 FID（INP）去衡量页面的交互性能。</p><p>7.用长任务拆分、延迟非关键模块执行、延迟非可视区域图片加载、减少页面渲染以及配置灵活的缓存策略等手段，提升网站的交互性能。</p><p>——END——</p><p><strong>参考资料：</strong></p><p>[1]HTML living standand - evnet loop processing model:</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhtml.spec.whatwg.org%2Fmultipage%2Fwebappapis.html%23event-loop-processing-model" target="_blank">https://html.spec.whatwg.org/multipage/webappapis.html#event-loop-processing-model</a></p><p><strong>推荐阅读：</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574835%26idx%3D1%26sn%3D31d1b6ec0ecf857f5fb12ca8a2816fb1%26chksm%3Dc03f954ff7481c599d34556eeaba1960a4261d2e304e86989a54fa9e334c15a9ff8d58aa00b1%26scene%3D21%23wechat_redirect" target="_blank">百度搜索展现服务重构：进步与优化</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574780%26idx%3D1%26sn%3D8eda1e3f3dc06d6f10394be4a9df86f8%26chksm%3Dc03f9480f7481d968a54f75a113c16651a5c371ae43f078705f965d0a51a19491f41d2179ab7%26scene%3D21%23wechat_redirect" target="_blank">百度 APP iOS 端包体积 50M 优化实践 (七) 编译器优化</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574670%26idx%3D1%26sn%3D45e9f922faad4fffceca07bc116b15eb%26chksm%3Dc03f94f2f7481de45ad4b17e0235eb0074e4d78dff760654e44aed98d6684d7e0ba1ccbeffcd%26scene%3D21%23wechat_redirect" target="_blank">百度搜索内容 HTAP 表格存储系统</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574408%26idx%3D1%26sn%3Dfc0f0b325a348a401d647f3cb048b68a%26chksm%3Dc03f93f4f7481ae2c964c6fd7ab54a8291edb7b2dae16c20c5e30e998a0bceb418d631d40abf%26scene%3D21%23wechat_redirect" target="_blank">大模型时代，「人人可 AI」的百度开发者平台长什么样？</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247574315%26idx%3D1%26sn%3De1fe788ba3ae4f0b2d503bfac899cefa%26chksm%3Dc03f9357f7481a413ba7325eb9064078f097e7586136b885d11db67b4a5955412312d2428869%26scene%3D21%23wechat_redirect" target="_blank">数十万 QPS，百度热点大事件搜索的稳定性保障实践</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 26 Dec 2023 01:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/10322486</guid>
            <link>https://my.oschina.net/u/4939618/blog/10322486</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源，想说爱你不容易~]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>前言</h3><p>其实很早以前，我就想写一篇文章，聊聊我之前的开源历程，我不是什么大牛，只是 github 上千万项目中一名普通 owner，但是我热爱开源，热爱分享，热爱编程，正因为如此，我打算借着 teamlinker 开源之际，从一名普通开源从业者的角度和大家聊聊我开源生涯中的种种过往，对自己对别人也算是一种借鉴和启发吧。</p><p>我不是计算机科班出身，只是秉持着从小对编程的热爱，通过自学走上了软件开发的道路，这一路上有风雨有彩虹，受到过质疑，但也受到过更多的鼓励和支持，也正因为如此，我格外能感受到所谓的自我学习和提升是一件多么不容易的事情，所以当我接触到开源的时候，自然而然的就有种说不出的亲切感，看着那些工整的源码，就仿佛像一个老师，循循善诱的给我们讲解着它的结构和功能，只要你愿意探索，就可以在其中发现无穷的乐趣。</p><h3>从开源走向创业</h3><p>还记得在 2016 年的时候，我当时在一家软件公司担任技术总监的职务，其中遇到的一个令人头疼的问题就是前后端总是为接口文档的同步问题争执不下，我当时就想如何有一个产品可以管理并且自动的同步接口文档，让前后端都有一个唯一的参照物的话，这个问题就可以得到很大的缓解，在网上找了一遍后并没有发现满意的产品，于是我决定自力更生，利用业余时间，完成了这个接口文档管理软件的开发，取名为：DOClever（老粉应该还记得这个产品一开始的名字叫 SBDoc ~）。</p><p>其实在一开始的时候，我并没有想太多，当时只是试探性的放到 github 上，并且给我的一些朋友试用，却出乎意料的大受好评。看见大家的积极的反馈以及 github 上 star 数目的与日俱增，我获得了作为程序员生涯以来第一次无与伦比的满足感。真正感受到原来开源是一件这么美妙的事情。</p><p>随着 DOClever 业务的加剧以及用户的扩大，在 2017 年的时候，我决定将 DOClever 做大做强，找了一些朋友，我们决定出来创业，当时也正值创业风口，我们的这个项目也很快受到了不少关注。我们当时主要的宣传窗口就是开源中国，在这里我们认识了很多志同道合的朋友，也得到了编辑们对我们项目的各种肯定与支持，在此我还是要好好感谢下开源中国，感谢你们对中国开源事业所做的贡献。</p><h3>商业化的探索与反思</h3><p>创业后很快我面临的便是广大开源软件共同遇到的一个问题：盈利。当时我试过很多方案，比如开源版本与收费版本分开，打造收费插件，产品免费服务收费等，但最后都发现很难真正落地，而我当时的想法也很单纯，觉得只要产品好，用户爱用就一定会有办法挣钱，所以我当时的精力全部扎进了产品研发中，开发了接口自动化测试模块，还大胆做出了一个决定：利用 electron 打造了桌面端，在当时的竞品中，敢做桌面端的我们算是第一个了，桌面端出来后用户的反馈很好，但是我们还是陷入无法盈利的恶性循环。也就是说你的产品不错，大家爱用，给你捐点小钱也 ok，但是一旦触及商业化，那么对不起在下告辞了~</p><p>后来我们也接过一些企业的定制化服务，周期长，任务重，有的甚至要驻点，但是为了团队的发展我们又不得不做，我内心知道这个不是长久之计，也实在不想把我们做成一个外包公司，我更希望大家能认可我们统一化的产品，如果你有什么需求，可以给我们一点时间，我们可以把它打造成模块化的功能。但是往往甲方爸爸告诉我：不行，你需要专门为我定制一个 VVVVVVIP 至尊特供版。</p><p>其实我事后有认真反思过商业化的问题，觉得主要有两点，接口管理平台本身市场就那么大，竞品也不少，而且软件的门槛也低，我之所以能脱颖而出无非是我免费开源，功能也不差，但用户不是非我不可，很多用户都是因为 postman 的协作功能需要收费而转向了我们，这些人的需求也很明确，就是要用免费的。第二点就是对于稍微大一点公司，他们内部都有自己的 api 接口管理，不会轻易的去使用外面的平台，就算去使用，也会对你原来的平台改的面目全非，有点公司良心点的还会请你去做个宣讲啥的，感谢你下。有的就直接 copy 你的代码把它变成他们内部开发的一个平台，这对于我们开源创业者可谓是竹篮打水一场空。</p><h3>创业失败</h3><p>在 2018 年年中的时候，我向现实做出了屈服，我解散了我们团队，我也去了一家大厂面试。我记得当时那个面试官问我做过哪些项目的时候，我把我的 github 给他看了下，他满意的笑了笑，于是我很快就被录取了。DOClever 自此也停止了更新，我把精力都投入了新的工作中，日子就这样一天天波澜不惊的过去，直到有一天群里的一个小伙伴给我发了一个链接，我点进去一看直接无语了，也是一个接口管理平台，但是里面的功能，业务逻辑甚至页面的布局和按钮的摆放都和 DOClever 一摸一样，霎那间我明白我们被抄袭了。可是我又能做些什么呢，DOClever 很久没有更新了，我当时的公司也注销了，软件著作权也失效了，我能做的就是祝福他们做的比我更好吧！</p><p>时光荏苒，如今，我也从那个大厂离开了，庆幸的是我在此期间积累了一些资本，至少可以做几年自己想做的事情，回顾过往，你问我开源后悔嘛，我不后悔，却又五味杂陈，因为开源我可以让更多人认识我，了解我，实现自我价值，也能找到满意的工作，五味杂陈是因为开源只是一个商业化的手段，不是目的，开源不光是源码的公开，更是一种价值的传递，内心的坚持，精神的坦诚，它对于创业者的要求更高，而我还远远不够。</p><h3>感悟</h3><p>我个人认为，开源创业需要满足两个条件：<br> 1、你的产品所在市场潜力够大，而你的产品的业务和功能又有一定的不可替代性。<br> 2、必须要有一套清晰的盈利模式，哪些东西可以通过开源来吸引流量，哪些东西是你的压箱底的宝贝，真正能让用户掏钱买单，这些我们自己是必须清楚的。很多人会吐槽国内的开源氛围太差，全是伸手党，你辛辛苦苦写的东西，别人给你一包装就是他自己的了。其实很多时候我们自己又何尝不是呢，我们的产品几乎没有哪个不用开源框架或者开源库的，但是不代表我们不尊重开源，国外的很多商用软件都会把用到的开源包列举出来一一感谢，这就是一个很好的例子，国内最近关于开源协议的几起民事诉讼的胜诉我相信也将成为一个很好的典范。</p><h3>新的征程</h3><p>回到我现在在做的事情 Teamlinker，这是一个基于人工智能的团队协作平台，融入了项目管理，视频会议，文件共享等功能，可以最大程度的让团队成员协同办公。很多人劝我 teamlinker 不要开源，但是我觉得作为一个技术从业者，我的骨子里有一种自由分享的精神，我也非常期望能和别人的交流来让我的产品变得更好，我想再试一试，失败并不可怕，可怕是在同样的地方跌倒却再也不敢站起来了~</p><p>开源，想说爱你不容易，但是我却甘之如饴。</p><p>后记：欢迎大家给我们的 teamlinker 提出一点建议和批评，如果能有一点小小的鼓励那就更好啦。<br> 官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fteam-linker.com" target="_blank">https://team-linker.com</a><br> Github：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTeamlinker%2FTeamlinker" target="_blank">https://github.com/Teamlinker/Teamlinker</a><br> Gitee：<a href="https://gitee.com/sx1989827/teamlinker">https://gitee.com/sx1989827/teamlinker</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 10:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272643</guid>
            <link>https://www.oschina.net/news/272643</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 也可以用 eBPF 了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>此项目<span style="background-color:#ffffff; color:#1f2328">允许在 Windows 上使用 Linux 生态中熟悉的现有 eBPF 工具链和应用接口。也就是说，该项目将现有的 eBPF 项目作为子模块，并添加中间层，使其能在 Windows 上运行。</span></p><p><span style="background-color:#ffffff; color:#1f2328">下图显示了本项目的基本架构和相关组件：</span><img height="1140" src="https://static.oschina.net/uploads/space/2023/1225/174251_tkYJ_3820517.png" width="1556" referrerpolicy="no-referrer"></p><p style="text-align:start"><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>现有的 eBPF 工具链（clang 等）可用于从各种语言的源代码生成 eBPF 字节码。字节码可以被任何应用程序使用，也可以通过 bpftool 或 Netsh 命令行工具使用。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>eBPF 字节码会被发送到一个静态验证器（PREVAIL 验证器），该验证器托管在一个安全的用户模式环境中，如系统服务、飞地或可信虚拟机。如果 eBPF 程序通过了验证器的所有检查，就可以加载到内核模式执行上下文中。通常情况下，这是通过 JIT 编译器（通过 uBPF JIT 编译器）将程序编译成本地代码并传递给执行上下文来实现的。在调试构建中，字节码可直接加载到解释器（从内核模式执行上下文中的 uBPF），但解释器不会仅在调试模式中支持，不提供发布构建频道支持，因为它被认为安全性较低。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>安装到内核模式执行上下文中的 eBPF 程序可以附加到各种钩子上，并调用 eBPF shim 公开的各种辅助 API，eBPF shim 内部封装了公共 Windows 内核 API，允许在现有版本的 Windows 上使用 eBPF。许多辅助程序已经存在，随着时间的推移，还将添加更多钩子和辅助程序。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start">此项目并不是 eBPF 的分支，<span style="background-color:#ffffff; color:#1f2328">eBPF for Windows 利用现有项目，包括 IOVisor uBPF 项目和 PREVAIL 校验器，通过为代码添加 Windows 特定的托管环境，将它们运行在 Windows 上。</span></p><p style="text-align:start"><span style="background-color:#ffffff; color:#1f2328">Linux 提供了许多钩子和辅助工具，其中有些是 Linux 特有的（例如，使用 Linux 内部数据结构），不适用于其它平台，而其它钩子和辅助工具则是通用的，目的是为 eBPF 程序提供支持。</span></p><p style="text-align:start"><span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>eBPF 还可以与 </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>HyperVisor-enforced Code Integrity（<span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>HyperVisor 强制代码完整性，HVCI）一起使用</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff; color:#1f2328">。启用 HVCI 后，eBPF 程序无法进行 JIT 编译，但可以以本地模式或解释模式运行。</span></p></div>
                                                                ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 10:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/ebpf-for-windows</guid>
            <link>https://www.oschina.net/p/ebpf-for-windows</link>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维「天工 SkyAgents」Beta 版全网测试]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><strong><span><span><span><span style="color:#1f2329">12 月 25 日，昆仑万维 AI Agents 开发平台「天工 SkyAgents」Beta 版正式开放测试，用户可在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodel-platform.tiangong.cn%2F" target="_blank">https://model-platform.tiangong.cn/ </a>立即体验。</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">昆仑万维「天工 SkyAgents」AI Agents 开发平台，基于昆仑万维「天工大模型」打造，具备从感知到决策，从决策到执行的自主学习和独立思考能力。用户可以通过自然语言构建自己的单个或多个「私人助理」，并能将不同任务模块化，通过操作系统模块的方式，实现执行包括问题预设、指定回复、知识库创建与检索、意图识别、文本提取、http 请求等</span></span></span></span><span><span><span>任务。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>在大模型技术高速发展、AI Agents 应用不断进步的当下，</span></span></span><span><span><span><span style="color:#1f2329">昆仑万维「天工 SkyAgents」是我们在智能体领域的一次探索与尝试。这个平台也许并不完美，但我们希望与广大开发者们携手共建、互助成长，不断开拓人工智能技术的应用边界。</span></span></span></span><span><span><span>现在不完美是为了未来的完美，我们一直在技术追求的过程中，坚信而勇于突破。</span></span></span></span></span></span></span></p><h4><span><span><span><span><strong><span><span><span>携手探索，合作共创</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>大模型时代，交互式 AI 有望成为未来大模型技术的主流落地方向。历史告诉我们，新兴事物的演进总会找到一个稳定的术语来描述这种载体，而 AI Agents（智能体）已经显现出了巨大潜力。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>目前，全球对智能体的关注异常热烈，OpenAI 高度关注智能体领域，并在 OpenAI dev day 发布会上发布了自定义 GPTs 以及 Assistance API；DeepMind 的联合创始人最近</span></span></span><span><span><span>也</span></span></span><span><span><span>提到下一代人工智能技术的发展方向将是交互式 AI，而不是生成式 AI。这种交互式 AI 很大程度上与智能体的描述是相符的，用户可以通过要求智能体完成各种任务，而智能体则可以操作软件或与人类协作，完成复杂场景的工作。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>在技术范式上，昆仑万维也在不断思考驱动智能体技术快速发展的底层技术和架构。我们同时也清楚地认识到，即使在大模型的语言交互能力的加持下，我们离一个完全可以自动做决策并执行任务的智能体还有距离。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span>今天，昆仑万维正式开放「天工 SkyAgents」Beta 版，</span></span></span><strong><u><span><span><span><u><span>作为我们在 AI Agents 技术能力和应用能力上的一次探索</span></u></span></span></span></u></strong><span><span><span>。我们希望通过此次探索，能让越来越多的用户与开发者能够将大</span></span></span><span><span><span><span style="color:#1f2329">模型技术应用到工作生活中，打造出满足日常需求、激发灵感创新的专属 AI Agents。我们也希望更多对 AI Agents 感兴趣的朋友们能够与我们一同携手共创。欢迎广大伙伴们提出建议与意见。 </span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="619" src="https://oscimg.oschina.net/oscnet/up-e7a06ccac57f87401c80becb561193a4041.png" width="1265" referrerpolicy="no-referrer"></p><h4><span><span><span><span><strong><span><span><span>什么是 AI Agents？</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">Agent 一般译为「智能体」或「代理」，其概念最早由麻省理工学院人工智能实验室（MIT AI Lab）创始人之一 Marvin Minsky 在其 1986 年出版的《思维的社会》一书中提出。它由社会与社会行为概念被引入计算系统内，指的是在某一环境下，能持续自主地发挥作用的计算实体。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">AI Agents 指的则是由人工智能技术驱动，能够感知环境、进行决策和执行动作的智能实体。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">AI Agents 并不是一个新兴的概念，自人工智能技术学科建立以来，就陆续有围绕 AI Agents 的研究出现。2012 年深度神经网络浪潮兴起后，有一支以强化学习训练 AI Agents 的学术派系诞生，轰动全球的围棋机器人 AlphaGo 可以看作是这一流派的研究成果。不过，此类 AI Agents 更适合对抗性游戏场景，在真实世界中较难落地。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">然而，大模型的出现改变了这一切。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">2023 年，随着大模型技术在自然语言理解、工程能力、数据能力、存储能力等领域的突破，大量对话交互类「GPT」涌现，以大模型技术驱动的 AI Agents 在通用性、实用性、可落地性等都得到了飞速发展，在全球掀起了又一阵 AI Agents 热潮。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">传统大模型应用大多基于 Prompt（用户提示词）实现，Prompt 的质量将直接影响大模型的回答效果，</span></span></span></span><strong><span><span><span><span style="color:#1f2329">缺乏提示词工程能力的普通用户难以将大模型的真正能力发挥到极致</span></span></span></span></strong><span><span><span><span style="color:#1f2329">。而 AI Agents 只需要用户给定工作目标，就可以通过独立思考、调用工具去逐步完成任务，极大降低大模型技术应用门槛。</span></span></span></span></span></span></span></span></p><h4><span><span><span><span><strong><span><span><span>AI Agents 三大核心模块：大脑、感知、执行</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">根据复旦大学论文《The Rise and Potential of Large Language Model Based Agents: A Survey》，AI Agents 可以划分为大脑（Brain），感知（Perception）、执行（Action）三大模块化能力。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><img alt="" height="497" src="https://oscimg.oschina.net/oscnet/up-e9dac7f27a534b98ae08bc84f655f2b0dff.png" width="828" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">（图片来源：《The Rise and Potential of Large Language Model Based Agents: A Survey》） </span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">1. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">大脑（Brain）</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">大脑是 AI Agents 的「核心信息处理中心」，具备理解当前环境并形成「记忆（Memory）」的能力，同时也具备存储并检索长期记忆的能力。「大脑」可以根据「记忆」和当前接收的信息进行逻辑推理，并将复杂问题拆解成可实现的子任务，应对复杂场景任务。同时，通过 RAG（检索增强生成）技术，AI Agent 可以根据当前场景和用户设定的目标进行进一步决策，实现独立思考、规划（Planning）和推理（Reasoning）。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">2. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">感知（Perception）</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">感知模块能够让 AI Agents 基于当前的环境和场景获取足够的信息，这正是其与传统 RPA 系统的区别之处。RPA 系统在面对大量未知信息、难以预测的环境时无法进行工作，AI Agents 则可以通过感知信息并做出对应的思考和行动，从而实现感知、理解和自主探索世界。 </span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">3. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">执行（Action）</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">执行模块赋予了 AI Agents 执行任务的权限和能力。AI Agents 在接收到用户任务指令后，结合由感知模块收集的当前场景信息，通过大脑进行总结和推理后，输出到执行模块中，使 AI Agents 能够根据用户需求完成指令。同时，AI Agents 拥有调用、使用工具（Tool use）的能力，这些工具可以帮助 Agents 更高效地完成复杂任务，同时也提高了其在某些具体场景中的可信度和灵活度，相关应用场景包括让 AI Agents 购买飞机票、点外卖、完成企业 IT/客服/法律任务等。</span></span></span></span></span></span></span></span></p><h4><span><span><span><span><strong><span><span><span>天工 SkyAgents</span></span></span></strong></span></span></span></span></h4><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">「天工 SkyAgents」基于昆仑万维「天工大模型」打造，拥有专属「大脑」、「感知」、「执行」模块。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">个人用户/开发者可以通过「天工 SkyAgents」进行自然语言和简单操作，无需代码编程能力，即可在几分钟之内部署属于自己的 AI Agents，完成行业研究报告、单据填写、商标设计、甚至健身计划、旅行航班预定等多项私人定制需求。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">企业用户/开发者则可以将「天工 SkyAgents」的众多能力按需拼装成企业 IT、智能客服、企业培训、HR、法律顾问等众多个性化的应用，并支持一键服务部署，确保其在不同业务系统中的无缝接入。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">「天工 SkyAgents」的 AI 能力背后，是昆仑万维 AI Agents 技术在模块化任务组件、智能知识库构建、第三方工具调用、个性化 AI Agents 一键分享等领域的能力积累。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">1. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">模块化任务组件，零代码打造专属 AI Agents</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">当前，多数用户既不具备代码开发经验，也不具备训练大模型提示词工程（Prompt Engineering）的能力，难以将众多日常生活的实际需求通过对话问答形式快速实现，无法将大模型能力发挥到极致。为了解决这一问题，「天工 SkyAgents」将大量任务组件模块化，集成了智能对话、信息加工、信息提取、信息分类、第三方数据获取、向量检索等能力。</span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">智能对话：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">智能对话模块借助 AI 能力，将用户发送的内容，通过大语言模型进行处理并回复给用户指定内容。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">信息加工：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">通过预设提示词（Prompt）的方式让大模型对特定信息输入进行加工，以获得符合需求的内容。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">信息提取：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">通过大模型对语义的理解，可以从输入信息中提取目标信息</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">信息分类：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">借助大模型的智能分析，将用户问题进行分类，针对不同类型的问题执行不同操作，方便进行个性化处理；</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">第三方数据获取：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">第三方数据接入会携带相关的参数，系统向指定地址发送 POST 请求，并接收响应。系统在携带相关参数的同时，可以实现与其他应用服务的数据互联互通。基于第三方数据获取模块可以极大扩展 AI Agents 的能力，打通数据库操作、联网搜索等更多场景。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">向量检索：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">针对常见的用户提问，系统可以将问题添加进知识库，便于搜索和查找。而对于「知识库」模块而言，用户可以输入问题，系统将在知识库中搜索相关问题与解答，并用自然语言进行输出。</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">2. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">智能知识库构建，支持大规模知识导入</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">大模型能力虽强，但也有其天生的弱项。一方面，大模型通过参数训练获得的知识只能停留在某一时点，更新成本很高；另一方面，大模型的训练数据通常以通用知识为主，细分领域的数据往往缺乏。为了解决这一问题，「天工 SkyAgents」支持导入更多格式和更大规模的数据和知识，给大模型增加了「知识库外脑」。</span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">支持多种数据导入形式：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">文本、文件、网站、问答对、在线文档等方式，轻松将已有知识进行导入</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">知识库 Embedding：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">将知识库中的内容元素表示为低维度的向量，使得知识库中的元素可以更容易地进行计算相似性、寻找相邻的实体等数学运算，从而提高了知识库在 AI Agents 中的可操作性。</span></span></span></span></span></span></span></span></li></ul><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">知识库自由链接：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">每个 AI Agents 可以自由链接所属知识库并同时由多个知识库进行内容供给，每个知识库也可以同时链接多个 AI Agents，知识库内容可根据需要启用和弃用，实现更灵活的知识内容管理。</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">3. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">第三方工具调用，多场景随心应对</span></span></span></span></strong></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">第三方工具调用：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">工具调用能力是将 AI Agents 与大量对话类 GPT 区别开来的核心能力之一，比如在机票预订场景中，除了对用户需求与航班信息进行分析判断，AI Agents 还需要调用票务平台、电子支付等不同工具。因此，除了基础的模块外，「天工 SkyAgents」还支持各类第三方工具的调用，用户可以根据自身需要进行工具的开发，使得构建 AI Agent 时拥有更多灵活的自由度。</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#3370ff">4. </span></span></span></span><strong><span><span><span><span style="color:#1f2329">个性化 AI Agents 一键分享</span></span></span></span></strong></span></span></span></span></p><ul><li><span><span><span><span><strong><span><span><span><span style="color:#1f2329">一键分享：</span></span></span></span></strong><span><span><span><span style="color:#1f2329">为了回馈广大用户与开发者们，更便捷地打造与使用 AI Agents，「天工 SkyAgents」上线新年专属活动，推出理想伴侣、有缘机伴、暖心家园三款官方新年模版，并全面简化了分发和使用流程。用户根据自己的创意设计出的 AI Agents 可以通过链接的方式向更多人分享，使用者只需点击链接，即可获得对该 AI Agents 的访问权。点击创建：https://model-platform.tiangong.cn/</span></span></span></span></span></span></span></span></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#1f2329">能力更全面、应用更智能、分享更便捷、平台更好用。本次「天工 SkyAgents」beta 版的正式开放内容，将进一步推动大模型技术的普惠化，帮助缺乏代码开发能力的个人与中小企业积极拥抱大模型技术，助力大模型走入千家万户，为人工智能生态发展贡献力量。</span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><span><span><span><span><strong><span><span style="background-color:#fbbfbc"><span><span>扫码进入「天工开放平台」 ，快速构建 AI Agent</span></span></span></span></strong></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:center"><img alt="" height="280" src="https://oscimg.oschina.net/oscnet/up-9032e1a9041a11a6ce891a3020335655fae.png" width="280" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 09:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272624</guid>
            <link>https://www.oschina.net/news/272624</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[燧原科技增资至 1 亿元，腾讯为第一大股东]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">天眼查 App 显示，上海燧原科技股份有限公司于近日发生工商变更，注册资本由约 443 万人民币增至 1 亿人民币。</span></p><p><span style="color:#000000">上海燧原科技股份有限公司（曾用名：上海燧原科技有限公司）成立于 2018 年 3 月，法定代表人、董事长兼总经理为赵立东（ZHAO LIDONG），经营范围含集成电路、计算机硬件研发、批发、零售，自有研发成果转让，并提供相关技术咨询与技术服务，销售自产产品，集成电路制造等。</span></p><p><span style="color:#000000">股东信息显示，<span style="background-color:#ffffff">该公司由腾讯科技（上海）有限公司、赵立东、张亚林、国家集成电路产业投资基金二期股份有限公司等共同持股。其中，腾讯科技（上海）有限公司持股约 21.37%，为第一大股东。</span></span></p><p><img height="250" src="https://oscimg.oschina.net/oscnet/up-1732a5466871889cdbf8c8cbb652bc144ab.png" width="700" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 25 Dec 2023 09:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/272620</guid>
            <link>https://www.oschina.net/news/272620</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
