<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 06 Oct 2023 11:27:28 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[1/8 的开源下载包含已知漏洞，开源项目的积极维护减少]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">Sonatype&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.sonatype.com%2Fintroducing-our-9th-annual-state-of-the-software-supply-chain-report" target="_blank">发布</a>了最新的一份</span>《软件供应链状况》报告，深入探讨了如何在充满选择的世界中定义更好的软件，并探讨人工智能 (AI) 对软件开发的深远影响；还研究了开源供应、需求和安全之间错综复杂的相互作用。</p><p>报告跟踪了 Java (Maven)、JavaScript (npm)、Python (PyPI)、.NET (NuGet Gallery) 四大开源生态系统的开源应用增长情况。2022 年至 2023 年间，可用开源项目的数量平均增长了 29%。2023 年，开源项目平均发布了 15 个可供使用的版本，不同开源注册中心的特定生态系统平均有 10 到 22 个版本。这意味着每个月都会发布 1-2 个新版本，在观察到的生态系统中总共发布了 6000 万个新版本。</p><p><img height="293" src="https://oscimg.oschina.net/oscnet/up-a3af85a689f0adbcfb8236b4dac77b7f235.png" width="500" referrerpolicy="no-referrer"></p><p>每个受检测的生态系统都表现出一致的项目增长率，平均同比增长率高达 29%。</p><p><img height="295" src="https://oscimg.oschina.net/oscnet/up-9ab7acc5786b753b241922eeaa519953a3d.png" width="500" referrerpolicy="no-referrer"></p><p>但随着开源组件供应量的持续增长，其需求却未能与之同步。在过去两年中，下载量的增长率逐渐下降。2023 年的平均增长率为 33%，与 2021 年 73% 的增长率相比大幅下降。</p><p><span style="color:#000000">与此同时，开源软件安全问题没有放缓的迹象。截至 2023 年 9 月，研究团队共发现了&nbsp;245,032 个恶意软件包，是往年总和的 2 倍。八分之一的开源下载存在已知风险，且仍有 23% 的 Log4j 下载存在严重漏洞。</span></p><p><img height="304" src="https://oscimg.oschina.net/oscnet/up-b8b946760f70163d67ebbf53b91a14930fd.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">开源项目的主动维护也变得越来越少。研究表明，去年有近五分之一（18.6%）的项目停止维护，影响了 Java 和 JavaScript 生态系统。<span style="background-color:#ffffff">只有 11% 的开源项目实际上得到了积极维护。</span>尽管存在这些缺陷，但 Sonatype 仍然表示，近 96% 存在已知漏洞的组件下载可以通过选择无漏洞版本来避免。</span></p><p><span style="color:#000000">就软件开发中的人工智能而言，97% 的受访 DevOps 和 SecOps 领导者表示，他们目前在工作流程中某种程度上使用了人工智能，大多数人每天使用两个或更多工具。</span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>去年，企业环境中 AI 和 ML 组件的采用率增加了 135%。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">研究还发现，企业自认为的安全程度与实际情况之间存在脱节。67% 的公司表示，他们确信自己的系统中没有来自漏洞库的代码，但今年有 10% 的公司因漏洞组件而遭遇安全漏洞。39% 的公司可以在</span><span style="background-color:#ffffff">&nbsp;1 到 7 天的时间内发现漏洞，29% 的公司需要一周以上的时间，28% 的公司只需要不到一天的时间。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sonatype.com%2Fstate-of-the-software-supply-chain%2Fintroduction" target="_blank">查看完整报告</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 04:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260454/9th-annual-state-of-the-software-supply-chain-report</guid>
            <link>https://www.oschina.net/news/260454/9th-annual-state-of-the-software-supply-chain-report</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AgentVerse —— 多 LLM 环境模拟框架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>AgentVerse 提供了一个多功能框架，可简化为大型语言模型（LLM）创建定制多代理环境的过程。框架旨在以最小的投入促进快速开发和定制，从而使研究人员能够专注于他们的研究，而不是被实施细节所困扰。</p><p><img alt="" height="333" src="https://static.oschina.net/uploads/space/2023/0915/161848_BpYH_4252687.png" width="500" referrerpolicy="no-referrer"></p><h4 style="text-align:start"><strong><span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特点</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><p><span><span><strong>高效的环境构建：</strong>我们的框架提供了一系列基本构建块，可以轻松创建多代理环境。只需要配置文件中的几行，就可以轻松构建 LLM 聊天室等基本环境。此过程需要为 LLM 士定义环境设置和提示，使研究人员能够专注于实验和分析。</span></span></p></li><li><p><span><span><strong>可定制组件</strong>：AgentVerse 通过将多代理环境划分为五个功能模块并定义各自的接口来简化多代理环境。对于使用 AgentVerse 提供的基础模块无法直接构建的复杂环境，你可以自定义这五个功能模块中的一个或多个接口，根据你的需求高效地创建你自己的多 Agent 环境。</span></span></p></li><li><p><span><span><strong>工具（插件）利用</strong>：AgentVerse 通过工具支持多代理环境。目前，AgentVerse 支持<a href="https://github.com/OpenBMB/BMTools">BMTools</a>中提供的工具。</span></span></p></li></ul><p><img height="287" src="https://static.oschina.net/uploads/space/2023/0915/161814_aa6e_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/agentverse</guid>
            <link>https://www.oschina.net/p/agentverse</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | Rocky Linux 系统安全加固工具 narsil]]>
            </title>
            <description>
                <![CDATA[<p><a href="https://gitee.com/seatonjiang/narsil/blob/main/README.md">English</a> | 简体中文</p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%23gh-light-mode-only"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/narsil-light.png#gh-light-mode-only" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%23gh-dark-mode-only"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/narsil-dark.png#gh-dark-mode-only" referrerpolicy="no-referrer"></a></p><p align="center"><img src="https://img.shields.io/static/v1?style=flat-square&amp;message=Rocky%20Linux&amp;color=15B076&amp;logo=rockylinux&amp;logoColor=FFFFFF&amp;label=" referrerpolicy="no-referrer"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fissues"><img src="https://img.shields.io/github/issues/seatonjiang/narsil?style=flat-square&amp;color=blue" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fpulls"><img src="https://img.shields.io/github/issues-pr/seatonjiang/narsil?style=flat-square&amp;color=brightgreen" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fblob%2Fmain%2FLICENSE"><img src="https://img.shields.io/github/license/seatonjiang/narsil?&amp;style=flat-square" referrerpolicy="no-referrer"></a></p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fissues">报告问题</a>
    ·
    <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fissues">功能需求</a></p><p align="center">Rocky Linux 的系统安全加固工具</p><h2><a id="user-content--工具截图" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E5%B7%A5%E5%85%B7%E6%88%AA%E5%9B%BE"></a>💻 工具截图</h2><h3><a id="user-content-脚本执行" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C"></a>脚本执行</h3><p align="center"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/script-execution.png" referrerpolicy="no-referrer"></p><h3><a id="user-content-登录信息" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E7%99%BB%E5%BD%95%E4%BF%A1%E6%81%AF"></a>登录信息</h3><p align="center"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/login-information.png" referrerpolicy="no-referrer"></p><h3><a id="user-content-挂载硬盘" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E6%8C%82%E8%BD%BD%E7%A1%AC%E7%9B%98"></a>挂载硬盘</h3><p align="center"><img src="https://gitee.com/seatonjiang/narsil/raw/main/.github/mount-disk.png" referrerpolicy="no-referrer"></p><h2><a id="user-content--工具特性" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E5%B7%A5%E5%85%B7%E7%89%B9%E6%80%A7"></a>✨ 工具特性</h2><ul><li>限制密码使用期限为 30 天</li><li>密码过期 30 天后，该账户将被禁用</li><li>设置两次修改密码的时间间隔为 1 天</li><li>在密码过期前 7 天将发出警告</li><li>将系统默认加密算法设置为 SHA512</li><li>将会话超时策略设置为 180 秒</li><li>为新建的用户创建并加入一个同名的组</li><li>将新建用户的 home 目录权限设置为 0750</li><li>将存量用户的 home 目录权限设置为 0750</li><li>强化 OpenSSH 配置（有些配置需要手动配置）</li><li>禁止没有 home 目录的用户登录</li><li>禁止新建的用户使用 SHELL 登录</li><li>禁止上传和用户信息的功能</li><li>禁止删除用户时同步删除该用户的组</li></ul><p>还有很多特性没有被列举出来，可以参考 <code>scripts</code> 目录下的文件了解更多信息。</p><h2><a id="user-content--使用说明" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"></a>🚀 使用说明</h2><h3><a id="user-content-第一步克隆仓库" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E7%AC%AC%E4%B8%80%E6%AD%A5%E5%85%8B%E9%9A%86%E4%BB%93%E5%BA%93"></a>第一步：克隆仓库</h3><p>确保服务器安装了 Git，否则需要先用 <code>sudo dnf install -y git</code> 命令安装软件：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://github.com/seatonjiang/narsil.git</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>如果因为网络问题无法连接，可以使用 Gitee 镜像仓库，但是镜像仓库会有 <code>30</code> 分钟的延迟：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone https://gitee.com/seatonjiang/narsil.git</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-第二步编辑配置" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E7%AC%AC%E4%BA%8C%E6%AD%A5%E7%BC%96%E8%BE%91%E9%85%8D%E7%BD%AE"></a>第二步：编辑配置</h3><p>进入项目文件夹：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">cd </span>narsil</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>核对配置文件中的配置信息（配置文件说明在下文）：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">vi narsil.conf</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-第三步运行脚本" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E7%AC%AC%E4%B8%89%E6%AD%A5%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC"></a>第三步：运行脚本</h3><p>如果是 root 账号，可以直接运行，如果是普通账号，需要使用 <code>sudo</code> 运行，而且必须用 <code>bash</code> 运行该脚本：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--配置文件" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"></a>📝 配置文件</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c"># 每一项操作完成后进行验证</span></span><span id="LC2" class="line"><span class="py">VERIFY</span><span class="p">=</span><span class="s">'Y'</span></span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c"># 云服务器使用 Metadata 覆盖默认配置</span></span><span id="LC5" class="line"><span class="py">METADATA</span><span class="p">=</span><span class="s">'Y'</span></span><span id="LC6" class="line"></span><span id="LC7" class="line"><span class="c"># 在 banner 中添加生产环境的提示</span></span><span id="LC8" class="line"><span class="py">PROD_TIPS</span><span class="p">=</span><span class="s">'Y'</span></span><span id="LC9" class="line"></span><span id="LC10" class="line"><span class="c"># SSH 端口配置</span></span><span id="LC11" class="line"><span class="py">SSH_PORT</span><span class="p">=</span><span class="s">'22'</span></span><span id="LC12" class="line"></span><span id="LC13" class="line"><span class="c"># 时区配置</span></span><span id="LC14" class="line"><span class="py">TIME_ZONE</span><span class="p">=</span><span class="s">'Asia/Shanghai'</span></span><span id="LC15" class="line"></span><span id="LC16" class="line"><span class="c"># 主机名称配置（当 METADATA 为 Y 时会自动拉取元数据）</span></span><span id="LC17" class="line"><span class="py">HOSTNAME</span><span class="p">=</span><span class="s">'rockylinux'</span></span><span id="LC18" class="line"></span><span id="LC19" class="line"><span class="c"># DNS 服务器配置（当 METADATA 为 Y 时会自动拉取元数据）</span></span><span id="LC20" class="line"><span class="py">DNS_SERVER</span><span class="p">=</span><span class="s">'119.29.29.29 119.28.28.28'</span></span><span id="LC21" class="line"></span><span id="LC22" class="line"><span class="c"># NTP 服务器配置（当 METADATA 为 Y 时会自动拉取元数据）</span></span><span id="LC23" class="line"><span class="py">NTP_SERVER</span><span class="p">=</span><span class="s">'ntp.tencent.com'</span></span><span id="LC24" class="line"></span><span id="LC25" class="line"><span class="c"># Docker 配置</span></span><span id="LC26" class="line"><span class="py">DOCKER_CE_REPO</span><span class="p">=</span><span class="s">'http://mirrors.tencent.com/docker-ce/linux/centos/docker-ce.repo'</span></span><span id="LC27" class="line"><span class="py">DOCKER_CE_MIRROR</span><span class="p">=</span><span class="s">'mirrors.tencent.com'</span></span><span id="LC28" class="line"><span class="py">DOCKER_HUB_MIRRORS</span><span class="p">=</span><span class="s">'https://hub-mirror.c.163.com'</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--独立功能" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E7%8B%AC%E7%AB%8B%E5%8A%9F%E8%83%BD"></a>🔨 独立功能</h2><p>Narsil 中包含了一些独立的功能，这些功能并不在自动执行的脚本中，需要使用参数单独使用，可以使用 <code>sudo bash narsil.sh -h</code> 命令查看所有独立功能。</p><h3><a id="user-content-清理垃圾" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E6%B8%85%E7%90%86%E5%9E%83%E5%9C%BE"></a>清理垃圾</h3><p>清理所有的系统日志文件。</p><blockquote><p>某些云服务商提供的镜像由于制作的过程不规范，导致打包了一些垃圾文件到镜像中，建议在初始化系统之前先进行清理。</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-c</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-安装-docker" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E5%AE%89%E8%A3%85-docker"></a>安装 Docker</h3><p>安装 Docker 服务并设置镜像加速（腾讯云会自动使用内网加速地址）。</p><blockquote><p>安装完成后，可以使用 <code>docker run hello-world</code> 测试 Docker 的相关功能是否正常。</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-d</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-挂载硬盘-1" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E6%8C%82%E8%BD%BD%E7%A1%AC%E7%9B%98-1"></a>挂载硬盘</h3><p>交互式挂载数据盘（腾讯云会使用弹性云硬盘的软链接方式挂载），数据无价，操作过程切记小心！</p><blockquote><p>如果所选的硬盘已经被挂载，会提示解除挂载及格式化操作。</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-f</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-修改主机名称" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0"></a>修改主机名称</h3><p>配置文件的参数如果没有变化，那么将优先获取元数据。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-h</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-修改端口" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E4%BF%AE%E6%94%B9%E7%AB%AF%E5%8F%A3"></a>修改端口</h3><p>交互式修改 SSH 端口。</p><blockquote><p>端口范围需要在 10000 到 65535 之间。</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-p</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-卸载监控" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E5%8D%B8%E8%BD%BD%E7%9B%91%E6%8E%A7"></a>卸载监控</h3><p>卸载云服务商安装到服务器中的各种监控组件。</p><blockquote><p>目前已经支持腾讯云监控组件的卸载。</p></blockquote><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-r</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-添加交换空间" class="anchor" href="https://gitee.com/seatonjiang/narsil#%E6%B7%BB%E5%8A%A0%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4"></a>添加交换空间</h3><p>如果物理内存太小，建议添加交换空间。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nb">sudo </span>bash narsil.sh <span class="nt">-s</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--目录结构" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"></a>📂 目录结构</h2><p>下面是整个项目的文件夹结构，<code>config</code> 及 <code>scripts</code> 文件夹中的文件省略显示。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">narsil</span><span id="LC2" class="line">├── narsil.sh</span><span id="LC3" class="line">├── narsil.conf</span><span id="LC4" class="line">├── config</span><span id="LC5" class="line">│   └── <span class="o">(</span>some config files<span class="o">)</span></span><span id="LC6" class="line">└── scripts</span><span id="LC7" class="line">    └── <span class="o">(</span>some script files<span class="o">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--参与共建" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E5%8F%82%E4%B8%8E%E5%85%B1%E5%BB%BA"></a>🤝 参与共建</h2><p>我们欢迎所有的贡献，你可以将任何想法作为 Pull Requests 或 Issues 提交，顺颂商祺 :)</p><h2><a id="user-content--开源许可" class="anchor" href="https://gitee.com/seatonjiang/narsil#-%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF"></a>📃 开源许可</h2><p>项目基于 GNU 通用公共许可证 v3.0 发布，详细说明请参阅 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fseatonjiang%2Fnarsil%2Fblob%2Fmain%2FLICENSE">LICENCE</a> 文件。</p>]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/seatonjiang/narsil</guid>
            <link>https://gitee.com/seatonjiang/narsil</link>
        </item>
        <item>
            <title>
                <![CDATA[呼唤国内 Java 开发者共建 Solon]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h3>Solon 是什么？</h3><p style="color:#24292e; text-align:start"><strong>Java 生态级应用开发框架</strong>。从零开始构建，有自己的标准规范与开放生态（历时五年，具备全球第二级别的生态规模）。更多内容详见：<a href="https://www.oschina.net/news/258633">《中国这么多 Java 开发者，应该诞生出生态级应用开发框架》</a></p><h3>有什么特点？</h3><ul><li>启动快 5 ～ 10 倍。<span>&nbsp;</span><strong>（更快）</strong></li><li>qps 高 2～ 3 倍。<span>&nbsp;</span><strong>（更高）</strong></li><li>运行时内存节省 1/3 ~ 1/2。<span>&nbsp;</span><strong>（更少）</strong></li><li>打包可以缩小到 1/2 ~ 1/10；比如，300Mb 的变成了 23Mb。<span>&nbsp;</span><strong>（更小）</strong></li><li>同时支持 jdk8, jdk11, jdk17, jdk21,<span>&nbsp;</span><strong>graalvm native image</strong></li></ul><h3>呼唤？</h3><p style="color:#24292e; text-align:start">如果您开源感兴趣且愿意学习和贡献，欢迎您共建 Solon 生态。</p><h3>项目仓库地址？</h3><ul><li>gitee：<a href="https://gitee.com/noear/solon">https://gitee.com/noear/solon</a></li><li>github：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnoear%2Fsolon" target="_blank">https://github.com/noear/solon</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 05 Oct 2023 13:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260414</guid>
            <link>https://www.oschina.net/news/260414</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RMS 谈 AI、Red Hat 和道德软件许可]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">在瑞士 Biel 举行的庆祝 GNU 诞生 40 周年的活动上，GNU 和 FSF 创始人 Richard Stallman (RMS) 发表了 25 分钟的演讲，除了披露身患癌症外，他还谈论了 Red Hat、AI 和道德软件许可。</p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-d7dc3b154962c7667a46bffdb69807efc99.png" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><em>RMS 在瑞士 Biel 参加庆祝 GNU 40 岁生日的活动</em></p><p style="color:#000000; text-align:start">RMS 表示目前正在接受滤泡性淋巴瘤的治疗，他称之为「生长缓慢和可控的」。</p><p style="color:#000000; text-align:start"><strong>Red Hat&nbsp;<strong><strong>和&nbsp;</strong></strong>GPL</strong></p><p style="color:#000000; text-align:start">Red Hat 的支持合同禁止客户重新分发该公司的开源软件，RMS 认为此举可能没有违反 GPL 许可，但其做法是「反社会的」。</p><p style="color:#000000; text-align:start">他认为 Red Hat 应该停止这一做法，或者社区能通过施加影响力让 Red Hat 做出改变。</p><p style="color:#000000; text-align:start"><strong>生成式&nbsp;<strong><strong>AI&nbsp;</strong></strong>不具备理解能力</strong></p><p style="color:#000000; text-align:start">对于 AI 或生成式聊天机器人 ChatGPT，RMS 认为危险主要来自于 AI 营销人员所编织的敍事。</p><p style="color:#000000; text-align:start">他认为今天的 AI 尚未真正具有理解能力，但人们正使用 AI 这一术语来夸大其词，他说 ChatGPT 生成的内容都是废话，不过是流畅的废话。</p><p style="color:#000000; text-align:start">因此他认为，相信 ChatGPT 这类产品生成的内容的人都很愚蠢。</p><p style="color:#000000; text-align:start">RMS 说道：「在我看来，‘intelligence’ 意味着需要具备了解或理解某个领域的能力。如果某些东西不能真正理解事情，我们不应该说它是智能的，甚至是一点智能都没有，但人们正在用人工智能一词来描述废话生成器。」</p><p style="color:#000000; text-align:start">所以他没有把那些产品称作「人工智能」或任何带有 ‘intelligence’ 一词的东西，因为这会鼓励大众认为它们（生成式人工智能程序）所说的不是胡说八道。它鼓励大众相信它们，这给了他们造成巨大伤害的机会。</p><p style="color:#000000; text-align:start">然而，这并不意味着 RMS 认为真正的人工智能并不存在。</p><p style="color:#000000; text-align:start">他说：「有些程序可以查看一些放大细胞的照片并告诉你诊断结果，无论是否患有癌症，比任何人类医生都更有可能正确。另外，有一些人工智能系统可以非常有效地找出什么会吸引人们的注意力。这些被反社交媒体平台使用，可悲的是，它们效果很好。他们非常擅长这些工作，但他们所做的是让用户上瘾。」</p><p style="color:#000000; text-align:start"><strong>道德软件许可证</strong></p><p style="color:#000000; text-align:start">RMS 似乎不是所谓的「道德」软件许可证的支持者，试图监管谁可以使用软件。</p><p style="color:#000000; text-align:start">这不足为奇，因为他倡导的自由软件哲学的四项基本自由中的第一项是用户具有出于任何目的运行软件的自由。</p><p style="color:#000000; text-align:start">演讲最后，RMS 抛出了一个问题——「我们如何让年轻人对自由软件感兴趣？」</p><p style="color:#000000; text-align:start">他称这个问题是「我们在社区中面临的难题之一」。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 05 Oct 2023 04:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260374/rms-talks-red-hat-ai-and-ethical-software-licenses</guid>
            <link>https://www.oschina.net/news/260374/rms-talks-red-hat-ai-and-ethical-software-licenses</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龙芯为 Linux 6.7 支持 LoongArch 架构 KVM 虚拟机]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在已发布的多个 Linux 内核版本中，龙芯工程师都致力于为 LoongArch 架构实现更多内核功能。到目前为止，LoongArch CPU 的性能虽然无法与 x86_64 或 Arm 硬件相比，但正在慢慢变得更加实用，此外架构支持方面已经越来越成熟。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgit.kernel.org%2Fpub%2Fscm%2Flinux%2Fkernel%2Fgit%2Fchenhuacai%2Flinux-loongson.git%2Flog%2F%3Fh%3Dloongarch-next" target="_blank">根据龙芯工程师最新提交的代码</a>，Linux 内核的龙芯 Git 分支已将其所有初始 KVM 支持 (Kernel-based Virtual Machine) 代码提交到 loongarch-next 排队，迎接大约一个月后 Linux 6.7 合并窗口，即将迎来对基于内核的虚拟机支持。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-da5409cd652b9af9cb94b9dd19283a665d1.png" referrerpolicy="no-referrer"></p><p>这组补丁为龙芯 CPU 提供了所有基础的 KVM 支持代码。这种 KVM 支持依赖于 LoongArch 的虚拟化扩展，是 LoongArch 支持的首个虚拟化方式。</p><p>虽然考虑到目前 LoongArch CPU 性能水平，KVM 虚拟化支持在目前可能不太实用，但随着性能的提高，以及龙芯未来在云 / 虚拟化服务器领域的扩展，KVM 虚拟化支持将变得十分重要，因此提早做准备是有必要的。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 04 Oct 2023 04:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260296/loongarch-kvm-for-linux-6-7</guid>
            <link>https://www.oschina.net/news/260296/loongarch-kvm-for-linux-6-7</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GCC 安全策略文档已合并到仓库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">最近几周在 GCC 邮件列表进行讨论后，开发团队为 GCC 代码库添加了 GCC 安全策略，以概述编译器项目的安全流程。</p><p style="color:#000000; text-align:start"><img alt="" src="https://static.oschina.net/uploads/space/2023/1006/113615_PVqj_2720166.jpeg" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">该文档概述了 GCC 安全漏洞处理建议、GCC 语言运行库的安全注意事项、在 GCC 中实现的安全功能，以及私下报告安全漏洞的最佳方式。</p><p style="color:#000000; text-align:start">GCC 安全政策文档于周三<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgcc.gnu.org%2Fgit%2F%3Fp%3Dgcc.git%3Ba%3Dcommit%3Bh%3D4cac1d2eec5549927fe0caee179f80007e8d729b" target="_blank">提交</a>到代码库。如果希望了解更多关于 GCC 安全策略的内容，可以在&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgcc.gnu.org%2Fgit%2F%3Fp%3Dgcc.git%3Ba%3Dblob%3Bf%3DSECURITY.txt" target="_blank">SECURITY.txt</a>&nbsp;中阅读。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 04 Oct 2023 03:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260447/gcc-security-policy</guid>
            <link>https://www.oschina.net/news/260447/gcc-security-policy</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 使用 FHE 实现加密大语言模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 编辑器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">近来，大语言模型 (LLM) 已被证明是提高编程、内容生成、文本分析、网络搜索及远程学习等诸多领域生产力的可靠工具。</p><span id="OSC_h2_1"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">大语言模型对用户隐私的影响</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">尽管 LLM 很有吸引力，但如何保护好 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">输入给这些模型的用户查询中的隐私</code> 这一问题仍然存在。一方面，我们想充分利用 LLM 的力量，但另一方面，存在向 LLM 服务提供商泄露敏感信息的风险。在某些领域，例如医疗保健、金融或法律，这种隐私风险甚至有一票否决权。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">一种备选解决方案是本地化部署，LLM 所有者将其模型部署在客户的计算机上。然而，这不是最佳解决方案，因为构建 LLM 可能需要花费数百万美元 (GPT3 为 460 万美元)，而本地部署有泄露模型知识产权 (intellectual property, IP) 的风险。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Zama 相信有两全其美之法: 我们的目标是同时保护用户的隐私和模型的 IP。通过本文，你将了解如何利用 Hugging Face transformers 库并让这些模型的某些部分在加密数据上运行。完整代码见，此处。</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">全同态加密 (Fully Homomorphic Encryption，FHE) 可以解决 LLM 隐私挑战</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">针对 LLM 部署的隐私挑战，Zama 的解决方案是使用全同态加密 (FHE)，在加密数据上执行函数。这种做法可以实现两难自解，既可以保护模型所有者知识产权，同时又能维护用户的数据隐私。我们的演示表明，在 FHE 中实现的 LLM 模型保持了原始模型的预测质量。为此，我们需要调整 Hugging Face transformers 库，中的 GPT2 实现，使用 Concrete-Python 对推理部分进行改造，这样就可以将 Python 函数转换为其 FHE 等效函数。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-ratio="1.2027809965237544" data-type="png" data-w="863" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/338741ab-aa57-4681-b21f-eeeabcd24fce.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     图 1. GPT2 架构; 图源: https://en.wikipedia.org/wiki/GPT-2 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">图 1 展示了由多个 transformer block 堆叠而成的 GPT2 架构: 其中最主要的是多头注意力 (multi-head attention，MHA) 层。每个 MHA 层使用模型权重来对输入进行投影，然后各自计算注意力，并将注意力的输出重新投影到新的张量中。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 TFHE 中，模型权重和激活均用整数表示。非线性函数必须通过可编程自举 (Programmable Bootstrapping，PBS) 操作来实现。PBS 对加密数据实施查表 (table lookup，TLU) 操作，同时刷新密文以支持，任意计算。不好的一面是，此时 PBS 的计算时间在线性运算中占主导地位。利用这两种类型的运算，你可以在 FHE 中表达任何子模型的计算，甚至完整的 LLM 计算。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">使用 FHE 实现 LLM 的一层</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">接下来，你将了解如何加密多头注意力 (MHA) 中的一个注意力头。你可以在，此处，找到完整的 MHA 实现代码。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-ratio="1.0334538878842676" data-type="svg" data-w="1106" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/72fc90eb-872e-4a86-9f18-c949824b4c7d.svg" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     图 2. 在 FHE 中运行 LLM 模型的某些部分 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">图 2 概述了一个简化的底层实现。在这个方案中，模型权重会被分成两个部分，分别存储在客户端和服务端。首先，客户端在本地开始推理，直至遇到已第一个不在本地的层。用户将中间结果加密并发送给服务端。服务端对其执行相应的注意力机制计算，然后将结果返回给客户端，客户端对结果进行解密并继续在本地推理。</p><span id="OSC_h3_4"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">量化</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先，为了对加密值进行模型推理，模型的权重和激活必须被量化并转换为整数。理想情况是使用，训练后量化，这样就不需要重新训练模型了。这里，我们使用整数和 PBS 来实现 FHE 兼容的注意力机制，并检查其对 LLM 准确率的影响。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">要评估量化的影响，我们运行完整的 GPT2 模型，并让其中的一个 LLM 头进行密态计算。然后我们基于此评估权重和激活的量化比特数对准确率的影响。</p><figure data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-ratio="0.8024691358024691" data-type="png" data-w="567" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/e0260d01-fa3c-414c-a6d7-a0c0025b9e4b.png" referrerpolicy="no-referrer"><figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     单注意力头量化的平均 top-k 准确率 
   </figcaption></figure><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">上图表明 4 比特量化保持了原始精度的 96%。该实验基于含有约 80 个句子的数据集，并通过将原始模型的 logits 预测与带有量化注意力头的模型的 logits 预测进行比较来计算最终指标。</p><span id="OSC_h3_5"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">在 Hugging Face GPT2 模型中使用 FHE</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我们需要在 Hugging Face 的 transformers 库的基础上重写加密模块的前向传播，以使其包含量化算子。首先通过加载 GPT2LMHeadModel 构建一个 SingleHeadQGPT2Model 实例，然后手动使用 QGPT2SingleHeadAttention 替换第一个多头注意力模块，代码如下。你可以在，这里，找到模型的完整实现。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">self.transformer.h[<span style="color: #008080;line-height: 26px;">0</span>].attn&nbsp;=&nbsp;QGPT2SingleHeadAttention(config,&nbsp;n_bits=n_bits)<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">至此，前向传播已被重载成用 FHE 算子去执行多头注意力的第一个头，包括构建查询、键和值矩阵的投影。以下代码中的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">QGPT2</code> 模块的代码见，此处。</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;"><span style="line-height: 26px;"><span style="font-weight: bold;line-height: 26px;">class</span>&nbsp;<span style="color: #458;font-weight: bold;line-height: 26px;">SingleHeadAttention</span><span style="line-height: 26px;">(QGPT2)</span>:</span><br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #d14;line-height: 26px;">"""Class&nbsp;representing&nbsp;a&nbsp;single&nbsp;attention&nbsp;head&nbsp;implemented&nbsp;with&nbsp;quantization&nbsp;methods."""</span><br><br><br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="line-height: 26px;"><span style="font-weight: bold;line-height: 26px;">def</span>&nbsp;<span style="color: #900;font-weight: bold;line-height: 26px;">run_numpy</span><span style="line-height: 26px;">(self,&nbsp;q_hidden_states:&nbsp;np.ndarray)</span>:</span><br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Convert&nbsp;the&nbsp;input&nbsp;to&nbsp;a&nbsp;DualArray&nbsp;instance</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_x&nbsp;=&nbsp;DualArray(<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;float_array=self.x_calib,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int_array=q_hidden_states,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;quantizer=self.quantizer<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Extract&nbsp;the&nbsp;attention&nbsp;base&nbsp;module&nbsp;name</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mha_weights_name&nbsp;=&nbsp;<span style="color: #d14;line-height: 26px;">f"transformer.h.<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>.attn."</span><br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Extract&nbsp;the&nbsp;query,&nbsp;key&nbsp;and&nbsp;value&nbsp;weight&nbsp;and&nbsp;bias&nbsp;values&nbsp;using&nbsp;the&nbsp;proper&nbsp;indices</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;head_0_indices&nbsp;=&nbsp;[<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list(range(i&nbsp;*&nbsp;self.n_embd,&nbsp;i&nbsp;*&nbsp;self.n_embd&nbsp;+&nbsp;self.head_dim))<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-weight: bold;line-height: 26px;">for</span>&nbsp;i&nbsp;<span style="font-weight: bold;line-height: 26px;">in</span>&nbsp;range(<span style="color: #008080;line-height: 26px;">3</span>)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv_weights&nbsp;=&nbsp;...<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv_bias&nbsp;=&nbsp;...<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Apply&nbsp;the&nbsp;first&nbsp;projection&nbsp;in&nbsp;order&nbsp;to&nbsp;extract&nbsp;Q,&nbsp;K&nbsp;and&nbsp;V&nbsp;as&nbsp;a&nbsp;single&nbsp;array</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv&nbsp;=&nbsp;q_x.linear(<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight=q_qkv_weights,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias=q_qkv_bias,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key=<span style="color: #d14;line-height: 26px;">f"attention_qkv_proj_layer_<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>"</span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Extract&nbsp;the&nbsp;queries,&nbsp;keys&nbsp;and&nbsp;vales</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_qkv&nbsp;=&nbsp;q_qkv.expand_dims(axis=<span style="color: #008080;line-height: 26px;">1</span>,&nbsp;key=<span style="color: #d14;line-height: 26px;">f"unsqueeze_<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>"</span>)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_q,&nbsp;q_k,&nbsp;q_v&nbsp;=&nbsp;q_qkv.enc_split(<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #008080;line-height: 26px;">3</span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis=<span style="color: #008080;line-height: 26px;">-1</span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key=<span style="color: #d14;line-height: 26px;">f"qkv_split_layer_<span style="color: rgb(51, 51, 51);line-height: 26px;">{self.layer}</span>"</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #998;font-style: italic;line-height: 26px;">#&nbsp;Compute&nbsp;attention&nbsp;mechanism</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;q_y&nbsp;=&nbsp;self.attention(q_q,&nbsp;q_k,&nbsp;q_v)<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-weight: bold;line-height: 26px;">return</span>&nbsp;self.finalize(q_y)<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">模型中的其他计算仍以浮点形式进行，未加密，并由客户端在本地执行。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">将预训练的权重加载到修改后的 GPT2 模型中，然后调用 <em style="color: black;">generate</em> 方法:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">qgpt2_model&nbsp;=&nbsp;SingleHeadQGPT2Model.from_pretrained(<br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #d14;line-height: 26px;">"gpt2_model"</span>,&nbsp;n_bits=<span style="color: #008080;line-height: 26px;">4</span>,&nbsp;use_cache=<span style="color: #008080;line-height: 26px;">False</span><br>)<br><br>output_ids&nbsp;=&nbsp;qgpt2_model.generate(input_ids)<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">举个例子，你可以要求量化模型补全短语 「Cryptography is a」 。在 FHE 中运行模型时，如果量化精度足够，生成的输出为:</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">「Cryptography is a very important part of the security of your computer」</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">当量化精度太低时，您会得到:</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">「Cryptography is a great way to learn about the world around you」</p><span id="OSC_h3_6"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">编译为 FHE</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">现在，你可以使用以下 Concrete-ML 代码编译注意力头:</p><pre data-tool="mdnice 编辑器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">circuit_head&nbsp;=&nbsp;qgpt2_model.compile(input_ids)<br></code></pre><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">运行此代码，你将看到以下打印输出: 「Circuit compiled with 8 bit-width」。该配置与 FHE 兼容，显示了在 FHE 中执行的操作所需的最大位宽。</p><span id="OSC_h3_7"></span><h3 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">复杂度</span><span style="display: none;"></span></h3><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 transformer 模型中，计算量最大的操作是注意力机制，它将查询、键和值相乘。在 FHE 中，加密域中乘法的特殊性加剧了成本。此外，随着序列长度的增加，这些乘法的数量还会呈二次方增长。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">而就加密注意力头而言，长度为 6 的序列需要 11622 次 PBS 操作。我们目前的实验还很初步，尚未对性能进行优化。虽然可以在几秒钟内运行，但不可否认它需要相当多的计算能力。幸运的是，我们预期，几年后，硬件会将延迟提高 1000 倍到 10000 倍，使原来在 CPU 上需要几分钟的操作缩短到 ASIC 上的低于 100 毫秒。有关这些估算的更多信息，请参阅，此博文。</p><span id="OSC_h2_8"></span><h2 data-tool="mdnice 编辑器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">总结</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">大语言模型有望使能大量应用场景，但其实现引发了用户隐私的重大关切。在本文中，我们朝着密态 LLM 迈出了第一步，我们的最终愿景是让整个模型完全在云上运行，同时用户的隐私还能得到充分尊重。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">当前的做法包括将 GPT2 等模型中的特定部分转换至 FHE 域。我们的实现利用了 transformers 库，用户还能评估模型的一部分在加密数据上运行时对准确率的影响。除了保护用户隐私之外，这种方法还允许模型所有者对其模型的主要部分保密。你可在，此处，找到完整代码。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Zama 库 Concrete 和 Concrete-ML (别忘了给我们的 github 代码库点个星星 ⭐️💛) 允许直接构建 ML 模型并将其转换至等价的 FHE 域，从而使之能够对加密数据进行计算和预测。</p><p data-tool="mdnice 编辑器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">希望你喜欢这篇文章。请随时分享你的想法/反馈！</p><hr data-tool="mdnice 编辑器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 编辑器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/encrypted-llm</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Roman Bredehoft，Jordan Frery</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">译者: Matrix Yao (姚伟峰)，英特尔深度学习工程师，工作方向为 transformer-family 模型在各模态数据上的应用及大规模模型的训练推理。</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">审校/排版: zhongdongy (阿东)</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - Hugging Face（gh_504339124f0f）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 04 Oct 2023 03:29:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10112832</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10112832</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大模型在无损压缩方面超越 PNG 和 FLAC]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">Google DeepMind 和 Meta 的研究人员发表论文《<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2309.10668" target="_blank">Language Modeling Is Compression</a>》，他们发现 DeepMind 的大语言模型 Chinchilla 70B 在图像和音频的无损压缩上超过了 PNG 和 FLAC。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:start">论文提到，Chinchilla 70B 能将 ImageNet 图像数据库中的图像无损压缩到原始大小 43.4%，超过了 PNG 算法的 58.5%。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:start">Chinchilla 能将 LibriSpeech 音频数据集中的样本无损压缩到原始大小 16.4%，超过 FLAC 算法的 30.3%。</p><p style="color:#000000; text-align:start"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ca6b2c476913b6a89c88077731175c6b63b.png" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farstechnica.com%2Finformation-technology%2F2023%2F09%2Fai-language-models-can-exceed-png-and-flac-in-lossless-compression-says-study%2F" target="_blank">据介绍</a>，Chinchilla 70B 主要是训练用于处理文本，但它在压缩其它类型的数据集上的效果也表现优异，甚至优于专门的算法。</p><p style="color:#000000; text-align:start">下面的例子比较了 gzip 和 Chinchilla 在示例文本上的生成效果。可以看到，gzip 的输出没有可读性。</p><p><img alt="" src="https://static.oschina.net/uploads/space/2023/1005/191209_GfKh_2720166.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 03 Oct 2023 11:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260407/llm-can-exceed-png-and-flac-in-lossless-compression</guid>
            <link>https://www.oschina.net/news/260407/llm-can-exceed-png-and-flac-in-lossless-compression</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[特斯拉：FSD 不使用高清地图，只依赖神经网络和海量数据]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>特斯拉最近解释了其全自动驾驶 (FSD) 软件是如何运作的，以及其作出决策背后的依据。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1003/180701_AefK_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>特斯拉的官方推特账号<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTesla%2Fstatus%2F1707858812424606039" target="_blank">转发</a>了特斯拉硅谷车主俱乐部发布的一段短视频，视频内容展示了 FSD 如何在没有任何导航的情况下在湖边的一条土路上行驶。该俱乐部<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FteslaownersSV%2Fstatus%2F1706123024037269568" target="_blank">写道</a>：「世界还没有意识到正在发生什么。」</p><p><img height="823" src="https://static.oschina.net/uploads/space/2023/1003/180844_X59r_2720166.png" width="725" referrerpolicy="no-referrer"></p><p>特斯拉在转发的推文中说道：</p><blockquote><p>特斯拉 FSD 不依赖高清地图，这意味着 Autopilot 可以在汽车以前从未见过的地方启用。 虽然它会考虑导航以到达正确的目的地，但如果没有路线或地图可用，它会选择最可能的路径。<strong>这条路径是由大多数人在任何给定场景下所做的事情决定的，并由我们全球数百万辆汽车的学习提供动力。</strong>车道的概念也只是松散地嵌入到我们的系统中，使汽车能够自信地在没有标记的道路上行驶。</p></blockquote><p>特斯拉利用其车队的视频来训练 FSD 的能力。马斯克此前曾表示：「道路是为生物神经网络和眼睛设计的，因此数字神经网络和摄像头将发挥最佳作用。」</p><p>今年 7 月初，在 2023 年世界人工智能大会上，马斯克还表示，特斯拉「非常接近」实现全自动驾驶能力。他说：「过去我对这个预测一直是错误的，但我觉得我们比以往任何时候都更接近这个预测。」</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-adf92c911bcb0d3d528ae1aac0dca386027.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 03 Oct 2023 10:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260260</guid>
            <link>https://www.oschina.net/news/260260</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Stability AI 发布最新语言模型：Stable LM 3B]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Stability AI 昨日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fblog%2Fstable-lm-3b-sustainable-high-performance-language-models-smart-devices" target="_blank">发布</a>最新语言模型：Stable LM 3B，可在笔记本和手机等智能设备上运行。</p><p><img src="https://static.oschina.net/uploads/space/2023/1003/123230_hJQt_2720166.png" referrerpolicy="no-referrer"></p><p>公告写道，Stable LM 3B 包含 30 亿个参数，相比于行业通常使用的 70 亿参数，它更小、更高效。主要功能如下：&nbsp;</p><ul><li>文本生成：可以用于生成文本</li><li>自回归：基于变换器解码器架构</li><li>多样性的训练数据：使用了多个开源大规模数据集</li></ul><p>Stable LM 3B 主要特点：</p><ol><li>高性能：尽管只有 30 亿个参数，但性能与更大的模型相当，甚至有时超过它们。</li><li>低功耗：设计为在便携式设备上高效运行，因此电力需求较低。</li><li>多平台兼容：可以在边缘设备、家用电脑以及其他便携式数字设备上运行。</li><li>可微调：模型可以根据特定需求进行微调，如编程辅助或其他专用应用。</li><li>开源：该模型已在 Hugging Face 平台上开源 (<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fstabilityai%2Fstablelm-3b-4e1t" target="_blank">https://huggingface.co/stabilityai/stablelm-3b-4e1t</a>)，方便开发者使用和改进。</li><li>训练细节：该模型在 Stability AI 的集群上进行了训练，使用了 256 个 NVIDIA A100 40GB GPU（AWS P4d 实例）。</li></ol><p>详情：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstability.ai%2Fblog%2Fstable-lm-3b-sustainable-high-performance-language-models-smart-devices" target="_blank">https://stability.ai/blog/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 03 Oct 2023 04:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260235/stable-lm-3b</guid>
            <link>https://www.oschina.net/news/260235/stable-lm-3b</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[适用于 Box 的 ONLYOFFICE 文档集成应用程序现已可用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">适用于 Box 的 ONLYOFFICE 集成应用程序可直接在 Box 前端中处理文件。 请继续阅读了解详情。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="New integration available: ONLYOFFICE &amp; Box" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/09/27103552/ONLYOFFICE-Box-integration.jpg" referrerpolicy="no-referrer"></p><h2>ONLYOFFICE 文档是什么</h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite.aspx" target="_blank">ONLYOFFICE 文档</a>是一个功能强大的在线编辑器，用于文本文档、电子表格、演示文稿、表单和 PDF 阅读器，可以与任何平台集成。跨平台并与微软格式高度兼容，ONLYOFFICE 为初创公司提供了优秀的办公套件。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">在 ONLYOFFICE 文档中，您能够以实时和段落锁定模式安全地协作处理文档。共享权限包括可编辑、可查看、可审阅、可填写表单、可留评论等。其他协作功能包括追踪更改、版本历史记录、文档比较和恢复。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">由于自定义选项和灵活性，ONLYOFFICE 文档几乎可以适应任何屏幕。默认功能可通过第三方插件进行扩展，例如 <a href="https://www.oschina.net/news/259993/onlyoffice-ai">AI 助手</a>、缩放、谷歌翻译、文本识别、语音输入等。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 也可以与其他平台集成，允许您在&nbsp;<span style="background-color:#ffffff; color:#333333">Odoo、Pipedrive、Confluence、Moodle、Nextcloud、Seafile 等平台上使用文档协作编辑功能。</span></p><h2><strong>ONLYOFFICE 应用程序及其功能</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 新的集成应用程序可以让用户在流行的云内容管理平台 Box 中轻松打开和编辑现有文档、电子表格和演示文稿。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">为此，请单击 3 点图标启动文件上下文菜单，找到<strong>集成</strong>，然后选择<strong>用 ONLYOFFICE 打</strong><strong>开</strong>，相应的 ONLYOFFICE 编辑器将以全屏模式在新选项卡中打开。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">如果您与其他 Box 用户有共享文件，还可以协作处理文档。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="New integration available: ONLYOFFICE &amp; Box" src="https://static-blog.onlyoffice.com/wp-content/uploads/2023/09/27103850/Box-onlyoffice-edit-files.png" referrerpolicy="no-referrer"></p><h2><strong>如何安装应用程序</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 应用程序可在<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapp.box.com%2Fapp-center%2Fonlyoffice_personal%2Fapp" target="_blank">Box App Center</a>（应用程序中心）完全免费使用。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faccount.box.com%2Flogin" target="_blank">登录您的 Box 帐户</a>并按「<strong>安装</strong>」按钮即可。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>请注意</strong>：该应用程序使用 ONLYOFFICE 文档云的预配置租户，不需要任何额外配置。</p><h2><strong>支持的文件格式</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">适用于 Box 的 ONLYOFFICE 应用程序支持处理多种文件格式：</p><ul><li>OOXML 文件，包括 DOCX、XLSX、PPTX，可直接打开进行编辑。</li><li>DOCXF 和 OFORM，用于处理数字表单。</li><li>ODT、ODP、ODS、TXT、CSV、RTF、EPUB、FB2 只能打开查看，也可以直接进行编辑，但由于格式限制可能会导致数据丢失，或者转换为 OOXML 进行进一步编辑。</li><li>DOC、XLS、PPT、DOT、ET、FODP、HTM、POT 等可以打开仅供查看，也可以转换为 OOXML 进行编辑。</li><li>PDF、DJVU、OXPS 只能打开查看。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 02 Oct 2023 11:17:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260197</guid>
            <link>https://www.oschina.net/news/260197</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[「开源 Windows」ReactOS 改进 GUI 设置/安装]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日，ReactOS Deutschlande.V.&nbsp;宣布聘请了该项目的长期贡献者，在接下来的五个月内致力于开发 ReactOS GUI 设置模式 (ReactOS GUI setup mode)，该特性将替代之前基于文本的设置方案，以降低使用门槛。</p><p>目前 ReactOS 正在向 Hermès Bélusca-Maïto 支付费用，让他在接下来的五个月内开发 ReactOS GUI 设置模式，以完成安装 ReactOS 过程中第一阶段的目标。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bf70d29b68f97316bc35adb689b7fa33baf.png" referrerpolicy="no-referrer"></p><p>据介绍，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Freactos.org%2Fwiki%2FInstalling_ReactOS" target="_blank">安装 ReactOS 会经历三个阶段</a>。前两个阶段需要处理系统的安装，而第三阶段是用户的第一个可用引导界面。</p><ul><li>第一阶段 – 文本模式设置，从 ReactOS CD-ROM 启动。</li><li>第二阶段 – 引导至 GUI 安装程序。用户信息的输入和文件的注册。</li><li>第三阶段 – 引导至桌面，用户配置。</li></ul><p><strong>目前安装 ReactOS 第一步的唯一选择是通过文本模式安装</strong>，其余的安装将在第二阶段安装后处理。自该项目启动以来，这一直是在虚拟机或裸机上安装 ReactOS 的标准方法，因此需要一些门槛，也劝退了不少用户。</p><p>ReactOS GUI 设置模式的开发路线图如下：</p><ul><li>完成有关 CAB 文件提取的 setupapi.dll 的部分 Winesync；</li><li>将 FreeLdr 引导加载程序安装选择步骤移至 ROS 磁盘 / 分区选择步骤之后，并放在实际安装之前；</li><li>集成注册表设置回调（目前 GUI 设置中不存在）；</li><li>添加对 GUI 设置的 GPT 支持；</li><li>杂项（进一步清理、一些重构等）。</li></ul><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Freactos.org%2Fproject-news%2Fhermes-belusca-hired-full-time%2F" target="_blank">详情</a></p><blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">ReactOS 项目的主要目标就是提供一个与 Windows 环境二进制兼容的操作系统。它能让你的 Windows 应用程序和驱动程序如同在 Windows 上一样运行。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">此外，由于应用了 Windows 操作系统的外观特性，已经熟悉 Windows 用户界面的用户在使用 ReactOS 时将驾轻就熟。ReactOS 的终极目标是使你能够在感觉不到最终用户体验变化的前提下，使用 ReactOS 来替代 Windows。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://static.oschina.net/uploads/space/2019/0306/073550_CIxD_2720166.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 02 Oct 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260162/reactos-gui-setup-project</guid>
            <link>https://www.oschina.net/news/260162/reactos-gui-setup-project</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果中国 App Store 将不允许未备案应用上架]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>苹果更新了「App 信息」中「<strong>在中国大陆的供应情况</strong>」，要求 App 有备案号才能在中国大陆的 App Store 中上架。这意味着大部分外国应用将无法通过 App Store 在中国区提供下载。</p><p><img src="https://static.oschina.net/uploads/space/2023/1002/112310_WnrJ_2720166.jpg" referrerpolicy="no-referrer"></p><p><img src="https://static.oschina.net/uploads/space/2023/1002/112502_k0Xd_2720166.jpg" referrerpolicy="no-referrer"></p><p>苹果称：</p><blockquote><p>中国工业和信息化部（MIIT）要求 App 必须具备有效的互联网信息服务提供者（ICP）备案号。此外，游戏 App 必须取得网络游戏出版物号。图书和报刊杂志 App 必须持有中国国家新闻出版署（NPPA）颁发的《网络出版服务许可证》。包含宗教内容的 App 必须持有中国国家宗教事务局（NRAA）颁发的《互联网宗教信息服务许可证》。新闻 App 必须持有中国国家互联网信息办公室（CAC）颁发的《互联网新闻信息服务许可证》。如果你已经或计划在中国大陆的 App Store 中提供上述类型的 App，则必须提供相关信息和证明文件。如果 App 符合上述情况，请在「App 信息」页面的相应位置填写 ICP 备案信息。为方便 Apple 验证你的网络游戏出版物号，请上传游戏的 ISBN（国际标准书号）核发单或批复文件，以及最新营业执照的副本。此外，你还可以上传相应运营单位的授权协议。为方便 Apple 验证你的出版许可，请上传《网络出版服务许可证》或中国国家新闻出版署颁发的其他相关许可、授权方提供的出版许可授权书、营业执照、ICP 许可证或类似的证明文件。为方便 Apple 验证你的互联网宗教信息服务许可，请上传《互联网宗教信息服务许可证》、授权方提供的许可授权书、营业执照、ICP 许可证或类似的证明文件。为方便 Apple 验证你的互联网新闻信息服务许可，请上传《互联网新闻信息服务许可证》、授权方提供的许可授权书、营业执照、ICP 许可证或类似的证明文件。</p></blockquote><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fcn%2Fhelp%2Fapp-store-connect%2Freference%2Fapp-information%2F" target="_blank">https://developer.apple.com/cn/help/app-store-connect/reference/app-information/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 02 Oct 2023 03:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260160</guid>
            <link>https://www.oschina.net/news/260160</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Snap 商店遭受恶意应用攻击，临时新增人工审核]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000"><span style="background-color:#ffffff">Canonical 的 Snap Store&nbsp;团队发布<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.snapcraft.io%2Ft%2Ftemporary-suspension-of-automatic-snap-registration-following-security-incident%2F37077" target="_blank">公告称</a>，他们于近日收到了一些用户所报告的安全隐患事件。即，几个最近新发布的 Snap 可能存在恶意</span><span style="background-color:#ffffff">，可以</span><span style="background-color:#ffffff">窃取用户的加密资金。</span></span></p><p><span style="color:#000000">目前，Snap Store 已经删除了所报告的 Snap。新的 Snap 注册实施了临时人工审核要求，立即生效。此人工审查旨在阻止恶意行为者注册合法应用程序的名称（或至少听起来合法的名称），并将其用作向用户推送恶意 Snap 的途径。</span></p><p><img height="270" src="https://oscimg.oschina.net/oscnet/up-88656dc09868a0f56e324642884ef0b8f38.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">当用户尝试注册新的&nbsp;Snap 时，系统将提示「请求保留名称」。Snap Store 工作人员手动审核成功后，该名称将被注册。上传和发布现有 Snap 的修订版则不会受到影响。</span></p><blockquote><p style="text-align:start"><span style="color:#000000">对于这可能给我们的 snap 发布者和开发者带来的任何不便，我们深表歉意。然而，我们认为这是目前最谨慎的行动。</span></p><p style="text-align:start"><span style="color:#000000">我们希望彻底调查这一事件，而不会给系统带来任何干扰，更重要的是，我们希望确保我们的用户在 Snap Store 中获得安全且值得信赖的体验。</span></p><p style="text-align:start"><span style="color:#000000">请耐心等待我们进行调查。我们将在未来几天提供更详细的更新。</span></p></blockquote><p><span style="color:#000000">如果你最近从 Snap Store 安装了任何新上架的<span style="background-color:#ffffff">加密账本应用程序</span>，不妨检查一下应用程序是否还在列表中。如果没有，这可能意味着它已因为被怀疑是恶意程序而撤下。&nbsp;</span></p><p><span style="color:#000000">更多详情可查看&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.snapcraft.io%2Ft%2Ftemporary-suspension-of-automatic-snap-registration-following-security-incident%2F37077" target="_blank">Snapcraft 论坛</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260114/snap-store-security-incident</guid>
            <link>https://www.oschina.net/news/260114/snap-store-security-incident</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[美国国家安全局将开设人工智能安全中心]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美国国家安全局 (NSA) 宣布正在创建人工智能安全中心，以「监督美国国家安全系统内人工智能功能的开发和集成」。</span></p><p><span style="color:#000000">新中心将帮助促进与在国家安全中使用人工智能相关的最佳实践、评估方法和风险框架的发展。美国国家安全局将整合所有与人工智能和安全相关的活动，并在人工智能安全中心进行。</span></p><p><span style="color:#000000">美国国家安全局将与商业公司、国家实验室、学术界、国防部和选定的外国合作伙伴就这一计划密切合作。</span></p><p><span style="color:#000000">美国国家安全局局长、陆军上将 Paul Nakasone 表示：</span></p><blockquote><p><span style="color:#000000">「人工智能将对我们国家以及我们的盟友和合作伙伴的外交、技术和经济事务中的国家安全产生越来越重要的影响。今天，美国在这个关键领域处于领先地位，但这种领先不应被视为理所当然。几十年来，我们的对手一直利用盗窃和利用我们的知识产权来促进他们的利益，他们将寻求利用我们在人工智能方面的进步，并破坏我们对其的应用。」</span></p></blockquote><p><span style="color:#000000">这一公告是美国政府一系列人工智能相关举措中的又一项。例如，1 月份，美国国防部更新了 2012 年关于负责任地开发自主武器系统的指南，以反映人工智能的最新进展。2020 年，他们还发布了《负责任的人工智能战略和实施路径》。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260112/nsa-open-ai-security-center</guid>
            <link>https://www.oschina.net/news/260112/nsa-open-ai-security-center</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Yazi —— 极速终端文件管理器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Yazi（中文「鸭子」）是一个用 Rust 编写的终端文件管理器，基于非阻塞异步 I/O。它旨在提供高效、用户友好且可定制的文件管理体验。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span style="background-color:#ffffff; color:#1f2328">注意：Yazi 目前正在积极开发中，可能不稳定。</span></p><h4 style="text-align:start"><strong><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特性</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><strong>完全异步支持</strong>：所有 I/O 操作都是异步的，CPU 任务分布在多个线程上，充分利用可用资源。</li><li><strong>强大的异步任务调度和管理</strong>：提供实时进度更新、任务取消和内部任务优先级分配。</li><li><strong>内置支持多种图像协议</strong>：还与Überzug++集成，覆盖几乎所有终端。</li><li><strong>内置代码高亮和图像编码</strong>：结合预缓存机制，大大加速图像和普通文件的加载。</li><li>与 fd、rg、fzf、zicide 集成</li><li>类似 Vim 的输入组件和选择组件</li><li>多选项卡支持，可滚动预览（适用于视频、PDF、档案、目录、代码等）</li><li>批量重命名、可视模式、文件选择器</li><li>题系统、自定义布局、垃圾桶、CSI u</li><li>...&nbsp;</li></ul><p><img height="353" src="https://static.oschina.net/uploads/space/2023/0918/162924_SnRz_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/yazi</guid>
            <link>https://www.oschina.net/p/yazi</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 一站式开源数据可观测性平台 Datavines]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-datavines" class="anchor" href="https://gitee.com/datavane/datavines#datavines"></a>Datavines</h1><p><a href="https://gitee.com/datavane/datavines/blob/dev/README.md"><img src="https://img.shields.io/badge/document-English-blue.svg" alt="EN doc" referrerpolicy="no-referrer"></a><a href="https://gitee.com/datavane/datavines/blob/dev/README.zh-CN.md"><img src="https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%E4%B8%AD%E6%96%87%E7%89%88-blue.svg" alt="CN doc" referrerpolicy="no-referrer"></a></p><hr><p>Datavines 是一站式开源数据可观测性平台，提供元数据管理、数据概览报告、数据质量管理，数据分布查询、数据趋势洞察等核心能力，致力于帮助用户全面地了解和掌管数据，让您做到心中有数。</p><h2><a id="user-content-架构设计" class="anchor" href="https://gitee.com/datavane/datavines#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1"></a>架构设计</h2><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/architecture.jpg" alt="DataVinesArchitecture" referrerpolicy="no-referrer"></p><h2><a id="user-content-安装" class="anchor" href="https://gitee.com/datavane/datavines#%E5%AE%89%E8%A3%85"></a>安装</h2><p>使用<code>Maven3.6.1</code>以及以上版本</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>mvn clean package <span class="nt">-Prelease</span><span class="nt">-DskipTests</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content-特性" class="anchor" href="https://gitee.com/datavane/datavines#%E7%89%B9%E6%80%A7"></a>特性</h2><h3><a id="user-content-数据目录" class="anchor" href="https://gitee.com/datavane/datavines#%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95"></a>数据目录</h3><ul><li>定时获取<strong>数据源元数据</strong>，构造数据目录</li><li>定时监听<strong>元数据变更</strong>情况</li><li>支持元数据的<strong>标签管理</strong></li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-catalog.jpg" alt="数据目录" referrerpolicy="no-referrer"></p><h3><a id="user-content-数据质量监控" class="anchor" href="https://gitee.com/datavane/datavines#%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E7%9B%91%E6%8E%A7"></a>数据质量监控</h3><ul><li>内置 <strong>27</strong> 个数据质量检查规则，开箱即用</li><li>支持 <strong>4</strong> 种数据质量检查规则类型
<ul><li>单表单列检查类型</li><li>单表自定义<code>SQL</code>检查类型</li><li>跨表准确性检查类型</li><li>两表值比对检查类型</li></ul></li><li>支持配置定时任务进行<strong>定时检查</strong></li><li>支持配置 <code>SLA </code>用于<strong>检查结果告警</strong></li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-quality.jpg" alt="数据质量检查" referrerpolicy="no-referrer"></p><h3><a id="user-content-数据概览" class="anchor" href="https://gitee.com/datavane/datavines#%E6%95%B0%E6%8D%AE%E6%A6%82%E8%A7%88"></a>数据概览</h3><ul><li>支持定时执行数据探测，输出<strong>数据概览报告</strong></li><li>支持<strong>自动识别</strong>列的类型自动匹配合适的数据概况指标</li><li>支持<strong>表行数趋势</strong>监控</li><li>支持列的<strong>数据分布</strong>情况查看</li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-profile.jpg" alt="数据目录" referrerpolicy="no-referrer"></p><h3><a id="user-content-插件化设计" class="anchor" href="https://gitee.com/datavane/datavines#%E6%8F%92%E4%BB%B6%E5%8C%96%E8%AE%BE%E8%AE%A1"></a>插件化设计</h3><p>平台以插件化设计为核心，以下模块都支持用户<code>自定义插件</code>进行扩展</p><ul><li><strong>数据源</strong>：已支持 <code>MySQL</code>、<code>Impala</code>、<code>Starocks</code>、<code>Doris</code>、<code>Presto</code>、<code>Trino</code>、<code>ClickHouse</code>、<code>PostgreSQL</code></li><li><strong>检查规则</strong>：内置空值检查、非空检查、枚举检查等 27 个检查规则</li><li><strong>作业执行引擎</strong>：已支持<code>Spark</code>和<code>Local</code>两种执行引擎。<code>Spark </code>引擎目前仅支持<code>Spark2.4</code>版本，<code>Local</code> 引擎则是基于<code>JDBC</code>开发的本地执行引擎，无需依赖其他执行引擎。</li><li><strong>告警通道</strong>：已支持<strong>邮件</strong></li><li><strong>错误数据存储</strong>：已支持 <code>MySQL</code> 和 <strong>本地文件</strong>（仅支持<code>Local</code>执行引擎）</li><li><strong>注册中心</strong>：已支持 <code>MySQL</code>、<code>PostgreSQL</code> 和 <code>ZooKeeper</code></li></ul><h3><a id="user-content-多种运行模式" class="anchor" href="https://gitee.com/datavane/datavines#%E5%A4%9A%E7%A7%8D%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"></a>多种运行模式</h3><ul><li>提供<strong>Web 页面</strong>配置检查作业、运行作业、查看作业执行日志、查看错误数据和检查结果</li><li>支持<strong>在线生成</strong>作业运行脚本，通过 <code>datavines-submit.sh</code> 来提交作业，可与调度系统配合使用</li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/data-job-script.jpg" alt="作业脚本" referrerpolicy="no-referrer"></p><h3><a id="user-content-容易部署高可用" class="anchor" href="https://gitee.com/datavane/datavines#%E5%AE%B9%E6%98%93%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8"></a>容易部署&amp;高可用</h3><ul><li>平台依赖少，容易部署</li><li>最小仅依赖 <code>MySQL</code> 既可启动项目，完成数据质量作业的检查</li><li>支持水平扩容，自动容错</li><li><strong>无中心化设计</strong>，<code>Server</code> 节点支持水平扩展提高性能</li><li>作业<strong>自动容错</strong>，保证作业不丢失和不重复执行</li></ul><h2><a id="user-content-环境依赖" class="anchor" href="https://gitee.com/datavane/datavines#%E7%8E%AF%E5%A2%83%E4%BE%9D%E8%B5%96"></a>环境依赖</h2><ol><li><code>Java</code> 运行环境:<code>Jdk8</code></li><li><code>Datavines</code> 支持 <code>JDBC</code> 引擎，如果你的数据量较小或者只是想做功能验证，可以使用 <code>JDBC</code> 引擎</li><li>如果您要想要基于 <code>Spark</code> 来运行 <code>Datavines</code> ，那么需要保证你的服务器具有运行 <code>Spark</code> 应用程序的条件</li></ol><h2><a id="user-content-快速入门" class="anchor" href="https://gitee.com/datavane/datavines#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"></a>快速入门</h2><p>请参考官方文档：<a href="https://gitee.com/link?target=https%3A%2F%2Fdatavane.github.io%2Fdatavines-website%2Fzh-CN%2Fdocs%2Fuser-guide%2Fquick-start%2F">快速入门指南</a></p><h2><a id="user-content-开发指南" class="anchor" href="https://gitee.com/datavane/datavines#%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97"></a>开发指南</h2><p>请参考官方文档：<a href="https://gitee.com/link?target=https%3A%2F%2Fdatavane.github.io%2Fdatavines-website%2Fzh-CN%2Fdocs%2Fdevelopment%2Fenvironment-preparation%2F">开发指南</a></p><h2><a id="user-content-贡献指南" class="anchor" href="https://gitee.com/datavane/datavines#%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97"></a>贡献指南</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fpulls"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" referrerpolicy="no-referrer"></a></p><p>你可以提交 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fpulls">pull requests</a> 或者 <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fissues%2Fnew%2Fchoose">GitHub issues</a>.</p><blockquote><p>如果您是发布问题的新手，我们要求您阅读 <a href="https://gitee.com/link?target=http%3A%2F%2Fwww.catb.org%2F~esr%2Ffaqs%2Fsmart-questions.html"><em>How To Ask Questions The Smart Way</em></a> (<strong>本指南不提供此项目的实际支持服务！</strong>) 和<a href="https://gitee.com/link?target=http%3A%2F%2Fwww.chiark.greenend.org.uk%2F~sgtatham%2Fbugs.html">How to Report Bugs Effectively</a> 。好的错误报告可以让我们更好地帮助您！</p></blockquote><p>感谢所有已经为 Datavines 做出贡献的人！</p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fdatavane%2Fdatavines%2Fgraphs%2Fcontributors"><img src="https://contrib.rocks/image?repo=datavane/datavines" alt="contrib graph" referrerpolicy="no-referrer"></a></p><h2><a id="user-content-license" class="anchor" href="https://gitee.com/datavane/datavines#license"></a>License</h2><p><code>Datavines</code> 基于 <a href="https://gitee.com/datavane/datavines/blob/dev/LICENSE">Apache License 2.0</a> 协议。<code>Datavines</code> 依赖了一些第三方组件，它们的开源协议也为 <code>Apache License 2.0</code> 或者兼容 <code>Apache License 2.0</code>， 此外 <code>Datavines</code> 也直接引用或者修改了 <code>Apache DolphinScheduler</code>、<code>SeaTunnel</code> 以及 <code>Dubbo</code> 中的一些代码，均为 <code>Apache License 2.0</code> 协议的，感谢这些项目的贡献。</p><h2><a id="user-content-社交媒体" class="anchor" href="https://gitee.com/datavane/datavines#%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93"></a>社交媒体</h2><ul><li>微信公众号（中文，扫描二维码关注）</li></ul><p><img src="https://gitee.com/datavane/datavines/raw/dev/docs/img/wechat-qrcode.jpg" alt="微信二维码" referrerpolicy="no-referrer"></p>]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/datavane/datavines</guid>
            <link>https://gitee.com/datavane/datavines</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 语言大模型的进化轨迹]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><section style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;"><img class="rich_pages wxw-img" data-ratio="0.6001955034213099" src="https://oscimg.oschina.net/oscnet/c4090c6e-9047-4acf-8026-4ee2c0bd5701.jpg" data-w="1023" referrerpolicy="no-referrer"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"></span></section><section style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;outline: 0px;background-color: rgb(25, 25, 25);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-style="max-width: 100%; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important; color: rgb(163, 163, 163) !important;" class="js_darkmode__0" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;background-color: rgb(255, 255, 255);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section style="margin-right: 8px;margin-left: 8px;outline: 0px;visibility: visible;line-height: 1.75em;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-style="padding: 10px; max-width: 100%; background-color: rgb(239, 239, 239); color: rgb(62, 62, 62); line-height: 25.6px; display: inline-block; width: 670px; border-width: 2px; border-style: dashed; border-color: transparent; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important;" class="js_darkmode__1" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="padding: 10px;outline: 0px;background-color: rgb(239, 239, 239);line-height: 25.6px;display: inline-block;width: 670px;border-width: 2px;border-style: dashed;border-color: transparent;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 的发布是语言大模型（LLM）发展史的转折点，它让人们意识到 LLM 的潜力，并引发了「AI 竞赛」，世界上主要人工智能实验室和初创公司都参与其中。在这之后，基于 LLM 的聊天机器人层出不穷。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 及相关 LLM 模型让我们共同见证了 AI 的历史性变革，很多人好奇，LLM 和它们的运作方式究竟是怎样的？它们是如何被构建的？未来又将走向何方？本文对此进行了深入探讨。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">本文作者 Etienne Bernard 是人工智能和机器学习专家，NuMind 的联合创始人兼 CEO，该企业创建由 LLM 提供支持的自定义 NLP 模型。Etienne 曾在 Wolfram Research 工作八年，主要担任机器学习负责人，并领导了自动学习工具、用户友好的深度学习框架以及各种机器学习应用程序的开发。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></em></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">&nbsp;（以下内容经授权后由 OneFlow 编译，转载请联系 OneFlow 获得授权。来源：https://www.numind.ai/blog/what-are-large-language-models）</span></em></p></section></section></section></section></section></section></section></section></section></section></section></section></section><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><section style="line-height: 1.6em;margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);"><strong><span style="letter-spacing: 2px;font-size: 16px;">作者 |&nbsp;Etienne Bernard</span></strong></span></section><section style="line-height: 1.6em;margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);"><strong><span style="letter-spacing: 2px;font-size: 16px;">OneFlow 编译</span></strong></span></section><section style="line-height: 1.6em;margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);"><strong><span style="letter-spacing: 2px;font-size: 16px;">翻译 | 宛子琳、贾川、杨婷</span></strong></span></section><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><span id="OSC_h2_1"></span><h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">1</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">语言模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">简单来说，<strong>语言模型能够以某种方式生成文本</strong>。它的应用十分广泛，例如，可以用语言模型进行情感分析、标记有害内容、回答问题、概述文档等等。但理论上，语言模型的潜力远超以上常见任务。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">想象你有一个完备的语言模型，可生成任意类型的文本，并且人们还无法辨别这些内容是否由计算机生成，那么我们就可以使其完成很多事，例如生成具有代表性的内容，如电子邮件、新闻稿、书籍和电影剧本等。再进一步来看，<strong>还可以用其生成计算机程序，甚至构建整个软件。只要愿意，我们还可以让它生成科学论文</strong>。如果语言模型真正「完备」，那么它们生成的论文将能够以假乱真，与真实论文没有区别，这意味着必须对语言模型展开实质性研究！</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">当然，就目前而言，完备的语言模型还无法实现，不过也展示出了这些系统的潜力。<strong>语言模型不仅仅能「预测文本」，它们的潜力可能远超想象。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">现在我们回顾一下语言模型的发展历程，从最初的朴素语言模型到目前基于 Transformer 的 LLM（语言大模型）。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">2</span></strong></p><span id="OSC_h2_2"></span><h2 style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">朴素语言模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">语言模型是机器学习模型，因此它们会学习如何生成文本。教授它们的方法（即训练阶段）是<strong>提供一个大规模文本语料库，它们将从中学习如何模仿生成这些文本的过程。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">也许这听起来有些抽象，但创建一个朴素语言模型实际上非常简单。你可以将文本语料库分成一定大小的字符串块，并测量它们的频率。下面是我使用大小为 2 的字符串得到的结果：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5605858854860186" src="https://oscimg.oschina.net/oscnet/ef013e46-5762-483f-b482-421a3f071c50.png" data-type="png" data-w="751" height="auto" width="751" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">图源：《机器学习导论》</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这些字符串块被称为 n-gram（其中 n 表示字符串的大小，因此此处 n=2）。通过这些 n-gram，你可以像玩多米诺骨牌一样生成文本。从一个初始的 n-gram 开始，例如「th」，然后根据测量的频率随机选择一个以初始 n-gram 结尾的 n-gram 。在这个例子中，如果选择「hi」，就会形成「th」 + 「hi」 = 「thi」。然后再继续添加以「i」开头的 n-gram，以此类推，生成整段文本。不过正如你所想，这些 n-gram 模型并不能生成足够连贯的文本。以下是我继续执行这一过程时得到的结果：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">说实话，这一结果并不太理想！但也说得通，因为该模型的记忆能力很有限，只通过前一个字符来预测下一个字符。如果我们使用 n=4 的字符串，结果会稍微好一些：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">「complaine building thing Lakers inter blous of try sure camp Fican chips always and to New Semested and the to have being severy undiscussion to can you better is early shoot on」</span></em><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">现在出现了一些拼写正确的单词，但结果仍不够理想！理论上，进一步增加 n 的值，输出结果会得到改善，但在实践中，<strong>我们无法显著增加 n 值，因为这需要一个庞大的数据集来训练模型</strong>。最后，我们可以尝试将单词而不是字符作为基本单位（在自然语言处理术语中称为「词元（token）」）。这会改善输出结果，但因为 n&lt;6，生成的文本仍然缺乏连贯性。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这些朴素语言模型的记忆能力始终有限，因此无法生成超过一定长度的连贯文本</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">。尽管如此，它们仍具备一定用途。几年前，朴素语言模型被广泛用于文本分类和语音识别，且如今仍被用于语言识别等任务。<strong>然而，对于更高级的文本理解和文本生成任务来说，朴素语言模型就捉襟见肘了。因此需要神经网络。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">3</span></strong></p><span id="OSC_h2_3"></span><h2 style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">基于神经网络的语言模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">现代语言模型基于（人工）神经网络。<strong>神经网络是受人脑启发开发出的计算机，能够通过任务示例学习如何执行任务</strong>。这种机器学习形式也被称为深度学习，因为其中的网络由多个计算层组成（因此被称为「深度」网络）。<strong>在神经网络中，通过遍历任务示例并迭代修改网络参数以优化任务目标，从而实现学习。你可以将这些参数想象成一组旋钮（knob），通过左右旋动以改进目标</strong>，但区别是计算机为你进行改进，并且知道如何同时正确地朝着改进方向进行调整（得益于著名的反向传播算法）。因此，网络会遍历任务示例（通常以几百个示例为一批），并在这一过程中优化目标。以下是一个正在被优化的目标示例（称为成本函数，数值越小越好）：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.607565011820331" src="https://oscimg.oschina.net/oscnet/ebf3e1ab-0914-4c47-ad3b-09f58569f6f6.png" data-type="png" data-w="423" height="auto" width="423" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">成本函数随训练迭代次数的变化。图源：《机器学习导论》</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">随着模型的训练，成本函数值会逐渐下降，意味着模型在任务处理上变得更加优秀。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在该案例中，我们想要生成文本。<strong>目前，标准的方法是训练一个模型，通过前面的单词预测后面的单词</strong>。由于下一个单词有多种可能性，模型会学习为每个可能的单词关联一个概率。以下是对「the cat sat on the」之后可能出现单词的概率分布可视化图像：<br><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5652173913043478" src="https://oscimg.oschina.net/oscnet/c028e4da-8de4-406c-adde-4643579804a5.png" data-type="png" data-w="529" height="auto" width="529" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">改编自《机器学习导论》</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">一旦拥有这样的预测模型，就可以从预测概率中抽样来生成下一个单词，然后将该单词重新输入到网络，再抽样一个新的单词，以此类推，从而生成文本</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">。这一生成过程被称为自回归，因为网络利用自己的预测结果来生成新的预测。虽然有人对此提出了异议，认为这并非最佳方法，但目前而言，这就是最实际的操作方式，且效果也出奇地好！</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">曾经用于建模语言的第一类神经网络是 RNN（循环神经网络），尤其是 LSTM（长短期记忆网络）架构。<strong>RNN 就像一个逐个阅读单词的小型机器，在这一过程中，它会更新思维状态（mental state）</strong>。这种思维状态如同记忆，使它们在生成文本时能大概记住一段时间的信息。<strong>相比 n-gram 模型，RNN 模型能够获得更为优越的性能。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">RNN 创建之初，神经对话模型（Neural Conversational Model）给我留下了深刻印象。该模型是 Google 于 2015 年基于电影字幕训练的一个特殊 LSTM 模型，当时这个模型已经算得上是 LLM 了（也可能是首个 LLM）：拥有 3 亿参数，并在约 10 亿词的数据上进行训练。由于电影字幕是对话形式，因此可直接将该模型用作聊天机器人。以下是不同人类输入对应的回答示例：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人类：你叫什么名字？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">机器：我叫朱莉娅。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人类：你是什么时候出生的？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">机器：7 月 20 日。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人类：我的名字是大衞。我的名字是什么？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">机器：大衞。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人类：天行者是谁？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">机器：他是一个英雄。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人类：天空是什么颜色？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">机器：蓝色。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">人类：血液是什么颜色？</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">机器：和黑眼圈的颜色相同。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">如你所见，该模型能够闲聊，同时也对世界有一定了解，这些知识完全是通过学习如何预测文本获得的！我记得自己曾对这一事实很感兴趣：<strong>学习预测文本迫使你理解世界</strong>（但并不意味着这个过程很容易）。然而，该模型也有一些明显的短板：它经常出错，并且与类似基于 LSTM 的模型一样，无法生成长篇连贯的文本。理论上，循环神经网络可以长时间记忆事物，<strong>但在实践中，它们却往往很快就忘记了：经过几十到一百个词之后，它们就会开始偏离主题，不再连贯。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">2017 年，人们针对短期记忆问题提出一种解决方案——Transformer</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">。Transformer 是一种基于注意力机制的新型神经网络架构（本质上是一种选择操作），下图来自介绍 Transformer 的论文，用以说明其在翻译任务中的工作原理：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="1.4446640316205535" src="https://oscimg.oschina.net/oscnet/535ec695-4411-41cb-90ef-59154234fded.png" data-type="png" data-w="1012" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">Transformer 架构。来源：https://arxiv.org/abs/1706.03762</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">Transformer 在各个方面都可圈可点，但最值得一提的是，<strong>该架构在文本建模方面表现非常出色，并且很适合在 GPU 上运行，从而处理（和学习）大量数据。正是有了 Transformer 这种架构，才使得现代 LLM 得以兴起（或至少起到了很强的促进作用）。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="color:#3f3f3f;"><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">4</span></span></strong></p><span id="OSC_h2_4"></span><h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;color: rgb(30, 35, 128);font-size: 17px;">现代语言大模型</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">Transformer 的发明标志着现代 LLM 时代的开始。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">自 2018 年以来，AI 实验室开始训练规模越来越大的模型。令众人惊讶的是，这些模型的质量也在不断提高！下图对这些模型进行了可视化，我们将重点介绍其中值得关注的模型：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><img class="rich_pages wxw-img" data-ratio="0.7972222222222223" src="https://oscimg.oschina.net/oscnet/d63f0ce4-11ec-418a-b09c-9a910e495283.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">LLM 进化树。来源：https://github.com/Mooler0410/LLMsPracticalGuide</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这些语言模型主要分为三类。一是「仅编码器（encoder-only）」组（上图中的粉色部分），该类语言模型擅长文本理解，因为它们允许信息在文本的两个方向上流动。二是「仅解码器（decoder-only）」组（上图中的蓝色部分），该类语言模型擅长文本生成，因为信息只能从文本的左侧向右侧流动，以自回归方式有效生成新词汇。三是「编码器-解码器（encoder-decoder）」组（上图中的绿色部分），该类语言模型对上述两种模型进行了结合，用于完成需要理解输入并生成输出的任务，例如翻译。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这一切都主要始于文本理解类模型。最初是使用 RNN 的 ELMo，之后是谷歌著名的 BERT 模型及其派生模型（如 RoBERTa），它们都基于 Transformer。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这些模型通常具有几亿个参数（相当于约 1GB 的计算机内存），在大约 10GB 到 100GB 的文本上进行训练（通常为几十亿个单词），并且可以在现代笔记本电脑上以约 0.1 秒的速度处理一段文本。<strong>这些模型极大地提升了文本理解任务的性能，如文本分类、实体检测和问题回答等。</strong>这已然是 NLP（自然语言处理）领域的一场革命，不过才刚刚拉开序幕……</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在文本理解类语言模型发展的同时，<strong>OpenAI 开始基于 Transformer 创建文本生成类语言模型</strong>。首先是 2018 年的 GPT-1，有 1 亿个参数；<strong>然后是 2019 年的 GPT-2，拥有高达 15 亿个参数，并在 40GB 的文本上进行了训练</strong><strong>。至少对我来说，GPT-2 的创建是一个至关重要的时刻。</strong>以下是 GPT-2 可以生成的文本示例，从一个由人类撰写的段落开始：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5203703703703704" src="https://oscimg.oschina.net/oscnet/6cc3b7d0-9aa6-4f4f-a9b6-95e215a32d2d.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">来源：https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">生成的英语文本质量很不错，而且具有连贯性。例如，科学家的名字没有改变，而这在基于 RNN 的模型中是个经典问题。<strong>由于 GPT-2 在所生成文本的质量上取得了巨大突破，</strong><strong>为避免滥用，OpenAI 最初决定不向公众发布。</strong>可以说 GPT-2 标志着 LLM 正朝着正确的方向发展。<strong>需要注意的是：使用这类语言模型需要先提供一个起始文本，这个起始文本被称为提示（prompt）。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">一年后（2020 年），OpenAI 创建了 GPT-3。<strong>GPT-3 是一个具有 1750 亿个参数的模型</strong>（需要 700GB 的计算机内存来存储模型！），<strong>该模型不仅规模显著扩大，文本生成质量也有重大改进。除了性能的提升外，GPT-3 还让人们对未来如何使用 LLM 大开眼界。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">首先，<strong>GPT-3 能够编写代码</strong>。例如，你可以使用 GPT-3 来生成（非常）简单的网站，只需在提示中描述网站的外观即可。以下是一个示例，让 GPT-3 使用 HTML 创建一个按钮：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.3148148148148148" src="https://oscimg.oschina.net/oscnet/891ad7cc-c694-4283-ba93-4a711bc8b6b3.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这些基本的编码能力在当时并不十分实用，<strong>但它们的出现意味着软件开发在未来可能会发生根本性转变。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">GPT-3 另一令人瞩目的能力是能够进行上下文学习，它可以通过提示中所展示的示例来学习如何执行任务。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这意味着你可以通过编写提示来定制 LLM，而无需更改它们的权重。这一能力开辟了一种全新的、完全基于提示的自然语言处理方式，如今十分受欢迎。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">总而言之，GPT-3 展示了「提示」作为一种新方式的潜力，可以让机器通过自然语言按照我们的意愿执行任务。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">注意：GPT-3 比 GPT-2 要大得多。<strong>自 2018 年以来，模型的规模急剧增加。</strong>以下是一些值得关注的 LLM 及其规模：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.84" src="https://oscimg.oschina.net/oscnet/7399dbde-b740-42d5-97e7-367afd2035ec.png" data-type="png" data-w="600" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在两年时间里，模型参数的数量增加了 1000 倍，目前最大的模型（如 GPT-4）已接近 1 万亿个参数，</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这是因为模型规模的增加与性能的改善密切相关，并且目前还未达到性能瓶颈。这些模型规模十分庞大，与人脑相比，人脑约有 1000 亿个神经元，每个神经元平均与其他 1000 个神经元相连接，总共约有 100 万亿个连接。从某种意义上说，最大的 LLM 仍然比人脑小 100 倍。当然，这只是一个非常宽泛的比较，因为人脑和当前 LLM 使用的架构和学习方法都截然不同。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">另一个有趣的指标是这些模型在训练阶段所「阅读（read）」的单词数量。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.7116666666666667" src="https://oscimg.oschina.net/oscnet/fce3c3d5-5632-40a4-92df-0de3b10de8d2.png" data-type="png" data-w="600" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">如你所见，数量十分庞大。<strong>这些模型在训练过程中会接触超 1000 亿个单词，是一个人在一生中听到或阅读单词数量的 100 倍以上！</strong>这显示出神经网络与人脑的不同之处：<strong>神经网络的学习速度比人类慢得多，但可以获得比人类接触的多得多的数据。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">需要注意的是，LLM 在训练过程中所接触到的单词数量并未像参数数量那样迅速增长（从 GPT-1 到 GPT-3 只增长了 3 倍）。这是因为优先考虑模型规模，不过结果证明这是一个小小的失误。最新的模型并没有比 GPT-3 大很多，但通过处理更多单词来进行训练。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">这种对数据的渴求导致了一个问题，即可用文本的总量存在硬性限制，约为数万亿个单词，而模型正在接近这一限制。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">虽然仍有可能循环遍历所有文本，但这会导致模型性能的回报递减。总而言之，可得出结论：网络在训练阶段处理的有效限制是几十万亿个单词，比 GPT-4 的数量约多出 10 倍。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">另一个问题是，通过用更多的数据训练更大的模型，计算成本也在增加。以下是训练上述模型的预估计算成本：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.7116666666666667" src="https://oscimg.oschina.net/oscnet/d828b020-6cac-4651-b22c-97d85f9b7678.png" data-type="png" data-w="600" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">为显著超越当前模型的性能，下一代模型需要耗费数亿美元的计算资源。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">虽然考虑到这些模型能带来的好处，这一成本是合理的，但如此巨大的花费仍然是一个问题。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">模型的扩展变得越来越困难。幸运的是，扩大规模并不是改进 LLM 的唯一途径。2022 年末，一项创新开启了另一场革命，这次的影响远远超出了 NLP 领域。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">5</span></strong></p><span id="OSC_h2_5"></span><h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;color: rgb(30, 35, 128);font-size: 17px;">指令调优和聊天机器人 LLM</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">GPT-3 揭示了提示的潜力，但撰写提示并不容易。事实上，传统语言模型经训练可以模仿其在网络上看到的内容。因此，要想创建一个好的提示，你必须清楚网络上哪种起始文本可能会引导模型生成你所期望的结果。这是一种奇怪的游戏，也是一种找到正确表述的艺术，<strong>你需要改变措辞，假装自己是专家，展示如何逐步思考的示例等等。这一过程叫做提示工程，这使得使用这些 LLM 变得困难。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">为解决这个问题，研究人员一直在探索如何修改基础 LLM，以让其更好地遵循人类指令。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">现主要有两种方法：一是使用人类编写的指令-回答对（instruction-answer pairs），并在此数据集上对基础 LLM 进行微调（即继续训练）。二是让 LLM 生成几个可能的答案，然后由人类对答案评分，并使用强化学习在此数据集上对 LLM 微调。这就是著名的 RLHF（人类反馈的强化学习）的过程。此外，我们还可以将两种方法相结合，OpenAI 在 InstructGPT 和 ChatGPT 中就对这两者进行了结合。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5685185185185185" src="https://oscimg.oschina.net/oscnet/2fbcb686-6afb-4f7f-9b9c-684b8b26350c.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">InstructGPT 和 ChatGPT 的指令调整步骤。来源：https://openai.com/blog/chatgpt（修改自 https://arxiv.org/abs/2203.02155）</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">将这两种技术结合在一起可以得到一个经过指令调整的 LLM。调整后的 LLM 比基础模型更擅长遵循人类指令，使用起来更加容易。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">经过指令调整的 LLM 已经非常出色了，但还有最后一步才能将这些 LLM 真正转化为每个人都可以使用的东西——聊天机器人。<strong>OpenAI 在 2022 年 12 月发布了 ChatGPT，一个基于 GPT-3.5 的聊天机器人。</strong>它的创建方式与 InstructGPT 相同，但这次使用的是整个对话而不仅仅是指令-回答对。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 发布后，基于 LLM 的新型聊天机器人开始层出不穷。OpenAI 使用 GPT-4 来代替 GPT-3.5，对 ChatGPT 进行了改进，Anthropic 发布了 Claude，Google 推出 Bard，Meta 也研发出了 LLaMA，还有几个开源 LLM 正在发布过程中。<strong>这是一次真正的模型大爆炸，将会带来许多令人兴奋的应用，NuMind 也会为此出一份力。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">ChatGPT 发布两个月后，迅速拥有了上亿用户，成为有史以来用户增长最快的产品。人们用 ChatGPT 来根据要点编写电子邮件、重新组织文本、总结文本、编写代码，或学习东西（在此之前，搜索引擎一直垄断着这项任务）。<strong>ChatGPT 的发布是 LLM 发展史的转折点，它让人们意识到了 LLM 的潜力，引发了「AI 竞赛」，世界上主要人工智能实验室和初创公司都参与其中。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">值得注意的是，LLM 的突然普及也引发了人们的担忧。人们担心 LLM 被有心人利用，做一些有害的事情，所以创建开放式 LLM 聊天机器人必须确保它们的「安全」性（或「与人类价值观保持一致」），也就是说它们不能帮助制造炸弹等。目前有一些方法可以绕过聊天机器人的安全防御措施，但随着时间推移，这些安全措施会逐渐完善，想绕过它们将变得十分困难。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">6</span></strong></p><span id="OSC_h2_6"></span><h2 style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><strong><span style="letter-spacing: 2px;color: rgb(30, 35, 128);font-size: 17px;">语言大模型的未来</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p></h2><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">近年来，LLM 取得了很大进步，人们对它的热情达到了空前高度，在这一领域投入了大量精力。那么，LLM 的未来将如何发展？虽然预测未来很难，但我们也有一些看法：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">模型大小和训练规模将继续扩大。扩展在过去取得了非常好的效果，且仍有提升空间</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">，但问题是，模型的训练成本急剧增长，逐渐让人望而却步（&gt;1 亿美元）。更好的 GPU 和新的专用硬件有助于扩展模型规模，但它们的开发和生产需要时间。此外，最大的模型已经迭代了所有书籍和整个网络，这意味着我们正在达到可用训练数据的极限（即「词元危机」）。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">因此，可以肯定的是，在未来几年内，参数数量不会像过去那样出现爆发式增长。<strong>最大的模型今年应该会稳定在 1 万亿参数以下规模，然后以每年 50% 的速度增长。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">LLM 将超越纯语言模型，<strong>将图像和视频纳入训练数据</strong>，成为多模态模型。从图像和视频中学习可能有助于模型更好地理解世界。GPT-4 就是在图像和文本上进行训练的，且取得了少许性能提升。<strong>利用视频数据训练 LLM 可能给这一领域带来质的改变，但这需要大量计算。预计还需两年多的时间才能真正实现利用视频训练「语言」大模型。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">扩大规模、实现语言模型向多模态模型的转变需要大量算力。为缓解这一问题，我们可以采用更好的神经架构和训练程序，这些架构和训练程序要么计算强度较低，要么可以用更少的数据进行学习（人类大脑证明这是可能的）。然而更可能的是类似于 RNN 的内存会卷土重来，因为这种内存运行时的效率非常高（例如最近的 RWKV 架构）。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><strong>此外，还可能有一些更大的变化，例如 LLM 不以自回归的方式生成，而是以自上而下的方式生成</strong>（例如在生成单词之前做出（随机）决定），这种做法可能更合乎逻辑（这就是神经网络目前生成图像的方式）。到底何时会开发出这样的新架构/方法还很难说，但我们预计应该就在未来几年，一旦开发出来，LLM 模型的性能将得到大幅提升。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">另一个改进方向是继续进行指令调优，让更多人参与到「教育」LLM（即与 AI 对齐）的过程中。这可以由私人 AI 实验室来实现，也可以是一个更像维基百科的众包项目，以改进和对齐开放模型的 LLM 能力。在这个问题上，我们还是希望偏离传统的 RLHF，而是让人们与模型对话来进行教导，就像我们对待孩子一样。我不确定这种项目的具体时间线，但我已经思考了一段时间，非常希望看到它的实现。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><br></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">上文我们只讨论了改进实际模型的方法，但实际上有一些方法可以在不改变模型的情况下改进 LLM。<strong>方法之一就是为 LLM 提供工具</strong>。这种工具可以是用于查找准确信息的搜索引擎，或者是用于进行基本数学计算的计算器。此外，它还可以是一个结合了推理引擎（符号人工智能的经典组件）的知识库，如 Wolfram Alpha，用于查找事实、进行逻辑推理或其他神经网络不擅长的计算。当然，这个工具还可以是一个用于编写和运行代码的完整编程环境。LLM 可以通过生成触发 API 调用的特殊词元（单词）来使用这些工具，然后将 API 的输出插入到生成的文本中。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.6586270871985158" src="https://oscimg.oschina.net/oscnet/49d3e79a-4b8d-42f1-b679-51c70d2b0c32.png" data-type="png" data-w="1078" height="auto" width="auto" referrerpolicy="no-referrer"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">LLM 使用工具示例。来源：https://arxiv.org/abs/2302.04761</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">上述趋势实际上已经开始了（例如，ChatGPT 插件、LangChain 库和 Toolformer 论文），我相信这些工具将成为 LLM 的核心。</span></strong></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">改进 LLM 的另一个方法是以更智能的方式使用它们，让它们更好地完成任务。这可以通过巧妙的提示或更高级的程序来实现。<strong>比如说我们可以让 LLM 按步骤进行思考（即思想链提示（ chain-of-thoughts prompting）），并提高 LLM 在逻辑任务上的表现。</strong>以下是提示 LLM 按步骤思考的示例：</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.4842592592592593" src="https://oscimg.oschina.net/oscnet/ae908068-436d-4861-9e91-105957832a7b.png" data-type="png" data-w="1080" height="auto" width="auto" referrerpolicy="no-referrer"></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;text-align: center;"><span style="letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);">思维链提示示例。来源：https://arxiv.org/abs/2201.11903</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">同样地，我们可以要求 LLM 反思、批判自己的输出，并对其进行迭代修改。</span></strong><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">通过迭代，我们可以显著提高 LLM 性能，尤其是生成代码方面的性能。<strong>我们还可以更进一步，创建完全自主的智能体，这些智能体可以管理任务列表并迭代任务，直到达到主要目标（请参考 AutoGPT 和 BabyAGI）。</strong><strong>目前，这些自动化智能体的运行效果并不理想，但它们的效果会逐步提升，很难说这些自动化智能体会发展到何种程度，对 LLM 产生何种影响。</strong></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">由于 LLM 可以通过这些程序（思想链、迭代批评等）改进答案，因此，我们可以使用这些程序创建指令-答案对，然后在指令-答案对上按顺序对 LLM 微调以提高其性能。这种自我完善是可能的（参见</span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(136, 136, 136);"><em>https://arxiv.org/abs/2210.11610</em></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">），我相信它具有很大的潜力。<strong>例如，我们可以想象模型为了变得更加自洽而与自身进行讨论，这是一种自我反思过程。</strong>可能会进一步提升 LLM 的表现。</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">LLM 可能还有其他改进方向，总的来说，我们无法确定 LLM 的未来，但显然它们将继续发展下去。<strong>理解和生成文本的能力使 LLM 成为了一项基本技术。即使在目前的发展情况下，LLM 也将解锁大量应用程序，日常工作中的数字助理就是一个很好的例子，更疯狂的是，LLM 甚至可能引导我们创造某种超级智能。</strong></span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;line-height: 1.6em;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><section style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;white-space: normal;outline: 0px;caret-color: rgba(0, 0, 0, 0.9);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-size-adjust: auto;line-height: 1.75em;text-align: left;"><span style="background-color: rgb(255, 255, 255);color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 1px;">其他人都在看</span><br></section><span id="OSC_h3_7"></span><h3 style="letter-spacing: 0.578px;white-space: normal;"><ul class="list-paddingleft-1" style="width: 577.422px;"><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491796%26idx%3D1%26sn%3D41f16bd562cebfeb5fbb06a8b8758ebb%26chksm%3Dfe426ee2c935e7f449d0cc74c9a1faeb23489ee06d6f02554c103459b01fb3ae8b1e1baa7e93%26scene%3D21%23wechat_redirect" textvalue="关于语言大模型的八大论断" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">关于语言大模型的八大论断</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491796%26idx%3D1%26sn%3D41f16bd562cebfeb5fbb06a8b8758ebb%26chksm%3Dfe426ee2c935e7f449d0cc74c9a1faeb23489ee06d6f02554c103459b01fb3ae8b1e1baa7e93%26scene%3D21%23wechat_redirect" textvalue="关于语言大模型的八大论断" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491801%26idx%3D1%26sn%3D9cc37240451fa684825ad82a3133e12a%26chksm%3Dfe426eefc935e7f9c31a21752e898004461180b0176f38ee7b390110610e99fff1d664450729%26scene%3D21%23wechat_redirect" textvalue="NCCL 源码解析④：建图过程" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">NCCL 源码解析④：建图过程</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491741%26idx%3D1%26sn%3D125132a0c895fbaf0606f0097cf95998%26chksm%3Dfe426eabc935e7bd81c3403dcc85eed4404f32f713862217c526596d86d728e1d94346cbbe43%26scene%3D21%23wechat_redirect" textvalue="揭示 GPT Tokenizer 的工作原理" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">揭示 GPT Tokenizer 的工作原理</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491741%26idx%3D1%26sn%3D125132a0c895fbaf0606f0097cf95998%26chksm%3Dfe426eabc935e7bd81c3403dcc85eed4404f32f713862217c526596d86d728e1d94346cbbe43%26scene%3D21%23wechat_redirect" textvalue="揭示 GPT Tokenizer 的工作原理" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491783%26idx%3D1%26sn%3Db3ebb8a7d4441aaceb62db59992db61b%26chksm%3Dfe426ef1c935e7e7a1ddfba5412a98ee8c091c4304724e73b202a0e127b533f8d039a3ed9703%26scene%3D21%23wechat_redirect" textvalue="语言大模型 100K 上下文窗口的秘诀" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">语言大模型 100K 上下文窗口的秘诀</a><br></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491721%26idx%3D1%26sn%3D71fd215ca3625f276913db5f62d6791e%26chksm%3Dfe426ebfc935e7a96d0437566485a5774b6e3063ba4c768093eaffc25f054730e0f7f836be3f%26scene%3D21%23wechat_redirect" textvalue="GPT 总设计师：大型语言模型的未来" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">GPT 总设计师：大型语言模型的未来</a></p></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><section style="outline: 0px;line-height: 1.75em;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" textvalue="一块 GPU 训练 TB 级推荐模型不是梦，OneEmbedding 性能一骑绝尘" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="outline: 0px;cursor: pointer;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">OneEmbedding:单卡</a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247488841%26idx%3D1%26sn%3D6c5de6713dbce2bd25d60db742879368%26chksm%3Dfe419b7fc93612690a667bec72a258ac837c2454cd180c2432c1c190bc236743cf7e4dd0dfee%26scene%3D21%23wechat_redirect" textvalue="一块 GPU 训练 TB 级推荐模型不是梦，OneEmbedding 性能一骑绝尘" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="outline: 0px;cursor: pointer;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">训练 TB 级推荐模型不是梦</a></section></li><li style="outline: 0px;font-size: 14px;letter-spacing: 1px;"><section style="outline: 0px;line-height: 1.75em;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247490555%26idx%3D1%26sn%3D280c4ac043a31170236a9d8fba5fc2d2%26chksm%3Dfe4195cdc9361cdb6db1cb3b77c66b45c353b2fb65c4d082fbae9b72fe0b3a441ab9101cb147%26scene%3D21%23wechat_redirect" textvalue="GLM 国产大模型训练加速：性能最高提升 3 倍，显存节省 1/3，低成本上手" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">GLM 训练加速：性能最高提升 3 倍，显存节省 1/3</a></section></li></ul><section style="outline: 0px;line-height: 1.75em;text-align: left;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;outline: 0px;background-color: rgb(255, 255, 255);letter-spacing: 1px;font-size: 14px;color: rgb(63, 63, 63);">试用 OneFlow: github.com/Oneflow-Inc/oneflow/</span></section></h3><h2 style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;white-space: normal;"><hr style="border-style: solid;border-right-width: 0px;border-bottom-width: 0px;border-left-width: 0px;border-color: rgba(0, 0, 0, 0.1);transform-origin: 0px 0px;transform: scale(1, 0.5);"></h2><p style="margin-bottom: 0px;letter-spacing: 0.578px;white-space: normal;text-align: center;"><img class="rich_pages wxw-img" data-backh="162" data-backw="578" data-galleryid="" data-ratio="0.2802690582959641" data-s="300,640" src="https://oscimg.oschina.net/oscnet/de5775ed-8e8f-4ce5-8a22-887be523b2a7.png" data-type="png" data-w="892" style="width: 100%;display: inline;height: auto;" referrerpolicy="no-referrer"></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - OneFlow（OneFlowTechnology）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 04:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10086766</guid>
            <link>https://my.oschina.net/oneflow/blog/10086766</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国庆中秋特别漫画：小哪吒猫助力大平台工程]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-d91588328d298da006ea97d4e2408fbd16c.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">现代 IT 和 DevOps 面临着业务增长、微服务数量激增、开发者工具分散、复杂流程和多云部署等诸多挑战，导致业务满意度下降和开发者体验受损。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-ddd1050d3f1669e0d201ad4b2a33c5d6070.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">而「平台工程」是一种软件工程方法，旨在简化交付流程、提高开发者生产力，更是被 Gartner 列为 2023 年十大战略技术趋势。ZadigX 新版本发布在即，它整合了企业现有资源和工具链，避免了从零开始的平台工程建设。ZadigX 通过强大的自定义流程引擎，升级企业低效的碎片化协作流程，轻松应对复杂的场景挑战，并利用 Kubernetes 云原生技术底座管理各种复杂异构环境。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-72413f6e0050d0bcce96663b06308814696.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify">ZadigX 国庆特别版带来了一系列强大的能力矩阵，包括深度集成企业现有工具和系统，企业无需从头开始构建平台，使业务治理更加轻松高效，开发者体验更为顺滑。这一版本还加强了 DevOps/Xops 工作流编排和质量工程解决方案，通过高度可扩展且低配置负担的自定义流程引擎，解决企业复杂流程和碎片化的挑战。同时，ZadigX 与众多合作伙伴紧密合作，推动平台工程的升级，为开发者提供了更多链接一切的机会。Enjoy～</p><span id="OSC_h3_1"></span><h3><strong>01、深度集成企业现有能力和工具链，只为开发者体验更丝滑</strong></h3><p><img src="https://oscimg.oschina.net/oscnet/up-b6f9875b650dc4ebfa1eb60c310e122e3e5.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#ff2968">自动化项目协同：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>发布计划统筹项目迭代规划，从需求到发布一站式完成。支持 Jira 项目、飞书 Meego 项目管理编排，实现自动化任务状态同步。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-54e1c98c02ac79da6d85f9efbaae785dd03.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-063c0ebf4dbe2972d06d743e2488d802e13.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-159cfb76a5b41b1e14912e183800b461347.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#ff2968">配置变更与数据变更协同：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>支持 Nacos、Apollo 等配置变更、 DMS/Flyway/MySQL 等数据变更编排，实现配置变更和数据变更的自动化晋级。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-db9a95b28c2e5ebaaaaee0aecaf55f084eb.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c635493645f6f3a64018816f86800201fd2.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a51568b8fb835c9ec3088ec54a2c41a7e84.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-43f879afbcedf20a7cac5d3963780c54fe1.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-58c7a50c777142c9e14daaa9e8ad5974687.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:#ff2968">开放扩展外部系统协同：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>支持全流程 OpenAPI 开放，自定义任务扩展，可接入任何外部系统。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bbd7129f4b81adfb60d163d08e72714dd40.png" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-dceca93bf7594c74c78bcbc7f9a72a7ecc9.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_2"></span><h3><strong>02、企业无需从零搭建，业务治理更轻松高效</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-3adab7831272ed9b40f791d2325ecaf118f.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">零运维负担接入：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">实施平台工程的难度大幅降低，可通过一键接入托管项目实现同时治理和推广。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e45016a56eb684b33c51f440492bc897c17.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-50919c16f1b290e77b4922045a5f5b13d11.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">企业无需修改现有流程：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">能够支持大规模、快速安全的批量项目接入，数千项服务迁移仅需 2 周。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-676ecce9bcbb61f1caed817d6b3dfa81aba.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3c0440b6bcaed7a50a2add4ef29f496a0c6.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">个性化配置管理：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>支持企业自定义 logo、主题、权限与用户组配置，提高业务管理效率。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-12bbc58cff1be661a11340fada277e8befb.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a1b75d264c539f975ab0531e0163475e7ff.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-1543dda576a5860182acbbc38759639a757.png" referrerpolicy="no-referrer"></p><span id="OSC_h3_3"></span><h3><strong>03、DevOps/Xops 工作流编排 ，质量工程解决方案</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-ab2e5ff67abc4443a039194940f67e015b5.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">支持全流程 DevOps 集成和交付：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">实现需求到发布的全流程协同，无缝整合开发、测试、预发布验证和生产发布流程。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6ea843be2aea86430a5b4a1ae9ed2ace72c.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f82f932ae93e50fc36088aa420a5aa7ede5.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-70e3c889b78a2e74364cd7d2d4ebad95eff.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">支持多类型资源平面和变更观测：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>集群管理支持指定访问权限和工作流任务执行，支持 Severless 集群 /GPU 调度/灵活调度策略确保资源合理安全分配；扩展支持 Kubernetes 资源对象 CronJob、CRD、CloneSet 等变更管理。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5968e2b07cca00089b6f6d68d27216bf1bf.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a1378c60b4045a36d2945b57845825fbd58.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">生产服务和生产环境管理：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><span>&nbsp;</span>隔离生产服务和生产环境资源管理和变更通道，同时支持自动化更新全局变量、环境配置、自助上下线服务、Helm Chart 生产部署等。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-a6d2054efd73946af6e81527d7f90377fc2.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bfaf96b6c418a91b0e6a0ac914a4d4fe5e9.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-e7613a48fda6753cdd34021ccec28df29c2.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">质量内建与安全防护：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">强调代码质量扫描、回归测试、质量门等质量工程建设，提高质量水平。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f3a80ad0fdd0182bafb4b7b7a5d51898e8f.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">个性化管理运营：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">提供内置数学模型，可定制的 DevOps 数据看板，助力企业有效实施研发管理理念。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6582e0c266d75c5c9404b39cf69c0248363.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-0ec43f3dd3b15b560a8d79a8990eb0cbe89.png" referrerpolicy="no-referrer"></span></p><span id="OSC_h3_4"></span><h3><strong>04、高扩展、低配置负担的自定义流程引擎，应对企业复杂流程挑战</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-8301a82372e5e33ba654fa882ef48959037.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">超低配置负担：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">支持 YAML/GUI 两种模式配置，内置 DevOps 最佳实践模板推动架构的标准化和治理。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ea42a5b8fcddf7b75e636b47c8589dcf6f4.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-0de22a4098f55bdd4a4079bcb4731e6c77f.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-cbd296208334ce881a5930355ea8d864543.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">无限并发与扩展性：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">利用强大的云原生底层能力，支持工作流参数传递、共享存储、任务并发配置。支持服务级别测试任务编排和蓝绿发布策略。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5a9882684eb859bdc97830cb6e9915148d5.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-85718bec21612698223f79bdd49b7ec7617.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5b85fb26407a6018d9ecf7a48df91ce76e9.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-ba6b1663852b874171c131c497984de61d9.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">自定义管控配置：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">强化任务步骤执行，支持集中管理、飞书、钉钉，OA 接入等审批流程。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6f0b2de0ee135fc440f95061c98b954926d.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3599d09f48e80895f1a45c89bdb5754977d.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-5d8fdb33fd92b58e83db1201fe1be35bc61.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">用户友好与灵活性：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">镜像分发任务支持配置目标镜像生成规则，任务列表可自定义展示字段。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-8ed3791587e9cb0c723958c6e2785a9e569.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-47200e5cc0905f11e73d76efe3e64bb95fb.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><span id="OSC_h3_5"></span><h3><strong>05、与众多合作伙伴联手共建平台工程升级方案，为开发者链接一切</strong></h3><p style="margin-left:0; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-47c27768bb61da18942141692c7acd82fa2.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">全链路灰度能力：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">融合阿里云 MSE 全链路灰度能力，开发者可轻松验证自助上线。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-46bcc5d51cf746d91687ecb79e48cf32981.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">可观测全链路：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">融合观测云检测服务，实现从变更到可观测全链路打通，一键发布。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-979e7bc7d790a3c3b0d9a880006b206bb21.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="margin-left:0; margin-right:0"><span style="color:#ff2968">安全策略内建：</span>支持清源 SCA、Fortify、Sonar 集成，全流程编排安全策略，每次变更都得到安全防护。</p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-66b182b75cbb3c998db1a6715bf3438cea5.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f478751e724c25bb9f36a717927132d8e25.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:#ff2968">AI 助力效能提升：</span><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">支持基于 Azure OpenAI 技术，提升 DevOps 诊断和运营效率，首次推出 AI 环境巡检和 AI 效能诊断模块。</span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-6c1e94b1ed2ff2b756730b38b6692cc9a45.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0"><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"><img alt="" src="https://oscimg.oschina.net/oscnet/up-4c09032ee8c8df89a48e7f3fcc75f473657.png" referrerpolicy="no-referrer"></span></p><p style="margin-left:0; margin-right:0">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">官方已开通免费 30 天试用</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">立即体验 ZadigX 最新版本，开启全新平台工程</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">创新之旅！🚀</p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px">&nbsp;<span style="background-color:#ffffff; color:#ff2968">ZadigX，开放，链接，专业</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px"><img src="https://oscimg.oschina.net/oscnet/up-737521b788156c5c0d8468b2e564baa99a6.png" referrerpolicy="no-referrer"></p><blockquote><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px"><strong>阅读原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNLnTwZQ-kEhEk7hw6ZRM_w" target="_blank">https://mp.weixin.qq.com/s/NLnTwZQ-kEhEk7hw6ZRM_w</a></strong></p></blockquote><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 01 Oct 2023 02:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/10115118</guid>
            <link>https://my.oschina.net/koderover/blog/10115118</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
    </channel>
</rss>
