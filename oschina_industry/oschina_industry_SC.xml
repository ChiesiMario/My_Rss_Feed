<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 06 Nov 2023 12:05:19 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Firefox Android 版扩展支持即将推出]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Mozilla 计划在 Firefox 120 版本发布 (预计于 11 月 21 日) 后为 Android 版 Firefox 提供浏览器扩展，并督促开发者评估其扩展代码，为此做好准备。</span></p><blockquote><p><span style="color:#000000">在 Firefox 120 的发布周期中，我们将开始在 addons.mozilla.org (AMO) 上看到数十个新的、可在 Firefox for Android 上公开使用的扩展。我们正在采取稳定的方法来开放移动扩展生态系统，以确保 Firefox for Android 在首次在移动环境中使用大量新扩展的同时，保持强大的性能标准。如果测试进展顺利，我们预计将在 12 月的某个时候推出完全开放的 Firefox for Android 扩展生态系统。</span></p></blockquote><p><img height="241" src="https://oscimg.oschina.net/oscnet/up-8be59849e0793fa2d91bbfbcf62cde5001d.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">事实上，早在 2019 年 Firefox&nbsp;移动产品战略负责人 Vesta Zare 就曾<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmozilla-mobile%2Ffenix%2Fissues%2F5315" target="_blank">提出</a>有关<span style="background-color:#ffffff">移动版扩展的</span>想法。但因为安全等方面的担忧，导致进展缓慢。现如今，</span><span style="color:#000000"><span style="background-color:#ffffff">Firefox 扩展程序的编辑部经理 Scott DeVaney 认为，预计用户将对此产生浓厚的兴趣。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">DeVaney 指出，按照当下的趋势，当 12 月份正式开放时 AMO 上将提供至少 200 多个新的 Firefox Android 扩展。</span>「虽然数百个扩展比你能在任何其他移动浏览器上找到的扩展都要多，<span style="background-color:#ffffff">但与 AMO 上近 40,000 个</span>桌面 Firefox 扩展<span style="background-color:#ffffff">相比，还是少得多</span>。因此，提高新用户可发现性的机会可能会吸引一些开发人员。」</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Chrome 浏览器的&nbsp;</span>Android 版尚不支持扩展功能。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2023%2F11%2F03%2Fmozilla_android_extensions%2F" target="_blank">The Register </a>指出，谷歌公司此举可能是因为担心&nbsp;Android 用户会使用插件屏蔽广告，从而影响其广告收益。不过，谷歌目前正在对其 Chrome 浏览器扩展架构 (Manifest v3) 进行修订。如果谷歌选择在 Android 版 Chrome 中添加扩展支持以避免被竞争对手甩在后面，那么 Manifest v3 扩展将更适合移动设备。值得注意的是，苹果、Mozilla 和微软都计划在各自的浏览器中支持 Manifest v3，但会有所变化。</span></p><p><span style="background-color:#ffffff; color:#000000">俄罗斯流行的 Yandex 移动浏览器已经在 2016 年增加了对 Android 扩展的支持，Kiwi 等其他基于 Android 的浏览器也均已实现。2021 年 9 月，苹果公司也在 iOS 15 中推出了对 Safari 扩展程序的支持。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 09:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265222/mozilla-android-extensions</guid>
            <link>https://www.oschina.net/news/265222/mozilla-android-extensions</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[释永信在 Meta 旧金山总部的分享：《禅宗遇到 AI》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>少林寺方丈释永信前几天在 Meta 旧金山总部进行了一场线下分享：《禅宗遇到 AI》。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-20a03a09dd590e8667727ffe3480e4cfe14.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-28ccc5a8d3722013dfb80753592032c7d65.png" referrerpolicy="no-referrer"></p><p>以下内容转载自<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.facebook.com%2FrealShiYongxin%2Fposts%2Fpfbid02BeBDeptmeVZLMuPyk6SXFqgFkz5DcQraoethMkiATQ4sxefEMic5ubBogwmNpW5Sl" target="_blank"> 释永信 Facebook 帐号</a></u></em>。</p><hr><p>释永信方丈 2023 年 11 月 2 日于旧金山脸书 (∞ Meta) 公司总部/Abbot Shi Yongxin at Meta Company Headquarters in San Francisco on November 2, 2023.</p><p>尊敬的各位来宾和朋友：</p><p>大家好！</p><p>今天非常荣幸能同各位朋友分享「禅宗遇到 AI」这个话题。随着人工智能技术的不断发展，它正在逐渐渗透到我们生活的各个领域。与此同时，这种技术的普及也对传统信仰产生了巨大影响。当古老的东方禅宗思想遇到 21 世纪尖端技术的人工智能，人文与科技的交汇势必会给当今世界的人们带来新的启示。</p><p>佛教到今天已经有 2500 余年的发展历史。禅宗是中国佛教影响最大、传播最广、发展最成熟的宗派，其中心思想可概括为「不立文字，教外别传，直指人心，见性成佛」。禅宗追求心灵的觉悟，它是对佛陀思想的继承和创新，同时又融汇了中国传统的儒家、道家思想，其修行方法以真修实证为主，不受任何知识、逻辑、思维乃至意识所束缚，是修禅者对解脱智慧的流露。禅宗思想深刻影响了中国的哲学、文学、艺术等领域，同时也在服务社会、净化人心、开启心智等方面做出了积极贡献。</p><p>少林寺始建于公元 495 年，禅宗初祖菩提达摩在少林寺面壁九年创立禅宗。少林寺作为禅宗祖庭，1500 多年来传承不断，其主要以「禅」为核心，以养生、功夫、医药和禅艺等为表现形式，方便度化众生。少林养生功法以习练《易筋经》等气功为主，辅以素食、坐禅、经行等方法，以达到涵养精气神之妙用。少林功夫是中国首批非物质文化遗产，以佛教信仰和禅宗智慧为基础，具有完整的技击理论体系，形成有擒拿、格斗、卸骨、点穴、拳械等多种功法，并形成了标准化、规范化的少林功夫段品制的修学体系，其最高境界为「禅武合一」。少林医药来自对佛学「医方明」的继承，结合中国传统中医，主张运用佛法治心、草本治身，以达到调养身心之功效。少林禅艺则以绘画、书法、雕刻、梵呗、茶器及围棋等为载体，以艺入禅来传播禅宗文化。</p><p>少林文化通过不断的传承与交流，已在韩国、日本、东南亚等地区得到广泛传播，近几十年来，欧美各国也涌现出许多少林文化的爱好者。少林寺还积极参与国际交流活动，为服务人类健康做出了积极贡献。目前，少林寺在全世界 150 多个国家 200 多个地区都有少林文化交流中心。</p><p>少林寺在历史发展中几经兴衰，但是如今依然传承不断，其原因在于少林文化的内动力，它兼容幷蓄，并且提倡人与自然，人与社会，人与自身的和合共生，同时少林文化在沟通国际关系、推动世界和平方面发挥了积极作用。少林寺在未来也依然会坚持传播平等、慈悲、清净、圆融的佛教普世价值观，更好的服务全人类。</p><p>当禅宗遇到人工智能时会发生什么？技术进步能否取代道德伦理进步？人工智能具有强大的数据处理和分析能力，并且经由程序和算法可能会表现出类似于人类的感知，但是人工智能并不能具备我们禅宗所讲的觉悟的心性。人类面对此人工智能应该保持头脑清醒，应该如禅宗所倡导的那样向内寻求，得到超越解脱的本觉智慧。</p><p>禅宗是强调修禅者通过自身的精进和努力，逐渐提升觉悟的境界，在这个过程中，常常会遇到诸多困惑和烦恼，AI 作为一作工具，可以检索查找相关经典，从而对治各种疑惑，为修禅者提供辅助和便利。</p><p>科技的进步让人们的闲暇时间增多，我们不希望因为闲暇时间的增多而使大众变得懒散放逸。在未来，我希望禅宗智慧和人工智能可以有更多互动，特别是在少林文化方面，能够携手搭建一个交流平台，让大众在修学体验少林禅、武、医、艺文化时，能够更加身临其境地感受少林文化的独特魅力，追求精神上的圆满，也让少林文化更好地服务全人类身心灵健康。</p><p>最后，祝愿大家一切吉祥！阿弥陀佛!</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 08:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265201</guid>
            <link>https://www.oschina.net/news/265201</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周热点 | VS Code 史上呼声最高的特性终于实现；vivo 发布自研操作系统蓝河 (BlueOS)....]]>
            </title>
            <description>
                <![CDATA[回顾一周热门资讯。2023.10.31-2023.11.05]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 07:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[DHorse 即将支持更多的登录方式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>现状</h2><p>在 v1.4.0 版本之前，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F512team%2Fdhorse" target="_blank">DHorse</a>支持的登录方式有：DHorse 系统本身、Ldap 两种；但是，既然作为企业级服务，只支持以上两种方式是不够的。当下，越来越多的企业使用钉钉和企业微信进行沟通和办公，支持这两种登录方式也势在必行，此外，还有传统的 SSO 登录，在未来的 v1.5.0 的版本里即将支持以上登录方式。</p><p>下面，简单介绍一下即将支持的这三种登录方式。</p><h3>钉钉登录</h3><p>开启钉钉登录，需要具备以下几个条件：</p><ul><li>需要拥有钉钉后台的管理权限；</li><li>需要创建钉钉应用；</li><li>需要进行 DHorse 的钉钉配置；</li></ul><h3>企业微信登录</h3><p>开启企业微信登录，需要具备以下几个条件：</p><ul><li>需要拥有企业微信的后台管理权限；</li><li>需要创建企业微信的应用；</li><li>需要配置 DHorse 的企业微信；</li></ul><h3>SSO 登录</h3><p>CAS 是 SSO 登录的主流实现者，DHorse 也使用 CAS 登录来实现 SSO 登录的功能；</p><p>开启 SSO 登录，需要具备以下几个条件：</p><ul><li>需要企业提供自己的 CAS 服务；</li><li>需要配置 DHorse 的 CAS 登录；</li></ul><h2>结论</h2><p>为了更好的与企业管理员工方式的多样性相结合，简化企业管理，支持尽可能多的登录方式势在必行。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265154</guid>
            <link>https://www.oschina.net/news/265154</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[李开复旗下 AI 公司发布 Yi 系列开源大模型，估值超 10 亿美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>创新工场董事长兼 CEO 李开复于今年创办了 AI 大模型创业公司「<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.01.ai%2F" target="_blank">零一万物</a></u>」。<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2506227176630145" target="_blank">根据 36 氪的独家报道</a></u>，零一万物已完成新一轮融资，由阿里云领投。目前，<strong>零一万物估值已超 10 亿美元，跻身独角兽行列</strong>。</p><p><strong>该公司已推出&nbsp;Yi-34B 和&nbsp;Yi-6B 两个开源大模型</strong>，号称对学术研究完全开放，同步开放免费商用申请。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4ab5886e43554fd3233305e7c8264217507.png" referrerpolicy="no-referrer"></p><blockquote><p>Hugging Face：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B" target="_blank">https://huggingface.co/01-ai/Yi-34B</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-6B" target="_blank">https://huggingface.co/01-ai/Yi-6B</a></p><p>ModelScope：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-34B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-34B/summary</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-6B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-6B/summary</a></p><p>GitHub：<br><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F01-ai%2FYi" target="_blank">https://github.com/01-ai/Yi</a></p></blockquote><p><span>据介绍，Yi 目前拥有 200K 上下文窗口，可处理约 40 万字的文本——这也是目前全球大模型中最长的上下文窗口。其中 Yi-34B 在 Hugging Face 英文测试榜单中位列第一，在 C-Eval 中文能力排行榜中超越所有开源模型。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e1c843e9962b9e9aecc13487da3270520c.png" referrerpolicy="no-referrer"><br><em>Hugging Face Open LLM Leaderboard (pretrained) 大模型排行榜，Yi-34B 高居榜首 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-03d63eae8034e7ca5d0e28148b2fb94dc3f.png" referrerpolicy="no-referrer"><br><em>C-Eval 排行榜:公开访问的模型，Yi-34B 全球第一 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e5919449029e62b8bf111322f96af0dcb3.png" referrerpolicy="no-referrer"></p><p>Yi-34B 和 Yi-6B 的表现：</p><ul><li><strong>C-Eval 中文能力排行榜</strong>：Yi-34B 在 C-Eval 中文能力排行榜上超越了所有开源模型，这意味着在中文语言理解和生成方面，Yi-34B 的性能优于其他所有开源的大模型。</li><li><strong>中文综合能力</strong>：在 CMMLU、E-Eval、Gaokao 等中文评测指标上，Yi-34B 明显领先于 GPT-4，展现了其在中文语境下的强大理解和应用能力。</li><li><strong>中文问答能力</strong>：在 BooIQ、OBQA 两个中文问答指标上，Yi-6B 和 Yi-34B 与 GPT-4 的表现水平相当，这表明它们在理解中文问题和提供准确答案方面具有很高的能力。</li><li><strong>超长文本处理</strong>：200K 上下文窗口，Yi-34B 能够处理大约 40 万汉字的超长文本输入，这在处理长篇中文文档、书籍或报告时尤为重要，能够理解和生成连贯、准确的中文文本。</li><li><strong>技术创新</strong>：零一万物自研规模化训练实验平台和智能数据处理管线。强大的 AI 基础设施支持，提高了训练效率和降低了成本。</li></ul><p>「零一万物」在官网写道，他们深信「以大语言模型为突破的 AI 2.0 正在掀起技术、平台到应用多个层面的革命」。根据他们的判断，AI 2.0 时代将诞生「比移动互联网大十倍的平台机会」，将把既有的软件、使用界面和应用重写一次，改写用户的交互和入口。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 05:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</guid>
            <link>https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenHarmony 4.0 开发数据：华为贡献者 1800 名、增删改代码 8849882 行]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenHarmony <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW9H8Yyq6-jK-35FnIsafSQ" target="_blank">公布</a></u>了关于 4.0 Release 版本的开发数据。</p><p>据介绍，<u><a href="https://www.oschina.net/news/264989/openharmony-4-0-released">OpenAtom OpenHarmony 4.0 Release 版本</a></u>于 10 月 27 日发布，经过了 32 周的开发周期。</p><p>在此期间，有 65499 个 Committs 进入了版本。共有 2220 位贡献者为 4.0 Release 版本做出了贡献。其中，华为贡献者 1800 名，累计 2000+名，共增删改代码 8849882 行，占比 80.03%。</p><p>华为的 5 名顶级贡献者和华为以外的 15 名顶级贡献者如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb921b7f488f8d9d32c10bfb308ed11d6fe.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">以下的单位参与了 OpenHarmony 4.0 Release 版本的工作，较活跃的如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-baa6184ec3c30845abf2d57faddb063630b.png" referrerpolicy="no-referrer"></p><p>不同单位在不同子系统的贡献比例：</p><p>华为的贡献覆盖 30 多个核心子系统，其他顶级共建单位在各领域的贡献情况如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9045d86ad3cdc74208e832cc5a7cc327d37.png" referrerpolicy="no-referrer"></p><p>这些单位对 OpenHarmony 4.0 Release 版本的工作主要集中在以下领域：</p><p>• 深开鸿的工作主要集中在短距，驱动，XTS，开发工具，ArkUI 子系统中，包括蓝牙&amp;wifi 增强，ArkUI 运行时，ArkUI 组件增强，NAPI 框架生成工具，ALSA 驱动 HDI 插件平台解耦，codec 驱动 HDI 接口，ArkUI XTS 套件支持，RK3568 开发板等特性。</p><p>• 开鸿智谷的工作主要集中在开发样例，开发板，轻内核子系统中，包括轻内核 queue 读写增强，ArkUI 组件集合样例，场景化仿应用开发（设备管理，通信，数据库，相机，语音）和 Niobe 开发板等特性。</p><p>• 软通动力的工作主要集中在 ArkUI，XTS，开发板子系统中，包括 ArkUI 组件（TextInput，TextTimer，边框）增强，wpt 套件 Reftest 自动化测试，ArkUI 布局 XTS 套件，UnionPi Tiger 开发板,扬帆致远开发板等特性。</p><p>• 九联科技的工作主要集中在开发样例，芯片内核驱动，HDF 驱动子系统中，包括温湿度传感器驱动，开发样例（通知，分布式账号管理，资源授权访问，一多交互等场景），A311D 芯片适配，UnionPi Tiger 开发板适配等特性。</p><p>• 润开鸿的工作主要集中在芯片开发板，ArkUI，驱动子系统中，包括 arkcompiler 中 arraybuffer 功能增强，启动流程优化，DAYU210 开发板，Neptune100 开发板适配等特性。</p><p>• 诚迈的工作主要在多模输入子系统中。</p><p>据称华为、深开鸿、软通动力、开鸿智谷分别建设超过 5 万+行代码并持续贡献中，成为 2023 年《百人代码贡献单位》。九联开鸿、润开鸿、京东、诚迈科技、中科院软件所、中软国际持续贡献中，计划今年 12 月 31 日前贡献 5 万+行功能特性代码。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 04:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265135</guid>
            <link>https://www.oschina.net/news/265135</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[马斯克旗下 xAI 发布首个 AI 大模型产品 Grok]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">马斯克旗下 xAI 团队发布其首个 AI 大模型产品 —— <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.ai%2F" target="_blank">Grok</a>；目前只训练了 2 个月左右的时间，因此尚处于非常早期的测试阶段。</span></p><blockquote><p><span style="color:#000000">Grok 是一款仿照《银河系漫游指南》设计的人工智能，可以回答几乎任何问题，更难能可贵的是，它甚至可以建议你要问什么问题！</span></p><p><span style="color:#000000">Grok 在回答问题时略带诙谐和反叛，因此如果你讨厌幽默，请不要使用它！</span></p><p><span style="color:#000000">Grok 的一个独特且根本的优势是它可以通过 𝕏 平台实时了解世界。它还能回答被大多数其他人工智能系统拒绝的尖锐问题。</span></p></blockquote><p><img height="316" src="https://oscimg.oschina.net/oscnet/up-95e999fb26b9fab921735913d2139b7577d.jpg" width="300" referrerpolicy="no-referrer"></p><p><img height="388" src="https://oscimg.oschina.net/oscnet/up-c1e26f5d404c988b2332dcab2ffaa7becdc.jpg" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Grok 基于&nbsp;xAI 团队于 11 月发布的自研大语言模型&nbsp;Grok-1。在&nbsp;xAI 宣布成立后，项目团队就用 330 亿个参数训练了一个 LLM 原型（Grok-0），这一<span style="background-color:#ffffff">早期模型</span>自称与 LLaMA 2 (70B) 能力相当，但只使用了一半的训练资源。</span></p><p><span style="color:#000000">Grok-1 则在此基础上改进了推理和编码能力。Grok-1 是一个基于 Transformer 的自回归模型，经过预先训练以执行 next-token 预测。然后利用人类和早期 Grok-0 模型的广泛反馈对该模型进行微调，初始 Grok-1 的上下文长度为 8192 个 token。</span></p><p><span style="color:#000000">一些评测结果如下所示：</span></p><p><span style="color:#000000"><img height="238" src="https://oscimg.oschina.net/oscnet/up-78c5896454178aea96eb296a0a2beeb7faf.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img height="96" src="https://oscimg.oschina.net/oscnet/up-ff9e8be5f7abf6322719c422a60352348a7.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Grok-1 也存在一些局限性，该语言模型不具备独立搜索网络的能力，官方建议在 Grok 中部署搜索工具和数据库可以增强模型的能力和真实性。并警告称，尽管可以访问外部信息源，但该模型仍会产生幻觉。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">为了创建 Grok，</span>xAI 团队还<span style="background-color:#ffffff">构建了一个基于 Kubernetes、Rust 和 JAX 的自定义训练和推理堆栈。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「</span>Rust 已被证明是构建可扩展、可靠且可维护的基础架构的理想选择。它提供高性能、丰富的生态系统，并防止分布式系统中通常会发现的大多数错误。鉴于我们的团队规模较小，基础架构的可靠性至关重要，否则维护就会缺乏创新。Rust 让我们充满信心，任何代码修改或重构都可能产生可以在最少监督的情况下运行数月的工作程序。<span style="background-color:#ffffff">」</span></span></p><p><span style="color:#000000">目前&nbsp;<span style="background-color:#ffffff">Grok 仅面向少数美国用户<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrok.x.ai%2F" target="_blank">开放测试</a>。</span></span></p><p><strong><span style="color:#000000">相关阅读：</span></strong></p><ul><li><a href="https://www.oschina.net/news/249159/elonmusk-announced-xai" target="_blank">马斯克宣布成立 xAI 公司</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265129/xai-grok</guid>
            <link>https://www.oschina.net/news/265129/xai-grok</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[承载微软跨平台生态之梦的 UWP，正在消亡]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>开发者发现，微软最新的 Windows&nbsp;11&nbsp;Canary Build 25987 预览版已经开始提供两个版本的 XAML Shell 服务，<strong>新的版本直接基于 Win32 + XAML</strong>，曾经被寄予厚望的 UWP 在新版本里已经不见踪影。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1106/113836_8gF1_2720166.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fthebookisclosed%2Fstatus%2F1720108362275213594" target="_blank">https://twitter.com/thebookisclosed/status/1720108362275213594</a></em></u></p></blockquote><p>据介绍，新增的 dll 名为 ControlCenter.dll，这是控制中心的文件，目前已经同时提供旧版本和新的基于 Win32+XAML 的版本，即用户可以通过 ViveTool 启用这种新变体。</p><p>一般来说能被发现已经可以通过 ViveTool 启用，那么这个新变化基本已经开发完毕，后续就会分别面向不同的用户进行测试，收集运行数据。</p><p>延伸阅读</p><ul><li><strong><a href="https://www.oschina.net/news/165300/ms-officially-deprecates-uwp">微软正式弃用 UWP</a></strong></li><li><strong><a href="https://www.oschina.net/news/149997/winui-3-uwp-win32-apps-windows11">WinUI 3 仍专注于 Win32 应用，暂无面向 UWP 的计划</a></strong></li><li><strong><a href="https://www.oschina.net/news/107123/microsofts-uwp-app-dream-is-dead">Win32 应用进入微软应用商店，UWP 怎么办？</a></strong></li><li><strong><a href="https://www.oschina.net/news/149797/ms-store-xmal">Microsoft Store 完全使用 XAML 以替代 HTML，Visual Studio 预计年底上架商店</a></strong></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265128</guid>
            <link>https://www.oschina.net/news/265128</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[蚂蚁集团百灵大模型通过备案，采用 Transfromer 架构]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 6 日，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jiemian.com%2Farticle%2F10342101_sina.html" target="_blank">界面新闻从蚂蚁集团获悉</a></u>，根据国家七部委联合公布的《生成式人工智能服务管理暂行办法》指导要求，蚂蚁百灵大模型已完成备案，基于百灵大模型的多款产品已陆续完成内测，将向公众开放。</p><p>本次通过备案的是<strong>蚂蚁百灵语言大模型，该大模型采用 Transfromer 架构</strong>，基于万亿级 Token 语料训练而成，支持窗口长度达 32K。</p><p>目前，蚂蚁大模型已形成包括大模型底层基础设施、基础大模型、行业大模型、应用产品在内的完整技术链条。</p><p>在基础大模型层面，除了本次通过备案的百灵语言大模型，蚂蚁集团也在研发百灵多模态大模型，并已内测。</p><blockquote><p><a href="https://www.oschina.net/news/257409/codefuse-ai" target="_blank">蚂蚁集团正式开源 CodeFuse 代码大模型</a><br><a href="https://www.oschina.net/news/246241" target="_blank">蚂蚁集团证实正研发语言和多模态大模型，命名「贞仪」</a></p></blockquote><p>国内第二批通过备案的 AI 大模型包括 11 家公司，部分已面向全社会开放服务。加上首批的 10&nbsp;余个大模型，目前已有超过 20&nbsp;个大模型获得备案。</p><p>新一批备案名单包括：网易有道（「子曰」大模型）、蚂蚁集团（百灵大模型）、面壁智能（「面壁露卡 Luca」）、出门问问（「序列猴子」）、昆仑万维（「天工」大模型）、美团（模型）、知乎（「知海图 AI」模型）、月之暗面（moonshot）、金山办公（WPS AI）、好未来（MathGPT 大模型）等。</p><p>8 月 31 日首批通过备案的 AI&nbsp;大模型包括百度文心一言、百川智能、商汤商量 SenseChat、抖音（云雀大模型）、智谱 AI（GLM 大模型）、中科院（紫东太初大模型）、上海 MiniMax（ABAB 大模型）、上海人工智能实验室（书生通用大模型）、「360 智脑」等等。</p><blockquote><p><a href="https://www.oschina.net/news/256949" target="_blank">挑战 ChatGPT，国产有这 8 款 AI 大模型产品</a></p></blockquote><p>据悉，今年 8 月 15 日正式施行的《生成式人工智能服务管理暂行办法》 ，提供具有舆论属性或者社会动员能力的生成式人工智能服务的，应当按照国家有关规定开展安全评估，并按照《互联网信息服务算法推荐管理规定》履行算法备案和变更、注销备案手续。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265114</guid>
            <link>https://www.oschina.net/news/265114</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[云几何内核开源平台 —— OpenGeometry 开源社区正式发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 5 日，由广东省工业和信息化厅、广东省科学技术厅、广东省教育厅、深圳市人民政府主办，工业和信息化部第五研究所、广东省数字化学会承办，深圳市工业和信息化局、深圳市龙岗区人民政府、深圳市福田区人民政府协办的 2023 工业软件生态大会在广东省深圳市召开。</p><p>在大会主论坛上，国内备受关注的云几何内核开源平台——OpenGeometry 开源社区正式发布。</p><p><img src="https://static.oschina.net/uploads/space/2023/1106/104536_bRwO_2720166.png" referrerpolicy="no-referrer"></p><p>据介绍，OpenGeometry Group（简称 OGG）是由数字化工业软件联盟孵化，并由开元几何（深圳）科技有限公司作为服务公司运营的开源项目。OpenGeometry 开源社区将通过搭建云几何内核的开源软件开发平台，构建新一代工业软件的核心「根」技术，为工业软件的产品研发提供支持，并带动上下游厂商、服务商等合作伙伴共同参与，最终形成产业链协同发展的良性循环。</p><p>OpenGeometry 开源社区表示，未来将积极与科研院校、工业软件厂商、工业软件应用企业、开发者等合作伙伴进行广泛的技术交流和合作，引进国内外最先进的技术、吸引顶尖的人才，引入数字化工业软件联盟的生态资源，深入电子、汽车、装备制造等行业应用中进行场景化联合研发，真正做到以高质量的技术更好地服务产业实体经济。</p><div>
 北师大港浸大的单肖文教授代在会上表示，OpenGeometry 开源社区对中国工业软件界意义很大，是构筑工业软件的「根」，只有「根」扎得深，工业软件的树才能枝繁叶茂。
</div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265108</guid>
            <link>https://www.oschina.net/news/265108</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[轻松理解 Transformers (3): Feed-Forward Layer 部分]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>编者按：随着人工智能技术的不断发展 Transformer 架构已经成为了当今最为热门的话题之一。前馈层作为 Transformer 架构中的重要组成部分，其作用和特点备受关注。本文通过浅显易懂的语言和生活中的例子，帮助读者逐步理解 Transformers 中的前馈层。</p><p>本文是 Transformers 系列的第三篇。作者的观点是：前馈层在 Transformer 架构中扮演着至关重要的角色，它能够有效地提高计算效率，同时也是集体智慧的体现。</p><p>文章作者首先介绍了前馈层的基本结构，它由全连接层组成，进行线性变换和线性计算。但也存在局限性，不能进行复杂的非线性变换。所以前馈层需要激活函数（如 ReLU）进行非线性转换，增强网络的表达能力。为防止模型仅记忆数据特征而不具备推理能力，需要使用正则化技术如 dropout。相信通过本文的阅读，读者将对 Transformer 中的前馈层有更深入的理解。</p><p>随着深度学习在语音、图像、自然语言处理等领域取得突破，人工智能或许正向着真正的通用人工智能迈进。但要培养通用人工智能，我们还需不断深入理解其中的原理和相关机制。</p><p>以下是译文，enjoy！</p></blockquote><p><strong>作者 | Chen Margalit</strong></p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fchen-margalit%2F" target="_blank">https://www.linkedin.com/in/chen-margalit/</a></strong></p><p><strong>编译 | 岳扬</strong></p><p><em><strong>本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。</strong></em></p><p><em>原文链接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftowardsdatascience.com%2Fsimplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9" target="_blank">https://towardsdatascience.com/simplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9</a></em></p><p>本节将介绍前馈层（Feed-Forward layer），这是大多数深度学习架构中的基础元素。在有关深度学习的常见话题交流时，一般都会强调它们在构造 Transformer 架构中的重要作用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a856aacefd53ae8070b810c099e0da6711.png" alt="" referrerpolicy="no-referrer"><em>原论文中的图片[1]</em></p><p>前馈全连接层（feed-forward linear layer）基本上就是一堆神经元，每个神经元都与其他神经元相连接。请看下图，其中 a、b、c 和 d 是神经元。这些神经元包含了一些 input（即一些我们想要理解的数据（像素值（pixels）、词嵌入（word embeddings）等））。它们与编号为 1 的神经元相连。每两个神经元之间的连接都有不同的连接权重值（connection strength）。例如，a-1 是 0.12，b-1 是-0.3，等等。实际上，左列中的所有神经元都与右列中的所有神经元相连。但是为了清晰起见，我没有在图像中展示全部的连接，你需要了解这一情况。就像图中有 a-1 一样，还应该有 a-2、b-2、c-2、d-3 等。两个神经元之间的每个连接都有不同的「连接权重」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f139aa760b0e5733e14a61f50803820e023.png" alt="" referrerpolicy="no-referrer"></p><p><em>该图由原文作者绘制</em></p><p>该架构有两点值得注意：</p><ol><li>如前所述，每个节点（神经元）都与其他节点相连。所有的 a、b、c、d 都与其他神经元（1、2、3）相连。可以将这幅图像看作是一条军队指挥链。1、2、3 是指挥官。他们从士兵 a、b、c、d 那里得到情报。a 知道某件事情的一些细节，但它的情报不够全面。1 知道的就更多了，因为它能够从 a、b、c 和 d 那里同时得到情报。2 和 3 也是指挥官，同样从 a、b、c、d 那里获取情报。这些指挥官（1、2、3）也会向更高级的指挥官传递报告。在他们之后的指挥官既从 a、b、c、d 那里得到情报，也从 1、2、3 那里得到情报，因为下一层（每列神经元为一层）也是以完全相同的方式进行全连接的。因此，首先要明白的是， 1 的情报比 a 更全面，而下一层指挥官的情报也比 1 更全面。</li><li>第二点需要注意的是，每个节点与下一层的每个其他节点之间的连接权重是不同的。a-1 是 0.12，b-1 是-0.3。我在这里给出的数字显然是虚构的，但它们也是在合理的范围内，并且它们都是自动学习调整的参数（learned parameters）（例如，它们在训练过程中会发生变化）。把这些数字看作是 1 对 a、b 等的影响程度。从 1 号指挥官的角度来看，a 的情报有一定的可信度。但不应该想当然地相信他说的每一句话，可以选择性地相信他说的某些话。b 则截然不同。这个节点通常会低估它接收到的输入（情报）的重要性，就像一个悠闲的人一样。「这是一只 tiger 吗？不，只是一只 big cat。」 这是对发生的事情的过度简化，但重要的是要注意这一点：<strong>每个神经元都掌握着一些 input（无论是原始输入还是经过处理的 input）并进行处理后将其传递下去。</strong></li></ol><p>你知道「传话游戏」吗？你和其他 10 个人坐成一排，然后你向下一个人耳语一个词，比如说「Pizza」。第 2 个人听成了类似「Pazza」的词，于是他们把「Pazza」传给了第 3 个人。第 3 个人听成了 「Lassa」（毕竟是耳语），于是他把 「Lassa」传给了第 4 个人。第 4 个人听成了 「Batata」，于是他又转述了 「Batata」，以此类推。当你问第 10 个人他听到了什么？结果他回答「Shambala」，我们是怎么从「Pizza」到「Shambala」的？这个游戏与神经网络的区别在于，每个人都会对信息进行处理。第二个人不会说 「Pazza」，他会说「Pazza 是意大利菜，很好吃」。第三个人会说：「Lassa 是一道意大利菜，在全世界都很常见」，等等。每个人（层）都会补充一些他们希望有用的东西。</p><p>基本情况就是这样。<strong>每个神经元获得输入，处理输入，然后继续传递。</strong> 为了与全连接层（fully connected layer）相匹配，我建议对这个游戏进行升级：从现在开始，在游戏中引入多行人，每个人都可以对每一行中的其他人说悄悄话。从每一行的第 2 位开始，每个人都会收到很多人的悄悄话，他们需要了解每个人说的话语的「权重」（重要性），这就是前馈层（Feed Forward Layer）。</p><p><strong>为什么我们要使用前馈层？因为它们使我们的计算能够更加有效，可以将其类比为集体智慧的体现。</strong> 讲一个关于「猜测一头牛重量」的故事吧！1906 年，在英国的某个地方，有人把一头牛带到一个展览会上。主持人随机挑选了 787 名观览者，请他们猜测这头牛的重量。你认为他们猜测的结果会是多少？这头牛的实际体重是多少呢？</p><p>他们猜测的平均值是 1197 磅（542 公斤）。这些都是随机抽取的群众对牛体重的估计。这个平均猜测值离真实重量相差多远呢？只有 1 磅差距，也就是 450 克。这头牛的重量是 1198 磅。这个故事来自这里[2]，我不确定细节是否准确，但回到本文的主题，我们可以把线性层 <em>（译者</em><em>注：此处即本文所说的前馈层）</em> 看作是在做类似的事情。通过增加更多的参数、更多的计算（更多的猜测），就可以得到更准确的结果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1dd0ad28fe0fffea90238839fce31188c1e.png" alt="" referrerpolicy="no-referrer"></p><p><em>照片由 Larry Costales[3] 在 Unsplash[4] 上发布</em></p><p>让我们试着想象一个真实的使用场景。给神经网络输入一张图片，让它判断图片里的是苹果还是橙子。这种架构基于卷积神经网络（CNN）层，本文不会深入讨论这个知识点，因为其超出了本系列文章的范围。但该层是一个能够学习和识别图像中特定模式（specific patterns）的计算层。 <em>（译者注：这些特定模式的识别有助于网络进行更准确的分类和判断，例如判断图像中是苹果还是橙子。）</em> 每一层都能识别更复杂的模式。例如，第一层几乎不能识别出任何东西，该层只是传递原始像素，第二层就能够识别出垂直线条。如果下一层同时接收到有垂直线条的信息，并从其他神经元那里听说还有非常接近的垂直线条。它会将两者综合起来进行计算、分析，然后思考：不错！这是一个角落。这就是从多个来源获取输入信息的好处。</p><p>我们可能会认为，进行计算的次数越多，得到的结果就越好。但事实上，并非完全是这样，但确实有一定的道理。如果我们做更多的计算，咨询更多人（神经元）的意见，通常就能得出更好的结果。</p><h1><strong>01 激活函数 Activation Function</strong></h1><p>接下来将介绍深度学习中另一个非常重要的基本概念的关键组成部分——激活函数，并探讨它与 Transformer 的关系，以便更好地理解两者之间的关联。</p><p>尽管全连接层（Fully connected layers）的使用非常广泛，但也存在一个很大的缺点——<strong>它们是线性层（linear layers），只能进行线性变换和线性计算。全连接层可以进行加法和乘法运算，但无法以「创造性」的方式转换输入（input）。有时候，仅仅增加计算量是不够的，需要以完全不同的思考方式来解决问题。</strong></p><p>如果我每天工作 10 个小时，每天赚 10 美元，如果我想更快地存下 1 万美元，我可以每周工作更多天，或者每天工作更多小时。但是肯定还有其他解决方案，对吧？有很多人不需要他们拥有的钱（我可以更好地利用它），或者我可以找到更高薪的工作等等。解决办法并不总是千篇一律。</p><p>同理，在本文的情况下，激活函数可以来提供帮助。激活函数能够帮助我们进行非线性变换（non-linear transformation）。例如，将一个数字列表[1, 4, -3, 5.6]转换为概率分布，就是 Softmax 激活函数的作用。该激活函数能够将这些数字转换为[8.29268754e-03, 1.66563082e-01, 1.51885870e-04, 8.24992345e-01]这样的输出。这 5 个数字相加等于 1。虽然这些数字看起来有些混乱，但 e-03 表示第一个数字（8）在小数点后 3 个零开始（例如 0.00，然后是 82926。实际上该数字是 0.00829268754）。<strong>这个 Softmax 激活函数将整数转换为 0 到 1 之间的浮点数，转换后的浮点数仍然保持了原始整数之间的相对大小关系。这种保持相对大小关系的特性在统计学中非常有用。</strong></p><p>还有其他类型的激活函数，其中最常用的之一是 ReLU（修正线性单元）。这是一种非常简单（同时也非常有用）的激活函数，它能够将任何负数转化为 0，而非负数保持不变。非常简单且实用。如果我将列表[1, -3, 2]输入 ReLU 函数，会得到[1, 0, 2]。</p><p>在介绍完复杂的 Softmax 之后，你可能会期望一些更复杂的东西，但有人曾经告诉我「Luck is useful」。有了激活函数后，我们就走运了。</p><p>我们之所以需要这些激活函数，是因为非线性关系（nonlinear relationship）无法通过线性计算（全连接层）来表示。如果我每工作一小时就能得到 10 美元，那么收入就是线性关系。如果我每连续工作 5 个小时，接下来的 5 个小时就能增加 10%，那么这种关系就不再是线性的了。我的工资不再是工作小时数乘以固定的小时工资。<strong>在文本生成等更复杂的任务中使用深度学习，就是因为我们要建模的关系高度非线性。</strong> 在「我喜欢」之后能出现的词并不是固定的。</p><p>ReLU 的一大优势，也许可以解释它为何被广泛使用，就是<strong>对大量数据进行计算的成本非常低。</strong> 当神经元数量较少时（比方说几万个），计算量并不重要。但是当像大语言模型那样使用数千亿个神经元时，一种更高效的计算方式会带来巨大差异。</p><h1><strong>02 正则化 Regularization</strong></h1><p>在解释 Transformer 中如何实现正则化（非常简单）之前，我们将介绍最后一个概念——dropout，这是一种正则化技术。由于算法是基于数据的，并且它们的任务是尽可能逼近训练目标，所以对于一个大脑聪明的人来说，有时仅仅记住一点点东西就足够了。正如我们在学校中所受到的教育，学习复杂的逻辑并不总是有用的，我们有时只需记住我们所见过的，或者记住与之接近的东西。第二次世界大战是什么时候发生的？嗯...它受到了第一次世界大战、经济危机、人民愤怒等等因素的影响...大约是 1917 年左右...所以我们就说是 1928 年吧。记住确切的日期可能更好。</p><p>可以想象，这对机器学习来说并不是好事。如果我们需要的是已经有答案的问题的答案，我们就不需要这些复杂的技术了。我们需要一个聪明的算法，因为我们无法记住所有的东西。我们需要它进行实时推理，进行思考。<strong>正则化（Regularization）是让算法仅学习不记忆的一系列技术的总称。在这些正则化技术中，一种常用的技术就是 dropout。</strong></p><h1><strong>03 Dropout</strong></h1><p>dropout 可以说是一种相当简单的技术。还记得我们说过全连接层（fully connected layers）是完全连接的吗？dropout 打破了这种逻辑。dropout 技术将「连接权重（connection strength）」设置为 0，这意味着该连接不会产生任何影响。对于 1 号指挥官来说，连接到士兵「a」的输入变为 0 时，「a」传递的情报会变得完全无用。不回答，不肯定，也不否定。<strong>我们在每一层中使用 dropout 技术时，会随机选择一定数量的神经元（由开发者配置），并将它们与其他神经元的连接权重设为 0。</strong> 每次指挥官会被迫忽略不同的士兵，因此无法记住其中任何一个士兵，因为下次可能不会再遇到它们传递情报。</p><h1><strong>04 回到 Transformer！</strong></h1><p>现在我们已经掌握了理解 Transformer 中前馈层工作原理所需的所有基础知识。接下来解释实现过程就会非常简单了。It will now be very simple.</p><p><img src="https://oscimg.oschina.net/oscnet/up-d58c4da377e46953ddd77cd2bcb9c4fdd64.png" alt="" referrerpolicy="no-referrer"></p><p><em>图片来自 Vaswani, A. 等人的论文[5]</em></p><p>在原论文中的架构图中，前馈线性层只做了四件事情：</p><ul><li><strong>对文本中的每个位置 (用向量表示)，进行逐位置的线性计算。</strong></li><li><strong>对线性运算的输出应用 ReLU 函数。</strong></li><li><strong>对上一步骤 ReLU 运算的输出进行再一次线性运算。</strong></li><li><strong>最后，将其添加到第 3 层的输出中。</strong></li></ul><p>就是这样。如果你有深度学习领域的相关经验，那么理解这一部分对你来说可能很容易。如果你没有经验，可能稍显吃力，但你已经理解了深度学习中一个极为重要的组成部分。</p><p>在下一部分,我们将介绍 Transformer 中的解码器 (Decoder) 部分相关知识！</p><p><strong>END</strong></p><h1><strong>参考资料</strong></h1><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wondriumdaily.com%2Fthe-wisdom-of-crowds%2F%23%3A%7E%3Atext%3DAn%2520Astonishing%2520Example%2520of%2520the%2520Wisdom%2520of%2520Crowds%26text%3DThe%2520actual%2520weight%2520of%2520the%2Cthat%2520weight%2520was%25201%252C197%2520pounds" target="_blank">https://www.wondriumdaily.com/the-wisdom-of-crowds/#:~:text=An%20Astonishing%20Example%20of%20the%20Wisdom%20of%20Crowds&amp;text=The%20actual%20weight%20of%20the,that%20weight%20was%201%2C197%20pounds</a>.</p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2F%40larry3%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/@larry3?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2Fphotos%2FAhf1ZmcKzgE%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/photos/Ahf1ZmcKzgE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/10141048</guid>
            <link>https://my.oschina.net/IDP/blog/10141048</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[龙芯 3A6000 国产桌面处理器本月底发布，对标英特尔 10 代酷睿]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日的龙芯中科 2023 年第三季度业绩说明会上，龙芯中科宣布&nbsp;3A6000 国产桌面处理器初步定于<strong>11 月 28 日发布</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-033f0723def37a98686c0268285f4fe7284.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frsc.sseinfo.com%2FroadshowIndex.do%3Fid%3D16536" target="_blank">https://rsc.sseinfo.com/roadshowIndex.do?id=16536</a></em></u></p><p>龙芯 3A6000 是基于龙架构的新一代四核处理器，于今年 8 月流片成功。综合相关测试结果，<strong>龙芯 3A6000 处理器总体性能与英特尔公司 2020 年上市的第 10 代酷睿四核处理器相当</strong>，因此也是不少国内用户期待的一款高性能国产处理器。</p><p>龙芯中科在业绩说明会上透露，龙芯 3A6000 将于 11 月底正式发布（初步定于 11 月 28 日），<strong>十几家整机 / ODM 企业将发布其整机产品</strong>。</p><p><img height="1098" src="https://static.oschina.net/uploads/space/2023/1106/145609_pmei_2720166.png" width="2910" referrerpolicy="no-referrer"></p><p>在谈到后续产品龙芯 3B6000 时，龙芯中科董事长、总经理胡伟武表示：「龙芯走的是提高效率路线，争取每 GHz 性能接近或达到苹果 CPU 的水平。<strong>3B6000 争取每 GHz 的性能再提高 20%-30%</strong>，在此基础上再用先进工艺提高主频，这时候龙芯 CPU 性能就处于世界领先行列了。当然，我们也会努力提高 3B6000 的主频。」</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 06:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265161</guid>
            <link>https://www.oschina.net/news/265161</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维「天工」大模型正式向全社会开放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 11 月 3 日，昆仑万维「天工」大模型通过《生成式人工智能服务管理暂行办法》备案，面向全社会开放服务！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>用户在应用商店下载「天工</span></span><span><span>APP」或登陆「天工官网」（www.tiangong.cn）均可直接注册使用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>「天工」是国内首个对标</span></span><span><span>ChatGPT 的双千亿级大语言模型，也是一个 AI 搜索引擎，一个对话式 AI 助手。「天工」拥有强大的自然语言处理和智能交互能力，能够实现个性化 AI 搜索、智能问答、聊天互动、文本生成、编写代码、语言翻译等多种应用场景，并且具有丰富的知识储备，涵盖科学、技术、文化、艺术、历史等领域。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span>&nbsp;<img alt="" height="589" src="https://oscimg.oschina.net/oscnet/up-d32a56bf391efe8f4eb7543b06215352058.png" width="1265" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2022 年 12 月 15 日，昆仑万维在北京举行 AIGC 技术发布会，发布自研 AIGC 全系列算法与模型，覆盖了图像、音乐、文本、编程等多模态的 AI 内容生成能力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 4 月 17 日，昆仑万维正式发布自研千亿级大语言模型「天工」，同时宣布启动邀请测试。「天工」用过通过自然语言与用户进行问答式交互，AI 生成能力可满足文案创作、知识问答、代码编程、逻辑推演、数理推算等多元化需求。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 5 月 19 日，北京市经济和信息化局公布第一批《北京市通用人工智能产业创新伙伴计划成员名单》。昆仑万维凭借在 AIGC 领域的前沿探索和投资布局，成为第一批模型伙伴和投资伙伴。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 8 月 23 日，昆仑万维推出国内第一款 AI 搜索产品——「天工 AI 搜索」，并开启内测申请。「天工 AI 搜索」深度融合 AI 大模型能力，通过人性化、智能化的方式全面提升用户的搜索体验，为用户提供快速、可靠的交互式搜索服务，并集成 AI 对话、AI 写作等常用功能，帮助用户提升工作效率，全面重塑中文搜索体验。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月，昆仑万维多模态大模型 Skywork-MM 在腾讯优图实验室联合厦门大学开展的多模态大语言模型测评 MME 中，综合得分排名第一。该评测首次对全球范围内 MLLM 模型进行了全面定量评测并公布了 16 个排行榜，包含感知、认知两个总榜单以及 14 个子榜单。Skywork-MM 模型位列综合榜单第一，其中，感知榜单排名第一、认知榜单排名第二。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 16 日，在权威推理榜单 Benchmark GSM8K 测试中，昆仑万维「天工」大模型以 80% 的正确率脱颖而出，大幅领先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%），这标志着天工的推理能力达到全球领先，接近 GPT-4。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 17 日，昆仑万维通过信通院「可信 AI」评估，并被评选为人工智能实验室副组长单位。经中国信通院评估，昆仑万维天工大模型符合 AIIA/PG 0071-2023、AIIA/PG 0072-2023 评估标准，模型开发、以及模型能力均达到了「4+级」。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>10 月 30 日，昆仑万维开源百亿级大语言模型「天工」Skywork-13B 系列，并配套开源了 600GB、150B Tokens 的超大高质量开源中文数据集。「天工」Skywork-13B 系列目前包括 130 亿参数的两大模型，Skywork-13B-Base 模型、Skywork-13B-Math 模型，它们在 CEVAL、GSM8K 等多个权威评测与基准测试上都展现了同等规模模型的最佳效果，其中文能力尤为出色，在中文科技、金融、政务等领域表现均高于其他开源模型。同时，昆仑万维「天工」Skywork-13B 系列大模型全面开</span></span><span><span>放商用——开发者无需申请，即可商用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>一直以来，昆仑万维致力于在</span></span><span><span>AIGC 模型算法方面的技术创新和开拓，致力于降低 AIGC 技术在各行各业的使用和学习门槛。通过《生成式人工智能服务管理暂行办法》备案后，昆仑万维将面向全社会开放 AI 服务，持续推动天工大模型及 AIGC 业务迈向新高度，提高多款生成式 AI 产品的用户体验，探索未知世界、创造美好未来。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265122</guid>
            <link>https://www.oschina.net/news/265122</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[国内最大开源模型发布，650 亿参数无条件免费商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">元象 XVERSE 公司宣布开源 650 亿参数高性能通用大模型 XVERSE-65B，无条件免费商用。</span></p><p><span style="color:#000000">XVERSE-65B 采用了 Transformer 网络结构，模型通过训练了 2.6 万亿个令牌的高质量多样化数据，包含了 40 多种语言。具有 16K 的上下文长度，适用于多轮对话、知识问答和摘要等任务。</span></p><p><span style="color:#000000">主要特点如下:</span></p><ul><li><span style="color:#000000"><strong>模型结构</strong>：XVERSE-65B 使用主流 Decoder-only 的标准 Transformer 网络结构，支持 16K 的上下文长度（Context Length），能满足更长的多轮对话、知识问答与摘要等需求，模型应用场景更广泛。</span></li><li><span style="color:#000000"><strong>训练数据</strong>：构建了 2.6 万亿 token 的高质量、多样化的数据对模型进行充分训练，包含中、英、俄、西等 40 多种语言，通过精细化设置不同类型数据的采样比例，使得中英两种语言表现优异，也能兼顾其他语言效果。</span></li><li><span style="color:#000000"><strong>分词</strong>：基于 BPE（Byte-Pair Encoding）算法，使用上百 GB 语料训练了一个词表大小为 100,534 的分词器，能够同时支持多语言，而无需额外扩展词表。</span></li><li><span style="color:#000000"><strong>训练框架</strong>：训练中采用 FlashAttention2 加速计算，3D 并行基础上采用虚拟流水线（virtual pipeline）技术，降低较长流水线和 16k 上下文窗口产生的过高气泡率，在千卡集群的峰值算力利用率达到业界前列。同时通过集群基础设施运营、资源调度、训练框架和调度平台协同等持续优化，打造出高稳定、低中断、强容错的训练系统，将每周有效训练率提升至 98.6%。</span></li></ul><p><span style="color:#000000"><strong>评测结果</strong></span></p><p><span style="color:#000000"><img height="454" src="https://oscimg.oschina.net/oscnet/up-2cd1eb2bb0579c1ae7d9b7cdba455e38df6.png" width="500" referrerpolicy="no-referrer">&nbsp;</span></p><blockquote><p><span style="color:#000000">元象 XVERSE 于 2021 年初在深圳成立，主营 AI 与 3D 技术，创始人姚星是前腾讯副总裁和腾讯 AI Lab 创始人。该公司目前累计融资金额超过 2 亿美元，投资机构包括腾讯、高榕资本、五源资本、高瓴创投、红杉中国、淡马锡和 CPE 源峰等。</span></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265120</guid>
            <link>https://www.oschina.net/news/265120</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[从科幻走向现实，LLM Agent 做到哪一步了？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LLM 洪流滚滚，AI 浪潮席卷全球，在这不断冲击行业认知的一年中，Agent 以冉冉新星之态引起开发者侧目。OpenAI 科学家 Andrej Karpathy 曾言「OpenAI 在大模型领域快人一步，但在 Agent 领域，却是和大家处在同一起跑线上。」</p><p>在此背景下，AI 从业者坚信：基于 LLM 的 Agent 会是一个崭新并且充满着机会的蓝海领域。</p><p>那么，究竟什么是 Agent？它的框架工作方式是什么？现阶段存在哪些问题？未来有着怎样的可能性？本文将分享一些思考。</p><h2>01.什么是 Agent？</h2><p><img src="https://oscimg.oschina.net/oscnet/up-1f337817172f1c53b43dbdb7e958d8fe1a8.png" alt="" referrerpolicy="no-referrer"></p><p>根据 OpenAI 科学家 Lilian Weng 的一张 Agent 示意图 [1] 我们可以了解 Agent 由一些组件来组成。</p><h3>规划模块</h3><ul><li><p>子目标分解：Agent 将目标分为更小的、易于管理的子目标，从而更高效地处理复杂的任务。</p></li><li><p>反省和调整：Agent 可以对过去的行为进行自我批评和自我反思，从错误中吸取教训，并针对未来的步骤进行完善，从而提高最终结果的质量。</p></li></ul><h3>记忆模块</h3><ul><li><p>短期记忆：在这里通常是指 in-context learning，即利用提示工程来让模型进行一定的学习。</p></li><li><p>长期记忆：这为 Agent 提供了长时间保留和召回信息的能力，通常是通过利用外部向量存储和快速检索。</p></li></ul><h3>工具使用模块</h3><p>代理学习调用外部 API 来获取模型权重中缺失的额外信息（通常在预训练后很难更改），包括当前信息、代码执行能力、对专有信息源的访问等。</p><p>所以当 Agent 接收到一个处理复杂任务的目标时，它会首先进行任务的拆解，并去执行子任务，每次大模型调用之间通过短期记忆连接，使得大模型能理解当前任务处理的状态。接下来 Agent 需要根据任务的状态来获取能够帮助模型处理任务的信息，这些信息可以是历史信息以及与任务有关的额外信息。</p><p>由于大模型拥有一定的认知能力，所以在无法精准定义所需信息的情况下，我们可以将与当前状态有相关性的信息组织起来，让大模型自主地去摘取它需要的内容。所以，比起基于关键字精准的匹配的搜索方法，向量数据库所拥有的根据语义相关性的模糊搜索在这一点上受到了 Agent 框架的广泛青睐。通过将长期记忆存放在一个数据库（向量数据库或传统数据库），并且在执行过程中根据需要进行检索，模型能够在任务的执行中获取执行经验以及认识到总体的状态。</p><h2>02.Agent 框架工作方式</h2><p>我们以 AutoGPT 为例，看看一个 Agent 框架具体是如何工作的：</p><p><img src="https://oscimg.oschina.net/oscnet/up-0eb6a67673ebe44e8085f325471e525612a.png" alt="" referrerpolicy="no-referrer"></p><p>AutoGPT[2] 使用 GPT-4 来生成任务、确定优先级并执行任务，同时使用插件进行互联网浏览和其他访问。AutoGPT 使用外部记忆来跟踪它正在做什么并提供上下文，使其能够评估其情况，生成新任务或自我纠正，并将新任务添加到队列中，然后对其进行优先级排序。</p><p>另一个著名的项目 babyagi[3] 也是采取类似工作的方式。Agent 与一般的 LLM 最大的不同点在于，LLM Agent 通常根据任务的总体目标来去指定以及编排子目标，而 LLM 通常是作为一个被调用的工具，在一个工作流中担任一个具体任务的执行者。</p><h2>03.LLM Agent 现阶段出现的问题</h2><p>由于一些 LLM（GPT-4）带来了惊人的自然语言理解和生成能力，并且能处理非常复杂的任务，一度让 LLM Agent 成为满足人们对科幻电影所有憧憬的最终答案。但是在实际使用过程中，大家逐渐发现了通往通用人工智能的道路并不是一蹴而就的，目前 Agent 很容易在一些情况下失败：</p><ul><li><p>Agent 会在处理某一个任务上陷入一个循环</p></li><li><p>prompt 越来越长，最终甚至超出最大内容长度</p></li><li><p>记忆模块的策略没有给 LLM 某些关键的信息而导致执行失败</p></li><li><p>LLM 由于幻觉问题错误使用工具，或者让事情半途而废</p></li></ul><p>上述问题随着大家对于 Agent 的了解开始浮出水面，这些问题一部分需要 LLM 自身来解决，另一部分也需要 Agent 框架来进行解决，通用的 Agent 仍需进一步打磨。</p><h2>04.Agent 的展望</h2><p>目前，LLM Agent 大多是处于实验和概念验证的阶段，持续提升 Agent 的能力才能让它真正从科幻走向现实。当然，我们也可以看到，围绕 LLM Agent 的生态也已经开始逐渐丰富，大部分工作都可以归类到以下三个方面进行探索：</p><h3>Agent 模型</h3><p>AgentBench[4] 指出了不同的 LLM 对于 Agent 的处理能力有很大区别，当前的 gpt-4（0613）版本以极大的优势领先于同类竞品，LLM 本身的逻辑推理能力以及更长的 prompt 处理能力都会是 Agent 中极其重要的因素。</p><p>sToolLLM[5] 则使用轻量级的 LLaMA 向更加复杂的大模型学习理解 API 和使用 API 的能力，希望能够将这种能力运用在更轻量的模型上。</p><h3>Agent 框架</h3><p>由 Lilian Weng 列出来的每一个组件都有探索的空间，目前学术探索较多的是利用框架提升 LLM 推理的能力，从 COT[6]、ReAct[7]、Reflexion[8] 等一系列方法，都是在不改变大模型的方法下，利用 prompt 去提升大模型的理性。关于记忆和搜索，目前普遍是将内容存储在数据库和搜索引擎中，Refexion 认为可以将执行过程中的观察以轨迹的形式存储在短期记忆中，而将接受反馈后的评估和自我反省总结的经验放在长期记忆中。在其他方向，AutoGen[9] 也在探索多智能体之间的通信与协作。</p><h3>Agent 应用</h3><p>实现真正意义上的 Agent 道阻且长，因为现实世界具有太多不确定性。在特定、具体的可控环境下，Agent 便可以如工厂中实现一道道供需的机器人一般，针对更多的场景特点进行针对性的设计，从而更好的去完成一些特定的任务，达到预期的效果。</p><p>MetaGPT[10] 是一个针对软件开发场景的 Agent，针对这一具体场景设计了各种具有不同技能的角色协作完成这一任务。Voyager[11] 是一个可以在 Minecraft 中可以进行自主探索、学习技能，并且会合成道具的 Agent。VoxPoser 结合了 RGB-D 信息以及 LLM 的推理能力后，可以完成更多复杂的机器人抓取操作。当下，Agent 尚不能做到完全可靠，针对更多场景的设计可以保障 Agent 不会在大部分简单场景下失败。</p><p>我们置身于一个充满无限可能性的时刻，人工智能的进步将继续塑造我们的未来，而 LLM Agent 无疑是这一演进过程中的亮点之一。人们探索人工智能，最终还是希望能够让人工智帮助人类完成自己无法做到的复杂任务，而 Agent 恰恰是从自动化走向智能化的一个关键的里程碑……</p><h3>参考链接</h3><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flilianweng.github.io%2F" target="_blank">https://lilianweng.github.io/</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSignificant-Gravitas%2FAuto-GPT" target="_blank">https://github.com/Significant-Gravitas/Auto-GPT</a></p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyoheinakajima%2Fbabyagi" target="_blank">https://github.com/yoheinakajima/babyagi</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.03688" target="_blank">https://arxiv.org/abs/2308.03688</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.16789" target="_blank">https://arxiv.org/abs/2307.16789</a></p><p>[6]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2201.11903" target="_blank">https://arxiv.org/abs/2201.11903</a></p><p>[7]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a></p><p>[8]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2303.11366" target="_blank">https://arxiv.org/abs/2303.11366</a></p><p>[9]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.08155" target="_blank">https://arxiv.org/abs/2308.08155</a></p><p>[10]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.00352" target="_blank">https://arxiv.org/abs/2308.00352</a></p><p>[11]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.16291" target="_blank">https://arxiv.org/abs/2305.16291</a></p><p>[12]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.05973" target="_blank">https://arxiv.org/abs/2307.05973</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10140821</guid>
            <link>https://my.oschina.net/u/4209276/blog/10140821</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🎁有奖问答 | 程序员如何入门大数据]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4855753_2331281">高手问答第 308 期 —— 程序员如何入门大数据？</a><div class="ui red label horizontal" data-tooltip="置顶">顶</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4855753" class="__user"><span>OSC 哒哒</span></a><span class="org-label org-label--simple primary" data-tooltip="认证官方账号"><i class="oicon oicon-org"></i></span> 发布于 10/31 12:14
                    </div><div class="item">阅读 2K+</div><div class="item collect-btn " data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331281" data-obj-type="2">6</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4855753_2331281#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">7</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手问答</a></div><div class="content" id="articleContent"><div><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>市面上不少公司都在做用户画像的相关工作，无论是电商行业、金融行业、视频行业等等，都有这样的产品。那到底怎么去定义用户画像呢？</span></span></span></span></span></span></span></span></span></span></span></div><div>
  &nbsp; 
</div><div><strong>OSCHINA 本期高手问答 (10 月 31 日 - 11 月 6 日) 我们请来</strong><strong>了嘉宾&nbsp;</strong><strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">诸葛子房</a>老师&nbsp;</span></strong><strong>来和大家一起探讨关于从 0 到 1 入门用户画像掌握大数据技术的问题。</strong></div><div>
  &nbsp; 
</div><div><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>可讨论的问题包括但不限于：</span></span></span></span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>想入门用户画像需要掌握哪些技术栈？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>没有企业的大量用户或者行为数据，普通用户该如何真实地模拟企业级的画像项目？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>程序员如何入门大数据？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大数据</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>行业都有哪些职位，以及在公司中发挥的作用如何</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大数据行业未来的发展如何，以 ChatGPT&nbsp;为代表的 AI 浪潮是否会让大数据行业走向</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>没落</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li></ul><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>有其他相关问题，也欢迎大家积极提问！</span></span></span></span></span></span></span></span></span></span></span></p><hr><h2>嘉宾介绍</h2><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>段小秋，网名：诸葛子房，先后就职于京东和 BAT，在大数据领域有多年工作经验，也是多个 Apache&nbsp;项目的贡献者。蓝桥杯蓝桥云课《用户画像案例精讲》专栏作者，也是开源项目 DataCompare&nbsp;作者。</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>微信</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>：zhugezifang001，欢迎交流沟通。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>个人</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>主页：</span></span></span></span></span></span></span></span><a href="https://gitee.com/ZhuGeZiFang" rel="nofollow"><span><span><span><u><span style="color:#1e6fff"><span><span>https://gitee.com/ZhuGeZiFang</span></span></span></u></span></span></span></a></span></span></span></p><p><img height="639" src="https://oscimg.oschina.net/oscnet/up-5e58f5cf142af8e6ec1a3b8c3dc1cef16ec.png" width="500" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>为了鼓励踊跃提问，会在问答结束后从提问者中抽取 2 名幸运会员赠予《</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户画像案例精讲》专栏电子版！</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="516" src="https://oscimg.oschina.net/oscnet/up-71771b786f7cc1bd0161793b6af70daf066.png" width="310" referrerpolicy="no-referrer"></p><p><img height="574" src="https://oscimg.oschina.net/oscnet/up-c2d9d9ce8dd66a412d3ef791ee45548dc45.png" width="311" referrerpolicy="no-referrer"></p></div><div><div><hr><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户</span></span></span></span></strong></span></span></span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>画像概念</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户画像，即：用标签的方式去描述一个人或者一台手机、一台电脑，有些公司称之为」用户画像「，有一些公司称之为」用户特征「，其实是一个意思。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>举个简单的例子：</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>袁小青，性别：女，年龄：22 岁，职业：时尚编辑，爱好：音乐、拍照，居住地：北京，消费情况：年薪 10w，喜欢的 app：抖音</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="310" src="https://oscimg.oschina.net/oscnet/up-d3e2ad6f2150ece5dd0882380562cb797a7.png" width="488" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>因此我们概念中描述的用户画像，其实是用标签的方式对于一个用户、一个账号、一部手机进行描述。</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="368" src="https://oscimg.oschina.net/oscnet/up-adc4c1c21829279233af14e8d74631dfab4.png" width="400" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户画像常见标签</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>既然上面讲到了对于用户进行标签化，那究竟要给用户打哪些标签呢？如何对标签进行分类呢？</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用户</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>画像核心标签以及其分类：</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="589" src="https://oscimg.oschina.net/oscnet/up-9efa6c4c17cb0bd2647c8d303db9def85cc.png" width="868" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用户画像的作用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>1. 个性化推荐</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>在使用一些社区产品、电商产品、短视频 app、音乐 app 的时候，经常会遇到推荐的场景，根据不同的人推荐不同的内容或者商品。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>这其实是用户画像其中的一个应用，根据用户查询用户的标签数据，来进行推荐用户感兴趣的内容</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>2. 营销圈选 (短信营销、PUSH 营销)</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>相信不少用户收到过类似的营销短信，或者一些 app&nbsp;弹窗，这个也是用户画像常见的应用场景</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>3. 策略引擎</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>根据用户的标签展示不同页面，比如说：北京地区的用户能才能领取北京的优惠券，以及只有高消费值的用户才有淘宝上奢侈品 Luxury 入口的界面。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>4. 算法模型</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>算法模型的训练，比如说：推荐模型、广告模型，需要用到画像数据来优化推荐模型。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>5. 画像报告</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>不少商业公司会出一些行业报告，比如说下图的小红书、锁屏 app&nbsp;的行业画像报告；还有我们经常看到的一些个人年度榜单。</span></span></span></span></span></span></span></span></span></span></span></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>大数据技术在用户画像中的实际应用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>由于</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>画像涉及到的一些行为数据，包括用户购物行为、观影行为，一些较为大型一些的公司数据日均都涉及 PB，因此需要处理的数据量非常大。在其中就会用到一些大数据的处理和存储技术，比如说：Hadoop、Spark、Hbase&nbsp;等等。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>同时随着业务发展，一些广告和推荐场景对于实时需求也更加明显，所以实时数据处理领域，Flink、Kafka 等实时相关技术领域也越来越重要了。</span></span></span></span></span></span></span></span></span></span></span></p><hr><div><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手问答一贯的风格，不欢迎任何与主题无关的讨论和喷子。</span></p><p>下面欢迎大家就<span>用户画像和大数据技术相关</span>问题向&nbsp;<strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">诸葛子房</a></span></strong><span style="color:#000000">老师</span><strong><span style="color:#000000">&nbsp;</span></strong>提问，直接回帖提问既可。</p></div></div></div></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331281" data-obj-type="2">6</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331281" data-obj-type="2" data-url="https://www.oschina.net/question/4855753_2331281"><i class="flag red icon"></i>举报</a></div></div>
            ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4855753_2331281</guid>
            <link>https://www.oschina.net/question/4855753_2331281</link>
        </item>
        <item>
            <title>
                <![CDATA[昆仑万维「天工」大模型正式向全社会开放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 11 月 3 日，昆仑万维「天工」大模型宣布通过《生成式人工智能服务管理暂行办法》备案，面向全社会开放服务！</p><p>用户在应用商店下载「天工 APP」或登陆「天工官网」（<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.tiangong.cn" target="_blank">www.tiangong.cn</a>）均可直接注册使用。</p><p>官方介绍称，「天工」是国内首个对标 ChatGPT 的双千亿级大语言模型，也是一个 AI 搜索引擎，一个对话式 AI 助手。「天工」拥有强大的自然语言处理和智能交互能力，能够实现个性化 AI 搜索、智能问答、聊天互动、文本生成、编写代码、语言翻译等多种应用场景，并且具有丰富的知识储备，涵盖科学、技术、文化、艺术、历史等领域。</p><p><img height="232" src="https://oscimg.oschina.net/oscnet/up-4220721cc203df8b9704c1aa7e7fb303f00.png" width="500" referrerpolicy="no-referrer"></p><p>2022 年 12 月 15 日，昆仑万维在北京举行 AIGC 技术发布会，发布自研 AIGC 全系列算法与模型，覆盖了图像、音乐、文本、编程等多模态的 AI 内容生成能力。</p><p>2023 年 4 月 17 日，昆仑万维正式发布自研千亿级大语言模型「天工」，同时宣布启动邀请测试。「天工」用过通过自然语言与用户进行问答式交互，AI 生成能力可满足文案创作、知识问答、代码编程、逻辑推演、数理推算等多元化需求。</p><p>2023 年 5 月 19 日，北京市经济和信息化局公布第一批《北京市通用人工智能产业创新伙伴计划成员名单》。昆仑万维成为第一批模型伙伴和投资伙伴。</p><p>2023 年 8 月 23 日，昆仑万维推出国内第一款 AI 搜索产品——「天工 AI 搜索」，并开启内测申请。「天工 AI 搜索」深度融合 AI 大模型能力，通过人性化、智能化的方式全面提升用户的搜索体验，为用户提供快速、可靠的交互式搜索服务，并集成 AI 对话、AI 写作等常用功能，帮助用户提升工作效率，全面重塑中文搜索体验。</p><p>2023 年 9 月，昆仑万维多模态大模型 Skywork-MM 在腾讯优图实验室联合厦门大学开展的多模态大语言模型测评 MME 中，综合得分排名第一。该评测首次对全球范围内 MLLM 模型进行了全面定量评测并公布了 16 个排行榜，包含感知、认知两个总榜单以及 14 个子榜单。Skywork-MM 模型位列综合榜单第一，其中，感知榜单排名第一、认知榜单排名第二。</p><p>2023 年 9 月 16 日，在权威推理榜单 Benchmark GSM8K 测试中，昆仑万维「天工」大模型以 80% 的正确率脱颖而出，大幅领先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%）。</p><p>2023 年 9 月 17 日，昆仑万维通过信通院「可信 AI」评估，并被评选为人工智能实验室副组长单位。经中国信通院评估，昆仑万维天工大模型符合 AIIA/PG 0071-2023、AIIA/PG 0072-2023 评估标准，模型开发、以及模型能力均达到了「4+级」。</p><p>10 月 30 日，昆仑万维开源百亿级大语言模型「天工」Skywork-13B 系列，并配套开源了 600GB、150B Tokens 的超大高质量开源中文数据集。「天工」Skywork-13B 系列目前包括 130 亿参数的两大模型，Skywork-13B-Base 模型、Skywork-13B-Math 模型，它们在 CEVAL、GSM8K 等多个权威评测与基准测试上都展现了同等规模模型的最佳效果，其中文能力尤为出色，在中文科技、金融、政务等领域表现均高于其他开源模型。同时，昆仑万维「天工」Skywork-13B 系列大模型全面开放商用——开发者无需申请，即可商用。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264987</guid>
            <link>https://www.oschina.net/news/264987</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[WinterJS —— Rust 编写的 Service Worker]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>WinterJS 是用 Rust 编写的 JavaScript Service Worker。</p><p>WinterJS 使用 SpiderMonkey 运行时执行 JavaScript（与 Firefox 使用的运行时相同），并遵循 WinterCG 规范，目的是最大限度地兼容 Cloudflare Workers、Deno Deploy 和 Vercel 等其他服务（因此命名为 WinterJS）。</p><p>WinterJS 除了速度极快，还能通过 WASIX&nbsp;<strong>编译成 WebAssembly</strong>，因此完全支持在 Wasmer 上运行。</p></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/winterjs</guid>
            <link>https://www.oschina.net/p/winterjs</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 基于连接的可扩展消息传输协议 SocketD]]>
            </title>
            <description>
                <![CDATA[<h1 align="center"><a id="user-content---socketd" class="anchor" href="https://gitee.com/noear/socketd#--socketd"></a>
  SocketD
</h1><p align="center"><strong>基于连接的可扩展消息传输协议</strong></p><p align="center"><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fsearch.maven.org%2Fartifact%2Forg.noear%2Fsocketd"><img src="https://img.shields.io/maven-central/v/org.noear/socketd.svg?label=Maven%20Central" alt="Maven" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.apache.org%2Flicenses%2FLICENSE-2.0.txt"><img src="https://img.shields.io/:license-Apache2-blue.svg" alt="Apache 2" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjavase-jdk8-downloads.html"><img src="https://img.shields.io/badge/JDK-8-green.svg" alt="jdk-8" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk11-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-11-green.svg" alt="jdk-11" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk17-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-17-green.svg" alt="jdk-17" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk21-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-21-green.svg" alt="jdk-21" referrerpolicy="no-referrer"></a><br><a target="_blank" href="https://gitee.com/noear/socketd/stargazers"><img src="https://gitee.com/noear/socketd/badge/star.svg" alt="gitee star" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fnoear%2Fsocketd%2Fstargazers"><img src="https://img.shields.io/github/stars/noear/socketd.svg?logo=github" alt="github star" referrerpolicy="no-referrer"></a></p><br><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DkjB5JNiC"><img src="https://img.shields.io/badge/QQ%E4%BA%A4%E6%B5%81%E7%BE%A4-870505482-orange" referrerpolicy="no-referrer"></a></p><hr><p>SocketD 是一个基于连接的、可扩展的、主题消息驱动的传输协议。主要特性有：</p><ul><li>异步通讯，非阻塞，由主题消息驱动</li><li>语言无关，二进制通信协议（支持 tcp, ws, udp）。支持多语言、多平台</li><li>背压流控，请求时不让你把服务端发死了</li><li>断线重连，自动连接恢复</li><li>双向通讯，单链接双向互发双向互听</li><li>多路复用</li><li>自动分片，数据超出 16Mb，会自动分片、自动重组（udp 除外）</li><li>扩展定制，可以为数据添加 meta 标注（就像 http header）</li><li>接口简单</li></ul><h3><a id="user-content-快速入门与学习" class="anchor" href="https://gitee.com/noear/socketd#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AD%A6%E4%B9%A0"></a>快速入门与学习</h3><p>请点击：<a href="https://gitee.com/noear/socketd/blob/main/_docs">《快速入门与学习》</a>。Java 之外的语言与平台会尽快跟进（欢迎有兴趣的同学加入社区）</p><h3><a id="user-content-适用场景" class="anchor" href="https://gitee.com/noear/socketd#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"></a>适用场景</h3><p>可用于 MSG、RPC、IM、MQ 等一些的场景开发，可替代 Http, Websocket, gRpc 等一些协议。比如移动设备与服务器的连接，比如一些微服务场景等等。</p><h3><a id="user-content-简单的协议" class="anchor" href="https://gitee.com/noear/socketd#%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%8F%E8%AE%AE"></a>简单的协议</h3><ul><li>link (url style)</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">tcp://19.10.2.3:9812/path?u=noear&amp;t=1234</span><span id="LC2" class="line">udp://19.10.2.3:9812/path?u=noear&amp;t=1234</span><span id="LC3" class="line">ws://19.10.2.3:1023/path?u=noear&amp;t=1234</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>codec</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">//udp only &lt;2k, and no auto fragments</span><span id="LC2" class="line">[len:int][flag:int][sid:str(&lt;64)][\n][topic:str(&lt;512)][\n][metaString:str(&lt;4k)][\n][data:byte(&lt;16m)]</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>flag &amp; flow</li></ul><table><thead><tr><th>Flag</th><th>Server</th><th>Client</th></tr></thead><tbody><tr><td>Unknown</td><td>::close()</td><td>::close()</td></tr><tr><td>Connect</td><td>/</td><td>c(Connect)-&gt;s::onOpen(),s(Connack)-&gt;c::onOpen()</td></tr><tr><td>Connack</td><td>s::onOpen(),s(Connack)-&gt;c</td><td>/</td></tr><tr><td>Ping</td><td>/</td><td>c(Ping)-&gt;s(Pong)-&gt;c</td></tr><tr><td>Pong</td><td>s(Pong)-&gt;c</td><td>/</td></tr><tr><td>Message</td><td>s(Message)-&gt;c</td><td>c(Message)-&gt;s</td></tr><tr><td>Request</td><td>s(Request)-&gt;c(Reply or ReplyEnd)-&gt;s</td><td>c(Request)-&gt;s(Reply or ReplyEnd)-&gt;c</td></tr><tr><td>Subscribe</td><td>s(Subscribe)-&gt;c(Reply...ReplyEnd)-&gt;s</td><td>c(Subscribe)-&gt;s(Reply...ReplyEnd)-&gt;c</td></tr><tr><td>Reply</td><td>-&gt;s(Reply)-&gt;c</td><td>-&gt;c(Reply)-&gt;s</td></tr><tr><td>ReplyEnd</td><td>-&gt;s(ReplyEnd)-&gt;c</td><td>-&gt;c(ReplyEnd)-&gt;s</td></tr></tbody></table><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">//The reply acceptor registration in the channel is removed after the reply is completed</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-加入到交流群" class="anchor" href="https://gitee.com/noear/socketd#%E5%8A%A0%E5%85%A5%E5%88%B0%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>加入到交流群：</h3><table><thead><tr><th>QQ 交流群：870505482</th><th>微信交流群（申请时输入：SocketD）</th></tr></thead><tbody><tr><td></td><td><img src="https://gitee.com/noear/socketd/raw/main/group_wx.png" width="120" referrerpolicy="no-referrer"></td></tr></tbody></table><p>交流群里，会提供 "保姆级" 支持和帮助。如有需要，也可提供技术培训和顾问服务</p><h3><a id="user-content-第一个程序你好世界" class="anchor" href="https://gitee.com/noear/socketd#%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E4%BD%A0%E5%A5%BD%E4%B8%96%E7%95%8C"></a>第一个程序：你好世界！</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">public</span><span class="kd">class</span><span class="nc">Demo</span><span class="o">{</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kd">static</span><span class="kt">void</span><span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span><span class="n">args</span><span class="o">)</span><span class="kd">throws</span><span class="nc">Throwable</span><span class="o">{</span></span><span id="LC3" class="line"><span class="c1">//::启动服务端</span></span><span id="LC4" class="line"><span class="nc">SocketD</span><span class="o">.</span><span class="na">createServer</span><span class="o">(</span><span class="k">new</span><span class="nc">ServerConfig</span><span class="o">(</span><span class="s">"tcp"</span><span class="o">).</span><span class="na">port</span><span class="o">(</span><span class="mi">8602</span><span class="o">))</span></span><span id="LC5" class="line"><span class="o">.</span><span class="na">listen</span><span class="o">(</span><span class="k">new</span><span class="nc">SimpleListener</span><span class="o">(){</span></span><span id="LC6" class="line"><span class="nd">@Override</span></span><span id="LC7" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">onMessage</span><span class="o">(</span><span class="nc">Session</span><span class="n">session</span><span class="o">,</span><span class="nc">Message</span><span class="n">message</span><span class="o">)</span><span class="kd">throws</span><span class="nc">IOException</span><span class="o">{</span></span><span id="LC8" class="line"><span class="k">if</span><span class="o">(</span><span class="n">message</span><span class="o">.</span><span class="na">isRequest</span><span class="o">()){</span></span><span id="LC9" class="line"><span class="n">session</span><span class="o">.</span><span class="na">replyEnd</span><span class="o">(</span><span class="n">message</span><span class="o">,</span><span class="k">new</span><span class="nc">StringEntity</span><span class="o">(</span><span class="s">"And you too."</span><span class="o">));</span></span><span id="LC10" class="line"><span class="o">}</span></span><span id="LC11" class="line"><span class="o">}</span></span><span id="LC12" class="line"><span class="o">})</span></span><span id="LC13" class="line"><span class="o">.</span><span class="na">start</span><span class="o">();</span></span><span id="LC14" class="line"></span><span id="LC15" class="line"><span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span><span class="c1">//等会儿，确保服务端启动完成</span></span><span id="LC16" class="line"></span><span id="LC17" class="line"><span class="c1">//::打开客户端会话</span></span><span id="LC18" class="line"><span class="nc">Session</span><span class="n">session</span><span class="o">=</span><span class="nc">SocketD</span><span class="o">.</span><span class="na">createClient</span><span class="o">(</span><span class="s">"tcp://127.0.0.1:8602/hello?token=1b0VsGusEkddgr3d"</span><span class="o">)</span></span><span id="LC19" class="line"><span class="o">.</span><span class="na">open</span><span class="o">();</span></span><span id="LC20" class="line"></span><span id="LC21" class="line"><span class="c1">//发送并请求（且，收回答复）</span></span><span id="LC22" class="line"><span class="nc">Entity</span><span class="n">reply</span><span class="o">=</span><span class="n">session</span><span class="o">.</span><span class="na">sendAndRequest</span><span class="o">(</span><span class="s">"/demo"</span><span class="o">,</span><span class="k">new</span><span class="nc">StringEntity</span><span class="o">(</span><span class="s">"Hello wrold!"</span><span class="o">).</span><span class="na">meta</span><span class="o">(</span><span class="s">"user"</span><span class="o">,</span><span class="s">"noear"</span><span class="o">));</span></span><span id="LC23" class="line"><span class="o">}</span></span><span id="LC24" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 02:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/noear/socketd</guid>
            <link>https://gitee.com/noear/socketd</link>
        </item>
        <item>
            <title>
                <![CDATA[OpenELA 公开发布 Enterprise Linux 源代码]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000">Open Enterprise Linux Association (OpenELA)</span><span style="color:#000000"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenela.org%2Fnews%2F2023.11.02-governance_and_code_availability%2F" target="_blank">宣布</a>公开发布 Enterprise Linux (EL) 源代码并成立技术指导委员会。</span></p><blockquote><p><span style="color:#000000">「OpenELA 很高兴地宣布，现在所有人都可以获取构建衍生&nbsp;Enterprise Linux 操作系统所需的全部源代码包。初步侧重点在于 EL8 和 EL9，EL7 的软件包也即将推出。该项目致力于确保向社区无限期提供 EL 源代码。」</span></p></blockquote><p><img alt="" height="381" src="https://oscimg.oschina.net/oscnet/up-08878f094d1e8bcafadeca1ea19e8f93ccc.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenELA 是在今年 8 月份，由甲骨文、SUSE 和 CIQ (Rocky Linux 背后的商业实体) 联合组建的一个开源企业 Linux 发行版开发商的行业协会；旨在通过提供开放和免费的 Enterprise Linux 源代码，鼓励<span style="background-color:#ffffff">与 Red Hat Enterprise Linux (RHEL) 兼容的发行版的开发和协作</span>。</span><span style="background-color:#ffffff; color:#000000">OpenELA 的形成源于红帽</span><a href="https://www.oschina.net/news/246331/red-hat-centos-stream-sources">对 RHEL 源代码可用性的更改</a><span style="background-color:#ffffff; color:#000000">。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Oracle、SUSE 和 CIQ&nbsp;方面都表达了对这一进展的喜悦之情。CIQ 首席执行官兼 Rocky Linux 创始人 Gregory Kurtzer 发言称：</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「几十年来，各组织都在 CentOS 上进行标准化，因为它是免费的，遵循 Enterprise Linux 标准，并且得到许多供应商的大力支持。CentOS 停产后，不仅在生态系统中留下了一个巨大的漏洞，而且也清楚地表明了社区需要团结起来才能做得更好。OpenELA 正是这样的一个社区答案，它将确保所有专业 IT 部门和企业用例拥有一个协作和稳定的未来。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">AlmaLinux 尚未加入该协会。AlmaLinux 操作系统基金会主席 benny Vasquez 评论表示，「</span></span><span style="background-color:#ffffff; color:#000000">我总是很乐于看到一个新的非营利组织站稳脚跟并开始</span><span style="color:#000000"><span style="background-color:#ffffff">运作。不过我们目前还不会使用他们发布的代码，因为我们已经建立了自己的工作流程，不需要使用这些代码。」</span></span></p><p><span style="color:#000000">OpenELA&nbsp;已经<span style="background-color:#ffffff">完成了在美国特拉华州的非营利性非股份公司的注册，正在向美国国税局申请 501(c)(6) 免税资格。该公司表示，将为有兴趣支持开源企业 Linux 发行版开发目标和利益的利益相关者提供一个论坛。「创始公司认为，法律实体是对开源工作产生积极影响的基础性工具，可以统一开源工作的价值观，并确保与开源社区的适当接触。」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>相关阅读：</strong></span></p><ul><li style="text-align:start"><a href="https://www.oschina.net/news/253319/oracle-suse-ciq-openela" target="_blank">SUSE、甲骨文和 CIQ 组建 OpenELA：企业 Linux 源代码的社区存储库</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 04:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264995/openela-enterprise-linux-source</guid>
            <link>https://www.oschina.net/news/264995/openela-enterprise-linux-source</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
