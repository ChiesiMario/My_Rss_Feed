<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 08 Oct 2023 04:31:02 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Glibc 动态加载器存在严重本地提权漏洞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>近日有关 Glibc 动态加载器 (Dynamic Loader) 的一个严重漏洞被公开，<strong>攻击者获取本地用户 (local users) 身份后，利用该漏洞制造缓冲区溢出</strong>，<strong>即可获得完整 root 权限</strong>。</p><p>据介绍，攻击者使用由 ld.so 动态加载器制作的 GLIBC_TUNABLES 环境变量来触发漏洞，然后通过 SUID 权限安装文件时，能以 root 权限执行任意代码。</p><blockquote><p>Glibc 即 GNU C Library，是 GNU 系统以及大多数采用 Linux 内核的系统中的 C 运行库。Glibc 是 Linux 系统中最底层的 API，几乎其它任何运行库都会依赖于 Glibc。</p><p>它定义了典型程序所需的系统调用和其他基本功能，例如 open、malloc、printf、exit 等。 Glibc 的动态加载器是 glibc 的重要组成部分，负责准备和运行程序。当程序启动时，该加载器首先检查该程序以确定其所需的共享库。然后它搜索这些库，将它们加载到内存中，并在运行时将它们与可执行文件链接。</p><p>在此过程中，动态加载器解析符号引用，例如函数和变量引用，确保为程序的执行做好一切准备。鉴于其作用，动态加载器对安全性高度敏感，因为当本地用户启动 set-user-ID 或 set-group-ID 程序时，其代码会提权来运行。</p></blockquote><p>该漏洞最早<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.qualys.com%2Fvulnerabilities-threat-research%2F2023%2F10%2F03%2Fcve-2023-4911-looney-tunables-local-privilege-escalation-in-the-glibcs-ld-so" target="_blank">由 Qualys 报告</a></strong>，被命名为&nbsp;<strong>Looney Tunables</strong>，追踪编号为 CVE-2023-4911。据称过去两年发布的 Linux 发行版均受存在 Looney Tunables 漏洞 ，例如 Ubuntu 22.04 LTS、23.04、Fedora 38 以及其他容易受到此本地提权漏洞影响的发行版。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-25c8c90352d003a1c79ed3f79edbbd0bd55.png" referrerpolicy="no-referrer"></p><p>漏洞曝光后，独立安全研究员 Peter Geissler (blasty) 很快就发布了 PoC 代码，确认可以攻击 Linux 发行版。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9ef2f1befa040312fa6202ca9fe080882f7.png" referrerpolicy="no-referrer"></p><p>上文提到的 GLIBC_TUNABLES 环境变量旨在微调和优化与 glibc 相关的应用程序，是开发者和系统管理员的必备工具。它的滥用会广泛影响系统性能、可靠性和安全性。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 08 Oct 2023 03:49:57 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260786/glibc-ld-nasty-root-bug</guid>
            <link>https://www.oschina.net/news/260786/glibc-ld-nasty-root-bug</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[再添一员！Cutefish 桌面环境成功适配 openKylin]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">近日，在 openKylin 社区 Cutefish SIG 成员的努力下，openKylin 开源操作系统桌面环境又迎来一个新成员—</span><strong><span style="color:#000000">Cutefish</span></strong><span style="color:#000000">。这也是继 UKUI、KDE、Xfce 和 DDE 之后，openKylin 开源操作系统支持的第五个 Linux 桌面环境，为社区用户带来更多选择。</span></span></p><div><p style="text-align:center"><img alt="" height="921" src="https://oscimg.oschina.net/oscnet/up-e557c73aea5afb59e398f92bd116adde5c1.png" width="1637" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000"><span style="background-color:#f0f3ff">Cutefish 是一款简洁、美观、实用的桌面环境，为用户提供舒适的界面与优秀的用户体验，能够满足各种场景下的使用需求。</span></span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">除 X86 环境外，openKylin 社区 Cutefish SIG 也完成了 Cutefish 桌面环境对 openKylin 操作系统 ARM 架构板卡的适配。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-f2576a6dd2921f794fe704e744966b24dc3.jpg" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">同时，在赛昉科技和 RISC-V SIG 的帮助下，Cutefish SIG 成功将 Cutefish 桌面移植到 VisionFive2。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-48c1c00d01962014df6b292dc18001b4b32.jpg" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">截至目前，已完成 Cutefish 软件包的移植工作，并经 Cutefish SIG 成员测试可流畅运行桌面及其特色应用。欢迎大家在 openKylin 上安装和体验 Cutefish 桌面环境。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#2589fb">安装方式</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">1.添加每日构建源</span></strong></span></p><pre><code><span style="color:#114ba6">deb</span> http://archive.build.openkylin.top/openkylin yangtze-proposed main</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">2.更新源</span></strong></span></p><pre><code>sudo apt <span style="color:#114ba6">update</span> &amp;&amp; sudo apt <span style="color:#114ba6">upgrade</span></code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">3.搜查 Cutefish 软件包</span></strong></span></p><pre><code>sudo apt-<span style="color:#114ba6">cache</span><span style="color:#114ba6">search</span> cutefish</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">4.安装</span></strong></span></p><pre><code>sudo apt <span style="color:#114ba6">install</span> cutefish-core cutefish-dock cutefish-daemon 
cutefish-qt-plugins cutefish-calculator cutefish-debinstaller 
cutefish-filemanager cutefish-launcher cutefish-screenlocker 
cutefish-<span style="color:#114ba6">settings</span> cutefish-statusbar cutefish-terminal cutefish-videoplayer 
cutefish-wallpapers cutefish-<span style="color:#114ba6">cursor</span>-themes cutefish-gtk-themes 
cutefish-sddm-theme  fishui libcutefish</code></pre><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#000000">5.切换桌面</span></strong></span></p><div><p style="text-align:center"><img alt="" height="794" src="https://oscimg.oschina.net/oscnet/up-05f1ddfabb6c84942d02a3c851f48b47a92.png" width="1277" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#2589fb">关于 Cutefish SIG</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Cutefish 是一款简洁、美观、实用的桌面环境，Cutefish SIG 致力于维护 Cutefish 相关组件，如桌面、启动器、任务栏、控制中心、窗口管理器等，给 openKylin 提供美观易用的桌面环境。</span></span></p><ul><li><span><span style="color:#000000">SIG 主页：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/Cutefish</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260772</guid>
            <link>https://www.oschina.net/news/260772</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[SecZone 每日安全资讯（2023.10.08）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>环球动态<br> 1.Microsoft 将在 Windows 11 中引入密钥支持功能<br> 作为 Windows 11 重大更新的一部分，微软今天推出了密钥支持功能。用户将能使用设备 PIN 或生物识别信息登录网站和应用，而无需提供用户名和密码。【Microsoft is Rolling out Support for Passkeys in Windows 11 (thehackernews.com)】</p><p>2.黑客利用零点字体伪装成 Microsoft Outlook 诱骗显示虚假的 AV 扫描警报<br> 黑客正在利用零点字体在电子邮件中的新型技巧，使恶意邮件看起来像是 Microsoft Outlook 中的安全工具发出的扫描警报。这是首次记录到 ZeroFont 网络钓鱼技术以这种方式的使用。【针对 Microsoft 365 的钓鱼即服务平台 Greatness - FreeBuf 网络安全行业门户】</p><p>3. 谷歌为攻击中利用的 libwebp 漏洞分配了新的最高 CVE 编号<br> 谷歌已经为最近被攻击利用的 libwebp 安全漏洞分配了新的最高 CVE 编号（CVE-2023-5129）。这个零日漏洞在两周前修补过。【VMware Aria Operations for Networks 远程代码执行漏洞（CVE-2... - FreeBuf 网络安全行业门户】</p><p>4. 新的 AtlasCross 黑客冒充美国红十字会发送网络钓鱼诱饵<br> 「AtlasCross」新黑客组织冒充美国红十字会，针对有网络钓鱼诱饵的组织发送后门恶意软件。【Access denied | www.bleepingcomputer.com used Cloudflare to restrict access】</p><p>5. 苹果谷歌漏洞披露不充分，使腾讯 QQ 等数百万应用面临潜在风险<br> 安全研究员指出，苹果和谷歌近期披露的产品零日漏洞不完整，可能隐藏了一个上游开源库 libwebp 的漏洞，使腾讯 QQ 等数百万应用面临「巨大的盲点」，处于被攻击的危险之中。【苹果谷歌漏洞披露不完整，让腾讯 QQ 等数百万应用处于危险之中 - 安全内参 | 决策者的网络安全知识库 (secrss.com)】</p><p>6.科技巨头们联手成立了 PQC 联盟以推动量子密码学的应用<br> 微软、IBM Quantum、MITRE、PQShield、SandboxAQ 和滑铁卢大学等科技巨头联手启动了 PQC 联盟，旨在推动量子密码学在商业及开源领域的应用。Shor 算法作为构建所有非对称加密的基础，正受到量子计算的威胁。【Tech Giants Launch Post-Quantum Cryptography Coalition - Infosecurity Magazine (infosecurity-magazine.com)】</p><p>安全大爆料<br> 1. 加拿大的 Flair Airlines 公司在其用户数据保护方面存在严重问题<br> 根据 Cybernews 的研究团队的发现，加拿大的 Flair Airlines 公司在其用户数据保护方面存在着严重的问题。他们发现，该公司在处理敏感数据库和电子邮件地址凭据的过程中，竟然将它们保留了下来长达至少七个月的时间。这种情况无疑增加了乘客个人信息（如电子邮件、姓名或地址）被不法分子利用的风险。这不仅对乘客的个人隐私构成了威胁，也对他们的安全带来了潜在的风险。【Canadian Flair Airlines left user data leaking for months (securityaffairs.com)】</p><p>2. 科威特财政部遭.HYSIDA 勒索软件组织攻击<br> 财政部在今天黎明时分宣布，其一个系统遭到了恶意软件的黑客攻击。尽管系统和保护程序已经启动并停用，但该部仍在评估这次未遂黑客攻击的程度。此外，财政部还确认，工资转移程序不会受到这次网络攻击的影响，因为政府的财务系统是独立的。【The Rhysida ransomware group hit the Kuwait Ministry of Finance (securityaffairs.com)】</p><p>3. 3 万新生儿和孕期护理患者的数据泄露事件影响了 BORN ONTARIO<br> "BORN（更好的结果注册和网络）受到了网络安全漏洞的影响，这个漏洞是由我们使用的软件 Progress MOVEit 在执行安全文件传输时触发的全球性漏洞所导致。"【BORN Ontario data breach impacted 3.4 million newborns and pregnancy care patients (securityaffairs.com)】</p><p>4. 影子辛迪加：与 7 个勒索软件家族有关的新兴网络犯罪组织<br> 网络安全专家揭示了一个名为 ShadowSyndicate（前身为 Infra Storm）的新网络犯罪组织，该组织在过去一年中可能利用了多达七个不同的勒索软件家族。【ShadowSyndicate: A New Cybercrime Group Linked to 7 Ransomware Families (thehackernews.com)】</p><p>5. JetBrains TeamCity 的漏洞可能让攻击者获得源代码和构建管道的访问权限<br> 没有经过身份验证的攻击者可以利用 JetBrains TeamCity CI/CD 软件中的一个关键安全漏洞，在受影响的系统上远程执行代码。【Critical JetBrains TeamCity Flaw Could Expose Source Code and Build Pipelines to Attackers (thehackernews.com)】</p><p>6. 网络钓鱼者利用 Facebook 直播假货作为诱饵<br> NCC 警告称，「航海狂人」可能很容易被虚假的社交媒体帖子所诱惑，一些受害者甚至可能在不知不觉中成为了犯罪分子的新兵，以获取整齐的 Facebook 帐户详细信息。【Critical JetBrains TeamCity Flaw Could Expose Source Code and Build Pipelines to Attackers (thehackernews.com)】</p><p>前沿资讯<br> 1. macOS 平台上出现的新型信息窃密软件：MacStealer<br> 信息窃密恶意软件 MacStealer 能够对最新版本的 macOS 造成威胁，并且使用了 Telegram 作为 C&amp;C 信道来窃取受害者的敏感数据。【macOS 平台新出现的信息窃密软件：MacStealer_网络安全小肖的博客-CSDN 博客】</p><p>2. 零信任技术架构：SDP2.0 的中文改写版<br> "在零信任技术架构中，本质上没有太大的区别。在实际的客户环境中，我们需要根据具体情况有侧重点地进行建设，例如优先加强端点零信任能力（SDP 架构）、身份认证零信任能力（IAM 架构）或东西向流量的零信任能力（MSG 架构）等。"【白话零信任技术架构之 SDP2.0 - FreeBuf 网络安全行业门户】</p><p>3. 0day 审计：某微代码审计案例的中文改写版本<br> 这个方法是继承了 extends MobileAction 并通过 http 请求获取 action 参数，然后进行全局 jsp 文件搜索 SkinAction，发现通过了 jionActionUrl 方法调用，在第 2 行包含了&lt;%@ include file="/mobilemode/init.jsp"%&gt;，根据里方法构造出路径。【0day 审计之某微代码审计-腾讯云开发者社区-腾讯云 (tencent.com)】</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260771</guid>
            <link>https://www.oschina.net/news/260771</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Brave 裁员 9%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Brave Browser 和 Search 的制造商 Brave Software 向 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F06%2Fbrave-lays-off-9-of-its-workforce%2F" target="_blank">TechCrunch</a> 证实，该公司已跨部门裁员 9%。该公司没有具体说明裁员波及的员工人数，但它证实了这一裁员举措，并表示这一决定是由严峻的经济环境所驱动的。</span></p><p><span style="color:#000000">「在这个充满挑战的经济环境中，Brave 公司裁撤了一些职位，作为我们成本管理的一部分。有几个部门受到影响，占我们员工总数的 9%。」</span></p><p><img height="261" src="https://oscimg.oschina.net/oscnet/up-38a5daf764ff082e1ad6362984e1cec8e08.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">今年以来，该公司一直在采取措施以加强收入来源。4 月份，Brave Search 放弃了 Bing Index，开始依赖自己的索引解决方案。</span></p><p><span style="color:#000000">5 月份，该公司为客户发布了自己的&nbsp;search API，计划每 1,000 次查询收费 3 美元起。该 API 还为 AI 数据模型训练、具有存储权限的数据、拼写检查和自动建议提供了不同的计划。上个月，Brave 还为其 search API 推出了图像、新闻和视频搜索功能。</span></p><p><span style="color:#000000">此外，Brave 一直在为其浏览器测试名为 Leo 的原生人工智能助手。Brave 表示，虽然计划向所有用户开放，但 Leo 将拥有高级版，具有更高的速率限制和访问更多对话模型等功能。该公司指出，这将有助于其支付 API 访问和托管成本。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 03:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260770/brave-lays-off-9-of-its-workforce</guid>
            <link>https://www.oschina.net/news/260770/brave-lays-off-9-of-its-workforce</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[NASA 更改 CMS：从 Drupal 迁移到 WordPress]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>美国国家航空航天局 (NASA) 移除了新版<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nasa.gov%2F" target="_blank">&nbsp;nasa.gov </a>网站上的 beta 测试标签，标志其已正式可用。</p><p>据介绍，NASA 新版本官网采用了新的 CMS（内容管理系统） —— 从 Drupal 迁移到 WordPress。此次迁移花费了 18 个月，主要工作包括网站开发、数据迁移和内容建设。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6f81cac58978084713557fe55beb8b4510b.png" referrerpolicy="no-referrer"></p><p>NASA 在选择 CMS 时评估了商业和开源解决方案，对 100 多个 CMS 平台进行了考察，四个方案进入了最终候选名单，包括两个商业方案，以及两个开源方案 —— WordPress 和 Drupal。</p><p>他们认为 WordPress 的优势如下：</p><ul><li><strong>社区庞大</strong>，方便获取支持资源。</li><li><strong>插件生态丰富</strong>，更好地进行 SEO 优化、对内容进行实时分析等</li><li><strong>内容创作环境易于使用</strong></li></ul><p>WordPress.com VIP 金牌代理合作伙伴 Lone Rock Point 领导了 NASA 此次 CMS 迁移项目，该项目从一年的用户体验设计和对各种企业 CMS 的评估开始。作为该项目的一部分，NASA 的网站基础设施也从 AWS 迁移到了 WordPress.com VIP。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260768/nasa-chose-wordpress-cms</guid>
            <link>https://www.oschina.net/news/260768/nasa-chose-wordpress-cms</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[SudoLang —— 与 AI 语言模型协作的编程语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>SudoLang 是一种编程语言，旨在与 ChatGPT、Bing Chat、Anthropic Claude 和 Google Bard 等 AI 语言模型协作。它被设计为易于学习和使用，同时也非常具有表现力和力量。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>所有足够先进的语言模型都可以在没有任何特殊提示的情况下理解它。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><h4 style="text-align:start"><strong><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>特点</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></h4><ul><li><strong>基于自然语言约束的编程。</strong>与其告诉人工智能做什么，不如告诉它是什么或你想要什么，以及一些管理规则。人工智能会持续遵守这些约束，并可用于同步状态和行为。只需几行自然语言文本，约束条件就能轻松定义非常复杂的行为。</li><li>用于定义程序的结构和行为的<strong>接口。</strong></li><li><strong><code>/commands</code></strong>用于为程序交互定义聊天或编程接口。</li><li><strong>语义模式匹配</strong>。AI 可以智能地推断程序状态并匹配模式，诸如<code>(post contains harmful content) =&gt; explain(content policy)</code>。</li><li><strong>全能参照。</strong>你无需明确定义大多数函数。人工智能会为你推断出它们。</li></ul><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>对于大多数简单的提示，自然语言更好。用它。但如果你需要 AI 遵循程序、遵守约束、跟踪复杂状态或实现复杂算法，SudoLang 会非常有用。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>由于强调自然语言，SudoLang 比 JavaScript 或 Python 等编程语言更容易学习。</li><li>与自然语言提示相比，伪代码可以<a href="https://arxiv.org/abs/2305.11790">提高推理性能</a>，并为许多提示样式创建简写，例如思想链推理、决策树等。</li><li>SudoLang 是一种声明性、基于约束、面向接口的编程语言，这使其成为世界上最具表现力和紧凑的编程语言之一。SudoLang 提示通常可以比自然语言少 20% - 30% 的标记，从而降低提示成本并加快响应速度。</li><li>结构化伪代码提供范围块、缩进和视觉封装，这使得导航和维护复杂提示比自然语言更容易。</li><li>使用预定义类型和接口的结构化模板和查询可以降低格式错误响应的可能性，并<a href="https://arxiv.org/pdf/2212.06094.pdf">显着减少与语言模型交互所需的令牌数量</a>，特别是在请求<a href="https://yaml.org/">yaml</a>或<a href="https://en.wikipedia.org/wiki/Comma-separated_values">csv</a>格式的数据时。</li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/sudolang</guid>
            <link>https://www.oschina.net/p/sudolang</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 键映射解决方案 Capslock Magic]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-capslockmagic" class="anchor" href="https://gitee.com/miozus/CapslockMagic#capslockmagic"></a>CapslockMagic</h1><blockquote><p><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic">中文文档</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fen-us%2F">README</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fke-complex-modifications.pqrs.org%2F%23caps_lock_magic">Karabiner Gallery</a> | <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmiozus%2FCapslockMagic">Github Repo</a> | <a href="https://gitee.com/miozus/CapslockMagic">Gitee Repo</a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fthqby%2FAutoHotkey_H"><img src="https://img.shields.io/badge/AutoHotkey__H-thqby-orange?style=flat&amp;logo=GitHub" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmiozus%2FCapslockMagic"><img src="https://img.shields.io/badge/CapslockMagic-1.5.1-brightengreen?style=flat&amp;logo=ClickUp" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DiiuN83v3"><img src="https://img.shields.io/badge/QQ%E7%BE%A4-1026918136-yellow?style=flat&amp;logo=TencentQQ" referrerpolicy="no-referrer"></a></p></blockquote><p><img src="https://gitee.com/miozus/CapslockMagic/raw/master/docs/img/HHKB-win-keymap-pure.png" alt="hhkb" referrerpolicy="no-referrer"></p><p>Capslock Magic 是一套<strong>跨平台</strong>、<strong>跨应用</strong>的键映射解决方案。 它将 ⇪ CapsLock（大写锁定键）改造为一个强力的功能修饰键（✱ Hyper ），还改造了 <kbd>3</kbd><kbd>4</kbd><kbd>;</kbd> 按键，适用各种日常业务场景。奇迹般地提高操作效率与生产力。</p><p>—— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmonkey-ime">示例</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fquick-start-windows">安装</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">使用</a> —— <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">问题</a> ——</p><h2><a id="user-content-功能一览" class="anchor" href="https://gitee.com/miozus/CapslockMagic#%E5%8A%9F%E8%83%BD%E4%B8%80%E8%A7%88"></a>功能一览</h2><table><thead><tr><th>&nbsp;</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>底层</td><td>💻  支持 Win/Mac</td><td>⌨️  键盘配列 60</td><td>🧰  JavaScprit 风格</td><td>⚙️  配置自定义</td></tr><tr><td>基础</td><td>👾  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">启动程序</a></td><td>📺  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fwindow">窗口管理</a></td><td>🖱️  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmouse">鼠标操作</a></td><td><code>I</code><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fcapslock-enhancement">光标编辑</a></td></tr><tr><td>进化</td><td>🐵  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fmonkey-ime">猴子输入法</a></td><td><code>;</code><a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fsemicolon-hook">分号特殊符</a></td><td>3️⃣  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fnumpad">数字小键盘</a></td><td>🤖  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Fime-manager">中英文管家</a></td></tr><tr><td>进化</td><td>🦑  <a href="https://gitee.com/link?target=https%3A%2F%2Fmiozus.github.io%2FCapslockMagic%2F%23%2Fzh-cn%2Funiverse-editor">宇宙编辑器</a></td><td></td><td></td><td></td></tr></tbody></table>]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/miozus/CapslockMagic</guid>
            <link>https://gitee.com/miozus/CapslockMagic</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | MySQL 到 TiDB：Hive Metastore 横向扩展之路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互联网技术" data-alias="vivoVMIC" data-signature="分享 vivo 互联网技术干货与沙龙活动，推荐最新行业动态与热门会议。" data-from="0"></mp-common-profile></section><section style="font-size: 15px;line-height: 1.6;"><section style="margin: 10px 0% 8px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px solid rgb(219, 219, 219);border-bottom-left-radius: 0px;padding-left: 8px;align-self: flex-start;flex: 0 0 auto;"><section style="color: rgba(0, 0, 0, 0.5);font-size: 14px;text-align: justify;" powered-by="xiumi.us"><p>作者：vivo 互联网大数据团队 - Wang Zhiwen</p></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: left;" powered-by="xiumi.us"><section style="font-size: 14px;text-align: justify;line-height: 1.8;padding-right: 5px;padding-left: 5px;color: rgb(160, 160, 160);"><p>本文介绍了 vivo 在大数据元数据服务横向扩展道路上的探索历程，由实际面临的问题出发，对当前主流的横向扩展方案进行了调研及对比测试，通过多方面对比数据择优选择 TiDB 方案。其次分享了整个扩展方案流程、实施遇到的问题及解决方案，对于在大数据元数据性能上面临同样困境的开发者本篇文章具有非常高的参考借鉴价值。</p></section></section></section></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>一、背景</p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>大数据元数据服务 Hive Metastore Service（以下简称 HMS），存储着数据仓库中所依赖的所有元数据并提供相应的查询服务，使得计算引擎（Hive、Spark、Presto）能在海量数据中准确访问到需要访问的具体数据，其在离线数仓的稳定构建上扮演着举足轻重的角色。vivo 离线数仓的 Hadoop 集群基于 CDH 5.14.4 版本构建，HMS 的版本选择跟随 CDH 大版本，当前使用版本为 1.1.0-cdh5.14.4。</p><p><br></p><p>vivo 在 HMS 底层存储架构未升级前使用的是 MySQL 存储引擎，但随着 vivo 业务发展，数据爆炸式增长，存储的元数据也相应的增长到亿级别（PARTITION_PARAMS：8.1 亿、</p><p>PARTITION_KEY_VALS：3.5 亿、PARTITIONS：1.4 亿），在如此大量的数据基数下，我们团队经常面临机器资源的性能瓶颈，往往用户多并发的去查询某些大分区表（50w+分区），机器资源的使用率就会被打满，从而导致元数据查询超时，严重时甚至整个 HMS 集群不可用，此时恢复手段只能暂时停服所有 HMS 节点，直到 MySQL 机器负载降下来后在逐步恢复服务。为此，针对当前 MySQL 方案存在的严重性能瓶颈，HMS 急需一套完善的横向扩展方案来解决当前燃眉之急。</p></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>二、横向扩展技术方案选型</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">为解决 HMS 的性能问题，我们团队对 HMS 横向扩展方案做了大量的调研工作，总体下来业内在 HMS 的横向扩展思路上主要分为对 MySQL 进行拆库扩展或用高性能的分布式引擎替代 MySQL。在第一种思路上做的比较成熟的方案有<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fhotels.com%2F" textvalue="Hotels.com" linktype="text" imgurl="" tab="outerlink" data-linktype="2">Hotels.com</a>公司开源的 Waggle Dance，实现了一个跨集群的 Hive Metastore 代理网关，他允许用户同时访问多个集群的数据，这些集群可以部署在不同的平台上，特别是云平台。第二种思路当前主流的做法是用分布式存储引擎 TiDB 替换传统的 MySQL 引擎，在 Hive 社区中有不少公司对 hive 2.x 接入 TiDB 做了大量的测试并应用到生产中（<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FHive%2FUsing%2BTiDB%2Bas%2Bthe%2BHive%2BMetastore%2Bdatabase" textvalue="详情点击" linktype="text" imgurl="" tab="outerlink" data-linktype="2">详情点击</a>）。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.1 Waggle Dance</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">Waggle-dance 向用户提供统一的入口，将来自 Metastore 客户端的请求路由到底层对应的 Metastore 服务，同时向用户隐藏了底层的 Metastore 分布，从而在逻辑层面整合了多个 Metastore 的 Hive 库表信息。Waggle-dance 实现了 Metastore 的 Thrift API，客户端无需改动，对用户来说，Waggle-dance 就是一个 Metastore。其整体架构如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.9175925925925926" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/a9e0ef2a-6dea-4425-8220-7df8cbb062f1.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">Waggle Dance 架构</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">从 Waggle-dance 的架构中最突出的特性是其采用了多个不同的 MySQL 实例分担了原单 MySQL 实例的压力，除此之外其还有如下优势：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>用户侧可以沿用 Metastore 客户端的用法，配置多台 Waggle-dance 的连接，在当前 Waggle-dance 连接服务不可用的时候切换到其他的 Waggle-dance 服务上。</p></li><li><p>Waggle-dance 只需几秒即可启动，加上其无状态服务的特性，使得 Waggle-dance 具备高效的动态伸缩性，可以在业务高峰期快速上线新的服务节点分散压力，在低峰期下线部分服务节点释放资源。</p></li><li><p>Waggle-dance 作为一个网关服务，除了路由功能外，还支持后续的定制化开发和差异化部署，平台可根据需要添加诸如鉴权、防火墙过滤等功能。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.2 TiDB</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">TiDB 是 PingCAP 公司自主设计、研发的开源分布式关系型数据库，是一款同时支持在线事务处理与在线分析处理 (Hybrid Transactional and Analytical Processing, HTAP) 的融合型分布式数据库产品，具备水平扩容或者缩容、金融级高可用、实时 HTAP、云原生的分布式数据库、兼容 MySQL 5.7 协议和 MySQL 生态等重要特性。在 TiDB 4.x 版本中，其性能及稳定性较与之前版本得到了很大的提升并满足 HMS 的元数据查询性能需求。故我们对 TiDB 也做了相应的调研及测试。结合 HMS 及大数据生态，采用 TiDB 作为元数据存储整体的部署架构如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.8727272727272727" data-s="300,640" data-type="png" data-w="825" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/e149c269-2046-48a7-bb11-e0a90ce0edf1.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">HMS on TiDB 架构&nbsp; &nbsp;</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">由于 TiDB 本身具有水平扩展能力，扩展后能均分查询压力，该特性就是我们解决 HMS 查询性能瓶颈的大杀器。除此外该架构还有如下优势：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>用户无需任何改动；HMS 侧面没有任何改动，只是其依赖的底层存储发生变化。</p></li><li><p>不破坏数据的完整性，无需将数据拆分多个实例来分担压力，对 HMS 来说其就是一个完整、独立的数据库。</p></li><li><p>除引入 TiDB 作为存储引擎外，不需要额外的其他服务支撑整个架构的运行。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">2.3 TiDB 和 Waggle Dance 对比</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">前面内容对 Waggle-dance 方案和 TiDB 方案做了简单的介绍及优势总结，以下列举了这两个方案在多个维度的对比：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.6953703703703704" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3ce1c63-1cd8-4917-a94b-0e3c638c3328.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通过上述多个维度的对比，TiDB 方案在性能表现、水平扩展、运维复杂度及机器成本上都优于 waggle-dance 方案，故我们线上选择了前者进行上线应用。&nbsp;</p><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>三、TiDB 上线方案</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">选择 TiDB 引擎替代原 MySQL 存储引擎，由于 TiDB 与 MySQL 之间不能做双主架构，在切换过程中 HMS 服务须完全停服后并重新启动切换至 TiDB，为保障切换过程顺利及后面若有重大问题发生能及时回滚，在切换前做了如下数据同步架构以保障切换前 MySQL 与 TiDB 数据一致以及切换后仍有 MySQL 兜底。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4703703703703704" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/033aceb3-efa2-4951-9897-94e1c2cbe128.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB&amp;MySQL 上线前后数据同步架构</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在上述架构中，切换前唯一可写入的数据源只有源数据库主库，其他所有 TiDB、MySQL 节点都为只读状态，当且仅当所有 HMS 节点停服后，MySQL 源数据库从库及 TiDB 源数据库主库的数据同步最大时间戳与源数据库主库一致时，TiDB 源数据库主库才开放可写入权限，并在修改 HMS 底层存储连接串后逐一拉起 HMS 服务。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在上述架构完成后，即可开始具体的切换流程，切换整体流程如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.27037037037037037" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/20cfee5d-3265-4b12-9e43-7fa47ffb8f59.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">HMS 切换底层存储流程</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">其中在保障源 MySQL 与 TiDB 数据正常同步前，需要对 TiDB 做以下配置：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>tidb_skip_isolation_level_check 需要配置为 1 ，否则启动 HMS 存在 MetaException 异常。</p></li><li><p>tidb_txn_mode 需配置为 pessimistic ，提升事务一致性强度。</p></li><li><p>事务大小限制设置为 3G，可根据自己业务实际情况进行调整。</p></li><li><p>连接限制设置为最大 3000 ，可根据自己业务实际情况进行调整。</p></li></ul></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">此外在开启 sentry 服务状态下，需确认 sentry 元数据中 NOTIFICATION_ID 的值是否落后于 HMS 元数据库中 NOTIFICATION_SEQUENCE 表中的 NEXT_EVENT_ID 值，若落后需将后者替换为前者的值，否则可能会发生建表或创建分区超时异常。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">以下为 TiDB 方案在在不同维度上的表现：</p><section style="margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: transparent;padding: 10px;background-color: rgb(239, 239, 239);"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;" powered-by="xiumi.us"><li><p>在对 HQL 的兼容性上 TiDB 方案完全兼容线上所有引擎对元数据的查询，不存在语法兼容问题，对 HQL 语法兼容度达 100%&nbsp;</p></li><li><p>在性能表现上查询类接口平均耗时优于 MySQL，性能整体提升 15%；建表耗时降低了 80%，且支持更高的并发，TiDB 性能表现不差于 MySQL</p></li><li><p>在机器资源使用情况上整体磁盘使用率在 10% 以下；在没有热点数据访问的情况下，CPU 平均使用率在 12%；CPU.WAIT.IO 平均值在 0.025% 以下;集群不存在资源使用瓶颈。</p></li><li><p>在可扩展性上 TiDB 支持一键水平扩缩容，且内部实现查询均衡算法，在数据达到均衡的情况下各节点可平摊查询压力。</p></li><li><p>在容灾性上 TiDB Binlog 技术可稳定支撑 TiDB 与 MySQL 及 TiDB 之间的数据同步，实现完整的数据备份及可回退选择。</p></li><li><p>在服务高可用性上 TiDB 可选择 LVS 或 HaProxy 等服务实现负载均衡及故障转移。</p></li></ol></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">以下为上线后 HMS 主要 API 接口调用耗时情况统计：</p><section style="font-size: 15px;"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: 15px;margin-bottom: 15px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 5px;align-self: stretch;flex: 0 0 auto;margin-bottom: 30px;height: auto;z-index: 1;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section><section style="display: inline-block;vertical-align: top;width: auto;align-self: stretch;flex: 100 100 0%;height: auto;padding-right: 10px;padding-left: 10px;z-index: auto;line-height: 0;"><section style="display: flex;width: 100%;flex-flow: column;" powered-by="xiumi.us"><section style="z-index: 1;" powered-by="xiumi.us"><section style="text-align: right;margin-top: -5px;"><section style="display: inline-block;width: 100%;height: 5px;vertical-align: top;overflow: hidden;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-right: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bc1f5fe-5ed3-4507-8edd-99fd9eb4edcd.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-left: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.5880322209436134" data-s="300,640" data-type="jpeg" data-w="869" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/bde61013-5736-415d-a148-1fb6567a709e.png" referrerpolicy="no-referrer"></section></section></section></section><section style="justify-content: flex-start;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-right: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 304px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/4575beb3-65ef-435b-8992-48929786cf28.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 50%;align-self: flex-start;flex: 0 0 auto;padding-left: 5px;"><section style="text-align: center;line-height: 0;" powered-by="xiumi.us"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="269" data-cropsely1="0" data-cropsely2="179" data-ratio="0.6009227220299884" data-s="300,640" data-type="jpeg" data-w="867" style="vertical-align: middle;width: 298px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1c03991f-8f59-408b-a79e-d268d19c62d0.png" referrerpolicy="no-referrer"></section></section></section></section><section style="text-align: right;margin-bottom: -5px;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;height: 5px;vertical-align: top;overflow: hidden;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: top;width: 5px;align-self: stretch;flex: 0 0 auto;height: auto;margin-top: 30px;z-index: auto;"><br><br><br><br></section></section><section style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;" powered-by="xiumi.us"><section style="display: inline-block;width: auto;vertical-align: middle;align-self: center;flex: 100 100 0%;border-radius: 10px;overflow: hidden;height: auto;padding: 15px;border-style: solid;border-width: 1px;border-color: transparent;margin-right: 20px;z-index: 0;"><section style="display: inline-block;width: 100%;vertical-align: top;overflow-x: auto;border-radius: 5px;" powered-by="xiumi.us"><section style="overflow: hidden;width: 360%;max-width: 360% !important;"><section style="display: inline-block;vertical-align: middle;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/9bc1f5fe-5ed3-4507-8edd-99fd9eb4edcd.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.5880322209436134" data-s="300,640" data-type="jpeg" data-w="869" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/bde61013-5736-415d-a148-1fb6567a709e.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.588774341351661" data-s="300,640" data-type="jpeg" data-w="873" style="vertical-align: middle;width: 520px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/4575beb3-65ef-435b-8992-48929786cf28.png" referrerpolicy="no-referrer"></section></section></section><section style="display: inline-block;vertical-align: top;width: 25%;" powered-by="xiumi.us"><section style="text-align: left;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;width: 97%;height: auto;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="459" data-cropsely1="0" data-cropsely2="306" data-ratio="0.6009227220299884" data-s="300,640" data-type="jpeg" data-w="867" style="vertical-align: middle;width: 509px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1c03991f-8f59-408b-a79e-d268d19c62d0.png" referrerpolicy="no-referrer"></section></section></section></section></section><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;margin-top: -20px;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: bottom;width: auto;align-self: flex-end;flex: 0 0 auto;min-width: 5%;height: auto;margin-right: 5px;z-index: 2;"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section><section style="display: inline-block;vertical-align: bottom;width: auto;align-self: flex-end;flex: 0 0 auto;min-width: 5%;height: auto;"><section style="text-align: justify;color: rgb(223, 143, 51);font-size: 14px;" powered-by="xiumi.us"><p><br></p><p><span style="color: rgb(136, 136, 136);">（<span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.578px;text-wrap: wrap;">左右滑动</span><span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.578px;text-wrap: wrap;">，查看更多···</span>）</span></p></section></section></section></section></section><p powered-by="xiumi.us"><br></p></section><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>四、问题及解决方案</p></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.1 在模拟 TiDB 回滚至 MySQL 过程中出现主键冲突问题</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在 TiDB 数据增长 3 倍后，切换回 MySQL 出现主键重复异常，具体日志内容如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.12222222222222222" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/dfa5874c-61af-4491-b338-4a3c4bd816af.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">主键冲突异常日志</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">产生该问题的主要原因为每个 TiDB 节点在分配主键 ID 时，都申请一段 ID 作为缓存，用完之后再去取下一段，而不是每次分配都向存储节点申请。这意味着，TiDB 的 AUTO_INCREMENT 自增值在单节点上能保证单调递增，但在多个节点下则可能会存在剧烈跳跃。因此，在多节点下，TiDB 的 AUTO_INCREMENT 自增值从全局来看，并非绝对单调递增的，也即并非绝对有序的，从而导致 Metastore 库里的 SEQUENCE_TABLE 表记录的值不是对应表的最大值。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">造成主键冲突的主要原因是 SEQUENCE_TABLE 表记录的值不为元数据中实际的最大值，若存在该情况在切换回 MySQL 后就有可能生成已存在的主键导致初见冲突异常，此时只需将 SEQUENCE_TABLE 里的记录值设置当前实际表中的最大值即可。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.2 PARTITION_KEY_VALS 的索引取舍</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在使用 MySQL 引擎中，我们收集了部分慢查询日志，该类查询主要是查询分区表的分区，类似如下 SQL：</p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__comment">#以下查询为查询三级分区表模板，且每级分区都有过来条件</span></span></code><code><span class="code-snippet_outer"><br></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">SELECT</span> PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">FROM</span><span class="code-snippet__keyword">PARTITIONS</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> TBLS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> PARTITIONS.TBL_ID = TBLS.TBL_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> TBLS.TBL_NAME = <span class="code-snippet__string">'${TABLE_NAME}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> DBS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> TBLS.DB_ID = DBS.DB_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> DBS.NAME = <span class="code-snippet__string">'${DB_NAME}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER0</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER0.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER0.INTEGER_IDX = ${INDEX1}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER1</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER1.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER1.INTEGER_IDX = ${INDEX2}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span> PARTITION_KEY_VALS FILTER2</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span> FILTER2.PART_ID = PARTITIONS.PART_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER2.INTEGER_IDX = ${INDEX3}</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHERE</span> FILTER0.PART_KEY_VAL = <span class="code-snippet__string">'${PART_KEY}'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__keyword">CASE</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHEN</span> FILTER1.PART_KEY_VAL &lt;&gt; <span class="code-snippet__string">'__HIVE_DEFAULT_PARTITION__'</span><span class="code-snippet__keyword">THEN</span><span class="code-snippet__keyword">CAST</span>(FILTER1.PART_KEY_VAL <span class="code-snippet__keyword">AS</span><span class="code-snippet__built_in">decimal</span>(<span class="code-snippet__number">21</span>, <span class="code-snippet__number">0</span>))</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ELSE</span><span class="code-snippet__literal">NULL</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">END</span> = <span class="code-snippet__number">10</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span> FILTER2.PART_KEY_VAL = <span class="code-snippet__string">'068'</span>;</span></code></pre></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>在测试中通过控制并发重放该类型的 SQL，随着并发的增加，各个 API 的平均耗时也会增长，且重放的 SQL 查询耗时随着并发的增加查询平均耗时达到 100s 以上，虽然 TiDB 及 HMS 在压测期间没有出现任何异常，但显然这种查询效率会让用户很难接受。DBA 分析该查询没有选择合适的索引导致查询走了全表扫描，建议对 PARTITION_KEY_VALS 的 PARTITION_KEY_VAL 字段添加了额外的索引以加速查询，最终该类型的查询得到了极大的优化，即使加大并发到 100 的情况下平均耗时在 500ms 内，对此我们曾尝试对 PARTITION_KEY_VALS 添加上述索引操作。</p><p><br></p><p>但在线上实际的查询中，那些没有产生慢查询的分区查询操作其实都是按天分区的进行一级分区查询的，其 SQL 类似如下：</p></section><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__keyword">SELECT</span><span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">FROM</span><span class="code-snippet__string">"PARTITIONS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"TBLS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"TBL_ID"</span> = <span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"TBL_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"TBL_NAME"</span> = <span class="code-snippet__string">'tb1'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"DBS"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"TBLS"</span>.<span class="code-snippet__string">"DB_ID"</span> = <span class="code-snippet__string">"DBS"</span>.<span class="code-snippet__string">"DB_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"DBS"</span>.<span class="code-snippet__string">"NAME"</span> = <span class="code-snippet__string">'db1'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"PARTITION_KEY_VALS"</span><span class="code-snippet__string">"FILTER0"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"PART_ID"</span> = <span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"INTEGER_IDX"</span> = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">INNER</span><span class="code-snippet__keyword">JOIN</span><span class="code-snippet__string">"PARTITION_KEY_VALS"</span><span class="code-snippet__string">"FILTER1"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ON</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_ID"</span> = <span class="code-snippet__string">"PARTITIONS"</span>.<span class="code-snippet__string">"PART_ID"</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"INTEGER_IDX"</span> = <span class="code-snippet__number">1</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHERE</span><span class="code-snippet__string">"FILTER0"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span> = <span class="code-snippet__string">'2021-12-28'</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">AND</span><span class="code-snippet__keyword">CASE</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">WHEN</span><span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span> &lt;&gt; <span class="code-snippet__string">'__HIVE_DEFAULT_PARTITION__'</span><span class="code-snippet__keyword">THEN</span><span class="code-snippet__keyword">CAST</span>(<span class="code-snippet__string">"FILTER1"</span>.<span class="code-snippet__string">"PART_KEY_VAL"</span><span class="code-snippet__keyword">AS</span><span class="code-snippet__built_in">decimal</span>(<span class="code-snippet__number">21</span>, <span class="code-snippet__number">0</span>))</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">ELSE</span><span class="code-snippet__literal">NULL</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">END</span> = <span class="code-snippet__number">10</span>;</span></code></pre></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">由于对 PARTITION_KEY_VALS 的 PARTITION_KEY_VAL 字段添加了索引做查询优化，会导致该类查询生成的执行计划中同样会使用 idx_PART_KEY_VAL 索引进行数据扫描，该执行计划如下：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4898148148148148" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/20f84c22-d1ae-4c32-82be-4b884faf9249.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">走 idx_PART_KEY_VAL 索引执行计划</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">添加的 idx_PART_KEY_VAL 索引在该字段的具有相同值的数据较少时，使用该索引能检索较少的数据提升查询效率。在 hive 中的表一级分区基本是按天进行分区的，据统计每天天分区的增量为 26w 左右，如果使用 idx_PART_KEY_VAL 索引，按这个数值计算，查询条件为 day&gt;=2021-12-21 and day&lt;2021-12-26 的查询需要检索将近 160w 条数据，这显然不是一个很好的执行计划。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">若执行计划不走 idx_PART_KEY_VAL 索引，TiDB 可通过 dbs、tbls 检索出所有关联 partition 数据，在根据 part_id 和过滤条件扫描 PARTITION_KEY_VALS 数据并返回。此类执行计划扫描的数据量和需要查询的表的分区总量有关，如果该表只有少数的分区，则查询能够迅速响应，但如果查询的表有上百万的分区，则该类执行计划对于该类查询不是最优解。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.2675925925925926" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/97b2badc-d7bd-4e82-872c-cdfbed8555cd.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">不走 idx_PART_KEY_VAL 索引执行计划</span></p><section powered-by="xiumi.us"><p><br></p><p>针对不同执行计划的特性，整理了以下对比点：</p></section><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.2995910020449898" data-s="300,640" data-type="png" data-w="978" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/393b4adf-34c3-4685-9d35-3002044f44b6.png" referrerpolicy="no-referrer"></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在实际生产中元数据基本都是按天分区为主，每天增长大概有 26w 左右，且范围查询的使用场景较多，使用 idx_PART_KEY_VAL 索引查询的执行计划不太适合线上场景，故该索引需不适合添加到线上环境。</p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.3 TiDB 内存突增导致宕机问题</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在刚上线 TiDB 服务初期，曾数次面临 TiDB 内存溢出的问题，每次出现的时间都随机不确定，出现的时候内存突增几乎在一瞬间，若期间 TiDB 的内存抗住了突增量，突增部分内存释放在很长时间都不会得到释放，最终对 HMS 服务稳定性带来抖动。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4034833091436865" data-s="300,640" data-type="png" data-w="689" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/8844c991-06f3-4ca0-aab6-3d42df20759e.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB 内存突增情况</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通过和 TiDB 开发、DBA 联合分析下，确认 TiDB 内存飙高的原因为用户在使用 Dashboard 功能分析慢查询引起；在分析慢查询过程中，TiDB 需要加载本地所有的 slow-query 日志到内存，如果这些日志过大，则会造成 TiDB 内存突增，此外，如果在分析期间，用户点击了取消按钮，则有可能会造成 TiDB 的内存泄漏。针对该问题制定如下解决方案：</p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="display: inline-block;width: 100%;border-width: 1px;border-style: solid;border-color: rgb(160, 160, 160);padding: 10px;"><section style="text-align: justify;line-height: 1.8;padding-right: 5px;padding-left: 5px;" powered-by="xiumi.us"><ol class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p>使用大内存机器替换原小内存机器，避免分析慢查询时内存不够</p></li><li><p>调大慢查询阈值为 3s，减少日志产生</p></li><li><p>定时 mv 慢查询日志到备份目录</p></li></ol></section></section></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.4 locate 函数查询不走索引导致 TiKV 负异常</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">在 HMS 中存在部分通过 JDO 的方式去获取分区的查询，该类查询的过滤条件中用 locate 函数过滤 PART_NAME 数据，在 TiDB 中通过函数作用在字段中是不会触发索引查询的，所以在该类查询会加载对应表的所有数据到 TiDB 端计算过滤，TiKV 则需不断扫描全表并传输数据到 TiDB 段，从而导致 TiKV 负载异常。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.43148148148148147" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/0c22e9c9-f38c-4dec-b58b-d35a9460e937.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">locate 函数导致全表扫描</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">然而上述的查询条件可以通过 like 方式去实现，通过使用 like 语法，查询可以成功使用到 PARTITIONS 表的 UNIQUEPARTITION 索引过滤，进而在 TiKV 端进行索引过滤降低负载。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.45" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/35186c1a-9fcf-43a9-a5a0-7d7fa3ca1690.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;"><span style="font-size: 14px;color: rgb(136, 136, 136);">like 语法走索引过滤</span></span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">通过实现将 locate 函数查询转换为 like 语法查询，有效降低了 TiKV 端的负载情况。在 HMS 端完成变更后，TiKV 的 CPU 使用率降低了将近一倍，由于在 KV 端进行索引过滤，相应的 io 使用率有所上升，但网络传输则有明显的下降，由平均 1G 降低到 200M 左右。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.34814814814814815" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d6a4e572-c45f-424b-b9bc-a589fae353c2.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">变更前后 TiKV 的负载情况</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">除 TiKV 负载有明显的降低，TiDB 的整体性能也得到明显的提升，各项操作耗时呈量级降低。以下整理了 TiDB 增删改查的天平均耗时情况：</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.5666666666666667" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/d3a73735-d7f8-4d13-ac94-5deb12749daa.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="font-size: 14px;color: rgb(136, 136, 136);">TiDB P999 天平均耗时统计</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span style="font-size: 16px;color: rgb(65, 95, 255);">4.5 get_all_functions 优化</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">随着 hive udf 的不断增长，HMS 的 get_all_functions api 平均耗时增长的也越来越久，平均在 40-90s，而该 api 在 hive shell 中首次执行查询操作时会被调用注册所有的 udf，过长的耗时会影响用户对 hive 引擎的使用体验，例如执行简单的 show database 需要等待一分钟甚至更久才能返回结果。</p><p powered-by="xiumi.us"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.3824074074074074" data-s="300,640" data-type="png" data-w="1080" style="height: auto !important;" src="https://oscimg.oschina.net/oscnet/4b18f10c-d130-4c26-8213-44b30511d29c.png" referrerpolicy="no-referrer"></p><p style="text-wrap: wrap;text-align: center;" powered-by="xiumi.us"><span style="color: rgb(136, 136, 136);font-size: 14px;">原 get_all_functions api 平均耗时</span></p><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us">导致该 api 耗时严重的主要原因是 HMS 通过 JDO 方式获取所有的 Function，在获取所有的 udf 时后台会遍历每条 func 去关联 DBS、FUNC_RU 两个表，获取性能极低。而使用 directSQL 的方式去获取所有 udf 数据，响应耗时都在 1 秒以内完成，性能提升相当明显。以下为 directSQL 的 SQL 实现逻辑：</p><p powered-by="xiumi.us"><br></p><section class="code-snippet__fix code-snippet__js"><pre class="code-snippet__js" data-lang="sql"><code><span class="code-snippet_outer"><span class="code-snippet__keyword">select</span> FUNCS.FUNC_NAME,</span></code><code><span class="code-snippet_outer">  DBS.NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.CLASS_NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.OWNER_NAME,</span></code><code><span class="code-snippet_outer">  FUNCS.OWNER_TYPE,</span></code><code><span class="code-snippet_outer">  FUNCS.CREATE_TIME,</span></code><code><span class="code-snippet_outer">  FUNCS.FUNC_TYPE,</span></code><code><span class="code-snippet_outer">  FUNC_RU.RESOURCE_URI,</span></code><code><span class="code-snippet_outer">  FUNC_RU.RESOURCE_TYPE</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> FUNCS</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">left</span><span class="code-snippet__keyword">join</span> FUNC_RU <span class="code-snippet__keyword">on</span> FUNCS.FUNC_ID = FUNC_RU.FUNC_ID</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">left</span><span class="code-snippet__keyword">join</span> DBS <span class="code-snippet__keyword">on</span> FUNCS.DB_ID = DBS.DB_ID</span></code></pre></section><p powered-by="xiumi.us"><br></p><section style="margin-top: 10px;margin-bottom: 10px;text-align: center;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 1px solid rgb(65, 94, 255);font-size: 17px;color: rgb(65, 94, 255);"><p>五、总结</p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>我们从 2021 年 7 月份开始对 TiDB 进行调研，在经历数个月的测试于同年 11 月末将 MySQL 引擎切换到 TiDB。由于前期测试主要集中在兼容性和性能测试上，忽略了 TiDB 自身可能潜在的问题，在上线初期经历了数次因慢查询日志将 TiDB 内存打爆的情况，在这特别感谢我们的 DBA 团队、平台运营团队及 TiDB 官方团队帮忙分析、解决问题，得以避免该问题的再次发生；与此同时，由于当前 HMS 使用的版本较低，加上大数据的组件在不断的升级演进，我们也需要去兼容升级带来的变动，如 HDFS 升级到 3.x 后对 EC 文件读取的支持，SPARK 获取分区避免全表扫描改造等；此外由于 TiDB 的 latin 字符集支持中文字符的写入，该特性会导致用户误写入错误的中文分区，对于此类型数据无法通过现有 API 进行删除，还需要在应用层去禁止该类型错误分区写入，避免无用数据累积。</p><p><br></p><p>经历了一年多的实际生产环境检验，TiDB 内存整体使用在 10% 以内，TiKV CPU 使用平稳，使用峰值均在 30 核内，暂不存在系统瓶颈；HMS 服务的稳定性整体可控，关键 API 性能指标满足业务的实际需求，为业务的增长提供可靠支持。在未来三年内，我们将保持该架构去支撑整个大数据平台组件的稳定运行，期间我们也将持续关注行业内的变动，吸收更多优秀经验应用到我们的生产环境中来，包括但不限于对性能更好的高版本 TiDB 尝试，HMS 的性能优化案例。</p></section><p powered-by="xiumi.us"><br></p><section style="margin-right: 0%;margin-bottom: 20px;margin-left: 0%;justify-content: flex-start;display: flex;flex-flow: row;" powered-by="xiumi.us"><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section><section style="display: inline-block;vertical-align: middle;width: 20%;align-self: center;flex: 0 0 auto;"><section style="text-align: center;color: rgb(45, 66, 87);font-size: 11px;" powered-by="xiumi.us"><p>END</p></section></section><section style="display: inline-block;vertical-align: middle;width: 40%;align-self: center;flex: 0 0 auto;"><section style="margin-top: 0.5em;margin-bottom: 0.5em;" powered-by="xiumi.us"><section style="border-top: 1px dotted rgb(90, 98, 114);"><svg viewBox="0 0 1 1" style="float:left;line-height:0;width:0;vertical-align:top;"></svg></section></section></section></section><section style="margin-top: 10px;margin-bottom: 10px;text-align: left;" powered-by="xiumi.us"><section style="padding-left: 1em;padding-right: 1em;display: inline-block;text-align: center;"><span style="display: inline-block;padding: 0.3em 0.5em;border-radius: 0.5em;background-color: rgb(65, 94, 255);color: rgb(255, 255, 255);" title="" opera-tn-ra-cell="_$.pages:0.layers:0.comps:129.title1"><p>猜你喜欢</p></span></section><section style="border-width: 1px;border-style: solid;border-color: transparent;margin-top: -1em;padding: 20px 10px 10px;background-color: rgb(239, 239, 239);text-align: center;"><section style="font-size: 14px;text-align: left;" powered-by="xiumi.us"><ul class="list-paddingleft-1" style="padding-left: 40px;list-style-position: outside;"><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497299%26idx%3D1%26sn%3Dbf5b4b07d96090267e996a1dc3d0dce1%26chksm%3Debdb86c1dcac0fd7b7b662020ec78a154c8011be6cd0d6b19c091fa1befbc5f79ff45890b45b%26scene%3D21%23wechat_redirect" textvalue="vivo 数据中心网络链路质量监测的探索实践" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">vivo 数据中心网络链路质量监测的探索实践</a></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497274%26idx%3D1%26sn%3Db79ed12d3854f14a7e77eaae5f0de6b2%26chksm%3Debdb86a8dcac0fbe9743c35887bbf6299506aa490bfcd220b4872d506152ee1dcc4c5b45799a%26scene%3D21%23wechat_redirect" textvalue="K8s 多集群实践思考和探索" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">K8s 多集群实践思考和探索</a></p></li><li><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247497145%26idx%3D2%26sn%3D55519f4b73ff9b4a0d19ce6d0ac09a30%26chksm%3Debdb852bdcac0c3d0eb7fdc587942aa7203c63d04f6fefcd688a7a0f0bbaf8288479372695f6%26scene%3D21%23wechat_redirect" textvalue="JVM 内存大对象监控和优化实践" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">JVM 内存大对象监控和优化实践</a></p></li></ul></section></section></section><p powered-by="xiumi.us"><br></p><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe mp_common_widget" data-pluginname="mpprofile" data-id="MzI4NjY4MTU5Nw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt45QXJZicZ9gaNU2mRSlvqhQd94MJ7oQh4QFj1ibPV66xnUiaKoicSatwaGXepL5sBDSDLEckicX1ttibHg/0?wx_fmt=png" data-nickname="vivo 互联网技术" data-alias="vivoVMIC" data-signature="分享 vivo 互联网技术干货与沙龙活动，推荐最新行业动态与热门会议。" data-from="0"></mp-common-profile></section></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公众号 - vivo 互联网技术（vivoVMIC）。<br>如有侵权，请联系 support@oschina.cn 删除。<br>本文参与「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源创计划</a>」，欢迎正在阅读的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 07 Oct 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/10114822</guid>
            <link>https://my.oschina.net/vivotech/blog/10114822</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[苹果 App Store 免费榜第一是黄色软件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>澎湃新闻今日报道苹果 App Store 出现伪装成学习软件的黄色软件，并且冲上了「免费 App」排行榜第一名。</p><p>据悉，该软件的年龄分级为 4 岁以上，但是会引导用户进入赌博和其他黄色网站。网友小同表示，他下载了这款软件，想要学习英语字母，结果发现是一个色情视频软件。他认为这种伪装成学习软件的行为很危险，很容易对孩子造成不良影响。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c7a0ce5e4272f1b06c5119529647215fb11.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-69f6205b4eceb10672c0a3cff67e4f52d48.png" referrerpolicy="no-referrer"></p><p>事件被曝光后，苹果客服虽然进行了回应，但直到下午仍未下架软件。甚至排行榜更新后，App Store 免费榜第一、二名再次出现黄色软件，名为「骑 XX」、「牡丹 XXX」，年龄分级为 4 岁以上。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8b7f27342ea504c47ae6724514736b106a3.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-db2cf9f1307034d7e3a68e35ea067a0fe4f.png" referrerpolicy="no-referrer"></p><p><strong style="color:#424242">截至发稿，这些软件已被下架</strong><span style="background-color:#ffffff; color:#424242">。</span></p><p><span style="background-color:#ffffff; color:#424242">众所周知，苹果应用商店的审核规则极为严格。</span>上面提到的 App 其实就是浏览器套壳，前端显示的内容可以通过后台随意修改。但问题在于，苹果 App 的审核团队为何让这些「套壳」 App 上架到了应用商店？</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 14:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260711</guid>
            <link>https://www.oschina.net/news/260711</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[VS Code 的 C# 开发套件 (C# Dev Kit) 正式 GA]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今年 6 月，微软在 Visual Studio Code 的插件市场<a href="https://www.oschina.net/news/244148/c-sharp-dev-kit-for-visual-studio-code" target="_blank">上架</a>了官方打造的<strong> C# 开发套件 —— C# Dev Kit</strong>，让开发者在 VS Code 中方便地进行 C# 开发。</p><p>据介绍，C# Dev Kit 提高了开发者在使用 VS Code 过程中开发 C# 语言产品的效率。该套件兼容 C# 扩展，由语言服务器协议&nbsp; (LSP) 主机提供支持，从而创建一个高性能、可扩展且灵活的工具环境，可轻松将新体验集成到 C# for VS Code 中。</p><p>经过 4 个多月的测试和打磨，微软近日宣布&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fdotnet%2Fcsharp-dev-kit-now-generally-available%2F" target="_blank"><strong>C# Dev Kit 正式 GA</strong></a>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-abd88ca70f16b7de5318e2944c0f5c847dd.png" referrerpolicy="no-referrer"></p><p>微软表示在预览版期间，累计为 C# Dev Kit 修复了 350 多个问题，其中大部分由社区报告，并对该产品进行了 300 多项有针对性的改进。</p><p>微软称用户的反馈加速推进了 C# Dev Kit 的正式发布，开发团队会继续提升性能和可靠性，并将每月添加新功能。</p><p>根据微软的介绍，C# Dev Kit 从 Visual Studio 中借用了一些开发者们熟悉的概念，并能够与现有的 C# 扩展一起使用，以及通过增加一套强大的工具和实用程序来增强 C# 开发环境，这些工具和实用程序与 VS Code 原生集成，以帮助 C# 开发者更快地编写、调试和维护他们的代码，并减少错误。</p><p>C# Dev Kit 由以下部分组成：</p><ul><li><strong>C# 扩展</strong>：它提供基本的语言服务支持，并继续独立于这项工作进行维护；</li><li><strong>C# Dev Kit 扩展</strong>：它建立在 Visual Studio 的基础上，提供解决方案管理、模板、测试、调试；</li><li><strong>IntelliCode for C# Dev Kit 扩展</strong>：它将 AI 驱动的开发带到了编辑器中；</li></ul><p><img alt="" src="https://static.oschina.net/uploads/space/2023/0607/112538_up8O_4937141.png" referrerpolicy="no-referrer"></p><p><strong><a href="https://www.oschina.net/news/244148/c-sharp-dev-kit-for-visual-studio-code" target="_blank">点此查看详细介绍</a></strong>。</p><p>C# Dev Kit 下载地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3Dms-dotnettools.csdevkit%26ssr%3Dfalse" target="_blank">https://marketplace.visualstudio.com/</a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 09:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260688/vs-code-csharp-dev-kit-ga</guid>
            <link>https://www.oschina.net/news/260688/vs-code-csharp-dev-kit-ga</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Docker 与 Neo4j 等合作推出 GenAI Stack]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Docker 在其年度 DockerCon 开发者大会主题演讲中<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fintroducing-a-new-genai-stack%2F" target="_blank">宣布</a>与 Neo4j、LangChain 和 Ollama 合作推出新的 GenAI Stack。该 GenAI Stack <span style="background-color:#ffffff">简化了 AI/ML 集成，</span>旨在帮助开发人员快速轻松地构建生成式 AI 应用程序，而无需搜索和配置各种技术。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-0852df0e6f3480e6f6d1ddd240cf679021f.webp" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">根据介绍，GenAI Stack 中包含的内容包括有：</span></p><ul><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>预配置的 LLM</strong>：提供预配置的大语言模型 (LLM)，例如 Llama2、GPT-3.5 和 GPT-4，以快速启动 AI 项目。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Ollama&nbsp;管理</strong>：Ollama 简化了开源 LLM 的本地管理，让你的 AI 开发过程更加顺畅。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Neo4j 作为默认数据库</strong>：Neo4j 作为默认数据库，提供图形和原生向量搜索功能。这有助于揭示数据模式和关系，最终提高 AI/ML 模型的速度和准确性。Neo4j 还充当这些模型的长期存储器。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>Neo4j 知识图谱</strong>：Neo4j 知识图谱为 LLM 提供更精确的 GenAI 预测和结果。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>LangChain 编排</strong>：LangChain 促进了 LLM、应用程序和数据库之间的通信，并提供了一个强大的向量索引。LangChain 是一个用于开发由 LLM 支持的应用程序的框架。其中包括 LangSmith，一种调试、测试、评估和监控 LLM 应用程序的新方法。</span></span></li><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff"><strong>全面支持</strong>：提供了一系列有用的工具、代码模板、操作指南和 GenAI 最佳实践。</span></span></li></ul><p><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-346a6330b9b20f9dbd5753904b2051aeda1.webp" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">此外，该公司还通过</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fai-early-access-program%2F" target="_blank">抢先体验计划</a><span style="color:#000000">推出了一款新的生成式 AI 助手，名为 Docker AI。&nbsp;Docker 首席执行官 Scott Johnston 表示，与 Copilot 或&nbsp;Amazon&nbsp;CodeWhisperer 等其他代码生成助手相比，Docker AI 助手可以帮助开发人员定义应用程序的各个方面并排除故障。</span></p><p><span style="color:#000000">"当开发人员编辑 Dockerfile 或 Docker Compose 文件、调试本地 docker build 或在本地运行测试时，Docker AI 会根据具体情况提供自动指导。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 09:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260683/docker-genai-stack</guid>
            <link>https://www.oschina.net/news/260683/docker-genai-stack</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 23.10 将正式支持 Raspberry Pi 5]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根据 omgubuntu 的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F10%2Fubuntu-23-10-will-support-raspberry-pi-5" target="_blank">报道</a>，即将发布的 Ubuntu 23.10 会正式支持<a href="https://www.oschina.net/news/259858/introducing-raspberry-pi-5" target="_blank">树莓派 5</a>。</p><blockquote><p style="margin-left:0px; margin-right:0px; text-align:start"><strong>延伸阅读：<a href="https://www.oschina.net/news/259858/introducing-raspberry-pi-5" target="_blank">Raspberry Pi 5 将于 10 月底发布，60 美元起售</a></strong></p></blockquote><p>报道指出，由于 Canonical 开发者可以提前使用树莓派 5，因此他们能够在设备上测试即将发布的 Ubuntu 版本，确定需要支持新硬件的领域，并将所需的新（和已升级）软件包放入 file_Feature Freeze Exceptions_to （文件_功能冻结异常_队列）中。</p><p>部分针对树莓派 5 的改进包括：引入新的&nbsp;<code>pisp</code>&nbsp;包来处理树莓派 5 大大增强的相机功能；并对&nbsp;<code>python3-gpiozero</code>&nbsp;进行重大更新，以符合新型号对其 GPIO 操作所做的更改。</p><p>另外要注意的是，更新的 rpiboot 软件包将无法在 Ubuntu 23.10 发布时及时提供，但由于这不是严格要求的，所以问题不大。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 07:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260645/ubuntu-23-10-will-support-raspberry-pi-5</guid>
            <link>https://www.oschina.net/news/260645/ubuntu-23-10-will-support-raspberry-pi-5</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里云 PAI - 灵骏大模型训练工具 Pai-Megatron-Patch 正式开源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h3_1"></span><h3>Pai-Megatron-Patch 是什么</h3><p style="text-align:justify">Pai-Megatron-Patch 工具是阿里云机器学习平台 PAI 算法团队研发，基于阿里云智算服务 PAI-灵骏平台的大模型最佳实践解决方案配套工具，旨在帮助大模型开发者快速上手灵骏产品，完成大语言模型（LLM）的高效分布式训练，有监督指令微调，模型离线推理验证等完整大模型开发链路。该项目提供了业界主流开源大模型基于 Megatron-LM 的训练&amp;离线推理验证流程，方便用户快速上手大模型训练。</p><span id="OSC_h3_2"></span><h3>主要特性</h3><ul><li>多款热门大模型支持：llama，llama-2，codellama, 百川，通义千问，Falcon，GLM，Starcoder，Bloom，chatglm 等</li><li>支持模型权重互转转换：在 Huggingface，Megatron 和 Transformer Engine 之间进行算子命名空间映射</li><li>支持 Flash Attention 2.0 和 Transformer Engine 模式下的 FP8 训练加速且确保收敛</li><li>丰富且简单易用的使用示例，支持大模型预训练，微调，评估和推理，强化学习全流程最佳实践</li></ul><span id="OSC_h3_3"></span><h3>开源地址</h3><p style="text-align:justify"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%253Fspm%253Da2c6h.13046898.publish-article.3.5d586ffa9uOzwk" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a></p><span id="OSC_h3_4"></span><h3>技术架构</h3><p style="text-align:justify">Pai-Megatron-Patch 的设计理念是不对 Megatron-LM 的源码进行侵入式修改，即不在 Megatron-LM 里面添加新的功能特性，将需要扩充完善的部分以 patch 补丁的方式呈现。在 patch 中构建 LLM 训练链路通过依赖 Megatron-LM 核心库的方法实现和 Megatron-LM 的解耦合。这样解耦合的好处就是 Megatron-LM 的升级不会影响用户的 LLM 最佳实践体验。</p><p style="text-align:justify">Pai-Megatron-Patch 中包含模型库，分词器，模型转换，强化学习，离线文本生成以及使用示例和工具集等用于构建 LLM 训练的关键要素。在模型库中包含热门大模型的 Megatron 版本实现，例如 baichuan，bloom，chatglm，falcon，galactica，glm，llama，qwen 和 starcoder，后续还会根据需要及时添加新的 Megatron 版大模型实现。同时 patch 还提供了 huggingface 模型权重和 Megatron 模型权重之间的双向转换。一方面是方便用户加载 huggingface 的权重在 Megatron 中继续预训练或者微调，另一方面是方便用户对训练好的 Megatron 模型使用 huggingface 的评估/推理流程对模型质量进行客观评估。在强化学习部分，patch 提供了 PPO 训练流程等，方便用户使用 SFT 模型和 RM 模型进行强化学习。最后 patch 提供了大量的使用示例帮助用户快速开始大模型训练&amp;离线推理。具体请参考阿里云灵骏产品的使用流程:&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F2505831.html%253Fspm%253Da2c6h.13046898.publish-article.4.5d586ffa9uOzwk%2526tab%253Donestop" target="_blank">智算服务 PAI 灵骏大模型分布式训练方案</a></p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-2459be9f4c59a8fd9ac6472cd888c176_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h3_5"></span><h3>关键技术</h3><span id="OSC_h4_6"></span><h4>模型权重转换</h4><p style="text-align:justify">研发 Megatron-Patch 的初衷之一就是能将世界各地研发机构在 Huggingface 上放出的热门大模型使用 Megatron 引擎进行继续预训练或者继续微调。这就需要首先将 Huggingface 模型格式的 ckpt 转换成 Megatron 模型格式，才能正确加载进来，否则会出现 pytorch 加载模型失败。Megatron-Patch 的一个核心可靠性保障特征就是在采用算子拆分，流水并行，序列并行，Zero 显存优化，BF16 混合精度，梯度检查点等训练加速技术确保模型训练吞吐速度平均提升 1.5 倍以上的同时，在评估任务模式下的单一样本前向 loss 值，预训练/微调任务模式下的 loss 曲线，离线文本生成任务模式下的生成效果这三个方面和 Huggingface 是对齐的，从而确保 Megatron 版模型的可靠性。</p><p style="text-align:justify">另一方面，Megatron 版的 transformer 实现方式提供了一种让用户仅仅通过设置开关就能实现不同种类 GPT 模式的能力。比如 llama 模型打开如下开关即可</p><pre><code>--swiglu \
  --use-rotary-position-embeddings \
  --no-position-embedding \
  --untie-embeddings-and-output-weights \
  --disable-bias-linear</code></pre><p style="text-align:justify">如果想将 llama 模式变成 baichuan 模型，那么仅仅需要添加采用--use-alibi-mask 开关，同时关闭 Rotary Embeeding 开关即可，具体配置如下所示：</p><pre><code>--swiglu \
  --use-alibi-mask \
  --position-embedding-type none \
  --untie-embeddings-and-output-weights \
  --disable-bias-linear</code></pre><p style="text-align:justify">下面我们以 llama-2 为例，详解从 huggingface 到 megatron 的模型权重转换技术。下表总结了两者在不同 module 上的命名对应关系。在 patch 实现过程中，我们首先将 HF 格式的 ckpt 转换到一种内部格式，然后再把这种内部格式转换成对应的外部格式。这样做可以最大程度复用已有的转换逻辑来处理新模型。在转换为内部格式的过程中，</p><p style="text-align:justify">q_proj, k_proj, v_proj 需要沿着第 0 维拼接在一起后赋值给内部变量 query_key_value。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-e3637f10e008e7548046df938ee8bac6_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">当用户在资源受限情况下需要按照 TP&gt;1 来拆分权重的时候，这里需要注意的是针对 MLP 层的 gate_proj 和 up_proj 的操作。不能像 qkv 那样在转换成内部格式的时候进行 merge 再执行算子拆分。需要在拆分前加入如下针对 MLP 层的权重合并的代码逻辑才能确保正确收敛。</p><pre><code>for i in range(tp_size):
    params_dict = get_element_from_dict_by_path(output_state_dict[i],
                                                "model.language_model.encoder")
    dense_h_to_4h_1_name = 'mlp.dense_h_to_4h_1.weight'
    dense_h_to_4h_1_layer_name = f"layers.{layer}.{dense_h_to_4h_1_name}"
    dense_h_to_4h_1_weight = params_dict[dense_h_to_4h_1_layer_name]
    dense_h_to_4h_2_name = 'mlp.dense_h_to_4h_2.weight'
    dense_h_to_4h_2_layer_name = f"layers.{layer}.{dense_h_to_4h_2_name}"
    dense_h_to_4h_2_weight = params_dict[dense_h_to_4h_2_layer_name]
    dense_h_to_4h_name = 'mlp.dense_h_to_4h.weight'
    dense_h_to_4h_layer_name = f"layers.{layer}.{dense_h_to_4h_name}"
    params_dict[dense_h_to_4h_layer_name] = torch.cat(
    [dense_h_to_4h_1_weight, dense_h_to_4h_2_weight], dim=0)</code></pre><span id="OSC_h4_7"></span><h4>基于 TE 的 FP8 训练收敛</h4><p style="text-align:justify">Transformer Engine(TE) 是一个在英伟达 GPUS 上运行的针对 Transformer 模型的加速库，其中包括针对 Hopper GPU 的 FP8 混合精度，该精度可以在较低的显存利用率下提供更好的训练&amp;推理速度。在 TE 内部封装了 Flash Attention 实现，同时 TE 还提供了一组高度优化后的算子用来构建 Transformer 模型。比如 LayerNormLinear 就是将 LayerNorm 和 QKV-Proojection 进行算子融合，LayerNormMLP 就是将 layernorm 和 mlp 进行算子融合。如下图所示：</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-214b47fb7b967d3f92dd7dd58092446b_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">从 Huggingface 到 TE 模型的权重转换技术和之前是类似的，也需要事先找到两者之间的映射关系。从下表可以看出，TE 中多了_extra_state 是用来存 fp8 训练的 scale 和 history 的，这些在加载的时候会出现冲突，这时只要将 load_state_dict 函数的 strict 设置成 False 就可以了，比如 load_state_dict(state_dict_, strict=False)。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-125038fa0f82beec327ee0234b3b79c2_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">在 Megatron-Patch 中使用示例中打开 FP8 混合精度训练开关也很容易，如下所示：</p><pre><code>if [ $PR = fp16 ]; then
    pr_options=" \
        --fp16"
elif [ $PR = bf16 ]; then
    pr_options=" \
        --bf16"
elif [ $PR = fp8 ]; then
    pr_options=" \
        --bf16
        --fp8-hybrid \
        --fp8-amax-compute-algo max \
        --fp8-amax-history-len 1024 \
        --transformer-impl transformer_engine"
fi</code></pre><p style="text-align:justify">我们可以使用如下训练脚本<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fgpt3_llama%2Frun_pretrain_megatron_llama_enwiki.sh%253Fspm%253Da2c6h.13046898.publish-article.5.5d586ffa9uOzwk%2526file%253Drun_pretrain_megatron_llama_enwiki.sh" target="_blank">run_pretrain_megatron_llama_enwiki.sh</a>来测试打开 FP8 开关后的预训练收敛性。下图展示了 llama-7B 和 llama-2-70B 模型在打开和关闭 FP8 时的 loss 曲线对比，可以看出基本是重合的。</p><p style="text-align:justify">LLama-7B</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-6b4c07368bdeb4e3c80251d6972511f1_720w.webp" referrerpolicy="no-referrer"></p><p>LLama2-70B</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-6ed82c26ed8ee7661a913687e7905a6b_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_8"></span><h4>大模型训练&amp;推理</h4><p style="text-align:justify">从 github 上获取 Megatron 模型训练工具 PAI-Megatron-Patch（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%253Fspm%253Da2c6h.13046898.publish-article.6.5d586ffa9uOzwk" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch</a>）源代码并拷贝到工作目录/mnt/workspace/下。</p><p style="text-align:justify"><strong>模型格式转换</strong></p><p style="text-align:justify">使用我们提供的模型转换脚本，将 huggingface 格式的模型文件转换为 megatron 格式：</p><pre><code>cd /mnt/workspace/
mkdir llama2-ckpts
cd llama2-ckpts
wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-ckpts/Llama-2-7b-hf.tgz
tar -zxf Llama-2-7b-hf.tgz
mv Llama-2-7b-hf llama2-7b-hf
cd /mnt/workspace/PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/llama
sh model_convertor.sh \
/root/Megatron-LM-23.04        \
/mnt/workspace/llama2-ckpts/llama2-7b-hf         \
/mnt/workspace/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1  \
1  \
1  \
llama-7b \
0 \
false</code></pre><p style="text-align:justify"><strong>继续预训练</strong></p><p style="text-align:justify">中文继续预训练汉化指引</p><p style="text-align:justify">Step1: 获取需要扩充词表的模型（如 llama-13b-hf）</p><p style="text-align:justify">Step2: 获取需要扩充的词表</p><ul><li>使用 sentence-piece 代码库从自有文本语料中学习词表，得到 randeng-sp.model 文件</li></ul><p style="text-align:justify">Step3: 词表扩充</p><ul><li>扩充模型 tokenizer：将 randeng-sp.model 中的词表添加到 llama-13b-hf 文件夹下 tokenizer.model 中</li><li>扩充模型词表对应的参数矩阵 
  <ul><li>word_embedding、lm_head</li><li>新词向量可以使用原词向量均值作为初始化，比如「天气」=mean([「天」，「气」])</li></ul></li><li>修改与词表大小相关的文件并保存，如 config.json</li></ul><p style="text-align:justify">运行继续预训练脚本&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fllama2%2Frun_pretrain_megatron_llama.sh%253Fspm%253Da2c6h.13046898.publish-article.7.5d586ffa9uOzwk%2526file%253Drun_pretrain_megatron_llama.sh" target="_blank">run_pretrain_megatron_llama.sh</a>，需要传入的参数列表如下</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
MODEL_SIZE=$4                   # 模型结构参数量级：7B, 13B
BATCH_SIZE=$5                   # 每卡训练一次迭代样本数: 4, 8
GLOBAL_BATCH_SIZE=$6            # 全局 batch size
LR=$7                           # 学习率: 1e-5, 5e-5
MIN_LR=$8                       # 最小学习率: 1e-6, 5e-6
SEQ_LEN=$9                      # 序列长度
PAD_LEN=${10}                   # Padding 长度：100
EXTRA_VOCAB_SIZE=${11}          # 词表扩充大小
PR=${12}                        # 训练精度: fp16, bf16
TP=${13}                        # 模型并行度
PP=${14}                        # 流水并行度
AC=${15}                        # 激活检查点模式: sel, full
DO=${16}                        # 是否使用 Megatron 版 Zero-1 降显存优化器: true, false
FL=${17}                        # 是否使用 Flash Attention: true, false
SP=${18}                        # 是否使用序列并行: true, false
SAVE_INTERVAL=${19}             # 保存 ckpt 的间隔
DATASET_PATH=${20}              # 训练数据集路径
PRETRAIN_CHECKPOINT_PATH=${21}  # 预训练模型路径
TRAIN_TOKENS=${22}              # 训练 token 数
WARMUP_TOKENS=${23}             # 预热 token 数
OUTPUT_BASEPATH=${24}           # 训练输出文件路径</code></pre><p style="text-align:justify">注意设置正确的数据集<strong>挂载路径 WORK_DIR</strong>以及<strong>运行环境 ENV</strong>，运行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_pretrain_megatron_llama.sh \
dlc \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B   \
1    \
16 \
1e-5   \
1e-6   \
2048  \
80  \
0   \
fp16  \
1   \
1  \
sel  \
true   \
false  \
false   \
100000  \
${WORK_DIR}/llama2-datasets/wudao/wudao_llamabpe_text_document   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
100000000   \
10000   \
${WORK_DIR}/output_megatron_llama2/</code></pre><p style="text-align:justify"><strong>有监督微调</strong></p><p style="text-align:justify">在微调开始之前，请先进入<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Ftoolkits%2Fpretrain_data_preprocessing%2FREADME.md%253Fspm%253Da2c6h.13046898.publish-article.8.5d586ffa9uOzwk%2526file%253DREADME.md" target="_blank">https://github.com/alibaba/Pai-Megatron-Patch/blob/main/toolkits/pretrain_data_preprocessing/README.md</a>&nbsp;获取 json 文件。运行<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fgithub.com%2Falibaba%2FPai-Megatron-Patch%2Fblob%2Fmain%2Fexamples%2Fllama2%2Frun_finetune_megatron_llama.sh%253Fspm%253Da2c6h.13046898.publish-article.9.5d586ffa9uOzwk%2526file%253Drun_finetune_megatron_llama.sh" target="_blank">run_finetune_megatron_llama.sh</a>脚本，需要传入的参数列表如下</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
MODEL_SIZE=$4                   # 模型结构参数量级: 7B, 13B
BATCH_SIZE=$5                   # 每卡训练一次迭代样本数: 4, 8
LR=$6                           # 学习率: 1e-5, 5e-5
MIN_LR=$7                       # 最小学习率: 1e-6, 5e-6
SEQ_LEN=$8                      # 序列长度
PAD_LEN=$9                      # Padding 长度：100
EXTRA_VOCAB_SIZE=${10}          # 词表扩充大小
PR=${11}                        # 训练精度: fp16, bf16
TP=${12}                        # 模型并行度
PP=${13}                        # 流水并行度
AC=${14}                        # 激活检查点模式: sel, full
DO=${15}                        # 是否使用 Megatron 版 Zero-1 降显存优化器: true, false
FL=${16}                        # 是否使用 Flash Attention: true, false
SP=${17}                        # 是否使用序列并行: true, false
TRAIN_DATASET_PATH=${18}        # 训练数据集路径
VALID_DATASET_PATH=${19}        # 验证数据集路径
PRETRAIN_CHECKPOINT_PATH=${20}  # 预训练模型路径
EPOCH=${21}                     # 训练迭代轮次
OUTPUT_BASEPATH=${22}           # 训练输出文件路径</code></pre><p style="text-align:justify">多节点运行示例如下所示：</p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
sh run_finetune_megatron_llama.sh  \
dlc    \
/root/Megatron-LM-23.04   \
${WORK_DIR}/PAI-Megatron-Patch  \
7B     \
1      \
1e-5   \
1e-6   \
2048   \
80     \
0      \
fp16   \
1      \
1      \
sel    \
true   \
false  \
false  \
${WORK_DIR}/llama2-datasets/wudao_train.json   \
${WORK_DIR}/llama2-datasets/wudao_valid.json   \
${WORK_DIR}/llama2-ckpts/llama2-7b-hf-to-megatron-tp1-pp1   \
2   \
${WORK_DIR}/output_megatron_llama2/
</code></pre><p style="text-align:justify"><strong>离线推理</strong></p><p style="text-align:justify">模型训练完成后，可以进行离线推理，评估模型效果。根据上面的训练流程不同，我们提供了 Megatron 格式的推理链路。对于 Megatron 训练的模型，可以直接用 Megatron 框架进行推理。</p><pre><code>ENV=$1                          # 运行环境: dlc, dsw
MEGATRON_PATH=$2                # 设置开源 Megatron 的代码路径
MEGATRON_PATCH_PATH=$3          # 设置 Megatron Patch 的代码路径
CHECKPOINT_PATH=$4              # 模型微调阶段的模型保存路径
MODEL_SIZE=$5                   # 模型结构参数量级: 1.1B, 1.7B, 7.1B
TP=$6                           # 模型并行度
BS=$7                           # 每卡推理一次迭代样本数: 1, 4, 8
SEQ_LEN=$8                      # 序列长度: 256, 512, 1024
PAD_LEN=$9                      # PAD 长度：需要将文本拼接到的长度
EXTRA_VOCAB_SIZE=${10}          # 模型转换时增加的 token 数量
PR=${11}                        # 推理采用的精度: fp16, bf16
TOP_K=${12}                     # 采样策略中选择排在前面的候选词数量 (0-n): 0, 5, 10, 20
INPUT_SEQ_LEN=${13}             # 输入序列长度: 512
OUTPUT_SEQ_LEN=${14}            # 输出序列长度: 256
INPUT_FILE=${15}                # 需要推理的文本文件: input.txt, 每行为一个样本
OUTPUT_FILE=${16}               # 推理输出的文件: output.txt
# TOP_K 和 TOP_P 必须有一个为 0
TOP_P=${17}                     # 采样策略中选择排在前面的候选词百分比 (0-1): 0, 0.85, 0.95
TEMPERATURE=${18}               # 采样策略中温度惩罚: 1-n
REPETITION_PENALTY=${19}        # 避免生成是产生大量重复，可以设置为 (1-2) 默认为 1.2</code></pre><ul><li>此处提供一个离线推理输出的文件，推理的数据组织形式需要与微调时的保持一致。 
  <ul><li>测试样本：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fatp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com%2Frelease%2Fmodels%2Fpai-megatron-patch%2Fllama2-datasets%2Fpred_input.jsonl%253Fspm%253Da2c6h.13046898.publish-article.10.5d586ffa9uOzwk%2526file%253Dpred_input.jsonl" target="_blank">https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/llama2-datasets/pred_input.jsonl</a></li></ul></li><li>注意： 
  <ul><li>模型保存的路径下缺少 tokenizer 依赖的文件，需要将微调前模型路径下所有 json 文件及 tokenizer.model 拷贝至保存模型的路径下（位于{OUTPUT_BASEPATH }/checkpoint），与 latest_checkpointed_iteration.txt 同级。</li></ul></li></ul><p style="text-align:justify">以下有监督微调过程保存模型的推理代码，需要将 run_text_generation_megatron_llama.sh 脚本中 CUDA_VISIBLE_DEVICES 参数设置为 0；GPUS_PER_NODE 参数设置为 1；同时使用下列代码进行推理。此时使用单卡进行推理。<strong>注意：此处模型 tp 为 1，可使用单卡推理；如果 tp&gt;1，则需使用相应卡数进行推理。</strong></p><pre><code>export WORK_DIR=/mnt/workspace
cd ${WORK_DIR}/PAI-Megatron-Patch/examples/llama2
bash run_text_generation_megatron_llama.sh \
dsw \
/root/Megatron-LM-23.04 \
${WORK_DIR}/PAI-Megatron-Patch \
../../../llama2-train \
7B \
1 \
1 \
1024 \
1024 \
0 \
fp16 \
10 \
512 \
512 \
${WORK_DIR}/pred_input.jsonl \
${WORK_DIR}/llama2_pred.txt \
0 \
1.0 \
1.2</code></pre><span id="OSC_h4_9"></span><h4>大模型强化学习</h4><p style="text-align:justify">一般来说，SFT 微调过的模型在对话场景已经会有不错的表现了。如果想进一步提升模型效果，可以再加上 RLHF 训练。包括奖励模型（Reward Model）的训练和强化学习（PPO）的训练。这里展示了如何使用当前最常用的 RLHF 开源代码框架，DeepSpeed-Chat 和 trlx，来进行奖励函数训练（RM），以及强化学习优化（PPO）。</p><p style="text-align:justify"><strong>模型格式转换</strong></p><p style="text-align:justify">如果基于 huggingface 格式的模型直接进行奖励模型训练（RM）和强化学习优化（PPO），可以跳过此步骤。</p><p style="text-align:justify">如果基于 Megatron 格式的模型，如 PAI-Megatron-Patch 训练好的 SFT 模型，进行 RM 和 PPO 训练，需要使用我们提供的模型转换脚本，先将 Megatron 格式的模型文件转换为 huggingface 格式。</p><p style="text-align:justify">LLaMA2 模型转换：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/gpt3_llama
bash model_convertor.sh \
/path/to/Megatron-LM \
/path/to/megatron_llama2_ckpt \
/path/to/hf_llama2_ckpt \
1 \
1 \
llama-7b \
0 \
true</code></pre><p style="text-align:justify">BLOOM 模型转换：</p><pre><code>cd PAI-Megatron-Patch/toolkits/model_checkpoints_convertor/bloom
bash model_convertor_huggingface_megatron.sh \
/path/to/Megatron-LM \
/path/to/megatron_bloom_ckpt \
/path/to/hf_bloom_ckpt \
1 \
1 \
true</code></pre><p style="text-align:justify"><strong>DeepSpeed-Chat</strong></p><p style="text-align:justify">下载安装开源社区 DeepSpeed-Chat 源代码：</p><pre><code>cd PAI-Megatron-Patch/rlhf/deepspeed-chat
git clone https://github.com/microsoft/DeepSpeedExamples.git
cp -f rm_main.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/main.py
cp -f utils.py DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/utils.py
cd DeepSpeedExamples/applications/DeepSpeed-Chat/
pip install -r requirements.txt</code></pre><p style="text-align:justify">基于 LLaMA2 模型训练奖励模型（RM）：</p><pre><code>cd training/step2_reward_model_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b.sh</code></pre><p style="text-align:justify">基于 LLaMA2 进行强化学习优化训练（PPO）：</p><pre><code>cd training/step3_rlhf_finetuning/ &amp;&amp; bash training_scripts/llama2/run_llama2_7b_lora.sh</code></pre><p style="text-align:justify"><strong>trlx</strong></p><p style="text-align:justify">下载安装开源社区 trlx 源代码：</p><pre><code>cd PAI-Megatron-Patch/rlhf/trlx
git clone https://github.com/CarperAI/trlx.git
cp trlx_bloom_rlhf.py trlx_bloom_rlhf_test.py trlx/examples/summarize_rlhf/
cp train_reward_model_bloom.py reward_model_bloom.py ds_config_bloom.json trlx/examples/summarize_rlhf/reward_model/
cp -f ds_config_trlx_gptj_summarize.json trlx/examples/summarize_rlhf/configs/
cd trlx
pip install -e .</code></pre><p style="text-align:justify">基于 BLOOM 模型训练奖励模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_bloom.py</code></pre><p style="text-align:justify">基于 GPT-J 模型训练奖励模型（RM）：</p><pre><code>cd examples/summarize_rlhf/reward_model/ &amp;&amp; deepspeed train_reward_model_gptj.py</code></pre><p style="text-align:justify">基于 BLOOM 模型进行强化学习优化训练（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf.py</code></pre><p style="text-align:justify">基于 GPT-J 模型进行强化学习优化训练（PPO）：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_gptj_text_summarization.py</code></pre><p style="text-align:justify">PPO 单测</p><p style="text-align:justify">如果您想跳过，有监督微调（SFT）与，奖励模型训练（RM）两个步骤，只单独测试 PPO 模块的性能，可以运行如下指令单测 PPO：</p><pre><code>cd examples/summarize_rlhf/ &amp;&amp; accelerate launch --config_file configs/default_accelerate_config.yaml trlx_bloom_rlhf_test.py</code></pre><span id="OSC_h3_10"></span><h3>开源生态——构想和未来</h3><p style="text-align:justify">在 PAI-Megatron-Patch 的开发过程中，我们围绕中文大模型训练加速落地沉淀了以下几个方面的内容：</p><ul><li>Huggingface 的模型权重无损转换成 Megatron 或者 Transformer Engine 可读的模型权重。</li><li>H800 集群开启 FP8 混合精度训练确保收敛。</li><li>LLM 大模型在 PAI 灵骏智算平台上的最佳实践。</li><li>强化学习技术在 PAI 灵骏智算平台上的最佳实践。</li></ul><p style="text-align:justify">后续在 PAI-Megatron-Patch 中还会陆续放出更多高质量的大模型和最佳实践。</p><span id="OSC_h3_11"></span><h3>参考文献</h3><p style="text-align:justify">[1]. Attention Is All You Need</p><p style="text-align:justify">[2]. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</p><p style="text-align:justify">[3]. Reducing Activation Recomputation in Large Transformer Models</p><p style="text-align:justify">[4]. FP8 Formats for Deep Learning</p><p style="text-align:justify">[5]. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</p><p style="text-align:justify">[6]. LLaMA: Open and Efficient Foundation Language Models</p><p style="text-align:justify">[7]. Llama 2: Open Foundation and Fine-Tuned Chat Models</p><p style="text-align:justify">[8]. Benchmarking Large Language Models on NVIDIA H100 GPUs with CoreWeave</p><blockquote><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fclick.aliyun.com%2Fm%2F1000373503%2F" target="_blank"><span style="color:#e67e22">点击立即免费试用云产品，开启云上实践之旅！</span></a></strong></blockquote><p style="text-align:justify"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1337652%3Futm_content%3Dg_1000381155" target="_blank">原文链接</a></strong></p><p style="text-align:justify"><strong>本文为阿里云原创内容，未经允许不得转载。</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/yunqi/blog/10115767</guid>
            <link>https://my.oschina.net/yunqi/blog/10115767</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenJDK 合并英特尔 x86-simd-sort，将数据排序速度提高 7-15 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">今年早些时候，英特尔发布了<span style="background-color:#ffffff">一个利用了 AVX-512 的 x86-simd-sort 快速排序库</span>；当 Numpy 将 <span style="background-color:#ffffff">x86-simd-sort 代码进行合并后发现</span>，对于 16 位到 64 位的数据类型，排序速度提高了 10~17 倍。如今，英特尔软件工程师又发布了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fx86-simd-sort%2Freleases%2Ftag%2Fv3.0" target="_blank">x86-simd-sort 3.0</a>，OpenJDK 也已经将这一修改版进行了合并。</span></p><p><img height="254" src="https://oscimg.oschina.net/oscnet/up-e6ce9bf7b77cccf7d2121e07398176707ac.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">x86-simd-sort 3.0 添加了一个新的「avx512_argselect」方法</span><span style="background-color:#ffffff; color:#000000">，用于</span><span style="color:#000000">计算 arg nth_element，该</span><span style="background-color:#ffffff; color:#000000">方法</span><span style="color:#000000">返回一个对数据数组进行分区的索引数组。x86-simd-sort 3.0 版本还对其 benchmarks 进行了改进，现在使用 __builtin_cpu_supports 而不是 querying cpuinfo，</span><span style="background-color:#ffffff; color:#000000">并进行了各种其他更改。</span><br><br><span style="color:#000000">目前，x86-simd-sort 3.0 已合并至&nbsp;Numpy 主分支中，它提供了 np.partition 和 np.argpartition 的 AVX-512 矢量化版本。将 np.partition 的 16 位速度提高了 25 倍，将 32 位 dtypes 的速度提高了 17 倍，将 64 位 dtypes 的速度提高了约 8 倍。与此同时，<span style="background-color:#ffffff">新的 avx512_argselect 方法还使&nbsp;</span>np.argpartition 的速度提高了 6.5 倍。</span></p><p><span style="color:#000000">并入 OpenJDK 的 x86-simd-sort 是一个略有修改的版本，该版本将 <span style="background-color:#ffffff">32 位数据排序速度提高了 15 倍，64 位数据排序速度提高了约 7 倍。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">更多详情<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenjdk%2Fjdk%2Fpull%2F14227" target="_blank">可查看此处</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260605/intel-x86-simd-sort-3-0-openjdk</guid>
            <link>https://www.oschina.net/news/260605/intel-x86-simd-sort-3-0-openjdk</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 遭「卡脖子」，OpenAI 计划自研 AI 芯片]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start">根据&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F06%2Fopenai-said-to-be-considering-developing-its-own-ai-chips%2F%3Fguccounter%3D1%26guce_referrer%3DaHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS5oay8%26guce_referrer_sig%3DAQAAAL3fVeW5BS1z3Z9olNE6c2iybavGH0APpfPZxySiJi7WUXe83N7739IvRls5vIwuXKyA2eYoWcTiKlUTh7jVhzMkKKxJTSaY_n4awPm8XvK2tXu2OjLfdsRALDvUWwB1idflbNBNoRwu_fzD-uhZrxP90RGZfxjBWi5mEUiKzpMc" target="_blank">TechCrunch</a>&nbsp;的报道，随着 AI 芯片短缺的问题日益严重，OpenAI 现已开始考虑自研 AI 芯片。</p><p style="color:#000000; text-align:start">据悉，从去年开始 OpenAI 内部就已经开始讨论 AI 芯片战略，以解决其 AI 芯片短缺的问题。这些方案包括自研 AI 芯片、与英伟达等芯片制造商展开更紧密的合作、实现供应商多元化等。</p><p>OpenAI 首席执行官 Sam Altman 去年就公开抱怨英伟达 GPU 芯片稀缺，称公司受到 GPU 的严重限制。</p><p>由于英伟达主导了全球 95% 的 Al 训练领域市场，随着英伟达 GPU 显卡稀缺，加上 AI 算力成本持续攀升，即便强如 OpenAI 也在寻找新方案，从而避免长期被「卡脖子」。</p><p style="color:#000000; text-align:start">报道称，该公司尚未决定继续推进。Sam Altman 此前表示已将收购更多 AI 芯片作为公司的首要任务。</p><p style="color:#000000; text-align:start"><img alt="" src="https://static.oschina.net/uploads/space/2023/1007/112609_aSEr_2720166.jpeg" referrerpolicy="no-referrer"></p><p style="color:#000000; text-align:start">OpenAI 和大多数竞争对手一样，依赖基于 GPU 的硬件来开发 ChatGPT、GPT-4 和 DALL-E 3 等模型。GPU 能够并行执行许多计算，因此非常适合训练当今最强大的人工智能。</p><p style="color:#000000; text-align:start">不过 GPU 等芯片目前面临严重短缺的问题，据报道，英伟达性能最好的人工智能芯片在 2024 年之前都已售罄。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 03:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260598</guid>
            <link>https://www.oschina.net/news/260598</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CoDeF —— 强时序一致性视频处理算法]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CoDeF 是能够高度保持视频时序一致性的的视频处理算法，可以轻松完成视频风格迁移、视频关键点追踪（包括流体）、用户自定义的视频内容编辑等任务。</p><p>CoDeF 支持将图像风格化算法升级为视频风格化算法，将图像关键点检测算法升级为视频关键点跟踪算法（甚至包括水和烟雾等非刚性物体的追踪），将图像语义分割算法升级为视频物体跟踪算法，将图像超分算法升级为视频超分算法，同时支持用户可交互的视频内容编辑。</p><p><img src="https://oscimg.oschina.net/oscnet/up-86a32563b77d2c6eaf06e2b3c03c320f292.gif" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/codef</guid>
            <link>https://www.oschina.net/p/codef</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推荐 | 字符串插值变量处理工具库 FlexVars]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-flexvars" class="anchor" href="https://gitee.com/zhangfisher/flexvars#flexvars"></a>FlexVars</h1><p>Powerful string interpolation tool library</p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fzhangfisher.github.io%2Fflexvars%2F%23%2Fcn%2Freadme">中文</a><a href="https://gitee.com/link?target=https%3A%2F%2Fzhangfisher.github.io%2Fflexvars%2F%23%2Fen%2Freadme">English</a></p><h2><a id="user-content-features" class="anchor" href="https://gitee.com/zhangfisher/flexvars#features"></a>Features</h2><p>-Supports positional and dictionary interpolation
-Supports multiple error handling mechanisms
-Support for null value processing mechanism
-Support filter chain processing of input variable values
-Support variable prefix suffix
-98%+unit test coverage</p><h2><a id="user-content-getting-started" class="anchor" href="https://gitee.com/zhangfisher/flexvars#getting-started"></a>Getting Started</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="k">import</span><span class="p">{</span><span class="nx">FlexVars</span><span class="p">}</span><span class="k">from</span><span class="dl">"</span><span class="s2">flexvars</span><span class="dl">"</span></span><span id="LC2" class="line"></span><span id="LC3" class="line"><span class="kd">const</span><span class="nx">flexvars</span><span class="o">=</span><span class="k">new</span><span class="nx">FlexVars</span><span class="p">({</span></span><span id="LC4" class="line"><span class="na">filters</span><span class="p">:{</span></span><span id="LC5" class="line"><span class="na">currency</span><span class="p">:{</span></span><span id="LC6" class="line"><span class="na">args</span><span class="p">:[</span><span class="dl">"</span><span class="s2">prefix</span><span class="dl">"</span><span class="p">,</span><span class="dl">"</span><span class="s2">suffix</span><span class="dl">"</span><span class="p">,</span><span class="dl">"</span><span class="s2">sign</span><span class="dl">"</span><span class="p">],</span></span><span id="LC7" class="line"><span class="na">default</span><span class="p">:{</span><span class="na">prefix</span><span class="p">:</span><span class="dl">"</span><span class="s2">USD </span><span class="dl">"</span><span class="p">,</span><span class="na">suffix</span><span class="p">:</span><span class="dl">""</span><span class="p">,</span><span class="na">sign</span><span class="p">:</span><span class="dl">"</span><span class="s2">$</span><span class="dl">"</span><span class="p">}</span></span><span id="LC8" class="line"><span class="nl">next</span><span class="p">:(</span><span class="na">value</span><span class="p">:</span><span class="kr">any</span><span class="p">,</span><span class="na">args</span><span class="p">:</span><span class="nb">Record</span><span class="o">&lt;</span><span class="kr">string</span><span class="p">,</span><span class="kr">any</span><span class="o">&gt;</span><span class="p">,</span><span class="na">context</span><span class="p">:</span><span class="nx">FlexFilterContext</span><span class="p">)</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC9" class="line"><span class="k">return</span><span class="s2">`</span><span class="p">${</span><span class="nx">args</span><span class="p">.</span><span class="nx">prefix</span><span class="p">}${</span><span class="nx">args</span><span class="p">.</span><span class="nx">sign</span><span class="p">}${</span><span class="nx">value</span><span class="p">}${</span><span class="nx">args</span><span class="p">.</span><span class="nx">suffix</span><span class="p">}</span><span class="s2">`</span></span><span id="LC10" class="line"><span class="p">}</span></span><span id="LC11" class="line"><span class="p">}</span></span><span id="LC12" class="line"><span class="p">}</span></span><span id="LC13" class="line"><span class="p">})</span></span><span id="LC14" class="line"></span><span id="LC15" class="line"><span class="kd">const</span><span class="nx">_</span><span class="o">=</span><span class="nx">flexvars</span><span class="p">.</span><span class="nx">replace</span></span><span id="LC16" class="line"></span><span id="LC17" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello {}</span><span class="dl">"</span><span class="p">,</span><span class="dl">"</span><span class="s2">flexvars</span><span class="dl">"</span><span class="p">))</span></span><span id="LC18" class="line"><span class="c1">// =&gt; hello flexvars</span></span><span id="LC19" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">I am {}</span><span class="dl">"</span><span class="p">,</span><span class="dl">"</span><span class="s2">tom</span><span class="dl">"</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">I am tom</span><span class="dl">"</span><span class="p">)</span></span><span id="LC20" class="line"><span class="c1">// =&gt; I am tom</span></span><span id="LC21" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">{ value | currency}</span><span class="dl">"</span><span class="p">,</span><span class="mi">100</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">USD $100</span><span class="dl">"</span><span class="p">))</span></span><span id="LC22" class="line"><span class="c1">// =&gt; USD $100</span></span><span id="LC23" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">{ value | currency('RMB','￥','元')}</span><span class="dl">"</span><span class="p">,</span><span class="mi">100</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">RMB ￥100 元</span><span class="dl">"</span><span class="p">))</span><span class="c1">// </span></span><span id="LC24" class="line"><span class="c1">// =&gt; RMB ￥100 元</span></span><span id="LC25" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">{ value | currency({prefix:'EUR '',suffix:''',sign:'€'})}</span><span class="dl">"</span><span class="p">,</span><span class="mi">100</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">RMB €100</span><span class="dl">"</span><span class="p">))</span></span><span id="LC26" class="line"><span class="c1">// =&gt; EUR €100</span></span><span id="LC27" class="line"></span><span id="LC28" class="line"><span class="nx">flexvars</span><span class="p">.</span><span class="nx">addFilter</span><span class="p">({</span></span><span id="LC29" class="line"><span class="na">name</span><span class="p">:</span><span class="dl">"</span><span class="s2">add</span><span class="dl">"</span><span class="p">,</span></span><span id="LC30" class="line"><span class="na">args</span><span class="p">:[</span><span class="dl">"</span><span class="s2">step</span><span class="dl">"</span><span class="p">],</span></span><span id="LC31" class="line"><span class="na">default</span><span class="p">:{</span><span class="na">step</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span></span><span id="LC32" class="line"><span class="nx">next</span><span class="p">(</span><span class="na">value</span><span class="p">:</span><span class="kr">any</span><span class="p">,</span><span class="na">args</span><span class="p">:</span><span class="nb">Record</span><span class="o">&lt;</span><span class="kr">string</span><span class="p">,</span><span class="kr">any</span><span class="o">&gt;</span><span class="p">,</span><span class="na">context</span><span class="p">:</span><span class="nx">FlexFilterContext</span><span class="p">){</span></span><span id="LC33" class="line"><span class="k">return</span><span class="nb">parseInt</span><span class="p">(</span><span class="nx">value</span><span class="p">)</span><span class="o">+</span><span class="nx">args</span><span class="p">.</span><span class="nx">step</span></span><span id="LC34" class="line"><span class="p">}</span></span><span id="LC35" class="line"><span class="p">})</span></span><span id="LC36" class="line"><span class="c1">// call chaining</span></span><span id="LC37" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">{ value | add}</span><span class="dl">"</span><span class="p">,</span><span class="mi">100</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">101</span><span class="dl">"</span><span class="p">)</span></span><span id="LC38" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">{ value | add|add }</span><span class="dl">"</span><span class="p">,</span><span class="mi">100</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">102</span><span class="dl">"</span><span class="p">)</span></span><span id="LC39" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">{ value | add(2)|add(3) }</span><span class="dl">"</span><span class="p">,</span><span class="mi">100</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">105</span><span class="dl">"</span><span class="p">)</span></span><span id="LC40" class="line"><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">_</span><span class="p">(</span><span class="dl">"</span><span class="s2">{ value | add(2)|add(3)|add(4) }</span><span class="dl">"</span><span class="p">,</span><span class="mi">100</span><span class="p">)).</span><span class="nx">toBe</span><span class="p">(</span><span class="dl">"</span><span class="s2">109</span><span class="dl">"</span><span class="p">)</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 02:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/zhangfisher/flexvars</guid>
            <link>https://gitee.com/zhangfisher/flexvars</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 买彩票能中大奖？用 Java 盘点常见的概率悖论]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>引言</h1><p>《双色球头奖概率与被雷劈中的概率哪个高？》</p><p>《3 人轮流射击，枪法最差的反而更容易活下来？》</p><p>让我们用 Java 来探索 ta 们！</p><span id="OSC_h1_2"></span><h1>悖论 1：著名的三门问题</h1><p><strong>规则描述</strong>：你正在参加一个游戏节目，你被要求在三扇门中选择一扇：其中一扇后面有一辆车；其余两扇后面则是山羊。你选择了一道门，假设是一号门，然后知道门后面有什么的主持人，开启了另一扇后面有山羊的门，假设是三号门。他然后问你：「你想选择二号门吗？请问若想获得车，参赛者应该换二号门吗？</p><p><img alt="" src="https://mp.toutiao.com/mp/agw/article_material/open_image/get?code=ZjdjNjc4YjA2ZDYwMTE0MjNiYmViZTFjN2ZkMDQxZWIsMTY5NDA3OTk1MDA0Ng==" referrerpolicy="no-referrer"></p><p><strong>论证</strong>：分析需求，拆解为如下代码</p><pre><code>/**
 * &lt;p&gt; 三门问题解决方案 &lt;/p&gt;
 * @author yuanfeng.wang
 * @since 2023/8/29
 */
import java.util.Random;

public class ThreeDoorSolution {

    public static void main(String[] args) {
        // 模拟执行 1 万次，打印获胜的概率
        threeDoor(10000);
    }

    /**
     * 三门问题逻辑拆解
     * @param numSimulations 总共执行多少轮游戏
     */
    private static void threeDoor(int numSimulations) {
        int switchWins = 0;
        int stayWins = 0;

        Random random = new Random();
        for (int i = 0; i &lt; numSimulations; i++) {
            // 随机确定车所在的门
            int carDoor = random.nextInt(3);

            // 玩家随机选择一扇门
            int playerChoice = random.nextInt(3);

            // 主持人随机打开一扇门：要求该门不是玩家选择的，且必须是羊
            int openedDoor;
            do {
                openedDoor = random.nextInt(3);
            } while (openedDoor == carDoor || openedDoor == playerChoice);

            // 换门后的选择：不能是打开的门，不能是玩家选择的门，则是交换之后的门
            int finalChoice;
            do {
                finalChoice = random.nextInt(3);
            } while (finalChoice == playerChoice || finalChoice == openedDoor);

            // 计算是否换门获胜
            if (finalChoice == carDoor) {
                switchWins++;
            }

            // 计算不换门获胜
            if (playerChoice == carDoor) {
                stayWins++;
            }
        }

        // 输出结果
        System.out.println("在 " + numSimulations + " 次模拟中：");
        System.out.println("换门获胜的概率：" + (double) switchWins / numSimulations);
        System.out.println("不换门获胜的概率：" + (double) stayWins / numSimulations);
    }
}
// 模拟运行，打印结果如下
// 在 10000 次模拟中：
// 换门获胜的概率：0.6679
// 不换门获胜的概率：0.3321

</code></pre><p><strong>结论</strong>：三门问题看似一道简单的概率题，几十年来却一直引发巨大争议，持两种不同观点的人基本是五五开；事实上始终选择换门的玩家，获胜的概率 2/3，而保持原方案的胜率只有 1/3</p><span id="OSC_h1_3"></span><h1>悖论 2：双色球我能中大奖</h1><p><strong>规则描述</strong>：从 1-33 个红色球中随机选出 6 个，再从 1-16 个蓝色球中随机选择 1 个，最终开奖出一注 6+1 组合球，无顺序要求；</p><ul><li>一等奖：中 6 红 + 1 蓝</li><li>二等奖：中 6 红</li><li>三等奖：中 5 红 + 1 蓝</li><li>四等奖：中 4 红 + 1 蓝，或只中 5 个红</li><li>五等奖：中 3 红 + 1 蓝，或只中 4 个红</li><li>六等奖：中 1 蓝</li></ul><p><strong>论证</strong>：分析玩法，计算一等奖中奖率，从 33 个红球样本中选择 6 个，计算总共的组合数，即数学公式 C(n, m) = n!/((n-m)! * m!)，代入计算 C(33, 6) = 33!/((33-6)! * 6!) = 1107568，再乘以 16，最终得出一等奖获奖概率 1/17721088。</p><p>分析规则，以下代码展示了开奖一次，购买 N 注时，打印中奖信息的程序，当代入 N=500 万时，多次执行，可以很轻松打印出一等奖</p><pre><code>
import java.util.*;

/**
 * &lt;p&gt;双色球随机模拟&lt;/p&gt;
 * @author yuanfeng.wang
 * @since 2023/8/29
 */
public class SsqSolution {

    private static Random random = new Random();

    /**
     * 开奖的红球
     */
    private static Set&lt;Integer&gt; winningRedBalls;

    /**
     * 开奖的蓝球
     */
    private static int winningBlueBall;

    // 静态块初始化一组开奖号码
    static {
        // 篮球 01-16
        winningBlueBall = random.nextInt(16) + 1;

        // 红球 01-33 生成 6 个
        winningRedBalls = new HashSet&lt;&gt;();
        while (winningRedBalls.size() &lt; 6) {
            int num = random.nextInt(33) + 1;
            winningRedBalls.add(num);
        }
    }

    public static void main(String[] args) {
        play(500_0000);
    }

    /**
     *
     * @param num 运行一次程序只开一次奖，此参数表示总共购买多少注
     */
    public static void play(int num) {
        System.out.println("\n 本期开奖号码：");
        System.out.println("红球：" + winningRedBalls + " 篮球：" + winningBlueBall);
        for (int i = 0; i &lt; num; i++) {
            playOnce();
        }
    }

    private static void playOnce() {
        Set&lt;Integer&gt; userRedBalls = getUserSelectedRedBalls();
        int userBlueBall = getUserSelectedBlueBall();

        int redBallMatch = countMatchingBalls(userRedBalls, winningRedBalls);
        boolean blueBallMatch = (userBlueBall == winningBlueBall);

        if (redBallMatch == 6 &amp;&amp; blueBallMatch) {
            System.out.println("\n 恭喜你中了一等奖！");
            System.out.println("玩家购买的号码：");
            System.out.println("红球：" + userRedBalls + " 蓝球：" + userBlueBall);
        } else if (redBallMatch == 6) {
            System.out.println("\n 恭喜你中了二等奖！");
        } else if (redBallMatch == 5 &amp;&amp; blueBallMatch) {
//            System.out.println("\n 恭喜你中了三等奖！");
        } else if (redBallMatch == 5 || (redBallMatch == 4 &amp;&amp; blueBallMatch)) {
//            System.out.println("\n 恭喜你中了四等奖！");
        } else if (redBallMatch == 4 || (redBallMatch == 3 &amp;&amp; blueBallMatch)) {
//            System.out.println("\n 恭喜你中了五等奖！");
        } else if (blueBallMatch) {
//            System.out.println("\n 恭喜你中了最小奖！");
        } else {
            //没中奖，不打印记录
        }
    }

    /**
     * 返回玩家选择的 6 个红球,范围 1-33，不重复
     */
    private static Set&lt;Integer&gt; getUserSelectedRedBalls() {
        Set&lt;Integer&gt; userRedBalls = new HashSet&lt;&gt;();
        while (userRedBalls.size() &lt; 6) {
            int num = random.nextInt(33) + 1;
            userRedBalls.add(num);
        }
        return userRedBalls;
    }

    /**
     * 玩家选择的 1 个蓝球,范围 1-16
     */
    private static int getUserSelectedBlueBall() {
        return random.nextInt(16) + 1;
    }

    /**
     * 匹配中了几个红球
     * @return 中红球个数
     */
    private static int countMatchingBalls(Set&lt;Integer&gt; userBalls, Set&lt;Integer&gt; winningBalls) {
        int count = 0;
        for (int ball : userBalls) {
            if (winningBalls.contains(ball)) {
                count++;
            }
        }
        return count;
    }

}

</code></pre><p><strong>结论</strong>：排除其它因素，头奖概率约 1700 万分之 1，这个结论并不直观，例举如下几个进行对比</p><p>1.一家祖孙三代人的生日都在同一天的概率约为 27 万分之一</p><p>2.小行星撞击地球的概率保守推测是 200 万分之一</p><p>3.生出全男或全女四胞胎的概率约为 352 万分之一</p><span id="OSC_h1_4"></span><h1>悖论 3：三个枪手</h1><p><strong>描述</strong>：三个小伙子同时爱上了一个姑娘，为了决定他们谁能娶这个姑娘，他们决定用枪进行一次决斗。A 的命中率是 30％，B 比他好些，命中率是 50％，最出色的枪手是 C，他从不失误，命中率是 100％。由于这个显而易见的事实，为公平起见，他们决定按这样的顺序：A 先开枪，B 第二，C 最后。然后这样循环，直到他们只剩下一个人。那么 A 第一枪应该怎么打？谁活下来的概率最大？</p><p><strong>论证</strong>：每个人的目标都是活下来，为了目标寻找最好的策略。以下开始分人讨论</p><p><strong>A：</strong></p><ul><li>若 A 开枪射杀了 B，则下个开枪是 C，C 会 100% 射杀 A，这不是一个好策略</li><li>若 A 开枪射杀了 C，则下一轮 B 会有 50% 的几率杀掉自己</li><li>若 A 开枪未打中，则下一轮可以坐山观虎斗，所以 A 最好的策略看似是故意打空枪更好一些</li></ul><p><strong>B：</strong></p><ul><li>若 A 已经将 C 射杀，此时 B 与 A 互相射击，B 的生存率高于 A</li><li>B 只能选择射杀 C，因为只要 C 活着，都会优先射杀 B</li></ul><p><strong>C：</strong></p><ul><li>先消除威胁大的 B，然后再杀掉 A，只要自己有开 2 枪的机会，直接获胜</li></ul><p><strong>结论</strong>：需求太复杂，暂未实现生存概率计算😭，欢迎补充悖论 3 的代码论证过程</p><blockquote><p>作者：京东保险&nbsp;王苑沣</p><p>来源：京东云开发者社区，转载请注明来源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10109696</guid>
            <link>https://my.oschina.net/u/4090830/blog/10109696</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[KubeSphere 社区双周报 | OpenFunction v1.2.0 发布]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>KubeSphere 社区双周报主要整理展示新增的贡献者名单和证书、新增的讲师证书以及两周内提交过 commit 的贡献者，并对近期重要的 PR 进行解析，同时还包含了线上/线下活动和布道推广等一系列社区动态。</p><p>本次双周报涵盖时间为：2023.09.15-2023.09.28。</p><h2>贡献者名单</h2><p><img src="https://oscimg.oschina.net/oscnet/up-cce05b68864a3f222cd17e6df1aa1c3655b.gif" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-7e6818d775388b1291392b3250789734a38.png" alt="" referrerpolicy="no-referrer"></p><h2>新晋 KubeSphere Contributor</h2><p>两周内共有 2 位新晋 KubeSphere Contributor，感谢各位对 KubeSphere 社区的贡献！</p><p><img src="https://oscimg.oschina.net/oscnet/up-ca0b0945c103e0492a91de92a5132784bea.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-e3ad1819572baf498ffd15433cf938b034d.png" alt="" referrerpolicy="no-referrer"></p><h2>近期更新</h2><h3>KubeSphere</h3><h4>1. 支持通过 IP 搜索 pod</h4><p>相关 PR：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fpull%2F5921" target="_blank">https://github.com/kubesphere/kubesphere/pull/5921</a></p><p>贡献者：zhou1203</p><h3>OpenFunction</h3><h4>1. 发布了 OpenFunction v1.2.0，支持使用 keda-addons-http 作为同步函数运行时</h4><p>相关 Release: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenFunction%2FOpenFunction%2Freleases%2Ftag%2Fv1.2.0" target="_blank">https://github.com/OpenFunction/OpenFunction/releases/tag/v1.2.0</a></p><p>贡献者：wrongerror</p><h4>2. 升级 OpenFunction Chart 依赖组件 Dapr, Keda 以及 contour 的版本</h4><p>相关 PR: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenFunction%2Fcharts%2Fpull%2F51" target="_blank">https://github.com/OpenFunction/charts/pull/51</a></p><p>贡献者：wrongerror</p><h3>KubeKey</h3><h4>1. 支持部署 Kubernetes v1.27+</h4><p>相关 PR: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubekey%2Fpull%2F2000" target="_blank">https://github.com/kubesphere/kubekey/pull/2000</a></p><p>贡献者：pixiake</p><h4>2. 支持部署高可用 Harbor</h4><p>相关 PR：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubekey%2Fpull%2F1992" target="_blank">https://github.com/kubesphere/kubekey/pull/1992</a></p><p>贡献者：wenwenxiong</p><blockquote><p>本文由博客一文多发平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 发布！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 06 Oct 2023 02:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/10115731</guid>
            <link>https://my.oschina.net/u/4197945/blog/10115731</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[越来越多开源项目停更，Java 生态受影响最大]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">Sonatype&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.sonatype.com%2Fintroducing-our-9th-annual-state-of-the-software-supply-chain-report" target="_blank">发布</a>了最新的一份</span>《软件供应链状况》报告，深入探讨了如何在充满选择的世界中定义更好的软件，并探讨人工智能 (AI) 对软件开发的深远影响；还研究了开源供应、需求和安全之间错综复杂的相互作用。</p><p>报告跟踪了 Java (Maven)、JavaScript (npm)、Python (PyPI)、.NET (NuGet Gallery) 四大开源生态系统的开源应用增长情况。2022 年至 2023 年间，可用开源项目的数量平均增长了 29%。2023 年，开源项目平均发布了 15 个可供使用的版本，不同开源注册中心的特定生态系统平均有 10 到 22 个版本。这意味着每个月都会发布 1-2 个新版本，在观察到的生态系统中总共发布了 6000 万个新版本。</p><p><img height="293" src="https://oscimg.oschina.net/oscnet/up-a3af85a689f0adbcfb8236b4dac77b7f235.png" width="500" referrerpolicy="no-referrer"></p><p>每个受检测的生态系统都表现出一致的项目增长率，平均同比增长率高达 29%。</p><p><img height="295" src="https://oscimg.oschina.net/oscnet/up-9ab7acc5786b753b241922eeaa519953a3d.png" width="500" referrerpolicy="no-referrer"></p><p>但随着开源组件供应量的持续增长，其需求却未能与之同步。在过去两年中，下载量的增长率逐渐下降。2023 年的平均增长率为 33%，与 2021 年 73% 的增长率相比大幅下降。</p><p><span style="color:#000000">与此同时，开源软件安全问题没有放缓的迹象。截至 2023 年 9 月，研究团队共发现了&nbsp;245,032 个恶意软件包，是往年总和的 2 倍。八分之一的开源下载存在已知风险，且仍有 23% 的 Log4j 下载存在严重漏洞。</span></p><p><img height="304" src="https://oscimg.oschina.net/oscnet/up-b8b946760f70163d67ebbf53b91a14930fd.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">开源项目的主动维护也变得越来越少。研究表明，去年有近五分之一（18.6%）的项目停止维护，影响了 Java 和 JavaScript 生态系统。<span style="background-color:#ffffff">只有 11% 的开源项目实际上得到了积极维护。</span>尽管存在这些缺陷，但 Sonatype 仍然表示，近 96% 存在已知漏洞的组件下载可以通过选择无漏洞版本来避免。</span></p><p><span style="color:#000000">就软件开发中的人工智能而言，97% 的受访 DevOps 和 SecOps 领导者表示，他们目前在工作流程中某种程度上使用了人工智能，大多数人每天使用两个或更多工具。</span><span><span><span><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>去年，企业环境中 AI 和 ML 组件的采用率增加了 135%。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">研究还发现，企业自认为的安全程度与实际情况之间存在脱节。67% 的公司表示，他们确信自己的系统中没有来自漏洞库的代码，但今年有 10% 的公司因漏洞组件而遭遇安全漏洞。39% 的公司可以在</span><span style="background-color:#ffffff">&nbsp;1 到 7 天的时间内发现漏洞，29% 的公司需要一周以上的时间，28% 的公司只需要不到一天的时间。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sonatype.com%2Fstate-of-the-software-supply-chain%2Fintroduction" target="_blank">查看完整报告</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 05 Oct 2023 04:46:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260454/9th-annual-state-of-the-software-supply-chain-report</guid>
            <link>https://www.oschina.net/news/260454/9th-annual-state-of-the-software-supply-chain-report</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
