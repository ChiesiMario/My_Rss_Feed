<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 29 Jan 2024 07:01:25 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[百川智能发布超千亿大模型 Baichuan 3，中文评测超越 GPT-4]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1 月 29 日，百川智能发布超千亿参数的大语言模型 Baichuan 3。</p><p>链接：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.baichuan-ai.com%2F" target="_blank">https://www.baichuan-ai.com/</a></u></em></p><p>据称在多个权威通用能力评测如 CMMLU、GAOKAO 和 AGI-Eval 中，Baichuan 3 都展现了出色的能力，<strong>尤其在中文任务上更是超越了 GPT-4</strong>。而在数学和代码专项评测如 MATH、HumanEval 和 MBPP 中同样表现出色。</p><p><img src="https://oscimg.oschina.net/oscnet/up-4943e22112dc10bfbb4d4346b8b76cb1448.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-df748cfd41a08e601ad56b92c70ee27d974.png" referrerpolicy="no-referrer"></p><p>不仅如此，其在对逻辑推理能力及专业性要求极高的 MCMLE、MedExam、CMExam 等权威医疗评测上的中文效果同样超过了 GPT-4，是中文医疗任务表现最佳的大模型。Baichuan 3 还突破「迭代式强化学习」技术，进一步提升了语义理解和生成能力，在诗词创作的格式、韵律、表意等方面表现优异，领先于其他大模型。</p><p>在测试逻辑推理能力的 MCMLE、MedExam、CMExam 等医疗评测上，Baichuan 3 的中文效果同样号称超过了 GPT-4，是「中文医疗任务表现最佳的大模型」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c58c3189e812e73b513f6f5f311965c43f5.png" referrerpolicy="no-referrer"></p><p>据介绍，百川智能在 Baichuan 3 训练过程中提出了「动态数据选择」、「重要度保持」以及「异步 CheckPoint 存储」等多种技术手段及方案，稳定训练时间达到一个月以上，故障恢复时间不超过 10 分钟。</p><p>百川智能表示，Baichuan 3 还突破「迭代式强化学习」技术，进一步提升了语义理解和生成能力，在诗词创作的格式、韵律、表意等方面进行了提升，对于宋词这种格式多变，结构深细、韵律丰富的高难度文体，生成的内容亦能工整对仗、韵脚和谐，让每个人都能创作出咏物、寄思的五言律诗、七言绝句，写下的言志、抒情的「沁园春」、「定风波」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-8959061fdec6f20cfdb40450da65be44c34.jpg" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-200b2ab4aedbbf84adc97af95557a2b8c51.jpg" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 06:57:22 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276843</guid>
            <link>https://www.oschina.net/news/276843</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[.NET 8 动态 PGO 简析]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h2_1"></span><h2>原文：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fmp.weixin.qq.com%2Fs%253F__biz%253DMzg5NDYwNjU4MA%253D%253D%2526mid%253D2247486038%2526idx%253D1%2526sn%253D9c070c8e07acfe85269835a709cd5b6d%2526chksm%253Dc01c47cdf76bcedb8362846a829faf4c1853f4abcbe9708d6551264387f3795f7cb3e3e54828%2526token%253D1735800899%2526lang%253Dzh_CN%2523rd" target="_blank" rel="nofollow">.NET8 动态 PGO 简析</a></u></h2><p><strong>作者：江湖评谈，公众号同名：江湖评谈 (Jianghupt）,欢迎关注。</strong></p><p>&nbsp;</p><span id="OSC_h2_2"></span><h2><strong>前言</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">.NET8 在性能方面的惊人飞跃，远超过去所取得成就，这在很大程度上归功于动态 PGO。【 I dare say the improvements in .NET 8 in the JIT are an incredible leap beyond what was achieved in the past, in large part due to dynamic PGO…官方原话】</p><span id="OSC_h2_3"></span><h2><strong>详细</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">在早期的.NET 方法只编译一次，在第一次调用该方法的时候，JIT 启动以生成该方法的代码。后续的调用以及当前的调用都会使用 JIT 生成的代码来运行程序，这是一个简单的无冲突的时代，但是也是一个原始的时代。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">简单和原始在于，方法只编译一次，再无其它可能性。无冲突在于，尤其是.NET 开源时代，分层，动态 PGO，OSR 等等都会破坏原有的代码逻辑，造成一定的复杂度，而早期的.NET 不存在这种状况。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">优化是编译器里面最耗时的操作，编译器可以花费超长的时间来优化一段代码或者一个指令集。但是程序使用者，或者软件使用者，或者软件开发者没有超长的时间去等待编译器慢慢的完成一个方法的编译。这是很致命的。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">在编译时间和代码质量上需要权衡利益得失。好的代码质量，需要更长的时间去编译，差的代码质量，则编译更快。这取决于 JIT 本身是如何工作的。大量的事实证明，在程序中大部分方法都只是调用一次或者几次，耗费很多的时间去优化这些方法。优化的时间反而超过了这些方法本身运行的时间，这完全是得不偿失的。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">为了解决这种情况，.NET Core3.0 中引入了新的 JIT 功能，称之为分层编译。通过分层一个方法可能会被编译多次，在第一次编译的时候被编译为 0 层 (tier0),在 0 层当中 JIT 优先考虑的是代码编译的速度，而不是质量。在 0 层的编译特点是，最小优化 (min opts，但是依然会保持一些优化)，之所以这样，是因为它需要更快速的编译而不是更好质量的代码。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">0 层之后，会有 1 层 (tier1)。这一层是基于 0 层的代码运行情况而来，比如 JIT 收集到 0 层的某个方法，运行的时间超过了 60ms,运行的次数超过了 2 次 (.NET8 R2R 函数进入分层编译队列的阈值，比如 Console.ReadLine 方法)，那么 JIT 就会把 0 层的这个方法放入到分层编译队列，进行编译之后该方法就会进一步优化形成了 1 层 (tier1),此后调用该方法和当前调用该方法都会调用 1 层的代码，而弃用了 0 层的代码。</p><span id="OSC_h2_4"></span><h2><strong>神来之笔</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">这里需要注意了，只有极少数的符合阈值的方法才能够进入 1 层。这样其实是 0 层和 1 层共生运行一个程序的过程，既保证了代码的质量，又保证了程序运行的速度，这是.NET8 的一个神奇点。但是它的好处远不止于此。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 1</strong>，代码从 0 层被优化到 1 层，JIT 在 0 层的时候就会收集到代码的信息，并且在编译到 1 层的时候，会进行相对应的优化。如果 JIT 直接从一开始把代码编译到 1 层，那么可能无法拥有这样的优化。举个例子，比如 0 层有个方法，它里面有个静态只读字段，0 层编译的时候它一定被初始化过了。JIT 就可以根据它收集到的初始化的内容，在生成 1 层代码的时候进行相对应的优化。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 2</strong>，有一种情况，一个方法可能只运行了寥寥几次或者只有一次。但是它里面有 for 循环这种代码，一直不停的运行。如果没有分层编译，它直接进入了 Tier1，这样很粗暴的方式明显不行。为了解决这个问题，.NET 中引入了 OSR(On-Stack Replacement)，当一个循环计数达到一定的阈值，JIT 将编译该方法的新优化版本，此后从最小代码优化版本调到新优化版本中继续执行。非常巧妙的一个方式。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 3，</strong>基于配置文件的静态优化 (PGO) 已经存在了几十年。适用于多种环境和语言，比如 C/C++,Python,Java 等等。这种原理主要是，在一些代码关键地方收集信息，下次运行根据这些信息重新构建应用程序。因为做到这些需要一些编译器或者其它一些配置，称之为静态 PGO。而通过分层，Tier0 优化到 Tier1 的基础上，所有的都是 JIT 自行收集，自行判断，自行优化，无须任何额外的开发工作，或者基础设施的配置，它就是动态 PGO。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"><strong>神奇点 4，</strong>把 R2R 纳入到分层编译。R2R 是一个预编译镜像，它里面存储的 Native Header 是完全的二进制运行代码，它跟 AOT 的不同在于它运行了一定的次数之后，会被 JIT 进行重新优化编译。如果不把它纳入到分层编译，这对动态 PGO 的性能是一个很大的阻碍。</p><span id="OSC_h2_5"></span><h2><strong>编译分支和例子</strong></h2><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">一般的来说，即时编译分为两个分支。即源码编译和 R2R(它大量的应用在 System.Private.CoreLib.dll 里面) 预编译 (AOT 不属于即时编译，这里需要注意)。</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">源码编译即所谓未 PreJIT 编译，0 层一般都是未优化 (not optimized)，未检查 (not instrumented)，在 0 层进行了检查但是未优化，此后在 1 层生成优化性代码。R2R 即所谓 PreJIT 编译，因为 R2R 可能已经被优化过了。所以 0 层它是已优化，未检查，会在 0 层进行检查。到了 1 层已优化已检查，然后会再次生成一个优化性的代码，也称之为 1 层 (但其实已经是 2 层，了)。参考如下图:</p><div><img height="629" src="https://pic2.zhimg.com/80/v2-080f882fe065fc243c87fbd61f80c1f5_720w.webp" width="1080" referrerpolicy="no-referrer"></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">下面看下 Tier0 优化的一个例子，上面说到 Tier0 是确保编译速度，而忽略代码质量。但是不代表 Tier0 不进行代码优化。下面就是 0 层代码优化的例子。</p><div><pre><code class="language-text">// dotnet run -c Release -f net8.0

MaybePrint(42.0);

static void MaybePrint&lt;T&gt;(T value)
{
    if (value is int)
        Console.WriteLine(value);
}</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">0 层 JIT 可以进行一定常量折叠 (在编译的时候评估常量而不是在运行的时候),这可以让 0 层生成更少的代码。一般的来说，0 层 JIT 大部分时间都是与虚拟机交互。如果能够减少一些永远不会使用的分支，可以大幅度提高编译的时间，也能获得更好的代码质量。将 DOTNET_JitDisasm 设置为 MaybePrint，运行</p><div><pre><code class="language-text">dotnet run -c Release -f net7.0</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">0 层代码如下：</p><div><pre><code class="language-text"> Assembly listing for method Program:&lt;&lt;Main&gt;$&gt;g__MaybePrint|0_0[double](double)
; Emitting BLENDED_CODE for X64 CPU with AVX - Windows
; Tier-0 compilation
; MinOpts code
; rbp based frame
; partially interruptible

G_M000_IG01:                ;; offset=0000H
       55                   push     rbp
       4883EC30             sub      rsp, 48
       C5F877               vzeroupper
       488D6C2430           lea      rbp, [rsp+30H]
       33C0                 xor      eax, eax
       488945F8             mov      qword ptr [rbp-08H], rax
       C5FB114510           vmovsd   qword ptr [rbp+10H], xmm0

G_M000_IG02:                ;; offset=0018H
       33C9                 xor      ecx, ecx
       85C9                 test     ecx, ecx
       742D                 je       SHORT G_M000_IG03
       48B9B877CB99F97F0000 mov      rcx, 0x7FF999CB77B8
       E813C9AE5F           call     CORINFO_HELP_NEWSFAST
       488945F8             mov      gword ptr [rbp-08H], rax
       488B4DF8             mov      rcx, gword ptr [rbp-08H]
       C5FB104510           vmovsd   xmm0, qword ptr [rbp+10H]
       C5FB114108           vmovsd   qword ptr [rcx+08H], xmm0
       488B4DF8             mov      rcx, gword ptr [rbp-08H]
       FF15BFF72000         call     [System.Console:WriteLine(System.Object)]

G_M000_IG03:                ;; offset=0049H
       90                   nop

G_M000_IG04:                ;; offset=004AH
       4883C430             add      rsp, 48
       5D                   pop      rbp
       C3                   ret

; Total bytes of code 80</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">System.Console:WriteLine 里面的代码都是可以进行优化的，但是.NET7 里面 0 层它解析出了 MaybePrint，并未意识到其根本不会执行。现在在.NET8 里面 JIT 意识到分支永远不会执行，所以生成如下：</p><div><pre><code class="language-text">; Assembly listing for method Program:&lt;&lt;Main&gt;$&gt;g__MaybePrint|0_0[double](double) (Tier0)
; Emitting BLENDED_CODE for X64 with AVX - Windows
; Tier0 code
; rbp based frame
; partially interruptible

G_M000_IG01:                ;; offset=0x0000
       push     rbp
       mov      rbp, rsp
       vmovsd   qword ptr [rbp+0x10], xmm0

G_M000_IG02:                ;; offset=0x0009

G_M000_IG03:                ;; offset=0x0009
       pop      rbp
       ret

; Total bytes of code 11</code></pre></div><p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start">&nbsp;</p><span id="OSC_h1_6"></span><h1>欢迎关注公众号：<strong>江湖评谈 (jianghupt）</strong></h1><h2><img alt="" height="430" src="https://oscimg.oschina.net/oscnet/up-011ec0cc18092e37225986048b70675dae9.png" width="430" referrerpolicy="no-referrer"></h2></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 06:42:22 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5407571/blog/10983721</guid>
            <link>https://my.oschina.net/u/5407571/blog/10983721</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百度输入法在候选词区域植入广告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>V2EX 用户发帖称，百度输入法最新版本在候选词区域植入了广告。</p><p>具体表现为，如果用户要打「招商银行」四个字，当输入「招商」之后，候选词的首位是「★热门加盟店排行」的链接，点击后会进入名为「加盟星榜单」的广告页面。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-0682b5080fc14f1967ebbe8ed9f2c741f2b.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.v2ex.com%2Ft%2F1011440" target="_blank">https://www.v2ex.com/t/1011440</a></u></em></p></blockquote><p>别的不说，想出这个功能的产品经理真是个人才，因此评论区有用户感叹道：</p><blockquote><p><em>不说用户体验怎么样，不得不说这个键盘的候选词广告想法确实超前，不光超前，还实现了。</em></p><p><em>根据输入内容，直接用候选词的方式推送广告，从源头出发拿到用户的一手数据，直接甩掉了各种中间商。速度也更快，更精确的投送。</em></p><p><em>可以说是真 nb 呀</em></p></blockquote><p>知名科技博主阑夕评价道：「<em>你都打出招商两个字了，一定是想加盟店铺做生意吧？逻辑极其通顺智能，对不对？这真的是人类能够企及的创新吗，太牛逼了。</em>」</p><blockquote><p><img height="604" src="https://oscimg.oschina.net/oscnet/up-9c82c56b05a42376a5e053f16691428897d.png" width="1270" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 04:07:33 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276832</guid>
            <link>https://www.oschina.net/news/276832</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Katalyst v0.4.0 发布：潮汐混部与资源超分]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-35370f991af6656824cb1bdd4d587fa5449.png" alt="" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0NDMzNjkxNw%3D%3D%26mid%3D2247485561%26idx%3D1%26sn%3Dc5a10a4f5e692568a60f76fb3bab67c2%26chksm%3Dc3277103f450f815423288c62b7f66d0a86a67f3820950c77acbf241cad0e2b56f1e0461bb5f%26scene%3D21%23wechat_redirect" target="_blank">Katalyst</a> 是字节跳动开源的成本优化实践系统，致力于解决云原生场景下的资源不合理利用问题，为资源管理和成本优化提供解决方案。</p><blockquote><p>来源&nbsp;| KubeWharf 社区</p><p>项目 |&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewharf%2Fkatalyst-core" target="_blank">github.com/kubewharf/katalyst-core</a></p></blockquote><p>近日，Katalyst 社区完成了 0.4.0 版本发布。除了持续优化 QoS 能力之外，我们还在新版本中提供了可以独立在原生 Kubernetes 上使用的潮汐混部和资源超售能力。</p><p>和在离线常态混部一样，这些能力是字节跳动在不同业务场景中实现降本增效的技术手段，我们在抽象出标准化能力之后也进行了开源，期望这些能力可以帮助用户以更低的落地成本完成资源效能提升。</p><h1>潮汐混部</h1><h2>背景</h2><p>通过给应用分配差异化的 QoS 等级，Katalyst 可以基于资源隔离和动态调控能力实现在单机维度的在离线业务混部，即常态混部。这种混部模式虽然可以实现极致的资源效能提升，但是也增加了基础设施的复杂度。同时因为引入了例如 Reclaimed 资源这样的概念，要落地常态混部往往还需要做一些业务侧的适配。</p><p>为了让用户可以以更低的成本落地混部能力，在 v0.4.0 中，Katalyst 提供了潮汐混部（Tidal Colocation）功能。</p><h2>技术解读</h2><p>在潮汐混部中引入了潮汐节点池的概念，并且将集群中的节点划分为「在线」和「离线」两种类型。潮汐混部主要分为两个部分：</p><ul><li><strong>实例数管理</strong>：通过 HPA、CronHPA 等各种横向扩缩能力来管理在线业务的实例数，在夜间可以腾出资源给离线业务使用</li><li><strong>潮汐节点池管理</strong>：Tidal Controller 基于设定好的策略对潮汐节点池中的节点做 binpacking，将腾出的资源折合成整机出让给离线业务</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-20c31affd845929187609604ca5d98f5d2a.png" alt="" referrerpolicy="no-referrer"></p><h2>使用</h2><ol><li>在集群中选取加入潮汐节点池的节点，并为节点打上某个 Label</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  ...
  labels:
    beta.kubernetes.io/arch: amd64
    beta.kubernetes.io/os: linux
    # 潮汐节点标识
    tidenodes: "true"
  name: 192.168.0.11
spec:
  ...
</code></pre><ol start="2"><li>创建潮汐节点池配置</li></ol><pre><code>apiVersion: tide.katalyst.kubewharf.io/v1alpha1
kind: TideNodePool
metadata:
  name: tidenodepool-example
spec:
  nodeConfigs:
    nodeSelector:
      # 与加入潮汐节点池的节点中的标签匹配
      tidenodes: "true"
    # 配置潮汐节点池中为在线和离线节点预留的节点量
    reserve:
      offline: 25%
      online: 10%
</code></pre><ol start="3"><li>潮汐控制器为节点打上对应的标签和污点，并且会根据各个节点的负载情况动态做 Binpacking 调整节点角色</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  labels:
    beta.kubernetes.io/arch: amd64
    beta.kubernetes.io/os: linux
    tidenodes: "true"
    # 潮汐控制器为在线节点打上在线标签，离线类似
    tide.katalyst.kubewharf.io/node-pool: tidenodepool-sample
    tide.katalyst.kubewharf.io/node-type: online
    tide.katalyst.kubewharf.io/reserve: "false"
    tide.katalyst.kubewharf.io/tide: "true"
  name: 192.168.0.11
spec:
  # 潮汐控制器为在线节点打上禁止离线调度的污点，离线类似
  taints:
  - effect: NoExecute
    key: tide.katalyst.kubewharf.io/offline-not-used
    value: "true"
  ...
</code></pre><ol start="4"><li>部署在线离线业务，为应用打上相应标签和污点容忍，并配置 HPA 规则</li></ol><pre><code>kind: Deployment
apiVersion: apps/v1
metadata:
  name: tide-online
spec:
  replicas: 30
  selector:
    matchLabels:
      app: tide-online
  template:
    metadata:
      labels:
        # 标识在线
        tide.katalyst.kubewharf.io/pod-type: online
        app: tide-online
    spec:
      tolerations:
        # 容忍污点
      - key: "tide.katalyst.kubewharf.io/offline-not-used" 
        operator: "Exists"
      nodeSelector:
        # 选择在线节点，包含预留+潮汐
        tide.katalyst.kubewharf.io/node-type: online
      containers:
      - name: busybox
        image: busybox
        command: ["sleep", "36000"]
        resources:
          requests:
            cpu: "4"
            memory: "8Gi"
</code></pre><h1>在线超分</h1><h2>背景</h2><p>在线业务的资源使用量往往会随着访问数量的波动而变化，具备明显的潮汐特性。为了确保业务的稳定性，用户通常会以峰值时消耗的资源量作为申请的依据，而且往往会有过度申请资源的倾向，这些资源会被浪费。</p><p>Katalyst 提供了在离线混部的能力作为解决上述问题的方式之一，但是在一些场景下，在离线混部可能不便于落地，比如：</p><ul><li>负载类型比较单一，只有在线业务</li><li>业务方不愿意改变申请资源的协议来申请 Reclaimed 资源</li></ul><p>在新版本中，Katalyst 针对在线业务场景，提供了一种简单的、对业务方无感的资源超分方案，便于用户快速提升资源利用率。</p><h2>技术解读</h2><ul><li><strong>Over-commit Webhook</strong>：劫持 kubelet 上报心跳的请求，并对 Allocatable 资源量进行放大</li><li><strong>Over-commit Controller</strong>：超分配置管理</li><li><strong>Katalyst Agent</strong>：通过干扰检测和驱逐，保障超分后节点的性能和稳定性；根据指标数据，计算并上报动态的超分比</li><li><strong>Katalyst Scheduler</strong>：对需要绑核的 Pod 进行准入，避免超分导致实际无法绑核而启动失败</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-15d23b597098e49126aa0ae68cb1b5f0d0c.png" alt="" referrerpolicy="no-referrer"></p><h2>使用</h2><ol><li>为需要超分的节点池的节点打上 Label</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  annotations:
    # 超分节点池的标识
    katalyst.kubewharf.io/overcommit_node_pool: node-pool-1 
  name: 10.27.0.1
spec:
  ...
status:
  # 未超分时的资源量
  allocatable:
    cpu: 15900m
    memory: 32059820Ki
  capacity:
    cpu: 16
    memory: 32424364Ki
  ...
</code></pre><p>2.&nbsp;创建超分规则</p><pre><code>apiVersion: overcommit.katalyst.kubewharf.io/v1alpha1
kind: NodeOvercommitConfig
metadata:
  name: node-overcommit-config-1
spec:
  # 该规则匹配具有如下节点池 Label 的节点
  # katalyst.kubewharf.io/overcommit_node_pool=node-pool-1 
  nodeOvercommitSelectorVal: "node-pool-1"
  # 各种资源的超分比
  resourceOvercommitRatio:
    cpu: 2
status:
  # 该规则匹配的节点名称列表
  matchedNodeList: 
    - 10.27.0.1
    - 10.27.0.2
    - 10.27.0.3
</code></pre><ol start="3"><li>观察 Node 对象，发现 Katalyst 将超分比、未超分时的资源量更新到&nbsp;Annotation 中，并根据超分比对 Allocatable 和 Capacity 进行了放大</li></ol><pre><code>apiVersion: v1
kind: Node
metadata:
  annotations:
    katalyst.kubewharf.io/overcommit_node_pool: node-pool-1 
    # 以下字段由 Katalyst 添加
    # CPU 超分比
    katalyst.kubewharf.io/cpu-overcommit-ratio: "2"
    # Memory 超分比
    katalyst.kubewharf.io/memory-overcommit-ratio: "1"
    # 超分前的 CPU Capacity
    katalyst.kubewharf.io/original_capacity_cpu: "16"
    # 超分前的 Memory Capacity
    katalyst.kubewharf.io/original_capacity_memory: "32424364Ki"
    # 超分前的 CPU Allocatable
    katalyst.kubewharf.io/original_allocatable_cpu: "15900m"
    # 超分前的 Memory Allocatable
    katalyst.kubewharf.io/original_allocatable_memory: "32424364Ki"
  name: 10.27.0.1
spec:
  ...
status:
  # 超分后的资源量
  allocatable:
    cpu: 31800m
    memory: 32059820Ki
  capacity:
    cpu: 32
    memory: 32424364Ki
  ...
</code></pre><h1>NUMA 粒度混部内存管控框架</h1><h2>背景</h2><p>Katalyst 当前的混部策略只考虑整体机器的可用资源，导致离线任务在 NUMA 跨度申请内存时，内存容量和带宽在各 NUMA 间分布不均匀。这种情况下，当前的混部策略往往无法精确控制内存使用量，进而引起内存压力。</p><p>针对这种情况，我们提出了一种精细化的 NUMA 粒度内存管控框架，旨在通过 sysadvisor 计算 memory provisions，并与 qrm memory plugin 交互，实现更细致的 NUMA 内存管理。这将使 qrm memory plugin 能够根据 memory provisions 进行 NUMA 细粒度内存控制。</p><h2>技术解读</h2><p>在 Sysadvisor 的 Memory Plugin 中，我们引入了名为 memoryProvisioner 的插件，负责计算每个 NUMA 的内存供应逻辑。</p><p>为增强其可扩展性，我们设计了 ProvisionPolicy 接口，包含 Update 和 GetProvision 两个方法，分别用于定期更新内存供应量和获取 provision 建议。MemoryProvisioner 插件实现了 MemoryAdvisorPlugin 接口。</p><p>此策略基于 Memory Headroom 的 PolicyNUMAAware 策略，通过遍历每个物理 NUMA 及其 pod，计算每个 NUMA 的内存供应量。具体计算逻辑包括分析 NUMA Exclusive 设置，获取每个 NUMA 节点的空闲内存，并应用公式考虑 reclaimed cores、系统 scale_factor 和 reserved 内存，以实现更均衡的 NUMA 内存分配。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5947a2be6ceb2494b055eb33148d597d250.png" alt="" referrerpolicy="no-referrer"></p><h2>使用</h2><p>katalyst-agent 添加了&nbsp;<code>memory-provision-policy</code>&nbsp;的启动参数，用于指定计算策略，默认是 canonical。用法如下：</p><pre><code>katalyst-agent --kubeconfig=/root/.kube/config \
--memory-resource-plugin-advisor=true   \
--memory-advisor-plugins=memory-provisioner \
--memory-provision-policy=memory-provisioner-canonical \
...
</code></pre><h1>支持 OOM 优先级作为 QoS 增强</h1><h2>背景</h2><p>目前，Kubernetes 中 pod 的 OOM 优先级主要受其 QoS 级别与其对内存的申请量、使用量影响。然而，当前混部场景下，kubelet 原生的 oom_score_adj 计算策略已经不能很好的满足需求，例如：</p><ul><li>需要给两个都映射到原生的 Burstable 级别的 shared_cores pods 设定 OOM 优先级</li><li>需要在两个原生都是 Guaranteed 级别的 dedicated_cores pod 和 shared_cores pod 之间设定 shared_cores pod 要早于 dedicated_cores pod OOM</li></ul><p>此外，当前 kubelet 中提供的静态 oom_score_adj 计算机制，不支持 OOM 优先级的动态调整。因此 Katalyst 提供了一个关于 OOM 优先级的 QoS Enhancement，支持更加灵活地为 pods 设置 OOM 优先级。</p><h2>技术解读</h2><p>Katalyst 通过在内核添加 ebpf 的方式实现用户自定义的 OOM 策略注入，并在上层 qrm memory plugin 中完成用户定义策略的解析以及 OOM Priority 的配置下发。</p><h2>使用</h2><p>OOM Priority 信息通过 annotaion 在 pod 上进行指定</p><pre><code>annotations:
    "katalyst.kubewharf.io/memory_enhancement":'{
    "numa_binding": "true", 
    "numa_exclusive": "true",
    "oom_priority": priorityValueInt,
    }'
</code></pre><p>priorityValueInt 的取值越大表示优先级越高，并且取值范围受 pod 所指定的 QoS level 影响。</p><h1>支持拓扑感知调度</h1><p>在搜索、广告、推荐、游戏、AI 分布式训练等业务场景下，用户对时延的敏感性较高，对容器在微拓扑级别的摆放方式存在要求。原生 K8s 的微拓扑管理能力存在一些局限，调度器不感知微拓扑，可能导致出现较多的因不满足 NUMA 亲和要求而造成的 Admit 失败。</p><p>因此，Katalyst 在 v0.4.0 实现了拓扑感知调度功能，支持两种模式：</p><ul><li>Native 策略：兼容 K8s 原生的 NUMA 亲和和绑核策略</li><li>Dynamic 策略：混部场景下增强的绑核策略，对于&nbsp;dedicated_cores&nbsp;QoS 级别，支持了 NUMA 亲和 (numa_binding) 以及 NUMA 独占 (numa_exclusive) 两种语义</li></ul><h1>其他</h1><ul><li>SysAdvisor 框架支持对接自定义业务模型，调优 rama provision policy 计算结果</li><li>QRM 支持设置整机和容器级别 TCP Memory 上限，缓解 TCP 内存满导致的丢包问题</li><li>Eviction 集成 RootFS 驱逐能力，定制排序策略和 QoS 级别驱逐阈值</li><li>KCMAS 优化存储数据结构和索引，支持多 tag 能力</li><li>ServiceProfilingDescriper (SPD) 支持服务维度的混部 baseline 和 per-pod 灰度能力</li><li>社区开发切换到基于 owner review 模式</li><li>基于超时实现死锁检测功能</li></ul><h2>新版本体验路径</h2><p>请参考社区官方文档体验 Katalyst 潮汐混部和资源超分能力:</p><ul><li>潮汐混部：gokatalyst.io/docs/user-guide/tidal-colocation/</li><li>资源超分：gokatalyst.io/docs/user-guide/resource-overcommitment/</li></ul><h2>感谢贡献者</h2><p>在本次新版本的发布过程中，社区也迎来了不少新的贡献者，在此向他们的付出表示由衷感谢：</p><p><img src="https://oscimg.oschina.net/oscnet/up-83be15e44a1ec8ffe211a81ad949b4e8982.png" alt="" referrerpolicy="no-referrer"></p><p>非常期待更多开发者和用户加入到 Katalyst 开源社区中，和我们一起交流和探讨在离线混部以及资源效能的相关话题。</p><hr><p>项目地址：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewharf%2Fkatalyst-core" target="_blank">github.com/kubewharf/katalyst-core</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 03:25:33 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6210722/blog/10979687</guid>
            <link>https://my.oschina.net/u/6210722/blog/10979687</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[文本检索性能提升 40 倍，Apache Doris 倒排索引深度解读]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 OLAP 领域，Apache Doris 已成为高性能、高并发以及高时效性的代名词。在面向海量数据的复杂查询需求时，除硬件配置、集群规模、网络带宽等因素外，提升性能的核心在于如何最大程度地降低 SQL 执行时的 CPU、内存和 IO 开销，而这其中数据库索引扮演着至关重要的角色。合理的索引结构设计可以跳过大量不必要的底层数据读取、快速检索定位到所需数据，并进一步提升后续计算的执行效率、降低查询 SQL 的运行时间和资源消耗。</p><p>Apache Doris 提供了丰富的索引以加速数据的读取和过滤，依据是否需要用户手工创建，索引类型大体可以分为智能内建索引和用户创建索引两类，其中智能内建索引是指在数据写入时自动生成的索引，无需用户干预，包括前缀索引和 ZoneMap 索引。用户创建索引需要用户根据业务特点手动创建，包括 Bloom Filter 索引和 2.0 版本新增的倒排索引与 NGram Bloom Filter 索引。</p><p>相较于用户比较熟悉的前缀索引、Bloom Filter 索引，2.0 版本所新增的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg3Njc2NDAwOA%3D%3D%26mid%3D2247519079%26idx%3D1%26sn%3Da232a72695ff93eea0ffe79635936dcb%26chksm%3Dcf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e%26scene%3D21%23wechat_redirecthttp%3A%2F%2F" rel="nofollow" target="_blank">倒排索引</a>和 NGram Bloom Filter 在文本检索、模糊匹配以及非主键列检索等场景有着更为明显的性能提升。本文将以 Amazon customer reviews 数据集为例，介绍 Apache Doris 在查询该数据集以及类似场景中，如何充分利用倒排索引以及 NGram Bloom Filter 索引进行查询加速，并详细解析其工作原理与最佳实践。</p><span id="OSC_h2_1"></span><h2>数据集样例</h2><p>在本文中，我们使用的数据集包含约 1.3 亿条亚马逊产品的用户评论信息。该数据集以 Snappy 压缩的 Parquet 文件形式存在，总大小约为 37GB。以下为数据集的样例：</p><p><img src="https://cdn.selectdb.com/static/_e5e3fca815.png" alt="数据集样例.png" referrerpolicy="no-referrer"></p><p>在子集中，每行包含用户 ID（<code>customer_id</code>）、评论 ID（<code>review_id</code>）、已购买产品 ID（<code>product_id</code>）、产品分类（<code>product_category</code>）、评分（<code>star_rating</code>）、评论标题（<code>review_headline</code>）、评论内容（<code>review_body</code>）等 15 列信息。 根据上述可知，列中包含了适用于索引加速的各种特征。例如，<code>customer_id</code> 是高基数的数值列，<code>product_id</code> 是低基数的定长短文本列，<code>product_title</code> 是适合文本检索的短文本列，<code>review_body</code> 则是适合文本搜索的长文本列。</p><p>通过这些列，我们可以模拟两个典型索引查询场景，具体如下：</p><ul><li>文本搜索查询：搜索 <code>review body</code> 字段中包含特定内容的产品信息。</li><li>非主键列明细查询：查询特定产品 ID（<code>product_id</code>）或者特定用户 ID（<code>customer_id</code>）的评论信息。</li></ul><p>接下来，我们将以文本搜索和非主键列明细查询为主要方向，对比在有索引和无索引的情况下查询性能的差异。同时，我们也将详细解析索引减少查询耗时、提高查询效率的原理。</p><span id="OSC_h2_2"></span><h2>环境搭建</h2><p>为了快速搭建环境，并进行集群创建和数据导入，我们使用单节点集群（1FE、1BE）并按照以下步骤进行操作：</p><ol><li><p>搭建 Apache Doris ：具体操作请参考：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoris.apache.org%2Fzh-CN%2Fdocs%2Fget-starting%2Fquick-start%2F" rel="nofollow" target="_blank">快速开始</a></p></li><li><p>创建数据表：按照下列建表语句进行数据表创建</p></li></ol><pre><code class="language-SQL">CREATE TABLE `amazon_reviews` (  
  `review_date` int(11) NULL,  
  `marketplace` varchar(20) NULL,  
  `customer_id` bigint(20) NULL,  
  `review_id` varchar(40) NULL,
  `product_id` varchar(10) NULL,
  `product_parent` bigint(20) NULL,
  `product_title` varchar(500) NULL,
  `product_category` varchar(50) NULL,
  `star_rating` smallint(6) NULL,
  `helpful_votes` int(11) NULL,
  `total_votes` int(11) NULL,
  `vine` boolean NULL,
  `verified_purchase` boolean NULL,
  `review_headline` varchar(500) NULL,
  `review_body` string NULL
) ENGINE=OLAP
DUPLICATE KEY(`review_date`)
COMMENT 'OLAP'
DISTRIBUTED BY HASH(`review_date`) BUCKETS 16
PROPERTIES (
"replication_allocation" = "tag.location.default: 1",
"compression" = "ZSTD"
);

</code></pre><p>3.下载数据集：从下方链接分别下载数据集，数据集为 Parque 格式，并经过 Snappy 压缩，总大小约为 37GB</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2010.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2010</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2011.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2011</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2012.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2012</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2013.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2013</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2014.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2014</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdatasets-documentation.s3.eu-west-3.amazonaws.com%2Famazon_reviews%2Famazon_reviews_2015.snappy.parquet" rel="nofollow" target="_blank">amazon_reviews_2015</a></li></ul><p>4.导入数据集：下载完成后，分别执行以下命令，导入数据集</p><pre><code class="language-Bash">curl --location-trusted -u root: -T amazon_reviews_2010.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2011.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2012.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2013.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2014.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load
curl --location-trusted -u root: -T amazon_reviews_2015.snappy.parquet -H "format:parquet" http://${BE_IP}:${BE_PORT}/api/${DB}/amazon_reviews/_stream_load


</code></pre><p>5.查看与验证：完成上述步骤后，可以在 MySQL 客户端执行以下语句，来查看导入的数据行数和所占用空间。从下方代码可知：共导入 135589433 行数据，在 Doris 中占用空间 25.873GB，比压缩后的 Parquet 列式存储进一步降低了 30%。</p><pre><code class="language-SQL">mysql&gt; SELECT COUNT() FROM amazon_reviews;
+-----------+
| count(*)  |
+-----------+
| 135589433 |
+-----------+
1 row in set (0.02 sec)
mysql&gt; SHOW DATA FROM amazon_reviews;
+----------------+----------------+-----------+--------------+-----------+------------+
| TableName      | IndexName      | Size      | ReplicaCount | RowCount  | RemoteSize |
+----------------+----------------+-----------+--------------+-----------+------------+
| amazon_reviews | amazon_reviews | 25.873 GB | 16           | 135589433 | 0.000      |
|                | Total          | 25.873 GB | 16           |           | 0.000      |
+----------------+----------------+-----------+--------------+-----------+------------+
2 rows in set (0.00 sec)


</code></pre><span id="OSC_h2_3"></span><h2>文本搜索查询加速</h2><span id="OSC_h3_4"></span><h3>无索引硬匹配</h3><p>环境及数据准备就绪后，我们尝试对 <code>review_body</code> 列进行文本搜索查询。具体需求是在数据集中查出评论中包含「is super awesome」关键字的前 5 种产品，并按照评论数量降序排列，查询结果需显示每种产品的 ID、随机一个产品标题、平均星级评分以及评论总数。<code>review_body</code> 列的特征是评论内容比较长，因此进行文本搜索会有一定的性能压力。</p><p>首先我们直接进行查询，以下是查询的示例语句：</p><pre><code class="language-SQL">SELECT
    product_id,
    any(product_title),
    AVG(star_rating) AS rating,
    COUNT() AS count
FROM
    amazon_reviews
WHERE
    review_body LIKE '%is super awesome%'
GROUP BY
    product_id
ORDER BY
    count DESC,
    rating DESC,
    product_id
LIMIT 5;


</code></pre><p>执行结果如下，查询耗时为 <strong>7.6 秒</strong></p><pre><code class="language-SQL">+------------+------------------------------------------+--------------------+-------+
| product_id | any_value(product_title)                 | rating             | count |
+------------+------------------------------------------+--------------------+-------+
| B00992CF6W | Minecraft                                | 4.8235294117647056 |    17 |
| B009UX2YAC | Subway Surfers                           | 4.7777777777777777 |     9 |
| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |              4.875 |     8 |
| B0086700CM | Temple Run                               |                  5 |     6 |
| B00KWVZ750 | Angry Birds Epic RPG                     |                  5 |     6 |
+------------+------------------------------------------+--------------------+-------+
5 rows in set (7.60 sec)


</code></pre><span id="OSC_h3_5"></span><h3>利用 Ngram BloomFilter 索引加速查询</h3><p>接下来，我们尝试使用 Ngram BloomFilter 索引进行查询加速</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX review_body_ngram_idx(review_body) USING NGRAM_BF PROPERTIES("gram_size"="10", "bf_size"="10240");


</code></pre><p>添加 Ngram BloomFilter 索引之后，再次执行相同的查询。执行结果如下，<strong>查询耗时缩短至 0.93 秒，相较于未开启索引，查询效率提高了 8 倍。</strong></p><pre><code class="language-SQL">+------------+------------------------------------------+--------------------+-------+
| product_id | any_value(product_title)                 | rating             | count |
+------------+------------------------------------------+--------------------+-------+
| B00992CF6W | Minecraft                                | 4.8235294117647056 |    17 |
| B009UX2YAC | Subway Surfers                           | 4.7777777777777777 |     9 |
| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |              4.875 |     8 |
| B0086700CM | Temple Run                               |                  5 |     6 |
| B00KWVZ750 | Angry Birds Epic RPG                     |                  5 |     6 |
+------------+------------------------------------------+--------------------+-------+
5 rows in set (0.93 sec)


</code></pre><p>接下来，我们根据代码示例展开说明。使用 <code>ALTER TABLE</code> 语句为表增加 Ngram BloomFilter 索引时，<code>gram_size</code> 和 <code>bf_size</code> 参数具有特定的含义：</p><ul><li><code>gram_size</code>：表示 n-gram 中的 n 值，即连续字符的长度。在上述代码示例中，<code>"gram_size"="10"</code> 表示每个 n-gram 包含 10 个字符。这意味着文本将被切割成数个字符长度为 10 的字符串，这些字符串将用于构建索引。</li><li><code>bf_size</code>：表示 Bloom Filter 的大小，以字节（Byte）为单位。例如，<code>"bf_size"="10240"</code>表示所使用 Bloom Filter 数据大小占用空间为 10240 字节。</li></ul><p>在了解基本的参数定义后，我们来探索 <strong>Ngram BloomFilter 加速查询的原理：</strong></p><ul><li>Ngram 分词：使用 <code>gram_size</code> 对每行数据进行分词，当 <code>gram_size=5</code> 时，"hello world" 被切分为 ["hello"， "ello "， "llo w"， "lo wo"， "o wor"， " worl"， "world"]。这些子字符串经过哈希函数计算后，将被添加到相应大小（<code>bf_size</code>）的 Bloom Filter 中。由于 Doris 数据是按页面（page）组织存储，相应的 Bloom Filter 也会按页面（page）生成。</li><li>查询加速：以「hello」为例，在匹配过程中也将被切分并生成对应的 Bloom Filter，用于与各页面的 Bloom Filter 进行对比。如果 Bloom Filter 判断为包含匹配字符串（可能会出现假阳性），则加载相应的页面以进一步匹配；否则，将跳过该页面。其原理即通过跳过不需要加载的页面（page），减少需要扫描的数据量，从而显著降低了查询延时。</li></ul><p><img src="https://cdn.selectdb.com/static/Apache_Doris_c50be251fc.png" alt="Apache Doris 数据存储结构" referrerpolicy="no-referrer"></p><p>Ngram Bloom Filter 示意图</p><p>通过上述原理描述可以看出，针对不同的场景合理的配置 Ngram BloomFilter 的参数会达到更好的效果， <code>gram_size</code> 的大小直接影响匹配时效率，而 <code>bf_size</code> 的大小影响存储容量和误判率。通常情况下，较大的 <code>bf_size</code> 可以降低误判率，但这样也会占用更多的存储空间。因此，我们建议从以下两方面综合考量配置参数：</p><p><strong>数据特性：</strong> 考虑要索引的数据类型。对于文本数据，需要根据文本的平均长度和字符分布来确定。</p><ul><li>对于较短的文本（如单词或短语）：较小的 <code>gram_size</code>（例如 2-4）和较小的 <code>bf_size</code> 可能更合适。</li><li>对于较长的文本（如句子或大段描述：较大的 <code>gram_size</code>（例如 5-10）和较大的 <code>bf_size</code> 可能更有效。</li></ul><p><strong>查询模式：</strong> 考虑查询的典型模式。</p><ul><li>如果查询通常包含短语或接近完整的单词，较大的 <code>gram_size</code> 可能更好。</li><li>对于模糊匹配或包含多种变化的查询，较小的 <code>gram_size</code> 可以提供更灵活的匹配。</li></ul><span id="OSC_h3_6"></span><h3>利用倒排索引加速查询</h3><p>除了采用 Ngram BloomFilter 索引进行查询加速，还可以选择基于 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg3Njc2NDAwOA%3D%3D%26mid%3D2247519079%26idx%3D1%26sn%3Da232a72695ff93eea0ffe79635936dcb%26chksm%3Dcf2f8560f8580c768bbde99ef8ca97d3a42ecc03b5d8d106b85f5474c90b6068781a79b3611e%26token%3D533653942%26lang%3Dzh_CN%23rd" rel="nofollow" target="_blank">倒排索引</a> 进一步加速文本搜索的效率。可以通过以下步骤来构建倒排索引：</p><p>1.<strong>新增倒排索引：</strong> 对 <code>amazon_reviews</code> 表的 <code>review_body</code> 列添加倒排索引，该索引采用英文分词，并支持 Phrase 短语查询，短语查询即进行文本搜索时，分词后的词语顺序将会影响搜索结果。 2.<strong>为历史数据创建索引：</strong> 按照新增索引信息对历史数据进行索引构建，使历史数据就也可以使用倒排索引进行查询。</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX review_body_inverted_idx(`review_body`) 
    USING INVERTED PROPERTIES("parser" = "english","support_phrase" = "true"); 
BUILD INDEX review_body_inverted_idx ON amazon_reviews;

</code></pre><p>3.<strong>查看及验证：</strong> 构建完索引之后，可以通过以下方式对索引构建情况进行查看：</p><pre><code class="language-SQL">mysql&gt; show BUILD INDEX WHERE TableName="amazon_reviews";
+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+
| JobId | TableName      | PartitionName  | AlterInvertedIndexes                                                                                                              | CreateTime              | FinishTime              | TransactionId | State    | Msg  | Progress |
+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+
| 10152 | amazon_reviews | amazon_reviews | [ADD INDEX review_body_inverted_idx (
review_body
) USING INVERTED PROPERTIES("parser" = "english", "support_phrase" = "true")],  | 2024-01-23 15:42:28.658 | 2024-01-23 15:48:42.990 | 11            | FINISHED |      | NULL     |
+-------+----------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+
1 row in set (0.00 sec)


</code></pre><p>如果对分词效果不确定，可以使用 TOKENIZE 函数进行分词测试。TOKENIZE 函数接收两个输入：一个是需要进行分词的文本，一个是分词的属性字段。</p><pre><code class="language-SQL">mysql&gt; SELECT TOKENIZE('I can honestly give the shipment and package 100%, it came in time that it was supposed to with no hasels, and the book was in PERFECT condition.
super awesome buy, and excellent for my college classs', '"parser" = "english","support_phrase" = "true"');
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| tokenize('I can honestly give the shipment and package 100%, it came in time that it was supposed to with no hasels, and the book was in PERFECT condition. super awesome buy, and excellent for my college classs', '"parser" = "english","support_phrase" = "true"')                                              |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ["i", "can", "honestly", "give", "the", "shipment", "and", "package", "100", "it", "came", "in", "time", "that", "it", "was", "supposed", "to", "with", "no", "hasels", "and", "the", "book", "was", "in", "perfect", "condition", "super", "awesome", "buy", "and", "excellent", "for", "my", "college", "classs"] |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
1 row in set (0.05 sec)


</code></pre><p>在倒排索引创建完成后，我们使用 <code>MATCH_PHRASE</code> 来查询包含关键词"is super awesome"的产品评论信息（具体需求可回顾前文）。</p><pre><code class="language-SQL">SELECT
    product_id,
    any(product_title),
    AVG(star_rating) AS rating,
    COUNT() AS count
FROM
    amazon_reviews
WHERE
    review_body MATCH_PHRASE 'is super awesome'
GROUP BY
    product_id

ORDER BY
    count DESC,
    rating DESC,
    product_id
LIMIT 5;


</code></pre><p>以上述代码示例进行说明，<code>review_body MATCH_PHRASE 'is super awesome'</code> 表示对 <code>review_body</code> 列进行短语匹配查询。具体而言，查询会在 <code>review_body</code> 中按照英文分词后，寻找同时包含 "is"、"super" 和 "awesome" 这三个词语的文本片段，同时要求这三个词语的顺序是 "is" 在前，"super" 在中间，"awesome" 在后，并且词语之间没有间隔（不区分大小写）。</p><p>这里需要说明的是，MATCH 与 LIKE 查询的差异在于，MATCH 查询时会忽略大小写，把句子切分成一个个词来匹配，能够更快速定位符合条件的结果，特别是在大规模数据集情况下，MATCH 的效率提升更为明显。</p><p>执行结果如下所示，<strong>开启倒排索引后查询耗时仅 0.19 秒，性能较仅开启 Ngram BloomFilter 索引时提升了 4 倍，较未开启索引时提升了近 40 倍，极大幅度提升了文本检索的效率。</strong></p><pre><code class="language-SQL">+------------+------------------------------------------+-------------------+-------+
| product_id | any_value(product_title)                 | rating            | count |
+------------+------------------------------------------+-------------------+-------+
| B00992CF6W | Minecraft                                | 4.833333333333333 |    18 |
| B009UX2YAC | Subway Surfers                           |               4.7 |    10 |
| B00DJFIMW6 | Minion Rush: Despicable Me Official Game |                 5 |     7 |
| B0086700CM | Temple Run                               |                 5 |     6 |
| B00KWVZ750 | Angry Birds Epic RPG                     |                 5 |     6 |
+------------+------------------------------------------+-------------------+-------+
5 rows in set (0.19 sec)


</code></pre><p>究其加速原因可知，倒排索引是通过将文本分解为单词，并建立从单词到行号列表的映射。这些映射关系按照单词进行排序，并构建跳表索引。在查询特定单词时，可以通过跳表索引和二分查找等方法，在有序的映射中快速定位到对应的行号列表，进而获取行的内容。<strong>这种查询方式避免了逐行匹配，将算法复杂度从 O（n） 降低到 O（logn），在处理大规模数据时能显著提高查询性能。</strong></p><p><img src="https://cdn.selectdb.com/static/_c6e7b4f9ab.png" alt="倒排索引原理示意图" referrerpolicy="no-referrer"></p><p>为深入了解倒排索引的加速原理，需从倒排索引内部引读写逻辑说起。在 Doris 中，从逻辑角度来看，倒排索引应用于表的列级别，而从物理存储和实现角度来看，倒排索引实际是建立在数据文件级别上的。具体如下：</p><ul><li><strong>写入阶段：</strong> 数据在写入数据文件的同时，也将同步写入排索引文件中，对于每个写入数据的行号，均与倒排索引中的行号一一对应的。</li><li><strong>查询阶段：</strong> 如果查询 <code>WHERE</code> 条件中包含已建立倒排索引的列，Doris 会自动查询索引文件，返回满足条件的行号列表，再利用 Doris 通用的行号过滤机制，跳过不必要的行和页面，只读取满足条件的行，以达到查询加速的效果。</li></ul><p>总的来说，Doris 的倒排索引机制在物理层面是通过数据文件和索引文件配合工作，而在逻辑层面则通过列和行的映射来实现高效的数据检索和查询加速。</p><span id="OSC_h2_7"></span><h2>非主键列查询加速</h2><p>为了进一步验证倒排索引对非主键列查询加速的影响，我们选择对产品 ID 和用户 ID 的维度信息进行查询。</p><span id="OSC_h3_8"></span><h3>未开启倒排索引</h3><p>当查询用户 13916588 对产品 B002DMK1R0 的评论信息时，执行以下 SQL 语句进行查询时，需要对全表数据进行扫描，<strong>查询耗时为 1.81 秒。</strong></p><pre><code class="language-SQL">mysql&gt; SELECT product_title,review_headline,review_body,star_rating 
FROM amazon_reviews 
WHERE product_id='B002DMK1R0' AND customer_id=13916588;
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| product_title                                                   | review_headline      | review_body                                                                                                                 | star_rating |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| Magellan Maestro 4700 4.7-Inch Bluetooth Portable GPS Navigator | Nice Features But... | This is a great GPS. Gets you where you are going. Don't forget to buy the seperate (grr!) cord for the traffic kit though! |           4 |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
1 row in set (1.81 sec)


</code></pre><span id="OSC_h3_9"></span><h3>倒排索引查询加速</h3><p>接下来，我们为 <code>product_id</code> 和 <code>customer_id</code> 添加倒排索引。在这个场景中，倒排索引的使用与文本搜索时不同，该场景无需对 <code>product_id</code> 和 <code>customer_id</code> 进行分词，只需对这两列的 Value→RowID 的创建倒排映射表。</p><p>首先，通过执行以下 SQL 语句创建倒排索引：</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX product_id_inverted_idx(product_id) USING INVERTED ;
ALTER TABLE amazon_reviews ADD INDEX customer_id_inverted_idx(customer_id) USING INVERTED ;
BUILD INDEX product_id_inverted_idx ON amazon_reviews;
BUILD INDEX customer_id_inverted_idx ON amazon_reviews;


</code></pre><p>其次，当索引构建完成后，执行同样的查询语句，<strong>查询耗时从 1.81 秒降到了 0.06 秒</strong>，查询耗时显著降低，相比未添加索引的情况，<strong>查询效率提升了约 30 倍。</strong></p><pre><code class="language-SQL">mysql&gt; SELECT product_title,review_headline,review_body,star_rating FROM amazon_reviews WHERE product_id='B002DMK1R0' AND customer_id='13916588';
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| product_title                                                   | review_headline      | review_body                                                                                                                 | star_rating |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
| Magellan Maestro 4700 4.7-Inch Bluetooth Portable GPS Navigator | Nice Features But... | This is a great GPS. Gets you where you are going. Don't forget to buy the seperate (grr!) cord for the traffic kit though! |           4 |
+-----------------------------------------------------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------+-------------+
1 row in set (0.06 sec)

</code></pre><p>通过观察可发现，倒排索引在于类似非主键列的维度查询中具有非常出色的加速效果。为更深入且直观的查看加速效果，可通过 Doris Profile 信息来进一步探索。</p><span id="OSC_h3_10"></span><h3>Profile 分析</h3><p>需要注意的是，在开启查询的 Profile 之前，需先在 MySQL 客户端执行 <code>SET enable_profile=true;</code> 命令。完成后再执行查询语句，并访问 http://FE_IP:FE_HTTP_PORT/QueryProfile， 来查看与本次查询相关的 Profile ID 以及详细的 Profile 信息。</p><p>本文中仅截取一个特定片段的 SegmentIterator Profile 信息来说明倒排索引查询加速原因。</p><pre><code class="language-YAML">SegmentIterator:
  - FirstReadSeekCount: 0
  - FirstReadSeekTime: 0ns
  - FirstReadTime: 13.119ms
  - IOTimer: 19.537ms
  - InvertedIndexQueryTime: 11.583ms
  - RawRowsRead: 1
  - RowsConditionsFiltered: 0
  - RowsInvertedIndexFiltered: 16.907403M (16907403)
  - RowsShortCircuitPredInput: 0
  - RowsVectorPredFiltered: 0
  - RowsVectorPredInput: 0
  - ShortPredEvalTime: 0ns
  - TotalPagesNum: 27
  - UncompressedBytesRead: 3.71 MB
  - VectorPredEvalTime: 0ns

</code></pre><p>从上述 Profile 中的 <code>RowsInvertedIndexFiltered: 16.907403M (16907403) 以及 RawRowsRead: 1</code>，我们可以观察到：倒排索引过滤了 16907403 行数据，最终只保留 1 行数据（即命中的那条数据）。根据 <code>FirstReadTime: 13.119ms</code> 可知，在读取这行数据所在的页面（page）耗时 13.119 ms，而根据<code>InvertedIndexQueryTime: 11.583ms</code> 可知，倒排索引执行时间仅耗时 11.58 ms。<strong>这意味着倒排索引仅在 11.58 ms 内过滤了 16907403 行数据，执行效率非常高。</strong></p><p>为更直接对比，接下来展示未增加倒排索引情况下 SegmentIterator 的执行情况：</p><pre><code class="language-YAML">SegmentIterator:
  - FirstReadSeekCount: 9.374K (9374)
  - FirstReadSeekTime: 400.522ms
  - FirstReadTime: 3s144ms
  - IOTimer: 2s564ms
  - InvertedIndexQueryTime: 0ns
  - RawRowsRead: 16.680706M (16680706)
  - RowsConditionsFiltered: 226.698K (226698)
  - RowsInvertedIndexFiltered: 0
  - RowsShortCircuitPredInput: 1
  - RowsVectorPredFiltered: 16.680705M (16680705)
  - RowsVectorPredInput: 16.680706M (16680706)
  - RowsZonemapFiltered: 226.698K (226698)
  - ShortPredEvalTime: 2.723ms
  - TotalPagesNum: 5.421K (5421)
  - UncompressedBytesRead: 277.05 MB
  - VectorPredEvalTime: 8.114ms


</code></pre><p>根据上述 Profile 观察可知，由于没有索引进行过滤， FirstRead 需要花费 3.14s 的时间来加载 16680706 行数据，然后使用 Predicate Evaluate 进行条件过滤，过滤掉其中 16680705 行，而条件过滤本身只消耗了不到 10ms 的时间，由此可见，大部分时间被消耗在加载原始数据上。</p><p>通过对比可知，建立倒排索引可以大大减少加载原始数据的时间，提高查询的执行效率。索引能够快速定位满足条件的行，从而减少不必要的数据加载和处理，节省时间和资源。</p><span id="OSC_h2_11"></span><h2>低基数文本列索引加速</h2><p>众所周知，倒排索引对于高基数文本列的查询来说，加速效果十分显著。然而，在低基数列的情况下，可能由于需创建过多的索引项而导致更大的开销，从而对查询性能产生负面影响。接下来，我们将以 <code>product_category</code> 作为谓词列进行过滤，来检验 Apache Doris 倒排索引在低基数文本列的加速效果如何。</p><pre><code class="language-SQL">mysql&gt; SELECT COUNT(DISTINCT product_category) FROM amazon_reviews ;
+----------------------------------+
| count(DISTINCT product_category) |
+----------------------------------+
|                               43 |
+----------------------------------+
1 row in set (0.57 sec)


</code></pre><p>通过上述操作可知，到 <code>product_category</code> 仅有 43 种分类，是一个典型的低基数文本列。接下来，我们对其增加倒排索引</p><pre><code class="language-SQL">ALTER TABLE amazon_reviews ADD INDEX product_category_inverted_idx(`product_category`) USING INVERTED;
BUILD INDEX product_category_inverted_idx ON amazon_reviews;

</code></pre><p>添加倒排索引之后，运行如下 SQL 查询，指查询产品分类为 Mobile_Electronics 产品中评价数量最多的前三名产品信息</p><pre><code class="language-SQL">SELECT 
    product_id,
    product_title,
    AVG(star_rating) AS rating,
    any(review_body),
    any(review_headline),
    COUNT(*) AS count 
FROM 
    amazon_reviews 
WHERE 
    product_category = 'Mobile_Electronics' 
GROUP BY 
    product_title, product_id 
ORDER BY 
    count DESC 
LIMIT 10;


</code></pre><p>从下方结果可知，增加倒排索引之后，查询耗时为 1.54s。</p><pre><code class="language-SQL">+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+
| product_id | product_title                                                                                                                                                                                          | rating             | any_value(review_body)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | any_value(review_headline)      | count |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+
| B00J46XO9U | iXCC Lightning Cable 3ft, iPhone charger, for iPhone X, 8, 8 Plus, 7, 7 Plus, 6s, 6s Plus, 6, 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](Black and White) | 4.3766233766233764 | Great cable and works well. Exact fit as Apple cable. I would recommend this to anyone who is looking to save money and for a quality cable.                                                                                                                                                                                                                                                                                                                                                             | Apple certified lightning cable |  1078 |
| B004911E9M | Wall AC Charger USB Sync Data Cable for iPhone 4, 3GS, and iPod                                                                                                                                        | 2.4281805745554035 | A total waste of money for me because I needed it for a iPhone 4.  The plug will only go in upside down and thus won't work at all.                                                                                                                                                                                                                                                                                                                                                                      | Won't work with a iPhone 4!     |   731 |
| B002D4IHYM | New Trent Easypak 7000mAh Portable Triple USB Port External Battery Charger/Power Pack for Smartphones, Tablets and more (w/built-in USB cable)                                                        | 4.5216095380029806 | I bought this product based on the reviews that i read and i am very glad that i did. I did have a problem with the product charging my itouch after i received it but i emailed the company and they corrected the problem immediately. VERY GOOD customer service, very prompt. The product itself is very good. It charges my power hungry itouch very quickly and the imax battery power lasts for a long time. All in all a very good purchase that i would recommend to anyone who owns an itouch. | Great product &amp; company         |   671 |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-------+
3 rows in set (1.54 sec)


</code></pre><p>接下来，我们关闭倒排索引，以观察未加倒排索引时的查询耗时。这里需要说明的是，当需要关闭索引或在增加索引后发现效果不理想，可以在 MySQL 客户端中执行 <code>set enable_inverted_index_query=false;</code>，便捷且快速地临时关闭倒排索引。我们再次运行查询 SQL，如下所示，查询耗时为 1.8s。</p><pre><code class="language-SQL">+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+
| product_id | product_title                                                                                                                                                                                          | rating             | any_value(review_body)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | any_value(review_headline)            | count |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+
| B00J46XO9U | iXCC Lightning Cable 3ft, iPhone charger, for iPhone X, 8, 8 Plus, 7, 7 Plus, 6s, 6s Plus, 6, 6 Plus, SE 5s 5c 5, iPad Air 2 Pro, iPad mini 2 3 4, iPad 4th Gen [Apple MFi Certified](Black and White) | 4.3766233766233764 | These cables are great. They feel quality, and best of all, they work as they should. I have no issues with them whatsoever and will be buying more when needed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Just like the original from Apple     |  1078 |
| B004911E9M | Wall AC Charger USB Sync Data Cable for iPhone 4, 3GS, and iPod                                                                                                                                        | 2.4281805745554035 | I ordered two of these chargers for an Iphone 4. Then I started experiencing weird behavior from the touch screen. It would select the wrong area of the screen, or it would refuse to scroll beyond a certain point and jump back up to the top of the page. This behavior occurs whenever either of the two that I bought are attached and charging. When I remove them, it works fine once again. Needless to say, these items are being returned.                                                                                                                                                                                                                                                                                                                                                                              | Beware - these chargers are defective |   731 |
| B002D4IHYM | New Trent Easypak 7000mAh Portable Triple USB Port External Battery Charger/Power Pack for Smartphones, Tablets and more (w/built-in USB cable)                                                        | 4.5216095380029806 | I received this in the mail 4 days ago, and after charging it for 6 hours, I've been using it as the sole source for recharging my 3Gs to see how long it would work.  I use my Iphone A LOT every day and usually by the time I get home it's down to 50% or less.  After 4 days of using the IMAX to recharge my Iphone, it finally went from 3 bars to 4 this afternoon when I plugged my iphone in.  It charges the iphone very quickly, and I've been topping my phone off (stopping around 95% or so) twice a day.  This is a great product and the size is very similar to a deck of cards (not like an iphone that someone else posted) and is very easy to carry in a jacket pocket or back pack.  I bought this for a 4 day music festival I'm going to, and I have no worries at all of my iphone running out of juice! | FANTASTIC product!                    |   671 |
+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------+-------+
3 rows in set (1.80 sec)


</code></pre><p>综上可知，倒排索引对于低基数列场景也有 15% 的查询性能提升，虽不如高基数列场景的提升效果，但并未产生退化效果或负面影响。此外，Apache Doris 针对低基数列采用了较好的编码（如字典编码）方式和压缩技术，并且可以通过内置索引（如 zonemap）进行有效过滤。因此，即使不添加倒排索引仍能展现较好的查询效果。</p><span id="OSC_h2_12"></span><h2>总结语</h2><p>总而言之，Apache Doris 中的倒排索引显著优化了针对谓词列的过滤操作，即 SQL 查询中的 Where 子句。通过精确匹配行号，减少了存储层需要扫描的数据量，从而提高了查询性能。即使在性能提升有限的情况下，倒排索引也不会对查询效率产生负面影响。此外，倒排索引还支持轻量级的索引管理操作，如对增加或删除索引（ADD/DROP INDEX）以及构建索引（BUILD INDEX）操作进行管理。同时，还提供了在 MySQL 客户端便捷地启用或关闭索引（enable_inverted_index_query=true/false）的功能，使用户能够轻松利用倒排索引来检验查询加速效果。</p><p>倒排索引和 NGram Bloom Filter 索引为不同场景提供了查询加速方案，在选择索引类型时，数据集的特定特征和查询模式是关键考虑因素。以下是一些常见的适配场景：</p><ul><li><strong>大规模数据非主键列点查场景：</strong> 在这种场景下，往往存在大量分散的数值列在值，且查询的值命中量很低。为了加速查询，除了在建表时利用 Doris 内置的智能索引能力之外，还可以通过给对应的列增加倒排索引来加速查询。倒排索引对字符类型、数值类型、日期等标量类型支持比较完整。</li><li><strong>短文本列的文本检索场景：</strong> 如果短文本分布比较离散（即文本之间相似度低），则适合使用 Ngram Bloom Filter 索引，能够有效地处理短文本的模糊匹配查询（LIKE）。同时，在短文本场景下 Apache Doris 的向量化处理能力可以得到更加充分和高效的应用和发挥。如果短文本分布比较集中（如大量文本相似，少量文本不同），则适合使用倒排分词索引，这样可以保证词典比较小，适合快速检索获取行号列表。</li><li><strong>长文本列的文本搜索场景：</strong> 针对长文本列，倒排分词索引是更好的方案。相比于暴力字符串匹配，倒排索引提供了更高效的查询性能，避免了大量的 CPU 资源消耗。</li></ul><p>自 Apache Doris 最早引入倒排索引至今已有近一年时间，从，早期 2.0 Preview 版本至最近发布的 2.0.4，这一年间经历了大量开源用户在真实业务环境海量数据下的打磨和验证，性能与稳定性已经得到充分验证。而在后续的规划中，我们也将持续在现有基础上进行迭代和优化，包括：</p><ul><li><strong>自定义倒排索引分词能力，</strong> 针对用户在不同场景下分词效果的需求，提供用户对自定义分词器。</li><li><strong>支持更多类型的倒排索引，</strong> 后续会增加对 Array、Map 等复杂数据类型的支持，以更全面地满足各类查询需求。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 03:12:56 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5735652/blog/10946708</guid>
            <link>https://my.oschina.net/u/5735652/blog/10946708</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大神只用 Excel 就构建了一颗 CPU：具有 128kb RAM、配备汇编语言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>YouTube 科技博主「Inkbox」近日发布视频介绍如何在 Microsoft Excel 的限制下构建功能齐全 CPU。Inkbox 称没有使用任何 Visual Basic 脚本或插件 —— 完全用 Excel 实现。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-b39e1a5e12f6b2b05206163af0964e75039.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D5rg7xvTJ8SU" target="_blank">https://www.youtube.com/watch?v=5rg7xvTJ8SU</a></u></em></p></blockquote><p>据介绍，这是一颗 16 位 CPU，在 Excel 中构建并以 3Hz 时钟频率运行，具有 128KB RAM、16 色 128x128 像素显示屏和自定义汇编语言，所有这些都在 Excel 中运行。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-05bafb20ee50b854fae8d35fd3dd39d81d6.png" referrerpolicy="no-referrer"></p><p>这个 Excel CPU 项目最令人印象深刻的壮举之一是 Inkbox 为其创建了功能完整的<strong>汇编语言 Excel-ASM16</strong>，它包含 23 种不同的指令，并支持变量、标签，甚至二进制文件。虽然这些是汇编语言的基本功能，但对于在 Microsoft Excel 下运行的 16 位 CPU 的限制来说已经足够了。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-d48c1c2c41f8b1cdf10a21f3aeef8642108.png" referrerpolicy="no-referrer"></p><p>如果各位感兴趣，可通过作者在 GitHub 提供的文件来尝试：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FInkboxSoftware%2FexcelCPU" target="_blank">https://github.com/InkboxSoftware/excelCPU</a></u></em>。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-aae05a6c21c604e1ec7a527008912e357a2.png" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 03:08:56 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276824/16-bit-cpu-built-and-runs-in-excel</guid>
            <link>https://www.oschina.net/news/276824/16-bit-cpu-built-and-runs-in-excel</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Windows 重新设计引导安装界面]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微软上周<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsspai.com%2Flink%3Ftarget%3Dhttps%253A%252F%252Fblogs.windows.com%252Fwindows-insider%252F2024%252F01%252F26%252Fannouncing-windows-11-insider-preview-build-26040-canary-channel%252F" target="_blank">发布</a>了新的 Canary 频道 Windows 11 预览版，构建号为 Build 26040。这一版本中，微软大幅修改了使用安装镜像引导安装步骤的界面设计。<strong>据称这是该界面自 Windows Vista 以来首次获得显著更新</strong>，但功能、流程仍与之前大致相同。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-26e854305d1df56a60cfcdba9ed69958381.png" referrerpolicy="no-referrer"></p><p>Build 26040 的其他新功能还包括从附近 Android 设备获取截图、将 Surface 上加强通话中人声的 Voice Clarity 功能开放给更多用户，以及支持 USB 80Gbps 等。微软还在同版本号的 Windows Server 预览版中正式采用了 Windows Server 2025 的品牌名称。</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 29 Jan 2024 02:19:27 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276820/winsetup-redesign</guid>
            <link>https://www.oschina.net/news/276820/winsetup-redesign</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[iOS 17.4 测试版包含大模型相关代码]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>外界普遍预计苹果将在 6 月份通过 iOS 18 推出主要的新人工智能功能。<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F9to5mac.com%2F2024%2F01%2F26%2Fapple-siri-chatgpt-ios-18-development%2F" target="_blank">不过根据 9to5Mac 的报道</a></u>，他们在 iOS 17.4 第一个测试版中发现的代码表明，苹果正在开发由大语言模型技术支持的 Siri 新版本，并得到了其他来源的一些帮助。</p><p>所谓其他来源是指苹果似乎正在使用 OpenAI 的 ChatGPT API 进行内部测试，以帮助开发自己的 AI 模型。代码显示，iOS 17.4 包含一个新的 SiriSummarization 私有框架，可调用 OpenAI 的 ChatGPT API。由于苹果不太可能会在 iOS 18 正式版本中使用 ChatGPT 支持其 AI 功能，所以它更可能是在对自己的大模型进行内部测试，然后与 ChatGPT 的结果进行对照。</p><p>此外，SiriSummarization 框架包含多个系统提示次示例，比如「请总结」、「请回答这个问题」和「请总结给定的文本」之类的内容。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3f96d8da8563affdc4b0df3d91c734d13e7.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2702eb6dc68bef558e9523eeb683230bad0.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-de57b6c81deabb583eec4ad236180f46b43.png" referrerpolicy="no-referrer"></p><p>目前看来，iOS 17.4 代码表明苹果正在测​​试四种不同的人工智能模型。这包括之前报道过的苹果内部模型「Ajax」。并且 iOS 17.4 正在测试两个版本的 AjaxGPT，其中一种在设备上处理，另一种不在设备上处理——可能是在云端。</p><hr><p>延伸阅读：<em><u><a href="https://www.oschina.net/news/272282/apple-wants-ai-to-run-directly-on-its-hardware" target="news">苹果将大语言模型部署到设备本地</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 28 Jan 2024 03:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276784/apple-siri-chatgpt-ios-18-development</guid>
            <link>https://www.oschina.net/news/276784/apple-siri-chatgpt-ios-18-development</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 24.04 LTS 默认内核将采用 Linux 6.8]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Canonical 公布了 Ubuntu 24.04 LTS 的内核计划，并表示将正在开发的 Linux 6.8 作为下一个长期支持 Ubuntu 桌面/服务器发行版的默认内核。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-52cfbfb2fcedea1152f4477d95c244d43dc.png" referrerpolicy="no-referrer"><br><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fintroducing-kernel-6-8-for-the-24-04-noble-numbat-release%2F41958" target="_blank">https://discourse.ubuntu.com/t/introducing-kernel-6-8-for-the-24-04-noble-numbat-release/41958</a></u></em></p></blockquote><p>此前许多人在讨论&nbsp;Ubuntu 24.04 LTS 会采用哪个内核版本，有人觉得是 Linux 6.6 LTS，因为它在 2023 年成为了长期支持版本。也有人认为是最新的稳定内核 Linux 6.7，该版本有很多有用的新特性。</p><p>现在 Canonical 工程师 Andrea Righi 宣布了在 Ubuntu 24.04 中采用 Linux 6.8 作为默认内核的暂定计划。目前实验性内核构建已经可以通过 PPA 获得。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2e410065f0236df7ac936c52bc02d24a386.png" referrerpolicy="no-referrer"></p><p>目前看来，有了 Linux 6.8 内核、GNOME 46 桌面环境、GCC 13 编译器和其他更新的工具链组件、Mesa 24.0 以及许多其他更新的加入，Ubuntu 24.04 LTS 的表现应该会相当不错。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 28 Jan 2024 02:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276779/ubuntu-24-04-will-use-linux-6-8</guid>
            <link>https://www.oschina.net/news/276779/ubuntu-24-04-will-use-linux-6-8</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[感谢有你，1Panel 开源面板项目致敬社区开发者]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; text-align:start"><span><span style="color:#000000">2024 年 1 月 24 日，1Panel 开源面板项目 GitHub Star 数成功突破 15,000 大关。</span></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">1Panel 开源项目（</span></span><em><span><span style="color:#000000">https://github.com/1Panel-dev</span></span></em><span><span style="color:#000000">）于 2023 年 3 月 20 日正式发布。作为一款现代化、开源的 Linux 服务器运维管理面板，1Panel 旨在通过开源的方式，帮助用户简化建站与运维管理流程。</span></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">在广大用户和开发者的支持下，1Panel 与开源社区共同成长，连续二个季度入选 ROSS Index 最具成长性开源初创榜单。1Panel 也是中国领先的开源软件提供商 FIT2CLOUD 飞致云旗下最具成长性的开源项目，自项目对外发布至在代码托管平台 GitHub</span><strong><span style="color:#ff8124">获得 15,000 个 Star 耗时 315 天。</span></strong></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">1Panel 开源项目组感谢以下 61 位社区开发者为本项目在过去的 10 个月所做出的杰出贡献：</span></span></p><p style="color:#000000; text-align:center"><span><span style="color:#000000">zhengkunwang223<br> ssongliu<br> wangdan-fit2cloud<br> wanghe-fit2cloud<br> maninhill<br> liqiang-fit2cloud<br> wan92hen<br> LeeEirc<br> huailei000<br> wojiushixiaobai<br> liuruibin<br> ruibaby<br> luyang351<br> okxlin<br> qwenode<br> WankkoRee<br> Anyexyz<br> deep-project<br> igophper<br> QuentinHsu<br> Mystery00<br> ali-pay<br> eltociear<br> mx2913<br> shaozi17<br> HansHans135<br> wc7086<br> budou0608<br> Avey777<br> penndu<br> TScci<br> moonrailgun<br> emlog<br> vastsa<br> xiongsp<br> clover1420<br> wuhang2003<br> L-607<br> a76yyyy<br> androidmumo<br> mouday<br> kingwrcy<br> bh1xaq<br> sunheyi6<br> maxoyed<br> guclan<br> xiahao90<br> baozishu<br> xinkeng0<br> hhun<br> 2327972001<br> FoXiMao<br> nightzjp<br> xushulang<br> wzrove<br> xiaolongyuan<br> SkyAerope<br> allyxmiko<br> CyJaySong<br> Osub<br> hezhizheng</span></span></p><p style="color:#000000; text-align:start"><span><strong><span style="color:#ff8124">开源漫长路，幸得同行。因为有你，一切才能成真。</span></strong></span></p><p style="color:#000000; text-align:start"><span><span style="color:#000000">为了回馈以上社区开发者对 1Panel 开源面板项目的贡献，1Panel 开源项目组将为名单中每位开发者发放一件精美的定制衞衣，请名单中的开发者携带 GitHub 个人主页截图，在 GitHub 平台联系</span></span><em><span><span style="color:#000000">@wanghe-fit2cloud</span></span></em><span><span style="color:#000000">领取兑换券，在飞致云周边商城兑换即可。</span></span></p><p style="color:#000000; text-align:start"><img alt="" height="800" src="https://oscimg.oschina.net/oscnet/up-64b8ab5f6b7f87f1d738046eae8c0753a59.jpg" width="800" referrerpolicy="no-referrer"></p><p><img alt="" height="800" src="https://oscimg.oschina.net/oscnet/up-424e92275ae129e529a820e5c80a57acaee.jpg" width="800" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 27 Jan 2024 09:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276755</guid>
            <link>https://www.oschina.net/news/276755</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[贾扬清最新开源项目 —— 500 行代码构建的 AI 搜索工具]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>贾扬清前几天在社交平台介绍了自己开发的 AI 应用 <strong>Lepton&nbsp;Search&nbsp;</strong>—— 一个用 500 行 Python 代码构建的对话式 AI 搜索工具。</p><blockquote><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">贾扬清是开源深度学习框架&nbsp;<span>Caffe 创始人、TensorFlow 作者之一、也是 PyTorch 1.0 的共同创始人。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">2023 年 3 月，贾扬清从阿里离职后联合创立了一家新的 AI 公司 Lepton AI，旨在建立高效的 AI 应用平台。Lepton AI 总部位于美国加利福尼亚州帕洛阿托，官网宣称可通过 Lepton AI 在几分钟内高效、大规模地运行 AI 应用。相比大模型，贾扬清团队更偏重 AI 能力的开发。</p></blockquote><p>Lepton Search 体验地址：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsearch.lepton.run%2F" target="_blank">https://search.lepton.run/</a></u></em></p><blockquote><p><img src="https://static.oschina.net/uploads/space/2024/0127/111705_z1mo_2720166.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fjiayq%2Fstatus%2F1750242829769801793" target="_blank">https://twitter.com/jiayq/status/1750242829769801793</a></u></em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-41b1824d46f8241761f7373dd369c4dc32e.png" referrerpolicy="no-referrer"></p></blockquote><p>贾扬清介绍称，Lepton Search 的后端是 Mixtral-8x7b 模型，托管在 LeptonAI，输出速度能达到每秒大约 200 个 token，搜索引擎采用了 Bing 的搜索 API。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-653f2a2bd37324fb0d75d8ceb45ba2c5187.png" referrerpolicy="no-referrer"></p><p>他还分享了自己开发这个项目的一些经验：</p><blockquote><ol><li>搜索质量至关重要。优质的摘要片段是形成精准概括的关键。</li><li>适当加入一些虚构内容实际上有助于补充摘要片段中缺失的「常识性信息」。</li><li>在进行内容概括时，开源模型表现出了卓越的效果。</li></ol></blockquote><p>就在今天，Lepton Search 正式开源，包含完整前后端源代码，采用 Apache License，可商用。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-116ed38956c869e03488944c71900a4e950.png" referrerpolicy="no-referrer"><strong><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fleptonai%2Fsearch_with_lepton" target="_blank">https://github.com/leptonai/search_with_lepton</a></u></em></strong></p></blockquote><p>可以看到，项目的核心 Python 代码确实不到 500 行：</p><p><img src="https://oscimg.oschina.net/oscnet/up-77dd1b3dcedd92ca8bb144ffa26f4580df9.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 27 Jan 2024 03:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276738/search-with-lepton-opensource</guid>
            <link>https://www.oschina.net/news/276738/search-with-lepton-opensource</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 官方中文页面上线]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>据 ChatGPT 页面显示，OpenAI 现已向用户推出 ChatGPT 多语言功能 Alpha 版测试，用户可以参与该测试并选择不同语言的界面。</span></p><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start">如下图所示，ChatGPT 会检测系统当前使用的语言，并提醒用户进行切换。</p><p><img src="https://oscimg.oschina.net/oscnet/up-41f3d658b126bb17b44ecc0dcca38d35513.png" referrerpolicy="no-referrer"></p><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>用户也可以通过设置页面选择不同的语言，目前 OpenAI 提供中文、日语、法语、意大利语、葡萄牙语、德语、俄语等不同的语言选项。</span></p><p style="color:#2a2a2a; margin-left:0; margin-right:0; text-align:start"><span>需要注意的是，<strong>当前版本仅仅是交互页面显示中文，默认语言仍然是英文</strong>。</span></p><p><img src="https://oscimg.oschina.net/oscnet/up-025f0868755df562dfaa3a86e44750ca65a.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 27 Jan 2024 02:57:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276736</guid>
            <link>https://www.oschina.net/news/276736</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌与 Hugging Face 合作，帮助开发人员训练 AI 模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theverge.com%2F2024%2F1%2F25%2F24050445%2Fgoogle-cloud-hugging-face-ai-developer-access" target="_blank">据 TheVerge 报道</a></u>，Google Cloud 与 AI 模型托管平台 Hugging Face 建立了新的合作伙伴关系，让开发人员无需支付 Google Cloud 订阅费用即可构建、训练和部署 AI 模型。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-d368af44406fc85ef32d28adcf03fb2e856.png" referrerpolicy="no-referrer"></p></blockquote><p>现在，使用 Hugging Face 平台的外部开发人员将能够「经济高效」地访问谷歌的张量处理单元 (TPU) 和 GPU 超级计算机，其中包括数千台 Nvidia 的热门且出口受限的 H100。</p><p>Hugging Face 是流行的 AI 模型托管平台，存储了海量开源基础模型，例如 Meta 的 Llama 2 和 Stability AI 的 Stable Diffusion。它还拥有许多用于模型训练的数据库。该平台上托管了超过 350,000 个模型，供开发人员使用或将自己的模型上传到 Hugging Face，就像程序员将代码放在 GitHub 上一样。Hugging Face 的估值为 45 亿美元，去年 Google、亚马逊、Nvidia 等公司帮助筹集了 2.35 亿美元。</p><p>谷歌表示，Hugging Face 用户可以在「2024 年上半年」开始使用人工智能应用程序构建平台 Vertex AI 和 Kubernetes 引擎，帮助训练和微调模型。</p><p>谷歌在一份声明中表示，与 Hugging Face 的合作「进一步增强了谷歌云对开源人工智能生态系统开发的支持」。谷歌的一些模型位于 Hugging Face 上，但其标志性大型语言模型（如 Gemini，现在为聊天机器人 Bard 提供支持）和文本到图像模型 Imagen 不在平台上，被认为是更闭源的模型。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 27 Jan 2024 02:53:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276735</guid>
            <link>https://www.oschina.net/news/276735</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[杭州全橙加入 openKylin，推动社区技术创新和生态发展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>近日，杭州全橙智能软件有限公司<span>（以下简称「<span>杭州全橙</span>」）</span>签署<span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">了 openKylin 社区</span>CLA(Contributor License Agreement 贡献者许可协议)，正式加入 openKylin 开源社区。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="1079" src="https://oscimg.oschina.net/oscnet/up-08b2fa33cf54ed04b117fc975bd25c74844.png" width="829" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>杭州全橙诞生于 2021 年，由一群对开源软件充满热爱的年轻人组成。我们坚信开源软件会成为人类文明的技术底座以及科技知识的存储载体。全橙的使命是帮助企业更加高效的基于开源软硬件生态开发出超越客户预期的产品及服务，并吸引辅助更多的企业进入开源生态贡献中。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><img alt="" height="410" src="https://oscimg.oschina.net/oscnet/up-f22c6fc2081272d89a93914a93adcd38421.png" width="940" referrerpolicy="no-referrer"></p><p><span>在加入 openKylin 社区后，杭州全橙将进一步加强与社区的合作，加入 RISC-V SIG，在开源软件移植方面配合社区的迁移工作，为社区在 RISC-V 领域的开源软件生态贡献力量，推动社区技术创新和生态发展。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 09:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276714</guid>
            <link>https://www.oschina.net/news/276714</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[湖仓新范式的造浪者 | StarRocks 2023 年度总结（文末福利）]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" src="https://files.mdnice.com/user/9541/b8d071a5-8994-43a8-a5b7-40f89b778dae.png" referrerpolicy="no-referrer"><img alt="" height="2182" src="https://oscimg.oschina.net/oscnet/up-caedd95a98fb9ac1dfccb3660bedd1731c4.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="3944" src="https://oscimg.oschina.net/oscnet/up-62a23685e32e3a33c3e2c020e0d291ccbe2.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="2206" src="https://oscimg.oschina.net/oscnet/up-aeb14bfffb7c1900d157a28df7eab7198d9.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="2675" src="https://oscimg.oschina.net/oscnet/up-4c625f199e90927a365f8c3f9e44051ddf3.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="3959" src="https://oscimg.oschina.net/oscnet/up-7d38d20c2c0de1d35eda5259b4644434a90.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="1582" src="https://oscimg.oschina.net/oscnet/up-c362b58f82630c930e5c2bd5d305b5f6673.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="1949" src="https://oscimg.oschina.net/oscnet/up-8954a8e599c50a94e679577d4fa5a0f3c0d.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="2869" src="https://oscimg.oschina.net/oscnet/up-5b2e73606a896c25a1cdebf5a267b85af50.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="1341" src="https://oscimg.oschina.net/oscnet/up-52fe8de49c747cbad97034172df899b5b54.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="1055" src="https://oscimg.oschina.net/oscnet/up-98969aa60f0eed4c4c5c6588b452381fcbc.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="3312" src="https://oscimg.oschina.net/oscnet/up-9285cee27034a78cad2e436895ef705c7c1.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="1583" src="https://oscimg.oschina.net/oscnet/up-a55ea920c7bec4bf0ad447cbd0c80192942.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="1357" src="https://oscimg.oschina.net/oscnet/up-56561c3a899f0bf07376af06b9e3ef5678a.png" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" height="1280" src="https://oscimg.oschina.net/oscnet/up-d4d7604ef7c4a6713f60ad2daec1d9c879f.png" width="845" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><img alt="" src="https://files.mdnice.com/user/9541/1ed2507b-3758-45f5-aa48-353be3881ced.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/91cc5496-2499-4e4c-b398-a9f810b85765.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/8c32a905-cb20-4702-a9b8-6ab1d1c3b465.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/0ef20d30-ee46-4924-9e1d-616cf3535e9a.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/d23dcddb-2766-4fc7-abd5-87222e2192c3.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/8ce92f33-1883-4e93-a907-01faa7efd7ef.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/0f70fa89-2b4d-469a-96c7-bf551c3b4253.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/38b0171e-b1cc-4350-bdb8-ea911c4d1d0d.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/2cdee249-3f6b-45ad-8089-7ae61aacdf2c.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/4f7afe29-7449-491e-8046-5beb79190fb5.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/5cee0625-41f1-4873-87ea-d72bab1f4062.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/ec777ab4-97f9-418c-ab46-4e9abf28c789.png" referrerpolicy="no-referrer"><img alt="" src="https://files.mdnice.com/user/9541/1b46d79c-ac46-4b94-9873-94c8cbc0179c.png" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><strong>新年期望征集</strong></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">社区的进步离不开大家的支持，新的一年我们也期望能与更多的小伙伴们大步前行、共同成长。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">最后，欢迎来 StarRocks 论坛写下你对社区 2024 年的期望，我们还有好礼相赠。大胆的留下你的想法，万一实现了呢！</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">任意选择以下一个或多个问题回答就能成功参加抽奖，2/19 开奖：</p><ol><li><p>你最希望社区推出什么 feature？</p></li><li><p>你最希望社区跟哪个大数据生态组件结合？</p></li><li><p>你最希望社区提供怎样的内容？</p></li><li><p>你希望社区提供什么活动？或是去哪个城市？</p></li><li><p>其他建议</p></li></ol><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><strong>奖品池</strong></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">京东卡 100 元 *3 B 站季度大会员 *5 StarRocks 鼠标垫 *5 StarRocks 峰会纪念 T 恤 *10 （花样可 4 选择 1，因为要定制，年后才会开始寄送！）</p><p><img alt="" src="https://files.mdnice.com/user/9541/230fd404-3e2a-4eed-83fc-287791cbdac6.jpg" referrerpolicy="no-referrer"><img alt="" height="584" src="https://oscimg.oschina.net/oscnet/up-7cfc2e3fb6d0669e252141d7a00e4bd99ed.jpg" width="1080" referrerpolicy="no-referrer"></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><strong>活动传送门</strong></p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">https://forum.mirrorship.cn/t/topic/10947</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 08:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276709</guid>
            <link>https://www.oschina.net/news/276709</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年最受欢迎的人工智能工具 TOP 10]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>使用 SEO 行业著名的工具 SEMrush，通过从列出 AI 工具的各种目录中抓取数据，根据访问量排名，最受欢迎的前 10 大工具如下：</p><p>1、OpenAI 的产品 <strong>ChatGPT</strong> 在 2022 年底引发了人工智能热潮，成为 2023 年最受欢迎的人工智能工具。从 2022 年 9 月到 2023 年 8 月，ChatGPT 占据了行业网络访问量的 60% 以上，网站访问量达到 146 亿次。</p><p>2、排在 ChatGPT 之后的是另一个聊天机器人<strong>Character.AI，</strong>它与生产力相关的用户查询的单一 LLM 不同，而是用户可以自由交谈的对话机器人（dialog agents）。其可以扮演的角色包括从电视节目和视频游戏中的明星到约会教练、还有全球在世和过世的名人。</p><p>3、书写工具 <strong>QuillBot</strong> 跻身 2023 年最受欢迎的人工智能网络产品前三名，这三者合计占人工智能产品网站访问量的 80% 以上。</p><p>4-5、除了 LLMs 之外，领先的 AI 图像生成器 <strong>Midjourney</strong> 是 2023 年第四大最受欢迎的 AI 工具，紧随其后的是开源社区 <strong>Hugging Face</strong>，该社区拥有数百种独特的 AI 模型，其中包括 、图像生成器和其他可免费访问的人工智能工具。</p><p>6-10、排名第 6-10 名的工具依次为：大型语言模型 Google 的<strong>Bard</strong>、人工智能写作工具<strong>NovelAI</strong>、视频制作人工智能工具 <strong>CapCut</strong>、聊天机器人工具 <strong>JanitorAI</strong>、图像生成工具<strong> Civitas</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0dcc31a6ee823c1bb8bb86385ea8cd56b72.png" referrerpolicy="no-referrer"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.visualcapitalist.com%2Franked-the-most-popular-ai-tools%2F" target="_blank">https://www.visualcapitalist.com/ranked-the-most-popular-ai-tools/</a></em></u></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 07:56:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276707/the-most-popular-ai-tools-2023</guid>
            <link>https://www.oschina.net/news/276707/the-most-popular-ai-tools-2023</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FTC 就微软、OpenAI 等的 AI 投资及合作展开调查]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美国联邦贸易委员会（FTC）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ftc.gov%2Fnews-events%2Fnews%2Fpress-releases%2F2024%2F01%2Fftc-launches-inquiry-generative-ai-investments-partnerships" target="_blank">宣布</a>针对生成式 AI 市场中最大的五家参与者：谷歌母公司 Alphabet 、亚马逊、Anthropic PBC、微软和 OpenAI&nbsp;五家大型科技公司的 AI 投资和合作伙伴关系展开调查。</span></p><p><span style="color:#000000">作为 OpenAI 的主要投资方，微软自 2019 年双方开展合作以来已向 OpenAI 投资了至少 130 亿美元，并获得了该公司 49% 的股份。亚马逊和谷歌也已分别承诺向 Anthropic 投资 40 亿美元和 20 亿美元。</span></p><p><span style="color:#000000">FTC 此举是基于《联邦贸易委员会法》第 6(b) 条，审查微软与 OpenAI、亚马逊与 Anthropic 以及谷歌与 Anthropic 之间的交易对市场竞争格局的影响。此次调查也将有助于该机构加深执法人员对生成式 AI 开发者和云服务供应商之间的投资和合作关系的了解。</span></p><p><img height="229" src="https://oscimg.oschina.net/oscnet/up-ae265ed8bae04913684ea7b268e78f88045.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">目前，FTC 已将强制令发送给了各家，并要求这几家公司在 45 天内提供调查所需的信息。包括：</span></p><ul><li><span style="color:#000000">有关具体投资或合作伙伴关系的信息，包括协议和投资/伙伴关系的战略理由。</span></li><li><span style="color:#000000">具体合作或投资的实际影响，包括围绕新产品发布、管理或监督权以及定期会议主题的决策。</span></li><li><span style="color:#000000">交易的竞争影响分析，包括与市场份额、竞争、竞争对手、市场、销售增长潜力或产品或地域市场扩张有关的信息。</span></li><li><span style="color:#000000">AI 投入和资源的竞争，包括生成式 AI 所需的关键产品和服务的竞争态势。</span></li><li><span style="color:#000000">向任何其他政府实体（包括外国政府实体）提供的与这些主题相关的任何调查、信息请求或其他问询有关的信息。</span></li></ul><p><span style="color:#000000">FTC 主席 Lina M. Khan 在声明中表示，「历史表明，新技术可以创造新市场和良性竞争。随着公司竞相开发 AI 并将其货币化，我们必须警惕那些扼杀这一机遇的策略。我们的研究将揭示占主导地位的公司所进行的投资和合作是否有扭曲创新和破坏公平竞争的风险。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 07:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276704/ftc-launches-inquiry-generative-ai-investments-partnerships</guid>
            <link>https://www.oschina.net/news/276704/ftc-launches-inquiry-generative-ai-investments-partnerships</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年湖南省人工智能和大数据产业发展年度报告]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>湖南省工业和信息化厅今日发布了<em>《2023 年湖南省人工智能和大数据产业发展年度报告》</em>。报告提到，2023 年湖南省<strong>人工智能核心产业产值达到 189 亿元</strong>，同比增长 24%，<strong>大数据产业产值达到 1250 亿元</strong>，同比增长 13%。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2024/0126/143021_0nKV_2720166.png" referrerpolicy="no-referrer"><br><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgxt.hunan.gov.cn%2Fgxt%2Fxxgk_71033%2Ftzgg%2F202401%2Ft20240126_32635744.html" target="_blank">https://gxt.hunan.gov.cn/gxt/xxgk_71033/tzgg/202401/t20240126_32635744.html</a></em></u></p></blockquote><p>根据报告中的算力相关数据，湖南全省算力规模超 5200PFlops，超算算力位居全国第三位，建成和在建规模以上数据中心 51 个，标准机架 17.2 万架。</p><p>人工智能技术方面，<span style="background-color:#ffffff; color:#3b3b3b">湘江鲲鹏推出的兆瀚</span><span style="background-color:#ffffff; color:#3b3b3b">RA2300-A</span><span style="background-color:#ffffff; color:#3b3b3b">系列</span><span style="background-color:#ffffff; color:#3b3b3b">AI</span><span style="background-color:#ffffff; color:#3b3b3b">推理服务器在算力、精度、计算效率等方面处于国内领先水平，广泛应用于</span><span style="background-color:#ffffff; color:#3b3b3b">OCR</span><span style="background-color:#ffffff; color:#3b3b3b">识别、搜索推荐、智慧城市等诸多中心侧大模型推理场景。</span></p><p>报告最后提到了他们面临诸多问题和挑战：</p><ul><li><strong>一是算力资源利用效率有待提升</strong>。全省智能算力占比较低，算力资源利用率不高，全省规模以上数据中心机架利用率低于全国平均水平。</li><li><strong>二是头部企业支撑引领有待加强</strong>。我省人工智能、大数据企业普遍存在体量小、技术力量薄弱、产品单一等问题，缺少具有全国代表性龙头企业。</li><li><strong>三是行业融合应用水平有待拓展</strong>。我省人工智能、大数据应用场景总体不够深入，与不同领域结合程度差距较大，主要应用场景集中在智能制造、智能交通、电子政务智能管控等领域，农业、轻工业等领域应用程度相对较低。</li><li><strong>四是产业创新发展生态有待优化</strong>。高质量数据集相对匮乏，人工智能开源生态尚未完备，产业链的带动性和影响力有待进一步提高。</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 06:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276697</guid>
            <link>https://www.oschina.net/news/276697</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[今天是将 Firefox 设置为默认浏览器的好日子]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>苹果今日<u><a href="https://www.oschina.net/news/276674">宣布</a></u>在在欧盟地区对 iOS、Safari 浏览器和 App Store 进行更改。</p><p>其中 Safari 浏览器在欧盟地区的更改如下：<strong>iOS 用户现在就可以将第三方网络浏览器（而非 Safari 浏览器）设为默认浏览器</strong>。</p><p>Firefox 当即发推表示：「<em>今天是将 Firefox 设置为默认浏览器的好日子<img alt="😎" height="20.39772605895996" src="https://abs-0.twimg.com/emoji/v2/svg/1f60e.svg" style="margin-left:0.075em; margin-right:0.075em" width="20.39772605895996" referrerpolicy="no-referrer">。</em>」</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-af61337c299ca89913bc382cdf8e3d8f7e7.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ffirefox%2Fstatus%2F1750252384582803578" target="_blank">https://twitter.com/firefox/status/1750252384582803578</a></u></em></p></blockquote><ul><li>延伸阅读：<em><u><a href="https://www.oschina.net/news/269923/firefox-on-the-brink" target="news">Firefox 会被淘汰吗？</a></u></em></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 04:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276693</guid>
            <link>https://www.oschina.net/news/276693</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[重庆警方破获「苹果 ID 贷」非法经营案，以「库克回租」为名非法放贷、暴力催收]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thepaper.cn%2FnewsDetail_forward_26150502" target="_blank">据中新网报道</a></u>，重庆巫溪县公安局获悉，该局成功侦破一起全国性「苹果 ID 贷」非法经营案，捣毁涉及 21 省 (市) 非法经营网络贷款犯罪团伙 9 个，抓获犯罪嫌疑人 41 人，涉及借款人员 2 万余名，涉案金额 1.3 亿元。</p><p>2023 年 5 月，重庆巫溪县公安局凤凰派出所接到陶某报警称，自己的苹果手机 (iPhone13) 被人远程控制锁机，请求民警帮助。后经民警综合研判，一个以黄某为首的从事互联网非法放贷犯罪团伙逐渐浮出水面。</p><p>经查，自 2022 年 8 月以来，黄某等 9 人未经监管部门批准，以营利为目的，打着「库克回租」的幌子，通过平台投放「苹果 ID 贷」广告，招揽苹果手机用户并提供贷款，再通过远程控制手机应用，修改苹果 ID 密码，威胁将手机锁机，并以拨打亲属电话骚扰、曝光个人信息等催收方式，让借款人超额还款。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-26b87b238e3799ee00df2fb9ff4bb158c38.png" referrerpolicy="no-referrer"></p></blockquote><p>该团伙累计非法放贷本金 700 余万元，非法获利 100 余万元。掌握相关证据后，专案组民警分赴陕西、四川等地，将该非法经营犯罪团伙成员全部抓获。</p><p>办案民警随后对该案扩线研判出另外 8 个涉及全国 21 省 (市) 与黄某团伙具有相同作案手法的非法经营犯罪团伙，梳理出借款人员 2 万余名。</p><p>巫溪县公安局在重庆市公安局经侦总队指导下，将该案报请公安部，并成功发起全国集群战役，成功打掉利用「苹果 ID 贷」非法经营网络贷款犯罪团伙 9 个，抓获犯罪嫌疑人 41 人，涉案金额 1.3 亿元。</p><p>目前，该案所有犯罪嫌疑人均被依法采取刑事强制措施，案件正在进一步办理中。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 26 Jan 2024 04:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/276691</guid>
            <link>https://www.oschina.net/news/276691</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
