<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[开源中国-综合资讯]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[开源中国-综合资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 08 Mar 2024 12:46:47 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[中国开发者团队打造、AI 原⽣编程语⾔——MoonBit（月兔）宣布开源核心库]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>MoonBit（月兔）</strong>是中国开发者团队创建的编程语言（类似 Rust，支持 GC），由粤港澳大湾区数字经济研究院（IDEA 研究院）基础软件中心负责人张宏波领导的团队开发，目标是打造下一代智能开发平台。</p><p>更确切地说，MoonBit 是一个用于云计算和边缘计算的 WebAssembly 端到端<strong><span style="background-color:#e67e22">编程语言工具链</span></strong>，集开发、编译、测试、部署于一体 —— 涵盖了<strong>通用程序语言设计、编译器、构建系统、<span style="background-color:#ffffff; color:#3e3e3e">编辑器和语言服务器、</span></strong><strong>IDE、部署工具</strong>等。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e5e0b28951654b436ae58851ccd89e23a74.png" referrerpolicy="no-referrer"></p><p>MoonBit 宣称是国内首个工业级编程语言及完整工具链，专为云 + AI 打造，其核心技术自主研发，通过专注 Wasm 形成后发优势，目前在核心指标（<strong>编译速度、运行速度、体积大小</strong>）已成功领先传统语言。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9e98befd4e414666b4cec2e6eaec0a287ef.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-3560401c3111f53d706370aa0ff14fe13b9.png" referrerpolicy="no-referrer"></p><p><em>via&nbsp;<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FywFwp2tuyACBQRvnf9Pwcg" target="_blank">https://mp.weixin.qq.com/s/ywFwp2tuyACBQRvnf9Pwcg</a></u></em></p><p>近日 MoonBit <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.moonbitlang.com%2Fblog%2Fmoonbitlang-core-opensource" target="_blank">宣布正式开源核心库</a></u>，并表示已接近 Beta 测试阶段，语言功能也趋于稳定。目前已建立了用于支持核心库开发的重要基础设施，确保提升语言功能的稳定性。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-81a4f0c79951695bfffeca223ae5fff4029.png" referrerpolicy="no-referrer"></p></blockquote><p>MoonBit 核心库已托管至 GitHub：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmoonbitlang%2Fcore" target="_blank">https://github.com/moonbitlang/core</a></p><p><img src="https://oscimg.oschina.net/oscnet/up-12af06ca111ce715a0c8b40fea3926aceff.png" referrerpolicy="no-referrer"></p><p>按照发布计划，MoonBit 将于今年 Q2 发布 Beta 测试，并将编译器源代码开源。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f6cad2b32b15b432636c4a34391f3fe3f99.png" referrerpolicy="no-referrer"></p><p>延伸阅读：</p><ul><li><a href="https://www.oschina.net/news/269052" target="_blank">国产编程语言 MoonBit（月兔）需要支持中文关键字吗？</a></li><li><a href="https://www.oschina.net/news/255951/moonbit-first-announce" target="_blank">中国开发者团队创建的编程语言：MoonBit（月兔）</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 09:25:38 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282169/moonbitlang-core-opensource</guid>
            <link>https://www.oschina.net/news/282169/moonbitlang-core-opensource</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[阿里巴巴集团 CEO 吴泳铭：通义千问正加快追赶 GPT-4]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>阿里巴巴集团 CEO 吴泳铭在《中国网信》杂志发文表示，人工智能大模型开启全新的智能时代，引发人机交互、计算范式和认知协作三场革命，正在加快形成新质生产力、增强发展新动能。其中，人机交互革命将重构一切软件，大模型将驱动一切硬件，并催生出人形机器人等人工智能原生终端产业。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-38880f78cb87b35d70913e5494121ae0c55.png" referrerpolicy="no-referrer"></p></blockquote><p>在计算范式方面，当前正处于从 CPU（中央处理器）主导的通用计算模式向以 GPU（图形处理器）为核心的人工智能计算加速切换的技术拐点。未来的云计算发展模式将以人工智能大模型驱动的计算为核心，带动全行业进入新一轮的技术创新期。</p><p>吴泳铭表示，<span style="color:#222222">通义千问正加快追赶 GPT-4，并把基础大模型能力释放出来。通过开放 API/SDK 调用等方式，千行百业的开发者和企业用户不仅可以便捷开发人工智能原生应用，还可以与合作伙伴高效实现产业协同，促进大模型上下游产业链融合发展。</span></p><p><span style="color:#222222">作为国内基础大模型的代表之一，</span><span style="color:#222222">通义千问同时开源了可在消费级终端部署的 18 亿参数模型以及视觉理解、音频理解两款多模态大模型，实现「全尺寸、全模态」开源。</span></p><blockquote><p><em>原文：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FxaBrKq3bCoZ0ex4_R-6g2w" target="_blank">吴泳铭：拥抱人工智能驱动的产业智能革命</a></u></em></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 06:20:21 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282129</guid>
            <link>https://www.oschina.net/news/282129</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[开源日报 | RISC-V 能否和 x86、Arm 一起成为三大主流架构；给阎王开发地府管理系统]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.3.6</strong></span></h3><h2><strong><span style="color:#16a085">今日要点</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/281958" target="_blank">人形机器人训练框架 Humanoid-Gym 开源</a></h3><p>具身智能与人形机器人公司星动纪元联合清华大学、上海期智研究院开源了人形机器人强化学习训练框架 Humanoid-Gym。据称用户可以通过该框架使用 sim-to-sim 转换接口，在更高精度的仿真环境 Mujoco 中进行验证，继而提升 sim-to-real 转换的效率和成功率。</p><p><img src="https://oscimg.oschina.net/oscnet/up-95a8171d1abfb99f48eb5c4100d0f64b981.png" referrerpolicy="no-referrer"></p><h3><a href="https://www.oschina.net/news/281899/beta-node-js-org" target="_blank">Node.js 新版官网开启 Beta 测试：全新现代化 UI、优化交互</a></h3><p style="margin-left:.0001pt; margin-right:0"><img src="https://oscimg.oschina.net/oscnet/up-d7f75fbfacc0c0f7aa4bd49a44845da9c0e.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-c9984afc8c57cf2cc9b031519ad713980ba.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">体验地址：</span><strong style="color:#333333"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbeta-node-js-org.vercel.app%2Fen" target="_blank">https://beta-node-js-org.vercel.app/en</a></u></em></strong></p><hr><h2><strong><span style="color:#16a085">今日观察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-6ec3b20f675b27562c05f71a7f68b0feeea.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FO3MFRyhUM" target="_blank">蚁工厂</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-f79882793f2c3b5ba0d8ef389f91762bb0a.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">-&nbsp;&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA4NjMxNTMyNA%3D%3D%26mid%3D2650024520%26idx%3D1%26sn%3D27ada577f394f4cd84730bc226f97d55%26chksm%3D87ca121bb0bd9b0d8310b2e67031d026aa8086433326d1bee68b7d22984cbddfae42c880bb70%26token%3D1369750951%26lang%3Dzh_CN" target="_blank">与非网 eefocus</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推荐</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-45a4fc134e321b61b047e5dab22fc904087.png" referrerpolicy="no-referrer"></p><p><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fupscayl%2Fupscayl" target="_blank">https://github.com/upscayl/upscayl</a></u></em></p><hr><h2><span style="color:#16a085"><strong>开源之声</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-2ba28e306747a770ec1cfa3080a160bc9cf.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-5dbb425a68782d320559ece122394be5db8.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日项目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 GitHub 精选</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-25880e79ca4957bcef3f0121f8720f50f26.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在线阅读完整日报内容，访问：</span></strong><br><em><u><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7xd6teyhekcvamw/24_risc_v_x86_arm_5LsjoStPUn.pdf" target="_blank">开源日报第 024 期：RISC-V 能否和 x86、Arm 一起成为三大主流架构；给阎王开发地府管理系统</a></u></em></h4></blockquote><hr><p><strong>往期回顾</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/svxac61bjmbmmw5/23_google_microsoft_cM5zZacKru.pdf" target="_blank">开源日报第 023 期：Google=开源，好评；Microsoft=闭源收入还低，差评</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/3vmzfjvp7mpvv26/22_sora_cuda_Syy7OJyUvc.pdf" target="_blank">开源日报第 022 期：轻松复现 Sora 模型；事关 CUDA 兼容，英伟达禁止了；百度还差一个「遥遥领先」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/z3rhs3qkyeqwoax/21_open_ai_JROaEZat3b.pdf" target="_blank">开源日报第 021 期：闭源模型就是比开源安全；起诉 OpenAI 不能更赞同；中国算力产业出现五个真问题</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/lv84pwvd03it00i/20_open_ai_pingora_yaml_mE5RuB20Vl.pdf" target="_blank">开源日报第 020 期：为什么王炸都来自 OpenAI；Pingora 最好不要用 YAML 当配置文件</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/mx86z1dhywrw71p/19_ai_c_llm_IgpNOVZtCz.pdf" target="_blank">开源日报第 019 期：我让 AI 用 C 语言写一个算法；微软三进制 LLM</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/qdljicvqiqsshd6/187ZiLwG48lc_CngfQJ1Qxs.pdf" target="_blank">开源日报第 018 期：苹果十年造车梦碎；这个开源项目有点...「大胆」</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">开源日报第 017 期：MariaDB 消亡史；写代码我有三不沾；V 神建议马斯克用 Linux</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">开源日报第 016 期：鸿蒙程序员平均月薪超 1 万 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">开源日报第 015 期：为什么挡不住英伟达；Sora 不靠蛮力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">开源日报第 014 期：目前的人工智能技术连猫的智能水平都没达到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">开源日报第 013 期：等到 Sora 开源了立刻推出属于我们自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">开源日报第 012 期：Sora 给中国 AI 带来的真实变化；Dart 3.3 发布</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">开源日报第 011 期：目前还没有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">开源日报第 010 期：Tauri v2 支持 Android 和 iOS，跨平台开发新选择</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">开源日报第 009 期：Vue.js 诞生 10 周年；扎克伯格解释 Meta 为什么要开源其 AI 技术</a></li><li><a href="https://www.oschina.net/news/277585">开源日报第 008 期：推动中国开源软硬件发展的经验与建议</a></li><li><a href="https://www.oschina.net/news/277415">开源日报第 007 期：「Linux 中国」 开源社区宣布停止运营</a></li><li><a href="https://www.oschina.net/news/277214">开源日报第 006 期：选择技术栈一定要选择开源的</a></li><li><a href="http://www.oschina.net/news/277040">开源日报第 005 期：RISC-V 万兆开源交换机发售；npm 存在大量武林外传视频</a></li><li><a href="https://www.oschina.net/news/276864">开源日报第 004 期：百度输入法在候选词区域植入广告；大神用 Excel 构建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 04:32:37 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282115</guid>
            <link>https://www.oschina.net/news/282115</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[工信部：准备试点开放互联网数据中心]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">今天（8 日）上午，</span>在十四届全国人大二次会议第二场「部长通道」集中采访活动上，工信部部长金壮龙<span style="background-color:#ffffff; color:#222222">介绍推进新型工业化举措时表示</span>，今年的重点工作主要有四项：</p><ul><li>一是全面保持回升向好态势，深入实施十大行业稳增长工作方案。</li><li>二是全力推进制造业、重点产业链高质量行动计划，发挥联组企业，发挥产业链供应链韧性和竞争力。</li><li>三是加快推进以先进制造业为骨干的现代化产业体系。推动传统产业向高端化、智能化、绿色化转型。打造一批具有国际影响力的中国制造品牌，比如国产大飞机、燃气轮机、大邮轮等，都是这几年经过重大攻关突破的。还要创建国家制造业创新中心，发展高科技，实现产业化，快速形成新质生产力，培育壮大先进制造业集群。</li><li>四是，着力推进产业科技创新能力，发挥企业在创新中的主体作用。首先要推进科技创新与产业创新深度融合，另一个要推进信息化与工业化深度融合，包括超前建设 5g 算力等信息设施，促进制造业向数字化、网络化、智能化发展等。金壮龙说，推进新型工业化要深化改革、扩大开放，所以我们国家全面取消了制造业领域外资准入限制，同时我们准备试点开放互联网数据中心等增值电信服务。</li></ul><p><span style="background-color:#ffffff; color:#222222">金壮龙表示，推进新型工业化要深化改革、扩大开放，所以我们国家全面取消了制造业领域外资准入限制，同时我们准备试点开放互联网数据中心等增值电信服务。</span>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 03:44:11 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282111</guid>
            <link>https://www.oschina.net/news/282111</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[央视评「某自助建站软件」系列案：知识产权]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.cctv.com%2F2024%2F03%2F08%2FARTIdzXtam1xEcKQJptkU89a240308.shtml" target="_blank">央视新闻发布独家视频</a>，列举了一些被写入今年最高法的工作报告的典型案例，其中包括一起【 知识产权「钓鱼式维权」案】：</p><blockquote><p>某公司宣传其「自助建网」软件可「免费」下载使用，却以用户未在网站页面保留其版权标识等为由，提起诉讼 9000 多件。法院审理认为，其以不当经营方式诱发大批量「侵权」，靠索赔获利不应支持，遂大幅下调判赔标准，批量诉讼应声而落。各级人民法院严格依法保护知识产权，遏制「钓鱼式维权」。</p></blockquote><p><img alt="" src="https://static.oschina.net/uploads/space/2024/0308/113006_IZ8Z_4489239.png" referrerpolicy="no-referrer"></p><p>此前<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1710072119651876226%26wfr%3Dspider%26for%3Dpc" target="_blank">湖南媒体报道</a>相关案件时提到了某公司的三步「钓鱼」模式：</p><p><img src="https://oscimg.oschina.net/oscnet/up-a7d67974c0289259343f730292c08a3f115.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 03:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282109</guid>
            <link>https://www.oschina.net/news/282109</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微软计划 3 月底发布首款 AI PC]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fhardware%2Fsurface%2Fexclusive-microsoft-will-unveil-oled-surface-pro-10-and-arm-surface-laptop-6-this-month-ahead-of-major-windows-11-ai-update" target="_blank">据 Windows Centra 报道</a>，微软计划在本月晚些时候发布新款 Surface Pro 和 Surface Laptop 硬件产品，<strong>而这些产品将会作为微软首款人工智能 PC 推出</strong>。</p><p>全新 Surface Pro 10 和 Surface Laptop 6 将是首批搭载基于英特尔酷睿 Ultra 和高通骁龙 X Elite 处理器的 Surface PC，配备新一代 NPU，可增强 AI 性能。</p><p>Windows Central 报道称，AI Explorer 功能是 AI PC 与普通 PC 的区别所在。它被看作是一个「升级版 Copilot」，内置历史/时间轴功能，用户在电脑上所有活动都将转化为可以用自然语言搜索的时刻（moment）。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-877fbcc3a3bb7964562c57c2352094e6958.png" referrerpolicy="no-referrer"></p><p>该功能适用于所有应用程序，用户可以通过该功能直接搜索之前打开的对话、文档、网页与图片。</p><blockquote><p>例如，用户可以输入「找一下上次李梅说她喜欢哪些餐厅」，AI Explorer 就会显示出李梅之前提到这些餐厅时的确切对话。</p></blockquote><blockquote><p>提示词含糊一些也同样奏效，例如「帮我找找和恐龙有关的东西」，AI Explorer 便会调出之前用户在电脑上打开过的有关恐龙的所有单次、短语、图片以及相关主题。</p></blockquote><blockquote><p>AI Explorer 还可以根据现有情况，帮助用户启动工作流程或项目，甚至可以基于当前屏幕内容提出任务建议。比如，当用户正在浏览一张图片时，AI Explorer 会自动弹出「编辑图片」按键，用户可以输入「用照片应用程序移除这张图片的背景」等相关操作。</p></blockquote><p>之前新一代操作系统 Windows11 23H2 已重点强调了 AI 功能，并提供多项 AI 工具：集成基于 Bing Chat 和 GPT-4 的 Copilot，并对一些操作系统中的基础功能进行 AI 升级，包括画图（Point）、视频编辑器（Clichamp）、截图工具（Snipping Tool）和照片等。</p><p>但 Windows Central 提醒，上述 AI 功能将作为 Windows 11 24H2 版本更新的一部分，在今年秋季发布，这也意味着，本次新款 Surface Pro 和 Surface Laptop 不会在发布之初即拥有 AI Explorer 功能。</p><p>除了微软之外，多家厂商也早已紧锣密鼓地展开布局，储备多款产品抢滩 AI PC。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-adbd9a7447864da92e1b6848acd57f22df9.png" referrerpolicy="no-referrer"></p><p>有报告指出，端侧 AI 部署是当前 AI 实现规模化扩展及应用落地的关键。作为底层技术和上层应用之间的载体，AI PC 在模型侧、硬件侧、软件及应用侧均存在产业升级趋势，AI PC 将是 AI 端侧落地第一站。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 03:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282104</guid>
            <link>https://www.oschina.net/news/282104</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[PieCloudDB Database 3 月产品动态丨功能再度升级，安全机制更加完善]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1><strong>第一部分 PieCloudDB Database 最新动态</strong></h1><ul><li><strong>元数据缓存服务功能迭代</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">PieCloudDB 实现元数据 MetaCache 缓存服务，<strong>支持缓存进程信息，大幅度提升了获取快照操作的性能，</strong><span>&nbsp;</span>从而加快查询相应速度。</p><ul><li><strong>本地缓存 LocalCache 的阶段性功能</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">PieCloudDB 本地缓存清理策略新增阶段性功能，粒度更加精细化，<strong>新增缓存命中率展示函数 pdb_get_local_cache_hit_rate（）。</strong></p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-3f73bbfc6118193b248c3685bfbe08ec82a.png" referrerpolicy="no-referrer"></p><ul><li><strong>云上云版新增 mTLS 安全机制</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">PieCloudDB 云上云版新增 Mutual Transport Layer Security（mTLS）安全机制，<strong>有效提高网络通信的安全性，防止中间人攻击、数据篡改和信息泄露等威胁</strong>，赋能 isito 对跨集群 rpc 的 7 层网络管控能力，如分流、灰度、负载均衡等。</p><ul><li><strong>PieCloudDB 新增产品兼容性互认证证书</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">PieCloudDB 近期完成了与 OpenCloudOS 和 TencentOS Server 两款产品的兼容性认证测试，进一步巩固了国产化兼容、适配程度，助力企业客户建立自主可控技术体系，围绕业务场景打造领先的数据计算解决方案。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-9a963dc3b3bde1d67443180cca8cd95bc04.png" referrerpolicy="no-referrer"></p><h1><strong>第二部分 OpenPie 近期新闻</strong></h1><ul><li><strong>拓数派走进北大研究生公选课</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">拓数派联手开源联盟 PG 分会打造数据库内核开发从入门到进阶内容，经过评审成功进入北京大学研究生开源开发实践公选课框架。拓数派产品市场总监吴疆将作为讲师之一针对查询优化器原理展开授课。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em>直达链接：</em><span>&nbsp;</span><a href="https://my.oschina.net/u/5944765/blog/11045028"><em>点击了解详情</em></a></p><ul><li><strong>PostgreSQL 2023 代码贡献榜发布，拓数派荣占一席</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">在 2023 年，PostgreSQL 90% 的新代码由 50 人完成，拓数派技术专家 Richard Guo 是其中之一，并已经连续两年上榜，充分说明了拓数派团队的技术实力。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em>直达链接：</em><span>&nbsp;</span><a href="https://my.oschina.net/u/5944765/blog/11030244"><em>点击了解详情</em></a></p><ul><li><strong>拓数派技术专家被 PostgreSQL 官方正式认可为 Contributor</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">拓数派技术专家 Richard Guo 荣获 PostgreSQL 官方认可，正式成为 PostgreSQL Contributors 中的一员，据统计，Richard 是目前 PG Contributor 中唯二的中国人。</p><h1><strong>第三部分，数据库行业热点</strong></h1><ul><li><strong>Sora 震撼发布，生成式 AI 的飞跃</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">OpenAI 于 2 月 15 日正式发布了文生视频大模型 Sora，在保证视频质量的同时，能够根据用户提供的文本描述生成长达 60s 的视频。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em>来源：openai.com/sora</em></p><ul><li><strong>Snowflake CEO 宣布退休，公司股价暴跌 20%</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">云数据平台独角兽 Snowflake 财报营收指引低于预期，2 月 28 日，其首席执行官 Frank Slootman 决定退休，隔夜，Snowflake 股价在盘后交易中暴跌超过 20%。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em>来源：Snowflake 官网</em></p><ul><li><strong>MariaDB 面临私有化收购提议</strong></li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">2 月 19 日，MariaDB 披露收到了私募股权公司 K1 Investment Management 的临时收购要约，总交易金额约为 3700 万美元。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><em>来源：MariaDB 官网</em></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 02:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282083</guid>
            <link>https://www.oschina.net/news/282083</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.14.0 - 自定义角色支持自定义权限]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-7a870fb5ce9429fbcf559a3d5891101ac45.png" alt="" referrerpolicy="no-referrer"></p><h2>🚀 新功能</h2><ul><li>自定义角色支持自定义权限。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-a4b9b9ed9eca8068b3303df1ca77c287471.png" alt="file" referrerpolicy="no-referrer"></p><ul><li>SQL 审核 CI 支持 BitBucket。</li><li>数据脱敏支持跨库查询。</li><li>SQL 编辑器中可分享表的链接。</li></ul><h2>🎄 改进</h2><ul><li>支持 MongoDB TLS/SSL 连接。</li><li>优化 Redis 查询展示结果。</li><li>在工单列表上显示失败的任务状态。</li><li>添加了一个 SQL 审核规则，建议用户为大型表启用 gh-ost 在线变更。</li><li>PostgreSQL 工单中 SET ROLE 语句对 CREATE INDEX CONCURRENTLY 语句生效。</li><li>数据脱敏支持 PostgreSQL 函数作为数据源。</li><li>将批量变更模式项目中新建的数据库添加到待执行的 DDL 工单中。</li><li>允许在 MySQL 5.6 版本上使用 gh-ost。</li></ul><h2>🐞 Bug 修复</h2><ul><li>修复了 AWS DocumentDB 的兼容性问题。</li><li>修复了 PostgreSQL TLS/SSL 连接的的问题。</li></ul><h2>📕 安装及升级</h2><p>参考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升级指南</a>。如果从之前版本升级，获取新版本后，重新启动升级即可。</p><hr><p>💡 更多资讯，请关注 Bytebase 公号：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 02:14:53 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/11046384</guid>
            <link>https://my.oschina.net/u/6148470/blog/11046384</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[姜宁三连任 Apache 软件基金会董事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Apache 软件基金会于近日举行了一年一度的成员会议，并<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.apache.org%2Ffoundation%2Fentry%2Fannouncing-the-new-asf-board-of-directors" target="_blank">选举</a>出了 2024 年度新的董事会成员：</p><ul><li>Rich Bowen</li><li>Shane Curcuru</li><li>Christofer Dutz</li><li>Jeff Jirsa</li><li>Willem Jiang</li><li>Jean-Baptiste Onofre</li><li>Justin Mclean</li><li>Craig L Russell</li><li>Sander Striker</li></ul><p><img height="304" src="https://oscimg.oschina.net/oscnet/up-3497b100ece60279decc1be3604bf382c93.png" width="500" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#24292e">这也是姜宁继 <a href="https://www.oschina.net/news/184964/new-asf-board">2022</a>、2023 后，在 2024 年三连任进入 ASF 董事会。此外，去年的董事成员&nbsp;</span><span style="color:#24292e">Bertrand Delacretaz 和 Sharan Foga</span>&nbsp;卸任，<span style="background-color:#ffffff; color:#24292e">ASF<span>&nbsp;</span></span>表达了对他们的感谢，并对新任董事和回归董事表示了欢迎。</p><p><span style="background-color:#ffffff; color:#24292e">有关 ASF 治理的概述以及 ASF 董事会、执行官和项目/委员会副主席的完整列表可访问：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_9-GJwLqQy2leglLxXNblg" target="_blank">http://apache.org/foundation/</a><span style="background-color:#ffffff; color:#24292e">。</span></p><p><strong><span style="background-color:#ffffff; color:#24292e">延伸阅读：</span></strong></p><ul><li><a href="https://my.oschina.net/u/3859945/blog/5504643" target="news">姜宁，带程序员前往开源「乌托邦」</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 08 Mar 2024 02:07:53 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282078</guid>
            <link>https://www.oschina.net/news/282078</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[RWKV 在「不可作弊的模型评测」中获得良好成绩]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><span>众所周知，目前大模型的基准测试很容易受到各种因素的影响，比如在训练中偷跑测试集之类。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><span>GitHub 开发者&nbsp;Jellyfish042 则认为，</span><span>用「实时的、新鲜的数据</span><span>」去</span><span>测试大模型，可能是一种更公平的模型测评解决方案。</span></span><span>因此，他</span><span>提出了一种名为 Uncheatable Eval（不可作弊的模型评测）&nbsp;的新型模型评估测试。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span>Uncheatable Eval 会</span><span style="background-color:#ffffff; color:#1f2328">使用<strong>最新的 arXiv 论文和新闻文章</strong>等实时语料库，以此来评估语言模型的真实建模能力和泛化能力。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#1f2328">仓库地址：<u>https://github.com/Jellyfish042/uncheatable_eval</u></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><strong><u>最新测试结果</u></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><span style="background-color:#ffffff; color:#1f2328">在最新一期针对<span>&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">3B&nbsp;参数规模<span style="background-color:#ffffff; color:#1f2328">模型</span></span>的&nbsp;&nbsp;Uncheatable Eval&nbsp; 基准测试中，</span><span style="background-color:#ffffff; color:#1f2328">我们很开心地看到：在最新的 arXiv 论文测评中（无论是物理还是计算机科学方向），RWKV 模型最新的第六代架构 「RWKV-6」&nbsp;的表现都非常好，在基准测试中博得头筹。</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span><span style="background-color:#ffffff; color:#1f2328">前一代架构&nbsp;「RWKV-5」亦不遑多让，名列前茅。</span></span></p><p style="text-align:center"><img height="246" src="https://oscimg.oschina.net/oscnet/up-0497e4b1f6b0c62f9462ddf137992172eaf.png" width="1472" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><span style="color:#888888">图：使用物理方向<span style="background-color:#ffffff">&nbsp;arXiv&nbsp;论文进行&nbsp;<span style="background-color:#ffffff">Uncheatable Eval 测试</span></span></span></p><p style="text-align:center"><img height="247" src="https://oscimg.oschina.net/oscnet/up-88bfa21424434ad9be0c1632f641a97564d.png" width="1475" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><span style="color:#888888"><span>图：使用计算机科学方向</span><span style="background-color:#ffffff">&nbsp;arXiv&nbsp;论文进行&nbsp;Uncheatable Eval 测试</span></span></p><p style="text-align:center"><img height="247" src="https://oscimg.oschina.net/oscnet/up-604113d391456541e78f40ca0d35705e322.png" width="1474" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0px; margin-right:0px; text-align:center"><span style="background-color:#ffffff; color:#888888"><span style="background-color:#ffffff; color:#888888">图：使用 BBC 新闻</span>进行&nbsp;Uncheatable Eval 测试</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#1f2328">在 3B&nbsp;参数模型的三项&nbsp;<span style="background-color:#ffffff; color:#1f2328">&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">Uncheatable&nbsp;Eval 测试</span>中，RWKV-6 和 RWKV-5&nbsp;的<strong>综合得分</strong>闯入三甲，综合得分第一为&nbsp;<span style="background-color:#ffffff; color:#1f2328">sta</span><span style="background-color:#ffffff; color:#1f2328">blel</span><span style="background-color:#ffffff; color:#1f2328">m-3b-4e1t</span>。</span></p><p style="text-align:center"><img height="344" src="https://oscimg.oschina.net/oscnet/up-3b47918865e3d633202fd9235f118893886.png" width="1010" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="background-color:#ffffff; color:#888888"><span style="background-color:#ffffff; color:#888888">图：</span>3B&nbsp;模型在&nbsp;Uncheatable Eval 测试的综合得分</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><strong><span style="background-color:#ffffff; color:#1f2328">补</span><span style="background-color:#ffffff; color:#1f2328">充</span><span style="background-color:#ffffff; color:#1f2328">说</span><span style="background-color:#ffffff; color:#1f2328">明：</span></strong><span style="background-color:#ffffff; color:#1f2328">相比&nbsp;<span style="background-color:#ffffff; color:#1f2328">sta</span><span style="background-color:#ffffff; color:#1f2328">blel</span><span style="background-color:#ffffff; color:#1f2328">m-3b-4e1t 炼的 4T 令牌的语料<span style="background-color:#ffffff; color:#1f2328">（1T&nbsp;语料</span><span style="background-color:#ffffff; color:#1f2328">炼</span><span style="background-color:#ffffff; color:#1f2328">&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">4&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">遍）</span>，</span>参与评测的 RWKV 模型</span><span style="background-color:#ffffff; color:#1f2328">只炼了&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">1.1&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">T 令牌的语料</span><span style="background-color:#ffffff; color:#1f2328">。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><strong><span style="background-color:#ffffff; color:#1f2328"><u>往期</u><u>测试结果</u></span></strong></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#1f2328">下</span><span style="background-color:#ffffff; color:#1f2328">面是一些</span><span style="background-color:#ffffff; color:#1f2328">旧的测试结果，与最新的</span><span style="background-color:#ffffff; color:#1f2328">&nbsp;Uncheatable Eval&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">代码相比，下图使用的测试方法略有不同。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><u><strong><u>1. 往期测试：（1.5B 参数模型）</u></strong></u></p><p style="text-align:center"><img height="528" src="https://oscimg.oschina.net/oscnet/up-229f9455c036a49ed0cd4ee789aef50288a.png" width="1834" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><span style="color:#888888">图：使用<span style="color:#888888">物理方向</span><span style="background-color:#ffffff; color:#888888">&nbsp;arXiv&nbsp;论文</span></span><span style="background-color:#ffffff; color:#888888">进行&nbsp;Uncheatable Eval 测试</span></span></p><p style="text-align:center"><img height="530" src="https://oscimg.oschina.net/oscnet/up-b2d69a14247c711f7a749a181ffc7b4e5c6.png" width="1834" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><span style="color:#888888">图：使用<span style="color:#888888">计算机科学方向</span><span style="background-color:#ffffff; color:#888888">&nbsp;arXiv&nbsp;论文</span></span><span style="background-color:#ffffff; color:#888888">进行&nbsp;Uncheatable Eval 测试</span></span></p><p style="text-align:center"><img height="551" src="https://oscimg.oschina.net/oscnet/up-c7c121dde7abad04ee4533cf4c22b55da16.png" width="1835" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><span style="color:#888888">图：使用 BBC 新闻</span><span style="background-color:#ffffff; color:#888888">进行&nbsp;Uncheatable Eval 测试</span></span></p><p style="text-align:center"><img height="560" src="https://oscimg.oschina.net/oscnet/up-a2de13eb341a40947d1bef3e3dad3d43c80.png" width="987" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><span style="background-color:#ffffff; color:#888888">图：</span><span style="background-color:#ffffff; color:#888888">1.5B&nbsp;模型在&nbsp;Uncheatable Eval 测试的综合得分</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="color:#888888"><span style="background-color:#ffffff; color:#888888"><span style="background-color:#ffffff; color:#888888"><span style="background-color:#ffffff; color:#1f2328">在 1~2B&nbsp;&nbsp;参数模型的&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">&nbsp;</span><span style="background-color:#ffffff; color:#1f2328">Uncheatable&nbsp;Eval 测试</span><span style="background-color:#ffffff; color:#1f2328">中，RWKV-6 1.6B 模型的</span><strong>综合得分</strong><span style="background-color:#ffffff; color:#1f2328">排名第一。</span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><u><strong><u>2.往期测试：（7B 模型）</u></strong></u></p><p style="text-align:center"><img height="323" src="https://oscimg.oschina.net/oscnet/up-e723f83517d5626867c86e3c26170126803.png" width="1443" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888">图：使用计算机科学方向<span style="background-color:#ffffff; color:#888888">&nbsp;arXiv&nbsp;论文进行&nbsp;Uncheatable Eval 测试</span></span></p><p style="text-align:center"><img height="323" src="https://oscimg.oschina.net/oscnet/up-6581fb5d0184668f2318dad7a50aa546d0d.png" width="1443" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888">图：使用物理方向 arXiv 论文进行 Uncheatable Eval 测试</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="background-color:#ffffff; color:#1f2328"><span style="background-color:#ffffff; color:#1f2328">可以看到，</span><span style="background-color:#ffffff; color:#1f2328">在往期的测试结果中，无论是 1.5B 还是 7B 参数规模，&nbsp;</span>RWKV 模型都保持着非常优秀的表现。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><u><strong><u>相关链接</u></strong></u></p><p><span style="background-color:#ffffff; color:#1f2328">Uncheatable Eval 仓库地址：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJellyfish042%2Funcheatable_eval" target="_blank"><u>https://github.com/Jellyfish042/uncheatable_eval</u></a></p><h3><u><strong>RWKV 模型介绍</strong></u></h3><p><span style="color:#444444">RWKV 是一种创新的深度学习网络架构，它将 Transformer 与 RNN 各自的优点相结合，同时实现高度并行化训练与高效推理，时间复杂度为线性复杂度，在长序列推理场景下具有优于 Transformer 的性能潜力。</span></p><p style="text-align:center"><img height="1168" src="https://oscimg.oschina.net/oscnet/up-7e19694ea848d1ae9ed6bbf9aa05c4dcf5c.png" width="2758" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><span style="color:#888888">图：</span>RWKV 架构</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff">RWKV 模型的最新版本是 RWKV-6 ，架构图如下：</span></p><p style="text-align:center"><img height="3374" src="https://oscimg.oschina.net/oscnet/up-07f0ead5cdea81926af77d9c2fbf0a0d206.jpg" width="1606" referrerpolicy="no-referrer"></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center"><span style="color:#888888"><span style="background-color:#ffffff; color:#888888">图：</span><span style="background-color:#ffffff; color:#888888">RWKV-6 架构</span></span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#444444">相对&nbsp;<span>Transformer 架构，</span>RWKV 架构的推理成本降低 2~10 倍，训练成本降低 2~3 倍。</span></p><p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"><span style="color:#444444">RWKV 模型最初由彭博设计，主要算力由 Stability AI 和 EleutherAI 等机构捐赠。如今，RWKV 已捐赠给 Linux Foundation AI&amp;Data 作为孵化项目。</span></p><p><u><strong>加入 RWKV 社区</strong></u></p><ul><li><span><span style="color:#444444">RWKV 官网：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.com%2F" target="_blank"><u>https://www.rwkv.com/</u></a></span></li><li>RWKV GitHub 仓库：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBlinkDL%2FRWKV-LM" target="_blank"><u>https://github.com/BlinkDL/RWKV-LM</u></a></li><li>RWKV-5 模型下载：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-5-world" target="_blank">https://huggingface.co/BlinkDL/rwkv-5-world</a></u></li><li>RWKV-6 模型下载：<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-6-world" target="_blank">https://huggingface.co/BlinkDL/rwkv-6-world</a></u></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 11:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282030</guid>
            <link>https://www.oschina.net/news/282030</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[前谷歌软件工程师被控窃取机密 AI 技术]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>美联社报道，美国司法部周三表示，Google 公司的一名前软件工程师被指控窃取该公司的人工智能技术，同时与两家位于中国的公司秘密合作。中国公民丁林葳（音译）因四项联邦商业机密盗窃罪在加利福尼亚州纽瓦克市被捕，每项罪名皆最高可判处 10 年监禁。</p><p>总检察长梅里克-加兰（Merrick Garland）在旧金山举行的美国律师协会会议上<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dl64VlrA-GUA" target="_blank">宣布了该案</a></u>，他与其他执法部门领导人曾多次警告中国经济间谍活动的威胁以及人工智能进步带来的国家安全问题。</p><p>联邦调查局局长克里斯托弗-雷（Christopher Wray）在一份声明中说："今天的指控是最新的例证，说明中华人民共和国境内公司的关联公司为窃取美国的创新技术不择手段。窃取美国公司的创新技术和商业机密会造成就业损失，并对经济和国家安全造成破坏性后果。"</p><p>最近几周，美国司法部领导人一直在就外国对手如何利用人工智能技术对美国造成负面影响敲响警钟。</p><p>司法部副部长丽莎-摩纳哥（Lisa Monaco）在上个月的一次演讲中<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapnews.com%2Farticle%2Ffbi-election-interference-wray-2024-campaign-ai-a0c4a95c818839b18f919c6d648c4dcf" target="_blank">表示</a></u>，政府的多机构颠覆性技术打击小组将把人工智能执法放在优先事项的首位。</p><p>加利福尼亚州北区法院周三公布的一份起诉书称，丁在 2019 年受雇于 Google，可以接触到该公司超级计算数据中心的机密信息，但他在两年前开始将数百个文件上传到一个个人持有的 Google 云账户。</p><p>检察官说，在盗窃开始后的几周内，丁被中国一家初创科技公司聘为首席技术官，该公司吹嘘自己使用了人工智能技术。起诉书称，他前往中国，参加了该公司的投资者会议，并试图为其筹集资金。起诉书称，他还单独创办了一家总部位于中国的初创公司，并担任首席执行官，该公司希望训练"由超级计算芯片驱动的大型人工智能模型"，且并没有向 Google 披露这两家公司的关联关系。</p><p>12 月 26 日，他从公司辞职。三天后，Google 相关部门得知他曾以其中一家中国公司首席执行官的身份出席了在北京举行的投资者会议而报警。起诉书称，Google 方面还查看了监控录像，录像显示另一名员工在丁工作的大楼扫描了他的门禁卡，使他看起来不在中国。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9b61448ad14c6ad426c8fb453f0a7042e03.png" referrerpolicy="no-referrer"></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-5d14d945f47b2a80e9f34f07d722e5033ed.png" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 11:18:59 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282027</guid>
            <link>https://www.oschina.net/news/282027</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[LFOSSA 祝大家女神节快乐！助力女性开源职业发展！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><div><div><div><div><p><img height="1000" src="https://oscimg.oschina.net/oscnet/up-87fca7e99dc80187c6d9bafde6383da273a.png" width="2350" referrerpolicy="no-referrer"></p><p><span style="color:rgba(0, 0, 0, 0.9)">女神节，是一个赞美和庆祝的日子。让我们在这个特殊的日子里，向所有的女性表示最深的敬意和祝福。</span><span style="color:rgba(0, 0, 0, 0.9)">回顾历史，我们可以看到女性在各个领域都取得了令人瞩目的成就。</span><span style="color:rgba(0, 0, 0, 0.9)">无论是在科学、艺术、政治还是商业领域，女性都展现出了她们独特的才华和魅力。</span><span style="color:rgba(0, 0, 0, 0.9)">她们不仅在自己的领域里取得了巨大的成功，还为整个社会带来了积极的影响。</span></p><p><span>在开源领域，虽然</span><span style="color:#000000">开源女性开发者属于少数群体，但女性开发者于开源中扮演重要的角色和贡献。</span><span>LFOSSA 开源软件学园为表达对女性的尊重，认识到女性价值，欣赏女性的才华和贡献，为她们在开源领域提供更多的机会和平台<strong>。在 3 月 8 日国际妇女节来临之际，LFOSSA 开源软件学园为众多开发者送出专属福利</strong>&nbsp;——&nbsp;</span><span style="color:#ff0000"><strong>3 月 7 日 - 3 月 10 日，</strong><strong>Linux Foundation</strong><strong>开源软件学园官方课程及认证考试全场 9 折。</strong></span></p><p><span>Linux Foundation 开源软件学园一直致力于推<span style="color:#000000">动</span></span><span style="color:#000000">开源多样化及包容的开源社区</span><span>，鼓励女性在不同领域挖掘属于自己独特的闪光点。请持续关注我们，之后陆续推出超多女神节的活动，欢迎参加！</span></p><p><span>感谢女性在不同领域取得的成就，每一位女性都拥有源源不断的智慧，同样拥有原原本本的自信。保持女性在开源事业上独特的魅力，能够充分发挥自己的潜力。</span></p><p><span>祝大家女神节快乐，继续持之以恒，卓尔不群！</span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>部份精选官方课程认证超级套购</span></span></span></p><p style="color:#242b3c; text-align:center"><span><img alt="1707387858746433.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707387858746433.png" width="270" referrerpolicy="no-referrer"></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA<span>&amp;CKS&amp;LFS258&amp;LFS260 超级套购</span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 8198 元</span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">，</span><span><span style="color:#ab1942"><span><strong>现价 7378.2 元</strong></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F23" target="_blank">CKS&amp;LFS260&amp;CKA&amp;LFS258 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span style="color:#ab1942"><span><img alt="1707387940238031.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707387940238031.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>KCNA&amp;CKA&amp;LFS250&amp;LFS258 超级套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 6158 元</s><span>，<span style="color:#ab1942"><strong>现价 5542.2 元</strong></span></span></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F57" target="_blank">LFS250&amp;LFS258&amp;KCNA&amp;CKA 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span style="color:#ff0000"><span><span><span style="color:#000000"><img alt="1707388029979327.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388029979327.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span><span>CKA&amp;CKAD&amp;</span>CKS<span>超级套购</span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 7438 元</s><span>，<span style="color:#ab1942"><strong>现价 6694.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F30" target="_blank">CKA&amp;CKAD&amp;CKS 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><img alt="1707388086590851.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388086590851.png" width="270" referrerpolicy="no-referrer"></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;CKS&amp;PCA 超级套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 6528 元</s><span>，<span style="color:#ab1942"><strong>现价 5875.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F69" target="_blank">CKA&amp;CKS&amp;PCA 超级套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><span><img alt="1707388149744838.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388149744838.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;PCA 超级套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><s>原价 4288 元</s><span>，<span style="color:#ab1942"><strong>现价 3859.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F58" target="_blank">PCA&amp;CKA 双证套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span><span style="color:#ab1942"><img alt="1707388208170950.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388208170950.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKS&amp;CKA 双证套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 5358 元</span></span><span><span style="color:#ab1942">，<strong>现价 4822.2 元</strong></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F22" target="_blank">CKS&amp;CKA 双证套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><span><span><img alt="1707388275334439.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388275334439.png" width="270" referrerpolicy="no-referrer"></span></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>CKA&amp;ICA 双证套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 4288 元</span></span><span>，</span><strong>现价 3859.2 元</strong></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F71" target="_blank">CKA&amp;ICA 双证套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center"><span><span><img alt="1707388329473176.png" height="150" src="https://training.linuxfoundation.cn/files/editor/images/1707388329473176.png" width="270" referrerpolicy="no-referrer"></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span>RVFA&amp;LFD210-CN 套购</span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:center"><span><span><span style="background-color:#fff8f8; color:rgba(0, 0, 0, 0.9)">原价 2208 元</span></span><span>，<span><span style="color:#ab1942"><strong>现价 1987.2 元</strong></span></span></span></span></p><p style="color:#242b3c; text-align:center"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack%2F63" target="_blank">RVFA&amp;LFD210-CN 套购_专业课程-Linux Foundation 开源软件学园</a></span></p><p style="color:#242b3c; text-align:center">&nbsp;</p><p style="color:rgba(0, 0, 0, 0.9)"><span><span>查看更多 LFOSSA 培训、认证及套购产品：</span></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank"><span>培训</span></a><span>：<span style="color:#245bdb"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank">Linux 系统管理_云技术线上自学课程-Linux Foundation 开源软件学园</a></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank"><span>认证</span></a><span>：</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank">Linux 自学考试认证-Linux Foundation 开源软件学园</a></span></p><p style="color:rgba(0, 0, 0, 0.9)"><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank">套购</a>:&nbsp;<span style="color:#245bdb"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank">Linux Foundation 开源软件学园-Linux_云技术_Kubernetes 专业考试认证_K8s_CKA_CKS</a></span></span></span></p><p style="color:rgba(0, 0, 0, 0.9); text-align:justify">&nbsp;</p><p><span><span><span>点击&nbsp;<span style="color:#ff0000"><strong>此网址</strong></span><strong>&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2F" target="_blank">Linux Foundation 开源软件学园-Linux_云技术_Kubernetes 专业考试认证_K8s_CKA_CKS</a>&nbsp;</strong></span>进入 LFOSSA 官网。了解更多 Linux 基金会相关课程和认证考试。</span></span></p><p>&nbsp;</p><p><span><strong><span style="color:#000000">来自 LFOSSA 开源软件学园的</span>温馨提示：</strong></span></p><p><span><span><strong>特别需要注意的是，</strong><strong>Linux 基金会</strong><strong>发布了&nbsp;</strong><strong>LF</strong><strong>认证考试政策的变更如下</strong>：</span></span></p><p><span><span style="color:#d83931"><strong>自</strong><strong>北京时间</strong><strong>2024 年 4 月 1 日上午 8 时起，所有 36 个月有效期的</strong><strong>LF</strong><strong>认证考试将缩短为 24 个月有效期。任何在&nbsp;</strong><strong>UTC</strong><strong>&nbsp;时间 2024 年 4 月 1 日 00:00 之前，安排并通过考试的学员仍然将获得 36 个月的认证有效期。</strong></span></span></p><p><span><span>由于考试需求将会急剧增加，我们建议考生尽早安排预约 CKA 考试。你可以在这里了解有关详情：</span></span></p><p><span><span><strong>考试政策的公告</strong>——</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247498227%26idx%3D1%26sn%3D21e81f4521e07892176dc002c59a9162%26chksm%3Dc3595926f42ed030c326966c0fa15c38b502565abf76a791450f1307a12eb9404af897e8b596%26scene%3D21%23wechat_redirect" target="_blank">CNCF 认证考试更新公告</a></span></p><p><span><span><strong>考试贴士</strong>&nbsp;——</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247502744%26idx%3D1%26sn%3Dc67bc4b2851fa8fb16e88e8036810bae%26chksm%3Dc3596b4df42ee25b6513756e28352d3c2b9258a1aa2c352d15eed8aedb2116abacaa1daf085f%26scene%3D21%23wechat_redirect" target="_blank">LF 认证考试考生贴士</a></span></p></div></div></div></div></div></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 10:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/282019</guid>
            <link>https://www.oschina.net/news/282019</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[我的历时一年的独立开发故事]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 2023 年 2 月 5 日，当我从赫尔辛基飞往上海浦东机场时，并没有预见到接下来一年的生活将会是怎样的。经过几个月悠闲轻松的日子后，我开始了独立开发的征程。首先我会简要介绍一下成果，然后分享我对独立开发的看法以及一些技术层面的经验。 经过一年的努力，截至目前，我的成果如下：</p><ul><li>支出 2000 美元，主要云服务支出</li><li>收入 0，注册用户 0</li><li>一个可运行的系统： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flets-script.com" target="_blank">https://lets-script.com</a></li></ul><p>我不反对独立开发，但要认清现实，如果你的目标是通过独立开发发财致富，那么一个可能的结果是（开玩笑）：</p><ol><li>一年，众叛亲离</li><li>二年，妻离子散</li><li>三年，灰飞烟灭</li></ol><p>如果你有这样的觉悟，或者不是从致富的角度出发，独立开发也是一种宝贵的经历。</p><p>接下来，我将分享我开发的产品以及一些技术经验。请允许我以一个业余选手的身份谈论这些想法。。</p><h2>产品理念</h2><p>我希望打造一个以脚本为核心的简单任务执行平台。市面上的产品往往认为 Shell 脚本不够友好，因此会在外层添加各种包装，有的使用 YAML 配置，有的采用自定义编程逻辑，类似于 Github Action。然而，Github 用一个 checkout 插件来完成 git checkout 的功能，我认为直接使用 git 更为简洁明了。如果你认为 Shell 脚本已经足够强大、方便且经得起考验，那又何必在外面再加一层，用一些功能不强大的方法来掩盖 Linux 脚本系统的强大呢？</p><p>lets-script.com 允许用户部署他们自己的任务运行服务器，无论是在家中、公司还是在互联网上。目前，系统共享了两个运行服务器，一个位于日本，另一个在我家中。</p><h2>不要迷信云和云服务</h2><p>云服务和人工智能无疑都非常有价值。然而，在媒体和云服务提供商的大力宣传下，用户和开发者可能会被迷惑，失去独立思考的能力。</p><p>云服务虽然发展迅速，但单体软件同样在迅速发展。如果你没有充分的理由，就不要轻易将自有系统替换为云服务。比如，消息队列，用微软的 Eventbus 替代 RabbitMQ？我认为毫无必要，何必轻易地将自己锁定在一个厂商身上呢？我最初也使用了 Eventbus，但经过深思熟虑，最终还是切换回了 RabbitMQ。我开始使用 Azure 的容器应用服务，但后来也切换到了 Nginx 架构，所有这些措施都使我后来可以轻松地迁移到其他云平台。</p><h2>不要完全依赖第三方登录</h2><p>要保持自有的登录系统始终可用，然后再选择性的加入协作登录系统。我的系统在初期也是使用第三方的登录系统。后来，架设自己的邮件服务器，重新实现用户登录功能。以 email 为中心的登录系统是非常可靠的系统。</p><h2>Cloudflare 的诱惑和局限</h2><p>个人认为 Cloudflare 是一个非常具有特色的产品，也挺慷慨，一般个人项目基本上不需要花钱。在 https 和 http 场景下几乎是首选，我把所有的域名都交给 Cloudflare 解析了。比如我家里的一台服务器目前用作 lets-script 的命令执行服务器。网址是 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fworker-2.lets-script.com" target="_blank">https://worker-2.lets-script.com</a> , 只要家里的服务器上安装一个 Cloudlared 服务，该 https 加密的网址始终可用。</p><p>但也不要盲目信赖 Cloudflare。它并不适用于所有场景，有时使用你自己的 Nginx 才是最终的解决方案。比如，524 错误，默认超时时间为 100 秒（企业订阅可以自定义超时时间），超过 100 秒就会返回 524 错误。而我的系统，在控制枱交互的情况下，执行 10 分钟的任务是很常见的，因此无法通过 Cloudflare 代理。此外，text/event-stream 或者 ndjson 都无法通过 Cloudflare 代理，至少目前官方不支持。虽然官方支持 WebSocket，但我最终选择了 WebSocket 作为我的系统的解决方案，例如，当您运行系统的 Hello World 示例时，您可以清晰地感受到实时输出。</p><p>接下来谈谈我对独立开发的反思。</p><h2>独立开发是低效的，是一种过时的生产方式</h2><p>除了少数基于命令行的工具类软件，其它软件都需要横跨许多技术，它天然需要协作开发，用一己之力去完成是非常低效的。比如，我的系统，开始使用 Reactjs，Gatsbyjs 使用 js 开发，后来不用框架了，用自己的半通用性 js 库，切换到 typescript，然后大量自定义 Codemirror 的功能，在后端的 Webflux 之间来回切换，无论专注于那一边都可以将代码写的很稳定，但是两头兼顾，两边的代码质量都打折扣。</p><h2>独立开发需要做好充足的准备，包括技术、资金、时间和心理准备。</h2><p>由于社会形态的差异，中国人从事独立开发更需要有强大的心理准备，因为独立开发意味着你像一个工匠，将注意力转移到了产品之上，从而于社会产生距离，要控制好这种孤独感，保持身心健康。</p><h2>如果你正在考虑独立开发，请务必慎重考虑。</h2><p>如果你的主要目的是经济回报，更加需要慎重考虑。</p><p>最后，我的独立开发的产品已经完成，从 azure 平台迁移到一家日本公司的平台之后预计费用减半，就当作日常娱乐开支，让它长期运行吧。</p><p>此外，我正在积极寻找一份软件开发的工作，如果你有碰巧阅读到本文，请帮助我扩散和联系，<em><strong>非常感谢</strong></em>。</p><p>我的联系方式： <a href="https://www.oschina.net/action/GoToLink?url=mailto%3Ajianglibo%40hotmail.com" target="_blank">jianglibo@hotmail.com</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 09:48:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/jianglibo/blog/11046245</guid>
            <link>https://my.oschina.net/jianglibo/blog/11046245</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GreptimeDB v0.7 发布 — 全面支持云原生监控场景]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>就在上周，我们公布了 GreptimeDB 2024 路线图，揭示了今年 GreptimeDB 的几个重大版本计划。随着三月初春的到来，首个适用于生产级别的 GreptimeDB 开源版也在万物复苏的「惊蛰」时节如约而至。v0.7 版本标志着我们向生产就绪版本迈出的重要一步，我们欢迎社区的每一位成员积极参与使用，并提供宝贵的反馈意见。</p><p>从 v0.6 到 v0.7，Greptime 团队取得了显著的进步：<strong>累计合并了 184 个 Commits，修改了 705 个文件，包括 82 项功能增强、35 项 Bug 修复、19 次代码重构，以及大量的测试工作。</strong> 这期间，一共有 <strong>8 名独立贡献者</strong>参与 GreptimeDB 的代码贡献，<strong>特别感谢 Eugene Tolbakov 作为 GreptimeDB 首位 committer，持续活跃在 GreptimeDB 的代码贡献中</strong>，和我们一同成长！</p><blockquote><p><strong>更新重点（省流版）</strong><strong>Metric Engine</strong>：针对可观测场景设计的全新引擎可被推荐使用，能处理大量的小表，适合云原生监控场景； <strong>Region Migration</strong>：优化了使用体验，可以通过 SQL 方便地执行 Region 迁移； <strong>Inverted Index</strong>：高效定位用户查询所涉及数据段，显著减少扫描数据文件所需 IO 操作，加速查询过程。</p></blockquote><blockquote><p>v0.7 是 GreptimeDB 开源以来少数几次的重大版本更新之一，此次我们也将在视频号直播。了解更多功能细节、观看 demo 演示，或者和我们核心开发团队深入交流，欢迎参与下周四（3 月 14 日）晚 19:30 的直播。</p></blockquote><h2>Region Migration</h2><p>Region Migration 提供在 Datanode 之间迁移数据表的 Region 的能力，借助这个能力，我们可以容易地实现热点数据迁移，以及负载平衡的水平扩展。GreptimeDB 在发布 v0.6 时曾提到初步实现了 Region Migration，此次版本更新完善并优化了使用体验。</p><p>现在，我们可以通过 SQL 方便地执行 Region 迁移：</p><pre><code class="language-sql">select migrate_region(
    region_id,
    from_dn_id,
    to_dn_id,
    [replay_timeout(s)]);
</code></pre><p><img src="https://oscimg.oschina.net/oscnet/up-6b527cc6319d52e06cda4b35c8481e3f486.png" alt="" referrerpolicy="no-referrer"></p><h2>Metric Engine</h2><p>Metric Engine 是针对可观测场景来设计的一个的全新引擎，它的主要目标是能处理大量的小表，特别适合云原生监控比如使用 Prometheus 的场景。通过利用合成的宽表，这个新的 Engine 提供指标数据存储和元数据复用的能力，「表」在它之上变得更轻量，它可以克服现有 Mito 引擎的表过于重量级的一些限制。</p><p><img src="https://oscimg.oschina.net/oscnet/up-34283d2899e494d63d72b44a78def7c94a9.png" alt="" referrerpolicy="no-referrer"></p><ul><li><p><strong>图例 - 原始 Metric 数据</strong></p><ul><li>以下六个 Node Exporter 的 Metrics 为例。在 Prometheus 为代表的单值模型系统中，即使是关联度很高的指标也需要拆成若干个分开存储。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-9f8b2bb0d60477ad713d884fea5bed395ef.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>图例 - 用户视角的逻辑表</strong></p><ul><li>Metric Engine 原汁原味地还原了 Metrics 的结构，用户见到的就是写入的 Metrics 结构。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-7b84dc5597d1cc9db0eb3fd0c6dc5309637.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>图例 - 存储视角的物理表</strong></p><ul><li>在存储层，Metric Engine 进行了映射，使用一张物理表来存储相关的数据，能够降低存储成本，并支撑更大规模的 Metrics 存储。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-cae0172c4a2c1b78bee1eee55e9d221e63f.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>图例 - 接下来的研发计划：Fields 自动分组</strong></p><ul><li>在实际场景产生的 Metrics 中，大部分都是有关联性的。GreptimeDB 可以自动推导相关的指标并放合并到一起，不仅能跨 Metrics 减少时间线的数量，而且对于关联查询也很友好。</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-27c251355fb040fe61da01dc3b819b88edb.png" alt="" referrerpolicy="no-referrer"></p></li><li><p><strong>存储成本优化</strong></p></li></ul><p>基于 AWS S3 存储后端进行成本测试，各写入约三十分钟的时长的数据，总和写入量约 30w row/s 。统计过程中的各个操作发生的次数，根据 AWS 的报价估算成本。测试过程中 index 功能均开启。</p><p>报价参考 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fs3%2Fpricing%2F" target="_blank">https://aws.amazon.com/s3/pricing/</a> 的 Standard 等级</p><p><img src="https://oscimg.oschina.net/oscnet/up-621ba7795c14b78da54e214601f04a07a59.png" alt="" referrerpolicy="no-referrer"></p><p>从上述测试表格可以看到，Metric Engine 能够通过减少物理表的数量大幅降低存储成本，各阶段操作次数均有数量级减少，折算的综合成本相比 Mito Engine 能降低八倍以上。</p><h2>Inverted Index</h2><p>Inverted Index 作为新引入的索引模块，旨在高效定位用户查询所涉及数据段，显著减少扫描数据文件所需 IO 操作，加速查询过程。TSBS 测试场景下场景性能平均提升 50%，部分场景性能提升近 200%。Inverted Index 的核心优势包括：</p><ol><li>开箱即用：系统自动生成合适的索引，用户无需额外指定；</li><li>功能实用：支持多列列值的等值、范围和正则匹配，确保在多数场景下都能迅速定位和过滤数据；</li><li>灵活适应：自动调控内部参数以平衡构建成本和查询效率，有效应对不同场景的索引需求</li></ol><ul><li><strong>图例 - Inverted Index 的逻辑表示及数据定位过程</strong><ul><li>用户在多个列指定过滤条件，经过 Inverted Index 的快速定位，能排除掉大部分不匹配的数据段，最终得到较少的待扫描数据段，实现查询加速。</li></ul></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-6ed07495343672eeb6a785d084409529bc8.png" alt="" referrerpolicy="no-referrer"></p><h2>其他更新</h2><p><strong>1. 数据库的管理功能得到显著增强</strong></p><p>我们对 information_schema 表进行了大幅补充，新增了 SCHEMATA 和 PARTITIONS 等信息。此外，新版本引入了众多新的 SQL 函数以实现对 DB 的管理操作。例如，现在通过 SQL 即可触发 Region Flush、执行 Region 迁移，还可以查询 procedure 的执行状态等。</p><p><strong>2. 性能提升</strong></p><p>在 v0.7 版本中，对 Memtable 进行了重构，提升了数据扫描速度并降低了内存占用。同时，我们针对对象存储的读写性能也做了许多的改进和优化。</p><h2>升级指南</h2><p>由于新版本存在一些重大变更，本次 v0.7 发布需要停机升级，推荐使用官方升级工具，大致升级流程如下：</p><ol><li>创建一个全新的 v0.7 集群</li><li>关闭旧集群流量入口（停写）</li><li>通过 GreptimeDB CLI 升级工具导出表结构和数据</li><li>通过 GreptimeDB CLI 升级工具导入数据到新集群</li><li>入口流量切换至新集群</li></ol><p>详细升级指南请参考：</p><ul><li>中文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.cn%2Fuser-guide%2Fupgrade" target="_blank">https://docs.greptime.cn/user-guide/upgrade</a></li><li>英文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.com%2Fuser-guide%2Fupgrade" target="_blank">https://docs.greptime.com/user-guide/upgrade</a></li></ul><h2>未来展望</h2><p>我们下一个重要的里程碑在四月份，届时将推出 v0.8 版本。这一版本将引入 GreptimeFlow，一款优化的流计算方案，专门用于 GreptimeDB 数据流中执行连续聚合操作。考虑到灵活性的需求，GreptimeFlow 既可以集成进 GreptimeDB 计算层共同部署，也能作为独立服务部署。</p><p>除了功能层面的不断升级，我们在版本性能方面也在持续进行优化，v0.7 版本的性能虽然对比之前已经有了巨大的提升，但在可观测场景下距离部分主流方案还有一些差距，这也将是我们接下来的重点优化方向。</p><p>欢迎阅读 GreptimeDB Roadmap 2024，全面了解我们全年的版本更新计划。也欢迎各位参与代码贡献或功能、性能的反馈和讨论，让我们携手见证 GreptimeDB 持续的成长与精进。</p><h3>关于 Greptime：</h3><p>Greptime 格睿科技致力于为智能汽车、物联网及可观测等产生大量时序数据的领域提供实时、高效的数据存储和分析服务，帮助客户挖掘数据的深层价值。目前主要有以下三款产品：</p><ul><li><p>GreptimeDB 是一款用 Rust 语言编写的时序数据库，具有分布式、开源、云原生和兼容性强等特点，帮助企业实时读写、处理和分析时序数据的同时降低长期存储成本。</p></li><li><p>GreptimeCloud 可以为用户提供全托管的 DBaaS 服务，能够与可观测性、物联网等领域高度结合。</p></li><li><p>GreptimeAI 是为 LLM 应用量身定制的可观测性解决方案。</p></li><li><p>车云一体解决方案是一款深入车企实际业务场景的时序数据库解决方案，解决了企业车辆数据呈几何倍数增长后的实际业务痛点。</p></li></ul><p>GreptimeCloud 和 GreptimeAI 已正式公测，欢迎关注公众号或官网了解最新动态！对企业版 GreptimDB 感兴趣也欢迎联系小助手（微信搜索 greptime 添加小助手）。</p><p>官网：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreptime.cn%2F" target="_blank">https://greptime.cn/</a></p><p>GitHub: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb" target="_blank">https://github.com/GreptimeTeam/greptimedb</a></p><p>文档：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.greptime.cn%2F" target="_blank">https://docs.greptime.cn/</a></p><p>Twitter: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FGreptime" target="_blank">https://twitter.com/Greptime</a></p><p>Slack: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.greptime.com%2Fslack" target="_blank">https://www.greptime.com/slack</a></p><p>LinkedIn: <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fgreptime" target="_blank">https://www.linkedin.com/company/greptime</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 09:46:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6839317/blog/11046126</guid>
            <link>https://my.oschina.net/u/6839317/blog/11046126</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 年 DevOps 报告：文化、用户中心性和技术能力驱动组织成功]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#060607">《</span>2023 年 DevOps 报告<span style="background-color:#ffffff; color:#060607">》强调了健康文化、用户中心性、技术能力和灵活基础设施在提高组织绩效、团队协作和员工福祉方面的重要性，并探讨了这些因素如何通过各种实践和流程相互影响。</span></p><p><img alt="" height="308" src="https://static.oschina.net/uploads/space/2024/0307/154350_urjp_4700705.png" width="366" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#060607">以下是报告的主要发现和内容概述：</span></p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>1. 研究目标和方法</strong></p><ul><li>报告旨在为领导者和实践者提供影响组织、团队和员工福祉的见解。</li><li>研究使用了严格的统计评估方法，调查了超过 36,000 名专业人士，覆盖各种规模的组织和多个行业。</li><li>研究方法包括定量调查研究、日志分析和模拟信念和权力传播的方式。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>2. 关键发现</strong></p><ul><li><strong>文化的重要性</strong>：健康的文化是建立技术能力、提高技术绩效、实现组织绩效目标和帮助员工成功的关键。</li><li><strong>用户中心性</strong>：以用户为中心的开发方法可以显著提高组织绩效。</li><li><strong>软件交付性能</strong>：加快代码审查是提高软件交付性能的有效途径。</li><li><strong>技术能力</strong>：高质量的文档可以增强技术能力对组织绩效的影响。</li><li><strong>基础设施的灵活性</strong>：云计算通过提供灵活的基础设施，有助于提高组织绩效。</li><li><strong>文化投资</strong>：健康的组织文化对员工福祉和组织绩效有积极影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>3. 技术能力和流程</strong></p><ul><li>报告探讨了人工智能、基于主干的开发、松散耦合架构、持续集成和快速代码审查等技术能力如何预测性能。</li><li>这些技术能力对团队绩效、组织绩效、软件交付性能和运营性能有积极影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>4. 文档的作用</strong></p><ul><li>高质量的文档是基础，它推动了技术能力的实施，并放大了这些能力对组织绩效的影响。</li><li>文档质量对团队绩效、组织绩效和运营性能有显著的正面影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>5. 可靠性和性能</strong></p><ul><li>可靠性实践（如服务水平目标和自动化）对运营性能有显著影响，从而提高了团队和组织绩效。</li><li>高运营性能可以减少员工的倦怠感，提高生产力和工作满意度。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>6. 基础设施的灵活性</strong></p><ul><li>使用公共云的团队在基础设施灵活性上有所提高，这反过来又提高了组织绩效。</li><li>云计算对员工福祉有积极影响，包括减少倦怠、提高工作满意度和生产力。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>7. 文化投资</strong></p><ul><li>健康的文化对员工福祉和组织绩效有积极影响，包括减少倦怠、提高工作满意度和生产力。</li><li>文化对技术能力的实施和团队绩效有积极影响。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>8. 多样性和包容性</strong></p><ul><li>报告发现，被认定为代表性不足的群体和女性或自我描述为女性的人在倦怠感上更高。</li><li>这些群体可能承担更多的重复性工作，这可能解释了他们报告的更高倦怠水平。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>9. 新员工的生产力</strong></p><ul><li>新员工的生产力低于有经验的团队成员，但高质量的文档和人工智能的集成可能有助于他们更快地提高生产力。</li></ul><p style="color:#060607; margin-left:0; margin-right:0; text-align:start"><strong>10. 研究方法和社区参与</strong></p><ul><li>报告详细描述了研究方法，包括如何生成假设、开发调查问卷、收集和分析数据。</li><li>鼓励读者加入 DORA 社区，分享经验，学习并从他人的改进实践中获得灵感。</li></ul><p><span style="background-color:#ffffff; color:#060607">报告还包含了关于如何解读报告中的模型和图表的附录，以及如何通过模拟和贝叶斯统计来探索数据的可能解释和不确定性。</span></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">报告详情可至<strong><span style="color:#333333"><span style="background-color:#f39c12">「开源中国 APP - 报告模块」</span></span></strong>查看。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">APP 下载地址：</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img height="300" src="https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png" width="300" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>（<em>目前仅提供 Android 版本）</em></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:48:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281976</guid>
            <link>https://www.oschina.net/news/281976</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 加速引擎 PAI-TorchAcc：整体介绍与性能概述]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>作者：沈雯婷、黄奕桐、艾宝乐、王昂、李永</p><h1>1、简介</h1><p>PAI-TorchAcc(Torch Accelerator) 是阿里云人工智能平台开发的 Pytorch 上的大模型训练加速框架。</p><p>PAI-TorchAcc 提供了一套基于 Pytorch 的简洁、易用的接口，无需进行模型转换就可以无缝地接入 HuggingFace 上的模型，并用多种分布式策略进行训练加速。</p><p>PAI-TorchAcc 借助社区 PyTorch/XLA，通过 LazyTensor 技术将 Pytorch 代码转换为静态执行图，基于计算图，结合阿里云上的计算资源情况，进行了大量的 GPU 硬件上模型训练的针对性分布式优化、计算优化。</p><p>得益于简单的模型接入方式、基于计算图的优化，PAI-TorchAcc 能够灵活地支持各种大模型的多种规模，兼容不同的硬件。PAI-TorchAcc 支持常见大模型 1B-175B 的训练，训练吞吐相对 PyTorch 原生、Megatron-LM 均有提升，如 LLaMA 系列模型，相比 PyTorch 原生提升了 140%，相比 Megatron-LM 提升了 5%，在 A100 上 MFU 达到 70%，8 卡到 128 卡线性加速比达到 15.6X。</p><h1>2、背景和需求</h1><h2>2.1 背景</h2><ul><li><strong>大模型训练</strong></li></ul><p>近年来，大语言模型、视频生成类模型迅速发展，它们基于庞大的文本、图片、视频等数据集进行训练，执行多种自然语言处理、图像生成、视频生成等任务，具备强大的理解和生成能力。随着计算资源和技术的不断进步，大模型的参数量已增长到数亿甚至数万亿级别，例如 LLaMA、GPT-3、通义千问、Sora 等，这些模型在许多基准测试上表现出了前所未有的性能。</p><p>然而，训练大模型需要极高的成本。比如使用 Megatron-LM 预训练一个 OPT-175B 模型需要上千张 A100 训练 2 个月[1]，硬件利用率 MFU 约 47%，期间因为硬件故障经历了几十次 checkpoint 的加载和续训练。使用 PyTorch FSDP 进行 LLaMA-2-70B 的微调也需要 16 张 A100 运行约 13.5 小时[2]。NVIDIA A100、H100 等硬件资源价格高昂且不易获取，市面上也逐渐出现了其他性价比更高的硬件资源。</p><p>加速不同的大模型的预训练、续训练、微调，充分利用不同的硬件资源，提升资源利用率，是降低大模型训练成本的一个有效途径。</p><ul><li><strong>Megatron-LM</strong></li></ul><p>NVIDIA Megatron-LM[3]是一个基于 PyTorch 的分布式训练框架，用来训练基于 Transformer 的大模型。Megatron-LM 综合应用了数据并行、模型并行、流水并行来实现 GPT-3 等特定模型的训练。然而，不同的大模型、训练数据集接入 Megatron-LM 十分不灵活，需要将 checkpoint 和数据格式进行转换。同时，Megatron-LM 虽然对一些模型算子做了手动的优化，在面对不同模型的不同计算模式时，难以自动地应用这种手动的优化。</p><ul><li><strong>DeepSpeed</strong></li></ul><p>DeepSpeed[4]是微软开源的一个 PyTorch 上的大模型分布式训练框架，支持 ZeRO 和流水并行，并且可以结合 Megatron-LM 运行 3D 并行。DeepSpeed 已经成为 HuggingFace transformers 库中一个训练组件。然而 DeepSpeed 性能表现较差，并且和 Megatron-LM 同样存在面对不同计算模式时无法灵活优化的限制。</p><ul><li><strong>PyTorch/XLA</strong></li></ul><p>PyTorch/XLA[5]将 PyTorch 和 OpenXLA 相结合，使用 LazyTenor 技术，将 PyTorch 代码转换为静态执行图，在静态图上进行计算图优化和后端编译优化。Pytorch/XLA 主要是针对 TPU 场景进行优化，在 GPU 上还存在一定问题和优化空间，如不支持 Transformers 模型常用的 FlashAttention 加速算子、不支持 torchrun 拉起、计算通信 Overlap 差、显存开销大等问题。</p><h2>2.2 需求</h2><p>基于以上背景，我们需要一个大模型分布式训练引擎，能够方便接入多变的 PyTorch 模型，尤其是 Transformer 类模型，兼容多种硬件。在不同模型变化的计算模式下，在不同硬件变化的硬件架构和计算、访存能力下，能够自动地对计算进行优化，尤其在阿里云的硬件上能够表现较高的性能。同时，大模型导致单卡内存和显存无法完全放下，不同的模型需要结合不同的分布式策略，合理通信，完成多卡训练并提升线性加速比。</p><h1>3、PAI-TorchAcc 核心技术特性</h1><h3>灵活的模型接入</h3><ul><li>支持 LLaMA 系列、Qwen、BaiChuan、ChatGLM、OLMo、Bloom 等常见的大模型 1B-175B 的训练；</li><li>无缝对接 HuggingFace 中的模型；</li><li>一键接入和加速 Pytorch 模型。</li></ul><h3>千亿级模型参数量</h3><ul><li>已经支持 1B 到 175B 大模型训练；</li></ul><h3>全面的训练模式</h3><ul><li>支持混合精度训练，包括 Float32、Float16、BFloat16 等；</li><li>支持 Pytorch 模型的预训练、微调和续训练。</li></ul><h3>组合的分布式策略</h3><ul><li>支持 Data Parallel、Tensor Parallel、Sequence Parallel、Fully Sharded Data Parallel、Pipeline 等分布式策略及其组合。</li></ul><h3>自动计算优化和显存优化</h3><ul><li>使用手动的 Gradient Checkpoint 和自动的 Rematerialization 降低峰值显存；</li><li>自动进行显存规划和管理，降低峰值显存和减少显存碎片化；</li><li>自动对 Kernel 进行编译优化，提高计算效率；</li><li>自动接入 SOTA 的高性能 Kernel。</li></ul><h3>兼容多种硬件</h3><ul><li>兼容 NVIDIA A100/800, H100/800, V100 等；</li><li>兼容阿里云上灵骏集群的硬件资源。</li></ul><h3>与现有框架对比</h3><p><img src="https://oscimg.oschina.net/oscnet/up-16e4c9ebf76f202837eb23fa7d35588c6a8.png" alt="" referrerpolicy="no-referrer"></p><h1>4、PAI-TorchAcc 架构</h1><h2>4.1 总体架构</h2><p><img src="https://oscimg.oschina.net/oscnet/up-b1ac021283f5b408400fb4d7b8ce1ef1ce8.png" alt="" referrerpolicy="no-referrer"></p><p>PAI-TorchAcc 的架构自顶向下分为以下几层：</p><ul><li><strong>模型层</strong>：支持计算机视觉、自然语言处理、语音合成等深度学习模型训练的加速；</li><li><strong>算法库</strong>：支持 HuggingFace Transfomers、PAI-EasyNLP、TIMM 等算法库构建的模型；</li><li><strong>前端</strong>：支持以 PyTorch 为前端语言的模型训练；</li><li><strong>Lowering</strong>：使用 LazyTensor、Symbolic Trace 等技术将前端代码转换为静态执行图;</li><li><strong>IR</strong>：使用多层中间表达，包含 High-Level 的设备无关的 IR 和 Low-Level 的设备相关的 IR，基于两层 IR 上分别做计算图优化和后端编译优化。</li><li><strong>编译优化引擎</strong>：TorchAcc 的编译优化引擎包括计算图优化引擎 TorchAcc Compiler 和多种后端编译优化引擎 BladeDISC 和 OpenXLA。基于两层 IR，进行分布式优化、显存优化、通信优化、计算优化以及算子调度和显存管理等优化，生成优化的设备码。</li><li><strong>硬件</strong>：最终产生硬件相关的设备码在不同算力、带宽和显存的硬件设备上执行。</li></ul><h2>4.2 接口</h2><p>PAI-TorchAcc 抽取了一套简洁的接口，灵活接入并加速任意的 Pytorch 模型，而不需要改动原有的模型代码。</p><p>通过 PAI-TorchAcc 加速模型训练一般需要三步：</p><ol><li>定义 torchacc.Config，并指定加速选项。</li><li>调用 torchacc.accelerate，并传入 model 和 config，完成加速训练的准备。</li><li>通过 torchacc.AsyncLoader 对 torch dataset_loader 进行封装，加速数据加载。</li></ol><pre><code class="language-python">model = ...
  dataloader = ...

+ # 一行代码加速模型，也可传入 Config 配置更丰富的加速功能，如分布式策略、编译优化选项等
+ model = torchacc.accelerate(model)

+ # 异步加速数据加载
+ dataloader = torchacc.AsyncLoader(dataloader, model.device)

  model.train()
  for source, labels in dataloader:
      ...
</code></pre><h2>4.3 编译优化</h2><p>PAI-TorchAcc 通过 LazyTensor、Symbolic Trace 等技术将前端 Pytorch 代码转换为静态执行图，并在静态图上进行自动优化，在分布式的硬件设备上高效运行。</p><h2>4.4 计算图优化</h2><p>在 Tensor Graph 上进行优化，这层优化基于 High-Level IR——StableHLO 进行。</p><ul><li>分布式： 通过分图和通信算子插入，完成流水并行、SPMD 等。</li><li>显存优化：通过算子级别的显存 Live range 和复用分析、静态调度策略、自动重算、显存管理优化等来减少显存的峰值和碎片化。</li><li>计算优化：通过 CSE 等简化计算，通过算子大粒度融合来优化访存密集型算子，减少 kernel launch，减少访存，提升计算效率；通过自动的计算图匹配重写的方式接入 Flash Attention 等高性能 Kernel。</li><li>通信优化：通过通信算子的合并、拆分、异步化以及算子的调度来提升通信效率，提高计算和通信的 overlap。</li></ul><h2>4.5 后端编译优化</h2><p>在 Buffer Graph 上进行优化，这层优化基于 Low-Level 的 IR，包括 LHLO、LLVM IR 和多种 MLIR 的 dialect。</p><ul><li>多后端：支持 OpenXLA 和阿里自研的 BladeDISC 两种编译后端；</li><li>Lowering 和 Codegen：将上层的 StableHLO Lowering 成 LHLO 和多种 MLIR 的 dialect，并在各级 Lowering 过程中进行优化，最终表达为 LLVM IR，通过 LLVM 生成针对硬件的优化代码；</li><li>Custom Call：High-Level IR 自动 Pattern rewrite 的优化 kernel，通过 custom call 调用。</li></ul><h1>5、实践案例和性能</h1><p>PAI-TorchAcc 在 A100 上能够达到 70% 的 MFU，并且在多卡下几乎线性扩展（8 卡到 128 卡加速比 15.6X），在灵活支持各种模型的基础上，性能能够高于 Megatron-LM。我们在常见的开源大模型上做了性能测试，使用相同的硬件资源，PAI-TorchAcc 的训练吞吐相对 PyTorch 原生、Megatron 均有提升，如 LLaMA 系列模型相对 PyTorch 原生提升了 140%，相对 Megatron 提升了 5%。</p><p>我们将在后续的系列文章中提供一个具体的实践案例：PAI-TorchAcc 在 OLMo 模型训练上的接入示例和加速效果，并且给出加速的来源分析。</p><h1>6、总结和未来展望</h1><p>PAI-TorchAcc 可以灵活接入 Pytorch 模型，并通过并行化策略、显存优化、计算优化和调度优化等方法来加速大模型以及视觉类、语音类模型的训练。PAI-TorchAcc 已经在常见大模型上如 LLaMA、LLaMA-2、BaiChuan、ChatGLM、QWen、OLMo、Bloom 取得了不错的效果。<strong>未来我们将从以下方向继续深入优化，以支持更多的场景，取得更好的加速效果。</strong></p><ol><li>Graph Capture 优化和子图编译：在生成计算图的过程中遇到无法识别的算子将导致编译失败，我们将进一步优化 Graph Capture，并支持子图的编译优化。</li><li>自动分布式：PAI-TorchAcc 提供了多种分布式策略，然而在不同的模型和硬件上，使用哪种组合的分布式策略、如何进行分图能够取得最优的性能，仍然需要根据经验手动配置。PAI-TorchAcc 将借助静态计算图和模型、硬件特性，做自动的分布式。</li><li>AutoGC：借助静态计算图和模型、硬件特性，自动进行 checkpoint 选点。</li><li>动态 Shape 性能优化：动态 Shape 导致重编译引起的性能下降，当前我们通过分桶的方式减少了重编译的次数，仍然存在大量的 padding，如何做更高性能的动态 Shape 支持，是一个深入优化的方向。</li><li>自研编译优化引擎 BladeDISC 的优化。</li></ol><h1>引用</h1><p>[1] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2205.01068.pdf" target="_blank">https://arxiv.org/pdf/2205.01068.pdf</a></p><p>[2] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fram-efficient-pytorch-fsdp" target="_blank">https://huggingface.co/blog/ram-efficient-pytorch-fsdp</a></p><p>[3] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FNVIDIA%2FMegatron-LM" target="_blank">https://github.com/NVIDIA/Megatron-LM</a></p><p>[4] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2FDeepSpeed" target="_blank">https://github.com/microsoft/DeepSpeed</a></p><p>[5] <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpytorch%2Fxla" target="_blank">https://github.com/pytorch/xla</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:46:12 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/11045933</guid>
            <link>https://my.oschina.net/u/5583868/blog/11045933</link>
            <author>
                <![CDATA[原创]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[快手启动鸿蒙原生应用开发]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">「华为终端云服务」官博消息称，快手宣布全面拥抱鸿蒙生态，启动快手 App 鸿蒙原生应用开发，将推出鸿蒙星河版快手 APP。</span></p><blockquote><p><span style="color:#000000">「快手为鸿蒙生态带来更丰富的内容生态和领先的短视频社交服务能力，HarmonyOS 也为数亿快手用户带来全场景短视频社交新体验和更流畅、智能、便捷的生活服务。」</span></p></blockquote><p><img height="474" src="https://oscimg.oschina.net/oscnet/up-126df7aa28662554855ae07406650e06d46.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">对此，快手官方也在评论区回复称，鸿蒙星河版快手 APP 将为广大用户带来全场景的短视频社交新体验，用户可以在华为手机、平板、车机等多个终端实现短视频内容无缝接续，不因切换场景而中断体验。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:17:12 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281966</guid>
            <link>https://www.oschina.net/news/281966</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">开发工具供应商 Perforce Software <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perforce.com%2Fpress-releases%2Fannual-java-report-reveals-42-companies-are-dedicating-resources-developer" target="_blank">发布</a>了一份 Java 社区年度调查结果，即 JRebel 2024 年 Java 开发人员生产力报告；提供了有关影响 Java 发展趋势的关键因素的行业数据和分析。</span></p><p><span style="color:#000000">主要调查结果集中在提高 Java 生产力的方法上 —— 42% 的受访者创建了专门的生产力团队或工作组。今年的报告还发现了 Java IDE 偏好的变化、微服务数量的增加以及远程部署时间的延长。</span></p><p><span style="color:#000000">调查发现<strong>对 Java 工具和人才的投资</strong>呈上升趋势。60% 的受访者表示他们的公司计划在未来一年内增加 Java 开发人员，只有 13% 的受访者表示不计划增加 Java 开发人员，另有 27% 的受访者表示不确定。</span></p><p><span style="color:#000000">虽然市场不景气，但开发人员工具预算基本保持稳定。42% 的受访者表示计划增加 Java 工具预算，22% 的受访者不打算增加工具预算，36% 的受访者不确定。此外，31% 的受访者表示他们的年度工具预算（每位开发人员）为 500 美元或以上，相较 2023 年的 22% 有所增长。</span></p><p><img height="231" src="https://oscimg.oschina.net/oscnet/up-7daaf894200c1a119c1d21b6d56e898ec2b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Perforce 首席技术官 Rod Cope 表示："Java 将继续存在"。「这些数字共同传递出一个强烈的信息：Java 将继续成为企业应用的核心部分。事实上，企业在大型 Java 应用程序方面的根深蒂固，将继续成为整个开发人员生态系统雇用 Java 开发人员的推动力。」</span></p><p><span style="color:#000000">就开发人员<strong>最常用的 Java 版本而言</strong>，11% 的受访者表示已经升级到了 Java 21；但仍有 24% 的受访者表示他们正在使用 Java 8，18% 的受访者正在使用 Java 11。</span></p><p><img height="372" src="https://oscimg.oschina.net/oscnet/up-205fcee58753d4df208b0e00bf9e72da113.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Perforce 表示，考虑到 Oracle 分别在 2022 年 3 月和 2023 年 9 月停止了对 Java 8 和 Java 11 的高级支持。因此，不受支持的 JDK 版本的高使用率意味着公司正在获得第三方供应商提供的支持，如 Amazon Corretto、Azul Zulu 和 OpenLogic 等。且随着 Oracle 加快长期支持 JDK 版本的频率（从每三年一次到每两年一次），预计 Java 21 的采用率将会增加。</span></p><p><span style="color:#000000">在 <strong>Java IDE 的偏好</strong>方面，IntelliJ IDEA 再次以 41% 的比例位居榜首。Eclipse 以 23% 位居第二，Microsoft Visual Studio Code 以 19% 的份额排名第三。此外，还有 84% 的 IntelliJ IDEA 用户表示，他们在 Java 开发实践中还使用过其他 IDE，其中 VSCode 是最常见的选择。</span></p><p><span style="color:#000000">受访者的 <strong>Java 技术栈与</strong>往年相比大部分保持不变，Tomcat、Spring Boot 和 Jenkins 等主流技术仍遥遥领先。36% 的受访者表示他们使用 Tomcat 作为主要应用程序的应用服务器，其次是 JBoss/Wildfly (15%)、WebLogic (12%)、WebSphere (10%)、Jetty (10%) 、Glassfish/Payara (8%)。</span></p><p><span style="color:#000000">微服务框架的结果也是类似的，67% 的受访者使用 Spring Boot；其他分别是 DropWizard（11%）、Quarkus（8%）、Micronaut（5%）和 Vert.x（1%）。Jenkins 是迄今为止最流行的 CI/CD 技术，占 37%。TeamCity 的使用率相较 2023 年增长了一倍多（10%）；其他技术的使用率基本保持不变，GitHub Actions（17%）、Travis CI（9%）、Circle CI（8%）和 Bamboo（7%）。</span></p><p><img height="458" src="https://oscimg.oschina.net/oscnet/up-4f9b117abee52a3c46b662a7c76b9502fc6.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Amazon Web Services 是最受欢迎的云供应商，占 31%，其次是 Microsoft Azure，占 18%。表示不使用任何云供应商的受访者比例从去年的 21% 下降至 13%。</span></p><p><span style="color:#000000">当 Java 开发人员被问及，如果开发时间增加 10%，他们会怎么做时？增加功能（26%）和提高测试覆盖率（18%）等务实的答案名列前茅，但其他答案也包括"喝咖啡"和"消除技术债务"等。</span></p><p><span style="color:#000000">更多详情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jrebel.com%2Fsites%2Fdefault%2Ffiles%2Fpdfs%2Freport-jrebel-2024-dev-productivity.pdf" target="_blank">查看完整报告</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281964/perforce-annual-java-report</guid>
            <link>https://www.oschina.net/news/281964/perforce-annual-java-report</link>
            <author>
                <![CDATA[来源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[如果企图在人工智能上搞「小院高墙」，将会犯下新历史错误]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>3 月 7 日上午 10 时，十四届全国人大二次会议在梅地亚中心新闻发布厅举行记者会，中共中央政治局委员、外交部长王毅就「中国外交政策和对外关系」相关问题回答中外记者提问。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9567f8c994b50351b847eed70b2d4975657.png" referrerpolicy="no-referrer"></p><p>凤凰衞视记者提问：国际社会非常关注人工智能问题，很多国家提出关于人工智能全球治理方案，我们关注到中国也提出了关于《全球人工智能治理倡议》，中方认为如何才能确保人工智能朝着真正有利于人类文明进步的方向发展？另外，中方对大国人工智能合作持何立场？</p><p>王毅说，人工智能进入爆发式发展的关键阶段。我们主张发展与安全并重，既要拥抱新事物新机遇，也要装好刹车再上路，共同推进人工智能全球治理。去年 10 月，习近平主席提出《全球人工智能治理倡议》，清楚阐明了中方的态度和主张。</p><p>我们关注的主要是三个确保：<strong>一是确保有益</strong>。人工智能的发展有利于人类共同福祉，符合人类伦理规范，符合国际法规则，符合人类文明进步方向。<strong>二是确保安全</strong>。人工智能始终处于人类控制之下，不断提高可解释性和可预测性，为此要建立各种风险评估和管控机制。<strong>三是确保公平</strong>。在联合国框架下成立人工智能国际治理机构，各国都能在人工智能的发展进程中平等参与、平等受益。</p><p>王毅说，我还要强调的是，<strong>如果企图在人工智能上也搞什么「小院高墙」，将会犯下新的历史错误，不仅阻挡不了各国的科技发展，还会破坏国际产业链供应链完整，削弱人类应对风险挑战的能力</strong>。中国对与各国开展人工智能合作持积极开放态度，迄今已经与一些国家建立了对话机制。人工智能大国之间的合作很重要，发展中国家的能力建设也很重要。我们将适时向联大提交「加强人工智能能力建设国际合作」的决议草案，促进各方加强技术共享，努力弥合智能鸿沟，不让任何国家掉队。谢谢！</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 07 Mar 2024 07:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/281963</guid>
            <link>https://www.oschina.net/news/281963</link>
            <author>
                <![CDATA[来源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[大模型在产品原型生成中的应用实践]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/news/281031/oschina-app-2024" target="_blank">【开源中国 APP 全新上线】「动弹」 回归、集成大模型对话、畅读技术报告 <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><span id="OSC_h1_1"></span><h1>一、背景</h1><p style="color:#24292f; text-align:start">在 B 端研发过程中，产品原型在产品需求文档中起着重要的作用。然而，在实际的开发过程中，我们发现了一些问题。首先，在需求评审阶段，有些产品需求文档可能缺少原型或者原型与研发团队的规范不一致，这需要研发同学与产品同学沟通补充原型图或者按照研发团队的规范进行绘制，这增加了产品同学和研发团队之间的沟通成本以及增加了产品同学的学习成本。其次，在业务验收阶段，开发的页面或效果可能不符合业务侧的期望，这又需要产品和研发团队反复沟通，导致业务侧对效果的感知链路过长。此外，产品同学还需要花费大量时间来根据需求文档描述输出样式固定的原型文档。</p><p style="color:#24292f; text-align:start">为了解决这些问题，我们想到了利用产品在『市场需求文档（MRD）——产品需求文档（PRD）——页面（Page）』沟通过程中沉淀的『共识』，即产品需求文档中的页面描述。我们可以利用大语言模型强大的推理能力，将这些共识『翻译』成符合研发团队规范的页面，从而减少沟通成本并缩短业务侧对效果的感知链路。另外，为了减少产品在不同界面切换频次，可以让产品利用浏览器插件在 PRD 文档页面进行文字选择，然后唤起原型生成工具生成页面原型和修改原型。本文主要介绍了我们利用大模型辅助产品同学生成页面原型的实践经验。</p><span id="OSC_h1_2"></span><h1>二、流程设计</h1><p style="color:#24292f; text-align:start">一般来说，产品同学是根据业务同学或者运营同学的 MRD 来细化产品需求。如果业务有视觉要求，则会由设计同学负责产品的界面和交互设计，否则由产品同学利用常见市面上常见的原型工具来设计界面和交互。我们自研的智能原型工具的定位是作为产品同学在原型设计时的可选工具，且不改变产品的原有工作流。基于此，我们设计了如下原型生成流程：<img alt="231.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/231.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">该流程主要是将用户利用常见市面上常见的原型工具变成利用智能原型工具插件选中 PRD 文档中的产品描述，利用 LLM 基于得物自研低代码平台配置规范生成原型图。产品同学工作的空间还是在文档中，不用切换到其他软件或者界面，即可利用 Chrome 插件来生成原型。产品同学保存生成的记录后，可以供自己查询，也可以供业务同学查看效果，还可以供研发同学快速开发使用。</p><span id="OSC_h1_3"></span><h1>三、实现原理</h1><p style="color:#24292f; text-align:start">智能原型工具将产品所写的页面描述、修改指令、拖拽动作作为输入，低代码领域知识作为补充，大模型或可视化编辑器作为处理器，低代码 SDK 作为渲染器，页面原型作为输出。智能页面原型工具从输入到输出的具体实现原理如图所示：<img alt="2008.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/2008.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_4"></span><h1>四、架构设计</h1><p style="color:#24292f; text-align:start">根据上述生成流程设计，我们设计的产品原型生成分层架构如图所示：<img alt="1209.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1209.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">产品原型生成工具的架构可以分为四层，分别是<strong>应用场景、能力层、引擎层和基础层</strong>，具体如下：</p><ul><li><p><strong>应用场景</strong>：主要是产品同学利用智能页面原型工具生成原型和研发利用原型对应低代码平台配置完成从 0 到 1 的页面开发。</p></li><li><p><strong>能力层</strong>：则是辅助产品同学生产原型的能力集合。这些能力支撑了产品快速生成、快速修改原型，生成内容可以管理，不影响产品同学使用流程等场景。</p></li><li><p><strong>引擎层：</strong><span>&nbsp;</span>是得物自研低代码引擎和推理引擎，是生成原型配置和渲染配置的发动机。得物自研低代码引擎不仅包括得物自研低代码 SDK，还有得物 B 端组件 Poizon Design、精品组件 Poizon Components 以及业务组件。推理引擎则包括文生文的通用模型、图生文的通用模型、生成低代码平台配置的 Coder 模型。推理引擎部署在得物自研大模型平台上。选择使用内部部署大模型的原因是，调用外部模型有数据泄露风险，外部模型 API 有一定稳定性风险，训练成本较高。场景知识库是依据对内部各业务域的 PRD 进行分析得到的高频场景而构建的。目前场景知识库已包含了列表、表单、弹窗等等高频场景。</p></li><li><p><strong>基础层</strong>：则是产品原型智能生成工具的接口服务、记录存储、模型部署和监控。</p></li></ul><span id="OSC_h1_5"></span><h1>五、实践效果</h1><span id="OSC_h2_6"></span><h2>界面展示</h2><p style="color:#24292f; text-align:start">下图是界面原型智能生成工具的主界面，主要包括新建与刷新区、生成记录列表区、快捷操作区、辅助操作区、页面效果预览区、分享与评价区、对话修改区，具体如下：</p><ul><li><strong>新建与刷新区</strong>主要是在当前界面直接配置页面原型、根据页面描述智能生成界面原型以及刷新生成记录列表。</li><li><strong>生成记录列表区</strong>主要是展示生成的界面原型关联的 PRD、原型描述、生成时间。</li><li><strong>快捷操作区</strong>是界面原型编辑、截图、保存、重新生成、低代码平台配置编辑、复制低代码平台配置等操作的快捷按钮。</li><li><strong>辅助操作区</strong>是界面描述模板、历史记录、问题反馈、帮助文档等帮助按钮。</li><li><strong>页面效果与预览区</strong>是生成的原型展示区域，原型是可以交互操作的。</li><li><strong>分享与评价</strong>是方便产品同学将生成的原型分享给业务或研发同学预览以及可以对智能生成的原型质量做评价帮助提升模型生成的准确性。</li><li><strong>对话修改区</strong>是方便产品同学通过对话形式来利用模型对生成的界面原型做修改。</li></ul><p style="color:#24292f; text-align:start"><img alt="7809.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/7809.png" referrerpolicy="no-referrer"></p><span id="OSC_h2_7"></span><h2>使用效果</h2><p style="color:#24292f; text-align:start">下面视频中展示了从 PRD 文档到页面原型的过程。从视频中可以看到，智能原型生成工具支持对生成的原型进行微调，还生成了相对应的低代码平台配置。</p><span id="OSC_h2_8"></span><h2>落地情况</h2><p style="color:#24292f; text-align:start">智能原型工具生成原型的用时在 15 秒以内，具备生成记录可查、可修改。同时，智能原型工具已实现关键使用链路埋点，可以及时发现产品同学使用卡点。目前内部已有较多的产品同学正在使用智能原型工具生成 B 端页面原型。通过与产品同学的沟通，收到的使用反馈总体体验是正向的。也有产品同学参与共建智能原型工具。</p><span id="OSC_h1_9"></span><h1>六、后续规划</h1><ul><li><p><strong>场景扩展：</strong><span>&nbsp;</span>目前，智能原型工具主要支持表单、列表、弹窗等等高频场景，后续将支持复杂表单、复杂列表、图表等等产品同学在工作中会涉及的页面场景。</p></li><li><p><strong>大模型训练</strong>：在上文中可以看到模型是智能原型工具的加速器，但目前只用到了大模型的推理能力，需要外挂知识库才能生成符合规范的页面原型。这制约了生成原型的生成速度和扩展性。后续将利用工程化手段对得物自研低代码平台的使用教程、示例、用户使用数据等数据做结构化处理，然后利用大模型和知识库生成训练数据，对通用大模型进行微调，得到智能原型工具模型。同时，将训练过程工程化和自动化。从而进一步提升原型生成效率和质量，批量覆盖更多场景。模型训练思路如图所示：<img alt="7800.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/7800.png" referrerpolicy="no-referrer"></p></li><li><p><strong>优化 MRD2PRD2Code 链路</strong>：与自研低代码平台协同，缩短 MRD2PRD2Code 链路，使每一个产研链路中的每个节点的结论都可以得到一个可见的结果，从而进一步减少沟通成本与提升交付效率。</p></li><li><p><strong>Web2Code 链路</strong>：Web2Code 主要是为了产品同学需要对老页面做修改的场景，产品同学打开老页面即可生成原型，然后在生成原型上做修改。</p></li><li><p><strong>编辑功能增强</strong>：上文中提到智能原型工具的编辑功能是通过表单配置来对大模型生成的低代码平台配置进行修改，还不够灵活，后续组件拖拽式编辑功能。另外，支持产品通过组件拖拽生成原型以及相应产品描述功能。</p></li></ul><p style="color:#24292f; text-align:start">*<strong>文/bigboy</strong></p><p style="color:#24292f; text-align:start">&nbsp;</p><p style="color:#000000; text-align:start">本文属得物技术原创，更多精彩文章请看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2F" rel="nofollow" target="_blank">得物技术官网</a></p><p style="color:#000000; text-align:start">未经得物技术许可严禁转载，否则依法追究法律责任！</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 06 Mar 2024 03:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/11046041</guid>
            <link>https://my.oschina.net/u/5783135/blog/11046041</link>
            <author>
                <![CDATA[得物技术]]>
            </author>
        </item>
    </channel>
</rss>
