<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 23 Sep 2023 07:30:51 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[尤雨溪：高質量中文文檔的重要性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000"><span style="background-color:#ffffff">Vue.js 和 Vite 的創建者</span>尤雨溪在最近的一次<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.thisdot.co%2Fblog%2Fcreator-of-vue-js-and-vite-evan-yous-journey-from-google-engineer-to-open%2F" target="_blank">訪談中</a>，談到了自己<span style="background-color:#ffffff">成為獨立開源開發人員的歷程；重點介紹了向全職開源工作的過渡、Vue.js 的成長以及他對未來的期望。</span></span></p><p><span style="color:#000000"><img height="282" src="https://oscimg.oschina.net/oscnet/up-98b89dc57ad7b224f597857decc86eb4ee9.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">在分享了成為一名全職開源開發人員的歷程以及促進這一轉變的挑戰和因素時，尤雨溪將自己的成功歸功於運氣和堅持的結合。他詳細闡述了自己開發 Vue.js 的經歷，強調了保持對解決一些有趣的問題時的熱情；並概述了 API 驅動開發的方法，即在實現之前設計事物的工作方式。</span></p><p><span style="color:#000000">尤雨溪解釋稱，Vue.js 最初是通過 Hacker News 和中國社交網絡等平台吸引的用戶，而這主要得益於它自下而上的方法和用戶友好的文檔；與 React 和 Angular 等大型框架形成了鮮明對比。</span></p><p><span style="color:#000000">他認為，Vue.js 的發展歷程中的一大轉折點是其在 Laravel 社區中的嶄露頭角，正是因此才鞏固了 Vue.js 作為生產項目可靠框架的聲譽。關於 Vue.js 對後端開發人員的吸引力，尤雨溪則認為，主要得益於該項目與傳統後端框架的無縫集成。</span></p><p><span style="color:#000000">訪談內容還涉及了&nbsp;<span style="background-color:#ffffff">Vue.js 在不同地區（尤其是亞洲）的採用情況。尤雨溪將項目在這些地區的成功歸功於自己對中國社交網絡的積極參與，同時還強調了高質量中文文檔的重要性。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">此外，尤雨溪還分享了他在 Vue.js 早期階段的工作節奏和滿足感，並將其與項目發展過程中所需的更復雜的決策過程進行了對比。</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FweaYWoL_ymI" target="_blank">查看完整視頻</a>。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 23 Sep 2023 04:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/259202</guid>
            <link>https://www.oschina.net/news/259202</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英特爾參與 CentOS Stream 項目]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">紅帽官方發佈<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FgAmZSf447gZEqd8n3tGd_A" target="_blank">公告</a>歡迎英特爾參與進 CentOS Stream 項目，並表示「這一舉措不僅進一步深化了我們長期的合作關係，也構建在英特爾已經在 Fedora 項目中積極貢獻的基礎之上。」</span></p><p><img height="250" src="https://oscimg.oschina.net/oscnet/up-de0d91800dda02f5f04460a8e28f9ef7085.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">目前，CentOS Stream 共包括以下特別興趣小組（SIG）：</span></p><ul><li><p><span style="color:#000000">指令集架構（ISA）特別興趣小組（SIG）致力於聚焦於 CentOS Stream 中最新的 ISA 基線和工具鏈技術，以提高性能並減少碳足跡為最終目標。</span></p></li><li><p><span style="color:#000000">虛擬化 SIG 旨在為最新的虛擬化安全功能提供全面支持，確保開箱即用，其中包括像 Intel® Trust Domain Extensions（Intel® TDX）這樣的保密計算能力。</span></p></li><li><p><span style="color:#000000">超大規模 SIG 旨在支持和構建適用於大規模基礎設施的 CentOS Stream 部署用例，以滿足不同規模的需求。</span></p></li></ul><p>英特爾將為這些小組做出貢獻。「<span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">通過積極頻繁地為 CentOS Stream 貢獻，紅帽和英特爾能夠更有效地支持 RHEL 中最新的硬件架構進步，尤其是那些滿足我們用戶新興關鍵需求的進展。</span>」</p><p><span>英特爾公司系統軟件工程副總裁兼總經理 Mark Skarpness 表示，該公司的目標是藉助 CentOS Stream 和 Fedora，為紅帽生態系統的所有上游貢獻提供更強大的英特爾平台支持。</span></p><p><span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)">除了為 CentOS Stream 貢獻外，紅帽與英特爾的合作涵蓋了多個領域，包括 5G 網絡、邊緣計算、人工智能（AI）和系統安全。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 23 Sep 2023 03:24:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/259196</guid>
            <link>https://www.oschina.net/news/259196</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[NExT-GPT —— 任意對任意多模態大語言模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start">NExT-GPT 是一個端到端通用的任意多模態大型語言模型（MM-LLM）系統。開發團隊將 LLM 與多模態適配器和不同的擴散解碼器連接起來，使 NExT-GPT 能夠感知輸入並以文本、圖像、視頻和音頻的任意組合生成輸出。</p><p style="text-align:start">通過利用現有訓練有素的高性能編碼器和解碼器，NExT-GPT 僅使用某些投影層的少量參數（1％）進行調整，這不僅有利於低成本訓練，而且便於方便地擴展到更多潛在的方式。</p><p style="text-align:start">此外還引入了模態切換指令調整（MosIT）併為 MosIT 手動策劃高質量的數據集，在此基礎上，NExT-GPT 被賦予了複雜的跨模態語義理解和內容生成的能力。</p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>NExt-GPT 建立在現有預訓練的 LLM、多模態編碼器和 SoTA 擴散模型之上，具有足夠的端到端指令調整。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><img alt="" height="255" src="https://static.oschina.net/uploads/space/2023/0922/152547_Wq8a_4252687.png" width="500" referrerpolicy="no-referrer"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><strong>多模態編碼階段。</strong>利用已建立的編碼器以各種模式對輸入進行編碼，其中這些表示通過投影層投影成法學碩士可以理解的類似語言的表示。</li><li><strong>LLM 理解和推理階段。</strong>利用現有的開源法學碩士作為核心來處理輸入信息以進行語義理解和推理。LLM 不僅直接生成文本標記，還生成獨特的「模態信號」標記，這些標記充當指示解碼層是否相應輸出模態內容以及輸出什麼模態內容的指令。</li><li><strong>多模式生成階段。</strong>從 LLM（如果有）接收具有特定指令的多模態信號，基於 Transformer 的輸出投影層將信號標記表示映射為後續多模態解碼器可以理解的表示形式。</li></ul><p><img height="138" src="https://static.oschina.net/uploads/space/2023/0922/152430_MsEF_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><img alt="" height="599" src="https://static.oschina.net/uploads/space/2023/0922/152456_Uqt0_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><em>NExT-GPT 推理過程。灰色表示模塊已停用。</em></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 23 Sep 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/next-gpt</guid>
            <link>https://www.oschina.net/p/next-gpt</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 雲原生分佈式操作系統 KubeSphere]]>
            </title>
            <description>
                <![CDATA[<p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2F"><img src="https://gitee.com/kchstack/kubesphere/raw/master/docs/images/kubesphere-icon.gif" alt="banner" width="200px" referrerpolicy="no-referrer"></a></p><p align="center"><b>The container platform tailored for <i>Kubernetes multi-cloud, datacenter, and edge</i> management</b></p><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2Fkubesphere%2Fkubesphere"><img src="https://goreportcard.com/badge/github.com/kubesphere/kubesphere" alt="A+" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fhub.docker.com%2Fr%2Fkubesphere%2Fks-installer"><img src="https://img.shields.io/docker/pulls/kubesphere/ks-installer" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fissues%3Fq%3Dis%253Aissue%2Bis%253Aopen%2Bsort%253Aupdated-desc%2Blabel%253A%2522good%2Bfirst%2Bissue%2522"><img src="https://img.shields.io/github/issues/kubesphere/kubesphere/good%20first%20issue?logo=github" alt="good first issue" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Ftwitter.com%2Fintent%2Ffollow%3Fscreen_name%3DKubeSphere"><img src="https://img.shields.io/twitter/follow/KubeSphere?style=social" alt="follow on Twitter" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fjoin.slack.com%2Ft%2Fkubesphere%2Fshared_invite%2Fzt-1ilxbsp39-t4ES4xn5OI0eF5hvOoAhEw"><img src="https://img.shields.io/badge/Slack-2000%2B-blueviolet?logo=slack&amp;logoColor=white" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.youtube.com%2Fchannel%2FUCyTdUQUYjf7XLjxECx63Hpw"><img src="https://img.shields.io/youtube/channel/subscribers/UCyTdUQUYjf7XLjxECx63Hpw?style=social" referrerpolicy="no-referrer"></a></p><hr><h2><a id="user-content-what-is-kubesphere" class="anchor" href="https://gitee.com/kchstack/kubesphere#what-is-kubesphere"></a>What is KubeSphere</h2><blockquote><p>English | <a href="https://gitee.com/kchstack/kubesphere/blob/master/README_zh.md">中文</a></p></blockquote><p><a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2F">KubeSphere</a> is a <strong>distributed operating system for cloud-native application management</strong>, using <a href="https://gitee.com/link?target=https%3A%2F%2Fkubernetes.io">Kubernetes</a> as its kernel. It provides a plug-and-play architecture, allowing third-party applications to be seamlessly integrated into its ecosystem. KubeSphere is also a multi-tenant container platform with full-stack automated IT operation and streamlined DevOps workflows. It provides developer-friendly wizard web UI, helping enterprises to build out a more robust and feature-rich platform, which includes most common functionalities needed for enterprise Kubernetes strategy, see <a href="https://gitee.com/kchstack/kubesphere#features">Feature List</a> for details.</p><p>The following screenshots give a close insight into KubeSphere. Please check <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Fintroduction%2Fwhat-is-kubesphere%2F">What is KubeSphere</a> for further information.</p><table><tbody><tr><td width="50%" align="center"><b>Workbench</b></td><td width="50%" align="center"><b>Project Resources</b></td></tr><tr><td><img src="https://gitee.com/kchstack/kubesphere/raw/master/docs/images/console.png" referrerpolicy="no-referrer"></td><td><img src="https://gitee.com/kchstack/kubesphere/raw/master/docs/images/project.png" referrerpolicy="no-referrer"></td></tr><tr><td width="50%" align="center"><b>CI/CD Pipeline</b></td><td width="50%" align="center"><b>App Store</b></td></tr><tr><td><img src="https://gitee.com/kchstack/kubesphere/raw/master/docs/images/cicd.png" referrerpolicy="no-referrer"></td><td><img src="https://gitee.com/kchstack/kubesphere/raw/master/docs/images/app-store.png" referrerpolicy="no-referrer"></td></tr></tbody></table><h2><a id="user-content-demo-environment" class="anchor" href="https://gitee.com/kchstack/kubesphere#demo-environment"></a>Demo environment</h2><p>🎮 <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.cloud%2Fen%2Fconsole%2Fmanaged-cluster%2F">KubeSphere Lite</a> provides you with free, stable, and out-of-the-box managed cluster service. After registration and login, you can easily create a K8s cluster with KubeSphere installed in only 5 seconds and experience feature-rich KubeSphere.</p><p>🖥 You can view the <a href="https://gitee.com/link?target=https%3A%2F%2Fyoutu.be%2FYxZ1YUv0CYs">Demo Video</a> to get started with KubeSphere.</p><h2><a id="user-content-features" class="anchor" href="https://gitee.com/kchstack/kubesphere#features"></a>Features</h2><details><summary><b>🕸 Provisioning Kubernetes Cluster</b></summary>
  Support deploy Kubernetes on any infrastructure, support online and air-gapped installation. <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Finstalling-on-linux%2Fintroduction%2Fintro%2F">Learn more</a>.
  </details><details><summary><b>🔗 Kubernetes Multi-cluster Management</b></summary>
  Provide a centralized control plane to manage multiple Kubernetes clusters, and support the ability to propagate an app to multiple K8s clusters across different cloud providers.
  </details><details><summary><b>🤖 Kubernetes DevOps</b></summary>
  Provide GitOps-based CD solutions and use Argo CD to provide the underlying support, collecting CD status information in real time. With the mainstream CI engine Jenkins integrated, DevOps has never been easier. <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdevops%2F">Learn more</a>.
  </details><details><summary><b>🔎 Cloud Native Observability</b></summary>
  Multi-dimensional monitoring, events and auditing logs are supported; multi-tenant log query and collection, alerting and notification are built-in. <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fobservability%2F">Learn more</a>.
  </details><details><summary><b>🧩 Service Mesh (Istio-based)</b></summary>
  Provide fine-grained traffic management, observability and tracing for distributed microservice applications, provides visualization for traffic topology. <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fservice-mesh%2F">Learn more</a>.
  </details><details><summary><b>💻 App Store</b></summary>
  Provide an App Store for Helm-based applications, and offer application lifecycle management on Kubernetes platform. <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Fpluggable-components%2Fapp-store%2F">Learn more</a>.
  </details><details><summary><b>💡 Edge Computing Platform</b></summary>
  KubeSphere integrates <a href="https://gitee.com/link?target=https%3A%2F%2Fkubeedge.io%2Fen%2F">KubeEdge</a> to enable users to deploy applications on the edge devices and view logs and monitoring metrics of them on the console. <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Fpluggable-components%2Fkubeedge%2F">Learn more</a>.
  </details><details><summary><b>📊 Metering and Billing</b></summary>
  Track resource consumption at different levels on a unified dashboard, which helps you make better-informed decisions on planning and reduce the cost. <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Ftoolbox%2Fmetering-and-billing%2Fview-resource-consumption%2F">Learn more</a>.
  </details><details><summary><b>🗃 Support Multiple Storage and Networking Solutions</b></summary>
  Support GlusterFS, CephRBD, NFS, LocalPV solutions, and provide CSI plugins to consume storage from multiple cloud providers.Provide Load Balancer Implementation <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fopenelb">OpenELB</a> for Kubernetes in bare-metal, edge, and virtualization. Provides network policy and Pod IP pools management, support Calico, Flannel, Kube-OVN..
  </details><details><summary><b>🏘 Multi-tenancy</b></summary>
  Provide unified authentication with fine-grained roles and three-tier authorization system, and support AD/LDAP authentication.
  </details><details><summary><b>🧠 GPU Workloads Scheduling and Monitoring</b></summary>
  Create GPU workloads on the GUI, schedule GPU resources, and manage GPU resource quotas by tenant.
  </details><h2><a id="user-content-architecture" class="anchor" href="https://gitee.com/kchstack/kubesphere#architecture"></a>Architecture</h2><p>KubeSphere uses a loosely-coupled architecture that separates the <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fconsole">frontend</a> from the <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere">backend</a>. External systems can access the components of the backend through the REST APIs.</p><p><img src="https://gitee.com/kchstack/kubesphere/raw/master/docs/images/architecture.png" alt="Architecture" referrerpolicy="no-referrer"></p><hr><h2><a id="user-content-latest-release" class="anchor" href="https://gitee.com/kchstack/kubesphere#latest-release"></a>Latest release</h2><p>🎉 KubeSphere 3.3.2 was released! It brings enhancements and better user experience, see the <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Frelease%2Frelease-v332%2F">Release Notes For 3.3.2</a> for the updates.</p><h2><a id="user-content-installation" class="anchor" href="https://gitee.com/kchstack/kubesphere#installation"></a>Installation</h2><p>KubeSphere can run anywhere from on-premise datacenter to any cloud to edge. In addition, it can be deployed on any version-compatible Kubernetes cluster. The installer will start a minimal installation by default, you can <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Fquick-start%2Fenable-pluggable-components%2F">enable other pluggable components before or after installation</a>.</p><h3><a id="user-content-quick-start" class="anchor" href="https://gitee.com/kchstack/kubesphere#quick-start"></a>Quick start</h3><h4><a id="user-content-installing-on-k8sk3s" class="anchor" href="https://gitee.com/kchstack/kubesphere#installing-on-k8sk3s"></a>Installing on K8s/K3s</h4><p>Ensure that your cluster has installed Kubernetes v1.19.x, v1.20.x, v1.21.x, * v1.22.x, * v1.23.x, or * v1.24.x. For Kubernetes versions with an asterisk, some features of edge nodes may be unavailable due to incompatibility. Therefore, if you want to use edge nodes, you are advised to install Kubernetes v1.21.x or earlier.
Run the following commands to install KubeSphere on an existing Kubernetes cluster:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="s">kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/kubesphere-installer.yaml</span></span><span id="LC2" class="line"></span><span id="LC3" class="line"><span class="s">kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/cluster-configuration.yaml</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-all-in-one" class="anchor" href="https://gitee.com/kchstack/kubesphere#all-in-one"></a>All-in-one</h4><p>👨‍💻 No Kubernetes? You can use <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubekey">KubeKey</a> to install both KubeSphere and Kubernetes/K3s in single-node mode on your Linux machine. Let's take K3s as an example:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c1"># Download KubeKey</span></span><span id="LC2" class="line"><span class="s">curl -sfL https://get-kk.kubesphere.io | VERSION=v2.3.0 sh -</span></span><span id="LC3" class="line"><span class="c1"># Make kk executable</span></span><span id="LC4" class="line"><span class="s">chmod +x kk</span></span><span id="LC5" class="line"><span class="c1"># Create a cluster</span></span><span id="LC6" class="line"><span class="s">./kk create cluster --with-kubernetes v1.21.4-k3s --with-kubesphere v3.3.1</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>You can run the following command to view the installation logs. After KubeSphere is successfully installed, you can access the KubeSphere web console at <code>http://IP:30880</code> and log in using the default administrator account (admin/P@88w0rd).</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="s">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-kubesphere-for-hosted-kubernetes-services" class="anchor" href="https://gitee.com/kchstack/kubesphere#kubesphere-for-hosted-kubernetes-services"></a>KubeSphere for hosted Kubernetes services</h3><p>KubeSphere is hosted on the following cloud providers, and you can try KubeSphere by one-click installation on their hosted Kubernetes services.</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Faws.amazon.com%2Fquickstart%2Farchitecture%2Fqingcloud-kubesphere%2F">KubeSphere for Amazon EKS</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fmarket.azure.cn%2Fmarketplace%2Fapps%2Fqingcloud.kubesphere">KubeSphere for Azure AKS</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fmarketplace.digitalocean.com%2Fapps%2Fkubesphere">KubeSphere for DigitalOcean Kubernetes</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.qingcloud.com%2Fproducts%2Fkubesphereqke">KubeSphere on QingCloud AppCenter(QKE)</a></li></ul><p>You can also install KubeSphere on other hosted Kubernetes services within minutes, see the <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Finstalling-on-kubernetes%2F">step-by-step guides</a> to get started.</p><blockquote><p>👨‍💻 No internet access? Refer to the <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Finstalling-on-kubernetes%2Fon-prem-kubernetes%2Finstall-ks-on-linux-airgapped%2F">Air-gapped Installation on Kubernetes</a> or <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fdocs%2Finstalling-on-linux%2Fintroduction%2Fair-gapped-installation%2F">Air-gapped Installation on Linux</a> for instructions on how to use private registry to install KubeSphere.</p></blockquote><h2><a id="user-content-guidance-discussion-contribution-and-support" class="anchor" href="https://gitee.com/kchstack/kubesphere#guidance-discussion-contribution-and-support"></a>Guidance, discussion, contribution, and support</h2><p>We <img class="emoji" alt=":heart:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/heart-aa0a990af1ed6612e33b6344ea04b28b.png" width="14" height="14" referrerpolicy="no-referrer"> your contribution. The <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fcommunity">community</a> walks you through how to get started contributing KubeSphere. The <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fcommunity%2Ftree%2Fmaster%2Fdeveloper-guide%2Fdevelopment">development guide</a> explains how to set up development environment.</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fjoin.slack.com%2Ft%2Fkubesphere%2Fshared_invite%2FenQtNTE3MDIxNzUxNzQ0LTZkNTdkYWNiYTVkMTM5ZThhODY1MjAyZmVlYWEwZmQ3ODQ1NmM1MGVkNWEzZTRhNzk0MzM5MmY4NDc3ZWVhMjE">Slack Channel</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.youtube.com%2Fchannel%2FUCyTdUQUYjf7XLjxECx63Hpw">Youtube</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Ftwitter.com%2FKubeSphere">Twitter</a></li></ul><p>:hugs: Please submit any KubeSphere bugs, issues, and feature requests to <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fissues">KubeSphere GitHub Issue</a>.</p><p><img class="emoji" alt=":heart_decoration:" style="vertical-align: middle" src="https://cn-assets.gitee.com/assets/emoji/heart_decoration-c6bb912722707dbea619b810f0f9eccf.png" width="14" height="14" referrerpolicy="no-referrer"> The KubeSphere team also provides efficient official ticket support to respond in hours. For more information, click <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.cloud%2Fen%2Fticket%2F">KubeSphere Online Support</a>.</p><h2><a id="user-content-who-are-using-kubesphere" class="anchor" href="https://gitee.com/kchstack/kubesphere#who-are-using-kubesphere"></a>Who are using KubeSphere</h2><p>The <a href="https://gitee.com/link?target=https%3A%2F%2Fkubesphere.io%2Fcase%2F">user case studies</a> page includes the user list of the project. You can <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fissues%2F4123">leave a comment</a> to let us know your use case.</p><h2><a id="user-content-landscapes" class="anchor" href="https://gitee.com/kchstack/kubesphere#landscapes"></a>Landscapes</h2><p align="center"><br><br><img src="https://landscape.cncf.io/images/left-logo.svg" width="150" referrerpolicy="no-referrer">&nbsp;&nbsp;<img src="https://landscape.cncf.io/images/right-logo.svg" width="200" referrerpolicy="no-referrer">&nbsp;&nbsp;
<br><br>
KubeSphere is a member of CNCF and a <a href="https://gitee.com/link?target=https%3A%2F%2Fwww.cncf.io%2Fcertification%2Fsoftware-conformance%2F%23logos">Kubernetes Conformance Certified platform
</a>, which enriches the <a href="https://gitee.com/link?target=https%3A%2F%2Flandscape.cncf.io%2F%3Flandscape%3Dobservability-and-analysis%26license%3Dapache-license-2-0">CNCF CLOUD NATIVE Landscape.
</a></p>]]>
            </description>
            <pubDate>Sat, 23 Sep 2023 03:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/kchstack/kubesphere</guid>
            <link>https://gitee.com/kchstack/kubesphere</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 實時數倉混沌演練實踐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" target="_blank">數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><span id="OSC_h1_1"></span><h1>一、背景介紹</h1><p>目前實時數倉提供的投放實時指標優先級別越來越重要，不再是單獨的報表展示等功能，特別是提供給下游規則引擎的相關數據，直接對投放運營的廣告投放產生直接影響，數據延遲或者異常均可能產生直接或者間接的資產損失。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-809771304bbfbfaefda51eb5e25fc0b743f.jpg" referrerpolicy="no-referrer"></p><p>從投放管理平台的鏈路全景圖來看，實時數倉是不可或缺的一環,可以快速處理海量數據，並迅速分析出有效信息，同時支持投放管理平台的手動控盤。實時節點事故，將可能導致整個投放鏈路無法正常運行，另外，投放規則引擎是自動化操作，服務需要 24 小時運行，所以需要配置及時有效的數據質量監控預警，能快速識別到波動異常或者不符合業務的數據，從而計劃引入混沌工程，希望可以通過主動注入故障的方式、儘可能提前感知風險、發現潛在問題，並針對性地進行防範、加固，避免故障發生時所帶來的嚴重後果，提高實時數倉整體抗風險能力。</p><span id="OSC_h1_2"></span><h1>二、演練範圍</h1><p>為了能更細緻反應出混沌演練情況，根據演練的內容不同，將實時數倉混沌分為兩部分：<strong>技術側和業務側</strong>。</p><p><strong>技術側混沌</strong>：基於中間件、數據庫、JVM、基礎資源、網絡、服務等注入常見的異常，根據實際業務中梳理的應用核心場景進行混沌演練，檢驗系統的脆弱性和應急響應能力，從而提升團隊的穩定性保障處理能力。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-cc08de52de41ac5854303f7b55939ec35ff.jpg" referrerpolicy="no-referrer"></p><p><strong>業務側混沌</strong>：對於電商活動密集型的公司來説，各種到達率、曝光率，以及更加宏觀的 GMV、用戶拉新數、用戶召喚數等，都能表現出業務的健康程度，在實際生活中，為了描述一種穩定狀態，我們需要一組指標構成一種模型，而不是單一指標。無論是否採用混沌工程，識別出這類指標的健康狀態都是至關重要的，所以要圍繞它們建立一整套完善的數據採集、監控、預警機制，當業務指標發生波動較大時，我們能搞快速感知、定位、修復止血。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-f656ab86204af67698ca5e53593548d77c9.jpg" referrerpolicy="no-referrer"></p><p><strong>過往數倉混沌工程均是技術側，此次在投放鏈路已搭建完成主備鏈路的前提下，期望通可以通過多輪業務側混沌，提高系統整體的數據異動感知能力。</strong></p><span id="OSC_h1_3"></span><h1>三、演練計劃</h1><p>工欲善其事，必先利其器，在執行混沌演練前，需要準備好前置工作，制定合理的演練 SOP、方案、計劃，對演練環境、腳本、數據、工具，場景及爆炸半徑等進行可能性評估，在確認可行性 ok 的情況下，約好關聯方時間，再進行實踐操作。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-cfdf19906836e41b5cb869b64608d799432.jpg" referrerpolicy="no-referrer"></p><p>本篇主要和大家分享基於業務側的實時數倉混沌演練過程：</p><span id="OSC_h2_4"></span><h2>1.編寫演練 SOP</h2><p>SOP 是一種標準的作業程序，就是將某一事件的操作步驟和要求，進行細化、量化及優化，形成一種標準的操作過程，關於業務側混沌，尤其是實時數倉數據相關的演練，我們也是第一次做，目前在業界也沒有找到相關的演練指導參考，處於探索階段，為了方便項目進度的順利進行及後續演練操作更加規範、高效，在演練前期大家經過溝通、討論後，項目前期梳理的 SOP 演練模板，如下： <img alt="" src="https://oscimg.oschina.net/oscnet/up-b05836c213c5deb4a521e61b8d9bf67f60f.jpg" referrerpolicy="no-referrer"></p><span id="OSC_h2_5"></span><h2>2.演練方案調研</h2><p>先收集實時數倉投放鏈路核心指標範圍，在此基礎上，拉取一段時間內的歷史數據進行分析，找到每個指標對應的健康波動閥值，從而在配置相應的 DQC 規則監控，對於波動不在健康閥值的異常指標，在分鐘級別（預期 15min）內及時告警，並快速排查響應。為此，在演練前期，我們經歷過一系列的方案調研、探索，如下：</p><p><strong>「下文提供的方案，指標數據都是以設備激活數為例進行分析」</strong></p><ul><li><p>方案一: 按照天維度，收集最近一段時間，<strong>同一天每個整點設備激活數，佔當天大盤佔比</strong>，統計出最小值、最大值，作為該指標的健康波動閥值; <img alt="" src="https://oscimg.oschina.net/oscnet/up-5db6bf773388277a477d014346b562cbbc9.jpg" referrerpolicy="no-referrer"></p></li><li><p>方案二: 按照天維度，收集一段時間內，<strong>同一天相鄰整點指標波動</strong>數據找規律，比如每天上午 9 點到 10 點的波動數據，然後分別通過一系列的數學分佈方法進行數據統計，從而希望找一個相對穩定的波動區間； <img alt="" src="https://oscimg.oschina.net/oscnet/up-e6acfa0ba597d5eec2b48a96608a1ded0d4.jpg" referrerpolicy="no-referrer"></p></li><li><p>方案三: 按照天維度，收集一段時間內，<strong>相鄰天整點指標波動</strong>數據找規律，比如昨天上午 9 點到前天上午 9 點的波動數據，然後分別通過一系列的數學分佈方法進行數據統計，從而希望找一個相對穩定的波動區間； <img alt="" src="https://oscimg.oschina.net/oscnet/up-ec085c12fa338ea0704fef3dcc4a96d16fa.jpg" referrerpolicy="no-referrer"></p></li><li><p>方案四:在前面三種方案的基礎上，指標在工作日和週末的波動可能不一樣，所以我們在日維度統計的基礎上，我們也調研了<strong>周維度同比波動</strong>分佈情況，比如每週一上午 9 點到上午 10 點的波動數據，然後分別通過一系列的數學分佈方法進行數據統計，從而希望找一個相對穩定的波動區間； <img alt="" src="https://oscimg.oschina.net/oscnet/up-867fe3fd131a2016e25d162e0a81407fc07.jpg" referrerpolicy="no-referrer"></p></li><li><p>方案五:同理，我們也調研了<strong>周維度環比波動</strong>分佈情況，比如本週一上午 9 點到上週一上午 9 點的波動數據，然後分別通過一系列的數學分佈方法進行數據統計，從而希望找一個相對穩定的波動區間； <img alt="" src="https://oscimg.oschina.net/oscnet/up-3f6117360a9087dea86b7d0a38eb7053db9.jpg" referrerpolicy="no-referrer"></p></li><li><p>方案六：基於主備鏈路，在 source 源相同的情況下，經過實時數倉計算出的指標，在同一段時間兩條鏈路 sink 出來的結果數據，正常應該是保持一致，或者波動較小，比如 10 分鐘延遲的主備鏈路，波動不超過 10%，平均差異做到一致性做到 90% 以上。</p></li></ul><p>方案 1 到 5，都嘗試過一遍，每個方案場景數據通過最大值、最小值、平均值、各百分位分佈、方差、標準差等統計出來的數據分析，很難找到一個相當穩定的波動規律，也無法框定指標具體的閥值區間，實際演練過程，如果設置的波動告警閥值過大，真實生產上業務數據波動異常時，無法及時告警發現；設置過小，將導致告警頻繁，對其準確性、有效性可能存在質疑，而且，實時投放的核心指標有幾十個，每個指標對應的健康閥值都不一樣，要收集、分析成本非常高，從演練的效果上看，也不是很明顯。</p><p><strong>整體評估下來，演練主要採用的是方案六：涉及到的實時投放核心指標數共收集 29 個，一段時間內（15min），主備鏈路指標波動差異不超過 10%。</strong></p><span id="OSC_h2_6"></span><h2>3.演練方式</h2><p>紅藍對抗演練，將團隊分為紅（防）藍（攻）兩組。</p><blockquote><p>測試人員組成藍軍：負責制定混沌演練方案，執行目標系統故障注入，詳細記錄演練過程；</p><p>實時數倉開發為紅軍：負責發現故障、應急響應、排除故障，同時驗證系統在不同故障場景下的容錯能力、監控能力、人員響應能力、恢復能力等可靠性能力。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-f3b6dfa0fc9f4c79a51bf8dda03258b9c04.jpg" referrerpolicy="no-referrer"></p></blockquote><span id="OSC_h1_7"></span><h1>四、演練流程</h1><p>整體演練過程，大致分為三個階段：準備階段、攻防階段及覆盤階段。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-7cd2ed35bed2468d536c47d934484c34db0.jpg" referrerpolicy="no-referrer"></p><span id="OSC_h2_8"></span><h2>1.準備階段</h2><ul><li><p>方案准備完評審通過後，確認好鏈路計劃；</p></li><li><p>藍軍按計劃根據事先制定的攻擊方案，提前準備好相應的測試數據、腳本； ‍</p></li><li><p>紅軍按計劃根據事先制定的攻擊方案，在演練前，提前確保環境可用，並進行監控防禦、應急響應措施。</p></li></ul><span id="OSC_h2_9"></span><h2>2.攻防階段</h2><ul><li><p>藍隊根據事先制定的攻擊方案，模擬真實的攻擊行為，按照約定的時間在演練鏈路（備用鏈路）進行攻擊，進行故障注入，同時記錄好相應的操作步驟，方便後續報告梳理；</p></li><li><p>紅隊在藍軍攻擊後，通過飛書/郵件告警等通知方式實時關注監控系統運行情況，如有異常告警，需第一時間進行問題排查定位，在評估修復方案；</p></li><li><p>在攻防對抗的過程中，藍軍可根據紅軍的防禦措施進行調整和改進攻擊策略，盡力突破系統的防禦並達到既定目標，同時紅軍也可分析藍軍的攻擊手法和行為模型，不斷改進防禦措施來加強防禦。</p></li></ul><span id="OSC_h2_10"></span><h2>3.覆盤和改進階段</h2><ul><li><p>在混沌演練結束後，進行總結和評估，分析紅隊和藍隊的表現，評估系統的安全性和抗攻擊能力；</p></li><li><p>總結經驗教訓，總結成功的防禦措施和失敗的攻擊手法，以便於改進系統的安全策略； ‍</p></li><li><p>根據評估結果和總結經驗，制定改進計劃，修補系統中的漏洞和薄弱點，提升系統的抗風險能力。</p></li></ul><span id="OSC_h1_11"></span><h1>五、攻防實戰</h1><p>本次演練共計有 29 個指標波動 case，整體演練操作大同小異。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-231ad23a9d169ab0aca3cc910ee770bb003.jpg" referrerpolicy="no-referrer"></p><p>以其中 case17 「召回商品收藏 uv 在某個渠道下整點波動異常」為例，<strong>具體的演練操作流程如下。</strong></p><span id="OSC_h2_12"></span><h2>1.數據準備</h2><ul><li>通過後台數據庫，拉出生產主 (備) 鏈路，某個渠道（如<code>media_id</code> = '2'）下某個整點（如<code>hour</code> = 10）下，召回商品收藏 uv 對應的整體統計值 N。</li></ul><pre><code>--渠道小時整點維度下，商品收藏 uv 彙總數據
select
  `指標名稱`,
  `日期`,
  '2' as `指標 ID`,
  `小時段`,
  sum(`指標值`)
from table_a
where
  date = date_format(now(), '%Y%m%d')
  and `指標名稱` in ( '商品收藏 uv' )
  and `小時段` = 10
  AND `指標 id` = '2'
GROUP BY
  `指標名稱`,
  `日期`,
  `小時段`
order by
  指標名稱;
</code></pre><ul><li>拉出備用鏈路，某個渠道（如<code>media_id</code> = '2'）下某個整點（如<code>hour</code> = 10）下，具體的一條明細數據，記錄商品收藏 uv 對應的值為 n,把 n 改為 n+0.1N,後續注入進備用鏈路，從而使得主備波動差異在 10%。</li></ul><pre><code>-- 明細數據
select
  t.指標名稱,t.賬戶 id,t.計劃 ID,t.設備類型,t.指標值
from
  (
    select
      `賬戶 id`,
      `計劃 id`,
      `指標名稱`,
      `指標值`,
      `設備類型` ,
      row_number() over (partition by 指標名稱 order by 指標值 desc ) as rn
    from  table_a
    where
      date = date_format(now(), '%Y%m%d')
      and `指標名稱` in ('商品收藏 uv')
      and `設備類型` = '召回'
      and `小時段` = 10
      AND `指標 id` = '2'
  ) t
where
  t.rn = 1
ORDER BY 指標名稱;
</code></pre><ul><li>整理後得到需要注入的數據數據，見標黃部分。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-ede988eb7f5092a5961838f767529977686.jpg" referrerpolicy="no-referrer"></li></ul><span id="OSC_h2_13"></span><h2>2.故障注入 odps</h2><ul><li>將需要注入的數據導入 odps。</li></ul><p>導入前，需要在 datawork 空間中新建測試表 du_qa_dw_dev.hundun_case，用於導入演練數據</p><pre><code>-- drop table if  EXISTS du_qa_dw_dev.hundun_case;
CREATE TABLE IF NOT EXISTS hundun_case
(
    message  STRING COMMENT '消息內容'
)
COMMENT '混沌演練'
;
</code></pre><ul><li>往 du_qa_dw_dev.hundun_case 表裏灌數。</li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9a812903d786097d62990f612ff7aa80cac.jpg" referrerpolicy="no-referrer"><img alt="" src="https://oscimg.oschina.net/oscnet/up-46b380b575675ee1cfa3f6fb5dcfd895036.jpg" referrerpolicy="no-referrer"></p><ul><li>驗證數據導入是否成功。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-f1b328461b1a5b283c4e8975019463c0d4d.jpg" referrerpolicy="no-referrer"></li></ul><span id="OSC_h2_14"></span><h2>3.odps 同步到 kafka</h2><p>執行 flink 同步腳本，將 odsp du_qa_dw_dev.hundun_case 表表數據同步到對應的 kafka topic 中。</p><p><strong>flink 任務腳本：</strong></p><pre><code>--SQL
--********************************************************************--
--odps 同步到 kakfa 腳本，用於實時數倉混沌演練異常注入使用
--********************************************************************--
-- 基本函數
CREATE FUNCTION JsonParseField AS 'com.alibaba.blink.udx.log.JsonParseField';
CREATE FUNCTION jsonStringUdf AS 'com.alibaba.blink.udx.udf.JsonStringUdfV2';
---同步賬號表
CREATE TABLE `source` (
message                        VARCHAR  
) WITH (
   'connector' = 'du-odps',
  'endPoint' = '***',
  'project' = '***',
  'tableName' = 'hundun_case_01',
  'accessId' = '*******',
  'accessKey' = '*******'

);

CREATE TABLE `kafka_sink` (
  `messageKey`  VARBINARY,
  `message`  VARBINARY,
  PRIMARY KEY (`messageKey`) NOT ENFORCED
) WITH (
  'connector' = 'du-kafka',
  'topic' = '********',
   'properties.bootstrap.servers' = '*******',
  'properties.compression.type' = 'gzip',
  'properties.batch.size' = '40960',
  'properties.linger.ms' = '1000',
  'key.format' = 'raw',
  'value.format' = 'raw',
  'value.fields-include' = 'EXCEPT_KEY'
);

INSERT INTO kafka_sink
SELECT
cast(MD5(message) as VARBINARY),
cast(message as VARBINARY)
FROM source
;
</code></pre><span id="OSC_h2_15"></span><h2>4.kafka 平台查詢數據</h2><p>執行完 flink 同步任務後，可通過後台查詢，對應的數據是否同步成功。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-1cf077eceab902d334f7a02744f110a4ea3.jpg" referrerpolicy="no-referrer"></p><span id="OSC_h2_16"></span><h2>5.異常注入通知</h2><p>在異常注入完成後，可以通過飛書羣通知，告知紅軍，如收到告警，需第一時間羣告知。</p><blockquote><p>藍軍：藍軍已完成數據準備，請紅軍在演練前確保環境 OK 且已完成規則配置，另外務必將演練時間計劃及時同步通知到下游關聯方；</p><p>藍軍：已完成注入。</p></blockquote><span id="OSC_h2_17"></span><h2>6.告警觸發通知</h2><ul><li>紅軍在演練前，可通過監控平台提前配置好防禦規則。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-db13e71a209e4074cce8a2bbc1a41667f5c.jpg" referrerpolicy="no-referrer"></li><li>在異常注入後，如符合預期，在 15min 內發現指標波動異常，紅軍需及時同步到演練羣中。</li></ul><blockquote><p>中危**雙鏈路主備一致監控</p><p>服務名：**** 環境：****** 告警時間：****** 觸發條件：**雙鏈路比對波動異常，持續 10 分鐘，告警詳情：指標:prd_collect_uv 主對比備下降:[-10%] 主:1066 備:956</p><p>業務域：實時數倉</p><p>應用負責人：***</p></blockquote><ul><li>如不符合預期，未在 15min 內發現指標波動異常，紅軍需及時定位、跟進問題，並在修復後，溝通後續演練驗證修復結果。</li></ul><blockquote><p>紅軍：15min 內未收到告警，定位中</p><p>紅軍：原因已找到，由於***造成，導致告警數據沒有及時發出，正在修復處理</p><p>紅軍：已修復，請紅軍重新發起攻擊</p></blockquote><span id="OSC_h2_18"></span><h2>7.演練過程記錄</h2><p>收集、彙總記錄演練過程中的每個操作，含時間點、執行人、操作等，如下： <img alt="" src="https://oscimg.oschina.net/oscnet/up-464e3d7975b42956cc2007407a22290fcce.jpg" referrerpolicy="no-referrer"></p><span id="OSC_h1_19"></span><h1>六、演練總結</h1><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-679f8b1b380d497f60dc055e5eb209dc097.jpg" referrerpolicy="no-referrer"></p><span id="OSC_h1_20"></span><h1>七、未來展望</h1><p>實時數倉業務側的混沌演練，從 0 到 1，在經過一系列的探索實踐後，通過主備鏈路比對方式，演練期間對於異常波動的指標，可以快速識別感知，從演練結果上，取得了不錯的成效，但也存在一定的侷限性，如：</p><ul><li><p>演練期間，通過人工注入的異常數據，如無法快速清除，可能影響到備用鏈路使用。</p></li><li><p>對於沒有備鏈路的實時指標波動，需要制定更精細化的可行方案，找尋指標健康波動範圍。</p></li></ul><p>這些都需要團隊進一步去探索、解決，同時在演練的過程中，我們將不斷積累、豐富演練 case、完善演練庫，後續計劃通過引入工具（平台）、建立演練協助機制、定期定時演練等手段，使混沌演練更加自動化、規範化、常態化，提高實時數倉整體數據穩定。 <img alt="" src="https://oscimg.oschina.net/oscnet/up-44be503ee4b17e831ef9e2fabf906b71236.jpg" referrerpolicy="no-referrer"> *文 / 袁宵</p><p>本文屬得物技術原創，更多精彩文章請看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com%2F" rel="nofollow" target="_blank">得物技術官網</a></p><p>未經得物技術許可嚴禁轉載，否則依法追究法律責任！</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 23 Sep 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/10112796</guid>
            <link>https://my.oschina.net/u/5783135/blog/10112796</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為開源 openInula 前端框架，兼容 React API 和生態]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">lnula（發音為：[ˈɪnjʊlə]）。openInula 是一款用於構建用戶界面的 JavaScript 庫，提供響應式 API 幫助開發者簡單高效構建 web 頁面，比傳統虛擬 DOM 方式渲染效率提升 30% 以上！同時 InulaJS 提供與 React 保持一致的 API，並且提供 5 大常用功能豐富的核心組件：狀態管理器、路由、國際化、請求組件、應用腳手架，以便開發者高效、高質量的構築基於 InulaJS 的前端產品。</p><h2 style="margin-left:0; margin-right:0; text-align:left">技術架構</h2><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><img alt="輸入圖片説明" src="https://static.oschina.net/uploads/img/202309/23073740_6lHO.png" referrerpolicy="no-referrer"></p><h3 style="margin-left:0; margin-right:0; text-align:left">核心能力</h3><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>響應式 API</strong></p><ul><li>openInula 通過最小化重新渲染的範圍，從而進行高效的 UI 渲染。這種方式避免了虛擬 DOM 的開銷，使得 openInula 在性能方面表現出色。</li><li>openInula 通過比較變化前後的 JavaScript 對象以細粒度的依賴追蹤機制來實現響應式更新，無需用戶過度關注性能優化。</li><li>簡潔 API：
<ol style="list-style-type:lower-roman"><li>openInula 提供了兩組簡潔直觀的 API--響應式 API 和與 React 一致的傳統 API，使得開發者可以輕鬆地構建複雜的交互式界面。</li><li>openInula 簡潔的 API 極大降低了開發者的學習成本，開發者使用響應式 API 可以快速構建高效的前端界面。</li></ol></li></ul><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>兼容 ReactAPI</strong></p><ul><li>與 React 保持一致 API 的特性、可以無縫支持 React 生態。</li><li>使用傳統 API 可以無縫將 React 項目切換至 openInula，React 應用可零修改切換至 openInula。</li></ul><h3 style="margin-left:0; margin-right:0; text-align:left">openInula 配套組件</h3><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>狀態管理器/inula-X</strong></p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">inula-X 是 openInula 默認提供的狀態管理器，無需額外引入三方庫，就可以簡單實現跨組件/頁面共享狀態。 inula-X 與 Redux 比可創建多個 Store，不需要在 Reducer 中返回 state 並且簡化了 Action 和 Reducer 的創建步驟，原生支持異步能力，組件能做到精準重渲染。inula-X 均可使用函數組件、class 組件，能提供 redux 的適配接口及支持響應式的特點。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>路由/inula-router</strong></p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">inula-router 是 openInula 生態組建的一部分，為 openInula 提供前端路由的能力，是構建大型應用必要組件。 inula-router 涵蓋 react-router、history、connect-react-router 的功能。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>請求/inula-request</strong></p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">inula-request 是 openInula 生態組件，涵蓋常見的網絡請求方式，並提供動態輪詢鈎子函數給用戶更便捷的定製化請求體驗。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>國際化/inula-intl</strong></p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">lnula-intl 是基於 openInula 生態組件，其主要提供了國際化功能，涵蓋了基本的國際化組件和鈎子函數，便於用戶在構建國際化能力時方便操作。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>調試工具/inula-dev-tools</strong></p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">inula-dev-tools 是一個為 openInula 開發者提供的強大工具集，能夠方便地查看和編輯組件樹、管理應用狀態以及進行性能分析，極大提高了開發效率和診斷問題的便捷性。</p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"><strong>腳手架/inula-cli</strong></p><p style="color:#40485b; margin-left:0; margin-right:0; text-align:left">lnula-cli 是一套針對 openInula 的編譯期插件，它支持代碼優化、JSX 語法轉換以及代碼分割，有助於提高應用的性能、可讀性和可維護性。</p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 23:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/openinula</guid>
            <link>https://www.oschina.net/p/openinula</link>
        </item>
        <item>
            <title>
                <![CDATA[低代碼引擎 TinyEngine 正式發佈！！！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" target="_blank">數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p><img src="https://oscimg.oschina.net/oscnet/up-889246aad04bcf78bd25d07144ac7a00325.png" alt="" referrerpolicy="no-referrer"> 在當今數字化飛速發展的時代，企業對高效、敏捷的應用程序需求日益旺盛。為了滿足這一需求，越來越多的低代碼開發平台開始湧現。這些平台通過提供簡單易用的開發工具和優化後的開發流程，幫助開發者快速構建高質量、可重複使用的應用程序，同時降低了開發的難度和成本，提高了開發效率和靈活性。這些低代碼開發平台的出現，無疑為企業的數字化轉型提供了更快速、更高效的方法，也將推動整個軟件開發行業的進步。</p><h2>TinyEngine 項目介紹</h2><p>隨着企業對於低代碼開發平台的需求日益增長，急需一個通用的解決方案來滿足各種低代碼平台的開發需求。正是在這種情況下，低代碼引擎應運而生。它是一種通用的開發框架，通過對低代碼平台系統常用的功能進行解構，將其劃分為多個功能模塊，併為每個模塊定義了相應的協議和開發範式，使得開發者可以根據自身的業務需求，輕鬆定製開發出自己的低代碼開發平台。</p><p>隨着企業對於低代碼開發平台的需求日益增長，急需一個通用的解決方案來滿足各種低代碼平台的開發需求。正是在這種情況下，低代碼引擎應運而生。它是一種通用的開發框架，通過對低代碼平台系統常用的功能進行解構，將其劃分為多個功能模塊，併為每個模塊定義了相應的協議和開發範式，使得開發者可以根據自身的業務需求，輕鬆定製開發出自己的低代碼開發平台。</p><p><img src="https://oscimg.oschina.net/oscnet/up-eafd0400a47b2223f7736ca1f815f5931b7.png" alt="" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 提供了低代碼底層能力，並集成了人工智能，從而使用戶能夠高效開發。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 具有強大的拖拽功能，無論是圖元還是複雜組件，都能在畫布上帶來流暢的體驗。它適用於多場景的低代碼平台開發，包括資源編排、流程編排、服務端渲染、模型驅動、移動端、大屏端以及頁面編排等低代碼平台。</p><h3>架構</h3><p><img src="https://oscimg.oschina.net/oscnet/up-9987cd6c7d0245549bcf11fca5ea1e97da5.png" alt="" referrerpolicy="no-referrer"></p><h3>核心亮點</h3><ul><li><strong>可以定製開發低碼平台</strong>。</li></ul><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 採用靈活的系統架構，其出色的整體架構提供了高度的自定義自由度，使用戶能夠像搭建積木一樣選擇不同的模塊來構建自己的專屬設計器。此外，插件化的架構使得用戶可以方便地擴展與業務相關的功能。 在 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 中，插件根據位置大致分為三類：toolbars/plugins/settings，分別對應頂部區域、左側區域和右側區域。toolbars 插件主要偏向於無需 UI 或者 UI 較為簡單的工具插件，plugins 是業務功能插件，顯示在左側 (或下方) 抽屜頁面，可以通過點擊進行展開收起或切換。這些功能都像是獨立的積木塊，用戶可以選擇性地保留或刪除。同時，用戶也可以開發自己的插件或工具，並將其安裝到對應的位置。<strong>TinyEngine 的靈活性極強，用戶可以自由地決定他們想要開發什麼樣的低代碼平台。</strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 提供了一套完善的插件體系，涵蓋了插件開發所需的基礎 UI 庫、工具庫、插件面板的顯示控制、生命週期管理、公共 API 註冊與共享等。這一體系使得開發者只需遵循簡單的規範，即可快速開發出業務所需的插件，從而極大地提高了開發效率和靈活性。通過使用 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 提供的插件體系，開發者可以更加輕鬆地管理和維護複雜的插件生態系統，同時降低維護成本。總之，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 的插件體系為開發者提供了一個全面、高效、靈活的開發平台，使得快速開發出高質量的插件成為可能。</p><p>插件開發需要遵循一定的開發規範，主要是文件規範與導出規範：</p><p>1、文件規範，必須包含下面幾個文件</p><pre><code class="language-js">pluginProject
- src 插件源碼
- index.js 註冊插件入口，需要導出約定的數據結構
- package.json
</code></pre><p>2、導出規範， index.js 文件需要導出一個對象來聲明基礎信息</p><pre><code class="language-js"> import component, { api } from './src/Main.vue'
 
 export default {
          id: 'pluginId', // 插件 id
          title: 'pluginName', // 插件名
          icon: 'js', // 插件 icon
          align: 'top', // 插件位置，左側插件可選值：'top' | 'bottom'  工具欄可選值：'right' | 'center' | 'left'
          component, // 插件面板打開時渲染的組件
          api, // 插件暴露的 api，可以提供給其他插件調用
        }
</code></pre><p>在此基礎上就可以按照業務需要自由開發相關邏輯代碼。</p><p>3、最後在 addons.js 插件配置文件中引入，就完成一個完整的插件開發了。</p><pre><code class="language-js">import Materials from '@xxxx/lowcode-plugin-materials'

        export default {
          plugins: [
            Materials,
            // ...
          ],
          toolbars: [
            // ...
          ],
          settings: [
            // ...
          ],
        }
</code></pre><p>（ps:我們呼籲用戶把開發的插件包開源，共建 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 的生態。）</p><ul><li><strong>TinyEngine 有開放的物料協議和擴展接口。</strong> &nbsp;</li></ul><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 低代碼引擎默認的物料來源於華為雲開源組件庫 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2Ftiny-vue%2Fzh-CN%2Fos-theme%2Fdocs%2Fchangelog" target="_blank">TinyVue</a>，該組件庫擁有豐富的組件和強大的功能。並且實現了跨端垮技術棧，同時支持 vue2 和 vue3。即使業務系統使用其他組件庫，也無需切換，得益於 TinyEngine 強大的開放物料設計，可直接導入第三方組件庫，例如 elementUI 和 AntDesign 等。引擎底層技術架構採用 webcomponent 技術，因此支持 Vue、React 和 Angular 等不同技術棧的組件或區塊。<strong>用戶可以自由選擇所需的組件庫並導入使用</strong>。</p><p>導入第三方組件庫，找到 runner.js 物料文件。然後參照默認物料 @opentiny/vue 即可，主要修改以下地方：</p><pre><code class="language-js">// 全量導入 UI 組件庫
import UI from '@xxxx/UI'

Object.entries(UI).forEach(([key, component]) =&gt; {
   const { name } = component
   if (name) {
   window.TinyLowcodeComponent[name] = component
   }
  })

// 導入某個組件庫裏面的單個組件
 import { button } from '@xxxx/UI'

window.TinyLowcodeComponent[name] = button
</code></pre><p>通過導入第三方組件庫，用戶可以在低代碼平台中使用這些組件庫來開發應用程序。除了導入組件外，用戶還需要通過 bundle.json 文件來描述導入的組件所暴露出來的事件和屬性。這樣，用戶可以在應用程序中使用這些組件，並通過 bundle.json 文件來瞭解和使用組件的事件和屬性。這是一個非常方便和靈活的功能，使得用戶可以自由地使用和定製他們所需的組件，從而快速開發出高質量的應用程序。</p><pre><code class="language-json"> // 以下 JSON 為節選按鈕暴露的屬性
        {
          "schema": {
            "type": "object",
            "properties": {
              "size": {
                "title": "定義按鈕尺寸",
                "type": "string",
                "enum": ["large", "medium", "small", "mini"],
                "enumNames": ["較大尺寸", "中等尺寸", "較小尺寸", "迷你尺寸"],
                "default": ""
              },
              "text": {
                "title": "設置按鈕顯示的文本",
                "type": "string",
                "default": ""
              }
            },
            "events": {
              "onClick": {
                "label": {
                  "zh_CN": "鼠標單擊時觸發",
                  "en_US": "Triggered on mouse click"
                },
                "description": {
                  "zh_CN": "鼠標單擊時觸發的回調函數"
                },
                "type": "event",
                "defaultValue": ""
              }
            }
          }
        }
</code></pre><ul><li><strong>TinyEngine 支持自定義 DSL 生成定製的源代碼。</strong></li></ul><p>相對於在運行時由平台提供渲染引擎的方式，這種方式能夠為用戶提供更多的自主權和安全性。用戶可以自由地定義自己的 DSL，並根據需要生成定製化的源代碼，從而更加靈活地控制應用程序的行為和性能。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a49a7815e0e7252136772b0fcb2daf2f5ca.png" alt="" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 默認生成 Vue 的源代碼。當頁面編排完成後，會生成一個包含頁面信息的 schema。DSL 通過便利遞歸等方法，從中生成源代碼。如果技術棧是 Angular 或 React，用戶可以完全開發一個 Angular 或 React 的 DSL，從而生成一個新的源代碼工程。用戶可以根據自己的需求定製生成源代碼的方式，這是一個非常靈活和強大的功能，使得 TinyEngine 可以適應不同的技術棧和需求，從而更加廣泛地應用於各種應用程序的開發。</p><p>如果你想開發其他技術棧的 DSL，那麼一定要對<strong>頁面協議</strong>比較熟悉。</p><pre><code class="language-js">interface&nbsp;IPageSchema&nbsp;{&nbsp;//&nbsp;頁面&nbsp;或&nbsp;區塊&nbsp;schema  
&nbsp;&nbsp;fileName?:&nbsp;string;&nbsp;//&nbsp;頁面名稱，schema&nbsp;是頁面時使用  
&nbsp;&nbsp;componentName?:&nbsp;string;&nbsp;//&nbsp;組件名，schema&nbsp;是頁面時值為&nbsp;"Page"  
&nbsp;&nbsp;blockName?:&nbsp;string;&nbsp;//&nbsp;區塊名，schema&nbsp;是區塊時使用  
&nbsp;&nbsp;id:&nbsp;string;  
&nbsp;&nbsp;css?:&nbsp;string;&nbsp;//&nbsp;頁面全局樣式  
&nbsp;&nbsp;props?:&nbsp;{&nbsp;//&nbsp;組件綁定的屬性  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[prop:string]?:&nbsp;any;  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;style?:&nbsp;string;&nbsp;//&nbsp;行內樣式  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;className?:&nbsp;string;&nbsp;//&nbsp;綁定的樣式類名  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lifeCycles?:&nbsp;{&nbsp;//&nbsp;生命週期  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[prop:string]?:&nbsp;{  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:&nbsp;'js';&nbsp;//&nbsp;固定值  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;source:&nbsp;string;&nbsp;//&nbsp;函數字符串  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};  
&nbsp;&nbsp;children?:&nbsp;Array&lt;&nbsp;IComponentSchema&nbsp;&gt;&nbsp;|&nbsp;string;&nbsp;//&nbsp;子組件列表&nbsp;或&nbsp;文本字符串  
&nbsp;&nbsp;dataSource?:&nbsp;{&nbsp;//&nbsp;數據源  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;Array&lt;&nbsp;IDateSource&nbsp;&gt;&nbsp;//&nbsp;數據源列表  
&nbsp;&nbsp;};  
&nbsp;&nbsp;actions?:&nbsp;{&nbsp;//&nbsp;頁面&nbsp;JS  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;module:&nbsp;{  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;source:&nbsp;string;&nbsp;//&nbsp;頁面定義的&nbsp;JS&nbsp;源碼字符串  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:&nbsp;"FUNCTION";&nbsp;//&nbsp;固定值  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list:&nbsp;Array&lt;{  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id:&nbsp;string;&nbsp;//&nbsp;頁面所定義的函數名  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title:&nbsp;string;&nbsp;//&nbsp;配置時顯示名稱&nbsp;與&nbsp;id&nbsp;一致  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&gt;  
&nbsp;&nbsp;};  
&nbsp;&nbsp;bridge?:&nbsp;{&nbsp;//&nbsp;橋接  
&nbsp;&nbsp;imports?:&nbsp;Array&lt;{  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;string;&nbsp;//&nbsp;配置時顯示名稱  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:&nbsp;"package"&nbsp;|&nbsp;"local";&nbsp;//&nbsp;package:&nbsp;npm&nbsp;包;&nbsp;local:&nbsp;本地文件  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;path:&nbsp;string;&nbsp;//&nbsp;導入的路徑 (包名或者本地路徑)  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item:&nbsp;string;&nbsp;//&nbsp;導入的項目  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;useDefault?:&nbsp;boolean;&nbsp;//&nbsp;是否默認導出  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;instance?:&nbsp;string;&nbsp;//&nbsp;實例名，需要注入 service 時需要添加該字段，typescript&nbsp;模式下使用  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&gt;  
&nbsp;&nbsp;};  
&nbsp;&nbsp;inputs:&nbsp;Array&lt;{&nbsp;//&nbsp;頁面接口：輸入類型  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;string;&nbsp;//&nbsp;輸入屬性名稱  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:&nbsp;string;&nbsp;//&nbsp;數據類型聲明  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;defaultValue?:&nbsp;any;&nbsp;//&nbsp;默認值  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&gt;;  
&nbsp;&nbsp;outputs:&nbsp;Array&lt;{&nbsp;//&nbsp;頁面接口：事件輸出  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;string;&nbsp;//&nbsp;typescript 類型聲明  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:&nbsp;string;&nbsp;//&nbsp;數據類型聲明  
&nbsp;&nbsp;}&gt;;  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;schema?:&nbsp;IComponentMetaSchema&nbsp;//&nbsp;區塊時使用，區塊需要暴露的組件屬性元數據  
&nbsp;&nbsp;}
</code></pre><p>對於需要被搜索引擎爬蟲 SEO 的用戶，也可以用服務端 SSR 的解決方式。這種方案也可以用來快速查看自己編輯的頁面。</p><pre><code class="language-js"> // 偽代碼
 function render(_schema) {
  let _arr = []
  _schema.forEach((item) =&gt; {
    let componentName = item.componentName
    if (item.children &amp;&amp; item.children.length) {
      _arr.push(
        h(componentName, item.props, [
          item?.props?.text,
          render(item.children),
        ]),
      )
    } else {
      const text = item?.props?.text || ''
      _arr.push(h(componentName, item.props, text))
    }
  })

  return _arr
}
</code></pre><ul><li><strong>TinyEngine 支持高低代碼混合開發。</strong></li></ul><p>高低代碼混合開發可以更好地滿足業務需求。在企業的應用開發中，往往需要面對快速變化的業務需求，此時，如果全部採用低代碼方式進行開發，則可能會因為代碼的複雜性而無法快速適應變化。而如果採用高低代碼混合的方式，則可以通過低代碼進行常規業務的快速開發，對於特殊的業務邏輯，則由專業開發人員通過高代碼進行實現，這樣就可以更好地滿足業務需求的變化。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 在構建應用程序的過程中，提供了下載源代碼的功能，使得用戶可以在線下進行復雜業務邏輯的調試。這一特點極大地便利了開發者的操作，減少了在線調試和測試的時間和資源消耗，同時也提高了代碼的質量和可靠性。通過下載源代碼進行調試，用戶可以更加靈活地控制應用程序的行為和性能，從而更好地滿足業務需求。總之，TinyEngine 的這一特點為用戶提供了更多的自主權和靈活性，使得他們可以更加高效地控制應用程序的行為和性能。</p><ul><li><strong>TinyEngine 支持 AI 輔助開發。</strong> &nbsp;</li></ul><p>低代碼平台與 AI 的結合具有巨大的發展潛力。這種結合可以在很大程度上提高非專業開發者的開發效率和應用智能化水平。隨着 AI 技術的不斷髮展和低代碼平台的不斷成熟，二者的結合將會在更多領域內實現更高效、更智能的業務流程和管理模式，帶來更大的商業價值。</p><p>低代碼平台通過提供易於使用的開發工具和預先構建的模塊，簡化了應用程序的開發過程。AI 技術則可以幫助應用程序具備更智能、更自適應的特性。通過低代碼平台和 AI 的結合，開發者可以更快速、更高效地構建應用程序，並實現更智能化的應用特性。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3acfa3b07927729dbdd65990716f506f4e0.gif" alt="" referrerpolicy="no-referrer"></p><h2>企業關於低代碼的需求</h2><ul><li><h3>PDM 元數據電子審批流</h3></li></ul><p>審批流業務場景是現代企業運營中不可或缺的一環。業務流程從某個特定點開始，然後經過一系列的審批節點，完成流程的審批。這些節點通常由不同級別的人員擔任，例如主管、經理、財務、法務和總經理等，每個人都扮演着特定的角色和職責。</p><p>假設場景如下：流程發起人 A 啓動了一個電子審批流程。這個流程首先會被傳遞到主管進行審批。在審批過程中，主管會仔細檢查初始業務流程信息和其他相關數據，然後決定是否進一步推進流程，或退回給 A 進行修訂。如果主管批准了這個流程，那麼它將被移交給下一級審批人，也就是經理。在經理的審批環節，他/她也會詳查相關數據和信息，並基於這些以及自己的獨立判斷來做出決策。值得注意的是，儘管經理可以查看到主管填寫的一些技術信息，但這些信息並不對財務和法務公開。也就是説，只有經理和總經理可以看到這些技術信息，財務和法務無法獲知。經理會根據這些保密信息以及自己的專業判斷來決定是否繼續推進流程。</p><p>如果經理也批准了該流程，那麼它將被送至財務節點進行審批。在審批過程中，財務主要關注經濟相關的問題，例如價格、付款方式等等。一旦財務審批通過，流程會被移交給法務進行審批。</p><p>與財務審批類似，法務審批主要關注法律風險和合規性問題。在審批時，法務會仔細檢查相關的合同、協議等法律文件，並評估是否存在任何法律風險或合規性問題。一旦法務批准了流程，流程將被移交給總經理進行最後的審批，以完成整個審批流程。 <img src="https://oscimg.oschina.net/oscnet/up-9fc0999e0fce89328d824f66ddf847869ac.png" alt="" referrerpolicy="no-referrer"> 需要注意的是，這種審批流業務場景並不是隻有一個，而是有很多個。例如，除了上述的採購流程，還有其他業務流程需要進行審批，比如：數據入庫流程、報價流程等等。每個流程都有自己的特點和審批節點數量不一。有些流程可能只需要兩三個節點就可以完成審批，有些則可能需要十幾個節點才能完成。但是，所有類型的審批流大致相似。如：頁面上常見的元素包括表單、表格以及常用的審批組件等。</p><p><strong>技術分析：</strong> 若採用傳統的開發方式，每當新增一種流程時，前端開發人員都需要開發所有審批節點的審批頁面，並重新進行發佈流程。同樣地，服務端開發人員也需要重新建立一個審批流，通過特定頁面錄入各節點審批人，並編寫相應的審批流規則。顯然，這對於前端和服務端開發人員來説都是十分繁瑣的工作。</p><p><strong>解決方案：</strong> &nbsp;基於 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 低代碼引擎，開發出一個專為電子審批流設計的低代碼平台。然後，將所有與流程相關的組件，如模板、評審記錄和流程指引等導入到平台的物料區域。最後，將這個專注於開發審批流的低代碼平台集成到 PDM 元數據電子流業務模塊中。在低代碼平台上，想要開發任意一個流程的審批頁面，只需要將流程模板拖入，並在模板中嵌入本流程的表單或表格，即可輕鬆完成該節點的審批頁面，極大地提高了開發效率和便利性！ 服務端也將採用另一種特定於 flow 類型的低代碼平台（將在後續內容中詳細介紹），以實現對審批流程人員編排。這樣，前後端之間的連接就實現了完美的貫通。</p><p><img src="https://oscimg.oschina.net/oscnet/up-a11ab19ac7c4e4cc0c06599cea2390308c9.png" alt="" referrerpolicy="no-referrer"></p><ul><li><h3>Flow 圖元編排類型設計器</h3></li></ul><p>圖形編排在眾多場景中扮演着重要角色，例如流程圖、審批流、部署流水線和架構圖等。資源編排只是編排的主體變成了雲服務資源。</p><p>資源編排遵循基礎設施即代碼（Infrastructure as Code, IaC）的設計理念，資源編排與以往單獨管理每種雲服務資源的方式有所不同。通過資源編排設計器，用戶無需手動創建多個資源，只需在平台上使用設計器進行拖拽和配置，即可生成模板，並一鍵部署多個資源。這樣，用戶可以更加高效地管理和編排雲服務資源，提高資源的利用率和部署速度。</p><p>因此，針對資源編排服務場景，我們需要定製一個專用的低代碼平台來滿足用戶的需求。該平台將具備圖形化界面，允許用戶通過簡單的拖拽和配置來創建、修改和刪除資源編排模板，而無需編寫大量的代碼。此外，該平台還將支持一鍵部署功能，以快速部署多個資源，提高資源編排的效率和速度。</p><p>考慮到需要支持大量的雲服務資源，且每個雲服務資源需要配置的屬性各不相同，因此採用傳統開發方式為每種雲服務資源開發專門的屬性設置頁面是不可行的。因此，我們需要一個能夠自定義渲染的屬性配置方案。通過自定義渲染，用戶可以根據不同的雲服務資源類型和屬性，自由地定義和控制屬性頁面的交互效果，從而提高屬性配置的靈活性和可擴展性。</p><p>同時模板是極為重要的一環，它直接關係到最終資源的部署。因此，模板需要符合特定的標準格式，這就要求畫布和屬性面板的輸入必須能夠準確反映到最終的模板中。</p><p>整理出主要的述求：</p><ul><li>整個頁面應至少包含以下幾部分：資源列表、畫布和屬性設置面板</li><li>畫布應具備核心的拖拽和連線繪圖功能，以支持用戶直觀地進行資源編排</li><li>屬性設置面板需要支持自定義配置渲染，以滿足不同雲服務資源類型和屬性的配置需求</li><li>該平台應具備可拓展性，以支持開發出其他能力，滿足未來可能出現的新的編排需求</li></ul><p>在分析了上述需求後，我們可以清楚地看到，使用傳統開發方式將面臨巨大的工作量和現實的實現困難。同時，經過對比發現，資源編排設計器和低代碼設計器之間有許多相似之處，例如它們都涉及基礎資源、拖拽操作和配置功能，只是在畫布區域存在差異。</p><p><strong>解決方案：</strong> TinyEngine 作為一個出色的低代碼引擎，通過優秀的整體架構提供了高度自由的定製能力。它允許我們像搭積木一樣選擇不同的積木來搭建一個專屬的設計器。同時，屬性面板全部通過 JSON 配置文件進行渲染，無需編寫任何代碼，靈活而強大。這種開發方式可以大大降低開發成本，提高效率。 該設計器的佈局類似於 VS Code，核心模板與功能區域劃分清晰明瞭，易於上手。插件化的架構也使得自由拓展業務相關功能變得輕而易舉。 綜上所述，我們最終決定使用 TinyEngine 來開發圖元編排設計器，以滿足資源編排的需求。</p><p><img src="https://oscimg.oschina.net/oscnet/up-83884bfe0dc60af97c83a8fcd38fb3980d5.png" alt="" referrerpolicy="no-referrer"></p><ul><li><h3>其他業務類型的低碼平台訴求</h3></li></ul><p>1，跨境電商的低代碼平台，旨在方便商家快速裝修店鋪。商家只需要從平台提供的模板中選擇一套適合自己的商品模板，並進行文字和圖片的修改，即可快速建立自己的電商網站。此外，該平台還需要具備方便搜索引擎優化（SEO）的功能，讓商家的電商網站更容易被潛在客戶發現。</p><p>2，隨着移動互聯網的迅速普及，各種應用程序推送消息的需求日益增長。在這個背景下，APP 廠商只需要使用推送消息平台提供的模板，並簡單配置一下推送內容和樣式，即可輕鬆實現消息推送。</p><p>3，運維管理平台是針對企業運營過程中涉及的各種數據和頁面進行管理的工具。隨着企業運營數據的不斷增加，頁面變得越來越複雜。其實不同的崗位對於關心的信息也不盡相同。低代碼平台的應用可以讓不同崗位的員工通過簡單的拖拽操作，輕鬆獲取自己需要的數據和信息。這種方式不僅可以提高工作效率，而且還可以降低操作難度，使得更多人可以輕鬆上手使用。</p><h2>未來展望</h2><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank">TinyEngine</a> 專注於為用戶提供低代碼的基礎能力，目前正致力於跟生成式 AI 相結合，與用戶共同打造面向未來的應用。</p><h2><strong>其他説明</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-82d36f2d7d034985e744c65d9c21470bba8.png" alt="" referrerpolicy="no-referrer"></p><p>OpenTiny&nbsp;是一套企業級 Web 應用構建解決方案，提供跨端、跨框架的 UI 組件庫，適配 PC 端 / 移動端等多端，支持&nbsp;Vue2 / Vue3 / Angular&nbsp;多技術棧，擁有集成人工智能的低代碼引擎，包含主題配置系統 / 中後台模板 / CLI&nbsp;命令行等豐富的效率提升工具，可幫助開發者高效開發 Web 應用。</p><p><strong>核心亮點：</strong></p><ul><li>跨端跨框架：&nbsp;使用 Renderless 無渲染組件設計架構，實現了一套代碼同時支持 Vue2 / Vue3，PC / Mobile 端，並支持函數級別的邏輯定製和全模板替換，靈活性好、二次開發能力強</li><li>組件豐富：PC 端有 100+組件，移動端有 30+組件，包含高頻組件 Table、Tree、Select 等，內置虛擬滾動，保證大數據場景下的流暢體驗，除了業界常見組件之外，我們還提供了一些獨有的特色組件，如：Split 面板分割器、IpAddress IP 地址輸入框、Calendar 日曆、Crop 圖片裁切等</li><li>集成人工智能：低代碼引擎提供低代碼底層的能力，集成人工智能，讓 AI 助力用戶高效開發，適用於多場景的低代碼平台開發。如：資源編排、服務端渲染、模型驅動、移動端、大屏端、頁面編排等低代碼平台</li><li>配置式組件：&nbsp;組件支持模板式和配置式兩種使用方式，適合低代碼平台，目前團隊已經將 OpenTiny 集成到內部的低代碼平台，針對低碼平台做了大量優化</li><li>周邊生態齊全：&nbsp;提供了基於 Angular + TypeScript 的 TinyNG 組件庫，提供包含 10+ 實用功能、20+ 典型頁面的 TinyPro 中後台模板，提供覆蓋前端開發全流程的 TinyCLI 工程化工具，提供強大的在線主題配置平台 TinyTheme</li></ul><hr><p>歡迎加入 OpenTiny 開源社區。添加微信小助手：opentiny-official 一起參與交流前端技術～</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fopentiny.design%252F" title="https://link.juejin.cn/?target=https%3A%2F%2Fopentiny.design%2F" target="_blank">OpenTiny 官網</a>&nbsp;：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fopentiny.design%252F" title="https://link.juejin.cn/?target=https%3A%2F%2Fopentiny.design%2F" target="_blank">opentiny.design/</a></strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fgithub.com%252Fopentiny%252F" title="https://github.com/opentiny/" target="_blank">OpenTiny 代碼倉庫</a>：<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttps%253A%252F%252Fgithub.com%252Fopentiny%252F" title="https://github.com/opentiny/" target="_blank">github.com/opentiny/</a></strong></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fopentiny.design%252Ftiny-vue" title="https://link.juejin.cn/?target=https%3A%2F%2Fopentiny.design%2Ftiny-vue" target="_blank">Vue 組件庫</a>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fopentiny.design%252Ftiny-vue" title="https://link.juejin.cn/?target=https%3A%2F%2Fopentiny.design%2Ftiny-vue" target="_blank">opentiny.design/tiny-vue</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fopentiny.design%252Ftiny-ng" title="https://link.juejin.cn/?target=https%3A%2F%2Fopentiny.design%2Ftiny-ng" target="_blank">Angular 組件庫</a>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fopentiny.design%252Ftiny-ng" title="https://link.juejin.cn/?target=https%3A%2F%2Fopentiny.design%2Ftiny-ng" target="_blank">opentiny.design/tiny-ng</a></p><p>歡迎進入代碼倉庫 Star🌟TinyVue、TinyNG、TinyCLI~</p><p>如果你也想要共建，可以進入代碼倉庫，找到&nbsp;<code>good first issue</code>標籤，一起參與開源貢獻~</p><p><strong>往期文章推薦</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-e8bd5f9b0f2dedea3b5fcd23ab93a80c124.png" alt="" referrerpolicy="no-referrer"></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttp%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzU5ODA3OTY5Ng%253D%253D%2526mid%253D2247491605%2526idx%253D1%2526sn%253Db85064d6b81a2a673bc9e1eeea82a1dd%2526chksm%253Dfe4b01aac93c88bc1de779f6e558da7cdd181cec49a1fbdac804b54bab19729cbc45ddf3f104%2526scene%253D21%2523wechat_redirect" title="http://mp.weixin.qq.com/s?__biz=MzU5ODA3OTY5Ng==&amp;mid=2247491605&amp;idx=1&amp;sn=b85064d6b81a2a673bc9e1eeea82a1dd&amp;chksm=fe4b01aac93c88bc1de779f6e558da7cdd181cec49a1fbdac804b54bab19729cbc45ddf3f104&amp;scene=21#wechat_redirect" target="_blank">必不可少的 UI 組件一——組件的基礎知識</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttp%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzU5ODA3OTY5Ng%253D%253D%2526mid%253D2247491250%2526idx%253D1%2526sn%253D66b6840f3f93d415a33b9ade09dcd9b8%2526chksm%253Dfe48ff0dc93f761ba3965380b759b184616d9dc39a903f1bda689037ba0b177c98fb0bae7c38%2526scene%253D21%2523wechat_redirect" title="http://mp.weixin.qq.com/s?__biz=MzU5ODA3OTY5Ng==&amp;mid=2247491250&amp;idx=1&amp;sn=66b6840f3f93d415a33b9ade09dcd9b8&amp;chksm=fe48ff0dc93f761ba3965380b759b184616d9dc39a903f1bda689037ba0b177c98fb0bae7c38&amp;scene=21#wechat_redirect" target="_blank">OpenTiny Vue 3.10.0 版本發佈：組件 Demo 支持 Composition 寫法，新增 4 個新組件</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttp%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzU5ODA3OTY5Ng%253D%253D%2526mid%253D2247490886%2526idx%253D1%2526sn%253D3c0fcbe86c01b01e0ed876904743ca76%2526chksm%253Dfe48fcf9c93f75ef621391689021922451ae5621c75f0c5c3024352d9df8d0f18139095865f9%2526scene%253D21%2523wechat_redirect" title="http://mp.weixin.qq.com/s?__biz=MzU5ODA3OTY5Ng==&amp;mid=2247490886&amp;idx=1&amp;sn=3c0fcbe86c01b01e0ed876904743ca76&amp;chksm=fe48fcf9c93f75ef621391689021922451ae5621c75f0c5c3024352d9df8d0f18139095865f9&amp;scene=21#wechat_redirect" target="_blank">前端 Vuer，請收好這份《Vue 組件單元測試》寶典</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttp%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzU5ODA3OTY5Ng%253D%253D%2526mid%253D2247490622%2526idx%253D1%2526sn%253Df928726a3608ebf0999529187dc2a22c%2526chksm%253Dfe48fd81c93f7497608ed97ea0d60d12b61d03c062ebda49c84a9c4e3cdb0550e25930df9aa1%2526scene%253D21%2523wechat_redirect" title="http://mp.weixin.qq.com/s?__biz=MzU5ODA3OTY5Ng==&amp;mid=2247490622&amp;idx=1&amp;sn=f928726a3608ebf0999529187dc2a22c&amp;chksm=fe48fd81c93f7497608ed97ea0d60d12b61d03c062ebda49c84a9c4e3cdb0550e25930df9aa1&amp;scene=21#wechat_redirect" target="_blank">OpenTiny 前端組件庫正式開源啦！面向未來，為開發者而生</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttp%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzU5ODA3OTY5Ng%253D%253D%2526mid%253D2247490528%2526idx%253D1%2526sn%253D911d84e6bb275e6125464f07643c1150%2526chksm%253Dfe48fa5fc93f734911c4f44a5f4e2d6c4e29e00ad68cae35c4edc3771de1cbf65cd5f2a8a224%2526scene%253D21%2523wechat_redirect" title="http://mp.weixin.qq.com/s?__biz=MzU5ODA3OTY5Ng==&amp;mid=2247490528&amp;idx=1&amp;sn=911d84e6bb275e6125464f07643c1150&amp;chksm=fe48fa5fc93f734911c4f44a5f4e2d6c4e29e00ad68cae35c4edc3771de1cbf65cd5f2a8a224&amp;scene=21#wechat_redirect" target="_blank">從自研走向開源的 TinyVue 組件庫</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.cn%3Ftarget%3Dhttp%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzI2MDE3MTM4MA%253D%253D%2526mid%253D2701520396%2526idx%253D1%2526sn%253Dbd42224d212cb4b78ffcbca98f463db8%2526chksm%253Dce9cfd17f9eb7401d41b21639f80b09846a1c44b237c6733b809aeb2259c3d2521c88c490e7a%2526scene%253D21%2523wechat_redirect" title="http://mp.weixin.qq.com/s?__biz=MzI2MDE3MTM4MA==&amp;mid=2701520396&amp;idx=1&amp;sn=bd42224d212cb4b78ffcbca98f463db8&amp;chksm=ce9cfd17f9eb7401d41b21639f80b09846a1c44b237c6733b809aeb2259c3d2521c88c490e7a&amp;scene=21#wechat_redirect" target="_blank">我要做開源，提交我的第一個 PR</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 10:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6769809/blog/10112556</guid>
            <link>https://my.oschina.net/u/6769809/blog/10112556</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenTiny 低代碼開發引擎子項目 TinyEngine 正式發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>2023 年 9 月 21 日，華為全聯接大會 2023 「開源創新，共築智能世界」論壇在上海前灘香格里拉酒店圓滿落幕。在此次開源分論壇上，華為雲開源業務總經理鄧明昆進行了題為《開源協同創新，加速雲計算應用》的分享。</p><p><img alt="" height="333" src="https://oscimg.oschina.net/oscnet/up-117a8ef69eb67291660e465882856e89581.webp" width="500" referrerpolicy="no-referrer"></p><p><em>華為雲開源業務總經理，鄧明昆</em></p><p>鄧明昆在分論壇演講中提到：雲原生技術以「分佈式、松耦合、高韌性」等特徵在企業基礎架構升級及應用開發上展現出巨大的價值，越來越多企業開始基於雲原生構建面向未來的創新服務。華為雲深耕雲原生，堅持開放共享，協同推動雲原生技術創新與生態發展，共創新價值，釋放數字生產力。 截止到目前，華為雲已經開源了多個開源項目，並吸引了社區廣大開發者的深度參與和支持。</p><p><strong>1.聚焦分佈式雲原生技術設施與雲原生應用技術棧開源</strong></p><p>Kurator 整合多雲、多集羣統一編排、統一調度、統一流量治理，統一監控運維、邊雲協同等核心能力，助力廣大開發者快速搭建分佈式雲原生平台，實現跨雲跨邊的一致性分佈式雲原生應用體驗。</p><p>與此同時，華為雲還將雲原生技術棧開源，幫助開發者快速構建雲原生應用。通過雲原生應用技術棧，開發者可以專注業務實現，應用一跳入雲，實現業務敏捷、高效創新。</p><p><img alt="" height="333" src="https://oscimg.oschina.net/oscnet/up-2509296725ce8927bcbc81f4e5c44bb5cfc.webp" width="500" referrerpolicy="no-referrer"></p><p><strong>2.Volcano 特性升級，新能力釋放大模型計算潛力</strong></p><p>大模型時代，以 GPU 為核心的算力供給已成為大模型產業發展的關鍵基礎設施，用戶對於 GPU 資源的使用存在資源利用率低、資源分配不靈活等痛點問題，必須採購大量冗餘的異構算力才能滿足業務需求，異構算力成本高昂，為企業的發展帶來很大的負擔。</p><p>基於此現狀，鄧明昆在演講中向大家介紹了 Volcano 的兩個重點特性：<strong> GPU 調度與隔離以及 JobFlow 工作流編排引擎支持。</strong></p><ul><li>通過 GPU 資源多任務共享，GPU 資源按比例分配等技術來大幅提升算力資源的利用率，降低算力成本。</li><li>通過支持 JobFlow 輕量任務流編排引擎，幫助開發者簡化多個任務並行與依賴關係的管理，大幅度提升整體計算效率。</li></ul><p><strong>3. OpenTiny 低代碼開發引擎子項目 TinyEngine 正式發佈，AI 輔助加速應用創新</strong></p><p>OpenTiny 作為開源的跨端、跨框架、跨版本企業級前端組件方案，可以幫助開發者快速構建極致體驗的雲原生應用。在本次大會中，鄧明昆正式對外發布了低代碼開發引擎子項目 TinyEngine。</p><p>TinyEngine 低碼引擎通過接入華為雲盤古大模型等各類大模型的強大能力，使得開發者通過文本交互或者語音對話就可以完成 WEB 應用的開發，應用技術門檻大幅降低，開發效率大幅提升，實現企業應用的高效敏捷、極致體驗。</p><p>鄧明昆強調：</p><p>「華為雲堅持深耕雲原生，堅持開源開放，我們希望通過開源、開放，能夠快速凝聚企業、開源組織、學術機構、以及廣大開發者一起推動雲原生技術共享，以及雲原生產業的標準化，真正實現雲原生產業創新與生態發展，共創新價值，釋放數字生產力！」</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 10:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/259135</guid>
            <link>https://www.oschina.net/news/259135</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CentOS Integration SIG 成立]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">CentOS 董事會已<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.centos.org%2F2023%2F09%2Fcentos-board-meeting-recap-september-2023%2F" target="_blank">批准</a>成立 CentOS Integration Special Interest Group (SIG)。該小組旨在幫助那些在 Red Hat Enterprise Linux (RHEL) 或特別是其上游 CentOS Stream 上構建產品和服務的人員，驗證其能否在未來版本中繼續運行。</span></p><p><span style="color:#000000">紅帽 RHEL CI 工程師 Aleksandra Fedorova 在相關</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.centos.org%2Fpipermail%2Fcentos-devel%2F2023-August%2F143077.html" target="_blank">提案</a><span style="color:#000000">中提出：</span></p><blockquote><p style="text-align:start"><span style="color:#000000"><span><span><span><span><span><span><span><span><span><span><span><span>我想提議成立一個新的特別興趣小組，專注於圍繞 CentOS Stream 的集成工作。</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span style="color:#000000">集成就是驗證構建在 RHEL 或 CentOS Stream 基礎上的產品和服務能否在 CentOS Stream 和下一個 RHEL 版本上繼續運行，並且不會因軟件包更新而中斷。</span></p><p><span style="color:#000000">由於 RHEL 內容只有在發佈後才可用，因此&nbsp;</span>RHEL-based<span>&nbsp;</span><span style="color:#000000">服務傳統上使用的是 catching-up 集成模式：人們必須在更新發布後調整其產品和服務，以便在新的 RHEL 上運行。調整服務需要時間，會佔用受支持的 RHEL 生命週期。這也減少了我們處理破壞性變更的選擇。</span></p><p><span style="color:#000000">CentOS Stream 提供了一種實現前瞻性集成的方法：你可以在開發過程中，在變更發佈到 CentOS Stream 或 RHEL 軟件源之前，儘早進行集成。這樣，我們就可以防止或至少為任何可能通過 CentOS Stream 或 RHEL 更新發布的破壞性變更做好準備。</span></p></blockquote><p><span style="color:#000000">此&nbsp;SIG 的目的在於，在 CentOS Stream 更新發布到 CentOS 鏡像之前，提供一個共享空間來開發和維護有關協作控制和測試 CentOS Stream 更新的工具和知識庫。包括 package-level&nbsp;和 compose-level 集成。</span></p><p><span style="color:#000000">SIG 計劃將記錄其他 SIG 使用的現有集成工作流程；確定常見問題；管理、開發和推廣 CentOS Stream 的第三方 CI；以及開發集成工具包。</span></p><p><span style="color:#000000">在 SIG 獲得董事會批准之後，Aleksandra Fedorova 還發帖<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscussion.fedoraproject.org%2Ft%2Fcentos-integration-sig-everyone-is-welcome%2F90378" target="_blank">表示</a>，該小組正在建立工具和溝通渠道，歡迎大家加入並探討合作方式。</span></p><p><img height="315" src="https://oscimg.oschina.net/oscnet/up-3e6928d626dc3ff9422b7d4ff53f37fa148.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 09:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/259120/centos-integration-sig</guid>
            <link>https://www.oschina.net/news/259120/centos-integration-sig</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 開源華容道（滑塊拼圖）遊戲]]>
            </title>
            <description>
                <![CDATA[<pre class="clean txt-style">這是一款 linux 平台下的滑塊拼圖遊戲. 詳細文檔參見 doc/slide.pdf.
遊戲按前後台模式設計. 後台負責遊戲規則實現和流程控制, 前台負責與用戶交互. 
前端開發者可以基於軟件包內的遊戲引擎部分開發不同的用戶界面.

軟件包內包含 3 個部分:

1) 遊戲引擎
2) ncurses 的前端
3) gtk3 的前端

編譯運行方法為:

1) 遊戲引擎 (無法直接運行)
make

2) 基於 ncurses 的前端
make sp_cs
./sp_cs

3) 基於 gtk3 的前端
make sp_gtk
./sp_gtk

依賴:

ncurses
gtk3
pkg-config</pre>
]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 07:19:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/tfcolin/slide</guid>
            <link>https://gitee.com/tfcolin/slide</link>
        </item>
        <item>
            <title>
                <![CDATA[PHP、.NET 和 Java 到底誰遙遙領先，看評論區見高低！]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/2720166_2331057">PHP、.NET 和 Java 到底誰遙遙領先，看評論區見高低！</a><div class="ui red label horizontal" data-tooltip="置頂">頂</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/hardbone" class="__user"><span>局</span></a> 發佈於，昨天 12:32
                    </div><div class="item">閲讀 3K+</div><div class="item collect-btn " data-id="2331057" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags="PHP"><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331057" data-obj-type="2">3</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/2720166_2331057#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">12</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/tag/php" target="_blank"><img src="https://static.oschina.net/uploads/logo/php_C12WY.png" referrerpolicy="no-referrer">PHP</a></div><div class="content" id="articleContent"><p class="ad-wrap"><a data-traceid="question_detail_above_text_link_ad" data-tracepid="question_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" target="_blank">數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？&gt;&gt;&gt; <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></p><p>上週末將《<a href="https://www.oschina.net/news/257647/an-internet-of-php" target="_blank" rel="nofollow">PHP 最新統計數據：市場份額超 7 成、CMS 中的王者</a>》這篇新聞掛到了置頂位，並且修改了標題——《PHP 遙遙領先》。</p><p><img src="https://static.oschina.net/uploads/space/2023/0922/121304_DUFP_2720166.png" referrerpolicy="no-referrer"></p><p>「編程語言一哥」PHP 不負眾望，水友們的評論馬上幹到了上百條。春哥<a href="https://my.oschina.net/easysoft" target="_blank" rel="nofollow"></a><a href="https://my.oschina.net/easysoft" target="_blank" rel="nofollow">@開源春哥</a> 甚至讓我長期置頂這篇新聞：</p><blockquote><p><img height="464" src="https://static.oschina.net/uploads/space/2023/0922/120758_eC7B_2720166.png" width="1747" referrerpolicy="no-referrer"></p></blockquote><p>剛好 Java 前天也發佈了重大更新<strong>&nbsp;<a href="https://www.oschina.net/news/258730/jdk-21-lts-ga" target="_blank" rel="nofollow">Java 21 LTS</a></strong>，上週&nbsp;<strong>.NET 8&nbsp;也發佈了<a href="https://www.oschina.net/news/258091/performance-improvements-in-dot-net-8" target="_blank" rel="nofollow">首個 RC</a></strong>。</p><p>下面就來看看三大編程語言金剛的評論區表現。</p><p><img height="368" src="https://oscimg.oschina.net/oscnet/up-56c5275191fd70caf6787c4a196ed4b4eee.png" width="1298" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-2229a1117aad67bb82de3971896f8a2c3ab.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-5f055ef0241f6ea1c078a62eee16e4f84fd.png" referrerpolicy="no-referrer"></p><p>看到這，一眼高下立辨了吧？</p><p>不服？繼續看各自的精彩評論：</p><ul><li><strong>.NET</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-376d055216fd9aa85439f8eb344a71c3d06.png" referrerpolicy="no-referrer"></p><ul><li><strong>Java</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-1c44bba64b7ddae051509774c0982fb8ad8.png" referrerpolicy="no-referrer"></p><ul><li><strong>PHP</strong></li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-52b51e937e44bdbbd46d14a2716a1c39cf6.png" referrerpolicy="no-referrer"></p><p>好了，不多説了。Sir，this way——</p><ul><li><a href="https://www.oschina.net/comment/news/258091" target="_blank" rel="nofollow">.NET 8 性能大幅提升，比 .NET 7 遙遙領先</a></li><li><a href="https://www.oschina.net/comment/news/258730" target="_blank" rel="nofollow">Java 21 / JDK 21 (LTS) GA</a></li><li><a href="https://www.oschina.net/comment/news/257647" target="_blank" rel="nofollow">PHP 最新統計數據：市場份額超 7 成、CMS 中的王者</a></li></ul></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331057" data-user-id="2720166" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags="PHP"><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331057" data-obj-type="2">3</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331057" data-obj-type="2" data-url="https://www.oschina.net/question/2720166_2331057"><i class="flag red icon"></i>舉報</a></div></div>
            ]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 04:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/2720166_2331057</guid>
            <link>https://www.oschina.net/question/2720166_2331057</link>
        </item>
        <item>
            <title>
                <![CDATA[Windows 版 AI Copilot 將於 9 月 26 日推出]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">微軟<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.microsoft.com%2Fblog%2F2023%2F09%2F21%2Fannouncing-microsoft-copilot-your-everyday-ai-companion%2F" target="_blank">宣佈</a>將發佈統一的人工智能助手 Copilot，稱之為「Microsoft Copilot」；可在 Windows 11、Microsoft 365 以及 Edge 和必應的網絡瀏覽器中使用。</span></p><p><span style="color:#000000"><img alt="" height="281" src="https://static.oschina.net/uploads/space/2023/0922/114210_h1cO_4252687.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">公告指出，Copilot 將作為 Windows 11 免費更新的一部分，從 9 月 26 日開始以早期形式推出；並將於今年秋季在必應、Edge 和 Microsoft 365 Copilot 上推出。</span></p><ul><li><span style="color:#000000">下一個 Windows 11 更新擁有 150 多項新功能。為 Windows PC 帶來強大的 Copilot 功能和全新的人工智能體驗，如畫圖、照片、剪貼板等應用程序。</span></li><li><span style="color:#000000">必應將增加對 OpenAI 最新 <a href="https://www.oschina.net/news/259053/openai-dall-e-3">DALL.E 3</a> 模型的支持，並根據用戶的搜索歷史提供更加個性化的答案，還將提供全新的人工智能購物體驗，以及更新必應聊天企業版，使其更具移動性和可視化。DALL.E 3&nbsp;是 OpenAI 剛推出的最新圖像生成 AI 模型，該模型本身已升級包括生成嵌入圖像中的文本的能力，並且能夠更好地理解用戶對圖像中對象之間關係的自然語言描述。</span></li><li><span style="color:#000000">Microsoft 365 Copilot 將於 2023 年 11 月 1 日與 Microsoft 365 Chat (曾用名 Business Chat) 一起面向企業客戶全面推出。Microsoft 365 Chat 是一款全新的人工智能助手，可以梳理你工作中的所有數據，包括電子郵件、會議、聊天、文檔等，還有網絡。</span></li></ul><p><span style="color:#000000">Windows 中的 Copilot 集成提供的新功能之一是"Sound Like Me"，即 Copilot AI 可以掃描和分析你的寫作風格，並在 Microsoft Outlook 中為你撰寫電子郵件。微軟方面還演示了新的 Windows 版 Copilot，類似於其當前的開放式人工智能 Bing Chat 應用界面，右側欄允許用戶與 Copilot 對話，並選擇不同的選項。</span></p><p><span style="color:#000000">Microsoft 365 總經理 Colette Stallbaumer 在活動中<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fventurebeat.com%2Fai%2Fmicrosoft-announces-ai-copilot-for-windows-coming-september-26th%2F" target="_blank">發言</a>稱，計劃於 11 月 1 日推出的新 Microsoft 365 Copilot 可以跨多個網絡源實時執行自己的市場研究，為員工提供準確的最新信息。「你很快就會無法想象沒有它的生活。」</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.microsoft.com%2Fblog%2F2023%2F09%2F21%2Fannouncing-microsoft-copilot-your-everyday-ai-companion%2F" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 03:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/259065/microsoft-copilot-windows</guid>
            <link>https://www.oschina.net/news/259065/microsoft-copilot-windows</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[思科 280 億美元收購 Splunk]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>思科公司今日宣佈，將以每股 157 美元的現金收購網絡安全軟件公司 Splunk，交易總金額約為 280 億美元。</p><p>收購交易完成後，Splunk 總裁兼 CEO Gary Steele 將加入思科的高級領導團隊，向思科董事長兼 CEO 查克・羅賓斯 (Chuck Robbins) 彙報工作。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bfa94442f47d5f037a2aa360a512186ccfd.png" referrerpolicy="no-referrer"></p><p>Splunk 創建於 2003 年，總部位於舊金山，是一家網絡安全公司，<strong>幫助企業監控和分析其數據，以最大限度地減少黑客攻擊的風險，並更快地解決一些技術問題。</strong></p><p>羅賓斯對此表示：「我們很高興能讓思科和 Splunk 走到一起。兩家公司合併後，將有能力推動下一代以人工智能（AI）為基礎的安全和監控。從威脅檢測和響應，到威脅預測和預防，我們將幫助各種規模的組織更安全、更具彈性。」</p><p>Splunk 總裁兼 CEO Gary Steele 稱：「與思科的合併代表着 Splunk 下一階段的成長之旅，這將加快我們的使命，幫助世界各地的組織變得更具彈性，同時為股東提供更多價值。」</p><p>思科表示，在這筆交易完成後的第一個財年，預計將推動公司實現正現金流和毛利率增長，並在第二年實現每股收益增長（基於非美國通用會計準則）。此外，它還將加快思科的營收和毛利率增長。</p><p>這筆交易不會影響思科之前宣佈的股票回購計劃和分紅計劃。目前，該交易已獲得思科和 Splunk 董事會的一致批准，預計將在 2024 年第三季度末完成。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 22 Sep 2023 03:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/259064/cisco-to-acquire-splunk</guid>
            <link>https://www.oschina.net/news/259064/cisco-to-acquire-splunk</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[網易國產開源分佈式存儲系統 —— Curve]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" target="_blank">數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p><strong>導讀：</strong>Curve 是一款高性能、易運維、雲原生的開源分佈式存儲系統 (CNCF Sandbox)。可應用於主流的雲原生基礎設施平台：對接 OpenStack 平台為雲主機提供高性能塊存儲服務；對接 Kubernetes 為其提供 RWO、RWX 等類型的持久化存儲卷；對接 PolarFS 作為雲原生數據庫的高性能存儲底座，完美支持雲原生數據庫的存算分離架構。</p><p>Curve 亦可作為雲存儲中間件使用 S3 兼容的對象存儲作為數據存儲引擎，為公有云用戶提供高性價比的共享文件存儲。本文將介紹 Curve 塊存儲相關的部分，並分享 Curve 在一些場景的應用。</p><p><strong>全文目錄：</strong></p><p>1.&nbsp;分佈式存儲介紹</p><p>2.&nbsp;Curve 架構及介紹</p><p>3.&nbsp;Curve 主要亮點</p><p>4.&nbsp;Curve RoadMap</p><p>5. 問答環節‍‍‍</p><hr><p style="text-align:center"><strong>01&nbsp;<strong style="font-weight:bold">分佈式存儲介紹</strong></strong></p><p><strong>1.分佈式存儲的分類</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-60548d0cd6163131fdc564e3830aa9d46cd.png" referrerpolicy="no-referrer"></p><p>首先簡單介紹一下分佈式存儲的分類。分佈式存儲可以分為三類：對象存儲、文件存儲和塊存儲。對象存儲在互聯網中應用的比較多，比如一個對象、一個圖片、一個音頻，這種可以通過 PUT GET 接口來進行存儲。文件存儲與傳統意義的文件系統的區別是，它是分佈式的，傳統的項目對應的是 Ext4，或者是 NTFS。塊存儲，就是所謂的雲盤。</p><p><strong>2. 分佈式存儲的要素</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-8f2e360879b2e122e40443a076540d994af.png" referrerpolicy="no-referrer"></p><p>下面介紹一下分佈式存儲在設計時的一些要素。首先，需要大容量的硬盤空間，並且可以隨機寫，還有最重要的是要保證服務的質量，數據不能丟失，還要保證它的可用性。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-f0e776540bc3e8b157a37ec8e92912f3a6b.png" referrerpolicy="no-referrer"></p><p><strong>要素可以拆解為以下三方面：</strong></p><p>①第一是高性能。在分佈存儲裏面，存儲節點會非常多，所以要知道數據存在什麼位置以及如何去取。</p><p>②第二是可用性。要保證數據的可靠性，避免數據丟失，並且保證在機器故障時數據的讀寫是能夠正常運行的。</p><p>③第三是可擴展性。如果容量用完了，可以新增機器擴展容量。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-5c8457c22a6744081c1412e447bd2493faa.png" referrerpolicy="no-referrer"></p><p>數據分佈，主要有兩種，一個是無中心節點，另一個是有中心節點。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-3d4c661ba73529efb2a5f0451c2eeae8f64.png" referrerpolicy="no-referrer"></p><p>另外一個比較重要的點是一致性協議。首先是 Ceph 的強一致性。在分佈式系統中，一致性是指在多個副本之間保持數據一致。在 RADOS 中，數據被分割成多個對象，每個對象都有多個副本，這些副本分佈在集羣的不同節點上。當一個對象被修改時，Ceph 會確保所有的副本都被同時更新，從而保證了強一致性。第二是 Raft 算法，他只需要大多數副本保證更新完成就可以認為成功了。</p><p style="text-align:center"><strong>02‍&nbsp;Curve 架構及介紹</strong></p><p><strong>1. 項目介紹</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-1b5a84574cb14756bf00e118f72a8e9e0c8.png" referrerpolicy="no-referrer"></p><p>關於 Curve，我們的願景是希望打造一款性能比較好，適用多種場景的，並且是圍繞開源的雲原生分佈式存儲系統。目前，Curve 已經捐贈給 CNCF 基金會，併成為其生態系統中的一個項目。Curve 提供塊存儲和文件存儲兩種方式，以滿足不同應用的需求。</p><p>對於 Curve 塊存儲，它具有快照克隆恢復功能，主要應用場景包括 OpenStack 雲主機和 Kubernetes 持久存儲卷。對於共享需求，Curve 提供文件存儲；對於性能要求較高且無共享需求的場景，建議使用 Curve 塊存儲。</p><p>Curve 還與阿里巴巴的 PolarDB 進行了聯合，作為其底層存儲運行。此外，Curve 也在 AI 訓練領域得到了廣泛應用。Curve 在過去幾年中通過了信創認證，並獲得了工信部組織的中國開源創新大賽二等獎。</p><p><strong>2. Curve 的架構介紹</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-6d3f00e6d8e462f9218aec534b1ec6eeee9.png" referrerpolicy="no-referrer"></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-fa6327e3f5acc103590004280e9c74fd8f9.png" referrerpolicy="no-referrer"></p><p>Curve 的整體架構是以硬盤為單位進行空間分配，每個硬盤被劃分為多個 segment，而每個 segment 又包含多個 chunk。引入 segment 的概念是為了減少原數據的量。類似於 Ceph 中的一個硬盤對應一個節點，Curve 中的一個硬盤對應一個服務組件，由一個磁盤進程進行管理。</p><p>Curve 採用了 Raft 協議作為其一致性協議的選擇。這是因為 Curve 項目的背景與我們在網易的實際業務需求有關。在網易的業務中，之前大部分業務使用的是 Ceph。然而，在使用 Ceph 過程中，一旦用戶更換硬盤或某個機器發生故障，會導致業務出現卡頓，這是業務方無法接受的。因此，這促使我們進行 Curve 的研發。基於這個背景，我們選擇了 Raft 協議。</p><p>選擇 Raft 協議的原因有兩個方面：一是 Raft 協議具有較高的可用性，相對於 Ceph 的強一致性模型，在集羣中出現一些問題時，可用性不會受到太大影響。另一個原因是 Raft 協議相對較容易理解。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-cd1ac097abb82dec9ef1e7ada229877b1e1.png" referrerpolicy="no-referrer"></p><p>在 Curve 的開發過程中，我們希望能夠快速迭代，並避免重複開發組件。為了實現這一目標，我們選擇了百度的 Braft 和 brpc 這兩個被廣泛認可為優秀的組件作為底層基礎。我們在這兩個組件的基礎上也進行了一系列的開發工作。</p><p style="text-align:center"><strong>03‍&nbsp;</strong><strong><strong><strong><strong><strong><strong>Curve 的主要亮點</strong></strong></strong></strong></strong></strong></p><p>Curve 的主要亮點是以下四個方面：</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-bc6e65700dc909c40311e218a9768746a67.png" referrerpolicy="no-referrer"></p><p>下面將逐一展開介紹。</p><p><strong>1. 高性能</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-e760595d7748b8f2b2f989156161c58b033.png" referrerpolicy="no-referrer"></p><p>Curve 在隨機讀寫方面表現優於 Ceph。然而，我們也要承認目前存在一個問題：在大塊順序讀寫方面，Curve 的性能差於於 Ceph。我們正在進行後續的優化工作，以改進這方面的性能表現。</p><p>在性能方面，我們的目標是支持雲原生數據庫，因為雲原生數據庫對性能要求較高。除了支持阿里巴巴的 PolarDB 數據庫，我們還支持網易內部的其他數據庫。我們致力於提供高性能的存儲解決方案，以滿足不同數據庫的需求。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-994eb01c84046176f0800e1ae5e041531dc.png" referrerpolicy="no-referrer"></p><p>在數據庫方面，我們引入了 SPDK（Storage Performance Development Kit）和 RDMA（Remote Direct Memory Access）技術。這兩種技術已經在 2023 年上半年上線。然而，在實施過程中，我們也面臨了一些問題和挑戰。以下是一些典型的例子：</p><ul><li><p>RDMA 對網絡質量要求較高。當用戶的網絡質量較差時，可能會出現丟包或擁塞現象，而這對性能的影響明顯高於 TCP。為瞭解決這個問題，我們實現了網絡鏈路的自動切換機制。當用戶的網絡質量較差時，系統會自動切換到 TCP 來應對這個問題。</p></li><li><p>在將 NVMe 綁定到 SPDK 後，它將沒有盤符。然而，缺少盤符會導致線上監控失效。對於一個存儲系統來説，缺乏監控是不可接受的。為瞭解決這個問題，我們利用 SPDK 提供的一系列腳本進行了內部適配，以確保監控的正常運行。這些問題和挑戰是我們在引入 SPDK 和 RDMA 技術時所面臨的，我們正在努力解決它們，以提供更穩定和可靠的存儲解決方案。</p></li><li><p>第三個挑戰是關於 Brpc 的 RDMA 支持。在當時，Brpc 的 RDMA 功能並不完善。因此，我們對 Brpc 的 RDMA 進行了支持。由於 RDMA 支持是一個較為常見的技術，我們對 Brpc 的 RDMA 進行了文檔介紹和代碼方面的比較。如果您對此感興趣，歡迎加入我們的微信羣進行學習和交流。</p></li><li><p>第四個挑戰是關於零拷貝技術。在引入 SPDK 後，我們希望引入零拷貝技術。然而，零拷貝技術在實施過程中有很多要求。因此，我們對這項技術進行了一些探索和研究。最終，我們成功實現了零拷貝技術，並且我們的技術和性能得到了顯著提升。</p></li></ul><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-65ade50ebc4c14c24941d3810e23d6e459d.png" referrerpolicy="no-referrer"></p><p>在混合存儲方面，我們利用了 bcache 來實現。為什麼要採用混合存儲呢？因為使用 NVMe 或者 SSD 可能會在性能和成本方面遇到一些瓶頸。因此，我們希望能夠利用 HDD 作為數據盤，類似於 Ceph 中的 HDD，而利用高性能存儲設備來提升低速磁盤的 IO 性能。為了實現這一目標，我們採用了 bcache 技術。</p><p>bcache 技術在我們的架構中起到了重要作用。在最初的設計中，我們使用了一個 NVMe 硬盤和幾塊數據盤。然而，如果 NVMe 硬盤發生故障，那麼整個數據盤的數據都會丟失。為瞭解決這個問題，我們採用了 raid 技術，以提供冗餘備份。此外，我們還對 bcache 進行了優化。在優化過程中，我們遇到了一些問題，例如發現 bcache 的 writeback 機制會失效，即使寫入的數據量未達到閾值。最終，我們發現這是一個 bug，並進行了修復。有關這個 bug 的詳細記錄可以在上面圖片的鏈接中找到。</p><p>在處理 bcache Gc 的影響方面，我們也進行了一些工作。例如，我們採取了分離的策略，將 WAL 單獨放置在 NVMe 設備中，而不放在 bcache Gc 的範圍內。通過這樣的方式，我們能夠減少 bcache Gc 對系統性能的影響。</p><p>第三個問題也是非常重要的，儘管在最初的測試中可能不容易發現，但我們花了相當長的時間來定位它。我們發現在測試集羣性能時，重複測試可能導致性能下降。最終的定位結果表明，這實際上是由於 NVMe 硬盤本身存在的問題。在持續寫入的情況下，NVMe 硬盤的性能可能會下降。這與硬盤的 SAD 和 OP 空間有關。通過適當設置 OP 空間，可以提升硬盤的性能。</p><p>此外，我們還瞭解到三星的企業級硬盤可能存在一些問題，例如固件支持方面。有關這方面的詳細記錄可以在下面圖片的參考鏈接中找到。如果您對此感興趣，歡迎參考相關文檔。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-0f3432603c41237ef6dc0e16b18b2046f3c.png" referrerpolicy="no-referrer"></p><p>在高性能方面，我們仍然有許多工作要做。正如之前提到的，我們的隨機讀寫性能要比 Ceph 好得多，但在順序讀寫方面則差於 Ceph。因此，我們將重點優化順序讀寫性能，這是我們後續工作的重點之一。</p><p>另一個重要工作是本地快照的支持。目前，我們的快照功能將快照上傳到 S3 存儲。然而，對於一些用戶來説，他們對數據的安全性要求更高，可能沒有使用 S3 存儲。因此，我們非常關注本地快照的支持，以滿足這些用戶的需求 (本地快照功能已經開發完成，預計 Q4 可 release)。</p><p>還有其它一些計劃，可以查看相關的 road map 以獲取更多信息。</p><p><strong>2. 易運維</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-e521a8cd71fec4d3f95abdc7ef5b4d8b943.png" referrerpolicy="no-referrer"></p><p>Curve 是一個易運維的存儲系統。即使對於不熟悉 Curve 的人來説，根據我們的文檔，只需要花費十幾分鐘的時間就能夠將 Curve 部署起來。除了部署易用性方面，我們還支持在 Kubernetes 雲原生環境中進行部署。我們提供了類似於 Operator 的解決方案，使得 Curve 的部署和運維更加簡單。目前，我們已經支持了基本的部署易用性，例如 Operator，但還有一些高級功能，如自動升級，尚未完全實現，我們將在後續繼續努力。</p><p><strong>3. 更穩定</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4477769b02032940a4736f7c927aefb98bc.png" referrerpolicy="no-referrer"></p><p>Curve 在穩定性方面具有顯著優勢。正如之前提到的，我們選擇開發 Curve 的原因之一就是為了提高系統的穩定性，這也是我們從 Ceph 中獲得的經驗。此外，熱升級也是 Curve 的一個亮點。關於熱升級的詳細信息，您可以在我們的文檔中找到相關介紹。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-ad257be5042ded1f38f1c744f47adbf71a5.png" referrerpolicy="no-referrer"></p><p>在 Curve 的開發過程中，我們對質量要求非常高。我們進行了單元測試、集成測試以及各種其他類型的測試，以確保系統的穩定性和可靠性。我們注重測試的全面性和多樣性，以確保 Curve 在各種異常場景下都能表現出色。</p><p><strong>4. 高質量</strong></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-1fceab38905487d84fc8b68135b0c4eb82a.png" referrerpolicy="no-referrer"></p><p>對於 Curve 項目，當開發者提交一個 PR 時，會自動觸發 CI 流程。CI 流程包括單元測試、集成測試和系統測試等多個測試環節。只有當 CI 流程通過並且測試通過後，PR 才會被合併入代碼庫。這樣的流程確保了代碼的質量和穩定性。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-d3c5f3188305357a77ff3ba6eff6e1f74e5.png" referrerpolicy="no-referrer"></p><p>在技術架構的先進性方面，簡要介紹兩個關鍵點。首先是中心化節點，它充當集羣的中心，可以感知集羣的負載容量和異常情況，並進行資源調度和數據均衡。其次是文件池的 chunkfilepool，它通過降低文件原數據的開銷來提高性能，同時也支持快照功能。目前，我們使用的是快照 S3，這使得用戶可以方便地與 S3 或其他對象存儲進行對接。</p><p style="text-align:center"><strong>04‍ RoadMap</strong></p><p>最後來分享一下後續的計劃。</p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-9eb888f377682035a38dcd90e23921c5ac3.png" referrerpolicy="no-referrer"></p><p>除了 CurveBS，我們還有 Curve FS 作為另一個重點方向。Curve BS 已經在網易進行了兩三年的大規模線上運行，數據非常穩定，目前主要是在進行支持一些高級特性方面的工作。而 Curve FS 在 2022 年 6 月份完成了第一個 release 版本並上線。截至目前，Curve FS 的開發時間只有大約一年左右，還有很多工作要做。特別是在 AI 時代，我們希望 Curve 能夠在支持 AI 方面做得更好，這也是我們的一個亮點。當然，除了支持 Ai，我們還在開發其他場景的支持，例如 ES 和傳統的接口，如 HDFS。</p><p style="text-align:center"><strong>05‍ 問答環節</strong></p><p><strong>Q：Curve 寫入代碼性能比 Ceph 低嗎？</strong></p><p>A：在性能方面，Curve 在隨機寫方面表現比 Ceph 要好很多，但在順序寫方面則差於 Ceph。這主要是因為 Ceph 在過去使用了雙寫的機制，導致日誌和數據都需要寫入兩次。為瞭解決這個問題，Ceph 後來採用了 BlueStore 引擎，使得大塊寫入時只需寫入數據一次，從而減少了原數據的寫入量。然而，Curve 目前仍然存在日誌和數據寫入兩份的問題，因為它使用了 Raft 機制。這導致了帶寬的利用率不高，性能相對於 Ceph 較差。因此，我們的重點之一是優化 Curve 的順序寫性能，特別是在 KBS（Kernel Block Service）方面。我們目前正在進行這方面的工作。</p><p><strong>Q</strong>：<strong>我瞭解 Curve，請提供 CurveFS 和 CurveBS 他們之間的區別和聯繫？</strong></p><p>A：Curve FS 是一個文件系統，而 Curve BS 是一個塊存儲系統。與 Ceph 相比，Curve 有一個有趣的特點是 Curve FS 和 Curve BS 可以進行聯動。這意味着 Curve FS 的數據既可以存儲在 S3 中，也可以存儲在 Curve BS 中。這是與 Ceph 相比的一個亮點。通過這種聯動，我們可以根據性能需求直接對接 Curve BS，或者根據成本需求直接對接 S3。這是我們的一個亮點，為用戶提供了更大的靈活性和選擇性。</p><p><strong>Q</strong>：<strong>SPD 跟 RDMA 什麼時候開源？</strong></p><p>A：關於 SPDK 和 RDMA，我們在 GitHub 上已經有一個版本可用。在上半年，我們在這方面進行了大量的工作，並且在不久前進行了上線。目前，我們正在整理相關的源代碼和其他資料。預計在第四季度我們將完成整理工作並達到一個穩定的狀態。</p><p><strong>Q</strong>：<strong>Curve 如何對接 K8S?在這一方面做了一些什麼事情？</strong></p><p>A：Curve 有一個重要亮點是易運維，我們開發了 CurveAdm 工具。CurveAdm 工具通過容器化技術實現了部署和易運維的功能，這只是其中的一小部分。此外，我們還支持與雲原生環境結合，我們已經通過 Operator 實現了這一功能。</p><p>&nbsp;</p><p style="text-align:center"><em><strong>------ END. ------</strong></em></p><p>🔥 社區資訊：</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MjgxNDYwMA%3D%3D%26mid%3D2247495286%26idx%3D1%26sn%3D958d75811fdf9b5e603988d0f693be10%26chksm%3Dcf525591f825dc8770eab6ecffef893730cc0b6b15a314f59fcbe3e200f5022942315c69569e%26scene%3D21%23wechat_redirect" target="_blank">Curve 社區上半年 Roadmap 進展及下半年規劃</a></p><p>🔥 用戶案例：</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MjgxNDYwMA%3D%3D%26mid%3D2247492574%26idx%3D1%26sn%3Df05f75b1d24e1f15e5b5de2e787993fd%26chksm%3Dcf525839f825d12fd537be23eeabbaf518c26d39f5d67013e9df5097a6841b002301abb8fa8c%26scene%3D21%23wechat_redirect" target="_blank">Curve 文件存儲在 Elasticsearch 冷熱數據存儲中的應用實踐</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MjgxNDYwMA%3D%3D%26mid%3D2247492351%26idx%3D1%26sn%3Dc40936fabc9d1c65da3888e14164fdb5%26chksm%3Dcf525918f825d00ecac6c5740b707dda3118e56b88bb218ba8b2554b3323faa6bd6733b91f63%26scene%3D21%23wechat_redirect" target="_blank">揚州萬方：基於申威平台的 Curve 塊存儲在高性能和超融合場景下的實踐</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MjgxNDYwMA%3D%3D%26mid%3D2247492032%26idx%3D1%26sn%3D9131727a47dc1b774689a99d6f2f01a8%26chksm%3Dcf525a27f825d331e21b9e0d56dcfd812eb49a5675950c6dd48ab1e5cd63795a27a70b35d290%26scene%3D21%23wechat_redirect" target="_blank">創雲融達：基於 Curve 塊存儲的超融合場景實踐</a></p><p>🔥 技術解析：</p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MjgxNDYwMA%3D%3D%26mid%3D2247495461%26idx%3D1%26sn%3D9b34ab555ad4d5fbde1b8a360044f69b%26chksm%3Dcf5254c2f825ddd4edaf667a87b6f26c32f91f7f2d3f1c0e1a3cd49fdbc88687524362bf8382%26scene%3D21%23wechat_redirect" target="_blank">探索 : CurveBS 模擬 RBD 接口對接 OpenStack</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MjgxNDYwMA%3D%3D%26mid%3D2247495489%26idx%3D1%26sn%3Dfc07a375f20d2729d8a1ba295db361db%26chksm%3Dcf5254a6f825ddb0092bc87c3021b1f2a8a7250e66fed43493febb2267d36dbdb633c7da9ba3%26scene%3D21%23wechat_redirect" target="_blank">Curve 安全加固：基於 Kerberos 的鑑權系統</a></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg4MjgxNDYwMA%3D%3D%26mid%3D2247495444%26idx%3D1%26sn%3D5439d799b880f1b2b81ccc9ff96152a9%26chksm%3Dcf5254f3f825dde5e38d5dde8aeead7031092d306ad050d00cfbe08e7df74bb0f4c88864ee64%26scene%3D21%23wechat_redirect" target="_blank">CurveBS RDMA &amp; SPDK 部署指南</a></p><p><img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-7cafa07c4121b6275cf4638eda144c93161.jpg" referrerpolicy="no-referrer"></p><p>&nbsp;</p><ul><li><p><strong>GitHub</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopencurve%2Fcurve" target="_blank">https://github.com/opencurve/curve</a></p></li><li><p><strong>官網</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopencurve.io%2F" target="_blank">https://opencurve.io/</a></p></li><li><p><strong>用戶論壇</strong>：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fask.opencurve.io%2F" target="_blank">https://ask.opencurve.io/</a></p></li><li><p><strong>微信羣：搜索羣助手微信號 OpenCurve_bot</strong></p></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Thu, 21 Sep 2023 03:04:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6923788/blog/10112708</guid>
            <link>https://my.oschina.net/u/6923788/blog/10112708</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 發佈 DALL-E 3，支持使用 ChatGPT 生成提示詞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>OpenAI&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fdall-e-3" target="_blank">宣佈</a>推出圖片生成模型 DALL-E 的最新版本 DALL-E 3，該版本將加入<strong>使用 ChatGPT 生成提示詞</strong>的功能。</p><p><img height="600" src="https://static.oschina.net/uploads/space/2023/0922/104305_q5ED_2720166.png" width="1314" referrerpolicy="no-referrer"></p><p>用戶可以利用簡單的提示詞讓 ChatGPT 生成適合的文字描述，並利用 DALL-E 3 來生成不同需求的圖片。DALL-E 3 還可以生成更高質量的圖像，且對提示詞有着更好的理解能力，特別是在處理長提示時表現更優。為用戶生成更好更精準的圖片。</p><p>DALL-E 3 將於 10 月份首先向 ChatGPT Plus 和 ChatGPT Enterprise 用戶提供，隨後在秋季向研究實驗室及其 API 服務發佈。</p><hr><p>OpenAI 官方給出了體現 DALL·E 3 出色理解能力的案例：</p><ul><li><strong>靈感來自荔枝的球形椅子</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-7b7f1f1044ed4cb5126a84865982e574dd7.png" referrerpolicy="no-referrer"></p><ul><li><strong>捲髮像暴風一樣飄揚，服裝像大理石和瓷器碎片組成的旋風一樣的舞者</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-04160afa5b9731aca3a7ca2832af1896695.png" referrerpolicy="no-referrer"></p><ul><li><strong>土豆國王俯瞰着它的王國</strong></li></ul><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-8fe2d4463cd59234d5b7210cc9805153601.png" referrerpolicy="no-referrer"></p><p>詳情：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fdall-e-3" target="_blank">https://openai.com/dall-e-3</a></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 21 Sep 2023 02:48:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/259053/openai-dall-e-3</guid>
            <link>https://www.oschina.net/news/259053/openai-dall-e-3</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國內首家！阿里雲 Elasticsearch 8.9 版本釋放 AI 搜索新動能]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" target="_blank">數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><p><strong>簡介：</strong> &nbsp;阿里雲作為國內首家上線 Elasticsearch 8.9 版本的廠商，在提供 Elasticsearch Relevance Engine™ (ESRE™) 引擎的基礎上，提供增強 AI 的最佳實踐與 ES 本身的混合搜索能力，為用戶帶來了更多創新和探索的可能性。</p><p>近年來，人工智能的快速發展和廣泛應用在各個行業中都取得了顯著的成果。在搜索領域，阿里雲 Elasticsearch 作為一款功能強大的搜索引擎，一直以來都在為企業提供高效、準確的搜索服務。現在，阿里雲作為國內首家上線 Elasticsearch 8.9 版本的廠商，在提供 Elasticsearch Relevance Engine™ (ESRE™) 引擎的基礎上，提供增強 AI 的最佳實踐與 ES 本身的混合搜索能力，為用戶帶來了更多創新和探索的可能性。</p><p>此次從 8.5 版本到 8.9 版本的全新升級，新增了以下重點功能，使得阿里雲 Elasticsearch 在向量檢索和混合搜索能力都具有顯著改善，大大提升了搜索結果的準確性和相關性。</p><ul><li>支持文本和向量召回結果混排（RRF）。</li><li>向量最大維度提升到 2048。</li><li>暴力檢索性能提升。</li><li>KNN 查詢支持多個字段同時查詢。</li><li>內置 ELSER 模型。</li><li>穩定支持 NLP 分佈式模型調度管理。</li><li>……</li></ul><p><strong>向量檢索---為搜索插上飛躍的翅膀</strong></p><p>向量檢索作為 8.x 版本的重要新增能力，突破了傳統的基於關鍵詞的搜索，利用機器學習和人工智能的力量，將文本內容轉換為向量表示，即將文本數據中的每個單詞表示為一個向量，並通過計算向量之間的距離來判斷文本之間的相似度來實現檢索，從而實現文本的高效檢索和處理。相較於傳統文本檢索，通過增加了單詞和文檔之間的語義關係，使得搜索的相關性顯著提升；同時處理對象從文本到圖像、語音等類型的擴展，應用場景的層面也得到了相應的增加；當然向量檢索更能夠根據用戶偏好定製化搜索結果，為用戶提供了個性化的搜索體驗。</p><p><img alt="" height="230" src="https://oscimg.oschina.net/oscnet/up-16bb40a3367330add16f6d6bb3d9d13145b.png" width="500" referrerpolicy="no-referrer"></p><p>向量檢索技術的應用場景非常廣泛，包括搜索引擎優化、圖像搜索、自然語言處理、推薦系統、情感分析等領域。現阿里雲 Elasticsearch 產品已經提供向量檢索基礎能力，可根據<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1298246%3Fspm%3Da2c6h.13046898.publish-article.3.5fe06ffakRqdWa" target="_blank">基於 Elasticsearch 向量檢索的以文搜圖</a>進行體驗。</p><p><strong>混合搜索 RRF---搜索結果和性能的雙重助力</strong></p><p>混合搜索 RRF（Reciprocal rank fusion）支持對多種不同方式召回的多個結果集進行綜合再排序，返回最終的排序結果。之前 Elasticsearch 已經分別支持基於 BM25 的相關性排序和向量相似度的召回排序，通過 RRF 可以對這兩者的結果進行綜合排序，使得排序的準確性顯著提升。相對於單一搜索搜索技術，混合搜索 RRF 的優勢十分明顯，可任意組合多個搜索技術並獲得綜合性搜索結果，使得搜索的準確性和相關性大幅提升，從場景的適應性來看，企業可根據自身業務設計專屬搜索方案，自由度也明顯提高。關於混合搜索 RRF 在搜索結果準確性和相關性提升的實驗驗證，可根據 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1332447%3Fspm%3Da2c6h.13046898.publish-article.4.5fe06ffakRqdWa" target="_blank">阿里雲 Elasticsearch 使用 RRF 混排優化語義查詢結果對比</a> 進行測試查看，並獲得如下結果。</p><p><img alt="" height="330" src="https://oscimg.oschina.net/oscnet/up-a559b4d22fa1a0cd7bb02b54d3ec0a52811.png" width="500" referrerpolicy="no-referrer"></p><p>隨着新版本的上線，阿里雲 Elasticsearch 再次展現了其在搜索領域的不斷前進。為用戶帶來了更加智能化和深層次的搜索體驗。未來，阿里雲 Elasticsearch 將繼續努力創新，為用戶帶來更多搜索技術的突破和可能性。</p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 21 Sep 2023 02:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/10112705</guid>
            <link>https://my.oschina.net/u/5583868/blog/10112705</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Go 1.22 將修復 for 循環變量錯誤]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>上月正式發佈的 <strong><a href="https://www.oschina.net/news/252970/go-1-21-released" target="_blank">Go 1.21 </a></strong>修改了&nbsp;for 循環變量的語義（預覽階段，<strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgolang%2Fgo%2Fwiki%2FLoopvarExperiment" target="_blank">點此查看詳情</a></strong>）。</p><p>現在，Go 團隊表示 <strong>Go 1.22 會將這項特性發布為正式功能</strong>。</p><p><img src="https://static.oschina.net/uploads/space/2023/0921/181540_2xic_2720166.png" referrerpolicy="no-referrer"></p><p>根據 Go 開發團隊技術 leader Russ Cox (rsc) 的介紹，Go 開發者經常會犯的錯誤是在循環迭代結束後，保留​​對循環變量的引用，此時它會採用預期之外的新值。</p><p>例如下面的程序：</p><pre><code class="language-go">func main() {
    done := make(chan bool)

    values := []string{"a", "b", "c"}
    for _, v := range values {
        go func() {
            fmt.Println(v)
            done &lt;- true
        }()
    }

    // wait for all goroutines to complete before exiting
    for _ = range values {
        &lt;-done
    }
}</code></pre><p>其創建的三個 goroutine 都用於打印相同的變量<code>v</code>，因此它們只會打印出&nbsp;「c」, 「c」, 「c」，而不是按順序打印 「a」, 「b」, 和 「c」。</p><p>從 Go1.21 開始，開發者可以啓用<code>GOEXPERIMENT=loopvar</code>來構建 Go 程序，以解決上文提到的 for 循環變量問題。</p><p>構建命令：</p><pre><code class="language-text">GOEXPERIMENT=loopvar go install my/program
GOEXPERIMENT=loopvar go build my/program
GOEXPERIMENT=loopvar go test my/program
GOEXPERIMENT=loopvar go test my/program -bench=.
...</code></pre><p>現在 Go 開發團隊表示，從 Go1.22 開始，新的 for 循環語義將會在 go.mod 文件中的 Go 版本大於等於 Go1.22 下默認啓用。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Sep 2023 10:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258984/golang-loopvar-preview</guid>
            <link>https://www.oschina.net/news/258984/golang-loopvar-preview</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Linux 內核 LTS 期限將從 6 年恢復至 2 年]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p><span style="color:#000000">在日前舉行的歐洲開源峯會上，Linux 內核開發人員兼《Linux Weekly News》執行主編 Jonathan Corbet <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zdnet.com%2Farticle%2Flong-term-support-for-linux-kernel-to-be-cut-as-maintainence-remains-under-strain%2F" target="_blank">介紹</a>了 Linux 內核的最新動態以及未來的發展方向。其中一項即將發生的重大變化是：Linux 內核的長期支持 (LTS) 時間將從六年縮短至兩年。</span></p><p><span style="color:#000000">目前 Linux 社區仍然遵守當前的生命週期終止時間表，因此已發佈的 6.1、5.15、5.10、5.4、4.19 和 4.14 六個 LTS 版本會遵守六年的規律，但之後發佈的新版本則只會有兩年週期。</span></p><p><span style="color:#000000">對此，Corbet 解釋稱，主要原因在於缺乏使用和缺乏支持；「維持這麼久確實沒有意義，因為人們已經不再使用它們了」。還有一個很大的問題是，Linux 代碼維護人員的倦怠；他們在完成工作時面臨着許多障礙。一方面，維護人員需要在日常工作之餘維護代碼，但維護工作通常沒有報酬。最重要的是，由於人手不足等問題，維護人員的工作量也越來越大。</span></p><p><span style="color:#000000">科技媒體 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farstechnica.com%2Fgadgets%2F2023%2F09%2Flinux-gives-up-on-6-year-lts-thats-fine-for-pcs-bad-for-android%2F" target="_blank">Ars Technica</a> 認為，對於 PC 端來説，兩年似乎是一個不錯的支持窗口；但對於基於 Linux 打造的 Android 移動操作系統來説，卻不盡然。2017 年，Google 開發者 Iliyan Malchev 在一次 Android Linux 演講中<a href="https://www.oschina.net/news/89220/linux-lts-6-year">宣佈</a> Linux 內核的 LTS 期限從兩年延長至六年；彼時的這一擴展主要就是考慮到了 Android 和物聯網設備。</span></p><p><span style="color:#000000"><img alt="" height="274" src="https://oscimg.oschina.net/oscnet/up-5fecaadc98e0bcc94e4fb7bffe6218bd2b6.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img alt="" height="274" src="https://oscimg.oschina.net/oscnet/up-826a6c24004d702cec301acd8b875458fa3.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">而現如今，在 PC 上，兩年僅代表內核更新之間的間隔時間，因此是一個很好的時間表。但對嵌入式設備而言，考慮到大部分的開發週期和整個消費者支持窗口期，這"兩年"時長顯然不夠。</span></p><p><span style="color:#000000">按照谷歌此前的描述，手機開發需要兩年時間，內核在工程流程的初期就已鎖定。因此如果按照兩年的 LTS 期限，當手機最終發貨時，LTS 內核將達到生命週期的終點，導致用戶將在設備的整個生命週期中使用過時的內核。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Sep 2023 09:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258970/linux-gives-up-on-6-year-lts</guid>
            <link>https://www.oschina.net/news/258970/linux-gives-up-on-6-year-lts</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[英偉達的 AI 霸主地位會持久嗎？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><div data-traceid="news_comment_top_ad" data-tracepid="news_comment_top" style="text-align: center;"><a style="color:#A00;font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" target="_blank">數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ <img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div></div><div class="rich_media_content js_underline_content
                       defaultNoSetting
            " id="js_content"><p style="text-align: center;margin-left: 8px;margin-right: 8px;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="375" data-backw="562" data-ratio="0.6670212765957447" data-s="300,640" data-type="jpeg" data-w="940" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;width: 100%;height: auto !important;" src="https://oscimg.oschina.net/oscnet/ba8c9635-bd23-4b82-8638-b5bdb6702999.jpg" referrerpolicy="no-referrer"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"></span><br></p><section style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><section style="letter-spacing: 0.578px;outline: 0px;background-color: rgb(25, 25, 25);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-style="max-width: 100%; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important; color: rgb(163, 163, 163) !important;" class="js_darkmode__0" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;background-color: rgb(255, 255, 255);visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)" data-darkmode-bgcolor-16339314364542="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)" data-darkmode-color-16339314364542="rgb(163, 163, 163)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)" style="outline: 0px;visibility: visible;"><section style="margin-right: 8px;margin-left: 8px;outline: 0px;visibility: visible;line-height: 1.75em;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-style="padding: 10px; max-width: 100%; background-color: rgb(239, 239, 239); color: rgb(62, 62, 62); line-height: 25.6px; display: inline-block; width: 670px; border-width: 2px; border-style: dashed; border-color: transparent; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important;" class="js_darkmode__1" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="padding: 10px;outline: 0px;background-color: rgb(239, 239, 239);line-height: 25.6px;display: inline-block;width: 670px;border-width: 2px;border-style: dashed;border-color: transparent;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><section data-darkmode-bgcolor-16221004879619="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16221004879619="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16221004879619="rgb(168, 168, 168)" data-darkmode-original-color-16221004879619="#fff|rgb(62, 62, 62)" data-darkmode-bgcolor-16339314364542="rgb(41, 41, 41)" data-darkmode-original-bgcolor-16339314364542="#fff|rgb(255, 255, 255)|rgb(239, 239, 239)" data-darkmode-color-16339314364542="rgb(168, 168, 168)" data-darkmode-original-color-16339314364542="#fff|rgb(163, 163, 163)|rgb(62, 62, 62)" style="outline: 0px;visibility: visible;"><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">目前英偉達因其 GPU 芯片在 AI 革命中扮演着核心角色，使其成為 AI 時代最賺錢的公司。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><br></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><span style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 2px;color: rgb(63, 63, 63);">本文作者&nbsp;<span style="color: rgb(63, 63, 63);font-size: 16px;letter-spacing: 2px;text-wrap: wrap;background-color: rgb(239, 239, 239);">Pete Warden&nbsp;</span>總結了鑄就英偉達 AI 霸主地位的四點優勢：</span><span style="color: rgb(63, 63, 63);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;letter-spacing: 2px;">幾乎無人運行大規模機器學習應用；英偉達的替代品都很糟糕；研究人員掌握着硬件採購的風向舵；訓練時延的影響。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><br></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">隨着 AI 技術的發展，<span style="color: rgb(63, 63, 63);font-size: 16px;letter-spacing: 2px;text-wrap: wrap;background-color: rgb(239, 239, 239);">Pete 預測，</span>上述優勢將逐漸發生變化：英偉達在整體 AI 市場中的份額佔比將下降，雖然 AI 市場整體將大幅增長，英偉達的絕對銷量會有所增長，但卻難以繼續維持目前的利潤率。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><br></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><span style="outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">Pete Warden 是智能傳感器公司 Useful Sensor 的創始人，出版了《公共數據手冊》和《大數據詞彙表》，創建了 OpenHeatMap 和 Data Science Toolkit 等開源項目。</span></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;"><br></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(239, 239, 239);line-height: 1.6em;text-align: left;"><span style="letter-spacing: 2px;outline: 0px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;color: rgb(63, 63, 63);">（以下內容由 OneFlow 編譯發佈，轉載請聯繫授權。</span><span style="color: rgb(63, 63, 63);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 16px;letter-spacing: 2px;">原文：https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/）</span></p></section></section></section></section></section></section></section></section></section></section></section></section></section></section><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong><span style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 2px;color: rgb(63, 63, 63);">作者 | Pete Warden</span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong><span style="color: rgb(63, 63, 63);font-size: 16px;letter-spacing: 2px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">OneFlow 編譯</span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong><span style="color: rgb(63, 63, 63);font-size: 16px;letter-spacing: 2px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">翻譯｜宛子琳、楊婷</span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">英偉達（Nvidia）是一家令人敬佩的公司，幾十年來他們勇於逆勢而行，實現與眾不同的願景，並因其在 AI 革命中扮演的核心角色（GPU 成為神經網絡計算的引擎），成為了市值最高的企業之一。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">然而，我認為在未來幾年內，英偉達在機器學習領域的主導地位可能會受到一定程度的動搖，本文將詳細解釋其中的原因。為闡明這一觀點，我打算探討一些驅動英偉達目前主導地位的因素，以及未來可能發生的變化。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);"><br></span></p><span id="OSC_h2_1"></span><h2><p style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">1</span></strong></p><p style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">目前的優勢</span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h2><span id="OSC_h3_2"></span><h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">1. 幾乎無人運行大規模機器學習的推理</span></strong></span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">除少數幾家大型科技公司之外，很少有其他公司真正開始大規模地在生產環境中運行大型 AI 模型。這些公司仍在探索如何利用這些新能力，因此它們的成本主要集中在數據集收集、用於訓練的硬件以及模型研究者的薪資。這意味着更重視機器學習的訓練，而非推理。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 15px;"><br></span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">2. 英偉達難以被替代</span></strong></span></p><h3 style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">對於創建或使用機器學習模型的開發者來説，相比使用 AMD 的 OpenCL 卡、<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489536%26idx%3D1%26sn%3D356152077173bca0e11129d755b78ac3%26chksm%3Dfe419636c9361f20a57ec7690f792c139741768f0a4c5296e4c736eb1e41d846f06be9787dd4%26scene%3D21%23wechat_redirect" textvalue="谷歌的 TPU" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><strong>谷歌的 TPU</strong></a>、<a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247489423%26idx%3D1%26sn%3D06ee2940404e0732ee7860152ddab571%26chksm%3Dfe4199b9c93610af10a6f32614fbb035d0acd56855e70e93a0e8af363beef8dd04ddaeeb43b0%26scene%3D21%23wechat_redirect" textvalue="Cerebras" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><strong>Cerebras</strong></a> 系統或其他硬件，使用英偉達的 GPU 更容易且更省時。英偉達的軟件堆棧更加成熟，提供了更為豐富的示例、文檔和相關資源，更容易找到有經驗的工程師，與主要框架的集成效果也更好。實際上，英偉達在構建平台效應方面無可匹敵，當前的市場形勢呈現出明顯的贏家通吃傾向，英偉達毫無疑問就是那個脫穎而出的贏家。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 15px;"><br></span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">3. 研究人員掌握硬件採購的話語權</span></strong></span></p><h3 style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">僱傭機器學習研究員是一項極具挑戰性的任務，經驗豐富的專家享有豐富的職業選擇，滿足他們的需求至關重要，而他們的需求之一就是英偉達平台。這些專家已經熟悉並能高效地在英偉達平台上工作，而使用其他的替代平台需要時間，且不一定能獲得同等的職場認可。考慮到僱傭和留住機器學習研究員的高昂成本，購買硬件時必須優先考慮他們的偏好。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 15px;"><br></span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">4、訓練時延的影響</span></strong></span></p><h3 style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">根據經驗，通常情況下，從頭訓練一個模型大約需要一週時間。自 AlexNet 早期以來，這一規則一直適用，因為如果迭代週期變長，就很難進行實證測試和原型製作等關鍵步驟了，而這些步驟對於達到所需的準確度目標來説仍然至關重要。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">隨着硬件性能的提升，人們構建的模型也越來越大，這導致訓練時間再次接近原先的水平。為獲得更好的效果，人們開始側重於構建更高質量的模型，而非減少整體訓練時間。因此，購買最新的英偉達 GPU 變得極具吸引力，因為大部分現有代碼可以直接使用，只是運行速度更快。理論上説，競爭對手有機會通過較低的時延贏得優勢，但由於其軟件堆棧並不完善（CUDA 在此方面已投資了數十年），這一機會只是一種幻覺。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><span id="OSC_h2_3"></span><h2 style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">2</span></strong></p><p style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">會發生怎樣的改變？</span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h2><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">希望上文所述的幾個原因足以成為解釋英偉達取得成功的重要結構性因素。以下是我對上述因素未來變化情況的預測。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong style="text-align: left;font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 15px;"><br></span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong style="text-align: left;font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">1. 推理（inference）而非訓練（training）將佔據主導地位</span></strong></span></p><h3 style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">幾年前有人告訴我：「訓練成本與研究人員數量成正比，推理成本與用戶數量成正比」。我從中得出的結論是，在未來某個時刻，公司在用戶請求上運行模型的計算量將超過他們用於訓練的計算量。雖然單次訓練的成本較高，運行推理的成本較低，但世界上有着大量的潛在用戶，涉及眾多不同的應用場景，這些推理需求的累計總量將超過訓練總量，因為研究人員的數量畢竟是有限的。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">對於硬件來説，這意味着優先級將轉向降低推理成本。<strong>很多機器學習研究員將推理視為訓練的一個子集，但從根本上講，這種看法是錯的。</strong></span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="color:#3f3f3f;"><span style="font-size: 16px;letter-spacing: 2px;"><strong><br></strong></span></span><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在推理過程中，由於需要在時延和吞吐量之間做權衡，所以通常難以組裝出大批量的輸入數據，而在面向用戶的應用程序中，時延一直是至關重要的影響因素。小型或單個輸入批次會顯著改變工作負載，並需要採用截然不同的優化方法。此外，在推理過程中，還有很多因素（如權重）是保持不變的，因此可以通過權重壓縮或常數摺疊（constant folding）等預處理技術來獲益。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 15px;"><br></span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong style="text-align: left;font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">2. CPU 在推理方面的競爭力</span></strong></span></p><h3 style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在模型訓練過程中，CPU 的速度仍然慢得讓人難以接受，因此上文在列舉英偉達的替代品時，並沒有提及 CPU。但主流的桌面級 CPU（x86、Arm，以及可能即將推出的 RISC-V）經過了幾十年的工具鏈投資，比英偉達具備更成熟的開發工具和社區。此外，主流 CPU 的單次計算操作成本也遠低於任何 GPU。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">回顧互聯網時代的早期階段，當時建立互聯網公司的主要成本是從 Sun 等公司花費數百萬美元購買高端網絡服務器硬件，因為它們是唯一能夠可靠地提供低時延網頁服務的平台，那些服務器擁有當時市面上最快的硬件配置。當整個網站需要在一台機器上運行時，硬件速度就成了至關重要的因素。然而，隨着分佈式軟件的應用，人們可以將工作分配到大量性能相對較低但廉價的通用 x86 服務器上，這導致 Sun 的市場份額迅速萎縮。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">目前，模型訓練很難以類似的方式進行分佈式處理。雖然工作負載可以在相互緊密連接的幾個 GPU 上進行分割，但不斷更新的模式使得通過在低端 CPU 上進行分片（sharding）來減少時延變得不現實。不過，對於推理階段，情況則不同。模型權重是固定的，因此可以在初始化階段輕鬆地在許多機器上進行復制，而無需通信。這使得大量的商用 PC 對依賴 ML 推理的應用程序來説非常有吸引力。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 15px;"><br></span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong style="text-align: left;font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">3. 部署工程師話語權增加</span></strong></span></p><h3 style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">隨着推理成本開始主導訓練過程，降低推理成本的壓力將越來越大。在這種情況下，研究人員的偏好將不再是最高優先級。為精簡生產流程，他們需要從事一些相對不太感興趣的工作。隨着相關技能的廣泛普及，未來幾年將會有更多能夠訓練模型的人進入勞動力市場。這意味着研究人員在企業中的話語權將被削弱，而部署團隊的需求會更受重視。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><strong style="font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 15px;"><br></span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;"><strong style="text-align: left;font-size: 16px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.034em;"><span style="letter-spacing: 2px;color: rgb(63, 63, 63);">4. 應用成本規律</span></strong></span></p><h3 style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h3><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">當推理階段佔據整體人工智能預算的主導地位時，硬件和工作負載的需求會有很大不同。研究人員十分注重快速實驗的能力，因此他們需要具備靈活性來進行新想法的原型設計。相對來説，應用程序通常較少更換模型，一旦研究人員找到了符合他們需求的模型，可能會在多年內使用相同的基本架構。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">或許我們正朝着這樣一個世界前進：模型作者使用類似於 Matlab 針對數學算法的專門工具，然後將結果交給部署工程師，由他們手動將結果轉換為更適用於特定應用的高效形式。這一推斷不無道理，因為如果模型架構保持不變（即便權重發生變化），隨時間的推移，任何的成本節約都會倍增。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><span id="OSC_h2_4"></span><h2 style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><p style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><strong><span style="letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);">3</span></strong></p><p style="line-height: 1.6em;text-align: center;margin-left: 8px;margin-right: 8px;"><strong><span style="letter-spacing: 2px;font-size: 17px;color: rgb(30, 35, 128);">上述改變意味着什麼？</span></strong></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p></h2><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">通過上述的四個預測可以得出結論：<strong>英偉達在 AI 市場份額中的佔比將下降。</strong>雖然 AI 市場整體將大幅增長，英偉達的絕對銷量可能會繼續增長，但將難以持續維持目前的利潤率。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">在這種轉變中，預計傳統的 CPU 平台（如 x86 和 Arm ）將勝出。推理過程需要與傳統的業務邏輯緊密集成，以運行終端用戶應用程序，因此很難想象，即使是針對推理而專門設計的硬件也能夠跨越總線（bus）運行，因為涉及延遲問題。相反，我預計 CPU 將獲得更加緊密集成的機器學習支持，首先作為協處理器，最終作為專門的指令，就像浮點數支持的演變一樣。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">以上因素推動着我的研究和創業方向。未來幾年，改進模型推理將帶來巨大的影響，但與訓練相比，推理仍然被忽視。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">不過，這種情況正在發生改變。像 Reddit 中的 LocalLlama 社區專注於推理的改進，GGML 的成功則證明瞭人們對專注推理的框架的需求之大，此外，幾個通用模型的傳播也增加了推理優化的回報。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><span style="font-size: 16px;letter-spacing: 2px;color: rgb(63, 63, 63);">我之所以如此關注邊緣端，是因為它最接近未來將運行大部分雲端 AI 的大規模普通 PC 的環境。早在 2013 年，我開始編寫 Jetpac SDK ，旨在通過在 100 台 m1.small AWS 服務器集羣上加速計算機視覺，相較於在數百萬張圖像上進行推理的 GPU 實例，這種方法更加經濟高效。後來我才意識到 SDK 在移動設備上的適用性如此之好。</span></p><p style="line-height: 1.6em;text-align: justify;margin-left: 8px;margin-right: 8px;"><br></p><section style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;text-wrap: wrap;outline: 0px;caret-color: rgba(0, 0, 0, 0.9);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-size-adjust: auto;line-height: 1.75em;text-align: left;"><span style="background-color: rgb(255, 255, 255);color: rgb(136, 136, 136);letter-spacing: 1px;font-size: 15px;">其他人都在看</span></section><span id="OSC_h3_5"></span><h3 style="letter-spacing: 0.578px;text-wrap: wrap;"><ul class="list-paddingleft-1" style="width: 577.422px;"><li style="outline: 0px;font-size: 15px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491988%26idx%3D1%26sn%3Dc5fcc5f3fa27bb00bf8ef9af05e7ca89%26chksm%3Dfe426fa2c935e6b4ebb279bf19471f39629ccfb6733e6d8a580fdcbb01e80bd59266f3830bac%26scene%3D21%23wechat_redirect" textvalue="OpenAI 首席科學家：通向無監督學習之路" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-wrap: wrap;letter-spacing: 0.578px;font-size: 15px;"><span style="font-size: 15px;">通向無監督學習之路</span></a><br></p></li><li style="outline: 0px;font-size: 15px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492023%26idx%3D1%26sn%3D28acd01925189816397de2317040f71e%26chksm%3Dfe426f81c935e697cacc74133e02923089df26cd8b2b07efd0e08d7a5ee2c9ca98d1a913f9cd%26scene%3D21%23wechat_redirect" textvalue="TorchDynamo 初探②：Torch.FX 調研和實踐" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="letter-spacing: 1px;text-wrap: wrap;font-size: 15px;"><span style="font-size: 15px;">Torch.FX 調研和實踐</span></a><br></p></li><li style="outline: 0px;font-size: 15px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492022%26idx%3D1%26sn%3D4c2dc51a0f57494539e2d0dae4e8356b%26chksm%3Dfe426f80c935e696b204053faad502b81a5aecf14c3ff804281f8f02bbc215519a3a2ac9627e%26scene%3D21%23wechat_redirect" textvalue="揭祕編碼器與解碼器語言模型" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="font-size: 15px;"><span style="font-size: 15px;">揭祕編碼器與解碼器語言模型</span></a></p></li><li style="outline: 0px;font-size: 15px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492022%26idx%3D1%26sn%3D4c2dc51a0f57494539e2d0dae4e8356b%26chksm%3Dfe426f80c935e696b204053faad502b81a5aecf14c3ff804281f8f02bbc215519a3a2ac9627e%26scene%3D21%23wechat_redirect" textvalue="揭祕編碼器與解碼器語言模型" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"></a><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491908%26idx%3D1%26sn%3D208a592f66f2cb2f412f9b58bca87401%26chksm%3Dfe426f72c935e6641a14837bb0a600bcbf28b9b2d427ca01477b492cfff2116aafedfd66c900%26scene%3D21%23wechat_redirect" textvalue="通俗解構語言大模型的工作原理" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="font-size: 15px;"><span style="font-size: 15px;">通俗解構語言大模型的工作原理</span></a></p></li><li style="outline: 0px;font-size: 15px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492001%26idx%3D1%26sn%3D8ee2ef77916c2992f570c294adc1ec19%26chksm%3Dfe426f97c935e6819fbd0cad4ca972da01c1ba40baef933db2a3eadfaed12a7605444ad86132%26scene%3D21%23wechat_redirect" textvalue="PyTorch 創始人：開源成功的方法論" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="letter-spacing: 0.578px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><span style="font-size: 15px;">PyTorch 創始人：開源成功的方法論</span></a></p></li><li style="outline: 0px;font-size: 15px;letter-spacing: 1px;"><p><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492040%26idx%3D1%26sn%3Daed3ec88c328d23435bb24cfe7179dbd%26chksm%3Dfe426ffec935e6e82af92f9922696b65de62ecb5e6499e3ab1e82725889bc164c1fdf4a6ff4f%26scene%3D21%23wechat_redirect" textvalue="OpenAI 首席科學家：直面 AGI 的可能性" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="letter-spacing: 0.578px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;"><span style="font-size: 15px;"><span style="letter-spacing: 0.578px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;">OpenAI 首席科學家：直面 AGI 的可能性</span></span></a></p></li></ul></h3><span id="OSC_h3_6"></span><h3 style="letter-spacing: 0.578px;text-wrap: wrap;"><ul class="list-paddingleft-1" style="width: 577.422px;"><li style="outline: 0px;font-size: 15px;letter-spacing: 1px;"><section style="letter-spacing: 0.578px;"><a target="_blank" href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491935%26idx%3D1%26sn%3D9535636ca06c16345b432a9de5383f1e%26chksm%3Dfe426f69c935e67f717ca8a968b9dd2a3f69b45f330b561b3584ba1b196149c8ba00d3d452eb%26scene%3D21%23wechat_redirect" textvalue="OpenAI 超級對齊負責人：「駕馭」超級智能的四年計劃" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="font-size: 15px;"><span style="font-size: 15px;">OpenAI 對齊負責人：「駕馭」超級智能四年計劃</span></a><br></section></li></ul><section style="outline: 0px;line-height: 1.75em;text-align: left;"><span style="outline: 0px;background-color: rgb(255, 255, 255);letter-spacing: 1px;color: rgb(63, 63, 63);font-size: 15px;">試用 OneFlow: github.com/Oneflow-Inc/oneflow/</span></section></h3><h2 style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);"><hr style="outline: 0px;border-style: solid;border-right-width: 0px;border-bottom-width: 0px;border-left-width: 0px;border-color: rgba(0, 0, 0, 0.1);transform-origin: 0px 0px;transform: scale(1, 0.5);"></h2><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);"><img class="rich_pages wxw-img" data-backh="162" data-backw="578" data-galleryid="" data-ratio="0.2802690582959641" data-s="300,640" data-type="png" data-w="892" style="letter-spacing: 0.578px;text-align: center;font-size: var(--articleFontsize);outline: 0px;display: inline;width: 100%;visibility: visible !important;height: auto !important;" src="https://oscimg.oschina.net/oscnet/5b64ee31-833c-4a6d-a3f5-1cbf8d5e1f08.png" referrerpolicy="no-referrer"></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Sep 2023 08:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/10112067</guid>
            <link>https://my.oschina.net/oneflow/blog/10112067</link>
            <author>
                <![CDATA[OneFlow 深度學習框架]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[deepin 官宣正式接入大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="ad-wrap" style="margin-bottom: 8px;"><a data-traceid="news_detail_above_text_link_1" data-tracepid="news_detail_above_text_link" style="color:#A00; font-weight:bold;" href="https://www.oschina.net/question/4489239_2331019" _blank"="">
數據技術都能四世同堂，憑什麼開發 30 歲就要被幹掉？ 
<img src="https://www.oschina.net/img/hot3.png" align="absmiddle" style="max-height: 32px;max-width: 32px;margin-top: -4px;" referrerpolicy="no-referrer"></a></div><p>deepin 正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fc13tYvL26S3CCht1f_RitA" target="_blank">官宣</a>已實現大模型能力接入，多款自研應用軟件實現智能化升級。</p><p>統信軟件高級副總經理、CTO 張磊表示：「目前 UOS AI 實現了國內外主流大模型的能力接入，並封裝成 deepin 的 AI 底層公共能力；同時，我們也將把 UOS AI 逐步開源給第三方應用，讓更多應用可以在 deepin 上直接調用大模型。</p><p>公告指出，大模型的接入為 deepin 帶來更多可能，操作系統可以更好地理解用戶行為，提升用戶體驗：</p><ul><li>首先，通用大模型通過操作系統探索更多應用場景。通用大模型具有強大的語言理解和處理能力，可以為用戶提供智能化的體驗；</li><li>其次，大模型的出現帶來了全新的交互模式，未來每位用戶都將擁有一個專屬的 AI 助理，這個助理將運行在操作系統之上；</li><li>最後，未來 AI 將是操作系統的基礎能力之一，合作伙伴可以直接調用操作系統提供的 AI 能力，釋放平台價值。</li></ul><h4><strong>三大應用，全新升級，為 AI 進化</strong></h4><p>在 AI 能力落地方面，deepin 選取了用戶常用的智能全局搜索、郵件、瀏覽器三大應用，率先開啓 AI 能力，為用戶提供智能化應用體驗。</p><p><strong>智能全局搜索：一鍵搜索、一鍵直達</strong></p><p>智能全局搜索支持三大核心能力，包括自然語言搜索、圖片內容搜索、文檔內容搜索，可實現「一鍵搜索，一鍵直達」的便捷體驗。</p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-9b7631bf352e063e37ad3063c3c4d6bb1ce.png" width="500" referrerpolicy="no-referrer"></p><p>不管是關鍵詞文件名查找，還是文件內容查找、圖片 OCR 查找、時間範圍查找等，都支持智能全局搜索。</p><p><strong>郵箱新體驗：在這裏，新建無限可能</strong></p><p>郵箱同樣是日常辦公中最為常見，也是應用最為頻繁的軟件之一。更多時候，我們會把時間花在書寫的規範性及排版構思中，而這些訴求都可以通過 UOS AI 快速完成，大大提升用戶的工作效率和品質。</p><p><img alt="" height="281" src="https://oscimg.oschina.net/oscnet/up-bd3092054ddf468288daf221eb7729ef732.png" width="500" referrerpolicy="no-referrer"></p><p>例如，僅需輸入郵件主題，UOS AI 便可輸出內容，供你參考；寫好郵件，想不出主題，UOS AI 幫你總結；對已寫的郵件內容不滿意，交給 UOS AI 幫你潤色……更多智能化功能，等你體驗。</p><p><strong>瀏覽器新玩法：從場景中來，到體驗中去</strong></p><p>從此，用提問代替搜索！來體驗瀏覽學習、創作編劇、提示詞管理等豐富功能。未來，還將加入更多智能化應用體驗。</p><p><img alt="" height="259" src="https://oscimg.oschina.net/oscnet/up-892cd0b93b60ecfaf7afa1a656c276a805f.png" width="500" referrerpolicy="no-referrer"></p><p>目前，瀏覽器 AI 三大亮點功能包括：</p><ul><li>聊天問答：右側固定聊天框，為用戶提供基於大模型的問答聊天服務；</li><li>快捷浮窗：在網頁內提供 AI 快捷浮窗，支持 AI 翻譯、AI 總結、AI 改寫等內容處理能力。同時支持在快捷浮窗運行用戶自定義的提示詞功能。</li><li>自定義提示詞：提供提示詞自定義功能，支持用戶自定義提示詞，已實現個性化功能。</li></ul><p>deepin 方面表示，此次接入大模型將為用戶帶來更加智能化的操作體驗。用戶可以通過語音識別、圖像識別等技術，更加便捷地進行操作，為日常使用帶來極大的便利。</p><p>「未來，UOS AI 將在 deepin 的原生應用和第三方應用中探索更多模式。隨着技術的不斷進步和發展，我們將會成為更加優秀的開源操作系統，為全球用戶帶來更好的體驗。同時，我們也期待更多的開發者和企業能夠參與到這一創新過程中來，共同推動開源操作系統和大模型的深度融合，為構建更美好的未來科技世界貢獻力量。」</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 20 Sep 2023 08:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/258958</guid>
            <link>https://www.oschina.net/news/258958</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
