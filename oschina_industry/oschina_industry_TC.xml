<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 31 Dec 2023 07:11:47 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[盤點 2023 十大宕機事故「冥場面」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>名場面？冥場面！</p><p>速來圍觀 2023 十大宕機事故「冥場面」——</p><hr><h1><a href="https://www.oschina.net/news/231236" target="_blank">嗶哩嗶哩（B 站）崩了兩次</a></h1><p>2023 年 3 月 5 日晚 20:20 左右，許多網友表示在使用 B 站時，手機和電腦端都無法訪問視頻詳情頁，且手機端無法查看收藏夾與歷史記錄。還有網友表示，首頁能夠正常加載，但全部是繁體字。</p><p><img src="https://oscimg.oschina.net/oscnet/up-affa896050135c6a15c206de322a4e28acc.png" referrerpolicy="no-referrer"></p><p><u><a href="https://www.oschina.net/news/252405">8 月 4 日晚間</a></u>，距離上次事故 5 個月後，又有許多網友反饋 B 站圖片（視頻封面）無法加載、視頻無法打開、視頻一直在緩衝。</p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/236219" target="_blank">騰訊「3.29」一級事故</a></h1><p>2023 年 3 月 29 日凌晨，騰訊旗下的微信和 QQ 等業務曾出現崩潰狀況，包括微信語音對話、朋友圈、微信支付，以及 QQ 文件傳輸、QQ 空間和 QQ 郵箱在內的多個功能無法使用。</p><p>直到 29 日早間，騰訊微信團隊才回應表示，經工程師搶修，系統正在逐步恢復。</p><p><img src="https://oscimg.oschina.net/oscnet/up-127213d84c63650497a340914182c4a89f9.png" referrerpolicy="no-referrer"></p><p>本次事故由廣州電信機房冷卻系統故障導致，騰訊將它定義為公司一級事故，並對大量相關領導做出了處罰。</p><p>4 月 12 日，工業和信息化部信息通信管理局<u><a href="https://www.oschina.net/news/236943">聽取騰訊公司關於 「3・29」 微信業務異常情況彙報</a></u>，要求騰訊公司進一步健全安全生產管理制度、落實網絡運行保障措施，堅決避免發生重大安全生產事故，切實提升公眾業務安全穩定運行水平。</p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/244039" target="_blank">唯品會 329 事故處罰結果：基礎平台部負責人被免職</a></h1><p>今年 3 月 29 日，「唯品會崩了」 登上熱搜，由於崩潰時間太長，影響了很多消費者無法正常下單。唯品會官方對此迴應稱，因系統短時故障，主站 「加購」 等功能或出現異常。</p><p>6 月 5 日，唯品會發布 「關於 329 機房宕機故障處理的公告」。公告稱，3 月 29 日（00:14-12:01）南沙 IDC 冷凍系統故障，導致機房設備溫度快速升高宕機，造成線上商城停止服務。此次事故影響時間持續 12 個小時，導致唯品會業績損失超億元，影響客戶達 800 萬，唯品會將此次故障判定為 P0 級故障。據瞭解，P0 屬於最高級別事故，比如崩潰、頁面無法訪問、主流程不通、主功能未實現，或在影響面上影響很大（即使 Bug 本身不嚴重）。</p><p>公告指出，唯品會決定對此次事件嚴肅處理，對應部門的直接管理者承擔此次事故責任，基礎平台部負責人予以免職作相應處理。</p><p><img src="https://oscimg.oschina.net/oscnet/up-168b9a6041c9b94335f6c23063ef7f9ce95.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/244118/microsoft-azure-outage-brazil" target="_blank">微軟 Azure 故障，17 個生產級數據庫被刪</a></h1><p>5 月 24 日，微軟 Azure DevOps 在巴西南部地區的一處 scale-unit 發生故障，導致宕機約 10.5 個小時。後續微軟首席軟件工程經理 Eric Mattingly 出面針對此次故障事件道歉，並<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstatus.dev.azure.com%2F_event%2F392143683%2Fpost-mortem">透露了</a>導致中斷的原因：即，一個簡單的拼寫錯誤致使 17 個生產級數據庫被刪除。</p><p><img alt="up-d28b235003ee1390973397efd32e59d2ee1.png" src="https://oscimg.oschina.net/oscnet/up-d28b235003ee1390973397efd32e59d2ee1.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/244330" target="_blank">中國電信出現大規模無服務問題</a></h1><p>2023 年 6 月 8 日下午，中國電信的網絡和通信服務出現無信號等失靈現象，絕大部分反饋的用戶都在廣東區域，疑似廣東省內故障。</p><p>此後中國電信客服迴應表示，電信基站全省（廣東電信）故障，暫時不能撥打電話，請耐心等待，現在緊急加急處理中，不便之處，敬請諒解。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3ccdb0730d3b6ee9d3faf43d5d2a31c7d6e.png" referrerpolicy="no-referrer"></p><p>歷時 4 個小時左右，廣東省內電信網絡全面恢復。</p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/263266" target="_blank">語雀 10.23 重大服務故障，持續 7 小時</a></h1><p>2023 年 10 月 23 日語雀出現重大服務故障，且持續 7 個多小時才完全恢復。語雀團隊後續公佈了故障原因及處理過程：</p><p>10 月 23 日下午，服務語雀的數據存儲運維團隊在進行升級操作時，由於新的運維升級工具 bug，導致華東地區生產環境存儲服務器被誤下線。受其影響，語雀數據服務發生嚴重故障，造成大面積的服務中斷。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d0d73c9d391b9afb17b5d8a1fdfe8babfa4.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/266694" target="_blank">阿里雲 11.12 重大服務故障，全線產品受影響</a></h1><p>2023 年 11 月 12 日下午，阿里雲出現嚴重故障，全線產品受影響。</p><p>後續官方確認故障原因與某個底層服務組件有關。在歷時約 5 個小時後，阿里雲宣佈受影響雲產品均已恢復，因故障影響部分雲產品的數據（如監控、賬單等）可能存在延遲推送情況，不影響業務運行。</p><p><img src="https://oscimg.oschina.net/oscnet/up-12e038da50562b9fb7806fac53534a272ac.png" referrerpolicy="no-referrer"></p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/268480" target="_blank">滴滴 11.27 系統服務故障，技術團隊連夜修復</a></h1><p>2023 年 11 月 27 日晚間，滴滴因系統故障導致 App 服務異常，不顯示定位且無法打車。11 月 27 日晚，滴滴出行進行了回覆：非常抱歉，由於系統故障，今天晚間滴滴 App 服務出現異常，經技術同學緊急修復，目前正陸續恢復中。</p><p>2023 年 11 月 28 日早間，滴滴出行消息稱，網約車等服務已恢復，騎車等在陸續修復中。11 月 28 日，在滴滴發出公告的同時，記者在上海、深圳等地使用滴滴呼叫網約車，發現網約車功能並未恢復使用，網絡加載異常，仍無法打車。11 月 28 日，滴滴向記者回應稱，網約車服務已恢復，司機乘客權益陸續恢復補發。</p><p><strong>11 月 29 日，滴滴再次發文致歉，稱初步確定事故起因是底層系統軟件發生故障</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-de730d329966eb2d4a658c5008f11be82a7.png" referrerpolicy="no-referrer"></p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1129/113103_VOdZ_2720166.png" referrerpolicy="no-referrer"></p></blockquote><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/231624/a-single-engineer-brought-down-twitter" target="_blank">推特嚴重宕機，馬斯克暴怒</a></h1><p>2023 年 2 月，馬斯克因其關於超級碗的推文曝光度不如美國總統拜登，而深夜緊急召集約 80 人解決算法問題。</p><p>3 月份，因一名工程師修改配置導致推特出現嚴重的宕機故障，馬斯克揚言要將代碼全部進行重構。</p><p><img src="https://static.oschina.net/uploads/space/2023/0308/083022_yiJO_2720166.png" referrerpolicy="no-referrer"></p><p>7 月份，用戶反饋平台再次出現問題，無法發佈新推文，收到 「超出限制」 的錯誤提示。馬斯克則迴應稱，Twitter 正在努力應對 「極端程度的數據抓取」 和 「系統操縱」，這些新的限制是遏制這些緊迫問題的重要措施。</p><p>&nbsp;</p><h1><a href="https://www.oschina.net/news/265693" target="_blank">ChatGPT 服務中斷近 2 小時，CEO 奧特曼道歉：流量遠超預期</a></h1><p>北京時間 11 月 8 日晚 22 點左右，OpenAI 旗下 ChatGPT 以及相關 API 出現中斷故障，導致面向用戶和開發者的服務近 2 小時無法正常使用。</p><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstatus.openai.com%2F">隨後 OpenAl 更新事故報告稱</a></u>，已確定了一個導致 API 和 ChatGPT 錯誤率高的問題，正在努力修復。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9dfae5273c9fd8f249f7e5bbc7592211806.png" referrerpolicy="no-referrer"></p><p>與此同時，OpenAI CEO 山姆・奧特曼<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fsama%2Fstatus%2F1722315204242149788">公開致歉稱</a></u>，本週發佈的新功能遇到遠超預期的使用量。公司原計劃在週一為所有訂閲者啓用 GPTs 服務，但目前還無法實現。由於負載的原因，短期內可能會出現服務不穩定的情況，對此情況向用戶道歉。</p><p>&nbsp;</p><p><em>延伸閲讀：<u><a href="https://www.oschina.net/news/270052">網信辦發佈《網絡安全事件報告管理辦法（徵求意見稿）》</a></u></em></p><hr><p>更多年度重磅事件回顧，查看<strong><u><a href="https://talk.gitee.com/report/china-open-source-2023-annual-report.pdf?fr=shida_news1231" target="_blank">《2023 中國開源開發者報告》</a></u></strong>。</p><p><img height="4950" src="https://oscimg.oschina.net/oscnet/up-742bb3d98bf476a2aa6120928bae7b2ee33.png" width="3497" referrerpolicy="no-referrer"><img height="4950" src="https://oscimg.oschina.net/oscnet/up-e2e5b4d5020eec787e184044fd4f42d8c7b.png" width="3497" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 31 Dec 2023 04:02:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273501</guid>
            <link>https://www.oschina.net/news/273501</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[惡意軟件濫用 Google OAuth 端點「恢復」cookie、劫持帳戶]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">多個信息竊取惡意軟件系列正在濫用名為「MultiLogin」的未記錄的 Google OAuth 端點來恢復過期的身份驗證 cookie 並登錄用戶帳戶（即使賬戶密碼已被重置）。</span></p><p style="color:#404040; margin-left:0; margin-right:0; text-align:justify"><span style="color:#000000">科技網站&nbsp;<span style="background-color:#ffffff"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Fmalware-abuses-google-oauth-endpoint-to-revive-cookies-hijack-accounts%2F" target="_blank">BleepingComputer</a> 指出，他們在今年 11 月底曾報道了兩名黑客：Lumma 和 Rhadamanthys，兩人聲稱可以恢復在攻擊中竊取的過期谷歌驗證 cookie。</span></span><span style="color:#000000"><span style="background-color:#ffffff">即使合法所有者已經註銷、重置密碼或會話過期，這些 cookie 仍可讓網絡犯罪分子在未經授權的情況下訪問谷歌賬戶。但在這一個多月來，BleepingComputer&nbsp;曾多次聯繫谷歌，詢問相關説法的真實性以及他們計劃如何緩解這一問題，卻從未收到過回覆。</span></span></p><p><span style="color:#000000">CloudSEK 研究人員日前發佈的一份報告則進一步揭示了這種零日漏洞利用的工作原理，並描繪了有關其利用規模的可怕景象。10 月 20 日，一個名為 PRISMA 的威脅行為者首次披露了這一漏洞稱，他們發現了一種恢復過期谷歌驗證 cookie 的方法。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>對漏洞進行逆向工程後，CloudSEK 發現它使用了一個名為「MultiLogin」的未記錄的 Google OAuth 端點，該端點旨在通過接受帳戶 ID 和 auth-login&nbsp;tokens 向量來同步不同 Google 服務之間的帳戶。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>「此請求用於在多個 Google 網站（例如 YouTube）的 Google 身份驗證 cookie 中設置瀏覽器中的 Chrome 帳戶。」&nbsp; &nbsp;</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>「這個請求是 Gaia Auth API 的一部分，只要 cookie 中的帳戶與瀏覽器中的帳戶不一致就會觸發。」</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>CloudSEK 表示，濫用該終端的信息竊取惡意軟件會提取登錄到谷歌賬戶的 Chrome 配置文件的 tokens 和賬戶 ID。這些被盜信息包含兩個關鍵數據：service (GAIA ID) 和 encrypted_token。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>加密令牌使用存儲在 Chrome 瀏覽器"Local State"文件中的加密密鑰進行解密。同樣的加密密鑰也用於解密瀏覽器中保存的密碼。利用竊取的 token：GAIA 與多重登錄端點配對，威脅行為者可以重新生成過期的 Google Service cookies，並保持對受損賬戶的持久訪問。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><img height="263" src="https://oscimg.oschina.net/oscnet/up-0d39112d34ae544e0bc2bc03fa265fea829.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#404040">CloudSek 研究員 Pavan Karthick 表示，他們對該漏洞進行了逆向工程，並能夠使用它來重新生成過期的 Google 身份驗證 cookie，如下所示：</span></p><p><img height="253" src="https://oscimg.oschina.net/oscnet/up-b05c5e78446b2fe30d3c88ba80361617dc5.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#404040">Karthick 解釋稱，如果用戶重置其 Google 密碼，身份驗證 cookie 只能重新生成一次。否則，它可以多次重新生成，從而提供對帳戶的持久訪問。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Lumma stealer 於 11 月 14 日首次利用了該漏洞，</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>Radamanthys 是第一個在 11 月 17 日效仿的人；</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>此後還有 12 月 1 日的 Stealc、12 月 11 日的 Medusa、12 月 12 日的 RisePro 和 12 月 26 日的 Whitesnake。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>因此，目前至少有 6 個信息竊取者聲稱能夠使用此 API 端點重新生成 Google cookie。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span><span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>此後，</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff; color:#070707">Lumma 還發布了該漏洞的更新版本：轉而使用 SOCKS 代理來逃避 Google 的濫用檢測措施，並在惡意軟件和 MultiLogin 端點之間實現加密通信；以抵消谷歌的緩解措。</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">BleepingComputer 認為，這實際上也表明，谷歌方面是知道這一漏洞的存在的。但該公司</span>尚未確認 MultiLogin 端點被濫用的這一事件，因此目前該漏洞利用的狀態及其緩解措施仍不清楚。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 31 Dec 2023 03:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273500/malware-abuses-google-oauth-endpoint-cookies</guid>
            <link>https://www.oschina.net/news/273500/malware-abuses-google-oauth-endpoint-cookies</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[1-11 月我國規上互聯網企業完成業務收入 15668 億元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">工信部最新</span></span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fgxsj%2Ftjfx%2Fhlw%2Fart%2F2023%2Fart_e133fb8083b84cc5993dfe7ae5eb32d0.html" target="_blank">發佈</a><span style="background-color:#ffffff; color:#000000"><span style="background-color:#ffffff">的&nbsp;2023 年 1-11 月份互聯網和相關服務業運行情況指出，</span></span><span style="color:#070707">1-11 月份，互聯網業務收入增速持續提升，利潤總額增勢放緩，研發經費持續下滑。</span></p><h4 style="margin-left:0px; margin-right:0px; text-align:justify"><strong><span>一、總體情況</span></strong></h4><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>互聯網業務收入</span></strong><strong><span>增速持續提升</span></strong><strong><span>。</span></strong></span><span>1－11</span><span>月份</span><span><span>，我國規模以上互聯網和相關服務企業</span><span><span>1</span></span><span>（以下簡稱互聯網企業）完成互聯網業務收入</span></span><span>15668 億元，同比增長 6.1%</span><span>。</span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><img height="249" src="https://oscimg.oschina.net/oscnet/up-207c3b83268b47a98ecb744cb5cdb7b82fb.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>利潤</span></strong><strong><span>總額</span></strong><strong><span>增勢放緩</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span><span>，我國規模以上互聯網企業營業成本同比增長</span></span><span>9.7%，增速較</span><span>1</span><span>－10 月份回落 0.1</span><span><span>個百分點。實現利潤總額</span></span><span>1189 億元，同比增長 2.5</span><span>%。</span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><img height="252" src="https://oscimg.oschina.net/oscnet/up-593de36ec44bc8dd102524f5b7a772b98b3.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>研發經費</span></strong><strong><span>持續下滑</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span><span>，我國規模以上互聯網企業共投入研發經費</span></span><span>822.7 億元，同比下降 4.5</span><span>%。</span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><img height="249" src="https://oscimg.oschina.net/oscnet/up-6fa68b7451c0f67c4ed961f6c2559e4f35a.png" width="500" referrerpolicy="no-referrer"></p><h4 style="margin-left:0px; margin-right:0px; text-align:justify"><strong><span>二、分領域情況</span></strong></h4><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>（一）信息服務領域企業</span></strong><strong><span>收入實現正增長</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span><span>，以信息服務為主的企業（包括新聞資訊、搜索、社交、遊戲、音樂視頻等）互聯網業務收入同比</span></span><span>增長 0.4</span><span>%。</span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>（二）生活服務領域企業收入</span></strong><strong><span>保持快速增長</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span><span>，以提供生活服務為主的平台企業（包括本地生活、租車約車、旅遊出行、金融服務、汽車、房屋住宅等）互聯網業務收入同比增長</span></span><span>22.1%。</span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>（三）網絡銷售領域企業收入</span></strong><strong><span>增速有所回落</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span><span>，主要提供網絡銷售服務的企業（包括大宗商品、農副產品、綜合電商、醫療用品、快遞等）互聯網業務收入同比增長</span></span><span>23.7%。</span></p><h4 style="margin-left:0px; margin-right:0px; text-align:justify"><strong><span>三、分地區情況</span></strong></h4><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>中</span></strong><strong><span>部地區互聯網業務收入增</span></strong><strong><span>速持續提升</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span><span>，東部地區完成互聯網業務收入</span></span><span>14016 億元，同比增長 6.5</span><span>%，增速與 1</span><span>－10 月份持平</span><span><span>，高於全國增速</span></span><span>0.4 個百分點，佔全國互聯網業務收入的比重為 89.5%。中部地區完成互聯網業務收入</span><span><span>701</span></span><span>億元，同比增長 10.5%，</span><span>增速</span><span>較 1－10 月份提升 4</span><span><span>個百分點，</span></span><span>高於全國增速 4.4 個百分點。西部地區完成互聯網業務收入 915.9 億元，同比下降 1.6</span><span>%，降幅較 1</span><span>－10 月份擴大 0.2</span><span><span>個百分點。東北地區完成互聯網業務收入</span></span><span>35.3 億元，同比下降 25.9</span><span>%，降幅較 1</span><span>－10 月份收窄 3.2</span><span><span>個百分點。</span></span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><img height="246" src="https://oscimg.oschina.net/oscnet/up-f13b705f77044296551c3a3d3f3473ce1a2.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>長三角</span></strong><strong><span>地區互聯網業務收入</span></strong><strong><span>增速領先</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span><span>，</span></span><span>京津冀地區完成互聯網業務收入 6000 億元，同比增長 5.6%，增速較</span><span>1</span><span>－10 月份提升 0.6 個百分點，佔全國互聯網業務收入的比重為 38.3%。</span><span>長三角</span><span>地區完成互聯網業務收入 5242 億元，同比增長 12.8%，增速較</span><span>1</span><span>－10 月份回落 0.4</span><span><span>個百分點，佔全國互聯網業務收入的比重為</span></span><span>37.5%。</span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><img height="307" src="https://oscimg.oschina.net/oscnet/up-ba7cb957eefa1894ad7636e89bb0f561fa4.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><span><strong><span>半數</span></strong><strong><span>地區互聯網業務</span></strong><strong><span>增速實現正增長</span></strong><strong><span>。</span></strong><span>1</span></span><span>－11 月份</span><span>，互聯網業務累計收入居前</span><span>5 名的</span><span>北京</span><span>（增長 3.2</span><span>%）、上海</span><span>（增長 17.4</span><span>%）、浙江</span><span>（增長 4.8%）、</span><span>廣東</span><span>（下降 6.6%）和天津（增長</span><span><span>19.1</span></span><span>%）共完成業務收入</span><span>13075</span><span>億元，同比增長 6.6</span><span>%，佔全國比重達</span><span>83.</span><span><span>5</span></span><span>%。全國互聯網業務增速實現正增長的省（區、市）有 16 個。</span></p><p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"><img height="242" src="https://oscimg.oschina.net/oscnet/up-196ef056da869e93a9d75c6e816c15b64ef.png" width="500" referrerpolicy="no-referrer"></p><p style="color:#070707; margin-left:2px; margin-right:0; text-align:justify"><span><strong><span>附註：</span></strong>1.規模以上互聯網和相關服務企業口徑由上年互聯網和相</span><span style="color:#070707">關服務收入 500 萬元以上調整為 2000 萬元及以上，文中所有同比增速均按可比口徑計算。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 31 Dec 2023 03:00:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273491</guid>
            <link>https://www.oschina.net/news/273491</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Shiori —— Go 編寫的書籤管理器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Shiori 是一個用 Go 語言編寫的簡單書籤管理器。旨在作為 Pocket&nbsp;的簡單克隆。你可以將其用作命令行應用程序或 Web 應用程序。該應用程序作為單個二進制文件分發，這意味着它可以輕鬆安裝和使用。</p><p><img height="244" src="https://static.oschina.net/uploads/space/2023/0816/150851_4oPv_4252687.png" width="500" referrerpolicy="no-referrer"></p><p><strong>特性：</strong></p><ul><li>基本書籤管理，即添加、編輯、刪除和搜索。</li><li>從 Netscape 書籤文件導入和導出書籤。</li><li>從 Pocket 導入書籤。</li><li>簡單幹淨的命令行界面。</li><li>簡單而漂亮的網絡界面，適合那些不想使用命令行應用程序的人。</li><li>由於其單一二進制格式，因此可移植。</li><li>支持 sqlite3、PostgreSQL 和 MySQL 作為其數據庫。</li><li>如果可能，默認情況下<code>shiori</code>將解析可讀內容並創建網頁的離線存檔。</li><li>[BETA]對 Firefox 和 Chrome 的<a href="https://github.com/go-shiori/shiori-web-ext">網絡擴展支持。</a></li></ul><p><img height="406" src="https://static.oschina.net/uploads/space/2023/0816/151010_pUOz_4252687.png" width="500" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sun, 31 Dec 2023 02:45:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/shiori</guid>
            <link>https://www.oschina.net/p/shiori</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 領先的開源數據庫自治運維平台 openGauss-DBMind]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-dbmind" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#dbmind"></a>DBMind</h1><p><a href="https://gitee.com/opengauss/openGauss-DBMind#dbmind-%E4%B8%AD%E6%96%87">中文</a> | <a href="https://gitee.com/opengauss/openGauss-DBMind#dbmind-engish">English</a></p><p>Maintainer: <a href="mailto:ai@opengauss.org">openGauss AI-SIG</a></p><h1><a id="user-content-dbmind-中文" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#dbmind-%E4%B8%AD%E6%96%87"></a>DBMind-中文</h1><p>DBMind 作為 openGauss 數據庫的一部分，為 openGauss 數據庫提供了自動駕駛能力，是一款領先的開源數據庫自治運維平台。通過 DBMind, 您可以很容易地發現數據庫的問題，同時可以實現秒級的數據庫問題根因分析。</p><p>DBMind 的特點：</p><ul><li>DBMind 採用了先進的插件化的架構形式，支持海量插件擴展；</li><li>支持多種運行模式，具備命令行交互式運行、服務式運行；</li><li>面向雲原生進行設計，支持 Prometheus，並提供多種豐富的 exporter 插件；</li><li>提供豐富的對接模式，可以很容易地與現有管理系統進行對接，支持 RESTful API、Python SDK、命令行、Prometheus 協議等模式；</li><li>支持端到端全流程的數據庫自治運維能力，包括慢 SQL 根因分析、workload 索引推薦、多指標關聯挖掘、故障自修復、異常檢測與根因分析等功能；</li></ul><p>DBMind 支持的主要能力：</p><ul><li>索引推薦</li><li>異常檢測與分析</li><li>多指標關聯分析</li><li>慢 SQL 根因分析</li><li>時序預測</li><li>參數調優與推薦</li><li>SQL 改寫與優化</li><li>故障自動修復</li></ul><p><img src="https://gitee.com/opengauss/openGauss-DBMind/raw/master/docs/dbmind.png" alt="DBMind 架構圖" referrerpolicy="no-referrer"></p><h2><a id="user-content-開始使用 dbmind" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8dbmind"></a>開始使用 DBMind</h2><h3><a id="user-content-下載並安裝 dbmind" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E4%B8%8B%E8%BD%BD%E5%B9%B6%E5%AE%89%E8%A3%85dbmind"></a>下載並安裝 DBMind</h3><p>DBMind 基於 Python 語言實現，在使用 DBMind 時，需要運行環境具備 Python 虛擬機，同時安裝好所需的第三方依賴。</p><h4><a id="user-content-方式一直接下載代碼部署" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E6%96%B9%E5%BC%8F%E4%B8%80%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E4%BB%A3%E7%A0%81%E9%83%A8%E7%BD%B2"></a>方式一：直接下載代碼部署</h4><p>DBMind 主要使用 Python 語言進行編寫，因此，可以在下載獲取 DBMind 的源代碼後，使用操作系統上安裝的 Python 虛擬機直接運行，不過該過程中的第三方依賴需要用戶手動安裝。</p><p>用戶可以通過 <code>git clone</code> 命令從 Gitee 或者 Github 上下載代碼，例如：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">git clone --depth 1 https://gitee.com/opengauss/openGauss-DBMind.git</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>也可以通過 Gitee 或者 Github 提供的 zip 包下載路徑進行下載，而後解壓縮該 zip 包即可。</p><p>下載 DBMind 後，會產生一個名為 <code>openGauss-DBMind</code> 的目錄， 將該目錄的路徑添加到環境變量<code>PATH</code>中，即可調用該目錄中的可執行文件。例如可以執行下述命令完成：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">chmod +x openGauss-DBMind/gs_dbmind</span><span id="LC2" class="line"></span><span id="LC3" class="line">echo PATH=`pwd`/openGauss-DBMind:'$PATH' &gt;&gt; ~/.bashrc</span><span id="LC4" class="line">echo 'export PATH' &gt;&gt; ~/.bashrc</span><span id="LC5" class="line"></span><span id="LC6" class="line">source ~/.bashrc</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-方式二使用安裝包進行部署" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E6%96%B9%E5%BC%8F%E4%BA%8C%E4%BD%BF%E7%94%A8%E5%AE%89%E8%A3%85%E5%8C%85%E8%BF%9B%E8%A1%8C%E9%83%A8%E7%BD%B2"></a>方式二：使用安裝包進行部署</h4><p>DBMind 會定期在 openGauss-DBMind 項目的 release 頁面發佈 DBMind 的安裝包，可以通過下載該 DBMind 安裝包進行安裝部署。該安裝包會自動將 DBMind 解壓到指定目錄，並配置好環境變量。</p><p>安裝包和校驗碼的下載地址為：</p><table><thead><tr><th>Name</th><th>Download</th><th>Remarks</th></tr></thead><tbody><tr><td>DBMind X86</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fopengauss.obs.cn-south-1.myhuaweicloud.com%2Flatest%2Fdbmind%2Fx86%2Fdbmind-installer-x86_64-python3.11.sh.tar.gz">dbmind-installer-x86_64-python3.11.sh.tar.gz</a></td><td>X86 架構下 DBMind 安裝包</td></tr><tr><td>DBMind X86 SHA256</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fopengauss.obs.cn-south-1.myhuaweicloud.com%2Flatest%2Fdbmind%2Fx86%2Fdbmind-installer-x86_64-python3.11.sh.tar.gz.sha256">dbmind-installer-x86_64-python3.11.sh.tar.gz.sha256</a></td><td>DBMind X86 安裝包 SHA256 校驗文件</td></tr><tr><td>DBMind ARM</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fopengauss.obs.cn-south-1.myhuaweicloud.com%2Flatest%2Fdbmind%2Farm%2Fdbmind-installer-aarch64-python3.11.sh.tar.gz">dbmind-installer-aarch64-python3.11.sh.tar.gz</a></td><td>ARM 架構下 DBMind 安裝包</td></tr><tr><td>DBMind ARM SHA256</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fopengauss.obs.cn-south-1.myhuaweicloud.com%2Flatest%2Fdbmind%2Farm%2Fdbmind-installer-aarch64-python3.11.sh.tar.gz.sha256">dbmind-installer-aarch64-python3.11.sh.tar.gz.sha256</a></td><td>DBMind ARM 安裝包 SHA256 校驗文件</td></tr></tbody></table><p>安裝包使用：</p><p>  解壓：tar zxvf dbmind-installer-x86_64-python3.11.sh.tar.gz</p><p>  DBMind 安裝: sh dbmind-installer-x86_64-python3.11.sh</p><h4><a id="user-content-關於 python 運行環境" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E5%85%B3%E4%BA%8Epython%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83"></a>關於 Python 運行環境</h4><p>需要至少為 Python3.7 的版本。雖然在 DBMind 的實現中對 Python3.7 以下的環境儘可能地進行了兼容，但是這些低版本的 Python 環境疏於測試，可能會引發意料之外的異常。同時，在 DBMind 啓動時，也會嘗試校驗 Python 版本，如果 Python 版本不符合要求，則默認不會繼續執行後續的動作。</p><p><em>DBMind 的 Python 版本由根目錄下的 constant 文件中的變量做約束</em></p><p>如果您的環境需要安裝多個版本的 Python 運行時，並且它們可能會引起衝突，那麼我們建議您將 DBMind 所需的 Python 運行環境安裝到 DBMind 根目錄下的 <code>python</code> 目錄中，DBMind 會優先選擇使用在其根目錄下 <code>python</code> 目錄中的環境。即 <code>gs_dbmind</code> 命令會首先在<code>python/bin</code> 目錄下尋找 <code>python3</code> 命令執行後續的 Python 功能。</p><h4><a id="user-content-關於第三方依賴" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E5%85%B3%E4%BA%8E%E7%AC%AC%E4%B8%89%E6%96%B9%E4%BE%9D%E8%B5%96"></a>關於第三方依賴</h4><p>DBMind 所使用的第三方依賴通過 DBMind 根目錄下的 <code>requirements-xxx.txt</code> 文件指定。對於 x86 架構（amd64）以及 ARM 架構（aarch64），使用了不同的文件名進行標識。這是因為 ARM 平台對於某些第三方依賴並不友好，必須指定特定的版本才可以安裝。</p><p>可以使用 pip 工具對第三方依賴進行安裝。與前文所述的情況類似，如果您當前的操作系統不得不安裝多個 Python 運行環境，那麼，DBMind 也支持對第三方依賴進行優先選擇。即可以將第三方依賴庫存儲到 DBMind 根目錄下的 <code>3rd</code> 目錄中。 在通過 <code>gs_dbmind</code> 命令使用 DBMind 功能時，會優先選擇該目錄下的 <code>3rd</code> 目錄中的第三方依賴庫進行加載。</p><p>以 x86 環境為例，可以使用下述<code>pip</code>命令安裝 DBMind 的第三方依賴庫：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">python3 -m pip install -r requirements-x86.txt</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>如果希望指定下載的第三方依賴庫地址，則可以通過 <code>--target</code> 或 <code>-t</code> 選項進行指定，例如</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">python3 -m pip install -r requirements-x86.txt -t 3rd</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-使用 dbmind" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E4%BD%BF%E7%94%A8dbmind"></a>使用 DBMind</h3><h4><a id="user-content-部署 prometheus" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E9%83%A8%E7%BD%B2prometheus"></a>部署 Prometheus</h4><p>可以通過 <a href="https://gitee.com/link?target=https%3A%2F%2Fprometheus.io%2F">Prometheus</a> 官方網站獲取下載方式，下載並部署 Prometheus，以便彙集對 openGauss 實例的監控結果。</p><h4><a id="user-content-部署 node-exporter" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E9%83%A8%E7%BD%B2node-exporter"></a>部署 Node Exporter</h4><p>下載並啓動 <a href="https://gitee.com/link?target=https%3A%2F%2Fprometheus.io%2Fdownload%2F%23node_exporter">Prometheus node exporter</a>.</p><p>Node exporter 可以用於監控 Linux 系統，因此每個 Linux 環境（或容器內）只需要部署一個實例即可。</p><h3><a id="user-content-啓動-dbmind-組件" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E5%90%AF%E5%8A%A8-dbmind-%E7%BB%84%E4%BB%B6"></a>啓動 DBMind 組件</h3><p>如果希望將 DBMind 作為後台服務運行，則下面的 DBMind 組件是必須安裝的，否則獲取不到數據庫的監控信息。為了獲得更高的安全機制，DBMind 提供的 exporter 默認是使用 Https 協議的，如果您覺得您的場景中不需要使用 Https 協議，則可以通過 <code>--disable-https</code> 選項禁用。</p><h4><a id="user-content-opengauss-exporter" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#opengauss-exporter"></a>openGauss Exporter</h4><p>openGauss exporter 從 openGauss 數據庫中讀取系統表（或系統視圖）的數據，並通過 Prometheus 存儲起來。由於 openGauss exporter 需要讀取監控數據庫的系統表信息，因此至少應該具備 <strong>monadmin</strong> 權限。例如，可以通過下述 SQL 語句為名為 <code>dbmind_monitor</code> 用戶賦予權限：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">ALTER USER dbmind_monitor monadmin;</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>使用 <code>gs_dbmind component opengauss_exporter ...</code> 命令即可啓動該 openGauss exporter 組件。例如，可以通過下述命令監控某個數據庫，通過 <code>--url</code> 參數指定被監控的數據庫實例地址：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component opengauss_exporter --url postgresql://username:password@host:port/database --web.listen-address 0.0.0.0 --web.listen-port 9187 --log.level warn --disable-https ...</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><code>--url</code> 表示的是數據庫的 DSN 地址，其格式可以<a href="https://gitee.com/opengauss/openGauss-DBMind#dsn%E7%9A%84%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E">參考此處</a>。</p><p>可以通過下述命令檢查 openGauss exporter 是否已經啓動：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">curl -vv http://localhost:9187/metrics</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-reprocessing-exporter" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#reprocessing-exporter"></a>Reprocessing Exporter</h4><p>reprocessing exporter 是一個用於二次加工處理數據的 exporter. 由於 node exporter、openGauss exporter 保存到 Prometheus 中的數據是即時的監控信息，而只通過這些信息是無法反應某些指標的瞬時增量信息的，例如 TPS、iops 信息等。因此，reprocessing exporter 可以用來計算增量信息或者聚合結果等。</p><p>由於 reprocessing 是從 Prometheus 中獲取指標數據，進行二次加工處理後再返回給 Prometheus. 因此，它與 Prometheus 是一一對應的，即如果只有一個 Prometheus 服務，則只需要一個 reprocessing exporter 即可。例如，可以通過下述命令啓動 reprocessing exporter:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component reprocessing_exporter 127.0.0.1 9090 --web.listen-address 0.0.0.0 --web.listen-port 9189</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>如果您的 Prometheus 使用了<code>basic authorization</code>方式進行登錄校驗，則需要額外指定 <code>--prometheus-auth-user</code> 以及 <code>--prometheus-auth-password</code> 選項的值。</p><h3><a id="user-content-配置以及啓動" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E5%90%AF%E5%8A%A8"></a>配置以及啓動</h3><p>DBMind 後台服務是常駐內存的。因此，您需要首先配置一個配置文件目錄，在該目錄中保存多個 DBMind 的配置文件。可以通過 <code>gs_dbmind service</code> 命令來進行配置文件目錄的生成以及服務的啓動。該命令的使用説明為：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">$ gs_dbmind service --help</span><span id="LC2" class="line">usage:  service [-h] -c DIRECTORY [--only-run {...}] [--interactive | --initialize] {setup,start,stop}</span><span id="LC3" class="line"></span><span id="LC4" class="line">positional arguments:</span><span id="LC5" class="line">  {setup,start,stop}    perform an action for service</span><span id="LC6" class="line"></span><span id="LC7" class="line">optional arguments:</span><span id="LC8" class="line">  -h, --help            show this help message and exit</span><span id="LC9" class="line">  -c DIRECTORY, --conf DIRECTORY</span><span id="LC10" class="line">                        set the directory of configuration files</span><span id="LC11" class="line">  --only-run {slow_query_diagnosis,forecast}</span><span id="LC12" class="line">                        explicitly set a certain task running in the backend</span><span id="LC13" class="line">  --interactive         configure and initialize with interactive mode</span><span id="LC14" class="line">  --initialize          initialize and check configurations after configuring.</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>下面，分別介紹配置文件目錄生成，以及服務的啓停操作。</p><h4><a id="user-content-配置 dbmind" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E9%85%8D%E7%BD%AEdbmind"></a>配置 DBMind</h4><p>DBMind 提供兩種方式進行配置文件的生成。一種是交互式的，通過 <code>--interactive</code> 選項指定；另一種則需要用戶自己手動來修改，這也是默認方式。</p><p><strong>交互式配置方式</strong></p><p>下面是一些使用示例，這裏我們用 <code>CONF_DIRECTORY</code> 標識我們的配置文件目錄：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service setup -c CONF_DIRECTORY --interactive</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>通過上述命令，用戶可以在交互式界面中，根據提示信息輸入需要監控的 openGauss 實例信息和參數。</p><p><strong>手動配置方式</strong></p><p>下面的命令演示瞭如何通過手動方式進行 DBMind 配置：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service setup -c CONF_DIRECTORY</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>在執行完上述命令後，會生成一個名為 <code>CONF_DIRECTORY</code> 的目錄，這個目錄裏麪包含有很多的配置文件。不過，用戶需要配置 <code>CONF_DIRECTORY/dbmind.conf</code> 文件即可。當用戶配置完該文件後，則需要執行一下下述命令，DBMind 會根據用戶剛剛配置的信息初始化 DBMind 系統：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service setup -c CONF_DIRECTORY --initialize</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-啓動與停止 dbmind 服務" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E5%90%AF%E5%8A%A8%E4%B8%8E%E5%81%9C%E6%AD%A2dbmind%E6%9C%8D%E5%8A%A1"></a>啓動與停止 DBMind 服務</h4><p>當用戶配置完 DBMind 數據庫後，則可以直接通過下述命令啓動 DBMind 後台服務：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service start -c CONF_DIRECTORY</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>通過下述命令關閉 DBMind 服務：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service stop -c CONF_DIRECTORY</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-dbmind 的組件" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#dbmind%E7%9A%84%E7%BB%84%E4%BB%B6"></a>DBMind 的組件</h3><p>如前文所述，DBMind 基於一種插件化設計，這個組件（component）即為 DBMind 提供的插件（plugin）。通過插件式設計，DBMind 可以任意進行功能擴展。如果想要使用某個組件的功能，則需要執行<code>component</code>子命令。例如某個名為<code>xtuner</code>的組件可以進行數據的參數調優，那麼可以執行下述命令來使用<code>xtuner</code>的功能。</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component xtuner --help</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-使用 docker 運行 dbmind" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E4%BD%BF%E7%94%A8docker%E8%BF%90%E8%A1%8Cdbmind"></a>使用 Docker 運行 DBMind</h3><p>DBMind 支持 Docker, 同時也會在 Docker Hub 上定期發佈 openGauss-DBMind 的 docker 鏡像，鏡像的地址是：</p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fhub.docker.com%2Fr%2Fdbmind%2Fopengauss_dbmind">https://hub.docker.com/r/dbmind/opengauss_dbmind</a></p><p>可以通過下述命令拉取該鏡像：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">docker pull dbmind/opengauss_dbmind</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-創建 docker 鏡像" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E5%88%9B%E5%BB%BAdocker%E9%95%9C%E5%83%8F"></a>創建 Docker 鏡像</h4><p>在某些情況下，您可能希望手動創建 DBMind 的 docker 鏡像，例如想要創建基於最新代碼的鏡像時。那麼，可以通過 DBMind 代碼根目錄下的 Dockerfile 文件創建。例如在 DBMind 的根目錄中執行下述命令，即可創建名為 <code>opengauss_dbmind</code> 的鏡像：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">docker build -t opengauss_dbmind .</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-docker-鏡像的使用" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#docker-%E9%95%9C%E5%83%8F%E7%9A%84%E4%BD%BF%E7%94%A8"></a>Docker 鏡像的使用</h4><p>DBMind 的 docker 鏡像的默認執行文件是 <code>docker_run.py</code>，該啓動腳本可以在容器中啓動 DBMind 所需的大多數依賴服務，包括 Prometheus, openGauss exporter, reprocessing exporter. 但是，卻無法在該鏡像容器內運行 node exporter 來監控遠端服務器上的信息。</p><p>用戶可以通過下述環境變量，將需要監控的 openGauss 服務信息傳遞給 DBMind 的 docker 鏡像：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">OPENGAUSS_DSNS: 需要監控的 openGauss 數據庫實例的 DSN 信息，多個 DSN 信息用逗號 (,) 隔開</span><span id="LC2" class="line">NODE_EXPORTERS: openGauss 數據庫實例所在機器的 node exporter 地址，多個地址用逗號 (,) 隔開</span><span id="LC3" class="line">METADATABASE: 可選，將 DBMind 的離線計算結果存儲起來的位置，用 DSN 形式標識數據庫的連接信息；若為空，則默認使用 SQLite 進行存儲</span><span id="LC4" class="line">SCRAPE_INTERVAL: 可選，指標信息的採集間隔，單位是秒；默認為 15 秒</span><span id="LC5" class="line">MASTER_USER: 可選，具有管理員權限的數據庫用戶名，可以用來執行某些數據庫變更動作或者查詢當前數據庫的即時狀態信息；若為空，則採用 OPENGAUSS_DSNS 中提供的用戶</span><span id="LC6" class="line">MASTER_USER_PWD: 可選，上述 MASTER_USER 對應的用戶密碼</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>注：DSN 的配置格式可以參考<a href="https://gitee.com/opengauss/openGauss-DBMind#dsn%E7%9A%84%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E">常見問題</a>中的説明。</p><p>使用<code>docker run</code>的<code>-v</code>參數可以將路徑進行映射，docker 容器內的日誌統一寫到 <code>/log</code> 目錄中，持久化的數據統一存放在 <code>/data</code> 目錄中。使用 <code>-p</code> 參數可以將容器內的端口號進行映射，Prometheus 的容器內端口是 9090, DBMind 的 web 服務則使用 8080 端口。下面是個啓動 docker 服務的例子：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">docker run -it \</span><span id="LC2" class="line">    -e OPENGAUSS_DSNS="dbname=postgres user=dbmind_monitor password=DBMind@123 port=6789 host=192.168.1.100, dbname=postgres user=dbmind_monitor password=DBMind@123 port=6789 host=192.168.1.101, dbname=postgres user=dbmind_monitor password=DBMind@123 port=6789 host=192.168.1.102" \</span><span id="LC3" class="line">    -e NODE_EXPORTERS="http://192.168.1.100:9100,http://192.168.1.101:9100,http://192.168.1.102:9100" \</span><span id="LC4" class="line">    -e METADATABASE='postgresql://dbmind_metadb:DBMind%40123@192.168.1.100:6789/dbmind_metadb' \</span><span id="LC5" class="line">    -e MASTER_USER='dbmind_sys' \</span><span id="LC6" class="line">    -e MASTER_USER_PWD='DBMind@123' \</span><span id="LC7" class="line">    -e SCRAPE_INTERVAL=30 \</span><span id="LC8" class="line">    -p 38080:8080 -p 39090:9090 \</span><span id="LC9" class="line">    -v `pwd`/data:/data -v `pwd`/log:/log \</span><span id="LC10" class="line">    dbmind/opengauss_dbmind </span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>上面的例子是一主二備節點的部署形態，他們的 IP 地址分別是<code>192.168.1.100</code>、<code>192.168.1.101</code>以及<code>192.168.1.102</code>，數據庫的端口號都是 6789. 上面我們使用了三個用戶，為了方便演示，它們的密碼都設置為<code>DBMind@123</code>。其中<code>dbmind_monitor</code>負責從 openGauss 數據庫中抓取指標監控，需要具備 <code>monitor admin</code>權限；<code>dbmind_sys</code> 至少需要具備 <code>monitor admin</code>權限，以便可以獲取數據庫的即時狀態，如果具備<code>sysadmin</code>權限，則可以完成一些數據庫變更動作，如慢 SQL 查殺；<code>dbmind_metadb</code> 只是負責數據保存，具備指定數據庫的使用權限即可；同時，這裏也進行了端口和目錄的映射。</p><p>如果希望使用命令行的形式運行 DBMind，則可以直接在該 docker 鏡像內調用 <code>gs_dbmind</code> 命令即可，Python 運行時和第三方依賴等都已經打包在 docker 鏡像中了，無需再次安裝。例如，希望使用 DBMind 的參數調優組件提供的功能，則可以執行下述命令：</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">docker run -it dbmind/opengauss_dbmind \</span><span id="LC2" class="line">   gs_dbmind component xtuner recommend \</span><span id="LC3" class="line">   --database tpcds \</span><span id="LC4" class="line">   --db-host 192.168.1.100 \</span><span id="LC5" class="line">   --host-user omm \</span><span id="LC6" class="line">   --db-user tpcds \</span><span id="LC7" class="line">   --db-port 16000</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>注：在使用<code>docker run</code> 命令運行 <code>gs_dbmind</code> 時，需要指定 <code>-it</code> 參數，以便創建一個 tty.</p><h2><a id="user-content-常見問題" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"></a>常見問題</h2><h3><a id="user-content-dsn 的格式説明" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#dsn%E7%9A%84%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E"></a>DSN 的格式説明</h3><p>DSN 是 Database Source Name 的縮寫，這裏支持兩種格式，一種是 K-V 格式，如<code>dbname=postgres user=username password=password_value port=6789 host=127.0.0.1</code>；另一種是 URL 形式，例如<code>postgresql://username:password_value@127.0.0.1:6789/postgres</code>；對於採用 URL 格式的 DSN，由於<code>@</code>等特殊字符用來分割 URL 串中各個部分的內容，故需要 URL 編碼（URL encode）。例如某個用戶<code>dbmind</code>的密碼為<code>DBMind@123</code>，則 URL 形式的 DSN 可以是<code>postgresql://dbmind:DBMind%40123@127.0.0.1:6789</code>，即將<code>@</code>字符編碼為<code>%40</code>. 類似地，需要編碼的字符還包括其他可能引起歧義的字符，如<code>/</code>, <code>\</code>, <code>?</code>, <code>&amp;</code>.</p><h2><a id="user-content-相關資料" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99"></a>相關資料</h2><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fdocs.opengauss.org%2Fzh%2Fdocs%2Flatest%2Fdocs%2FDeveloperguide%2FAI4DB-%25E6%2595%25B0%25E6%258D%25AE%25E5%25BA%2593%25E8%2587%25AA%25E6%25B2%25BB%25E8%25BF%2590%25E7%25BB%25B4.html">openGauss 在線手冊</a></li><li><a href="https://gitee.com/opengauss/openGauss-DBMind/wikis">DBMind wiki</a></li><li><a href="mailto:ai@opengauss.org">openGauss AI-SIG</a></li></ul><hr><h1><a id="user-content-dbmind-engish" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#dbmind-engish"></a>DBMind-Engish</h1><p>DBMind is a part of openGauss, which empowers openGauss to carry the autonomous operations and maintenance capabilities. DBMind is leading and open-source. Through DBMind, users can easily discover database problems and the root causes of the problems in seconds.</p><p><img src="https://gitee.com/opengauss/openGauss-DBMind/raw/master/docs/dbmind.png" alt="DBMind overview" referrerpolicy="no-referrer"></p><h2><a id="user-content-getting-started" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#getting-started"></a>Getting Started</h2><h3><a id="user-content-prerequisites" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#prerequisites"></a>Prerequisites</h3><p>In order to run DBMind, the following components should be configured and running.</p><h4><a id="user-content-python-runtime" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#python-runtime"></a>Python Runtime</h4><p>At least Python 3.7.</p><h4><a id="user-content-third-party-dependencies" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#third-party-dependencies"></a>Third-party Dependencies</h4><p>Use <code>pip3 install</code> to install the python dependencies.
Type the <code>pip3 install</code> command with dependencies according to the environment you are running:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">pip install -r requirements-aarch64.txt | requirements-x86.txt</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-prometheus-up-and-running" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#prometheus-up-and-running"></a>Prometheus up and Running</h4><p>Download and run the <a href="https://gitee.com/link?target=https%3A%2F%2Fprometheus.io%2F">Prometheus</a> time-series database.</p><h4><a id="user-content-node-exporter" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#node-exporter"></a>Node Exporter</h4><p>Download and run the <a href="https://gitee.com/link?target=https%3A%2F%2Fprometheus.io%2Fdownload%2F%23node_exporter">Prometheus node exporter</a>. Node-exporter is to monitor the Linux system. Hence, one Linux environment only needs to deploy one node-exporter.</p><h3><a id="user-content-dbmind-components" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#dbmind-components"></a>DBMind Components</h3><p>The following DBMind components are required:</p><p><strong>Note: If you want to get higher security, you should use the HTTPS scheme.</strong></p><h4><a id="user-content-opengauss-exporter-1" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#opengauss-exporter-1"></a>openGauss Exporter</h4><p>The openGauss-exporter reads data from the database and places it on the Prometheus time-series database.
OpenGauss-exporter is to monitor only one database instance. So if your deployment environment has not only one instance, you should start multiple openGauss-exporters to correspond to monitor multiple database instances.
It needs database access with a user having the role of at least <strong>monadmin</strong> (monitoring administrator) granted to run it. For example, you can grant monadmin privilege to role dbmind as below:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">ALTER USER dbmind monadmin;</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Use the following command with the parameters below:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component opengauss_exporter ...</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>You can get detailed explanations of this component through passing <code>--help</code>:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component opengauss_exporter --help</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>For example, the following command starts it:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component opengauss_exporter --url postgresql://username:password@host:port/database --web.listen-address 0.0.0.0 --web.listen-port 9187 --log.level warn --disable-https ...</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>To test that the exporter is up, type the following command on its host (or use change the localhost to the server address):</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">curl -vv http://localhost:9187/metrics</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-reprocessing-exporter-1" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#reprocessing-exporter-1"></a>Reprocessing Exporter</h4><p>Reprocessing-exporter is a re-processing module for metrics stored in the Prometheus server. It helps Prometheus to reprocess the metric data then dump the new data into Prometheus. Therefore, only one needs to be started in a deployment environment.
To run it use the command below:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component reprocessing_exporter ...</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Users can see usage by using <code>--help</code> too.</p><p>See this example for running the exporter in a single machine development environment:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component reprocessing_exporter 127.0.0.1 9090 --web.listen-address 0.0.0.0 --web.listen-port 9189</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Use the following command to check that the service is up:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">curl http://127.0.0.1:9189/metrics</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-configure-start-and-stop-the-dbmind-service" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#configure-start-and-stop-the-dbmind-service"></a>Configure, Start and Stop the DBMind Service</h3><p>DBMind service is a memory-resident backend service. Therefore, users should configure it first then start or stop the service by using the configuration.</p><p>Service usages:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">$ gs_dbmind service --help</span><span id="LC2" class="line">usage:  service [-h] -c DIRECTORY [--only-run {slow_query_diagnosis,forecast,anomaly_detection,alarm_log_diagnosis,index_recommendation,knob_recommendation}] [--dry-run] [-f]</span><span id="LC3" class="line">                [--interactive | --initialize]</span><span id="LC4" class="line">                {setup,start,stop,restart}</span><span id="LC5" class="line"></span><span id="LC6" class="line">positional arguments:</span><span id="LC7" class="line">  {setup,start,stop,restart}</span><span id="LC8" class="line">                        perform an action for service</span><span id="LC9" class="line"></span><span id="LC10" class="line">optional arguments:</span><span id="LC11" class="line">  -h, --help            show this help message and exit</span><span id="LC12" class="line">  -c DIRECTORY, --conf DIRECTORY</span><span id="LC13" class="line">                        set the directory of configuration files</span><span id="LC14" class="line">  --only-run {slow_query_diagnosis,forecast,anomaly_detection,alarm_log_diagnosis,index_recommendation,knob_recommendation}</span><span id="LC15" class="line">                        explicitly set a certain task running in the backend</span><span id="LC16" class="line">  --dry-run             run the backend task(s) once. the task to run can be specified by the --only-run argument</span><span id="LC17" class="line">  -f, --force           force to stop the process and cancel all in-progress tasks</span><span id="LC18" class="line">  --interactive         configure and initialize with interactive mode</span><span id="LC19" class="line">  --initialize          initialize and check configurations after configuring.</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-configure" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#configure"></a>Configure</h4><p>DBMind offers two methods to configure. The one is an interactive mode by using <code>--interactive</code> argument, the other is a modification by hands.</p><p>See this example for configuring in the interactive mode:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service setup -c CONF_DIRECTORY --interactive</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>Then users can type parameters into the shell terminal.</p><p>See the following example for configuring by hands:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service setup -c CONF_DIRECTORY</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>After executing the above command, the directory <code>CONF_DIRECTORY</code> will generate too many configuration files. Therefore, users should modify these parameters in the <code>CONF_DIRECTORY/dbmind.conf</code>. While users finish configuring, this command needs to be run to initialize DBMind according to the <code>CONF_DIRECTORY/dbmind.conf</code>.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service setup -c CONF_DIRECTORY --initialize</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="user-content-start-or-stop-the-dbmind-service" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#start-or-stop-the-dbmind-service"></a>Start or Stop the DBMind Service</h4><p>After configuring, specify your CONF_DIRECTORY, users can start or stop the service directly.</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind service start/stop -c CONF_DIRECTORY</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-component" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#component"></a>Component</h3><p>If users want to use a specific component offline. They can use the sub-command <code>component</code>:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component xxx ...</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><code>xxx</code> is the name of a component. Users can also get the component list by using the <code>--help</code> argument.</p><p>For example, use the following component to tune the knobs of a database:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">gs_dbmind component xtuner --help</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h1><a id="user-content-license" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#license"></a>LICENSE</h1><p>Mulan PSL v2</p><h1><a id="user-content-reference" class="anchor" href="https://gitee.com/opengauss/openGauss-DBMind#reference"></a>Reference</h1><ol><li><a href="https://gitee.com/link?target=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPercent-encoding">https://en.wikipedia.org/wiki/Percent-encoding</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fdba.stackexchange.com%2Fquestions%2F243219%2Fin-postgresql-url-i-cant-use-a-password-containing-special-characters">https://dba.stackexchange.com/questions/243219/in-postgresql-url-i-cant-use-a-password-containing-special-characters</a></li></ol>]]>
            </description>
            <pubDate>Sun, 31 Dec 2023 02:37:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/opengauss/openGauss-DBMind</guid>
            <link>https://gitee.com/opengauss/openGauss-DBMind</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 反向 Debug 瞭解一下？揭祕 Java DEBUG 的基本原理]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Debug 的時候，都遇到過手速太快，直接跳過了自己想調試的方法、代碼的時候吧……</p><p>一旦跳過，可能就得重新執行一遍，準備數據、重新啓動可能幾分鐘就過去了。</p><p><img alt="Untitled.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-08oleiHOrAlh8kTie.png" referrerpolicy="no-referrer"></p><p>好在 IDE 們都很強大，還給你後悔的機會，可以直接刪除某個 Stack Frame，直接返回到之前的狀態，確切的説是返回到之前的某個 Stack Frame，從而實現讓程序「逆向運行」。</p><p><img alt="Untitled 1.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-08tZjMjyHSbNdpAu8.png" referrerpolicy="no-referrer"></p><p>這個 Reset Frame 的能力，可不只是返回上一步，上 N 步也是可以的；選中你期望的那個幀，直接 Reset Frame/Drop Frame，可以直接回到調用棧上的某個棧幀，時間反轉！</p><p>可惜這玩意也不是那麼萬能，畢竟是通過 stack pop 這種操作實現，實際上只是給調用棧棧頂的 N 個 frame pop 出來而已，還談不上是真正的「反向 DEBUG」。</p><p>相比之下， GDB 的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sourceware.org%2Fgdb%2Fnews%2Freversible.html" rel="nofollow" target="_blank">Reverse Debugging</a>就比較強大，真正的 「反向」 DEBUG，逆向運行，實現回放。</p><p>所以吧在運行過程中，已經修改的數據，比如引用傳遞的方法參數、變量，一旦修改肯定回退不了，不然真的成時光機了。</p><p>這些亂七八糟的調試功能，都是基於 Java 內置的 Debug 體系來實現的。</p><span id="OSC_h1_1"></span><h1>JAVA DEBUG 體系</h1><p>Java 提供了一個完整的 Debug 體系<strong>JPDA</strong>(Java Platform Debugger Architecture)，這個 JPDA 架構體系由 3 部分組成：</p><ol><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.oracle.com%2Fjavase%2F8%2Fdocs%2Ftechnotes%2Fguides%2Fjvmti%2Findex.html" rel="nofollow" target="_blank">JVM TI</a>- Java VM Tool Interface</p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.oracle.com%2Fjavase%2F8%2Fdocs%2Ftechnotes%2Fguides%2Fjpda%2Fjdwp-spec.html" rel="nofollow" target="_blank">JDWP</a>- Java Debug Wire Protocol</p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.oracle.com%2Fjavase%2F8%2Fdocs%2Fjdk%2Fapi%2Fjpda%2Fjdi%2Findex.html" rel="nofollow" target="_blank">JDI</a>- Java Debug Interface</p></li></ol><p>如果結合 IDE 來看，那麼一個完整的 Debug 功能看起來就是這個樣子：</p><p><img alt="Untitled 2.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-08129VuqLlh19HeCExh.png" referrerpolicy="no-referrer"></p><p>解釋一下這個體系：</p><p>JVM TI 是一個 JVM 提供的一個調試接口，提供了一系列控制 JVM 行為的功能，比如分析、調試、監控、線程分析等等。也就是説，這個接口定義了一系列調試分析功能，而 JVM 實現了這個接口，從而提供調試能力。</p><p>不過吧，這個接口畢竟是 C++的，調用起來確實不方便，所以 Java 還提供了 JDI 這麼個 Java 接口。</p><p>JDI 接口使用 JDWP 這個私有的應用層協議，通過 TCP 和目標 VM 的 JVMTI 接口進行交互。</p><p>也可以把簡單這個 JDWP 協議理解為 JSF/Dubbo 協議；相當於 IDE 裏通過 JDI 這個 SDK，使用 JDWP 協議調用遠程 JVMTI 的 RPC 接口，來傳輸調試時的各種斷點、查看操作。</p><p>可能有人會問，搞什麼套殼！要什麼 JDWP，我直接 JVMTI 調試不是更香，鏈路越短性能越高！</p><p>當然可以，比如 Arthas 裏的部分功能，就直接使用了 JVMTI 接口，要什麼 JDI！直接 JVMTI 幹就完了。</p><p>開個玩笑，Arthas 畢竟不是 Debug 工具，人家根本就不用 JDI 接口。而且 JVMTI 的能力也不只是斷點，它的功能非常多：</p><p><img alt="Untitled 3.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-0819od43PdyVrEOjtTP.png" referrerpolicy="no-referrer"></p><p>左邊的功能類，提供了各種亂七八糟的功能，比如我們常用的添加一個斷點：</p><pre><code>jvmtiError
SetBreakpoint(jvmtiEnv* env,
            jmethodID method,
            jlocation location)

</code></pre><p>右邊的事件類，可以簡單的理解為回調；還是拿斷點舉例，如果我用上面的 SetBreakpoint 添加了一個斷點，那麼當執行到該位置時，就會觸發這個事件:</p><pre><code>void JNICALL
Breakpoint(jvmtiEnv *jvmti_env,
            JNIEnv* jni_env,
            jthread thread,
            jmethodID method,
            jlocation location)

</code></pre><p>JVMTI 的功能非常之多，而 JDI 只是實現了部分 JVMTI 的方法，所以某些專業的 Profiler 工具，可能會直接使用 JVMTI，從而實現更豐富的診斷分析功能。</p><span id="OSC_h1_2"></span><h1>遠程調試與本地調試</h1><p>不知道大家有沒有留意過本地 Debug 啓動時的日誌：</p><p><img alt="Untitled 4.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-08UAIUfwqu8mWHWTH.png" referrerpolicy="no-referrer"></p><p>第一行是隱藏了後半段的啓動命令，展開後是這個樣子：</p><pre><code>/path/to/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:53631,suspend=y,server=n -javaagent:/path/to/jetbrains/debugger-agent.jar ...

</code></pre><p>第二行是一個 Connected 日誌，意思是使用 socket 連接到遠程 VM 的 53631 端口</p><p>上一段説到，IDE 通過 JDI 接口，使用 JDWP 協議和目標 VM 的 JVMTI 交互。這裏的 53631 端口，就是目標 JVM 暴露出的 JVM TI 的 server 端口。</p><p>而第一行裏，IDEA 自動給我們加上了<code>-agentlib:jdwp=transport=dt_socket,address=127.0.0.1:53631</code>這麼一段，這個參數的意思就是，讓 jvm 以 53631 暴露 jdwp 協議</p><p>小知識，這個 agentlib 可不只是為 jvmti 提供的。它還可以讓 JVM 加載其他的 native lib 包，直接「外掛」到你的 jvm 上，下面是「外掛」的參數格式：</p><p><img alt="Untitled 5.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-08Vy0912rKBUuOBMye.png" referrerpolicy="no-referrer"></p><p>所以吧，上面的描述其實不太嚴謹，更專業的説法是：</p><p>讓 JVM 加載 JDWP 這個 agent 庫，參數為<code>transport=dt_socket,address=127.0.0.1:53631</code>，這個 jdwp agent 庫以 53631 端口提供了 jdwp 協議的 server。只不過這個 jdwp 是 jvm 內部的庫，不需要額外的 so/dylib/dll 文件。</p><p>如有需要，你完全可以弄個 「datupiao」 的 agentlib，「外掛」到這個 jvm 上，然後在這個 lib 裏調用 JVMTI 接口，然後暴露個端口提供服務和遠程交互，實現自己的 jdwp！</p><p>可能某些老闆們注意到了，本地調試還要 127.0.0.1 走 tcp 交互一遍，那遠程調試呢？</p><p>基於上面的解釋，本地調試和遠程調試真的沒啥區別！或者説，在目前 IDEA/Eclipse 的實現下，不存在本地調試，都是遠程！只不過一個是 127.0.0.1，一個是遠程的 IP 而已。</p><p>在本地調試時，IDEA 會自動給我們的 JVM 增加<code>agent</code>參數，隨機指定一個端口，然後通過 JDI 接口連接，代碼大概長這樣（JDI 的 SDK 在 JDK_HOME/lib/tools.jar ）：</p><pre><code>Map&lt;String, Connector.Argument&gt; env = connector.defaultArguments();
env.get("hostname").setValue(hostname);
env.get("port").setValue(port);

VirtualMachine vm = connector.attach(env);

</code></pre><p>瞅瞅， VirtualMachine 裏的就這點方法，能力上比 JVMTI 還是差遠了</p><pre><code>List&lt;ReferenceType&gt; classesByName(String className);

List&lt;ReferenceType&gt; allClasses();

void redefineClasses(Map&lt;? extends ReferenceType, byte[]&gt; classToBytes);

List&lt;ThreadReference&gt; allThreads();

void suspend();

void resume();

List&lt;ThreadGroupReference&gt; topLevelThreadGroups();

EventQueue eventQueue();

EventRequestManager eventRequestManager();

VoidValue mirrorOfVoid();

Process process();

</code></pre><p>再回來看看 IDEA 中獨立的遠程調試，配置好之後，紅框裏的信息會提示你 ，遠程的 JVM 需增加這一段啓動參數，而且支持多個版本 JDK 的格式，CV 大法就能直接用。</p><p><img alt="Untitled 6.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-09aZdTrWaGxcoBVtI.png" referrerpolicy="no-referrer"></p><span id="OSC_h1_3"></span><h1>-agentlib 和 -javaagent</h1><p>有些細心的同學可能發現了，IDEA 默認的啓動腳本里，同時配置了 -agentlib 和 -javaagent。</p><pre><code>-javaagent:/path/to/jetbrains/debugger-agent.jar 

</code></pre><p>這個 debugger-agent 吧，其實也沒幹啥事，只是對 JDK 內置的一些線程做了些增強，輔助 IDEA 的 debug 功能，支持一些異步的調試。</p><p><img alt="Untitled 7.png" src="https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-11-19-12-09uMEzNf19FBA12z11N.png" referrerpolicy="no-referrer"></p><p>agentlib、javaagent 這倆兄弟，定位其實很像，都是加載自定義的代碼。</p><p>不過區別在於，agentlib 是加載 native lib，需要 c/cpp 去寫，相當於外掛自己的代碼在 jvm 上，可以為所欲為，比如在 agentlib 裏調用上面説的 JVMTI 。</p><p>而 javaagent 是用 java 寫的，可以直接用上層的 Instrumentation API，做一些類的增強轉換之類，這也是大多數 APM Agent、Profiler Agent 實現的基本原理。</p><span id="OSC_h1_4"></span><h1>Arthas 的玩法</h1><p>Arthas 的核心入口，其實還是 javaagent，支持靜態加載和動態加載兩種玩法。</p><p>靜態沒啥好説的，啓動腳本里增加一個<code>-javaagent:/tmp/test/arthas-agent.jar</code>，然後為所欲為。</p><p>動態的叫 attach，使用 Java 提供的<code>VirtualMachine</code>就可以實現運行時添加 -javaagent，效果一樣：</p><pre><code>VirtualMachine virtualMachine = VirtualMachine.attach(virtualMachineDescriptor);
virtualMachine.loadAgent(agentPath, agentArgs);

</code></pre><p>這個 Agent 在 JVM 裏啓動了一個 TCP server，用於收發 Arthas Client 的各種 trace、watch 、Dashboard 等指令，然後通過 Instrumentation 增強 Class 插入代碼、或者直接調用某些 Java API，實現各種功能。</p><p>注意到了嗎？Arthas 可以直接下載一個 jar 包，java -jar 就能連上。</p><p>其實吧，它這個直接啓動的 jar 包，是一個 boot 包，啓動之後把亂七八糟的 jar 都下載下來。接着動態 attach 的方式，連接到本機指定進程號的 JVM，然後再為所欲為。</p><p>在 3.5 版本之後，Arthas 還新增了一個<strong><strong>vmtool</strong></strong>命令，這個命令可以直接獲取內存中的指定對象實例。</p><pre><code>$ vmtool --action getInstances --className java.lang.String --limit 10
@String[][
    @String[com/taobao/arthas/core/shell/session/Session],
    @String[com.taobao.arthas.core.shell.session.Session],
    @String[com/taobao/arthas/core/shell/session/Session],
    @String[com/taobao/arthas/core/shell/session/Session],
    @String[com/taobao/arthas/core/shell/session/Session.class],
    @String[com/taobao/arthas/core/shell/session/Session.class],
    @String[com/taobao/arthas/core/shell/session/Session.class],
    @String[com/],
    @String[java/util/concurrent/ConcurrentHashMap$ValueIterator],
    @String[java/util/concurrent/locks/LockSupport],
]

</code></pre><p>直接獲取內存對象，這玩意只靠 Instrumentation API 可做不到。Arthas 搞了個騷操作，直接 JNI 調用自定義 lib，用過 cpp 直接調用了 JVMTI 的 API，融合了 Instrumentation 和 JVMTI 的能力，這下是真的為所欲為了！</p><pre><code>#include &lt;stdio.h&gt;
#include &lt;jni.h&gt;
#include &lt;jni_md.h&gt;
#include &lt;jvmti.h&gt;
#include "arthas_VmTool.h" // under target/native/javah/

static jvmtiEnv *jvmti;

...

extern "C"
JNIEXPORT jobjectArray JNICALL
Java_arthas_VmTool_getInstances0(JNIEnv *env, jclass thisClass, jclass klass, jint limit) {
    jlong tag = getTag();
    limitCounter.init(limit);
    jvmtiError error = jvmti-&gt;IterateOverInstancesOfClass(klass, JVMTI_HEAP_OBJECT_EITHER,
                                               HeapObjectCallback, &amp;tag);
    if (error) {
        printf("ERROR: JVMTI IterateOverInstancesOfClass failed!%u\n", error);
        return NULL;
    }

    jint count = 0;
    jobject *instances;
    error = jvmti-&gt;GetObjectsWithTags(1, &amp;tag, &amp;count, &amp;instances, NULL);
    if (error) {
        printf("ERROR: JVMTI GetObjectsWithTags failed!%u\n", error);
        return NULL;
    }

    jobjectArray array = env-&gt;NewObjectArray(count, klass, NULL);
    //添加元素到數組
    for (int i = 0; i &lt; count; i++) {
        env-&gt;SetObjectArrayElement(array, i, instances[i]);
    }
    jvmti-&gt;Deallocate(reinterpret_cast&lt;unsigned char *&gt;(instances));
    return array;
}

</code></pre><span id="OSC_h1_5"></span><h1>總結</h1><ol><li><p>Debug 基於 JDPA 體系</p><ol><li><p>IDE 直接接入 JDPA 體系中的 JDI 接口完成</p></li><li><p>JDI 通過 JDWP 協議，調用遠程 VM 的 JVMTI 接口</p></li><li><p>JDWP 是通過 agentlib 加載的，agentlib 算是一個 native 的靜態「外掛」接口</p></li></ol></li><li><p>javaagent 是 JAVA 層面的「外掛」接口，用過 Instrumentation API（Java）實現各種功能，主要用於 APM、Profiler 工具</p></li><li><p>如果你想，在 javaagent 裏調用功能更豐富的 JVMTI 也不是不行。</p></li></ol><blockquote><p>作者：京東保險，蔣信</p><p>來源：京東雲開發者社區，轉載請註明來源</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 31 Dec 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/10388524</guid>
            <link>https://my.oschina.net/u/4090830/blog/10388524</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[致敬過去，迎接未來：DataCap 感恩有您的 2023，翹首期盼 2024 的精進與共創]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>親愛的 <code>DataCap</code> 軟件用戶，開發者：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;時光荏苒，<code>2023</code> 年即將成為過去，我們深感榮幸與感慨地站在這個時刻，對您們表達我們最深切的感謝。在過去的一年中，我們一直感受到了您們對我們軟件的不離不棄和堅定支持，這是我們最寶貴的動力。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;<code>2023</code> 年是我們 <code>DataCap</code> 軟件發展的關鍵一年。我們榮幸地宣佈，預定支持的大部分功能在這一年裏得以實現。然而，我們也要坦誠地承認，雖然這些功能在某些方面還存在不足和改進的空間，但正是在這個過程中，您們對我們軟件的寬容與理解成為我們前行路上最強大的支持。無論是在社交媒體上的反饋，還是通過郵件和客服的溝通以及 <code>GitHub</code> 和 <code>Gitee</code> 反饋，您們的每一次建議和反饋都是我們前進的明燈，是我們改進的方向。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;在這個感恩的季節，我們要向每一位 <code>DataCap</code> 用戶致以最衷心的感謝。是你們的熱情使用和持續支持，讓我們能夠不斷髮展、完善軟件。每一個新的用戶，每一個老用戶，都是我們成長曆程中不可或缺的一部分。感謝您們的信任，讓我們得以在軟件開發的道路上越走越遠。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;隨着 <code>2023</code> 年即將謝幕，我們更加興奮地展望着 <code>2024</code> 年。我們承諾，為了回饋您們的信任，我們將不遺餘力地投入到軟件的不斷完善中。我們將不懈努力，以確保軟件在穩定性、安全性和用戶友好性方面取得更大的進步。我們也將持續關注用戶反饋，不斷優化用戶體驗，確保軟件在您們手中能夠發揮最大的價值。同時也希望您在使用軟件中遇到的任何問題以及技術與我們溝通，我們將會以最大能力去解決並修復它。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;在此，我們要特別感謝那些默默為軟件發展貢獻的開發者們 (<strong>排名不分先後，開發者的列表為 github 中的 id</strong>，如果您有興趣可以關注他 (她) 們)。<code>mlboy</code>、<code>why198852</code>、<code>javalover123</code>、<code>pan3793</code>、<code>GtoCm</code>、<code>Smilewh888</code>、<code>chenwenming-zj</code>、<code>Stacey1018</code>、<code>hometownglory</code>、<code>shuangzishuai</code> 等等，感謝你們的辛勤付出和無私奉獻。正是有了你們的技術支持，軟件才能不斷創新、不斷進步。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;感謝 <code>GitHub</code>，<code>Gitee</code> 對軟件的託管和支持，在此向他們所有的工作人員致敬。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;感謝 <code>OpenTiny</code> 對我們的支持。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;最後，讓我們向新老用戶們表達最真摯的感激之情。是你們的陪伴，讓我們在軟件的道路上走得更加堅定。在新的一年裏，我們期許能夠為您們帶來更多的驚喜和便捷。無論您是一位新用戶，還是一位老用戶，都請相信，您的支持是我們前行的最大動力。</p><p><code>2024</code> 年，願我們繼續攜手，共同創造更加美好、更加智能的未來。</p><p>再次感謝您們的支持！</p><p>DataCap 軟件團隊 (Devlive 開源組織)</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 11:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273459/datacap-news</guid>
            <link>https://www.oschina.net/news/273459/datacap-news</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Farewell to Pika, Embracing the Arrival of PikiwiDB in 2024]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今年 (2023 年)&nbsp;3&nbsp;月份於某接手項目時，OpenAtom&nbsp;基金會&nbsp;Pika&nbsp;項目（ <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenAtomFoundation%2Fpika" target="_blank">https://github.com/OpenAtomFoundation/pika</a> ）對接人告訴我，OpenAtom&nbsp;基金會旗下的多個項目都面臨了一個共同問題：項目名稱被第三方註冊為商標。出於合規要求，餘三月份重點工作之一就是給項目重新申請一個全新的名稱。</p><p>在與&nbsp;Pika&nbsp;老團隊的成員進行商討後，結合了&nbsp;「兔子哥」&nbsp;和&nbsp;「YYJ」&nbsp;的建議，我決定將其命名為&nbsp;"Pi-kiwi-DB"：</p><ol><li>"Pi"&nbsp;念派 2.&nbsp;"Pik"&nbsp;恰好保留了&nbsp;"Pika"&nbsp;的前三個字母 3.&nbsp;"kiwi"&nbsp;音同&nbsp;"KV"，寓意幾維鳥</li></ol><p><img src="https://oscimg.oschina.net/oscnet/up-d73a02aed0d881c1ab72b620a395aac8a55.png" alt="" referrerpolicy="no-referrer"></p><p>Kiwi&nbsp;鳥孵化的鳥蛋佔據身體容量的一半，象徵着計算機大部分數據存儲在磁盤上，代表着&nbsp;「極大容量」；Kiwi&nbsp;鳥羽翼退化，身體小巧，雙腿強壯佔體重&nbsp;1/3，跑速快如人類，象徵着&nbsp;「極致性能」。所以，這一命名的選擇充分考慮了項目的發展方向和原有名稱的延續。</p><p>在&nbsp;2023&nbsp;年&nbsp;7&nbsp;月底，PikiwiDB（前身為&nbsp;Pika）發佈了自&nbsp;2021&nbsp;年加入&nbsp;OpenAtom&nbsp;基金會以來的首個生產可用版本&nbsp;v3.5.0。該版本通過採用&nbsp;C++17&nbsp;對整個代碼進行了重構，顯著提升了項目的代碼質量。全新的全量同步機製取代了備受詬病的&nbsp;Rsync&nbsp;方案，該方案在過去的&nbsp;8&nbsp;年裏一直在使用。此外，升級了&nbsp;RocksDB&nbsp;版本、引入新的集羣方案、增強了可觀測性、跨平台支持&nbsp;Mac&nbsp;等方面都取得了顯著的改進。</p><p>在接下來的半年中，PikiwiDB&nbsp;陸續發佈了&nbsp;v3.5.1&nbsp;和&nbsp;v3.5.2&nbsp;兩個版本，並計劃在不久的將來發布&nbsp;v3.5.3。這些版本的更新實現了數據的冷熱分離、命令的快慢分離、Redis&nbsp;事務、雲原生&nbsp;K8s&nbsp;Operator&nbsp;以及&nbsp;Go&nbsp;測試集的集成。這一系列的改進將讀性能提升到了微秒級別，單機讀取&nbsp;QPS&nbsp;翻倍，可達&nbsp;60&nbsp;萬&nbsp;/s。在穩定性和性能方面都取得了顯著的提升。社區活躍度方面，貢獻者數量增加了近&nbsp;3&nbsp;倍，達到&nbsp;121&nbsp;人（包括&nbsp;PikiwiDB&nbsp;和&nbsp;Pika），同時&nbsp;PR&nbsp;和&nbsp;Issue&nbsp;的總量也翻番，許多老用戶紛紛迴歸。</p><p>到&nbsp;12&nbsp;月，OpenAtom&nbsp;基金會告知：Pika&nbsp;新名稱&nbsp;PikiwiDB&nbsp;已經在政府相關部門獲得批准，商標也已審批下來。這標誌着整個過程的順利完成。</p><p>回顧&nbsp;2023&nbsp;年&nbsp;12&nbsp;月份，社會第三方機構對&nbsp;PikiwiDB&nbsp;(原&nbsp;Pika)&nbsp;的評價：</p><p>這一過程展示了&nbsp;PikiwiDB&nbsp;對項目的持續改進，不僅在技術上取得了顯著的進步，而且在品牌命名和合規性方面也取得了圓滿成功。</p><p><img src="https://oscimg.oschina.net/oscnet/up-dddcab84de08ed2d058294f472911e37f90.png" alt="" referrerpolicy="no-referrer"></p><ul><li>12&nbsp;月&nbsp;08&nbsp;日，Pika&nbsp;社區和&nbsp;dubbogo&nbsp;社區雙雙榮獲&nbsp;Oschina&nbsp;「2023 年度優秀開源技術團隊」</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-3d425b37dbb7dcd23e4cdf3d273695db0ad.png" alt="" referrerpolicy="no-referrer"></p><blockquote></blockquote><ul><li>12&nbsp;月&nbsp;13&nbsp;日，Pika[已更名&nbsp;PikiwiDB]&nbsp;被第三方獨立機構&nbsp;艾瑞諮詢研究院&nbsp;列為&nbsp;2023&nbsp;年&nbsp;&nbsp;「中國基礎軟件開源產業主要參與者」【DUBBO&nbsp;亦列其中】</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-846de83809b0b9fbab55bee81a04e84f452.png" alt="" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-89332cd585fca59db07e2cedcb162bbf7b3.png" alt="" referrerpolicy="no-referrer"></p><ul><li>12&nbsp;月&nbsp;29&nbsp;日，PikiwiDB(Pika)&nbsp;第一次以&nbsp;PikiwiDB&nbsp;的身份亮相&nbsp;Oschina&nbsp;2023&nbsp;年《中國開源開發者報告》</li></ul><p>展望&nbsp;2024&nbsp;年，PikiwiDB&nbsp;將重點發力於&nbsp;<a href="">雲原生方向</a>，繼續在&nbsp;「極大容量、極高性能、極致彈性」&nbsp;方向上進行探索。誠邀&nbsp;PikiwiDB（原&nbsp;Pika）社區的用戶積極參與共建，共同推動&nbsp;PikiwiDB（原&nbsp;Pika）在雲計算時代的發展。</p><p><img src="https://oscimg.oschina.net/oscnet/up-708fbac71201d8d036a6f6efa9fb2e1ed79.png" alt="" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 04:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/dubbogo/blog/10475258</guid>
            <link>https://my.oschina.net/dubbogo/blog/10475258</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Vue 2 生命週期即將結束]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在新的一年即將到來之際，尤雨溪於日前<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.vuejs.org%2Fposts%2Fvue-2-eol" target="_blank">發文</a>提醒 Vue 社區稱，Vue 2 將於 2023 年 12 月 31 日達到生命週期結束 (EOL)；並呼籲還在使用 Vue 2 的開發團隊考慮遷移至最新的&nbsp;Vue 3 版本。</p><p>Vue 2.0 於 2016 年發佈，距今已有 7 年多的時間。尤雨溪表示，2.0 版本是 Vue 成為主流框架歷程中的一個重要里程碑。「然而，並行地主動維護兩個主要版本對我們來説是不可持續的。隨着 Vue 3 及其生態系統的成熟，團隊是時候繼續前進並將精力集中在最新的主要版本上。」</p><p><img height="303" src="https://oscimg.oschina.net/oscnet/up-624c109953c0efc8aa6cc403c47e6b21d3b.png" width="700" referrerpolicy="no-referrer"></p><p>隨着&nbsp;Vue 2.0 版本 EOL 日期的臨近，他建議&nbsp;Vue 社區應該為 Vue 2 的棄用做好準備。12 月 31 日，Vue 團隊將在 npm 上將以下軟件包標記為已棄用：</p><ul><li>Vue 2 核心的所有主要和次要版本</li><li>專門支持 Vue 2 的 vue-router 版本（3.x 及更低版本）</li><li>專門支持 Vue 2 的 vuex&nbsp;版本（3.x 及更低版本）</li></ul><p>2023 年 12 月 31 日之後，Vue 2 將不再接收新功能、更新或修復，但仍可在所有現有分發渠道（CDN、包管理器、GitHub 等）上使用。<span style="color:#374151">換句話説，用戶的應用程序可以繼續工作，但會從包管理器中收到棄用警告，提醒其 Vue 2 不再是受支持的版本。</span></p><p><span style="color:#374151">Vue 3 自 2022 年 2 月 7 日以來就一直是 Vue 的默認版本。尤雨溪表示，遷移後的用戶將可以享受：</span></p><p>&nbsp;</p><ul style="margin-left:0; margin-right:0"><li>更小的包尺寸和更快的渲染帶來更好的性能。</li><li>增強的 TypeScript 支持，更輕鬆地進行大規模應用程序開發。</li><li>更高效的基於代理的反應系統。</li><li>新的內置組件，如 Fragment、Teleport 和 Suspense。</li><li>改進了構建工具支持和 Vue Devtools 體驗，等等。</li></ul><p>對於暫時無法遷移或者步向前一的用戶，他也提供了一些其他建議：<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:var(--tw-prose-headings)"><span><span><span><span><span><span><span><span><span><span><span><span><span><span>更新到 Vue 2 的最終版本、或購買 Vue 2 的擴展支持，以及和用戶分享相關的</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;Vue 2 EOL 計劃</span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="color:var(--tw-prose-headings)"><span><span><span><span><span><span><span><span><span><span><span><span><span><span>。於 12 月 24 日發佈的&nbsp;</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="background-color:#ffffff; color:#333333">2.7.16 是 Vue 2 的最終版本，包括了對 2.7 功能的一些最終修復，並改進了與 Vue 3 的類型對齊。</span></p><p><span style="background-color:#ffffff; color:#333333">「Vue 2 的結束僅標誌着一個新的開始——2024 年對 Vue 來説將是激動人心的一年！」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 03:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273400/vue-2-eol</guid>
            <link>https://www.oschina.net/news/273400/vue-2-eol</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GitHub Copilot Chat 普遍可用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>今年早些時候，GitHub 推出了 Copilot Chat；一個類似於 ChatGPT 的以編程為中心的聊天機器人，適用於訂閲 Copilot for Business 的組織。前不久，Copilot Chat 的測試版也面向 Copilot 個人用戶推出，每月收費 10 美元。</p><p>時至今日，GitHub 發文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2F2023-12-29-github-copilot-chat-now-generally-available-for-organizations-and-individuals%2F" target="_blank">宣佈</a>，GitHub Copilot Chat 現已普遍適用於 Visual Studio Code 和 Visual Studio，經過驗證的教師、學生和流行開源項目的維護人員也可以免費使用。</p><p><img alt="" height="266" src="https://oscimg.oschina.net/oscnet/up-a3b881ee5bc1674182cfdc6412c6fab4398.webp" width="500" referrerpolicy="no-referrer"></p><p>「所有 GitHub Copilot 個人用戶現在都可使用 GitHub Copilot Chat 功能。企業和組織管理員可通過為其用戶啓用 Copilot Chat 設置，授予開發團隊訪問 Copilot Chat 的權限。如果你已經在測試版中使用了 Copilot Chat，或者已經為你的開發團隊提供了訪問權限，則無需進行其他操作。」</p><p>GitHub Copilot Chat 由 GPT-4 提供支持，並專門針對開發場景進行了微調。開發人員可以用自然語言提示 Copilot Chat，以獲得實時指導，例如要求 Copilot Chat 解釋概念、檢測漏洞或編寫單元測試。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 03:05:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273397/github-copilot-chat-now-generally-available</guid>
            <link>https://www.oschina.net/news/273397/github-copilot-chat-now-generally-available</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Infinigen —— 無限高質量 3D 數據生成器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Infinigen 是無限高質量 3D 數據生成器，使用程序生成的無限逼真世界。這些數據 100% 通過程序化生成，不需要外部資產，也不依賴 AI，並且是免費開源的，生成質量非常高，據稱可以達到以假亂真的地步，甚至是花瓣上的皺紋都可定製。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-89f0a56c9b3a6cc8ff8cedb7501aecff0e0.png" referrerpolicy="no-referrer"></p><p>Infinigen 由普林斯頓視覺和學習實驗室開發：</p><ul><li>基於 Blender 編寫</li><li>每個小細節都是隨機的和可定製的，甚至是花瓣上的皺紋</li><li>自然界中多樣的物體和場景：植物、動物、地形；火、雲、雨和雪</li><li>Groundtruth 自動標註：光流、3D 場景流、深度、表面法線、全景分割、遮擋邊界</li></ul><p>其主要特性和功能包括：</p><p>1. 程序化：Infinigen 是一個程序生成器，它完全使用隨機的數學規則來創建所有的形狀和材料，從宏觀結構到微觀細節。Infinigen 可以創建無限的變化。用戶可以通過覆蓋隨機化的默認參數來完全控制資產的生成。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f9d8159ed3837b185ace5578b1e2d6b0973.png" referrerpolicy="no-referrer"></p><p>2. 多樣化：Infinigen 為自然世界中的多樣化對象和場景提供生成器，包括植物、動物、地形，以及火、雲、雨、雪等自然現象。當前對自然的關注是由於觀察到哺乳動物的視覺在自然世界中進化。然而，預計 Infinigen 將隨着時間的推移擴展到覆蓋建築環境和人造物體。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-e4874348efa3dd1ae71f5d170027ed35b43.png" referrerpolicy="no-referrer"></p><p>3. 真實的幾何形狀：Infinigen 針對計算機視覺研究進行了優化，特別是 3D 視覺。Infinigen 不使用 bump/normal-maps、全透明度或其他偽造幾何細節的技術。Infinigen 的所有細微的幾何細節都是真實的，確保了精確的 3D 地面真實性。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-2579dc0164572ce5aa1add312a321e16803.png" referrerpolicy="no-referrer"></p><p>4. 自動註釋：Infinigen 可以自動生成各種計算機視覺任務的高質量註釋，包括光流、3D 場景流、深度、表面法線、全景分割、遮擋邊界。因為用戶可以完全訪問渲染過程，所以註釋很容易定製。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-cbb0ac43739fd281ebc6ccdd23cead6aff3.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/infinigen</guid>
            <link>https://www.oschina.net/p/infinigen</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 嵌入式軟件平台框架 VSF]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-vsf----versaloon-software-framework" class="anchor" href="https://gitee.com/vsfteam/vsf#vsf----versaloon-software-framework"></a>VSF -- Versaloon Software Framework</h1><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Fblob%2Fmaster%2FLICENSE"><img src="https://img.shields.io/github/license/vsfteam/vsf.svg" alt="GitHub" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fwindows-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/windows-build.yml/badge.svg" alt="windows-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fcmake-native-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/cmake-native-build.yml/badge.svg" alt="cmake-native-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsfteam%2Fvsf%2Factions%2Fworkflows%2Fcmake-arm-cross-build.yml"><img src="https://github.com/vsfteam/vsf/actions/workflows/cmake-arm-cross-build.yml/badge.svg" alt="cmake-arm-cross-build" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fwindows-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/windows-build.yml/badge.svg?branch=vsf-sync" alt="vsf.linux windows build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fcmake-arm-cross-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/cmake-arm-cross-build.yml/badge.svg?branch=vsf-sync" alt="cmake-arm-cross-build" referrerpolicy="no-referrer"></a><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fvsf-linux%2Fvsf.linux%2Factions%2Fworkflows%2Fcmake-native-build.yml"><img src="https://github.com/vsf-linux/vsf.linux/actions/workflows/cmake-native-build.yml/badge.svg?branch=vsf-sync" alt="cmake-native-build" referrerpolicy="no-referrer"></a></p><p><a href="https://gitee.com/vsfteam/vsf/blob/master/README.md">English</a> |</p><p>VSF 全稱是 Versaloon Software Framework，是一個基於 Apache2.0 協議的開源嵌入式軟件平台框架。包含了從底層硬件的 hal 驅動、搶佔式多任務內核、各種服務和組件。全部代碼使用 C 語言，以及面向對象的方式實現。</p><h2><a id="user-content-整體框架" class="anchor" href="https://gitee.com/vsfteam/vsf#%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6"></a>整體框架</h2><h2><a id="user-content-目錄" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%9B%AE%E5%BD%95"></a>目錄</h2><table><thead><tr><th>目錄名</th><th>描述</th></tr></thead><tbody><tr><td>document</td><td>文檔</td></tr><tr><td>doxygen</td><td>doxygen 配置</td></tr><tr><td>example</td><td>示例代碼</td></tr><tr><td>hardware</td><td>VSF 開發板硬件資料</td></tr><tr><td>patch</td><td>一些補丁（第三方庫補丁等等）</td></tr><tr><td>script</td><td>一些工具腳本</td></tr><tr><td> cmake</td><td>cmake 工具腳本</td></tr><tr><td>source</td><td>VSF 源代碼</td></tr><tr><td> component</td><td>組件（文件系統、協議棧、UI、外部芯片驅動）</td></tr><tr><td> hal</td><td>硬件抽象層（芯片 arch 支持、芯片驅動）</td></tr><tr><td> kernel</td><td>內核</td></tr><tr><td> osa_service</td><td>依賴內核的軟件服務組件</td></tr><tr><td> service</td><td>軟件服務組件</td></tr><tr><td> shell</td><td>「皮膚」</td></tr><tr><td> utilities</td><td>基礎軟件工具（一些預處理功能、編譯器支持、列表等等）</td></tr></tbody></table><h2><a id="user-content-內核" class="anchor" href="https://gitee.com/vsfteam/vsf#%E5%86%85%E6%A0%B8"></a>內核</h2><p>基於事件驅動的搶佔式多任務內核，支持 51、8bit MCU、32/64 bit arm、riscv、x86 等等各種構架的芯片。</p><ul><li>事件驅動，有事件運行，沒事件休眠</li><li>搶佔模式下，任務切換由硬件實現，任務優先級就是硬件 swi（software interrupt）的優先級</li><li>不同優先級搶佔，同一優先級協作</li><li>可以運行在其他系統或者 RTOS 中，也可以運行在一個或者幾個 SWI 中斷中（和其他 RTOS 並存）。</li><li>多種任務形式
<ul><li>事件處理任務 -- 最小資源佔用，最簡配置下佔用 20 字節 ram，常用配置下佔用 40 字節 ram</li><li>pt 任務 -- 接近獨立堆棧任務開發方式的共享堆棧任務</li><li>獨立堆棧任務 -- 依賴 libc 中的 setjmp 庫</li><li>fsm 狀態機任務</li><li>「皮膚」中的其他任務封裝形式，比如 pthread</li></ul></li><li>信號量、互斥量、觸發器、隊列等等常用 IPC 工具</li></ul><h2><a id="user-content-組件" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%BB%84%E4%BB%B6"></a>組件</h2><ul><li>合理的框架設計，軟件高度可以複用</li><li>儘可能提供申明式的開發方式</li><li>標準化接口，第三方軟件一次性移植，全平台適配</li><li>軟件組件/框架
<ul><li>distbus -- 分佈式總線框架</li><li>fifo</li><li>heap</li><li>json</li><li>pool -- 內存池</li><li>stream -- 流接口</li><li>trace</li></ul></li><li>組件
<ul><li>fs -- 文件系統，支持 VFS（可使用第三方的文件系統）</li><li>input -- 輸入系統</li><li>mal -- 塊設備</li><li>scsi -- SCSI 設備</li><li>tcpip -- TCPIP 協議棧以及 netdrv 網絡設備（可使用第三方的 TCPIP 協議棧）</li><li>ui -- UI 以及顯示設備（可使用第三方的 GUI）</li><li>usb -- USB 主從機協議棧</li><li>bt -- 藍牙協議棧（使用第三方的 btstack）</li></ul></li></ul><h2><a id="user-content-硬件抽象層" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82"></a>硬件抽象層</h2><ul><li>標準 hal 接口，統一 API -- 比如：vsf_spi_init 可以用於所有 VSF 中支持的 SPI，包括芯片自帶 SPI、GPIO 模擬的 SPI、通過 USB 外擴的 SPI，通過分佈式總線訪問的遠端 SPI</li><li>簡化開發的 IP 核驅動 -- 移植僅需要實現時鐘、復位、中斷等等 IP 核心之外的功能</li><li>各種接口封裝模板</li><li>接口
<ul><li>PM</li><li>GPIO</li><li>SPI</li><li>I2C</li><li>PWM</li><li>ADC</li><li>SWI</li><li>USART</li><li>FLASH</li><li>USB</li><li>ethernet</li></ul></li></ul><h2><a id="user-content-皮膚" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%9A%AE%E8%82%A4"></a>「皮膚」</h2><p>「皮膚」可以把 VSF「偽裝」成其他系統，使得可以直接使用基於其他系統的應用代碼。</p><ul><li>SDL -- 可以直接使用一些基於 SDL 的應用層代碼</li><li>linux -- 可以直接使用一些基於 linux 的應用層代碼
<ul><li>posix</li><li>devfs</li><li>socket</li><li>console</li><li>一些 lib 庫的實現
<ul><li>libusb</li><li>libgen</li></ul></li></ul></li></ul><h2><a id="user-content-第三方" class="anchor" href="https://gitee.com/vsfteam/vsf#%E7%AC%AC%E4%B8%89%E6%96%B9"></a>第三方</h2><table><thead><tr><th>名字</th><th>路徑</th><th>許可</th><th>鏈接</th></tr></thead><tbody><tr><td>btstack</td><td>source/component/3rd-party/btstack/raw</td><td>Other</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fbluekitchen%2Fbtstack">https://github.com/bluekitchen/btstack</a></td></tr><tr><td>coremark</td><td>source/component/3rd-party/coremark/raw</td><td>Apache</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Feembc%2Fcoremark">https://github.com/eembc/coremark</a></td></tr><tr><td>freetype</td><td>source/component/3rd-party/freetype/raw</td><td>FreeType</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Ffreetype.org%2F">https://freetype.org/</a></td></tr><tr><td>zlib</td><td>source/component/3rd-party/zlib/raw</td><td>zlib</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fzlib.net%2F">http://zlib.net/</a></td></tr><tr><td>nuklear</td><td>source/component/3rd-party/nuklear/raw</td><td>MTI</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FImmediate-Mode-UI%2FNuklear">https://github.com/Immediate-Mode-UI/Nuklear</a></td></tr><tr><td>nnom</td><td>source/component/3rd-party/nnom/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fmajianjia%2Fnnom">https://github.com/majianjia/nnom</a></td></tr><tr><td>lua</td><td>source/component/3rd-party/lua/raw</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.lua.org%2F">https://www.lua.org/</a></td></tr><tr><td>lwip</td><td>source/component/3rd-party/lwip/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fsavannah.nongnu.org%2Fprojects%2Flwip%2F">https://savannah.nongnu.org/projects/lwip/</a></td></tr><tr><td>libpng</td><td>source/component/3rd-party/libpng/raw</td><td>PNG2</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flibpng.sf.net">https://libpng.sf.net</a></td></tr><tr><td>libjpeg-turbo</td><td>source/component/3rd-party/libjpeg-turbo/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flibjpeg-turbo.org%2F">https://libjpeg-turbo.org/</a></td></tr><tr><td>SDL_ttf</td><td>source/shell/media/sdl2/3rd-party/SDL_ttf</td><td>zlib</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fhg.libsdl.org%2FSDL_ttf%2F">https://hg.libsdl.org/SDL_ttf/</a></td></tr><tr><td>SDL_image</td><td>source/shell/media/sdl2/3rd-party/SDL_image</td><td>zlib</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fhg.libsdl.org%2FSDL_image%2F">https://hg.libsdl.org/SDL_image/</a></td></tr><tr><td>lvgl</td><td>source/component/3rd-party/lvgl/raw/lvgl</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flvgl.io%2F">https://lvgl.io/</a></td></tr><tr><td>lv_lib_freetype</td><td>source/component/3rd-party/lvgl/extension/lv_lib_freetype/raw</td><td>MIT</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Flvgl.io%2F">https://lvgl.io/</a></td></tr><tr><td>CMSIS</td><td>source/utilities/compiler/arm/3rd-party/CMSIS</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FARM-software%2FCMSIS_5">https://github.com/ARM-software/CMSIS_5</a></td></tr><tr><td>evm</td><td>source/component/3rd-party/evm/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fscriptiot%2Fevm">https://github.com/scriptiot/evm</a></td></tr><tr><td>LingLongGUI</td><td>source/component/3rd-party/LingLongGUI/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/gzbkey/LingLongGUI">https://gitee.com/gzbkey/LingLongGUI</a></td></tr><tr><td>PLOOC</td><td>source/utilities/3rd-party/PLOOC/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FGorgonMeducer%2FPLOOC">https://github.com/GorgonMeducer/PLOOC</a></td></tr><tr><td>mbedtls</td><td>source/component/3rd-party/mbedtls/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Ftls.mbed.org%2F">https://tls.mbed.org/</a></td></tr><tr><td>GuiLite</td><td>source/component/3rd-party/GuiLite/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fidea4good%2FGuiLite">https://github.com/idea4good/GuiLite</a></td></tr><tr><td>Segger_RTT</td><td>source/component/3rd-party/segger/raw/RTT</td><td>segger</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwiki.segger.com%2FRTT">https://wiki.segger.com/RTT</a></td></tr><tr><td>Segger_SystemView</td><td>source/component/3rd-party/segger/raw/SystemView</td><td>segger</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwiki.segger.com%2FSystemView">https://wiki.segger.com/SystemView</a></td></tr><tr><td>nuconsole</td><td>source/component/3rd-party/nuconsole/raw</td><td>nuvoton</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.nuvoton.com.cn%2F">https://www.nuvoton.com.cn/</a></td></tr><tr><td>AIC8800M_SDK</td><td>source/hal/driver/AIC/AIC8800/vendor</td><td>aic</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.aicsemi.com%2F">http://www.aicsemi.com/</a></td></tr><tr><td>awtk</td><td></td><td>LGPL 2.1</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fwww.zlg.cn%2Findex%2Fpub%2Fawtk.html">https://www.zlg.cn/index/pub/awtk.html</a></td></tr><tr><td>littlefs</td><td>source/component/3rd-party/littlefs/raw</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Flittlefs-project%2Flittlefs">https://github.com/littlefs-project/littlefs</a></td></tr><tr><td>getopt_long</td><td>source/shell/sys/linux/lib/3rd-party/getopt</td><td>OpenBSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fopenbsd%2Fsrc">https://github.com/openbsd/src</a></td></tr><tr><td>regex</td><td>source/shell/sys/linux/lib/3rd-party/regex</td><td>OpenBSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fopenbsd%2Fsrc">https://github.com/openbsd/src</a></td></tr><tr><td>fnmatch</td><td>source/shell/sys/linux/lib/3rd-party/fnmatch</td><td>BSD</td><td><a href="https://gitee.com/link?target=http%3A%2F%2Fwww.jbox.dk%2Fsanos%2Fsource%2Flib%2Ffnmatch.c.html">http://www.jbox.dk/sanos/source/lib/fnmatch.c.html</a></td></tr><tr><td>glob</td><td>source/shell/sys/linux/lib/3rd-party/glob</td><td>BSD</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fcloudius-systems%2Fmusl">https://github.com/cloudius-systems/musl</a></td></tr><tr><td>setjmp</td><td>source/hal/arch/x86/win</td><td>BSD</td><td></td></tr><tr><td>libtuv</td><td>source/shell/sys/linux/lib/3rd-party/libtuv/raw</td><td>Apache 2.0</td><td><a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FSamsung%2Flibtuv">https://github.com/Samsung/libtuv</a></td></tr></tbody></table><h2><a id="user-content-文檔" class="anchor" href="https://gitee.com/vsfteam/vsf#%E6%96%87%E6%A1%A3"></a><a href="https://gitee.com/vsfteam/vsf/blob/master/document/README_zh.md">文檔</a></h2>]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/vsfteam/vsf</guid>
            <link>https://gitee.com/vsfteam/vsf</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 混合專家模型 (MoE) 詳解]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div class="rich_media_content js_underline_content
                       autoTypeSetting24psection
            " id="js_content"><section data-tool="mdnice 編輯器" data-website="https://www.mdnice.com" style="font-size: 16px;color: black;padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 0px;word-break: break-word;text-align: left;font-family: Roboto, Oxygen, Ubuntu, Cantarell, PingFangSC-regular, PingFangTC-regular, &quot;Open Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif;" data-mpa-powered-by="yiban.io"><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">隨着 Mixtral 8x7B (announcement, model card) 的推出，一種稱為混合專家模型 (Mixed Expert Models，簡稱 MoEs) 的 Transformer 模型在開源人工智能社區引起了廣泛關注。在本篇博文中，我們將深入探討 MoEs 的核心組件、訓練方法，以及在推理過程中需要考量的各種因素。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們開始吧！</p><span id="OSC_h2_1"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">簡短總結</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoEs):</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      與稠密模型相比， 
     <strong style="color: black;">預訓練速度更快</strong></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      與具有相同參數數量的模型相比，具有更快的 
     <strong style="color: black;">推理速度</strong></section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      需要 
     <strong style="color: black;">大量顯存</strong>，因為所有專家系統都需要加載到內存中 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      在 
     <strong style="color: black;">微調方面存在諸多挑戰</strong>，但，近期的研究，表明，對混合專家模型進行 
     <strong style="color: black;">指令調優具有很大的潛力</strong>。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們開始吧！</p><span id="OSC_h2_2"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">什麼是混合專家模型？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">模型規模是提升模型性能的關鍵因素之一。在有限的計算資源預算下，用更少的訓練步數訓練一個更大的模型，往往比用更多的步數訓練一個較小的模型效果更佳。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoE) 的一個顯著優勢是它們能夠在遠少於稠密模型所需的計算資源下進行有效的預訓練。這意味着在相同的計算預算條件下，您可以顯著擴大模型或數據集的規模。特別是在預訓練階段，與稠密模型相比，混合專家模型通常能夠更快地達到相同的質量水平。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">那麼，究竟什麼是一個混合專家模型 (MoE) 呢？作為一種基於 Transformer 架構的模型，混合專家模型主要由兩個關鍵部分組成:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">稀疏 MoE 層</strong>: 這些層代替了傳統 Transformer 模型中的前饋網絡 (FFN) 層。MoE 層包含若干「專家」(例如 8 個)，每個專家本身是一個獨立的神經網絡。在實際應用中，這些專家通常是前饋網絡 (FFN)，但它們也可以是更復雜的網絡結構，甚至可以是 MoE 層本身，從而形成層級式的 MoE 結構。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">門控網絡或路由</strong>: 這個部分用於決定哪些令牌 (token) 被髮送到哪個專家。例如，在下圖中，「More」這個令牌可能被髮送到第二個專家，而「Parameters」這個令牌被髮送到第一個專家。有時，一個令牌甚至可以被髮送到多個專家。令牌的路由方式是 MoE 使用中的一個關鍵點，因為路由器由學習的參數組成，並且與網絡的其他部分一同進行預訓練。 
    </section></li></ul><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006177" data-ratio="0.7703703703703704" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8f46f9ec-4ee7-42d6-8b1d-68962ccb7e8b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformers paper 論文中的 MoE layer 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">總結來説，在混合專家模型 (MoE) 中，我們將傳統 Transformer 模型中的每個前饋網絡 (FFN) 層替換為 MoE 層，其中 MoE 層由兩個核心部分組成: 一個門控網絡和若干數量的專家。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">儘管混合專家模型 (MoE) 提供了若干顯著優勢，例如更高效的預訓練和與稠密模型相比更快的推理速度，但它們也伴隨着一些挑戰:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">訓練挑戰</strong>: 雖然 MoE 能夠實現更高效的計算預訓練，但它們在微調階段往往面臨泛化能力不足的問題，長期以來易於引發過擬合現象。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">推理挑戰</strong>: MoE 模型雖然可能擁有大量參數，但在推理過程中只使用其中的一部分，這使得它們的推理速度快於具有相同數量參數的稠密模型。然而，這種模型需要將所有參數加載到內存中，因此對內存的需求非常高。以 Mixtral 8x7B 這樣的 MoE 為例，需要足夠的 VRAM 來容納一個 47B 參數的稠密模型。之所以是 47B 而不是 8 x 7B = 56B，是因為在 MoE 模型中，只有 FFN 層被視為獨立的專家，而模型的其他參數是共享的。此外，假設每個令牌只使用兩個專家，那麼推理速度 (以 FLOPs 計算) 類似於使用 12B 模型 (而不是 14B 模型)，因為雖然它進行了 2x7B 的矩陣乘法計算，但某些層是共享的。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">瞭解了 MoE 的基本概念後，讓我們進一步探索推動這類模型發展的研究。</p><span id="OSC_h2_3"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">混合專家模型簡史</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoE) 的理念起源於 1991 年的論文 Adaptive Mixture of Local Experts。這個概念與集成學習方法相似，旨在為由多個單獨網絡組成的系統建立一個監管機制。在這種系統中，每個網絡 (被稱為「專家」) 處理訓練樣本的不同子集，專注於輸入空間的特定區域。那麼，如何選擇哪個專家來處理特定的輸入呢？這就是門控網絡發揮作用的地方，它決定了分配給每個專家的權重。在訓練過程中，這些專家和門控網絡都同時接受訓練，以優化它們的性能和決策能力。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在 2010 至 2015 年間，兩個獨立的研究領域為混合專家模型 (MoE) 的後續發展做出了顯著貢獻:</p><ol data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">組件專家</strong>: 在傳統的 MoE 設置中，整個系統由一個門控網絡和多個專家組成。在支持向量機 (SVMs) 、高斯過程和其他方法的研究中，MoE 通常被視為整個模型的一部分。然而，Eigen、Ranzato 和 Ilya 的研究，探索了將 MoE 作為更深層網絡的一個組件。這種方法允許將 MoE 嵌入到多層網絡中的某一層，使得模型既大又高效。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">條件計算</strong>: 傳統的神經網絡通過每一層處理所有輸入數據。在這一時期，Yoshua Bengio 等研究人員開始探索基於輸入令牌動態激活或停用網絡組件的方法。 
    </section></li></ol><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這些研究的融合促進了在自然語言處理 (NLP) 領域對混合專家模型的探索。特別是在 2017 年，Shazeer 等人 (團隊包括 Geoffrey Hinton 和 Jeff Dean，後者有時被戲稱為 「谷歌的 Chuck Norris」) 將這一概念應用於 137B 的 LSTM (當時被廣泛應用於 NLP 的架構，由 Schmidhuber 提出)。通過引入稀疏性，這項工作在保持極高規模的同時實現了快速的推理速度。這項工作主要集中在翻譯領域，但面臨着如高通信成本和訓練不穩定性等多種挑戰。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006175" data-ratio="0.48240635641316687" data-type="png" data-w="881" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/48db56ce-0292-4d84-a174-c5c7a03d5e8b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Outrageously Large Neural Network 論文中的 MoE layer 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">混合專家模型 (MoE) 的引入使得訓練具有數千億甚至萬億參數的模型成為可能，如開源的 1.6 萬億參數的 Switch Transformers 等。這種技術不僅在自然語言處理 (NLP) 領域得到了廣泛應用，也開始在計算機視覺領域進行探索。然而，本篇博客文章將主要聚焦於自然語言處理領域的應用和探討。</p><span id="OSC_h2_4"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">什麼是稀疏性?</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稀疏性的概念採用了條件計算的思想。在傳統的稠密模型中，所有的參數都會對所有輸入數據進行處理。相比之下，稀疏性允許我們僅針對整個系統的某些特定部分執行計算。這意味着並非所有參數都會在處理每個輸入時被激活或使用，而是根據輸入的特定特徵或需求，只有部分參數集合被調用和運行。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們深入分析 Shazeer 對混合專家模型 (MoE) 在翻譯應用中的貢獻。條件計算的概念 (即僅在每個樣本的基礎上激活網絡的不同部分) 使得在不增加額外計算負擔的情況下擴展模型規模成為可能。這一策略在每個 MoE 層中實現了數以千計甚至更多的專家的有效利用。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這種稀疏性設置確實帶來了一些挑戰。例如，在混合專家模型 (MoE) 中，儘管較大的批量大小通常有利於提高性能，但當數據通過激活的專家時，實際的批量大小可能會減少。比如，假設我們的輸入批量包含 10 個令牌， <strong style="color: black;">可能會有五個令牌被路由到同一個專家，而剩下的五個令牌分別被路由到不同的專家。這導致了批量大小的不均勻分配和資源利用效率不高的問題</strong>。在接下來的部分中，將會討論讓 MoE 高效運行的其他挑戰以及相應的解決方案。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">那我們應該如何解決這個問題呢？一個可學習的門控網絡 (G) 決定將輸入的哪一部分發送給哪些專家 (E):</p><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="y = \sum_{i=1}^{n} G(x)_i E_i(x)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><svg
                xmlns="http://www.w3.org/2000/svg" role="img" focusable="false" viewBox="0 -1562.5 8246.1 2808.5" aria-hidden="true" style="-webkit-overflow-scrolling: touch;vertical-align: -2.819ex;width: 18.656ex;height: 6.354ex;max-width: 300% !important;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(1823.6, 0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2, -1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345, 0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(509.9, 1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mi" transform="translate(3434.2, 0)"><path data-c="47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mo" transform="translate(4220.2, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4609.2, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="msub" transform="translate(5181.2, 0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(389, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(5864.2, 0)"><g data-mml-node="mi"><path data-c="45" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mi" transform="translate(738, -150) scale(0.707)"><path data-c="69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(6896.1, 0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7285.1, 0)"><path data-c="78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7857.1, 0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在這種設置下，雖然所有專家都會對所有輸入進行運算，但通過門控網絡的輸出進行加權乘法操作。但是，如果 G (門控網絡的輸出) 為 0 會發生什麼呢？如果是這種情況，就沒有必要計算相應的專家操作，因此我們可以節省計算資源。那麼一個典型的門控函數是什麼呢？一個典型的門控函數通常是一個帶有 softmax 函數的簡單的網絡。這個網絡將學習將輸入發送給哪個專家。</p><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="G_\sigma(x) = \text{Softmax}(x \cdot W_g)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.667ex;width: 24.749ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/addcdb77-1331-4c14-845f-06df5414abd2.svg" data-type="svg+xml" data-imgfileid="100006169"></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Shazeer 等人的工作還探索了其他的門控機制，其中包括帶噪聲的 TopK 門控 (Noisy Top-K Gating)。這種門控方法引入了一些可調整的噪聲，然後保留前 k 個值。具體來説:</p><ol data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      添加一些噪聲 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="H(x)_i = (x \cdot W_{\text{g}})_i + \text{StandardNormal()} \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i)
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.669ex;width: 60.565ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/26f83d98-1595-404e-9d4a-58c616d102c1.svg" data-type="svg+xml" data-imgfileid="100006173"></section></span><ol start="2" data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      選擇保留前 K 個值 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="\text{KeepTopK}(v, k)_i = \begin{cases}
v_i &amp; \text{if } v_i \text{ is in the top } k \text{ elements of } v, \\
-\infty &amp; \text{otherwise.}
\end{cases}
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -2.148ex;width: 58.794ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/4505b4a9-5c66-45c5-9f72-1b2377d74dca.svg" data-type="svg+xml" data-imgfileid="100006171"></section></span><ol start="3" data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      應用 Softmax 函數 
    </section></li></ol><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="G(x) = \text{Softmax}(\text{KeepTopK}(H(x), k))
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -0.566ex;width: 37.6ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/70f4a245-7a7f-483c-b524-8795deb3ae04.svg" data-type="svg+xml" data-imgfileid="100006170"></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這種稀疏性引入了一些有趣的特性。通過使用較低的 k 值 (例如 1 或 2)，我們可以比激活多個專家時更快地進行訓練和推理。為什麼不僅選擇最頂尖的專家呢？最初的假設是，需要將輸入路由到不止一個專家，以便門控學會如何進行有效的路由選擇，因此至少需要選擇兩個專家。Switch Transformers 就這點進行了更多的研究。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">我們為什麼要添加噪聲呢？這是為了專家間的負載均衡！</p><span id="OSC_h2_5"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">混合專家模型中令牌的負載均衡</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">正如之前討論的，如果所有的令牌都被髮送到只有少數幾個受歡迎的專家，那麼訓練效率將會降低。在通常的混合專家模型 (MoE) 訓練中，門控網絡往往傾向於主要激活相同的幾個專家。這種情況可能會自我加強，因為受歡迎的專家訓練得更快，因此它們更容易被選擇。為了緩解這個問題，引入了一個 <strong style="color: black;">輔助損失</strong>，旨在鼓勵給予所有專家相同的重要性。這個損失確保所有專家接收到大致相等數量的訓練樣本，從而平衡了專家之間的選擇。接下來的部分還將探討專家容量的概念，它引入了一個關於專家可以處理多少令牌的閾值。在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 庫中，可以通過 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">aux_loss</code> 參數來控制輔助損失。</p><span id="OSC_h2_6"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">MoEs and Transformers</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Transformer 類模型明確表明，增加參數數量可以提高性能，因此谷歌使用 GShard 嘗試將 Transformer 模型的參數量擴展到超過 6000 億並不令人驚訝。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">GShard 將在編碼器和解碼器中的每個前饋網絡 (FFN) 層中的替換為使用 Top-2 門控的混合專家模型 (MoE) 層。下圖展示了編碼器部分的結構。這種架構對於大規模計算非常有效: 當擴展到多個設備時，MoE 層在不同設備間共享，而其他所有層則在每個設備上覆制。我們將在 「讓 MoE 起飛」部分對這一點進行更詳細的討論。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006178" data-ratio="0.6046296296296296" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/8246ce4e-437b-4539-bf15-17cea720b24b.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     GShard 論文中的 MoE Transformer Encoder 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">為了保持負載平衡和訓練效率，GShard 的作者除了引入了上一節中討論的類似輔助損失外，還引入了一些關鍵變化:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">隨機路由</strong>: 在 Top-2 設置中，我們始終選擇排名最高的專家，但第二個專家是根據其權重比例隨機選擇的。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">專家容量</strong>: 我們可以設定一個閾值，定義一個專家能處理多少令牌。如果兩個專家的容量都達到上限，令牌就會溢出，並通過殘差連接傳遞到下一層，或在某些情況下被完全丟棄。專家容量是 MoE 中最重要的概念之一。為什麼需要專家容量呢？因為所有張量的形狀在編譯時是靜態確定的，我們無法提前知道多少令牌會分配給每個專家，因此需要一個固定的容量因子。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">GShard 的工作對適用於 MoE 的並行計算模式也做出了重要貢獻，但這些內容的討論超出了這篇博客的範圍。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意</strong>: 在推理過程中，只有部分專家被激活。同時，有些計算過程是共享的，例如自注意力 (self-attention) 機制，它適用於所有令牌。這就解釋了為什麼我們可以使用相當於 12B 稠密模型的計算資源來運行一個包含 8 個專家的 47B 模型。如果我們採用 Top-2 門控，模型會使用高達 14B 的參數。但是，由於自注意力操作 (專家間共享) 的存在，實際上模型運行時使用的參數數量是 12B。</p><span id="OSC_h2_7"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">Switch Transformers</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">儘管混合專家模型 (MoE) 顯示出了很大的潛力，但它們在訓練和微調過程中存在穩定性問題。Switch Transformers 是一項非常激動人心的工作，它深入研究了這些話題。作者甚至在 Hugging Face 上發佈了一個 1.6 萬億參數的 MoE，擁有 2048 個專家，你可以使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">transformers</code> 庫來運行它。Switch Transformers 實現了與 T5-XXL 相比 4 倍的預訓練速度提升。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006176" data-ratio="0.5101851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/56bee9cf-5842-4bfd-b5a5-cdc79c60b93d.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformer 論文中的 Switch Transformer Layer 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">就像在 GShard 中一樣，作者用混合專家模型 (MoE) 層替換了前饋網絡 (FFN) 層。Switch Transformers 提出了一個 Switch Transformer 層，它接收兩個輸入 (兩個不同的令牌) 並擁有四個專家。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">與最初使用至少兩個專家的想法相反，Switch Transformers 採用了簡化的單專家策略。這種方法的效果包括:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      減少門控網絡 (路由) 計算負擔 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      每個專家的批量大小至少可以減半 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      降低通信成本 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      保持模型質量 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 也對 <strong style="color: black;">專家容量</strong> 這個概念進行了研究。</p><span style="cursor:pointer;" data-tool="mdnice 編輯器"><section role="presentation" data-formula="\text{Expert Capacity} = \left(\frac{\text{tokens per batch}}{\text{number of experts}}\right) \times \text{capacity factor}
" data-formula-type="block-equation" style="text-align: center;overflow: auto;"><embed style="vertical-align: -2.148ex;width: 58.45ex;height: auto;max-width: 300% !important;" src="https://oscimg.oschina.net/oscnet/52d4608e-4c61-4d62-b055-dc8f790f459a.svg" data-type="svg+xml" data-imgfileid="100006172"></section></span><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">上述建議的容量是將批次中的令牌數量均勻分配到各個專家。如果我們使用大於 1 的容量因子，我們為令牌分配不完全平衡時提供了一個緩衝。增加容量因子會導致更高的設備間通信成本，因此這是一個需要考慮的權衡。特別值得注意的是，Switch Transformers 在低容量因子 (例如 1 至 1.25) 下表現出色。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformer 的作者還重新審視並簡化了前面章節中提到的負載均衡損失。在訓練期間，對於每個 Switch 層的輔助損失被添加到總模型損失中。這種損失鼓勵均勻路由，並可以使用超參數進行加權。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">作者還嘗試了混合精度的方法，例如用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bfloat16</code> 精度訓練專家，同時對其餘計算使用全精度進行。較低的精度可以減少處理器間的通信成本、計算成本以及存儲張量的內存。然而，在最初的實驗中，當專家和門控網絡都使用 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">bfloat16</code> 精度訓練時，出現了不穩定的訓練現象。這種不穩定性特別是由路由計算引起的，因為路由涉及指數函數等操作，這些操作對精度要求較高。因此，為了保持計算的穩定性和精確性，保持更高的精度是重要的。為了減輕不穩定性，路由過程也使用了全精度。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006174" data-ratio="0.2253731343283582" data-type="png" data-w="670" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/66532187-c893-46e4-8d55-3a04955edef9.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     使用混合精度不會降低模型質量並可實現更快的訓練 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">這個 Jupyter Notebook 展示瞭如何對 Switch Transformers 進行微調以進行摘要生成的詳細指南。然而，在開始微調 Switch Transformers 之前，強烈建議您先閲讀關於微調混合專家模型部分的內容。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 採用了編碼器 - 解碼器的架構，實現了與 T5 類似的混合專家模型 (MoE) 版本。GLaM 這篇工作探索瞭如何使用僅為原來 1/3 的計算資源 (因為 MoE 模型在訓練時需要的計算量較少，從而能夠顯著降低碳足跡) 來訓練與 GPT-3 質量相匹配的模型來提高這些模型的規模。作者專注於僅解碼器 (decoder-only) 的模型以及少樣本和單樣本評估，而不是微調。他們使用了 Top-2 路由和更大的容量因子。此外，他們探討了將容量因子作為一個動態度量，根據訓練和評估期間所使用的計算量進行調整。</p><span id="OSC_h2_8"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">用 Router z-loss 穩定模型訓練</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">之前討論的平衡損失可能會導致穩定性問題。我們可以使用許多方法來穩定稀疏模型的訓練，但這可能會犧牲模型質量。例如，引入 dropout 可以提高穩定性，但會導致模型質量下降。另一方面，增加更多的乘法分量可以提高質量，但會降低模型穩定性。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ST-MoE 引入的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">Router z-loss</code> 在保持了模型性能的同時顯著提升了訓練的穩定性。這種損失機制通過懲罰門控網絡輸入的較大 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);background-color: rgb(255, 245, 227);padding: 3px;margin: 3px;">logits</code> 來起作用，目的是促使數值的絕對大小保持較小，這樣可以有效減少計算中的舍入誤差。這一點對於那些依賴指數函數進行計算的門控網絡尤其重要。為了深入瞭解這一機制，建議參考原始論文以獲得更全面的細節。</p><span id="OSC_h2_9"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">專家如何學習？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">ST-MoE 的研究者們發現，編碼器中不同的專家傾向於專注於特定類型的令牌或淺層概念。例如，某些專家可能專門處理標點符號，而其他專家則專注於專有名詞等。與此相反，解碼器中的專家通常具有較低的專業化程度。此外，研究者們還對這一模型進行了多語言訓練。儘管人們可能會預期每個專家處理一種特定語言，但實際上並非如此。由於令牌路由和負載均衡的機制，沒有任何專家被特定配置以專門處理某一特定語言。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006181" data-ratio="0.9258760107816711" data-type="png" data-w="742" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/1137474f-1950-4033-8f38-785166343282.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     ST-MoE 論文中顯示了哪些令牌組被髮送給了哪個專家的表格 
   </figcaption></figure><span id="OSC_h2_10"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">專家的數量對預訓練有何影響？</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">增加更多專家可以提升處理樣本的效率和加速模型的運算速度，但這些優勢隨着專家數量的增加而遞減 (尤其是當專家數量達到 256 或 512 之後更為明顯)。同時，這也意味着在推理過程中，需要更多的顯存來加載整個模型。值得注意的是，Switch Transformers 的研究表明，其在大規模模型中的特性在小規模模型下也同樣適用，即便是每層僅包含 2、4 或 8 個專家。</p><span id="OSC_h2_11"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">微調混合專家模型</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);"><code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">4.36.0</code> 版本的 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">transformers</code> 庫支持 Mixtral 模型。你可以用以下命令進行安裝: <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">pip install "transformers==4.36.0 --upgrade</code></p></blockquote><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稠密模型和稀疏模型在過擬合的動態表現上存在顯著差異。稀疏模型更易於出現過擬合現象，因此在處理這些模型時，嘗試更強的內部正則化措施是有益的，比如使用更高比例的 dropout。例如，我們可以為稠密層設定一個較低的 dropout 率，而為稀疏層設置一個更高的 dropout 率，以此來優化模型性能。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在微調過程中是否使用輔助損失是一個需要決策的問題。ST-MoE 的作者嘗試關閉輔助損失，發現即使高達 11% 的令牌被丟棄，模型的質量也沒有顯著受到影響。令牌丟棄可能是一種正則化形式，有助於防止過擬合。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Switch Transformers 的作者觀察到，在相同的預訓練困惑度下，稀疏模型在下游任務中的表現不如對應的稠密模型，特別是在重理解任務 (如 SuperGLUE) 上。另一方面，對於知識密集型任務 (如 TriviaQA)，稀疏模型的表現異常出色。作者還觀察到，在微調過程中，較少的專家的數量有助於改善性能。另一個關於泛化問題確認的發現是，模型在小型任務上表現較差，但在大型任務上表現良好。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006182" data-ratio="0.38010471204188484" data-type="png" data-w="955" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/47346e7f-b742-4923-a63d-7ccecd2a6427.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     在小任務 (左圖) 中，我們可以看到明顯的過擬合，因為稀疏模型在驗證集中的表現要差得多。在較大的任務 (右圖) 中，MoE 則表現良好。該圖來自 ST-MoE 論文 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">一種可行的微調策略是嘗試凍結所有非專家層的權重。實踐中，這會導致性能大幅下降，但這符合我們的預期，因為混合專家模型 (MoE) 層佔據了網絡的主要部分。我們可以嘗試相反的方法: 僅凍結 MoE 層的參數。實驗結果顯示，這種方法幾乎與更新所有參數的效果相當。這種做法可以加速微調過程，並降低顯存需求。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006180" data-ratio="0.77" data-type="png" data-w="400" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/401ba984-a5f5-4772-95db-99c12f026ef7.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     通過僅凍結 MoE 層，我們可以在保持質量的同時加快訓練速度。該圖來自 ST-MoE 論文 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在微調稀疏混合專家模型 (MoE) 時需要考慮的最後一個問題是，它們有特別的微調超參數設置——例如，稀疏模型往往更適合使用較小的批量大小和較高的學習率，這樣可以獲得更好的訓練效果。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006183" data-ratio="0.37570303712035996" data-type="png" data-w="889" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/0f29d064-6852-4055-99ce-fab522c4d6bd.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     降低學習率和調大批量可以提升稀疏模型微調質量。該圖來自 ST-MoE 論文 
   </figcaption></figure><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">此時，您可能會對人們微調 MoE 中遇到的這些挑戰而感到沮喪，但最近的一篇論文 《MoEs Meets Instruction Tuning》 (2023 年 7 月) 帶來了令人興奮的發現。這篇論文進行了以下實驗:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      單任務微調 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      多任務指令微調 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      多任務指令微調後接單任務微調 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">當研究者們對 MoE 和對應性能相當的 T5 模型進行微調時，他們發現 T5 的對應模型表現更為出色。然而，當研究者們對 Flan T5 (一種 T5 的指令優化版本) 的 MoE 版本進行微調時，MoE 的性能顯著提升。更值得注意的是，Flan-MoE 相比原始 MoE 的性能提升幅度超過了 Flan T5 相對於原始 T5 的提升，這意味着 MoE 模型可能從指令式微調中獲益更多，甚至超過了稠密模型。此外，MoE 在多任務學習中表現更佳。與之前關閉 <strong style="color: black;">輔助損失</strong> 函數的做法相反，實際上這種損失函數可以幫助防止過擬合。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006179" data-ratio="0.4456140350877193" data-type="png" data-w="855" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/dc2a1d41-2a2d-4e63-b2c3-015fb22f56f3.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     與稠密模型相比，稀疏模型從指令微調中受益更多。該圖來自 MoEs Meets instructions Tuning 論文 
   </figcaption></figure><span id="OSC_h2_12"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">稀疏 VS 稠密，如何選擇?</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">稀疏混合專家模型 (MoE) 適用於擁有多台機器且要求高吞吐量的場景。在固定的預訓練計算資源下，稀疏模型往往能夠實現更優的效果。相反，在顯存較少且吞吐量要求不高的場景，稠密模型則是更合適的選擇。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);"><strong style="color: black;">注意</strong>: 直接比較稀疏模型和稠密模型的參數數量是不恰當的，因為這兩類模型基於的概念和參數量的計算方法完全不同。</p><span id="OSC_h2_13"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">讓 MoE 起飛</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">最初的混合專家模型 (MoE) 設計採用了分支結構，這導致了計算效率低下。這種低效主要是因為 GPU 並不是為處理這種結構而設計的，而且由於設備間需要傳遞數據，網絡帶寬常常成為性能瓶頸。在接下來的討論中，我們會討論一些現有的研究成果，旨在使這些模型在預訓練和推理階段更加高效和實用。我們來看看如何優化 MoE 模型，讓 MoE 起飛。</p><span id="OSC_h3_14"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">並行計算</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">讓我們簡要回顧一下並行計算的幾種形式:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">數據並行</strong>: 相同的權重在所有節點上覆制，數據在節點之間分割。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">模型並行</strong>: 模型在節點之間分割，相同的數據在所有節點上覆制。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">模型和數據並行</strong>: 我們可以在節點之間同時分割模型和數據。注意，不同的節點處理不同批次的數據。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);"><strong style="color: black;">專家並行</strong>: 專家被放置在不同的節點上。如果與數據並行結合，每個節點擁有不同的專家，數據在所有節點之間分割。 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">在專家並行中，專家被放置在不同的節點上，每個節點處理不同批次的訓練樣本。對於非 MoE 層，專家並行的行為與數據並行相同。對於 MoE 層，序列中的令牌被髮送到擁有所需專家的節點。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006184" data-ratio="0.5910194174757282" data-type="png" data-w="824" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d166997f-8e65-483f-91e6-e5e4c1ccdf96.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     Switch Transformers 論文中展示如何使用不同的並行技術在節點上分割數據和模型的插圖 
   </figcaption></figure><span id="OSC_h3_15"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">容量因子和通信開銷</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">提高容量因子 (Capacity Factor, CF) 可以增強模型的性能，但這也意味着更高的通信成本和對保存激活值的顯存的需求。在設備通信帶寬有限的情況下，選擇較小的容量因子可能是更佳的策略。一個合理的初始設置是採用 Top-2 路由、1.25 的容量因子，同時每個節點配置一個專家。在評估性能時，應根據需要調整容量因子，以在設備間的通信成本和計算成本之間找到一個平衡點。</p><span id="OSC_h3_16"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">部署技術</span><span style="display: none;"></span></h3><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">您可以在 <code style="font-size: 14px;border-radius: 4px;font-family: &quot;Operator Mono&quot;, Consolas, Monaco, Menlo, monospace;word-break: break-all;color: rgb(155, 110, 35);padding: 3px;margin: 3px;">Inference Endpoints</code> 部署 mistralai/Mixtral-8x7B-Instruct-v0.1。</p></blockquote><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">部署混合專家模型 (MoE) 的一個關鍵挑戰是其龐大的參數規模。對於本地使用情況，我們可能希望使用更小的模型。為了使模型更適合部署，下面是幾種有用的技術:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      預先蒸餾實驗: Switch Transformers 的研究者們進行了預先蒸餾的實驗。他們通過將 MoE 模型蒸餾回其對應的稠密模型，成功保留了 30-40% 的由稀疏性帶來的性能提升。預先蒸餾不僅加快了預訓練速度，還使得在推理中使用更小型的模型成為可能。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      任務級別路由: 最新的方法中，路由器被修改為將整個句子或任務直接路由到一個專家。這樣做可以提取出一個用於服務的子網絡，有助於簡化模型的結構。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      專家網絡聚合: 這項技術通過合併各個專家的權重，在推理時減少了所需的參數數量。這樣可以在不顯著犧牲性能的情況下降低模型的複雜度。 
    </section></li></ul><span id="OSC_h3_17"></span><h3 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 20px;line-height: 1.4;padding-top: 10px;margin-top: 10px;margin-bottom: 5px;"><span style="display: none;"></span><span style="color: rgb(81, 81, 81);font-size: 17px;padding-left: 1em;border-left: 3px solid rgb(249, 191, 69);">高效訓練</span><span style="display: none;"></span></h3><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">FasterMoE (2022 年 3 月) 深入分析了 MoE 在不同並行策略下的理論性能極限，並且探索了一系列創新技術，包括用於專家權重調整的方法、減少延遲的細粒度通信調度技術，以及一個基於最低延遲進行專家選擇的拓撲感知門控機制。這些技術的結合使得 MoE 運行速度提升高達 17 倍。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">Megablocks (2022 年 11 月) 則專注於通過開發新的 GPU kernel 來處理 MoE 模型中的動態性，以實現更高效的稀疏預訓練。其核心優勢在於，它不會丟棄任何令牌，並能高效地適應現代硬件架構 (支持塊稀疏矩陣乘)，從而達到顯著的加速效果。Megablocks 的創新之處在於，它不像傳統 MoE 那樣使用批量矩陣乘法 (這通常假設所有專家形狀相同且處理相同數量的令牌)，而是將 MoE 層表示為塊稀疏操作，可以靈活適應不均衡的令牌分配。</p><figure data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;"><img class="rich_pages wxw-img" data-imgfileid="100006185" data-ratio="0.2851851851851852" data-type="png" data-w="1080" style="margin-right: auto;margin-left: auto;width: 100%;border-radius: 5px;display: block;margin-bottom: 15px;height: auto !important;" src="https://oscimg.oschina.net/oscnet/d09a85e7-f59f-421c-8e9f-d75df34954c8.png" referrerpolicy="no-referrer"> &nbsp; 
   <figcaption style="margin-top: 5px;text-align: center;color: #dda52d;font-size: 14px;">
     針對不同規模的專家和令牌數量的塊稀疏矩陣乘法。該圖來自 MegaBlocks 論文 
   </figcaption></figure><span id="OSC_h2_18"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">開源混合專家模型</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">目前，下面這些開源項目可以用於訓練混合專家模型 (MoE):</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Megablocks: https://github.com/stanford-futuredata/megablocks 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Fairseq: https://github.com/facebookresearch/fairseq/tree/main/examples/moe_lm 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      OpenMoE: https://github.com/XueFuzhao/OpenMoE 
    </section></li></ul><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">對於開源的混合專家模型 (MoE)，你可以關注下面這些:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Switch Transformers (Google): 基於 T5 的 MoE 集合，專家數量從 8 名到 2048 名。最大的模型有 1.6 萬億個參數。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      NLLB MoE (Meta): NLLB 翻譯模型的一個 MoE 變體。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      OpenMoE: 社區對基於 Llama 的模型的 MoE 嘗試。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixtral 8x7B (Mistral): 一個性能超越了 Llama 2 70B 的高質量混合專家模型，並且具有更快的推理速度。此外，還發布了一個經過指令微調的模型。有關更多信息，可以在 Mistral 的，公告博客文章，中瞭解。 
    </section></li></ul><span id="OSC_h2_19"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">一些有趣的研究方向</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">首先是嘗試將稀疏混合專家模型 (SMoE) <strong style="color: black;">蒸餾</strong> 回到具有更少實際參數但相似等價參數量的稠密模型。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">MoE 的 <strong style="color: black;">量化</strong> 也是一個有趣的研究領域。例如，QMoE (2023 年 10 月) 通過將 MoE 量化到每個參數不到 1 位，將 1.6 萬億參數的 Switch Transformer 所需的存儲從 3.2TB 壓縮到僅 160GB。</p><p data-tool="mdnice 編輯器" style="margin-bottom: 20px;line-height: 1.8em;color: rgb(58, 58, 58);">簡而言之，一些值得探索的有趣領域包括:</p><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      將 Mixtral 蒸餾成一個稠密模型。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      探索合並專家模型的技術及其對推理時間的影響。 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      嘗試對 Mixtral 進行極端量化的實驗。 
    </section></li></ul><span id="OSC_h2_20"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">相關資源</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><ul data-tool="mdnice 編輯器" style="margin-top: 8px;margin-bottom: 8px;padding-left: 25px;" class="list-paddingleft-1"><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Adaptive Mixture of Local Experts (1991) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Learning Factored Representations in a Deep Mixture of Experts (2013) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer (2017) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding (Jun 2020) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      GLaM: Efficient Scaling of Language Models with Mixture-of-Experts (Dec 2021) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity (Jan 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      ST-MoE: Designing Stable and Transferable Sparse Expert Models (Feb 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      FasterMoE: modeling and optimizing training of large-scale dynamic pre-trained models(April 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      MegaBlocks: Efficient Sparse Training with Mixture-of-Experts (Nov 2022) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models (May 2023) 
    </section></li><li><section style="margin-top: 5px;margin-bottom: 5px;line-height: 26px;color: rgb(58, 58, 58);">
      Mixtral-8x7B-v0.1, Mixtral-8x7B-Instruct-v0.1. 
    </section></li></ul><span id="OSC_h2_21"></span><h2 data-tool="mdnice 編輯器" style="font-weight: bold;font-size: 22px;line-height: 1.2em;margin-top: 2em;margin-bottom: 35px;color: rgb(255, 157, 0);"><span style="font-size: 18px;color: rgb(255, 157, 11);padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;display: none;"></span><span style="color: rgb(255, 157, 11);visibility: visible;display: inline-block;border-left: 5px solid rgb(255, 157, 0);padding: 2px 13px;margin-right: 3px;height: 50%;font-size: 18px;">Citation</span><span style="font-size: 18px;color: rgb(255, 157, 11);display: inline-block;padding-left: 10px;border-left: 5px solid rgb(255, 157, 11);visibility: visible;"></span></h2><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">@misc {sanseviero2023moe,<br>    author       = { Omar Sanseviero and<br>                     Lewis Tunstall and<br>                     Philipp Schmid and<br>                     Sourab Mangrulkar and<br>                     Younes Belkada and<br>                     Pedro Cuenca<br>                   },<br>    title        = { Mixture of Experts Explained },<br>    year         = 2023,<br>    url          = { https://huggingface.co/blog/moe },<br>    publisher    = { Hugging Face Blog }<br>}<br></code></pre><pre data-tool="mdnice 編輯器" style="margin-top: 10px;margin-bottom: 10px;"><code style="overflow-x: auto;padding: 16px;color: #333;background: #f8f8f8;display: -webkit-box;font-family: Operator Mono, Consolas, Monaco, Menlo, monospace;border-radius: 0px;font-size: 12px;-webkit-overflow-scrolling: touch;">Sanseviero,&nbsp;et&nbsp;al.,&nbsp;<span style="color: #d14;line-height: 26px;">"Mixture&nbsp;of&nbsp;Experts&nbsp;Explained"</span>,&nbsp;Hugging&nbsp;Face&nbsp;Blog,&nbsp;2023.<br></code></pre><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;font-size: 0.9em;overflow: auto;color: rgb(106, 115, 125);padding: 10px 10px 10px 20px;margin-bottom: 20px;margin-top: 20px;border-left-color: rgb(255, 177, 27);background: rgb(255, 245, 227);"><p style="font-size: 16px;line-height: 26px;color: rgb(89, 89, 89);">🤗 寶子們可以戳 <strong style="color: black;">閲讀原文</strong> 查看文中所有的外部鏈接喲！</p></blockquote><hr data-tool="mdnice 編輯器" style="height: 1px;border-right: none;border-bottom: none;border-left: none;border-top-style: solid;border-top-color: rgb(249, 191, 69);margin-top: 20px;margin-bottom: 20px;"><blockquote data-tool="mdnice 編輯器" style="border-top: none;border-right: none;border-bottom: none;color: rgb(91, 91, 91);background: rgba(158, 158, 158, 0.1);padding-top: 1px;padding-bottom: 1px;padding-left: 5px;margin-top: 0px;margin-bottom: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><blockquote style="border-width: initial;border-style: none;border-color: initial;margin-top: 0px;margin-bottom: 0em;padding-top: 0px;padding-left: 0px;"><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">英文原文:&nbsp;<span style="color: rgb(136, 136, 136);letter-spacing: 0px;">https://hf.co/blog/moe</span></p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">原文作者: Omar Sanseviero, Lewis Tunstall, Philipp Schmid, Sourab Mangrulkar, Younes Belkada, Pedro Cuenca</p><p style="color: rgb(63, 63, 63);line-height: 1.5;font-size: 14px;margin: 10px;">譯者: xinyu66 (Xinyu Yang)</p></blockquote></blockquote></blockquote></blockquote></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div><p style="color: #858585; font-size: 13px;">本文分享自微信公眾號 - Hugging Face（gh_504339124f0f）。<br>如有侵權，請聯繫 support@oschina.cn 刪除。<br>本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 30 Dec 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/10444582</guid>
            <link>https://my.oschina.net/HuggingFace/blog/10444582</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[恭喜 LinkWeChat 榮獲 2023 開源創新榜「優秀開源項目」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span>&nbsp; &nbsp; &nbsp; 近日，由<strong>中國科協科學技術傳播中心、中國計算機學會、中國通信學會、中國科學院軟件研究所</strong>共同主辦，CSDN 承辦的 2023 開源創新榜專家評審會在國家科技傳播中心成功舉辦。評委會主任、中國計算機學會開源發展委員會主任王懷民院士，評委會副主任、中國科協科學技術傳播中心副主任陳鋭，評委會副主任、中國通信學會副理事長兼祕書長張延川，評委會副主任、中國科學院軟件研究所所長趙琛與來自全國學會、大學、科研院所、企業、開源基金會、行業聯盟等二十多位開源專家共同參與了本屆榜單評審工作，會議由陳鋭主持。</span></p><p><span>&nbsp; &nbsp; &nbsp; &nbsp; 2023 年開源創新榜相較往年有以下幾個變化。<strong>一是進一步提升權威性，</strong>主辦單位新加入中國計算機學會、中國通信學會、中國科學院軟件研究所，四家主辦單位優勢互補，共同推動榜單策劃、徵集申報、專家評審等工作重點。<strong>二是進一步提升公信力，</strong>由王懷民院士擔任評委會主任，指導組建了結構更加科學、領域更加全面的評審專家庫，從中提名形成最終評審專家。<strong>三是進一步提升專業度，</strong>圍繞項目、社區、人物三大類別，四家主辦單位打磨了更加客觀、嚴謹、貼合實際的評審標準和更加開放、公平、科學的評審辦法，在徵集過程中公開標準細節，接受社會的意見反饋，形成良性循環。</span></p><p><span>評委會最終評選出優秀開源項目 20 個，LinkWeChat<span style="color:#f2622e"><strong>成功入選。</strong></span></span></p><p><span><span style="color:#f2622e"><strong><img alt="" height="472" src="https://oscimg.oschina.net/oscnet/up-c75591fff8654955776eeed8c0294671c38.png" width="284" referrerpolicy="no-referrer"></strong></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 15:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273361</guid>
            <link>https://www.oschina.net/news/273361</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[告別 2023，迎接 2024]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>順便帶一下開放籤開源電子簽章上線兩週的小結，本週關鍵字「驚喜」。官網訪問量穩定在 200 左右/天，github/gitee:start 總計 130。5 個企業版意向客戶，以上便是開放簽上線兩週的運營數據。</span></span></span></span></span></span></span></span>&nbsp;</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>用「堅持」「艱辛」來總結 2023 年，這是我們真實的寫照。團隊這幾年確實很辛苦，經歷了創業的艱辛，失去了幾載青春、大把的票子，用很低的收入維持生活，這是我們的現狀。但是這些依然打不倒，也壓不跨我們，對我們來説也不是什麼」苦「。因為我們早已看淡了這些，我們相信我們這些年的積累、經驗總有一天有用武之地。因為我們有夢想（説夢想可能會有人笑話吧），我們可以把開放籤做好。其實毫不誇張的説，直至開放簽上線後，才體會到十年磨一劍的感受。不瞞大家，從開始做電子籤直至開放籤這個項目上線，真的已經十年了，期間被家人和朋友調侃十年才玩明白這點事兒。調侃歸調侃，真正想做好一個產品，我們覺得十年只是一個開始，沒有這十來年足夠的客戶、技術、服務等方方面面積累，以及我們對開放籤的堅持，估計開放簽上線後也是個沒血肉、立不住的產品吧。對開放籤來説，十年只是一個開始，我們深知沒有任何一件事情可以隨便、容易的完成的，接下來的幾年、幾十年，我們將持續的、頑強的深耕我們的產品、服務，讓電子簽章更簡單不是説説而已。</span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>用「驚喜」「憧憬」來展望 2024 年，驚喜發生在開放簽上線後，而且是持續的。驚喜的是沒想到有特別多的朋友在關注、關心我們，給我們提了不少戰略級別的建議，真的感謝你們。在此特別感謝@jack，感謝你給予我們的指導和建議。你給我們帶來了更多的正能量，我們更加堅定了能做好開放籤的信心。只要用心做好產品，我們相信 24 年會有更多的驚喜。24 年用「憧憬」一詞來展望新年，代表了我們對新的一年美好的期冀。我們期待有更多用戶可以低門檻的應用電子簽章，電子簽章可以更加簡單的得到普及。新的一年，我們更加期待開放籤可以更多的參與到公益和對社會有益的事業中，讓開源、開放的意義更大。</span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>寫在最後，我們還很年輕，還有很多不足，肯定在發展的道路上會犯很多錯誤，但是我們是開放的，有激情的，我們願意接受各種批評和質疑，最後還是用一句我們自己堅信的話來總結我們「我們相信開源開放會為產品與用戶之間帶來更多信任「，這就是開放籤的價值觀，是我們堅定走下去的信念。 </span></span></span></span></span></span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span><span style="color:#171a1d"><span><span><span><span>祝各位在新的一年順遂、如意。新年好！</span></span></span></span></span></span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 08:20:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273299</guid>
            <link>https://www.oschina.net/news/273299</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 大語言模型技術報告.pdf]]>
            </title>
            <description>
                <![CDATA[看之前先買瓶水，貨實在太乾了[Facepalm]]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://talk.gitee.com/report/china-open-source-2023-llm-report.pdf?fr=news1229</guid>
            <link>https://talk.gitee.com/report/china-open-source-2023-llm-report.pdf?fr=news1229</link>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 23.04 將於 2024 年 1 月 25 日結束支持]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">對 <a href="https://www.oschina.net/news/237763/ubuntu-23-04-released">Ubuntu 23.04「Lunar Lobster」</a>的官方支持將於 2024 年 1 月 25 日結束，還剩不到一個月的時間。</span></p><p><span style="color:#000000">Ubuntu 23.04 版本於 2023 年 4 月正式發佈，作為短期支持版本獲得 9 個月的支持。還在使用該版本的用戶<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.omgubuntu.co.uk%2F2023%2F12%2Fubuntu-2304-support-ends-january-2024" target="_blank">建議</a>可以考慮升級到 10 月份發佈的 <a href="https://www.oschina.net/news/261571/ubuntu-23-10-ga">Ubuntu 23.10"Mantic Minotaur"</a>，以確保可繼續收到來自 Canonical 的安全補丁、關鍵錯誤修復以及精選軟件的重要更新。</span></p><p><span style="color:#000000"><img alt="" height="263" src="https://oscimg.oschina.net/oscnet/up-4bdb313301be4efb73863c20508102b5a86.jpg" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Ubuntu 23.10 附帶了最新的 GNOME 45 版本（其中包含大量改進）、使用 Linux 6.5 內核、更新了圖形驅動程序，並首次發佈了 2 個全新的應用程序，這些應用程序目前為該版本<span style="background-color:#ffffff">獨有</span>： App Center 和 Firmware。</span></p><p><span style="color:#000000">同樣作為短期支持版本，Ubuntu 23.10 計劃將於 2024 年 7 月中旬達到 EOL。不過預計明年 4 月下旬，<span style="background-color:#ffffff"><a href="https://www.oschina.net/news/263525/ubuntu-24-04-release-date-april-25-2024">Ubuntu 24.04 LTS</a> 版本就會正式發佈，LTS 版本將獲得 5 年的安全更新、錯誤修復和精選應用程序更新；LTS 版本預期每 2 年發佈一次。</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:13:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273275/ubuntu-2304-support-ends-january-2024</guid>
            <link>https://www.oschina.net/news/273275/ubuntu-2304-support-ends-january-2024</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2023 mybatis-mp - 亮點一：可自定義默認值]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>1：默認值設置&nbsp;</p><div><pre><span style="color:#9e880d">@Table
</span><span style="color:#9e880d">@Data
</span><span style="color:#0033b3">public class </span><span style="color:#000000">DefaultValueTest </span>{

    <span style="color:#9e880d">@TableId
</span><span style="color:#9e880d"></span><span style="color:#0033b3">private </span><span style="color:#000000">Integer </span><span style="color:#871094">id</span>;

    <span style="color:#9e880d">@TableField</span>(defaultValue = <span style="color:#067d17">"{BLANK}"</span>)
    <span style="color:#0033b3">private </span><span style="color:#000000">String </span><span style="color:#871094">value1</span>;

    <span style="color:#9e880d">@TableField</span>(defaultValue = <span style="color:#067d17">"1"</span>)
    <span style="color:#0033b3">private </span><span style="color:#000000">Integer </span><span style="color:#871094">value2</span>;

    <span style="color:#9e880d">@TableField</span>(defaultValue = <span style="color:#067d17">"{NOW}"</span>)
    <span style="color:#0033b3">private </span><span style="color:#000000">LocalDateTime </span><span style="color:#871094">createTime</span>;
}
</pre></div><p>2：如何自定義默認值：</p><pre><code class="language-java">MybatisMpConfig.setDefaultValue("{NOW}", (type) -&gt; {
    if (type == LocalDateTime.class) {
        return LocalDateTime.now();
    } else if (type == LocalDate.class) {
        return LocalDate.now();
    } else if (type == Date.class) {
        return new Date();
    } else if (type == Long.class) {
        return System.currentTimeMillis();
    } else if (type == Integer.class) {
        return (int) (System.currentTimeMillis() / 1000);
    }
    throw new RuntimeException("Inconsistent types");
});</code></pre></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 06:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273274</guid>
            <link>https://www.oschina.net/news/273274</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[CNCF 報告：Kubernetes 推動雲支出增長]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>CNCF 發佈的一份調查報告<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F20%2Fcncf-cloud-native-finops-cloud-financial-management-microsurvey%2F" target="_blank">指出</a>，Kubernetes 的到來導致了雲支出急劇增加；有<span style="background-color:#fdfdfd; color:#000000">近一半 (49%) 的受訪者表示 Kubernetes 推動了雲支出增長。</span>其中，17% 的人表示成本大幅增加，32% 的人表示成本僅略有增加。</p><p>另一方面，13% 的受訪者在實施 Kubernetes 後成功顯着減少了雲支出，11% 的受訪者成功略微減少了支出。28% 的受訪者表示採用 Kubernetes 後沒有任何變化。</p><p><img height="273" src="https://oscimg.oschina.net/oscnet/up-153215e0c5e6743aa6ba642aee27efef80b.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">約 28% 的受訪者表示，Kubernetes 佔用了他們一半的預算，10% 的受訪者表示，這一數字高達 75%，還有極少數 5% 的受訪者表示，Kubernetes 佔用了他們的全部預算。</span></p><p><img height="279" src="https://oscimg.oschina.net/oscnet/up-0189729f7a76027da4a44209791e910f940.png" width="500" referrerpolicy="no-referrer"></p><p>26% 的人每月在雲計算上的支出高達 50000 美元；還有 22% 的人表示他們的支出是前者的 20 倍，每月高達 100 萬美元以上。此外，21% 的人每月雲計算支出不到 1 萬美元。</p><p>在受訪者中，Kubernetes 基礎設施的規模存在很大差異。近一半的受訪者 (49%) 只<span style="background-color:#fdfdfd; color:#000000">擁有最多 50 個節點</span>。15% 擁有 51-100 個節點，17% 擁有 101-250 個節點，18% 擁有超過 251 個節點。&nbsp;</p><p>許多人力和技術因素被認為是雲環境中支出以及不必要和意外成本增加的原因。過度配置以 70% 的比例遙遙領先，個人或團隊層面缺乏責任意識位居第二，為 45%。使用資源後未能停用資源以及存在技術債務（定義為尚未重新架構以利用雲原生環境的可擴展性的工作負載）並列第三，各佔 43%。</p><p><img alt="" height="417" src="https://oscimg.oschina.net/oscnet/up-4a03450fb93c2128ee80b363c64d6f5c9f6.png" width="500" referrerpolicy="no-referrer"></p><p>只有 19% 的受訪者表示他們能夠準確監控 Kubernetes 成本。40% 的人只是進行了估計，38% 的人表示他們根本沒有進行任何監控。</p><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2023%2F12%2F20%2Fcncf-cloud-native-finops-cloud-financial-management-microsurvey%2F" target="_blank">查看完整報告</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:38:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/273259/cncf-report-kubernetes-cloud-spen</guid>
            <link>https://www.oschina.net/news/273259/cncf-report-kubernetes-cloud-spen</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.13.0 - 支持 StarRocks]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>🚀 新功能</h2><ul><li>支持 StarRocks。</li><li>支持 PostgreSQL, Redshift, RisingWave 高級自動補全。</li></ul><h2>🎄 改進</h2><ul><li>支持在 SQL 編輯器的表結構 DDL 彈窗中展示 index 語句。</li><li>支持在 SQL 編輯器中查詢 PostgreSQL 外部表。</li><li>漢化釘釘 webhook 消息。</li></ul><h2>🎠 社區</h2><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1TG411r7rr%2F" target="_blank">盤點常用的 MySQL 可視化客戶端</a></li></ul><h2>📕 安裝及升級</h2><p>參考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升級指南</a>。如果從之前版本升級，獲取新版本後，重新啓動升級即可。</p><hr><p>💡 更多資訊，請關注 Bytebase 公號：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 29 Dec 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10456200</guid>
            <link>https://my.oschina.net/u/6148470/blog/10456200</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
    </channel>
</rss>
