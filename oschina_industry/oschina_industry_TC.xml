<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 16 Dec 2023 10:34:08 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[商湯科技創始人湯曉鷗離世，享年 55 歲]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>12 月 16 日，騰訊新聞報道稱，商湯科技董事長、人工智能科學家湯曉鷗於 12 月 15 日在睡夢中不幸離世，享年 55 歲。</p><p>湯曉鷗主要從事計算機視覺相關領域的研究，包括多媒體、計算機視覺、模式識別及視頻處理，是全球人臉識別技術的「開拓者」和「探路者」。</p><blockquote><p><img height="1272" src="https://static.oschina.net/uploads/space/2023/1216/153402_su2B_2720166.png" width="1442" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fview.inews.qq.com%2Fa%2F20231216A051VT00" target="_blank"><span style="background-color:rgba(0, 0, 0, 0); color:inherit">https://</span>view.inews.qq.com/a/20231216A051<span style="background-color:rgba(0, 0, 0, 0); color:inherit">VT00</span></a></u></em></p></blockquote><p>最早的網傳消息：</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1216/153606_97lp_2720166.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1644054135%2FNxokl6vOQ%3Fpagetype%3Dprofilefeed" target="_blank">https://weibo.com/1644054135/Nxokl6vOQ</a></u></em></p></blockquote><p>公開信息顯示，湯曉鷗 1968 年出生於遼寧鞍山，香港中文大學信息工程學系教授、工程學院傑出學人。湯曉鷗於 1990 年從中國科學技術大學畢業；1991 年獲得美國羅切斯特大學碩士學位；1996 年獲得麻省理工學院博士學位，之後進入香港中文大學工作；2001 年創立了香港中文大學多媒體實驗室；2005 年至 2007 年在微軟亞洲研究院工作，擔任視覺計算組主任；2008 年在深圳先進技術研究院多媒體集成技術研究室工作，擔任主任和研究員。</p><p><img height="457" src="https://oscimg.oschina.net/oscnet/up-a417892a92b7c38cf49b69a36526d033f48.png" width="300" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">湯曉鷗指導的博士生何愷明是深度殘差網絡 (ResNets) 的主要開發者。深度殘差網絡</span>使神經網絡能夠達到前所未有的深度，獲得以前難以實現的能力，促成了多個突破性的成果——包括 AlphaGo、AlphaFold 和 ChatGPT，為人工智能做出了基礎性貢獻。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 07:34:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271336</guid>
            <link>https://www.oschina.net/news/271336</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 設立 1000 萬美元基金，支持超人類 AI 風險研究]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">OpenAI <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fsuperalignment-fast-grants" target="_blank">宣佈</a>與 Eric Schmidt 合作，啓動了一項 1000 萬美元的新資助計劃，以支持技術研究，確保超人類人工智能（superhuman AI）系統的一致性和安全性。</span></p><p><span style="color:#000000">「<span style="background-color:#ffffff">我們相信超級智能可能在未來十年內到來。這些人工智能系統將擁有巨大的能力 —— 它們可能帶來巨大的好處，但也可能帶來巨大的風險。</span>」</span></p><p><img height="249" src="https://oscimg.oschina.net/oscnet/up-76bbf42b019b3dacb6d1b9184ea8dcc692a.png" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">該公司表示，當前確保 AI 系統安全的手段主要是依賴於人工監督的對齊技術（例如 RLHF）。但超</span>人類&nbsp;AI&nbsp;<span style="background-color:#ffffff">系統將能夠執行人類無法完全理解的複雜且富有創造性的行為。例如，如果一個超人模型生成一百萬行極其複雜的代碼，人類將無法可靠地評估這些代碼執行起來是安全還是危險，現有的技術可能不再夠用。&nbsp;</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">「這就引出了一個根本性的挑戰：人類如何引導和信任比自己聰明得多的人工智能系統？這是世界上尚未解決的最重要的技術問題之一。但我們認為，只要齊心協力，這個問題是可以解決的。現存<span style="background-color:#ffffff">許多有希望的方法和令人興奮的方向，以及許多唾手可得的成果。</span>」</span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000">作為其 Superalignment 項目的一部分，OpenAI 推出的這一資助計劃旨在：</span></p><ul><li style="text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">向學術實驗室、非營利組織和個人研究人員捐贈 10 萬至 200 萬美元</span></span></li><li style="text-align:start"><span style="color:#000000">並<span style="background-color:#ffffff">為研究生推出為期一年的 15 萬美元獎學金（一半將用於研究經費，另一半將作為津貼）</span></span></li></ul><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><span style="background-color:#ffffff">根據 OpenAI 的説法，申請這一資助資金的研究人員不要求有對齊工作的經驗，他們已準備好為尚未在這方面做過任何工作的研究人員提供支持。</span></span><span><span><span><span style="color:#585858"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fairtable.com%2FappnIXmOlWAJBzrJp%2FpaghnoKL6EHiKmKbf%2Fform" target="_blank"><span><span><span>申請</span></span></span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="color:#000000"><span style="background-color:#ffffff">將持續開放至 2 月 18 日，申請人將在申請截止日期後四個星期內收到回覆。&nbsp;</span></span></span></span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fairtable.com%2FappnIXmOlWAJBzrJp%2FpaghnoKL6EHiKmKbf%2Fform" target="_blank">申請表單</a></strong></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 03:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271307/openai-superalignment-grant-fund</guid>
            <link>https://www.oschina.net/news/271307/openai-superalignment-grant-fund</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[今年我國語言大模型市場增長率將超 100%]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#222222">據央視新聞報道，工業和信息化部賽迪研究院數據顯示，2023 年我國語言大模型市場規模實現較快提升，應用場景不斷豐富，增長率有望突破 100%。</span></p><p><span style="background-color:#ffffff; color:#222222">工業和信息化部賽迪研究院數據顯示，目前，我國已有超過 19 個語言大模型研發廠商，其中，15 家廠商的模型產品已經通過備案，預計今年我國語言大模型市場規模將達到 132.3 億元，增長率將達到 110%。</span></p><p><span style="background-color:#ffffff; color:#222222">語言大模型能夠模仿人類的對話和決策能力，是率先實現技術突破和應用落地的大模型，是當下人工智能的主賽道，在金融、醫療、教育、工業、遊戲、法律等多個行業應用廣泛。專家預測，到 2027 年，我國語言大模型市場規模有望達到 600 億元。</span></p><p><img height="273" src="https://oscimg.oschina.net/oscnet/up-256c6498333f3d9198b73f867a58b33c90d.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 03:28:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271303</guid>
            <link>https://www.oschina.net/news/271303</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Prompt flow —— 構建高質量的 LLM 應用程序]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span><strong>Prompt flow&nbsp;</strong>是一套開發工具，旨在簡化基於 LLM 的人工智能應用程序的端到端開發週期，從構思、原型設計、測試、評估到生產部署和監控。它使即時工程變得更加容易，並使你能夠構建具有生產質量的 LLM 應用程序。</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start"><span><span><span><span style="color:#1f2328"><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>通過該項目，你將能夠：</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>創建將 LLM、提示、Python 代碼和其他工具鏈接在一起的可執行工作流程。</li><li>輕鬆調試和迭代你的流程，尤其是與 LLM 的交互。</li><li>使用更大的數據集評估流程的質量和性能。</li><li>將測試和評估集成到你的 CI/CD 系統中，以確保流程的質量。</li><li>將你的流程部署到你選擇的服務平台或輕鬆集成到應用程序的代碼庫中。</li><li>（可選，官方強烈推薦）利用 Azure AI 中 Prompt flow 的雲版本與團隊協作。
<p>&nbsp;</p></li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 03:03:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/promptflow</guid>
            <link>https://www.oschina.net/p/promptflow</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 分佈式塊存儲系統 fastblock]]>
            </title>
            <description>
                <![CDATA[<h1><a id="fastblock 簡介" class="anchor" href="https://gitee.com/openeuler/fastblock#fastblock%E7%AE%80%E4%BB%8B"></a>fastblock 簡介</h1><p>目前使用的分佈式塊存儲系統 (ceph) 存在的問題已經不能適應對性能、延遲、成本和穩定性的需求，主要體現在:</p><ul><li>CPU 經濟性: 目前需要消耗大量的 CPU，CPU 在 nvme ssd 集羣中成為瓶頸</li><li>可用性差: 採用主從強同步複製策略, 集羣抖動時有 IO 會被 hang 住</li><li>單卷性能不足: 對接 qemu 時性能更差，做壓測時需要多個卷才能跑滿整個集羣的性能</li><li>單卷延遲過大: 不能充分利用 nvme 設備的低延遲特性，rbd 塊設備通常延遲都在毫秒級別</li><li>併發總性能不足: iops 和吞吐相對硬件能夠提供的水平相差較大</li></ul><p>fastblock 是為解決性能和延遲問題而生的，它的特點是:</p><ul><li>使用 spdk 編程框架編寫，利用用戶態 nvme 驅動、無鎖隊列等特性降低 IO 路徑延遲</li><li>引入 RDMA 網卡進行零拷貝、內核旁路、無需 CPU 幹預的網絡通信</li><li>使用 multi-raft 進行數據複製，保證數據可靠性</li><li>簡單、可靠、易定製的集羣元數據管理</li></ul><h1><a id="fastblock 設計及架構" class="anchor" href="https://gitee.com/openeuler/fastblock#fastblock%E8%AE%BE%E8%AE%A1%E5%8F%8A%E6%9E%B6%E6%9E%84"></a>fastblock 設計及架構</h1><p>fastblock 的架構跟 ceph 非常類似，且 monitor、osd、pg 等眾多概念都跟 ceph 一樣以便於快速理解，架構如下圖所示:<br><img src="https://gitee.com/openeuler/fastblock/raw/master/docs/architecture.png" alt="arch" referrerpolicy="no-referrer">
其中:</p><ul><li>Compute 表示計算服務</li><li>Monitor cluster 負責維護集羣元數據（包括 osdMap、pgMap、pool 信息和 image 信息），以及 pool 和 pg 的管理。</li><li>storage cluster 對應存儲集羣，每個存儲集羣包含多個 Storage Node，每個 Storage Node 上運行多個 osd(Object Storage Daemon)。</li><li>Control rpc 用於傳輸元數據，使用 tcp socket；Data rpc 用於在客戶端和 osd 之間傳輸數據請求；raft rpc 用於在 osd 之間傳輸 raft 論文中定義的 RPC 消息。其中 Data rpc 和 raft rpc 使用 protobuf 和 RDMA。</li><li>Monitor Client 是 monitor 客戶端模塊，用於跟 monitor 通信。</li><li>Command Dispatcher 是消息處理模塊，用於接收處理客戶端的數據請求。</li><li>raft Protocol Processer 用於處理 raft RPC 消息、選舉、成員變更等 raft 協議規定的內容。</li><li>raft Log Manager 負責管理和持久化 raft Log，持久化 raft Log 使用了 spdk blob。</li><li>Data State Machine 存儲用戶數據，使用了 spdk blobstore。</li><li>raft Log Entry Cache 用於緩存 raft Log，提高性能。</li><li>KV System 則提供 kv api，持久化時使用了 spdk blob。</li></ul><h1><a id="fastblock 組件及交互邏輯" class="anchor" href="https://gitee.com/openeuler/fastblock#fastblock%E7%BB%84%E4%BB%B6%E5%8F%8A%E4%BA%A4%E4%BA%92%E9%80%BB%E8%BE%91"></a>fastblock 組件及交互邏輯</h1><h2><a id="monitor" class="anchor" href="https://gitee.com/openeuler/fastblock#monitor"></a>monitor</h2><p>monitor 服務負責維護存儲節點狀態和節點加入刪除、存儲卷的元數據、維護集羣的拓撲結構、響應用戶創建 pool 等操作、根據當前的拓撲結構在 osd 上均勻創建 raft group 等。monitor 作為集羣管理工具，並不需要存儲數據，也不需要追求極致性能，所以使用 golang 進行實現, monitor 使用 etcd 進行多副本存儲。<br>
monitor 集羣是一致性的重要保證，因為客戶端、osd 看到的都是相同的視圖。對於所有客戶端的 io 操作都只能看到 pg 這一層，而 osd 和客戶端都會在啓動時開啓一個定時器定時去向 monitor 獲取 osdmap 和 pgmap 信息，所以所有的 osd 和客戶端都能夠看到相同的 pg 狀態變化並作出相同的相應，針對特定 pg 的寫入操作也不會寫到錯誤的地方。<br>
詳情可參考<a href="https://gitee.com/openeuler/fastblock/blob/master/monitor/README.md" title="monitor 簡介">monitor 簡介</a></p><h2><a id="osd-rpc 子系統" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-rpc%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd rpc 子系統</h2><p>rpc 子系統是連接各模塊的重要系統，出於異構網絡的要求，rpc 子系統的實現了兩種方式，即基於 socket（Control rpc）的和基於 rdma（Data Rpc 和 Raft Rpc）的，基於 socket 的就是經典的 linux socket 應用場景，而基於 rdma 的 rpc 則是使用異步 rdma(即 rdma write) 語義實現的。<br><img src="https://gitee.com/openeuler/fastblock/raw/master/docs/rpc_subsystem.png" alt="rpc 子系統" referrerpolicy="no-referrer">
上圖是 fastblock 中各個模塊之間的聯繫，由圖中可以看出使用了三種類型的 rpc，分別為 Control Rpc、Data Rpc 和 Raft Rpc:
Control rpc： 用於在客戶端與 monitor 之間，osd 與 monitor 之間傳遞 osdmap、pgmap 和 image 信息等數據，這些數據量不大，頻率不高，因此可以使用基於 socket 的實現;
Data rpc：用於在客戶端與 osd 之間傳輸對象數據操作和結果，這些數據量比較大，頻率會很高，因此需要基於 rdma 的方法;
Raft rpc： 用於在 osd 之間傳輸 raft rpc 協議內容，裏面會保護對象數據，這些數據量比較大，頻率會很高，因此需要基於 rdma 的方法。
Data rpc 和 Raft rpc 使用 protobuf 的 RPC 框架，網絡交互部分代碼使用 RDMA,rpc 傳輸數據的序列號都使用 protobuf。</p><h2><a id="osd-raft 子系統" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-raft%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd raft 子系統</h2><p>raft 通過選舉一個領導人，然後給予他全部的管理複製日誌的責任來實現一致性。領導人從客戶端接收日誌條目（log entries），把日誌條目複製到其他服務器上，並告訴其他的服務器什麼時候可以安全地將日誌條目應用到他們的狀態機中。 raft 在已經有很多開源實現，我們參考<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fwillemt%2Fraft" title="raft 的 C 語言實現">willemt</a>的 C 語言 raft 實現，並額外實現了 multi-raft，這個模塊主要包括了:</p><ul><li>raft groups 的管理，包括 raft 的創建、修改和刪除;</li><li>raft 選舉以及選舉超時處理;</li><li>raft log 處理，包括 log 緩存、log 落盤和 log 複製到 follower 節點;</li><li>數據 state machine 處理，既數據落盤;</li><li>raft 快照管理和 raft log recovery;</li><li>raft 成員變更管理 (暫未實現);</li><li>raft 心跳合併。</li></ul><p>實現 multi-group raft,意味着有多個 raft 並存，每個 raft 的 leader 需要給它的 follower 發送心跳包，因此就會有多個心跳包，如果 raft 過多就會導致心跳包過多，佔用大量的帶寬和 cpu 資源。解決方法也很簡單，每個 osd 可能屬於多個 raft，因此可以對相同 leader、相同 flower 的 raft 進行心跳的合併，這樣就可以減少心跳包數量。如下圖所示，有兩個 pg（raft）分別為 pg1 和 pg2，pg1 和 pg2 中都包含 osd1、osd2 和 osd3，osd1 是 leader，osd1 需要給 osd2 和 osd3 分別發送 heartbeat (pg1)，pg2 中 osd1 需要給 osd2 和 osd3 分別發送 heartbeat (pg2)。心跳合併後，只需要 osd1 給 osd2 和 osd3 分別發送 heartbeat (pg1, pg2)。
<img src="https://gitee.com/openeuler/fastblock/raw/master/docs/heartbeat_merge.png" alt="心跳合併" referrerpolicy="no-referrer"></p><h2><a id="osd-kv 子系統" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-kv%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd kv 子系統</h2><p>kv 子系統用於存儲 raft 的元數據、存儲系統本身的數據，由於數據量不大，就自己設計了一套。因為數據量不大，內存中的 hash map 就可以存儲所有數據，提供 put、remove 和 get 接口，每隔 10ms 把 hash map 中修改的數據寫到磁盤中。</p><h2><a id="osd-localstore 子系統" class="anchor" href="https://gitee.com/openeuler/fastblock#osd-localstore%E5%AD%90%E7%B3%BB%E7%BB%9F"></a>osd localstore 子系統</h2><p>本地存儲基於 spdk blobstrore 進行存儲，包含 3 個存儲功能模塊：</p><ul><li>disk_log: 存儲 raft log，一個 pg(對應一個 raft 組) 對應一個 spdk blob。</li><li>object_store: 存儲對象數據，一個對象對應一個 spdk blob。</li><li>kv_store: 每個 cpu 核擁有一個 spdk blob。保存當前 cpu 核上的需要保存的所有 kv 數據，包括 raft 的元數據、存儲系統本身的數據。
如下圖所示，假設我們運行了兩個 raft，localstore 為這兩個 raft 提供了 log、object 和 kv 這 3 部分存儲功能。
<img src="https://gitee.com/openeuler/fastblock/raw/master/docs/osd_localstore.png" alt="本地存儲引擎" referrerpolicy="no-referrer"></li></ul><h2><a id="客戶端" class="anchor" href="https://gitee.com/openeuler/fastblock#%E5%AE%A2%E6%88%B7%E7%AB%AF"></a>客戶端</h2><p>客戶端用於創建、修改和刪除 image，把用戶對 image 的數據操作轉換為對 object（osd 處理的基本數據單元）的操作，然後封裝為 Data Rpc 消息發送給 pg 的 leader osd，並接收處理 leader osd 返回的響應，結果返回給用戶。 客戶端有多種模式：使用 spdk vhost 提供給虛擬機使用；使用 NBD 提供給裸金屬使用；使用 CSI 提供給虛擬機使用。這三種模式最終都會調用 libfastblock 庫進行 image 到 object 的轉換，並和 osd 通信。 下面主要介紹使用 spdk vhost 提供給虛擬機使用的模式:<br>
調用 spdk 庫創建一個 vhost app，spdk 資源初始化後，需要開啓一個定時器去向 monitor 獲取 osdmap、pgmap 和 image 信息。
使用 spdk 的 rpc.py 腳本向 vhost app 發送創建 bdev（bdev_fastblock_create）的請求，vhost app 收到請求後創建 image，把 image 信息發送給 monitor，創建 bdev 設備，然後註冊此設備的操作接口（此接口會調用 libfastblock 庫）。
使用 spdk 的 rpc.py 腳本向 vhost app 發送創建 bdev 的 vhost-blk controller（vhost_create_blk_controller）的請求，vhost app 收到請求後打開 bdev 設備，註冊一個 vhost 驅動去處理 vhost 消息（創建一個可供客戶端 (如 qemu) 連接的 socket，並遵循 vhost 協議實現連接服務，這是 DPDK 中已實現的功能）。
libfastblock 把用戶對 image 的數據操作轉換為對 object（osd 處理的基本數據單元）的操作，然後封裝為 Data Rpc 消息發送給 pg 的 leader osd，並接收處理 leader osd 返回的響應。</p><h1><a id="代碼結構及編譯" class="anchor" href="https://gitee.com/openeuler/fastblock#%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84%E5%8F%8A%E7%BC%96%E8%AF%91"></a>代碼結構及編譯</h1><p>fastblock 代碼主要位於 src、monitor 和 spdk 目錄中:</p><ul><li>src 目錄主要包含 raft 實現、rdma 通信、底層存儲引擎、塊層 API 封裝等功能, 詳情見<a href="https://gitee.com/openeuler/fastblock/blob/master/src/README.md" title="src 代碼簡介">src 目錄簡介</a></li><li>monitor 目錄則包含了集羣元數據存儲管理、monitor 選舉、pg 分配、clustermap 分發等功能, 詳情見<a href="https://gitee.com/openeuler/fastblock/blob/master/monitor/README.md" title="monitor 代碼簡介">monitor 目錄簡介</a></li><li>spdk 目錄是通過複用 spdk 的 rdma 通信模塊以支撐低延遲的 rpc 通信, 詳情見<a href="https://gitee.com/openeuler/fastblock/blob/master/spdk/README.md" title="spdk 目錄簡介">spdk 目錄簡介</a>
編譯之前需要先安裝依賴，目前已進行了 ubuntu 21.10 和 openEuler 22.03 版本的驗證，其他操作系統可酌情更改.</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./install-deps.sh</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>首次編譯時，需要獲取 spdk 和 abseil-cpp 等依賴，可通過運行以下命令分別編譯 Release 版本的 montior 和 osd:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">./build.sh -t Release -c monitor</span><span id="LC2" class="line">./build.sh -t Release -c osd</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>編譯完成後，<code>fastblock-mon</code>和<code>fastblock-client</code>二進制位於<code>mon/</code>目錄下，而<code>fastblock-osd</code>和<code>fastblock-vhost</code>二進制位於<code>build/src/osd/</code>目錄和<code>build/src/bdev</code>目錄下。
後續 osd、vhost 有代碼改動，則可僅在<code>build/</code>目錄下編譯，而 monitor 有改動則可僅在<code>mon/</code>目錄下<code>make</code>即可。</p><h1><a id="部署及性能測試" class="anchor" href="https://gitee.com/openeuler/fastblock#%E9%83%A8%E7%BD%B2%E5%8F%8A%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95"></a>部署及性能測試</h1><p>參考<a href="https://gitee.com/openeuler/fastblock/blob/master/docs/performance_test_1012.md" title="性能測試報告">部署及測試報告</a>, 在我們的測試環境中，在每個 osd 僅適用一個核的情況下，獲得了 4k 隨機寫單線程 100us 以下的延遲以及併發 41 萬 iops 的性能。</p><h1><a id="future-works" class="anchor" href="https://gitee.com/openeuler/fastblock#future-works"></a>future works</h1><ul><li>實現卷快照、快照組等功能</li><li>實現卷 QoS</li><li>osd 和 client 多核性能優化</li><li>實現本地存儲引擎的可恢復性，以及本地存儲引擎優化</li><li>添加測試系統，進行單元測試、集成測試，特別是 raft 層和本地存儲引擎的故障測試</li><li>接入 CI 系統</li><li>實現可定製的 monitor 的 pg 分配插件</li><li>實現 raft 成員變更及與 monitor 的 pg 分配整體聯調</li><li>優化 osd client 的 rdma 連接管理</li><li>重寫 rdma 傳輸層以替換 spdk nvmf 版的 rdma 傳輸層</li><li>支持 DPU 卸載 vhost</li><li>監控數據導出及集羣運行時數據展示</li><li>部署工具開發及系統配置文件簡化</li><li>支持卷加解密功能</li><li>支持卷共享</li></ul>]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 02:58:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/openeuler/fastblock</guid>
            <link>https://gitee.com/openeuler/fastblock</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 如何做到人均告警減少 90%？B 站新一代告警平台的設計與實踐]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h1>一分鐘精華速覽</h1><p>B 站的業務規模和用戶羣體不斷擴大，對於服務的穩定性和可用性的要求也日益增高。這就需要 B 站的監控告警系統能夠及時、準確地發現和定位問題，以便儘快解決，維護好用戶的使用體驗。</p><p>本文是對 B 站在告警監控系統上的一次重要迭代和優化的詳細記錄。文章詳細闡述了 B 站對告警平台設計思路和優化迭代，以及在實現過程中遇到的問題和解決方法。特別是對於告警定位的精準性和定位效率的提升，文章給出了新的設計方案和實踐方法。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1c59a16c99cd6269dbb40c664c5cf2055c4.png" alt="file" referrerpolicy="no-referrer"></p><h1>作者介紹</h1><p><img src="https://oscimg.oschina.net/oscnet/up-a440bfaf0e2d837fc556f9759e77fe1f9e6.png" alt="file" referrerpolicy="no-referrer"></p><p>嗶哩嗶哩資深開發工程師——王程田</p><p>TakinTalks 穩定性社區專家團成員，嗶哩嗶哩資深開發工程師。2020 年加入 B 站先後負責事件平台，鏈路追蹤，AIOps 及告警平台方向技術演進 &amp;平台迭代。完成了新一代告警平台落地，達成了 99 分位一分鐘內的異常端到端發現，實現了人均告警從每週 1000+條/人到 70+條/人告警治理上的突破。</p><p>溫馨提醒：本文約 6000 字，預計花費 8 分鐘閲讀。</p><p>TakinTalks 穩定性社區後台回覆 「交流」 進入讀者交流羣；回覆「1130」獲取課件；</p><h1>背景</h1><p>在 B 站的多元化業務中，告警平台起着至關重要的作用。無論是視頻播放、彈幕發送、用戶評論、直播間管理，還是後台的內容審核、數據統計等，都離不開系統的穩定運行。告警平台可以實時監控這些業務系統的運行狀態，一旦出現異常，就會及時發出告警示，使運維人員能夠迅速定位問題，及時進行處理。</p><p>然而，維護這些業務的穩定運行並非易事。從告警發生的前、中、後三個階段，即生產端、傳輸端和消費端來看，B 站的告警平台設計都面臨着不小的挑戰和複雜性。 <img src="https://oscimg.oschina.net/oscnet/up-1dd0249404eb178d97848101b0fd3492b8f.png" alt="file" referrerpolicy="no-referrer"></p><p>考慮到這些業務需求和複雜度，我們着手對 B 站新一代告警平台進行了全面升級，結果達成了人均告警減少 90%，根因分析準確率高達 87.9% 的突破。在本文中，我將概述新一代告警平台的設計理念，並重點分享該平台在告警降噪和告警智能化分析方面的實施策略。</p><h1>一、告警平台做了哪些重點設計？</h1><h2>1.1 業務核心訴求</h2><p>在告警平台的設計和迭代過程中，我們不斷收到各類業務需求。總體上，這些需求的核心都集中在「以質量為中心，及時發現並處理異常，確保業務穩定性」。具體來説，需求場景可劃分為風險場景和故障場景。在風險場景中，需要提前感知並有效應對潛在問題；而在故障場景中，需要迅速發現線上問題，及時響應，以實現快速恢復。</p><p>在滿足這些業務需求的過程中，我們提煉出三個核心訴求和目標：</p><p>有效性：我們期望所有收到的告警都是有效的，即每次接收到告警時，都確實存在異常，而且這條告警對當前的接收者是具有意義的。</p><p>及時性：對於高優先級的異常，我們希望能在第一時間觸達並被用戶感知，以便他們能夠及時採取行動進行處理。</p><p>覆蓋性與跟進：我們期望實現告警的全面覆蓋和跟進。從用戶的角度來看，他們希望所有自己負責的業務或應用的場景都能被告警覆蓋，同時，他們也希望能瞭解不同場景的告警覆蓋情況。當規則產生異常後，用戶需要有一個便捷的方式去快速處理並跟進解決問題。</p><h2>1.2 告警平台詳細設計</h2><h3>1.2.1 閉環模型</h3><p>在告警平台的詳細設計中，我們基於前述的目標和業務需求，構建了一個閉環模型。這個模型旨在保證各關聯方的積極參與，從而推動目標的持續改善。特別的，告警定義和告警治理是模型中的兩個關鍵環節，因為它們決定了告警降噪和召回效果的優劣。 <img src="https://oscimg.oschina.net/oscnet/up-412a40c1cfbb39cb0c17812de113d3f3d26.png" alt="file" referrerpolicy="no-referrer"></p><p>接下來將詳細介紹 B 站告警定義、檢測、通道側功能的設計。重點是告警處理、根因分析以及告警治理側的實踐內容。</p><h3>1.2.2 告警接入</h3><p>在告警接入環節，主要區分了三個場景，這些場景的設計可以覆蓋業務對於告警接入的大部分需求。</p><p>1）面向平台的場景</p><p>我們為平台覆蓋的告警場景提供告警規則和模板的開放接口能力，支持多租戶規則集成。不同租戶可以基於預定義的模板進行配置，可以在業務申請或者註冊資源時，快速完成告警的定義和覆蓋，整個過程成本低，便捷性高。</p><p>2）面向自定義場景</p><p>我們為業務直接開放告警規則定義，包括規則的觸發條件配置、表達式及通知策略的配置。</p><p>3）面向第三方事件</p><p>我們開放事件集成能力，用戶可以通過註冊事件完成准入，主動觸發方式發送到告警平台，告警平台完成後續閉環的處理。</p><h3>1.2.3 告警計算</h3><p>我們設計了一個分佈式的告警計算引擎，實現了多級的調度。基於線上全量生效的規則，進行全局調度，將告警的場景、可用區調度到不同的可用區和計算集羣下。在同一個計算集羣下，進行本地調度，將任務調度到不同的計算節點，實現負載均衡。計算節點會週期性地檢測數據判斷告警是否觸發，觸發後將投遞到告警通道。 <img src="https://oscimg.oschina.net/oscnet/up-6dd8eb1e13f1625434405ab2a73c51430a1.png" alt="file" referrerpolicy="no-referrer"></p><h3>1.2.4 告警通道</h3><p>主要做降噪、渲染、分發，以實現準確的投遞和快速的觸達。對於引擎側產生的告警事件，在通道會生成告警消息，然後先經過降噪模塊，依次完成通知窗口攔截、通知頻率攔截、接警攔截、靜默攔截、抑制攔截、告警聚合等。接下來，經過告警渲染分發模塊，完成渲染接收人、渲染通知通道、渲染通知模板，最終觸達到用戶並更新告警的投遞狀態。 <img src="https://oscimg.oschina.net/oscnet/up-9ceb09b7a6a29d8ed6874d76ba957d1e1c1.png" alt="file" referrerpolicy="no-referrer"></p><h1>二、告警治理有哪些實踐心得？</h1><p>下面我將主要闡述 B 站在告警治理的實踐過程中，如何推行告警治理策略，降低告警噪聲，以及提高告警的有效性。</p><h2>2.1 告警治理背景</h2><p>過去一段時間裏，B 站的告警通知氾濫問題，對技術團隊和平台來説，這已經成為一個多年的困擾，也是一個較大的痛點。一方面，隨着穩定性問題的出現以及新平台的接入，告警規則和配置不斷增加；另一方面，又缺乏有效的告警治理和運營分析機制。這導致告警數量越來越多，很多用戶也不會去主動治理告警，反而選擇設定免打擾。最後，真實的風險和異常往往被淹沒在眾多告警中，無法第一時間被感知到。</p><p>用一句話來概括，就是「太多的告警就相當於沒有告警」。</p><h2>2.2 問題分析</h2><p>我們認為，這主要由以下四部分原因導致：</p><p>告警定義不合理：很多規則缺乏有效的維護，大量的規則在觸發後，並不代表有異常發生，業務也不會去處理。此外，有些告警的粒度太細，導致同一異常觸發後產生大量的告警，放大了整個通知的影響。</p><p>通知人數放大：由於歷史組織架構的變更或臨時排查問題，定位權限相耦合，導致服務樹長期缺乏治理，造成告警通知人數的大幅度放大，經常發給一些無關的人員。</p><p>缺少分析治理工具：雖然大家都知道告警太多了，需要治理，但是卻沒有頭緒，也沒有合適的平台能力幫助他們分析告警主要集中的部分，從而進行有針對性的治理。</p><p>缺乏有效的運營機制：大家對治理告警的動力不足，同時也缺乏有效的機制和規範約束。在歷史上可能經過一些短期治理後，告警又出現反彈，治理效果就不復存在。</p><h2>2.3 告警治理的三個階段</h2><p>在分析了告警氾濫的原因後，我們開始了告警治理，這個過程主要分為三個階段。 <img src="https://oscimg.oschina.net/oscnet/up-88282d9da6f4baae2fd9486d47eae1f9705.png" alt="file" referrerpolicy="no-referrer"></p><p>第一階段：目標設定</p><p>經過多輪的會議和討論，我們確定了告警數的指標，將原先每週超過 1000 條的告警數量降低到每週 80 條。這個目標在初始階段看起來幾乎是不可能完成的。然而，我們認為這 80 條告警是一個業務人員能夠逐條響應處理的合理範圍。於是，我們堅持以這個目標去執行，並盡力去達成。</p><p>第二階段：數據分析</p><p>我們將告警數據集成到數據倉庫中，提供了多維度的分析視圖，為告警治理提供了數據支持。通過計算公式來確定影響因子，公式基於告警通知數量，即：告警通知數量=告警數<em>每次觸發通知的人數</em>降噪係數。這個公式幫助我們明確了治理的方向和重點。</p><p>第三階段：治理動作</p><p>在這個階段，我們開始執行一系列治理動作。</p><p>首先，優化了告警項，與 SRE 和平台同事一起評估了默認告警項的合理性，對無效的告警項進行了關閉處理。對於一些不合理的告警項，我們評估並優化了其表達式和默認閾值等條件，以降低告警噪聲並提高告警的有效性。</p><p>其次，為瞭解決通知人數放大的問題，優化了告警接收人的設置。我們深度參與並推動了服務樹研發和負責人角色的校準，並推出了值班，升級等能力，以縮小告警的通知範圍，有效地降低了通知人數放大的噪聲。</p><p>最後，豐富了通道的告警降噪策略，支持了規則組的微調攔截能力，以及多維度下的告警彙總和聚合能力，從而更高效降低了告警噪聲。</p><h2>2.4 告警治理過程經驗總結</h2><p>在進行了一系列的告警治理行動後，我們對治理過程進行了總結和思考。主要從以下三個方面進行分享：</p><p>1）異常召回是底線</p><p>在整個治理過程中，集中處理的主要是無效的噪聲告警，然而，絕不能忽視真實且有效的告警。在治理中，我們始終堅守一個原則，即不能犧牲異常的召回率。因此，我們將注意力集中在那些持續觸發、重複觸發以及異常放大等不合理的規則上，以及 Top 級別的規則上，並對這些問題進行專項治理。</p><p>2）運營推進不可少</p><p>實際上，治理過程就是一個運營推進的過程。在這個過程中，創建了數十個羣組，制定了無數的治理、推進和跟進文檔，以確保整個密集且強制性的告警治理工作的落實。同時，也與各個場景平台以及 SRE 進行了緊密合作，共同推動了告警治理工作。</p><p>3）分層分級抓重點是方向</p><p>我們借鑑了毛劍老師的理念，強調分層分級，抓住重點，尤其是保證業務可用性的核心告警。對於事件類的告警，建議記錄並可查詢，以避免淹沒其他重要的告警通知。對於一些不適合直接通知業務側的依賴告警，建議通過關聯的方式來呈現，這樣可以有效地降低告警的噪聲。</p><h2>2.5 告警治理效果</h2><p>近半年地推式的告警治理，告警數據得到顯著改善：</p><p>中位數告警 1000 次/周減少到 74 次/周，減少到原來的 7.4%；</p><p>整體告警通知數從治理前 300w+減少到 22w+，減少到原來的 7%；</p><p>人均告警通知數從 1600+減少到 140，減少到原來的 8.8%； <img src="https://oscimg.oschina.net/oscnet/up-4aaba5026a5563dc1f202fb6d8ec6184710.png" alt="file" referrerpolicy="no-referrer"></p><h2>2.6 建立長效治理機制</h2><p>為了確保告警治理所取得的成果能夠持續穩定，我們構建了一套長效治理機制，具體包含以下三個方面：</p><p>1）便捷治理分析工具</p><p>包含了一個告警治理分析大盤，它被集成在告警平台上。這個大盤支持從業務、個人和公司等多個視角，通過多個維度對告警的分佈和趨勢進行分析。此外，我們還利用了一些治理工具，為快速治理提供了必要的能力。</p><p>2）數據報表訂閲</p><p>我們與 SRE 各個組件平台達成了共識，制定了共同的目標，並生成了各類數據報表的訂閲。持續跟進這些報表，以防止告警的惡化，並持續進行告警治理。 <img src="https://oscimg.oschina.net/oscnet/up-c3811ee980a3d066894a0537c26b3846b35.png" alt="file" referrerpolicy="no-referrer"></p><p>3）接入管控</p><p>針對新接入的規則和平台場景，增加了一些告警數據接入的人工校驗，以及平台側的校驗和噪聲監控。對於一些不合理的規則，我們會建議對應的接入方進行優化，以保持告警治理成果。</p><h1>三、告警根因分析是如何設計和應用的？</h1><p>結合當下業界廣泛運用的前沿技術，例如異常檢測、智能降噪、智能合併策略以及根因分析等，我將重點分享 B 站在根因分析方面的實踐和實戰經驗。</p><h2>3.1 根因分析背景</h2><p>隨着 SLO 體系的日益完善，更多的業務被接入到 SLO 體系中。這使得我們有了明確的異常定義和觸發對象，能夠更精確地實施根因分析。</p><p>此外，B 站已經設定了 「1-5-10」 的目標。目前，已經通過優化告警計算採集和通道，實現了 99 分位端到端一分鐘內的問題發現。然而，對於 5 分鐘的定位，仍存在一些瓶頸。定位過程過於依賴人工經驗，存在一定的不確定性。人工專家經驗因人而異，同時受場景影響，導致定位效率也不一致。另外，由於平台能力的建設和交互，以及一些極端情況下的響應延時，如凌晨故障或者出差等場景，都會影響定位效率。</p><p>最後，用戶需求的積累也在不斷增加。隨着業務和基礎設施的增長，人們越來越關注告警定位的效率，並積累了大量定位告警的經驗。因此，對於根因分析的需求日益迫切，同時，根因分析的實施條件也逐漸成熟。</p><h2>3.2 根因分析設計</h2><h3>3.2.1 根因分析設計 1.0 版</h3><p>首先，我們採用了以 SLO 告警為基礎的設計方案，對微服務架構下的黃金指標進行定位能力的設計，這就是 1.0 版根因分析設計。整個設計方案主要包含三個階段。 <img src="https://oscimg.oschina.net/oscnet/up-9bd92ad17719b87e37ee6ac443eaf813c83.png" alt="file" referrerpolicy="no-referrer"></p><p>首階段，我們監聽 SLO 的告警觸發，關聯錯誤的範圍和數據，然後基於這些數據分析日誌指標，挖掘出異常的維度。例如，錯誤可能集中在特定集羣的某個實例下，或者某個上游請求的某個接口。</p><p>第二階段，我們根據這些錯誤維度，對應用側的鏈路調用進行關聯，找出異常期間的異常鏈路。通過聚合分析，能區分出耗時和錯誤的場景，通過關鍵路徑分析和剪枝下鑽的方式，定位到異常鏈路下的異常節點。</p><p>最後一階段，將定位到的異常節點映射到知識圖譜中，通過數據圖譜關聯到相關的數據庫、緩存、消息隊列、容器、機器、交換機、機櫃、機房等信息。然後，結合異常、告警、變更等信息，通過關聯分析模型進行打分推薦，最終推薦出可能的 Top 根因排序。</p><p>儘管這個 1.0 版的根因分析設計在某些場景下的準確率可以接受，但是它仍然存在一些瓶頸。</p><p><img src="https://oscimg.oschina.net/oscnet/up-54c493835c8d5726c828410f1bc25b115b6.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.2.2 根因分析設計 2.0 版</h3><p>在設計 2.0 版的根因分析時，我們進行了全面的調研，深入瞭解了業界資深的 SRE 和業務同事們在定位問題時的過程。</p><p>總結下來，這個過程主要是：在告警觸發後，根據專家的經驗，關聯到具體的異常事件；然後再根據這些經驗，分析這個異常可能由哪些原因導致，並找出這些原因的相關指標和日誌等觀測數據；最後，通過觀察這些數據，判斷出導致異常的根源。</p><p>在設計 2.0 版的過程中，我們力求將這個過程普遍化，並構建一個異常知識圖譜，將專家的經驗沉澱下來。同時，也開放了根因分析的集成和知識目錄的功能，提供通用的根因分析能力。</p><p><img src="https://oscimg.oschina.net/oscnet/up-e5caf92711bcb72bd249bb36169653cf1be.png" alt="file" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-f219736ec60c443fe1e4c5ee319640d9a75.png" alt="file" referrerpolicy="no-referrer"></p><p>根因分析的實現主要圍繞知識的定義。這裏的知識主要是基於異常節點定義。每個異常都會定義在具體的某個實體節點下，例如某個應用或某個數據庫的集羣實例。每個異常都會關聯到具體的數據節點，比如日誌、指標、告警等，通過這些數據我們可以檢測和判斷異常的發生。同時，異常之間也存在傳導關係，一個異常可能由哪些異常導致，這些異常之間的傳導鏈路和關聯關係是怎樣的。這就是我們在知識工程中定義的整個知識結構。</p><p>這種基於知識圖譜的根因分析方式，很好地解決了 1.0 版中遇到的問題。使我們能夠更深入地理解異常發生的原因，更準確地定位到問題的根源。通過將專家的經驗進行系統化的沉澱，不僅提高了問題定位的效率，也使得知識的傳承和積累成為可能。</p><h3>3.2.3 AIOps 算法支持</h3><p>根因分析的能力建設，離不開 AIOps 算法的支撐。目前，我們已經構建了一個全面的算法體系，設計了指標、日誌、事件、鏈路等多個場景。同時，也根據不同類型的數據，支持了時序預測、異常檢測、指標分類以及日誌聚類、多維下鑽，和事件聚類、鏈路分析等多個場景的算法能力。 <img src="https://oscimg.oschina.net/oscnet/up-59882e82b01a1f6dfdd569508b48de9e812.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.2.4 關聯分析模型升級</h3><p>在關聯分析的過程中，我們將異常圖通過特徵構建、模型加載，基於模型推理預測並打分，最終推薦出異常的根因和傳導路徑。特徵設計包括：時間依賴特徵、圖關係/距離特徵、因果特徵、路徑相似特徵、事件類別特徵。</p><p>模型構建方面，在初期主要是基於冷啓動的方式，預定義了一些異常之間的傳播係數。隨着樣本標註數據的增多，開始進行模型的訓練，並基於模型進行推理和推薦。此外，我們也支持 GBDT 模型，以進一步提升關聯分析能力。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d6b0445d907edbb174e1774270aaad5e9fe.png" alt="file" referrerpolicy="no-referrer"></p><h2>3.3 難點和重點</h2><p>在根因分析的過程中，我們面臨着一些難點和重點。難點主要在於，如何有效評價推薦的根因，以及如何獲取用戶的準確率和評價數據。這對於評估不同版本，以及根因分析的準確率和有效性，以及幫助模型進行迭代至關重要。為瞭解決這個難題，我們進行了以下四部分工作：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5420196edcfd8b93bbbd8b23c00f71ee132.png" alt="file" referrerpolicy="no-referrer"></p><p>在整個過程中，一個重點是圍繞專家經驗的收集和構建。我們會與不同業務和 SRE 同學深度溝通，梳理相關的異常知識和專家經驗，完成這部分知識的定義。</p><p>對於組件方面，我們會與相關同學持續完善這部分知識的定義和構建能力。針對一些特殊場景，也會提供外部專家經驗的集成方案，提供根因分析的集成能力和接口，讓外部的根因也可以通過分析能力完成，實現人工告警的推薦、展示和評價。</p><h2>3.4 案例分析</h2><h3>3.4.1 上游流量突增導致服務限流，可用率下降</h3><p>在這種情況下，可以基於告警關聯到具體服務的 SLO 異常，並且下鑽得到具體的異常接口和錯誤。同時，通過異常關聯分析可以檢測到上游的流量突增，明確具體哪一個入口的流量突增。有了這些信息，業務側可以對上游的服務進行一些限流的配置並進行修復。</p><p><img src="https://oscimg.oschina.net/oscnet/up-447ee94180d00bc126ef72c16b89a733600.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.4.2 下游變更導致服務異常影響網關接口可用率</h3><p>可以通過根因分析關聯到具體的鏈路，並關聯到具體下游的異常和變更。最終，可以推薦出 AI 服務的變更是影響網關接口的主要原因。業務同學可以快速找到對應的變更人，然後進行排查和回滾等止損操作。</p><p><img src="https://oscimg.oschina.net/oscnet/up-d0179cd8afb98967fa016c6b5edc192f2ce.png" alt="file" referrerpolicy="no-referrer"></p><h3>3.4.3 下游 Redis 請求異常影響服務接口</h3><p>可以通過內部分析以及異常關聯到具體的服務，並構建起異常的傳導路徑。同時，可以推薦出具體的異常請求耗時和日誌。此外，業務側也可以與相關組件的同學一起進行更深入的定位。</p><p><img src="https://oscimg.oschina.net/oscnet/up-5ffa4fd875968133050d7a1cdeac23233f3.png" alt="file" referrerpolicy="no-referrer"></p><h2>3.5 效果評估</h2><p>根因分析已經落地，並取得了一些成效——</p><p>根因分析次數：20652/天</p><p>準確率：87.9%</p><p>召回率：77.5%</p><p>分析耗時 95 分位：10s</p><p>平均分析耗時：4s 內（這意味着，在告警發出後，平均僅需 4 秒鐘就可以推薦出根因，業務人員打開告警卡片就可以直接看到對應的異常根因。）</p><p><img src="https://oscimg.oschina.net/oscnet/up-c32a5ed1c13a8e5e899857ff7a6633ab6ae.png" alt="file" referrerpolicy="no-referrer"></p><h1>四、總結與展望</h1><p>設計告警平台時，需要考慮到多種多樣的業務需求和不同的應用場景。理解這些需求的本質，然後基於這個本質來構建平台的能力以及關鍵功能模型，並設計出閉環邏輯，以此來設計出更貼近業務需求的告警平台。其次，告警治理過程是必不可少的。無論告警的數量多少，只有通過完善的告警治理機制，才能使整個系統的閉環優化規則的定義，持續提升告警的有效性，發揮告警的價值。最後，告警與人工智能的結合是未來的發展趨勢。通過深度結合的一些能力，可以提升故障發現的準確率，減少定位和恢復止損的時間，為質量管理和系統穩定性提供保障。（全文完）</p><h1>Q&amp;A：</h1><p>1、這個告警治理是否主要靠人力篩選減少規則？</p><p>2、業務側的告警關聯降噪可以舉個例子嗎？是在監控側關聯還是在告警側關聯？業務告警可以和基礎告警關聯嗎？</p><p>3、告警後有進一步的自動分析場景嗎？</p><p>4、監控告警通知的發送狀態和效果怎麼管理？怎麼處理通知失敗或異常的情況？</p><p>5、在告警合併方面，高優告警怎麼不被淹沒？同時保證低優告警的質量巡檢？</p><p>6、怎麼優化根因分析的效率和準確性，來支持實時分析和批量處理呢？根因分析過程中，大量的數據和日誌信息怎麼管理和存儲？有哪些最佳實踐和經驗可以分享？</p><p>以上問題答案，歡迎點擊「<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.shulie.io%2F%3Fp%3D7721" target="_blank">閲讀全文</a>」，觀看完整版解答！</p><p>聲明：本文由公眾號「TakinTalks 穩定性社區」聯合社區專家共同原創撰寫，如需轉載，請後台回覆「轉載」獲得授權。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 02:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/5129714/blog/10321815</guid>
            <link>https://my.oschina.net/5129714/blog/10321815</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Oxlint 正式面市，JavaScript 開發者的新選擇？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 12 月 12 日，JavaScript 和 TypeScript 開發者們迎來了一個新工具的誕生——Oxlint。這個被設計用來快速捕捉錯誤或無用代碼的 JavaScript linter，以其顯著的性能優勢和易用性宣告了自己的市場入場。據報道，Oxlint 能夠在僅需幾秒鐘的時間內完成原本 ESLint 需要 75 分鐘才能完成的任務，這對於那些在持續集成環境中追求高效的大型項目來説，無疑是一種極具吸引力的改變。</p><p>然而，在技術社區，特別是在 HackerNews 上，對於 Oxlint 的討論並非全然積極。一部分人擔憂，儘管 Oxlint 在速度上有顯著提升，但這種優勢對於日常的開發工作可能並不那麼重要。畢竟，ESLint 的執行速度問題在多數情況下並不明顯，它只在大規模運行 lint 任務時才可能成為瓶頸。此外，Oxlint 的出現意味着可能需要重新實現 ESLint 的許多規則，這不僅降低了與現有生態的兼容性，也給未來的規則和語法更新帶來了同步維護的壓力。</p><p>另一方面，對於大型項目，優化 ESLint 的配置，比如僅掃描修改過的文件，可能就足以解決速度問題，而無需轉向全新的工具。這引發了一個更深層次的問題：開發和維護一個全新的工具是否真的值得，特別是對於商業項目而言，這種成本與收益的權衡需要更加審慎。</p><p>而且，不可忽視的是，Oxlint 在初期可能無法與 ESLint 的規則集完全兼容，功能上可能不如 ESLint 豐富。這對於那些依賴 ESLint 深厚生態的項目來説，可能是一個不小的挑戰。此外，關於 Oxlint 的性能提升，有觀點認為應該深入分析 ESLint 存在的性能瓶頸，並進行針對性優化，而不是簡單地通過更換工具來解決問題。</p><p>在這樣的背景下，Oxlint 的出現無疑給 JavaScript 和 TypeScript 的開發者們提供了一個新的選擇。它的高效性和易用性對於一些特定場景下的需求來説，可能是一個不錯的解決方案。但同時，它也帶來了一系列的考量，包括對現有生態的兼容性、功能的完備性，以及長期維護的可持續性等。</p><p>那麼，面對這樣一個新興工具，開發者們又該如何選擇？是否應該追求速度和效率，還是應該更加重視生態的完整性和成熟度？Oxlint 是否能夠在未來的技術演進中找到自己的定位，或者説，它能否引領一種新的開發工具趨勢？這些問題，可能還需要時間和更多的實踐來回答。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 16 Dec 2023 01:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271287</guid>
            <link>https://www.oschina.net/news/271287</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[生成式 AI 的落地焦慮，如何破？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span>自 ChatGPT 火爆出圈以來，各式大模型與生成式 AI 技術噴湧而出，醫療、金融、出行、消費零售、互聯網等各個行業都在尋找利用生成式</span></span><span><span> AI 技術賦能業務</span></span><span><span>創新</span></span><span><span>的方法。然而，</span></span><span><span>從摸索到落地，</span></span><span><span>企業</span></span><span><span>在應用</span></span><span><span>用生成式 AI 技術尚存在門檻，使用現成的技術服務又會產生安全等方面的顧慮，比如業務數據泄漏等問題。一時間，許多企業陷入進退兩難的境地。本篇就來説道説道企業在落地生成生式 AI 應用過程中的那些事。</span></span></span></span></p><ul><li><h2 style="text-align:left"><span><span><strong><strong><span><span><strong>從模型選擇到業務安全，生成式 AI 應用誕生的曲折</strong></span></span></strong></strong></span></span></h2></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>實際上，生成式 AI 市場經過一年多快速的發展，一方面市場上湧現出很多</span></span><span><span>大模型與配套服務，另一方面，企業面臨的難題也在與日俱增。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>首先，從模型的選擇開始，眼花繚亂的大模型就已經夠廠家喝上一壺。5 月 28 日，由中國科學技術信息研究所、科技部新一代人工智能發展研究中心聯合相關研究機構編寫的《中國人工智能大模型地圖研究報告》正式發佈，報告顯示，我國 10 億參數規模以上大模型已發佈近 80 個。再到 10 月中國新一代人工智能發展戰略研究院發佈的《2023 中國新一代人工智能科技產業發展報告》顯示，目前國內大模型總數達 238 個。而據北京經信局數據，截至 10 月初，北京發佈大模型數量達 115 個，其中通用大模型 12 個，垂類大模型 103 個。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>按照這個發展趨勢，「百模大戰」或許很快就會升級為「千模大戰」。而企業如何選擇大模型便會難上加難。在具體應用場景中，企業需要在準確性和性能平衡間作出衡量，有效地比較模型並根據其首選指標找到最佳選擇，這就需要深厚的數據科學專業知識，也會耗費大量的人力時間成本。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>而模型的選擇只是開始，確定模型之後，還需要結合自身業務，做模型的精調、訓練等工作。在這一步，公司的業務數據類型與大模型輸入所要求的數據類型需要做一定適配，同時輸入的數據需要具有代表性、多樣性、一致性和可靠性，這樣才能實現效果更佳的輸出，這便要求企業需要有既懂業務，又懂大模型技術的工程師對數據進行整理。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>此外，大模型的精調也需要大量的算力，需要投入大量的資金和時間來購買和維護硬件設備，或者租用雲服務，同時基礎設施也需要長時間的維護。而大模型技術作為新興技術，許多公司並沒有相應的人才儲備與經驗，這對企業來説也是不小的壓力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>模型本身的問題解決了之後，企業還要面臨安全隱患。比如很多使用方會擔心，用了某個大模型，那麼自己的數據會不會都被模型方看到甚至泄露？會不會導致敏感信息泄漏，或是生成違規內容等等？那麼，企業就需要確保數據在傳輸、存儲和處理的過程中不會被泄露或者濫用，以免給業務和聲譽帶來損失。</span></span></span></span></p><ul><li><h2 style="text-align:left"><span><span><strong><strong><span><span><strong>亞馬遜雲科技助力企業安全構建生成式 AI 應用</strong></span></span></strong></strong></span></span></h2></li></ul><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>面對種種挑戰，對於許企業來説，最佳選擇可以是給自己找一個 AI 助手，全方面輔助完成 AI 能力的嵌入，最常見的便是雲上大模型平台和服務。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>2023 年 11 月 28 日，2023 亞馬遜雲科技 re:Invent 在美國拉斯維加斯盛大開啓，並於 12 月 2 日圓滿落下帷幕。2023 年 12 月 12 日起，2023 亞馬遜雲科技 re:Invent 中國行城市巡展活動將在 10 大城市開啓，覆蓋北京、上海、廣州、深圳、成都、青島、南京、西安、杭州、長沙 10 個城市！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><img alt="" height="1068" src="https://oscimg.oschina.net/oscnet/up-2aec5379c01dccaa8d1cb0c81c83e824ec0.png" width="1600" referrerpolicy="no-referrer"></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>作為全球雲計算領域的年度風向標，2023 亞馬遜雲科技 re:Invent 為全球雲計算愛好者和構建者帶來了最新的產品和技術發佈、最前沿的領導者洞察和全球雲計算的最佳實踐。在今年 re:Invent 中，一系列重磅發佈成為大會焦點，從 Serverless、生成式 AI 時代的數據戰略、芯片與雲底座創新，到 Amazon Bedrock 的重磅更新、企業級生成式 AI 應用 (Amazon Q</span></span><span><span>) 的全新發布等等，系列組合拳為企業落地生成式 AI 應用全方位護航。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="1067" src="https://oscimg.oschina.net/oscnet/up-c52755aef19a7aa20abb1e9cd7e8662d7ab.png" width="1600" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>在多個新發布的動作中，一項全面託管服務的重磅更新引人注目——Amazon Bedrock 發佈更多模型選擇和全新強大功能。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>首先，Amazon Bedrock 上集成了 AI21 Labs、Anthropic、Cohere、Meta、Stability AI 和亞馬遜的多種行業領先大語言模型和其他模型，用戶可輕鬆訪問。不僅如此，為了幫助客戶在紛繁的模型中選擇更適合自己的，Amazon Bedrock 新功能可幫助客戶高效評估、比較和選擇最適合其應用場景和業務需求的模型。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>確定模型之後，企業往往需要針對模型做適配，或者説是擴展調優，最大程度地釋放數據價值。針對這些部分，Amazon Bedrock 知識庫功能使用上下文和相關公司數據定製模型響應：組織希望使用專有數據補充現有模型，以獲得更相關和更準確的響應。針對模型調優，Amazon Bedrock 中的 Cohere Command、Meta Llama 2 和 Amazon Titan 模型支持調優，為客戶的模型定製提供更多選項，Anthropic Claude 也即將支持調優。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>此外，Amazon Bedrock 也兼備代理功能，可以自動執行，使用公司系統和數據源執行多步驟任務。雖然模型能夠有效地進行對話和創建新內容，但如果能夠執行復雜的操作，例如解決問題以及與公司系統交互以完成任務（例如，旅行預定或訂購替換零件），它們可以提供更多價值。然而，這需要定製化地將模型與公司數據源、API 以及內部和外部系統集成起來。開發人員必須編寫代碼來協調模型、系統和用戶之間的交互，以便應用程序可以按邏輯順序執行一系列 API 調用。為了將模型與數據源連接起來，開發人員必須部署 RAG，以便模型可以根據任務調整其響應。最後，開發人員必須配置和管理必要的基礎設施，並制定數據安全和隱私策略。這些步驟非常耗時且需要專業知識，從而減慢了生成式 AI 應用程序的開發速度。現在正式可用、完全託管的 Amazon Bedrock 代理功能使生成式 AI 應用程序能夠跨公司系統和數據源執行多步驟任務。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>最後，在交互安全層面。雖然許多模型使用內置控件來過濾不良和有害內容，但企業希望進一步定製交互，以保證話題始終與業務相關，符合公司政策，並遵守「負責任的 AI」的原則。例如，銀行可能希望這樣設置其在線助手：避免查詢競爭對手、避免提供投資建議、以及限制有害內容。此外，應用戶要求，可能要變換或隱去用戶的個人身份信息（PII）以保證安全。企業希望以一種簡化的方式在生成 AI 應用程序中強化關鍵策略和規則，以提供所答即所問的用戶體驗並支持更安全地使用該技術。Amazon Bedrock 的 Guardrails 功能現已推出預覽版，使客戶能夠為生成式 AI 應用程序實施保護措施。藉助 Amazon Bedrock 的 Guardrails 功能，客戶可以根據應用程序要求和負責任的 AI 策略跨模型實施保護措施。這些應用程序根據客戶應用場景和「負責任的 AI」原則進行定製，因此這一功能可以增強用戶交互的安全性和隱私性。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="1067" src="https://oscimg.oschina.net/oscnet/up-28a6f412bca7e88f6847ddd2341600b1962.png" width="1600" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>目前，亞馬遜雲科技已經推出多款產品助力企業構建生成式 AI 應用，緩解 AI「焦慮」其中也不乏許多科技界合作伙伴。MongoDB 首席產品官 Sahir Azam 表示：「各行各業越來越多的客戶希望利用生成式 AI 來構建下一代應用程序，但許多人擔心數據隱私以及人工智能驅動的系統輸出的準確性。為了滿足客戶的需求，我們將 MongoDB Atlas 作為 Amazon Bedrock 的知識庫，以便我們的共同客戶可以利用其運營數據安全地構建生成式 AI 應用程序，以符合最終用戶期望的信任度和準確性來創建個性化體驗。通過這種集成，客戶可以訪問行業領先的基礎模型，並使用 MongoDB Atlas Vector Search 處理過的數據來創建應用程序，在正確的上下文中提供更多相關的輸出。利用 Amazon Bedrock 知識庫中內置的數據隱私最佳實踐，客戶可以節省在生成式 AI 運營上花費的時間，從而更專注於技術部署，以在，亞馬遜雲科技上提供更有吸引力的最終用戶體驗。」</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span>當然，除了 Amazon Bedrock，2023 亞馬遜雲科技 re:Inven 還有許多重磅發佈，並且在接下來的 2023 亞馬遜雲科技 re:Invent 中國活動中，亞馬遜雲科技也將對各個新產品新功能做深入解讀。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img alt="" height="1067" src="https://oscimg.oschina.net/oscnet/up-c47b8d38d09f54435ff17dbe0dd4b647787.png" width="1601" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fhttps%3A%2F%2Faws.amazon.com%2Fcn%2Fproducts%2F%3Faws-products-all.sort-by%3Ditem.additionalFields.productNameLowercase%26aws-products-all.sort-order%3Dasc%26awsf.re%253AInvent%3Devent-year%2523aws-reinvent-2023%26awsf.Free%2BTier%2BType%3D*all%26awsf.tech-category%3D*all%26trk%3D6ffebce9-f4cb-4ff0-910e-6b6ee3c74dc8%26sc_channel%3Del" target="_blank"><strong><span>點擊此處，一鏈速看亞馬遜雲科技 re:Invent 2023 的所有熱門發佈</span></strong></a><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fhttps%3A%2F%2Faws.amazon.com%2Fcn%2Fproducts%2F%3Faws-products-all.sort-by%3Ditem.additionalFields.productNameLowercase%26aws-products-all.sort-order%3Dasc%26awsf.re%253AInvent%3Devent-year%2523aws-reinvent-2023%26awsf.Free%2BTier%2BType%3D*all%26awsf.tech-category%3D*all%26trk%3D6ffebce9-f4cb-4ff0-910e-6b6ee3c74dc8%26sc_channel%3Del" target="_blank"><strong>。</strong></a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 10:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271239</guid>
            <link>https://www.oschina.net/news/271239</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[稚暉君創業公司再融資，金額超 6 億元，投前估值 35 億元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2560285742488705" target="_blank">據報道</a>，稚暉君創業公司智元機器人近日完成新一輪 A3 融資。</p><p>本輪融資由藍馳創投、中科創星、鼎暉投資、長飛基金、C 資本、高瓴創投、立景創新、三花控股集團、基石資本、臨港新片區基金和銀杏谷資本投資。 據瞭解，本輪投前估值為 35 億元，融資金額超 6 億元人民幣。</p><p>目前，該公司正在進行新一輪融資，投前 70 億元估值。截止發稿，官方並未給到回覆。</p><p>智元機器人因創始人「稚暉君」彭志輝而出名，公司希望對標特斯拉的擎天柱，產品方向為人形機器人。今年 8 月，智元推出了<em><u><a href="https://www.oschina.net/news/254290">遠徵 A1 人形機器人</a></u></em>，併發布了其自研的 PowerFlow 關節電機，反關節的設計和靈巧手 SkillHand。</p><p><img src="https://static.oschina.net/uploads/space/2023/0818/134556_I0Zb_2720166.jpg" referrerpolicy="no-referrer"></p><p>智元機器人在 8 月發佈會時表示，他們已經和多家頭部製造業服務企業對接，並面向 3C 電子、汽車裝備等不同場景，訓練了很多如擰螺絲的動作，公司預計 2024 年產品會推向商業化落地。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 08:41:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271228</guid>
            <link>https://www.oschina.net/news/271228</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MariaDB 拆分 SkySQL，作為獨立公司成立]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">MariaDB<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmariadb.com%2Fnewsroom%2Fpress-releases%2Fmariadb-finalizes-spinoff-of-skysql%2F" target="_blank"> 宣佈</a>已將其 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fskysql.com%2F" target="_blank">SkySQL</a> 業務拆分為一家獨立的雲數據庫公司，以負責構建和支持 SkySQL 產品。</span></p><p><span style="color:#000000">「我們相信，此次分拆將促進依賴 SkySQL 的客戶順利過渡。我們很高興 SkySQL 產品將在一家新公司的領導下繼續發展，同時讓我們能夠集中精力開發核心的 MariaDB 企業服務器產品。」</span></p><p><span style="color:#000000">未來，新公司 SkySQL Inc. 將承擔 SkySQL 數據庫即服務 (DBaaS) 的開發、銷售和支持工作。MariaDB 將持有 SkySQL 的股權，以強調兩家公司之間的長期合作關係。</span></p><p><span style="color:#000000">SkySQL DBaaS 產品是 MariaDB 數據庫的雲託管和生產級版本。SkySQL 表示，通過作為一個獨立實體推出，它將能夠加快向平台提供新功能的步伐。其主要優先事項之一是在 Microsoft Azure 上啓動該服務。目前，客戶可以通過 Amazon Web Services 和 Google Cloud 進行訪問。</span></p><p><span style="color:#000000"><img alt="" height="294" src="https://oscimg.oschina.net/oscnet/up-a1e38eab7fc4e80eb5d8322843767666f63.webp" width="300" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">MariaDB 於 2020 年推出了 SkySQL，稱它是流行的 MariaDB 數據庫的雲原生版本，是 MySQL 數據庫的替代品。由於 SkySQL 是基於 Kubernetes 構建，因此它可以與任何類型的雲基礎設施相融合。</span></p><p><span style="color:#000000">SkySQL 的雲原生特性意味着客戶可以更輕鬆地管理其數據庫部署。與 Oracle 等其他公司的數據庫產品相比，它的許可和管理也更容易。此外，SkySQL 是首批支持行、列式以及組合行和列式存儲的 DBaaS 服務之一，這是一種可以在同一個數據集上在一個位置處理事務和分析的技術。</span></p><p><span style="color:#000000">由於採用了 MariaDB 專有的 MaxScale 和 Xpand 技術，SkySQL 還聲稱比其他類型的數據庫具有更高的可用性和更大的可擴展性。</span></p><p><span style="color:#000000">作為一個獨立的實體，SkySQL 的領導團隊包括：首席執行官 Nithin Rao、聯合創始人 Jags Ramnarayan（首席技術官）和 Saravana Krishnamurthy (CPO)。曾在 MariaDB 中負責開發和運營 SkySQL 的核心技術團隊也已加入該公司。</span></p><p><span style="color:#000000">Rao <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsiliconangle.com%2F2023%2F12%2F14%2Fmariadb-spins-skysql-independent-database-service-company%2F" target="_blank">表示</a>，通過分拆 SkySQL，新公司將確保 SkySQL 繼續成為那些希望在雲中獲得最佳 MariaDB 體驗的客戶的「不二之選」。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 07:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271211/mariadb-spins-skysql-independent-company</guid>
            <link>https://www.oschina.net/news/271211/mariadb-spins-skysql-independent-company</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[FolkMQ 「多中心」集羣部署方案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#24292e; text-align:start">FolkMQ 是一個新起的內存型消息中間件。</p><h3>簡介</h3><ul><li>採用 「多路複用」 + "內存運行" + "快照持久化" + "Broker 集羣模式"（可選）+</li><li>基於<span>&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsocketd.noear.org%2F" target="_blank">Socket.D 網絡應用協議</a><span>&nbsp;</span>開發。全新設計，自主架構！</li></ul><table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&quot;system-ui&quot;,&quot;Segoe UI&quot;,Helvetica,Arial,sans-serif,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"><tbody><tr><th>角色</th><th>功能</th></tr></tbody><tbody><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">生產端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">發佈消息（Qos0、Qos1）、發佈定時消息（Qos0、Qos1）、發佈重試</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消費端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">訂閲、取消訂閲</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消費端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">消費-ACK（自動、手動）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">&nbsp;</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">服務端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">發佈-Confirm、訂閲-Confirm、取消訂閲-Confirm、派發-Retry、派發-Delayed</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">服務端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">內存運行、快照持久化（自動、停機、手動）</td></tr><tr><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">服務端</td><td style="border-color:#dfe2e5; border-style:solid; border-width:1px">集羣熱擴展</td></tr></tbody></table><h3>特點</h3><ul><li>高吞吐量、低延遲（單機版，180K TPS）</li><li>擴展性（集羣可」熱擴展「服務節點）</li><li>持久性、可靠性</li><li>高可用（只要有」一個「同類節點在即可）</li></ul><h3>多中心集羣部署演示：</h3><p><iframe frameborder="0" height="400" scrolling="no" src="https://player.bilibili.com/player.html?aid=409798174&amp;bvid=BV1vG411a7Q7&amp;cid=1367060964&amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &quot;system-ui&quot;, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"></iframe></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 04:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271182</guid>
            <link>https://www.oschina.net/news/271182</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 「泄露」 GPT-4.5，價格是 GPT-4 的 6 倍]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenAI 官網的產品價格訂閲頁面似乎意外地「泄露」了 GPT-4.5。按照頁面的信息，GPT-4.5 的價格是目前 GPT-4 的 6 倍。</p><blockquote><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-31d1ece739917eff1f166c5dbe37cdaf3cd.png" referrerpolicy="no-referrer"></p><p>來源：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2FOpenAI%2Fcomments%2F18i5n29%2Fanyone_hear_of_gpt45_drop_today%2F" target="_blank">https://www.reddit.com/r/OpenAI/comments/18i5n29/anyone_hear_of_gpt45_drop_today/</a></u></em></p></blockquote><p>根據描述，最先進的模型帶來了<strong>跨語言、音頻、視覺、視頻和 3D 的多模態功能，以及複雜的推理和跨模態理解</strong>，以及 3 個新型號：</p><ul><li>GPT-4.5</li><li>GPT-4.5-64k</li><li>GPT-4.5-audio-and-speech</li></ul></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271170/openai-leak-gpt45</guid>
            <link>https://www.oschina.net/news/271170/openai-leak-gpt45</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[夸克瀏覽器 PC 版開啓內測]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff"><span style="color:#555555">夸克瀏覽器今天正式開啓 PC 版本的內測，安裝包大小 165 MB，基於 Chromium&nbsp;112 內核版本打造，目前內測版本功能相對簡單，主打夸克小工具和夸克網盤。</span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-7d2b1e9f052bd1f16e693666b844526c384.png" width="500" referrerpolicy="no-referrer"></span></span></p><p><span style="color:#555555"><img alt="" height="313" src="https://oscimg.oschina.net/oscnet/up-c1abc7d9868a44f006af303db9fc34bc1f2.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="background-color:#ffffff"><span style="color:#555555"><img alt="" height="319" src="https://oscimg.oschina.net/oscnet/up-1a021e823d1e28e62da4d57b8883ec880ef.png" width="300" referrerpolicy="no-referrer"></span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555">安裝完成，需要使用夸克瀏覽器手機版掃碼登錄，登錄後的界面</span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555"><img alt="" height="338" src="https://oscimg.oschina.net/oscnet/up-118ef3c22895713a51398d5edfc8ff9bde0.png" width="500" referrerpolicy="no-referrer"></span></span></p><p><span style="background-color:#ffffff"><span style="color:#555555">文件工具中心</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:42:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271168</guid>
            <link>https://www.oschina.net/news/271168</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Bytebase 2.12.0 - 改進自動補全和佈局導航]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>🚀 新功能</h2><ul><li>支持 MySQL 高級自動補全。</li><li>支持從 UI 上導入分類分級配置。 <img src="https://oscimg.oschina.net/oscnet/up-0268af7aad60dafccd3d2d9f573a25e45b2.png" alt="file" referrerpolicy="no-referrer"></li></ul><h2>🔔 重大變更</h2><ul><li>作廢已有企業版試用證書。之後可以通過提交申請獲取新的試用證書。</li></ul><h2>🎄 改進</h2><ul><li><p>改進整體佈局和導航。</p></li><li><p>支持在 SQL 編輯器裏顯示以及查詢 PostgreSQL 數據庫分區表。</p></li><li><p>優化對數據庫/實例/慢查詢的過濾體驗。 <img src="https://oscimg.oschina.net/oscnet/up-0e38c7ab958fb392f60f9f749b38a5a5e48.png" alt="file" referrerpolicy="no-referrer"></p></li><li><p>Schema 編輯器性能優化。</p></li><li><p>支持 TiDB 7.5。</p></li><li><p>提升 MySQL SQL 審核，的兼容性。</p></li></ul><h2>🐞 Bug 修復</h2><ul><li>修復了當結果太大無法查詢 MongoDB 的問題。</li><li>修復了在 SQL Editor 中無法查詢 PostgreSQL 視圖的問題。</li></ul><h2>🎠 社區</h2><ul><li>感謝 @jinrenjie 提交 fix(smtp): fix host name error in smtp authentication #9674</li></ul><h2>📕 安裝及升級</h2><p>參考<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytebase%2Fbytebase%23installation" target="_blank">升級指南</a>。如果從之前版本升級，獲取新版本後，重新啓動升級即可。</p><hr><p>💡 更多資訊，請關注 Bytebase 公號：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/10321743</guid>
            <link>https://my.oschina.net/u/6148470/blog/10321743</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[互聯網大廠月薪分佈：字節跳動超 5% 員工月薪高於 5 萬]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>某統計機構公開了一份國內互聯網大廠的月薪分佈。從統計來看，貝殼、阿里、滴滴、拼多多、快手和騰訊有超過 60% 的員工，月薪都在 3-5 萬區間。而拼多多和字節跳動，還有 5% 以上的員工月薪超過了 5 萬。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6dee49384f61d67489bea92afa25362f142.png" referrerpolicy="no-referrer"></p><p>大家熟悉的華為，有 51% 的員工月薪在 3-5 萬區間（3.4% 員工月薪超過 5 萬），而小米這個數字為 47.5%。</p><p>事實上，不少互聯網公司內部都有等級評定，而像華為、阿里、騰訊內部，級別高的員工甚至年薪+分紅都輕鬆過百萬。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271163</guid>
            <link>https://www.oschina.net/news/271163</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[贈書 + 5 折購書，作者線上親解《MLOps 工程實踐》]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><strong>如何實現 </strong><strong>AI</strong><strong> 規模化落地？</strong></p><p><strong>如何跨越 </strong><strong>AI</strong><strong> 工程化鴻溝？</strong></p><p><strong>如何解決 </strong><strong>AI</strong><strong> 落地的效果與效率難題？</strong></p><p>這三大問題，都可以在《MLOps 工程實踐：工具、技術與企業級應用》這本書中找到答案。</p><p>《MLOps 工程實踐》由第四範式創始人領銜撰寫，騰訊、小米、百度等分享經驗，涵蓋生產級機器學習項目相關技術理論、工具和大廠案例，構建可靠、高效、可複用、可擴展機器學習模型。</p><p>12 月 18 日晚 19:00，《MLOps 工程實踐》的三名作者陳慶、顏丙政、趙喜生將直播分享本書內容，並講述寫書背後的故事，一起探討 MLOps 的過去、現在和未來。</p><p><img height="600" src="https://oscimg.oschina.net/oscnet/up-60cbe740936b6e154b981698fc29b5ca488.png" width="600" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p>此外，直播期間，我們還將對外<strong><span style="color:#2980b9">贈送 10 本《MLOps 工程實踐》</span></strong>，在直播評論區互動或參與直播抽獎即有機會獲得！</p><p>同時，在 12 月 18 日當天，定價 109 元的<span style="color:#2980b9"><strong>《MLOps 工程實踐》將打五折！</strong></span>掃碼入羣，即可獲取購書鏈接！</p><p><img height="401" src="https://oscimg.oschina.net/oscnet/up-c1ed9b7c34eb99c03694baa402a428eb7bd.png" width="414" referrerpolicy="no-referrer"></p><p><strong>直播主題：</strong>三大作者親解 MLOps ——《MLOps 工程實踐》讀書分享會</p><p><strong>直播時間：</strong>12 月 18 日（週一） 19:00-20:30</p><p><strong>直播平台：</strong>「OSC 開源社區」 視頻號</p><p><strong>主辦方：</strong>開源中國、機械工業出版社</p><div><div><p><strong>直播嘉賓：</strong></p><div><p>&nbsp;&nbsp; <strong>主持人：</strong></p><p>&nbsp;&nbsp;孫越，星策社區產品經理</p><p>&nbsp;&nbsp; <strong>分享嘉賓：</strong></p><p>&nbsp;&nbsp;陳慶，第四範式大語言模型式説解決方案產品負責人</p><p>&nbsp;&nbsp;顏丙政，第四範式架構師</p><p>&nbsp;&nbsp;趙喜生，騰訊機器學習平台架構師</p><p><img height="1422" src="https://oscimg.oschina.net/oscnet/up-96816a36a647d5cac6e6102f7c1ece4591d.png" width="800" referrerpolicy="no-referrer"></p><p><strong>除了贈書之外，我們還有更多直播福利：</strong></p></div></div></div><ul><li><p>互動抽獎：在直播評論區提問，被直播嘉賓回覆的用戶可獲 OSC T 恤 1 件，名額不限。</p></li><li><p>福袋抽獎：直播中將有多輪抽獎，參與就有機會獲得 OSC T 恤、筆記本、馬克杯 、前沿技術書籍等。</p></li></ul><p><img height="281" src="https://oscimg.oschina.net/oscnet/up-5107f5e07c513d574174e5301fed5a6be4c.png" width="500" referrerpolicy="no-referrer"></p><p>小夥伴們，我們直播間見～</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/10321745</guid>
            <link>https://my.oschina.net/u/3859945/blog/10321745</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[JavaScript 引擎 V8 年度回顧：新編譯器、修改基礎架構、改進 GC……]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>V8 官方博客<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv8.dev%2Fblog%2Fholiday-season-2023" target="_blank">回顧了</a></u> 2023 年的重要變化：通過創新的性能優化，V8 不斷突破 Web 領域的可能性界限。比如引入新的中間層編譯器，對頂層編譯器基礎架構、運行時和垃圾回收進行多項改進，從而全面提升速度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-bf9e793830df03255fd7b3a067d1fec862c.png" referrerpolicy="no-referrer"></p><p>除了性能改進之外，V8 團隊還為 JavaScript 和 WebAssembly 添加了許多新功能。比如通過 WasmGC 將支持垃圾回收的編程語言用於 Web 開發（<u><em><a href="https://www.oschina.net/news/264807/wasmgc-chrome" target="_blank">Chrome 支持運行 Kotlin、Java 等 GC 編程語言</a></em></u>）。</p><p>此外還改進了沙箱基礎設施，併為 V8 引入了控制流完整性 (CFI)，為用戶提供了更安全的環境。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3394d169661bc1f898bec9fe7ebe5286e7a.png" referrerpolicy="no-referrer"></p><p><strong>V8 2023 重磅新特性回顧</strong></p><ol><li><p><strong>新的中間層編譯器 Maglev</strong>：Maglev 是 V8 引擎的新中間層編譯器，它的推出使得代碼的優化速度大大提高。相比於現有的編譯器，Maglev 的編譯速度快了 10 到 100 倍，並且在 JetStream 和 Speedometer 等性能測試中取得了 8.2% 和 6% 的性能提升。</p></li><li><p><strong>新的頂層優化編譯器架構 Turboshaft</strong>：V8 引擎還引入了 Turboshaft，這是一個用於頂層優化編譯器的新內部架構。使用 Turboshaft 後，編譯速度提高了一倍，這有助於節約能源併為未來的性能提升奠定基礎。</p></li><li><p><strong>更快的 HTML 解析器</strong>：V8 團隊對 HTML 解析器進行了優化，這導致 Speedometer 測試分數提高了 3.4%。這些變化也被 WebKit 項目採納，從而對 Chrome 瀏覽器的性能產生了積極影響。</p></li><li><p><strong>更快的 DOM 分配</strong>：V8 團隊還對 DOM 對象的內存分配策略進行了優化，這使得 DOM 對象的分配速度提高了 3 倍，並在 DOM 密集型測試中取得了顯著的改進。</p></li><li><p><strong>新的 JavaScript 特性</strong>：V8 引擎還推出了一系列新的 JavaScript 特性，包括可調整大小的 ArrayBuffers、ArrayBuffer 傳輸、String isWellFormed 和 toWellFormed 等。</p></li><li><p><strong>WebAssembly 更新</strong>：V8 引擎為 WebAssembly 引入了多個新特性和性能優化，包括對多內存的支持、尾調用、放鬆的 SIMD 等。</p></li><li><p><strong>WebAssembly 垃圾回收</strong>：V8 引擎最終實現了 WebAssembly 垃圾回收（WasmGC），這使得可以將使用 Java、Kotlin、Dart 等垃圾回收語言編寫的應用程序編譯為 WebAssembly，從而提高了其運行速度。</p></li><li><p><strong>安全增強</strong>：V8 引擎還在安全方面進行了改進，包括改進了沙箱基礎設施、引入了控制流完整性（CFI）等。</p></li></ol><p>原文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv8.dev%2Fblog%2Fholiday-season-2023" target="_blank">https://v8.dev/blog</a></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 03:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271159/v8-2023-recap</guid>
            <link>https://www.oschina.net/news/271159/v8-2023-recap</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Firefox 為 Android 用戶提供 450 多個新擴展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Mozilla 正式<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Fen%2Fmozilla%2Fnew-extensions-youll-love-now-available-on-firefox-for-android%2F" target="_blank">宣佈</a>在 Addons.mozilla.org (AMO) Android 頁面上，面向用戶提供 450 多個新的 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fzh-CN%2Fandroid%2F%3F_gl%3D1*72qen9*_ga*MTM5NzQ4MDI5My4xNzAwNjE4OTgx*_ga_X4N05QV93S*MTcwMjYwNzA0MC4xLjAuMTcwMjYwNzA0MC4wLjAuMA.." target="_blank">Firefox Android 版擴展</a>。</span></p><p><span style="color:#000000">「這一里程碑標誌着一個新的開放式移動擴展生態系統的啓動，開發者現在可以自由創建和發佈擴展，用戶也可以輕鬆訪問並在 Firefox for Android 上安裝這些擴展。」</span></p><p><img height="303" src="https://oscimg.oschina.net/oscnet/up-7126e1593955faa3278ba5deb2d5c413912.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Firefox 工程副總裁 Vicky Chin 稱，擴展最初的意義就是人們用來定製自己的互聯網體驗的一種方式。Firefox&nbsp;是當下唯一一個支持開放擴展生態系統的主要 Android 瀏覽器。他們計劃在未來幾個月啓用更多擴展，供用戶選擇並定製自己的移動互聯網體驗。</span></p><p><span style="color:#000000">現在的人在<span style="background-color:#ffffff">很多事情上都依賴於移動設備 — 快速信息搜索、閲讀文章、聽音樂、尋找食譜等。</span>目前一些可用的相關擴展程序有：</span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fen-US%2Fandroid%2Faddon%2Fmidnight-lizard-quantum%2F%3Futm_source%3Daddons.mozilla.org%26utm%2520_medium%3Dreferral%26utm_content%3Dsearch" target="_blank"><strong>Midnight Lizard</strong></a><strong style="color:#000000"><span>&nbsp;</span>– 閲讀更輕鬆&nbsp;</strong></li></ul><p><span style="color:#000000">Midnight Lizard 擴展可以調節手機界面顏色，增加或減少亮度和對比度；還能添加藍光濾鏡、屏幕着色器，以及夜間模式。從而減輕眼睛疲勞，保持良好狀態。</span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fen-US%2Fandroid%2Faddon%2Fdark-background-light-text%2F%3Futm_source%3Daddons.mozilla.org%26utm_medium%3Dreferral%26utm_content%3Dsearch" target="_blank"><strong>深色背景和淺色文本</strong></a><strong>&nbsp;– 保持簡潔</strong></li></ul><p><span style="color:#000000">用戶可以自由定製，讓所有網頁都以深色背景和淺色文本的方式呈現，或者也可只選擇部分網頁。</span></p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faddons.mozilla.org%2Fen-US%2Fandroid%2Faddon%2Fworldwide-radio%2F" target="_blank"><strong>全球電台</strong></a><strong>&nbsp;– 盡情享受</strong></li></ul><p><span style="color:#000000">可直接從 Android 版 Firefox 瀏覽器訪問來自世界各地的 50,000 多個廣播電台。</span></p><p><span style="background-color:#ffffff; color:#000000">公告稱，隨着越來越多的開發者創建針對移動設備優化的內容，預計未來幾個月還將出現一波新的 Firefox for Android 擴展浪潮。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 02:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271154/new-extensions-available-firefox-for-android</guid>
            <link>https://www.oschina.net/news/271154/new-extensions-available-firefox-for-android</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[AI 代碼助手盛行，編程語言排行榜都沒法做了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>RedMonk 編程語言排行榜通過追蹤編程語言在 GitHub 和 Stack Overflow 上的代碼使用情況與討論數量，統計分析後進行排序，其旨在深入瞭解潛在的語言採用趨勢。因此在眾多編程語言榜單中，RedMonk 編程語言排行榜在專業度和認可度方面稱得上是業內天花板了。</p><blockquote><p>RedMonk 榜單的數據收集方式包含兩部分：<br> -使用 GitHub Archive 作為數據源對 GitHub 數據進行分析；<br> -Stack Overflow 部分則直接使用其提供的實用工具&nbsp;data explorer，具體排序算法見<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Fsogrady%2F2019%2F07%2F18%2Flanguage-rankings-6-19%2F">官方介紹</a>。</p></blockquote><p>該榜單一年發佈兩次，上次更新是 5 月（<u><a href="https://www.oschina.net/news/241358/redmonk-language-rankings-1-23" target="news">RedMonk 排行：Objective-C 日漸衰落</a></u>）。按照慣例，第 2 次更新是 11 月，但直到現在也沒有任何動靜。</p><p>昨日，官方<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredmonk.com%2Frstephens%2F2023%2F12%2F14%2Flanguage-rankings-update%2F" target="_blank">解釋</a></u>了為何遲遲不發佈新的編程語言榜單——原因是他們按照以往的方式獲取數據後發現，收集到的數據量跟往年比較相差巨大。</p><p>自 ChatGPT 發佈以來，各種 AI 代碼助手大行其道，因此問答社區的整體提問數量大幅下降。而在 GitHub 中，根據 GitHub Archive 的數據，與 2022 年 2 月的 PR 相比，2023 年 1 月的 PR 量下降了約 25%，完全出乎意料。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fd179e77353ed33816985ce76dfca218f56.png" referrerpolicy="no-referrer"></p><p>RedMonk 稱雖然早已知曉 Stack Overflow 的流量已出現顯著下滑（<em><u><a href="https://www.oschina.net/news/251072/the-fall-of-stack-overflow" target="news">Stack Overflow 訪問量大幅下降</a></u></em>），但沒有預料到 GitHub 上的數據會出現如此重大的「異常」。</p><p>因此 RedMonk 指出，基於人工智能的代碼助手的出現和興起已經影響了 RedMonk 語言排名的數據。隨着問題和知識共享從公共論壇轉移到私人工具，他們從公開數據中確定有意義趨勢的能力將無限期地改變。</p><p>RedMonk 稱會繼續跟蹤這些趨勢，<strong>並確定樣本量的變化將如何影響他們進行排名</strong>，同時預告&nbsp;2024 年 1 月，發佈新榜單。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 02:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271153/redmonk-language-rankings-update</guid>
            <link>https://www.oschina.net/news/271153/redmonk-language-rankings-update</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Google Groups 停止支持 Usenet]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>谷歌宣佈從&nbsp;2024 年 2 月 22 日開始，用戶無法再使用 Google Groups（網址為 groups.google.com）向 Usenet 羣組發佈內容、訂閲 Usenet 羣組，或查看新的 Usenet 內容。但可以繼續查看和搜索 2024 年 2 月 22 日之前在 Google Groups 上發佈的歷史 Usenet 內容。</p><p><img src="https://oscimg.oschina.net/oscnet/up-3d4af7d4780a6e633853c6fc3460057d75c.png" referrerpolicy="no-referrer"></p><p>來源：<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.google.com%2Fgroups%2Fanswer%2F11036538%3Fhl%3Den" target="_blank">https://support.google.com/groups/answer/11036538?hl=en</a></em></u></p><p>谷歌表示，在過去幾年裏，基於文本的 Usenet 羣組中的合規活躍已顯著下降，因為用戶已轉向更現代的技術和格式，例如社交媒體和基於 Web 的論壇。目前通過 Usenet 傳播的大部分內容都是<strong>二進制（非文本）文件共享</strong>（Google Groups 不支持該項功能），以及垃圾郵件。</p><p>Usenet（/ˈjuːznɛt/）是一種在計算機上可用的全球分佈式討論系統。它是從通用的 Unix 到 Unix 複製（UUCP） 撥號網絡架構中發展出來的。</p><p>杜克大學研究生湯姆·特拉斯科特與吉姆·埃利斯在 1979 年設計了 Usenet，並於 1980 年發佈。用戶閲讀和發佈消息到一個或多個主題類別，稱為「新聞組」。Usenet 在許多方面類似於公告板系統（BBS），並且是現在廣泛使用的 Internet 論壇的前身。</p><p>Linux 內核的命運齒輪啓動正是由 Usenet 見證——1991 年 8 月 26 日，芬蘭大學生 Linus Benedict Torvalds 向 comp.os.minix 新聞組的成員透露了出於 「業餘愛好」 而正在研究操作系統，當時 Linus 在郵件中表示自己搗鼓的操作系統只是一個業餘性質項目，不會像 GNU 那樣龐大和專業。</p><blockquote><p>我正在研究一款（自由的）操作系統（就是個興趣愛好，我不會搞得像 GNU 那麼大那麼專業），打算讓它工作在 386 (486) AT 平台上。它從四月就開始醞釀了，馬上就快好了。我希望那些喜歡或不喜歡 minix 的人能夠反饋意見，因為我的系統和它有點類似（同樣的文件系統的物理佈局 —— 由於實際原因，還有些其他的東西）。</p><p>我現在已經移植了&nbsp;bash (1.08) 和&nbsp;gcc (1.40)， 而且看起來奏效了。這意味着我會在幾個月內得到一些實用的東西。我想了解大多數人想要的特性是什麼，歡迎各位積極提出建議，不過我不保證能實現 :-)</p><p><img alt="" src="https://static.oschina.net/uploads/space/2019/0826/211817_vyJK_2720166.jpg" referrerpolicy="no-referrer"></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Fri, 15 Dec 2023 02:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/271146</guid>
            <link>https://www.oschina.net/news/271146</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
