<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 10 Oct 2023 09:43:17 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[Captum —— PyTorch 模型解釋和理解庫]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Captum 是為 PyTorch 設計的模型解釋性和理解庫。在拉丁語中，「Captum」意味着理解。這個庫為 PyTorch 模型提供了通用的實現方法，包括集成漸變、顯著性圖、smoothgrad、vargrad 等。它可以快速集成使用像 torchvision、torchtext 等特定領域的庫構建的模型。目前，Captum 仍處於測試階段，並在積極開發中。</p><p>隨着模型複雜性的增加以及透明度的缺失，模型解釋性方法變得越來越重要。模型理解已經成為研究的活躍領域，並在各個使用機器學習的行業中獲得了實際應用的關注。Captum 提供了最先進的算法，包括集成漸變，以使研究者和開發者更容易理解哪些特徵對模型的輸出起了作用。</p><p>對於模型開發者來説，Captum 可以幫助他們通過識別不同的特徵來改進和排查模型，從而設計出更好的模型，並排查意外的模型輸出。</p><p>Captum 還幫助機器學習研究者更輕鬆地實現可以與 PyTorch 模型互動的解釋性算法。此外，研究者還可以使用 Captum 快速地將他們的工作與庫中的其他現有算法進行對比。</p><p><strong>屬性算法概述</strong></p><p><strong>目標受眾</strong></p><p>Captum 的主要受眾是希望改進他們的模型並瞭解哪些特徵重要的模型開發者，以及專注於識別能夠更好解釋許多模型類型的算法的解釋性研究者。</p><p>應用工程師也可以使用 Captum。他們在生產中使用經過訓練的模型時，Captum 能提供更容易的排錯方式，並有可能為最終用戶提供更好的解釋，例如為什麼他們會看到某個特定的內容，如電影推薦。</p><p>總體而言，Captum 為 PyTorch 提供了一個強大的工具，不僅對模型進行深入的解釋和理解，還可以為模型開發者和研究人員提供有關模型工作原理的洞察，從而促進更好的模型設計和應用。</p></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 08:54:31 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/captum</guid>
            <link>https://www.oschina.net/p/captum</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | Redis 流量鏡像的實現]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h2_1"></span><h2>背景</h2><p>對 Redis 場景降本增效，涉及到將部分 Redis 實例遷移到類似社區 pika 這種支持 Redis 協議的基於 SSD 磁盤存儲的項目（阿里雲 Tair），降低存儲成本。遷移過程需要進行性能驗證，除了基本的選型壓測之外，還必須對每個業務場景做全指令的性能覆蓋，才能確保業務遷移的性能以及指令兼容穩定性。常規的做法是需要業務開發配合在工程裏進行流量雙發，或者小範圍流量灰度。</p><p>以上這個問題，不管哪種方式都需要投入更多的人力和時間，對降本增效本身這件事情來説，大大降低了 roi 。如果能夠做到直接將原 Redis 的所有讀流量重放到目標 Redis SSD 的實例，則遷移整件事件 SRE 可以完成 99% ，而且將大大縮短遷移實例的時間，所以 Redis 流量鏡像這個需求就應運而生了。</p><p>tips：我們的數據遷移方案採用阿里雲的 DTS ，DTS 是基於 Redis 主從複製的原理實現的，所以寫流量性能在數據同步過程就可以直接驗證了</p><span id="OSC_h2_2"></span><h2>調研</h2><p>Google 上、Github 上逛了一圈，沒有十分契合的東西，所以最後決定自研。查到的一些相關信息如下：</p><ul><li>阿里雲的 SLS Redis 審計日誌</li></ul><p>阿里雲的 Redis 實例支持將 Redis 的執行日誌丟到 SLS（一個日誌記錄查詢的產品） 記錄，但是隻有寫流量的記錄，達不到 Redis 讀流量回放的需求。</p><ul><li>pika redis-copy 工具：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenAtomFoundation%2Fpika%2Fissues%2F2044" target="_blank">https://github.com/OpenAtomFoundation/pika/issues/2044</a></li></ul><p>這個工具已經被 pika 項目丟棄了。目前只有文檔，倉庫裏已經沒有相關的代碼了。不過本文實現也是基於和 pika 的實現原理一樣的</p><ul><li>istio 實現 Redis 流量鏡像：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcloudnativeto%2Fcloudnativeto.github.io%2Fissues%2F76" target="_blank">https://github.com/cloudnativeto/cloudnativeto.github.io/issues/76</a></li></ul><p>基於 istio 做 Redis 的鏡像流量，必須接入 istio 才行，侷限性太大了，而且引入一個新的 istio 組件需要做很多的穩定性測試，所以這個路線就直接否了</p><span id="OSC_h2_3"></span><h2>實現</h2><p>直接接入正題，採用 Redis 的 monitor 指令來實現這個需求。</p><pre><code class="language-java">/**
 * @author kl (http://kailing.pub)
 * @since 2023/9/27
 */
public class RedisMonitorTest {

    static final JedisPool targetRedisPool = new JedisPool("127.0.0.1", 6398);
    static final JedisPool sourceRedisPool = new JedisPool("127.0.0.1", 6379);
    static final Set&lt;String&gt; redisReadCommands = new HashSet&lt;&gt;(Arrays.asList(
            "get", "strlen", "exists", "getbit", "getrange", "substr", "mget", "llen", "lindex",
            "lrange", "sismember", "scard", "srandmember", "sinter", "sunion", "sdiff", "smembers",
            "sscan", "zrange", "zrangebyscore", "zrevrangebyscore", "zrangebylex", "zrevrangebylex",
            "zcount", "zlexcount", "zrevrange", "zcard", "zscore", "zrank", "zrevrank", "zscan", "hget",
            "hmget", "hlen", "hstrlen", "hkeys", "hvals", "hgetall", "hexists", "hscan", "randomkey",
            "keys", "scan", "dbsize", "type", "sync", "psync", "ttl", "touch", "pttl", "dump", "object",
            "memory", "bitcount", "bitpos", "georadius_ro", "georadiusbymember_ro", "geohash",
            "geopos", "geodist", "pfcount", "xrange", "xrevrange", "xlen", "xread", "xpending",
            "xinfo", "lolwut"
    ));
    
    public static void main(String[] args) {
            try (Jedis jedis = sourceRedisPool.getResource()) {
                jedis.monitor(new JedisMonitor() {
                    @Override
                    public void onCommand(String command) {
                        sendCommand(command);
                    }
                });
            }
    }
    
    public static void sendCommand(String commandStr) {
        String[] parts = commandStr.split("\"");
        if (parts.length &lt; 2) {
            return;
        }
        String cmd = parts[1];
        List&lt;String&gt; args = new ArrayList&lt;&gt;();
        for (int i = 3; i &lt; parts.length; i += 2) {
            args.add(parts[i]);
        }
        if (redisReadCommands.contains(cmd.toLowerCase())) {
            ProtocolCommand command = () -&gt; cmd.getBytes(StandardCharsets.UTF_8);

            try (Jedis jedis = targetRedisPool.getResource()) {
                try {
                    long startTime = System.currentTimeMillis();
                    jedis.sendCommand(command, args.toArray(new String[0]));
                    System.out.println(cmd + ":" + (System.currentTimeMillis() - startTime));
                } catch (Exception e) {
                    System.err.println(cmd + e.getMessage());
                }
            }
        }
    }
}</code></pre><p>以上是一段可以直接執行的偽代碼，將&nbsp;sourceRedis 的所有讀流量轉發到&nbsp;targetRedis 執行</p><span id="OSC_h2_4"></span><h2>實現解析</h2><p>上面採用的 Java 的 Redis 客戶端 jedis 來開發，首先調用了 monitor 這個指令，這個指令是一個阻塞指令，會一直訂閲 Redis 服務端的指令執行記錄，記錄的格式如下：</p><pre><code>1695869359.747056 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869359805247076" "LIMIT" "0" "1"
1695869359.748040 [0 127.0.0.1:64257] "EXISTS" "asynq:{sys}:paused"
1695869359.748259 [0 127.0.0.1:64257] "EXISTS" "asynq:{sync}:paused"
1695869359.748578 [0 127.0.0.1:64257] "EXISTS" "asynq:{default}:paused"
1695869359.748916 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869359869190783" "LIMIT" "0" "1"
1695869359.749154 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869359877625076" "LIMIT" "0" "1"
1695869359.749348 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869359878760313" "LIMIT" "0" "1"
1695869359.749530 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869359882064571" "LIMIT" "0" "1"
1695869359.779048 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869360024586886" "LIMIT" "0" "1"
1695869359.785898 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869360031603858" "LIMIT" "0" "1"
1695869359.786092 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869360031656719" "LIMIT" "0" "1"
1695869359.786923 [0 127.0.0.1:64257] "ZRANGEBYSCORE" "delayed_tasks" "0" "1695869360031666910" "LIMIT" "0" "1"</code></pre><p>所以我們只要解析出指令，然後發送到目標實例就好了</p><p>這裏還涉及到一個問題，怎麼過濾出只有讀指令的記錄？</p><p>我嘗試過問 chatGPT ，但是他一點都不靠譜，不是少了讀的指令，就是用其他寫指令湊數。所以不可信。好在 Redis 服務端對每個指令都進行了打標，區分了讀指令還是寫指令。</p><p><img height="2124" src="https://oscimg.oschina.net/oscnet/up-44f7a2eac1677679c388b29b1cbb6516f98.png" width="2932" referrerpolicy="no-referrer"></p><p>所以只需要把所有的只讀指令打印到控制枱複製出來就解決這個問題了。</p><span id="OSC_h2_5"></span><h2>注意事項</h2><p>Redis monitor 指令是一個對 Redis 性能有損的指令，官方測試會對單實例 Redis 降低 50% 左右的性能，我實際測試在 Redis 實際負載不高的情況下,這個影響可以忽略不計（特別高 QPS 的實例謹慎使用）。因為 Redis 單機 QPS 能支撐 10W 。比如線上實時 QPS 1W ，使用 monitor 的時候，QPS 和 RT 幾乎沒有變化。</p><p>另外需要注意，monitor 長時間運行會增加 Redis 的內存消耗，所以如果做性能驗證，最好控制下時間，不要一直跑。</p><p><img height="1532" src="https://oscimg.oschina.net/oscnet/up-ec5ada01401a210a0401bba6bb508c8d109.png" width="1580" referrerpolicy="no-referrer"></p><ul><li>monitor 文檔：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fredis.io%2Fcommands%2Fmonitor%2F" target="_blank">https://redis.io/commands/monitor/</a></li></ul><span id="OSC_h2_6"></span><h2>結語</h2><p style="color:#000000; margin-left:0; margin-right:0; text-align:start">在本篇博客中，我們探討了 Redis 流量鏡像的實現方法和其在降本增效方面的重要性。我們瞭解到，傳統的驗證方式在遷移 Redis 實例時需要大量的人力和時間投入，降低了降本增效的 ROI。為瞭解決這一問題，引入了 Redis 流量鏡像的需求。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:start">通過將原 Redis 的所有讀流量直接重放到目標 Redis SSD 實例，我們可以高效地完成遷移實例的過程，減少了 SRE 的工作量，並顯著縮短了遷移時間。這種方法不僅提高了遷移過程的效率，還降低了成本和風險，使得降本增效的目標更加可行和實現。通過採用這種方法，我們可以更高效地遷移 Redis 實例，並在降低成本、提高效率的同時保持業務的性能和穩定性。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:start">謝謝您的閲讀！如果您有任何問題或想法，請隨時參與評論留言。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 08:51:31 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/klblog/blog/10115744</guid>
            <link>https://my.oschina.net/klblog/blog/10115744</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[內核維護者回應縮短 LTS 內核支持期限，原因就是沒人用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Linux 基金會上個月宣佈將 LTS 內核的支持時間<a href="https://www.oschina.net/news/258970/linux-gives-up-on-6-year-lts" target="_blank"><strong>從六年縮短到兩年</strong></a>。當時給出的原因是缺乏使用和缺乏支持。</p><blockquote><p>維持這麼久確實沒有意義，因為人們已經不再使用它們了。</p><p>還有一個很大的問題是，Linux 代碼維護人員的倦怠。他們在完成工作時面臨着許多障礙。一方面，維護人員需要在日常工作之餘維護代碼，但維護工作通常沒有報酬。最重要的是，由於人手不足等問題，維護人員的工作量也越來越大。</p></blockquote><p>穩定版內核維護者 Greg Kroah-Hartman <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D37749846" target="_blank">近日的迴應</a>再度印證上述原因——<strong>沒人用 LTS 內核</strong>。</p><p><img src="https://static.oschina.net/uploads/space/2023/1010/161155_p7kt_2720166.png" referrerpolicy="no-referrer"></p><p>對於 Linux 基金會減少對內核開發的批評，Greg 表示基金會對內核社區的投入和支持一直在增加。僅僅因為 Linux 基金會成員公司的需要而不斷引入新項目新用戶，並不意味着它減少對內核社區的投入。這不是零和遊戲，不是 Linux 基金會的運作方式。</p><p><img src="https://static.oschina.net/uploads/space/2023/1010/162752_spIB_2720166.png" referrerpolicy="no-referrer"></p><p>他強調 Linux 基金會對內核的支持一直在增加，根本不存在放棄的情況。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 08:29:31 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261164/greg-says-lf-strongly-supports-kernel-developers</guid>
            <link>https://www.oschina.net/news/261164/greg-says-lf-strongly-supports-kernel-developers</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Reddit Programming 板塊的未來]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">Reddit 管理員 ketralnis 發佈並置頂了一篇名為「<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F173viwj%2Fmeta_the_future_of_rprogramming%2F" target="_blank">The future of r/programming</a>」的帖子，就 r/programming 板塊的規則制訂徵集用戶意見。</span></p><p><span style="color:#000000">根據介紹，目前&nbsp;r/programming 板塊中允許發佈的內容類型包括：實際的編程內容、編程新聞、程序員職業內容、程序員感興趣但與編程無關的文章/新聞、以及一些帶代碼的演示。禁止的內容類型包括：政治和八卦討論、沒有代碼的演示、一些低質量無營養的提問和內容、發佈調查或招聘啓事以及 Meta posts 等</span></p><p><span style="color:#000000">此外，像一些寬泛的行業相關新聞、低質量的複製粘貼類內容、同一話題的重複討論帖、標題過於社論化或陰謀論的內容，一般情況下都會進行刪除。但如這該貼已經具有了一定的熱度，管理員則會視情況進行保留。</span></p><p><img height="395" src="https://oscimg.oschina.net/oscnet/up-16b207c45a0b6d76821ddb5ef82e35c5545.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">ketralnis 表示，目前 r/programming 板塊的相關規則非常模糊，且實際的版主管理方式與這些規則的聯繫也很鬆散。</span></p><p><span style="color:#000000">譬如，就算是一些被禁止發佈的帖子類型，如果評論線程中已經出現了健康的討論內容，那麼這些帖子大多數也都會被保留下來。且相關的評論審核也非常寬鬆，導致有很多機器人刷評以及一些引戰的激烈言論出現。「然而，GPT 評論機器人數量正在明顯上升，以我們現有的活躍版主人數而言，很快就會難以承受。」</span></p><p><span style="color:#000000">因此，ketralnis 在公告中也透露正在招募更多的 mods。「如果我們想讓它變得更好，就需要更多的人力。」</span></p><p><span style="color:#000000">「我們知道世界上存在對不受監管的空間的需求，但&nbsp;r/programming&nbsp;並不是這樣的空間......就我個人而言，我的夢想是讓&nbsp;r/programming&nbsp;成為擁有最高質量編程內容的地方，在這裏我每天都能讀到有趣的內容、學到新的知識。」</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 08:19:31 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261161/reddit-future-of-rprogramming</guid>
            <link>https://www.oschina.net/news/261161/reddit-future-of-rprogramming</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[九章雲極 DataCanvas 公司完成 D1 輪融資！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:center"><img height="383" src="https://oscimg.oschina.net/oscnet/up-bbbb9a1d74fefff63912dffe366a6a8cdd1.jpg" width="900" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>近日，九章雲極 DataCanvas 公司完成總融資額 3 億元 D1 輪融資。</strong>中國電子集團旗下中電智慧基金、華民投、中國太平旗下太平創新、浙江東方旗下東方嘉富等央國企旗下投資機構，以及卓源資本等專注人工智能賽道的知名財務投資機構參與本輪融資。</p><p style="margin-left:0; margin-right:0">九章雲極 DataCanvas 公司作為國家專精特新小巨人企業，其「人工智能」技術創新能力和「基礎軟件」產品商業化能力備受市場認可。2020 年被 Gartner 列入全球 AutoML 關鍵供應商庫，並連續四年入選 IDC 中國機器學習開發平台廠商全國 Top3。在全球人工智能開源領域，自主研發的多項全球首個開源項目，填補 AI 領域技術空白，引領人工智能行業跨時代發展。作為中國信通院的戰略合作單位、標準核心參編單位，共同編訂發佈全球首個 AI 模型開發管理標準、全國首個商用人工智能開發平台等多項人工智能基礎軟件領域、大模型領域的標準。作為大模型生態共同體中的通用大模型代表企業，模型夥伴成員單位，九章雲極 DataCanvas 公司與相關政府部門共建經濟高效的智算中心以及大模型產業集聚區，並率先落地規模化、可複製的大模型應用——企業知識管家，充分破除企業知識管理過程中的痛點難點，全面釋放企業業務價值。</p><p style="margin-left:0; margin-right:0">投資方表示，九章雲極 DataCanvas 公司包含大模型在內的前沿人工智能技術成果、長效優勢顯著的 AI 基礎軟件商業化策略，充分展現了我國科技創新企業的實力和潛力。基礎軟件是人工智能的底座，人工智能的基礎軟件的發展決定了人工智能發展的深度、高度、廣度，擁有商業化的廣闊市場。在大算力時代，充分發揮算法+算力的優勢，作為賽道領頭企業實現規模化行業應用能力，看好公司未來發展。</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>AI 基礎軟件</span>正為企業創新和社會進步提供核心驅動力</strong></p><p style="margin-left:0; margin-right:0"><span>近年來，AI 基礎軟件成為政府、技術服務廠商和市場客戶的重點關注和佈局方向，各部門政府相繼發佈措施條例來鼓勵、支持、培養基礎軟件產品服務的開發以及對本地現有產業的支持賦能，雲服務廠商、技術創新企業、傳統企業都正在利用自身優勢打造 AI 基礎軟件服務內核和外延，為垂直業務場景創新落地和跨行業智能決策提供源源不斷的活力。</span>IDC 數據顯示，截止到 2022 年底，中國人工智能軟件市場規模超過 307 億元人民幣。根據中國信息通信研究院測算，2022 年我國算力核心產業規模達到 1.8 萬億元，其中政府、金融、電信領域保持高速增長，連同其他專業 AI 服務領域的增長共同促進了中國人工智能基礎軟件的發展和應用落地。</p><p style="margin-left:0; margin-right:0">多年來，憑藉行業領先的人工智能基礎軟件，九章雲極 DataCanvas 為各行各業的頭部企業提供自主 AI 能力。在今年 6 月的產品發佈會上，九章雲極 DataCanvas 公司宣佈產品體系升級，重磅發佈業界前沿技術水準的 DataCanvas Alaya 九章元識大模型、DingoDB 多模向量數據庫等多款產品，共同構成<span>&nbsp;</span><strong>「AIFS 人工智能基礎軟件」和「DataPilot 數據領航員」</strong>核心產品體系。至此，九章雲極 DataCanvas 公司成功實現構建企業「大+小」模型能力的產品佈局。</p><p style="margin-left:0; margin-right:0">DataCanvas Alaya 九章元識大模型（以下簡稱「九章元識」）不僅包含配置和參數的多樣選擇，還以「白盒」形態提供給用戶，這使得用戶獲用大模型技術能力的同時，還獲得了最大化的自主能力。九章元識這一開放性無疑將大模型的自主應用門檻降到最低。</p><p style="margin-left:0; margin-right:0">此外，九章元識還具有「多模態」的重要屬性。支持各類結構化和非結構化數據（包括數字、文本、圖像、音頻、視頻等），將成倍轉化和輸出數據資產價值。同時，為了支撐多模態數據的對齊，九章雲極 DataCanvas 公司推出的開源產品 DingoDB 多模向量數據庫，配合元識大模型，可以為向量數據提供存儲和分析，為多模態數據的利用和管理提供必備工具載體。</p><p style="margin-left:0; margin-right:0">當前，九章雲極 DataCanvas 公司已推出基於九章元識和 DingoDB 的大模型解決方案「企業知識管家」，破除私域多模態數據管理和應用難題，賦能企業構建高度自動化與智能化的企業知識庫，加速多模態大模型落地應用。</p><p style="margin-left:0; margin-right:0; text-align:center"><strong><span>從 AI 基礎軟件到 AI 基礎服務</span>，&nbsp;「雲中雲」戰略再進階</strong></p><p style="margin-left:0; margin-right:0">從終端大模型應用，到模型構建平台、算法平台，到向量數據庫，再到最底層的算力建設，大模型技術的火熱為 AI 模型產業鏈提供層層機遇。在將底層核心技術視為發展命脈的市場態勢下，人工智能基礎設施再度引爆。基於對未來趨勢的研判和為用戶提供全生命週期服務的初衷，<strong>九章雲極 DataCanvas 公司正式成立智算中心，將在人工智能基礎軟件產品優勢的基礎上，為廣大用戶提供「算法+算力」一體化服務，構建高效計算底座的基礎設施。</strong></p><p style="margin-left:0; margin-right:0">九章雲極 DataCanvas 公司董事長方磊表示，自提出「雲中雲」戰略以來，公司以 AI 基礎軟件為載體，持續將 AI 能力嵌入千行百業的雲生態中，成果顯著。此次推出的「算法+算力」一體化服務，是抓住市場中算力的巨大需求，深化與雲廠商、智算中心等夥伴的生態合作，共同構建高質量的「AI 基礎服務」。&nbsp;</p><p style="margin-left:0; margin-right:0">未來，九章雲極 DataCanvas 公司將圍繞客戶的人工智能升級需求，踐行「雲中雲」戰略，充分佈局算力建設，加速多模態大模型行業落地，以先進技術創新引領行業，為數字經濟建設助力築基。</p><p style="margin-left:0; margin-right:0"><strong>投資方簡介</strong></p><p style="margin-left:0; margin-right:0"><strong>中電智慧基金</strong>作為中國電子的產業投資基金，堅持服務於中國電子主責主業，投向戰略性新興產業，推動重構計算產業體系，在集成電路、網絡安全、數據產業、高新電子等領域開展投資佈局。充分發揮產業背景優勢，推動被投企業與集團產業充分協同，對集團補鏈強鏈，對企業投後賦能。</p><p style="margin-left:0; margin-right:0"><strong>華民投</strong>是股權投資領域的國家隊、央企投資協會會員單位。藉助權威股東的資源背景，公司廣泛鏈接資本市場和 5000 多家上市公司，緊跟國家戰略，圍繞戰略新興產業開展投資，投資的項目涉及半導體、新材料、新能源、智能汽車、人工智能、數字經濟和生物醫藥等多個方向，全面助力國家產業升級轉型和經濟發展。</p><p style="margin-left:0; margin-right:0"><strong>太平創新</strong>是國內首批經原中國銀保監會批准設立的保險系私募基金管理公司之一，作為中國太平保險集團旗下專業私募股權投資平台，充分發揮保險資金的專業優勢與中國太平的央企擔當，佈局醫療健康、科技金融、先進製造、鄉村振興等投資賽道。</p><p style="margin-left:0; margin-right:0"><strong>東方嘉富</strong>是浙江省屬國有上市金控平台——浙江東方 (SH.600120) 旗下「市場化運作專業化管理」的混合所有制私募基金管理機構，重點關注智能製造和新材料、新一代信息技術及生命科學領域早期及成長期企業的投資，並已建立起私募股權投資加私募證券投資「一二級投研聯動」的資產管理體系。截至目前，東方嘉富累積管理基金總規模超 150 億元人民幣，累積投資企業超 90 家。</p><p style="margin-left:0; margin-right:0"><strong>卓源資本</strong>創始於 2016 年，是一家專注於集成電路及 AI 的專業投資機構，起源於清華大學計算機系 FIT 樓實驗室，由清華大學校友共同創辦。卓源資本致力於打造中國最領先的泛集成電路及 AI 領域的投資機構，創始團隊累計管理與投資規模超過 30 億人民幣。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 06:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261144</guid>
            <link>https://www.oschina.net/news/261144</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[首個圖文混合創作大模型「書生·浦語靈筆」開源]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">上海人工智能實驗室（上海 AI 實驗室）<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbXz_BRiv8CskONSWQR44WA" target="_blank">宣佈</a>推出首個圖文混合創作大模型書生·浦語靈筆（InternLM-XComposer，簡稱「浦語靈筆」），依託強大的多模態性能，解鎖「一鍵生成」圖文混合文章的創作能力，為大模型落地應用提供更多可能。</span></p><p><span style="color:#000000">目前，浦語靈筆已開源其中的智能創作和對話（InternLM-XComposer-7B）及多任務預訓練（InternLM-XComposer-VL-7B）版本，並提供免費商用。</span></p><p><span style="color:#000000">此前，上海 AI 實驗室曾陸續開源了書生·浦語大語言模型的 7B（InterLM-7B）及 20B（InternLM-20B）版本。基於書生·浦語大語言模型（InternLM），浦語靈筆接受視覺和語言模態輸入，不僅在圖文對話方面表現優秀，更具備圖文並茂文章的「一鍵生成」能力。</span></p><p><span style="color:#000000">浦語靈筆能夠進行流利的中英文圖文對話，準確理解圖像內容；並解鎖了圖文並茂文章創作的全新能力。除自動配圖能力外，浦語靈筆還提供了配圖推薦和更換功能，根據用戶實際需求定製圖文內容。</span></p><p><span style="color:#000000"><img alt="" height="284" src="https://oscimg.oschina.net/oscnet/up-ec14d16110bb87f0afcb2b74f79d7e39691.png" width="500" referrerpolicy="no-referrer"></span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-f6052a5051fe3cacf90b67197e4a6aca666.gif" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">目前，浦語靈筆已支持科普文稿、營銷廣告、新聞稿件、影視評論、生活指南等類型文章的圖文並茂生成，並將逐漸開放更多能力。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-65a9432b417fb971eade0876788010d6752.gif" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">浦語靈筆為圖文文章創作設計了「三步走」的算法流程：</span></p><ul><li><span style="color:#000000">理解用戶指令，創作符合主題要求的長文章。</span></li><li><span style="color:#000000">智能分析文章，模型自動規劃插圖的理想位置，並生成所需圖像的內容要求。</span></li><li><span style="color:#000000">多層次智能篩選，利用多模態大模型的圖像理解能力，從圖庫中鎖定最完美的圖片。</span></li></ul><p><img alt="" height="249" src="https://oscimg.oschina.net/oscnet/up-b14e63c7394663e682d3500915895eaf962.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">研究人員採用 5 個主流的多模態大模型評測對 InternLM-XComposer-VL-7B 的能力進行了詳細測試。</span></p><p><img height="384" src="https://oscimg.oschina.net/oscnet/up-6d115621e76f671c92c4cd8b35d201bd0c4.png" width="500" referrerpolicy="no-referrer"></p><p><img height="233" src="https://oscimg.oschina.net/oscnet/up-221640dab71f38f3d96610b4a6b94d5671d.png" width="500" referrerpolicy="no-referrer"></p><p><img height="353" src="https://oscimg.oschina.net/oscnet/up-fd2769a9128cb307d94d946f31bb4ff3bc2.png" width="500" referrerpolicy="no-referrer"></p><p><img height="345" src="https://oscimg.oschina.net/oscnet/up-fee648bef717b06a7d28b20b5d0ed2625e7.png" width="500" referrerpolicy="no-referrer"></p><p><img height="355" src="https://oscimg.oschina.net/oscnet/up-9c29359b6718e111b5a2c03074cc6ed6b97.png" width="500" referrerpolicy="no-referrer"></p><p><img height="315" src="https://oscimg.oschina.net/oscnet/up-b748c9bb6f4b6b3948fb921b630992b227f.png" width="500" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 06:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261135</guid>
            <link>https://www.oschina.net/news/261135</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ChatGPT 移動應用 9 月收入高達 458 萬美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">市場情報公司 Appfigures 的最新分析數據<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fappfigures.com%2Fresources%2Finsights%2F20231006%3Ff%3D2" target="_blank">顯示</a>，OpenAI 的官方 ChatGPT 應用程序安裝數量和收入持續增長，9 月份創下了兩項新紀錄：全球 iOS 和 Android 應用程序的下載量達到 1560 萬次，其中 Google Play 的下載量為 900 萬，App Store 的下載量為 660 萬。以及總收入接近 460 萬美元，淨收入 320 萬美元；其中 300 萬美元，自 iPhone 用戶，其餘來自 Google Play。</span></p><p><span style="color:#000000">ChatGPT 官方應用自 5 月起在 App Store 上架，7 月正式登錄 Google Play 平台。自推出以來，ChatGPT 應用的總安裝量已達到 5220 萬次。該應用在 6、7、8 月份的總營收分別為 210 萬美元、274 萬美元以及 381 萬美元。</span></p><p><span style="color:#000000">目前為止，美國仍是 ChatGPT 的最大市場，貢獻了該應用程序生命週期收入的約 60%。</span></p><p><img height="285" src="https://oscimg.oschina.net/oscnet/up-fd19ce9c3118494505c250065e7d0da18c7.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">但數據也顯示，移動端 ChatGPT 應用的收入增長已經開始放緩。前幾個月的收入增長率高達 30% (7 月為 31%，8 月為 39%)，但 9 月份已降至 20%，是迄今為止最低數值。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F10%2F09%2Fchatgpts-mobile-app-hit-record-4-58m-in-revenue-last-month-but-growth-is-slowing%2F" target="_blank">TechCrunch</a> 指出，收入增長放緩可能是 ChatGPT 接近飽和的第一個跡象，表明願意為每月 19.99 美元的 ChatGPT+ 訂閲服務付費的用戶可能已經達到了上限。</span></p><p><span style="color:#000000">不過 ChatGPT 並不是收入最高的 AI 應用。Appfigures 數據顯示，一款名為 Ask AI 的競爭對手由於大量的廣告支出而獲得了更多的收入；從 ChatGPT 移動版推出時的 5 月份的 648 萬美元上升到了 8 月份的峯值 655 萬美元。9 月份略有下降，降至 551 萬美元，但仍高於 ChatGPT。其他競爭者如 Genie 和 AI Chat Smith 的增長幅度都不及 Ask AI。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 03:36:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261118/chatgpts-mobile-app-revenue-4-58m</guid>
            <link>https://www.oschina.net/news/261118/chatgpts-mobile-app-revenue-4-58m</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[一站式服務，openKylin 系統小管家懂你所需！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">openKylin 社區 SystemManager SIG 致力於開發一款面向社區用戶，能傾聽用戶煩惱和訴求，也能提供便利途徑、解決用戶問題的麒麟管家應用。在 openKylin 1.0.1 版本中，麒麟管家新增了服務支持模塊，用於收集問題和建議。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">同時，社區還發布了</span><strong><span style="color:#0052ff">有獎參與活動</span></strong><span style="color:#000000">，</span><strong><span style="color:#000000">邀請所有用戶把大家在系統使用過程中遇到的問題，通過麒麟管家的服務支持模塊快速提交至 gitee 平台，幫助快速排查和解決問題，參與就有機會獲得社區定製獎品～活動詳情可戳下方鏈接：</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left">https://mp.weixin.qq.com/s/EYaiHBM-VhiDg80Knbr_FA&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">在前面的活動中，我們為大家着重講解了</span><strong><span style="color:#000000">服務支持模塊</span></strong><span style="color:#000000">。今天，我們就來給大家詳細介紹下麒麟管家的其餘三個模塊，包括</span><strong><span style="color:#000000">故障檢測、垃圾清理、百寶箱</span></strong><span style="color:#000000">。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">一、網絡連接不成功，管家幫您找問題</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">首先要為大家介紹的功能是「故障檢測」。當前故障檢測內容還相對單一，只包含「網絡檢測」，後續會陸續增加其他檢測類型，及「一鍵修復」功能。</span></span></p><div><p style="text-align:center"><img alt="" height="673" src="https://oscimg.oschina.net/oscnet/up-d1b0a902ea99d05ab092028116240aaec7b.png" width="1066" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">使用方法非常簡單，只需點擊「一鍵檢測」按鈕，管家會自動逐項排查網絡問題，並給出提示。</span></span></p><div><p style="text-align:center"><img alt="" height="672" src="https://oscimg.oschina.net/oscnet/up-c749e6d50d7191e33aa355e6da5b6efc899.png" width="1059" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">此外，還可以根據每個人不同的上網需求，將經常訪問的網站加入自動檢測隊列中。點擊右下角的「內網檢測設置」，打開「開啓內網檢測」開關，然後將要檢測的網絡地址填寫到對應的位置，點擊右側的加號可以添加多個地址，添加完成後點擊「保存」。</span></span></p><div><p style="text-align:center"><img alt="" height="704" src="https://oscimg.oschina.net/oscnet/up-bd51680a0542c4e4754f3b24a69585376ef.png" width="1095" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">二、系統垃圾不用慌，麒麟管家幫您忙</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本節要為大家介紹的功能是「垃圾清理」。可以一鍵清理 openKylin 操作系統中的垃圾文件，當前支持系統緩存、瀏覽器 cookies 及系統使用痕跡的清理。</span></span></p><div><p style="text-align:center"><img alt="" height="668" src="https://oscimg.oschina.net/oscnet/up-8055700cec2b846eca2ad5bd53aeb7038b1.png" width="1052" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">使用方法非常簡單，只需點擊「開始掃描」等待掃描完成，然後點擊「一鍵清理」即可自動完成清理操作。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-bae775d8d6b2e43c75703c1b94faaf395d0.png" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">此外，還可以根據每個人不同的清理需求，自定義垃圾清理類型。點擊垃圾清理首頁的垃圾分類比如「系統緩存」即可彈出清理列表選項，勾選的清理項不同，掃描的結果也會不同。</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-c82351d8f8a62816ef181bf2ad234c52dc2.png" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">三、管家百寶箱上新啦</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">最後要為大家介紹的功能是「百寶箱」，其中會收錄一些精緻而實用的小工具。隨着 openKylin 1.0.1 版本發佈，百寶箱中也加入了新成員。</span></span></p><div><p style="text-align:center"><img alt="" height="699" src="https://oscimg.oschina.net/oscnet/up-ac1e256da0171f9ac9a7ed6a957d7028954.png" width="1095" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">在之前的版本，百寶箱中收錄了「文件粉碎機」，可以讓您輕鬆粉碎機密和隱私文件，避免被恢復。操作也很簡單，從百寶箱點擊「文件粉碎機」卡片，點擊「添加」按鈕添加待粉碎的文件，然後點擊「粉碎」按鈕即可開始粉碎操作。</span></span></p><div><p style="text-align:center"><img alt="" height="684" src="https://oscimg.oschina.net/oscnet/up-fca6200212c5658abca6d8585f0c7881d52.png" width="1072" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">此外，百寶箱還新增了「win 遷移工具」，用於將 windows 系統中的數據遷移至 openKylin。首先點擊「win 遷移工具」卡片，在設置中選擇「win 端如何設置」查看設置教程，根據教程設置 windows 端共享，然後將 win 端的連接信息「ip 地址」、「工作組」、「用戶名」、「密碼」填寫在對應位置點擊「建立連接」。之後界面會根據 win 端共享的目錄結構生成樹狀圖表，在圖表中勾選要遷移的文件後點擊「開始遷移」即可自動遷移數據。</span></span></p><div><p style="text-align:center"><img alt="" height="696" src="https://oscimg.oschina.net/oscnet/up-907f36fa35cdf22684b187d1f14e47dea5b.png" width="1084" referrerpolicy="no-referrer"></p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">四、管家後續開發計劃</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">目前，小管家還有很多要完善的地方，如上文提到的故障檢測新增檢測項和一鍵修復功能，除此之外，還將新增驅動精靈板塊自動匹配和安裝外設驅動，百寶箱新增崩潰收集工具以及垃圾清理交互體驗優化等。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin 社區 SystemManager SIG 組會持續努力，打造更好用的小管家，讓其成為您使用 openKylin 系統時最知心的「朋友」。</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#4e84d8">關於 SystemManager SIG</span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">SystemManager SIG 組致力於組建系統管家開源社區，負責開發和維護系統管家及附屬工具，為 openKylin 生態和實用性添磚加瓦，歡迎各位的加入！</span></span></p><ul><li><span><span style="color:#000000">郵件列表：</span></span></li><li><span><span style="color:#0052ff">systemmanager@lists.openkylin.top</span></span></li><li><span><span style="color:#000000">SIG 主頁：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/SystemManager</span></span></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 03:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261115</guid>
            <link>https://www.oschina.net/news/261115</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[curl 8.4.0 將修復高危安全漏洞]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>curl 創始人&nbsp;Daniel Stenberg（社區稱號 bagder）表示將於 10 月 11 日發佈的 curl 8.4.0 會修復高危安全漏洞，並稱該漏洞可能是很長一段時間以來<strong> curl 遇到的最嚴重漏洞 (the worst curl security flaw in a long time)</strong>，同時影響到 libcurl 庫和 curl 工具。</p><p>此外還會修復被評級為"LOW"的安全漏洞——僅 libcurl 受影響。</p><ul><li>CVE-2023-38545: severity HIGH (affects both libcurl and the curl tool)</li><li>CVE-2023-38546: severity LOW (affects libcurl only, not the tool)</li></ul><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1010/105819_w1di_2720166.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcurl%2Fcurl%2Fdiscussions%2F12026" target="_blank">https://github.com/curl/curl/discussions/12026</a></p></blockquote><p>bagder 表示目前無法透露有關受影響的版本範圍，因為這會導致漏洞被高精確地針對性利用。他只説到「過去幾年」發佈的版本都會受影響。</p><p>bagder 已在郵件列表宣佈該消息，建議使用 curl 的開發者密切關注即將發佈的 curl 8.4.0，同時梳理在項目中使用該庫的情況，以便及時安裝更新。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 03:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261110/curl-8-4-coming</guid>
            <link>https://www.oschina.net/news/261110/curl-8-4-coming</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Unity 首席執行官 John Riccitiello 離職]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>根據 Unity 官方消息，Unity 首席執行官 John Riccitiello 已宣佈離職，該事宜即日生效。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-6c10a9521e4d9916a0e7e7d57f5f97d17cb.png" referrerpolicy="no-referrer"></p><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.businesswire.com%2Fnews%2Fhome%2F20231009494331%2Fen%2FUnity-Announces-Leadership-Transition" target="_blank">Unity 在一份聲明中表示</a>，已任命 James Whitehurst 為臨時首席執行官，Roelof Botha 為董事長。Riccitiello 將繼續為 Unity 提供建議，以確保平穩過渡，董事會將啓動任命一位永久首席執行官的流程。</p><p><img src="https://static.oschina.net/uploads/space/2023/1010/103434_WHy2_2720166.png" referrerpolicy="no-referrer"></p><p>此前 Unity 宣佈了新的收費規則，引起業內人士的強烈不滿。之後 Unity 向公眾和業內人士道歉，並調整了收費規則。</p><p><strong>延伸閲讀</strong></p><ul><li><a href="https://www.oschina.net/news/257929/unity-runtime-fee">Unity 引擎明年起根據遊戲安裝量收費 (runtime fee)</a></li><li><a href="https://www.oschina.net/news/258513/unity-apologize-for-runtime-fee">Unity 道歉：將修改 "runtime fee" 收費政策</a></li><li><a href="https://www.oschina.net/news/258477/wait-is-unity-allowed-to-just-change-its-fee-structure-like-that">走近「收費門」：互相矛盾的服務條款導致 Unity 面臨被起訴的風險</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 02:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261101/unity-ceo-john-riccitiello-is-retiring</guid>
            <link>https://www.oschina.net/news/261101/unity-ceo-john-riccitiello-is-retiring</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[【SIG 月報】9 月 openKylin 社區 SIG 組最新進展分享]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"><span><span style="color:#000000">為推動社區繁榮發展，打造開源操作系統創新生態，openKylin 社區圍繞</span><strong><span style="color:#000000">創新硬件、人機交互、智能支撐、終端安全、互聯協同、雲端融合</span></strong><span style="color:#000000">等多個技術領域，以技術小組的形式開展深入研究和技術創新。接下來，讓我們一起盤點 9 月份 openKylin 社區 SIG 組的最新進展：</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#4f9eff">9 月社區新增 SIG</span></span></strong></span></p><h1>9 月社區新增 1 個 SIG 組，目前已累計成立 86 個 SIG 組，新增 SIG 組信息如下：</h1><p style="color:#222222; margin-left:0; margin-right:0; text-align:left"><span><strong><span style="color:#ff9b0e"><span style="background-color:#f5faff">01</span></span><span style="color:#1c9cee"><span style="background-color:#f5faff">AI4OS SIG</span></span></strong></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000"><span style="background-color:#f5faff">操作系統智能化（Artificial Intelligence for Operating System）由社區愛好者發起成立，致力於將人工智能（AI）與操作系統（OS）相結合，以實現操作系統的智能化和性能優化。將大模型為代表的 AI 技術嵌入 openKylin 操作系統，讓 AI 深扎底層操作系統，可以在沒有任何應用作為中介的情況下，直接調用 AI 大模型能力完成任務。</span></span></span></p><ul><li><span><span style="color:#000000">SIG 主頁：</span></span></li><li><span><span style="color:#0052ff">https://gitee.com/openkylin/community/tree/master/sig/AI4OS</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#4f9eff">9 月社區 SIG 活躍度彙總</span></span></strong></span></p><p>9 月社區新增有效 PR 數 559 個、倉庫 Fork 數新增 104 個、SIG 組公開例會召開 7 次。截至目前，社區累計有效 PR 數 11122 個、倉庫 Fork 數 4364 個、SIG 組公開例會召開 93 次，其中：</p><ul><li><span><span style="color:#000000">9 月社區 SIG 組 PR 貢獻 top15 如下：</span></span></li></ul><div><p style="text-align:center"><img alt="" height="556" src="https://oscimg.oschina.net/oscnet/up-f6da435acfce936b5ba91e340785173187f.png" width="794" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">9 月社區 SIG 組活躍地圖分佈情況（顏色越深代表越活躍，參考維度：PR、issue、SIG 會議）如下：</span></span></p><div><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-13b61252308faea98672ac9805bdafca274.png" referrerpolicy="no-referrer"></p><p style="margin-left:0px; margin-right:0px">&nbsp;</p></div><p style="color:#222222; margin-left:0; margin-right:0; text-align:center"><span><strong><span style="color:#ffffff"><span style="background-color:#4f9eff">9 月社區技術進展與成果</span></span></strong></span></p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>一、UKUI SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">UKUI(Ultimate Kylin User Interface) SIG 小組致力於桌面環境相關軟件包的規劃、維護和升級工作，滿足各種設備和用戶需求的桌面環境程序，主要包含程序啓動器（開始菜單）、用戶配置、文件管理、登錄鎖屏、桌面、網絡工具、快捷配置等，為用戶提供基本的圖形化操作平台。桌面核心組件開發工具以 Qt、C++為主，宗旨是始終如一地提升系統的操作體驗，提供集穩定性、美觀性、流暢性和便捷性為一體的桌面環境。9 月進展如下：</span></span></p><ul><li><span><span style="color:#000000">系統監視器新增後台運行功能並註冊託盤圖標；</span></span></li><li><span><span style="color:#000000">搜索、開始菜單適配多 Display 場景下；</span></span></li><li><span><span style="color:#000000">優化搜索設置項顯示策略、優化內存操作邏輯和若干 bug；</span></span></li><li><span><span style="color:#000000">修復文件管理器操作相關的若干問題；</span></span></li><li><span><span style="color:#000000">修復切換語言後立刻重啓計算機後桌面出現多餘圖標問題；</span></span></li><li><span><span style="color:#000000">修復桌面目錄後出現「鎖狀」圖標問題；</span></span></li><li><span><span style="color:#000000">修復任務欄預覽窗口操作顯示邏輯問題；</span></span></li><li><span><span style="color:#000000">修復控制面板關於模塊部分名詞拼寫問題；</span></span></li><li><span><span style="color:#000000">修復系統安裝完成後應用通知按鈕為關閉狀態的問題；</span></span></li><li><span><span style="color:#000000">完成 3 篇桌面協議相關翻譯；</span></span></li><li><span><span style="color:#000000">UKUI-Lite 技術方案評審；</span></span></li><li><span><span style="color:#000000">UKUI Framework 後續規劃及統一接口方案評審。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎各位感興趣的社區開發者加入我們，一起打造 openKylin 桌面系統穩定易用的桌面環境！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>二、RISC-V SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#333333">本</span>SIG 組主要負責 RISC-V 架構開源軟件包的維護，發佈 openKylin 的 RISC-V 版本，進行軟件包構建、系統構建等工作。9 月 RISC-V SIG 組進展如下：</span></p><ul><li><span><span style="color:#000000">解決了 VisionFive2 開發板在 wayland 模式下鼠標指針不顯示的問題；</span></span></li><li><span><span style="color:#000000">製作 roma 筆記本新版 sdk3.6.1 的鏡像；</span></span></li><li><span><span style="color:#000000">更新併發布 VisionFive2 和荔枝派的 openKylin1.0.1 版本鏡像；</span></span></li><li><span><span style="color:#000000">獲取 electron 的包，通過安裝高版本依賴的方式解決了 electron 的啓動問題，目前可以在 xorg 模式下正常運行 electron；</span></span></li><li><span><span style="color:#000000">嘗試在荔枝派開發板中適配 gpu，和廠商溝通聯調；</span></span></li><li><span><span style="color:#000000">調試並進行 box64 代碼梳理。主要學習動態重編譯部分，梳理了運行微信從模擬運行入口，到 opcode 翻譯，到彙編指令執行的流程。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 RISC-V 開發平台技術方向感興趣的愛好者加入到 RISC-V SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>三、Release SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Release SIG 主要負責協調各個 SIG 組，把控版本開發進度和風險，制定版本發佈計劃，完成版本發佈工作等。Release SIG 9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">推動 openKylin 1.0.1 各架構版本集成、測試驗收等工作，完成 1.0.1 版本發佈；</span></span></li><li><span><span style="color:#000000">推動搜狗輸入法 NG 版本和 openKylin 1.0.1 適配；</span></span></li><li><span><span style="color:#000000">編寫 openKylin 1.0.1 版本更新日誌；</span></span></li><li><span><span style="color:#000000">openKylin 2.0 版本規劃，需求討論、推進，啓動基礎庫選型等工作；</span></span></li><li><span><span style="color:#000000">和儒特科技討論 QSFramework 在社區合作落地、代碼持續集成等事宜。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區版本集成、版本管理、版本發行等工作感興趣的愛好者加入到 Release SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>四、Packaging SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Packaging SIG 負責維護 openKylin 社區的軟件包打包規範，維護公共軟件包，以及協調和決策社區版本發佈過程中的包依賴問題。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">《openKylin 生態應用自主選型構建》任務第一階段選型報告評審；</span></span></li><li><span><span style="color:#000000">cme 程序無法使用（Compilation failed），執行報錯問題分析修改；</span></span></li><li><span><span style="color:#000000">解決 arm64 架構基礎構建工具 cmake 運行報符號未定義的問題；</span></span></li><li><span><span style="color:#000000">軟件包源碼信息整改。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區軟件自主選型、編譯打包工作感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>五、QA SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">QA SIG 組致力於提升 openKylin 社區版本質量，包括社區版本測試、質量保障等。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">openKylin-1.0-2309-beta-0901 版本測試；</span></span></li><li><span><span style="color:#000000">窗管替換 wlcom 專項測試；</span></span></li><li><span><span style="color:#000000">openKylin-1.0-2309-beta-0908 版本測試；</span></span></li><li><span><span style="color:#000000">openKylin-1.0.1-0918 版本測試。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區版本測試、質量管理感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>六、SecurityGovernance SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">openKylin SecurityGovernance SIG 通過接收和響應 openKylin 社區的產品安全問題報告、提供社區安全指導，開展安全治理等活動提升社區產品的安全性。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">Genmai 開發：新增安全漏洞自動化用例 poc40 個；解決某些架構下返回值異常導致崩潰問題；適配龍芯架構,適配 risc-v 架構，進度 80%；解決漏洞用例 yaml 文件格式錯誤問題；解決 kysec、Selinux 導致 poc 及基線掃描出錯問題；增加「將 root 權限傳入基線腳本」的功能；開發根據服務端版本自動更新功能；解決 C/S 架構漏洞檢測傳輸時長過長造成超時問題；新增原創安全漏洞 5 個；</span></span></li><li><span><span style="color:#000000">參加在西班牙畢爾巴鄂由 Linux 基金會主辦的 2023 Linux 安全峯會，並發表主題演講。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 版本安全全漏洞挖掘/驗證、安全漏洞修復等安全方面工作感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>七、OpenSDK SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">OpenSDK SIG 組負責開發者套件（base、system、applications）規劃、開發、維護等工作，致力於解決應用在多操作系統中的兼容性問題。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">完成配置化模塊的 conf2 表結構設計、xml2yaml 特定格式轉換工具開發工作；後端服務支持數據寫入以及鍵值對變更信號發送；</span></span></li><li><span><span style="color:#000000">優化並協助其他組件排查解決問題共 21 個：優化開發手冊易用性，包括 man 手冊以及開發指南中 API 引入的 sdk 版本號；優化應用埋點接口功能。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對開發者套件感興趣的社區愛好者們加入 OpenSDK SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>八、CompatWinApp SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">CompatWinApp SIG 組致力於將大量的 Windows 系統應用程序引入到 openKylin 系統。SIG 組將通過研究應用兼容技術和指令翻譯技術，研製完善的 windows 應用兼容方案，讓更多的 windows 應用能兼容運行於 openKylin 系統，不斷繁榮 openKylin 軟件生態。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">修改 wine 助手下載流程，直接下載應用修改為先跳轉到應用程序下載頁面；在當前應用配置文件中增加應用下載頁參數；</span></span></li><li><span><span style="color:#000000">下載應用時增加對用戶的操作提示；修復當應用下載鏈接更新時無法下載的問題；修復下載鏈接重定向時無法下載的問題；</span></span></li><li><span><span style="color:#000000">研究解決了 wine riched20 模塊中導致的微信編輯輸入框右鍵不顯示菜單的問題，初步解決了編輯框光標位置錯亂的問題；</span></span></li><li><span><span style="color:#000000">在 wine-program 倉庫 wiki 界面增加 wine 助手的使用説明。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對應用兼容技術和指令翻譯技術感興趣的愛好者加入到 CompatWinApp SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>九、Infrastructure SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Infrastructure SIG 負責 openKylin 社區的基礎平台系統功能的開發、維護。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">優化 openKylin 看板結合 SIG 狀態自動更新 SIG 數量問題；</span></span></li><li><span><span style="color:#000000">openKylin 看板增加任務平台積分更新功能；</span></span></li><li><span><span style="color:#000000">優化 openKylin 看板前端，增加頁面緩存 TAB；</span></span></li><li><span><span style="color:#000000">CLA 開放企業管理員手動添加簽署員工限制；</span></span></li><li><span><span style="color:#000000">CLA 修復企業管理員後台一些內容未國際化問題；</span></span></li><li><span><span style="color:#000000">openKylin 看板增加 commit 信息統計，支持 commit 記錄導出。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區基礎設施平台開發維護感興趣的愛好者加入到 Infrastructure SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十、Connectivity SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本 SIG 組致力於 openKylin 社區的互聯互通基礎能力開發與維護，9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">優化文件管理其插件相關能力，解決線程安全問題。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎各位感興趣的社區開發者加入 Connectivity SIG 小組，一起共建 openKylin 桌面系統互聯互通能力！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十一、I18n SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">I18N SIG 組負責 openKylin 社區國際化和本地化相關工作，包括多語言開發框架、多語言平台開發和維護，以及社區、版本內文檔的翻譯管理相關工作。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">翻譯官網新聞 18 篇；</span></span></li><li><span><span style="color:#000000">翻譯 openKylin 基於 RISC-V 的主要工作介紹；</span></span></li><li><span><span style="color:#000000">校驗 openKylin 個人信息保護及隱私政策聲明。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對操作系統、網站網頁、文檔等翻譯工作感興趣的社區愛好者們加入 I18n SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:left">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十二、InputMethod SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本 SIG 組致力於組建輸入法開源社區，推進開源輸入法框架及開源輸入法在社區維護。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">定位分析搜狗輸入法問題，包括 wayland 環境輸入窗口顯示異常、託盤菜單圖標顯示異常和候選詞上屏異常等問題；</span></span></li><li><span><span style="color:#000000">討論 OK 輸入法進展，完成 OK 輸入法設計文檔；</span></span></li><li><span><span style="color:#000000">分析拼音輸入法右鍵菜單顯示異常問題，與 fcitx 社區討論修改情況；</span></span></li><li><span><span style="color:#000000">完成虛擬鍵盤支持動畫效果開發，提高 UI 美觀度；</span></span></li><li><span><span style="color:#000000">完成虛擬鍵盤支持多語言輸入開發，其中包括哈薩克語、維吾爾語、柯爾克孜語和藏語等。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區 fcitx 輸入法框架、桌面虛擬鍵盤開發工作感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十三、Kernel SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Kernel SIG 組致力於新硬件適配、新功能、新特性開發。不斷提升內核健壯性、穩定性，能更好的為 openKylin 系統和應用程序提供底層技術支持。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">6.1 內核從 6.1.43 更新到 6.1.55。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對內核感興趣的社區小夥伴加入 openKylin 社區 Kernel SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="margin-left:0px; margin-right:0px; text-align:justify"><strong>十四、Virtualization SIG</strong></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Virtualization SIG 組致力於構建 openKylin 社區系統虛擬化技術，打造面向端、邊、雲的全場景虛擬化解決方案。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">qemu:修復了 CVE-2023-0330 漏洞。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對虛擬化組件或軟件包技術感興趣的社區小夥伴加入 openKylin 社區 Virtualization SIG 組！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十五、Framework SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">本 SIG 組致力於為 openKylin 社區提供集程序編輯、編譯、調試、發佈、分析等全套開發功能的編程環境，涵蓋通用集成開發環境、編譯工具鏈、運行時環境、類庫等，9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">Kylin-Code 發佈 v0.1.3，修復諸多問題，並上架應用商店；</span></span></li></ul><ul><li><span><span style="color:#000000">C/C++調試，Java 調試，插件依賴管理，死鎖檢測等插件發佈新版本。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎對集成開發環境研發感興趣的社區開發者和愛好者加入 Framework SIG！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十六、Cutefish SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">Cutefish SIG 負責移植 Cutefish 桌面環境及其組件，專注於打造美觀易用、極簡操作的桌面環境。9 月進展如下：</span></span></p><ul><li><span><span style="color:#000000">完成 RISC-V 架構開發板 VisionFive2 的適配工作；</span></span></li><li><span><span style="color:#000000">完成 ARM 架構開發板 CoolPi 4B 的適配工作。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">如果您對移植桌面環境有興趣，或者有相關打包經驗，歡迎加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十七、KernelBuilder SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">KernelBuilder SIG 組負責 openKylin 內核預覽版本的自動化構建，構建工具（kernel-builder）的規劃、開發、維護等工作。同時積極維護了 openkylin-rootfs 和 openkylin-wsl 倉庫，為 openKylin 提供了可用的根文件系統、wsl 開發環境為 openKylin 在 docker 容器化創造了條件。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">rootfs 根文件系統迭代更新；</span></span></li><li><span><span style="color:#000000">docker 鏡像打包製作；</span></span></li><li><span><span style="color:#000000">利用 github actions 自動打包製作 rootfs 根文件系統和 docker 鏡像，並更新內部環境；</span></span></li><li><span><span style="color:#000000">distcc 軟件適配進行中；</span></span></li><li><span><span style="color:#000000">為內核自動化構建創造 docker 預運行環境；</span></span></li><li><span><span style="color:#000000">同時本月聯合 opendde sig 開展共同開發計劃；</span></span></li><li><span><span style="color:#000000">香橙派 kernel 適配中、根文件系統適配中；</span></span></li><li><span><span style="color:#000000">內部測試 apt 源已搭建完成、目前可以小範圍通過 apt 分發測試版內核。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區內核構建及應用、docker 容器化、根文件系統、wsl 開發環境感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十八、RTHypervisor SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">RTHypervisor SIG 小組致力於實時虛擬化技術的研究，目前主要包括 Jailhouse，提供工控、車載等領域實時控制的虛擬化解決方案，Jailhouse 項目 9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">新增 arm64 平台上通過將 pcie rc 和 its 隔離給 non root cel 的方式，將 pcie 設備隔離給 non root cell，實現 pcie 設備直通功能。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有對 openKylin 社區實時虛擬化技術感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>十九、FAQ SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">FAQ SIG 小組致力於收集各渠道社區開發者、愛好者等用戶反饋的問題，並建立相關標準化流程推動問題解答或解決同時，在這一過程中不斷為 openKylin 社區積累 FAQ 知識庫。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">召開 1 次 SIG 例會，和 UKUI SIG，Docs SIG，Community SIG 組交流和討論當前待解決的問題；</span></span></li><li><span><span style="color:#000000">收集論壇、社羣高頻問題並提交 issue 指派給開發，解決 10+高頻問題；</span></span></li><li><span><span style="color:#000000">社羣用戶答疑與指導，指導用戶解決系統下載安裝、軟件商店、桌面環境等相關問題。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">歡迎所有感興趣的社區愛好者加入我們！</span></span></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify">&nbsp;</p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><em><strong>二十、OpenDDE SIG</strong></em></p><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">OpenDDE SIG 致力於維護 openKylin 的 DDE 桌面環境以及相關組件，專注於打造美觀易用、極簡操作的桌面環境。9 月主要進展如下：</span></span></p><ul><li><span><span style="color:#000000">聯合 KernelBuilder SIG 研究了 VisionFive2 EDK2 UEFI 鏡像製作流程；</span></span></li><li><span><span style="color:#000000">DDE 桌面軟件包更新工作。</span></span></li></ul><p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"><span><span style="color:#000000">如果您對移植桌面環境有興趣，或者有相關打包經驗，歡迎加入我們！</span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 02:25:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261098</guid>
            <link>https://www.oschina.net/news/261098</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[搞流式計算，大廠也沒有什麼神話]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p>抖音、今日頭條，是字節跳動旗下最受用戶歡迎的兩款產品，也是字節跳動的門面。而在這背後，是眾多技術團隊在支撐，流式計算就是其中一支。</p><p>不過，即使是在字節跳動，搞流式計算也沒有神話。只有一羣年輕人，花了六年時間，一步一個腳印，從一開始的「不懂技術不懂業務」，最後承載起了字節內部流式計算平台以及應用場景的構建，支撐了機器學習平台、推薦、數倉、搜索、廣告、流媒體、安全和風控等眾多核心業務。2022 年，該團隊完成了對 Flink 計算引擎的雲原生化改造，並通過火山引擎正式對外提供雲上能力。</p><p>這不是一個挽狂瀾於既倒的英雄故事，沒有什麼跌宕起伏的情節，也沒有耀眼的鮮花與掌聲。而是千千萬萬個普通開發者中的一小羣人，一邊在業務中被動接受成長，一邊在開源中主動尋求突破的一段記錄。</p><span id="OSC_h3_1"></span><h3><span style="color:#2980b9">01 <strong>代碼要寫，業務也要拉</strong></span></h3><p>2019 年，隨着抖音的爆發，字節跳動站在了高速增長的起點，直播、短視頻，廣告等業務也都乘勢而起。這些業務，都需要流式計算來支撐。</p><p><strong>字節流式計算團隊負責人張光輝，正面臨諸多棘手的問題。</strong></p><p>先把時間線往前推兩年，彼時張光輝剛加入字節跳動，計算引擎用的還是 Apache<em></em>Storm——誕生於 2011 年的、Twitter 開發的第一代流處理系統，只支持一些 low level 的 API。</p><p>「所有的 Storm 任務都是在開發機上用腳本提交，運維平台處於非常原始的狀態。如果 Storm 集羣故障，作業都無法自動恢復，甚至無法找到所有存量作業。」張光輝對此記憶猶新。</p><p>話雖這麼説，但誰也別嫌棄誰。那時張光輝的履歷上，並沒有流式計算產品的經驗，不過有些「沾親帶故」——參與過流式計算的上下游產品開發，比如數據採集、消息隊列。</p><p>好在趁着字節的業務場景偏單一，主要聚焦在機器學習場景，張光輝和其團隊將流式計算引擎從 Apache Storm 切換到了 Apache Flink。所謂團隊，其實連他在內，也僅有兩人。之後又在 2018 年與數據流團隊合作完成了流式計算平台化的構建，包括任務的監控、報警，日誌採集，異常診斷等工具體系。</p><p>來到 2019 年，流式計算要支撐的業務場景已經相當豐富，擴展到了實時數倉、安全和風控等，並且還在不斷增加。單個場景需求也變得更加複雜：推薦業務越來越大，單個作業超過 5 萬 Cores；實時數倉業務場景需要 SQL 來開發，且對數據準確性有了更高要求。</p><p>然而，由於團隊人手嚴重不足，工作進展很是緩慢。「只有兩個人，Oncall 輪流值周。不用值周的時候，往往都在解決上一週 Oncall 遺留的問題。」張光輝如此形容。</p><p>張光輝不得不一邊擴充人員，一邊與數據集成團隊着手構建 SQL 平台。李本超正是這個時候加入了流式計算團隊，並且在不久之後，就成為了 Flink SQL 方向的技術負責人。</p><p><strong>然而，用 </strong><strong>SQL</strong><strong> 來開發</strong><strong>流式計算</strong><strong>任務</strong><strong>，李本超也沒有太多經驗：「一開始，技術也不懂，業務也不懂。」</strong></p><p>在此之前，他在一家中小型企業任職，工作範圍涉及廣泛，流式計算只能算其中一個方向。加入字節後，李本超這才意識到，字節的流式計算規模遠超自己的想象。之前只能看到 1 個併發的任務，而在字節，一個任務的併發卻可以上萬，僅單個任務使用的計算資源就比其上家公司所有任務加起來都多。</p><p>但李本超不能不懂。一週五天上班時間，其中有三天，張光輝早上第一件事情就逮着他問，跟哪個業務聊了，能新建幾個 SQL 任務。</p><p><strong>指標每天都在頭頂打轉，李本超不得不給團隊「拉業務」。</strong>用的話術就跟在大街上攔住路人賣產品一樣，只不過地點換成了字節在北京的各個工區。</p><p>「哎，這個流式計算我們可以通過 SQL 開發，你們感不感興趣？想不想了解一下？」李本超沒事就聯繫電商、直播、廣告、遊戲、教育等業務部門負責人。只要人家點頭，李本超二話不説，馬上坐班車跑去工區現場交流。</p><p>張光輝評價：「那個時候，真的是‘無所不用其極’。」</p><p>有了 SQL 平台，開發及維護效率飛速提升。「原來一個人開發一個任務，需要一兩天。而現在，一個人一天直接就能搞定十個任務。此外，業務方與我們的溝通方式也更簡單了，對方寫的代碼我們也都能看懂，優化起來很方便。」</p><p>除此之外，字節在 Flink 穩定性方面做了大量的工作，比如支持黑名單機制，單點故障恢復，Gang 調度，推測執行等功能。由於業務對數據的準確性要求更高了，團隊支持作業開啓 Checkpoint 機制來保證數據不丟失，並在字節得到了大面積的推廣和落地。</p><p>在這個過程中，李本超也發現，Flink 可能沒有想象得那麼強大、易用，比如隨便改一改 SQL 狀態就沒法兼容。針對這類尚未被社區解決的問題，字節內部也進行了大量的優化方案探索。</p><p style="text-align:center"><img height="600" src="https://oscimg.oschina.net/oscnet/up-e8d825d23950c5e2d58dc9a101db0d82ab1.png" width="600" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#8f959e"><em>字節跳動 </em></span><span style="color:#8f959e"><em>Flink</em></span><span style="color:#8f959e"><em></em></span><span style="color:#8f959e"><em>SQL</em></span><span style="color:#8f959e"><em> 任務佔比</em></span></p><span id="OSC_h3_2"></span><h3><span style="color:#2980b9">02 <strong>Flink</strong><strong>，原來不止於流式計算</strong></span></h3><p>字節跳動選用 Flink 作為流式計算處理引擎後，每天有數萬個 Flink 作業運行在內部集羣上，峯值流量高達每秒 100 億條數據。單個作業的規模也非常大，每個計算節點使用 3 萬左右的併發，整個作業使用 300 多台物理機。Flink 集羣的穩定性和性能優化，以及單個超大作業的部署、執行和 Failover 等優化，面臨的問題在整個業界都難覓第二。</p><p>由於 Flink 是一個流批一體計算引擎，字節跳動內部也在積極推動 Flink 流批一體落地，上線了 2 萬多個 Flink 批式作業，在這個過程中解決了很多穩定性和性能問題，比如 Hive 語法兼容、慢節點、推測執行等。</p><p>同時，字節跳動內部啓動了 ByteHTAP 項目，結合字節內部的 OLTP 系統，已經能夠支持數據延時低（亞秒級）、數據一致性要求高的分析型計算，但還缺一個計算引擎來支持 OLAP 計算。由於字節在 Flink 做了大量的深入優化，最終將其作為 ByteHTAP 的 OLAP 引擎。</p><p style="text-align:center"><img height="630" src="https://oscimg.oschina.net/oscnet/up-0bdaccfa52987511e6780144f12d4450ee4.png" width="772" referrerpolicy="no-referrer"></p><p><strong>然而，</strong><strong>在 ByteHTAP </strong><strong>開始給業務方提供線上 </strong><strong>OLAP</strong><strong> 服務時，新的問題又出現了。</strong>業務方不僅對單併發查詢的 latency （延遲）有要求，還希望團隊提供的 OLAP 服務能夠支持高併發度。</p><p>正值 2021 年年初，方勇加入了字節跳動，擔任流式計算架構師。為了支撐線上業務，方勇和團隊要儘快把這塊的能力給補齊。</p><p>「整個開發過程非常煎熬，壓力非常大。」方勇説：」ByteHTAP 已經提供了線上服務，我們需要快速迭代，使 Flink 支持更高的併發查詢。」</p><p>每次團隊開週會，方勇都會盯着 QPS 指標。用了近半年的時間，「總算把 QPS 從個位數優化到十幾、幾十，直到線上單集羣支持幾百 QPS」。</p><p>近兩年，字節正在將 Flink OLAP 諸多優化貢獻回社區。 Flink OLAP 的相關內容也加入了到了 Apache Flink 2. 0 的 Roadmap 中。</p><p>一條完整的數據生產鏈路，分為三個計算場景，分別是流式、批式和 OLAP 計算。在實時數倉場景，需要 Storm 或 Flink 來支撐流式計算；在批式場景，則要依靠 Hive 或 Spark。當計算語義不一樣時，兩套引擎會導致流式結果和批式結果不一致。而且，流批一體數據計算完成之後，還需導入數倉或者離線存儲，此時還要引入一套新的 OLAP 引擎去探查、分析，這就更加無法保證正確性和一致性。</p><p>而且，優化及維護也頗為麻煩。三套系統就意味着，要建三個團隊去分別維護。一旦遇到需要優化或者解決 bug 等情況，還要分別到三個社區提 issue 討論。</p><p>Flink 社區提出了 Streaming Warehouse 解決這個問題，字節調研了目前流式計算發展方向和 Streaming Warehouse 系統，基於 Flink 和 Paimon 構建了 Streaming Warehouse 系統，分別統一流批一體的計算和存儲，增加了作業和數據血緣管理、數據一致性管理、流式數據訂正和回溯等核心功能，解決流式計算的準確性和數據運維等問題。</p><p style="text-align:center"><img height="259" src="https://oscimg.oschina.net/oscnet/up-fca6618852b7122974aca81d2377233a202.png" width="600" referrerpolicy="no-referrer"></p><p><strong>最終，「三套引擎，三個團隊」變成「一套引擎，一個團隊」。</strong>用方勇的話來説，使用 Flink 作為整個數據生產鏈路統一的流式、批式和 OLAP 一體的計算引擎，已經完全就不用擔心數據的實時性、業務分析的複雜性。</p><p>至於 Flink 的未來，方勇已經有了設想。他希望能夠集合社區的研發能力，一起完善整個 Flink 的計算生態，將 Flink 打造成統一流、批和 OLAP 的 Streaming Warehouse 系統。</p><span id="OSC_h3_3"></span><h3><span style="color:#2980b9">03 新業務，新場景，新挑戰</span></h3><p>2022 年，字節流式計算團隊支撐研發的計算引擎商業化產品「流式計算 Flink 版」上線火山引擎，正式對外提供雲上計算能力，而不是僅僅服務於字節內部業務。</p><p>在字節，這款產品被稱為「Serverless Flink」。Serverless Flink 依託於字節跳動在業內最大規模實時計算集羣實踐，基於火山引擎容器服務（VKE/VCI），提供 Serverless 極致彈性，是開箱即用的新一代雲原生全託管實時計算平台。</p><p><strong>事實上，將</strong><strong> Serverless </strong><strong>Flink</strong><strong> 稱之為一款</strong><strong>新上線的產品</strong><strong>可能並不合適。</strong>李本超解釋，所謂「流式計算 flink 版」，其實就是團隊在六年時間裏，讓 Apache Flink 在字節內部實現了大規模應用，並把積累的大量的產品經驗和技術能力「包裝」了一下，而不是重新做了一個產品。</p><p>它是基於 Apache Flink 衍生出來的，可以理解為 Apache Flink 增強版，並且 100% 兼容 Apache Flink，包含諸多特性：</p><ul><li><p>開發效率提升。 流式計算 Flink 版支持算子級別 Debug 輸出、Queryable State、Temporal Table Function DDL，在開發效率上對開源版本 Flink 有顯著提升。</p></li><li><p>可靠性提升。 流式計算 Flink 版針對單個 Task 進行 Checkpoint，提高了大併發下的 Checkpoint 成功率。單點任務恢復和節點黑名單機制功能，保障了對故障節點的快速響應，避免業務整體重啓。</p></li><li><p>Serverless 雲原生架構。 極致彈性，1‰ 核精細調度。</p></li><li><p>易用性增強。 極簡 SQL 開發，開箱即用、免運維、支持流式數據全生命週期管理。</p></li><li><p>高性能低價格。 高性價比、高 SLA 保證、超低 TCO。</p></li></ul><p style="text-align:center"><img height="312" src="https://oscimg.oschina.net/oscnet/up-94e4c01fd23fdb7e7327a975d5f2575b6dd.png" width="800" referrerpolicy="no-referrer"></p><p style="text-align:center"><span style="color:#8f959e"><em>流式計算</em></span><span style="color:#8f959e"><em>Flink</em></span><span style="color:#8f959e"><em>版，架構圖</em></span></p><p><strong>在 Serverless </strong><strong>Flink</strong><strong> 上線火山引擎之後，方勇發現，外部客戶需求與內部業務需求很是不同。</strong>比如有的客戶還在使用 Storm、Samza 等相對較為早期的流式技術棧。因此，團隊不僅要對客戶進行技術培訓和技術支持，還要幫助技術支持人員理解客戶的作業邏輯，以更好地服務其業務。</p><p>這意味着，流式計算團隊面臨的是新的場景與挑戰，有時甚至要從零開始構建一個新的系統。</p><p>不過，一切工作都在有條不紊地展開。近兩年，團隊成員已經擴展到 30 人，並對 Serverless Flink 在調度、運行時、SQL 等各個方面都進行了全方面的優化，極大提升性能。</p><p>此外，基於 Apache Flink 及 Apache Paimon，團隊在 Streaming Warehouse 實時數倉場景也有了新的突破，實現了支持數據的一致性、血緣，以及數據回溯等實時數倉的產品能力。</p><p>截止目前，基於流式計算 Flink 構建的實時業務場景已經涉及到字節幾乎所有的業務和產品，包括實時數倉、實時風控、商業化、電商、遊戲、小説、教育、房產、財經等，日常實時峯值超 100 億 QPS。與此同時，流批一體在特徵工程，數據同步，計數服務，電商等場景均得到了廣泛的使用和落地，已上線將近 2 萬 Flink Batch SQL 任務。</p><p><strong>此刻，張光輝才終於敢説：「 經歷了從 0 到 1 的過程之後，今天字節的流式計算平台，</strong><strong>已經可以打 8 分了。</strong><strong>」</strong></p><p>方勇提到，未來，團隊將在可用性、穩定性、性能等方面持續優化流式計算平台，並繼續深入 Flink OLAP 生產實踐，建設和完善穩定性和可用性等周邊系統，比如 Debug 能力、 Auto Scaling 系統。</p><p>除了流式計算之外，團隊在 Flink 批式方面也做了很多的優化和嘗試， 比如兼容 Hive SQL 語法等。同時，一些超大規模的作業，也在往 Flink 批式方向上去嘗試。在 Flink 批式場景積累經驗之後，團隊將會持續推動 Flink 流批一體的應用和實踐，同時結合社區需求，貢獻一些新的能力。</p><p>Native Engine 也將成為團隊探索的一大方向。Flink 以 Java 語言為主，部分技術涉及行式計算，導致它並不能很好地利用 CPU，以及更新迭代的一些新功能。而如何利用 Native Engine 提升性能及運算能力，降低成本，是大勢所趨。</p><span id="OSC_h3_4"></span><h3><span style="color:#2980b9">04 開源是一件自然而然的事</span></h3><p>從服務內部業務到服務外部客戶，字節對 Apache Flink 的應用愈加深入。當然，字節之於 Apache Flink，並非只停留在「用」的層面，而是源源不斷地將其創新成果貢獻到開源社區中，更是成為了研發 Flink OLAP 等方向的主要牽頭企業。在眾多為 Flink 社區貢獻的國內企業中，字節參與度能排到第二。</p><p><strong>除了 </strong><strong>Apache Flink</strong><strong>，流式計算團隊還為 </strong><strong>Apache</strong><strong> Calcite 、Apache Paimon 這兩個項目做出了不小的貢獻，並在社區構建了一定的影響力。</strong></p><p>Apache Calcite 是一個動態的數據管理框架，它可以實現 SQL 的解析、驗證、優化和執行。當前，字節是該項目核心貢獻公司之一，參與 plan 優化、方言生態增強、運行時優化等工作。Apache Paimon (incubating) 則是一項流式數據湖存儲技術，可以為用戶提供高吞吐、低延遲的數據攝入、流式訂閲以及實時查詢能力。字節是該項目的創始貢獻公司之一。</p><p>截至目前，字節流式計算團隊培養了包括李本超、方勇等在內共 8 名 Apache 項目 committer，為 Flink 社區貢獻了 174 個 commits，為 Calcite 社區貢獻了 47 個 commits，以及為 Paimon 社區貢獻了 107 個 commits。</p><p><strong>雖説開源成果豐碩，但在流式計算團隊，並沒有安排專門的人去貢獻開源。於他們而言，開源是一個自然而然的過程。</strong></p><p>「我們用開源的組件來搭建產品，鼓勵組員在日常開發過程中，將新增的功能特性、bug 修復以及一些優化，貢獻到社區。這就是我們日常的工作模式。希望大家在社區交流中，可以提升代碼質量以及保持對技術的探索。」張光輝補充説：「當然，最開始，也沒有什麼開源的氛圍，每個人都忙着業務。不過，李本超和方勇這兩個開源積極分子起了帶頭作用，其他團隊成員在其影響下，也逐漸接觸開源。」</p><p>李本超也提到，社區和公司之間沒有明顯界限。「上游項目 Apache Flink 跟我們的 Serverless Flink 其實是一個項目，只不過我們在用 Serverless Flink 來支撐一個更具體的公司業務場景。公司非常鼓勵我們把成果貢獻給社區。但如果內部需求更着急，或者説很難有一個非常快速且完整通用的方案，就會在內部先上線試用。」</p><p>團隊也不強制要求研發人員一定要參加社區。</p><p>「參與開源是一件比較偏個人的事情，看他自己個人興趣，以及對職業生涯、技術方面的規劃。不過為了保證內外系統的一致性，以及我們系統後續發展的兼容性，增進研發同學之間的技術交流及合作，我們非常鼓勵大家把遇到的問題提交到社區。有一些需要內部討論或支持方案，如果剛好也是外部開源社區所需要的，我們都會考慮把這些需求引進到內部。這樣可以做到內部統一開發，然後統一推進。」方勇解釋。</p><span id="OSC_h3_5"></span><h3><span style="color:#2980b9">05 要貢獻開源，其實並不容易</span></h3><p>如李本超所言，所有有利於社區變的更好的事情，都是一種貢獻，比如用戶問答、代碼 review、文檔的維護、不穩定測試的修復、build 系統的提升、技術討論、release 等等。</p><p><strong>但對於從未參與過開源的人來説，開始可能是最困難的一步。</strong></p><p>「在 Apache Calcite 、Apache Flink 以及 Apache Paimon 等社區，開發者非常活躍，很多人提 issue 都會得到解答。但沒參與之前，去哪裏去找 issue，怎麼寫代碼，怎麼提 PR，怎麼新建 feature，整個流程完全是陌生的。這個過程其實聽起來比較簡單，但真正去實踐的時候，發現它還是有一定門檻。」方勇提到。</p><p><strong>即使已經有了一些重大的開發成果，要貢獻給社區，也並不是簡單地把代碼從內部拿到外部。</strong></p><p>一些針對專項業務定製化開發的功能，在開源社區可能會被認為不夠通用。李本超説，一些新開發的功能特性，即使已經在業務上驗證過，但在回饋開源社區時，往往需要重新思考和設計，使其在滿足業務訴求的基礎上，又能抽象出更通用的能力。</p><p>當然，對李本超和方勇而言，字節業務的優先級自然是更高的，技術架構的普適性、能力的通用性方面的優先級稍微低一點。但在面對業務和社區共同的需求時，他們還是儘可能做到同時兼顧。也許最後開發出來的解決方案並不是最完美的，但已經能解決 80% 的問題。</p><p><strong>再進一步，如果已經抽象出一些功能特性，想把代碼貢獻到社區，也不代表這個過程會很順利。</strong>由於社區對核心組件的代碼要求比較高，在代碼被合併之前，包括 API 設計、PR 合理性等在內的各方面問題，都需要經過社區討論。</p><p>方勇曾向 Flink 提了一個 PR :在 job manager 節點進行內存優化。 一位德國的項目成員 review 代碼後，認為原理上可以。但他還問了幾個問題：為什麼要提交這個 PR，你們遇到了什麼問題，為什麼要採用這種方式修復它？ 因為 Flink JVM 的 Java 代碼從實現上來看，並沒有內存問題。</p><p>由於該部分涉及到 JVM 層的 classloader 和 full GC 優化，在此之前，方勇就曾與 JVM 系統組有過深入研究探討。他們發現，JVM 不僅有 Java 代碼實現， 還有 C++ 代碼實現，而 C++ 實現的代碼如果有一些複用情況，會出現內存泄露，導致 job manager 節點的 full GC 變多，處理性能下降。當方勇把這一分析過程以及 Benchmark 測試貼到社區後，最終獲得了認可。PR 也很快就被合併了。</p><p><strong>此外，貢獻開源還要從代碼架構的角度來思考，是否與現有系統兼容。</strong>李本超説，要獲得業務部門的認可，要求開發人員對業務有深入的理解，幫助業務部門解決問題，達到預期收益就可以。但在開源社區，想要貢獻代碼，不僅要考慮事件本身的合理性，還要考慮其通用性是否夠強，是否會跟已有功能衝突，未來怎麼維護，如何演進等等。</p><p>方勇就曾遇到過一個案例。一個容災體系，要先靠外部的數據流生成容災 ID，Flink 再通過該 ID 實現整個作業容災。社區為了支持這一功能，做了特定的 API 的開發。方勇在將部分功能代碼提交到倉庫時，就要考慮是否兼容特定的 API 。「不能讓這個 API 受到幹擾，否則 Flink 用戶升級版本之後，原先功能就運行不起來了。這對 Flink 的穩定性以及後續發展都是不利的。」</p><span id="OSC_h3_6"></span><h3><span style="color:#2980b9">06 加入 PMC/PPMC，責任更大了</span></h3><p>今年，李本超、方勇先後分別成為了 Apache Calcite、Apache Paimon（incubating）的 PMC member（項目管理委員會成員）、PPMC member（孵化器項目管理委員會成員）。</p><p>這意味着，二人為開源社區做出的貢獻，得到了認可。這並不容易。在社區想要獲得認可，不僅僅只看代碼，還要看技術能力、溝通能力、持續貢獻的意願，以及行為是否符合社區文化（比如 Apache 之道）。如何在日常參與社區事務的過程中，將能力和素質展現出來，是很有挑戰性的。</p><p><strong>李本超有一次印象深刻的經歷。</strong>在 Apache Calcite 社區，他從創建 issue，討論 issue，寫代碼，提交 PR ，到最終合入代碼，前後一共用了五個月的時間。</p><p>「不是説這個 issue 複雜到需要五個月，也不是説這五個月只做這一件事。社區成員都是異步溝通，大部分人都在利用業餘時間來討論問題和貢獻代碼。加上社區對代碼質量要求高，項目本身很複雜，在討論過程中，經常會產生不同的想法和建議。」這個過程對李本超來説，還是挺煎熬的。</p><p>「因為實現方案可能會換好幾次，不同方案要寫不同的代碼。最後討論來討論去，可能還是原來的好，又要在原來的基礎上再改。反反覆覆。最終代碼量也沒多大。」他補充説：「但這個過程能夠很好地展現出個人素質和能力。」</p><p>具備耐心，並且長期堅持，在開源社區是很必要的。方勇認為，成為 PPMC 需要持續關注和投入，保持在自己在社區的活躍度。「持續關注新的 issue，把自己的工作整理出來，再去社區提 issue，然後在社區發起討論，一起評估方案。最終把任務分解後，再開發代碼，再把它合進去，花費的時間週期可能會非常長。在 Flink 社區，如果要合入一些對公共 API 有修改的代碼，從設計討論，到投票，再到開發以及推進，整個過程至少需要 3 個月。」</p><p><strong>對李本超來説，成為 </strong><strong>Apache</strong><strong> Calcite 的 </strong><strong>PMC</strong><strong> member 就意味着肩負了起更大的責任。</strong>「我在社區沒有任何角色的時候，只關心是不是把問題解決了。而且社區裏一定會有更資深的人去幫我去確認代碼有沒有問題，有人在後背託着我。」</p><p>現在，他的身份變了，不再只是貢獻代碼，而是輔助他人貢獻。「我就是把好最後那道關的那個人，壓力和責任更大了。心裏會想着，這個東西我一定得想清楚，一定得為了社區健康、長遠的發展去思考，而不只是把代碼快速合入，把問題快速地解決掉。總之，更小心，更謹慎，思考維度也更多了。」</p><p>李本超還需要承擔很多非代碼的工作，比如代表社區跟 Apache 軟件基金會的基礎設施團隊討論社區機制、流程等問題，讓新加入的開發者在為項目做貢獻的時候，更容易、更方便。「很多時候，付出就不只是單純貢獻的維度了。投入到社區，需要自己有很大的興趣和足夠的精力。」</p><p><strong>同樣深感責任重大的，還有方勇。</strong>他見到過一些開源社區，在成員慢慢變少後，不再活躍，對項目造成了嚴重打擊。每年都有很多新的項目開源，也有很多老的開源項目死掉。</p><p>「既然給了 PPMC 這麼大的權限，作為成員之一，我對整個項目的發展方向就要有更多的考量。 PPMC 最主要的責任，就是對開源項目的把控，包括方向的抉擇、重大 feature 的演進。」</p><p>不同公司及團隊源源不斷地加入社區，會貢獻很多新的功能，有些甚至能夠拿來就用，無需重新開發，在加快項目和社區發展的同時，也在幫助字節完善其內部相關係統功能。當然，字節在將項目用於實際生產業務中時，也會為項目開發很多新的功能特性，並且經過了大量場景的驗證和錘鍊。因此，在規劃項目演進方向時，方勇除了考量外部需求以及其他 PPMC 的提議，會更加主動地去展現公司內部開發的功能，這樣既可以讓內外系統保持一致，也能推動項目更好地往前走。</p><span id="OSC_h3_7"></span><h3><span style="color:#2980b9">07 有了開源社區，好像有了靠山</span></h3><p>大部分人對開源的認知，都發端於使用開源項目。「但如果只是使用一個開源軟件，對社區的感知幾乎是沒有的。」張光輝雖然並未獲得 Apache Flink 的 committer 或 PMC member 的身份，但他和很多人一樣，也在為項目貢獻着自己的力量。</p><p>「以前覺得開源離我們很遠。尤其是在中國，這種感受更加明顯。但是在參與 Apache Flink 社區以及線下大會之後，跟開發者有了交流和接觸，自然而然就產生了情感上的鏈接，促使你主動回饋，促使你去成長。」<strong>張光輝自己也是從開源社區中成長起來的。</strong>此前在將流式計算引擎遷移到 Flink 時，張光輝就曾遇到過不少問題，經常會跟阿里、美團等公司的開發者在 Apache Flink 社區中討論。</p><p><strong>開源給李本超帶來了很強的踏實感。</strong>「我和這個領域最優秀的一羣人站在了一起。有什麼問題一起討論，一起解決，好像多了一個非常強大的虛擬團隊，即使是在處理內部業務的時候，也感覺自己有靠山了。社區裏邊有很多寫代碼超過 30 年的資深專家，不管是在技術領域，還是非技術領域，我都能從他們身上學到很多。」</p><p>在 Flink 社區，很多用戶都會在郵件組提一些涉及使用、調優等方面的問題。也許問題本身並不複雜，但因為 Flink 系統很複雜，對初學者而言，門檻還是有點高。</p><p><strong>同樣經歷過新手期的方勇，很能理解這種情況。</strong>「有時候，對方郵件提到的 bug 或者 issue，我們沒有遇到過，但我們仍然會去研究了相關的代碼，幫他解答，甚至直接提交代碼。問題解決之後，我經常會收到感謝郵件，這時候就覺得付出有回報，非常有成就感。」</p><p style="text-align:left">參與社區之後，方勇與開源社區成員見面的機會也更多了，經常與其深入交流項目演進、技術發展、行業趨勢等各方面的想法，同時也在促進各開源項目、社區之間的結合。現在，他正琢磨着，怎麼把 Apache Flink 和 Apache Paimon 更好地結合，做下一代流式計算解決方案。</p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 10 Oct 2023 01:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oscpyaqxylk/blog/10116398</guid>
            <link>https://my.oschina.net/oscpyaqxylk/blog/10116398</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源框架 NanUI 作者轉行賣鋼材，項目暫停開發]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>NanUI 作者在國慶節發佈了停更公告，稱該項目將暫停開發，原因是去年被裁員失業後，<strong>他已轉行銷售鋼材</strong>，現在很難騰出時間來開發和維護 NanUI 項目。</p><p>他説道：</p><blockquote><p>為了生存，本人只能花費更多的時間和精力去談單，去銷售，去收款，因此已經很難再騰出時間來開發和維護 NanUI 項目，對此我深感無奈，也希望後面生活和工作穩定後能騰出時間來繼續維護 NanUI。</p></blockquote><p>NanUI 作者表示，他所在公司因疫情於去年（2022 年）初徹底宣佈裁減所有開發崗位，因此他也只能順應大流在 36 歲這個尷尬的年紀失業。</p><p><img height="1285" src="https://static.oschina.net/uploads/space/2023/1009/173727_oVGe_2720166.png" width="1980" referrerpolicy="no-referrer"></p><p><em>via&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FXuanchenLin%2FNanUI%2Fdiscussions%2F367" target="_blank">https://github.com/XuanchenLin/NanUI/discussions/367</a></em></p><blockquote><p>NanUI 界面組件是一個開放源代碼的 .NET / .NET Core 窗體應用程序（WinForms）界面框架。它適用於希望使用 HTML5/CSS3 等前端技術來構建 Windows 窗體應用程序用戶界面的 .NET 開發人員。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-060f8d602f0ac9de0bb5953b554b233f62e.png" referrerpolicy="no-referrer"></p><p>NanUI 基於谷歌可嵌入的瀏覽器框架 Chromium Embedded Framework (CEF)，因此用戶可以使用各種前端技術 HTML5/CSS3/JavaScript 和流行前端框架 React/Vue/Angular/Blazor 設計和開發 .NET 桌面應用程序的用戶界面。</p><p>同時，NanUI 獨創的 JavaScript Bridge 可以方便地實現瀏覽器端與 .NET 之間的通信和數據交換。</p><p>使用 NanUI 界面框架將為傳統的 WinForm 應用程序的用戶界面設計和開發工作帶來無限種可能！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 09:50:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261033</guid>
            <link>https://www.oschina.net/news/261033</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[非凸科技受邀出席源創會，探討數據技術的未來發展]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:center"><img height="466" src="https://oscimg.oschina.net/oscnet/up-c551fe1ce356a89e7e8b392055164817d4f.jpg" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>9</span></span><span><span>月</span></span><span><span>23</span></span><span><span>日</span></span><span><span>，</span></span><span><span>由開源中國聯合騰訊雲</span></span><span><span>TVP</span></span><span><span>開展的「數據與前沿技術」源創會活動在成都順利舉行</span></span><span><span>，</span></span><span><span>非凸科技受邀出席</span></span><span><span>，</span></span><span><span>與業界專家們共同探討了數據存儲</span></span><span><span>、</span></span><span><span>數據分析</span></span><span><span>、</span></span><span><span>數據挖掘等前沿技術</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>會上</span></span><span><span>，</span></span><span><span>非凸科技成都分公司研發總監趙海峯以「量化交易的數據驅動」為主題進行了分享</span></span><span><span>。</span></span><span><span>在量化交易領域如何高效地獲取行情數據</span></span><span><span>，</span></span><span><span>如何將行情數據轉發到需要的服務器</span></span><span><span>，</span></span><span><span>如何處理大量歷史行情數據的存放和讀取</span></span><span><span>，</span></span><span><span>又是如何通過行情數據進行模型的訓練</span></span><span><span>，</span></span><span><span>趙海峯老師一一做出了精彩的解答</span></span><span><span>。</span></span><span><span>活動後</span></span><span><span>，</span></span><span><span>引發線上熱烈交流討論</span></span><span><span>。</span></span></span></span></p><p style="text-align:center"><img height="358" src="https://oscimg.oschina.net/oscnet/up-dd23c7e0f8444597f06f020859cc3e800bb.png" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>量化交易主要通過行情數據進行交易決策</span></span><span><span>，</span></span><span><span>那麼如何通過券商獲取行情</span></span><span><span>，</span></span><span><span>進行行情低延遲接收的軟硬件方案呢</span></span><span><span>？</span></span><span><span>交易所發佈</span></span><span><span>的</span></span><span><span>行情</span></span><span><span>會</span></span><span><span>經過券商的處理再轉發給交易機構</span></span><span><span>，</span></span><span><span>其轉發途徑主要有</span></span><span><span>TCP、UDP、FPGA</span></span><span><span>加速的 UDP 和</span></span><span><span>ASIC</span></span><span><span>加速的 UDP</span></span><span><span>行情</span></span><span><span>等</span></span><span><span>。</span></span><span><span>然而</span></span><span><span>，</span></span><span><span>券商通過</span></span><span><span>TCP</span></span><span><span>連接將處理後的行情數據轉發給交易機構</span></span><span><span>，</span></span><span><span>會存在延遲大</span></span><span><span>、</span></span><span><span>應用層</span></span><span><span>丟包</span></span><span><span>（非 TCP 協議丟包）、發送端負載大</span></span><span><span>等問題</span></span><span><span>。</span></span><span><span>為瞭解決這些問題</span></span><span><span>，</span></span><span><span>券商又通過</span></span><span><span>UDP</span></span><span><span>組播或廣播的方式</span></span><span><span>，</span></span><span><span>將處理後的行情或交易所原始行情轉發給交易機構</span></span><span><span>。</span></span><span><span>為了達到極致的低延遲，</span></span><span><span>券商端將會通過多種方式來解決</span></span><span><span>，</span></span><span><span>其中一個</span></span><span><span>特別有效</span></span><span><span>的方式是使用</span></span><span><span>L1</span></span><span><span>交換機</span></span><span><span>，在一層轉發光或電信號給客戶，其轉發延遲可以低至 4ns。</span></span><span><span>需要注意的是</span></span><span><span>，</span></span><span><span>雖然 UDP 不是一個可靠傳輸協議，但</span></span><span><span>在同一個交換機連接的服務器</span></span><span><span>之間使用 UDP 進行通信</span></span><span><span>，</span></span><span><span>正常情況下</span></span><span><span>在網絡上幾乎不</span></span><span><span>會</span></span><span><span>丟包</span></span><span><span>。然而，</span></span><span><span>在客戶端程序和服務器的網卡上可能</span></span><span><span>會</span></span><span><span>丟包</span></span><span><span>。</span></span><span><span>因此</span></span><span><span>，</span></span><span><span>客戶在接收行情時</span></span><span><span>，</span></span><span><span>可以使用</span></span><span><span>無鎖的</span></span><span><span>ring buffer</span></span><span><span>轉發數據到處理線程</span></span><span><span>，</span></span><span><span>以並</span></span><span><span>行處理</span></span><span><span>不同股票的行情，</span></span><span><span>然後</span></span><span><span>將處理結果</span></span><span><span>寫入共享內存</span></span><span><span>，</span></span><span><span>以供交易系統讀取</span></span><span><span>。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>收到行情後</span></span><span><span>，</span></span><span><span>如何將行情數據轉發給內部的其他消費者呢</span></span><span><span>？</span></span><span><span>如果對延遲要求沒有太高</span></span><span><span>，</span></span><span><span>可以使用</span></span><span><span>TCP</span></span><span><span>轉發行情</span></span><span><span>，</span></span><span><span>能夠自己控制丟包率</span></span><span><span>，為了降低延遲和增加吞吐，也可以使用 UDP 轉發行情。</span></span><span><span>由於逐筆行情不允許丟包</span></span><span><span>，</span></span><span><span>所以在使用</span></span><span><span>UDP</span></span><span><span>轉發行情時</span></span><span><span>，</span></span><span><span>可以搭配</span></span><span><span>TCP</span></span><span><span>行情重傳服務</span></span><span><span>，</span></span><span><span>通過</span></span><span><span>多路行情匯聚</span></span><span><span>、R</span></span><span><span>oc</span></span><span><span>ksdb</span></span><span><span>持久化</span></span><span><span>等方式對 UDP 轉發行情進行補充</span></span><span><span>。</span></span><span><span>如果</span></span><span><span>轉發行情前</span></span><span><span>進行數據壓縮</span></span><span><span>，</span></span><span><span>那麼延遲</span></span><span><span>和吞吐量可能會更優秀</span></span><span><span>。</span></span><span><span>行情壓縮主要有兩種方式</span></span><span><span>：</span></span><span><span>行情消息的壓縮</span></span><span><span>、</span></span><span><span>消息內部</span></span><span><span>字段</span></span><span><span>的壓縮</span></span><span><span>（</span></span><span><span>股票代碼</span></span><span><span>、</span></span><span><span>價格</span></span><span><span>）。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>行情轉發之後</span></span><span><span>，</span></span><span><span>如何使用行情數據分析交易執行情況</span></span><span><span>，</span></span><span><span>又該如何訓練模型呢</span></span><span><span>？</span></span><span><span>收取到行情後</span></span><span><span>，</span></span><span><span>其中一種應用場景是訓練量化交易模型</span></span><span><span>，</span></span><span><span>將收取到的行情數據進行特徵處理</span></span><span><span>，</span></span><span><span>提取因子</span></span><span><span>，並利用 AI</span></span><span><span>進行模型訓練</span></span><span><span>，</span></span><span><span>然後將訓練好的模型解析出來以備高效地計算</span></span><span><span>實時</span></span><span><span>信號</span></span><span><span>，</span></span><span><span>在接收到實時信號值之後</span></span><span><span>，</span></span><span><span>再</span></span><span><span>極速</span></span><span><span>推送到交易系統</span></span><span><span>，</span></span><span><span>就可以根據不同的策略配置觸發交易</span></span><span><span>；</span></span><span><span>另一種場景應用是把收取到的行情數據與</span></span><span><span>C</span></span><span><span>l</span></span><span><span>ickHouse</span></span><span><span>集成</span></span><span><span>，</span></span><span><span>這</span></span><span><span>不僅能提供高效的聚合和分析查詢</span></span><span><span>功能</span></span><span><span>，</span></span><span><span>還能使用流式聚合表自動計算</span></span><span><span>交易數據，如實時</span></span><span><span>交易盈虧</span></span><span><span>，風險指標等</span></span><span><span>。</span></span></span></span></p><p style="text-align:center"><img height="466" src="https://oscimg.oschina.net/oscnet/up-14ae8244232acc42aea0b9bf638cf1632ff.jpg" width="700" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>非凸科技正在加大對金融科技研究的投入</span></span><span><span>，</span></span><span><span>持續以行業技術交流與合作的方式</span></span><span><span>，</span></span><span><span>整合行業生態優勢資源</span></span><span><span>，</span></span><span><span>加快創新技術在實際業務場景中的落地</span></span><span><span>。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 09:31:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261029</guid>
            <link>https://www.oschina.net/news/261029</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[學習 DevOps 落地實踐，全面提升技術水平]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在我們高速發展的技術時代，DevOps 已經成為企業持續交付和優化業務的關鍵。但是目前市場寒冬、經濟下行，各大企業紛紛裁員。作為天選打工人的我們，收入鋭減、就業困難，普通人如何應對？大齡 IT 從業者，職業迷茫、焦慮恐慌，如何加強學習快速成長？</p><p style="text-align:center"><img height="249" src="https://static.oschina.net/uploads/space/2023/1009/165530_PSgw_2720166.png" width="400" referrerpolicy="no-referrer"></p><p>為了幫助社區成員解決以上問題，我們特別推出了一套針對技術社區的《DevOps 落地實踐訓練營》。這個訓練營將帶您全面瞭解 DevOps 的核心理念和實踐方法，從產品設計、需求管理、代碼管理、持續集成、部署發佈、數據度量、業務運營等各個領域，帶您端到端的學習 DevOps 相關知識。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165548_jSD5_2720166.png" referrerpolicy="no-referrer"></p><p>參加我們的 DevOps 落地實踐訓練營，您將會有以下收穫：</p><ol><li>提升技術能力：通過系統的培訓，您將對 DevOps 有更深入的理解，提升您的技術實力。</li><li>提高溝通能力：訓練營將幫助您更好地與開發、測試和運維團隊溝通，提高團隊協作效率。</li><li>拓寬知識視野：訓練營將邀請業內專家分享經驗，幫助您掌握最新的 DevOps 工具和技術。</li><li>發掘最佳實踐：通過案例分析和實踐操作，您將瞭解到更多的 DevOps 最佳實踐，為您的工作帶來更多靈感。</li></ol><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165712_fZMA_2720166.png" referrerpolicy="no-referrer"></p><p>我們的訓練營有以下亮點：</p><p>1、現在大多數的培訓都是線上，效果如何，相信大家都有自己的判斷。小編在以前學習線上課程時，超不過半小時就走神犯困。<strong>《DevOps 落地實踐訓練營》採用線下培訓形式，確保學員能夠親身體驗和實踐所學內容</strong>。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165732_9QiG_2720166.png" referrerpolicy="no-referrer"></p><p>2、術業有專攻，單一講師的培訓並不能做到全棧貫通賦能。本訓練營邀請多位專業講師聯袂推出端到端的實踐技能培訓，內容包含 25 個章節，<strong>全面講解軟件開發過程中產品設計、項目管理、開發、測試、架構等多個領域的知識實踐</strong>。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165752_0tuV_2720166.png" referrerpolicy="no-referrer"></p><p>3、職業技能培訓，最終的目的是學以致用。有別於其他認證類培訓，本次訓練營更為重要的是，<strong>每個環節都有動手練習環節，確保學員真正掌握所學技能</strong>。而且能夠將理論知識與實際工作緊密結合，為學員提供貫通全棧賦能的培訓。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165814_dmE9_2720166.png" referrerpolicy="no-referrer"></p><p>4、「天下苦高價培訓久矣。」本次訓練營，以 480 元的價格提供了一種高性價比的培訓方式，讓學員不再因價格而猶豫。如果你想在學習技能的同時，還想獲得一個職業技能證書，980 的價格，你就能獲得由」中國管理科學院「頒發的《專業人才培訓證書》。此處注意，培訓和證書並不強制綁定，本土培訓，僅此一家。</p><p style="text-align:center"><img src="https://static.oschina.net/uploads/space/2023/1009/165830_KvDB_2720166.png" referrerpolicy="no-referrer"></p><p>DevOps 落地實踐訓練營是一個全面提升技術水平的絕佳機會，不僅能幫助您更深入地理解 DevOps，還能提升您的團隊協作能力，拓寬知識視野，並讓您有機會接觸到更多的最佳實踐。我們邀請您積極參與，與業內專家和同行一起共創。我們期待在未來的交流和合作中與您共同成長，創造更多的可能性！</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 09:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/261024</guid>
            <link>https://www.oschina.net/news/261024</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[聯想計劃推出 Android PC]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">聯想於近日<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techradar.com%2Fcomputing%2Fdesktop-pcs%2Flenovo-shifts-direction-with-new-android-based-pcs-and-they-look-powerful" target="_blank">宣佈</a>計劃生產&nbsp;Android PC。該公司將於&nbsp;<span style="background-color:#ffffff">Esper&nbsp;</span>合作，<span style="background-color:#ffffff">重新設計其台式一體機 ThinkCentre M70a，「</span><span style="background-color:#ffffff">這台一體機將代表着聯想進軍 Android 領域的第一步」。Esper 是一家專門提供 Android 定製服務以及設備管理產品的公司。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">ThinkCentre M70a 採用 21.5 英寸 FHD 無邊框顯示屏，</span>現有版本採用英特爾處理器，可以從入門級 i3 一直配置到功能強大的 i9 芯片。M70a 目前採用的是 Windows 11 操作系統，但據透露新版本將採用 Android 系統。</span></p><p><img height="401" src="https://oscimg.oschina.net/oscnet/up-5eda0c1eee499fc80e95d2f72bb2c76eeee.png" width="500" referrerpolicy="no-referrer"></p><p><img height="399" src="https://oscimg.oschina.net/oscnet/up-98d83cf5f92a9b40a586a0f0345868a918a.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">聯想方面表示，ThinkCentre M70a 主要面向企業客戶，希望它能吸引零售和酒店業的企業使用。除此之外，聯想還計劃與 Esper 合作推出基於 Android 系統的 ThinkCentre M70q，以及基於 Windows 系統的 ThinkEdge SE30 和 ThinkCentre M90n-1 IoT。</span></p><p><span style="color:#000000">目前在台式電腦領域最接近 Android 系統的是惠普的 Chromebase AIO 等產品，由於採用了 ChromeOS，它可以通過谷歌 Play 商店運行 Android 應用程序。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 07:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260995/lenovo-esper-android-pc</guid>
            <link>https://www.oschina.net/news/260995/lenovo-esper-android-pc</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 易語言開發的服務器軟件 MODHTTP SERVER]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content-modhttp-server" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#modhttp-server"></a>MODHTTP SERVER</h1><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/fw.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>項目地址：<a href="https://gitee.com/wxgshuju/modhttp-server">https://gitee.com/wxgshuju/modhttp-server</a></p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/oschina.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>開源中國：<a href="https://gitee.com/link?target=https%3A%2F%2Fwww.oschina.net%2Fp%2Fmodhttp-server">https://www.oschina.net/p/modhttp-server</a></p><h4><a id="user-content-介紹" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E4%BB%8B%E7%BB%8D"></a>介紹</h4><p>MODHTTP SERVER 是採用國產化編程易語言開發的網站服務器軟件。</p><p>該程序集成 Nginx+ASP+PHP+MySQL+Openssl+HOSTS+MYSQL-FORM+Sqlite 數據庫管理器+Access 數據庫管理器;</p><p>支持 HTTP1.1 協議、HTTP2 協議、HTTP3 協議，該工具實現 NGINX 配置可視化編輯、PHP 可視化配置可視化編輯，</p><p>該程序不僅包括 ASP、PHP、Modhttp 調試環境，還包括了 MODHTTP 網頁視圖模塊開發工具、開發手冊等</p><h4><a id="user-content-聲明" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E5%A3%B0%E6%98%8E"></a>聲明</h4><p>本軟件基於開源協議 Apache 發佈，允許轉發，允許第三方修改，本軟件永久免費，終身免費</p><p>軟件開發者：魔帝本尊</p><p>支持平台：Windows</p><p>優點：綠色服務解壓即可安裝，一鍵可視化配置即可使用</p><p>項目狀態：持續更新維護中...</p><p>本軟件已經開源，如需要程序源碼請在 OPEN-SOURCE 中查看.</p><h4><a id="user-content-軟件架構" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84"></a>軟件架構</h4><p>本軟件需要安裝以下運行庫庫
Microsoft Visual C++ 2015-2022 Redistributable 14.38.32919.0 (2023-08-09)</p><p>x64 <a href="https://gitee.com/link?target=https%3A%2F%2Fdownload.visualstudio.microsoft.com%2Fdownload%2Fpr%2F02a6d5c5-3e10-47de-8025-d97a1321d3e3%2F5F60592799FAE0C82578112D4B621438FFC976AB39D848D8F7623F5705A83E27%2FVC_redist.x64.exe">https://download.visualstudio.microsoft.com/download/pr/02a6d5c5-3e10-47de-8025-d97a1321d3e3/5F60592799FAE0C82578112D4B621438FFC976AB39D848D8F7623F5705A83E27/VC_redist.x64.exe</a></p><p>x86 <a href="https://gitee.com/link?target=https%3A%2F%2Fdownload.visualstudio.microsoft.com%2Fdownload%2Fpr%2F02a6d5c5-3e10-47de-8025-d97a1321d3e3%2FAD573D3198853FC71137A88E51ABDE844B84F29B0CE6DD91BBEC661BC0143B36%2FVC_redist.x86.exe">https://download.visualstudio.microsoft.com/download/pr/02a6d5c5-3e10-47de-8025-d97a1321d3e3/AD573D3198853FC71137A88E51ABDE844B84F29B0CE6DD91BBEC661BC0143B36/VC_redist.x86.exe</a></p><h4><a id="user-content-下載路徑" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E4%B8%8B%E8%BD%BD%E8%B7%AF%E5%BE%84"></a>下載路徑</h4><p>最新版本：32.02</p><p>Gitee（含源碼）：<a href="https://gitee.com/wxgshuju/modhttp-server/raw/master/MODHTTP_SERVER32.02.7z">https://gitee.com/wxgshuju/modhttp-server/raw/master/MODHTTP_SERVER32.02.7z</a></p><p>代碼庫中所有文件經過病毒掃描查殺</p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t0.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>.e 文件，是易語言源代碼</p><p>.api 文件，是 MODHTTP 專屬的易語言網頁視圖模塊文件，作用等同 PHP、ASP</p><p>內存加速 1.7.ec  來源為彙編大神，白銀大佬 (2962946246) 無償提供</p><p>e2ee.fne e2ee_staticlib e2ee_static.res 來源為 E2EE 網站迅捷開發羣 (536544662)</p><p>2.3.2 免費版支持庫</p><p>源碼中用到了編碼轉換類，動態內存庫類等...</p><p>本地調試器.exe   是 MODHTTP 專屬視圖模塊的調試工具，可以清晰看到瀏覽器請求到 MODHTTP 8081 端口的各種信息</p><p>如果僅用 PHP、ASP、MySQL 等集成環境，不使用 MODHTTP 網頁視圖模塊文件則無需打開本地調試器.exe</p><h4><a id="user-content-安裝教程" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B"></a>安裝教程</h4><ol><li><p>解壓後打開&lt;&lt;MODHTTP.exe&gt;&gt;</p></li><li><p>解壓路徑中不允許有空格，建議解壓到根目錄，例如 C:\ D：\等</p></li></ol><h4><a id="user-content-使用説明" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"></a>使用説明</h4><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t1.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><ol><li>打開&lt;&lt;MODHTTP.exe&gt;&gt;</li></ol><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t2.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><ol start="2"><li><p>首次使用打開後點擊左上角菜單&gt;網站管理;打開網站管理器增填、修改網站目錄，修改完成後點擊【保存配置】按鈕，關閉此窗口</p></li><li><p>點擊啓動,在首頁右側找到擴展項&gt;Nginx&gt;配置調試，點擊【配置調試】按鈕，頁面顯示以下內容則配置成功，可以啓動服務。</p></li></ol><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">nginx: the configuration </span><span id="LC2" class="line">conf/nginx.conf syntax is ok</span><span id="LC3" class="line">nginx: configuration file D:\modhttp32.02A202310072215\modhttp-server\nginx/conf</span><span id="LC4" class="line">/nginx.conf test is successful</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t3.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>4.按需要勾選組件，如 Nginx，Mysql，ASP，PHP 等，在選項前面打勾啓動服務，如需關閉請再次點擊取消√則停止服務</p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t4.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><p>5.啓動服務後點擊右上角【訪問 nginx 頁面】按鈕，開始盡情的寫 BUG 吧</p><p><img src="https://gitee.com/wxgshuju/modhttp-server/raw/master/t5.png" alt="輸入圖片説明" referrerpolicy="no-referrer"></p><h4><a id="user-content-幫助" class="anchor" href="https://gitee.com/wxgshuju/modhttp-server#%E5%B8%AE%E5%8A%A9"></a>幫助</h4><p>鼠標光標移動到功能，文字標題會顯示幫助提示和信息</p>]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 06:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/wxgshuju/modhttp-server</guid>
            <link>https://gitee.com/wxgshuju/modhttp-server</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 聊聊前端框架的未來 Signals]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>Signals 在目前前端框架的選型中遙遙領先！</p></blockquote><p>國慶節前最後一週在 Code Review 新同學的 React 代碼，發現他想通過 memo 和 useCallback 只渲染被修改的子組件部分。事實上該功能在 React 中是難以做到的。因為 React 狀態變化後，會重新執行 render 函數。也就是在組件中調用 setState 之後，整個函數將會重新執行一次。</p><p>React 本身做不到。但是基於 Signals 的框架卻不會這樣，它通過自動狀態綁定和依賴跟蹤使得當前狀態變化後僅僅只會重新執行用到該狀態代碼塊。</p><p>個人當時沒有過多的解釋這個問題，只是匆匆解釋了一下 React 的渲染機制。在這裏做一個 Signals 的梳理。</p><h2>優勢</h2><p>對比 React，基於 Signals 的框架狀態響應粒度非常細。這裏以 Solid 為例：</p><pre><code class="language-js">import { createSignal, onCleanup } from "solid-js";

const CountingComponent = () =&gt; {
  // 創建一個 signal
  const [count, setCount] = createSignal(0);

  // 創建一個 signal
  const [count2] = createSignal(666);

  // 每一秒遞增 1
  const interval = setInterval(() =&gt; {
    setCount((c) =&gt; c + 1);
  }, 1000);

  // 組件銷燬時清除定時器
  onCleanup(() =&gt; clearInterval(interval));

  return (
    &lt;div&gt;
      &lt;div&gt;
        count: {count()}
        {console.log("count is", count())}
      &lt;/div&gt;
      &lt;div&gt;
        count2: {count2()}
        {console.log("count2 is", count2())}
      &lt;/div&gt;
    &lt;/div&gt;
  );
};
</code></pre><p>上面這段代碼在 count 單獨變化時，只會打印 count，壓根不會打印 count2 數據。</p><p>控制枱打印如下所示：</p><ul><li>count is 0</li><li>count2 is 666</li><li>count is 1</li><li>count is 2</li><li>...</li></ul><p>從打印結果來看，Solid 只會在最開始執行一次渲染函數，後續僅僅只會渲染更改過的 DOM 節點。這在 React 中是不可能做到的，React 是基於視圖驅動的，狀態改變會重新執行整個渲染函數，並且 React 完全無法識別狀態是如何被使用的，開發者甚至可以通過下面的代碼來實現 React 的重新渲染。</p><pre><code class="language-js">const [, forceRender] = useReducer((s) =&gt; s + 1, 0);
</code></pre><p>除了更新粒度細之外，使用 Signals 的框架心智模型也更加簡單。其中最大的特點是：開發者完全不必在意狀態在哪定義，也不在意對應狀態在哪渲染。如下所示：</p><pre><code class="language-js">import { createSignal } from "solid-js";

// 把狀態從過組件中提取出來
const [count, setCount] = createSignal(0);
const [count2] = createSignal(666);

setInterval(() =&gt; {
  setCount((c) =&gt; c + 1);
}, 1000);

// 子組件依然可以使用 count 函數
const SubCountingComponent = () =&gt; {
  return &lt;div&gt;{count()}&lt;/div&gt;;
};

const CountingComponent = () =&gt; {
  return (
    &lt;div&gt;
      &lt;div&gt;
        count: {count()}
        {console.log("count is", count())}
      &lt;/div&gt;
      &lt;div&gt;
        count2: {count2()}
        {console.log("count2 is", count2())}
      &lt;/div&gt;
      &lt;SubCountingComponent /&gt;
    &lt;/div&gt;
  );
};
</code></pre><p>上述代碼依然可以正常運行。因為它是基於狀態驅動的。開發者在組件內使用 Signal 是本地狀態，在組件外定義 Signal 就是全局狀態。</p><p>Signals 本身不是那麼有價值，但結合派生狀態以及副作用就不一樣了。代碼如下所示：</p><pre><code class="language-js">import {
  createSignal,
  onCleanup,
  createMemo,
  createEffect,
  onMount,
} from "solid-js";

const [count, setCount] = createSignal(0);

setInterval(() =&gt; {
  setCount((c) =&gt; c + 1);
}, 1000);

// 計算緩存
const doubleCount = createMemo(() =&gt; count() * 2);

// 基於當前緩存
const quadrupleCount = createMemo(() =&gt; doubleCount() * 2);

// 副作用
createEffect(() =&gt; {
  // 在 count 變化時重新執行 fetch
  fetch(`/api/${count()}`);
});

const CountingComponent = () =&gt; {
  // 掛載組件時執行
  onMount(() =&gt; {
    console.log("start");
  });

  // 銷燬組件時執行
  onCleanup(() =&gt; {
    console.log("end");
  });

  return (
    &lt;div&gt;
      &lt;div&gt;Count value is {count()}&lt;/div&gt;
      &lt;div&gt;doubleCount value is {doubleCount()}&lt;/div&gt;
      &lt;div&gt;quadrupleCount value is {quadrupleCount()}&lt;/div&gt;
    &lt;/div&gt;
  );
};
</code></pre><p>從上述代碼可以看到，派生狀態和副作用都不需要像 React 一樣填寫依賴項，同時也將副作用與生命週期分開 (代碼更好閲讀)。</p><h2>實現機制</h2><p>細粒度，高性能，同時還沒有什麼限制。不愧被譽為前端框架的未來。那麼它究竟是如何實現的呢？</p><p>本質上，Signals 是一個在訪問時跟蹤依賴、在變更時觸發副作用的值容器。</p><p>這種基於響應性基礎類型的範式在前端領域並不是一個特別新的概念：它可以追溯到十多年前的 Knockout observables 和 Meteor Tracker 等實現。Vue 的選項式 API 也是同樣的原則，只不過將基礎類型這部分隱藏在了對象屬性背後。依靠這種範式，Vue2 基本不需要優化就有非常不錯的性能。</p><h3>依賴收集</h3><p>React useState 返回當前狀態和設置值函數，而 Solid 的 createSignal 返回兩個函數。即：</p><pre><code class="language-TypeScript">type useState = (initial: any) =&gt; [state, setter];

type createSignal = (initial: any) =&gt; [getter, setter];
</code></pre><p>為什麼 createSignal 要傳遞 getter 方法而不是直接傳遞對應的 state 值呢？這是因為框架為了具備響應能力，Signal 必須要收集誰對它的值感興趣。僅僅傳遞狀態是無法提供 Signal 任何信息的。而 getter 方法不但返回對應的數值，同時執行時創建一個訂閲，以便收集所有依賴信息。</p><h3>模版編譯</h3><p>要保證 Signals 框架的高性能，就不得不結合模版編譯實現該功能，框架開發者通過模版編譯實現動靜分離，配合依賴收集，就可以做到狀態變量變化時點對點的 DOM 更新。所以目前主流的 Signals 框架沒有使用虛擬 DOM。而基於虛擬 DOM 的 Vue 目前依靠編譯器來實現類似的優化。</p><p>下面我們先看看 Solid 的模版編譯：</p><pre><code class="language-js">const CountingComponent = () =&gt; {
  const [count, setCount] = createSignal(0);
  const interval = setInterval(() =&gt; {
    setCount((c) =&gt; c + 1);
  }, 1000);

  onCleanup(() =&gt; clearInterval(interval));
  return &lt;div&gt;Count value is {count()}&lt;/div&gt;;
};
</code></pre><p>對應編譯後的的組件代碼。</p><pre><code class="language-js">const _tmpl$ = /*#__PURE__*/ _$template(`&lt;div&gt;Count value is `);

const CountingComponent = () =&gt; {
  const [count, setCount] = createSignal(0);
  const interval = setInterval(() =&gt; {
    setCount((c) =&gt; c + 1);
  }, 1000);

  onCleanup(() =&gt; clearInterval(interval));
  return (() =&gt; {
    const _el$ = _tmpl$(),
      _el$2 = _el$.firstChild;
    _$insert(_el$, count, null);
    return _el$;
  })();
};
</code></pre><ul><li>執行 _tmpl$ 函數，獲取對應組件的靜態模版</li><li>提取組件中的 count 函數，通過 _$insert 將狀態函數和對應模版位置進行綁定</li><li>調用 setCount 函數更新時，比對一下對應的 count，然後修改對應的 _el$ 對應數據</li></ul><h2>其他</h2><p>大家可以看一看使用 Signals 的主流框架：</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.vuejs.org%2Fapi%2Freactivity-core.html%23ref" target="_blank">Vue Ref</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fangular.io%2Fguide%2Fsignals" target="_blank">Angular Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpreactjs.com%2Fguide%2Fv10%2Fsignals%2F" target="_blank">Preact Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.solidjs.com%2Fdocs%2Flatest%2Fapi%23createsignal" target="_blank">Solid Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwik.builder.io%2Fdocs%2Fcomponents%2Fstate%2F%23usesignal" target="_blank">Qwik Signals</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsvelte.dev%2Fblog%2Frunes" target="_blank">Svelte 5(即將推出)</a></li></ul><p>不過目前來看 React 團隊可能不會使用 Signals。</p><ul><li>Signals 性能很好，但不是編寫 UI 代碼的好方式</li><li>計劃通過編譯器來提升性能</li><li>可能會添加類似 Signals 的原語</li></ul><p>PREACT 作者編寫了 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2F%40preact%2Fsignals-react" target="_blank">@preact/signals-react </a> 為 React 提供了 Signals。不過個人不建議在生產環境使用。</p><p>篇幅有限，後續個人會解讀 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2F%40preact%2Fsignals-core" target="_blank">@preact/signals-core</a> 的源碼。</p><h2>參考資料</h2><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7137100589208436743%3FsearchId%3D2023100323265799EF4CF92C95049F6276" target="_blank">精讀《SolidJS》</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.solidjs.com%2F" target="_blank">Solid.js</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsvelte.dev%2Fblog%2Frunes" target="_blank">Introducing runes</a></p></li></ul><h2>鼓勵一下</h2><p>如果你覺得這篇文章不錯，希望可以給與我一些鼓勵，在我的 github 博客下幫忙 star 一下。</p><p><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwsafight%2FpersonBlog" target="_blank">博客地址</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 06:52:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/wsafight/blog/10115779</guid>
            <link>https://my.oschina.net/wsafight/blog/10115779</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[兩行代碼解決大語言模型對話侷限！港中文賈佳亞團隊聯合 MIT 發佈超長文本擴展技術]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">中途迷失、模型偷懶、上下文越長大模型越笨......如果體驗過大語言模型產品,用戶多少會對文本輸入長度帶來的限制有所感觸，比如當想和大模型討論一些稍長的內容，需要拆分輸入，而前面輸入的要點，很快就會被大模型忘記。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">這是典型的大語言模型對話缺陷！就像先天有注意力缺陷的兒童，難以專注看完一本新書。而缺陷的關鍵，在於模型缺乏長文本處理能力。這個局面如今被打破。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">近日，賈佳亞團隊聯合 MIT 發佈的新技術和新模型悄然登上各大開源網站的熱榜：hugging face 熱榜第一、paperwithcode 熱度第一，Github 全部 python 項目熱度第五、github stars 一週內破千，Twitter 上的相關技術帖子瀏覽量近 18 萬......</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p7.itc.cn/q_70/images01/20231009/02802a3fa205413abde6f1ea42885d02.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">github stars 已達 1.3k</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p5.itc.cn/q_70/images01/20231009/598154ce3152480c8164e0cfab8efabb.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">Twitter 上的相關技術帖子瀏覽量近 18 萬</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">這項名為 LongLoRA 的技術實用但卻簡單得令人驚訝：只需兩行代碼、一台 8 卡 A100 機器，便可將 7B 模型的文本長度拓展到 100k tokens，70B 模型的文本長度拓展到 32k tokens；同時，該研究團隊還發布了首個擁有 70B 參數量的長文本對話大語言模型 LongAlpaca。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><strong>全球首個 70B 長文本大語言模型發佈</strong></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">LongLoRA 的提出，讓全球大語言模型的對話缺陷第一次得到解決，自此，幾十頁的論文、幾百頁的報告、鴻篇鉅製不再成為大模型盲區。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">對此，有專業人士激動地表示，LongLoRA 是大語言模型迷宮中的希望之燈！它代表着業界對長文本大語言模型的重新思考和關注，有效擴展了大語言模型的上下文窗口，允許模型考慮和處理較長的文本序列，是大語言模型的革新性發明。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p9.itc.cn/q_70/images01/20231009/cbe10d2967664215bffee1abef01d462.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">除了技術革新外，大語言模型處理長文本問題的一大難點還在於缺少公開的長文本對話數據。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">為此，研究團隊特意收集了 9k 條長文本問答語料對，包含針對名著、論文、深度報道甚至財務報表的各類問答。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">光會回答長問題還不夠，該團隊又挑選了 3k 的短問答語料與 9K 的長問答語料混合訓練，讓長文本大模型同時具備短文本對話能力。這個完整的數據集被稱為 LongAlpaca-12k，目前已經開源。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在 LongAlpaca-12k 數據集基礎上，研究團隊對不同參數大小 7B、13B、70B 進行了訓練和評測，開源模型包括 LongAlpaca-7B, LongAlpaca-13B 和 LongAlpaca-70B。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><strong>看小説、改論文、指點經濟堪稱全能王</strong></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">話不多説，盲選幾個 demo,一起看看應用了 LongLoRA 技術疊加 12K 問答語料的大模型 LongAlpaca 效果。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p3.itc.cn/q_70/images01/20231009/e0807c4fbd0e428da6cc72b9e4c566dc.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">讓系統新讀一篇論文，並根據 ICLR 的審查指南，對其提出修改意見，從而提升該論文的接收率。LongAlpaca 的意見是：通過更精確地闡明新穎性，提供更嚴格和更有對比性的實驗結果 (包括具體的數據集和指標)、更廣泛的應用和未來發展方向，重點呈現關鍵貢獻和影響，論文被接受的機會將得到提高。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p3.itc.cn/q_70/images01/20231009/783214e5577d4580a8f89721e98f148e.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">現在，讓系統讀兩篇新的不同的論文，讓 LongAlpaca 概括 ICLR 和 CVPR 兩個會議之間的風格區別。LongAlpaca 總結認為，CVPR 論文傾向更具結構性和實驗性的風格，專注於實用性和技術性。而 ICLR 的論文風格更加靈活，側重關鍵的理論分析和數學推導，而非標準格式。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">可以看出，經過訓練的 LongAlpaca 模型已經可以很輕鬆地接受新的長篇學術論文，在學術相關問題的回答上相當精準。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">接下來，再看看 LongAlpaca 模型在頗高閲讀和理解門檻的經濟領域的解讀表現。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p3.itc.cn/q_70/images01/20231009/e6eb1abcb4944627935707701425aa11.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p5.itc.cn/q_70/images01/20231009/a6f419f9eb03497e9aa357e147b61085.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">根據國際貨幣基金組織從 2012 年到 2023 年的全球經濟展望的概述合集，對經濟形勢進行逐年總結以及對未來經濟趨勢進行預測。LongAlpaca 告訴我們，2023 年全球經濟形勢不明朗，跟 2022 年相比，增長預計放緩;未來幾年，全球經濟擴張速度偏溫和並將低於預期，而地緣政治緊張、金融市場波動等大的挑戰依然存在，需通過多邊合作和結構性改革小心應對。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">LongAlpaca 還可以讀新的長篇小説，讀完後對內容進行分析。下面選取的對比模型是 13B 參數的 LongAlpaca 和 Llama2，且看各自表現。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p1.itc.cn/q_70/images01/20231009/72aeb31905df4635a8f3001fced32892.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">名著《西遊記》中，為什麼孫悟空在大鬧天宮時很厲害，但取，經路上卻屢屢受挫?LongAlpaca 給出了 5 點原因，大概可總結為 「孫悟空的不成熟、強大的對手、力量的限制、敵人的欺騙、最初，缺少同伴等因素導致了他在旅途中的失敗。但隨着時間推移，他獲，得了智慧、經驗和戰友，使他最終戰勝了最強大的敵人。」</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">而 Llama2 的回答較為簡單。「雖然他確實大鬧天宮，但説他代表着不敗的力量並不一定準確。事實上，他最終在西遊記中被強大的唐三藏打敗。」Llama2 沒有給出正確答案，並且還提出需要更多的內容信息。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p0.itc.cn/q_70/images01/20231009/a29c650d3a144a18afaf5e7b4d374559.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">這一次讓系統新讀一次《三體》，然後問第一部中，葉文潔為什麼要聯繫外星人，而後期又為什麼後悔？LongAlpaca 認為，葉文潔最初接觸外星人是出於理想主義和復仇，但隨着時間的推移，她對人類的看法發生了變化，意識到自己可能給全人類帶來的危險，她的悔恨與日俱增。回答得十分清晰。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">而 Llama2 的回答則是，「通過與外星人的互動，她希望能更深入地瞭解宇宙的本質，以及自己在宇宙中的位置。葉文潔逐漸意識到，外星人和他們的技術並不能解決她的問題。」回答籠統，之後開始對小説整體進行評論，答非所問。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">從模型給出的答案可發現，一些模型如 Llama2 [2] 可能在預訓練過程中見過相關小説，但如果在提問時進行僅根據小説題目進行短文本提問的話，回答並不理想。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">兩個模型的回答對比，高下立見。LongAlpaca 改學術論文、點評全球經濟大勢和讀小説，都是一把好手，完勝 Llama2。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><strong>兩行代碼和三個關鍵結論</strong></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">Llama2 可以説是 AI 社區內最強大的開源大模型之一，行業位置領先，LongAlpaca 居然可以完勝。其背後的 LongLoRA 技術成功引起網友們的注意，到底是怎麼做到的？</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">原來大語言模型對長文本處理過程中，計算量的主要開銷集中在自注意力機制 (self-attention)，其開銷隨着文本長度成平方次地增加。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">針對這個問題，研究團隊提出 LongLoRA 技術，並用分組和偏移的方式來對全局自注意力機制進行模擬。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p0.itc.cn/q_70/images01/20231009/e9c924b5c8564afa9f24a208a98eeb8c.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">簡單來説，就是將長文本對應的 tokens 拆分成不同的組，在每組內部做自注意力計算，而分組的方式在不同注意力頭 (attention head) 上有所偏移。這樣的方式既可以大幅度節約計算量，又可以維持全局感受野的傳遞。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">而這個實現方法也非常簡潔，僅兩行代碼即可完成！</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p9.itc.cn/q_70/images01/20231009/096cdf76e3394df796ed04057a1cb6c2.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">LongLoRA 還探索了低秩訓練的方式。原有的低秩訓練方式，如 LoRA [5]，無法在文本長度遷移上取得良好的效果。而 LongLoRA 在低秩訓練的基礎上，引入嵌入層 (Embedding layer 和 Normalization layers) 進行微調，從而達到可以和全參數微調 (Full fine-tune) 逼近的效果。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em"><img src="https://p7.itc.cn/q_70/images01/20231009/c684b6990a394aacb2859a1f064e09b9.png" referrerpolicy="no-referrer"></p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">進行不同長度文本擴展和訓練時，LongLoRA、LoRA 和全參數微調不同技術的具體效果如何，可以參考三個維度表現：</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在 Perplexity-困惑度上，原有 LoRA 方法的性能在不斷惡化，而 LongLoRA 和全參數微調都能在各種文本長度下維持很好的效果；</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在顯存消耗上，相比於全參數微調，LongLoRA 和原有 LoRA 都有大幅度的節省。例如，對於 8k 長度的模型訓練，相比於全參數微調，LongLoRA 將顯存消耗從 46.3GB 降低到 25.6GB；</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">在訓練時間上，對於 64k 長度的模型訓練，相比於常規 LoRA，LongLoRA 將訓練時間從 90～100 小時左右降低到 52.4 小時，而全參數微調超過 1000 小時。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">極簡的訓練方法、極少的計算資源和時間消耗，以及極佳的準確性，令 LongLoRA 大規模推廣成為可能。目前，相關技術與模型已全部開源，感興趣的用戶們可以自己部署感受。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">值得一提的是，這是賈佳亞團隊繼 8 月 9 日發佈的「可以分割一切」的多模態大模型 LISA 後的又一力作。相距不過短短兩個月，不得不説，這研究速度和能力跟 LongLoRA 一樣驚人。</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">代碼和 Demo 地址：https://github.com/dvlab-research/LongLoRA</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">論文地址：https://arxiv.org/pdf/2309.12307.pdf</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">參考文獻</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[1] LLaMA team. Llama: Open and efficient foundation language models. Arxiv, 2302.13971, 2023a.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[2] Llama2 team. Llama 2: Open foundation and fine-tuned chat models. Arxiv, 2307.09288, 2023b.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[3] Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending context window of large language models via positional interpolation. Arxiv, 2306.15595, 2023.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[4] Szymon Tworkowski, Konrad Staniszewski, Mikolaj Pacek, Yuhuai Wu, Henryk Michalewski, and Piotr Milos. Focused transformer: Contrastive training for context scaling. Arxiv, 2307.03170, 2023.</p><p style="color:#191919; margin-left:1.8em; margin-right:0.63em">[5] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. In ICLR, 2022.</p><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 05:26:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260968</guid>
            <link>https://www.oschina.net/news/260968</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[百度加緊訓練文心大模型 4.0，或將於 10 月 17 日發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>據科創板日報報道，百度正在加緊訓練文心大模型 4.0，或將在 10 月 17 日百度世界大會上發佈。</p><p>據消息人士透露，文心大模型 4.0 的進展比預期快很多，將是基礎模型的大升級，<strong>理解、生成、邏輯、記憶</strong>四大核心能力都將提升，尤其在邏輯推理、代碼和數學等方面提升最明顯。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-741c4810e55393b362a8f9a60b8c98a65dd.png" referrerpolicy="no-referrer"></p><p>今年 8 月，<a href="https://www.oschina.net/news/256156" target="_blank">百度宣佈文心一言率先向全社會全面開放</a>，所有用戶都能下載文心一言 App 或在官網體驗。</p><hr><p>延伸閲讀：<a href="https://www.oschina.net/news/256949">挑戰 ChatGPT，國產有這 8 款 AI 大模型產品</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 09 Oct 2023 04:11:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/260957</guid>
            <link>https://www.oschina.net/news/260957</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
