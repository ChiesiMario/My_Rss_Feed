<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 06 Nov 2023 08:03:14 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | VS Code 史上呼聲最高的特性終於實現；vivo 發佈自研操作系統藍河 (BlueOS)....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2023.10.31-2023.11.05]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 07:13:11 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649093933&#38;idx=1&#38;sn=8301a6849e75bd3af871ad1ba8be69c6&#38;chksm=880c4c3ebf7bc528a87ed1f4ad9a829884fb2d5ddf518c660d6024621d43431d81bccc469648&#38;token=1816704803&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[龍芯 3A6000 國產桌面處理器本月底發佈，對標英特爾 10 代酷睿]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在今日的龍芯中科 2023 年第三季度業績説明會上，龍芯中科宣佈&nbsp;3A6000 國產桌面處理器初步定於<strong>11 月 28 日發佈</strong>。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-033f0723def37a98686c0268285f4fe7284.png" referrerpolicy="no-referrer"></p><p>龍芯 3A6000 是基於龍架構的新一代四核處理器，於今年 8 月流片成功。綜合相關測試結果，<strong>龍芯 3A6000 處理器總體性能與英特爾公司 2020 年上市的第 10 代酷睿四核處理器相當</strong>，因此也是不少國內用戶期待的一款高性能國產處理器。</p><p>龍芯中科在業績説明會上透露，龍芯 3A6000 將於 11 月底正式發佈（初步定於 11 月 28 日），<strong>十幾家整機 / ODM 企業將發佈其整機產品</strong>。</p><p>在談到後續產品龍芯 3B6000 時，龍芯中科董事長、總經理胡偉武表示：「龍芯走的是提高效率路線，爭取每 GHz 性能接近或達到蘋果 CPU 的水平。<strong>3B6000 爭取每 GHz 的性能再提高 20%-30%</strong>，在此基礎上再用先進工藝提高主頻，這時候龍芯 CPU 性能就處於世界領先行列了。當然，我們也會努力提高 3B6000 的主頻。」</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 06 Nov 2023 06:48:46 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265161</guid>
            <link>https://www.oschina.net/news/265161</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[李開復旗下 AI 公司發佈 Yi 系列開源大模型，估值超 10 億美元]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>創新工場董事長兼 CEO 李開復於今年創辦了 AI 大模型創業公司「<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.01.ai%2F" target="_blank">零一萬物</a></u>」。<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2506227176630145" target="_blank">根據 36 氪的獨家報道</a></u>，零一萬物已完成新一輪融資，由阿里雲領投。目前，<strong>零一萬物估值已超 10 億美元，躋身獨角獸行列</strong>。</p><p><strong>該公司已推出&nbsp;Yi-34B 和&nbsp;Yi-6B 兩個開源大模型</strong>，號稱對學術研究完全開放，同步開放免費商用申請。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-4ab5886e43554fd3233305e7c8264217507.png" referrerpolicy="no-referrer"></p><blockquote><p>Hugging Face：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-34B" target="_blank">https://huggingface.co/01-ai/Yi-34B</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-6B" target="_blank">https://huggingface.co/01-ai/Yi-6B</a></p><p>ModelScope：<br> [1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-34B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-34B/summary</a><br> [2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.modelscope.cn%2Fmodels%2F01ai%2FYi-6B%2Fsummary" target="_blank">https://www.modelscope.cn/models/01ai/Yi-6B/summary</a></p><p>GitHub：<br><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F01-ai%2FYi" target="_blank">https://github.com/01-ai/Yi</a></p></blockquote><p><span>據介紹，Yi 目前擁有 200K 上下文窗口，可處理約 40 萬字的文本——這也是目前全球大模型中最長的上下文窗口。其中 Yi-34B 在 Hugging Face 英文測試榜單中位列第一，在 C-Eval 中文能力排行榜中超越所有開源模型。</span></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-0e1c843e9962b9e9aecc13487da3270520c.png" referrerpolicy="no-referrer"><br><em>Hugging Face Open LLM Leaderboard (pretrained) 大模型排行榜，Yi-34B 高居榜首 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-03d63eae8034e7ca5d0e28148b2fb94dc3f.png" referrerpolicy="no-referrer"><br><em>C-Eval 排行榜:公開訪問的模型，Yi-34B 全球第一 (2023 年 11 月 5 日)</em></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-3e5919449029e62b8bf111322f96af0dcb3.png" referrerpolicy="no-referrer"></p><p>Yi-34B 和 Yi-6B 的表現：</p><ul><li><strong>C-Eval 中文能力排行榜</strong>：Yi-34B 在 C-Eval 中文能力排行榜上超越了所有開源模型，這意味着在中文語言理解和生成方面，Yi-34B 的性能優於其他所有開源的大模型。</li><li><strong>中文綜合能力</strong>：在 CMMLU、E-Eval、Gaokao 等中文評測指標上，Yi-34B 明顯領先於 GPT-4，展現了其在中文語境下的強大理解和應用能力。</li><li><strong>中文問答能力</strong>：在 BooIQ、OBQA 兩個中文問答指標上，Yi-6B 和 Yi-34B 與 GPT-4 的表現水平相當，這表明它們在理解中文問題和提供準確答案方面具有很高的能力。</li><li><strong>超長文本處理</strong>：200K 上下文窗口，Yi-34B 能夠處理大約 40 萬漢字的超長文本輸入，這在處理長篇中文文檔、書籍或報告時尤為重要，能夠理解和生成連貫、準確的中文文本。</li><li><strong>技術創新</strong>：零一萬物自研規模化訓練實驗平台和智能數據處理管線。強大的 AI 基礎設施支持，提高了訓練效率和降低了成本。</li></ul><p>「零一萬物」在官網寫道，他們深信「以大語言模型為突破的 AI 2.0 正在掀起技術、平台到應用多個層面的革命」。根據他們的判斷，AI 2.0 時代將誕生「比移動互聯網大十倍的平台機會」，將把既有的軟件、使用界面和應用重寫一次，改寫用戶的交互和入口。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 05:43:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</guid>
            <link>https://www.oschina.net/news/265142/01-ai-valued-at-1b-open-source-yi-llm</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[承載微軟跨平台生態之夢的 UWP，正在消亡]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>開發者發現，微軟最新的 Windows&nbsp;11&nbsp;Canary Build 25987 預覽版已經開始提供兩個版本的 XAML Shell 服務，<strong>新的版本直接基於 Win32 + XAML</strong>，曾經被寄予厚望的 UWP 在新版本里已經不見蹤影。</p><blockquote><p><img src="https://static.oschina.net/uploads/space/2023/1106/113836_8gF1_2720166.png" referrerpolicy="no-referrer"></p><p>via&nbsp;<u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Fthebookisclosed%2Fstatus%2F1720108362275213594" target="_blank">https://twitter.com/thebookisclosed/status/1720108362275213594</a></em></u></p></blockquote><p>據介紹，新增的 dll 名為 ControlCenter.dll，這是控制中心的文件，目前已經同時提供舊版本和新的基於 Win32+XAML 的版本，即用戶可以通過 ViveTool 啓用這種新變體。</p><p>一般來説能被發現已經可以通過 ViveTool 啓用，那麼這個新變化基本已經開發完畢，後續就會分別面向不同的用戶進行測試，收集運行數據。</p><p>延伸閲讀</p><ul><li><strong><a href="https://www.oschina.net/news/165300/ms-officially-deprecates-uwp">微軟正式棄用 UWP</a></strong></li><li><strong><a href="https://www.oschina.net/news/149997/winui-3-uwp-win32-apps-windows11">WinUI 3 仍專注於 Win32 應用，暫無面向 UWP 的計劃</a></strong></li><li><strong><a href="https://www.oschina.net/news/107123/microsofts-uwp-app-dream-is-dead">Win32 應用進入微軟應用商店，UWP 怎麼辦？</a></strong></li><li><strong><a href="https://www.oschina.net/news/149797/ms-store-xmal">Microsoft Store 完全使用 XAML 以替代 HTML，Visual Studio 預計年底上架商店</a></strong></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265128</guid>
            <link>https://www.oschina.net/news/265128</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國內最大開源模型發佈，650 億參數無條件免費商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">元象 XVERSE 公司宣佈開源 650 億參數高性能通用大模型 XVERSE-65B，無條件免費商用。</span></p><p><span style="color:#000000">XVERSE-65B 採用了 Transformer 網絡結構，模型通過訓練了 2.6 萬億個令牌的高質量多樣化數據，包含了 40 多種語言。具有 16K 的上下文長度，適用於多輪對話、知識問答和摘要等任務。</span></p><p><span style="color:#000000">主要特點如下:</span></p><ul><li><span style="color:#000000"><strong>模型結構</strong>：XVERSE-65B 使用主流 Decoder-only 的標準 Transformer 網絡結構，支持 16K 的上下文長度（Context Length），能滿足更長的多輪對話、知識問答與摘要等需求，模型應用場景更廣泛。</span></li><li><span style="color:#000000"><strong>訓練數據</strong>：構建了 2.6 萬億 token 的高質量、多樣化的數據對模型進行充分訓練，包含中、英、俄、西等 40 多種語言，通過精細化設置不同類型數據的採樣比例，使得中英兩種語言表現優異，也能兼顧其他語言效果。</span></li><li><span style="color:#000000"><strong>分詞</strong>：基於 BPE（Byte-Pair Encoding）算法，使用上百 GB 語料訓練了一個詞表大小為 100,534 的分詞器，能夠同時支持多語言，而無需額外擴展詞表。</span></li><li><span style="color:#000000"><strong>訓練框架</strong>：訓練中採用 FlashAttention2 加速計算，3D 並行基礎上採用虛擬流水線（virtual pipeline）技術，降低較長流水線和 16k 上下文窗口產生的過高氣泡率，在千卡集羣的峯值算力利用率達到業界前列。同時通過集羣基礎設施運營、資源調度、訓練框架和調度平台協同等持續優化，打造出高穩定、低中斷、強容錯的訓練系統，將每週有效訓練率提升至 98.6%。</span></li></ul><p><span style="color:#000000"><strong>評測結果</strong></span></p><p><span style="color:#000000"><img height="454" src="https://oscimg.oschina.net/oscnet/up-2cd1eb2bb0579c1ae7d9b7cdba455e38df6.png" width="500" referrerpolicy="no-referrer">&nbsp;</span></p><blockquote><p><span style="color:#000000">元象 XVERSE 於 2021 年初在深圳成立，主營 AI 與 3D 技術，創始人姚星是前騰訊副總裁和騰訊 AI Lab 創始人。該公司目前累計融資金額超過 2 億美元，投資機構包括騰訊、高榕資本、五源資本、高瓴創投、紅杉中國、淡馬錫和 CPE 源峯等。</span></p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265120</guid>
            <link>https://www.oschina.net/news/265120</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[螞蟻集團百靈大模型通過備案，採用 Transfromer 架構]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 6 日，<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jiemian.com%2Farticle%2F10342101_sina.html" target="_blank">界面新聞從螞蟻集團獲悉</a></u>，根據國家七部委聯合公佈的《生成式人工智能服務管理暫行辦法》指導要求，螞蟻百靈大模型已完成備案，基於百靈大模型的多款產品已陸續完成內測，將向公眾開放。</p><p>本次通過備案的是<strong>螞蟻百靈語言大模型，該大模型採用 Transfromer 架構</strong>，基於萬億級 Token 語料訓練而成，支持窗口長度達 32K。</p><p>目前，螞蟻大模型已形成包括大模型底層基礎設施、基礎大模型、行業大模型、應用產品在內的完整技術鏈條。</p><p>在基礎大模型層面，除了本次通過備案的百靈語言大模型，螞蟻集團也在研發百靈多模態大模型，並已內測。</p><blockquote><p><a href="https://www.oschina.net/news/257409/codefuse-ai" target="_blank">螞蟻集團正式開源 CodeFuse 代碼大模型</a><br><a href="https://www.oschina.net/news/246241" target="_blank">螞蟻集團證實正研發語言和多模態大模型，命名「貞儀」</a></p></blockquote><p>國內第二批通過備案的 AI 大模型包括 11 家公司，部分已面向全社會開放服務。加上首批的 10&nbsp;餘個大模型，目前已有超過 20&nbsp;個大模型獲得備案。</p><p>新一批備案名單包括：網易有道（「子曰」大模型）、螞蟻集團（百靈大模型）、面壁智能（「面壁露卡 Luca」）、出門問問（「序列猴子」）、崑崙萬維（「天工」大模型）、美團（模型）、知乎（「知海圖 AI」模型）、月之暗面（moonshot）、金山辦公（WPS AI）、好未來（MathGPT 大模型）等。</p><p>8 月 31 日首批通過備案的 AI&nbsp;大模型包括百度文心一言、百川智能、商湯商量 SenseChat、抖音（雲雀大模型）、智譜 AI（GLM 大模型）、中科院（紫東太初大模型）、上海 MiniMax（ABAB 大模型）、上海人工智能實驗室（書生通用大模型）、「360 智腦」等等。</p><blockquote><p><a href="https://www.oschina.net/news/256949" target="_blank">挑戰 ChatGPT，國產有這 8 款 AI 大模型產品</a></p></blockquote><p>據悉，今年 8 月 15 日正式施行的《生成式人工智能服務管理暫行辦法》 ，提供具有輿論屬性或者社會動員能力的生成式人工智能服務的，應當按照國家有關規定開展安全評估，並按照《互聯網信息服務算法推薦管理規定》履行算法備案和變更、註銷備案手續。</p></div>
                                    ]]>
            </description>
            <pubDate>Sun, 05 Nov 2023 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265114</guid>
            <link>https://www.oschina.net/news/265114</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[DHorse 即將支持更多的登錄方式]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>現狀</h2><p>在 v1.4.0 版本之前，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F512team%2Fdhorse" target="_blank">DHorse</a>支持的登錄方式有：DHorse 系統本身、Ldap 兩種；但是，既然作為企業級服務，只支持以上兩種方式是不夠的。當下，越來越多的企業使用釘釘和企業微信進行溝通和辦公，支持這兩種登錄方式也勢在必行，此外，還有傳統的 SSO 登錄，在未來的 v1.5.0 的版本里即將支持以上登錄方式。</p><p>下面，簡單介紹一下即將支持的這三種登錄方式。</p><h3>釘釘登錄</h3><p>開啓釘釘登錄，需要具備以下幾個條件：</p><ul><li>需要擁有釘釘後台的管理權限；</li><li>需要創建釘釘應用；</li><li>需要進行 DHorse 的釘釘配置；</li></ul><h3>企業微信登錄</h3><p>開啓企業微信登錄，需要具備以下幾個條件：</p><ul><li>需要擁有企業微信的後台管理權限；</li><li>需要創建企業微信的應用；</li><li>需要配置 DHorse 的企業微信；</li></ul><h3>SSO 登錄</h3><p>CAS 是 SSO 登錄的主流實現者，DHorse 也使用 CAS 登錄來實現 SSO 登錄的功能；</p><p>開啓 SSO 登錄，需要具備以下幾個條件：</p><ul><li>需要企業提供自己的 CAS 服務；</li><li>需要配置 DHorse 的 CAS 登錄；</li></ul><h2>結論</h2><p>為了更好的與企業管理員工方式的多樣性相結合，簡化企業管理，支持儘可能多的登錄方式勢在必行。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 06:27:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265154</guid>
            <link>https://www.oschina.net/news/265154</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenELA 公開發布 Enterprise Linux 源代碼]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#000000">Open Enterprise Linux Association (OpenELA)</span><span style="color:#000000"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenela.org%2Fnews%2F2023.11.02-governance_and_code_availability%2F" target="_blank">宣佈</a>公開發布 Enterprise Linux (EL) 源代碼併成立技術指導委員會。</span></p><blockquote><p><span style="color:#000000">「OpenELA 很高興地宣佈，現在所有人都可以獲取構建衍生&nbsp;Enterprise Linux 操作系統所需的全部源代碼包。初步側重點在於 EL8 和 EL9，EL7 的軟件包也即將推出。該項目致力於確保向社區無限期提供 EL 源代碼。」</span></p></blockquote><p><img alt="" height="381" src="https://oscimg.oschina.net/oscnet/up-08878f094d1e8bcafadeca1ea19e8f93ccc.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenELA 是在今年 8 月份，由甲骨文、SUSE 和 CIQ (Rocky Linux 背後的商業實體) 聯合組建的一個開源企業 Linux 發行版開發商的行業協會；旨在通過提供開放和免費的 Enterprise Linux 源代碼，鼓勵<span style="background-color:#ffffff">與 Red Hat Enterprise Linux (RHEL) 兼容的發行版的開發和協作</span>。</span><span style="background-color:#ffffff; color:#000000">OpenELA 的形成源於紅帽</span><a href="https://www.oschina.net/news/246331/red-hat-centos-stream-sources">對 RHEL 源代碼可用性的更改</a><span style="background-color:#ffffff; color:#000000">。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Oracle、SUSE 和 CIQ&nbsp;方面都表達了對這一進展的喜悅之情。CIQ 首席執行官兼 Rocky Linux 創始人 Gregory Kurtzer 發言稱：</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「幾十年來，各組織都在 CentOS 上進行標準化，因為它是免費的，遵循 Enterprise Linux 標準，並且得到許多供應商的大力支持。CentOS 停產後，不僅在生態系統中留下了一個巨大的漏洞，而且也清楚地表明瞭社區需要團結起來才能做得更好。OpenELA 正是這樣的一個社區答案，它將確保所有專業 IT 部門和企業用例擁有一個協作和穩定的未來。」</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">AlmaLinux 尚未加入該協會。AlmaLinux 操作系統基金會主席 benny Vasquez 評論表示，「</span></span><span style="background-color:#ffffff; color:#000000">我總是很樂於看到一個新的非營利組織站穩腳跟並開始</span><span style="color:#000000"><span style="background-color:#ffffff">運作。不過我們目前還不會使用他們發佈的代碼，因為我們已經建立了自己的工作流程，不需要使用這些代碼。」</span></span></p><p><span style="color:#000000">OpenELA&nbsp;已經<span style="background-color:#ffffff">完成了在美國特拉華州的非營利性非股份公司的註冊，正在向美國國稅局申請 501(c)(6) 免稅資格。該公司表示，將為有興趣支持開源企業 Linux 發行版開發目標和利益的利益相關者提供一個論壇。「創始公司認為，法律實體是對開源工作產生積極影響的基礎性工具，可以統一開源工作的價值觀，並確保與開源社區的適當接觸。」</span></span></p><p style="margin-left:0; margin-right:0; text-align:start"><span style="color:#000000"><strong>相關閲讀：</strong></span></p><ul><li style="text-align:start"><a href="https://www.oschina.net/news/253319/oracle-suse-ciq-openela" target="_blank">SUSE、甲骨文和 CIQ 組建 OpenELA：企業 Linux 源代碼的社區存儲庫</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 04:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264995/openela-enterprise-linux-source</guid>
            <link>https://www.oschina.net/news/264995/openela-enterprise-linux-source</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenHarmony 4.0 開發數據：華為貢獻者 1800 名、增刪改代碼 8849882 行]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>OpenHarmony <u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW9H8Yyq6-jK-35FnIsafSQ" target="_blank">公佈</a></u>了關於 4.0 Release 版本的開發數據。</p><p>據介紹，<u><a href="https://www.oschina.net/news/264989/openharmony-4-0-released">OpenAtom OpenHarmony 4.0 Release 版本</a></u>於 10 月 27 日發佈，經過了 32 周的開發週期。</p><p>在此期間，有 65499 個 Committs 進入了版本。共有 2220 位貢獻者為 4.0 Release 版本做出了貢獻。其中，華為貢獻者 1800 名，累計 2000+名，共增刪改代碼 8849882 行，佔比 80.03%。</p><p>華為的 5 名頂級貢獻者和華為以外的 15 名頂級貢獻者如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-fb921b7f488f8d9d32c10bfb308ed11d6fe.png" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0">以下的單位參與了 OpenHarmony 4.0 Release 版本的工作，較活躍的如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-baa6184ec3c30845abf2d57faddb063630b.png" referrerpolicy="no-referrer"></p><p>不同單位在不同子系統的貢獻比例：</p><p>華為的貢獻覆蓋 30 多個核心子系統，其他頂級共建單位在各領域的貢獻情況如下：</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-9045d86ad3cdc74208e832cc5a7cc327d37.png" referrerpolicy="no-referrer"></p><p>這些單位對 OpenHarmony 4.0 Release 版本的工作主要集中在以下領域：</p><p>• 深開鴻的工作主要集中在短距，驅動，XTS，開發工具，ArkUI 子系統中，包括藍牙&amp;wifi 增強，ArkUI 運行時，ArkUI 組件增強，NAPI 框架生成工具，ALSA 驅動 HDI 插件平台解耦，codec 驅動 HDI 接口，ArkUI XTS 套件支持，RK3568 開發板等特性。</p><p>• 開鴻智谷的工作主要集中在開發樣例，開發板，輕內核子系統中，包括輕內核 queue 讀寫增強，ArkUI 組件集合樣例，場景化仿應用開發（設備管理，通信，數據庫，相機，語音）和 Niobe 開發板等特性。</p><p>• 軟通動力的工作主要集中在 ArkUI，XTS，開發板子系統中，包括 ArkUI 組件（TextInput，TextTimer，邊框）增強，wpt 套件 Reftest 自動化測試，ArkUI 佈局 XTS 套件，UnionPi Tiger 開發板,揚帆致遠開發板等特性。</p><p>• 九聯科技的工作主要集中在開發樣例，芯片內核驅動，HDF 驅動子系統中，包括溫濕度傳感器驅動，開發樣例（通知，分佈式賬號管理，資源授權訪問，一多交互等場景），A311D 芯片適配，UnionPi Tiger 開發板適配等特性。</p><p>• 潤開鴻的工作主要集中在芯片開發板，ArkUI，驅動子系統中，包括 arkcompiler 中 arraybuffer 功能增強，啓動流程優化，DAYU210 開發板，Neptune100 開發板適配等特性。</p><p>• 誠邁的工作主要在多模輸入子系統中。</p><p>據稱華為、深開鴻、軟通動力、開鴻智谷分別建設超過 5 萬+行代碼並持續貢獻中，成為 2023 年《百人代碼貢獻單位》。九聯開鴻、潤開鴻、京東、誠邁科技、中科院軟件所、中軟國際持續貢獻中，計劃今年 12 月 31 日前貢獻 5 萬+行功能特性代碼。</p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 04:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265135</guid>
            <link>https://www.oschina.net/news/265135</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[馬斯克旗下 xAI 發佈首個 AI 大模型產品 Grok]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">馬斯克旗下 xAI 團隊發佈其首個 AI 大模型產品 —— <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.ai%2F" target="_blank">Grok</a>；目前只訓練了 2 個月左右的時間，因此尚處於非常早期的測試階段。</span></p><blockquote><p><span style="color:#000000">Grok 是一款仿照《銀河系漫遊指南》設計的人工智能，可以回答幾乎任何問題，更難能可貴的是，它甚至可以建議你要問什麼問題！</span></p><p><span style="color:#000000">Grok 在回答問題時略帶詼諧和反叛，因此如果你討厭幽默，請不要使用它！</span></p><p><span style="color:#000000">Grok 的一個獨特且根本的優勢是它可以通過 𝕏 平台實時瞭解世界。它還能回答被大多數其他人工智能系統拒絕的尖鋭問題。</span></p></blockquote><p><img height="316" src="https://oscimg.oschina.net/oscnet/up-95e999fb26b9fab921735913d2139b7577d.jpg" width="300" referrerpolicy="no-referrer"></p><p><img height="388" src="https://oscimg.oschina.net/oscnet/up-c1e26f5d404c988b2332dcab2ffaa7becdc.jpg" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">Grok 基於&nbsp;xAI 團隊於 11 月發佈的自研大語言模型&nbsp;Grok-1。在&nbsp;xAI 宣佈成立後，項目團隊就用 330 億個參數訓練了一個 LLM 原型（Grok-0），這一<span style="background-color:#ffffff">早期模型</span>自稱與 LLaMA 2 (70B) 能力相當，但只使用了一半的訓練資源。</span></p><p><span style="color:#000000">Grok-1 則在此基礎上改進了推理和編碼能力。Grok-1 是一個基於 Transformer 的自迴歸模型，經過預先訓練以執行 next-token 預測。然後利用人類和早期 Grok-0 模型的廣泛反饋對該模型進行微調，初始 Grok-1 的上下文長度為 8192 個 token。</span></p><p><span style="color:#000000">一些評測結果如下所示：</span></p><p><span style="color:#000000"><img height="238" src="https://oscimg.oschina.net/oscnet/up-78c5896454178aea96eb296a0a2beeb7faf.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><img height="96" src="https://oscimg.oschina.net/oscnet/up-ff9e8be5f7abf6322719c422a60352348a7.png" width="700" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">Grok-1 也存在一些侷限性，該語言模型不具備獨立搜索網絡的能力，官方建議在 Grok 中部署搜索工具和數據庫可以增強模型的能力和真實性。並警告稱，儘管可以訪問外部信息源，但該模型仍會產生幻覺。</span></p><p><span style="color:#000000"><span style="background-color:#ffffff">為了創建 Grok，</span>xAI 團隊還<span style="background-color:#ffffff">構建了一個基於 Kubernetes、Rust 和 JAX 的自定義訓練和推理堆棧。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">「</span>Rust 已被證明是構建可擴展、可靠且可維護的基礎架構的理想選擇。它提供高性能、豐富的生態系統，並防止分佈式系統中通常會發現的大多數錯誤。鑑於我們的團隊規模較小，基礎架構的可靠性至關重要，否則維護就會缺乏創新。Rust 讓我們充滿信心，任何代碼修改或重構都可能產生可以在最少監督的情況下運行數月的工作程序。<span style="background-color:#ffffff">」</span></span></p><p><span style="color:#000000">目前&nbsp;<span style="background-color:#ffffff">Grok 僅面向少數美國用戶<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrok.x.ai%2F" target="_blank">開放測試</a>。</span></span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><a href="https://www.oschina.net/news/249159/elonmusk-announced-xai" target="_blank">馬斯克宣佈成立 xAI 公司</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265129/xai-grok</guid>
            <link>https://www.oschina.net/news/265129/xai-grok</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[崑崙萬維「天工」大模型正式向全社會開放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 11 月 3 日，崑崙萬維「天工」大模型通過《生成式人工智能服務管理暫行辦法》備案，面向全社會開放服務！</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>用戶在應用商店下載「天工</span></span><span><span>APP」或登陸「天工官網」（www.tiangong.cn）均可直接註冊使用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>「天工」是國內首個對標</span></span><span><span>ChatGPT 的雙千億級大語言模型，也是一個 AI 搜索引擎，一個對話式 AI 助手。「天工」擁有強大的自然語言處理和智能交互能力，能夠實現個性化 AI 搜索、智能問答、聊天互動、文本生成、編寫代碼、語言翻譯等多種應用場景，並且具有豐富的知識儲備，涵蓋科學、技術、文化、藝術、歷史等領域。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span>&nbsp;<img alt="" height="589" src="https://oscimg.oschina.net/oscnet/up-d32a56bf391efe8f4eb7543b06215352058.png" width="1265" referrerpolicy="no-referrer"></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2022 年 12 月 15 日，崑崙萬維在北京舉行 AIGC 技術發佈會，發佈自研 AIGC 全系列算法與模型，覆蓋了圖像、音樂、文本、編程等多模態的 AI 內容生成能力。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 4 月 17 日，崑崙萬維正式發佈自研千億級大語言模型「天工」，同時宣佈啓動邀請測試。「天工」用過通過自然語言與用戶進行問答式交互，AI 生成能力可滿足文案創作、知識問答、代碼編程、邏輯推演、數理推算等多元化需求。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 5 月 19 日，北京市經濟和信息化局公佈第一批《北京市通用人工智能產業創新夥伴計劃成員名單》。崑崙萬維憑藉在 AIGC 領域的前沿探索和投資佈局，成為第一批模型夥伴和投資夥伴。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 8 月 23 日，崑崙萬維推出國內第一款 AI 搜索產品——「天工 AI 搜索」，並開啓內測申請。「天工 AI 搜索」深度融合 AI 大模型能力，通過人性化、智能化的方式全面提升用戶的搜索體驗，為用戶提供快速、可靠的交互式搜索服務，並集成 AI 對話、AI 寫作等常用功能，幫助用戶提升工作效率，全面重塑中文搜索體驗。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月，崑崙萬維多模態大模型 Skywork-MM 在騰訊優圖實驗室聯合廈門大學開展的多模態大語言模型測評 MME 中，綜合得分排名第一。該評測首次對全球範圍內 MLLM 模型進行了全面定量評測並公佈了 16 個排行榜，包含感知、認知兩個總榜單以及 14 個子榜單。Skywork-MM 模型位列綜合榜單第一，其中，感知榜單排名第一、認知榜單排名第二。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 16 日，在權威推理榜單 Benchmark GSM8K 測試中，崑崙萬維「天工」大模型以 80% 的正確率脫穎而出，大幅領先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%），這標誌着天工的推理能力達到全球領先，接近 GPT-4。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>2023 年 9 月 17 日，崑崙萬維通過信通院「可信 AI」評估，並被評選為人工智能實驗室副組長單位。經中國信通院評估，崑崙萬維天工大模型符合 AIIA/PG 0071-2023、AIIA/PG 0072-2023 評估標準，模型開發、以及模型能力均達到了「4+級」。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>10 月 30 日，崑崙萬維開源百億級大語言模型「天工」Skywork-13B 系列，並配套開源了 600GB、150B Tokens 的超大高質量開源中文數據集。「天工」Skywork-13B 系列目前包括 130 億參數的兩大模型，Skywork-13B-Base 模型、Skywork-13B-Math 模型，它們在 CEVAL、GSM8K 等多個權威評測與基準測試上都展現了同等規模模型的最佳效果，其中文能力尤為出色，在中文科技、金融、政務等領域表現均高於其他開源模型。同時，崑崙萬維「天工」Skywork-13B 系列大模型全面開</span></span><span><span>放商用——開發者無需申請，即可商用。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span>一直以來，崑崙萬維致力於在</span></span><span><span>AIGC 模型算法方面的技術創新和開拓，致力於降低 AIGC 技術在各行各業的使用和學習門檻。通過《生成式人工智能服務管理暫行辦法》備案後，崑崙萬維將面向全社會開放 AI 服務，持續推動天工大模型及 AIGC 業務邁向新高度，提高多款生成式 AI 產品的用戶體驗，探索未知世界、創造美好未來。</span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:22:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265122</guid>
            <link>https://www.oschina.net/news/265122</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[從科幻走向現實，LLM Agent 做到哪一步了？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>LLM 洪流滾滾，AI 浪潮席捲全球，在這不斷衝擊行業認知的一年中，Agent 以冉冉新星之態引起開發者側目。OpenAI 科學家 Andrej Karpathy 曾言「OpenAI 在大模型領域快人一步，但在 Agent 領域，卻是和大家處在同一起跑線上。」</p><p>在此背景下，AI 從業者堅信：基於 LLM 的 Agent 會是一個嶄新並且充滿着機會的藍海領域。</p><p>那麼，究竟什麼是 Agent？它的框架工作方式是什麼？現階段存在哪些問題？未來有着怎樣的可能性？本文將分享一些思考。</p><h2>01.什麼是 Agent？</h2><p><img src="https://oscimg.oschina.net/oscnet/up-1f337817172f1c53b43dbdb7e958d8fe1a8.png" alt="" referrerpolicy="no-referrer"></p><p>根據 OpenAI 科學家 Lilian Weng 的一張 Agent 示意圖 [1] 我們可以瞭解 Agent 由一些組件來組成。</p><h3>規劃模塊</h3><ul><li><p>子目標分解：Agent 將目標分為更小的、易於管理的子目標，從而更高效地處理複雜的任務。</p></li><li><p>反省和調整：Agent 可以對過去的行為進行自我批評和自我反思，從錯誤中吸取教訓，並針對未來的步驟進行完善，從而提高最終結果的質量。</p></li></ul><h3>記憶模塊</h3><ul><li><p>短期記憶：在這裏通常是指 in-context learning，即利用提示工程來讓模型進行一定的學習。</p></li><li><p>長期記憶：這為 Agent 提供了長時間保留和召回信息的能力，通常是通過利用外部向量存儲和快速檢索。</p></li></ul><h3>工具使用模塊</h3><p>代理學習調用外部 API 來獲取模型權重中缺失的額外信息（通常在預訓練後很難更改），包括當前信息、代碼執行能力、對專有信息源的訪問等。</p><p>所以當 Agent 接收到一個處理複雜任務的目標時，它會首先進行任務的拆解，並去執行子任務，每次大模型調用之間通過短期記憶連接，使得大模型能理解當前任務處理的狀態。接下來 Agent 需要根據任務的狀態來獲取能夠幫助模型處理任務的信息，這些信息可以是歷史信息以及與任務有關的額外信息。</p><p>由於大模型擁有一定的認知能力，所以在無法精準定義所需信息的情況下，我們可以將與當前狀態有相關性的信息組織起來，讓大模型自主地去摘取它需要的內容。所以，比起基於關鍵字精準的匹配的搜索方法，向量數據庫所擁有的根據語義相關性的模糊搜索在這一點上受到了 Agent 框架的廣泛青睞。通過將長期記憶存放在一個數據庫（向量數據庫或傳統數據庫），並且在執行過程中根據需要進行檢索，模型能夠在任務的執行中獲取執行經驗以及認識到總體的狀態。</p><h2>02.Agent 框架工作方式</h2><p>我們以 AutoGPT 為例，看看一個 Agent 框架具體是如何工作的：</p><p><img src="https://oscimg.oschina.net/oscnet/up-0eb6a67673ebe44e8085f325471e525612a.png" alt="" referrerpolicy="no-referrer"></p><p>AutoGPT[2] 使用 GPT-4 來生成任務、確定優先級並執行任務，同時使用插件進行互聯網瀏覽和其他訪問。AutoGPT 使用外部記憶來跟蹤它正在做什麼並提供上下文，使其能夠評估其情況，生成新任務或自我糾正，並將新任務添加到隊列中，然後對其進行優先級排序。</p><p>另一個著名的項目 babyagi[3] 也是採取類似工作的方式。Agent 與一般的 LLM 最大的不同點在於，LLM Agent 通常根據任務的總體目標來去指定以及編排子目標，而 LLM 通常是作為一個被調用的工具，在一個工作流中擔任一個具體任務的執行者。</p><h2>03.LLM Agent 現階段出現的問題</h2><p>由於一些 LLM（GPT-4）帶來了驚人的自然語言理解和生成能力，並且能處理非常複雜的任務，一度讓 LLM Agent 成為滿足人們對科幻電影所有憧憬的最終答案。但是在實際使用過程中，大家逐漸發現了通往通用人工智能的道路並不是一蹴而就的，目前 Agent 很容易在一些情況下失敗：</p><ul><li><p>Agent 會在處理某一個任務上陷入一個循環</p></li><li><p>prompt 越來越長，最終甚至超出最大內容長度</p></li><li><p>記憶模塊的策略沒有給 LLM 某些關鍵的信息而導致執行失敗</p></li><li><p>LLM 由於幻覺問題錯誤使用工具，或者讓事情半途而廢</p></li></ul><p>上述問題隨着大家對於 Agent 的瞭解開始浮出水面，這些問題一部分需要 LLM 自身來解決，另一部分也需要 Agent 框架來進行解決，通用的 Agent 仍需進一步打磨。</p><h2>04.Agent 的展望</h2><p>目前，LLM Agent 大多是處於實驗和概念驗證的階段，持續提升 Agent 的能力才能讓它真正從科幻走向現實。當然，我們也可以看到，圍繞 LLM Agent 的生態也已經開始逐漸豐富，大部分工作都可以歸類到以下三個方面進行探索：</p><h3>Agent 模型</h3><p>AgentBench[4] 指出了不同的 LLM 對於 Agent 的處理能力有很大區別，當前的 gpt-4（0613）版本以極大的優勢領先於同類競品，LLM 本身的邏輯推理能力以及更長的 prompt 處理能力都會是 Agent 中極其重要的因素。</p><p>sToolLLM[5] 則使用輕量級的 LLaMA 向更加複雜的大模型學習理解 API 和使用 API 的能力，希望能夠將這種能力運用在更輕量的模型上。</p><h3>Agent 框架</h3><p>由 Lilian Weng 列出來的每一個組件都有探索的空間，目前學術探索較多的是利用框架提升 LLM 推理的能力，從 COT[6]、ReAct[7]、Reflexion[8] 等一系列方法，都是在不改變大模型的方法下，利用 prompt 去提升大模型的理性。關於記憶和搜索，目前普遍是將內容存儲在數據庫和搜索引擎中，Refexion 認為可以將執行過程中的觀察以軌跡的形式存儲在短期記憶中，而將接受反饋後的評估和自我反省總結的經驗放在長期記憶中。在其他方向，AutoGen[9] 也在探索多智能體之間的通信與協作。</p><h3>Agent 應用</h3><p>實現真正意義上的 Agent 道阻且長，因為現實世界具有太多不確定性。在特定、具體的可控環境下，Agent 便可以如工廠中實現一道道供需的機器人一般，針對更多的場景特點進行針對性的設計，從而更好的去完成一些特定的任務，達到預期的效果。</p><p>MetaGPT[10] 是一個針對軟件開發場景的 Agent，針對這一具體場景設計了各種具有不同技能的角色協作完成這一任務。Voyager[11] 是一個可以在 Minecraft 中可以進行自主探索、學習技能，並且會合成道具的 Agent。VoxPoser 結合了 RGB-D 信息以及 LLM 的推理能力後，可以完成更多複雜的機器人抓取操作。當下，Agent 尚不能做到完全可靠，針對更多場景的設計可以保障 Agent 不會在大部分簡單場景下失敗。</p><p>我們置身於一個充滿無限可能性的時刻，人工智能的進步將繼續塑造我們的未來，而 LLM Agent 無疑是這一演進過程中的亮點之一。人們探索人工智能，最終還是希望能夠讓人工智幫助人類完成自己無法做到的複雜任務，而 Agent 恰恰是從自動化走向智能化的一個關鍵的里程碑……</p><h3>參考鏈接</h3><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flilianweng.github.io%2F" target="_blank">https://lilianweng.github.io/</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSignificant-Gravitas%2FAuto-GPT" target="_blank">https://github.com/Significant-Gravitas/Auto-GPT</a></p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyoheinakajima%2Fbabyagi" target="_blank">https://github.com/yoheinakajima/babyagi</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.03688" target="_blank">https://arxiv.org/abs/2308.03688</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.16789" target="_blank">https://arxiv.org/abs/2307.16789</a></p><p>[6]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2201.11903" target="_blank">https://arxiv.org/abs/2201.11903</a></p><p>[7]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a></p><p>[8]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2303.11366" target="_blank">https://arxiv.org/abs/2303.11366</a></p><p>[9]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.08155" target="_blank">https://arxiv.org/abs/2308.08155</a></p><p>[10]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2308.00352" target="_blank">https://arxiv.org/abs/2308.00352</a></p><p>[11]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.16291" target="_blank">https://arxiv.org/abs/2305.16291</a></p><p>[12]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.05973" target="_blank">https://arxiv.org/abs/2307.05973</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:15:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4209276/blog/10140821</guid>
            <link>https://my.oschina.net/u/4209276/blog/10140821</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🎁有獎問答 | 程序員如何入門大數據]]>
            </title>
            <description>
                <![CDATA[<h1 class="header article-title"><a href="https://www.oschina.net/question/4855753_2331281">高手問答第 308 期 —— 程序員如何入門大數據？</a><div class="ui red label horizontal" data-tooltip="置頂">頂</div></h1><div class="extra ui horizontal list meta-wrap"><div class="item"><a href="https://my.oschina.net/u/4855753" class="__user"><span>OSC 噠噠</span></a><span class="org-label org-label--simple primary" data-tooltip="認證官方賬號"><i class="oicon oicon-org"></i></span> 發佈於 10/31 12:14
                    </div><div class="item">閲讀 2K+</div><div class="item collect-btn " data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i> 收藏 <span data-collect-count="" data-id="2331281" data-obj-type="2">6</span></div><div class="item comment-count"><a href="https://www.oschina.net/question/4855753_2331281#comments" class="normal"><i class="comment outline icon"></i> 答案 <span data-article-reply-count="">5</span></a></div></div><div class="tags"><a class="ui horizontal label" href="https://www.oschina.net/question/topic/masteronline" target="_blank"><img src="https://static.oschina.net/uploads/logo/masteronline_9WTeU.png" referrerpolicy="no-referrer">高手問答</a></div><div class="content" id="articleContent"><div><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>市面上不少公司都在做用戶畫像的相關工作，無論是電商行業、金融行業、視頻行業等等，都有這樣的產品。那到底怎麼去定義用戶畫像呢？</span></span></span></span></span></span></span></span></span></span></span></div><div>
  &nbsp; 
</div><div><strong>OSCHINA 本期高手問答 (10 月 31 日 - 11 月 6 日) 我們請來</strong><strong>了嘉賓&nbsp;</strong><strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">諸葛子房</a>老師&nbsp;</span></strong><strong>來和大家一起探討關於從 0 到 1 入門用戶畫像掌握大數據技術的問題。</strong></div><div>
  &nbsp; 
</div><div><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>可討論的問題包括但不限於：</span></span></span></span></span></span></span></span></span></span></span></p><ul><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>想入門用戶畫像需要掌握哪些技術棧？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>沒有企業的大量用戶或者行為數據，普通用戶該如何真實地模擬企業級的畫像項目？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>程序員如何入門大數據？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大數據</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>行業都有哪些職位，以及在公司中發揮的作用如何</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li><li><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>大數據行業未來的發展如何，以 ChatGPT&nbsp;為代表的 AI 浪潮是否會讓大數據行業走向</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>沒落</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>？</span></span></span></span></span></span></span></span></span></span></span></li></ul><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>有其他相關問題，也歡迎大家積極提問！</span></span></span></span></span></span></span></span></span></span></span></p><hr><h2>嘉賓介紹</h2><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>段小秋，網名：諸葛子房，先後就職於京東和 BAT，在大數據領域有多年工作經驗，也是多個 Apache&nbsp;項目的貢獻者。藍橋杯藍橋雲課《用戶畫像案例精講》專欄作者，也是開源項目 DataCompare&nbsp;作者。</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>微信</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>：zhugezifang001，歡迎交流溝通。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>個人</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>主頁：</span></span></span></span></span></span></span></span><a href="https://gitee.com/ZhuGeZiFang" rel="nofollow"><span><span><span><u><span style="color:#1e6fff"><span><span>https://gitee.com/ZhuGeZiFang</span></span></span></u></span></span></span></a></span></span></span></p><p><img height="639" src="https://oscimg.oschina.net/oscnet/up-5e58f5cf142af8e6ec1a3b8c3dc1cef16ec.png" width="500" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>為了鼓勵踴躍提問，會在問答結束後從提問者中抽取 2 名幸運會員贈予《</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用戶畫像案例精講》專欄電子版！</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="516" src="https://oscimg.oschina.net/oscnet/up-71771b786f7cc1bd0161793b6af70daf066.png" width="310" referrerpolicy="no-referrer"></p><p><img height="574" src="https://oscimg.oschina.net/oscnet/up-c2d9d9ce8dd66a412d3ef791ee45548dc45.png" width="311" referrerpolicy="no-referrer"></p></div><div><div><hr><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用戶</span></span></span></span></strong></span></span></span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>畫像概念</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用戶畫像，即：用標籤的方式去描述一個人或者一台手機、一台電腦，有些公司稱之為」用戶畫像「，有一些公司稱之為」用戶特徵「，其實是一個意思。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>舉個簡單的例子：</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>袁小青，性別：女，年齡：22 歲，職業：時尚編輯，愛好：音樂、拍照，居住地：北京，消費情況：年薪 10w，喜歡的 app：抖音</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="310" src="https://oscimg.oschina.net/oscnet/up-d3e2ad6f2150ece5dd0882380562cb797a7.png" width="488" referrerpolicy="no-referrer"></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>因此我們概念中描述的用戶畫像，其實是用標籤的方式對於一個用戶、一個賬號、一部手機進行描述。</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="368" src="https://oscimg.oschina.net/oscnet/up-adc4c1c21829279233af14e8d74631dfab4.png" width="400" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用戶畫像常見標籤</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>既然上面講到了對於用戶進行標籤化，那究竟要給用戶打哪些標籤呢？如何對標籤進行分類呢？</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>用戶</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>畫像核心標籤以及其分類：</span></span></span></span></span></span></span></span></span></span></span></p><p><img height="589" src="https://oscimg.oschina.net/oscnet/up-9efa6c4c17cb0bd2647c8d303db9def85cc.png" width="868" referrerpolicy="no-referrer"></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>用戶畫像的作用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>1. 個性化推薦</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>在使用一些社區產品、電商產品、短視頻 app、音樂 app 的時候，經常會遇到推薦的場景，根據不同的人推薦不同的內容或者商品。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>這其實是用戶畫像其中的一個應用，根據用戶查詢用戶的標籤數據，來進行推薦用戶感興趣的內容</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>2. 營銷圈選 (短信營銷、PUSH 營銷)</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>相信不少用戶收到過類似的營銷短信，或者一些 app&nbsp;彈窗，這個也是用戶畫像常見的應用場景</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>3. 策略引擎</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>根據用戶的標籤展示不同頁面，比如説：北京地區的用戶能才能領取北京的優惠券，以及只有高消費值的用戶才有淘寶上奢侈品 Luxury 入口的界面。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>4. 算法模型</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>算法模型的訓練，比如説：推薦模型、廣告模型，需要用到畫像數據來優化推薦模型。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>5. 畫像報告</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>不少商業公司會出一些行業報告，比如説下圖的小紅書、鎖屏 app&nbsp;的行業畫像報告；還有我們經常看到的一些個人年度榜單。</span></span></span></span></span></span></span></span></span></span></span></p><h4><span><span><span><span><span style="background-color:#ffffff"><span><strong><span><span style="color:#000000"><span><span>大數據技術在用戶畫像中的實際應用</span></span></span></span></strong></span></span></span></span></span></span></h4><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>由於</span></span></span></span></span></span></span></span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>畫像涉及到的一些行為數據，包括用戶購物行為、觀影行為，一些較為大型一些的公司數據日均都涉及 PB，因此需要處理的數據量非常大。在其中就會用到一些大數據的處理和存儲技術，比如説：Hadoop、Spark、Hbase&nbsp;等等。</span></span></span></span></span></span></span></span></span></span></span></p><p><span><span><span><span><span style="background-color:#ffffff"><span><span><span><span style="color:#000000"><span><span>同時隨着業務發展，一些廣告和推薦場景對於實時需求也更加明顯，所以實時數據處理領域，Flink、Kafka 等實時相關技術領域也越來越重要了。</span></span></span></span></span></span></span></span></span></span></span></p><hr><div><p><span style="background-color:#ffffff; color:#27ae60">OSChina 高手問答一貫的風格，不歡迎任何與主題無關的討論和噴子。</span></p><p>下面歡迎大家就<span>用戶畫像和大數據技術相關</span>問題向&nbsp;<strong><span style="color:#000000"><a href="https://my.oschina.net/u/4294800" rel="nofollow">諸葛子房</a></span></strong><span style="color:#000000">老師</span><strong><span style="color:#000000">&nbsp;</span></strong>提問，直接回帖提問既可。</p></div></div></div></div><div class="poll-wrap"></div><div class="additional-remarks"></div><div class="ui basic center aligned segment action"><div class="ui big buttons"><a class="ui basic button collect-btn hover" data-id="2331281" data-user-id="4855753" data-obj-type="2" data-max="99" data-tag-required="" data-current-user-id="" data-recommend-tags=""><i class="star outline icon"></i>收藏 (<span data-collect-count="" data-id="2331281" data-obj-type="2">6</span>)</a><div class="ui basic dropdown share button osc-share dropdown-share" data-tag="share-question"><i class="share icon"></i><span>分享</span><div class="menu"><a class="item" data-platform="weibo" data-value="weibo"><i class="weibo icon"></i>微博</a><a class="item" data-platform="qq" data-value="qq"><i class="qq icon"></i>QQ</a><a class="item" data-platform="wechat" data-value="wechat"><i class="weixin icon"></i>微信</a></div></div></div><div class="ui basic segment"><a class="ban" ban-report="" data-id="2331281" data-obj-type="2" data-url="https://www.oschina.net/question/4855753_2331281"><i class="flag red icon"></i>舉報</a></div></div>
            ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 03:08:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/question/4855753_2331281</guid>
            <link>https://www.oschina.net/question/4855753_2331281</link>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 基於連接的可擴展消息傳輸協議 SocketD]]>
            </title>
            <description>
                <![CDATA[<h1 align="center"><a id="user-content---socketd" class="anchor" href="https://gitee.com/noear/socketd#--socketd"></a>
  SocketD
</h1><p align="center"><strong>基於連接的可擴展消息傳輸協議</strong></p><p align="center"><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fsearch.maven.org%2Fartifact%2Forg.noear%2Fsocketd"><img src="https://img.shields.io/maven-central/v/org.noear/socketd.svg?label=Maven%20Central" alt="Maven" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.apache.org%2Flicenses%2FLICENSE-2.0.txt"><img src="https://img.shields.io/:license-Apache2-blue.svg" alt="Apache 2" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjavase-jdk8-downloads.html"><img src="https://img.shields.io/badge/JDK-8-green.svg" alt="jdk-8" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk11-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-11-green.svg" alt="jdk-11" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk17-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-17-green.svg" alt="jdk-17" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fwww.oracle.com%2Fjava%2Ftechnologies%2Fjavase%2Fjdk21-archive-downloads.html"><img src="https://img.shields.io/badge/JDK-21-green.svg" alt="jdk-21" referrerpolicy="no-referrer"></a><br><a target="_blank" href="https://gitee.com/noear/socketd/stargazers"><img src="https://gitee.com/noear/socketd/badge/star.svg" alt="gitee star" referrerpolicy="no-referrer"></a><a target="_blank" href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fnoear%2Fsocketd%2Fstargazers"><img src="https://img.shields.io/github/stars/noear/socketd.svg?logo=github" alt="github star" referrerpolicy="no-referrer"></a></p><br><p align="center"><a href="https://gitee.com/link?target=https%3A%2F%2Fjq.qq.com%2F%3F_wv%3D1027%26k%3DkjB5JNiC"><img src="https://img.shields.io/badge/QQ%E4%BA%A4%E6%B5%81%E7%BE%A4-870505482-orange" referrerpolicy="no-referrer"></a></p><hr><p>SocketD 是一個基於連接的、可擴展的、主題消息驅動的傳輸協議。主要特性有：</p><ul><li>異步通訊，非阻塞，由主題消息驅動</li><li>語言無關，二進制通信協議（支持 tcp, ws, udp）。支持多語言、多平台</li><li>背壓流控，請求時不讓你把服務端發死了</li><li>斷線重連，自動連接恢復</li><li>雙向通訊，單鏈接雙向互發雙向互聽</li><li>多路複用</li><li>自動分片，數據超出 16Mb，會自動分片、自動重組（udp 除外）</li><li>擴展定製，可以為數據添加 meta 標註（就像 http header）</li><li>接口簡單</li></ul><h3><a id="user-content-快速入門與學習" class="anchor" href="https://gitee.com/noear/socketd#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AD%A6%E4%B9%A0"></a>快速入門與學習</h3><p>請點擊：<a href="https://gitee.com/noear/socketd/blob/main/_docs">《快速入門與學習》</a>。Java 之外的語言與平台會盡快跟進（歡迎有興趣的同學加入社區）</p><h3><a id="user-content-適用場景" class="anchor" href="https://gitee.com/noear/socketd#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"></a>適用場景</h3><p>可用於 MSG、RPC、IM、MQ 等一些的場景開發，可替代 Http, Websocket, gRpc 等一些協議。比如移動設備與服務器的連接，比如一些微服務場景等等。</p><h3><a id="user-content-簡單的協議" class="anchor" href="https://gitee.com/noear/socketd#%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%8F%E8%AE%AE"></a>簡單的協議</h3><ul><li>link (url style)</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">tcp://19.10.2.3:9812/path?u=noear&amp;t=1234</span><span id="LC2" class="line">udp://19.10.2.3:9812/path?u=noear&amp;t=1234</span><span id="LC3" class="line">ws://19.10.2.3:1023/path?u=noear&amp;t=1234</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>codec</li></ul><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">//udp only &lt;2k, and no auto fragments</span><span id="LC2" class="line">[len:int][flag:int][sid:str(&lt;64)][\n][topic:str(&lt;512)][\n][metaString:str(&lt;4k)][\n][data:byte(&lt;16m)]</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li>flag &amp; flow</li></ul><table><thead><tr><th>Flag</th><th>Server</th><th>Client</th><th>備註</th></tr></thead><tbody><tr><td>Unknown</td><td>::close()</td><td>::close()</td><td></td></tr><tr><td>Connect</td><td>/</td><td>c(Connect)-&gt;s(Connack)-&gt;c::onOpen()</td><td></td></tr><tr><td>Connack</td><td>s(Connack)-&gt;c,s::onOpen()</td><td>/</td><td></td></tr><tr><td>Ping</td><td>/</td><td>c(Ping)-&gt;s(Pong)-&gt;c</td><td></td></tr><tr><td>Pong</td><td>s(Pong)-&gt;c</td><td>/</td><td></td></tr><tr><td>Close</td><td>s(Close)-&gt;c::onClose()</td><td>c(Close)-&gt;s::onClose()</td><td>用於特殊場景（如：udp）</td></tr><tr><td>Message</td><td>s(Message)-&gt;c</td><td>c(Message)-&gt;s</td><td></td></tr><tr><td>Request</td><td>s(Request)-&gt;c(Reply or ReplyEnd)-&gt;s</td><td>c(Request)-&gt;s(Reply or ReplyEnd)-&gt;c</td><td></td></tr><tr><td>Subscribe</td><td>s(Subscribe)-&gt;c(Reply...ReplyEnd)-&gt;s</td><td>c(Subscribe)-&gt;s(Reply...ReplyEnd)-&gt;c</td><td></td></tr><tr><td>Reply</td><td>-&gt;s(Reply)-&gt;c</td><td>-&gt;c(Reply)-&gt;s</td><td></td></tr><tr><td>ReplyEnd</td><td>-&gt;s(ReplyEnd)-&gt;c</td><td>-&gt;c(ReplyEnd)-&gt;s</td><td>結束答覆</td></tr></tbody></table><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">//The reply acceptor registration in the channel is removed after the reply is completed</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h3><a id="user-content-加入到交流羣" class="anchor" href="https://gitee.com/noear/socketd#%E5%8A%A0%E5%85%A5%E5%88%B0%E4%BA%A4%E6%B5%81%E7%BE%A4"></a>加入到交流羣：</h3><table><thead><tr><th>QQ 交流羣：870505482</th><th>微信交流羣（申請時輸入：SocketD）</th></tr></thead><tbody><tr><td></td><td><img src="https://gitee.com/noear/socketd/raw/main/group_wx.png" width="120" referrerpolicy="no-referrer"></td></tr></tbody></table><p>交流羣裏，會提供 "保姆級" 支持和幫助。如有需要，也可提供技術培訓和顧問服務</p><h3><a id="user-content-第一個程序你好世界" class="anchor" href="https://gitee.com/noear/socketd#%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E4%BD%A0%E5%A5%BD%E4%B8%96%E7%95%8C"></a>第一個程序：你好世界！</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="kd">public</span><span class="kd">class</span><span class="nc">Demo</span><span class="o">{</span></span><span id="LC2" class="line"><span class="kd">public</span><span class="kd">static</span><span class="kt">void</span><span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span><span class="n">args</span><span class="o">)</span><span class="kd">throws</span><span class="nc">Throwable</span><span class="o">{</span></span><span id="LC3" class="line"><span class="c1">//::啓動服務端</span></span><span id="LC4" class="line"><span class="nc">SocketD</span><span class="o">.</span><span class="na">createServer</span><span class="o">(</span><span class="k">new</span><span class="nc">ServerConfig</span><span class="o">(</span><span class="s">"tcp"</span><span class="o">).</span><span class="na">port</span><span class="o">(</span><span class="mi">8602</span><span class="o">))</span></span><span id="LC5" class="line"><span class="o">.</span><span class="na">listen</span><span class="o">(</span><span class="k">new</span><span class="nc">SimpleListener</span><span class="o">(){</span></span><span id="LC6" class="line"><span class="nd">@Override</span></span><span id="LC7" class="line"><span class="kd">public</span><span class="kt">void</span><span class="nf">onMessage</span><span class="o">(</span><span class="nc">Session</span><span class="n">session</span><span class="o">,</span><span class="nc">Message</span><span class="n">message</span><span class="o">)</span><span class="kd">throws</span><span class="nc">IOException</span><span class="o">{</span></span><span id="LC8" class="line"><span class="k">if</span><span class="o">(</span><span class="n">message</span><span class="o">.</span><span class="na">isRequest</span><span class="o">()){</span></span><span id="LC9" class="line"><span class="n">session</span><span class="o">.</span><span class="na">replyEnd</span><span class="o">(</span><span class="n">message</span><span class="o">,</span><span class="k">new</span><span class="nc">StringEntity</span><span class="o">(</span><span class="s">"And you too."</span><span class="o">));</span></span><span id="LC10" class="line"><span class="o">}</span></span><span id="LC11" class="line"><span class="o">}</span></span><span id="LC12" class="line"><span class="o">})</span></span><span id="LC13" class="line"><span class="o">.</span><span class="na">start</span><span class="o">();</span></span><span id="LC14" class="line"></span><span id="LC15" class="line"><span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span><span class="c1">//等會兒，確保服務端啓動完成</span></span><span id="LC16" class="line"></span><span id="LC17" class="line"><span class="c1">//::打開客戶端會話</span></span><span id="LC18" class="line"><span class="nc">Session</span><span class="n">session</span><span class="o">=</span><span class="nc">SocketD</span><span class="o">.</span><span class="na">createClient</span><span class="o">(</span><span class="s">"tcp://127.0.0.1:8602/hello?token=1b0VsGusEkddgr3d"</span><span class="o">)</span></span><span id="LC19" class="line"><span class="o">.</span><span class="na">open</span><span class="o">();</span></span><span id="LC20" class="line"></span><span id="LC21" class="line"><span class="c1">//發送並請求（且，收回答覆）</span></span><span id="LC22" class="line"><span class="nc">Entity</span><span class="n">reply</span><span class="o">=</span><span class="n">session</span><span class="o">.</span><span class="na">sendAndRequest</span><span class="o">(</span><span class="s">"/demo"</span><span class="o">,</span><span class="k">new</span><span class="nc">StringEntity</span><span class="o">(</span><span class="s">"Hello wrold!"</span><span class="o">).</span><span class="na">meta</span><span class="o">(</span><span class="s">"user"</span><span class="o">,</span><span class="s">"noear"</span><span class="o">));</span></span><span id="LC23" class="line"><span class="o">}</span></span><span id="LC24" class="line"><span class="o">}</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div>]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:54:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/noear/socketd</guid>
            <link>https://gitee.com/noear/socketd</link>
        </item>
        <item>
            <title>
                <![CDATA[雲幾何內核開源平台 —— OpenGeometry 開源社區正式發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>11 月 5 日，由廣東省工業和信息化廳、廣東省科學技術廳、廣東省教育廳、深圳市人民政府主辦，工業和信息化部第五研究所、廣東省數字化學會承辦，深圳市工業和信息化局、深圳市龍崗區人民政府、深圳市福田區人民政府協辦的 2023 工業軟件生態大會在廣東省深圳市召開。</p><p>在大會主論壇上，國內備受關注的雲幾何內核開源平台——OpenGeometry 開源社區正式發佈。</p><p><img src="https://static.oschina.net/uploads/space/2023/1106/104536_bRwO_2720166.png" referrerpolicy="no-referrer"></p><p>據介紹，OpenGeometry Group（簡稱 OGG）是由數字化工業軟件聯盟孵化，並由開元幾何（深圳）科技有限公司作為服務公司運營的開源項目。OpenGeometry 開源社區將通過搭建雲幾何內核的開源軟件開發平台，構建新一代工業軟件的核心「根」技術，為工業軟件的產品研發提供支持，並帶動上下游廠商、服務商等合作伙伴共同參與，最終形成產業鏈協同發展的良性循環。</p><p>OpenGeometry 開源社區表示，未來將積極與科研院校、工業軟件廠商、工業軟件應用企業、開發者等合作伙伴進行廣泛的技術交流和合作，引進國內外最先進的技術、吸引頂尖的人才，引入數字化工業軟件聯盟的生態資源，深入電子、汽車、裝備製造等行業應用中進行場景化聯合研發，真正做到以高質量的技術更好地服務產業實體經濟。</p><div>
 北師大港浸大的單肖文教授代在會上表示，OpenGeometry 開源社區對中國工業軟件界意義很大，是構築工業軟件的「根」，只有「根」扎得深，工業軟件的樹才能枝繁葉茂。
</div></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/265108</guid>
            <link>https://www.oschina.net/news/265108</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[輕鬆理解 Transformers (3): Feed-Forward Layer 部分]]>
            </title>
            <description>
                <![CDATA[<div class="content"><blockquote><p>編者按：隨着人工智能技術的不斷髮展 Transformer 架構已經成為了當今最為熱門的話題之一。前饋層作為 Transformer 架構中的重要組成部分，其作用和特點備受關注。本文通過淺顯易懂的語言和生活中的例子，幫助讀者逐步理解 Transformers 中的前饋層。</p><p>本文是 Transformers 系列的第三篇。作者的觀點是：前饋層在 Transformer 架構中扮演着至關重要的角色，它能夠有效地提高計算效率，同時也是集體智慧的體現。</p><p>文章作者首先介紹了前饋層的基本結構，它由全連接層組成，進行線性變換和線性計算。但也存在侷限性，不能進行復雜的非線性變換。所以前饋層需要激活函數（如 ReLU）進行非線性轉換，增強網絡的表達能力。為防止模型僅記憶數據特徵而不具備推理能力，需要使用正則化技術如 dropout。相信通過本文的閲讀，讀者將對 Transformer 中的前饋層有更深入的理解。</p><p>隨着深度學習在語音、圖像、自然語言處理等領域取得突破，人工智能或許正向着真正的通用人工智能邁進。但要培養通用人工智能，我們還需不斷深入理解其中的原理和相關機制。</p><p>以下是譯文，enjoy！</p></blockquote><p><strong>作者 | Chen Margalit</strong></p><p><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fchen-margalit%2F" target="_blank">https://www.linkedin.com/in/chen-margalit/</a></strong></p><p><strong>編譯 | 嶽揚</strong></p><p><em><strong>本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。</strong></em></p><p><em>原文鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftowardsdatascience.com%2Fsimplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9" target="_blank">https://towardsdatascience.com/simplifying-transformers-state-of-the-art-nlp-using-words-you-understand-part-4-feed-foward-264bfee06d9</a></em></p><p>本節將介紹前饋層（Feed-Forward layer），這是大多數深度學習架構中的基礎元素。在有關深度學習的常見話題交流時，一般都會強調它們在構造 Transformer 架構中的重要作用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9a856aacefd53ae8070b810c099e0da6711.png" alt="" referrerpolicy="no-referrer"><em>原論文中的圖片[1]</em></p><p>前饋全連接層（feed-forward linear layer）基本上就是一堆神經元，每個神經元都與其他神經元相連接。請看下圖，其中 a、b、c 和 d 是神經元。這些神經元包含了一些 input（即一些我們想要理解的數據（像素值（pixels）、詞嵌入（word embeddings）等））。它們與編號為 1 的神經元相連。每兩個神經元之間的連接都有不同的連接權重值（connection strength）。例如，a-1 是 0.12，b-1 是-0.3，等等。實際上，左列中的所有神經元都與右列中的所有神經元相連。但是為了清晰起見，我沒有在圖像中展示全部的連接，你需要了解這一情況。就像圖中有 a-1 一樣，還應該有 a-2、b-2、c-2、d-3 等。兩個神經元之間的每個連接都有不同的「連接權重」。</p><p><img src="https://oscimg.oschina.net/oscnet/up-f139aa760b0e5733e14a61f50803820e023.png" alt="" referrerpolicy="no-referrer"></p><p><em>該圖由原文作者繪製</em></p><p>該架構有兩點值得注意：</p><ol><li>如前所述，每個節點（神經元）都與其他節點相連。所有的 a、b、c、d 都與其他神經元（1、2、3）相連。可以將這幅圖像看作是一條軍隊指揮鏈。1、2、3 是指揮官。他們從士兵 a、b、c、d 那裏得到情報。a 知道某件事情的一些細節，但它的情報不夠全面。1 知道的就更多了，因為它能夠從 a、b、c 和 d 那裏同時得到情報。2 和 3 也是指揮官，同樣從 a、b、c、d 那裏獲取情報。這些指揮官（1、2、3）也會向更高級的指揮官傳遞報告。在他們之後的指揮官既從 a、b、c、d 那裏得到情報，也從 1、2、3 那裏得到情報，因為下一層（每列神經元為一層）也是以完全相同的方式進行全連接的。因此，首先要明白的是， 1 的情報比 a 更全面，而下一層指揮官的情報也比 1 更全面。</li><li>第二點需要注意的是，每個節點與下一層的每個其他節點之間的連接權重是不同的。a-1 是 0.12，b-1 是-0.3。我在這裏給出的數字顯然是虛構的，但它們也是在合理的範圍內，並且它們都是自動學習調整的參數（learned parameters）（例如，它們在訓練過程中會發生變化）。把這些數字看作是 1 對 a、b 等的影響程度。從 1 號指揮官的角度來看，a 的情報有一定的可信度。但不應該想當然地相信他説的每一句話，可以選擇性地相信他説的某些話。b 則截然不同。這個節點通常會低估它接收到的輸入（情報）的重要性，就像一個悠閒的人一樣。「這是一隻 tiger 嗎？不，只是一隻 big cat。」 這是對發生的事情的過度簡化，但重要的是要注意這一點：<strong>每個神經元都掌握着一些 input（無論是原始輸入還是經過處理的 input）並進行處理後將其傳遞下去。</strong></li></ol><p>你知道「傳話遊戲」嗎？你和其他 10 個人坐成一排，然後你向下一個人耳語一個詞，比如説「Pizza」。第 2 個人聽成了類似「Pazza」的詞，於是他們把「Pazza」傳給了第 3 個人。第 3 個人聽成了 「Lassa」（畢竟是耳語），於是他把 「Lassa」傳給了第 4 個人。第 4 個人聽成了 「Batata」，於是他又轉述了 「Batata」，以此類推。當你問第 10 個人他聽到了什麼？結果他回答「Shambala」，我們是怎麼從「Pizza」到「Shambala」的？這個遊戲與神經網絡的區別在於，每個人都會對信息進行處理。第二個人不會説 「Pazza」，他會説「Pazza 是意大利菜，很好吃」。第三個人會説：「Lassa 是一道意大利菜，在全世界都很常見」，等等。每個人（層）都會補充一些他們希望有用的東西。</p><p>基本情況就是這樣。<strong>每個神經元獲得輸入，處理輸入，然後繼續傳遞。</strong> 為了與全連接層（fully connected layer）相匹配，我建議對這個遊戲進行升級：從現在開始，在遊戲中引入多行人，每個人都可以對每一行中的其他人説悄悄話。從每一行的第 2 位開始，每個人都會收到很多人的悄悄話，他們需要了解每個人説的話語的「權重」（重要性），這就是前饋層（Feed Forward Layer）。</p><p><strong>為什麼我們要使用前饋層？因為它們使我們的計算能夠更加有效，可以將其類比為集體智慧的體現。</strong> 講一個關於「猜測一頭牛重量」的故事吧！1906 年，在英國的某個地方，有人把一頭牛帶到一個展覽會上。主持人隨機挑選了 787 名觀覽者，請他們猜測這頭牛的重量。你認為他們猜測的結果會是多少？這頭牛的實際體重是多少呢？</p><p>他們猜測的平均值是 1197 磅（542 公斤）。這些都是隨機抽取的羣眾對牛體重的估計。這個平均猜測值離真實重量相差多遠呢？只有 1 磅差距，也就是 450 克。這頭牛的重量是 1198 磅。這個故事來自這裏[2]，我不確定細節是否準確，但回到本文的主題，我們可以把線性層 <em>（譯者</em><em>注：此處即本文所説的前饋層）</em> 看作是在做類似的事情。通過增加更多的參數、更多的計算（更多的猜測），就可以得到更準確的結果。</p><p><img src="https://oscimg.oschina.net/oscnet/up-1dd0ad28fe0fffea90238839fce31188c1e.png" alt="" referrerpolicy="no-referrer"></p><p><em>照片由 Larry Costales[3] 在 Unsplash[4] 上發佈</em></p><p>讓我們試着想象一個真實的使用場景。給神經網絡輸入一張圖片，讓它判斷圖片裏的是蘋果還是橙子。這種架構基於卷積神經網絡（CNN）層，本文不會深入討論這個知識點，因為其超出了本系列文章的範圍。但該層是一個能夠學習和識別圖像中特定模式（specific patterns）的計算層。 <em>（譯者注：這些特定模式的識別有助於網絡進行更準確的分類和判斷，例如判斷圖像中是蘋果還是橙子。）</em> 每一層都能識別更復雜的模式。例如，第一層幾乎不能識別出任何東西，該層只是傳遞原始像素，第二層就能夠識別出垂直線條。如果下一層同時接收到有垂直線條的信息，並從其他神經元那裏聽説還有非常接近的垂直線條。它會將兩者綜合起來進行計算、分析，然後思考：不錯！這是一個角落。這就是從多個來源獲取輸入信息的好處。</p><p>我們可能會認為，進行計算的次數越多，得到的結果就越好。但事實上，並非完全是這樣，但確實有一定的道理。如果我們做更多的計算，諮詢更多人（神經元）的意見，通常就能得出更好的結果。</p><h1><strong>01 激活函數 Activation Function</strong></h1><p>接下來將介紹深度學習中另一個非常重要的基本概念的關鍵組成部分——激活函數，並探討它與 Transformer 的關係，以便更好地理解兩者之間的關聯。</p><p>儘管全連接層（Fully connected layers）的使用非常廣泛，但也存在一個很大的缺點——<strong>它們是線性層（linear layers），只能進行線性變換和線性計算。全連接層可以進行加法和乘法運算，但無法以「創造性」的方式轉換輸入（input）。有時候，僅僅增加計算量是不夠的，需要以完全不同的思考方式來解決問題。</strong></p><p>如果我每天工作 10 個小時，每天賺 10 美元，如果我想更快地存下 1 萬美元，我可以每週工作更多天，或者每天工作更多小時。但是肯定還有其他解決方案，對吧？有很多人不需要他們擁有的錢（我可以更好地利用它），或者我可以找到更高薪的工作等等。解決辦法並不總是千篇一律。</p><p>同理，在本文的情況下，激活函數可以來提供幫助。激活函數能夠幫助我們進行非線性變換（non-linear transformation）。例如，將一個數字列表[1, 4, -3, 5.6]轉換為概率分佈，就是 Softmax 激活函數的作用。該激活函數能夠將這些數字轉換為[8.29268754e-03, 1.66563082e-01, 1.51885870e-04, 8.24992345e-01]這樣的輸出。這 5 個數字相加等於 1。雖然這些數字看起來有些混亂，但 e-03 表示第一個數字（8）在小數點後 3 個零開始（例如 0.00，然後是 82926。實際上該數字是 0.00829268754）。<strong>這個 Softmax 激活函數將整數轉換為 0 到 1 之間的浮點數，轉換後的浮點數仍然保持了原始整數之間的相對大小關係。這種保持相對大小關係的特性在統計學中非常有用。</strong></p><p>還有其他類型的激活函數，其中最常用的之一是 ReLU（修正線性單元）。這是一種非常簡單（同時也非常有用）的激活函數，它能夠將任何負數轉化為 0，而非負數保持不變。非常簡單且實用。如果我將列表[1, -3, 2]輸入 ReLU 函數，會得到[1, 0, 2]。</p><p>在介紹完複雜的 Softmax 之後，你可能會期望一些更復雜的東西，但有人曾經告訴我「Luck is useful」。有了激活函數後，我們就走運了。</p><p>我們之所以需要這些激活函數，是因為非線性關係（nonlinear relationship）無法通過線性計算（全連接層）來表示。如果我每工作一小時就能得到 10 美元，那麼收入就是線性關係。如果我每連續工作 5 個小時，接下來的 5 個小時就能增加 10%，那麼這種關係就不再是線性的了。我的工資不再是工作小時數乘以固定的小時工資。<strong>在文本生成等更復雜的任務中使用深度學習，就是因為我們要建模的關係高度非線性。</strong> 在「我喜歡」之後能出現的詞並不是固定的。</p><p>ReLU 的一大優勢，也許可以解釋它為何被廣泛使用，就是<strong>對大量數據進行計算的成本非常低。</strong> 當神經元數量較少時（比方説幾萬個），計算量並不重要。但是當像大語言模型那樣使用數千億個神經元時，一種更高效的計算方式會帶來巨大差異。</p><h1><strong>02 正則化 Regularization</strong></h1><p>在解釋 Transformer 中如何實現正則化（非常簡單）之前，我們將介紹最後一個概念——dropout，這是一種正則化技術。由於算法是基於數據的，並且它們的任務是儘可能逼近訓練目標，所以對於一個大腦聰明的人來説，有時僅僅記住一點點東西就足夠了。正如我們在學校中所受到的教育，學習複雜的邏輯並不總是有用的，我們有時只需記住我們所見過的，或者記住與之接近的東西。第二次世界大戰是什麼時候發生的？嗯...它受到了第一次世界大戰、經濟危機、人民憤怒等等因素的影響...大約是 1917 年左右...所以我們就説是 1928 年吧。記住確切的日期可能更好。</p><p>可以想象，這對機器學習來説並不是好事。如果我們需要的是已經有答案的問題的答案，我們就不需要這些複雜的技術了。我們需要一個聰明的算法，因為我們無法記住所有的東西。我們需要它進行實時推理，進行思考。<strong>正則化（Regularization）是讓算法僅學習不記憶的一系列技術的總稱。在這些正則化技術中，一種常用的技術就是 dropout。</strong></p><h1><strong>03 Dropout</strong></h1><p>dropout 可以説是一種相當簡單的技術。還記得我們説過全連接層（fully connected layers）是完全連接的嗎？dropout 打破了這種邏輯。dropout 技術將「連接權重（connection strength）」設置為 0，這意味着該連接不會產生任何影響。對於 1 號指揮官來説，連接到士兵「a」的輸入變為 0 時，「a」傳遞的情報會變得完全無用。不回答，不肯定，也不否定。<strong>我們在每一層中使用 dropout 技術時，會隨機選擇一定數量的神經元（由開發者配置），並將它們與其他神經元的連接權重設為 0。</strong> 每次指揮官會被迫忽略不同的士兵，因此無法記住其中任何一個士兵，因為下次可能不會再遇到它們傳遞情報。</p><h1><strong>04 回到 Transformer！</strong></h1><p>現在我們已經掌握了理解 Transformer 中前饋層工作原理所需的所有基礎知識。接下來解釋實現過程就會非常簡單了。It will now be very simple.</p><p><img src="https://oscimg.oschina.net/oscnet/up-d58c4da377e46953ddd77cd2bcb9c4fdd64.png" alt="" referrerpolicy="no-referrer"></p><p><em>圖片來自 Vaswani, A. 等人的論文[5]</em></p><p>在原論文中的架構圖中，前饋線性層只做了四件事情：</p><ul><li><strong>對文本中的每個位置 (用向量表示)，進行逐位置的線性計算。</strong></li><li><strong>對線性運算的輸出應用 ReLU 函數。</strong></li><li><strong>對上一步驟 ReLU 運算的輸出進行再一次線性運算。</strong></li><li><strong>最後，將其添加到第 3 層的輸出中。</strong></li></ul><p>就是這樣。如果你有深度學習領域的相關經驗，那麼理解這一部分對你來説可能很容易。如果你沒有經驗，可能稍顯吃力，但你已經理解了深度學習中一個極為重要的組成部分。</p><p>在下一部分,我們將介紹 Transformer 中的解碼器 (Decoder) 部分相關知識！</p><p><strong>END</strong></p><h1><strong>參考資料</strong></h1><p>[1]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p><p>[2]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wondriumdaily.com%2Fthe-wisdom-of-crowds%2F%23%3A%7E%3Atext%3DAn%2520Astonishing%2520Example%2520of%2520the%2520Wisdom%2520of%2520Crowds%26text%3DThe%2520actual%2520weight%2520of%2520the%2Cthat%2520weight%2520was%25201%252C197%2520pounds" target="_blank">https://www.wondriumdaily.com/the-wisdom-of-crowds/#:~:text=An%20Astonishing%20Example%20of%20the%20Wisdom%20of%20Crowds&amp;text=The%20actual%20weight%20of%20the,that%20weight%20was%201%2C197%20pounds</a>.</p><p>[3]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2F%40larry3%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/@larry3?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[4]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Funsplash.com%2Fphotos%2FAhf1ZmcKzgE%3Futm_source%3Dunsplash%26utm_medium%3Dreferral%26utm_content%3DcreditCopyText" target="_blank">https://unsplash.com/photos/Ahf1ZmcKzgE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText</a></p><p>[5]<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p></div>
                                    ]]>
            </description>
            <pubDate>Sat, 04 Nov 2023 02:07:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/10141048</guid>
            <link>https://my.oschina.net/IDP/blog/10141048</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[崑崙萬維「天工」大模型正式向全社會開放]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>2023 年 11 月 3 日，崑崙萬維「天工」大模型宣佈通過《生成式人工智能服務管理暫行辦法》備案，面向全社會開放服務！</p><p>用戶在應用商店下載「天工 APP」或登陸「天工官網」（<a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.tiangong.cn" target="_blank">www.tiangong.cn</a>）均可直接註冊使用。</p><p>官方介紹稱，「天工」是國內首個對標 ChatGPT 的雙千億級大語言模型，也是一個 AI 搜索引擎，一個對話式 AI 助手。「天工」擁有強大的自然語言處理和智能交互能力，能夠實現個性化 AI 搜索、智能問答、聊天互動、文本生成、編寫代碼、語言翻譯等多種應用場景，並且具有豐富的知識儲備，涵蓋科學、技術、文化、藝術、歷史等領域。</p><p><img height="232" src="https://oscimg.oschina.net/oscnet/up-4220721cc203df8b9704c1aa7e7fb303f00.png" width="500" referrerpolicy="no-referrer"></p><p>2022 年 12 月 15 日，崑崙萬維在北京舉行 AIGC 技術發佈會，發佈自研 AIGC 全系列算法與模型，覆蓋了圖像、音樂、文本、編程等多模態的 AI 內容生成能力。</p><p>2023 年 4 月 17 日，崑崙萬維正式發佈自研千億級大語言模型「天工」，同時宣佈啓動邀請測試。「天工」用過通過自然語言與用戶進行問答式交互，AI 生成能力可滿足文案創作、知識問答、代碼編程、邏輯推演、數理推算等多元化需求。</p><p>2023 年 5 月 19 日，北京市經濟和信息化局公佈第一批《北京市通用人工智能產業創新夥伴計劃成員名單》。崑崙萬維成為第一批模型夥伴和投資夥伴。</p><p>2023 年 8 月 23 日，崑崙萬維推出國內第一款 AI 搜索產品——「天工 AI 搜索」，並開啓內測申請。「天工 AI 搜索」深度融合 AI 大模型能力，通過人性化、智能化的方式全面提升用戶的搜索體驗，為用戶提供快速、可靠的交互式搜索服務，並集成 AI 對話、AI 寫作等常用功能，幫助用戶提升工作效率，全面重塑中文搜索體驗。</p><p>2023 年 9 月，崑崙萬維多模態大模型 Skywork-MM 在騰訊優圖實驗室聯合廈門大學開展的多模態大語言模型測評 MME 中，綜合得分排名第一。該評測首次對全球範圍內 MLLM 模型進行了全面定量評測並公佈了 16 個排行榜，包含感知、認知兩個總榜單以及 14 個子榜單。Skywork-MM 模型位列綜合榜單第一，其中，感知榜單排名第一、認知榜單排名第二。</p><p>2023 年 9 月 16 日，在權威推理榜單 Benchmark GSM8K 測試中，崑崙萬維「天工」大模型以 80% 的正確率脫穎而出，大幅領先 GPT-3.5（57.1%）和 LLaMA2-70B（56.8%）。</p><p>2023 年 9 月 17 日，崑崙萬維通過信通院「可信 AI」評估，並被評選為人工智能實驗室副組長單位。經中國信通院評估，崑崙萬維天工大模型符合 AIIA/PG 0071-2023、AIIA/PG 0072-2023 評估標準，模型開發、以及模型能力均達到了「4+級」。</p><p>10 月 30 日，崑崙萬維開源百億級大語言模型「天工」Skywork-13B 系列，並配套開源了 600GB、150B Tokens 的超大高質量開源中文數據集。「天工」Skywork-13B 系列目前包括 130 億參數的兩大模型，Skywork-13B-Base 模型、Skywork-13B-Math 模型，它們在 CEVAL、GSM8K 等多個權威評測與基準測試上都展現了同等規模模型的最佳效果，其中文能力尤為出色，在中文科技、金融、政務等領域表現均高於其他開源模型。同時，崑崙萬維「天工」Skywork-13B 系列大模型全面開放商用——開發者無需申請，即可商用。</p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 03 Nov 2023 03:06:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264987</guid>
            <link>https://www.oschina.net/news/264987</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[WinterJS —— Rust 編寫的 Service Worker]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>WinterJS 是用 Rust 編寫的 JavaScript Service Worker。</p><p>WinterJS 使用 SpiderMonkey 運行時執行 JavaScript（與 Firefox 使用的運行時相同），並遵循 WinterCG 規範，目的是最大限度地兼容 Cloudflare Workers、Deno Deploy 和 Vercel 等其他服務（因此命名為 WinterJS）。</p><p>WinterJS 除了速度極快，還能通過 WASIX&nbsp;<strong>編譯成 WebAssembly</strong>，因此完全支持在 Wasmer 上運行。</p></div>
                                                                ]]>
            </description>
            <pubDate>Fri, 03 Nov 2023 02:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/winterjs</guid>
            <link>https://www.oschina.net/p/winterjs</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 複用性風控：軟件複用成本的量化管理]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="text-align:justify">複用性（Reusability）是軟件工程中一個被頻頻使用的術語，它一般作為產品的賣點被宣傳，或者出現在技術設計文檔之中。大部分看到這個概念的的受眾只是將其作為一個積極的軟件非功能屬性去理解，但卻忽略了其背後隱藏的風險。本文從另一個角度出發，去分析「複用性」這一概念背後的風險及成因，藉助筆者在業務安全和基礎安全的一點經驗，提出了一個在軟件研發流程中，管理「複用性成本風險」的風險管理模型。從模型出發，我們可以認識到實現複用時面臨的各項挑戰、開發認知謬誤、複用成本的形式化定義方法等，希望這些輸入能為讀者在後續的技術決策和軟件研發流程提供些許幫助。</p><p style="text-align:justify">本文主要分為三個部分：第一部分介紹複用性的定義以及不合理複用引入的主要技術債，第二部分分析複用性失效的原因；第三部分為複用性軟件資產的構建方和使用方提供一個形式化的度量工具，該工具將奠定後續風險管理模型評估階段定量分析的基礎；第四部分提出一個用於管理「複用性風險」的模型，覆蓋軟件研發生命週期的全流程，通過事前評估、事中緩釋和事後迭代三個環節最大程度地降低由於軟件複用帶來的軟件開發和維護成本。</p><span id="OSC_h3_1"></span><h3>一、複用性的理想與現實</h3><span id="OSC_h4_2"></span><h4><strong>1.1 複用定義：從代碼到系統</strong></h4><p style="text-align:justify">軟件複用是解決軟件質量和生產力問題的一種方法，它指的是在軟件開發過程中重複使用相同或相似的軟件元素。通過合理利用軟件複用技術，我們可以提高開發效率，並且降低開發過程中的錯誤率。同時，軟件複用還可以促進團隊協作和知識共享，使得開發者們能夠更好地利用彼此的經驗和資源。因此，在當今快節奏的開發環境中，軟件複用已經成為提高生產力和質量的關鍵策略之一。在過去幾十年的時間裏，很多編程語言的成功（Python、Java 等）和開源文化的蓬勃發展，都與複用密不可分。軟件複用可以在不同粒度上進行，包括代碼和設計拷貝、源代碼複用、設計和軟件體系結構複用以及領域特定的軟件體系結構複用等。早期的軟件複用主要集中在代碼級別，例如共享方法、抽象類、庫、微服務和 Docker 鏡像等。隨着時間推移，其外延拓展至領域知識、開發經驗、設計文檔、需求分析和測試用例及數據等在不同階段所產生的各種軟件產品。<strong>在本文中，除非特別説明，複用性主要指的就是聚焦代碼的複用，下文中的「組件複用」，不僅限於通常我們認知中的公共庫，還包括代碼方法、公共類、軟件框架、可集成系統等軟件開發中的可複用元素。</strong></p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-963651fba23c39dc34c4a58a1a6eaacb_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_3"></span><h4><strong>1.2 複用風險：複雜度和成本</strong></h4><p style="text-align:justify">誠然，通過組件的複用可以提高軟件開發效率和質量，但複用不是銀彈，複用也會有一些副作用：</p><p style="text-align:justify">1.兼容性/安全性/性能；</p><p style="text-align:justify">2.增加了系統間的依賴；</p><p style="text-align:justify">3.增加了開發和維護成本。</p><p style="text-align:justify"><strong>首先，兼容性/安全性/性能</strong>等這幾類問題，是針對可複用組件的使用方來説的，一般來説，在決策是否複用之前就可以評估，其指標和過程也比較清晰，這裏就不具體展開了。</p><p style="text-align:justify"><strong>其次，複用會增加系統依賴。</strong>依賴關係是軟件的基本組成部分，無法消除，但軟件設計的目標之一是儘可能消除依賴關係，並使依賴關係儘可能簡單和明顯。當我們引入外部組件進行復用時，軟件組件之間的依賴關係會導致組件變更範圍的擴大以及組件認知負荷的增加，前者是針對組件維護方而言的，即看似簡單的變更需要在許多不同的地方修改代碼，<strong>隨着消費者數量的增長，在不同需求之間進行平衡變得越來越困難；</strong>後者是對於組件使用方而言的，即開發人員需要了解大量組件領域知識才能實現有效的組件複用。比如，需要了解待使用接口中若干入參的設計意圖、是否存在隱式依賴傳遞從而導致依賴衝突等。依賴的增加會為系統引入更多的複雜性，而我們知道，構建軟件系統的核心挑戰就是管理複雜性，複用組件只會在一定程度上轉移複雜性，但並不能消除複雜性。因此，我們需要在「複用組件降低成本」和「複用組件引入依賴（複雜性）」之間取得平衡。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-3612b21399b66c7600b9f27155d86f92_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify"><strong>最後，複用會增加各項成本。</strong>包括開發的成本、變更的成本、集成的成本、領域知識遷移的成本。對於一個面向複用設計的組件來説，實現正確抽象和通用框架的設計和開發成本，比一次性的解決方案高得多，對於組件的後續維護者來説，這樣的可複用框架和庫通常也會帶來陡峭的學習曲線（因為文檔一般是缺失的），組件會逐漸走向腐化，最後不得不推倒重來。此外，對於可複用組件的使用方來説，其理解和集成組件的成本通常也是被忽略的，一些強推的業務層的「偽複用框架」給前台集成的同學帶來了巨大的集成、學習和維護成本。</p><p style="text-align:justify">上述複用帶來問題，有一些是可以規避的，如兼容性、性能、容量等的匹配度，有一些是無法避免的，如設計通用化組件的開發成本、不合理的抽象導致的代碼腐化、不合理的複用導致的維護成本等。事實上，無論我們在技術上做多麼精妙的設計，技術的創新永遠滯後於系統的腐化速度。</p><p style="text-align:justify">為了最大程度的降低複用帶來的風險，本文提出一套從類比於安全風險管理的「複用性風險」應對模型，從事前評估、事中緩釋、事後迭代三個階段出發，最大程度地降低我們在開發可複用組件、使用可複用組件中遇到的各類風險。需要説明的是，<strong>上面以及後面指的「複用性風險」，定義為「由於不合理的複用決策，導致依賴和複雜度膨脹過快，從而導致軟件維護成本過高」的問題，</strong>除了成本風險外，由於複用組件的不合理使用或存在的缺陷而導致的兼容性、安全性、性能等方面的風險，其風險更為顯著和易於治理，因此不是本文論述的重點。此外，複用開發過程中的開發目標偏移、迭代和發佈計劃的延期、人員短缺等風險，限於篇幅也不在這裏展開。</p><p style="text-align:justify">第二部分首先會介紹導致「複用提升軟件開發效率」這一原則失效的幾類主要原因，第三部分會重點介紹用於評估複用性的若干工具，有了對複用性本質的認識後，再第四部分我們會簡要介紹複用性風險管理模型。</p><span id="OSC_h3_4"></span><h3>二、複用性風險根因分析</h3><span id="OSC_h4_5"></span><h4><strong>2.1 現實挑戰：正確和錯誤的抽象</strong></h4><p style="text-align:justify">我們複用組件的一個初衷，除了是為了提升研發效率之外，也是希望可複用組件可以將領域的複雜性隔離在一個我們永遠看不到的地方，從而整體降低組件使用方的系統複雜度。因此，一個可複用的組件，無論其規模大小，其設計過程就是對某個領域高度抽象的過程。在設計組件時，向上面對當前或潛在的需求，需要我們做一定的前向通用設計，向下儘可能屏蔽掉組件的實現細節，抽象的結果直接決定了後續該組件可複用性程度的高低（可複用性的度量將在下一個章節詳述）。但遺憾的是，良好的抽象能力對於大部分開發者來説是一個稀缺的產物，它需要對問題進行清晰的定義、簡化和分解，同時識別和利用通用模式，將子問題的解法組合起來形成一個整體解決方案，依賴對設計模式、開源的庫和框架、數據結構和算法以及大量生產項目的長期實踐和思考。</p><p style="text-align:justify">在日常的代碼中，我們不乏抽象，但大部分都是不合理的抽象。錯誤的抽象造成的危害甚於不抽象，比如常見的一個現象：對設計模式的適用範圍知之甚少，僅僅為了炫技而濫用設計模式，導致代碼的可讀性和可維護性下降。</p><p style="text-align:justify">除了對抽象能力的要求外，很多時候需求緊迫度、開發資源、責任心以及組件所在領域職責的變更等因素，都會導致可複用組件從出生就帶着「高成本」的原罪，其後續的使用成本和維護成本會急劇上升，這裏就不一一展開了。</p><span id="OSC_h4_6"></span><h4><strong>2.2 認知謬誤：複用不是設計目標</strong></h4><p style="text-align:justify">一個對於複用性的認知謬誤就是，把「不重複」等效為「複用」，這兩個概念之間有相似之處，但還是有一些微妙的差別。「不重複」即我們所熟知的 DRY 原則（Don’t Repeat Yourself），其目標是通過減少重複建設從而避免承擔副本不一致的維護成本，而 Reusability 是從所有代碼中找到重複的部分，然後在複雜度可控的前提下，努力抽象出可複用的東西。一堆不重複的代碼，並不代表存在可複用的組件。</p><p style="text-align:justify"><strong>複用只是實現不重複目標的一種手段，「不重複」才是我們設計軟件系統時的目標，單純追逐「複用性」很多時候會出現一些本末倒置的現象。</strong>如出現了一些接入成本非常高的自動測試框架、業務中台框架，一味追逐「（我）一次開發，（你）隨處使用」，殊不知在使用方需要消耗大量的精力去內化框架設計者的設計初衷，面對十幾個接入參數或配置文件一籌莫展。</p><p style="text-align:justify">舉個例子，偶爾會看到我們在業務層代碼中，部分同學會把簡單的新增和修改邏輯抽象為一個方法，美其名曰「提供給接入層複用」，如下面的 insertOrUpdate 方法中，初看是複用了領域對象轉換和用戶對象是否存在的代碼，符合 DRY 原則，但實際上卻是混用了兩個不同的業務語義，會給後續的維護帶來較高的成本，如變更用戶信息時，需要做更個性化的用戶屬性處理，這時候調整領域對象轉換處的代碼，將會影響新增邏輯。</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-3c8e7289db213680d7aa473520b964c9_720w.webp" referrerpolicy="no-referrer"></p><p>更合理的實現是，將明顯不同語義的代碼進行拆分，雖然看上去存在一定程度上的代碼重複，但其設計會更利於後續的功能迭代，也更符合代碼的「單一職責」設計原則。</p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-5f8500b6ba012049c89989be0edced10_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_7"></span><h4><strong>2.3 決策偏差：複用的決策權在哪</strong></h4><p style="text-align:justify">代碼的複用更多的時候是軟件開發者自發完成的，但我們無法忽視的一點是，如何集成、是否複用、如何複用、是否是同一個功能、使用什麼粒度的複用，很多時候是由業務架構決定的，「康威定律」還是無法迴避的。</p><p style="text-align:justify">比如，在一個新的場景裏，產品要求把「PPT 上與其名字相同的一個功能」進行復用，以快速上線，雖然他們除了名字相同，其產品形態、業務流程、環境依賴等都不一樣。最終強行「複用」的結果就是代碼邏輯裏出現了大量的分支判斷，底層技術架構變得臃腫。由於對於領域的理解不同，出現這種情況在所難免。雖然很多時候軟件複用的決策權並不在開發者這裏，但出於技術情懷也好，責任心也罷，開發者有義務去做這種糾偏，最大程度地消除這種差異性。但需要認識到技術的作用在這裏並不是決定性的，卓越的技術是複用成功的必要非充分條件。</p><span id="OSC_h4_8"></span><h4><strong>2.4 工具缺失：如何計算複用成本</strong></h4><p style="text-align:justify">複用性度量，主要分為兩個部分：</p><p style="text-align:justify">1.複用度：決定一個組件複用性高低水平的因素有哪些？</p><p style="text-align:justify">2.複用成本：組件集成方、組件所在的組織，決定實行復用策略後的 ROI 如何計算？</p><p style="text-align:justify">通過複用度和複用成本兩個指標，我們可以進行一定程度上的複用性定量分析，做出更為長遠的技術決策。比如，可以瞭解到一個複用性高的組件，其特徵有哪些？引入一個新的第三方組件時，除了基礎的功能性組件外，我還需要考慮哪些？相較於使用已經存在的組件，是否考慮重新造一個輪子？「複用」和「造輪子」間成本有多大？關於複用性的度量工具，第三部分將重點論述。</p><span id="OSC_h3_9"></span><h3>三、複用性的形式化度量</h3><span id="OSC_h4_10"></span><h4><strong>3.1 組件度量：可複用水平的評估</strong></h4><p style="text-align:justify">我們在設計一段代碼/一個類/一個模塊等可複用的組件時，一些可衡量的軟件指標共同決定了組件的可複用性水平的高低。這些指標包括：可靠性（Reliability）、可讀性（Understandability）、可維護性（Maintainability）、通用性（Generality）與可遷移性（Portability），如下圖所示。每一個指標可由各類代碼度量屬性決定，如組件的可遷移性由「組件的獨立性」和「耦合性」兩個屬性決定，大部分的度量屬性都是可以通過形式化定義並計算出來。不同指標的決定因子及度量值（括號中）如下：</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-ae30c926a96772aa3e71efcc921e9e0e_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">1.<strong>可靠性：</strong>性能（響應時間）、容錯程度（恢復時間）；</p><p style="text-align:justify">2.<strong>通用性：</strong>類泛化水平（子類實例個數或接口實現類個數）；</p><p style="text-align:justify">3.<strong>可讀性：</strong>內聚性（類之間耦合度）、複雜度（圈複雜度）、規模（代碼行數）、文檔水平（數量+完整度）；</p><p style="text-align:justify">4.<strong>可維護性：</strong>易於修改、單測和迴歸測試（測試覆蓋度）、組件的獨立性（依賴數）、耦合性（類間耦合度）；</p><p style="text-align:justify">5.<strong>可遷移性：</strong>組件的獨立性（依賴數）、耦合性（類間耦合度）。</p><p style="text-align:justify">為了度量整個組件的的可複用性，有必要定義一個可複用性計算模型。該模型基於上圖所示的複用性屬性模型。主要的可複用性屬性、影響這些屬性的因素以及度量這些因素的量度之間的關係顯示在這個模型中。理論上，軟件組件的可複用性 (用&nbsp;<em>Reusability</em>&nbsp;表示) 可以用表達式來計算：</p><p style="text-align:justify"><em>Reusability = w1*M + w2*R + w3*P + w4*U + w5*G</em></p><p style="text-align:justify">其中&nbsp;<em>w1 ~ w5</em>&nbsp;為不同指標的權重值，指標&nbsp;<em>M（Maintainability）、R（Reliability）、P（Portability）、U（Understandability）、G（Generality）</em>&nbsp;值進行歸一化（0 ... 1）後，乘以每個指標不同的權重值，通過計算得到最終的組件的可複用度。</p><p style="text-align:justify">在上面的分析過程中，存在部分度量無法進行定量分析的情況，但不同因子組合計算還是有意義的，我們可以拿這些指標去評估我們目前的系統，存在的問題的嚴重程度。當下次別人問我們為什麼要複用組件 A 而不是組件 B 時，我們可以給出更令人信服的理由，而不僅僅是「我覺得」、「A 比 B 好很多」等論述。</p><span id="OSC_h4_11"></span><h4><strong>3.2 組織度量：複用的投入產出比</strong></h4><p style="text-align:justify">對組件的複用性有了一個感性認知後，更加一步地，讓我們從經濟的角度去思考複用性背後的成本問題。首先，我們先定義幾個變量&nbsp;<strong>RL、NUC、RCR、RCWR</strong>。</p><ul><li><strong>RL（Reuse Level）</strong>：可複用組件在應用中的比例，即 RL=複用的組件中代碼行數/應用總的代碼行數；</li><li><strong>NUC（Not Use Cost）</strong>：應用開發過程中完全不使用可複用組件的成本，注意不包括後續的維護成本；</li><li><strong>RCR（Relative Cost of Reuse）</strong>：複用既有的組件與重新造一個相似的輪子，這兩者之間工作量的比值，一般在 0.03~0.4 之間，經驗值為 20%，即這意味着複用所花費的成本大約是編寫新組件所投入的 20%；</li><li><strong>RCWR（Relative Cost of Writing for Reuse）</strong>：開發可複用的組件與開發一次性使用的模塊，這兩者之間工作量的比值，一般在 1.0~2.2 之間，經驗值為 1.5，即這意味着編寫可複用軟件需要大約 50% 的額外成本。</li></ul><p style="text-align:justify">對於集成方而言，可以計算因複用節省的成本（DCA，Development Cost Avoidance）以及複用後的成本節省比佔比（ DCAR，Development Cost Avoidance Ratio）：</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-ac493599b0c28acc0e45e8e36f988186_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">舉例，如果複用度 RL = 40%， RCR = 0.2，則軟件集成方節約成本佔比 = 0.64，即節省了 64% 的成本。同時我們可以得到一個簡單的結論，對於組件的集成方來説，如果想要提升成本佔比，則需要：<strong>可複用組件在項目中的複用度越高越好，同時可複用組件的 RCR 應較低。</strong>這意味着可複用組件拓展性、可讀性需要保持在一個較高的水平，這樣集成方在集成時的二次開發和適配成本會較低，這個結論也是契合我們研發時的直覺的。</p><p style="text-align:justify">對於組織而言，假如某可複用組件的 N 個場景被使用了，則組織複用收益 OROI 可計算如下：</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-6d2fc9255a7e8362245fea5bbc0424ab_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">舉例：如果複用度 RL = 40%，RCR = 0.2，RCWR = 1.5，複用次數為 5 次，則，組織收益 OROI = 167%，這意味着開發一個可複用的組件，同時在多個場景進行復用，是有超額回報的。但是不是隻要複用了就會有收益呢？另 OROI = (N*(1-RCR) - RCWR)/RCWR &gt; 0 可以得到 N &gt; RCWR/(1-RCR)，帶入上面預設的 RCR = 0.2，RCWR = 1.5 這兩個值，得到 N &gt; 2，這意味着需要兩個或兩個以上的場景複用了此組件，我們此次研發活動才會取得正向的收益。與此同時，我們可以從上面的公式得到以下幾個關於提升組織複用 ROI 的結論：<strong>可複用組件在項目中複用度越高越好，開發可複用組件時，RCWR 和 RCR 越低越好。</strong>RCWR 低意味着不要去過度設計，組件的泛化性需要在領域內得到一定的控制，RCR 低意味着可複用組件可讀性好、拓展性高，集成時的成本不高。</p><p style="text-align:justify">馬丁·福勒（Martin Fowler）在《重構》一書提出了一條代碼重構經驗法則「Rule of Three 」，即我們可以複製和粘貼一次代碼，但是當複製相同的代碼三次時，應將其提取到新過程中進行抽象以便於複用，法則裏面的最小重複次數 3，其值亦符合上述 N &gt; RCWR/(1-RCR) 的結論。</p><span id="OSC_h4_12"></span><h4><strong>3.3 重複度量：複用和複製的邊界</strong></h4><p style="text-align:justify">回到我們第二節中所提到的問題：為什麼説 DRY 原則不等價於複用？假設以下場景：1. 項目中設計了全局的字符串常量類，所有的公共常量都放在此處，其他模塊中的類都引用此常量，這是一個好的實踐嗎，是不是定義模塊內的常量類或類中的常量字段會更好？2. 我需要進行字符串判重邏輯，是自己重寫一個字符串工具類，還是直接使用如 commons-lang 或 guava 包中的代碼呢？上面的場景都沒有絕對的答案，但就我目前看到的情況來看，在很多開發者的編碼習慣中，因為過度去追逐「複用性」，出現了一些沒有必要的依賴負擔，如使用全局常量類，出現沒必要的類加載，第三方包的隨意使用，造成應用包膨脹或者集成時的包衝突問題。<strong>有時候，複製一些類似的代碼比嘗試泛化再實例要好得多，過度使用抽象只會模糊真正關鍵的問題。</strong></p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-0ce4791fa1d8b3d3c325d20da80465f7_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">那什麼時候可以複製，什麼時候不建議呢？除了 2.2 中提到的語義不一致時的適度複製（就不是複用），當我們真實使用的代碼佔可複用組件整體代碼邏輯的比例較低時（譬如只使用了 commons-lang 包中的 StringUitls 類），可以考慮重寫一份，進行適度的複製粘貼，實現該處邏輯和集成方「自治」。對應前面的結論，這種情況下意味着 RL 較低，同時&nbsp;<strong>RCR 較高，比如 RL = 0.01，RCR = 0.8，則，軟件集成方節約成本佔比只有 RL*(1-RCR) = 0.2%</strong>，這一點收益同後續可能潛在的風險（包膨脹和包衝突）相比，複製可能是一個更好的選擇。</p><span id="OSC_h3_13"></span><h3>四、複用性風險管理模型</h3><p style="text-align:justify">有了前面兩個部分的鋪墊，我們再回頭去審視因為複用引入的成本風險，應該採取哪些措施能使得風險最小化呢？在業務風控和數據安全等泛信息安全的業務中，我們對風險管理的抽象，都會強調事前、事中、事後的風險控制流程。相似地，我們可以在代碼研發過程中，<strong>通過建立事前評估、事中緩釋及事後迭代的複用性風險管控手段</strong>，降低風險發生的可能性及其造成的影響，並根據業務架構和技術架構的發展趨勢採取規避、降低和轉移風險的措施，將風險控制到團隊可承受的水平之內，最大程度地避免或延緩因為複用導致的維護成本高、系統快速腐化等問題。</p><p style="text-align:justify">事前評估、事中緩釋、事後迭代形成的全生命週期複用性風險管理模型如下圖所示：</p><p style="text-align:center"><img src="https://pic2.zhimg.com/80/v2-68fe36560c29dea37111fa27bd2310e9_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h4_14"></span><h4><strong>4.1 事前評估：成本與啓發式決策</strong></h4><p style="text-align:justify">風控的事前階段（評估+分析），一般基於某些黑樣本出發，挖掘出適用於後續風險對抗階段的某些風險行為特徵或模型，並基於歷史樣本計算出準確率和召回率。在複用性風險的事前階段，我們也可以通過定性和定量的評估手段，儘早發現各種複用時的「壞味道」，立即予以糾正或防範，把風險消滅在萌芽狀態，避免因為錯誤的複用引入過多技術債。評估的流程主要分為：可複用組件評估、複用成本和收益的度量、啓發式決策這三個階段，具體地：</p><p style="text-align:justify">1.如果待複用的組件是已存在的，則可以計算或估算出已複用組件的可複用水平，考量的指標即上面提到的可靠性、可讀性、可維護性、通用性和可遷移性，不同場景的指標權重不一，可以結合具體場景進行判斷；</p><p style="text-align:justify">2.如果待複用的組件是需要新建的，則可以計算出後續集成節約的人力成本，以及中長期的時間裏組織通過複用組件獲取的整體收益，通過結合複用成本、複用收益、當前組織人力現狀、後續業務進行最終的決策；</p><p style="text-align:justify">3.如果步驟 1 和 2 都得不到一個最終的結論，下面還有一些啓發式的經驗幫助我們決定是否真的需要複用。</p><p style="text-align:justify"><strong>可能需要複用的場景</strong>（抽象組件或複用既有組件）：</p><p style="text-align:justify">1.待複用的業務邏輯非常專業，如 Json 序列化、加解密；</p><p style="text-align:justify">2.相同或相似業務語義的代碼已經存在多（3）處，需要重構；</p><p style="text-align:justify">3.待選的可複用組件文檔非常全面，易於接入、拓展、替換或移除；</p><p style="text-align:justify">4.業務邏輯變更頻繁，每次變更需要同時變更多個系統或模塊以保持同步；</p><p style="text-align:justify">5.需要即時共享且對不一致性容忍度較低的一些業務邏輯單元，如表的元信息。</p><p style="text-align:justify"><strong>可能無需複用的場景</strong>（那就再造一個輪子吧）：</p><p style="text-align:justify">1.沒有文檔，或文檔質量較差；</p><p style="text-align:justify">2.重複造一個不太難，同時維護成本較低；</p><p style="text-align:justify">3.只使用了可複用組件所有功能裏的很少一點邏輯；</p><p style="text-align:justify">4.要花費大量的時間去了解可複用組件的設計思路；</p><p style="text-align:justify">5.可複用組件在拓展新功能時，需要投入大量的精力去協同推進；</p><p style="text-align:justify">6.可複用組件集成時的適配或拓展代碼，比單獨重寫該組件的代碼還要多；</p><p style="text-align:justify">7.可複用的組件是整個應用的核心，且後續業務發展迅速有較多的定製需求；</p><p style="text-align:justify">8.可複用組件的產品文檔或系統設計中承諾了太多的功能（餅），過於「雄心勃勃」；</p><p style="text-align:justify">9.最後一點：如果決策時覺得可用可不用，那大概率也是不需要複用的，相信自己的第一判斷。</p><p style="text-align:justify">通過成本和收益估算，以及若干啓發式的決策經驗，大多數的場景我們都可以評估得到一個清晰的是否複用的答案。軟件複用可能會在短期內提高生產力，但它可能會產生長期後果，所以這一步需要慎之又慎。</p><span id="OSC_h4_15"></span><h4><strong>4.2 事中緩釋：HCLC&amp;測試&amp;文檔</strong></h4><p style="text-align:justify">事中緩釋階段是控制複用性風險的核心環節，它主要聚焦在可複用組件的開發階段，通過一系列的關鍵步驟將複用風險在開發或正式使用前儘可能地降低，主要包括下面幾個要點：</p><ul><li>高內聚低耦合</li><li>單元測試和迴歸測試</li><li>完整且有效的文檔化</li></ul><p style="text-align:justify"><strong>高內聚低耦合（HCLC）。</strong>這是一個老生常談的事情了，內聚和耦合會影響可複用水平中的多個指標，如是否內聚會影響可讀性和可遷移性，耦合會影響可維護性、可遷移性和可讀性。軟件工程中已經有很多設計原則或模式供我們選擇了，如在代碼開發階段，優先組合、依賴倒置、裏式替換、接口隔離、單一職責、開放封閉、23 種設計模式等，在架構設計階段，也有若干的架構設計模式或方法論，如分層、CQRS、異步事件驅動、領域驅動設計等。</p><p style="text-align:justify"><strong>完整且有效的文檔。</strong>「好的代碼是自解釋性的」，這句話不完全對。首先，無論是我們的架構設計抑或是代碼設計，很多東西是無法在代碼中體系出來的，如對於領域抽象的取捨、決策的思考過程等，即便是我們的的接口、成員變量、實現，其命名和設計過程已經到了一個非常高的水平，代碼中「隱藏信息」還是會損失，而註釋可以儘可能去彌補這部分損失。其次，需要認識到：人類的感知與溝通速度是很慢且低效的，需要通過文檔去填補雙方溝通時的這一道鴻溝。當然，這裏討論的是一般情況，依託「無文檔化」構建核心「競爭力」的行為模式不應歸入此類。最後，一個正常的組織，人員是會流失的，大部分人最終都會離開這個組織，可複用組件的關鍵設計者如果不在組織裏了，這種知識性的損失將是永久性的，文檔（註釋、設計）起到了一個備份領域知識的作用。</p><p style="text-align:center"><img src="https://pic3.zhimg.com/80/v2-865f007635a00f99fa6fbed28bc1075e_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify"><strong>單元測試和迴歸測試。</strong>複用理論之所以成立，出發點是我們希望使用已經存在的、成熟的軟件資產來提升研發效率，同時降低系統缺陷，一套全面的自動化迴歸測試，不僅有利於集成方，也會讓後續和此可複用組件相關的每一個人受益。如果我們開發的可複用組件沒有自動化的迴歸測試，那這樣的組件是不合格的，是不應該發佈公共倉庫的。缺少自動化測試或核心流程自動化測試覆蓋度較低的組件，對於集成方和組件後續的維護者來説是一場災難，它給系統引入的巨大的技術債甚於完全沒有配套文檔的可複用組件。</p><span id="OSC_h4_16"></span><h4><strong>4.3 事後迭代：捕捉領域變化&amp;組織</strong></h4><p style="text-align:justify">在開發可複用組件時，如果一開始就大刀闊斧地投入研發資源，最終可能會創建與直接需求無關的軟件資產，並由於設計、開發和測試時間的增加而產生重大的進度風險，相反，通過多次迭代改進可複用組件來降低這些風險，<strong>一個良好的組件、框架和軟件架構需要時間來設計、實現、優化、驗證、應用、維護和增強。</strong>與此同時，第一階段的開發和集成結束後，在迭代的過程中進行持續性的風險管理，可以使得可複用組件的風險保持在一個較低的水位，儘可能地延長組件的生命力，需要做的主要事項包括：持續捕捉領域變化以及相應的組織支持。</p><p style="text-align:justify"><strong>捕捉領域變化。</strong>上面提到了，代碼中有部分內隱的知識，事實上，<strong>一個可複用的組件就是開發者對於某個領域思考的結果</strong>，無論它是以類文件、模塊還是系統的方式呈現。而領域都是會變化的，變化包括：領域的邊界會拓展、領域內部分實體內涵會變化、不同領域之間的邊界會重疊或者融合等。領域變化後，如果在這其中的可複用組件沒有進行適當的調整，就會出現技術和業務配速失效的問題。可複用組件在封裝了領域知識的同時，也一定程度上屏蔽了複雜度，當組件不足以承擔起領域的實體或功能出現偏差時，就會出現「複雜度泄漏」的問題。</p><p style="text-align:justify">捕捉域變化的兩個關鍵動作：統一領域上下文以及關註上遊需求池。統一領域上下文重要性不言而喻，<strong>很多時候各方意見出現偏差的根本原因是大家沒有形成統一溝通的語言，無法簡單、準確且清晰地描述各自的訴求。</strong>我在進行某風險域架構治理時，做的第一件事情就是拉上了業產研三方，統一大家對「規則」和「策略」兩個概念的內涵和邊界的認知。其次，開發人員和架構師需緊密關注需求池，從需求本身出發，區分領域中可變性和通用性的關鍵來源。識別出問題域中的所有變化是不現實的，我們可以關注一些關鍵問題，如面對一個新的需求，可以考慮：</p><p style="text-align:justify">1.我們討論的概念是否一致？</p><p style="text-align:justify">2.該需求涉及哪些領域實體？</p><p style="text-align:justify">3.該需求是否需要有我們新增實體？</p><p style="text-align:justify">4.新增實體是否會與既有實體產生二義性？</p><p style="text-align:justify">5.之前是否存在類似的需求？有什麼不同？</p><p style="text-align:justify">6.新增的需求是否可以和既有的邏輯進行隔離？</p><p style="text-align:justify">7.......</p><p style="text-align:center"><img src="https://pic1.zhimg.com/80/v2-b4a6ff6154f2348778fd424cd86b6cfc_720w.webp" referrerpolicy="no-referrer"></p><p style="text-align:justify">是否有一種指導原則，可以讓我們在跟蹤這些域變化的時候，進行更合理的設計與取捨呢？熵增原理告訴我們：一個孤立的熱力學系統的熵不減。對於系統的可逆過程熵不變，不可逆過程熵增加。因此，類比軟件工程領域，在組件的事後迭代階段，<strong>一個儘可能消除代碼設計/軟件架構中熵增的設計原則：在既有組件中新增的功能點需要存在逆向的刪除機制</strong>，這樣就可以儘可能讓可複用組件跳出逐漸混亂無法維護的宿命。功能可逆的具體操作具體可以表現為：SPI 機制（Service Provider Interface ）、面向接口的編程、通過模塊隔離隨機的或一次性的需求等。</p><p style="text-align:justify"><strong>組織和配套的文化。首先，組織是業務架構的投射</strong>，當複用組件內的領域實體和組織負責的領域實體出現偏差時，就會出現因錯位產生的技術債，結果無非是兩種：一種是之前的可複用組件直接被拋棄，任由其自生自滅；另一種缺少破釜沉舟進行重構勇氣與擔當，既然不是我負責的，那就改一改重新用，原先統一均衡的結構會快速打破。<strong>其次，可複用組件和框架的好壞取決於構建和使用它們的人</strong>，我們需要能評估風險和機遇的管理者，需要能識別領域本質複雜度和偶然複雜度、同時能很好掌握設計模式和架構模式的架構師，以及，在開發原則、模式和實踐上經驗豐富的開發人員，組件是否可複用、可以複用多久，很大程度上是具備良好設計和經驗豐富的開發人員的副產品。<strong>再者，在事後迭代階段，我們需要專門的團隊或負責人為此可複用資產負責</strong>，不斷監控平台代碼庫的健康，跟蹤和修復錯誤，堅持正確抽象，不斷完善文檔。當然上述只是理想情況，更多的時候，這樣的人或團隊是不存在的，或者即便存在，相應的組織激勵也是缺失的，在一個沒有複用的文化土壤中，組件腐化只是時間問題。最後，有了正確的組織和優秀的人，長期的<strong>信心、熱情、激勵以及管理層的支持與響應</strong>，也都是成功的複用必不可少的條件。</p><p style="text-align:center"><img src="https://pic4.zhimg.com/80/v2-2228938440622697c56b0d0ace934f73_720w.webp" referrerpolicy="no-referrer"></p><span id="OSC_h3_17"></span><h3>五、關於複用的一點感想</h3><p style="text-align:justify">本文想重點去表達的幾個觀點：不要過度去追逐「複用」、可複用的水平以及複用投入產出比是可量化的、可複用資產是內隱的領域知識、適度的重複也是可接受的、文檔可以彌補領域知識的損失、架構演進中新增功能需可逆。</p><p style="text-align:justify">撰寫此篇文章的初衷，一方面源於近幾年來在指導新同學時，發現出現較多的「偽複用」現象，例如為了減少代碼，將共享的方法簽名放在接口中，形成「過程式接口」，另一方面，自己也寫過一些「為了複用」而設計的組件或模塊，從中間件到業務組件大概有十幾個了。但最近逐漸開始意識到，很多時候為了後續的可遷移性，一些架構或代碼層的的前向防禦性設計作用並不大，過度抽象反而是給使用方造成了一些理解上的困難。到底哪些真的需要複用，哪些可以妥協，梳理完這篇文章後，堅定了一部分想法（例如全程文檔化），也給一些既有觀念做了糾偏。</p><p style="text-align:justify">上面也一直在傳遞一個觀點，好的軟件資產是一個優秀團隊的副產品。當把複用的目光從軟件聚焦到人，我們自己身上，哪些是可以複用的，哪些又是平台或組織賦予我們的？去除掉那些光怪陸離的虛幻部分，不可變的部分又有哪些？授權後的高價值專利算一種，其有效期為二十年。思考過程中沉澱可能算另一種，它們或多或少且階段性地概述了當時的所思所想，無論內容是否全面、正確，也塗抹上了時光的顏色，這也是這篇文章產生的另一個動機。</p><p style="text-align:justify">作者｜齊光</p><blockquote><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fclick.aliyun.com%2Fm%2F1000373503%2F" target="_blank"><span style="color:#ff9900">點擊立即免費試用雲產品，開啓雲上實踐之旅！</span></a></strong></blockquote><p style="text-align:justify"><strong><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1364680%3Futm_content%3Dg_1000382902" target="_blank">原文鏈接</a></strong></p><p style="text-align:justify"><strong>本文為阿里雲原創內容，未經允許不得轉載</strong></p></div>
                                    ]]>
            </description>
            <pubDate>Fri, 03 Nov 2023 02:51:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/yunqi/blog/10140476</guid>
            <link>https://my.oschina.net/yunqi/blog/10140476</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[谷歌放棄 Web Environment Integrity API 提案]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">谷歌<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fincreasing-trust-for-embedded-media.html" target="_blank">宣佈</a>放棄其備受爭議的&nbsp;<span style="background-color:#ffffff">Web Environment Integrity API 提案，轉而開發&nbsp;</span><span style="background-color:#ffffff">Android WebView Media Integrity API。</span></span></p><p><span style="color:#000000">今年 5 月份，谷歌在開發者郵件列表中宣佈了其&nbsp;</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity%2Fblob%2Fmain%2Fexplainer.md%23goals" target="_blank">Web Environment Integrity API</a><span style="color:#000000">，旨在作為一種限制在線欺詐和濫用的方法，同時不會引發跨站點跟蹤或瀏覽器指紋識別等隱私問題。但卻遭受了公眾的強烈反對，認為其更類似於一種網站的數字版權管理（DRM）功能，擔心谷歌藉此限制網絡自由。</span></p><p><span style="color:#000000">因此在收到眾多反饋後，谷歌表示其&nbsp;<span style="background-color:#ffffff">Chrome 團隊不再考慮&nbsp;Web Environment Integrity API；並將重點轉向範圍更窄的解決方案 Android WebView Media Integrity API，僅針對應用程序中嵌入的 WebView。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">根據介紹，這個新的 API 只擴展了具有 Google 移動服務 (GMS) 的 Android 設備上的現有功能，並且沒有計劃提供超出嵌入式媒體（例如流媒體視頻和音頻）或 Android WebView 之外的功能。</span></span></p><p><span style="color:#000000"><img height="248" src="https://oscimg.oschina.net/oscnet/up-79bb6dbdddd857c0a5caad36bd7b735e59e.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">Android WebView API 允許應用程序開發人員顯示嵌入媒體的網頁，並增強對 UI 的控制和高級配置選項，以允許在應用程序中無縫集成。這為移動應用開發帶來了很大的靈活性，但同時也為欺詐和濫用提供了途徑；因為它允許應用程序開發人員訪問網頁內容，攔截或修改用戶與網頁的交互。</span></span></p><p><span style="color:#000000"><span style="background-color:#ffffff">新的 Android WebView Media Integrity API 旨在使嵌入式媒體提供商能夠訪問定製的完整性響應，其中包含設備和應用程序的完整性判定，以便他們能夠確保他們的流媒體在安全、可信的環境中運行，無論嵌入式應用程序是從哪個應用程序商店安裝的。</span></span></p><p><span style="color:#000000">谷歌方面計劃<span style="background-color:#ffffff">在明年初，與選定的嵌入式媒體供應商一起試點實驗性 Android WebView Media Integrity API。</span></span></p><p><span style="color:#000000">詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-developers.googleblog.com%2F2023%2F11%2Fincreasing-trust-for-embedded-media.html" target="_blank">查看官方博客</a>。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Thu, 02 Nov 2023 04:01:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/264883/google-abandons-web-environment-integrity-api</guid>
            <link>https://www.oschina.net/news/264883/google-abandons-web-environment-integrity-api</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
    </channel>
</rss>
