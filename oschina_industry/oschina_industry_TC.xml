<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Wed, 28 Feb 2024 12:28:41 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[零一萬物發佈 Yi 大模型 API 並啓動公測，支持上下文 200K]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">零一萬物通過其微信公眾號<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkSdGJh0xro9vm_LDDhMhgQ" target="_blank">宣佈</a>，經過一段時間的開發和內測正式發佈 Yi 大模型 API，同時啓動邀測。目前，Yi 大模型 API 邀測名額限量開放中，申請成功即送 1000 萬&nbsp;tokens。</span></p><p>此次邀測提供了兩種模型：</p><ul><li>Yi-34B-Chat（0205）：支持聊天、問答、對話、寫作、翻譯等功能。</li><li>Yi-34B-Chat-200K：200K 上下文，多文檔閲讀理解、超長知識庫構建小能手。</li></ul><h4><strong>模型優勢</strong></h4><ul><li><strong>超長上下文</strong></li></ul><p>本次重磅出台 Yi-34B-Chat-200K API，加速大模型應用進入「長文本時代」。200K 支持處理約 20～30 萬個中英文字符（例如，可以輕鬆處理整本《哈利•波特與魔法石》小説），適合用於多篇文檔內容理解、海量數據分析挖掘和跨領域知識融合等，為各行各業提供了極大的便利。例如，金融分析師可以用它快速閲讀報告並預測市場趨勢、律師可以用它精準解讀法律條文、科研人員可以用它高效提取論文要點、文學愛好者可以用它快速掌握作品精髓等，應用場景非常廣泛。</p><p>例如，以下是 Yi-34B-Chat-200K 對經典文學作品《呼嘯山莊》進行復雜角色和角色關係的歸納總結，該小説篇幅龐大（中文字數約 30 萬字），且人物關係錯綜複雜，但它仍能精準地梳理和總結出人物之間的關係，展示了它在處理超長上下文時出色的複雜內容理解和分析能力。</p><p><img alt="" height="605" src="https://oscimg.oschina.net/oscnet/up-8036e1fcb930944e32404b4d2a35bd4bc33.png" width="300" referrerpolicy="no-referrer"></p><ul><li><strong>出色的指令遵循和創意內容生成能力</strong></li></ul><p>此前，零一萬物發佈並開源了 Yi-34B-Chat（1123），它的回覆風格符合人類偏好，但在指令遵循上結果不夠穩定。而此次新發布的 Yi-34B-Chat（0205）經過深度優化，性能得到大幅提升，不僅繼承了符合人類偏好的回覆風格，很擅長創意性內容創作，而且能夠更好地理解複雜的用戶需求，遵循多約束指令（指令遵循能力提升了近 30%），穩定生成指定格式的內容。</p><p>例如，以下是兩個版本在指令遵循方面的測評對比。</p><p><strong>Prompt 1: 幫我輸出一個俄國作家的書單，以 JSON 格式輸出一個的 list，其中每一個 item 都要有兩個 key，分別是書名和作家名字，請列出 3 本不同的書</strong></p><p><strong><img alt="" height="336" src="https://oscimg.oschina.net/oscnet/up-2d761ddabb83b7d03ee21cc74072f2431e1.jpg" width="500" referrerpolicy="no-referrer"></strong></p><p>Yi-34B-Chat（1123）輸出的 JSON 文件格式略有不足（例如，第 8 行和第 12 行的引號），而 Yi-34B-Chat（0205）輸出的 JSON 文件格式全部正確。</p><p><strong>Prompt 2: 判斷下面這段話的情緒傾向，如果是正面的，回覆數字 1；如果是負面的，回覆數字 0：</strong></p><p><strong>這款手機真是物超所值，性能強大，電池續航長，外觀設計也很有檔次。我用了幾個月，到現在還像新的一樣。</strong></p><p><img height="169" src="https://oscimg.oschina.net/oscnet/up-e185cce9ff54b8737e02470009fe90a8d31.png" width="500" referrerpolicy="no-referrer"></p><p>Yi-34B-Chat（1123）雖然理解了問題，但是沒有完全遵循指令，輸出了較多冗餘的分析。而 Yi-34B-Chat（0205）理解了問題，且正確遵循了用戶指令。</p><h4><strong>API 優勢</strong></h4><ul><li><strong>推理速度快</strong></li></ul><p>為了提升 API 性能，團隊在 API 側進行了推理優化，因此 Yi-34B-Chat 系列 API 具備較快的推理速度，這不僅縮短了處理時間，同時也保持了出色的模型效果。此外，優化的 API 接口顯著降低了模型回覆的延遲，進一步提高了用戶體驗的流暢性和響應速度。</p><ul><li><strong>兼容 OpenAI</strong></li></ul><p>Yi 大模型 API 與 OpenAI API 完全兼容，你只需修改少量代碼，可以平滑遷移，即刻享受 Yi 大模型的超凡魅力。</p><pre><code>
import openai
from openai import OpenAI

API_BASE = "https://api.lingyiwanwu.com/v1"
API_KEY = "{{your key}}"

client = OpenAI(
    # defaults to os.environ.get("OPENAI_API_KEY")
    api_key=API_KEY,
    base_url=API_BASE
)
completion = client.chat.completions.create(
    model="yi-34b-chat-200k",
    messages=[{"role": "user", "content": "Hi, who are you"}]
)
print(completion)</code></pre></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 10:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280668</guid>
            <link>https://www.oschina.net/news/280668</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[WordPress 母公司 Automattic 計劃出售數據給 OpenAI 等 AI 公司]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.404media.co%2Ftumblr-and-wordpress-to-sell-users-data-to-train-ai-tools%2F" target="_blank">404 Media 的一份報告顯示</a></u>，Tumblr 和 WordPress.com 的所有者正在與人工智能公司 Midjourney 和 OpenAI 進行談判，以提供從用戶帖子中抓取的訓練數據。</p><p><img height="1268" src="https://oscimg.oschina.net/oscnet/up-876500a00ea4d490602adc6cf3a01127f29.png" width="2282" referrerpolicy="no-referrer"></p><p>這份來自公司內部匿名消息人士的報告稱，Automattic 與兩家人工智能公司之間的交易「迫在眉睫」。過去一週，Tumblr 上流傳着一些模糊的謠言，暗示與 Midjourney 的交易可能會為該網站帶來新的收入來源。</p><p>根據報告，Automattic 計劃在週三<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fautomattic.com%2F2024%2F02%2F27%2Fprotecting-user-choice%2F" target="_blank">推出一項新設置</a></u>，「允許用戶選擇不與包括人工智能公司在內的第三方共享數據」。</p><p>但它引用的內部帖子表明，該公司抓取了一份「初始數據轉儲」，其中包含「2014 年至 2023 年間 Tumblr 的所有公開帖子內容」，其中包括不會在博客上公開可見的內容——Automattic 稱是錯誤抓取。目前尚不清楚這些數據做了什麼，以及哪些數據已發送到 Midjourney 和 OpenAI。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 09:31:52 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280659/tumblr-and-wordpress-to-sell-users-data-to-train-ai-tools</guid>
            <link>https://www.oschina.net/news/280659/tumblr-and-wordpress-to-sell-users-data-to-train-ai-tools</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[在 Zoom 會議中協作處理文檔：適用於 Zoom 的 ONLYOFFICE 協作空間 app 現已發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">對 Zoom 用戶的好消息！用於 Zoom 的應用程序現已發佈，可使用 ONLYOFFICE 協作空間在 Zoom 中編輯和協作辦公文件。請閲讀本文了解詳情。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/01/10155146/ONLYOFFICE-DocSpace-app-for-Zoom-available.png" referrerpolicy="no-referrer"></p><h2><strong>為</strong><strong>文檔協作</strong><strong>而生</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">用於 Zoom&nbsp;的 ONLYOFFICE 協作空間 app 可以讓您直接在 Zoom 會議中，與其他人一起處理文件：</p><ul><li>創建、上傳和共享有編輯或實時查看權限的文檔。</li><li>使用兩種共同編輯模式（修訂、評論）與其他參與者實時協同編輯文檔、工作表、幻燈片。</li><li>使用集成的 AI 助手生成、總結和翻譯文本。</li><li>討論並填寫複雜的在線表格，如銷售協議或合同。</li><li>查看 PDF 文檔，添加註釋、註釋、繪圖。</li><li>將 Zoom 會議期間編輯的文件存儲在協作房間中，並隨時隨地查看它們。</li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="在 Zoom 會議中協作處理文檔：適用於 Zoom 的 ONLYOFFICE 協作空間 app 現已發佈" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/28095320/16.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">此外，在第一次 app 授權後會創建&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocspace.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddocspace_zoom" target="_blank"><u>ONLYOFFICE 協作空間</u></a>賬號，您可以用它來高效管理會議的文件：</p><ul><li>管理文件，併為工作文檔創建協作或自定義房間。</li><li>設置靈活的訪問權限：編輯、評論、審閲或僅查看。</li><li>創建公共房間，讓外部人員也能訪問您的文檔。</li></ul><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="在 Zoom 會議中協作處理文檔：適用於 Zoom 的 ONLYOFFICE 協作空間 app 現已發佈" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/28095314/13.png" referrerpolicy="no-referrer"></p><h2><strong>完全免費</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">使用新發布的 app、創建協作空間帳戶都是免費的。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">此外，在&nbsp;<strong>2024 年 8 月 1 日前</strong><strong>，</strong><strong>通過 Z</strong><strong>oom</strong><strong><span>&nbsp;</span>註冊</strong><strong><span>&nbsp;</span>ONLYOFFICE 協作空間</strong>的用戶都可以獲得以下福利：</p><ul><li>100 個管理員用戶</li><li>100 個房間</li><li>100 GB 磁盤空間</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">注：本福利方案有效期為 6 個月（自注冊之日起）。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">如果您有一個龐大的團隊，需要更多的管理員或更大的存儲空間，可以選擇<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocspace-prices.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddocspace_zoom" target="_blank"><u>協作空間專業版</u></a>，它只需要為具有擴展權限的管理員和高級用戶付費，可免費添加其他普通用戶。</p><h2><strong>快速</strong><strong>上手</strong><strong>和使用</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>1.</strong>登錄您的 Zoom 賬戶。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>2.</strong>在「應用程序」板塊安裝 ONLYOFFICE 協作空間，並允許請求的應用程序權限。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>3.</strong>開始會議，切換到「應用程序」選項卡，然後啓動 ONLYOFFICE 協作空間 app。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>4.</strong>從列表中選擇所需的文件來開啓協作。您可以給其他參會者授予「編輯」或「實時查看」權限。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="在 Zoom 會議中協作處理文檔：適用於 Zoom 的 ONLYOFFICE 協作空間 app 現已發佈" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/28095308/14-2.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>5.</strong>會議結束後，可在相應的 ONLYOFFICE 協作空間房間中查看文件的更改。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="在 Zoom 會議中協作處理文檔：適用於 Zoom 的 ONLYOFFICE 協作空間 app 現已發佈" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/28095325/15.png" referrerpolicy="no-referrer"></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:center"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.zoom.us%2Fapps%2FOW6rOq-nRgCihG5eps_p-g" target="_blank">免費獲取應用程序</a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>注</strong>：ONLYOFFICE 協作空間 app 與 Zoom 桌面應用程序也兼容。</p><h2><strong>常見問題</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>我需要在</strong><strong>哪裏</strong><strong>註冊才能使用該 app 嗎？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">不用。當您開始使用該應用程序時，系統會根據您的 Zoom 數據（帳戶 ID、姓名、電子郵件）自動創建一個免費的協作空間帳戶。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>在創建的 ONLYOFFICE<span>&nbsp;</span></strong><strong>協作</strong><strong>空間帳戶中可以做什麼？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">您可以創建協作、自定義和公共房間、邀請用戶、編輯各種文檔、使用存儲空間。<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelpcenter.onlyoffice.com%2Fuserguides%2Fdocspace-index.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddocspace_zoom" target="_blank"><u>查看功能指南</u></a></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>如果我已經有</strong><strong>協作</strong><strong>空間</strong><strong>帳戶怎麼辦？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">您也可以使用該應用程序，但是月也會創建一個新的協作空間帳戶，因為第一個應用程序版本不支持帳戶同步。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>這種集成是免費的嗎？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">用於 Zoom 的 ONLYOFFICE 協作空間的應用程序完全免費。創建的協作空間帳戶也是免費版本，如有必要，可以切換到<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocspace-prices.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddocspace_zoom" target="_blank"><u>專業版協作空間</u></a>。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>會議結束後如何找到編輯</strong><strong>過</strong><strong>的文件？</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">在協作會話期間對一個或多個文件所做的所有更改，都保存在自動創建的名為&nbsp;Zoom Collaboration_date_time 的協作房間中。</p><div><h3><strong>相關鏈接</strong></h3><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.zoom.us%2Fapps%2FOW6rOq-nRgCihG5eps_p-g" target="_blank">用於 Zoom 的 ONLYOFFICE 協作空間 app</a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelpcenter.onlyoffice.com%2Fintegration%2Fgettingstarted-zoom.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddocspace_zoom" target="_blank">相關指南</a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocspace.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddocspace_zoom" target="_blank">ONLYOFFICE 協作空間</a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fall-connectors.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddocspace_zoom" target="_blank">查看所有的 ONLYOFFICE 集成</a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 09:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280658</guid>
            <link>https://www.oschina.net/news/280658</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[華為發佈通信行業首個大模型]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">2 月 26 日至 2 月 29 日舉行的世界移動通信大會（MWC24）期間，華為發佈了由其自主研發的服務於通信行業的大模型。</span></p><p><span style="color:#000000"><img height="282" src="https://oscimg.oschina.net/oscnet/up-7be3f3a47ce7d8c9ff61ba6653dd16045d4.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">根據介紹，華為通信大模型是一款基於人工智能的商用大模型，提供關鍵的智能化技術能力，用於優化通信網絡性能、智能調度資源等，旨在實現在 5G 技術基礎上演進而來的 5G-A 時代智能化目標。</span></p><p><span style="color:#000000">華為董事、ICT 產品與解決方案總裁楊超斌介紹，華為通信大模型支撐運營商智能化目標，面向不同角色，提供智能語言交互能力，提升員工知識水平和工作效率；面向不同運營運維場景，提供智能體應用，分析拆解複雜流程，編排操作方案，確保用戶體驗和滿意度。</span></p><p><span style="color:#000000">華為通信大模型具有眾多典型場景實踐。如在敏捷業務發放案例中，通過放號助手的多模態精準評估，實現了快速用戶放號；在用戶體驗保障案例中，通過大模型的尋優能力，實現了多目標體驗保障；在輔助排障場景下，跨流程的質差分析和對話輔助處理，顯著改善了故障處理效率。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 08:31:36 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280646</guid>
            <link>https://www.oschina.net/news/280646</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OpenAI 稱《紐約時報》曾僱人入侵 ChatGPT]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">OpenAI 要求駁回《紐約時報》於去年 12 月對其提起的版權訴訟的大部分內容，指控《紐約時報》花錢請人入侵 OpenAI 的產品，以在該案中製造誤導性證據。《紐約時報》曾起訴 OpenAI 和微軟公司，稱這兩家公司非法使用其受版權保護的材料來訓練 AI 模型，分流了《紐約時報》網站的流量。</span></p><blockquote><p><span style="color:#000000">「《紐約時報》投訴中的指控不符合其著名的嚴格新聞標準。隨着本案的進展，真相將水落石出，那就是《紐約時報》花錢僱人入侵了 OpenAI 的產品。他們花了數以萬計的嘗試，才產生了構成原告證據 J 的高度反常的結果。他們只有通過使用公然違反 OpenAI 使用條款的欺騙性提示，瞄準並利用一個漏洞（OpenAI 已承諾解決該漏洞），才能做到這一點。即便如此，他們還不得不向該工具提供他們想要獲取的文章的逐字段落，而這些文章幾乎都已出現在多個公共網站上。正常人不會以這種方式使用 OpenAI 的產品。」</span></p></blockquote><p><img height="259" src="https://oscimg.oschina.net/oscnet/up-3b5642691a2dd2818f5e24e4c20c0da1846.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">OpenAI 認為，與投訴中的指控相反的是，ChatGPT 無論如何都不能替代《紐約時報》的訂閲。因為在現實世界中，人們不會也不能為此目的使用 ChatGPT 或任何其他 OpenAI 產品。</span></p><p><span style="color:#000000">且《紐約時報》近年來一直在跟進 OpenAI 聊天機器人的發展，卻從未提出過任何有關版權侵權的擔憂。OpenAI 聲稱，他們在 2020 年就披露了《紐約時報》的文章被用於訓練其 AI 模型的這一事實，但該報卻在 ChatGPT 於 2022 年首次亮相後人氣爆棚時才開始關心此事，提起訴訟要求賠償數十億美元。</span></p><p><span style="color:#000000">OpenAI 還回應了《紐約時報》對 ChatGPT 提供付費文章訪問權限的擔憂；表示這種只是一個"罕見的錯誤"，目前正在努力修復中。並聲稱，"《紐約時報》沒有完整闡述所有的全部故事。"</span></p><p><span style="color:#000000">對此，《紐約時報》的首席法律顧問 Ian Crosby 則<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farstechnica.com%2Ftech-policy%2F2024%2F02%2Fopenai-accuses-nyt-of-hacking-chatgpt-to-set-up-copyright-suit%2F" target="_blank">反駁稱</a>，OpenAI 離奇地將《紐約時報》尋求證據的行為誤解成了黑客行為。並補充稱，OpenAI 的抄襲規模遠遠大於起訴書中 100 多個示例。「開發新產品不能成為違反版權法的藉口。」</span></p><p><span style="color:#000000">詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffingfx.thomsonreuters.com%2Fgfx%2Flegaldocs%2Fbyvrkxbmgpe%2FOPENAI%2520MICROSOFT%2520NEW%2520YORK%2520TIMES%2520mtd.pdf" target="_blank">查看完整文件</a>。</span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><a href="https://www.oschina.net/news/274916/openai-and-journalism" target="_blank">OpenAI 稱《紐約時報》的版權訴訟毫無根據</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 07:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280623/openai-new-york-times-lawsuit-hackin</guid>
            <link>https://www.oschina.net/news/280623/openai-new-york-times-lawsuit-hackin</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[螞蟻百靈大模型推出 20 億參數遙感模型 SkySense]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">螞蟻百靈大模型推出了 20 億參數多模態遙感基礎模型 SkySense，這也是螞蟻在多模態領域最新的研發成果。公開資料顯示，SkySense 由螞蟻 AI 創新研發部門 NextEvo 與武漢大學聯合研發。</span></p><p><span style="color:#000000">SkySense 在總計 17 項國際權威公開數據集進行了測評，其測試任務類型包括了土地利用監測、高分辨率目標識別、地物變化檢測等 7 種常見遙感感知任務，並與國際上已發佈的包括 IBM 和 NASA 聯合研發的 Prithvi 等共 18 個全球主流同類模型做了測試結果比較。</span></p><p><span style="color:#000000">數據顯示，在 17 項測評中 SkySense 均名列第一。比如，在國際高清遙感地物檢測榜單 FAIR1M 2.0 中，SkySense 平均精度（mAP）領先第二名超 3%。</span></p><p><span style="color:#000000"><img height="417" src="https://oscimg.oschina.net/oscnet/up-30d9098a9be808fb8043382fec2a6d88bcc.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">在螞蟻百靈大模型多模態能力支持下，研發人員基於內部構建的 19 億遙感影像數據集進行預訓練，得到了 20.6 億參數量的模型 SkySense。這也是迄今為止國際上參數規模最大、覆蓋任務最全、識別精度最高的多模態遙感大模型。</span></p><p><span style="color:#000000">目前 SkySense 可廣泛應用於城市規劃、森林保護、應急救災、綠色金融、農業監測等重要領域，目前通過螞蟻內部 MEarth 平台提供數據與識別服務。&nbsp;</span></p><p><span style="color:#000000">據瞭解，螞蟻集團正在計劃開放 Skysense 模型參數，與行業共建，促進智能遙感技術與應用發展。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 06:15:40 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280605</guid>
            <link>https://www.oschina.net/news/280605</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[又一家硅谷明星公司誤刪庫了]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>之前我們連續分析了兩起誤刪庫事件，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FShYpGMwrqige2bvmfO8ZRg" target="_blank">Linear 刪庫</a>，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FY7qAaYt2uIylqlPve9DGzg" target="_blank">GitLab 刪庫</a>。就在我們準備讓這個主題告一段落時，業界又發生了一起刪庫事件。</p><p><img src="https://oscimg.oschina.net/oscnet/up-438613acc1f6667c828e7dbe14679e574cf.png" alt="file" referrerpolicy="no-referrer"></p><p>這次的主角是 Resend，也是最近硅谷冉冉升起的明星初創公司。想重塑郵件體驗，挑戰像 Mailchimp 這樣的老牌玩家。</p><p><img src="https://oscimg.oschina.net/oscnet/up-59af844e75075e65e2d572ba7ba58a40bbd.png" alt="file" referrerpolicy="no-referrer"></p><p><strong>這次的刪庫事件依然是熟悉的配方，在執行數據庫 schema 變更時，本來是針對本地環境執行，但結果命令發給了生產數據庫，就這樣把數據都刪沒了。</strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-a35feb6af09f25ccb81dd4a7d6e38a21a59.png" alt="file" referrerpolicy="no-referrer"></p><p>而在恢復的過程中，第一次恢復使用了錯誤的備份，導致浪費了 6 個小時。又經過額外的 5 小時備份，才把數據庫恢復過來，但還是有 5 分鐘的數據丟失了。Resend 也列出了一些後續措施：</p><ul><li>恢復 5 分鐘丟失的數據</li><li>收回所有用戶對生產環境的寫權限</li><li>改進本地開發流程，以降低數據庫 schema 變更的風險</li><li>提高故障演練的頻率</li></ul><p>也因為 Resend 小有名氣，所以也引來了 Hacker News 上網友們的鋭評：</p><p><img src="https://oscimg.oschina.net/oscnet/up-f09cddcfcfafcdbbf0bc92d56ac41656d0c.png" alt="file" referrerpolicy="no-referrer"></p><p>太業餘了，像 email 這種核心組件，還是交給更加成熟的 AWS SES，Postmark，Sendgrid 這些吧。</p><p><img src="https://oscimg.oschina.net/oscnet/up-df0428cac45dece8b9cd009e4d6d2a3c10f.png" alt="file" referrerpolicy="no-referrer"></p><p>或許這家公司根本就不該存在。</p><h2>如何避免</h2><p>筆者認為這個故障雖然有點低級。但連錯數據庫這個事情，不算少見。備份過程碰到意外，也很常見。當然低級的問題，解決起來也不難。</p><p>針對第一點，引入像 Bytebase 這樣的變更審核工具，所有針對生產環境的變更操作都要通過 Bytebase，經過人工審核後才能發佈。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ba37741baf890b551db462c259fd8f6b5d0.png" alt="file" referrerpolicy="no-referrer"></p><p>針對第二點，首先是採用雲上的託管數據庫服務，因為他們提供了完整的數據備份和恢復功能。另外就是定期做災備演練。</p><p>大家也引以為戒吧。</p><hr><p>💡 更多資訊，請關注 Bytebase 公號：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 05:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/11045039</guid>
            <link>https://my.oschina.net/u/6148470/blog/11045039</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.27</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/280456/osi-delayed-open-source-publication-report" target="_blank">OSI 發佈報告，研究 BSL 這樣的 「延遲開源發佈」</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Open Source Initiative（OSI）近期發佈了一個報告《Delayed Open Source Publication: A Survey of Historical and Current Practices》（延遲開源發佈：歷史與當前實踐調研）。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Delayed Open Source Publication，簡稱 DOSP，延遲開源發佈的意思。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">結論：DOSP 自開源運動早期以來一直在使用，公司通常利用它來保持商業優勢，同時儘可能保留開源的優勢。報告強調，DOSP 的實驗性和多樣性比預期的要多，且這種趨勢可能會繼續。</p><h3><a href="https://www.oschina.net/news/280524" target="_blank">馬斯克抱怨微軟 Windows 難用，V 神：加入 Linux！</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><img src="https://oscimg.oschina.net/oscnet/up-e5e820c2d6e02c58e0b272f4e8447623295.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-b918faeab5307706355aed13cc098be8979.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微信&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkyMjQzOTkyMQ%3D%3D%26mid%3D2247484005%26idx%3D1%26sn%3D74c8079c36bc1a1a704a41f9d3dc48f9%26chksm%3Dc1f51bfbf68292ed01843d1451dc4170e814babd874c8b1661aa5c21e2bb9d99ad62da6ee348" target="_blank">IT 知識刺客</a></em></u></p><p><img src="https://oscimg.oschina.net/oscnet/up-7376d45caae71d8c9a249f35fb238c25d26.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- 微博&nbsp;</span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2689166291%2FO2vRh7Twn" target="_blank">歸零歸零歸 ww</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-505c94c6606e7aefd93a64ce5f75063c652.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-ddca260d14744131b56cecc93028c61a364.png" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-271b8a5abd0cf2553fb727bb13de466f0c2.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 Gitee 精選</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-618659c15ef289866a177fc7ccfe8e89e53.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/7r8dkz3232v4e7a/17_maria_db_v_linux_GoyNoM85IZ.pdf">開源日報第 017 期：MariaDB 消亡史；寫代碼我有三不沾；V 神建議馬斯克用 Linux</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul><p>&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 04:12:01 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280594</guid>
            <link>https://www.oschina.net/news/280594</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[國人獨立開發的開源 Redis 客戶端 ioredis 被 Redis 公司收購]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff; color:#333333">ioredis 作者&nbsp;</span><a href="https://my.oschina.net/u/1051352" target="_blank">@Luin</a><span style="background-color:#ffffff; color:#333333">&nbsp;宣佈該項目已被 Redis 公司收購。</span>ioredis 是一個用於 Node.js 的 Redis 客戶端，健壯、性能好、功能強大且全面。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-c7b9c050507e824beecc36c4767b126c712.png" referrerpolicy="no-referrer"></p></blockquote><p>目前&nbsp;ioredis 在 GitHub 的開源地址已遷移至&nbsp;Redis 公司旗下：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fredis%2Fioredis" target="_blank">https://github.com/redis/ioredis</a></u></em></p><p><img height="601" src="https://oscimg.oschina.net/oscnet/up-be0cf491613bb1c935a0bcfa6354508563c.jpg" width="1170" referrerpolicy="no-referrer"></p><p>兩年前，ioredis <u><a href="https://www.oschina.net/news/208601">超過 </a></u>redis 成為了 Node.js 最流行的 Redis 客戶端。當時&nbsp;<span style="background-color:#ffffff; color:#333333">ioredis 作者</span>還感嘆&nbsp;redis 歷經諸多波折終被 Redis 官方收購。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b93256e806a38a0bede1296043170bf2947.png" referrerpolicy="no-referrer"></p><p><a href="https://my.oschina.net/u/1051352" target="_blank">@Luin</a><span style="background-color:#ffffff; color:#333333">&nbsp;曾表示&nbsp;</span>ioredis 是自己獨立從零開發的項目，創建初衷也很「極客」——沒找到滿意的開源庫，所以決定自己動手幹。歷經 9 年，從個人的&nbsp;side project 到被開源公司收購，吾輩楷模！</p><blockquote><p>2014 年底的時候我開始使用 Node.js 開發後端程序。為了連接 Redis ，所以研究了下市面上的 Redis 客戶端庫。當時最流行的庫 redis 是由 Uber 的首席架構師 Matt Ranney 開發的。使用後發現這個庫有一些讓自己不滿意的地方：</p><ol><li>不支持 Promise （當時 Promise 還是個非常新的概念）</li><li>命令語法不太美觀（個人審美差異😄）</li><li>功能不齊全：缺少 Cluster 、Sentinel 等 Redis 新功能的支持。</li></ol><p>由於當時正好有點閒暇時間，就自己從零開發並開源了 ioredis 。</p></blockquote><p>延伸閲讀：<em><u><a href="https://www.oschina.net/news/208601" target="_blank">ioredis 成為最流行的 Node.js Redis 庫</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 03:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280584/redis-ltd-acquire-ioredis</guid>
            <link>https://www.oschina.net/news/280584/redis-ltd-acquire-ioredis</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[任天堂起訴 Switch 模擬器 Yuzu 開發者]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">美國任天堂公司正在對流行模擬器工具 Yuzu 背後的開發商 Tropic Haze LLC 提起訴訟，控告其「大規模侵犯任天堂和其他人版權作品知識產權」。</span></p><p><img height="315" src="https://oscimg.oschina.net/oscnet/up-7661078344ba837f79511462e7252c9b144.png" width="500" referrerpolicy="no-referrer"></p><p><span style="color:#000000">該公司在最新提交的一份法律<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdockets.justia.com%2Fdocket%2Frhode-island%2Fridce%2F1%3A2024cv00082%2F56980%3Fref%3Doverkill.wtf" target="_blank">文件</a>中指出，Tropic Haze LLC 非法規避了任天堂 Switch 遊戲的軟件加密和版權保護系統，從而助長了盜版行為，侵犯了《數字千年版權法案》（DMCA）規定的版權。並表示，其《塞爾達傳説：王國之淚》在正式零售發售之前就因盜版被下載了超過一百萬份。</span></p><p><span style="color:#000000">任天堂聲稱，Yuzu 的主要開發者已公開承認 Yuzu 網站向用戶提供了指導，教他們如何入侵任天堂 Switch 遊戲機，以及如何未經授權複製任天堂視頻遊戲。同時，任天堂還強調了 Yuzu 從中的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patreon.com%2Fyuzuteam%3Fref%3Doverkill.wtf" target="_blank">獲利</a></span><span style="color:#333333">；</span><span style="color:#000000">該項目目前已經得到了 7000 多名會員的支持，每月收入接近 3 萬美元。</span></p><p><span style="color:#333333">因此，任天堂現在正在尋求獲得損失賠償，要求對每項違 </span><span style="color:#000000">DMCA&nbsp;</span><span style="color:#333333">反規避和反販運條款的行為賠償 2,500 美元，對每項侵犯版權的行為賠償 150,000 美元。以及要求法院查封、扣押和銷燬 Yuzu 模擬器的所有副本，和任天堂認為侵犯其版權的軟件和硬件，並提出了"......立即將域名 yuzu-emu.org ......移交任天堂控制"的需求。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 02:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280580/nintendo-sue-yuzu-emulator</guid>
            <link>https://www.oschina.net/news/280580/nintendo-sue-yuzu-emulator</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[MFiX —— 開源多相流 CFD 軟件]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>MFiX 是美國能源部開發的一款用於模擬顆粒流體多相流的開源軟件，CFD 部分使用 SIMPLE 算法，而顆粒部分包含了 TFM、MPPIC 以及 DEM 等模型，且可以模擬連續相和離散相之間的傳質傳熱。</p><p>MFiX 基於 fortran 語言開發，核心特性包括：並行、開源、跨平台、一鍵安裝、用戶圖形界面、支持 TFM/DEM/PIC 多種模型。</p><ul><li>跨平台：該軟件支持 Windows\Linux\macOS，使得用戶既能在 windows 下學習、測試算例，也可以直接在超算平台上進行計算</li><li>一鍵安裝：該開源軟件可以通過 anaconda 方便的一鍵安裝，解決了大規模開源軟件難以編譯安裝的痛點</li><li>用戶圖形界面：該軟件支持用戶圖形界面，可以方便的設置計算參數、監控計算結果。</li><li>Cutcell 網格：該軟件採用 cutcell 網格處理複雜結構，可以通過 stl 文件或軟件內置的幾何結構生成器構建模擬計算區域。</li><li>物性數據庫：軟件自帶物性數據庫，方便傳熱、化學反應的計算</li><li>Stiff Chem Solver: 燃燒等化學反應的特徵時間遠遠小於流動的特徵時間，通過 stiff 化學求解器分步求解化學反應和流體流動，該軟件可以方便的模擬多相反應流動</li><li>該軟件自帶多個演示算例，學習曲線平滑</li><li>模型豐富：採用 SIMPLE 算法的流體求解器、雙流體 TFM 求解器、離散單元法 DEM 顆粒模擬、CFD-DEM 模擬、MP-PIC 模擬</li><li>MPI 多機並行，方便在超算平台上大規模計算</li></ul><p><strong>運行截圖</strong></p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-be3c669b3b0de4ac6c4bd620524919062f8.png" referrerpolicy="no-referrer"></p></div>
                                                                ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 02:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/mfix</guid>
            <link>https://www.oschina.net/p/mfix</link>
        </item>
        <item>
            <title>
                <![CDATA[拓數派聯手開源聯盟 PG 分會，走進北京大學研究生公選課]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>為促進基礎軟件在中國高校的傳播，進一步提高在校研究生對基礎軟件的學習和開發實踐能力，培養數據庫研發人才，<strong>拓數派聯手開源聯盟 PG 分會，走進北京大學</strong>，同國家特色化示範性軟件學院：北京大學軟件與微電子學院合作，進行了 2024 年《北京大學 PostgreSQL 內核開發：從入門到進階》研究生公選課的打造與授課。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-b22e29aa29909713ba2a7862c06e3909db1.png" referrerpolicy="no-referrer"></p><p style="text-align:center">公選課講師及校方合影</p><p>本次課程由北京大學荊琦教授聯閤中國開源軟件推進聯盟（COPU）組織發起，面向國內一流技術企業收集優秀課程，已成功開展了 3 年。<strong>2024 年，拓數派聯手 PG 開源分會精心組織了新學期的數據庫內核開發從入門到進階內容，經過評審成功進入北京大學研究生開源開發實踐公選課框架。</strong> 公選課開課報告會已於 2 月 20 日成功舉行。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-fa96e68a8eefabc87ccf8c5eea797339cb6.png" referrerpolicy="no-referrer"></p><p style="text-align:center">公選課開課報告會合影</p><p>本次課程時長 16 周，共包括 32 個課時內容，針對數據庫的數據加密、數據存取和優化器原理與實踐三部分內容展開講授。<strong>其中拓數派產品市場總監吳疆作為《優化器原理與實踐》部分的講師，結合雲原生虛擬數倉 PieCloudDB Database 在雲原生優化器的打造經驗，</strong> 將以開源數據庫 PostgreSQL 作為實操數據庫，針對查詢優化器的基本原理和工作流程展開授課。通過四周的學習，學生將學會如何使用統計信息和成本模型來評估不同的查詢執行計劃，並選擇最佳的執行路徑。我們還將討論常見的查詢優化技術，包括索引選擇、連接算法和謂詞下推等。</p><p style="text-align:center"><img alt="" src="https://oscimg.oschina.net/oscnet/up-590815f6a6a18c08c611006284b9f326ed2.png" referrerpolicy="no-referrer"></p><p style="text-align:center">吳疆在開課報告會上發表演講</p><p>拓數派一直致力於促進產學研合作，通過校園行系列活動「校園 Pie」的組織與打造、高校課程的合作、聯合實驗室的創建等多種方式，希望通過前沿技術、產業界案例和應用的分享，促進學術界與產業界的進一步融合，為數據庫從業人才的培養和交流平台的打造提供更多的支持。新的一年，拓數派將不斷努力，在產品、商業和生態的打造上繼續前行！</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 02:16:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280576</guid>
            <link>https://www.oschina.net/news/280576</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | 小紅書自主研發的跨平台播放器 REDPlayer]]>
            </title>
            <description>
                <![CDATA[<h1><a id="redplayer" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#redplayer"></a>REDPlayer</h1><p><img src="https://gitee.com/rte-dev/RedPlayer/raw/main/redplayer.jpg" alt="示例圖片" referrerpolicy="no-referrer"></p><p><img src="https://img.shields.io/badge/release-v1.0.0-blue" alt="GitHub release (latest by date including pre-releases)" referrerpolicy="no-referrer"><img src="https://img.shields.io/badge/license-LGPL2.1-blue" alt="GitHub license" referrerpolicy="no-referrer"></p><h2><a id="about-redplayer" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#about-redplayer"></a>About REDPlayer</h2><p>REDPlayer 是一款由小紅書自主研發的跨平台 (支持 Android、iOS、HarmonyOS 等平台) 播放器。不同於行業其他播放器，REDPlayer 具有結構簡單、耦合度低、功能邊界清晰等特點，提供了多種接入方式，技術人員可根據需要靈活選擇，既可快速集成 SDK 使用，也可基於源碼進行定製開發。</p><p>REDPlayer 的宗旨是讓開發者可以快速明確地瞭解播放器的基本構造，並可根據個人需求進行簡單擴展，滿足不同用戶的多樣需求，可作為學生學習的基礎工具，也可作為企業的商用平台。</p><p>REDPlayer 支持點播、直播場景下的多種協議和格式 (如 HLS、MP4、FLV 等)，並可二次擴展更多協議 (如：RTC 等)。每個模塊均是解耦的，開發者可以根據需要掛載自定義模塊，如自研解碼器、渲染器等。</p><table><thead><tr><th>Platform</th><th>Build Status</th></tr></thead><tbody><tr><td>Android</td><td>Done</td></tr><tr><td>iOS</td><td>Done</td></tr><tr><td>others</td><td>In Coming</td></tr></tbody></table><h3><a id="quickstartdemo" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#quickstartdemo"></a>Quickstart/Demo</h3><ul><li><p>Android <a href="https://gitee.com/rte-dev/RedPlayer/blob/main/source/android/README.md">Quickstart</a>/ <a href="https://gitee.com/rte-dev/RedPlayer/blob/main/source/android/app/README.md">Demo</a></p></li><li><p>IOS <a href="https://gitee.com/rte-dev/RedPlayer/blob/main/source/ios/README.md">Quickstart</a>/ <a href="https://gitee.com/rte-dev/RedPlayer/blob/main/source/ios/RedPlayerDemo">Demo</a></p></li><li><p>In coming...</p></li></ul><h3><a id="features" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#features"></a>Features</h3><table><thead><tr><th>Function</th><th>Function Description</th><th>Current Support Situation</th><th>Other Notes</th></tr></thead><tbody><tr><td>Rich Format</td><td>Supports rich audio and video formats such as FLV, HLS, MP4, MP3, and Vorbis</td><td>✅</td><td></td></tr><tr><td>DASH Protocol</td><td>Supports standard protocol DASH</td><td>✅</td><td>Optimized version of DASH for on-demand support in the later stage</td></tr><tr><td>HDR</td><td>Supports multiple HDR formats such as HDR10/HLG. Distribution and playback support are provided according to the model</td><td>✅</td><td></td></tr><tr><td>URL Playback</td><td>Supports playback of local and network videos via URL</td><td>✅</td><td></td></tr><tr><td>Log Reporting</td><td>Supports reporting player logs and statistics related to playback point information</td><td>✅</td><td></td></tr><tr><td>Abnormal Analysis</td><td>Supports obtaining corresponding abnormal information through log analysis</td><td>✅</td><td></td></tr><tr><td>H.264 Playback &amp; Hardware Decoding</td><td>Supports H.264 video sources and hardware decoding</td><td>✅</td><td></td></tr><tr><td>H.265 Playback &amp; Hardware Decoding</td><td>Supports H.265 video sources and hardware decoding</td><td>✅</td><td>Software decoding capabilities will be supported in the later stage</td></tr><tr><td>Automatic switching between software and hardware decoding</td><td>Automatically switches to software decoding when the terminal does not support hardware decoding</td><td>✅</td><td></td></tr><tr><td>Playback Control</td><td>Supports playback control functions such as start, end, pause, and resume</td><td>✅</td><td></td></tr><tr><td>Accurate Seeking</td><td>Supports accurate seeking to a specified position, which can be accurate to the frame level</td><td>✅</td><td></td></tr><tr><td>Dynamic Dropping</td><td>Start dynamic dropping when the frame rate exceeds 60 fps</td><td>✅</td><td></td></tr><tr><td>Replay</td><td>Supports manually triggered replay after the video ends</td><td>✅</td><td></td></tr><tr><td>Continue playing</td><td>Supports setting the continuous playing time point</td><td>✅</td><td></td></tr><tr><td>Loop Playback</td><td>Supports automatic replay after video playback ends</td><td>✅</td><td>Parameter configuration is required</td></tr><tr><td>Variable Speed Playback</td><td>Supports variable speed playback of 0.5-2 times, and the audio 實現 variable speed without changing the pitch</td><td>✅</td><td></td></tr><tr><td>Definition Adjustment</td><td>Supports switching between multiple definitions for on-demand and transcoding</td><td>✅</td><td></td></tr><tr><td>Seeking within the Cache</td><td>Supports seeking without clearing the buffer for cached video content</td><td>✅</td><td></td></tr><tr><td>Packing Mode</td><td>Supports picture cropping and filling</td><td>✅</td><td></td></tr><tr><td>Private DRM</td><td>Supports private DRM encryption schemes</td><td>✅</td><td></td></tr><tr><td>Adaptive Bitrate</td><td>When playing HLS/DASH, it supports automatically selecting the definition for playback through bandwidth prediction</td><td>✅</td><td>Currently only supports selection before playback, and does not support abr during playback</td></tr><tr><td>Volume Settings</td><td>Supports real-time adjustment of system volume and mute operation</td><td>✅</td><td></td></tr><tr><td>Pure Audio Playback</td><td>Supports playing audio only</td><td>✅</td><td></td></tr><tr><td>Preload</td><td>Supports setting the preload size to reduce the time spent on the first screen</td><td>✅</td><td></td></tr><tr><td>Play While Downloading</td><td>Supports playing while caching and downloading subsequent content, and you can set network policies</td><td>✅</td><td></td></tr><tr><td>Playback Callback</td><td>Supports playback status callback, first frame callback, playback completion or failure callback</td><td>✅</td><td></td></tr><tr><td>Retry on Playback Failure</td><td>Automatically retries on playback failure</td><td>✅</td><td>Only supports retries for non-4XX and 5XX classes</td></tr><tr><td>Real-time Download Speed</td><td>Supports getting real-time download speed</td><td>❌</td><td>Will be supported in later versions</td></tr><tr><td>Encrypted Streaming PlayBack</td><td>Support for on-demand transcoding of encrypted streams</td><td>❌</td><td>Need for custom development</td></tr><tr><td>Screenshot Function</td><td>Support for capturing any frame of the playback picture</td><td>❌</td><td>Will be supported in later versions</td></tr><tr><td>Thumbnail Preview</td><td>Support for previewing progress bar thumbnails (sprite map)</td><td>❌</td><td>Related to business, not currently supported</td></tr><tr><td>Set player size</td><td>Support for customizing the width and height of the player</td><td>❌</td><td>Will be supported in later versions</td></tr><tr><td>External subtitles</td><td>Support for two docking modes of external subtitles: full-link solution and pure client solution</td><td>❌</td><td>Will be supported in later versions</td></tr><tr><td>Client super-resolution</td><td>The client performs super-resolution enhancement on low-quality videos</td><td>❌</td><td>Will be supported in later versions</td></tr><tr><td>H.266 playback</td><td>Support for video playback in H.266 encoding format</td><td>❌</td><td>Will be supported in later versions</td></tr><tr><td>AV1 playback</td><td>Support for video playback in AV1 encoding format</td><td>❌</td><td>Will be supported in later versions</td></tr></tbody></table><h3><a id="open-content" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#open-content"></a>Open Content</h3><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">```bash</span><span id="LC2" class="line"># Describe the main contents of current open source and the estimated time and contents of the next open source</span><span id="LC3" class="line">```</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><ul><li><a href="https://gitee.com/rte-dev/RedPlayer/blob/main/CONTENTS.md">CONTENTS.md</a></li></ul><h3><a id="usage" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#usage"></a>Usage</h3><ul><li>You can directly integrate your project by calling the interface or compile independently.</li><li><a href="https://gitee.com/rte-dev/RedPlayer/blob/main/INTERFACES.md">INTERFACES.md</a></li></ul><h3><a id="build-environment" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#build-environment"></a>Build Environment</h3><ul><li><p><strong>Install Homebrew &amp; Git</strong></p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"> /bin/bash <span class="nt">-c</span><span class="s2">"</span><span class="si">$(</span>curl <span class="nt">-fsSL</span> https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh<span class="si">)</span><span class="s2">"</span></span><span id="LC2" class="line"> brew <span class="nb">install </span>git</span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li><p><strong>Build Android</strong></p><p><strong>Using Android SDK</strong></p><p><a href="https://gitee.com/link?target=https%3A%2F%2Fdeveloper.android.com%2Fstudio%3Fhl%3Den">Andrioid SDK</a> is android project base dependency. You should download and then config with the following command:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c"># add this line to your ~/.bash_profile or ~/.profile, the android sdk will work</span></span><span id="LC2" class="line"><span class="nb">export </span><span class="nv">ANDROID_SDK</span><span class="o">=</span>&lt;your sdk path&gt;</span><span id="LC3" class="line"></span><span id="LC4" class="line"><span class="c"># My build environment:</span></span><span id="LC5" class="line"><span class="c"># macOS 14.0</span></span><span id="LC6" class="line"><span class="c"># Android Studio Flamingo | 2022.2.1 Patch 2</span></span><span id="LC7" class="line"><span class="c"># gradle version: 7.5.0</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li><li><p><strong>Build iOS</strong></p><p><strong>Using CocoaPods</strong></p><p><a href="https://gitee.com/link?target=http%3A%2F%2Fcocoapods.org">CocoaPods</a> is a dependency manager for Cocoa projects. You can install it with the following command:</p><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="nv">$ </span>gem <span class="nb">install </span>cocoapods</span><span id="LC2" class="line"></span><span id="LC3" class="line"><span class="c"># My build environment:</span></span><span id="LC4" class="line"><span class="c"># macOS 14.0</span></span><span id="LC5" class="line"><span class="c"># Xcode 15.2 (15C500b)</span></span><span id="LC6" class="line"><span class="c"># Cocoapods version: 1.10.2</span></span><span id="LC7" class="line"><span class="c"># Ruby 3.0.6p216</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div></li></ul><h3><a id="latest-changes" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#latest-changes"></a>Latest Changes</h3><ul><li><a href="https://gitee.com/rte-dev/RedPlayer/blob/main/NEWS.md">NEWS.md</a></li></ul><h3><a id="support" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#support"></a>Support</h3><ul><li>Please try to discuss technical issues (<a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2FRTE-Dev%2FRedPlayer%2Fissues">https://github.com/RTE-Dev/RedPlayer/issues</a>) publicly on github, and do not inquire privately by email. We will not reply one by one.</li></ul><h3><a id="licence" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#licence"></a>Licence</h3><h4><a id="self-licence" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#self-licence"></a>Self Licence</h4><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">Copyright (c) 2024 xiaohongshu</span><span id="LC2" class="line">Licensed under LGPLv2.1 or later</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h4><a id="dependence-licence" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#dependence-licence"></a>Dependence Licence</h4><ul><li>ffmpeg: LGPL v2.1+</li><li>soundtouch: LGPL v2.1</li><li>libcurl: MIT License</li><li>c-ares: MIT License</li><li>glide: MIT License</li><li>Masonry: MIT License</li><li>openssl: Apache License 2.0</li><li>PictureSelector: Apache License 2.0</li></ul><h3><a id="law-and-rule" class="anchor" href="https://gitee.com/rte-dev/RedPlayer#law-and-rule"></a>Law And Rule</h3><p>All rights and explanations belong to Xiaohongshu，you should always ask your lawyer for these stuffs before use it in your product.</p>]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 02:14:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/rte-dev/RedPlayer</guid>
            <link>https://gitee.com/rte-dev/RedPlayer</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 語言大模型的浮點運算分配]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><p><img height="352" src="https://oscimg.oschina.net/oscnet/203eda90-2b91-4ed0-9fbf-02459d2253d5.jpg" width="578" referrerpolicy="no-referrer"></p><p style="margin-left:8px; margin-right:8px; text-align:left"><span>本文</span><span>通過實證分析展示了實際 LLM 模型的 FLOPS 分配情況，並與理論分析進行對比。</span><span>通過理論和實證相結合的方式，本文為理解和優化語言大模型的性能提供了有益見解。</span></p><p>&nbsp;</p><p><span>作者 Finbarr Timbers 是一名機器學習研究員，曾就職於 DeepMind。（以下內容由 OneFlow 編譯發佈，轉載請聯繫授權。原文：<span style="background-color:#efefef">https://www.artfintel.com/p/where-do-llms-spend-their-flops</span></span><span><span>）</span></span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="margin-left:8px; margin-right:8px"><strong><span style="color:#3f3f3f">作者 |&nbsp;Finbarr Timbers</span></strong></p><p style="margin-left:8px; margin-right:8px"><strong><span style="color:#3f3f3f">OneFlow 編譯</span></strong></p><p style="margin-left:8px; margin-right:8px"><strong><span style="color:#3f3f3f">翻譯｜宛子琳、楊婷</span></strong></p><p>&nbsp;</p><p><span style="color:#3f3f3f">本文對 LLM 的性能進行了理論分析，然後通過詳細分析一個實際的 LLM，查看實證結果與理論之間的差異。首先是理論分析部分，我會藉助</span><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491309%26idx%3D1%26sn%3D407fefb7ec76a2c9fdfe1ae960f7de4d%26chksm%3Dfe4190dbc93619cd0b9bfecb979e142a125fd8548d323dd9bdc2cbeb619400202e6e1affced0%26scene%3D21%23wechat_redirect" target="_blank"><strong><span>Kipply 的優質博文</span></strong></a><span style="color:#3f3f3f">來填充細節。基本結論是：對於標準解碼器模型，FLOPS（每秒浮點運算數）的分配如下（按每層計算）：</span></p><p>&nbsp;</p><ol><li><p><span style="color:#3f3f3f">6d^2 用於計算 QKV（Query（查詢）、Key（鍵）和 Value（值））</span></p></li><li><p><span style="color:#3f3f3f">2d^2 用於計算注意力輸出矩陣，softmax(Q @ K.T) @ V</span></p></li><li><p><span style="color:#3f3f3f">16d^2 用於運行前饋神經網絡（FFN）&nbsp;</span></p></li></ol><p>&nbsp;</p><p><span style="color:#3f3f3f">總計 24d^2 FLOPS。從百分比看，25% 的時間用於計算 QKV，約 8% 的時間用於計算注意力輸出矩陣，約 66% 的時間用於運行 FFN。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">那麼用於注意力機制的時間呢？眾所周知，注意力機制方程為：</span></p><p>&nbsp;</p><p style="text-align:center"><img height="84" src="https://oscimg.oschina.net/oscnet/fec217d2-600c-4ed3-850a-7407dd0b583b.jpg" width="315" referrerpolicy="no-referrer"></p><p style="text-align:left">&nbsp;</p><p style="text-align:left"><span style="color:#3f3f3f">假設你正在使用 KV 緩存，Q（查詢）、K（鍵）和 V（值）都是 d 維向量（等價於（d，1）矩陣）。每個點積大約需要 2d 個 flops（</span><span style="color:#888888"><em><span>https://www.stat.cmu.edu/~ryantibs/convexopt-F18/scribes/Lecture_19.pdf</span></em></span><span style="color:#3f3f3f">），加上進行 d 次除法需要 d 個 flops，總計約為 5d 個 flops，四捨五入為零。</span></p><p>&nbsp;</p><p style="text-align:center"><img height="112" src="https://oscimg.oschina.net/oscnet/4c742fa6-51fa-4652-bcf4-06fcb9d9263e.png" width="253" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span style="color:#3f3f3f">當 d 等於 4096（在 Llama7b 中的取值），這僅為 0.005%，幾乎可以忽略不計。這似乎表明注意力機制不重要，但事實並非如此。我們之所以使用 KV 緩存（以及 flash attention 等）正是因為它們非常重要，可以將其類比於米爾頓·弗裏德曼的恆溫器（</span><span style="color:#888888"><em><span>https://worthwhile.typepad.com/worthwhile_canadian_initi/2010/12/milton-friedmans-thermostat.html</span></em><span>，感謝 @bradchattergoon</span></span><span style="color:#3f3f3f">）：</span></p><p>&nbsp;</p><p><span style="color:#888888"><em><span>假設一個房屋配備了一個運行良好的恆溫器，那麼我們能看到爐子燃燒的油量（M）與室外溫度（V）之間存在強烈的負相關關係，同時爐子燃燒的油量（M）與室內溫度（P）之間沒有相關性，此外，室外溫度（V）與室內溫度（P）之間也沒有相關性。</span></em></span></p><p>&nbsp;</p><p><span style="color:#888888"><em><span>一位計量經濟學家觀察數據後得出結論：燃燒的油量對室內溫度沒有影響，室外溫度對室內溫度也沒有影響。唯一的影響似乎是燃燒油量會降低室外溫度。</span></em></span></p><p>&nbsp;</p><p><span style="color:#888888"><em><span>觀察相同的數據，第二位計量經濟學家得出了完全相反的結論。他認為，室外溫度（V）增加唯一的影響是會減少耗油量（M），而不會對室內溫度（P）產生任何影響。</span></em></span></p><p>&nbsp;</p><p><span style="color:#888888"><em><span style="color:#888888">儘管兩位計量經濟學家得出了不同的結論，但他們一致認為燃燒油量（M）和室外溫度（V）對室內溫度（P）沒有影響。基於這一共識，他們決定關閉爐子，不再浪費金錢購買燃油。</span></em></span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">KV 緩存需要 O(T) 的內存（其中 T 是我們希望生成的詞元數），因此內存需求成本較高，這一點可以參考公司股票（$NVDA）情況。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">KV 緩存有多大呢？對於每個詞元，需要存儲以下數量的字節（第一個 2 是因為我們假設使用 bf16 精度，因此每個參數佔用 2 個字節；第二個 2 是因為需要同時存儲 K 和 V 張量）：</span></p><p style="text-align:center"><img height="77" src="https://oscimg.oschina.net/oscnet/64861c4b-a4cb-4b5a-94e8-85c4b0b6f198.jpg" width="415" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span style="color:#3f3f3f">注意，根據假設，n_heads*d_head=d_model=d，因此字節數為 4*層數*d。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">GPT-3 有 96 層，d_model 為 12288，每個詞元需要 4.72MB。因此，生成 2048 個詞元需要 5.6GB 的內存。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">儘管如此，要使用給定模型生成給定長度的序列，我們仍需使用與 KV 緩存相同的內存量，只是在每次前向傳播結束時將其丟棄。因此，我們並不需要更多內存。從某種意義上説，KV 緩存不佔用內存（至少在 Jax 中是如此，除了一些繁瑣的 bookkeeping 工作）。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">對於一些新興架構（例如 Mistral 7B）又有何不同呢？Mistral 7b 使用了分組查詢注意力（Llama2 也使用了類似的注意力機制，就好像這兩個模型的作者存在某種聯繫。）和滑動窗口注意力。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">在分組查詢注意力中，我們可以在多頭之間共享一個 KV 投影（MQA），具體而言，可以是所有注意力頭之間共享一個 KV 投影（MQA，</span><span style="color:#888888"><em><span>https://arxiv.org/abs/1911.02150</span></em></span><span style="color:#3f3f3f">），或者將其分成多個組（GQA，</span><span style="color:#888888"><em><span>https://arxiv.org/abs/2305.13245v</span></em><span>3</span></span><span style="color:#3f3f3f">）。這兩種方法都等同於具有較小 d_model 的標準多頭注意力（MHA）。在之前的 KV 緩存計算中，我們假設注意力頭的數量乘以頭的維度等於模型維度，但是在 MQA/GQA 中，我們放寬了這一假設。KV 緩存公式如下：</span></p><p>&nbsp;</p><p style="text-align:center"><img height="66" src="https://oscimg.oschina.net/oscnet/5062dc02-0be8-4534-b2b4-39320bbfa8a9.jpg" width="345" referrerpolicy="no-referrer"></p><p>&nbsp;</p><p><span style="color:#3f3f3f">可以轉換為：</span></p><p style="color:#494949">&nbsp;</p><p style="text-align:center"><img height="71" src="https://oscimg.oschina.net/oscnet/96864198-3330-4aab-8f30-22d5cd408e8e.jpg" width="332" referrerpolicy="no-referrer"></p><p style="color:#494949">&nbsp;</p><p><span><span style="color:#3f3f3f">其中，注意力頭的數量乘以頭的維度就是模型的有效維度。因此，可以看到，隨着 KV 頭數量的減少，KV 緩存大小呈線性減小（ 這也是 GQA/MQA 方法背後的關鍵動機之一）。</span></span></p><p>&nbsp;</p><p><span><span style="color:#3f3f3f">Llama{1,2} 模型參數如下：</span></span></p><p style="color:#494949">&nbsp;</p><p style="color:#494949"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/7a2e216e-dbda-47b6-96f4-17d8c0b5f9b6.png" width="1060" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p><span><span><span style="color:#3f3f3f">Llama 2 中，每個詞元所需的 KV 緩存如下：</span></span></span></p><p style="color:#494949"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/0acb1a24-9589-4d7e-bc1f-6be3cbe3a123.png" width="auto" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">在沒有分組查詢注意力（GQA）的情況下，34B 模型需要的 KV 緩存內存是原來的 5 倍，而 70B 模型需要的 KV 緩存內存是原來的 8 倍。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">Llama/Mistral 的另一個改進是滑動窗口注意力，它保證我們可以將 KV 緩存限制在窗口大小，對於 Llama7B 來説，窗口大小為 4096。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">1</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">性能驅動的架構變化</span></strong></span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">如前所述，LLM 每層使用了 24d^2 個 flops。增加的層數將線性擴展 flops 和參數數量，增加模型寬度會二次方擴展模型大小。需要注意的是，這是因為參數的數量與 d_model 的平方成正比，因為我們的大多數層是從一個 d_model 輸入向量轉變為一個 d_model 的輸出向量，所以權重矩陣的尺寸為 (d_model, d_model)。換句話説，計算量與參數的數量呈正比，增加 d_model 會使參數數量呈二次方增加。模型深度增加一倍會使參數數量翻倍，但模型寬度增加一倍會使參數數量增加四倍。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">儘管如此，更寬的模型的優勢是能夠更好地並行化。要計算第 N 層，必須首先計算前面的 N-1 層。這在高效並行化上十分困難，尤其是在訓練期間，而通過張量並行化方法，跨多個 GPU 拆分單個層要容易得多。如果你主要關心時延，那麼選擇更寬的模型可能更合適。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">2</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">實證分析</span></strong></span></p><p style="margin-left:8px; margin-right:8px; text-align:center">&nbsp;</p><p><span style="color:#3f3f3f">我使用 Colab 進行了這項分析。（</span><span style="color:#888888"><em>https://colab.research.google.com/drive/1TH6AKsICZqlFoW1ph8h3wsF7q7qVMF8T?usp=sharing</em></span><span style="color:#3f3f3f">）</span></p><p><span style="color:#3f3f3f">以下是單次前向傳播的高級概要（我的網站上有交互式概要：</span><span style="color:#888888"><em>https://finbarr.ca/static/llama-profile.svg</em></span><span style="color:#3f3f3f">）：</span></p><p>&nbsp;</p><p style="color:#494949"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/d803a059-2155-4d20-bdfe-d09119f0d0a4.png" width="2378" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">可以看到，本次運行的總時間中有 4.88% 用於單次前向傳播。在前向傳播中，有 1.98% 的時間用於注意力機制，有 2.58% 的時間用於多層感知機（MLP）。在前向傳播的總時間中，有 40% 的時間用於注意力層，53% 用於 MLP。在注意力層內部，時間分配在 4 個不同的線性層上，其中有 2 個線性層花費的時間大致相同（linear_1、linear_2），一個花費的時間多 50%（linear_3），另一個則是前兩者的兩倍（linear_0）。我猜測 linear_0 正在計算查詢嵌入，而 linear_1/2 正在計算鍵和值嵌入。請注意，由於 KV 頭的數量較少，計算速度要快得多！GQA（Query-aware Attention）帶來了明顯的差異，即便所使用的注意力機制（</span><span style="color:#888888"><em>xformers.ops.memory_efficient_attention</em></span><span style="color:#3f3f3f">）要求 QKV 嵌入被廣播到相同的大小。</span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">理論分析預測，2/3 的時間將用於計算 FFN，1/3 將用於計算注意力機制。這基本符合我們上面所看到的情況。我們花在計算注意力機制上的時間略多於 MLP，但我懷疑這是因為 MLP 正在為 Torch 執行一個經良好優化的路徑。</span></p><p>&nbsp;</p><p style="margin-left:8px; margin-right:8px; text-align:center"><strong><span style="color:#f6ab00">3</span></strong></p><p style="margin-left:8px; margin-right:8px; text-align:center"><span style="color:#1e2380"><strong><span style="color:#1e2380">性能變化</span></strong></span></p><p>&nbsp;</p><p><span style="color:#a5a5a5"><span style="color:#3f3f3f">接下來，我對 Llama2 進行了一系列實驗，涉及模型寬度和深度的調整。以下是實驗結果：</span></span></p><p>&nbsp;</p><p style="color:#494949"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/0d787e3e-65db-48e6-9f1b-241cb3529be4.png" width="567" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p><span style="color:#a5a5a5"><span style="color:#3f3f3f">結果非常有趣。可以看到，隱藏維度為 1024 和 1536 的兩個模型的速度基本沒有變化（1.10 秒 vs1.11 秒），隱藏維度為 1024 和 2048 的模型只發生了輕微變化（1.15 秒 vs1.10 秒）。然而，當我們比較隱藏維度為 2048（1.15 秒）、3072（1.41 秒）和 4096（1.82 秒）的模型時，可以看到速度類似於線性擴展！</span></span></p><p>&nbsp;</p><p><span style="color:#a5a5a5"><span style="color:#3f3f3f">對此，我的看法是，調度 kernel 和實際執行矩陣乘法中存在較大的開銷。這是在 T4 上運行的，儘管按現在的標準來看有些過時，但仍具有 65 TFLOPS 的 bf16 計算能力。如果我們將兩個 1024x1024 的矩陣相乘，這就需要 1G FLOP 的計算能力，因此，理論上，我們可以每秒乘以 65000 個 1024x1024 的矩陣。實際上，我們只能得到其 60-80% 的性能，但仍然是每秒 40000 次矩陣乘法。如今的 GPU 擁有大量核心，T4 有 2560 個 CUDA 核心，每個核心的運行頻率在 585 到 1590 MHz 之間。因此，任何能夠並行化的任務都表現良好，但是那些需要順序計算的任務則不會得到優化。我認為，這就是圖中所看到的的情況——沒有足夠的並行性來充分利用 GPU。</span></span></p><p>&nbsp;</p><p><span style="color:#a5a5a5"><span style="color:#3f3f3f">Transformer 的深度使性能與預期完全一致：推理時間與深度呈線性增長。最深的模型可能存在一些噪聲，但它的性能表現相當穩定。</span></span></p><p>&nbsp;</p><p style="color:#494949"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/64122776-737e-4d29-bc3e-bdd23f972cf0.png" width="567" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p><span style="color:#3f3f3f">接下來，我計算了生成更多詞元所需的成本（對每個詞元數量進行了 10 次運行，以減少噪音）：</span></p><p>&nbsp;</p><p style="color:#494949"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/d3c4dac0-6e2f-4efa-b5d6-a3cfcc0740b7.png" width="auto" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p><span style="color:#a5a5a5"><span style="color:#3f3f3f">正如預期的那樣，完全呈線性增長，因為 Llama2 使用了 KV 緩存。如果我們查看保留的內存，就會看到 KV 緩存與預期的一致（在某種程度上）：</span></span></p><p>&nbsp;</p><p style="color:#494949"><span><img height="auto" src="https://oscimg.oschina.net/oscnet/5e09bf5a-80bb-44e5-b570-fe8e6c840b03.png" width="571" referrerpolicy="no-referrer"></span></p><p>&nbsp;</p><p><span style="color:#a5a5a5"><span><span><span><span style="color:#3f3f3f">可以看到，模型每增加 20 個詞元，內存佔用就會增加約 2.1MB。由於該模型的 d_model 為 1024，有 8 個隱藏層，因此需要 4 * num_layers * d_model 字節的內存，即 4*8*1024 字節=每詞元 32KB 的內存。理論上我們只需要 640KB 的內存。目前還不清楚額外的 3 倍開銷是從哪裏產生的。我懷疑是因為執行還不夠高效。</span></span></span></span></span></p><p>&nbsp;</p><span id="OSC_h3_1"></span><h3>&nbsp;</h3><p style="margin-left:8px; margin-right:8px"><strong><span style="color:#3f3f3f">【語言大模型推理最高<strong><span>加速 11</span></strong>倍】</span></strong><span style="color:#3f3f3f">SiliconLLM 是由硅基流動開發的高效、易用、可擴展的 LLM 推理加速引擎，旨在為用戶提供開箱即用的推理加速能力，顯著降低大模型部署成本，加速生成式 AI 產品落地。（技術合作、交流請添加微信：SiliconFlow01）</span></p><p style="margin-left:8px; margin-right:8px">&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/838dbcc5-3a63-4cde-8f52-3b567a5f020a.png" referrerpolicy="no-referrer"></p><p style="text-align:left"><span style="color:#3f3f3f">SiliconLLM 的吞吐最高提升近<strong>4</strong>倍，時延最高降低近<strong>4</strong>倍</span></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/d7781a37-f9dd-4d5f-b5ef-7767cc2816af.png" referrerpolicy="no-referrer"></p><p style="text-align:left"><strong><span style="color:#3f3f3f">數據中心+PCIe</span></strong><span style="color:#3f3f3f">：SiliconLLM 的吞吐最高提升近<strong>5</strong>倍；<strong>消費卡場景</strong>：SiliconLLM 的吞吐最高提升近<strong>3</strong>倍</span></p><p style="text-align:center">&nbsp;</p><p style="text-align:center"><img src="https://oscimg.oschina.net/oscnet/d42ca228-3463-4797-9dfb-454d4682d478.png" referrerpolicy="no-referrer"></p><p style="margin-left:8px; margin-right:8px"><strong><span style="color:#3f3f3f">Sy</span><span style="color:#3f3f3f">stem Prompt 場景</span></strong><span style="color:#3f3f3f">：SiliconLLM 的吞吐最高提升<strong>11</strong>倍；<strong>MoE 模型</strong>：推理 SiliconLLM 的吞吐最高提升近<strong>10</strong>倍</span></p><p>&nbsp;</p><p><span style="color:#888888">其他人都在看</span></p><span id="OSC_h3_2"></span><h3>&nbsp;</h3><ul><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493221%26idx%3D1%26sn%3D0c75b8115f4d4a27c8a5d6505a0a4986%26chksm%3Dfe426853c935e145d21abd30e0ceb29486c9e306032dfcb3d071ce34d171425c11341a57d7bf%26scene%3D21%23wechat_redirect" target="_blank">800+頁免費「大模型」電子書</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493108%26idx%3D1%26sn%3Db254dff8281096bf6f5462489e94658a%26chksm%3Dfe426bc2c935e2d404fb803985241ea05109aa9d7925a1876304a51c322fa5e6e57dd41e2e66%26scene%3D21%23wechat_redirect" target="_blank">語言大模型的推理技巧</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491309%26idx%3D1%26sn%3D407fefb7ec76a2c9fdfe1ae960f7de4d%26chksm%3Dfe4190dbc93619cd0b9bfecb979e142a125fd8548d323dd9bdc2cbeb619400202e6e1affced0%26scene%3D21%23wechat_redirect" target="_blank">語言大模型的推理演算</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493321%26idx%3D1%26sn%3Dffc39c67080fefb01f1790e285a5085b%26chksm%3Dfe4268ffc935e1e9c8aeb5a095f08868a5eb8df90c1f46eb1e07044ec34ae6404d14b8b5926b%26scene%3D21%23wechat_redirect" target="_blank">語言大模型推理加速指南</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247492811%26idx%3D1%26sn%3D916e330a2a4152dab3192635c3e475fa%26chksm%3Dfe426afdc935e3eb2f371ff5f56247c95800ce91a950a89bea871c26ddc4c3d13371acf03978%26scene%3D21%23wechat_redirect" target="_blank">語言大模型推理性能工程：最佳實踐</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493149%26idx%3D1%26sn%3Dfd0369875ad89e8ad173935ec7b38126%26chksm%3Dfe42682bc935e13d91f1ae73cb0135cca0d815c0356baef29c20ab985c9279280e28ae956642%26scene%3D21%23wechat_redirect" target="_blank">邁向 100 倍加速：全棧 Transformer 推理優化</a></p></li><li><p><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493282%26idx%3D1%26sn%3D7f91a174ab4cccf16303aa3ce11afac7%26chksm%3Dfe426894c935e182d15b65dbf6d1e3d4d12398664ceae848f6fa79ee289dff1fad23a9c8aea5%26scene%3D21%23wechat_redirect" target="_blank">Mistral AI:LLM 推理的吞吐、時延及成本空間</a></p></li></ul><p><span style="color:#3f3f3f">試用 OneDiff:&nbsp;<strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgithub.com%2Fsiliconflow%2Fonediff" target="_blank">github.com/siliconflow/onediff</a></strong></span></p><span id="OSC_h2_3"></span><h2 style="margin-left:8px; margin-right:8px">&nbsp;</h2><p><img src="https://oscimg.oschina.net/oscnet/4d6d060f-6daf-4d9f-a3db-4de78e4b9745.png" width="578" referrerpolicy="no-referrer"></p><p>&nbsp;</p></div><p style="color:#858585">本文分享自微信公眾號 - OneFlow（OneFlowTechnology）。<br> 如有侵權，請聯繫 support@oschina.cn 刪除。<br> 本文參與「<a href="https://www.oschina.net/sharing-plan" target="_blank">OSC 源創計劃</a>」，歡迎正在閲讀的你也加入，一起分享。</p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 02:09:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/11030216</guid>
            <link>https://my.oschina.net/oneflow/blog/11030216</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GreatSQL TPC-H 性能測試報告正式發佈！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img height="383" src="https://oscimg.oschina.net/oscnet/up-93f0563f25f5317db04df95a53c0bcc8c0f.png" width="900" referrerpolicy="no-referrer"></p><p style="text-align:center">GreatSQL TPC-H 性能測試報告 - （2024 年 2 月 28 日）</p><p>完整性能測試報告：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fdocs%2F8032-25%2Fuser-manual%2F10-optimze%2F3-3-benchmark-greatsql-tpch-report.html" target="_blank">https://greatsql.cn/docs/8032-25/user-manual/10-optimze/3-3-benchmark-greatsql-tpch-report.html</a></p><h2>1、概述</h2><p>本次測試針對 GreatSQL 數據庫基於標準 TPC-H 場景的測試。</p><p>TPC-H（商業智能計算測試）是美國交易處理效能委員會（TPC，TransactionProcessing Performance Council）組織制定的用來模擬決策支持類應用的一個測試集。目前，學術界和工業界普遍採用 TPC-H 來評價決策支持技術方面應用的性能。這種商業測試可以全方位評測系統的整體商業計算綜合能力，對廠商的要求更高，同時也具有普遍的商業實用意義，目前在銀行信貸分析和信用卡分析、電信運營分析、稅收分析、煙草行業決策分析中都有廣泛的應用，TPC-H 查詢包含八張數據表和 22 條複雜 SQL 查詢，大多數查詢包含多表聯接（JOIN）、子查詢和聚合查詢等。</p><p>GreatSQL 數據庫是一款<strong>開源免費</strong>數據庫，可在普通硬件上滿足金融級應用場景，具有<strong>高可用</strong>、<strong>高性能</strong>、<strong>高兼容</strong>、<strong>高安全</strong>等特性，可作為 MySQL 或 Percona Server for MySQL 的理想可選替換。</p><h2>2、測試環境</h2><table><tbody><tr><th>配置</th><th>備註</th></tr></tbody><tbody><tr><td>操作系統</td><td>OS：CentOS Linux release 7.9.2009 (Core)<br> 內核：3.10.0-1160.el7.x86_64</td></tr><tr><td>CPU</td><td>Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz * 4</td></tr><tr><td>內存</td><td>251G</td></tr><tr><td>磁盤</td><td>INTEL SSDPE2KE032T8</td></tr><tr><td>數據庫</td><td>GreatSQL 8.0.32-25, Release 25, Revision 79f57097e3f</td></tr></tbody></table><p><strong>提示</strong>：在下面運行 TPC-H 測試時，設置了 Rapid 引擎最大可使用的內存及線程數。</p><pre><code class="language-sql">greatsql&gt; SET GLOBAL rapid_memory_limit = 68719476736;
greatsql&gt; SET GLOBAL rapid_worker_threads = 32;
</code></pre><h2>3、測試表結構和數據量</h2><p>各表數據量對比：</p><table><tbody><tr><th>表名</th><th>TPC-H SF100 數據量</th><th>TPC-H SF300 數據量</th><th>備註</th></tr></tbody><tbody><tr><td>region</td><td>5</td><td>5</td><td>地區信息</td></tr><tr><td>nation</td><td>25</td><td>25</td><td>國家表</td></tr><tr><td>supplier</td><td>1000000</td><td>3000000</td><td>供應商信息</td></tr><tr><td>part</td><td>20000000</td><td>60000000</td><td>零件表</td></tr><tr><td>customer</td><td>15000000</td><td>45000000</td><td>消費者表</td></tr><tr><td>partsupp</td><td>80000000</td><td>240000000</td><td>配件供應表</td></tr><tr><td>orders</td><td>150000000</td><td>450000000</td><td>訂單表</td></tr><tr><td>lineitem</td><td>600037902</td><td>1799989091</td><td>訂單明細表</td></tr></tbody></table><p>Rapid 引擎表空間壓縮率：</p><table><tbody><tr><th>庫名</th><th>InnoDB 表空間文件總大小</th><th>Rapid 引擎表空間總大小</th><th>壓縮率</th></tr></tbody><tbody><tr><td>TPC-H SF100</td><td>184570593436</td><td>28728373248</td><td>6.42</td></tr><tr><td>TPC-H SF300</td><td>591644573888</td><td>74334864443</td><td>7.96</td></tr></tbody></table><p>各表結構關係如下圖所示：</p><p><img height="720" src="https://oscimg.oschina.net/oscnet/up-1c9a6376e22d965db5c040dd053da59ae6a.png" width="756" referrerpolicy="no-referrer"></p><h2>4、測試結果</h2><p>GreatSQL 8.0.32-25 中，採用全新的 Rapid 存儲引擎，使得其在 TPC-H 性能測試中表現大大優於此前的其他版本，也大大優於 MySQL 社區版、Percona Server MySQL、MariaDB 等數據庫。</p><p>在 TPC-H SF100 場景下，運行完全部 22 個 TPC-H 查詢 SQL 總耗時為<strong>79.28 秒</strong>。在 TPC-H SF300 場景下，運行完全部 22 個 TPC-H 查詢 SQL 總耗時為<strong>386.195 秒</strong>。</p><p>每條 SQL 詳細耗時如下：</p><table><tbody><tr><th>TPC-H Query</th><th>GreatSQL TPC-H SF100（32C64G）耗時（秒）</th><th>GreatSQL TPC-H SF300（32C64G）耗時（秒）</th></tr></tbody><tbody><tr><td>Q1</td><td>1.184</td><td>3.537</td></tr><tr><td>Q2</td><td>0.924</td><td>3.865</td></tr><tr><td>Q3</td><td>1.324</td><td>4.167</td></tr><tr><td>Q4</td><td>3.678</td><td>22.712</td></tr><tr><td>Q5</td><td>1.287</td><td>4.119</td></tr><tr><td>Q6</td><td>0.344</td><td>0.959</td></tr><tr><td>Q7</td><td>5.48</td><td>50.217</td></tr><tr><td>Q8</td><td>1.13</td><td>3.534</td></tr><tr><td>Q9</td><td>7.311</td><td>31.872</td></tr><tr><td>Q10</td><td>2.885</td><td>15.301</td></tr><tr><td>Q11</td><td>0.477</td><td>0.921</td></tr><tr><td>Q12</td><td>0.799</td><td>2.294</td></tr><tr><td>Q13</td><td>3.758</td><td>10.997</td></tr><tr><td>Q14</td><td>0.966</td><td>2.471</td></tr><tr><td>Q15</td><td>2.831</td><td>11.898</td></tr><tr><td>Q16</td><td>1.194</td><td>3.487</td></tr><tr><td>Q17</td><td>8.537</td><td>27.523</td></tr><tr><td>Q18</td><td>13.007</td><td>108.237</td></tr><tr><td>Q19</td><td>1.892</td><td>4.046</td></tr><tr><td>Q20</td><td>4.21</td><td>10.668</td></tr><tr><td>Q21</td><td>11.965</td><td>60.084</td></tr><tr><td>Q22</td><td>2.513</td><td>3.286</td></tr><tr><td>總耗時</td><td><strong>77.696</strong></td><td><strong>386.195</strong></td></tr></tbody></table><p>GreatSQL SF100 vs SF300（32C64G）對比示意圖如下</p><p><img height="400" src="https://oscimg.oschina.net/oscnet/up-a576e5fe8987d0e3b32a49b4122e603c754.png" width="981" referrerpolicy="no-referrer"></p><h2>5、測試步驟</h2><h3>5.1 安裝 GreatSQL</h3><p>請參考 GreatSQL 手冊內容：<strong>安裝指南</strong> ➥https://greatsql.cn/docs/8032-25/user-manual/4-install-guide/0-install-guide.html，完成 GreatSQL 安裝。</p><h3>5.2 生成 TPC-H 測試數據</h3><p>請參考 GreatSQL 手冊內容：<strong>TPC-H 性能測試</strong> ➥https://greatsql.cn/docs/8032-25/user-manual/10-optimze/3-2-benchmark-tpch.html，完成 TPC-H 工具編譯安裝。</p><p>運行 TPC-H <code>dbgen</code> 工具，生成數據文件，一共會生成 8 個表對應的 tbl 數據文件，例如：</p><pre><code class="language-shell">$ ./dbgen -vf -s 100
...

$ ls -l *tbl
-rw-r--r-- 1 root root  2463490271 Sep 26 09:20 customer.tbl
-rw-r--r-- 1 root root 79579694556 Sep 26 09:20 lineitem.tbl
-rw-r--r-- 1 root root        2224 Sep 26 09:20 nation.tbl
-rw-r--r-- 1 root root 17793116301 Sep 26 09:20 orders.tbl
-rw-r--r-- 1 root root 12209211160 Sep 26 09:20 partsupp.tbl
-rw-r--r-- 1 root root  2453234158 Sep 26 09:20 part.tbl
-rw-r--r-- 1 root root         389 Sep 26 09:20 region.tbl
-rw-r--r-- 1 root root   142869803 Sep 26 09:20 supplier.tbl
</code></pre><p>也可以參考 <strong>duckdb_dbgen.py</strong> ➥ <a href="https://gitee.com/GreatSQL/GreatSQL-Doc/blob/master/tpch/3.0.1/duckdb_dbgen.py">https://gitee.com/GreatSQL/GreatSQL-Doc/blob/master/tpch/3.0.1/duckdb_dbgen.py</a> 腳本做法，利用 duckdb 並行生成測試數據。</p><h3>5.3 創建 TPC-H 測試數據庫表並導入數據</h3><p>參考 GreatSQL 社區提供的 TPC-H 數據庫表初始化腳本：<strong>tpch-create-table.sql</strong> ➥ <a href="https://gitee.com/GreatSQL/GreatSQL-Doc/blob/master/tpch/3.0.1/tpch-create-table.sql%EF%BC%8C%E5%AE%8C%E6%88%90TPC-H%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%88%9B%E5%BB%BA%E3%80%82">https://gitee.com/GreatSQL/GreatSQL-Doc/blob/master/tpch/3.0.1/tpch-create-table.sql，完成 TPC-H 測試數據庫表創建。</a></p><pre><code class="language-shell">$ mysql -f &lt; tpch-create-table.sql
$ mysqlshow tpch100
Database: tpch100
+----------+
|  Tables  |
+----------+
| customer |
| lineitem |
| nation   |
| orders   |
| part     |
| partsupp |
| region   |
| revenue0 |
| supplier |
+----------+
</code></pre><p>利用 GreatSQL 的 <strong>parallel load data 特性</strong> ➥ <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fdocs%2F8032-25%2Fuser-manual%2F5-enhance%2F5-1-highperf-parallel-load.html" target="_blank">https://greatsql.cn/docs/8032-25/user-manual/5-enhance/5-1-highperf-parallel-load.html</a> 並行導入 TPC-H 測試數據。</p><p>需要先修改 GreatSQL 選項<code>secure_file_priv</code>設置，指向上述 workdir 所在目錄，重啓 GreatSQL 使之生效。</p><p>參考 GreatSQL 社區提供的併發導入腳本：<strong><a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fload-data-parallel.sh" target="_blank">load-data-parallel.sh</a></strong> ➥ <a href="https://gitee.com/GreatSQL/GreatSQL-Doc/blob/master/tpch/3.0.1/load-data-parallel.sh%EF%BC%8C%E5%AE%8C%E6%88%90%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E3%80%82">https://gitee.com/GreatSQL/GreatSQL-Doc/blob/master/tpch/3.0.1/load-data-parallel.sh，完成數據導入。</a></p><p><strong>提示</strong>：運行 LOAD DATA 導入數據時，可能會在 <code>tmpdir</code> 產生臨時文件，因此要保證 <code>tmpdir</code> 有足夠的剩餘可用磁盤空間。</p><h3>5.4 確認 Rapid 引擎設置，並加載數據到 secondary engine</h3><p>數據導入完成後，在開始運行 TPC-H 測試前，需要先將測試數據加載到 secondary engine 引擎中。</p><p>先執行下面命令，動態修改 Rapid 引擎最大可使用內存，其餘相關選項均為默認值：</p><pre><code class="language-sql">greatsql&gt; SET GLOBAL rapid_memory_limit = 68719476736;
greatsql&gt; SET GLOBAL rapid_worker_threads = 32;
</code></pre><p>之後，執行以下命令加載測試數據到 secondary engine：</p><pre><code class="language-sql">greatsql&gt; alter table customer secondary_load;
alter table lineitem secondary_load;
alter table nation secondary_load;
alter table orders secondary_load;
alter table part secondary_load;
alter table partsupp secondary_load;
alter table region secondary_load;
alter table supplier secondary_load;
</code></pre><p>這個過程需要一定時間，請耐心等待。</p><h3>5.5 執行 TPC-H 測試</h3><p>參考 GreatSQL 社區提供的 TPC-H 性能測試腳本，完成測試，並記錄各個 SQL 的耗時。</p><p>該測試腳本大概工作模式如下：</p><ol><li><p>先執行 22 個查詢 SQL，進行數據預熱，每條 SQL 各執行 2 次。</p></li><li><p>再分別執行 22 個查詢 SQL，每個 SQL 各執行 3 次。</p></li><li><p>每次執行 SQL 都會記錄其起止時間，及其耗時，如下面例所示：</p></li></ol><pre><code class="language-shell">[2023-09-27 01:38:45] BEGIN RUN TPC-H Q1 1 times
[2023-09-27 01:38:46] TPC-H Q1 END, COST: 1.301s


[2023-09-27 01:38:46] BEGIN RUN TPC-H Q1 2 times
[2023-09-27 01:38:47] TPC-H Q1 END, COST: 0.787s
</code></pre><p>上述結果中的 COST: 1.301s ，即為本 SQL 的運行耗時：1.301 秒。</p><p>完整性能測試報告：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgreatsql.cn%2Fdocs%2F8032-25%2Fuser-manual%2F10-optimze%2F3-3-benchmark-greatsql-tpch-report.html" target="_blank">https://greatsql.cn/docs/8032-25/user-manual/10-optimze/3-3-benchmark-greatsql-tpch-report.html</a></p></div>
                                    ]]>
            </description>
            <pubDate>Wed, 28 Feb 2024 01:49:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280571</guid>
            <link>https://www.oschina.net/news/280571</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[馬斯克抱怨微軟 Windows 難用，V 神：加入 Linux！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>特斯拉 CEO 埃隆・馬斯克在社交平台説道，上週末他購買了一台新款的 Windows 11 筆記本電腦，卻發現必須創建微軟賬戶 (MSA) 才能使用系統，這讓他感到非常憤怒，認為這變相地讓微軟的人工智能 (AI) 訪問了他的數據。</p><blockquote><p><img src="https://oscimg.oschina.net/oscnet/up-e5e820c2d6e02c58e0b272f4e8447623295.png" referrerpolicy="no-referrer"><em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FVitalikButerin%2Fstatus%2F1762363524918227423" target="_blank">https://twitter.com/VitalikButerin/status/1762363524918227423</a></u></em></p></blockquote><p>對此，<span style="background-color:#ffffff; color:#333333">以太坊聯合創始人 Vitalik Buterin（V 神）</span>建議馬斯克改用 Linux 桌面發行版。</p><p>X 上的一些用戶稱讚 V 神推廣了開源軟件。但也有人指出，Linux 可能不是馬斯克的最佳選擇，因為他使用 PC 的主要目的是玩遊戲。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 09:59:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280524</guid>
            <link>https://www.oschina.net/news/280524</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[GPL 抗辯成功——織夢 CMS「系列」版權糾紛迎來重大轉折]]>
            </title>
            <description>
                <![CDATA[<div class="content"><div><blockquote><p style="text-align:justify"><span style="color:#27ae60"><strong>摘要</strong></span></p><p style="text-align:justify"><span style="color:#4e5f70">原告：上海卓卓網絡科技有限公司（以下簡稱：卓卓公司）</span></p><p style="text-align:justify"><span style="color:#4e5f70">被告：****醫院</span></p><p style="text-align:justify"><span style="color:#4e5f70">事件：****醫院使用 DedeCMSV5.7-sp1 軟件開發網站，卓卓公司以擁有 DedeCMS Biz V1.0 以及後續多個版本的著作權為由，認為醫院侵犯了自己的著作權，要求***醫院賠償 5800 元的授權許可費和 8700 元的訴訟費用。</span></p><p style="text-align:justify"><span style="color:#4e5f70">判決：一審法院認為 DedeCMSV5.7-sp1 中包含 GPL 協議下開源的代碼，整體應遵守 GPL 協議，****醫院使用軟件不用支付授權費用，但仍需遵守署名權的要求。</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>持續近 3 年、涉及 300 萬用戶的織夢 CMS 「系列」版權糾紛案在</span></span></span><span><span><span>近</span></span></span><span><span><span>日迎來第一份抗辯成功判決。上海卓卓網絡科技有限公司自 2021 年起，以「織夢商業網站內容管理系統【簡稱：DedeCMS Biz】V1.0」著作權方的身份，在全國各地起訴多個網站中含有 DedeCMS 相關代碼的公司，要求賠償。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>2023 年 9 月 11 日，卓卓公司訴****醫院侵害計算機軟件著作權糾紛案件立案。2024 年 2 月 19 日，江蘇省無錫市中級人民法院</span></span></span><span><span><span>作出</span></span></span><span><span><span>一審判決書，認可了 GPL 的</span></span></span><span><span><span>「</span></span></span><span><span><span>傳染性</span></span></span><span><span><span>」</span></span></span><span><span><span>，涉案軟件（具體版本為 DedeCMSV5.7-sp1）整體按 GPL 對外許可，但要求使用者（被告）在網頁底部添加原告網址鏈接，不得侵犯原告的署名權。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>一審判決書在判決書送達之日起十五日，當事人沒有提起上訴的，就會生效。據案件知情人士分析，卓卓公司肯定會上訴。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>開源中國</span></span></span><span><span><span>從知情人處</span></span></span><span><span><span>獲取並查閲判決書。據判決書顯示，卓卓公司提出，卓卓通過受讓取得了 DedeCMS Biz V1.0 的軟件著作權，又在 DedeCMS Biz V1.0 版本的基礎上迭代出 DedeCMSV5.5、DedeCMSV5.6、DedeCMSV5.7 等版本。****醫院名下網站相關網頁相關源代碼與卓卓公司享有著作權的涉案軟件代碼相同，證據包括授權協議中的卓卓公司名稱、Powered By DedeCMS、織夢內容管理系統 DEDECMS 的 logo/mark 等等。但****醫院並未向卓卓公司購買正版涉案軟件，也從未獲得過卓卓公司商業使用授權許可。因此卓卓要求****醫院支付涉案軟件 DedeCMS 軟件的授權許可費 5800 元，以及卓卓公司為訴訟所指出的 8700 元費用，共計 14500 元。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>而****醫院辯稱：卓卓雖然通過受取得 DedeCMS Biz V1.0 的軟件著作權，但沒有證據能夠證明卓卓公司是織夢內容管理系統 DedeCMS 軟件的著作權人。此外，DedeCMS 是一款以 GPL 協議對外許可發佈的開源軟件，DedeCMS 後續版本包括涉案權利軟件都是在 DedeCMSV3 版本基礎上迭代升級的，因此受 GPL 約束。根據 GPL 協議禁止添加商業使用的限制條款，也不允許著作權人就軟件本身收取授權許可費。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>此外，圍繞案件，卓卓公司和****醫院還列舉了多項訴求與證據，詳情可查看一審判決書（尚未生效）。</span></span></span></span></span></span></p><div><blockquote><div><span style="color:#4e5f70">此份判決書由知情人提供並脫密：https://report.oschina.net/api/files/jhim80u9qm1ofsw/79ci47r1rrt9yqm/2023_02_482_cEvUNytTpS.pdf</span></div></blockquote></div><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>法院總結此案件爭議焦點有兩個：</span></span></span></span></span></span></p><div><blockquote><div><span style="color:#4e5f70">綜合雙方的訴辯主張，並經雙方確認，本院對本案的爭議焦點歸納為：</span></div><div><span style="color:#4e5f70">一、涉案權利軟件的著作權人是否是卓卓公司；</span></div><div><span style="color:#4e5f70">二、****醫院是否有權依據 GPL 協議免費使用涉案權利軟件</span></div></blockquote></div><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>針對第一點，法院認為：</span></span></span></span></span></span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span style="color:#4e5f70">涉案權利軟件的著作權人是卓卓公司。</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>針對第二點，法院認為：</span></span></span></span></span></span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span>&nbsp;</span><span><span><span><span style="color:#646a73">涉案軟件 DedeCMSV5.7-sp1&nbsp;是包含採用 GPLV2.0 及以後版本做為協議的 sphinxclient 的派生作品。……由此本案中卓卓公司將涉案軟件進行發佈代表卓卓公司已經接受 GPL 協議。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#646a73">……</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#646a73">涉案軟件應當遵守 GPL 協議，卓卓公司在涉案軟件的許可協議中的「商業用途需獲得授權」的條款與 GPL 協議</span></span></span><span><span><span style="color:#646a73">相</span></span></span><span><span><span style="color:#646a73">牴觸，卓卓公司有義務按照 GPL 協議將涉案軟件整體授權給獲得許可的人，****醫院因 GPL 協議獲得了對涉案軟件使用的授權，並未侵犯卓卓公司的複製權，卓卓公司無權對此行為請求支付授權費用。</span></span></span></span></span><span>&nbsp;</span></p></blockquote><p><span>不過，法院認為****醫院需在網站註明來源是卓卓公司。</span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span>&nbsp;</span><span><span><span><span style="color:#646a73">卓卓公司在許可協議中載明用戶應在使用涉案軟件建成網站的主頁標註網站鏈接 www.dedecms.com，該條款並不構成對下游接收者對軟件複製、分發、修改權利的限制，應當有效。</span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span><span style="color:#646a73">……</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span style="color:#646a73">GPL 協議作為許可協議有雙務性，被許可人在行使複製、發佈修改開源軟件的權利時，也需要按照協議要求承擔相應義務，****醫院使用涉案軟件 DedeCMS 建成了網站，但未在主頁標註卓卓公司創作印記或官網鏈接，違反了該附加條款，侵害了卓卓公司的署名權，損害了卓卓公司的身份權益。故卓卓公司請求****醫院賠償損失並賠禮道歉，具有事實和法律依據，本院予以支持。</span></span></span></span></span><span>&nbsp;</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>最終，法院判定由****醫院賠償卓卓公司經濟損失及合理維權開支共 800 元，並在判決生效之日起十日內在其公司網站主頁發佈為期三十日的賠禮道歉聲明。在關於賠償金額的表述中，法院的考量因素中還提到兩點值得關注：</span></span></span></span></span></span></p><blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span style="color:#4e5f70">第三，卓卓公司主張****醫院在內的用戶需遵守涉案軟件的許可協議，但卓卓公司在使用他人代碼時卻未遵守他人軟件的 GPL 許可協議，其行為本身有違誠信原則，具有不正當性。卓卓公司自身對涉案軟件的著作權也存在管理不周的情況，軟件源代碼中記錄的版權信息、署名都未直接指向卓卓公司，源代碼中不同位置的許可協議條款存在不一致的情形。</span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span style="color:#4e5f70">第四，卓卓公司以涉案軟件為權利基礎，在全國法院提起大量侵害計算機軟件著作權糾紛案件，並因此獲得較大收益，該種維權模式既不利於有效打擊侵權源頭，又大量佔用解決糾紛的公共資源，不宜提倡和鼓勵。</span></p></blockquote><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>此外，據企查查信息顯示，上海卓卓發起了多起侵害計算機軟件著作權糾紛訴訟，自 2 月 28 日-3 月 30 日將陸續有案件開庭。</span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><img height="522" src="https://static.oschina.net/uploads/space/2024/0227/170855_5DFc_4489239.png" width="600" referrerpolicy="no-referrer"></p><p style="margin-left:.0001pt; margin-right:0; text-align:left"><span><span><span><span><span><span>開源中國將持續關注 DedeCMS 系列版權糾紛案件進展，本週內也將梳理此係列糾紛的時間線，歡迎知情者私信爆料。</span></span></span></span></span></span></p></div></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 09:10:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280518/gpl-dedecms</guid>
            <link>https://www.oschina.net/news/280518/gpl-dedecms</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[白宮敦促開發者改用內存安全的編程語言]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">白宮國家網絡主任辦公室 (ONCD) <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.whitehouse.gov%2Foncd%2Fbriefing-room%2F2024%2F02%2F26%2Fpress-release-technical-report%2F" target="_blank">發佈</a>了一份報告，呼籲科技界主動減少網絡空間的攻擊面；通過改用 Rust 等內存安全編程語言，減少內存安全漏洞的數量來提高軟件安全性。同時鼓勵研究界解決軟件可測量性問題，以便開發出更好的測量網絡安全質量的診斷方法。</span></p><p><img height="390" src="https://oscimg.oschina.net/oscnet/up-7cb1183993aa2d8ce4f54a8bb5787fa09a7.png" width="300" referrerpolicy="no-referrer"></p><p><span style="color:#000000">ONCD 例舉了歷史上一些著名的網絡攻擊事件，包括：1988 年的 Morris 蠕蟲病毒、2003 年的 Slammer 蠕蟲病毒、2014 年的 Heartbleed 漏洞、2016 年的 Trident 漏洞、2023 年的 Blastpass 漏洞。並指出，所有這些問題的背後都有一個共同的根本原因，即內存安全漏洞。</span></p><p><span style="color:#000000">報告稱：「35 年來，三十五年來，內存安全漏洞一直困擾着數字生態系統，但情況本不必如此。消除整類軟件漏洞的挑戰是一個緊迫而複雜的問題。展望未來，必須採取新方法來減輕這種風險。」</span></p><p><span style="color:#000000">「減少內存安全漏洞的最高槓桿方法是保護網絡空間的構建模塊之一：編程語言。使用內存安全編程語言可以消除大多數內存安全錯誤。」</span></p><p><span style="color:#000000">在此之前，</span><span style="background-color:#ffffff"><span style="color:#000000">美國國家安全局 (NSA) 曾於 2022 年 11 月發佈了關於軟件開發人員如何防止軟件內存安全問題的</span><a href="https://www.oschina.net/news/217425/nsa-memory-safe-programming-language" target="_blank">指南。</a></span><span style="background-color:#ffffff; color:#000000">美國網絡安全與基礎設施安全局 (CISA)<span>&nbsp;</span></span><span style="color:#070707"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span style="background-color:#ffffff"><span><span><span>也在 2023 年 12 月發佈了類似<a href="https://www.oschina.net/news/269933/cisa-the-case-for-memory-safe-roadmaps">報告</a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="color:#000000"><span style="background-color:#ffffff">，</span>要求過渡到內存安全編程語言，通過消除與內存相關的漏洞來減少軟件產品的攻擊面。</span></p><p><span style="color:#000000">ONCD 報告以美國總統拜登於 2023 年 3 月簽署的</span><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Fwhite-house-releases-new-us-national-cybersecurity-strategy%2F" target="_blank">國家網絡安全戰略</a><span style="color:#000000">為基礎，將網絡安全的責任從個人和小型企業轉移到技術公司和聯邦政府等更有能力管理不斷變化的威脅的大型組織身上。並在與整個聯邦政府的安全設計計劃和研發工作保持一致的同時更進一步，涵蓋了由 CISA、NSA、FBI 和 NIST 領導的計劃和研發工作。</span></p><p><span style="color:#000000">報告中有關內存安全的工作還補充了美國國會對此主題的興趣。此外，美國參議院國土安全和政府事務委員會主席 Gary Peters (D-MI) 和美國參議員 Ron Wyden (D-OR) 也向 ONCD 強調了他們在內存安全方面的立法努力。</span></p><p><span style="color:#000000">更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.whitehouse.gov%2Fwp-content%2Fuploads%2F2024%2F02%2FFinal-ONCD-Technical-Report.pdf" target="_blank">查看完整報告</a>。</span></p><p><strong><span style="color:#000000">相關閲讀：</span></strong></p><ul><li><a href="https://www.oschina.net/news/217425/nsa-memory-safe-programming-language" target="_blank">美國國家安全局建議從 C/C++ 切換到內存安全語言</a></li><li><a href="https://www.oschina.net/news/269933/cisa-the-case-for-memory-safe-roadmaps" target="_blank">美國 CISA 建議放棄 C/C++，消除內存安全漏洞</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 08:33:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280505/white-house-memory-safe-programming-languages</guid>
            <link>https://www.oschina.net/news/280505/white-house-memory-safe-programming-languages</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[南京大學將開通全國高校首家 AI 課程]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">南京大學正式發佈全國高校首家面向 3700 餘名新生開設的「1+X+Y」三層次的人工智能通識核心課總體方案。</span></p><p><span style="color:#000000">該方案包含 1 門必修的人工智能通識核心課，X 門人工智能素養課，Y 門各學科與人工智能深度融合的前沿拓展課。其中，1 門人工智能通識核心課面向對象為 2024 年起面向全體本科新生。</span></p><p><span style="color:#000000"><img height="256" src="https://oscimg.oschina.net/oscnet/up-c46928165fcc29d00ea987b62dd6db02a66.png" width="500" referrerpolicy="no-referrer"></span></p><p><span style="color:#000000">南京大學黨委書記、中國科學院院士譚鐵牛指出，當今世界，由人工智能引領的新一輪科技革命和產業變革方興未艾。在移動互聯網、大數據、超級計算、傳感網、腦科學等新理論新技術驅動下，人工智能已經對經濟發展、社會進步、全球治理等各方面產生重大而深遠的影響。只有緊跟時代步伐，把握時代脈搏，才能順勢而上，應勢而為，把創新主動權、發展主動權牢牢掌握在自己手中。</span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 08:03:42 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280497</guid>
            <link>https://www.oschina.net/news/280497</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[0201-0225 開放籤團隊工作日記]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span><span><span><span>2022 年底</span></span></span><span><span><span>團隊決定</span></span></span><span><span><span>以全新的產品運營和設計思路重回電子簽章行業，重新做</span></span></span><span><span><span>電子簽章</span></span></span><span><span><span>產品。至於當時如何離開電子簽章，又是如何回來的，具體原因等後面再敍。在這麼多年的創業的過程中，我們團隊經歷了從迷茫無助到方向堅定（我們認為的），從一點點構建基礎技術架構到基本成熟，有太多的不容易，每一個不容易都可以是個故事，具體的也在將來一一再敍，這次單説最近的一些工作感受和工作概況。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>經過努力</span></span></span><span><span><span>，23 年底（12 月 15 日）</span></span></span><span><span><span>產品</span></span></span><span><span><span>上線</span></span></span><span><span><span>後</span></span></span><span><span><span>，我們深知自己在</span></span></span><span><span><span>市場競爭中與頭部企業仍存在功能層面的差距</span></span></span><span><span><span>，不敢妄想有什麼好的反饋和成果。但是首</span></span></span><span><span><span>月</span></span></span><span><span><span>便</span></span></span><span><span><span>迎來了</span></span></span><span><span><span>付費用戶</span></span></span><span><span><span>（企業版）和近</span></span></span><span><span><span>百</span></span></span><span><span><span>個開源用戶</span></span></span><span><span><span>，</span></span></span><span><span><span>這完全出乎我和同事的意料</span></span></span><span><span><span>。剛開始我們以為這些用戶至少要在 3-5 個月內才能積累到。事實證明我們錯了，我們保守了，但是方向貌似對了（還需要更多的付出和積累）。在與客戶溝通過程中，很快就收集到</span></span></span><span><span><span>首批客戶集中提出</span></span></span><span><span><span>的眾多需求，主要體現在</span></span></span><span><span><span>移動端簽署、API 集成、</span></span></span><span><span><span>國產化</span></span></span><span><span><span>及優化交互體驗</span></span></span><span><span><span>四大方面。也有很多我們在設計過程中沒有考慮到的，沒有考慮到的方面對我們來説尤其珍貴，價值巨大。</span></span></span><span><span><span>所以</span></span></span><span><span><span>我們在年前</span></span></span><span><span><span>加快工作節奏，</span></span></span><span><span><span>年後規劃新年一季度目標。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>首要任務是</span></span></span><span><span><span>移動端開發，並承諾於春節後第一週交付新功能。</span></span></span><span><span><span>這段時間的工作節奏是這樣的：</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>1、</span></span></span><span><span><span>臨近春節</span></span></span><span><span><span>（</span></span></span><span><span><span>農曆 28 日</span></span></span><span><span><span>）</span></span></span><span><span><span>我們完成了功能開</span></span></span><span><span><span>發，勉強通過冒煙測試</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>2、</span></span></span><span><span><span>年後進行系統和功能測試時，</span></span></span><span><span><span>出乎意料的事情接踵而至</span></span></span><span><span><span>，</span></span></span><span><span><span>出現了</span></span></span><span><span><span>移動端鏈接邏輯</span></span></span><span><span><span>跳轉混亂</span></span></span><span><span><span>、文件簽署內存異常、</span></span></span><span><span><span>簽署</span></span></span><span><span><span>圖片丟失、簽署控件重複等</span></span></span><span><span><span>問題</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>3、</span></span></span><span><span><span>測試同學「大壯」在羣裏</span></span></span><span><span><span>發飆了，</span></span></span><span><span><span>講述上線風險和延期上線的請求</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>4、不動聲色的產品負責人老胡看到</span></span></span><span><span><span>請求</span></span></span><span><span><span>後</span></span></span><span><span><span>一直未回覆（他的性格很剛強，表面不説，內心很要強）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>5、老胡</span></span></span><span><span><span>開始</span></span></span><span><span><span>着手</span></span></span><span><span><span>理清工作任務，</span></span></span><span><span><span>逐條分析 BUG，確定優先級。</span></span></span><span><span><span>···········（結果：原定計劃</span></span></span><span><span><span>（2 月 25 日）</span></span></span><span><span><span>未完成上線）只好協調大家</span></span></span><span><span><span>週六日</span></span></span><span><span><span>繼續</span></span></span><span><span><span>通宵奮戰</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>6、</span></span></span><span><span><span>直至</span></span></span><span><span><span>2 月 26 日</span></span></span><span><span><span>凌晨五點成功修復所有問題並上線新版本</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>這個過程真是酸爽，自從決定做開放籤以來，首先內心是非常欣慰的，工作狀態也超好，整個團隊也是熱情澎湃的，甚至自然而然的解決了一些團隊管理問題。</span></span></span><span><span><span>同樣的產品不同的公司，都是為了服務客戶</span></span></span><span><span><span>和理想在</span></span></span><span><span><span>奮鬥</span></span></span><span><span><span>、在</span></span></span><span><span><span>熬夜，感謝</span></span></span><span><span><span>團</span></span></span><span><span><span>隊成員的努力付出</span></span></span><span><span><span>！加油！（會想盡一切辦法和努力給大家加雞腿，讓我們</span></span></span><span><span><span>的</span></span></span><span><span><span>產品更好</span></span></span><span><span><span>，</span></span></span><span><span><span>團隊更頑強</span></span></span><span><span><span>，客戶更放心</span></span></span><span><span><span>........）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>值得欣喜的是，按照約定我們成功完成版本更新</span></span></span><span><span><span>，</span></span></span><span><span><span>並與兩家新客戶簽約。接下來，我們將採取敏捷迭代策略，小步快跑地滿足需求</span></span></span><span><span><span>。</span></span></span><span><span><span>同時大膽創新簽約場景模式，使更多企業在真實場景下實現高效合規</span></span></span><span><span><span>簽署，讓電子籤更簡單不是説説而已</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:right"><span><span><span><span><span><span><span>2024 年 02 月 27 日</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 07:32:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280492</guid>
            <link>https://www.oschina.net/news/280492</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
    </channel>
</rss>
