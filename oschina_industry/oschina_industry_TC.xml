<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title>
            <![CDATA[開源中國-綜合資訊]]>
        </title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="https://rsshub.app/oschina/news/industry" rel="self" type="application/rss+xml" />
        <description>
            <![CDATA[開源中國-綜合資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]>
        </description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 27 Feb 2024 08:00:25 GMT</lastBuildDate>
        <ttl>120</ttl>
        <item>
            <title>
                <![CDATA[0201-0225 開放籤團隊工作日記]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="margin-left:0.0001pt; margin-right:0px"><span><span><span><span><span><span><span>2022 年底</span></span></span><span><span><span>團隊決定</span></span></span><span><span><span>以全新的產品運營和設計思路重回電子簽章行業，重新做</span></span></span><span><span><span>電子簽章</span></span></span><span><span><span>產品。至於當時如何離開電子簽章，又是如何回來的，具體原因等後面再敍。在這麼多年的創業的過程中，我們團隊經歷了從迷茫無助到方向堅定（我們認為的），從一點點構建基礎技術架構到基本成熟，有太多的不容易，每一個不容易都可以是個故事，具體的也在將來一一再敍，這次單説最近的一些工作感受和工作概況。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>經過努力</span></span></span><span><span><span>，23 年底（12 月 15 日）</span></span></span><span><span><span>產品</span></span></span><span><span><span>上線</span></span></span><span><span><span>後</span></span></span><span><span><span>，我們深知自己在</span></span></span><span><span><span>市場競爭中與頭部企業仍存在功能層面的差距</span></span></span><span><span><span>，不敢妄想有什麼好的反饋和成果。但是首</span></span></span><span><span><span>月</span></span></span><span><span><span>便</span></span></span><span><span><span>迎來了</span></span></span><span><span><span>付費用戶</span></span></span><span><span><span>（企業版）和近</span></span></span><span><span><span>百</span></span></span><span><span><span>個開源用戶</span></span></span><span><span><span>，</span></span></span><span><span><span>這完全出乎我和同事的意料</span></span></span><span><span><span>。剛開始我們以為這些用戶至少要在 3-5 個月內才能積累到。事實證明我們錯了，我們保守了，但是方向貌似對了（還需要更多的付出和積累）。在與客戶溝通過程中，很快就收集到</span></span></span><span><span><span>首批客戶集中提出</span></span></span><span><span><span>的眾多需求，主要體現在</span></span></span><span><span><span>移動端簽署、API 集成、</span></span></span><span><span><span>國產化</span></span></span><span><span><span>及優化交互體驗</span></span></span><span><span><span>四大方面。也有很多我們在設計過程中沒有考慮到的，沒有考慮到的方面對我們來説尤其珍貴，價值巨大。</span></span></span><span><span><span>所以</span></span></span><span><span><span>我們在年前</span></span></span><span><span><span>加快工作節奏，</span></span></span><span><span><span>年後規劃新年一季度目標。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>首要任務是</span></span></span><span><span><span>移動端開發，並承諾於春節後第一週交付新功能。</span></span></span><span><span><span>這段時間的工作節奏是這樣的：</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>1、</span></span></span><span><span><span>臨近春節</span></span></span><span><span><span>（</span></span></span><span><span><span>農曆 28 日</span></span></span><span><span><span>）</span></span></span><span><span><span>我們完成了功能開</span></span></span><span><span><span>發，勉強通過冒煙測試</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>2、</span></span></span><span><span><span>年後進行系統和功能測試時，</span></span></span><span><span><span>出乎意料的事情接踵而至</span></span></span><span><span><span>，</span></span></span><span><span><span>出現了</span></span></span><span><span><span>移動端鏈接邏輯</span></span></span><span><span><span>跳轉混亂</span></span></span><span><span><span>、文件簽署內存異常、</span></span></span><span><span><span>簽署</span></span></span><span><span><span>圖片丟失、簽署控件重複等</span></span></span><span><span><span>問題</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>3、</span></span></span><span><span><span>測試同學「大壯」在羣裏</span></span></span><span><span><span>發飆了，</span></span></span><span><span><span>講述上線風險和延期上線的請求</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>4、不動聲色的產品負責人老胡看到</span></span></span><span><span><span>請求</span></span></span><span><span><span>後</span></span></span><span><span><span>一直未回覆（他的性格很剛強，表面不説，內心很要強）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>5、老胡</span></span></span><span><span><span>開始</span></span></span><span><span><span>着手</span></span></span><span><span><span>理清工作任務，</span></span></span><span><span><span>逐條分析 BUG，確定優先級。</span></span></span><span><span><span>···········（結果：原定計劃</span></span></span><span><span><span>（2 月 25 日）</span></span></span><span><span><span>未完成上線）只好協調大家</span></span></span><span><span><span>週六日</span></span></span><span><span><span>繼續</span></span></span><span><span><span>通宵奮戰</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>6、</span></span></span><span><span><span>直至</span></span></span><span><span><span>2 月 26 日</span></span></span><span><span><span>凌晨五點成功修復所有問題並上線新版本</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>這個過程真是酸爽，自從決定做開放籤以來，首先內心是非常欣慰的，工作狀態也超好，整個團隊也是熱情澎湃的，甚至自然而然的解決了一些團隊管理問題。</span></span></span><span><span><span>同樣的產品不同的公司，都是為了服務客戶</span></span></span><span><span><span>和理想在</span></span></span><span><span><span>奮鬥</span></span></span><span><span><span>、在</span></span></span><span><span><span>熬夜，感謝</span></span></span><span><span><span>團</span></span></span><span><span><span>隊成員的努力付出</span></span></span><span><span><span>！加油！（會想盡一切辦法和努力給大家加雞腿，讓我們</span></span></span><span><span><span>的</span></span></span><span><span><span>產品更好</span></span></span><span><span><span>，</span></span></span><span><span><span>團隊更頑強</span></span></span><span><span><span>，客戶更放心</span></span></span><span><span><span>........）</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:justify"><span><span><span><span><span><span><span>值得欣喜的是，按照約定我們成功完成版本更新</span></span></span><span><span><span>，</span></span></span><span><span><span>並與兩家新客戶簽約。接下來，我們將採取敏捷迭代策略，小步快跑地滿足需求</span></span></span><span><span><span>。</span></span></span><span><span><span>同時大膽創新簽約場景模式，使更多企業在真實場景下實現高效合規</span></span></span><span><span><span>簽署，讓電子籤更簡單不是説説而已</span></span></span><span><span><span>。</span></span></span></span></span></span></span></p><p style="margin-left:.0001pt; margin-right:0; text-align:right"><span><span><span><span><span><span><span>2024 年 02 月 27 日</span></span></span></span></span></span></span></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 07:32:21 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280492</guid>
            <link>https://www.oschina.net/news/280492</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Spring Boot 拒絕用 AI 為倉庫自動生成註釋]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="color:#000000">一名開發者近日在 Spring Boot 提交了一項 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-boot%2Fpull%2F39754%2F" target="_blank">PR</a>，旨在使用 AI 模型為整個 Spring Boot 代碼庫添加註釋：</span></p><blockquote><p><span style="color:#000000">此代碼變更為整個 Spring Boot 代碼庫添加了註釋。本 PR 的內容完全由自定義微調 AI 模型創建。</span></p><p><span style="color:#000000">我們正在對我們的工具進行大規模實驗，在數百萬行代碼上運行該工具，以識別任何 bug 或錯誤。在此代碼庫中運行時，該工具的編譯成功率高達 99.9%。</span></p><p><span style="color:#000000">我們可以選擇放棄這些代碼，或者將其發佈並作為一項貢獻。我們選擇了後者，並決定打開此 Pull Request。</span></p></blockquote><p><img height="280" src="https://oscimg.oschina.net/oscnet/up-c694ca89e5d80a24accaf670c4f099452bc.png" width="700" referrerpolicy="no-referrer"></p><p><span style="color:#000000">但 Spring Boot 項目負責人 Phil Webb 對此進行了婉拒。並表示，相較自動生成，團隊成員更喜歡人工手動的方式；且自動生成這種無差別的方式，很可能給整個倉庫增添許多不必要的麻煩。</span></p><p><span style="color:#000000">「我認為您的工具對於正在學習代碼庫或需要某些部分的額外幫助的人來説可能非常有用。」</span></p><p>Reddit 上的一些討論也表達了對這一提議的<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F1b0n9kx%2Fai_added_comments_for_the_entire_code_base_of%2F" target="_blank">不看好</a>：</p><blockquote><p>「哇，這太可怕了。我真希望這只是個玩笑，提出要求的人只是在嘲笑這個想法。」</p><p>「如果這不是純粹為了吸引眼球，那麼我想公關背後的開發人員可以説是真的缺乏開發技能。」</p></blockquote><p>目前，相關 PR 已被關閉。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 06:21:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280473/ai-comments-spring-boot</guid>
            <link>https://www.oschina.net/news/280473/ai-comments-spring-boot</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[開源日報 | 鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。</p><h3><span style="color:#e67e22"><strong># 2024.2.26</strong></span></h3><h2><strong><span style="color:#16a085">今日要點</span></strong></h2><p><strong>OpenSource Daily</strong></p><h3><a href="https://www.oschina.net/news/280197/warp-for-linux" target="_blank">基於 Rust 開發的終端應用 Warp 發佈 Linux 版本</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">Warp 是一個基於 Rust 開發的現代化終端應用，內置 AI 功能，支持 CPU 加速。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left">此前 Warp 僅面向 Mac 平台提供，近日其開發團隊終於<u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.warp.dev%2Fblog%2Fwarp-for-linux" target="_blank">發佈</a></u>了 Linux 版本，用戶可在大多數主流 Linux 發行版上安裝 Warp，包括 Ubuntu、Fedora、Arch Linux 或 Red Hat。</p><h3><a href="https://www.oschina.net/news/280083/wubuntu-windows-ubuntu" target="_blank">Wubuntu：披着 Windows 11 外衣的 Ubuntu</a></h3><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><strong>Wubuntu，又稱 "Windows Ubuntu"</strong>，是基於 Ubuntu 開發的操作系統，其最具特色之處在於<strong>完全復刻了 Windows 的所有外觀和功能</strong>，而且運行時不需要具備 TPM、安全啓動或任何其他硬件要求。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:left"><span>此外，Wubuntu</span>&nbsp;通過集成 Wine 提供了與 Windows 應用的兼容性，開發者稱 Wubuntu 支持運行 Windows 的 .exe 和 .msi&nbsp;程序，以及支持 Android 應用。</p><p><img src="https://oscimg.oschina.net/oscnet/up-b78011bce450db4cf20d1bb7cc559cd4cb6.png" referrerpolicy="no-referrer"></p><hr><h2><strong><span style="color:#16a085">今日觀察</span></strong></h2><p><img src="https://oscimg.oschina.net/oscnet/up-a5cb30243de8b0b91be1d481043c473ad9e.png" referrerpolicy="no-referrer"></p><p><span style="background-color:#ffffff; color:#333333">- </span><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tmtpost.com%2F6949344.html" target="_blank">鈦媒體</a></em></u></p><hr><h2><span style="color:#16a085"><strong>今日推薦</strong></span></h2><p><img src="https://oscimg.oschina.net/oscnet/up-dd0b05ccdc75b8e461bccd191d8b02a887a.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>開源之聲</strong></span></h2><p><img height="376" src="https://oscimg.oschina.net/oscnet/up-61ab492b02eb694af46583aa700ca993ddd.png" width="1104" referrerpolicy="no-referrer"></p><p><img src="https://oscimg.oschina.net/oscnet/up-393f28205ac4c95982b1545e5541957f5f9.png" referrerpolicy="no-referrer"></p><hr><h2><span style="color:#16a085"><strong>每日項目榜</strong></span></h2><p><strong><span style="background-color:#e67e22">每日 Gitee 精選</span></strong></p><p><img src="https://oscimg.oschina.net/oscnet/up-f0e8ff0ed6f05f1864bb5c951acca5d3893.png" referrerpolicy="no-referrer"></p><blockquote><h4><strong><span style="background-color:#e67e22">在線閲讀完整日報內容，訪問：</span></strong><br><u><em><strong><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/6typ9w3u98f5mxn/16_1_8_2efTeNfFjN.pdf">開源日報第 016 期：鴻蒙程序員平均月薪超 1 萬 8；中美 AI 差距有多大？</a></strong></em></u></h4></blockquote><hr><p><strong>往期回顧</strong></p><ul><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/92n4c9ryegpcq1z/015_sora_KcAkRNX93Y.pdf">開源日報第 015 期：為什麼擋不住英偉達；Sora 不靠蠻力</a></li><li><a href="https://report.oschina.net/api/files/jhim80u9qm1ofsw/s7n800w84o6guyv/014_kyezhNxOGD.pdf">開源日報第 014 期：目前的人工智能技術連貓的智能水平都沒達到</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC013%E6%9C%9F%EF%BC%9A%E7%AD%89%E5%88%B0%20Sora%20%E5%BC%80%E6%BA%90%E4%BA%86%E7%AB%8B%E5%88%BB%E6%8E%A8%E5%87%BA%E5%B1%9E%E4%BA%8E%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B.pdf">開源日報第 013 期：等到 Sora 開源了立刻推出屬於我們自己的大模型</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC012%E6%9C%9F%EF%BC%9ASora%20%E7%BB%99%E4%B8%AD%E5%9B%BD%20AI%20%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%8F%98%E5%8C%96%EF%BC%9BDart%203.3%20%E5%8F%91%E5%B8%83.pdf">開源日報第 012 期：Sora 給中國 AI 帶來的真實變化；Dart 3.3 發佈</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC11%E6%9C%9F%EF%BC%9A%E7%9B%AE%E5%89%8D%E8%BF%98%E6%B2%A1%E6%9C%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%89%88Linux%E2%80%9D.pdf">開源日報第 011 期：目前還沒有「大模型版 Linux」</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5%E7%AC%AC010%E6%9C%9F%EF%BC%9ATauri%20v2%20%E6%94%AF%E6%8C%81%20Android%20%E5%92%8C%20iOS%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%96%B0%E9%80%89%E6%8B%A9.pdf">開源日報第 010 期：Tauri v2 支持 Android 和 iOS，跨平台開發新選擇</a></li><li><a href="https://oscimg.oschina.net/public_shard/%E5%BC%80%E6%BA%90%E6%97%A5%E6%8A%A5009%E6%9C%9F%EF%BC%9AVue.js%E8%AF%9E%E7%94%9F10%E5%91%A8%E5%B9%B4%EF%BC%9B%E6%89%8E%E5%85%8B%E4%BC%AF%E6%A0%BC%E8%A7%A3%E9%87%8AMeta%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E6%BA%90%E5%85%B6AI%E6%8A%80%E6%9C%AF.pdf">開源日報第 009 期：Vue.js 誕生 10 週年；扎克伯格解釋 Meta 為什麼要開源其 AI 技術</a></li><li><a href="https://www.oschina.net/news/277585">開源日報第 008 期：推動中國開源軟硬件發展的經驗與建議</a></li><li><a href="https://www.oschina.net/news/277415">開源日報第 007 期：「Linux 中國」 開源社區宣佈停止運營</a></li><li><a href="https://www.oschina.net/news/277214">開源日報第 006 期：選擇技術棧一定要選擇開源的</a></li><li><a href="http://www.oschina.net/news/277040">開源日報第 005 期：RISC-V 萬兆開源交換機發售；npm 存在大量武林外傳視頻</a></li><li><a href="https://www.oschina.net/news/276864">開源日報第 004 期：百度輸入法在候選詞區域植入廣告；大神用 Excel 構建 CPU</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 04:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280457</guid>
            <link>https://www.oschina.net/news/280457</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[OSI 發佈報告，研究 BSL 這樣的「延遲開源發佈」]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><span style="background-color:#ffffff">Open Source Initiative（OSI）近期發佈了一個報告《Delayed Open Source Publication:&nbsp;</span>A Survey of Historical and Current Practices<span style="background-color:#ffffff; color:#060607">》（</span>延遲開源發佈：歷史與當前實踐調研<span style="background-color:#ffffff; color:#060607">），作者是 Seth Schoen、James Vasile 和 Karl Fogel。</span></p><p>&nbsp;</p><p style="color:#060607; margin-left:0; margin-right:0; text-align:start">Delayed Open Source Publication，簡稱 DOSP，延遲開源發佈的意思，這份報告研究了它的歷史和現狀。報告核心要點：</p><p style="margin-left:0; margin-right:0"><strong>延遲開源發佈（DOSP）定義</strong>：DOSP 是指軟件最初在專有許可下發布，然後計劃性地在某個時間點將源代碼以開源許可的形式公開。</p><p style="margin-left:0; margin-right:0"><strong>歷史背景</strong>：DOSP 的做法可以追溯到 GNU 項目，並且一直延續至今。公司嘗試各種商業模式，以在有限時間內保持獨家權利，然後過渡到 OSI（開放源代碼倡議）批准的許可。</p><p style="margin-left:0; margin-right:0"><strong>策略類型</strong>：DOSP 分為三種類型：無條件計劃性重新許可、事件驅動的重新許可和有條件的重新許可。</p><p style="margin-left:0; margin-right:0"><strong>商業源許可（BUSL）</strong>：BUSL 是一種新興的 DOSP 許可方式，它要求在特定的「變更日期」後，軟件的許可將變為開源許可。這種做法在數據庫系統中尤為常見。（以往也叫 BSL）</p><p style="margin-left:0; margin-right:0">以下是當前知名的 16 個使用 BUSL 的項目，都是延遲幾年後轉型成開源協議：</p><p style="margin-left:0; margin-right:0"><img height="1588" src="https://static.oschina.net/uploads/space/2024/0227/115012_ybIG_3820517.png" width="1434" referrerpolicy="no-referrer"></p><p style="margin-left:0; margin-right:0"><strong>反競爭條款</strong>：一些 DOSP 許可中包含反競爭條款，旨在防止許可證持有者使用軟件提供與許可方直接競爭的服務。</p><p style="margin-left:0; margin-right:0"><strong>後果和影響</strong>：從開源許可轉變為 DOSP 許可的項目可能會受到批評，有時會導致用戶轉向其他項目或維護競爭性的分支。</p><p style="margin-left:0; margin-right:0"><strong>未來研究問題</strong>：報告提出了一些未來研究的問題，包括 AGPL 與 DOSP 許可的比較、DOSP 對外部貢獻的影響、BUSL 額外使用授權的分類、以及在初始開源發佈後重新許可的策略。</p><p style="margin-left:0; margin-right:0"><strong>結論</strong>：DOSP 自開源運動早期以來一直在使用，公司通常利用它來保持商業優勢，同時儘可能保留開源的優勢。報告強調，DOSP 的實驗性和多樣性比預期的要多，且這種趨勢可能會繼續。</p><p>詳情可以查看<a href="https://apiv1.oschina.net/api/files/jhim80u9qm1ofsw/27nfbrttho0ynu9/delayed_open_source_publication_2FzjpHTElG.pdf?token=">報告原文</a>。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:57:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280456/osi-delayed-open-source-publication-report</guid>
            <link>https://www.oschina.net/news/280456/osi-delayed-open-source-publication-report</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[終於，我們拿下了硅谷的那個 Linear]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-0963fd788787982101b5435a54ca146c2ab.png" alt="file" referrerpolicy="no-referrer"></p><p>就像設計領域的 Figma，文檔領域的 Notion，Linear 同樣在軟件開發管理領域推出了革命性的工具。而且以其名字 Linear Style 命名的設計風格，也成為了一股軟件設計潮流。</p><p><img src="https://oscimg.oschina.net/oscnet/up-19feb8c039e4eb58e00760e5e8abaeba7f9.png" alt="file" referrerpolicy="no-referrer"></p><p>Linear 於 2019 年在美國 🇺🇸 舊金山創立。目前服務的對象涵蓋了從新興初創到知名上市公司的廣泛範圍，其中包括 Vercel、Arc、Runway，Supercell 和 OpenSea 等知名企業。其產品因能顯著提升團隊生產力和協作效率而成為近幾年硅谷新興公司的首選。</p><p><img src="https://oscimg.oschina.net/oscnet/up-29fa5d140ca7408dad14b59ffc2cef3023a.png" alt="file" referrerpolicy="no-referrer"></p><p><strong>Linear 使用 Bytebase 管理其數據庫的全開發生命週期。收口員工查詢數據庫操作，通過 Bytebase API 將數據庫變更集成進現有 CI/CD 工作流。</strong></p><p>Linear 的員工統一在 SQL 編輯器查詢數據，通過權限管控、數據脫敏及行為審計，限制查詢範圍、監控行為並滿足合規需求。</p><p>通過 Bytebase API 將數據庫變更的審核部署集成進現有的代碼提交部署工作流中，觸發在 Bytebase 中建立工單，自動進行 SQL 預審核以減少人力降低錯誤可能性；根據變更的風險等級，通過自定義審批流確保相應的審批管理；並且，通過變更記錄的查詢功能，便於鎖定特定的變更，以利於後續的審計。此外，單點登錄 (SSO)，雙因子身份驗證 (2FA) 等功能進一步為賬戶管理帶來了便利性和安全性保障。</p><p>未來 Linear 還將利用 Bytebase 的批量變更能力管理部署在不同地域的同構數據庫。</p><p><img src="https://oscimg.oschina.net/oscnet/up-07cce1911ea9af359d0b945ffb3b6a4eca4.png" alt="file" referrerpolicy="no-referrer"></p><p>對開發者工具極其挑剔的 Linear 最終選擇了 Bytebase。正如我們在 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkzMjI2MDY5OQ%3D%3D%26mid%3D2247483664%26idx%3D1%26sn%3Dbd6be60909c156c2d54687ad90ba4825%26chksm%3Dc25f3f24f528b63261d5d86fb9ddcad8f36826bdaa16fdb43da555d5457313c5036aa1665b78%26scene%3D21%23wechat_redirect" target="_blank">2021 年發佈 Bytebase</a> 時設想的那樣，<strong>Bytebase 會站上世界最高的舞台，成為現代軟件研發工具鏈上的核心一環</strong>。</p><p><img src="https://oscimg.oschina.net/oscnet/up-551f266a1ef72674d8516e4795c1c18b9b4.png" alt="file" referrerpolicy="no-referrer"></p><hr><p>💡 更多資訊，請關注 Bytebase 公號：Bytebase</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:52:03 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/11044874</guid>
            <link>https://my.oschina.net/u/6148470/blog/11044874</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Ubuntu 工程師使用 Rust 為 Linux 開發內核調度程序]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>Ubuntu 內核團隊工程師 Andrea Righi 使用&nbsp;Rust 編寫了一個 Linux 內核調度程序，並利用 eBPF 在運行時動態加載。Ubuntu 還沒有承諾將其作為發行版的一部分，Righi 也在博客表示這是一個實驗性內核項目，用於探索 Rust 在 Ubuntu 的應用，並談到了未來<strong>利用 Rust 和 eBPF 進行「微內核設計」</strong>的可能性。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-c0d741c436f514bc20978b2df98eb1e23a1.png" referrerpolicy="no-referrer"></p><p>Righi 在博客介紹稱，用 Rust 開發的內核調度程序 sched-ext 不僅為開發者提供了便利，還能讓用戶也受益，比如可以根據用戶的工作負載和其他特殊情況加載優化的調度程序。</p><p>博客文章最後寫道：</p><blockquote><p>「我們正朝着一種微內核設計邁進，它有可能為 Linux 認證鋪平道路：在上述情況下，如果用戶空間調度程序崩潰，任務將無縫過渡到默認的內核調度程序，確保系統的持續可用性，而不會出現任何停機時間。</p><p>這表明，類似的方法也可用於其他子系統，從而使 Linux 內核能夠提供完全冗餘和崩潰安全的系統。」</p></blockquote><p>相關鏈接</p><ul><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsched-ext%2Fscx%2Fpull%2F161" target="_blank">https://github.com/sched-ext/scx/pull/161</a></li><li><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2F%2Fblog%2Fcrafting-new-linux-schedulers-with-sched-ext-rust-and-ubuntu" target="_blank">https://ubuntu.com//blog/crafting-new-linux-schedulers-with-sched-ext-rust-and-ubuntu</a></li></ul></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 03:25:03 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280450/ubuntu-rust-scheduler-micro</guid>
            <link>https://www.oschina.net/news/280450/ubuntu-rust-scheduler-micro</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Rebebuca —— 桌面端 ffmpeg 管理器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>Rebebuca（發音：瑞貝不卡） 是一個使用 Rust 開發的桌面端 ffmpeg 管理器，在不卡系列中處於推流端的生態位（Monibuca 為服務端，Jessibuca 為播放端）。</p></li><li><p>Rebebuca 在不久的將來會支持管理 Monibuca&nbsp;進程。</p></li><li><p><strong style="color:black"><span style="color:#010101">Rebebuca&nbsp;</span>可以在 30 秒內完成創建、運行、管理你的 ffmpeg 命令</strong></p><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div class="ckeditor-html5-video" style="text-align:center"><video controls="controls" src="https://rebebuca.com/quick.mp4">&nbsp;</video></div></div><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0">&nbsp;</div><div style="margin-left:0; margin-right:0">&nbsp;</div></div></div></div></div></div></div></div></div></div></li><li><p>幫助我們更好的管理繁多複雜的 ffmpeg 參數和 ffmpeg 命令運行狀態</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>功能特性</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>ffmpeg 命令全週期管理</p><ul style="list-style-type:circle; margin-left:0; margin-right:0"><li style="list-style-type:circle"><p>支持 ffmpeg 命令運行、停止、重啓等操作</p></li><li style="list-style-type:circle"><p>支持 ffmpeg 命令參數可視化配置、導入終端命令</p></li><li style="list-style-type:circle"><p>支持，按項目維度管理各種 ffmpeg 命令</p></li><li style="list-style-type:circle"><p>支持，數據導出</p></li></ul></li><li><p>列表+詳情交互模式</p></li><li><p>支持 ffmpeg 源切換、中英語言、深色淺色主題切換、窗口關閉方式選擇</p><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0">&nbsp;</div><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0"><div style="margin-left:0; margin-right:0; text-align:center"><div class="ckeditor-html5-video" style="text-align:center"><video controls="controls" src="https://rebebuca.com/quick.mp4">&nbsp;</video></div></div><div style="margin-left:0; margin-right:0">&nbsp;</div></div></div></div></div></div></div></div></div></div></li><li><p>支持軟件自動更新</p></li><li><p>支持 mac 和 window 平台</p></li><li><p>簡單好用、能力豐富、長期維護</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>下載安裝</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>Windows：https://download.m7s.live/rb/Rebebuca_0.1.0_x64_en-US.msi</p></li><li><p>Mac：https://download.m7s.live/rb/Rebebuca_0.1.0_x64.dmg</p></li><li><p>Mac(arm64) ：https://download.m7s.live/rb/Rebebuca_0.1.0_aarch64.dmg</p></li></ul><h2 style="margin-left:30px; margin-right:30px; text-align:center"><span>官方地址</span></h2><ul style="list-style-type:square; margin-left:0; margin-right:0"><li><p>官方網站：https://rebebuca.com</p></li><li><p>github：https://github.com/rebebuca/rebebuca</p></li></ul></div>
                                                                ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/p/rebebuca</guid>
            <link>https://www.oschina.net/p/rebebuca</link>
        </item>
        <item>
            <title>
                <![CDATA[華為發佈首個 5.5G 智能核心網：計劃 2024 年商用]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>在 MWC24 巴塞羅那期間，華為雲核心網產品線總裁高治國發布 5.5G 智能核心網解決方案。</p><p>據悉，2023 年新通話已在中國 31 省部署，可支撐 5000 萬用戶，同時在歐洲、拉美、中東、亞太等多個區域得到了廣泛驗證，計劃 2024 年商用。高治國表示：「華為發佈的業界首個新通話-A 通過智能能力和 DC（Data Channel）交互能力升級，正式邁入多模態通信時代。」</p><p><img height="333" src="https://oscimg.oschina.net/oscnet/up-b019072789c268abb1883dc58f6487ea5eb.png" width="500" referrerpolicy="no-referrer"></p><p>5.5G 也就是 5G-A，全稱為 5G-Advanced，是 5G 的技術演進，具備更大帶寬、更廣連接、確定性時延等能力。作為 5G-A 的重要技術之一，三載波聚合（3CC）是 5G-A 的基礎體驗網，5G-A 三載波聚合可以通過三載波組網方案，結合確定性體驗保障等技術，進一步提升網絡質量與體驗。</p><p>華為倡導的 5.5G 時代，是包含 5.5G、F5.5G、Net5.5G 等全面演進升級的端到端解決方案，會帶來 10 倍的網絡性能提升，可實現下行萬兆、上行千兆的峯值能力。同時在時延、定位、可靠性方面也有了 10 倍的提升，還能實現毫秒級時延和低成本千億物聯。</p><p>在 2023 MWC 上海展會上， 華為董事、ICT 產品與解決方案總裁楊超斌曾宣佈，華為 2024 年將會推出面向商用的 5.5G 全套網絡設備。</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:40:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280433</guid>
            <link>https://www.oschina.net/news/280433</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[Gitee 推薦 | Web 端彈幕庫 Fly Barrage]]>
            </title>
            <description>
                <![CDATA[<h1><a id="user-content--fly-barrage" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-fly-barrage"></a>✨ Fly Barrage</h1><p>Fully functional and powerful web-based barrage library</p><p>功能完善，強大的 web 端彈幕庫</p><h2><a id="user-content--rendering-effects" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-rendering-effects"></a>🎥 Rendering effects</h2><p><img src="https://gitee.com/fei_fei27/fly-barrage/raw/master/public/imgs/0001.png" alt="渲染效果" referrerpolicy="no-referrer"></p><h2><a id="user-content--official-website" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-official-website"></a>📝 Official Website</h2><p><a href="https://gitee.com/link?target=https%3A%2F%2Ffly-barrage.netlify.app%2F">https://fly-barrage.netlify.app/</a></p><h2><a id="user-content--install" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-install"></a>📥 Install</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line">npm <span class="nb">install </span>fly-barrage</span></pre><div class="markdown-code-block-copy-btn"></div></div></div><h2><a id="user-content--usage" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-usage"></a>🌍 Usage</h2><div class="white"><div class="highlight markdown-code-block"><pre><span id="LC1" class="line"><span class="c">&lt;!-- Taking Vue framework as an example, this library is not limited to specific frameworks. --&gt;</span></span><span id="LC2" class="line"><span class="nt">&lt;</span><span class="k">template</span><span class="nt">&gt;</span></span><span id="LC3" class="line"><span class="nt">&lt;div</span><span class="na">id=</span><span class="s">"container"</span><span class="nt">&gt;</span></span><span id="LC4" class="line"><span class="nt">&lt;video</span></span><span id="LC5" class="line"><span class="na">ref=</span><span class="s">"video"</span></span><span id="LC6" class="line"><span class="na">id=</span><span class="s">"video"</span></span><span id="LC7" class="line"><span class="na">controls</span></span><span id="LC8" class="line"><span class="na">autoplay</span></span><span id="LC9" class="line"><span class="na">src=</span><span class="s">"../src/assets/demo1.mp4"</span></span><span id="LC10" class="line"><span class="err">@</span><span class="na">play=</span><span class="s">"videoPlay"</span></span><span id="LC11" class="line"><span class="err">@</span><span class="na">pause=</span><span class="s">"videoPause"</span></span><span id="LC12" class="line"><span class="nt">&gt;&lt;/video&gt;</span></span><span id="LC13" class="line"><span class="nt">&lt;/div&gt;</span></span><span id="LC14" class="line"><span class="nt">&lt;/</span><span class="k">template</span><span class="nt">&gt;</span></span><span id="LC15" class="line"></span><span id="LC16" class="line"><span class="nt">&lt;</span><span class="k">script</span><span class="na">setup</span><span class="na">lang=</span><span class="s">"ts"</span><span class="nt">&gt;</span></span><span id="LC17" class="line"><span class="k">import</span><span class="nx">BarrageRenderer</span><span class="p">,</span><span class="p">{</span><span class="nx">BarrageOptions</span><span class="p">}</span><span class="k">from</span><span class="dl">'</span><span class="s1">fly-barrage</span><span class="dl">'</span><span class="p">;</span></span><span id="LC18" class="line"><span class="k">import</span><span class="p">{</span><span class="nx">onMounted</span><span class="p">,</span><span class="nx">ref</span><span class="p">}</span><span class="k">from</span><span class="dl">'</span><span class="s1">vue</span><span class="dl">'</span><span class="p">;</span></span><span id="LC19" class="line"></span><span id="LC20" class="line"><span class="kd">const</span><span class="nx">barrages</span><span class="p">:</span><span class="nx">BarrageOptions</span><span class="p">[]</span><span class="o">=</span><span class="p">[</span></span><span id="LC21" class="line"><span class="p">{</span></span><span id="LC22" class="line"><span class="dl">"</span><span class="s2">id</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">e55b45c9-7f9e-48c9-9bba-4d3b53441976</span><span class="dl">"</span><span class="p">,</span></span><span id="LC23" class="line"><span class="dl">"</span><span class="s2">barrageType</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">scroll</span><span class="dl">"</span><span class="p">,</span></span><span id="LC24" class="line"><span class="dl">"</span><span class="s2">time</span><span class="dl">"</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span></span><span id="LC25" class="line"><span class="dl">"</span><span class="s2">text</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">殘燈無焰影幢幢，此夕聞君謫九江。</span><span class="dl">"</span><span class="p">,</span></span><span id="LC26" class="line"><span class="dl">"</span><span class="s2">fontSize</span><span class="dl">"</span><span class="p">:</span><span class="mi">34</span><span class="p">,</span></span><span id="LC27" class="line"><span class="dl">"</span><span class="s2">lineHeight</span><span class="dl">"</span><span class="p">:</span><span class="mf">1.2</span><span class="p">,</span></span><span id="LC28" class="line"><span class="dl">"</span><span class="s2">color</span><span class="dl">"</span><span class="p">:</span><span class="dl">"</span><span class="s2">#FFFF00</span><span class="dl">"</span><span class="p">,</span></span><span id="LC29" class="line"><span class="p">},</span></span><span id="LC30" class="line"><span class="p">];</span></span><span id="LC31" class="line"></span><span id="LC32" class="line"><span class="kd">const</span><span class="nx">barrageRenderer</span><span class="o">=</span><span class="nx">ref</span><span class="o">&lt;</span><span class="nx">BarrageRenderer</span><span class="o">&gt;</span><span class="p">();</span></span><span id="LC33" class="line"><span class="kd">const</span><span class="nx">video</span><span class="o">=</span><span class="nx">ref</span><span class="p">();</span></span><span id="LC34" class="line"></span><span id="LC35" class="line"><span class="nx">onMounted</span><span class="p">(()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC36" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="o">=</span><span class="k">new</span><span class="nx">BarrageRenderer</span><span class="p">({</span></span><span id="LC37" class="line"><span class="na">container</span><span class="p">:</span><span class="dl">'</span><span class="s1">container</span><span class="dl">'</span><span class="p">,</span></span><span id="LC38" class="line"><span class="na">video</span><span class="p">:</span><span class="nx">video</span><span class="p">.</span><span class="nx">value</span><span class="p">,</span></span><span id="LC39" class="line"><span class="nx">barrages</span><span class="p">,</span></span><span id="LC40" class="line"><span class="p">});</span></span><span id="LC41" class="line"><span class="p">})</span></span><span id="LC42" class="line"></span><span id="LC43" class="line"><span class="kd">const</span><span class="nx">videoPlay</span><span class="o">=</span><span class="p">()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC44" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="p">?.</span><span class="nx">play</span><span class="p">();</span></span><span id="LC45" class="line"><span class="p">};</span></span><span id="LC46" class="line"></span><span id="LC47" class="line"><span class="kd">const</span><span class="nx">videoPause</span><span class="o">=</span><span class="p">()</span><span class="o">=&gt;</span><span class="p">{</span></span><span id="LC48" class="line"><span class="nx">barrageRenderer</span><span class="p">.</span><span class="nx">value</span><span class="p">?.</span><span class="nx">pause</span><span class="p">();</span></span><span id="LC49" class="line"><span class="p">};</span></span><span id="LC50" class="line"><span class="nt">&lt;/</span><span class="k">script</span><span class="nt">&gt;</span></span><span id="LC51" class="line"></span><span id="LC52" class="line"><span class="nt">&lt;</span><span class="k">style</span><span class="nt">&gt;</span></span><span id="LC53" class="line"><span class="o">*</span><span class="p">{</span></span><span id="LC54" class="line"><span class="nl">padding</span><span class="p">:</span><span class="m">0</span><span class="p">;</span></span><span id="LC55" class="line"><span class="nl">margin</span><span class="p">:</span><span class="m">0</span><span class="p">;</span></span><span id="LC56" class="line"><span class="p">}</span></span><span id="LC57" class="line"></span><span id="LC58" class="line"><span class="nf">#container</span><span class="p">{</span></span><span id="LC59" class="line"><span class="nl">width</span><span class="p">:</span><span class="m">1000px</span><span class="p">;</span></span><span id="LC60" class="line"><span class="nl">height</span><span class="p">:</span><span class="m">700px</span><span class="p">;</span></span><span id="LC61" class="line"><span class="nl">margin</span><span class="p">:</span><span class="m">20px</span><span class="nb">auto</span><span class="m">0</span><span class="p">;</span></span><span id="LC62" class="line"><span class="p">}</span></span><span id="LC63" class="line"></span><span id="LC64" class="line"><span class="nf">#video</span><span class="p">{</span></span><span id="LC65" class="line"><span class="nl">width</span><span class="p">:</span><span class="m">100%</span><span class="p">;</span></span><span id="LC66" class="line"><span class="nl">height</span><span class="p">:</span><span class="m">100%</span><span class="p">;</span></span><span id="LC67" class="line"><span class="nl">background</span><span class="p">:</span><span class="no">black</span><span class="p">;</span></span><span id="LC68" class="line"><span class="p">}</span></span><span id="LC69" class="line"><span class="nt">&lt;/</span><span class="k">style</span><span class="nt">&gt;</span></span></pre><div class="markdown-code-block-copy-btn"></div></div></div><p>For complete usage, please clone the project directly, install the dependencies, and then execute npm run dev to view the complete usage</p><p>Try to use a higher version of the node version, my local version is v18.19.0</p><h2><a id="user-content--license" class="anchor" href="https://gitee.com/fei_fei27/fly-barrage#-license"></a>🌲 License</h2><p><a href="https://gitee.com/fei_fei27/fly-barrage/blob/master/LICENSE">MIT License</a></p>]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:35:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/fei_fei27/fly-barrage</guid>
            <link>https://gitee.com/fei_fei27/fly-barrage</link>
        </item>
        <item>
            <title>
                <![CDATA[每日一博 | 得物自研 API 網關實踐之路]]>
            </title>
            <description>
                <![CDATA[<div class="content"><span id="OSC_h1_1"></span><h1>一、業務背景</h1><p style="color:#24292f; text-align:start">老網關使用 Spring Cloud Gateway （下稱 SCG）技術框架搭建，SCG 基於 webflux 編程範式，webflux 是一種響應式編程理念，響應式編程對於提升系統吞吐率和性能有很大幫助; webflux 的底層構建在 netty 之上性能表現優秀；SCG 屬於 spring 生態的產物，具備開箱即用的特點，以較低的使用成本助力得物早期的業務快速發展；但是隨着公司業務的快速發展，流量越來越大，網關迭代的業務邏輯越來越多，以及安全審計需求的不斷升級和穩定性需求的提高，SCG 在以下幾個方面逐步暴露了一系列的問題。</p><span id="OSC_h2_2"></span><h2>網絡安全</h2><p style="color:#24292f; text-align:start">從網絡安全角度來講，對公網暴露接口無疑是一件風險極高的事情，網關是對外網絡流量的重要橋樑，早期的接口暴露採用泛化路由的模式，即通過正則形式（ /api/v1/app/order/** ）的路由規則開放接口，單個應用服務往往只配置一個泛化路由，後續上線新接口時外部可以直接訪問；這帶來了極大的安全風險，很多時候業務開發的接口可能僅僅是內部調用，但是一不小心就被泛化路由開放到了公網，甚至很多時候沒人講得清楚某個服務具體有多少接口屬於對外，多少對內；另一方面從監控數據來看，黑產勢力也在不斷對我們的接口做滲透試探。</p><span id="OSC_h2_3"></span><h2>協同效率</h2><p style="color:#24292f; text-align:start">引入了接口註冊機制，所有對外暴露接口逐一註冊到網關，未註冊接口不可訪問，安全的問題得到了解決但同時帶來了性能問題，SCG 採用遍歷方式匹配路由規則，接口註冊模式推廣後路由接口註冊數量迅速提升到 3W+，路由匹配性能出現嚴重問題；泛化路由的時代，一個服務只有一個路由配置，變動頻率很低，配置工作由網關關開發人員負責，效率尚可，接口註冊模式將路由工作轉移到了業務開發同學的身上，這就得引入一套完整的路由審核流程，以提升協同效率；由於路由信息早期都存在配置中心，同時這麼大的數據量給配置中心也帶來極大的壓力和穩定性風險。</p><span id="OSC_h2_4"></span><h2>性能與維護成本</h2><p style="color:#24292f; text-align:start">業務迭代的不斷增多，也使得 API 網關堆積了很多的業務邏輯，這些業務邏輯分散在不同的 filter 中，為了降低開發成本，網關只有一套主線分支，不同集羣部署的代碼完全相同，但是不同集羣的業務屬性不同，所需要的 filter 邏輯是不一樣的；如內網網關集羣幾乎沒什麼業務邏輯，但是 App 集羣可能需要幾十個 filter 的邏輯協同工作；這樣的一套代碼對內網網關而言，存在着大量的性能浪費；如何平衡維護成本和運行效率是個需要思考的問題。</p><span id="OSC_h2_5"></span><h2>穩定性風險</h2><p style="color:#24292f; text-align:start">API 網關作為基礎服務，承載全站的流量出入，穩定性無疑是第一優先級，但其定位決定了絕不可能是一個簡單的代理層，在穩定運行的同時依然需要承接大量業務需求，例如 C 端用戶登錄下線能力，App 強升能力，B 端場景下的鑑權能力等；很難想象較長一段時間以來，網關都保持着雙週一次的發版頻率；頻繁的發版也帶來了一些問題，實例啓動初期有很多資源需要初始化，此時承接的流量處理時間較長，存在着明顯的接口超時現象；早期的每次發版幾乎都會導致下游服務的接口短時間內超時率大幅提高，而且往往涉及多個服務一起出現類似情況；為此甚至拉了一個網關發版公告羣，提前置頂發版公告，讓業務同學和 NOC 有一個心裏預期；在發佈升級期間儘可能讓業務服務無感知這是個剛需。</p><span id="OSC_h2_6"></span><h2>定製能力</h2><p style="color:#24292f; text-align:start">流量灰度是網關最常見的功能之一，對於新版本迭代，業務服務的某個節點發布新版本後希望引入少部分流量試跑觀察，但很遺憾 SCG 原生並不支持，需要對負載均衡算法進行手動改寫才可以，此外基於流量特徵的定向節點路由也需要手動開發，在 SCG 中整個負載均衡算法屬於比較核心的模塊，不對外直接暴露，存在較高的改造成本。</p><p style="color:#24292f; text-align:start">B 端業務和 C 端業務存在着很大的不同，例如對接口的響應時間的忍受度是不一樣的，B 端場景下下載一個報表用戶可以接受等待 10s 或者 1 分鐘，但是 C 端用戶現在沒有這個耐心。作為代理層針對以上的場景，我們需要針對不同接口定製不同的超時時間，原生的 SCG 顯然也不支持。</p><p style="color:#24292f; text-align:start">諸如此類的定製需求還有很多，我們並不寄希望於開源產品能夠開箱即用滿足全部需求，但至少定製性拓展性足夠好。上手改造成本低。</p><span id="OSC_h1_7"></span><h1>二、技術痛點</h1><p style="color:#24292f; text-align:start">SCG 主要使用了 webflux 技術，webflux 的底層構建在 reactor-netty 之上，而 reactor-netty 構建於 netty 之上；SCG 能夠和 spring cloud 的技術棧的各組件，完美適配，做到開箱即用，以較低的使用成本助力得物早期的業務快速發展；但是使用 webflux 也是需要付出一定成本，首先它會額外增加編碼人員的心智負擔，需要理解流的概念和常用的操作函數，諸如 map, flatmap, defer 等等；其次異步非阻塞的編碼形式，充斥着大量的回調函數，會導致順序性業務邏輯被割裂開來，增加代碼閲讀理理解成本；此外經過多方面評估我們發現 SCG 存在以下缺點：</p><span id="OSC_h2_8"></span><h2>內存泄露問題</h2><p style="color:#24292f">SCG 存在較多的內存泄漏問題，排查困難，且官方遲遲未能修復，長期運行會導致服務觸發 OOM 並宕機；以下為 github 上 SCG 官方開源倉庫的待解決的內存泄漏問題，大約有 16 個之多。</p><p style="color:#24292f; text-align:center"><img alt="80.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/80.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 內存泄漏 BUG</p><p style="color:#24292f">下圖可以看到 SCG 在長期運行的過程中內存使用一直在增長，<strong>當增長到機器內存上限時當前節點將不可用，聯繫到網關單節點所承接的 QPS 在幾千，可想而知節點宕機帶來的危害有多大</strong>；一段時間以來我們需要對 SCG 網關做定期重啓。</p><p style="color:#24292f; text-align:center"><img alt="078.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/078.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 生產實例內存增長趨勢</p><span id="OSC_h2_9"></span><h2>響應式編程範式複雜</h2><p style="color:#24292f">基於 webflux 中的 flux 和 mono ，在對 request 和 response 信息讀取修改時，編碼複雜度高，代碼理解困難，下圖是對 body 信息進行修改時的代碼邏輯。</p><p style="color:#24292f; text-align:center"><img alt="607.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/607.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">對 requestBody 進行修改的方式</p><span id="OSC_h2_10"></span><h2>多層抽象的性能損耗</h2><p style="color:#24292f; text-align:start">儘管相比於傳統的阻塞式網關，SCG 的性能已經足夠優秀，但相比原生的 netty 仍然比較低下，SCG 依賴於 webflux 編程範式，webflux 構建於 reactor-netty 之上，reactor-netty 構建於 netty 之上，多層抽象存在較大的性能損耗。<span>&nbsp;</span></p><p style="color:#24292f; text-align:start"><img alt="106.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/106.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 依賴層級</p><p style="color:#24292f">一般認為程序調用棧越深性能越差；下圖為只有一個 filter 的情況下的調用棧，可以看到存在大量的 webflux 中的 subscribe() 和 onNext() 方法調用,這些方法的執行不關聯任何業務邏輯，屬於純粹的框架運行層代碼，粗略估算下沒有引入任何邏輯的情況下 SCG 的調用棧深度在 90+ ，如果引入多個 filter 處理不同的業務邏輯，線程棧將進一步加深，<strong>當前網關的業務複雜度實際棧深度會達到 120 左右，也就是差不多有四分之三的非業務棧損耗，這個比例是有點誇張的。</strong></p><p style="color:#24292f; text-align:center"><img alt="205.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/205.png" referrerpolicy="no-referrer"><img alt="200.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/200.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG filter 調用棧深度</p><span id="OSC_h2_11"></span><h2>路由能力不完善</h2><p style="color:#24292f">原生的的 SCG 並不支持動態路由管理，路由的配置信息通過大量的 KV 配置來做，平均一個路由配置需要三到四條 KV 配置信息來支撐，這些配置數據一般放在諸如 Apollo 或者 ark 這樣的配置中心，即使是添加了新的配置 SCG 並不能動態識別，需要引入動態刷新路由配置的能力。另一方面路由匹配算法通過遍歷所有的路由信息逐一匹配的模式，當接口級別的路由數量急劇膨脹時，性能是個嚴重問題。</p><p style="color:#24292f; text-align:center"><img alt="017.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/017.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 路由匹配算法為 On 時間複雜度</p><span id="OSC_h2_12"></span><h2>預熱時間長，冷啓動 RT 尖刺大</h2><p style="color:#24292f">SCG 中 LoadBalancerClient 會調用 choose 方法來選擇合適的 endpoint 作為本次 RPC 發起調用的真實地址，由於是懶加載，只有在有真實流量觸發時才會加載創建相關資源；在觸發底層的 NamedContextFactory#getContext 方法時存在一個全局鎖導致，woker 線程在該鎖上大量等待。</p><p style="color:#24292f; text-align:center"><img alt="769.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/769.png" referrerpolicy="no-referrer">NamedContextFactory#getContext 方法存在全局鎖</p><p style="color:#24292f; text-align:center"><img alt="209.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/209.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">SCG 發佈時超時報錯增多</p><span id="OSC_h2_13"></span><h2>定製性差，數據流控制耦合</h2><p style="color:#24292f">SCG 在開發運維過程中已經出現了較多的針對源碼改造的場景，如動態路由，路由匹配性能優化等；其設計理念老舊，控制流和數據流混合使用，架構不清晰，如對路由管理操作仍然耦合在 filter 中，即使引入 spring mvc 方式管理，依然綁定使用 webflux 編程範式，同時也無法做到控制流端口獨立，存在一定安全風險。</p><p style="color:#24292f; text-align:center"><img alt="9007.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9007.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">filter 中對路由進行管理</p><span id="OSC_h1_14"></span><h1>三、方案調研</h1><span id="OSC_h2_15"></span><h2>理想中的網關</h2><p style="color:#24292f; text-align:start">綜合業務需求和技術痛點，我們發現<strong>理想型的網關</strong>應該是這個樣子的：</p><ul><li><p>支持海量接口註冊，並能夠在運行時支持動態添加修改路由信息，具備出色路由匹配性能</p></li><li><p>編程範式儘可能簡單，降低開發人員心智負擔，同時最好是開發人員較為熟悉的語言</p></li><li><p>性能足夠好，至少要等同於目前 SCG 的性能，RT99 線和 ART 較低</p></li><li><p>穩定性好，無內存泄漏，能夠長時間持續穩定運行，發佈升級期間要儘可能下游無感</p></li><li><p>拓展能力強，支持超時定製，多網絡協議支持，http，Dubbo 等，生態完善</p></li><li><p>架構設計清晰，數據流與控制流分離，集成 UI 控制面</p></li></ul><span id="OSC_h2_16"></span><h2>開源網關對比</h2><p style="color:#24292f; text-align:start">基於以上需求，我們對市面上的常見網關進行了調研，以下幾個開源方案對比。</p><p style="color:#24292f; text-align:start"><img alt="6078.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6078.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">結合當前團隊的技術棧，我們傾向於選擇 Java 技術棧的開源產品，唯一可選的只有 zuul2 ，但是 zuul2 路由註冊和穩定性方面也不能夠滿足我們的需求，也沒有實現數控分離的架構設計。因此唯有走上自研之路。</p><span id="OSC_h1_17"></span><h1>四、自研架構</h1><p style="color:#24292f; text-align:start">通常而言代理網關分為透明代理與非透明代理，其主要區別在於對於流量是否存在侵入性，這裏的侵入性主要是指對請求和響應數據的修改；顯然 API Gateway 的定位決定了必然會對流量進行數據調整，常見的調整主要有，添加或者修改 head 信息，加密或者解密 query params head ,以及 requestbody 或者 responseBody，可以説 http 請求的每一個部分數據都存在修改的可能性，這要求代理層必須要完全解析數據包信息，而非簡單的做一個路由器轉發功能。</p><p style="color:#24292f; text-align:start">傳統的服務器架構，以 reactor 架構為主。boss 線程和 worker 線程的明確分工，boss 線程負責連接建立創建；worker 線程負責已經建立的連接的讀寫事件監聽處理，同時會將部分複雜業務的處理放到獨立的線程池中，進而避免 worker 線程的執行時間過長影響對網絡事件處理的及時性；由於網關是 IO 密集型服務，相對來説計算內容較少，可以不必引入這樣的業務線程池；直接基於 netty 原生 reactor 架構實現。</p><span id="OSC_h2_18"></span><h2>Reactor 多線程架構</h2><p style="color:#24292f; text-align:start"><img alt="1009.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1009.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">為了只求極致性能和降低多線程編碼的數據競爭，單個請求從接收到轉發後端，再到接收後端服務響應，以及最終的回寫給 client 端，這一系列操作被設計為完全閉合在一個 workerEventLoop 線程中處理；這需要 worker 線程中執行的 IO 類型操作全部實現異步非阻塞化，確保 worker 線程的高速運轉；這樣的架構和 NGINX 很類似；我們稱之為 thread-per-core 模式。<img alt="1008.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1008.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_19"></span><h2>API 網關組件架構</h2><p style="color:#24292f; text-align:start"><img alt="7008.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/7008.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_20"></span><h2>數據流控制流分離</h2><p style="color:#24292f; text-align:start">數據面板專注於流量代理，不處理任何 admin 類請求，控制流監聽獨立的端口，接收管理指令。</p><p style="color:#24292f; text-align:start"><img alt="6009.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6009.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h1_21"></span><h1>五、核心設計</h1><span id="OSC_h2_22"></span><h2>請求上下文封裝</h2><p style="color:#24292f; text-align:start">新的 API 網關底層仍然基於 Netty，其自帶的 http 協議解析 handler 可以直接使用。基於 netty 框架的編程範式，需要在初始化時逐一註冊用到的 Handler。<span>&nbsp;</span></p><p style="color:#24292f; text-align:start"><img alt="10035.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/10035.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:center">Client 到 Proxy 鏈路 Handler 執行順序</p><p style="color:#24292f; text-align:start">HttpServerCodec 負責 HTTP 請求的解析；對於體積較大的 Http 請求，客戶端可能會拆成多個小的數據包進行發送，因此在服務端需要適當的封裝拼接，避免收到不完整的 http 請求；HttpObjectAggregator 負責整個請求的拼裝組合。</p><p style="color:#24292f; text-align:start">拿到 HTTP 請求的全部信息後在業務 handler 中進行處理；如果請求體積過大直接拋棄；使用 ServerWebExchange 對象封裝請求上下文信息，其中包含了 client2Proxy 的 channel, 以及負責處理該 channel 的 eventLoop 線程等信息，考慮到整個請求的處理過程中可能在不同階段傳遞一些拓展信息，引入了 getAttributes 方法，用於存儲需要傳遞的數據；此外 ServerWebExchange 接口的基本遵循了 SCG 的設計規範，保證了在遷移業務邏輯時的最小化改動；具體到實現類，可以參考如下代碼：</p><pre><code>@Getter
  public class DefaultServerWebExchange implements ServerWebExchange {
    private final Channel client2ProxyChannel;
    private final Channel proxy2ClientChannel;
    private final EventLoop executor;
    private ServerHttpRequest request;
    private ServerHttpResponse response;
    private final Map&lt;String, Object&gt; attributes;
 }
</code></pre><p style="text-align:center">DefaultServerWebExchange</p><p style="color:#24292f; text-align:start">Client2ProxyHttpHandler 作為核心的入口 handler 負責將接收到的 FullHttpRequest 進行封裝和構建 ServerWebExchange 對象，其核心邏輯如下。可以看到對於數據讀取封裝的邏輯較為簡單，並沒有植入常見的業務邏輯，封裝完對象後隨即調用 Request filter chain。</p><pre><code>@Override
protected void channelRead0(ChannelHandlerContext ctx, FullHttpRequest fullHttpRequest) {
    try {
        Channel client2ProxyChannel = ctx.channel();
        DefaultServerHttpRequest serverHttpRequest = new DefaultServerHttpRequest(fullHttpRequest, client2ProxyChannel);
        ServerWebExchange serverWebExchange = new DefaultServerWebExchange(client2ProxyChannel,(EventLoop) ctx.executor(), serverHttpRequest, null);
        // request filter chain
        this.requestFilterChain.filter(serverWebExchange);
    }catch (Throwable t){
        log.error("Exception caused before filters!\n {}",ExceptionUtils.getStackTrace(t));
        ByteBufHelper.safeRelease(fullHttpRequest);
        throw t;
    }
}
</code></pre><p style="text-align:center">Client2ProxyHttpHandler 精簡後的代碼</p><span id="OSC_h2_23"></span><h2>FilterChain 設計</h2><p style="color:#24292f; text-align:start">FilterChain 可以解決異步請求發送出去後，還沒收到響應，但是順序邏輯已經執行完成的尷尬；例如當我們在上文的。</p><p style="color:#24292f; text-align:start">channelRead0 方法中發起某個鑑權 RPC 調用時，出於性能考慮只能使用非阻塞的方式，按照 netty 的非阻塞編碼 API 最終要引入類似如下的 callback 機制，++在業務邏輯上在沒有收到 RPC 的響應之前該請求的處理應該「暫停」，等待收到響應時才能繼續後續的邏輯執行++; 也就是下面代碼中的下一步執行邏輯並不能執行，正確的做法是將 nextBiz() 方法包裹在 callBack() 方法內，由 callBack() 觸發後續邏輯的執行；這只是發起一次 RPC 調用的情況，在實際的的日常研發過程中存在着鑑權，風控，集羣限流（Redis）等多次 RPC 調用，這就導致這樣的非阻塞代碼編寫將異常複雜。</p><pre><code>ChannelFuture writeFuture = channel.writeAndFlush(asyncRequest.httpRequest);
    writeFuture.addListener(future -&gt; {
                if(future.isSuccess()) {
                   callBack();
                }
            }
    );
    nextBiz()；
</code></pre><p style="text-align:center">非阻塞調用下的業務邏輯編排</p><p style="color:#24292f; text-align:start">對於這樣的複雜場景，採用 filterChain 模式可以很好的解決；首先 RequestFilterChain().filter(serverWebExchange); 後不存在任何邏輯；發起請求時 ，當前 filter 執行結束，由於此時沒有調用 chain.filter(exchange); 所以不會繼續執行下一個 filter，發送請求到下游的邏輯也不會執行；當前請求的處理流程暫時中止，<strong>eventloop 線程將切換到其他請求的處理過程上；當收到 RPC 響應時，chain.filter(exchange) 被執行，之前中斷的流程被重新拉起。</strong></p><pre><code>public void filter(ServerWebExchange exchange) {
    if (this.index &lt; filters.size()) {
        GatewayFilter filter = filters.get(this.index);
        DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1);
        try {
            filter.filter(exchange, chain);
        }catch (Throwable e){
            log.error("Filter chain unhandle backward exception! Request path {}, FilterClass: {}, exception: {}", exchange.getRequest().getPath(),   filter.getClass(), ExceptionUtils.getFullStackTrace(e));
            ResponseDecorator.failResponse(exchange,500, "網關內部錯誤！filter chain exception！");
        }
    }
}
</code></pre><p style="text-align:center">基於 filterChain 的調用模式</p><p style="color:#24292f; text-align:start">對於 filter 的執行需要定義先後順序，這裏參考了 SCG 的方案，每個 filter 返回一個 order 值。不同的地方在於 DAG 的設計不允許 order 值重複，因為在 order 重複的情況下，很難界定到底哪個 Filter 先執行，存在模糊地帶，這不是我們期望看到的；DAG 中的 Filter 執行順序為 order 值從小到大，且不允許 order 值重複。為了易於理解，<strong>這裏將 Filter 拆分為了 requestFilter，和 responseFilter；分別代表請求的處理階段，和拿到下游響應階段，responseFilter 遵循同樣的邏輯執行順序與不可重複性。</strong></p><pre><code>public interface GatewayFilter extends Ordered {
    void filter(ServerWebExchange exchange, GatewayFilterChain chain);
}

public interface ResponseFilter extends GatewayFilter { }

public interface RequestFilter extends GatewayFilter { }
</code></pre><p style="text-align:center">filter 接口設計</p><span id="OSC_h2_24"></span><h2>路由管理與匹配</h2><p style="color:#24292f; text-align:start">以 SCG 網關註冊的路由數量為基準，網關節點的需要支撐的路由規則數量是上萬級別的，按照得物目前的業務量，上限不超過 5W，為了保證匹配性能，路由規則放在分佈式緩存中顯然是不合適的，需要保存在節點的內存中。類似於在 nginx 上配置上萬條 location 規則，手動維護難度可想而知，即使在配置中心管理起來也很麻煩，所以需要引入獨立路由管理模塊。<img alt="1090.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1090.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">在匹配的效率上也需要進一步優化，SCG 的路由匹配策略為普通的循環迭代逐一匹配，時間效率為 On，在路由規則膨脹到萬級別後，性能急劇拉胯，結合得物的接口規範，新網關採用 Hash 匹配模式，將匹配效率提升到 O1；hash 的 key 為接口的 path, 需要強調的是在同一個網關集羣中，path 是唯一的，這裏的 path 並不等價於業務服務的接口 path, 絕大多數時候存在一些剪裁，例如在業務服務的編寫的/order/detail 接口，在網關實際註冊的接口可能為/api/v1/app/order/detail；由於使用了 path 作為 key 進行 hash 匹配。常見的 restful 接口顯然是不支持的，確切的講基於 path 傳參數模式的接口均不支持；出於某些歷史原因，網關保留了類似 nginx 的前綴匹配的支持，但是這部分功能不對外開放。</p><pre><code>public class Route implements Ordered {
    private final String id;
    private final int skipCount;
    private final URI uri;
 }
</code></pre><p style="text-align:center">route 類設計</p><p style="color:#24292f; text-align:start">route 的 URI 字段中包含了，需要路由到的具體服務名，這裏也可以稱之為 host ，route 信息會暫存在 exchange 對象的 attributes 屬性中, 在後續的 loadbalance 階段 host 信息會被進一步替換為真實的 endpoint。</p><pre><code>private Route lookupRoute(ServerWebExchange exchange) {
    String path = exchange.getRequest().getPath();
    CachingRouteLocator locator = (CachingRouteLocator) routeLocator;
    Route exactRoute = pathRouteMap.getOrDefault(path, null);
    if (exactRoute != null) {
        exchange.getAttributes().put(DAGApplicationConfig.GATEWAY_ROUTE_CACHE, route);
        return exactRoute;
    }
}
</code></pre><p style="text-align:center">路由匹配邏輯</p><span id="OSC_h2_25"></span><h2>單線程閉環</h2><p style="color:#24292f; text-align:start">為了更好地利用 CPU，以及減少不必要的數據競爭，++將單個請求的處理全部閉合在一個線程當中++；這意味着這個請求的業務邏輯處理，RPC 調用，權限驗證，限流 token 獲取都將始終由某個固定線程處理。netty 中，網絡連接被抽象為 channel，channel 與 eventloop 線程的對應關係為 N 對 1，一個 channel 僅能被一個 eventloop 線程所處理，這在處理用戶請求時沒有問題，但是在接收請求完畢向下遊轉發請求時，我們碰到了一些挑戰，下游的連接往往是連接池在管理，連接池的管理是另一組 eventLoop 線程在負責，++為了保持閉環需要將連接池的線程設定為處理當前請求的線程++，並且只能是這一個線程；這樣一來，默認狀態下啓動的 N 個線程（N 與機器核心數相同），分別需要管理一個連接池；thread-per-core 模式的性能已經在 nginx 開源組件上得到驗證。<img alt="659.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/659.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_26"></span><h2>連接管理優化</h2><p style="color:#24292f; text-align:start">為了滿足單線程閉環，需要將連接池的管理線程設置為當前的 eventloop 線程，最終我們通過 threadlocal 進行線程與連接池的綁定；通常情況下 netty 自帶的連接池 FixedChannelPool 可以滿足我們大部分場景下的需求，這樣的連接池也是適用於多線程的場景；由於新網關使用 thread-per-core 模式並將請求處理的全生命週期閉合在單個線程中，所有為了線程安全的額外操作不再必要且存在性能浪費；為此需要對原生連接池做一些優化, 連接的獲取和釋放簡化為對鏈表結構的簡單 getFirst , addLast。</p><p style="color:#24292f; text-align:start">對於 RPC 而言，無論是 HTTP，還是 Dubbo，Redis 等最終底層都需要用到 TCP 連接，將構建在 TCP 連接上的數據解析協議與連接剝離後，我們發現這種純粹的連接管理是可以複用的，對於連接池而言不需要知道具體連接的用途，只需要維持到特定 endpoint 的連接穩定即可，那麼這裏的 RPC 服務的連接仍然可以放入連接池中進行託管；最終的連接池設計架構圖。<img alt="1300.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1300.jpeg" referrerpolicy="no-referrer"></p><span id="OSC_h2_27"></span><h2>AsyncClient 設計</h2><p style="color:#24292f; text-align:start">對於七層流量而言基本全部都是 Http 請求，同樣在 RPC 請求中 http 協議也佔了大多數，考慮到還會存在少量的 dubbo, Redis 等協議通信的場景。因此需要抽象出一套異步調用框架來支撐；這樣的框架需要具備超時管理，回調執行，錯誤輸出等功能，更重要的是具備協議無關性質， 為了更方便使用需要支持鏈式調用。</p><p style="color:#24292f; text-align:start">發起一次 RPC 調用通常可以分為以下幾步：</p><ol><li>獲取目標地址和使用的協議, 目標服務為集羣部署時，需要使用 loadbalance 模塊</li><li>封裝發送的請求，這樣的請求在應用層可以具體化為某個 Request 類，網絡層序列化為二進制數據流</li><li>出於性能考慮選擇非阻塞式發送，發送動作完成後開始計算超時</li><li>接收數據響應，由於採用非阻塞模式，這裏的發送線程並不會以 block 的方式等待數據</li><li>在超時時間內完成數據處理，或者觸發超時導致連接取消或者關閉<img alt="9006.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9006.jpeg" referrerpolicy="no-referrer"></li></ol><p style="color:#24292f">AsyncClient 模塊內容並不複雜，AsyncClient 為抽象類不區分使用的網絡協議；ConnectionPool 作為連接的管理者被 client 所引用，<strong>獲取連接的 key 使用 protocol+ip+port 再適合不過</strong>；通常在某個具體的連接初始化階段就已經確定了該 channel 所使用的協議，因此初始化時會直接綁定協議 Handler；當協議為 HTTP 請求時，HttpClientCodec 為 HTTP 請求的編解碼 handler；也可以是構建在 TCP 協議上的 Dubbo, Mysql ,Redis 等協議的 handler。</p><p style="color:#24292f; text-align:start">首先對於一個請求的不同執行階段需要引入狀態定位，這裏引入了 STATE 枚舉：</p><pre><code>enum STATE{
        INIT,SENDING,SEND,SEND_SUCCESS,FAILED,TIMEOUT,RECEIVED
}
</code></pre><p style="color:#24292f; text-align:start">其次在執行過程中設計了 AsyncContext 作為信息存儲的載體，內部包含 request 和 response 信息，作用類似於上文提到的 ServerWebExchange；channel 資源從連接池中獲取，使用完成後需要自動放回。</p><pre><code>public class AsyncContext&lt;Req, Resp&gt; implements Cloneable{
    STATE state = STATE.INIT;
    final Channel usedChannel;
    final ChannelPool usedChannelPool;
    final EventExecutor executor;
    final AsyncClient&lt;Req, Resp&gt; agent;
    
    Req request;
    Resp response;
    
    ResponseCallback&lt;Resp&gt; responseCallback;
    ExceptionCallback exceptionCallback;
    
    int timeout;
    long deadline;
    long sendTimestamp;

    Promise&lt;Resp&gt; responsePromise;
}
</code></pre><p style="text-align:center">AsyncContext</p><p style="color:#24292f; text-align:start">AsyncClient 封裝了基本的網絡通信能力，不拘泥於某個固定的協議，可以是 Redis, http，Dubbo 等。當將數據寫出去之後，該 channel 的非阻塞調用立即結束，在沒有收到響應之前無法對 AsyncContext 封裝的數據做進一步處理，如何在收到數據時將接收到的響應和之前的請求管理起來這是需要面對的問題，channel 對象，的 attr 方法可以用於臨時綁定一些信息，以便於上下文切換時傳遞數據，可以在發送數據時將 AsyncContext 對象綁定到該 channel 的某個固定 key 上。當 channel 收到響應信息時，在相關的 AsyncClientHandler 裏面取出 AsyncContext。</p><pre><code>public abstract class AsyncClient&lt;Req, Resp&gt; implements Client {
    private static final int defaultTimeout = 5000;
    private final boolean doTryAgain = false;
    private final ChannelPoolManager channelPoolManager = ChannelPoolManager.getChannelPoolManager();
    protected static AttributeKey&lt;AsyncRequest&gt; ASYNC_REQUEST_KEY = AttributeKey.valueOf("ASYNC_REQUEST");

    public abstract ApplicationProtocol getProtocol();
    
    public AsyncContext&lt;Req, Resp&gt; newRequest(EventExecutor executor, String endpoint, Req request) {
        final ChannelPoolKey poolKey = genPoolKey(endpoint);
        ChannelPool usedChannelPool = channelPoolManager.acquireChannelPool(executor, poolKey);
        return new AsyncContext&lt;&gt;(this,executor,usedChannelPool,request, defaultTimeout, executor.newPromise());
    }

    public void submitSend(AsyncContext&lt;Req, Resp&gt; asyncContext){
        asyncContext.state = AsyncContext.STATE.SENDING;
        asyncContext.deadline = asyncContext.timeout + System.currentTimeMillis();   
        ReferenceCountUtil.retain(asyncContext.request);
        Future&lt;Resp&gt; responseFuture = trySend(asyncContext);
        responseFuture.addListener((GenericFutureListener&lt;Future&lt;Resp&gt;&gt;) future -&gt; {
            if(future.isSuccess()){
                ReferenceCountUtil.release(asyncContext.request);
                Resp response = future.getNow();
                asyncContext.responseCallback.callback(response);
            }
        });
    }
    /**
     * 嘗試從連接池中獲取連接併發送請求，若失敗返回錯誤
     */
    private Promise&lt;Resp&gt; trySend(AsyncContext&lt;Req, Resp&gt; asyncContext){
        Future&lt;Channel&gt; acquireFuture = asyncContext.usedChannelPool.acquire();
        asyncContext.responsePromise = asyncContext.executor.newPromise();
        acquireFuture.addListener(new GenericFutureListener&lt;Future&lt;Channel&gt;&gt;() {
                @Override
                public void operationComplete(Future&lt;Channel&gt; channelFuture) throws Exception {
                    sendNow(asyncContext,channelFuture);
                }
        });
        return asyncContext.responsePromise;
    }

    private void sendNow(AsyncContext&lt;Req, Resp&gt; asyncContext, Future&lt;Channel&gt; acquireFuture){
        boolean released = false;
        try {
            if (acquireFuture.isSuccess()) {
                NioSocketChannel channel = (NioSocketChannel) acquireFuture.getNow();
                released = true;
                assert channel.attr(ASYNC_REQUEST_KEY).get() == null;
                asyncContext.usedChannel = channel;
                asyncContext.state = AsyncContext.STATE.SEND;
                asyncContext.sendTimestamp = System.currentTimeMillis();
                channel.attr(ASYNC_REQUEST_KEY).set(asyncContext);
                ChannelFuture writeFuture = channel.writeAndFlush(asyncContext.request);
                channel.eventLoop().schedule(()-&gt; doTimeout(asyncContext), asyncContext.timeout, TimeUnit.MILLISECONDS);
            } else {
                asyncContext.responsePromise.setFailure(acquireFuture.cause());
            }
        } catch (Exception e){
            throw new Error("Unexpected Exception.............!");
        }finally {
            if(!released) {
                ReferenceCountUtil.safeRelease(asyncContext.request);
            }
        }
    }
}
</code></pre><p style="text-align:center">AsyncClient 核心源碼</p><pre><code>public class AsyncClientHandler extends SimpleChannelInboundHandler {
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception {
        AsyncContext asyncContext = ctx.attr(AsyncClient.ASYNC_REQUEST_KEY).get();
        try {
            asyncContext.state = AsyncContext.STATE.RECEIVED;
            asyncContext.releaseChannel();
            asyncContext.responsePromise.setSuccess(msg);
        }catch (Throwable t){
            log.error("Exception raised when set Success callback. Exception \n: {}", ExceptionUtils.getFullStackTrace(t));
            ByteBufHelper.safeRelease(msg);
            throw t;
        }
    }
}
</code></pre><p style="text-align:center">AsyncClientHandler</p><p style="color:#24292f; text-align:start">通過上面幾個類的封裝得到了一個易用使用的 AsyncClient，下面的代碼為調用權限系統的案例：</p><pre><code>final FullHttpRequest httpRequest = HttpRequestUtil.getDefaultFullHttpRequest(newAuthReq, serviceInstance, "/auth/newCheckSls");
asyncClient.newRequest(exchange.getExecutor(), endPoint,httpRequest)
        .timeout(timeout)
        .onComplete(response -&gt; {
            String checkResultJson = response.content().toString(CharsetUtil.UTF_8);
            response.release();
            NewAuthResult result = Jsons.parse(checkResultJson,NewAuthResult.class);
            TokenResult tokenResult = this.buildTokenResult(result);
            String body = exchange.getAttribute(DAGApplicationConfig.REQUEST_BODY);

            if (tokenResult.getUserInfoResp() != null) {
                UserInfoResp userInfo = tokenResult.getUserInfoResp();
                headers.set("userid", userInfo.getUserid() == null ? "" : String.valueOf(userInfo.getUserid()));
                headers.set("username", StringUtils.isEmpty(userInfo.getUsername()) ? "" : userInfo.getUsername());
                headers.set("name", StringUtils.isEmpty(userInfo.getName()) ? "" : userInfo.getName());
                chain.filter(exchange);
            } else {
                log.error("{},heads: {},response: {}", path, headers, tokenResult);
                int code = tokenResult.getCode() != null ? tokenResult.getCode().intValue() : ResultCode.UNAUTHO.code;
                ResponseDecorator.failResponse(exchange, code, tokenResult.getMsg());
            }
        })
        .onError(throwable -&gt; {
            log.error("Request service {},occur an exception {}",endPoint, throwable);
            ResponseDecorator.failResponseWithStatus(exchange,HttpResponseStatus.INTERNAL_SERVER_ERROR,"AuthFilter 驗證失敗");
        })
        .sendRequest();
</code></pre><p style="text-align:center">asyncClient 的使用</p><span id="OSC_h2_28"></span><h2>請求超時管理</h2><p style="color:#24292f; text-align:start">一個請求的處理時間不能無限期拉長， 超過某個閾值的情況下 App 的頁面會被取消 ，長時間的加載卡頓不如快速報錯帶來的體驗良好；顯然網關需要針對接口做超時處理，尤其是在向後端服務發起請求的過程，通常我們會設置一個默認值，例如 3 秒鐘，超過這個時間網關會向請求端回寫 timeout 的失敗信息，由於網關下游接入的服務五花八門，可能是 RT 敏感型的 C 端業務，也可能是邏輯較重 B 端服務接口，甚至是存在大量計算的監控大盤接口。這就導致不同接口對超時時間的訴求不一樣，因此針對每個接口的超時時間設定應該被獨立出來，而不是統一配置成一個值。</p><pre><code>asyncClient.newRequest(exchange.getExecutor(), endPoint,httpRequest)
        .timeout(timeout)
        .onComplete(response -&gt; {
            String checkResultJson = response.content().toString(CharsetUtil.UTF_8);
            //..........
        })
        .onError(throwable -&gt; {
            log.error("Request service {},occur an exception {}",endPoint, throwable);
            ResponseDecorator.failResponseWithStatus(exchange,HttpResponseStatus.INTERNAL_SERVER_ERROR,"AuthFilter 驗證失敗");
        })
        .sendRequest();
</code></pre><p style="color:#24292f; text-align:start">asyncClient 的鏈式調用設計了 timeout 方法，用於傳遞超時時間，我們可以通過一個全局 Map 來配置這樣的信息。</p><p style="color:#24292f; text-align:start">Map&lt;String,Integer&gt; 其 key 為全路徑的 path 信息，V 為設定的超時時間，單位為 ms, 至於 Map 的信息在實際配置過程中如何承載，使用 ARK 配置或者 Mysql 都很容易實現。處於併發安全和性能的極致追求，超時事件的設定和調度最好能夠在與當前 channel 綁定的線程中執行，慶幸的是 EventLoop 線程自帶 schedule 方法。具體來看上文的 AsyncClient 的 56 行。schedule 方法內部以堆結構的方式實現了對超時時間進行管理，整體性能尚可。</p><span id="OSC_h2_29"></span><h2>堆外內存管理優化</h2><p style="color:#24292f; text-align:start">常見的堆外內存手動管理方式無非是引用計數，不同處理邏輯可能針對 RC (引用計數) 的值做調整，到某個環節的業務邏輯處理後已經不記得當前的引用計數值是多少了，甚至是前面的 RC 增加了，後面的 RC 忘記減少了；但換個思路，在數據回寫給客戶端後我們肯定要把這個請求整個生命週期所申請的堆外內存全部釋放掉，堆外內存在回收的時候條件只有一個，就是 RC 值為 0 ，那麼在最終的 release 的時候，我們引入一個 safeRelase 的思路 , 如果當前的 RC&gt;0 就不停的 release ，直至為 0；因此只要把這樣的邏輯放在 netty 的最後一個 Handler 中即可保證內存得到有效釋放。</p><pre><code>public static void safeRelease(Object msg){
    if(msg instanceof ReferenceCounted){
        ReferenceCounted ref = (ReferenceCounted) msg;
        int refCount = ref.refCnt();
        for(int i=0; i&lt;refCount; i++){
            ref.release();
        }
    }
}
</code></pre><p style="text-align:center">safeRelease</p><span id="OSC_h2_30"></span><h2>響應時間尖刺優化</h2><p style="color:#24292f; text-align:start">由於 DAG 選擇了複用 spring 的 loadbalance 模塊，但這樣一來就會和 SCG 一樣存在啓動初期的響應時間尖刺問題；為此我們進一步分析 RibbonLoadBalancerClient 的構建過程，發現其用到了 NamedContextFactory，該類的 contexts 變量保存了每一個 serviceName 對應的一個獨立 context，這種使用模式帶來大量的性能浪費。</p><pre><code>public abstract class NamedContextFactory&lt;C extends NamedContextFactory.Specification&gt;implements DisposableBean, ApplicationContextAware {
    //1. contexts 保存 key -&gt; ApplicationContext 的 map
    private Map&lt;String, AnnotationConfigApplicationContext&gt; contexts = new ConcurrentHashMap&lt;&gt;();
    //........
}
</code></pre><p style="color:#24292f; text-align:start">在實際運行中 RibbonLoadBalancerClient 會調用 choose 方法來選擇合適的 endpoint 作為本次 RPC 發起調用的真實地址；choose 方法執行過程中會觸發 getLoadBalancer() 方法執行，可以看到該方法的可以按照傳入的 serviceId 獲取專屬於這個服務的 LoadBalancer，事實上這樣的設計有點多此一舉。大部分情況下，每個服務的負載均衡算法都一致的，完全可以複用一個 LoadBalancer 對象；該方法最終是從 spring 容器中獲取 LoadBalancer。</p><pre><code>class  RibbonLoadBalancerClient{
    //..........
    private SpringClientFactory clientFactory;
    
    @Override
    public ServiceInstance choose(String serviceId) {
       return choose(serviceId, null);
    }
    
    public ServiceInstance choose(String serviceId, Object hint) {
       Server server = getServer(getLoadBalancer(serviceId), hint);
       if (server == null) {
          return null;
       }
       return new RibbonServer(serviceId, server, isSecure(server, serviceId),
             serverIntrospector(serviceId).getMetadata(server));
    }
    
    protected ILoadBalancer getLoadBalancer(String serviceId) {
       return this.clientFactory.getLoadBalancer(serviceId);
    }
    //.........
}
</code></pre><p style="text-align:center">RibbonLoadBalancerClient</p><p style="color:#24292f; text-align:start"><strong>由於是懶加載，實際流量觸發下才會執行，因此第一次執行時，RibbonLoadBalancerClient 對象並不存在，需要初始化創建，創建時大量線程併發調用 SpringClientFactory#getContext 方法，鎖在同一個對象上，出現大量的 RT 尖刺。這也解釋了為什麼 SCG 網關在發佈期間會出現響應時間大幅度抖動的現象。</strong></p><pre><code>public class SpringClientFactory extends NamedContextFactory&lt;RibbonClientSpecification&gt;{
    //............    
    protected AnnotationConfigApplicationContext getContext(String name) {
       if (!this.contexts.containsKey(name)) {
          synchronized (this.contexts) {
             if (!this.contexts.containsKey(name)) {
                this.contexts.put(name, createContext(name));
             }
          }
       }
       return this.contexts.get(name);
    }
    //.........
}
</code></pre><p style="text-align:center">SpringClientFactory</p><p style="color:#24292f; text-align:start">在後期的壓測過程中，發現 DAG 的線程數量遠超預期，基於 thread-per-core 的架構模式下，過多的線程對性能損害比較大，尤其是當負載上升到較高水位時。上文提到<strong>默認情況下，每個服務都會創建獨立 loadBalanceClient , 而在其內部又會啓動獨立的線程去同步當前關聯的 serviceName 對應的可用 serverList</strong>,網關的特殊性導致需要接入的服務數量極為龐大，進而導致運行一段時間後 DAG 的線程數量急劇膨脹，對於同步 serverList 這樣的動作而言，完全可以採用非阻塞的方式從註冊中心拉取相關的 serverList , 這種模式下單線程足以滿足性能要求。</p><p style="color:#24292f; text-align:start"><img alt="1078.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1078.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">serverList 的更新前後架構對比</p><p style="color:#24292f; text-align:start">通過預先初始化的方式以及全局只使用 1 個 context 的方式，可以將這裏冷啓動尖刺消除，改造後的測試結果符合預期。<img alt="6034.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/6034.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">通過進一步修改優化 spring loadbalance serverList 同步機制，降低 90% 線程數量的使用。</p><p style="color:#24292f; text-align:start"><img alt="879.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/879.png" referrerpolicy="no-referrer"></p><p style="text-align:center">優化前線程數量（725）</p><p style="color:#24292f; text-align:start"><img alt="779.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/779.png" referrerpolicy="no-referrer"></p><p style="text-align:center">優化後線程數量（72）</p><span id="OSC_h2_31"></span><h2>集羣限流改造優化</h2><p style="color:#24292f; text-align:start">首先來看 DAG 啓動後 sentinel 相關線程，類似的問題，線程數量非常多，需要針對性優化。<img alt="234.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/234.png" referrerpolicy="no-referrer"></p><p style="text-align:center">Sentinel 線程數</p><p style="color:#24292f; text-align:start">sentinel 線程分析優化：</p><p style="color:#24292f; text-align:start"><img alt="120.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/120.jpeg" referrerpolicy="no-referrer"><img alt="220.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/220.png" referrerpolicy="no-referrer"></p><p style="text-align:center">最終優化後的線程數量為 4 個</p><p style="color:#24292f; text-align:start">sentinel 原生限流源碼分析如下，進一步分析 SphU#entry 方法發現其底調用 FlowRuleCheck#passClusterCheck；<strong>在 passClusterCheck 方法中發現底層網絡 IO 調用為阻塞式</strong>，由於該方法的執行線程為 workerEventLoop，因此需要使用上文提到的 AsyncClient 進行優化。</p><pre><code>private void doSentinelFlowControl(ServerWebExchange exchange, GatewayFilterChain chain, String resource){
    Entry urlEntry = null;
    try {
        if (!StringUtil.isEmpty(resource)) {
            //1. 檢測是否限流
            urlEntry = SphU.entry(resource, ResourceTypeConstants.COMMON_WEB, EntryType.IN);
        }
       //2. 通過，走業務邏輯
        chain.filter(exchange);
    } catch (BlockException e) {
        //3. 攔截，直接返回 503
        ResponseDecorator.failResponseWithStatus(exchange, HttpResponseStatus.SERVICE_UNAVAILABLE, ResultCode.SERVICE_UNAVAILABLE.message);
    } catch (RuntimeException e2) {
        Tracer.traceEntry(e2, urlEntry);
        log.error(ExceptionUtils.getFullStackTrace(e2));
        ResponseDecorator.failResponseWithStatus(exchange, HttpResponseStatus.INTERNAL_SERVER_ERROR,HttpResponseStatus.INTERNAL_SERVER_ERROR.reasonPhrase());
    } finally {
        if (urlEntry != null) {
            urlEntry.exit();
        }
        ContextUtil.exit();
    }
}
</code></pre><p style="text-align:center">SentinelGatewayFilter（sentinel 適配 SCG 的邏輯）</p><pre><code>public class RedisTokenService implements InitializingBean {
    private final RedisAsyncClient client = new RedisAsyncClient();
    private final RedisChannelPoolKey connectionKey;
    
    public RedisTokenService(String host, int port, String password, int database, boolean ssl){
        connectionKey = new RedisChannelPoolKey(String host, int port, String password, int database, boolean ssl);
    }
    //請求 token
    public Future&lt;TokenResult&gt; asyncRequestToken(ClusterFlowRule rule){
        ....
        sendMessage(redisReqMsg,this.connectionKey)
    }
    
    private Future&lt;TokenResult&gt; sendMessage(RedisMessage requestMessage, EventExecutor executor, RedisChannelPoolKey poolKey){
        AsyncRequest&lt;RedisMessage,RedisMessage&gt; request = client.newRequest(executor, poolKey,requestMessage);
        DefaultPromise&lt;TokenResult&gt; tokenResultFuture = new DefaultPromise&lt;&gt;(request.getExecutor());

        request.timeout(timeout)
                .onComplete(response -&gt; {
                    ...
                    tokenResultFuture.setSuccess(response);
                })
                .onError(throwable -&gt; {
                    ...
                    tokenResultFuture.setFailure(throwable);
                }).sendRequest();

        return tokenResultFuture;
    }
}
</code></pre><p style="text-align:center">RedisTokenService</p><p style="color:#24292f; text-align:start">最終的限流 Filter 代碼如下：</p><pre><code>public class SentinelGatewayFilter implements RequestFilter {
    @Resource
    RedisTokenService tokenService;\
    
    @Override
    public void filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //當前為 netty NioEventloop 線程
        ServerHttpRequest request = exchange.getRequest();
        String resource = request.getPath() != null ? request.getPath() : "";
  
        //判斷是否有集羣限流規則
        ClusterFlowRule rule = ClusterFlowManager.getClusterFlowRule(resource);
        if (rule != null) {
           //異步非阻塞請求 token
            tokenService.asyncRequestToken(rule,exchange.getExecutor())
                    .addListener(future -&gt; {
                        TokenResult tokenResult;
                        if (future.isSuccess()) {
                            tokenResult = (TokenResult) future.getNow();
                        } else {
                            tokenResult = RedisTokenService.FAIL;
                        }
                        if(tokenResult == RedisTokenService.FAIL || tokenResult == RedisTokenService.ERROR){
                            log.error("Request cluster token failed, will back to local flowRule check");
                        }
                        ClusterFlowManager.setTokenResult(rule.getRuleId(), tokenResult);
                        doSentinelFlowControl(exchange, chain, resource);
                    });
        } else {
            doSentinelFlowControl(exchange, chain, resource);
        }
    }
}
</code></pre><p style="text-align:center">改造後適配 DAG 的 SentinelGatewayFilter</p><span id="OSC_h1_32"></span><h1>六、壓測性能</h1><span id="OSC_h2_33"></span><h2>DAG 高壓表現</h2><p style="color:#24292f; text-align:start">wrk -t32 -c1000 -d60s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">DAG 網關的 QPS、實時 RT、錯誤率、CPU、內存監控圖；<strong>在 CPU 佔用 80% 情況下，能夠支撐的 QPS 在 4.5W。</strong><img alt="657.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/657.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 網關的 QPS、RT 折線圖</p><p style="color:#24292f; text-align:start"><img alt="645.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/645.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>DAG 在 CPU 佔用 80% 情況下，能夠支撐的 QPS 在 4.5W，ART 19ms</strong></p><span id="OSC_h2_34"></span><h2>SCG 高壓表現</h2><p style="color:#24292f; text-align:start">wrk -t32 -c1000 -d60s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">SCG 網關的 QPS、實時 RT、錯誤率、CPU、內存監控圖：<img alt="3410.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/3410.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start">SCG 網關的 QPS、RT 折線圖：<img alt="1670.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1670.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>SCG 在 CPU 佔用 95% 情況下，能夠支撐的 QPS 在 1.1W，ART 54.1ms</strong></p><span id="OSC_h2_35"></span><h2>DAG 低壓表現</h2><p style="color:#24292f; text-align:start">wrk -t5 -c20 -d120s -s param-delay1ms.lua --latency http://a.b.c.d:xxxxx</p><p style="color:#24292f; text-align:start">DAG 網關的 QPS、實時 RT、錯誤率、CPU、內存：<img alt="1354.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1354.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 網關的 QPS、RT 折線圖：</p><p style="color:#24292f; text-align:start"><img alt="1·.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1%C2%B7.png" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>DAG 在 QPS 1.1W 情況下，CPU 佔用 30%，ART 1.56ms</strong></p><span id="OSC_h2_36"></span><h2>數據對比</h2><p style="color:#24292f; text-align:start"><img alt="00.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/-00.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>結論</strong></p><p style="color:#24292f; text-align:start">滿負載情況下，DAG 要比 SCG 的吞吐量高很多，QPS 幾乎是 4 倍，RT 反而消耗更低，SCG 在 CPU 被打滿後，RT 表現出現嚴重性能劣化。DAG 的吞吐控制和 SCG 一樣情況下，CPU 和 RT 損耗下降了更多。DAG 在最大壓力下，內存消耗比較高，達到了 75% 左右，不過到峯值後，就不再會有大幅變動了。對比壓測結果，結論令人欣喜，<strong>SCG 作為 Java 生態當前使用最廣泛的網關，其性能屬於一線水準，DAG 的性能達到其 4 倍以上也是遠超意料，這樣的結果給與研發同學極大的鼓舞。</strong></p><span id="OSC_h1_37"></span><h1>七、投產收益</h1><span id="OSC_h2_38"></span><h2>安全性提升</h2><p style="color:#24292f; text-align:start"><strong>完善的接口級路由管理</strong></p><p style="color:#24292f; text-align:start">基於接口註冊模式的全新路由上線，包含了接口註冊的申請人，申請時間，接口場景備註信息等，接口管理更加嚴謹規範；結合路由組功能可以方便的查詢當前服務的所有對外接口信息，某種程度上具備一定的 API 查詢管理能力；同時為了緩解用戶需要檢索的接口太多的尷尬，引入了一鍵收藏功能，大部分時候用戶只需要切換到已關注列表即可。</p><p style="color:#24292f; text-align:start"><img alt="·01.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/%C2%B701.png" referrerpolicy="no-referrer"></p><p style="text-align:center">註冊接口列表</p><p style="color:#24292f; text-align:start"><img alt="=0.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/=0.png" referrerpolicy="no-referrer"></p><p style="text-align:center">接口收藏</p><p style="color:#24292f; text-align:start"><strong>防滲透能力極大增強</strong></p><p style="color:#24292f; text-align:start">早期的泛化路由，給黑產的滲透帶來了極大的想象空間和安全隱患，甚至可以在外網直接訪問某些業務的配置信息。<img alt="701.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/701.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">黑產接口滲透</p><p style="color:#24292f; text-align:start">接口註冊模式啓用後，所有未註冊的接口均無法訪問，防滲透能力提升一個台階，同時自動推送異常接口訪問信息。</p><p style="color:#24292f; text-align:start"><img alt="81.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/8-1.png" referrerpolicy="no-referrer"></p><p style="text-align:center">404 接口訪問異常推送</p><span id="OSC_h2_39"></span><h2>穩定性增強</h2><p style="color:#24292f; text-align:start"><strong>內存泄漏問題解決</strong></p><p style="color:#24292f; text-align:start">通過一系列手段改進優化和嚴格的測試，新網關的內存使用更加穩健，內存增長曲線直接拉平，徹底解決了泄漏問題。</p><p style="color:#24292f; text-align:start"><img alt="2300.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/2300.png" referrerpolicy="no-referrer"></p><p style="text-align:center">老網關內存增長趨勢</p><p style="color:#24292f; text-align:start"><img alt="789=.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/789=.png" referrerpolicy="no-referrer"></p><p style="text-align:center">新網關內存增長趨勢</p><p style="color:#24292f; text-align:start"><strong>響應時間尖刺消除</strong></p><p style="color:#24292f; text-align:start">通過預先初始化 &amp; context 共用等手段，去除了運行時併發創建多個 context 搶佔全局鎖的開銷，冷啓動 RT 尖刺降低 99% ；關於 spring load balance 模塊的更多優化細節可以參考這篇博客：Spring LoadBalance 存在問題與優化。</p><p style="color:#24292f; text-align:start"><strong>壓測數據對比</strong><img alt="1=.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/1-=.jpeg" referrerpolicy="no-referrer"></p><p style="color:#24292f; text-align:start"><strong>實際生產監控</strong></p><p style="color:#24292f; text-align:start">趨勢圖上略有差異，但是從非 200 請求的絕對值上看，這種差異可以忽略, <strong>對比發佈期間和非發佈期間異常請求的數量，發現基本沒有區別，這代表着以往的發佈期間的響應時間尖刺基本消除，做到了發佈期間業務服務徹底無感知。</strong></p><p style="color:#24292f; text-align:start"><img alt="01.jpeg" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-1.jpeg" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 4 日發佈期間各節點流量變化</p><p style="color:#24292f; text-align:start"><img alt="02.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-2.png" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 4 日異常請求狀態數量監控 (發佈期間)</p><p style="color:#24292f; text-align:start"><img alt="03.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-3.png" referrerpolicy="no-referrer"></p><p style="text-align:center">1 月 5 日異常請求狀態數量監控（無發佈）</p><span id="OSC_h2_40"></span><h2>降本增效</h2><p style="color:#24292f; text-align:start"><strong>資源佔用下降 50% +</strong></p><p style="color:#24292f; text-align:start"><img alt="04.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-4.png" referrerpolicy="no-referrer"></p><p style="text-align:center">SCG 平均 CPU 佔用</p><p style="color:#24292f; text-align:start"><img alt="05.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-5.png" referrerpolicy="no-referrer"></p><p style="text-align:center">DAG 資源佔用</p><p style="color:#24292f; text-align:start"><strong>JDK17 升級收益</strong></p><p style="color:#24292f">得益於 ZGC 的優秀算法，JVM17 在 GC 暫停時間上取得了出色的成果，網關作為延遲敏感型應用對 GC 的暫停時間尤為看重，為此我們組織升級了 JDK17 版本；下面為同等流量壓力情況下的配置不同 GC 的效果對比，<strong>可以看到 GC 的暫停時間從平均 70ms 降低到 1ms 內，RT99 線得到大幅度提升；吞吐量不再受流量波動而大幅度變化，性能表現更加穩定；同時網關的平均響應時間損耗降低 5%。</strong></p><p style="color:#24292f"><img alt="08.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/0-8.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK8-G1 暫停時間表現</p><p style="color:#24292f; text-align:start"><img alt="09.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/09-.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17-ZGC 暫停時間表現</p><p style="color:#24292f; text-align:start">吞吐量方面，G1 伴隨流量的變化呈現出一定的波動趨勢，均線在 99.3% 左右。ZGC 的吞吐量則比較穩定，維持在無限接近 100% 的水平。</p><p style="color:#24292f; text-align:start"><img alt="9.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/9--.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK8-G1 吞吐量</p><p style="color:#24292f; text-align:start"><img alt="1.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/--1.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17-ZGC 吞吐量</p><p style="color:#24292f; text-align:start">對於實際業務接口的影響，從下圖中可以看到平均響應時間有所下降，這裏的 RT 差值表示接口經過網關層的損耗時間；不同接口的 RT 差值損耗是不同的，這可能和請求響應體的大小，是否經過登錄驗證，風控驗證等業務邏輯有關。</p><p style="color:#24292f; text-align:start"><img alt="80.png" src="https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10569101/8-0.png" referrerpolicy="no-referrer"></p><p style="text-align:center">JDK17 與 JDK8 ART 對比</p><p style="color:#24292f; text-align:start">需要指出的是 ZGC 對於一般的 RT 敏感型應用有很大提升， 服務的 RT 99 線得到顯著改善。但是如果當前應用大量使用了堆外內存的方式，則提升相對較弱，如大量使用 netty 框架的應用, 因為這些應用的大部分數據都是通過手動釋放的方式進行管理。</p><span id="OSC_h1_41"></span><h1>八、思考總結</h1><span id="OSC_h2_42"></span><h2>架構演進</h2><p style="color:#24292f; text-align:start">API 網關的自研並非一蹴而就，而是經歷了多次業務迭代循序漸進的過程；從早期的泛化路由引發的安全問題處理，到後面的大量路由註冊，帶來的匹配性能下降 ，以及最終壓垮老網關最後一根稻草的內存泄漏問題；在不同階段需要使用不同的應對策略，早期業務快速迭代，大量的需求堆積，最快的時候一個功能點的改動需要三四天內上線 ，我們很難有足夠的精力去做一些深層次的改造，這個時候需求導向為優先，功能性建設完善優先，是一個快速奔跑的建設期；伴隨體量的增長安全和穩定性的重視程度逐步拔高，繼而推進了這些方面的大量建設；從拓展 SCG 的原有功能到改進框架源碼，以及最終的自研重寫，可以説新的 API 網關是一個業務推進而演化出來的產物，也只有這樣 」生長「 出來的架構產品才能更好的契合業務發展的需要。</p><span id="OSC_h2_43"></span><h2>技術思考</h2><p style="color:#24292f; text-align:start">開源的 API 網關有很多，但是自研的案例並不多，我們能夠參考的方案也很有限。除了幾個業界知名的產品外，很多開源的項目參考的價值並不大；從自研的目標來看，我們最基本的要求是性能和穩定性要優於現有的開源產品，至少 Java 的生態是這樣；這就要求架構設計和代碼質量上必須比現有的開源產品更加優秀，才有可能；為此我們深度借鑑了流量代理界的常青樹 Nginx，發現基於 Linux 多進程模型下的 OS，如果要發揮出最大效能，單 CPU 核心支撐單進程（線程）是效率最高的模式。可以將 OS 的進程調度開銷最小化同時將高速緩存 miss 降到最低，此外還要儘可能減少或者消除數據競爭，避免鎖等待和自旋帶來的性能浪費；DAG 的整個技術架構可以簡化的理解為引入了獨立控制流的多線程版的 Nginx。</p><p style="color:#24292f; text-align:start">中間件的研發創新存在着較高的難度和複雜性，更何況是在業務不斷推進中換引擎。在整個研發過程中，為了儘可能適配老的業務邏輯，對原有的業務邏輯的改動最小化，新網關對老網關的架構層接口做了全面適配；換句話説新引擎的對外暴露的核心接口與老網關保持一致，讓老的業務邏輯在 0 改動或者僅改動少量幾行代碼後就能在新網關上直接跑，能夠極大幅度降低我們的測試迴歸成本，因為這些代碼本身的邏輯正確性，已經在生產環境得到了大量驗證。這樣的適配器模式同樣適用於其他組件和業務開發。</p><p style="color:#24292f; text-align:start">作為底層基礎組件的開發人員，要對自己寫下的每一行代碼都有清晰的認識，不瞭解的地方一定要多翻資料，多讀源碼，模稜兩可的理解是絕對不夠的；常見的開源組件雖然説大部分代碼都是資深開發人員寫出來的，但是有程序員的地方就有 bug ，要帶着審慎眼光去看到這些組件，而不是一味地使用盲從，所謂盡信書不如無書；很多中間件的基本原理都是相通的，如常見 Raft 協議，基於 epoll 的 reactor 網絡架構，存儲領域的零拷貝技術，預寫日誌，常見的索引技術，hash 結構，B+樹，LSM 樹等等。一個成熟的中間件往往會涉及多個方向的技術內容。研發人員並不需要每一個組件都涉獵極深，也不現實，掌握常見的架構思路和技巧以及一些基本的技術點，做到對一兩個組件做到熟稔於心。思考和理解到位了，很容易觸類旁通。</p><span id="OSC_h2_44"></span><h2>穩定性把控</h2><p style="color:#24292f; text-align:start">自研基礎組件是一項浩大的工程，可以預見代碼量會極為龐大，如何有效管理新項目的代碼質量是個棘手的問題; 原有業務邏輯的改造也需要回歸測試；現實的情況是中間件團隊沒有專職的測試，質量保證完全依賴開發人員；這就對開發人員的代碼質量提出了極高的要求，一方面我們通過與老網關適配相同的代理引擎接口，降低遷移成本和業務邏輯出現 bug 的概率；另一方面還對編碼質量提出了高標準，平均每週兩到三次的 CodeReview；80% 的單元測試行覆蓋率要求。</p><p style="color:#24292f; text-align:start">網關作為流量入口，承接全司最高流量，對穩定性的要求極為苛刻。最理想的狀態是在業務服務沒有任何感知的情況下，我們將新網關逐步替換上去；為此我們對新網關上線的過程做了充分的準備，嚴格控制上線過程；具體來看整個上線流程分為以下幾個階段：</p><p style="color:#24292f; text-align:start"><strong>第一階段</strong></p><p style="color:#24292f; text-align:start">我們在壓測環境長時間高負載壓測，持續運行時間 24 小時以上，以檢測內存泄漏等穩定性問題。同時利用性能檢測工具抓取熱點火焰圖，做針對性優化。</p><p style="color:#24292f; text-align:start"><strong>第二階段</strong></p><p style="color:#24292f; text-align:start">發佈測試環境試跑，採用並行試跑的方式，新老網關同時對外提供服務（流量比例 1 ：1，初期新網關承接流量可能只有十分之一），一旦用戶反饋的問題可能跟新網關有關，或者發現異常 case，立即關停新網關的流量。待查明原因並確認修復後，重新引流。</p><p style="color:#24292f; text-align:start"><strong>第三階段</strong></p><p style="color:#24292f; text-align:start">上線預發，小得物環境試跑，由於這些環境流量不大，依然可以並行長時間試跑，發現問題解決問題。</p><p style="color:#24292f; text-align:start"><strong>第四階段</strong></p><p style="color:#24292f; text-align:start">生產引流，單節點從萬分之一比例開始灰度，逐步引流放大，每個階段停留 24 小時以上，觀察修正後再放大，循環此過程；基於單節點承擔正常比例流量後，再次抓取火焰圖，基於真實流量場景下的性能熱點做針對性優化。</p><span id="OSC_h2_45"></span><h2>團隊成長</h2><p style="color:#24292f; text-align:start">回顧整個研發歷程我們在不間斷新業務承接的情況下，幾個月時間內完成開發和上線，從節奏上來講不可謂不快，研發同學的心態也經歷了一些變化。從一開始的質疑，認為大家以前從沒有做過的東西現在就這點人能搞的出來嗎？到中期的這個組件寫起來蠻有挑戰也很有意思！直到後期初版壓測數據出來後的驚訝。就項目結果而言，可以説收穫感滿滿，從後續的針對研發同學的 one one 溝通反饋來看，對於整個項目感觸最大的是技術上的提升很大，對高併發網絡編程領域的認知提升了一個檔次, 尤其是異步編程方面，技術信心增強很多；內部也組織了分享會，大家普遍很感興趣，收穫了較大的技術紅利。</p><p style="color:#24292f; text-align:start">*<strong>文/簌語</strong></p><p>本文屬得物技術原創，更多精彩文章請看：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.dewu.com" target="_blank">得物技術官網</a></p><p>未經得物技術許可嚴禁轉載，否則依法追究法律責任！</p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:30:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/11033092</guid>
            <link>https://my.oschina.net/u/5783135/blog/11033092</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[微軟投資「歐洲版 OpenAI」 Mistral]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>微軟公司週一宣佈與法國大模型創業公司&nbsp;Mistral AI 建立新的合作伙伴關係，後者有 「歐洲版 OpenAI」 之稱。</p><p>微軟在一份聲明中表示將投資 20 億歐元幫助 Mistral AI 開啓「新的商業機會」，並向全球市場擴張，但沒有提供進一步的財務細節。</p><p>根據協議，Mistral 宣佈其最先進的大模型 Mistral Large 首次通過微軟的雲服務 Azure 提供——成為繼 OpenAI 之後第二家在微軟 Azure 雲計算平台上提供商業語言模型的公司。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-24b13d1f5c37e4bc325eac6c3bbdf3ab204.png" referrerpolicy="no-referrer"><u><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmistral-large%2F" target="_blank">https://mistral.ai/news/mistral-large/</a></em></u></p><p>微軟還將幫助這家初創公司獲得新客戶，後者將推出其 ChatGpt 風格的多語言對話助手「Le Chat」（貓）。微軟總裁布拉德·史密斯（Brad Smith）週一表示，這筆交易是該公司支持歐洲技術的「重要」信號。</p><p>與此同時，有人發現 Mistral AI 修改了其網站內容，刪除了所有提及對開源社區義務的內容，所以有網友推測他們未來不太可能再發布任何開源模型。</p><p><img src="https://oscimg.oschina.net/oscnet/up-c96c457e5fd400acfcd37ead7a44f8b1528.png" referrerpolicy="no-referrer"></p><p>一位 X 用戶發帖稱：「我不想説謊；我很遺憾 Mistral 沒有開源他們的任何模型。我以為他們是 OSS 團隊的。」另一位用戶轉發了微軟 CEO 納德拉宣佈與 Mistral AI 合作的消息，並評論稱：「這可能是原因。」馬斯克則<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Felonmusk%2Fstatus%2F1762217391633952953" target="_blank">評論道</a>：「是微軟讓他們閉源的？」</p><p><img height="2051" src="https://oscimg.oschina.net/oscnet/up-6027c2509b672051b14eb678783045ad0e9.png" width="1287" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Tue, 27 Feb 2024 02:23:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280426</guid>
            <link>https://www.oschina.net/news/280426</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[中文 JDK21 API 網站上線，為 Java 開發者提供全新體驗！]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">Java Development Kit (JDK) 21 是 Java 平台的最新版本，為 Java 開發者提供了許多新特性和改進。為了更好地支持中文開發者，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在碼官網</a>在此自豪地宣佈推出最新的中文 JDK21 API 網站。</p><p>這個<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn" target="_blank">存在碼</a>網站將成為中文 Java 開發者的首選資源，提供以下內容：</p><ol><li>中文 Java 教程：提供系統的 Java 編程教程，從 Java 基礎到高級特性，全面介紹 Java 編程的最佳實踐。</li><li>JavaFX 教程：提供 JavaFX 編程的詳細教程，介紹 JavaFX 的視圖和控制器、圖形和動畫、媒體和圖像等多個方面。</li><li>Orekit 教程：提供 Orekit 庫的詳細教程，介紹 Orekit 的軌道運動學和控制、姿態和姿態動力學、導航和定位等多個方面。</li><li>JDK21 API 文檔：提供 JDK21 中所有類和方法的詳細 API 文檔，包括類描述、方法簽名、參數和返回值等。</li><li>JDK21 工具的中文文檔：提供 JDK21 中所有工具的中文文檔，包括<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjava.cunzaima.cn%2Fjdk21%2Fdoc-zh%2Fspecs%2Fman%2Fjpackage.html" target="_blank">j</a>package、jwebserver、jlink、jmap 等。</li></ol><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">我們相信，這個新的中文 JDK21 API 將會成為中文 Java 開發者的不可或缺的工具，為他們提供更加便捷和高效的 Java 開發體驗。歡迎訪問<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn%2F" target="_blank">https://cunzaima.cn/</a>，並在評論區留下您的反饋和建議。</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left">感謝您的支持和關注！</p><p style="color:#000000; margin-left:0; margin-right:0; text-align:left"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcunzaima.cn%2F" target="_blank"><img height="100" src="https://oscimg.oschina.net/oscnet/up-3f77e9064178316e9c9acacd55ae6b89c0f.jpg" width="100" referrerpolicy="no-referrer"></a></p><p>網站內容截圖：</p><p><img height="887" src="https://oscimg.oschina.net/oscnet/up-b439f6c336100368058aa097a0cc2cc8b44.png" width="1166" referrerpolicy="no-referrer"></p><p><img height="887" src="https://oscimg.oschina.net/oscnet/up-e5afd9a524f3a61fbd854899739c3a190fb.png" width="1166" referrerpolicy="no-referrer"></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 14:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280393</guid>
            <link>https://www.oschina.net/news/280393</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[ONLYOFFICE 文檔獲得達夢數據兼容認證：如何將數據庫連接到編輯器]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Foffice-suite.aspx" target="_blank">ONLYOFFICE 文檔</a>獲得了與達夢數據庫的兼容證書。閲讀本文，瞭解如何將數據庫連接到 ONLYOFFICE 開源文檔編輯器。</p><p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"><img alt="ONLYOFFICE 文檔獲得達夢數據兼容認證：如何將數據庫連接到編輯器" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/22105702/onlyoffice-and-dameng-db.png" referrerpolicy="no-referrer"></p><h2><strong>關於達</strong><strong>夢</strong><strong>數據</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">隨着數字經濟的快速發展，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.dameng.com%2F" target="_blank"><u>達夢</u></a>在數字化轉型解決方案方面積累了豐富的經驗，為客戶提供各類數據庫軟件及集羣軟件、雲計算與大數據等一系列產品及服務。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">目前的&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.dameng.com%2Fview%2F16.html" target="_blank"><u>DM8</u></a><span>&nbsp;</span>是新一代大型通用關係數據庫，完全支持 ANSI SQL 標準和主流編程語言接口/開發框架。該數據庫擁有行列融合存儲技術，兼容 OLAP 和 OLTP 系統，滿足 HTAP 混合應用場景。</p><h2><strong>兼容性</strong><strong>認證</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">ONLYOFFICE 與武漢達蒙數據庫股份有限公司一起通過了相互測試。因此，<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdocs-enterprise.aspx%3Futm_source%3Dblog%26utm_medium%3Darticle%26utm_campaign%3Ddameng" target="_blank"><u>ONLYOFFICE<span>&nbsp;</span></u><u>文檔</u></a>被認證為與 DM8 兼容的穩定解決方案。</p><p style="text-align:center"><img alt="ONLYOFFICE Docs certified by Dameng: How to connect DB to the editors" src="https://static-blog.onlyoffice.com/wp-content/uploads/2024/02/22105811/dameng-certificate-714x1024.jpg" referrerpolicy="no-referrer"></p><h2><strong>如何將</strong><strong>達夢數據庫</strong><strong>連接到 ONLYOFFICE 文檔</strong></h2><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">本指南建議先在一個單獨的分支裏開發實現一個測試 bench：<code>feature/damengdb-compose</code></p><pre><code class="language-javascript"><span>BUILD=&lt;build-number-</span><strong>from</strong><span>-develop&gt; docker compose up -d</span></code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">使用 Docker 安裝 ONLYOFFICE 文檔時，可以指定可用<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%3Ftab%3Dreadme-ov-file%23available-configuration-parameters" target="_blank"><u>變量</u></a><em>（DB_TYPE</em>、<em>DB_NAME</em>、<em>DB_HOST、DB_USER</em>、<em>DB_PWD、DB_PORT）</em><em>，</em>允許自定義數據庫連接。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">要連接達夢數據庫，需要將連接條件和參數添加到 ONLYOFFICE 文檔（文件服務器）映像的初始化入口點腳本中。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%2Fpull%2F712%2Ffiles%23diff-8303d91c24ab115773c468f37319449463b1e1ff312b4e560d14a7c16a1e4b25R377" target="_blank"><u>添加新的數據庫類型</u></a>：</p><pre><code class="language-javascript"><span style="color:#880000">"dameng"</span><span>)
</span><span>      DB_PORT=${</span><span>DB_PORT</span><span>:-</span><span style="color:#880000">"5236"</span><span>}
</span>      ;;</code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%2Fpull%2F712%2Ffiles%23diff-8303d91c24ab115773c468f37319449463b1e1ff312b4e560d14a7c16a1e4b25R423" target="_blank"><u>添加</u><u>遠程數據庫創建功能</u></a>：</p><pre><code class="language-javascript"><strong>create_dameng_tbl</strong><span>(</span><span>)</span><span> {
</span>  DM8_USER=SYSDBA
  DM8_PASS=SYSDBA001

<span>  (cd /opt/dmdbms/bin/ &amp;&amp; ./disql $DM8_USER/$DM8_PASS@$DB_HOST:$DB_PORT -e </span><span style="color:#880000">"create user "</span><span>onlyoffice</span><span style="color:#880000">" identified by "</span><span>onlyoffice</span><span style="color:#880000">" password_policy 0;"</span><span>)
</span>  # Create db on remote server
<span>  echo </span><span style="color:#880000">"EXIT"</span><span> | tee -a $APP_DIR/server/schema/dameng/createdb.sql
</span><span>  (cd /opt/dmdbms/bin/ &amp;&amp; ./disql $DM8_USER/$DM8_PASS@$DB_HOST:$DB_PORT \</span><span style="color:#880000">`$APP_DIR/server/schema/dameng/createdb.sql)
</span><span style="color:#880000">}</span></code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">將這些更改添加到入口腳本後，文檔服務器就可以初始化與數據庫的連接了。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">創建一個簡單的&nbsp;compose 文件，您可以在其中指定文檔服務器所需的變量：</p><ul><li><strong>DB_TYPE：</strong>&nbsp;達夢數據庫</li><li><strong>DB_HOST：</strong>compose 文件中數據庫服務的名稱（DNS 名稱）</li><li><strong>DB_NAME：</strong>要使用的數據庫的名稱。應在容器啓動時出現。</li><li><strong>DB_USER：</strong>用戶名</li><li><strong>DB_PWD：</strong>用戶密碼</li><li><strong>DB_PORT：</strong>帶數據庫的服務端口</li></ul><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">從<code>damengdb</code><span>&nbsp;</span>容器裝入二進制目錄，以便文件服務器容器可以訪問<code>disql</code><span>&nbsp;</span>實用程序。請參閲<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FONLYOFFICE%2FDocker-DocumentServer%2Fpull%2F712%2Ffiles%23diff-bc48fb274f9199eed1a1a0dabb00738c2c5dd87ab1c85fdb1feb15d22c83f66b" target="_blank"><u>docker-compose.yml</u></a>以瞭解更多信息。</p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start"><strong>運行<span>&nbsp;</span></strong><strong>stand</strong></p><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">要啓動這個 stand，請執行以下命令：</p><pre><code class="language-javascript"><span>git clone -b feature/damentdb-compose https:</span><span style="color:#888888">//github.com/ONLYOFFICE/Docker-DocumentServer.git</span><span></span>cd Docker-DocumentServer/tests/damengdb/
docker compose up –d</code></pre><p style="color:#333333; margin-left:0; margin-right:0; text-align:start">注意：數據庫映像可在&nbsp;hub.docker 上獲得。為方便起見，我們上傳了&nbsp;v8.1.2.128&nbsp;映像：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhub.docker.com%2Fr%2Fdanilaworker%2Fdamengdb" target="_blank"><u>點擊此處查看</u></a>。</p><div><h3><strong>相關鏈接</strong></h3><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.dameng.com%2F" target="_blank"><u>達</u><u>夢官方網站</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fcertificates.aspx" target="_blank"><u>ONLYOFFICE 證書</u></a></p><p style="color:#333333; margin-left:0; margin-right:0"><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.onlyoffice.com%2Fzh%2Fdownload-docs.aspx" target="_blank"><u>獲取 ONLYOFFICE 文檔</u></a></p></div></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 12:18:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280385</guid>
            <link>https://www.oschina.net/news/280385</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[鴻蒙程序員平均月薪超 1 萬 8]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>據智聯招聘數據顯示，春招鴻蒙崗位需求是去年近 3 倍。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-47729617a06471ca213c42bdadb7fd974ad.png" referrerpolicy="no-referrer"></p><p>本月初，華為 HarmonyOS 在新年賀詞中提到，基於開源鴻蒙開發的 HarmonyOS NEXT 鴻蒙星河版將在今年秋天正式和消費者見面，這也促使大量企業急需鴻蒙人才。</p><p>春節後開工第一週，鴻蒙相關職位數同比增長 163%，投遞人數同比增長 349%，同時，鴻蒙開發崗的招聘薪資，達到 18191 元/月，比總體開發崗的平均薪資（16617 元/月）高出 9%。</p><p><img alt="" src="https://oscimg.oschina.net/oscnet/up-bb038ad20fec544a0619fbde6c5f4049059.png" referrerpolicy="no-referrer"></p><p>來自：<em><u><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1656737654%2FO2miyxjc4" target="_blank">現代快報</a></u></em></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 10:49:02 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280369</guid>
            <link>https://www.oschina.net/news/280369</link>
            <author>
                <![CDATA[來源: 投稿]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[雲原生週刊：Docker 推出 Docker Build Cloud]]>
            </title>
            <description>
                <![CDATA[<div class="content"><h2>開源項目推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkube-vip%2Fkube-vip" target="_blank">Kube-Vip</a></h3><p>Kube-Vip 旨在為 Kubernetes 集羣提供高可用性和負載均衡功能。它提供了一個可插拔的 VIP（虛擬 IP）管理器，可以為集羣中的服務分配一個虛擬 IP 地址，並自動將流量路由到正確的節點。該項目提供了多種配置選項，可以根據需要選擇適合的負載均衡算法和 IP 模式。Kube-Vip 還支持一些高級功能，如自定義健康檢查和故障轉移。通過使用 Kube-Vip，用戶可以輕鬆地實現 Kubernetes 集羣的高可用性和可靠性，提供穩定的服務和無縫的故障恢復能力。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fselefra%2Fselefra" target="_blank">Selefra</a></h3><p>Selefra 的意思是「從基礎設施中選擇*」。它是一款開源策略即代碼軟件，可為多雲和 SaaS 環境提供分析，包括 AWS、GCP、Azure、阿里雲、Kubernetes、Github、Cloudflare 和 Slack 等 30 多種服務。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmarvasgit%2Fkubernetes-statemonitor" target="_blank">KubeStateWatch</a></h3><p>KubeStateWatch 是 Kubernetes 的狀態監視器，用於向多個通道發送通知，告知更改的時間和內容。</p><p>它可以獨立使用，也可以部署在 Kubernetes 中。但它的主要目的是部署在 Kubernetes 中。</p><p>KubeStateWatch 是 kubewatch 的擴展和簡化版本。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fweaveworks%2Ftf-controller" target="_blank">Weave GitOps' Terraform Controller</a></h3><p>Weave GitOps 的 Terraform 控制器（又名 Weave TF-Controller）是 Flux 的控制器，用於以 GitOps 方式協調 Terraform 資源。藉助 Flux 與 Terraform 的強大功能，TF-controller 允許您按照自己的節奏在 Kubernetes 和 Terraform 領域中對基礎設施和應用程序資源進行 GitOps 化。</p><h2>文章推薦</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40deepaksharma2494%2Funderstanding-kubernetes-and-docker-easiest-explanation-9505638107e3" target="_blank">瞭解 Docker 和 Kubernetes：一個簡單的解釋</a></h3><p>這篇文章以簡單易懂的方式解釋了 Kubernetes 和 Docker 的概念。文章首先介紹了 Docker 的作用，將應用程序和其依賴項打包成容器，實現跨平台的可移植性。然後，文章詳細解釋了 Kubernetes 的作用，它是一個容器編排和管理工具，用於自動化應用程序的部署、擴展和管理。文章強調了 Kubernetes 的重要性，它可以幫助解決容器化應用程序的挑戰，如負載均衡、服務發現和自動容錯。通過理解這兩個概念，讀者可以更好地瞭解如何使用 Docker 打包應用程序，並如何使用 Kubernetes 管理和運行這些容器化應用程序。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fovercast.blog%2Fzero-downtime-deployments-with-kubernetes-a-full-guide-71019397b924" target="_blank">使用 Kubernetes 進行零停機部署：完整指南</a></h3><p>這篇文章提供了關於使用 Kubernetes 實現零停機時間部署的全面指南。它介紹了零停機時間部署的基本原理和重要性，並詳細解釋了 Kubernetes 支持的各種部署策略，如滾動更新、藍綠部署和金絲雀發佈。文章還深入探討瞭如何通過 Kubernetes 的服務和 Ingress 來優化流量管理，確保應用程序的高可用性和用戶體驗。此外，文章還介紹了一些高級的零停機時間技術，如特性標誌和 A/B 測試，以進一步提升部署的彈性和可靠性。</p><h2>雲原生動態</h2><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoq.com%2Fnews%2F2024%2F02%2Fdocker-build-cloud%2F%3FtopicPageSponsorship%3Defb5f5b6-1e14-4b4f-8fdb-fd15c9d625f9" target="_blank">Docker 推出 Docker Build Cloud</a></h3><p>Docker 最近宣佈了他們基於雲的容器鏡像構建工具 Docker Build Cloud 的正式推出。Docker Build Cloud 提供遠程共享緩存和針對 AMD64 和 ARM64 CPU 架構的本地構建器，旨在"改善協作"並減少鏡像構建時間。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloudnativenow.com%2Ffeatures%2Fcrossplane-maintainers-add-python-support-to-control-plane%2F" target="_blank">Crossplane 增加對 Python 的支持</a></h3><p>用於管理混合 IT 環境的開源 Crossplane 平台的維護者除了現有的 Go 支持之外，還增加了對 Python 編程語言的支持。</p><p>此外，除了現在將項目託管在 xpkg.upbound.io 上之外，命令行界面 (CLI) 還通過其他子命令進行了擴展，以簡化 DevOps 工作流程，xpkg.upbound.io 是唯一符合開放容器計劃 (OCI) 規範的註冊中心瞭解 Crossplane 包的內部結構。</p><p>Crossplane 最初由 Upbound 開發，是 Kubernetes 控制平面的擴展，它使用複合資源定義 (XRD) 和 Kubernetes 自定義資源定義 (CRD) 將該控制平面的覆蓋範圍擴展到舊平台。該功能使得跨多個雲和本地 IT 環境集中管理控制平面成為可能。隨着 Crossplane 1.15 版本的發佈，IT 團隊現在還可以使用 Kubernetes 應用程序編程接口 (API) 服務器中的驗證庫根據其模式離線驗證資源。</p><h3><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoq.com%2Fnews%2F2024%2F02%2Fgrab-kafka-kubernetes-aws-nth%2F%3FtopicPageSponsorship%3Defb5f5b6-1e14-4b4f-8fdb-fd15c9d625f9" target="_blank">Grab 改進 K8s 上的 Kafka 容錯能力</a></h3><p>Grab 更新了 Kubernetes 上的 Kafka 設置，以提高容錯能力，並完全消除 Kafka 代理意外終止時的人為幹預。為瞭解決初始設計的缺點，團隊集成了 AWS Node Termination Handler (NTH)，使用負載均衡器控制器進行目標組映射，並切換到 ELB 捲進行存儲。</p><p>兩年來，Grab 一直在生產環境中使用 Strimzi 在 Kubernetes ( EKS ) 上運行 Apache Kafka，作為其 Coban 實時數據平台的一部分。該團隊之前利用 Strimzi（現在是 CNCF 孵化項目），通過將經過驗證的身份驗證、授權和機密性機制應用於所有服務器-服務器和客戶端-服務器集成來增強 Kafka 集羣安全性。</p><blockquote><p>本文由博客一文多發平台 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank">OpenWrite</a> 發佈！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 09:55:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/11044789</guid>
            <link>https://my.oschina.net/u/4197945/blog/11044789</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[2024 年 Apache DolphinScheduler RoadMap：引領開源調度系統的未來]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>非常歡迎大家來到 Apache DolphinScheduler 社區！隨着開源技術在全球範圍內的快速發展，社區的貢獻者 <strong>「同仁」</strong> 一直致力於構建一個強大而活躍的開源調度系統社區，為用戶提供高效、可靠的任務調度和工作流管理解決方案。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6e52878282cac3d28604d1cbd49899728c9.png" alt="file" referrerpolicy="no-referrer"></p><p>在過去的一段時間裏，我們取得了一些重要的成就，但我們的願景遠未實現。為了更好地滿足用戶需求和推動項目的發展，我們在 2024 新春伊始，制定了以下 Roadmap，將在未來的版本中實現一系列激動人心的功能和改進。</p><h2>當前社區狀態</h2><p>2024 年 roadmap 有兩個來源，部分是來自 2023 年發起但是沒有開始實施，或者實施了部分的議題，另一部分是最新新增的議題。2024 年 roadmap 可以分成如下幾個部分</p><p><strong>雲原生相關</strong>： 我們希望增加 K8S executor 複用 K8S 提供的能力做彈性資源管理、監控和失敗重試等</p><p><strong>任務插件增強</strong>： 我們收到了用戶關於任務插件的訴求，將會進一步支持 streaming 類型的任務、trigger 類型插件等，除此之外，我們還希望統一在 worker 和 master 中運行的任務、以及為任務插件增加生命週期的接口。於此同時我們會持續關注動態任務組件的功能，希望以後可以對任務組件單獨發版保證迭代頻率</p><p><strong>DataOps 相關</strong>：希望引入 data ops 相關功能，通過集成 git 供應商來實現 git ops，最終實現工作流 CICD&nbsp;</p><p><strong>測試</strong>： 我們會繼續完善和增加項目單元測試覆蓋率，並且逐步補充 API 部分的測試</p><p><strong>其他優化</strong>：引入工作流事件觸發功能；優化審計日誌</p><h3>雲原生相關</h3><p>我們希望引入 K8S executor 作為 dispatcher 將 dolphinscheduler 的任務分發到 K8S 中，K8S executor 的好處是我們可以有更高的資源利用率；沿用 K8S 的監控機制，實現 pod level 的監控；沿用 pod 容錯做任務容錯。</p><p>這個設計的核心是將 executor 的抽象出來變成可配置的， 用戶可以選擇 K8S 或者非 K8S 的 executor，如果選擇 K8S executor ，dolphinscheduler 會將任務提交到 K8S API server ，每個任務啓動一個 worker，運行一個 pod。這一點的好處是 worker 不是一個長期運行的資源，而是僅當有任務的時候才需要啓動。當業務低谷的時候，我們有空運行的 worker 來等待任務運行。</p><p>詳情請看鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F13316" target="_blank">https://github.com/apache/dolphinscheduler/issues/13316</a></p><p><img src="https://oscimg.oschina.net/oscnet/up-bcabca103a55182159cc091dd62f7578835.png" alt="file" referrerpolicy="no-referrer"></p><h3>任務插件增強</h3><p><strong>streaming 任務類型增強</strong></p><p>2023 年 dolphinscheduler 社區增加了 streaming 任務類型的支持，但是是使用 shell 提交 flink 任務，一經推出收穫了不少用戶。當時實現的是一個簡單版本，想看看用戶反饋，開發者在開發過程，以及用戶的使用中發現了部分可優化項。這部分優化項目我們希望能在 2024 年有部分進展，其中包括</p><ul><li>使用 flink sdk 去創建和提交任務，目前的 shell 方式提交不能很好的監控和處理運行中的任務，使用 sdk 可以有更多功能的支持，詳情請看鏈接：&nbsp;<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F11440" target="_blank">https://github.com/apache/dolphinscheduler/issues/11440</a></li><li>支持 flink sql</li><li>增加 flink 的指標</li><li>增加 checkpoints savepoint 管理，保證任務失敗重試等異常情況能繼續執行</li></ul><p>詳情請查看 <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F11352" target="_blank">https://github.com/apache/dolphinscheduler/issues/11352</a></p><p><strong>動態任務組件 &amp; 任務單獨發版</strong></p><p>這個任務是引入動態任務組件的概念，將任務組件的參數通過後端定義，然後在前端渲染，希望通過這樣方法化簡任務組件的開發流程，在參數的輸入類型沒有新增的情況下，可以不修改或者少修改前端代碼而實現任務組件的新增和修改。</p><p>詳情請看鏈接：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F12526" target="_blank">https://github.com/apache/dolphinscheduler/issues/12526</a></p><p>同時這個任務也是我們將任務插件單獨發版的前置任務，任務插件單獨發版也是非常重要的功能，實現了這個功能後，我們可以加快任務插件的發版頻率，保證用戶使用的是功能豐富、最新的任務插件。例如我們有一個新的任務插件 A ，這個插件在昨天被 merge 到 dev 分支，那麼我們今天就能安排這個插件的發版。又例如我們發現了已經發版的任務插件 B 有比較嚴重的 bug，在，這個 bug 被 fix 後，我們就能安排插件的 bugfix 版本發版。</p><p>這個任務已經實現了已經簡單的 demo，詳情請看鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F12526" target="_blank">https://github.com/apache/dolphinscheduler/issues/12526</a></p><p><strong>任務插件生命週期管理</strong></p><p>為任務插件增加 close 方法從而更好的管理任務插件，特別是需要關閉資源的的任務組件，如數據庫、雲計算資源任務等。我們目前為任務插件定義了 init、handle、cancel 等方法，對於關閉資源的方法都是在任務中單獨實現的，所以希望抽象一個 close 方法統一處理需要關閉資源的任務。</p><p>詳情請看鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F14877" target="_blank">https://github.com/apache/dolphinscheduler/issues/14877</a></p><p><strong>統一 worker 和邏輯任務</strong></p><p>dolphinscheduler 現在有兩個類型的任務 spi，分別是 worker 任務和邏輯任務，這兩種任務類型分別是運行在 worker 上的，以及運行在 master 上的。不同的 spi 導致兩種任務有不同的生命週期管理，並且不利於後面動態任務組件的實現，所以需要將兩種任務儘可能弄成統一 spi。</p><p>詳情請看鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F14823" target="_blank">https://github.com/apache/dolphinscheduler/issues/14823</a></p><h3>Git Ops</h3><p>dolphinscheduler 在處理生產和開發環境的時候，只能通過 json 導入導出來實現，社區部分夥伴建議我們可以使用 gitops 方法論來實現開發到生產環境的部署。GitOps 是一種基於版本控制系統的持續交付和基礎設施管理的方法。它的核心理念是將整個系統的狀態和配置存儲在版本控制庫中，通過 Git 的特性實現對系統的自動化管理和持續交付。</p><p><strong>gitops 支持</strong></p><p>希望將工作流相關資源的校驗、工作流部署到生產環境的功能集成到 dolphinscheduler 中，集成之後只需要在 dolphinscheduler 配置 git 供應商的 url 和鑑權信息，就能在遠程倉庫中有新的 push 事件後，立馬觸發工作流的更新操作，從而保證生產中的工作流和遠端 git 供應商的定義是一樣的，實現客戶的 cicd ，保證流程簡單便捷</p><p><strong>測試</strong></p><p>測試對於開源軟件至關重要，它不僅確保軟件質量和穩定性，還提高了用戶體驗。通過全面的測試，可以及時發現和修復潛在的問題，增強軟件的可靠性。測試也是保證新功能引入不破壞現有功能的關鍵，為開源項目的可持續發展提供了堅實的基礎。dolphinscheduler 社區從 2023 年一直在努力提高測試覆蓋度、並做了優化讓貢獻者更加方便的寫測試，但是測試的增強是一個長期的工作，2024 年我們會堅持這部分內容</p><p><strong>API 測試</strong></p><p>在 api 層面的測試，確保我們核心的 api 接口能正常運行。當被 api 測試覆蓋的接口，可以確保每次提交新代碼時，API 接口邏輯和依賴關係都正確，不會破壞之前已有的功能。補充缺失的單元測試，確保接口與接口之間的連接性。dolphinscheduler 社區在 2023 年已經啓動 api 測試的補充，目前部分核心接口已經覆蓋，希望在 2024 年將盡可能多的 api 接口進行覆蓋。</p><p>詳情請看鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F10411" target="_blank">https://github.com/apache/dolphinscheduler/issues/10411</a></p><p><strong>UT 增強</strong></p><p>單元測試對比 API 測試是粒度更加小的，他能保證部分代碼塊如預期般工作，在此之前我們升級到了 junit5，並且增加了 worker 部分的測試覆蓋率，與 api 測試一樣的是，這是一個長期的工作，同時需要更多有激情的貢獻者參與到該功能的建設中。</p><p>詳情請看鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F10573" target="_blank">https://github.com/apache/dolphinscheduler/issues/10573</a></p><h3>其他優化</h3><p><strong>工作流 trigger 支持</strong></p><p>引入 trigger 插件實現事件觸發，目前我們工作流的啓動方式有兩種，用戶手動觸發；定時觸發。事件觸發是希望增加其中的範圍，讓工作流可以被更多的事件觸發。目前打算支持的事件包括</p><ul><li>定時觸發： 目前已經有的觸發方式</li><li>消息隊列觸發：通過消息監聽消息隊列的方式觸發工作流</li><li>HTTP、TCP、SMTP 觸發：通過監聽 HTTP、TCP、SMTP 特定事件觸發工作流</li></ul><p><img src="https://oscimg.oschina.net/oscnet/up-b839753a55a744119a2477182268d00ef2f.png" alt="file" referrerpolicy="no-referrer"></p><p>詳情請看鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F15330" target="_blank">https://github.com/apache/dolphinscheduler/issues/15330</a></p><p><strong>審計日誌增強</strong></p><p>Apache Dolphinscheduler 會在 2024 年增加更多的審計日誌相關的功能，保證將用戶對資源的操作能記錄下來，這裏的資源包括項目、工作流、任務、資源中心文件、udf、數據源等在 dolphinscheduler 中會被創建、修改、刪除、更新的資源。</p><p>我們目前打算通過 AOP 的方式實現這個功能，<strong>實現了審計日誌後</strong>，用戶可以更好的查看資源創建情況，當出現意外情況時及時通過審計日誌發現歷史操作。</p><p>目前有一個 PR 初步實現了這個功能，詳情請看鏈接： <a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fdolphinscheduler%2Fissues%2F15423" target="_blank">https://github.com/apache/dolphinscheduler/issues/15423</a></p><p>隨着這份路線圖的實施，Apache DolphinScheduler 社區將持續優化和擴展我們的調度系統，為用戶提供更加強大、靈活和高效的解決方案。</p><p>我們相信，通過社區成員的共同努力和用戶的積極反饋，Apache DolphinScheduler 將繼續領跑開源調度和工作流管理領域，為企業和開發者帶來更多的價值和可能性。讓我們攜手並進，共同見證 Apache DolphinScheduler 的蓬勃發展和創新旅程。</p><p>&nbsp;</p><blockquote><p>本文由 <a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.whaleops.com" target="_blank">白鯨開源科技</a> 提供發佈支持！</p></blockquote></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 09:47:00 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/dailidong/blog/11044801</guid>
            <link>https://my.oschina.net/dailidong/blog/11044801</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[基於 Qt5 的 Windows 截圖工具，可代替微信和搜狗截圖]]>
            </title>
            <description>
                <![CDATA[<p><img src="https://gitee.com/tujiaw/ntscreenshot/raw/master/ntscreenshot_demo.png" alt="ntscreenshot" referrerpolicy="no-referrer"><img src="https://gitee.com/tujiaw/ntscreenshot/raw/master/ntscreenshot_demo2.png" alt="ntscreenshot" referrerpolicy="no-referrer"></p><p><a href="https://gitee.com/tujiaw/ntscreenshot/tree/master/release">已編譯好的綠色包下載</a></p><h1><a id="user-content-ntscreenshot" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#ntscreenshot"></a>ntscreenshot</h1><p>Windows 截圖工具，基本功能都實現了，陸陸續續也花了不少時間，<a href="https://gitee.com/tujiaw/ntscreenshot">源碼地址</a>有興趣的 Star 一下吧。</p><h1><a id="user-content-功能列表" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E5%8A%9F%E8%83%BD%E5%88%97%E8%A1%A8"></a>功能列表</h1><h2><a id="user-content-基本的截圖功能" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%88%AA%E5%9B%BE%E5%8A%9F%E8%83%BD"></a>基本的截圖功能</h2><ul><li>託盤菜單</li><li>全局快捷鍵設置，默認 F5 截圖，F6 貼圖</li><li>開機自啓動設置</li><li>移動鼠標自動感知選區</li><li>放大器，放大當前鼠標所在像素點周圍區域</li><li>顯示選區大小，鼠標光標座標，光標所在位置像素的顏色</li><li>c 鍵複製當前顏色</li><li>移動鼠標選擇選區</li><li>方向鍵進行像素級移動</li><li>截圖背景透明度設置</li><li>保存截圖到剪切板</li><li>保存截圖到文件目錄</li></ul><h2><a id="user-content-貼圖" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E8%B4%B4%E5%9B%BE"></a>貼圖</h2><ul><li>貼圖管理</li><li>貼圖邊框</li></ul><h2><a id="user-content-標註" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E6%A0%87%E6%B3%A8"></a>標註</h2><ul><li>基本圖形文字標註</li><li>支持改顏色，畫筆、字體大小</li><li>支持馬賽克</li><li>支持撤銷</li></ul><h2><a id="user-content-上傳圖牀" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E4%B8%8A%E4%BC%A0%E5%9B%BE%E5%BA%8A"></a>上傳圖牀</h2><p>需要配置服務器</p><h2><a id="user-content-設置" class="anchor" href="https://gitee.com/tujiaw/ntscreenshot#%E8%AE%BE%E7%BD%AE"></a>設置</h2><p>託盤右鍵菜單打開設置窗口</p>]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 09:44:00 GMT</pubDate>
            <guid isPermaLink="false">https://gitee.com/tujiaw/ntscreenshot</guid>
            <link>https://gitee.com/tujiaw/ntscreenshot</link>
        </item>
        <item>
            <title>
                <![CDATA[GitHub Copilot 會擴大代碼的不安全性]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p>開發者安全公司 Snyk 發文<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsnyk.io%2Fblog%2Fcopilot-amplifies-insecure-codebases-by-replicating-vulnerabilities%2F" target="_blank">指出</a>，GitHub Copilot 可以複製代碼中現有的安全問題。即當用戶現有的代碼庫存在安全問題時，GitHub Copilot 可能會基於此提供一些不安全的代碼建議；「這意味着，項目中現有的安全債務會讓使用 Copilot 的不安全開發變得更不安全。」</p><p>另一方面，如果代碼庫已經高度安全，則 Copilot 生成存在安全問題的代碼的可能性就會較小，因為它可以利用的不安全代碼上下文較少。這也極大地激勵了人們投入時間來減少現有代碼庫中的漏洞，從而減少未來通過生成式 AI 編碼助手引入的問題。</p><p>Snyk 表示， GitHub Copilot、Amazon CodeWhisperer 和 ChatGPT 等生成式 AI 編碼助手在生產力和代碼效率方面實現了重大飛躍。但這些工具不理解代碼語義，因此無法對其進行判斷。</p><p>GitHub Copilot 根據從大量現有代碼存儲庫中學到的模式和結構生成代碼片段。雖然這種方法有優點，但在安全方面也存在明顯的缺點。Copilot 的代碼建議可能會無意中複製鄰接文件中存在的現有安全漏洞和不良做法，導致不安全的編碼實踐，併為一系列安全漏洞打開大門。</p><p><img height="287" src="https://oscimg.oschina.net/oscnet/up-af08dd68db7fed4ac1bc73918bf7af185e2.png" width="500" referrerpolicy="no-referrer"></p><p>為了減少 AI 助手生成的代碼中重複出現現有的安全問題，Snyk 建議採取以下措施：</p><ul><li>開發人員應該對代碼進行手動審查。</li><li>安全團隊應該建立 SAST（security application security testing）護欄，包括策略。</li><li>開發人員應遵守安全編碼指南。</li><li>安全團隊應該為開發團隊提供培訓和意識，並對每個團隊積壓的問題進行優先級和分類。</li><li>執行團隊應強制要求設置安全護欄。</li></ul><p>更多詳情可<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsnyk.io%2Fblog%2Fcopilot-amplifies-insecure-codebases-by-replicating-vulnerabilities%2F" target="_blank">查看官方博客</a>。&nbsp;</p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 08:12:00 GMT</pubDate>
            <guid isPermaLink="false">https://www.oschina.net/news/280334/github-copilot-amplifies-insecure-codebases</guid>
            <link>https://www.oschina.net/news/280334/github-copilot-amplifies-insecure-codebases</link>
            <author>
                <![CDATA[來源: OSCHINA]]>
            </author>
        </item>
        <item>
            <title>
                <![CDATA[🔥 周熱點 | Warp 正式發佈 Linux 版本；披着 Windows 11 外衣的 Ubuntu：能跑 exe 程序、支持 Android 應用.....]]>
            </title>
            <description>
                <![CDATA[回顧一週熱門資訊。2024.02.19-2024.02.25]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 07:39:00 GMT</pubDate>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094405&#38;idx=1&#38;sn=76fa95b2d568a613ee5903f8d3976d4a&#38;chksm=880c4216bf7bcb00d586ffe8ded38f9c3b4426ec5ddfc0f8617a965327c402a814e03533dd08&#38;token=1383836775&#38;lang=zh_CN#rd</guid>
            <link>https://mp.weixin.qq.com/s?__biz=MzA4OTI5NjUwOA==&#38;mid=2649094405&#38;idx=1&#38;sn=76fa95b2d568a613ee5903f8d3976d4a&#38;chksm=880c4216bf7bcb00d586ffe8ded38f9c3b4426ec5ddfc0f8617a965327c402a814e03533dd08&#38;token=1383836775&#38;lang=zh_CN#rd</link>
        </item>
        <item>
            <title>
                <![CDATA[1024 分辨率下最快模型，字節跳動文生圖開放模型 SDXL-Lightning 發佈]]>
            </title>
            <description>
                <![CDATA[<div class="content"><p><img src="https://oscimg.oschina.net/oscnet/up-73d9ffe00a0d63e36ff98fa923e79b6bf92.png" alt="" referrerpolicy="no-referrer"></p><blockquote><p>文章來源｜字節跳動智能創作團隊</p></blockquote><p>很高興跟大家分享我們最新的文生圖模型 —— SDXL-Lightning，它實現了前所未有的速度和質量，並且已經向社區開放。</p><p>模型：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FByteDance%2FSDXL-Lightning" target="_blank">https://huggingface.co/ByteDance/SDXL-Lightning</a></p><p>論文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.13929" target="_blank">https://arxiv.org/abs/2402.13929</a></p><p><img src="https://oscimg.oschina.net/oscnet/up-dbb8391e5301fe0818c07c5007701e0819d.png" alt="" referrerpolicy="no-referrer"></p><h2>閃電般的圖像生成</h2><p>生成式 AI 正憑藉其根據文本提示（text prompts）創造出驚豔圖像乃至視頻的能力，贏得全球的矚目。然而，當前最先進的生成模型依賴於擴散過程（diffusion），這是一個將噪聲逐步轉化為圖像樣本的迭代過程。這個過程需要耗費巨大的計算資源並且速度較慢，在生成高質量圖像樣本的過程中，單張圖像的處理時間約為 5 秒，其中通常需要多次（20 到 40 次）調用龐大的神經網絡。這樣的速度限制了有快速、實時生成需求的應用場景。如何在提升生成質量的同時加快速度，是當前研究的熱點領域，也是我們工作的核心目標。</p><p>SDXL-Lightning 通過一種創新技術——<strong>漸進式對抗蒸餾（Progressive Adversarial Distillation）</strong>——突破了這一障礙，實現了前所未有的生成速度。該模型能夠在短短 2 步或 4 步內生成極高質量和分辨率的圖像，將計算成本和時間降低十倍。我們的方法甚至可以在 1 步內為超時敏感的應用生成圖像，雖然可能會稍微犧牲一些質量。</p><p>除了速度優勢，SDXL-Lightning 在圖像質量上也有顯著表現，並在評估中超越了以往的加速技術。在實現更高分辨率和更佳細節的同時保持良好的多樣性和圖文匹配度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6b51a9297b11683e92da115b696de953036.gif" alt="" referrerpolicy="no-referrer"> 速度對比示意</p><p>原始模型（20 步），我們的模型（2 步）</p><h2>模型效果</h2><p>我們的模型可以通過 1 步、2 步、4 步和 8 步來生成圖像。推理步驟越多，圖像質量越好。</p><p>以下是我們的 4 步生成結果： <img src="https://oscimg.oschina.net/oscnet/up-015feba9e22188c5c0903fb75dce3e8b13f.png" alt="" referrerpolicy="no-referrer"></p><p>以下是我們的 2 步生成結果： <img src="https://oscimg.oschina.net/oscnet/up-4943949b28735497159ae73bd6222f0c97a.png" alt="" referrerpolicy="no-referrer"></p><p>與以前的方法（Turbo 和 LCM）相比，我們的方法生成的圖像在細節上有顯著改進，並且更忠實於原始生成模型的風格和佈局。</p><p><img src="https://oscimg.oschina.net/oscnet/up-99a60575458ab118c0706dcfb0fcd00f199.png" alt="" referrerpolicy="no-referrer"></p><h2>回饋社區，開放模型</h2><p>開源開放的浪潮已經成為推動人工智能迅猛發展的關鍵力量，字節跳動也自豪地成為這股浪潮的一部分。我們的模型基於目前最流行的文字生成圖像開放模型 SDXL，該模型已經擁有一個繁榮的生態系統。現在，我們決定將 SDXL-Lightning 開放給全球的開發者、研究人員和創意從業者，以便他們能訪問並運用這一模型，進一步推動整個行業的創新和協作。</p><p>在設計 SDXL-Lightning 時，我們就考慮到與開放模型社區的兼容。社區中已有眾多藝術家和開發者創建了各種各樣的風格化圖像生成模型，例如卡通和動漫風格等。為了支持這些模型，我們提供 SDXL-Lightning 作為一個增速插件，它可以無縫地整合到這些多樣風格的 SDXL 模型中，為各種不同模型加快圖像生成的速度。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9b1d4811ae28daa9f18b7dc72848ab191b5.png" alt="" referrerpolicy="no-referrer"> 我們的模型也可以和目前非常流行的控制插件 ControlNet 相結合，實現極速可控的圖片生成。</p><p><img src="https://oscimg.oschina.net/oscnet/up-9215316be3b78c2af2c84a7df0cc9760b1f.png" alt="" referrerpolicy="no-referrer"> 我們的模型也支持開源社區裏目前最流行的生成軟件 ComfyUI，模型可以被直接加載來使用： <img src="https://oscimg.oschina.net/oscnet/up-db434e5743cd4966699ba28133c7606abfe.png" alt="" referrerpolicy="no-referrer"></p><h2>關於技術細節</h2><p>從理論上來説，圖像生成是一個由噪聲到清晰圖像的逐步轉化過程。在這一過程中，神經網絡學習在這個轉化流（flow）中各個位置上的梯度。</p><p>生成圖像的具體步驟是這樣的：首先，我們在流的起點，隨機採樣一個噪聲樣本，接着用神經網絡計算出梯度。根據當前位置上的梯度，我們對樣本進行微小的調整，然後不斷重複這一過程。每一次迭代，樣本都會更接近最終的圖像分佈，直至獲得一張清晰的圖像。</p><p><img src="https://oscimg.oschina.net/oscnet/up-586c0cfa75fa7c3308fa9421e66f6bb352d.png" alt="" referrerpolicy="no-referrer"><em>圖：生成流程</em><em>（</em><em>圖片來自</em><em>：</em><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2011.13456" target="_blank">https://arxiv.org/abs/2011.13456</a></em><em>）</em></p><p>由於生成流複雜且非直線，生成過程必須一次只走一小步以減少梯度誤差累積，所以需要神經網絡的頻繁計算，這就是計算量大的原因。</p><p><img src="https://oscimg.oschina.net/oscnet/up-13ed5521422c15757fe99d8e1c85130cdc0.png" alt="" referrerpolicy="no-referrer"><em>圖：曲線流程</em><em>（</em><em>圖片來自</em><em>：</em><em><a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2210.05475" target="_blank">https://arxiv.org/abs/2210.05475</a></em><em>）</em></p><p>為了減少生成圖像所需的步驟數量，許多研究致力於尋找解決方案。一些研究提出了能減少誤差的採樣方法，而其他研究則試圖使生成流更加直線化。儘管這些方法有所進展，但它們仍然需要超過 10 個推理步驟來生成圖像。</p><p>另一種方法是模型蒸餾，它能夠在少於 10 個推理步驟的情況下生成高質量圖像。不同於計算當前流位置下的梯度，模型蒸餾改變模型預測的目標，直接讓其預測下一個更遠的流位置。具體來説，我們訓練一個學生網絡直接預測老師網絡完成了多步推理的後的結果。這樣的策略可以大幅減少所需的推理步驟數量。通過反覆應用這個過程，我們可以進一步降低推理步驟的數量。這種方法被先前的研究稱之為漸進式蒸餾。</p><p><img src="https://oscimg.oschina.net/oscnet/up-6d96b685339c4b2a6d8f5b95cf6be348912.png" alt="" referrerpolicy="no-referrer"><em>圖：漸進式蒸餾</em><em>，學生網絡預測老師網絡多步後的結果</em></p><p>在實際操作中，學生網絡往往難以精確預測未來的流位置。誤差隨着每一步的累積而放大，導致在少於 8 步推理的情況下，模型產生的圖像開始變得模糊不清。</p><p>為瞭解決這個問題，我們的策略是不強求學生網絡精確匹配教師網絡的預測，而是讓學生網絡在概率分佈上與教師網絡保持一致。換言之，學生網絡被訓練來預測一個概率上可能的位置，即使這個位置並不完全準確，我們也不會對它進行懲罰。這個目標是通過對抗訓練來實現的，引入了一個額外的判別網絡來幫助實現學生網絡和教師網絡輸出的分佈匹配。</p><p>這是我們研究方法的簡要概述。在我們的技術論文（<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.13929" target="_blank">https://arxiv.org/abs/2402.13929</a>）中，我們提供了更深入的理論分析、訓練策略以及模型的具體公式化細節。</p><h2>SDXL-Lightning 之外</h2><p>儘管本研究主要探討瞭如何利用 SDXL-Lightning 技術進行圖像生成，但我們所提出的漸進式對抗蒸餾方法的應用潛力不侷限於靜態圖像的範疇。這一創新技術也可以被運用於快速且高質量生成視頻、音頻以及其他多模態內容。我們誠摯邀請您在 HuggingFace 平台上體驗 SDXL-Lightning，並期待您寶貴的意見和反饋。</p><p>模型：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FByteDance%2FSDXL-Lightning" target="_blank">https://huggingface.co/ByteDance/SDXL-Lightning</a></p><p>論文：<a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.13929" target="_blank">https://arxiv.org/abs/2402.13929</a></p></div>
                                    ]]>
            </description>
            <pubDate>Mon, 26 Feb 2024 07:36:47 GMT</pubDate>
            <guid isPermaLink="false">https://my.oschina.net/u/6210722/blog/11044777</guid>
            <link>https://my.oschina.net/u/6210722/blog/11044777</link>
            <author>
                <![CDATA[原創]]>
            </author>
        </item>
    </channel>
</rss>
